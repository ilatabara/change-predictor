id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fmagnum~master~I050e206b99793e0a07ba670d141b64592549c61b,openstack/magnum,master,I050e206b99793e0a07ba670d141b64592549c61b,Add wait condition on swarm services in swarm bay,MERGED,2015-05-21 18:06:21.000000000,2015-05-22 05:31:07.000000000,2015-05-22 05:31:05.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7494}, {'_account_id': 11650}]","[{'number': 1, 'created': '2015-05-21 18:06:21.000000000', 'files': ['magnum/templates/docker-swarm/swarm.yaml', 'magnum/templates/docker-swarm/fragments/write-swarm-manager-service.yaml', 'magnum/templates/docker-swarm/swarmnode.yaml', 'magnum/templates/docker-swarm/fragments/write-swarm-agent-service.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/4933edd80428820056f3b023a37c5d2332e814e4', 'message': 'Add wait condition on swarm services in swarm bay\n\nThis blocks the heat stack from going into CREATE_COMPLETE status until\nall of the swarm services have completely started. This also means that\nif the swarm services fail to start, the bay will eventually timeout\ninstead of going into CREATE_COMPLETE.\n\nChange-Id: I050e206b99793e0a07ba670d141b64592549c61b\nCloses-bug: #1452936\nCloses-bug: #1457596\n'}]",0,184841,4933edd80428820056f3b023a37c5d2332e814e4,8,4,1,5387,,,0,"Add wait condition on swarm services in swarm bay

This blocks the heat stack from going into CREATE_COMPLETE status until
all of the swarm services have completely started. This also means that
if the swarm services fail to start, the bay will eventually timeout
instead of going into CREATE_COMPLETE.

Change-Id: I050e206b99793e0a07ba670d141b64592549c61b
Closes-bug: #1452936
Closes-bug: #1457596
",git fetch https://review.opendev.org/openstack/magnum refs/changes/41/184841/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/templates/docker-swarm/fragments/write-swarm-manager-service.yaml', 'magnum/templates/docker-swarm/swarm.yaml', 'magnum/templates/docker-swarm/swarmnode.yaml', 'magnum/templates/docker-swarm/fragments/write-swarm-agent-service.yaml']",4,4933edd80428820056f3b023a37c5d2332e814e4,," ExecStartPost=/usr/bin/curl -sf -X PUT -H 'Content-Type: application/json' \ --data-binary '{""Status"": ""SUCCESS"", ""Reason"": ""Setup complete"", ""Data"": ""OK"", ""UniqueId"": ""00000""}' \ ""$WAIT_HANDLE""",,45,0
openstack%2Fnova~master~I2ace62158faaa0b6a7df3c32f2cb9f235d178013,openstack/nova,master,I2ace62158faaa0b6a7df3c32f2cb9f235d178013,Fix loading things in instance_extra for old instances,MERGED,2015-05-13 18:50:54.000000000,2015-05-22 03:09:12.000000000,2015-05-15 06:52:50.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 11530}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-13 18:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/462ab945fc2348966ba9389122d622bcea222f0b', 'message': ""Fix loading things in instance_extra for old instances\n\nIf we don't have db_inst['extra'] then we can't load those things. We\nshould just set them to None instead of exploding.\n\nChange-Id: I2ace62158faaa0b6a7df3c32f2cb9f235d178013\nCloses-Bug: #1446082\n""}, {'number': 2, 'created': '2015-05-13 19:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c38e5709fc318a2e8f119253f77b32288b4e6708', 'message': ""Fix loading things in instance_extra for old instances\n\nIf we don't have db_inst['extra'] then we can't load those things. We\nshould just set them to None instead of exploding.\n\nChange-Id: I2ace62158faaa0b6a7df3c32f2cb9f235d178013\nCloses-Bug: #1446082\n""}, {'number': 3, 'created': '2015-05-13 19:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a052ab38e9bc23e28e399810829b3bc42709f38', 'message': ""Fix loading things in instance_extra for old instances\n\nIf we don't have db_inst['extra'] then we can't load those things. We\nshould just set them to None instead of exploding.\n\nChange-Id: I2ace62158faaa0b6a7df3c32f2cb9f235d178013\nCloses-Bug: #1446082\n""}, {'number': 4, 'created': '2015-05-13 23:08:55.000000000', 'files': ['nova/objects/instance.py', 'nova/tests/unit/objects/test_instance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1bfb65d5ac8f7180edf3c4ecea09c8e15982bf27', 'message': ""Fix loading things in instance_extra for old instances\n\nIf we don't have db_inst['extra'] then we can't load those things. We\nshould just set them to None instead of exploding.\n\nChange-Id: I2ace62158faaa0b6a7df3c32f2cb9f235d178013\nCloses-Bug: #1446082\n""}]",14,182787,1bfb65d5ac8f7180edf3c4ecea09c8e15982bf27,47,13,4,4393,,,0,"Fix loading things in instance_extra for old instances

If we don't have db_inst['extra'] then we can't load those things. We
should just set them to None instead of exploding.

Change-Id: I2ace62158faaa0b6a7df3c32f2cb9f235d178013
Closes-Bug: #1446082
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/182787/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/objects/instance.py'],1,462ab945fc2348966ba9389122d622bcea222f0b,bug/1446082," instance_extra = db_inst.get('extra') or {} if instance_extra['flavor'] is not None: self._flavor_from_db(instance_extra['flavor']) # NOTE(danms): We can be called with a dict instead of a # SQLAlchemy object, so we have to be careful here if hasattr(db_inst, '__dict__'): have_extra = 'extra' in db_inst.__dict__ else: have_extra = 'extra' in db_inst if have_extra: instance._load_numa_topology( db_inst.get('extra').get('numa_topology')) else: instance.numa_topology = None if 'pci_requests' in expected_attrs: if have_extra: instance._load_pci_requests( db_inst.get('extra').get('pci_requests')) else: instance.pci_requests = None if 'vcpu_model' in expected_attrs: if have_extra: instance._load_vcpu_model( db_inst.get('extra').get('vcpu_model')) else: instance.vcpu_model = None", if db_inst['extra']['flavor'] is not None: self._flavor_from_db(db_inst['extra']['flavor']) instance._load_numa_topology( db_inst.get('extra').get('numa_topology')) if 'pci_requests' in expected_attrs: instance._load_pci_requests( db_inst.get('extra').get('pci_requests')) if 'vcpu_model' in expected_attrs: instance._load_vcpu_model(db_inst.get('extra').get('vcpu_model')),25,7
openstack%2Fdevstack~master~I81e4e3a6c97b0057610e6b256aff5df4da884e33,openstack/devstack,master,I81e4e3a6c97b0057610e6b256aff5df4da884e33,Use stevedore for keystone backends,MERGED,2015-05-11 15:34:31.000000000,2015-05-22 02:47:31.000000000,2015-05-15 22:59:18.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 6486}, {'_account_id': 7118}, {'_account_id': 7715}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-05-11 15:34:31.000000000', 'files': ['lib/keystone'], 'web_link': 'https://opendev.org/openstack/devstack/commit/331a64f9d087692cba10f3dd15c6b01595e1c127', 'message': 'Use stevedore for keystone backends\n\nWith bp stevedore, keystone will load backend drivers using\nstevedore entrypoints. Using the qualified class name is\ndeprecated.\n\nSince stevedore is going to validate that the entrypoint is\nfound, there\'s no need to list the valid backends, so backend\nvalidation was removed. This change will cause the server to fail\nto start if the backends are misconfigured rather than using the\ndefault one.\n\nThe names of the stevedore endpoints are ""sql"", ""ldap"", etc.,\nrather than the qualified class name, so the way that these\nare specified in KEYSTONE_IDENTITY_BACKEND, etc., is the same as\nthe stevedore entrypoint and there\'s no need to translate.\n\nChange-Id: I81e4e3a6c97b0057610e6b256aff5df4da884e33\n'}]",0,181937,331a64f9d087692cba10f3dd15c6b01595e1c127,21,7,1,6486,,,0,"Use stevedore for keystone backends

With bp stevedore, keystone will load backend drivers using
stevedore entrypoints. Using the qualified class name is
deprecated.

Since stevedore is going to validate that the entrypoint is
found, there's no need to list the valid backends, so backend
validation was removed. This change will cause the server to fail
to start if the backends are misconfigured rather than using the
default one.

The names of the stevedore endpoints are ""sql"", ""ldap"", etc.,
rather than the qualified class name, so the way that these
are specified in KEYSTONE_IDENTITY_BACKEND, etc., is the same as
the stevedore entrypoint and there's no need to translate.

Change-Id: I81e4e3a6c97b0057610e6b256aff5df4da884e33
",git fetch https://review.opendev.org/openstack/devstack refs/changes/37/181937/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/keystone'],1,331a64f9d087692cba10f3dd15c6b01595e1c127,bp/stevedore,"# Select the Catalog backend driver# Select the token persistence backend driver# Select the Identity backend driver# Select the Assignment backend driver# Select Keystone's token provider (and format) # Choose from 'uuid', 'pki', 'pkiz', or 'fernet' iniset $KEYSTONE_CONF identity driver ""$KEYSTONE_IDENTITY_BACKEND"" iniset $KEYSTONE_CONF assignment driver ""$KEYSTONE_ASSIGNMENT_BACKEND"" iniset $KEYSTONE_CONF token provider $KEYSTONE_TOKEN_FORMAT iniset $KEYSTONE_CONF token driver ""$KEYSTONE_TOKEN_BACKEND"" iniset $KEYSTONE_CONF catalog driver ""$KEYSTONE_CATALOG_BACKEND""","# Select the backend for Keystone's service catalog# Select the backend for Tokens# Select the backend for Identity# Select the backend for Assignment# Select Keystone's token format # Choose from 'UUID', 'PKI', or 'PKIZ'# valid identity backends as per dir keystone/identity/backends KEYSTONE_VALID_IDENTITY_BACKENDS=kvs,ldap,pam,sql # valid assignment backends as per dir keystone/identity/backends KEYSTONE_VALID_ASSIGNMENT_BACKENDS=kvs,ldap,sql # check if identity backend is valid if [[ ""$KEYSTONE_VALID_IDENTITY_BACKENDS"" =~ ""$KEYSTONE_IDENTITY_BACKEND"" ]]; then iniset $KEYSTONE_CONF identity driver ""keystone.identity.backends.$KEYSTONE_IDENTITY_BACKEND.Identity"" fi # check if assignment backend is valid if [[ ""$KEYSTONE_VALID_ASSIGNMENT_BACKENDS"" =~ ""$KEYSTONE_ASSIGNMENT_BACKEND"" ]]; then iniset $KEYSTONE_CONF assignment driver ""keystone.assignment.backends.$KEYSTONE_ASSIGNMENT_BACKEND.Assignment"" fi iniset $KEYSTONE_CONF token provider keystone.token.providers.$KEYSTONE_TOKEN_FORMAT.Provider if [[ ""$KEYSTONE_TOKEN_BACKEND"" = ""sql"" ]]; then iniset $KEYSTONE_CONF token driver keystone.token.persistence.backends.sql.Token elif [[ ""$KEYSTONE_TOKEN_BACKEND"" = ""memcache"" ]]; then iniset $KEYSTONE_CONF token driver keystone.token.persistence.backends.memcache.Token else iniset $KEYSTONE_CONF token driver keystone.token.persistence.backends.kvs.Token fi iniset $KEYSTONE_CONF catalog driver keystone.catalog.backends.sql.Catalog iniset $KEYSTONE_CONF catalog driver ""keystone.catalog.backends.templated.Catalog""",11,31
openstack%2Fapi-site~master~Iebb49c05c0617dc6b48083cc85d4ac29a78b0531,openstack/api-site,master,Iebb49c05c0617dc6b48083cc85d4ac29a78b0531,"Description for ""subnet ID"" in create a load balancer pool is not accurate",MERGED,2015-05-14 14:26:56.000000000,2015-05-22 02:38:41.000000000,2015-05-22 02:38:40.000000000,"[{'_account_id': 3}, {'_account_id': 2448}]","[{'number': 1, 'created': '2015-05-14 14:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/f3a85eda3ea923ca10328aff334febf6cc06a2f9', 'message': 'Description for ""subnet"" in create ""Create a load balancer pool"" not accurate\n\nCurrently, in http://developer.openstack.org/api-ref-networking-v2-ext.html\nunder Create Loadbalancer pool the description for subnet_id is\nwronly mentioned. Now this is corrected.\nAlso the descripton for lb_algorithm is added.\n\nCloses-Bug: #1453750\nChange-Id: Iebb49c05c0617dc6b48083cc85d4ac29a78b0531\n'}, {'number': 2, 'created': '2015-05-20 02:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/f02b75e6fce581c7e981caea5e32e657ce104c15', 'message': 'Description for ""subnet"" in create ""Create a load balancer pool"" not accurate\n\nCurrently, in http://developer.openstack.org/api-ref-networking-v2-ext.html\nunder Create Loadbalancer pool the description for subnet_id is\nwronly mentioned. Now this is corrected.\nAlso the descripton for lb_algorithm is added.\n\nCloses-Bug: #1453750\nChange-Id: Iebb49c05c0617dc6b48083cc85d4ac29a78b0531\n'}, {'number': 3, 'created': '2015-05-20 02:14:01.000000000', 'files': ['api-ref/src/docbkx/ch_netconn-v2-ext.xml', 'api-ref/src/wadls/netconn-api/src/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/849397a3b4f4516f101ebc1dbb3fc5221cfb8b57', 'message': 'Description for ""subnet ID"" in create a load balancer pool is not accurate\n\nCorrects the create load balancer pool description for subnet_id\nAdds the descripton for lb_algorithm\n\nCloses-Bug: #1453750\nChange-Id: Iebb49c05c0617dc6b48083cc85d4ac29a78b0531\n'}]",0,183059,849397a3b4f4516f101ebc1dbb3fc5221cfb8b57,10,2,3,15899,,,0,"Description for ""subnet ID"" in create a load balancer pool is not accurate

Corrects the create load balancer pool description for subnet_id
Adds the descripton for lb_algorithm

Closes-Bug: #1453750
Change-Id: Iebb49c05c0617dc6b48083cc85d4ac29a78b0531
",git fetch https://review.opendev.org/openstack/api-site refs/changes/59/183059/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/netconn-api/src/common.ent'],1,f3a85eda3ea923ca10328aff334febf6cc06a2f9,fix-bug-1453750," <para>The ID of the subnet on which to allocate the VIP address.</para> </wadl:doc> </param> <param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" name=""lb_algorithm"" style=""plain"" type=""xsd:string""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN"">",,8,0
openstack%2Fapi-site~master~I4a59f79720715d6469433f0aa4d1d96f030cfc1b,openstack/api-site,master,I4a59f79720715d6469433f0aa4d1d96f030cfc1b,Document API changes for stack tags in Heat,MERGED,2015-05-18 17:40:46.000000000,2015-05-22 02:38:39.000000000,2015-05-22 02:38:37.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 7253}]","[{'number': 1, 'created': '2015-05-18 17:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/fbd10948898e851f623bbdb3ad7dfa1d17a29346', 'message': 'Document API changes for stack tags in Heat\n\nChange-Id: I4a59f79720715d6469433f0aa4d1d96f030cfc1b\n'}, {'number': 2, 'created': '2015-05-18 19:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/6affba5ce1bb97e4839696224adf8d8c71f619e1', 'message': 'Document API changes for stack tags in Heat\n\nChange-Id: I4a59f79720715d6469433f0aa4d1d96f030cfc1b\n'}, {'number': 3, 'created': '2015-05-19 18:49:51.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/samples/stack_list_resp.json', 'api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack_show_resp.json', 'api-ref/src/wadls/orchestration-api/src/v1/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/297ebcb4cbb128998b76717a53cc20cbe02f09b1', 'message': 'Document API changes for stack tags in Heat\n\nChange-Id: I4a59f79720715d6469433f0aa4d1d96f030cfc1b\n'}]",1,184101,297ebcb4cbb128998b76717a53cc20cbe02f09b1,13,3,3,7253,,,0,"Document API changes for stack tags in Heat

Change-Id: I4a59f79720715d6469433f0aa4d1d96f030cfc1b
",git fetch https://review.opendev.org/openstack/api-site refs/changes/01/184101/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/orchestration-api/src/v1/samples/stack_list_resp.json', 'api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack_show_resp.json', 'api-ref/src/wadls/orchestration-api/src/v1/common.ent']",4,fbd10948898e851f623bbdb3ad7dfa1d17a29346,stack-tags,"<!ENTITY tagsParameter ' <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""tags"" style=""plain"" required=""false""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> A list of simple string tags to associate with the stack. If multiple tags are passed, they should be separated by commas. For example, <code>tag1,tag2</code>. </para> </wadl:doc> </param> '>",,64,4
openstack%2Fdevstack~master~I569b406db46cf6bdabcbfd8c5eb6f3cbdbc3cff7,openstack/devstack,master,I569b406db46cf6bdabcbfd8c5eb6f3cbdbc3cff7,Remove KEYSTONE_AUTH_CACHE_DIR,MERGED,2015-05-11 17:54:58.000000000,2015-05-22 02:09:58.000000000,2015-05-22 02:09:57.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6486}, {'_account_id': 7118}, {'_account_id': 7715}]","[{'number': 1, 'created': '2015-05-11 17:54:58.000000000', 'files': ['lib/keystone'], 'web_link': 'https://opendev.org/openstack/devstack/commit/eb7a0d9b2d22da3d1e0fbc3f581c597a1a510666', 'message': ""Remove KEYSTONE_AUTH_CACHE_DIR\n\nKeystone doesn't use a cache directory.\n\nChange-Id: I569b406db46cf6bdabcbfd8c5eb6f3cbdbc3cff7\n""}]",0,182002,eb7a0d9b2d22da3d1e0fbc3f581c597a1a510666,12,5,1,6486,,,0,"Remove KEYSTONE_AUTH_CACHE_DIR

Keystone doesn't use a cache directory.

Change-Id: I569b406db46cf6bdabcbfd8c5eb6f3cbdbc3cff7
",git fetch https://review.opendev.org/openstack/devstack refs/changes/02/182002/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/keystone'],1,eb7a0d9b2d22da3d1e0fbc3f581c597a1a510666,keysteve,,KEYSTONE_AUTH_CACHE_DIR=${KEYSTONE_AUTH_CACHE_DIR:-/var/cache/keystone} # Create cache dir sudo install -d -o $STACK_USER $KEYSTONE_AUTH_CACHE_DIR rm -f $KEYSTONE_AUTH_CACHE_DIR/*,0,5
openstack%2Fdevstack~master~Ifee92127f32db85d4d55f665471c8da1c9a970e7,openstack/devstack,master,Ifee92127f32db85d4d55f665471c8da1c9a970e7,Remove setting nonexistant [ec2] driver option in keystone,MERGED,2015-05-11 15:38:07.000000000,2015-05-22 02:09:05.000000000,2015-05-22 02:09:02.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6486}, {'_account_id': 7118}, {'_account_id': 7715}, {'_account_id': 8119}]","[{'number': 1, 'created': '2015-05-11 15:38:07.000000000', 'files': ['lib/keystone'], 'web_link': 'https://opendev.org/openstack/devstack/commit/71a8eccdc3594b2e0395d7df75e69eb877269e81', 'message': ""Remove setting nonexistant [ec2] driver option in keystone\n\nThere's no [ec2] driver option in keystone.\n\nChange-Id: Ifee92127f32db85d4d55f665471c8da1c9a970e7\n""}]",0,181939,71a8eccdc3594b2e0395d7df75e69eb877269e81,13,6,1,6486,,,0,"Remove setting nonexistant [ec2] driver option in keystone

There's no [ec2] driver option in keystone.

Change-Id: Ifee92127f32db85d4d55f665471c8da1c9a970e7
",git fetch https://review.opendev.org/openstack/devstack refs/changes/39/181939/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/keystone'],1,71a8eccdc3594b2e0395d7df75e69eb877269e81,keysteve,," iniset $KEYSTONE_CONF ec2 driver ""keystone.contrib.ec2.backends.sql.Ec2""",0,1
openstack%2Fapi-site~master~I869a9e1996d55549fdbaa6d84dfffc2595bd7e9c,openstack/api-site,master,I869a9e1996d55549fdbaa6d84dfffc2595bd7e9c,Adds associate security group action to Compute API v2,MERGED,2015-05-18 15:42:03.000000000,2015-05-22 01:20:00.000000000,2015-05-22 01:19:59.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 15293}]","[{'number': 1, 'created': '2015-05-18 15:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/98afc77c58d7c9fa57bb956c1186933590f96859', 'message': 'Adds associate security group action to Compute API v2\n\nChange-Id: I869a9e1996d55549fdbaa6d84dfffc2595bd7e9c\nCloses-bug:1456189\n'}, {'number': 2, 'created': '2015-05-18 19:02:47.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2/api_samples/server-action-associatesecgroup.json', 'api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/f6d2698bcbee37b8f5de840d58571f1989c500b9', 'message': 'Adds associate security group action to Compute API v2\n\nChange-Id: I869a9e1996d55549fdbaa6d84dfffc2595bd7e9c\nCloses-bug:1456189\n'}]",1,184085,f6d2698bcbee37b8f5de840d58571f1989c500b9,13,3,2,964,,,0,"Adds associate security group action to Compute API v2

Change-Id: I869a9e1996d55549fdbaa6d84dfffc2595bd7e9c
Closes-bug:1456189
",git fetch https://review.opendev.org/openstack/api-site refs/changes/85/184085/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/compute-api/src/v2/api_samples/server-action-associatesecgroup.json', 'api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl']",2,98afc77c58d7c9fa57bb956c1186933590f96859,bug/1456189," <method name=""POST"" id=""associateSecGroup""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"" title=""Associate security group with server""> <para role=""shortdesc"">Applies a specified security group to a server. Specify the <code>addSecurityGroup</code> action and the name of the security group in the request body.</para> </wadl:doc> <request> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../api_samples/server-action-associatesecgroup.json""/> </wadl:doc> </representation> </request> <response status=""202""/> <!-- Common, GET, postput, inProgress Faults--> &commonFaults; &getFaults; &postPutFaults; &inProgressFault; </method>",,22,0
openstack%2Fnova~master~I74e270304e03a843e6051afcaae7812af5564875,openstack/nova,master,I74e270304e03a843e6051afcaae7812af5564875,Additional cleanup after compute RPC 3.x removal,MERGED,2015-05-12 20:54:46.000000000,2015-05-22 01:06:16.000000000,2015-05-22 01:06:13.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-12 20:54:46.000000000', 'files': ['nova/tests/unit/compute/test_rpcapi.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dee72c8e76c415851d5bcd1f6cdd0e31f3d16129', 'message': 'Additional cleanup after compute RPC 3.x removal\n\nThis change does some additional cleanup like removing the now orphaned\n_spawn() method and a related test. Furthermore it does away with some\nrpcapi test stuff that no longer applies and also makes sure we send\nobjects instead of primitives in all rpcapi tests. Finally, some left-\nover parameters in the client-side attach_volume() method are removed\nsince those are no longer needed.\n\nChange-Id: I74e270304e03a843e6051afcaae7812af5564875\n'}]",0,182450,dee72c8e76c415851d5bcd1f6cdd0e31f3d16129,15,11,1,6450,,,0,"Additional cleanup after compute RPC 3.x removal

This change does some additional cleanup like removing the now orphaned
_spawn() method and a related test. Furthermore it does away with some
rpcapi test stuff that no longer applies and also makes sure we send
objects instead of primitives in all rpcapi tests. Finally, some left-
over parameters in the client-side attach_volume() method are removed
since those are no longer needed.

Change-Id: I74e270304e03a843e6051afcaae7812af5564875
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/182450/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_rpcapi.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py']",6,dee72c8e76c415851d5bcd1f6cdd0e31f3d16129,drop-compute-v3," self.compute_rpcapi.attach_volume(context, instance, volume_bdm)"," self.compute_rpcapi.attach_volume(context, instance=instance, volume_id=volume_id, mountpoint=device, bdm=volume_bdm)",14,131
openstack%2Fnova~master~I63320b966f74485652be0a441b8ce212cf85cd76,openstack/nova,master,I63320b966f74485652be0a441b8ce212cf85cd76,Use EnumField for instance external event name,MERGED,2015-05-14 17:47:22.000000000,2015-05-22 01:00:06.000000000,2015-05-22 01:00:03.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15882}]","[{'number': 1, 'created': '2015-05-14 17:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c232ea08d9cecf0003c0bd1198c76dbd26d09761', 'message': 'Use EnumField for instance external event name\n\nChange-Id: I63320b966f74485652be0a441b8ce212cf85cd76\n'}, {'number': 2, 'created': '2015-05-14 18:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28169ed77b3ee050c8e202bddcb88a5961b534f6', 'message': 'Use EnumField for instance external event name\n\nChange-Id: I63320b966f74485652be0a441b8ce212cf85cd76\n'}, {'number': 3, 'created': '2015-05-14 18:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bba9b8db95765ef933435fe795fd22fbf27c2f26', 'message': 'Use EnumField for instance external event name\n\nThere is no need to bump the version since the format is not changed.\nChange-Id: I63320b966f74485652be0a441b8ce212cf85cd76\n'}, {'number': 4, 'created': '2015-05-15 17:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5818f1d2f68fa37d6fffbcf2cc4f8f70708a7573', 'message': 'Use EnumField for instance external event name\n\nThere is no need to bump the version since the format is not changed.\nChange-Id: I63320b966f74485652be0a441b8ce212cf85cd76\n'}, {'number': 5, 'created': '2015-05-20 22:16:53.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_external_event.py', 'nova/objects/external_event.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/72c631d63821da80644b715295f501b97e4b5dc5', 'message': 'Use EnumField for instance external event name\n\nThere is no need to bump the version since the format is not changed.\nChange-Id: I63320b966f74485652be0a441b8ce212cf85cd76\n'}]",11,183131,72c631d63821da80644b715295f501b97e4b5dc5,61,15,5,6685,,,0,"Use EnumField for instance external event name

There is no need to bump the version since the format is not changed.
Change-Id: I63320b966f74485652be0a441b8ce212cf85cd76
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/183131/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_external_event.py', 'nova/objects/external_event.py']",4,c232ea08d9cecf0003c0bd1198c76dbd26d09761,bug/enum," # Version 1.1: changes 'name' to be EnumField VERSION = '1.1' 'name': fields.EnumField(valid_values=EVENT_NAMES),"," VERSION = '1.0' 'name': fields.StringField(),",25,13
openstack%2Fpycadf~master~Ic723041f70b03b2bbb346ba3d1013528c1cf2b22,openstack/pycadf,master,Ic723041f70b03b2bbb346ba3d1013528c1cf2b22,Remove script already nuked from oslo-incubator,MERGED,2015-05-16 20:02:56.000000000,2015-05-22 00:58:00.000000000,2015-05-22 00:57:59.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6537}]","[{'number': 1, 'created': '2015-05-16 20:02:56.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/2cc7a4077e62a9c0cac5c0caf8de598c52d0a189', 'message': 'Remove script already nuked from oslo-incubator\n\nChange-Id: Ic723041f70b03b2bbb346ba3d1013528c1cf2b22\n'}]",0,183831,2cc7a4077e62a9c0cac5c0caf8de598c52d0a189,7,3,1,5638,,,0,"Remove script already nuked from oslo-incubator

Change-Id: Ic723041f70b03b2bbb346ba3d1013528c1cf2b22
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/31/183831/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,2cc7a4077e62a9c0cac5c0caf8de598c52d0a189,,,script=tools/run_cross_tests.sh,0,1
openstack%2Fopenstack-manuals~master~Id218c80526ac33d8b095d8b6d43cd70982bb6ef2,openstack/openstack-manuals,master,Id218c80526ac33d8b095d8b6d43cd70982bb6ef2,Correct the URL for the rdo-release package,ABANDONED,2015-05-18 21:39:26.000000000,2015-05-22 00:37:22.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 9162}, {'_account_id': 14320}, {'_account_id': 15279}]","[{'number': 1, 'created': '2015-05-18 21:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/075dedf3074c59fc2244f144be0581c4ef2d9e8b', 'message': 'Correct the URL for the rdo-release package\n\nChange-Id: Id218c80526ac33d8b095d8b6d43cd70982bb6ef2\nCloses-Bug: #1452991\n'}, {'number': 2, 'created': '2015-05-18 22:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5b2a148d5fb4443aec914b4d0f69d5f670c9d794', 'message': 'Correct the URL for the rdo-release package\nRevert URL to http\n\nChange-Id: Id218c80526ac33d8b095d8b6d43cd70982bb6ef2\nCloses-Bug: #1452991\n'}, {'number': 3, 'created': '2015-05-21 00:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ce4254e2be4a8c3e9a5009789dbc8c4d0dd99cf5', 'message': 'Correct the URL for the rdo-release package\n\nRevert URL to http\n\nChange-Id: Id218c80526ac33d8b095d8b6d43cd70982bb6ef2\nCloses-Bug: #1452991\n'}, {'number': 4, 'created': '2015-05-21 06:26:05.000000000', 'files': ['doc/install-guide/section_basics-packages.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ef82424cc8754a4cb96778dacbf251cd15b8b3ae', 'message': 'Correct the URL for the rdo-release package\n\nChange-Id: Id218c80526ac33d8b095d8b6d43cd70982bb6ef2\nCloses-Bug: #1452991\n'}]",2,184131,ef82424cc8754a4cb96778dacbf251cd15b8b3ae,17,7,4,15279,,,0,"Correct the URL for the rdo-release package

Change-Id: Id218c80526ac33d8b095d8b6d43cd70982bb6ef2
Closes-Bug: #1452991
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/31/184131/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_basics-packages.xml'],1,075dedf3074c59fc2244f144be0581c4ef2d9e8b,bug/1452991," <screen os=""fedora;centos;rhel""><prompt>#</prompt> <userinput>yum install https://repos.fedorapeople.org/repos/openstack/openstack-kilo/rdo-release-kilo-1.noarch.rpm</userinput></screen>"," <screen os=""fedora;centos;rhel""><prompt>#</prompt> <userinput>yum install http://rdo.fedorapeople.org/openstack-kilo/rdo-release-kilo.rpm</userinput></screen>",1,1
openstack%2Fdiskimage-builder~master~Ieb633b31214f1accf03b92a2b06590fdf2127b6b,openstack/diskimage-builder,master,Ieb633b31214f1accf03b92a2b06590fdf2127b6b,redhat-common: rename 01-clean-old-kernels.sh to drop .sh extension,MERGED,2015-05-20 14:28:28.000000000,2015-05-22 00:35:02.000000000,2015-05-22 00:35:00.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 9369}]","[{'number': 1, 'created': '2015-05-20 14:28:28.000000000', 'files': ['elements/redhat-common/finalise.d/01-clean-old-kernels'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f91df5dfc66909e811f02ff4ef0087e742d00bda', 'message': 'redhat-common: rename 01-clean-old-kernels.sh to drop .sh extension\n\ndib-run-parts filters the acceptable characters in script names,\nand ""."" is not allowed (see $allowed_regex there), so\n01-clean-old-kernels.sh is never executed.\n\nRename it to drop its .sh extension, so it is executed for real.\n\nChange-Id: Ieb633b31214f1accf03b92a2b06590fdf2127b6b\n'}]",0,184509,f91df5dfc66909e811f02ff4ef0087e742d00bda,8,3,1,12320,,,0,"redhat-common: rename 01-clean-old-kernels.sh to drop .sh extension

dib-run-parts filters the acceptable characters in script names,
and ""."" is not allowed (see $allowed_regex there), so
01-clean-old-kernels.sh is never executed.

Rename it to drop its .sh extension, so it is executed for real.

Change-Id: Ieb633b31214f1accf03b92a2b06590fdf2127b6b
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/09/184509/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/redhat-common/finalise.d/01-clean-old-kernels'],1,f91df5dfc66909e811f02ff4ef0087e742d00bda,,,,0,0
openstack%2Fhorizon~stable%2Fkilo~I307b3511e44072d306ea6da2d849271afb8e4aa8,openstack/horizon,stable/kilo,I307b3511e44072d306ea6da2d849271afb8e4aa8,"test patch, please ignore",ABANDONED,2015-05-20 22:37:27.000000000,2015-05-22 00:12:19.000000000,,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 9981}]","[{'number': 1, 'created': '2015-05-20 22:37:27.000000000', 'files': ['.jshintrc'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2e19b17b5ef4ab0f9f9d3103bb4941309484bd5c', 'message': 'test patch, please ignore\n\nChange-Id: I307b3511e44072d306ea6da2d849271afb8e4aa8\n'}]",0,184643,2e19b17b5ef4ab0f9f9d3103bb4941309484bd5c,8,3,1,4264,,,0,"test patch, please ignore

Change-Id: I307b3511e44072d306ea6da2d849271afb8e4aa8
",git fetch https://review.opendev.org/openstack/horizon refs/changes/43/184643/1 && git format-patch -1 --stdout FETCH_HEAD,['.jshintrc'],1,2e19b17b5ef4ab0f9f9d3103bb4941309484bd5c,fix_jshint_issues," ""unused"": false, ""undef"": false,",,2,0
openstack%2Fproject-config~master~I1493da3e6e5c4920772f60400dde69faccdc6b60,openstack/project-config,master,I1493da3e6e5c4920772f60400dde69faccdc6b60,Add beaker-rspec jobs to puppet-openstackci repo,MERGED,2015-05-21 23:01:35.000000000,2015-05-22 00:02:17.000000000,2015-05-22 00:02:15.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6316}, {'_account_id': 6554}, {'_account_id': 11610}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-05-21 23:01:35.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/42184c49928a10021af30695e00b7cbb9b62c202', 'message': 'Add beaker-rspec jobs to puppet-openstackci repo\n\nChange-Id: I1493da3e6e5c4920772f60400dde69faccdc6b60\n'}]",0,184897,42184c49928a10021af30695e00b7cbb9b62c202,10,6,1,5263,,,0,"Add beaker-rspec jobs to puppet-openstackci repo

Change-Id: I1493da3e6e5c4920772f60400dde69faccdc6b60
",git fetch https://review.opendev.org/openstack/project-config refs/changes/97/184897/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,42184c49928a10021af30695e00b7cbb9b62c202,downstream-puppet, - name: ^gate-puppet-openstackci-puppet-beaker-rspec-dsvm-.*$ voting: false - name: puppet-beaker-jobs,,5,0
openstack%2Fapp-catalog~master~Ieddc187a9197ce2573732ac52e96f701e48e078b,openstack/app-catalog,master,Ieddc187a9197ce2573732ac52e96f701e48e078b,Remove RAX supported templates,MERGED,2015-05-21 22:32:34.000000000,2015-05-21 23:43:52.000000000,2015-05-21 22:41:10.000000000,"[{'_account_id': 3}, {'_account_id': 7256}, {'_account_id': 9788}, {'_account_id': 16145}]","[{'number': 1, 'created': '2015-05-21 22:32:34.000000000', 'files': ['openstack_catalog/web/static/heat_templates.yaml'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/e9a9892f95806df5e35fccf5c960f7d613acdc08', 'message': ""Remove RAX supported templates\n\nTemplates were incorrectly added to the catalog which say supported by\nRackspace by someone who does not work at Rackspace and does not have\nRackspace's permission to add templates to the catalog which say they\nare supported by Rackspace.\n\nChange-Id: Ieddc187a9197ce2573732ac52e96f701e48e078b\n""}]",0,184887,e9a9892f95806df5e35fccf5c960f7d613acdc08,8,4,1,6434,,,0,"Remove RAX supported templates

Templates were incorrectly added to the catalog which say supported by
Rackspace by someone who does not work at Rackspace and does not have
Rackspace's permission to add templates to the catalog which say they
are supported by Rackspace.

Change-Id: Ieddc187a9197ce2573732ac52e96f701e48e078b
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/87/184887/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/web/static/heat_templates.yaml'],1,e9a9892f95806df5e35fccf5c960f7d613acdc08,REMOVE-RAX-TEMPLATES,, name: Gitlab CE provided_by: name: Rackspace company: Rackspace description: > This is a template to deploy Gitlab on a single Linux server with OpenStack Heat. This template uses chef-solo to configure the server. More details on usage and options can be found at: https://github.com/rackspace-orchestration-templates/gitlab release: - Icehouse - Juno - Kilo format: HOT supported_by: Rackspace license: Apache 2.0 attributes: url: https://github.com/rackspace-orchestration-templates/gitlab/blob/master/gitlab.yaml - name: Minecraft provided_by: name: Rackspace company: Rackspace description: > This is a Heat template to deploy a single Linux server running a Minecraft server. The Minecraft server will be setup leveraging Chef solo. More details on usage and options can be found at: https://github.com/rackspace-orchestration-templates/minecraft release: - Icehouse - Juno - Kilo format: HOT supported_by: Rackspace license: Apache 2.0 attributes: url: https://github.com/rackspace-orchestration-templates/minecraft/blob/master/minecraft-server.yaml -,0,41
openstack%2Fnova~master~I5bf22823bfdb235f10a434428c14c85816990601,openstack/nova,master,I5bf22823bfdb235f10a434428c14c85816990601,simple_tenant_usage: declare method static,ABANDONED,2015-03-17 10:36:17.000000000,2015-05-21 23:32:53.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-17 10:36:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/001080b353d0d93062cdb494d47356d50e38da61', 'message': 'simple_tenant_usage: declare method static\n\nSome methods are not relying on the instance, so declare them as static.\n\nChange-Id: I5bf22823bfdb235f10a434428c14c85816990601\n'}, {'number': 2, 'created': '2015-03-18 16:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9eece1e0fe1e9c31df3f12c48920f061009465d', 'message': 'simple_tenant_usage: declare method static\n\nSome methods are not relying on the instance, so declare them as static.\n\nChange-Id: I5bf22823bfdb235f10a434428c14c85816990601\n'}, {'number': 3, 'created': '2015-03-19 09:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a231031d055fb63ca010e58f77c3de18a3693ee4', 'message': 'simple_tenant_usage: declare method static\n\nSome methods are not relying on the instance, so declare them as static.\n\nChange-Id: I5bf22823bfdb235f10a434428c14c85816990601\n'}, {'number': 4, 'created': '2015-03-20 07:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f20330ec843ce95737b2e8729c4f42262c41de56', 'message': 'simple_tenant_usage: declare method static\n\nSome methods are not relying on the instance, so declare them as static.\n\nChange-Id: I5bf22823bfdb235f10a434428c14c85816990601\n'}, {'number': 5, 'created': '2015-03-20 10:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f028306ea688f606e97ebdfa8195a669852c6b1', 'message': 'simple_tenant_usage: declare method static\n\nSome methods are not relying on the instance, so declare them as static.\n\nChange-Id: I5bf22823bfdb235f10a434428c14c85816990601\n'}, {'number': 6, 'created': '2015-04-24 14:56:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dc0355db73a42367e0bb581ef0f1a1ec3e0b742c', 'message': 'simple_tenant_usage: declare method static\n\nSome methods are not relying on the instance, so declare them as static.\n\nChange-Id: I5bf22823bfdb235f10a434428c14c85816990601\n'}, {'number': 7, 'created': '2015-05-12 08:41:57.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/simple_tenant_usage.py', 'nova/api/openstack/compute/contrib/simple_tenant_usage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0b4315bab1ee756f700a0ab2b1bb4782136df76a', 'message': 'simple_tenant_usage: declare method static\n\nSome methods are not relying on the instance, so declare them as static.\n\nChange-Id: I5bf22823bfdb235f10a434428c14c85816990601\n'}]",2,165017,0b4315bab1ee756f700a0ab2b1bb4782136df76a,54,11,7,1669,,,0,"simple_tenant_usage: declare method static

Some methods are not relying on the instance, so declare them as static.

Change-Id: I5bf22823bfdb235f10a434428c14c85816990601
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/165017/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/simple_tenant_usage.py', 'nova/api/openstack/compute/contrib/simple_tenant_usage.py']",2,001080b353d0d93062cdb494d47356d50e38da61,jd/remove-strtime," @staticmethod def _hours_for(instance, period_start, period_stop): @staticmethod def _get_flavor(context, instance, flavors_cache): @staticmethod def _parse_datetime(dtstr): @staticmethod def get_resources():"," def _hours_for(self, instance, period_start, period_stop): def _get_flavor(self, context, instance, flavors_cache): def _parse_datetime(self, dtstr): def get_resources(self):",16,8
openstack%2Fnova~master~Ic0036b85768018214dc4fe672e9325b5d04d3c26,openstack/nova,master,Ic0036b85768018214dc4fe672e9325b5d04d3c26,"Leverage timeutils, drop strtime()",ABANDONED,2015-03-16 15:52:26.000000000,2015-05-21 23:32:47.000000000,,"[{'_account_id': 3}, {'_account_id': 1446}, {'_account_id': 1653}, {'_account_id': 1669}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-16 15:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4e658643dc27fdedbefc0837a5e5dbe4e286236', 'message': ""simple_tenant_usage: levera timeutils, drop strtime()\n\nThis patch remove some code that tried to parse time in different way by\nleveraging timeutils instead. It also drops strtime() usage as it's\ngoing to be deprecated in oslo_utils (see\nI8b5119e64369ccac3423dccc04421f99912df733).\n\nChange-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26\n""}, {'number': 2, 'created': '2015-03-16 15:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2ad107a15a111ae5dbb670b11cb9df0e6ca9fef', 'message': ""simple_tenant_usage: levera timeutils, drop strtime()\n\nThis patch remove some code that tried to parse time in different way by\nleveraging timeutils instead. It also drops strtime() usage as it's\ngoing to be deprecated in oslo_utils (see\nI8b5119e64369ccac3423dccc04421f99912df733).\n\nChange-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26\n""}, {'number': 3, 'created': '2015-03-17 09:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2bdf910cfbe7f68bece862005b0e17d590ba2cb', 'message': ""simple_tenant_usage: leverage timeutils, drop strtime()\n\nThis patch remove some code that tried to parse time in different way by\nleveraging timeutils instead. It also drops strtime() usage as it's\ngoing to be deprecated in oslo_utils (see\nI8b5119e64369ccac3423dccc04421f99912df733).\n\nChange-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26\n""}, {'number': 4, 'created': '2015-03-17 10:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/813062f79b0ef0594ea5ccb6cd19c52e1de4534f', 'message': ""simple_tenant_usage: leverage timeutils, drop strtime()\n\nThis patch remove some code that tried to parse time in different way by\nleveraging timeutils instead. It also drops strtime() usage as it's\ngoing to be deprecated in oslo_utils (see\nI8b5119e64369ccac3423dccc04421f99912df733).\n\nChange-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26\n""}, {'number': 5, 'created': '2015-03-17 10:36:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24ba0dce6bf00955aa7d6ba061e5fe0060d72db2', 'message': ""simple_tenant_usage: leverage timeutils, drop strtime()\n\nThis patch remove some code that tried to parse time in different way by\nleveraging timeutils instead. It also drops strtime() usage as it's\ngoing to be deprecated in oslo_utils (see\nI8b5119e64369ccac3423dccc04421f99912df733).\n\nChange-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26\n""}, {'number': 6, 'created': '2015-03-18 16:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eba3402f80a598d57b90c7e7744dcf6f1b7b542d', 'message': ""Leverage timeutils, drop strtime()\n\nThis patch remove some code that tried to parse time in different way by\nleveraging timeutils instead. It also drops strtime() usage as it's\ngoing to be deprecated in oslo_utils (see\nI8b5119e64369ccac3423dccc04421f99912df733).\n\nChange-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26\n""}, {'number': 7, 'created': '2015-03-19 09:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a8edad5ac4710d1ee058b3c4c3c0d1eb26d2256', 'message': ""Leverage timeutils, drop strtime()\n\nThis patch remove some code that tried to parse time in different way by\nleveraging timeutils instead. It also drops strtime() usage as it's\ngoing to be deprecated in oslo_utils (see\nI8b5119e64369ccac3423dccc04421f99912df733).\n\nChange-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26\n""}, {'number': 8, 'created': '2015-03-20 07:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dceb2765e24bdfa6af296004cb225d9871a2e07c', 'message': ""Leverage timeutils, drop strtime()\n\nThis patch remove some code that tried to parse time in different way by\nleveraging timeutils instead. It also drops strtime() usage as it's\ngoing to be deprecated in oslo_utils (see\nI8b5119e64369ccac3423dccc04421f99912df733).\n\nChange-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26\n""}, {'number': 9, 'created': '2015-03-20 10:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6885bbec25e995f843b8d336e55209cf0ad2da13', 'message': ""Leverage timeutils, drop strtime()\n\nThis patch remove some code that tried to parse time in different way by\nleveraging timeutils instead. It also drops strtime() usage as it's\ngoing to be deprecated in oslo_utils (see\nI8b5119e64369ccac3423dccc04421f99912df733).\n\nChange-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26\n""}, {'number': 10, 'created': '2015-04-24 14:56:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d584e656827abcf39bb8f1f1701556966af51ff', 'message': ""Leverage timeutils, drop strtime()\n\nThis patch remove some code that tried to parse time in different way by\nleveraging timeutils instead. It also drops strtime() usage as it's\ngoing to be deprecated in oslo_utils (see\nI8b5119e64369ccac3423dccc04421f99912df733).\n\nChange-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26\n""}, {'number': 11, 'created': '2015-05-12 08:41:58.000000000', 'files': ['nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/tests/unit/virt/vmwareapi/test_imagecache.py', 'nova/tests/unit/api/openstack/compute/contrib/test_simple_tenant_usage.py', 'nova/tests/unit/api/ec2/test_ec2_validate.py', 'nova/tests/unit/compute/test_compute.py', 'nova/virt/vmwareapi/imagecache.py', 'nova/tests/unit/cells/test_cells_messaging.py', 'nova/db/sqlalchemy/api.py', 'nova/notifications.py', 'nova/api/openstack/compute/plugins/v3/simple_tenant_usage.py', 'nova/tests/unit/compute/test_shelve.py', 'nova/tests/unit/scheduler/filters/test_trusted_filters.py', 'nova/compute/manager.py', 'nova/tests/unit/db/test_db_api.py', 'nova/api/openstack/compute/contrib/simple_tenant_usage.py', 'nova/context.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/15349471fe9faf45d157a7cb03baf77b150b40b1', 'message': ""Leverage timeutils, drop strtime()\n\nThis patch remove some code that tried to parse time in different way by\nleveraging timeutils instead. It also drops strtime() usage as it's\ngoing to be deprecated in oslo_utils (see\nI8b5119e64369ccac3423dccc04421f99912df733).\n\nChange-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26\n""}]",10,164753,15349471fe9faf45d157a7cb03baf77b150b40b1,83,16,11,1669,,,0,"Leverage timeutils, drop strtime()

This patch remove some code that tried to parse time in different way by
leveraging timeutils instead. It also drops strtime() usage as it's
going to be deprecated in oslo_utils (see
I8b5119e64369ccac3423dccc04421f99912df733).

Change-Id: Ic0036b85768018214dc4fe672e9325b5d04d3c26
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/164753/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/contrib/test_simple_tenant_usage.py', 'nova/api/openstack/compute/contrib/simple_tenant_usage.py']",2,f4e658643dc27fdedbefc0837a5e5dbe4e286236,jd/remove-strtime,"class SimpleTenantUsageController(object): @staticmethod def _hours_for(instance, period_start, period_stop): @staticmethod def _get_flavor(context, instance, flavors_cache): @staticmethod def _parse_datetime(dtstr): try: value = timeutils.parse_isotime(dtstr) except ValueError: now = timeutils.utcnow().replace(tzinfo=iso8601.iso8601.Utc()) now = timeutils.utcnow().replace(tzinfo=iso8601.iso8601.Utc())","import sixdef parse_strtime(dstr, fmt): try: return timeutils.parse_strtime(dstr, fmt) except (TypeError, ValueError) as e: raise exception.InvalidStrTime(reason=six.text_type(e)) class SimpleTenantUsageController(object): def _hours_for(self, instance, period_start, period_stop): def _get_flavor(self, context, instance, flavors_cache): def _parse_datetime(self, dtstr): for fmt in [""%Y-%m-%dT%H:%M:%S"", ""%Y-%m-%dT%H:%M:%S.%f"", ""%Y-%m-%d %H:%M:%S.%f""]: try: value = parse_strtime(dtstr, fmt) break except exception.InvalidStrTime: pass else: now = timeutils.parse_isotime(timeutils.strtime()) now = timeutils.parse_isotime(timeutils.strtime())",11,43
openstack%2Fha-guide~master~I6fbafd4d4fcbd506cc4e41823fd00c94fdbac9ec,openstack/ha-guide,master,I6fbafd4d4fcbd506cc4e41823fd00c94fdbac9ec,Moved XML to RST in ha-guide.,MERGED,2015-05-21 23:03:29.000000000,2015-05-21 23:30:21.000000000,2015-05-21 23:30:21.000000000,"[{'_account_id': 3}, {'_account_id': 9123}, {'_account_id': 9382}, {'_account_id': 10068}]","[{'number': 1, 'created': '2015-05-21 23:03:29.000000000', 'files': ['doc/ha-guide/source/controller-ha.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/7879f6d7e10b8ee9ea050a5972494c361a3540b1', 'message': 'Moved XML to RST in ha-guide.\n\ncontroller.xml file was modified\n\nChange-Id: I6fbafd4d4fcbd506cc4e41823fd00c94fdbac9ec\n'}]",0,184898,7879f6d7e10b8ee9ea050a5972494c361a3540b1,8,4,1,16483,,,0,"Moved XML to RST in ha-guide.

controller.xml file was modified

Change-Id: I6fbafd4d4fcbd506cc4e41823fd00c94fdbac9ec
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/98/184898/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/controller-ha.rst'],1,7879f6d7e10b8ee9ea050a5972494c361a3540b1,,The cloud controller runs on the management network and must talk to all other services.,,1,0
openstack%2Fdiskimage-builder~master~I5bfa9a3e83d3259db2436404034ad58c780de1c9,openstack/diskimage-builder,master,I5bfa9a3e83d3259db2436404034ad58c780de1c9,Simple-init should disable cloud-init,MERGED,2015-05-11 16:51:32.000000000,2015-05-21 23:29:55.000000000,2015-05-21 23:29:54.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 10035}, {'_account_id': 12092}]","[{'number': 1, 'created': '2015-05-11 16:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/776ef363fc2124c0da4e938f8474b235b69bf906', 'message': 'Simple-init should disable cloud-init\n\nCloud-init and simple-init are not meant to play together. Lets disable\ncloud-init if simple-init is installed.\n\nAlso guarding cloud-init-datasources against running in an environment\nwhere cloud-init is not installed.\n\nChange-Id: I5bfa9a3e83d3259db2436404034ad58c780de1c9\n'}, {'number': 2, 'created': '2015-05-11 16:55:25.000000000', 'files': ['elements/cloud-init-datasources/install.d/05-set-cloud-init-sources', 'elements/simple-init/element-deps', 'elements/simple-init/environment.d/50-disable-cloud-init'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/dc33f6ddd090696810868750f8b9916a1dfb4fc0', 'message': 'Simple-init should disable cloud-init\n\nCloud-init and simple-init are not meant to play together. Lets disable\ncloud-init if simple-init is installed.\n\nAlso guarding cloud-init-datasources against running in an environment\nwhere cloud-init is not installed.\n\nChange-Id: I5bfa9a3e83d3259db2436404034ad58c780de1c9\n'}]",2,181977,dc33f6ddd090696810868750f8b9916a1dfb4fc0,15,6,2,10035,,,0,"Simple-init should disable cloud-init

Cloud-init and simple-init are not meant to play together. Lets disable
cloud-init if simple-init is installed.

Also guarding cloud-init-datasources against running in an environment
where cloud-init is not installed.

Change-Id: I5bfa9a3e83d3259db2436404034ad58c780de1c9
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/77/181977/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/cloud-init-datasources/install.d/05-set-cloud-init-sources', 'elements/simple-init/element-deps']",2,776ef363fc2124c0da4e938f8474b235b69bf906,simple-init-disable-cloud-init,cloud-init-datasources,,9,6
openstack%2Fdevstack~master~Ief7cb33d926a9538f4eb39c74d906ee0c879de35,openstack/devstack,master,Ief7cb33d926a9538f4eb39c74d906ee0c879de35,Disable firewalld always,MERGED,2015-05-15 03:22:45.000000000,2015-05-21 23:29:52.000000000,2015-05-21 23:29:50.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 4220}, {'_account_id': 6854}, {'_account_id': 6962}]","[{'number': 1, 'created': '2015-05-15 03:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/679f1ff1191c8cae162a69116da21ff4590cc8cd', 'message': ""Disable firewalld always\n\nWe've bike-sheded over this before\n(I5252a12223a35f7fb7a4ac3c58aa4a3cd1bc4799) but I have just traced\ndown further issues to firewalld with neutron+ipv6 (see the bug).\n\nIn fact, as mentioned in the comments, RDO disables firewalld and the\nneutron guide says to disable it [1].  The force flag is left if\nanyone really wants this; but nobody is testing (or, as far as I can\ntell, working on) this so bring devstack back into line and disable it\nalways.  Note we do not remove the package; as has been found in the\npuppet scripts this can lead to dependency issues.\n\n[1] http://docs.openstack.org/developer/devstack/guides/neutron.html\n\nChange-Id: Ief7cb33d926a9538f4eb39c74d906ee0c879de35\nPartial-Bug: 1455303\n""}, {'number': 2, 'created': '2015-05-15 09:14:32.000000000', 'files': ['lib/nova_plugins/functions-libvirt', 'tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3380a16974defc62db65fbc8e30e2510b57b84b6', 'message': ""Disable firewalld always\n\nWe've bike-sheded over this before\n(I5252a12223a35f7fb7a4ac3c58aa4a3cd1bc4799) but I have just traced\ndown further issues to firewalld with neutron+ipv6 (see the bug).\n\nIn fact, as mentioned in the comments, RDO disables firewalld and the\nneutron guide says to disable it [1].  The force flag is left if\nanyone really wants this; but nobody is testing (or, as far as I can\ntell, working on) this so bring devstack back into line and disable it\nalways.  Note we do not remove the package; as has been found in the\npuppet scripts this can lead to dependency issues.\n\n[1] http://docs.openstack.org/developer/devstack/guides/neutron.html\n\nChange-Id: Ief7cb33d926a9538f4eb39c74d906ee0c879de35\nPartial-Bug: 1455303\n""}]",0,183384,3380a16974defc62db65fbc8e30e2510b57b84b6,13,6,2,7118,,,0,"Disable firewalld always

We've bike-sheded over this before
(I5252a12223a35f7fb7a4ac3c58aa4a3cd1bc4799) but I have just traced
down further issues to firewalld with neutron+ipv6 (see the bug).

In fact, as mentioned in the comments, RDO disables firewalld and the
neutron guide says to disable it [1].  The force flag is left if
anyone really wants this; but nobody is testing (or, as far as I can
tell, working on) this so bring devstack back into line and disable it
always.  Note we do not remove the package; as has been found in the
puppet scripts this can lead to dependency issues.

[1] http://docs.openstack.org/developer/devstack/guides/neutron.html

Change-Id: Ief7cb33d926a9538f4eb39c74d906ee0c879de35
Partial-Bug: 1455303
",git fetch https://review.opendev.org/openstack/devstack refs/changes/84/183384/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,679f1ff1191c8cae162a69116da21ff4590cc8cd,bug/1455303," if [[ $FORCE_FIREWALLD == ""False"" ]]; then # slows things down significantly (this issue was fixed in # later fedoras). There was also an additional issue with # firewalld hanging after install of libvirt with polkit [1]. # firewalld also causes problems with neturon+ipv6 [2] # # Note we do the same as the RDO packages and stop & disable, # rather than remove. This is because other packages might # have the dependency [3][4]. # # [1] https://bugzilla.redhat.com/show_bug.cgi?id=1099031 # [2] https://bugs.launchpad.net/neutron/+bug/1455303 # [3] https://github.com/redhat-openstack/openstack-puppet-modules/blob/master/firewall/manifests/linux/redhat.pp # [4] http://docs.openstack.org/developer/devstack/guides/neutron.html sudo systemctl disable firewalld sudo systemctl enable iptables sudo systemctl stop firewalld sudo systemctl start iptables"," if [[ ${DISTRO} =~ (f20) && $FORCE_FIREWALLD == ""False"" ]]; then # slows things down significantly. However, for those cases # where that combination is desired, allow this fix to be skipped. # There was also an additional issue with firewalld hanging # after install of libvirt with polkit. See # https://bugzilla.redhat.com/show_bug.cgi?id=1099031 uninstall_package firewalld",18,9
openstack%2Fdevstack~master~Ia5d06afa74bc645c2f19711cfa37e57a377c329b,openstack/devstack,master,Ia5d06afa74bc645c2f19711cfa37e57a377c329b,Do not set OS_CACERT if there is no CA cert,MERGED,2015-05-05 22:01:55.000000000,2015-05-21 23:28:30.000000000,2015-05-21 23:28:28.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 6488}, {'_account_id': 7118}, {'_account_id': 8119}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-05-05 22:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ffb3b85921a13340056e2e65e6f08d7a0049bb08', 'message': 'Do not set OS_CACERT if there is no CA cert\n\nIn openrc, if we set OS_CACERT, some things will expect it to be there\nin pre-flight checks. But it may very well be missing. This ""fails\nclosed"" because if we find the file, we try to use it, but if we don\'t\nfind the file, and the user thought we should be using it, we\'ll just\nnot be able to verify the server\'s name, and the libs will fail on that.\n\nChange-Id: Ia5d06afa74bc645c2f19711cfa37e57a377c329b\nCloses-Bug: #1452036\n'}, {'number': 2, 'created': '2015-05-06 20:55:22.000000000', 'files': ['openrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/52a3bebcfcb09ec2b78d0357f1a074458ab04053', 'message': 'Do not set OS_CACERT if there is no CA cert\n\nIn openrc, if we set OS_CACERT, some things will expect it to be there\nin pre-flight checks. But it may very well be missing. This ""fails\nclosed"" because if we find the file, we try to use it, but if we don\'t\nfind the file, and the user thought we should be using it, we\'ll just\nnot be able to verify the server\'s name, and the libs will fail on that.\n\nChange-Id: Ia5d06afa74bc645c2f19711cfa37e57a377c329b\nCloses-Bug: #1452036\n'}]",5,180340,52a3bebcfcb09ec2b78d0357f1a074458ab04053,17,7,2,6488,,,0,"Do not set OS_CACERT if there is no CA cert

In openrc, if we set OS_CACERT, some things will expect it to be there
in pre-flight checks. But it may very well be missing. This ""fails
closed"" because if we find the file, we try to use it, but if we don't
find the file, and the user thought we should be using it, we'll just
not be able to verify the server's name, and the libs will fail on that.

Change-Id: Ia5d06afa74bc645c2f19711cfa37e57a377c329b
Closes-Bug: #1452036
",git fetch https://review.opendev.org/openstack/devstack refs/changes/40/180340/2 && git format-patch -1 --stdout FETCH_HEAD,['openrc'],1,ffb3b85921a13340056e2e65e6f08d7a0049bb08,bug/1452036,"# If the file does not exist, we should not try to use it. [[ -e $OS_CACERT ]] || unset OS_CACERT",,2,0
openstack%2Fpython-novaclient~master~If278565ef07de1a8fef3ff96fc3608e41f3ceea3,openstack/python-novaclient,master,If278565ef07de1a8fef3ff96fc3608e41f3ceea3,Use clouds.yaml for functional test credentials,MERGED,2015-05-14 16:40:09.000000000,2015-05-21 23:09:37.000000000,2015-05-21 23:09:36.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 4690}]","[{'number': 1, 'created': '2015-05-14 16:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/4eb8659ca2e5819b47390a61a09def3d9aaea7a1', 'message': 'Use clouds.yaml for functional test credentials\n\ndevstack emits a clouds.yaml file now, so it can be used for finding the\ncredentials needed to connect to the cloud for functional testing.\n\nDepends-On: I1150b943f52f10d19f8434b27e8dde73a14d7843\nChange-Id: If278565ef07de1a8fef3ff96fc3608e41f3ceea3\n'}, {'number': 2, 'created': '2015-05-14 17:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/3f8a696150611324d73407cdc73a9612267d7d90', 'message': 'Use clouds.yaml for functional test credentials\n\ndevstack emits a clouds.yaml file now, so it can be used for finding the\ncredentials needed to connect to the cloud for functional testing.\n\nDepends-On: I1150b943f52f10d19f8434b27e8dde73a14d7843\nChange-Id: If278565ef07de1a8fef3ff96fc3608e41f3ceea3\n'}, {'number': 3, 'created': '2015-05-15 02:55:19.000000000', 'files': ['novaclient/tests/functional/hooks/post_test_hook.sh', 'functional_creds.conf.sample', 'test-requirements.txt', 'novaclient/tests/functional/base.py', 'README.rst'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/22569f218e4ca461da4e50dfc686adae6a44d2ba', 'message': 'Use clouds.yaml for functional test credentials\n\ndevstack emits a clouds.yaml file now, so it can be used for finding the\ncredentials needed to connect to the cloud for functional testing.\n\nDepends-On: I1150b943f52f10d19f8434b27e8dde73a14d7843\nChange-Id: If278565ef07de1a8fef3ff96fc3608e41f3ceea3\n'}]",0,183106,22569f218e4ca461da4e50dfc686adae6a44d2ba,16,5,3,2,,,0,"Use clouds.yaml for functional test credentials

devstack emits a clouds.yaml file now, so it can be used for finding the
credentials needed to connect to the cloud for functional testing.

Depends-On: I1150b943f52f10d19f8434b27e8dde73a14d7843
Change-Id: If278565ef07de1a8fef3ff96fc3608e41f3ceea3
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/06/183106/2 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/functional/hooks/post_test_hook.sh', 'functional_creds.conf.sample', 'novaclient/tests/functional/base.py', 'test-requirements.txt', 'README.rst']",5,4eb8659ca2e5819b47390a61a09def3d9aaea7a1,passcreds,Functional testing assumes the existance of a `clouds.yaml` file as supported by `os-client-config` (http://docs.openstack.org/developer/os-client-config) It assumes the existence of a cloud named `devstack` that behaves like a normal devstack installation with a demo and an admin user/tenant - or clouds named `functional_admin` and `functional_nonadmin`.,Functional testing assumes the existance of a functional_creds.conf in the root directory. See the .sample for example format.,51,45
openstack%2Fopenstack-ansible~master~I7cbcc6ed351a85c198386af866a8693f618bdbbd,openstack/openstack-ansible,master,I7cbcc6ed351a85c198386af866a8693f618bdbbd,Update all services in master to current head,MERGED,2015-05-12 22:16:23.000000000,2015-05-21 23:07:40.000000000,2015-05-21 23:07:39.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7414}, {'_account_id': 9884}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-05-12 22:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4fd3bbedba1fc3f617bf7465dd652b03fa767aa7', 'message': ""Update all services in master to current head\n\nThis change updates all of the sha's throughout the stack to the\nlatest sha within the master branch.\n\nChange-Id: I7cbcc6ed351a85c198386af866a8693f618bdbbd\n""}, {'number': 2, 'created': '2015-05-17 04:22:11.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/openstack_clients.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6fc1d2608d1298cd74e6595f4a7b1f5537ef9ce8', 'message': ""Update all services in master to current head\n\nThis change updates all of the sha's throughout the stack to the\nlatest sha within the master branch.\n\nChange-Id: I7cbcc6ed351a85c198386af866a8693f618bdbbd\n""}]",0,182476,6fc1d2608d1298cd74e6595f4a7b1f5537ef9ce8,14,5,2,7353,,,0,"Update all services in master to current head

This change updates all of the sha's throughout the stack to the
latest sha within the master branch.

Change-Id: I7cbcc6ed351a85c198386af866a8693f618bdbbd
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/76/182476/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/vars/repo_packages/openstack_clients.yml', 'playbooks/vars/repo_packages/openstack_services.yml']",2,4fd3bbedba1fc3f617bf7465dd652b03fa767aa7,master-update,"cinder_git_install_branch: e8d2a6e74bc26040329113daa3798e3dee81a972 # HEAD of ""master"" as of 12.05.2015glance_git_install_branch: 4efb56aae9288952bdb0d368a7c307e8524b80d8 # HEAD of ""master"" as of 12.05.2015heat_git_install_branch: 4032e40cce01cf2f31a359d9bbbcb34c3f0d2cae # HEAD of ""master"" as of 12.05.2015horizon_git_install_branch: 6f3d61241ac32f61e77562a7813e6fd9813a478c # HEAD of ""master"" as of 12.05.2015keystone_git_install_branch: 344b4fea7ec3dd703cbcbd080c983759206d13f9 # HEAD of ""master"" as of 12.05.2015neutron_git_install_branch: 2aa336aeb86b5ba4c2569f43242506813bf60e2d # HEAD of ""master"" as of 12.05.2015neutron_lbaas_git_install_branch: 74825a4b94d968e7ed768e5febe1dc12d5b57586 # HEAD of ""master"" as of 12.05.2015neutron_vpnaas_git_install_branch: 5400931e658602fdde3dc2ce2e3a8512d22829ae # HEAD of ""master"" as of 12.05.2015neutron_fwaas_git_install_branch: b3dcd49842d081a61118a7273d0b5dbc92797ff0 # HEAD of ""master"" as of 12.05.2015nova_git_install_branch: d56dd7d233dfafc9245bc0ad972fbfea9ece916f # HEAD of ""master"" as of 12.05.2015swift_git_install_branch: 19fd9d6404f5fbb62abf1e36c559cf02895f90f1 # HEAD of ""master"" as of 12.05.2015tempest_git_install_branch: 8fba8d3f4647bd97ef9949454a58f0c6f1a3cfb1 # HEAD of ""master"" as of 12.05.2015","cinder_git_install_branch: 9690c2dcd02442e47bf215ede1d52333999a55a3 # HEAD of ""master"" as of 20.04.2015glance_git_install_branch: 20ec82f18c368bbc8a89e79d2d6eee2de2c2a9ea # HEAD of ""master"" as of 20.04.2015heat_git_install_branch: 5854f1d121d11faebd6e962e251d2e84bda801de # HEAD of ""master"" as of 20.04.2015horizon_git_install_branch: 9f8c35c9e479ebd480a111167cafed4371df665a # HEAD of ""master"" as of 22.04.2015keystone_git_install_branch: fbf8985903fcf528e4636cb39880e3ab94c079c0 # HEAD of ""master"" as of 20.04.2015neutron_git_install_branch: cc020dc930d88ae0419a650ad0c268b23f9e9ebe # HEAD of ""master"" as of 20.04.2015neutron_lbaas_git_install_branch: 700da77315d609ee02ba1a031df681d51abf2eab # HEAD of ""master"" as of 20.04.2015neutron_vpnaas_git_install_branch: 0782a2ba25cd8fce8c735c84fadd2fa9b670f418 # HEAD of ""master"" as of 20.04.2015neutron_fwaas_git_install_branch: ba861cf9b9fd345626e2c4e9d3307b74825d5eea # HEAD of ""master"" as of 20.04.2015nova_git_install_branch: e77edeee0e7bf4c710b42023da6d9ae2e31cd8b1 # HEAD of ""master"" as of 20.04.2015swift_git_install_branch: 843236a635049d0a05d69f47aa675f90641c025d # HEAD of ""master"" as of 20.04.2015tempest_git_install_branch: d1a391a55482d64b9014e7b41219af195722d990 # HEAD of ""master"" as of 20.3.2015",15,15
openstack%2Fmonasca-agent~master~Icf930ee00c32814494911c14851c44b47648c6c0,openstack/monasca-agent,master,Icf930ee00c32814494911c14851c44b47648c6c0,Add dimensions support to the argument based detection plugins,MERGED,2015-05-20 22:09:46.000000000,2015-05-21 23:06:37.000000000,2015-05-21 23:06:37.000000000,"[{'_account_id': 3}, {'_account_id': 12133}, {'_account_id': 12443}, {'_account_id': 14517}, {'_account_id': 15027}]","[{'number': 1, 'created': '2015-05-20 22:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/197ab70355b891a8a9eddccbab0f21632583237e', 'message': 'Add dimensions support to the argument based detection plugins\n\nChange-Id: Icf930ee00c32814494911c14851c44b47648c6c0\n'}, {'number': 2, 'created': '2015-05-21 22:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/a9433030b4a7d3a48cbf90fad29cb0f439f93f4d', 'message': 'Add dimensions support to the argument based detection plugins\n\nChange-Id: Icf930ee00c32814494911c14851c44b47648c6c0\n'}, {'number': 3, 'created': '2015-05-21 22:40:42.000000000', 'files': ['monasca_setup/detection/args_plugin.py', 'conf.d/host_alive.yaml.example', 'monasca_setup/detection/__init__.py', 'monasca_setup/detection/plugins/http_check.py', 'docs/Customizations.md', 'monasca_setup/detection/plugin.py', 'monasca_setup/detection/plugins/host_alive.py', 'monasca_setup/main.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/7cb4c717d401733a5f068810bfe4305e1451a562', 'message': 'Add dimensions support to the argument based detection plugins\n\nChange-Id: Icf930ee00c32814494911c14851c44b47648c6c0\n'}]",0,184636,7cb4c717d401733a5f068810bfe4305e1451a562,13,5,3,11094,,,0,"Add dimensions support to the argument based detection plugins

Change-Id: Icf930ee00c32814494911c14851c44b47648c6c0
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/36/184636/2 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_setup/detection/args_plugin.py', 'conf.d/host_alive.yaml.example', 'monasca_setup/detection/plugins/http_check.py', 'monasca_setup/detection/plugin.py', 'monasca_setup/detection/plugins/host_alive.py', 'monasca_setup/main.py']",6,197ab70355b891a8a9eddccbab0f21632583237e,feature/dimensions, # todo add option to install dependencies, # todo add option to install dependencies,58,29
openstack%2Fneutron~master~Ifac59476e4785b86bca6e2a54759f4271629a193,openstack/neutron,master,Ifac59476e4785b86bca6e2a54759f4271629a193,Non-json body on POST 500's,MERGED,2015-04-08 22:12:49.000000000,2015-05-21 23:03:22.000000000,2015-05-21 23:03:19.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 6951}, {'_account_id': 7037}, {'_account_id': 7924}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15752}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-04-08 22:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9e2f61aa7a21e2f9e84c47d347253f5902ae8832', 'message': ""Non-json body on POST 500's\n\nIf the body of a POST request is not json, we get crashes.\nThis can happen when middleware sends along unexpected data.\n\nRM#12092\n\nChange-Id: Ifac59476e4785b86bca6e2a54759f4271629a193\n""}, {'number': 2, 'created': '2015-04-08 22:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/febe17221fae7dd6d0e235c52343cafd5da3ac6f', 'message': ""Non-json body on POST 500's\n\nIf the body of a POST request is not json, we get crashes.\nThis can happen when middleware sends along unexpected data.\n\nChange-Id: Ifac59476e4785b86bca6e2a54759f4271629a193\n""}, {'number': 3, 'created': '2015-04-09 16:42:59.000000000', 'files': ['neutron/tests/unit/api/v2/test_base.py', 'neutron/api/v2/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff9c92c712be07f9fa39832debc2af7ee239515b', 'message': ""Non-json body on POST 500's\n\nIf the body of a POST request is not json, we get crashes.\nThis can happen when middleware sends along unexpected data.\n\nCloses-bug #1441879\n\nChange-Id: Ifac59476e4785b86bca6e2a54759f4271629a193\n""}]",6,171836,ff9c92c712be07f9fa39832debc2af7ee239515b,95,37,3,7037,,,0,"Non-json body on POST 500's

If the body of a POST request is not json, we get crashes.
This can happen when middleware sends along unexpected data.

Closes-bug #1441879

Change-Id: Ifac59476e4785b86bca6e2a54759f4271629a193
",git fetch https://review.opendev.org/openstack/neutron refs/changes/36/171836/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/api/v2/base.py', 'neutron/tests/unit/test_api_v2.py']",2,9e2f61aa7a21e2f9e84c47d347253f5902ae8832,bug/1441879," def test_create_body_string_not_json(self): data = 'a string' self._test_create_failure_bad_request('networks', data) def test_create_body_boolean_not_json(self): data = True self._test_create_failure_bad_request('networks', data) ",,26,15
openstack%2Fnova~master~I60a89bf7884dbcb066c63101168b359013fe832b,openstack/nova,master,I60a89bf7884dbcb066c63101168b359013fe832b,Drop compute RPC 3.x support,MERGED,2015-05-04 21:38:04.000000000,2015-05-21 22:59:08.000000000,2015-05-12 19:10:39.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 6450}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14027}, {'_account_id': 14250}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-04 21:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3cb14162f280da29d0f69180038108968845b131', 'message': 'Drop compute RPC 3.x support\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}, {'number': 2, 'created': '2015-05-05 15:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9fa099f083d285c1dffdeb11a25c06882a00c48e', 'message': 'Drop compute RPC 3.x support\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}, {'number': 3, 'created': '2015-05-05 22:23:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0d3ae7e9a06a2b6cdb0610eaf84436e95233f10', 'message': 'Drop compute RPC 3.x support\n\nThis drops all the things we no longer need when not supporting the\ncompute RPC 3.x interface. The major changes are removing of the\nrun_instance() path and the mass of tests that hit that route. There\nare also quite a few tests that still depend on object_compat\ndecorations on compute manager methods, which require some\nchanges here.\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}, {'number': 4, 'created': '2015-05-05 23:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4903105d6aa46926434a3545e76e2c63e8af7f2', 'message': 'Drop compute RPC 3.x support\n\nThis drops all the things we no longer need when not supporting the\ncompute RPC 3.x interface. The major changes are removing of the\nrun_instance() path and the mass of tests that hit that route. There\nare also quite a few tests that still depend on object_compat\ndecorations on compute manager methods, which require some\nchanges here.\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}, {'number': 5, 'created': '2015-05-06 15:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/930e9e8c9f45b683b9bab10173c518d3c126b9ba', 'message': 'Drop compute RPC 3.x support\n\nThis drops all the things we no longer need when not supporting the\ncompute RPC 3.x interface. The major changes are removing of the\nrun_instance() path and the mass of tests that hit that route. There\nare also quite a few tests that still depend on object_compat\ndecorations on compute manager methods, which require some\nchanges here.\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}, {'number': 6, 'created': '2015-05-06 19:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d09016158d983fcbb13820e70dab61d0064a9365', 'message': 'Drop compute RPC 3.x support\n\nThis drops all the things we no longer need when not supporting the\ncompute RPC 3.x interface. The major changes are removing of the\nrun_instance() path and the mass of tests that hit that route. There\nare also quite a few tests that still depend on object_compat\ndecorations on compute manager methods, which require some\nchanges here.\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}, {'number': 7, 'created': '2015-05-07 19:32:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/483015e38cc978171e68eddf2e70abf4dbc1a540', 'message': 'Drop compute RPC 3.x support\n\nThis drops all the things we no longer need when not supporting the\ncompute RPC 3.x interface. The major changes are removing of the\nrun_instance() path and the mass of tests that hit that route. There\nare also quite a few tests that still depend on object_compat\ndecorations on compute manager methods, which require some\nchanges here.\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}, {'number': 8, 'created': '2015-05-07 20:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad8b77723d3e64008ce0a82a82721d53511f9931', 'message': 'Drop compute RPC 3.x support\n\nThis drops all the things we no longer need when not supporting the\ncompute RPC 3.x interface. The major changes are removing of the\nrun_instance() path and the mass of tests that hit that route. There\nare also quite a few tests that still depend on object_compat\ndecorations on compute manager methods, which require some\nchanges here.\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}, {'number': 9, 'created': '2015-05-07 21:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37ede2c94fbf4369fdcd8e4008718bb0cab55d93', 'message': 'Drop compute RPC 3.x support\n\nThis drops all the things we no longer need when not supporting the\ncompute RPC 3.x interface. The major changes are removing of the\nrun_instance() path and the mass of tests that hit that route. There\nare also quite a few tests that still depend on object_compat\ndecorations on compute manager methods, which require some\nchanges here.\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}, {'number': 10, 'created': '2015-05-08 14:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/41edd5938bc4d610744f123e10194a072f2dcb51', 'message': 'Drop compute RPC 3.x support\n\nThis drops all the things we no longer need when not supporting the\ncompute RPC 3.x interface. The major changes are removing of the\nrun_instance() path and the mass of tests that hit that route. There\nare also quite a few tests that still depend on object_compat\ndecorations on compute manager methods, which require some\nchanges here.\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}, {'number': 11, 'created': '2015-05-11 14:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5446208117206ae58d700742e39cc0d19d39be25', 'message': 'Drop compute RPC 3.x support\n\nThis drops all the things we no longer need when not supporting the\ncompute RPC 3.x interface. The major changes are removing of the\nrun_instance() path and the mass of tests that hit that route. There\nare also quite a few tests that still depend on object_compat\ndecorations on compute manager methods, which require some\nchanges here.\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}, {'number': 12, 'created': '2015-05-12 14:45:15.000000000', 'files': ['nova/tests/unit/compute/test_rpcapi.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/virt/xenapi/test_xenapi.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/91b35b22e753a4eb0c22c004bb12586970a95e11', 'message': 'Drop compute RPC 3.x support\n\nThis drops all the things we no longer need when not supporting the\ncompute RPC 3.x interface. The major changes are removing of the\nrun_instance() path and the mass of tests that hit that route. There\nare also quite a few tests that still depend on object_compat\ndecorations on compute manager methods, which require some\nchanges here.\n\nChange-Id: I60a89bf7884dbcb066c63101168b359013fe832b\n'}]",10,179951,91b35b22e753a4eb0c22c004bb12586970a95e11,102,17,12,4393,,,0,"Drop compute RPC 3.x support

This drops all the things we no longer need when not supporting the
compute RPC 3.x interface. The major changes are removing of the
run_instance() path and the mass of tests that hit that route. There
are also quite a few tests that still depend on object_compat
decorations on compute manager methods, which require some
changes here.

Change-Id: I60a89bf7884dbcb066c63101168b359013fe832b
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/179951/12 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py']",3,3cb14162f280da29d0f69180038108968845b131,drop-compute-v3," version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' # TODO(danms): This needs to be fixed for objects version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' # TODO(danms): This needs to be fixed for objects! version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' msg_args = {'rescue_password': rescue_password, 'clean_shutdown': clean_shutdown, 'rescue_image_ref': rescue_image_ref, 'instance': instance, } version = '4.0' # TODO(danms): This needs to be fixed for objects! 'instance_type': instance_type_p, 'clean_shutdown': clean_shutdown, } version = '4.0' version = '4.0' version = '4.0' version = '4.0' extra = {'destroy_disks': destroy_disks, 'migrate_data': migrate_data, } version = '4.0' version = '4.0' version = '4.0' version = '4.0' 'device_type': device_type} version = '4.0' version = '4.0' version = '4.0' version = '4.0' msg_args = {'instance': instance, 'clean_shutdown': clean_shutdown} version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' msg_args = {'instance': instance, 'image_id': image_id, 'clean_shutdown': clean_shutdown} version = '4.0' msg_args = {'instance': instance, 'clean_shutdown': clean_shutdown} version = '4.0' version = '4.0' version = '4.0' version = '4.0' version='4.0') version = '4.0' version = '4.0' version = '4.0' version = '4.0' version = '4.0' # TODO(danms): This needs to be fixed for objects!"," version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.12') version = self._compat_ver('4.0', '3.17') if self.client.can_send_version('4.0'): version = '4.0' else: version = '3.16' kw['mountpoint'] = mountpoint kw['volume_id'] = volume_id version = self._compat_ver('4.0', '3.7') def _warn_buggy_live_migrations(self, data=None): # NOTE(danms): We know that libvirt live migration with shared block # storage was buggy (potential loss of data) before version 3.32. # Since we need to support live migration with older clients, we need # to warn the operator of this possibility. The logic below tries to # decide if a warning should be emitted, assuming the positive if # not sure. This can be removed when we bump to RPC API version 4.0. if data: if data.get('is_shared_block_storage') is not False: # Shared block storage, or unknown should_warn = True else: # Specifically not shared block storage should_warn = False else: # Unknown, so warn to be safe should_warn = True if should_warn: LOG.warning(_LW('Live migration with clients before RPC version ' '3.32 is known to be buggy with shared block ' 'storage. See ' 'https://bugs.launchpad.net/nova/+bug/1250751 for ' 'more information!')) if self.client.can_send_version('4.0'): version = '4.0' elif self.client.can_send_version('3.32'): version = '3.32' else: version = '3.0' self._warn_buggy_live_migrations() if self.client.can_send_version('4.0'): version = '4.0' elif self.client.can_send_version('3.32'): version = '3.32' else: version = '3.0' self._warn_buggy_live_migrations() if self.client.can_send_version('4.0'): version = '4.0' elif self.client.can_send_version('3.29'): version = '3.29' else: version = '3.0' instance = jsonutils.to_primitive(instance) version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.17') if self.client.can_send_version('4.0'): version = '4.0' elif self.client.can_send_version('3.25'): version = '3.25' else: version = '3.0' instance = jsonutils.to_primitive(instance) version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0') if self.client.can_send_version('4.0'): version = '4.0' elif self.client.can_send_version('3.28'): version = '3.28' else: version = '3.0' instance = jsonutils.to_primitive(instance) version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.18') version = self._compat_ver('4.0', '3.31') version = self._compat_ver('4.0', '3.2') version = self._compat_ver('4.0', '3.1') version = self._compat_ver('4.0', '3.10') version = self._compat_ver('4.0', '3.34') version = self._compat_ver('4.0', '3.3') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0') if self.client.can_send_version('4.0'): version = '4.0' elif self.client.can_send_version('3.26'): version = '3.26' else: version = '3.0' instance = jsonutils.to_primitive(instance) version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.14') version = self._compat_ver('4.0', '3.19') if self.client.can_send_version('4.0'): version = '4.0' elif self.client.can_send_version('3.38'): version = '3.38' else: del msg_args['clean_shutdown'] version = '3.0' version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.21') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.13') if self.client.can_send_version('4.0'): version = '4.0' elif self.client.can_send_version('3.30'): version = '3.30' else: version = '3.0' instance = jsonutils.to_primitive(instance) msg_args = {'rescue_password': rescue_password} if self.client.can_send_version('4.0'): version = '4.0' msg_args['clean_shutdown'] = clean_shutdown msg_args['rescue_image_ref'] = rescue_image_ref elif self.client.can_send_version('3.37'): version = '3.37' msg_args['clean_shutdown'] = clean_shutdown msg_args['rescue_image_ref'] = rescue_image_ref elif self.client.can_send_version('3.24'): version = '3.24' msg_args['rescue_image_ref'] = rescue_image_ref else: version = '3.9' msg_args['instance'] = instance version = self._compat_ver('4.0', '3.0') 'instance_type': instance_type_p} if self.client.can_send_version('4.0'): version = '4.0' msg_args['clean_shutdown'] = clean_shutdown elif self.client.can_send_version('3.37'): version = '3.37' msg_args['clean_shutdown'] = clean_shutdown else: version = '3.0' version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0') if self.client.can_send_version('4.0'): version = '4.0' extra = {'destroy_disks': destroy_disks, 'migrate_data': migrate_data, } elif self.client.can_send_version('3.32'): version = '3.32' extra = {'destroy_disks': destroy_disks, 'migrate_data': migrate_data, } else: version = '3.0' extra = {} self._warn_buggy_live_migrations(migrate_data) version = self._compat_ver('4.0', '3.8') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0') 'device_type': device_type, 'return_bdm_object': True} if self.client.can_send_version('4.0'): version = '4.0' del kw['return_bdm_object'] elif self.client.can_send_version('3.35'): version = '3.35' else: del kw['return_bdm_object'] version = '3.16' version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0') msg_args = {'instance': instance} if self.client.can_send_version('4.0'): version = '4.0' msg_args['clean_shutdown'] = clean_shutdown elif self.client.can_send_version('3.37'): version = '3.37' msg_args['clean_shutdown'] = clean_shutdown else: version = '3.0' version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.22') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.11') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.20') msg_args = {'instance': instance, 'image_id': image_id} if self.client.can_send_version('4.0'): version = '4.0' msg_args['clean_shutdown'] = clean_shutdown elif self.client.can_send_version('3.37'): version = '3.37' msg_args['clean_shutdown'] = clean_shutdown else: version = '3.0' msg_args = {'instance': instance} if self.client.can_send_version('4.0'): version = '4.0' msg_args['clean_shutdown'] = clean_shutdown elif self.client.can_send_version('3.37'): version = '3.37' msg_args['clean_shutdown'] = clean_shutdown else: version = '3.0' version = self._compat_ver('4.0', '3.15') version = self._compat_ver('4.0', '3.6') version = self._compat_ver('4.0', '3.6') version=self._compat_ver('4.0', '3.23')) if not self.client.can_send_version(version): version = '3.40' if not self.client.can_send_version(version): version = '3.36' if 'numa_topology' in limits and limits['numa_topology']: topology_limits = limits['numa_topology'] if node is not None: cnode = objects.ComputeNode.get_by_host_and_nodename( ctxt, host, node) else: cnode = ( objects.ComputeNode. get_first_node_by_host_for_old_compat( ctxt, host)) host_topology = objects.NUMATopology.obj_from_db_obj( cnode.numa_topology) limits['numa_topology'] = jsonutils.dumps( topology_limits.to_dict_legacy(host_topology)) if not self.client.can_send_version(version): version = '3.33' if 'instance_type' in filter_properties: flavor = filter_properties['instance_type'] flavor_p = objects_base.obj_to_primitive(flavor) filter_properties = dict(filter_properties, instance_type=flavor_p) if not self.client.can_send_version(version): version = '3.23' if requested_networks is not None: if utils.is_neutron(): requested_networks = [(network_id, address, port_id) for (network_id, address, port_id, _) in requested_networks.as_tuples()] else: requested_networks = [(network_id, address) for (network_id, address) in requested_networks.as_tuples()] version = self._compat_ver('4.0', '3.39') version = self._compat_ver('4.0', '3.39') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0') version = self._compat_ver('4.0', '3.0')",103,1465
openstack%2Fnova~master~I38cd7b53cdfd694c0eba1b6054d8e4c33759b0b8,openstack/nova,master,I38cd7b53cdfd694c0eba1b6054d8e4c33759b0b8,Handle return code 2 from blkid calls,MERGED,2015-02-27 11:31:13.000000000,2015-05-21 22:58:36.000000000,2015-05-11 16:48:32.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 935}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 12898}, {'_account_id': 15286}]","[{'number': 1, 'created': '2015-02-27 11:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10f914b5bb7e87aa20340172e58f3c8a187e55f6', 'message': 'Handle return code 2 from blkid calls\n\nblkid returns code 2 if the requested TYPE key is not found\nfor the specified device.\n\nEnsure that this situation is handled correctly; blkid will\nnot return any data, so the return value will be empty.\n\nChange-Id: I38cd7b53cdfd694c0eba1b6054d8e4c33759b0b8\nCloses-Bug: #1426324\n'}, {'number': 2, 'created': '2015-02-27 14:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27bbef87c4f0830c04844b1e4b0b2619a9e37530', 'message': 'Handle return code 2 from blkid calls\n\nblkid returns code 2 if the requested TYPE key is not found\nfor the specified device.\n\nEnsure that this situation is handled correctly; blkid will\nnot return any data, so the return value will be empty.\n\nChange-Id: I38cd7b53cdfd694c0eba1b6054d8e4c33759b0b8\nCloses-Bug: #1426324\n'}, {'number': 3, 'created': '2015-05-11 13:39:19.000000000', 'files': ['nova/virt/disk/vfs/localfs.py', 'nova/tests/unit/virt/disk/vfs/test_localfs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/051fced477cdead4e307c23fc343da427beb6c81', 'message': 'Handle return code 2 from blkid calls\n\nblkid returns code 2 if the requested TYPE key is not found\nfor the specified device.\n\nEnsure that this situation is handled correctly; blkid will\nnot return any data, so the return value will be empty.\n\nChange-Id: I38cd7b53cdfd694c0eba1b6054d8e4c33759b0b8\nCloses-Bug: #1426324\n'}]",4,159797,051fced477cdead4e307c23fc343da427beb6c81,39,14,3,935,,,0,"Handle return code 2 from blkid calls

blkid returns code 2 if the requested TYPE key is not found
for the specified device.

Ensure that this situation is handled correctly; blkid will
not return any data, so the return value will be empty.

Change-Id: I38cd7b53cdfd694c0eba1b6054d8e4c33759b0b8
Closes-Bug: #1426324
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/159797/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/disk/vfs/localfs.py'],1,10f914b5bb7e87aa20340172e58f3c8a187e55f6,bug/1426324," run_as_root=True, check_exit_code=[0, 2])", run_as_root=True),2,1
openstack%2Fgnocchi~master~I7310dfa5038ef8851a5b2730b2940915c8cfaaa2,openstack/gnocchi,master,I7310dfa5038ef8851a5b2730b2940915c8cfaaa2,tests: start/stop coord before using it,MERGED,2015-05-06 15:25:54.000000000,2015-05-21 22:58:14.000000000,2015-05-21 22:58:12.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6924}, {'_account_id': 8358}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-05-06 15:25:54.000000000', 'files': ['gnocchi/tests/base.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/caa77782a25f336ccaf2c878cf3a486880a6dd64', 'message': 'tests: start/stop coord before using it\n\nLuckily the driver we use never needed that, but it may not work for all\ntooz drivers.\n\nChange-Id: I7310dfa5038ef8851a5b2730b2940915c8cfaaa2\n'}]",0,180581,caa77782a25f336ccaf2c878cf3a486880a6dd64,13,6,1,1669,,,0,"tests: start/stop coord before using it

Luckily the driver we use never needed that, but it may not work for all
tooz drivers.

Change-Id: I7310dfa5038ef8851a5b2730b2940915c8cfaaa2
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/81/180581/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/tests/base.py'],1,caa77782a25f336ccaf2c878cf3a486880a6dd64,jd/remove-coord-in-base, self.coord.start() self.coord.stop() ,,4,0
openstack%2Ftripleo-heat-templates~master~I6985683851187a2512c37f59eaee5905bbc2dae2,openstack/tripleo-heat-templates,master,I6985683851187a2512c37f59eaee5905bbc2dae2,Adapt Galera ocf resource to puppet-pacemaker last update,ABANDONED,2015-05-14 06:43:47.000000000,2015-05-21 22:42:48.000000000,,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 7984}, {'_account_id': 8042}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-05-14 06:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1d12693a5558247798f0e4cabcdea30e54e64184', 'message': 'Adapt Galera ocf resource to puppet-pacemaker last update\n\nUpdate the definition of the pacemaker::resource::ocf for Galera to\nreflect the changes that happened in master.\n\nChange-Id: I6985683851187a2512c37f59eaee5905bbc2dae2\n'}, {'number': 2, 'created': '2015-05-14 07:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/380a0997454bf9f6797a43768a07a832fcacefee', 'message': 'Adapt Galera ocf resource to puppet-pacemaker last update\n\nUpdate the definition of the pacemaker::resource::ocf for Galera to\nreflect the changes that happened in master.\n\nChange-Id: I6985683851187a2512c37f59eaee5905bbc2dae2\n'}, {'number': 3, 'created': '2015-05-14 07:30:03.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c2e903cad599bdedc4e9b6165a8a306ff5be6fc9', 'message': 'Adapt Galera ocf resource to puppet-pacemaker last update\n\nUpdate the definition of the pacemaker::resource::ocf for Galera to\nreflect the changes that happened in master.\n\nChange-Id: I6985683851187a2512c37f59eaee5905bbc2dae2\n'}]",2,182947,c2e903cad599bdedc4e9b6165a8a306ff5be6fc9,13,5,3,9410,,,0,"Adapt Galera ocf resource to puppet-pacemaker last update

Update the definition of the pacemaker::resource::ocf for Galera to
reflect the changes that happened in master.

Change-Id: I6985683851187a2512c37f59eaee5905bbc2dae2
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/47/182947/3 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,1d12693a5558247798f0e4cabcdea30e54e64184,pcmk_resource_change," resource_name => 'heartbeat:galera', op_params => 'promote timeout=300s on-fail=block', master_params => true, meta_params => ""master-max=${galera_nodes_count} ordered=true "", resource_params => ""enable_creation=true wsrep_cluster_address='gcomm://${galera_nodes}'"", require => Class['::mysql::server'], before => Exec['galera-ready'],"," resource_name => 'heartbeat:galera', options => ""enable_creation=true wsrep_cluster_address='gcomm://${galera_nodes}' meta master-max=${galera_nodes_count} ordered=true op promote timeout=300s on-fail=block --master"", require => Class['::mysql::server'], before => Exec['galera-ready'],",7,4
openstack%2Fcinder-specs~master~I71ded4fe3e33d45880d1327e945657728454657e,openstack/cinder-specs,master,I71ded4fe3e33d45880d1327e945657728454657e,Virtuozzo Storage volume driver,ABANDONED,2015-05-19 17:03:38.000000000,2015-05-21 22:42:00.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-19 17:03:38.000000000', 'files': ['specs/liberty/vzstorage-volume-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/f761fab77d02792b25325978d38057b04b309b62', 'message': ""Virtuozzo Storage volume driver\n\nAdd spec for Virtuozzo Storage volume driver.\n\nVirtuozzo Storage is a fault-tolerant distributed storage\nsystem optimized for virtualization workloads. From client's\npoint of view it looks like network attached storage (NFS or\nGlusterFS).\n\nblueprint virtuozzo-cloud-storage-support\n\nChange-Id: I71ded4fe3e33d45880d1327e945657728454657e\n""}]",0,184296,f761fab77d02792b25325978d38057b04b309b62,3,1,1,12661,,,0,"Virtuozzo Storage volume driver

Add spec for Virtuozzo Storage volume driver.

Virtuozzo Storage is a fault-tolerant distributed storage
system optimized for virtualization workloads. From client's
point of view it looks like network attached storage (NFS or
GlusterFS).

blueprint virtuozzo-cloud-storage-support

Change-Id: I71ded4fe3e33d45880d1327e945657728454657e
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/96/184296/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/vzstorage-volume-driver.rst'],1,f761fab77d02792b25325978d38057b04b309b62,bp/virtuozzo-cloud-storage-support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================== Virtuozzo Storage Volume Driver =============================== https://blueprints.launchpad.net/cinder/+spec/virtuozzo-cloud-storage-support The purpose of this blueprint to add a volume driver supporting Virtuozzo Storage, which is a fault-tolerant distributed storage system optimized for virtualization workloads. From client's point of view it looks like network attached storage (NFS or GlusterFS). Virtuozzo Storage allows to use disk space of conventional linux systems to provide fault-tolerant storage with automatic recovery. It's optimized for performance of virtualization workloads and has strong data consistency. Problem description =================== Currently Virtuozzo storage is not supported in Openstack in spite of benefits it provides. Use Cases ========= * Use separate Virtuozzo Storage cluster as cinder backend. * Reuse compute nodes free space for storing volumes data. Proposed change =============== The proposed driver will use available infrastructure for NAS drivers, RemoteFSDriver class and os-brick, like NFS or smbfs drivers. At this point only required set of operations will be implemented. It will include support for raw and qcow2 images. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ The driver will periodically check for filesystem info, like free and total space. Also shares list will be read from a config file on start. Other deployer impact --------------------- The user will provide a list of vzstorage clusters, which should be used in cinder. This list will be placed in a file located at a path configured in the cinder config file. This share list may contain vzstorage mount options such as SSD cache options. Oversubmit and used space ratios may also be configured in the cinder config file. The user will be able to configure default volume type (raw or qcow2), which can be overriden by volume's extra specs. Implementation ============== Assignee(s) ----------- Primary assignee: <dguryanov@virtuozzo.com> Work Items ---------- Provide support for mounting vzstorage clusters in the remotefs client. Implement all required methods in a derived from RemoteFSDriver class. Dependencies ============ Libvirt vzstorage volume driver blueprint: https://blueprints.launchpad.net/nova/+spec/libvirt-vzstorage-volume-support Testing ======= A Cinder CI will be testing the vzstorage related features. Documentation Impact ==================== Using the vzstorage backend will be documented. References ========== Virtuozzo Storage documentation: http://download.cloudserver.parallels.com/doc/pcs/en_us/parallels/6/current/html/Parallels_Cloud_Storage_Administrators_Guide/ ",,128,0
openstack%2Ftripleo-heat-templates~master~Iff90e5f217fe77ccdb99764c48ac83705f6a4e25,openstack/tripleo-heat-templates,master,Iff90e5f217fe77ccdb99764c48ac83705f6a4e25,Adapt MongoDB systemd resource to puppet-pacemaker last update,ABANDONED,2015-05-14 06:50:20.000000000,2015-05-21 22:41:37.000000000,,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-14 06:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a97099464d60be4ce282900dbe3fbf49615430d0', 'message': 'Adapt MongoDB systemd resource to puppet-pacemaker last update\n\nUpdate the definition of the pacemaker::resource::systemd for MongoDB to\nreflect the changes that happened in master.\n\nChange-Id: Iff90e5f217fe77ccdb99764c48ac83705f6a4e25\n'}, {'number': 2, 'created': '2015-05-14 07:30:03.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fc894ac574f48c3e46907fe16ad8b4ac4e7ab1d0', 'message': 'Adapt MongoDB systemd resource to puppet-pacemaker last update\n\nUpdate the definition of the pacemaker::resource::systemd for MongoDB to\nreflect the changes that happened in master.\n\nChange-Id: Iff90e5f217fe77ccdb99764c48ac83705f6a4e25\n'}]",0,182948,fc894ac574f48c3e46907fe16ad8b4ac4e7ab1d0,7,3,2,9410,,,0,"Adapt MongoDB systemd resource to puppet-pacemaker last update

Update the definition of the pacemaker::resource::systemd for MongoDB to
reflect the changes that happened in master.

Change-Id: Iff90e5f217fe77ccdb99764c48ac83705f6a4e25
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/48/182948/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,a97099464d60be4ce282900dbe3fbf49615430d0,pcmk_resource_change," op_params => 'start timeout=120s', clone_params => true, before => Exec['mongodb-ready'],"," options => ""op start timeout=120s"", clone => true, before => Exec['mongodb-ready'],",3,3
openstack%2Ftripleo-heat-templates~master~I1aaf45cb971bc931fe5e9de95b41eca61057e098,openstack/tripleo-heat-templates,master,I1aaf45cb971bc931fe5e9de95b41eca61057e098,Adapt HAProxy systemd resource to puppet-pacemaker last update,ABANDONED,2015-05-14 07:10:08.000000000,2015-05-21 22:41:30.000000000,,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-14 07:10:08.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/18bdd944d4bf53f33a3507338a9ac7aab55c4bb4', 'message': 'Adapt HAProxy systemd resource to puppet-pacemaker last update\n\nUpdate the definition of the pacemaker::resource::systemd for HAProxy to\nreflect the changes that happened in master.\n\nChange-Id: I1aaf45cb971bc931fe5e9de95b41eca61057e098\n'}]",0,182955,18bdd944d4bf53f33a3507338a9ac7aab55c4bb4,5,3,1,9410,,,0,"Adapt HAProxy systemd resource to puppet-pacemaker last update

Update the definition of the pacemaker::resource::systemd for HAProxy to
reflect the changes that happened in master.

Change-Id: I1aaf45cb971bc931fe5e9de95b41eca61057e098
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/55/182955/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,18bdd944d4bf53f33a3507338a9ac7aab55c4bb4,pcmk_resource_change," clone_params => true,"," clone => true,",1,1
openstack%2Ftripleo-heat-templates~master~I6870768ae287e87792813772352f484d526f3ee7,openstack/tripleo-heat-templates,master,I6870768ae287e87792813772352f484d526f3ee7,Adapt RabbitMQ ocf resource to puppet-pacemaker last update,ABANDONED,2015-05-14 07:21:16.000000000,2015-05-21 22:41:16.000000000,,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-14 07:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7f0ebfdf5faba57143ab8f160a4cfeadad61126', 'message': 'Adapt RabbitMQ ocf resource to puppet-pacemaker last update\n\nUpdate the definition of the pacemaker::resource::ocf for RabbitMQ to\nreflect the changes that happened in master.\n\nChange-Id: I6870768ae287e87792813772352f484d526f3ee7\n'}, {'number': 2, 'created': '2015-05-14 07:30:03.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0e74ed070b0701de4fb1a8f0baf0ac794db2c804', 'message': 'Adapt RabbitMQ ocf resource to puppet-pacemaker last update\n\nUpdate the definition of the pacemaker::resource::ocf for RabbitMQ to\nreflect the changes that happened in master.\n\nChange-Id: I6870768ae287e87792813772352f484d526f3ee7\n'}]",0,182958,0e74ed070b0701de4fb1a8f0baf0ac794db2c804,7,3,2,9410,,,0,"Adapt RabbitMQ ocf resource to puppet-pacemaker last update

Update the definition of the pacemaker::resource::ocf for RabbitMQ to
reflect the changes that happened in master.

Change-Id: I6870768ae287e87792813772352f484d526f3ee7
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/58/182958/2 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,f7f0ebfdf5faba57143ab8f160a4cfeadad61126,pcmk_resource_change," ocf_agent_name => 'heartbeat:rabbitmq-cluster', resource_params => 'set_policy=\'ha-all ^(?!amq\.).* {""ha-mode"":""all""}\'', clone_params => true, require => Class['::rabbitmq'],"," resource_name => 'heartbeat:rabbitmq-cluster', options => 'set_policy=\'ha-all ^(?!amq\.).* {""ha-mode"":""all""}\'', clone => true, require => Class['::rabbitmq'],",4,4
openstack%2Fcue~master~Icfbae2d6a6d1be37869dcd6b9a31745aa013ec18,openstack/cue,master,Icfbae2d6a6d1be37869dcd6b9a31745aa013ec18,Updating cue/cmd/manage.py get_arg_string() argument parser,ABANDONED,2015-05-21 18:31:10.000000000,2015-05-21 22:37:27.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-21 18:31:10.000000000', 'files': ['cue/cmd/manage.py', 'cue/tests/unit/cmd/test_manage.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/a0a712259513f392fe0af7cd11900463527ff1d1', 'message': 'Updating cue/cmd/manage.py get_arg_string() argument parser\n\nLooks like get_arg_string() would improperly chop off the first two characters\nof an argument that was passed in with two dashes (--example).\n\nChange-Id: Icfbae2d6a6d1be37869dcd6b9a31745aa013ec18\n'}]",0,184845,a0a712259513f392fe0af7cd11900463527ff1d1,3,1,1,15904,,,0,"Updating cue/cmd/manage.py get_arg_string() argument parser

Looks like get_arg_string() would improperly chop off the first two characters
of an argument that was passed in with two dashes (--example).

Change-Id: Icfbae2d6a6d1be37869dcd6b9a31745aa013ec18
",git fetch https://review.opendev.org/openstack/cue refs/changes/45/184845/1 && git format-patch -1 --stdout FETCH_HEAD,"['cue/cmd/manage.py', 'cue/tests/unit/cmd/test_manage.py']",2,a0a712259513f392fe0af7cd11900463527ff1d1,cue_cmd_test," self.assertEqual(""foo"", manage.get_arg_string(args2))"," # Todo (Dan) Fix the get_arg_string conditional so cases like arg2 # Todo (Dan) will properly return 'foo', not 'o'. self.assertEqual(""o"", manage.get_arg_string(args2)) ",2,6
openstack%2Fopenstack-manuals~master~I56135a86d8138564407496b291042b82fa5fca30,openstack/openstack-manuals,master,I56135a86d8138564407496b291042b82fa5fca30,Fix User Guide links,MERGED,2015-05-20 20:19:48.000000000,2015-05-21 22:33:07.000000000,2015-05-21 22:33:04.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7923}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-05-20 20:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dd67aa0d5af0695bdbc95f5ca3e0fb0cdfd0abe3', 'message': 'Fix User Guide links\n\nRemove extra /enduser/ in URL that does not exist anymore in\nreferences to End User Guide.\n\nChange-Id: I56135a86d8138564407496b291042b82fa5fca30\n'}, {'number': 2, 'created': '2015-05-20 20:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1e0670b768db2219abaccd8473869ca3ab95847d', 'message': 'Fix User Guide links\n\nAdjust links for End User guides changes.\n\nChange-Id: I56135a86d8138564407496b291042b82fa5fca30\n'}, {'number': 3, 'created': '2015-05-20 20:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e0e07c1781baa0e83f6325d876cf887114a84cb2', 'message': 'Fix User Guide links\n\nAdjust links for End User guides changes.\n\nChange-Id: I56135a86d8138564407496b291042b82fa5fca30\n'}, {'number': 4, 'created': '2015-05-20 20:48:41.000000000', 'files': ['doc/user-guide-admin/source/dashboard_admin_manage_stacks.rst', 'doc/common/section_keystone-concepts-service-management.xml', 'doc/user-guide-admin/source/nova_cli_manage_projects_security.rst', 'doc/user-guide-admin/source/dashboard_set_quotas.rst', 'doc/user-guide-admin/source/cli_admin_manage_stacks.rst', 'doc/user-guide-admin/source/dashboard_view_cloud_resources.rst', 'doc/install-guide/ch_launch-instance.xml', 'doc/admin-guide-cloud/ch_blockstorage.xml', 'doc/user-guide/source/hot-guide/hot_basic_resources.rst', 'doc/user-guide-admin/source/cli_admin_manage_ip_addresses.rst', 'doc/admin-guide-cloud/compute/section_compute-configure-migrations.xml', 'doc/admin-guide-cloud/compute/section_compute-networking-nova.xml', 'doc/user-guide-admin/source/manage_projects_users_and_roles.rst', 'doc/config-reference/ch_computeconfigure.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5009f41e6861ea875c7e5f92f082d8055325efc8', 'message': 'Fix User Guide links\n\nAdjust links for End User guides changes.\n\nChange-Id: I56135a86d8138564407496b291042b82fa5fca30\n'}]",0,184610,5009f41e6861ea875c7e5f92f082d8055325efc8,12,4,4,6547,,,0,"Fix User Guide links

Adjust links for End User guides changes.

Change-Id: I56135a86d8138564407496b291042b82fa5fca30
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/10/184610/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/ch_launch-instance.xml', 'doc/admin-guide-cloud/ch_blockstorage.xml', 'doc/admin-guide-cloud/compute/section_compute-configure-migrations.xml', 'doc/config-reference/ch_computeconfigure.xml']",4,dd67aa0d5af0695bdbc95f5ca3e0fb0cdfd0abe3,," xlink:href=""http://docs.openstack.org/user-guide/cli_change_the_size_of_your_server.html"""," xlink:href=""http://docs.openstack.org/user-guide/enduser/cli_change_the_size_of_your_server.html""",5,5
openstack%2Fneutron-fwaas~master~Ie70bd52b4a7e0b0683488b893036af7f4ada68dd,openstack/neutron-fwaas,master,Ie70bd52b4a7e0b0683488b893036af7f4ada68dd,Updated from global requirements,MERGED,2015-05-07 23:32:47.000000000,2015-05-21 22:17:25.000000000,2015-05-21 22:17:22.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 8645}, {'_account_id': 10119}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 15330}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-05-07 23:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/93e85507e372a5bfe7c9365404dd9060a66d07f7', 'message': 'Updated from global requirements\n\nChange-Id: Ie70bd52b4a7e0b0683488b893036af7f4ada68dd\n'}, {'number': 2, 'created': '2015-05-16 16:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/418d48b2fcb7dd7dc202bb559fd3b394910283be', 'message': 'Updated from global requirements\n\nChange-Id: Ie70bd52b4a7e0b0683488b893036af7f4ada68dd\n'}, {'number': 3, 'created': '2015-05-19 23:30:13.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/c5855ef623ef0bceb6b6799aa145b14732fc490e', 'message': 'Updated from global requirements\n\nChange-Id: Ie70bd52b4a7e0b0683488b893036af7f4ada68dd\n'}]",0,181207,c5855ef623ef0bceb6b6799aa145b14732fc490e,29,9,3,11131,,,0,"Updated from global requirements

Change-Id: Ie70bd52b4a7e0b0683488b893036af7f4ada68dd
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/07/181207/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,93e85507e372a5bfe7c9365404dd9060a66d07f7,openstack/requirements,"pbr>=0.11,<2.0","pbr>=0.6,!=0.7,<1.0",1,1
openstack%2Foslotest~master~Ic59c73abb9b09cb594bf7df4173d7f99f81d526c,openstack/oslotest,master,Ic59c73abb9b09cb594bf7df4173d7f99f81d526c,Remove six.moves call,MERGED,2015-01-15 10:24:11.000000000,2015-05-21 22:13:37.000000000,2015-05-21 22:13:36.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 9397}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-01-15 10:24:11.000000000', 'files': ['oslotest/moxstubout.py', 'oslotest/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslotest/commit/9e0c8ad2c251274128499a7fcfb591c488d27d2b', 'message': ""Remove six.moves call\n\nThis patches remove the six.move call as it's does not move anything\nsince it relies always on mox3.\n\nChange-Id: Ic59c73abb9b09cb594bf7df4173d7f99f81d526c\n""}]",0,147446,9e0c8ad2c251274128499a7fcfb591c488d27d2b,15,6,1,1669,,,0,"Remove six.moves call

This patches remove the six.move call as it's does not move anything
since it relies always on mox3.

Change-Id: Ic59c73abb9b09cb594bf7df4173d7f99f81d526c
",git fetch https://review.opendev.org/openstack/oslotest refs/changes/46/147446/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslotest/moxstubout.py', 'oslotest/__init__.py', 'tox.ini']",3,9e0c8ad2c251274128499a7fcfb591c488d27d2b,jd/remove-mox,, six.moves.mox,1,3
openstack%2Frally~master~I6958e298272c8792444f102cdc8c7fdf2e893178,openstack/rally,master,I6958e298272c8792444f102cdc8c7fdf2e893178,Server Group quotas support,MERGED,2015-05-20 14:05:13.000000000,2015-05-21 22:01:34.000000000,2015-05-21 22:01:32.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8576}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-20 14:05:13.000000000', 'files': ['rally/plugins/openstack/context/quotas/nova_quotas.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/106154de1bc310a78a9e7ee96274b2787f6f7f89', 'message': 'Server Group quotas support\n\nThe quota context should allow to configure server group related quotas.\n\nChange-Id: I6958e298272c8792444f102cdc8c7fdf2e893178\n'}]",0,184500,106154de1bc310a78a9e7ee96274b2787f6f7f89,8,4,1,7132,,,0,"Server Group quotas support

The quota context should allow to configure server group related quotas.

Change-Id: I6958e298272c8792444f102cdc8c7fdf2e893178
",git fetch https://review.opendev.org/openstack/rally refs/changes/00/184500/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/plugins/openstack/context/quotas/nova_quotas.py'],1,106154de1bc310a78a9e7ee96274b2787f6f7f89,," }, ""server_groups"": { ""type"": ""integer"", ""minimum"": -1 }, ""server_group_members"": { ""type"": ""integer"", ""minimum"": -1",,8,0
openstack%2Frally~master~I729d7feff5ea0e0013a08c83293a5f2cecad9a13,openstack/rally,master,I729d7feff5ea0e0013a08c83293a5f2cecad9a13,[Spec] Move plugins spec to implemented,MERGED,2015-05-21 14:15:48.000000000,2015-05-21 22:01:25.000000000,2015-05-21 22:01:22.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-21 14:15:48.000000000', 'files': ['doc/specs/implemented/split_plugins.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/65e100e291446233a933fb7fbd4ec1766c43bb11', 'message': '[Spec] Move plugins spec to implemented\n\nChange-Id: I729d7feff5ea0e0013a08c83293a5f2cecad9a13\nImplements: blueprint split-plugins\n'}]",0,184792,65e100e291446233a933fb7fbd4ec1766c43bb11,8,4,1,8576,,,0,"[Spec] Move plugins spec to implemented

Change-Id: I729d7feff5ea0e0013a08c83293a5f2cecad9a13
Implements: blueprint split-plugins
",git fetch https://review.opendev.org/openstack/rally refs/changes/92/184792/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/specs/implemented/split_plugins.rst'],1,65e100e291446233a933fb7fbd4ec1766c43bb11,bp/split-plugins,,,0,0
openstack%2Fha-guide~master~I01ca79b5694d5ffd4a81f1984d98d36238e5c880,openstack/ha-guide,master,I01ca79b5694d5ffd4a81f1984d98d36238e5c880,HA Concepts for introduction,MERGED,2015-05-19 20:49:26.000000000,2015-05-21 21:58:01.000000000,2015-05-21 21:58:00.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6926}, {'_account_id': 7751}, {'_account_id': 9162}, {'_account_id': 9382}, {'_account_id': 10014}, {'_account_id': 11444}, {'_account_id': 12651}, {'_account_id': 16483}]","[{'number': 1, 'created': '2015-05-19 20:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/56cf97417e0824a7ae752dfb901f653dc9eb578b', 'message': 'HA Concepts for introduction\n\nThis commit mostly contains material that was in the old ha-guide\nwith a few edits.  It adds new material about quorums and\nsingle-controller ha environments.\n\nWe should add links to other parts of the documentation as those\npieces are written.  We also have an outstanding LP for additional\ninformation that is required.\n\nImplements blueprint improve-ha-guide\n\nChange-Id: I01ca79b5694d5ffd4a81f1984d98d36238e5c880\n'}, {'number': 2, 'created': '2015-05-20 19:19:45.000000000', 'files': ['doc/ha-guide/source/intro-ha-concepts.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/e78694afbc0b5167bc00c44c3b90f3a997a91d48', 'message': 'HA Concepts for introduction\n\nThis commit mostly contains material that was in the old ha-guide\nwith a few edits.  It adds new material about quorums and\nsingle-controller ha environments.\n\nWe should add links to other parts of the documentation as those\npieces are written.  We also have an outstanding LP for additional\ninformation that is required.\n\nNote that some of these terms are defined in the Glossary and the docs\nnow have links to those terms.  We may want to augment those Glossary\ndefinitions as we move forward.\n\nImplements blueprint improve-ha-guide\n\nChange-Id: I01ca79b5694d5ffd4a81f1984d98d36238e5c880\n'}]",18,184323,e78694afbc0b5167bc00c44c3b90f3a997a91d48,17,10,2,10014,,,0,"HA Concepts for introduction

This commit mostly contains material that was in the old ha-guide
with a few edits.  It adds new material about quorums and
single-controller ha environments.

We should add links to other parts of the documentation as those
pieces are written.  We also have an outstanding LP for additional
information that is required.

Note that some of these terms are defined in the Glossary and the docs
now have links to those terms.  We may want to augment those Glossary
definitions as we move forward.

Implements blueprint improve-ha-guide

Change-Id: I01ca79b5694d5ffd4a81f1984d98d36238e5c880
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/23/184323/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/intro-ha-concepts.rst'],1,56cf97417e0824a7ae752dfb901f653dc9eb578b,bp/improve-ha-guide,"High Availability systems seek to minimize two things: - **System downtime** -- Occurs when a user-facing service is unavailable beyond a specified maximum amount of time. - **Data loss** -- Accidental deletion or destruction of data. Most high availability systems guarantee protection against system downtime and data loss only in the event of a single failure. However, they are also expected to protect against cascading failures, where a single failure deteriorates into a series of consequential failures.High availability is implemented with redundant hardware running redundant instances of each service. If one piece of hardware running one instance of a service fails, the system can then failover to use another instance of a service that is running on hardware that did not fail. A crucial aspect of high availability is the elimination of single points of failure (SPOFs). An SPOF is an individual piece of equipment or software that causes system downtime or data loss if it fails. In order to eliminate SPOFs, check that mechanisms exist for redundancy of: - Network components, such as switches and routers - Applications and automatic service migration - Storage components - Facility services such as power, air conditioning, and fire protection Most high availability systems fail in the event of multiple independent (non-consequential) failures. In this case, most implementations favor protecting data over maintaining availability. High-availability systems typically achieve an uptime percentage of 99.99% or more, which roughly equates to less than an hour of cumulative downtime per year. In order to achieve this, high availability systems should keep recovery times after a failure to about one to two minutes, sometimes significantly less. OpenStack currently meets such availability requirements for its own infrastructure services, meaning that an uptime of 99.99% is feasible for the OpenStack infrastructure proper. However, OpenStack does not guarantee 99.99% availability for individual guest instances. This document discusses some common methods of implementing highly available systems, with an emphasis on the core OpenStack services and other open source services that are closely aligned with OpenStack. These methods are by no means the only ways to do it; you may supplement these services with commercial hardware and software that provides additional features and functionality. You also need to address high availability concerns for any applications software that you run on your OpenStack environment. The important thing is to make sure that your services are redundant and available; how you achieve that is up to you. Preventing single points of failure can depend on whether or not a service is stateless. A **stateless service** is one that provides a response after your request and then requires no further attention. To make a stateless service highly available, you need to provide redundant instances and load balance them. OpenStack services that are stateless include nova-api, nova-conductor, glance-api, keystone-api, neutron-api and nova-scheduler. A **stateful service** is one where subsequent requests to the service depend on the results of the first request. Stateful services are more difficult to manage because a single action typically involves more than one request, so simply providing additional instances and load balancing does not solve the problem. For example, if the Horizon user interface reset itself every time you went to a new page, it would not be very useful. OpenStack services that are stateful include the OpenStack database and message queue. Making stateful services highly available can depend on whether you choose an active/passive or active/active configuration. Active/Passive vs Active/Active ------------------------------- An **active/passive** installation for a stateless service typically maintains a redundant instance that can be brought online when the active service fails. For example, OpenStack writes to the main database while maintaining a disaster recovery database that can be brought online if the main database fails. A typical active/passive installation for a stateful service maintains a replacement resource that can be brought online when required. Requests are handled using a virtual IP address (VIP) that facilitates returning to service with minimal reconfiguration. A separate application (such as Pacemaker or Corosync) monitors these services, bringing the backup online as necessary. In an **active/active** configuration, each service also has a backup but manages both the main and redundant systems concurrently. This way, if there is a failure, the user is unlikely to notice. The backup system is already online and takes on increased load while the main system is fixed and brought back online. Typically, an active/active installation for a stateless service maintains a redundant instance, and requests are load balanced using a virtual IP address and a load balancer such as HAProxy. A typical active/active installation for a stateful service includes redundant services, with all instances having an identical state. In other words, updates to one instance of a database update all other instances. This way a request to one instance is the same as a request to any other. A load balancer manages the traffic to these systems, ensuring that operational systems always handle the request. Clusters and Quorums -------------------- The quorum specifies the minimal number of nodes that must be functional in a cluster of redundant nodes in order for the cluster to remain functional. When one node fails and failover transfers control to other nodes, the system must ensure that data and processes remain sane. To determine this, the contents of the remaining nodes are compared and, if there are discrepencies, a ""majority rules"" algorithm is implemented. For this reason, each cluster in a high availability environment must have an odd number of nodes and the quorum must specify an odd number of nodes. If multiple nodes fail so that the cluster size falls below the quorum value, the cluster itself fails. For example, in a 7-node cluster, the quorum could be set to 5 or 3. If quorum is 5 and three nodes fail simultaneously, the cluster itself would fail, whereas it would continue to function if the quorum were set to 3. When configuring an OpenStack environment for study or demonstration purposes, it is possible to turn off the quorum checking; this is discussed later in this guide. Production systems should always run with quorum enabled. OpenStack supports a single-controller high availability mode that is managed by the services that manage highly available environments but is not actually highly available because no redundant controllers are configured to use for failover. This environment can be used for study and demonstration but is not appropriate for a production environment. It is possible to add controllers to such an environment to convert it into a truly highly available environment.",Quorums -------,147,2
openstack%2Fmurano-apps~master~Ib587267566e467beb1c440119a5366a4ff02fb0e,openstack/murano-apps,master,Ib587267566e467beb1c440119a5366a4ff02fb0e,Add apps needed for a CI/CD pipeline.,ABANDONED,2015-05-21 21:54:04.000000000,2015-05-21 21:57:36.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-21 21:54:04.000000000', 'files': ['OpenLDAP/package/manifest.yaml', 'Jenkins/package/Resources/GetKey.template', 'Jenkins/package/Resources/scripts/deployJenkins.sh', 'Gerrit/package/manifest.yaml', 'Gerrit/package/Resources/PutKey.template', 'OpenLDAP/package/Resources/ConfigureOpenLDAPDomain.template', 'Attis/package/manifest.yaml', 'Gerrit/package/Classes/Gerrit.yaml', 'Gerrit/package/UI/ui.yaml', 'Jenkins/package/UI/ui.yaml', 'Jenkins/package/Resources/ConnectLDAP.template', 'Jenkins/package/Resources/scripts/noop.sh', 'Jenkins/package/Resources/DeployJenkins.template', 'Jenkins/package/Resources/ConnectGerrit.template', 'OpenLDAP/package/Resources/DeployOpenLDAP.template', 'OpenLDAP/package/Resources/scripts/configureOpenLDAPUser.sh', 'Jenkins/package/Classes/Jenkins.yaml', 'OpenLDAP/package/Resources/scripts/deployOpenLDAP.sh', 'OpenLDAP/package/UI/ui.yaml', 'Attis/package/logo.png', 'Attis/package/UI/ui.yaml', 'Gerrit/package/Resources/scripts/putKey.sh', 'Gerrit/package/Resources/scripts/connectLDAP.sh', 'OpenLDAP/package/Resources/scripts/configureOpenLDAPDomain.sh', 'Gerrit/package/Resources/ConnectLDAP.template', 'OpenLDAP/package/Resources/ConfigureOpenLDAPUser.template', 'Jenkins/package/manifest.yaml', 'OpenLDAP/package/Classes/OpenLDAP.yaml', 'Jenkins/package/logo.png', 'Gerrit/package/logo.png', 'Jenkins/package/Resources/scripts/connectGerrit.sh', 'Attis/package/Classes/Attis.yaml', 'OpenLDAP/package/logo.png', 'Gerrit/package/Resources/DeployGerrit.template', 'Gerrit/package/Resources/scripts/deployGerrit.sh', 'Jenkins/package/Resources/scripts/connectLDAP.sh'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/8586d689000c213230946f6ec5754f13e42e5e5f', 'message': 'Add apps needed for a CI/CD pipeline.\n\nAttis-- wrapper app that deploys and configures the CI/CD infrastructure\nOpenLDAP-- openLDAP app; Create user jenkins/openstack for authentication\nGerrit-- Gerrit app that uses OpenLDAP for authentication; create user gerrit\nJenkins-- Jenkins app that uses OpenLDAP for authentication\n\nMake changes based on code review\nChange-Id: I41260869c4454057db591341b353dcb11f07457a\n\nonly part of ssh key was copied\n\nChange-Id: Ib587267566e467beb1c440119a5366a4ff02fb0e\n'}]",0,184873,8586d689000c213230946f6ec5754f13e42e5e5f,3,1,1,15663,,,0,"Add apps needed for a CI/CD pipeline.

Attis-- wrapper app that deploys and configures the CI/CD infrastructure
OpenLDAP-- openLDAP app; Create user jenkins/openstack for authentication
Gerrit-- Gerrit app that uses OpenLDAP for authentication; create user gerrit
Jenkins-- Jenkins app that uses OpenLDAP for authentication

Make changes based on code review
Change-Id: I41260869c4454057db591341b353dcb11f07457a

only part of ssh key was copied

Change-Id: Ib587267566e467beb1c440119a5366a4ff02fb0e
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/73/184873/1 && git format-patch -1 --stdout FETCH_HEAD,"['OpenLDAP/package/manifest.yaml', 'Jenkins/package/Resources/GetKey.template', 'Jenkins/package/Resources/scripts/deployJenkins.sh', 'Gerrit/package/manifest.yaml', 'Gerrit/package/Resources/PutKey.template', 'OpenLDAP/package/Resources/ConfigureOpenLDAPDomain.template', 'Attis/package/manifest.yaml', 'Gerrit/package/Classes/Gerrit.yaml', 'Gerrit/package/UI/ui.yaml', 'Jenkins/package/UI/ui.yaml', 'Jenkins/package/Resources/ConnectLDAP.template', 'Jenkins/package/Resources/scripts/noop.sh', 'Jenkins/package/Resources/DeployJenkins.template', 'Jenkins/package/Resources/ConnectGerrit.template', 'OpenLDAP/package/Resources/DeployOpenLDAP.template', 'OpenLDAP/package/Resources/scripts/configureOpenLDAPUser.sh', 'Jenkins/package/Classes/Jenkins.yaml', 'OpenLDAP/package/Resources/scripts/deployOpenLDAP.sh', 'OpenLDAP/package/UI/ui.yaml', 'Attis/package/logo.png', 'Attis/package/UI/ui.yaml', 'Gerrit/package/Resources/scripts/putKey.sh', 'Gerrit/package/Resources/scripts/connectLDAP.sh', 'OpenLDAP/package/Resources/scripts/configureOpenLDAPDomain.sh', 'Gerrit/package/Resources/ConnectLDAP.template', 'OpenLDAP/package/Resources/ConfigureOpenLDAPUser.template', 'Jenkins/package/manifest.yaml', 'OpenLDAP/package/Classes/OpenLDAP.yaml', 'Jenkins/package/logo.png', 'Gerrit/package/logo.png', 'Jenkins/package/Resources/scripts/connectGerrit.sh', 'Attis/package/Classes/Attis.yaml', 'OpenLDAP/package/logo.png', 'Gerrit/package/Resources/DeployGerrit.template', 'Gerrit/package/Resources/scripts/deployGerrit.sh', 'Jenkins/package/Resources/scripts/connectLDAP.sh']",36,8586d689000c213230946f6ec5754f13e42e5e5f,I41260869c4454057db591341b353dcb11f07457a,"#!/bin/bash OPENLDAP_IP=""$1"" DOMAIN=""$2"" NAME=""`echo ""$DOMAIN"" | cut -d. -f1`"" TLD=""`echo ""$DOMAIN"" | cut -d. -f2`"" cat << CONFIG >> /var/lib/jenkins/config.xml <?xml version='1.0' encoding='UTF-8'?> <hudson> <disabledAdministrativeMonitors/> <version>1.0</version> <numExecutors>2</numExecutors> <mode>NORMAL</mode> <useSecurity>true</useSecurity> <authorizationStrategy class=""hudson.security.AuthorizationStrategy\$Unsecured""/> <securityRealm class=""hudson.security.LDAPSecurityRealm"" plugin=""ldap@1.6""> <server>ldap://${OPENLDAP_IP}</server> <rootDN>dc=${NAME},dc=${TLD}</rootDN> <inhibitInferRootDN>false</inhibitInferRootDN> <userSearchBase></userSearchBase> <userSearch>uid={0}</userSearch> <managerDN>cn=admin,dc=${NAME},dc=${TLD}</managerDN> <managerPassword>b3BlbnN0YWNr</managerPassword> <disableMailAddressResolver>false</disableMailAddressResolver> </securityRealm> <disableRememberMe>false</disableRememberMe> <projectNamingStrategy class=""jenkins.model.ProjectNamingStrategy\$DefaultProjectNamingStrategy""/> <workspaceDir>\${JENKINS_HOME}/workspace/\${ITEM_FULLNAME}</workspaceDir> <buildsDir>\${ITEM_ROOTDIR}/builds</buildsDir> <markupFormatter class=""hudson.markup.EscapedMarkupFormatter""/> <jdks/> <viewsTabBar class=""hudson.views.DefaultViewsTabBar""/> <myViewsTabBar class=""hudson.views.DefaultMyViewsTabBar""/> <clouds/> <scmCheckoutRetryCount>0</scmCheckoutRetryCount> <views> <hudson.model.AllView> <owner class=""hudson"" reference=""../../..""/> <name>All</name> <filterExecutors>false</filterExecutors> <filterQueue>false</filterQueue> <properties class=""hudson.model.View\$PropertyList""/> </hudson.model.AllView> </views> <primaryView>All</primaryView> <slaveAgentPort>0</slaveAgentPort> <label></label> <nodeProperties/> <globalNodeProperties/> </hudson> CONFIG service jenkins restart ",,1203,0
openstack%2Fglance~master~I5c72a7692e7bb0ed36613f5dbfb42142afc5bd6e,openstack/glance,master,I5c72a7692e7bb0ed36613f5dbfb42142afc5bd6e,Set http_keepalive default value to False,ABANDONED,2015-03-18 07:28:13.000000000,2015-05-21 21:47:41.000000000,,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 6549}, {'_account_id': 9303}]","[{'number': 1, 'created': '2015-03-18 07:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e4faa37a5ffa769f617efc3f1779d3500a18f735', 'message': 'Set http_keepalive default value to False\n\nIn order to close the client socket connection explicitly after\nthe response is sent and read successfully by the client, you\nsimply have to set keepalive to False when you create a wsgi\nserver. Right now it is set to True for backward compatibility.\n\nChanged default value of http_keepalive to False.\n\nChange-Id: I5c72a7692e7bb0ed36613f5dbfb42142afc5bd6e\nCloses-Bug: #1433435\n'}, {'number': 2, 'created': '2015-03-18 09:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0e23969e351f749dce64b94f74e899f934ff5ebc', 'message': 'Set http_keepalive default value to False\n\nPresently, the wsgi server allows persist connections. Hence even\nafter the response is sent to the client, it does not close the\nclient socket connection. Because of this problem, the green thread\nis not released back to the pool. Setting this option to False will\nprevent avoid this leak happen. Right now it is set to True for\nbackward compatibility.\n\nChanged default value of http_keepalive to False.\n\nChange-Id: I5c72a7692e7bb0ed36613f5dbfb42142afc5bd6e\nCloses-Bug: #1433435\n'}, {'number': 3, 'created': '2015-03-18 10:27:49.000000000', 'files': ['glance/common/wsgi.py', 'etc/glance-api.conf', 'doc/source/configuring.rst', 'etc/glance-registry.conf'], 'web_link': 'https://opendev.org/openstack/glance/commit/24a88712aa9599e6a2f6a3f4e6e7a31dd9a9ffb5', 'message': 'Set http_keepalive default value to False\n\nPresently, the wsgi server allows persist connections. Hence even\nafter the response is sent to the client, it does not close the\nclient socket connection. Because of this problem, the green thread\nis not released back to the pool. Setting this option to False will\navoid this leak happen. Right now it is set to True for backward\ncompatibility.\n\nChanged default value of http_keepalive to False.\n\nChange-Id: I5c72a7692e7bb0ed36613f5dbfb42142afc5bd6e\nCloses-Bug: #1433435\n'}]",4,165321,24a88712aa9599e6a2f6a3f4e6e7a31dd9a9ffb5,17,4,3,9303,,,0,"Set http_keepalive default value to False

Presently, the wsgi server allows persist connections. Hence even
after the response is sent to the client, it does not close the
client socket connection. Because of this problem, the green thread
is not released back to the pool. Setting this option to False will
avoid this leak happen. Right now it is set to True for backward
compatibility.

Changed default value of http_keepalive to False.

Change-Id: I5c72a7692e7bb0ed36613f5dbfb42142afc5bd6e
Closes-Bug: #1433435
",git fetch https://review.opendev.org/openstack/glance refs/changes/21/165321/2 && git format-patch -1 --stdout FETCH_HEAD,['glance/common/wsgi.py'],1,e4faa37a5ffa769f617efc3f1779d3500a18f735,bug/1433435," cfg.BoolOpt('http_keepalive', default=False,"," cfg.BoolOpt('http_keepalive', default=True,",1,1
openstack%2Fnova~master~I2f5720b191bad1a411b35a4f6816b891e51142cc,openstack/nova,master,I2f5720b191bad1a411b35a4f6816b891e51142cc,Move image creation from compute api to manager,ABANDONED,2015-01-27 08:42:34.000000000,2015-05-21 21:47:10.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6466}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-01-27 08:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68e71fb634a900caecbb6d079d749a839266247e', 'message': 'Move image creation from compute api to manager\n\nshelve_offload_time parameter is configured only on the compute nodes and\nin case it is set to -2 then it is not necessary to take the snapshot of\nthe instance so the logic of creating image is moved from compute api to\ncompute manager.\n\nMoved create_image method to compute utils package to create the image on\ncompute node and removed image_id from shelve_instance rpc call.\n\nChange-Id: I2f5720b191bad1a411b35a4f6816b891e51142cc\nblueprint: improve-unshelve-performance\n'}, {'number': 2, 'created': '2015-01-27 09:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0cb2686cc8d5629f60f633ab76587b7b28c44c79', 'message': 'Move image creation from compute api to manager\n\nshelve_offload_time parameter is configured only on the compute nodes and\nin case it is set to -2 then it is not necessary to take the snapshot of\nthe instance so the logic of creating image is moved from compute api to\ncompute manager.\n\nMoved create_image method to compute utils package to create the image on\ncompute node and removed image_id from shelve_instance rpc call.\n\nChange-Id: I2f5720b191bad1a411b35a4f6816b891e51142cc\nblueprint: improve-unshelve-performance\n'}, {'number': 3, 'created': '2015-04-08 09:54:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4abd901e47a9ebb3fc4d3d2747df023d057f9c7f', 'message': 'Move image creation from compute api to manager\n\nshelve_offload_time parameter is configured only on the compute nodes and\nin case it is set to -2 then it is not necessary to take the snapshot of\nthe instance so the logic of creating image is moved from compute api to\ncompute manager.\n\nMoved create_image method to compute utils package to create the image on\ncompute node and removed image_id from shelve_instance rpc call.\n\nChange-Id: I2f5720b191bad1a411b35a4f6816b891e51142cc\nblueprint: improve-unshelve-performance\n'}, {'number': 4, 'created': '2015-04-08 09:57:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92da4567e631f5b48659c011e68909e155e24aed', 'message': 'Move image creation from compute api to manager\n\nshelve_offload_time parameter is configured only on the compute nodes and\nin case it is set to -2 then it is not necessary to take the snapshot of\nthe instance so the logic of creating image is moved from compute api to\ncompute manager.\n\nMoved create_image method to compute utils package to create the image on\ncompute node and removed image_id from shelve_instance rpc call.\n\nChange-Id: I2f5720b191bad1a411b35a4f6816b891e51142cc\nblueprint: improve-unshelve-performance\n'}, {'number': 5, 'created': '2015-04-09 12:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2ca28aebdb15d050a8e7ae08002c224822975bb2', 'message': 'Move image creation from compute api to manager\n\nshelve_offload_time parameter is configured only on the compute nodes and\nin case it is set to -2 then it is not necessary to take the snapshot of\nthe instance so the logic of creating image is moved from compute api to\ncompute manager.\n\nMoved create_image method to compute utils package to create the image on\ncompute node and removed image_id from shelve_instance rpc call.\n\nChange-Id: I2f5720b191bad1a411b35a4f6816b891e51142cc\nblueprint: improve-unshelve-performance\n'}, {'number': 6, 'created': '2015-04-09 12:17:33.000000000', 'files': ['nova/tests/unit/compute/test_rpcapi.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/compute/test_shelve.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py', 'nova/compute/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f357384071df0afb667934608e1e6c984f504e5c', 'message': 'Move image creation from compute api to manager\n\nshelve_offload_time parameter is configured only on the compute nodes and\nin case it is set to -2 then it is not necessary to take the snapshot of\nthe instance so the logic of creating image is moved from compute api to\ncompute manager.\n\nMoved create_image method to compute utils package to create the image on\ncompute node and removed image_id from shelve_instance rpc call.\n\nChange-Id: I2f5720b191bad1a411b35a4f6816b891e51142cc\nblueprint: improve-unshelve-performance\n'}]",0,150315,f357384071df0afb667934608e1e6c984f504e5c,46,14,6,9303,,,0,"Move image creation from compute api to manager

shelve_offload_time parameter is configured only on the compute nodes and
in case it is set to -2 then it is not necessary to take the snapshot of
the instance so the logic of creating image is moved from compute api to
compute manager.

Moved create_image method to compute utils package to create the image on
compute node and removed image_id from shelve_instance rpc call.

Change-Id: I2f5720b191bad1a411b35a4f6816b891e51142cc
blueprint: improve-unshelve-performance
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/150315/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_rpcapi.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/compute/test_shelve.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py', 'nova/compute/utils.py']",7,68e71fb634a900caecbb6d079d749a839266247e,bp/improve-unshelve-performance,"def create_image(context, instance, name, image_type, image_api, extra_properties=None): """"""Create new image entry in the image service. This new image will be reserved for the compute manager to upload a snapshot or backup. :param context: security context :param instance: nova.db.sqlalchemy.models.Instance :param name: string for name of the snapshot :param image_type: snapshot | backup :param extra_properties: dict of extra image properties to include """""" if extra_properties is None: extra_properties = {} instance_uuid = instance['uuid'] properties = { 'instance_uuid': instance_uuid, 'user_id': str(context.user_id), 'image_type': image_type, } image_ref = instance.image_ref sent_meta = get_image_metadata(context, image_api, image_ref, instance) sent_meta['name'] = name sent_meta['is_public'] = False # The properties set up above and in extra_properties have precedence properties.update(extra_properties or {}) sent_meta['properties'].update(properties) return image_api.create(context, sent_meta) ",,106,95
openstack%2Fnova~master~Iedb910e6656cdefd6d668262c7ed0726dbb1475a,openstack/nova,master,Iedb910e6656cdefd6d668262c7ed0726dbb1475a,Improve performance of Unshelve api,ABANDONED,2015-01-27 10:25:04.000000000,2015-05-21 21:46:13.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5170}, {'_account_id': 6466}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-01-27 10:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09bdbc7ba3f29155e797694f5a12059073a961f5', 'message': 'Improve performance of Unshelve api\n\nAim of this feature is to improve the performance of unshelve instance\nby eliminating downloading/copying snapshot time. All instance files will be\nretained in the instance store backed by shared or non-shared storage on the\ncompute node when an instance is shelved.\n\nAn existing configuration parameter ""shelved_offload_time"" will be used here\nto indicate the instance files should not be deleted.\n\nNew value will be added:\nshelved_offload_time = -2\n\nOffload partially. In this case instance files will be retained. CPU and\nMemory will be released back to the hypervisor which can be used for\nspawning new instances.\n\nAdded new VM state \'SHELVED_PARTIAL_OFFLOADED\' and new Task state\n\'SHELVING_PARTIAL_OFFLOADING\', so user can identify by VM status\nthat, instance is partially offloaded and instance files are persisted\non the host.\n\nDocImpact:\nAn existing configuration parameter “shelved_offload_time"" will be modified\nhere to indicate the instance files shouldn’t be deleted.\n\n-1, never offload\n0, offload when shelved\n> 0, offload using “_poll_shelved_instances” periodic task\n\nNew value will be added\n-2, offload partially, release CPU/Memory but retain instance files\n\nChange-Id: Iedb910e6656cdefd6d668262c7ed0726dbb1475a\nblueprint: improve-unshelve-performance\n'}, {'number': 2, 'created': '2015-04-09 12:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d717c55f4d61cb85d171df530d981a43e1ede3b9', 'message': 'Improve performance of Unshelve api\n\nAim of this feature is to improve the performance of unshelve instance\nby eliminating downloading/copying snapshot time. All instance files will be\nretained in the instance store backed by shared or non-shared storage on the\ncompute node when an instance is shelved.\n\nAn existing configuration parameter ""shelved_offload_time"" will be used here\nto indicate the instance files should not be deleted.\n\nNew value will be added:\nshelved_offload_time = -2\n\nOffload partially. In this case instance files will be retained. CPU and\nMemory will be released back to the hypervisor which can be used for\nspawning new instances.\n\nAdded new VM state \'SHELVED_PARTIAL_OFFLOADED\' and new Task state\n\'SHELVING_PARTIAL_OFFLOADING\', so user can identify by VM status\nthat, instance is partially offloaded and instance files are persisted\non the host.\n\nDocImpact:\nAn existing configuration parameter “shelved_offload_time"" will be modified\nhere to indicate the instance files shouldn’t be deleted.\n\n-1, never offload\n0, offload when shelved\n> 0, offload using “_poll_shelved_instances” periodic task\n\nNew value will be added\n-2, offload partially, release CPU/Memory but retain instance files\n\nChange-Id: Iedb910e6656cdefd6d668262c7ed0726dbb1475a\nblueprint: improve-unshelve-performance\n'}, {'number': 3, 'created': '2015-04-09 13:14:33.000000000', 'files': ['nova/tests/unit/compute/test_rpcapi.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/tests/unit/compute/test_shelve.py', 'nova/compute/task_states.py', 'nova/compute/vm_states.py', 'nova/api/openstack/common.py', 'nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/043c004a7ec00e6a89b067a77c95dd8b3c84361e', 'message': 'Improve performance of Unshelve api\n\nAim of this feature is to improve the performance of unshelve instance\nby eliminating downloading/copying snapshot time. All instance files will be\nretained in the instance store backed by shared or non-shared storage on the\ncompute node when an instance is shelved.\n\nAn existing configuration parameter ""shelved_offload_time"" will be used here\nto indicate the instance files should not be deleted.\n\nNew value will be added:\nshelved_offload_time = -2\n\nOffload partially. In this case instance files will be retained. CPU and\nMemory will be released back to the hypervisor which can be used for\nspawning new instances.\n\nAdded new VM state \'SHELVED_PARTIAL_OFFLOADED\' and new Task state\n\'SHELVING_PARTIAL_OFFLOADING\', so user can identify by VM status\nthat, instance is partially offloaded and instance files are persisted\non the host.\n\nDocImpact:\nAn existing configuration parameter “shelved_offload_time"" will be modified\nhere to indicate the instance files shouldn’t be deleted.\n\n-1, never offload\n0, offload when shelved\n> 0, offload using “_poll_shelved_instances” periodic task\n\nNew value will be added\n-2, offload partially, release CPU/Memory but retain instance files\n\nChange-Id: Iedb910e6656cdefd6d668262c7ed0726dbb1475a\nblueprint: improve-unshelve-performance\n'}]",2,150344,043c004a7ec00e6a89b067a77c95dd8b3c84361e,21,12,3,9303,,,0,"Improve performance of Unshelve api

Aim of this feature is to improve the performance of unshelve instance
by eliminating downloading/copying snapshot time. All instance files will be
retained in the instance store backed by shared or non-shared storage on the
compute node when an instance is shelved.

An existing configuration parameter ""shelved_offload_time"" will be used here
to indicate the instance files should not be deleted.

New value will be added:
shelved_offload_time = -2

Offload partially. In this case instance files will be retained. CPU and
Memory will be released back to the hypervisor which can be used for
spawning new instances.

Added new VM state 'SHELVED_PARTIAL_OFFLOADED' and new Task state
'SHELVING_PARTIAL_OFFLOADING', so user can identify by VM status
that, instance is partially offloaded and instance files are persisted
on the host.

DocImpact:
An existing configuration parameter “shelved_offload_time"" will be modified
here to indicate the instance files shouldn’t be deleted.

-1, never offload
0, offload when shelved
> 0, offload using “_poll_shelved_instances” periodic task

New value will be added
-2, offload partially, release CPU/Memory but retain instance files

Change-Id: Iedb910e6656cdefd6d668262c7ed0726dbb1475a
blueprint: improve-unshelve-performance
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/150344/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_rpcapi.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/tests/unit/compute/test_shelve.py', 'nova/compute/task_states.py', 'nova/compute/vm_states.py', 'nova/api/openstack/common.py', 'nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py']",11,09bdbc7ba3f29155e797694f5a12059073a961f5,bp/improve-unshelve-performance," host = instance.get('host', None) # When instance is partially offloaded, shelved_host is stored in # system_metadata. If instance goes into error state while unshelving # then also shelved_host is present in the system metadata. if not host and instance.vm_state in ( vm_states.SHELVED_PARTIAL_OFFLOADED, vm_states.ERROR): host = instance.system_metadata.get('shelved_host', None) if host: instance.host = host instance.save() vm_states.SHELVED_OFFLOADED, vm_states.SHELVED_PARTIAL_OFFLOADED])", vm_states.SHELVED_OFFLOADED]),460,110
openstack%2Fneutron~master~If6d5e7d836a32e712937734af80c1f6313565118,openstack/neutron,master,If6d5e7d836a32e712937734af80c1f6313565118,Decrease the default DHCP lease time to 8 minutes,ABANDONED,2015-01-27 21:55:29.000000000,2015-05-21 21:29:18.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-27 21:55:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ce84fb3c37e2161f613b653b54438ae9344c78d8', 'message': 'Decrease the default DHCP lease time to 8 minutes\n\nThis patch decreases the default DHCP lease time to 8 minutes.\nThis is to allow VMs to regain connectivity faster after their\nIP address is changed. With the current default, a VM could remain\nunreachable for up to 12 hours if no proactive action is taken\n(e.g. restarting the VM, logging into the console, etc).\n\nCloses-Bug: #1415221\nChange-Id: If6d5e7d836a32e712937734af80c1f6313565118\n'}, {'number': 2, 'created': '2015-01-27 23:15:59.000000000', 'files': ['etc/neutron.conf', 'neutron/common/config.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f67404409b4c49c6380b5f4ee15376a60b06cce', 'message': 'Decrease the default DHCP lease time to 8 minutes\n\nThis patch decreases the default DHCP lease time to 8 minutes.\nThis is to allow VMs to regain connectivity faster after their\nIP address is changed. With the current default, a VM could remain\nunreachable for up to 12 hours if no proactive action is taken\n(e.g. restarting the VM, logging into the console, etc).\n\nDocImpact\n\nCloses-Bug: #1415221\nChange-Id: If6d5e7d836a32e712937734af80c1f6313565118\n'}]",5,150595,5f67404409b4c49c6380b5f4ee15376a60b06cce,39,20,2,7787,,,0,"Decrease the default DHCP lease time to 8 minutes

This patch decreases the default DHCP lease time to 8 minutes.
This is to allow VMs to regain connectivity faster after their
IP address is changed. With the current default, a VM could remain
unreachable for up to 12 hours if no proactive action is taken
(e.g. restarting the VM, logging into the console, etc).

DocImpact

Closes-Bug: #1415221
Change-Id: If6d5e7d836a32e712937734af80c1f6313565118
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/150595/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/neutron.conf', 'neutron/common/config.py', 'neutron/tests/unit/test_linux_dhcp.py']",3,ce84fb3c37e2161f613b653b54438ae9344c78d8,bug/1415221," max_leases=16777216, lease_duration=480,"," max_leases=16777216, lease_duration=86400,",6,3
openstack%2Fpython-neutronclient~master~I32583e5a87fae8a8332172c94adc364dc8188883,openstack/python-neutronclient,master,I32583e5a87fae8a8332172c94adc364dc8188883,Updated help message for router-update command,ABANDONED,2015-01-07 09:19:06.000000000,2015-05-21 21:29:17.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 7293}]","[{'number': 1, 'created': '2015-01-07 09:19:06.000000000', 'files': ['neutronclient/neutron/v2_0/router.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b21efaced8e399ed92cbe5c1829c681b8ec20bfb', 'message': 'Updated help message for router-update command\n\nneutron help router-update was not displaying all the available\noptions (--name and --admin-state-up).\n\nUpdated the help message to display these as well.\n\nChange-Id: I32583e5a87fae8a8332172c94adc364dc8188883\nCloses-bug: #1406794\n'}]",1,145439,b21efaced8e399ed92cbe5c1829c681b8ec20bfb,6,3,1,12030,,,0,"Updated help message for router-update command

neutron help router-update was not displaying all the available
options (--name and --admin-state-up).

Updated the help message to display these as well.

Change-Id: I32583e5a87fae8a8332172c94adc364dc8188883
Closes-bug: #1406794
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/39/145439/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/router.py'],1,b21efaced8e399ed92cbe5c1829c681b8ec20bfb,bug/1406794," def add_known_arguments(self, parser): parser.add_argument( '--name', dest='name', help=_('Updated Name of router.')) parser.add_argument( '--admin-state-up', dest='admin_state', choices=['True', 'False'], help=_('Set admin state to True or False')) def args2body(self, parsed_args): body = {self.resource: {'admin_state_up': parsed_args.admin_state}} neutronV20.update_dict(parsed_args, body[self.resource], ['name']) return body ",,17,0
openstack%2Fneutron~master~I9cfbdc78b4f81270d5e811ef656876d0f6f59cb8,openstack/neutron,master,I9cfbdc78b4f81270d5e811ef656876d0f6f59cb8,ipv6: simplify enable_ipv6_ra,ABANDONED,2015-01-16 22:31:08.000000000,2015-05-21 21:29:16.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 7183}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-16 22:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f23e4916c2a0a8b163bc85e1f30193fe4510b79', 'message': ""ipv6: simplify enable_ipv6_ra\n\n* don't disable radvd in a function called enable_*;\n* assume caller calls the function only if there are some ipv6 ports;\n* explicitly disable radvd from _process_internal_ports() instead of relying on\n  enable_ipv6_ra() to disable (sic!) unused radvd process for us.\n* avoid redundant ip version checks in RA module.\n\nChange-Id: I9cfbdc78b4f81270d5e811ef656876d0f6f59cb8\n""}, {'number': 2, 'created': '2015-01-17 14:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/15e351d1199b303807d4a140736dfb1772ebfa94', 'message': ""ipv6: simplify enable_ipv6_ra\n\n* don't disable radvd in a function called enable_*;\n* assume caller calls the function only if there are some ipv6 ports;\n* explicitly disable radvd from _process_internal_ports() instead of relying on\n  enable_ipv6_ra() to disable (sic!) unused radvd process for us.\n* avoid redundant ip version checks in RA module.\n\nChange-Id: I9cfbdc78b4f81270d5e811ef656876d0f6f59cb8\n""}, {'number': 3, 'created': '2015-01-17 14:28:02.000000000', 'files': ['neutron/agent/linux/ra.py', 'neutron/agent/l3/agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/44c572f66c7b62b9f8d504e7787ffd861ad003d7', 'message': ""ipv6: simplify enable_ipv6_ra\n\n* don't disable radvd in a function called enable_*;\n* assume caller calls the function only if there are some ipv6 ports;\n* explicitly disable radvd from _process_internal_ports() instead of relying on\n  enable_ipv6_ra() to disable (sic!) unused radvd process for us.\n* avoid redundant ip version checks in RA module.\n\nChange-Id: I9cfbdc78b4f81270d5e811ef656876d0f6f59cb8\n""}]",2,148017,44c572f66c7b62b9f8d504e7787ffd861ad003d7,47,21,3,9656,,,0,"ipv6: simplify enable_ipv6_ra

* don't disable radvd in a function called enable_*;
* assume caller calls the function only if there are some ipv6 ports;
* explicitly disable radvd from _process_internal_ports() instead of relying on
  enable_ipv6_ra() to disable (sic!) unused radvd process for us.
* avoid redundant ip version checks in RA module.

Change-Id: I9cfbdc78b4f81270d5e811ef656876d0f6f59cb8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/148017/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/ra.py', 'neutron/agent/l3/agent.py']",2,0f23e4916c2a0a8b163bc85e1f30193fe4510b79,," def _is_ipv6_port(port): return netaddr.IPNetwork(p['subnet']['cidr']).version == 6 new_ipv6_ports = [p for p in new_ports if _is_ipv6_port(p)] old_ipv6_port = any(_is_ipv6_port(p) for p in old_ports) if new_ipv6_ports or old_ipv6_port: ipv6_internal_ports = [p for p in internal_ports if _is_ipv6_port(p)] if ipv6_internal_ports: # (re)configure radvd process ra.enable_ipv6_ra(ri.router_id, ri.ns_name, ipv6_internal_ports, self.get_internal_device_name, self.root_helper) else: # cleanup radvd left from removed IPv6 ports ra.disable_ipv6_ra(ri.router_id, ri.ns_name, self.root_helper)"," new_ipv6_port = False old_ipv6_port = False if (not new_ipv6_port and netaddr.IPNetwork(p['subnet']['cidr']).version == 6): new_ipv6_port = True if (not old_ipv6_port and netaddr.IPNetwork(p['subnet']['cidr']).version == 6): old_ipv6_port = True # Enable RA if new_ipv6_port or old_ipv6_port: ra.enable_ipv6_ra(ri.router_id, ri.ns_name, internal_ports, self.get_internal_device_name, self.root_helper)",34,35
openstack%2Fneutron~master~I5d23e0354d307d7e6d638b34eb0a2084aada297f,openstack/neutron,master,I5d23e0354d307d7e6d638b34eb0a2084aada297f,Change 'Openstack' to 'OpenStack',ABANDONED,2015-02-02 20:24:05.000000000,2015-05-21 21:29:15.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 167}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6620}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-02-02 20:24:05.000000000', 'files': ['neutron/plugins/ml2/drivers/brocade/README.md', 'neutron/agent/ovsdb.py', 'neutron/plugins/brocade/README.md', 'doc/source/devref/development.environment.rst', 'etc/neutron.conf', 'neutron/agent/l3/router_info.py', 'neutron/plugins/vmware/nsxlib/router.py', 'neutron/agent/l3/dvr.py', 'bin/neutron-rootwrap-xen-dom0', 'neutron/agent/l3/dvr_router.py', 'neutron/plugins/common/utils.py', 'neutron/plugins/vmware/nsxlib/l2gateway.py', 'etc/neutron/plugins/cisco/cisco_plugins.ini', 'neutron/agent/l3/ha_router.py', 'doc/source/docbkx/docbkx-example/src/docbkx/example.xml', 'etc/neutron/plugins/ml2/ml2_conf_cisco.ini', 'neutron/agent/linux/ovsdb_vsctl.py', 'neutron/agent/l3/legacy_router.py', 'neutron/plugins/ml2/drivers/cisco/apic/config.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ecdde6353a006fd7fcb96b7ef3048d5225c1803e', 'message': ""Change 'Openstack' to 'OpenStack'\n\nAccording to https://wiki.openstack.org/wiki/Documentation/Conventions\nthe correct wording is 'OpenStack' and not 'Openstack'.\n\nChange-Id: I5d23e0354d307d7e6d638b34eb0a2084aada297f\n""}]",4,152265,ecdde6353a006fd7fcb96b7ef3048d5225c1803e,32,22,1,167,,,0,"Change 'Openstack' to 'OpenStack'

According to https://wiki.openstack.org/wiki/Documentation/Conventions
the correct wording is 'OpenStack' and not 'Openstack'.

Change-Id: I5d23e0354d307d7e6d638b34eb0a2084aada297f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/152265/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/brocade/README.md', 'neutron/agent/ovsdb.py', 'neutron/plugins/brocade/README.md', 'doc/source/devref/development.environment.rst', 'etc/neutron.conf', 'neutron/agent/l3/router_info.py', 'neutron/plugins/vmware/nsxlib/router.py', 'neutron/agent/l3/dvr.py', 'bin/neutron-rootwrap-xen-dom0', 'neutron/agent/l3/dvr_router.py', 'neutron/plugins/common/utils.py', 'neutron/plugins/vmware/nsxlib/l2gateway.py', 'etc/neutron/plugins/cisco/cisco_plugins.ini', 'neutron/agent/l3/ha_router.py', 'doc/source/docbkx/docbkx-example/src/docbkx/example.xml', 'etc/neutron/plugins/ml2/ml2_conf_cisco.ini', 'neutron/agent/linux/ovsdb_vsctl.py', 'neutron/agent/l3/legacy_router.py', 'neutron/plugins/ml2/drivers/cisco/apic/config.py']",19,ecdde6353a006fd7fcb96b7ef3048d5225c1803e,openstack," help=_(""Name for the app profile used for OpenStack"")), help=_(""Name for the vlan namespace to be used for OpenStack"")), help=_(""Range of VLAN's to be used for OpenStack"")),"," help=_(""Name for the app profile used for Openstack"")), help=_(""Name for the vlan namespace to be used for Openstack"")), help=_(""Range of VLAN's to be used for Openstack"")),",31,31
openstack%2Fneutron~master~Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26,openstack/neutron,master,Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26,ML2 Type Driver refactor part 3,ABANDONED,2014-08-18 23:35:36.000000000,2015-05-21 21:29:14.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 107}, {'_account_id': 841}, {'_account_id': 1689}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6558}, {'_account_id': 6659}, {'_account_id': 6694}, {'_account_id': 6698}, {'_account_id': 6854}, {'_account_id': 7018}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8792}, {'_account_id': 9008}, {'_account_id': 9093}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10624}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}, {'_account_id': 14039}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2014-08-18 23:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5bdf4a317f47394844bbafa89e8800acffe815fb', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 2, 'created': '2014-08-18 23:40:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/372b045f864da82cb70c4d8e02e37b096cf7c8c4', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 3, 'created': '2014-08-19 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab1933e985326c4cf431e4e89442ad68a641e009', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 4, 'created': '2014-08-19 17:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e6e126920fc13835f47c0fd772ba083d5ff1949', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 5, 'created': '2014-08-19 17:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b7781a6e23d8c39f365b6af90ff9428844db6675', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 6, 'created': '2014-08-19 17:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dbdfcf8e20f2c5f35d6f0e43f7dcb2a7429fca0c', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 7, 'created': '2014-08-19 21:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1afcaed6c092411c5a1f60b09621e0a292d72c62', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 8, 'created': '2014-08-20 21:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc9765c66c0c54bd31ad6983f2000108c352bb47', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 9, 'created': '2014-08-22 19:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9e9809f05148f23bb28c7ae525c249454c4bfaf2', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 10, 'created': '2014-09-01 02:03:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/998df0b39f99c0a50f25f36e1ebf4017ea0bc4be', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 11, 'created': '2014-09-01 14:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd4225e6c99c814572f8daeb25aa03c4522dd78f', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 12, 'created': '2014-09-01 21:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5973a0694c149d9e9081384f43b14ef72a0e8187', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 13, 'created': '2014-09-02 14:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c106dd77cfc05de6829a3b13d9eb6d88bbdfd42', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 14, 'created': '2014-09-03 14:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8580f892346a25424c7dd5750ae763998391d9f0', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 15, 'created': '2015-01-26 19:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8c559e1d05c8924ad439c83faa1bb1ea0aeb3a9', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 16, 'created': '2015-01-27 19:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78c2b73c7a8b8cdd0f6b0bceb54e8d5b7e792bde', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 17, 'created': '2015-01-27 23:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4124bbce8141a1d42e1acd91bd37f2b4ecf7390a', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 18, 'created': '2015-01-27 23:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/df0a98752f163e076476a6c3d936e6fd5575353e', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}, {'number': 19, 'created': '2015-01-28 03:14:06.000000000', 'files': ['neutron/plugins/ml2/managers.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/plugins/ml2/models.py', 'neutron/plugins/ml2/db.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/db/migration/alembic_migrations/versions/33a3d31845ad_ml2_refactor_for_provider_networks.py', 'neutron/tests/unit/ml2/db/test_ml2_db.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/295b6688dd333198a3e60628a13bc44a48853758', 'message': 'ML2 Type Driver refactor part 3\n\nThis commit builds on top of part 2 to introduce differentiation\nbetween provider and tenant networks.\n\nChange-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26\nImplements: Blueprint ml2-type-driver-refactor\n'}]",44,115151,295b6688dd333198a3e60628a13bc44a48853758,440,48,19,107,,,0,"ML2 Type Driver refactor part 3

This commit builds on top of part 2 to introduce differentiation
between provider and tenant networks.

Change-Id: Ic77ade6b1d1be9af2f3503cc17e869f0e2493e26
Implements: Blueprint ml2-type-driver-refactor
",git fetch https://review.opendev.org/openstack/neutron refs/changes/51/115151/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/managers.py', 'neutron/plugins/ml2/models.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/plugins/ml2/db.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/db/migration/alembic_migrations/versions/33a3d31845ad_ml2_refactor_for_provider_networks.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/plugins/ml2/plugin.py']",8,5bdf4a317f47394844bbafa89e8800acffe815fb,bp/ml2-type-driver-refactor," provider.SEGMENTATION_ID: segment[api.SEGMENTATION_ID], api.PROVIDER_SEGMENT: segment[api.PROVIDER_SEGMENT]} network[api.PROVIDER_SEGMENT] = segment[api.PROVIDER_SEGMENT]", provider.SEGMENTATION_ID: segment[api.SEGMENTATION_ID]},82,7
openstack%2Fneutron~master~Idd8b1688477f72e420df5eab97a836a278f49dec,openstack/neutron,master,Idd8b1688477f72e420df5eab97a836a278f49dec,Detect if iproute2 allows delete namespace,ABANDONED,2014-07-11 12:55:42.000000000,2015-05-21 21:29:12.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5756}, {'_account_id': 6502}, {'_account_id': 6598}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10536}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-07-11 12:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a1f933a1d289c3d8bc2092b125a44a5325d7ad6c', 'message': 'Detect if iproute2 allows delete namespace\n\ncheck if it is safe to delete namespace when config dhcp or router\n_delete_namespaces is True, to disable the config if is not safe to\ndelete\n\nThe check creates 2 test netns and tries to remove one namespace when\nanother one is mounted (i.e busy to sleep). If remove fails, clean up\nthe test by deleting the namespaces when they are not busy anymore\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a\nfailed scenario and 20111117-1ubuntu2.3 for succeed\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 2, 'created': '2014-07-14 18:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c9921960bc8a71d09c36cb56c222655d9faa5d1d', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when they are not busy anymore.\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a\nfailed scenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --iproute_patch or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 3, 'created': '2014-07-15 09:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/32eb8a513edd77dbc780cab6a8d6cbe0adb51cf3', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when they are not busy anymore.\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a\nfailed scenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --iproute_patch or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 4, 'created': '2014-08-12 15:34:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01de6fb9c078dd051ccdf093c51959a02600ffd4', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 5, 'created': '2014-08-25 10:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4f997190b59432bd8dc0802cd1c757a1e64b1f0', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 6, 'created': '2014-08-25 13:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/214299d5e2dfd273d397429acba1590b6c2370fa', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 7, 'created': '2014-08-26 16:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/33f85234836e90deac6a0c98458e4a9998c37d45', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 8, 'created': '2014-10-30 14:12:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/65bbe541f6d85703441a786f4e1c93ea9a18195a', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 9, 'created': '2014-11-13 14:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4d0dcbfda9a7f5942be03fee7596f20e48aa839', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 10, 'created': '2014-11-17 16:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69c105901f3ef1f5962597b1c4d6e4d5f49569b2', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 11, 'created': '2014-11-18 09:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/06d038b8fd4b7add34526ba621d5842ee9f3f57c', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 12, 'created': '2014-11-18 12:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d01a51aac79dca18e0e611c6fa61c9980d7cd2a', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 13, 'created': '2015-01-07 14:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20b8b17bc73c494b88b6b920731d1f475a1e360b', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 14, 'created': '2015-01-08 18:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3f9fdefd384bfa17db63b1725be5c2de565ac24a', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 15, 'created': '2015-01-12 15:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d0da9ea6872dd7045a1236eb8dfa6a1a90ffcae', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 16, 'created': '2015-01-14 14:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a7a610928e09d9e6e927b9668d1dace0c391390', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 17, 'created': '2015-01-15 09:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ca7037f7e365e762f95300211382dcff427baca', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}, {'number': 18, 'created': '2015-02-07 14:44:46.000000000', 'files': ['neutron/cmd/sanity/checks.py', 'neutron/tests/functional/sanity/test_sanity.py', 'etc/neutron/rootwrap.d/sanity.filters', 'neutron/cmd/sanity_check.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/84ae1c4de912153c0cc1262baee72d424807024b', 'message': 'Detect if iproute2 allows delete namespace\n\nsanity check if it is safe to delete namespace when config dhcp or\nrouter_delete_namespaces is enabled. The check creates 2 test netns\nand tries to remove one namespace when another one is mounted (i.e\nbusy to sleep). If remove fails, clean up the test by deleting the\nnamespaces when not sleep.\n\nThis check followed the steps 1,2,7,8 reported by Red Hat to reproduce\nthe issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685\nFor Ubuntu:\nhttps://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981\n\nIntegration tested with iproute version 20111117-1ubuntu2 for a failed\nscenario and 20111117-1ubuntu2.3 for succeed by calling:\nneutron-sanity-check --delete_ip_namespace or\nneutron-sanity-check --config-file /etc/neutron/l3_agent.ini or\nneutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini\n\nChange-Id: Idd8b1688477f72e420df5eab97a836a278f49dec\nCloses-Bug: 1253135\n'}]",76,106365,84ae1c4de912153c0cc1262baee72d424807024b,433,43,18,10536,,,0,"Detect if iproute2 allows delete namespace

sanity check if it is safe to delete namespace when config dhcp or
router_delete_namespaces is enabled. The check creates 2 test netns
and tries to remove one namespace when another one is mounted (i.e
busy to sleep). If remove fails, clean up the test by deleting the
namespaces when not sleep.

This check followed the steps 1,2,7,8 reported by Red Hat to reproduce
the issue https://bugzilla.redhat.com/show_bug.cgi?id=1062685
For Ubuntu:
https://bugs.launchpad.net/ubuntu/+source/iproute/+bug/1238981

Integration tested with iproute version 20111117-1ubuntu2 for a failed
scenario and 20111117-1ubuntu2.3 for succeed by calling:
neutron-sanity-check --delete_ip_namespace or
neutron-sanity-check --config-file /etc/neutron/l3_agent.ini or
neutron-sanity-check --config-file /etc/neutron/dhcp_agent.ini

Change-Id: Idd8b1688477f72e420df5eab97a836a278f49dec
Closes-Bug: 1253135
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/106365/10 && git format-patch -1 --stdout FETCH_HEAD,"['etc/neutron/rootwrap.d/dhcp.filters', 'neutron/agent/dhcp_agent.py', 'neutron/tests/unit/test_linux_ip_lib.py', 'neutron/agent/linux/ip_lib.py', 'neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/tests/unit/test_dhcp_agent.py', 'etc/neutron/rootwrap.d/l3.filters']",8,a1f933a1d289c3d8bc2092b125a44a5325d7ad6c,bug/1253135," # sleep sleep: CommandFilter, sleep, root",,141,0
openstack%2Fneutron~master~I1bfcc90c878ec04796372ad97542c40bec6b2391,openstack/neutron,master,I1bfcc90c878ec04796372ad97542c40bec6b2391,portbinding: introduce dev_group attribute,ABANDONED,2015-01-23 12:43:35.000000000,2015-05-21 21:29:11.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 6509}, {'_account_id': 7249}, {'_account_id': 7535}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11647}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-23 12:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b6d3f78140129ec38693993c5e762beb60e491e1', 'message': ""portbinding: introduce dev_group attribute\n\nAdd a 'binding:dev_group' attribute that allows to\nspecify device group for a port that would be\nused in nova to define VF/PF placement.\n\nChange-Id: I1bfcc90c878ec04796372ad97542c40bec6b2391\n""}, {'number': 2, 'created': '2015-01-23 15:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/52869d59ac009a2a9156a0424696f608a439169a', 'message': ""portbinding: introduce dev_group attribute\n\nAdd a 'binding:dev_group' attribute that allows to\nspecify device group for a port that would be\nused in nova to define VF/PF placement.\n\nNeeded for bp:\nhttps://blueprints.launchpad.net/nova/+spec/libvirt-sriov-nic-bonding\n\nChange-Id: I1bfcc90c878ec04796372ad97542c40bec6b2391\n""}, {'number': 3, 'created': '2015-01-25 12:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e1a13e60534a9f39da5c39f981a8951e5976d651', 'message': ""portbinding: introduce dev_group attribute\n\nAdd a 'binding:dev_group' attribute that allows to\nspecify device group for a port that would be\nused in nova to define VF/PF placement.\n\nNeeded for bp:\nhttps://blueprints.launchpad.net/nova/+spec/libvirt-sriov-nic-bonding\n\nChange-Id: I1bfcc90c878ec04796372ad97542c40bec6b2391\n""}, {'number': 4, 'created': '2015-01-26 13:35:51.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/544212a0e6f9_portbinding_add_dev_group.py', 'neutron/extensions/portbindings.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/plugins/ml2/models.py', 'neutron/tests/unit/_test_extension_portbindings.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/db/portbindings_db.py', 'neutron/plugins/ml2/plugin.py', 'etc/policy.json'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c3f07664ca51b2e37ea5b00f98f47b7b2586e892', 'message': ""portbinding: introduce dev_group attribute\n\nAdd a 'binding:dev_group' attribute that allows to\nspecify device group for a port that would be\nused in nova to define VF/PF placement.\n\nNeeded for bp:\nhttps://blueprints.launchpad.net/nova/+spec/libvirt-sriov-nic-bonding\n\nChange-Id: I1bfcc90c878ec04796372ad97542c40bec6b2391\n""}]",12,149604,c3f07664ca51b2e37ea5b00f98f47b7b2586e892,82,24,4,7535,,,0,"portbinding: introduce dev_group attribute

Add a 'binding:dev_group' attribute that allows to
specify device group for a port that would be
used in nova to define VF/PF placement.

Needed for bp:
https://blueprints.launchpad.net/nova/+spec/libvirt-sriov-nic-bonding

Change-Id: I1bfcc90c878ec04796372ad97542c40bec6b2391
",git fetch https://review.opendev.org/openstack/neutron refs/changes/04/149604/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/544212a0e6f9_portbinding_add_dev_group.py', 'neutron/extensions/portbindings.py', 'neutron/plugins/ml2/models.py', 'neutron/tests/unit/_test_extension_portbindings.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/db/portbindings_db.py', 'etc/policy.json', 'neutron/plugins/ml2/plugin.py']",9,b6d3f78140129ec38693993c5e762beb60e491e1,bp/libvirt-sriov-nic-bonding, dev_group = attrs and attrs.get(portbindings.DEV_GROUP) if (attributes.is_attr_set(dev_group) and binding.dev_group != dev_group): binding.dev_group = dev_group changes = True port[portbindings.DEV_GROUP] = binding.dev_group,,98,1
openstack%2Fneutron~master~Ie34e29d695a15d05de1fe75b7422f75adbb49152,openstack/neutron,master,Ie34e29d695a15d05de1fe75b7422f75adbb49152,get_vm_port_hostid should log PortNotFound Exception,ABANDONED,2015-01-16 01:54:40.000000000,2015-05-21 21:29:10.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 7016}, {'_account_id': 7787}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12076}, {'_account_id': 12683}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-16 01:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/74b644edb6918ca3a0495815053fc4f342b0a9cd', 'message': ""get_vm_port_hostid must call get_port with port_id\n\nWhen there are two or more Neutron Server deployed,\ndelete FloatingIP agent gateway port fails under\ncertain scenarios when a VM port associated with\nfloatingip gets deleted before the the floatingip\nagent gateway port is deleted.\n\nSo when the second process comes in to delete the\nfloatingip agent gateway port, it calls the\nget_vm_port_hostid with a fip['port_id'] that is\nalready been deleted and so PortNotFound exception\nis raised when get_port is called.\n\nThis patch addresses the issue by checking for the\nvalid port_id before it calls the get_port in\nget_vm_port_hostid.\n\nChange-Id: Ie34e29d695a15d05de1fe75b7422f75adbb49152\nCloses-Bug: #1408855\n""}, {'number': 2, 'created': '2015-01-21 16:42:22.000000000', 'files': ['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/db/l3_dvr_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c17689a2b901f10dffa0e8c76452e1de1295dead', 'message': ""get_vm_port_hostid should log PortNotFound Exception\n\nWhen there are two or more Neutron Server deployed,\ndelete FloatingIP agent gateway port fails under\ncertain scenarios when a VM port associated with\nfloatingip gets deleted before the the floatingip\nagent gateway port is deleted.\n\nSo when the second process comes in to delete the\nfloatingip agent gateway port, it calls the\nget_vm_port_hostid with a fip['port_id'] that is\nalready been deleted and so PortNotFound exception\nis raised when get_port is called.\n\nThis patch addresses the issue by checking for the\nvalid port_id before it calls the get_port in\nget_vm_port_hostid and also logs a debug message\nwhen PortNotFound Exception is raised.\n\nChange-Id: Ie34e29d695a15d05de1fe75b7422f75adbb49152\nCloses-Bug: #1408855\n""}]",8,147725,c17689a2b901f10dffa0e8c76452e1de1295dead,48,26,2,7016,,,0,"get_vm_port_hostid should log PortNotFound Exception

When there are two or more Neutron Server deployed,
delete FloatingIP agent gateway port fails under
certain scenarios when a VM port associated with
floatingip gets deleted before the the floatingip
agent gateway port is deleted.

So when the second process comes in to delete the
floatingip agent gateway port, it calls the
get_vm_port_hostid with a fip['port_id'] that is
already been deleted and so PortNotFound exception
is raised when get_port is called.

This patch addresses the issue by checking for the
valid port_id before it calls the get_port in
get_vm_port_hostid and also logs a debug message
when PortNotFound Exception is raised.

Change-Id: Ie34e29d695a15d05de1fe75b7422f75adbb49152
Closes-Bug: #1408855
",git fetch https://review.opendev.org/openstack/neutron refs/changes/25/147725/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/db/l3_dvr_db.py']",2,74b644edb6918ca3a0495815053fc4f342b0a9cd,bug/1408855," if port_id: vm_port_db = port or self._core_plugin.get_port(context, port_id) device_owner = vm_port_db['device_owner'] if vm_port_db else """" if (n_utils.is_dvr_serviced(device_owner) or device_owner == DEVICE_OWNER_AGENT_GW): return vm_port_db[portbindings.HOST_ID]"," vm_port_db = port or self._core_plugin.get_port(context, port_id) device_owner = vm_port_db['device_owner'] if vm_port_db else """" if (n_utils.is_dvr_serviced(device_owner) or device_owner == DEVICE_OWNER_AGENT_GW): return vm_port_db[portbindings.HOST_ID]",25,5
openstack%2Fpython-neutronclient~master~I2b7c25e695e8ee21d8ca587c203da5105b5aa5db,openstack/python-neutronclient,master,I2b7c25e695e8ee21d8ca587c203da5105b5aa5db,OpenContrail IPAM Client and CLI Support,ABANDONED,2014-12-29 05:46:01.000000000,2015-05-21 21:29:09.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 4187}, {'_account_id': 4362}, {'_account_id': 4656}, {'_account_id': 6785}, {'_account_id': 6812}, {'_account_id': 7448}, {'_account_id': 8126}, {'_account_id': 8306}, {'_account_id': 9631}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 10393}, {'_account_id': 12912}, {'_account_id': 13768}]","[{'number': 1, 'created': '2014-12-29 05:46:01.000000000', 'files': ['neutronclient/tests/unit/test_cli20.py', 'neutronclient/v2_0/client.py', 'neutronclient/tests/unit/test_cli20_ipam.py', 'neutronclient/neutron/v2_0/ipam.py', 'neutronclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/fd82a95a531781b3a0a154e542f43cb6c6632866', 'message': 'OpenContrail IPAM Client and CLI Support\n\nChange-Id: I2b7c25e695e8ee21d8ca587c203da5105b5aa5db\nImplements: blueprint opencontrail-ipam-support\n'}]",0,144258,fd82a95a531781b3a0a154e542f43cb6c6632866,12,18,1,9631,,,0,"OpenContrail IPAM Client and CLI Support

Change-Id: I2b7c25e695e8ee21d8ca587c203da5105b5aa5db
Implements: blueprint opencontrail-ipam-support
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/58/144258/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/test_cli20.py', 'neutronclient/v2_0/client.py', 'neutronclient/tests/unit/test_cli20_ipam.py', 'neutronclient/neutron/v2_0/ipam.py', 'neutronclient/shell.py']",5,fd82a95a531781b3a0a154e542f43cb6c6632866,bp/opencontrail-ipam-support,"from neutronclient.neutron.v2_0 import ipam 'contrail-ipam-list': ipam.ListIpam, 'contrail-ipam-show': ipam.ShowIpam, 'contrail-ipam-create': ipam.CreateIpam, 'contrail-ipam-delete': ipam.DeleteIpam, 'contrail-ipam-update': ipam.UpdateIpam,",,219,1
openstack%2Fneutron~master~Id2f694b6ea42d5c605ead89bf993c3e7c0eb9fc8,openstack/neutron,master,Id2f694b6ea42d5c605ead89bf993c3e7c0eb9fc8,Untangle functional test_l3_agent test from unit tests,ABANDONED,2015-01-26 15:39:28.000000000,2015-05-21 21:29:08.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 6788}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-26 15:39:28.000000000', 'files': ['neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/tests/common/l3_helpers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/496630a69415bf4cf0bf0b77b500e8e0e9757523', 'message': 'Untangle functional test_l3_agent test from unit tests\n\nMove the following functions into a new l3_helpers module and reuse those\nfunctions from both types of tests:\n\n- get_ha_interface,\n- prepare_router_data,\n- router_append_interface.\n\nChange-Id: Id2f694b6ea42d5c605ead89bf993c3e7c0eb9fc8\n'}]",0,150062,496630a69415bf4cf0bf0b77b500e8e0e9757523,23,21,1,9656,,,0,"Untangle functional test_l3_agent test from unit tests

Move the following functions into a new l3_helpers module and reuse those
functions from both types of tests:

- get_ha_interface,
- prepare_router_data,
- router_append_interface.

Change-Id: Id2f694b6ea42d5c605ead89bf993c3e7c0eb9fc8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/150062/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/tests/common/l3_helpers.py']",3,496630a69415bf4cf0bf0b77b500e8e0e9757523,split_ra_unit_tests,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import netaddr from neutron.common import constants as l3_constants from neutron.openstack.common import uuidutils _uuid = uuidutils.generate_uuid def router_append_interface(router, count=1, ip_version=4, ra_mode=None, addr_mode=None): if ip_version == 4: ip_pool = '35.4.%i.4' cidr_pool = '35.4.%i.0/24' gw_pool = '35.4.%i.1' elif ip_version == 6: ip_pool = 'fd01:%x::6' cidr_pool = 'fd01:%x::/64' gw_pool = 'fd01:%x::1' else: raise ValueError(""Invalid ip_version: %s"" % ip_version) interfaces = router[l3_constants.INTERFACE_KEY] current = sum( [netaddr.IPNetwork(p['subnet']['cidr']).version == ip_version for p in interfaces]) mac_address = netaddr.EUI('ca:fe:de:ad:be:ef') mac_address.dialect = netaddr.mac_unix for i in range(current, current + count): interfaces.append( {'id': _uuid(), 'network_id': _uuid(), 'admin_state_up': True, 'fixed_ips': [{'ip_address': ip_pool % i, 'subnet_id': _uuid()}], 'mac_address': str(mac_address), 'subnet': {'cidr': cidr_pool % i, 'gateway_ip': gw_pool % i, 'ipv6_ra_mode': ra_mode, 'ipv6_address_mode': addr_mode}}) mac_address.value += 1 def prepare_router_data(ip_version=4, enable_snat=None, num_internal_ports=1, enable_floating_ip=False, enable_ha=False): if ip_version == 4: ip_addr = '19.4.4.4' cidr = '19.4.4.0/24' gateway_ip = '19.4.4.1' elif ip_version == 6: ip_addr = 'fd00::4' cidr = 'fd00::/64' gateway_ip = 'fd00::1' else: raise ValueError(""Invalid ip_version: %s"" % ip_version) router_id = _uuid() ex_gw_port = {'id': _uuid(), 'mac_address': 'ca:fe:de:ad:be:ee', 'network_id': _uuid(), 'fixed_ips': [{'ip_address': ip_addr, 'subnet_id': _uuid()}], 'subnet': {'cidr': cidr, 'gateway_ip': gateway_ip}} router = { 'id': router_id, 'distributed': False, l3_constants.INTERFACE_KEY: [], 'routes': [], 'gw_port': ex_gw_port} if enable_floating_ip: router[l3_constants.FLOATINGIP_KEY] = [{ 'id': _uuid(), 'port_id': _uuid(), 'floating_ip_address': '19.4.4.2', 'fixed_ip_address': '10.0.0.1'}] router_append_interface(router, count=num_internal_ports, ip_version=ip_version) if enable_ha: router['ha'] = True router['ha_vr_id'] = 1 router[l3_constants.HA_INTERFACE_KEY] = get_ha_interface() if enable_snat is not None: router['enable_snat'] = enable_snat return router def get_ha_interface(ip='169.254.192.1', mac='12:34:56:78:2b:5d'): return {'admin_state_up': True, 'device_id': _uuid(), 'device_owner': 'network:router_ha_interface', 'fixed_ips': [{'ip_address': ip, 'subnet_id': _uuid()}], 'id': _uuid(), 'mac_address': mac, 'name': u'L3 HA Admin port 0', 'network_id': _uuid(), 'status': u'ACTIVE', 'subnet': {'cidr': '169.254.192.0/18', 'gateway_ip': '169.254.255.254', 'id': _uuid()}, 'tenant_id': '', 'agent_id': _uuid(), 'agent_host': 'aaa', 'priority': 1} ",,184,162
openstack%2Fneutron~master~Iaff23ef378c0d163b681b54bd80229ea6374fe5b,openstack/neutron,master,Iaff23ef378c0d163b681b54bd80229ea6374fe5b,test_l3_agent: hide L3NATAgent arguments under a helper method,ABANDONED,2015-01-26 15:39:28.000000000,2015-05-21 21:29:06.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-26 15:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f69d9368e8e2943dea965c00cc637f394a634a57', 'message': ""test_l3_agent: hide L3NATAgent arguments under a helper method\n\nIn next patches, I want to define HOSTNAME as a class attribute so that\nit's possible to define it once in a parent class. So as a preparatory\nstep, move manual HOSTNAME argument passes to L3NATAgent under a\nseparate method to avoid additional burden on reviewers.\n\nChange-Id: Iaff23ef378c0d163b681b54bd80229ea6374fe5b\n""}, {'number': 2, 'created': '2015-01-26 15:53:44.000000000', 'files': ['neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d6ecc977014e960f7bef86e7638f1cc742535a1', 'message': ""test_l3_agent: hide L3NATAgent arguments under a helper method\n\nIn next patches, I want to define HOSTNAME as a class attribute so that\nit's possible to define it once in a parent class. So as a preparatory\nstep, move manual HOSTNAME argument passes to L3NATAgent under a\nseparate method to avoid additional burden on reviewers.\n\nChange-Id: Iaff23ef378c0d163b681b54bd80229ea6374fe5b\n""}]",0,150063,7d6ecc977014e960f7bef86e7638f1cc742535a1,47,21,2,9656,,,0,"test_l3_agent: hide L3NATAgent arguments under a helper method

In next patches, I want to define HOSTNAME as a class attribute so that
it's possible to define it once in a parent class. So as a preparatory
step, move manual HOSTNAME argument passes to L3NATAgent under a
separate method to avoid additional burden on reviewers.

Change-Id: Iaff23ef378c0d163b681b54bd80229ea6374fe5b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/150063/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/test_l3_agent.py'],1,f69d9368e8e2943dea965c00cc637f394a634a57,split_ra_unit_tests," def _get_l3_nat_agent(self): return l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() self.assertRaises(SystemExit, self._get_l3_nat_agent) agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() self.assertRaises(SystemExit, self._get_l3_nat_agent) self.assertRaises(SystemExit, self._get_l3_nat_agent) agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() self.assertRaises(messaging.MessagingTimeout, self._get_l3_nat_agent) agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent() agent = self._get_l3_nat_agent()"," agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) self.assertRaises(SystemExit, l3_agent.L3NATAgent, HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) self.assertRaises(SystemExit, l3_agent.L3NATAgent, HOSTNAME, self.conf) self.assertRaises(SystemExit, l3_agent.L3NATAgent, HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) self.assertRaises(messaging.MessagingTimeout, l3_agent.L3NATAgent, HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf)",90,91
openstack%2Fneutron~master~Ia961f41db6884338a49c681664b17624342f2c14,openstack/neutron,master,Ia961f41db6884338a49c681664b17624342f2c14,test_l3_agent: make HOSTNAME a class attribute,ABANDONED,2015-01-26 15:39:28.000000000,2015-05-21 21:29:05.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-26 15:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/658d0989a94b19a9867d0f11aa394de5e0dee13a', 'message': 'test_l3_agent: make HOSTNAME a class attribute\n\nThis is to be able to move HOSTNAME into a parent class in later patch.\n\nChange-Id: Ia961f41db6884338a49c681664b17624342f2c14\n'}, {'number': 2, 'created': '2015-01-26 15:53:44.000000000', 'files': ['neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a33fa287abee28dedefa8cd30cf2ac97a0ceecdc', 'message': 'test_l3_agent: make HOSTNAME a class attribute\n\nThis is to be able to move HOSTNAME into a parent class in later patch.\n\nChange-Id: Ia961f41db6884338a49c681664b17624342f2c14\n'}]",1,150064,a33fa287abee28dedefa8cd30cf2ac97a0ceecdc,43,21,2,9656,,,0,"test_l3_agent: make HOSTNAME a class attribute

This is to be able to move HOSTNAME into a parent class in later patch.

Change-Id: Ia961f41db6884338a49c681664b17624342f2c14
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/150064/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/test_l3_agent.py'],1,658d0989a94b19a9867d0f11aa394de5e0dee13a,split_ra_unit_tests," HOSTNAME = 'myhost' return l3_agent.L3NATAgent(self.HOSTNAME, self.conf) ri.router['gw_port_host'] = self.HOSTNAME agent.host = self.HOSTNAME agent.host = self.HOSTNAME router['gw_port_host'] = self.HOSTNAME router['gw_port_host'] = self.HOSTNAME {'distributed': True, 'gw_port_host': self.HOSTNAME}) agent.host = self.HOSTNAME 'host': self.HOSTNAME}]} 'host': self.HOSTNAME}]} 'host': self.HOSTNAME, agent.host = self.HOSTNAME agent = self._get_l3_nat_agent() 'host': self.HOSTNAME, 'host': self.HOSTNAME, router['gw_port_host'] = self.HOSTNAME","HOSTNAME = 'myhost' return l3_agent.L3NATAgent(HOSTNAME, self.conf) ri.router['gw_port_host'] = HOSTNAME agent.host = HOSTNAME agent.host = HOSTNAME router['gw_port_host'] = HOSTNAME router['gw_port_host'] = HOSTNAME {'distributed': True, 'gw_port_host': HOSTNAME}) agent.host = HOSTNAME 'host': HOSTNAME}]} 'host': HOSTNAME}]} 'host': HOSTNAME, agent.host = HOSTNAME agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) 'host': HOSTNAME, 'host': HOSTNAME, router['gw_port_host'] = HOSTNAME",18,17
openstack%2Fneutron~master~I15354b83f4f85b71af37f223010a9c9f86811a4c,openstack/neutron,master,I15354b83f4f85b71af37f223010a9c9f86811a4c,Moved common code to mock L3 agent into a separate class,ABANDONED,2015-01-26 15:39:28.000000000,2015-05-21 21:29:04.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-26 15:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ebd21965e75cd35db1fd855d5376f486d4bfd09d', 'message': 'Moved common code to mock L3 agent into a separate class\n\nThis code will be reused from all unit tests that want to instantiate\nand process updates for mocked L3 agents.\n\nChange-Id: I15354b83f4f85b71af37f223010a9c9f86811a4c\n'}, {'number': 2, 'created': '2015-01-26 15:53:44.000000000', 'files': ['neutron/tests/unit/test_common/l3_agent_base.py', 'neutron/tests/unit/test_common/__init__.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/31068dd9f6f655ec4470025528021a4b4bdae211', 'message': 'Moved common code to mock L3 agent into a separate class\n\nThis code will be reused from all unit tests that want to instantiate\nand process updates for mocked L3 agents.\n\nChange-Id: I15354b83f4f85b71af37f223010a9c9f86811a4c\n'}]",0,150065,31068dd9f6f655ec4470025528021a4b4bdae211,39,20,2,9656,,,0,"Moved common code to mock L3 agent into a separate class

This code will be reused from all unit tests that want to instantiate
and process updates for mocked L3 agents.

Change-Id: I15354b83f4f85b71af37f223010a9c9f86811a4c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/150065/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/common/l3_agent_base.py', 'neutron/tests/unit/common/__init__.py', 'neutron/tests/unit/test_l3_agent.py']",3,ebd21965e75cd35db1fd855d5376f486d4bfd09d,split_ra_unit_tests,from neutron.tests.unit.common import l3_agent_baseclass TestBasicRouterOperations(l3_agent_base.TestL3RouterBase):,"from neutron.agent.common import config as agent_configfrom neutron.agent.l3 import config as l3_configfrom neutron.agent.l3 import hafrom neutron.common import config as base_configfrom neutron.openstack.common import logfrom neutron.tests import baseclass TestBasicRouterOperations(base.BaseTestCase): HOSTNAME = 'myhost' self.conf = agent_config.setup_conf() self.conf.register_opts(base_config.core_opts) self.conf.register_cli_opts(log.common_cli_opts) self.conf.register_cli_opts(log.logging_cli_opts) self.conf.register_opts(l3_config.OPTS) self.conf.register_opts(ha.OPTS) agent_config.register_interface_driver_opts_helper(self.conf) agent_config.register_use_namespaces_opts_helper(self.conf) agent_config.register_root_helper(self.conf) self.conf.register_opts(interface.OPTS) self.conf.set_override('interface_driver', 'neutron.agent.linux.interface.NullDriver') self.conf.set_override('state_path', '') self.device_exists_p = mock.patch( 'neutron.agent.linux.ip_lib.device_exists') self.device_exists = self.device_exists_p.start() mock.patch('neutron.agent.l3.ha.AgentMixin' '._init_ha_conf_path').start() self.utils_exec_p = mock.patch( 'neutron.agent.linux.utils.execute') self.utils_exec = self.utils_exec_p.start() self.utils_replace_file_p = mock.patch( 'neutron.agent.linux.utils.replace_file') self.utils_replace_file = self.utils_replace_file_p.start() self.l3pluginApi_cls_p = mock.patch( 'neutron.agent.l3.agent.L3PluginApi') l3pluginApi_cls = self.l3pluginApi_cls_p.start() self.plugin_api = mock.MagicMock() l3pluginApi_cls.return_value = self.plugin_api def _get_l3_nat_agent(self): return l3_agent.L3NATAgent(self.HOSTNAME, self.conf) def _process_router_ipv6_interface_added( self, router, ra_mode=None, addr_mode=None): agent = self._get_l3_nat_agent() ri = l3router.RouterInfo(router['id'], self.conf.root_helper, router=router) agent.external_gateway_added = mock.Mock() # Process with NAT agent.process_router(ri) orig_nat_rules = ri.iptables_manager.ipv4['nat'].rules[:] # Add an IPv6 interface and reprocess l3_helpers.router_append_interface(router, count=1, ip_version=6, ra_mode=ra_mode, addr_mode=addr_mode) # Reassign the router object to RouterInfo ri.router = router agent.process_router(ri) # IPv4 NAT rules should not be changed by adding an IPv6 interface nat_rules_delta = [r for r in ri.iptables_manager.ipv4['nat'].rules if r not in orig_nat_rules] self.assertFalse(nat_rules_delta) return ri ",96,67
openstack%2Fneutron~master~I63755735f03827bd65685ebdec7b617a67e9383e,openstack/neutron,master,I63755735f03827bd65685ebdec7b617a67e9383e,tests: moved unit tests for neutron.agent.linux.ra module,ABANDONED,2015-01-26 15:39:28.000000000,2015-05-21 21:29:02.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-26 15:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e337ce18c3069604d1bffaff016bec5a2bcd4f3a', 'message': ""tests: moved unit tests for neutron.agent.linux.ra module\n\nThose tests should be unbound from general L3 agent unit tests to make\nit clear what's covered by tests (not many) and what's not (a lot).\n\nblueprint reorganize-unit-test-tree\n\nChange-Id: I63755735f03827bd65685ebdec7b617a67e9383e\n""}, {'number': 2, 'created': '2015-01-26 15:53:44.000000000', 'files': ['neutron/tests/unit/agent/linux/test_ra.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/573e57d0a3ca28de79e1f0fe23e7b29009e20951', 'message': ""tests: moved unit tests for neutron.agent.linux.ra module\n\nThose tests should be unbound from general L3 agent unit tests to make\nit clear what's covered by tests (not many) and what's not (a lot).\n\nChange-Id: I63755735f03827bd65685ebdec7b617a67e9383e\n""}]",0,150066,573e57d0a3ca28de79e1f0fe23e7b29009e20951,38,20,2,9656,,,0,"tests: moved unit tests for neutron.agent.linux.ra module

Those tests should be unbound from general L3 agent unit tests to make
it clear what's covered by tests (not many) and what's not (a lot).

Change-Id: I63755735f03827bd65685ebdec7b617a67e9383e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/150066/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/linux/test_ra.py', 'neutron/tests/unit/test_l3_agent.py']",2,e337ce18c3069604d1bffaff016bec5a2bcd4f3a,split_ra_unit_tests,,"from neutron.agent.linux import ra def test_spawn_radvd(self): router = l3_helpers.prepare_router_data() conffile = '/fake/radvd.conf' pidfile = '/fake/radvd.pid' agent = self._get_l3_nat_agent() # we don't want the whole process manager to be mocked to be # able to catch execute() calls self.external_process_p.stop() self.ip_cls_p.stop() get_pid_file_name = ('neutron.agent.linux.external_process.' 'ProcessManager.get_pid_file_name') with mock.patch('neutron.agent.linux.utils.execute') as execute: with mock.patch(get_pid_file_name) as get_pid: get_pid.return_value = pidfile ra._spawn_radvd(router['id'], conffile, agent.get_ns_name(router['id']), self.conf.root_helper) cmd = execute.call_args[0][0] self.assertIn('radvd', cmd) _join = lambda *args: ' '.join(args) cmd = _join(*cmd) self.assertIn(_join('-C', conffile), cmd) self.assertIn(_join('-p', pidfile), cmd) self.assertIn(_join('-m', 'syslog'), cmd) def test_generate_radvd_conf_other_flag(self): # we don't check other flag for stateful since it's redundant # for this mode and can be ignored by clients, as per RFC4861 expected = {l3_constants.IPV6_SLAAC: False, l3_constants.DHCPV6_STATELESS: True} for ra_mode, flag_set in expected.iteritems(): router = l3_helpers.prepare_router_data() ri = self._process_router_ipv6_interface_added(router, ra_mode=ra_mode) ra._generate_radvd_conf(ri.router['id'], router[l3_constants.INTERFACE_KEY], mock.Mock()) asserter = self.assertIn if flag_set else self.assertNotIn asserter('AdvOtherConfigFlag on;', self.utils_replace_file.call_args[0][1]) ",67,51
openstack%2Fneutron-fwaas~master~I824b2f5d1b95549df7225e23dbcc718290ecd71d,openstack/neutron-fwaas,master,I824b2f5d1b95549df7225e23dbcc718290ecd71d,Change to the new force_apply call,ABANDONED,2015-02-24 21:03:51.000000000,2015-05-21 21:29:01.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 7448}, {'_account_id': 10387}, {'_account_id': 12525}]","[{'number': 1, 'created': '2015-02-24 21:03:51.000000000', 'files': ['neutron_fwaas/services/firewall/drivers/linux/iptables_fwaas.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/4aeb2578790adb575da44c579f6f46ee3ed83530', 'message': 'Change to the new force_apply call\n\nChange-Id: I824b2f5d1b95549df7225e23dbcc718290ecd71d\nDepends-On: I024e15a265c3e112a89ce91fe0f5564fb40528a2\n'}]",0,158865,4aeb2578790adb575da44c579f6f46ee3ed83530,6,5,1,7448,,,0,"Change to the new force_apply call

Change-Id: I824b2f5d1b95549df7225e23dbcc718290ecd71d
Depends-On: I024e15a265c3e112a89ce91fe0f5564fb40528a2
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/65/158865/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_fwaas/services/firewall/drivers/linux/iptables_fwaas.py'],1,4aeb2578790adb575da44c579f6f46ee3ed83530,157557, ipt_mgr.force_apply() ipt_mgr.force_apply() ipt_mgr.force_apply(), ipt_mgr.defer_apply_off() ipt_mgr.defer_apply_off() ipt_mgr.defer_apply_off(),3,3
openstack%2Fneutron~master~Iac07098fbf09c560ca1b511858f768d3eb87352f,openstack/neutron,master,Iac07098fbf09c560ca1b511858f768d3eb87352f,pep8: validate neutron-rootwrap-xen-dom0,ABANDONED,2015-01-21 15:58:39.000000000,2015-05-21 21:29:00.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 5044}, {'_account_id': 5170}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 12643}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-21 15:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5b992229ecfe52514fc65ecb1b038e25b2a9712', 'message': 'pep8: validate neutron-rootwrap-xen-dom0\n\nMove the code into .py file so that flake8 validates it.\n\nThis move requires some changes to pass pep8 checks. Specifically,\n- some whitespacing and line wrapping rules to apply,\n- adopt oslo.serialization.jsonutils instead of json.\n\nProvide executable via console_scripts entry instead of\nbin/neutron-rootwrap-xen-dom0.\n\nChange-Id: Iac07098fbf09c560ca1b511858f768d3eb87352f\n'}, {'number': 2, 'created': '2015-01-21 16:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/defc7829cc9192f591bb5685b51f5f2ed5bf28cf', 'message': 'pep8: validate neutron-rootwrap-xen-dom0\n\nMove the code into .py file so that flake8 validates it.\n\nThis move requires some changes to pass pep8 checks. Specifically,\n- some whitespacing and line wrapping rules to apply,\n- adopt oslo.serialization.jsonutils instead of json.\n\nProvide executable via console_scripts entry instead of\nbin/neutron-rootwrap-xen-dom0.\n\nChange-Id: Iac07098fbf09c560ca1b511858f768d3eb87352f\n'}, {'number': 3, 'created': '2015-01-21 16:03:30.000000000', 'files': ['neutron/cmd/neutron_rootwrap_xen_dom0.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d49f4ad9538d16b03f349c59da9a3210cf66b20e', 'message': 'pep8: validate neutron-rootwrap-xen-dom0\n\nMove the code into .py file so that flake8 validates it.\n\nThis move requires some changes to pass pep8 checks. Specifically,\n- some whitespacing and line wrapping rules to apply,\n- adopt oslo.serialization.jsonutils instead of json.\n\nProvide executable via console_scripts entry instead of\nbin/neutron-rootwrap-xen-dom0.\n\nChange-Id: Iac07098fbf09c560ca1b511858f768d3eb87352f\n'}]",0,148969,d49f4ad9538d16b03f349c59da9a3210cf66b20e,46,24,3,9656,,,0,"pep8: validate neutron-rootwrap-xen-dom0

Move the code into .py file so that flake8 validates it.

This move requires some changes to pass pep8 checks. Specifically,
- some whitespacing and line wrapping rules to apply,
- adopt oslo.serialization.jsonutils instead of json.

Provide executable via console_scripts entry instead of
bin/neutron-rootwrap-xen-dom0.

Change-Id: Iac07098fbf09c560ca1b511858f768d3eb87352f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/69/148969/2 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'bin/neutron-rootwrap-xen-dom0']",2,b5b992229ecfe52514fc65ecb1b038e25b2a9712,tox,,"#!/usr/bin/env python # Copyright (c) 2012 Openstack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Neutron root wrapper for dom0. Executes networking commands in dom0. The XenAPI plugin is responsible determining whether a command is safe to execute. """""" from __future__ import print_function import ConfigParser import json import os import select import sys import traceback import XenAPI RC_UNAUTHORIZED = 99 RC_NOCOMMAND = 98 RC_BADCONFIG = 97 RC_XENAPI_ERROR = 96 def parse_args(): # Split arguments, require at least a command exec_name = sys.argv.pop(0) # argv[0] required; path to conf file if len(sys.argv) < 2: print(""%s: No command specified"" % exec_name) sys.exit(RC_NOCOMMAND) config_file = sys.argv.pop(0) user_args = sys.argv[:] return exec_name, config_file, user_args def _xenapi_section_name(config): sections = [sect for sect in config.sections() if sect.lower() == ""xenapi""] if len(sections) == 1: return sections[0] print(""Multiple [xenapi] sections or no [xenapi] section found!"") sys.exit(RC_BADCONFIG) def load_configuration(exec_name, config_file): config = ConfigParser.RawConfigParser() config.read(config_file) try: exec_dirs = config.get(""DEFAULT"", ""exec_dirs"").split("","") filters_path = config.get(""DEFAULT"", ""filters_path"").split("","") section = _xenapi_section_name(config) url = config.get(section, ""xenapi_connection_url"") username = config.get(section, ""xenapi_connection_username"") password = config.get(section, ""xenapi_connection_password"") except ConfigParser.Error: print(""%s: Incorrect configuration file: %s"" % (exec_name, config_file)) sys.exit(RC_BADCONFIG) if not url or not password: msg = (""%s: Must specify xenapi_connection_url, "" ""xenapi_connection_username (optionally), and "" ""xenapi_connection_password in %s"") % (exec_name, config_file) print(msg) sys.exit(RC_BADCONFIG) return dict( filters_path=filters_path, url=url, username=username, password=password, exec_dirs=exec_dirs, ) def filter_command(exec_name, filters_path, user_args, exec_dirs): # Add ../ to sys.path to allow running from branch possible_topdir = os.path.normpath(os.path.join(os.path.abspath(exec_name), os.pardir, os.pardir)) if os.path.exists(os.path.join(possible_topdir, ""neutron"", ""__init__.py"")): sys.path.insert(0, possible_topdir) from oslo.rootwrap import wrapper # Execute command if it matches any of the loaded filters filters = wrapper.load_filters(filters_path) filter_match = wrapper.match_filter( filters, user_args, exec_dirs=exec_dirs) if not filter_match: print(""Unauthorized command: %s"" % ' '.join(user_args)) sys.exit(RC_UNAUTHORIZED) def run_command(url, username, password, user_args, cmd_input): try: session = XenAPI.Session(url) session.login_with_password(username, password) host = session.xenapi.session.get_this_host(session.handle) result = session.xenapi.host.call_plugin( host, 'netwrap', 'run_command', {'cmd': json.dumps(user_args), 'cmd_input': json.dumps(cmd_input)}) return json.loads(result) except Exception as e: traceback.print_exc() sys.exit(RC_XENAPI_ERROR) def main(): exec_name, config_file, user_args = parse_args() config = load_configuration(exec_name, config_file) filter_command(exec_name, config['filters_path'], user_args, config['exec_dirs']) # If data is available on the standard input, we need to pass it to the # command executed in dom0 cmd_input = None if select.select([sys.stdin,],[],[],0.0)[0]: cmd_input = """".join(sys.stdin) return run_command(config['url'], config['username'], config['password'], user_args, cmd_input) if __name__ == '__main__': print(main()) ",1,142
openstack%2Fneutron~master~I261fe26335e9bc94ec3a87c70bb3c2add32d01e4,openstack/neutron,master,I261fe26335e9bc94ec3a87c70bb3c2add32d01e4,Return false for empty subnet_ids,ABANDONED,2015-02-04 10:09:16.000000000,2015-05-21 21:28:59.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6788}, {'_account_id': 9681}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 12076}, {'_account_id': 12683}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-02-04 10:09:16.000000000', 'files': ['neutron/tests/unit/test_l3_schedulers.py', 'neutron/db/l3_agentschedulers_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/246b64c643778e9c50b16f768c7ce7d69fc4d213', 'message': ""Return false for empty subnet_ids\n\ncheck_ports_exist_on_l3agent checks if there exists one port whose\nbinding host is the same as the input l3 agent, and whose subnet is\nattached to the input router. But if subnet_ids returned by\nget_subnet_ids_on_router is empty, get_ports will return all the\nports since filter with empty 'subnet_id' is ignored in get_ports.\nWith empty subnet_ids, check_ports_exist_on_l3agent should just\nreturn false instead.\n\nChange-Id: I261fe26335e9bc94ec3a87c70bb3c2add32d01e4\nCloses-Bug: #1417908\n""}]",8,152845,246b64c643778e9c50b16f768c7ce7d69fc4d213,25,19,1,12076,,,0,"Return false for empty subnet_ids

check_ports_exist_on_l3agent checks if there exists one port whose
binding host is the same as the input l3 agent, and whose subnet is
attached to the input router. But if subnet_ids returned by
get_subnet_ids_on_router is empty, get_ports will return all the
ports since filter with empty 'subnet_id' is ignored in get_ports.
With empty subnet_ids, check_ports_exist_on_l3agent should just
return false instead.

Change-Id: I261fe26335e9bc94ec3a87c70bb3c2add32d01e4
Closes-Bug: #1417908
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/152845/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_l3_schedulers.py', 'neutron/db/l3_agentschedulers_db.py']",2,246b64c643778e9c50b16f768c7ce7d69fc4d213,bug/1417908, if not subnet_ids: return False,,3,1
openstack%2Fneutron~master~Ia25cdca1deb4b99989b8e79d70dc2866624d12e2,openstack/neutron,master,Ia25cdca1deb4b99989b8e79d70dc2866624d12e2,ML2 Mechanism Driver for SeaMicro,ABANDONED,2015-03-03 06:26:30.000000000,2015-05-21 21:28:58.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10984}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}]","[{'number': 1, 'created': '2015-03-03 06:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/41b43581813210c3ad2e7b686b8a14dd9cd63c11', 'message': 'ML2 Mechanism Driver for SeaMicro\n\nAdd support for SeaMicro chassis in OpenStack neutron as a\nML2 mechanism driver.\n\nImplements blueprint seamicro-mechanism-driver\n\nChange-Id: Ia25cdca1deb4b99989b8e79d70dc2866624d12e2\n'}, {'number': 2, 'created': '2015-03-03 07:00:17.000000000', 'files': ['neutron/plugins/ml2/drivers/seamicro/driver.py', 'neutron/plugins/ml2/drivers/seamicro/__init__.py', 'etc/neutron/plugins/ml2/ml2_conf_seamicro.ini', 'neutron/db/migration/alembic_migrations/versions/1605b6b38302_seamicro_ml2_mech_dri.py', 'neutron/tests/unit/ml2/test_machanism_seamicro.py', 'setup.cfg', 'neutron/plugins/ml2/drivers/seamicro/requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b129e2dc57cc82c26bf8b31f4c91bb930e5a2f31', 'message': 'ML2 Mechanism Driver for SeaMicro\n\nAdd support for SeaMicro chassis in OpenStack neutron as a\nML2 mechanism driver.\n\nImplements blueprint seamicro-mechanism-driver\n\nChange-Id: Ia25cdca1deb4b99989b8e79d70dc2866624d12e2\n'}]",3,160660,b129e2dc57cc82c26bf8b31f4c91bb930e5a2f31,43,20,2,10984,,,0,"ML2 Mechanism Driver for SeaMicro

Add support for SeaMicro chassis in OpenStack neutron as a
ML2 mechanism driver.

Implements blueprint seamicro-mechanism-driver

Change-Id: Ia25cdca1deb4b99989b8e79d70dc2866624d12e2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/160660/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/seamicro/driver.py', 'neutron/plugins/ml2/drivers/seamicro/__init__.py', 'etc/neutron/plugins/ml2/ml2_conf_seamicro.ini', 'neutron/db/migration/alembic_migrations/versions/1605b6b38302_seamicro_ml2_mech_dri.py', 'neutron/tests/unit/ml2/test_machanism_seamicro.py', 'setup.cfg', 'neutron/plugins/ml2/drivers/seamicro/requirements.txt']",7,41b43581813210c3ad2e7b686b8a14dd9cd63c11,bp/seamicro-mechanism-driver,seamicro-ml2 ,,429,0
openstack%2Fneutron-fwaas~master~If83044f3790b307e5fdbd91d90c598b30c8f4174,openstack/neutron-fwaas,master,If83044f3790b307e5fdbd91d90c598b30c8f4174,Restart l3 agent services leads to firewall error,ABANDONED,2014-12-15 06:52:53.000000000,2015-05-21 21:28:54.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 6659}, {'_account_id': 10387}, {'_account_id': 11822}, {'_account_id': 12525}, {'_account_id': 12683}]","[{'number': 1, 'created': '2014-12-15 06:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/31eac6f0607b399702d28a5119a87da9436d7ba8', 'message': ""when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.\n\n   step:\n   1. Create network and router in A and B tenant.\n   2. Create a firewall in A tenant.\n   3. Restart vpn and l3 agent serivce.\n   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn\nThen I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.\nCloses-Bug: #1398267\n\nChange-Id: If83044f3790b307e5fdbd91d90c598b30c8f4174\n""}, {'number': 2, 'created': '2014-12-15 06:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/8bb675087d0b3a89d33193ae2e4ed75bde57c57a', 'message': ""when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.\n\n   step:\n   1. Create network and router in A and B tenant.\n   2. Create a firewall in A tenant.\n   3. Restart vpn and l3 agent serivce.\n   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn\nThen I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.\n\nCloses-Bug: #1398267\nChange-Id: If83044f3790b307e5fdbd91d90c598b30c8f4174\n""}, {'number': 3, 'created': '2014-12-15 13:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/02628be0837a6934399590ea2bed880dd989806a', 'message': ""when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.\n\n   step:\n   1. Create network and router in A and B tenant.\n   2. Create a firewall in A tenant.\n   3. Restart vpn and l3 agent serivce.\n   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn\nThen I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.\n\nCloses-Bug: #1398267\nChange-Id: If83044f3790b307e5fdbd91d90c598b30c8f4174\n""}, {'number': 4, 'created': '2014-12-16 07:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/f76d5b84fb2a0f61cf251d5fefc06514d5d8368b', 'message': ""Restart l3 agent services leads to firewall error.\n\nwhen restart the vpn and l3 agent, the firewall rule apply to all tenants' router.\n   step:\n   1. Create network and router in A and B tenant.\n   2. Create a firewall in A tenant.\n   3. Restart vpn and l3 agent serivce.\n   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn\nThen I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.\n\nCloses-Bug: #1398267\nChange-Id: If83044f3790b307e5fdbd91d90c598b30c8f4174\n""}, {'number': 5, 'created': '2014-12-16 09:45:24.000000000', 'files': ['neutron_fwaas/services/firewall/agents/l3reference/firewall_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/f288aaa3e9cede172e42a43b904ba33adeee5a93', 'message': ""Restart l3 agent services leads to firewall error\n\nwhen restart the vpn and l3 agent, the firewall rule apply to all tenants' router.\n   step:\n   1. Create network and router in A and B tenant.\n   2. Create a firewall in A tenant.\n   3. Restart vpn and l3 agent serivce.\n   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn\nThen I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.\n\nCloses-Bug: #1398267\nChange-Id: If83044f3790b307e5fdbd91d90c598b30c8f4174\n""}]",9,141734,f288aaa3e9cede172e42a43b904ba33adeee5a93,25,8,5,14203,,,0,"Restart l3 agent services leads to firewall error

when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.
   step:
   1. Create network and router in A and B tenant.
   2. Create a firewall in A tenant.
   3. Restart vpn and l3 agent serivce.
   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn
Then I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.

Closes-Bug: #1398267
Change-Id: If83044f3790b307e5fdbd91d90c598b30c8f4174
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/34/141734/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron_fwaas/services/firewall/agents/l3reference/firewall_l3_agent.py'],1,31eac6f0607b399702d28a5119a87da9436d7ba8,bug/1398267," if fw['tenant_id'] == ri.router['tenant_id']: self._invoke_driver_for_sync_from_plugin( ctx, router_info_list, fw)"," self._invoke_driver_for_sync_from_plugin( ctx, router_info_list, fw)",5,4
openstack%2Fneutron~master~I136acd6bd1ca4e3958276409726196e330f81a1a,openstack/neutron,master,I136acd6bd1ca4e3958276409726196e330f81a1a,Add basic functional test for DVR migrate case,ABANDONED,2015-03-09 10:40:00.000000000,2015-05-21 21:28:53.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 7183}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-03-09 10:40:00.000000000', 'files': ['neutron/agent/l3/router_info.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3857df419f4878c5c160770e8d1162ef1134fa82', 'message': 'Add basic functional test for DVR migrate case\n\nSupports and depends on:\nhttps://review.openstack.org/#/c/151181/\nhttps://review.openstack.org/#/c/162117/\n\nChange-Id: I136acd6bd1ca4e3958276409726196e330f81a1a\n'}]",0,162596,3857df419f4878c5c160770e8d1162ef1134fa82,23,23,1,13667,,,0,"Add basic functional test for DVR migrate case

Supports and depends on:
https://review.openstack.org/#/c/151181/
https://review.openstack.org/#/c/162117/

Change-Id: I136acd6bd1ca4e3958276409726196e330f81a1a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/96/162596/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/router_info.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/unit/test_l3_agent.py']",3,3857df419f4878c5c160770e8d1162ef1134fa82,dvr-migrate-functional-test," floating_ip_host=None, enable_ha=False, 'gateway_ip': gateway_ip}, 'binding:host_id': floating_ip_host} if floating_ip_host: 'fixed_ip_address': '10.0.0.1', 'host': floating_ip_host}]"," enable_floating_ip=False, enable_ha=False, 'gateway_ip': gateway_ip}} if enable_floating_ip: 'fixed_ip_address': '10.0.0.1'}]",92,18
openstack%2Fneutron~master~Ic14699985dc1dafc4c948f83cb482c5db26117b2,openstack/neutron,master,Ic14699985dc1dafc4c948f83cb482c5db26117b2,Enable pylint on tests subdir,ABANDONED,2015-03-06 00:29:44.000000000,2015-05-21 21:28:52.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 11279}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-03-06 00:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0521cab2143b455462f17b2487dd84b761d2c876', 'message': 'Enable pylint on tests subdir\n\nChange-Id: Ic14699985dc1dafc4c948f83cb482c5db26117b2\n'}, {'number': 2, 'created': '2015-03-06 14:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/accae3f3c5088d653d091a89b8832e529dbc0151', 'message': 'Enable pylint on tests subdir\n\nChange-Id: Ic14699985dc1dafc4c948f83cb482c5db26117b2\n'}, {'number': 3, 'created': '2015-03-06 15:22:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/564cfda608ce0892d4e32264dcb15a64a53b4eb7', 'message': 'Enable pylint on tests subdir\n\nChange-Id: Ic14699985dc1dafc4c948f83cb482c5db26117b2\n'}, {'number': 4, 'created': '2015-03-06 19:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f03bd6244c3562819f0b6e93b33584a3ac8b844d', 'message': 'Enable pylint on tests subdir\n\nChange-Id: Ic14699985dc1dafc4c948f83cb482c5db26117b2\n'}, {'number': 5, 'created': '2015-03-06 19:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c083119c27c34419849db6a80bb2cd92b12ed783', 'message': 'Enable pylint on tests subdir\n\nChange-Id: Ic14699985dc1dafc4c948f83cb482c5db26117b2\n'}, {'number': 6, 'created': '2015-03-09 13:40:40.000000000', 'files': ['neutron/tests/unit/agent/linux/test_async_process.py', '.pylintrc', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/tests/unit/test_extensions.py', 'neutron/tests/unit/test_security_groups_rpc.py', 'neutron/tests/unit/test_extension_extraroute.py', 'neutron/tests/unit/test_wsgi.py', 'neutron/tests/unit/agent/linux/test_ip_monitor.py', 'neutron/tests/unit/extension_stubs.py', 'neutron/tests/unit/linuxbridge/test_lb_neutron_agent.py', 'neutron/tests/unit/api/rpc/agentnotifiers/test_dhcp_rpc_agent_api.py', 'neutron/tests/unit/nec/test_ofc_manager.py', 'neutron/tests/unit/ml2/drivers/freescale/test_mechanism_fslsdn.py', 'neutron/tests/unit/test_l3_schedulers.py', 'neutron/tests/unit/test_linux_ip_lib.py', 'neutron/tests/functional/db/test_migrations.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/unit/db/test_agent_db.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/tests/api/test_v2_rest.py', 'neutron/tests/unit/services/metering/test_metering_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/12c1b16fbc835a23d1f76d0660b6eba1bc7db2f4', 'message': 'Enable pylint on tests subdir\n\nChange-Id: Ic14699985dc1dafc4c948f83cb482c5db26117b2\n'}]",5,161959,12c1b16fbc835a23d1f76d0660b6eba1bc7db2f4,102,28,6,8873,,,0,"Enable pylint on tests subdir

Change-Id: Ic14699985dc1dafc4c948f83cb482c5db26117b2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/161959/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/linux/test_async_process.py', '.pylintrc', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/tests/unit/test_extensions.py', 'neutron/tests/unit/test_security_groups_rpc.py', 'neutron/tests/unit/test_extension_extraroute.py', 'neutron/tests/unit/test_wsgi.py', 'neutron/tests/unit/agent/linux/test_ip_monitor.py', 'neutron/tests/unit/extension_stubs.py', 'neutron/tests/unit/linuxbridge/test_lb_neutron_agent.py', 'neutron/tests/unit/api/rpc/agentnotifiers/test_dhcp_rpc_agent_api.py', 'neutron/tests/unit/bigswitch/fake_server.py', 'neutron/tests/unit/nec/test_ofc_manager.py', 'neutron/tests/unit/ml2/drivers/freescale/test_mechanism_fslsdn.py', 'neutron/tests/unit/test_l3_schedulers.py', 'neutron/tests/unit/test_linux_ip_lib.py', 'neutron/tests/unit/bigswitch/test_router_db.py', 'neutron/tests/functional/db/test_migrations.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/unit/db/test_agent_db.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/tests/api/test_v2_rest.py', 'neutron/tests/unit/services/metering/test_metering_agent.py']",23,0521cab2143b455462f17b2487dd84b761d2c876,pylint_tests," l3_meter_notification = next(n for n in fake_notifier.NOTIFICATIONS if n['event_type'] == 'l3.meter') self.assertEqual(l3_meter_notification['event_type'], 'l3.meter') payload = l3_meter_notification['payload']"," self.assertNotEqual(len(fake_notifier.NOTIFICATIONS), 0) for n in fake_notifier.NOTIFICATIONS: if n['event_type'] == 'l3.meter': break self.assertEqual(n['event_type'], 'l3.meter') payload = n['payload']",71,81
openstack%2Fneutron~master~Ie0ad9dcbaa99f5ca3200c62690efe4bd2c406e38,openstack/neutron,master,Ie0ad9dcbaa99f5ca3200c62690efe4bd2c406e38,Move pylint dep from tox to test-requirements,ABANDONED,2015-03-11 16:11:32.000000000,2015-05-21 21:28:50.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6854}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14535}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-03-11 16:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7039fbcd1f6c90e8c46bb499e659d4ba4a2761de', 'message': 'Move pylint dep from tox to test-requirements\n\nChange-Id: Ie0ad9dcbaa99f5ca3200c62690efe4bd2c406e38\n'}, {'number': 2, 'created': '2015-03-11 16:12:12.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f52783cabfef95069bb2018c85936248854f74a', 'message': 'Move pylint dep from tox to test-requirements\n\nDepends-on: I7c2464285ffc618620bd3fd094e0cb0199979976\nChange-Id: Ie0ad9dcbaa99f5ca3200c62690efe4bd2c406e38\n'}]",0,163510,8f52783cabfef95069bb2018c85936248854f74a,33,23,2,8873,,,0,"Move pylint dep from tox to test-requirements

Depends-on: I7c2464285ffc618620bd3fd094e0cb0199979976
Change-Id: Ie0ad9dcbaa99f5ca3200c62690efe4bd2c406e38
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/163510/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,7039fbcd1f6c90e8c46bb499e659d4ba4a2761de,pin_pylint,,deps = {[testenv]deps} pylint,1,3
openstack%2Fneutron~master~I024e15a265c3e112a89ce91fe0f5564fb40528a2,openstack/neutron,master,I024e15a265c3e112a89ce91fe0f5564fb40528a2,Eliminate defer_apply_on/off in iptables manager,ABANDONED,2015-02-24 21:02:37.000000000,2015-05-21 21:28:48.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-02-24 21:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/926b96abb20fddea8d22bfddcda42a7baac400b6', 'message': 'Eliminate defer_apply_on/off in iptables manager\n\nGo all in with the context manager based implementation for deferring\napplication of iptables rules to discourage use of them which can lead to\nassymmetrical usage.  For firewall, since _on/_off are in the interface, use\n__enter__ and __exit__ methods explicitly.\n\nChange-Id: I024e15a265c3e112a89ce91fe0f5564fb40528a2\nNeeded-By: ????\n'}, {'number': 2, 'created': '2015-02-24 21:04:24.000000000', 'files': ['neutron/agent/linux/iptables_firewall.py', 'neutron/agent/linux/iptables_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9da01ebb6f1f276d4186b175fb4117a549c57d7c', 'message': 'Eliminate defer_apply_on/off in iptables manager\n\nGo all in with the context manager based implementation for deferring\napplication of iptables rules to discourage use of them which can lead to\nassymmetrical usage.  For firewall, since _on/_off are in the interface, use\n__enter__ and __exit__ methods explicitly.\n\nChange-Id: I024e15a265c3e112a89ce91fe0f5564fb40528a2\nNeeded-By: I824b2f5d1b95549df7225e23dbcc718290ecd71d\n'}]",6,158863,9da01ebb6f1f276d4186b175fb4117a549c57d7c,38,22,2,7448,,,0,"Eliminate defer_apply_on/off in iptables manager

Go all in with the context manager based implementation for deferring
application of iptables rules to discourage use of them which can lead to
assymmetrical usage.  For firewall, since _on/_off are in the interface, use
__enter__ and __exit__ methods explicitly.

Change-Id: I024e15a265c3e112a89ce91fe0f5564fb40528a2
Needed-By: I824b2f5d1b95549df7225e23dbcc718290ecd71d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/158863/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/iptables_firewall.py', 'neutron/agent/linux/iptables_manager.py']",2,926b96abb20fddea8d22bfddcda42a7baac400b6,, self.iptables_apply_deferred = 0 self.iptables_apply_deferred += 1 self.iptables_apply_deferred -= 1 try: self.apply() self.force_apply() def force_apply(self):, self.iptables_apply_deferred = False self.defer_apply_on() try: self.defer_apply_off() def defer_apply_on(self): self.iptables_apply_deferred = True def defer_apply_off(self): self.iptables_apply_deferred = False self._apply() self._apply() def _apply(self):,11,17
openstack%2Fneutron~master~Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c,openstack/neutron,master,Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c,Prevent race conditions on DVR FIP resources,ABANDONED,2015-02-05 23:28:40.000000000,2015-05-21 21:28:46.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6620}, {'_account_id': 6876}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 8873}, {'_account_id': 9077}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 12040}, {'_account_id': 13770}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-02-05 23:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e8fda051fa7ee7614ca95c16ab42bf5f0f4911be', 'message': 'WIP: adding logging and evaluating a change\n\nWIP not ready for review\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\n'}, {'number': 2, 'created': '2015-02-06 17:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f5bc3557645c42347fea7851b7c471e1a92436b', 'message': 'WIP: adding logging and evaluating a change\n\nWIP not ready for review\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 3, 'created': '2015-02-10 20:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa0d13ae74ac279db48e6b3600642f1b2efb5e75', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 4, 'created': '2015-02-10 21:23:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/312254e6f9355ba6d6d7a82582005d75e8e03501', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 5, 'created': '2015-02-10 23:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39edcde41d66f4c45a418bb26dff6c1fb5b591d6', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 6, 'created': '2015-02-12 19:09:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0b2fa5d902e4f79ccf676b980775a789e5252cac', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 7, 'created': '2015-02-17 21:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9c188a7e0668e4abb45ba55955309e64762f0d2', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 8, 'created': '2015-02-24 01:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0994d59d8a19581a0d632bf18dbf197abfc947e6', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 9, 'created': '2015-02-25 06:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a3ee35ec19c4c41a6d6473327a8ba50cea88cd0', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 10, 'created': '2015-03-03 06:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6fecb84d0ec198b251a52d7cf8b90de5a0468f7c', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 11, 'created': '2015-03-03 22:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/60a45a8a3769139600fe6c8e125f7adc717c1261', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 12, 'created': '2015-03-04 19:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f43ba447e18519a5076b8411317587460bffc339', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 13, 'created': '2015-03-05 18:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a22ab18cdd337a458b6b5e1972c95c165cae2289', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 14, 'created': '2015-03-05 18:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0288a8471a175c6345930b56ea693bcd6bb97aa7', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}, {'number': 15, 'created': '2015-03-10 22:42:27.000000000', 'files': ['neutron/agent/l3/dvr_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/701ade1dc85d44d0bcd4ec37494cd1e662dcb5c1', 'message': 'Prevent race conditions on DVR FIP resources\n\nMultiple threads can step on each other while\nadding or removing resources needed for DVR\nfloating IPs such as Agent gateway port and\nFIP namespace. A conditional lock is added here\nthat comes into effect only for DVRs.\n\nChange-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c\nrelated-bug: #1415522\n'}]",8,153422,701ade1dc85d44d0bcd4ec37494cd1e662dcb5c1,432,34,15,9077,,,0,"Prevent race conditions on DVR FIP resources

Multiple threads can step on each other while
adding or removing resources needed for DVR
floating IPs such as Agent gateway port and
FIP namespace. A conditional lock is added here
that comes into effect only for DVRs.

Change-Id: Ic7315aef7bcbc109f0c0e4d2696de357d08bbe3c
related-bug: #1415522
",git fetch https://review.opendev.org/openstack/neutron refs/changes/22/153422/10 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3/agent.py'],1,e8fda051fa7ee7614ca95c16ab42bf5f0f4911be,nsLock,"import threading nsLock = threading.Lock() with self.nsLock: if ri.router['distributed']: self.create_dvr_fip_interfaces(ri, ex_gw_port) interface_name = self._get_external_device_interface_name( ri, ex_gw_port) fip_statuses = self._configure_fip_addresses(ri, interface_name) if ri.fip_ns.agent_gateway_port: if ri.dist_fip_count == 0: ri.fip_ns.create_rtr_2_fip_link(ri) # kicks the FW Agent to add rules for the IR namespace if # configured self.process_router_add(ri) else: LOG.debug('Floating IPs exist but no agent_gateway_port')"," if ri.router['distributed']: self.create_dvr_fip_interfaces(ri, ex_gw_port) interface_name = self._get_external_device_interface_name( ri, ex_gw_port) fip_statuses = self._configure_fip_addresses(ri, interface_name) if ri.fip_ns.agent_gateway_port and floating_ips: if ri.dist_fip_count == 0: ri.fip_ns.create_rtr_2_fip_link(ri) # kicks the FW Agent to add rules for the IR namespace if # configured self.process_router_add(ri)",18,11
openstack%2Fpython-neutronclient~master~I47b1eab5057e2ad716eb7e5e6cac21618abef8d7,openstack/python-neutronclient,master,I47b1eab5057e2ad716eb7e5e6cac21618abef8d7,PEP8(version: 1.6.2) test fails in root directory of neutronclient.,ABANDONED,2015-03-12 01:06:49.000000000,2015-05-21 21:28:45.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}]","[{'number': 1, 'created': '2015-03-12 01:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/5374906e619364072e10de4d68aff6051df708d1', 'message': 'PEP8(version: 1.6.2) test fails in root directory of neutronclient.\n\nChange-Id: I47b1eab5057e2ad716eb7e5e6cac21618abef8d7\nCloses-Bug: #1431094\n'}, {'number': 2, 'created': '2015-03-13 01:21:06.000000000', 'files': ['neutronclient/neutron/v2_0/networkprofile.py', 'neutronclient/neutron/v2_0/policyprofile.py', 'neutronclient/tests/unit/test_cli20.py', 'neutronclient/neutron/v2_0/contrib/_fox_sockets.py', 'doc/source/conf.py', 'neutronclient/tests/unit/fw/test_cli20_firewallpolicy.py', 'neutronclient/common/serializer.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/63e8308a7d67db2f276a8f27a933dbf90badadcb', 'message': 'PEP8(version: 1.6.2) test fails in root directory of neutronclient.\n\nChange-Id: I47b1eab5057e2ad716eb7e5e6cac21618abef8d7\nCloses-Bug: #1431094\n'}]",5,163663,63e8308a7d67db2f276a8f27a933dbf90badadcb,7,3,2,8575,,,0,"PEP8(version: 1.6.2) test fails in root directory of neutronclient.

Change-Id: I47b1eab5057e2ad716eb7e5e6cac21618abef8d7
Closes-Bug: #1431094
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/63/163663/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/networkprofile.py', 'neutronclient/neutron/v2_0/policyprofile.py', 'neutronclient/tests/unit/test_cli20.py', 'neutronclient/tests/unit/test_cli20_subnet.py', 'neutronclient/neutron/v2_0/contrib/_fox_sockets.py', 'neutronclient/neutron/v2_0/__init__.py', 'doc/source/conf.py', 'neutronclient/tests/unit/fw/test_cli20_firewallpolicy.py', 'neutronclient/common/serializer.py']",9,5374906e619364072e10de4d68aff6051df708d1,bug/1431094,# # Codes from neutron wsgi # # NOTE (ameade): the has_atom should be removed after all of the # TODO(bcwaldon): accomplish this without a type-check # TODO(bcwaldon): accomplish this without a type-check,### ### Codes from neutron wsgi ### #NOTE (ameade): the has_atom should be removed after all of the #TODO(bcwaldon): accomplish this without a type-check #TODO(bcwaldon): accomplish this without a type-check,24,21
openstack%2Fneutron-vpnaas~master~Ib4e21d7420b16537cf9ea326b9ea2528baf36920,openstack/neutron-vpnaas,master,Ib4e21d7420b16537cf9ea326b9ea2528baf36920,API extension for PPTP VPN,ABANDONED,2015-03-13 06:15:47.000000000,2015-05-21 21:28:44.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4428}]","[{'number': 1, 'created': '2015-03-13 06:15:47.000000000', 'files': ['neutron_vpnaas/db/vpn/vpn_validator.py', 'neutron_vpnaas/db/migration/alembic_migrations/versions/3e72ed57fd3b_pptp_vpn.py', 'neutron_vpnaas/db/vpn/pptp_db.py', 'neutron_vpnaas/extensions/pptp.py', 'neutron_vpnaas/extensions/vpnaas.py', 'neutron_vpnaas/services/vpn/plugin.py', 'neutron_vpnaas/db/migration/alembic_migrations/versions/HEAD', 'neutron_vpnaas/db/vpn/vpn_db.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/250bec103cf4af7e2909a887abbaf855f94bf39b', 'message': 'API extension for PPTP VPN\n\nImplement blueprint: pptp-vpn-support\nChange-Id: Ib4e21d7420b16537cf9ea326b9ea2528baf36920\n'}]",0,164087,250bec103cf4af7e2909a887abbaf855f94bf39b,5,3,1,4428,,,0,"API extension for PPTP VPN

Implement blueprint: pptp-vpn-support
Change-Id: Ib4e21d7420b16537cf9ea326b9ea2528baf36920
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/87/164087/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/db/vpn/vpn_validator.py', 'neutron_vpnaas/db/migration/alembic_migrations/versions/3e72ed57fd3b_pptp_vpn.py', 'neutron_vpnaas/db/vpn/pptp_db.py', 'neutron_vpnaas/extensions/pptp.py', 'neutron_vpnaas/db/migration/alembic_migrations/versions/HEAD', 'neutron_vpnaas/extensions/vpnaas.py', 'neutron_vpnaas/services/vpn/plugin.py', 'neutron_vpnaas/db/vpn/vpn_db.py']",8,250bec103cf4af7e2909a887abbaf855f94bf39b,bp/pptp-vpn-support,"from neutron_vpnaas.extensions import pptpclass PPTPCredential(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): __tablename__ = ""pptp_credentials"" name = sa.Column(sa.String(255)) username = sa.Column(sa.String(255), nullable=False) password = sa.Column(sa.String(128), nullable=False) connections = orm.relationship(""ConnCredAssociation"", backref=""pptp_credentials"", cascade=""all, delete-orphan"") class PPTPConnection(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant): """"""Represents a PPTPConnection Object."""""" __tablename__ = ""pptp_connections"" name = sa.Column(sa.String(255)) admin_state_up = sa.Column(sa.Boolean()) status = sa.Column(sa.String(16), nullable=False) vpnservice_id = sa.Column(sa.String(36), sa.ForeignKey('vpnservices.id')) client_address_pool_cidr = sa.Column(sa.String(64), nullable=False) credentials = orm.relationship(""ConnCredAssociation"", backref=""pptp_connections"", cascade=""all, delete-orphan"") class ConnCredAssociation(model_base.BASEV2): """"""Many-to-Many association between connection and credential."""""" connection_id = sa.Column(sa.String(36), sa.ForeignKey(""pptp_connections.id""), primary_key=True) credential_id = sa.Column(sa.String(36), sa.ForeignKey(""pptp_credentials.id""), primary_key=True) subnet_id = sa.Column(sa.String(36), sa.ForeignKey('subnets.id')) pptp_vpn_connections = orm.relationship( PPTPConnection, backref='vpnservice', cascade=""all, delete-orphan"") elif issubclass(model, PPTPConnection): raise pptp.PPTPConnectionNotFound(conn_id=v_id) elif issubclass(model, PPTPCredential): raise pptp.PPTPCredentialNotFound(cred_id=v_id) if vpnservice.get('subnet_id'): res['subnet_id'] = vpnservice['subnet_id'] if vpns.get('subnet_id'): vpnservice_db = VPNService( id=uuidutils.generate_uuid(), tenant_id=tenant_id, name=vpns['name'], description=vpns['description'], subnet_id=vpns['subnet_id'], router_id=vpns['router_id'], admin_state_up=vpns['admin_state_up'], status=constants.PENDING_CREATE) else: vpnservice_db = VPNService( id=uuidutils.generate_uuid(), tenant_id=tenant_id, name=vpns['name'], description=vpns['description'], router_id=vpns['router_id'], admin_state_up=vpns['admin_state_up'], status=constants.PENDING_CREATE)"," subnet_id = sa.Column(sa.String(36), sa.ForeignKey('subnets.id'), nullable=False) 'subnet_id': vpnservice['subnet_id'], vpnservice_db = VPNService(id=uuidutils.generate_uuid(), tenant_id=tenant_id, name=vpns['name'], description=vpns['description'], subnet_id=vpns['subnet_id'], router_id=vpns['router_id'], admin_state_up=vpns['admin_state_up'], status=constants.PENDING_CREATE)",582,18
openstack%2Fneutron~master~I5fab1eae7213b641d376e45ce1f894576fc042ba,openstack/neutron,master,I5fab1eae7213b641d376e45ce1f894576fc042ba,Enable a bunch of pylint checks,ABANDONED,2015-03-06 15:22:28.000000000,2015-05-21 21:28:43.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 6524}, {'_account_id': 7787}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-03-06 15:22:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee487b09aa0c7d7da27a513f1a55761bdf6c7aa4', 'message': 'Remove non-parent-init-called pylint exclusion\n\nChange-Id: I5fab1eae7213b641d376e45ce1f894576fc042ba\n'}, {'number': 2, 'created': '2015-03-06 19:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/958d128797f10deefb9c9d3cdd29aa110ab1a1ff', 'message': 'Enable a bunch of pylint checks\n\nChange-Id: I5fab1eae7213b641d376e45ce1f894576fc042ba\n'}, {'number': 3, 'created': '2015-03-06 19:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2e954d8ee50635f4d15cc4b72a5a6a2f339b6be0', 'message': 'Enable a bunch of pylint checks\n\nChange-Id: I5fab1eae7213b641d376e45ce1f894576fc042ba\n'}, {'number': 4, 'created': '2015-03-09 13:40:40.000000000', 'files': ['neutron/plugins/embrane/agent/dispatcher.py', 'neutron/tests/unit/test_extension_security_group.py', '.pylintrc', 'neutron/tests/unit/cisco/n1kv/test_n1kv_db.py', 'neutron/agent/l3/dvr_router.py', 'neutron/db/dvr_mac_db.py', 'neutron/tests/unit/test_linux_interface.py', 'neutron/agent/metadata/agent.py', 'neutron/tests/unit/ml2/test_type_tunnel.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb8d208347b0d991ad825ad4ef278b9a03cefd49', 'message': 'Enable a bunch of pylint checks\n\nChange-Id: I5fab1eae7213b641d376e45ce1f894576fc042ba\n'}]",4,162190,eb8d208347b0d991ad825ad4ef278b9a03cefd49,74,27,4,8873,,,0,"Enable a bunch of pylint checks

Change-Id: I5fab1eae7213b641d376e45ce1f894576fc042ba
",git fetch https://review.opendev.org/openstack/neutron refs/changes/90/162190/4 && git format-patch -1 --stdout FETCH_HEAD,"['.pylintrc', 'neutron/agent/metadata/agent.py']",2,ee487b09aa0c7d7da27a513f1a55761bdf6c7aa4,pylint_tests, # pylint: disable=non-parent-init-called,,1,1
openstack%2Fneutron-vpnaas~master~Ib14023854be8f6d00d9f39cda32aff69b454bf60,openstack/neutron-vpnaas,master,Ib14023854be8f6d00d9f39cda32aff69b454bf60,PPTP VPN agent support,ABANDONED,2015-03-13 06:52:32.000000000,2015-05-21 21:28:42.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4428}, {'_account_id': 12860}]","[{'number': 1, 'created': '2015-03-13 06:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/a96d412241f1b2226bd322333683b037f7be0705', 'message': ""PPTP VPN agent support\n\nCurrently, the service driver is shared with ipsec, but the device\ndriver is seperated. This is for making ipsec and ppp co-exist in\none depolyment. The accel-ppp driver now is fully supported for pptp.\n\nNOTE: because of the pptpd deamon couldn't specify credential file,\nso there is a problem to using this driver when associating or\ndisassociating credential from connection.\n\nChange-Id: Ib14023854be8f6d00d9f39cda32aff69b454bf60\n""}, {'number': 2, 'created': '2015-03-13 06:53:33.000000000', 'files': ['etc/neutron_vpnaas.conf', 'neutron_vpnaas/services/vpn/service_drivers/ipsec.py', 'neutron_vpnaas/services/vpn/service_drivers/cisco_ipsec.py', 'etc/vpn_agent.ini', 'neutron_vpnaas/services/vpn/service_drivers/__init__.py', 'neutron_vpnaas/services/vpn/service_drivers/base_ipsec.py', 'neutron_vpnaas/services/vpn/device_drivers/linux.py', 'neutron_vpnaas/services/vpn/plugin.py', 'neutron_vpnaas/services/vpn/common/constants.py', 'neutron_vpnaas/services/vpn/device_drivers/accel_ppp.py', 'neutron_vpnaas/services/vpn/device_drivers/__init__.py', 'neutron_vpnaas/services/vpn/device_drivers/template/pptpd/pptpd.conf.template', 'neutron_vpnaas/services/vpn/agent.py', 'neutron_vpnaas/services/vpn/device_drivers/pptp.py', 'neutron_vpnaas/db/vpn/pptp_db.py', 'neutron_vpnaas/services/vpn/device_drivers/template/accel-ppp/accel-ppp.conf.template', 'neutron_vpnaas/services/vpn/device_drivers/template/accel-ppp/chap-secrets.template', 'neutron_vpnaas/services/vpn/device_drivers/template/pptpd/options.pptpd.template', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py', 'neutron_vpnaas/services/vpn/common/topics.py', 'neutron_vpnaas/services/vpn/service_drivers/base.py', 'etc/neutron/rootwrap.d/vpnaas.filters', 'neutron_vpnaas/db/vpn/vpn_db.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/85a3e441ff29c4aef4452ba4ff05d669832ebfbc', 'message': ""PPTP VPN agent support\n\nCurrently, the service driver is shared with ipsec, but the device\ndriver is seperated. This is for making ipsec and ppp co-exist in\none depolyment. The accel-ppp driver now is fully supported for pptp.\n\nNOTE: because of the pptpd deamon couldn't specify credential file,\nso there is a problem to using this driver when associating or\ndisassociating credential from connection.\n\nImplement blueprint: pptp-vpn-support\nChange-Id: Ib14023854be8f6d00d9f39cda32aff69b454bf60\n""}]",0,164092,85a3e441ff29c4aef4452ba4ff05d669832ebfbc,6,4,2,4428,,,0,"PPTP VPN agent support

Currently, the service driver is shared with ipsec, but the device
driver is seperated. This is for making ipsec and ppp co-exist in
one depolyment. The accel-ppp driver now is fully supported for pptp.

NOTE: because of the pptpd deamon couldn't specify credential file,
so there is a problem to using this driver when associating or
disassociating credential from connection.

Implement blueprint: pptp-vpn-support
Change-Id: Ib14023854be8f6d00d9f39cda32aff69b454bf60
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/92/164092/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/neutron_vpnaas.conf', 'neutron_vpnaas/services/vpn/service_drivers/ipsec.py', 'neutron_vpnaas/services/vpn/service_drivers/cisco_ipsec.py', 'etc/vpn_agent.ini', 'neutron_vpnaas/services/vpn/service_drivers/__init__.py', 'neutron_vpnaas/services/vpn/service_drivers/base_ipsec.py', 'neutron_vpnaas/services/vpn/device_drivers/linux.py', 'neutron_vpnaas/services/vpn/plugin.py', 'neutron_vpnaas/services/vpn/common/constants.py', 'neutron_vpnaas/services/vpn/device_drivers/accel_ppp.py', 'neutron_vpnaas/services/vpn/device_drivers/__init__.py', 'neutron_vpnaas/services/vpn/device_drivers/template/pptpd/pptpd.conf.template', 'neutron_vpnaas/services/vpn/agent.py', 'neutron_vpnaas/services/vpn/device_drivers/pptp.py', 'neutron_vpnaas/db/vpn/pptp_db.py', 'neutron_vpnaas/services/vpn/device_drivers/template/accel-ppp/accel-ppp.conf.template', 'neutron_vpnaas/services/vpn/device_drivers/template/accel-ppp/chap-secrets.template', 'neutron_vpnaas/services/vpn/device_drivers/template/pptpd/options.pptpd.template', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py', 'neutron_vpnaas/services/vpn/common/topics.py', 'neutron_vpnaas/services/vpn/service_drivers/base.py', 'etc/neutron/rootwrap.d/vpnaas.filters', 'neutron_vpnaas/db/vpn/vpn_db.py']",23,a96d412241f1b2226bd322333683b037f7be0705,bp/pptp-vpn-support," pptpconnections = orm.relationship( def update_ipsec_status_by_agent(self, context, service_status_info_list):"," pptp_vpn_connections = orm.relationship( def update_status_by_agent(self, context, service_status_info_list):",1888,346
openstack%2Fneutron~master~Iceeffb8d0bc6067db8ef23774d9b4a3b991245ee,openstack/neutron,master,Iceeffb8d0bc6067db8ef23774d9b4a3b991245ee,Fix dist_fip_count problem during router migration,ABANDONED,2015-01-29 09:34:44.000000000,2015-05-21 21:28:41.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 6876}, {'_account_id': 7183}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 11279}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-01-29 09:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9aeae51fbfe45c0ad384bb548f031de8282ac1b', 'message': ""Fix dist_fip_count problem during router migration\n\nWhen router is migrating from legacy to distributed,\nri object in l3 agent is a LegacyRouter object instead\nof DvrRouter object. Therefore it doesn't has dist_fip_count\nattribute. This patch fixed the AttributeError in this\nscenario.\n\nThis is introduced by commit ee4bae211309e0f1fcee5565ddd2379997e1de13,\nso using the same bug to track the fix.\n\nChange-Id: Iceeffb8d0bc6067db8ef23774d9b4a3b991245ee\nCloses-Bug: 1367039\n""}, {'number': 2, 'created': '2015-01-29 11:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/289661c0757da7ca34ea05879243b29f6d35c573', 'message': ""Fix dist_fip_count problem during router migration\n\nWhen router is migrating from legacy to distributed,\nri object in l3 agent is a LegacyRouter object instead\nof DvrRouter object. Therefore it doesn't has dist_fip_count\nattribute. This patch fixed the AttributeError in this\nscenario.\n\nThis is introduced by commit ee4bae211309e0f1fcee5565ddd2379997e1de13,\nso using the same bug to track the fix.\n\nChange-Id: Iceeffb8d0bc6067db8ef23774d9b4a3b991245ee\nCloses-Bug: 1367039\n""}, {'number': 3, 'created': '2015-02-05 03:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c1460a3ff61eeb38400816128ff7b1b9f1c715a1', 'message': ""Fix dist_fip_count problem during router migration\n\nWhen router is migrating from legacy to distributed,\nri object in l3 agent is a LegacyRouter object instead\nof DvrRouter object. Therefore it doesn't has dist_fip_count\nattribute. This patch fixed the AttributeError in this\nscenario.\n\nThis is introduced by commit ee4bae211309e0f1fcee5565ddd2379997e1de13,\nso using the same bug to track the fix.\n\nChange-Id: Iceeffb8d0bc6067db8ef23774d9b4a3b991245ee\nCloses-Bug: 1367039\n""}, {'number': 4, 'created': '2015-02-09 02:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d312d6f7109c3d7b8080cbdd671be843d687b2b3', 'message': ""Fix dist_fip_count problem during router migration\n\nWhen router is migrating from legacy to distributed,\nri object in l3 agent is a LegacyRouter object instead\nof DvrRouter object. Therefore it doesn't has dist_fip_count\nattribute. This patch fixed the AttributeError in this\nscenario.\n\nThis is introduced by commit ee4bae211309e0f1fcee5565ddd2379997e1de13,\nso using the same bug to track the fix.\n\nChange-Id: Iceeffb8d0bc6067db8ef23774d9b4a3b991245ee\nCloses-Bug: 1367039\n""}, {'number': 5, 'created': '2015-02-12 02:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9af5f814f6c1a34f58e97ef9a4f24a067acde0c', 'message': ""Fix dist_fip_count problem during router migration\n\nWhen router is migrating from legacy to distributed,\nri object in l3 agent is a LegacyRouter object instead\nof DvrRouter object. Therefore it doesn't has dist_fip_count\nattribute. This patch fixed the AttributeError in this\nscenario.\n\nChange-Id: Iceeffb8d0bc6067db8ef23774d9b4a3b991245ee\nCloses-Bug: 1421042\n""}, {'number': 6, 'created': '2015-02-24 07:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b2df3e93da77d9051d34c5d2ac93636ba16ea72', 'message': ""Fix dist_fip_count problem during router migration\n\nWhen router is migrating from legacy to distributed,\nri object in l3 agent is a LegacyRouter object instead\nof DvrRouter object. Therefore it doesn't have dist_fip_count\nattribute. This patch fixed the AttributeError in this\nscenario.\n\nChange-Id: Iceeffb8d0bc6067db8ef23774d9b4a3b991245ee\nCloses-Bug: 1421042\n""}, {'number': 7, 'created': '2015-03-06 09:13:11.000000000', 'files': ['neutron/tests/unit/agent/test_dvr_fip_ns.py', 'neutron/agent/l3/agent.py', 'neutron/agent/l3/dvr_fip_ns.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd2c123f40eb146e319e6d1f7a9fc707727a6de9', 'message': ""Fix dist_fip_count problem during router migration\n\nWhen router is migrating from legacy to distributed,\nri object in l3 agent is a LegacyRouter object instead\nof DvrRouter object. Therefore it doesn't have dist_fip_count\nattribute. This patch fixed the AttributeError in this\nscenario.\n\nChange-Id: Iceeffb8d0bc6067db8ef23774d9b4a3b991245ee\nCloses-Bug: 1421042\n""}]",9,151153,cd2c123f40eb146e319e6d1f7a9fc707727a6de9,142,35,7,7183,,,0,"Fix dist_fip_count problem during router migration

When router is migrating from legacy to distributed,
ri object in l3 agent is a LegacyRouter object instead
of DvrRouter object. Therefore it doesn't have dist_fip_count
attribute. This patch fixed the AttributeError in this
scenario.

Change-Id: Iceeffb8d0bc6067db8ef23774d9b4a3b991245ee
Closes-Bug: 1421042
",git fetch https://review.opendev.org/openstack/neutron refs/changes/53/151153/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3/dvr.py'],1,e9aeae51fbfe45c0ad384bb548f031de8282ac1b,bug/1421042," if (not ri.router.get('distributed') or getattr(ri, 'dist_fip_count') is not None):", if not ri.router.get('distributed') or ri.dist_fip_count is not None:,2,1
openstack%2Fneutron~master~I63c65c3a2ea60066788da9d41b18cb744b4ea51a,openstack/neutron,master,I63c65c3a2ea60066788da9d41b18cb744b4ea51a,SeaMicro plugin decomposition,ABANDONED,2015-03-03 09:37:13.000000000,2015-05-21 21:28:40.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 10984}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-03-03 09:37:13.000000000', 'files': ['doc/source/devref/contribute.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/34d6a2958c16c3f92ad2a249e7abfca7cc45bea1', 'message': 'SeaMicro plugin decomposition\n\nUpdated vendor decomposition progress chart\n\n[1] https://github.com/seamicro/seamicro-ml2.git\n\nChange-Id: I63c65c3a2ea60066788da9d41b18cb744b4ea51a\nPartially-implements: blueprint core-vendor-decomposition\nCloses-bug: #1427548\n'}]",6,160712,34d6a2958c16c3f92ad2a249e7abfca7cc45bea1,34,20,1,10984,,,0,"SeaMicro plugin decomposition

Updated vendor decomposition progress chart

[1] https://github.com/seamicro/seamicro-ml2.git

Change-Id: I63c65c3a2ea60066788da9d41b18cb744b4ea51a
Partially-implements: blueprint core-vendor-decomposition
Closes-bug: #1427548
",git fetch https://review.opendev.org/openstack/neutron refs/changes/12/160712/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/contribute.rst'],1,34d6a2958c16c3f92ad2a249e7abfca7cc45bea1,bp/core-vendor-decomposition,| seamicro-ml2_ | ml2 | no | yes | [B] | | +-------------------------------+-----------------------+-----------+------------------+---------+--------------+ .. _seamicro-ml2: SeaMicro -------- * Git: https://github.com/seamicro/seamicro-ml2 * PyPi: https://pypi.python.org/pypi/seamicro-ml2,,10,0
openstack%2Fneutron~master~Ibb75bb6295eca0496281e60202b95e9abf66cf8d,openstack/neutron,master,Ibb75bb6295eca0496281e60202b95e9abf66cf8d,WIP: ml2 async proof-of-concept,ABANDONED,2015-02-10 04:21:39.000000000,2015-05-21 21:28:39.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1297}, {'_account_id': 1689}, {'_account_id': 1923}, {'_account_id': 2888}, {'_account_id': 5217}, {'_account_id': 6524}, {'_account_id': 6558}, {'_account_id': 6598}, {'_account_id': 6697}, {'_account_id': 8792}, {'_account_id': 10257}]","[{'number': 1, 'created': '2015-02-10 04:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5917ecb0ffe3da26b7ad34571a40436ae60fcc04', 'message': ""WIP: ml2 async poc impl\n\nThis is based on earlier work (manishg, gus):\nI35971770d87acb353333782150937ace5f4b9db5\nIaa52c6c11b32963735b0b16008fdeb6bb5b60e17\n\nThis is mainly doing the same as current ml2 with introduction\nof taskflow.  In subsequent iterations, I'll slowly add intermediate\nstates and move out the engine out after REST response.\n\nChange-Id: Ibb75bb6295eca0496281e60202b95e9abf66cf8d\n""}, {'number': 2, 'created': '2015-02-10 19:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f0d93237328044060abc1916907b1115dfdbc466', 'message': ""WIP: ml2 async proof-of-concept\n\nThis is based on earlier work (manishg, gus):\nI35971770d87acb353333782150937ace5f4b9db5\nIaa52c6c11b32963735b0b16008fdeb6bb5b60e17\n\nThis is mainly doing the same as current ml2 with introduction\nof taskflow.  In subsequent iterations, I'll slowly add intermediate\nstates and move out the engine out after REST response.\n\nChange-Id: Ibb75bb6295eca0496281e60202b95e9abf66cf8d\n""}, {'number': 3, 'created': '2015-02-13 23:34:27.000000000', 'files': ['neutron/plugins/ml2/managers.py', 'requirements.txt', 'neutron/plugins/ml2/drivers/examples/__init__.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/service.py', 'neutron/plugins/ml2/plugin.py', 'neutron/plugins/ml2/drivers/examples/example_one.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0cfdd6c114074c7a3855bfe8c9f48d9e0794cc71', 'message': ""WIP: ml2 async proof-of-concept\n\nThis is based on earlier work (manishg, gus):\nI35971770d87acb353333782150937ace5f4b9db5\nIaa52c6c11b32963735b0b16008fdeb6bb5b60e17\n\nThis is mainly doing the same as current ml2 with introduction\nof taskflow.  In subsequent iterations, I'll slowly add intermediate\nstates and move out the engine out after REST response.\n\nPatchSet 3:\n* added documentation\n* reorganized the code a little bit\n* need to work on some unit tests\n* will add async in next patch set\n* added TODOs to indicate future patch set updates\n\nChange-Id: Ibb75bb6295eca0496281e60202b95e9abf66cf8d\n""}]",0,154333,0cfdd6c114074c7a3855bfe8c9f48d9e0794cc71,59,13,3,8792,,,0,"WIP: ml2 async proof-of-concept

This is based on earlier work (manishg, gus):
I35971770d87acb353333782150937ace5f4b9db5
Iaa52c6c11b32963735b0b16008fdeb6bb5b60e17

This is mainly doing the same as current ml2 with introduction
of taskflow.  In subsequent iterations, I'll slowly add intermediate
states and move out the engine out after REST response.

PatchSet 3:
* added documentation
* reorganized the code a little bit
* need to work on some unit tests
* will add async in next patch set
* added TODOs to indicate future patch set updates

Change-Id: Ibb75bb6295eca0496281e60202b95e9abf66cf8d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/154333/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/managers.py', 'requirements.txt', 'neutron/plugins/ml2/driver_api.py', 'neutron/plugins/ml2/drivers/mech_mock_one.py', 'neutron/plugins/ml2/drivers/mech_mock_two.py', 'neutron/plugins/ml2/plugin.py']",6,5917ecb0ffe3da26b7ad34571a40436ae60fcc04,ml2-async,"import concurrent.futuresfrom taskflow import engines as tf_engines from taskflow.listeners import logging as tf_logging_listener #make max_workers config self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=10) def _taskflow_load(self, flow, **kwargs): # TODO(gus): Taskflow engine should be configurable eng = tf_engines.load( flow, engine='parallel', executor=self.executor, **kwargs) tf_logging_listener.DynamicLoggingListener(eng).register() return eng flow = self.mechanism_manager.update_port_postcommit_flow() self._taskflow_load(flow, store={ 'port_context': cur_context, }).run() flow = self.mechanism_manager.create_network_postcommit_flow() eng = self._taskflow_load(flow, store={ 'mech_context': mech_context, 'network': network, }) eng.run() flow = self.mechanism_manager.update_network_postcommit_flow() self._taskflow_load(flow, store={'mech_context': mech_context}).run() flow = self.mechanism_manager.delete_network_postcommit_flow() self._taskflow_load(flow, store={ 'mech_context': mech_context, }).run() flow = self.mechanism_manager.create_subnet_postcommit_flow() self._taskflow_load(flow, store={ 'subnet_context': mech_context, }).run() flow = self.mechanism_manager.update_subnet_postcommit_flow() self._taskflow_load(flow, store={'subnet_context': mech_context}).run() flow = self.mechanism_manager.delete_subnet_postcommit_flow() self._taskflow_load(flow, store={ 'subnet_context': mech_context, }).run() flow = self.mechanism_manager.create_port_postcommit() self._taskflow_load(flow, store={ 'port_context': mech_context, }).run() flow = self.mechanism_manager.update_port_postcommit_flow() self._taskflow_load(flow, store={'port_context': mech_context}).run() # TODO(gus): This should be one unordered_flow, but we # need to be able to rebind subflow args first. for mech_context in bound_mech_contexts: flow = self.mechanism_manager.delete_port_postcommit_flow() self._taskflow_load(flow, store={ 'port_context': mech_context, }).run() flow = self.mechanism_manager.update_port_postcommit_flow() self._taskflow_load(flow, store={ 'port_context': mech_context, }).run()", self.mechanism_manager.update_port_postcommit(cur_context) self.mechanism_manager.create_network_postcommit(mech_context) self.mechanism_manager.update_network_postcommit(mech_context) self.mechanism_manager.delete_network_postcommit(mech_context) self.mechanism_manager.create_subnet_postcommit(mech_context) self.mechanism_manager.update_subnet_postcommit(mech_context) self.mechanism_manager.delete_subnet_postcommit(mech_context) self.mechanism_manager.create_port_postcommit(mech_context) self.mechanism_manager.update_port_postcommit(mech_context) for mech_context in bound_mech_contexts: self.mechanism_manager.delete_port_postcommit(mech_context) self.mechanism_manager.update_port_postcommit(mech_context),644,35
openstack%2Fneutron~master~I3d319e9647960d8eb8e4b85ac9e2e56e2d762ea1,openstack/neutron,master,I3d319e9647960d8eb8e4b85ac9e2e56e2d762ea1,Add row lock when update dhcp reserved port,ABANDONED,2015-02-25 13:06:40.000000000,2015-05-21 21:28:36.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 7567}, {'_account_id': 8441}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-02-25 13:06:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/095d23dd372bfe96a0d279abdfaec592295090f8', 'message': 'Add row lock when update dhcp reserved port\n\nTo avoid race condition when two dhcp agent using a reserved dhcp\nport, put a row lock when update port for dhcp reserved port.\n\nChange-Id: I3d319e9647960d8eb8e4b85ac9e2e56e2d762ea1\nCloses-Bug: #1425402\n'}, {'number': 2, 'created': '2015-02-25 14:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/144ee3aece46387a6deaad62bd0495980d3caaa7', 'message': 'Add row lock when update dhcp reserved port\n\nTo avoid race condition when two dhcp agent using a reserved dhcp\nport, put a row lock when update port for dhcp reserved port.\n\nChange-Id: I3d319e9647960d8eb8e4b85ac9e2e56e2d762ea1\nCloses-Bug: #1425402\n'}, {'number': 3, 'created': '2015-03-10 02:41:08.000000000', 'files': ['neutron/tests/unit/test_dhcp_rpc.py', 'neutron/api/rpc/handlers/dhcp_rpc.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/83752625fca9148e0545bb673a54d5cbd84121f0', 'message': 'Add row lock when update dhcp reserved port\n\nTo avoid race condition when two dhcp agent using a reserved dhcp\nport, put a row lock when update port for dhcp reserved port.\n\nChange-Id: I3d319e9647960d8eb8e4b85ac9e2e56e2d762ea1\nCloses-Bug: #1425402\n'}]",2,159110,83752625fca9148e0545bb673a54d5cbd84121f0,62,28,3,7567,,,0,"Add row lock when update dhcp reserved port

To avoid race condition when two dhcp agent using a reserved dhcp
port, put a row lock when update port for dhcp reserved port.

Change-Id: I3d319e9647960d8eb8e4b85ac9e2e56e2d762ea1
Closes-Bug: #1425402
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/159110/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/api/rpc/handlers/dhcp_rpc.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/common/exceptions.py']",3,095d23dd372bfe96a0d279abdfaec592295090f8,bug/1425402,"class ReservedDhcpPortInUse(InUse): message = _(""Unable to complete operation on reserved dhcp "" ""port %(port_id)s for network %(net_id)s. Port already has "" ""an attached device %(device_id)s."") ",,24,3
openstack%2Fpython-neutronclient~master~Ifefee97944059a0993e547a842c675c12be18120,openstack/python-neutronclient,master,Ifefee97944059a0993e547a842c675c12be18120,Add rate limiting security groups rules CLI extension,ABANDONED,2015-02-16 12:57:16.000000000,2015-05-21 21:28:35.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 14249}, {'_account_id': 14535}]","[{'number': 1, 'created': '2015-02-16 12:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/744777716a14213c6be8e299d32b335de86bd089', 'message': 'Add rate limiting security groups rules CLI extension.\n\nChange-Id: Ifefee97944059a0993e547a842c675c12be18120\nImplements: blueprint security-group-brute-force-prevention-cli\n'}, {'number': 2, 'created': '2015-02-17 08:42:33.000000000', 'files': ['neutronclient/neutron/v2_0/securitygroup.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/bacb06cb469b301b0344037e6faaaeaeffa1878e', 'message': 'Add rate limiting security groups rules CLI extension\n\nChange-Id: Ifefee97944059a0993e547a842c675c12be18120\nImplements: blueprint security-group-brute-force-prevention-cli\n'}]",2,156205,bacb06cb469b301b0344037e6faaaeaeffa1878e,13,5,2,14249,,,0,"Add rate limiting security groups rules CLI extension

Change-Id: Ifefee97944059a0993e547a842c675c12be18120
Implements: blueprint security-group-brute-force-prevention-cli
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/05/156205/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/securitygroup.py'],1,744777716a14213c6be8e299d32b335de86bd089,bp/security-group-brute-force-prevention-cli," 'remote_ip_prefix', 'remote_group_id', 'action'] parser.add_argument( '--rate', help=_('rate threshold')) parser.add_argument( '--period', help=_('rate period threshold in second')) parser.add_argument( '--tcp_flags', help=_('tcp flags matches')) parser.add_argument( '--state', help=_('connection state')) parser.add_argument( '--action', help=_('allow, drop or block')) parser.add_argument( '--block_time', help=_('time to block for block action')) if parsed_args.rate: body['security_group_rule'].update( {'rate': parsed_args.rate}) if parsed_args.period: body['security_group_rule'].update( {'period': parsed_args.period}) if parsed_args.tcp_flags: body['security_group_rule'].update( {'tcp_flags': parsed_args.tcp_flags}) if parsed_args.state: body['security_group_rule'].update( {'state': parsed_args.state}) if parsed_args.action: body['security_group_rule'].update( {'action': parsed_args.action}) if parsed_args.block_time: body['security_group_rule'].update( {'block_time': parsed_args.block_time})"," 'remote_ip_prefix', 'remote_group_id']",37,1
openstack%2Fneutron~master~I01c901bc20f1a3e51b9a7d386f3c97e3925d1955,openstack/neutron,master,I01c901bc20f1a3e51b9a7d386f3c97e3925d1955,WIP: Avoid assigned port as a second gateway to an existing router,ABANDONED,2015-03-17 11:26:40.000000000,2015-05-21 21:28:34.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 7249}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14956}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15696}]","[{'number': 1, 'created': '2015-03-17 11:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5ffa43be1c7c7b1bb038804e6c12bc15e5b0eaed', 'message': 'WIP:Avoid assigned port as a second gateway to an existing router\n\nChange-Id: I01c901bc20f1a3e51b9a7d386f3c97e3925d1955\nCloses-bug: #1430345\n'}, {'number': 2, 'created': '2015-03-17 11:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4a9aacda1fd5988ff94d21e15a8b16bcbf312554', 'message': 'WIP:Avoid assigned port as a second gateway to an existing router\n\nChange-Id: I01c901bc20f1a3e51b9a7d386f3c97e3925d1955\nCloses-bug: #1430345\n'}, {'number': 3, 'created': '2015-03-17 14:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/757a5d61a2928975378105b5a6d1a79d46fa24fe', 'message': 'WIP:Avoid assigned port as a second gateway to an existing router\n\nChange-Id: I01c901bc20f1a3e51b9a7d386f3c97e3925d1955\nCloses-bug: #1430345\n'}, {'number': 4, 'created': '2015-03-17 17:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1ec905860fe0017cb665b602a5291ad991f075c4', 'message': ""Avoid assigned port as a second gateway to an existing router\n\nThe manually created port can be assign as a\n--device_owner='network:router_gateway' to a router that already\nhave a default gateway which cause one router to have two default\ngateways.\n\nPartial-bug: #1430345\n\nChange-Id: I01c901bc20f1a3e51b9a7d386f3c97e3925d1955\n""}, {'number': 5, 'created': '2015-03-20 12:55:13.000000000', 'files': ['neutron/tests/unit/test_l3_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/l3_db.py', 'neutron/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab82370fa3eb8b08ebedf86cbec78946e246d219', 'message': ""WIP: Avoid assigned port as a second gateway to an existing router\n\nThe manually created port can be assign as a\n--device_owner='network:router_gateway' to a router that already\nhave a default gateway which cause one router to have two default\ngateways.\n\nPartial-bug: #1430345\n\nChange-Id: I01c901bc20f1a3e51b9a7d386f3c97e3925d1955\n""}]",0,165031,ab82370fa3eb8b08ebedf86cbec78946e246d219,113,31,5,7249,,,0,"WIP: Avoid assigned port as a second gateway to an existing router

The manually created port can be assign as a
--device_owner='network:router_gateway' to a router that already
have a default gateway which cause one router to have two default
gateways.

Partial-bug: #1430345

Change-Id: I01c901bc20f1a3e51b9a7d386f3c97e3925d1955
",git fetch https://review.opendev.org/openstack/neutron refs/changes/31/165031/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/db_base_plugin_v2.py', 'neutron/common/exceptions.py']",2,5ffa43be1c7c7b1bb038804e6c12bc15e5b0eaed,bug/1430345,"class RouterAlreadyHasGatewayToNetwork(Conflict): message = _(""The following router %(device_id)s has already set gateway "" ""to network %(network_id)s."") ",,42,21
openstack%2Fneutron~master~I047e22d987ec20954caab6857381810a44aca71e,openstack/neutron,master,I047e22d987ec20954caab6857381810a44aca71e,Change default sg table's name into plural,ABANDONED,2015-02-01 09:50:30.000000000,2015-05-21 21:28:33.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 7805}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2015-02-01 09:50:30.000000000', 'files': ['neutron/db/securitygroups_db.py', 'neutron/db/migration/alembic_migrations/versions/14be42f3d0a5_default_sec_group_table.py', 'neutron/tests/functional/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9afadaf7e047c86acc8bdaf3a78bbfa2bad234dd', 'message': ""Change default sg table's name into plural\n\nIn general, we use plural words to represent table name.\nThis patch also fix some nits mentioned in review\nhttps://review.openstack.org/#/c/142101\n\nChange-Id: I047e22d987ec20954caab6857381810a44aca71e\nCloses-Bug: 1416813\n""}]",0,151929,9afadaf7e047c86acc8bdaf3a78bbfa2bad234dd,32,23,1,2874,,,0,"Change default sg table's name into plural

In general, we use plural words to represent table name.
This patch also fix some nits mentioned in review
https://review.openstack.org/#/c/142101

Change-Id: I047e22d987ec20954caab6857381810a44aca71e
Closes-Bug: 1416813
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/151929/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/securitygroups_db.py', 'neutron/db/migration/alembic_migrations/versions/14be42f3d0a5_default_sec_group_table.py', 'neutron/tests/functional/db/test_migrations.py']",3,9afadaf7e047c86acc8bdaf3a78bbfa2bad234dd,bug/1416813," sg_table = sqlalchemy.Table( sg_table.create(conn) conn.execute(sg_table.insert(), ["," SecurityGroup = sqlalchemy.Table( SecurityGroup.create(conn) conn.execute(SecurityGroup.insert(), [",7,7
openstack%2Fneutron~master~I10cb5adb32a2fe18a301038f349b2e3504980abb,openstack/neutron,master,I10cb5adb32a2fe18a301038f349b2e3504980abb,A cleanup of dhcp_agent_scheduler.py,ABANDONED,2014-12-24 08:25:14.000000000,2015-05-21 21:28:32.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 11822}, {'_account_id': 12040}, {'_account_id': 14039}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}, {'_account_id': 15444}]","[{'number': 1, 'created': '2014-12-24 08:25:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd19dd35ac8bad300e5a670b6b44d483f3dc4760', 'message': 'Cleanup/add log to auto scheduler\n\nThis is a cleanup adding debug log to auto_scheduler of\ndhcp_agent_scheduler.py.\n\nChange-Id: I10cb5adb32a2fe18a301038f349b2e3504980abb\n'}, {'number': 2, 'created': '2014-12-25 00:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1f87ce1ee697188b77fde462688fa68904f9655', 'message': 'Cleanup/add log to auto scheduler\n\nThis is a cleanup adding debug log to auto_scheduler of\ndhcp_agent_scheduler.py.\n\nChange-Id: I10cb5adb32a2fe18a301038f349b2e3504980abb\n'}, {'number': 3, 'created': '2014-12-25 01:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c86cff95e5754c0bf1c0fe39e7848382955ab22c', 'message': 'Add log to auto scheduler\n\nThis is a cleanup adding the same debug log of [schedule] method to\n[auto_schedule_networks] method of dhcp_agent_scheduler.py.\nThe debug log will file the network id when the network is not going to\nbind any more DHCP agents due to already binding enough agents\n(agents number is more than dhcp_agent_per_network paramater).\n\nChange-Id: I10cb5adb32a2fe18a301038f349b2e3504980abb\n'}, {'number': 4, 'created': '2015-01-07 02:44:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d2b0ca4b151a3748c9602e7d1da8ad5e73f193f5', 'message': 'A cleanup of dhcp_agent_scheduler.py\n\nThis is a cleanup move the double coding of the check of\ndhcp_agent_per_network into a separate method and reuse from both\nschedule() and auto_schedule_networks().\n\nAlso, this cleanup enable auto_schedule_networks() to have the same\ndebug log output as schedule() when the network is not going to\nbind any more DHCP agents due to already binding enough agents\n(agents number is more than dhcp_agent_per_network paramater).\n\nChange-Id: I10cb5adb32a2fe18a301038f349b2e3504980abb\n'}, {'number': 5, 'created': '2015-01-07 06:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a8bce1de6700dae688be5428955f07a2abe3ca5', 'message': 'A cleanup of dhcp_agent_scheduler.py\n\nThis is a cleanup move the double coding of the check of\ndhcp_agent_per_network into a separate method and reuse from both\nschedule() and auto_schedule_networks().\n\nAlso, this cleanup enable auto_schedule_networks() to have the same\ndebug log output as schedule() when the network is not going to\nbind any more DHCP agents due to already binding enough agents\n(agents number is more than dhcp_agent_per_network paramater).\n\nChange-Id: I10cb5adb32a2fe18a301038f349b2e3504980abb\n'}, {'number': 6, 'created': '2015-01-08 00:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a324dc7a558ffe3bdb7d4ee9395a24cc0f053891', 'message': 'A cleanup of dhcp_agent_scheduler.py\n\nThis is a cleanup move the double coding into a separate method and\nreuse from both schedule() and auto_schedule_networks().\n\nAlso, this cleanup enable auto_schedule_networks() to have the same\ndebug log output as schedule() when the network is not going to\nbind any more DHCP agents due to already binding enough agents\n(agents number is more than dhcp_agent_per_network paramater).\n\nChange-Id: I10cb5adb32a2fe18a301038f349b2e3504980abb\n'}, {'number': 7, 'created': '2015-01-08 04:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4001cf57a995b28d17e6853342d4fad0f958ed0', 'message': 'A cleanup of dhcp_agent_scheduler.py\n\nThis is a cleanup move the double coding into a separate method and\nreuse from both schedule() and auto_schedule_networks().\n\nAlso, this cleanup enable auto_schedule_networks() to have the same\ndebug log output as schedule() when the network is not going to\nbind any more DHCP agents due to already binding enough agents\n(agents number is more than dhcp_agent_per_network paramater).\n\nChange-Id: I10cb5adb32a2fe18a301038f349b2e3504980abb\n'}, {'number': 8, 'created': '2015-01-09 08:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c3ec204cb09a58d4667f2fa28ee18451d12b0e23', 'message': 'A cleanup of dhcp_agent_scheduler.py\n\nThis is a cleanup move the double coding into a separate method and\nreuse from both schedule() and auto_schedule_networks().\n\nChange-Id: I10cb5adb32a2fe18a301038f349b2e3504980abb\n'}, {'number': 9, 'created': '2015-01-20 08:29:45.000000000', 'files': ['neutron/tests/unit/test_dhcp_scheduler.py', 'neutron/scheduler/dhcp_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cbff5f3b2281eada29909d6054bdc59ab27378c5', 'message': 'A cleanup of dhcp_agent_scheduler.py\n\nThis is a cleanup move the double coding into a separate method and\nreuse from both schedule() and auto_schedule_networks().\n\nChange-Id: I10cb5adb32a2fe18a301038f349b2e3504980abb\n'}]",36,143795,cbff5f3b2281eada29909d6054bdc59ab27378c5,200,30,9,14039,,,0,"A cleanup of dhcp_agent_scheduler.py

This is a cleanup move the double coding into a separate method and
reuse from both schedule() and auto_schedule_networks().

Change-Id: I10cb5adb32a2fe18a301038f349b2e3504980abb
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/143795/9 && git format-patch -1 --stdout FETCH_HEAD,['neutron/scheduler/dhcp_agent_scheduler.py'],1,dd19dd35ac8bad300e5a670b6b44d483f3dc4760,cleanup/dhcp_agent_scheduler.py," LOG.debug('Network %s is already hosted', LOG.debug('Network %s is already hosted', net_id) LOG.debug('Auto schedule network %s to DHCP agent %s', dhcp_agent.id, net_id)"," LOG.debug('Network %s is hosted already',",5,1
openstack%2Fneutron-fwaas~master~I61ec017035bd18ce6b5095fa87577f197952c75b,openstack/neutron-fwaas,master,I61ec017035bd18ce6b5095fa87577f197952c75b,Add script to copy neutron tests,ABANDONED,2015-03-26 20:57:28.000000000,2015-05-21 21:28:28.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2035}, {'_account_id': 8124}, {'_account_id': 10119}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-03-26 20:57:28.000000000', 'files': ['neutron_fwaas/tests/neutron/__init__.py', 'tools/copy_neutron_tests.sh', 'neutron_fwaas/tests/neutron/tests/unit/testlib_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/f9c2f68cd20730e5d17fff8f41b4a16a51f5eee9', 'message': 'Add script to copy neutron tests\n\nThis change adds a script to automate the copying of neutron test\nmodules used by neutron-fwaas.\n\nUsage:\n  tools/copy_neutron_tests $NEUTRON_FOLDER\n\nChange-Id: I61ec017035bd18ce6b5095fa87577f197952c75b\n'}]",0,168155,f9c2f68cd20730e5d17fff8f41b4a16a51f5eee9,10,8,1,8124,,,0,"Add script to copy neutron tests

This change adds a script to automate the copying of neutron test
modules used by neutron-fwaas.

Usage:
  tools/copy_neutron_tests $NEUTRON_FOLDER

Change-Id: I61ec017035bd18ce6b5095fa87577f197952c75b
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/55/168155/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/tests/neutron/__init__.py', 'tools/copy_neutron_tests.sh', 'neutron_fwaas/tests/neutron/tests/unit/testlib_plugin.py']",3,f9c2f68cd20730e5d17fff8f41b4a16a51f5eee9,vendoring,"# Copyright 2014 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import gc import weakref import mock from oslo_config import cfg from neutron.db import agentschedulers_db from neutron import manager from neutron.tests import base from neutron.tests import fake_notifier class PluginSetupHelper(object): """"""Mixin for use with testtools.TestCase."""""" def cleanup_core_plugin(self): """"""Ensure that the core plugin is deallocated."""""" nm = manager.NeutronManager if not nm.has_instance(): return # TODO(marun) Fix plugins that do not properly initialize notifiers agentschedulers_db.AgentSchedulerDbMixin.agent_notifiers = {} # Perform a check for deallocation only if explicitly # configured to do so since calling gc.collect() after every # test increases test suite execution time by ~50%. check_plugin_deallocation = ( base.bool_from_env('OS_CHECK_PLUGIN_DEALLOCATION')) if check_plugin_deallocation: plugin = weakref.ref(nm._instance.plugin) nm.clear_instance() if check_plugin_deallocation: gc.collect() # TODO(marun) Ensure that mocks are deallocated? if plugin() and not isinstance(plugin(), mock.Base): self.fail('The plugin for this test was not deallocated.') def setup_coreplugin(self, core_plugin=None): # Plugin cleanup should be triggered last so that # test-specific cleanup has a chance to release references. self.addCleanup(self.cleanup_core_plugin) if core_plugin is not None: cfg.CONF.set_override('core_plugin', core_plugin) class NotificationSetupHelper(object): """"""Mixin for use with testtools.TestCase."""""" def setup_notification_driver(self, notification_driver=None): self.addCleanup(fake_notifier.reset) if notification_driver is None: notification_driver = [fake_notifier.__name__] cfg.CONF.set_override(""notification_driver"", notification_driver) ",,122,0
openstack%2Fneutron~master~I82ea89f1695f1e6e7c7b8ab4e39ee969d7312a6d,openstack/neutron,master,I82ea89f1695f1e6e7c7b8ab4e39ee969d7312a6d,Remove qg from router namespace for DVR migration,ABANDONED,2015-01-29 11:07:23.000000000,2015-05-21 21:28:26.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 7183}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9077}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 11279}, {'_account_id': 12040}, {'_account_id': 12683}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-01-29 11:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/89751a8d5b8426d0bdfd47c0607694e8788f71d0', 'message': 'Remove qg from router namespace for DVR migration\n\nCurrently, when migrating a legacy router to distributed\nrouter, associated floating IP no longer works because\nqg device is still in qrouter namespace.\n\nThis is due to ovs-vsctl del qg port is execuated together\nwith add port operation. This fix separate the two ovs-vsctl\noperations.\n\nChange-Id: I82ea89f1695f1e6e7c7b8ab4e39ee969d7312a6d\nCloses-Bug: 1405528\n'}, {'number': 2, 'created': '2015-02-02 10:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/88d1893ca932181b2e50d501ddf9bb0efc56d248', 'message': 'Remove qg from router namespace for DVR migration\n\nCurrently, when migrating a legacy router to distributed\nrouter, associated floating IP no longer works because\nqg device is still in qrouter namespace.\n\nThis is due to ovs-vsctl del qg port is execuated together\nwith add port operation. This fix separate the two ovs-vsctl\noperations.\n\nChange-Id: I82ea89f1695f1e6e7c7b8ab4e39ee969d7312a6d\nCloses-Bug: 1405528\n'}, {'number': 3, 'created': '2015-02-05 03:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d95c32623bc71ba7171fd975869c437e7d31408', 'message': 'Remove qg from router namespace for DVR migration\n\nCurrently, when migrating a legacy router to distributed\nrouter, associated floating IP no longer works because\nqg device is still in qrouter namespace.\n\nThis is due to ovs-vsctl del qg port is execuated together\nwith add port operation. This fix separate the two ovs-vsctl\noperations.\n\nChange-Id: I82ea89f1695f1e6e7c7b8ab4e39ee969d7312a6d\nCloses-Bug: 1405528\n'}, {'number': 4, 'created': '2015-02-09 03:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/57946b6038688cdfc86554e57a2be7af7c259f09', 'message': 'Remove qg from router namespace for DVR migration\n\nCurrently, when migrating a legacy router to distributed\nrouter, associated floating IP no longer works because\nqg device is still in qrouter namespace.\n\nThis is due to ovs-vsctl del qg port is execuated together\nwith add port operation. This fix separate the two ovs-vsctl\noperations.\n\nChange-Id: I82ea89f1695f1e6e7c7b8ab4e39ee969d7312a6d\nCloses-Bug: 1405528\n'}, {'number': 5, 'created': '2015-03-06 09:15:36.000000000', 'files': ['neutron/tests/unit/agent/linux/test_ovs_lib.py', 'neutron/agent/linux/ovs_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f0866823499c059fd7620eb0fa97b97b12541c6', 'message': 'Remove qg from router namespace for DVR migration\n\nCurrently, when migrating a legacy router to distributed\nrouter, associated floating IP no longer works because\nqg device is still in qrouter namespace.\n\nThis is due to ovs-vsctl del qg port is execuated together\nwith add port operation. This fix separate the two ovs-vsctl\noperations.\n\nChange-Id: I82ea89f1695f1e6e7c7b8ab4e39ee969d7312a6d\nCloses-Bug: 1405528\n'}]",5,151181,2f0866823499c059fd7620eb0fa97b97b12541c6,106,30,5,7183,,,0,"Remove qg from router namespace for DVR migration

Currently, when migrating a legacy router to distributed
router, associated floating IP no longer works because
qg device is still in qrouter namespace.

This is due to ovs-vsctl del qg port is execuated together
with add port operation. This fix separate the two ovs-vsctl
operations.

Change-Id: I82ea89f1695f1e6e7c7b8ab4e39ee969d7312a6d
Closes-Bug: 1405528
",git fetch https://review.opendev.org/openstack/neutron refs/changes/81/151181/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/ovs_lib.py'],1,89751a8d5b8426d0bdfd47c0607694e8788f71d0,bug/1405528," self.add_port(port_name, *interface_attr_tuples)"," txn.add(self.ovsdb.add_port(self.br_name, port_name, may_exist=False)) if interface_attr_tuples: txn.add(self.ovsdb.db_set('Interface', port_name, *interface_attr_tuples))",1,5
openstack%2Fneutron-specs~master~I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8,openstack/neutron-specs,master,I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8,Spec for nova-network to neutron migration process,ABANDONED,2014-12-17 14:28:55.000000000,2015-05-21 21:28:25.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 581}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 704}, {'_account_id': 782}, {'_account_id': 792}, {'_account_id': 964}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2033}, {'_account_id': 2271}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 3189}, {'_account_id': 4146}, {'_account_id': 4393}, {'_account_id': 5292}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 5575}, {'_account_id': 5754}, {'_account_id': 5948}, {'_account_id': 6316}, {'_account_id': 6524}, {'_account_id': 6873}, {'_account_id': 8515}, {'_account_id': 8655}, {'_account_id': 8788}, {'_account_id': 9656}, {'_account_id': 11279}]","[{'number': 1, 'created': '2014-12-17 14:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c3c83f5363ff0485feab6941c0ce03c569802e4b', 'message': 'Spec for neutron part of nova-network to neutron migration\n\nWIP: not well detailed yet, prototyping is in progress\n\nblueprint migration-from-nova-net\n\nChange-Id: I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8\n'}, {'number': 2, 'created': '2014-12-18 08:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6ec301f08f1817f0907137a2564f5049604a0a4e', 'message': 'Spec for neutron part of nova-network to neutron migration\n\nWIP: not well detailed yet, prototyping is in progress\n\nblueprint migration-from-nova-net\n\nChange-Id: I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8\n'}, {'number': 3, 'created': '2014-12-22 13:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5446552467ba81025fba8ea675ac92c79c6561bf', 'message': 'Spec for neutron part of nova-network to neutron migration\n\nWIP: not well detailed yet, prototyping is in progress\n\nblueprint migration-from-nova-net\n\nChange-Id: I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8\n'}, {'number': 4, 'created': '2015-01-12 16:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e5495b43203687b48ac70f35c63c44671535840e', 'message': 'Spec for neutron part of nova-network to neutron migration\n\nWIP: not enough detailed yet, prototyping is in progress\n\nblueprint migration-from-nova-net\n\nChange-Id: I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8\n'}, {'number': 5, 'created': '2015-01-16 01:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5ba40770ad211ae438e6fb75ea55b96244cb81bf', 'message': 'Spec for nova-network to neutron migration process\n\nThis change describes the overall proposed process and major work\nitems required.  More details are still needed.\n\nblueprint migration-from-nova-net\n\nChange-Id: I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8\n'}, {'number': 6, 'created': '2015-01-16 20:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/088890d34fa81cb7c03be74a4072ec8157278f91', 'message': 'Spec for nova-network to neutron migration process\n\nThis change describes the overall proposed process and major work\nitems required.  More details are still needed.\n\nblueprint migration-from-nova-net\n\nChange-Id: I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8\n'}, {'number': 7, 'created': '2015-01-19 15:18:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/547c0ba106905b44f72960f9c0c41f31fe4ff4e1', 'message': 'Spec for nova-network to neutron migration process\n\nThis change describes the overall proposed process and major work\nitems required.  More details are still needed.\n\nblueprint migration-from-nova-net\n\nChange-Id: I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8\n'}, {'number': 8, 'created': '2015-01-27 02:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4274c648e2e890fca4e0bcf24a266311aade3f22', 'message': 'Spec for nova-network to neutron migration process\n\nThis change describes the overall proposed process and major work\nitems required.  More implementation details are still needed.\n\nblueprint migration-from-nova-net\n\nChange-Id: I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8\n'}, {'number': 9, 'created': '2015-01-30 03:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b1eef309e69a6f9e2efdc20d4508d9df96404230', 'message': 'Spec for nova-network to neutron migration process\n\nThis change describes the overall proposed process and major work\nitems required.  More implementation details are still needed.\n\nblueprint migration-from-nova-net\n\nChange-Id: I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8\n'}, {'number': 10, 'created': '2015-01-30 04:21:47.000000000', 'files': ['specs/kilo/migration-from-nova-net.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a5daa9a500fd96c52c686e1077d8d0ac1b2f470a', 'message': 'Spec for nova-network to neutron migration process\n\nThis change describes the overall proposed process and major work\nitems required.  More implementation details are still needed.\n\nblueprint migration-from-nova-net\n\nChange-Id: I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8\n'}]",139,142456,a5daa9a500fd96c52c686e1077d8d0ac1b2f470a,83,35,10,5948,,,0,"Spec for nova-network to neutron migration process

This change describes the overall proposed process and major work
items required.  More implementation details are still needed.

blueprint migration-from-nova-net

Change-Id: I30f541b1a45777b4673de8dbfd12b0bf6fdd13a8
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/56/142456/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/migration-from-nova-net.rst'],1,c3c83f5363ff0485feab6941c0ce03c569802e4b,bp/migration-from-nova-net,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================= Neutron part of Nova-network to Neutron migration ================================================= https://blueprints.launchpad.net/neutron/+spec/migration-from-nova-net This blueprint describes the neutron part of the proposed way to migrate OpenStack deployments from nova-network to neutron. Problem Description =================== Nova-network deprecation process requires neutron to reach full feature parity with nova-network and as part of the parity plan there needs to be a way to automatically migrate existing deployments to neutron. This will likely require changes to both nova and neutron as well as support at the orchestration level. Current document will describe neutron part of the process. Proposed Change =============== Overall proposed migration process ---------------------------------- * Neutron step 0 * configure neutron to reverse proxy calls to nova (this spec) * Nova-compute restart one (a spec should be filed in nova) * Freeze nova's network state (probably by stopping nova-api, but we could be smarter than that if required) * run a special purpose nova management util to: * Update all nova-compute nodes to point neutron and remove nova-net agent for neutron nova aware L2 agent * move the tap devices from the nova-net bridge onto neutron managed bridge. This might have the side-effect of causing the network configuration to be rebuilt for some instances * API can be unfrozen at this time until ready for step 2 * Neutron restart two (another spec expected describing how data translation will be performed, how nova data models will be mapped to neutron) * Freeze nova's network state (probably by stopping nova-api, but we could be smarter than that if required) * Dump/translate/restore data from nova-net to neutron * Configure neutron to point to its own database * Unfreeze nova API *** Stopping point for linuxbridge to linuxbridge translation, or continue for rollout of new tech * Nova-compute restart two (out of scope of the current plan) * Configure OVS or new technology, ensure that proper ML2 driver is installed * Restart Layer2 agent on each hypervisor where next gen networking should be enabled Neutron proxy mode ------------------ The idea of the reverse proxy to nova is to ensure that we have a single source of truth for L3 information during migration. The main purpose is to ensure that the control plane elements can continue to function and that an operator could perform a rolling upgrade. New monolithic plugin will be created, able to work with nova db. It will be based on ML2 with linuxbridge. For neutron to be able to reference nova db during transition phase, there should be a contact point in nova. Nova REST API seems to not be enough, as for example, it does not even let us allocate IP addresses. So the proposal is to make neutron communicate with nova-conductor directly. Nova-conductor in it's turn brings the dependency on nova-objects. While nova-like objects will probably be introduced as part of core refactoring effort [1], we should still have an option to import and use both conductor api and nova-objects directly from nova codebase. Next thing to decide is to what degree should neutron use nova db? Simple answer is that we should not use neutron db at all but use only nova db. This is needed in order to support a rolling upgrade and rollbacks. The problem here is that using only nova db for all the stuff at first glance seems not feasible as it simply does not contain all the data neutron needs to function. So the proposal would be to limit neutron API to operations supported by nova-network. All operations that cannot be accomplished due to the lack of data should be forbidden during transition state. We can limit the scope even further by running neutron in read-only mode. For those nova-compute nodes that are moved under neutron, instances internal and external connectivity will be preserved by bridging nova and neutron l2 segments. This will be done as part of the process of reconfiguring nova computes for using neutron and moving instances' tap devices with nova management util (see ""Nova-compute restart one"" in overall process) Data Model Impact ----------------- Neutron in proxy mode will not work with neutron data models. REST API Impact --------------- Neutron REST API will be limited to operations supported by nova-net during transition phase. As a first step it is decided to run neutron in read-only mode. We can iterate on that later to extend allowed operations in proxy mode. Security Impact --------------- No security impact is expected Notifications Impact -------------------- None Other End User Impact --------------------- Neutron API will be limited while running in proxy mode. Performance Impact ------------------ Performance degradation is expected during transition phase as neutron will need to reference nova db. IPv6 Impact ----------- No special IPv6 impact is expected Other Deployer Impact --------------------- None Developer Impact ---------------- None Community Impact ---------------- Migration path must be provided in order to deprecate nova-net. Current doc describes the first step of the proposed plan. Alternatives ------------ * Live Migration [2] Stand up new hypervisors with neutron L2 agent and then live migrate instances one at a time. Does not work in clouds with no live migration * Cold Migration [2] Snapshot and then resume instance on another hypervisor with neutron (requires lots of storage and guest are offline during transition) Requires lots of storage * vif-by-vif [2, see revision 8] Install neutron and nova-net agents and then upgrade vifs one network at a time or upgrade one guest at a time Not 100% predictable where you are in the process, requires tooling Implementation ============== Assignee(s) ----------- obondarev Work Items ---------- * Make neutron able to access nova db (adopt nova objects and nova conductor api interface) * write new monolithic plugin, which should be able to work with (and only with) nova db Dependencies ============ The possible dependencies are: * neutron core refactoring [1] * pluggable IPAM [4] Testing ======= ""sideways"" grenade job proposal, by Clark Boylan: ""The way this job works is it sets up an ""old"" and ""new"" pair of master based cloud configs. The ""old"" side is configured to use nova-net and the ""new"" side is configured to use neutron. Grenade then fires up the ""old"" cloud, adds some things to it, runs some tests, shuts it down, ""upgrades"", then checks that things still work in the ""new"" cloud. My best guess is that most of the work here will need to be done in the ""upgrade"" section where we teach Grenade (and consequently everyone else) how to make this transition."" [3] Tempest Tests ------------- Existing tempest tests will be used during ""sideways"" grenade job (see above) Functional Tests ---------------- Functional tests should be added for neutron-nova-net proxy plugin API Tests --------- None Documentation Impact ==================== Documentation should be created/updated describing the whole neutron migration process in details. User Documentation ------------------ Developer Documentation ----------------------- None References ========== [1] https://review.openstack.org/140527 [2] https://review.openstack.org/101921 [3] http://lists.openstack.org/pipermail/openstack-dev/2014-October/047593.html [4] https://review.openstack.org/#/c/97967/ ",,257,0
openstack%2Fneutron~master~Idda448c9eaeb43e83d6b0f4b5da0239ccad3cdbd,openstack/neutron,master,Idda448c9eaeb43e83d6b0f4b5da0239ccad3cdbd,Apply Floating NAT only on the external interface,ABANDONED,2014-09-30 21:23:39.000000000,2015-05-21 21:28:23.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1131}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 7141}, {'_account_id': 7183}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-09-30 21:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a4b70f44c1c1c104b3eb7d19c9dca92310f524ad', 'message': 'Apply Floating NAT only on the external interface\n\nSpecify the external interface in the Floating IP\niptables NAT rules. This fixes issue when using\nFloating IP with extra routes.\n\nWIP:\n  - it has to be more tested\n  - unit has to be provided\n\nChange-Id: Idda448c9eaeb43e83d6b0f4b5da0239ccad3cdbd\nCloses-bug: #1375994\n'}, {'number': 2, 'created': '2014-10-10 08:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/07eee1b72f64a8c6b8ac9a275da4f62b87a0eae1', 'message': 'Apply Floating NAT only on the external interface\n\nSpecify the external interface in the Floating IP\niptables NAT rules. This fixes issue when using\nFloating IP with extra routes.\n\nChange-Id: Idda448c9eaeb43e83d6b0f4b5da0239ccad3cdbd\nCloses-bug: #1375994\n'}, {'number': 3, 'created': '2014-10-20 08:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca98a494ac78ce565da342d6da6b5f71090a7fcc', 'message': 'Apply Floating NAT only on the external interface\n\nSpecify the external interface in the Floating IP\niptables NAT rules. This fixes issue when using\nFloating IP with extra routes.\n\nChange-Id: Idda448c9eaeb43e83d6b0f4b5da0239ccad3cdbd\nCloses-bug: #1375994\n'}, {'number': 4, 'created': '2014-11-20 16:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/08f649aeef493093316f68d15c0536de1c47e48e', 'message': 'Apply Floating NAT only on the external interface\n\nSpecify the external interface in the Floating IP\niptables NAT rules. This fixes issue when using\nFloating IP with extra routes.\n\nChange-Id: Idda448c9eaeb43e83d6b0f4b5da0239ccad3cdbd\nCloses-bug: #1375994\n'}, {'number': 5, 'created': '2014-11-26 09:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fdd7f2a5a1e31c8224e5912e7a1000ed3fdbca44', 'message': 'Apply Floating NAT only on the external interface\n\nSpecify the external interface in the Floating IP\niptables NAT rules. This fixes issue when using\nFloating IP with extra routes.\n\nChange-Id: Idda448c9eaeb43e83d6b0f4b5da0239ccad3cdbd\nCloses-bug: #1375994\n'}, {'number': 6, 'created': '2014-11-28 09:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a20131196b9add7eca555b34f8baf80fe56da184', 'message': 'Apply Floating NAT only on the external interface\n\nSpecify the external interface in the Floating IP\niptables NAT rules. This fixes issue when using\nFloating IP with extra routes.\n\nChange-Id: Idda448c9eaeb43e83d6b0f4b5da0239ccad3cdbd\nCloses-bug: #1375994\n'}, {'number': 7, 'created': '2014-12-12 10:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/144b7bcf4eba22fb9fdf0a4eeb3d23900cbd88c9', 'message': 'Apply Floating NAT only on the external interface\n\nSpecify the external interface in the Floating IP\niptables NAT rules. This fixes issue when using\nFloating IP with extra routes.\n\nChange-Id: Idda448c9eaeb43e83d6b0f4b5da0239ccad3cdbd\nCloses-bug: #1375994\n'}, {'number': 8, 'created': '2015-01-22 13:33:28.000000000', 'files': ['neutron/agent/l3/agent.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b377f3e4d3d6f26b75271e4e1d5886695ac9027', 'message': 'Apply Floating NAT only on the external interface\n\nSpecify the external interface in the Floating IP\niptables NAT rules. This fixes issue when using\nFloating IP with extra routes.\n\nChange-Id: Idda448c9eaeb43e83d6b0f4b5da0239ccad3cdbd\nCloses-bug: #1375994\n'}]",5,125203,5b377f3e4d3d6f26b75271e4e1d5886695ac9027,172,34,8,7141,,,0,"Apply Floating NAT only on the external interface

Specify the external interface in the Floating IP
iptables NAT rules. This fixes issue when using
Floating IP with extra routes.

Change-Id: Idda448c9eaeb43e83d6b0f4b5da0239ccad3cdbd
Closes-bug: #1375994
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/125203/8 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3_agent.py'],1,a4b70f44c1c1c104b3eb7d19c9dca92310f524ad,restart," def process_router_floating_ip_nat_rules(self, ri, interface_name): for chain, rule in self.floating_forward_rules(fip_ip, fixed, interface_name): # Clear out all iptables rules for floating ips ri.iptables_manager.ipv4['nat'].clear_rules_by_tag('floating_ip') ri.iptables_manager.defer_apply_off() self.process_router_floating_ip_nat_rules(ri, interface_name) ri.iptables_manager.defer_apply_off() # Once NAT rules for floating IPs are safely in place # configure their addresses on the external gateway port def floating_forward_rules(self, floating_ip, fixed_ip, interface_name): return [('PREROUTING', '-i %s -d %s -j DNAT --to %s' % (interface_name, floating_ip, fixed_ip)), ('OUTPUT', '-o %s -d %s -j DNAT --to %s' % (interface_name, floating_ip, fixed_ip)), ('float-snat', '-o %s -s %s -j SNAT --to %s' % (interface_name, fixed_ip, floating_ip))]"," self.process_router_floating_ip_nat_rules(ri) ri.iptables_manager.defer_apply_off() # Once NAT rules for floating IPs are safely in place # configure their addresses on the external gateway port def process_router_floating_ip_nat_rules(self, ri): # Clear out all iptables rules for floating ips ri.iptables_manager.ipv4['nat'].clear_rules_by_tag('floating_ip') for chain, rule in self.floating_forward_rules(fip_ip, fixed): def floating_forward_rules(self, floating_ip, fixed_ip): return [('PREROUTING', '-d %s -j DNAT --to %s' % (floating_ip, fixed_ip)), ('OUTPUT', '-d %s -j DNAT --to %s' % (floating_ip, fixed_ip)), ('float-snat', '-s %s -j SNAT --to %s' % (fixed_ip, floating_ip))]",19,16
openstack%2Fneutron~master~Ib1ce939b0fb4ad81f67e2e2f552cbdcd4396ac83,openstack/neutron,master,Ib1ce939b0fb4ad81f67e2e2f552cbdcd4396ac83,Split out get_sync_data from L3_NAT_dbonly_mixin,ABANDONED,2014-10-09 05:42:31.000000000,2015-05-21 21:28:21.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 333}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-10-09 05:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2292638c301c0224e69365795183e43083f0d0ce', 'message': 'Split out get_sync_data from L3_NAT_dbonly_mixin\n\nThis patch splits out get_sync_data logic from L3_NAT_dbonly_mixin\nand L3_NAT_with_dvr_db_mixin.\nIf wanted, the split logic would be a part of\n(a subclass of) L3RpcCallback later.\n\nChange-Id: Ib1ce939b0fb4ad81f67e2e2f552cbdcd4396ac83\nCloses-Bug: #1177106\n'}, {'number': 2, 'created': '2014-10-10 03:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/060c4dacd0c26b772b23a7a7cd6c368a13041a8b', 'message': 'Split out get_sync_data from L3_NAT_dbonly_mixin\n\nThis patch splits out get_sync_data logic from L3_NAT_dbonly_mixin\nand L3_NAT_with_dvr_db_mixin.\nIf wanted, the split logic would be a part of\n(a subclass of) L3RpcCallback later.\n\nChange-Id: Ib1ce939b0fb4ad81f67e2e2f552cbdcd4396ac83\nCloses-Bug: #1177106\n'}, {'number': 3, 'created': '2014-10-10 05:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f59ee4d6730658da6beb08281a2aa09636aa62c2', 'message': 'Split out get_sync_data from L3_NAT_dbonly_mixin\n\nThis patch splits out get_sync_data logic from L3_NAT_dbonly_mixin\nand L3_NAT_with_dvr_db_mixin.\nIf wanted, the split logic would be a part of\n(a subclass of) L3RpcCallback later.\n\nChange-Id: Ib1ce939b0fb4ad81f67e2e2f552cbdcd4396ac83\nCloses-Bug: #1177106\n'}, {'number': 4, 'created': '2014-10-10 07:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/33e3eadb64aa9df7e86f9e97930c16316ae38d96', 'message': 'Split out get_sync_data from L3_NAT_dbonly_mixin\n\nThis patch splits out get_sync_data logic from L3_NAT_dbonly_mixin\nand L3_NAT_with_dvr_db_mixin.\nIf wanted, the split logic would be a part of\n(a subclass of) L3RpcCallback later.\n\nChange-Id: Ib1ce939b0fb4ad81f67e2e2f552cbdcd4396ac83\nCloses-Bug: #1177106\n'}, {'number': 5, 'created': '2014-10-10 09:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb6e64414f5fb88aec539815c3a228f9110d54b4', 'message': 'Split out get_sync_data from L3_NAT_dbonly_mixin\n\nThis patch splits out get_sync_data logic from L3_NAT_dbonly_mixin\nand L3_NAT_with_dvr_db_mixin.\nIf wanted, the split logic would be a part of\n(a subclass of) L3RpcCallback later.\n\nChange-Id: Ib1ce939b0fb4ad81f67e2e2f552cbdcd4396ac83\nCloses-Bug: #1177106\n'}, {'number': 6, 'created': '2015-01-20 23:05:05.000000000', 'files': ['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/db/l3_hamode_db.py', 'neutron/db/l3_dvr_db.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e65554223aebe36e5c472cd4795e723cdad9e4d5', 'message': 'Split out get_sync_data from L3_NAT_dbonly_mixin\n\nThis patch splits out get_sync_data logic from L3_NAT_dbonly_mixin\nand L3_NAT_with_dvr_db_mixin.\nIf wanted, the split logic would be a part of\n(a subclass of) L3RpcCallback later.\n\nChange-Id: Ib1ce939b0fb4ad81f67e2e2f552cbdcd4396ac83\nCloses-Bug: #1177106\n'}]",2,127140,e65554223aebe36e5c472cd4795e723cdad9e4d5,129,27,6,333,,,0,"Split out get_sync_data from L3_NAT_dbonly_mixin

This patch splits out get_sync_data logic from L3_NAT_dbonly_mixin
and L3_NAT_with_dvr_db_mixin.
If wanted, the split logic would be a part of
(a subclass of) L3RpcCallback later.

Change-Id: Ib1ce939b0fb4ad81f67e2e2f552cbdcd4396ac83
Closes-Bug: #1177106
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/127140/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/db/l3_hamode_db.py', 'neutron/db/l3_dvr_db.py', 'neutron/db/l3_db.py']",5,2292638c301c0224e69365795183e43083f0d0ce,bp/l3-plugin-for-routervm,"class L3RpcCallbackGetSyncData(object): @property def _core_plugin(self): return manager.NeutronManager.get_plugin() def __init__(self, l3_plugin): self._l3_plugin = l3_plugin def _build_routers_list(self, context, routers, gw_ports): for router in routers: gw_port_id = router['gw_port_id'] # Collect gw ports only if available if gw_port_id and gw_ports.get(gw_port_id): router['gw_port'] = gw_ports[gw_port_id] return routers def _get_sync_routers(self, context, router_ids=None, active=None): """"""Query routers and their gw ports for l3 agent. Query routers with the router_ids. The gateway ports, if any, will be queried too. l3 agent has an option to deal with only one router id. In addition, when we need to notify the agent the data about only one router (when modification of router, its interfaces, gw_port and floatingips), we will have router_ids. @param router_ids: the list of router ids which we want to query. if it is None, all of routers will be queried. @return: a list of dicted routers with dicted gw_port populated if any """""" filters = {'id': router_ids} if router_ids else {} if active is not None: filters['admin_state_up'] = [active] router_dicts = self._l3_plugin.get_routers(context, filters=filters) gw_port_ids = [] if not router_dicts: return [] for router_dict in router_dicts: gw_port_id = router_dict['gw_port_id'] if gw_port_id: gw_port_ids.append(gw_port_id) gw_ports = [] if gw_port_ids: gw_ports = dict((gw_port['id'], gw_port) for gw_port in self._get_sync_gw_ports(context, gw_port_ids)) # NOTE(armando-migliaccio): between get_routers and _get_sync_gw_ports # gw ports may get deleted, which means that router_dicts may contain # ports that gw_ports does not; we should rebuild router_dicts, but # letting the callee check for missing gw_ports sounds like a good # defensive approach regardless return self._build_routers_list(context, router_dicts, gw_ports) def _get_sync_floating_ips(self, context, router_ids): """"""Query floating_ips that relate to list of router_ids."""""" if not router_ids: return [] return self._l3_plugin.get_floatingips(context, {'router_id': router_ids}) def _get_sync_gw_ports(self, context, gw_port_ids): if not gw_port_ids: return [] filters = {'id': gw_port_ids} gw_ports = self._core_plugin.get_ports(context, filters) if gw_ports: self.populate_subnet_for_ports(context, gw_ports) return gw_ports def _get_sync_interfaces(self, context, router_ids, device_owners=None): """"""Query router interfaces that relate to list of router_ids."""""" device_owners = device_owners or [DEVICE_OWNER_ROUTER_INTF] if not router_ids: return [] filters = {'device_id': router_ids, 'device_owner': device_owners} interfaces = self._core_plugin.get_ports(context, filters) if interfaces: self.populate_subnet_for_ports(context, interfaces) return interfaces def populate_subnet_for_ports(self, context, ports): """"""Populate ports with subnet. These ports already have fixed_ips populated. """""" if not ports: return def each_port_with_ip(): for port in ports: fixed_ips = port.get('fixed_ips', []) if len(fixed_ips) > 1: LOG.info(_(""Ignoring multiple IPs on router port %s""), port['id']) continue elif not fixed_ips: # Skip ports without IPs, which can occur if a subnet # attached to a router is deleted LOG.info(_(""Skipping port %s as no IP is configure on it""), port['id']) continue yield (port, fixed_ips[0]) network_ids = set(p['network_id'] for p, _ in each_port_with_ip()) filters = {'network_id': [id for id in network_ids]} fields = ['id', 'cidr', 'gateway_ip', 'network_id', 'ipv6_ra_mode'] subnets_by_network = dict((id, []) for id in network_ids) for subnet in self._core_plugin.get_subnets(context, filters, fields): subnets_by_network[subnet['network_id']].append(subnet) for port, fixed_ip in each_port_with_ip(): port['extra_subnets'] = [] for subnet in subnets_by_network[port['network_id']]: subnet_info = {'id': subnet['id'], 'cidr': subnet['cidr'], 'gateway_ip': subnet['gateway_ip'], 'ipv6_ra_mode': subnet['ipv6_ra_mode']} if subnet['id'] == fixed_ip['subnet_id']: port['subnet'] = subnet_info else: port['extra_subnets'].append(subnet_info) def _process_router(self, context, router): pass def _process_routers(self, context, routers): routers_dict = {} for router in routers: routers_dict[router['id']] = router self._process_router(context, router) return routers_dict def _process_floating_ip(self, context, floating_ip): pass def _process_router_floating_ip(self, context, router, floating_ip): router.setdefault(l3_constants.FLOATINGIP_KEY, []).append(floating_ip) def _process_floating_ips(self, context, routers_dict, floating_ips): for floating_ip in floating_ips: self._process_floating_ip(context, floating_ip) router = routers_dict.get(floating_ip['router_id']) if router: self._process_router_floating_ip(context, router, floating_ip) def _process_interface(self, context, router, interface): router.setdefault(l3_constants.INTERFACE_KEY, []).append(interface) def _process_interfaces(self, context, routers_dict, interfaces): for interface in interfaces: router = routers_dict.get(interface['device_id']) if router: self._process_interface(context, router, interface) def _get_router_info_list(self, context, router_ids=None, active=None, device_owners=None): """"""Query routers and their related floating_ips, interfaces."""""" with context.session.begin(subtransactions=True): routers = self._get_sync_routers(context, router_ids=router_ids, active=active) router_ids = [router['id'] for router in routers] interfaces = self._get_sync_interfaces( context, router_ids, device_owners) floating_ips = self._get_sync_floating_ips(context, router_ids) return (routers, interfaces, floating_ips) def _process_sync_data(self, context, routers, interfaces, floating_ips): routers_dict = self._process_routers(context, routers) self._process_floating_ips(context, routers_dict, floating_ips) self._process_interfaces(context, routers_dict, interfaces) return routers_dict.values() def get_sync_data(self, context, router_ids=None, active=None): routers, interfaces, floating_ips = self._get_router_info_list( context, router_ids=router_ids, active=active) return self._process_sync_data( context, routers, interfaces, floating_ips) def _get_sync_data_callback_cls(self, rpc_callback_cls): rpc_callback = getattr(self, '_get_sync_data_callback_', None) if rpc_callback is None: self._get_sync_data_callback_ = rpc_callback_cls(self) return self._get_sync_data_callback_ @property def _get_sync_data_callback(self): return self._get_sync_data_callback_cls(L3RpcCallbackGetSyncData) return self._get_sync_data_callback.get_sync_data( context, router_ids, active)"," def _build_routers_list(self, context, routers, gw_ports): for router in routers: gw_port_id = router['gw_port_id'] # Collect gw ports only if available if gw_port_id and gw_ports.get(gw_port_id): router['gw_port'] = gw_ports[gw_port_id] return routers def _get_sync_routers(self, context, router_ids=None, active=None): """"""Query routers and their gw ports for l3 agent. Query routers with the router_ids. The gateway ports, if any, will be queried too. l3 agent has an option to deal with only one router id. In addition, when we need to notify the agent the data about only one router (when modification of router, its interfaces, gw_port and floatingips), we will have router_ids. @param router_ids: the list of router ids which we want to query. if it is None, all of routers will be queried. @return: a list of dicted routers with dicted gw_port populated if any """""" filters = {'id': router_ids} if router_ids else {} if active is not None: filters['admin_state_up'] = [active] router_dicts = self.get_routers(context, filters=filters) gw_port_ids = [] if not router_dicts: return [] for router_dict in router_dicts: gw_port_id = router_dict['gw_port_id'] if gw_port_id: gw_port_ids.append(gw_port_id) gw_ports = [] if gw_port_ids: gw_ports = dict((gw_port['id'], gw_port) for gw_port in self.get_sync_gw_ports(context, gw_port_ids)) # NOTE(armando-migliaccio): between get_routers and get_sync_gw_ports # gw ports may get deleted, which means that router_dicts may contain # ports that gw_ports does not; we should rebuild router_dicts, but # letting the callee check for missing gw_ports sounds like a good # defensive approach regardless return self._build_routers_list(context, router_dicts, gw_ports) def _get_sync_floating_ips(self, context, router_ids): """"""Query floating_ips that relate to list of router_ids."""""" if not router_ids: return [] return self.get_floatingips(context, {'router_id': router_ids}) def get_sync_gw_ports(self, context, gw_port_ids): if not gw_port_ids: return [] filters = {'id': gw_port_ids} gw_ports = self._core_plugin.get_ports(context, filters) if gw_ports: self._populate_subnet_for_ports(context, gw_ports) return gw_ports def get_sync_interfaces(self, context, router_ids, device_owners=None): """"""Query router interfaces that relate to list of router_ids."""""" device_owners = device_owners or [DEVICE_OWNER_ROUTER_INTF] if not router_ids: return [] filters = {'device_id': router_ids, 'device_owner': device_owners} interfaces = self._core_plugin.get_ports(context, filters) if interfaces: self._populate_subnet_for_ports(context, interfaces) return interfaces def _populate_subnet_for_ports(self, context, ports): """"""Populate ports with subnet. These ports already have fixed_ips populated. """""" if not ports: return def each_port_with_ip(): for port in ports: fixed_ips = port.get('fixed_ips', []) if len(fixed_ips) > 1: LOG.info(_(""Ignoring multiple IPs on router port %s""), port['id']) continue elif not fixed_ips: # Skip ports without IPs, which can occur if a subnet # attached to a router is deleted LOG.info(_(""Skipping port %s as no IP is configure on it""), port['id']) continue yield (port, fixed_ips[0]) network_ids = set(p['network_id'] for p, _ in each_port_with_ip()) filters = {'network_id': [id for id in network_ids]} fields = ['id', 'cidr', 'gateway_ip', 'network_id', 'ipv6_ra_mode'] subnets_by_network = dict((id, []) for id in network_ids) for subnet in self._core_plugin.get_subnets(context, filters, fields): subnets_by_network[subnet['network_id']].append(subnet) for port, fixed_ip in each_port_with_ip(): port['extra_subnets'] = [] for subnet in subnets_by_network[port['network_id']]: subnet_info = {'id': subnet['id'], 'cidr': subnet['cidr'], 'gateway_ip': subnet['gateway_ip'], 'ipv6_ra_mode': subnet['ipv6_ra_mode']} if subnet['id'] == fixed_ip['subnet_id']: port['subnet'] = subnet_info else: port['extra_subnets'].append(subnet_info) def _process_router(self, context, router): pass def _process_routers(self, context, routers): routers_dict = {} for router in routers: routers_dict[router['id']] = router self._process_router(context, router) return routers_dict def _process_floating_ip(self, context, floating_ip): pass def _process_router_floating_ip(self, context, router, floating_ip): router.setdefault(l3_constants.FLOATINGIP_KEY, []).append(floating_ip) def _process_floating_ips(self, context, routers_dict, floating_ips): for floating_ip in floating_ips: self._process_floating_ip(context, floating_ip) router = routers_dict.get(floating_ip['router_id']) if router: self._process_router_floating_ip(context, router, floating_ip) def _process_interface(self, context, router, interface): router.setdefault(l3_constants.INTERFACE_KEY, []).append(interface) def _process_interfaces(self, context, routers_dict, interfaces): for interface in interfaces: router = routers_dict.get(interface['device_id']) if router: self._process_interface(context, router, interface) def _get_router_info_list(self, context, router_ids=None, active=None, device_owners=None): """"""Query routers and their related floating_ips, interfaces."""""" with context.session.begin(subtransactions=True): routers = self._get_sync_routers(context, router_ids=router_ids, active=active) router_ids = [router['id'] for router in routers] interfaces = self.get_sync_interfaces( context, router_ids, device_owners) floating_ips = self._get_sync_floating_ips(context, router_ids) return (routers, interfaces, floating_ips) def _process_sync_data(self, context, routers, interfaces, floating_ips): routers_dict = self._process_routers(context, routers) self._process_floating_ips(context, routers_dict, floating_ips) self._process_interfaces(context, routers_dict, interfaces) return routers_dict.values() routers, interfaces, floating_ips = self._get_router_info_list( context, router_ids=router_ids, active=active) return self._process_sync_data( context, routers, interfaces, floating_ips)",300,264
openstack%2Fneutron~master~I12d54159da3fed5223ae97dd01ef0b6948c2915d,openstack/neutron,master,I12d54159da3fed5223ae97dd01ef0b6948c2915d,Add sanity check for wrong MTU when using tunnels,ABANDONED,2014-10-21 09:11:24.000000000,2015-05-21 21:28:18.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 1689}, {'_account_id': 2874}, {'_account_id': 3217}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5756}, {'_account_id': 6524}, {'_account_id': 6598}, {'_account_id': 6659}, {'_account_id': 6698}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10061}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10257}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 12890}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2014-10-21 09:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5a8e1519a6805a310d6f573ee1b0ac31588ab90c', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN, GRE and STT are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, the packets\nwill drop somewhere along the way, causing problems which can be\nsomewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 2, 'created': '2014-11-03 11:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7ab07e80dad964281a59c8e2465f6214c8483bbe', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN, GRE and STT are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 3, 'created': '2014-11-17 07:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e5929d20975be1fa178d6bf44b59051bba6bc206', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN, GRE and STT are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 4, 'created': '2014-11-17 08:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5d9a54b79727d472ab20f3a4a0e058c46b24f8bd', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN, GRE and STT are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 5, 'created': '2014-11-17 11:57:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e4297b3c96b071a3e251833fb5125fd957d4f7e', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN, GRE and STT are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 6, 'created': '2015-01-13 08:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b537f6cabdc72342b3afdd701f327eda8f244971', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN, GRE and STT are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 7, 'created': '2015-01-13 09:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a0c572b7a57638424caae7a95d2a6e95231f60ae', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN, GRE and STT are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 8, 'created': '2015-01-14 12:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d2beac509aecf04b28d499799b4abc4bdde8d42', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN, GRE and STT are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 9, 'created': '2015-01-19 16:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/862edba89d598d97ef3ba6d2aa66d1d372c2de8f', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN and GRE are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 10, 'created': '2015-01-20 07:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/537d72c3d20571f0552927675b5c8cc8604e3d19', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN and GRE are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 11, 'created': '2015-01-21 09:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f8d1e2f5600c7945eb61de09640d60c1ca51cf03', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN and GRE are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 12, 'created': '2015-03-03 16:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d9047827275bc7387c295d25a83b868a8b900d09', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN and GRE are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 13, 'created': '2015-03-05 06:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0cd5f423e927f9892ca4d6917e1f7056f07b17a2', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN and GRE are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (24 bytes) will be added, causing the actual sent\npacket to be 1524 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 14, 'created': '2015-03-05 09:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/657be02549d3788066145de92e8da8eb8a4e6ce6', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN and GRE are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (42 bytes) will be added, causing the actual sent\npacket to be 1542 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 15, 'created': '2015-03-18 09:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5d4a5ed3fe729e7b05ccb1efd75edce25051794f', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN and GRE are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (42 bytes) will be added, causing the actual sent\npacket to be 1542 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}, {'number': 16, 'created': '2015-03-18 10:05:43.000000000', 'files': ['neutron/cmd/sanity/checks.py', 'neutron/tests/functional/sanity/test_sanity.py', 'neutron/cmd/sanity_check.py', 'neutron/tests/unit/test_sanity_checks.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a27fad82f6acf55c53c06999dd2a2d97cb61ffab', 'message': ""Add sanity check for wrong MTU when using tunnels\n\nWhen setting up a multi-node setup which uses tunnels, packets from one\nnode to the other is encapsulated in tunnels (VXLAN and GRE are the\ncurrent options offered), which causes the packets to increase in size.\nIn other words, when using GRE, a packet of size 1500 will be changed\nand the GRE header (42 bytes) will be added, causing the actual sent\npacket to be 1542 bytes.\n\nIn case the underlying infrastructure's MTU is set to 1500, there may be\na performance degradation due to the potential fragmentation of frames,\ncausing problems which can be somewhat difficult to debug.\n\nThis patch adds a sanity check for whether or not the physical\ninterface's MTU is high enough (for our previous example, 1524 is\nneeded), and if not a warning is printed. This is only a warning since\nthere could be other solutions (for example, the instance's MTU can be\nlowered to a suitable size manually, fixing the problem).\n\nCloses-bug: #1375815\nChange-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d\n""}]",178,129852,a27fad82f6acf55c53c06999dd2a2d97cb61ffab,324,51,16,12444,,,0,"Add sanity check for wrong MTU when using tunnels

When setting up a multi-node setup which uses tunnels, packets from one
node to the other is encapsulated in tunnels (VXLAN and GRE are the
current options offered), which causes the packets to increase in size.
In other words, when using GRE, a packet of size 1500 will be changed
and the GRE header (42 bytes) will be added, causing the actual sent
packet to be 1542 bytes.

In case the underlying infrastructure's MTU is set to 1500, there may be
a performance degradation due to the potential fragmentation of frames,
causing problems which can be somewhat difficult to debug.

This patch adds a sanity check for whether or not the physical
interface's MTU is high enough (for our previous example, 1524 is
needed), and if not a warning is printed. This is only a warning since
there could be other solutions (for example, the instance's MTU can be
lowered to a suitable size manually, fixing the problem).

Closes-bug: #1375815
Change-Id: I12d54159da3fed5223ae97dd01ef0b6948c2915d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/52/129852/16 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/cmd/sanity/checks.py', 'neutron/cmd/sanity_check.py']",2,5a8e1519a6805a310d6f573ee1b0ac31588ab90c,bug/1375815,"from neutron.openstack.common.gettextutils import _LE, _LWdef check_mtu(): result = checks.is_mtu_valid( root_helper=cfg.CONF.AGENT.root_helper, local_ip=cfg.CONF.OVS.local_ip, tunnel_types=cfg.CONF.AGENT.tunnel_types) if not result: params = checks.TUNNEL_OVERHEAD.copy() params['local_ip'] = cfg.CONF.OVS.local_ip LOG.warning(_LW('The MTU of the physical interface holding IP ' '%(local_ip)s is not high enough and should be ' 'raised. Please note that the overhead for VXLAN is ' '%(vxlan)s, the overhead for GRE is %(gre)s and the ' 'overhead for STT is %(stt)s.'), params) return result BoolOptCallback('check_mtu', check_mtu, default=False, help=_('Check for MTU inconsistencies')), cfg.CONF.set_override('check_mtu', True) if __name__ == '__main__': main()",from neutron.openstack.common.gettextutils import _LE,54,1
openstack%2Fneutron~master~Ibcf0a08a624a08ceb3da4c3f4df021bbed9bf453,openstack/neutron,master,Ibcf0a08a624a08ceb3da4c3f4df021bbed9bf453,Fix neutron.tests.tempest.config use of cfg.CONF,ABANDONED,2015-04-01 17:49:50.000000000,2015-05-21 21:28:14.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 6524}, {'_account_id': 7016}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-04-01 17:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cb0a6de1806aea9d07599d25ec4d76a3e392ea8a', 'message': ""Fix neutron.tests.tempest.config use of cfg.CONF\n\nTempest configuration previously used the oslo_config global cfg.CONF,\nwhich conflicted with Neutron's use of the same global.  This change\nmoves tempest config to use a local ConfigOpts instance instead of the\nglobal to eliminate the potential for conflict.\n\nChange-Id: Ibcf0a08a624a08ceb3da4c3f4df021bbed9bf453\n""}, {'number': 2, 'created': '2015-04-01 21:37:22.000000000', 'files': ['neutron/tests/retargetable/client_fixtures.py', 'neutron/tests/retargetable/rest_fixture.py', 'neutron/tests/tempest/README.rst', 'neutron/tests/retargetable/base.py', 'neutron/tests/tempest/config.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/afbba5b735dec03d9416e9c0706944ccbc44db4a', 'message': ""Fix neutron.tests.tempest.config use of cfg.CONF\n\nTempest configuration previously used the oslo_config global cfg.CONF,\nwhich conflicted with Neutron's use of the same global.  This change\nmoves tempest config to use a local ConfigOpts instance instead of the\nglobal to eliminate the potential for conflict.\n\nChange-Id: Ibcf0a08a624a08ceb3da4c3f4df021bbed9bf453\n""}]",2,169856,afbba5b735dec03d9416e9c0706944ccbc44db4a,45,27,2,2035,,,0,"Fix neutron.tests.tempest.config use of cfg.CONF

Tempest configuration previously used the oslo_config global cfg.CONF,
which conflicted with Neutron's use of the same global.  This change
moves tempest config to use a local ConfigOpts instance instead of the
global to eliminate the potential for conflict.

Change-Id: Ibcf0a08a624a08ceb3da4c3f4df021bbed9bf453
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/169856/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/retargetable/client_fixtures.py', 'neutron/tests/retargetable/rest_fixture.py', 'neutron/tests/tempest/README.rst', 'neutron/tests/retargetable/base.py', 'neutron/tests/tempest/config.py']",5,cb0a6de1806aea9d07599d25ec4d76a3e392ea8a,169856,"# Use a local ConfigOpts instance to avoid conflicting with Neutron's # use of cfg.CONF _CONF = cfg.ConfigOpts() register_opt_group(_CONF, g, o) return getattr(_CONF, attr) self.auth = _CONF.auth self.compute = _CONF.compute self.compute_feature_enabled = _CONF['compute-feature-enabled'] self.identity = _CONF.identity self.identity_feature_enabled = _CONF['identity-feature-enabled'] self.image = _CONF.image self.image_feature_enabled = _CONF['image-feature-enabled'] self.network = _CONF.network self.network_feature_enabled = _CONF['network-feature-enabled'] self.volume = _CONF.volume self.volume_feature_enabled = _CONF['volume-feature-enabled'] self.object_storage = _CONF['object-storage'] self.object_storage_feature_enabled = _CONF[ self.database = _CONF.database self.orchestration = _CONF.orchestration self.messaging = _CONF.messaging self.telemetry = _CONF.telemetry self.dashboard = _CONF.dashboard self.data_processing = _CONF.data_processing self.data_processing_feature_enabled = _CONF[ self.boto = _CONF.boto self.stress = _CONF.stress self.scenario = _CONF.scenario self.service_available = _CONF.service_available self.debug = _CONF.debug self.baremetal = _CONF.baremetal self.input_scenario = _CONF['input-scenario'] self.cli = _CONF.cli self.negative = _CONF.negative _CONF.set_default('domain_name', self.identity.admin_domain_name, group='identity') _CONF.set_default('alt_domain_name', self.identity.admin_domain_name, group='identity') logging.register_options(_CONF) if os.path.isfile(path): _CONF([], project='tempest', default_config_files=config_files) else: _CONF([], project='tempest') logging.setup(_CONF, 'tempest') _CONF.log_opt_values(LOG, std_logging.DEBUG)"," register_opt_group(cfg.CONF, g, o) return getattr(cfg.CONF, attr) self.auth = cfg.CONF.auth self.compute = cfg.CONF.compute self.compute_feature_enabled = cfg.CONF['compute-feature-enabled'] self.identity = cfg.CONF.identity self.identity_feature_enabled = cfg.CONF['identity-feature-enabled'] self.image = cfg.CONF.image self.image_feature_enabled = cfg.CONF['image-feature-enabled'] self.network = cfg.CONF.network self.network_feature_enabled = cfg.CONF['network-feature-enabled'] self.volume = cfg.CONF.volume self.volume_feature_enabled = cfg.CONF['volume-feature-enabled'] self.object_storage = cfg.CONF['object-storage'] self.object_storage_feature_enabled = cfg.CONF[ self.database = cfg.CONF.database self.orchestration = cfg.CONF.orchestration self.messaging = cfg.CONF.messaging self.telemetry = cfg.CONF.telemetry self.dashboard = cfg.CONF.dashboard self.data_processing = cfg.CONF.data_processing self.data_processing_feature_enabled = cfg.CONF[ self.boto = cfg.CONF.boto self.stress = cfg.CONF.stress self.scenario = cfg.CONF.scenario self.service_available = cfg.CONF.service_available self.debug = cfg.CONF.debug self.baremetal = cfg.CONF.baremetal self.input_scenario = cfg.CONF['input-scenario'] self.cli = cfg.CONF.cli self.negative = cfg.CONF.negative cfg.CONF.set_default('domain_name', self.identity.admin_domain_name, group='identity') cfg.CONF.set_default('alt_domain_name', self.identity.admin_domain_name, group='identity') logging.register_options(cfg.CONF) if os.path.isfile(path): cfg.CONF([], project='tempest', default_config_files=config_files) else: cfg.CONF([], project='tempest') logging.setup(cfg.CONF, 'tempest') cfg.CONF.log_opt_values(LOG, std_logging.DEBUG)",96,118
openstack%2Fneutron~master~I956dcb2a1a0d927cb4331df91a8bfeac0694e9fe,openstack/neutron,master,I956dcb2a1a0d927cb4331df91a8bfeac0694e9fe,Forbid update router port to have more than one ip,ABANDONED,2015-01-16 03:57:52.000000000,2015-05-21 21:28:12.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 6524}, {'_account_id': 7293}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-16 03:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55f58d74770406eb9898099a7553a6cb94b9a995', 'message': 'Forbid update router port to have more than one ip\n\nA port with more than one ips is not allowed to be attached to a\nrouter, so we should also forbid updating a router port to have\nmore then one ips.\n\nChange-Id: I956dcb2a1a0d927cb4331df91a8bfeac0694e9fe\nCloses-Bug: #1410688\n'}, {'number': 2, 'created': '2015-01-21 02:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/042af10718eba7546e065c024e087423ed3940e0', 'message': 'Forbid update router port to have more than one ip\n\nA port with more than one ips is not allowed to be attached to a\nrouter, so we should also forbid updating a router port to have\nmore then one ips.\n\nChange-Id: I956dcb2a1a0d927cb4331df91a8bfeac0694e9fe\nCloses-Bug: #1410688\n'}, {'number': 3, 'created': '2015-02-06 03:39:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/77906b1c68d8def78c5b037697ae25fdc643a99e', 'message': 'Forbid update router port to have more than one ip\n\nA port with more than one ips is not allowed to be attached to a\nrouter, so we should also forbid updating a router port to have\nmore then one ips.\n\nChange-Id: I956dcb2a1a0d927cb4331df91a8bfeac0694e9fe\nCloses-Bug: #1410688\n'}, {'number': 4, 'created': '2015-02-06 07:34:10.000000000', 'files': ['neutron/tests/unit/test_l3_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b41077e310852de70d05f000851987989435fd19', 'message': 'Forbid update router port to have more than one ip\n\nA port with more than one ips is not allowed to be attached to a\nrouter, so we should also forbid updating a router port to have\nmore then one ips.\n\nChange-Id: I956dcb2a1a0d927cb4331df91a8bfeac0694e9fe\nCloses-Bug: #1410688\n'}]",11,147739,b41077e310852de70d05f000851987989435fd19,83,27,4,12076,,,0,"Forbid update router port to have more than one ip

A port with more than one ips is not allowed to be attached to a
router, so we should also forbid updating a router port to have
more then one ips.

Change-Id: I956dcb2a1a0d927cb4331df91a8bfeac0694e9fe
Closes-Bug: #1410688
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/147739/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,55f58d74770406eb9898099a7553a6cb94b9a995,bug/1410688, if (len(new_ips) > 1 and device_owner == constants.DEVICE_OWNER_ROUTER_INTF): msg = _('Cannot assign more than one fixed ips to router port') raise n_exc.InvalidInput(error_message=msg) ,,5,0
openstack%2Fneutron~master~Ib5434ab8a2ccfefcccc28942827900df91d25c54,openstack/neutron,master,Ib5434ab8a2ccfefcccc28942827900df91d25c54,Test attaching router to IPv6 subnets,ABANDONED,2015-04-01 15:49:59.000000000,2015-05-21 21:28:09.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4656}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6698}, {'_account_id': 8767}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10068}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 12378}, {'_account_id': 12581}, {'_account_id': 12632}, {'_account_id': 13372}, {'_account_id': 13409}, {'_account_id': 13642}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15637}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-04-01 15:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9278b995ec3fd9492d9b854df787739641a66dc2', 'message': 'Test attaching router to IPv6 subnets\n\nTest attaching router interface to SLAAC networks when\nits IP is set explicitly during subnet setup.\nTest attaching router interface to SLAAC networks when\nits IP is set by default by Openstack during subnet setup.\n\nOriginated by Sergey Shnaidman.\n\nCloses-Bug: 1394112\n\nChange-Id: Ib5434ab8a2ccfefcccc28942827900df91d25c54\n'}, {'number': 2, 'created': '2015-04-01 15:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99b818d4cbfa8c9735e0dbc52a735954c78bdd4b', 'message': 'Test attaching router to IPv6 subnets\n\nTest attaching router interface to SLAAC networks when\nits IP is set explicitly during subnet setup.\nTest attaching router interface to SLAAC networks when\nits IP is set by default by Openstack during subnet setup.\n\nOriginated by Sergey Shnaidman.\n\nCloses-Bug: 1394112\n\nChange-Id: Ib5434ab8a2ccfefcccc28942827900df91d25c54\n'}, {'number': 3, 'created': '2015-04-06 13:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/11b25b414cc55c09287fe672ffde6f019fe9bc85', 'message': 'Test attaching router to IPv6 subnets\n\nTest attaching router interface to SLAAC networks when\nits IP is set explicitly during subnet setup.\nTest attaching router interface to SLAAC networks when\nits IP is set by default by Openstack during subnet setup.\n\nOriginated by Sergey Shnaidman.\n\nCloses-Bug: 1394112\n\nChange-Id: Ib5434ab8a2ccfefcccc28942827900df91d25c54\n'}, {'number': 4, 'created': '2015-04-06 13:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc8b0f0d6d865bd6dea0c627a49fb6a23458a8ba', 'message': 'Test attaching router to IPv6 subnets\n\nTest attaching router interface to SLAAC networks when\nits IP is set explicitly during subnet setup.\nTest attaching router interface to SLAAC networks when\nits IP is set by default by Openstack during subnet setup.\n\nOriginated by Sergey Shnaidman.\n\nCloses-Bug: 1394112\n\nChange-Id: Ib5434ab8a2ccfefcccc28942827900df91d25c54\n'}, {'number': 5, 'created': '2015-04-06 14:06:13.000000000', 'files': ['test-requirements.txt', 'neutron/tests/api/test_dhcp_ipv6.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4249b2c2d39cca027d1a7a0711c79825e8e322ca', 'message': 'Test attaching router to IPv6 subnets\n\n1. Test attaching router interface to SLAAC networks when\nits IP is set explicitly during subnet setup.\n2. Same as p. 1 but for IP is set by default during subnet setup.\n\nCo-Authored-By: Sergey Shnaidman <sshnaidm@cisco.com> \n\nCloses-Bug: 1394112\n\nChange-Id: Ib5434ab8a2ccfefcccc28942827900df91d25c54'}]",16,169817,4249b2c2d39cca027d1a7a0711c79825e8e322ca,107,35,5,13372,,,0,"Test attaching router to IPv6 subnets

1. Test attaching router interface to SLAAC networks when
its IP is set explicitly during subnet setup.
2. Same as p. 1 but for IP is set by default during subnet setup.

Co-Authored-By: Sergey Shnaidman <sshnaidm@cisco.com> 

Closes-Bug: 1394112

Change-Id: Ib5434ab8a2ccfefcccc28942827900df91d25c54",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/169817/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/tempest/api/network/test_dhcp_ipv6.py'],1,9278b995ec3fd9492d9b854df787739641a66dc2,bug/1394112," super(NetworksTestDHCPv6, cls).skip_checks() def _create_custom_subnet(self, kwargs): # The gateway is not set when creating this subnet net_cidr = netaddr.IPNetwork(CONF.network.tenant_network_v6_cidr) mask_bits = CONF.network.tenant_network_v6_mask_bits cidr = str(next(iter(net_cidr.subnet(mask_bits)))) kwargs.update({ 'network_id': self.network['id'], 'cidr': cidr}) body = self.client.create_subnet(**kwargs) self.subnets.append(body['subnet']) return body['subnet'] @test.idempotent_id('a8df74bb-97a5-4998-8206-6eb295f82675') def test_dhcp_stateless_router_explicit_gw(self): """"""With all options below the router interface shall receive first allocated address from created subnet, because gateway is set explicitly to particular IP in 'create_subnet' function. All ports however receive SLAAC addresses. """""" for ra_mode, add_mode in ( ('dhcpv6-stateless', 'dhcpv6-stateless'), ('slaac', 'slaac') ): kwargs = {'ipv6_ra_mode': ra_mode, 'ipv6_address_mode': add_mode} subnet, router_port = self._create_subnet_router(kwargs) router_port_ip = router_port['fixed_ips'][0]['ip_address'] port = self.create_port(self.network) port_ip = port['fixed_ips'][0]['ip_address'] self._clean_network() eui64_ip = data_utils.get_ipv6_addr_by_EUI64( subnet['cidr'], port['mac_address']).format() self.assertEqual(port_ip, eui64_ip, (""Port IP %s is not the same as EUI64 "" ""address: %s"") % (port_ip, eui64_ip)) self.assertEqual(router_port_ip, subnet['gateway_ip'], (""Router IP %s is not as gateway IP from "" ""subnets data: %s"") % ( router_port_ip, subnet['gateway_ip'])) @test.idempotent_id('d8ff015d-d2f2-4cb4-8b8c-a8fc052ea971') def test_dhcp_stateless_router_default_gw(self): """"""With all options below the router interface shall receive default address of subnet gateway, because gateway is not set explicitly in local function '_create_custom_subnet'. All ports however receive SLAAC addresses. """""" for ra_mode, add_mode in ( ('dhcpv6-stateless', 'dhcpv6-stateless'), ('slaac', 'slaac') ): kwargs = {'ipv6_ra_mode': ra_mode, 'ipv6_address_mode': add_mode, 'ip_version': 6} subnet = self._create_custom_subnet(kwargs) router = self.create_router( router_name=data_utils.rand_name(""routerv6-""), admin_state_up=True) router_port = self.create_router_interface(router['id'], subnet['id']) body = self.client.show_port(router_port['port_id']) router_port_ip = body['port']['fixed_ips'][0]['ip_address'] port = self.create_port(self.network) port_ip = port['fixed_ips'][0]['ip_address'] self._clean_network() eui64_ip = data_utils.get_ipv6_addr_by_EUI64( subnet['cidr'], port['mac_address']).format() self.assertEqual(port_ip, eui64_ip, (""Port IP %s is not the same as EUI64 "" ""address: %s"") % (port_ip, eui64_ip)) self.assertEqual(router_port_ip, subnet['gateway_ip'], (""Router IP %s is not as gateway IP from "" ""subnets data: %s"") % ( router_port_ip, subnet['gateway_ip'])) ",,79,0
openstack%2Fneutron~master~Iec2da682ab645b90d5d3fc548c3ca4b15d62c011,openstack/neutron,master,Iec2da682ab645b90d5d3fc548c3ca4b15d62c011,InvalidQuotaValue should use error code 403,ABANDONED,2014-12-24 09:06:03.000000000,2015-05-21 21:28:07.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 12040}, {'_account_id': 12140}, {'_account_id': 12683}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-24 09:06:03.000000000', 'files': ['neutron/tests/unit/test_quota_ext.py', 'neutron/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/facc12ee2644e721a67e014e303d44b3a9e4846e', 'message': ""InvalidQuotaValue should use error code 403\n\nThe neutron InvalidQuotaValue exception extends\nConflict (HttpConflict, Error code 409)  but\nthat doesn't really make sense for this exception.\nIt should be rather 403 (Forbidden).\n\nSo updated the code to raise 403 instead of 409\nand added a test case for the same.\n\nChange-Id: Iec2da682ab645b90d5d3fc548c3ca4b15d62c011\nCloses-Bug: #1405099\n""}]",2,143801,facc12ee2644e721a67e014e303d44b3a9e4846e,40,26,1,12140,,,0,"InvalidQuotaValue should use error code 403

The neutron InvalidQuotaValue exception extends
Conflict (HttpConflict, Error code 409)  but
that doesn't really make sense for this exception.
It should be rather 403 (Forbidden).

So updated the code to raise 403 instead of 409
and added a test case for the same.

Change-Id: Iec2da682ab645b90d5d3fc548c3ca4b15d62c011
Closes-Bug: #1405099
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/143801/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_quota_ext.py', 'neutron/common/exceptions.py']",2,facc12ee2644e721a67e014e303d44b3a9e4846e,bug/1405099,class InvalidQuotaValue(NotAuthorized):,class InvalidQuotaValue(Conflict):,5,1
openstack%2Fneutron~master~I9713a607a85d4bdcb9730d00cf8551d142acfb0f,openstack/neutron,master,I9713a607a85d4bdcb9730d00cf8551d142acfb0f,Use left join for security group retrieve,ABANDONED,2015-02-15 07:30:46.000000000,2015-05-21 21:28:04.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 7805}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 11822}, {'_account_id': 12040}, {'_account_id': 12076}, {'_account_id': 12683}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-02-15 07:30:46.000000000', 'files': ['neutron/tests/unit/test_security_groups_rpc.py', 'neutron/db/securitygroups_rpc_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/645bdddf7ecb894aade62293ecdd5d491904c28a', 'message': 'Use left join for security group retrieve\n\nCurrently server joins SecurityGroupPortBinding and SecurityGroupRule\ntable to retrieve security group rules of a port, so an empty security\ngroup is not returned. This will cause trouble if enhanced RPC is\nenabled. The security_groups field in the RPC response will not\ncontain the id of the empty security group so agent will not update\nthis security group. Thus it will not take effect deleting the last\nrule in a security group.\n\nThis patch left joins SecurityGroupPortBinding and SecurityGroupRule\ntable to ensure that empty security group can also be returned.\n\nChange-Id: I9713a607a85d4bdcb9730d00cf8551d142acfb0f\nCloses-Bug: #1420056\n'}]",2,156032,645bdddf7ecb894aade62293ecdd5d491904c28a,28,25,1,12076,,,0,"Use left join for security group retrieve

Currently server joins SecurityGroupPortBinding and SecurityGroupRule
table to retrieve security group rules of a port, so an empty security
group is not returned. This will cause trouble if enhanced RPC is
enabled. The security_groups field in the RPC response will not
contain the id of the empty security group so agent will not update
this security group. Thus it will not take effect deleting the last
rule in a security group.

This patch left joins SecurityGroupPortBinding and SecurityGroupRule
table to ensure that empty security group can also be returned.

Change-Id: I9713a607a85d4bdcb9730d00cf8551d142acfb0f
Closes-Bug: #1420056
",git fetch https://review.opendev.org/openstack/neutron refs/changes/32/156032/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/securitygroups_rpc_base.py', 'neutron/tests/unit/test_security_groups_rpc.py']",2,645bdddf7ecb894aade62293ecdd5d491904c28a,bug/1420056," self.assertItemsEqual(port_rpc['security_group_rules'], expected) self.assertItemsEqual(port_rpc['security_group_rules'], expected)"," self.assertEqual(port_rpc['security_group_rules'], expected) self.assertEqual(port_rpc['security_group_rules'], expected)",15,9
openstack%2Fpython-neutronclient~master~Ida125c6e03e0e40ba62be0da2e7b4ce37c0d4c03,openstack/python-neutronclient,master,Ida125c6e03e0e40ba62be0da2e7b4ce37c0d4c03,Creating separate folder for nuage extensions,ABANDONED,2015-03-18 17:53:39.000000000,2015-05-21 21:27:58.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 8124}, {'_account_id': 9380}, {'_account_id': 10980}]","[{'number': 1, 'created': '2015-03-18 17:53:39.000000000', 'files': ['neutronclient/neutron/v2_0/nuage/__init__.py', 'neutronclient/neutron/v2_0/nuage/netpartition.py', 'neutronclient/shell.py', 'neutronclient/tests/unit/test_cli20_nuage_netpartition.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/a8ba012ec2f52d9c5f62113c22cfa71163082cc5', 'message': 'Creating separate folder for nuage extensions\n\nWe will be adding multiple files related to nuage\nextensions, so it would be nice to have a separate\nnuage folder. Also moving the current extension file\nnetpartition.py to the new folder.\n\nChange-Id: Ida125c6e03e0e40ba62be0da2e7b4ce37c0d4c03\nCloses-Bug: #1428836\n'}]",0,165535,a8ba012ec2f52d9c5f62113c22cfa71163082cc5,9,5,1,9380,,,0,"Creating separate folder for nuage extensions

We will be adding multiple files related to nuage
extensions, so it would be nice to have a separate
nuage folder. Also moving the current extension file
netpartition.py to the new folder.

Change-Id: Ida125c6e03e0e40ba62be0da2e7b4ce37c0d4c03
Closes-Bug: #1428836
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/35/165535/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/nuage/__init__.py', 'neutronclient/neutron/v2_0/nuage/netpartition.py', 'neutronclient/shell.py', 'neutronclient/tests/unit/test_cli20_nuage_netpartition.py']",4,a8ba012ec2f52d9c5f62113c22cfa71163082cc5,,from neutronclient.neutron.v2_0.nuage import netpartition,from neutronclient.neutron.v2_0 import netpartition,2,2
openstack%2Fneutron-fwaas~master~I9c2d6016cef81448099db07df11c7534cdb1af34,openstack/neutron-fwaas,master,I9c2d6016cef81448099db07df11c7534cdb1af34,Move pylint checks to pep8 testenv,ABANDONED,2015-03-03 10:01:48.000000000,2015-05-21 21:27:57.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 8645}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 11752}, {'_account_id': 15226}]","[{'number': 1, 'created': '2015-03-03 10:01:48.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/f113118a7fa60a55f6837ce52a2ad1c0c3c45230', 'message': 'Move pylint checks to pep8 testenv\n\nThe tox.ini file has been updated such that the pylint violation checks\nhave been moved to the pep8 testenv. If pylint is executed as a separate\njob, handling potential unexpected breakages would become a difficult job\nbecause we need to get infra involved. Also, an extra node needs to be\nspinned, when the checks can easily be handled by the node for the pep8\njob.\n\nFurther, having pylint running with tox -epep8 would help developers\nbecome aware of pylint violations sooner rather than later, if they forget\nto run the pylint testenv too before submitting the change.\n\nChange-Id: I9c2d6016cef81448099db07df11c7534cdb1af34\n'}]",0,160719,f113118a7fa60a55f6837ce52a2ad1c0c3c45230,15,8,1,15226,,,0,"Move pylint checks to pep8 testenv

The tox.ini file has been updated such that the pylint violation checks
have been moved to the pep8 testenv. If pylint is executed as a separate
job, handling potential unexpected breakages would become a difficult job
because we need to get infra involved. Also, an extra node needs to be
spinned, when the checks can easily be handled by the node for the pep8
job.

Further, having pylint running with tox -epep8 would help developers
become aware of pylint violations sooner rather than later, if they forget
to run the pylint testenv too before submitting the change.

Change-Id: I9c2d6016cef81448099db07df11c7534cdb1af34
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/19/160719/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f113118a7fa60a55f6837ce52a2ad1c0c3c45230,,deps = {[testenv]deps} pylint pylint --rcfile=.pylintrc --output-format=colorized {posargs:neutron_fwaas},[testenv:pylint] deps = {[testenv]deps} pylint commands = pylint --rcfile=.pylintrc --output-format=colorized {posargs:neutron_fwaas} ,4,7
openstack%2Fneutron~master~Iaa5597d9cfe43f4e0bebdbb898d3547ec81838ee,openstack/neutron,master,Iaa5597d9cfe43f4e0bebdbb898d3547ec81838ee,WIP: NSX Subnet mappings,ABANDONED,2015-04-10 23:16:29.000000000,2015-05-21 21:27:53.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15752}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-04-10 23:16:29.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/23ea866e8958_add_nsx_subnet_mapping.py', 'neutron/plugins/vmware/dbexts/nsx_models.py', 'neutron/db/migration/alembic_migrations/versions/HEAD'], 'web_link': 'https://opendev.org/openstack/neutron/commit/55c1af4d4305eb3feea7afc107f59804259e533d', 'message': 'WIP: NSX Subnet mappings\n\nThis patch introduces a new mapping class to associate\nNeutron subnets (in particular those on external networks)\nwith NSX entities.\n\nChange-Id: Iaa5597d9cfe43f4e0bebdbb898d3547ec81838ee\n'}]",0,172598,55c1af4d4305eb3feea7afc107f59804259e533d,31,29,1,261,,,0,"WIP: NSX Subnet mappings

This patch introduces a new mapping class to associate
Neutron subnets (in particular those on external networks)
with NSX entities.

Change-Id: Iaa5597d9cfe43f4e0bebdbb898d3547ec81838ee
",git fetch https://review.opendev.org/openstack/neutron refs/changes/98/172598/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/23ea866e8958_add_nsx_subnet_mapping.py', 'neutron/plugins/vmware/dbexts/nsx_models.py', 'neutron/db/migration/alembic_migrations/versions/HEAD']",3,55c1af4d4305eb3feea7afc107f59804259e533d,nsx_subnet_mapping,23ea866e8958,20c469a5f920 ,50,1
openstack%2Fpython-neutronclient~master~Icb0ce23f04177b935f36b71c2e54ea34087fd7bb,openstack/python-neutronclient,master,Icb0ce23f04177b935f36b71c2e54ea34087fd7bb,Update neutronclient shell to use shared arguments from Session,ABANDONED,2015-04-03 07:46:16.000000000,2015-05-21 21:27:52.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 8124}, {'_account_id': 14250}]","[{'number': 1, 'created': '2015-04-03 07:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/36267bf60573fb9ef7db7eb9c5992a1efc056f00', 'message': ""Update neutronclient shell to use shared arguments from Session\n\nThe neutronclient implemented it's own version of the CLI arguments that\nare now provided by keystoneclient's session object. This changeset\nconverts neutron over to utilizing the shared argument registration.\n\nChange-Id: Icb0ce23f04177b935f36b71c2e54ea34087fd7bb\nCloses-Bug: 1434105\n""}, {'number': 2, 'created': '2015-04-08 11:08:31.000000000', 'files': ['neutronclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/8666e64a6c0ae2cd28056a18edb0bce14849ff89', 'message': ""Update neutronclient shell to use shared arguments from Session\n\nThe neutronclient implemented it's own version of the CLI arguments that\nare now provided by keystoneclient's session object. This changeset\nconverts neutron over to utilizing the shared argument registration.\n\nChange-Id: Icb0ce23f04177b935f36b71c2e54ea34087fd7bb\nCloses-Bug: 1434105\n""}]",3,170370,8666e64a6c0ae2cd28056a18edb0bce14849ff89,12,5,2,14250,,,0,"Update neutronclient shell to use shared arguments from Session

The neutronclient implemented it's own version of the CLI arguments that
are now provided by keystoneclient's session object. This changeset
converts neutron over to utilizing the shared argument registration.

Change-Id: Icb0ce23f04177b935f36b71c2e54ea34087fd7bb
Closes-Bug: 1434105
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/70/170370/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/shell.py'],1,36267bf60573fb9ef7db7eb9c5992a1efc056f00,bug/1434105," # Register the CLI arguments that have moved to the session object. session.Session.register_cli_options(parser) parser.set_defaults(insecure=utils.env('NEUTRONCLIENT_INSECURE', default=False)) "," '--os-cert', metavar='<certificate>', default=utils.env('OS_CERT'), help=_(""Path of certificate file to use in SSL "" ""connection. This file can optionally be "" ""prepended with the private key. Defaults "" ""to env[OS_CERT]."")) parser.add_argument( '--os-cacert', metavar='<ca-certificate>', default=env('OS_CACERT', default=None), help=_(""Specify a CA bundle file to use in "" ""verifying a TLS (https) server certificate. "" ""Defaults to env[OS_CACERT]."")) parser.add_argument( '--os-key', metavar='<key>', default=utils.env('OS_KEY'), help=_(""Path of client key to use in SSL "" ""connection. This option is not necessary "" ""if your key is prepended to your certificate "" ""file. Defaults to env[OS_KEY]."")) parser.add_argument( parser.add_argument( '--insecure', action='store_true', default=env('NEUTRONCLIENT_INSECURE', default=False), help=_(""Explicitly allow neutronclient to perform \""insecure\"" "" ""SSL (https) requests. The server's certificate will "" ""not be verified against any certificate authorities. "" ""This option should be used with caution."")) ",6,35
openstack%2Fneutron~master~I1b043b36c313ee8e543973bbeb992b319a003bbe,openstack/neutron,master,I1b043b36c313ee8e543973bbeb992b319a003bbe,l2population_rpc: Refactor RPC endpoint,ABANDONED,2014-12-19 03:38:10.000000000,2015-05-21 21:27:50.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 333}, {'_account_id': 1561}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-19 03:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb0b6f8e781f2554befbf42395bf18dc7561f7cf', 'message': 'l2population_rpc: Refactor rpc endpoint\n\nWIP\n\nChange-Id: I1b043b36c313ee8e543973bbeb992b319a003bbe\n'}, {'number': 2, 'created': '2014-12-19 03:39:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/767432f4914d932f926d0216907f3dadd48968bd', 'message': 'l2population_rpc: Refactor rpc endpoint\n\nWIP\n\nChange-Id: I1b043b36c313ee8e543973bbeb992b319a003bbe\n'}, {'number': 3, 'created': '2014-12-19 04:40:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e6af2f32e8615a5a58c58422d4ce20379a1ba9ae', 'message': 'l2population_rpc: Refactor RPC endpoint\n\n- Separate the endpoint class from the mixin in order to make it clear\n  which methods are intended to be exposed via RPC.  This also makes the\n  RPC versioning easier to maintain.\n\n- Adapt ofagent and OVS agent.\n\nPartial-Bug: #1112634\nChange-Id: I1b043b36c313ee8e543973bbeb992b319a003bbe\n'}, {'number': 4, 'created': '2014-12-19 04:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78fc72211095a4d3984ea174c253127f243232a9', 'message': 'l2population_rpc: Refactor RPC endpoint\n\n- Separate the endpoint class from the mixin in order to make it clear\n  which methods are intended to be exposed via RPC.  This also makes the\n  RPC versioning easier to maintain.\n\n- Adapt ofagent and OVS agent.\n\nPartial-Bug: #1112634\nChange-Id: I1b043b36c313ee8e543973bbeb992b319a003bbe\n'}, {'number': 5, 'created': '2014-12-19 07:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c4648b5e2e3c6b18658c5eab0f7aa80ef2df4615', 'message': 'l2population_rpc: Refactor RPC endpoint\n\n- Separate the endpoint class from the mixin in order to make it clear\n  which methods are intended to be exposed via RPC.  This also makes the\n  RPC versioning easier to maintain.\n\n- Adapt ofagent and OVS agent.\n\nPartial-Bug: #1112634\nChange-Id: I1b043b36c313ee8e543973bbeb992b319a003bbe\n'}, {'number': 6, 'created': '2014-12-24 02:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/68a514b5536f186d28429acc717bae51dbc3066a', 'message': 'l2population_rpc: Refactor RPC endpoint\n\n- Separate the endpoint class from the mixin in order to make it clear\n  which methods are intended to be exposed via RPC.  This also makes the\n  RPC versioning easier to maintain.\n\n- Adapt ofagent and OVS agent.\n\nPartial-Bug: #1112634\nChange-Id: I1b043b36c313ee8e543973bbeb992b319a003bbe\n'}, {'number': 7, 'created': '2015-01-20 06:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/72a6cb24247b4103a6517c5de69812bcea62186e', 'message': 'l2population_rpc: Refactor RPC endpoint\n\n- Separate the endpoint class from the mixin in order to make it clear\n  which methods are intended to be exposed via RPC.  This also makes the\n  RPC versioning easier to maintain.\n\n- Adapt ofagent and OVS agent.\n\nPartial-Bug: #1112634\nChange-Id: I1b043b36c313ee8e543973bbeb992b319a003bbe\n'}, {'number': 8, 'created': '2015-01-21 02:20:55.000000000', 'files': ['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/common/rpc.py', 'neutron/agent/l2population_rpc.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2db98a8e9708d712d593aba3d69407cdca739c4e', 'message': 'l2population_rpc: Refactor RPC endpoint\n\n- Separate the endpoint class from the mixin in order to make it clear\n  which methods are intended to be exposed via RPC.  This also makes the\n  RPC versioning easier to maintain.\n\n- Adapt ofagent and OVS agent.\n\nPartial-Bug: #1413041\nPartial-Bug: #1112634\nChange-Id: I1b043b36c313ee8e543973bbeb992b319a003bbe'}]",1,142973,2db98a8e9708d712d593aba3d69407cdca739c4e,139,22,8,6854,,,0,"l2population_rpc: Refactor RPC endpoint

- Separate the endpoint class from the mixin in order to make it clear
  which methods are intended to be exposed via RPC.  This also makes the
  RPC versioning easier to maintain.

- Adapt ofagent and OVS agent.

Partial-Bug: #1413041
Partial-Bug: #1112634
Change-Id: I1b043b36c313ee8e543973bbeb992b319a003bbe",git fetch https://review.opendev.org/openstack/neutron refs/changes/73/142973/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/agent/l2population_rpc.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py']",3,fb0b6f8e781f2554befbf42395bf18dc7561f7cf,bug/1112634," self.endpoints = [ l2population_rpc.L2populationRpcEndpoint(self), self, ]", self.endpoints = [self],32,5
openstack%2Fneutron~master~I3662967c3ae4957c1013fbcc376f5f8c7ac383b9,openstack/neutron,master,I3662967c3ae4957c1013fbcc376f5f8c7ac383b9,OpenContrail IPAM Extension,ABANDONED,2015-01-06 10:10:19.000000000,2015-05-21 21:27:49.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 4187}, {'_account_id': 4362}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6785}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8126}, {'_account_id': 8306}, {'_account_id': 9008}, {'_account_id': 9631}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 12912}, {'_account_id': 13768}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-06 10:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/36c3ffc404490cc27d63a73f6503cb647c875263', 'message': 'OpenContrail IPAM Extension\n\nChange-Id: I3662967c3ae4957c1013fbcc376f5f8c7ac383b9\nImplements: blueprint opencontrail-ipam-extension\n'}, {'number': 2, 'created': '2015-01-06 10:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/96f7acf9981ea4a528c6299e85fab23984187efd', 'message': 'OpenContrail IPAM Extension\n\nChange-Id: I3662967c3ae4957c1013fbcc376f5f8c7ac383b9\nImplements: blueprint opencontrail-ipam-extension\n'}, {'number': 3, 'created': '2015-01-06 13:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f5eca64a437ae233e2c3f7baa993891d23635d6e', 'message': 'OpenContrail IPAM Extension\n\nChange-Id: I3662967c3ae4957c1013fbcc376f5f8c7ac383b9\nImplements: blueprint opencontrail-ipam-extension\n'}, {'number': 4, 'created': '2015-01-07 06:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b6cbc2682d164128d661e2700611b1b9e3ce8ef8', 'message': 'OpenContrail IPAM Extension\n\nFollowing IPAM Operations are implemented\nCreate IPAM\nGet IPAM\nUpdate IPAM\nDelete IPAM\nDependency: blueprint opencontrail-add-extension-support\n\nChange-Id: I3662967c3ae4957c1013fbcc376f5f8c7ac383b9\nImplements: blueprint opencontrail-ipam-extension\n'}, {'number': 5, 'created': '2015-01-13 19:35:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d782f97971c44847665c1864fc70e2fcc113f88', 'message': 'OpenContrail IPAM Extension\n\nFollowing IPAM Operations are implemented\nCreate IPAM\nGet IPAM\nUpdate IPAM\nDelete IPAM\nDependency: blueprint opencontrail-add-extension-support\n\nChange-Id: I3662967c3ae4957c1013fbcc376f5f8c7ac383b9\nImplements: blueprint opencontrail-ipam-extension\n'}, {'number': 6, 'created': '2015-01-18 09:52:37.000000000', 'files': ['neutron/plugins/opencontrail/plugins/contrail_plugin_ipam.py', 'neutron/plugins/opencontrail/extensions/__init__.py', 'neutron/plugins/opencontrail/plugins/__init__.py', 'neutron/plugins/opencontrail/extensions/ipam.py', 'neutron/tests/unit/opencontrail/test_extension_ipam.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a5f583bb9d118b801156f916c1ec481e86f30e2c', 'message': 'OpenContrail IPAM Extension\n\nFollowing IPAM delegates are implemented\nCreate IPAM\nGet IPAM/IPAMs\nUpdate IPAM\nDelete IPAM\n\nChange-Id: I3662967c3ae4957c1013fbcc376f5f8c7ac383b9\nImplements: blueprint opencontrail-ipam-extension\n'}]",10,145184,a5f583bb9d118b801156f916c1ec481e86f30e2c,95,37,6,9631,,,0,"OpenContrail IPAM Extension

Following IPAM delegates are implemented
Create IPAM
Get IPAM/IPAMs
Update IPAM
Delete IPAM

Change-Id: I3662967c3ae4957c1013fbcc376f5f8c7ac383b9
Implements: blueprint opencontrail-ipam-extension
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/145184/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/opencontrail/plugins/contrail_plugin_ipam.py', 'neutron/plugins/opencontrail/extensions/__init__.py', 'neutron/plugins/opencontrail/plugins/__init__.py', 'neutron/plugins/opencontrail/extensions/ipam.py', 'neutron/tests/unit/opencontrail/test_extension_ipam.py']",5,36c3ffc404490cc27d63a73f6503cb647c875263,bp/opencontrail-ipam-extension,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Copyright 2013 Big Switch Networks, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # @author: Sumit Naiksatam, sumitnaiksatam@gmail.com, Big Switch Networks, Inc. import copy import mock from webob import exc from neutron.openstack.common import uuidutils from neutron.plugins.opencontrail.extensions import ipam from neutron.tests.unit import test_api_v2 from neutron.tests.unit import test_api_v2_extension _uuid = uuidutils.generate_uuid _get_path = test_api_v2._get_path class IpamExtensionTestCase(test_api_v2_extension.ExtensionTestCase): fmt = 'json' def setUp(self): super(IpamExtensionTestCase, self).setUp() plural_mappings = {'ipam': 'ipams'} self._setUpExtension( 'neutron.plugins.opencontrail.extensions.ipam.IpamPluginBase', None, ipam.RESOURCE_ATTRIBUTE_MAP, ipam.Ipam, 'neutron', plural_mappings=plural_mappings) def test_create_ipam(self): ipam_id = _uuid() data = {'ipam': {'name': 'ipam1', 'mgmt': {}, 'tenant_id': _uuid()}} return_value = copy.copy(data['ipam']) return_value.update({'id': ipam_id}) instance = self.plugin.return_value instance.create_ipam.return_value = return_value res = self.api.post(_get_path('ipams', fmt=self.fmt), self.serialize(data), content_type='application/%s' % self.fmt) instance.create_ipam.assert_called_with(mock.ANY, ipam=data) self.assertEqual(res.status_int, exc.HTTPCreated.code) res = self.deserialize(res) self.assertIn('ipam', res) self.assertEqual(res['ipam'], return_value) def test_ipam_list(self): ipam_id = _uuid() return_value = [{'tenant_id': _uuid(), 'id': ipam_id}] instance = self.plugin.return_value instance.get_ipams.return_value = return_value res = self.api.get(_get_path('ipams', fmt=self.fmt)) instance.get_ipams.assert_called_with(mock.ANY, fields=mock.ANY, filters=mock.ANY) self.assertEqual(res.status_int, exc.HTTPOk.code) def test_ipam_get(self): ipam_id = _uuid() return_value = {'tenant_id': _uuid(), 'id': ipam_id} instance = self.plugin.return_value instance.get_ipam.return_value = return_value res = self.api.get(_get_path('ipams', id=ipam_id, fmt=self.fmt)) instance.get_ipam.assert_called_with(mock.ANY, ipam_id, fields=mock.ANY) self.assertEqual(res.status_int, exc.HTTPOk.code) res = self.deserialize(res) self.assertIn('ipam', res) self.assertEqual(res['ipam'], return_value) def test_ipam_update(self): ipam_id = _uuid() update_data = {'ipam': {'mgmt': ''}} return_value = {'tenant_id': _uuid(), 'id': ipam_id} instance = self.plugin.return_value instance.update_ipam.return_value = return_value res = self.api.put(_get_path('ipams', id=ipam_id, fmt=self.fmt), self.serialize(update_data)) instance.update_ipam.assert_called_with(mock.ANY, ipam_id, ipam=update_data) self.assertEqual(res.status_int, exc.HTTPOk.code) res = self.deserialize(res) self.assertIn('ipam', res) self.assertEqual(res['ipam'], return_value) def test_ipam_delete(self): ipam_id = _uuid() res = self.api.delete(_get_path('ipams', id=ipam_id, fmt=self.fmt)) delete_entity = getattr(self.plugin.return_value, ""delete_"" + 'ipam') delete_entity.assert_called_with(mock.ANY, ipam_id) self.assertEqual(res.status_int, exc.HTTPNoContent.code) ",,323,0
openstack%2Fneutron~master~I42b937874b866e975f159e0becec7bf7f99075ac,openstack/neutron,master,I42b937874b866e975f159e0becec7bf7f99075ac,Fixes sync between Arista ML2 driver and EOS,ABANDONED,2015-01-21 23:01:12.000000000,2015-05-21 21:27:48.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9596}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-21 23:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/248059ff635556f72fcdfa1311eb168bed7acc24', 'message': 'Fixes sync between Arista ML2 driver and EOS\n\nA bug in the sync code prevented the Arista ML2 driver from syncing with EOS.\nThis patch fixes the bug and adds some unit tests to ensure that the sync\nbehaves as expected.\n\nCloses-Bug: 1411383\nChange-Id: I42b937874b866e975f159e0becec7bf7f99075ac\n'}, {'number': 2, 'created': '2015-01-23 21:15:20.000000000', 'files': ['neutron/plugins/ml2/drivers/arista/config.py', 'neutron/plugins/ml2/drivers/arista/mechanism_arista.py', 'neutron/tests/unit/ml2/drivers/arista/test_arista_mechanism_driver.py', 'etc/neutron/plugins/ml2/ml2_conf_arista.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c672c8dce2df77ba35dacb68c5a1c4494936ebb5', 'message': 'Fixes sync between Arista ML2 driver and EOS\n\nA bug in the sync code prevented the Arista ML2 driver from syncing with EOS.\nThis patch fixes the bug and adds some unit tests to ensure that the sync\nbehaves as expected.\n\nDocImpact: The default sync_interval has been changed from 180 to 20 seconds.\n\nCloses-Bug: 1411383\nChange-Id: I42b937874b866e975f159e0becec7bf7f99075ac\n'}]",4,149072,c672c8dce2df77ba35dacb68c5a1c4494936ebb5,37,20,2,9596,,,0,"Fixes sync between Arista ML2 driver and EOS

A bug in the sync code prevented the Arista ML2 driver from syncing with EOS.
This patch fixes the bug and adds some unit tests to ensure that the sync
behaves as expected.

DocImpact: The default sync_interval has been changed from 180 to 20 seconds.

Closes-Bug: 1411383
Change-Id: I42b937874b866e975f159e0becec7bf7f99075ac
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/149072/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/arista/config.py', 'neutron/plugins/ml2/drivers/arista/mechanism_arista.py', 'neutron/tests/unit/ml2/drivers/arista/test_arista_mechanism_driver.py']",3,248059ff635556f72fcdfa1311eb168bed7acc24,bug/1411383,"class SyncServiceTest(base.BaseTestCase): """"""Test cases for the sync service."""""" def setUp(self): super(SyncServiceTest, self).setUp() self.rpc = mock.MagicMock() ndb = db.NeutronNets() self.sync_service = arista.SyncService(self.rpc, ndb) self.sync_service._force_sync = False def test_region_in_sync(self): """"""Tests whether the region_in_sync() behaves as expected."""""" region_updated_time = { 'regionName': 'RegionOne', 'regionTimestamp': '12345' } self.rpc.get_region_updated_time.return_value = region_updated_time self.sync_service._region_updated_time = None assert not self.sync_service._region_in_sync() self.sync_service._region_updated_time = region_updated_time assert self.sync_service._region_in_sync() def test_synchronize_required(self): """"""Tests whether synchronize() sends the right commands if a sync is required. """""" region_updated_time = { 'regionName': 'RegionOne', 'regionTimestamp': '12345' } self.rpc.get_region_updated_time.return_value = region_updated_time self.sync_service._region_updated_time = { 'regionName': 'RegionOne', 'regionTimestamp': '0', } tenant_id = 'tenant-1' network_id = 'net-1' segmentation_id = 42 db.remember_tenant(tenant_id) db.remember_network(tenant_id, network_id, segmentation_id) self.rpc.get_tenants.return_value = {} self.sync_service.synchronize() expected_calls = [ mock.call.get_region_updated_time(), mock.call._run_openstack_cmds(['sync start']), mock.call.register_with_eos(), mock.call.get_tenants(), mock.call.create_network_bulk(tenant_id, [{'network_id': network_id, 'segmentation_id': segmentation_id, 'network_name': '', 'shared': False}]), mock.call._run_openstack_cmds(['sync end']), mock.call.get_region_updated_time() ] assert self.rpc.mock_calls == expected_calls db.forget_network(tenant_id, network_id) db.forget_tenant(tenant_id) def test_synchronize_not_required(self): """"""Tests whether synchronize() sends the right commands if a sync is not required. """""" region_updated_time = { 'regionName': 'RegionOne', 'regionTimestamp': '424242' } self.rpc.get_region_updated_time.return_value = region_updated_time self.sync_service._region_updated_time = { 'regionName': 'RegionOne', 'regionTimestamp': '424242', } self.sync_service.synchronize() # If the timestamps do match, then the sync should not be executed. expected_calls = [ mock.call.get_region_updated_time(), mock.call._run_openstack_cmds(['sync end']), ] assert self.rpc.mock_calls == expected_calls def test_synchronize_one_network(self): """"""Test to ensure that only the required resources are sent to EOS."""""" # Store two tenants in a db and a single tenant in EOS. # The sync should send details of the second tenant to EOS tenant_1_id = 'tenant-1' tenant_1_net_1_id = 'ten-1-net-1' tenant_1_net_1_seg_id = 11 db.remember_tenant(tenant_1_id) db.remember_network(tenant_1_id, tenant_1_net_1_id, tenant_1_net_1_seg_id) tenant_2_id = 'tenant-2' tenant_2_net_1_id = 'ten-2-net-1' tenant_2_net_1_seg_id = 21 db.remember_tenant(tenant_2_id) db.remember_network(tenant_2_id, tenant_2_net_1_id, tenant_2_net_1_seg_id) self.rpc.get_tenants.return_value = { tenant_1_id: { 'tenantVmInstances': {}, 'tenantNetworks': { tenant_1_net_1_id: { 'networkId': tenant_1_net_1_id, 'shared': False, 'networkName': 'Net1', 'segmenationType': 'vlan', 'segmentationTypeId': tenant_1_net_1_seg_id, } } } } self.sync_service.synchronize() expected_calls = [ mock.call.get_region_updated_time(), mock.call._run_openstack_cmds(['sync start']), mock.call.register_with_eos(), mock.call.get_tenants(), mock.call.create_network_bulk(tenant_2_id, [{'network_id': tenant_2_net_1_id, 'segmentation_id': tenant_2_net_1_seg_id, 'network_name': '', 'shared': False}]), mock.call._run_openstack_cmds(['sync end']), mock.call.get_region_updated_time() ] assert self.rpc.mock_calls == expected_calls db.forget_network(tenant_1_id, tenant_1_net_1_id) db.forget_network(tenant_2_id, tenant_2_net_1_id) db.forget_tenant(tenant_1_id) db.forget_tenant(tenant_2_id) def test_synchronize_all_networks(self): """"""Test to ensure that only the required resources are sent to EOS."""""" # Store two tenants in a db and none on EOS. # The sync should send details of all tenants to EOS tenant_1_id = 'tenant-1' tenant_1_net_1_id = 'ten-1-net-1' tenant_1_net_1_seg_id = 11 db.remember_tenant(tenant_1_id) db.remember_network(tenant_1_id, tenant_1_net_1_id, tenant_1_net_1_seg_id) tenant_2_id = 'tenant-2' tenant_2_net_1_id = 'ten-2-net-1' tenant_2_net_1_seg_id = 21 db.remember_tenant(tenant_2_id) db.remember_network(tenant_2_id, tenant_2_net_1_id, tenant_2_net_1_seg_id) self.rpc.get_tenants.return_value = {} self.sync_service.synchronize() expected_calls = [ mock.call.get_region_updated_time(), mock.call._run_openstack_cmds(['sync start']), mock.call.register_with_eos(), mock.call.get_tenants(), mock.call.create_network_bulk(tenant_2_id, [{'network_id': tenant_2_net_1_id, 'segmentation_id': tenant_2_net_1_seg_id, 'network_name': '', 'shared': False}]), mock.call.create_network_bulk(tenant_1_id, [{'network_id': tenant_1_net_1_id, 'segmentation_id': tenant_1_net_1_seg_id, 'network_name': '', 'shared': False}]), mock.call._run_openstack_cmds(['sync end']), mock.call.get_region_updated_time() ] assert self.rpc.mock_calls == expected_calls db.forget_network(tenant_1_id, tenant_1_net_1_id) db.forget_network(tenant_2_id, tenant_2_net_1_id) db.forget_tenant(tenant_1_id) db.forget_tenant(tenant_2_id) "," def test_sync_start(self): self.drv.sync_start() cmds = ['enable', 'configure', 'cvx', 'service openstack', 'region RegionOne', 'sync start', 'exit', 'exit', 'exit'] self.drv._server.runCmds.assert_called_once_with(version=1, cmds=cmds) def test_sync_end(self): self.drv.sync_end() cmds = ['enable', 'configure', 'cvx', 'service openstack', 'region RegionOne', 'sync end', 'exit', 'exit', 'exit'] self.drv._server.runCmds.assert_called_once_with(version=1, cmds=cmds) ",278,107
openstack%2Fneutron~master~I269de325950dac998bf02704a174bbb15ef2b6ac,openstack/neutron,master,I269de325950dac998bf02704a174bbb15ef2b6ac,Check if the port is ACTIVE before sending update_fdb message,ABANDONED,2015-01-26 14:52:11.000000000,2015-05-21 21:27:47.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2888}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6697}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9093}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-26 14:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a7765c4983460984a96bc9f54365b15aa86b4ecd', 'message': ""Check if the port is ACTIVE before sending update_fdb message\n\nWhen a port is not ACTIVE, l2pop don't have to notify any change\nof its IPs, since no agent should have the fdb entrie for a port\nwhich is not ACTIVE.\n\nChange-Id: I269de325950dac998bf02704a174bbb15ef2b6ac\nCloses-bug: #1414650\n""}, {'number': 2, 'created': '2015-02-04 10:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c04ec2f1161ad83b8d370d20adcd2c5581e186c9', 'message': ""Check if the port is ACTIVE before sending update_fdb message\n\nWhen a port is not ACTIVE, l2pop don't have to notify any change\nof its IPs, since no agent should have the fdb entrie for a port\nwhich is not ACTIVE.\n\nThis patch also fix a nit introduced by\nI1864c0882cda7eddc9ced519ed3f96c91b2b63f3\nwhich is rasing a misspelled exception\n\nChange-Id: I269de325950dac998bf02704a174bbb15ef2b6ac\nCloses-bug: #1414650\n""}, {'number': 3, 'created': '2015-02-04 10:58:15.000000000', 'files': ['neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/tests/unit/ml2/drivers/test_l2population.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/db2a4e1604dab1d830719ee8c4c9c5da1b8fa10e', 'message': ""Check if the port is ACTIVE before sending update_fdb message\n\nWhen a port is not ACTIVE, l2pop don't have to notify any change\nof its IPs, since no agent should have the fdb entrie for a port\nwhich is not ACTIVE.\n\nThis patch also fixes a nit introduced by\nI1864c0882cda7eddc9ced519ed3f96c91b2b63f3\nwhich is raising a misspelled exception\n\nChange-Id: I269de325950dac998bf02704a174bbb15ef2b6ac\nCloses-bug: #1414650\n""}]",9,150045,db2a4e1604dab1d830719ee8c4c9c5da1b8fa10e,62,27,3,2888,,,0,"Check if the port is ACTIVE before sending update_fdb message

When a port is not ACTIVE, l2pop don't have to notify any change
of its IPs, since no agent should have the fdb entrie for a port
which is not ACTIVE.

This patch also fixes a nit introduced by
I1864c0882cda7eddc9ced519ed3f96c91b2b63f3
which is raising a misspelled exception

Change-Id: I269de325950dac998bf02704a174bbb15ef2b6ac
Closes-bug: #1414650
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/150045/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/tests/unit/ml2/drivers/test_l2population.py']",2,a7765c4983460984a96bc9f54365b15aa86b4ecd,bug/1414650," def test_fixed_ips_changed_port_not_up(self): self._register_ml2_agents() with self.subnet(network=self._network) as subnet: host_arg = {portbindings.HOST_ID: HOST} with self.port(subnet=subnet, cidr='10.0.0.0/24', device_owner=DEVICE_OWNER_COMPUTE, arg_list=(portbindings.HOST_ID,), **host_arg) as port1: p1 = port1['port'] self.mock_fanout.reset_mock() data = {'port': {'fixed_ips': [{'ip_address': '10.0.0.2'}, {'ip_address': '10.0.0.10'}]}} req = self.new_update_request('ports', data, p1['id']) res = self.deserialize(self.fmt, req.get_response(self.api)) ips = res['port']['fixed_ips'] self.assertEqual(len(ips), 2) self.assertFalse(self.mock_fanout.called) ",,27,3
openstack%2Fneutron~master~Ideb2bd9f9c230a2a497080c9ff57a4c6f59ec375,openstack/neutron,master,Ideb2bd9f9c230a2a497080c9ff57a4c6f59ec375,OVS agent supports arp responder for VLAN,ABANDONED,2015-01-23 02:55:51.000000000,2015-05-21 21:27:45.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2888}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 12076}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2015-01-23 02:55:51.000000000', 'files': ['neutron/plugins/openvswitch/common/config.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b8473ec5b7920ca4496f90cabf53f4d5bb916c0', 'message': 'OVS agent supports arp responder for VLAN\n\nThis commit[1] introduces a new agent configuration ""l2pop_network_types"".\nIn ofagent, this configuration is used to enable arp responder for non-tunnel\nnetwork types like VLAN, using the l2pop information. This patch adds an\noption to switch this feature in OVS agent.\n\n[1] https://review.openstack.org/#/c/112947\n\nChange-Id: Ideb2bd9f9c230a2a497080c9ff57a4c6f59ec375\nCloses-Bug: #1413056\n'}]",0,149462,7b8473ec5b7920ca4496f90cabf53f4d5bb916c0,23,20,1,12076,,,0,"OVS agent supports arp responder for VLAN

This commit[1] introduces a new agent configuration ""l2pop_network_types"".
In ofagent, this configuration is used to enable arp responder for non-tunnel
network types like VLAN, using the l2pop information. This patch adds an
option to switch this feature in OVS agent.

[1] https://review.openstack.org/#/c/112947

Change-Id: Ideb2bd9f9c230a2a497080c9ff57a4c6f59ec375
Closes-Bug: #1413056
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/149462/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/openvswitch/common/config.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py']",2,7b8473ec5b7920ca4496f90cabf53f4d5bb916c0,bug/1413056," l2pop_for_vlan=False, l2pop_network_types = list(self.tunnel_types) if l2pop_for_vlan: l2pop_network_types.append(p_const.TYPE_VLAN) 'l2pop_network_types': l2pop_network_types, l2pop_for_vlan=config.AGENT.l2pop_for_vlan,",,8,0
openstack%2Fneutron~stable%2Fjuno~I5fd9bf4163eafa321c5fca7ffb7901ae289f323b,openstack/neutron,stable/juno,I5fd9bf4163eafa321c5fca7ffb7901ae289f323b,Make L2 DVR Agent start successfully without an active neutron server,ABANDONED,2015-03-11 10:19:02.000000000,2015-05-21 21:27:44.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1131}, {'_account_id': 1420}, {'_account_id': 8344}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}]","[{'number': 1, 'created': '2015-03-11 10:19:02.000000000', 'files': ['neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b19d2d95bc81673f2d6f008011e0f8760d8fde9', 'message': ""Make L2 DVR Agent start successfully without an active neutron server\n\nIf the L2 Agent is started before the neutron controller\nis available, it will fail to obtain its unique DVR MAC\naddress, and fall-back to operate in non-DVR mode\npermanently.\n\nThis fix does two things:\n1. Makes the L2 Agent attempt to retry obtaining a DVR MAC\naddress up to five times on initialization, which should be\nenough time for RPC to be successful.  On failure, it will\nfall back to non-DVR mode, ensuring that basic switching\ncontinues to be functional.\n\n2. Correctly obtains the current operating mode of the\nL2 Agent in _report_state(), instead of only reporting\nthe configured state.  This operating mode is carried\nin 'in_distributed_mode' attribute of agent state, and\nis separate from the existing enable_distributed_routing\nstatic config that is already sent.\n\nConflicts:\n\tneutron/plugins/openvswitch/agent/ovs_neutron_agent.py\n\nChange-Id: I5fd9bf4163eafa321c5fca7ffb7901ae289f323b\nCloses-bug: #1364215\n(cherry picked from commit 51303b5fe4785d0cda76f095c95eb4d746d7d783)\n""}]",0,163349,4b19d2d95bc81673f2d6f008011e0f8760d8fde9,20,17,1,12549,,,0,"Make L2 DVR Agent start successfully without an active neutron server

If the L2 Agent is started before the neutron controller
is available, it will fail to obtain its unique DVR MAC
address, and fall-back to operate in non-DVR mode
permanently.

This fix does two things:
1. Makes the L2 Agent attempt to retry obtaining a DVR MAC
address up to five times on initialization, which should be
enough time for RPC to be successful.  On failure, it will
fall back to non-DVR mode, ensuring that basic switching
continues to be functional.

2. Correctly obtains the current operating mode of the
L2 Agent in _report_state(), instead of only reporting
the configured state.  This operating mode is carried
in 'in_distributed_mode' attribute of agent state, and
is separate from the existing enable_distributed_routing
static config that is already sent.

Conflicts:
	neutron/plugins/openvswitch/agent/ovs_neutron_agent.py

Change-Id: I5fd9bf4163eafa321c5fca7ffb7901ae289f323b
Closes-bug: #1364215
(cherry picked from commit 51303b5fe4785d0cda76f095c95eb4d746d7d783)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/163349/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py']",3,4b19d2d95bc81673f2d6f008011e0f8760d8fde9,bug/1364215," # here inside the call to reset_tunnel_br() self.reset_tunnel_br(tun_br) report_interval = cfg.CONF.AGENT.report_interval if report_interval: heartbeat = loopingcall.FixedIntervalLoopingCall( self._report_state) heartbeat.start(interval=report_interval) if self.enable_tunneling: self.setup_tunnel_br() self.agent_state.get('configurations')['in_distributed_mode'] = ( self.dvr_agent.in_distributed_mode()) def reset_tunnel_br(self, tun_br_name=None): '''(re)initialize the tunnel bridge. def setup_tunnel_br(self): '''Setup the tunnel bridge. Add all flows to the tunnel bridge. ''' self.reset_tunnel_br() if self.enable_distributed_routing: self.dvr_agent.reset_ovs_parameters(self.int_br, self.tun_br, self.patch_int_ofport, self.patch_tun_ofport) self.dvr_agent.reset_dvr_parameters() self.dvr_agent.setup_dvr_flows_on_integ_tun_br()"," # here inside the call to setup_tunnel_br self.setup_tunnel_br(tun_br) report_interval = cfg.CONF.AGENT.report_interval if report_interval: heartbeat = loopingcall.FixedIntervalLoopingCall( self._report_state) heartbeat.start(interval=report_interval) def setup_tunnel_br(self, tun_br_name=None): '''Setup the tunnel bridge. self.dvr_agent.reset_ovs_parameters(self.int_br, self.tun_br, self.patch_int_ofport, self.patch_tun_ofport) self.dvr_agent.setup_dvr_flows_on_integ_tun_br()",175,59
openstack%2Fneutron~master~I4defd2642cd70f3c2ee12f106c939a79d440c569,openstack/neutron,master,I4defd2642cd70f3c2ee12f106c939a79d440c569,Add events on dropped packet by security groups firewall.,ABANDONED,2015-04-14 13:19:36.000000000,2015-05-21 21:27:43.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1131}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10257}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-04-14 13:19:36.000000000', 'files': ['neutron/db/securitygroups_db.py', 'neutron/agent/linux/iptables_firewall_event_syslog.py', 'neutron/agent/linux/iptables_comments.py', 'neutron/db/securitygroups_rpc_base.py', 'neutron/agent/linux/iptables_firewall.py', 'neutron/agent/firewall_event.py', 'neutron/extensions/securitygroup.py', 'neutron/tests/unit/agent/test_securitygroups_rpc.py', 'neutron/agent/securitygroups_rpc.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/db/migration/alembic_migrations/versions/190526727dd3_security_groups_event.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/64092baea5c98b9ea4fe2bfb857652b3c7484d04', 'message': ""Add events on dropped packet by security groups firewall.\n\nThis patch includes:\n - A boolean event parameter addition to the security group entity\n(API/DB/Propagation to the Firewall driver).\n - An extension of the existing iptables firewall driver that sends\nevents to ceilometer\n\nTo use these patch with complete events you need:\n - To activate ceilometer to your devstack configuration file adding\nthese lines (section [[local|localrc]]):\n\nenable_service ceilometer-acompute ceilometer-acentral\nceilometer-anotification ceilometer-collector\nenable_service ceilometer-alarm-evaluator,ceilometer-alarm-notifier\nenable_service ceilometer-api\n\n - To add parameter to 'ml2_conf.ini' file in your devstack\nconfiguration file adding these lines:\n\n[securitygroup]\nfirewall_event_driver=neutron.agent.linux.iptables_firewall_event_syslog.IptablesFirewallSyslogEventDriver\n\n - Add the new events definition at the end of the 'file\nevent_definitions.yaml' in ceilometer conf folder:\n\n- event_type: security.groups.firewall.drop.*\n  traits: &security_groups_firewall\n    src_ip:\n      fields: payload.src_ip\n    dst_port_number:\n      fields: payload.dst_port_number\n    protocol:\n      fields: payload.protocol\n    dst_ip:\n      fields: payload.dst_ip\n    dst_port_id:\n      fields: payload.dst_port_id\n    rule_type:\n      fields: payload.rule_type\n    time_stamp:\n      fields: payload.time_stamp\n    tenant_id:\n      fields: payload.tenant_id\n\n - Associate an instance to a security group that have the event column\nset to 1/true to receive the events.\n\nChange-Id: I4defd2642cd70f3c2ee12f106c939a79d440c569\nStatus: Beta implementation for POC purpose\nImplements: blueprint security-groups-dropped-packets-event\n""}]",1,173310,64092baea5c98b9ea4fe2bfb857652b3c7484d04,29,28,1,14249,,,0,"Add events on dropped packet by security groups firewall.

This patch includes:
 - A boolean event parameter addition to the security group entity
(API/DB/Propagation to the Firewall driver).
 - An extension of the existing iptables firewall driver that sends
events to ceilometer

To use these patch with complete events you need:
 - To activate ceilometer to your devstack configuration file adding
these lines (section [[local|localrc]]):

enable_service ceilometer-acompute ceilometer-acentral
ceilometer-anotification ceilometer-collector
enable_service ceilometer-alarm-evaluator,ceilometer-alarm-notifier
enable_service ceilometer-api

 - To add parameter to 'ml2_conf.ini' file in your devstack
configuration file adding these lines:

[securitygroup]
firewall_event_driver=neutron.agent.linux.iptables_firewall_event_syslog.IptablesFirewallSyslogEventDriver

 - Add the new events definition at the end of the 'file
event_definitions.yaml' in ceilometer conf folder:

- event_type: security.groups.firewall.drop.*
  traits: &security_groups_firewall
    src_ip:
      fields: payload.src_ip
    dst_port_number:
      fields: payload.dst_port_number
    protocol:
      fields: payload.protocol
    dst_ip:
      fields: payload.dst_ip
    dst_port_id:
      fields: payload.dst_port_id
    rule_type:
      fields: payload.rule_type
    time_stamp:
      fields: payload.time_stamp
    tenant_id:
      fields: payload.tenant_id

 - Associate an instance to a security group that have the event column
set to 1/true to receive the events.

Change-Id: I4defd2642cd70f3c2ee12f106c939a79d440c569
Status: Beta implementation for POC purpose
Implements: blueprint security-groups-dropped-packets-event
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/173310/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/securitygroups_db.py', 'neutron/agent/linux/iptables_firewall_event_syslog.py', 'neutron/agent/linux/iptables_comments.py', 'neutron/db/securitygroups_rpc_base.py', 'neutron/agent/linux/iptables_firewall.py', 'neutron/agent/firewall_event.py', 'neutron/extensions/securitygroup.py', 'neutron/tests/unit/agent/test_securitygroups_rpc.py', 'neutron/agent/securitygroups_rpc.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/db/migration/alembic_migrations/versions/190526727dd3_security_groups_event.py']",11,64092baea5c98b9ea4fe2bfb857652b3c7484d04,bp/security-groups-dropped-packets-event,"# Copyright 2015 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # """"""security groups add events on dropped packets Revision ID: 190526727dd3 Revises: 20c469a5f920 Create Date: 2015-03-31 15:26:44.809197 """""" # revision identifiers, used by Alembic. revision = '190526727dd3' down_revision = '20c469a5f920' from alembic import op import sqlalchemy as sa def upgrade(): op.add_column('securitygroups', sa.Column('event', sa.SmallInteger(), nullable=True)) def downgrade(): op.drop_column('securitygroups', 'event') ",,321,47
openstack%2Fneutron~master~Id171afb3e9bafacd8b77ace9087f6ee2317c4054,openstack/neutron,master,Id171afb3e9bafacd8b77ace9087f6ee2317c4054,WIP Alternate Refactoring for Pluggable IPAM,ABANDONED,2015-04-10 14:34:58.000000000,2015-05-21 21:27:41.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12912}, {'_account_id': 13768}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15752}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-04-10 14:34:58.000000000', 'files': ['neutron/db/db_base_plugin_v2.py', 'neutron/ipam/__init__.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d3aa596b20ad73061845b273d48746fddb790be', 'message': ""WIP Alternate Refactoring for Pluggable IPAM\n\nThis provides an alternate approach to the refactoring needed\nfor pluggable IPAM. In [1], the proposed approach does not require\nchanges to any plugins, only to the base class. The approach in\nthis patch requires changes to the plugin subclasses in order to\nutilize pluggable IPAM; unchanged plugins will continue to use\nthe builtin IPAM.\n\nThe advantage of this patch is that the IPAM driver calls are\ndone prior to the start of the management layer's transaction.\nThis means that there is no open transaction during any external\nAPI calls.\n\nThis is very much a WIP, it is only intended to demonstrate the\nalternate approach. Some notes:\n   * Only the create_port method is refactored\n   * Much of the validation (such as _test_fixed_ips_for_port) is\n     deferred to the driver layer.\n   * There is no error handling\n   * I haven't even looked to see if it will handle IPv6, auto-\n     addressed ports, or router ports.\n   * I borrowed the ipam/__init__.py changes from [1].\n   * It is only very lightly tested: allocations for fixed IPs\n     via the neutron CLI are working in the single-subnet case,\n     as well as allocations when only a network ID is specified.\n   * Since none of the subnet calls are refactored, you have to\n     manual setup the database entries for them for the driver\n     to know what to do.\n   * IPAllocations are still stored, as that is the foreign key\n     relationships defined by the Port object for its IPs.\n   * The new driver is used for the actual allocations. This is\n     done prior to the start of the transaction in the ML2\n     create_port call.\n   * Obviously the final routines would appear in the DB plugin\n     not the ML2 plugin so they can be used by other plugins.\n\n[1] https://review.openstack.org/153236\n\nChange-Id: Id171afb3e9bafacd8b77ace9087f6ee2317c4054\n""}]",11,172443,3d3aa596b20ad73061845b273d48746fddb790be,45,31,1,12912,,,0,"WIP Alternate Refactoring for Pluggable IPAM

This provides an alternate approach to the refactoring needed
for pluggable IPAM. In [1], the proposed approach does not require
changes to any plugins, only to the base class. The approach in
this patch requires changes to the plugin subclasses in order to
utilize pluggable IPAM; unchanged plugins will continue to use
the builtin IPAM.

The advantage of this patch is that the IPAM driver calls are
done prior to the start of the management layer's transaction.
This means that there is no open transaction during any external
API calls.

This is very much a WIP, it is only intended to demonstrate the
alternate approach. Some notes:
   * Only the create_port method is refactored
   * Much of the validation (such as _test_fixed_ips_for_port) is
     deferred to the driver layer.
   * There is no error handling
   * I haven't even looked to see if it will handle IPv6, auto-
     addressed ports, or router ports.
   * I borrowed the ipam/__init__.py changes from [1].
   * It is only very lightly tested: allocations for fixed IPs
     via the neutron CLI are working in the single-subnet case,
     as well as allocations when only a network ID is specified.
   * Since none of the subnet calls are refactored, you have to
     manual setup the database entries for them for the driver
     to know what to do.
   * IPAllocations are still stored, as that is the foreign key
     relationships defined by the Port object for its IPs.
   * The new driver is used for the actual allocations. This is
     done prior to the start of the transaction in the ML2
     create_port call.
   * Obviously the final routines would appear in the DB plugin
     not the ML2 plugin so they can be used by other plugins.

[1] https://review.openstack.org/153236

Change-Id: Id171afb3e9bafacd8b77ace9087f6ee2317c4054
",git fetch https://review.opendev.org/openstack/neutron refs/changes/43/172443/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/db_base_plugin_v2.py', 'neutron/ipam/__init__.py', 'neutron/plugins/ml2/plugin.py']",3,3d3aa596b20ad73061845b273d48746fddb790be,bp/neutron-ipam,"from neutron import ipam from neutron.ipam import driver as ipam_base def _use_builtin_ipam(self): False def _requested_ips_to_allocated_ips(self, context, requested_ips): allocated_ips = [] for ip in requested_ips: subnetpool = None subnet = self._get_subnet(context, ip['subnet_id']) if subnet.subnetpool_id: subnetpool = self._get_subnetpool(context, subnet.subnetpool_id) ipam_driver = ipam_base.Pool.get_instance(subnetpool) ipam_subnet = ipam_driver.get_subnet(ip['subnet_id']) addr = None if 'ip_address' in ip: addr = ip['ip_address'] addr_request = ipam.AddressRequestFactory(addr) addr = ipam_subnet.allocate(addr_request) allocated_ips += [{'subnet_id': subnet.id, 'ip_address': addr}] return allocated_ips def _allocate_port_ips(self, context, port): # determine the subnets on which to allocate the IPs if port['fixed_ips'] is attributes.ATTR_NOT_SPECIFIED: subnets = self._get_subnets_by_network(context, port['network_id']) fixed_ips = [{'subnet_id': s.id} for s in subnets] else: fixed_ips = port['fixed_ips'] port['fixed_ips'] = self._requested_ips_to_allocated_ips(context, fixed_ips) def create_port(self, context, port): self._allocate_port_ips(context, port['port'])"," def create_port(self, context, port):",132,22
openstack%2Fneutron~master~Idd4a31f26620aafda2daaeb4349a7a86ec20f580,openstack/neutron,master,Idd4a31f26620aafda2daaeb4349a7a86ec20f580,Update contribute.rst with Nuage plugin decomposition,ABANDONED,2015-03-18 18:02:39.000000000,2015-05-21 21:27:40.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6502}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 11701}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}, {'_account_id': 14956}, {'_account_id': 15443}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-03-18 18:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/df6073d68b9f9fd5b78c735edfa9944087fa2d07', 'message': 'Update contribute.rst with Nuage plugin decomposition\n\nUpdate the status of the Nuage Plugin code split\nin the contribute devref.\n\nChange-Id: Idd4a31f26620aafda2daaeb4349a7a86ec20f580\n'}, {'number': 2, 'created': '2015-03-18 18:04:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d3e25b8846b4a45e48ada534a83801f7a754ae04', 'message': 'Update contribute.rst with Nuage plugin decomposition\n\nUpdate the status of the Nuage Plugin code split\nin the contribute devref.\n\nChange-Id: Idd4a31f26620aafda2daaeb4349a7a86ec20f580\n'}, {'number': 3, 'created': '2015-03-24 20:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/88289095476a9d29cdc3445716e5a568157e3031', 'message': 'Update contribute.rst with Nuage plugin decomposition\n\nUpdate the status of the Nuage Plugin code split\nin the contribute devref.\n\nChange-Id: Idd4a31f26620aafda2daaeb4349a7a86ec20f580\n'}, {'number': 4, 'created': '2015-03-27 21:06:52.000000000', 'files': ['doc/source/devref/contribute.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/111664ce199989f5caaafe0d0170eae07c11a659', 'message': 'Update contribute.rst with Nuage plugin decomposition\n\nUpdate the status of the Nuage Plugin code split\nin the contribute devref.\n\nChange-Id: Idd4a31f26620aafda2daaeb4349a7a86ec20f580\n'}]",2,165536,111664ce199989f5caaafe0d0170eae07c11a659,73,31,4,11701,,,0,"Update contribute.rst with Nuage plugin decomposition

Update the status of the Nuage Plugin code split
in the contribute devref.

Change-Id: Idd4a31f26620aafda2daaeb4349a7a86ec20f580
",git fetch https://review.opendev.org/openstack/neutron refs/changes/36/165536/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/contribute.rst'],1,df6073d68b9f9fd5b78c735edfa9944087fa2d07,update_nuage_decomp,| nuage-openstack-neutron_ | core | no | no | [C] | Kilo |Nuage ----- * Git: https://github.com/nuage-networks/nuage-openstack-neutron ,| nuage-openstack-neutron_ | | | | | |.. _nuage-openstack-neutron:,5,2
openstack%2Fneutron~master~I8367662cc9fbd0274fdcdb0ab1da31865c41af6b,openstack/neutron,master,I8367662cc9fbd0274fdcdb0ab1da31865c41af6b,OpenContrail plugin code split,ABANDONED,2015-03-10 23:02:52.000000000,2015-05-21 21:27:38.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1580}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 8887}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10237}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14571}, {'_account_id': 14956}, {'_account_id': 15330}, {'_account_id': 15443}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-03-10 23:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48c9e9cc0fd516e11d9770af9d9062e850804016', 'message': 'OpenContrail plugin code split\n\n- Removes main codes and unit tests of opencontrail plugin\n\nRelated to blueprint core-vendor-decomposition\n\nChange-Id: I8367662cc9fbd0274fdcdb0ab1da31865c41af6b\n'}, {'number': 2, 'created': '2015-03-12 22:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc570e104c4ebebaf3816b37b351531ebf01bfbb', 'message': 'OpenContrail plugin code split\n\n- Removes main codes and unit tests of opencontrail plugin\n\nRelated to blueprint core-vendor-decomposition\n\nChange-Id: I8367662cc9fbd0274fdcdb0ab1da31865c41af6b\n'}, {'number': 3, 'created': '2015-03-14 01:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c0d4af1675c9941c9974bc566f657af48aff3135', 'message': 'OpenContrail plugin code split\n\n- Removes main codes and unit tests of opencontrail plugin\n\nRelated to blueprint core-vendor-decomposition\n\nChange-Id: I8367662cc9fbd0274fdcdb0ab1da31865c41af6b\n'}, {'number': 4, 'created': '2015-03-16 23:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66114df98840dfe6aacf63d928670a1bda213714', 'message': 'OpenContrail plugin code split\n\n- Removes main codes and unit tests of opencontrail plugin\n\nRelated to blueprint core-vendor-decomposition\n\nChange-Id: I8367662cc9fbd0274fdcdb0ab1da31865c41af6b\n'}, {'number': 5, 'created': '2015-03-18 02:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1873ba67884328c68cac15202b28ffd994d2938f', 'message': 'OpenContrail plugin code split\n\n- Removes main codes and unit tests of opencontrail plugin\n\nRelated to blueprint core-vendor-decomposition\nCloses-bug: #1433397\n\nChange-Id: I8367662cc9fbd0274fdcdb0ab1da31865c41af6b\n'}, {'number': 6, 'created': '2015-03-20 02:46:02.000000000', 'files': ['neutron/plugins/opencontrail/common/__init__.py', 'neutron/plugins/opencontrail/requirements.txt', 'neutron/tests/unit/opencontrail/__init__.py', 'neutron/plugins/opencontrail/common/exceptions.py', 'neutron/plugins/opencontrail/contrail_plugin.py', 'doc/source/devref/contribute.rst', 'neutron/tests/unit/opencontrail/test_contrail_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d9fc6e4ab3a494bf51e0fb5fe95cbb9695fc596f', 'message': 'OpenContrail plugin code split\n\n- Removes main codes and unit tests of opencontrail plugin\n\nRelated to blueprint core-vendor-decomposition\nCloses-bug: #1433397\n\nChange-Id: I8367662cc9fbd0274fdcdb0ab1da31865c41af6b\n'}]",8,163218,d9fc6e4ab3a494bf51e0fb5fe95cbb9695fc596f,243,38,6,2031,,,0,"OpenContrail plugin code split

- Removes main codes and unit tests of opencontrail plugin

Related to blueprint core-vendor-decomposition
Closes-bug: #1433397

Change-Id: I8367662cc9fbd0274fdcdb0ab1da31865c41af6b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/18/163218/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/opencontrail/common/__init__.py', 'neutron/tests/unit/opencontrail/__init__.py', 'neutron/plugins/opencontrail/common/exceptions.py', 'neutron/plugins/opencontrail/contrail_plugin.py', 'doc/source/devref/contribute.rst', 'neutron/tests/unit/opencontrail/test_contrail_plugin.py']",6,48c9e9cc0fd516e11d9770af9d9062e850804016,bug/1433397,,"# Copyright 2014 Juniper Networks. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import datetime import uuid import mock import netaddr from oslo_config import cfg from oslo_serialization import jsonutils from testtools import matchers import webob.exc from neutron.api import extensions from neutron.api.v2 import attributes as attr from neutron.api.v2 import base as api_base from neutron.common import exceptions as exc from neutron import context as neutron_context from neutron.db import db_base_plugin_v2 from neutron.db import external_net_db from neutron.db import l3_db from neutron.db import securitygroups_db from neutron.extensions import portbindings from neutron.extensions import securitygroup as ext_sg from neutron.tests.unit import _test_extension_portbindings as test_bindings from neutron.tests.unit import test_db_plugin as test_plugin from neutron.tests.unit import test_extension_security_group as test_sg from neutron.tests.unit import test_extensions from neutron.tests.unit import test_l3_plugin CONTRAIL_PKG_PATH = ""neutron.plugins.opencontrail.contrail_plugin"" class FakeServer(db_base_plugin_v2.NeutronDbPluginV2, external_net_db.External_net_db_mixin, securitygroups_db.SecurityGroupDbMixin, l3_db.L3_NAT_db_mixin): """"""FakeServer for contrail api server. This class mocks behaviour of contrail API server. """""" supported_extension_aliases = ['external-net', 'router', 'floatingip'] @property def _core_plugin(self): return self def create_port(self, context, port): self._ensure_default_security_group_on_port(context, port) sgids = self._get_security_groups_on_port(context, port) result = super(FakeServer, self).create_port(context, port) self._process_port_create_security_group(context, result, sgids) return result def update_port(self, context, id, port): original_port = self.get_port(context, id) updated_port = super(FakeServer, self).update_port(context, id, port) port_updates = port['port'] if ext_sg.SECURITYGROUPS in port_updates: port_updates[ext_sg.SECURITYGROUPS] = ( self._get_security_groups_on_port(context, port)) self._delete_port_security_group_bindings(context, id) self._process_port_create_security_group( context, updated_port, port_updates[ext_sg.SECURITYGROUPS]) else: updated_port[ext_sg.SECURITYGROUPS] = ( original_port[ext_sg.SECURITYGROUPS]) return updated_port def delete_port(self, context, id, l3_port_check=True): if l3_port_check: self.prevent_l3_port_deletion(context, id) self.disassociate_floatingips(context, id) super(FakeServer, self).delete_port(context, id) def create_subnet(self, context, subnet): subnet_data = subnet['subnet'] if subnet_data['gateway_ip'] == '0.0.0.0': subnet_data['gateway_ip'] = None return super(FakeServer, self).create_subnet(context, subnet) def create_network(self, context, network): net_data = network['network'] tenant_id = self._get_tenant_id_for_create(context, net_data) self._ensure_default_security_group(context, tenant_id) result = super(FakeServer, self).create_network(context, network) self._process_l3_create(context, result, network['network']) return result def update_network(self, context, id, network): with context.session.begin(subtransactions=True): result = super( FakeServer, self).update_network(context, id, network) self._process_l3_update(context, result, network['network']) return result def delete_network(self, context, id): self.delete_disassociated_floatingips(context, id) super(FakeServer, self).delete_network(context, id) def request(self, *args, **kwargs): request_data = jsonutils.loads(kwargs['data']) context_dict = request_data['context'] context = neutron_context.Context.from_dict(context_dict) resource_type = context_dict['type'] operation = context_dict['operation'] data = request_data['data'] resource = None if data.get('resource'): body = data['resource'] if resource_type not in [ 'security_group_rule', 'router', 'floatingip']: for key, value in body.items(): if value is None: body[key] = attr.ATTR_NOT_SPECIFIED resource = {resource_type: body} obj = {} code = webob.exc.HTTPOk.code try: if operation == 'READ': func = getattr(self, 'get_%s' % resource_type) obj = func(context, data['id']) if operation == 'READALL': func = getattr(self, 'get_%ss' % resource_type) obj = func(context, filters=data.get('filters')) if operation == 'READCOUNT': func = getattr(self, 'get_%ss_count' % resource_type) count = func(context, filters=data.get('filters')) obj = {'count': count} if operation == 'CREATE': func = getattr(self, 'create_%s' % resource_type) obj = func(context, resource) if operation == 'UPDATE': func = getattr(self, 'update_%s' % resource_type) obj = func(context, data['id'], resource) if operation == 'DELETE': func = getattr(self, 'delete_%s' % resource_type) obj = func(context, data['id']) if operation == 'ADDINTERFACE': obj = self.add_router_interface( context, data['id'], data['resource']) if operation == 'DELINTERFACE': obj = self.remove_router_interface( context, data['id'], data['resource']) except (exc.NeutronException, netaddr.AddrFormatError) as error: for fault in api_base.FAULT_MAP: if isinstance(error, fault): mapped_exc = api_base.FAULT_MAP[fault] code = mapped_exc.code obj = {'type': error.__class__.__name__, 'message': error.msg, 'detail': ''} if data.get('id'): obj['id'] = data.get('id') response = mock.MagicMock() response.status_code = code def return_obj(): return obj response.json = return_obj return response FAKE_SERVER = FakeServer() class Context(object): def __init__(self, tenant_id=''): self.read_only = False self.show_deleted = False self.roles = [u'admin', u'KeystoneServiceAdmin', u'KeystoneAdmin'] self._read_deleted = 'no' self.timestamp = datetime.datetime.now() self.auth_token = None self._session = None self._is_admin = True self.admin = uuid.uuid4().hex.decode() self.request_id = 'req-' + str(uuid.uuid4()) self.tenant = tenant_id class KeyStoneInfo(object): """"""To generate Keystone Authentication information Contrail Driver expects Keystone auth info for testing purpose. """""" auth_uri = 'http://host:35357/v2.0/' identity_uri = 'http://host:5000' admin_user = 'neutron' admin_password = 'neutron' admin_token = 'neutron' admin_tenant_name = 'neutron' class ContrailPluginTestCase(test_plugin.NeutronDbPluginV2TestCase): _plugin_name = ('%s.NeutronPluginContrailCoreV2' % CONTRAIL_PKG_PATH) def setUp(self, plugin=None, ext_mgr=None): if 'v6' in self._testMethodName: self.skipTest(""OpenContrail Plugin does not support IPV6."") cfg.CONF.keystone_authtoken = KeyStoneInfo() mock.patch('requests.post').start().side_effect = FAKE_SERVER.request super(ContrailPluginTestCase, self).setUp(self._plugin_name) class TestContrailNetworksV2(test_plugin.TestNetworksV2, ContrailPluginTestCase): def setUp(self): super(TestContrailNetworksV2, self).setUp() class TestContrailSubnetsV2(test_plugin.TestSubnetsV2, ContrailPluginTestCase): def setUp(self): super(TestContrailSubnetsV2, self).setUp() def test_delete_subnet_dhcp_port_associated_with_other_subnets(self): self.skipTest(""There is no dhcp port in contrail"") def _helper_test_validate_subnet(self, option, exception): cfg.CONF.set_override(option, 0) with self.network() as network: subnet = {'network_id': network['network']['id'], 'cidr': '10.0.2.0/24', 'ip_version': 4, 'tenant_id': network['network']['tenant_id'], 'gateway_ip': '10.0.2.1', 'dns_nameservers': ['8.8.8.8'], 'host_routes': [{'destination': '135.207.0.0/16', 'nexthop': '1.2.3.4'}]} error = self.assertRaises(exception, FAKE_SERVER._validate_subnet, neutron_context.get_admin_context( load_admin_roles=False), subnet) self.assertThat( str(error), matchers.Not(matchers.Contains('built-in function id'))) class TestContrailPortsV2(test_plugin.TestPortsV2, ContrailPluginTestCase): def test_create_port_public_network_with_invalid_ip_no_subnet_id(self): super(TestContrailPortsV2, self). \ test_create_port_public_network_with_invalid_ip_no_subnet_id( expected_error='ContrailBadRequestError') def test_create_port_public_network_with_invalid_ip_and_subnet_id(self): super(TestContrailPortsV2, self). \ test_create_port_public_network_with_invalid_ip_and_subnet_id( expected_error='ContrailBadRequestError') def test_delete_ports_by_device_id(self): self.skipTest(""This method tests rpc API of "" ""which contrail isn't using"") def test_delete_ports_by_device_id_second_call_failure(self): self.skipTest(""This method tests rpc API of "" ""which contrail isn't using"") def test_delete_ports_ignores_port_not_found(self): self.skipTest(""This method tests private method of "" ""which contrail isn't using"") def test_update_port_mac_bad_owner(self): self.check_update_port_mac( device_owner='network:router', expected_status=webob.exc.HTTPConflict.code, expected_error='ContrailConflictError') def test_update_port_mac_used(self): self.check_update_port_mac_used(expected_error='ContrailConflictError') class TestContrailSecurityGroups(test_sg.TestSecurityGroups, ContrailPluginTestCase): def setUp(self, plugin=None, ext_mgr=None): super(TestContrailSecurityGroups, self).setUp(self._plugin_name, ext_mgr) ext_mgr = extensions.PluginAwareExtensionManager.get_instance() self.ext_api = test_extensions.setup_extensions_middleware(ext_mgr) class TestContrailPortBinding(ContrailPluginTestCase, test_bindings.PortBindingsTestCase): VIF_TYPE = portbindings.VIF_TYPE_VROUTER HAS_PORT_FILTER = True def setUp(self): super(TestContrailPortBinding, self).setUp() class TestContrailL3NatTestCase(ContrailPluginTestCase, test_l3_plugin.L3NatDBIntTestCase): mock_rescheduling = False def setUp(self): super(TestContrailL3NatTestCase, self).setUp() ",15,962
openstack%2Fpython-neutronclient~master~Id08a46be0e419ae97e86a261d3a295e3b02bac0b,openstack/python-neutronclient,master,Id08a46be0e419ae97e86a261d3a295e3b02bac0b,Replace underscore with hyphen in Cisco CLI options.,ABANDONED,2015-03-23 18:14:14.000000000,2015-05-21 21:27:37.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 8124}, {'_account_id': 9631}, {'_account_id': 12485}, {'_account_id': 12524}, {'_account_id': 13376}]","[{'number': 1, 'created': '2015-03-23 18:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/a51b8ebd980a0cabbd58bc27a1bbb1cbc6f05193', 'message': 'Replace underscore with hyphen in CLI options\n\nChange-Id: Id08a46be0e419ae97e86a261d3a295e3b02bac0b\nCloses-bug: 1223504\n'}, {'number': 2, 'created': '2015-04-02 06:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ecde6b4febb09930a53c1abc8419ac83fd7f386a', 'message': 'Replace underscore with hyphen in CLI options\n\nChange-Id: Id08a46be0e419ae97e86a261d3a295e3b02bac0b\nCloses-bug: 1223504\n'}, {'number': 3, 'created': '2015-04-13 10:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/44a86a0de7022134ce62f6882b4e66ec1e08e1a1', 'message': 'Replace underscore with hyphen in CLI options\n\nChange-Id: Id08a46be0e419ae97e86a261d3a295e3b02bac0b\nCloses-bug: 1223504\n'}, {'number': 4, 'created': '2015-04-13 11:18:32.000000000', 'files': ['neutronclient/neutron/v2_0/networkprofile.py', 'neutronclient/tests/unit/test_cli20_networkprofile.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e9d04f6069e9e565189c2efc5fb13c1a46ec59b1', 'message': 'Replace underscore with hyphen in Cisco CLI options.\n\nChange-Id: Id08a46be0e419ae97e86a261d3a295e3b02bac0b\nCloses-bug: 1223504\n'}]",13,166949,e9d04f6069e9e565189c2efc5fb13c1a46ec59b1,22,8,4,12485,,,0,"Replace underscore with hyphen in Cisco CLI options.

Change-Id: Id08a46be0e419ae97e86a261d3a295e3b02bac0b
Closes-bug: 1223504
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/49/166949/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/networkprofile.py'],1,a51b8ebd980a0cabbd58bc27a1bbb1cbc6f05193,bug/1223504," parser.add_argument('--sub-type', parser.add_argument('--segment-range', parser.add_argument('--physical-network', parser.add_argument('--multicast-ip-range',"," parser.add_argument('--sub_type', parser.add_argument('--segment_range', parser.add_argument('--physical_network', parser.add_argument('--multicast_ip_range',",4,4
openstack%2Fneutron~master~Iffbcf10842ae861be05c43f4a68ce48fc016731b,openstack/neutron,master,Iffbcf10842ae861be05c43f4a68ce48fc016731b,Fix DVR SNAT unscheduling if host doesn't have service ports,ABANDONED,2015-04-13 17:30:19.000000000,2015-05-21 21:27:35.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 8873}, {'_account_id': 9077}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15840}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-04-13 17:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0008db048a2e072c30bee1b726b84b8cfa5e4cfd', 'message': ""Fix DVR SNAT unscheduling if host doesn't have service ports\n\nWhen a DVR router interface is removed, the SNAT portion of the\nrouter was unscheduled because the dvr_snat node was not hosting\nVM, LB or DHCP ports. However, in this case, if the router still\nhas SNAT ports in other subnets, it was still unscheduled when\nit should not have been.\n\nChange-Id: Iffbcf10842ae861be05c43f4a68ce48fc016731b\nCloses-Bug: #1443524\n""}, {'number': 2, 'created': '2015-04-13 19:13:28.000000000', 'files': ['neutron/db/l3_dvr_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ed1d2d5c346ef0b65b1ede270d67635db49a5481', 'message': ""Fix DVR SNAT unscheduling if host doesn't have service ports\n\nThe SNAT portion of a distributed router is scheduled when\nthe router is attached to an external network. It is deleted\nwhen an internal interface is removed and there do not remain\nany VMs, LB or DHCP ports on the subnet of the deleted interface.\n\nWhen a DVR router interface is removed, the SNAT portion of the\nrouter was unscheduled because the dvr_snat node was not hosting\nVM, LB or DHCP ports. However, in this case, if the router still\nhas SNAT ports in other subnets, it was still unscheduled when\nit should not have been.\n\nThis patch changes the unscheduling of the SNAT portion of a\ndistributed router so that it is unscheduled only when the external\ninterface of a router is deleted, which mirrors the logic of\nSNAT scheduling.\n\nChange-Id: Iffbcf10842ae861be05c43f4a68ce48fc016731b\nCloses-Bug: #1443596\n""}]",4,173002,ed1d2d5c346ef0b65b1ede270d67635db49a5481,60,32,2,8873,,,0,"Fix DVR SNAT unscheduling if host doesn't have service ports

The SNAT portion of a distributed router is scheduled when
the router is attached to an external network. It is deleted
when an internal interface is removed and there do not remain
any VMs, LB or DHCP ports on the subnet of the deleted interface.

When a DVR router interface is removed, the SNAT portion of the
router was unscheduled because the dvr_snat node was not hosting
VM, LB or DHCP ports. However, in this case, if the router still
has SNAT ports in other subnets, it was still unscheduled when
it should not have been.

This patch changes the unscheduling of the SNAT portion of a
distributed router so that it is unscheduled only when the external
interface of a router is deleted, which mirrors the logic of
SNAT scheduling.

Change-Id: Iffbcf10842ae861be05c43f4a68ce48fc016731b
Closes-Bug: #1443596
",git fetch https://review.opendev.org/openstack/neutron refs/changes/02/173002/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_agentschedulers_db.py'],1,0008db048a2e072c30bee1b726b84b8cfa5e4cfd,bug/1443596, if ((port['device_owner'] == constants.DEVICE_OWNER_ROUTER_SNAT or n_utils.is_dvr_serviced(port['device_owner'])) and l3_agent['host'] == port['binding:host_id']): return True, if (n_utils.is_dvr_serviced(port['device_owner']) and l3_agent['host'] == port['binding:host_id']): return True,4,3
openstack%2Fneutron~master~I59e2e1c090cb95ee1bd14dbb53b6ff2c5e2713fd,openstack/neutron,master,I59e2e1c090cb95ee1bd14dbb53b6ff2c5e2713fd,Handle 'ipset exists' errors when creating ipsets,ABANDONED,2015-04-14 23:42:50.000000000,2015-05-21 21:27:29.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8788}, {'_account_id': 8976}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11114}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-04-14 23:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d75abecc5d9a3d4aa880f58a226641284b07d721', 'message': ""Ignore 'ipset exists' errors when creating ipsets\n\nWhen the element limit for ipsets changes, 'ipset create'\nwill fail with an error indicating that a set with the\nsame name already exists even when the '-exists' flag\nis passed. This puts the agent in an exception loop and\nstops it from configuring the security groups correctly.\n\nThis was introduced by Ic0b5b38a840e737dc6be938230f4052974c8620f\nwhere the default element limit was increased and it was made\nconfigurable. Without this patch, the only work-around is to\nmanually destroy all of the IP sets before starting the agent\nafter changing the max elements.\n\nThis patch just catches the failure and checks for the 'exists'\nstring. If it finds it, it ignores it just like the '-exists' flag\nwould. The adjustment of the maximum elements automatically occurs\non the next swap.\n\nChange-Id: I59e2e1c090cb95ee1bd14dbb53b6ff2c5e2713fd\nCloses-Bug: #1444201\n""}, {'number': 2, 'created': '2015-04-15 00:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f1a2cceaa7e70a8d89c9f6d5ce5043ce8ca55fc', 'message': ""Ignore 'ipset exists' errors when creating ipsets\n\nWhen the element limit for ipsets changes, 'ipset create'\nwill fail with an error indicating that a set with the\nsame name already exists even when the '-exists' flag\nis passed. This puts the agent in an exception loop and\nstops it from configuring the security groups correctly.\n\nThis was introduced by Ic0b5b38a840e737dc6be938230f4052974c8620f\nwhere the default element limit was increased and it was made\nconfigurable. Without this patch, the only work-around is to\nmanually destroy all of the IP sets before starting the agent\nafter changing the max elements.\n\nThis patch just catches the failure and checks for the 'exists'\nstring. If it finds it, it ignores it just like the '-exists' flag\nwould. The adjustment of the maximum elements automatically occurs\non the next swap.\n\nChange-Id: I59e2e1c090cb95ee1bd14dbb53b6ff2c5e2713fd\nCloses-Bug: #1444201\n""}, {'number': 3, 'created': '2015-04-15 10:18:39.000000000', 'files': ['neutron/tests/functional/agent/linux/test_ipset.py', 'neutron/tests/unit/agent/linux/test_ipset_manager.py', 'neutron/agent/linux/ipset_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bb007a8fedb8e406f7a7deee93ff28250491865b', 'message': ""Handle 'ipset exists' errors when creating ipsets\n\nWhen the parameters for an ipset are different from an existing\nipset with the same name, 'ipset create' will fail with an error\nindicating that a set with the same name already exists even when\nthe '-exists' flag is present. This causes the agent to constantly\nthrow exceptions and stops it from configuring the security groupsi\ncorrectly.\n\nThis was introduced by Ic0b5b38a840e737dc6be938230f4052974c8620f\nwhere the default element limit was increased and it was made\nconfigurable. Without this patch, the only work-around is to\nmanually destroy all of the IP sets before starting the agent\nafter changing the max elements.\n\nThis patch just catches the failure and checks for the 'exists'\nstring. If it finds it, it explicitly destroys the existing set\nand any associated iptables rules (required to remove the set).\nIt then creates the new set with the different parameters.\n\nChange-Id: I59e2e1c090cb95ee1bd14dbb53b6ff2c5e2713fd\nCloses-Bug: #1444201\n""}]",18,173608,bb007a8fedb8e406f7a7deee93ff28250491865b,92,34,3,7787,,,0,"Handle 'ipset exists' errors when creating ipsets

When the parameters for an ipset are different from an existing
ipset with the same name, 'ipset create' will fail with an error
indicating that a set with the same name already exists even when
the '-exists' flag is present. This causes the agent to constantly
throw exceptions and stops it from configuring the security groupsi
correctly.

This was introduced by Ic0b5b38a840e737dc6be938230f4052974c8620f
where the default element limit was increased and it was made
configurable. Without this patch, the only work-around is to
manually destroy all of the IP sets before starting the agent
after changing the max elements.

This patch just catches the failure and checks for the 'exists'
string. If it finds it, it explicitly destroys the existing set
and any associated iptables rules (required to remove the set).
It then creates the new set with the different parameters.

Change-Id: I59e2e1c090cb95ee1bd14dbb53b6ff2c5e2713fd
Closes-Bug: #1444201
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/173608/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/linux/test_ipset_manager.py', 'neutron/agent/linux/ipset_manager.py']",2,d75abecc5d9a3d4aa880f58a226641284b07d721,bug/1439817,"from oslo_utils import excutils try: self._apply(cmd) except RuntimeError as e: # even though we use the -exist flag, ipset will throw an error if # the max elements have changed. we just suppress the error here # and don't worry about creating a set with the correct max elems # since _refresh_set will do that for us with excutils.save_and_reraise_exception() as ctxt: if 'set with the same name already exists' in str(e): ctxt.reraise = False", self._apply(cmd),25,1
openstack%2Fneutron~stable%2Fjuno~I21fdd627e9b028c1ffc7ff4f63828e4443fae6ce,openstack/neutron,stable/juno,I21fdd627e9b028c1ffc7ff4f63828e4443fae6ce,(DO NOT MERGE/WIP/POC) OVSFirewallDriver,ABANDONED,2015-04-20 10:43:12.000000000,2015-05-21 21:27:28.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 8788}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-04-20 10:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1010bd5acdf0baf494c81557d2316a8308308ae', 'message': '(DO NOT MERGE/WIP/POC) OVSFirewallDriver\n\nI have backported the driver to Juno to make a test deployment\nwith standard tools.\n\nCo-Authored-By: Amir Sadoughi < ....>\n\nConflicts:\n\tneutron/agent/securitygroups_rpc.py\n\tneutron/plugins/ml2/drivers/mech_openvswitch.py\n\tneutron/plugins/openvswitch/agent/ovs_neutron_agent.py\n\nChange-Id: I21fdd627e9b028c1ffc7ff4f63828e4443fae6ce\n'}, {'number': 2, 'created': '2015-04-22 12:36:18.000000000', 'files': ['neutron/agent/linux/ovs_lib.py', 'neutron/plugins/ml2/drivers/mech_openvswitch.py', 'neutron/agent/linux/openvswitch_firewall.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/agent/securitygroups_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/536547c919a569a1c24db404877c4103018ccca3', 'message': '(DO NOT MERGE/WIP/POC) OVSFirewallDriver\n\nI have backported the driver to Juno to make a test deployment\nwith standard tools.\n\nCo-Authored-By: Amir Sadoughi < ....>\n\nConflicts:\n\tneutron/agent/securitygroups_rpc.py\n\tneutron/plugins/ml2/drivers/mech_openvswitch.py\n\tneutron/plugins/openvswitch/agent/ovs_neutron_agent.py\n\nChange-Id: I21fdd627e9b028c1ffc7ff4f63828e4443fae6ce\n'}]",0,175347,536547c919a569a1c24db404877c4103018ccca3,39,21,2,8788,,,0,"(DO NOT MERGE/WIP/POC) OVSFirewallDriver

I have backported the driver to Juno to make a test deployment
with standard tools.

Co-Authored-By: Amir Sadoughi < ....>

Conflicts:
	neutron/agent/securitygroups_rpc.py
	neutron/plugins/ml2/drivers/mech_openvswitch.py
	neutron/plugins/openvswitch/agent/ovs_neutron_agent.py

Change-Id: I21fdd627e9b028c1ffc7ff4f63828e4443fae6ce
",git fetch https://review.opendev.org/openstack/neutron refs/changes/47/175347/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/ovs_lib.py', 'neutron/plugins/ml2/drivers/mech_openvswitch.py', 'neutron/agent/linux/openvswitch_firewall.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/agent/securitygroups_rpc.py']",5,f1010bd5acdf0baf494c81557d2316a8308308ae,," for device in devices.values(): self.firewall.prepare_port_filter(device) for device in devices.values(): LOG.debug(""Update port filter for %s"", device['device']) self.firewall.update_port_filter(device)"," for device in devices.values(): self.firewall.prepare_port_filter(device) for device in devices.values(): LOG.debug(_(""Update port filter for %s""), device['device']) self.firewall.update_port_filter(device)",451,9
openstack%2Fneutron~master~I8ad0464e76462bbce13d044c5195225d261c25ba,openstack/neutron,master,I8ad0464e76462bbce13d044c5195225d261c25ba,Stop openvswitch agent rpc connection on Exception,ABANDONED,2015-04-22 21:21:37.000000000,2015-05-21 21:27:27.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-04-22 21:21:37.000000000', 'files': ['neutron/tests/unit/plugins/openvswitch/agent/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/780f761d042fd26dec7313890c7ca99bd0975b95', 'message': 'Stop openvswitch agent rpc connection on Exception\n\nIf exceptions are raised during neutron-server\ninitiation, this will result in lots\nof fanout queues leak in RabbitMQ\n\nThere are many possible cases that will raise\nexception\nbetween self.setup_rpc() and consume_in_thread()\nso this patch\ncatches and logs/stops connections.\n\nChange-Id: I8ad0464e76462bbce13d044c5195225d261c25ba\nCloses-Bug: #1434378\n'}]",0,176495,780f761d042fd26dec7313890c7ca99bd0975b95,22,20,1,2276,,,0,"Stop openvswitch agent rpc connection on Exception

If exceptions are raised during neutron-server
initiation, this will result in lots
of fanout queues leak in RabbitMQ

There are many possible cases that will raise
exception
between self.setup_rpc() and consume_in_thread()
so this patch
catches and logs/stops connections.

Change-Id: I8ad0464e76462bbce13d044c5195225d261c25ba
Closes-Bug: #1434378
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/176495/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/openvswitch/agent/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py']",2,780f761d042fd26dec7313890c7ca99bd0975b95,bug/1434378," connection = None try: if self.enable_tunneling: # The patch_int_ofport and patch_tun_ofport are updated # here inside the call to reset_tunnel_br() self.reset_tunnel_br(tun_br) self.dvr_agent = ovs_dvr_neutron_agent.OVSDVRNeutronAgent( self.context, self.dvr_plugin_rpc, self.int_br, self.tun_br, self.bridge_mappings, self.phys_brs, self.int_ofports, self.phys_ofports, self.patch_int_ofport, self.patch_tun_ofport, cfg.CONF.host, self.enable_tunneling, self.enable_distributed_routing) report_interval = cfg.CONF.AGENT.report_interval if report_interval: heartbeat = loopingcall.FixedIntervalLoopingCall( self._report_state) heartbeat.start(interval=report_interval) if self.enable_tunneling: self.setup_tunnel_br() self.dvr_agent.setup_dvr_flows() # Collect additional bridges to monitor self.ancillary_brs = self.setup_ancillary_bridges(integ_br, tun_br) # Security group agent support self.sg_agent = sg_rpc.SecurityGroupAgentRpc( self.context, self.sg_plugin_rpc, defer_refresh_firewall=True) # Initialize iteration counter self.iter_num = 0 self.run_daemon_loop = True self.quitting_rpc_timeout = quitting_rpc_timeout except Exception: LOG.exception(_LE( ""Failed to initialize %s agent"" % self.__class__.__name__)) self.connection.stop() raise else: # The initialization is complete; we can start receiving messages self.connection.consume_in_threads()"," if self.enable_tunneling: # The patch_int_ofport and patch_tun_ofport are updated # here inside the call to reset_tunnel_br() self.reset_tunnel_br(tun_br) self.dvr_agent = ovs_dvr_neutron_agent.OVSDVRNeutronAgent( self.context, self.dvr_plugin_rpc, self.int_br, self.tun_br, self.bridge_mappings, self.phys_brs, self.int_ofports, self.phys_ofports, self.patch_int_ofport, self.patch_tun_ofport, cfg.CONF.host, self.enable_tunneling, self.enable_distributed_routing) report_interval = cfg.CONF.AGENT.report_interval if report_interval: heartbeat = loopingcall.FixedIntervalLoopingCall( self._report_state) heartbeat.start(interval=report_interval) if self.enable_tunneling: self.setup_tunnel_br() self.dvr_agent.setup_dvr_flows() # Collect additional bridges to monitor self.ancillary_brs = self.setup_ancillary_bridges(integ_br, tun_br) # Security group agent support self.sg_agent = sg_rpc.SecurityGroupAgentRpc(self.context, self.sg_plugin_rpc, defer_refresh_firewall=True) # Initialize iteration counter self.iter_num = 0 self.run_daemon_loop = True # The initialization is complete; we can start receiving messages self.connection.consume_in_threads() self.quitting_rpc_timeout = quitting_rpc_timeout",149,52
openstack%2Fneutron~master~I0a67acf2bf0542bc1c34c2df64e58623ca16af06,openstack/neutron,master,I0a67acf2bf0542bc1c34c2df64e58623ca16af06,TLS capability extension implementation for lbaas v2,ABANDONED,2015-01-21 11:37:06.000000000,2015-05-21 21:27:22.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 6951}, {'_account_id': 8446}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 12040}]","[{'number': 1, 'created': '2015-01-21 11:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/442582baa10b25031c442c602d39a6ee3b2327c1', 'message': 'Adding LBaaS v2 TLS capability extension resources\n\nThis change is part of LBaaS TLS capability feature\nadded to the neutron-lbaas advanced service repository\nhttps://review.openstack.org/#/c/145085\n\nThe change is adding TLS related resources to the existing\nLBaaS v2 extension resources\n\nChange-Id: I0a67acf2bf0542bc1c34c2df64e58623ca16af06\n'}, {'number': 2, 'created': '2015-01-21 14:05:17.000000000', 'files': ['neutron/extensions/loadbalancerv2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c2e344cb04c2de56fd673770bf4d028bad6ee4bd', 'message': 'TLS capability extension implementation for lbaas v2\n\nThis change is part of LBaaS TLS capability feature\nadded to the neutron-lbaas advanced service repository\nhttps://review.openstack.org/#/c/145085\n\nThe change is adding TLS related resources to the existing\nLBaaS v2 extension resources\n\nChange-Id: I0a67acf2bf0542bc1c34c2df64e58623ca16af06\nPartially-implements: blueprint lbaas-ssl-termination\n'}]",0,148896,c2e344cb04c2de56fd673770bf4d028bad6ee4bd,44,20,2,8446,,,0,"TLS capability extension implementation for lbaas v2

This change is part of LBaaS TLS capability feature
added to the neutron-lbaas advanced service repository
https://review.openstack.org/#/c/145085

The change is adding TLS related resources to the existing
LBaaS v2 extension resources

Change-Id: I0a67acf2bf0542bc1c34c2df64e58623ca16af06
Partially-implements: blueprint lbaas-ssl-termination
",git fetch https://review.opendev.org/openstack/neutron refs/changes/96/148896/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/extensions/loadbalancerv2.py'],1,442582baa10b25031c442c602d39a6ee3b2327c1,bp/lbaas-ssl-termination,"PROTOCOL_TERMINATED_HTTPS = 'TERMINATED_HTTPS' POOL_SUPPORTED_PROTOCOLS = (PROTOCOL_TCP, PROTOCOL_HTTPS, PROTOCOL_HTTP) LISTENER_SUPPORTED_PROTOCOLS = (PROTOCOL_TCP, PROTOCOL_HTTPS, PROTOCOL_HTTP, PROTOCOL_TERMINATED_HTTPS) LISTENER_POOL_COMPATIBLE_PROTOCOLS = ( (PROTOCOL_TCP, PROTOCOL_TCP), (PROTOCOL_HTTP, PROTOCOL_HTTP), (PROTOCOL_HTTPS, PROTOCOL_HTTPS), (PROTOCOL_TERMINATED_HTTPS, PROTOCOL_HTTP))class TLSDefaultContainerNotSpecified(nexception.BadRequest): message = _(""Default TLS container was not specified"") class TLSContainerNotFound(nexception.NotFound): message = _(""TLS container %(container_id)s could not be found"") class TLSContainerInvalid(nexception.NeutronException): message = _(""TLS container %(container_id)s is invalid. %(reason)s"") 'default_tls_container_id': {'allow_post': True, 'allow_put': True, 'default': None, 'validate': {'type:uuid_or_none': None}, 'is_visible': True}, 'sni_container_ids': {'allow_post': True, 'allow_put': True, 'default': None, 'convert_to': attr.convert_to_list, 'validate': {'type:uuid_list': None}, 'is_visible': True}, 'validate': {'type:values': LISTENER_SUPPORTED_PROTOCOLS}, 'validate': {'type:values': POOL_SUPPORTED_PROTOCOLS}, plural_mappings.update({'sni_container_ids': 'sni_container_id'})","SUPPORTED_PROTOCOLS = (PROTOCOL_TCP, PROTOCOL_HTTPS, PROTOCOL_HTTP) 'validate': {'type:values': SUPPORTED_PROTOCOLS}, 'validate': {'type:values': SUPPORTED_PROTOCOLS},",35,3
openstack%2Fneutron~master~I9b1c9647eeb158c69ebe47a64ff4fe684b7c01b0,openstack/neutron,master,I9b1c9647eeb158c69ebe47a64ff4fe684b7c01b0,Create the second vip return incorrect error code,ABANDONED,2014-12-22 07:17:24.000000000,2015-05-21 21:27:21.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 8279}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 11126}, {'_account_id': 12040}, {'_account_id': 12683}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-22 07:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1f82945899c8cd946c54957f77c97a3bdc71e24', 'message': 'Create the second vip use one pool id should not return 500 error,\nIt may be 409 error.\n\nChange-Id: I9b1c9647eeb158c69ebe47a64ff4fe684b7c01b0\n'}, {'number': 2, 'created': '2014-12-22 11:19:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5b11f6c80181e164bd95cd72d7ccebba8c95c9f', 'message': 'Create the second vip return incorrect error code\n\nCreate the second vip use the same pool id,it returns 500 error.\nIt should return 409 error code.This will fix it.\n\nChange-Id: I9b1c9647eeb158c69ebe47a64ff4fe684b7c01b0\nFixes: bug #1402908\n'}, {'number': 3, 'created': '2014-12-23 02:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/147a4644d5f61e0d1c8de6b1cbe0e8b4da5288da', 'message': 'Create the second vip return incorrect error code\n\nCreate the second vip use the same pool id,it returns 500 error.\nIt should return 409 error code.This will fix it.\nIt will fix the same bug of creating member.\n\nChange-Id: I9b1c9647eeb158c69ebe47a64ff4fe684b7c01b0\nCloses-Bug: bug #1402908\n'}, {'number': 4, 'created': '2014-12-23 03:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b50e28da30533de4b5d8b4303caaa3ad5c8c75d0', 'message': 'Create the second vip return incorrect error code\n\nCreate the second vip use the same pool id,it returns 500 error.\nIt should return 409 error code.This will fix it.\n\nChange-Id: I9b1c9647eeb158c69ebe47a64ff4fe684b7c01b0\nCloses-Bug: bug #1402908\n'}, {'number': 5, 'created': '2014-12-24 01:57:14.000000000', 'files': ['neutron/extensions/loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a330c4b550f9c7f0e210bf5d712d246bdf695d4', 'message': 'Create the second vip return incorrect error code\n\nCreate the second vip use the same pool id,it returns 500 error.\nIt should return 409 error code.This will fix it.\n\nChange-Id: I9b1c9647eeb158c69ebe47a64ff4fe684b7c01b0\nCloses-Bug: bug #1402908\n'}]",0,143380,0a330c4b550f9c7f0e210bf5d712d246bdf695d4,100,22,5,12683,,,0,"Create the second vip return incorrect error code

Create the second vip use the same pool id,it returns 500 error.
It should return 409 error code.This will fix it.

Change-Id: I9b1c9647eeb158c69ebe47a64ff4fe684b7c01b0
Closes-Bug: bug #1402908
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/143380/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron/extensions/loadbalancer.py'],1,f1f82945899c8cd946c54957f77c97a3bdc71e24,bug/1402908,class VipExists(qexception.Conflict):,class VipExists(qexception.NeutronException):,1,1
openstack%2Fneutron~master~I9c901a0b5c9d5fabd44dab7cbd15209f4bcb20ff,openstack/neutron,master,I9c901a0b5c9d5fabd44dab7cbd15209f4bcb20ff,Create the same member twice should not return 500 error,ABANDONED,2014-12-27 03:29:30.000000000,2015-05-21 21:27:19.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 7805}, {'_account_id': 8124}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 11822}, {'_account_id': 12040}, {'_account_id': 12683}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-27 03:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf7c1f14cf2c48a8c863b8e95b6a6391703e3697', 'message': 'Create the same member twice should not return 500 error\n\n1.Create the first member by using address, protocol-port and one pool id.(successfully)\n2.Create the second member by using the same address, protocol-port and one pool id.(failure)\nAnd return ""Internal Server Error (HTTP 500)""\nThe change will change it to 409 error.\n\nChange-Id: I9c901a0b5c9d5fabd44dab7cbd15209f4bcb20ff\nCloses-Bug: #1405091\n'}, {'number': 2, 'created': '2015-01-06 09:02:15.000000000', 'files': ['neutron/extensions/loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/55d5f1cca8b921d535634f9388f8efcdc12ed7c5', 'message': 'Create the same member twice should not return 500 error\n\nThe change will change it to 409 error.\n\nChange-Id: I9c901a0b5c9d5fabd44dab7cbd15209f4bcb20ff\nCloses-Bug: #1405091\n'}]",1,144188,55d5f1cca8b921d535634f9388f8efcdc12ed7c5,80,29,2,12683,,,0,"Create the same member twice should not return 500 error

The change will change it to 409 error.

Change-Id: I9c901a0b5c9d5fabd44dab7cbd15209f4bcb20ff
Closes-Bug: #1405091
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/144188/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/extensions/loadbalancer.py'],1,bf7c1f14cf2c48a8c863b8e95b6a6391703e3697,bug/1405091,class MemberExists(qexception.Conflict):,class MemberExists(qexception.NeutronException):,1,1
openstack%2Fpython-neutronclient~master~I6071163bda76a2eb0619c7f7d597979f00febdbe,openstack/python-neutronclient,master,I6071163bda76a2eb0619c7f7d597979f00febdbe,Updated type parameter in loadbalancer,ABANDONED,2015-02-20 05:36:24.000000000,2015-05-21 21:27:18.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 6951}, {'_account_id': 11952}]","[{'number': 1, 'created': '2015-02-20 05:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b90129b0f78c9ba563537bb383fa094a017e868a', 'message': 'Updated type parameter in loadbalancer\n\nInitially,  V2 API specification load balancer\nhealthmonitor has a parameter ""type"" which can\nnot be parsed by JSON parser because JSON also\nalso has type parameter\n\nNow, it replaced by ""healthmonitor_type""\n\nChange-Id: I6071163bda76a2eb0619c7f7d597979f00febdbe\nCloses-Bug: #1415336\n'}, {'number': 2, 'created': '2015-02-23 07:24:13.000000000', 'files': ['neutronclient/tests/unit/lb/test_cli20_healthmonitor.py', 'neutronclient/neutron/v2_0/lb/healthmonitor.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/cf85a96c6fa3efb9fe942aa8e0996534a9dad2e6', 'message': 'Updated type parameter in loadbalancer\n\nInitially,  V2 API specification load balancer\nhealthmonitor has a parameter ""type"" which can\nnot be parsed by JSON parser because JSON also\nalso has type parameter\n\nNow, it replaced by ""healthmonitor_type""\n\nChange-Id: I6071163bda76a2eb0619c7f7d597979f00febdbe\nCloses-Bug: #1415336\n'}]",1,157660,cf85a96c6fa3efb9fe942aa8e0996534a9dad2e6,13,9,2,12869,,,0,"Updated type parameter in loadbalancer

Initially,  V2 API specification load balancer
healthmonitor has a parameter ""type"" which can
not be parsed by JSON parser because JSON also
also has type parameter

Now, it replaced by ""healthmonitor_type""

Change-Id: I6071163bda76a2eb0619c7f7d597979f00febdbe
Closes-Bug: #1415336
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/60/157660/2 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/lb/healthmonitor.py'],1,b90129b0f78c9ba563537bb383fa094a017e868a,bug_1415336," list_columns = ['id', 'healthmonitor_type', 'admin_state_up'] '--healthmonitor_type', 'healthmonitor_type': parsed_args.healthmonitor_type,"," list_columns = ['id', 'type', 'admin_state_up'] '--type', 'type': parsed_args.type,",3,3
openstack%2Fneutron~master~Iffb08f042d9198754ff6d30e5be0c74c3e141797,openstack/neutron,master,Iffb08f042d9198754ff6d30e5be0c74c3e141797,Add service group as a firewall customized service,ABANDONED,2015-02-27 02:19:18.000000000,2015-05-21 21:27:16.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 490}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6995}, {'_account_id': 7249}, {'_account_id': 7474}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10041}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10182}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11753}, {'_account_id': 12040}, {'_account_id': 12525}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-02-27 02:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/11320450ce130a71b478a550905ed3a65706fdc8', 'message': 'Add service group as a firewall customized service\n\nThis patch introduces the model and extension framework\nfor implementing service group.\nTwo resources service_group and service_object are added,\nmodules can refer multiple service groups to allow the\nuser flexibilty to define their own groups and use them without impacting\nthe other users.\nEach service object can be defined with a timeout value that can be used\nto overwrite default session idle timeout value.\nMore info can be found at service group wiki\nhttps://wiki.openstack.org/wiki/Neutron/FWaaS/FWaaS-ServiceGroup\nImplements: blueprint fwaas-customized-service for customized service\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\n\nChange-Id: Iffb08f042d9198754ff6d30e5be0c74c3e141797\n'}, {'number': 2, 'created': '2015-03-02 22:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/79dbf7453763293b374da9d536807cb5761ecdc4', 'message': 'Add service group as a firewall customized service\n\nThis patch introduces the model and extension framework\nfor implementing service group.\nTwo resources service_group and service_object are added,\nmodules can refer multiple service groups to allow the\nuser flexibilty to define their own groups and use them without impacting\nthe other users.\nEach service object can be defined with a timeout value that can be used\nto overwrite default session idle timeout value.\nMore info can be found at service group wiki\nhttps://wiki.openstack.org/wiki/Neutron/FWaaS/FWaaS-ServiceGroup\nImplements: blueprint fwaas-customized-service for customized service\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\n\nChange-Id: Iffb08f042d9198754ff6d30e5be0c74c3e141797\n'}, {'number': 3, 'created': '2015-03-04 00:06:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2203df2d74b32878f93adfa00e9e4cdd9f95db17', 'message': 'Add service group as a firewall customized service\n\nThis patch introduces the model and extension framework\nfor implementing service group.\nTwo resources service_group and service_object are added,\nmodules can refer multiple service groups to allow the\nuser flexibilty to define their own groups and use them without impacting\nthe other users.\nEach service object can be defined with a timeout value that can be used\nto overwrite default session idle timeout value.\nMore info can be found at service group wiki\nhttps://wiki.openstack.org/wiki/Neutron/FWaaS/FWaaS-ServiceGroup\nImplements: blueprint fwaas-customized-service for customized service\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\n\nChange-Id: Iffb08f042d9198754ff6d30e5be0c74c3e141797\n'}, {'number': 4, 'created': '2015-03-09 18:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/18ffe1c050bacfa7a9e6c45992d23ce09f31bb16', 'message': 'Add service group as a firewall customized service\n\nThis patch introduces the model and extension framework\nfor implementing service group.\nTwo resources service_group and service_object are added,\nmodules can refer multiple service groups to allow the\nuser flexibilty to define their own groups and use them without impacting\nthe other users.\nEach service object can be defined with a timeout value that can be used\nto overwrite default session idle timeout value.\nMore info can be found at service group wiki\nhttps://wiki.openstack.org/wiki/Neutron/FWaaS/FWaaS-ServiceGroup\nImplements: blueprint fwaas-customized-service for customized service\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\nChange-Id: Iffb08f042d9198754ff6d30e5be0c74c3e141797\n'}, {'number': 5, 'created': '2015-03-09 20:44:17.000000000', 'files': ['neutron/db/migration/models/head.py', 'neutron/extensions/servicegroup.py', 'neutron/db/servicegroup_db.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/db/migration/alembic_migrations/versions/ec870d35388_servicegroup.py', 'neutron/tests/unit/test_extension_service_group.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ece2717e25ea12f2c014c232952612bbe8a2bc5e', 'message': 'Add service group as a firewall customized service\n\nThis patch introduces the model and extension framework\nfor implementing service group.\nTwo resources service_group and service_object are added,\nmodules can refer multiple service groups to allow the\nuser flexibilty to define their own groups and use them without impacting\nthe other users.\nEach service object can be defined with a timeout value that can be used\nto overwrite default session idle timeout value.\nMore info can be found at service group wiki\nhttps://wiki.openstack.org/wiki/Neutron/FWaaS/FWaaS-ServiceGroup\nImplements: blueprint fwaas-customized-service for customized service\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\nChange-Id: Iffb08f042d9198754ff6d30e5be0c74c3e141797\n'}]",27,159692,ece2717e25ea12f2c014c232952612bbe8a2bc5e,107,34,5,11753,,,0,"Add service group as a firewall customized service

This patch introduces the model and extension framework
for implementing service group.
Two resources service_group and service_object are added,
modules can refer multiple service groups to allow the
user flexibilty to define their own groups and use them without impacting
the other users.
Each service object can be defined with a timeout value that can be used
to overwrite default session idle timeout value.
More info can be found at service group wiki
https://wiki.openstack.org/wiki/Neutron/FWaaS/FWaaS-ServiceGroup
Implements: blueprint fwaas-customized-service for customized service
Authored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>
Change-Id: Iffb08f042d9198754ff6d30e5be0c74c3e141797
",git fetch https://review.opendev.org/openstack/neutron refs/changes/92/159692/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/models/head.py', 'neutron/extensions/servicegroup.py', 'neutron/db/servicegroup_db.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/tests/unit/test_extension_service_group.py', 'neutron/db/migration/alembic_migrations/versions/3498d36c18ad_service_group.py']",6,11320450ce130a71b478a550905ed3a65706fdc8,bp/fwaas-customized-service,"# Copyright 2015 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # """"""service_group Revision ID: 3498d36c18ad Revises: 2d2a8a565438 Create Date: 2015-02-26 15:56:48.019935 """""" # revision identifiers, used by Alembic. revision = '3498d36c18ad' down_revision = '2d2a8a565438' from alembic import op import sqlalchemy as sa from sqlalchemy.dialects import mysql def upgrade(): ### commands auto generated by Alembic - please adjust! ### op.create_table('serviceobjects', sa.Column('tenant_id', sa.String(length=255), nullable=True), sa.Column('id', sa.String(length=36), nullable=False), sa.Column('name', sa.String(length=255), nullable=True), sa.Column('protocol', sa.String(length=40), nullable=True), sa.Column('src_port_min', sa.Integer(), nullable=True), sa.Column('src_port_max', sa.Integer(), nullable=True), sa.Column('dst_port_min', sa.Integer(), nullable=True), sa.Column('dst_port_max', sa.Integer(), nullable=True), sa.Column('icmp_code', sa.Integer(), nullable=True), sa.Column('icmp_type', sa.Integer(), nullable=True), sa.Column('timeout', sa.Integer(), nullable=True), sa.PrimaryKeyConstraint('id'), mysql_engine='InnoDB' ) op.create_index(op.f('ix_serviceobjects_tenant_id'), 'serviceobjects', ['tenant_id'], unique=False) op.create_table('servicegroups', sa.Column('tenant_id', sa.String(length=255), nullable=True), sa.Column('id', sa.String(length=36), nullable=False), sa.Column('name', sa.String(length=255), nullable=True), sa.Column('description', sa.String(length=1024), nullable=True), sa.PrimaryKeyConstraint('id'), mysql_engine='InnoDB' ) op.create_index(op.f('ix_servicegroups_tenant_id'), 'servicegroups', ['tenant_id'], unique=False) op.create_table('servicegroup_serviceobject_associations', sa.Column('svg_id', sa.String(length=36), nullable=False), sa.Column('svo_id', sa.String(length=36), nullable=False), sa.ForeignKeyConstraint(['svg_id'], ['servicegroups.id'], ), sa.ForeignKeyConstraint(['svo_id'], ['serviceobjects.id'], ), sa.PrimaryKeyConstraint('svg_id', 'svo_id'), mysql_engine='InnoDB' ) ### end Alembic commands ### def downgrade(): ### commands auto generated by Alembic - please adjust! ### op.drop_table('servicegroup_serviceobject_associations') op.drop_index(op.f('ix_servicegroups_tenant_id'), table_name='servicegroups') op.drop_table('servicegroups') op.drop_index(op.f('ix_serviceobjects_tenant_id'), table_name='serviceobjects') op.drop_table('serviceobjects') ### end Alembic commands ### ",,1329,1
openstack%2Fneutron-lbaas~master~I2570b6eb0d3fb90ac6b11ffdf20d66639058abbd,openstack/neutron-lbaas,master,I2570b6eb0d3fb90ac6b11ffdf20d66639058abbd,Fix vip_session_persistence's cookie_name always NULL,ABANDONED,2015-01-17 07:16:50.000000000,2015-05-21 21:27:15.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6951}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 12040}, {'_account_id': 12860}]","[{'number': 1, 'created': '2015-01-17 07:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/1224b6de4ba14ce1fb54cafdae29dc8d20ae6ae3', 'message': 'Fix vip_session_persistence\'s cookie_name always NULL\nWhen update loadblance vip session-persistence cookie_name,\nuse args like:\n--session-persistence type=dict \\\ntype=""SOURCE_IP"", [cookie_name=""test""]\nThe dict key is [cookie_name, not cookie_name, the same as the value.\n\nTo fix it, strip the bracket.\n\nChange-Id: I2570b6eb0d3fb90ac6b11ffdf20d66639058abbd\nCloses-Bug:#1405135\n'}, {'number': 2, 'created': '2015-01-17 07:22:04.000000000', 'files': ['neutron_lbaas/db/loadbalancer/loadbalancer_db.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/bbb8eaa874cc89218ab98a7f04b31d9ff3c82342', 'message': 'Fix vip_session_persistence\'s cookie_name always NULL\n\nWhen update loadblance vip session-persistence cookie_name,\nuse args like:\n--session-persistence type=dict \\\ntype=""SOURCE_IP"", [cookie_name=""test""]\nThe dict key is [cookie_name, not cookie_name, the same as the value.\n\nTo fix it, strip the bracket.\n\nChange-Id: I2570b6eb0d3fb90ac6b11ffdf20d66639058abbd\nCloses-Bug:#1405135\n'}]",0,148047,bbb8eaa874cc89218ab98a7f04b31d9ff3c82342,12,7,2,12860,,,0,"Fix vip_session_persistence's cookie_name always NULL

When update loadblance vip session-persistence cookie_name,
use args like:
--session-persistence type=dict \
type=""SOURCE_IP"", [cookie_name=""test""]
The dict key is [cookie_name, not cookie_name, the same as the value.

To fix it, strip the bracket.

Change-Id: I2570b6eb0d3fb90ac6b11ffdf20d66639058abbd
Closes-Bug:#1405135
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/47/148047/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/db/loadbalancer/loadbalancer_db.py'],1,1224b6de4ba14ce1fb54cafdae29dc8d20ae6ae3,bug/1405135, if 'cookie_name' not in info.keys()[0]: else: info['cookie_name'] = info.values()[0][:-1], if 'cookie_name' not in info:,3,1
openstack%2Fpython-neutronclient~master~I99fa2768c566b1ecdb45c0c1e1e023862b1a85cb,openstack/python-neutronclient,master,I99fa2768c566b1ecdb45c0c1e1e023862b1a85cb,Fixes Bug1411115,ABANDONED,2015-03-09 09:43:24.000000000,2015-05-21 21:27:12.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 8124}, {'_account_id': 8575}, {'_account_id': 10068}, {'_account_id': 14535}]","[{'number': 1, 'created': '2015-03-09 09:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/fd58dc44043794f8b1cd86100887d100267680f0', 'message': 'Fixes Bug1411115\n\nChange-Id: I99fa2768c566b1ecdb45c0c1e1e023862b1a85cb\n'}, {'number': 2, 'created': '2015-03-11 01:14:07.000000000', 'files': ['neutronclient/neutron/v2_0/router.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/8f5fd139ee5f58ffbaa7b78d81c61fefc3a4e68a', 'message': 'Fixes Bug1411115\n\nChange-Id: I99fa2768c566b1ecdb45c0c1e1e023862b1a85cb\n'}]",2,162582,8f5fd139ee5f58ffbaa7b78d81c61fefc3a4e68a,12,7,2,8575,,,0,"Fixes Bug1411115

Change-Id: I99fa2768c566b1ecdb45c0c1e1e023862b1a85cb
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/82/162582/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/router.py'],1,fd58dc44043794f8b1cd86100887d100267680f0,bug/1411115," parser.add_argument( '--external_gateway_info', dest='external_gateway_info', type=jsonutils.loads, help=_('Set external gateway information.')) ['name', 'tenant_id', 'distributed', 'ha', 'external_gateway_info'])"," ['name', 'tenant_id', 'distributed', 'ha'])",8,1
openstack%2Fneutron-specs~master~Ib0b20d12802bb9a12d9cb8fb19b0dc2c62729af8,openstack/neutron-specs,master,Ib0b20d12802bb9a12d9cb8fb19b0dc2c62729af8,fix some wrapping errors,ABANDONED,2015-03-17 03:31:25.000000000,2015-05-21 21:27:11.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 13000}]","[{'number': 1, 'created': '2015-03-17 03:31:25.000000000', 'files': ['specs/kilo/virtual-network-performance-monitor.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6ddfb7b8470cac8dbec984d2f410b8a0cb895ea9', 'message': 'fix some wrapping errors\n\nChange-Id: Ib0b20d12802bb9a12d9cb8fb19b0dc2c62729af8\n'}]",0,164937,6ddfb7b8470cac8dbec984d2f410b8a0cb895ea9,5,4,1,14129,,,0,"fix some wrapping errors

Change-Id: Ib0b20d12802bb9a12d9cb8fb19b0dc2c62729af8
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/37/164937/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/virtual-network-performance-monitor.rst'],1,6ddfb7b8470cac8dbec984d2f410b8a0cb895ea9,bp/virtual-network-performance-monitor,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Virtual Network Performance Monitor (VNPM) ========================================== https://blueprints.launchpad.net/neutron/+spec/virtual-network-performance-monitor The tenants and operators need to be aware of the network performance, such as delay, delay jitter and packet loss ratio, but current Neutron APIs do not support such requirements. The blueprint introduces a virtual network performance monitor service extension API and corresponding data model for the tenants to specify their requirements on monitoring virtual network performance. Besides, this blueprint also describes the reference implementation of the extended API. Problem Description =================== Currently neutron allows tenants to create virtual network services, but does not provide available API for the tenants to monitor the virtual network for alarming and performance optimization. So, VNPM API is necessary to be provided to monitor network performance indicators (KPIs), including delay, delay jitter, and packet loss. The tenants may obtain these network performance indicators (KPIs) information by running specific tools on VMs now. However, this self-implementation way is complex, special-purpose, error-prone and time consuming. Thus, it is valuable to provide a virtual network performance monitor API to provide that. Proposed Change =============== This blueprint proposes: 1) a North Bound Neutron API to represent the requirement of monitoring virtual network performance in the logical resources. 2) a reference architecture to implement the proposed API. Specifically, the virtual network performance parameters in this blueprint include: 1) Delay: the delay from one port to another port, the port refers to the virtual port in neutron. 2) Delay jitter: the variation of packet delay from one port to another port. 3) Packet loss: the ratio of lost packets to total transmitted packets from one port to another port. The introduced interface allows the tenants to express their requirements on virtual network performance monitoring, e.g., the source and destination of the port to monitor. The main advantage of the extensions described in this blueprint is that they provide a standard and flexible way for the tenants and operators to monitor virtual network performance, while current Neutron APIs do not support such requirements. The following diagram illustrates the overall workflows. asciiflow:: +-------------------------+ | | | | | Neutron Server | +-------+ +-----+ | | | | | | | | | | | | | +-------------------------+ | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | ML2 Plugin | | VNPM Plugin | | | | | | | | | +-------------------------+ +-------------------------+ | | | | | | +-------------------------+ | | | | | Compute Node | | | | | | +----------------------+ | +-----------+ | | | | |----| VNPM Agent | | | | | |----------------+ | | | | | | | | | vProbe | +----------------------+ | | | | |------------+ | | +-----------+ VNPM plugin is proposed to provide North Bound REST interface, which supports CRUD operation on VNPM resource. VNPM Agent and vProbe is proposed to implement the function of measuring network performance. Specifically, each compute node deploys VNPM agent and vProbe. The VNPM plugin transforms the Rest APIs into Neutron RPC messages. The RPC messages are sent to the proposed VNPM agents by the RabbitMQ bus. According to the received messages, the VNPM agent manages the vProbe, and the vProbe sends test packets to other vProbe to test the network performance. The vProbe then sends the test result to the VNPM agent, and the VNPM agent further populates the network performance information with the Oslo notification mechanism. The above architecture/method is only for reference implementation. The developers can also use other architecture/methods to implement the proposed interfaces. for supporting this VNPM API, vProbe and VNPM agent are proposed to use. Data Model Impact ----------------- Add DB tables: * neutron.VNPMs New DB model introduced: 1.VNPM * vn_performance_monitors - the VNPM resource. Attributes: * id - unique identifier. * name - user readable name of the specified VNPM. * description - description of the VNPM. * tenant-id - the creator and owner of the VNPM. * source_id - the neutron port of the source of the network performance to be measured. * destination_id - the neutron port of the destination of the network performance to be measured. * test_type - once or periodic measurement. * period_time - the time duration of a measurement, only functions when the test type is set to periodic. * response_type - two options: {normal, only alarm}. If the value is set to ""normal"", every measurement results will be reported. If the value is set to ""only alarm"", only the measurement results that exceeds the specified threshold be reported. * reachability - indicates whether to test reachability or not. * delay - indicates whether to test delay or not. * delay_threshold - the threshold of the delay, only functions when delay is tested and the response_type is set to ""only alarm"". * jitter - indicates whether to test delay jitter or not. * jitter_threshold - the threshold of the delay jitter, only functions when delay jitter is tested and the response_type is set to ""only alarm"". * loss - indicates whether to test packet loss ratio or not. * loss_threshold- the threshold of the packet loss ratio, only functions when packet loss is tested and the response_type is set to ""only alarm"". REST API Impact --------------- A separate extension will be created that will expose the VNPM resource. The VNPM resource property is presented as follows: RESOURCE_ATTRIBUTE_MAP = { 'vn_performance_monitors': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'description': {'allow_post': True,'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'source_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'destination_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'test_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['once','periodic']}, 'is_visible': True, 'default': 'once'}, 'period_time': {'allow_post': True, 'allow_put': True, 'validate': {'type:float': None}, 'is_visible': True}, 'response_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['normal','only_alarm']}, 'is_visible': True}, 'reachability': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'jitter': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'loss': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay_threshold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'jitter_threshold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'loss_threshold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, } } Security Impact --------------- Standard Neutron tenant object ownership rules will apply. Notifications Impact -------------------- New notifications will be added to report the virtual network performance. The format of the notification: +--------------+------------+--------------------------------------------------------+ |key |Value |Notes | +--------------+------------+--------------------------------------------------------+ |id |Integer |VNPM ID | +--------------+------------+--------------------------------------------------------+ |test_type |String |The value should be ""once"" or ""periodic"" | +--------------+------------+--------------------------------------------------------+ |period_time |Integer |Time duration for two tests if test_type is set to | | | |""periodic"" | +--------------+------------+--------------------------------------------------------+ |response_type |String |The value should be ""normal"" or ""only alarm"" | +--------------+------------+--------------------------------------------------------+ |notification | | | |_time |Integer |The time sending this notification | +--------------+------------+--------------------------------------------------------+ |reachability |Bool |True if reachable; False if not reachable | +--------------+------------+--------------------------------------------------------+ |delay(ms) |float |The packets delay from the source neutron port to the | | | |destination neutron port | +--------------+------------+--------------------------------------------------------+ |jitter(ms) |float |The delay jitter | +--------------+------------+--------------------------------------------------------+ |loss |float |packets loss ratio | +--------------+------------+--------------------------------------------------------+ Other End User Impact --------------------- None. Performance Impact ------------------ The vProbes need to send test packets and therefore have impact on system performance. However, the administrator can configure how much resource the vProbe can use, including the percentage of CPU cycle, the total throughput, to minimize the impact. IPv6 Impact ----------- None Other Deployer Impact --------------------- If vProbe is to be enabled, it is required to configure the vProbe plugin in neutron.conf. Developer Impact ---------------- This API is a new resource extension, and will not affect existing API. Community Impact ---------------- None Alternatives ------------ Since new data model and interface is being proposed here, a direct alternate does not exist. If ovs/linuxbridge has the vProbe function, VNPM plugin can directly communicate with ovs/linuxbridge. Implementation ============== Assignee(s) ----------- Chengyong Lin, linchengyong@huawei.com Jiaqiang Liu, liujq89@gmail.com Shaoran Xiao, xsran@163.com Feng Dong, albert.dongfeng@huawei.com Xiaofeng Ji, jixiaofeng@huawei.com Depeng Jin, nxjql@126.com Yong Li, liyong07@tsinghua.edu.cn Fengkai Li, lifengkai@huawei.com Wenxia Dong, dongwenxia@huawei.com Enhui Liu, liuenhui@huawei.com Work Items ---------- 1. Implementing Rest API extension * Add a file under neutron/extensions to implement resource extension to and the base class of the plugin to process the API request. * Add a file under neutron/db to implement the data base operation. * Add a directory under neutron/services to implement the plugin. 2. Implementing vProbe * The function of vProbe includes sending test packets to specified IP, calculating the network performance parameter according to the received test packets. Besides, the vProbe should provide interfaces to communicate with VNPM agents. The implementation will be deployed on compute node as a system service. 3. Implementing VNPM agent * The function of VNPM agent includes interaction with the VNPM plugin through RPC, managing vProbes, populate the network performance information with Oslo notification mechanism. The implementation file of VNPM agent will be put under neutron/services/VNPM, and deployed on compute node. Dependencies ============ None Testing ======= Both, functional and, system tests will be added. Tempest Tests ------------- None Functional Tests ---------------- None API Tests --------- None Documentation Impact ==================== User Documentation ------------------ None Developer Documentation ----------------------- None References ========== None ",,383,0
openstack%2Fneutron-specs~master~If82efa9a3a4780e901f6ddf6de9d8910cdcb6993,openstack/neutron-specs,master,If82efa9a3a4780e901f6ddf6de9d8910cdcb6993,Remove the extra blank lines,ABANDONED,2015-03-17 03:13:39.000000000,2015-05-21 21:27:10.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 13000}]","[{'number': 1, 'created': '2015-03-17 03:13:39.000000000', 'files': ['specs/kilo/virtual-network-performance-monitor.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2328de745ef85a94b4097a95625a830f3f14229a', 'message': 'Remove the extra blank lines\n\nChange-Id: If82efa9a3a4780e901f6ddf6de9d8910cdcb6993\n'}]",0,164935,2328de745ef85a94b4097a95625a830f3f14229a,5,4,1,14129,,,0,"Remove the extra blank lines

Change-Id: If82efa9a3a4780e901f6ddf6de9d8910cdcb6993
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/35/164935/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/virtual-network-performance-monitor.rst'],1,2328de745ef85a94b4097a95625a830f3f14229a,bp/virtual-network-performance-monitor,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Virtual Network Performance Monitor (VNPM) ========================================== https://blueprints.launchpad.net/neutron/+spec/virtual-network-performance-monitor The tenants and operators need to be aware of the network performance, such as delay, delay jitter and packet loss ratio, but current Neutron APIs do not support such requirements. The blueprint introduces a virtual network performance monitor service extension API and corresponding data model for the tenants to specify their requirements on monitoring virtual network performance. Besides, this blueprint also describes the reference implementation of the extended API. Problem Description =================== Currently neutron allows tenants to create virtual network services, but does not provide available API for the tenants to monitor the virtual network for alarming and performance optimization. So, VNPM API is necessary to be provided to monitor network performance indicators (KPIs), including delay, delay jitter, and packet loss. The tenants may obtain these network performance indicators (KPIs) information by running specific tools on VMs now. However, this self-implementation way is complex, special-purpose, error-prone and time consuming. Thus, it is valuable to provide a virtual network performance monitor API to provide that. Proposed Change =============== This blueprint proposes: * a North Bound Neutron API to represent the requirement of monitoring virtual network performance in the logical resources. * a reference architecture to implement the proposed API. Specifically, the virtual network performance parameters in this blueprint include: * Delay: the delay from one port to another port, the port refers to the virtual port in neutron. * Delay jitter: the variation of packet delay from one port to another port. * Packet loss: the ratio of lost packets to total transmitted packets from one port to another port. The introduced interface allows the tenants to express their requirements on virtual network performance monitoring, e.g., the source and destination of the port to monitor. The main advantage of the extensions described in this blueprint is that they provide a standard and flexible way for the tenants and operators to monitor virtual network performance, while current Neutron APIs do not support such requirements. The following diagram illustrates the overall workflows. asciiflow:: +-------------------------+ | | | | | Neutron Server | +-------+ +-----+ | | | | | | | | | | | | | +-------------------------+ | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | ML2 Plugin | | VNPM Plugin | | | | | | | | | +-------------------------+ +-------------------------+ | | | | | | +-------------------------+ | | | | | Compute Node | | | | | | +----------------------+ | +-----------+ | | | | |----| VNPM Agent | | | | | |----------------+ | | | | | | | | | vProbe | +----------------------+ | | | | |------------+ | | +-----------+ VNPM plugin is proposed to provide North Bound REST interface, which supports CRUD operation on VNPM resource. VNPM Agent and vProbe is proposed to implement the function of measuring network performance. Specifically, each compute node deploys VNPM agent and vProbe. The VNPM plugin transforms the Rest APIs into Neutron RPC messages. The RPC messages are sent to the proposed VNPM agents by the RabbitMQ bus. According to the received messages, the VNPM agent manages the vProbe, and the vProbe sends test packets to other vProbe to test the network performance. The vProbe then sends the test result to the VNPM agent, and the VNPM agent further populates the network performance information with the Oslo notification mechanism. The above architecture/method is only for reference implementation. The developers can also use other architecture/methods to implement the proposed interfaces. For supporting this VNPM API, vProbe and VNPM agent are proposed to use. Data Model Impact ----------------- Add DB tables: * neutron.VNPMs New DB model introduced: 1.VNPM * vn_performance_monitors - the VNPM resource. Attributes: * id - unique identifier. * name - user readable name of the specified VNPM. * description - description of the VNPM. * tenant-id - the creator and owner of the VNPM. * source_id - the neutron port of the source of the network performance to be measured. * destination_id - the neutron port of the destination of the network performance to be measured. * test_type - once or periodic measurement. * period_time - the time duration of a measurement, only functions when the test type is set to periodic. * response_type - two options: {normal, only alarm}. If the value is set to ""normal"", every measurement results will be reported. If the value is set to ""only alarm"", only the measurement results that exceeds the specified threshold be reported. * reachability - indicates whether to test reachability or not. * delay - indicates whether to test delay or not. * delay_threshold - the threshold of the delay, only functions when delay is tested and the response_type is set to ""only alarm"". * jitter - indicates whether to test delay jitter or not. * jitter_threshold - the threshold of the delay jitter, only functions when delay jitter is tested and the response_type is set to ""only alarm"". * loss - indicates whether to test packet loss ratio or not. * loss_threshold- the threshold of the packet loss ratio, only functions when packet loss is tested and the response_type is set to ""only alarm"". REST API Impact --------------- A separate extension will be created that will expose the VNPM resource. The VNPM resource property is presented as follows: RESOURCE_ATTRIBUTE_MAP = { 'vn_performance_monitors': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'description': {'allow_post': True,'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'source_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'destination_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'test_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['once','periodic']}, 'is_visible': True, 'default': 'once'}, 'period_time': {'allow_post': True, 'allow_put': True, 'validate': {'type:float': None}, 'is_visible': True}, 'response_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['normal','only_alarm']}, 'is_visible': True}, 'reachability': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'jitter': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'loss': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay_threshold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'jitter_threshold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'loss_threshold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, } } Security Impact --------------- Standard Neutron tenant object ownership rules will apply. Notifications Impact -------------------- New notifications will be added to report the virtual network performance. The format of the notification: +--------------+------------+--------------------------------------------------------+ |key |Value |Notes | +--------------+------------+--------------------------------------------------------+ |id |Integer |VNPM ID | +--------------+------------+--------------------------------------------------------+ |test_type |String |The value should be ""once"" or ""periodic"" | +--------------+------------+--------------------------------------------------------+ |period_time |Integer |Time duration for two tests if test_type is set to | | | |""periodic"" | +--------------+------------+--------------------------------------------------------+ |response_type |String |The value should be ""normal"" or ""only alarm"" | +--------------+------------+--------------------------------------------------------+ |notification | | | |_time |Integer |The time sending this notification | +--------------+------------+--------------------------------------------------------+ |reachability |Bool |True if reachable; False if not reachable | +--------------+------------+--------------------------------------------------------+ |delay(ms) |float |The packets delay from the source neutron port to the | | | |destination neutron port | +--------------+------------+--------------------------------------------------------+ |jitter(ms) |float |The delay jitter | +--------------+------------+--------------------------------------------------------+ |loss |float |packets loss ratio | +--------------+------------+--------------------------------------------------------+ Other End User Impact --------------------- None. Performance Impact ------------------ The vProbes need to send test packets and therefore have impact on system performance. However, the administrator can configure how much resource the vProbe can use, including the percentage of CPU cycle, the total throughput, to minimize the impact. IPv6 Impact ----------- None Other Deployer Impact --------------------- If vProbe is to be enabled, it is required to configure the vProbe plugin in neutron.conf. Developer Impact ---------------- This API is a new resource extension, and will not affect existing API. Community Impact ---------------- None Alternatives ------------ Since new data model and interface is being proposed here, a direct alternate does not exist. If ovs/linuxbridge has the vProbe function, VNPM plugin can directly communicate with ovs/linuxbridge. Implementation ============== Assignee(s) ----------- Chengyong Lin, linchengyong@huawei.com Jiaqiang Liu, liujq89@gmail.com Shaoran Xiao, xsran@163.com Feng Dong, albert.dongfeng@huawei.com Xiaofeng Ji, jixiaofeng@huawei.com Depeng Jin, nxjql@126.com Yong Li, liyong07@tsinghua.edu.cn Fengkai Li, lifengkai@huawei.com Wenxia Dong, dongwenxia@huawei.com Enhui Liu, liuenhui@huawei.com Work Items ---------- 1. Implementing Rest API extension * Add a file under neutron/extensions to implement resource extension to and the base class of the plugin to process the API request. * Add a file under neutron/db to implement the data base operation. * Add a directory under neutron/services to implement the plugin. 2. Implementing vProbe * The function of vProbe includes sending test packets to specified IP, calculating the network performance parameter according to the received test packets. Besides, the vProbe should provide interfaces to communicate with VNPM agents. The implementation will be deployed on compute node as a system service. 3. Implementing VNPM agent * The function of VNPM agent includes interaction with the VNPM plugin through RPC, managing vProbes, populate the network performance information with Oslo notification mechanism. The implementation file of VNPM agent will be put under neutron/services/VNPM, and deployed on compute node. Dependencies ============ None Testing ======= Both, functional and, system tests will be added. Tempest Tests ------------- None Functional Tests ---------------- None API Tests --------- None Documentation Impact ==================== User Documentation ------------------ None Developer Documentation ----------------------- None References ========== None ",,338,0
openstack%2Fneutron~master~I8cbb04209cdc1370f14179e568536ad56cb8c559,openstack/neutron,master,I8cbb04209cdc1370f14179e568536ad56cb8c559,Add log for metadata DB reset,ABANDONED,2015-03-30 08:55:46.000000000,2015-05-21 21:27:09.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 6981}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10068}, {'_account_id': 10116}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11343}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-03-30 08:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/079c005e0c422bdfe0446f755357240d56f35ca6', 'message': 'Add log for metadata DB reset\n\nAdd a debug log to remind user the metadata does not need DB connection,\nso reset it.\n\nChange-Id: I8cbb04209cdc1370f14179e568536ad56cb8c559\n'}, {'number': 2, 'created': '2015-03-30 09:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01a9133132b393d6a04f46c53af2150f119d9883', 'message': 'Add log for metadata DB reset\n\nAdd a debug log to remind user the metadata does not need DB connection,\nso reset it.\n\nChange-Id: I8cbb04209cdc1370f14179e568536ad56cb8c559\n'}, {'number': 3, 'created': '2015-03-31 02:26:11.000000000', 'files': ['neutron/agent/metadata_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/051f6d29ecf60d8b1493bb26e6c03e129ec15937', 'message': 'Add log for metadata DB reset\n\nAdd a warning log to remind user the metadata does not need DB connection,\nso reset it.\n\nChange-Id: I8cbb04209cdc1370f14179e568536ad56cb8c559\n'}]",7,168821,051f6d29ecf60d8b1493bb26e6c03e129ec15937,82,30,3,15814,,,0,"Add log for metadata DB reset

Add a warning log to remind user the metadata does not need DB connection,
so reset it.

Change-Id: I8cbb04209cdc1370f14179e568536ad56cb8c559
",git fetch https://review.opendev.org/openstack/neutron refs/changes/21/168821/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/metadata_agent.py'],1,079c005e0c422bdfe0446f755357240d56f35ca6,db_reset_log," LOG.debug(""Clean DB connection for metadata"")",,1,0
openstack%2Fneutron~master~Ifa612d3bb9f2b00230fb3be7bb088f98efeb43f0,openstack/neutron,master,Ifa612d3bb9f2b00230fb3be7bb088f98efeb43f0,L7 capability extension implementation for lbaas v2,ABANDONED,2015-01-21 09:54:48.000000000,2015-05-21 21:27:06.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6951}, {'_account_id': 8446}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 12040}]","[{'number': 1, 'created': '2015-01-21 09:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8cb9406c81e744bc7ca9ddf1c714016a19675989', 'message': 'Adding LBaaS v2 L7 capability extension resources\n\nThis change is part of LBaaS L7 capability feature\nadded to the neutron-lbaas advanced service repository\nhttps://review.openstack.org/#/c/148232/\n\nThe change is adding L7 related resources to the existing\nLBaaS v2 extension resources\n\nChange-Id: Ifa612d3bb9f2b00230fb3be7bb088f98efeb43f0\n'}, {'number': 2, 'created': '2015-01-21 13:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3030d504f6d2217ef7f8a497453eda5d38755c66', 'message': 'L7 capability extension implementation for lbaas v2\n\nThis change is part of LBaaS L7 capability feature\nadded to the neutron-lbaas advanced service repository\nhttps://review.openstack.org/#/c/148232/\n\nThe change is adding L7 related resources to the existing\nLBaaS v2 extension resources\n\nChange-Id: Ifa612d3bb9f2b00230fb3be7bb088f98efeb43f0\nPartially-implements: blueprint lbaas-l7-rules\n'}, {'number': 3, 'created': '2015-01-21 16:57:18.000000000', 'files': ['neutron/extensions/loadbalancerv2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/154ba1d47dfb8d01ef223f0da65b1356ebde4970', 'message': 'L7 capability extension implementation for lbaas v2\n\nThis change is part of LBaaS L7 capability feature\nadded to the neutron-lbaas advanced service repository\nhttps://review.openstack.org/#/c/148232/\n\nThe change is adding L7 related resources to the existing\nLBaaS v2 extension resources\n\nThis is WIP\n\nChange-Id: Ifa612d3bb9f2b00230fb3be7bb088f98efeb43f0\nPartially-implements: blueprint lbaas-l7-rules'}]",2,148859,154ba1d47dfb8d01ef223f0da65b1356ebde4970,63,22,3,8446,,,0,"L7 capability extension implementation for lbaas v2

This change is part of LBaaS L7 capability feature
added to the neutron-lbaas advanced service repository
https://review.openstack.org/#/c/148232/

The change is adding L7 related resources to the existing
LBaaS v2 extension resources

This is WIP

Change-Id: Ifa612d3bb9f2b00230fb3be7bb088f98efeb43f0
Partially-implements: blueprint lbaas-l7-rules",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/148859/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/extensions/loadbalancerv2.py'],1,8cb9406c81e744bc7ca9ddf1c714016a19675989,bp/lbaas-l7-rules,"import sysL7_RULE_TYPE_HOST_NAME = 'HOST_NAME' L7_RULE_TYPE_PATH = 'PATH' L7_RULE_TYPE_FILE_TYPE = 'FILE_TYPE' L7_RULE_TYPE_HEADER = 'HEADER' L7_RULE_TYPE_COOKIE = 'COOKIE' SUPPORTED_L7_RULE_TYPES = (L7_RULE_TYPE_HOST_NAME, L7_RULE_TYPE_PATH, L7_RULE_TYPE_FILE_TYPE, L7_RULE_TYPE_HEADER, L7_RULE_TYPE_COOKIE) L7_RULE_COMPARE_TYPE_REGEX = 'REGEX' L7_RULE_COMPARE_TYPE_STARTS_WITH = 'STARTS_WITH' L7_RULE_COMPARE_TYPE_ENDS_WITH = 'ENDS_WITH' L7_RULE_COMPARE_TYPE_CONTAINS = 'CONTAINS' L7_RULE_COMPARE_TYPE_EQUALS_TO = 'EQUALS_TO' L7_RULE_COMPARE_TYPE_GREATER_THAN = 'GREATER_THAN' L7_RULE_COMPARE_TYPE_LESS_THAN = 'LESS_THAN' SUPPORTED_L7_RULE_COMPARE_TYPES = (L7_RULE_COMPARE_TYPE_REGEX, L7_RULE_COMPARE_TYPE_STARTS_WITH, L7_RULE_COMPARE_TYPE_ENDS_WITH, L7_RULE_COMPARE_TYPE_CONTAINS, L7_RULE_COMPARE_TYPE_EQUALS_TO, L7_RULE_COMPARE_TYPE_GREATER_THAN, L7_RULE_COMPARE_TYPE_LESS_THAN) L7_POLICY_ACTION_REJECT = 'REJECT' L7_POLICY_ACTION_REDIRECT_TO_POOL = 'REDIRECT_TO_POOL' L7_POLICY_ACTION_REDIRECT_TO_URL = 'REDIRECT_TO_URL' SUPPORTED_L7_POLICY_ACTIONS = (L7_POLICY_ACTION_REJECT, L7_POLICY_ACTION_REDIRECT_TO_POOL, L7_POLICY_ACTION_REDIRECT_TO_URL) class L7PolicyRedirectPoolIdMissing(nexception.Conflict): message = _(""Redirect pool id is missing for L7 Policy with"" "" pool redirect action"") class L7PolicyRedirectUrlMissing(nexception.Conflict): message = _(""Redirect URL is missing for L7 Policy with"" "" URL redirect action"") class RuleNotFoundForL7Policy(nexception.NotFound): message = _(""Rule %(rule_id)s could not be found in"" "" l7 policy %(l7policy_id)s"") }, 'l7policies': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'description': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'listener_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True}, 'action': {'allow_post': True, 'allow_put': True, 'validate': { 'type:values': SUPPORTED_L7_POLICY_ACTIONS}, 'is_visible': True}, 'redirect_pool_id': {'allow_post': True, 'allow_put': True, 'validate': {'type:uuid_or_none': None}, 'default': attr.ATTR_NOT_SPECIFIED, 'is_visible': True}, 'redirect_url': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'position': {'allow_post': True, 'allow_put': True, 'convert_to': attr.convert_to_int, 'default': sys.maxint, 'is_visible': True}, 'rules': {'allow_post': False, 'allow_put': False, 'is_visible': True}, 'admin_state_up': {'allow_post': True, 'allow_put': True, 'default': True, 'convert_to': attr.convert_to_boolean, 'is_visible': True}, 'status': {'allow_post': False, 'allow_put': False, 'is_visible': True} }, 'rules': { 'parent': {'collection_name': 'l7policies', 'member_name': 'l7policy'}, 'parameters': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'type': {'allow_post': True, 'allow_put': True, 'validate': { 'type:values': SUPPORTED_L7_RULE_TYPES}, 'is_visible': True}, 'compare_type': {'allow_post': True, 'allow_put': True, 'validate': { 'type:values': SUPPORTED_L7_RULE_COMPARE_TYPES}, 'is_visible': True}, 'key': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True}, 'value': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'admin_state_up': {'allow_post': True, 'allow_put': True, 'default': True, 'convert_to': attr.convert_to_boolean, 'is_visible': True}, 'status': {'allow_post': False, 'allow_put': False, 'is_visible': True} } special_mappings = {'l7policies': 'l7policy'} special_mappings, RESOURCE_ATTRIBUTE_MAP) plural_mappings['rules'] = 'rule' resource_name = special_mappings.get(collection_name, collection_name[:-1]) @abc.abstractmethod def get_l7policies(self, context, filters=None, fields=None): pass @abc.abstractmethod def get_l7policy(self, context, id, fields=None): pass @abc.abstractmethod def create_l7policy(self, context, l7policy): pass @abc.abstractmethod def update_l7policy(self, context, id, l7policy): pass @abc.abstractmethod def delete_l7policy(self, context, id): pass @abc.abstractmethod def get_l7policy_rules(self, context, l7policy_id, filters=None): pass @abc.abstractmethod def get_l7policy_rule(self, context, id, l7policy_id): pass @abc.abstractmethod def create_l7policy_rule(self, context, rule, l7policy_id): pass @abc.abstractmethod def update_l7policy_rule(self, context, id, rule, l7policy_id): pass @abc.abstractmethod def delete_l7policy_rule(self, context, id, l7policy_id): pass"," {}, RESOURCE_ATTRIBUTE_MAP) resource_name = collection_name[:-1]",175,2
openstack%2Fneutron-specs~master~I3a7445a8cd43504cdb3db3d078cc1a4e2c58c343,openstack/neutron-specs,master,I3a7445a8cd43504cdb3db3d078cc1a4e2c58c343,Implements: Blueprint TimeSyncAsAService,ABANDONED,2015-04-04 12:21:05.000000000,2015-05-21 21:27:04.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6072}, {'_account_id': 9237}, {'_account_id': 10370}, {'_account_id': 10980}, {'_account_id': 12525}, {'_account_id': 14605}]","[{'number': 1, 'created': '2015-04-04 12:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/675385d4e417114fde9b48678b0fcb658266fd2d', 'message': 'Implements: Blueprint TimeSyncAsAService\n\nChange-Id: I3a7445a8cd43504cdb3db3d078cc1a4e2c58c343\n'}, {'number': 2, 'created': '2015-04-04 14:24:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/39b57282f589a967c150eb4043084658e84b8090', 'message': 'Implements: Blueprint TimeSyncAsAService\n\nChange-Id: I3a7445a8cd43504cdb3db3d078cc1a4e2c58c343\n'}, {'number': 3, 'created': '2015-04-04 15:54:49.000000000', 'files': ['specs/liberty/time-sync-as-service.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/1120c30964399b750c898fde399e5216e65611a5', 'message': 'Implements: Blueprint TimeSyncAsAService\n\nChange-Id: I3a7445a8cd43504cdb3db3d078cc1a4e2c58c343\n'}]",14,170671,1120c30964399b750c898fde399e5216e65611a5,26,8,3,14605,,,0,"Implements: Blueprint TimeSyncAsAService

Change-Id: I3a7445a8cd43504cdb3db3d078cc1a4e2c58c343
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/71/170671/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/time-sync-as-service.rst'],1,675385d4e417114fde9b48678b0fcb658266fd2d,bp/TimeSyncAsAService,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================================== Neutron Time Synchronization as a service using NTP =================================================== URL of the launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/time-sync-as-service In modern computer networks time synchronization is critical because every aspect of managing, securing, planning, and debugging a network involves determining when events happen. Time also provides the only frame of reference between all devices on the network. Without synchronized time, accurately correlating log files between these devices is difficult, even impossible. Current Openstack framework provides a provision for time synchronization via running NTP [1]_ server on the control node [2]_. All the VM's in turn synchronize their timing from the time server running on the control node. This blueprint proposes a idea of enhancing the current openstack time synchronization capibility. Problem description =================== Multiple tenants can be orchestrated and monitored in the purview of a single openstack framework. Let say different tenants orchestrated by same openstack admin, want to synchronize their time from different time source for their own reasons, business and trust. An example to this could be a tenant whose network is geographically distributed and he want to synchronize the time of his entire network from a single time source to ensure time uniformity acroos all his network. Proposed change =============== Our proposal will enhance the current time synchronization capibility by 1. Providing single or multiple time synchronization sources (i.e. primary and secondary to consider failover of primary time source) for different tenants. This could also be extended to have a single time synchronization for all the tenants (i.e. the current behavior). 2. Introducing an idea of having separate NTP agent per tenant which will act as NTP server for the specific tenant. All the tenant VM's should synchronize their time from the NTP agent. 3. Using NTP's authentication functionality and guarantee authenticity and reliability of the synchronized time. All the above mentioned functionalities will be achieved by extending neutron's advanced service plugin framework. For achieving this we need to have 1. An API to create/delete NTP authentication details. 2. An API to create/delete NTP time synchronization source with its time synchronization mode details. 3. Separate NTP agents per tenant which will act as NTP time server for their respective tenant/s. 4. Database updates (new resources) for supporting above API's. Alternatives ============ This blueprint does not mandate that the proposed technology should only to be used for achiving time synchronization. The same may be achieved by following the steps as stated in openstack Network Time Protocol (NTP) configuration guide [1]_. Data model impact ================= Following new resources are proposed: 1. NtpAuthentication +---------+------+-------+---------+-------------+---------------+ |Attribute|Type |Access |Default |Validation/ ||Description | |Name | | |Value |Conversion | | +=========+======+=======+=========+=============+===============+ |id |string|RO, all|generated|N/A |Identity. | | |(UUID)| | | | | +---------+------+-------+---------+-------------+---------------+ |tenant_Id|string|RW, all|required |string |Tenant details.| | |(UUID)| | | | | +---------+------+-------+---------+-------------+---------------+ |source_Id| |RW, all|required |foreign-key |Time source | | | | | |for |details. | | | | | |NtpTimeSource| | +---------+------+-------+---------+-------------+---------------+ |auth_type|string|RW, all|required |string |Authentication | | | | | | |type. (simple | | | | | | |or autokey) | +---------+------+-------+---------+-------------+---------------+ |username |string|RW, all|optional |string |Authentication | | | | | | |username, if | | | | | | |the auth_type | | | | | | |is simple. | +---------+------+-------+---------+-------------+---------------+ |password |string|RW, all|optional |string |Authentication | | | | | | |password, if | | | | | | |the auth_type | | | | | | |is simple. | +---------+------+-------+---------+-------------+---------------+ 2. NtpTimeSource +---------+------+-------+---------+-----------+---------------------+ |Attribute|Type |Access |Default |Validation/|Description | |Name | | |Value |Conversion | | +=========+======+=======+=========+===========+=====================+ |id |string|RO, all|generated|N/A |Identity. | | |(UUID)| | | | | +---------+------+-------+---------+-----------+---------------------+ |name |string|RO, all|generated|N/A |Time synchronization | | |(UUID)| | | |source name. | +---------+------+-------+---------+-----------+---------------------+ |tenant_Id|string|RW, all|required |string |Tenant details. | | |(UUID)| | | | | +---------+------+-------+---------+-----------+---------------------+ |version |string|RW, all|optional |string |NTP protocol version | | | | | | |(either version 3/4) | | | | | | |By default, NTPv4 | | | | | | |version will be | | | | | | |considered. | +---------+------+-------+---------+-----------+---------------------+ |mode |string|RW, all|optional |string |Time source mode | | | | | | |(unicast / multicast)| | | | | | |.By default, the | | | | | | | mode will be unicast| +---------+------+-------+---------+-----------+---------------------+ |ip |string|RW, all|optional |string |Time source IP | | | | | | |address. | +---------+------+-------+---------+-----------+-------------------- + |role |string|RW, all|optional |string |Primary or secondary | | | | | | |By default, role | | | | | | |will be considered | | | | | | |to be primary. | +---------+------+-------+---------+-----------+-------------------- + |auth |string|RW, all|required |string |Authentication name, | | | | | | |defined via | | | | | | |NtpAuthentication. | +---------+------+-------+---------+-----------+-------------------- + Note: Above defined resource packages can also be exteneded in future for adding various facilities provided by NTP protocol _[2]. USAGE WORKFLOW: +------------------------------------------------------+ | | | +-------------+ +-------------+ +-------------+ | | | NTP Agent | | NTP Agent | | NTP Agent | | | | for Tenant_1| | for Tenant_2| | for Tenant_n| | | +-------------+ +-------------+...+-------------+ | | | | | | +-------------+ | | | Network Node| | | +-------------| | | | +------------------------------------------------------+ 1. Assume a topology in which different tenant want to synchronize the time from different time sources (Ex. Let's say Tenant_1 from Time_Source1, Tenant_2 from Time_Source2 and so on.) 2. If the tenant want to set authentication rule then the same needs to be specified first. (Ex: Let's say Tenant_2 want to have simple authentication for it's primary time source and autokey authencation for the secondary source.) a. Create simple authentication neutron ntp-auth-create --name simpleauth --type simple --username openstack --password openstack b. Create autokey authentication neutron ntp-auth-create --name autokeyauth --type autokey 3. Create separate NTP time sources for diferent tenants. a. Create time source for Tenant 1: neutron ntp-source-create --name Tenant1_TimeSource --mode unicast --ip 192.168.4.1 b. Create time source for Tenant 2 1. Primary source having simpleauth. neutron ntp-source-create --name Tenant2_Primary_TimeSource --mode unicast --ip 192.168.4.2 --auth simpleauth 2. Secondary source (NTPv3) having autokeyauth. neutron ntp-source-create --name Tenant2_Secondary_TimeSource --version 3 --mode multicast --ip 224.0.0.45 --role secondary --auth autokeyauth 4. After the configuration is done, NTP agents per will be deployed for the specified tenant and the created agent will act as the time server for the specified tenant. REST API Impact =============== The example below uses ReST API to create two NTP time synchronization source (primary and secondary) for a tenant (Tenant2) having simpleauth authencation for primary source and autokey auth for the secondary one. First step is to create NTP authentication details followed by NTP time source creation. Note: NTP authentication is an optional parameter and should only be created if the time source needs to be authencation for security puposes. 1. ReST API example for creating NTP authentication is shown below. POST /v2.0/timesyncaas/ntp-authentication Accept: application/json { ""ntp_authentication"": [ { ""auth_name"" : ""Tenant1_simpleauth"", ""auth_type"" : ""simple"", // Other option: ""autokey"" ""username"" : ""openstack"", ""password"" : ""openstack"",}, { ""auth_name"" : ""Tenant1_autokeyauth"", ""auth_type"" : ""autokey"" // Other option: ""simple"" }, ] } Response :: { ""ntp_authentication"": [ { ""auth_name"" : ""Tenant1_simpleauth"", ""auth_type"" : ""simple"", // Other option: ""autokey"" ""username"" : ""openstack"", ""password"" : ""openstack"", ""id"":""<UUID value>""}, { ""auth_name"" : ""Tenant1_autokeyauth"", ""auth_type"" : ""autokey"" // Other option: ""simple"" }, ""id"":""<UUID value>""} ] } 2. ReST API example for creating NTP time source is shown below. POST /v2.0/timesyncaas/ntp-timesource Accept: application/json { ""ntp_timesource"": [ { ""name"" : ""Tenant2_Primary_TimeSource"", ""version"" : ""4"", // Other option: ""3"" ""mode"" : ""unicast"", // Other option: ""multicast"" ""ip_address"" : ""192.168.4.1"", ""auth"" : ""simpleauth""}, { ""name"" : ""Tenant2_Secondary_TimeSource"", ""version"" : ""3"", // Other option: ""4"" ""mode"" : ""multicast"", // Other option: ""unicast"" ""ip_address"" : ""224.0.0.45"", ""role"" : ""secondary"", ""auth"" : ""autokeyauth""} ] } Response :: { ""ntp_timesource"": [ { ""name"" : ""Tenant2_Primary_TimeSource"", ""version"" : ""4"", // Other option: ""3"" ""mode"" : ""unicast"", // Other option: ""multicast"" ""ip_address"" : ""192.168.4.1"", ""auth"" : ""simpleauth"", ""id"":""<UUID value>""}, { ""name"" : ""Tenant2_Secondary_TimeSource"", ""version"" : ""3"", // Other option: ""4"" ""mode"" : ""multicast"", // Other option: ""unicast"" ""ip_address"" : ""224.0.0.45"", ""role"" : ""secondary"", ""auth"" : ""autokeyauth"", ""id"":""<UUID value>""} ] } Security impact =============== CRUD API is provided using existing API model, no new surface is exposed. Time synchronization source configuration is provided by underlying advance service plugin framework, so no new surface is exposed. Notifications impact ==================== No notification impact is expected. Other end user impact ==================== No impact is expected. Performance Impact ================== No significant performance impact is expected. Other deployer Impact ===================== No other deployment impacts are expected Developer Impact ================ No developer impact is expected. Implementation ============== Following people are working on several different aspects of the proposed idea: Primary assignee: Vikram Choudhary<vikschw> Other contributors: Dongfeng Dhruv Dhody Work Items ========== 1. Build API 2. Update Datamodel 3. Build unit-tests 4. Update documentation Dependencies ============ None Testing ======= Unit Tests will be provided. Documentation Impact ==================== Documentation will need to be updated for: 1. TimeSyncaaS model and usage References ========== .. [1] Openstack Network Time Protocol (NTP) configuration guide http://docs.openstack.org/havana/install-guide/install/yum/content/basics-ntp.html .. [2] Network Time Protocol (NTP): http://en.wikipedia.org/wiki/Network_Time_Protocol ",,379,0
openstack%2Fpython-barbicanclient~master~I2bd8bf64792dd91d7b79709398840c0c2d07a69d,openstack/python-barbicanclient,master,I2bd8bf64792dd91d7b79709398840c0c2d07a69d,Add capability of specifying Barbican version to client,MERGED,2015-05-20 00:52:27.000000000,2015-05-21 21:20:50.000000000,2015-05-21 21:20:48.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11561}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-05-20 00:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/6a7eef591e7b8e13857e06b518086be392e7efe0', 'message': 'Add capability of specifying Barbican version to client\n\nWhile specifying the version of the Barbican API was possible before,\nthis was being ignored on the client and the default version was always\nhardcoded. This CR now takes that into account and will append the\nversion to the base endpoint.\n\nChange-Id: I2bd8bf64792dd91d7b79709398840c0c2d07a69d\n'}, {'number': 2, 'created': '2015-05-20 01:02:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/18997489262a74414d1306a0f06a478881fafb53', 'message': 'Add capability of specifying Barbican version to client\n\nWhile specifying the version of the Barbican API was possible before,\nthis was being ignored on the client and the default version was always\nhardcoded. This CR now takes that into account and will append the\nversion to the base endpoint.\n\nChange-Id: I2bd8bf64792dd91d7b79709398840c0c2d07a69d\n'}, {'number': 3, 'created': '2015-05-20 16:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/ecc4466b6d09a73e7e0a77d743ea0976a84b93ae', 'message': 'Add capability of specifying Barbican version to client\n\nWhile specifying the version of the Barbican API was possible before,\nthis was being ignored on the client and the default version was always\nhardcoded. This CR now takes that into account and will append the\nversion to the base endpoint.\n\nChange-Id: I2bd8bf64792dd91d7b79709398840c0c2d07a69d\n'}, {'number': 4, 'created': '2015-05-20 16:45:20.000000000', 'files': ['barbicanclient/client.py', 'functionaltests/client/test_client_connectivity.py'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/240c5812678400ab4b823b1e2f8bff7a8a55cb48', 'message': 'Add capability of specifying Barbican version to client\n\nWhile specifying the version of the Barbican API was possible before,\nthis was being ignored on the client and the default version was always\nhardcoded. This CR now takes that into account and will append the\nversion to the base endpoint.\n\nChange-Id: I2bd8bf64792dd91d7b79709398840c0c2d07a69d\n'}]",3,184362,240c5812678400ab4b823b1e2f8bff7a8a55cb48,17,13,4,10873,,,0,"Add capability of specifying Barbican version to client

While specifying the version of the Barbican API was possible before,
this was being ignored on the client and the default version was always
hardcoded. This CR now takes that into account and will append the
version to the base endpoint.

Change-Id: I2bd8bf64792dd91d7b79709398840c0c2d07a69d
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/62/184362/3 && git format-patch -1 --stdout FETCH_HEAD,"['barbicanclient/client.py', 'functionaltests/client/test_client_connectivity.py']",2,6a7eef591e7b8e13857e06b518086be392e7efe0,remove_base_url,"from barbicanclient import exceptions def assert_client_cannot_contact_barbican(self, client): self.assertRaises(exceptions.HTTPClientError, client.containers.list) self.assertRaises(exceptions.HTTPClientError, client.orders.list) self.assertRaises(exceptions.HTTPClientError, client.secrets.list) def test_client_cannot_access_server_if_unexistant_version_specified(self): barbicanclient = client.Client( endpoint=CONF.keymanager.url, project_id=CONF.keymanager.project_id, auth=self.auth, version='unexistant_version') self.assert_client_cannot_contact_barbican(barbicanclient)",,20,2
openstack%2Fswift~feature%2Fhummingbird~I769b8ef81dae0d9cb7c9da3753b98b8e00d0293f,openstack/swift,feature/hummingbird,I769b8ef81dae0d9cb7c9da3753b98b8e00d0293f,go: lower-case incoming ETag,MERGED,2015-05-14 22:39:07.000000000,2015-05-21 21:19:54.000000000,2015-05-21 21:19:52.000000000,"[{'_account_id': 3}, {'_account_id': 1009}, {'_account_id': 1179}, {'_account_id': 2828}, {'_account_id': 16218}]","[{'number': 1, 'created': '2015-05-14 22:39:07.000000000', 'files': ['go/objectserver/main.go', 'go/objectserver/main_test.go'], 'web_link': 'https://opendev.org/openstack/swift/commit/68a5354f5bf7691219e97ea63cef7e977e11c9fa', 'message': 'go: lower-case incoming ETag\n\nLower-case request ETag on PUT, so comparisons work correctly.\n\nChange-Id: I769b8ef81dae0d9cb7c9da3753b98b8e00d0293f\n'}]",2,183340,68a5354f5bf7691219e97ea63cef7e977e11c9fa,10,5,1,2828,,,0,"go: lower-case incoming ETag

Lower-case request ETag on PUT, so comparisons work correctly.

Change-Id: I769b8ef81dae0d9cb7c9da3753b98b8e00d0293f
",git fetch https://review.opendev.org/openstack/swift refs/changes/40/183340/1 && git format-patch -1 --stdout FETCH_HEAD,"['go/objectserver/main.go', 'go/objectserver/main_test.go']",2,68a5354f5bf7691219e97ea63cef7e977e11c9fa,loweretag," func TestBadEtag(t *testing.T) { ts, err := makeObjectServer() assert.Nil(t, err) defer ts.Close() req, err := http.NewRequest(""PUT"", fmt.Sprintf(""http://%s:%d/sda/0/a/c/o"", ts.host, ts.port), bytes.NewBuffer([]byte(""ABCDEFGHIJKLMNOPQRSTUVWXYZ""))) assert.Nil(t, err) req.Header.Set(""Content-Type"", ""application/octet-stream"") req.Header.Set(""Content-Length"", ""26"") req.Header.Set(""ETag"", ""11111111111111111111111111111111"") req.Header.Set(""X-Timestamp"", hummingbird.GetTimestamp()) resp, err := http.DefaultClient.Do(req) assert.Nil(t, err) assert.Equal(t, 422, resp.StatusCode) } func TestCorrectEtag(t *testing.T) { ts, err := makeObjectServer() assert.Nil(t, err) defer ts.Close() req, err := http.NewRequest(""PUT"", fmt.Sprintf(""http://%s:%d/sda/0/a/c/o"", ts.host, ts.port), bytes.NewBuffer([]byte(""ABCDEFGHIJKLMNOPQRSTUVWXYZ""))) assert.Nil(t, err) req.Header.Set(""Content-Type"", ""application/octet-stream"") req.Header.Set(""Content-Length"", ""26"") req.Header.Set(""ETag"", ""437bba8e0bf58337674f4539e75186ac"") req.Header.Set(""X-Timestamp"", hummingbird.GetTimestamp()) resp, err := http.DefaultClient.Do(req) assert.Nil(t, err) assert.Equal(t, 201, resp.StatusCode) } func TestUppercaseEtag(t *testing.T) { ts, err := makeObjectServer() assert.Nil(t, err) defer ts.Close() req, err := http.NewRequest(""PUT"", fmt.Sprintf(""http://%s:%d/sda/0/a/c/o"", ts.host, ts.port), bytes.NewBuffer([]byte(""ABCDEFGHIJKLMNOPQRSTUVWXYZ""))) assert.Nil(t, err) req.Header.Set(""Content-Type"", ""application/octet-stream"") req.Header.Set(""Content-Length"", ""26"") req.Header.Set(""ETag"", ""437BBA8E0BF58337674F4539E75186AC"") req.Header.Set(""X-Timestamp"", hummingbird.GetTimestamp()) resp, err := http.DefaultClient.Do(req) assert.Nil(t, err) assert.Equal(t, 201, resp.StatusCode) }",,52,1
openstack%2Fpython-barbicanclient~master~Id589c76fb5fe481a3dd48ee1baa26f7d19d2d1a1,openstack/python-barbicanclient,master,Id589c76fb5fe481a3dd48ee1baa26f7d19d2d1a1,Remove instances of _base_url,MERGED,2015-05-19 18:48:39.000000000,2015-05-21 21:16:43.000000000,2015-05-21 21:16:41.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11561}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-05-19 18:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/77da2d5948a63625d7efd9b006e7fe91f100d3d9', 'message': ""Remove instances of _base_url\n\nThe variable _base_url was not really necessary since we are setting up\nthe endpoint_override variable which will eventually be used when making\na request through the keystoneclient's session.\n\nThis is a step in getting the client to use the keystoneclient's\nAPI more wisely. A subsequent CR will remove the need for the\nendpoint_override and make use of keystoneclient's endpoint_filters to\ndiscover the Barbican endpoint.\n\nChange-Id: Id589c76fb5fe481a3dd48ee1baa26f7d19d2d1a1\n""}, {'number': 2, 'created': '2015-05-19 20:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/ca56493a82c7686e8b7e0f436f02c8ec339f2ade', 'message': ""Remove instances of _base_url\n\nThe variable _base_url was not really necessary since we are setting up\nthe endpoint_override variable which will eventually be used when making\na request through the keystoneclient's session.\n\nThis is a step in getting the client to use the keystoneclient's\nAPI more wisely. A subsequent CR will remove the need for the\nendpoint_override and make use of keystoneclient's endpoint_filters to\ndiscover the Barbican endpoint.\n\nChange-Id: Id589c76fb5fe481a3dd48ee1baa26f7d19d2d1a1\n""}, {'number': 3, 'created': '2015-05-19 20:43:22.000000000', 'files': ['barbicanclient/base.py', 'barbicanclient/client.py', 'barbicanclient/containers.py', 'functionaltests/client/v1/functional/test_containers.py', 'barbicanclient/tests/test_client.py', 'functionaltests/client/v1/behaviors/base_behaviors.py'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/4c4b8e8025cd4012d5bf7879061b63d9e13e2f4f', 'message': ""Remove instances of _base_url\n\nThe variable _base_url was not really necessary since we are setting up\nthe endpoint_override variable which will eventually be used when making\na request through the keystoneclient's session.\n\nThis is a step in getting the client to use the keystoneclient's\nAPI more wisely. A subsequent CR will remove the need for the\nendpoint_override and make use of keystoneclient's endpoint_filters to\ndiscover the Barbican endpoint.\n\nChange-Id: Id589c76fb5fe481a3dd48ee1baa26f7d19d2d1a1\n""}]",0,184309,4c4b8e8025cd4012d5bf7879061b63d9e13e2f4f,13,15,3,10873,,,0,"Remove instances of _base_url

The variable _base_url was not really necessary since we are setting up
the endpoint_override variable which will eventually be used when making
a request through the keystoneclient's session.

This is a step in getting the client to use the keystoneclient's
API more wisely. A subsequent CR will remove the need for the
endpoint_override and make use of keystoneclient's endpoint_filters to
discover the Barbican endpoint.

Change-Id: Id589c76fb5fe481a3dd48ee1baa26f7d19d2d1a1
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/09/184309/3 && git format-patch -1 --stdout FETCH_HEAD,"['barbicanclient/base.py', 'barbicanclient/client.py', 'barbicanclient/containers.py', 'barbicanclient/tests/test_client.py']",4,77da2d5948a63625d7efd9b006e7fe91f100d3d9,remove_base_url," self.assertEqual(c.endpoint_override, 'http://localhost:9311/v1') def test_endpoint_override_starts_with_endpoint_url(self): self.assertTrue(c.endpoint_override.startswith(self.endpoint)) def test_endpoint_override_ends_with_default_api_version(self): self.assertTrue( c.endpoint_override.endswith(client._DEFAULT_API_VERSION))"," self.assertEqual(c._base_url, 'http://localhost:9311/v1') def test_base_url_starts_with_endpoint_url(self): self.assertTrue(c._base_url.startswith(self.endpoint)) def test_base_url_ends_with_default_api_version(self): self.assertTrue(c._base_url.endswith(client._DEFAULT_API_VERSION))",10,14
openstack%2Fopenstacksdk~master~Ib571f5fab8bfb3ea4674b8524a490b98b8d55c2c,openstack/openstacksdk,master,Ib571f5fab8bfb3ea4674b8524a490b98b8d55c2c,Add id_attribute to base proxy calls,MERGED,2015-05-21 15:46:18.000000000,2015-05-21 21:08:57.000000000,2015-05-21 21:08:55.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-21 15:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9c8f24f4f482781511a5c44ce410ac3d963e9f71', 'message': 'Add id_attribute to base proxy calls\n\nIf the id attribute was not id, the base proxy was broken.\n\nChange-Id: Ib571f5fab8bfb3ea4674b8524a490b98b8d55c2c\nCloses-Bug: #1457513\n'}, {'number': 2, 'created': '2015-05-21 16:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/59c8b696200ec9567988695b48a6cb13cdf97d1e', 'message': 'Add id_attribute to base proxy calls\n\nIf the id attribute was not id, the base proxy was broken.\n\nChange-Id: Ib571f5fab8bfb3ea4674b8524a490b98b8d55c2c\nCloses-Bug: #1457513\n'}, {'number': 3, 'created': '2015-05-21 21:02:49.000000000', 'files': ['openstack/tests/functional/compute/v2/test_keypair.py', 'openstack/proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/25049be285447fa9e174d541f25ea72aa66f0cfc', 'message': 'Add id_attribute to base proxy calls\n\nIf the id attribute was not id, the base proxy was broken.\n\nChange-Id: Ib571f5fab8bfb3ea4674b8524a490b98b8d55c2c\nCloses-Bug: #1457513\n'}]",0,184806,25049be285447fa9e174d541f25ea72aa66f0cfc,11,3,3,8736,,,0,"Add id_attribute to base proxy calls

If the id attribute was not id, the base proxy was broken.

Change-Id: Ib571f5fab8bfb3ea4674b8524a490b98b8d55c2c
Closes-Bug: #1457513
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/06/184806/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/functional/compute/v2/test_keypair.py', 'openstack/proxy.py']",2,9c8f24f4f482781511a5c44ce410ac3d963e9f71,bug/1457513, args = {resource_type.id_attribute: resource.Resource.get_id(value)} res = resource_type.existing(**args) args = {resource_type.id_attribute: resource.Resource.get_id(value)} res = resource_type.existing(**args) args = {resource_type.id_attribute: resource.Resource.get_id(value)} res = resource_type.existing(**args) args = { resource_type.id_attribute: resource.Resource.get_id(value)} res = resource_type.existing(**args), res = resource_type.existing(id=resource.Resource.get_id(value)) res = resource_type.existing(id=resource.Resource.get_id(value)) res = resource_type.existing(id=resource.Resource.get_id(value)) res = resource_type.existing(id=resource.Resource.get_id(value)),14,9
openstack%2Fnetworking-ovn~master~I2ea44c83ddbdd27413391f9d383d62d7f70eeb0b,openstack/networking-ovn,master,I2ea44c83ddbdd27413391f9d383d62d7f70eeb0b,Additions to TODO,ABANDONED,2015-05-21 13:15:59.000000000,2015-05-21 21:02:04.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 5756}, {'_account_id': 8788}, {'_account_id': 11343}, {'_account_id': 11604}, {'_account_id': 13070}]","[{'number': 1, 'created': '2015-05-21 13:15:59.000000000', 'files': ['TODO.rst'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0155ce59af1eb2509a2cff51cd6553da245eb2bc', 'message': 'Additions to TODO\n\n1) QoS Integrations\n2) Support DPDK-OVS with OVN\n\nChange-Id: I2ea44c83ddbdd27413391f9d383d62d7f70eeb0b\n'}]",0,184779,0155ce59af1eb2509a2cff51cd6553da245eb2bc,6,10,1,11343,,,0,"Additions to TODO

1) QoS Integrations
2) Support DPDK-OVS with OVN

Change-Id: I2ea44c83ddbdd27413391f9d383d62d7f70eeb0b
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/79/184779/1 && git format-patch -1 --stdout FETCH_HEAD,['TODO.rst'],1,0155ce59af1eb2509a2cff51cd6553da245eb2bc,todo_fix, * Correlate API efforts with L2 Gateway project Integrations ---------------------- * QoS * DPDK OVS * Binding ports by both ML2 mechanism drivers for running OVN with DPDK OVS * Detect and handle needed gaps (OVS-DPDK L2 agent?),,12,0
openstack%2Fopenstacksdk~master~I422d5af228e77f94330e9ad1f5151277c149b48d,openstack/openstacksdk,master,I422d5af228e77f94330e9ad1f5151277c149b48d,Add keypair functional tests,MERGED,2015-05-21 14:37:46.000000000,2015-05-21 21:01:29.000000000,2015-05-21 21:01:28.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-21 14:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9d6b00682d310b3cf02a43c04db39f273a576e69', 'message': 'Add keypair functional tests\n\nChange-Id: I422d5af228e77f94330e9ad1f5151277c149b48d\n'}, {'number': 2, 'created': '2015-05-21 16:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4188358e86e1d1a6d55a68d8ed9b298d6364770b', 'message': 'Add keypair functional tests\n\nChange-Id: I422d5af228e77f94330e9ad1f5151277c149b48d\n'}, {'number': 3, 'created': '2015-05-21 16:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/206804fd45d1a7b8a5a9708837bfc44366e639bc', 'message': 'Add keypair functional tests\n\nChange-Id: I422d5af228e77f94330e9ad1f5151277c149b48d\n'}, {'number': 4, 'created': '2015-05-21 16:27:08.000000000', 'files': ['openstack/tests/functional/compute/v2/test_keypair.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3207d1f741149deb5d9b6b1f4c8ad271c570aca0', 'message': 'Add keypair functional tests\n\nChange-Id: I422d5af228e77f94330e9ad1f5151277c149b48d\n'}]",2,184797,3207d1f741149deb5d9b6b1f4c8ad271c570aca0,13,3,4,8736,,,0,"Add keypair functional tests

Change-Id: I422d5af228e77f94330e9ad1f5151277c149b48d
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/97/184797/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/compute/v2/test_keypair.py'],1,9d6b00682d310b3cf02a43c04db39f273a576e69,aftkeypair,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from openstack.compute.v2 import keypair from openstack.tests.functional import base class TestKeypair(base.BaseFunctionalTest): NAME = uuid.uuid4().hex ID = None @classmethod def setUpClass(cls): super(TestKeypair, cls).setUpClass() sot = cls.conn.compute.create_keypair(name=cls.NAME) assert isinstance(sot, keypair.Keypair) cls.assertIs(cls.NAME, sot.name) cls.ID = sot.id @classmethod def tearDownClass(cls): pass sot = cls.conn.compute.delete_keypair(cls.ID) cls.assertIs(None, sot) def test_find(self): sot = self.conn.compute.find_keypair(self.NAME) self.assertEqual(self.ID, sot.id) # def test_get(self): # sot = self.conn.compute.get_keypair(self.NAME) # self.assertEqual(self.NAME, sot.name) # self.assertEqual(self.ID, sot.id) # def test_list(self): names = [o.name for o in self.conn.compute.keypairs()] self.assertIn(self.NAME, names) ",,49,0
openstack%2Fopenstacksdk~master~I3cace40bfa1a4d6aed39dd922060bc149227e8f7,openstack/openstacksdk,master,I3cace40bfa1a4d6aed39dd922060bc149227e8f7,Fix underline for docs,MERGED,2015-05-21 16:38:12.000000000,2015-05-21 21:00:17.000000000,2015-05-21 21:00:17.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-21 16:38:12.000000000', 'files': ['doc/source/users/userguides/network.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2a01a7d0bda4699d290a88cc4ad98ffd36938154', 'message': 'Fix underline for docs\n\nChange-Id: I3cace40bfa1a4d6aed39dd922060bc149227e8f7\n'}]",0,184818,2a01a7d0bda4699d290a88cc4ad98ffd36938154,6,2,1,8736,,,0,"Fix underline for docs

Change-Id: I3cace40bfa1a4d6aed39dd922060bc149227e8f7
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/18/184818/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/users/userguides/network.rst'],1,2a01a7d0bda4699d290a88cc4ad98ffd36938154,underline,=======================,===================,1,1
openstack%2Fopenstacksdk~master~I5df545b09020034488f348326fcdbc6587a5fa6b,openstack/openstacksdk,master,I5df545b09020034488f348326fcdbc6587a5fa6b,Remove pass from delete functional tests,MERGED,2015-05-21 16:41:09.000000000,2015-05-21 21:00:11.000000000,2015-05-21 21:00:11.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-21 16:41:09.000000000', 'files': ['openstack/tests/functional/network/v2/test_network.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3f8aa7d534c398a239ca723f82e9015f36219a0d', 'message': 'Remove pass from delete functional tests\n\nChange-Id: I5df545b09020034488f348326fcdbc6587a5fa6b\n'}]",0,184821,3f8aa7d534c398a239ca723f82e9015f36219a0d,6,2,1,8736,,,0,"Remove pass from delete functional tests

Change-Id: I5df545b09020034488f348326fcdbc6587a5fa6b
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/21/184821/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_network.py'],1,3f8aa7d534c398a239ca723f82e9015f36219a0d,pass,, pass,0,1
openstack%2Ffuel-library~master~Ib2fa6ff4c9c685004fb87add89c199b192cee5c7,openstack/fuel-library,master,Ib2fa6ff4c9c685004fb87add89c199b192cee5c7,Fix eth0 hardcode for Nailgun iptables,MERGED,2015-05-21 16:33:13.000000000,2015-05-21 20:52:34.000000000,2015-05-21 20:51:54.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13344}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-21 16:33:13.000000000', 'files': ['deployment/puppet/nailgun/examples/host-only.pp', 'deployment/puppet/nailgun/manifests/host.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b6e2b88bc73c01c0cffb536b29b2ce5c90a854b9', 'message': 'Fix eth0 hardcode for Nailgun iptables\n\nPass actual admin interface into nailgun::iptables class.\n\nChange-Id: Ib2fa6ff4c9c685004fb87add89c199b192cee5c7\nCloses-bug: #1457559\n'}]",0,184817,b6e2b88bc73c01c0cffb536b29b2ce5c90a854b9,27,9,1,9387,,,0,"Fix eth0 hardcode for Nailgun iptables

Pass actual admin interface into nailgun::iptables class.

Change-Id: Ib2fa6ff4c9c685004fb87add89c199b192cee5c7
Closes-bug: #1457559
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/17/184817/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/nailgun/examples/host-only.pp', 'deployment/puppet/nailgun/manifests/host.pp']",2,b6e2b88bc73c01c0cffb536b29b2ce5c90a854b9,bug/1457559,"$admin_iface = 'eth0', class { 'nailgun::iptables': admin_iface => $admin_iface, }", class { 'nailgun::iptables': },5,1
openstack%2Fnova~master~I7da701f37d162f97b924cb8eede76de4f1c8bf7a,openstack/nova,master,I7da701f37d162f97b924cb8eede76de4f1c8bf7a,Code clean up db.instance_get_all_by_host(),MERGED,2015-03-13 10:37:32.000000000,2015-05-21 20:42:18.000000000,2015-05-21 20:42:15.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6450}, {'_account_id': 6802}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10224}, {'_account_id': 10385}, {'_account_id': 10618}, {'_account_id': 11103}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15888}]","[{'number': 1, 'created': '2015-03-13 10:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d55fb89d4c9d043c5776498d202e3c9cfa7af0a', 'message': 'Code clean up db.instance_get_all_by_host()\n\nReplaces db.instance_get_all_by_host()\nwith objects.InstanceList.get_by_host()\nalso, fixed several unit test cases fail by using\nmock to replace stub.\n\nCloses-Bug: #1390483\n\nChange-Id: I7da701f37d162f97b924cb8eede76de4f1c8bf7a\n'}, {'number': 2, 'created': '2015-03-13 11:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/abc6076115b6e67ff47ba4c7547c33b64e94bf1c', 'message': 'Code clean up db.instance_get_all_by_host()\n\nReplaces db.instance_get_all_by_host()\nwith objects.InstanceList.get_by_host()\nalso, fixed several unit test cases fail by using\nmock to replace stub.\n\nCloses-Bug: #1390483\n\nChange-Id: I7da701f37d162f97b924cb8eede76de4f1c8bf7a\n'}, {'number': 3, 'created': '2015-04-29 21:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33ba3628d665bee6463c6c365e1278c301f38778', 'message': 'Code clean up db.instance_get_all_by_host()\n\nReplaces db.instance_get_all_by_host()\nwith objects.InstanceList.get_by_host()\nalso, fixed several unit test cases fail by using\nmock to replace stub.\n\nCloses-Bug: #1390483\n\nChange-Id: I7da701f37d162f97b924cb8eede76de4f1c8bf7a\n'}, {'number': 4, 'created': '2015-04-29 21:17:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dc0d75aa31761bafaff4ecf2dd5f9e3dcb016a66', 'message': 'Code clean up db.instance_get_all_by_host()\n\nReplaces db.instance_get_all_by_host()\nwith objects.InstanceList.get_by_host()\nalso, fixed several unit test cases fail by using\nmock to replace stub.\n\nCloses-Bug: #1390483\n\nChange-Id: I7da701f37d162f97b924cb8eede76de4f1c8bf7a\n'}, {'number': 5, 'created': '2015-05-12 08:16:43.000000000', 'files': ['nova/tests/unit/compute/test_host_api.py', 'nova/tests/unit/api/openstack/compute/contrib/test_hypervisors.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5660899fc11055566f2dd495d35c016b4410ea10', 'message': 'Code clean up db.instance_get_all_by_host()\n\nReplaces db.instance_get_all_by_host()\nwith objects.InstanceList.get_by_host()\nalso, fixed several unit test cases fail by using\nmock to replace stub.\n\nCloses-Bug: #1390483\n\nChange-Id: I7da701f37d162f97b924cb8eede76de4f1c8bf7a\n'}]",11,164132,5660899fc11055566f2dd495d35c016b4410ea10,69,20,5,6062,,,0,"Code clean up db.instance_get_all_by_host()

Replaces db.instance_get_all_by_host()
with objects.InstanceList.get_by_host()
also, fixed several unit test cases fail by using
mock to replace stub.

Closes-Bug: #1390483

Change-Id: I7da701f37d162f97b924cb8eede76de4f1c8bf7a
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/164132/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/contrib/test_hypervisors.py', 'nova/tests/unit/compute/test_host_api.py', 'nova/compute/api.py']",3,2d55fb89d4c9d043c5776498d202e3c9cfa7af0a,bug/1390483," #return self.db.instance_get_all_by_host(context, host_name) return objects.InstanceList.get_by_host(context, host_name)"," return self.db.instance_get_all_by_host(context, host_name)",14,23
openstack%2Fdiskimage-builder~master~I378a74255010eca192f5766b653f8a42404be5ea,openstack/diskimage-builder,master,I378a74255010eca192f5766b653f8a42404be5ea,Initial element tests,MERGED,2015-04-17 02:38:24.000000000,2015-05-21 20:36:34.000000000,2015-05-21 20:19:19.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 9369}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-04-17 02:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9e3079a0865e3520c1de5bdb68c3f3dbdda37b8a', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 2, 'created': '2015-04-17 03:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/54f94aa87585fd97460bf31b3e0634a0982b0690', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 3, 'created': '2015-04-17 03:56:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/65a1ef59a71b7160842cededf7539c01a14b956c', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 4, 'created': '2015-04-17 15:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ce36f0b910e6399f61caa5e1421f33e344f84c77', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 5, 'created': '2015-04-17 16:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/fd92ac5337c25217fbb09bffcdf7b569a448028e', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 6, 'created': '2015-04-22 19:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/a9814a7a2d7a14867080c7469c937e6f2a7145d9', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 7, 'created': '2015-04-22 21:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/07f3c9a8ed3c3ce4df857bd3e622b32c4073b68d', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 8, 'created': '2015-04-24 16:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/2cf21e8f7299daa536e4b3410b653c9c3a8e99ed', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 9, 'created': '2015-04-24 21:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9560b1bb353883f34cef3103e13ddc4d5465b152', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 10, 'created': '2015-04-27 15:25:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/106d2a6465e7272fcf36384505f900648b39ebfc', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 11, 'created': '2015-04-27 19:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/721d3c9ee01736663577cbe49f048a36821ff2d6', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 12, 'created': '2015-04-27 22:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/85c5f1331b7881a2637decae94c41bf28699165a', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 13, 'created': '2015-04-27 22:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/90aeddf98636423a590a4c3cfab3c2c6aa019989', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 14, 'created': '2015-04-27 22:40:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/14c9f4c14a43daa4897e74a5c02e769e82f28c5e', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 15, 'created': '2015-04-27 22:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/211c8dc7b157933a3194755766f18cc47f76eeda', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 16, 'created': '2015-04-27 23:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/536b2b3a38bbe0530484f28c6d802af65e7324bd', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 17, 'created': '2015-04-27 23:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c718b301a8ed6123edfa974f9e42bf09e544d051', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 18, 'created': '2015-04-27 23:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ebda108bc638575c74b8a70fe325351487b4bc19', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 19, 'created': '2015-04-27 23:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7f4167c1b10d0e5f73ebd7be5c052e8eccb934b1', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 20, 'created': '2015-04-27 23:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/5179a1f365779dba824527dc040b796454de6a28', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 21, 'created': '2015-04-28 00:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4b7615b657d4d10a7a191b52e552d87478ea5b77', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 22, 'created': '2015-04-30 19:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f8e1d8cf1e28c3bec8c2cb43f7fa3d31fbf0a9b7', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 23, 'created': '2015-05-01 22:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/6c7d8ca0df55e9cee414cb3fdc133b388ebdcad9', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 24, 'created': '2015-05-07 22:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f2dfc4992a704a8d722a5a337ab169c423dc2f2e', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}, {'number': 25, 'created': '2015-05-17 02:08:34.000000000', 'files': ['tests/test_functions.bash', 'elements/apt-sources/test-elements/test-sources/environment.d/00-set-apt-sources', 'doc/source/developer/developing_elements.rst', 'tests/test_elements.bash', 'elements/apt-sources/test-elements/test-sources/extra-data.d/00-write-apt-sources', 'lib/img-functions', 'tests/run_functests.sh', 'elements/apt-sources/test-elements/test-sources/element-deps', 'doc/source/conf.py', 'elements/apt-sources/test-elements/test-sources/pre-install.d/00-test-apt-sources'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b9b6640fa725de859f47618cfe4c56cee1acec88', 'message': 'Initial element tests\n\nAdding a test function which allows us to use elements to perform\nelement-specific tests. In order for this to work sanely, also adding\nsome configuration to our break system so we can assert on negative\ntests.\n\nAlso adding a test for apt-sources to verify this code actually works.\n\nChange-Id: I378a74255010eca192f5766b653f8a42404be5ea\n'}]",6,174681,b9b6640fa725de859f47618cfe4c56cee1acec88,84,4,25,10035,,,0,"Initial element tests

Adding a test function which allows us to use elements to perform
element-specific tests. In order for this to work sanely, also adding
some configuration to our break system so we can assert on negative
tests.

Also adding a test for apt-sources to verify this code actually works.

Change-Id: I378a74255010eca192f5766b653f8a42404be5ea
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/81/174681/25 && git format-patch -1 --stdout FETCH_HEAD,"['elements/apt-sources/test-elements/test-sources/environment.d/00-set-apt-sources', 'tests/test_functions.bash', 'tests/test_elements.bash', 'elements/apt-sources/test-elements/test-sources/extra-data.d/00-write-apt-sources', 'lib/img-functions', 'tests/run_functests.sh', 'elements/apt-sources/test-elements/test-sources/element-deps', 'elements/apt-sources/test-elements/test-sources/pre-install.d/00-test-apt-sources']",8,9e3079a0865e3520c1de5bdb68c3f3dbdda37b8a,feature/support-aci-building,"#!/bin/bash set -eux set -o pipefail echo ""Verifying apt sources.list content"" [ -f /etc/apt/sources.list ] [ ""$(cat /etc/apt/sources.list)"" = ""testdata"" ] touch /tmp/dib-test-succeeded exit 1 ",,65,1
openstack%2Fdiskimage-builder~master~I9fa330fd82e5289b549713f6b31345f6113cef1d,openstack/diskimage-builder,master,I9fa330fd82e5289b549713f6b31345f6113cef1d,Install debian locales,MERGED,2015-05-17 01:59:45.000000000,2015-05-21 20:19:26.000000000,2015-05-21 20:19:26.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 9369}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-05-17 01:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/77f8bdbff6825c792cc5cc71a84f5a89c862965b', 'message': 'Install debian locales\n\nBuilding debian images failes due to missing the locale were trying to\nset.\n\nChange-Id: I9fa330fd82e5289b549713f6b31345f6113cef1d\n'}, {'number': 2, 'created': '2015-05-17 02:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/91bb5c018c7f9bb748e8c7f7333ad71afc1bf28c', 'message': 'Install debian locales\n\nBuilding debian images failes due to missing the locale were trying to\nset.\n\nChange-Id: I9fa330fd82e5289b549713f6b31345f6113cef1d\n'}, {'number': 3, 'created': '2015-05-19 19:23:44.000000000', 'files': ['elements/debian-minimal/element-deps', 'elements/debian/package-installs.yaml'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/917962d26cb18143ae2b84209bbf1e05de228a10', 'message': 'Install debian locales\n\nBuilding debian images failes due to missing the locale were trying to\nset.\n\nChange-Id: I9fa330fd82e5289b549713f6b31345f6113cef1d\n'}]",0,183891,917962d26cb18143ae2b84209bbf1e05de228a10,16,4,3,10035,,,0,"Install debian locales

Building debian images failes due to missing the locale were trying to
set.

Change-Id: I9fa330fd82e5289b549713f6b31345f6113cef1d
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/91/183891/3 && git format-patch -1 --stdout FETCH_HEAD,['elements/debootstrap/package-installs.yaml'],1,77f8bdbff6825c792cc5cc71a84f5a89c862965b,fix/debian-missing-locales,locales-all:,,1,0
openstack%2Ftempest~master~I5884149fef95c50d62ffde6e5c9488da1a9d6a55,openstack/tempest,master,I5884149fef95c50d62ffde6e5c9488da1a9d6a55,Fixing broken Heat tests for Swift resources,MERGED,2015-05-16 14:28:22.000000000,2015-05-21 20:19:17.000000000,2015-05-21 20:19:14.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7428}, {'_account_id': 8871}]","[{'number': 1, 'created': '2015-05-16 14:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d108d0155c2f8e69ee0f2e02fb4409540ec884c0', 'message': ""Fixing broken Heat tests for Swift resources\n\nI have encountered it recently. I just ran Heat tests for Swift\nresources and saw that these tests are broken. It looks like no dsvm\ncheck job runs these tests and that is why we didn't encounter this\nissue earlier. I have found the commit that breaks these tests.\nhttps://review.openstack.org/#/c/153681/\n\nIn order to fix the tests we should add the following deleted code lines\nto the file tempest/api/orchestration/stacks/test_swift_resources.py:\n\n    @classmethod\n    def setup_credentials(cls):\n        super(SwiftResourcesTestJSON, cls).setup_credentials()\n        cls.os = clients.Manager()\n\nAfter adding these code lines we have working tests again.\n\nChange-Id: I5884149fef95c50d62ffde6e5c9488da1a9d6a55\nCloses-Bug: #1455775\n""}, {'number': 2, 'created': '2015-05-20 16:11:10.000000000', 'files': ['tempest/api/orchestration/stacks/test_swift_resources.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1876b5dc062fb01e1bab174728439947f107ff9a', 'message': ""Fixing broken Heat tests for Swift resources\n\nI have encountered it recently. I just ran Heat tests for Swift\nresources and saw that these tests are broken. It looks like no dsvm\ncheck job runs these tests and that is why we didn't encounter this\nissue earlier. I have found the commit that breaks these tests.\nhttps://review.openstack.org/#/c/153681/\n\nIn order to fix the tests we should add the following code lines\nto the file tempest/api/orchestration/stacks/test_swift_resources.py:\n\n    @classmethod\n    def setup_credentials(cls):\n        super(SwiftResourcesTestJSON, cls).setup_credentials()\n        stack_owner_role = CONF.orchestration.stack_owner_role\n        operator_role = CONF.object_storage.operator_role\n        cls.os = cls.get_client_manager(\n            roles=[stack_owner_role, operator_role])\n\nAfter adding these code lines we have working tests again.\n\nCloses-Bug: #1455775\n\nChange-Id: I5884149fef95c50d62ffde6e5c9488da1a9d6a55\n""}]",2,183801,1876b5dc062fb01e1bab174728439947f107ff9a,15,7,2,7428,,,0,"Fixing broken Heat tests for Swift resources

I have encountered it recently. I just ran Heat tests for Swift
resources and saw that these tests are broken. It looks like no dsvm
check job runs these tests and that is why we didn't encounter this
issue earlier. I have found the commit that breaks these tests.
https://review.openstack.org/#/c/153681/

In order to fix the tests we should add the following code lines
to the file tempest/api/orchestration/stacks/test_swift_resources.py:

    @classmethod
    def setup_credentials(cls):
        super(SwiftResourcesTestJSON, cls).setup_credentials()
        stack_owner_role = CONF.orchestration.stack_owner_role
        operator_role = CONF.object_storage.operator_role
        cls.os = cls.get_client_manager(
            roles=[stack_owner_role, operator_role])

After adding these code lines we have working tests again.

Closes-Bug: #1455775

Change-Id: I5884149fef95c50d62ffde6e5c9488da1a9d6a55
",git fetch https://review.opendev.org/openstack/tempest refs/changes/01/183801/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/orchestration/stacks/test_swift_resources.py'],1,d108d0155c2f8e69ee0f2e02fb4409540ec884c0,bug/1455775,"from tempest import clients def setup_credentials(cls): super(SwiftResourcesTestJSON, cls).setup_credentials() cls.os = clients.Manager() @classmethod",,6,0
openstack%2Fkeystone~master~Ia260838c85f897c52740217d8d222bb86edc11c6,openstack/keystone,master,Ia260838c85f897c52740217d8d222bb86edc11c6,Implement validation on the Identity V3 API,MERGED,2014-10-30 22:07:43.000000000,2015-05-21 20:17:15.000000000,2015-05-21 20:17:12.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5046}, {'_account_id': 6486}, {'_account_id': 7244}, {'_account_id': 8871}, {'_account_id': 8978}, {'_account_id': 9751}, {'_account_id': 10118}, {'_account_id': 11022}, {'_account_id': 13063}, {'_account_id': 13478}, {'_account_id': 15519}]","[{'number': 1, 'created': '2014-10-30 22:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/63d71ab914b0b968f6250e8b55919476d8326897', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1218682\n'}, {'number': 2, 'created': '2014-10-30 22:10:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/45315de61432da3dcd089d5648684e1e9b8c254f', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1218682\nCloses-Bug: #1387605\n'}, {'number': 3, 'created': '2014-11-04 09:13:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/537035d81e81dbd46613ca87c539d4e1b02087b8', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1218682\nCloses-Bug: #1387605\n'}, {'number': 4, 'created': '2014-11-07 08:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a0379e04c5f7d44addb24c04150a67ee555da08a', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1218682\nCloses-Bug: #1387605\n'}, {'number': 5, 'created': '2014-12-17 12:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1e25aa59a6c1a6992ed5e456b4beece704ea4cb5', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1218682\nCloses-Bug: #1387605\n'}, {'number': 6, 'created': '2014-12-18 14:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6a9743072526a3ee518ecd95ebd8eef851ef54e5', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1218682\nCloses-Bug: #1387605\n'}, {'number': 7, 'created': '2015-01-31 10:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/82180bd955b853e5ca316868f33b262b2170fe62', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nDue to import order issue with loading CONF.identity.max_password_length\nin the JSONschema, the validation has been added in the controller instead.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1218682\nCloses-Bug: #1387605\n'}, {'number': 8, 'created': '2015-01-31 10:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ec5000468511a5fc4a77ec942846784a8e10bf6f', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nDue to import order issue with loading CONF.identity.max_password_length\nin the JSONschema, the validation has been added in the controller instead.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 9, 'created': '2015-02-10 01:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7f0530738fc6d5c5b23e3b61f0b9be7316a52b4a', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nAlso, fixed the import ordering of config in the test setup.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 10, 'created': '2015-02-10 20:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8aed0bff59b3852fc74a4521e9721bd0db5d7f40', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 11, 'created': '2015-02-10 20:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f1314e6fc04b81473e31699d9d044307f4ee860a', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 12, 'created': '2015-02-14 03:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8548a78abce60940f376798b34097d7a43f383db', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 13, 'created': '2015-02-18 05:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/195ce93439361af012c654edc5d4295d2928c1bb', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 14, 'created': '2015-02-19 02:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/427c1e6bd827d0b2beed02f2f48863344207ac28', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 15, 'created': '2015-02-26 01:21:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c4fd584ec928db9fc8c72e594cae1d5d98eee795', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 16, 'created': '2015-02-26 01:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2bf693cea40e35ecfc43782d70abab45730ccee2', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 17, 'created': '2015-03-02 22:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c45a2d5ef8df70b5aa6c03ca43c0a6ee6bca48d2', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 18, 'created': '2015-03-03 00:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/23a2c7b845e3025cf93a91d67a44edc79a30b122', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 19, 'created': '2015-03-09 19:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0c2e4b18ba1c2f84999f4aaccd20e398be7cc6a7', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 20, 'created': '2015-03-26 19:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fd469781f979ec927d28344a63d4f8cb9afc737d', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 21, 'created': '2015-05-01 14:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6eacaca55805fdce4a923d6899d6a0547f197571', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: identity-api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}, {'number': 22, 'created': '2015-05-01 17:47:22.000000000', 'files': ['keystone/tests/unit/test_validation.py', 'keystone/identity/schema.py', 'keystone/identity/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f2103ffdcd2523662f791c01aaf94709cec06cf3', 'message': 'Implement validation on the Identity V3 API\n\nUse JSONSchema to validate CRUD operations on the V3 Identity resources.\nThis includes wrapping the create and update methods for Users and\nGroups.\n\nCo-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>\n\nChange-Id: Ia260838c85f897c52740217d8d222bb86edc11c6\nbp: identity-api-validation\nCloses-Bug: #999084\nCloses-Bug: #1387605\n'}]",55,132122,f2103ffdcd2523662f791c01aaf94709cec06cf3,95,13,22,5046,,,0,"Implement validation on the Identity V3 API

Use JSONSchema to validate CRUD operations on the V3 Identity resources.
This includes wrapping the create and update methods for Users and
Groups.

Co-Authored-By: Lin Hua Cheng <os.lcheng@gmail.com>

Change-Id: Ia260838c85f897c52740217d8d222bb86edc11c6
bp: identity-api-validation
Closes-Bug: #999084
Closes-Bug: #1387605
",git fetch https://review.opendev.org/openstack/keystone refs/changes/22/132122/21 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/identity/schema.py', 'keystone/identity/controllers.py', 'keystone/tests/test_validation.py', 'keystone/tests/test_v3.py']",4,63d71ab914b0b968f6250e8b55919476d8326897,bp/api-validation, ref['email'] = uuid.uuid4().hex + '@example.com', ref['email'] = uuid.uuid4().hex,292,5
openstack%2Frally~master~Ie393f3b0481c178a3442ac695ebba083ee1cbefd,openstack/rally,master,Ie393f3b0481c178a3442ac695ebba083ee1cbefd,[Validation] Allow `required_clients' validate admin clients,MERGED,2015-05-15 16:08:24.000000000,2015-05-21 20:13:18.000000000,2015-05-21 20:13:15.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8576}, {'_account_id': 9601}, {'_account_id': 10475}, {'_account_id': 14027}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-15 16:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/52998dc668bb06009c1452dd22fe8acb6ca2c7a7', 'message': ""[Validation] Allow `required_clients' validate admin clients\n\nSometimes we need to validate if some clients are available\nfor admin endpoint.\n\nSo this patch adds optional `admin' key argument to validator\nvalidation.required_clients for this purpose.\n\nChange-Id: Ie393f3b0481c178a3442ac695ebba083ee1cbefd\n""}, {'number': 2, 'created': '2015-05-18 09:31:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c44328339640b7f0c4273480cd47318f050d2ee7', 'message': ""[Validation] Allow `required_clients' validate admin clients\n\nSometimes we need to validate if some clients are available\nfor admin endpoint.\n\nSo this patch adds optional `admin' key argument to validator\nvalidation.required_clients for this purpose.\n\nChange-Id: Ie393f3b0481c178a3442ac695ebba083ee1cbefd\n""}, {'number': 3, 'created': '2015-05-20 10:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e42a8a1d8b0a6b31f07c2729a46e5c6796d8aa87', 'message': ""[Validation] Allow `required_clients' validate admin clients\n\nSometimes we need to validate if some clients are available\nfor admin endpoint.\n\nSo this patch adds optional `admin' key argument to validator\nvalidation.required_clients for this purpose.\n\nChange-Id: Ie393f3b0481c178a3442ac695ebba083ee1cbefd\n""}, {'number': 4, 'created': '2015-05-21 14:02:17.000000000', 'files': ['rally/benchmark/validation.py', 'tests/unit/benchmark/test_validation.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/8c528f8d9e32776228d577d13265057f35c9da95', 'message': ""[Validation] Allow `required_clients' validate admin clients\n\nSometimes we need to validate if some clients are available\nfor admin endpoint.\n\nSo this patch adds optional `admin' key argument to validator\nvalidation.required_clients for this purpose.\n\nChange-Id: Ie393f3b0481c178a3442ac695ebba083ee1cbefd\n""}]",3,183583,8c528f8d9e32776228d577d13265057f35c9da95,30,7,4,10475,,,0,"[Validation] Allow `required_clients' validate admin clients

Sometimes we need to validate if some clients are available
for admin endpoint.

So this patch adds optional `admin' key argument to validator
validation.required_clients for this purpose.

Change-Id: Ie393f3b0481c178a3442ac695ebba083ee1cbefd
",git fetch https://review.opendev.org/openstack/rally refs/changes/83/183583/3 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/validation.py', 'tests/unit/benchmark/test_validation.py']",2,52998dc668bb06009c1452dd22fe8acb6ca2c7a7,update-validator-required-clients,"MODULE = ""rally.benchmark.validation."" @mock.patch(MODULE + ""os.access"") @mock.patch(MODULE + ""os.access"") @mock.patch(MODULE + ""_file_access_ok"") @mock.patch(MODULE + ""types.ImageResourceType.transform"") @mock.patch(MODULE + ""types.ImageResourceType.transform"") @mock.patch(MODULE + ""types.ImageResourceType.transform"") @mock.patch(MODULE + ""types.FlavorResourceType.transform"") @mock.patch(MODULE + ""types.FlavorResourceType.transform"") @mock.patch(MODULE + ""types.FlavorResourceType.transform"") @mock.patch(MODULE + ""types.FlavorResourceType.transform"") @mock.patch(MODULE + ""types.FlavorResourceType.transform"") @mock.patch(MODULE + ""_get_validated_image"") @mock.patch(MODULE + ""_get_validated_flavor"") @mock.patch(MODULE + ""types.FlavorResourceType.transform"") @mock.patch(MODULE + ""_get_validated_image"") @mock.patch(MODULE + ""tempest.Tempest"") @mock.patch(MODULE + ""tempest.Tempest"") @mock.patch(MODULE + ""osclients"") def test_required_clients(self, mock_clients): result = validator({}, clients, {}) self.assertFalse(mock_clients.Clients.called) result = validator({}, clients, {}) self.assertFalse(result.is_valid, result.msg) @mock.patch(MODULE + ""objects"") @mock.patch(MODULE + ""osclients"") def test_required_clients_with_admin(self, mock_clients, mock_objects): validator = self._unwrap_validator(validation.required_clients, ""keystone"", ""nova"", admin=True) clients = mock.Mock() clients.keystone.return_value = ""keystone"" clients.nova.return_value = ""nova"" mock_clients.Clients.return_value = clients mock_objects.Endpoint.return_value = ""foo_endpoint"" result = validator({}, clients, {""admin"": {""foo"": ""bar""}}) self.assertTrue(result.is_valid, result.msg) mock_objects.Endpoint.assert_called_once_with(foo=""bar"") mock_clients.Clients.assert_called_once_with(""foo_endpoint"") clients.nova.side_effect = ImportError result = validator({}, clients, {""admin"": {""foo"": ""bar""}})"," @mock.patch(""rally.benchmark.validation.os.access"") @mock.patch(""rally.benchmark.validation.os.access"") @mock.patch(""rally.benchmark.validation._file_access_ok"") @mock.patch(""rally.benchmark.validation.types.ImageResourceType.transform"") @mock.patch(""rally.benchmark.validation.types.ImageResourceType.transform"") @mock.patch(""rally.benchmark.validation.types.ImageResourceType.transform"") @mock.patch(""rally.benchmark.validation.types.FlavorResourceType."" ""transform"") @mock.patch(""rally.benchmark.validation.types.FlavorResourceType."" ""transform"") @mock.patch(""rally.benchmark.validation.types.FlavorResourceType."" ""transform"") @mock.patch(""rally.benchmark.validation.types.FlavorResourceType."" ""transform"") @mock.patch(""rally.benchmark.validation.types.FlavorResourceType."" ""transform"") @mock.patch(""rally.benchmark.validation._get_validated_image"") @mock.patch(""rally.benchmark.validation._get_validated_flavor"") @mock.patch(""rally.benchmark.validation.types.FlavorResourceType."" ""transform"") @mock.patch(""rally.benchmark.validation._get_validated_image"") @mock.patch(""rally.benchmark.validation.tempest.Tempest"") @mock.patch(""rally.benchmark.validation.tempest.Tempest"") def test_required_clients(self): result = validator({}, clients, None) result = validator({}, clients, None)",49,28
openstack%2Ftempest~master~I7b37af339aea1be0cbe4bae1156e9f5dc20d0dd7,openstack/tempest,master,I7b37af339aea1be0cbe4bae1156e9f5dc20d0dd7,Add test caller to scenario manager ssh connection failure for tracking,MERGED,2015-05-21 16:26:25.000000000,2015-05-21 20:12:41.000000000,2015-05-21 20:12:39.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}]","[{'number': 1, 'created': '2015-05-21 16:26:25.000000000', 'files': ['tempest/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5f0ac52a6dccc69ccb33f9713d5b2986e654c59a', 'message': ""Add test caller to scenario manager ssh connection failure for tracking\n\ntest_volume_boot_pattern (v1 and v2) has been failing with generic\nSSHTimeout for awhile now but due to the very generic nature of the\nfailure we don't have a fingerprint in elastic-recheck for tracking the\nproblem.\n\nThis adds the specific error to the message that's logged and adds the\ntest caller so we can track specific tests hitting this failure rather\nthan everything that could possibly hit it and muddle the bug\ncategorization in elastic-recheck.\n\nRelated-Bug: #1355573\n\nChange-Id: I7b37af339aea1be0cbe4bae1156e9f5dc20d0dd7\n""}]",0,184815,5f0ac52a6dccc69ccb33f9713d5b2986e654c59a,7,3,1,6873,,,0,"Add test caller to scenario manager ssh connection failure for tracking

test_volume_boot_pattern (v1 and v2) has been failing with generic
SSHTimeout for awhile now but due to the very generic nature of the
failure we don't have a fingerprint in elastic-recheck for tracking the
problem.

This adds the specific error to the message that's logged and adds the
test caller so we can track specific tests hitting this failure rather
than everything that could possibly hit it and muddle the bug
categorization in elastic-recheck.

Related-Bug: #1355573

Change-Id: I7b37af339aea1be0cbe4bae1156e9f5dc20d0dd7
",git fetch https://review.opendev.org/openstack/tempest refs/changes/15/184815/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/manager.py'],1,5f0ac52a6dccc69ccb33f9713d5b2986e654c59a,bug/1355573,"from tempest_lib.common.utils import misc as misc_utils except Exception as e: message = ('Initializing SSH connection to %(ip)s failed. ' 'Error: %(error)s' % {'ip': ip, 'error': e}) caller = misc_utils.find_test_caller() if caller: message = '(%s) %s' % (caller, message) LOG.exception(message)", except Exception: LOG.exception('Initializing SSH connection to %s failed' % ip),8,2
openstack%2Foslo.log~master~I505a6e4946db88db4a1e57ed37f43bd203c7ab1f,openstack/oslo.log,master,I505a6e4946db88db4a1e57ed37f43bd203c7ab1f,Deprecate WritableLogger - used for eventlet logging,MERGED,2015-05-04 15:09:12.000000000,2015-05-21 20:07:08.000000000,2015-05-21 20:07:06.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-04 15:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/230feff83c0c5da5ada8671a653a5aee109ed203', 'message': ""Deprecate WritableLogger - used for eventlet logging\n\nWritableLogger was used for example in Nova as a bridge to the\neventlet's logging mechanism. Eventlet has been enhanced in\n0.17.2 to use python loggers directly, so we don't need this\nanymore.\n\nCloses-Bug: #1440773\nChange-Id: I505a6e4946db88db4a1e57ed37f43bd203c7ab1f\n""}, {'number': 2, 'created': '2015-05-04 16:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/59c82a848c4fd7ffd56848dbb33a2cefad7e0b91', 'message': ""Deprecate WritableLogger - used for eventlet logging\n\nWritableLogger was used for example in Nova as a bridge to the\neventlet's logging mechanism. Eventlet has been enhanced in\n0.17.2 to use python loggers directly, so we don't need this\nanymore.\n\nCloses-Bug: #1440773\nChange-Id: I505a6e4946db88db4a1e57ed37f43bd203c7ab1f\n""}, {'number': 3, 'created': '2015-05-04 20:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/c003945703f32652b52868c72e8e6574a259b396', 'message': ""Deprecate WritableLogger - used for eventlet logging\n\nWritableLogger was used for example in Nova as a bridge to the\neventlet's logging mechanism. Eventlet has been enhanced in\n0.17.2 to use python loggers directly, so we don't need this\nanymore.\n\nCloses-Bug: #1440773\nChange-Id: I505a6e4946db88db4a1e57ed37f43bd203c7ab1f\n""}, {'number': 4, 'created': '2015-05-04 20:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/c24e5ca025ce9060b3bd935e8942340d47cfb8cc', 'message': ""Deprecate WritableLogger - used for eventlet logging\n\nWritableLogger was used for example in Nova as a bridge to the\neventlet's logging mechanism. Eventlet has been enhanced in\n0.17.2 to use python loggers directly, so we don't need this\nanymore.\n\nCloses-Bug: #1440773\nChange-Id: I505a6e4946db88db4a1e57ed37f43bd203c7ab1f\n""}, {'number': 5, 'created': '2015-05-05 00:17:33.000000000', 'files': ['oslo_log/loggers.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/dbae3bf351de63d972996c536489bbc95dadd0d4', 'message': ""Deprecate WritableLogger - used for eventlet logging\n\nWritableLogger was used for example in Nova as a bridge to the\neventlet's logging mechanism. Eventlet has been enhanced in\n0.17.2 to use python loggers directly, so we don't need this\nanymore.\n\nCloses-Bug: #1440773\nChange-Id: I505a6e4946db88db4a1e57ed37f43bd203c7ab1f\n""}]",0,179808,dbae3bf351de63d972996c536489bbc95dadd0d4,16,4,5,5638,,,0,"Deprecate WritableLogger - used for eventlet logging

WritableLogger was used for example in Nova as a bridge to the
eventlet's logging mechanism. Eventlet has been enhanced in
0.17.2 to use python loggers directly, so we don't need this
anymore.

Closes-Bug: #1440773
Change-Id: I505a6e4946db88db4a1e57ed37f43bd203c7ab1f
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/08/179808/4 && git format-patch -1 --stdout FETCH_HEAD,['oslo_log/loggers.py'],1,230feff83c0c5da5ada8671a653a5aee109ed203,bug/1440773,"from openstack.common import versionutils @versionutils.deprecated( versionutils.deprecated.LIBERTY, remove_in=+1)",,4,0
openstack%2Frally~master~I92987c11f2c7b0cb7bab0d0d9e052b30ffa95366,openstack/rally,master,I92987c11f2c7b0cb7bab0d0d9e052b30ffa95366,[Context] Users cleanup should not fail without networking,MERGED,2015-05-15 13:19:57.000000000,2015-05-21 20:05:39.000000000,2015-05-21 20:05:36.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8576}, {'_account_id': 9601}, {'_account_id': 10475}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-15 13:19:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e5e1d44ff45ee025c818347176e4b760b74a45f1', 'message': '[Context] Fix users context cleanup: now works without networking\n\nUsers context cleanup tries to remove default secgroup,\neven if there is networking component not available.\nThis causes error on clouds with reduced components set (for example,\nFuel master node).\n\nThis patch disables default security group removal for these\nspecific cases.\n\nChange-Id: I92987c11f2c7b0cb7bab0d0d9e052b30ffa95366\nCloses-Bug: 1455474\n'}, {'number': 2, 'created': '2015-05-15 15:49:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/649153ed986ca2b89924d4505f4563528296bfdf', 'message': '[Context] Users cleanup should not fail without networking\n\nUsers context cleanup tries to remove default secgroup,\neven if there is networking component not available.\nThis causes error on clouds with reduced components set (for example,\nFuel master node).\n\nThis patch disables default security group removal for these\nspecific cases.\n\nChange-Id: I92987c11f2c7b0cb7bab0d0d9e052b30ffa95366\nCloses-Bug: 1455474\n'}, {'number': 3, 'created': '2015-05-15 15:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1bbbcc32163c2a2b2aaf7fb75f3ff5595eb3dcf6', 'message': '[Context] Users cleanup should not fail without networking\n\nUsers context cleanup tries to remove default secgroup,\neven if there is networking component not available.\nThis causes error on clouds with reduced components set (for example,\nFuel master node).\n\nThis patch disables default security group removal for these\nspecific cases.\n\nChange-Id: I92987c11f2c7b0cb7bab0d0d9e052b30ffa95366\nCloses-Bug: 1455474\n'}, {'number': 4, 'created': '2015-05-18 09:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/308177fca9e1b6bc06650685f450090f9c15cf3b', 'message': '[Context] Users cleanup should not fail without networking\n\nUsers context cleanup tries to remove default secgroup,\neven if there is networking component not available.\nThis causes error on clouds with reduced components set (for example,\nFuel master node).\n\nThis patch disables default security group removal for these\nspecific cases.\n\nChange-Id: I92987c11f2c7b0cb7bab0d0d9e052b30ffa95366\nCloses-Bug: 1455474\n'}, {'number': 5, 'created': '2015-05-19 16:20:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c7f00022b85eb53835ec9365a44a4462ce7a0979', 'message': '[Context] Users cleanup should not fail without networking\n\nUsers context cleanup tries to remove default secgroup,\neven if there is networking component not available.\nThis causes error on clouds with reduced components set (for example,\nFuel master node).\n\nThis patch disables default security group removal for these\nspecific cases.\n\nChange-Id: I92987c11f2c7b0cb7bab0d0d9e052b30ffa95366\nCloses-Bug: 1455474\n'}, {'number': 6, 'created': '2015-05-20 10:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/148a67f8e0744b934605e1f13913b5139e93c894', 'message': '[Context] Users cleanup should not fail without networking\n\nUsers context cleanup tries to remove default secgroup,\neven if there is networking component not available.\nThis causes error on clouds with reduced components set (for example,\nFuel master node).\n\nThis patch disables default security group removal for these\nspecific cases.\n\nChange-Id: I92987c11f2c7b0cb7bab0d0d9e052b30ffa95366\nCloses-Bug: 1455474\n'}, {'number': 7, 'created': '2015-05-21 13:59:35.000000000', 'files': ['rally/plugins/openstack/context/users.py', 'tests/unit/plugins/openstack/context/test_users.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/1be6e57d325f2a60a439d31e4a899434c0d6d716', 'message': '[Context] Users cleanup should not fail without networking\n\nUsers context cleanup tries to remove default secgroup,\neven if there is networking component not available.\nThis causes error on clouds with reduced components set (for example,\nFuel master node).\n\nThis patch disables default security group removal for these\nspecific cases.\n\nChange-Id: I92987c11f2c7b0cb7bab0d0d9e052b30ffa95366\nCloses-Bug: 1455474\n'}]",5,183510,1be6e57d325f2a60a439d31e4a899434c0d6d716,43,7,7,10475,,,0,"[Context] Users cleanup should not fail without networking

Users context cleanup tries to remove default secgroup,
even if there is networking component not available.
This causes error on clouds with reduced components set (for example,
Fuel master node).

This patch disables default security group removal for these
specific cases.

Change-Id: I92987c11f2c7b0cb7bab0d0d9e052b30ffa95366
Closes-Bug: 1455474
",git fetch https://review.opendev.org/openstack/rally refs/changes/10/183510/6 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/wrappers/network.py', 'tests/unit/benchmark/wrappers/test_network.py', 'rally/benchmark/context/users.py']",3,e5e1d44ff45ee025c818347176e4b760b74a45f1,bug/1455474, net_wrapper = network.wrap(clients) if (not net_wrapper or net_wrapper.SERVICE_IMPL != consts.Service.NEUTRON): # NOTE(amaretskiy): No need to remove secgroup if there is no # networking component available, net_wrapper = network.wrap(clients) if net_wrapper.SERVICE_IMPL != consts.Service.NEUTRON:,13,4
openstack%2Fbarbican~master~Ifd7398485aba653567901c53f419feb35992df0d,openstack/barbican,master,Ifd7398485aba653567901c53f419feb35992df0d,Split out generate mkek and hmac from get command,MERGED,2015-05-20 22:18:04.000000000,2015-05-21 20:04:59.000000000,2015-05-21 20:04:57.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 9234}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-05-20 22:18:04.000000000', 'files': ['barbican/tests/plugin/crypto/test_p11_crypto.py', 'barbican/plugin/crypto/pkcs11.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/d148f0514dde47ffefb24b7dc782b05e537212dc', 'message': 'Split out generate mkek and hmac from get command\n\nCreated a separate function for the generate commands\nas well as updated the tests to account for these\nchanges and test the new functions added.\n\nChange-Id: Ifd7398485aba653567901c53f419feb35992df0d\n'}]",7,184639,d148f0514dde47ffefb24b7dc782b05e537212dc,10,5,1,11970,,,0,"Split out generate mkek and hmac from get command

Created a separate function for the generate commands
as well as updated the tests to account for these
changes and test the new functions added.

Change-Id: Ifd7398485aba653567901c53f419feb35992df0d
",git fetch https://review.opendev.org/openstack/barbican refs/changes/39/184639/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/tests/plugin/crypto/test_p11_crypto.py', 'barbican/plugin/crypto/pkcs11.py']",2,d148f0514dde47ffefb24b7dc782b05e537212dc,rngeezus,"class P11CryptoKeyHandleException(exception.BarbicanException): message = u._(""No key handle was found"") self.get_mkek( self.get_hmac_key(self.current_hmac_label, session) def get_mkek(self, mkek_label, session): raise P11CryptoKeyHandleException() def generate_mkek(self, mkek_label, mkek_length, session): # Generate a key that is persistent and not extractable ck_attributes = self.build_attributes([ Attribute(CKA_CLASS, CKO_SECRET_KEY), Attribute(CKA_KEY_TYPE, CKK_AES), Attribute(CKA_VALUE_LEN, mkek_length), Attribute(CKA_LABEL, mkek_label), Attribute(CKA_PRIVATE, True), Attribute(CKA_SENSITIVE, True), Attribute(CKA_ENCRYPT, True), Attribute(CKA_DECRYPT, True), Attribute(CKA_SIGN, True), Attribute(CKA_VERIFY, True), Attribute(CKA_TOKEN, True), Attribute(CKA_WRAP, True), Attribute(CKA_UNWRAP, True), Attribute(CKA_EXTRACTABLE, False) ]) mkek = self.generate_kek(ck_attributes.template, session) self.key_handles[mkek_label] = mkek return mkek def get_hmac_key(self, hmac_label, session): raise P11CryptoKeyHandleException() self.key_handles[hmac_label] = hmac_key return hmac_key def generate_hmac_key(self, hmac_label, session): # Generate a key that is persistent and not extractable ck_attributes = self.build_attributes([ Attribute(CKA_CLASS, CKO_SECRET_KEY), Attribute(CKA_KEY_TYPE, CKK_AES), Attribute(CKA_VALUE_LEN, 32), Attribute(CKA_LABEL, hmac_label), Attribute(CKA_PRIVATE, True), Attribute(CKA_SENSITIVE, True), Attribute(CKA_SIGN, True), Attribute(CKA_VERIFY, True), Attribute(CKA_TOKEN, True), Attribute(CKA_EXTRACTABLE, False) ]) hmac_key = self.generate_kek(ck_attributes.template, session)"," self.get_or_generate_mkek( mkek_length, self.get_or_generate_hmac_key(self.current_hmac_label, session) def get_or_generate_mkek(self, mkek_label, mkek_length, session): # Generate a key that is persistent and not extractable ck_attributes = self.build_attributes([ Attribute(CKA_CLASS, CKO_SECRET_KEY), Attribute(CKA_KEY_TYPE, CKK_AES), Attribute(CKA_VALUE_LEN, mkek_length), Attribute(CKA_LABEL, mkek_label), Attribute(CKA_PRIVATE, True), Attribute(CKA_SENSITIVE, True), Attribute(CKA_ENCRYPT, True), Attribute(CKA_DECRYPT, True), Attribute(CKA_SIGN, True), Attribute(CKA_VERIFY, True), Attribute(CKA_TOKEN, True), Attribute(CKA_WRAP, True), Attribute(CKA_UNWRAP, True), Attribute(CKA_EXTRACTABLE, False) ]) mkek = self.generate_kek(ck_attributes.template, session) def get_or_generate_hmac_key(self, hmac_label, session): # Generate a key that is persistent and not extractable ck_attributes = self.build_attributes([ Attribute(CKA_CLASS, CKO_SECRET_KEY), Attribute(CKA_KEY_TYPE, CKK_AES), Attribute(CKA_VALUE_LEN, 32), Attribute(CKA_LABEL, hmac_label), Attribute(CKA_PRIVATE, True), Attribute(CKA_SENSITIVE, True), Attribute(CKA_SIGN, True), Attribute(CKA_VERIFY, True), Attribute(CKA_TOKEN, True), Attribute(CKA_EXTRACTABLE, False) ]) hmac_key = self.generate_kek(ck_attributes.template, session)",100,43
openstack%2Frally~master~I4fd2d271da1b7fd300fbbeb6107aa958e716fd2b,openstack/rally,master,I4fd2d271da1b7fd300fbbeb6107aa958e716fd2b,Rename rally.cmd to rally.cli,MERGED,2015-05-20 19:14:33.000000000,2015-05-21 20:02:01.000000000,2015-05-21 20:01:59.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-20 19:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e4fe43b4edb7b429249117c4bae37ced0985a589', 'message': ""Rename rally.cmd to rally.cli\n\nThere is module 'cmd' in standard library, and unittest's discover\ndoes modify sys.path when running tests. This cause errors when running\nunit tests in some environments (E.g. pycharm)\n\nChange-Id: I4fd2d271da1b7fd300fbbeb6107aa958e716fd2b\nCloses-Bug: 1457162\n""}, {'number': 2, 'created': '2015-05-20 19:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/debbc84e5101f4c0fdecde7122af6c71a8ecb686', 'message': ""Rename rally.cmd to rally.cli\n\nThere is module 'cmd' in standard library, and unittest's discover\ndoes modify sys.path when running tests. This cause errors when running\nunit tests in some environments (E.g. pycharm)\n\nChange-Id: I4fd2d271da1b7fd300fbbeb6107aa958e716fd2b\nCloses-Bug: 1457162\n""}, {'number': 3, 'created': '2015-05-21 15:14:38.000000000', 'files': ['tests/unit/cli/commands/test_deployment.py', 'tests/unit/cli/__init__.py', 'tests/unit/cli/commands/test_task.py', 'tests/functional/utils.py', 'tests/unit/cli/test_manage.py', 'tests/unit/cli/test_cliutils.py', 'tests/functional/test_cli_deployment.py', 'rally/cli/commands/info.py', 'tests/unit/cli/commands/test_show.py', 'rally/cli/commands/__init__.py', 'tests/unit/cli/commands/test_use.py', 'tests/unit/cli/commands/__init__.py', 'rally/cli/commands/show.py', 'rally/cli/envutils.py', 'tests/functional/test_cli_use.py', 'rally/cli/commands/use.py', 'tests/functional/test_task_samples.py', 'tests/unit/cli/commands/test_info.py', 'tests/unit/cli/commands/test_verify.py', 'rally/cli/cliutils.py', 'tests/functional/test_cli_info.py', 'tests/unit/test_resources.py', 'rally/cli/manage.py', 'rally/cli/commands/task.py', 'tests/functional/test_cli_task.py', 'tests/unit/cli/test_envutils.py', 'rally/cli/commands/deployment.py', 'rally/cli/commands/verify.py', 'setup.cfg', 'rally/cli/__init__.py', 'rally/cli/main.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/a9b635f62e1666e51d7e0cc9b7f5b77c2788e527', 'message': ""Rename rally.cmd to rally.cli\n\nThere is module 'cmd' in standard library, and unittest's discover\ndoes modify sys.path when running tests. This cause errors when running\nunit tests in some environments (E.g. pycharm)\n\nChange-Id: I4fd2d271da1b7fd300fbbeb6107aa958e716fd2b\nCloses-Bug: 1457162\n""}]",4,184591,a9b635f62e1666e51d7e0cc9b7f5b77c2788e527,24,6,3,7369,,,0,"Rename rally.cmd to rally.cli

There is module 'cmd' in standard library, and unittest's discover
does modify sys.path when running tests. This cause errors when running
unit tests in some environments (E.g. pycharm)

Change-Id: I4fd2d271da1b7fd300fbbeb6107aa958e716fd2b
Closes-Bug: 1457162
",git fetch https://review.opendev.org/openstack/rally refs/changes/91/184591/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/cli/commands/test_deployment.py', 'tests/unit/cli/__init__.py', 'tests/unit/cli/commands/test_task.py', 'tests/unit/cli/test_manage.py', 'tests/unit/cli/test_cliutils.py', 'tests/functional/test_cli_deployment.py', 'rally/cli/commands/info.py', 'tests/unit/cli/commands/test_show.py', 'rally/cli/commands/__init__.py', 'tests/unit/cli/commands/test_use.py', 'tests/unit/cli/commands/__init__.py', 'rally/cli/commands/show.py', 'rally/cli/envutils.py', 'tests/functional/test_cli_use.py', 'rally/cli/commands/use.py', 'tests/unit/cli/commands/test_info.py', 'tests/unit/cli/commands/test_verify.py', 'rally/cli/cliutils.py', 'tests/unit/test_resources.py', 'rally/cli/manage.py', 'rally/cli/commands/task.py', 'tests/functional/test_cli_task.py', 'tests/unit/cli/test_envutils.py', 'rally/cli/commands/deployment.py', 'rally/cli/commands/verify.py', 'rally/cli/__init__.py', 'rally/cli/main.py']",27,e4fe43b4edb7b429249117c4bae37ced0985a589,bug/1457162,from rally.cli import cliutils from rally.cli.commands import deployment from rally.cli.commands import info from rally.cli.commands import show from rally.cli.commands import task from rally.cli.commands import use from rally.cli.commands import verify,from rally.cmd import cliutils from rally.cmd.commands import deployment from rally.cmd.commands import info from rally.cmd.commands import show from rally.cmd.commands import task from rally.cmd.commands import use from rally.cmd.commands import verify,192,192
openstack%2Fkeystone~master~I7e85b2b879f4c66c3664e8610d3ddbb999a5ac75,openstack/keystone,master,I7e85b2b879f4c66c3664e8610d3ddbb999a5ac75,"Revert ""Loosen validation on matching trusted dashboard""",MERGED,2015-05-05 22:33:24.000000000,2015-05-21 19:35:21.000000000,2015-05-21 19:35:18.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 8978}, {'_account_id': 13478}]","[{'number': 1, 'created': '2015-05-05 22:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9741fe723ec63bc96b37975b73d0de38e6b0fb56', 'message': 'Revert ""Loosen validation on matching trusted dashboard""\n\nLoosening the validation introduce a security hole for unvalidated redirect.\n\nThis reverts commit fb6920e5fe1fef2fa32afe602d2bf93f18d48a3f.\n\nChange-Id: I7e85b2b879f4c66c3664e8610d3ddbb999a5ac75\n'}, {'number': 2, 'created': '2015-05-06 16:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ae0f5242c9d543144b9bd618f22ee61098f4b112', 'message': 'Revert ""Loosen validation on matching trusted dashboard""\n\nLoosening the validation introduce a security hole for unvalidated redirect.\n\nThis reverts commit fb6920e5fe1fef2fa32afe602d2bf93f18d48a3f.\n\nChange-Id: I7e85b2b879f4c66c3664e8610d3ddbb999a5ac75\nCloses-Bug: #1440958\n'}, {'number': 3, 'created': '2015-05-06 16:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2fbc671568d501d304344d6a16248189e85bd392', 'message': 'Revert ""Loosen validation on matching trusted dashboard""\n\nLoosening the validation introduce a security hole for unvalidated redirect. For example: redirect_url=http://dashboard/sso?next=http://hacksite\n\nThis reverts commit fb6920e5fe1fef2fa32afe602d2bf93f18d48a3f.\n\nChange-Id: I7e85b2b879f4c66c3664e8610d3ddbb999a5ac75\nCloses-Bug: #1440958\n'}, {'number': 4, 'created': '2015-05-06 16:39:38.000000000', 'files': ['keystone/tests/unit/test_v3_federation.py', 'keystone/contrib/federation/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b48c820e3015a0d6264df6a0a87bf1a3dbea61c4', 'message': 'Revert ""Loosen validation on matching trusted dashboard""\n\nLoosening the validation introduce a security hole for unvalidated redirect.\n\nFor example: redirect_url=http://dashboard/sso?next=http://hacksite\n\nThis reverts commit fb6920e5fe1fef2fa32afe602d2bf93f18d48a3f.\n\nChange-Id: I7e85b2b879f4c66c3664e8610d3ddbb999a5ac75\nCloses-Bug: #1440958\n'}]",0,180343,b48c820e3015a0d6264df6a0a87bf1a3dbea61c4,22,7,4,1941,,,0,"Revert ""Loosen validation on matching trusted dashboard""

Loosening the validation introduce a security hole for unvalidated redirect.

For example: redirect_url=http://dashboard/sso?next=http://hacksite

This reverts commit fb6920e5fe1fef2fa32afe602d2bf93f18d48a3f.

Change-Id: I7e85b2b879f4c66c3664e8610d3ddbb999a5ac75
Closes-Bug: #1440958
",git fetch https://review.opendev.org/openstack/keystone refs/changes/43/180343/4 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_v3_federation.py', 'keystone/contrib/federation/controllers.py']",2,9741fe723ec63bc96b37975b73d0de38e6b0fb56,bug/1440958, if host in CONF.federation.trusted_dashboard:," def _is_trusted_dashboard(self, host): """"""Verify that host is a trusted dashboard. Check if the host scheme and netloc matches one of listed trusted_dashboard. """""" host_url = urllib.parse.urlparse(host) for dashboard in CONF.federation.trusted_dashboard: dashboard_url = urllib.parse.urlparse(dashboard) if (host_url.scheme == dashboard_url.scheme and host_url.netloc == dashboard_url.netloc): return True return False if self._is_trusted_dashboard(host):",1,32
openstack%2Fkeystoneauth~master~I302d7bf2008cbb38dca340acbb2f40121329cbaf,openstack/keystoneauth,master,I302d7bf2008cbb38dca340acbb2f40121329cbaf,Remove un-needed requirements,MERGED,2015-05-16 23:24:04.000000000,2015-05-21 19:33:55.000000000,2015-05-21 19:33:54.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-16 23:24:04.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/5aee35cf6e09e1f8bd78fd79736f6c2e8598d84d', 'message': 'Remove un-needed requirements\n\nChange-Id: I302d7bf2008cbb38dca340acbb2f40121329cbaf\n'}]",0,183849,5aee35cf6e09e1f8bd78fd79736f6c2e8598d84d,15,6,1,2903,,,0,"Remove un-needed requirements

Change-Id: I302d7bf2008cbb38dca340acbb2f40121329cbaf
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/49/183849/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5aee35cf6e09e1f8bd78fd79736f6c2e8598d84d,,,"iso8601>=0.1.9 netaddr>=0.7.12PrettyTable>=0.7,<0.8",0,3
openstack%2Fneutron~master~I34c2249d0865485578767865c82414e1d813d563,openstack/neutron,master,I34c2249d0865485578767865c82414e1d813d563,Match order of iptables arguments to iptables-save,MERGED,2015-05-19 23:39:28.000000000,2015-05-21 19:29:47.000000000,2015-05-21 17:14:21.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 8358}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-05-19 23:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a28e133608c207c5954836a5e6837cc0e1d252b0', 'message': 'Match order of iptables arguments to iptables-save\n\nThe way we were forming our iptables rules was not matching\nthe output of iptables-save. This caused the logic that preserves\ncounters to miss many of the rules.\n\nThis patch corrects the order for the comments and the allowed address\npairs to match the output order of iptables-save.\n\nCloses-Bug: #1456823\nChange-Id: I34c2249d0865485578767865c82414e1d813d563\n'}, {'number': 2, 'created': '2015-05-20 19:04:46.000000000', 'files': ['neutron/agent/linux/iptables_firewall.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/tests/unit/agent/test_securitygroups_rpc.py', 'neutron/tests/unit/agent/linux/test_iptables_firewall.py', 'neutron/tests/unit/agent/linux/test_iptables_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/12889f70e1ae547598f4c663e9da5b9bb03e347e', 'message': 'Match order of iptables arguments to iptables-save\n\nThe way we were forming our iptables rules was not matching\nthe output of iptables-save. This caused the logic that preserves\ncounters to miss many of the rules.\n\nThis patch corrects the order for the comments and the allowed address\npairs to match the output order of iptables-save.\n\nCloses-Bug: #1456823\nChange-Id: I34c2249d0865485578767865c82414e1d813d563\n'}]",1,184355,12889f70e1ae547598f4c663e9da5b9bb03e347e,71,31,2,7787,,,0,"Match order of iptables arguments to iptables-save

The way we were forming our iptables rules was not matching
the output of iptables-save. This caused the logic that preserves
counters to miss many of the rules.

This patch corrects the order for the comments and the allowed address
pairs to match the output order of iptables-save.

Closes-Bug: #1456823
Change-Id: I34c2249d0865485578767865c82414e1d813d563
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/184355/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/iptables_firewall.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/tests/unit/agent/linux/test_iptables_firewall.py', 'neutron/tests/unit/agent/linux/test_iptables_manager.py']",4,a28e133608c207c5954836a5e6837cc0e1d252b0,bug/1456823," '[0:0] -A neutron-postrouting-bottom ' '-m comment --comment ""%(snat_out_comment)s"" -j %(bn)s-snat\n'"," '[0:0] -A neutron-postrouting-bottom -j %(bn)s-snat ' '-m comment --comment ""%(snat_out_comment)s""\n'",23,14
openstack%2Fos-testr~master~I9953019794ba53fcfcb20e32fecbe94da22c9565,openstack/os-testr,master,I9953019794ba53fcfcb20e32fecbe94da22c9565,Fix ValueError in subunit_trace,MERGED,2015-04-18 11:40:34.000000000,2015-05-21 19:26:10.000000000,2015-05-21 19:26:10.000000000,"[{'_account_id': 3}, {'_account_id': 5196}]","[{'number': 1, 'created': '2015-04-18 11:40:34.000000000', 'files': ['test-requirements.txt', 'os_testr/tests/test_subunit_trace.py', 'os_testr/subunit_trace.py'], 'web_link': 'https://opendev.org/openstack/os-testr/commit/9832648353432fa0e05a3003bbf67052453e9d3f', 'message': ""Fix ValueError in subunit_trace\n\nWhen a subunit stream for a testcase doesn't contain start end\nenddate, the duration can't be calculated which leads to a:\n\nValueError: could not convert string to float\n\nCheck now if the duration is an empty string and add basic test\ncoverage based on ddt for the subunit_trace command.\n\nChange-Id: I9953019794ba53fcfcb20e32fecbe94da22c9565\n""}]",0,175126,9832648353432fa0e05a3003bbf67052453e9d3f,7,2,1,7102,,,0,"Fix ValueError in subunit_trace

When a subunit stream for a testcase doesn't contain start end
enddate, the duration can't be calculated which leads to a:

ValueError: could not convert string to float

Check now if the duration is an empty string and add basic test
coverage based on ddt for the subunit_trace command.

Change-Id: I9953019794ba53fcfcb20e32fecbe94da22c9565
",git fetch https://review.opendev.org/openstack/os-testr refs/changes/26/175126/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'os_testr/tests/test_subunit_trace.py', 'os_testr/subunit_trace.py']",3,9832648353432fa0e05a3003bbf67052453e9d3f,, test_dur = get_duration(test['timestamps']).strip('s') # NOTE(toabctl): get_duration() can return an empty string # which leads to a ValueError when casting to float if test_dur: runtime += float(test_dur), runtime += float(get_duration(test['timestamps']).strip('s')),67,1
openstack%2Fneutron~master~Ic22e932cbf3c4b75cd424f4b41428da869f197cf,openstack/neutron,master,Ic22e932cbf3c4b75cd424f4b41428da869f197cf,Python 3: use six.string_types instead of basestring,MERGED,2015-05-20 13:14:39.000000000,2015-05-21 19:25:11.000000000,2015-05-21 19:25:10.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 8122}, {'_account_id': 8124}, {'_account_id': 9008}, {'_account_id': 9107}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12561}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-05-20 13:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a7c6be64ed0083a94b6ea442efbb63ff5869debb', 'message': 'Python 3: use six.string_types instead of basestring\n\nIn Python 3, there is no ""basestring"". In Python 3, ""six.string_types"" is\n""basestring"", and ""str"" in Python 3.\n\nChange-Id: Ic22e932cbf3c4b75cd424f4b41428da869f197cf\n'}, {'number': 2, 'created': '2015-05-20 13:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5b09f959dcfb953a418f298cecda04abac44b6c', 'message': 'Python 3: use six.string_types instead of basestring\n\nIn Python 3, there is no ""basestring"". In Python 3, ""six.string_types"" is\n""basestring"", and ""str"" in Python 3.\n\nChange-Id: Ic22e932cbf3c4b75cd424f4b41428da869f197cf\n'}, {'number': 3, 'created': '2015-05-20 14:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1fb4a31261febf0e48f0618ef1acf2f3ab52c65', 'message': 'Python 3: use six.string_types instead of basestring\n\nIn Python 3, there is no ""basestring"". In Python 3, ""six.string_types"" is\n""basestring"", and ""str"" in Python 3.\n\nChange-Id: Ic22e932cbf3c4b75cd424f4b41428da869f197cf\nBlueprint: neutron-python3\n'}, {'number': 4, 'created': '2015-05-21 02:09:46.000000000', 'files': ['neutron/agent/ovsdb/impl_vsctl.py', 'neutron/db/l3_dvr_db.py', 'neutron/quota.py', 'neutron/api/v2/attributes.py', 'neutron/extensions/securitygroup.py', 'neutron/hacking/checks.py', 'neutron/tests/unit/hacking/test_checks.py', 'neutron/db/common_db_mixin.py', 'neutron/db/migration/alembic_migrations/heal_script.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6c1cb05302f369b3105cea73cb86a00018ada6be', 'message': 'Python 3: use six.string_types instead of basestring\n\nIn Python 3, there is no ""basestring"". In Python 3, ""six.string_types"" is\n""basestring"", and ""str"" in Python 3.\n\nChange-Id: Ic22e932cbf3c4b75cd424f4b41428da869f197cf\nBlueprint: neutron-python3\n'}]",4,184482,6c1cb05302f369b3105cea73cb86a00018ada6be,98,35,4,8122,,,0,"Python 3: use six.string_types instead of basestring

In Python 3, there is no ""basestring"". In Python 3, ""six.string_types"" is
""basestring"", and ""str"" in Python 3.

Change-Id: Ic22e932cbf3c4b75cd424f4b41428da869f197cf
Blueprint: neutron-python3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/82/184482/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/ovsdb/impl_vsctl.py', 'neutron/db/l3_dvr_db.py', 'neutron/api/v2/attributes.py', 'neutron/quota.py', 'neutron/extensions/securitygroup.py', 'neutron/db/common_db_mixin.py', 'neutron/db/migration/alembic_migrations/heal_script.py']",7,a7c6be64ed0083a94b6ea442efbb63ff5869debb,bp/neutron-python3,"import six if isinstance(new, six.string_types): if isinstance(default.arg, six.string_types):"," if isinstance(new, basestring): if isinstance(default.arg, basestring):",18,12
openstack%2Frally~master~If5649e988c0d3c5ace7d546e002ae7c6e4a3a15b,openstack/rally,master,If5649e988c0d3c5ace7d546e002ae7c6e4a3a15b,DO-NOT-MERGE test fuel scenraio,ABANDONED,2015-05-20 16:46:17.000000000,2015-05-21 19:14:20.000000000,,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-20 16:46:17.000000000', 'files': ['tests/unit/benchmark/scenarios/fuel/test_environments.py', 'rally/benchmark/scenarios/fuel/utils.py', 'rally/benchmark/scenarios/fuel/environments.py', 'tests/unit/benchmark/scenarios/fuel/test_utils.py', 'samples/tasks/scenarios/fuel/list-environments.yaml', 'tests/unit/benchmark/scenarios/fuel/__init__.py', 'samples/tasks/scenarios/fuel/list-environments.json', 'optional-requirements.txt', 'rally/benchmark/scenarios/fuel/__init__.py', 'rally-jobs/fuel.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/512d5b2aa04c8fdb9ea455c2d890da34cf0b8bac', 'message': 'DO-NOT-MERGE test fuel scenraio\n\nChange-Id: If5649e988c0d3c5ace7d546e002ae7c6e4a3a15b\n'}]",0,184542,512d5b2aa04c8fdb9ea455c2d890da34cf0b8bac,39,3,1,7369,,,0,"DO-NOT-MERGE test fuel scenraio

Change-Id: If5649e988c0d3c5ace7d546e002ae7c6e4a3a15b
",git fetch https://review.opendev.org/openstack/rally refs/changes/42/184542/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/fuel/utils.py', 'tests/unit/benchmark/scenarios/fuel/test_environments.py', 'rally/benchmark/scenarios/fuel/environments.py', 'tests/unit/benchmark/scenarios/fuel/test_utils.py', 'samples/tasks/scenarios/fuel/list-environments.yaml', 'tests/unit/benchmark/scenarios/fuel/__init__.py', 'optional-requirements.txt', 'samples/tasks/scenarios/fuel/list-environments.json', 'rally/benchmark/scenarios/fuel/__init__.py', 'rally-jobs/fuel.yaml']",10,512d5b2aa04c8fdb9ea455c2d890da34cf0b8bac,delme,"--- FuelEnvironments.list_environments: - runner: type: ""constant"" times: 200 concurrency: 10 sla: failure_rate: max: 0 ",,242,1
openstack%2Fdragonflow~master~I8f0653ffa880c957dedb9e738726e1d641808645,openstack/dragonflow,master,I8f0653ffa880c957dedb9e738726e1d641808645,Fixes to README,MERGED,2015-05-21 13:26:31.000000000,2015-05-21 18:58:56.000000000,2015-05-21 18:58:55.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 13070}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-05-21 13:26:31.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b9f9cce742190a2c0833645706fcf87cd52adecc', 'message': 'Fixes to README\n\nChange-Id: I8f0653ffa880c957dedb9e738726e1d641808645\n'}]",0,184785,b9f9cce742190a2c0833645706fcf87cd52adecc,6,4,1,11343,,,0,"Fixes to README

Change-Id: I8f0653ffa880c957dedb9e738726e1d641808645
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/85/184785/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,b9f9cce742190a2c0833645706fcf87cd52adecc,readme_changes,`Installation Guide <https://github.com/stackforge/dragonflow/tree/master/doc/source>`_ `DevStack Single Node Configuration <https://github.com/stackforge/dragonflow/tree/master/doc/source/single-node-conf>`_ `DevStack Multi Node Configuration <https://github.com/stackforge/dragonflow/tree/master/doc/source/multi-node-conf>`_,`Installation guide <https://github.com/stackforge/dragonflow/tree/master/doc/source>`_ `DevStack Single node configration <https://github.com/stackforge/dragonflow/tree/master/doc/source/single-node-conf>`_ `DevStack Multi node configration <https://github.com/stackforge/dragonflow/tree/master/doc/source/multi-node-conf>`_,5,3
openstack%2Fheat~master~Ifbcbd1252e96b0a7f88be5dd9335cbd7263a3331,openstack/heat,master,Ifbcbd1252e96b0a7f88be5dd9335cbd7263a3331,Fix property validation for TemplateResource during update,ABANDONED,2015-05-21 18:58:11.000000000,2015-05-21 18:58:43.000000000,,[],"[{'number': 1, 'created': '2015-05-21 18:58:11.000000000', 'files': ['heat_integrationtests/functional/test_template_resource.py', 'heat/engine/resources/template_resource.py', 'heat/engine/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2e255be046a96c773abd7655327d04bdb997a737', 'message': 'Fix property validation for TemplateResource during update\n\nThis fix adds schema regeneration before props are validated\nfor TemplateResource during stack-update.\n\nChange-Id: Ifbcbd1252e96b0a7f88be5dd9335cbd7263a3331\nCloses-Bug: #1452983\nCloses-Bug: #1453923\n(cherry picked from commit Ia79a25083489f48ed7332fbbd089a0090452cdc4)\n'}]",0,184850,2e255be046a96c773abd7655327d04bdb997a737,2,0,1,8833,,,0,"Fix property validation for TemplateResource during update

This fix adds schema regeneration before props are validated
for TemplateResource during stack-update.

Change-Id: Ifbcbd1252e96b0a7f88be5dd9335cbd7263a3331
Closes-Bug: #1452983
Closes-Bug: #1453923
(cherry picked from commit Ia79a25083489f48ed7332fbbd089a0090452cdc4)
",git fetch https://review.opendev.org/openstack/heat refs/changes/50/184850/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat_integrationtests/functional/test_template_resource.py', 'heat/engine/resources/template_resource.py', 'heat/engine/resource.py']",3,2e255be046a96c773abd7655327d04bdb997a737,bug/1452983," # Regenerate the schema, else validation would fail self.regenerate_info_schema(after) def regenerate_info_schema(self, definition): """""" Default implementation; should be overridden by resources that would require schema refresh during update, ex. TemplateResource :definition: Resource Definition """""" # By default, do not regenerate pass ",,113,5
openstack%2Ftripleo-heat-templates~master~I6bfee04649aa36116d1141ebe06d08b310ec8939,openstack/tripleo-heat-templates,master,I6bfee04649aa36116d1141ebe06d08b310ec8939,Align puppet Controller post-deploy Deployment names,MERGED,2015-05-12 16:35:46.000000000,2015-05-21 18:50:06.000000000,2015-05-21 16:50:48.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-05-12 16:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/204ff860a954627b6ec8f3e382042d96c40d6d4f', 'message': 'Align puppet Controller post-deploy Deployment names\n\nAlign all Deployment resource so we can use a glob convention for\nstepped deployments via heat hooks/breakpoints.\n\nSince most resources already use a FooDeployment_StepN convention,\nalign those which deviate from this as a precursor to supporting\nstepped deployment, e.g stepping through ""*Deployment_Step*"".\n\nChange-Id: I6bfee04649aa36116d1141ebe06d08b310ec8939\n'}, {'number': 2, 'created': '2015-05-13 17:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e5c27bd7eb5dba99b6f78e2b63cab74d38212923', 'message': 'Align puppet Controller post-deploy Deployment names\n\nAlign all Deployment resource so we can use a glob convention for\nstepped deployments via heat hooks/breakpoints.\n\nSince most resources already use a FooDeployment_StepN convention,\nalign those which deviate from this as a precursor to supporting\nstepped deployment, e.g stepping through ""*Deployment_Step*"".\n\nChange-Id: I6bfee04649aa36116d1141ebe06d08b310ec8939\n'}, {'number': 3, 'created': '2015-05-15 11:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/918f9ae0c17dce73e23bf205df53dbb78e75f9c6', 'message': 'Align puppet Controller post-deploy Deployment names\n\nAlign all Deployment resource so we can use a glob convention for\nstepped deployments via heat hooks/breakpoints.\n\nSince most resources already use a FooDeployment_StepN convention,\nalign those which deviate from this as a precursor to supporting\nstepped deployment, e.g stepping through ""*Deployment_Step*"".\n\nChange-Id: I6bfee04649aa36116d1141ebe06d08b310ec8939\n'}, {'number': 4, 'created': '2015-05-21 16:47:53.000000000', 'files': ['puppet/controller-post-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/23c329bbb9fc39f84a9397c59272bd81ab4628fe', 'message': 'Align puppet Controller post-deploy Deployment names\n\nAlign all Deployment resource so we can use a glob convention for\nstepped deployments via heat hooks/breakpoints.\n\nSince most resources already use a FooDeployment_StepN convention,\nalign those which deviate from this as a precursor to supporting\nstepped deployment, e.g stepping through ""*Deployment_Step*"".\n\nChange-Id: I6bfee04649aa36116d1141ebe06d08b310ec8939\n'}]",2,182381,23c329bbb9fc39f84a9397c59272bd81ab4628fe,22,9,4,4328,,,0,"Align puppet Controller post-deploy Deployment names

Align all Deployment resource so we can use a glob convention for
stepped deployments via heat hooks/breakpoints.

Since most resources already use a FooDeployment_StepN convention,
align those which deviate from this as a precursor to supporting
stepped deployment, e.g stepping through ""*Deployment_Step*"".

Change-Id: I6bfee04649aa36116d1141ebe06d08b310ec8939
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/81/182381/4 && git format-patch -1 --stdout FETCH_HEAD,['puppet/controller-post-puppet.yaml'],1,204ff860a954627b6ec8f3e382042d96c40d6d4f,stepped_deployment," # NOTE: To enable stepping through the deployments via heat hooks, # you must observe the glob naming defined in overcloud-steps.yaml # e.g all Deployment resources should have a *Deployment_StepN suffix ControllerLoadBalancerDeployment_Step1: ControllerServicesBaseDeployment_Step2: depends_on: ControllerLoadBalancerDeployment_Step1 depends_on: ControllerServicesBaseDeployment_Step2 ControllerOvercloudServicesDeployment_Step4: depends_on: ControllerOvercloudServicesDeployment_Step4", # NOTE(dprince): Heat breakpoints would make for a really cool way to step # through breakpoints in a controlled manner across the entire cluster ControllerDeploymentLoadBalancer_Step1: ControllerDeploymentServicesBase_Step2: depends_on: ControllerDeploymentLoadBalancer_Step1 depends_on: ControllerDeploymentServicesBase_Step2 ControllerDeploymentOvercloudServices_Step4: depends_on: ControllerDeploymentOvercloudServices_Step4,9,8
openstack%2Fironic-python-agent~master~I3315e111bd5994d2af2a7a2d0079a09e3d4e4d8b,openstack/ironic-python-agent,master,I3315e111bd5994d2af2a7a2d0079a09e3d4e4d8b,Rename gendocs tox environment,MERGED,2015-05-20 14:38:27.000000000,2015-05-21 18:49:46.000000000,2015-05-21 18:49:44.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7711}, {'_account_id': 10380}]","[{'number': 1, 'created': '2015-05-20 14:38:27.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/141191bcfac852486885011836f8512914e14052', 'message': 'Rename gendocs tox environment\n\nAll other openstack projects use docs environment, use the same\nname for ironic-python-agent as well.\n\nChange-Id: I3315e111bd5994d2af2a7a2d0079a09e3d4e4d8b\n'}]",0,184512,141191bcfac852486885011836f8512914e14052,12,4,1,6547,,,0,"Rename gendocs tox environment

All other openstack projects use docs environment, use the same
name for ironic-python-agent as well.

Change-Id: I3315e111bd5994d2af2a7a2d0079a09e3d4e4d8b
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/12/184512/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,141191bcfac852486885011836f8512914e14052,gendocs,[testenv:docs],[testenv:gendocs],1,1
openstack%2Fec2-api~master~Id2438158f959068391c0302846dc61a59cf7284c,openstack/ec2-api,master,Id2438158f959068391c0302846dc61a59cf7284c,Store static routes for VPN gateways,MERGED,2015-05-16 14:29:43.000000000,2015-05-21 18:38:24.000000000,2015-05-21 18:38:21.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-05-16 14:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/bf0ef00b297a952a374e06c2fbb6665b1f85b9dd', 'message': 'Store static routes for VPN gateways\n\nChange-Id: Id2438158f959068391c0302846dc61a59cf7284c\n'}, {'number': 2, 'created': '2015-05-16 14:43:47.000000000', 'files': ['ec2api/api/cloud.py', 'ec2api/tests/unit/fakes.py', 'ec2api/api/route_table.py', 'ec2api/tests/unit/test_route_table.py', 'ec2api/exception.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/2ab476ecb2afcf2e2f9c3da68b99ef1e62c7d081', 'message': 'Store static routes for VPN gateways\n\nChange-Id: Id2438158f959068391c0302846dc61a59cf7284c\n'}]",0,183802,2ab476ecb2afcf2e2f9c3da68b99ef1e62c7d081,7,3,2,10224,,,0,"Store static routes for VPN gateways

Change-Id: Id2438158f959068391c0302846dc61a59cf7284c
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/02/183802/2 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/cloud.py', 'ec2api/tests/unit/fakes.py', 'ec2api/api/route_table.py', 'ec2api/tests/unit/test_route_table.py', 'ec2api/exception.py']",5,bf0ef00b297a952a374e06c2fbb6665b1f85b9dd,vpn,"class InvalidGatewayIDNotFound(EC2NotFoundException): ec2_code = 'InvalidGatewayID.NotFound' msg_fmt = _(""The gateway ID '%(id)s' does not exist"") ",,103,19
openstack%2Fec2-api~master~I6d1d88c779321e875c16943a4aa162457543267c,openstack/ec2-api,master,I6d1d88c779321e875c16943a4aa162457543267c,Implement VPN gateways,MERGED,2015-05-16 12:35:25.000000000,2015-05-21 18:36:55.000000000,2015-05-21 18:36:53.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-05-16 12:35:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/0ec634895845b8a8b60dab010a1d90908234cec1', 'message': 'Implement VPN gateways\n\nChange-Id: I6d1d88c779321e875c16943a4aa162457543267c\n'}, {'number': 2, 'created': '2015-05-16 14:29:43.000000000', 'files': ['ec2api/tests/unit/test_ec2utils.py', 'ec2api/tests/unit/test_vpc.py', 'ec2api/api/cloud.py', 'ec2api/tests/unit/test_ec2_validate.py', 'ec2api/api/common.py', 'ec2api/api/vpn_gateway.py', 'ec2api/api/vpc.py', 'ec2api/tests/unit/fakes.py', 'ec2api/api/ec2utils.py', 'ec2api/exception.py', 'ec2api/tests/unit/test_vpn_gateway.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/6843471ed137b67730f26f45ea734ab247e0a5c2', 'message': 'Implement VPN gateways\n\nChange-Id: I6d1d88c779321e875c16943a4aa162457543267c\n'}]",0,183789,6843471ed137b67730f26f45ea734ab247e0a5c2,8,3,2,10224,,,0,"Implement VPN gateways

Change-Id: I6d1d88c779321e875c16943a4aa162457543267c
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/89/183789/2 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/unit/test_ec2utils.py', 'ec2api/tests/unit/test_vpc.py', 'ec2api/api/cloud.py', 'ec2api/api/common.py', 'ec2api/api/vpn_gateway.py', 'ec2api/api/vpc.py', 'ec2api/tests/unit/fakes.py', 'ec2api/api/ec2utils.py', 'ec2api/exception.py', 'ec2api/tests/unit/test_vpn_gateway.py']",10,0ec634895845b8a8b60dab010a1d90908234cec1,vpn,"# Copyright 2014 # The Cloudscaling Group, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import mock from ec2api.tests.unit import base from ec2api.tests.unit import fakes from ec2api.tests.unit import matchers from ec2api.tests.unit import tools class VpnGatewayTestCase(base.ApiTestCase): def setUp(self): super(VpnGatewayTestCase, self).setUp() self.DB_VPN_GATEWAY_2_ATTACHED = tools.update_dict( fakes.DB_VPN_GATEWAY_2, {'vpc_id': fakes.ID_EC2_VPC_2}) self.DB_VPN_GATEWAY_1_DETACHED = tools.update_dict( fakes.DB_VPN_GATEWAY_1, {'vpc_id': None}) def test_create_vpn_gateway(self): self.db_api.add_item.side_effect = ( tools.get_db_api_add_item(fakes.ID_EC2_VPN_GATEWAY_2)) resp = self.execute('CreateVpnGateway', {'Type': 'ipsec.1'}) self.assertEqual({'vpnGateway': fakes.EC2_VPN_GATEWAY_2}, resp) self.db_api.add_item.assert_called_once_with( mock.ANY, 'vgw', {}, project_id=None) def test_attach_vpn_gateway(self): self.set_mock_db_items(fakes.DB_VPN_GATEWAY_1, fakes.DB_VPN_GATEWAY_2, fakes.DB_VPC_2) resp = self.execute('AttachVpnGateway', {'VpcId': fakes.ID_EC2_VPC_2, 'VpnGatewayId': fakes.ID_EC2_VPN_GATEWAY_2}) self.assertEqual({'attachment': {'state': 'attached', 'vpcId': fakes.ID_EC2_VPC_2}}, resp) self.db_api.update_item.assert_called_once_with( mock.ANY, self.DB_VPN_GATEWAY_2_ATTACHED) def test_attach_vpn_gateway_idempotent(self): self.set_mock_db_items(fakes.DB_VPN_GATEWAY_1, fakes.DB_VPC_1) resp = self.execute('AttachVpnGateway', {'VpcId': fakes.ID_EC2_VPC_1, 'VpnGatewayId': fakes.ID_EC2_VPN_GATEWAY_1}) self.assertEqual({'attachment': {'state': 'attached', 'vpcId': fakes.ID_EC2_VPC_1}}, resp) self.assertFalse(self.db_api.update_item.called) def test_attach_vpn_gateway_invalid_parameters(self): def do_check(error_code): self.assert_execution_error( error_code, 'AttachVpnGateway', {'VpcId': fakes.ID_EC2_VPC_2, 'VpnGatewayId': fakes.ID_EC2_VPN_GATEWAY_2}) self.assertFalse(self.db_api.update_item.called) self.db_api.reset_mock() self.set_mock_db_items(fakes.DB_VPC_2) do_check('InvalidVpnGatewayID.NotFound') self.set_mock_db_items(fakes.DB_VPN_GATEWAY_2) do_check('InvalidVpcID.NotFound') self.set_mock_db_items( tools.update_dict(fakes.DB_VPN_GATEWAY_2, {'vpc_id': fakes.ID_EC2_VPC_1}), fakes.DB_VPC_2) do_check('VpnGatewayAttachmentLimitExceeded') self.set_mock_db_items( fakes.DB_VPN_GATEWAY_2, fakes.DB_VPC_2, tools.update_dict(fakes.DB_VPN_GATEWAY_1, {'vpc_id': fakes.ID_EC2_VPC_2})) do_check('InvalidVpcState') def test_detach_vpn_gateway(self): self.set_mock_db_items(fakes.DB_VPN_GATEWAY_1) resp = self.execute( 'DetachVpnGateway', {'VpcId': fakes.ID_EC2_VPC_1, 'VpnGatewayId': fakes.ID_EC2_VPN_GATEWAY_1}) self.assertEqual({'return': True}, resp) self.db_api.update_item.assert_called_once_with( mock.ANY, self.DB_VPN_GATEWAY_1_DETACHED) def test_detach_vpn_gateway_invalid_parameters(self): def do_check(error_code): self.assert_execution_error( error_code, 'DetachVpnGateway', {'VpcId': fakes.ID_EC2_VPC_1, 'VpnGatewayId': fakes.ID_EC2_VPN_GATEWAY_2}) self.assertEqual(0, self.neutron.remove_gateway_router.call_count) self.assertEqual(0, self.db_api.update_item.call_count) self.neutron.reset_mock() self.db_api.reset_mock() self.set_mock_db_items() do_check('InvalidVpnGatewayID.NotFound') self.set_mock_db_items(fakes.DB_VPN_GATEWAY_2) do_check('InvalidVpnGatewayAttachment.NotFound') self.set_mock_db_items(self.DB_VPN_GATEWAY_2_ATTACHED) do_check('InvalidVpnGatewayAttachment.NotFound') def test_delete_vpn_gateway(self): self.set_mock_db_items(fakes.DB_VPN_GATEWAY_2) resp = self.execute( 'DeleteVpnGateway', {'VpnGatewayId': fakes.ID_EC2_VPN_GATEWAY_2}) self.assertEqual({'return': True}, resp) self.db_api.delete_item.assert_called_once_with( mock.ANY, fakes.ID_EC2_VPN_GATEWAY_2) def test_delete_vpn_gateway_invalid_parameters(self): def do_check(error_code): self.assert_execution_error( error_code, 'DeleteVpnGateway', {'VpnGatewayId': fakes.ID_EC2_VPN_GATEWAY_1}) self.assertFalse(self.db_api.delete_item.called) self.db_api.reset_mock() self.set_mock_db_items() do_check('InvalidVpnGatewayID.NotFound') self.set_mock_db_items(fakes.DB_VPN_GATEWAY_1) do_check('IncorrectState') def test_describe_vpn_gateways(self): self.set_mock_db_items(fakes.DB_VPN_GATEWAY_1, fakes.DB_VPN_GATEWAY_2) resp = self.execute('DescribeVpnGateways', {}) self.assertThat(resp['vpnGatewaySet'], matchers.ListMatches([fakes.EC2_VPN_GATEWAY_1, fakes.EC2_VPN_GATEWAY_2])) resp = self.execute('DescribeVpnGateways', {'VpnGatewayId.1': fakes.ID_EC2_VPN_GATEWAY_2}) self.assertThat(resp['vpnGatewaySet'], matchers.ListMatches([fakes.EC2_VPN_GATEWAY_2])) self.db_api.get_items_by_ids.assert_called_once_with( mock.ANY, set([fakes.ID_EC2_VPN_GATEWAY_2])) self.check_filtering( 'DescribeVpnGateways', 'vpnGatewaySet', [('attachment.state', 'attached'), ('attachment.vpc-id', fakes.ID_EC2_VPC_1), ('state', 'available'), ('type', 'ipsec.1'), ('vpn-gateway-id', fakes.ID_EC2_VPN_GATEWAY_2)]) self.check_tag_support( 'DescribeVpnGateways', 'vpnGatewaySet', fakes.ID_EC2_VPN_GATEWAY_2, 'vpnGatewayId') ",,421,2
openstack%2Fec2-api~master~I7f14e9f19db513382b101050c8895079b3f5b249,openstack/ec2-api,master,I7f14e9f19db513382b101050c8895079b3f5b249,vpn (temporary),ABANDONED,2015-05-20 18:23:52.000000000,2015-05-21 18:26:10.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-20 18:23:52.000000000', 'files': ['ec2api/tests/unit/test_ec2utils.py', 'ec2api/api/cloud.py', 'ec2api/api/internet_gateway.py', 'ec2api/api/ec2utils.py', 'ec2api/api/route_table.py', 'ec2api/exception.py', 'ec2api/api/subnet.py', 'ec2api/api/common.py', 'ec2api/api/vpn_gateway.py', 'ec2api/api/vpnutils.py', 'ec2api/api/vpn_connection.py', 'ec2api/tests/unit/test_customer_gateway.py', 'ec2api/tests/unit/test_vpn_gateway.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/4a8fceec9fcb2353d420e43d3d8257e6260d1ec3', 'message': 'vpn (temporary)\n\nChange-Id: I7f14e9f19db513382b101050c8895079b3f5b249\n'}]",0,184573,4a8fceec9fcb2353d420e43d3d8257e6260d1ec3,3,1,1,10224,,,0,"vpn (temporary)

Change-Id: I7f14e9f19db513382b101050c8895079b3f5b249
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/73/184573/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/unit/test_ec2utils.py', 'ec2api/api/cloud.py', 'ec2api/api/internet_gateway.py', 'ec2api/api/ec2utils.py', 'ec2api/api/route_table.py', 'ec2api/exception.py', 'ec2api/api/subnet.py', 'ec2api/api/common.py', 'ec2api/api/vpn_gateway.py', 'ec2api/api/vpnutils.py', 'ec2api/api/vpn_connection.py', 'ec2api/tests/unit/test_customer_gateway.py', 'ec2api/tests/unit/test_vpn_gateway.py']",13,4a8fceec9fcb2353d420e43d3d8257e6260d1ec3,vpn, self.set_mock_db_items(self.DB_VPN_GATEWAY_1_DETACHED) do_check('IncorrectState') ,,689,16
openstack%2Fkeystone~master~I5832ec450e3fd89c9159c5ff333af7c100a5810c,openstack/keystone,master,I5832ec450e3fd89c9159c5ff333af7c100a5810c,Remove the deprecated compute_port option,MERGED,2015-05-15 06:38:14.000000000,2015-05-21 18:15:52.000000000,2015-05-21 18:15:50.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 7725}, {'_account_id': 8119}, {'_account_id': 8290}, {'_account_id': 8978}, {'_account_id': 16165}]","[{'number': 1, 'created': '2015-05-15 06:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2c67902c0d312fb22ce01ced9f4cf3bb05300396', 'message': 'Remove the deprecated compute_port option\n\nThe compute_port option has been marked deprecated and should be remove in\nLiberty, and it is useless now.\n\nChange-Id: I5832ec450e3fd89c9159c5ff333af7c100a5810c\nClose-Bug: #1455344\n'}, {'number': 2, 'created': '2015-05-18 01:41:09.000000000', 'files': ['keystone/common/config.py', 'keystone/catalog/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b5baf63e1adc2fb9dee6832e11c1180289e61860', 'message': 'Remove the deprecated compute_port option\n\nThe compute_port option has been marked deprecated and should be remove in\nLiberty, and it is useless now.\n\nChange-Id: I5832ec450e3fd89c9159c5ff333af7c100a5810c\nPartially implements: blueprint removed-as-of-liberty\n'}]",4,183405,b5baf63e1adc2fb9dee6832e11c1180289e61860,16,7,2,8290,,,0,"Remove the deprecated compute_port option

The compute_port option has been marked deprecated and should be remove in
Liberty, and it is useless now.

Change-Id: I5832ec450e3fd89c9159c5ff333af7c100a5810c
Partially implements: blueprint removed-as-of-liberty
",git fetch https://review.opendev.org/openstack/keystone refs/changes/05/183405/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/common/config.py', 'keystone/catalog/core.py']",3,2c67902c0d312fb22ce01ced9f4cf3bb05300396,bp/removed-as-of-liberty," 'compute_host', 'admin_port', 'public_port',"," 'compute_host', 'compute_port', 'admin_port', 'public_port',",1,16
openstack%2Fkeystone~master~Ib5d66f2d5ae9d29b7fcf4e194f2fcb7ad0b894db,openstack/keystone,master,Ib5d66f2d5ae9d29b7fcf4e194f2fcb7ad0b894db,basestring no longer exists in Python3,MERGED,2015-04-24 19:56:51.000000000,2015-05-21 18:15:43.000000000,2015-05-21 18:15:41.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8119}, {'_account_id': 9142}]","[{'number': 1, 'created': '2015-04-24 19:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1db2d22d66c130538079fc81ff097ead38b6c332', 'message': 'basestring no longer exists in Python3\n\nbp python3\n\nChange-Id: Ib5d66f2d5ae9d29b7fcf4e194f2fcb7ad0b894db\n'}, {'number': 2, 'created': '2015-04-25 00:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7a3365f99cf43be3ac0450dbbdefd294d9d03023', 'message': 'basestring no longer exists in Python3\n\nbp python3\n\nChange-Id: Ib5d66f2d5ae9d29b7fcf4e194f2fcb7ad0b894db\n'}, {'number': 3, 'created': '2015-04-29 20:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e9973b657dbff52e3934be13fc08edc8efb06b0a', 'message': 'basestring no longer exists in Python3\n\nbp python3\nChange-Id: Ib5d66f2d5ae9d29b7fcf4e194f2fcb7ad0b894db\n'}, {'number': 4, 'created': '2015-05-08 11:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/23b5331af80db41a20ad3b340ff3cb6c8f8225cc', 'message': 'basestring no longer exists in Python3\n\nbp python3\nChange-Id: Ib5d66f2d5ae9d29b7fcf4e194f2fcb7ad0b894db\n'}, {'number': 5, 'created': '2015-05-08 11:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/36905c641ed5e11c162e93aa661139edffbf0ea0', 'message': 'basestring no longer exists in Python3\n\nbp python3\nChange-Id: Ib5d66f2d5ae9d29b7fcf4e194f2fcb7ad0b894db\n'}, {'number': 6, 'created': '2015-05-21 16:34:12.000000000', 'files': ['keystone/tests/unit/token/test_provider.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/4490ec808ebe61a566eaf91f2b054f50a8413faa', 'message': 'basestring no longer exists in Python3\n\nbp python3\nChange-Id: Ib5d66f2d5ae9d29b7fcf4e194f2fcb7ad0b894db\n'}]",2,177418,4490ec808ebe61a566eaf91f2b054f50a8413faa,26,8,6,7725,,,0,"basestring no longer exists in Python3

bp python3
Change-Id: Ib5d66f2d5ae9d29b7fcf4e194f2fcb7ad0b894db
",git fetch https://review.opendev.org/openstack/keystone refs/changes/18/177418/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/token/test_provider.py'],1,1db2d22d66c130538079fc81ff097ead38b6c332,bp/python3,"import six self.assertTrue(isinstance(s, six.string_types))"," self.assertTrue(isinstance(s, basestring))",3,1
openstack%2Fkeystone~master~Iccebc56132c6dadaea4182e457b611f83d9a6da3,openstack/keystone,master,Iccebc56132c6dadaea4182e457b611f83d9a6da3,Add mocking for memcache for Python3 tests,MERGED,2015-04-24 19:56:51.000000000,2015-05-21 18:13:38.000000000,2015-05-21 18:13:36.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1941}, {'_account_id': 6486}, {'_account_id': 9142}]","[{'number': 1, 'created': '2015-04-24 19:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5131b0fd684681f38bffcc4f0a9cc00f7f0c37f1', 'message': ""Add mocking for memcache for Python3 tests\n\nmemcache currently doesn't work in Python3.\n\nbp python3\n\nChange-Id: Iccebc56132c6dadaea4182e457b611f83d9a6da3\n""}, {'number': 2, 'created': '2015-04-25 00:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6f62247dfe21d8857d8383654bd3688f986efc52', 'message': ""Add mocking for memcache for Python3 tests\n\nmemcache currently doesn't work in Python3.\n\nbp python3\n\nChange-Id: Iccebc56132c6dadaea4182e457b611f83d9a6da3\n""}, {'number': 3, 'created': '2015-04-29 20:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/203cb4ba561e5576875ef4a7cf3e3af9b670a56f', 'message': ""Add mocking for memcache for Python3 tests\n\nmemcache currently doesn't work in Python3.\n\nbp python3\n\nChange-Id: Iccebc56132c6dadaea4182e457b611f83d9a6da3\n""}, {'number': 4, 'created': '2015-05-08 11:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/03a958fcef07e7741c7a14c1403b090d2f674b79', 'message': ""Add mocking for memcache for Python3 tests\n\nmemcache currently doesn't work in Python3.\n\nbp python3\n\nChange-Id: Iccebc56132c6dadaea4182e457b611f83d9a6da3\n""}, {'number': 5, 'created': '2015-05-08 11:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7fcf8d15ca0c21f26a402575a099f8e7f4e30eac', 'message': ""Add mocking for memcache for Python3 tests\n\nmemcache currently doesn't work in Python3.\n\nbp python3\n\nChange-Id: Iccebc56132c6dadaea4182e457b611f83d9a6da3\n""}, {'number': 6, 'created': '2015-05-21 16:33:57.000000000', 'files': ['keystone/tests/unit/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9d3e8fd54c392f44420d6ffbfa94a66358019b8d', 'message': ""Add mocking for memcache for Python3 tests\n\nmemcache currently doesn't work in Python3.\n\nbp python3\n\nChange-Id: Iccebc56132c6dadaea4182e457b611f83d9a6da3\n""}]",0,177417,9d3e8fd54c392f44420d6ffbfa94a66358019b8d,27,5,6,7725,,,0,"Add mocking for memcache for Python3 tests

memcache currently doesn't work in Python3.

bp python3

Change-Id: Iccebc56132c6dadaea4182e457b611f83d9a6da3
",git fetch https://review.opendev.org/openstack/keystone refs/changes/17/177417/3 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/__init__.py'],1,5131b0fd684681f38bffcc4f0a9cc00f7f0c37f1,bp/python3, sys.modules['memcache'] = mock.Mock(),,1,0
openstack%2Fnova~master~I498e80aef9c05b125d396f40fcb0e6ae4bef8da6,openstack/nova,master,I498e80aef9c05b125d396f40fcb0e6ae4bef8da6,Merge V2 and V2.1 services functional tests,MERGED,2015-03-30 08:15:25.000000000,2015-05-21 18:10:05.000000000,2015-05-21 18:10:02.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15882}]","[{'number': 1, 'created': '2015-03-30 08:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f59dec40a9cdd0f1ff42a5bb1e712ec2aaabae55', 'message': 'Merge V2 and V2.1 services functional tests\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges services functional tests.\n\nIn V2 services API has following extensions\n- os-services\n- os-extended-services-delete\n- os-extended-services\n\nIn V2.1 above extensions have been merged together in services plugins\n\nChange-Id: I498e80aef9c05b125d396f40fcb0e6ae4bef8da6\n'}, {'number': 2, 'created': '2015-04-17 01:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/492a86efaebf851f93f84a7db882113927c0198d', 'message': 'Merge V2 and V2.1 services functional tests\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges services functional tests.\n\nIn V2 services API has following extensions\n- os-services\n- os-extended-services-delete\n- os-extended-services\n\nIn V2.1 above extensions have been merged together in services plugins\n\nChange-Id: I498e80aef9c05b125d396f40fcb0e6ae4bef8da6\n'}, {'number': 3, 'created': '2015-05-12 02:10:10.000000000', 'files': ['doc/api_samples/os-services/service-enable-put-resp.json', 'nova/tests/functional/api_samples/os-services/services-list-get-resp.json.tpl', 'doc/api_samples/os-services/service-disable-log-put-req.json', 'nova/tests/functional/test_api_samples.py', 'doc/api_samples/os-services/services-list-get-resp.json', 'nova/tests/functional/api_samples/os-services/service-enable-put-resp.json.tpl', 'nova/tests/functional/api_samples/os-extended-services-delete/services-get-resp.json.tpl', 'doc/api_samples/os-services/service-enable-put-req.json', 'nova/tests/functional/api_samples/os-services/service-disable-log-put-req.json.tpl', 'nova/tests/functional/api_samples/os-services/service-disable-put-req.json.tpl', 'doc/api_samples/os-services/service-disable-put-resp.json', 'doc/api_samples/os-services/service-disable-put-req.json', 'nova/tests/functional/api_samples/os-services/service-enable-put-req.json.tpl', 'doc/api_samples/os-extended-services-delete/services-get-resp.json', 'nova/tests/functional/api_samples/os-services/services-get-resp.json.tpl', 'nova/tests/functional/v3/test_services.py', 'doc/api_samples/os-services/service-disable-log-put-resp.json', 'doc/api_samples/os-services/services-get-resp.json', 'nova/tests/functional/api_samples/os-services/service-disable-put-resp.json.tpl', 'nova/tests/functional/api_samples/os-services/service-disable-log-put-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/3e1275c6fd5b0eff2ac3ca2c279159113b380c51', 'message': 'Merge V2 and V2.1 services functional tests\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges services functional tests.\n\nIn V2 services API has following extensions\n- os-services\n- os-extended-services-delete\n- os-extended-services\n\nIn V2.1 above extensions have been merged together in services plugins\n\nChange-Id: I498e80aef9c05b125d396f40fcb0e6ae4bef8da6\n'}]",0,168808,3e1275c6fd5b0eff2ac3ca2c279159113b380c51,37,12,3,8556,,,0,"Merge V2 and V2.1 services functional tests

Currently v2 and v2.1 have separate functional tests and their
corresponding sample files. As v2 and v2.1 are supposed to be identical,
there is overhead to maintain two set of functional tests and sample files.
We can have one set of tests which can run for both v2 and v2.1.

This commit merges services functional tests.

In V2 services API has following extensions
- os-services
- os-extended-services-delete
- os-extended-services

In V2.1 above extensions have been merged together in services plugins

Change-Id: I498e80aef9c05b125d396f40fcb0e6ae4bef8da6
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/168808/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/api_samples/os-services/service-enable-put-resp.json', 'nova/tests/functional/api_samples/os-services/services-list-get-resp.json.tpl', 'doc/api_samples/os-services/service-disable-log-put-req.json', 'nova/tests/functional/test_api_samples.py', 'doc/api_samples/os-services/services-list-get-resp.json', 'nova/tests/functional/api_samples/os-services/service-enable-put-resp.json.tpl', 'nova/tests/functional/api_samples/os-extended-services-delete/services-get-resp.json.tpl', 'doc/api_samples/os-services/service-enable-put-req.json', 'nova/tests/functional/api_samples/os-services/service-disable-log-put-req.json.tpl', 'nova/tests/functional/api_samples/os-services/service-disable-put-req.json.tpl', 'doc/api_samples/os-services/service-disable-put-resp.json', 'doc/api_samples/os-services/service-disable-put-req.json', 'nova/tests/functional/api_samples/os-services/service-enable-put-req.json.tpl', 'doc/api_samples/os-extended-services-delete/services-get-resp.json', 'nova/tests/functional/api_samples/os-services/services-get-resp.json.tpl', 'nova/tests/functional/v3/test_services.py', 'doc/api_samples/os-services/service-disable-log-put-resp.json', 'doc/api_samples/os-services/services-get-resp.json', 'nova/tests/functional/api_samples/os-services/service-disable-put-resp.json.tpl', 'nova/tests/functional/api_samples/os-services/service-disable-log-put-resp.json.tpl']",20,f59dec40a9cdd0f1ff42a5bb1e712ec2aaabae55,merge_sample_tests,,"{ ""service"": { ""binary"": ""%(binary)s"", ""host"": ""%(host)s"", ""disabled_reason"": ""%(disabled_reason)s"", ""status"": ""disabled"" } } ",21,437
openstack%2Fnova~master~I315b8430a92907d27534f7b4828c35792371d6dc,openstack/nova,master,I315b8430a92907d27534f7b4828c35792371d6dc,Ironic: Fix delete instance when spawning,MERGED,2015-05-14 09:57:43.000000000,2015-05-21 18:09:47.000000000,2015-05-21 18:09:44.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-14 09:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/72c080ce84320ca1e2be1950eb3e2adf394a57eb', 'message': 'Ironic: Fix felete instance when spawming\n\nNova allows issuein a ""nova delete"" command when the instance is being\nspawnmed, that wasn\'t working in Ironic because the spawn() in the Ironic\nnova driver doesn\'t return until the node have been deployed or error\nout and that causes Ironic to hold a lock that prevents the instance\ntermination to call destroy() in the Ironic nova driver.\n\nThis patch fixes that problem by making the loop waiting the node to\nget active (or error) in Ironic to also look at the instance task_state\nand see if it\'s being deleted. In case the instance is being deleted\nmid deployment operation we break the loop releasing the lock and then\ndestroy() gets called in Ironic aborting the deployment there.\n\nCloses-Bug: #1455000\nChange-Id: I315b8430a92907d27534f7b4828c35792371d6dc\n'}, {'number': 2, 'created': '2015-05-14 09:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b9d341dbe69f21356c4d745f0247742e970827c', 'message': 'Ironic: Fix delete instance when spawming\n\nNova allows issuein a ""nova delete"" command when the instance is being\nspawnmed, that wasn\'t working in Ironic because the spawn() in the Ironic\nnova driver doesn\'t return until the node have been deployed or error\nout and that causes Ironic to hold a lock that prevents the instance\ntermination to call destroy() in the Ironic nova driver.\n\nThis patch fixes that problem by making the loop waiting the node to\nget active (or error) in Ironic to also look at the instance task_state\nand see if it\'s being deleted. In case the instance is being deleted\nmid deployment operation we break the loop releasing the lock and then\ndestroy() gets called in Ironic aborting the deployment there.\n\nCloses-Bug: #1455000\nChange-Id: I315b8430a92907d27534f7b4828c35792371d6dc\n'}, {'number': 3, 'created': '2015-05-14 14:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3777b9f77810ebb1b0397c86b27cc29e053161c7', 'message': 'Ironic: Fix delete instance when spawming\n\nNova allows issuein a ""nova delete"" command when the instance is being\nspawnmed, that wasn\'t working in Ironic because the spawn() in the Ironic\nnova driver doesn\'t return until the node have been deployed or error\nout and that causes Ironic to hold a lock that prevents the instance\ntermination to call destroy() in the Ironic nova driver.\n\nThis patch fixes that problem by making the loop waiting the node to\nget active (or error) in Ironic to also look at the instance task_state\nand see if it\'s being deleted. In case the instance is being deleted\nmid deployment operation we break the loop releasing the lock and then\ndestroy() gets called in Ironic aborting the deployment there.\n\nCloses-Bug: #1455000\nChange-Id: I315b8430a92907d27534f7b4828c35792371d6dc\n'}, {'number': 4, 'created': '2015-05-14 15:39:31.000000000', 'files': ['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ea3967a1fb47297608defd680286fd9051ff5bbe', 'message': 'Ironic: Fix delete instance when spawning\n\nNova allows issuing a ""nova delete"" command when the instance is being\nspawned, that wasn\'t working in Ironic because the spawn() in the Ironic\nnova driver doesn\'t return until the node have been deployed or errored\nout and that causes Ironic to hold a lock that prevents the instance\ntermination to call destroy() in the Ironic nova driver.\n\nThis patch fixes that problem by making the loop waiting on the node to\nget active (or error) in Ironic to also look at the instance task_state\nand see if it\'s being deleted. In case the instance is being deleted\nmid deployment operation we break the loop releasing the lock and then\ndestroy() gets called in Ironic aborting the deployment there.\n\nCloses-Bug: #1455000\nChange-Id: I315b8430a92907d27534f7b4828c35792371d6dc\n'}]",19,182992,ea3967a1fb47297608defd680286fd9051ff5bbe,37,11,4,6773,,,0,"Ironic: Fix delete instance when spawning

Nova allows issuing a ""nova delete"" command when the instance is being
spawned, that wasn't working in Ironic because the spawn() in the Ironic
nova driver doesn't return until the node have been deployed or errored
out and that causes Ironic to hold a lock that prevents the instance
termination to call destroy() in the Ironic nova driver.

This patch fixes that problem by making the loop waiting on the node to
get active (or error) in Ironic to also look at the instance task_state
and see if it's being deleted. In case the instance is being deleted
mid deployment operation we break the loop releasing the lock and then
destroy() gets called in Ironic aborting the deployment there.

Closes-Bug: #1455000
Change-Id: I315b8430a92907d27534f7b4828c35792371d6dc
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/182992/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py']",2,72c080ce84320ca1e2be1950eb3e2adf394a57eb,bug/1455000," @mock.patch.object(objects.Instance, 'get_by_uuid') def test__wait_for_active_pass(self, fake_validate, fake_inst): fake_inst.return_value = instance self.driver._wait_for_active(self.ctx, FAKE_CLIENT, instance) fake_inst.assert_called_once_with(self.ctx, instance.uuid) fake_validate.assert_called_once_with(FAKE_CLIENT, instance) @mock.patch.object(objects.Instance, 'get_by_uuid') def test__wait_for_active_done(self, fake_validate, fake_inst): fake_inst.return_value = instance self.ctx, FAKE_CLIENT, instance) fake_inst.assert_called_once_with(self.ctx, instance.uuid) fake_validate.assert_called_once_with(FAKE_CLIENT, instance) @mock.patch.object(objects.Instance, 'get_by_uuid') def test__wait_for_active_fail(self, fake_validate, fake_inst): fake_inst.return_value = instance self.ctx, FAKE_CLIENT, instance) fake_inst.assert_called_once_with(self.ctx, instance.uuid) fake_validate.assert_called_once_with(FAKE_CLIENT, instance) @mock.patch.object(objects.Instance, 'get_by_uuid') @mock.patch.object(ironic_driver, '_validate_instance_and_node') def test__wait_for_active_abort(self, fake_validate, fake_inst): instance = fake_instance.fake_instance_obj(self.ctx, uuid=uuidutils.generate_uuid(), task_state=task_states.DELETING) fake_inst.return_value = instance self.assertRaises(exception.InstanceDeployFailure, self.driver._wait_for_active, self.ctx, FAKE_CLIENT, instance) fake_inst.assert_called_once_with(self.ctx, instance.uuid) # Assert _validate_instance_and_node wasn't called self.assertFalse(fake_validate.called) self.ctx, self.ctx,"," def test__wait_for_active_pass(self, fake_validate): self.driver._wait_for_active(FAKE_CLIENT, instance) self.assertTrue(fake_validate.called) def test__wait_for_active_done(self, fake_validate): FAKE_CLIENT, instance) self.assertTrue(fake_validate.called) def test__wait_for_active_fail(self, fake_validate): FAKE_CLIENT, instance) self.assertTrue(fake_validate.called)",43,10
openstack%2Fneutron-fwaas~master~I6775bae26edc928104143020f5678ab8b2801cfa,openstack/neutron-fwaas,master,I6775bae26edc928104143020f5678ab8b2801cfa,Add validation of port_range for firewall-rule,MERGED,2015-04-23 03:31:33.000000000,2015-05-21 18:00:39.000000000,2015-05-21 18:00:36.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 6995}, {'_account_id': 8645}, {'_account_id': 10119}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 11126}, {'_account_id': 11343}, {'_account_id': 12525}, {'_account_id': 12860}, {'_account_id': 13702}, {'_account_id': 15330}, {'_account_id': 15444}, {'_account_id': 16347}]","[{'number': 1, 'created': '2015-04-23 03:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/960179b963ae4ad7c1c8e8dc8bcf6468a7aad656', 'message': 'Add validation of port_range for firewall-rule\n\nThis commit validates the port_range of ""source_port"" and\n""destination_port"" in creating/updating firewall-rule.\n\nCloses-Bug: #1447435\nChange-Id: I6775bae26edc928104143020f5678ab8b2801cfa\n'}, {'number': 2, 'created': '2015-05-07 06:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/79f732c44f0d85a89bf9b0a3fafedcc6d5a81921', 'message': 'Add validation of port_range for firewall-rule\n\nThis commit validates the port_range of ""source_port"" and\n""destination_port"" in creating/updating firewall-rule.\nIt checks the relation between ""min_port"" and ""max_port"".\nThis validation checks following case:\n\n  ex. source_port = 10000:1024\n\nCloses-Bug: #1447435\nChange-Id: I6775bae26edc928104143020f5678ab8b2801cfa\n'}, {'number': 3, 'created': '2015-05-15 11:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/ce23b90e58b3c5a6d6fe6ecbb6012ee1aa567d78', 'message': 'Add validation of port_range for firewall-rule\n\nThis commit validates the port_range of ""source_port"" and\n""destination_port"" in creating/updating firewall-rule.\nIt checks the relation between ""min_port"" and ""max_port"".\nThis validation checks following case:\n\n  ex. source_port = 10000:1024\n\nCloses-Bug: #1447435\nChange-Id: I6775bae26edc928104143020f5678ab8b2801cfa\n'}, {'number': 4, 'created': '2015-05-18 20:28:13.000000000', 'files': ['neutron_fwaas/tests/unit/db/firewall/test_firewall_db.py', 'neutron_fwaas/extensions/firewall.py', 'neutron_fwaas/db/firewall/firewall_db.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/6d2885ca4ec656bd0fadc4e9cbf96cd845d6c351', 'message': 'Add validation of port_range for firewall-rule\n\nThis commit validates the port_range of ""source_port"" and\n""destination_port"" in creating/updating firewall-rule.\nIt checks the relation between ""min_port"" and ""max_port"".\nThis validation checks following case:\n\n  ex. source_port = 10000:1024\n\nCloses-Bug: #1447435\nChange-Id: I6775bae26edc928104143020f5678ab8b2801cfa\n'}]",8,176589,6d2885ca4ec656bd0fadc4e9cbf96cd845d6c351,52,16,4,13702,,,0,"Add validation of port_range for firewall-rule

This commit validates the port_range of ""source_port"" and
""destination_port"" in creating/updating firewall-rule.
It checks the relation between ""min_port"" and ""max_port"".
This validation checks following case:

  ex. source_port = 10000:1024

Closes-Bug: #1447435
Change-Id: I6775bae26edc928104143020f5678ab8b2801cfa
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/89/176589/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/tests/unit/db/firewall/test_firewall_db.py', 'neutron_fwaas/extensions/firewall.py', 'neutron_fwaas/db/firewall/firewall_db.py']",3,960179b963ae4ad7c1c8e8dc8bcf6468a7aad656,bug/1447435," if not min_port: max_port = min_port self._validate_fwr_port_range(min_port, max_port) self._validate_fwr_port_range(str(min_port), str(max_port)) return '%d:%d' % (min_port, max_port) def _validate_fwr_port_range(self, min_port, max_port): port_range = '%s:%s' % (min_port, max_port) if min_port > max_port: raise fw_ext.FirewallRuleInvalidPortValue(port=port_range) "," else: return '%d:%d' % (min_port, max_port)",31,3
openstack%2Fneutron~master~I222a9f44c5ed6c879feb2fb9e04047ae8f2c7745,openstack/neutron,master,I222a9f44c5ed6c879feb2fb9e04047ae8f2c7745,Adding loadbalanacerv2 device owner constant to neutron constants,MERGED,2015-05-21 09:12:38.000000000,2015-05-21 17:59:18.000000000,2015-05-21 17:59:16.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-05-21 09:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8670b63b2e46fc5458acf0ca5c573c700f810708', 'message': ""Adding loadbalanacerv2 device owner constant to neutron constants\n\nThe neutron constants doesn't have the contant for device owner\nlbaasv2. This fix adds the contant. This is needed for bug 1430394\nas we need to check the device owner when the port is to be deleted.\nPartial-Bug: #1430394\n\nChange-Id: I222a9f44c5ed6c879feb2fb9e04047ae8f2c7745\n""}, {'number': 2, 'created': '2015-05-21 09:15:33.000000000', 'files': ['neutron/common/constants.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/84fb6660a337e5e1f515b600ac8c22c6fdf82ec9', 'message': ""Adding loadbalanacerv2 device owner constant to neutron constants\n\nThe neutron constants doesn't have the constant for device owner\nlbaasv2. This fix adds the constant. This is needed for the bug 1430394\nas we need to check the device owner when the port is to be deleted.\nPartial-Bug: #1430394\n\nChange-Id: I222a9f44c5ed6c879feb2fb9e04047ae8f2c7745\n""}]",0,184744,84fb6660a337e5e1f515b600ac8c22c6fdf82ec9,35,23,2,15237,,,0,"Adding loadbalanacerv2 device owner constant to neutron constants

The neutron constants doesn't have the constant for device owner
lbaasv2. This fix adds the constant. This is needed for the bug 1430394
as we need to check the device owner when the port is to be deleted.
Partial-Bug: #1430394

Change-Id: I222a9f44c5ed6c879feb2fb9e04047ae8f2c7745
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/184744/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/common/constants.py'],1,8670b63b2e46fc5458acf0ca5c573c700f810708,bug/1430394,"DEVICE_OWNER_LOADBALANCERV2 = ""neutron:LOADBALANCERV2""",,1,0
openstack%2Ffuel-library~master~I8ff6388cdd785404ea3659584b20b9e977a1c253,openstack/fuel-library,master,I8ff6388cdd785404ea3659584b20b9e977a1c253,Set mnesia_table_loading_timeout to 10 seconds,MERGED,2015-05-21 02:07:30.000000000,2015-05-21 17:48:07.000000000,2015-05-21 17:47:26.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 13948}, {'_account_id': 14168}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-21 02:07:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/015af6b860cb72f4f782714be96f0305a4a8a076', 'message': 'Set mnesia_table_loading_timeout to 10 seconds\n\nThis commit sets mnesia_table_loading_timeout to\n10 seconds thus making rabbitmq cluster failover\nprocess faster. This option was initially suggested\nby Michael Klishin (RabbitMQ developer)\n\nChange-Id: I8ff6388cdd785404ea3659584b20b9e977a1c253\nRelated-bug: #1455761\nRelated-bug: #1432603\n'}, {'number': 2, 'created': '2015-05-21 02:37:36.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/rabbitmq/rabbitmq.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a2a146972dc63208280920ff1cf9321a6300171b', 'message': 'Set mnesia_table_loading_timeout to 10 seconds\n\nThis commit sets mnesia_table_loading_timeout to\n10 seconds thus making rabbitmq cluster failover\nprocess faster. This option was initially suggested\nby Michael Klishin (RabbitMQ developer)\n\nChange-Id: I8ff6388cdd785404ea3659584b20b9e977a1c253\nRelated-bug: #1455761\nRelated-bug: #1432603\n'}]",0,184674,a2a146972dc63208280920ff1cf9321a6300171b,43,7,2,8786,,,0,"Set mnesia_table_loading_timeout to 10 seconds

This commit sets mnesia_table_loading_timeout to
10 seconds thus making rabbitmq cluster failover
process faster. This option was initially suggested
by Michael Klishin (RabbitMQ developer)

Change-Id: I8ff6388cdd785404ea3659584b20b9e977a1c253
Related-bug: #1455761
Related-bug: #1432603
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/74/184674/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/rabbitmq/rabbitmq.pp'],1,015af6b860cb72f4f782714be96f0305a4a8a076,bug/1455761," $mnesia_table_loading_timeout = hiera('mnesia_table_loading_timeout', '10000') 'mnesia_table_loading_timeout' => $mnesia_table_loading_timeout,",,2,0
openstack%2Fopenstack-specs~master~I86042cc2ee15b841ba1c7bd093e483859bdce4b2,openstack/openstack-specs,master,I86042cc2ee15b841ba1c7bd093e483859bdce4b2,Managing stable branch requirements,ABANDONED,2015-03-04 00:45:37.000000000,2015-05-21 17:46:34.000000000,,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 24}, {'_account_id': 308}, {'_account_id': 935}, {'_account_id': 979}, {'_account_id': 1420}, {'_account_id': 1669}, {'_account_id': 1726}, {'_account_id': 1849}, {'_account_id': 1955}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 4190}, {'_account_id': 4257}, {'_account_id': 5263}, {'_account_id': 6159}, {'_account_id': 6609}, {'_account_id': 6786}, {'_account_id': 6969}, {'_account_id': 7069}, {'_account_id': 7680}, {'_account_id': 9453}, {'_account_id': 9656}, {'_account_id': 14288}]","[{'number': 1, 'created': '2015-03-04 00:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-specs/commit/8d3bb64bd9c89829b348298dbe0abc88d380ec5c', 'message': 'Managing stable branch requirements\n\nDocument and formalize the plans to change how we manage python\nrequirements.txt for stable branches.\n\nCo-authored-by: Joe Gordon <joe.gordon0@gmail.com>\n\nChange-Id: I86042cc2ee15b841ba1c7bd093e483859bdce4b2\n'}, {'number': 2, 'created': '2015-03-04 22:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-specs/commit/37ef6bf10da1ff77b319cb7343e5cf7f3815330c', 'message': 'Managing stable branch requirements\n\nDocument and formalize the plans to change how we manage python\nrequirements.txt for stable branches.\n\nCo-authored-by: Joe Gordon <joe.gordon0@gmail.com>\n\nChange-Id: I86042cc2ee15b841ba1c7bd093e483859bdce4b2\n'}, {'number': 3, 'created': '2015-03-10 20:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-specs/commit/1915c8d7d264e734a28af69061f7c6c3cf6c7041', 'message': 'Managing stable branch requirements\n\nDocument and formalize the plans to change how we manage python\nrequirements.txt for stable branches.\n\nCo-authored-by: Joe Gordon <joe.gordon0@gmail.com>\n\nChange-Id: I86042cc2ee15b841ba1c7bd093e483859bdce4b2\n'}, {'number': 4, 'created': '2015-03-12 18:00:39.000000000', 'files': ['specs/stable-requirements.rst'], 'web_link': 'https://opendev.org/openstack/openstack-specs/commit/0a87c1bbf3b327e6ca55a6072998de408fa5b5c9', 'message': 'Managing stable branch requirements\n\nDocument and formalize the plans to change how we manage python\nrequirements.txt for stable branches.\n\nCo-authored-by: Joe Gordon <joe.gordon0@gmail.com>\n\nChange-Id: I86042cc2ee15b841ba1c7bd093e483859bdce4b2\n'}]",47,161047,0a87c1bbf3b327e6ca55a6072998de408fa5b5c9,39,28,4,1420,,,0,"Managing stable branch requirements

Document and formalize the plans to change how we manage python
requirements.txt for stable branches.

Co-authored-by: Joe Gordon <joe.gordon0@gmail.com>

Change-Id: I86042cc2ee15b841ba1c7bd093e483859bdce4b2
",git fetch https://review.opendev.org/openstack/openstack-specs refs/changes/47/161047/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/stable-requirements.rst'],1,8d3bb64bd9c89829b348298dbe0abc88d380ec5c,stablebranches,".. This template should be in ReSTructured text. For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, build the docs using tox, or see: http://rst.ninjs.org The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/openstack/+spec/awesome-thing should be named specs/awesome-thing.rst. Wrap text at 79 columns. Do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None If you would like to provide a diagram with your spec, ascii diagrams are required. http://asciiflow.com/ is a very nice tool to assist with making ascii diagrams. The reason for this is that the tool used to review specs is based purely on plain text. Plain text will allow review to proceed without having to look at additional files which can not be viewed in gerrit. It will also allow inline feedback on the diagram itself. ========================================== Managing stable branch python requirements ========================================== https://blueprints.launchpad.net//+spec/example Make stable branches fail less by preventing stable branch python requirements from changing out from under us. Problem description =================== In the past we have had significant issues with stable branches breaking due to releases of new libraries. The first step to fix this was adding upper bounds on all stable/juno global requirements. But this isn't enough and stable branches can still break due to: * Releases of uncapped secondary dependencies * Required package versions being removed from pypi This blueprint aims to address the first issue, while the second point will remain an open issue. This also has the added benefit of helping ensure we test a known dependency set across a period of time. Proposed change =============== Don't change anything with requirements on master. For stable branches: * Leave ``requirements.txt`` (and ``test-requirements.txt``) as is. Allow these to be updated as required to specify any version constraints necessary during the maintanence period of the branch. * Add tooling to the ``openstack/requirements`` infrastructure to generate a ``requirements.gate`` and ``test-requirements.gate`` as part of the post-merge job that currently proposes requirement syncs to projects. In addition to updated ``requirements.txt`` and ``test-requirements.txt``, the bot-generated reviews will also include a ``requirements.gate`` and ``test-requirements.gate``, which are static snapshots of all dependencies at that time. Unlike ``requirements.txt`` this will include a list of all dependencies, including transitive, and use pinning (``foo==1.1.1``) * Project CI jobs (ie, devstack) that run on the requirements sync reviews will validate that the proposed static dependency set in ``requirements.gate``, as well as any changes to the main ``requirements.txt``, function as expected. If tests pass and the change merges, the repo's ``requirements.gate`` will be serve as a canonical list of dependencies that are known to work without conflict. This file will not change until a new requirement sync has been proposed by the bot as a result of a relevant top-level dependency changing in ``global-requirements.txt``. The ``requirements.gate`` file will serve as metadata used by upstream to help ensure we are testing a consistent set of dependencies over a period of time. We may choose to avoid shipping these files in release tarballs. Alternatives ------------ * Leave things as is, cap direct dependencies on stable branches and don't touch transitive dependencies. Implementation ============== * When changes are tested and merged to ``global-requirements.txt``, the bot submits a review containing a compiled ``requirements.gate`` and ``test-requirements.gate`` to projects, containing a list of pinned dependencies (top-level and transitive). These changes will be proposed in same reviews that are currently created when ``global-requirements.txt`` changes [1]. * CI jobs (specifically devstack) running will be adjusted to install the list of pinned dependencies from ``requirements.gate`` prior to installing project code. Installation of project code will remain unchanged, except for the fact that dependencies will already have been satisfied by those installed from ``requirements.gate``. [1] https://review.openstack.org/#/c/156376/ Assignee(s) ----------- Adam Gandelman (adam_g) Work Items ---------- * Update requirement tooling to compile a complete list of pinned dependencies for projects. pip-compile looks promising [1] * Update ``openstack/requirements`` infra to include these generated files as part of the automatic requirement sync patches proposed by the bot. * Update devstack to warm venvs with a pip installation of the ``requirements.gate`` dependencies prior to installing code. This behavior should probably be configurable. * Modify devstack jobs to archive a pip-freeze.txt for each service venv. [1] http://nvie.com/posts/better-package-management/ Dependencies ============ This depends on current work to isolate devstack deployed services into per-service virtualenvs. Without that, we risk the ``requirements.gate`` of two projects differing because they were generated at different times, and conflicts due to the strict pinning. History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Kilo - Introduced .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,151,0
openstack%2Ftaskflow~master~Iff45f386b5dc8efc3fe82ca3b1e961a0c23d7ac7,openstack/taskflow,master,Iff45f386b5dc8efc3fe82ca3b1e961a0c23d7ac7,Fix updated_at column of sqlalchemy tables,MERGED,2015-05-20 18:39:53.000000000,2015-05-21 17:46:21.000000000,2015-05-21 17:46:19.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 10584}, {'_account_id': 16459}]","[{'number': 1, 'created': '2015-05-20 18:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d1bc1718d66330c71f17455e0821627ce7c68ed4', 'message': 'Fix updated_at column of sqlalchemy tables\n\nThe column updated_at did not update after the refactoring made in\n687ec913790653f79badc8f5d656c86792e94271.\n\nChange-Id: Iff45f386b5dc8efc3fe82ca3b1e961a0c23d7ac7\n'}, {'number': 2, 'created': '2015-05-21 05:50:45.000000000', 'files': ['taskflow/persistence/backends/sqlalchemy/tables.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e183fc9dbc101d10491a8b04bb73cfb789b8826c', 'message': 'Fix updated_at column of sqlalchemy tables\n\nThe column updated_at does not update its value after the refactoring\nmade in 687ec913790653f79badc8f5d656c86792e94271.\n\nCloses-Bug: #1457309\nChange-Id: Iff45f386b5dc8efc3fe82ca3b1e961a0c23d7ac7\n'}]",0,184579,e183fc9dbc101d10491a8b04bb73cfb789b8826c,14,4,2,16459,,,0,"Fix updated_at column of sqlalchemy tables

The column updated_at does not update its value after the refactoring
made in 687ec913790653f79badc8f5d656c86792e94271.

Closes-Bug: #1457309
Change-Id: Iff45f386b5dc8efc3fe82ca3b1e961a0c23d7ac7
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/79/184579/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/persistence/backends/sqlalchemy/tables.py'],1,d1bc1718d66330c71f17455e0821627ce7c68ed4,bug/sqlalchemy-updated-field," onupdate=timeutils.utcnow), onupdate=timeutils.utcnow), onupdate=timeutils.utcnow),"," default=timeutils.utcnow), default=timeutils.utcnow), default=timeutils.utcnow),",3,3
openstack%2Fdevstack~master~I01e13e01a0bcd2cc2d6658d6b5966cd4956e2d8c,openstack/devstack,master,I01e13e01a0bcd2cc2d6658d6b5966cd4956e2d8c,Allow for pre-created Ironic libvirt VMs,ABANDONED,2014-12-03 02:10:58.000000000,2015-05-21 17:46:06.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-03 02:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d6e939e9a8afffb2c333d8ac381ba0e64a9dedee', 'message': 'Allow for pre-created Ironic libvirt VMs\n\nIf using the pxe_ssh driver, the only VMs that may be used for testing are\nthose auto-created locally by devstack.  This adds an additional option to\npass a file to devstack that contains required information for local or\nnon-local libvirt virtual machines to be enrolled and used with the pxe_ssh\ndriver.\n\nChange-Id: I01e13e01a0bcd2cc2d6658d6b5966cd4956e2d8c\n'}, {'number': 2, 'created': '2014-12-04 23:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d4813984e192817c9be673a78eed5372e3b0600b', 'message': 'Allow for pre-created Ironic libvirt VMs\n\nIf using the pxe_ssh driver, the only VMs that may be used for testing are\nthose auto-created locally by devstack.  This adds an additional option to\npass a file to devstack that contains required information for local or\nnon-local libvirt virtual machines to be enrolled and used with the pxe_ssh\ndriver.\n\nChange-Id: I01e13e01a0bcd2cc2d6658d6b5966cd4956e2d8c\n'}, {'number': 3, 'created': '2014-12-09 20:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1afb033bf6fe4572a94e1f86f7c5476daa696de9', 'message': 'Allow for pre-created Ironic libvirt VMs\n\nIf using the pxe_ssh driver, the only VMs that may be used for testing are\nthose auto-created locally by devstack.  This adds an additional option to\npass a file to devstack that contains required information for local or\nnon-local libvirt virtual machines to be enrolled and used with the pxe_ssh\ndriver.\n\nChange-Id: I01e13e01a0bcd2cc2d6658d6b5966cd4956e2d8c\n'}, {'number': 4, 'created': '2014-12-23 19:54:32.000000000', 'files': ['lib/ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b5f249ba8410c1e0a57c31a5572cf4bd10307dc7', 'message': 'Allow for pre-created Ironic libvirt VMs\n\nIf using the pxe_ssh driver, the only VMs that may be used for testing are\nthose auto-created locally by devstack.  This adds an additional option to\npass a file to devstack that contains required information for local or\nnon-local libvirt virtual machines to be enrolled and used with the pxe_ssh\ndriver.\n\nChange-Id: I01e13e01a0bcd2cc2d6658d6b5966cd4956e2d8c\n(cherry picked from commit 0f33061a8aa8e7e26485c509907580c682352eca)\n'}]",0,138606,b5f249ba8410c1e0a57c31a5572cf4bd10307dc7,17,3,4,1420,,,0,"Allow for pre-created Ironic libvirt VMs

If using the pxe_ssh driver, the only VMs that may be used for testing are
those auto-created locally by devstack.  This adds an additional option to
pass a file to devstack that contains required information for local or
non-local libvirt virtual machines to be enrolled and used with the pxe_ssh
driver.

Change-Id: I01e13e01a0bcd2cc2d6658d6b5966cd4956e2d8c
(cherry picked from commit 0f33061a8aa8e7e26485c509907580c682352eca)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/06/138606/4 && git format-patch -1 --stdout FETCH_HEAD,['lib/ironic'],1,d6e939e9a8afffb2c333d8ac381ba0e64a9dedee,multi,"# By default, devstack will create local libvirt VM domains to be used as # Ironic nodes. You may instead specify existing VMs and libvirt connection # information in a file using the following format: # mac_addr cpus memory(mb) disk(gb) ephemeral(gb) virt_type host_ip username, ie: # # 52:54:00:f8:67:95 1 512 11 1 virsh 10.0.0.247 22 adam # # Note that connections happen via SSH and $IRONIC_SSH_KEY_FILE is expected to # to be authorized on the remote host. IRONIC_VM_INFO_FILE=${IRONIC_VM_INFO_FILE:-$IRONIC_DATA_DIR/ironic_vms} # Create libvirt domains and network if required. If we have VM_INFO file, we can # assume these have setup already. if [[ ! -e ""$IRONIC_VM_INFO_FILE"" ]]; then # Call libvirt setup scripts in a new shell to ensure any new group membership sudo su $STACK_USER -c ""$IRONIC_SCRIPTS_DIR/setup-network"" if [[ ""$IRONIC_VM_LOG_CONSOLE"" == ""True"" ]] ; then local log_arg=""$IRONIC_VM_LOG_DIR"" else local log_arg="""" fi local vm_name for vm_name in $(_ironic_bm_vm_names); do sudo su $STACK_USER -c ""$IRONIC_SCRIPTS_DIR/create-node $vm_name \ $IRONIC_VM_SPECS_CPU $IRONIC_VM_SPECS_RAM $IRONIC_VM_SPECS_DISK \ amd64 $IRONIC_VM_NETWORK_BRIDGE $IRONIC_VM_EMULATOR \ $log_arg"" >> $IRONIC_VM_MACS_CSV_FILE done if [[ ""$IRONIC_DEPLOY_DRIVER"" =~ ""pxe"" ]] ; then if [[ -e $IRONIC_VM_MACS_CSV_FILE ]]; then local ironic_hwinfo_file=$IRONIC_VM_MACS_CSV_FILE elif [[ -e $IRONIC_VM_INFO_FILE ]]; then local ironic_hwinfo_file=$IRONIC_VM_INFO_FILE else die $LINENO ""No VM info file found at $IRONIC_VM_MACS_CSV_FILE or $IRONIC_VM_INFO_FILE"" fi if [[ ! -e $IRONIC_IPMIINFO_FILE ]]; then die $LINENO ""IPMI HW info file not found at $IRONIC_IPMIINFO_FILE"" fi if [[ ""$ironic_hwinfo_file"" == ""$IRONIC_VM_MACS_CSV_FILE"" ]]; then # The VMs to be enrolled were created on this node only and we # only need the generated mac addr. local mac_address=$hardware_info local ironic_node_cpu=$IRONIC_VM_SPECS_CPU local ironic_node_ram=$IRONIC_VM_SPECS_RAM local ironic_node_disk=$IRONIC_VM_SPECS_DISK local ironic_node_virt_type=$IRONIC_VM_SSH_VIRT_TYPE local ironic_node_virt_ssh_addr=$IRONIC_VM_SSH_ADDRESS local ironic_node_virt_ssh_port=$IRONIC_VM_SSH_PORT local ironic_node_virt_ssh_user=$IRONIC_VM_SSH_USERNAME local ironic_ephemeral_disk=$IRONIC_VM_EPHEMERAL_DISK else # We are feeding in a list of pre-created libvirt VMs, possibly # on other hosts. local mac_address=$(echo $hardware_info | awk '{print $1}') local ironic_node_cpu=$(echo $hardware_info | awk '{print $2}') local ironic_node_ram=$(echo $hardware_info | awk '{print $3}') local ironic_node_disk=$(echo $hardware_info | awk '{print $4}') local ironic_ephemeral_disk=$(echo $hardware_info | awk '{print $5}') local ironic_node_virt_type=$(echo $hardware_info | awk '{print $6}') local ironic_node_virt_ssh_addr=$(echo $hardware_info | awk '{print $7}') local ironic_node_virt_ssh_port=$(echo $hardware_info | awk '{print $8}') local ironic_node_virt_ssh_user=$(echo $hardware_info | awk '{print $9}') fi local node_options=""\ -i ssh_virt_type=$ironic_node_virt_type \ -i ssh_address=$ironic_node_virt_ssh_addr \ -i ssh_port=$ironic_node_virt_ssh_port \ -i ssh_username=$ironic_node_virt_ssh_user \ -i ssh_key_filename=$IRONIC_KEY_FILE"" local ironic_node_cpu=$IRONIC_HW_NODE_CPU local ironic_node_ram=$IRONIC_HW_NODE_RAM local ironic_node_disk=$IRONIC_HW_NODE_DISK local ironic_ephemeral_disk=$IRONIC_HW_EPHEMERAL_DISK local ipmi_address=$(echo $hardware_info |awk '{print $1}') local node_options=""\ -i ipmi_address=$ipmi_address \ -i ipmi_password=$ironic_ipmi_passwd \ # Append the appropriate required kernel/ramdisk node_options+="" -i $_IRONIC_DEPLOY_KERNEL_KEY=$IRONIC_DEPLOY_KERNEL_ID"" node_options+="" -i $_IRONIC_DEPLOY_RAMDISK_KEY=$IRONIC_DEPLOY_RAMDISK_ID"" -p cpus=$ironic_node_cpu \ -p memory_mb=$ironic_node_ram \ -p local_gb=$ironic_node_disk \"," # Call libvirt setup scripts in a new shell to ensure any new group membership sudo su $STACK_USER -c ""$IRONIC_SCRIPTS_DIR/setup-network"" if [[ ""$IRONIC_VM_LOG_CONSOLE"" == ""True"" ]] ; then local log_arg=""$IRONIC_VM_LOG_DIR"" else local log_arg="""" local vm_name for vm_name in $(_ironic_bm_vm_names); do sudo su $STACK_USER -c ""$IRONIC_SCRIPTS_DIR/create-node $vm_name \ $IRONIC_VM_SPECS_CPU $IRONIC_VM_SPECS_RAM $IRONIC_VM_SPECS_DISK \ amd64 $IRONIC_VM_NETWORK_BRIDGE $IRONIC_VM_EMULATOR \ $log_arg"" >> $IRONIC_VM_MACS_CSV_FILE done if [[ ""$IRONIC_DEPLOY_DRIVER"" == ""pxe_ssh"" ]] ; then local ironic_node_cpu=$IRONIC_VM_SPECS_CPU local ironic_node_ram=$IRONIC_VM_SPECS_RAM local ironic_node_disk=$IRONIC_VM_SPECS_DISK local ironic_ephemeral_disk=$IRONIC_VM_EPHEMERAL_DISK local ironic_hwinfo_file=$IRONIC_VM_MACS_CSV_FILE local node_options=""\ -i $_IRONIC_DEPLOY_KERNEL_KEY=$IRONIC_DEPLOY_KERNEL_ID \ -i $_IRONIC_DEPLOY_RAMDISK_KEY=$IRONIC_DEPLOY_RAMDISK_ID \ -i ssh_virt_type=$IRONIC_SSH_VIRT_TYPE \ -i ssh_address=$IRONIC_VM_SSH_ADDRESS \ -i ssh_port=$IRONIC_VM_SSH_PORT \ -i ssh_username=$IRONIC_SSH_USERNAME \ -i ssh_key_filename=$IRONIC_SSH_KEY_DIR/$IRONIC_SSH_KEY_FILENAME"" local ironic_node_cpu=$IRONIC_HW_NODE_CPU local ironic_node_ram=$IRONIC_HW_NODE_RAM local ironic_node_disk=$IRONIC_HW_NODE_DISK local ironic_ephemeral_disk=$IRONIC_HW_EPHEMERAL_DISK local mac_address=$hardware_info local ipmi_address=$(echo $hardware_info |awk '{print $1}') local node_options=""-i ipmi_address=$ipmi_address -i ipmi_password=$ironic_ipmi_passwd\ -p cpus=$ironic_node_cpu\ -p memory_mb=$ironic_node_ram\ -p local_gb=$ironic_node_disk\",87,38
openstack%2Fironic~master~I349400d313db2659e4ea84883def74c15e1f98c2,openstack/ironic,master,I349400d313db2659e4ea84883def74c15e1f98c2,Do not pass PXE net config from bootloader to ramdisk,ABANDONED,2015-02-03 14:35:26.000000000,2015-05-21 17:46:00.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-02-03 14:35:26.000000000', 'files': ['ironic/drivers/modules/elilo_efi_pxe_config.template', 'ironic/tests/test_pxe_utils.py', 'ironic/tests/drivers/pxe_config.template', 'ironic/drivers/modules/pxe_config.template', 'ironic/drivers/modules/ipxe_config.template'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c1e31a448cd0e0bf93fa8b5ec3e2c3d6bae009ec', 'message': ""Do not pass PXE net config from bootloader to ramdisk\n\nAll PXE templates currently pass network configuration from the\nbootloader to the ramdisk via a kernel parameter,\nip=$ip:$tftp-server:$gateway:$netmask. The current deploy-ironic\nramdisks built by DIB uses this to bring up networking manually,\nbut this behavior exists there for non-PXE deployments where DHCP\nis unavailable.  We ideally want ramdisks to use DHCP to allow pushing\nmore than just ip/gw/nm. This updates PXE templates to not pass net config,\nsince DHCP is assumed to be functioning for all PXE env.  Without the\nip= parameter, the ramdisk has no easy way to resolve the boot server's\naddress.  To signal where to callback to, a boot_server parameter has\nbeen added that points back to the TFTP server address.\n\nThis is a re-submit of a previously reverted patch.\n\nChange-Id: I349400d313db2659e4ea84883def74c15e1f98c2\nCloses-bug: 1401298\n""}]",1,152551,c1e31a448cd0e0bf93fa8b5ec3e2c3d6bae009ec,9,5,1,1420,,,0,"Do not pass PXE net config from bootloader to ramdisk

All PXE templates currently pass network configuration from the
bootloader to the ramdisk via a kernel parameter,
ip=$ip:$tftp-server:$gateway:$netmask. The current deploy-ironic
ramdisks built by DIB uses this to bring up networking manually,
but this behavior exists there for non-PXE deployments where DHCP
is unavailable.  We ideally want ramdisks to use DHCP to allow pushing
more than just ip/gw/nm. This updates PXE templates to not pass net config,
since DHCP is assumed to be functioning for all PXE env.  Without the
ip= parameter, the ramdisk has no easy way to resolve the boot server's
address.  To signal where to callback to, a boot_server parameter has
been added that points back to the TFTP server address.

This is a re-submit of a previously reverted patch.

Change-Id: I349400d313db2659e4ea84883def74c15e1f98c2
Closes-bug: 1401298
",git fetch https://review.opendev.org/openstack/ironic refs/changes/51/152551/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/elilo_efi_pxe_config.template', 'ironic/tests/test_pxe_utils.py', 'ironic/tests/drivers/pxe_config.template', 'ironic/drivers/modules/pxe_config.template', 'ironic/drivers/modules/ipxe_config.template']",5,c1e31a448cd0e0bf93fa8b5ec3e2c3d6bae009ec,bug/1401298,"kernel {{ pxe_options.deployment_aki_path }} selinux=0 disk={{ pxe_options.disk }} iscsi_target_iqn={{ pxe_options.iscsi_target_iqn }} deployment_id={{ pxe_options.deployment_id }} deployment_key={{ pxe_options.deployment_key }} ironic_api_url={{ pxe_options.ironic_api_url }} troubleshoot=0 boot_server={{ pxe_options.tftp_server }} text {{ pxe_options.pxe_append_params|default("""", true) }} BOOTIF=${mac} {% if pxe_options.root_device %}root_device={{ pxe_options.root_device }}{% endif %}","kernel {{ pxe_options.deployment_aki_path }} selinux=0 disk={{ pxe_options.disk }} iscsi_target_iqn={{ pxe_options.iscsi_target_iqn }} deployment_id={{ pxe_options.deployment_id }} deployment_key={{ pxe_options.deployment_key }} ironic_api_url={{ pxe_options.ironic_api_url }} troubleshoot=0 text {{ pxe_options.pxe_append_params|default("""", true) }} ip=${ip}:${next-server}:${gateway}:${netmask} BOOTIF=${mac} {% if pxe_options.root_device %}root_device={{ pxe_options.root_device }}{% endif %}",8,9
openstack%2Fqa-specs~master~If2f5822a9b427cca19f1d42de7becc93b709f826,openstack/qa-specs,master,If2f5822a9b427cca19f1d42de7becc93b709f826,Improve diskimage-builder in devstack,ABANDONED,2014-11-20 19:26:52.000000000,2015-05-21 17:45:39.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5196}]","[{'number': 1, 'created': '2014-11-20 19:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/d65632b97920df7b0e3e9aee1265cf6516698d1c', 'message': 'Improve diskimage-builder in devstack\n\nThis outlines various steps needed to improve how we install, use and\ntest diskimage-builder via devstack.\n\nChange-Id: If2f5822a9b427cca19f1d42de7becc93b709f826\n'}, {'number': 2, 'created': '2014-11-20 20:28:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/7c57dd19f1bfce9388cf9867da51f5e8556eab3c', 'message': 'Improve diskimage-builder in devstack\n\nThis outlines various steps needed to improve how we install, use and\ntest diskimage-builder via devstack.\n\nChange-Id: If2f5822a9b427cca19f1d42de7becc93b709f826\n'}, {'number': 3, 'created': '2014-11-25 23:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/5c46ca5fbe3c205b427b0e5dfc48b6a393d48d09', 'message': 'Improve diskimage-builder in devstack\n\nThis outlines various steps needed to improve how we install, use and\ntest diskimage-builder via devstack.\n\nPart of blueprint:dib-devstack\n\nChange-Id: If2f5822a9b427cca19f1d42de7becc93b709f826\n'}, {'number': 4, 'created': '2014-11-26 22:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/01a902e4f4fde0d682955b22b02507caa4508e99', 'message': 'Improve diskimage-builder in devstack\n\nThis outlines various steps needed to improve how we install, use and\ntest diskimage-builder via devstack.\n\nPart of blueprint:dib-devstack\n\nChange-Id: If2f5822a9b427cca19f1d42de7becc93b709f826\n'}, {'number': 5, 'created': '2014-11-26 22:23:20.000000000', 'files': ['doc/source/index.rst', 'specs/devstack/dib-devstack.rst'], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/d3071eb06d0780faf109cb80dffd15775c6621ae', 'message': 'Improve diskimage-builder in devstack\n\nThis outlines various steps needed to improve how we install, use and\ntest diskimage-builder via devstack.\n\nPart of blueprint:dib-devstack\n\nChange-Id: If2f5822a9b427cca19f1d42de7becc93b709f826\n'}]",2,136101,d3071eb06d0780faf109cb80dffd15775c6621ae,10,4,5,1420,,,0,"Improve diskimage-builder in devstack

This outlines various steps needed to improve how we install, use and
test diskimage-builder via devstack.

Part of blueprint:dib-devstack

Change-Id: If2f5822a9b427cca19f1d42de7becc93b709f826
",git fetch https://review.opendev.org/openstack/qa-specs refs/changes/01/136101/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/dib-devstack.rst'],1,d65632b97920df7b0e3e9aee1265cf6516698d1c,136101,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/tempest/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ============================= Improve diskimage-builder in devstack ============================= This aims to improve how diskimage-builder (DIB) is installed, used and tested in devstack. Problem description =================== Originally, the only consumers of DIB in devstack were lib/baremetal and lib/ironic. Both used it to build a deployment kernel and ramdisk pair. Each library installed DIB itself, from either tip of trunk or (trunk + gerrit patch). This allowed Ironic to run its devstack job against patches to DIB and test that proposed code does not break deployment ramdisk builds. At some point, all DIB installation in devstack migrated to installing directly from pip and never from git, losing the ability to test proposed DIB patches. We ideally want to be able to toggle running DIB from release, master, or proposed patch depending on where the job is running in the same way we do for client libraries and oslo. Heat's devstack integration began relying on DIB, but rather than managing it in lib/heat, new lib/dib library was added that manages DIB as a first class service. This centralizes all DIB related things and Ironic and other DIB consumers should rely on it. This would let us more easily control the execution environment of DIB and allow us to point it at local caches and package mirrors for use during image build (they currently hit the distant internet for python and distro packages). Proposed change =============== * Update devstack to manage repositories for DIB and related components via GITREPO/GITBRANCH and add logic to lib/dib's install_dib() to install from pip or git depending on configuration, similar to oslo. * Add functionality to lib/dib to build ramdisks. * Update lib/ironic + lib/baremetal to rely on lib/dib for all things DIB. This would make enabling the 'dib' service a hard requirement to use either. * Update devstack-gate's features.yaml to enable the dib service for projects that require it in their devstack job (ironic). Alternatives ------------ * Stop treating DIB as a service and instead move its functionality elsewhere, ./tools/dib/functions-dib? We would then be burying install time logic deeper into the tree. I'd prefer to keep it as a top-level thing. Implementation ============== https://review.openstack.org/#/q/status:open+topic:dib_devstack,n,z Assignee(s) ----------- Primary assignee: Adam Gandelman (adam_g) Can optionally can list additional ids if they intend on doing substantial implementation work on this blueprint. Milestones ---------- Target Milestone for completion: Juno-1 Work Items ---------- Dependencies ============ ",,90,0
openstack%2Fdevstack~master~I7fe75b0bd7e990baf5133a9ee975eb1641d31c86,openstack/devstack,master,I7fe75b0bd7e990baf5133a9ee975eb1641d31c86,Spawn console log monitors for Ironic VM nodes,ABANDONED,2014-10-17 00:43:50.000000000,2015-05-21 17:45:34.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 7118}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-17 00:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/74a3262f8a1518d459306f3d5266b3174c58d52a', 'message': 'Spawn console log monitors for Ironic VM nodes\n\nWe log the libvirt console output of each ironic VM node, however,\nthese logs are truncated with every power cycle.  This makes it\nimpossible to debug provisioning issues during tempest runs unless\nthe failure happens to occur on the last test that was run on a\nspecific node.  This change creates background monitors, either in\nscreen or via a directly forked process, to monitor the ephemeral logs\nand capture all of the output generated by node VMs.\n\nChange-Id: I7fe75b0bd7e990baf5133a9ee975eb1641d31c86\n'}, {'number': 2, 'created': '2014-10-17 17:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/cf2751ec3fc5f832f801f34ab4c8e67326182eba', 'message': 'Spawn console log monitors for Ironic VM nodes\n\nWe log the libvirt console output of each ironic VM node, however,\nthese logs are truncated with every power cycle.  This makes it\nimpossible to debug provisioning issues during tempest runs unless\nthe failure happens to occur on the last test that was run on a\nspecific node.  This change creates background monitors, either in\nscreen or via a directly forked process, to monitor the ephemeral logs\nand capture all of the output generated by node VMs.\n\nChange-Id: I7fe75b0bd7e990baf5133a9ee975eb1641d31c86\n'}, {'number': 3, 'created': '2014-10-20 20:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/65f839ca55bea4bfa5cd18f669c06078805159fe', 'message': 'Spawn console log monitors for Ironic VM nodes\n\nWe log the libvirt console output of each ironic VM node, however,\nthese logs are truncated with every power cycle.  This makes it\nimpossible to debug provisioning issues during tempest runs unless\nthe failure happens to occur on the last test that was run on a\nspecific node.  This change creates background monitors, either in\nscreen or via a directly forked process, to monitor the ephemeral logs\nand capture all of the output generated by node VMs.\n\nChange-Id: I7fe75b0bd7e990baf5133a9ee975eb1641d31c86\n'}, {'number': 4, 'created': '2014-10-20 20:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/702b15178663e72744d3ebfec659cbeb9af04fe9', 'message': 'Spawn console log monitors for Ironic VM nodes\n\nWe log the libvirt console output of each ironic VM node, however,\nthese logs are truncated with every power cycle.  This makes it\nimpossible to debug provisioning issues during tempest runs unless\nthe failure happens to occur on the last test that was run on a\nspecific node.  This change creates background monitors, either in\nscreen or via a directly forked process, to monitor the ephemeral logs\nand capture all of the output generated by node VMs.\n\nChange-Id: I7fe75b0bd7e990baf5133a9ee975eb1641d31c86\n'}, {'number': 5, 'created': '2014-10-21 21:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b761b0d807d73c601c733853a485c42ef106548c', 'message': 'Spawn console log monitors for Ironic VM nodes\n\nWe log the libvirt console output of each ironic VM node, however,\nthese logs are truncated with every power cycle.  This makes it\nimpossible to debug provisioning issues during tempest runs unless\nthe failure happens to occur on the last test that was run on a\nspecific node.  This change creates background monitors, either in\nscreen or via a directly forked process, to monitor the ephemeral logs\nand capture all of the output generated by node VMs.\n\nChange-Id: I7fe75b0bd7e990baf5133a9ee975eb1641d31c86\n'}, {'number': 6, 'created': '2014-11-25 02:09:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0a283ab421e786b6fe68b3ef7d163af216eac4af', 'message': ""Spawn console log monitors for Ironic VM nodes\n\nWe log the libvirt console output of each ironic VM node, however,\nthese logs are truncated with every power cycle.  This makes it\nimpossible to debug provisioning issues during tempest runs unless\nthe failure happens to occur on the last test that was run on a\nspecific node.  This change creates background monitors, either in\nscreen or via a directly forked process, to monitor the ephemeral logs\nand capture all of the output generated by node VMs.  To make this easier,\nthe 'internal' _run_process() is renamed to bg_process() and used from\nlib/ironic.\n\nChange-Id: I7fe75b0bd7e990baf5133a9ee975eb1641d31c86\n""}, {'number': 7, 'created': '2014-12-16 02:07:31.000000000', 'files': ['lib/ironic', 'tools/ironic/scripts/ironic-vm-console-monitor', 'functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/86d9ba51c5476c52396fe35c77ad533e5343458d', 'message': ""Spawn console log monitors for Ironic VM nodes\n\nWe log the libvirt console output of each ironic VM node, however,\nthese logs are truncated with every power cycle.  This makes it\nimpossible to debug provisioning issues during tempest runs unless\nthe failure happens to occur on the last test that was run on a\nspecific node.  This change creates background monitors, either in\nscreen or via a directly forked process, to monitor the ephemeral logs\nand capture all of the output generated by node VMs.  To make this easier,\nthe 'internal' _run_process() is renamed to bg_process() and used from\nlib/ironic.\n\nChange-Id: I7fe75b0bd7e990baf5133a9ee975eb1641d31c86\n""}]",1,129099,86d9ba51c5476c52396fe35c77ad533e5343458d,31,5,7,1420,,,0,"Spawn console log monitors for Ironic VM nodes

We log the libvirt console output of each ironic VM node, however,
these logs are truncated with every power cycle.  This makes it
impossible to debug provisioning issues during tempest runs unless
the failure happens to occur on the last test that was run on a
specific node.  This change creates background monitors, either in
screen or via a directly forked process, to monitor the ephemeral logs
and capture all of the output generated by node VMs.  To make this easier,
the 'internal' _run_process() is renamed to bg_process() and used from
lib/ironic.

Change-Id: I7fe75b0bd7e990baf5133a9ee975eb1641d31c86
",git fetch https://review.opendev.org/openstack/devstack refs/changes/99/129099/5 && git format-patch -1 --stdout FETCH_HEAD,['lib/ironic'],1,74a3262f8a1518d459306f3d5266b3174c58d52a,ironic_monitor_vm_logs,"# start_bm_vm_console_monitors() - Spawn screen windows or background processes to monitor # baremetal VM console logs, which are truncated after every power cycle. function start_bm_vm_console_monitors { local vm_name for vm_name in $(_ironic_bm_vm_names); do local console_log_file=""$IRONIC_VM_LOG_DIR/${vm_name}_console.log"" local cmd=""while [ ! -f $console_log_file ]; do sleep 1; done; sudo tail -f $console_log_file"" local win_name=""ir-vm-$(echo $vm_name | cut -d_ -f2)"" if [[ ""$USE_SCREEN"" == ""True"" ]]; then screen_process $win_name ""$cmd"" else bash -c ""$cmd"" >> $IRONIC_VM_LOG_DIR/${vm_name}_console_monitor.log & fi done } if [[ ""$IRONIC_VM_LOG_CONSOLE"" == ""True"" ]] ; then start_bm_vm_console_monitors"," if [[ ""IRONIC_VM_LOG_CONSOLE"" == ""True"" ]] ; then start_bm_vm_log_monitor",18,2
openstack%2Fdevstack~master~Iac384096cc98a8ba29b1df67deaf110f3dd4f434,openstack/devstack,master,Iac384096cc98a8ba29b1df67deaf110f3dd4f434,Install DIB from release or master,ABANDONED,2014-10-08 23:18:35.000000000,2015-05-21 17:45:29.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 9009}, {'_account_id': 10385}, {'_account_id': 12487}]","[{'number': 1, 'created': '2014-10-08 23:18:35.000000000', 'files': ['lib/heat', 'lib/dib', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a4b2167f63d2124c83896d0e67d67730f98fa543', 'message': 'Install DIB from release or master\n\nThis sets up diskimage-builder and friends to be installed from release\nor master depending on their presence in LIBS_FROM_MASTER.  It will allow\npre-commit testing in the CI pipelines of those projects and any others\nthat wish to co-gate with them.\n\nChange-Id: Iac384096cc98a8ba29b1df67deaf110f3dd4f434\n'}]",1,127072,a4b2167f63d2124c83896d0e67d67730f98fa543,11,7,1,1420,,,0,"Install DIB from release or master

This sets up diskimage-builder and friends to be installed from release
or master depending on their presence in LIBS_FROM_MASTER.  It will allow
pre-commit testing in the CI pipelines of those projects and any others
that wish to co-gate with them.

Change-Id: Iac384096cc98a8ba29b1df67deaf110f3dd4f434
",git fetch https://review.opendev.org/openstack/devstack refs/changes/72/127072/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/heat', 'lib/dib', 'stackrc']",3,a4b2167f63d2124c83896d0e67d67730f98fa543,dib_devstack,"GITREPO[""diskimage-builder""]=${DIB_REPO:-${GIT_BASE}/openstack/diskimage-builder.git} GITBRANCH[""diskimage-builder""]=${DIB_BRANCH:-master}GITREPO[""os-apply-config""]=${OAC_REPO:-${GIT_BASE}/openstack/os-apply-config.git} GITBRANCH[""os-apply-config""]=${OAC_BRANCH:-master}GITREPO[""os-collect-config""]=${OCC_REPO:-${GIT_BASE}/openstack/os-collect-config.git} GITBRANCH[""os-collect-config""]=${OCC_BRANCH:-master}GITREPO[""os-refresh-config""]=${ORC_REPO:-${GIT_BASE}/openstack/os-collect-config.git} GITBRANCH[""os-refresh-config""]=${ORC_BRANCH:-master}GITREPO[""tripleo-image-elements""]=${TIE_REPO:-${GIT_BASE}/openstack/tripleo-image-elements.git} GITBRANCH[""tripleo-image-elements""]=${TIE_BRANCH:-master}",DIB_REPO=${DIB_REPO:-${GIT_BASE}/openstack/diskimage-builder.git} DIB_BRANCH=${DIB_BRANCH:-master}OAC_REPO=${OAC_REPO:-${GIT_BASE}/openstack/os-apply-config.git} OAC_BRANCH=${OAC_BRANCH:-master}OCC_REPO=${OCC_REPO:-${GIT_BASE}/openstack/os-collect-config.git} OCC_BRANCH=${OCC_BRANCH:-master}ORC_REPO=${ORC_REPO:-${GIT_BASE}/openstack/os-refresh-config.git} ORC_BRANCH=${ORC_BRANCH:-master}TIE_REPO=${TIE_REPO:-${GIT_BASE}/openstack/tripleo-image-elements.git} TIE_BRANCH=${TIE_BRANCH:-master},24,22
openstack%2Fdevstack~master~Idfbcc89375f5c84fae18b31027cda44ba76e0e2d,openstack/devstack,master,Idfbcc89375f5c84fae18b31027cda44ba76e0e2d,Use dib service to build Ironic pxe_ssh deploy ramdisk,ABANDONED,2014-10-02 00:08:09.000000000,2015-05-21 17:45:09.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-02 00:08:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f34c021f0f87ddf350feb1506b4dfc1096fb1992', 'message': ""Use dib service to build Ironic pxe_ssh deploy ramdisk\n\nRely on the the DIB service's functionality for building the Ironic\npxe_ssh ramdisk. This removes fragmentation and allows the DIB environment\nto be configured and managed in a single place.\n\nIn addition to calling ramdisk_image_create, this moves validation of required\nservices to earlier in exection and adds a check for the dib service being\nenabled.\n\nChange-Id: Idfbcc89375f5c84fae18b31027cda44ba76e0e2d\nPartial-bug: #1375488\n""}, {'number': 2, 'created': '2014-10-08 23:18:35.000000000', 'files': ['lib/ironic', 'extras.d/50-ironic.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/dbde4a9c6cbd8ad8ee9e2daeb4888d9d89fd69cd', 'message': ""Use dib service to build Ironic pxe_ssh deploy ramdisk\n\nRely on the the DIB service's functionality for building the Ironic\npxe_ssh ramdisk. This removes fragmentation and allows the DIB environment\nto be configured and managed in a single place.\n\nIn addition to calling ramdisk_image_create, this moves validation of required\nservices to earlier in execution and adds a check for the dib service being\nenabled.\n\nChange-Id: Idfbcc89375f5c84fae18b31027cda44ba76e0e2d\nPartial-bug: #1375488\n""}]",0,125524,dbde4a9c6cbd8ad8ee9e2daeb4888d9d89fd69cd,16,6,2,1420,,,0,"Use dib service to build Ironic pxe_ssh deploy ramdisk

Rely on the the DIB service's functionality for building the Ironic
pxe_ssh ramdisk. This removes fragmentation and allows the DIB environment
to be configured and managed in a single place.

In addition to calling ramdisk_image_create, this moves validation of required
services to earlier in execution and adds a check for the dib service being
enabled.

Change-Id: Idfbcc89375f5c84fae18b31027cda44ba76e0e2d
Partial-bug: #1375488
",git fetch https://review.opendev.org/openstack/devstack refs/changes/24/125524/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ironic', 'extras.d/50-ironic.sh']",2,f34c021f0f87ddf350feb1506b4dfc1096fb1992,dib_devstack," # make sure all needed service were enabled for srv in nova glance key; do if ! is_service_enabled ""$srv""; then die $LINENO ""$srv should be enabled for Ironic."" fi done if [ ""$IRONIC_BUILD_DEPLOY_RAMDISK"" == ""True"" ] && [ ""$IRONIC_DEPLOY_DRIVER"" == ""pxe_ssh"" ] ; then if ! is_service_enabled dib ; then die $LINENO ""dib should be enabled for building Ironic's pxe_ssh ramdisk."" fi fi",,12,13
openstack%2Fkeystone~master~If01a93a18cef6159adad50496e6335e88f86024d,openstack/keystone,master,If01a93a18cef6159adad50496e6335e88f86024d,Fix xmldsig import,MERGED,2015-05-20 09:33:31.000000000,2015-05-21 17:44:56.000000000,2015-05-21 17:44:53.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 2218}, {'_account_id': 6482}, {'_account_id': 8978}, {'_account_id': 11491}, {'_account_id': 13294}]","[{'number': 1, 'created': '2015-05-20 09:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9908bdf9a6a7a47cb2ae48eb8a61fe033702ded0', 'message': 'Fix xmldsig import\n\nFollowing pysaml2 commit 9af3252035484f4a8c624eba0f35b68280d43fd2 ,\nxmldsig was moved under saml2, no longer being at the top level.\nUpdating import accordingly.\n\nChange-Id: If01a93a18cef6159adad50496e6335e88f86024d\n'}, {'number': 2, 'created': '2015-05-20 11:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c2b075897026f7e720a4650f9826a1b81f4c3e22', 'message': 'Fix xmldsig import\n\nFollowing pysaml2 commit 9af3252035484f4a8c624eba0f35b68280d43fd2 ,\nxmldsig was moved under saml2, no longer being at the top level.\nCraeting a conditional import, so it can work now and when the\npysaml2 commit is included in a new release.\n\nChange-Id: If01a93a18cef6159adad50496e6335e88f86024d\n'}, {'number': 3, 'created': '2015-05-20 13:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/71903b78d6b57877c32319335f7aef87332585e9', 'message': 'Fix xmldsig import\n\nAfter commit https://goo.gl/TjLQFz to pysaml2, xmldsig was moved\nunder saml2, no longer being at the top level. Craeting a\nconditional import, so it can work now and when the pysaml2\ncommit is included in a new release.\n\nChange-Id: If01a93a18cef6159adad50496e6335e88f86024d\n'}, {'number': 4, 'created': '2015-05-21 08:23:07.000000000', 'files': ['keystone/tests/unit/test_v3_federation.py', 'keystone/contrib/federation/idp.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c90dd3a0f8280e28bbbff691c0ae27aff736658a', 'message': 'Fix xmldsig import\n\nAfter commit https://goo.gl/TjLQFz to pysaml2, xmldsig was moved\nunder saml2, no longer being at the top level. Craeting a\nconditional import, so it can work now and when the pysaml2\ncommit is included in a new release.\n\nChange-Id: If01a93a18cef6159adad50496e6335e88f86024d\n'}]",1,184445,c90dd3a0f8280e28bbbff691c0ae27aff736658a,19,7,4,13294,,,0,"Fix xmldsig import

After commit https://goo.gl/TjLQFz to pysaml2, xmldsig was moved
under saml2, no longer being at the top level. Craeting a
conditional import, so it can work now and when the pysaml2
commit is included in a new release.

Change-Id: If01a93a18cef6159adad50496e6335e88f86024d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/45/184445/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_v3_federation.py', 'keystone/contrib/federation/idp.py']",2,9908bdf9a6a7a47cb2ae48eb8a61fe033702ded0,jpena/saml2changes,from saml2 import xmldsig,import xmldsig,2,2
openstack%2Fironic~master~Ifbb75612ae0bca9ec3486859314f5e37d281f74b,openstack/ironic,master,Ifbb75612ae0bca9ec3486859314f5e37d281f74b,Update to hacking 0.10.x,MERGED,2015-05-20 07:00:22.000000000,2015-05-21 17:44:46.000000000,2015-05-21 17:44:45.000000000,"[{'_account_id': 3}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 9751}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 15524}]","[{'number': 1, 'created': '2015-05-20 07:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1f95c7e2efe065b1ead28616c3ebd1aab8d31b54', 'message': 'Update to hacking 0.10.x\n\nUpdate to current hacking. This change needs to be manually imported\nfrom the global requirements repository.\n\nChange-Id: Ifbb75612ae0bca9ec3486859314f5e37d281f74b\n'}, {'number': 2, 'created': '2015-05-21 06:07:21.000000000', 'files': ['test-requirements.txt', 'test-requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c009f51c42a8c7e511d005b007d7fad0d7b5f73a', 'message': 'Update to hacking 0.10.x\n\nUpdate to current hacking. This change needs to be manually imported\nfrom the global requirements repository.\n\nChange-Id: Ifbb75612ae0bca9ec3486859314f5e37d281f74b\n'}]",0,184421,c009f51c42a8c7e511d005b007d7fad0d7b5f73a,19,7,2,6547,,,0,"Update to hacking 0.10.x

Update to current hacking. This change needs to be manually imported
from the global requirements repository.

Change-Id: Ifbb75612ae0bca9ec3486859314f5e37d281f74b
",git fetch https://review.opendev.org/openstack/ironic refs/changes/21/184421/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'test-requirements-py3.txt']",2,1f95c7e2efe065b1ead28616c3ebd1aab8d31b54,update-hacking,"hacking>=0.10.0,<0.11","hacking>=0.9.2,<0.10",2,2
openstack%2Fneutron~stable%2Fjuno~I729753c15c51c86655651b132fcf8eab78884eb5,openstack/neutron,stable/juno,I729753c15c51c86655651b132fcf8eab78884eb5,Fixes Hyper-V agent port disconnect issue,MERGED,2015-03-04 15:35:41.000000000,2015-05-21 17:44:34.000000000,2015-05-21 17:44:33.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1420}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-03-04 15:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bfd3d11a7ab4bb5abd2bb0f8cb1b0c85a549ebdf', 'message': ""Fixes Hyper-V agent port disconnect issue\n\nOn Windows / Hyper-V Server 2008 R2, when a switch port\nhave to be disconnected because the VM using it was\nremoved, DisconnectSwitchPort will fail, returning an\nerror code and a HyperVException is raised.\n\nIf the VM's VNIC has been removed, disconnecting the\nswitch port is no longer necessary and the it will\nproceed to remove the switch port.\n\nThis issue is not present in Windows / Hyper-V Server 2012,\nas the switch ports are cleaned automatically.\n\nNote: This commit is not a classic backport, as this commit is not\nmerged in master, since the Hyper-V Neutron Agent was decomposed\nfrom the master branch. This commit is already included in the\nnetworking_hyperv project:\nhttps://github.com/stackforge/networking-hyperv/commit/f5956a34d09d6468a0645c541cba1a92b9938fc1\n\n(cherry picked from commit 2e8fe958eb68e04b5b608d2d4dd53973193a931f)\n\nConflicts:\n\tneutron/plugins/hyperv/agent/hyperv_neutron_agent.py\n\nCloses-Bug: #1374108\n\nChange-Id: I729753c15c51c86655651b132fcf8eab78884eb5\n""}, {'number': 2, 'created': '2015-03-31 14:28:43.000000000', 'files': ['neutron/plugins/hyperv/agent/utils.py', 'neutron/plugins/hyperv/agent/utilsv2.py', 'neutron/tests/unit/hyperv/test_hyperv_utilsv2.py', 'neutron/plugins/hyperv/agent/hyperv_neutron_agent.py', 'neutron/tests/unit/hyperv/test_hyperv_utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1dcb072bebd31094623555a4f387bafc9712820e', 'message': ""Fixes Hyper-V agent port disconnect issue\n\nOn Windows / Hyper-V Server 2008 R2, when a switch port\nhave to be disconnected because the VM using it was\nremoved, DisconnectSwitchPort will fail, returning an\nerror code and a HyperVException is raised.\n\nIf the VM's VNIC has been removed, disconnecting the\nswitch port is no longer necessary and the it will\nproceed to remove the switch port.\n\nThis issue is not present in Windows / Hyper-V Server 2012,\nas the switch ports are cleaned automatically.\n\nNote: This commit is not a classic backport, as this commit is not\nmerged in master, since the Hyper-V Neutron Agent was decomposed\nfrom the master branch. This commit is already included in the\nnetworking_hyperv project:\nhttps://github.com/stackforge/networking-hyperv/commit/f5956a34d09d6468a0645c541cba1a92b9938fc1\n\n(cherry picked from commit 2e8fe958eb68e04b5b608d2d4dd53973193a931f)\n\nConflicts:\n\tneutron/plugins/hyperv/agent/hyperv_neutron_agent.py\n\nCloses-Bug: #1374108\n\nChange-Id: I729753c15c51c86655651b132fcf8eab78884eb5\n""}]",0,161273,1dcb072bebd31094623555a4f387bafc9712820e,53,25,2,8213,,,0,"Fixes Hyper-V agent port disconnect issue

On Windows / Hyper-V Server 2008 R2, when a switch port
have to be disconnected because the VM using it was
removed, DisconnectSwitchPort will fail, returning an
error code and a HyperVException is raised.

If the VM's VNIC has been removed, disconnecting the
switch port is no longer necessary and the it will
proceed to remove the switch port.

This issue is not present in Windows / Hyper-V Server 2012,
as the switch ports are cleaned automatically.

Note: This commit is not a classic backport, as this commit is not
merged in master, since the Hyper-V Neutron Agent was decomposed
from the master branch. This commit is already included in the
networking_hyperv project:
https://github.com/stackforge/networking-hyperv/commit/f5956a34d09d6468a0645c541cba1a92b9938fc1

(cherry picked from commit 2e8fe958eb68e04b5b608d2d4dd53973193a931f)

Conflicts:
	neutron/plugins/hyperv/agent/hyperv_neutron_agent.py

Closes-Bug: #1374108

Change-Id: I729753c15c51c86655651b132fcf8eab78884eb5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/73/161273/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/hyperv/agent/utils.py', 'neutron/plugins/hyperv/agent/utilsv2.py', 'neutron/tests/unit/hyperv/test_hyperv_utilsv2.py', 'neutron/plugins/hyperv/agent/hyperv_neutron_agent.py', 'neutron/tests/unit/hyperv/test_hyperv_utils.py']",5,bfd3d11a7ab4bb5abd2bb0f8cb1b0c85a549ebdf,bug/1374198," @mock.patch.object(utils.HyperVUtils, ""_get_switch_port_path_by_name"") def test_disconnect_switch_port_not_found(self, mock_get_swp_path): mock_svc = self.utils._conn.Msvm_VirtualSwitchManagementService()[0] mock_get_swp_path.return_value = None self.utils.disconnect_switch_port(mock.sentinel.FAKE_VSWITCH_NAME, mock.sentinel.FAKE_PORT_NAME, True, True) self.assertFalse(mock_svc.DisconnectSwitchPort.called) self.assertFalse(mock_svc.DeleteSwitchPort.called) @mock.patch.object(utils.HyperVUtils, ""_get_switch_port_path_by_name"") def test_disconnect_switch_port(self, mock_get_swp_path): mock_svc = self.utils._conn.Msvm_VirtualSwitchManagementService()[0] mock_svc.DisconnectSwitchPort.return_value = (0, ) mock_svc.DeleteSwitchPort.return_value = (0, ) mock_get_swp_path.return_value = mock.sentinel.FAKE_PATH self.utils.disconnect_switch_port(mock.sentinel.FAKE_VSWITCH_NAME, mock.sentinel.FAKE_PORT_NAME, False, True) mock_svc.DisconnectSwitchPort.assert_called_once_with( SwitchPort=mock.sentinel.FAKE_PATH) mock_svc.DeleteSwitchPort.assert_called_once_with( SwitchPort=mock.sentinel.FAKE_PATH) @mock.patch.object(utils.HyperVUtils, ""_get_switch_port_path_by_name"") def test_disconnect_switch_port_disconnected(self, mock_get_swp_path): mock_svc = self.utils._conn.Msvm_VirtualSwitchManagementService()[0] mock_svc.DeleteSwitchPort.return_value = (0, ) mock_get_swp_path.return_value = mock.sentinel.FAKE_PATH self.utils.disconnect_switch_port(mock.sentinel.FAKE_VSWITCH_NAME, mock.sentinel.FAKE_PORT_NAME, True, True) self.assertFalse(mock_svc.DisconnectSwitchPort.called) mock_svc.DeleteSwitchPort.assert_called_once_with( SwitchPort=mock.sentinel.FAKE_PATH) @mock.patch.object(utils.HyperVUtils, ""_get_switch_port_path_by_name"") def test_disconnect_switch_port_disconnect_ex(self, mock_get_swp_path): mock_svc = self.utils._conn.Msvm_VirtualSwitchManagementService()[0] mock_svc.DisconnectSwitchPort.return_value = ( mock.sentinel.FAKE_VAL, ) mock_get_swp_path.return_value = mock.sentinel.FAKE_PATH self.assertRaises(utils.HyperVException, self.utils.disconnect_switch_port, mock.sentinel.FAKE_VSWITCH_NAME, mock.sentinel.FAKE_PORT_NAME, False, True) mock_svc.DisconnectSwitchPort.assert_called_once_with( SwitchPort=mock.sentinel.FAKE_PATH) @mock.patch.object(utils.HyperVUtils, ""_get_switch_port_path_by_name"") def test_disconnect_switch_port_delete_ex(self, mock_get_swp_path): mock_svc = self.utils._conn.Msvm_VirtualSwitchManagementService()[0] mock_svc.DeleteSwitchPort.return_value = (mock.sentinel.FAKE_VAL, ) mock_get_swp_path.return_value = mock.sentinel.FAKE_PATH self.assertRaises(utils.HyperVException, self.utils.disconnect_switch_port, mock.sentinel.FAKE_VSWITCH_NAME, mock.sentinel.FAKE_PORT_NAME, True, True) mock_svc.DeleteSwitchPort.assert_called_once_with( SwitchPort=mock.sentinel.FAKE_PATH) ",,89,16
openstack%2Fironic~master~Ia070d60754dfd85966178eadbf82a4d98b64407a,openstack/ironic,master,Ia070d60754dfd85966178eadbf82a4d98b64407a,Prepare for hacking 0.10.x,MERGED,2015-05-19 07:27:26.000000000,2015-05-21 17:44:30.000000000,2015-05-21 17:44:27.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 9751}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-05-19 07:27:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/01e63b8a9872e8bd2ac8b5888b142546b94e7af2', 'message': 'Update hacking to unbreak pep8 check\n\nWith the release of pbr 1.0.0, we need a newer version of hacking.\nUpdate the version. hacking is manually synced from global requirements\nrepo, use the version from there.\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-dev/2015-May/064362.html\n\nChange-Id: Ia070d60754dfd85966178eadbf82a4d98b64407a\n'}, {'number': 2, 'created': '2015-05-19 07:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8dd673007ef989367e2ddcaf430d2a107e1494c4', 'message': 'Update hacking to unbreak pep8 check\n\nWith the release of pbr 1.0.0, we need a newer version of hacking.\nUpdate the version. hacking is manually synced from global requirements\nrepo, use the version from there.\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-dev/2015-May/064362.html\n\nChange-Id: Ia070d60754dfd85966178eadbf82a4d98b64407a\n'}, {'number': 3, 'created': '2015-05-19 07:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a9a481c40480d7fc04651f0998ce042590485c1b', 'message': ""Update hacking to unbreak pep8 check\n\nWith the release of pbr 1.0.0, we need a newer version of hacking.\nUpdate the version. hacking is manually synced from global requirements\nrepo, use the version from there.\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-dev/2015-May/064362.html\n\nFix also new failures due to hacking update. The failure messages fixed\nare:\nH238  old style class declaration, use new style (inherit from `object`)\nH105  Don't use author tags\nH501  Do not use self.__dict__ for string formatting\n\nChange-Id: Ia070d60754dfd85966178eadbf82a4d98b64407a\n""}, {'number': 4, 'created': '2015-05-19 10:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/49236252cc1418c99151d7a73cc5e3cbfcd24e00', 'message': ""Update hacking to unbreak pep8 check\n\nWith the release of pbr 1.0.0, we need a newer version of hacking.\nUpdate the version. hacking is manually synced from global requirements\nrepo, use the version from there.\n\nAlso add simplegeneric to test-requirements-py3 to pass tests.\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-dev/2015-May/064362.html\n\nFix also new failures due to hacking update. The failure messages fixed\nare:\nH238  old style class declaration, use new style (inherit from `object`)\nH105  Don't use author tags\nH501  Do not use self.__dict__ for string formatting\n\nChange-Id: Ia070d60754dfd85966178eadbf82a4d98b64407a\n""}, {'number': 5, 'created': '2015-05-20 06:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/09a9368b5bfcb63928c698c7f1051929808fc7d0', 'message': ""Prepare for hacking 0.10.x\n\nFix new warning that are introduced with hacking 0.10.x.\nThe failure messages fixed are:\nH238  old style class declaration, use new style (inherit from `object`)\nH105  Don't use author tags\nH501  Do not use self.__dict__ for string formatting\n\nChange-Id: Ia070d60754dfd85966178eadbf82a4d98b64407a\n""}, {'number': 6, 'created': '2015-05-21 06:07:21.000000000', 'files': ['ironic/tests/test_driver_factory.py', 'ironic/api/acl.py', 'ironic/common/service.py', 'ironic/api/hooks.py', 'ironic/tests/drivers/test_seamicro.py', 'ironic/tests/test_keystone.py', 'ironic/tests/matchers.py', 'ironic/api/controllers/root.py', 'ironic/api/middleware/parsable_error.py', 'ironic/objects/base.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/2720765cb3aa61a7b271dbeeadefaa62fa8e120f', 'message': ""Prepare for hacking 0.10.x\n\nFix new warning that are introduced with hacking 0.10.x.\nThe failure messages fixed are:\nH238  old style class declaration, use new style (inherit from `object`)\nH105  Don't use author tags\nH501  Do not use self.__dict__ for string formatting\n\nChange-Id: Ia070d60754dfd85966178eadbf82a4d98b64407a\n""}]",2,184198,2720765cb3aa61a7b271dbeeadefaa62fa8e120f,43,8,6,6547,,,0,"Prepare for hacking 0.10.x

Fix new warning that are introduced with hacking 0.10.x.
The failure messages fixed are:
H238  old style class declaration, use new style (inherit from `object`)
H105  Don't use author tags
H501  Do not use self.__dict__ for string formatting

Change-Id: Ia070d60754dfd85966178eadbf82a4d98b64407a
",git fetch https://review.opendev.org/openstack/ironic refs/changes/98/184198/4 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,01e63b8a9872e8bd2ac8b5888b142546b94e7af2,update-hacking,"hacking>=0.10.0,<0.11","hacking>=0.9.2,<0.10",1,1
openstack%2Fneutron~master~I7340b3b408a6edaf9b4b307909631e628befe921,openstack/neutron,master,I7340b3b408a6edaf9b4b307909631e628befe921,VMware NSXV: update configuration file,MERGED,2015-05-15 15:14:56.000000000,2015-05-21 17:44:17.000000000,2015-05-21 17:44:15.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 8119}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 11343}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-05-15 15:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1775924cd07667c39e2e278d98bf61dfd8cf6d05', 'message': 'VMware NSXV: update configuration file\n\nUpdate the configuration file to show the variables for configuring\nthe Edge username and password. This is very useful for administrators\nwhen they wish to debug issues.\n\nChange-Id: I7340b3b408a6edaf9b4b307909631e628befe921\n'}, {'number': 2, 'created': '2015-05-20 00:37:59.000000000', 'files': ['etc/neutron/plugins/vmware/nsx.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fdf7107dece3c9ac891750c6752ccaf8d8403101', 'message': 'VMware NSXV: update configuration file\n\nUpdate the configuration file to show the variables for configuring\nthe Edge username and password. This is very useful for administrators\nwhen they wish to debug issues.\n\nChange-Id: I7340b3b408a6edaf9b4b307909631e628befe921\n'}]",11,183565,fdf7107dece3c9ac891750c6752ccaf8d8403101,80,31,2,1653,,,0,"VMware NSXV: update configuration file

Update the configuration file to show the variables for configuring
the Edge username and password. This is very useful for administrators
when they wish to debug issues.

Change-Id: I7340b3b408a6edaf9b4b307909631e628befe921
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/183565/2 && git format-patch -1 --stdout FETCH_HEAD,['etc/neutron/plugins/vmware/nsx.ini'],1,1775924cd07667c39e2e278d98bf61dfd8cf6d05,edge-password,# (Optional) Enable a administrator to configure the egde user and passwords # Username to configure for Edge appliance login # edge_appliance_user = # (Optional) Password to configure for Edge appliance login # edge_appliance_password = ,,6,0
openstack%2Fdevstack~master~I230fd662904bc9947baeb233a73e0baa52c4247d,openstack/devstack,master,I230fd662904bc9947baeb233a73e0baa52c4247d,Adds ramdisk creation to lib/dib,ABANDONED,2014-10-02 00:08:09.000000000,2015-05-21 17:44:08.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1420}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-02 00:08:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e619ad56bfa5e5427b95fb523cfede68ffe42704', 'message': 'Adds ramdisk creation to lib/dib\n\nAdds a utility function to lib/dib that can be used to create\na ramdisk with the appropriate environment set.\n\nChange-Id: I230fd662904bc9947baeb233a73e0baa52c4247d\n'}, {'number': 2, 'created': '2014-10-08 23:18:35.000000000', 'files': ['lib/dib'], 'web_link': 'https://opendev.org/openstack/devstack/commit/89e45b2020c8a4831e115220a8102aa315ef1c0f', 'message': 'Adds ramdisk creation to lib/dib\n\nAdds a utility function to lib/dib that can be used to create\na ramdisk with the appropriate environment set.\n\nChange-Id: I230fd662904bc9947baeb233a73e0baa52c4247d\n'}]",2,125523,89e45b2020c8a4831e115220a8102aa315ef1c0f,13,6,2,1420,,,0,"Adds ramdisk creation to lib/dib

Adds a utility function to lib/dib that can be used to create
a ramdisk with the appropriate environment set.

Change-Id: I230fd662904bc9947baeb233a73e0baa52c4247d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/23/125523/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/dib'],1,e619ad56bfa5e5427b95fb523cfede68ffe42704,dib_devstack,"OCC_DIR=$DEST/os-collect-config ORC_DIR=$DEST/os-refresh-config OAC_DIR=$DEST/os-apply-configDIB_PYPI_MIRROR_URL=${DIB_PYPI_MIRROR_URL:-http://$SERVICE_HOST:$DIB_PIP_REPO_PORT/} if [ -a $HOME/.pip/pip.conf ]; then # Add the current pip.conf index-url as an extra-index-url # in the image build DIB_PYPI_MIRROR_URL_1=$(iniget $HOME/.pip/pip.conf global index-url) else DIB_PYPI_MIRROR_URL_1=${DIB_PYPI_MIRROR_URL_1:-http://pypi.python.org/simple} fi PYPI_MIRROR_URL=$DIB_PYPI_MIRROR_URL \ PYPI_MIRROR_URL_1=$DIB_PYPI_MIRROR_URL_1 \# ramdisk_image_create() - Creates a ramdisk and kernel. Note, this call # outputs two files in $TOP_DIR/files/, $image_name.initramfs and # $image_name.kernel. function ramdisk_image_create { local image_name=$1 local image_elements=$2 local elements_path=$3 local image_path=$TOP_DIR/files/$image_name ELEMENTS_PATH=$elements_path \ PYPI_MIRROR_URL=$DIB_PYPI_MIRROR_URL \ PYPI_MIRROR_URL_1=$DIB_PYPI_MIRROR_URL_1 \ DIB_OFFLINE=$DIB_BUILD_OFFLINE \ DIB_APT_SOURCES=$DIB_APT_SOURCES \ ramdisk-image-create -a amd64 $image_elements $EXTRA_ELEMENTS -a amd64 \ --image-cache $DIB_IMAGE_CACHE -o $image_path } "," OCC_DIR=$DEST/os-collect-config ORC_DIR=$DEST/os-refresh-config OAC_DIR=$DEST/os-apply-config # Set the local pip repo as the primary index mirror so the # image is built with local packages local pypi_mirror_url=http://$SERVICE_HOST:$DIB_PIP_REPO_PORT/ local pypi_mirror_url_1 if [ -a $HOME/.pip/pip.conf ]; then # Add the current pip.conf index-url as an extra-index-url # in the image build pypi_mirror_url_1=$(iniget $HOME/.pip/pip.conf global index-url) else # If no pip.conf, set upstream pypi as an extra mirror # (this also sets the .pydistutils.cfg index-url) pypi_mirror_url_1=http://pypi.python.org/simple fi PYPI_MIRROR_URL=$pypi_mirror_url \ PYPI_MIRROR_URL_1=$pypi_mirror_url_1 \",34,20
openstack%2Fdevstack-gate~master~I054e27ece797433922fef4fdf9d69e87f2e39bdf,openstack/devstack-gate,master,I054e27ece797433922fef4fdf9d69e87f2e39bdf,Enable DIB service for Ironic,ABANDONED,2014-09-18 21:54:22.000000000,2015-05-21 17:43:55.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 2889}, {'_account_id': 4146}, {'_account_id': 6786}, {'_account_id': 8871}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-09-18 21:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/a08710e494dfe0781189c1f5b7640f3d7bbcd069', 'message': 'Enable DIB service for Ironic\n\nEnable the new DIB service in devstack and allow DIB to be\ninstalled from source during the Ironic ramdisk creation.\nThis will make Ironic actually test proposed changes to DIB\nand ensure we are using tip of DIB trunk while testing against\nIronic and elsewhere.\n\nChange-Id: I054e27ece797433922fef4fdf9d69e87f2e39bdf\nCloses-bug: #1371319\n'}, {'number': 2, 'created': '2014-09-23 23:07:43.000000000', 'files': ['features.yaml'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/a314fe920bf09dfa71c423b132d9c80694134225', 'message': 'Enable DIB service for Ironic\n\nEnable the new DIB service in devstack and allow DIB to be\ninstalled from source during the Ironic ramdisk creation.\nThis will make Ironic actually test proposed changes to DIB\nand ensure we are using tip of DIB trunk while testing against\nIronic and elsewhere.\n\nChange-Id: I054e27ece797433922fef4fdf9d69e87f2e39bdf\nCloses-bug: #1371319\n'}]",0,122539,a314fe920bf09dfa71c423b132d9c80694134225,39,8,2,1420,,,0,"Enable DIB service for Ironic

Enable the new DIB service in devstack and allow DIB to be
installed from source during the Ironic ramdisk creation.
This will make Ironic actually test proposed changes to DIB
and ensure we are using tip of DIB trunk while testing against
Ironic and elsewhere.

Change-Id: I054e27ece797433922fef4fdf9d69e87f2e39bdf
Closes-bug: #1371319
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/39/122539/2 && git format-patch -1 --stdout FETCH_HEAD,['features.yaml'],1,a08710e494dfe0781189c1f5b7640f3d7bbcd069,dib_devstack," services: [ir-api, ir-cond, dib]"," services: [ir-api, ir-cond]",1,1
openstack%2Fdevstack~master~I14703ee4ac53de049c9ab6c00a2580b3ce47ae4c,openstack/devstack,master,I14703ee4ac53de049c9ab6c00a2580b3ce47ae4c,Use global-requirements.gate to pre-install specific reqs (WIP),ABANDONED,2015-03-17 19:48:20.000000000,2015-05-21 17:43:44.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1849}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-03-17 19:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f0950fa7d5a134bdce5f24c9378d2d0d10c0de26', 'message': ""Use global-requirements.gate to pre-install specific reqs (WIP)\n\nThis adds the ability to pre-install a specific set of dependencies\nfrom global-requirements.gate.  The needed requirements are\ncalculated from each project's requirements.txt using pip-compile, and the\nspecific version are queried from global-requirements.gate (to be hosted in\nthe requirements repo). This results in a temporary requirements file that\nis pip installed just prior to installing the project code.\n\nChange-Id: I14703ee4ac53de049c9ab6c00a2580b3ce47ae4c\n""}, {'number': 2, 'created': '2015-03-17 20:15:27.000000000', 'files': ['inc/python'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a47361b1da32ebef4f6acadc6a7d3e90b9cbeb9a', 'message': ""Use global-requirements.gate to pre-install specific reqs (WIP)\n\nThis adds the ability to pre-install a specific set of dependencies\nfrom global-requirements.gate.  The needed requirements are\ncalculated from each project's requirements.txt using pip-compile, and the\nspecific version are queried from global-requirements.gate (to be hosted in\nthe requirements repo). This results in a temporary requirements file that\nis pip installed just prior to installing the project code.\n\nChange-Id: I14703ee4ac53de049c9ab6c00a2580b3ce47ae4c\n""}]",0,165195,a47361b1da32ebef4f6acadc6a7d3e90b9cbeb9a,7,4,2,1420,,,0,"Use global-requirements.gate to pre-install specific reqs (WIP)

This adds the ability to pre-install a specific set of dependencies
from global-requirements.gate.  The needed requirements are
calculated from each project's requirements.txt using pip-compile, and the
specific version are queried from global-requirements.gate (to be hosted in
the requirements repo). This results in a temporary requirements file that
is pip installed just prior to installing the project code.

Change-Id: I14703ee4ac53de049c9ab6c00a2580b3ce47ae4c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/95/165195/2 && git format-patch -1 --stdout FETCH_HEAD,['inc/python'],1,f0950fa7d5a134bdce5f24c9378d2d0d10c0de26,compiled_reqs,"# Compiles all dependencies needed by a a project requirements file. # This includes top-level dependencies and transitive dependencies. # _compile_project_requirements <path-to-project-requirements-file> function _compile_project_requirements { if ! which pip-compile; then die $LINENO ""pip-compile not found, please install from https://github.com/nvie/pip-tools"" fi local project_requirements=$1 local tmp_dir=$(mktemp -d) local requirements_in=""$tmp_dir/project_requirements.in"" local requirements_out=""$tmp_dir/project_requirements.txt"" cp $project_requirements $requirements_in pip-compile $requirements_in cat $requirements_out rm -rf $tmp_dir } # For a given requirements file, determine explicit versions to be tested # from the global-requirements.gate in the requirements repo, and save them # to a new requirements file. This involves calculating the entire dependency # set for a given project and querying the central global-requirements.gate # for specific versions we want to use. # build_project_gate_requirements <path-to-project-requirements-file> <output-file> function build_project_gate_requirements { local project_requirements=$1 local out_file=$2 local p_req g_req req echo ""# Gate requirements based on dependencies specified in $project_requirements"" >$out_file for req in $(_compile_project_requirements $project_requirements); do p_req=${req%==*} g_req=$(get_from_global_requirements_gate $p_req) echo $g_req >>$out_file done } # For stable branches, we use a static set of pinned dependencies stored in # in the requirements repo. These are installed before any project and # should satisfy anything listed in project's requirements.txt. if [ ""$USE_GATE_REQUIREMENTS"" == ""True"" ]; then if [ ! -e $REQUIREMENTS_DIR/global-requirements.gate ]; then die $LINENO ""USE_GATE_REQUIREMENTS==True but global-requirements.gate"" \ ""is not found in REQUIREMENTS_DIR ($REQUIREMENTS_DIR)."" fi # This should be output to somewhere that will be archived on logserver build_project_gate_requirements ""$@/requirements.txt"" ""$@/gate-requirements.txt"" $sudo_pip \ http_proxy=${http_proxy:-} \ https_proxy=${https_proxy:-} \ no_proxy=${no_proxy:-} \ PIP_FIND_LINKS=$PIP_FIND_LINKS \ $cmd_pip install \ -r ""$@/gate-requirements.txt"" if [[ ""$INSTALL_TESTONLY_PACKAGES"" == ""True"" ]]; then build_project_gate_requirements ""$@/test-requirements.txt"" ""$@/gate-test-requirements.txt"" $sudo_pip \ http_proxy=${http_proxy:-} \ https_proxy=${https_proxy:-} \ no_proxy=${no_proxy:-} \ PIP_FIND_LINKS=$PIP_FIND_LINKS \ $cmd_pip install \ -r ""$@/gate-test-requirements.txt"" fi fi # get pinned version of specified dependency from gloabl-requirements.gate # file, if one is listed. # get_from_global_requirements_gate <package> function get_from_global_requirements_gate { set -o xtrace local package=$1 local required_pkg=$(grep -h ""^${package}=="" $REQUIREMENTS_DIR/global-requirements.gate | cut -d\# -f1) # It is safe to not fail here, in case a new transitive dependency has been introduced # somewhere upstream but it does not exist in g-r.gate, we can skip knowing whatever # package pulled it in is still pinned to an older version in g-r.gate. if [[ $required_pkg == """" ]]; then echo ""WARN: Can't find package $package in global-requirements.gate, skipping"" fi echo $required_pkg set +x xtrace } ",,83,0
openstack%2Fpython-ironicclient~master~I621b90727daab93d4c895f98b98985f63fbcebd9,openstack/python-ironicclient,master,I621b90727daab93d4c895f98b98985f63fbcebd9,Testing functional tests (DO NOT MERGE),ABANDONED,2015-03-10 21:39:53.000000000,2015-05-21 17:43:30.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}]","[{'number': 1, 'created': '2015-03-10 21:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f172c38654ed988db44c6810112008dd2e3cf7ef', 'message': 'Testing functional tests (DO NOT MERGE)\n\nChange-Id: I621b90727daab93d4c895f98b98985f63fbcebd9\n'}, {'number': 2, 'created': '2015-03-26 21:00:13.000000000', 'files': ['tools/run_functional.sh'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/5b20fda96c17bbb7b3a6ef9934e9d5fdff7a9ddd', 'message': 'Testing functional tests (DO NOT MERGE)\n\nChange-Id: I621b90727daab93d4c895f98b98985f63fbcebd9\n'}]",0,163203,5b20fda96c17bbb7b3a6ef9934e9d5fdff7a9ddd,17,2,2,1420,,,0,"Testing functional tests (DO NOT MERGE)

Change-Id: I621b90727daab93d4c895f98b98985f63fbcebd9
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/03/163203/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/run_functional.sh'],1,f172c38654ed988db44c6810112008dd2e3cf7ef,163203,#,,1,0
openstack%2Ffuel-library~master~I5d8ba80038dafca12b06bef7804b28cae8e57207,openstack/fuel-library,master,I5d8ba80038dafca12b06bef7804b28cae8e57207,"Close connections to glance-{api,registry} after 11 minutes",MERGED,2015-05-21 12:36:07.000000000,2015-05-21 17:42:50.000000000,2015-05-21 17:42:11.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9546}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-21 12:36:07.000000000', 'files': ['deployment/puppet/openstack/manifests/ha/glance.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9e4bbca9e03b3bf032d8f1cec32453b027cc14a6', 'message': 'Close connections to glance-{api,registry} after 11 minutes\n\nChange-Id: I5d8ba80038dafca12b06bef7804b28cae8e57207\nCloses-Bug: 1456683\n'}]",0,184770,9e4bbca9e03b3bf032d8f1cec32453b027cc14a6,28,14,1,13948,,,0,"Close connections to glance-{api,registry} after 11 minutes

Change-Id: I5d8ba80038dafca12b06bef7804b28cae8e57207
Closes-Bug: 1456683
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/70/184770/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/ha/glance.pp'],1,9e4bbca9e03b3bf032d8f1cec32453b027cc14a6,bug/1456683," 'option' => ['httpchk', 'httplog','httpclose'], 'timeout server' => '11m', order => '090', listen_port => 9191, require_service => 'glance-registry', haproxy_config_options => { 'timeout server' => '11m', },"," option => ['httpchk', 'httplog','httpclose'], order => '090', listen_port => 9191, require_service => 'glance-registry',",8,4
openstack%2Ffuel-library~master~I329e26a0b4da1b2be676dd7f8e6eb39e89eb11f4,openstack/fuel-library,master,I329e26a0b4da1b2be676dd7f8e6eb39e89eb11f4,Specify default delay while boot for LACP bonds.,MERGED,2015-05-19 03:20:27.000000000,2015-05-21 17:39:06.000000000,2015-05-21 17:38:27.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 13343}, {'_account_id': 14316}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-19 03:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c18916cd3fedc37a79f108500113ba2d93c5aff0', 'message': 'Specify default delay while boot for LACP bonds.\n\nHardcode 30s delay for all LACP bonds. Only for LACP. Only at node boot time.\nSystem administrator can re-define this value by CLI\n\nThis patchset is a workaround and should be reverted in 7.0\nafter implementing this feature in UI\n\nChange-Id: I329e26a0b4da1b2be676dd7f8e6eb39e89eb11f4\nRelated-bug: #1441435\nRelated-bug: #1456436\n'}, {'number': 2, 'created': '2015-05-19 03:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a94588d4d4c2a11af17f857c199358f11d938dab', 'message': 'Specify default delay while boot for LACP bonds.\n\nHardcode 30s delay for all LACP bonds. Only for LACP. Only at node boot time.\nSystem administrator can re-define this value by CLI\n\nThis patchset is a workaround and should be reverted in 7.0\nafter implementing this feature in UI\n\nChange-Id: I329e26a0b4da1b2be676dd7f8e6eb39e89eb11f4\nRelated-bug: #1441435\nRelated-bug: #1456436\n'}, {'number': 3, 'created': '2015-05-20 00:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/801fd15dd4421ced202946d813fb16157d0a2220', 'message': 'Specify default delay while boot for LACP bonds.\n\nHardcode 45s delay for LACP bonds and 15s for non-LACP. Only at node boot time.\nSystem administrator can re-define this value by CLI\n\nThis patchset is a workaround and should be reverted in 7.0\nafter implementing this feature in UI\n\nChange-Id: I329e26a0b4da1b2be676dd7f8e6eb39e89eb11f4\nRelated-bug: #1441435\nRelated-bug: #1456436\n'}, {'number': 4, 'created': '2015-05-20 00:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3a1c209c43917800d6f72d918cd9d82afda00ad8', 'message': 'Specify default delay while boot for LACP bonds.\n\nHardcode 45s delay for LACP bonds and 15s for non-LACP. Only at node boot time.\nSystem administrator can re-define this value by CLI\n\nThis patchset is a workaround and should be reverted in 7.0\nafter implementing this feature in UI\n\nChange-Id: I329e26a0b4da1b2be676dd7f8e6eb39e89eb11f4\nRelated-bug: #1441435\nRelated-bug: #1456436\n'}, {'number': 5, 'created': '2015-05-20 02:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7c89cfd1d277a6a2446bc95b097c5cc48da7d1cd', 'message': 'Specify default delay while boot for LACP bonds.\n\nHardcode 45s delay for LACP bonds and 15s for non-LACP. Only at node boot time.\nSystem administrator can re-define this value by CLI\n\nThis patchset is a workaround and should be reverted in 7.0\nafter implementing this feature in UI\n\nChange-Id: I329e26a0b4da1b2be676dd7f8e6eb39e89eb11f4\nRelated-bug: #1441435\nRelated-bug: #1456436\n'}, {'number': 6, 'created': '2015-05-20 18:45:25.000000000', 'files': ['deployment/puppet/l23network/manifests/l2/bridge.pp', 'deployment/puppet/l23network/spec/classes/bridge_with__delay_while_up__option__spec.rb', 'deployment/puppet/l23network/README.md', 'deployment/puppet/l23network/spec/classes/bond_with__delay_while_up__option__spec.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/generate_network_config.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/114b470f4a31cc98b4724d0b0fc0a7b334b6f545', 'message': 'Specify default delay while boot for LACP bonds.\n\nHardcode 45s delay for LACP bonds and 15s for non-LACP. Only at node boot time.\nSystem administrator can re-define this value by CLI\n\nThis patchset is a workaround and should be reverted in 7.0\nafter implementing this feature in UI\n\nChange-Id: I329e26a0b4da1b2be676dd7f8e6eb39e89eb11f4\nRelated-bug: #1441435\nRelated-bug: #1456436\n'}]",0,184176,114b470f4a31cc98b4724d0b0fc0a7b334b6f545,113,8,6,7468,,,0,"Specify default delay while boot for LACP bonds.

Hardcode 45s delay for LACP bonds and 15s for non-LACP. Only at node boot time.
System administrator can re-define this value by CLI

This patchset is a workaround and should be reverted in 7.0
after implementing this feature in UI

Change-Id: I329e26a0b4da1b2be676dd7f8e6eb39e89eb11f4
Related-bug: #1441435
Related-bug: #1456436
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/76/184176/6 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/l23network/lib/puppet/parser/functions/generate_network_config.rb', 'deployment/puppet/l23network/spec/classes/bond_with__delay_while_up__option__spec.rb']",2,c18916cd3fedc37a79f108500113ba2d93c5aff0,bug/1441435,"require 'spec_helper' describe 'l23network::examples::run_network_scheme', :type => :class do let(:network_scheme) do <<eof --- network_scheme: version: 1.1 provider: lnx interfaces: eth1: {} eth2: {} eth3: {} eth4: {} eth5: {} eth6: {} eth7: {} eth8: {} transformations: - action: add-bond name: bond0 interfaces: - eth1 - eth2 bond_properties: mode: 802.3ad - action: add-bond name: bond1 interfaces: - eth3 - eth4 bond_properties: mode: 802.3ad delay_while_up: 77 - action: add-bond name: bond2 interfaces: - eth5 - eth6 bond_properties: mode: balance-rr - action: add-bond name: bond3 interfaces: - eth7 - eth8 bond_properties: mode: balance-rr delay_while_up: 77 endpoints: {} roles: {} eof end context 'Default ""delay_while_up"" property for' do let(:title) { 'lacp_bonds' } let(:facts) { { :osfamily => 'RedHat', :operatingsystem => 'Centos', :kernel => 'Linux', :l23_os => 'centos6', :l3_fqdn_hostname => 'stupid_hostname', } } let(:params) do { :settings_yaml => network_scheme, } end it do should compile end it 'LACP bond without defined delay' do should contain_l23_stored_config('bond0').with({ 'delay_while_up' => '30', }) end it 'LACP bond with specified delay' do should contain_l23_stored_config('bond1').with({ 'delay_while_up' => '77', }) end it 'non LACP bond without defined delay' do should contain_l23_stored_config('bond2').without('delay_while_up') end it 'non LACP bond with specified delay' do should contain_l23_stored_config('bond3').with({ 'delay_while_up' => '77', }) end end end ### ",,107,0
openstack%2Fopenstack-manuals~master~Ide4848c0c83b796ddbc777e966fcd2a4170e9323,openstack/openstack-manuals,master,Ide4848c0c83b796ddbc777e966fcd2a4170e9323,Fix incorrect links to user guide,ABANDONED,2015-05-21 16:21:26.000000000,2015-05-21 17:36:56.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-05-21 16:21:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0d721de5c33e4bdc0011cf717d270ce336337c7b', 'message': 'Fix incorrect link to user guide\n\nChange-Id: Ide4848c0c83b796ddbc777e966fcd2a4170e9323\n'}, {'number': 2, 'created': '2015-05-21 17:09:58.000000000', 'files': ['doc/admin-guide-cloud/ch_blockstorage.xml', 'doc/admin-guide-cloud/compute/section_compute-configure-migrations.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cf868592df305770c60c13775a859a97d8e63844', 'message': 'Fix incorrect links to user guide\n\nChange-Id: Ide4848c0c83b796ddbc777e966fcd2a4170e9323\n'}]",1,184813,cf868592df305770c60c13775a859a97d8e63844,9,4,2,7923,,,0,"Fix incorrect links to user guide

Change-Id: Ide4848c0c83b796ddbc777e966fcd2a4170e9323
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/13/184813/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/compute/section_compute-configure-migrations.xml'],1,0d721de5c33e4bdc0011cf717d270ce336337c7b,fixlink," xlink:href=""http://docs.openstack.org/user-guide/cli_config_drive.html"""," xlink:href=""http://docs.openstack.org/user-guide/enduser/cli_config_drive.html""",1,1
openstack%2Fnova~master~I080a162ee0deaa4a6ac4f082338cd002ef86c5c0,openstack/nova,master,I080a162ee0deaa4a6ac4f082338cd002ef86c5c0,Replace MySQL-python test req with mysqlclient,ABANDONED,2015-05-05 12:48:31.000000000,2015-05-21 17:34:50.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 9107}, {'_account_id': 9578}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-05 12:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4140f8df2ea44f0d056ff66f833e64b909aea06', 'message': 'Replace MySQL-python test req. with mysqlclient\n\nMySQL-python project is no more active: last commit in january 2014. The\nmysqlclient is a fork created by the author of PyMySQL, INADA Naoki. It\nis actively developed by multiple contributors, includes bugfixes, has\nnew features and support Python 3.\n\nmysqlclient is a drop-in replacement, it provides the same Python module\n(MySQLdb).\n\nBlueprint nova-python3\nDepends-On: I109f3726fff27de2b61bc3423615207c12bb0af2\nChange-Id: I080a162ee0deaa4a6ac4f082338cd002ef86c5c0\n'}, {'number': 2, 'created': '2015-05-12 10:28:52.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/a9b157015cba2e15d79b1fc510b142aebdc04601', 'message': 'Replace MySQL-python test req with mysqlclient\n\nMySQL-python project is no more active: last commit in january 2014. The\nmysqlclient is a fork created by the author of PyMySQL, INADA Naoki. It\nis actively developed by multiple contributors, includes bugfixes, has\nnew features and support Python 3.\n\nmysqlclient is a drop-in replacement, it provides the same Python module\n(MySQLdb).\n\nBlueprint nova-python3\nDepends-On: I109f3726fff27de2b61bc3423615207c12bb0af2\nChange-Id: I080a162ee0deaa4a6ac4f082338cd002ef86c5c0\n'}]",0,180128,a9b157015cba2e15d79b1fc510b142aebdc04601,18,6,2,9107,,,0,"Replace MySQL-python test req with mysqlclient

MySQL-python project is no more active: last commit in january 2014. The
mysqlclient is a fork created by the author of PyMySQL, INADA Naoki. It
is actively developed by multiple contributors, includes bugfixes, has
new features and support Python 3.

mysqlclient is a drop-in replacement, it provides the same Python module
(MySQLdb).

Blueprint nova-python3
Depends-On: I109f3726fff27de2b61bc3423615207c12bb0af2
Change-Id: I080a162ee0deaa4a6ac4f082338cd002ef86c5c0
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/180128/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,e4140f8df2ea44f0d056ff66f833e64b909aea06,bp/nova-python3,mysqlclient # GPL,MySQL-python,1,1
openstack%2Ftripleo-heat-templates~master~Ic534e5aeb03bd53296dc4d98c2ac5971464d7fe4,openstack/tripleo-heat-templates,master,Ic534e5aeb03bd53296dc4d98c2ac5971464d7fe4,Overcloud: bump HOT version to 2015-04-30,MERGED,2015-05-20 17:11:06.000000000,2015-05-21 17:34:24.000000000,2015-05-21 16:03:11.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-20 17:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/24391b46c959fa682fe7820d8c600dd45e641316', 'message': 'Overcloud: bump HOT version to 2015-04-30\n\nThis patch bumps the HOT version for the overcloud\nto Kilo 2015-04-30. We should have already done this\nsince we are making use of OS::stack_id (a kilo feature)\nin some of the nested stacks. Also, this will give us access to\nthe new repeat function as well.\n\nChange-Id: Ic534e5aeb03bd53296dc4d98c2ac5971464d7fe4\n'}, {'number': 2, 'created': '2015-05-20 18:39:56.000000000', 'files': ['compute-post.yaml', 'controller.yaml', 'puppet/bootstrap-config.yaml', 'network/internal_api.yaml', 'puppet/controller-config.yaml', 'network/storage_mgmt.yaml', 'ceph-storage-post.yaml', 'network/tenant.yaml', 'puppet/all-nodes-config.yaml', 'puppet/controller-post-puppet.yaml', 'overcloud-without-mergepy.yaml', 'swift-devices-and-proxy-config.yaml', 'controller-post.yaml', 'puppet/ceph-storage-post-puppet.yaml', 'net-config-noop.yaml', 'cinder-storage-post.yaml', 'compute.yaml', 'puppet/cinder-storage-puppet.yaml', 'puppet/compute-post-puppet.yaml', 'network/noop.yaml', 'puppet/compute-puppet.yaml', 'puppet/cinder-storage-post.yaml', 'net-config-bond.yaml', 'swift-storage.yaml', 'cinder-storage.yaml', 'ceph-storage.yaml', 'puppet/swift-storage-post.yaml', 'network/storage.yaml', 'swift-storage-post.yaml', 'all-nodes-config.yaml', 'puppet/ceph-storage-puppet.yaml', 'bootstrap-config.yaml', 'puppet/swift-storage-puppet.yaml', 'puppet/swift-devices-and-proxy-config.yaml', 'ceph-cluster-config.yaml', 'puppet/ceph-cluster-config.yaml', 'network/external.yaml', 'network/networks.yaml', 'puppet/controller-config-pacemaker.yaml', 'net-config-bridge.yaml', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b56c2f01bdc32d407dc6b981abf30465ddd0b9f8', 'message': 'Overcloud: bump HOT version to 2015-04-30\n\nThis patch bumps the HOT version for the overcloud\nto Kilo 2015-04-30. We should have already done this\nsince we are making use of OS::stack_id (a kilo feature)\nin some of the nested stacks. Also, this will give us access to\nthe new repeat function as well.\n\nChange-Id: Ic534e5aeb03bd53296dc4d98c2ac5971464d7fe4\n'}]",0,184550,b56c2f01bdc32d407dc6b981abf30465ddd0b9f8,18,5,2,360,,,0,"Overcloud: bump HOT version to 2015-04-30

This patch bumps the HOT version for the overcloud
to Kilo 2015-04-30. We should have already done this
since we are making use of OS::stack_id (a kilo feature)
in some of the nested stacks. Also, this will give us access to
the new repeat function as well.

Change-Id: Ic534e5aeb03bd53296dc4d98c2ac5971464d7fe4
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/50/184550/2 && git format-patch -1 --stdout FETCH_HEAD,"['compute-post.yaml', 'controller.yaml', 'puppet/bootstrap-config.yaml', 'puppet/controller-config.yaml', 'ceph-storage-post.yaml', 'puppet/all-nodes-config.yaml', 'puppet/controller-post-puppet.yaml', 'overcloud-without-mergepy.yaml', 'swift-devices-and-proxy-config.yaml', 'controller-post.yaml', 'puppet/ceph-storage-post-puppet.yaml', 'net-config-noop.yaml', 'cinder-storage-post.yaml', 'compute.yaml', 'puppet/cinder-storage-puppet.yaml', 'puppet/compute-post-puppet.yaml', 'puppet/compute-puppet.yaml', 'puppet/cinder-storage-post.yaml', 'net-config-bond.yaml', 'swift-storage.yaml', 'cinder-storage.yaml', 'ceph-storage.yaml', 'puppet/swift-storage-post.yaml', 'swift-storage-post.yaml', 'all-nodes-config.yaml', 'puppet/ceph-storage-puppet.yaml', 'bootstrap-config.yaml', 'puppet/swift-storage-puppet.yaml', 'puppet/swift-devices-and-proxy-config.yaml', 'ceph-cluster-config.yaml', 'puppet/ceph-cluster-config.yaml', 'puppet/controller-config-pacemaker.yaml', 'net-config-bridge.yaml', 'puppet/controller-puppet.yaml']",34,24391b46c959fa682fe7820d8c600dd45e641316,kilo_hot,heat_template_version: 2015-04-30,heat_template_version: 2014-10-16,34,34
openstack%2Fpython-keystoneclient~master~I88ddfdb674db1ec9c0fd4f9a62ae8347785ea10c,openstack/python-keystoneclient,master,I88ddfdb674db1ec9c0fd4f9a62ae8347785ea10c,Remove keystoneclient.middleware,MERGED,2015-04-27 09:34:57.000000000,2015-05-21 17:26:39.000000000,2015-04-27 16:54:39.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 9107}]","[{'number': 1, 'created': '2015-04-27 09:34:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/bfc83214dbd49c1923d682529ebfd963bea2b37f', 'message': ""Remove keystoneclient.middleware\n\nThe code has been moved to the new keystonemiddleware project and\nkeystone.middleware was deprecated since Juno. It's time to drop it in\nLiberty.\n\nRemove the directory keystoneclient/middleware/.\n\nRemove test_auth_token_middleware.py, test_memcache_crypt.py and\ntest_s3_token_middleware.py in keystoneclient/tests/unit/.\n\nRemove the create_middleware_cert shell function from\nexamples/pki/gen_pki.sh. And remove the call from\nexamples/pki/run_all.sh.\n\nRemove netaddr, pycrypto and WebOb test dependencies, only needed to\ntest the removed middleware.\n\nChange-Id: I88ddfdb674db1ec9c0fd4f9a62ae8347785ea10c\n""}, {'number': 2, 'created': '2015-04-27 14:42:09.000000000', 'files': ['requirements.txt', 'keystoneclient/middleware/memcache_crypt.py', 'test-requirements.txt', 'examples/pki/gen_pki.sh', 'keystoneclient/tests/unit/test_auth_token_middleware.py', 'keystoneclient/tests/unit/test_s3_token_middleware.py', 'keystoneclient/middleware/__init__.py', 'keystoneclient/tests/unit/test_memcache_crypt.py', 'keystoneclient/middleware/s3_token.py', 'examples/pki/run_all.sh', 'keystoneclient/middleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/37742ec52082f14a8467a464a431987ac1b5df7a', 'message': ""Remove keystoneclient.middleware\n\nThe code has been moved to the new keystonemiddleware project and\nkeystone.middleware was deprecated since Juno. It's time to drop it in\nLiberty.\n\nRemove the directory keystoneclient/middleware/.\n\nRemove test_auth_token_middleware.py, test_memcache_crypt.py and\ntest_s3_token_middleware.py in keystoneclient/tests/unit/.\n\nRemove the create_middleware_cert shell function from\nexamples/pki/gen_pki.sh. And remove the call from\nexamples/pki/run_all.sh.\n\nRemove netaddr, pycrypto and WebOb test dependencies, only needed to\ntest the removed middleware.\n\nDocImpact: The keystoneclient.middleware module has been removed\n\nCloses-Bug: #1449066\nChange-Id: I88ddfdb674db1ec9c0fd4f9a62ae8347785ea10c\n""}]",1,177694,37742ec52082f14a8467a464a431987ac1b5df7a,19,4,2,9107,,,0,"Remove keystoneclient.middleware

The code has been moved to the new keystonemiddleware project and
keystone.middleware was deprecated since Juno. It's time to drop it in
Liberty.

Remove the directory keystoneclient/middleware/.

Remove test_auth_token_middleware.py, test_memcache_crypt.py and
test_s3_token_middleware.py in keystoneclient/tests/unit/.

Remove the create_middleware_cert shell function from
examples/pki/gen_pki.sh. And remove the call from
examples/pki/run_all.sh.

Remove netaddr, pycrypto and WebOb test dependencies, only needed to
test the removed middleware.

DocImpact: The keystoneclient.middleware module has been removed

Closes-Bug: #1449066
Change-Id: I88ddfdb674db1ec9c0fd4f9a62ae8347785ea10c
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/94/177694/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'keystoneclient/middleware/memcache_crypt.py', 'test-requirements.txt', 'examples/pki/gen_pki.sh', 'keystoneclient/tests/unit/test_auth_token_middleware.py', 'keystoneclient/tests/unit/test_s3_token_middleware.py', 'keystoneclient/middleware/__init__.py', 'keystoneclient/middleware/s3_token.py', 'keystoneclient/tests/unit/test_memcache_crypt.py', 'examples/pki/run_all.sh', 'keystoneclient/middleware/auth_token.py']",11,bfc83214dbd49c1923d682529ebfd963bea2b37f,bug/1449066,,"# Copyright 2010-2012 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. """""" TOKEN-BASED AUTH MIDDLEWARE .. warning:: This module is DEPRECATED. The auth_token middleware has been moved to the `keystonemiddleware repository <http://docs.openstack.org/developer/keystonemiddleware/>`_. This WSGI component: * Verifies that incoming client requests have valid tokens by validating tokens with the auth service. * Rejects unauthenticated requests UNLESS it is in 'delay_auth_decision' mode, which means the final decision is delegated to the downstream WSGI component (usually the OpenStack service) * Collects and forwards identity information based on a valid token such as user name, tenant, etc HEADERS ------- * Headers starting with HTTP\_ is a standard http header * Headers starting with HTTP_X is an extended http header Coming in from initial call from client or customer ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ HTTP_X_AUTH_TOKEN The client token being passed in. HTTP_X_STORAGE_TOKEN The client token being passed in (legacy Rackspace use) to support swift/cloud files Used for communication between components ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ WWW-Authenticate HTTP header returned to a user indicating which endpoint to use to retrieve a new token What we add to the request for use by the OpenStack service ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ HTTP_X_IDENTITY_STATUS 'Confirmed' or 'Invalid' The underlying service will only see a value of 'Invalid' if the Middleware is configured to run in 'delay_auth_decision' mode HTTP_X_DOMAIN_ID Identity service managed unique identifier, string. Only present if this is a domain-scoped v3 token. HTTP_X_DOMAIN_NAME Unique domain name, string. Only present if this is a domain-scoped v3 token. HTTP_X_PROJECT_ID Identity service managed unique identifier, string. Only present if this is a project-scoped v3 token, or a tenant-scoped v2 token. HTTP_X_PROJECT_NAME Project name, unique within owning domain, string. Only present if this is a project-scoped v3 token, or a tenant-scoped v2 token. HTTP_X_PROJECT_DOMAIN_ID Identity service managed unique identifier of owning domain of project, string. Only present if this is a project-scoped v3 token. If this variable is set, this indicates that the PROJECT_NAME can only be assumed to be unique within this domain. HTTP_X_PROJECT_DOMAIN_NAME Name of owning domain of project, string. Only present if this is a project-scoped v3 token. If this variable is set, this indicates that the PROJECT_NAME can only be assumed to be unique within this domain. HTTP_X_USER_ID Identity-service managed unique identifier, string HTTP_X_USER_NAME User identifier, unique within owning domain, string HTTP_X_USER_DOMAIN_ID Identity service managed unique identifier of owning domain of user, string. If this variable is set, this indicates that the USER_NAME can only be assumed to be unique within this domain. HTTP_X_USER_DOMAIN_NAME Name of owning domain of user, string. If this variable is set, this indicates that the USER_NAME can only be assumed to be unique within this domain. HTTP_X_ROLES Comma delimited list of case-sensitive role names HTTP_X_SERVICE_CATALOG json encoded keystone service catalog (optional). For compatibility reasons this catalog will always be in the V2 catalog format even if it is a v3 token. HTTP_X_TENANT_ID *Deprecated* in favor of HTTP_X_PROJECT_ID Identity service managed unique identifier, string. For v3 tokens, this will be set to the same value as HTTP_X_PROJECT_ID HTTP_X_TENANT_NAME *Deprecated* in favor of HTTP_X_PROJECT_NAME Project identifier, unique within owning domain, string. For v3 tokens, this will be set to the same value as HTTP_X_PROJECT_NAME HTTP_X_TENANT *Deprecated* in favor of HTTP_X_TENANT_ID and HTTP_X_TENANT_NAME Keystone-assigned unique identifier, string. For v3 tokens, this will be set to the same value as HTTP_X_PROJECT_ID HTTP_X_USER *Deprecated* in favor of HTTP_X_USER_ID and HTTP_X_USER_NAME User name, unique within owning domain, string HTTP_X_ROLE *Deprecated* in favor of HTTP_X_ROLES Will contain the same values as HTTP_X_ROLES. OTHER ENVIRONMENT VARIABLES --------------------------- keystone.token_info Information about the token discovered in the process of validation. This may include extended information returned by the Keystone token validation call, as well as basic information about the tenant and user. """""" import contextlib import datetime import logging import os import stat import tempfile import time import netaddr from oslo_config import cfg from oslo_serialization import jsonutils from oslo_utils import timeutils import requests import six from six.moves import urllib from keystoneclient import access from keystoneclient.common import cms from keystoneclient import exceptions from keystoneclient.middleware import memcache_crypt from keystoneclient.openstack.common import memorycache # alternative middleware configuration in the main application's # configuration file e.g. in nova.conf # [keystone_authtoken] # auth_host = 127.0.0.1 # auth_port = 35357 # auth_protocol = http # admin_tenant_name = admin # admin_user = admin # admin_password = badpassword # when deploy Keystone auth_token middleware with Swift, user may elect # to use Swift memcache instead of the local Keystone memcache. Swift memcache # is passed in from the request environment and its identified by the # 'swift.cache' key. However it could be different, depending on deployment. # To use Swift memcache, you must set the 'cache' option to the environment # key where the Swift cache object is stored. # NOTE(jamielennox): A number of options below are deprecated however are left # in the list and only mentioned as deprecated in the help string. This is # because we have to provide the same deprecation functionality for arguments # passed in via the conf in __init__ (from paste) and there is no way to test # that the default value was set or not in CONF. # Also if we were to remove the options from the CONF list (as typical CONF # deprecation works) then other projects will not be able to override the # options via CONF. opts = [ cfg.StrOpt('auth_admin_prefix', default='', help='Prefix to prepend at the beginning of the path. ' 'Deprecated, use identity_uri.'), cfg.StrOpt('auth_host', default='127.0.0.1', help='Host providing the admin Identity API endpoint. ' 'Deprecated, use identity_uri.'), cfg.IntOpt('auth_port', default=35357, help='Port of the admin Identity API endpoint. ' 'Deprecated, use identity_uri.'), cfg.StrOpt('auth_protocol', default='https', help='Protocol of the admin Identity API endpoint ' '(http or https). Deprecated, use identity_uri.'), cfg.StrOpt('auth_uri', default=None, # FIXME(dolph): should be default='http://127.0.0.1:5000/v2.0/', # or (depending on client support) an unversioned, publicly # accessible identity endpoint (see bug 1207517) help='Complete public Identity API endpoint'), cfg.StrOpt('identity_uri', default=None, help='Complete admin Identity API endpoint. This should ' 'specify the unversioned root endpoint ' 'e.g. https://localhost:35357/'), cfg.StrOpt('auth_version', default=None, help='API version of the admin Identity API endpoint'), cfg.BoolOpt('delay_auth_decision', default=False, help='Do not handle authorization requests within the' ' middleware, but delegate the authorization decision to' ' downstream WSGI components'), cfg.BoolOpt('http_connect_timeout', default=None, help='Request timeout value for communicating with Identity' ' API server.'), cfg.IntOpt('http_request_max_retries', default=3, help='How many times are we trying to reconnect when' ' communicating with Identity API Server.'), cfg.StrOpt('admin_token', secret=True, help='This option is deprecated and may be removed in a future' ' release. Single shared secret with the Keystone configuration' ' used for bootstrapping a Keystone installation, or otherwise' ' bypassing the normal authentication process. This option' ' should not be used, use `admin_user` and `admin_password`' ' instead.'), cfg.StrOpt('admin_user', help='Keystone account username'), cfg.StrOpt('admin_password', secret=True, help='Keystone account password'), cfg.StrOpt('admin_tenant_name', default='admin', help='Keystone service account tenant name to validate' ' user tokens'), cfg.StrOpt('cache', default=None, help='Env key for the swift cache'), cfg.StrOpt('certfile', help='Required if Keystone server requires client certificate'), cfg.StrOpt('keyfile', help='Required if Keystone server requires client certificate'), cfg.StrOpt('cafile', default=None, help='A PEM encoded Certificate Authority to use when ' 'verifying HTTPs connections. Defaults to system CAs.'), cfg.BoolOpt('insecure', default=False, help='Verify HTTPS connections.'), cfg.StrOpt('signing_dir', help='Directory used to cache files related to PKI tokens'), cfg.ListOpt('memcached_servers', deprecated_name='memcache_servers', help='Optionally specify a list of memcached server(s) to' ' use for caching. If left undefined, tokens will instead be' ' cached in-process.'), cfg.IntOpt('token_cache_time', default=300, help='In order to prevent excessive effort spent validating' ' tokens, the middleware caches previously-seen tokens for a' ' configurable duration (in seconds). Set to -1 to disable' ' caching completely.'), cfg.IntOpt('revocation_cache_time', default=10, help='Determines the frequency at which the list of revoked' ' tokens is retrieved from the Identity service (in seconds). A' ' high number of revocation events combined with a low cache' ' duration may significantly reduce performance.'), cfg.StrOpt('memcache_security_strategy', default=None, help='(optional) if defined, indicate whether token data' ' should be authenticated or authenticated and encrypted.' ' Acceptable values are MAC or ENCRYPT. If MAC, token data is' ' authenticated (with HMAC) in the cache. If ENCRYPT, token' ' data is encrypted and authenticated in the cache. If the' ' value is not one of these options or empty, auth_token will' ' raise an exception on initialization.'), cfg.StrOpt('memcache_secret_key', default=None, secret=True, help='(optional, mandatory if memcache_security_strategy is' ' defined) this string is used for key derivation.'), cfg.BoolOpt('include_service_catalog', default=True, help='(optional) indicate whether to set the X-Service-Catalog' ' header. If False, middleware will not ask for service' ' catalog on token validation and will not set the' ' X-Service-Catalog header.'), cfg.StrOpt('enforce_token_bind', default='permissive', help='Used to control the use and type of token binding. Can' ' be set to: ""disabled"" to not check token binding.' ' ""permissive"" (default) to validate binding information if the' ' bind type is of a form known to the server and ignore it if' ' not. ""strict"" like ""permissive"" but if the bind type is' ' unknown the token will be rejected. ""required"" any form of' ' token binding is needed to be allowed. Finally the name of a' ' binding method that must be present in tokens.'), cfg.BoolOpt('check_revocations_for_cached', default=False, help='If true, the revocation list will be checked for cached' ' tokens. This requires that PKI tokens are configured on the' ' Keystone server.'), cfg.ListOpt('hash_algorithms', default=['md5'], help='Hash algorithms to use for hashing PKI tokens. This may' ' be a single algorithm or multiple. The algorithms are those' ' supported by Python standard hashlib.new(). The hashes will' ' be tried in the order given, so put the preferred one first' ' for performance. The result of the first hash will be stored' ' in the cache. This will typically be set to multiple values' ' only while migrating from a less secure algorithm to a more' ' secure one. Once all the old tokens are expired this option' ' should be set to a single value for better performance.'), ] CONF = cfg.CONF CONF.register_opts(opts, group='keystone_authtoken') LIST_OF_VERSIONS_TO_ATTEMPT = ['v2.0', 'v3.0'] CACHE_KEY_TEMPLATE = 'tokens/%s' class BIND_MODE(object): DISABLED = 'disabled' PERMISSIVE = 'permissive' STRICT = 'strict' REQUIRED = 'required' KERBEROS = 'kerberos' def will_expire_soon(expiry): """"""Determines if expiration is about to occur. :param expiry: a datetime of the expected expiration :returns: boolean : true if expiration is within 30 seconds """""" soon = (timeutils.utcnow() + datetime.timedelta(seconds=30)) return expiry < soon def _token_is_v2(token_info): return ('access' in token_info) def _token_is_v3(token_info): return ('token' in token_info) def confirm_token_not_expired(data): if not data: raise InvalidUserToken('Token authorization failed') if _token_is_v2(data): timestamp = data['access']['token']['expires'] elif _token_is_v3(data): timestamp = data['token']['expires_at'] else: raise InvalidUserToken('Token authorization failed') expires = timeutils.parse_isotime(timestamp) expires = timeutils.normalize_time(expires) utcnow = timeutils.utcnow() if utcnow >= expires: raise InvalidUserToken('Token authorization failed') return timeutils.isotime(at=expires, subsecond=True) def _v3_to_v2_catalog(catalog): """"""Convert a catalog to v2 format. X_SERVICE_CATALOG must be specified in v2 format. If you get a token that is in v3 convert it. """""" v2_services = [] for v3_service in catalog: # first copy over the entries we allow for the service v2_service = {'type': v3_service['type']} try: v2_service['name'] = v3_service['name'] except KeyError: pass # now convert the endpoints. Because in v3 we specify region per # URL not per group we have to collect all the entries of the same # region together before adding it to the new service. regions = {} for v3_endpoint in v3_service.get('endpoints', []): region_name = v3_endpoint.get('region') try: region = regions[region_name] except KeyError: region = {'region': region_name} if region_name else {} regions[region_name] = region interface_name = v3_endpoint['interface'].lower() + 'URL' region[interface_name] = v3_endpoint['url'] v2_service['endpoints'] = list(regions.values()) v2_services.append(v2_service) return v2_services def safe_quote(s): """"""URL-encode strings that are not already URL-encoded."""""" return urllib.parse.quote(s) if s == urllib.parse.unquote(s) else s def _conf_values_type_convert(conf): """"""Convert conf values into correct type."""""" if not conf: return {} _opts = {} opt_types = dict((o.dest, getattr(o, 'type', str)) for o in opts) for k, v in six.iteritems(conf): try: if v is None: _opts[k] = v else: _opts[k] = opt_types[k](v) except KeyError: _opts[k] = v except ValueError as e: raise ConfigurationError( 'Unable to convert the value of %s option into correct ' 'type: %s' % (k, e)) return _opts class InvalidUserToken(Exception): pass class ServiceError(Exception): pass class ConfigurationError(Exception): pass class NetworkError(Exception): pass class MiniResp(object): def __init__(self, error_message, env, headers=[]): # The HEAD method is unique: it must never return a body, even if # it reports an error (RFC-2616 clause 9.4). We relieve callers # from varying the error responses depending on the method. if env['REQUEST_METHOD'] == 'HEAD': self.body = [''] else: self.body = [error_message] self.headers = list(headers) self.headers.append(('Content-type', 'text/plain')) class AuthProtocol(object): """"""Auth Middleware that handles authenticating client calls."""""" def __init__(self, app, conf): self.LOG = logging.getLogger(conf.get('log_name', __name__)) self.LOG.info('Starting keystone auth_token middleware') self.LOG.warning( 'This middleware module is deprecated as of v0.10.0 in favor of ' 'keystonemiddleware.auth_token - please update your WSGI pipeline ' 'to reference the new middleware package.') # NOTE(wanghong): If options are set in paste file, all the option # values passed into conf are string type. So, we should convert the # conf value into correct type. self.conf = _conf_values_type_convert(conf) self.app = app # delay_auth_decision means we still allow unauthenticated requests # through and we let the downstream service make the final decision self.delay_auth_decision = (self._conf_get('delay_auth_decision') in (True, 'true', 't', '1', 'on', 'yes', 'y')) # where to find the auth service (we use this to validate tokens) self.identity_uri = self._conf_get('identity_uri') self.auth_uri = self._conf_get('auth_uri') # NOTE(jamielennox): it does appear here that our defaults arguments # are backwards. We need to do it this way so that we can handle the # same deprecation strategy for CONF and the conf variable. if not self.identity_uri: self.LOG.warning('Configuring admin URI using auth fragments. ' 'This is deprecated, use \'identity_uri\'' ' instead.') auth_host = self._conf_get('auth_host') auth_port = int(self._conf_get('auth_port')) auth_protocol = self._conf_get('auth_protocol') auth_admin_prefix = self._conf_get('auth_admin_prefix') if netaddr.valid_ipv6(auth_host): # Note(dzyu) it is an IPv6 address, so it needs to be wrapped # with '[]' to generate a valid IPv6 URL, based on # http://www.ietf.org/rfc/rfc2732.txt auth_host = '[%s]' % auth_host self.identity_uri = '%s://%s:%s' % (auth_protocol, auth_host, auth_port) if auth_admin_prefix: self.identity_uri = '%s/%s' % (self.identity_uri, auth_admin_prefix.strip('/')) else: self.identity_uri = self.identity_uri.rstrip('/') if self.auth_uri is None: self.LOG.warning( 'Configuring auth_uri to point to the public identity ' 'endpoint is required; clients may not be able to ' 'authenticate against an admin endpoint') # FIXME(dolph): drop support for this fallback behavior as # documented in bug 1207517. # NOTE(jamielennox): we urljoin '/' to get just the base URI as # this is the original behaviour. self.auth_uri = urllib.parse.urljoin(self.identity_uri, '/') self.auth_uri = self.auth_uri.rstrip('/') # SSL self.cert_file = self._conf_get('certfile') self.key_file = self._conf_get('keyfile') self.ssl_ca_file = self._conf_get('cafile') self.ssl_insecure = self._conf_get('insecure') # signing self.signing_dirname = self._conf_get('signing_dir') if self.signing_dirname is None: self.signing_dirname = tempfile.mkdtemp(prefix='keystone-signing-') self.LOG.info('Using %s as cache directory for signing certificate', self.signing_dirname) self.verify_signing_dir() val = '%s/signing_cert.pem' % self.signing_dirname self.signing_cert_file_name = val val = '%s/cacert.pem' % self.signing_dirname self.signing_ca_file_name = val val = '%s/revoked.pem' % self.signing_dirname self.revoked_file_name = val # Credentials used to verify this component with the Auth service since # validating tokens is a privileged call self.admin_token = self._conf_get('admin_token') if self.admin_token: self.LOG.warning( ""The admin_token option in the auth_token middleware is "" ""deprecated and should not be used. The admin_user and "" ""admin_password options should be used instead. The "" ""admin_token option may be removed in a future release."") self.admin_token_expiry = None self.admin_user = self._conf_get('admin_user') self.admin_password = self._conf_get('admin_password') self.admin_tenant_name = self._conf_get('admin_tenant_name') memcache_security_strategy = ( self._conf_get('memcache_security_strategy')) self._token_cache = TokenCache( self.LOG, cache_time=int(self._conf_get('token_cache_time')), hash_algorithms=self._conf_get('hash_algorithms'), env_cache_name=self._conf_get('cache'), memcached_servers=self._conf_get('memcached_servers'), memcache_security_strategy=memcache_security_strategy, memcache_secret_key=self._conf_get('memcache_secret_key')) self._token_revocation_list = None self._token_revocation_list_fetched_time = None self.token_revocation_list_cache_timeout = datetime.timedelta( seconds=self._conf_get('revocation_cache_time')) http_connect_timeout_cfg = self._conf_get('http_connect_timeout') self.http_connect_timeout = (http_connect_timeout_cfg and int(http_connect_timeout_cfg)) self.auth_version = None self.http_request_max_retries = ( self._conf_get('http_request_max_retries')) self.include_service_catalog = self._conf_get( 'include_service_catalog') self.check_revocations_for_cached = self._conf_get( 'check_revocations_for_cached') def _conf_get(self, name): # try config from paste-deploy first if name in self.conf: return self.conf[name] else: return CONF.keystone_authtoken[name] def _choose_api_version(self): """"""Determine the api version that we should use."""""" # If the configuration specifies an auth_version we will just # assume that is correct and use it. We could, of course, check # that this version is supported by the server, but in case # there are some problems in the field, we want as little code # as possible in the way of letting auth_token talk to the # server. if self._conf_get('auth_version'): version_to_use = self._conf_get('auth_version') self.LOG.info('Auth Token proceeding with requested %s apis', version_to_use) else: version_to_use = None versions_supported_by_server = self._get_supported_versions() if versions_supported_by_server: for version in LIST_OF_VERSIONS_TO_ATTEMPT: if version in versions_supported_by_server: version_to_use = version break if version_to_use: self.LOG.info('Auth Token confirmed use of %s apis', version_to_use) else: self.LOG.error( 'Attempted versions [%s] not in list supported by ' 'server [%s]', ', '.join(LIST_OF_VERSIONS_TO_ATTEMPT), ', '.join(versions_supported_by_server)) raise ServiceError('No compatible apis supported by server') return version_to_use def _get_supported_versions(self): versions = [] response, data = self._json_request('GET', '/') if response.status_code == 501: self.LOG.warning('Old keystone installation found...assuming v2.0') versions.append('v2.0') elif response.status_code != 300: self.LOG.error('Unable to get version info from keystone: %s', response.status_code) raise ServiceError('Unable to get version info from keystone') else: try: for version in data['versions']['values']: versions.append(version['id']) except KeyError: self.LOG.error( 'Invalid version response format from server') raise ServiceError('Unable to parse version response ' 'from keystone') self.LOG.debug('Server reports support for api versions: %s', ', '.join(versions)) return versions def __call__(self, env, start_response): """"""Handle incoming request. Authenticate send downstream on success. Reject request if we can't authenticate. """""" self.LOG.debug('Authenticating user token') self._token_cache.initialize(env) try: self._remove_auth_headers(env) user_token = self._get_user_token_from_header(env) token_info = self._validate_user_token(user_token, env) env['keystone.token_info'] = token_info user_headers = self._build_user_headers(token_info) self._add_headers(env, user_headers) return self.app(env, start_response) except InvalidUserToken: if self.delay_auth_decision: self.LOG.info( 'Invalid user token - deferring reject downstream') self._add_headers(env, {'X-Identity-Status': 'Invalid'}) return self.app(env, start_response) else: self.LOG.info('Invalid user token - rejecting request') return self._reject_request(env, start_response) except ServiceError as e: self.LOG.critical('Unable to obtain admin token: %s', e) resp = MiniResp('Service unavailable', env) start_response('503 Service Unavailable', resp.headers) return resp.body def _remove_auth_headers(self, env): """"""Remove headers so a user can't fake authentication. :param env: wsgi request environment """""" auth_headers = ( 'X-Identity-Status', 'X-Domain-Id', 'X-Domain-Name', 'X-Project-Id', 'X-Project-Name', 'X-Project-Domain-Id', 'X-Project-Domain-Name', 'X-User-Id', 'X-User-Name', 'X-User-Domain-Id', 'X-User-Domain-Name', 'X-Roles', 'X-Service-Catalog', # Deprecated 'X-User', 'X-Tenant-Id', 'X-Tenant-Name', 'X-Tenant', 'X-Role', ) self.LOG.debug('Removing headers from request environment: %s', ','.join(auth_headers)) self._remove_headers(env, auth_headers) def _get_user_token_from_header(self, env): """"""Get token id from request. :param env: wsgi request environment :return token id :raises InvalidUserToken if no token is provided in request """""" token = self._get_header(env, 'X-Auth-Token', self._get_header(env, 'X-Storage-Token')) if token: return token else: if not self.delay_auth_decision: self.LOG.warn('Unable to find authentication token' ' in headers') self.LOG.debug('Headers: %s', env) raise InvalidUserToken('Unable to find token in headers') def _reject_request(self, env, start_response): """"""Redirect client to auth server. :param env: wsgi request environment :param start_response: wsgi response callback :returns HTTPUnauthorized http response """""" headers = [('WWW-Authenticate', 'Keystone uri=\'%s\'' % self.auth_uri)] resp = MiniResp('Authentication required', env, headers) start_response('401 Unauthorized', resp.headers) return resp.body def get_admin_token(self): """"""Return admin token, possibly fetching a new one. if self.admin_token_expiry is set from fetching an admin token, check it for expiration, and request a new token is the existing token is about to expire. :return admin token id :raise ServiceError when unable to retrieve token from keystone """""" if self.admin_token_expiry: if will_expire_soon(self.admin_token_expiry): self.admin_token = None if not self.admin_token: (self.admin_token, self.admin_token_expiry) = self._request_admin_token() return self.admin_token def _http_request(self, method, path, **kwargs): """"""HTTP request helper used to make unspecified content type requests. :param method: http method :param path: relative request url :return (http response object, response body) :raise ServerError when unable to communicate with keystone """""" url = '%s/%s' % (self.identity_uri, path.lstrip('/')) kwargs.setdefault('timeout', self.http_connect_timeout) if self.cert_file and self.key_file: kwargs['cert'] = (self.cert_file, self.key_file) elif self.cert_file or self.key_file: self.LOG.warn('Cannot use only a cert or key file. ' 'Please provide both. Ignoring.') kwargs['verify'] = self.ssl_ca_file or True if self.ssl_insecure: kwargs['verify'] = False RETRIES = self.http_request_max_retries retry = 0 while True: try: response = requests.request(method, url, **kwargs) break except Exception as e: if retry >= RETRIES: self.LOG.error('HTTP connection exception: %s', e) raise NetworkError('Unable to communicate with keystone') # NOTE(vish): sleep 0.5, 1, 2 self.LOG.warn('Retrying on HTTP connection exception: %s', e) time.sleep(2.0 ** retry / 2) retry += 1 return response def _json_request(self, method, path, body=None, additional_headers=None): """"""HTTP request helper used to make json requests. :param method: http method :param path: relative request url :param body: dict to encode to json as request body. Optional. :param additional_headers: dict of additional headers to send with http request. Optional. :return (http response object, response body parsed as json) :raise ServerError when unable to communicate with keystone """""" kwargs = { 'headers': { 'Content-type': 'application/json', 'Accept': 'application/json', }, } if additional_headers: kwargs['headers'].update(additional_headers) if body: kwargs['data'] = jsonutils.dumps(body) response = self._http_request(method, path, **kwargs) try: data = jsonutils.loads(response.text) except ValueError: self.LOG.debug('Keystone did not return json-encoded body') data = {} return response, data def _request_admin_token(self): """"""Retrieve new token as admin user from keystone. :return token id upon success :raises ServerError when unable to communicate with keystone Irrespective of the auth version we are going to use for the user token, for simplicity we always use a v2 admin token to validate the user token. """""" params = { 'auth': { 'passwordCredentials': { 'username': self.admin_user, 'password': self.admin_password, }, 'tenantName': self.admin_tenant_name, } } response, data = self._json_request('POST', '/v2.0/tokens', body=params) try: token = data['access']['token']['id'] expiry = data['access']['token']['expires'] if not (token and expiry): raise AssertionError('invalid token or expire') datetime_expiry = timeutils.parse_isotime(expiry) return (token, timeutils.normalize_time(datetime_expiry)) except (AssertionError, KeyError): self.LOG.warn( 'Unexpected response from keystone service: %s', data) raise ServiceError('invalid json response') except (ValueError): data['access']['token']['id'] = '<SANITIZED>' self.LOG.warn( 'Unable to parse expiration time from token: %s', data) raise ServiceError('invalid json response') def _validate_user_token(self, user_token, env, retry=True): """"""Authenticate user token :param user_token: user's token id :param retry: Ignored, as it is not longer relevant :return uncrypted body of the token if the token is valid :raise InvalidUserToken if token is rejected :no longer raises ServiceError since it no longer makes RPC """""" token_id = None try: token_ids, cached = self._token_cache.get(user_token) token_id = token_ids[0] if cached: data = cached if self.check_revocations_for_cached: # A token stored in Memcached might have been revoked # regardless of initial mechanism used to validate it, # and needs to be checked. for tid in token_ids: is_revoked = self._is_token_id_in_revoked_list(tid) if is_revoked: self.LOG.debug( 'Token is marked as having been revoked') raise InvalidUserToken( 'Token authorization failed') elif cms.is_pkiz(user_token): verified = self.verify_pkiz_token(user_token, token_ids) data = jsonutils.loads(verified) elif cms.is_asn1_token(user_token): verified = self.verify_signed_token(user_token, token_ids) data = jsonutils.loads(verified) else: data = self.verify_uuid_token(user_token, retry) expires = confirm_token_not_expired(data) self._confirm_token_bind(data, env) self._token_cache.store(token_id, data, expires) return data except NetworkError: self.LOG.debug('Token validation failure.', exc_info=True) self.LOG.warn('Authorization failed for token') raise InvalidUserToken('Token authorization failed') except Exception: self.LOG.debug('Token validation failure.', exc_info=True) if token_id: self._token_cache.store_invalid(token_id) self.LOG.warn('Authorization failed for token') raise InvalidUserToken('Token authorization failed') def _build_user_headers(self, token_info): """"""Convert token object into headers. Build headers that represent authenticated user - see main doc info at start of file for details of headers to be defined. :param token_info: token object returned by keystone on authentication :raise InvalidUserToken when unable to parse token object """""" auth_ref = access.AccessInfo.factory(body=token_info) roles = ','.join(auth_ref.role_names) if _token_is_v2(token_info) and not auth_ref.project_id: raise InvalidUserToken('Unable to determine tenancy.') rval = { 'X-Identity-Status': 'Confirmed', 'X-Domain-Id': auth_ref.domain_id, 'X-Domain-Name': auth_ref.domain_name, 'X-Project-Id': auth_ref.project_id, 'X-Project-Name': auth_ref.project_name, 'X-Project-Domain-Id': auth_ref.project_domain_id, 'X-Project-Domain-Name': auth_ref.project_domain_name, 'X-User-Id': auth_ref.user_id, 'X-User-Name': auth_ref.username, 'X-User-Domain-Id': auth_ref.user_domain_id, 'X-User-Domain-Name': auth_ref.user_domain_name, 'X-Roles': roles, # Deprecated 'X-User': auth_ref.username, 'X-Tenant-Id': auth_ref.project_id, 'X-Tenant-Name': auth_ref.project_name, 'X-Tenant': auth_ref.project_name, 'X-Role': roles, } self.LOG.debug('Received request from user: %s with project_id : %s' ' and roles: %s ', auth_ref.user_id, auth_ref.project_id, roles) if self.include_service_catalog and auth_ref.has_service_catalog(): catalog = auth_ref.service_catalog.get_data() if _token_is_v3(token_info): catalog = _v3_to_v2_catalog(catalog) rval['X-Service-Catalog'] = jsonutils.dumps(catalog) return rval def _header_to_env_var(self, key): """"""Convert header to wsgi env variable. :param key: http header name (ex. 'X-Auth-Token') :return wsgi env variable name (ex. 'HTTP_X_AUTH_TOKEN') """""" return 'HTTP_%s' % key.replace('-', '_').upper() def _add_headers(self, env, headers): """"""Add http headers to environment."""""" for (k, v) in six.iteritems(headers): env_key = self._header_to_env_var(k) env[env_key] = v def _remove_headers(self, env, keys): """"""Remove http headers from environment."""""" for k in keys: env_key = self._header_to_env_var(k) try: del env[env_key] except KeyError: pass def _get_header(self, env, key, default=None): """"""Get http header from environment."""""" env_key = self._header_to_env_var(key) return env.get(env_key, default) def _invalid_user_token(self, msg=False): # NOTE(jamielennox): use False as the default so that None is valid if msg is False: msg = 'Token authorization failed' raise InvalidUserToken(msg) def _confirm_token_bind(self, data, env): bind_mode = self._conf_get('enforce_token_bind') if bind_mode == BIND_MODE.DISABLED: return try: if _token_is_v2(data): bind = data['access']['token']['bind'] elif _token_is_v3(data): bind = data['token']['bind'] else: self._invalid_user_token() except KeyError: bind = {} # permissive and strict modes don't require there to be a bind permissive = bind_mode in (BIND_MODE.PERMISSIVE, BIND_MODE.STRICT) if not bind: if permissive: # no bind provided and none required return else: self.LOG.info('No bind information present in token.') self._invalid_user_token() # get the named mode if bind_mode is not one of the predefined if permissive or bind_mode == BIND_MODE.REQUIRED: name = None else: name = bind_mode if name and name not in bind: self.LOG.info('Named bind mode %s not in bind information', name) self._invalid_user_token() for bind_type, identifier in six.iteritems(bind): if bind_type == BIND_MODE.KERBEROS: if not env.get('AUTH_TYPE', '').lower() == 'negotiate': self.LOG.info('Kerberos credentials required and ' 'not present.') self._invalid_user_token() if not env.get('REMOTE_USER') == identifier: self.LOG.info('Kerberos credentials do not match ' 'those in bind.') self._invalid_user_token() self.LOG.debug('Kerberos bind authentication successful.') elif bind_mode == BIND_MODE.PERMISSIVE: self.LOG.debug('Ignoring Unknown bind for permissive mode: ' '%(bind_type)s: %(identifier)s.', {'bind_type': bind_type, 'identifier': identifier}) else: self.LOG.info('Couldn`t verify unknown bind: %(bind_type)s: ' '%(identifier)s.', {'bind_type': bind_type, 'identifier': identifier}) self._invalid_user_token() def verify_uuid_token(self, user_token, retry=True): """"""Authenticate user token with keystone. :param user_token: user's token id :param retry: flag that forces the middleware to retry user authentication when an indeterminate response is received. Optional. :returns: token object received from keystone on success :raise InvalidUserToken: if token is rejected :raise ServiceError: if unable to authenticate token """""" # Determine the highest api version we can use. if not self.auth_version: self.auth_version = self._choose_api_version() if self.auth_version == 'v3.0': headers = {'X-Auth-Token': self.get_admin_token(), 'X-Subject-Token': safe_quote(user_token)} path = '/v3/auth/tokens' if not self.include_service_catalog: # NOTE(gyee): only v3 API support this option path = path + '?nocatalog' response, data = self._json_request( 'GET', path, additional_headers=headers) else: headers = {'X-Auth-Token': self.get_admin_token()} response, data = self._json_request( 'GET', '/v2.0/tokens/%s' % safe_quote(user_token), additional_headers=headers) if response.status_code == 200: return data if response.status_code == 404: self.LOG.warn('Authorization failed for token') raise InvalidUserToken('Token authorization failed') if response.status_code == 401: self.LOG.info( 'Keystone rejected admin token, resetting') self.admin_token = None else: self.LOG.error('Bad response code while validating token: %s', response.status_code) if retry: self.LOG.info('Retrying validation') return self.verify_uuid_token(user_token, False) else: self.LOG.warn('Invalid user token. Keystone response: %s', data) raise InvalidUserToken() def is_signed_token_revoked(self, token_ids): """"""Indicate whether the token appears in the revocation list."""""" for token_id in token_ids: if self._is_token_id_in_revoked_list(token_id): self.LOG.debug('Token is marked as having been revoked') return True return False def _is_token_id_in_revoked_list(self, token_id): """"""Indicate whether the token_id appears in the revocation list."""""" revocation_list = self.token_revocation_list revoked_tokens = revocation_list.get('revoked', None) if not revoked_tokens: return False revoked_ids = (x['id'] for x in revoked_tokens) return token_id in revoked_ids def cms_verify(self, data, inform=cms.PKI_ASN1_FORM): """"""Verifies the signature of the provided data's IAW CMS syntax. If either of the certificate files might be missing, fetch them and retry. """""" def verify(): try: return cms.cms_verify(data, self.signing_cert_file_name, self.signing_ca_file_name, inform=inform).decode('utf-8') except cms.subprocess.CalledProcessError as err: self.LOG.warning('Verify error: %s', err) raise try: return verify() except exceptions.CertificateConfigError: # the certs might be missing; unconditionally fetch to avoid racing self.fetch_signing_cert() self.fetch_ca_cert() try: # retry with certs in place return verify() except exceptions.CertificateConfigError as err: # if this is still occurring, something else is wrong and we # need err.output to identify the problem self.LOG.error('CMS Verify output: %s', err.output) raise def verify_signed_token(self, signed_text, token_ids): """"""Check that the token is unrevoked and has a valid signature."""""" if self.is_signed_token_revoked(token_ids): raise InvalidUserToken('Token has been revoked') formatted = cms.token_to_cms(signed_text) verified = self.cms_verify(formatted) return verified def verify_pkiz_token(self, signed_text, token_ids): if self.is_signed_token_revoked(token_ids): raise InvalidUserToken('Token has been revoked') try: uncompressed = cms.pkiz_uncompress(signed_text) verified = self.cms_verify(uncompressed, inform=cms.PKIZ_CMS_FORM) return verified # TypeError If the signed_text is not zlib compressed except TypeError: raise InvalidUserToken(signed_text) def verify_signing_dir(self): if os.path.exists(self.signing_dirname): if not os.access(self.signing_dirname, os.W_OK): raise ConfigurationError( 'unable to access signing_dir %s' % self.signing_dirname) uid = os.getuid() if os.stat(self.signing_dirname).st_uid != uid: self.LOG.warning( 'signing_dir is not owned by %s', uid) current_mode = stat.S_IMODE(os.stat(self.signing_dirname).st_mode) if current_mode != stat.S_IRWXU: self.LOG.warning( 'signing_dir mode is %s instead of %s', oct(current_mode), oct(stat.S_IRWXU)) else: os.makedirs(self.signing_dirname, stat.S_IRWXU) @property def token_revocation_list_fetched_time(self): if not self._token_revocation_list_fetched_time: # If the fetched list has been written to disk, use its # modification time. if os.path.exists(self.revoked_file_name): mtime = os.path.getmtime(self.revoked_file_name) fetched_time = datetime.datetime.utcfromtimestamp(mtime) # Otherwise the list will need to be fetched. else: fetched_time = datetime.datetime.min self._token_revocation_list_fetched_time = fetched_time return self._token_revocation_list_fetched_time @token_revocation_list_fetched_time.setter def token_revocation_list_fetched_time(self, value): self._token_revocation_list_fetched_time = value @property def token_revocation_list(self): timeout = (self.token_revocation_list_fetched_time + self.token_revocation_list_cache_timeout) list_is_current = timeutils.utcnow() < timeout if list_is_current: # Load the list from disk if required if not self._token_revocation_list: open_kwargs = {'encoding': 'utf-8'} if six.PY3 else {} with open(self.revoked_file_name, 'r', **open_kwargs) as f: self._token_revocation_list = jsonutils.loads(f.read()) else: self.token_revocation_list = self.fetch_revocation_list() return self._token_revocation_list def _atomic_write_to_signing_dir(self, file_name, value): # In Python2, encoding is slow so the following check avoids it if it # is not absolutely necessary. if isinstance(value, six.text_type): value = value.encode('utf-8') def _atomic_write(destination, data): with tempfile.NamedTemporaryFile(dir=self.signing_dirname, delete=False) as f: f.write(data) os.rename(f.name, destination) try: _atomic_write(file_name, value) except (OSError, IOError): self.verify_signing_dir() _atomic_write(file_name, value) @token_revocation_list.setter def token_revocation_list(self, value): """"""Save a revocation list to memory and to disk. :param value: A json-encoded revocation list """""" self._token_revocation_list = jsonutils.loads(value) self.token_revocation_list_fetched_time = timeutils.utcnow() self._atomic_write_to_signing_dir(self.revoked_file_name, value) def fetch_revocation_list(self, retry=True): headers = {'X-Auth-Token': self.get_admin_token()} response, data = self._json_request('GET', '/v2.0/tokens/revoked', additional_headers=headers) if response.status_code == 401: if retry: self.LOG.info( 'Keystone rejected admin token, resetting admin token') self.admin_token = None return self.fetch_revocation_list(retry=False) if response.status_code != 200: raise ServiceError('Unable to fetch token revocation list.') if 'signed' not in data: raise ServiceError('Revocation list improperly formatted.') return self.cms_verify(data['signed']) def _fetch_cert_file(self, cert_file_name, cert_type): if not self.auth_version: self.auth_version = self._choose_api_version() if self.auth_version == 'v3.0': if cert_type == 'signing': cert_type = 'certificates' path = '/v3/OS-SIMPLE-CERT/' + cert_type else: path = '/v2.0/certificates/' + cert_type response = self._http_request('GET', path) if response.status_code != 200: raise exceptions.CertificateConfigError(response.text) self._atomic_write_to_signing_dir(cert_file_name, response.text) def fetch_signing_cert(self): self._fetch_cert_file(self.signing_cert_file_name, 'signing') def fetch_ca_cert(self): self._fetch_cert_file(self.signing_ca_file_name, 'ca') class CachePool(list): """"""A lazy pool of cache references."""""" def __init__(self, cache, memcached_servers): self._environment_cache = cache self._memcached_servers = memcached_servers @contextlib.contextmanager def reserve(self): """"""Context manager to manage a pooled cache reference."""""" if self._environment_cache is not None: # skip pooling and just use the cache from the upstream filter yield self._environment_cache return # otherwise the context manager will continue! try: c = self.pop() except IndexError: # the pool is empty, so we need to create a new client c = memorycache.get_client(self._memcached_servers) try: yield c finally: self.append(c) class TokenCache(object): """"""Encapsulates the auth_token token cache functionality. auth_token caches tokens that it's seen so that when a token is re-used the middleware doesn't have to do a more expensive operation (like going to the identity server) to validate the token. initialize() must be called before calling the other methods. Store a valid token in the cache using store(); mark a token as invalid in the cache using store_invalid(). Check if a token is in the cache and retrieve it using get(). """""" _INVALID_INDICATOR = 'invalid' def __init__(self, log, cache_time=None, hash_algorithms=None, env_cache_name=None, memcached_servers=None, memcache_security_strategy=None, memcache_secret_key=None): self.LOG = log self._cache_time = cache_time self._hash_algorithms = hash_algorithms self._env_cache_name = env_cache_name self._memcached_servers = memcached_servers # memcache value treatment, ENCRYPT or MAC self._memcache_security_strategy = memcache_security_strategy if self._memcache_security_strategy is not None: self._memcache_security_strategy = ( self._memcache_security_strategy.upper()) self._memcache_secret_key = memcache_secret_key self._cache_pool = None self._initialized = False self._assert_valid_memcache_protection_config() def initialize(self, env): if self._initialized: return self._cache_pool = CachePool(env.get(self._env_cache_name), self._memcached_servers) self._initialized = True def get(self, user_token): """"""Check if the token is cached already. Returns a tuple. The first element is a list of token IDs, where the first one is the preferred hash. The second element is the token data from the cache if the token was cached, otherwise ``None``. :raises InvalidUserToken: if the token is invalid """""" if cms.is_asn1_token(user_token) or cms.is_pkiz(user_token): # user_token is a PKI token that's not hashed. token_hashes = list(cms.cms_hash_token(user_token, mode=algo) for algo in self._hash_algorithms) for token_hash in token_hashes: cached = self._cache_get(token_hash) if cached: return (token_hashes, cached) # The token wasn't found using any hash algorithm. return (token_hashes, None) # user_token is either a UUID token or a hashed PKI token. token_id = user_token cached = self._cache_get(token_id) return ([token_id], cached) def store(self, token_id, data, expires): """"""Put token data into the cache. Stores the parsed expire date in cache allowing quick check of token freshness on retrieval. """""" self.LOG.debug('Storing token in cache') self._cache_store(token_id, (data, expires)) def store_invalid(self, token_id): """"""Store invalid token in cache."""""" self.LOG.debug('Marking token as unauthorized in cache') self._cache_store(token_id, self._INVALID_INDICATOR) def _assert_valid_memcache_protection_config(self): if self._memcache_security_strategy: if self._memcache_security_strategy not in ('MAC', 'ENCRYPT'): raise ConfigurationError('memcache_security_strategy must be ' 'ENCRYPT or MAC') if not self._memcache_secret_key: raise ConfigurationError('memcache_secret_key must be defined ' 'when a memcache_security_strategy ' 'is defined') def _cache_get(self, token_id): """"""Return token information from cache. If token is invalid raise InvalidUserToken return token only if fresh (not expired). """""" if not token_id: # Nothing to do return if self._memcache_security_strategy is None: key = CACHE_KEY_TEMPLATE % token_id with self._cache_pool.reserve() as cache: serialized = cache.get(key) else: secret_key = self._memcache_secret_key if isinstance(secret_key, six.string_types): secret_key = secret_key.encode('utf-8') security_strategy = self._memcache_security_strategy if isinstance(security_strategy, six.string_types): security_strategy = security_strategy.encode('utf-8') keys = memcache_crypt.derive_keys( token_id, secret_key, security_strategy) cache_key = CACHE_KEY_TEMPLATE % ( memcache_crypt.get_cache_key(keys)) with self._cache_pool.reserve() as cache: raw_cached = cache.get(cache_key) try: # unprotect_data will return None if raw_cached is None serialized = memcache_crypt.unprotect_data(keys, raw_cached) except Exception: msg = 'Failed to decrypt/verify cache data' self.LOG.exception(msg) # this should have the same effect as data not # found in cache serialized = None if serialized is None: return None # Note that _INVALID_INDICATOR and (data, expires) are the only # valid types of serialized cache entries, so there is not # a collision with jsonutils.loads(serialized) == None. if not isinstance(serialized, six.string_types): serialized = serialized.decode('utf-8') cached = jsonutils.loads(serialized) if cached == self._INVALID_INDICATOR: self.LOG.debug('Cached Token is marked unauthorized') raise InvalidUserToken('Token authorization failed') data, expires = cached try: expires = timeutils.parse_isotime(expires) except ValueError: # Gracefully handle upgrade of expiration times from *nix # timestamps to ISO 8601 formatted dates by ignoring old cached # values. return expires = timeutils.normalize_time(expires) utcnow = timeutils.utcnow() if utcnow < expires: self.LOG.debug('Returning cached token') return data else: self.LOG.debug('Cached Token seems expired') raise InvalidUserToken('Token authorization failed') def _cache_store(self, token_id, data): """"""Store value into memcache. data may be _INVALID_INDICATOR or a tuple like (data, expires) """""" serialized_data = jsonutils.dumps(data) if isinstance(serialized_data, six.text_type): serialized_data = serialized_data.encode('utf-8') if self._memcache_security_strategy is None: cache_key = CACHE_KEY_TEMPLATE % token_id data_to_store = serialized_data else: secret_key = self._memcache_secret_key if isinstance(secret_key, six.string_types): secret_key = secret_key.encode('utf-8') security_strategy = self._memcache_security_strategy if isinstance(security_strategy, six.string_types): security_strategy = security_strategy.encode('utf-8') keys = memcache_crypt.derive_keys( token_id, secret_key, security_strategy) cache_key = CACHE_KEY_TEMPLATE % memcache_crypt.get_cache_key(keys) data_to_store = memcache_crypt.protect_data(keys, serialized_data) with self._cache_pool.reserve() as cache: cache.set(cache_key, data_to_store, time=self._cache_time) def filter_factory(global_conf, **local_conf): """"""Returns a WSGI filter app for use with paste.deploy."""""" conf = global_conf.copy() conf.update(local_conf) def auth_filter(app): return AuthProtocol(app, conf) return auth_filter def app_factory(global_conf, **local_conf): conf = global_conf.copy() conf.update(local_conf) return AuthProtocol(None, conf) if __name__ == '__main__': """"""Run this module directly to start a protected echo service:: $ python -m keystoneclient.middleware.auth_token When the ``auth_token`` module authenticates a request, the echo service will respond with all the environment variables presented to it by this module. """""" def echo_app(environ, start_response): """"""A WSGI application that echoes the CGI environment to the user."""""" start_response('200 OK', [('Content-Type', 'application/json')]) environment = dict((k, v) for k, v in six.iteritems(environ) if k.startswith('HTTP_X_')) yield jsonutils.dumps(environment) from wsgiref import simple_server # hardcode any non-default configuration here conf = {'auth_protocol': 'http', 'admin_token': 'ADMIN'} app = AuthProtocol(echo_app, conf) server = simple_server.make_server('', 8000, app) print('Serving on port 8000 (Ctrl+C to end)...') server.serve_forever() ",0,4409
openstack%2Fhacking~master~Icc3875d6bf97ab10011c17c89244564045efc759,openstack/hacking,master,Icc3875d6bf97ab10011c17c89244564045efc759,Add a six-related checker,ABANDONED,2014-03-13 03:34:33.000000000,2015-05-21 17:25:45.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2472}, {'_account_id': 9107}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-03-13 03:34:33.000000000', 'files': ['hacking/core.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/hacking/commit/b76d3507b9dccc5dc32172ae47b3e1532302bf0e', 'message': 'Add a six-related checker\n\nThis checker allows people to write code that works with Python 2 and 3 by\npointing out Python2-isms that can easily be replaced by calls to methods from\nthe six module.\n\nChange-Id: Icc3875d6bf97ab10011c17c89244564045efc759\n'}]",2,80171,b76d3507b9dccc5dc32172ae47b3e1532302bf0e,17,6,1,8122,,,0,"Add a six-related checker

This checker allows people to write code that works with Python 2 and 3 by
pointing out Python2-isms that can easily be replaced by calls to methods from
the six module.

Change-Id: Icc3875d6bf97ab10011c17c89244564045efc759
",git fetch https://review.opendev.org/openstack/hacking refs/changes/71/80171/1 && git format-patch -1 --stdout FETCH_HEAD,"['hacking/core.py', 'setup.cfg']",2,b76d3507b9dccc5dc32172ae47b3e1532302bf0e,add_six_checker, H238 = hacking.core:hacking_use_six,,22,0
openstack%2Fneutron~master~I3c7366c69b10c202c0511126fbee6b3aac36759e,openstack/neutron,master,I3c7366c69b10c202c0511126fbee6b3aac36759e,Block subnet create when a network hosts subnets allocated from different pools,MERGED,2015-05-05 20:08:34.000000000,2015-05-21 17:24:00.000000000,2015-05-21 17:23:57.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12524}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14258}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}, {'_account_id': 15882}]","[{'number': 1, 'created': '2015-05-05 20:08:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/befb63ebcf73b36181ff7aa4425b86054cc97e76', 'message': 'Block subnet create when network hosts subnets allocated from different pools\n\nThis change will ensure that all subnets on a given network have been\nallocated from the same subnet pool. This provides cleaner subnet\noverlap detection.\n\nChange-Id: I3c7366c69b10c202c0511126fbee6b3aac36759e\nCloses-Bug: #1451559\n'}, {'number': 2, 'created': '2015-05-08 04:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea852c1b3d1cd428407a34df08d375bb188b4f52', 'message': 'Block subnet create when a network hosts subnets allocated from different pools\n\nThis change will ensure that all subnets with the same ip_version on a given\nnetwork have been allocated from the same subnet pool or no pool. This\nprovides cleaner subnet overlap detection.\n\nChange-Id: I3c7366c69b10c202c0511126fbee6b3aac36759e\nCloses-Bug: #1451559\n'}, {'number': 3, 'created': '2015-05-08 04:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9eec673081e634a55b87a7bd8b85e97e7a3cb4d0', 'message': 'Block subnet create when a network hosts subnets allocated from different pools\n\nThis change will ensure that all subnets with the same ip_version on a given\nnetwork have been allocated from the same subnet pool or no pool. This\nprovides cleaner subnet overlap detection.\n\nChange-Id: I3c7366c69b10c202c0511126fbee6b3aac36759e\nCloses-Bug: #1451559\n'}, {'number': 4, 'created': '2015-05-11 18:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8b9057b147cca75a4f624d208dcef8b75f387c82', 'message': 'Block subnet create when a network hosts subnets allocated from different pools\n\nThis change will ensure that all subnets with the same ip_version on a given\nnetwork have been allocated from the same subnet pool or no pool. This\nprovides cleaner subnet overlap detection.\n\nChange-Id: I3c7366c69b10c202c0511126fbee6b3aac36759e\nCloses-Bug: #1451559\n'}, {'number': 5, 'created': '2015-05-12 15:42:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f80d0e2229ca5f93cefcfdc7aaf37911b5526c9', 'message': 'Block subnet create when a network hosts subnets allocated from different pools\n\nThis change will ensure that all subnets with the same ip_version on a given\nnetwork have been allocated from the same subnet pool or no pool. This\nprovides cleaner subnet overlap detection.\n\nChange-Id: I3c7366c69b10c202c0511126fbee6b3aac36759e\nCloses-Bug: #1451559\n'}, {'number': 6, 'created': '2015-05-13 20:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5dd788747586447f3fe75562162e94d6767292bf', 'message': 'Block subnet create when a network hosts subnets allocated from different pools\n\nThis change will ensure that all subnets with the same ip_version on a given\nnetwork have been allocated from the same subnet pool or no pool. This\nprovides cleaner subnet overlap detection.\n\nChange-Id: I3c7366c69b10c202c0511126fbee6b3aac36759e\nCloses-Bug: #1451559\n'}, {'number': 7, 'created': '2015-05-13 22:23:59.000000000', 'files': ['neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/tests/api/test_subnetpools.py', 'neutron/tests/api/test_subnetpools_negative.py', 'neutron/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/251f551a5fe8fe05cdc8c9b9cfad357245b39bb9', 'message': 'Block subnet create when a network hosts subnets allocated from different pools\n\nThis change will ensure that all subnets with the same ip_version on a given\nnetwork have been allocated from the same subnet pool or no pool. This\nprovides cleaner subnet overlap detection.\n\nChange-Id: I3c7366c69b10c202c0511126fbee6b3aac36759e\nCloses-Bug: #1451559\n'}]",12,180299,251f551a5fe8fe05cdc8c9b9cfad357245b39bb9,192,36,7,4187,,,0,"Block subnet create when a network hosts subnets allocated from different pools

This change will ensure that all subnets with the same ip_version on a given
network have been allocated from the same subnet pool or no pool. This
provides cleaner subnet overlap detection.

Change-Id: I3c7366c69b10c202c0511126fbee6b3aac36759e
Closes-Bug: #1451559
",git fetch https://review.opendev.org/openstack/neutron refs/changes/99/180299/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/tests/api/test_subnetpools_negative.py', 'neutron/common/exceptions.py']",4,befb63ebcf73b36181ff7aa4425b86054cc97e76,," class NetworkSubnetPoolAffinityError(BadRequest): message = _(""Subnets hosted on the same network must be allocated from "" ""the same subnet pool"")",,44,0
openstack%2Fcue~master~I3c757d123e7b8369769cd1f49672a5c07fe01ec5,openstack/cue,master,I3c757d123e7b8369769cd1f49672a5c07fe01ec5,Updating API Context hook header data extraction for context,MERGED,2015-05-09 01:46:59.000000000,2015-05-21 17:23:33.000000000,2015-05-21 17:23:32.000000000,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 5390}, {'_account_id': 10584}, {'_account_id': 13771}]","[{'number': 1, 'created': '2015-05-09 01:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/fe123078eb52358f51ba626f00c27b3eca5d5f6c', 'message': 'Increasing cluster name length to 255\n\nRally names the clusters using a UUID and some other texts, which causes the\nname of the cluster to exceed its length.\n\nChange-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5\n'}, {'number': 2, 'created': '2015-05-11 20:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/f1f4e8cfe4326a4c46e8c1309efd2961c8038664', 'message': 'Increasing cluster name length to 255\n\nRally names the clusters using a UUID and some other texts, which causes the\nname of the cluster to exceed its length.\n\nChange-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5\n'}, {'number': 3, 'created': '2015-05-11 20:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/3b3e6137809cd882f2b7cc22e17005693c96d17f', 'message': ""Increasing cluster project name length to 255\n\nRally names the user's project name using a UUID and some other texts,\nwhich causes the name to exceed its length.\n\nChange-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5\n""}, {'number': 4, 'created': '2015-05-12 17:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/5b3e0a169618cc8e7363489da1d80857e6473db6', 'message': 'Resolving tenant id configuration for request context\n\ncloses-bug: 1454362\n\nChange-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5\n'}, {'number': 5, 'created': '2015-05-12 20:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/d003d0ff4281352c64a62e492b3f96259a00f79c', 'message': 'Updating API Context hook header data extraction for context\n\nUpdating hooks to conform to updated keystone middleware\nheaders.  Project/Tenant name was being persisted in DB instead\nof project/tenant ID.\n\ncloses-bug: 1454362\n\nChange-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5\n'}, {'number': 6, 'created': '2015-05-13 00:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/042e8ff51c3c51de40508edad425e805cc4d81ea', 'message': 'Updating API Context hook header data extraction for context\n\nUpdating hooks to conform to updated keystone middleware\nheaders.  Project/Tenant name was being persisted in DB instead\nof project/tenant ID.\n\ncloses-bug: 1454362\n\nChange-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5\n'}, {'number': 7, 'created': '2015-05-14 17:33:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/da260ae21125741632afb32102eaa48fd9ba4d85', 'message': 'Updating API Context hook header data extraction for context\n\nUpdating hooks to conform to updated keystone middleware\nheaders.  Project/Tenant name was being persisted in DB instead\nof project/tenant ID.\n\ncloses-bug: 1454362\n\nChange-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5\n'}, {'number': 8, 'created': '2015-05-15 17:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/d02259e468e89d3f8b257cfa28798139d89337d5', 'message': 'Updating API Context hook header data extraction for context\n\nUpdating hooks to conform to updated keystone middleware\nheaders.  Project/Tenant name was being persisted in DB instead\nof project/tenant ID.\n\nPartial-Bug: 1454362\n\nChange-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5\n'}, {'number': 9, 'created': '2015-05-15 17:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/fa17bf68d1c84e37a6c5bbbbe0682e50cf29afd9', 'message': 'Updating API Context hook header data extraction for context\n\nUpdating hooks to conform to updated keystone middleware\nheaders.  Project/Tenant name was being persisted in DB instead\nof project/tenant ID.\n\nPartial-Bug: 1454362\n\nChange-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5\n'}, {'number': 10, 'created': '2015-05-18 22:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/758a76c42c097837b52eac8614ca6efb4cfc1718', 'message': 'Updating API Context hook header data extraction for context\n\nUpdating hooks to conform to updated keystone middleware\nheaders.  Project/Tenant name was being persisted in DB instead\nof project/tenant ID.\n\ncloses-Bug: 1454362\n\nChange-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5\n'}, {'number': 11, 'created': '2015-05-18 22:46:26.000000000', 'files': ['cue/api/hooks.py', 'cue/tests/functional/api/__init__.py', 'cue/tests/unit/api/test_hooks.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/54501635a2feebc01b67c93c984739f497abc754', 'message': 'Updating API Context hook header data extraction for context\n\nUpdating hooks to conform to updated keystone middleware\nheaders.  Project/Tenant name was being persisted in DB instead\nof project/tenant ID.\n\ncloses-Bug: 1454362\n\nChange-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5\n'}]",8,181601,54501635a2feebc01b67c93c984739f497abc754,32,5,11,5390,,,0,"Updating API Context hook header data extraction for context

Updating hooks to conform to updated keystone middleware
headers.  Project/Tenant name was being persisted in DB instead
of project/tenant ID.

closes-Bug: 1454362

Change-Id: I3c757d123e7b8369769cd1f49672a5c07fe01ec5
",git fetch https://review.opendev.org/openstack/cue refs/changes/01/181601/8 && git format-patch -1 --stdout FETCH_HEAD,['cue/db/sqlalchemy/alembic/versions/236f63c96b6a_initial_version.py'],1,fe123078eb52358f51ba626f00c27b3eca5d5f6c,increase_length," sa.Column('project_id', sa.String(length=256), nullable=False),"," sa.Column('project_id', sa.String(length=36), nullable=False),",1,1
openstack%2Fironic~master~I48971c79ba3d745056ff3d3157fde08b3d566f94,openstack/ironic,master,I48971c79ba3d745056ff3d3157fde08b3d566f94,Fix drac implementation of set_boot_device,MERGED,2015-04-13 19:19:30.000000000,2015-05-21 17:14:36.000000000,2015-05-21 17:14:33.000000000,"[{'_account_id': 3}, {'_account_id': 114}, {'_account_id': 2889}, {'_account_id': 6610}, {'_account_id': 6773}, {'_account_id': 7419}, {'_account_id': 7711}, {'_account_id': 9751}, {'_account_id': 10239}, {'_account_id': 10250}, {'_account_id': 12081}, {'_account_id': 12715}, {'_account_id': 13997}, {'_account_id': 14619}, {'_account_id': 14886}]","[{'number': 1, 'created': '2015-04-13 19:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/934081cb28ba62bac274f0772f217ec37cb84e19', 'message': 'Fix drac implementetation of set_boot_device.\n\nThe drac implementation of set_boot_device was not recognizing when\nit did not actually need to change the boot order, which caused it to\ntry running a config job when there was nothing to do.\n\nThis adds a check for that conditino, end exits early if there is\n nothing to do.\n\nChange-Id: I48971c79ba3d745056ff3d3157fde08b3d566f94\n'}, {'number': 2, 'created': '2015-04-13 20:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fb5938c60f558381f269c177ac98180a7753360a', 'message': 'Fix drac implementation of set_boot_device.\n\nThe drac implementation of set_boot_device was not recognizing when\nit did not actually need to change the boot order, which caused it to\ntry running a config job when there was nothing to do.\n\nThis adds a check for that condition, end exits early if there is\n nothing to do.\n\nChange-Id: I48971c79ba3d745056ff3d3157fde08b3d566f94\n'}, {'number': 3, 'created': '2015-04-13 20:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/63c2a8abd04e1fa700bf3260786451589aa37e4b', 'message': 'Fix drac implementation of set_boot_device.\n\nThe drac implementation of set_boot_device was not recognizing when\nit did not actually need to change the boot order, which caused it to\ntry running a config job when there was nothing to do.\n\nThis adds a check for that condition, end exits early if there is\n nothing to do.\n\nChange-Id: I48971c79ba3d745056ff3d3157fde08b3d566f94\n'}, {'number': 4, 'created': '2015-05-19 17:52:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/853134730c49a053e86b05196430290f417b6761', 'message': 'Fix drac implementation of set_boot_device\n\nThe drac implementation of set_boot_device was not recognizing when\nit did not actually need to change the boot order, which caused it to\ntry running a config job when there was nothing to do.\n\nThis adds a check for that condition, and exits early if there is\nnothing to do.\n\nCloses-Bug: 1454259\nChange-Id: I48971c79ba3d745056ff3d3157fde08b3d566f94\n'}, {'number': 5, 'created': '2015-05-21 14:21:02.000000000', 'files': ['ironic/drivers/modules/drac/management.py', 'ironic/tests/drivers/drac/test_management.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1edf56dbbfef63eb7bc4d25c83f2c88fd1d99833', 'message': 'Fix drac implementation of set_boot_device\n\nThe drac implementation of set_boot_device was not recognizing when\nit did not actually need to change the boot order, which caused it to\ntry running a config job when there was nothing to do.\n\nThis adds a check for that condition, and exits early if there is\nnothing to do.\n\nCloses-Bug: 1454259\nChange-Id: I48971c79ba3d745056ff3d3157fde08b3d566f94\n'}]",26,173047,1edf56dbbfef63eb7bc4d25c83f2c88fd1d99833,47,15,5,114,,,0,"Fix drac implementation of set_boot_device

The drac implementation of set_boot_device was not recognizing when
it did not actually need to change the boot order, which caused it to
try running a config job when there was nothing to do.

This adds a check for that condition, and exits early if there is
nothing to do.

Closes-Bug: 1454259
Change-Id: I48971c79ba3d745056ff3d3157fde08b3d566f94
",git fetch https://review.opendev.org/openstack/ironic refs/changes/47/173047/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/drac/management.py'],1,934081cb28ba62bac274f0772f217ec37cb84e19,bug/1454259," # If we are already booting from the right device, do nothing. if self.get_boot_device(task) == {'boot_device': device, 'persistent': persistent}: return ",,6,0
openstack%2Fneutron~master~I41693f4613b5a69a01a33e54f90e82177f42e1af,openstack/neutron,master,I41693f4613b5a69a01a33e54f90e82177f42e1af,Remove middleware oslo-incubator module,MERGED,2015-05-20 21:20:22.000000000,2015-05-21 17:10:07.000000000,2015-05-21 17:10:05.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-05-20 21:20:22.000000000', 'files': ['neutron/openstack/common/middleware/__init__.py', 'neutron/openstack/common/middleware/request_id.py', 'openstack-common.conf', 'neutron/openstack/common/middleware/catch_errors.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/29ea6436070762d38d17d9a34968bed8651b7c4b', 'message': ""Remove middleware oslo-incubator module\n\nThe module was used during Kilo cycle to provide backwards compatibility\nfor users that upgrade to the release without updating their\napi-paste.ini. We have issued the deprecation warning for a cycle now,\nso we should be ok to just drop the compatibility layer.\n\nNote that the change may require a notion in release notes to make sure\neveryone is notified, even if they don't look through their logs.\n\nDocImpact\n\nChange-Id: I41693f4613b5a69a01a33e54f90e82177f42e1af\n""}]",0,184624,29ea6436070762d38d17d9a34968bed8651b7c4b,32,28,1,9656,,,0,"Remove middleware oslo-incubator module

The module was used during Kilo cycle to provide backwards compatibility
for users that upgrade to the release without updating their
api-paste.ini. We have issued the deprecation warning for a cycle now,
so we should be ok to just drop the compatibility layer.

Note that the change may require a notion in release notes to make sure
everyone is notified, even if they don't look through their logs.

DocImpact

Change-Id: I41693f4613b5a69a01a33e54f90e82177f42e1af
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/184624/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/openstack/common/middleware/__init__.py', 'neutron/openstack/common/middleware/request_id.py', 'openstack-common.conf', 'neutron/openstack/common/middleware/catch_errors.py']",4,29ea6436070762d38d17d9a34968bed8651b7c4b,,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Compatibility shim for Kilo, while operators migrate to oslo.middleware."""""" from oslo_middleware import catch_errors from neutron.openstack.common import versionutils @versionutils.deprecated(as_of=versionutils.deprecated.KILO, in_favor_of='oslo.middleware.CatchErrors') class CatchErrorsMiddleware(catch_errors.CatchErrors): pass ",0,51
openstack%2Fnova-specs~master~I8c59291787bf0d96480cb97d98037ea40e636438,openstack/nova-specs,master,I8c59291787bf0d96480cb97d98037ea40e636438,Instance update validation,ABANDONED,2015-02-19 23:38:44.000000000,2015-05-21 17:09:44.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 6804}]","[{'number': 1, 'created': '2015-02-19 23:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/78f90e000d0ba745b20d056c4095a4a4b6ce64d7', 'message': 'Instance update validation\n\nNova instance updates can currently set bogus values (such as vm state\nDELETED plus power state RUNNING). When this happens no error is\ntriggered or logged and we only find out when users complain. By\nputting some sanity checking into Nova we can catch these situations\nand trigger an error.\n\nChange-Id: I8c59291787bf0d96480cb97d98037ea40e636438\n'}, {'number': 2, 'created': '2015-02-25 22:37:14.000000000', 'files': ['specs/liberty/instance-update-validate.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f9c03ef4b13c2706948226bd9bd72e3dfa56ab28', 'message': 'Instance update validation\n\nNova instance updates can currently set bogus values (such as vm state\nDELETED plus power state RUNNING). When this happens no error is\ntriggered or logged and we only find out when users complain. By\nputting some sanity checking into Nova we can catch these situations\nand trigger an error.\n\nChange-Id: I8c59291787bf0d96480cb97d98037ea40e636438\n'}]",25,157596,f9c03ef4b13c2706948226bd9bd72e3dfa56ab28,17,5,2,4190,,,0,"Instance update validation

Nova instance updates can currently set bogus values (such as vm state
DELETED plus power state RUNNING). When this happens no error is
triggered or logged and we only find out when users complain. By
putting some sanity checking into Nova we can catch these situations
and trigger an error.

Change-Id: I8c59291787bf0d96480cb97d98037ea40e636438
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/96/157596/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/instance-update-validate.rst'],1,78f90e000d0ba745b20d056c4095a4a4b6ce64d7,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================== Instance update validation ========================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/instance-update-validate Nova instance updates can currently set bogus values (such as vm state DELETED plus power state RUNNING). When this happens no error is triggered or logged and we only find out when users complain. By putting some sanity checking into Nova we can catch these situations and trigger an error. See for instance https://bugs.launchpad.net/nova/+bug/1392798 which could not have happened if we had the proposed validation in place. Problem description =================== Keeping instance state internally consistent currently requires careful code, careful tests, and careful reviewing. This allows bugs to creep into the code where we make mistakes. Use Cases ---------- Developers will not need to think as hard to be confident that their updates to Nova which affect instance state are correct. (They should still think though!) Likewise reviewers will have a slightly easier time, and bugs like the aforementioned bug 1392798 will be much harder to introduce into the codebase. Some cases where that might occur in error code paths will now through a update failure error instead, but that should still be a better tradeoff (as we'll have a stack trace of the point the bad update was attempted rather than having to do a code audit/search to figure out the bug). Users may be affected in those corner cases where something would have succeeded with bad data before and will now error, but that is unlikely. Project Priority ----------------- This spec probably fits in the Bugs priority. Proposed change =============== Posting to get preliminary feedback on the scope of this spec. I believe adding in validation to either Instance.save or db/sqlalchemy/api.py's _instance_update would work. Aesthetically adding it to Instance.save would be better, but there is perhaps some still unconverted code using the DB api directly which this would thus not catch. Alternatives ------------ There are lots of different ways to implement such checks - monkeypatching, formal state machines and so on, but there is little reason to include additional complexity at this time. Data model impact ----------------- The data model is becoming more restrictive. However since we're only going to block updates, and we should be able to only block changes to validated fields - we don't need to do a migration where we audit to ensure all existing instances are valid. REST API impact --------------- No REST API impact. Security impact --------------- This change doesn't deal with sensitive data, doesn't make it possible for users to make more requests, or consume more resources from the requests they can make today. As such I don't believe there is a security impact. Notifications impact -------------------- No notifications change. Other end user impact --------------------- The feature is not directly accessible to users. In the event of bad code trying to violate the datamodel an exception will be raised, and this will be treated the same as all our existing exceptions. Performance Impact ------------------ There will be a small increase in overhead when saving objects, but only a few dozen opcodes - unlikely to show up on the most sensitive profiling. Other deployer impact --------------------- No deployer impact anticipated. Developer impact ---------------- Developers will have mistakes caught for them. If the set of valid states is expanded they will have a single place in code to change to permit that (plus the associated tests). Implementation ============== Assignee(s) ----------- Primary assignee: lifeless Other contributors: None Work Items ---------- * Write a validator routine and hook it into `Instance.save`. * Write tests. * Push for review. Dependencies ============ No dependencies. Testing ======= Unit testing of the new code, plus the existing functional testing of Nova will be sufficient. Since its belts-and-bracers, we shouldn't test this code directly outside of unit tests. Documentation Impact ==================== We should document the data model constraints in developer docs, but no new end user docs are needed. References ========== * https://bugs.launchpad.net/nova/+bug/1392798 ",,159,0
openstack%2Fneutron~master~I3f990895887e156de929bd7ac3732df114dd4a4b,openstack/neutron,master,I3f990895887e156de929bd7ac3732df114dd4a4b,Reuse caller's session in ML2 DB methods,MERGED,2015-04-14 13:39:36.000000000,2015-05-21 17:04:30.000000000,2015-05-21 17:04:27.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 6695}, {'_account_id': 6854}, {'_account_id': 7016}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11444}, {'_account_id': 12040}, {'_account_id': 13409}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-04-14 13:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/04a040bc76cb7cf9d26dfdabc348a3ef1be82491', 'message': ""Reuse callers session in ML2 DB methods\n\nThis patch changes the get_port_from_device_mac() and\nget_sg_ids_grouped_by_port() methods in ML2 db.py module so that they do\nnot create a new database session (via get_session()), but instead reuse\nthe session associated with the caller's context.\n\nChange-Id: I3f990895887e156de929bd7ac3732df114dd4a4b\nCloses-Bug: 1441205\n""}, {'number': 2, 'created': '2015-04-20 20:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a9c6331add852eb9e0e0918b503fbee4514ddcd', 'message': ""Reuse callers session in ML2 DB methods\n\nThis patch changes the get_port_from_device_mac() and\nget_sg_ids_grouped_by_port() methods in ML2 db.py module so that they do\nnot create a new database session (via get_session()), but instead reuse\nthe session associated with the caller's context.\n\nChange-Id: I3f990895887e156de929bd7ac3732df114dd4a4b\nCloses-Bug: 1441205\n""}, {'number': 3, 'created': '2015-04-20 22:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e2377b3680e4afa1f2103a0a402d99d631547ecd', 'message': ""Reuse callers session in ML2 DB methods\n\nThis patch changes the get_port_from_device_mac() and\nget_sg_ids_grouped_by_port() methods in ML2 db.py module so that they do\nnot create a new database session (via get_session()), but instead reuse\nthe session associated with the caller's context.\n\nChange-Id: I3f990895887e156de929bd7ac3732df114dd4a4b\nCloses-Bug: 1441205\n""}, {'number': 4, 'created': '2015-04-21 22:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/170be360d48141e5e3936964d31e7f0c5e36f07b', 'message': ""Reuse caller's session in ML2 DB methods\n\nThis patch changes the get_port_from_device_mac() and\nget_sg_ids_grouped_by_port() methods in ML2 db.py module so that they do\nnot create a new database session (via get_session()), but instead reuse\nthe session associated with the caller's context.\n\nThe motivation for this change is to avoid a possible database deadlock\nas described in:\n   https://bugs.launchpad.net/neutron/+bug/1440183/comments/13\n\nIn order to make the session that is associated with the caller's context\nto be available to these ML2 DB methods, the get_ports_from_devices plugin\nAPI in securitygroups_rps_base.py needs to be modified so that the context\ncan be passed down to the ML2 plugin. (A similar change is made to the\nget_port_from_device plugin API for consistency.)\n\nChange-Id: I3f990895887e156de929bd7ac3732df114dd4a4b\nCloses-Bug: 1441205\n""}, {'number': 5, 'created': '2015-04-30 13:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d14154fb1b7ed190f6aad6a8946274e1846ddc6b', 'message': ""Reuse caller's session in ML2 DB methods\n\nThis patch changes the get_port_from_device_mac() and\nget_sg_ids_grouped_by_port() methods in ML2 db.py module so that\nthey do not create a new database session (via get_session()), but\ninstead reuse the session associated with the caller's context.\n\nThe motivation for this change is to avoid a possible database\ndeadlock as described in:\n   https://bugs.launchpad.net/neutron/+bug/1440183/comments/13\n\nIn order to make the session that is associated with the caller's\ncontext to be available to these ML2 DB methods, the\nget_ports_from_devices plugin API in securitygroups_rps_base.py\nneeds to be modified so that the context can be passed down to the\nML2 plugin. (A similar change is made to the get_port_from_device\nplugin API for consistency.)\n\nChange-Id: I3f990895887e156de929bd7ac3732df114dd4a4b\nCloses-Bug: 1441205\n""}, {'number': 6, 'created': '2015-05-06 20:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a9ae575550469fb8f853a97a5a3bfa4d321c083', 'message': ""Reuse caller's session in ML2 DB methods\n\nThis patch changes the get_port_from_device_mac() and\nget_sg_ids_grouped_by_port() methods in ML2 db.py module so that\nthey do not create a new database session (via get_session()), but\ninstead reuse the session associated with the caller's context.\n\nThe motivation for this change is to avoid a possible database\ndeadlock as described in:\n   https://bugs.launchpad.net/neutron/+bug/1440183/comments/13\n\nIn order to make the session that is associated with the caller's\ncontext available to these ML2 DB methods, the\nget_ports_from_devices plugin API in securitygroups_rps_base.py\nneeds to be modified so that the context can be passed down to the\nML2 plugin. (A similar change is made to the get_port_from_device\nplugin API for consistency.)\n\nChange-Id: I3f990895887e156de929bd7ac3732df114dd4a4b\nCloses-Bug: 1441205\n""}, {'number': 7, 'created': '2015-05-07 21:27:35.000000000', 'files': ['neutron/plugins/ml2/rpc.py', 'neutron/plugins/oneconvergence/plugin.py', 'neutron/tests/unit/plugins/ml2/test_db.py', 'neutron/tests/unit/plugins/oneconvergence/test_security_group.py', 'neutron/api/rpc/handlers/securitygroups_rpc.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/db/securitygroups_rpc_base.py', 'neutron/plugins/ml2/db.py', 'neutron/tests/unit/plugins/ml2/test_security_group.py', 'neutron/tests/unit/agent/test_securitygroups_rpc.py', 'neutron/tests/unit/plugins/ml2/test_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/47dd65cf986d712e9c6ca5dcf4420dfc44900b66', 'message': ""Reuse caller's session in ML2 DB methods\n\nThis patch changes the get_port_from_device_mac() and\nget_sg_ids_grouped_by_port() methods in ML2 db.py module so that\nthey do not create a new database session (via get_session()), but\ninstead reuse the session associated with the caller's context.\n\nIn order to make the session that is associated with the caller's\ncontext available to these ML2 DB methods, the\nget_ports_from_devices plugin API in securitygroups_rps_base.py\nneeds to be modified so that the context can be passed down to the\nML2 plugin. (A similar change is made to the get_port_from_device\nplugin API for consistency.)\n\nChange-Id: I3f990895887e156de929bd7ac3732df114dd4a4b\nCloses-Bug: 1441205\n""}]",10,173320,47dd65cf986d712e9c6ca5dcf4420dfc44900b66,292,43,7,6695,,,0,"Reuse caller's session in ML2 DB methods

This patch changes the get_port_from_device_mac() and
get_sg_ids_grouped_by_port() methods in ML2 db.py module so that
they do not create a new database session (via get_session()), but
instead reuse the session associated with the caller's context.

In order to make the session that is associated with the caller's
context available to these ML2 DB methods, the
get_ports_from_devices plugin API in securitygroups_rps_base.py
needs to be modified so that the context can be passed down to the
ML2 plugin. (A similar change is made to the get_port_from_device
plugin API for consistency.)

Change-Id: I3f990895887e156de929bd7ac3732df114dd4a4b
Closes-Bug: 1441205
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/173320/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/rpc.py', 'neutron/db/securitygroups_rpc_base.py', 'neutron/plugins/ml2/db.py', 'neutron/tests/unit/plugins/ml2/test_security_group.py', 'neutron/tests/unit/plugins/ml2/test_rpc.py', 'neutron/tests/unit/plugins/ml2/test_db.py', 'neutron/api/rpc/handlers/securitygroups_rpc.py', 'neutron/plugins/ml2/plugin.py']",8,04a040bc76cb7cf9d26dfdabc348a3ef1be82491,bug/1441205," def get_ports_from_devices(self, context, devices): port_ids_to_devices = dict( (self._device_to_port_id(context, device), device) for device in devices) ports = db.get_ports_and_sgs(context, port_ids) def _device_to_port_id(self, context, device): port = db.get_port_from_device_mac(context, device)"," def get_ports_from_devices(self, devices): port_ids_to_devices = dict((self._device_to_port_id(device), device) for device in devices) ports = db.get_ports_and_sgs(port_ids) def _device_to_port_id(self, device): port = db.get_port_from_device_mac(device)",49,46
openstack%2Fpython-cinderclient~master~I1d5c962b027413edb5201930c5556dc873b9dbbe,openstack/python-cinderclient,master,I1d5c962b027413edb5201930c5556dc873b9dbbe,Cinder client does not expose error details,ABANDONED,2015-01-19 22:25:26.000000000,2015-05-21 16:25:15.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5538}, {'_account_id': 6348}, {'_account_id': 7160}, {'_account_id': 7173}, {'_account_id': 7219}, {'_account_id': 7634}, {'_account_id': 8074}, {'_account_id': 10115}, {'_account_id': 10263}, {'_account_id': 10559}, {'_account_id': 13636}, {'_account_id': 14305}]","[{'number': 1, 'created': '2015-01-19 22:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/3b8c56f39134f4fedcfc8c2cf11f16db9444edea', 'message': 'Cinder client does not expose error details\n\nBy default, the keystone client raises a keystoneclient.openstack.common.\napiclient.exceptions.BadRequest exception if the HTTP response code\nis >= 400. This generic exception does not contain the detailed error\ndata (only a ""Bad Request"" message) and, therefore, the error data cannot\nbe exposed to the caller.\n\nFor example, when the following command fails, the caller is not given any\nindication of the cause of the failure:\n\n > cinder backup-create Vol1 --name Back1\n ERROR: Bad Request (HTTP 400) (Request-ID: ...)\n\nThe error message data is included in the HTTP response and this patch set\nretrieves it by:\n * Overriding the default behavior of the keystoneclient so that an exception\n   is not raised\n * Detecting errors in the cinderclient and raising a formatted exception\n   that contains the appropriate detailed message data\n\nWith this fix, the detailed message is exposed to the user:\n\n > cinder backup-create Vol1 --name Back1\n ERROR: Invalid volume: Volume to be backed up must be available (HTTP 400)\n (Request-ID: ...)\n\nChange-Id: I1d5c962b027413edb5201930c5556dc873b9dbbe\nCloses-Bug: 1412583\n'}, {'number': 2, 'created': '2015-04-02 14:34:56.000000000', 'files': ['cinderclient/client.py', 'cinderclient/tests/unit/test_client.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/af58fc7ab8b7fc6ea5130650b22156c5bcbebfd0', 'message': 'Cinder client does not expose error details\n\nBy default, the keystone client raises a keystoneclient.openstack.common.\napiclient.exceptions.BadRequest exception if the HTTP response code\nis >= 400. This generic exception does not contain the detailed error\ndata (only a ""Bad Request"" message) and, therefore, the error data cannot\nbe exposed to the caller.\n\nFor example, when the following command fails, the caller is not given any\nindication of the cause of the failure:\n\n > cinder backup-create Vol1 --name Back1\n ERROR: Bad Request (HTTP 400) (Request-ID: ...)\n\nThe error message data is included in the HTTP response and this patch set\nretrieves it by:\n * Overriding the default behavior of the keystoneclient so that an exception\n   is not raised\n * Detecting errors in the cinderclient and raising a formatted exception\n   that contains the appropriate detailed message data\n\nWith this fix, the detailed message is exposed to the user:\n\n > cinder backup-create Vol1 --name Back1\n ERROR: Invalid volume: Volume to be backed up must be available (HTTP 400)\n (Request-ID: ...)\n\nChange-Id: I1d5c962b027413edb5201930c5556dc873b9dbbe\nCloses-Bug: 1412583\n'}]",7,148373,af58fc7ab8b7fc6ea5130650b22156c5bcbebfd0,39,16,2,10559,,,0,"Cinder client does not expose error details

By default, the keystone client raises a keystoneclient.openstack.common.
apiclient.exceptions.BadRequest exception if the HTTP response code
is >= 400. This generic exception does not contain the detailed error
data (only a ""Bad Request"" message) and, therefore, the error data cannot
be exposed to the caller.

For example, when the following command fails, the caller is not given any
indication of the cause of the failure:

 > cinder backup-create Vol1 --name Back1
 ERROR: Bad Request (HTTP 400) (Request-ID: ...)

The error message data is included in the HTTP response and this patch set
retrieves it by:
 * Overriding the default behavior of the keystoneclient so that an exception
   is not raised
 * Detecting errors in the cinderclient and raising a formatted exception
   that contains the appropriate detailed message data

With this fix, the detailed message is exposed to the user:

 > cinder backup-create Vol1 --name Back1
 ERROR: Invalid volume: Volume to be backed up must be available (HTTP 400)
 (Request-ID: ...)

Change-Id: I1d5c962b027413edb5201930c5556dc873b9dbbe
Closes-Bug: 1412583
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/73/148373/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/client.py', 'cinderclient/tests/test_client.py']",2,3b8c56f39134f4fedcfc8c2cf11f16db9444edea,bug/1412583,"import mock @mock.patch('keystoneclient.adapter.LegacyJsonAdapter.request') def test_request(self, mock_req): req_resp = mock.MagicMock() type(req_resp).status_code = mock.PropertyMock(return_value=200) mock_req.return_value = (req_resp, {}) client = cinderclient.client.SessionClient(None) resp, body = client.request() self.assertEqual(req_resp, resp) self.assertEqual({}, body) mock_req.assert_called_once_with(authenticated=False, raise_exc=False) @mock.patch('keystoneclient.adapter.LegacyJsonAdapter.request') def test_request_error(self, mock_req): req_resp = mock.MagicMock() type(req_resp).status_code = mock.PropertyMock(return_value=400) mock_req.return_value = (req_resp, {}) client = cinderclient.client.SessionClient(None) self.assertRaises(cinderclient.exceptions.ClientException, client.request)",,30,1
openstack%2Fopenstacksdk~master~I60db722ecff0929a49d7474766d0521cc8f063a4,openstack/openstacksdk,master,I60db722ecff0929a49d7474766d0521cc8f063a4,Remove some mentions to preferences from docs,MERGED,2015-05-21 01:38:08.000000000,2015-05-21 16:22:44.000000000,2015-05-21 16:22:41.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-21 01:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0ddaa93e6d787f3cb390d07c72ea8fce572293b9', 'message': 'Remove some mentions to preferences from docs\n\nChange-Id: I60db722ecff0929a49d7474766d0521cc8f063a4\n'}, {'number': 2, 'created': '2015-05-21 16:14:11.000000000', 'files': ['doc/source/users/index.rst', 'doc/source/users/userguides/usage.rst', 'doc/source/contributors/layout.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8c5402e0cdd475808aa2dbfb6995069903f174a6', 'message': 'Remove some mentions to preferences from docs\n\nChange-Id: I60db722ecff0929a49d7474766d0521cc8f063a4\n'}]",2,184672,8c5402e0cdd475808aa2dbfb6995069903f174a6,10,3,2,8736,,,0,"Remove some mentions to preferences from docs

Change-Id: I60db722ecff0929a49d7474766d0521cc8f063a4
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/72/184672/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/users/index.rst', 'doc/source/users/userguides/usage.rst', 'doc/source/contributors/layout.rst']",3,0ddaa93e6d787f3cb390d07c72ea8fce572293b9,docsprofile,"transport, and user pofile. It exposes methods corresponding to","transport, and user preferences. It exposes methods corresponding to",5,5
openstack%2Fbarbican~master~Id3e4940e40eae8b42fb7f53ea5542df6090d4510,openstack/barbican,master,Id3e4940e40eae8b42fb7f53ea5542df6090d4510,Remove unused incubated cryptoutils,MERGED,2015-05-21 04:15:30.000000000,2015-05-21 16:21:59.000000000,2015-05-21 16:21:58.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6928}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}]","[{'number': 1, 'created': '2015-05-21 04:15:30.000000000', 'files': ['barbican/openstack/common/crypto/__init__.py', 'barbican/openstack/common/crypto/utils.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/11bbbc02cac086ef91eb193fd1df7259efc7c0ae', 'message': 'Remove unused incubated cryptoutils\n\nBarbican is not using the crypto utils pieces in oslo-incubator and that\nmodule has been marked for deprecation.\n\nChange-Id: Id3e4940e40eae8b42fb7f53ea5542df6090d4510\n'}]",0,184711,11bbbc02cac086ef91eb193fd1df7259efc7c0ae,8,8,1,12000,,,0,"Remove unused incubated cryptoutils

Barbican is not using the crypto utils pieces in oslo-incubator and that
module has been marked for deprecation.

Change-Id: Id3e4940e40eae8b42fb7f53ea5542df6090d4510
",git fetch https://review.opendev.org/openstack/barbican refs/changes/11/184711/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/openstack/common/crypto/__init__.py', 'barbican/openstack/common/crypto/utils.py']",2,11bbbc02cac086ef91eb193fd1df7259efc7c0ae,,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2013 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import base64 from Crypto.Hash import HMAC from Crypto import Random from barbican.openstack.common.gettextutils import _ # noqa from barbican.openstack.common import importutils class CryptoutilsException(Exception): """"""Generic Exception for Crypto utilities."""""" message = _(""An unknown error occurred in crypto utils."") class CipherBlockLengthTooBig(CryptoutilsException): """"""The block size is too big."""""" def __init__(self, requested, permitted): msg = _(""Block size of %(given)d is too big, max = %(maximum)d"") message = msg % {'given': requested, 'maximum': permitted} super(CryptoutilsException, self).__init__(message) class HKDFOutputLengthTooLong(CryptoutilsException): """"""The amount of Key Material asked is too much."""""" def __init__(self, requested, permitted): msg = _(""Length of %(given)d is too long, max = %(maximum)d"") message = msg % {'given': requested, 'maximum': permitted} super(CryptoutilsException, self).__init__(message) class HKDF(object): """"""An HMAC-based Key Derivation Function implementation (RFC5869) This class creates an object that allows to use HKDF to derive keys. """""" def __init__(self, hashtype='SHA256'): self.hashfn = importutils.import_module('Crypto.Hash.' + hashtype) self.max_okm_length = 255 * self.hashfn.digest_size def extract(self, ikm, salt=None): """"""An extract function that can be used to derive a robust key given weak Input Key Material (IKM) which could be a password. Returns a pseudorandom key (of HashLen octets) :param ikm: input keying material (ex a password) :param salt: optional salt value (a non-secret random value) """""" if salt is None: salt = '\x00' * self.hashfn.digest_size return HMAC.new(salt, ikm, self.hashfn).digest() def expand(self, prk, info, length): """"""An expand function that will return arbitrary length output that can be used as keys. Returns a buffer usable as key material. :param prk: a pseudorandom key of at least HashLen octets :param info: optional string (can be a zero-length string) :param length: length of output keying material (<= 255 * HashLen) """""" if length > self.max_okm_length: raise HKDFOutputLengthTooLong(length, self.max_okm_length) N = (length + self.hashfn.digest_size - 1) / self.hashfn.digest_size okm = """" tmp = """" for block in range(1, N + 1): tmp = HMAC.new(prk, tmp + info + chr(block), self.hashfn).digest() okm += tmp return okm[:length] MAX_CB_SIZE = 256 class SymmetricCrypto(object): """"""Symmetric Key Crypto object. This class creates a Symmetric Key Crypto object that can be used to encrypt, decrypt, or sign arbitrary data. :param enctype: Encryption Cipher name (default: AES) :param hashtype: Hash/HMAC type name (default: SHA256) """""" def __init__(self, enctype='AES', hashtype='SHA256'): self.cipher = importutils.import_module('Crypto.Cipher.' + enctype) self.hashfn = importutils.import_module('Crypto.Hash.' + hashtype) def new_key(self, size): return Random.new().read(size) def encrypt(self, key, msg, b64encode=True): """"""Encrypt the provided msg and returns the cyphertext optionally base64 encoded. Uses AES-128-CBC with a Random IV by default. The plaintext is padded to reach blocksize length. The last byte of the block is the length of the padding. The length of the padding does not include the length byte itself. :param key: The Encryption key. :param msg: the plain text. :returns encblock: a block of encrypted data. """""" iv = Random.new().read(self.cipher.block_size) cipher = self.cipher.new(key, self.cipher.MODE_CBC, iv) # CBC mode requires a fixed block size. Append padding and length of # padding. if self.cipher.block_size > MAX_CB_SIZE: raise CipherBlockLengthTooBig(self.cipher.block_size, MAX_CB_SIZE) r = len(msg) % self.cipher.block_size padlen = self.cipher.block_size - r - 1 msg += '\x00' * padlen msg += chr(padlen) enc = iv + cipher.encrypt(msg) if b64encode: enc = base64.b64encode(enc) return enc def decrypt(self, key, msg, b64decode=True): """"""Decrypts the provided ciphertext, optionally base 64 encoded, and returns the plaintext message, after padding is removed. Uses AES-128-CBC with an IV by default. :param key: The Encryption key. :param msg: the ciphetext, the first block is the IV """""" if b64decode: msg = base64.b64decode(msg) iv = msg[:self.cipher.block_size] cipher = self.cipher.new(key, self.cipher.MODE_CBC, iv) padded = cipher.decrypt(msg[self.cipher.block_size:]) l = ord(padded[-1]) + 1 plain = padded[:-l] return plain def sign(self, key, msg, b64encode=True): """"""Signs a message string and returns a base64 encoded signature. Uses HMAC-SHA-256 by default. :param key: The Signing key. :param msg: the message to sign. """""" h = HMAC.new(key, msg, self.hashfn) out = h.digest() if b64encode: out = base64.b64encode(out) return out ",0,179
openstack%2Fopenstacksdk~master~Idcaf59a1d3363b3e5ed2f49effc1e7a236e94f85,openstack/openstacksdk,master,Idcaf59a1d3363b3e5ed2f49effc1e7a236e94f85,Add requirements.txt file for readthedocs,MERGED,2015-05-21 15:17:39.000000000,2015-05-21 16:17:04.000000000,2015-05-21 16:17:02.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-21 15:17:39.000000000', 'files': ['docs-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/66b219612cebc4007ada9f6470d5e843f79b952e', 'message': ""Add requirements.txt file for readthedocs\n\nYou can't seem to specify two requirements.txt files for\nreadthedocs, so I created this one that includes both.\n\nChange-Id: Idcaf59a1d3363b3e5ed2f49effc1e7a236e94f85\n""}]",0,184802,66b219612cebc4007ada9f6470d5e843f79b952e,6,2,1,8736,,,0,"Add requirements.txt file for readthedocs

You can't seem to specify two requirements.txt files for
readthedocs, so I created this one that includes both.

Change-Id: Idcaf59a1d3363b3e5ed2f49effc1e7a236e94f85
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/02/184802/1 && git format-patch -1 --stdout FETCH_HEAD,['docs-requirements.txt'],1,66b219612cebc4007ada9f6470d5e843f79b952e,rtd,-r requirements.txt -r test-requirements.txt ,,2,0
openstack%2Fopenstacksdk~master~I7f02ff85948f1107b430aef1d199145a1e11852b,openstack/openstacksdk,master,I7f02ff85948f1107b430aef1d199145a1e11852b,Correct the API base path of lbaas resources,MERGED,2015-05-21 06:40:40.000000000,2015-05-21 16:16:00.000000000,2015-05-21 16:15:58.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-21 06:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6ebdea33d16f14eb788fbe1e1baf1a80c2fac2b1', 'message': 'Correct the API base path of lbaas resources\n\nAccording to the reference of Neutron v2 API, the current API base\npath of lbaas resources is incorrect. This patch fixes this issue.\n\nChange-Id: I7f02ff85948f1107b430aef1d199145a1e11852b\n'}, {'number': 2, 'created': '2015-05-21 06:44:07.000000000', 'files': ['openstack/network/v2/load_balancer.py', 'openstack/network/v2/health_monitor.py', 'openstack/tests/unit/network/v2/test_health_monitor.py', 'openstack/tests/unit/network/v2/test_listener.py', 'openstack/tests/unit/network/v2/test_pool.py', 'openstack/tests/unit/network/v2/test_load_balancer.py', 'openstack/network/v2/pool.py', 'openstack/network/v2/listener.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/69d1a6bb422fca4021c35db6ff92f877a5cd3bc9', 'message': 'Correct the API base path of lbaas resources\n\nAccording to the reference of Neutron v2 API, the current API base\npath of lbaas resources is incorrect. This patch fixes this issue.\n\nChange-Id: I7f02ff85948f1107b430aef1d199145a1e11852b\n'}]",0,184722,69d1a6bb422fca4021c35db6ff92f877a5cd3bc9,9,3,2,11034,,,0,"Correct the API base path of lbaas resources

According to the reference of Neutron v2 API, the current API base
path of lbaas resources is incorrect. This patch fixes this issue.

Change-Id: I7f02ff85948f1107b430aef1d199145a1e11852b
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/22/184722/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/network/v2/load_balancer.py', 'openstack/network/v2/health_monitor.py', 'openstack/network/v2/pool.py', 'openstack/network/v2/listener.py']",4,6ebdea33d16f14eb788fbe1e1baf1a80c2fac2b1,fix-lbaas-base-path, base_path = '/lbaas/listeners', base_path = '/listeners',4,4
openstack%2Fneutron~master~Iabf2e94c2b2d91f68fe016695fc56831c1aa13e1,openstack/neutron,master,Iabf2e94c2b2d91f68fe016695fc56831c1aa13e1,Centralized register_OVS_agent in tests,MERGED,2015-04-29 18:06:59.000000000,2015-05-21 16:09:30.000000000,2015-05-21 16:09:27.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 14027}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-04-29 18:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f89c36ad26a45957cff10378961826b3bc48a686', 'message': 'Centralized register_OVS_agent in tests\n\nThis will allow the helper to be used for new DVR and l2pop\nunit tests.\n\nChange-Id: Iabf2e94c2b2d91f68fe016695fc56831c1aa13e1\n'}, {'number': 2, 'created': '2015-05-08 18:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b58a4e582e8d0101736f1ffc038893dbde91b60', 'message': 'Centralized register_OVS_agent in tests\n\nThis will allow the helper to be used for new DVR and l2pop\nunit tests.\n\nChange-Id: Iabf2e94c2b2d91f68fe016695fc56831c1aa13e1\n'}, {'number': 3, 'created': '2015-05-13 16:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a74b6e40eaf6f1e21d8855a1e581ebe22f6896f7', 'message': 'Centralized register_OVS_agent in tests\n\nThis will allow the helper to be used for new DVR and l2pop\nunit tests.\n\nChange-Id: Iabf2e94c2b2d91f68fe016695fc56831c1aa13e1\n'}, {'number': 4, 'created': '2015-05-14 15:10:50.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/l2pop/test_mech_driver.py', 'neutron/tests/common/helpers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ce95331c6b7f811d6e12f6c0e7ca7a5e5ed8e140', 'message': 'Centralized register_OVS_agent in tests\n\nThis will allow the helper to be used for new DVR and l2pop\nunit tests.\n\nChange-Id: Iabf2e94c2b2d91f68fe016695fc56831c1aa13e1\n'}]",0,178789,ce95331c6b7f811d6e12f6c0e7ca7a5e5ed8e140,102,35,4,8873,,,0,"Centralized register_OVS_agent in tests

This will allow the helper to be used for new DVR and l2pop
unit tests.

Change-Id: Iabf2e94c2b2d91f68fe016695fc56831c1aa13e1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/178789/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/l2pop/test_mech_driver.py', 'neutron/tests/common/helpers.py']",2,f89c36ad26a45957cff10378961826b3bc48a686,register_ovs_agent," def _get_ovs_agent_dict(host, agent_type, binary, tunnel_types, tunneling_ip='20.0.0.1', interface_mappings=None, l2pop_network_types=None): agent = { 'binary': binary, 'host': host, 'topic': constants.L2_AGENT_TOPIC, 'configurations': {'tunneling_ip': tunneling_ip, 'tunnel_types': tunnel_types}, 'agent_type': agent_type, 'tunnel_type': [], 'start_flag': True} if interface_mappings is not None: agent['configurations']['interface_mappings'] = interface_mappings if l2pop_network_types is not None: agent['configurations']['l2pop_network_types'] = l2pop_network_types return agent def register_ovs_agent(host=HOST, agent_type=constants.AGENT_TYPE_OVS, binary='neutron-openvswitch-agent', tunnel_types=['vxlan'], tunneling_ip='20.0.0.1', interface_mappings=None, l2pop_network_types=None): agent = _get_ovs_agent_dict(host, agent_type, binary, tunnel_types, tunneling_ip, interface_mappings, l2pop_network_types) return _register_agent(agent)",,65,93
openstack%2Fneutron~master~Ib9eb4a825454d99607deca61ceeb7acb43a9b248,openstack/neutron,master,Ib9eb4a825454d99607deca61ceeb7acb43a9b248,Fix minor errors in the Vyatta L3 Plugin:,MERGED,2015-05-21 00:30:33.000000000,2015-05-21 16:09:16.000000000,2015-05-21 16:09:14.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 8358}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 14081}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-05-21 00:30:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eef613c6c3a235f0a0a5aae67b6ffd661418fd7a', 'message': 'Fix minor errors in the Vyatta L3 Plugin:\n\nupdate management_network to management_network_id in vrouter.ini\nFix copyright header to refer to Brocade in vrouter_neutron_plugin.py\nFix neutron.service_plugins brocade_vyatta_l3 entry in setup.cfg\n\nChange-Id: Ib9eb4a825454d99607deca61ceeb7acb43a9b248\nCloses-Bug: #1457235\n'}, {'number': 2, 'created': '2015-05-21 00:38:53.000000000', 'files': ['neutron/services/l3_router/brocade/vyatta/vrouter_neutron_plugin.py', 'setup.cfg', 'etc/neutron/plugins/brocade/vyatta/vrouter.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/86d5944fcc2f44aac7cd786ea429f942fc5cb66e', 'message': 'Fix minor errors in the Vyatta L3 Plugin:\n\nupdate management_network to management_network_id in vrouter.ini\nFix copyright header to refer to Brocade in vrouter_neutron_plugin.py\nFix neutron.service_plugins brocade_vyatta_l3 entry in setup.cfg\n\nChange-Id: Ib9eb4a825454d99607deca61ceeb7acb43a9b248\nCloses-Bug: #1457235\n'}]",0,184657,86d5944fcc2f44aac7cd786ea429f942fc5cb66e,43,31,2,13485,,,0,"Fix minor errors in the Vyatta L3 Plugin:

update management_network to management_network_id in vrouter.ini
Fix copyright header to refer to Brocade in vrouter_neutron_plugin.py
Fix neutron.service_plugins brocade_vyatta_l3 entry in setup.cfg

Change-Id: Ib9eb4a825454d99607deca61ceeb7acb43a9b248
Closes-Bug: #1457235
",git fetch https://review.opendev.org/openstack/neutron refs/changes/57/184657/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/l3_router/brocade/vyatta/vrouter_neutron_plugin.py', 'setup.cfg', 'etc/neutron/plugins/brocade/vyatta/vrouter.ini']",3,eef613c6c3a235f0a0a5aae67b6ffd661418fd7a,bug/1457235,# vRouter Management network id # management_network_id = # Eaxmple: management_network_id = 7190bb5f-e32a-48fb-9c67-12c1365d0083 ,# vRouter Management network name # management_network = management,5,4
openstack%2Fdevstack~master~I1150b943f52f10d19f8434b27e8dde73a14d7843,openstack/devstack,master,I1150b943f52f10d19f8434b27e8dde73a14d7843,Write out a clouds.yaml file,MERGED,2015-05-14 15:23:11.000000000,2015-05-21 16:01:11.000000000,2015-05-21 16:01:08.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 3099}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-05-14 15:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/79ae15836c55a99a2cb7276d67dba8a6408a637e', 'message': 'Write out a clouds.yaml file\n\nos-client-config consumes clouds.yaml files, which is now supported in\npython-openstackclient and shade. It also makes for a non-envvar way of\ngetting config info into functional tests.\n\nChange-Id: I1150b943f52f10d19f8434b27e8dde73a14d7843\n'}, {'number': 2, 'created': '2015-05-14 15:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/af1d5c0c0336a15b2b34967a7673fbb92d9f5657', 'message': 'Write out a clouds.yaml file\n\nos-client-config consumes clouds.yaml files, which is now supported in\npython-openstackclient and shade. It also makes for a non-envvar way of\ngetting config info into functional tests.\n\nChange-Id: I1150b943f52f10d19f8434b27e8dde73a14d7843\n'}, {'number': 3, 'created': '2015-05-14 15:37:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ba618fece5af130152ed6a96fc54cbb4ae1acb49', 'message': 'Write out a clouds.yaml file\n\nos-client-config consumes clouds.yaml files, which is now supported in\npython-openstackclient and shade. It also makes for a non-envvar way of\ngetting config info into functional tests.\n\nChange-Id: I1150b943f52f10d19f8434b27e8dde73a14d7843\n'}, {'number': 4, 'created': '2015-05-14 15:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5c651c6128586ea1b03da2fdd67de516461c6a99', 'message': 'Write out a clouds.yaml file\n\nos-client-config consumes clouds.yaml files, which is now supported in\npython-openstackclient and shade. It also makes for a non-envvar way of\ngetting config info into functional tests.\n\nChange-Id: I1150b943f52f10d19f8434b27e8dde73a14d7843\n'}, {'number': 5, 'created': '2015-05-14 17:58:23.000000000', 'files': ['clean.sh', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/61045ca58a89f9ce3a2c905450885700119a8a6f', 'message': 'Write out a clouds.yaml file\n\nos-client-config consumes clouds.yaml files, which is now supported in\npython-openstackclient and shade. It also makes for a non-envvar way of\ngetting config info into functional tests.\n\nChange-Id: I1150b943f52f10d19f8434b27e8dde73a14d7843\n'}]",6,183080,61045ca58a89f9ce3a2c905450885700119a8a6f,21,6,5,2,,,0,"Write out a clouds.yaml file

os-client-config consumes clouds.yaml files, which is now supported in
python-openstackclient and shade. It also makes for a non-envvar way of
getting config info into functional tests.

Change-Id: I1150b943f52f10d19f8434b27e8dde73a14d7843
",git fetch https://review.opendev.org/openstack/devstack refs/changes/80/183080/3 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,79ae15836c55a99a2cb7276d67dba8a6408a637e,,"# Write out a clouds.yaml file # putting the location into a variable to allow for easier refactoring later # to make it overridable. There is current no usecase where doing so makes # sense, so I'm not actually doing it now. CLOUDS_YAML=~/.config/openstack/clouds.yaml if [ -f $CLOUDS_YAML ]; then mkdir -p $(dirname $CLOUDS_YAML) fi cat >>""$CLOUDS_YAML"" <<EOF clouds: devstack: auth: auth_url: $SERVICE_PROTCOL://$SERVICE_HOST:5000/v$IDENTITY_API_VERSION username: demo password: demo password: $ADMIN_PASSWORD region_name: $REGION_NAME identity_api_version: $IDENTITY_API_VERSION EOF if [ -f $SSL_BUNDLE_FILE ]; then echo "" cacert: $SSL_BUNDLE_FILE"" >>""$CLOUDS_YAML"" fi ",,23,0
openstack%2Ffuel-web~master~If1f2edd000ec12b6d22deadb0f6a22be71373353,openstack/fuel-web,master,If1f2edd000ec12b6d22deadb0f6a22be71373353,Fix for deadlocks in test_cluster_locking_after_deployment,ABANDONED,2015-05-15 12:25:00.000000000,2015-05-21 15:55:43.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 10959}, {'_account_id': 11577}]","[{'number': 1, 'created': '2015-05-15 12:25:00.000000000', 'files': ['nailgun/nailgun/rpc/receiver.py', 'nailgun/nailgun/task/manager.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/15360f9d03c6c140d4dca243a8267cc3ebe4cd41', 'message': 'Fix for deadlocks in test_cluster_locking_after_deployment\n\nOnly necessary tasks is locked now instead all cluster tasks locking\n\nChange-Id: If1f2edd000ec12b6d22deadb0f6a22be71373353\nCloses-Bug: #1455467\n'}]",0,183494,15360f9d03c6c140d4dca243a8267cc3ebe4cd41,7,4,1,10959,,,0,"Fix for deadlocks in test_cluster_locking_after_deployment

Only necessary tasks is locked now instead all cluster tasks locking

Change-Id: If1f2edd000ec12b6d22deadb0f6a22be71373353
Closes-Bug: #1455467
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/94/183494/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/rpc/receiver.py', 'nailgun/nailgun/task/manager.py']",2,15360f9d03c6c140d4dca243a8267cc3ebe4cd41,bug/1455467," finally: # For more accurate progress calculation objects.Task.get_by_uid(task_deletion.id, lock_for_update=True)", # For more accurate progress calulation,6,8
openstack%2Ffuel-docs~master~Id5736403614478fcfa1e1006f98516ef44da4e01,openstack/fuel-docs,master,Id5736403614478fcfa1e1006f98516ef44da4e01,Removing *.pyc files after applying a patch,MERGED,2015-03-25 11:57:39.000000000,2015-05-21 15:40:14.000000000,2015-05-21 15:40:14.000000000,"[{'_account_id': 3}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 13082}, {'_account_id': 14396}, {'_account_id': 14947}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-03-25 11:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/90e284e14b05fa9e1dafd4950d4b9851a6a2e093', 'message': 'Removing *.pyc files after applying a patch\n\nAdds to a patching procedure that one needs to delete\nappropriate *.pyc files after applying a patch and\nbefore restarting a service.\n\nChange-Id: Id5736403614478fcfa1e1006f98516ef44da4e01\n'}, {'number': 2, 'created': '2015-03-26 07:45:23.000000000', 'files': ['pages/operations/patch/0050-apply-patch.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d856ed8d6905573fd03bcd5026bfc571fcbfb57c', 'message': 'Removing *.pyc files after applying a patch\n\nAdds to a patching procedure that one needs to delete\nappropriate *.pyc files after applying a patch and\nbefore restarting a service.\n\nChange-Id: Id5736403614478fcfa1e1006f98516ef44da4e01\n'}]",1,167571,d856ed8d6905573fd03bcd5026bfc571fcbfb57c,17,7,2,14643,,,0,"Removing *.pyc files after applying a patch

Adds to a patching procedure that one needs to delete
appropriate *.pyc files after applying a patch and
before restarting a service.

Change-Id: Id5736403614478fcfa1e1006f98516ef44da4e01
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/71/167571/2 && git format-patch -1 --stdout FETCH_HEAD,['pages/operations/patch/0050-apply-patch.rst'],1,90e284e14b05fa9e1dafd4950d4b9851a6a2e093,apply_patch_note," .. note:: After applying the patch, but before restarting the service, it is highly recommended to remove the ``*.pyc`` files from the corresponding directory.",,2,0
openstack%2Ftripleo-common~master~Ib78b12ea45792d607a354b444c6c05534a11437d,openstack/tripleo-common,master,Ib78b12ea45792d607a354b444c6c05534a11437d,Scale down heat stack,MERGED,2015-05-20 09:15:18.000000000,2015-05-21 15:31:59.000000000,2015-05-21 15:31:58.000000000,"[{'_account_id': 3}, {'_account_id': 7582}, {'_account_id': 8041}, {'_account_id': 8042}, {'_account_id': 15192}]","[{'number': 1, 'created': '2015-05-20 09:15:18.000000000', 'files': ['tripleo_common/tests/test_scale.py', 'tripleo_common/scale.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6ca55cc4a4b21a4c1d24872d2da877f006e16881', 'message': 'Scale down heat stack\n\nAllows scaling down heat stack deployed using tuskar templates.\nIt expects list if nova instance ids on input, for each instance\nit finds heat resource and tuskar role name and then it updates\ntuskar plan with updateed number of nodes for each role and\nit updates heat stack passing it list of resource ids representing\ninstances to remove.\n\nChange-Id: Ib78b12ea45792d607a354b444c6c05534a11437d\n'}]",2,184442,6ca55cc4a4b21a4c1d24872d2da877f006e16881,9,5,1,7582,,,0,"Scale down heat stack

Allows scaling down heat stack deployed using tuskar templates.
It expects list if nova instance ids on input, for each instance
it finds heat resource and tuskar role name and then it updates
tuskar plan with updateed number of nodes for each role and
it updates heat stack passing it list of resource ids representing
instances to remove.

Change-Id: Ib78b12ea45792d607a354b444c6c05534a11437d
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/42/184442/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/test_scale.py', 'tripleo_common/scale.py']",2,6ca55cc4a4b21a4c1d24872d2da877f006e16881,scaledown1," self.plan.uuid, [{'name': param_name, 'value': str(num)}]) self._update_stack() def scaledown(self, instances): resources = self.heatclient.resources.list(self.stack_id, nested_depth=5) resources_by_role = {} instance_list = list(instances) for res in resources: try: instance_list.remove(res.physical_resource_id) except ValueError: continue stack_name, stack_id = next( x['href'] for x in res.links if x['rel'] == 'stack').rsplit('/', 2)[1:] # get resource to remove from resource group (it's parent resource # of nova server) role_resource = next(x for x in resources if x.physical_resource_id == stack_id) # get tuskar role name from resource_type, # resource_type is in format like ""Tuskar::Compute-1"" role = role_resource.resource_type.rsplit('::', 1)[-1] if role not in resources_by_role: resources_by_role[role] = [] resources_by_role[role].append(role_resource) if instance_list: raise ValueError( ""Couldn't find following instances in stack %s: %s"" % (self.stack_id, ','.join(instance_list))) # decrease count for each tuskar role in tuskar plan and add removal # policy for each resource group patch_params = [] stack_params = {} for role, role_resources in resources_by_role.items(): param_name = ""{0}::count"".format(role) old_count = next(x['value'] for x in self.plan.parameters if x['name'] == param_name) count = max(int(old_count) - len(role_resources), 0) patch_params.append({'name': param_name, 'value': str(count)}) # add instance resource names into removal_policies # so heat knows which instances should be removed removal_param = ""{0}::removal_policies"".format(role) stack_params[removal_param] = [{ 'resource_list': [r.resource_name for r in role_resources] }] LOG.debug('updating plan %s: %s', self.plan.uuid, patch_params) self.plan = self.tuskarclient.plans.patch(self.plan.uuid, patch_params) self._update_stack(parameters=stack_params) def _update_stack(self, parameters={}): 'environment': env, 'parameters': parameters"," self.plan.uuid, [{'name': param_name, 'value': str(num)}]) 'environment': env",113,11
openstack%2Ftempest~master~I07aa30091c8d0171b942e1804f5894d625363fdd,openstack/tempest,master,I07aa30091c8d0171b942e1804f5894d625363fdd,Ensure scenario utils creds are cleaned up,MERGED,2015-05-14 23:51:59.000000000,2015-05-21 15:31:19.000000000,2015-05-21 15:31:16.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5689}, {'_account_id': 8871}]","[{'number': 1, 'created': '2015-05-14 23:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7e061e1c16f21c467b661028a4225276c4265cc8', 'message': ""Ensure scenario utils creds are cleaned up\n\nThis commit makes 2 changes to the scenario utils methods to ensure\nthat any created credentials are cleaned up after they are no longer\nneeded. The first change switches the ImageUtils class to not create\nit's own creds, it is only called from inside of a test class which\nhas already allocated credentials. So instead this just passes them\ninto the class. The second is to add a cleanup helper on\nInputScenarioUtils which gets called after all the api calls that\nneeds credentials are made.\n\nChange-Id: I07aa30091c8d0171b942e1804f5894d625363fdd\n""}, {'number': 2, 'created': '2015-05-15 16:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/39e35d8beaea13154666de619f2c780a9b7e72ab', 'message': ""Ensure scenario utils creds are cleaned up\n\nThis commit makes 2 changes to the scenario utils methods to ensure\nthat any created credentials are cleaned up after they are no longer\nneeded. The first change switches the ImageUtils class to not create\nit's own creds, it is only called from inside of a test class which\nhas already allocated credentials. So instead this just passes them\ninto the class. The second is to add a cleanup helper on\nInputScenarioUtils which gets called after all the api calls that\nneeds credentials are made.\n\nCloses-Bug: #1455561\nChange-Id: I07aa30091c8d0171b942e1804f5894d625363fdd\n""}, {'number': 3, 'created': '2015-05-15 17:03:28.000000000', 'files': ['tempest/scenario/test_server_basic_ops.py', 'tempest/scenario/utils.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/96cadf48145b6e38ae0768675e97a08e79e00bbb', 'message': ""Ensure scenario utils creds are cleaned up\n\nThis commit makes 2 changes to the scenario utils methods to ensure\nthat any created credentials are cleaned up after they are no longer\nneeded. The first change switches the ImageUtils class to not create\nit's own creds, it is only called from inside of a test class which\nhas already allocated credentials. So instead this just passes them\ninto the class. The second is to add a cleanup helper on\nInputScenarioUtils which gets called after all the api calls that\nneeds credentials are made.\n\nCloses-Bug: #1455561\nChange-Id: I07aa30091c8d0171b942e1804f5894d625363fdd\n""}]",0,183358,96cadf48145b6e38ae0768675e97a08e79e00bbb,15,4,3,5196,,,0,"Ensure scenario utils creds are cleaned up

This commit makes 2 changes to the scenario utils methods to ensure
that any created credentials are cleaned up after they are no longer
needed. The first change switches the ImageUtils class to not create
it's own creds, it is only called from inside of a test class which
has already allocated credentials. So instead this just passes them
into the class. The second is to add a cleanup helper on
InputScenarioUtils which gets called after all the api calls that
needs credentials are made.

Closes-Bug: #1455561
Change-Id: I07aa30091c8d0171b942e1804f5894d625363fdd
",git fetch https://review.opendev.org/openstack/tempest refs/changes/58/183358/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/test_server_basic_ops.py', 'tempest/scenario/utils.py']",2,7e061e1c16f21c467b661028a4225276c4265cc8,(HEAD," def __init__(self, os): def clear_creds(self): self.isolated_creds.clear_isolated_creds() output = None output = standard_tests finally: scenario_utils.clear_creds() if output is not None: return output"," def __init__(self): network_resources = { 'network': False, 'router': False, 'subnet': False, 'dhcp': False, } self.isolated_creds = credentials.get_isolated_credentials( name='ScenarioImageUtils', identity_version=CONF.identity.auth_version, network_resources=network_resources) os = clients.Manager(self.isolated_creds.get_primary_creds()) return standard_tests",11,14
openstack%2Ftripleo-ci~master~I72a5339a39fd7a447c37bec9f40ef08beb34d5f8,openstack/tripleo-ci,master,I72a5339a39fd7a447c37bec9f40ef08beb34d5f8,Bump up HA job timeout for resource availability,MERGED,2015-05-21 13:20:45.000000000,2015-05-21 15:29:57.000000000,2015-05-21 15:29:57.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 8041}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-05-21 13:20:45.000000000', 'files': ['toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/80a7ba5faa3f3033129eb13e5bf7703e03fc0147', 'message': ""Bump up HA job timeout for resource availability\n\nThe HA jobs are timing out, but it's not because Puppet run would take\nlong. It's getting the VMs reserved which takes long. E.g. [1]:\n\nCompute | CREATE_IN_PROGRESS | 2015-05-21T10:04:14Z\nCompute | CREATE_COMPLETE    | 2015-05-21T10:50:00Z\n\nOr from another job [2]:\n\nController | CREATE_IN_PROGRESS | 2015-05-21T10:17:59Z\nController | CREATE_COMPLETE    | 2015-05-21T11:04:19Z\n\nThis means that Puppet sometimes gets to start only about 50 minutes\nafter the stack-create starts, and then the stack-create exceeds the\ncurrent 60 minute timeout. Hopefully increasing the timeout is just a\ntemporary measure until we're able to fix the root issue of VM creation\ntime.\n\n[1] http://logs.openstack.org/50/184550/2/check-tripleo/check-tripleo-ironic-overcloud-f20puppet-ha/d35a79f/console.html#_2015-05-21_11_09_42_767\n[2] http://logs.openstack.org/17/177117/4/check-tripleo/check-tripleo-ironic-overcloud-f20puppet-ha/68cc435/console.html#_2015-05-21_11_22_36_670\n\nChange-Id: I72a5339a39fd7a447c37bec9f40ef08beb34d5f8\n""}]",0,184782,80a7ba5faa3f3033129eb13e5bf7703e03fc0147,9,7,1,8042,,,0,"Bump up HA job timeout for resource availability

The HA jobs are timing out, but it's not because Puppet run would take
long. It's getting the VMs reserved which takes long. E.g. [1]:

Compute | CREATE_IN_PROGRESS | 2015-05-21T10:04:14Z
Compute | CREATE_COMPLETE    | 2015-05-21T10:50:00Z

Or from another job [2]:

Controller | CREATE_IN_PROGRESS | 2015-05-21T10:17:59Z
Controller | CREATE_COMPLETE    | 2015-05-21T11:04:19Z

This means that Puppet sometimes gets to start only about 50 minutes
after the stack-create starts, and then the stack-create exceeds the
current 60 minute timeout. Hopefully increasing the timeout is just a
temporary measure until we're able to fix the root issue of VM creation
time.

[1] http://logs.openstack.org/50/184550/2/check-tripleo/check-tripleo-ironic-overcloud-f20puppet-ha/d35a79f/console.html#_2015-05-21_11_09_42_767
[2] http://logs.openstack.org/17/177117/4/check-tripleo/check-tripleo-ironic-overcloud-f20puppet-ha/68cc435/console.html#_2015-05-21_11_22_36_670

Change-Id: I72a5339a39fd7a447c37bec9f40ef08beb34d5f8
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/82/184782/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_gate_test.sh'],1,80a7ba5faa3f3033129eb13e5bf7703e03fc0147,ha-timeout," export OVERCLOUD_STACK_TIMEOUT=""90"""," export OVERCLOUD_STACK_TIMEOUT=""60""",1,1
openstack%2Fheat~master~I3e956b39c314b5bd236a4c1a762f01856cea2905,openstack/heat,master,I3e956b39c314b5bd236a4c1a762f01856cea2905,Create security group rules in loose loop,ABANDONED,2014-10-14 10:44:47.000000000,2015-05-21 15:26:27.000000000,,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 10487}, {'_account_id': 10787}, {'_account_id': 13323}]","[{'number': 1, 'created': '2014-10-14 10:44:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/87428f2d41d1cb288774ef968b6e8efe1780b923', 'message': 'Create security group rules in loose loop\n\nChange-Id: I3e956b39c314b5bd236a4c1a762f01856cea2905\nCloses-Bug: #1265937\n'}, {'number': 2, 'created': '2014-10-15 08:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e29bdfec1bd5de02b8c9dcb45e7c4d8ee9ffe695', 'message': 'Create security group rules in loose loop\n\nChange-Id: I3e956b39c314b5bd236a4c1a762f01856cea2905\nCloses-Bug: #1265937\n'}, {'number': 3, 'created': '2014-11-03 11:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e331763aedfa42bf27fa211b8bbdb3cac8474d92', 'message': 'Create security group rules in loose loop\n\nAdded classes CreateRuleNeutronTask and CreateRuleNovaTask which\nallow to create security group rules using scheduler.TaskRunner.\n\nChange-Id: I3e956b39c314b5bd236a4c1a762f01856cea2905\nCloses-Bug: #1265937\n'}, {'number': 4, 'created': '2014-11-03 14:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9e129bd3ce75e88b1d0cdf8041fbec6cde72da5a', 'message': 'Create security group rules in loose loop\n\nAdded classes CreateRuleNeutronTask and CreateRuleNovaTask which\nallow to create security group rules using scheduler.TaskRunner.\n\nChange-Id: I3e956b39c314b5bd236a4c1a762f01856cea2905\nCloses-Bug: #1265937\n'}, {'number': 5, 'created': '2014-11-05 09:29:08.000000000', 'files': ['heat/engine/resources/security_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/acc7c92be6f0a9ba453ca6a2017321be139f47a2', 'message': 'Create security group rules in loose loop\n\nAdded classes CreateRuleNeutronTask and CreateRuleNovaTask which\nallow to create security group rules using scheduler.TaskRunner.\n\nChange-Id: I3e956b39c314b5bd236a4c1a762f01856cea2905\nCloses-Bug: #1265937\n'}]",9,128234,acc7c92be6f0a9ba453ca6a2017321be139f47a2,34,10,5,13323,,,0,"Create security group rules in loose loop

Added classes CreateRuleNeutronTask and CreateRuleNovaTask which
allow to create security group rules using scheduler.TaskRunner.

Change-Id: I3e956b39c314b5bd236a4c1a762f01856cea2905
Closes-Bug: #1265937
",git fetch https://review.opendev.org/openstack/heat refs/changes/34/128234/3 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/security_group.py'],1,87428f2d41d1cb288774ef968b6e8efe1780b923,bug/1265937,"from heat.engine import scheduler from heat.openstack.common import log as logging LOG = logging.getLogger(__name__) checkers = [] task = CreateRuleNovaTask(self, rule, sec) checkers.append(scheduler.TaskRunner(task)) return checkers checkers = [] for rule in new: task = CreateRuleNovaTask(self, rule, sec) checkers.append(scheduler.TaskRunner(task)) return checkers checkers = [] # self.create_rule(rule) task = CreateRuleNeutronTask( self, self._convert_to_neutron_rule(rule)) checkers.append(scheduler.TaskRunner(task)) task = CreateRuleNeutronTask( self, self._convert_to_neutron_rule(rule)) checkers.append(scheduler.TaskRunner(task)) return checkers checkers = [] for rule in new: task = CreateRuleNeutronTask( self, self._convert_to_neutron_rule(rule)) checkers.append(scheduler.TaskRunner(task)) return checkers checkers = impl(self).create() if checkers: checkers[0].start() return checkers def check_create_complete(self, checkers): for checker in checkers: if not checker.started(): checker.start() if not checker.step(): return False return True checkers = impl(self).update(props) if checkers: checkers[0].start() return checkers def check_update_complete(self, checkers): for checker in checkers: if not checker.started(): checker.start() if not checker.step(): return False return True class CreateRuleNovaTask(object): def __init__(self, group, rule, sec): self.group = group self.rule = rule self.sec = sec def __str__(self): return ""Adding rule to security group id %s"" % self.sec.id def __repr__(self): return ""%s+="" % self.sec.id def __call__(self): LOG.debug(str(self)) try: self.group.client.security_group_rules.create( self.sec.id, self.rule.get(self.group.sg.RULE_IP_PROTOCOL), self.rule.get(self.group.sg.RULE_FROM_PORT), self.rule.get(self.group.sg.RULE_TO_PORT), self.rule.get(self.group.sg.RULE_CIDR_IP), self.rule.get(self.group.sg.RULE_SOURCE_SECURITY_GROUP_ID)) except Exception as ex: # ignore error if the group already exists if not (self.group.plugin.is_bad_request(ex) and 'already exists' in six.text_type(ex)): raise yield class CreateRuleNeutronTask(object): def __init__(self, group, rule): self.group = group self.rule = rule def __str__(self): return (""Adding rule to security group id %s"" % self.group.sg.resource_id) def __repr__(self): return ""%s+="" % self.group.sg.resource_id def __call__(self): LOG.debug(str(self)) try: self.group.client.create_security_group_rule({ 'security_group_rule': self.rule}) except Exception as ex: # ignore error if the group already exists if not self.group.plugin.is_conflict(ex): raise yield"," self.create_rule(sec, rule) def create_rule(self, sec, rule): try: self.client.security_group_rules.create( sec.id, rule.get(self.sg.RULE_IP_PROTOCOL), rule.get(self.sg.RULE_FROM_PORT), rule.get(self.sg.RULE_TO_PORT), rule.get(self.sg.RULE_CIDR_IP), rule.get(self.sg.RULE_SOURCE_SECURITY_GROUP_ID)) except Exception as ex: # ignore error if the group already exists if not (self.plugin.is_bad_request(ex) and 'already exists' in six.text_type(ex)): raise for rule in new: self.create_rule(sec, rule) self.create_rule(rule) self.create_rule(rule) def create_rule(self, rule): try: self.client.create_security_group_rule({ 'security_group_rule': self._convert_to_neutron_rule(rule) }) except Exception as ex: # ignore error if the group already exists if not self.plugin.is_conflict(ex): raise for rule in new: self.create_rule(rule) impl(self).create() impl(self).update(props)",108,33
openstack%2Ffuel-web~master~Ie1a210d02e093079d4bd9799f34b954f42cae4db,openstack/fuel-web,master,Ie1a210d02e093079d4bd9799f34b954f42cae4db,"Add uname, lsmod, release files to diag snapshots",MERGED,2015-05-20 16:41:06.000000000,2015-05-21 15:19:34.000000000,2015-05-21 15:07:36.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8789}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-20 16:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0d78191af97b8cd78aaa75715a6f2e5ae06d483e', 'message': 'Add uname, lsmod, release files to diag snapshots\n\nIn order to help with troubleshooting, we would like to capture the\ncurrent running kernel, loaded modules and what OS release the nodes\nare currently running.\n\nChange-Id: Ie1a210d02e093079d4bd9799f34b954f42cae4db\nCloses-Bug: 1457077\n'}, {'number': 2, 'created': '2015-05-21 14:08:37.000000000', 'files': ['nailgun/nailgun/settings.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/50889f0ffc31f5c12f0ba2f72f0f33ae57da057b', 'message': 'Add uname, lsmod, release files to diag snapshots\n\nIn order to help with troubleshooting, we would like to capture the\ncurrent running kernel, loaded modules and what OS release the nodes\nare currently running.\n\nChange-Id: Ie1a210d02e093079d4bd9799f34b954f42cae4db\nCloses-Bug: 1457077\n'}]",3,184540,50889f0ffc31f5c12f0ba2f72f0f33ae57da057b,30,10,2,14985,,,0,"Add uname, lsmod, release files to diag snapshots

In order to help with troubleshooting, we would like to capture the
current running kernel, loaded modules and what OS release the nodes
are currently running.

Change-Id: Ie1a210d02e093079d4bd9799f34b954f42cae4db
Closes-Bug: 1457077
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/40/184540/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/settings.yaml'],1,0d78191af97b8cd78aaa75715a6f2e5ae06d483e,bug/1457077, - type: command command: uname -a to_file: uname_a.txt - type: command command: lsmod to_file: lsmod.txt - type: file path: /etc/*-release - type: command command: uname -a to_file: uname_a.txt - type: command command: lsmod to_file: lsmod.txt - type: file path: /etc/*-release,,16,1
openstack%2Ffuel-qa~master~I953f4becc46d9773865114270eb8e34361e2eedc,openstack/fuel-qa,master,I953f4becc46d9773865114270eb8e34361e2eedc,Changed default fuel-stats collector and stats host,MERGED,2015-05-19 12:58:52.000000000,2015-05-21 15:15:52.000000000,2015-05-21 15:15:52.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 10959}, {'_account_id': 11081}, {'_account_id': 11110}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}]","[{'number': 1, 'created': '2015-05-19 12:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/5a8d6634f4387ca1377589e8f55f8a1929c4738c', 'message': 'Changed default fuel-stats collector host\n\nChanged from fuel-stats-testing.vm.mirantis.net to fuel-stats.vm.miranits.net,\nbecause testing instance is not stable and may be broken.\n\nChange-Id: I953f4becc46d9773865114270eb8e34361e2eedc\nCloses-Bug: #1455741\n'}, {'number': 2, 'created': '2015-05-21 14:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/79bac8f76d9b1eaf528a62405e175eff78e03a6d', 'message': 'Changed default fuel-stats collector and stats host\n\nChanged from fuel-*-testing.vm.mirantis.net to\nspecialized fuel-*-systest.infra.miranits.net,\nbecause testing instance is not stable and may be broken.\n\nfuel-stats-systest.infra.miranits.net is under zabbix monitoring.\n\nChange-Id: I953f4becc46d9773865114270eb8e34361e2eedc\nCloses-Bug: #1455741\n'}, {'number': 3, 'created': '2015-05-21 14:49:00.000000000', 'files': ['fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/dbbb3690d37ba0486a62e2becedb38dfd2fa5656', 'message': 'Changed default fuel-stats collector and stats host\n\nChanged from fuel-*-testing.vm.mirantis.net to\nspecialized fuel-*-systest.infra.miranits.net,\nbecause testing instance is not stable and may be broken.\n\nfuel-stats-systest.infra.miranits.net is under zabbix monitoring.\n\nChange-Id: I953f4becc46d9773865114270eb8e34361e2eedc\nCloses-Bug: #1455741\n'}]",0,184241,dbbb3690d37ba0486a62e2becedb38dfd2fa5656,22,12,3,11110,,,0,"Changed default fuel-stats collector and stats host

Changed from fuel-*-testing.vm.mirantis.net to
specialized fuel-*-systest.infra.miranits.net,
because testing instance is not stable and may be broken.

fuel-stats-systest.infra.miranits.net is under zabbix monitoring.

Change-Id: I953f4becc46d9773865114270eb8e34361e2eedc
Closes-Bug: #1455741
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/41/184241/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/settings.py'],1,5a8d6634f4387ca1377589e8f55f8a1929c4738c,bug/1455741, 'fuel-collect.vm.mirantis.net'), '172.18.160.39'),1,1
openstack%2Ffuel-devops~master~Ia16c0206c1c6d8817970c6d8c9744f6885adba4f,openstack/fuel-devops,master,Ia16c0206c1c6d8817970c6d8c9744f6885adba4f,Fix node attach_to_networks for slave interfaces,ABANDONED,2015-05-12 17:22:05.000000000,2015-05-21 15:11:13.000000000,,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 12867}, {'_account_id': 13505}, {'_account_id': 14372}, {'_account_id': 14953}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-12 17:22:05.000000000', 'files': ['devops/models/node.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/45b73b7ac984a357a7580dacf8b34b621ff9b8ef', 'message': 'Fix node attach_to_networks for slave interfaces\n\nThe node.attach_to_networks function has a bug where the get_networks\ncall is not actually returning the available networks for the node.\nThis causes the slave nodes to be created with out network interfaces.\nTo fix this, the get_networks call is updated with the name__in\nparameter to properly perform an IN sql query since the get_networks\ncall just passes all paramters on to a queryset.\n\nChange-Id: Ia16c0206c1c6d8817970c6d8c9744f6885adba4f\nCloses-Bug: 1444058\n'}]",1,182392,45b73b7ac984a357a7580dacf8b34b621ff9b8ef,11,10,1,14985,,,0,"Fix node attach_to_networks for slave interfaces

The node.attach_to_networks function has a bug where the get_networks
call is not actually returning the available networks for the node.
This causes the slave nodes to be created with out network interfaces.
To fix this, the get_networks call is updated with the name__in
parameter to properly perform an IN sql query since the get_networks
call just passes all paramters on to a queryset.

Change-Id: Ia16c0206c1c6d8817970c6d8c9744f6885adba4f
Closes-Bug: 1444058
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/92/182392/1 && git format-patch -1 --stdout FETCH_HEAD,['devops/models/node.py'],1,45b73b7ac984a357a7580dacf8b34b621ff9b8ef,bug/1444058, networks = self.environment.get_networks(name__in=network_names), networks = self.environment.get_networks(name=network_names),1,1
openstack%2Ffuel-qa~master~I6ff5a350625a078b003688baba0de9e7439647aa,openstack/fuel-qa,master,I6ff5a350625a078b003688baba0de9e7439647aa,"Add exception for ostf smoke, while issue  #1455468 is not fix.",MERGED,2015-05-20 07:03:21.000000000,2015-05-21 14:58:15.000000000,2015-05-21 14:58:14.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 11427}, {'_account_id': 12199}, {'_account_id': 13306}, {'_account_id': 14167}, {'_account_id': 14946}, {'_account_id': 15005}, {'_account_id': 15921}]","[{'number': 1, 'created': '2015-05-20 07:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/e684632ce72c035ee3afd67782fab218e76e1534', 'message': 'Add exception for ostf smoke, while issue  #1455468 is not fix.\nRelated-bug: #1455468\n\nChange-Id: I6ff5a350625a078b003688baba0de9e7439647aa\n'}, {'number': 2, 'created': '2015-05-20 15:05:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/51284f241decb61e7baac025b28d57e728f11731', 'message': 'Add exception for ostf smoke, while issue  #1455468 is not fix.\n\nRelated-bug: #1455468\n\nChange-Id: I6ff5a350625a078b003688baba0de9e7439647aa\n'}, {'number': 3, 'created': '2015-05-20 15:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/1f1c130ba5e84cfb1281623692c1f438d68b2f7f', 'message': 'Add exception for ostf smoke, while issue  #1455468 is not fix.\n\nRelated-bug: #1455468\n\nChange-Id: I6ff5a350625a078b003688baba0de9e7439647aa\n'}, {'number': 4, 'created': '2015-05-20 16:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/53197742b519965353094d3fbcc365f1ada026a9', 'message': 'Add exception for ostf smoke, while issue  #1455468 is not fix.\n\n-Add exception for ostf smoke, while issue  #1455468 is not fix\n-Increase timeout for ""os_conn.get_instance_detail(srv).status"",\n server needs more time to get Active state.\nRelated-bug: #1455468\n\nChange-Id: I6ff5a350625a078b003688baba0de9e7439647aa\n'}, {'number': 5, 'created': '2015-05-20 16:35:05.000000000', 'files': ['fuelweb_test/tests/test_vcenter.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/47584b844cca755ee619bb48c813a6d75a6d0d76', 'message': 'Add exception for ostf smoke, while issue  #1455468 is not fix.\n\n-Add exception for ostf smoke, while issue  #1455468 is not fix\n-Increase timeout for ""os_conn.get_instance_detail(srv).status"",\n server needs more time to get Active state.\nRelated-bug: #1455468\n\nChange-Id: I6ff5a350625a078b003688baba0de9e7439647aa\n'}]",4,184422,47584b844cca755ee619bb48c813a6d75a6d0d76,37,10,5,15660,,,0,"Add exception for ostf smoke, while issue  #1455468 is not fix.

-Add exception for ostf smoke, while issue  #1455468 is not fix
-Increase timeout for ""os_conn.get_instance_detail(srv).status"",
 server needs more time to get Active state.
Related-bug: #1455468

Change-Id: I6ff5a350625a078b003688baba0de9e7439647aa
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/22/184422/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_vcenter.py'],1,e684632ce72c035ee3afd67782fab218e76e1534,glance_fix," cluster_id=cluster_id, test_sets=['sanity', 'ha']) # ##### Fix me if 1455468 is fixed ###### try: self.fuel_web.run_ostf(cluster_id, test_sets=['smoke']) except AssertionError: logger.debug(""Tests failed from first probe,"" "" we sleep 10 seconds try one more time"" "" and if it fails again - test will fails "") time.sleep(60) self.fuel_web.run_ostf(cluster_id, test_sets=['smoke']) cluster_id=cluster_id, test_sets=['sanity', 'ha']) # ##### FIXME if 1455468 is fixed ###### try: self.fuel_web.run_ostf(cluster_id, test_sets=['smoke']) except AssertionError: logger.debug(""Tests failed from first probe,"" "" we sleep 10 seconds try one more time"" "" and if it fails again - test will fails "") time.sleep(60) self.fuel_web.run_ostf(cluster_id, test_sets=['smoke']) cluster_id=cluster_id, test_sets=['sanity', 'ha']) # ##### FIXME if 1455468 is fixed ###### try: self.fuel_web.run_ostf(cluster_id, test_sets=['smoke']) except AssertionError: logger.debug(""Tests failed from first probe,"" "" we sleep 10 seconds try one more time"" "" and if it fails again - test will fails "") time.sleep(60) self.fuel_web.run_ostf(cluster_id, test_sets=['smoke']) cluster_id=cluster_id, test_sets=['sanity', 'ha']) # ##### Fix me if 1455468 is fixed ###### try: self.fuel_web.run_ostf(cluster_id, test_sets=['smoke']) except AssertionError: logger.debug(""Tests failed from first probe,"" "" we sleep 10 seconds try one more time"" "" and if it fails again - test will fails "") time.sleep(60) self.fuel_web.run_ostf(cluster_id, test_sets=['smoke']) cluster_id=cluster_id, test_sets=['sanity', 'ha']) # ##### FIXME if 1455468 is fixed ###### try: self.fuel_web.run_ostf(cluster_id, test_sets=['smoke']) except AssertionError: logger.debug(""Tests failed from first probe,"" "" we sleep 10 seconds try one more time"" "" and if it fails again - test will fails "") time.sleep(60) self.fuel_web.run_ostf(cluster_id, test_sets=['smoke'])"," cluster_id=cluster_id, test_sets=['smoke', 'sanity', 'ha'], timeout=60 * 60) cluster_id=cluster_id, test_sets=['smoke', 'sanity', 'ha'], timeout=60 * 60) cluster_id=cluster_id, test_sets=['smoke', 'sanity', 'ha']) cluster_id=cluster_id, test_sets=['smoke', 'sanity', 'ha']) cluster_id=cluster_id, test_sets=['smoke', 'sanity', 'ha'], timeout=60 * 60)",65,8
openstack%2Ffuel-devops~master~I64b2537990ab99196a91803acfbeb83dec370273,openstack/fuel-devops,master,I64b2537990ab99196a91803acfbeb83dec370273,Add --remove option and additional checks,ABANDONED,2014-10-08 20:43:54.000000000,2015-05-21 14:47:29.000000000,,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 10808}, {'_account_id': 11110}, {'_account_id': 12817}, {'_account_id': 13505}]","[{'number': 1, 'created': '2014-10-08 20:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/f3492ca87e7bfb934ea6bd8701d0d6417b509d2c', 'message': 'Add --remove option and additional checks\n\n  * dos.py sync --remove to remove existing vm/net which are absent in DB\n  * check enviroment existence before any action\n\nChange-Id: I64b2537990ab99196a91803acfbeb83dec370273\n'}, {'number': 2, 'created': '2014-10-08 20:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/4572cb277601badf24de7351e33e9455630bb5b5', 'message': 'Add --remove option and additional checks\n\n  * dos.py sync --remove to remove existing vm/net which are absent in DB\n  * check enviroment existence before any action\n\nChange-Id: I64b2537990ab99196a91803acfbeb83dec370273\n'}, {'number': 3, 'created': '2014-10-08 20:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/d996571278e0724583f60f3dbb0411f1e7d2c975', 'message': 'Add --remove option and additional checks\n\n  * dos.py sync --remove to remove existing vm/net which are absent in DB\n  * check enviroment existence before any action\n\nChange-Id: I64b2537990ab99196a91803acfbeb83dec370273\n'}, {'number': 4, 'created': '2014-10-09 11:13:22.000000000', 'files': ['devops/driver/libvirt/libvirt_driver.py', 'devops/shell.py', 'devops/settings.py', 'devops/manager.py', 'devops/models.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/963750cebe35834598920383ff317540414d9520', 'message': 'Add --remove option and additional checks\n\n  * dos.py sync --remove to remove existing vm/net which are absent in DB\n  * check enviroment existence before any action\n\nChange-Id: I64b2537990ab99196a91803acfbeb83dec370273\n'}]",0,126999,963750cebe35834598920383ff317540414d9520,19,8,4,11110,,,0,"Add --remove option and additional checks

  * dos.py sync --remove to remove existing vm/net which are absent in DB
  * check enviroment existence before any action

Change-Id: I64b2537990ab99196a91803acfbeb83dec370273
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/99/126999/4 && git format-patch -1 --stdout FETCH_HEAD,"['devops/shell.py', 'devops/settings.py', 'devops/manager.py', 'devops/models.py']",4,f3492ca87e7bfb934ea6bd8701d0d6417b509d2c,add_remove_option," def synchronize_all(cls, remove=False): networks = {driver._get_name(e.name, n.name): n for e in cls.objects.all() for n in e.networks} existing_networks = set(driver.network_list()) existing_domains = set(driver.node_list()) domains_to_undefine = [] if remove: domains_to_undefine = existing_domains - set(nodes.keys()) for domain in domains_to_undefine: logger.info('Undefine domain: {0}'.format(domain)) driver.node_remove(domain, True) networks_to_undefine = existing_networks - set(networks.keys()) for network in networks_to_undefine: logger.info('Undefine network: {0}'.format(network)) driver.network_remove(network) nodes_to_remove = set(nodes.keys()) - existing_domains for node in nodes_to_remove: nodes[node].delete() networks_to_undefine = set(networks.keys()) - existing_networks for network in networks_to_undefine: networks[network].delete() cls.erase_empty() logger.info('Undefined domains: %s, removed nodes: %s'. format(domains=len(domains_to_undefine), nodes=len(nodes_to_remove)))"," def synchronize_all(cls): domains = set(driver.node_list()) # FIXME (AWoodward) This willy nilly wacks domains when you run this # on domains that are outside the scope of devops, if anything this # should cause domains to be imported into db instead of undefined. # It also leaves network and volumes around too # Disabled untill a safer implmentation arrives # # domains_to_undefine = domains - set(nodes.keys()) # for d in domains_to_undefine: # driver.node_undefine_by_name(d) nodes_to_remove = set(nodes.keys()) - domains for n in nodes_to_remove: nodes[n].delete() cls.erase_empty() logger.info('Undefined domains: %s, removed nodes: %s', (0, len(nodes_to_remove)))",79,49
openstack%2Ffuel-library~master~I23b46ee5bc01f7cc0ef71c2217a6a88c0114186a,openstack/fuel-library,master,I23b46ee5bc01f7cc0ef71c2217a6a88c0114186a,Remove the task cinder from dependencies of the task cinder-vmware,MERGED,2015-05-19 16:12:46.000000000,2015-05-21 14:40:16.000000000,2015-05-21 14:39:35.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11427}, {'_account_id': 12199}, {'_account_id': 13306}, {'_account_id': 14774}, {'_account_id': 14946}, {'_account_id': 16044}]","[{'number': 1, 'created': '2015-05-19 16:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/869fcc047a5f2b8630fd79adb237b473b8eba538', 'message': 'Remove the task cinder from dependencies of the task cinder-vmware\n\nThere is wrong requires for task top-role-cinder-vmware. In most cases\nit useless. In some --- dangerous.\n\nChange-Id: I23b46ee5bc01f7cc0ef71c2217a6a88c0114186a\nCloses-bug: 1456491\n'}, {'number': 2, 'created': '2015-05-20 13:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ced18969c0f5a86903bac6b165d4f2a05215429c', 'message': 'Remove the task cinder from dependencies of the task cinder-vmware\n\nThere is wrong requires for task top-role-cinder-vmware. In most cases\nit useless. In some --- dangerous.\n\nChange-Id: I23b46ee5bc01f7cc0ef71c2217a6a88c0114186a\nCloses-bug: 1456491\n'}, {'number': 3, 'created': '2015-05-20 18:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a987f4beb980f2d70f675a72914c0ce1b491f4b1', 'message': 'Remove the task cinder from dependencies of the task cinder-vmware\n\nThere is wrong requires for task top-role-cinder-vmware. In most cases\nit useless. In some --- dangerous.\n\nChange-Id: I23b46ee5bc01f7cc0ef71c2217a6a88c0114186a\nCloses-bug: 1456491\n'}, {'number': 4, 'created': '2015-05-21 09:12:01.000000000', 'files': ['deployment/puppet/deployment_groups/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/openstack-cinder/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/vmware/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/roles/tasks.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/242e1d49778a19f57d7deec387931b53dc3816cd', 'message': ""Remove the task cinder from dependencies of the task cinder-vmware\n\nThe task top-role-cinder-vmware depends on 2 tasks: top-role-cinder and\nopenstack-cinder. It's wrong, because openstack-cinder does all needed\njob. In most cases top-role-cinder useless, in some --- dangerous.\n\nFor this reason wrong dependence should be deleted.\n\nChange-Id: I23b46ee5bc01f7cc0ef71c2217a6a88c0114186a\nCloses-bug: 1456491\n""}]",2,184279,242e1d49778a19f57d7deec387931b53dc3816cd,86,13,4,12199,,,0,"Remove the task cinder from dependencies of the task cinder-vmware

The task top-role-cinder-vmware depends on 2 tasks: top-role-cinder and
openstack-cinder. It's wrong, because openstack-cinder does all needed
job. In most cases top-role-cinder useless, in some --- dangerous.

For this reason wrong dependence should be deleted.

Change-Id: I23b46ee5bc01f7cc0ef71c2217a6a88c0114186a
Closes-bug: 1456491
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/79/184279/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/deployment_groups/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/vmware/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/roles/tasks.yaml']",3,869fcc047a5f2b8630fd79adb237b473b8eba538,bug/1456491, groups: [cinder]," groups: [cinder, cinder-vmware]",3,4
openstack%2Fmurano-deployment~master~Ia2837ef11dfba2228381fb77b008bc6ea5068f36,openstack/murano-deployment,master,Ia2837ef11dfba2228381fb77b008bc6ea5068f36,Refactored Windows image-builder,MERGED,2015-05-20 17:38:39.000000000,2015-05-21 14:36:46.000000000,2015-05-21 14:36:46.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7562}]","[{'number': 1, 'created': '2015-05-20 17:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/3af5a4b15f27c8d59e29b8a4a2038b8fcffcf1dd', 'message': 'Refactored Windows image-builder\n\n* main logic rewritten in bash instead of make\n* updated unattended scenarios\n* updated used software\n* updated powershell scripts\n* fixed support if win2k8r2\n\nChange-Id: Ia2837ef11dfba2228381fb77b008bc6ea5068f36\n'}, {'number': 2, 'created': '2015-05-20 17:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/a06296f0b263c22572399dd96e06020343e045f4', 'message': 'Refactored Windows image-builder\n\n* main logic rewritten in bash instead of make\n* updated unattended scenarios\n* updated used software\n* updated powershell scripts\n* fixed support if win2k8r2\n\nChange-Id: Ia2837ef11dfba2228381fb77b008bc6ea5068f36\n'}, {'number': 3, 'created': '2015-05-20 20:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/f59cc9f23acf4862c1851143d0d4f75cce3b888c', 'message': 'Refactored Windows image-builder\n\n* main logic rewritten in bash instead of make\n* updated unattended scenarios\n* updated used software\n* updated powershell scripts\n* fixed support of win2k8r2\n\nChange-Id: Ia2837ef11dfba2228381fb77b008bc6ea5068f36\n'}, {'number': 4, 'created': '2015-05-21 11:14:07.000000000', 'files': ['contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/autounattend.xml.template', 'contrib/windows/image-builder/share/scripts/Start-Sysprep.ps1', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/README.rts', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/1.Windows-Post-Install.ps1', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/autounattend.xml.template', 'contrib/windows/image-builder/share/files/README.rst', 'contrib/windows/image-builder/share/scripts/REAME.rst', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/3.Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/lib/templates/smbshare.conf.template', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/3.Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/share/scripts/ws-2008r2-core/wpi.ps1', 'contrib/windows/image-builder/share/scripts/ws-2008r2-std/Start-Sysprep.ps1', 'contrib/windows/image-builder/share/files/ws-2012-core/autounattend.xml.template', 'contrib/windows/image-builder/share/files/ws-2008r2-std/unattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/README.rst', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/README.rst', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/3.Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/share/files/ws-2008r2-std/README.rst', 'contrib/windows/image-builder/process_config.sh', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/1.Windows-Post-Install.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/config.ini', 'contrib/windows/image-builder/share/scripts/ws-2008r2-core/Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/share/files/ws-2012-std/README.rst', 'contrib/windows/image-builder/functions.sh', 'contrib/windows/image-builder/Makefile', 'contrib/windows/image-builder/lib/templates/README.rst', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/1.Windows-Post-Install.ps1', 'contrib/windows/image-builder/share/scripts/ws-2012-core/wpi.ps1', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/autounattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/unattend.xml.template', 'contrib/windows/image-builder/share/scripts/ws-2008r2-std/wpi.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/README.rst', 'contrib/windows/image-builder/share/README.rst', 'contrib/windows/image-builder/install.sh', 'contrib/windows/image-builder/launch-vm.sh', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/unattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/autounattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/unattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/1.Windows-Post-Install.ps1', 'contrib/windows/image-builder/README.rst', 'contrib/windows/image-builder/substvars.sh', 'contrib/windows/image-builder/lib/templates/deafultnet.template', 'contrib/windows/image-builder/share/scripts/ws-2012-core/Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/lib/windowssetup/unattend/README.rst', 'contrib/windows/image-builder/share/files/userdata.py', 'contrib/windows/image-builder/share/files/ws-2012-core/unattend.xml.template', 'contrib/windows/image-builder/install-vm.sh', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/README.rst', 'contrib/windows/image-builder/share/files/ws-2012-core/README.rst', 'contrib/windows/image-builder/share/files/ws-2008r2-core/README.rst', 'contrib/windows/image-builder/share/scripts/ws-2012-std/wpi.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/README.rst', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/README.rst', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/unattend.xml.template', 'contrib/windows/image-builder/share/scripts/Get-InstalledSoftware.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/3.Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/README.rst', 'contrib/windows/image-builder/share/scripts/ws-2012-std/Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/README.rst', 'contrib/windows/image-builder/runme.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/a66da37ca49ce92a2720970b8133d4a2da0e3fa4', 'message': 'Refactored Windows image-builder\n\n* main logic rewritten in bash instead of make\n* updated unattended scenarios\n* updated used software\n* updated powershell scripts\n* fixed support of win2k8r2\n\nChange-Id: Ia2837ef11dfba2228381fb77b008bc6ea5068f36\n'}]",5,184556,a66da37ca49ce92a2720970b8133d4a2da0e3fa4,15,5,4,7613,,,0,"Refactored Windows image-builder

* main logic rewritten in bash instead of make
* updated unattended scenarios
* updated used software
* updated powershell scripts
* fixed support of win2k8r2

Change-Id: Ia2837ef11dfba2228381fb77b008bc6ea5068f36
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/56/184556/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/autounattend.xml.template', 'contrib/windows/image-builder/share/scripts/Start-Sysprep.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/1.Windows-Post-Install.ps1', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/autounattend.xml.template', 'contrib/windows/image-builder/share/files/README.rst', 'contrib/windows/image-builder/share/scripts/REAME.rst', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/3.Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/lib/templates/smbshare.conf.template', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/3.Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/share/scripts/ws-2008r2-core/wpi.ps1', 'contrib/windows/image-builder/share/scripts/ws-2008r2-std/Start-Sysprep.ps1', 'contrib/windows/image-builder/share/files/ws-2012-core/autounattend.xml.template', 'contrib/windows/image-builder/share/files/ws-2008r2-std/unattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/README.md', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/3.Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/share/files/ws-2008r2-std/README.rst', 'contrib/windows/image-builder/process_config.sh', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/1.Windows-Post-Install.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/config.ini', 'contrib/windows/image-builder/share/scripts/ws-2008r2-core/Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/share/files/ws-2012-std/README.rst', 'contrib/windows/image-builder/functions.sh', 'contrib/windows/image-builder/Makefile', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-standard/1.Windows-Post-Install.ps1', 'contrib/windows/image-builder/share/scripts/ws-2012-core/wpi.ps1', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/autounattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/unattend.xml.template', 'contrib/windows/image-builder/lib/templates/README.md', 'contrib/windows/image-builder/share/scripts/ws-2008r2-std/wpi.ps1', 'contrib/windows/image-builder/share/README.rst', 'contrib/windows/image-builder/install.sh', 'contrib/windows/image-builder/README.md', 'contrib/windows/image-builder/launch-vm.sh', 'contrib/windows/image-builder/lib/windowssetup/unattend/README.md', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/README.md', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/unattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/autounattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-core/unattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/scripts/common/userdata.py', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/1.Windows-Post-Install.ps1', 'contrib/windows/image-builder/README.rst', 'contrib/windows/image-builder/substvars.sh', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/README.md', 'contrib/windows/image-builder/lib/templates/deafultnet.template', 'contrib/windows/image-builder/lib/windowssetup/scripts/README.md', 'contrib/windows/image-builder/share/scripts/ws-2012-core/Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/share/files/ws-2012-core/unattend.xml.template', 'contrib/windows/image-builder/install-vm.sh', 'contrib/windows/image-builder/share/files/ws-2012-core/README.rst', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k8r2-standard/README.md', 'contrib/windows/image-builder/share/files/ws-2008r2-core/README.rst', 'contrib/windows/image-builder/share/scripts/ws-2012-std/wpi.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k8r2-core/README.md', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/unattend.xml.template', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-standard/README.md', 'contrib/windows/image-builder/share/scripts/Get-InstalledSoftware.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/README.md', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-standard/2.Start-Sysprep.ps1', 'contrib/windows/image-builder/lib/windowssetup/scripts/w2k12r2-core/3.Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/share/scripts/ws-2012-std/Start-AtFirstBoot.ps1', 'contrib/windows/image-builder/lib/windowssetup/unattend/w2k12r2-core/README.md', 'contrib/windows/image-builder/runme.sh']",65,3af5a4b15f27c8d59e29b8a4a2038b8fcffcf1dd,,"#!/bin/bash # Copyright (c) 2015 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # START_DIR=""$(cd ""$(dirname ""${0}"")"" && pwd)"" WORK_DIR=""${START_DIR}/workspace"" CFG_FILE=""${CFG_FILE:-$START_DIR/config.ini}"" LOG_DIR=""${START_DIR}/logs"" LOG_FILE=""${LOG_DIR}/run_$(date +%Y-%m-%d_%H).log"" LOG_LVL=3 declare -A Config ######## FUNCTIONS ############## # logler function log() { local input=""$*"" if [ ! -d ""${LOG_DIR}"" ]; then mkdir -p ""${LOG_DIR}"" fi case ""${LOG_LVL}"" in 3) if [ ! -z ""${input}"" ]; then echo ""${input}"" | tee -a ""${LOG_FILE}"" fi ;; 2) if [ ! -z ""${input}"" ]; then echo ""${input}"" >> ""${LOG_FILE}"" fi ;; 1) if [ ! -z ""${input}"" ]; then echo ""${input}"" fi ;; *) ;; esac } # iniget config-file section option function iniget { local xtrace='' xtrace=$(set +o | grep xtrace) set +o xtrace local file=$1 local section=$2 local option=$3 local line line=$(sed -ne ""/^\[$section\]/,/^\[.*\]/ { /^$option[ \t]*=/ p; }"" ""$file"") echo ""${line#*=}"" $xtrace } # ini_has_option config-file section option function ini_has_option_sudo() { local file=$1 local section=$2 local option=$3 local line line=$(sudo sed -ne ""/^\[$section\]/,/^\[.*\]/ { /^$option[ \t]*=/ p; }"" ""$file"") [ -n ""$line"" ] } # iniset config-file section option value function iniset_sudo() { local xtrace=$(set +o | grep xtrace) set +o xtrace local file=$1 local section=$2 local option=$3 local value=$4 [[ -z $section || -z $option ]] && return if ! sudo grep -q ""^\[$section\]"" ""$file"" 2>/dev/null; then # Add section at the end echo -e ""\n[$section]"" | sudo tee -a ""$file"" fi if ! ini_has_option_sudo ""$file"" ""$section"" ""$option""; then # Add it sudo sed -i -e ""/^\[$section\]/ a\\ $option = $value "" ""$file"" else local sep=$(echo -ne ""\x01"") # Replace it sudo sed -i -e '/^\['${section}'\]/,/^\[.*\]/ s'${sep}'^\('${option}'[ \t]*=[ \t]*\).*$'${sep}'\1'""${value}""${sep} ""$file"" 2>/dev/null fi $xtrace } # check reuirements function check_sys_packages() { local forceinstall=""${1:-false}"" local retval=0 local packages=""qemu-kvm virt-manager virt-goodies virtinst bridge-utils libvirt-bin uuid-runtime samba samba-common cifs-utils"" if [ ! -f ""/etc/debian_version"" ] || ! lsb_release -a 2>/dev/null | grep -qE '(Mint|Ubuntu|Debian)'; then log ""Err: Ubuntu like distros only supported for now !"" exit 2 fi for package in ${packages} do dpkg-query --status ""${package}"" >> /dev/null 2>&1 if [ ""$?"" -ne 0 ]; then if [ ""${forceinstall}"" == true ]; then sudo apt-get install -y ""${package}"" || retval=$? else log ""Wrn: ${package} required, please install it !"" retval=1 fi fi done sudo usermod -a -G libvirtd ""${USER}"" 2>/dev/null return ""${retval}"" } # read configuration function init() { local wdir='' local vmswdir='' #local vioiso='' local reqsoft='' local winrels='' local prun='' local smbmode='' local smbhost='' local smbuser='' local smbdomain='' local smbpasswd='' local smbcredsfile='' local smbsharename='' wdir=""$(iniget ""${CFG_FILE}"" ""default"" ""workdir"")"" vmswdir=""$(iniget ""${CFG_FILE}"" ""default"" ""vmsworkdir"")"" prun=""$(iniget ""${CFG_FILE}"" ""default"" ""runparallel"")"" reqsoft=""$(iniget ""${CFG_FILE}"" ""default"" ""requirements"")"" winrels=""$(iniget ""${CFG_FILE}"" ""default"" ""available_win_versions"")"" smbmode=""$(iniget ""${CFG_FILE}"" ""samba"" ""mode"")"" smbhost=""$(iniget ""${CFG_FILE}"" ""samba"" ""host"")"" smbuser=""$(iniget ""${CFG_FILE}"" ""samba"" ""user"")"" smbdomain=""$(iniget ""${CFG_FILE}"" ""samba"" ""domain"")"" smbpasswd=""$(iniget ""${CFG_FILE}"" ""samba"" ""password"")"" smbsharename=""$(iniget ""${CFG_FILE}"" ""samba"" ""sharename"")"" if [ ! -z ""${reqsoft}"" ]; then Config[""requirements""]=""${reqsoft}""; fi if [ ! -z ""${winrels}"" ]; then Config[""win_releases""]=""${winrels}""; fi if [ ! -z ""${prun}"" ]; then Config[""runparallel""]=""${prun}""; fi if [ ! -z ""${wdir}"" ]; then WORK_DIR=""${wdir}/workspace""; fi if [ ! -z ""${vmswdir}"" ]; then sudo mkdir -p ""${vmswdir}"" && sudo chown -R ""${USER}"" ""${vmswdir}"" || exit 2 Config[""vmsworkdir""]=""${vmswdir}"" fi if [ ! -d ""$WORK_DIR"" ]; then sudo mkdir -p ""${WORK_DIR}"" && sudo chown -R ""${USER}"":""${USER}"" ""${WORK_DIR}""/ || exit $? fi mkdir -p ""${WORK_DIR}/mnt"" || exit $? mkdir -p ""${WORK_DIR}/downloads"" || exit $? smbcredsfile=""${WORK_DIR}/smb.creds"" Config[""smbcredsfile""]=""${smbcredsfile}"" Config[""loopmountoptions""]=""-o uid=$(id -u),gid=$(id -g),loop"" Config[""smbmountoptions""]=""-o vers=2.0,nounix,iocharset=utf8,uid=$(id -u),gid=$(id -g)"" if [ ""${smbmode}"" == ""local"" ]; then Config[""smblocalsetuprequired""]=true else Config[""smblocalsetuprequired""]=false fi if [ ""${smbuser}"" != ""guest"" ]; then if [ -f ""${Config[""smbcredsfile""]}"" ]; then rm -f ""${Config[""smbcredsfile""]}"" || exit $?; fi echo username=""${smbuser}"" > ""${Config[""smbcredsfile""]}"" if [ ! -z ""${smbdomain}"" ]; then echo domain=""${smbdomain}"" >> ""${Config[""smbcredsfile""]}"" else echo domain=""${smbhost}"" >> ""${Config[""smbcredsfile""]}"" fi echo password=""${smbpasswd}"" >> ""${Config[""smbcredsfile""]}"" Config[""smbmountoptions""]+="",credentials=${Config[""smbcredsfile""]}"" else Config[""smbmountoptions""]+="",guest"" fi Config[""smbmountpoint""]=""${WORK_DIR}/mnt"" Config[""smbshare""]=""//${smbhost}/${smbsharename}"" Config[""downloadsdir""]=""${WORK_DIR}/downloads"" } # check disk space function check_free_space() { local min_free_g=""50"" local sys_free='' log ""Checking free space for ${Config[""vmsworkdir""]} folder partition..."" sys_free=""$(sudo df ""${Config[""vmsworkdir""]}"" --total -k -h --output=avail | head -n2 | tail -n1)"" if [ ""${sys_free/G/}"" -lt ""${min_free_g}"" ]; then log ""Err: You have not enough free space ${sys_free} at ${Config[""vmsworkdir""]}, required - ${min_free_g}G!"" exit 2 fi } # check libvirt function check_libvirtnet() { local networkname='default' log ""Checking libvirt network..."" virsh net-list | grep -q ""${networkname}"" if [ ""$?"" -ne 0 ]; then virsh net-define ""${START_DIR}/lib/templates/defaultnet.template"" || exit 2 virsh net-autostart ""${networkname}"" || exit 2 virsh net-start ""${networkname}"" || exit 2 fi } # iptables rules for local Samba server function set_iptables_smb_rules() { log ""Configuring iptables rules..."" sudo iptables -nvL INPUT | grep -q 'NetBIOS Name Service' || sudo iptables -A INPUT -p udp --dport 137 -m comment --comment ""add by winimage-builder - NetBIOS Name Service"" -j ACCEPT sudo iptables -nvL INPUT | grep -q 'NetBIOS Datagram Service' || sudo iptables -A INPUT -p udp --dport 138 -m comment --comment ""add by winimage-builder - NetBIOS Datagram Service"" -j ACCEPT sudo iptables -nvL INPUT | grep -q 'NetBIOS Session Service' || sudo iptables -A INPUT -p tcp --dport 139 -m comment --comment ""add by winimage-builder - NetBIOS Session Service"" -j ACCEPT sudo iptables -nvL INPUT | grep -q 'Microsoft Directory Service' || sudo iptables -A INPUT -p tcp --dport 445 -m comment --comment ""add by winimage-builder - Microsoft Directory Service"" -j ACCEPT } # check & configure local Samba server function prepare_local_sambaserver() { local share_path='' local sharename='' local makeserviceconfiguration=""${1:-false}"" local showtip=""${2:-false}"" local smbconf_path=""/etc/samba/smb.conf"" if [ ""${Config[""smblocalsetuprequired""]}"" == true ]; then if [ -f ""${smbconf_path}"" ] && [ ""${makeserviceconfiguration}"" == true ]; then log ""Configuring local Samba server..."" share_path=""${WORK_DIR}/smbshare"" sudo mkdir -p ""${share_path}"" || return $? sudo chown -R nobody:nogroup ""${share_path}"" sharename=""$(iniget ""${CFG_FILE}"" ""samba"" ""sharename"")"" iniset_sudo ${smbconf_path} ""${sharename}"" 'comment' 'Image Builder Share' iniset_sudo ${smbconf_path} ""${sharename}"" 'path' ""${share_path}"" iniset_sudo ${smbconf_path} ""${sharename}"" 'browsable' ""yes"" iniset_sudo ${smbconf_path} ""${sharename}"" 'guest ok' ""yes"" iniset_sudo ${smbconf_path} ""${sharename}"" 'guest account' ""nobody"" iniset_sudo ${smbconf_path} ""${sharename}"" 'read only' ""no"" iniset_sudo ${smbconf_path} ""${sharename}"" 'create mask' ""0755"" log ""Restarting Samba services..."" sudo restart smbd || return $? sudo restart nmbd || return $? sleep 3 set_iptables_smb_rules return 0 else log ""Err: File ${smbconf_path} not found!"" return 1 fi else if [ ""${showtip}"" == true ]; then log ""FYI: please, configure youre remote samba resource properly with rw access and make modifications at ${CFG_FILE}, [samba] section!"" log ""FYI: Linux /etc/samba/smb.conf part template could looks like this:"" cat ""${START_DIR}/lib/templates/smbshare.conf.template"" fi fi return 0 } # mounting cifs/smbfs function checkmountremote() { sudo mount | grep -q ""${Config[""smbmountpoint""]}"" && umountremote sleep 1 } function mountremote() { log ""Mounting Samba share and checking rw access..."" sudo mount -t cifs ${Config[""smbshare""]} ${Config[""smbmountpoint""]} ${Config[""smbmountoptions""]} if [ ""$?"" -ne 0 ]; then log ""ERR: Can't mount ${Config[""smbshare""]}!""; exit 1;fi touch ""${Config[""smbmountpoint""]}/testfile"" && rm -f ""${Config[""smbmountpoint""]}/testfile"" || exit $? } # function umountremote() { log ""Unounting Samba share..."" sudo umount ""${Config[""smbmountpoint""]}"" if [ ""$?"" -ne 0 ]; then log ""ERR: Can't unmount ${Config[""smbmountpoint""]}!""; exit 1;fi } # prepare CoreFunctions function prepare_corefunctions_ps() { local cf_src_dir='' local cf_zipfile='' cf_src_dir=""$(cd ""${START_DIR}""/../WindowsPowerShell && pwd)"" cd ""${cf_src_dir}"" && make all >> /dev/null 2>&1 if [ ""$?"" -ne 0 ]; then log ""Err: Can't build powershell CoreFunctions !"" exit 2 fi cf_zipfile=""${cf_src_dir}""/CoreFunctions.zip if [ ! -f ""${cf_zipfile}"" ]; then log ""Err: Please, check make parameters at ${cf_src_dir} of file name for ${cf_zipfile} !"" exit 2 fi mv ""${cf_zipfile}"" ""${Config[""downloadsdir""]}"" } # Download function downloadrequirements() { local sw_required=false local sw_redownload=false local sw_download_from='' local sw_download_as='' local sw_download_as_fullpath='' for requirement in ${Config[""requirements""]} do sw_required=""$(iniget ""${CFG_FILE}"" ""${requirement}"" ""required"")"" if [ ""${sw_required}"" == true ]; then sw_download_as=""$(iniget ""${CFG_FILE}"" ""${requirement}"" ""saveas"")"" sw_download_from=""$(iniget ""${CFG_FILE}"" ""${requirement}"" ""url"")"" sw_redownload=""$(iniget ""${CFG_FILE}"" ""${requirement}"" ""redownload"")"" if [ ""${requirement}"" == ""virtio_iso"" ]; then sw_download_as_fullpath=""${WORK_DIR}/${sw_download_as}"" Config[""virtio_iso""]=""${sw_download_as_fullpath}"" else sw_download_as_fullpath=""${Config[""downloadsdir""]}/${sw_download_as}"" fi if [ ! -f ""${sw_download_as_fullpath}"" ] || [ ""${sw_redownload}"" == true ]; then log ""Downloading ${requirement}..."" if [ ""${sw_redownload}"" == true ]; then rm -f ""${sw_download_as_fullpath}""; log "".redownload for ${requirement} enabled"" ;fi wget -q ""${sw_download_from}"" -O ""${sw_download_as_fullpath}"" if [ ""$?"" -ne 0 ]; then log ""Wrn: Error occurred during downloading of ${sw_download_from} !"";fi fi fi done } # show win_releases function show_configured_win_releases() { local rel_enabled=false local rel_iso='' local rel_desc='' local rel_edits='' for release in ${Config[""win_releases""]} do rel_enabled=""$(iniget ""${CFG_FILE}"" ""${release}"" ""enabled"")"" if [ ""${rel_enabled}"" == true ]; then rel_iso=""$(iniget ""${CFG_FILE}"" ""${release}"" ""iso"")"" if [ -f ""${rel_iso}"" ]; then rel_desc=""$(iniget ""${CFG_FILE}"" ""${release}"" ""description"")"" rel_edits=""$(iniget ""${CFG_FILE}"" ""${release}"" ""editions"")"" log ""[${release}] - ${rel_desc}(${rel_edits/ /,})"" else log ""Err: Can't access ${rel_iso}, please check ${CFG_FILE} [${release}] section!"" fi fi done } # prepare mirror function preparemirror() { local mirrordir=""${WORK_DIR}/mirror"" if [ ! -d ""${mirrordir}"" ]; then mkdir ""${mirrordir}"" else rm -rf ""${mirrordir}"" fi mkdir -p ""${mirrordir}/Scripts"" mkdir -p ""${mirrordir}/Files"" cp -r ""${Config[""downloadsdir""]}""/* ""${mirrordir}""/Files/ cp -r ""${START_DIR}""/lib/windowssetup/scripts/* ""${mirrordir}""/Scripts/ } # copy mirror to smbshare function copymirrortomnt() { local mirrordir=""${WORK_DIR}/mirror"" cp -r ""${mirrordir}""/* ""${Config[""smbmountpoint""]}""/ || exit $? rm -rf ""${mirrordir}"" } # prepare virtual floppy image function make_virtualfloppy() { local unattend_dir=""${1}"" local vms_path=""${2}"" local vfloppy='' local smbcreds='' local retval=0 if [ ! -d ""${vms_path}"" ]; then log ""Err: Can't access ${vms_path}, check [defaults]/vmsworkdir parameter !""; return ""${retval}""; fi vfloppy=""${vms_path}/startup.vfd"" sudo rm -f $vfloppy if [ ! -f ""${vfloppy}"" ]; then dd bs=512 count=2880 if=/dev/zero of=""${vfloppy}"" >> /dev/null 2>&1 || return $? mkfs.msdos ""${vfloppy}"" >> /dev/null || retval=$? mkdir -p ""${vms_path}""/mnt/floppy || retval=$? mount | grep -q ""${vms_path}""/mnt/floppy && sudo umount ""${vms_path}""/mnt/floppy 2>/dev/null sudo mount -t vfat ${Config[""loopmountoptions""]} ""${vfloppy}"" ""${vms_path}""/mnt/floppy/ || return $? cp ""${unattend_dir}/autounattend.xml.template"" ""${vms_path}""/mnt/floppy/autounattend.xml cp ""${unattend_dir}/unattend.xml.template"" ""${vms_path}""/mnt/floppy/nextunattend.xml sed ""s/%_IMAGE_BUILDER_HOST_%/$(iniget ""${CFG_FILE}"" ""samba"" ""host"")/g"" -i ""${vms_path}""/mnt/floppy/autounattend.xml || retval=$? sed ""s/%_SHARE_PATH_%/$(iniget ""${CFG_FILE}"" ""samba"" ""sharename"")/g"" -i ""${vms_path}""/mnt/floppy/autounattend.xml || retval=$? if [ ""$(iniget ""${CFG_FILE}"" ""samba"" ""mode"")"" == ""local"" ]; then smbcreds='' else local smbdomain smbdomain=$(iniget ""${CFG_FILE}"" ""samba"" ""domain"") if [ -z ""${smbdomain}"" ]; then smbdomain=$(iniget ""${CFG_FILE}"" ""samba"" ""host""); fi smbcreds=""\""$(iniget ""${CFG_FILE}"" ""samba"" ""password"")\"" \/USER:${smbdomain}\\\\$(iniget ""${CFG_FILE}"" ""samba"" ""user"")"" fi sed ""s/%_SHARE_CREDS_%/${smbcreds}/g"" -i ""${vms_path}""/mnt/floppy/autounattend.xml || retval=$? sleep 1 sudo umount ""${vms_path}""/mnt/floppy || return $? rm -rf ""${vms_path}""/mnt || return $? fi return ""${retval}"" } # copy virtio iso- function copy_virtiodrv() { local vms_path=""${1}"" if [ ! -f ""${Config[""virtio_iso""]}"" ]; then log ""Err: Cant access ${Config[""virtio_iso""]}, check [vitrio_iso] configuration section or file ${Config[""virtio_iso""]} exists !"" exit 2 else cp -f ""${Config[""virtio_iso""]}"" ""${vms_path}""/virtio.iso || return $? fi return 0 } # start install function start_win_vm() { local vms_path=""${1}"" local win_boot_iso_path=""${2}"" local vm_virtio_iso_path='' local vm_setup_vfd_path='' local vm_name='' local vm_build_log='' local vm_img_ref_path='' vm_virtio_iso_path=""${vms_path}""/virtio.iso vm_setup_vfd_path=""${vms_path}""/startup.vfd vm_name=""$(basename ""${vms_path}"")-$(uuidgen --time)"" vm_build_log=""${LOG_DIR}/${vm_name}.log"" vm_img_ref_path=""${WORK_DIR}/$(basename ""${vms_path}"")-ref.qcow2"" if [ ""${Config[""runparallel""]}"" == true ]; then IMAGE_BUILDER_ROOT=${vms_path} IMAGE_NAME=${vm_name} VIRTIO_ISO=${vm_virtio_iso_path} FLOPPY_IMG=${vm_setup_vfd_path} BOOT_ISO=${win_boot_iso_path} VM_REF_IMG_COPY_TO_WORKSPACE=${vm_img_ref_path} bash ""${START_DIR}/launch-vm.sh"" >> ""${vm_build_log}"" 2>&1 & log "" vm preparations in progress, reference image would be built as ${vm_img_ref_path}, check build logfile - ${vm_build_log} !"" else IMAGE_BUILDER_ROOT=${vms_path} IMAGE_NAME=${vm_name} VIRTIO_ISO=${vm_virtio_iso_path} FLOPPY_IMG=${vm_setup_vfd_path} BOOT_ISO=${win_boot_iso_path} VM_REF_IMG_COPY_TO_WORKSPACE=${vm_img_ref_path} bash ""${START_DIR}/launch-vm.sh"" 2>&1 | tee -a ""${vm_build_log}"" fi } # cycled build function process_windows() { local rel_enabled=false local rel_iso='' local rel_desc='' local rel_edits='' local rel_unattend_templ_prefix='' local rel_unattend_templ_dir='' local rel_vms_temp_dir='' for release in ${Config[""win_releases""]} do rel_enabled=""$(iniget ""${CFG_FILE}"" ""${release}"" ""enabled"")"" if [ ""${rel_enabled}"" == true ]; then rel_desc=""$(iniget ""${CFG_FILE}"" ""${release}"" ""description"")"" rel_iso=""$(iniget ""${CFG_FILE}"" ""${release}"" ""iso"")"" rel_edits=""$(iniget ""${CFG_FILE}"" ""${release}"" ""editions"")"" rel_unattend_templ_prefix=""$(iniget ""${CFG_FILE}"" ""${release}"" ""unattend_template_prefix"")"" if [ -z ""${rel_unattend_templ_prefix}"" ]; then rel_unattend_templ_prefix=""${release}"" fi if [ -f ""${rel_iso}"" ]; then for rel_edition in ${rel_edits} do rel_unattend_templ_dir=""${START_DIR}/lib/windowssetup/unattend/${rel_unattend_templ_prefix}-${rel_edition}"" rel_vms_temp_dir=""${Config[""vmsworkdir""]}/${rel_unattend_templ_prefix}-${rel_edition}"" mkdir -p ""${rel_vms_temp_dir}"" || exit 2 make_virtualfloppy ""${rel_unattend_templ_dir}"" ""${rel_vms_temp_dir}"" if [ ""$?"" -ne 0 ]; then log ""Err: Can't create virtual floppy at ${rel_vms_temp_dir} with autounattend.xml !"" exit 2 fi copy_virtiodrv ""${rel_vms_temp_dir}"" if [ ""$?"" -ne 0 ]; then log ""Err: Can't copy virt-io drivers iso(${Config[""virtio_iso""]}) to ${rel_vms_temp_dir} !"" exit 2 fi log ""[${release}] - ${rel_edition} - build started at - ${rel_vms_temp_dir}..."" start_win_vm ""${rel_vms_temp_dir}"" ""${rel_iso}"" done else log ""Err: Can't access ${rel_iso}, please check ${CFG_FILE} [${release}] section!"" fi fi done } # usage function usage() { echo ""${0} --help - Help information --check-smb - Check or configure Samba server, please RUN this command at 1st!(${CFG_FILE} [samba] options) --download-requirements - Download required software dicribed in ${CFG_FILE} --show-configured - Display chosen MS Windows releases to build(${CFG_FILE} [default]/available_win_versions value) --run - Run automated image creation"" echo ""IMPORTANT!: To run this tool you need to setup SUDO WITHOUT PASSWORD PROMPT for your USER !!! run as root: "" } # aka main function run_normal() { check_free_space check_libvirtnet prepare_corefunctions_ps downloadrequirements preparemirror prepare_local_sambaserver if [ ""$?"" -eq 0 ]; then checkmountremote mountremote copymirrortomnt process_windows sleep 1 umountremote fi rm -f ""${Config[""smbcredsfile""]}"" 2>/dev/null } #------------------------------------------------------------------------------ # start of main logic # if [ ""$#"" -eq 0 ]; then usage exit 1 fi # check_sys_packages false init # processing command line args while [ ""$#"" -ge 1 ] do key=""${1}"" case ${key} in --show-configured) show_configured_win_releases break ;; --config-file) if [ ! -z ""${2}"" ] & [ -f ""${2}"" ]; then CFG_FILE=""${2}"" init else echo ""Config file not set properly!"" exit 2 fi shift ;; --download-requirements) downloadrequirements break ;; --check-smb) prepare_local_sambaserver true true if [ ""$?"" -eq 0 ]; then checkmountremote mountremote sleep 1 umountremote rm -f ""${Config[""smbcredsfile""]}"" 2>/dev/null fi break ;; --forceinstall-dependencies) check_sys_packages true shift ;; --run) run_normal break ;; *) usage break ;; esac shift done #------------------------------------------------------------------------------ ",,3322,4668
openstack%2Fhacking~master~I983c754d3455e227d10e5ad7e5bcc3924e079103,openstack/hacking,master,I983c754d3455e227d10e5ad7e5bcc3924e079103,Document the reasoning behind general hacking rules,MERGED,2015-05-19 21:24:11.000000000,2015-05-21 14:32:03.000000000,2015-05-21 14:32:02.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-19 21:24:11.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/hacking/commit/0c4aafb07e916a8de92811b1f706b29db1c6948c', 'message': 'Document the reasoning behind general hacking rules\n\nTry to answer the question why do we have this rule.\n\nChange-Id: I983c754d3455e227d10e5ad7e5bcc3924e079103\n'}]",0,184333,0c4aafb07e916a8de92811b1f706b29db1c6948c,7,3,1,1849,,,0,"Document the reasoning behind general hacking rules

Try to answer the question why do we have this rule.

Change-Id: I983c754d3455e227d10e5ad7e5bcc3924e079103
",git fetch https://review.opendev.org/openstack/hacking refs/changes/33/184333/1 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,0c4aafb07e916a8de92811b1f706b29db1c6948c,docs,"- [H201] Do not write ``except:``, use ``except Exception:`` at the very least. When catching an exception you should be as specific so you don't mistakenly catch unexpected exceptions. - [H101] Include your name with TODOs as in ``# TODO(yourname)``. This makes it easier to find out who the author of the comment was. - [H105] Don't use author tags. We use version control instead. - [H106] Don't put vim configuration in source files (off by default). - Do not shadow a built-in or reserved word. Shadowing built -in or reserved words makes the code harder to understand. Example::- [H306] Alphabetically order your imports by the full module path. Organize your imports according to the `Import order","- [H201] Do not write ``except:``, use ``except Exception:`` at the very least - [H101] Include your name with TODOs as in ``# TODO(yourname)`` - [H105] Don't use author tags. - [H106] Don't put vim configuration in source files (off by default) - Do not shadow a built-in or reserved word. Example::- [H306] Order your imports by the full module path - Organize your imports according to the `Import order",12,7
openstack%2Fhacking~master~Icf1809b0020766f59d6c33ef50bd3176dec55431,openstack/hacking,master,Icf1809b0020766f59d6c33ef50bd3176dec55431,Expand depends documentation in readme,MERGED,2015-05-19 21:24:11.000000000,2015-05-21 14:30:40.000000000,2015-05-21 14:30:40.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-19 21:24:11.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/hacking/commit/93d7f7fcfb905b88ecb64f14ab21f3d1637e8db0', 'message': 'Expand depends documentation in readme\n\n* Update the list of packages it will install\n* Document why we pin dependencies, as this goes against the standard\n  practices in most OpenStack projects.\n\nChange-Id: Icf1809b0020766f59d6c33ef50bd3176dec55431\n'}]",0,184332,93d7f7fcfb905b88ecb64f14ab21f3d1637e8db0,7,3,1,1849,,,0,"Expand depends documentation in readme

* Update the list of packages it will install
* Document why we pin dependencies, as this goes against the standard
  practices in most OpenStack projects.

Change-Id: Icf1809b0020766f59d6c33ef50bd3176dec55431
",git fetch https://review.opendev.org/openstack/hacking refs/changes/32/184332/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,93d7f7fcfb905b88ecb64f14ab21f3d1637e8db0,docs,"Hacking pins its dependencies, as a new release of some dependency can break hacking based gating jobs. This is because new versions of dependencies can introduce new rules, or make existing rules stricter. This will install specific versions of ``flake8`` with the ``hacking``, ``pep8``, ``mccabe`` and ``pyflakes`` plugins.",This will install ``flake8`` with the ``hacking`` and ``pyflake`` plugins,6,1
openstack%2Frally~master~Iaaa2e7f0b35931fd11480737524d9e09371f721a,openstack/rally,master,Iaaa2e7f0b35931fd11480737524d9e09371f721a,[Scenario] Split Scenarios - P6,MERGED,2015-05-17 14:28:31.000000000,2015-05-21 14:25:19.000000000,2015-05-21 14:04:09.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 8576}, {'_account_id': 10475}, {'_account_id': 13919}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-17 14:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/491a7ed3ce12d79e0cee12332b0a44113953a368', 'message': '[Scenario] Split Designate, Neutron, Nova, VM\n\nMove under plugins/openstack\n\nChange-Id: Iaaa2e7f0b35931fd11480737524d9e09371f721a\nImplements: blueprint split-plugins\n'}, {'number': 2, 'created': '2015-05-17 14:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/846a09200ca48a626949c532de33428a08023f35', 'message': '[Scenario] Split Designate, Neutron, Nova, VM\n\nMove under plugins/openstack\n\nChange-Id: Iaaa2e7f0b35931fd11480737524d9e09371f721a\nImplements: blueprint split-plugins\n'}, {'number': 3, 'created': '2015-05-18 05:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4fa7da64813388400c7fbe0466d43e84b25f34af', 'message': '[Scenario] Split Designate, Neutron, Nova, VM\n\nMove under plugins/openstack\n\nChange-Id: Iaaa2e7f0b35931fd11480737524d9e09371f721a\nImplements: blueprint split-plugins\n'}, {'number': 4, 'created': '2015-05-18 06:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6da853fcb086e6eb729872a039b8855099d2718b', 'message': '[Scenario] Split Scenarios - P6\n\nMove under plugins/openstack:\n    * Designate\n    * Neutron\n    * Nova\n    * VM\n\nImplements: blueprint split-plugins\n\nChange-Id: Iaaa2e7f0b35931fd11480737524d9e09371f721a\n'}, {'number': 5, 'created': '2015-05-21 06:36:55.000000000', 'files': ['tests/unit/plugins/openstack/scenarios/designate/__init__.py', 'rally/plugins/openstack/scenarios/nova/keypairs.py', 'tests/unit/plugins/openstack/scenarios/vm/test_utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_servers.py', 'rally/plugins/openstack/scenarios/nova/security_group.py', 'tests/unit/plugins/openstack/scenarios/neutron/test_utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_security_group.py', 'tests/unit/plugins/openstack/scenarios/neutron/test_network.py', 'tests/unit/plugins/openstack/scenarios/designate/test_basic.py', 'rally/plugins/openstack/scenarios/vm/__init__.py', 'rally/plugins/openstack/scenarios/neutron/utils.py', 'rally/plugins/openstack/scenarios/cinder/volumes.py', 'tests/unit/plugins/openstack/scenarios/designate/test_utils.py', 'rally/plugins/openstack/scenarios/murano/environments.py', 'rally/plugins/openstack/scenarios/nova/floating_ips_bulk.py', 'rally/plugins/openstack/context/servers.py', 'tests/unit/plugins/openstack/scenarios/neutron/__init__.py', 'tests/unit/plugins/openstack/scenarios/glance/test_images.py', 'rally/plugins/openstack/scenarios/nova/servers.py', 'rally/plugins/openstack/scenarios/neutron/__init__.py', 'tests/unit/plugins/openstack/scenarios/nova/__init__.py', 'rally/plugins/openstack/context/vm/custom_image.py', 'rally/plugins/openstack/scenarios/glance/images.py', 'tests/unit/plugins/openstack/scenarios/nova/test_keypairs.py', 'rally/plugins/openstack/scenarios/vm/utils.py', 'rally/plugins/openstack/scenarios/designate/utils.py', 'rally/plugins/openstack/scenarios/vm/vmtasks.py', 'rally/common/opts.py', 'rally/plugins/openstack/scenarios/nova/utils.py', 'rally/plugins/openstack/scenarios/designate/__init__.py', 'tests/unit/plugins/openstack/context/test_servers.py', 'rally/plugins/openstack/scenarios/nova/hypervisors.py', 'tests/unit/plugins/openstack/scenarios/nova/test_hypervisors.py', 'rally/plugins/openstack/scenarios/designate/basic.py', 'tests/unit/plugins/openstack/scenarios/nova/test_floating_ips_bulk.py', 'tests/unit/plugins/openstack/scenarios/vm/__init__.py', 'tests/unit/plugins/openstack/scenarios/vm/test_vmtasks.py', 'rally/plugins/openstack/scenarios/neutron/network.py', 'rally/plugins/openstack/scenarios/nova/__init__.py', 'tests/unit/plugins/openstack/scenarios/nova/test_utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/827e41ef98380d00618e027083d6b46ee3f2bc67', 'message': '[Scenario] Split Scenarios - P6\n\nMove under plugins/openstack:\n    * Designate\n    * Neutron\n    * Nova\n    * VM\n\nImplements: blueprint split-plugins\n\nChange-Id: Iaaa2e7f0b35931fd11480737524d9e09371f721a\n'}]",0,183918,827e41ef98380d00618e027083d6b46ee3f2bc67,29,7,5,8576,,,0,"[Scenario] Split Scenarios - P6

Move under plugins/openstack:
    * Designate
    * Neutron
    * Nova
    * VM

Implements: blueprint split-plugins

Change-Id: Iaaa2e7f0b35931fd11480737524d9e09371f721a
",git fetch https://review.opendev.org/openstack/rally refs/changes/18/183918/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/plugins/openstack/scenarios/designate/__init__.py', 'rally/plugins/openstack/scenarios/nova/keypairs.py', 'tests/unit/plugins/openstack/scenarios/vm/test_utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_servers.py', 'rally/plugins/openstack/scenarios/nova/security_group.py', 'tests/unit/plugins/openstack/scenarios/neutron/test_utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_security_group.py', 'tests/unit/plugins/openstack/scenarios/neutron/test_network.py', 'tests/unit/plugins/openstack/scenarios/designate/test_basic.py', 'rally/plugins/openstack/scenarios/vm/__init__.py', 'rally/plugins/openstack/scenarios/neutron/utils.py', 'rally/plugins/openstack/scenarios/cinder/volumes.py', 'tests/unit/plugins/openstack/scenarios/designate/test_utils.py', 'rally/plugins/openstack/scenarios/murano/environments.py', 'rally/plugins/openstack/scenarios/nova/floating_ips_bulk.py', 'rally/plugins/openstack/context/servers.py', 'tests/unit/plugins/openstack/scenarios/neutron/__init__.py', 'tests/unit/plugins/openstack/scenarios/glance/test_images.py', 'rally/plugins/openstack/scenarios/nova/servers.py', 'rally/plugins/openstack/scenarios/neutron/__init__.py', 'tests/unit/plugins/openstack/scenarios/nova/__init__.py', 'rally/plugins/openstack/context/vm/custom_image.py', 'rally/plugins/openstack/scenarios/glance/images.py', 'tests/unit/plugins/openstack/scenarios/nova/test_keypairs.py', 'rally/plugins/openstack/scenarios/vm/utils.py', 'rally/plugins/openstack/scenarios/designate/utils.py', 'rally/plugins/openstack/scenarios/vm/vmtasks.py', 'rally/common/opts.py', 'rally/plugins/openstack/scenarios/nova/utils.py', 'rally/plugins/openstack/scenarios/designate/__init__.py', 'tests/unit/plugins/openstack/context/test_servers.py', 'rally/plugins/openstack/scenarios/nova/hypervisors.py', 'tests/unit/plugins/openstack/scenarios/nova/test_hypervisors.py', 'rally/plugins/openstack/scenarios/designate/basic.py', 'tests/unit/plugins/openstack/scenarios/nova/test_floating_ips_bulk.py', 'tests/unit/plugins/openstack/scenarios/vm/__init__.py', 'tests/unit/plugins/openstack/scenarios/vm/test_vmtasks.py', 'rally/plugins/openstack/scenarios/neutron/network.py', 'rally/plugins/openstack/scenarios/nova/__init__.py', 'tests/unit/plugins/openstack/scenarios/nova/test_utils.py']",40,491a7ed3ce12d79e0cee12332b0a44113953a368,bp/split-plugins,"from rally.plugins.openstack.scenarios.nova import utilsNOVA_UTILS = ""rally.plugins.openstack.scenarios.nova.utils""","from rally.benchmark.scenarios.nova import utilsNOVA_UTILS = ""rally.benchmark.scenarios.nova.utils""",45,47
openstack%2Frally~master~I776e47f8bae3a2d1baebc51c213eb981a58d1975,openstack/rally,master,I776e47f8bae3a2d1baebc51c213eb981a58d1975,[Scenario] Split Scenarios - P5,MERGED,2015-05-17 14:28:31.000000000,2015-05-21 13:52:11.000000000,2015-05-21 13:40:06.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 8576}, {'_account_id': 10475}, {'_account_id': 13919}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-17 14:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d95bbffbb5c9905f80e27499c376cfcbf82c8239', 'message': '[Scenario] Split Zaqar, Mistral, Heat, Ceilometer\n\nMove under plugins/openstack\n\nImplements: blueprint split-plugins\n\nChange-Id: I776e47f8bae3a2d1baebc51c213eb981a58d1975\n'}, {'number': 2, 'created': '2015-05-17 14:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/dde7096d7691f8fcdb1846ebfbfab01f23b103e6', 'message': '[Scenario] Split Zaqar, Mistral, Heat, Ceilometer\n\nMove under plugins/openstack\n\nImplements: blueprint split-plugins\n\nChange-Id: I776e47f8bae3a2d1baebc51c213eb981a58d1975\n'}, {'number': 3, 'created': '2015-05-18 05:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/03459884de85991b0e084153ae4abc94df2d5b59', 'message': '[Scenario] Split Zaqar, Mistral, Heat, Ceilometer\n\nMove under plugins/openstack\n\nImplements: blueprint split-plugins\n\nChange-Id: I776e47f8bae3a2d1baebc51c213eb981a58d1975\n'}, {'number': 4, 'created': '2015-05-18 06:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ad8edbacd7e408d3feabdce217098bf3f2c3301a', 'message': '[Scenario] Split Scenarios - P5\n\nMove under plugins/openstack:\n    * Zaqar\n    * Mistral\n    * Heat\n    * Ceilometer\n\nImplements: blueprint split-plugins\n\nChange-Id: I776e47f8bae3a2d1baebc51c213eb981a58d1975\n'}, {'number': 5, 'created': '2015-05-21 06:36:55.000000000', 'files': ['rally/plugins/openstack/scenarios/ceilometer/queries.py', 'rally/plugins/openstack/scenarios/mistral/__init__.py', 'tests/unit/plugins/openstack/scenarios/mistral/__init__.py', 'tests/unit/plugins/openstack/scenarios/zaqar/test_utils.py', 'tests/unit/plugins/openstack/scenarios/zaqar/test_basic.py', 'rally/plugins/openstack/context/ceilometer.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_resources.py', 'rally/plugins/openstack/scenarios/heat/utils.py', 'rally/plugins/openstack/scenarios/ceilometer/meters.py', 'rally/plugins/openstack/scenarios/ceilometer/stats.py', 'tests/unit/plugins/openstack/scenarios/mistral/test_workbooks.py', 'rally/plugins/openstack/context/stacks.py', 'tests/unit/plugins/openstack/scenarios/mistral/test_utils.py', 'rally/plugins/openstack/scenarios/zaqar/__init__.py', 'rally/plugins/openstack/scenarios/ceilometer/resources.py', 'tests/unit/plugins/openstack/scenarios/heat/__init__.py', 'rally/plugins/openstack/scenarios/zaqar/basic.py', 'rally/plugins/openstack/scenarios/ceilometer/__init__.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_stats.py', 'rally/plugins/openstack/scenarios/ceilometer/samples.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_samples.py', 'rally/plugins/openstack/scenarios/heat/__init__.py', 'tests/unit/plugins/openstack/scenarios/heat/test_stacks.py', 'rally/plugins/openstack/scenarios/mistral/workbooks.py', 'tests/unit/plugins/openstack/context/test_stacks.py', 'tests/unit/plugins/openstack/scenarios/zaqar/__init__.py', 'rally/plugins/openstack/scenarios/zaqar/utils.py', 'rally/common/opts.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_meters.py', 'rally/plugins/openstack/scenarios/ceilometer/alarms.py', 'tests/unit/plugins/openstack/scenarios/heat/test_utils.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_alarms.py', 'rally/plugins/openstack/scenarios/ceilometer/utils.py', 'rally/plugins/openstack/scenarios/mistral/utils.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/__init__.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_utils.py', 'rally/plugins/openstack/scenarios/heat/stacks.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_queries.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/b2b7e20047ff6be74bcb866d300169531ab9720f', 'message': '[Scenario] Split Scenarios - P5\n\nMove under plugins/openstack:\n    * Zaqar\n    * Mistral\n    * Heat\n    * Ceilometer\n\nImplements: blueprint split-plugins\n\nChange-Id: I776e47f8bae3a2d1baebc51c213eb981a58d1975\n'}]",0,183917,b2b7e20047ff6be74bcb866d300169531ab9720f,26,7,5,8576,,,0,"[Scenario] Split Scenarios - P5

Move under plugins/openstack:
    * Zaqar
    * Mistral
    * Heat
    * Ceilometer

Implements: blueprint split-plugins

Change-Id: I776e47f8bae3a2d1baebc51c213eb981a58d1975
",git fetch https://review.opendev.org/openstack/rally refs/changes/17/183917/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/scenarios/ceilometer/queries.py', 'rally/plugins/openstack/scenarios/mistral/__init__.py', 'tests/unit/plugins/openstack/scenarios/mistral/__init__.py', 'tests/unit/plugins/openstack/scenarios/zaqar/test_utils.py', 'tests/unit/plugins/openstack/scenarios/zaqar/test_basic.py', 'rally/plugins/openstack/context/ceilometer.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_resources.py', 'rally/plugins/openstack/scenarios/heat/utils.py', 'rally/plugins/openstack/scenarios/ceilometer/meters.py', 'rally/plugins/openstack/scenarios/ceilometer/stats.py', 'tests/unit/plugins/openstack/scenarios/mistral/test_workbooks.py', 'rally/plugins/openstack/context/stacks.py', 'tests/unit/plugins/openstack/scenarios/mistral/test_utils.py', 'rally/plugins/openstack/scenarios/zaqar/__init__.py', 'rally/plugins/openstack/scenarios/ceilometer/resources.py', 'tests/unit/plugins/openstack/scenarios/heat/__init__.py', 'rally/plugins/openstack/scenarios/zaqar/basic.py', 'rally/plugins/openstack/scenarios/ceilometer/__init__.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_stats.py', 'rally/plugins/openstack/scenarios/ceilometer/samples.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_samples.py', 'rally/plugins/openstack/scenarios/heat/__init__.py', 'tests/unit/plugins/openstack/scenarios/heat/test_stacks.py', 'rally/plugins/openstack/scenarios/mistral/workbooks.py', 'tests/unit/plugins/openstack/context/test_stacks.py', 'tests/unit/plugins/openstack/scenarios/zaqar/__init__.py', 'rally/plugins/openstack/scenarios/zaqar/utils.py', 'rally/common/opts.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_meters.py', 'rally/plugins/openstack/scenarios/ceilometer/alarms.py', 'tests/unit/plugins/openstack/scenarios/heat/test_utils.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_alarms.py', 'rally/plugins/openstack/scenarios/ceilometer/utils.py', 'rally/plugins/openstack/scenarios/mistral/utils.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/__init__.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_utils.py', 'rally/plugins/openstack/scenarios/heat/stacks.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_queries.py']",38,d95bbffbb5c9905f80e27499c376cfcbf82c8239,bp/split-plugins,from rally.plugins.openstack.scenarios.ceilometer import queries,from rally.benchmark.scenarios.ceilometer import queries,43,42
openstack%2Fnova~stable%2Fkilo~I31022213e8a023bf01453c346fe78b4faf6bbdd5,openstack/nova,stable/kilo,I31022213e8a023bf01453c346fe78b4faf6bbdd5,Fixes Nova network manager DHCP server behavior,ABANDONED,2015-05-20 20:57:39.000000000,2015-05-21 13:42:11.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9732}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 16421}]","[{'number': 1, 'created': '2015-05-20 20:57:39.000000000', 'files': ['nova/network/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/acc75c3fd249806045e143619f98ac2005770c96', 'message': 'Fixes Nova network manager DHCP server behavior\n\nThis fixes bug #1456321. When creating multiple networks at once via\nnova-manage network create, the DHCP server for all created networks\nwould be the gateway IP of the first network. This modifies that\nbehavior so that the DHCP server for each network is the same as the\ngateway IP (dhcp_server can still be explicitly provided, which will\noverride this behavior).\n\nChange-Id: I31022213e8a023bf01453c346fe78b4faf6bbdd5\nCloses-Bug: 1456321\n'}]",0,184620,acc75c3fd249806045e143619f98ac2005770c96,13,6,1,16421,,,0,"Fixes Nova network manager DHCP server behavior

This fixes bug #1456321. When creating multiple networks at once via
nova-manage network create, the DHCP server for all created networks
would be the gateway IP of the first network. This modifies that
behavior so that the DHCP server for each network is the same as the
gateway IP (dhcp_server can still be explicitly provided, which will
override this behavior).

Change-Id: I31022213e8a023bf01453c346fe78b4faf6bbdd5
Closes-Bug: 1456321
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/184620/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/manager.py'],1,acc75c3fd249806045e143619f98ac2005770c96,bug/1456321, if dhcp_server: subnet_dhcp_server = dhcp_server else: subnet_dhcp_server = net.gateway if str(net.dhcp_start) == subnet_dhcp_server: net.dhcp_server = subnet_dhcp_server, if not dhcp_server: dhcp_server = net.gateway if str(net.dhcp_start) == dhcp_server: net.dhcp_server = dhcp_server,6,4
openstack%2Fmurano-dashboard~master~Icb7e275694e5900d07b7dc4172601cdf56cc53c6,openstack/murano-dashboard,master,Icb7e275694e5900d07b7dc4172601cdf56cc53c6,[DO NOT MERGE] CI Test,ABANDONED,2015-05-21 11:06:22.000000000,2015-05-21 13:35:53.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 13752}]","[{'number': 1, 'created': '2015-05-21 11:06:22.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/1593bcbe8af9289fec86c1b5c64f1a857b05dfc7', 'message': '[DO NOT MERGE] CI Test\n\nChange-Id: Icb7e275694e5900d07b7dc4172601cdf56cc53c6\n'}]",0,184760,1593bcbe8af9289fec86c1b5c64f1a857b05dfc7,20,3,1,13752,,,0,"[DO NOT MERGE] CI Test

Change-Id: Icb7e275694e5900d07b7dc4172601cdf56cc53c6
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/60/184760/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,1593bcbe8af9289fec86c1b5c64f1a857b05dfc7,,,,0,0
openstack%2Fneutron~master~I90855d665ab8d42c4dd26b91d2e8b63feef122f4,openstack/neutron,master,I90855d665ab8d42c4dd26b91d2e8b63feef122f4,Refactor initialize() of sriov mech driver,MERGED,2015-05-05 12:52:29.000000000,2015-05-21 13:21:31.000000000,2015-05-21 13:21:29.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2035}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8655}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 12561}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}, {'_account_id': 15882}, {'_account_id': 15899}]","[{'number': 1, 'created': '2015-05-05 12:52:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/50f5f18ed26ab7146e2caf168b229d7b06719a4b', 'message': 'Refactor initialize() of sriov mech driver\n\nThis patch rewrites checking correctness of supported_pci_vendor_devs\nconfig value from C-style to Python-style. Patch also adds some tests\nfor wrong values passed.\n\nChange-Id: I90855d665ab8d42c4dd26b91d2e8b63feef122f4\n'}, {'number': 2, 'created': '2015-05-05 14:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d16f25acd02d8eade9c1b0c015ac6211395fd3e', 'message': 'Refactor initialize() of sriov mech driver\n\nThis patch rewrites checking correctness of supported_pci_vendor_devs\nconfig value from C-style to Python-style. Patch also adds some tests\nfor wrong values passed.\n\nChange-Id: I90855d665ab8d42c4dd26b91d2e8b63feef122f4\n'}, {'number': 3, 'created': '2015-05-14 15:57:29.000000000', 'files': ['neutron/plugins/ml2/drivers/mech_sriov/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/mech_sriov/test_mech_sriov_nic_switch.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/750ae6979d920007dc87701cb69db82d72f99fd7', 'message': 'Refactor initialize() of sriov mech driver\n\nThis patch rewrites checking correctness of supported_pci_vendor_devs\nconfig value from C-style to Python-style. Patch also adds some tests\nfor wrong values passed.\n\nChange-Id: I90855d665ab8d42c4dd26b91d2e8b63feef122f4\n'}]",12,180131,750ae6979d920007dc87701cb69db82d72f99fd7,112,37,3,8655,,,0,"Refactor initialize() of sriov mech driver

This patch rewrites checking correctness of supported_pci_vendor_devs
config value from C-style to Python-style. Patch also adds some tests
for wrong values passed.

Change-Id: I90855d665ab8d42c4dd26b91d2e8b63feef122f4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/31/180131/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/mech_sriov/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/mech_sriov/test_mech_sriov_nic_switch.py']",2,50f5f18ed26ab7146e2caf168b229d7b06719a4b,sriov_cleanup," self._set_config(['wrong_entry']) self.assertRaises(cfg.Error, self.driver.initialize) def test_initialize_missing_product_id(self): self._set_config(['vendor_id:']) self.assertRaises(cfg.Error, self.driver.initialize) def test_initialize_missing_vendor_id(self): self._set_config([':product_id']) self.assertRaises(cfg.Error, self.driver.initialize) def test_initialize_multiple_colons(self): self._set_config(['foo:bar:baz']) self.assertRaises(cfg.Error, self.driver.initialize) def test_initialize_missing_empty_string(self): self._set_config([''])", self._set_config('wrong_entry'),29,20
openstack%2Fpuppet-swift~master~I85bccd1f8812ec683eb755a5244e9b7686ab017e,openstack/puppet-swift,master,I85bccd1f8812ec683eb755a5244e9b7686ab017e,Fix puppet-lint issue,ABANDONED,2015-05-18 10:59:17.000000000,2015-05-21 12:43:36.000000000,,"[{'_account_id': 3}, {'_account_id': 5241}, {'_account_id': 7155}]","[{'number': 1, 'created': '2015-05-18 10:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/8a40476527ac43bcaea814909bfd1353bf703be3', 'message': 'Fix puppet-lint issue\n\nChange-Id: I85bccd1f8812ec683eb755a5244e9b7686ab017e\n'}, {'number': 2, 'created': '2015-05-18 13:01:31.000000000', 'files': ['manifests/storage/mount.pp', 'spec/defines/swift_storage_mount_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/5a9b2250247459913b43f18e782ffb5bd78fe0b7', 'message': 'Fix puppet-lint issue\n\nChange-Id: I85bccd1f8812ec683eb755a5244e9b7686ab017e\n'}]",2,184015,5a9b2250247459913b43f18e782ffb5bd78fe0b7,9,3,2,5241,,,0,"Fix puppet-lint issue

Change-Id: I85bccd1f8812ec683eb755a5244e9b7686ab017e
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/15/184015/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/storage/mount.pp'],1,8a40476527ac43bcaea814909bfd1353bf703be3,bug/1444736, if ($::selinux == true) {, if ($::selinux == 'true') {,1,1
openstack%2Fironic~master~I86b245e44a48518ca077b4b84a09e7d72d372702,openstack/ironic,master,I86b245e44a48518ca077b4b84a09e7d72d372702,Fixes some docstring warnings,MERGED,2015-05-05 22:00:41.000000000,2015-05-21 12:35:47.000000000,2015-05-21 12:35:43.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 8119}, {'_account_id': 9066}, {'_account_id': 9751}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 12356}, {'_account_id': 13295}, {'_account_id': 13997}, {'_account_id': 14228}]","[{'number': 1, 'created': '2015-05-05 22:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fee147657327cde3018d9ba2b433f213d87bceec', 'message': ""Fixes some docstring warnings and upgrades Sphinx\n\nSome warnings related to whitespace, improper indentation,\nand improper use of literals are fixed. Sphinx is upgraded to allow\nmocking of dependencies outside Ironic that aren't present at runtime\nwhen building the documentation.\n\nChange-Id: I86b245e44a48518ca077b4b84a09e7d72d372702\nPartial-Bug: 1277282\n""}, {'number': 2, 'created': '2015-05-06 21:25:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/efe825415cbd3597a9370b6c2770e81979349440', 'message': 'Fixes some docstring warnings\n\nSome warnings related to whitespace, improper indentation,\nand improper use of literals are fixed.\n\nChange-Id: I86b245e44a48518ca077b4b84a09e7d72d372702\nPartial-Bug: 1277282\n'}, {'number': 3, 'created': '2015-05-07 17:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a8f46b48ec520d47fc7941271bf9fac7bcc7d1d1', 'message': 'Fixes some docstring warnings\n\nSome warnings related to whitespace, improper indentation,\nand improper use of literals are fixed.\n\nChange-Id: I86b245e44a48518ca077b4b84a09e7d72d372702\nPartial-Bug: 1277282\n'}, {'number': 4, 'created': '2015-05-08 16:44:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bd832b7f9a352a455b423e4564ae9774fa5ea537', 'message': 'Fixes some docstring warnings\n\nSome warnings related to whitespace, improper indentation,\nand improper use of literals are fixed.\n\nChange-Id: I86b245e44a48518ca077b4b84a09e7d72d372702\nPartial-Bug: 1277282\n'}, {'number': 5, 'created': '2015-05-15 19:58:21.000000000', 'files': ['ironic/drivers/modules/msftocs/management.py', 'ironic/drivers/modules/irmc/management.py', 'ironic/dhcp/base.py', 'ironic/drivers/agent.py', 'ironic/drivers/modules/virtualbox.py', 'ironic/drivers/modules/ilo/deploy.py', 'ironic/drivers/modules/pxe.py', 'ironic/drivers/modules/amt/power.py', 'ironic/drivers/modules/msftocs/power.py', 'ironic/drivers/modules/amt/management.py', 'ironic/conductor/task_manager.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/0818ffd3b09373427195a7cfa85b8a903c978033', 'message': 'Fixes some docstring warnings\n\nSome warnings related to whitespace, improper indentation,\nand improper use of literals are fixed.\n\nChange-Id: I86b245e44a48518ca077b4b84a09e7d72d372702\nPartial-Bug: 1277282\n'}]",14,180339,0818ffd3b09373427195a7cfa85b8a903c978033,67,14,5,13295,,,0,"Fixes some docstring warnings

Some warnings related to whitespace, improper indentation,
and improper use of literals are fixed.

Change-Id: I86b245e44a48518ca077b4b84a09e7d72d372702
Partial-Bug: 1277282
",git fetch https://review.opendev.org/openstack/ironic refs/changes/39/180339/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/irmc/management.py', 'ironic/dhcp/base.py', 'ironic/drivers/agent.py', 'ironic/drivers/modules/virtualbox.py', 'test-requirements.txt', 'ironic/drivers/modules/ilo/deploy.py', 'ironic/drivers/modules/pxe.py', 'ironic/drivers/modules/amt/power.py', 'doc/source/conf.py', 'ironic/conductor/task_manager.py', 'ironic/drivers/modules/amt/management.py']",11,fee147657327cde3018d9ba2b433f213d87bceec,bug/1277282," :returns: a dictionary containing:: boot_device: the boot device persistent: Whether the boot device will persist to all future boots or not, None if it is unknown. "," :returns: a dictionary containing: :boot_device: the boot device :persistent: Whether the boot device will persist to all future boots or not, None if it is unknown.",24,13
openstack%2Ffreezer~master~I19c49c668722674b43bea78a601ca05bf5fd690f,openstack/freezer,master,I19c49c668722674b43bea78a601ca05bf5fd690f,Freezer API and UI configuration endpoint,ABANDONED,2015-05-07 16:13:37.000000000,2015-05-21 12:28:03.000000000,,"[{'_account_id': 3}, {'_account_id': 14340}]","[{'number': 1, 'created': '2015-05-07 16:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/623108e2434d000fdc22fa6ed950caeeeaf9af51', 'message': 'Freezer API and UI configuration endpoint\n\nChange-Id: I19c49c668722674b43bea78a601ca05bf5fd690f\n'}, {'number': 2, 'created': '2015-05-13 15:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/bdd3fd2ad27e544dd0c0e481887f532e7afd0118', 'message': 'Freezer API and UI configuration endpoint\n\nChange-Id: I19c49c668722674b43bea78a601ca05bf5fd690f\n'}, {'number': 3, 'created': '2015-05-13 15:46:56.000000000', 'files': ['freezer_api/README.rst', 'freezer/apiclient/client.py', 'freezer_api/freezer_api/api/v1/configs.py', 'freezer_api/freezer_api/storage/elastic.py', 'freezer/apiclient/registration.py', 'freezer_api/freezer_api/api/v1/__init__.py', 'freezer/apiclient/configs.py', 'tests/test_apiclient_backup.py', 'freezer_api/freezer_api/api/v1/clients.py', 'freezer/apiclient/exceptions.py', 'freezer_api/freezer_api/common/utils.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/58292869ac8ca0322b38e1ce3223fa0f055ff51d', 'message': 'Freezer API and UI configuration endpoint\n\nChange-Id: I19c49c668722674b43bea78a601ca05bf5fd690f\n'}]",0,181053,58292869ac8ca0322b38e1ce3223fa0f055ff51d,7,2,3,14340,,,0,"Freezer API and UI configuration endpoint

Change-Id: I19c49c668722674b43bea78a601ca05bf5fd690f
",git fetch https://review.opendev.org/openstack/freezer refs/changes/53/181053/2 && git format-patch -1 --stdout FETCH_HEAD,"['freezer_api/README.rst', 'freezer/apiclient/client.py', 'freezer_api/freezer_api/api/v1/configs.py', 'freezer_api/freezer_api/storage/elastic.py', 'freezer/apiclient/configs.py', 'freezer_api/freezer_api/api/v1/__init__.py', 'freezer/apiclient/exceptions.py', 'freezer_api/freezer_api/common/utils.py']",8,623108e2434d000fdc22fa6ed950caeeeaf9af51,,"import uuid class ConfigDoc: """""" Wraps a config_file dict and adds some utility methods, and fields """""" def __init__(self, user_id='', user_name='', data={}): self.user_id = user_id self.user_name = user_name self.data = data self.id = str(uuid.uuid4()) def is_valid(self): try: assert (self.config_id is not '') assert (self.user_id is not '') except: return False return True def serialize(self): return {'config_id': self.config_id, 'user_id': self.user_id, 'user_name': self.user_name, 'config_file': self.data} @staticmethod def un_serialize(d): return ConfigDoc( user_id=d['user_id'], user_name=d['user_name'], data=d['config_file']) @property def config_set_id(self): return {'config_id': str(uuid.uuid4())} @property def config_id(self): return str(uuid.uuid4())",,296,2
openstack%2Frally~master~I26dfe2418445e4cc772c8d2baffb50894e5f4c05,openstack/rally,master,I26dfe2418445e4cc772c8d2baffb50894e5f4c05,[Scenario] Split Scenarios - P4,MERGED,2015-05-17 14:28:31.000000000,2015-05-21 12:25:36.000000000,2015-05-21 12:14:34.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 8576}, {'_account_id': 10475}, {'_account_id': 13919}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-17 14:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8243c80e5c91e4d74a02b04942d12914265ac193', 'message': '[Scenario] Split Requests, Quotas, Keystone, Authenticate, EC2  under Plugins\n\nMove under plugins/openstack\n\nImplements: blueprint split-plugins\n\nChange-Id: I26dfe2418445e4cc772c8d2baffb50894e5f4c05\n'}, {'number': 2, 'created': '2015-05-17 14:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f602f88c68dbce6ee31238db669bdeae140c64a7', 'message': '[Scenario] Split Requests, Quotas, Keystone, Authenticate, EC2  under Plugins\n\nMove under plugins/openstack\n\nImplements: blueprint split-plugins\n\nChange-Id: I26dfe2418445e4cc772c8d2baffb50894e5f4c05\n'}, {'number': 3, 'created': '2015-05-18 05:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d7a868f572f3b2a272fff4334c8cf4cceccd8ebb', 'message': '[Scenario] Split Requests, Quotas, Keystone, Authenticate, EC2  under Plugins\n\nMove under plugins/openstack\n\nImplements: blueprint split-plugins\n\nChange-Id: I26dfe2418445e4cc772c8d2baffb50894e5f4c05\n'}, {'number': 4, 'created': '2015-05-18 06:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bb4622cfecd5c8a0d2dc3837e0ce08eeada62c2d', 'message': '[Scenario] Split Scenarios - P4\n\nMove under plugins/openstack:\n    * Requests\n    * Quotas\n    * Keystone\n    * Authenticate\n    * EC2\n\nImplements: blueprint split-plugins\n\nChange-Id: I26dfe2418445e4cc772c8d2baffb50894e5f4c05\n'}, {'number': 5, 'created': '2015-05-21 06:36:55.000000000', 'files': ['rally/plugins/openstack/scenarios/ec2/utils.py', 'tests/unit/plugins/openstack/scenarios/quotas/test_utils.py', 'tests/unit/plugins/openstack/context/cleanup/test_resources.py', 'rally/plugins/openstack/scenarios/quotas/utils.py', 'rally/plugins/openstack/scenarios/authenticate/__init__.py', 'rally/plugins/openstack/scenarios/keystone/__init__.py', 'tests/unit/plugins/openstack/scenarios/ec2/test_utils.py', 'rally/plugins/openstack/scenarios/keystone/utils.py', 'tests/unit/plugins/openstack/scenarios/keystone/__init__.py', 'tests/unit/plugins/openstack/scenarios/quotas/test_quotas.py', 'rally/plugins/openstack/scenarios/quotas/quotas.py', 'tests/unit/plugins/openstack/scenarios/quotas/__init__.py', 'rally/plugins/openstack/scenarios/keystone/basic.py', 'tests/unit/plugins/openstack/scenarios/keystone/test_utils.py', 'tests/unit/plugins/openstack/scenarios/ec2/__init__.py', 'rally/plugins/openstack/context/cleanup/resources.py', 'tests/unit/plugins/openstack/scenarios/ec2/test_servers.py', 'tests/unit/plugins/openstack/scenarios/authenticate/__init__.py', 'rally/common/opts.py', 'rally/plugins/openstack/scenarios/quotas/__init__.py', 'tests/unit/plugins/openstack/scenarios/test_authenticate.py', 'tests/unit/plugins/openstack/scenarios/keystone/test_basic.py', 'tests/unit/plugins/openstack/scenarios/authenticate/test_authenticate.py', 'rally/plugins/openstack/scenarios/ec2/servers.py', 'rally/plugins/openstack/scenarios/authenticate/authenticate.py', 'rally/plugins/openstack/scenarios/ec2/__init__.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/86b1175da7a4d12ae16737f67b5b3be888324668', 'message': '[Scenario] Split Scenarios - P4\n\nMove under plugins/openstack:\n    * Quotas\n    * Keystone\n    * Authenticate\n    * EC2\n\nImplements: blueprint split-plugins\n\nChange-Id: I26dfe2418445e4cc772c8d2baffb50894e5f4c05\n'}]",0,183916,86b1175da7a4d12ae16737f67b5b3be888324668,33,8,5,8576,,,0,"[Scenario] Split Scenarios - P4

Move under plugins/openstack:
    * Quotas
    * Keystone
    * Authenticate
    * EC2

Implements: blueprint split-plugins

Change-Id: I26dfe2418445e4cc772c8d2baffb50894e5f4c05
",git fetch https://review.opendev.org/openstack/rally refs/changes/16/183916/3 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/scenarios/ec2/utils.py', 'tests/unit/plugins/openstack/scenarios/quotas/test_utils.py', 'tests/unit/plugins/openstack/context/cleanup/test_resources.py', 'rally/plugins/openstack/scenarios/quotas/utils.py', 'rally/plugins/openstack/scenarios/authenticate/__init__.py', 'rally/plugins/openstack/scenarios/keystone/__init__.py', 'tests/unit/plugins/openstack/scenarios/ec2/test_utils.py', 'rally/plugins/openstack/scenarios/keystone/utils.py', 'tests/unit/plugins/openstack/scenarios/keystone/__init__.py', 'rally/plugins/openstack/scenarios/requests/http_requests.py', 'rally/plugins/openstack/scenarios/requests/utils.py', 'tests/unit/plugins/openstack/scenarios/quotas/test_quotas.py', 'rally/plugins/openstack/scenarios/requests/__init__.py', 'rally/plugins/openstack/scenarios/quotas/quotas.py', 'tests/unit/plugins/openstack/scenarios/requests/test_utils.py', 'tests/unit/plugins/openstack/scenarios/requests/__init__.py', 'tests/unit/plugins/openstack/scenarios/quotas/__init__.py', 'rally/plugins/openstack/scenarios/keystone/basic.py', 'tests/unit/plugins/openstack/scenarios/keystone/test_utils.py', 'tests/unit/plugins/openstack/scenarios/ec2/__init__.py', 'tests/unit/plugins/openstack/scenarios/requests/test_http_requests.py', 'rally/plugins/openstack/context/cleanup/resources.py', 'tests/unit/plugins/openstack/scenarios/ec2/test_servers.py', 'tests/unit/plugins/openstack/scenarios/authenticate/__init__.py', 'rally/common/opts.py', 'rally/plugins/openstack/scenarios/quotas/__init__.py', 'tests/unit/plugins/openstack/scenarios/test_authenticate.py', 'tests/unit/plugins/openstack/scenarios/keystone/test_basic.py', 'tests/unit/plugins/openstack/scenarios/authenticate/test_authenticate.py', 'rally/plugins/openstack/scenarios/ec2/servers.py', 'rally/plugins/openstack/scenarios/authenticate/authenticate.py', 'rally/plugins/openstack/scenarios/ec2/__init__.py']",32,8243c80e5c91e4d74a02b04942d12914265ac193,bp/split-plugins,,,23,25
openstack%2Frally~master~Iecc89784698e4fdcc5dfcf4c1c1abf4f3e52a136,openstack/rally,master,Iecc89784698e4fdcc5dfcf4c1c1abf4f3e52a136,[Scenario] Split Scenarios - requests,MERGED,2015-05-21 06:36:55.000000000,2015-05-21 12:11:55.000000000,2015-05-21 12:09:32.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-21 06:36:55.000000000', 'files': ['tests/unit/plugins/common/scenarios/requests/test_utils.py', 'rally/plugins/common/scenarios/requests/__init__.py', 'tests/unit/plugins/common/scenarios/requests/__init__.py', 'rally/plugins/common/scenarios/requests/http_requests.py', 'rally/plugins/common/scenarios/requests/utils.py', 'tests/unit/plugins/common/scenarios/requests/test_http_requests.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/b8eba75cad21e54d8646d6cca0a3a5963bfd38de', 'message': '[Scenario] Split Scenarios - requests\n\nMove under plugins/common\n\nChange-Id: Iecc89784698e4fdcc5dfcf4c1c1abf4f3e52a136\n'}]",0,184721,b8eba75cad21e54d8646d6cca0a3a5963bfd38de,9,4,1,8576,,,0,"[Scenario] Split Scenarios - requests

Move under plugins/common

Change-Id: Iecc89784698e4fdcc5dfcf4c1c1abf4f3e52a136
",git fetch https://review.opendev.org/openstack/rally refs/changes/21/184721/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/plugins/common/scenarios/requests/test_utils.py', 'rally/plugins/common/scenarios/requests/__init__.py', 'tests/unit/plugins/common/scenarios/requests/__init__.py', 'rally/plugins/common/scenarios/requests/http_requests.py', 'rally/plugins/common/scenarios/requests/utils.py', 'tests/unit/plugins/common/scenarios/requests/test_http_requests.py']",6,b8eba75cad21e54d8646d6cca0a3a5963bfd38de,bp/split-plugins,"from rally.plugins.common.scenarios.requests import http_requestsSCN = ""rally.plugins.common.scenarios""","from rally.benchmark.scenarios.requests import http_requestsSCN = ""rally.benchmark.scenarios""",4,6
openstack%2Fdevstack~stable%2Ficehouse~I5fd214cffb91070f3e2dc8fa7a4e97315d2a3c61,openstack/devstack,stable/icehouse,I5fd214cffb91070f3e2dc8fa7a4e97315d2a3c61,Disable volume bootable flag in tempest for icehouse,ABANDONED,2015-05-14 07:10:11.000000000,2015-05-21 12:10:53.000000000,,"[{'_account_id': 3}, {'_account_id': 5803}]","[{'number': 1, 'created': '2015-05-14 07:10:11.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/de96b4a525063f0e4c1f6631a819fcaacd2b3eb3', 'message': 'Disable volume bootable flag in tempest for icehouse\n\ntempest commit https://review.openstack.org/#/c/181827/\nthis commit add new testcase for tempest to support volume bootable,\nicehouse does not support this flag , updating to bootable false.\n\nChange-Id: I5fd214cffb91070f3e2dc8fa7a4e97315d2a3c61\n'}]",0,182956,de96b4a525063f0e4c1f6631a819fcaacd2b3eb3,3,2,1,11075,,,0,"Disable volume bootable flag in tempest for icehouse

tempest commit https://review.openstack.org/#/c/181827/
this commit add new testcase for tempest to support volume bootable,
icehouse does not support this flag , updating to bootable false.

Change-Id: I5fd214cffb91070f3e2dc8fa7a4e97315d2a3c61
",git fetch https://review.opendev.org/openstack/devstack refs/changes/56/182956/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,de96b4a525063f0e4c1f6631a819fcaacd2b3eb3,, # icehouse does not support bootable volume iniset $TEMPEST_CONFIG volume-feature-enabled bootable False,,2,0
openstack%2Ffuel-web~master~I1b9ddc2d8ec790b5a6cb1095e32559cf506c48e7,openstack/fuel-web,master,I1b9ddc2d8ec790b5a6cb1095e32559cf506c48e7,IBP: configure mcollectived so it daemonizes itself,MERGED,2015-05-20 13:18:40.000000000,2015-05-21 12:03:51.000000000,2015-05-21 11:52:08.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8749}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 12599}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-20 13:18:40.000000000', 'files': ['fuel_agent/cloud-init-templates/cloud_config_ubuntu.jinja2'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d0b5cc08ac2da4a66118fd3a1076d34970a1a202', 'message': ""IBP: configure mcollectived so it daemonizes itself\n\nThe server.cfg shipped with mcollective package tells mcollectived to\ndaemonize itself, and the config generated by cloud init tells it to run\nin the background (assuming that the init script is responsible for\ndaemonization). This mismatch breaks PID file: start-stop-daemon forks,\ndetaches, records its pid, and runs mcollectived which daemonizes again.\nAs a result the PID recored in the PID file is wrong so subsequent\nstart/restart/stop action can't find the previously launched process\nand starts an extra instance of mcollective.\n\nIn order to solve the problem\n1) fix the init script (assuming that mcollectived daemonizes itself)\n2) generate a proper server.cfg (with daemonize=1 statement)\n\nRelated-Bug: #1454741\nMerge-After: https://review.fuel-infra.org/6760\nChange-Id: I1b9ddc2d8ec790b5a6cb1095e32559cf506c48e7\n""}]",0,184483,d0b5cc08ac2da4a66118fd3a1076d34970a1a202,18,11,1,13194,,,0,"IBP: configure mcollectived so it daemonizes itself

The server.cfg shipped with mcollective package tells mcollectived to
daemonize itself, and the config generated by cloud init tells it to run
in the background (assuming that the init script is responsible for
daemonization). This mismatch breaks PID file: start-stop-daemon forks,
detaches, records its pid, and runs mcollectived which daemonizes again.
As a result the PID recored in the PID file is wrong so subsequent
start/restart/stop action can't find the previously launched process
and starts an extra instance of mcollective.

In order to solve the problem
1) fix the init script (assuming that mcollectived daemonizes itself)
2) generate a proper server.cfg (with daemonize=1 statement)

Related-Bug: #1454741
Merge-After: https://review.fuel-infra.org/6760
Change-Id: I1b9ddc2d8ec790b5a6cb1095e32559cf506c48e7
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/83/184483/1 && git format-patch -1 --stdout FETCH_HEAD,['fuel_agent/cloud-init-templates/cloud_config_ubuntu.jinja2'],1,d0b5cc08ac2da4a66118fd3a1076d34970a1a202,bug/1454741, daemonize: 1, daemonize: 0,1,1
openstack%2Fironic~master~I46fd50da89c3247bffefc9c971f8eda309bbe9bd,openstack/ironic,master,I46fd50da89c3247bffefc9c971f8eda309bbe9bd,Rename gendocs tox environment,MERGED,2015-05-20 14:37:15.000000000,2015-05-21 12:00:24.000000000,2015-05-21 12:00:21.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 9751}, {'_account_id': 12081}, {'_account_id': 13719}]","[{'number': 1, 'created': '2015-05-20 14:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b5356e77659f1f775b7ec9535c86cfd0c0c8159b', 'message': 'Rename gendocs tox environment\n\nAll other openstack projects use docs environment, use the same\nname for ironic as well.\n\nChange-Id: I46fd50da89c3247bffefc9c971f8eda309bbe9bd\n'}, {'number': 2, 'created': '2015-05-21 06:06:17.000000000', 'files': ['doc/source/dev/dev-quickstart.rst', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6befe83d879e7a9410501c1bb60239a185b3cf7a', 'message': 'Rename gendocs tox environment\n\nAll other openstack projects use docs environment, use the same\nname for ironic as well.\n\nChange-Id: I46fd50da89c3247bffefc9c971f8eda309bbe9bd\n'}]",0,184511,6befe83d879e7a9410501c1bb60239a185b3cf7a,19,7,2,6547,,,0,"Rename gendocs tox environment

All other openstack projects use docs environment, use the same
name for ironic as well.

Change-Id: I46fd50da89c3247bffefc9c971f8eda309bbe9bd
",git fetch https://review.opendev.org/openstack/ironic refs/changes/11/184511/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/dev/dev-quickstart.rst', 'tox.ini']",2,b5356e77659f1f775b7ec9535c86cfd0c0c8159b,gendocs,[testenv:docs],[testenv:gendocs],2,2
openstack%2Ffuel-library~master~Ie6ba8508baa044806f6f87c696c465bd5351e3c5,openstack/fuel-library,master,Ie6ba8508baa044806f6f87c696c465bd5351e3c5,"Fix ""Disabled UMM"" functionality Related-bug:#1456526",MERGED,2015-05-19 14:39:11.000000000,2015-05-21 11:47:26.000000000,2015-05-21 11:46:45.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 13948}, {'_account_id': 14316}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-19 14:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6e5e38b0965e45175f4b512ff29249d95d84e16b', 'message': 'Fix ""Disabled UMM"" functionality\nRelated-bug:#1456526\n\nChange-Id: Ie6ba8508baa044806f6f87c696c465bd5351e3c5\n'}, {'number': 2, 'created': '2015-05-21 08:32:17.000000000', 'files': ['deployment/puppet/umm/files/umm_svc'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2f75ff589923bac70b5bed9ba777ea1c5f7289f6', 'message': 'Fix ""Disabled UMM"" functionality\nRelated-bug:#1456526\n\nChange-Id: Ie6ba8508baa044806f6f87c696c465bd5351e3c5\n'}]",3,184260,2f75ff589923bac70b5bed9ba777ea1c5f7289f6,50,7,2,14316,,,0,"Fix ""Disabled UMM"" functionality
Related-bug:#1456526

Change-Id: Ie6ba8508baa044806f6f87c696c465bd5351e3c5
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/60/184260/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/umm/files/umm_svc'],1,6e5e38b0965e45175f4b512ff29249d95d84e16b,184260,"[ ""z$UMM"" == ""zyes"" ] || exit 0","[ ""z$UMM"" == ""zyes"" ] || exit",1,1
openstack%2Ffuel-astute~master~Id7021e12249aa7d32f6a338174c73d03bf84e9bb,openstack/fuel-astute,master,Id7021e12249aa7d32f6a338174c73d03bf84e9bb,Fix string interpolation in missing nodes error,MERGED,2015-05-21 08:22:55.000000000,2015-05-21 11:43:55.000000000,2015-05-21 11:42:01.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 11082}, {'_account_id': 13445}]","[{'number': 1, 'created': '2015-05-21 08:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/b1d0a908f29252bc4daddf98c4b570da92b0ec47', 'message': 'Fix string interpolation in missing nodes error\n\nChange-Id: Id7021e12249aa7d32f6a338174c73d03bf84e9bb\nCloses-Bug: #1457377\n'}, {'number': 2, 'created': '2015-05-21 08:36:14.000000000', 'files': ['lib/astute/deployment_engine.rb', 'spec/unit/deployment_engine_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/e39046ab9f35d6a49603e06cc12487a8b2f0aaab', 'message': 'Fix string interpolation in missing nodes error\n\nChange-Id: Id7021e12249aa7d32f6a338174c73d03bf84e9bb\nCloses-Bug: #1457377\n'}]",0,184738,e39046ab9f35d6a49603e06cc12487a8b2f0aaab,18,7,2,12200,,,0,"Fix string interpolation in missing nodes error

Change-Id: Id7021e12249aa7d32f6a338174c73d03bf84e9bb
Closes-Bug: #1457377
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/38/184738/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/astute/deployment_engine.rb'],1,b1d0a908f29252bc4daddf98c4b570da92b0ec47,bug/1457377," error_message = ""Critical nodes are not available for deployment: #{missing_required}""", error_message = 'Critical nodes are not available for deployment: #{missing_required}',1,1
openstack%2Ffuel-web~master~Ie3b7166cf6542f2f4aa707c80a2014231311d15d,openstack/fuel-web,master,Ie3b7166cf6542f2f4aa707c80a2014231311d15d,Change labels for DNS,MERGED,2015-05-21 10:41:14.000000000,2015-05-21 11:08:45.000000000,2015-05-21 10:56:51.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-05-21 10:41:14.000000000', 'files': ['nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/translations/core.json'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d7933f0d12891d92761a67a48acb73d678d4ae1a', 'message': 'Change labels for DNS\n\nChange labels for DNS entries in Network\nand Settings tab\n\nChange-Id: Ie3b7166cf6542f2f4aa707c80a2014231311d15d\nCloses-Bug: 1456226\n'}]",0,184757,d7933f0d12891d92761a67a48acb73d678d4ae1a,11,3,1,13344,,,0,"Change labels for DNS

Change labels for DNS entries in Network
and Settings tab

Change-Id: Ie3b7166cf6542f2f4aa707c80a2014231311d15d
Closes-Bug: 1456226
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/57/184757/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/translations/core.json']",2,d7933f0d12891d92761a67a48acb73d678d4ae1a,bug/1456226," ""dns_nameservers"": ""Guest OS DNS Servers"","," ""dns_nameservers"": ""DNS Servers"",",2,2
openstack%2Ffuel-docs~master~I40822a50c189eddc97b85bdd7aae5af7dbb0972f,openstack/fuel-docs,master,I40822a50c189eddc97b85bdd7aae5af7dbb0972f,200 nodes support,ABANDONED,2015-04-30 07:21:03.000000000,2015-05-21 11:06:59.000000000,,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8954}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-04-30 07:21:03.000000000', 'files': ['pages/release-notes/v6-1/new-features/200-nodes.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/50ed9973c574191d68c200dde929ac63f9044af1', 'message': '200 nodes support\n\nAdd description of\nbeing certified for 200 nodes\nsupport\n\nChange-Id: I40822a50c189eddc97b85bdd7aae5af7dbb0972f\n'}]",1,178960,50ed9973c574191d68c200dde929ac63f9044af1,6,4,1,14342,,,0,"200 nodes support

Add description of
being certified for 200 nodes
support

Change-Id: I40822a50c189eddc97b85bdd7aae5af7dbb0972f
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/60/178960/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-1/new-features/200-nodes.rst'],1,50ed9973c574191d68c200dde929ac63f9044af1,stable/6.1,"Scalability Certification for 200-node environmentsEnvironments deployed with Fuel 6.1 are certified as stable and scalable at up to 200 nodes. We continue to work to eliminate stability, scalability, and performance issues for large environments. See the `200 nodes support <https://blueprints.launchpad.net/fuel/+spec/200-nodes-support>`_ blueprint for details about the implementation.",Scalability Certification for 100-node environmentsSee `Certify control plane and data plane on a scale up to 200 nodes <https://mirantis.jira.com/browse/PROD-141>`_ and `200 nodes support <https://blueprints.launchpad.net/fuel/+spec/200-nodes-support>`_.,9,5
openstack%2Ffuel-web~master~Ibdce514cc5f2616b94441c6d10ed87649bf73a93,openstack/fuel-web,master,Ibdce514cc5f2616b94441c6d10ed87649bf73a93,List packages and repos in snapshot,MERGED,2015-05-21 07:29:06.000000000,2015-05-21 10:59:29.000000000,2015-05-21 10:47:34.000000000,"[{'_account_id': 3}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 14188}, {'_account_id': 14543}, {'_account_id': 15454}]","[{'number': 1, 'created': '2015-05-21 07:29:06.000000000', 'files': ['nailgun/nailgun/settings.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ab8ac58eebefe7ac74c10dbbb3b36668b93a56d3', 'message': 'List packages and repos in snapshot\n\nAdded commands to list all packages and repos in snapshot\nfor Fuel Master node and slaves.\n\nCloses-Bug: #1457197\nChange-Id: Ibdce514cc5f2616b94441c6d10ed87649bf73a93\n'}]",3,184724,ab8ac58eebefe7ac74c10dbbb3b36668b93a56d3,17,10,1,15454,,,0,"List packages and repos in snapshot

Added commands to list all packages and repos in snapshot
for Fuel Master node and slaves.

Closes-Bug: #1457197
Change-Id: Ibdce514cc5f2616b94441c6d10ed87649bf73a93
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/24/184724/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/settings.yaml'],1,ab8ac58eebefe7ac74c10dbbb3b36668b93a56d3,bug/1457197, to_file: centos_installed_rpms.txt - type: command command: yum repolist to_file: centos_repo_list.txt to_file: centos_installed_rpms.txt - type: command command: yum repolist to_file: centos_repo_list.txt to_file: ubuntu_installed_debs.txt - type: command command: apt-cache policy to_file: ubuntu_repo_list.txt, to_file: installed-rpms.txt to_file: installed-rpms.txt to_file: installed-debs.txt,12,3
openstack%2Ffuel-ostf~master~I335ab933a6627e933108558569ec670513367505,openstack/fuel-ostf,master,I335ab933a6627e933108558569ec670513367505,Fix Heat OSTF cleanup mechanism,MERGED,2015-05-18 16:56:04.000000000,2015-05-21 10:45:19.000000000,2015-05-21 10:43:04.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7428}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 13962}, {'_account_id': 14691}]","[{'number': 1, 'created': '2015-05-18 16:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/b82bffa7e5e8e21660335c8bced66cd5b511f96a', 'message': 'Fix Heat OSTF cleanup mechanism\n\nOld cleanup mechanism for Heat stacks was unreliable: during stack\ncreation it collected stack objects to an array of objects and then\njust call object.delete() for all items of an array without checking\nthat object has such method and that it was really deleted.\n\nChange-Id: I335ab933a6627e933108558569ec670513367505\nCloses-Bug: #1455513\n'}, {'number': 2, 'created': '2015-05-19 12:22:10.000000000', 'files': ['fuel_health/heatmanager.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/04e04d71cfdea62a98ced6fc65781d2c18bedad9', 'message': 'Fix Heat OSTF cleanup mechanism\n\nOld cleanup mechanism for Heat stacks was unreliable: during stack\ncreation it collected stack objects to an array of objects and then\njust call object.delete() for all items of an array without checking\nthat object has such method and that it was really deleted.\n\nChange-Id: I335ab933a6627e933108558569ec670513367505\nCloses-Bug: #1455513\n'}]",0,184096,04e04d71cfdea62a98ced6fc65781d2c18bedad9,17,7,2,8592,,,0,"Fix Heat OSTF cleanup mechanism

Old cleanup mechanism for Heat stacks was unreliable: during stack
creation it collected stack objects to an array of objects and then
just call object.delete() for all items of an array without checking
that object has such method and that it was really deleted.

Change-Id: I335ab933a6627e933108558569ec670513367505
Closes-Bug: #1455513
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/96/184096/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/cleanup.py', 'fuel_health/heatmanager.py']",2,b82bffa7e5e8e21660335c8bced66cd5b511f96a,," self.addCleanup(self._delete_stack, stack.id) def _delete_stack(self, stack_id): LOG.debug(""Deleting stack: %s"" % stack_id) if self._find_stack(self.heat_client, 'id', stack_id) is None: return self.heat_client.stacks.delete(stack_id) self._wait_for_stack_deleted(stack_id) LOG.debug(""Resource '%s' has been deleted."" % stack_id) "," self.set_resource(stack.id, stack)",9,16
openstack%2Ffuel-web~master~I22b47fe41987603a4c5b5187682f652eb000719f,openstack/fuel-web,master,I22b47fe41987603a4c5b5187682f652eb000719f,Change URL to documentation for Ubuntu repo configuration,MERGED,2015-05-21 09:22:40.000000000,2015-05-21 10:29:39.000000000,2015-05-21 10:17:25.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 10474}]","[{'number': 1, 'created': '2015-05-21 09:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2c5aa12e43a6f65b20c5d6ea28d65c654f521bf2', 'message': 'Change URL to documentation for repo configuration\n\nChange-Id: I22b47fe41987603a4c5b5187682f652eb000719f\nCloses-Bug: #1455661\n'}, {'number': 2, 'created': '2015-05-21 09:43:49.000000000', 'files': ['nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/js/utils.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ea8ecbd3e43ee26a664521cb78d959d10b279abb', 'message': 'Change URL to documentation for Ubuntu repo configuration\n\nChange-Id: I22b47fe41987603a4c5b5187682f652eb000719f\nRelated-Bug: #1455661\n'}]",0,184747,ea8ecbd3e43ee26a664521cb78d959d10b279abb,18,7,2,8735,,,0,"Change URL to documentation for Ubuntu repo configuration

Change-Id: I22b47fe41987603a4c5b5187682f652eb000719f
Related-Bug: #1455661
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/47/184747/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/js/utils.js']",2,2c5aa12e43a6f65b20c5d6ea28d65c654f521bf2,bug/1455661," url: /(?:https?:\/\/([\-\w\.]+)+(:\d+)?(\/([\w\/_\-\.]*(\?[\w\/_\-\.&%]*)?(#[\w\/_\-\.&%]*)?)?)?)/,"," url: /(?:https?:\/\/([\-\w\.]+)+(:\d+)?(\/([\w\/_\-\.]*(\?\S+)?)?)?)/,",3,3
openstack%2Ffuel-main~master~I7ca5d3efa0c515a5b93d9113d5fbe4829f33a619,openstack/fuel-main,master,I7ca5d3efa0c515a5b93d9113d5fbe4829f33a619,Add packages to requirements-deb.txt,ABANDONED,2015-05-13 16:00:49.000000000,2015-05-21 10:28:22.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8777}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10474}, {'_account_id': 11969}, {'_account_id': 13194}]","[{'number': 1, 'created': '2015-05-13 16:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8ad0acadf897e92e276cf5191876d19976169490', 'message': 'Add package libc-bin to requirements-deb.txt\n\nThis package is required for debootstrap for preparing images.\n\nChange-Id: I7ca5d3efa0c515a5b93d9113d5fbe4829f33a619\nCloses-Bug:#1454763\n'}, {'number': 2, 'created': '2015-05-14 08:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/00573fa9868a7c6cb2efc53bc45992fef618f8ae', 'message': 'Add packages to requirements-deb.txt\n\n- libc-bin required for debootstrap (IBP)\n- grep required for dpkg --configure actions\n\nThis package is required for debootstrap for preparing images.\n\nChange-Id: I7ca5d3efa0c515a5b93d9113d5fbe4829f33a619\nCloses-Bug:#1454763\n'}, {'number': 3, 'created': '2015-05-15 11:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c6426b12aa09ddc5bb5a5995156efadf2ab89089', 'message': ""Add packages to requirements-deb.txt\n\n- 'libc-bin' required for debootstrap (IBP)\n- 'grep' required for dpkg --configure actions\n- 'login' required for generating /etc/shadow file\n\nThis package is required for debootstrap for preparing images.\n\nChange-Id: I7ca5d3efa0c515a5b93d9113d5fbe4829f33a619\nCloses-Bug:#1454763\n""}, {'number': 4, 'created': '2015-05-15 11:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/46e2f9e71b81b289a8be337563d491ae938cfac5', 'message': ""Add packages to requirements-deb.txt\n\n- 'libc-bin' required for debootstrap (IBP)\n- 'grep' required for dpkg --configure actions\n- 'login' required for generating /etc/shadow file\n\nThis package is required for debootstrap for preparing images.\n\nChange-Id: I7ca5d3efa0c515a5b93d9113d5fbe4829f33a619\nCloses-Bug:#1454763\n""}, {'number': 5, 'created': '2015-05-16 11:08:53.000000000', 'files': ['requirements-deb.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5c94d2808eed6f437f4310d5b985acf7a8f740a2', 'message': 'Add packages to requirements-deb.txt\n\nThese packages are required for image creation (IBP)\n\nChange-Id: I7ca5d3efa0c515a5b93d9113d5fbe4829f33a619\nCloses-Bug:#1454763\n'}]",2,182739,5c94d2808eed6f437f4310d5b985acf7a8f740a2,39,9,5,11969,,,0,"Add packages to requirements-deb.txt

These packages are required for image creation (IBP)

Change-Id: I7ca5d3efa0c515a5b93d9113d5fbe4829f33a619
Closes-Bug:#1454763
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/39/182739/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements-deb.txt'],1,8ad0acadf897e92e276cf5191876d19976169490,bug/1454763,libc-bin,,1,0
openstack%2Ftripleo-heat-templates~master~I6351d972ab00f4661d98338d95310d33f271de2f,openstack/tripleo-heat-templates,master,I6351d972ab00f4661d98338d95310d33f271de2f,Start non-pacemakerized services in step 4,MERGED,2015-05-21 08:21:14.000000000,2015-05-21 10:11:13.000000000,2015-05-21 10:11:12.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8041}]","[{'number': 1, 'created': '2015-05-21 08:21:14.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7f6df7c642e02aba4b3975bf31cbc7330172e899', 'message': ""Start non-pacemakerized services in step 4\n\nPreviously we've been starting non-pacemakerized services in step 3 on\nbootstrap node and in step 4 on others. Now that $sync_db in OpenStack\nPuppet modules is decoupled from $enabled and $manage_service [1] we can\nstart the services in step 4 on all nodes.\n\n[1] https://bugs.launchpad.net/puppet-glance/+bug/1452278\n\nChange-Id: I6351d972ab00f4661d98338d95310d33f271de2f\n""}]",0,184737,7f6df7c642e02aba4b3975bf31cbc7330172e899,8,3,1,8042,,,0,"Start non-pacemakerized services in step 4

Previously we've been starting non-pacemakerized services in step 3 on
bootstrap node and in step 4 on others. Now that $sync_db in OpenStack
Puppet modules is decoupled from $enabled and $manage_service [1] we can
start the services in step 4 on all nodes.

[1] https://bugs.launchpad.net/puppet-glance/+bug/1452278

Change-Id: I6351d972ab00f4661d98338d95310d33f271de2f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/37/184737/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,7f6df7c642e02aba4b3975bf31cbc7330172e899,,$non_pcmk_start = hiera('step') >= 4,# FIXME: change to only step 4 after this patch is merged: # https://review.openstack.org/#/c/180565/ # $non_pcmk_start = hiera('step') >= 4$non_pcmk_start = hiera('step') >= 4 or (hiera('step') >= 3 and $pacemaker_master),1,4
openstack%2Fhorizon~master~I42c92f7b4d8f07d67191ae70e27abb2270a02a52,openstack/horizon,master,I42c92f7b4d8f07d67191ae70e27abb2270a02a52,Imported Translations from Transifex,MERGED,2015-05-21 06:20:06.000000000,2015-05-21 10:00:11.000000000,2015-05-21 10:00:09.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8358}]","[{'number': 1, 'created': '2015-05-21 06:20:06.000000000', 'files': ['openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'horizon/locale/pt_BR/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c76c478c001f6e554c0c989c81c12ca8df512265', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I42c92f7b4d8f07d67191ae70e27abb2270a02a52\n'}]",0,184720,c76c478c001f6e554c0c989c81c12ca8df512265,8,4,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I42c92f7b4d8f07d67191ae70e27abb2270a02a52
",git fetch https://review.opendev.org/openstack/horizon refs/changes/20/184720/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'horizon/locale/pt_BR/LC_MESSAGES/djangojs.po']",4,c76c478c001f6e554c0c989c81c12ca8df512265,transifex/translations,"# Andre Campos Bezerra <andrecbezerra@gmail.com>, 2015""POT-Creation-Date: 2015-05-19 06:10-0500\n"" ""PO-Revision-Date: 2015-05-21 04:58+0000\n"" ""Last-Translator: Andre Campos Bezerra <andrecbezerra@gmail.com>\n""msgid ""Current Usage"" msgstr ""Uso atual"" msgid ""Remaining"" msgstr ""Restante"" msgid ""Total"" msgstr ""Total"" ","""POT-Creation-Date: 2015-05-07 20:21-0500\n"" ""PO-Revision-Date: 2015-05-07 18:03+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""",17473,4
openstack%2Ftripleo-heat-templates~master~I064485e5f04b1b77044e714a78b0c71337515095,openstack/tripleo-heat-templates,master,I064485e5f04b1b77044e714a78b0c71337515095,Temporarily disable Horizon in HA job,ABANDONED,2015-05-19 13:51:03.000000000,2015-05-21 09:58:34.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-19 13:51:03.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/562ac247944a71178a9e9a7a6c7005b4569e9a61', 'message': 'Temporarily disable Horizon in HA job\n\nThe HA job seems to be hitting a timeout during start of httpd\nservice (apparently still in-progress after 2mins).\n\nSystemd will interrupt the startup logging a message like:\n\n  systemd[1]: httpd.service start-pre operation timed out.\n\nin httpd.log\n\nChange-Id: I064485e5f04b1b77044e714a78b0c71337515095\n'}]",1,184252,562ac247944a71178a9e9a7a6c7005b4569e9a61,6,5,1,6796,,,0,"Temporarily disable Horizon in HA job

The HA job seems to be hitting a timeout during start of httpd
service (apparently still in-progress after 2mins).

Systemd will interrupt the startup logging a message like:

  systemd[1]: httpd.service start-pre operation timed out.

in httpd.log

Change-Id: I064485e5f04b1b77044e714a78b0c71337515095
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/52/184252/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,562ac247944a71178a9e9a7a6c7005b4569e9a61,pcmk_resource_change," # NOTE: horizon is temporarily disabled due to CI issues in the HA scenario #$vhost_params = { add_listen => false } #class { 'horizon': # cache_server_ip => split(hiera('memcache_node_ips', '127.0.0.1'), ','), # vhost_extra_params => $vhost_params, #}"," $vhost_params = { add_listen => false } class { 'horizon': cache_server_ip => split(hiera('memcache_node_ips', '127.0.0.1'), ','), vhost_extra_params => $vhost_params, }",6,5
openstack%2Ffuel-web~master~I2558973b4594327936b7bf9b8897d5ed143ec099,openstack/fuel-web,master,I2558973b4594327936b7bf9b8897d5ed143ec099,Do not run connectivity repo checks for old envs,MERGED,2015-05-20 14:23:56.000000000,2015-05-21 09:56:23.000000000,2015-05-21 09:43:29.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 10391}, {'_account_id': 12200}, {'_account_id': 14543}]","[{'number': 1, 'created': '2015-05-20 14:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b3cc62d70be409d8f059019ab999274e48cc3a31', 'message': ""Do not run connectivity repo checks for old envs\n\nWe have repo connectivity checks only since Fuel 6.1. It means that\nnetchecker in Fuel < 6.1 doesn't have those checks and therefore we\nshould run them.\n\nCloses-Bug: #1457013\n\nChange-Id: I2558973b4594327936b7bf9b8897d5ed143ec099\nSigned-off-by: Igor Kalnitsky <igor@kalnitsky.org>\n""}, {'number': 2, 'created': '2015-05-20 15:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dfa4ed3cb1b8b2355586ac81d347f91537629217', 'message': ""Do not run connectivity repo checks for old envs\n\nWe have repo connectivity checks only since Fuel 6.1. It means that\nnetchecker in Fuel < 6.1 doesn't have those checks and therefore we\nshould run them.\n\nCloses-Bug: #1457013\n\nChange-Id: I2558973b4594327936b7bf9b8897d5ed143ec099\nSigned-off-by: Igor Kalnitsky <igor@kalnitsky.org>\n""}, {'number': 3, 'created': '2015-05-21 08:44:56.000000000', 'files': ['nailgun/nailgun/task/task.py', 'nailgun/nailgun/test/integration/test_verify_networks_task_manager.py', 'nailgun/nailgun/consts.py', 'nailgun/nailgun/test/unit/test_check_repo_connection_task.py', 'nailgun/nailgun/task/manager.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8089159b4ead21ac4a7d8964c8a6a3c122b67061', 'message': ""Do not run connectivity repo checks for old envs\n\nWe have repo connectivity checks only since Fuel 6.1. It means that\nnetchecker in Fuel < 6.1 doesn't have those checks and therefore we\nshould not run them.\n\nCloses-Bug: #1457013\n\nChange-Id: I2558973b4594327936b7bf9b8897d5ed143ec099\nSigned-off-by: Igor Kalnitsky <igor@kalnitsky.org>\n""}]",8,184507,8089159b4ead21ac4a7d8964c8a6a3c122b67061,40,9,3,10391,,,0,"Do not run connectivity repo checks for old envs

We have repo connectivity checks only since Fuel 6.1. It means that
netchecker in Fuel < 6.1 doesn't have those checks and therefore we
should not run them.

Closes-Bug: #1457013

Change-Id: I2558973b4594327936b7bf9b8897d5ed143ec099
Signed-off-by: Igor Kalnitsky <igor@kalnitsky.org>
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/07/184507/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/task/task.py', 'nailgun/nailgun/test/integration/test_verify_networks_task_manager.py', 'nailgun/nailgun/consts.py', 'nailgun/nailgun/test/unit/test_check_repo_connection_task.py', 'nailgun/nailgun/task/manager.py']",5,b3cc62d70be409d8f059019ab999274e48cc3a31,bug/1457013,"from distutils.version import StrictVersion # we have remote connectivity checks sicne fuel 6.1, so # we should not create those tasks for old envs if StrictVersion(self.cluster.fuel_version) >= \ StrictVersion(consts.FUEL_REMOTE_REPOS): # repo connectivity check via default gateway task, name=consts.TASK_NAMES.check_repo_availability) tasks.CheckRepoAvailability(repo_check_task, vlan_ids)) # repo connectivity check via external gateway conf, errors = tasks.CheckRepoAvailabilityWithSetup.get_config( self.cluster) # if there is no conf - there is no nodes on which # we need to setup network if conf: repo_check_task = objects.task.Task.create_subtask( task, consts.TASK_NAMES.check_repo_availability_with_setup) verify_task.add_subtask( tasks.CheckRepoAvailabilityWithSetup( repo_check_task, conf)) if errors: notifier.notify( ""warning"", '\n'.join(errors), self.cluster.id )"," repo_check_task = objects.task.Task.create_subtask( task, name=consts.TASK_NAMES.check_repo_availability) verify_task.add_subtask( tasks.CheckRepositoryConnectionFromSlavesTask(repo_check_task, vlan_ids)) config, errors = tasks.RepoAvailabilityWithSetup.get_config( self.cluster) # if there is no config - there is no nodes on which # we need to setup network if config: task, name=consts.TASK_NAMES.check_repo_availability_with_setup) tasks.RepoAvailabilityWithSetup( repo_check_task, config)) if errors: notifier.notify( ""warning"", '\n'.join(errors), self.cluster.id )",65,24
openstack%2Ffuel-docs~master~I6a5986f248002010d797a62b1c843fd575244dca,openstack/fuel-docs,master,I6a5986f248002010d797a62b1c843fd575244dca,Fix command syntax in Ops Guide (RabbitMQ issue),MERGED,2015-05-14 07:19:12.000000000,2015-05-21 09:53:58.000000000,2015-05-21 09:53:56.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}, {'_account_id': 13695}]","[{'number': 1, 'created': '2015-05-14 07:19:12.000000000', 'files': ['pages/operations/2451-rabbitmq-backport-ocf.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6dd762ae41ea089bb22ffe73a5759680789d7b5a', 'message': 'Fix command syntax in Ops Guide (RabbitMQ issue)\n\nThis commit fixes incorrect syntax of the\ndownload command for OCF script.\n\nChange-Id: I6a5986f248002010d797a62b1c843fd575244dca\nCloses-Bug: 1454110\n'}]",0,182957,6dd762ae41ea089bb22ffe73a5759680789d7b5a,9,4,1,13082,,,0,"Fix command syntax in Ops Guide (RabbitMQ issue)

This commit fixes incorrect syntax of the
download command for OCF script.

Change-Id: I6a5986f248002010d797a62b1c843fd575244dca
Closes-Bug: 1454110
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/57/182957/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/operations/2451-rabbitmq-backport-ocf.rst'],1,6dd762ae41ea089bb22ffe73a5759680789d7b5a,bug/1454110, https://raw.githubusercontent.com/stack \ forge/fuel-library/stable/6.0/deployment/puppet/nova/files/ocf/rabbitmq chmod +x /etc/puppet/modules/nova/files/ocf/rabbitmq do scp /etc/puppet/modules/nova/files/ocf/rabbitmq \, https://raw.githubusercontent.com/stack \ forge/fuel-library/stable/6.0/deployment/puppet/nova/files/ocf/rabbitmq chmod +x /etc/puppet/modules/nova/files/ocf/rabbitmq do scp /etc/puppet/modules/nova/files/ocf/rabbitmq \ ,4,4
openstack%2Ffuel-docs~master~Id42108387c0ad7fbd5786200b18ae7b21cbd820e,openstack/fuel-docs,master,Id42108387c0ad7fbd5786200b18ae7b21cbd820e,Provides placeholders for Fuel CLI commands,MERGED,2015-05-14 09:05:44.000000000,2015-05-21 09:53:19.000000000,2015-05-21 09:53:19.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}, {'_account_id': 13695}]","[{'number': 1, 'created': '2015-05-14 09:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/7868b9cd1c98edeba645fe720ade9b5cea310d5a', 'message': ""Provides placeholders for Fuel CLI commands\n\nSome commands don't have placeholders,\nbut do have specific examples/values.\nSuch an approach is not useful.\n\nThis commit provides the required placeholders.\n\nChange-Id: Id42108387c0ad7fbd5786200b18ae7b21cbd820e\nCloses-Bug: 1454295\n""}, {'number': 2, 'created': '2015-05-14 10:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/54ddd5716a6180aa28a1c3ebdf172ec0a9011a7c', 'message': ""Provides placeholders for Fuel CLI commands\n\nSome commands don't have placeholders,\nbut do have specific examples/values.\nSuch an approach is not useful.\n\nThis commit provides the required placeholders.\n\nChange-Id: Id42108387c0ad7fbd5786200b18ae7b21cbd820e\nCloses-Bug: 1454295\n""}, {'number': 3, 'created': '2015-05-14 11:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8d43dae54959985a21cd2873ba1edf1e8c9cdfcd', 'message': ""Provides placeholders for Fuel CLI commands\n\nSome commands don't have placeholders,\nbut do have specific examples/values.\nSuch an approach is not useful.\n\nThis commit provides the required placeholders.\n\nChange-Id: Id42108387c0ad7fbd5786200b18ae7b21cbd820e\nCloses-Bug: 1454295\n""}, {'number': 4, 'created': '2015-05-14 11:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4482a69b4b8e10b4860f198c399c3584738b3dcc', 'message': ""Provides placeholders for Fuel CLI commands\n\nSome commands don't have placeholders,\nbut do have specific examples/values.\nSuch an approach is not useful.\n\nThis commit provides the required placeholders.\n\nChange-Id: Id42108387c0ad7fbd5786200b18ae7b21cbd820e\nCloses-Bug: 1454295\n""}, {'number': 5, 'created': '2015-05-14 12:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a6589325ed2277bbb0e8cca75d61d21b16b6319a', 'message': ""Provides placeholders for Fuel CLI commands\n\nSome commands don't have placeholders,\nbut do have specific examples/values.\nSuch an approach is not useful.\n\nThis commit provides the required placeholders.\n\nChange-Id: Id42108387c0ad7fbd5786200b18ae7b21cbd820e\nCloses-Bug: 1454295\n""}, {'number': 6, 'created': '2015-05-14 13:55:07.000000000', 'files': ['pages/terminology/n/node.rst', 'pages/reference-architecture/1000-logical-setup.rst', 'pages/file-ref/openstack-yaml.rst', 'pages/user-guide/0800-node-internals.rst', 'pages/user-guide/cli.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/2c69e09cbd622db1df05e949d42663e22c339929', 'message': ""Provides placeholders for Fuel CLI commands\n\nSome commands don't have placeholders,\nbut do have specific examples/values.\nSuch an approach is not useful.\n\nThis commit provides the required placeholders.\n\nChange-Id: Id42108387c0ad7fbd5786200b18ae7b21cbd820e\nCloses-Bug: 1454295\n""}]",13,182981,2c69e09cbd622db1df05e949d42663e22c339929,34,4,6,13082,,,0,"Provides placeholders for Fuel CLI commands

Some commands don't have placeholders,
but do have specific examples/values.
Such an approach is not useful.

This commit provides the required placeholders.

Change-Id: Id42108387c0ad7fbd5786200b18ae7b21cbd820e
Closes-Bug: 1454295
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/81/182981/3 && git format-patch -1 --stdout FETCH_HEAD,['pages/user-guide/cli.rst'],1,7868b9cd1c98edeba645fe720ade9b5cea310d5a,bug/1454295," fuel env create --name <env_name> --rel 1 fuel --env <env_id> env set --name <NewEmvName> --mode ha_compact fuel --env <env_id> env delete fuel env --update --env <env_id> --rel 42 fuel --env-id <env_id> node list fuel node set --node <node_id> --role controller --env <env_id> fuel node set --node <node_id>,<node_id>,<node_id> --role compute,cinder --env <env_id> fuel node remove --node <node_id>,<node_id> --env <env_id> fuel node remove --node <node_id>,<node_id> fuel node remove --env <env_id> fuel --env <env_id> nodegroup fuel --env <env_id> nodegroup --create --name ""group 1"" fuel --env <env_id> nodegroup --delete --group <group_id> fuel --env <env_id> nodegroup --delete --group <group_id1>,<group_id2>,<group_id3> fuel --env <env_id> nodegroup --assign --node <node_id> --group <group_id> fuel --env <env_id> nodegroup --assign --node <node1_id>,<node2_id>,4 --group <group_id> fuel --env <env_id> deploy-changes fuel --env <env_id> node --provision --node <node1_id>,<node2_id> fuel --env <env_id> node --deploy --node <node1_id>,<node2_id> fuel user --change-password --new-pass=<new_password> and ``os-password`` options are used rather than ``user`` and ``--change-password``."," fuel env create --name MyEnv --rel 1 fuel --env 1 env set --name NewEmvName --mode ha_compact fuel --env 1 env delete fuel env --update --env 1 --rel 42 fuel --env-id 1 node list fuel node set --node 1 --role controller --env 1 fuel node set --node 2,3,4 --role compute,cinder --env 1 fuel node remove --node 2,3 --env 1 fuel node remove --node 2,3 fuel node remove --env 1 fuel --env 1 nodegroup fuel --env 1 nodegroup --create --name ""group 1"" fuel --env 1 nodegroup --delete --group 1 fuel --env 1 nodegroup --delete --group 2,3,4 fuel --env 1 nodegroup --assign --node 1 --group 1 fuel --env 1 nodegroup --assign --node 2,3,4 --group 1 fuel --env 1 deploy-changes fuel --env 1 node --provision --node 1,2 fuel --env 1 node --deploy --node 1,2 fuel user --change-password --new-pass=*new* and **os-password** options are used rather than **user** and **--change-password**.",22,22
openstack%2Ffuel-ostf~master~I86a355fb8ff22fa4e97a86cb9d98e47e840160e4,openstack/fuel-ostf,master,I86a355fb8ff22fa4e97a86cb9d98e47e840160e4,Erase instances  if neutron tests fails,MERGED,2015-05-20 15:59:34.000000000,2015-05-21 09:45:37.000000000,2015-05-21 09:42:59.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-05-20 15:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/c580000e1296e28db91aa445c47347cb725bac7f', 'message': 'Erase instances  if neutron tests fails\n\nChange-Id: I86a355fb8ff22fa4e97a86cb9d98e47e840160e4\nCloses-Bug: #1456634\n'}, {'number': 2, 'created': '2015-05-20 16:46:32.000000000', 'files': ['fuel_health/neutronmanager.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/7bed6a1c4483bc843c2bbe188d369b5fdf1e4c1c', 'message': 'Erase instances  if neutron tests fails\n\nChange-Id: I86a355fb8ff22fa4e97a86cb9d98e47e840160e4\nCloses-Bug: #1456634\n'}]",8,184525,7bed6a1c4483bc843c2bbe188d369b5fdf1e4c1c,21,7,2,6719,,,0,"Erase instances  if neutron tests fails

Change-Id: I86a355fb8ff22fa4e97a86cb9d98e47e840160e4
Closes-Bug: #1456634
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/25/184525/2 && git format-patch -1 --stdout FETCH_HEAD,['fuel_health/neutronmanager.py'],1,c580000e1296e28db91aa445c47347cb725bac7f,1456634," try: [cls.compute_client.servers.delete(srv) for srv in cls.compute_client.servers.list() if 'ost1_' in srv.name] except Exception as exc: cls.error_msg.append(exc) LOG.debug(traceback.format_exc()) for subnet in cls.subnets: cls.neutron_client.remove_interface_router( router['id'], {""subnet_id"": subnet['id']})",,10,1
openstack%2Ffuel-qa~master~Id838c7962ebb8ba314fb3db66b59bffdda173fc5,openstack/fuel-qa,master,Id838c7962ebb8ba314fb3db66b59bffdda173fc5,Disable zabbix tests,MERGED,2015-05-13 15:44:19.000000000,2015-05-21 09:06:22.000000000,2015-05-21 09:06:22.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}]","[{'number': 1, 'created': '2015-05-13 15:44:19.000000000', 'files': ['fuelweb_test/tests/test_zabbix.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/69fdcb155331970b94b51cceea8886d5104e1804', 'message': 'Disable zabbix tests\n\nacording to review https://review.openstack.org/#/c/182615/\nwe can disable zabbix tests for now and delete\nit in the 7.0\n\nChange-Id: Id838c7962ebb8ba314fb3db66b59bffdda173fc5\n'}]",0,182727,69fdcb155331970b94b51cceea8886d5104e1804,9,4,1,6719,,,0,"Disable zabbix tests

acording to review https://review.openstack.org/#/c/182615/
we can disable zabbix tests for now and delete
it in the 7.0

Change-Id: Id838c7962ebb8ba314fb3db66b59bffdda173fc5
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/27/182727/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_zabbix.py'],1,69fdcb155331970b94b51cceea8886d5104e1804,disable_zabbix_tests,"@test(enabled=False, groups=[""known_issues""]) @test(enabled=False, depends_on=[SetupEnvironment.prepare_slaves_3],","@test(groups=[""known_issues""]) @test(depends_on=[SetupEnvironment.prepare_slaves_3],",2,2
openstack%2Fneutron~master~Ie6cf4c0579c87902621829878bd6f61312dbb4b1,openstack/neutron,master,Ie6cf4c0579c87902621829878bd6f61312dbb4b1,[WIP] DB migration from Nova to Neutron,ABANDONED,2015-01-19 13:43:07.000000000,2015-05-21 08:51:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2035}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 8655}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}, {'_account_id': 14956}]","[{'number': 1, 'created': '2015-01-19 13:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/06582ebd195558375f3f9616acdf8d546c50e1a3', 'message': '[WIP] DB migration from Nova to Neutron\n\nChange-Id: Ie6cf4c0579c87902621829878bd6f61312dbb4b1\n'}, {'number': 2, 'created': '2015-01-20 18:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/711f6d1b3385d1a2dee2b2bcc420cb4a24dfb860', 'message': ""[WIP] DB migration from Nova to Neutron\n\nSome parts of currently implemented migrations are still\nnot complete. Consistency on neutron side hasn't been tested.\n\nMissing items:\n   - translate virtual_interfaces into ports\n   - translate fixed ips\n   - translate floating ips\n   - update ipallocations\n   - implement default security groups\n\nblueprint migration-from-nova-net\n\nChange-Id: Ie6cf4c0579c87902621829878bd6f61312dbb4b1\n""}, {'number': 3, 'created': '2015-01-27 12:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/93d13975f6f3f3c217b362878f25662e78bcf165', 'message': ""[WIP] DB migration from Nova to Neutron\n\nSome parts of currently implemented migrations are still\nnot complete. Consistency on neutron side hasn't been tested.\n\nMissing items:\n   - translate fixed ips\n   - translate floating ips\n   - update ipallocations\n\nblueprint migration-from-nova-net\n\nChange-Id: Ie6cf4c0579c87902621829878bd6f61312dbb4b1\n""}, {'number': 4, 'created': '2015-01-27 13:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b8304f34bb921c994e127424531112427ebacf54', 'message': ""[WIP] DB migration from Nova to Neutron\n\nSome parts of currently implemented migrations are still\nnot complete. Consistency on neutron side hasn't been tested.\n\nMissing items:\n   - translate fixed ips\n   - translate floating ips\n   - update ipallocations\n\nblueprint migration-from-nova-net\n\nChange-Id: Ie6cf4c0579c87902621829878bd6f61312dbb4b1\n""}, {'number': 5, 'created': '2015-02-10 09:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/325d64310b52b83ba786675f39fdc875fc0a5929', 'message': ""[WIP] DB migration from Nova to Neutron\n\nSome parts of currently implemented migrations are still\nnot complete. Consistency on neutron side hasn't been tested.\n\nMissing items:\n   - translate fixed ips\n   - translate floating ips\n   - update ipallocations\n\nblueprint migration-from-nova-net\n\nChange-Id: Ie6cf4c0579c87902621829878bd6f61312dbb4b1\n""}, {'number': 6, 'created': '2015-02-11 19:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/58c3afc48848e1fd26ced18c8ae3366a17807d46', 'message': ""[WIP] DB migration from Nova to Neutron\n\nSome parts of currently implemented migrations are still\nnot complete. Consistency on neutron side hasn't been tested.\n\nMissing items:\n   - migrate floating ips\n   - probably routers will be needed\n\nblueprint migration-from-nova-net\n\nChange-Id: Ie6cf4c0579c87902621829878bd6f61312dbb4b1\n""}, {'number': 7, 'created': '2015-02-20 17:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/231497854422325b3c04994b46e75aa60ada5221', 'message': '[WIP] DB migration from Nova to Neutron\n\nI tested migrating db from nnet to neutron on two all-in-one setups. I\nwas able to boot a vm in a migrated flat network. Migrated ports have same\nconfiguration as the newly created port which indicates ports were\nmigrated succesfully.\n\nMissing items if needed:\n   - migrate floating ips\n   - probably routers will be needed\n\nblueprint migration-from-nova-net\n\nChange-Id: Ie6cf4c0579c87902621829878bd6f61312dbb4b1\n'}, {'number': 8, 'created': '2015-02-26 18:42:29.000000000', 'files': ['neutron/db/db_base_plugin_v2.py', 'neutron/db/migration/migrate_nova_network_to_neutron.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/305b471f7e8f780c6e445c56720e21412f5e69d1', 'message': '[WIP] DB migration from Nova to Neutron\n\nI tested migrating db from nnet to neutron on two all-in-one setups. I\nwas able to boot a vm in a migrated flat network. Migrated ports have same\nconfiguration as the newly created port which indicates ports were\nmigrated succesfully.\n\nMissing items if needed:\n   - migrate floating ips\n\n   - probably routers will be needed?\n\nPossible optimizations:\n   - profiling which db queries take most of time and optimize the query\n   - avoid multiple queries and cache fetched data, this will bring\n     higher memory usage but faster migration process\n\nblueprint migration-from-nova-net\n\nChange-Id: Ie6cf4c0579c87902621829878bd6f61312dbb4b1\n'}]",49,148260,305b471f7e8f780c6e445c56720e21412f5e69d1,156,29,8,8655,,,0,"[WIP] DB migration from Nova to Neutron

I tested migrating db from nnet to neutron on two all-in-one setups. I
was able to boot a vm in a migrated flat network. Migrated ports have same
configuration as the newly created port which indicates ports were
migrated succesfully.

Missing items if needed:
   - migrate floating ips

   - probably routers will be needed?

Possible optimizations:
   - profiling which db queries take most of time and optimize the query
   - avoid multiple queries and cache fetched data, this will bring
     higher memory usage but faster migration process

blueprint migration-from-nova-net

Change-Id: Ie6cf4c0579c87902621829878bd6f61312dbb4b1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/148260/8 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/migrate_nova_network_to_neutron.py'],1,06582ebd195558375f3f9616acdf8d546c50e1a3,bp/migration-from-nova-net,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" """""" import argparse import six import sqlalchemy as sa #TODO(jlibosva): Can we get library from oslo-incubator? from neutron.common import constants as neutron_constants from neutron.openstack.common import log as logging from neutron.openstack.common import uuidutils LOG = logging.getLogger(__name__) def make_subnet_from_nova_network(network): ip_version = None if network['cidr']: ip_version = 4 elif network['cidr_v6']: ip_version = 6 else: LOG.warning('Unknown ip_version from network %s', network) cidr = network['cidr_v6'] if network['cidr_v6'] else network['cidr'] subnet = {'tenant_id': network['project_id'], 'id': uuidutils.generate_uuid(), 'name': 'subnet_%s' % cidr, 'ip_version': ip_version, 'cidr': cidr, 'gateway_ip': (network['gateway_v6'] if network['gateway_v6'] else network['gateway']), 'enable_dhcp': True, 'shared': True} return subnet def make_network_from_nova_network(nova_network): neutron_network = { 'id': uuidutils.generate_uuid(), 'tenant_id': nova_network['project_id'], 'name': 'nova_network_%s' % nova_network['id'], 'status': neutron_constants.NET_STATUS_ACTIVE, 'admin_state_up': True, 'shared': False } return neutron_network def create_routers(networks, subnets): pass class NameTablesMeta(type): """"""Metaclass for setting table names All Table() instances in given class will get name according its referencing attribute. The name will be accessible via attribute .name """""" def __init__(cls, name, bases, dct): for name, attr in dct.items(): if isinstance(attr, Table): attr.name = name return super(NameTablesMeta, cls).__init__(name, bases, dct) class Table(object): """"""SQLAlchemy table descriptor When accessing instance of class, instance of table is created if it doesn't exist yet. The table is taken from metadata of attribute's owner. That means class that uses this class must have metadata attribute. """""" def __get__(self, instance, owner): if not hasattr(self, 'table'): self.table = sa.Table(self.name, instance.metadata, autoload=True, autoload_with=instance.engine) return self.table def __set__(self, instance, value): raise AttributeError('Attribute %s is read-only' % self.name) @six.add_metaclass(NameTablesMeta) class Database(object): """"""Generic database object Tables can be defined here as class attributes. """""" # TODO(jlibosva): Rewrite to __getattribute__ instead of metaclass def __init__(self, connection_url): self.metadata = sa.MetaData() self._url = connection_url @property def engine(self): if not hasattr(self, '_engine'): self._engine = sa.create_engine(self._url) self.metadata.create_all(self._engine) return self._engine def execute(self, *args, **kwargs): return self.engine.execute(*args, **kwargs) class NovaDatabase(Database): networks = Table() fixed_ips = Table() floating_ips = Table() virtual_interfaces = Table() security_groups = Table() security_groups_rules = Table() class NeutronDatabase(Database): networks = Table() externalnetworks = Table() networksegments = Table() subnets = Table() ipallocations = Table() iptallocationpools = Table() ipavailabilityranges = Table() ml2_flat_allocations = Table() ml2_vlan_allocations = Table() ports = Table() class Migrator(object): def __init__(self, nova_db_url, neutron_db_url): self.neutron_db = NeutronDatabase(neutron_db_url) self.nova_db = NovaDatabase(nova_db_url) self.migrated_networks = list() self.migrated_subnets = list() def migrate(self): self.migrate_networks() create_routers(self.migrated_networks, self.migrated_subnets) self.migrate_vifs() self.migrate_security_groups() def migrate_networks(self): nova_nets_table = self.nova_db.networks nova_nets = self.nova_db.execute(nova_nets_table.select()) neutron_nets_table = self.neutron_db.networks neutron_extnet_table = self.neutron_db.externalnetworks neutron_extnets = list() neutron_subnets_table = self.neutron_db.subnets for nova_network in nova_nets: nova_network = dict(nova_network) neutron_network = make_network_from_nova_network(nova_network) self.migrated_networks.append(neutron_network) #TODO(jlibosva): make external network based on ? #TODO(jlibosva): make network segments with ml2 type_manager #TODO(jlibosva): ml2_network_segments ? subnet = make_subnet_from_nova_network(nova_network) subnet['network_id'] = neutron_network['id'] self.migrated_subnets.append(subnet) LOG.debug('From nova network %s new network %s and subnet %s were ' 'created.', nova_network, neutron_network, subnet) import ipdb; ipdb.set_trace() self.neutron_db.execute(neutron_nets_table.insert(), self.migrated_networks) self.neutron_db.execute(neutron_extnet_table.insert(), neutron_extnets) self.neutron_db.execute(neutron_subnets_table.insert(), self.migrated_subnets) #TODO(jlibosva): Create ipallocationpools based on subnets #TODO(jlibosva): ml2_vlan_allocations #TODO(jlibosva): if dhcp was used, create networkdhcpagentbindings # entries def migrate_vifs(self): nova_vifs_table = self.nova_db.virtual_interfaces #TODO(jlibosva): Make ipallocations based on used ips by vifs #TODO(jlibosva): Create ipavailablity ranges based on subnets #TODO(jlibosva): ml2_port_bindings #TODO(jlibosva): ports def migrate_security_groups(self): pass def parse_arguments(): parser = argparse.ArgumentParser() parser.add_argument('nova_db_cs', help=""Connection string to nova database"") parser.add_argument('neutron_db_cs', help=""Connection string to neutron database"") return parser.parse_args() def main(): args = parse_arguments() migrator = Migrator(args.nova_db_cs, args.neutron_db_cs) migrator.migrate() if __name__ == ""__main__"": main() ",,226,0
openstack%2Ftripleo-heat-templates~master~I4b6b77e878017bf92d7c59c868d393e74405a355,openstack/tripleo-heat-templates,master,I4b6b77e878017bf92d7c59c868d393e74405a355,Use clustercheck script to control galera-ready,MERGED,2015-05-20 14:19:06.000000000,2015-05-21 08:20:48.000000000,2015-05-21 08:20:47.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8041}, {'_account_id': 8042}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-05-20 14:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ef8b5f5e3f4e95d1ac59244aa83c36668e28f129', 'message': 'Use clustercheck script to control galera-ready\n\nChange-Id: I4b6b77e878017bf92d7c59c868d393e74405a355\n'}, {'number': 2, 'created': '2015-05-20 14:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4edc4d362243822769a5294ee407c07eafb6be58', 'message': 'Use clustercheck script to control galera-ready\n\nChange-Id: I4b6b77e878017bf92d7c59c868d393e74405a355\n'}, {'number': 3, 'created': '2015-05-20 14:42:47.000000000', 'files': ['overcloud-without-mergepy.yaml', 'controller.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/controller-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5390499e692a3a12a60507e359384c44b1ea6784', 'message': 'Use clustercheck script to control galera-ready\n\nThe exec timeout/attempts is configured so that it is\nleft running for up to 30mins if the command runs but is\nunsuccessfull and up to 2h if the command times out.\n\nChange-Id: I4b6b77e878017bf92d7c59c868d393e74405a355\n'}]",0,184505,5390499e692a3a12a60507e359384c44b1ea6784,13,5,3,6796,,,0,"Use clustercheck script to control galera-ready

The exec timeout/attempts is configured so that it is
left running for up to 30mins if the command runs but is
unsuccessfull and up to 2h if the command times out.

Change-Id: I4b6b77e878017bf92d7c59c868d393e74405a355
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/05/184505/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-without-mergepy.yaml', 'controller.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/controller-puppet.yaml']",4,ef8b5f5e3f4e95d1ac59244aa83c36668e28f129,pcmk_resource_change,, MysqlClustercheckPassword: type: string hidden: true default: '' # Has to be here because of the ignored empty value bug mysql_clustercheck_password: {get_param: MysqlClustercheckPassword} mysql_clustercheck_password: {get_input: mysql_clustercheck_password},9,27
openstack%2Ffuel-library~master~If6f7f7e500f4a76d79349be802d43ba479dd597f,openstack/fuel-library,master,If6f7f7e500f4a76d79349be802d43ba479dd597f,Change version of kmod-openvswitch to kernel version,MERGED,2015-05-19 10:36:44.000000000,2015-05-21 08:20:05.000000000,2015-05-21 08:19:28.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11427}, {'_account_id': 11827}, {'_account_id': 13194}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-19 10:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cb27b31486579a4fa59816685520bc52eed17355', 'message': 'Change version of kmod-openvswitch to kernel version\n\nAs long as we should have 2 versions of kmod-openvswitch for\nevery kernel, we should select right version in manifests.\n\nChange-Id: If6f7f7e500f4a76d79349be802d43ba479dd597f\nRelated-Bug: #1456459\n'}, {'number': 2, 'created': '2015-05-19 15:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7bb24244fbf1c1a1a0b450d37a161f8d8eb689c7', 'message': 'Change version of kmod-openvswitch to kernel version\n\nAs long as we should have 2 versions of kmod-openvswitch for\nevery kernel, we should select right version in manifests.\n\nChange-Id: If6f7f7e500f4a76d79349be802d43ba479dd597f\nRelated-Bug: #1456459\n'}, {'number': 3, 'created': '2015-05-20 08:29:15.000000000', 'files': ['deployment/puppet/l23network/manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1d66413fcbd7289d56692c4c2e69456c2df81ed5', 'message': 'Change version of kmod-openvswitch to kernel version\n\nAs long as we should have 2 versions of kmod-openvswitch for\nevery kernel, we should select right version in manifests.\n\nChange-Id: If6f7f7e500f4a76d79349be802d43ba479dd597f\nRelated-Bug: #1456459\n'}]",0,184220,1d66413fcbd7289d56692c4c2e69456c2df81ed5,79,14,3,11827,,,0,"Change version of kmod-openvswitch to kernel version

As long as we should have 2 versions of kmod-openvswitch for
every kernel, we should select right version in manifests.

Change-Id: If6f7f7e500f4a76d79349be802d43ba479dd597f
Related-Bug: #1456459
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/20/184220/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/l23network/manifests/params.pp'],1,cb27b31486579a4fa59816685520bc52eed17355,bug/1456459," $ovs_datapath_package_name = ""kmod-openvswitch-$::kernelversion"""," $ovs_datapath_package_name = $::kernelmajversion ? { '3.10' => 'kmod-openvswitch-3.10.55-1', default => 'kmod-openvswitch', }",1,4
openstack%2Ffuel-library~master~Ibd4e87fbf3a27d1fca1bcad39ee9f534c9a92f60,openstack/fuel-library,master,Ibd4e87fbf3a27d1fca1bcad39ee9f534c9a92f60,Increase repo url availability timeout values,MERGED,2015-05-19 21:30:04.000000000,2015-05-21 08:19:52.000000000,2015-05-21 08:19:09.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8797}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11427}, {'_account_id': 11827}, {'_account_id': 13948}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-19 21:30:04.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/netconfig/tasks.yaml', 'deployment/puppet/osnailyfacter/lib/puppet/parser/functions/url_available.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e2845376be1ec0f34747d8f0d725b1000b460132', 'message': 'Increase repo url availability timeout values\n\nIn order to improve the experiance when deploying nodes on slow or\ncongested network links, we need to increase the values of the\ntimeouts for our url availability check. We are increasing them from\n5 seconds for the open and read timeouts to 60 seconds. Additionally\nwe are increasing the overall timeout on the check to 180 seconds. We\nare also increasing the task timeout from 600 seconds to 3600 seconds.\n\nChange-Id: Ibd4e87fbf3a27d1fca1bcad39ee9f534c9a92f60\nCloses-Bug: 1456805\nRelated-Bug: 1261940\n'}]",0,184334,e2845376be1ec0f34747d8f0d725b1000b460132,29,11,1,14985,,,0,"Increase repo url availability timeout values

In order to improve the experiance when deploying nodes on slow or
congested network links, we need to increase the values of the
timeouts for our url availability check. We are increasing them from
5 seconds for the open and read timeouts to 60 seconds. Additionally
we are increasing the overall timeout on the check to 180 seconds. We
are also increasing the task timeout from 600 seconds to 3600 seconds.

Change-Id: Ibd4e87fbf3a27d1fca1bcad39ee9f534c9a92f60
Closes-Bug: 1456805
Related-Bug: 1261940
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/34/184334/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/modular/netconfig/tasks.yaml', 'deployment/puppet/osnailyfacter/lib/puppet/parser/functions/url_available.rb']",2,e2845376be1ec0f34747d8f0d725b1000b460132,bug/1456805, out = Timeout::timeout(180) do http.open_timeout = 60 http.read_timeout = 60, out = Timeout::timeout(15) do http.open_timeout = 5 http.read_timeout = 5,4,4
openstack%2Ffuel-library~master~Ifc0109e55adc7fbf30b51f5cfb259ea2ae5bf585,openstack/fuel-library,master,Ifc0109e55adc7fbf30b51f5cfb259ea2ae5bf585,Fix disk space and error handling in dockerctl restore,MERGED,2015-05-19 17:21:24.000000000,2015-05-21 08:19:33.000000000,2015-05-21 08:18:53.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 6926}, {'_account_id': 7732}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-19 17:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/eca7904c2af6acc1ad0723e867aef8333da9f9b7', 'message': 'Fix disk space and error handling in dockerctl restore\n\nReduced free disk space for stateful restore to 2gb\n(still 11gb for full restore). Nonzero command exit\ncodes only apply to the beginning of restore, but\ncontainer startup now is handled without ""set -e"".\n\nChange-Id: Ifc0109e55adc7fbf30b51f5cfb259ea2ae5bf585\nPartial-Bug: #1448211\n'}, {'number': 2, 'created': '2015-05-19 21:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ab0f952e756ed0826a39ea689980f86a1813864c', 'message': 'Fix disk space and error handling in dockerctl restore\n\nReduced free disk space for stateful restore to 2gb\n(still 11gb for full restore). Nonzero command exit\ncodes only apply to the beginning of restore, but\ncontainer startup now is handled without ""set -e"".\n\nChange-Id: Ifc0109e55adc7fbf30b51f5cfb259ea2ae5bf585\nPartial-Bug: #1448211\n'}, {'number': 3, 'created': '2015-05-20 11:19:41.000000000', 'files': ['files/fuel-docker-utils/functions.sh'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/02393e503db32ee3c790e249df11c967dfcd1af4', 'message': 'Fix disk space and error handling in dockerctl restore\n\nReduced free disk space for stateful restore to 2gb\n(still 11gb for full restore). Nonzero command exit\ncodes only apply to the beginning of restore, but\ncontainer startup now is handled without ""set -e"".\n\nChange-Id: Ifc0109e55adc7fbf30b51f5cfb259ea2ae5bf585\nPartial-Bug: #1448211\nCloses-Bug: #1455488\n'}]",2,184298,02393e503db32ee3c790e249df11c967dfcd1af4,67,11,3,7195,,,0,"Fix disk space and error handling in dockerctl restore

Reduced free disk space for stateful restore to 2gb
(still 11gb for full restore). Nonzero command exit
codes only apply to the beginning of restore, but
container startup now is handled without ""set -e"".

Change-Id: Ifc0109e55adc7fbf30b51f5cfb259ea2ae5bf585
Partial-Bug: #1448211
Closes-Bug: #1455488
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/98/184298/2 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-docker-utils/functions.sh'],1,eca7904c2af6acc1ad0723e867aef8333da9f9b7,bug/docker-restore-disk-space," grep ""$id"" /proc/mounts | awk '{print $2}' | sort -r | xargs --no-run-if-empty -n1 umount -l 2>/dev/null verify_disk_space ""restore"" ""$fullrestore"" set +e fullbackup=1 statefulonly=0 if [[ ""$2"" != ""$statefulonly"" ]]; then #2gb free space required for light backup (( required = 2 * 1024 * 1024 )) spaceerror=""Insufficient disk space to perform $1. At least 2gb must be free on /var partition."" else #11gb free space required to backup and restore (( required = 11 * 1024 * 1024 )) spaceerror=""Insufficient disk space to perform $1. At least 11gb must be free on /var partition."" fi echo ""$spaceerror"" 1>&2"," umount -l $(grep ""$id"" /proc/mounts | awk '{print $2}' | sort -r) 2>/dev/null verify_disk_space ""restore"" #11gb free space required to backup and restore (( required = 11 * 1024 * 1024 )) echo ""Insufficient disk space to perform $1. At least 11gb must be free on /var partition."" 1>&2",15,6
openstack%2Fironic~master~Ic4f42e59cbda968d301c797ef77ff98030c55c41,openstack/ironic,master,Ic4f42e59cbda968d301c797ef77ff98030c55c41,Added vagrant VM for developer use,MERGED,2015-03-24 22:25:06.000000000,2015-05-21 08:17:31.000000000,2015-05-21 08:17:29.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 8106}, {'_account_id': 9315}, {'_account_id': 9717}, {'_account_id': 10380}, {'_account_id': 11655}, {'_account_id': 12081}, {'_account_id': 13295}, {'_account_id': 13362}, {'_account_id': 13997}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-03-24 22:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b44ea6a4f1d59c34480ce60f181df1e6f73863a4', 'message': ""Added vagrant VM for developer use\n\nThis patch adds a vagrantfile and ansible playbook that captures\nthe instructions from the ironic developer quickstart. By using\n'vagrant up', and configuring your local dev instance to use\n192.168.99.11, you should be able to exercise your services locally.\nDocumentation has also been updated.\n\nChange-Id: Ic4f42e59cbda968d301c797ef77ff98030c55c41\n""}, {'number': 2, 'created': '2015-03-25 15:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2ad505549497f345dc544b8bece92d121fad64a3', 'message': ""Added vagrant VM for developer use\n\nThis patch adds a vagrantfile and ansible playbook that captures\nthe instructions from the ironic developer quickstart. By using\n'vagrant up', and configuring your local dev instance to use\n192.168.99.11, you should be able to exercise your services locally.\nDocumentation has also been updated.\n\nChange-Id: Ic4f42e59cbda968d301c797ef77ff98030c55c41\n""}, {'number': 3, 'created': '2015-04-08 19:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6002a49d41e52a85f7402e7fd1a65400a51ebdea', 'message': ""Added vagrant VM for developer use\n\nThis patch adds a vagrantfile and ansible playbook that captures\nthe instructions from the ironic developer quickstart. By using\n'vagrant up', and configuring your local dev instance to use\n192.168.99.11, you should be able to exercise your services locally.\nDocumentation has also been updated.\n\nChange-Id: Ic4f42e59cbda968d301c797ef77ff98030c55c41\n""}, {'number': 4, 'created': '2015-04-23 18:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7a8f681c633b3ff980f6322203fc56b6c70beae6', 'message': ""Added vagrant VM for developer use\n\nThis patch adds a vagrantfile and ansible playbook that captures\nthe instructions from the ironic developer quickstart. By using\n'vagrant up', and configuring your local dev instance to use\n192.168.99.11, you should be able to exercise your services locally.\nDocumentation has also been updated.\n\nChange-Id: Ic4f42e59cbda968d301c797ef77ff98030c55c41\n""}, {'number': 5, 'created': '2015-04-30 15:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/90baa26879f681174e6858cd8e04002ad31a3f50', 'message': ""Added vagrant VM for developer use\n\nThis patch adds a vagrantfile and ansible playbook that captures\nthe instructions from the ironic developer quickstart. By using\n'vagrant up', and configuring your local dev instance to use\n192.168.99.11, you should be able to exercise your services locally.\nDocumentation has also been updated.\n\nChange-Id: Ic4f42e59cbda968d301c797ef77ff98030c55c41\n""}, {'number': 6, 'created': '2015-05-14 00:17:28.000000000', 'files': ['doc/source/dev/dev-quickstart.rst', '.gitignore', 'Vagrantfile', 'vagrant.yml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/ef237e0e5f11bfabca760b898756af39f0ffbd31', 'message': ""Added vagrant VM for developer use\n\nThis patch adds a vagrantfile and ansible playbook that captures\nthe instructions from the ironic developer quickstart. By using\n'vagrant up', and configuring your local dev instance to use\n192.168.99.11, you should be able to exercise your services locally.\nDocumentation has also been updated.\n\nChange-Id: Ic4f42e59cbda968d301c797ef77ff98030c55c41\n""}]",2,167415,ef237e0e5f11bfabca760b898756af39f0ffbd31,54,13,6,9717,,,0,"Added vagrant VM for developer use

This patch adds a vagrantfile and ansible playbook that captures
the instructions from the ironic developer quickstart. By using
'vagrant up', and configuring your local dev instance to use
192.168.99.11, you should be able to exercise your services locally.
Documentation has also been updated.

Change-Id: Ic4f42e59cbda968d301c797ef77ff98030c55c41
",git fetch https://review.opendev.org/openstack/ironic refs/changes/15/167415/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/dev/dev-quickstart.rst', '.gitignore', 'Vagrantfile', 'vagrant.yml']",4,b44ea6a4f1d59c34480ce60f181df1e6f73863a4,cors,"--- ############################################################################### # This ansible playbook installs all supporting software necessary to run the # ironic service locally into the vagrant VM attached. Its intent is to provide # a quickstart development environment that doesn't pollute an engineer's own # machine. # # The vagrant vm's IP address is assumed to be 192.168.99.11 # # http://docs.openstack.org/developer/ironic/dev/dev-quickstart.html#exercising-the-services-locally # - hosts: ironic sudo: yes tasks: ############################################################################ # APT Updates ############################################################################ # Make sure our VM's software is ~@Latest - name: Apt Update apt: update_cache=yes upgrade=dist cache_valid_time=86400 # Reboot if required. - name: Reboot system if required command: shutdown -r now 'Rebooting to complete system upgrade' removes=/var/run/reboot-required register: rebooted - name: Wait for VM Reboot. sudo: no local_action: wait_for port=22 host=""{{ip}}"" search_regex=OpenSSH delay=10 timeout=900 when: rebooted.changed ############################################################################ # Install all the needed packages in one go. ############################################################################ - name: Install Required Packages apt: name={{item}} state=present with_items: - rabbitmq-server - python-mysqldb - mysql-server - mysql-client ############################################################################ # Configure rabbitmq. ############################################################################ - name: Ensure rabbitmq is running service: name=rabbitmq-server state=started enabled=yes - name: Add ironic RabbitMQ user rabbitmq_user: user=ironic password=ironic vhost=/ configure_priv=.* read_priv=.* write_priv=.* state=present ############################################################################ # Configure mysql. ############################################################################ - name: Configure MySQL lineinfile: dest=/etc/mysql/my.cnf line=""bind-address={{ip}}"" regexp=""^bind\-address"" notify: Restart MySQL - name: Create MySQL Database mysql_db: name=ironic state=present - name: Create ironic MySQL user mysql_user: name=ironic password=ironic host={{item}} priv=ironic.*:ALL state=present with_items: - localhost - ""%"" - name: Ensure mysql is running service: name=mysql state=started enabled=yes ############################################################################ # Create ironic.conf.local configuration. ############################################################################ - name: Update local configuration with vagrant parameters. sudo: no local_action: ini_file dest=etc/ironic/ironic.conf.local section=""{{item.section}}"" option=""{{item.option}}"" value=""{{item.value}}"" with_items: - { section: 'glance', option: 'auth_strategy', value: 'noauth' } - { section: 'neutron', option: 'auth_strategy', value: 'noauth' } - { section: 'database', option: 'connection', value: ""mysql://ironic:ironic@{{ip}}/ironic"" } - { section: 'DEFAULT', option: 'auth_strategy', value: 'noauth' } - { section: 'DEFAULT', option: 'enabled_drivers', value: 'fake_ipmitool' } - { section: 'DEFAULT', option: 'pecan_debug', value: 'true' } - { section: 'oslo_messaging_rabbit', option: 'rabbit_host', value: ""{{ip}}"" } - { section: 'oslo_messaging_rabbit', option: 'rabbit_userid', value: ""ironic"" } - { section: 'oslo_messaging_rabbit', option: 'rabbit_password', value: ""ironic"" } ############################################################################# # Handlers ############################################################################# handlers: - name: Restart MySQL service: name=mysql state=restarted enabled=yes ",,235,24
openstack%2Ftripleo-heat-templates~master~Ia78ec38520bd1295872ea2690e8d3f8d6b01c46c,openstack/tripleo-heat-templates,master,Ia78ec38520bd1295872ea2690e8d3f8d6b01c46c,Prepare for adding OpenStack services to Pacemaker,MERGED,2015-05-20 08:32:11.000000000,2015-05-21 08:13:41.000000000,2015-05-21 08:13:39.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 8042}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-05-20 08:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/614d94cbe89fa78f56216392605fe2dff36497b3', 'message': 'Prepare for adding OpenStack services to Pacemaker\n\nWe need to write config for OpenStack services on all nodes in step 3 so\nthat we can then create pacemaker resources in step 4. (If we wrote\nconfig on non-bootstrap nodes in step 4 as it is currently, services on\nthose nodes might be started unconfigured. This is an inter-node\nordering issue that cannot be easily solved from within Puppet\nmanifests, hence the use of steps to enforce this ordering.)\n\nChange-Id: Ia78ec38520bd1295872ea2690e8d3f8d6b01c46c\n'}, {'number': 2, 'created': '2015-05-20 09:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/61cb0c2260e62c0c6cb8b28fe98622d39245a3f7', 'message': 'Prepare for adding OpenStack services to Pacemaker\n\nWe need to write config for OpenStack services on all nodes in step 3 so\nthat we can then create pacemaker resources in step 4. (If we wrote\nconfig on non-bootstrap nodes in step 4 as it is currently, services on\nthose nodes might be started unconfigured. This is an inter-node\nordering issue that cannot be easily solved from within Puppet\nmanifests, hence the use of steps to enforce this ordering.)\n\nChange-Id: Ia78ec38520bd1295872ea2690e8d3f8d6b01c46c\n'}, {'number': 3, 'created': '2015-05-20 12:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7e12961af97a1309ebf8b82d0f475b7df7f82148', 'message': 'Prepare for adding OpenStack services to Pacemaker\n\nWe need to write config for OpenStack services on all nodes in step 3 so\nthat we can then create pacemaker resources in step 4. (If we wrote\nconfig on non-bootstrap nodes in step 4 as it is currently, services on\nthose nodes might be started unconfigured. This is an inter-node\nordering issue that cannot be easily solved from within Puppet\nmanifests, hence the use of steps to enforce this ordering.)\n\nChange-Id: Ia78ec38520bd1295872ea2690e8d3f8d6b01c46c\n'}, {'number': 4, 'created': '2015-05-20 12:54:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/72f3200f3608cde283bf839f5e2ae74ce04961eb', 'message': 'Prepare for adding OpenStack services to Pacemaker\n\nWe need to write config for OpenStack services on all nodes in step 3 so\nthat we can then create pacemaker resources in step 4. (If we wrote\nconfig on non-bootstrap nodes in step 4 as it is currently, services on\nthose nodes might be started unconfigured. This is an inter-node\nordering issue that cannot be easily solved from within Puppet\nmanifests, hence the use of steps to enforce this ordering.)\n\nChange-Id: Ia78ec38520bd1295872ea2690e8d3f8d6b01c46c\n'}, {'number': 5, 'created': '2015-05-20 12:55:59.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/43d4eee72884c23de2aef76436ba2044afdb80e8', 'message': 'Prepare for adding OpenStack services to Pacemaker\n\nWe need to write config for OpenStack services on all nodes in step 3 so\nthat we can then create pacemaker resources in step 4. (If we wrote\nconfig on non-bootstrap nodes in step 4 as it is currently, services on\nthose nodes might be started unconfigured. This is an inter-node\nordering issue that cannot be easily solved from within Puppet\nmanifests, hence the use of steps to enforce this ordering.)\n\nChange-Id: Ia78ec38520bd1295872ea2690e8d3f8d6b01c46c\n'}]",1,184436,43d4eee72884c23de2aef76436ba2044afdb80e8,29,5,5,8042,,,0,"Prepare for adding OpenStack services to Pacemaker

We need to write config for OpenStack services on all nodes in step 3 so
that we can then create pacemaker resources in step 4. (If we wrote
config on non-bootstrap nodes in step 4 as it is currently, services on
those nodes might be started unconfigured. This is an inter-node
ordering issue that cannot be easily solved from within Puppet
manifests, hence the use of steps to enforce this ordering.)

Change-Id: Ia78ec38520bd1295872ea2690e8d3f8d6b01c46c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/36/184436/2 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,614d94cbe89fa78f56216392605fe2dff36497b3,pcmk_resource_change,"# When to start and enable services which haven't been Pacemakerized # FIXME: change to only step 4 after this patch is merged: # https://review.openstack.org/#/c/180565/ # $non_pcmk_start = hiera('step') >= 4 # FIXME: remove when we start all OpenStack services using Pacemaker # (occurences of this variable will be gradually replaced with false) $non_pcmk_start = hiera('step') >= 4 or (hiera('step') >= 3 and $pacemaker_master) if hiera('step') >= 3 { manage_service => $non_pcmk_start, enabled => $non_pcmk_start, manage_service => $non_pcmk_start, enabled => $non_pcmk_start, manage_service => $non_pcmk_start, enabled => $non_pcmk_start, manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::nova::cert': manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::nova::conductor': manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::nova::consoleauth': manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::nova::vncproxy': manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::nova::scheduler': manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::neutron::agents::dhcp' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::neutron::agents::l3' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } manage_service => $non_pcmk_start, enabled => $non_pcmk_start, manage_service => $non_pcmk_start, enabled => $non_pcmk_start, manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::cinder::scheduler' : manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::cinder::volume' : manage_service => $non_pcmk_start, enabled => $non_pcmk_start, class { '::swift::proxy' : manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::ceilometer::api' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::ceilometer::agent::notification' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::ceilometer::agent::central' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::ceilometer::alarm::notifier' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::ceilometer::alarm::evaluator' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::ceilometer::collector' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::heat::api' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::heat::api_cfn' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::heat::api_cloudwatch' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, } class { '::heat::engine' manage_service => $non_pcmk_start, enabled => $non_pcmk_start, }} #END STEP 3 if hiera('step') >= 4 { # TODO: pacemaker::resource::service for OpenStack services go here } #END STEP 4",if (hiera('step') >= 3 and $pacemaker_master) or hiera('step') >= 4 { } include ::nova::cert include ::nova::conductor include ::nova::consoleauth include ::nova::vncproxy include ::nova::scheduler } include ::neutron::agents::dhcp include ::neutron::agents::l3 include ::cinder::scheduler include ::cinder::volume include ::swift::proxy include ::ceilometer::api include ::ceilometer::agent::notification include ::ceilometer::agent::central include ::ceilometer::alarm::notifier include ::ceilometer::alarm::evaluator include ::ceilometer::collector include ::heat::api include ::heat::api_cfn include ::heat::api_cloudwatch include ::heat::engine} #END STEP 3/4,110,22
openstack%2Fnova~master~Ib151c3d67cc91957d8a7dedc4cdaf8c4de1da6c7,openstack/nova,master,Ib151c3d67cc91957d8a7dedc4cdaf8c4de1da6c7,Fix the race condition in instance_create when checking for duplicate hostname,ABANDONED,2015-04-12 01:24:39.000000000,2015-05-21 07:57:10.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 7653}, {'_account_id': 9578}, {'_account_id': 11061}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-04-12 01:24:39.000000000', 'files': ['nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4d57a1ad11d02975e2a080b7ff8891a0908209cc', 'message': 'Fix the race condition in instance_create when checking for\nduplicate hostname\n\nThere is a race condition in instance_create, that allows creation\nseveral instances with duplicate hostname. Before storing instance\nrecord in database, there is a query for existing records with same\nhostname. However, when we have two instances, running\n_get_sec_group_models() for first instance, then second instance\nwith same hostname will pass through _validate_unique_server_name(),\nthere will be duplicates. This patch reverses them order to fix the\nrace condition.\n\nChange-Id: Ib151c3d67cc91957d8a7dedc4cdaf8c4de1da6c7\nCloses-Bug: #1436897\n'}]",0,172693,4d57a1ad11d02975e2a080b7ff8891a0908209cc,10,7,1,7653,,,0,"Fix the race condition in instance_create when checking for
duplicate hostname

There is a race condition in instance_create, that allows creation
several instances with duplicate hostname. Before storing instance
record in database, there is a query for existing records with same
hostname. However, when we have two instances, running
_get_sec_group_models() for first instance, then second instance
with same hostname will pass through _validate_unique_server_name(),
there will be duplicates. This patch reverses them order to fix the
race condition.

Change-Id: Ib151c3d67cc91957d8a7dedc4cdaf8c4de1da6c7
Closes-Bug: #1436897
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/172693/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api.py'],1,4d57a1ad11d02975e2a080b7ff8891a0908209cc,Bug1436897," if 'hostname' in values: _validate_unique_server_name(context, session, values['hostname'])"," if 'hostname' in values: _validate_unique_server_name(context, session, values['hostname'])",2,2
openstack%2Ftempest~master~I5889287cc0c16f902252877295155d9b9cd5820c,openstack/tempest,master,I5889287cc0c16f902252877295155d9b9cd5820c,Adds unit test for Javelin,MERGED,2015-03-19 11:08:26.000000000,2015-05-21 07:52:01.000000000,2015-05-21 07:51:59.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 3153}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7020}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-03-19 11:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/eda5898bf59769e5f3dda61b8881d481ca01fea8', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}, {'number': 2, 'created': '2015-03-29 21:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/57863eee323870e5e38ffa5d1c01d9a03df63bb4', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}, {'number': 3, 'created': '2015-03-30 10:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b979b781af79ffdabd1b7b37151aac4df6acc1fc', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nDone so far:\n\n* Users: create/destroy\n* Tenants: create/destroy\n* Objects: create/destroy\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}, {'number': 4, 'created': '2015-03-30 11:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e347df9250fe71947a49828d4194983c8d3f39a4', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nDone so far:\n\n* Users: create/destroy\n* Tenants: create/destroy\n* Objects: create/destroy\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}, {'number': 5, 'created': '2015-03-30 14:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a8fe95cfac65aaf98e2bef093d1379a02f63d0e3', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nDone so far:\n\n* Users: create/destroy\n* Tenants: create/destroy\n* Objects: create/destroy\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}, {'number': 6, 'created': '2015-03-30 16:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9ea66331fb8fb97c538d75ed45261ac26b302d57', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nDone so far:\n\n* Users: create/destroy\n* Tenants: create/destroy\n* Objects: create/destroy\n* Images: create/destroy\n* Networks: create/destroy\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}, {'number': 7, 'created': '2015-04-06 16:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c80ba87cd343e97a892c0902b5ec701a8865b7e1', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nDone so far:\n\n* Users: create/destroy\n* Tenants: create/destroy\n* Objects: create/destroy\n* Images: create/destroy\n* Networks: create/destroy\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}, {'number': 8, 'created': '2015-04-06 17:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/af0a3b226759166dea4f0e07df23f3dfe40d7939', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nDone so far:\n\n* Users: create/destroy\n* Tenants: create/destroy\n* Objects: create/destroy\n* Images: create/destroy\n* Networks: create/destroy\n* Subnets: create/destroy\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}, {'number': 9, 'created': '2015-04-21 10:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/49b2fe2ca100f987cbd56ff260b405ed9c066a9a', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nDone so far:\n\n* Users: create/destroy\n* Tenants: create/destroy\n* Objects: create/destroy\n* Images: create/destroy\n* Networks: create/destroy\n* Subnets: create/destroy\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}, {'number': 10, 'created': '2015-05-11 11:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/266fb1ace97bc5b08d46f5e5604ff9cd895b6d64', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nDone so far:\n\n* Users: create/destroy\n* Tenants: create/destroy\n* Objects: create/destroy\n* Images: create/destroy\n* Networks: create/destroy\n* Subnets: create/destroy\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}, {'number': 11, 'created': '2015-05-12 11:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/400e6a38d126049b7d1586f67b04fdf7bff576fb', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nDone so far:\n\n* Users: create/destroy\n* Tenants: create/destroy\n* Objects: create/destroy\n* Images: create/destroy\n* Networks: create/destroy\n* Subnets: create/destroy\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}, {'number': 12, 'created': '2015-05-12 13:09:39.000000000', 'files': ['tempest/tests/cmd/test_javelin.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/fe75f93be1c52f1c634e32d6feb11a120df3f2bb', 'message': ""Adds unit test for Javelin\n\nJavelin lacks unit tests. Let's add some!\n\nDone so far:\n\n* Users: create/destroy\n* Tenants: create/destroy\n* Objects: create/destroy\n* Images: create/destroy\n* Networks: create/destroy\n* Subnets: create/destroy\n\nPartially implements: blueprint javelin2\n\nChange-Id: I5889287cc0c16f902252877295155d9b9cd5820c\n""}]",2,165775,fe75f93be1c52f1c634e32d6feb11a120df3f2bb,54,8,12,7020,,,0,"Adds unit test for Javelin

Javelin lacks unit tests. Let's add some!

Done so far:

* Users: create/destroy
* Tenants: create/destroy
* Objects: create/destroy
* Images: create/destroy
* Networks: create/destroy
* Subnets: create/destroy

Partially implements: blueprint javelin2

Change-Id: I5889287cc0c16f902252877295155d9b9cd5820c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/75/165775/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/tests/cmd/test_javelin.py'],1,eda5898bf59769e5f3dda61b8881d481ca01fea8,bp/javelin2,"#!/usr/bin/env python # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from tempest.cmd import javelin from tempest.tests import base class TestCreateResources(base.TestCase): def test_create_tenants(self): def fake_create(tenant): self.fake_body.append({'name': tenant}) fake_auth = mock.Mock() self.fake_body = [] fake_auth.identity.list_tenants.return_value = self.fake_body fake_auth.identity.create_tenant.side_effect = fake_create with mock.patch.object(javelin, ""keystone_admin"", return_value=fake_auth): javelin.create_tenants(['tenant1']) self.assertTrue('tenant1' in [x['name'] for x in self.fake_body]) def test_create_users(self): def fake_create(name, password, tenant_id, email, enabled): self.fake_body.append( { 'name': name, 'pass': password, 'tenant_id': tenant_id, 'email': email, 'enabled': enabled } ) fake_auth = mock.Mock() self.fake_body = [] fake_auth.identity.get_tenant_by_name.return_value = { 'name': 'tenant1', 'id': 1 } fake_auth.identity.create_user.side_effect = fake_create with mock.patch.object(javelin, ""keystone_admin"", return_value=fake_auth): test_user = { 'name': 'user1', 'pass': 'password' } javelin.create_users([test_user]) self.assertIn('user1', [x['name'] for x in self.fake_body]) class TestCheckResources(base.TestCase): pass class TestDestroyResources(base.TestCase): def test_destroy_tenants(self): def fake_destroy(tenant_id): for tenant in self.fake_body: if tenant['id'] == tenant_id: self.fake_body.remove(tenant) fake_auth = mock.Mock() self.fake_body = [{'id': '1', 'name': 'tenant1'}] fake_auth.identity.delete_tenant.side_effect = fake_destroy fake_auth.identity.get_tenant_by_name.return_value = self.fake_body[0] with mock.patch.object(javelin, ""keystone_admin"", return_value=fake_auth): javelin.destroy_tenants(['tenant1']) self.assertTrue('tenant1' not in [x['name'] for x in self.fake_body]) def test_destroy_users(self): def fake_destroy(user_id): for user in self.fake_body: if user['id'] == user_id: self.fake_body.remove(user) fake_auth = mock.Mock() self.fake_body = [{'id': '1', 'name': 'user1'}] fake_auth.identity.delete_user.side_effect = fake_destroy fake_auth.identity.get_tenant_by_name.return_value = {'id': 1} fake_auth.identity.get_user_by_username = {'id': 1} with mock.patch.object(javelin, ""keystone_admin"", return_value=fake_auth): javelin.destroy_users(['user1']) self.assertTrue('user1' not in [x['name'] for x in self.fake_body]) ",,108,0
openstack%2Ftempest~master~I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479,openstack/tempest,master,I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479,Extend credentials to support roles,MERGED,2015-04-09 09:31:01.000000000,2015-05-21 07:11:05.000000000,2015-05-21 07:11:02.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-04-09 09:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ee8bbed68f240ed91faae6159361d56cf135cd17', 'message': 'Extend credentials to support roles\n\nTest can request credentials to be allocated by specifying\nthe required credential types at class level.\nExtending that mechanism to support credentials by roles as\nwell.\n\nChange-Id: I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479\n'}, {'number': 2, 'created': '2015-04-09 17:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/45c63ce09cfc5426b5749c0dd4a175141f78ec87', 'message': 'Extend credentials to support roles\n\nTest can request credentials to be allocated by specifying\nthe required credential types at class level.\nExtending that mechanism to support credentials by roles as\nwell.\n\nChange-Id: I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479\n'}, {'number': 3, 'created': '2015-04-09 19:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/db26e01313fb7f2c9ba3c141997b480fb6a986a2', 'message': 'Extend credentials to support roles\n\nTest can request credentials to be allocated by specifying\nthe required credential types at class level.\nExtending that mechanism to support credentials by roles as\nwell.\n\nChange-Id: I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479\n'}, {'number': 4, 'created': '2015-04-10 14:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/94e041989920cb3afb75527f62832532482b57e5', 'message': 'Extend credentials to support roles\n\nTest can request credentials to be allocated by specifying\nthe required credential types at class level.\nExtending that mechanism to support credentials by roles as\nwell.\n\nChange-Id: I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479\n'}, {'number': 5, 'created': '2015-04-10 18:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ae2aae6671f0af34c2a9ab7ae91ac28334b547b8', 'message': 'Extend credentials to support roles\n\nTest can request credentials to be allocated by specifying\nthe required credential types at class level.\nExtending that mechanism to support credentials by roles as\nwell.\n\nChange-Id: I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479\n'}, {'number': 6, 'created': '2015-05-12 19:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6b2474c2d2b133d78ac8b34999ff529fe424a1cf', 'message': 'Extend credentials to support roles\n\nTest can request credentials to be allocated by specifying\nthe required credential types at class level.\nExtending that mechanism to support credentials by roles as\nwell.\n\nChange-Id: I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479\n'}, {'number': 7, 'created': '2015-05-13 07:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8fb6fabd365652a4d7f1ef59368920223d595081', 'message': 'Extend credentials to support roles\n\nTest can request credentials to be allocated by specifying\nthe required credential types at class level.\nExtending that mechanism to support credentials by roles as\nwell.\n\nChange-Id: I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479\n'}, {'number': 8, 'created': '2015-05-13 10:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f8a258f56261e5feeace1e8ae35879413f3228cb', 'message': 'Extend credentials to support roles\n\nTest can request credentials to be allocated by specifying\nthe required credential types at class level.\nExtending that mechanism to support credentials by roles as\nwell.\n\nChange-Id: I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479\n'}, {'number': 9, 'created': '2015-05-13 15:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5ae98cbef8ce6c0f0fc56aad92dd1e31a021b9ac', 'message': 'Extend credentials to support roles\n\nTest can request credentials to be allocated by specifying\nthe required credential types at class level.\nExtending that mechanism to support credentials by roles as\nwell.\n\nChange-Id: I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479\n'}, {'number': 10, 'created': '2015-05-13 19:05:39.000000000', 'files': ['tempest/api/object_storage/test_account_quotas_negative.py', 'tempest/api/object_storage/base.py', 'tempest/api/object_storage/test_account_quotas.py', 'tempest/api/object_storage/test_object_services.py', 'tempest/api/object_storage/test_account_services_negative.py', 'tempest/api/object_storage/test_container_acl.py', 'tempest/api/object_storage/test_container_acl_negative.py', 'tempest/api/object_storage/test_account_services.py', 'tempest/api/object_storage/test_container_sync.py', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/825b2d3eae360252f7d21ea34952db6111b53916', 'message': 'Extend credentials to support roles\n\nTest can request credentials to be allocated by specifying\nthe required credential types at class level.\nExtending that mechanism to support credentials by roles as\nwell.\n\nChange-Id: I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479\n'}]",14,171980,825b2d3eae360252f7d21ea34952db6111b53916,44,6,10,1921,,,0,"Extend credentials to support roles

Test can request credentials to be allocated by specifying
the required credential types at class level.
Extending that mechanism to support credentials by roles as
well.

Change-Id: I2f026e553f8c2c2a4cf2cb319bcd67e7d82e0479
",git fetch https://review.opendev.org/openstack/tempest refs/changes/80/171980/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/object_storage/test_account_quotas_negative.py', 'tempest/api/object_storage/base.py', 'tempest/api/object_storage/test_account_quotas.py', 'tempest/api/object_storage/test_object_services.py', 'tempest/api/object_storage/test_account_services_negative.py', 'tempest/api/object_storage/test_container_acl.py', 'tempest/api/object_storage/test_account_services.py', 'tempest/api/object_storage/test_container_acl_negative.py', 'tempest/api/object_storage/test_container_sync.py', 'tempest/test.py']",10,ee8bbed68f240ed91faae6159361d56cf135cd17,bp/resource-cleanup," # at class setup time. Credential types can be 'primary', 'alt', 'admin' or # a list of roles credentials = [] idx = 1 try: if isinstance(credentials_type, six.string_types): manager = cls.get_client_manager( credential_type=credentials_type) setattr(cls, 'os_%s' % credentials_type, manager) # Setup some common aliases if credentials_type == 'primary': cls.os = cls.manager = cls.os_primary if credentials_type == 'admin': cls.os_adm = cls.admin_manager = cls.os_admin if credentials_type == 'alt': cls.alt_manager = cls.os_alt elif isinstance(credentials_type, list): manager = cls.get_client_manager(roles=credentials_type, force_new=True) setattr(cls, 'os_roles_%s' % idx, manager) idx += 1"," credentials = [] # at class setup time. Credential types can be 'primary', 'alt' or 'admin' try: manager = cls.get_client_manager( credential_type=credentials_type) setattr(cls, 'os_%s' % credentials_type, manager) # Setup some common aliases if credentials_type == 'primary': cls.os = cls.manager = cls.os_primary if credentials_type == 'admin': cls.os_adm = cls.admin_manager = cls.os_admin if credentials_type == 'alt': cls.alt_manager = cls.os_alt",62,32
openstack%2Fopenstack-manuals~master~Ibee3908ed28c2cf48bf93646ecdabd407eca3be4,openstack/openstack-manuals,master,Ibee3908ed28c2cf48bf93646ecdabd407eca3be4,Imported Translations from Transifex,MERGED,2015-05-21 06:12:24.000000000,2015-05-21 06:58:04.000000000,2015-05-21 06:58:02.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-05-21 06:12:24.000000000', 'files': ['doc/config-reference/locale/config-reference.pot', 'doc/common/locale/common.pot', 'doc/common/locale/ja.po', 'doc/common/locale/zh_CN.po', 'doc/common/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/34547f2904293a5086ebc12eb23dbf4120e4f738', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ibee3908ed28c2cf48bf93646ecdabd407eca3be4\n'}]",0,184718,34547f2904293a5086ebc12eb23dbf4120e4f738,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ibee3908ed28c2cf48bf93646ecdabd407eca3be4
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/18/184718/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/locale/config-reference.pot', 'doc/common/locale/common.pot', 'doc/common/locale/ja.po', 'doc/common/locale/zh_CN.po', 'doc/common/locale/fr.po']",5,34547f2904293a5086ebc12eb23dbf4120e4f738,transifex/translations,"""POT-Creation-Date: 2015-05-21 05:03+0000\n"" ""PO-Revision-Date: 2015-05-21 00:33+0000\n""msgid ""Description"" msgstr ""Description"" msgid ""For example:"" msgstr ""Par exemple :"" msgid ""Projects"" msgstr ""Projets"" msgid ""Get details for your image to check its status:"" msgstr ""Trouver les détails de votre image pour vérifier son état:"" ","""POT-Creation-Date: 2015-05-07 20:19+0000\n"" ""PO-Revision-Date: 2015-05-07 17:13+0000\n""msgid ""Manage Compute service quotas"" msgstr ""Gérer les quotas du service Calcul"" msgid ""Description"" msgstr ""Description"" msgid ""Number of floating IP addresses allowed per tenant."" msgstr ""Nombre d'adresses IP flottantes allouées par projet."" msgid ""instances"" msgstr ""instances"" msgid ""Number of key pairs allowed per user."" msgstr ""Nombre de paires de clefs alloué par utilisateur."" msgid ""ram"" msgstr ""ram"" msgid ""Number of security groups per tenant."" msgstr ""Nombre de groupes de sécurité par projet."" msgid ""Number of rules per security group."" msgstr ""Nombre de règles par groupe de sécurité."" msgid ""To view and update default quota values"" msgstr ""Pour voir et mettre à jour les valeurs par défaut des quotas"" msgid ""For example:"" msgstr ""Par exemple :"" msgid ""key"" msgstr ""clé"" msgid ""value"" msgstr ""valeur"" msgid ""tenantName"" msgstr ""Nom du locataire"" msgid ""Obtain the tenant ID, as follows:"" msgstr ""Obtenir l'identité du locataire, comme suit:"" msgid ""Update a particular quota value, as follows:"" msgstr ""Mettre à jour une valeur de quota particulier, comme suit:"" msgid ""quotaName"" msgstr ""Nom du quota"" msgid ""tenantID"" msgstr ""Identifiant du locataire"" msgid ""userName"" msgstr ""Nom d'utilisateur"" msgid ""Manage images with the nova client"" msgstr ""Gérer les images avec le client nova"" msgid """" ""The safest approach is to shut down the instance before you take a snapshot."" msgstr """" ""L'approche le plus sûr, c'est d'arrêter l'instance avant de prendre "" ""l'instantané."" msgid """" ""You cannot create a snapshot from an instance that has an attached volume. "" ""Detach the volume, create the image, and re-mount the volume."" msgstr """" ""Vous ne pouvez pas créer un instantané d'une unstance qui a un volume "" ""attaché. Détachez le volume, créez l'image, et puis remonter le volume."" msgid ""To create an image"" msgstr ""Pour créer un image"" msgid ""To create the image, list instances to get the server ID:"" msgstr ""Pour créer l'image, listez les instances pour trouver l'ID du serveur:"" msgid ""Get details for your image to check its status:"" msgstr ""Trouver les détails de votre image pour vérifier son état:"" msgid ""IMAGE"" msgstr ""IMAGE"" msgid ""To launch an instance from your image"" msgstr ""Pour lancer une instance depuis votre image"" msgid """" ""To launch an instance from your image, include the image ID and flavor ID, "" ""as follows:"" msgstr """" ""Pour lancer une instance depuis votre image, inclure l'ID de l'image et l'ID "" ""du type d'instance, comme suite:"" msgid ""Troubleshoot image creation"" msgstr ""Résoudre les problèmes de la création des images"" msgid ""Create and manage networks"" msgstr ""Créez et gérez des réseaux"" msgid ""Create networks"" msgstr ""Créez des réseaux"" msgid ""Create a network:"" msgstr ""Créez un réseau"" msgid ""Create subnets"" msgstr ""Créez des sous-réseaux"" msgid ""Create a subnet:"" msgstr ""Créez un sous-réseau"" msgid ""Create routers"" msgstr ""Créer des routeurs"" msgid ""ROUTER"" msgstr ""ROUTEUR"" msgid ""NETWORK"" msgstr ""RESEAU"" msgid ""Link the router to the subnet:"" msgstr ""Liez le routeur au sous-réseau:"" msgid ""Create ports"" msgstr ""Créer des ports"" msgid ""Create a port with specified IP address:"" msgstr ""Créer un port avec une adresse IP précisée:"" msgid ""Create a port without specified IP address:"" msgstr ""Créer un port sans une adresse IP précisée:"" msgid ""PARAMETER"" msgstr ""PARAMETER"" msgid ""COMMAND"" msgstr ""COMMAND"" msgid ""ARGUMENT"" msgstr ""ARGUMENT"" msgid """" ""For example, you can run the <placeholder-1/> and <placeholder-2/> commands, "" ""as follows:"" msgstr """" ""Par exemple, vous pouvez exécuter les commandes <placeholder-1/> et "" ""<placeholder-2/>, comme suit:"" msgid ""token"" msgstr ""jeton"" msgid ""endpoint"" msgstr ""Point de terminaison"" msgid ""id"" msgstr ""id"" msgid ""To configure the keystone client with an authentication token"" msgstr ""Pour configurer le client keystone avec un jeton d'authentification"" msgid """" ""Alternatively, you can specify these parameters on any keystone client "" ""command:"" msgstr """" ""Alternativement, vous pouvez spécifier ces paramètres sur un client de "" ""commande keystone:"" msgid ""To configure the keystone client with a user name and password"" msgstr """" ""Pour configurer le client keystone avec un nom d'utilisateur et un mot de "" ""passe"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'figures/launch_instances.png'; md5=8a7e6864bce97f6478db572daf3ef5de"" msgstr """" ""@@image: 'figures/launch_instances.png'; md5=8a7e6864bce97f6478db572daf3ef5de"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid ""@@image: 'figures/instances.png'; md5=6b0f5cb3009d447334ff8b5c5b2cd121"" msgstr ""@@image: 'figures/instances.png'; md5=6b0f5cb3009d447334ff8b5c5b2cd121"" msgid ""Launch an instance from an image"" msgstr ""Lancer une instance depuis une image"" msgid ""Instances are virtual machines that run inside the cloud."" msgstr """" ""Les instances sont des machines virtuelles individuelles qui tournent dans "" ""le cloud."" msgid """" ""Alternatively, you can launch an instance from an image that you have copied "" ""to a persistent volume."" msgstr """" ""Autrement, vous pouvez lancer une instance à partird'une image qui a été "" ""copiée sur un volume persistent."" msgid ""To launch an instance, specify the following parameters:"" msgstr ""Pour lancer une instance, spécifiez les paramètres suivants:"" msgid ""A <guilabel>name</guilabel> for your instance."" msgstr ""Un <guilabel>name</guilabel> pour votre instance."" msgid """" ""Access and security credentials, which include one or both of the following "" ""credentials:"" msgstr """" ""Certificats d'accès et de sécurité, qui incluent un ou plusieurs des "" ""certificats suivants :"" msgid ""To launch an instance:"" msgstr ""Pour lancer une instance"" msgid ""Log in to the OpenStack dashboard."" msgstr ""Connectez-vous au tableau de bord OpenStack"" msgid """" ""If you are a member of multiple projects, select a project from the drop-"" ""down list at the top of the <guilabel>Project</guilabel> tab."" msgstr """" ""Si vous êtes membre de multiple projets, selectionnez un projet de la liste "" ""déroulante en tête de l'onglet <guilabel>Project</guilabel>."" msgid ""Click the <guilabel>Images &amp; Snapshot</guilabel> category."" msgstr ""Cliquez sur la catégorie <guilabel>Images &amp; Snapshot</guilabel>."" msgid ""OpenStack dashboard - Launch Instances window"" msgstr ""Tableau de bord OpenStack - Fenêtre du lancement des instances"" msgid """" ""Select an image and click <guibutton>Launch</guibutton>. The "" ""<guilabel>Launch Image</guilabel> window appears: <placeholder-1/>"" msgstr """" ""Sélectionnez une image et cliquez sur <guibutton>Launch</guibutton>. La "" ""fenêtre <guilabel>Launch Image</guilabel> s'affiche: <placeholder-1/>"" msgid ""Specify the following parameters:"" msgstr ""Spécifiez les paramètres suivants:"" msgid ""Enter an instance name to assign to the virtual machine."" msgstr ""Entrer le nom d'une instance pour l'assigner à la machine virtuel."" msgid """" ""From the <guilabel>Flavor</guilabel> drop-down list, select the size of the "" ""virtual machine to launch."" msgstr """" ""A partir de la liste déroulante <guilabel>Flavor</guilabel>, sélectionnez la "" ""taille de la machine virtuelle à lancer."" msgid ""Optionally, select a keypair."" msgstr ""Facultativement, choisissez une paire de clés."" msgid """" ""In <guilabel>Instance Count</guilabel>, enter the number of virtual machines "" ""to launch from this image."" msgstr """" ""Dans <guilabel>Instance Count</guilabel>, entrez le nombre de machines "" ""virtuelles à lancer depuis cette instance."" msgid """" ""Assign the instance to the default security group. If you added rules to "" ""this group, the instance implements these rules."" msgstr """" ""Assignez l'instance au groupe de sécurité par défaut. Si vous ajoutez des "" ""règles à ce groupe, l'instance met en oeuvre ces règles."" msgid """" ""Click <guibutton>Launch Instance</guibutton>. The instance is launched on "" ""any of the compute nodes in the cloud."" msgstr """" ""Cliquez sur <guibutton>Launch Instance</guibutton>. L'instance est lancé sur "" ""n'importe quel nœud de calcul dans le cloud. "" msgid ""OpenStack dashboard - Instances"" msgstr ""Tableau de bord OpenStack - Instances"" msgid """" ""If you did not provide a keypair on starting and have not touched security "" ""groups or rules so far, by default the instance can only be accessed from "" ""inside the cloud through VNC at this point. Even pinging the instance is not "" ""possible."" msgstr """" ""Si vous ne fournissez pas de paire de clés, de groupes de sécurités, ou de "" ""règles jusqu'ici, les utilisateurs ne peuvent accéder à l'instance qu'à "" ""partir du cloud par VNC. Même pinger l'instance n'est pas possible."" msgid ""Manage images"" msgstr ""Gérez les images"" msgid """" ""The cloud operator assigns roles to users. Roles determine who can upload "" ""and manage images. The operator might restrict image upload and management "" ""to only cloud administrators or operators."" msgstr """" ""L'opérateur du cloud assigne des rôles aux utilisateurs. Les rôles "" ""déterminent qui peut télécharger et gérer des images. L'opérateur pourrait "" ""restreindre le téléchargement d'images et de gestion uniquement pour les "" ""administrateurs du cloud ou les opérateurs."" msgid """" ""For details about image creation, see the <link href=\""http://docs.openstack."" ""org/image-guide/content/\""><citetitle>Virtual Machine Image Guide</"" ""citetitle></link>."" msgstr """" ""Pour plus de détails sur la création de l'image, voir le <link href=\""http://"" ""docs.openstack.org/image-guide/content/\""><citetitle>Virtual Machine Image "" ""Guide</citetitle></link>."" msgid ""List or get details for images (glance)"" msgstr ""Lister ou trouver les détails pour les images (glance)"" msgid ""show_multiple_locations = True"" msgstr ""show_multiple_locations = True"" msgid ""imageID"" msgstr ""imageID"" msgid ""Create or update an image (glance)"" msgstr ""Créer ou mettre à jour une image (glance)"" msgid ""The name of the image."" msgstr ""Le nom de l'image."" msgid ""The tenant who should own the image."" msgstr ""Le locataire qui devrait posséder l'image."" msgid ""qemu or kvm"" msgstr ""qemu ou kvm"" msgid ""ide"" msgstr ""ide"" msgid ""scsi"" msgstr ""scsi"" msgid ""virtio"" msgstr ""virtio"" msgid ""xen"" msgstr ""xen"" msgid ""e1000"" msgstr ""e1000"" msgid ""ne2k_pci"" msgstr ""ne2k_pci"" msgid ""pcnet"" msgstr ""pcnet"" msgid ""rtl8139"" msgstr ""rtl8139"" msgid ""netfront"" msgstr ""netfront"" msgid ""vmware"" msgstr ""vmware"" msgid ""VirtualE1000"" msgstr ""VirtualE1000"" msgid ""VirtualPCNet32"" msgstr ""VirtualPCNet32"" msgid ""VirtualVmxnet"" msgstr ""VirtualVmxnet"" msgid ""Insert metadata during launch"" msgstr ""<placeholder-2/>"" msgid """" ""When booting a server, you can also add metadata, so that you can more "" ""easily identify it amongst your ever-growing elastic cloud. Use the "" ""<literal>--meta</literal> option with a key=value pair, where you can make "" ""up the string for both the key and the value. For example, you could add a "" ""description and also the creator of the server. <placeholder-1/>"" msgstr """" ""Lorsque vous bootez un serveur, vous pouvez aussi ajouter des métadonnées, "" ""pour pouvoir l'identifier plus facilement au sein de votre toujours "" ""grandissant cloud élastique. Utilisez l'option <literal>--meta</literal> "" ""avec une paire key=value, où vous pouvez faire le lien entre la clé et la "" ""valeur. Par exemple, vous pouvez ajouter une description et aussi un "" ""créateur du serveur.<placeholder-1/>"" msgid """" ""When viewing the server information, you can see the metadata included on "" ""the <literal>metadata</literal> line: <placeholder-1/>"" msgstr """" ""Lorsque vous voyez les informations du serveur, vous pouvez voir les "" ""métadonnées inclues sur la ligne <literal>metadata</literal>: <placeholder-1/"" "">"" msgid ""Basic quota configuration"" msgstr ""Configurations basic des quotas "" msgid ""Launch an instance from a volume"" msgstr ""Lancer une instance d'un volume"" msgid ""Task"" msgstr ""Tâche"" msgid ""List volumes:"" msgstr ""Listez les volumes:"" msgid ""Create volume from image and boot instance"" msgstr ""Créez un volume depuis une image et démarrer une instance."" msgid ""List the available images:"" msgstr ""Lister les images disponibles:"" msgid ""List the available flavors:"" msgstr ""Listez les types d'instances disponibles:"" msgid """" ""To create a bootable volume from an image and launch an instance from this "" ""volume, use the <parameter>--block-device</parameter> parameter."" msgstr """" ""Pour créer un volume démarrable depuis une image et pour lancer une instance "" ""depuis ce volume, utilisez le paramètre <parameter>--block-device</"" ""parameter>."" msgid ""FLAVOR"" msgstr ""TYPE D'INSTANCE"" msgid ""SOURCE"" msgstr ""SOURCE"" msgid ""ID"" msgstr ""ID"" msgid ""SIZE"" msgstr ""TAILLE"" msgid ""NAME"" msgstr ""NOM"" msgid ""The parameters are:"" msgstr ""Les paramètres sont:"" msgid """" ""<parameter>--block-device</parameter> source=<replaceable>SOURCE</"" ""replaceable>,id=<replaceable>ID</replaceable>,dest=<replaceable>DEST</"" ""replaceable>,size=<replaceable>SIZE</replaceable>,"" ""shutdown=<replaceable>PRESERVE</replaceable>,bootindex=<replaceable>INDEX</"" ""replaceable>"" msgstr """" ""<parameter>--block-device</parameter> source=<replaceable>SOURCE</"" ""replaceable>,id=<replaceable>ID</replaceable>,dest=<replaceable>DEST</"" ""replaceable>,size=<replaceable>SIZE</replaceable>,"" ""shutdown=<replaceable>PRESERVE</replaceable>,bootindex=<replaceable>INDEX</"" ""replaceable>"" msgid """" ""Create a bootable volume from an image, before the instance boots. The "" ""volume is not deleted when the instance is terminated:"" msgstr """" ""Créez un volume démarrable depuis une image avant le lancement de "" ""l'instance. Le volume n'est pas supprimé quand l'instance est terminée:"" msgid """" ""List volumes to see the bootable volume and its attached "" ""<literal>myInstanceFromVolume</literal> instance:"" msgstr """" ""Listez les volumes pour voir l'instance démarrable et son instance "" ""<literal>myInstanceFromVolume</literal> jointe:"" msgid ""IMAGE_ID"" msgstr ""IMAGE_ID"" msgid ""Log in to the dashboard"" msgstr ""Connectez-vous au tableau de bord"" msgid """" ""On the <guilabel>Log In</guilabel> page, enter your user name and password, "" ""and click <guibutton>Sign In</guibutton>."" msgstr """" ""Au page <guilabel>Log In</guilabel>, entrez votre nom d'utilisateur et mot "" ""de passe, et cliquez sur <guibutton>Sign In</guibutton>."" msgid ""<placeholder-1/> tab"" msgstr ""<placeholder-1/> tab"" msgid ""Instances"" msgstr ""Instances"" msgid ""Volumes"" msgstr ""Volumes"" msgid ""View, create, edit, and delete volumes."" msgstr ""Voir, créer, éditer et supprimer des columes."" msgid ""Volume Snapshots"" msgstr ""Instantanés du volume"" msgid ""Images"" msgstr ""Images"" msgid ""Access &amp; Security"" msgstr ""Accès et Sécurité"" msgid ""Security Groups"" msgstr ""Groupes de sécurité"" msgid ""Key Pairs"" msgstr ""Paires de Clefs"" msgid ""Floating IPs"" msgstr ""IP flottantes"" msgid ""API Access"" msgstr ""Accès API"" msgid ""View API endpoints."" msgstr ""Voir des points de terminaison d'API."" msgid ""Network"" msgstr ""Réseau"" msgid ""Network Topology"" msgstr ""Topologie du Réseau"" msgid ""View the network topology."" msgstr ""Voir la topologie du réseau"" msgid ""Networks"" msgstr ""Réseaux"" msgid ""Create and manage public and private networks."" msgstr ""Créer et gérer les réseaux publics et privés."" msgid ""Routers"" msgstr ""Routeurs"" msgid ""Create and manage subnets."" msgstr ""Créez et gérez des sous-réseaux."" msgid ""Object Store"" msgstr ""Stockage d'objet"" msgid ""Containers"" msgstr ""Conteneurs"" msgid ""Stacks"" msgstr ""Stacks"" msgid ""Admin tab"" msgstr ""Onglet d'administration"" msgid ""System Panel"" msgstr ""Gestion Système"" msgid ""Resource Usage"" msgstr ""Usage de ressource"" msgid ""Daily Report"" msgstr ""Rapport journalier"" msgid ""View the daily report."" msgstr ""Voir la rapport journalier."" msgid ""Stats"" msgstr ""Stats"" msgid ""Hypervisors"" msgstr ""Hyperviseurs"" msgid ""View the hypervisor summary."" msgstr ""Voir le résumé d'hyperviseur."" msgid ""Host Aggregates"" msgstr ""Agrégations d'hôte."" msgid ""System Info"" msgstr ""Informations Système"" msgid ""Services"" msgstr ""Services"" msgid ""View a list of the services."" msgstr ""Voir une liste de toutes les services."" msgid ""Compute Services"" msgstr ""Services de calcul"" msgid ""View a list of all Compute services."" msgstr ""Voir une liste de toutes les services calcul."" msgid ""Network Agents"" msgstr ""Agents réseau."" msgid ""View the network agents."" msgstr ""Voir les agents réseau."" msgid ""Default Quotas"" msgstr ""Quotas par défaut"" msgid ""Identity Panel"" msgstr ""Gestion des Identités"" msgid ""Projects"" msgstr ""Projets"" msgid ""Users"" msgstr ""Utilisateurs"" msgid ""Manage volumes"" msgstr ""Gérer les volumes"" msgid ""volumeID"" msgstr ""volumeID"" msgid ""destinationHost"" msgstr ""destinationHost"" msgid ""Create a volume"" msgstr ""Créer un volume"" msgid """" ""To verify that your volume was created successfully, list the available "" ""volumes:"" msgstr """" ""Pour vérifier que votre volume a été bien créé, listez les volumes "" ""disponibles:"" msgid ""Attach a volume to an instance"" msgstr ""Joindre un volume à l'instance"" msgid ""Note the ID of your volume."" msgstr ""Notez l'identité de votre volume."" msgid ""Note that the volume is now available."" msgstr ""Notez que le volume est maintenant disponible."" msgid ""Delete a volume"" msgstr ""Supprimez un volume"" msgid """" ""When the volume is fully deleted, it disappears from the list of volumes:"" msgstr """" ""Quand le volume a été complètement supprimé, il ne s'affiche plus dans la "" ""liste des volumes: "" msgid ""Transfer a volume"" msgstr ""Transférer un volume"" msgid ""VOLUME_ID"" msgstr ""ID_VOLUME"" msgid ""transferID"" msgstr ""transferID"" msgid ""authKey"" msgstr ""authKey"" msgid ""Delete the volume:"" msgstr ""Supprimez le volume:"" msgid ""CLIENT_NAME"" msgstr ""CLIENT_NAME"" msgid ""COMMAND_NAME"" msgstr ""COMMAND_NAME"" msgid ""Add security group and rules"" msgstr ""Ajouter un groupe de sécurité et des règles"" msgid """" ""The following procedure shows you how to add security groups and add rules "" ""to the default security group."" msgstr """" ""Le procédure suivant vous montre comment ajouter les groupes de sécurité et "" ""ajouter des règles au groupe de sécurité par défaut."" msgid ""Add or delete a security group"" msgstr ""Ajouter ou supprimer un groupe de sécurité"" msgid """" ""All the traffic originated by the instances (outbound traffic) is allowed"" msgstr ""Tout trafic créé par des instances (trafic sortant) est autorisé."" msgid ""All the traffic destined to instances (inbound traffic) is denied"" msgstr ""Tout trafic à destination des instances (trafic entrant) est refusé."" msgid ""All the instances inside the group are allowed to talk to each other"" msgstr ""Tous les instances dans le groupe peuvent communiquer entre elles. "" msgid """" ""You can add extra rules into the default security group for handling the "" ""egress traffic. Rules are ingress only at this time."" msgstr """" ""Vous pouvez ajouter des règles supplémentaires dans le groupe de sécurité "" ""par défaut afin de gérer le trafic de sortie. Les règles concerne le trafic "" ""d'entrée uniquement à ce stade-là."" msgid ""Modify security group rules"" msgstr ""Modifier les règles du groupe de sécurité"" msgid ""Port at start of range."" msgstr ""Port au début de la gamme."" msgid ""Port at end of range."" msgstr ""Port à la fin de la gamme."" msgid ""The CIDR notation"" msgstr ""La notation CIDR"" ",94,5116
openstack%2Fapi-site~master~Ice9b496ba90eff145444fec4e5f3296b8a34bd57,openstack/api-site,master,Ice9b496ba90eff145444fec4e5f3296b8a34bd57,Imported Translations from Transifex,MERGED,2015-05-21 06:02:57.000000000,2015-05-21 06:35:22.000000000,2015-05-21 06:35:22.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-05-21 06:02:57.000000000', 'files': ['api-quick-start/locale/pt_BR.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/716784a981f3e4f672dba0801948e4d08424a088', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ice9b496ba90eff145444fec4e5f3296b8a34bd57\n'}]",0,184715,716784a981f3e4f672dba0801948e4d08424a088,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ice9b496ba90eff145444fec4e5f3296b8a34bd57
",git fetch https://review.opendev.org/openstack/api-site refs/changes/15/184715/1 && git format-patch -1 --stdout FETCH_HEAD,['api-quick-start/locale/pt_BR.po'],1,716784a981f3e4f672dba0801948e4d08424a088,transifex/translations,"# # Translators: # Gabriel Wainer, 2013 # Guteemebrg Nunes <gutemhc@gmail.com>, 2015 # Josemar Muller Lohn <j@lo.hn>, 2013 # Luís Eduardo Tenório Silva <eduardovansilva@gmail.com>, 2014 # Sandro Porciuncula Rodrigues <sandro@conacloud.com.br>, 2015 # Welkson Renny de Medeiros <welkson@gmail.com>, 2012 msgid """" msgstr """" ""Project-Id-Version: OpenStack Manuals\n"" ""POT-Creation-Date: 2015-05-21 00:29+0000\n"" ""PO-Revision-Date: 2015-05-21 00:57+0000\n"" ""Last-Translator: Guteemebrg Nunes <gutemhc@gmail.com>\n"" ""Language-Team: Portuguese (Brazil) (http://www.transifex.com/projects/p/"" ""openstack-manuals-i18n/language/pt_BR/)\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Language: pt_BR\n"" ""Plural-Forms: nplurals=2; plural=(n > 1);\n"" msgid ""OpenStack command-line clients"" msgstr ""Cliente de linha de comando do OpenStack"" msgid """" ""For scripting work, you can use a command-line client like the <systemitem "" ""role=\""client\"">python-novaclient</systemitem> client. This client enables "" ""you to use the Compute API through a command-line interface."" msgstr """" ""Para trabalhar com stripts, você pode usar um cliente de linha de comando "" ""como o <systemitem role=\""client\"">python-novaclient</systemitem>. Esse "" ""cliente permite você usar a Compute API através de uma interface de linha de "" ""comando."" msgid """" ""For information about the command-line clients, see <link href=\""http://docs."" ""openstack.org/cli-reference/content/\""><citetitle>OpenStack Command-Line "" ""Interface Reference</citetitle></link>."" msgstr """" ""Para informações sobre o cliente de linha de comando, veja <link href="" ""\""http://docs.openstack.org/cli-reference/content/\""><citetitle>Referência "" ""da Interface de Linha de Comando do OpenStack</citetitle></link>."" msgid ""Install the clients"" msgstr ""Instalação do cliente"" msgid """" ""Use <placeholder-1/> to install the OpenStack clients on a Mac OS X or Linux "" ""system. It is easy and ensures that you get the latest version of the client "" ""from the <link href=\""http://pypi.python.org/pypi\"">Python Package Index</"" ""link>. Also, <placeholder-2/> lets you update or remove a package."" msgstr """" ""Use o <placeholder-1/> para instalar o cliente OpenStack em um Mac OS ou "" ""sistema Linux. É fácil e garante que você obtenha a versão mais recente do "" ""cliente a partir de <link href=\""http://pypi.python.org/pypi\"">Python "" ""Package Index</link>. <placeholder-2/> também permite atualizar ou remover "" ""um pacote."" msgid ""You must install each client separately."" msgstr ""Você deve instalar cada cliente separadamente."" msgid ""Run this command to install or update a client package:"" msgstr ""Execute esse comando para instalar ou atualizar um pacote do cliente:"" msgid ""PROJECT"" msgstr ""PROJETO"" msgid ""Where <replaceable>PROJECT</replaceable> is the project name."" msgstr ""Onde <replaceable>PROJECT</replaceable> é o nome do projeto."" msgid ""For example, to install the <placeholder-1/> client, run this command:"" msgstr """" ""Por exemplo, para instalar o cliente <placeholder-1/>, execute esse comando:"" msgid ""To update the <placeholder-1/> client, run this command:"" msgstr ""Para atualizar o cliente <placeholder-1/>, execute esse comando:"" msgid ""To remove the <placeholder-1/> client, run this command:"" msgstr ""Para remover o cliente <placeholder-1/>, execute esse comando:"" msgid """" ""Before you can issue client commands, you must download and source the "" ""<filename>openrc</filename> file to set environment variables."" msgstr """" ""Antes que você possa executar comandos no cliente, você deve baixar e "" ""acrescentar/substituir o arquivo <filename>openrc</filename> para definir as "" ""variáveis de ambiente."" msgid """" ""For complete information about the OpenStack clients, including how to "" ""source the <filename>openrc</filename> file, see <link href=\""http://docs."" ""openstack.org/user-guide/content/\""><citetitle>OpenStack End User Guide</"" ""citetitle></link>, <link href=\""http://docs.openstack.org/user-guide-admin/"" ""content/\""><citetitle>OpenStack Admin User Guide</citetitle></link>, and "" ""<link href=\""http://docs.openstack.org/cli-reference/content/"" ""\""><citetitle>OpenStack Command-Line Interface Reference</citetitle></link>."" msgstr """" ""Para informações completas sobre o cliente OpenStack, inclueindo como "" ""modificar o arquivo <filename>openrc</filename>, veja <link href=\""http://"" ""docs.openstack.org/user-guide/content/\""><citetitle>Guia do usuário do "" ""OpenStack</citetitle></link>, <link href=\""http://docs.openstack.org/user-"" ""guide-admin/content/\""><citetitle>Guia do Administrador OpenStack</"" ""citetitle></link>, e <link href=\""http://docs.openstack.org/cli-reference/"" ""content/\""><citetitle>Referência da Interface de Linha de Comando do "" ""OpenStack</citetitle></link>."" msgid ""Launch an instance"" msgstr ""Lançando uma instância"" msgid """" ""To launch instances, you must choose a name, an image, and a flavor for your "" ""instance."" msgstr """" ""Para disparar uma instância, você precisa escolher um nome, uma imagem e um "" ""flavor para sua instância."" msgid """" ""To list available images, call the Compute API through the <placeholder-1/> "" ""client, as follows:"" msgstr """" ""Para listar as imagens disponíveis, chame a Compute API através do "" ""<placeholder-1/> cliente, conforme segue:"" msgid ""To list flavors, run this command:"" msgstr ""Para listar os flavors, execute este comando:"" msgid ""To launch an instance, note the IDs of your desired image and flavor."" msgstr """" ""Para iniciar uma instancia, observe os IDs da sua imagem desejada e flavor."" msgid """" ""To launch an instance named <literal>my_instance</literal>, run the "" ""<placeholder-1/> command with the image and flavor IDs and the server name, "" ""as follows:"" msgstr """" ""Para iniciar uma instância de nome <literal>my_instance</literal>, execute o "" ""<placeholder-1/> comando com o ID da imagem e do flavor e o nome do "" ""servidor, como segue:"" msgid ""Use the <placeholder-1/> command to view your server:"" msgstr ""Use o <placeholder-1/> comando para visualizar seu servidor:"" msgid """" ""To view details for a specified server, use the <placeholder-1/> command. "" ""Include the ID of the server:"" msgstr """" ""Para ver detalhes de um servidor específico, use o comando <placeholder-1/>. "" ""Inclua o ID do servidor:"" msgid ""OpenStack API Quick Start"" msgstr ""OpenStack API - Início rápido"" msgid ""To begin sending API requests, use one of the following methods:"" msgstr ""Para começar a enviar API requests, use um dos seguintes métodos:"" msgid ""cURL"" msgstr ""cURL"" msgid """" ""A command-line tool that lets you send HTTP requests and receive responses. "" ""See <xref linkend=\""Compute_API_Quick_Start\""/>."" msgstr """" ""Uma ferramenta para terminal que permite que você mande requisições HTTP e "" ""receba as respsotas. Veja <xref linkend=\""Compute_API_Quick_Start\""/>."" msgid ""REST clients"" msgstr ""Clientes REST"" msgid ""OpenStack Python Software Development Kit (SDK)"" msgstr ""Kit de desenvolvimento de software Python para OpenStack (SDK)"" msgid ""OpenStack APIs"" msgstr ""APIs do OpenStack"" msgid ""Authentication and API request workflow"" msgstr ""Fluxo de Autenticação e Requisição da API"" msgid ""Parameter"" msgstr ""Parâmetro"" msgid ""Type"" msgstr ""Tipo"" msgid ""Description"" msgstr ""Descrição"" msgid ""username (required)"" msgstr ""nome de usuário (obrigatório)"" msgid ""xsd:string"" msgstr ""xsd:string"" msgid """" ""The user name. If you do not provide a user name and password, you must "" ""provide a token."" msgstr """" ""O nome de usuário. Se você não fornecer um nome de usuário e senha, você "" ""precisa fornecer um token."" msgid ""password (required)"" msgstr ""senha (obrigatório)"" msgid ""The password for the user."" msgstr ""A senha para o usuário."" msgid ""tenantName (Optional)"" msgstr ""tenantName (Opcional)"" msgid ""tenantId"" msgstr ""tenantId"" msgid ""tenantName"" msgstr ""tenantName"" msgid ""400"" msgstr ""400"" msgid ""tenantId (Optional)"" msgstr ""tenantId (Optional)"" msgid ""capi:UUID"" msgstr ""capi:UUID"" msgid ""token (Optional)"" msgstr ""token (Opcional)"" msgid """" ""A token. If you do not provide a token, you must provide a user name and "" ""password."" msgstr """" ""Um token. Se você não fornecer um token, precisa fornecer um usuário e senha."" msgid ""If the request succeeds, the server returns an authentication token."" msgstr """" ""Se a requisição for bem sucedida, o servidor retorna um token de "" ""autenticação."" msgid ""Authenticate"" msgstr ""Autenticar"" msgid ""The following example shows a successful response:"" msgstr ""O exemplo que segue mostra uma resposta bem sucedida."" msgid """" ""If you do not know your tenant name or ID, you can send an authentication "" ""request with an empty tenantName, as follows:"" msgstr """" ""Se você não conhece o nome do seu tenant ou ID, você pode enviar uma "" ""requisição de autenticação com um tenantName vazio, como segue:"" msgid ""Send API requests"" msgstr ""Manda requisição de API"" msgid ""Use the Compute API to list flavors, as follows:"" msgstr ""Use o Compute API para listar os flavors, como segue:"" msgid ""token"" msgstr ""token"" msgid ""tenant_id"" msgstr ""tenant_id"" msgid ""Use the Compute API to list images, as follows:"" msgstr ""Use o Compute API para listar imagens, como segue:"" msgid ""Use the Compute API to list servers, as follows:"" msgstr ""Use o Compute API para listar imagens, como segue:"" #. Put one translator per line, in the form of NAME <EMAIL>, YEAR1, YEAR2 msgid ""translator-credits"" msgstr ""Créditos da tradução"" ",,272,0
openstack%2Fopenstack-manuals~master~Ice7dd127a12ce453454808043af6ba34996e3a21,openstack/openstack-manuals,master,Ice7dd127a12ce453454808043af6ba34996e3a21,Change GB to GiB for volume creation,MERGED,2015-05-20 02:52:20.000000000,2015-05-21 06:19:29.000000000,2015-05-21 06:19:28.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 10705}]","[{'number': 1, 'created': '2015-05-20 02:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f6b3074cab55966bcebebe9f4a9df95dc0a90d01', 'message': 'Change GB to GiB for volume creation\n\nChange-Id: Ice7dd127a12ce453454808043af6ba34996e3a21\nCloses-Bug: #1456631\n'}, {'number': 2, 'created': '2015-05-21 06:09:30.000000000', 'files': ['doc/common-rst/cli_manage_volumes.rst', 'doc/user-guide/source/dashboard_manage_volumes.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9f3d13715a30746a495ee4abaf52c0854e9ecae3', 'message': 'Change GB to GiB for volume creation\n\nChange-Id: Ice7dd127a12ce453454808043af6ba34996e3a21\nCloses-Bug: #1456631\n'}]",0,184406,9f3d13715a30746a495ee4abaf52c0854e9ecae3,13,5,2,2448,,,0,"Change GB to GiB for volume creation

Change-Id: Ice7dd127a12ce453454808043af6ba34996e3a21
Closes-Bug: #1456631
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/06/184406/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/section_cli_cinder_manage_volumes.xml', 'doc/common-rst/cli_manage_volumes.rst', 'doc/user-guide/source/dashboard_manage_volumes.rst']",3,f6b3074cab55966bcebebe9f4a9df95dc0a90d01,bug/1456631, :guilabel:`Size (GB)`: The size of the volume in gibibytes (GiB)., :guilabel:`Size (GB)`: The size of the volume in gigabytes.,3,3
openstack%2Fopenstack-manuals~master~I32cabf9be5a8c3ea78149c301b07ce79ce2d40b6,openstack/openstack-manuals,master,I32cabf9be5a8c3ea78149c301b07ce79ce2d40b6,Adds command to list samples for l3 meter-labels,MERGED,2015-04-19 07:56:15.000000000,2015-05-21 06:19:11.000000000,2015-05-21 06:19:10.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 14962}, {'_account_id': 15279}]","[{'number': 1, 'created': '2015-04-19 07:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/13bbfbb1b80443148301e2a68b1a79da589ce309', 'message': 'Adds command to list samples for l3 meter-labels\n\nAdds the command to list values for meter-labels created using a set of snmp measurements.\n\nChange-Id: I32cabf9be5a8c3ea78149c301b07ce79ce2d40b6\nCloses-bug: #1318604\n'}, {'number': 2, 'created': '2015-04-21 06:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ebc299661630739303c175416a21d23b063a3a47', 'message': 'Adds command to list samples for l3 meter-labels\n\nAdds the command to list values for meter-labels created using a set of snmp measurements.\n\nChange-Id: I32cabf9be5a8c3ea78149c301b07ce79ce2d40b6\nCloses-bug: #1318604\n'}, {'number': 3, 'created': '2015-04-21 08:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/eaeec7d7ece9ca093b035f3a00ba0079230918bc', 'message': 'Adds command to list samples for l3 meter-labels\n\nAdds the command to list values for meter-labels created using a set of snmp measurements.\n\nCloses-bug: #1318604\nChange-Id: I32cabf9be5a8c3ea78149c301b07ce79ce2d40b6\n'}, {'number': 4, 'created': '2015-05-19 00:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/012c3cb3d49c11dd6e75a770e87c8c2156feaebc', 'message': 'Adds command to list samples for l3 meter-labels\n\nAdds the command to list values for meter-labels created using a set of snmp measurements.\n\nCloses-bug: #1318604\nChange-Id: I32cabf9be5a8c3ea78149c301b07ce79ce2d40b6\n'}, {'number': 5, 'created': '2015-05-21 01:24:43.000000000', 'files': ['doc/admin-guide-cloud/networking/section_networking_adv_features.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f46c719c44e0e9e3a2f2d37c318b5d83f0a21a64', 'message': 'Adds command to list samples for l3 meter-labels\n\nAdds the command to list values for meter-labels created using a set of snmp measurements.\n\nCloses-bug: #1318604\nChange-Id: I32cabf9be5a8c3ea78149c301b07ce79ce2d40b6\n'}]",6,175198,f46c719c44e0e9e3a2f2d37c318b5d83f0a21a64,27,8,5,14474,,,0,"Adds command to list samples for l3 meter-labels

Adds the command to list values for meter-labels created using a set of snmp measurements.

Closes-bug: #1318604
Change-Id: I32cabf9be5a8c3ea78149c301b07ce79ce2d40b6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/98/175198/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/networking/section_networking_adv_features.xml'],1,13bbfbb1b80443148301e2a68b1a79da589ce309,bug/1318604, <tr> <td>Lists the value of created meter-label.</td> <td> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m <replaceable>snmp_measurement</replaceable></userinput</screen> <para>For example:</para> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m hardware.cpu.load.1min</userinput</screen> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m hardware.cpu.load.5min</userinput</screen> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m hardware.cpu.load.15min</userinput</screen> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m hardware.disk.size.total</userinput</screen> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m hardware.disk.size.used</userinput</screen> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m hardware.network.bandwidth.bytes</userinput</screen> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m hardware.network.incoming.bytes</userinput</screen> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m hardware.network.outgoing.bytes</userinput</screen> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m hardware.network.outgoing.errors</userinput</screen> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m hardware.memory.total</userinput</screen> <screen><prompt>$</prompt> <userinput>ceilometer sample-list -m hardware.memory.used</userinput</screen> </td> </tr>,,40,0
openstack%2Fpuppet-cinder~master~Iac59d79d6c12ed8e5e3d23d50d53f43b63ba6f89,openstack/puppet-cinder,master,Iac59d79d6c12ed8e5e3d23d50d53f43b63ba6f89,Synchronize LICENSE file with OpenStack projects,MERGED,2015-05-19 23:38:37.000000000,2015-05-21 06:15:20.000000000,2015-05-21 06:15:19.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-05-19 23:38:37.000000000', 'files': ['LICENSE'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/24bb8f7b326eec428907fb104dd56e4240b5a5d4', 'message': 'Synchronize LICENSE file with OpenStack projects\n\nUpdate LICENSE file to be the same as other OpenStack projects.\n\nChange-Id: Iac59d79d6c12ed8e5e3d23d50d53f43b63ba6f89\nCloses-bug: #1241725\n'}]",0,184354,24bb8f7b326eec428907fb104dd56e4240b5a5d4,8,3,1,7155,,,0,"Synchronize LICENSE file with OpenStack projects

Update LICENSE file to be the same as other OpenStack projects.

Change-Id: Iac59d79d6c12ed8e5e3d23d50d53f43b63ba6f89
Closes-bug: #1241725
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/54/184354/1 && git format-patch -1 --stdout FETCH_HEAD,['LICENSE'],1,24bb8f7b326eec428907fb104dd56e4240b5a5d4,1241725,"Copyright 2012 OpenStack Foundation Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."," Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. ""License"" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. ""Licensor"" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. ""Legal Entity"" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, ""control"" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. ""You"" (or ""Your"") shall mean an individual or Legal Entity exercising permissions granted by this License. ""Source"" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. ""Object"" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. ""Work"" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). ""Derivative Works"" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. ""Contribution"" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, ""submitted"" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as ""Not a Contribution."" ""Contributor"" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a ""NOTICE"" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets ""[]"" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same ""printed page"" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",10,198
openstack%2Fgrenade~master~Ic8e1f231c9886a181029526ab5e291ff212781e9,openstack/grenade,master,Ic8e1f231c9886a181029526ab5e291ff212781e9,Switch cinder to use lioadm instead of tgt,ABANDONED,2015-03-25 17:13:05.000000000,2015-05-21 06:06:48.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 5803}]","[{'number': 1, 'created': '2015-03-25 17:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/d0f86b9a1e275e4fbb9882aad7289dbba02938fc', 'message': 'Switch cinder to use lioadm instead of tgt\n\n* stop tgtd\n* install helper dependency\n* change config\n\nRelated-change: Ia54c59914c1d3ff2ef5f00ecf819426bc448d0a9\nChange-Id: Ic8e1f231c9886a181029526ab5e291ff212781e9\n'}, {'number': 2, 'created': '2015-03-25 18:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/2e41e8bf6a6174a846efe92e54bb1aea39c269ed', 'message': 'Switch cinder to use lioadm instead of tgt\n\n* stop tgtd\n* install helper dependency\n* change config\n\nRelated-change: Ia54c59914c1d3ff2ef5f00ecf819426bc448d0a9\nChange-Id: Ic8e1f231c9886a181029526ab5e291ff212781e9\n'}, {'number': 3, 'created': '2015-03-26 06:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/128bb57905df93f2d89273ac661d0c258ffc7fc5', 'message': 'Switch cinder to use lioadm instead of tgt\n\n* install the lioadm helper dependency\n* change the config to use lioadm\n\nRelated-change: Ia54c59914c1d3ff2ef5f00ecf819426bc448d0a9\nChange-Id: Ic8e1f231c9886a181029526ab5e291ff212781e9\n'}, {'number': 4, 'created': '2015-03-26 08:40:02.000000000', 'files': ['upgrade-cinder'], 'web_link': 'https://opendev.org/openstack/grenade/commit/1bca20ecbeff29f6b0e28c08091ee6077719be7e', 'message': 'Switch cinder to use lioadm instead of tgt\n\n* install the lioadm helper dependency\n* change the config to use lioadm\n* stop tgt if it started be the `TARGET` devstack\n\nRelated-change: Ia54c59914c1d3ff2ef5f00ecf819426bc448d0a9\nChange-Id: Ic8e1f231c9886a181029526ab5e291ff212781e9\n'}]",2,167698,1bca20ecbeff29f6b0e28c08091ee6077719be7e,14,5,4,5803,,,0,"Switch cinder to use lioadm instead of tgt

* install the lioadm helper dependency
* change the config to use lioadm
* stop tgt if it started be the `TARGET` devstack

Related-change: Ia54c59914c1d3ff2ef5f00ecf819426bc448d0a9
Change-Id: Ic8e1f231c9886a181029526ab5e291ff212781e9
",git fetch https://review.opendev.org/openstack/grenade refs/changes/98/167698/2 && git format-patch -1 --stdout FETCH_HEAD,['upgrade-cinder'],1,d0f86b9a1e275e4fbb9882aad7289dbba02938fc,tgt-to-lio,# switch to lioadm if is_ubuntu; then is_package_installed tgt && stop_service tgt else is_package_installed scsi-target-utils && stop_service tgtd fi install_package python-rtslib iniset $CINDER_CONF DEFAULT iscsi_helper lioadm iniset $CINDER_CONF lvmdriver-1 iscsi_helper lioadm ,,13,0
openstack%2Fapp-catalog~master~Ife54f36000183063175a41c4e02f37e176888ea9,openstack/app-catalog,master,Ife54f36000183063175a41c4e02f37e176888ea9,Add Heat template for Lattice.,MERGED,2015-05-20 14:12:42.000000000,2015-05-21 05:27:48.000000000,2015-05-21 05:27:41.000000000,"[{'_account_id': 3}, {'_account_id': 9788}, {'_account_id': 10068}, {'_account_id': 13900}, {'_account_id': 16145}]","[{'number': 1, 'created': '2015-05-20 14:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/a70448ef3737807d94d7c246ebbb379f2e02e83c', 'message': 'Add Heat template for Lattice. (http://lattice.cf/docs)\n\nChange-Id: Ife54f36000183063175a41c4e02f37e176888ea9\nSigned-off-by: LaynePeng <appamail@hotmail.com>\n'}, {'number': 2, 'created': '2015-05-20 15:16:00.000000000', 'files': ['openstack_catalog/web/static/heat_templates.yaml'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/5a1e9c1a0f2624902d1fb9ed3bbff774c305fef8', 'message': 'Add Heat template for Lattice.\n\nChange-Id: Ife54f36000183063175a41c4e02f37e176888ea9\nSigned-off-by: LaynePeng <appamail@hotmail.com>\n'}]",4,184503,5a1e9c1a0f2624902d1fb9ed3bbff774c305fef8,15,5,2,16447,,,0,"Add Heat template for Lattice.

Change-Id: Ife54f36000183063175a41c4e02f37e176888ea9
Signed-off-by: LaynePeng <appamail@hotmail.com>
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/03/184503/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/web/static/heat_templates.yaml'],1,a70448ef3737807d94d7c246ebbb379f2e02e83c,," - name: Lattice provided_by: name: Layne Peng href: mailto:appamail@hotmail.com company: EMC description: > Lattice is an open source project for running containerized workloads on a cluster (http://lattice.cf/docs ). Lattice bundles up http load-balancing, a cluster scheduler, log aggregation/streaming and health management into an easy-to-deploy and easy-to-use package. This is a Lattice template for deploying a Lattice cluster on a Ubuntu Cloud VM. More details on usage and options can be found at: https://github.com/LaynePeng/heat-lattice release: - Icehouse - Juno - Kilo format: HOT supported_by: Layne Peng license: Apache 2.0 attributes: url: https://github.com/LaynePeng/heat-lattice/blob/master/lattice.yaml",,19,0
openstack%2Ftripleo-incubator~master~Ib150de715d6f09c57f920fa3755675718a2e76d1,openstack/tripleo-incubator,master,Ib150de715d6f09c57f920fa3755675718a2e76d1,Switch to new setup-flavors,ABANDONED,2014-10-29 05:11:59.000000000,2015-05-21 05:14:40.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6348}, {'_account_id': 8449}, {'_account_id': 9369}, {'_account_id': 9453}, {'_account_id': 10206}, {'_account_id': 12459}]","[{'number': 1, 'created': '2014-10-29 05:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/9fd6ed907e14e6fd62377b33c5443352dd0c77ec', 'message': ""Switch to new setup-flavors\n\nSwitch to the new setup-flavors utility provided by os-cloud-config.\nThis doesn't remove any existing script from this repository, but\nreplaces functionality in setup-baremetal.\n\nThis also removes the hardcoded 'baremetal' as the flavor name for\nthe undercloud and overcloud scripts, since the scripts will now\nprogrammatically work out the flavor name, and raise an error if\nthere is more than one.\n\nChange-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1\n""}, {'number': 2, 'created': '2014-10-30 01:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f3c06ace104343bde4d66b1c0e138f695623cb02', 'message': ""Switch to new setup-flavors\n\nSwitch to the new setup-flavors utility provided by os-cloud-config.\nThis doesn't remove any existing script from this repository, but\nreplaces functionality in setup-baremetal.\n\nThis also removes the hardcoded 'baremetal' as the flavor name for\nthe undercloud and overcloud scripts, since the scripts will now\nprogrammatically work out the flavor name, and raise an error if\nthere is more than one.\n\nChange-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1\n""}, {'number': 3, 'created': '2014-11-03 11:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/cd218ccdcfdfac28ad348b0392c8951928c30ec5', 'message': ""Switch to new setup-flavors\n\nSwitch to the new setup-flavors utility provided by os-cloud-config.\nThis doesn't remove any existing script from this repository, but\nreplaces functionality in setup-baremetal.\n\nThis also removes the hardcoded 'baremetal' as the flavor name for\nthe undercloud and overcloud scripts, since the scripts will now\nprogrammatically work out the flavor name, and raise an error if\nthere is more than one.\n\nChange-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1\n""}, {'number': 4, 'created': '2014-11-12 02:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/0652cf5cae3b3ccb15a4a405b88d2888e29aa278', 'message': ""Switch to new setup-flavors\n\nSwitch to the new setup-flavors utility provided by os-cloud-config.\nThis doesn't remove any existing script from this repository, but\nreplaces functionality in setup-baremetal.\n\nThis also removes the hardcoded 'baremetal' as the flavor name for\nthe undercloud and overcloud scripts, since the scripts will now\nprogrammatically work out the flavor name, and raise an error if\nthere is more than one.\n\nChange-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1\n""}, {'number': 5, 'created': '2014-11-17 02:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f52616838e6c6a0c794b6fe319ec762f251588f2', 'message': ""Switch to new setup-flavors\n\nSwitch to the new setup-flavors utility provided by os-cloud-config.\nThis doesn't remove any existing script from this repository, but\nreplaces functionality in setup-baremetal.\n\nThis also removes the hardcoded 'baremetal' as the flavor name for\nthe undercloud and overcloud scripts, since the scripts will now\nprogrammatically work out the flavor name, and raise an error if\nthere is more than one.\n\nChange-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1\n""}, {'number': 6, 'created': '2014-11-27 04:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/d64de80f06bbe6730f6f7b826f6af87e8ebb8211', 'message': ""Switch to new setup-flavors\n\nSwitch to the new setup-flavors utility provided by os-cloud-config.\nThis doesn't remove any existing script from this repository, but\nreplaces functionality in setup-baremetal.\n\nThis also removes the hardcoded 'baremetal' as the flavor name for\nthe undercloud and overcloud scripts, since the scripts will now\nprogrammatically work out the flavor name, and raise an error if\nthere is more than one.\n\nChange-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1\n""}, {'number': 7, 'created': '2014-12-10 04:33:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ed822e0d3c20da0b74dcbf593dfc99aa27873b20', 'message': ""Switch to new setup-flavors\n\nSwitch to the new setup-flavors utility provided by os-cloud-config.\nThis doesn't remove any existing script from this repository, but\nreplaces functionality in setup-baremetal.\n\nThis also removes the hardcoded 'baremetal' as the flavor name for\nthe undercloud and overcloud scripts, since the scripts will now\nprogrammatically work out the flavor name, and raise an error if\nthere is more than one.\n\nChange-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1\n""}, {'number': 8, 'created': '2015-01-14 21:51:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/cc1b081433cae94600264c021801a6a60d5d2420', 'message': ""Switch to new setup-flavors\n\nSwitch to the new setup-flavors utility provided by os-cloud-config.\nThis doesn't remove any existing script from this repository, but\nreplaces functionality in setup-baremetal.\n\nThis also removes the hardcoded 'baremetal' as the flavor name for\nthe undercloud and overcloud scripts, since the scripts will now\nprogrammatically work out the flavor name, and raise an error if\nthere is more than one.\n\nChange-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1\n""}, {'number': 9, 'created': '2015-01-15 04:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/1faaa4fe6a78a055e162ff0b13fc60a71db54575', 'message': ""Switch to new setup-flavors\n\nSwitch to the new setup-flavors utility provided by os-cloud-config.\nThis doesn't remove any existing script from this repository, but\nreplaces functionality in setup-baremetal.\n\nThis also removes the hardcoded 'baremetal' as the flavor name for\nthe undercloud and overcloud scripts, since the scripts will now\nprogrammatically work out the flavor name, and raise an error if\nthere is more than one.\n\nChange-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1\n""}, {'number': 10, 'created': '2015-01-16 03:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/77f86cf38d2dfc56fffad40ad6a5903448b621f7', 'message': ""Switch to new setup-flavors\n\nSwitch to the new setup-flavors utility provided by os-cloud-config.\nThis doesn't remove any existing script from this repository, but\nreplaces functionality in setup-baremetal.\n\nThis also removes the hardcoded 'baremetal' as the flavor name for\nthe undercloud and overcloud scripts, since the scripts will now\nprogrammatically work out the flavor name, and raise an error if\nthere is more than one.\n\nChange-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1\n""}, {'number': 11, 'created': '2015-01-17 06:12:34.000000000', 'files': ['scripts/devtest_seed.sh', 'scripts/setup-clienttools', 'scripts/devtest_undercloud.sh', 'scripts/wait_for_hypervisor_stats', 'scripts/devtest_overcloud.sh', 'scripts/setup-baremetal'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/8a04b0dae5b074d5accb788828e5962c934361c1', 'message': ""Switch to new setup-flavors\n\nSwitch to the new setup-flavors utility provided by os-cloud-config.\nThis doesn't remove any existing script from this repository, but\nreplaces functionality in setup-baremetal.\n\nThis also removes the hardcoded 'baremetal' as the flavor name for\nthe undercloud and overcloud scripts, since the scripts will now\nprogrammatically work out the flavor name, and raise an error if\nthere is more than one.\n\nChange-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1\n""}]",40,131635,8a04b0dae5b074d5accb788828e5962c934361c1,79,8,11,9369,,,0,"Switch to new setup-flavors

Switch to the new setup-flavors utility provided by os-cloud-config.
This doesn't remove any existing script from this repository, but
replaces functionality in setup-baremetal.

This also removes the hardcoded 'baremetal' as the flavor name for
the undercloud and overcloud scripts, since the scripts will now
programmatically work out the flavor name, and raise an error if
there is more than one.

Change-Id: Ib150de715d6f09c57f920fa3755675718a2e76d1
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/35/131635/9 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/devtest_seed.sh', 'scripts/setup-clienttools', 'scripts/devtest_undercloud.sh', 'scripts/wait_for_hypervisor_stats', 'scripts/devtest_overcloud.sh', 'scripts/setup-baremetal']",6,9fd6ed907e14e6fd62377b33c5443352dd0c77ec,new-setup-flavors," echo "" --flavors -- A JSON file describing the flavors to create""FLAVORS_PATH= TEMP=$(getopt -o h -l help,service-host:,nodes:,flavors: -n $SCRIPT_NAME -- ""$@"") --flavors) FLAVORS_PATH=""$2""; shift 2 ;;if [ -z ""$FLAVORS_PATH"" ]; then setup-flavors -n <(echo $NODES) -k $deploy_kernel_id -r $deploy_ramdisk_id else setup-flavors -f $FLAVORS_PATH -k $deploy_kernel_id -r $deploy_ramdisk_id"," TEMP=$(getopt -o h -l help,service-host:,nodes: -n $SCRIPT_NAME -- ""$@"")function cleanup_flavor () { local FLAVOR_NAME=${1:?""cleanup_flavor requires a flavor name""} if nova flavor-show ""$FLAVOR_NAME"" &> /dev/null; then nova flavor-delete ""$FLAVOR_NAME"" fi } # While we can't mix hypervisors, having non-baremetal flavors will just # confuse things. cleanup_flavor 'm1.tiny' cleanup_flavor 'm1.small' cleanup_flavor 'm1.medium' cleanup_flavor 'm1.large' cleanup_flavor 'm1.xlarge' cleanup_flavor 'baremetal' # XXX(lifeless) this should be a loop making sure every node is represented # with a flavor. MEM=$(jq -r "".[0][\""memory\""]"" <<< $NODES) DISK=$(jq -r "".[0][\""disk\""]"" <<< $NODES) CPU=$(jq -r "".[0][\""cpu\""]"" <<< $NODES) ARCH=$(jq -r "".[0][\""arch\""]"" <<< $NODES) EPHEMERAL_DISK=$(( $DISK - $ROOT_DISK )) if (( $EPHEMERAL_DISK < 0 )); then echo ""Error: NODE_DISK - ROOT_DISK must be >= 0 to specify size of ephemeral disk"" exit 1 nova flavor-create baremetal \ --ephemeral $EPHEMERAL_DISK auto $MEM $ROOT_DISK $CPU nova flavor-key baremetal set ""cpu_arch""=""$ARCH"" \ ""baremetal:deploy_kernel_id""=""$deploy_kernel_id"" \ ""baremetal:deploy_ramdisk_id""=""$deploy_ramdisk_id""",56,53
openstack%2Fopenstack-manuals~master~I617043e1d4ff48a016f4e9f0f0e5647a02ca2102,openstack/openstack-manuals,master,I617043e1d4ff48a016f4e9f0f0e5647a02ca2102,Correct URL for hypervisor support matrix,MERGED,2015-05-21 01:16:01.000000000,2015-05-21 05:02:26.000000000,2015-05-21 05:02:24.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 9162}, {'_account_id': 14320}]","[{'number': 1, 'created': '2015-05-21 01:16:01.000000000', 'files': ['doc/config-reference/compute/section_compute-hypervisors.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ec07992e2183677ed56be95cfaa6e0c6d0f9c5e0', 'message': 'Correct URL for hypervisor support matrix\n\nChange-Id: I617043e1d4ff48a016f4e9f0f0e5647a02ca2102\nCloses-Bug: #1455699\n'}]",0,184669,ec07992e2183677ed56be95cfaa6e0c6d0f9c5e0,8,5,1,15279,,,0,"Correct URL for hypervisor support matrix

Change-Id: I617043e1d4ff48a016f4e9f0f0e5647a02ca2102
Closes-Bug: #1455699
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/69/184669/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_compute-hypervisors.xml'],1,ec07992e2183677ed56be95cfaa6e0c6d0f9c5e0,bug/1455699," xlink:href=""http://docs.openstack.org/developer/nova/support-matrix.html"" >http://docs.openstack.org/developer/nova/support-matrix.html</link> used to run Linux-based virtual machines.</para>"," xlink:href=""http://wiki.openstack.org/HypervisorSupportMatrix"" >http://wiki.openstack.org/HypervisorSupportMatrix</link> use to run Linux-based virtual machines.</para>",3,3
openstack%2Ftempest~master~Ia23cab169c46d631444399ab1edd93c43cfb7ef5,openstack/tempest,master,Ia23cab169c46d631444399ab1edd93c43cfb7ef5,To test bootable flag in a cinder volume,MERGED,2015-05-11 08:56:04.000000000,2015-05-21 05:00:00.000000000,2015-05-21 04:59:58.000000000,"[{'_account_id': 3}, {'_account_id': 5803}, {'_account_id': 6578}, {'_account_id': 6890}, {'_account_id': 7350}, {'_account_id': 7872}, {'_account_id': 8871}, {'_account_id': 10725}, {'_account_id': 11075}, {'_account_id': 15524}]","[{'number': 1, 'created': '2015-05-11 08:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1f476fec6b8399cc85b94dbdf61c0870c56cb18c', 'message': 'To test bootable flag in a cinder volume\nThis commit adds to cinder client bootable_volume capability , change\nthe bootable flag in a cinder volume to True or False.\nAnd a testcase for changing the bootable flag from true to false.\n\nChange-Id: Ia23cab169c46d631444399ab1edd93c43cfb7ef5\n'}, {'number': 2, 'created': '2015-05-11 09:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/73bd06378382e3ee5a07a8fe7d68efcb86e170fa', 'message': 'To test bootable flag in a cinder volume\n\nThis commit adds to cinder client a bootable capability\nsupported flags are  True or False.\nAnd a testcase for changing the bootable flag from true to false.\n\nChange-Id: Ia23cab169c46d631444399ab1edd93c43cfb7ef5\n'}, {'number': 3, 'created': '2015-05-11 09:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8c75404802397238ac7dfb33f56230c3da7dfa48', 'message': 'To test bootable flag in a cinder volume\n\nThis commit adds to cinder client a bootable capability\nsupported flags are  True or False.\nAnd a testcase for changing the bootable flag from true to false.\n\nChange-Id: Ia23cab169c46d631444399ab1edd93c43cfb7ef5\n'}, {'number': 4, 'created': '2015-05-11 17:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b97c001531b7568274cc6f57c5f0d4603470071b', 'message': 'To test bootable flag in a cinder volume\n\nThis commit adds to cinder client a bootable capability\nsupported flags are  True or False.\nAnd a testcase for changing the bootable flag from true to false.\n\nUpdate bootable volume is not supported on ice-house\nAdded new flag under config.py - to enbale this feature by request\nChange-Id: Ia23cab169c46d631444399ab1edd93c43cfb7ef5\n'}, {'number': 5, 'created': '2015-05-12 02:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cf2779a3097245b49c515dac9af22ac0d6ad504c', 'message': 'To test bootable flag in a cinder volume\n\nThis commit adds to cinder client a bootable capability\nsupported flags are  True or False.\nAnd a testcase for changing the bootable flag from true to false.\n\nUpdate bootable volume is not supported on ice-house\nAdded new flag under config.py - to enbale this feature by request\nChange-Id: Ia23cab169c46d631444399ab1edd93c43cfb7ef5\n'}, {'number': 6, 'created': '2015-05-13 05:37:16.000000000', 'files': ['tempest/services/volume/json/volumes_client.py', 'etc/tempest.conf.sample', 'tempest/config.py', 'tempest/api/volume/test_volumes_actions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8a657ae2529edf4099acb248c664a38a73d6177b', 'message': 'To test bootable flag in a cinder volume\n\nThis commit adds to cinder client a bootable capability\nsupported flags are  True or False.\nAnd a testcase for changing the bootable flag from true to false.\n\nUpdate bootable volume is not supported on icehouse\nAdded new flag under config.py - to enbale this feature by request\nChange-Id: Ia23cab169c46d631444399ab1edd93c43cfb7ef5\n'}]",4,181827,8a657ae2529edf4099acb248c664a38a73d6177b,31,10,6,11075,,,0,"To test bootable flag in a cinder volume

This commit adds to cinder client a bootable capability
supported flags are  True or False.
And a testcase for changing the bootable flag from true to false.

Update bootable volume is not supported on icehouse
Added new flag under config.py - to enbale this feature by request
Change-Id: Ia23cab169c46d631444399ab1edd93c43cfb7ef5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/27/181827/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/volume/json/volumes_client.py', 'tempest/api/volume/test_volumes_actions.py']",2,1f476fec6b8399cc85b94dbdf61c0870c56cb18c,," @test.idempotent_id('63e21b4c-0a0c-41f6-bfc3-7c2816815599') def test_volume_bootable(self): # Verify that a volume bootable flag is retrieved for bool_bootable in [True, False]: self.client.bootable_volume(self.volume['id'], bool_bootable) fetched_volume = self.client.show_volume(self.volume['id']) # Get Volume information bool_flag = self._is_true(fetched_volume['bootable']) self.assertEqual(bool_bootable, bool_flag) ",,21,1
openstack%2Fcinder~master~Idf99f3fba8d910e95572f1c458c190985144bfde,openstack/cinder,master,Idf99f3fba8d910e95572f1c458c190985144bfde,Fix some LOG.warn to LOG.warning in Cinder,ABANDONED,2015-05-20 08:46:17.000000000,2015-05-21 02:01:12.000000000,,"[{'_account_id': 3}, {'_account_id': 8846}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12249}, {'_account_id': 12491}, {'_account_id': 12493}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 13636}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 15374}, {'_account_id': 16160}]","[{'number': 1, 'created': '2015-05-20 08:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9a99ac92a3d6e30a2d62c4a4efd8512fe0065618', 'message': 'Fix some LOG.warn to LOG.warning in Cinder\n\nLOG.warn is deprecated, we should use LOG.warning at now.\n\nLOG.warn still exist in some corner of cinder. Not much, but should fix it\nsoon.\n\nChange-Id: Idf99f3fba8d910e95572f1c458c190985144bfde\nClose-Bug: #1456940\n'}, {'number': 2, 'created': '2015-05-20 09:22:20.000000000', 'files': ['cinder/tests/unit/scheduler/test_host_manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8a9ddd08079e0560ab6b9327de2e90d790ac1838', 'message': 'Fix some LOG.warn to LOG.warning in Cinder\n\nLOG.warn is deprecated, we should use LOG.warning at now.\n\nLOG.warn still exist in some corner of cinder. Not much, but should fix it\nsoon.\n\nChange-Id: Idf99f3fba8d910e95572f1c458c190985144bfde\nClose-Bug: #1456940\n'}]",0,184439,8a9ddd08079e0560ab6b9327de2e90d790ac1838,28,17,2,8846,,,0,"Fix some LOG.warn to LOG.warning in Cinder

LOG.warn is deprecated, we should use LOG.warning at now.

LOG.warn still exist in some corner of cinder. Not much, but should fix it
soon.

Change-Id: Idf99f3fba8d910e95572f1c458c190985144bfde
Close-Bug: #1456940
",git fetch https://review.opendev.org/openstack/cinder refs/changes/39/184439/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/openstack/common/loopingcall.py', 'cinder/tests/unit/scheduler/test_host_manager.py']",2,9a99ac92a3d6e30a2d62c4a4efd8512fe0065618,bug/1456940, host_manager.LOG.warning = _mock_warning host_manager.LOG.warning = _mock_warning, host_manager.LOG.warn = _mock_warning host_manager.LOG.warn = _mock_warning,5,5
openstack%2Fopenstacksdk~master~Ib9e3652764f923bcf4804d1af4064d3034c96f7e,openstack/openstacksdk,master,Ib9e3652764f923bcf4804d1af4064d3034c96f7e,Fix documentation warnings,MERGED,2015-05-21 01:20:56.000000000,2015-05-21 01:34:51.000000000,2015-05-21 01:34:50.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-21 01:20:56.000000000', 'files': ['openstack/network/v2/_proxy.py', 'doc/source/users/proxies/keystore.rst', 'openstack/compute/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e074646d0d8059c538be775ac4ffd3626473c3c9', 'message': 'Fix documentation warnings\n\nChange-Id: Ib9e3652764f923bcf4804d1af4064d3034c96f7e\n'}]",0,184670,e074646d0d8059c538be775ac4ffd3626473c3c9,6,2,1,8736,,,0,"Fix documentation warnings

Change-Id: Ib9e3652764f923bcf4804d1af4064d3034c96f7e
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/70/184670/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/users/proxies/keystore.rst', 'openstack/network/v2/_proxy.py', 'openstack/compute/v2/_proxy.py']",3,e074646d0d8059c538be775ac4ffd3626473c3c9,," :param kwargs \*\*query: Optional query parameters to be sent to limit the flavors being returned. :param kwargs \*\*query: Optional query parameters to be sent to limit the flavors being returned. :param kwargs \*\*query: Optional query parameters to be sent to limit the servers being returned. Available parameters include: * changes_since: A time/date stamp for when the server last changed status. * image: An image resource or ID. * flavor: A flavor resource or ID. * name: Name of the server as a string. Can be queried with regular expressions. The regular expression ?name=bob returns both bob and bobb. If you must match on only bob, you can use a regular expression that matches the syntax of the underlying database server that is implemented for Compute, such as MySQL or PostgreSQL. * status: Value of the status of the server so that you can filter on ""ACTIVE"" for example. * host: Name of the host as a string. * limit: Requests a specified page size of returned items from the query. Returns a number of items up to the specified limit value. Use the limit parameter to make an initial limited request and use the ID of the last-seen item from the response as the marker parameter value in a subsequent limited request. * marker: Specifies the ID of the last-seen item. Use the limit parameter to make an initial limited request and use the ID of the last-seen item from the response as the marker parameter value in a subsequent limited request."," :param kwargs **query: Optional query parameters to be sent to limit the flavors being returned. :param kwargs **query: Optional query parameters to be sent to limit the flavors being returned. :param kwargs **query: Optional query parameters to be sent to limit the servers being returned. Available parameters include: * changes_since: A time/date stamp for when the server last changed status. * image: An image resource or ID. * flavor: A flavor resource or ID. * name: Name of the server as a string. Can be queried with regular expressions. The regular expression ?name=bob returns both bob and bobb. If you must match on only bob, you can use a regular expression that matches the syntax of the underlying database server that is implemented for Compute, such as MySQL or PostgreSQL. * status: Value of the status of the server so that you can filter on ""ACTIVE"" for example. * host: Name of the host as a string. * limit: Requests a specified page size of returned items from the query. Returns a number of items up to the specified limit value. Use the limit parameter to make an initial limited request and use the ID of the last-seen item from the response as the marker parameter value in a subsequent limited request. * marker: Specifies the ID of the last-seen item. Use the limit parameter to make an initial limited request and use the ID of the last-seen item from the response as the marker parameter value in a subsequent limited request.",79,99
openstack%2Fdevstack~master~Ie48a859476faff22a4dfef466516e2d7d62ef0c0,openstack/devstack,master,Ie48a859476faff22a4dfef466516e2d7d62ef0c0,Fix function and test for 'trueorfalse'.,MERGED,2015-05-11 09:06:03.000000000,2015-05-21 01:14:34.000000000,2015-05-12 21:34:28.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 7715}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-05-11 09:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e7aee8bb15536d30dd576cc8f819f6003011b746', 'message': 'Fix function and test for \'trueorfalse\'.\n\nThe function\'s comment is written as follow, however the function accepts\nother values (ex. ""e"", ""t"", ""T"", ""f"", ""F"", etc...).\n\n---\n---\n\nThis patch fixes the issue and add test patterns.\n\nChange-Id: Ie48a859476faff22a4dfef466516e2d7d62ef0c0\nCloses-bug: #1453687\n'}, {'number': 2, 'created': '2015-05-11 09:27:03.000000000', 'files': ['functions-common', 'tests/test_truefalse.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/98f59aafaf88328f6aee98efa0f563fb8bf91ebd', 'message': 'Fix function and test for \'trueorfalse\'.\n\nThe function\'s comment is written as follow, however the function accepts\nother values (ex. ""e"", ""t"", ""T"", ""f"", ""F"", etc...).\n\n---\nAccepts as False: 0 no No NO false False FALSE\nAccepts as True: 1 yes Yes YES true True TRUE\n---\n\nMoreover if testval mach True or False, the function exits without resetting\nxtrace.\n\nThis patch fixes the issue and add test patterns.\n\nChange-Id: Ie48a859476faff22a4dfef466516e2d7d62ef0c0\nCloses-bug: #1453687\n'}]",0,181833,98f59aafaf88328f6aee98efa0f563fb8bf91ebd,11,6,2,14257,,,0,"Fix function and test for 'trueorfalse'.

The function's comment is written as follow, however the function accepts
other values (ex. ""e"", ""t"", ""T"", ""f"", ""F"", etc...).

---
Accepts as False: 0 no No NO false False FALSE
Accepts as True: 1 yes Yes YES true True TRUE
---

Moreover if testval mach True or False, the function exits without resetting
xtrace.

This patch fixes the issue and add test patterns.

Change-Id: Ie48a859476faff22a4dfef466516e2d7d62ef0c0
Closes-bug: #1453687
",git fetch https://review.opendev.org/openstack/devstack refs/changes/33/181833/1 && git format-patch -1 --stdout FETCH_HEAD,"['functions-common', 'tests/test_truefalse.sh']",2,e7aee8bb15536d30dd576cc8f819f6003011b746,bug/1453687,"function test_trueorfalse { local uppertrue=TRUE local capyes=Yes local lowyes=yes local upperyes=YES for default in True False; do for name in one captrue lowtrue uppertrue capyes lowyes upperyes; do assert_equal ""True"" $(trueorfalse $default $name) ""\$(trueorfalse $default $name)"" done done local upperfalse=FALSE local capno=No local lowno=no local upperno=NO for default in True False; do for name in zero capfalse lowfalse upperfalse capno lowno upperno; do assert_equal ""False"" $(trueorfalse $default $name) ""\$(trueorfalse $default $name)""test_trueorfalse","function test_truefalse { local abrevtrue=t local abrevfalse=f for against in True False; do for name in one captrue lowtrue abrevtrue; do assert_equal ""True"" $(trueorfalse $against $name) ""\$(trueorfalse $against $name)"" done done for against in True False; do for name in zero capfalse lowfalse abrevfalse; do assert_equal ""False"" $(trueorfalse $against $name) ""\$(trueorfalse $against $name)""test_truefalse",30,19
openstack%2Fopenstack-manuals~master~I904f46d2c72f7be25c66d31241e5c1d2d3e3e8a3,openstack/openstack-manuals,master,I904f46d2c72f7be25c66d31241e5c1d2d3e3e8a3,Correct URL for hypervisor support matrix,ABANDONED,2015-05-21 01:09:42.000000000,2015-05-21 01:10:12.000000000,,[{'_account_id': 6547}],"[{'number': 1, 'created': '2015-05-21 01:09:42.000000000', 'files': ['doc/common/section_cli_nova_boot_from_volume.xml', 'doc/common/section_dashboard_access.xml', 'doc/common/section_cli_nova_quotas.xml', 'doc/common/section_cli_keystone_credentials.xml', 'doc/common/section_cli_keystone_example_usage.xml', 'doc/common/section_cli_nova_metadata.xml', 'doc/common/section_cli_neutron_manage_networks.xml', 'doc/common/section_cli_nova_fileinjection.xml', 'doc/common/section_cli_cinder_manage_volumes.xml', 'doc/common/section_cli_nova_images.xml', 'doc/common/section_cli_nova_secgroups.xml', 'doc/common/ch_using_openstack_overview.xml', 'doc/common/section_cli_glance_manage_images.xml', 'doc/common/section_dashboard_launch_instances_from_image.xml', 'doc/config-reference/compute/section_compute-hypervisors.xml', 'doc/common/section_cli_neutron-quotas.xml', 'doc/common/section_cli_help.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/153f974aa669c021a74203a1d35c566aa74161c3', 'message': 'Correct URL for hypervisor support matrix\n\nChange-Id: I904f46d2c72f7be25c66d31241e5c1d2d3e3e8a3\nCloses-Bug: #1455699\n'}]",0,184664,153f974aa669c021a74203a1d35c566aa74161c3,2,1,1,15279,,,0,"Correct URL for hypervisor support matrix

Change-Id: I904f46d2c72f7be25c66d31241e5c1d2d3e3e8a3
Closes-Bug: #1455699
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/64/184664/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/section_cli_nova_boot_from_volume.xml', 'doc/common/section_dashboard_access.xml', 'doc/common/section_cli_nova_quotas.xml', 'doc/common/section_cli_keystone_credentials.xml', 'doc/common/section_cli_keystone_example_usage.xml', 'doc/common/section_cli_nova_metadata.xml', 'doc/common/section_cli_neutron_manage_networks.xml', 'doc/common/section_cli_nova_fileinjection.xml', 'doc/common/section_cli_cinder_manage_volumes.xml', 'doc/common/section_cli_nova_images.xml', 'doc/common/section_cli_nova_secgroups.xml', 'doc/common/ch_using_openstack_overview.xml', 'doc/common/section_cli_glance_manage_images.xml', 'doc/common/section_dashboard_launch_instances_from_image.xml', 'doc/config-reference/compute/section_compute-hypervisors.xml', 'doc/common/section_cli_neutron-quotas.xml', 'doc/common/section_cli_help.xml']",17,153f974aa669c021a74203a1d35c566aa74161c3,bug/1455699,,"<?xml version=""1.0"" encoding=""UTF-8""?> <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""cli_help""> <title>Get help for client commands</title> <para>To get usage information, including a list of commands with descriptions, for a client, run the following command:</para> <screen><prompt>$</prompt> <userinput><replaceable>CLIENT_NAME</replaceable> help</userinput></screen> <para>For example, to get help information for the swift client, run the following command:</para> <screen><prompt>$</prompt> <userinput>swift help</userinput></screen> <screen><?db-font-size 65%?><computeroutput>Usage: swift [--version] [--help] [--snet] [--verbose] [--debug] [--quiet] [--auth &lt;auth_url>] [--auth-version &lt;auth_version>] [--user &lt;username>] [--key &lt;api_key>] [--retries &lt;num_retries>] [--os-username &lt;auth-user-name>] [--os-password &lt;auth-password>] [--os-tenant-id &lt;auth-tenant-id>] [--os-tenant-name &lt;auth-tenant-name>] [--os-auth-url &lt;auth-url>] [--os-auth-token &lt;auth-token>] [--os-storage-url &lt;storage-url>] [--os-region-name &lt;region-name>] [--os-service-type &lt;service-type>] [--os-endpoint-type &lt;endpoint-type>] [--os-cacert &lt;ca-certificate>] [--insecure] [--no-ssl-compression] &lt;subcommand> ... Command-line interface to the OpenStack Swift API. Positional arguments: &lt;subcommand> delete Delete a container or objects within a container download Download objects from containers list Lists the containers for the account or the objects for a container post Updates meta information for the account, container, or object stat Displays information for the account, container, or object upload Uploads files or directories to the given container Examples: swift -A https://auth.api.rackspacecloud.com/v1.0 -U user -K api_key stat -v swift --os-auth-url https://api.example.com/v2.0 --os-tenant-name tenant \ --os-username user --os-password password list swift --os-auth-token 6ee5eb33efad4e45ab46806eac010566 \ --os-storage-url https://10.1.5.2:8080/v1/AUTH_ced809b6a4baea7aeab61a \ list swift list --lh</computeroutput></screen> <note> <para>Depending on your credentials, you might not have permission to use every command.</para> </note> <para>After the <option>help</option> command, you can enter a command name to get help for that command, as follows:</para> <screen><prompt>$</prompt> <userinput><replaceable>CLIENT_NAME</replaceable> help <replaceable>COMMAND_NAME</replaceable></userinput></screen> <para>For example, to get help for the glance <command>image-show</command> command, enter the following command:</para> <screen><prompt>$</prompt> <userinput>glance help image-show</userinput></screen> <para>The command returns a description of the command and its positional and optional arguments:</para> <screen><?db-font-size 75%?><computeroutput>usage: glance image-show [--human-readable] &lt;IMAGE> Describe a specific image. Positional arguments: &lt;IMAGE> Name or ID of image to describe. Optional arguments: --human-readable Print image size in a human-friendly format.</computeroutput></screen> </section> ",3,3402
openstack%2Fcastellan~master~I894af868f9a635a932cddbbbb4261704d09240b2,openstack/castellan,master,I894af868f9a635a932cddbbbb4261704d09240b2,Migrate to oslo_context,MERGED,2015-05-20 23:53:12.000000000,2015-05-21 01:09:23.000000000,2015-05-21 01:09:23.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-05-20 23:53:12.000000000', 'files': ['requirements.txt', 'castellan/context.py', 'castellan/tests/key_manager/test_mock_key_manager.py'], 'web_link': 'https://opendev.org/openstack/castellan/commit/255f34c1d48f5e3f1b7be51741c4dda1178cbdcb', 'message': 'Migrate to oslo_context\n\nChange-Id: I894af868f9a635a932cddbbbb4261704d09240b2\n'}]",0,184650,255f34c1d48f5e3f1b7be51741c4dda1178cbdcb,8,10,1,10873,,,0,"Migrate to oslo_context

Change-Id: I894af868f9a635a932cddbbbb4261704d09240b2
",git fetch https://review.opendev.org/openstack/castellan refs/changes/50/184650/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'castellan/context.py', 'castellan/tests/key_manager/test_mock_key_manager.py']",3,255f34c1d48f5e3f1b7be51741c4dda1178cbdcb,oslo_context,from oslo_context import context ,from castellan import context,3,76
openstack%2Fneutron~master~I080acaaa1d4753619fbbb76dddba6d946d84e73f,openstack/neutron,master,I080acaaa1d4753619fbbb76dddba6d946d84e73f,Python 3: Use six.moves.range,MERGED,2015-05-19 09:54:10.000000000,2015-05-21 00:48:18.000000000,2015-05-21 00:48:15.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 8122}, {'_account_id': 8124}, {'_account_id': 8655}, {'_account_id': 9008}, {'_account_id': 9107}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12561}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15882}]","[{'number': 1, 'created': '2015-05-19 09:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c551f3adb305efd44dc77dd94d6e932c61b216c5', 'message': 'Python 3: Use six.moves.range\n\nThe function `xrange` was renamed to `range` in Python 3.\n\n* Remove `xrange` occurences so that Python 3 tests can pass. Use\n  `six.moves.range` instead to get the right function in both cases.\n* Generalize the use of the efficient `range` (ex-`xrange`) in\n  critical sections (when iterating over large lists).\n* Simplify code.\n\nChange-Id: I080acaaa1d4753619fbbb76dddba6d946d84e73f\nPartially implements: blueprint neutron-python3\n'}, {'number': 2, 'created': '2015-05-19 14:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/19466b84659c7a54e990deb53f8e4d35a30a5348', 'message': 'Python 3: Use six.moves.range\n\nThe function `xrange` was renamed to `range` in Python 3.\n\n* Remove `xrange` occurences so that Python 3 tests can pass. Use\n  `six.moves.range` instead to get the right function in both cases.\n* Generalize the use of the efficient `range` (ex-`xrange`) in\n  critical sections (when iterating over large lists).\n* Simplify code.\n* Add a hacking check to prevent future usage of `xrange`.\n\nChange-Id: I080acaaa1d4753619fbbb76dddba6d946d84e73f\nPartially implements: blueprint neutron-python3\n'}, {'number': 3, 'created': '2015-05-19 15:34:35.000000000', 'files': ['neutron/tests/functional/agent/linux/test_process_monitor.py', 'neutron/tests/unit/api/v2/test_base.py', 'neutron/tests/unit/plugins/cisco/n1kv/test_n1kv_db.py', 'neutron/plugins/ml2/drivers/type_vlan.py', 'neutron/tests/unit/tests/test_post_mortem_debug.py', 'neutron/tests/functional/agent/linux/test_async_process.py', 'neutron/tests/unit/agent/l3/test_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/base_type_tunnel.py', 'neutron/hacking/checks.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/hacking/test_checks.py', 'neutron/db/sqlalchemyutils.py', 'neutron/tests/unit/plugins/oneconvergence/test_nvsd_agent.py', 'neutron/plugins/brocade/vlanbm.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/plugins/ml2/drivers/type_vxlan.py', 'neutron/plugins/ml2/drivers/type_gre.py', 'HACKING.rst', 'neutron/tests/tempest/common/glance_http.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5836bbca83845fd78200c083465601d2558cdac2', 'message': 'Python 3: Use six.moves.range\n\nThe function `xrange` was renamed to `range` in Python 3.\n\n* Remove `xrange` occurences so that Python 3 tests can pass. Use\n  `six.moves.range` instead to get the right function in both cases.\n* Generalize the use of the efficient `range` (ex-`xrange`) in\n  critical sections (when iterating over large lists).\n* Simplify code.\n* Add a hacking check to prevent future usage of `xrange`.\n\nChange-Id: I080acaaa1d4753619fbbb76dddba6d946d84e73f\nPartially implements: blueprint neutron-python3\n'}]",8,184216,5836bbca83845fd78200c083465601d2558cdac2,90,34,3,12561,,,0,"Python 3: Use six.moves.range

The function `xrange` was renamed to `range` in Python 3.

* Remove `xrange` occurences so that Python 3 tests can pass. Use
  `six.moves.range` instead to get the right function in both cases.
* Generalize the use of the efficient `range` (ex-`xrange`) in
  critical sections (when iterating over large lists).
* Simplify code.
* Add a hacking check to prevent future usage of `xrange`.

Change-Id: I080acaaa1d4753619fbbb76dddba6d946d84e73f
Partially implements: blueprint neutron-python3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/16/184216/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/agent/linux/test_process_monitor.py', 'neutron/tests/unit/api/v2/test_base.py', 'neutron/tests/unit/plugins/cisco/n1kv/test_n1kv_db.py', 'neutron/plugins/ml2/drivers/type_vlan.py', 'neutron/tests/functional/scheduler/test_dhcp_agent_scheduler.py', 'neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/tests/unit/tests/test_post_mortem_debug.py', 'neutron/tests/functional/agent/linux/test_async_process.py', 'neutron/tests/unit/agent/l3/test_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/base_type_tunnel.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/agent/l3/test_namespace_manager.py', 'neutron/db/sqlalchemyutils.py', 'neutron/tests/unit/plugins/oneconvergence/test_nvsd_agent.py', 'neutron/api/rpc/handlers/dhcp_rpc.py', 'neutron/agent/dhcp/agent.py', 'neutron/plugins/brocade/vlanbm.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/plugins/ml2/drivers/type_vxlan.py', 'neutron/plugins/ml2/drivers/type_gre.py', 'neutron/tests/functional/agent/linux/helpers.py', 'neutron/tests/tempest/common/glance_http.py']",22,c551f3adb305efd44dc77dd94d6e932c61b216c5,bp/neutron-python3,from six.moves import http_client as httplib from six.moves import range for i in range(x509.get_extension_count()):,from six.moves import http_client as httplibfrom six import moves for i in moves.xrange(x509.get_extension_count()):,45,35
openstack%2Fneutron~stable%2Fjuno~I0896730126d6dca13fe9284b4d812cfb081b6218,openstack/neutron,stable/juno,I0896730126d6dca13fe9284b4d812cfb081b6218,Don't resync on DHCP agent setup failure,MERGED,2015-04-24 11:07:16.000000000,2015-05-21 00:47:57.000000000,2015-05-21 00:47:54.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 6854}, {'_account_id': 6876}, {'_account_id': 7125}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-04-24 11:07:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/773f57c18b18d7a852484850f13b52cdd096e55b', 'message': ""Don't resync on DHCP agent setup failure\n\nThere are various cases where the DHCP agent will try to\ncreate a DHCP port for a network and there will be a failure.\nThis has primarily been caused by a lack of available IP addresses\nin the allocation pool. Trying to fix all availability corner cases\non the server side will be very difficult due to race conditions between\nmultiple ports being created, the dhcp_agents_per_network parameter, etc.\n\nThis patch just stops the resync attempt on the agent side if a failure\nis caused by an IP address generation problem. Future updates to the subnet\nwill cause another attempt so if the tenant does fix the issue they will\nget DHCP service.\n\nChange-Id: I0896730126d6dca13fe9284b4d812cfb081b6218\nCloses-Bug: #1447883\n(cherry picked from commit db9ac7e0110a0c2ef1b65213317ee8b7f1053ddc)\n""}, {'number': 2, 'created': '2015-04-24 11:33:01.000000000', 'files': ['neutron/agent/dhcp_agent.py', 'neutron/tests/unit/test_dhcp_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/17850aacbbe920f85a2eff8e5632708e8f31a609', 'message': ""Don't resync on DHCP agent setup failure\n\nThere are various cases where the DHCP agent will try to\ncreate a DHCP port for a network and there will be a failure.\nThis has primarily been caused by a lack of available IP addresses\nin the allocation pool. Trying to fix all availability corner cases\non the server side will be very difficult due to race conditions between\nmultiple ports being created, the dhcp_agents_per_network parameter, etc.\n\nThis patch just stops the resync attempt on the agent side if a failure\nis caused by an IP address generation problem. Future updates to the subnet\nwill cause another attempt so if the tenant does fix the issue they will\nget DHCP service.\n\nChange-Id: I0896730126d6dca13fe9284b4d812cfb081b6218\nCloses-Bug: #1447883\n(cherry picked from commit db9ac7e0110a0c2ef1b65213317ee8b7f1053ddc)\n""}]",0,177174,17850aacbbe920f85a2eff8e5632708e8f31a609,41,20,2,7787,,,0,"Don't resync on DHCP agent setup failure

There are various cases where the DHCP agent will try to
create a DHCP port for a network and there will be a failure.
This has primarily been caused by a lack of available IP addresses
in the allocation pool. Trying to fix all availability corner cases
on the server side will be very difficult due to race conditions between
multiple ports being created, the dhcp_agents_per_network parameter, etc.

This patch just stops the resync attempt on the agent side if a failure
is caused by an IP address generation problem. Future updates to the subnet
will cause another attempt so if the tenant does fix the issue they will
get DHCP service.

Change-Id: I0896730126d6dca13fe9284b4d812cfb081b6218
Closes-Bug: #1447883
(cherry picked from commit db9ac7e0110a0c2ef1b65213317ee8b7f1053ddc)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/74/177174/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/dhcp_agent.py', 'neutron/tests/unit/test_dhcp_agent.py']",2,773f57c18b18d7a852484850f13b52cdd096e55b,bug/1447883," def test_call_driver_ip_address_generation_failure(self): error = oslo_messaging.RemoteError( exc_type='IpAddressGenerationFailure') self._test_call_driver_failure(exc=error, expected_sync=False) ",,11,1
openstack%2Fnova~master~I7ced236b6f8f8b6a5d2e7fee3c4f0ba4d72c21fb,openstack/nova,master,I7ced236b6f8f8b6a5d2e7fee3c4f0ba4d72c21fb,Replace unicode with six.text_type,MERGED,2015-05-04 17:33:48.000000000,2015-05-21 00:47:39.000000000,2015-05-21 00:47:36.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 8300}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9107}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12561}, {'_account_id': 14027}, {'_account_id': 14358}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-04 17:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd2a86d7f7a482c4fc8c5acbb62d0b3f3fd660a9', 'message': 'Replace unicode with six.text_type\n\nThe Unicode type is \'unicode\' in Python 2 and \'str\' on Python 3: replace\nunicode with six.text_type to make Nova compatible with Python 2 and\nPython 3.\n\nThis patch was generated by the following tool (revision e760664379c3) with the\noperation ""unicode"":\nhttps://bitbucket.org/haypo/misc/src/tip/python/sixer.py\n\nManual change:\n\n* Replace ""isinstance(value, str) or isinstance(value, unicode)""\n  with ""isinstance(value, six.string_types)"" in nova/api/ec2/ec2utils.py\n\n* Revert changes in strings in:\n\n  - nova/compute/api.py\n  - nova/hacking/checks.py\n  - nova/tests/unit/api/openstack/test_wsgi.py\n  - nova/utils.py\n\n* Revert changes in nova/tests/unit/test_hacking.py: tests must use\n  ""unicode()"". The nova.hacking module will probably need other changes\n  to support Python 3.\n\n* Reformat nova/tests/unit/objects/test_instance_action.py and\n  nova/tests/unit/virt/hyperv/test_hypervapi.py to 80 columns\n\nBlueprint nova-python3\nChange-Id: I7ced236b6f8f8b6a5d2e7fee3c4f0ba4d72c21fb\n'}, {'number': 2, 'created': '2015-05-12 10:32:47.000000000', 'files': ['nova/api/ec2/__init__.py', 'nova/tests/unit/objects/test_instance_action.py', 'nova/tests/unit/virt/hyperv/test_hypervapi.py', 'nova/tests/unit/virt/test_virt.py', 'nova/compute/flavors.py', 'nova/tests/unit/test_availability_zones.py', 'nova/api/ec2/cloud.py', 'nova/api/ec2/ec2utils.py', 'nova/virt/ironic/driver.py', 'nova/utils.py', 'nova/compute/utils.py', 'nova/tests/unit/api/openstack/compute/contrib/test_migrate_server.py', 'nova/tests/unit/api/openstack/compute/test_flavors.py', 'nova/api/openstack/__init__.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_manage.py', 'nova/tests/unit/virt/libvirt/test_volume.py', 'nova/objects/fields.py', 'nova/api/openstack/compute/servers.py', 'nova/network/floating_ips.py', 'nova/api/openstack/wsgi.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/unit/virt/ironic/test_driver.py', 'doc/ext/support_matrix.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/tests/unit/api/openstack/test_faults.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/67eedf4fa020362d847dc14aec331db5c30a1173', 'message': 'Replace unicode with six.text_type\n\nThe Unicode type is \'unicode\' in Python 2 and \'str\' on Python 3: replace\nunicode with six.text_type to make Nova compatible with Python 2 and\nPython 3.\n\nThis patch was generated by the following tool (revision e760664379c3) with the\noperation ""unicode"":\nhttps://bitbucket.org/haypo/misc/src/tip/python/sixer.py\n\nManual change:\n\n* Replace ""isinstance(value, str) or isinstance(value, unicode)""\n  with ""isinstance(value, six.string_types)"" in nova/api/ec2/ec2utils.py\n\n* Revert changes in strings in:\n\n  - nova/compute/api.py\n  - nova/hacking/checks.py\n  - nova/tests/unit/api/openstack/test_wsgi.py\n  - nova/utils.py\n\n* Revert changes in nova/tests/unit/test_hacking.py: tests must use\n  ""unicode()"". The nova.hacking module will probably need other changes\n  to support Python 3.\n\n* Reformat nova/tests/unit/objects/test_instance_action.py and\n  nova/tests/unit/virt/hyperv/test_hypervapi.py to 80 columns\n\nBlueprint nova-python3\nChange-Id: I7ced236b6f8f8b6a5d2e7fee3c4f0ba4d72c21fb\n'}]",0,179850,67eedf4fa020362d847dc14aec331db5c30a1173,57,18,2,9107,,,0,"Replace unicode with six.text_type

The Unicode type is 'unicode' in Python 2 and 'str' on Python 3: replace
unicode with six.text_type to make Nova compatible with Python 2 and
Python 3.

This patch was generated by the following tool (revision e760664379c3) with the
operation ""unicode"":
https://bitbucket.org/haypo/misc/src/tip/python/sixer.py

Manual change:

* Replace ""isinstance(value, str) or isinstance(value, unicode)""
  with ""isinstance(value, six.string_types)"" in nova/api/ec2/ec2utils.py

* Revert changes in strings in:

  - nova/compute/api.py
  - nova/hacking/checks.py
  - nova/tests/unit/api/openstack/test_wsgi.py
  - nova/utils.py

* Revert changes in nova/tests/unit/test_hacking.py: tests must use
  ""unicode()"". The nova.hacking module will probably need other changes
  to support Python 3.

* Reformat nova/tests/unit/objects/test_instance_action.py and
  nova/tests/unit/virt/hyperv/test_hypervapi.py to 80 columns

Blueprint nova-python3
Change-Id: I7ced236b6f8f8b6a5d2e7fee3c4f0ba4d72c21fb
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/179850/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/ec2/__init__.py', 'nova/tests/unit/objects/test_instance_action.py', 'nova/tests/unit/virt/hyperv/test_hypervapi.py', 'nova/tests/unit/virt/test_virt.py', 'nova/compute/flavors.py', 'nova/tests/unit/test_availability_zones.py', 'nova/api/ec2/cloud.py', 'nova/api/ec2/ec2utils.py', 'nova/virt/ironic/driver.py', 'nova/utils.py', 'nova/compute/utils.py', 'nova/tests/unit/api/openstack/compute/contrib/test_migrate_server.py', 'nova/tests/unit/api/openstack/compute/test_flavors.py', 'nova/api/openstack/__init__.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_manage.py', 'nova/tests/unit/virt/libvirt/test_volume.py', 'nova/objects/fields.py', 'nova/api/openstack/compute/servers.py', 'nova/network/floating_ips.py', 'nova/api/openstack/wsgi.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/unit/virt/ironic/test_driver.py', 'doc/ext/support_matrix.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/tests/unit/api/openstack/test_faults.py']",25,bd2a86d7f7a482c4fc8c5acbb62d0b3f3fd660a9,bp/nova-python3,"import six self.assertIn(""I've been translated!"", six.text_type(response.body))"," self.assertIn(""I've been translated!"", unicode(response.body))",58,40
openstack%2Fpython-swiftclient~master~I54e8eb138976269bb36392a811089c33c1ace4d3,openstack/python-swiftclient,master,I54e8eb138976269bb36392a811089c33c1ace4d3,Add tests for uploads deleting DLO segments,MERGED,2015-02-05 10:06:17.000000000,2015-05-21 00:47:30.000000000,2015-05-21 00:47:28.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 7847}, {'_account_id': 9216}, {'_account_id': 12193}]","[{'number': 1, 'created': '2015-02-05 10:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/bd71fa85da624c2e2a661205f1bb097e91c32114', 'message': 'Add tests for uploads deleting DLO segments\n\nThis patch adds unit tests to verify that\nuploads overwriting an existing DLO manifest\nwill delete any segments pointed to by the\nmanifest, unless --leave-segments is specified.\n\nAlso test the --leave-segments option with an\nexisting SLO manifest.\n\nChange-Id: I54e8eb138976269bb36392a811089c33c1ace4d3\n'}, {'number': 2, 'created': '2015-02-05 10:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/03ce4e2d52be946a26375d89d8fbf6080350bf2e', 'message': 'Add tests for uploads deleting DLO segments\n\nThis patch adds unit tests to verify that\nuploads overwriting an existing DLO manifest\nwill delete any segments pointed to by the\nmanifest, unless --leave-segments is specified.\n\nAlso test the --leave-segments option with an\nexisting SLO manifest.\n\nRelated-Bug: 1418007\n\nChange-Id: I54e8eb138976269bb36392a811089c33c1ace4d3\n'}, {'number': 3, 'created': '2015-02-24 16:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/bfa166bbc5f9ba1981f0639c5121d8e1ce87a91e', 'message': 'Add tests for uploads deleting DLO segments\n\nThis patch adds unit tests to verify that\nuploads overwriting an existing DLO manifest\nwill delete any segments pointed to by the\nmanifest, unless --leave-segments is specified.\n\nAlso test the --leave-segments option with an\nexisting SLO manifest.\n\nRelated-Bug: 1418007\n\nChange-Id: I54e8eb138976269bb36392a811089c33c1ace4d3\n'}, {'number': 4, 'created': '2015-02-25 16:55:23.000000000', 'files': ['tests/unit/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/dcf2124d4190ec8d1b99e3e42cdafdafc92d6cf9', 'message': 'Add tests for uploads deleting DLO segments\n\nThis patch adds unit tests to verify that\nuploads overwriting an existing DLO manifest\nwill delete any segments pointed to by the\nmanifest, unless --leave-segments is specified.\n\nAlso test the --leave-segments option with an\nexisting SLO manifest.\n\nRelated-Bug: 1418007\n\nChange-Id: I54e8eb138976269bb36392a811089c33c1ace4d3\n'}]",6,153177,dcf2124d4190ec8d1b99e3e42cdafdafc92d6cf9,20,6,4,7847,,,0,"Add tests for uploads deleting DLO segments

This patch adds unit tests to verify that
uploads overwriting an existing DLO manifest
will delete any segments pointed to by the
manifest, unless --leave-segments is specified.

Also test the --leave-segments option with an
existing SLO manifest.

Related-Bug: 1418007

Change-Id: I54e8eb138976269bb36392a811089c33c1ace4d3
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/77/153177/4 && git format-patch -1 --stdout FETCH_HEAD,['tests/unit/test_shell.py'],1,bd71fa85da624c2e2a661205f1bb097e91c32114,bug/1418007," def test_upload_delete_slo_segments(self, connection): def test_upload_leave_slo_segments(self, connection): # Test upload overwriting a manifest respects --leave-segments connection.return_value.head_container.return_value = { 'x-storage-policy': 'one'} connection.return_value.attempts = 0 argv = ["""", ""upload"", ""container"", self.tmpfile, ""--leave-segments""] connection.return_value.head_object.side_effect = [ {'x-static-large-object': 'true', # For the upload call 'content-length': '2'}, {'x-static-large-object': 'false', # For the 1st delete call 'content-length': '2'}, {'x-static-large-object': 'false', # For the 2nd delete call 'content-length': '2'} ] connection.return_value.get_object.return_value = ({}, json.dumps( [{'name': 'container1/old_seg1'}, {'name': 'container2/old_seg2'}] )) swiftclient.shell.main(argv) connection.return_value.put_object.assert_called_with( 'container', self.tmpfile.lstrip('/'), mock.ANY, content_length=0, headers={'x-object-meta-mtime': mock.ANY}, response_dict={}) self.assertEqual([], connection.return_value.delete_object.mock_calls) @mock.patch('swiftclient.service.Connection') def test_upload_delete_dlo_segments(self, connection): # Upload delete existing segments connection.return_value.head_container.return_value = { 'x-storage-policy': 'one'} connection.return_value.attempts = 0 argv = ["""", ""upload"", ""container"", self.tmpfile] connection.return_value.head_object.side_effect = [ {'x-object-manifest': 'container1/prefix', 'content-length': '0'}, {}, {} ] connection.return_value.get_container.side_effect = [ [None, [{'name': 'prefix_a', 'bytes': 0, 'last_modified': '123T456'}, {'name': 'prefix_b', 'bytes': 0, 'last_modified': '123T456'}]] ] swiftclient.shell.main(argv) connection.return_value.put_object.assert_called_with( 'container', self.tmpfile.lstrip('/'), mock.ANY, content_length=0, headers={'x-object-meta-mtime': mock.ANY}, response_dict={}) expected_delete_calls = [ mock.call( 'container1', 'prefix_a', query_string=None, response_dict={} ), mock.call( 'container1', 'prefix_b', query_string=None, response_dict={} ) ] self.assertEqual( sorted(expected_delete_calls), sorted(connection.return_value.delete_object.mock_calls) ) @mock.patch('swiftclient.service.Connection') def test_upload_leave_dlo_segments(self, connection): # Upload delete existing segments connection.return_value.head_container.return_value = { 'x-storage-policy': 'one'} connection.return_value.attempts = 0 argv = ["""", ""upload"", ""container"", self.tmpfile, ""--leave-segments""] connection.return_value.head_object.side_effect = [ {'x-object-manifest': 'container1/prefix', 'content-length': '0'}, {}, {} ] connection.return_value.get_container.side_effect = [ [None, [{'name': 'prefix_a', 'bytes': 0, 'last_modified': '123T456'}, {'name': 'prefix_b', 'bytes': 0, 'last_modified': '123T456'}]] ] swiftclient.shell.main(argv) connection.return_value.put_object.assert_called_with( 'container', self.tmpfile.lstrip('/'), mock.ANY, content_length=0, headers={'x-object-meta-mtime': mock.ANY}, response_dict={}) self.assertEqual([], connection.return_value.delete_object.mock_calls) @mock.patch('swiftclient.service.Connection')"," @mock.patch('swiftclient.shell.walk') def test_upload_delete(self, connection, walk):",100,2
openstack%2Fpython-swiftclient~master~Ie9cfc86fa2156b94b45d290ac12e3f71b20d6c4f,openstack/python-swiftclient,master,Ie9cfc86fa2156b94b45d290ac12e3f71b20d6c4f,Add test for timeout being passed to keystone client,MERGED,2015-04-28 15:59:15.000000000,2015-05-21 00:44:52.000000000,2015-05-21 00:44:51.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 12193}]","[{'number': 1, 'created': '2015-04-28 15:59:15.000000000', 'files': ['tests/unit/test_swiftclient.py', 'tests/unit/test_shell.py', 'tests/unit/utils.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/a39e18ff5ac5d8705baef4328ea8433583f8d656', 'message': 'Add test for timeout being passed to keystone client\n\nExtends existing unit test for timeout being passed to get_auth\nto cover v2.0 auth when keystone client should get the timeout\nkwarg.\n\nRelated-Bug: 1447847\nChange-Id: Ie9cfc86fa2156b94b45d290ac12e3f71b20d6c4f\n'}]",0,178258,a39e18ff5ac5d8705baef4328ea8433583f8d656,8,4,1,7847,,,0,"Add test for timeout being passed to keystone client

Extends existing unit test for timeout being passed to get_auth
to cover v2.0 auth when keystone client should get the timeout
kwarg.

Related-Bug: 1447847
Change-Id: Ie9cfc86fa2156b94b45d290ac12e3f71b20d6c4f
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/58/178258/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_swiftclient.py', 'tests/unit/test_shell.py', 'tests/unit/utils.py']",3,a39e18ff5ac5d8705baef4328ea8433583f8d656,bug/1447847," class FakeKeystone(object): ''' Fake keystone client module. Returns given endpoint url and auth token. ''' def __init__(self, endpoint, token): self.calls = [] self.auth_version = None self.endpoint = endpoint self.token = token class _Client(): def __init__(self, endpoint, token, **kwargs): self.auth_token = token self.endpoint = endpoint self.service_catalog = self.ServiceCatalog(endpoint) class ServiceCatalog(object): def __init__(self, endpoint): self.calls = [] self.endpoint_url = endpoint def url_for(self, **kwargs): self.calls.append(kwargs) return self.endpoint_url def Client(self, **kwargs): self.calls.append(kwargs) self.client = self._Client(endpoint=self.endpoint, token=self.token, **kwargs) return self.client class Unauthorized(Exception): pass class AuthorizationFailure(Exception): pass class EndpointNotFound(Exception): pass def _make_fake_import_keystone_client(fake_import): def _fake_import_keystone_client(auth_version): fake_import.auth_version = auth_version return fake_import, fake_import return _fake_import_keystone_client",,74,51
openstack%2Ffuel-library~master~Ia816dad7365c68b2d1144fe315f4bafdf08d16ce,openstack/fuel-library,master,Ia816dad7365c68b2d1144fe315f4bafdf08d16ce,Switch keystone WSGI app to be run as multiprocess,MERGED,2015-05-20 20:36:33.000000000,2015-05-21 00:30:36.000000000,2015-05-21 00:29:58.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 13055}, {'_account_id': 13478}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-20 20:36:33.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/keystone/keystone.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7d21e927d5e132a9019cbed1199c5d1bd2d1f70d', 'message': 'Switch keystone WSGI app to be run as multiprocess\n\nThis commit makes apache spin up a bunch of\nkeystone processes in order to avoid race\ncondition when keystone cannot safely\ninitialize KVS region\n\nChange-Id: Ia816dad7365c68b2d1144fe315f4bafdf08d16ce\nPartial-bug: #1457037\n'}]",2,184615,7d21e927d5e132a9019cbed1199c5d1bd2d1f70d,26,6,1,8786,,,0,"Switch keystone WSGI app to be run as multiprocess

This commit makes apache spin up a bunch of
keystone processes in order to avoid race
condition when keystone cannot safely
initialize KVS region

Change-Id: Ia816dad7365c68b2d1144fe315f4bafdf08d16ce
Partial-bug: #1457037
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/15/184615/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/keystone/keystone.pp'],1,7d21e927d5e132a9019cbed1199c5d1bd2d1f70d,bug/1457037," threads => 1, workers => min(max($::processorcount,2), 24),"," threads => min(max($::processorcount,2), 24),",2,1
openstack%2Fnova~master~I4e46ee252e6b29b063bcc8204d60d670eb79daef,openstack/nova,master,I4e46ee252e6b29b063bcc8204d60d670eb79daef,devref: add information to clarify nova scope,MERGED,2015-04-29 11:43:43.000000000,2015-05-21 00:12:56.000000000,2015-05-13 05:00:30.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6962}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15674}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-04-29 11:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1e61487011e11fa70f57e7ce9ec87e43c8c7ab9', 'message': 'devref: add information to clarify nova scope\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\nWARNING: this is a work in progress\n'}, {'number': 2, 'created': '2015-05-01 09:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a0fa26996f1fe4a8d1eb849fa4c69caf48c0d83', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 3, 'created': '2015-05-01 12:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce976c06aaf5cc3ef8c748a12e902081ae3d76a3', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 4, 'created': '2015-05-04 20:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71e1cafbc0f355b210d8c601a40bb4c9dd3934ba', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 5, 'created': '2015-05-05 15:44:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/843dc94837ae22508342fa133a69151c2703fc7f', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 6, 'created': '2015-05-05 15:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e374fca27248dd2b66cb87bd2ea3ee475daa2308', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 7, 'created': '2015-05-06 08:29:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5692a008429bf05860d7fd1970b76f716c9c00d3', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 8, 'created': '2015-05-06 08:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec1dc9b11d76c561615c50a0b5bbdf9fe5f83c6f', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 9, 'created': '2015-05-07 09:43:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b865af5a6d88a1ae0e0e5dbe31014831bcf3c8ee', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 10, 'created': '2015-05-07 09:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a23df2edf1d5f66876236be01eb8a743c9f69176', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 11, 'created': '2015-05-07 09:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4729b0d9807c2ac92fa9908c48a60c8280d879c7', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 12, 'created': '2015-05-08 14:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6105a7b6eeb2ce3715d7e1384906022e427a55a', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nPart of blueprint devref-refresh-liberty\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef""}, {'number': 13, 'created': '2015-05-11 09:18:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f97fba038d9f6a167d234610a2fd91973f40c55d', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nPart of blueprint devref-refresh-liberty\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 14, 'created': '2015-05-12 09:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/415ed85c6a6a4089566dca05718b42e1651d92d2', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nPart of blueprint devref-refresh-liberty\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}, {'number': 15, 'created': '2015-05-12 23:17:28.000000000', 'files': ['doc/source/index.rst', 'doc/source/devref/project_scope.rst', 'doc/source/devref/index.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/09c2afa85b99e691fa9b4a71bd2c79c9818de6c0', 'message': ""devref: add information to clarify nova scope\n\nThis adds a document that helps clarify the scope of the Nova mission\nstatement.\n\nWe need to keep the Nova project a manageable size. Agreeing on what\nNova should focus on is a great way to make sure we grow Nova in a\nconsistent way, leaving open opportunities for other projects to do a\nbetter job of things Nova doesn't see as part of its core mission.\n\nPart of blueprint devref-refresh-liberty\n\nChange-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef\n""}]",110,178623,09c2afa85b99e691fa9b4a71bd2c79c9818de6c0,113,19,15,782,,,0,"devref: add information to clarify nova scope

This adds a document that helps clarify the scope of the Nova mission
statement.

We need to keep the Nova project a manageable size. Agreeing on what
Nova should focus on is a great way to make sure we grow Nova in a
consistent way, leaving open opportunities for other projects to do a
better job of things Nova doesn't see as part of its core mission.

Part of blueprint devref-refresh-liberty

Change-Id: I4e46ee252e6b29b063bcc8204d60d670eb79daef
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/178623/7 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/what_we_dont_do.rst', 'doc/source/devref/index.rst']",2,d1e61487011e11fa70f57e7ce9ec87e43c8c7ab9,bp/devref-refresh-liberty, what_we_dont_do,,56,0
openstack%2Fastara-horizon~stable%2Fkilo~I7b753661e08c0896f7e30976ce82ec9cc39937ff,openstack/astara-horizon,stable/kilo,I7b753661e08c0896f7e30976ce82ec9cc39937ff,"Update defaultbranch in .gitreview, bump version to 2015.1.1",MERGED,2015-05-18 18:39:29.000000000,2015-05-21 00:02:17.000000000,2015-05-21 00:02:14.000000000,"[{'_account_id': 3}, {'_account_id': 6287}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-05-18 18:39:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-horizon/commit/39e99810f341cb7201b8cff3105f8c1efccba771', 'message': 'Update defaultbranch in .gitreview\n\nChange-Id: I7b753661e08c0896f7e30976ce82ec9cc39937ff\n'}, {'number': 2, 'created': '2015-05-18 20:51:29.000000000', 'files': ['.gitreview', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/astara-horizon/commit/d5f3836a044e2f34294dd7341689b044e4221800', 'message': 'Update defaultbranch in .gitreview, bump version to 2015.1.1\n\nChange-Id: I7b753661e08c0896f7e30976ce82ec9cc39937ff\n'}]",0,184107,d5f3836a044e2f34294dd7341689b044e4221800,9,3,2,1420,,,0,"Update defaultbranch in .gitreview, bump version to 2015.1.1

Change-Id: I7b753661e08c0896f7e30976ce82ec9cc39937ff
",git fetch https://review.opendev.org/openstack/astara-horizon refs/changes/07/184107/2 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,39e99810f341cb7201b8cff3105f8c1efccba771,,defaultbranch=stable/kilo,,1,0
openstack%2Fpython-keystoneclient~master~I8daf4a5b289a460b2a5b3c1828bc4a264aad26ef,openstack/python-keystoneclient,master,I8daf4a5b289a460b2a5b3c1828bc4a264aad26ef,Access Info,ABANDONED,2015-02-28 20:51:49.000000000,2015-05-20 23:56:44.000000000,,[],"[{'number': 1, 'created': '2015-02-28 20:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/dd7fdedc7cfff4ab42d5823cf261086ba6de7195', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone\ntoken: A set of classes for the base Keystone domain model, a builder\nobject, and a sample director for creating the access info from the\npython objects produced by json parsing.\n\n Change-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n\nChange-Id: I8daf4a5b289a460b2a5b3c1828bc4a264aad26ef\n'}, {'number': 2, 'created': '2015-05-20 23:55:58.000000000', 'files': ['keystoneclient/models/__init__.py', 'keystoneclient/models/builder.py', 'keystoneclient/tests/unit/test_access_info.py', 'keystoneclient/models/access_info.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/f4ce22aa07b2e75cf9f2d6345a32a4adb241cea0', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone\ntoken: A set of classes for the base Keystone domain model, a builder\nobject, and a sample director for creating the access info from the\npython objects produced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f'}]",0,160131,f4ce22aa07b2e75cf9f2d6345a32a4adb241cea0,5,0,2,2218,,,0,"Access Info

A Strict python model for the access info represented by a keystone
token: A set of classes for the base Keystone domain model, a builder
object, and a sample director for creating the access info from the
python objects produced by json parsing.

Change-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/31/160131/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/models/__init__.py', 'keystoneclient/models/builder.py', 'keystoneclient/tests/unit/test_access_info.py', 'keystoneclient/models/access_info.py']",4,dd7fdedc7cfff4ab42d5823cf261086ba6de7195,access_info_split,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Unified in-memory access model."""""" import datetime from oslo_utils import timeutils # gap, in seconds, to determine whether the given token is about to expire STALE_TOKEN_DURATION = 30 def assert_string(obj): if not isinstance(obj, basestring): raise ValueError(""%s not a string"" % obj) return obj def assert_class(cls, obj): if type(obj) != cls: raise ValueError(""%s not of class %s "" % (type(obj).__name__, cls.__name__)) def assert_datetime(obj): assert_class(datetime.datetime, obj) if (obj.tzinfo is None): raise ValueError('Timezone information missing from datetime') def assert_is_instance(cls, obj): if not isinstance(obj, cls): raise ValueError(""%s not of class %s "" % (type(obj).__name__, cls.__name__)) class DateString(str): def __init__(self, value): assert_datetime(value) self.value = value strval = timeutils.strtime(value) super(DateString, self).__init__(strval) def __eq__(self, other): if isinstance(other, DateString): return self.value == other.value elif isinstance(other, datetime.datetime): return self.value == other elif isinstance(other, basestring): other_date = timeutils.parse_isotime(other) return self.value == other_date return False def utcoffset(self): return self.value.utcoffset() def replace(self, *args, **kwargs): return self.value.replace(*args, **kwargs) def strftime(self, format): return self.value.strftime(format) @property def tzinfo(self): return self.value.tzinfo class Immutable(object): _is_immutable = False def __setattr__(self, att, v): if self._is_immutable is False: super(Immutable, self).__setattr__(att, v) else: raise AttributeError('attempt to modify immutable object') def get(self, attr, default=None): try: return self.__dict__[attr] except KeyError: return default def __getitem__(self, attr): return self.__dict__[attr] def lock(self): self._is_immutable = True def iteritems(self): return self.__dict__.iteritems() def __iter__(self): for key in dir(self): yield key class TypeSafeList(list): def __init__(self, item_class, items): self._item_class = item_class for item in items: assert_class(self._item_class, item) self.append(item) def __setitem__(self, key, item): assert_class(self._item_class, item) super(TypeSafeList, self).__setitem__(key, item) def append(self, item): assert_class(self._item_class, item) super(TypeSafeList, self).append(item) class SubclassList(list): def __init__(self, item_class, items): self._item_class = item_class for item in items: assert_is_instance(self._item_class, item) self.append(item) def __setitem__(self, key, item): assert_is_instance(self._item_class, item) super(SubclassList, self).__setitem__(key, item) def append(self, item): assert_is_instance(self._item_class, item) super(SubclassList, self).append(item) class Domain(Immutable): def __init__(self, id, name): self.id = id self.name = name class Role(Immutable): def __init__(self, id, name): self.id = id assert_string(name) self.name = name class User(Immutable): def __init__(self, id, name, domain): self.domain = domain self.id = id self.name = name class Endpoint(Immutable): def __init__(self, id, region): if id is not None: self.id = assert_string(id) if region is not None: self.region = assert_string(region) class V3Endpoint(Endpoint): def __init__(self, id, interface, region, region_id, url): super(V3Endpoint, self).__init__(id, region) if (id is None): raise ValueError(""id must not be none for V3 endpoint"") self.interface = assert_string(interface) self.url = assert_string(url) if region_id is not None: self.region_id = assert_string(region_id) class V2Endpoint(Endpoint): # The Endpoint is a subset of these values, all of them are optional def __init__(self, id, tenantId, region, interface, publicURL, internalURL, adminURL, versionInfo, versionList, versionId): super(V2Endpoint, self).__init__(id, region) if publicURL is not None: self.publicURL = publicURL if internalURL is not None: self.internalURL = internalURL if adminURL is not None: self.adminURL = adminURL if tenantId is not None: self.tenantId = assert_string(tenantId) if interface is not None: self.interface = assert_string(interface) if versionInfo is not None: self.versionInfo = versionInfo if versionList is not None: self.versionList = versionList if versionId is not None: self.versionId = versionId class Service(Immutable): def __init__(self, id, type, name, endpoints): self.id = id self.type = type self.name = name self.endpoints = SubclassList(Endpoint, endpoints) class Catalog(TypeSafeList): def __init__(self, services): super(Catalog, self).__init__(Service, services) class Project(Immutable): def __init__(self, id, name, domain): assert_class(Domain, domain) self.id = id self.name = name self.domain = domain class Trust(Immutable): def __init__(self, id, impersonation, trustor_user_id, trustee_user_id): self.impersonation = bool(impersonation) self.id = id self.trustor_user_id = trustor_user_id self.trustee_user_id = trustee_user_id class Oauth(Immutable): def __init__(self, consumer_id, access_token_id): self.consumer_id = consumer_id self.access_token_id = access_token_id class Group(Immutable): def __init__(self, id): self.id = id class Groups(TypeSafeList): def __init__(self, groups): super(Groups, self).__init__(Group, groups) class Federation(Immutable): def __init__(self, identity_provider, protocol, groups): self.identity_provider = identity_provider self.protocol = protocol self.groups = groups class Token(Immutable): def __init__(self, user, catalog, roles, expires_at, issued_at, methods, scope, delegation=None, federation=None): assert_class(User, user) if catalog is not None: assert_class(Catalog, catalog) if isinstance(scope, Project): self.project = scope elif isinstance(scope, Domain): self.domain = scope elif scope is None: scope = None else: raise ValueError(""Scope must be project, domain, or None"") self.expires_at = DateString(expires_at) self.issued_at = DateString(issued_at) self.methods = methods self.user = user self.catalog = catalog self.roles = roles if delegation is not None: if isinstance(delegation, Trust): self.trust = delegation elif isinstance(delegation, Oauth): self.oauth = delegation if federation is not None: assert_class(Federation, federation) self.federation = federation else: self.federation = None ",,940,0
openstack%2Fnova~master~I6a1234673a82909780dc7a82d5998705342dbfc6,openstack/nova,master,I6a1234673a82909780dc7a82d5998705342dbfc6,Drop L from literal integer numbers for Python 3,MERGED,2015-05-04 16:05:31.000000000,2015-05-20 23:52:57.000000000,2015-05-15 17:34:41.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9107}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14358}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-04 16:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ab22cba3ec07e8c916bf38692d14af07d5eec7f', 'message': 'Drop L from literal integer numbers for Python 3\n\nOn Python 3, 123L is a syntax error. Replace 123L with 123 to get code working\non Python 2 and Python 3.\n\nThis patch was generated by the following tool (revision 9f3076ad5e09) using\nthe ""long"" operation:\nhttps://bitbucket.org/haypo/misc/src/tip/python/sixer.py\n\nManual change:\n\n* In nova/tests/unit/objects/test_fields.py, we explicitly want to check that\n  long integers are supported as well. Keep the test on long, but replace\n  1L with long(1) to avoid the syntax error on Python 3.\n\nBlueprint nova-python3\n\nChange-Id: I6a1234673a82909780dc7a82d5998705342dbfc6\n'}, {'number': 2, 'created': '2015-05-11 09:16:02.000000000', 'files': ['nova/tests/unit/virt/hyperv/test_hostutils.py', 'nova/tests/unit/virt/libvirt/test_host.py', 'nova/tests/unit/objects/test_fields.py', 'nova/tests/unit/virt/hyperv/test_vhdutils.py', 'nova/virt/fake.py', 'nova/tests/unit/compute/monitors/test_cpu_monitor.py', 'nova/tests/unit/virt/hyperv/test_vhdutilsv2.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/virt/xenapi/test_vm_utils.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9bc21deea75abc23388c2816369947dbfd673e57', 'message': 'Drop L from literal integer numbers for Python 3\n\nOn Python 3, 123L is a syntax error. Replace 123L with 123 to get code working\non Python 2 and Python 3.\n\nThis patch was generated by the following tool (revision 9f3076ad5e09) using\nthe ""long"" operation:\nhttps://bitbucket.org/haypo/misc/src/tip/python/sixer.py\n\nManual change:\n\n* In nova/tests/unit/objects/test_fields.py, we explicitly want to check that\n  long integers are supported as well. Keep the test on long, but replace\n  1L with long(1) to avoid the syntax error on Python 3.\n\nBlueprint nova-python3\nChange-Id: I6a1234673a82909780dc7a82d5998705342dbfc6\n'}]",0,179828,9bc21deea75abc23388c2816369947dbfd673e57,35,16,2,9107,,,0,"Drop L from literal integer numbers for Python 3

On Python 3, 123L is a syntax error. Replace 123L with 123 to get code working
on Python 2 and Python 3.

This patch was generated by the following tool (revision 9f3076ad5e09) using
the ""long"" operation:
https://bitbucket.org/haypo/misc/src/tip/python/sixer.py

Manual change:

* In nova/tests/unit/objects/test_fields.py, we explicitly want to check that
  long integers are supported as well. Keep the test on long, but replace
  1L with long(1) to avoid the syntax error on Python 3.

Blueprint nova-python3
Change-Id: I6a1234673a82909780dc7a82d5998705342dbfc6
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/179828/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/hyperv/test_hostutils.py', 'nova/tests/unit/objects/test_fields.py', 'nova/tests/unit/virt/hyperv/test_vhdutils.py', 'nova/virt/fake.py', 'nova/tests/unit/compute/monitors/test_cpu_monitor.py', 'nova/tests/unit/virt/hyperv/test_vhdutilsv2.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/virt/xenapi/test_vm_utils.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",10,6ab22cba3ec07e8c916bf38692d14af07d5eec7f,bp/nova-python3," return (169, 688640, 0, 0, -1) return (4408, 82, 0, 0, 0, 0, 0, 0) return {'actual': 220160, 'rss': 200164} return 280160 expect = {'vda_read': 688640, 'vda_read_req': 169, 'vda_write': 0, 'vda_write_req': 0, 'vda_errors': -1, 'vdb_read': 688640, 'vdb_read_req': 169, 'vdb_write': 0, 'vdb_write_req': 0, 'vdb_errors': -1, 'memory': 280160, 'memory-actual': 220160, 'memory-rss': 200164, 'vnet0_rx': 4408, 'vnet0_rx_drop': 0, 'vnet0_rx_errors': 0, 'vnet0_rx_packets': 82, 'vnet0_tx': 0, 'vnet0_tx_drop': 0, 'vnet0_tx_errors': 0, 'vnet0_tx_packets': 0, 'read_bytes': 688640, 'read_requests': 169, 'write_bytes': 0, 'write_requests': 0}, 'read_bytes': 688640, 'read_requests': 169, 'write_bytes': 0, 'write_requests': 0}], 'rx_drop': 0, 'rx_errors': 0, 'rx_octets': 4408, 'rx_packets': 82, 'tx_drop': 0, 'tx_errors': 0, 'tx_octets': 0, 'tx_packets': 0}], return ([(0, 1, 15340000000, 0), (1, 1, 1640000000, 0), (2, 1, 3040000000, 0), (3, 1, 1420000000, 0)], return (4408, 82, 0, 0, 0, 0, 0, 0) return {'actual': 220160, 'rss': 200164} return 280160 expect = {'cpu0_time': 15340000000, 'cpu1_time': 1640000000, 'cpu2_time': 3040000000, 'cpu3_time': 1420000000, 'memory': 280160, 'memory-actual': 220160, 'memory-rss': 200164, 'vnet0_rx': 4408, 'vnet0_rx_drop': 0, 'vnet0_rx_errors': 0, 'vnet0_rx_packets': 82, 'vnet0_tx': 0, 'vnet0_tx_drop': 0, 'vnet0_tx_errors': 0, 'vnet0_tx_packets': 0, 'cpu_details': [{'time': 15340000000}, {'time': 1640000000}, {'time': 3040000000}, {'time': 1420000000}], 'rx_drop': 0, 'rx_errors': 0, 'rx_octets': 4408, 'rx_packets': 82, 'tx_drop': 0, 'tx_errors': 0, 'tx_octets': 0, 'tx_packets': 0}], return ([(0, 1, 15340000000, 0), (1, 1, 1640000000, 0), (2, 1, 3040000000, 0), (3, 1, 1420000000, 0)], return (169, 688640, 0, 0, -1) return {'actual': 220160, 'rss': 200164} return 280160 expect = {'cpu0_time': 15340000000, 'cpu1_time': 1640000000, 'cpu2_time': 3040000000, 'cpu3_time': 1420000000, 'vda_read': 688640, 'vda_read_req': 169, 'vda_write': 0, 'vda_write_req': 0, 'vda_errors': -1, 'vdb_read': 688640, 'vdb_read_req': 169, 'vdb_write': 0, 'vdb_write_req': 0, 'vdb_errors': -1, 'memory': 280160, 'memory-actual': 220160, 'memory-rss': 200164, 'cpu_details': [{'time': 15340000000}, {'time': 1640000000}, {'time': 3040000000}, {'time': 1420000000}], 'read_bytes': 688640, 'read_requests': 169, 'write_bytes': 0, 'write_requests': 0}, 'read_bytes': 688640, 'read_requests': 169, 'write_bytes': 0, 'write_requests': 0}], return ([(0, 1, 15340000000, 0), (1, 1, 1640000000, 0), (2, 1, 3040000000, 0), (3, 1, 1420000000, 0)], return (169, 688640, 0, 0, -1) return (4408, 82, 0, 0, 0, 0, 0, 0) return 280160 expect = {'cpu0_time': 15340000000, 'cpu1_time': 1640000000, 'cpu2_time': 3040000000, 'cpu3_time': 1420000000, 'vda_read': 688640, 'vda_read_req': 169, 'vda_write': 0, 'vda_write_req': 0, 'vda_errors': -1, 'vdb_read': 688640, 'vdb_read_req': 169, 'vdb_write': 0, 'vdb_write_req': 0, 'vdb_errors': -1, 'memory': 280160, 'vnet0_rx': 4408, 'vnet0_rx_drop': 0, 'vnet0_rx_errors': 0, 'vnet0_rx_packets': 82, 'vnet0_tx': 0, 'vnet0_tx_drop': 0, 'vnet0_tx_errors': 0, 'vnet0_tx_packets': 0, 'cpu_details': [{'time': 15340000000}, {'time': 1640000000}, {'time': 3040000000}, {'time': 1420000000}], 'read_bytes': 688640, 'read_requests': 169, 'write_bytes': 0, 'write_requests': 0}, 'read_bytes': 688640, 'read_requests': 169, 'write_bytes': 0, 'write_requests': 0}], 'rx_drop': 0, 'rx_errors': 0, 'rx_octets': 4408, 'rx_packets': 82, 'tx_drop': 0, 'tx_errors': 0, 'tx_octets': 0, 'tx_packets': 0}], return ([(0, 1, 15340000000, 0), (1, 1, 1640000000, 0), (2, 1, 3040000000, 0), (3, 1, 1420000000, 0)], return (169, 688640, 0, 0, -1) return (4408, 82, 0, 0, 0, 0, 0, 0) return {'actual': 220160, 'rss': 200164} return 280160 expect = {'cpu0_time': 15340000000, 'cpu1_time': 1640000000, 'cpu2_time': 3040000000, 'cpu3_time': 1420000000, 'vda_read': 688640, 'vda_read_req': 169, 'vda_write': 0, 'vda_write_req': 0, 'vda_errors': -1, 'vdb_read': 688640, 'vdb_read_req': 169, 'vdb_write': 0, 'vdb_write_req': 0, 'vdb_errors': -1, 'memory': 280160, 'memory-actual': 220160, 'memory-rss': 200164, 'vnet0_rx': 4408, 'vnet0_rx_drop': 0, 'vnet0_rx_errors': 0, 'vnet0_rx_packets': 82, 'vnet0_tx': 0, 'vnet0_tx_drop': 0, 'vnet0_tx_errors': 0, 'vnet0_tx_packets': 0, 'cpu_details': [{'time': 15340000000}, {'time': 1640000000}, {'time': 3040000000}, {'time': 1420000000}], 'read_bytes': 688640, 'read_requests': 169, 'write_bytes': 0, 'write_requests': 0}, 'read_bytes': 688640, 'read_requests': 169, 'write_bytes': 0, 'write_requests': 0}], 'rx_drop': 0, 'rx_errors': 0, 'rx_octets': 4408, 'rx_packets': 82, 'tx_drop': 0, 'tx_errors': 0, 'tx_octets': 0, 'tx_packets': 0}], return ([(0, 1, 15340000000, 0), (1, 1, 1640000000, 0), (2, 1, 3040000000, 0), (3, 1, 1420000000, 0)], return (169, 688640, 0, 0, -1) return (4408, 82, 0, 0, 0, 0, 0, 0) return {'actual': 220160, 'rss': 200164} return 280160 expect = {'cpu0_time': 15340000000, 'cpu1_time': 1640000000, 'cpu2_time': 3040000000, 'cpu3_time': 1420000000, 'vda_read': 688640, 'vda_read_req': 169, 'vda_write': 0, 'vda_write_req': 0, 'vda_errors': -1, 'vdb_read': 688640, 'vdb_read_req': 169, 'vdb_write': 0, 'vdb_write_req': 0, 'vdb_errors': -1, 'memory': 280160, 'memory-actual': 220160, 'memory-rss': 200164, 'vnet0_rx': 4408, 'vnet0_rx_drop': 0, 'vnet0_rx_errors': 0, 'vnet0_rx_packets': 82, 'vnet0_tx': 0, 'vnet0_tx_drop': 0, 'vnet0_tx_errors': 0, 'vnet0_tx_packets': 0, 'br0_rx': 4408, 'br0_rx_drop': 0, 'br0_rx_errors': 0, 'br0_rx_packets': 82, 'br0_tx': 0, 'br0_tx_drop': 0, 'br0_tx_errors': 0, 'br0_tx_packets': 0, 'cpu_details': [{'time': 15340000000}, {'time': 1640000000}, {'time': 3040000000}, {'time': 1420000000}], 'read_bytes': 688640, 'read_requests': 169, 'write_bytes': 0, 'write_requests': 0}, 'read_bytes': 688640, 'read_requests': 169, 'write_bytes': 0, 'write_requests': 0}], 'rx_drop': 0, 'rx_errors': 0, 'rx_octets': 4408, 'rx_packets': 82, 'tx_drop': 0, 'tx_errors': 0, 'tx_octets': 0, 'tx_packets': 0}, 'rx_drop': 0, 'rx_errors': 0, 'rx_octets': 4408, 'rx_packets': 82, 'tx_drop': 0, 'tx_errors': 0, 'tx_octets': 0, 'tx_packets': 0}], arch.X86_64, 15814, 8, 1208, 1, 1, 4, 2] arch.X86_64, 15814, 8, 1208, 1, 1, 4, 2] return (169, 688640, 0, 0, -1) 'rd_bytes': 688640, 'wr_req': 0, 'rd_req': 169, 'wr_bytes': 0}, 'rd_bytes': 688640, 'wr_req': 0, 'rd_req': 169, 'wr_bytes': 0}]"," return (169L, 688640L, 0L, 0L, -1L) return (4408L, 82L, 0L, 0L, 0L, 0L, 0L, 0L) return {'actual': 220160L, 'rss': 200164L} return 280160L expect = {'vda_read': 688640L, 'vda_read_req': 169L, 'vda_write': 0L, 'vda_write_req': 0L, 'vda_errors': -1L, 'vdb_read': 688640L, 'vdb_read_req': 169L, 'vdb_write': 0L, 'vdb_write_req': 0L, 'vdb_errors': -1L, 'memory': 280160L, 'memory-actual': 220160L, 'memory-rss': 200164L, 'vnet0_rx': 4408L, 'vnet0_rx_drop': 0L, 'vnet0_rx_errors': 0L, 'vnet0_rx_packets': 82L, 'vnet0_tx': 0L, 'vnet0_tx_drop': 0L, 'vnet0_tx_errors': 0L, 'vnet0_tx_packets': 0L, 'read_bytes': 688640L, 'read_requests': 169L, 'write_bytes': 0L, 'write_requests': 0L}, 'read_bytes': 688640L, 'read_requests': 169L, 'write_bytes': 0L, 'write_requests': 0L}], 'rx_drop': 0L, 'rx_errors': 0L, 'rx_octets': 4408L, 'rx_packets': 82L, 'tx_drop': 0L, 'tx_errors': 0L, 'tx_octets': 0L, 'tx_packets': 0L}], return ([(0, 1, 15340000000L, 0), (1, 1, 1640000000L, 0), (2, 1, 3040000000L, 0), (3, 1, 1420000000L, 0)], return (4408L, 82L, 0L, 0L, 0L, 0L, 0L, 0L) return {'actual': 220160L, 'rss': 200164L} return 280160L expect = {'cpu0_time': 15340000000L, 'cpu1_time': 1640000000L, 'cpu2_time': 3040000000L, 'cpu3_time': 1420000000L, 'memory': 280160L, 'memory-actual': 220160L, 'memory-rss': 200164L, 'vnet0_rx': 4408L, 'vnet0_rx_drop': 0L, 'vnet0_rx_errors': 0L, 'vnet0_rx_packets': 82L, 'vnet0_tx': 0L, 'vnet0_tx_drop': 0L, 'vnet0_tx_errors': 0L, 'vnet0_tx_packets': 0L, 'cpu_details': [{'time': 15340000000L}, {'time': 1640000000L}, {'time': 3040000000L}, {'time': 1420000000L}], 'rx_drop': 0L, 'rx_errors': 0L, 'rx_octets': 4408L, 'rx_packets': 82L, 'tx_drop': 0L, 'tx_errors': 0L, 'tx_octets': 0L, 'tx_packets': 0L}], return ([(0, 1, 15340000000L, 0), (1, 1, 1640000000L, 0), (2, 1, 3040000000L, 0), (3, 1, 1420000000L, 0)], return (169L, 688640L, 0L, 0L, -1L) return {'actual': 220160L, 'rss': 200164L} return 280160L expect = {'cpu0_time': 15340000000L, 'cpu1_time': 1640000000L, 'cpu2_time': 3040000000L, 'cpu3_time': 1420000000L, 'vda_read': 688640L, 'vda_read_req': 169L, 'vda_write': 0L, 'vda_write_req': 0L, 'vda_errors': -1L, 'vdb_read': 688640L, 'vdb_read_req': 169L, 'vdb_write': 0L, 'vdb_write_req': 0L, 'vdb_errors': -1L, 'memory': 280160L, 'memory-actual': 220160L, 'memory-rss': 200164L, 'cpu_details': [{'time': 15340000000L}, {'time': 1640000000L}, {'time': 3040000000L}, {'time': 1420000000L}], 'read_bytes': 688640L, 'read_requests': 169L, 'write_bytes': 0L, 'write_requests': 0L}, 'read_bytes': 688640L, 'read_requests': 169L, 'write_bytes': 0L, 'write_requests': 0L}], return ([(0, 1, 15340000000L, 0), (1, 1, 1640000000L, 0), (2, 1, 3040000000L, 0), (3, 1, 1420000000L, 0)], return (169L, 688640L, 0L, 0L, -1L) return (4408L, 82L, 0L, 0L, 0L, 0L, 0L, 0L) return 280160L expect = {'cpu0_time': 15340000000L, 'cpu1_time': 1640000000L, 'cpu2_time': 3040000000L, 'cpu3_time': 1420000000L, 'vda_read': 688640L, 'vda_read_req': 169L, 'vda_write': 0L, 'vda_write_req': 0L, 'vda_errors': -1L, 'vdb_read': 688640L, 'vdb_read_req': 169L, 'vdb_write': 0L, 'vdb_write_req': 0L, 'vdb_errors': -1L, 'memory': 280160L, 'vnet0_rx': 4408L, 'vnet0_rx_drop': 0L, 'vnet0_rx_errors': 0L, 'vnet0_rx_packets': 82L, 'vnet0_tx': 0L, 'vnet0_tx_drop': 0L, 'vnet0_tx_errors': 0L, 'vnet0_tx_packets': 0L, 'cpu_details': [{'time': 15340000000L}, {'time': 1640000000L}, {'time': 3040000000L}, {'time': 1420000000L}], 'read_bytes': 688640L, 'read_requests': 169L, 'write_bytes': 0L, 'write_requests': 0L}, 'read_bytes': 688640L, 'read_requests': 169L, 'write_bytes': 0L, 'write_requests': 0L}], 'rx_drop': 0L, 'rx_errors': 0L, 'rx_octets': 4408L, 'rx_packets': 82L, 'tx_drop': 0L, 'tx_errors': 0L, 'tx_octets': 0L, 'tx_packets': 0L}], return ([(0, 1, 15340000000L, 0), (1, 1, 1640000000L, 0), (2, 1, 3040000000L, 0), (3, 1, 1420000000L, 0)], return (169L, 688640L, 0L, 0L, -1L) return (4408L, 82L, 0L, 0L, 0L, 0L, 0L, 0L) return {'actual': 220160L, 'rss': 200164L} return 280160L expect = {'cpu0_time': 15340000000L, 'cpu1_time': 1640000000L, 'cpu2_time': 3040000000L, 'cpu3_time': 1420000000L, 'vda_read': 688640L, 'vda_read_req': 169L, 'vda_write': 0L, 'vda_write_req': 0L, 'vda_errors': -1L, 'vdb_read': 688640L, 'vdb_read_req': 169L, 'vdb_write': 0L, 'vdb_write_req': 0L, 'vdb_errors': -1L, 'memory': 280160L, 'memory-actual': 220160L, 'memory-rss': 200164L, 'vnet0_rx': 4408L, 'vnet0_rx_drop': 0L, 'vnet0_rx_errors': 0L, 'vnet0_rx_packets': 82L, 'vnet0_tx': 0L, 'vnet0_tx_drop': 0L, 'vnet0_tx_errors': 0L, 'vnet0_tx_packets': 0L, 'cpu_details': [{'time': 15340000000L}, {'time': 1640000000L}, {'time': 3040000000L}, {'time': 1420000000L}], 'read_bytes': 688640L, 'read_requests': 169L, 'write_bytes': 0L, 'write_requests': 0L}, 'read_bytes': 688640L, 'read_requests': 169L, 'write_bytes': 0L, 'write_requests': 0L}], 'rx_drop': 0L, 'rx_errors': 0L, 'rx_octets': 4408L, 'rx_packets': 82L, 'tx_drop': 0L, 'tx_errors': 0L, 'tx_octets': 0L, 'tx_packets': 0L}], return ([(0, 1, 15340000000L, 0), (1, 1, 1640000000L, 0), (2, 1, 3040000000L, 0), (3, 1, 1420000000L, 0)], return (169L, 688640L, 0L, 0L, -1L) return (4408L, 82L, 0L, 0L, 0L, 0L, 0L, 0L) return {'actual': 220160L, 'rss': 200164L} return 280160L expect = {'cpu0_time': 15340000000L, 'cpu1_time': 1640000000L, 'cpu2_time': 3040000000L, 'cpu3_time': 1420000000L, 'vda_read': 688640L, 'vda_read_req': 169L, 'vda_write': 0L, 'vda_write_req': 0L, 'vda_errors': -1L, 'vdb_read': 688640L, 'vdb_read_req': 169L, 'vdb_write': 0L, 'vdb_write_req': 0L, 'vdb_errors': -1L, 'memory': 280160L, 'memory-actual': 220160L, 'memory-rss': 200164L, 'vnet0_rx': 4408L, 'vnet0_rx_drop': 0L, 'vnet0_rx_errors': 0L, 'vnet0_rx_packets': 82L, 'vnet0_tx': 0L, 'vnet0_tx_drop': 0L, 'vnet0_tx_errors': 0L, 'vnet0_tx_packets': 0L, 'br0_rx': 4408L, 'br0_rx_drop': 0L, 'br0_rx_errors': 0L, 'br0_rx_packets': 82L, 'br0_tx': 0L, 'br0_tx_drop': 0L, 'br0_tx_errors': 0L, 'br0_tx_packets': 0L, 'cpu_details': [{'time': 15340000000L}, {'time': 1640000000L}, {'time': 3040000000L}, {'time': 1420000000L}], 'read_bytes': 688640L, 'read_requests': 169L, 'write_bytes': 0L, 'write_requests': 0L}, 'read_bytes': 688640L, 'read_requests': 169L, 'write_bytes': 0L, 'write_requests': 0L}], 'rx_drop': 0L, 'rx_errors': 0L, 'rx_octets': 4408L, 'rx_packets': 82L, 'tx_drop': 0L, 'tx_errors': 0L, 'tx_octets': 0L, 'tx_packets': 0L}, 'rx_drop': 0L, 'rx_errors': 0L, 'rx_octets': 4408L, 'rx_packets': 82L, 'tx_drop': 0L, 'tx_errors': 0L, 'tx_octets': 0L, 'tx_packets': 0L}], arch.X86_64, 15814L, 8, 1208, 1, 1, 4, 2] arch.X86_64, 15814L, 8, 1208, 1, 1, 4, 2] return (169L, 688640L, 0L, 0L, -1L) 'rd_bytes': 688640L, 'wr_req': 0L, 'rd_req': 169L, 'wr_bytes': 0L}, 'rd_bytes': 688640L, 'wr_req': 0L, 'rd_req': 169L, 'wr_bytes': 0L}]",326,323
openstack%2Fpython-keystoneclient~master~Id34261f4a21662b374bb2eff4b9128d0ffb31f2f,openstack/python-keystoneclient,master,Id34261f4a21662b374bb2eff4b9128d0ffb31f2f,Access Info,ABANDONED,2014-12-02 20:13:46.000000000,2015-05-20 23:52:29.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 11333}, {'_account_id': 13161}]","[{'number': 1, 'created': '2014-12-02 20:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/1b3f61c848d2de92e0fb16e791180015411bea80', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 2, 'created': '2014-12-03 23:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/fa65a173bb94b5828cc63aeb39cd671898b3b294', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 3, 'created': '2014-12-04 22:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/a994a7f857ec2c547c24ac29f8ffed7b2bf63283', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 4, 'created': '2014-12-10 16:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/fa52b0a90bc1a5fdccb352548ae6a1bfec2c6a6f', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 5, 'created': '2015-01-25 14:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/58536662eed0cfad04512922a8a59a58450f30fe', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 6, 'created': '2015-01-25 16:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/1b19ca37da4bc529e9fe768329075e56e6a5ad8b', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 7, 'created': '2015-01-30 20:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/e3ee4a8ad18a365f6662f7055acd4f65650080b6', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nIncorporates unrelated change to CMS to get pep8 to pass\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 8, 'created': '2015-02-09 19:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/4694df3481c40676d3d312b11c31d0ec9ec78eb5', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nIncorporates unrelated change to CMS to get pep8 to pass\n\npartially implements bp token-provider-cleanup\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 9, 'created': '2015-02-11 21:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/ee1c0875b14e060d0ab4e82e854928ba7d837d01', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nIncorporates unrelated change to CMS to get pep8 to pass\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 10, 'created': '2015-02-12 04:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/98dc59ce3c8d2cde53c52ef0c8024e3598a941db', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nIncorporates unrelated change to CMS to get pep8 to pass\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 11, 'created': '2015-02-13 04:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/38094d51dfbc867dc44d0e74cf9a4dab6c09f9c5', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nIncorporates unrelated change to CMS to get pep8 to pass\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 12, 'created': '2015-02-18 03:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/f8d82f60c9800952943c8f3e73f064943e59d12e', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone token.\nContains a set of classes for the base Keystone domain model, a builder object,\nand a sample director for creating the access info from the python objects\nproduced by json parsing.\n\nIncorporates unrelated change to CMS to get pep8 to pass\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 13, 'created': '2015-02-28 20:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/a62f81d2a39a1fb1e849b7d2d68608a7265b0196', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone\ntoken:  A set of classes for the base Keystone domain model, a builder\nobject, and a sample director for creating the access info from the\npython objects produced by json parsing.  Only to replace V3 tokens, as\nmuch of the usage of V2,0 Tkkens is historical and depends on deep\nknowledge of the token layout as a dictionary.\n\nIncorporates unrelated change to CMS to get pep8 to pass\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 14, 'created': '2015-02-28 21:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/f92355243590815faf1fe254a708c2a61542bcff', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone\ntoken: A set of classes for the base Keystone domain model, a builder\nobject, and a sample director for creating the access info from the\npython objects produced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 15, 'created': '2015-03-02 03:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/20b552e215428da4f7f120935f9d08175337ebb6', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone\ntoken: A set of classes for the base Keystone domain model, a builder\nobject, and a sample director for creating the access info from the\npython objects produced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 16, 'created': '2015-03-02 15:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/afa8eea06ef616e715c9e2bcbfa1b9d3f9ddbb58', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone\ntoken: A set of classes for the base Keystone domain model, a builder\nobject, and a sample director for creating the access info from the\npython objects produced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 17, 'created': '2015-04-01 15:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/e7abc0ea01c57c3fea3d28aba11a9f7f266036e0', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone\ntoken: A set of classes for the base Keystone domain model, a builder\nobject, and a sample director for creating the access info from the\npython objects produced by json parsing.\n\nblueprint unified-access-info\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 18, 'created': '2015-04-07 02:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/2cf3fdc40ae03f10a65cf9531cd72cf5fc90486d', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone\ntoken: A set of classes for the base Keystone domain model, a builder\nobject, and a sample director for creating the access info from the\npython objects produced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 19, 'created': '2015-04-07 03:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/2c308c2293804cbe89a5c71b40fcce554a670872', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone\ntoken: A set of classes for the base Keystone domain model, a builder\nobject, and a sample director for creating the access info from the\npython objects produced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 20, 'created': '2015-04-22 15:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/6763fa4c3d04d744f650dd05e85fabc07db8c48a', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone\ntoken: A set of classes for the base Keystone domain model, a builder\nobject, and a sample director for creating the access info from the\npython objects produced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}, {'number': 21, 'created': '2015-04-22 17:10:31.000000000', 'files': ['keystoneclient/models/__init__.py', 'examples/pki/cms/auth_v3_token_unscoped.json', 'keystoneclient/models/builder.py', 'examples/pki/cms/auth_token_v2_scoped.json', 'examples/pki/cms/auth_v3_token_project_scoped.json', 'keystoneclient/tests/unit/test_access_info.py', 'examples/pki/cms/auth_v3_token_domain_scoped.json', 'keystoneclient/tests/test_access_info.py', 'keystoneclient/models/access_info.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/e70a7babdc1bed15bf57b3f90707fcae9e6d3656', 'message': 'Access Info\n\nA Strict python model for the access info represented by a keystone\ntoken: A set of classes for the base Keystone domain model, a builder\nobject, and a sample director for creating the access info from the\npython objects produced by json parsing.\n\nChange-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f\n'}]",103,138519,e70a7babdc1bed15bf57b3f90707fcae9e6d3656,71,16,21,2218,,,0,"Access Info

A Strict python model for the access info represented by a keystone
token: A set of classes for the base Keystone domain model, a builder
object, and a sample director for creating the access info from the
python objects produced by json parsing.

Change-Id: Id34261f4a21662b374bb2eff4b9128d0ffb31f2f
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/19/138519/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/models/__init__.py', 'keystoneclient/models/builder.py', 'keystoneclient/tests/test_access_info.py', 'keystoneclient/models/access_info.py']",4,1b3f61c848d2de92e0fb16e791180015411bea80,access_info_split,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Unified in-memory access model."""""" def assert_class(cls, obj): if type(obj) != cls: raise ValueError(""%s not of class %s "" % (type(obj).__name__, cls.__name__)) class Immutable(object): _is_immutable = False def __setattr__(self, att, v): if self._is_immutable is False: super(Immutable, self).__setattr__(att, v) else: raise AttributeError('attempt to modify immutable object') def __getitem__(self, attr): return self.__dict__[attr] def lock(self): self._is_immutable = True class TypeSafeList(list): def __init__(self, item_class, items): self._item_class = item_class for item in items: assert_class(self._item_class, item) self.append(item) def __setitem__(self, key, item): assert_class(self._item_class, item) super(TypeSafeList, self).__setitem__(key, item) def append(self, item): assert_class(self._item_class, item) super(TypeSafeList, self).append(item) class Domain(Immutable): def __init__(self, id, name): self.id = id self.name = name class Role(Immutable): def __init__(self, id, name): self.id = id self.name = name class User(Immutable): def __init__(self, id, name, domain): assert_class(Domain, domain) self.domain = domain self.id = id self.name = name class Endpoint(Immutable): def __init__(self, id, interface, region, url): self.id = id self.interface = interface self.region = region self.url = url class Service(Immutable): def __init__(self, id, type, name, endpoints): self.id = id self.type = type self.name = name self.endpoints = TypeSafeList(Endpoint, endpoints) class Catalog(TypeSafeList): def __init__(self, services): super(Catalog, self).__init__(Service, services) class Project(Immutable): def __init__(self, id, name, domain): assert_class(Domain, domain) self.id = id self.name = name self.domain = domain class Token(Immutable): def __init__(self, user, catalog, roles, expires_at, issued_at, methods, scope): assert_class(User, user) assert_class(Catalog, catalog) if isinstance(scope, Project): self.project = scope elif isinstance(scope, Domain): self.domain = scope elif scope is None: scope = None else: raise ValueError(""Scope must be project, domain, or None"") self.expires_at = expires_at self.issued_at = issued_at self.methods = methods self.user = user self.catalog = catalog self.roles = roles def token_to_auth_context(self): auth_context = {'token': self, 'is_delegated_auth': False} auth_context['user_id'] = self.user.id if self.project_scoped: auth_context['project_id'] = self.project.id elif self.domain_scoped: auth_context['domain_id'] = self.domain.id if self.trust_scoped: auth_context['is_delegated_auth'] = True auth_context['trust_id'] = self.trust.id auth_context['trustor_id'] = self.trust.trustor_user_id auth_context['trustee_id'] = self.trust.trustee_user_id else: auth_context['trust_id'] = None auth_context['trustor_id'] = None auth_context['trustee_id'] = None roles = self.role_names if roles: auth_context['roles'] = roles if self.oauth_scoped: auth_context['is_delegated_auth'] = True auth_context['consumer_id'] = self.oauth.consumer_id auth_context['access_token_id'] = self.oauth.access_token_id if self.is_federated_user: auth_context['group_ids'] = self.federation.group_ids return auth_context ",,532,0
openstack%2Fkeystone~master~I52ee09f15130e15e25dd6e64bfdee1f480dbc6ed,openstack/keystone,master,I52ee09f15130e15e25dd6e64bfdee1f480dbc6ed,Refactor deprecations tests,MERGED,2015-04-24 19:56:51.000000000,2015-05-20 23:31:42.000000000,2015-05-20 23:31:40.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 9142}, {'_account_id': 13063}]","[{'number': 1, 'created': '2015-04-24 19:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ffa4f52974bc3382ba75c43fd72be923005693cf', 'message': ""Refactor deprecations tests\n\n- rename to make the name reveal the test's intentions\n- simplify the implementation\n\nChange-Id: I52ee09f15130e15e25dd6e64bfdee1f480dbc6ed\n""}, {'number': 2, 'created': '2015-04-25 00:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9f9d6fea9bc0dce3339a3a86e7a03ff43305fda7', 'message': ""Refactor deprecations tests\n\n- rename to make the name reveal the test's intentions\n- simplify the implementation\n\nChange-Id: I52ee09f15130e15e25dd6e64bfdee1f480dbc6ed\n""}, {'number': 3, 'created': '2015-04-29 20:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6480ade9604d7d41b3886f3d775cf3bfcdb8371a', 'message': ""Refactor deprecations tests\n\n- rename to make the name reveal the test's intentions\n- simplify the implementation\n\nChange-Id: I52ee09f15130e15e25dd6e64bfdee1f480dbc6ed\n""}, {'number': 4, 'created': '2015-05-08 11:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b8cf05d94094a4f8c270dfcb62244bad66a815cf', 'message': ""Refactor deprecations tests\n\n- rename to make the name reveal the test's intentions\n- simplify the implementation\n\nChange-Id: I52ee09f15130e15e25dd6e64bfdee1f480dbc6ed\n""}, {'number': 5, 'created': '2015-05-08 11:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b5d673cad9afbd38819149429d94901fd01dc931', 'message': ""Refactor deprecations tests\n\n- rename to make the name reveal the test's intentions\n- simplify the implementation\n\nChange-Id: I52ee09f15130e15e25dd6e64bfdee1f480dbc6ed\n""}, {'number': 6, 'created': '2015-05-20 21:51:25.000000000', 'files': ['keystone/tests/unit/tests/test_core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b18f8d96a579a6e736a0b1d7e19c54502db40102', 'message': ""Refactor deprecations tests\n\n- rename to make the name reveal the test's intentions\n- simplify the implementation\n\nChange-Id: I52ee09f15130e15e25dd6e64bfdee1f480dbc6ed\n""}]",6,177416,b18f8d96a579a6e736a0b1d7e19c54502db40102,26,8,6,7725,,,0,"Refactor deprecations tests

- rename to make the name reveal the test's intentions
- simplify the implementation

Change-Id: I52ee09f15130e15e25dd6e64bfdee1f480dbc6ed
",git fetch https://review.opendev.org/openstack/keystone refs/changes/16/177416/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/tests/test_core.py'],1,ffa4f52974bc3382ba75c43fd72be923005693cf,bp/python3," def test_deprecation_warnings_are_raised_as_exceptions_in_tests(self): self.assertThat( lambda: warnings.warn('this is deprecated', DeprecationWarning), matchers.raises(DeprecationWarning))"," def test_deprecations(self): # If any deprecation warnings occur during testing it's raised as # exception. def use_deprecated(): warnings.warn('this is deprecated', DeprecationWarning) self.assertThat(use_deprecated, matchers.raises(DeprecationWarning))",4,8
openstack%2Fos-brick~master~Ia859a4c4661995af21ede8ea75cd772eba35978d,openstack/os-brick,master,Ia859a4c4661995af21ede8ea75cd772eba35978d,Added a unit test for masking iscsiadm passwords,MERGED,2015-05-08 20:52:44.000000000,2015-05-20 23:10:47.000000000,2015-05-20 23:10:47.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 5997}, {'_account_id': 11904}]","[{'number': 1, 'created': '2015-05-08 20:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/7bcb7eda10e9373abf7bd702e4f20e8c89acf63a', 'message': 'Added a unit test for masking iscsiadm passwords\n\nThis patch adds a unit test to make sure that\nthe ISCSIConnector is masking passwords in the\nLOG output for _run_iscsiadm\n\nChange-Id: Ia859a4c4661995af21ede8ea75cd772eba35978d\n'}, {'number': 2, 'created': '2015-05-14 16:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/77b07ebe6fe06f4d132d2be9b879de8f84f5f2d5', 'message': 'Added a unit test for masking iscsiadm passwords\n\nThis patch adds a unit test to make sure that\nthe ISCSIConnector is masking passwords in the\nLOG output for _run_iscsiadm\n\nChange-Id: Ia859a4c4661995af21ede8ea75cd772eba35978d\n'}, {'number': 3, 'created': '2015-05-14 18:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/eb078d884a0567f7ea8ee94487cfc80d24b2bde8', 'message': 'Added a unit test for masking iscsiadm passwords\n\nThis patch adds a unit test to make sure that\nthe ISCSIConnector is masking passwords in the\nLOG output for _run_iscsiadm\n\nChange-Id: Ia859a4c4661995af21ede8ea75cd772eba35978d\n'}, {'number': 4, 'created': '2015-05-14 20:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/194534831f93b331e2f197ba946820431a85c0c6', 'message': 'Added a unit test for masking iscsiadm passwords\n\nThis patch adds a unit test to make sure that\nthe ISCSIConnector is masking passwords in the\nLOG output for _run_iscsiadm\n\nChange-Id: Ia859a4c4661995af21ede8ea75cd772eba35978d\n'}, {'number': 5, 'created': '2015-05-20 16:30:39.000000000', 'files': ['os_brick/tests/initiator/test_connector.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/20b9a0e9e57fab4c940b94ea7b1d2f57d4ab9c6c', 'message': 'Added a unit test for masking iscsiadm passwords\n\nThis patch adds a unit test to make sure that\nthe ISCSIConnector is masking passwords in the\nLOG output for _run_iscsiadm\n\nChange-Id: Ia859a4c4661995af21ede8ea75cd772eba35978d\n'}]",4,181553,20b9a0e9e57fab4c940b94ea7b1d2f57d4ab9c6c,21,5,5,5997,,,0,"Added a unit test for masking iscsiadm passwords

This patch adds a unit test to make sure that
the ISCSIConnector is masking passwords in the
LOG output for _run_iscsiadm

Change-Id: Ia859a4c4661995af21ede8ea75cd772eba35978d
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/53/181553/4 && git format-patch -1 --stdout FETCH_HEAD,['os_brick/tests/initiator/test_connector.py'],1,7bcb7eda10e9373abf7bd702e4f20e8c89acf63a,test-log," def test_sanitize_log_run_iscsiadm(self): # Tests that the parameters to the _run_iscsiadm function # are sanitized for when passwords are logged. def fake_debug(*args, **kwargs): self.assertIn('node.session.auth.password', args[0]) self.assertNotIn('scrubme', args[0]) def fake_execute(*args, **kwargs): return (None, None) iscsi = connector.ISCSIConnector(None) iscsi.set_execute(fake_execute) volume = {'id': 'fake_uuid'} connection_info = self.iscsi_connection(volume, ""10.0.2.15:3260"", ""fake_iqn"") iscsi_properties = connection_info['data'] with mock.patch.object(connector.LOG, 'debug', side_effect=fake_debug) as debug_mock: iscsi._iscsiadm_update(iscsi_properties, 'node.session.auth.password', 'scrubme') # we don't care what the log message is, we just want to make sure # our stub method is called which asserts the password is scrubbed self.assertTrue(debug_mock.called) ",,28,0
openstack%2Fpython-keystoneclient~master~Id423a538c169264a81c5714e6a9eff9b33912a55,openstack/python-keystoneclient,master,Id423a538c169264a81c5714e6a9eff9b33912a55,Support discovery on the AUTH_INTERFACE,MERGED,2015-03-30 06:18:03.000000000,2015-05-20 23:10:11.000000000,2015-05-20 23:10:10.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 8978}]","[{'number': 1, 'created': '2015-03-30 06:18:03.000000000', 'files': ['keystoneclient/tests/unit/auth/test_identity_common.py', 'keystoneclient/tests/unit/auth/test_identity_v3.py', 'keystoneclient/auth/identity/base.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/fd16240be482b4841dfafeee404f3a8e2678333e', 'message': 'Support discovery on the AUTH_INTERFACE\n\nWe need to allow get_endpoint(interface=auth.AUTH_INTERFACE, version=X)\nto support the same version negotiation that the service catalog goes\nthrough. This is required to support generic plugins where you often\nprovide an unversioned auth_url to the plugin but need a versioned URL\nto query for available projects.\n\nChange-Id: Id423a538c169264a81c5714e6a9eff9b33912a55\nCloses-Bug: #1438013\n'}]",0,168791,fd16240be482b4841dfafeee404f3a8e2678333e,7,3,1,7191,,,0,"Support discovery on the AUTH_INTERFACE

We need to allow get_endpoint(interface=auth.AUTH_INTERFACE, version=X)
to support the same version negotiation that the service catalog goes
through. This is required to support generic plugins where you often
provide an unversioned auth_url to the plugin but need a versioned URL
to query for available projects.

Change-Id: Id423a538c169264a81c5714e6a9eff9b33912a55
Closes-Bug: #1438013
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/91/168791/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/tests/unit/auth/test_identity_common.py', 'keystoneclient/tests/unit/auth/test_identity_v3.py', 'keystoneclient/auth/identity/base.py']",3,fd16240be482b4841dfafeee404f3a8e2678333e,authprojects," # the auth url then we can ignore many of the checks. Typically if you # are asking for the auth endpoint it means that there is no catalog to # query however we still need to support asking for a specific version # of the auth_url for generic plugins. if interface is base.AUTH_INTERFACE: url = self.auth_url service_type = service_type or 'identity' else: if not service_type: LOG.warn(_LW('Plugin cannot return an endpoint without ' 'knowing the service type that is required. Add ' 'service_type to endpoint filtering data.')) return None if not interface: interface = 'public' service_catalog = self.get_access(session).service_catalog url = service_catalog.url_for(service_type=service_type, endpoint_type=interface, region_name=region_name, service_name=service_name)"," # the auth url then we can ignore the rest of the checks. Typically if # you are asking for the auth endpoint it means that there is no # catalog to query anyway. if interface is base.AUTH_INTERFACE: return self.auth_url if not service_type: LOG.warn(_LW('Plugin cannot return an endpoint without knowing ' 'the service type that is required. Add service_type ' 'to endpoint filtering data.')) return None if not interface: interface = 'public' service_catalog = self.get_access(session).service_catalog url = service_catalog.url_for(service_type=service_type, endpoint_type=interface, region_name=region_name, service_name=service_name)",50,18
openstack%2Frally~master~I033135828b960da4cc3fd35b96ee69f700815a35,openstack/rally,master,I033135828b960da4cc3fd35b96ee69f700815a35,Add functional test for task samples,MERGED,2015-05-08 14:07:37.000000000,2015-05-20 23:09:47.000000000,2015-05-20 22:58:36.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 13609}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-08 14:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8ed1e3b209a98fad932affe9a752e9671851f633', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 2, 'created': '2015-05-12 12:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d505eb8b386ce080b541bc40caa0ddf52d3c930f', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 3, 'created': '2015-05-14 14:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0b40e10f8393e796834885e4d2d388097042cc8a', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 4, 'created': '2015-05-14 14:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/21ae3c979c97bb90433fe69af4b145366263a5c2', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 5, 'created': '2015-05-14 14:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c6eb851b9d00d7f6454be10fd44b60714c8d27c9', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 6, 'created': '2015-05-14 16:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/61fe045c8e8fb3510af76dc7d92a9436eb52c542', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 7, 'created': '2015-05-14 17:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e8337ace5b9a603e3a09268f0a8a9208a05b638b', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 8, 'created': '2015-05-15 12:27:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/da196b960f91fdb702c17e89588a3f472c21dd9b', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 9, 'created': '2015-05-15 12:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c7b923689e06cc8d97d61f4a8fbee47ac1f905ff', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 10, 'created': '2015-05-15 15:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1410b42ac0f8e9e267db9835953f77dc671adba7', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 11, 'created': '2015-05-15 17:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ed60aa60fe1996944e4f0f4713df0bc0d1fb6ba8', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 12, 'created': '2015-05-15 21:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/26d236e11c09dfb6d9f6ff54c0d362c78e478655', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 13, 'created': '2015-05-16 09:38:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/682383f1a85b6e21d1224cfdab81b43be3c57974', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 14, 'created': '2015-05-16 21:21:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0245e1f105b6c5e7b1a543f502f4c4f9726c5e8c', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 15, 'created': '2015-05-18 13:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/34fa93a67f846eeced62eb61a58b9a59e3b80d35', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 16, 'created': '2015-05-18 15:40:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9b7fbce3d502280b2a4e49dc4a7a4c60d98a10d4', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 17, 'created': '2015-05-18 15:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c822b8470f9e72b861960a0f3424cd6f8632ecdb', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 18, 'created': '2015-05-18 16:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0ae280b04fe918c3d78ad528d25e67ec038e9f3f', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}, {'number': 19, 'created': '2015-05-19 15:15:32.000000000', 'files': ['samples/tasks/scenarios/nova/boot-and-associate-floating-ip.yaml', 'samples/tasks/scenarios/nova/boot-lock-unlock-and-delete.json', 'samples/tasks/scenarios/nova/boot-and-rebuild.json', 'samples/tasks/scenarios/nova/boot-and-associate-floating-ip.json', 'samples/tasks/scenarios/nova/boot-and-rebuild.yaml', 'tests/functional/test_task_samples.py', 'samples/tasks/scenarios/nova/boot-lock-unlock-and-delete.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/3d3b57199a08bab4d2d39bfc7e9e92321f809678', 'message': 'Add functional test for task samples\n\nIt would be nice if there is a functional test to confirm\nall the task samples are good for out-of-box testing. So\nhere we go.\n\nAlso Fix nova/boot-lock-unlock-and-delete scenario flavor,\nnova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.\nChange flavor value from apsent on gate to regexp.\n\nChange-Id: I033135828b960da4cc3fd35b96ee69f700815a35\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>\n'}]",10,181400,3d3b57199a08bab4d2d39bfc7e9e92321f809678,90,7,19,12395,,,0,"Add functional test for task samples

It would be nice if there is a functional test to confirm
all the task samples are good for out-of-box testing. So
here we go.

Also Fix nova/boot-lock-unlock-and-delete scenario flavor,
nova/boot-and-associate-floating-ip flavor, nova/boot-and-rebuild.
Change flavor value from apsent on gate to regexp.

Change-Id: I033135828b960da4cc3fd35b96ee69f700815a35
Co-Authored-By: Roman Vasilets <rvasilets@mirantis.com>
Co-Authored-By: Fei Long Wang <flwang@catalyst.net.nz>
",git fetch https://review.opendev.org/openstack/rally refs/changes/00/181400/16 && git format-patch -1 --stdout FETCH_HEAD,['tests/functional/test_task_samples.py'],1,8ed1e3b209a98fad932affe9a752e9671851f633,test_task_samples,"# Copyright 2014: Mirantis Inc. # Copyright 2014: Catalyst IT Ltd. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import re import traceback import unittest from oslo_config import cfg import yaml from rally.benchmark.scenarios import base from tests.functional import utils class TestTaskSamples(unittest.TestCase): def setUp(self): super(TestTaskSamples, self).setUp() self.rally = utils.Rally() self.samples_path = os.path.join( os.path.dirname(__file__), os.pardir, os.pardir, ""samples"", ""tasks"") def _need_to_modify(self, sample): pass def create_temp_sample(self, sample): pass def test_schema_is_valid(self): scenarios = set() version = self.rally(""--version"") cfg.CONF([], project=""rally"", version=version) for dirname, dirnames, filenames in os.walk(self.samples_path): for filename in filenames: full_path = os.path.join(dirname, filename) # NOTE(hughsaunders): Skip non config files # (bug https://bugs.launchpad.net/rally/+bug/1314369) if not re.search(""\.(ya?ml|json)$"", filename, flags=re.I): continue with open(full_path) as task_file: try: task_config = yaml.safe_load(task_file.read()) try: self.rally(""task validate --task %s"" % full_path) except utils.RallyCmdError as e: if e.output.find(""Service is not available"") == -1: raise e except Exception: print(traceback.format_exc()) self.assertTrue(False, ""Wrong task config %s"" % full_path) else: scenarios.update(task_config.keys()) # TODO(boris-42): We should refactor scenarios framework add ""_"" to # all non-benchmark methods.. Then this test will pass. missing = set(base.Scenario.list_benchmark_scenarios()) - scenarios # check missing scenario is not from plugin missing = [scenario for scenario in list(missing) if base.Scenario.get_by_name(scenario.split(""."")[0]). __module__.startswith(""rally"")] self.assertEqual(missing, [], ""These scenarios don't have samples: %s"" % missing) ",,80,0
openstack%2Fdevstack-vagrant~master~I842519620f51a8690a4681f4b90f41301c337f9e,openstack/devstack-vagrant,master,I842519620f51a8690a4681f4b90f41301c337f9e,Add swap memory with a swapfile,ABANDONED,2015-03-10 18:47:12.000000000,2015-05-20 22:57:29.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6672}, {'_account_id': 8726}, {'_account_id': 9215}]","[{'number': 1, 'created': '2015-03-10 18:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/d8381ddfd85e30cc86fcee75452c6208d7c4abfe', 'message': 'Add swap memory with a swapfile\n\nThis commit will add a file to be used as a swap and to increase virtual\nmachine memory with swapfile. It uses the RH formula to set swapsize\nhttps://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Storage_Administration_Guide/ch-swapspace.html#s1-swap-what-is\n\nChange-Id: I842519620f51a8690a4681f4b90f41301c337f9e\n'}, {'number': 2, 'created': '2015-03-19 18:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/b542bc5ba1905b9db3133c43e3858b6ae3006708', 'message': 'Add swap memory with a swapfile\n\nThis commit will add a file to be used as a swap and to increase virtual\nmachine memory with swapfile. It uses the RH formula to set swapsize.\n\nIf M < 2G\n    S = M * 2G\nElse\n    S = M + 2G\n\nReference:\nhttps://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Storage_Administration_Guide/ch-swapspace.html#s1-swap-what-is\n\nChange-Id: I842519620f51a8690a4681f4b90f41301c337f9e\n'}, {'number': 3, 'created': '2015-03-31 15:16:56.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/9bcb0a99c3e8aa0315b058f55fae11a9a0a6293e', 'message': 'Add swap memory with a swapfile\n\nThis commit will add a file to be used as a swap and to increase virtual\nmachine memory with swapfile. It uses the RH formula to set swapsize.\n\nIf M < 2\n    S = M * 2\nElse\n    S = M + 2\n\nReference:\nhttps://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Storage_Administration_Guide/ch-swapspace.html#s1-swap-what-is\n\nChange-Id: I842519620f51a8690a4681f4b90f41301c337f9e\n'}]",4,163130,9bcb0a99c3e8aa0315b058f55fae11a9a0a6293e,12,5,3,6672,,,0,"Add swap memory with a swapfile

This commit will add a file to be used as a swap and to increase virtual
machine memory with swapfile. It uses the RH formula to set swapsize.

If M < 2
    S = M * 2
Else
    S = M + 2

Reference:
https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Storage_Administration_Guide/ch-swapspace.html#s1-swap-what-is

Change-Id: I842519620f51a8690a4681f4b90f41301c337f9e
",git fetch https://review.opendev.org/openstack/devstack-vagrant refs/changes/30/163130/3 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,d8381ddfd85e30cc86fcee75452c6208d7c4abfe,addswap,"$addswap= <<SWAPON if [ ! -f /swapfile ]; then MEM=$(grep MemTotal /proc/meminfo | awk '{print $2}') if [ $MEM -lt 2097152 ]; then SWAP=`echo ""$(($MEM * 2))""` else SWAP=`echo ""$(($MEM + 2097152 ))""` fi /bin/dd if=/dev/zero of=/swapfile bs=1k count=$SWAP /sbin/mkswap /swapfile /sbin/swapon /swapfile fi SWAPON # shell provision vm.provision :shell, :inline => $addswap",,15,0
openstack%2Fkeystone~master~I6af0fdd6d1efacb47692b89c329e45ac59fef7cb,openstack/keystone,master,I6af0fdd6d1efacb47692b89c329e45ac59fef7cb,Removes temporary fix for doc generation,MERGED,2015-05-13 12:22:43.000000000,2015-05-20 22:38:29.000000000,2015-05-20 22:38:27.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 8978}]","[{'number': 1, 'created': '2015-05-13 12:22:43.000000000', 'files': ['doc/ext/__init__.py', 'doc/source/conf.py', 'doc/ext/apidoc.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6f98a9e2bd7eed7f618a453d18055c34f84cd1ca', 'message': 'Removes temporary fix for doc generation\n\nA temporary fix was added to get around a bug in how pbr handles\nits autodoc_tree_index_modules setting. Since this bug is fixed we no\nlonger need the work around.\n\nChange-Id: I6af0fdd6d1efacb47692b89c329e45ac59fef7cb\nCloses-Bug: #1260495\n'}]",0,182643,6f98a9e2bd7eed7f618a453d18055c34f84cd1ca,7,3,1,7725,,,0,"Removes temporary fix for doc generation

A temporary fix was added to get around a bug in how pbr handles
its autodoc_tree_index_modules setting. Since this bug is fixed we no
longer need the work around.

Change-Id: I6af0fdd6d1efacb47692b89c329e45ac59fef7cb
Closes-Bug: #1260495
",git fetch https://review.opendev.org/openstack/keystone refs/changes/43/182643/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ext/__init__.py', 'doc/ext/apidoc.py', 'doc/source/conf.py', 'setup.cfg']",4,6f98a9e2bd7eed7f618a453d18055c34f84cd1ca,bug/1260495,autodoc_tree_index_modules = True,#autodoc_tree_index_modules = True #autodoc_tree_root = ./keystone,1,57
openstack%2Frally~master~I095d4efe181308feffbd49c59a1c52fa2ce0ca59,openstack/rally,master,I095d4efe181308feffbd49c59a1c52fa2ce0ca59,[Scenario] Split Scenarios - P3,MERGED,2015-05-17 14:28:31.000000000,2015-05-20 22:31:08.000000000,2015-05-20 22:20:09.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 13919}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-17 14:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3e97bc225935383ddb4163ae10809ed33dcd9418', 'message': '[Scenario] Split Sahara, Swift, Glance, Cinder  under Plugins\n\nMove under plugins/openstack\n\nImplements: blueprint split-plugins\n\nChange-Id: I095d4efe181308feffbd49c59a1c52fa2ce0ca59\n'}, {'number': 2, 'created': '2015-05-17 14:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/56b50633580a3a6d8ba96af49456c6c10c33605c', 'message': '[Scenario] Split Sahara, Swift, Glance, Cinder  under Plugins\n\nMove under plugins/openstack\n\nImplements: blueprint split-plugins\n\nChange-Id: I095d4efe181308feffbd49c59a1c52fa2ce0ca59\n'}, {'number': 3, 'created': '2015-05-18 05:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/76f0eafd90a9944b14a2eb7f40520a0914345745', 'message': '[Scenario] Split Sahara, Swift, Glance, Cinder  under Plugins\n\nMove under plugins/openstack\n\nImplements: blueprint split-plugins\n\nChange-Id: I095d4efe181308feffbd49c59a1c52fa2ce0ca59\n'}, {'number': 4, 'created': '2015-05-18 06:33:37.000000000', 'files': ['tests/unit/plugins/openstack/scenarios/sahara/__init__.py', 'tests/unit/plugins/openstack/context/test_volumes.py', 'rally/plugins/openstack/scenarios/swift/objects.py', 'rally/plugins/openstack/scenarios/glance/__init__.py', 'rally/plugins/openstack/scenarios/swift/__init__.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_cluster.py', 'tests/unit/plugins/openstack/scenarios/swift/__init__.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_image.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_clusters.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_jobs.py', 'tests/unit/plugins/openstack/scenarios/swift/test_utils.py', 'rally/plugins/openstack/scenarios/sahara/jobs.py', 'rally/plugins/openstack/context/images.py', 'tests/unit/plugins/openstack/scenarios/swift/test_objects.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_edp.py', 'tests/unit/plugins/openstack/scenarios/glance/__init__.py', 'rally/benchmark/scenarios/vm/vmtasks.py', 'rally/plugins/openstack/scenarios/sahara/consts.py', 'tests/unit/plugins/openstack/scenarios/cinder/__init__.py', 'rally/plugins/openstack/scenarios/cinder/volumes.py', 'rally/plugins/openstack/context/volumes.py', 'rally/plugins/openstack/scenarios/sahara/utils.py', 'rally/plugins/openstack/scenarios/sahara/clusters.py', 'tests/unit/plugins/openstack/scenarios/glance/test_images.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_utils.py', 'rally/benchmark/scenarios/nova/servers.py', 'rally/plugins/openstack/scenarios/cinder/utils.py', 'tests/unit/plugins/openstack/scenarios/glance/test_utils.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_node_group_templates.py', 'rally/plugins/openstack/scenarios/glance/images.py', 'rally/plugins/openstack/context/sahara/sahara_cluster.py', 'rally/plugins/openstack/context/sahara/sahara_image.py', 'rally/plugins/openstack/scenarios/glance/utils.py', 'rally/common/opts.py', 'rally/plugins/openstack/scenarios/sahara/__init__.py', 'tests/unit/plugins/openstack/context/test_images.py', 'tests/unit/plugins/openstack/scenarios/cinder/test_volumes.py', 'rally/plugins/openstack/scenarios/sahara/node_group_templates.py', 'rally/plugins/openstack/scenarios/swift/utils.py', 'tests/unit/plugins/openstack/scenarios/cinder/test_utils.py', 'rally/plugins/openstack/scenarios/cinder/__init__.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/d60e9c5c60d8e736feea08c2222bf7a106fd4a35', 'message': '[Scenario] Split Scenarios - P3\n\nMove under plugins/openstack:\n    * Sahara\n    * Swift\n    * Glance\n    * Cinder\n\nImplements: blueprint split-plugins\n\nChange-Id: I095d4efe181308feffbd49c59a1c52fa2ce0ca59\n'}]",0,183915,d60e9c5c60d8e736feea08c2222bf7a106fd4a35,17,5,4,8576,,,0,"[Scenario] Split Scenarios - P3

Move under plugins/openstack:
    * Sahara
    * Swift
    * Glance
    * Cinder

Implements: blueprint split-plugins

Change-Id: I095d4efe181308feffbd49c59a1c52fa2ce0ca59
",git fetch https://review.opendev.org/openstack/rally refs/changes/15/183915/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/plugins/openstack/scenarios/sahara/__init__.py', 'tests/unit/plugins/openstack/context/test_volumes.py', 'rally/plugins/openstack/scenarios/swift/objects.py', 'rally/plugins/openstack/scenarios/glance/__init__.py', 'rally/plugins/openstack/scenarios/swift/__init__.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_cluster.py', 'tests/unit/plugins/openstack/scenarios/swift/__init__.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_image.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_clusters.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_jobs.py', 'tests/unit/plugins/openstack/scenarios/swift/test_utils.py', 'rally/plugins/openstack/scenarios/sahara/jobs.py', 'rally/plugins/openstack/context/images.py', 'tests/unit/plugins/openstack/scenarios/swift/test_objects.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_edp.py', 'tests/unit/plugins/openstack/scenarios/glance/__init__.py', 'rally/benchmark/scenarios/vm/vmtasks.py', 'rally/plugins/openstack/scenarios/sahara/consts.py', 'tests/unit/plugins/openstack/scenarios/cinder/__init__.py', 'rally/plugins/openstack/scenarios/cinder/volumes.py', 'rally/plugins/openstack/context/volumes.py', 'rally/plugins/openstack/scenarios/sahara/utils.py', 'rally/plugins/openstack/scenarios/sahara/clusters.py', 'tests/unit/plugins/openstack/scenarios/glance/test_images.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_utils.py', 'rally/benchmark/scenarios/nova/servers.py', 'rally/plugins/openstack/scenarios/cinder/utils.py', 'tests/unit/plugins/openstack/scenarios/glance/test_utils.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_node_group_templates.py', 'rally/plugins/openstack/scenarios/glance/images.py', 'rally/plugins/openstack/context/sahara/sahara_cluster.py', 'rally/plugins/openstack/context/sahara/sahara_image.py', 'rally/plugins/openstack/scenarios/glance/utils.py', 'rally/common/opts.py', 'rally/plugins/openstack/scenarios/sahara/__init__.py', 'tests/unit/plugins/openstack/context/test_images.py', 'tests/unit/plugins/openstack/scenarios/cinder/test_volumes.py', 'rally/plugins/openstack/scenarios/sahara/node_group_templates.py', 'rally/plugins/openstack/scenarios/swift/utils.py', 'tests/unit/plugins/openstack/scenarios/cinder/test_utils.py', 'rally/plugins/openstack/scenarios/cinder/__init__.py']",41,3e97bc225935383ddb4163ae10809ed33dcd9418,bp/split-plugins,,,53,51
openstack%2Fkeystone-specs~master~If5f03551be2d3a98ce21737a6bbd29cf0cb0b85f,openstack/keystone-specs,master,If5f03551be2d3a98ce21737a6bbd29cf0cb0b85f,"Revert ""Provide ability to read default domain configuration options""",MERGED,2015-05-20 22:16:46.000000000,2015-05-20 22:25:02.000000000,2015-05-20 22:25:00.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}]","[{'number': 1, 'created': '2015-05-20 22:16:46.000000000', 'files': ['specs/liberty/domain-config-default.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/f9d67761ee5d5934eb2c1d3e86f47a57cb5b0024', 'message': 'Revert ""Provide ability to read default domain configuration options""\n\nThis reverts commit 1850ccf016a7527f172ed043e42cb6ad95ce41d1.\n\nChange-Id: If5f03551be2d3a98ce21737a6bbd29cf0cb0b85f\n'}]",0,184638,f9d67761ee5d5934eb2c1d3e86f47a57cb5b0024,7,3,1,2903,,,0,"Revert ""Provide ability to read default domain configuration options""

This reverts commit 1850ccf016a7527f172ed043e42cb6ad95ce41d1.

Change-Id: If5f03551be2d3a98ce21737a6bbd29cf0cb0b85f
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/38/184638/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/domain-config-default.rst'],1,f9d67761ee5d5934eb2c1d3e86f47a57cb5b0024,,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ Domain Configuration Storage ============================ `bp domain-config-default <https://blueprints.launchpad.net/keystone/+spec/domain-config-default>`_ Provide the ability for the default values for domain-configurable options to be retrieved via the API. Problem Description =================== Domain specific option configuration via the API was introduced in Kilo: https://github.com/openstack/keystone-specs/blob/master/specs/kilo/domain-config-ext.rst This provides the crud mechanism to manager domain specific options. However, it does not allow a domain admin to discover the default settings for any such options - and hence the knowledge of whether they need to override a specific option for a given domain. Proposed Change =============== This proposal will extend the domain config API to allow the retrieval of the default options for those that can be configured on a domain basis, allowing a domain administrator to then decide whether to use the existing facilities of the domain config API to override any of these values. It does not provide an ability to set the global default values for a keystone server - these can still only be changed via the main keystone configuration file. Alternatives ------------ Rather than provide a specific API to retrieve the defaults, we could modify the current API (which is marked as experimental) to simply return the current value for any option, whether it is the default or whether it has been set explicitly by the API for this domain. While this is perhaps simpler for those just reading the option values, it would complicate the semantics of the APIs to modify such options. For instance, you would somehow need to represent in the API the fact that if you deleted an option that was set for a domain, and then read it back, you would still get a value...it would just be the default value. Data Model Impact ----------------- None REST API Impact --------------- The exact API specification will be defined as part of a review of changes to the Identity API. Security Impact --------------- This functionality exposes a new API to the backend configuration data for a domain. Like any other v3 API, it will be subject to the standard RBAC permissions model. Notifications Impact -------------------- None Other End User Impact --------------------- None Performance Impact ------------------ None Other Deployer Impact --------------------- None Developer Impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: henry-nash Work Items ---------- - Get agreement of API specifications - Implement the domain configuration code - Add support to keystoneclient library - Add support to openstack client The work for supporting this API in Horizon will be proposed separately. Dependencies ============ None Testing ======= None, above and beyond unit testing Documentation Impact ==================== Changes to the Identity API and configuration.rst. References ========== None ",0,134
openstack%2Fhorizon~stable%2Fjuno~I4821eacb0bb274befab7995f3a8f87c82d3997f5,openstack/horizon,stable/juno,I4821eacb0bb274befab7995f3a8f87c82d3997f5,Sanitation of metadata passed from Django,MERGED,2015-05-15 19:25:34.000000000,2015-05-20 22:23:22.000000000,2015-05-20 22:23:20.000000000,"[{'_account_id': 3}, {'_account_id': 1446}, {'_account_id': 1955}, {'_account_id': 2455}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6486}, {'_account_id': 6914}, {'_account_id': 9576}]","[{'number': 1, 'created': '2015-05-15 19:25:34.000000000', 'files': ['horizon/templates/horizon/common/_modal_form_update_metadata.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6c944b5013acb0dce7cf3d8717e58f7f2427be07', 'message': 'Sanitation of metadata passed from Django\n\nWe need to escape HTML in metadata passed from Django, which\ncan lead to security issues. Refer to the bug for more details.\n\nConflicts:\n horizon/templates/horizon/common/_modal_form_update_metadata.html\n\nThe conflict was that there are extra spaces in the line.\n\nCo-Authored-By: Szymon Wroblewski <szymon.wroblewski@intel.com>\nChange-Id: I4821eacb0bb274befab7995f3a8f87c82d3997f5\nCloses-bug: #1449260\n(cherry picked from commit 81e1fa13177c8e259c90183409696305f55cdd75)\n(cherry picked from commit e7f3e0880f4e311c768c413e43317674cb234515)\n'}]",0,183659,6c944b5013acb0dce7cf3d8717e58f7f2427be07,13,9,1,6486,,,0,"Sanitation of metadata passed from Django

We need to escape HTML in metadata passed from Django, which
can lead to security issues. Refer to the bug for more details.

Conflicts:
 horizon/templates/horizon/common/_modal_form_update_metadata.html

The conflict was that there are extra spaces in the line.

Co-Authored-By: Szymon Wroblewski <szymon.wroblewski@intel.com>
Change-Id: I4821eacb0bb274befab7995f3a8f87c82d3997f5
Closes-bug: #1449260
(cherry picked from commit 81e1fa13177c8e259c90183409696305f55cdd75)
(cherry picked from commit e7f3e0880f4e311c768c413e43317674cb234515)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/59/183659/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/common/_modal_form_update_metadata.html'],1,6c944b5013acb0dce7cf3d8717e58f7f2427be07,bug/1449260, var existing_metadata = JSON.parse('{{existing_metadata|escapejs}}'); var available_metadata = JSON.parse('{{available_metadata|escapejs}}');, var existing_metadata = {{existing_metadata|safe}}; var available_metadata = {{available_metadata|safe}};,2,2
openstack%2Fkeystone-specs~master~I7b5ab1d9e0766533074be228ad4d0f47cebc3496,openstack/keystone-specs,master,I7b5ab1d9e0766533074be228ad4d0f47cebc3496,Provide ability to read default domain configuration options,MERGED,2015-05-20 13:29:57.000000000,2015-05-20 22:14:37.000000000,2015-05-20 22:14:37.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 6460}, {'_account_id': 8866}]","[{'number': 1, 'created': '2015-05-20 13:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/914bcdd1bbd81353406bb9a341b5a4404bb6f5d3', 'message': 'Provide ability to read default domain configuration options\n\nBlueprint domain-config-default\n\nChange-Id: I7b5ab1d9e0766533074be228ad4d0f47cebc3496\n'}, {'number': 2, 'created': '2015-05-20 13:33:10.000000000', 'files': ['specs/liberty/domain-config-default.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/1850ccf016a7527f172ed043e42cb6ad95ce41d1', 'message': 'Provide ability to read default domain configuration options\n\nBlueprint domain-config-default\n\nChange-Id: I7b5ab1d9e0766533074be228ad4d0f47cebc3496\n'}]",0,184486,1850ccf016a7527f172ed043e42cb6ad95ce41d1,10,4,2,5707,,,0,"Provide ability to read default domain configuration options

Blueprint domain-config-default

Change-Id: I7b5ab1d9e0766533074be228ad4d0f47cebc3496
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/86/184486/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/domain-config-ext.rst'],1,914bcdd1bbd81353406bb9a341b5a4404bb6f5d3,bp/domain-config-default,"`bp domain-config-default <https://blueprints.launchpad.net/keystone/+spec/domain-config-default>`_ Provide the ability for the default values for domain-configurable options to be retrieved via the API.Domain specific option configuration via the API was introduced in Kilo: https://github.com/openstack/keystone-specs/blob/master/specs/kilo/domain-config-ext.rst This provides the crud mechanism to manager domain specific options. However, it does not allow a domain admin to discover the default settings for any such options - and hence the knowledge of whether they need to override a specific option for a given domain. This proposal will extend the domain config API to allow the retrieval of the default options for those that can be configured on a domain basis, allowing a domain administrator to then decide whether to use the existing facilities of the domain config API to override any of these values. It does not provide an ability to set the global default values for a keystone server - these can still only be changed via the main keystone configuration file.Rather than provide a specific API to retrieve the defaults, we could modify the current API (which is marked as experimental) to simply return the current value for any option, whether it is the default or whether it has been set explicitly by the API for this domain. While this is perhaps simpler for those just reading the option values, it would complicate the semantics of the APIs to modify such options. For instance, you would somehow need to represent in the API the fact that if you deleted an option that was set for a domain, and then read it back, you would still get a value...it would just be the default value.NoneNoneNoneNone, above and beyond unit testing","`bp domain-config-ext <https://blueprints.launchpad.net/keystone/+spec/domain-config-ext>`_ Provide the means to store the configuration options that would normally stored in domain-specific configuration files in an SQL table instead.Domain specific configuration files are used to specify the unique options for a given domain with regard to its identity backend (for example ``[ldap] url`` to be used for that domain). This use of a separate configuration file for each domain leads to some complexity in the choreography of on-boarding a new domain, e.g.: * Call the Keystone API to add a new domain, create whatever domain role assignments are required * Use an out-of-band mechanism to create and place the domain specific configuration file on the Keystone server * Restart Keystone to ensure cause the domain specific configuration file to be read The two different mediums of where information about a domain is stored (i.e. identity driver information in the configuration file as well as domain name, description etc. in SQL) also makes it rather difficult to easily see what options are defined for a specific domain.This proposal will provide the ability to store the configuration options in an SQL backend, indexed by domain ID. A main configuration option will dictate whether Keystone uses this extension to obtain domain specific configuration data or the existing domain specific configuration files approach. It will be an all or nothing option - there will be no mixing of some options in the extension and some in configuration files. If the extension is specified as the store of configuration data, then any domain-specific configuration files will be ignored. Keystone will go through the logic of building the domain configurations in the same way as it does today, either reading the configurations options from the extension or from the set files. Whenever any of the domain-specific configuration options are updated, the identity backend for a given domain will be re-loaded (using whatever new configuration data there may be), further assisting the on-boarding of a domain. This new capability can only be used to replace options that would have appeared in a domain specific file - it will not allow options to be specified that would normally only appear in the main Keystone configuration file. Since the options are available via REST, the openstack client and Horizon can provide the ability to view and set this information. Although the configuration options will be stored in SQL, this does not imply anything about the medium of the identity backends themselves (which could be all LDAP if required). One concern over this ability would be that some configuration options may be considered highly sensitive and would want to be stored separately and while can be written via the API, they cannot be read (for example password of the user required for doing LDAP searches, in the case when anonymous query is not supported). To address this concern, it is proposed that internally we enforce an explicit whitelist of config options that can be read. All others will be stored in a separate backend table and not returned on read. The current proposal is that all config options except password will be included in the whitelist. This means that the LDAP url will be returned on read (since that will be a common option cloud administrators might want to check). There may be situations where the url is required to encode a non-whitelisted item (e.g. password). To avoid these then being visible on read, we will support the substitution commands within any config strings that allow any non-whitelisted items to be referenced, by specifying within the option: %(config-option-name)s For example: ""url"": ""http://myldap/root/henry/%(password)s"" The configuration option specified for substitution, which must exist in the same group as the option being defined (in this case ""url""), will be substituted when Keystone uses the configuration option internally. This new capability will initially be classed as experimental in-tree functionality, with the intention of migrating to stable as soon as possible, with a stretch goal of this occurring before the release of Kilo.Use of federation to access IdPs would (effectively) move this problem to creating mapping rules.Changes to the data model will be restricted to a new tables for storing the configuration information.None, other than this functionality will subscribe to domain deletion events.For cloud providers who have already deployed a domain-specific installation, a one-shot option to keystone-manage will be provided that will copy the contents of the domain-specific configuration files into the SQL store.- Implement the keystone-manage migration optionBeyond the regular unit testing, there will be testing for the migration options.",29,82
openstack%2Fglance~master~I585490f4f3e7792a172d72741016a77ab5e5a764,openstack/glance,master,I585490f4f3e7792a172d72741016a77ab5e5a764,Modify entry point tests to not require deps,ABANDONED,2015-05-19 21:17:00.000000000,2015-05-20 22:14:13.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 9107}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-19 21:17:00.000000000', 'files': ['glance/tests/unit/test_opts.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/549749dc7548bb243409ab55a211823176d9c61e', 'message': ""Modify entry point tests to not require deps\n\nDon't fail if a requirement cannot be loaded.\n\npbr 1.0 was released but many libraries still require pbr < 1.0.\ngate-glance-python27 fails because of that.\n\nChange-Id: I585490f4f3e7792a172d72741016a77ab5e5a764\nCloses-Bug: #1456800\n""}]",0,184326,549749dc7548bb243409ab55a211823176d9c61e,6,4,1,9107,,,0,"Modify entry point tests to not require deps

Don't fail if a requirement cannot be loaded.

pbr 1.0 was released but many libraries still require pbr < 1.0.
gate-glance-python27 fails because of that.

Change-Id: I585490f4f3e7792a172d72741016a77ab5e5a764
Closes-Bug: #1456800
",git fetch https://review.opendev.org/openstack/glance refs/changes/26/184326/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/test_opts.py'],1,549749dc7548bb243409ab55a211823176d9c61e,bug/1456800, list_fn = ep.load(require=False), list_fn = ep.load(),1,1
openstack%2Fkeystone-specs~master~If2138e94b8b2e5269cd7d88497f6acf92a645c19,openstack/keystone-specs,master,If2138e94b8b2e5269cd7d88497f6acf92a645c19,environment setup for functional tests,MERGED,2015-02-05 17:14:23.000000000,2015-05-20 22:14:12.000000000,2015-05-20 22:14:10.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5196}, {'_account_id': 6486}, {'_account_id': 6804}, {'_account_id': 7725}]","[{'number': 1, 'created': '2015-02-05 17:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/26a95003a8493ae6d49301d47ad52d3cc0e6a72a', 'message': 'environment setup for functional tests\n\nDescribes how we define and create environments for functional tests.\n\nbp functional-testing-setup\n\nChange-Id: If2138e94b8b2e5269cd7d88497f6acf92a645c19\n'}, {'number': 2, 'created': '2015-03-08 04:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/c475ce77bacb2902bfb2028f0d6fa40ca7f121a6', 'message': 'environment setup for functional tests\n\nDescribes how we define and create environments for functional tests.\n\nbp functional-testing-setup\n\nChange-Id: If2138e94b8b2e5269cd7d88497f6acf92a645c19\n'}, {'number': 3, 'created': '2015-05-20 22:08:29.000000000', 'files': ['specs/backlog/functional-testing-setup.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/bfbbf7f880069eb3be4db3251e3546f936f4fcaa', 'message': 'environment setup for functional tests\n\nDescribes how we define and create environments for functional tests.\n\nbp functional-testing-setup\n\nChange-Id: If2138e94b8b2e5269cd7d88497f6acf92a645c19\n'}]",6,153300,bfbbf7f880069eb3be4db3251e3546f936f4fcaa,18,8,3,7725,,,0,"environment setup for functional tests

Describes how we define and create environments for functional tests.

bp functional-testing-setup

Change-Id: If2138e94b8b2e5269cd7d88497f6acf92a645c19
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/00/153300/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/functional-testing-setup.rst'],1,26a95003a8493ae6d49301d47ad52d3cc0e6a72a,functional-testing,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================== Functional Testing Environments =============================== `bp functional-testing-setup <https://blueprints.launchpad.net/keystone/+spec/functional-testing-setup>`_ The new direction for functional testing is to `move`_ it out of tempest and into the projects. This means that we need to provide direction and some sort of framework for how this is to be done in Keystone. This information was originally captured in `an etherpad <https://etherpad.openstack.org/p/keystone-functional-tests>`_ while it was being discussed. .. _move: http://lists.openstack.org/pipermail/openstack-dev/2014-July/041188.html Problem Description =================== In `another spec <http://specs.openstack.org/openstack/keystone-specs/specs/ kilo/functional-testing.html>`_ we defined two types of functional tests. Shared tests that can be run against any Keystone instance to verify its behavior. Configuration specific tests that should only be run against a Keystone instance that has been configured a certain way, e.g. federation. These tests can be run against any Keystone instance by specifying the URL. This means that a provider that has implemented federation with some domain specific IdP can run the federation tests to see if there are any major problems. We also need a standard way to define expected configurations so that it is easy for developers to standup test environments and easy for CI. Not all created configurations will be in CI. We will have to pick based on risk of bugs, popularity and CI resources. This spec doesn't talk too much more about that. Proposed Change =============== Constraints ----------- * stick to the methods/mechanisms used for adding functional tests in other OpenStack projects; this may be slightly different so that we can experiment with better solutions, but i don't want to be too far outside of the box * it should be very easy to add new configurations that need to be tested * the tests should be runnable by the gate for enforcement * the tests should be runnable by developers using devstack Concepts -------- devstack vm (dsvm) configurations the scripts and configuration necessary to setup Keystone for testing a type of deployment (eventlet, Apache, federation, etc) scenario tests the actual tests themselves; i am picturing this just using our current framework and tools used in unit testing (maybe with more focus on using the KeystoneClient API shared tests the scenario tests the show the base behavior of the system; these will run under every configuration Basic idea ---------- Configurations are actually implemented as devstack hooks. This allows it to be easily used for gate testing. Each configuration will provide a script that will restack a devstack instance. This restacking just automates the calls to the gate hooks. This will allow developers to switch between configurations as their testing needs change. The tests themselves will be run as tox targets. Possible configurations ----------------------- These are things that we potentially want to gate against. There are many possible configurations to test against. Below are just a few. Generally speaking every run_tests.sh will run the standard tests as well as any tests specific to that configuration. * eventlet - deploy on eventlet * Apache - deploy behind mod_wsgi * federation - deploy on Apache using mod_shib .. example directory structure: Directory structures -------------------- :: dsvm └── {configuration name} ├── devstack │ ├── extras.d │ │ └── *.sh │ ├── files │ │ └── {...} │ ├── lib │ │ └── {...} │ └── local.conf ├── stack.sh ├── unstack.sh └── run_tests.sh configuration name This is the directory that will hold all of the files necessary for a configuraion. extras.d A directory of shell scripts that implement devstack plugins. This is not Keystone specific, but rather devstack specific. These shell scripts are really just calling to functions defined in 'lib' shell scripts instead of implementing significant logic. files A directory containing files used by devstack. This is there things like configuration templates would go. lib A directory containing supporting shell scripts that defined the logic used by plugin scripts. local.conf This is the devstack configuration. If defines the plugins necessary for testing the configuration. stack.sh Script used to initialize a devstack with a specific configuration. This will move any existing configuration (local.conf) out of the way before installing the one bundled with this dsvm configuration. We'll then call devstack's stack.sh. unstack.sh Removes any dsvm configuration specifics configs and moves back anything that was moved by stack.sh. We'll then call devstack's unstack.sh. run_tests.sh Script to call stack.sh, run the functional tests and call unstack.sh for a dsvm configuration. Alternatives ------------ I have not really investigated alternatives. This proposal represents what I learned from other projects and the changes I think are necessary to satisfy the `constraints`_. Security Impact --------------- None. This is about test environments and doesn't directly impact production code. Notifications Impact -------------------- None. This is about test environments and doesn't directly impact production code. Other End User Impact --------------------- None. This is about test environments and doesn't directly impact production code. Performance Impact ------------------ None. This is about test environments and doesn't directly impact production code. Other Deployer Impact --------------------- None. This is about test environments and doesn't directly impact production code. Developer Impact ---------------- Developers will have to learn and understand devstack/devstack-gate to some extent if they wish to use the bundled configurations for functional testing. Implementation ============== Assignee(s) ----------- Primary assignee: dstanek Other contributors: <anyone> Work Items ---------- 1. create initial configuration for standard tests 2. create a configuration for federation tests 3. create experimental gate jobs for both configurations Dependencies ============ A devstack instance is necessary to use the configuration scripts. Documentation Impact ==================== The developer documentation will need to be updated to explain how to run the scripts to setup the devstack configurations. References ========== The start of the implementation: * https://review.openstack.org/#/c/151310/ * https://review.openstack.org/#/c/151311/ * https://review.openstack.org/#/c/139137/ Some of the references I used when writing the code for this spec: OSC * http://git.openstack.org/cgit/openstack-infra/project-config/tree/jenkins/jobs/osc-functional.yaml * http://git.openstack.org/cgit/openstack/python-openstackclient/tree/post_test_hook.sh devstack-gate * https://github.com/openstack-infra/devstack-gate neutron * http://git.openstack.org/cgit/openstack-infra/project-config/tree/jenkins/jobs/neutron-functional.yaml * http://git.openstack.org/cgit/openstack/neutron/tree/neutron/tests/contrib/gate_hook.sh designate * https://github.com/openstack/designate/blob/master/contrib/devstack/post_test_hook.sh Google!: * https://www.google.com/webhp?sourceid=chrome-instant&ion=1&espv=2&es_th=1&ie=UTF-8#safe=active&q=devstack%20post_test_hook ",,262,0
openstack%2Fneutron~master~Icb1fbd5d35dcbecce54426b9ef1e1be18b706d8b,openstack/neutron,master,Icb1fbd5d35dcbecce54426b9ef1e1be18b706d8b,Use convenience method from db api to create nested transaction,MERGED,2015-03-19 13:43:31.000000000,2015-05-20 22:12:12.000000000,2015-05-20 22:12:09.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7125}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14956}, {'_account_id': 15296}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-03-19 13:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae8936d6d0221049ecb523293afec13d136bc5cb', 'message': 'Use convenience method from db api to create nested transaction\n\nInstead of dealing with conditional nesting, use method that\ncreates nested transaction if possible.\n\nChange-Id: Icb1fbd5d35dcbecce54426b9ef1e1be18b706d8b\n'}, {'number': 2, 'created': '2015-05-19 02:47:10.000000000', 'files': ['neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a52ce62845c899407879e8afbac611fa78eac769', 'message': 'Use convenience method from db api to create nested transaction\n\nInstead of dealing with conditional nesting, use method that\ncreates nested transaction if possible.\n\nChange-Id: Icb1fbd5d35dcbecce54426b9ef1e1be18b706d8b\n'}]",3,165822,a52ce62845c899407879e8afbac611fa78eac769,85,41,2,6072,,,0,"Use convenience method from db api to create nested transaction

Instead of dealing with conditional nesting, use method that
creates nested transaction if possible.

Change-Id: Icb1fbd5d35dcbecce54426b9ef1e1be18b706d8b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/22/165822/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,ae8936d6d0221049ecb523293afec13d136bc5cb,nested-refactoring,"from neutron.db import api as db_api mac_address): try: with db_api.autonested_transaction(context.session): context, network_id, port_data, mac)"," mac_address, nested=False): try: with context.session.begin(subtransactions=True, nested=nested): # nested = True frames an operation that may potentially fail # within a transaction, so that it can be rolled back to the # point before its failure while maintaining the enclosing # transaction context, network_id, port_data, mac, nested=True)",4,7
openstack%2Fkeystone-specs~master~I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607,openstack/keystone-specs,master,I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607,Materialized path for project hierarchy,MERGED,2015-04-14 17:20:09.000000000,2015-05-20 22:11:40.000000000,2015-05-20 22:11:40.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6804}, {'_account_id': 7725}, {'_account_id': 8866}, {'_account_id': 8978}, {'_account_id': 11022}, {'_account_id': 13055}, {'_account_id': 13478}]","[{'number': 1, 'created': '2015-04-14 17:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/4926c5429d58bfdb405878289e3f1bee92baccf1', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 2, 'created': '2015-04-14 17:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/f99e81447958a98145cad2b6a0bd18979cdcc473', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 3, 'created': '2015-04-15 16:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/ffc25fa539bfa283a8287c66e0cb921a653f4381', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 4, 'created': '2015-04-15 18:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/2aab026e11902c869249175acfa94fc8d91001d0', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 5, 'created': '2015-04-15 19:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/8f019bc5fb28d88fe323191da0440561853c874c', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 6, 'created': '2015-04-16 12:25:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/5bd5b8fa4a5a148a02561eecf955d5dbd6a90270', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 7, 'created': '2015-04-16 14:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/9a5fc2b55cce4dc3ffd690ef65733ae2d6c0356a', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 8, 'created': '2015-04-17 12:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/c88a9d75db5a28f7a24192e8c1b44cc7dc36b241', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 9, 'created': '2015-04-21 15:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/afc42ca29e6489957f6ae2b9572baa7bac56dcc5', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 10, 'created': '2015-04-22 09:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/23fcb5c2ae80158670119961414e77d788fc3386', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 11, 'created': '2015-04-22 09:48:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/8e33fb1c08088ee5b72133fc6d474ad92795adcd', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 12, 'created': '2015-04-22 16:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/cbdcd3839a08c372364d89296af14998e7dac2ef', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 13, 'created': '2015-04-22 16:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/2b800f634c631b3030a8bbc3e28dda199e042cd5', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 14, 'created': '2015-04-22 16:59:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/63b5dc0d75eba101b3736268061ac2fa2bd2c48a', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 15, 'created': '2015-04-23 17:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/a8b7e56ac8694db7c0f414e7aa64d30db00e7717', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}, {'number': 16, 'created': '2015-05-20 22:04:36.000000000', 'files': ['specs/liberty/materialize-project-hierarchy.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/fc5c6f32835852ec6f41abece2a19f7900ffde63', 'message': 'Materialized path for project hierarchy\n\nImplements bp materialize-project-hierarchy\n\nChange-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607\n'}]",64,173424,fc5c6f32835852ec6f41abece2a19f7900ffde63,71,12,16,13055,,,0,"Materialized path for project hierarchy

Implements bp materialize-project-hierarchy

Change-Id: I7000bc4ffc7e0b1d75bc69be38b4f53844ac1607
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/24/173424/16 && git format-patch -1 --stdout FETCH_HEAD,['specs/backlog/materialize-hierarchy.rst'],1,4926c5429d58bfdb405878289e3f1bee92baccf1,bp/materialize-project-hierarchy,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================= Materialized path - materialize-project-hierarchy ================================================= `bp example <https://blueprints.launchpad.net/keystone/+spec/materialize-project-hierarchy>`_ To manage hierarchical multitenancy data effectively the existing adjacency list paradigm is not enough: recursion is required to traverse the tree. Materialized path concept allows to find all ascendants, descendants, children of the node in a single request operation. Problem Description =================== Given the project hierarchy as follows: A -> B -> C -> D Disabling B project needs to disable all it's descendants: C and D So there is a need to check every D-scoped token against all parents recursively. Proposed Change =============== It is possible to avoid recursion having entire project pedigree stored in the model instead of simple parent link. For example:: DELIMITER = '->' project.pedigree = A.id + DELIMITER + B.id + .. + DELIMITER + D.id So every project has it's pedigree stored what allows to find all projects needed to be checked and all descendant projects will have pedigree starting with pedigree of ancestor. Alternatives ------------ What other ways could we do this thing? Why aren't we using those? This doesn't have to be a full literature review, but it should demonstrate that thought has been put into why the proposed solution is an appropriate one. Security Impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? * Does this change involve cryptography or hashing? * Does this change require the use of sudo or any elevated privileges? * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. For more detailed guidance, please see the OpenStack Security Guidelines as a reference (https://wiki.openstack.org/wiki/Security/Guidelines). These guidelines are a work in progress and are designed to help you identify security best practices. For further information, feel free to reach out to the OpenStack Security Group at openstack-security@lists.openstack.org. Notifications Impact -------------------- Please specify any changes to notifications. Be that an extra notification, changes to an existing notification, or removing a notification. Other End User Impact --------------------- Aside from the API, are there other ways a user will interact with this feature? * Does this change have an impact on python-keystoneclient? What does the user interface there look like? Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A small change in a utility function or a commonly used decorator can have a large impacts on performance. * Calls which result in a database queries can have a profound impact on performance when called in critical sections of the code. * Will the change include any locking, and if so what considerations are there on holding the lock? Other Deployer Impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * If this change is a new binary, how would it be deployed? * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? Developer Impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the driver API, discussion of how other backends would implement the feature is required. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in keystone, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Keystone (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to ",,209,0
openstack%2Fanchor~master~Ib223deca5bfd5fc67560fd030813020a07e054ce,openstack/anchor,master,Ib223deca5bfd5fc67560fd030813020a07e054ce,Simplifying the validator config,MERGED,2015-04-24 14:20:06.000000000,2015-05-20 21:59:21.000000000,2015-05-20 21:59:20.000000000,"[{'_account_id': 3}, {'_account_id': 7063}, {'_account_id': 11397}, {'_account_id': 11650}, {'_account_id': 11716}]","[{'number': 1, 'created': '2015-04-24 14:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/300273c43727426dce536a5c6272017f78a0f7ba', 'message': 'Simplifying the validator config\n\nLess nesting, removed redundent lists\n\nChange-Id: Ib223deca5bfd5fc67560fd030813020a07e054ce\n'}, {'number': 2, 'created': '2015-04-30 11:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/85d2d99692780fc23b190149d5ea83366081ce23', 'message': 'Simplifying the validator config\n\nLess nesting, removed redundent lists\n\nChange-Id: Ib223deca5bfd5fc67560fd030813020a07e054ce\n'}, {'number': 3, 'created': '2015-04-30 11:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/bd7063af5c03d0a3a92494fd3bba46f02b1cea49', 'message': 'Simplifying the validator config\n\nLess nesting, removed redundent lists\n\nChange-Id: Ib223deca5bfd5fc67560fd030813020a07e054ce\n'}, {'number': 4, 'created': '2015-05-05 11:46:36.000000000', 'files': ['config.json', 'anchor/certificate_ops.py', 'tests/controllers/bad_config_domains.py', 'tests/test_certificate_ops.py', 'tests/test_functional.py', 'tests/controllers/test_app.py', 'tests/controllers/good_config_domains.py', 'anchor/app.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/abd2fef7a870c81dcebd259a3986b5a282487c4f', 'message': 'Simplifying the validator config\n\nLess nesting, removed redundent lists\n\nChange-Id: Ib223deca5bfd5fc67560fd030813020a07e054ce\n'}]",12,177281,abd2fef7a870c81dcebd259a3986b5a282487c4f,29,5,4,11716,,,0,"Simplifying the validator config

Less nesting, removed redundent lists

Change-Id: Ib223deca5bfd5fc67560fd030813020a07e054ce
",git fetch https://review.opendev.org/openstack/anchor refs/changes/81/177281/4 && git format-patch -1 --stdout FETCH_HEAD,"['config.json', 'anchor/certificate_ops.py', 'tests/controllers/bad_config_domains.py', 'tests/test_certificate_ops.py', 'tests/test_functional.py', 'tests/controllers/test_app.py', 'tests/controllers/good_config_domains.py', 'anchor/app.py']",8,300273c43727426dce536a5c6272017f78a0f7ba,simplifying_config,"def config_check_domains(validator_set): for name, step in validator_set.iteritems(): if 'allowed_domains' in step: for domain in step['allowed_domains']: if not domain.startswith('.'): raise ConfigValidationException( ""Domain that does not start with "" ""a '.' <{}>"".format(domain)) print(""Found {} validator sets."".format(len(conf.validators))) for name, validator_set in conf.validators.iteritems(): print(""Checking validator set <{}> ...."".format(name)) if len(validator_set) == 0: raise ConfigValidationException( ""Validator set <{}> is empty"".format(name)) for step in validator_set.keys(): if not hasattr(validators, step): raise ConfigValidationException( ""Validator set <{}> contains an "" ""unknown validator <{}>"".format(name, step)) config_check_domains(validator_set) print(""OK"")","def config_check_domains(conf): # gc.validators[0]['steps'][0][1]['allowed_domains'] for validator in conf.validators: for step in validator['steps']: if 'allowed_domains' in step[1]: for domain in step[1]['allowed_domains']: if not domain.startswith('.'): raise ConfigValidationException( ""Domain that does not start with "" ""a '.' <%s>"", domain) for i, validators_list in enumerate(conf.validators): name = validators_list.get(""name"") if not name: raise ConfigValidationException(""Validator set <%d> is missing a "" ""name"" % (i + 1)) if not validators_list.get(""steps""): raise ConfigValidationException(""Validator set <%s> is missing "" ""validation steps"" % name) for step in validators_list[""steps""]: if len(step) == 0: raise ConfigValidationException(""Validator set <%s> contains "" ""a step with no validator "" ""name"" % name) if not hasattr(validators, step[0]): raise ConfigValidationException(""Validator set <%s> contains "" ""an unknown validator <%s>"" % (name, step[0])) config_check_domains(conf)",156,447
openstack%2Ffuel-library~master~I879f4d31d25900e8dc9ae400205fe295e35b93d1,openstack/fuel-library,master,I879f4d31d25900e8dc9ae400205fe295e35b93d1,Fix dependency to ubuntu_service_override for cs_service,MERGED,2015-05-20 16:43:34.000000000,2015-05-20 21:58:57.000000000,2015-05-20 21:58:16.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-20 16:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/785bd0319ee07e93d389a54d351af2d5edd21bed', 'message': ""Fix dependencies for ubuntu_service_override tweak\n\nSometimes it's possible that ubuntu override file isn't deleted before\nPacemaker starts to evaluate an HA resource. It leads to the missing override\nfile at the end of deployment, and a service can be started by upstart.\n\nChange-Id: I879f4d31d25900e8dc9ae400205fe295e35b93d1\nCloses-bug: #1457115\n""}, {'number': 2, 'created': '2015-05-20 17:16:07.000000000', 'files': ['deployment/puppet/cluster/manifests/corosync/cs_service.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fb1add6b93a06cbf176c2a15e009203dd2fc1a3b', 'message': ""Fix dependency to ubuntu_service_override for cs_service\n\nSometimes it's possible that ubuntu override file isn't deleted before\nPacemaker starts to evaluate an HA resource. It leads to the missing override\nfile at the end of deployment, and a service can be started by upstart.\n\nChange-Id: I879f4d31d25900e8dc9ae400205fe295e35b93d1\nCloses-bug: #1457115\n""}]",0,184541,fb1add6b93a06cbf176c2a15e009203dd2fc1a3b,44,8,2,7604,,,0,"Fix dependency to ubuntu_service_override for cs_service

Sometimes it's possible that ubuntu override file isn't deleted before
Pacemaker starts to evaluate an HA resource. It leads to the missing override
file at the end of deployment, and a service can be started by upstart.

Change-Id: I879f4d31d25900e8dc9ae400205fe295e35b93d1
Closes-bug: #1457115
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/41/184541/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/tweaks/manifests/ubuntu_service_override.pp'],1,785bd0319ee07e93d389a54d351af2d5edd21bed,bug/1457115, Exec[$exec_name] -> Service[$service_name],,1,0
openstack%2Fpython-barbicanclient~master~I1fd2ec5f96d335d2c008d290a09e1133ff03e94c,openstack/python-barbicanclient,master,I1fd2ec5f96d335d2c008d290a09e1133ff03e94c,Add support for certificate order,MERGED,2015-05-01 14:42:27.000000000,2015-05-20 21:58:04.000000000,2015-05-20 21:58:02.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-05-01 14:42:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/488899d7ce690e127551763b2a7801d4f1ba104c', 'message': 'Add support for certificate order\n\nThis adds the ability to create and list certificate orders, using new\nparameters for order create a specific handling for listing.\n\nChange-Id: I1fd2ec5f96d335d2c008d290a09e1133ff03e94c\n'}, {'number': 2, 'created': '2015-05-04 14:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/67510756ef4f213c86cf7ec0ad3b1aea207b7eaf', 'message': 'Add support for certificate order\n\nThis adds the ability to create and list certificate orders, using new\nparameters for order create a specific handling for listing.\n\nCloses-Bug: #1451458\nChange-Id: I1fd2ec5f96d335d2c008d290a09e1133ff03e94c\n'}, {'number': 3, 'created': '2015-05-08 17:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/b4cc293ee6e7a3eb4a542dec37b2865ce71d3330', 'message': 'Add support for certificate order\n\nThis adds the ability to create and list certificate orders, using new\nparameters for order create a specific handling for listing.\n\nCloses-Bug: #1451458\nChange-Id: I1fd2ec5f96d335d2c008d290a09e1133ff03e94c\n'}, {'number': 4, 'created': '2015-05-08 19:42:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/5f6fd8f967c9c1aa50d5a318c1dcbe9bf94c660c', 'message': 'Add support for certificate order\n\nThis adds the ability to create and list certificate orders, using new\nparameters for order create a specific handling for listing.\n\nCloses-Bug: #1451458\nChange-Id: I1fd2ec5f96d335d2c008d290a09e1133ff03e94c\n'}, {'number': 5, 'created': '2015-05-09 08:42:12.000000000', 'files': ['barbicanclient/barbican_cli/orders.py', 'barbicanclient/orders.py', 'barbicanclient/tests/test_orders.py'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/b5ef798446b4fc0b410641ee8c5653ded91a437a', 'message': 'Add support for certificate order\n\nThis adds the ability to create and list certificate orders, using new\nparameters for order create a specific handling for listing.\n\nCloses-Bug: #1451458\nChange-Id: I1fd2ec5f96d335d2c008d290a09e1133ff03e94c\n'}]",2,179397,b5ef798446b4fc0b410641ee8c5653ded91a437a,19,7,5,7385,,,0,"Add support for certificate order

This adds the ability to create and list certificate orders, using new
parameters for order create a specific handling for listing.

Closes-Bug: #1451458
Change-Id: I1fd2ec5f96d335d2c008d290a09e1133ff03e94c
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/97/179397/2 && git format-patch -1 --stdout FETCH_HEAD,"['barbicanclient/barbican_cli/orders.py', 'barbicanclient/orders.py', 'barbicanclient/tests/test_orders.py']",3,488899d7ce690e127551763b2a7801d4f1ba104c,bug/1451458," class WhenTestingCertificateOrders(test_client.BaseEntityResource): def setUp(self): self._setUp('orders', entity_id='d0460cc4-2876-4493-b7de-fc5c812883cc') self.container_ref = ( self.endpoint + '/containers/a2292306-6da0-4f60-bd8a-84fc8d692716') self.source_container_ref = ( self.endpoint + '/containers/c6f20480-c1e5-442b-94a0-cb3b5e0cf179') self.cert_order_data = """"""{{ ""status"": ""ACTIVE"", ""container_ref"": ""{0}"", ""updated"": ""2014-10-21T17:15:50.871596"", ""meta"": {{ ""name"": ""secretname"", ""subject_dn"": ""cn=server.example.com,o=example.com"", ""request_type"": ""stored-key"", ""container_ref"": ""{1}"" }}, ""created"": ""2014-10-21T17:15:50.824202"", ""type"": ""certificate"", ""order_ref"": ""{2}"" }}"""""".format(self.container_ref, self.source_container_ref, self.entity_href) self.manager = self.client.orders def _get_order_args(self, order_data): order_args = json.loads(order_data) order_args.update(order_args.pop('meta')) order_args.pop('type') return order_args def test_get(self): self.responses.get(self.entity_href, text=self.cert_order_data) order = self.manager.get(order_ref=self.entity_href) self.assertIsInstance(order, orders.CertificateOrder) self.assertEqual(self.entity_href, order.order_ref) # Verify the correct URL was used to make the call. self.assertEqual(self.entity_href, self.responses.last_request.url) def test_repr(self): order_args = self._get_order_args(self.cert_order_data) order_obj = orders.CertificateOrder(api=None, **order_args) self.assertIn('order_ref=' + self.entity_href, repr(order_obj)) def test_constructor(self): data = {'order_ref': self.entity_href} self.responses.post(self.entity_base + '/', json=data) order = self.manager.create_certificate( name='name', subject_dn='cn=server.example.com,o=example.com', request_type='stored-key', source_container_ref=self.source_container_ref ) order_href = order.submit() self.assertEqual(self.entity_href, order_href) # Verify the correct URL was used to make the call. self.assertEqual(self.entity_base + '/', self.responses.last_request.url) # Verify that correct information was sent in the call. order_req = json.loads(self.responses.last_request.text) self.assertEqual('name', order_req['meta']['name']) self.assertEqual('cn=server.example.com,o=example.com', order_req['meta']['subject_dn']) self.assertEqual('stored-key', order_req['meta']['request_type']) self.assertEqual(self.source_container_ref, order_req['meta']['container_ref']) def test_list(self): data = {""orders"": [json.loads(self.cert_order_data) for _ in range(3)]} self.responses.get(self.entity_base, json=data) orders_list = self.manager.list(limit=10, offset=5) self.assertEqual(len(orders_list), 3) self.assertIsInstance(orders_list[0], orders.CertificateOrder) self.assertEqual(self.entity_href, orders_list[0].order_ref)"," self.assertEqual(total, 1)",187,11
openstack%2Fpuppet-keystone~master~I6eb3d137173d2542a8083bbca3acf3bee10c5919,openstack/puppet-keystone,master,I6eb3d137173d2542a8083bbca3acf3bee10c5919,Decouple sync_db from enabled,MERGED,2015-05-06 14:33:56.000000000,2015-05-20 21:52:31.000000000,2015-05-20 21:52:29.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 7155}, {'_account_id': 8042}, {'_account_id': 8112}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-05-06 14:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/493ff063f37763e51b4827661759d2c56ec31743', 'message': 'Decouple sync_db from enabled\n\nWe want db_sync to run even though enabled can be set to False.\n\nChange-Id: I6eb3d137173d2542a8083bbca3acf3bee10c5919\nCloses-Bug: 1452278\n'}, {'number': 2, 'created': '2015-05-06 14:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/7aa454df698d63175f017bd3f07f6d06871f7dac', 'message': 'Decouple sync_db from enabled\n\nWe want db_sync to run even though enabled can be set to False.\n\nChange-Id: I6eb3d137173d2542a8083bbca3acf3bee10c5919\nCloses-Bug: 1452278\n'}, {'number': 3, 'created': '2015-05-06 15:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/8c41ad2ff33191f509528c04d8e01d3a97670637', 'message': 'Decouple sync_db from enabled\n\nWe want db_sync to run even though enabled can be set to False.\n\nChange-Id: I6eb3d137173d2542a8083bbca3acf3bee10c5919\nCloses-Bug: 1452278\n'}, {'number': 4, 'created': '2015-05-12 10:42:06.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/3c08645ba8b894d3adce3d65464dd43a0a33ce55', 'message': 'Decouple sync_db from enabled\n\nWe want db_sync to run even though enabled can be set to False.\n\nChange-Id: I6eb3d137173d2542a8083bbca3acf3bee10c5919\nCloses-Bug: 1452278\n'}]",1,180565,3c08645ba8b894d3adce3d65464dd43a0a33ce55,31,8,4,6796,,,0,"Decouple sync_db from enabled

We want db_sync to run even though enabled can be set to False.

Change-Id: I6eb3d137173d2542a8083bbca3acf3bee10c5919
Closes-Bug: 1452278
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/65/180565/4 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,493ff063f37763e51b4827661759d2c56ec31743,bug/1452278, if $sync_db {, if $enabled and $sync_db {,1,1
openstack%2Fdjango_openstack_auth~master~I1eeab29e7bf41cc437c0ddb4a517fdb4858dea40,openstack/django_openstack_auth,master,I1eeab29e7bf41cc437c0ddb4a517fdb4858dea40,WIP - Reduce session size,ABANDONED,2015-05-01 16:37:07.000000000,2015-05-20 21:48:04.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 7665}, {'_account_id': 9142}]","[{'number': 1, 'created': '2015-05-01 16:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/34c1fcd35d6cf949ae8ab16eeba54ebd368cfcf3', 'message': 'WIP - Reduce session size\n\nChange-Id: I1eeab29e7bf41cc437c0ddb4a517fdb4858dea40\n'}, {'number': 2, 'created': '2015-05-01 17:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/de0c2c66843048258933878f7a5dc771e6fc3b8b', 'message': 'WIP - Reduce session size\n\nChange-Id: I1eeab29e7bf41cc437c0ddb4a517fdb4858dea40\n'}, {'number': 3, 'created': '2015-05-04 06:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/9bc49ff41a9097ad401f34d206e2c53e493acfd4', 'message': 'WIP - Reduce session size\n\nChange-Id: I1eeab29e7bf41cc437c0ddb4a517fdb4858dea40\n'}, {'number': 4, 'created': '2015-05-05 02:52:22.000000000', 'files': ['openstack_auth/user.py', 'openstack_auth/views.py', 'openstack_auth/backend.py', 'openstack_auth/utils.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/8545263ebae69ed13e39e648e882eef933c6d7b6', 'message': 'WIP - Reduce session size\n\nImplements: bp session-token-improvement\n\nChange-Id: I1eeab29e7bf41cc437c0ddb4a517fdb4858dea40\n'}]",5,179419,8545263ebae69ed13e39e648e882eef933c6d7b6,18,4,4,1941,,,0,"WIP - Reduce session size

Implements: bp session-token-improvement

Change-Id: I1eeab29e7bf41cc437c0ddb4a517fdb4858dea40
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/19/179419/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/user.py'],1,34c1fcd35d6cf949ae8ab16eeba54ebd368cfcf3,bp/session-token-improvement,"def get_service_catalog(request, auth_url, token, project_id): if hasattr(request, 'service_catalog'): return request.service_catalog session = utils.get_session() auth_url = utils.fix_auth_url_version(auth_url) scoped_auth = utils.get_token_auth_plugin(auth_url, token=token, project_id=project_id) scoped_auth_ref = scoped_auth.get_access(session) request.service_catalog = scoped_auth_ref.service_catalog.get_data() return request.service_catalog svc_catalog = get_service_catalog(request, endpoint, token.id, token.project['id']) #svc_catalog = token.serviceCatalog utils.default_services_region(svc_catalog, request) service_catalog=svc_catalog, self.serviceCatalog = None #auth_ref.service_catalog.get_data() #self.serviceCatalog = [{u'endpoints': [{u'url': u'http://10.0.2.15:8773/', u'interface': u'internal', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'0e9ee4973a3b44279b70a4b2e2ec7ef8'}, {u'url': u'http://10.0.2.15:8773/', u'interface': u'admin', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'c454da79de2041ee8ccb0d1dcd61d295'}, {u'url': u'http://10.0.2.15:8773/', u'interface': u'public', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'd664e3e8db514483856e12c5055b7747'}], u'type': u'ec2', u'id': u'170fe519934d40b5b5e0ccaf4e456966', u'name': u'ec2'}, {u'endpoints': [{u'url': u'http://10.0.2.15:8776/v1/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'admin', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'1b06bcf157ea4ae49a4c3adf3906dd2c'}, {u'url': u'http://10.0.2.15:8776/v1/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'internal', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'798b65e9c1ab4cf696778acb572f2cc4'}, {u'url': u'http://10.0.2.15:8776/v1/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'public', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'85a1f259e56d4ab99554d902383b9182'}], u'type': u'volume', u'id': u'5289390282a449d2b7f695e8c4db3d6a', u'name': u'cinder'}, {u'endpoints': [{u'url': u'http://10.0.2.15:8776/v2/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'admin', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'83e9d244506a42d7b1ff6cd472a270b5'}, {u'url': u'http://10.0.2.15:8776/v2/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'internal', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'9c320d28d9d143b1ba699c758dc814de'}, {u'url': u'http://10.0.2.15:8776/v2/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'public', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'eed7fb062af141bb880861414c9d8354'}], u'type': u'volumev2', u'id': u'750f50b4ae3b4d5591401771d5889514', u'name': u'cinderv2'}, {u'endpoints': [{u'url': u'http://10.0.2.15:9292', u'interface': u'internal', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'1f9b433983bc4ab6b1ac4f7ac3f51a4a'}, {u'url': u'http://10.0.2.15:9292', u'interface': u'admin', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'7c29e30e888a4db0b506757e021033ad'}, {u'url': u'http://10.0.2.15:9292', u'interface': u'public', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'aae9b809f6424bbba056daf6b1e2a7ae'}], u'type': u'image', u'id': u'759f9397cc1b481fb60cda318eb1bff6', u'name': u'glance'}, {u'endpoints': [{u'url': u'http://10.0.2.15:8774/v2/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'admin', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'4770211533124ef4ba94e38ecd214cc8'}, {u'url': u'http://10.0.2.15:8774/v2/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'internal', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'6c2f478b3404485d95110debdf946e78'}, {u'url': u'http://10.0.2.15:8774/v2/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'public', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'750798740be24415a17ac7b10baf1ae2'}], u'type': u'compute', u'id': u'bf1bae6ab3964e4caf072398e4231b34', u'name': u'nova'}, {u'endpoints': [{u'url': u'http://10.0.2.15:35357/v2.0', u'interface': u'admin', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'4073c5a048f84d519d47dc0a148f6ec4'}, {u'url': u'http://10.0.2.15:5000/v2.0', u'interface': u'public', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'567dcce1d4d54a38954125295584703e'}, {u'url': u'http://10.0.2.15:5000/v2.0', u'interface': u'internal', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'94a68895f457400096d79308c076a585'}], u'type': u'identity', u'id': u'bfe80400769b45099ae46533b1474457', u'name': u'keystone'}, {u'endpoints': [{u'url': u'http://10.0.2.15:8774/v2.1/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'public', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'1b80688304784eafba164fc1f919d0a6'}, {u'url': u'http://10.0.2.15:8774/v2.1/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'admin', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'1d434cc4f6254985b024e7deb561010b'}, {u'url': u'http://10.0.2.15:8774/v2.1/49b5a010ffbe47eb9cf43dc92ce3daf1', u'interface': u'internal', u'region': u'RegionOne', u'region_id': u'RegionOne', u'id': u'f8b5899eb022451bb96bd94920508f59'}], u'type': u'computev21', u'id': u'e3f7358ded1845bdb1d7263bc692a3d6', u'name': u'novav21'}] "," utils.default_services_region(token.serviceCatalog, request) service_catalog=token.serviceCatalog, self.serviceCatalog = auth_ref.service_catalog.get_data()",19,3
openstack%2Fopenstack-manuals~master~I627ebde0c0a9b683c9ff36e261905937625c8e8c,openstack/openstack-manuals,master,I627ebde0c0a9b683c9ff36e261905937625c8e8c,Remove unused common files,MERGED,2015-05-20 12:10:22.000000000,2015-05-20 21:45:21.000000000,2015-05-20 21:45:19.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7923}]","[{'number': 1, 'created': '2015-05-20 12:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1d017ab8f984512145ec43d9609c237c11654ae4', 'message': 'Remove unused common files\n\nThese files are not used for building any of our documents, they were\npart of the User Guides but are now converted to RST and not\nneeded in XML anymore.\n\nChange-Id: I627ebde0c0a9b683c9ff36e261905937625c8e8c\n'}, {'number': 2, 'created': '2015-05-20 12:15:23.000000000', 'files': ['doc/common/section_cli_nova_boot_from_volume.xml', 'doc/common/section_dashboard_access.xml', 'doc/common/section_cli_nova_quotas.xml', 'doc/common/section_cli_keystone_credentials.xml', 'doc/common/section_cli_keystone_example_usage.xml', 'doc/common/section_cli_nova_metadata.xml', 'doc/common/section_cli_neutron_manage_networks.xml', 'doc/common/section_cli_nova_fileinjection.xml', 'doc/common/section_cli_cinder_manage_volumes.xml', 'doc/common/section_cli_nova_images.xml', 'doc/common/section_cli_nova_secgroups.xml', 'doc/common/ch_using_openstack_overview.xml', 'doc/common/section_cli_glance_manage_images.xml', 'doc/common/section_dashboard_launch_instances_from_image.xml', 'doc/common/section_cli_neutron-quotas.xml', 'doc/common/section_cli_help.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/18e34d7f6f2d74dae5e52fbe8c84e6ad7a470baa', 'message': 'Remove unused common files\n\nThese files are not used for building any of our documents, they were\npart of the User Guides but are now converted to RST and not\nneeded in XML anymore.\n\nChange-Id: I627ebde0c0a9b683c9ff36e261905937625c8e8c\n'}]",0,184467,18e34d7f6f2d74dae5e52fbe8c84e6ad7a470baa,8,3,2,6547,,,0,"Remove unused common files

These files are not used for building any of our documents, they were
part of the User Guides but are now converted to RST and not
needed in XML anymore.

Change-Id: I627ebde0c0a9b683c9ff36e261905937625c8e8c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/67/184467/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/section_cli_nova_boot_from_volume.xml', 'doc/common/section_dashboard_access.xml', 'doc/common/section_cli_nova_quotas.xml', 'doc/common/section_cli_keystone_credentials.xml', 'doc/common/section_cli_keystone_example_usage.xml', 'doc/common/section_cli_nova_fileinjection.xml', 'doc/common/section_cli_cinder_manage_volumes.xml', 'doc/common/section_cli_nova_images.xml', 'doc/common/section_cli_nova_secgroups.xml', 'doc/common/section_cli_glance_manage_images.xml', 'doc/common/section_dashboard_launch_instances_from_image.xml', 'doc/common/section_cli_neutron-quotas.xml', 'doc/common/section_cli_help.xml']",13,1d017ab8f984512145ec43d9609c237c11654ae4,common-cleanup,,"<?xml version=""1.0"" encoding=""UTF-8""?> <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""cli_help""> <title>Get help for client commands</title> <para>To get usage information, including a list of commands with descriptions, for a client, run the following command:</para> <screen><prompt>$</prompt> <userinput><replaceable>CLIENT_NAME</replaceable> help</userinput></screen> <para>For example, to get help information for the swift client, run the following command:</para> <screen><prompt>$</prompt> <userinput>swift help</userinput></screen> <screen><?db-font-size 65%?><computeroutput>Usage: swift [--version] [--help] [--snet] [--verbose] [--debug] [--quiet] [--auth &lt;auth_url>] [--auth-version &lt;auth_version>] [--user &lt;username>] [--key &lt;api_key>] [--retries &lt;num_retries>] [--os-username &lt;auth-user-name>] [--os-password &lt;auth-password>] [--os-tenant-id &lt;auth-tenant-id>] [--os-tenant-name &lt;auth-tenant-name>] [--os-auth-url &lt;auth-url>] [--os-auth-token &lt;auth-token>] [--os-storage-url &lt;storage-url>] [--os-region-name &lt;region-name>] [--os-service-type &lt;service-type>] [--os-endpoint-type &lt;endpoint-type>] [--os-cacert &lt;ca-certificate>] [--insecure] [--no-ssl-compression] &lt;subcommand> ... Command-line interface to the OpenStack Swift API. Positional arguments: &lt;subcommand> delete Delete a container or objects within a container download Download objects from containers list Lists the containers for the account or the objects for a container post Updates meta information for the account, container, or object stat Displays information for the account, container, or object upload Uploads files or directories to the given container Examples: swift -A https://auth.api.rackspacecloud.com/v1.0 -U user -K api_key stat -v swift --os-auth-url https://api.example.com/v2.0 --os-tenant-name tenant \ --os-username user --os-password password list swift --os-auth-token 6ee5eb33efad4e45ab46806eac010566 \ --os-storage-url https://10.1.5.2:8080/v1/AUTH_ced809b6a4baea7aeab61a \ list swift list --lh</computeroutput></screen> <note> <para>Depending on your credentials, you might not have permission to use every command.</para> </note> <para>After the <option>help</option> command, you can enter a command name to get help for that command, as follows:</para> <screen><prompt>$</prompt> <userinput><replaceable>CLIENT_NAME</replaceable> help <replaceable>COMMAND_NAME</replaceable></userinput></screen> <para>For example, to get help for the glance <command>image-show</command> command, enter the following command:</para> <screen><prompt>$</prompt> <userinput>glance help image-show</userinput></screen> <para>The command returns a description of the command and its positional and optional arguments:</para> <screen><?db-font-size 75%?><computeroutput>usage: glance image-show [--human-readable] &lt;IMAGE> Describe a specific image. Positional arguments: &lt;IMAGE> Name or ID of image to describe. Optional arguments: --human-readable Print image size in a human-friendly format.</computeroutput></screen> </section> ",0,3037
openstack%2Fapi-site~master~I090b9a3d46511061811bdaffda219a662497b61f,openstack/api-site,master,I090b9a3d46511061811bdaffda219a662497b61f,Update volume size from GB to GiB,MERGED,2015-05-20 02:35:02.000000000,2015-05-20 21:33:51.000000000,2015-05-20 21:33:49.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7923}]","[{'number': 1, 'created': '2015-05-20 02:35:02.000000000', 'files': ['api-ref/src/wadls/volume-api/src/v2/os-volume-manage-v2.wadl', 'api-ref/src/wadls/volume-api/src/v2/volume-api-v2.wadl', 'api-ref/src/wadls/volume-api/src/v2/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/b32caadc5dc500b04ee19fe9572a9205ec3ab903', 'message': 'Update volume size from GB to GiB\n\nChange-Id: I090b9a3d46511061811bdaffda219a662497b61f\nPartial-Bug: #1456631\n'}]",0,184405,b32caadc5dc500b04ee19fe9572a9205ec3ab903,7,3,1,2448,,,0,"Update volume size from GB to GiB

Change-Id: I090b9a3d46511061811bdaffda219a662497b61f
Partial-Bug: #1456631
",git fetch https://review.opendev.org/openstack/api-site refs/changes/05/184405/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/volume-api/src/v2/os-volume-manage-v2.wadl', 'api-ref/src/wadls/volume-api/src/v2/volume-api-v2.wadl', 'api-ref/src/wadls/volume-api/src/v2/common.ent']",3,b32caadc5dc500b04ee19fe9572a9205ec3ab903,bug/1456631," <para>Maximum total amount of volumes, in gibibytes (GiB).</para></wadl:doc> <para>Total number of gibibytes (GiB) used.</para></wadl:doc> gibibytes (GiB).</para></wadl:doc> <para>The size of the volume, in gibibytes (GiB).</para></wadl:doc>"," <para>Maximum total amount of volumes (GB).</para></wadl:doc> <para>Total number of GBs used.</para></wadl:doc> GBs.</para></wadl:doc> <para>The size of the volume, in GBs.</para></wadl:doc>",11,8
openstack%2Fnova~master~Iecb9d8970dd97d3d9068e1cff08f05df877a65fb,openstack/nova,master,Iecb9d8970dd97d3d9068e1cff08f05df877a65fb,Connecting Nova to DRBD storage nodes directly.,ABANDONED,2015-01-22 13:09:53.000000000,2015-05-20 21:22:44.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 14339}]","[{'number': 1, 'created': '2015-01-22 13:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/531247790d681b54dd850b31d34b3b4360d75adc', 'message': 'Connecting Nova to DRBD storage nodes directly.\n\nsee https://review.openstack.org/#/c/134153/\n\nChange-Id: Iecb9d8970dd97d3d9068e1cff08f05df877a65fb\n'}, {'number': 2, 'created': '2015-01-22 14:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a82a32ef060ab609603798769d9c9a37be9576f', 'message': 'Connecting Nova to DRBD storage nodes directly.\n\nsee https://review.openstack.org/#/c/134153/\n\nChange-Id: Iecb9d8970dd97d3d9068e1cff08f05df877a65fb\n'}, {'number': 3, 'created': '2015-02-12 13:41:00.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/volume.py', 'etc/nova/rootwrap.d/compute.filters'], 'web_link': 'https://opendev.org/openstack/nova/commit/fbd059a0d64d0651106da605af473bc628c6d35a', 'message': 'Connecting Nova to DRBD storage nodes directly.\n\nsee https://review.openstack.org/#/c/134153/\n\nChange-Id: Iecb9d8970dd97d3d9068e1cff08f05df877a65fb\n'}]",8,149244,fbd059a0d64d0651106da605af473bc628c6d35a,32,11,3,10677,,,0,"Connecting Nova to DRBD storage nodes directly.

see https://review.openstack.org/#/c/134153/

Change-Id: Iecb9d8970dd97d3d9068e1cff08f05df877a65fb
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/149244/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/volume.py', 'etc/nova/rootwrap.d/compute.filters']",3,531247790d681b54dd850b31d34b3b4360d75adc,bp/drbd,"# nova/virt/libvirt/volume.py drbdadm: CommandFilter, drbdadm, root",,59,0
openstack%2Ftripleo-puppet-elements~master~I3d54ea0c409eb34f0b25eeb98a30bb785828fbac,openstack/tripleo-puppet-elements,master,I3d54ea0c409eb34f0b25eeb98a30bb785828fbac,Define $DIB_INSTALLTYPE_puppet_modules,MERGED,2015-04-30 14:18:36.000000000,2015-05-20 21:20:53.000000000,2015-05-20 21:20:50.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-04-30 14:18:36.000000000', 'files': ['elements/puppet-modules/environment.d/01-puppet-modules-install-types.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/0c9e2c7655321481ea2900b8dc54687f8d942b36', 'message': ""Define $DIB_INSTALLTYPE_puppet_modules\n\nDefine $DIB_INSTALLTYPE_puppet_modules if it's not already defined,\notherwise this will cause an error if running with -u.\n\nChange-Id: I3d54ea0c409eb34f0b25eeb98a30bb785828fbac\n""}]",0,179101,0c9e2c7655321481ea2900b8dc54687f8d942b36,10,3,1,7144,,,0,"Define $DIB_INSTALLTYPE_puppet_modules

Define $DIB_INSTALLTYPE_puppet_modules if it's not already defined,
otherwise this will cause an error if running with -u.

Change-Id: I3d54ea0c409eb34f0b25eeb98a30bb785828fbac
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/01/179101/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-modules/environment.d/01-puppet-modules-install-types.sh'],1,0c9e2c7655321481ea2900b8dc54687f8d942b36,define-var,"DIB_INSTALLTYPE_puppet_modules=${DIB_INSTALLTYPE_puppet_modules:-""source""} ",,2,0
openstack%2Ftripleo-puppet-elements~master~Ibd57f757fbe5a97592869e8244b9fb4b1a310298,openstack/tripleo-puppet-elements,master,Ibd57f757fbe5a97592869e8244b9fb4b1a310298,Rename $name variable to $module_name,MERGED,2015-05-06 12:01:25.000000000,2015-05-20 21:17:46.000000000,2015-05-20 21:17:45.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 8041}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-06 12:01:25.000000000', 'files': ['elements/puppet-modules/environment.d/01-puppet-modules-install-types.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/22be91c1e8fcd69808b621a8bf4fa5c274523962', 'message': 'Rename $name variable to $module_name\n\ndib-run-parts also uses a $name variable as part of its log output.\nSince $name was being set here, it caused the name of the last listed\npuppet module (puppet-tuskar in this case) to be logged on every line of\noutput from the entire diskimage-builder run. Use $module_name to avoid\nthe variable name collision.\n\nChange-Id: Ibd57f757fbe5a97592869e8244b9fb4b1a310298\n'}]",0,180499,22be91c1e8fcd69808b621a8bf4fa5c274523962,9,4,1,7144,,,0,"Rename $name variable to $module_name

dib-run-parts also uses a $name variable as part of its log output.
Since $name was being set here, it caused the name of the last listed
puppet module (puppet-tuskar in this case) to be logged on every line of
output from the entire diskimage-builder run. Use $module_name to avoid
the variable name collision.

Change-Id: Ibd57f757fbe5a97592869e8244b9fb4b1a310298
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/99/180499/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-modules/environment.d/01-puppet-modules-install-types.sh'],1,22be91c1e8fcd69808b621a8bf4fa5c274523962,name, for module_name in \ export DIB_INSTALLTYPE_${module_name//\-/_}='source', for name in \ export DIB_INSTALLTYPE_${name//\-/_}='source',2,2
openstack%2Fkeystone~master~I48dedfd61fb389961c4c72c26752352c087ae5a7,openstack/keystone,master,I48dedfd61fb389961c4c72c26752352c087ae5a7,Fixes deprecations test for Python3,MERGED,2015-04-24 19:56:51.000000000,2015-05-20 21:15:25.000000000,2015-05-20 21:15:24.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 9142}]","[{'number': 1, 'created': '2015-04-24 19:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b968f34883effa99d7508ef46d13e7874d1ccf90', 'message': 'Fixes deprecations test for Python3\n\nJust us the warning module directly to trigger the expected behavior. It\nis imposible to find a language feature that is deprecated in all\nsupported versions of Python.\n\nbp python3\n\nChange-Id: I48dedfd61fb389961c4c72c26752352c087ae5a7\n'}, {'number': 2, 'created': '2015-04-25 00:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/770e77d9993073f032f200892aaa578c82a80d74', 'message': 'Fixes deprecations test for Python3\n\nJust us the warning module directly to trigger the expected behavior. It\nis imposible to find a language feature that is deprecated in all\nsupported versions of Python.\n\nbp python3\n\nChange-Id: I48dedfd61fb389961c4c72c26752352c087ae5a7\n'}, {'number': 3, 'created': '2015-04-29 20:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9415f5c337912a80d8b2f59670c401c96d4344cc', 'message': 'Fixes deprecations test for Python3\n\nJust us the warning module directly to trigger the expected behavior. It\nis imposible to find a language feature that is deprecated in all\nsupported versions of Python.\n\nbp python3\n\nChange-Id: I48dedfd61fb389961c4c72c26752352c087ae5a7\n'}, {'number': 4, 'created': '2015-05-08 11:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3073df4b2035752037a836ec1c8e4f787ffb4c90', 'message': 'Fixes deprecations test for Python3\n\nJust use the warning module directly to trigger the expected behavior.\nIt is imposible to find a language feature that is deprecated in all\nsupported versions of Python.\n\nbp python3\n\nChange-Id: I48dedfd61fb389961c4c72c26752352c087ae5a7\n'}, {'number': 5, 'created': '2015-05-08 11:11:35.000000000', 'files': ['keystone/tests/unit/tests/test_core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2aa92f7c816ff4a4af4fd739911186b6db1181c8', 'message': 'Fixes deprecations test for Python3\n\nJust use the warning module directly to trigger the expected behavior.\nIt is imposible to find a language feature that is deprecated in all\nsupported versions of Python.\n\nbp python3\n\nChange-Id: I48dedfd61fb389961c4c72c26752352c087ae5a7\n'}]",5,177415,2aa92f7c816ff4a4af4fd739911186b6db1181c8,19,5,5,7725,,,0,"Fixes deprecations test for Python3

Just use the warning module directly to trigger the expected behavior.
It is imposible to find a language feature that is deprecated in all
supported versions of Python.

bp python3

Change-Id: I48dedfd61fb389961c4c72c26752352c087ae5a7
",git fetch https://review.opendev.org/openstack/keystone refs/changes/15/177415/5 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/tests/test_core.py'],1,b968f34883effa99d7508ef46d13e7874d1ccf90,bp/python3," warnings.warn('this is deprecated', DeprecationWarning)", # DeprecationWarning: BaseException.message has been deprecated as # of Python 2.6 try: raise Exception('something') except Exception as e: e.message,1,6
openstack%2Fnova~master~Id4e405e7579530ed1c1f22ccc972d45b6d185f41,openstack/nova,master,Id4e405e7579530ed1c1f22ccc972d45b6d185f41,"Revert ""Detach volume after deleting instance with no host""",MERGED,2015-05-20 17:36:21.000000000,2015-05-20 21:07:39.000000000,2015-05-20 21:07:36.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-20 17:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c6daadbbdb293603920c1887bc84ad8fa84d0c3', 'message': 'Revert ""Detach volume after deleting instance with no host""\n\nThis reverts commit d1baa9fe7eb342b63fc85cbb5ef70bb676de6566\n\nThe change introduced a race on delete where there isn\'t a host while prepping block devices and we hit a NoneType error in nova-compute.\n\nThere was also a recheck grind on the original change showing it wasn\'t safe and needs to be reworked.\n\nChange-Id: Id4e405e7579530ed1c1f22ccc972d45b6d185f41\nCloses-Bug: #1456771\nRelated-Bug: #1448316\n'}, {'number': 2, 'created': '2015-05-20 17:37:20.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/api/openstack/compute/plugins/v3/test_servers.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/compute/test_servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1ba72081715869fe6d0ffba3436fb09ef9499335', 'message': 'Revert ""Detach volume after deleting instance with no host""\n\nThis reverts commit d1baa9fe7eb342b63fc85cbb5ef70bb676de6566\n\nThe change introduced a race on delete where there isn\'t a host while\nprepping block devices and we hit a NoneType error in nova-compute.\n\nThere was also a recheck grind on the original change showing it wasn\'t\nsafe and needs to be reworked.\n\nChange-Id: Id4e405e7579530ed1c1f22ccc972d45b6d185f41\nCloses-Bug: #1456771\nRelated-Bug: #1448316\n'}]",0,184554,1ba72081715869fe6d0ffba3436fb09ef9499335,14,10,2,6873,,,0,"Revert ""Detach volume after deleting instance with no host""

This reverts commit d1baa9fe7eb342b63fc85cbb5ef70bb676de6566

The change introduced a race on delete where there isn't a host while
prepping block devices and we hit a NoneType error in nova-compute.

There was also a recheck grind on the original change showing it wasn't
safe and needs to be reworked.

Change-Id: Id4e405e7579530ed1c1f22ccc972d45b6d185f41
Closes-Bug: #1456771
Related-Bug: #1448316
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/184554/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/api/openstack/compute/plugins/v3/test_servers.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/compute/test_servers.py', 'nova/compute/api.py']",5,8c6daadbbdb293603920c1887bc84ad8fa84d0c3,bug/1404867," shelved_offloaded = (instance.vm_state == vm_states.SHELVED_OFFLOADED) if not instance.host and not shelved_offloaded: try: compute_utils.notify_about_instance_usage( self.notifier, context, instance, ""%s.start"" % delete_type) instance.destroy() compute_utils.notify_about_instance_usage( self.notifier, context, instance, ""%s.end"" % delete_type, system_metadata=instance.system_metadata) quotas.commit() return except exception.ObjectActionError: instance.refresh() is_local_delete = True try: if not shelved_offloaded: if not is_local_delete: if original_task_state in (task_states.DELETING, task_states.SOFT_DELETING): LOG.info(_LI('Instance is already in deleting state, ' 'ignoring this request'), instance=instance) quotas.rollback() return self._record_action_start(context, instance, instance_actions.DELETE) # NOTE(snikitin): If instance's vm_state is 'soft-delete', # we should not count reservations here, because instance # in soft-delete vm_state have already had quotas # decremented. More details: # https://bugs.launchpad.net/nova/+bug/1333145 if instance.vm_state == vm_states.SOFT_DELETED: quotas.rollback() cb(context, instance, bdms, reservations=quotas.reservations) except exception.ComputeHostNotFound: pass # isn't up, delete instance from db and clean bdms info and # network info"," if (not instance.host or instance.vm_state == vm_states.SHELVED_OFFLOADED): is_local_delete = True else: try: except exception.ComputeHostNotFound: is_local_delete = True # isn't up or is unknown i.e. instance.host is None, delete # instance from db and clean bdms info and network info else: if original_task_state in (task_states.DELETING, task_states.SOFT_DELETING): LOG.info(_LI('Instance is already in deleting state, ' 'ignoring this request'), instance=instance) quotas.rollback() return self._record_action_start(context, instance, instance_actions.DELETE) # NOTE(snikitin): If instance's vm_state is 'soft-delete', # we should not count reservations here, because instance # in soft-delete vm_state have already had quotas # decremented. More details: # https://bugs.launchpad.net/nova/+bug/1333145 if instance.vm_state == vm_states.SOFT_DELETED: quotas.rollback() cb(context, instance, bdms, reservations=quotas.reservations)",112,201
openstack%2Ftripleo-heat-templates~master~Iffa19edc39e880cf3ae243277ffcc23a6eaa6b89,openstack/tripleo-heat-templates,master,Iffa19edc39e880cf3ae243277ffcc23a6eaa6b89,Compute: os-net-config for isolated networks,ABANDONED,2015-05-11 17:50:50.000000000,2015-05-20 20:58:13.000000000,,"[{'_account_id': 3}, {'_account_id': 360}]","[{'number': 1, 'created': '2015-05-11 17:50:50.000000000', 'files': ['network/config/compute-bonded-vlan.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ab39fd57eae8cf8a2b5b49833ee106ce213bcd22', 'message': 'Compute: os-net-config for isolated networks\n\nThis patch adds a new os-net-config script that configures\nisolated VLAN networks for the compute role on top of\na 2 NIC (nic2 and nic3) OVS bonded bridge.\n\nThis provisioning network bridge is still created\non nic1.\n\nChange-Id: Iffa19edc39e880cf3ae243277ffcc23a6eaa6b89\n'}]",0,181999,ab39fd57eae8cf8a2b5b49833ee106ce213bcd22,6,2,1,360,,,0,"Compute: os-net-config for isolated networks

This patch adds a new os-net-config script that configures
isolated VLAN networks for the compute role on top of
a 2 NIC (nic2 and nic3) OVS bonded bridge.

This provisioning network bridge is still created
on nic1.

Change-Id: Iffa19edc39e880cf3ae243277ffcc23a6eaa6b89
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/99/181999/1 && git format-patch -1 --stdout FETCH_HEAD,['network/config/compute-bonded-vlan.yaml'],1,ab39fd57eae8cf8a2b5b49833ee106ce213bcd22,networks,heat_template_version: 2014-10-16 description: > Compute role softare config to drive os-net-config configuration for isolated Vlan network(s) on top of two OVS Bonded NICs. The provisioning network continues to run on nic1. parameters: ExternalIpSubnet: description: IP address/subnet on the external network type: string InternalApiIpSubnet: description: IP address/subnet on the internal API network type: string StorageIpSubnet: description: IP address/subnet on the storage network type: string StorageMgmtIpSubnet: description: IP address/subnet on the storage mgmt network type: string TenantIpSubnet: description: IP address/subnet on the tenant network type: string resources: OsNetConfigImpl: type: OS::Heat::StructuredConfig properties: group: os-apply-config config: os_net_config: network_config: - type: ovs_bridge name: {get_input: bridge_name} use_dhcp: true members: - type: interface name: nic1 # force the MAC address of the bridge to this interface primary: true - type: ovs_bridge name: br-bond members: - type: ovs_bond name: bond1 members: - type: interface name: nic2 - type: interface name: nic3 - type: vlan device: bond1 vlan_id: 10 addresses: - ip_netmask: {get_param: TenantIpSubnet} - type: vlan device: bond1 vlan_id: 20 addresses: - ip_netmask: {get_param: StorageIpSubnet} - type: vlan device: bond1 vlan_id: 30 addresses: - ip_netmask: {get_param: InternalApiIpSubnet} outputs: config_id: description: The ID of the OsNetConfigImpl resource. value: {get_resource: OsNetConfigImpl} ,,83,0
openstack%2Fcinder~master~I4e1ddf02087499b4efff6eabf2310a245bef93c9,openstack/cinder,master,I4e1ddf02087499b4efff6eabf2310a245bef93c9,Add new exception to retryables in SolidFire driver,MERGED,2015-05-04 17:32:58.000000000,2015-05-20 20:47:03.000000000,2015-05-09 16:45:54.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 8119}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 10058}, {'_account_id': 10263}, {'_account_id': 10379}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15764}]","[{'number': 1, 'created': '2015-05-04 17:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7228bea4961486ec5b4e0f1df2a3d7a664ff3dc0', 'message': 'Add new exception to retryables in SolidFire driver\n\nNewer versions of SolidFire Element OS introduce an\ninternal snapshot mechanism during cloning that also\nincludes a new exception (xNotReadyForIO).\n\nThis can be encountered when programmatically cloning\nhundreds of large volumes. Typically this will succeed\non a retry of the clone command, so we should add this\nnew exception to our list of retryable exceptions in\nthe SolidFire driver.\n\nChange-Id: I4e1ddf02087499b4efff6eabf2310a245bef93c9\nCloses-Bug: #1451505\n'}, {'number': 2, 'created': '2015-05-09 15:02:04.000000000', 'files': ['cinder/volume/drivers/solidfire.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3c431998f8f88d823a89423c2c34d878f0fdb4ce', 'message': 'Add new exception to retryables in SolidFire driver\n\nNewer versions of SolidFire Element OS introduce an\ninternal snapshot mechanism during cloning that also\nincludes a new exception (xNotReadyForIO).\n\nThis can be encountered when programmatically cloning\nhundreds of large volumes. Typically this will succeed\non a retry of the clone command, so we should add this\nnew exception to our list of retryable exceptions in\nthe SolidFire driver.\n\nChange-Id: I4e1ddf02087499b4efff6eabf2310a245bef93c9\nCloses-Bug: #1451505\n'}]",0,179849,3c431998f8f88d823a89423c2c34d878f0fdb4ce,68,31,2,2243,,,0,"Add new exception to retryables in SolidFire driver

Newer versions of SolidFire Element OS introduce an
internal snapshot mechanism during cloning that also
includes a new exception (xNotReadyForIO).

This can be encountered when programmatically cloning
hundreds of large volumes. Typically this will succeed
on a retry of the clone command, so we should add this
new exception to our list of retryable exceptions in
the SolidFire driver.

Change-Id: I4e1ddf02087499b4efff6eabf2310a245bef93c9
Closes-Bug: #1451505
",git fetch https://review.opendev.org/openstack/cinder refs/changes/49/179849/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/solidfire.py'],1,7228bea4961486ec5b4e0f1df2a3d7a664ff3dc0,bug/1451505," 'xMaxClonesPerNodeExceeded', 'xNotReadyForIO']", 'xMaxClonesPerNodeExceeded'],2,1
openstack%2Fkolla~master~Ibf770b0b7917b9944716e6f80845121d425d9e46,openstack/kolla,master,Ibf770b0b7917b9944716e6f80845121d425d9e46,Dummy commit - adds comment lines,ABANDONED,2015-05-14 20:09:05.000000000,2015-05-20 20:44:15.000000000,,"[{'_account_id': 3}, {'_account_id': 3098}]","[{'number': 1, 'created': '2015-05-14 20:09:05.000000000', 'files': ['tests/test_keystone.py', 'tests/test_images.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/0d6c5f27aef92c294e51add2eee5fa56d9b72663', 'message': 'Dummy commit - adds comment lines\n\n(Trying to test functional gate)\n\nChange-Id: Ibf770b0b7917b9944716e6f80845121d425d9e46\n'}]",0,183195,0d6c5f27aef92c294e51add2eee5fa56d9b72663,7,2,1,3098,,,0,"Dummy commit - adds comment lines

(Trying to test functional gate)

Change-Id: Ibf770b0b7917b9944716e6f80845121d425d9e46
",git fetch https://review.opendev.org/openstack/kolla refs/changes/95/183195/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_images.py', 'tests/test_keystone.py']",2,0d6c5f27aef92c294e51add2eee5fa56d9b72663,,#,,2,0
openstack%2Fopenstack-nose~master~I0c3551efab09724dee31855d4a3c88164f9888c9,openstack/openstack-nose,master,I0c3551efab09724dee31855d4a3c88164f9888c9,Fixes unicode formatting bug,MERGED,2015-05-20 19:27:36.000000000,2015-05-20 20:42:41.000000000,2015-05-20 20:42:41.000000000,"[{'_account_id': 3}, {'_account_id': 385}]","[{'number': 1, 'created': '2015-05-20 19:27:36.000000000', 'files': ['openstack/nose_plugin.py'], 'web_link': 'https://opendev.org/openstack/openstack-nose/commit/de9dcf85a0b53628d709c6314bccfefed780703f', 'message': 'Fixes unicode formatting bug\n\nChange-Id: I0c3551efab09724dee31855d4a3c88164f9888c9\n'}]",0,184594,de9dcf85a0b53628d709c6314bccfefed780703f,6,2,1,11193,,,0,"Fixes unicode formatting bug

Change-Id: I0c3551efab09724dee31855d4a3c88164f9888c9
",git fetch https://review.opendev.org/openstack/openstack-nose refs/changes/94/184594/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/nose_plugin.py'],1,de9dcf85a0b53628d709c6314bccfefed780703f,unicode_formatting_fix, self.stream.write(' {0}'.format(name).ljust(65)), self.stream.write((' ' * 4 + str(name)).ljust(65)),1,1
openstack%2Fpuppet-neutron~stable%2Fjuno~Ic6905fe4240934f526e4b0d21bee695c8d93f28c,openstack/puppet-neutron,stable/juno,Ic6905fe4240934f526e4b0d21bee695c8d93f28c,Fix neutron file_line dependency,MERGED,2015-05-13 13:09:42.000000000,2015-05-20 20:32:44.000000000,2015-05-20 20:32:43.000000000,"[{'_account_id': 3}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 10540}, {'_account_id': 15675}]","[{'number': 1, 'created': '2015-05-13 13:09:42.000000000', 'files': ['manifests/plugins/ml2.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/3ee6b8251f75feeaf86cce25d41b2f7f61d160cd', 'message': 'Fix neutron file_line dependency\n\nWithout this patch, on Ubuntu the neutron module will sometimes try to\napply the NEUTRON_PLUGIN_CONFIG file line change to the file\n/etc/default/neutron-server before it exists. On Ubuntu, this file is\nmanaged by the neutron-server package. Since we otherwise do not need\nto manage that file on its own, we add a dependency on the package\nresource to make sure the file will be in place before trying to modify\nit with file_line.\n\nChange-Id: Ic6905fe4240934f526e4b0d21bee695c8d93f28c\n(cherry picked from commit a731408167847854ed39decf1b00ae5f698bcda6)\n'}]",0,182661,3ee6b8251f75feeaf86cce25d41b2f7f61d160cd,8,5,1,11583,,,0,"Fix neutron file_line dependency

Without this patch, on Ubuntu the neutron module will sometimes try to
apply the NEUTRON_PLUGIN_CONFIG file line change to the file
/etc/default/neutron-server before it exists. On Ubuntu, this file is
managed by the neutron-server package. Since we otherwise do not need
to manage that file on its own, we add a dependency on the package
resource to make sure the file will be in place before trying to modify
it with file_line.

Change-Id: Ic6905fe4240934f526e4b0d21bee695c8d93f28c
(cherry picked from commit a731408167847854ed39decf1b00ae5f698bcda6)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/61/182661/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/plugins/ml2.pp'],1,3ee6b8251f75feeaf86cce25d41b2f7f61d160cd,, Package<| title == 'neutron-server' |> -> File_line['/etc/default/neutron-server:NEUTRON_PLUGIN_CONFIG'], File_line['/etc/default/neutron-server:NEUTRON_PLUGIN_CONFIG'],2,1
openstack%2Fbarbican~master~I74324b3b8a312461eb1c2daae12f4caf2b88fcc5,openstack/barbican,master,I74324b3b8a312461eb1c2daae12f4caf2b88fcc5,Updating setup docs to use Python 2.7.9,MERGED,2015-05-20 19:25:03.000000000,2015-05-20 20:15:29.000000000,2015-05-20 20:15:27.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 9234}]","[{'number': 1, 'created': '2015-05-20 19:25:03.000000000', 'files': ['doc/source/setup/dev.rst'], 'web_link': 'https://opendev.org/openstack/barbican/commit/a7e881b4f3860ef5c2134270abec64a9c9a35bce', 'message': 'Updating setup docs to use Python 2.7.9\n\nChange-Id: I74324b3b8a312461eb1c2daae12f4caf2b88fcc5\n'}]",0,184593,a7e881b4f3860ef5c2134270abec64a9c9a35bce,8,4,1,11661,,,0,"Updating setup docs to use Python 2.7.9

Change-Id: I74324b3b8a312461eb1c2daae12f4caf2b88fcc5
",git fetch https://review.opendev.org/openstack/barbican refs/changes/93/184593/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/setup/dev.rst'],1,a7e881b4f3860ef5c2134270abec64a9c9a35bce,,"For the Barbican development, we'll just be installing Python 2.7.9. pyenv install 2.7.9 pyenv global 2.7.9 2.7.9 active when you created the virtualenv, then the default Python version will become 2.7.9 when you reactivate the virtualenv.","For the Barbican development, we'll just be installing Python 2.6.9 and 2.7.8. pyenv install 2.6.9 pyenv install 2.7.8 pyenv global 2.7.8 2.6.9 2.7.8 active when you created the virtualenv, then the default Python version will become 2.7.8 when you reactivate the virtualenv.",5,6
openstack%2Ffreezer~master~I688c6cd7d5678b886bece6ffb8fa569842e25d5f,openstack/freezer,master,I688c6cd7d5678b886bece6ffb8fa569842e25d5f,"Changed client data description to include ""hostname""""",MERGED,2015-05-05 13:24:24.000000000,2015-05-20 20:13:57.000000000,2015-05-20 20:13:56.000000000,"[{'_account_id': 3}, {'_account_id': 11151}]","[{'number': 1, 'created': '2015-05-05 13:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/aa2897af965856bce2ac15b18c78415c9ec96bec', 'message': 'Changed client data description to include ""hostname""""\n\nChange-Id: I688c6cd7d5678b886bece6ffb8fa569842e25d5f\n'}, {'number': 2, 'created': '2015-05-20 20:09:33.000000000', 'files': ['freezer_api/README.rst'], 'web_link': 'https://opendev.org/openstack/freezer/commit/8184cf27ee1392efef11cb9697339a7797ca9f12', 'message': 'Changed client data description to include ""hostname""""\n\nChange-Id: I688c6cd7d5678b886bece6ffb8fa569842e25d5f\n'}]",0,180146,8184cf27ee1392efef11cb9697339a7797ca9f12,8,2,2,14028,,,0,"Changed client data description to include ""hostname""""

Change-Id: I688c6cd7d5678b886bece6ffb8fa569842e25d5f
",git fetch https://review.opendev.org/openstack/freezer refs/changes/46/180146/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer_api/README.rst'],1,aa2897af965856bce2ac15b18c78415c9ec96bec,," ""hostname"": string",,1,0
openstack%2Ffreezer~master~If43ac22b580ae387d85a4dc024a259ca2634a856,openstack/freezer,master,If43ac22b580ae387d85a4dc024a259ca2634a856,"Added parameters to the ""list-backups"" python api",MERGED,2015-05-05 08:42:33.000000000,2015-05-20 20:09:24.000000000,2015-05-20 20:09:23.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 14159}]","[{'number': 1, 'created': '2015-05-05 08:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/ca19def9a4f366ae5904d4708d974e5697a45518', 'message': 'Added parameters to the ""list-backups"" python api\n\nAdded the following parameters: limit, offset,\nsearch (can contain: time_before, time_after)\n\nChange-Id: If43ac22b580ae387d85a4dc024a259ca2634a856\n'}, {'number': 2, 'created': '2015-05-20 20:06:01.000000000', 'files': ['freezer/apiclient/backups.py', 'tests/test_apiclient_backup.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/40df98536d3fd1bbbd538af5f9d5b0f9a1f3acf9', 'message': 'Added parameters to the ""list-backups"" python api\n\nAdded the following parameters: limit, offset,\nsearch (can contain: time_before, time_after)\n\nChange-Id: If43ac22b580ae387d85a4dc024a259ca2634a856\n'}]",0,180061,40df98536d3fd1bbbd538af5f9d5b0f9a1f3acf9,9,3,2,14028,,,0,"Added parameters to the ""list-backups"" python api

Added the following parameters: limit, offset,
search (can contain: time_before, time_after)

Change-Id: If43ac22b580ae387d85a4dc024a259ca2634a856
",git fetch https://review.opendev.org/openstack/freezer refs/changes/61/180061/2 && git format-patch -1 --stdout FETCH_HEAD,"['freezer/apiclient/backups.py', 'tests/test_apiclient_backup.py']",2,ca19def9a4f366ae5904d4708d974e5697a45518,backup_filter," @patch('freezer.apiclient.backups.requests') def test_list_parameters(self, mock_requests): mock_response = Mock() mock_response.status_code = 200 backup_list = [{'backup_id_0': 'qwerqwer'}, {'backup_id_1': 'asdfasdf'}] mock_response.json.return_value = {'backups': backup_list} mock_requests.get.return_value = mock_response retval = self.b.list(limit=5, offset=5, search={""time_before"": 1428529956}) mock_requests.get.assert_called_with( 'http://testendpoint:9999/v1/backups/', params={'limit': 5, 'offset': 5}, data='{""time_before"": 1428529956}', headers={'X-Auth-Token': 'testtoken'}) self.assertEqual(retval, backup_list) ",,35,2
openstack%2Fpython-keystoneclient~master~Ib76743b768c5f0eef756184f1da49613423298f0,openstack/python-keystoneclient,master,Ib76743b768c5f0eef756184f1da49613423298f0,Prompt for password on CLI if not provided,MERGED,2015-04-14 23:37:52.000000000,2015-05-20 20:08:06.000000000,2015-05-20 20:08:05.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 11333}, {'_account_id': 13055}, {'_account_id': 13478}, {'_account_id': 14920}]","[{'number': 1, 'created': '2015-04-14 23:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/f2f071677ed59ba2ce620c10e812e6b1e9c515fd', 'message': ""Prompt for password on CLI if not provided\n\nload_from_argparse_arguments is very specifically for use with argparse.\nWe can therefore safely prompt for a password from the user if none is\nprovided and it won't affect config options or other loading mechanisms.\n\nChange-Id: Ib76743b768c5f0eef756184f1da49613423298f0\n""}, {'number': 2, 'created': '2015-04-15 01:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/5d27698d0a3e7e0af34ac040e28d2cf6b889bfb4', 'message': ""Prompt for password on CLI if not provided\n\nload_from_argparse_arguments is very specifically for use with argparse.\nWe can therefore safely prompt for a password from the user if none is\nprovided and it won't affect config options or other loading mechanisms.\n\nChange-Id: Ib76743b768c5f0eef756184f1da49613423298f0\n""}, {'number': 3, 'created': '2015-05-02 06:21:53.000000000', 'files': ['keystoneclient/shell.py', 'keystoneclient/auth/identity/generic/password.py', 'keystoneclient/auth/identity/v3/password.py', 'keystoneclient/tests/unit/auth/test_identity_v2.py', 'keystoneclient/utils.py', 'keystoneclient/tests/unit/auth/test_identity_v3.py', 'keystoneclient/tests/unit/auth/test_password.py', 'keystoneclient/auth/identity/v2.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/17d51f771ea9b6210c00c946d16d94fedc3f9cc1', 'message': ""Prompt for password on CLI if not provided\n\nload_from_argparse_arguments is very specifically for use with argparse.\nWe can therefore safely prompt for a password from the user if none is\nprovided and it won't affect config options or other loading mechanisms.\n\nChange-Id: Ib76743b768c5f0eef756184f1da49613423298f0\n""}]",1,173605,17d51f771ea9b6210c00c946d16d94fedc3f9cc1,18,9,3,7191,,,0,"Prompt for password on CLI if not provided

load_from_argparse_arguments is very specifically for use with argparse.
We can therefore safely prompt for a password from the user if none is
provided and it won't affect config options or other loading mechanisms.

Change-Id: Ib76743b768c5f0eef756184f1da49613423298f0
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/05/173605/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/shell.py', 'keystoneclient/auth/identity/generic/password.py', 'keystoneclient/auth/identity/v3/password.py', 'keystoneclient/tests/unit/auth/test_identity_v2.py', 'keystoneclient/tests/unit/auth/test_identity_v3.py', 'keystoneclient/utils.py', 'keystoneclient/tests/unit/auth/test_password.py', 'keystoneclient/auth/identity/v2.py']",8,f2f071677ed59ba2ce620c10e812e6b1e9c515fd,cliplugin," def load_from_argparse_arguments(cls, namespace, **kwargs): if not (kwargs.get('password') or namespace.os_password): kwargs['password'] = utils.prompt_user_password() return super(Password, cls).load_from_argparse_arguments(namespace, **kwargs) @classmethod",,136,7
openstack%2Fpython-keystoneclient~master~I07fb46f156fdf8267fd3d4dc7c587cd604838d73,openstack/python-keystoneclient,master,I07fb46f156fdf8267fd3d4dc7c587cd604838d73,Ensure that failing responses are logged,MERGED,2015-05-05 01:02:49.000000000,2015-05-20 20:06:22.000000000,2015-05-20 20:06:20.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 8978}, {'_account_id': 9098}, {'_account_id': 9142}, {'_account_id': 13055}, {'_account_id': 13478}]","[{'number': 1, 'created': '2015-05-05 01:02:49.000000000', 'files': ['keystoneclient/tests/unit/test_session.py', 'keystoneclient/session.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/c7ec27a448d20201471a8f953e3b58b9ded589aa', 'message': ""Ensure that failing responses are logged\n\nThe boolean value of a failed response is False and so the way we\npopulate the log output does not work when the request failed.\n\nWhen logging check that a response is not None rather than simply\nchecking it's boolean value.\n\nChange-Id: I07fb46f156fdf8267fd3d4dc7c587cd604838d73\nCloses-Bug: #1451625\n""}]",1,179984,c7ec27a448d20201471a8f953e3b58b9ded589aa,11,7,1,7191,,,0,"Ensure that failing responses are logged

The boolean value of a failed response is False and so the way we
populate the log output does not work when the request failed.

When logging check that a response is not None rather than simply
checking it's boolean value.

Change-Id: I07fb46f156fdf8267fd3d4dc7c587cd604838d73
Closes-Bug: #1451625
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/84/179984/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/tests/unit/test_session.py', 'keystoneclient/session.py']",2,c7ec27a448d20201471a8f953e3b58b9ded589aa,bug/1451625, if response is not None:, if response:,13,1
openstack%2Ffuel-qa~master~Ie1bddc965719ca59a143f8f43c53546a4553b1b9,openstack/fuel-qa,master,Ie1bddc965719ca59a143f8f43c53546a4553b1b9,Add two methods to wait for cluster HA and OS services ready,MERGED,2015-04-30 07:50:46.000000000,2015-05-20 20:02:55.000000000,2015-05-20 20:02:54.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15984}, {'_account_id': 16106}]","[{'number': 1, 'created': '2015-04-30 07:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/74b01a9eae69787124f759b26114024dbf50ab40', 'message': ""Add assert_ha_services_ready() to wait for cluster HA services\n\nOSTF 'HA' test group should be used to validate if a cluster\nin the operational state.\nThere are rabbitmq and mysql checks, and will be added haproxy\nand pacemaker checks.\n\nWithout these services the cluster can fail requests from tests.\n\nChange-Id: Ie1bddc965719ca59a143f8f43c53546a4553b1b9\nCloses-Bug: #1383247\n""}, {'number': 2, 'created': '2015-05-05 07:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/b207c5e5238ad74d7b4025ceab95411acae5d92c', 'message': ""Add assert_ha_services_ready() to wait for cluster HA services\n\nOSTF 'HA' test group should be used to validate if a cluster\nin the operational state.\nThere are rabbitmq and mysql checks, and will be added haproxy\nand pacemaker checks.\n\nWithout these services the cluster can fail requests from tests.\n\nChange-Id: Ie1bddc965719ca59a143f8f43c53546a4553b1b9\nCloses-Bug: #1383247\n""}, {'number': 3, 'created': '2015-05-05 08:48:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/426c33ce4c9da5bb4d1f934ac94ddd75058d45e8', 'message': ""Add assert_ha_services_ready() to wait for cluster HA services\n\nOSTF 'HA' test group should be used to validate if a cluster\nin the operational state.\nThere are rabbitmq and mysql checks, and will be added haproxy\nand pacemaker checks.\n\nWithout these services the cluster can fail requests from tests.\n\nChange-Id: Ie1bddc965719ca59a143f8f43c53546a4553b1b9\nCloses-Bug: #1383247\n""}, {'number': 4, 'created': '2015-05-14 14:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/50294f0a4306954d2961fcc83e57a8ba484a3b46', 'message': ""Add assert_ha_services_ready() to wait for cluster HA services\n\nOSTF 'HA' test group should be used to validate if a cluster\nin the operational state.\nThere are rabbitmq and mysql checks, and will be added haproxy\nand pacemaker checks.\n\nWithout these services the cluster can fail requests from tests.\n\nChange-Id: Ie1bddc965719ca59a143f8f43c53546a4553b1b9\nCloses-Bug: #1383247\n""}, {'number': 5, 'created': '2015-05-17 13:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/4054d80b37f892151d06ba0e72a068f58fe3c4c7', 'message': ""Add two methods to wait for cluster HA and OS services ready\n\nassert_ha_services_ready():\n OSTF 'HA' test group should be used to validate if a cluster\n in the operational state.\n There are rabbitmq and mysql checks, and will be added haproxy\n and pacemaker checks.\n\n Without these services the cluster can fail requests from tests.\n\nassert_os_services_ready():\n OSTF 'Sanity' test group to wait until for OpenStack are ready.\n\nChange-Id: Ie1bddc965719ca59a143f8f43c53546a4553b1b9\nCloses-Bug: #1383247\nCloses-Bug: #1455910\n""}, {'number': 6, 'created': '2015-05-17 13:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/e599f3d0ce184ea13f10f4a209e557bdb17e75c7', 'message': ""Add two methods to wait for cluster HA and OS services ready\n\nassert_ha_services_ready():\n OSTF 'HA' test group should be used to validate if a cluster\n in the operational state.\n There are rabbitmq and mysql checks, and will be added haproxy\n and pacemaker checks.\n\n Without these services the cluster can fail requests from tests.\n\nassert_os_services_ready():\n OSTF 'Sanity' test group to wait until OpenStack services are\n ready.\n\nChange-Id: Ie1bddc965719ca59a143f8f43c53546a4553b1b9\nCloses-Bug: #1383247\nCloses-Bug: #1455910\n""}, {'number': 7, 'created': '2015-05-18 06:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/a41be7c940e4978aa533e317bca1486306c50de6', 'message': ""Add two methods to wait for cluster HA and OS services ready\n\nassert_ha_services_ready():\n OSTF 'HA' test group should be used to validate if a cluster\n in the operational state.\n There are rabbitmq and mysql checks, and will be added haproxy\n and pacemaker checks.\n\n Without these services the cluster can fail requests from tests.\n\nassert_os_services_ready():\n OSTF 'Sanity' test group to wait until OpenStack services are\n ready.\n\nChange-Id: Ie1bddc965719ca59a143f8f43c53546a4553b1b9\nCloses-Bug: #1383247\nCloses-Bug: #1455910\n""}, {'number': 8, 'created': '2015-05-18 10:28:01.000000000', 'files': ['fuelweb_test/__init__.py', 'fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/tests_strength/test_restart.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/aa50833aaebc598de37fcc5d617d77f894b569e7', 'message': ""Add two methods to wait for cluster HA and OS services ready\n\nassert_ha_services_ready():\n OSTF 'HA' test group should be used to validate if a cluster\n in the operational state.\n There are rabbitmq and mysql checks, and will be added haproxy\n and pacemaker checks.\n\n Without these services the cluster can fail requests from tests.\n\nassert_os_services_ready():\n OSTF 'Sanity' test group to wait until OpenStack services are\n ready.\n\nChange-Id: Ie1bddc965719ca59a143f8f43c53546a4553b1b9\nCloses-Bug: #1383247\nCloses-Bug: #1455910\n""}]",2,178966,aa50833aaebc598de37fcc5d617d77f894b569e7,44,13,8,11969,,,0,"Add two methods to wait for cluster HA and OS services ready

assert_ha_services_ready():
 OSTF 'HA' test group should be used to validate if a cluster
 in the operational state.
 There are rabbitmq and mysql checks, and will be added haproxy
 and pacemaker checks.

 Without these services the cluster can fail requests from tests.

assert_os_services_ready():
 OSTF 'Sanity' test group to wait until OpenStack services are
 ready.

Change-Id: Ie1bddc965719ca59a143f8f43c53546a4553b1b9
Closes-Bug: #1383247
Closes-Bug: #1455910
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/66/178966/8 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/tests_strength/test_restart.py']",2,74b01a9eae69787124f759b26114024dbf50ab40,bug/1383247, self.fuel_web.assert_ha_services_ready(cluster_id) self.fuel_web.assert_ha_services_ready(cluster_id) self.fuel_web.assert_ha_services_ready(cluster_id),,20,0
openstack%2Ffreezer~master~Ie5a65870ffc400b2cfabf8c25465972e52471e55,openstack/freezer,master,Ie5a65870ffc400b2cfabf8c25465972e52471e55,Bandwith limitation functional test,MERGED,2015-04-13 19:26:33.000000000,2015-05-20 20:00:00.000000000,2015-05-20 19:59:59.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 12211}, {'_account_id': 14123}, {'_account_id': 14159}, {'_account_id': 15358}]","[{'number': 1, 'created': '2015-04-13 19:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/6277ed145de2967dd370e9aee2d356bd3c30df04', 'message': 'Bandwith limitation functional test\n\nTest bandwith throttle limits for backup (upload) and\nrestore (download). Test is performed with 1MB text file\nand 512KB/s limit so upload/download time should be greater\nthan 2s.\n\nChange-Id: Ie5a65870ffc400b2cfabf8c25465972e52471e55\nImplements: blueprint functional-testing\n'}, {'number': 2, 'created': '2015-04-14 21:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/ab4ef0594c6d7ddc5e405f4856ce9aa0208256f2', 'message': 'Bandwith limitation functional test\n\nTest bandwith throttle limits for backup (upload) and\nrestore (download). Test is performed with 1MB text file\nand 512KB/s limit.\n\nChange-Id: Ie5a65870ffc400b2cfabf8c25465972e52471e55\nImplements: blueprint functional-testing\n'}, {'number': 3, 'created': '2015-04-15 14:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/a0a6d0cd011cb1e99b83482cde71d1e769fc39f9', 'message': 'Bandwith limitation functional test\n\nTest bandwith throttle limits for backup (upload) and\nrestore (download). Test is performed with 1MB text file\nand 512KB/s limit.\n\nChange-Id: Ie5a65870ffc400b2cfabf8c25465972e52471e55\nImplements: blueprint functional-testing\n'}, {'number': 4, 'created': '2015-05-20 19:47:27.000000000', 'files': ['tests/scenario/backup_scenario.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/dc8c1a565a0b1a17793a9a72cf976910bdebbddb', 'message': 'Bandwith limitation functional test\n\nTest bandwith throttle limits for backup (upload) and\nrestore (download). Test is performed with 1MB text file\nand 512KB/s limit.\n\nChange-Id: Ie5a65870ffc400b2cfabf8c25465972e52471e55\nImplements: blueprint functional-testing\n'}]",0,173049,dc8c1a565a0b1a17793a9a72cf976910bdebbddb,14,6,4,14786,,,0,"Bandwith limitation functional test

Test bandwith throttle limits for backup (upload) and
restore (download). Test is performed with 1MB text file
and 512KB/s limit.

Change-Id: Ie5a65870ffc400b2cfabf8c25465972e52471e55
Implements: blueprint functional-testing
",git fetch https://review.opendev.org/openstack/freezer refs/changes/49/173049/4 && git format-patch -1 --stdout FETCH_HEAD,['tests/scenario/backup_scenario.py'],1,6277ed145de2967dd370e9aee2d356bd3c30df04,bp/functional-testing,"import string import time def snap_tmp_tree_sha1(self, file_list): """""" Creates dictionary with absolute paths as keys and SHA1 Git style hashes as values. Takes list of absolute file paths. """""" def create_big_file(self, file_path, size): """""" Create test text file with random data and configurable size """""" buf = list(string.printable) with open(file_path, 'w') as handle: for i in range(size//len(buf)): random.shuffle(buf) handle.write('%s' % ''.join(buf)) handle.close() def test_bandwith_limit(self): """""" Freezer upload/download speed limit test. We set a fixed 512KB/s speed and try to backup (upload) 1MB file na restore (download) the backup. Each of those action on avarage should not take more than 2s or less than 3s 2s < EXEC_TIME < 3s. Without throttle it is normaly about 0.4s. freezerc --action backup --path-to-backup /tmp/freezer_test_XXXX --backup-name UUID --container UUID --upload-limit 524288 freezerc --action restore --path-to-backup /tmp/freezer_test_XXXX --backup-name UUID --container UUID --download-limit 524288 """""" # print '\nWorking in:', self.tmp_path # Set 512KB/s connection limit speed_limit_bytes = 512 * 1024 time_low = 2 abs_file_name = self.tmp_path + os.path.sep + 'limitfoo' # Create 1MB test text file with random data self.create_big_file(abs_file_name, 2 * speed_limit_bytes) # Freezer CLI for backup argument dictionary test_args = { 'action' : 'backup', 'src_file' : copy(self.tmp_path), 'backup_name' : str(uuid.uuid4()), 'container' : str(uuid.uuid4()), 'upload_limit' : speed_limit_bytes } (backup_args, _) = arguments.backup_arguments(test_args) self.assertEqual(backup_args.mode, 'fs') self.assertEqual(backup_args.max_backup_level, 0) start_time = time.time() # Call Freezer CLI backup main.freezer_main(backup_args) end_time = time.time() # Calculate backup time in sec upload_time = end_time - start_time # print ""\nUpload time: %g seconds"" % upload_time # Test that time is longer than the theoretical 2 sec self.assertTrue(time_low < upload_time) # Delete test file os.unlink(abs_file_name) # Build dictionary for Freezer CLI restore test_args = { 'action' : 'restore', 'restore_abs_path' : copy(self.tmp_path), 'backup_name' : copy(backup_args.backup_name), 'container' : copy(backup_args.container), 'download_limit' : speed_limit_bytes } (restore_args, _) = arguments.backup_arguments(test_args) self.assertEqual(backup_args.mode, 'fs') start_time = time.time() # Call the actual Freezer CLI restore main.freezer_main(restore_args) end_time = time.time() self.assertTrue(os.path.isfile(abs_file_name)) # Calculate restore time in sec download_time = end_time - start_time # print ""Download time: %g seconds"" % download_time # sys.stdout.flush() # Test that time is longer than the theoretical 2 sec self.assertTrue(time_low < download_time) "," def snap_tmp_tree_sha1(self, file_list):",98,0
openstack%2Ffuel-ostf~master~I1c89544d2f212638d53eba3e33ed4bb6990a32a8,openstack/fuel-ostf,master,I1c89544d2f212638d53eba3e33ed4bb6990a32a8,Fixed incorrect work of Glance OSTF tests,MERGED,2015-05-18 23:28:53.000000000,2015-05-20 19:56:37.000000000,2015-05-20 19:54:21.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8592}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11391}, {'_account_id': 12199}, {'_account_id': 12200}, {'_account_id': 13717}, {'_account_id': 13962}, {'_account_id': 14510}, {'_account_id': 14614}, {'_account_id': 14691}]","[{'number': 1, 'created': '2015-05-18 23:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/b2749db8d6da7f2d096fca8da573fe58895b5f18', 'message': ""Fixed incorrect work of Glance OSTF tests\n\n- Using image id instead of image to append and object to list to\n  enumerate images\n- Fixed incorrect logic of 'update_image' step in CRUD Glance v1 test\n- Fixed _cleanup_images function\n\nChange-Id: I1c89544d2f212638d53eba3e33ed4bb6990a32a8\nPartial-Bug: #1455468\n""}, {'number': 2, 'created': '2015-05-19 15:05:24.000000000', 'files': ['fuel_health/nmanager.py', 'fuel_health/glancemanager.py', 'fuel_health/tests/smoke/test_create_images.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/6c72a73394c069200950468aff331982ec161134', 'message': ""Fixed incorrect work of Glance OSTF tests\n\n- Using image id instead of image to append an object to list to\n  enumerate images\n- Fixed incorrect logic of 'update_image' step in CRUD Glance v1 test\n- Fixed _cleanup_images function\n\nChange-Id: I1c89544d2f212638d53eba3e33ed4bb6990a32a8\nPartial-Bug: #1455468\n""}]",19,184152,6c72a73394c069200950468aff331982ec161134,30,16,2,13962,,,0,"Fixed incorrect work of Glance OSTF tests

- Using image id instead of image to append an object to list to
  enumerate images
- Fixed incorrect logic of 'update_image' step in CRUD Glance v1 test
- Fixed _cleanup_images function

Change-Id: I1c89544d2f212638d53eba3e33ed4bb6990a32a8
Partial-Bug: #1455468
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/52/184152/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/nmanager.py', 'fuel_health/glancemanager.py', 'fuel_health/tests/smoke/test_create_images.py']",3,b2749db8d6da7f2d096fca8da573fe58895b5f18,bug/1455468," self.image = self.verify(100, self.update_image, 4, fail_msg, 'Updating image', self.glance_client_v1, self.image, group_props, prop, value_prop) self.verify(200, self.delete_image, 6, fail_msg, 'Deleting image',"," self.verify(100, self.update_image, 4, fail_msg, 'Updating image', self.glance_client_v1, self.image, group_props, prop, value_prop) self.verify(200, self.delete_image, 5, fail_msg, 'Deleting image',",15,10
openstack%2Ffreezer~master~Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6,openstack/freezer,master,Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6,Incremental LVM functional test,MERGED,2015-03-30 09:55:40.000000000,2015-05-20 19:54:42.000000000,2015-05-20 19:54:41.000000000,"[{'_account_id': 3}, {'_account_id': 358}, {'_account_id': 11151}, {'_account_id': 12211}, {'_account_id': 14159}, {'_account_id': 14340}, {'_account_id': 14786}, {'_account_id': 15358}]","[{'number': 1, 'created': '2015-03-30 09:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/bad51a3f4c34ddeeb5f89db188157566fe140a89', 'message': 'WIP: Incremental LVM functional test\n\nIn this test we will perform 30 level LVM backup.\nAfter which backup Swift objects are examined in the container.\nThen we will attempt to restore and test the SHA1 hash of\neach file included in the backup directory before the backup and\nafter the restore.\n\nChange-Id: Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6\nBP: functional-testing\n'}, {'number': 2, 'created': '2015-03-30 13:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/8e6f852e43d5f545254d3979abf6d88315366acf', 'message': 'WIP: 30.03.2015 Incremental LVM functional test\n\nIn this test we will perform 30 level LVM backup.\nAfter which backup Swift objects are examined in the container.\nThen we will attempt to restore and test the SHA1 hash of\neach file included in the backup directory before the backup and\nafter the restore.\n\nChange-Id: Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6\nBP: functional-testing\n'}, {'number': 3, 'created': '2015-03-30 14:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/f4abaec0f90b2ab0c16c221a440771d2a233fb94', 'message': 'WIP: Incremental LVM functional test\n\nIn this test we will perform 30 level LVM backup.\nAfter which backup Swift objects are examined in the container.\nThen we will attempt to restore and test the SHA1 hash of\neach file included in the backup directory before the backup and\nafter the restore.\n\nBLUEPRINT: functional-testing\nChange-Id: Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6\n'}, {'number': 4, 'created': '2015-04-01 10:51:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/55e98c0eac879741d31ff18dc75b6954eb6b7200', 'message': 'Incremental LVM functional test\n\nIn this test we will perform 5 level LVM backup.\nAfter which backup Swift objects are examined in the container.\nThen we will attempt to restore and test the SHA1 hash of\neach file included in the backup directory before the backup and\nafter the restore.\n\nBLUEPRINT: functional-testing\nChange-Id: Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6\n'}, {'number': 5, 'created': '2015-04-01 12:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/f4acaa5c4131d1de75fb28bbd03fd0d90726bf91', 'message': 'Incremental LVM functional test\n\nIn this test we will perform 5 level LVM backup.\nAfter which backup Swift objects are examined in the container.\nThen we will attempt to restore and test the SHA1 hash of\neach file included in the backup directory before the backup and\nafter the restore.\n\nImplements blueprint functional-testing\nChange-Id: Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6\n'}, {'number': 6, 'created': '2015-04-13 11:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/d7eb155b44d5337ba1ef9df8a9d2e926f3e43b76', 'message': 'Incremental LVM functional test\n\nIn this test we will perform 5 level LVM backup.\nAfter which backup Swift objects are examined in the container.\nThen we will attempt to restore and test the SHA1 hash of\neach file included in the backup directory before the backup and\nafter the restore.\n\nImplements blueprint functional-testing\nChange-Id: Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6\n'}, {'number': 7, 'created': '2015-04-14 21:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/821231b4a413d3b86eeb4985b3ae3330a432e9a9', 'message': 'Incremental LVM functional test\n\nIn this test we will perform 5 level LVM backup.\nAfter which backup Swift objects are examined in the container.\nThen we will attempt to restore and test the SHA1 hash of\neach file included in the backup directory before the backup and\nafter the restore.\n\nImplements blueprint functional-testing\nChange-Id: Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6\n'}, {'number': 8, 'created': '2015-04-15 14:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/3ef8649485144d979885df531bc1881b69a6d9a7', 'message': 'Incremental LVM functional test\n\nIn this test we will perform 5 level LVM backup.\nAfter which backup Swift objects are examined in the container.\nThen we will attempt to restore and test the SHA1 hash of\neach file included in the backup directory before the backup and\nafter the restore.\n\nImplements blueprint functional-testing\nChange-Id: Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6\n'}, {'number': 9, 'created': '2015-05-20 19:45:37.000000000', 'files': ['tests/scenario/backup_scenario.py', 'tests/scenario/vagrant-scripts/create-lvm.sh'], 'web_link': 'https://opendev.org/openstack/freezer/commit/13605903ed159560bab6052804481b4b558f121f', 'message': 'Incremental LVM functional test\n\nIn this test we will perform 5 level LVM backup.\nAfter which backup Swift objects are examined in the container.\nThen we will attempt to restore and test the SHA1 hash of\neach file included in the backup directory before the backup and\nafter the restore.\n\nImplements blueprint functional-testing\nChange-Id: Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6\n'}]",5,168837,13605903ed159560bab6052804481b4b558f121f,31,8,9,14786,,,0,"Incremental LVM functional test

In this test we will perform 5 level LVM backup.
After which backup Swift objects are examined in the container.
Then we will attempt to restore and test the SHA1 hash of
each file included in the backup directory before the backup and
after the restore.

Implements blueprint functional-testing
Change-Id: Ib50a6d85d815ef6125f512f60e446d7ec3a8a6b6
",git fetch https://review.opendev.org/openstack/freezer refs/changes/37/168837/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/scenario/backup_scenario.py'],1,bad51a3f4c34ddeeb5f89db188157566fe140a89,bp/functional-testing,"import os import sys import re import time <tmp_files> ........... dir_foo <tmp_files> ........... dir_bar <tmp_files> ........... dir_foobar <tmp_files> ........... dir_barfoo <tmp_files> ........... dir_foofoo <tmp_files> ........... dir_barbar <tmp_files> ........... #tmp_files = ['foo', 'bar', 'foobar', 'barfoo', 'foofoo', 'barbar', 'hello.lock'] #tmp_dirs = ['', 'dir_foo', 'dir_bar', 'dir_foobar', 'dir_barfoo', 'dir_foofoo', 'dir_barbar'] tmp_files = ['foo'] tmp_dirs = [''] """""" """""" # Delete some file counter = 0 while (counter < 0): if fn not in self.tmp_deleted: os.unlink(fn) self.tmp_deleted.append(fn) counter += 1 # Change the content of a couple files counter = 0 while (counter < 1): remaining = list() if fn not in self.tmp_deleted: f = open(fn, 'w') f.write('text changed {}\n'.format(uuid.uuid4())) f.close() self.tmp_modified.append(fn) counter += 1 def test_lvm_incremental_level30(self): """""" Incremental LVM snapshots filesystem backup freezerc --action backup --lvm-srcvol /dev/freezer-test1-volgroup/freezer-test1-vol --lvm-dirmount /tmp/freezer-test-lvm-snapshot --lvm-volgroup freezer-test1-volgroup --lvm-snapsize 1M --file-to-backup /mnt/freezer-test-lvm/lvm_test_XXXX/ --container UUID --exclude ""\*.lock"" --backup-name UUID --max-level 30 """""" # Set arguments lvm_path = '/mnt/freezer-test-lvm' self.tmp_path = tempfile.mkdtemp(prefix='lvm_test_', dir=lvm_path) self.create_tmp_tree(self.tmp_path) max_level = 5 test_args = { #'proxy' : '', 'action' : 'backup', 'lvm_srcvol' : '/dev/freezer-test1-volgroup/freezer-test1-vol', 'lvm_dirmount' : '/tmp/freezer-test-lvm-snapshot', 'lvm_volgroup' : 'freezer-test1-volgroup', 'lvm_snapsize' : '1M', #'exclude' : '*.lock', 'src_file' : copy(self.tmp_path), 'backup_name' : str(uuid.uuid4()), 'container' : str(uuid.uuid4()), 'max_backup_level' : max_level } (backup_args, _) = arguments.backup_arguments(test_args) # Make sure default value for MODE is filesystem self.assertEqual(backup_args.mode, 'fs') # Check that if not explicitly defined the MAX-BACKUP is set properly self.assertEqual(backup_args.max_backup_level, max_level) print '\n#### BACKUP_NAME:', backup_args.backup_name print '\n#### CONTAINER:', backup_args.container fdict_before = [] i = 0 while len(fdict_before) < max_level: fdict_before.append( self.snap_tmp_tree_sha1(self.tmp_files) ) main.freezer_main(backup_args) print '\n*** BEFORE BACKUP LEVEL', i, '***' print open(self.tmp_path + os.path.sep + 'foo', 'r').read() self.damage_tmp_tree(self.tmp_files) time.sleep(5) i += 1 backup_args = swift.get_container_content(backup_args) # Filter only the container names from all other data name_list = [item['name'] for item in backup_args.remote_obj_list] counter = 0 while counter < max_level: found_objects = [obj for obj in name_list if obj.endswith('_%s' % counter)] objects_str = ' '.join(found_objects) print '\n', objects_str self.assertEqual('%s(%s)' % (objects_str, len(found_objects)), objects_str + '(2)') found_objects = sorted(found_objects) self.assertEqual(found_objects[1], found_objects[0][-len(found_objects[1]):]) counter += 1 i = -1 for j in range(max_level): print '\n::::::::::::::::::::::', j, '::::::::::::::::::::::::' for i in range(max_level): restore_level = i #random.randint(0, max_level) restore_epoch = re.findall('(\d{10}?)_%s' % restore_level , ' '.join(name_list))[0] restore_epoch = int(restore_epoch) + 1 restore_date = time.strftime('%Y-%m-%dT%H:%M:%S', time.localtime(int(restore_epoch)) ) print '>>>>>>>>>', restore_level, restore_epoch, restore_date #print '\nCMD: ls -l %s' % self.tmp_path #print os.system('ls -l ' + self.tmp_path) os.unlink(self.tmp_path + os.path.sep + 'foo') #print '\nCMD: ls -l %s' % self.tmp_path #print os.system('ls -l ' + self.tmp_path) # Restore arguments test_args = { #'proxy' : '', 'action' : 'restore', 'restore_abs_path' : copy(self.tmp_path), 'backup_name' : copy(backup_args.backup_name), 'container' : copy(backup_args.container), 'restore_from_date' : restore_date } (restore_args, _) = arguments.backup_arguments(test_args) self.assertEqual(restore_args.mode, 'fs') # Call RESTORE on Freezer code base main.freezer_main(restore_args) fdict_after = self.snap_tmp_tree_sha1(self.tmp_files) if len(fdict_after) != len(fdict_before[j]): print '%%%%% File count do not match' continue # Check if cout of all original files match recovered files # plus the number of deleted .LOCK files which were not restored for key in fdict_before[j]: self.assertTrue(os.path.isfile(key)) if key + fdict_before[j][key] == key + fdict_after[key]: print '\nRESTORED:', key, fdict_after[key], 'OK' print '\nEXPECTED:', key, fdict_before[j][key], 'OK' else: print '\nRESTORED', key, fdict_after[key], 'FAIL' print '\nEXPECTED', key, fdict_before[j][key], 'FAIL' ","import os, sys |-dir_foo | |-dir_bar | | | | | |-hello.lock | | |-foo | | |-bar | | |-foobar | | | |-hello.lock | |-foo | |-bar | |-foobar | |-hello.lock |-foo |-bar |-foobar tmp_files = ['foo', 'bar', 'foobar', 'hello.lock'] tmp_dirs = ['', 'dir_foo', 'dir_bar'] # Delete 4 file for nfile in range(4): os.unlink(fn) tmp_files.remove(fn) self.tmp_deleted.append(fn) # Change the content of 3 files for nfile in range(3): f = open(fn, 'w') f.write('foofoo\n') f.close() self.tmp_modified.append(fn)",160,31
openstack%2Fsolum-specs~master~Iedd00827461f6fb6bb98c209673700053fade53e,openstack/solum-specs,master,Iedd00827461f6fb6bb98c209673700053fade53e,App resource,MERGED,2015-04-14 22:03:06.000000000,2015-05-20 19:54:08.000000000,2015-05-20 19:54:08.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 9095}]","[{'number': 1, 'created': '2015-04-14 22:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/040de230681addb1e909595860c2b4d10c5f66ff', 'message': '(WIP) App resource\n\nImplements: app-resource\n\nChange-Id: Iedd00827461f6fb6bb98c209673700053fade53e\n'}, {'number': 2, 'created': '2015-04-15 19:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/473c4957a31e1cd96673f05caaac62de6912e746', 'message': '(WIP) App resource\n\nImplements: app-resource\n\nChange-Id: Iedd00827461f6fb6bb98c209673700053fade53e\n'}, {'number': 3, 'created': '2015-04-15 21:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/c4a7d06e378896e33dfb9335d025e38352f3a5a7', 'message': '(WIP) App resource\n\nImplements: app-resource\n\nChange-Id: Iedd00827461f6fb6bb98c209673700053fade53e\n'}, {'number': 4, 'created': '2015-04-27 21:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/c926f5ab3cc3637d842f49d527931ea57f5d2d4e', 'message': '(WIP) App resource\n\nblueprint app-resource\n\nChange-Id: Iedd00827461f6fb6bb98c209673700053fade53e\n'}, {'number': 5, 'created': '2015-05-13 16:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/159a91bbcf42f557bfe03b87f3c5eaafcbd7aed5', 'message': ""App resource\n\nIntroduces a first-order resource, the app, to manage Solum applications\nand replace the assembly and plan resources.\nIncludes an 'actions' model to allow for richer configuration of workflows\nand better tracking of artifacts and application changes.\n\nblueprint app-resource\n\nChange-Id: Iedd00827461f6fb6bb98c209673700053fade53e\n""}, {'number': 6, 'created': '2015-05-13 17:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/11e012b37751dc80d64e2dcfca1b2957957a4638', 'message': ""App resource\n\nIntroduces a first-order resource, the app, to manage Solum applications\nand replace the assembly and plan resources.\nIncludes an 'actions' model to allow for richer configuration of workflows\nand better tracking of artifacts and application changes.\n\nblueprint app-resource\n\nChange-Id: Iedd00827461f6fb6bb98c209673700053fade53e\n""}, {'number': 7, 'created': '2015-05-19 16:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/7ffdf7ae0823923904ee70aba19adca6f4c7e442', 'message': ""App resource\n\nIntroduces a first-order resource, the app, to manage Solum applications\nand replace the assembly and plan resources.\nIncludes an 'actions' model to allow for richer configuration of workflows\nand better tracking of artifacts and application changes.\n\nblueprint app-resource\n\nChange-Id: Iedd00827461f6fb6bb98c209673700053fade53e\n""}, {'number': 8, 'created': '2015-05-19 16:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/6d5c32928ef1fe8c54c5289614258fa1163308f9', 'message': ""App resource\n\nIntroduces a first-order resource, the app, to manage Solum applications\nand replace the assembly and plan resources.\nIncludes an 'actions' model to allow for richer configuration of workflows\nand better tracking of artifacts and application changes.\n\nblueprint app-resource\n\nChange-Id: Iedd00827461f6fb6bb98c209673700053fade53e\n""}, {'number': 9, 'created': '2015-05-19 17:13:20.000000000', 'files': ['doc/source/index.rst', 'specs/liberty/app-resource.rst'], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/653a0d07b46b83eb8163964ee483b07f0e794867', 'message': ""App resource\n\nIntroduces a first-order resource, the app, to manage Solum applications\nand replace the assembly and plan resources.\nIncludes an 'actions' model to allow for richer configuration of workflows\nand better tracking of artifacts and application changes.\n\nblueprint app-resource\n\nChange-Id: Iedd00827461f6fb6bb98c209673700053fade53e\n""}]",106,173564,653a0d07b46b83eb8163964ee483b07f0e794867,38,5,9,1375,,,0,"App resource

Introduces a first-order resource, the app, to manage Solum applications
and replace the assembly and plan resources.
Includes an 'actions' model to allow for richer configuration of workflows
and better tracking of artifacts and application changes.

blueprint app-resource

Change-Id: Iedd00827461f6fb6bb98c209673700053fade53e
",git fetch https://review.opendev.org/openstack/solum-specs refs/changes/64/173564/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/app-resource.rst'],1,040de230681addb1e909595860c2b4d10c5f66ff,bp/app-resource,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================== An 'app' resource for managing applications =========================================== https://blueprints.launchpad.net/solum/+spec/app-resource This specification lines out a new first-class resource, the app, to be presented by the API as a simplified collection of assemblies, plan registrations, logs of actions, and infrastructure. Problem description =================== Interacting with Solum presently involves managing languagepacks, plans, assemblies, and sometimes components, heat stacks, pipelines, and services. The CLI has been augmented with a virtual ""app"" resource to simplify some of these interactions to reduce the resources to languagepacks and these new apps. Unfortunately, this simplification isn't available in the Solum API, and users of the API outside the CLI are missing out on this interaction. For example, due to the direct reference to plan in assembly, plans may not be deleted if there are any existing assemblies referencing it, meaning at present that soft deletions aren't possible for assemblies with our current models. Proposed change =============== Some elements of an application should persist between builds and deployments, like the networking information, or the overall status of an application. Other elements are complicated enough to warrant being separate resources, though not top-level due to their direct reliance on other resources, and to their nature of changing more frequently than the app as a whole. An app resource will own a history of registration revisions, a set of current states of test/build/deploy, an entry-point URL for the app, trigger URL, and a set of other metadata relevant to a single application. Alternatives ------------ One of the major pain points in manipulating Solum resources at present is understanding the relationship between plan and assembly, and what part each resource represents in an application. At minimum, decoupling assembly's direct reference to plan would be a good start, and could open the way to adding versioning to plans without necessarily needing to rebuild every assembly. Discerning from the API how many assemblies were created with a given plan is a tedious task, requiring fetching all a user's assemblies and filtering them by inspecting their plan_uri, and parsing that to fetch the uuid. At minimum, some search tools ought to be built into the API for example to filter, paginate, and order these assemblies by their fields, including created and updated dates. In any case, the conveniences the official CLI provides ought to be pulled back into the API to make Solum more accessible. Data model impact ----------------- - Plan table to be removed and replaced with a registration table. Some of an app's data belongs to an app, like the app entry point URI and the trigger URI, but some data might change from deployment to deployment, like the source repo and current branch. - Assembly table to be removed and replaced with a history table. The running of containers is still Solum's bread and butter, but the manual management of the containers and any other Openstack resources like Nova networks is better left to Solum to manage. App resource (to be completed) Action resource (to be completed) Registration resource (to be completed) REST API impact --------------- App Commands The app is the primary resource Solum manages. In addition to its own metadata and information, an app also owns a list of registration resources, and a list of actions. Being a first-class REST resource, an app has the standard Create, Read, Update, and Delete verbs: List all Apps GET http://SOLUM/apps 200 OK { 'apps': [ { 'uuid': '039db61a-b79a-43b3-821f-1e84e49fbdf3', 'name': 'ghost', 'description': 'My ghost blog', 'status': { 'test': 'INPROGRESS', 'build': 'PENDING', 'deploy': 'SUCCESS', } 'app_url': 'http://192.0.2.100', 'trigger_url': 'http://SOLUM/triggers/f2970536-c225-4959-9634-ddaf162cc214', 'created': <datetime>, 'updated': <datetime>, } ] } Create an App POST http://SOLUM/apps/ ... 200 OK { 'app': ... } Show one App GET http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3 200 OK { 'app': { 'uuid': '039db61a-b79a-43b3-821f-1e84e49fbdf3', 'name': 'ghost', 'description': 'My ghost blog', 'status': { 'test': 'INPROGRESS', 'build': 'PENDING', 'deploy': 'SUCCESS', } 'app_url': 'http://192.0.2.100', 'trigger_url': 'http://SOLUM/triggers/f2970536-c225-4959-9634-ddaf162cc214', 'registration': { 'repo_url': 'http://github.com/fakeuser/ghost.git', 'repo_sha': 'master', 'language_pack': 'python2.7-20150208', }, } } Update one App PUT http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3' { 'description': 'My old ghost blog', } 200 OK { 'app': { 'uuid': '039db61a-b79a-43b3-821f-1e84e49fbdf3', 'name': 'ghost', 'description': 'My old ghost blog', 'status': { 'test': 'INPROGRESS', 'build': 'PENDING', 'deploy': 'SUCCESS', } 'app_url': 'http://192.0.2.100', 'trigger_url': 'http://SOLUM/triggers/f2970536-c225-4959-9634-ddaf162cc214', 'registration': { 'repo_url': 'http://github.com/fakeuser/ghost.git', 'repo_sha': 'master', 'language_pack': 'python2.7-20150208', }, } } Delete one stopped App DELETE http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3 204 NO_CONTENT Registration commands A registration is a set of user-defined information pertaining to the building and deploying of an application. It includes information like the language pack used, the source repository location and revision, the ports exposed on the app, which workflow stages to execute, and a number of other things. An app owns at any time a list of at least one registration, and when an action is executed on an app the current (or a user-selected) registration is used to inform the process. Being a history, the resource does not support updates or deletes per se, though its structure as a history still leaves a mechanism for revision and reversion in a non-destructive manner. List all registrations GET http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/registrations 200 OK { 'registrations': [ { 'id': 2, 'created': <datetime>, 'repo_url': 'http://github.com/fakeuser/ghost.git', 'repo_sha': 'master', 'language_pack': 'python2.7-20150208', }, { 'id': 1, 'created': <datetime>, 'repo_url': 'http://github.com/fakeuser/ghost.git', 'repo_sha': 'addbottomnavbar', 'language_pack': 'python2.7-20150115', }, ] } Show current registration GET http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/registrations/current 200 OK { 'registration': { 'id': 2, 'created': <datetime>, 'repo_url': 'http://github.com/fakeuser/ghost.git', 'repo_sha': 'master', 'language_pack': 'python2.7-20150208', } } Show one registration GET http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/registrations/1 200 OK { 'registration': { 'id': 1, 'created': <datetime>, 'repo_url': 'http://github.com/fakeuser/ghost.git', 'repo_sha': 'addbottomnavbar', 'language_pack': 'python2.7-20150115', } } Create new registration POST http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/registrations { 'repo_url': 'http://github.com/fakeuser/ghost.git', 'repo_sha': 'newcolorscheme', 'language_pack': 'python2.7-20150117', } 200 OK { 'registration': { 'id': 3, 'created': <datetime>, 'repo_url': 'http://github.com/fakeuser/ghost.git', 'repo_sha': 'newcolorscheme', 'language_pack': 'python2.7-20150117', } } Create new registration by duplicating specific registration PUT http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/registrations/1 { } 200 OK { 'registration': { 'id': 4, 'created': <datetime>, 'repo_url': 'http://github.com/fakeuser/ghost.git', 'repo_sha': 'addbottomnavbar', 'language_pack': 'python2.7-20150115', } } Create new registration by duplicating and then modifying specific registration PUT http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/registrations/1 { 'repo_sha': 'addcarousel', } 200 OK { 'registration': { 'id': 5, 'created': <datetime>, 'repo_url': 'http://github.com/fakeuser/ghost.git', 'repo_sha': 'addcarousel', 'language_pack': 'python2.7-20150115', } } Workflow action commands An app of course manages each stage of an application through its CI/CD lifecycle. The workflow commands expose application control verbs to the user for direct interaction. Test app with current registration POST http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions { 'action': 'test', } 202 ACCEPTED { 'action': { 'id': 34, 'action': 'test', 'test_cmd': 'tox -epep8 -epy27', 'status': 'PENDING', 'started': <datetime>, 'updated': <datetime>, } } Build app with current registration POST http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions { 'action': 'build', } 202 ACCEPTED { 'action': { 'id': 35, 'action': 'build', 'status': 'PENDING', 'started': <datetime>, 'updated': <datetime>, } } Deploy app with last good build POST http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions { 'action': 'deploy', } 202 ACCEPTED { 'action': { 'id': 36, 'action': 'deploy', 'build_id': 35, 'status': 'PENDING', 'started': <datetime>, 'updated': <datetime>, } } Deploy app with specific good build POST http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions { 'action': 'deploy', 'build_id': 12, } 202 ACCEPTED { 'action': { 'id': 37, 'action': 'deploy', 'build_id': 12, 'status': 'PENDING', 'started': <datetime>, 'updated': <datetime>, } } Stop running app POST http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions { 'action': 'stop', } 202 ACCEPTED { 'action': { 'id': 38, 'action': 'stop', 'status': 'PENDING', 'started': <datetime>, 'updated': <datetime>, } } Execute entire workflow defined in current registration ??? POST http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions { 'action': ???, } 202 ACCEPTED { ??? } Execute entire workflow defined in specific registration ??? POST http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions { 'action': ???, 'registration': 1, } 202 ACCEPTED { ??? } Action history commands Every workflow action generates an entry in the actions table, and its current status is actively updated as an app goes through its workflow. Furthermore, the results of an action, including successfully built images and the logs from a given action, are available to the user for review at any time. Like registration, an app's action history does not support updates or deletes, and is in fact only appended to by Solum by way of executing workflow actions upon an app. List complete history GET http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions 200 OK { 'actions': [ { 'id': 38, 'action': 'stop', 'status': 'PENDING', 'started': <datetime>, 'updated': <datetime>, 'logs': <some URI>, }, { 'id': 37, 'action': 'deploy', 'build_id': 12, 'status': 'FAILED', 'started': <datetime>, 'updated': <datetime>, 'logs': <some URI>, }, { 'id': 36, 'action': 'deploy', 'build_id': 35, 'status': 'FAILED', 'started': <datetime>, 'updated': <datetime>, 'logs': <some URI>, }, { 'id': 35, 'action': 'build', 'status': 'SUCCESS', 'started': <datetime>, 'updated': <datetime>, 'logs': <some URI>, }, { 'id': 34, 'action': 'test', 'test_cmd': 'tox -epep8 -epy27', 'status': 'SUCCESS', 'started': <datetime>, 'updated': <datetime>, 'logs': <some URI>, }, . . . ] } Get most recent test, build, and deploy status GET http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions/latest 302 FOUND http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions/38 Get most recent good test action, good build action, and good deploy status GET http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions?filter=lastgood 200 OK { 'actions': [ { 'id': 35, 'action': 'build', 'status': 'SUCCESS', 'started': <datetime>, 'updated': <datetime>, 'logs': <some URI>, }, { 'id': 34, 'action': 'test', 'test_cmd': 'tox -epep8 -epy27', 'status': 'SUCCESS', 'started': <datetime>, 'updated': <datetime>, 'logs': <some URI>, }, { 'id': 30, 'action': 'deploy', 'status': 'SUCCESS', 'started': <datetime>, 'updated': <datetime>, 'logs': <some URI>, }, . . . ] } Download logs of specific completed action GET http://SOLUM/apps/039db61a-b79a-43b3-821f-1e84e49fbdf3/actions/30/logs 200 OK <text/plain logfile> Security impact --------------- (to be determined) Notifications impact -------------------- (to be determined) Other end user impact --------------------- At minimum, python-solumclient will be drastically simplified. At present, it already presents 'app' commands that manipulate primarily plan and assembly resources. By implementing these features in the API, the playing field is much more level should someone want to interact with Solum without using the official CLI. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <ed--cranford> Work Items ---------- - Create registration and history tables - Create app resource and model - Create child registration model - Create child history model - Remove assembly and plan models and tables - Remove assembly and plan commands from CLI - Modify app commands in CLI Dependencies ============ None Testing ======= A drastic modification of the models and resources in Solum will of course require extensive changes to both unit and tempest tests. Ideally, the tests will be made simpler, as a lot of metadata should be handled by the API and not by waitloops and client-side aggregation and filtering of API responses. Documentation Impact ==================== Significantly less effort will be spent on explaining assemblies and plans and their relationship to an application--arguably one of the most confusing ideas in Solum at present is that it is a tool for managing application lifecycles and yet has no application resource to speak of. References ========== None ",,605,0
openstack%2Ffreezer~master~I8a84ea4aa46a7acaecb103aa20f3dc8acd128d0c,openstack/freezer,master,I8a84ea4aa46a7acaecb103aa20f3dc8acd128d0c,freezer api support for action,MERGED,2015-05-08 14:12:33.000000000,2015-05-20 19:48:27.000000000,2015-05-20 19:48:26.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 14028}, {'_account_id': 14159}, {'_account_id': 14340}, {'_account_id': 15358}]","[{'number': 1, 'created': '2015-05-08 14:12:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/ef71e80186f519826e2b1524d6b2d214d402f9e7', 'message': 'freezer api support for action\n\nAdds an endpoint to the api for managing actions\n\nChange-Id: I8a84ea4aa46a7acaecb103aa20f3dc8acd128d0c\n'}, {'number': 2, 'created': '2015-05-13 17:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/c2380ff811acf84eab5bd0be19f2eceaebc80c66', 'message': 'freezer api support for action\n\nAdds an endpoint to the api for managing actions\n\nChange-Id: I8a84ea4aa46a7acaecb103aa20f3dc8acd128d0c\n'}, {'number': 3, 'created': '2015-05-13 18:13:09.000000000', 'files': ['freezer_api/README.rst', 'freezer_api/freezer_api/common/exceptions.py', 'freezer_api/freezer_api/storage/elastic.py', 'freezer_api/freezer_api/api/v1/actions.py', 'tests/test_apiclient_registration.py', 'freezer_api/freezer_api/api/v1/__init__.py', 'freezer_api/freezer_api/api/v1/backups.py', 'freezer_api/freezer_api/api/v1/clients.py', 'freezer_api/tests/test_actions.py', 'freezer_api/tests/test_clients.py', 'freezer_api/tests/test_exceptions.py', 'tests/test_apiclient_client.py', 'freezer/apiclient/client.py', 'freezer_api/tests/common.py', 'freezer_api/tests/test_elastic.py', 'tests/test_apiclient_backup.py', 'freezer/apiclient/exceptions.py', 'freezer/apiclient/actions.py', 'tests/test_apiclient_actions.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/1ae5c2e0248012446978419e02bb022ea3b7a76f', 'message': 'freezer api support for action\n\nAdds an endpoint to the api for managing actions\n\nChange-Id: I8a84ea4aa46a7acaecb103aa20f3dc8acd128d0c\n'}]",0,181402,1ae5c2e0248012446978419e02bb022ea3b7a76f,14,6,3,14159,,,0,"freezer api support for action

Adds an endpoint to the api for managing actions

Change-Id: I8a84ea4aa46a7acaecb103aa20f3dc8acd128d0c
",git fetch https://review.opendev.org/openstack/freezer refs/changes/02/181402/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezer_api/README.rst', 'freezer_api/freezer_api/common/exceptions.py', 'freezer/apiclient/client.py', 'freezer_api/freezer_api/storage/elastic.py', 'freezer_api/freezer_api/api/v1/actions.py', 'freezer_api/freezer_api/api/v1/__init__.py', 'tests/test_apiclient_backup.py', 'freezer/apiclient/actions.py']",8,ef71e80186f519826e2b1524d6b2d214d402f9e7,api-actions,""""""" Copyright 2015 Hewlett-Packard Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. This product includes cryptographic software written by Eric Young (eay@cryptsoft.com). This product includes software written by Tim Hudson (tjh@cryptsoft.com). ======================================================================== """""" import json import requests from freezer.apiclient import exceptions class ActionManager(object): def __init__(self, client): self.client = client self.endpoint = self.client.endpoint + '/v1/actions/' @property def headers(self): return {'X-Auth-Token': self.client.auth_token} def create(self, doc): r = requests.post(self.endpoint, data=json.dumps(doc), headers=self.headers) if r.status_code != 201: raise exceptions.MetadataCreationFailure( ""[*] Error {0}: {1}"".format(r.status_code, r.text)) action_id = r.json()['action_id'] return action_id def delete(self, action_id): endpoint = self.endpoint + action_id r = requests.delete(endpoint, headers=self.headers) if r.status_code != 204: raise exceptions.MetadataDeleteFailure( ""[*] Error {0}"".format(r.status_code)) def list(self, limit=10, offset=0, search=None): """""" Retrieves a list of action info structures :param limit: number of result to return (optional, default 10) :param offset: order of first document (optional, default 0) :param search: structured query (optional) can contain: * ""match"": list of {field, value} Example: { ""match"": [ {""description"": ""some search text here""}, {""backup_name"": ""mydata""}, ... ], } """""" data = json.dumps(search) if search else None query = {'limit': int(limit), 'offset': int(offset)} r = requests.get(self.endpoint, headers=self.headers, params=query, data=data) if r.status_code != 200: raise exceptions.MetadataGetFailure( ""[*] Error {0}: {1}"".format(r.status_code, r.text)) return r.json()['actions'] def get(self, action_id): endpoint = self.endpoint + action_id r = requests.get(endpoint, headers=self.headers) if r.status_code == 200: return r.json() if r.status_code == 404: return None raise exceptions.MetadataGetFailure( ""[*] Error {0}"".format(r.status_code)) def update(self, action_id, update_doc): endpoint = self.endpoint + action_id r = requests.patch(endpoint, headers=self.headers, data=json.dumps(update_doc)) if r.status_code != 200: raise exceptions.MetadataGetFailure( ""[*] Error {0}: {1}"".format(r.status_code, r.text)) return r.json()['version'] def set_status(self, action_id, new_status): return self.update(action_id, {'status': new_status}) ",,401,8
openstack%2Ffreezer~master~Ic74038fc15c22ab81dd77547be4048033c131623,openstack/freezer,master,Ic74038fc15c22ab81dd77547be4048033c131623,Add tests for client registration,MERGED,2015-05-05 09:30:13.000000000,2015-05-20 19:46:31.000000000,2015-05-20 19:46:29.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 14028}, {'_account_id': 14340}, {'_account_id': 15358}]","[{'number': 1, 'created': '2015-05-05 09:30:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/6687a4f998b165abe5f258d5c494c2d8861a0efa', 'message': 'Add tests for client registration\n\nFix missing tests for client registration\n\nChange-Id: Ic74038fc15c22ab81dd77547be4048033c131623\n'}, {'number': 2, 'created': '2015-05-08 14:12:33.000000000', 'files': ['tests/test_apiclient_registration.py', 'freezer/apiclient/registration.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/5324b9a4bceebfb4de4cda85d802c88ae983afa4', 'message': 'Add tests for client registration\n\nFix missing tests for client registration\n\nChange-Id: Ic74038fc15c22ab81dd77547be4048033c131623\n'}]",0,180077,5324b9a4bceebfb4de4cda85d802c88ae983afa4,8,5,2,14159,,,0,"Add tests for client registration

Fix missing tests for client registration

Change-Id: Ic74038fc15c22ab81dd77547be4048033c131623
",git fetch https://review.opendev.org/openstack/freezer refs/changes/77/180077/2 && git format-patch -1 --stdout FETCH_HEAD,"['freezer/apiclient/registration.py', 'tests/test_apiclient_registration.py']",2,6687a4f998b165abe5f258d5c494c2d8861a0efa,api-actions,"""""""Freezer swift.py related tests Copyright 2015 Hewlett-Packard Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. This product includes cryptographic software written by Eric Young (eay@cryptsoft.com). This product includes software written by Tim Hudson (tjh@cryptsoft.com). ======================================================================== """""" import unittest from mock import Mock, patch from freezer.apiclient import exceptions from freezer.apiclient import registration class TestRegistrationManager(unittest.TestCase): def setUp(self): self.mock_client = Mock() self.mock_client.endpoint = 'http://testendpoint:9999' self.mock_client.auth_token = 'testtoken' self.r = registration.RegistrationManager(self.mock_client) @patch('freezer.apiclient.registration.requests') def test_create(self, mock_requests): self.assertEqual(self.r.endpoint, 'http://testendpoint:9999/v1/clients/') self.assertEqual(self.r.headers, {'X-Auth-Token': 'testtoken'}) @patch('freezer.apiclient.registration.requests') def test_create_ok(self, mock_requests): mock_response = Mock() mock_response.status_code = 201 mock_response.json.return_value = {'client_id': 'qwerqwer'} mock_requests.post.return_value = mock_response retval = self.r.create(client_info={'client': 'metadata'}) self.assertEqual(retval, 'qwerqwer') @patch('freezer.apiclient.registration.requests') def test_create_fail_when_api_return_error_code(self, mock_requests): mock_response = Mock() mock_response.status_code = 500 mock_requests.post.return_value = mock_response self.assertRaises(exceptions.MetadataCreationFailure, self.r.create, {'client': 'metadata'}) @patch('freezer.apiclient.registration.requests') def test_delete_ok(self, mock_requests): mock_response = Mock() mock_response.status_code = 204 mock_requests.delete.return_value = mock_response retval = self.r.delete('test_client_id') self.assertIsNone(retval) @patch('freezer.apiclient.registration.requests') def test_delete_fail(self, mock_requests): mock_response = Mock() mock_response.status_code = 500 mock_requests.delete.return_value = mock_response self.assertRaises(exceptions.MetadataDeleteFailure, self.r.delete, 'test_client_id') @patch('freezer.apiclient.registration.requests') def test_get_ok(self, mock_requests): mock_response = Mock() mock_response.status_code = 200 mock_response.json.return_value = {'client_id': 'qwerqwer'} mock_requests.get.return_value = mock_response retval = self.r.get('test_client_id') self.assertEqual(retval, {'client_id': 'qwerqwer'}) @patch('freezer.apiclient.registration.requests') def test_get_none(self, mock_requests): mock_response = Mock() mock_response.status_code = 404 mock_requests.get.return_value = mock_response retval = self.r.get('test_client_id') self.assertIsNone(retval) # get_error @patch('freezer.apiclient.registration.requests') def test_list_ok(self, mock_requests): mock_response = Mock() mock_response.status_code = 200 client_list = [{'client_id_0': 'qwerqwer'}, {'client_id_1': 'asdfasdf'}] mock_response.json.return_value = {'clients': client_list} mock_requests.get.return_value = mock_response retval = self.r.list() self.assertEqual(retval, client_list) @patch('freezer.apiclient.registration.requests') def test_list_error(self, mock_requests): mock_response = Mock() mock_response.status_code = 404 client_list = [{'client_id_0': 'qwerqwer'}, {'client_id_1': 'asdfasdf'}] mock_response.json.return_value = {'clients': client_list} mock_requests.get.return_value = mock_response self.assertRaises(exceptions.MetadataGetFailure, self.r.list) ",,117,2
openstack%2Ffreezer~master~Iaa97f7a4efaa6bbc97ef8fa5566d5c5a55d2a11f,openstack/freezer,master,Iaa97f7a4efaa6bbc97ef8fa5566d5c5a55d2a11f,Fix stale import in freezer_api/storage/driver.py,MERGED,2015-05-20 17:36:43.000000000,2015-05-20 19:45:01.000000000,2015-05-20 19:45:01.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 14028}, {'_account_id': 14340}, {'_account_id': 15358}]","[{'number': 1, 'created': '2015-05-20 17:36:43.000000000', 'files': ['freezer_api/tests/test_driver.py', 'freezer_api/freezer_api/storage/driver.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/3b7b176a0b058da9f3c95a7fe207799908e6577b', 'message': 'Fix stale import in freezer_api/storage/driver.py\n\nfreezer_api/storage/driver.py has a stale import\n\nthe referenced file is simpledict.py which is not\nneeded anymore and has been removed\n\nChange-Id: Iaa97f7a4efaa6bbc97ef8fa5566d5c5a55d2a11f\nCloses-Bug: #1457158\n'}]",0,184555,3b7b176a0b058da9f3c95a7fe207799908e6577b,7,5,1,14159,,,0,"Fix stale import in freezer_api/storage/driver.py

freezer_api/storage/driver.py has a stale import

the referenced file is simpledict.py which is not
needed anymore and has been removed

Change-Id: Iaa97f7a4efaa6bbc97ef8fa5566d5c5a55d2a11f
Closes-Bug: #1457158
",git fetch https://review.opendev.org/openstack/freezer refs/changes/55/184555/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezer_api/tests/test_driver.py', 'freezer_api/freezer_api/storage/driver.py']",2,3b7b176a0b058da9f3c95a7fe207799908e6577b,,from freezer_api.storage import elastic,"from freezer_api.storage import simpledict, elastic",2,6
openstack%2Fpython-keystoneclient~master~Ic8a041262105ab9859539b0410c41ec42ab2b2a9,openstack/python-keystoneclient,master,Ic8a041262105ab9859539b0410c41ec42ab2b2a9,Cleanup exceptions,ABANDONED,2014-12-16 22:33:02.000000000,2015-05-20 19:35:24.000000000,,"[{'_account_id': 3}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-12-16 22:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/d7ac4129cbfe6d96a48e1fd36edc2567ec2e2afa', 'message': ""Cleanup exceptions\n\nWe have a general problem with syncing exceptions from oslo-incubator\nbecause whilst each project ends up with an exception named the same -\nthey are not the same object and cannot be caught in a unified way.\n\nAs we push session to be the default transport mechanism this is\nbecoming more and more of a problem as each client needs to do it's own\nexception handling so that the exception in its tree is raised and not\nbreak compatibility.\n\nWe need to structure keystone exceptions as if keystoneclient is the\nbase dependency for all other clients and allow them to import the\nsession exceptions on there own in such that we can start reusing these\nobjects across clients.\n\nChange-Id: Ic8a041262105ab9859539b0410c41ec42ab2b2a9\n""}, {'number': 2, 'created': '2014-12-16 23:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/ece779bcae1bce383423600e3c85a765b9854acd', 'message': ""Cleanup exceptions\n\nWe have a general problem with syncing exceptions from oslo-incubator\nbecause whilst each project ends up with an exception named the same -\nthey are not the same object and cannot be caught in a unified way.\n\nAs we push session to be the default transport mechanism this is\nbecoming more and more of a problem as each client needs to do it's own\nexception handling so that the exception in its tree is raised and not\nbreak compatibility.\n\nWe need to structure keystone exceptions as if keystoneclient is the\nbase dependency for all other clients and allow them to import the\nsession exceptions on there own in such that we can start reusing these\nobjects across clients.\n\nChange-Id: Ic8a041262105ab9859539b0410c41ec42ab2b2a9\n""}, {'number': 3, 'created': '2014-12-16 23:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/d31abd49505b81d2ffffc980d80c32fab67478fe', 'message': ""Cleanup exceptions\n\nWe have a general problem with syncing exceptions from oslo-incubator\nbecause whilst each project ends up with an exception named the same -\nthey are not the same object and cannot be caught in a unified way.\n\nAs we push session to be the default transport mechanism this is\nbecoming more and more of a problem as each client needs to do it's own\nexception handling so that the exception in its tree is raised and not\nbreak compatibility.\n\nWe need to structure keystone exceptions as if keystoneclient is the\nbase dependency for all other clients and allow them to import the\nsession exceptions on there own in such that we can start reusing these\nobjects across clients.\n\nChange-Id: Ic8a041262105ab9859539b0410c41ec42ab2b2a9\n""}, {'number': 4, 'created': '2014-12-17 06:37:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/95b03b5f4ba9a01ea7fadff70307054bc0e37300', 'message': ""Cleanup exceptions\n\nWe have a general problem with syncing exceptions from oslo-incubator\nbecause whilst each project ends up with an exception named the same -\nthey are not the same object and cannot be caught in a unified way.\n\nAs we push session to be the default transport mechanism this is\nbecoming more and more of a problem as each client needs to do it's own\nexception handling so that the exception in its tree is raised and not\nbreak compatibility.\n\nWe need to structure keystone exceptions as if keystoneclient is the\nbase dependency for all other clients and allow them to import the\nsession exceptions on there own in such that we can start reusing these\nobjects across clients.\n\nChange-Id: Ic8a041262105ab9859539b0410c41ec42ab2b2a9\n""}, {'number': 5, 'created': '2014-12-17 08:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/64633f7db3bd6a44e8a046d958a485e7ca7fb5e3', 'message': ""Cleanup exceptions\n\nWe have a general problem with syncing exceptions from oslo-incubator\nbecause whilst each project ends up with an exception named the same -\nthey are not the same object and cannot be caught in a unified way.\n\nAs we push session to be the default transport mechanism this is\nbecoming more and more of a problem as each client needs to do it's own\nexception handling so that the exception in its tree is raised and not\nbreak compatibility.\n\nWe need to structure keystone exceptions as if keystoneclient is the\nbase dependency for all other clients and allow them to import the\nsession exceptions on there own in such that we can start reusing these\nobjects across clients.\n\nChange-Id: Ic8a041262105ab9859539b0410c41ec42ab2b2a9\n""}, {'number': 6, 'created': '2015-01-19 00:16:54.000000000', 'files': ['keystoneclient/openstack/common/apiclient/__init__.py', 'keystoneclient/exceptions/session.py', 'keystoneclient/openstack/common/apiclient/base.py', 'keystoneclient/exceptions/auth.py', 'keystoneclient/exceptions/client.py', 'keystoneclient/exceptions/__init__.py', 'keystoneclient/openstack/common/apiclient/client.py', 'keystoneclient/openstack/common/uuidutils.py', 'keystoneclient/openstack/common/apiclient/utils.py', 'keystoneclient/base.py', 'keystoneclient/exceptions.py', 'keystoneclient/exceptions/base.py', 'openstack-common.conf', 'keystoneclient/openstack/common/apiclient/auth.py', 'keystoneclient/openstack/common/_i18n.py', 'keystoneclient/openstack/common/apiclient/fake_client.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/9a8c5c0e84c325ea6477a6df963469ab7464a59b', 'message': ""Cleanup exceptions\n\nWe have a general problem with syncing exceptions from oslo-incubator\nbecause whilst each project ends up with an exception named the same -\nthey are not the same object and cannot be caught in a unified way.\n\nAs we push session to be the default transport mechanism this is\nbecoming more and more of a problem as each client needs to do it's own\nexception handling so that the exception in its tree is raised and not\nbreak compatibility.\n\nWe need to structure keystone exceptions as if keystoneclient is the\nbase dependency for all other clients and allow them to import the\nsession exceptions on there own in such that we can start reusing these\nobjects across clients.\n\nChange-Id: Ic8a041262105ab9859539b0410c41ec42ab2b2a9\n""}]",0,142243,9a8c5c0e84c325ea6477a6df963469ab7464a59b,13,2,6,7191,,,0,"Cleanup exceptions

We have a general problem with syncing exceptions from oslo-incubator
because whilst each project ends up with an exception named the same -
they are not the same object and cannot be caught in a unified way.

As we push session to be the default transport mechanism this is
becoming more and more of a problem as each client needs to do it's own
exception handling so that the exception in its tree is raised and not
break compatibility.

We need to structure keystone exceptions as if keystoneclient is the
base dependency for all other clients and allow them to import the
session exceptions on there own in such that we can start reusing these
objects across clients.

Change-Id: Ic8a041262105ab9859539b0410c41ec42ab2b2a9
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/43/142243/6 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/openstack/common/memorycache.py', 'keystoneclient/openstack/common/apiclient/__init__.py', 'keystoneclient/exceptions/session.py', 'keystoneclient/openstack/common/__init__.py', 'keystoneclient/openstack/common/apiclient/base.py', 'keystoneclient/exceptions/client.py', 'keystoneclient/exceptions/__init__.py', 'keystoneclient/openstack/common/apiclient/client.py', 'keystoneclient/openstack/common/uuidutils.py', 'keystoneclient/openstack/common/apiclient/utils.py', 'keystoneclient/base.py', 'keystoneclient/exceptions.py', 'keystoneclient/exceptions/base.py', 'openstack-common.conf', 'keystoneclient/openstack/common/apiclient/auth.py', 'keystoneclient/openstack/common/_i18n.py', 'keystoneclient/openstack/common/apiclient/fake_client.py']",17,d7ac4129cbfe6d96a48e1fd36edc2567ec2e2afa,session-exc,,"# Copyright 2013 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" A fake server that ""responds"" to API methods with pre-canned responses. All of these responses come from the spec, so if for some reason the spec's wrong the tests might raise AssertionError. I've indicated in comments the places where actual behavior differs from the spec. """""" # W0102: Dangerous default value %s as argument # pylint: disable=W0102 import json import requests import six from six.moves.urllib import parse from keystoneclient.openstack.common.apiclient import client def assert_has_keys(dct, required=None, optional=None): required = required or [] optional = optional or [] for k in required: try: assert k in dct except AssertionError: extra_keys = set(dct.keys()).difference(set(required + optional)) raise AssertionError(""found unexpected keys: %s"" % list(extra_keys)) class TestResponse(requests.Response): """"""Wrap requests.Response and provide a convenient initialization. """""" def __init__(self, data): super(TestResponse, self).__init__() self._content_consumed = True if isinstance(data, dict): self.status_code = data.get('status_code', 200) # Fake the text attribute to streamline Response creation text = data.get('text', """") if isinstance(text, (dict, list)): self._content = json.dumps(text) default_headers = { ""Content-Type"": ""application/json"", } else: self._content = text default_headers = {} if six.PY3 and isinstance(self._content, six.string_types): self._content = self._content.encode('utf-8', 'strict') self.headers = data.get('headers') or default_headers else: self.status_code = data def __eq__(self, other): return (self.status_code == other.status_code and self.headers == other.headers and self._content == other._content) class FakeHTTPClient(client.HTTPClient): def __init__(self, *args, **kwargs): self.callstack = [] self.fixtures = kwargs.pop(""fixtures"", None) or {} if not args and ""auth_plugin"" not in kwargs: args = (None, ) super(FakeHTTPClient, self).__init__(*args, **kwargs) def assert_called(self, method, url, body=None, pos=-1): """"""Assert than an API method was just called. """""" expected = (method, url) called = self.callstack[pos][0:2] assert self.callstack, \ ""Expected %s %s but no calls were made."" % expected assert expected == called, 'Expected %s %s; got %s %s' % \ (expected + called) if body is not None: if self.callstack[pos][3] != body: raise AssertionError('%r != %r' % (self.callstack[pos][3], body)) def assert_called_anytime(self, method, url, body=None): """"""Assert than an API method was called anytime in the test. """""" expected = (method, url) assert self.callstack, \ ""Expected %s %s but no calls were made."" % expected found = False entry = None for entry in self.callstack: if expected == entry[0:2]: found = True break assert found, 'Expected %s %s; got %s' % \ (method, url, self.callstack) if body is not None: assert entry[3] == body, ""%s != %s"" % (entry[3], body) self.callstack = [] def clear_callstack(self): self.callstack = [] def authenticate(self): pass def client_request(self, client, method, url, **kwargs): # Check that certain things are called correctly if method in [""GET"", ""DELETE""]: assert ""json"" not in kwargs # Note the call self.callstack.append( (method, url, kwargs.get(""headers"") or {}, kwargs.get(""json"") or kwargs.get(""data""))) try: fixture = self.fixtures[url][method] except KeyError: pass else: return TestResponse({""headers"": fixture[0], ""text"": fixture[1]}) # Call the method args = parse.parse_qsl(parse.urlparse(url)[4]) kwargs.update(args) munged_url = url.rsplit('?', 1)[0] munged_url = munged_url.strip('/').replace('/', '_').replace('.', '_') munged_url = munged_url.replace('-', '_') callback = ""%s_%s"" % (method.lower(), munged_url) if not hasattr(self, callback): raise AssertionError('Called unknown API method: %s %s, ' 'expected fakes method name: %s' % (method, url, callback)) resp = getattr(self, callback)(**kwargs) if len(resp) == 3: status, headers, body = resp else: status, body = resp headers = {} self.last_request_id = headers.get('x-openstack-request-id', 'req-test') return TestResponse({ ""status_code"": status, ""text"": body, ""headers"": headers, }) ",256,1758
openstack%2Ftempest~master~Ia17f4dd2585c0d51540b05bcd9e08eec2757c1dd,openstack/tempest,master,Ia17f4dd2585c0d51540b05bcd9e08eec2757c1dd,Add cleanup after creating keypair,MERGED,2015-05-12 06:34:30.000000000,2015-05-20 19:28:31.000000000,2015-05-20 19:28:30.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}, {'_account_id': 7020}, {'_account_id': 8871}, {'_account_id': 10234}, {'_account_id': 10300}, {'_account_id': 10388}, {'_account_id': 14965}]","[{'number': 1, 'created': '2015-05-12 06:34:30.000000000', 'files': ['tempest/api/compute/servers/test_servers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/525a5bc9414795b642de9834c6cd8b55a68637c3', 'message': 'Add cleanup after creating keypair\n\nThere is no cleanup added after a keypair is created in test case\ntest_create_specify_keypair in test_servers.py which causes the test\ncase to leave behind a keypair when allow_tenant_isolation is false.\nThis issue is not observed when allow_tenant_isolation is true and\nadmin credentials are provided in tempest.conf as the tenant itself is\ndeleted after the test case ends.\n\nCloses-Bug:1453112\nChange-Id: Ia17f4dd2585c0d51540b05bcd9e08eec2757c1dd\nSigned-off-by: ahmad <afaheem88@gmail.com>\n'}]",0,182166,525a5bc9414795b642de9834c6cd8b55a68637c3,19,9,1,14965,,,0,"Add cleanup after creating keypair

There is no cleanup added after a keypair is created in test case
test_create_specify_keypair in test_servers.py which causes the test
case to leave behind a keypair when allow_tenant_isolation is false.
This issue is not observed when allow_tenant_isolation is true and
admin credentials are provided in tempest.conf as the tenant itself is
deleted after the test case ends.

Closes-Bug:1453112
Change-Id: Ia17f4dd2585c0d51540b05bcd9e08eec2757c1dd
Signed-off-by: ahmad <afaheem88@gmail.com>
",git fetch https://review.opendev.org/openstack/tempest refs/changes/66/182166/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_servers.py'],1,525a5bc9414795b642de9834c6cd8b55a68637c3,bug/1453112," self.addCleanup(self.keypairs_client.delete_keypair, key_name)",,1,0
openstack%2Fdiskimage-builder~master~Iffbc69de0516b58bfde48e87cd73073428d66b05,openstack/diskimage-builder,master,Iffbc69de0516b58bfde48e87cd73073428d66b05,doc: small snippet about operating system elements,MERGED,2015-05-15 17:15:58.000000000,2015-05-20 19:09:48.000000000,2015-05-20 19:09:46.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 10035}, {'_account_id': 12320}]","[{'number': 1, 'created': '2015-05-15 17:15:58.000000000', 'files': ['doc/source/developer/developing_elements.rst'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/2a7052e8ff65911ea1490b876e2faa4ae4552342', 'message': 'doc: small snippet about operating system elements\n\nAdd a small documentation paragraph about the operating system elements,\nwhat they are required to provide (and thus what other elements can rely\non).\n\nThis makes DISTRO_NAME a prime-class variable, which can now be assumed\nto always exists (it was de-facto required so far).\n\nChange-Id: Iffbc69de0516b58bfde48e87cd73073428d66b05\n'}]",0,183616,2a7052e8ff65911ea1490b876e2faa4ae4552342,11,4,1,12320,,,0,"doc: small snippet about operating system elements

Add a small documentation paragraph about the operating system elements,
what they are required to provide (and thus what other elements can rely
on).

This makes DISTRO_NAME a prime-class variable, which can now be assumed
to always exists (it was de-facto required so far).

Change-Id: Iffbc69de0516b58bfde48e87cd73073428d66b05
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/16/183616/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/developer/developing_elements.rst'],1,2a7052e8ff65911ea1490b876e2faa4ae4552342,os-doc,"Operating system elements ^^^^^^^^^^^^^^^^^^^^^^^^^ Some elements define the base structure for an operating system -- for example, the ``opensuse`` element builds a base openSUSE system. Such elements have more requirements than the other elements: * they must have ``operating-system`` in their element-provides, so this indicates they are an ""operating system"". * they must export the ``DISTRO_NAME`` environment variable with the name of the distribution built, using an environment.d script. For example, the ``opensuse`` element exports ``DISTRO_NAME=opensuse``.",,12,0
openstack%2Fdiskimage-builder~master~I3e19f6269ceba937fcd630bab265d132bd525519,openstack/diskimage-builder,master,I3e19f6269ceba937fcd630bab265d132bd525519,Use Centos 7 cloud image symlink,MERGED,2015-05-14 19:41:13.000000000,2015-05-20 19:08:49.000000000,2015-05-20 19:08:46.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 9369}, {'_account_id': 12092}]","[{'number': 1, 'created': '2015-05-14 19:41:13.000000000', 'files': ['elements/centos7/root.d/10-centos7-cloud-image'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/6e358d1cd44c6841a2bbe802ad5dc241bba0615b', 'message': 'Use Centos 7 cloud image symlink\n\nWe should make use of the CentOS-7-x86_64-GenericCloud.qcow2 symlink from\nhttp://cloud.centos.org/centos/7/images/ instead of having a hard coded cloud\nimage. Specific cloud images can still be downloaded by overriding\n$DIB_RELEASE.\n\nMore importantly, using the symlink will keep us automatically up to date with\nthe latest CentOS 7 cloud image. The image in use by the hard coded value\noccassionally exhibits ""No space left on device"" errors after the cloud-init\nfilesystem resize. More info about this issue is at:\nhttp://xfs.org/index.php/XFS_FAQ#Q:_Why_do_I_receive_No_space_left_on_device_after_xfs_growfs.3F\n\nThe newer cloud image (with a newer kernel) does not exhibit this issue.\n\nChange-Id: I3e19f6269ceba937fcd630bab265d132bd525519\n'}]",0,183185,6e358d1cd44c6841a2bbe802ad5dc241bba0615b,12,4,1,7144,,,0,"Use Centos 7 cloud image symlink

We should make use of the CentOS-7-x86_64-GenericCloud.qcow2 symlink from
http://cloud.centos.org/centos/7/images/ instead of having a hard coded cloud
image. Specific cloud images can still be downloaded by overriding
$DIB_RELEASE.

More importantly, using the symlink will keep us automatically up to date with
the latest CentOS 7 cloud image. The image in use by the hard coded value
occassionally exhibits ""No space left on device"" errors after the cloud-init
filesystem resize. More info about this issue is at:
http://xfs.org/index.php/XFS_FAQ#Q:_Why_do_I_receive_No_space_left_on_device_after_xfs_growfs.3F

The newer cloud image (with a newer kernel) does not exhibit this issue.

Change-Id: I3e19f6269ceba937fcd630bab265d132bd525519
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/85/183185/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/centos7/root.d/10-centos7-cloud-image'],1,6e358d1cd44c6841a2bbe802ad5dc241bba0615b,centos-generic, DIB_RELEASE=${DIB_RELEASE:-GenericCloud}, DIB_RELEASE=${DIB_RELEASE:-GenericCloud-20140929_01},1,1
openstack%2Fdiskimage-builder~master~I84d185887007d501306fe22731dd073e62fdfe36,openstack/diskimage-builder,master,I84d185887007d501306fe22731dd073e62fdfe36,Have simple-init regenerate ssh keys on boot,MERGED,2015-05-10 17:51:47.000000000,2015-05-20 19:06:44.000000000,2015-05-20 19:06:42.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 9369}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-05-10 17:51:47.000000000', 'files': ['elements/simple-init/install.d/simple-init.sh'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/53a57e871398b92549a12fff473b5a68d5321833', 'message': ""Have simple-init regenerate ssh keys on boot\n\nIf the keys aren't there on boot, we want to generate them.\n\nChange-Id: I84d185887007d501306fe22731dd073e62fdfe36\n""}]",0,181749,53a57e871398b92549a12fff473b5a68d5321833,15,5,1,2,,,0,"Have simple-init regenerate ssh keys on boot

If the keys aren't there on boot, we want to generate them.

Change-Id: I84d185887007d501306fe22731dd073e62fdfe36
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/49/181749/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/simple-init/install.d/simple-init.sh'],1,53a57e871398b92549a12fff473b5a68d5321833,,if [ -f /usr/bin/dpkg ] ; then test -f /etc/ssh/ssh_host_rsa_key || dpkg-reconfigure openssh-server fi,,3,0
openstack%2Fpython-keystoneclient~master~Ib387f030af0a585fca806d03cbd6d78b2521c6e1,openstack/python-keystoneclient,master,Ib387f030af0a585fca806d03cbd6d78b2521c6e1,Access Info Formatter,ABANDONED,2015-04-10 17:01:52.000000000,2015-05-20 19:00:01.000000000,,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 11333}]","[{'number': 1, 'created': '2015-04-10 17:01:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/9c746e266a843b5678ae72971220363afd1ee2db', 'message': 'Access Info Formatter\n\nThis patch provides library funtions to convert Access Info\nobject to token data.\n\npartially implements bp token-provider-cleanup\n\nChange-Id: Ib387f030af0a585fca806d03cbd6d78b2521c6e1\n'}, {'number': 2, 'created': '2015-04-15 20:27:55.000000000', 'files': ['keystoneclient/models/formatter.py', 'keystoneclient/tests/unit/test_access_info.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/23c961023f39388ce5b496f93ae699c807aec1d4', 'message': 'Access Info Formatter\n\nThis patch provides library funtions to convert Access Info\nobject to token data.\n\npartially implements bp token-provider-cleanup\n\nChange-Id: Ib387f030af0a585fca806d03cbd6d78b2521c6e1\n'}]",3,172514,23c961023f39388ce5b496f93ae699c807aec1d4,13,3,2,11333,,,0,"Access Info Formatter

This patch provides library funtions to convert Access Info
object to token data.

partially implements bp token-provider-cleanup

Change-Id: Ib387f030af0a585fca806d03cbd6d78b2521c6e1
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/14/172514/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/models/formatter.py', 'keystoneclient/tests/unit/test_access_info.py']",2,9c746e266a843b5678ae72971220363afd1ee2db,bp/token-provider-cleanup,"from keystoneclient.models import formatter def test_builder_unscoped_access_info_to_token_data(self): director = builder.PythonDirector() access = director.construct(access_data_unscoped) self.assertIsNotNone(access) self.assert_deep_match(access_data_unscoped['token'], access) token_data = formatter.Formatter.get_token_data_v3(access) self.assert_deep_match(token_data['token'], access) def test_builder_project_scoped_access_info_to_token_data(self): director = builder.PythonDirector() access = director.construct(access_data_project_scoped) self.assertIsNotNone(access) self.assert_deep_match(access_data_project_scoped['token'], access) token_data = formatter.Formatter.get_token_data_v3(access) self.assert_deep_match(token_data['token'], access) def test_builder_domain_scoped_domain_access_info_to_token_data(self): director = builder.PythonDirector() access = director.construct(access_data_domain_scoped) self.assertIsNotNone(access) token_data = formatter.Formatter.get_token_data_v3(access) self.assert_deep_match(token_data['token'], access) ",,160,0
openstack%2Fopenstack-manuals~master~Ie5e128b6f94e29e9ef216ea668284756a69ec2b7,openstack/openstack-manuals,master,Ie5e128b6f94e29e9ef216ea668284756a69ec2b7,[install-guide] [yum] use apache front-end for keystone,MERGED,2015-04-28 09:52:58.000000000,2015-05-20 18:56:29.000000000,2015-05-16 07:25:21.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 9382}, {'_account_id': 9515}]","[{'number': 1, 'created': '2015-04-28 09:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/81a22f86416e08e8210dd67f35d374cc98eb6a70', 'message': '[install-guide] [yum] use apache front-end for keystone\n\nReplace default eventlet front-end with Apache front-end to provide\na more production-style deployment.\n\nPartially implements bp installguide-kilo.\n\nChange-Id: Ie5e128b6f94e29e9ef216ea668284756a69ec2b7\n'}, {'number': 2, 'created': '2015-04-28 10:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3284510c992e5bad442252046693c52476ae3b0a', 'message': '[install-guide] [yum] use apache front-end for keystone\n\nReplace default eventlet front-end with Apache front-end to provide\na more production-style deployment.\n\nPartially implements bp installguide-kilo.\n\nChange-Id: Ie5e128b6f94e29e9ef216ea668284756a69ec2b7\n'}, {'number': 3, 'created': '2015-05-11 14:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f41f187c2caee2e59cc3babe752dd3253f8cdd76', 'message': '[install-guide] [yum] use apache front-end for keystone\n\nReplace default eventlet front-end with Apache front-end to provide\na more production-style deployment.\n\nPartially implements bp installguide-kilo.\n\nChange-Id: Ie5e128b6f94e29e9ef216ea668284756a69ec2b7\n'}, {'number': 4, 'created': '2015-05-15 21:49:12.000000000', 'files': ['doc/install-guide/section_keystone-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f1c871aa98aaf496a1618ad7c25c2ba48b6bd66b', 'message': '[install-guide] [yum] use apache front-end for keystone\n\nReplace default eventlet front-end with Apache front-end to provide\na more production-style deployment.\n\nPartially implements bp installguide-kilo.\n\nChange-Id: Ie5e128b6f94e29e9ef216ea668284756a69ec2b7\n'}]",0,178112,f1c871aa98aaf496a1618ad7c25c2ba48b6bd66b,24,5,4,167,,,0,"[install-guide] [yum] use apache front-end for keystone

Replace default eventlet front-end with Apache front-end to provide
a more production-style deployment.

Partially implements bp installguide-kilo.

Change-Id: Ie5e128b6f94e29e9ef216ea668284756a69ec2b7
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/12/178112/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_keystone-install.xml'],1,81a22f86416e08e8210dd67f35d374cc98eb6a70,bp/installguide-kilo," <screen os=""rhel;centos;fedora""><prompt>#</prompt> <userinput>yum install openstack-keystone httpd mod_wsgi python-openstackclient memcached python-memcached</userinput></screen> <procedure os=""ubuntu;rhel;centos;fedora""> <para>Edit the <filename os=""ubuntu"">/etc/apache2/apache2.conf</filename> <filename os=""rhel;centos;fedora"">/etc/httpd/conf/httpd.conf</filename> file and <filename os=""ubuntu"">/etc/apache2/sites-available/wsgi-keystone.conf</filename> <filename os=""rhel;centos;fedora"">/etc/httpd/conf.d/wsgi-keystone.conf</filename> <programlisting os=""ubuntu"">Listen 5000 <programlisting os=""rhel;fedora;centos"">Listen 5000 Listen 35357 &lt;VirtualHost *:5000&gt; WSGIDaemonProcess keystone-public processes=5 threads=1 user=keystone display-name=%{GROUP} WSGIProcessGroup keystone-public WSGIScriptAlias / /var/www/cgi-bin/keystone/main WSGIApplicationGroup %{GLOBAL} WSGIPassAuthorization On LogLevel info ErrorLog /var/log/httpd/keystone-error.log CustomLog /var/log/httpd/keystone-access.log combined &lt;/VirtualHost&gt; &lt;VirtualHost *:35357&gt; WSGIDaemonProcess keystone-admin processes=5 threads=1 user=keystone display-name=%{GROUP} WSGIProcessGroup keystone-admin WSGIScriptAlias / /var/www/cgi-bin/keystone/admin WSGIApplicationGroup %{GLOBAL} WSGIPassAuthorization On LogLevel info ErrorLog /var/log/httpd/keystone-error.log CustomLog /var/log/httpd/keystone-access.log combined &lt;/VirtualHost&gt;</programlisting> <step os=""ubuntu""> <step os=""ubuntu""> <step os=""ubuntu;rhel;fedora;centos""> <screen os=""ubuntu""><prompt>#</prompt> <userinput>service apache2 restart</userinput></screen> <screen os=""rhel;fedora;centos""><prompt>#</prompt> <userinput>systemctl enable httpd.service</userinput> <prompt>#</prompt> <userinput>systemctl start httpd.service</userinput></screen> <step os=""opensuse;sles"">"," <screen os=""rhel;centos;fedora""><prompt>#</prompt> <userinput>yum install openstack-keystone python-openstackclient memcached python-memcached</userinput></screen> <procedure os=""ubuntu""> <para>Edit the <filename>/etc/apache2/apache2.conf</filename> file and <filename>/etc/apache2/sites-available/wsgi-keystone.conf</filename> <programlisting>Listen 5000 <step> <step> <step os=""ubuntu""> <screen><prompt>#</prompt> <userinput>service apache2 restart</userinput></screen> <step os=""rhel;fedora;centos;opensuse;sles"">",38,10
openstack%2Fopenstacksdk~master~I9425ea7da6d5da0b5640dbb76c890785b35badd3,openstack/openstacksdk,master,I9425ea7da6d5da0b5640dbb76c890785b35badd3,Change example for preferences,MERGED,2015-05-20 18:00:01.000000000,2015-05-20 18:53:39.000000000,2015-05-20 18:53:38.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-20 18:00:01.000000000', 'files': ['examples/connection.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ae45a0726c41e8a62fc20defb230854baed6ac19', 'message': 'Change example for preferences\n\nChange-Id: I9425ea7da6d5da0b5640dbb76c890785b35badd3\n'}]",0,184566,ae45a0726c41e8a62fc20defb230854baed6ac19,6,2,1,8736,,,0,"Change example for preferences

Change-Id: I9425ea7da6d5da0b5640dbb76c890785b35badd3
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/66/184566/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/connection.py'],1,ae45a0726c41e8a62fc20defb230854baed6ac19,," opts.preferences.set_region(opts.preferences.ALL, cloud.region)"," opts.user_preferences.set_region(opts.user_preferences.ALL, cloud.region)",1,1
openstack%2Ftripleo-ci~master~I11c2674391834ec09e0b029a3f9b181b8456de8b,openstack/tripleo-ci,master,I11c2674391834ec09e0b029a3f9b181b8456de8b,puppet: use a single image for CI,MERGED,2015-04-24 02:29:10.000000000,2015-05-20 18:44:37.000000000,2015-05-20 18:44:36.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 6796}, {'_account_id': 7144}]","[{'number': 1, 'created': '2015-04-24 02:29:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/85e0c797eb409882f7bc3a4f4eed2f85506462ec', 'message': 'puppet: use a single image for CI\n\nThis patch updates the Puppet CI job so that it uses the new\ndisk_image.yaml functionality in devtest to use a single\nimage for all of the Overcloud roles. This should help\nsave CI time.\n\nChange-Id: I11c2674391834ec09e0b029a3f9b181b8456de8b\nDepends-On: I78c4c532169721674b2ea58ef37d2a4b23693fae\n'}, {'number': 2, 'created': '2015-04-24 11:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ac1df41817a02ba5213ddedcb114d2907428714e', 'message': 'puppet: use a single image for CI\n\nThis patch updates the Puppet CI job so that it uses the new\ndisk_image.yaml functionality in devtest to use a single\nimage for all of the Overcloud roles. This should help\nsave CI time.\n\nDepends-On: I6ad2357d68cd87764d78a723eaecbd487b5a98c1\n\nChange-Id: I11c2674391834ec09e0b029a3f9b181b8456de8b\n'}, {'number': 3, 'created': '2015-05-07 18:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/51326c4ef9de9290bff365bb1cb1f2639b9c0af7', 'message': 'puppet: use a single image for CI\n\nThis patch updates the Puppet CI job so that it uses the new\ndisk_image.yaml functionality in devtest to use a single\nimage for all of the Overcloud roles. This should help\nsave CI time and also significantly cleans up how\nwe configure the puppet CI job.\n\nDepends-On: I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56\n\nChange-Id: I11c2674391834ec09e0b029a3f9b181b8456de8b\n'}, {'number': 4, 'created': '2015-05-18 21:34:39.000000000', 'files': ['toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d80d1d75be1a2b0db8e379de94b3c20d5c6a6817', 'message': 'puppet: use a single image for CI\n\nThis patch updates the Puppet CI job so that it uses the new\ndisk_image.yaml functionality in devtest to use a single\nimage for all of the Overcloud roles. This should help\nsave CI time and also significantly cleans up how\nwe configure the puppet CI job.\n\nDepends-On: I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56\n\nChange-Id: I11c2674391834ec09e0b029a3f9b181b8456de8b\n'}]",2,177060,d80d1d75be1a2b0db8e379de94b3c20d5c6a6817,32,5,4,360,,,0,"puppet: use a single image for CI

This patch updates the Puppet CI job so that it uses the new
disk_image.yaml functionality in devtest to use a single
image for all of the Overcloud roles. This should help
save CI time and also significantly cleans up how
we configure the puppet CI job.

Depends-On: I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56

Change-Id: I11c2674391834ec09e0b029a3f9b181b8456de8b
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/60/177060/4 && git format-patch -1 --stdout FETCH_HEAD,['toci_gate_test.sh'],1,85e0c797eb409882f7bc3a4f4eed2f85506462ec,puppet-single-image, # Disk images file used to deploy puppet with an all-in-one image export OVERCLOUD_DISK_IMAGES_CONFIG=/opt/stack/new/disk_images.yaml cat >> $OVERCLOUD_DISK_IMAGES_CONFIG <<EOF_CAT disk_images: - imagename: overcloud arch: amd64 type: qcow2 elements: - hosts baremetal dhcp-all-interfaces os-collect-config heat-config-puppet puppet-modules hiera overcloud-compute overcloud-controller stackuser os-net-config delorean-repo rdo-release heat_parameters: - controllerImage - NovaImage - CephStorageImage - BlockStorageImage EOF_CAT, BASE_PUPPET_ELEMENTS='hosts baremetal dhcp-all-interfaces os-collect-config heat-config-puppet puppet-modules hiera' export OVERCLOUD_CONTROL_DIB_ELEMENTS=$BASE_PUPPET_ELEMENTS export OVERCLOUD_CONTROL_DIB_EXTRA_ARGS='overcloud-controller' export OVERCLOUD_COMPUTE_DIB_ELEMENTS=$BASE_PUPPET_ELEMENTS export OVERCLOUD_COMPUTE_DIB_EXTRA_ARGS='overcloud-compute',17,5
openstack%2Ftripleo-incubator~master~I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56,openstack/tripleo-incubator,master,I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56,Add a puppet disk images YAML file,MERGED,2015-05-07 18:48:53.000000000,2015-05-20 18:43:51.000000000,2015-05-20 18:43:51.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 6796}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-05-07 18:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/bbba754099886c403b86e2f0947050c0c4f69499', 'message': 'Add a puppet disk images YAML file\n\nThis patch adds a puppet version of the new disk_image.yaml\nfile which can be used to drive build-images and load-images\nvia devtest_overcloud.sh.\n\nThe overcloud_puppet_disk_images.yaml currently builds a\nsingle image that is configured to be used for all\npuppet roles.\n\nAlso, includes doc updates to show how this simplifies\nthe using puppet w/ devtest_overcloud.sh.\n\nChange-Id: I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56\n'}, {'number': 2, 'created': '2015-05-07 18:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/c3e49480799b96ab3e03929ecf12d3bd463154fd', 'message': 'Add a puppet disk images YAML file\n\nThis patch adds a puppet version of the new disk_image.yaml\nfile which can be used to drive build-images and load-images\nvia devtest_overcloud.sh.\n\nThe overcloud_puppet_disk_images.yaml currently builds a\nsingle image that is configured to be used for all\npuppet roles.\n\nAlso, includes doc updates to show how this simplifies\nthe using puppet w/ devtest_overcloud.sh.\n\nChange-Id: I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56\n'}, {'number': 3, 'created': '2015-05-07 19:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ba2aa923d22152c82119b4e3e970165f42ba95dc', 'message': 'Add a puppet disk images YAML file\n\nThis patch adds a puppet version of the new disk_image.yaml\nfile which can be used to drive build-images and load-images\nvia devtest_overcloud.sh.\n\nThe overcloud_puppet_disk_images.yaml currently builds a\nsingle image that is configured to be used for all\npuppet roles.\n\nAlso, includes doc updates to show how this simplifies\nthe using puppet w/ devtest_overcloud.sh.\n\nChange-Id: I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56\n'}, {'number': 4, 'created': '2015-05-09 12:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/32308df91b9c9cdd72fb8d2ad9b76de3eeeef44f', 'message': 'Add a puppet disk images YAML file\n\nThis patch adds a puppet version of the new disk_image.yaml\nfile which can be used to drive build-images and load-images\nvia devtest_overcloud.sh.\n\nThe overcloud_puppet_disk_images.yaml currently builds a\nsingle image that is configured to be used for all\npuppet roles.\n\nAlso, includes doc updates to show how this simplifies\nthe using puppet w/ devtest_overcloud.sh.\n\nChange-Id: I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56\n'}, {'number': 5, 'created': '2015-05-14 16:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/c7761e089df9b0c6790a7ca8737e6eba45bee7a6', 'message': 'Add a puppet disk images YAML file\n\nThis patch adds a puppet version of the new disk_image.yaml\nfile which can be used to drive build-images and load-images\nvia devtest_overcloud.sh.\n\nThe overcloud_puppet_disk_images.yaml currently builds a\nsingle image that is configured to be used for all\npuppet roles.\n\nAlso, includes doc updates to show how this simplifies\nthe using puppet w/ devtest_overcloud.sh.\n\nChange-Id: I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56\n'}, {'number': 6, 'created': '2015-05-17 01:34:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/dd5946ee8e71a7178d798ab650cf43fcb8130bd1', 'message': 'Add a puppet disk images YAML file\n\nThis patch adds a puppet version of the new disk_image.yaml\nfile which can be used to drive build-images and load-images\nvia devtest_overcloud.sh.\n\nThe overcloud_puppet_disk_images.yaml currently builds a\nsingle image that is configured to be used for all\npuppet roles.\n\nAlso, includes doc updates to show how this simplifies\nthe using puppet w/ devtest_overcloud.sh.\n\nChange-Id: I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56\n'}, {'number': 7, 'created': '2015-05-18 21:25:09.000000000', 'files': ['doc/source/puppet.rst', 'scripts/overcloud_puppet_disk_images.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/d59602cbfaee6aae4a609e534d372fc1747770ab', 'message': 'Add a puppet disk images YAML file\n\nThis patch adds a puppet version of the new disk_image.yaml\nfile which can be used to drive build-images and load-images\nvia devtest_overcloud.sh.\n\nThe overcloud_puppet_disk_images.yaml currently builds a\nsingle image that is configured to be used for all\npuppet roles.\n\nAlso, includes doc updates to show how this simplifies\nthe using puppet w/ devtest_overcloud.sh.\n\nChange-Id: I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56\n'}]",7,181114,d59602cbfaee6aae4a609e534d372fc1747770ab,36,5,7,360,,,0,"Add a puppet disk images YAML file

This patch adds a puppet version of the new disk_image.yaml
file which can be used to drive build-images and load-images
via devtest_overcloud.sh.

The overcloud_puppet_disk_images.yaml currently builds a
single image that is configured to be used for all
puppet roles.

Also, includes doc updates to show how this simplifies
the using puppet w/ devtest_overcloud.sh.

Change-Id: I1b1dbd5a7e2a4fda2eff31813518df8bc72e7e56
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/14/181114/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/puppet.rst', 'scripts/overcloud_puppet_disk_images.yaml']",2,bbba754099886c403b86e2f0947050c0c4f69499,build-images,# A puppet images YAML file that will build and # load a single puppet base image to be used for # all roles. # # The heat_parameter section is used to output a heat # environment file that maps heat parameter # names to the Glance image IDs. disk_images: - imagename: overcloud arch: amd64 type: qcow2 elements: - hosts baremetal dhcp-all-interfaces os-collect-config heat-config-puppet puppet-modules hiera overcloud-compute overcloud-controller stackuser os-net-config delorean-repo rdo-release heat_parameters: - controllerImage - NovaImage - CephStorageImage - BlockStorageImage ,,24,23
openstack%2Fapi-site~master~If85bc020cd54e3ca06e5d320024dec9428764641,openstack/api-site,master,If85bc020cd54e3ca06e5d320024dec9428764641,Publish Libcloud version of FirstApp,MERGED,2015-05-20 17:43:39.000000000,2015-05-20 18:28:01.000000000,2015-05-20 18:28:01.000000000,"[{'_account_id': 3}, {'_account_id': 136}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 4625}, {'_account_id': 7232}, {'_account_id': 9382}, {'_account_id': 15867}]","[{'number': 1, 'created': '2015-05-20 17:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/1b26996ce77365e713922af9bcb4c92deab5ec99', 'message': ""Publish Libcloud version of FirstApp\n\nThe Libcloud version of FirstApp is ready to move from draft stage\nso it can be widely disseminated to satiate the burning need for this\ncontent that is currently not being addressed. The guide will be\npromoted heavily leading into and at the summit.\n\nSo far it has received significantly more editing and testing than\nother sprint-created documents when they were published. This is thanks\nto the work of: Andreas Jaegar, Karen Bradshaw, Diane Fleming, Shilla Saebi,\nJames Dempsey's users, Jon Proulx, Bruno Lago, Chuck Burkett, Dana Bauer,\nand the original authors (at least 2 each section).\n\nAny areas lacking in the guide are well understood and captured in the\nbug list:\nhttps://bugs.launchpad.net/openstack-manuals/+bugs?field.tag=firstapp\nand there are no major blockers that would prevent listing this guide\non developer.openstack.org.\n\nThis patch links the libcloud section of developer.openstack.org to the\nguide.\n\nChange-Id: If85bc020cd54e3ca06e5d320024dec9428764641\n""}, {'number': 2, 'created': '2015-05-20 17:44:10.000000000', 'files': ['tox.ini', 'www/index.html'], 'web_link': 'https://opendev.org/openstack/api-site/commit/5a11f8343cd0253c18ca81f704a822bc3be62d6a', 'message': ""Publish Libcloud version of FirstApp\n\nThe Libcloud version of FirstApp is ready to move from draft stage\nso it can be widely disseminated to satiate the burning need for this\ncontent that is currently not being addressed. The guide was very well\nreceived during it's packed-room summit sesion.\n\nSo far it has received significantly more editing and testing than\nother sprint-created documents when they were published. This is thanks\nto the work of: Andreas Jaegar, Karen Bradshaw, Diane Fleming, Shilla Saebi,\nJames Dempsey's users, Jon Proulx, Bruno Lago, Chuck Burkett, Dana Bauer,\nand the original authors (at least 2 each section).\n\nAny areas lacking in the guide are well understood and captured in the\nbug list:\nhttps://bugs.launchpad.net/openstack-manuals/+bugs?field.tag=firstapp\nand there are no major blockers that would prevent listing this guide\non developer.openstack.org.\n\nThis patch links the libcloud section of developer.openstack.org to the\nguide.\n\nChange-Id: If85bc020cd54e3ca06e5d320024dec9428764641\n""}]",0,184560,5a11f8343cd0253c18ca81f704a822bc3be62d6a,13,8,2,612,,,0,"Publish Libcloud version of FirstApp

The Libcloud version of FirstApp is ready to move from draft stage
so it can be widely disseminated to satiate the burning need for this
content that is currently not being addressed. The guide was very well
received during it's packed-room summit sesion.

So far it has received significantly more editing and testing than
other sprint-created documents when they were published. This is thanks
to the work of: Andreas Jaegar, Karen Bradshaw, Diane Fleming, Shilla Saebi,
James Dempsey's users, Jon Proulx, Bruno Lago, Chuck Burkett, Dana Bauer,
and the original authors (at least 2 each section).

Any areas lacking in the guide are well understood and captured in the
bug list:
https://bugs.launchpad.net/openstack-manuals/+bugs?field.tag=firstapp
and there are no major blockers that would prevent listing this guide
on developer.openstack.org.

This patch links the libcloud section of developer.openstack.org to the
guide.

Change-Id: If85bc020cd54e3ca06e5d320024dec9428764641
",git fetch https://review.opendev.org/openstack/api-site refs/changes/60/184560/2 && git format-patch -1 --stdout FETCH_HEAD,"['tox.ini', 'www/index.html']",2,1b26996ce77365e713922af9bcb4c92deab5ec99,publish-firstapp," <a class=""link"" href=""http://developer.openstack.org/firstapp-libcloud/getting_started.html"" target=""_top""> Writing your First OpenStack Application </a> </dd> <dd>",,8,4
openstack%2Fproject-config~master~I9f8252133d460e5042ea88a67cf11546b2164a0d,openstack/project-config,master,I9f8252133d460e5042ea88a67cf11546b2164a0d,Increase Kolla build timeout by 30 minutes,ABANDONED,2015-05-18 13:23:13.000000000,2015-05-20 18:26:22.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-18 13:23:13.000000000', 'files': ['jenkins/jobs/kolla.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/65b1acddd394b769bcc91c42903f996e89523789', 'message': 'Increase Kolla build timeout by 30 minutes\n\nThe latest full build attempt was terminated at 90 minutes, so increase\nby 30 minutes. I personally am hopeful that once we get image building\nverification passing in the gate, we can start focusing on using a cache\nto speed up this process significantly.\n\nChange-Id: I9f8252133d460e5042ea88a67cf11546b2164a0d\n'}]",0,184051,65b1acddd394b769bcc91c42903f996e89523789,3,1,1,3098,,,0,"Increase Kolla build timeout by 30 minutes

The latest full build attempt was terminated at 90 minutes, so increase
by 30 minutes. I personally am hopeful that once we get image building
verification passing in the gate, we can start focusing on using a cache
to speed up this process significantly.

Change-Id: I9f8252133d460e5042ea88a67cf11546b2164a0d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/51/184051/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/kolla.yaml'],1,65b1acddd394b769bcc91c42903f996e89523789,, timeout: 120, timeout: 90,1,1
openstack%2Fec2-api~master~I90d370552f402f11b5971ad2a94a5144d437c95f,openstack/ec2-api,master,I90d370552f402f11b5971ad2a94a5144d437c95f,vpn (temporary),ABANDONED,2015-05-18 09:26:04.000000000,2015-05-20 18:26:16.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-05-18 09:26:04.000000000', 'files': ['ec2api/tests/unit/test_ec2utils.py', 'ec2api/api/cloud.py', 'ec2api/api/internet_gateway.py', 'ec2api/api/ec2utils.py', 'ec2api/api/route_table.py', 'ec2api/exception.py', 'ec2api/api/subnet.py', 'ec2api/api/common.py', 'ec2api/api/vpn_gateway.py', 'ec2api/api/vpnutils.py', 'ec2api/api/vpn_connection.py', 'ec2api/tests/unit/test_customer_gateway.py', 'ec2api/tests/unit/test_vpn_gateway.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/354b79c4f6b28da0fb5ec1d4e487078be67c213d', 'message': 'vpn (temporary)\n\nChange-Id: I90d370552f402f11b5971ad2a94a5144d437c95f\n'}]",0,184003,354b79c4f6b28da0fb5ec1d4e487078be67c213d,3,1,1,10224,,,0,"vpn (temporary)

Change-Id: I90d370552f402f11b5971ad2a94a5144d437c95f
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/03/184003/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/unit/test_ec2utils.py', 'ec2api/api/cloud.py', 'ec2api/api/internet_gateway.py', 'ec2api/api/ec2utils.py', 'ec2api/api/route_table.py', 'ec2api/exception.py', 'ec2api/api/subnet.py', 'ec2api/api/common.py', 'ec2api/api/vpn_gateway.py', 'ec2api/api/vpnutils.py', 'ec2api/api/vpn_connection.py', 'ec2api/tests/unit/test_customer_gateway.py', 'ec2api/tests/unit/test_vpn_gateway.py']",13,354b79c4f6b28da0fb5ec1d4e487078be67c213d,vpn, self.set_mock_db_items(self.DB_VPN_GATEWAY_1_DETACHED) do_check('IncorrectState') ,,656,16
openstack%2Fdevstack~master~I835e55bbafc7e0640987e6f3c8ee0c873f875ee0,openstack/devstack,master,I835e55bbafc7e0640987e6f3c8ee0c873f875ee0,Import xattr with sudo early on,MERGED,2015-05-05 22:16:53.000000000,2015-05-20 18:19:06.000000000,2015-05-06 02:16:47.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 9107}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-05-05 22:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1fcd5c9c24d5c239a02d74fb22b82fb03c4a656c', 'message': 'Import xattr with sudo early on\n\nxattr fails to import due to being unable to build cffi bindings unless\nit is imported as root beforehand.\n\nChange-Id: I835e55bbafc7e0640987e6f3c8ee0c873f875ee0\nCloses-Bug: #1451992\n'}, {'number': 2, 'created': '2015-05-05 23:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f8883b552748c51979af6c3decdc6628840a5b4c', 'message': 'Import xattr with sudo early on\n\nxattr fails to import due to being unable to build cffi bindings unless\nit is imported as root beforehand.\n\nChange-Id: I835e55bbafc7e0640987e6f3c8ee0c873f875ee0\nCloses-Bug: #1451992\n'}, {'number': 3, 'created': '2015-05-06 00:08:15.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/ee3d2a8ece24efe8ee8b0304c133574967eb60d3', 'message': 'Import xattr with sudo early on\n\nxattr fails to import due to being unable to build cffi bindings unless\nit is imported as root beforehand.\n\nDepends-On: I6a9d64277974933ae9b7bbe2a40b8a0eb0fa8c6a\n\nChange-Id: I835e55bbafc7e0640987e6f3c8ee0c873f875ee0\nCloses-Bug: #1451992'}]",1,180341,ee3d2a8ece24efe8ee8b0304c133574967eb60d3,18,6,3,10035,,,0,"Import xattr with sudo early on

xattr fails to import due to being unable to build cffi bindings unless
it is imported as root beforehand.

Depends-On: I6a9d64277974933ae9b7bbe2a40b8a0eb0fa8c6a

Change-Id: I835e55bbafc7e0640987e6f3c8ee0c873f875ee0
Closes-Bug: #1451992",git fetch https://review.opendev.org/openstack/devstack refs/changes/41/180341/2 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,1fcd5c9c24d5c239a02d74fb22b82fb03c4a656c,fix/xattr-cffi-fail," # Due to https://bugs.launchpad.net/swift/+bug/1451992 we have to import # this package with root once so the CFFI bindings can be built pip_install xattr sudo python -c ""import xattr""",,5,0
openstack%2Fnova-powervm~master~I2fe1e93b7039383889e56b809d5348ee2d5222a9,openstack/nova-powervm,master,I2fe1e93b7039383889e56b809d5348ee2d5222a9,SSP: Only consider this host's VIOSes,MERGED,2015-05-18 22:13:38.000000000,2015-05-20 18:09:58.000000000,2015-05-20 18:09:57.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 13883}, {'_account_id': 14070}]","[{'number': 1, 'created': '2015-05-18 22:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/cd5a482e7c4d7fb629ecdc5a6e32f581dcbac73d', 'message': ""SSP: get host_uuid from disk driver\n\nThe previous algorithm of parsing the LPAR's AssociatedManagedSystem to\nretrieve the UUID of the host was unnecessarily complex.  This change\nset simply uses the self.host_uuid available from the disk driver.\n\nChange-Id: I2fe1e93b7039383889e56b809d5348ee2d5222a9\n""}, {'number': 2, 'created': '2015-05-19 21:32:59.000000000', 'files': ['nova_powervm/tests/virt/powervm/disk/test_ssp.py', 'nova_powervm/tests/virt/powervm/data/fake_cluster.txt', 'nova_powervm/virt/powervm/disk/ssp.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/8ee482c82a32d173a88891c6d15b84469d464c3d', 'message': ""SSP: Only consider this host's VIOSes\n\nPreviously, the SSP disk driver was gleaning the list of VIOS UUIDs from\nthe list of Nodes in the Cluster, and optionally restricting that list\nto VIOSes from a specified host.\n\nIt will almost never be useful to know about VIOSes residing on a\ndifferent host.  Any attempt to talk to those VIOSes through the PowerVM\nAPI will fail, as we don't have a pypowervm connection to that host.\n\nTherefore this change set simplifies the retrieval of VIOS UUIDs,\neliminating the host_uuid option and restricting the result to VIOSes on\nthe current host.\n\nChange-Id: I2fe1e93b7039383889e56b809d5348ee2d5222a9\n""}]",0,184140,8ee482c82a32d173a88891c6d15b84469d464c3d,11,5,2,14070,,,0,"SSP: Only consider this host's VIOSes

Previously, the SSP disk driver was gleaning the list of VIOS UUIDs from
the list of Nodes in the Cluster, and optionally restricting that list
to VIOSes from a specified host.

It will almost never be useful to know about VIOSes residing on a
different host.  Any attempt to talk to those VIOSes through the PowerVM
API will fail, as we don't have a pypowervm connection to that host.

Therefore this change set simplifies the retrieval of VIOS UUIDs,
eliminating the host_uuid option and restricting the result to VIOSes on
the current host.

Change-Id: I2fe1e93b7039383889e56b809d5348ee2d5222a9
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/40/184140/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/tests/virt/powervm/disk/test_ssp.py', 'nova_powervm/virt/powervm/disk/ssp.py']",2,cd5a482e7c4d7fb629ecdc5a6e32f581dcbac73d,ssp_host_uuid," lpar_id = vm.get_vm_id(self.adapter, lpar_uuid) for vios_uuid in self._vios_uuids(host_uuid=self.host_uuid): # The LPAR's host has to be self.host_uuid, else the PowerVM API will # fail. for vios_uuid in self._vios_uuids(host_uuid=self.host_uuid): tsk_map.add_vscsi_mapping(self.host_uuid, vios_uuid, lpar_uuid, lu)"," lpar_qps = vm.get_vm_qp(self.adapter, lpar_uuid) lpar_id = lpar_qps['PartitionID'] host_uuid = pvm_u.get_req_path_uuid( lpar_qps['AssociatedManagedSystem'], preserve_case=True) for vios_uuid in self._vios_uuids(host_uuid=host_uuid): # Note that the LPAR's host is likely to be the same as self.host_uuid, # but this is safer. host_href = vm.get_vm_qp(self.adapter, lpar_uuid, 'AssociatedManagedSystem') host_uuid = pvm_u.get_req_path_uuid(host_href, preserve_case=True) for vios_uuid in self._vios_uuids(host_uuid=host_uuid): tsk_map.add_vscsi_mapping(host_uuid, vios_uuid, lpar_uuid, lu)",13,25
openstack%2Fpython-mistralclient~master~I97b15a1b9f41f98f5928f8bda4769957a37678d2,openstack/python-mistralclient,master,I97b15a1b9f41f98f5928f8bda4769957a37678d2,Mistral bash completion script optimization,MERGED,2015-05-18 03:26:07.000000000,2015-05-20 18:08:09.000000000,2015-05-20 18:08:09.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2015-05-18 03:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/ddd8c8195d63b010d10dc9437774d72ed0150f52', 'message': ""Mistral bash completion script optimization\n\nMake bash completion script generated automatically by using  'mistral\nbash-completion' commands\n\nPartially Implements: blueprint bash-completion-script-optimization\n\nChange-Id: I97b15a1b9f41f98f5928f8bda4769957a37678d2\n""}, {'number': 2, 'created': '2015-05-18 04:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/05d71c427b47d0319cdb5dbd37793e342aa27236', 'message': ""Mistral bash completion script optimization\n\nMake bash completion script generated automatically by using  'mistral\nbash-completion' commands\n\nPartially Implements: blueprint bash-completion-script-optimization\n\nChange-Id: I97b15a1b9f41f98f5928f8bda4769957a37678d2\n""}, {'number': 3, 'created': '2015-05-20 08:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/228ca0e0fa256e2bf13faba6e2c495dbafe1af5b', 'message': ""Mistral bash completion script optimization\n\nMake bash completion script generated automatically by using  'mistral\nbash-completion' commands\n\nPartially Implements: blueprint bash-completion-script-optimization\n\nChange-Id: I97b15a1b9f41f98f5928f8bda4769957a37678d2\n""}, {'number': 4, 'created': '2015-05-20 13:34:58.000000000', 'files': ['mistralclient/tests/unit/v2/test_cli_bash_completion.py', 'tools/mistral.bash_completion'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/ad4f2b34b7be048872df8412536bed995de74da2', 'message': ""Mistral bash completion script optimization\n\nMake bash completion script generated automatically by using  'mistral\nbash-completion' commands\n\nAdd a unit test for 'bash-completion' command.\n\nPartially Implements: blueprint bash-completion-script-optimization\nChange-Id: I97b15a1b9f41f98f5928f8bda4769957a37678d2\n""}]",0,183968,ad4f2b34b7be048872df8412536bed995de74da2,16,5,4,6732,,,0,"Mistral bash completion script optimization

Make bash completion script generated automatically by using  'mistral
bash-completion' commands

Add a unit test for 'bash-completion' command.

Partially Implements: blueprint bash-completion-script-optimization
Change-Id: I97b15a1b9f41f98f5928f8bda4769957a37678d2
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/68/183968/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/mistral.bash_completion'],1,ddd8c8195d63b010d10dc9437774d72ed0150f52,bp/bash-completion-script-optimization,"_mistral_opts="""" # lazy init _mistral_flags="""" # lazy init _mistral_opts_exp="""" # lazy init local cur prev mbc cflags COMPREPLY=() cur=""${COMP_WORDS[COMP_CWORD]}"" prev=""${COMP_WORDS[COMP_CWORD-1]}"" if [ ""x$_mistral_opts"" == ""x"" ] ; then mbc=""`mistral bash-completion`"" _mistral_opts=""`echo ""$mbc"" | sed -e ""s/\s-[a-z0-9_-]*//g"" -e ""s/\s\s*/ /g""`"" _mistral_flags=""`echo "" $mbc"" | sed -e ""s/ [^-][^-][a-z0-9_-]*//g"" -e ""s/\s\s*/ /g""`"" _mistral_opts_exp=""`echo ""$_mistral_opts"" | sed -e ""s/\s/|/g""`"" fi if [[ "" ${COMP_WORDS[@]} "" =~ "" ""($_mistral_opts_exp)"" "" && ""$prev"" != ""help"" ]] ; then COMPREPLY=($(compgen -W ""${_mistral_flags}"" -- ${cur})) else COMPREPLY=($(compgen -W ""${_mistral_opts}"" -- ${cur})) fi return 0","#!/bin/bash declare -A SUBCOMMANDS declare -A OPTS OPTS[""action-execution-get""]=""-h --help -f --format -c --column --max-width --prefix"" OPTS[""action-execution-get-input""]=""-h --help"" OPTS[""action-execution-get-output""]=""-h --help"" OPTS[""action-execution-list""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""action-execution-update""]=""-h --help -f --format -c --column --max-width --prefix --state --output"" OPTS[""action-create""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""action-delete""]=""-h --help"" OPTS[""action-get""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""action-get-definition""]=""-h --help"" OPTS[""action-list""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""action-update""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""complete""]=""-h --help --name --shell"" OPTS[""cron-trigger-create""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""cron-trigger-delete""]=""-h --help"" OPTS[""cron-trigger-get""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""cron-trigger-list""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""environment-create""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""environment-delete""]=""-h --help"" OPTS[""environment-get""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""environment-list""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""environment-update""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""execution-create""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""execution-delete""]=""-h --help"" OPTS[""execution-get""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""execution-get-input""]=""-h --help"" OPTS[""execution-get-output""]=""-h --help"" OPTS[""execution-list""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""execution-update""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""help""]=""-h --help"" OPTS[""task-get""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""task-get-result""]=""-h --help"" OPTS[""task-get-published""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""task-list""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""workbook-create""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""workbook-delete""]=""-h --help"" OPTS[""workbook-get""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""workbook-get-definition""]=""-h --help"" OPTS[""workbook-list""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""workbook-update""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""workbook-validate""]=""-h --help -f --format -c --column --max-width --prefix"" OPTS[""workflow-create""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""workflow-delete""]=""-h --help"" OPTS[""workflow-get""]=""-h --help -f --format -c --column --max-width --variable --prefix"" OPTS[""workflow-get-definition""]=""-h --help"" OPTS[""workflow-list""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""workflow-update""]=""-h --help -f --format -c --column --max-width --quote"" OPTS[""workflow-validate""]=""-h --help -f --format -c --column --max-width --prefix"" COMMANDS=""${!OPTS[*]}"" COMPREPLY=() local cur=""${COMP_WORDS[COMP_CWORD]}"" local prev=""${COMP_WORDS[COMP_CWORD-1]}"" if [[ $cur =~ (\.|\~|\/).* ]] ; then _filedir elif [ $COMP_CWORD == ""1"" ] ; then COMPREPLY=($(compgen -W ""$COMMANDS"" -- ${cur})) elif [ $COMP_CWORD == ""2"" ] ; then COMPREPLY=($(compgen -W ""${OPTS[${prev}]}"" -- ${cur})) fi return 0",19,65
openstack%2Fmistral~master~Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6,openstack/mistral,master,Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6,Fix devstack back to rabbit,MERGED,2014-09-26 07:56:52.000000000,2015-05-20 18:07:06.000000000,2015-05-20 18:07:05.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7700}, {'_account_id': 8358}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-09-26 07:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ac452479533388e1b3999b53855fcac0d189f802', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 2, 'created': '2014-09-26 09:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d8082b61a59bf710bff70318cceb1e1578c95e0d', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 3, 'created': '2014-10-22 10:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4690303af26c39ae3cd54d624b94b714d1ce879b', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 4, 'created': '2014-10-22 10:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/5123b6334e4f7b1be8b3ceaa5a20d52d8d6880c7', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 5, 'created': '2014-10-22 11:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/a10915b4633b7b1d86c1dea66aa3e2786c674de6', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 6, 'created': '2014-10-22 12:18:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/0801b6cf69080930a0603d02936a3c7c1296e75f', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 7, 'created': '2014-10-22 12:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/246506effbff1baa96780ad683e9fbf8ad9b0d52', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 8, 'created': '2015-04-09 13:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/90072395fcb08c8dc0f4ae6a4b39d1cf061f690a', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 9, 'created': '2015-04-10 09:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f322bda76f1ee5920f38b1740c7d1f1ddb0dbbef', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 10, 'created': '2015-04-10 09:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1f0839354b9a1e9d9f8cc67f5bff87be1063c823', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 11, 'created': '2015-04-10 13:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ec7c791431072f1a41be02c9577dbeda221c6667', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 12, 'created': '2015-04-13 10:08:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/31622420c7892252f7f836ad2c5a0ca773c91ec6', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 13, 'created': '2015-04-13 10:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/81c5c2cebb8e9f4da865e60b00ccef2ea1329187', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 14, 'created': '2015-04-13 11:08:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/dbd35b4e5817c50eae8abed7a7d25d4c89ba608a', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 15, 'created': '2015-04-13 12:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/882db106a59475ec1a3971dd8ed3248a433331a6', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 16, 'created': '2015-05-19 09:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c238adf527f7c143e30f78fe4e27ba60b136cdb6', 'message': 'Fix devstack back to rabbit\n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n'}, {'number': 17, 'created': '2015-05-20 08:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/33ec9a516114c69628e32377bbf5d8d91ba6c69c', 'message': ""Fix devstack back to rabbit\n\nFound the root of the problem: \n  Heat-engine uses queue 'engine' in rabbit, therefore we\n  need to rename our queue in order to increase uniqueness \n\nFixes-bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n""}, {'number': 18, 'created': '2015-05-20 08:39:38.000000000', 'files': ['contrib/devstack/lib/mistral', 'etc/mistral.conf.sample', 'mistral/config.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/7499f55a2678af3fc3ad7c6391699bdc9ec15ed8', 'message': ""Fix devstack back to rabbit\n\nFound the root of the problem: \n  Heat-engine uses queue 'engine' in rabbit, therefore we\n  need to rename our queue in order to increase uniqueness \n\nCloses-Bug: #1324967\n\nChange-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6\n""}]",0,124321,7499f55a2678af3fc3ad7c6391699bdc9ec15ed8,51,7,18,7700,,,0,"Fix devstack back to rabbit

Found the root of the problem: 
  Heat-engine uses queue 'engine' in rabbit, therefore we
  need to rename our queue in order to increase uniqueness 

Closes-Bug: #1324967

Change-Id: Iaf8a8f9f0357ae15ee4fc47d0031572a162526e6
",git fetch https://review.opendev.org/openstack/mistral refs/changes/21/124321/2 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/mistral'],1,ac452479533388e1b3999b53855fcac0d189f802,bug/1324967, iniset $MISTRAL_CONF_FILE DEFAULT rpc_backend rabbit, iniset $MISTRAL_CONF_FILE DEFAULT rpc_backend fake,1,1
openstack%2Fpython-mistralclient~master~Id0e52daf4ee3f7c1ba9fefaa4f103bd74e66d97d,openstack/python-mistralclient,master,Id0e52daf4ee3f7c1ba9fefaa4f103bd74e66d97d,Add bash-completion command support,MERGED,2015-05-18 03:26:07.000000000,2015-05-20 17:54:55.000000000,2015-05-20 17:54:53.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2015-05-18 03:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/62710d556147e13d579f1697635c62e5deeed3d8', 'message': ""Add bash-completion command support\n\nImplement a helper command 'mistral bash-completion' to generate available\ncommands and options supported by mistral.\n\nChange-Id: Id0e52daf4ee3f7c1ba9fefaa4f103bd74e66d97d\nPartically Implements: blueprint bash-completion-script-optimization\n""}, {'number': 2, 'created': '2015-05-18 04:03:11.000000000', 'files': ['mistralclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/1e79ff547171d32dc6ff585a5c704bb7f0809bc7', 'message': ""Add bash-completion command support\n\nImplement a helper command 'mistral bash-completion' to generate available\ncommands and options supported by mistral.\n\nChange-Id: Id0e52daf4ee3f7c1ba9fefaa4f103bd74e66d97d\nPartically Implements: blueprint bash-completion-script-optimization\n""}]",0,183967,1e79ff547171d32dc6ff585a5c704bb7f0809bc7,11,6,2,6732,,,0,"Add bash-completion command support

Implement a helper command 'mistral bash-completion' to generate available
commands and options supported by mistral.

Change-Id: Id0e52daf4ee3f7c1ba9fefaa4f103bd74e66d97d
Partically Implements: blueprint bash-completion-script-optimization
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/67/183967/2 && git format-patch -1 --stdout FETCH_HEAD,['mistralclient/shell.py'],1,62710d556147e13d579f1697635c62e5deeed3d8,bp/bash-completion-script-optimization,"from cliff import commandclass BashCompletionCommand(command.Command): """"""Prints all of the commands and options for bash-completion."""""" def take_action(self, parsed_args): commands = set() options = set() for option, _action in self.app.parser._option_string_actions.items(): options.add(option) for command_name, command in self.app.command_manager: commands.add(command_name) print(' '.join(commands | options)) 'bash-completion': BashCompletionCommand,",,18,0
openstack%2Fpython-muranoclient~master~I322c27a5733b4100a2b340cb8480e963e9da022d,openstack/python-muranoclient,master,I322c27a5733b4100a2b340cb8480e963e9da022d,[DO NOT MERGE] CI test,ABANDONED,2015-05-20 17:13:11.000000000,2015-05-20 17:38:00.000000000,,"[{'_account_id': 7821}, {'_account_id': 13752}]","[{'number': 1, 'created': '2015-05-20 17:13:11.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/1cbc439d2841f410e793ffb6d7359ba2f98dca16', 'message': '[DO NOT MERGE] CI test\n\nChange-Id: I322c27a5733b4100a2b340cb8480e963e9da022d\n'}]",0,184551,1cbc439d2841f410e793ffb6d7359ba2f98dca16,7,2,1,13752,,,0,"[DO NOT MERGE] CI test

Change-Id: I322c27a5733b4100a2b340cb8480e963e9da022d
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/51/184551/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,1cbc439d2841f410e793ffb6d7359ba2f98dca16,,,,0,0
openstack%2Fapi-sig~master~I5485970686e352d5146bcfe2a3cf53388b929b04,openstack/api-sig,master,I5485970686e352d5146bcfe2a3cf53388b929b04,Adding guideline for evaluating api changes,MERGED,2015-05-06 16:24:34.000000000,2015-05-20 17:37:39.000000000,2015-05-20 17:37:37.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 964}, {'_account_id': 970}, {'_account_id': 1112}, {'_account_id': 2750}, {'_account_id': 10670}, {'_account_id': 11564}, {'_account_id': 12000}, {'_account_id': 12321}, {'_account_id': 12606}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-05-06 16:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-sig/commit/57a42e5159e966983caaea0384293376ced37007', 'message': 'Adding guideline for evaluating api changes\n\nThis change converts the wiki page for evaluating api changes[1] into a\nguideline. The content of the page has been kept largely the same aside\nfrom a few grammar and consistency changes. One example has been removed\nas the link to the bug and review had been abandoned. The questions have\nalso been removed as these seemed out of place for a guideline.\n\n[1]: https://wiki.openstack.org/wiki/APIChangeGuidelines\n\nChange-Id: I5485970686e352d5146bcfe2a3cf53388b929b04\n'}, {'number': 2, 'created': '2015-05-12 16:29:50.000000000', 'files': ['guidelines/evaluating_api_changes.rst'], 'web_link': 'https://opendev.org/openstack/api-sig/commit/9d76e6eb6fe8cc756ef0a6c5097f1651e1b98572', 'message': 'Adding guideline for evaluating api changes\n\nThis change converts the wiki page for evaluating api changes[1] into a\nguideline. The content of the page has been kept largely the same aside\nfrom a few grammar and consistency changes. One example has been removed\nas the link to the bug and review had been abandoned. The questions have\nalso been removed as these seemed out of place for a guideline.\n\n[1]: https://wiki.openstack.org/wiki/APIChangeGuidelines\n\nChange-Id: I5485970686e352d5146bcfe2a3cf53388b929b04\n'}]",27,180612,9d76e6eb6fe8cc756ef0a6c5097f1651e1b98572,29,12,2,10670,,,0,"Adding guideline for evaluating api changes

This change converts the wiki page for evaluating api changes[1] into a
guideline. The content of the page has been kept largely the same aside
from a few grammar and consistency changes. One example has been removed
as the link to the bug and review had been abandoned. The questions have
also been removed as these seemed out of place for a guideline.

[1]: https://wiki.openstack.org/wiki/APIChangeGuidelines

Change-Id: I5485970686e352d5146bcfe2a3cf53388b929b04
",git fetch https://review.opendev.org/openstack/api-sig refs/changes/12/180612/1 && git format-patch -1 --stdout FETCH_HEAD,['guidelines/evaluating_api_changes.rst'],1,57a42e5159e966983caaea0384293376ced37007,eval_api_changes,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================== Evaluating API Changes ====================== This guideline provides help to developers, core reviewers, and QA engineers on evaluating whether a given API-impacting change is acceptable with respect to the OpenStack governance policy on API stability[1]. Guidance ======== The following types of changes are generally considered acceptable: * The change is the only way to fix a security bug. * Fixing a bug so that a request which resulted in an error response before is now successful. * Adding a new response header. * Changing an error response code to be more accurate. The following types of changes are acceptable when conditionally added as a new API extension: * Adding a property to a resource representation. * Adding an optional property to a resource representation which may be supplied by clients, assuming the API previously would ignore this property. The following types of changes are generally **not** considered acceptable: * A change such that a request which was successful before now results in an error response (unless the success reported previously was hiding an existing error condition). * Changing or removing a property in a resource representation. * Changing the semantics of a property in a resource representation which may be supplied by clients. * Changing or removing a response header. * Changing which response code is returned on success. You may feel a particular case is special and warrants an incompatible API change. Please consider these responses to commonly used justifications: *""The change is needed to improve API consistency.""* Your desire to improve API consistency is appreciated, but all APIs have warts. Inconsistencies that need breaking changes can be fixed in a new API version. Please find a way to channel your efforts into preparations to fix these consistencies in the next API version. *""It is unlikely that any existing users of the API would be affected.""* It is difficult to predict how people are using the APIs. Developers do the strangest things. As our APIs become more adopted over time, it will only become more futile to attempt to make such predictions. One thing you can do is to help improve our documentation about how our APIs should be used. If we can document in future versions that we do not make guarantees about certain behaviours, that may give us some small additional leeway when it comes to making changes. *""The existing API is not well documented.""* If an API's behavior isn't adequately documented, then developers using the API have no choice but to go by what they observe the behavior to be. *""The change does not impact users of OpenStack's client libraries or command line interfaces.""* We encourage developers to develop against OpenStack REST API. There will be many tools and applications which favor the REST API over our libraries or command line interfaces. Examples ======== **Failing silently** At one point the change password nova API would return success even if the system was unable to do it. This made sense to fix because any client checking the response code of this request surely wants to know if the request failed. Any existing client which this change affects was broken anyway because it was failing to actually change the admin password. * Launchpad bug - `[novaclient] root-password fails and does not return error <https://bugs.launchpad.net/nova/+bug/1038227>`_ **Out of spec features belong in extensions** The ``config_drive`` attribute on servers is not part of the 1.1 Compute API spec, so it was moved into an extension which could be disabled. * Launchpad bug - `OSAPI v1.1 needs to document config-drive as an extension <https://bugs.launchpad.net/nova/+bug/833331>`_ **Adding new header OK; changing response code not so much** Rather than returning ""200 OK"" for successful volume creation, we should return ""201 Created"" and include a ``Location`` header. It was decided that it is safe to add the ``Location`` header, but not change the response code. * Launchpad bug - `Volume creation 201 API response does not include a Location header <https://bugs.launchpad.net/nova/+bug/1026600>`_ **Inappropriate extension** Sometimes you come across an extension that makes no sense and is highly unlikely to be used by anyone. * Launchpad blueprint - `Deprecate CreateServerExt extension <https://blueprints.launchpad.net/nova/+spec/deprecate-createserverext>`_ **Bugfixes OK** Fixing incorrect counting of hosts in instance usage audit log. * Launchpad bug - `Instance usage audit log extension miscounts hosts <https://bugs.launchpad.net/nova/+bug/1030106>`_ **Extension aliases** * Gerrit review - `Make extension aliases consistent <https://review.openstack.org/#/c/10812/>`_ **500 error** * Launchpad bug - `Server create with malformed body yields a 500 error <https://bugs.launchpad.net/nova/+bug/1035120>`_ * Launchpad bug - `malformed server update causes: KeyError: 'server' <https://bugs.launchpad.net/nova/+bug/1038227>`_ **Inconsistent handling of volume attach device** * Gerrit review - `Allow nova to guess device if not passed to attach <https://review.openstack.org/#/c/10908/>`_ **Missing Property From XML Representation** * Launchpad bug - `hypervisor_hostname in extended server status doesn't appear in xml <https://bugs.launchpad.net/nova/+bug/1039276>`_ References ========== [1]: https://wiki.openstack.org/wiki/Governance/Approved/APIStability Mailing list discussion, ""Standardizing status codes in the native API (July 2012)"". http://lists.openstack.org/pipermail/openstack-dev/2012-July/thread.html#132 ",,151,0
openstack%2Fnova~master~Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb,openstack/nova,master,Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb,Detach volume after deleting instance with no host,MERGED,2015-01-08 10:25:16.000000000,2015-05-20 17:36:22.000000000,2015-05-16 05:03:43.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1011}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 8213}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10224}, {'_account_id': 10385}, {'_account_id': 10485}, {'_account_id': 11103}, {'_account_id': 11214}, {'_account_id': 11530}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15888}]","[{'number': 1, 'created': '2015-01-08 10:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2868a0c92e8a3e5f85c2bfd525508821e46ee11', 'message': 'Detach volume after deleting the instance\n\nIf an instance is booted from volume and goes in to error state due to\nsome reason. Volume from which instance is booted, remains in-use state\neven the instance is deleted because instance has no host associated\nwith it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin error state and has no host associated with it.\n\nCloses-Bug: #1404867\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 2, 'created': '2015-01-21 06:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3246048080f62e92b75a7fac2e0790819c88141f', 'message': 'Detach volume after deleting the instance\n\nIf an instance is booted from volume and goes in to error state due to\nsome reason. Volume from which instance is booted, remains in-use state\neven the instance is deleted because instance has no host associated\nwith it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin error state and has no host associated with it.\n\nCloses-Bug: #1404867\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 3, 'created': '2015-01-23 08:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27d3438c870cb8519145d6210c1ff7a0c21a5e7e', 'message': 'Detach volume after deleting the instance\n\nIf an instance is booted from volume and goes in to error state due to\nsome reason. Volume from which instance is booted, remains in-use state\neven the instance is deleted because instance has no host associated\nwith it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin error state and has no host associated with it.\n\nCloses-Bug: #1404867\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 4, 'created': '2015-02-13 10:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/af1c9ae095e7250d86e634c1994b01ef39293b6a', 'message': 'Detach volume after deleting the instance\n\nIf an instance is booted from volume and goes in to error state due to\nsome reason. Volume from which instance is booted, remains in-use state\neven the instance is deleted because instance has no host associated\nwith it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin error state and has no host associated with it.\n\nCloses-Bug: #1404867\nCloses-Bug: #1408527\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 5, 'created': '2015-03-11 14:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/119a8424afd2aeebe2645b5ed70417c646ad5ffb', 'message': 'Detach volume after deleting the instance\n\nIf an instance is booted from volume and goes in to error state due to\nsome reason. Volume from which instance is booted, remains in-use state\neven the instance is deleted because instance has no host associated\nwith it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin error state and has no host associated with it. This will cleanup\nboth volumes and the networks.\n\nCloses-Bug: #1404867\nCloses-Bug: #1408527\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 6, 'created': '2015-03-12 07:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e5651b6538e03577b73c2662a0b093959b08a92d', 'message': 'Detach volume after deleting the instance\n\nIf an instance is booted from volume and goes in to error state due to\nsome reason. Volume from which instance is booted, remains in-use state\neven the instance is deleted because instance has no host associated\nwith it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin error state and has no host associated with it. This will cleanup\nboth volumes and the networks.\n\nCloses-Bug: #1404867\nCloses-Bug: #1408527\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 7, 'created': '2015-03-18 06:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2cfa2fe52339b4eda66b6e5d097b7b221091c7c', 'message': 'Detach volume after deleting the instance\n\nIf an instance is booted from volume and goes in to error state due to\nsome reason. Volume from which instance is booted, remains in-use state\neven the instance is deleted because instance has no host associated\nwith it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin error state and has no host associated with it. This will cleanup\nboth volumes and the networks.\n\nCloses-Bug: #1404867\nCloses-Bug: #1408527\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 8, 'created': '2015-04-03 07:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70af464776ab794c379e1f2d08293c08973c71fc', 'message': 'Detach volume after deleting the instance\n\nIf an instance is booted from volume and goes in to error state due to\nsome reason. Volume from which instance is booted, remains in-use state\neven the instance is deleted because instance has no host associated\nwith it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin error state and has no host associated with it. This will cleanup\nboth volumes and the networks.\n\nCurrently in test_servers.py, ""test_delete_server_instance"" executes\nsimilar to ""test_delete_server_instance_while_building"". This is because\n""test_delete_server_instance"" calls instance.save() method which updates\nvm_state to building where it should be in active state.\n\nFixed ""test_delete_server_instance"" to test deleting an instance which\nis in active state and has a valid host.\n\nCloses-Bug: #1404867\nCloses-Bug: #1408527\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 9, 'created': '2015-04-16 10:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f71562245ba288ceb14879dc0da8533bd52c32d0', 'message': 'Detach volume after deleting the instance\n\nIf an instance is booted from volume and goes in to error state due to\nsome reason. Volume from which instance is booted, remains in-use state\neven the instance is deleted because instance has no host associated\nwith it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin error state and has no host associated with it. This will cleanup\nboth volumes and the networks.\n\nCurrently in test_servers.py, ""test_delete_server_instance"" executes\nsimilar to ""test_delete_server_instance_while_building"". This is because\n""test_delete_server_instance"" calls instance.save() method which updates\nvm_state to building where it should be in active state.\n\nFixed ""test_delete_server_instance"" to test deleting an instance which\nis in active state and has a valid host.\n\nCloses-Bug: #1404867\nCloses-Bug: #1408527\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 10, 'created': '2015-04-17 06:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7d5cf8c81b8200a85fa517a0b820558ccc7052a', 'message': 'Detach volume after deleting the instance\n\nIf an instance is booted from volume and goes in to error state due to\nsome reason. Volume from which instance is booted, remains in-use state\neven the instance is deleted because instance has no host associated\nwith it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin error state and has no host associated with it. This will cleanup\nboth volumes and the networks.\n\nCurrently in test_servers.py, ""test_delete_server_instance"" executes\nsimilar to ""test_delete_server_instance_while_building"". This is because\n""test_delete_server_instance"" calls instance.save() method which updates\nvm_state to building where it should be in active state.\n\nFixed ""test_delete_server_instance"" to test deleting an instance which\nis in active state and has a valid host.\n\nCloses-Bug: #1404867\nCloses-Bug: #1408527\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 11, 'created': '2015-04-21 09:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a34fd26866de4463752b87da41f7f8cb72985cd4', 'message': 'Detach volume after deleting the instance\n\nIf an instance is booted from volume and goes in to error state due to\nsome reason. Volume from which instance is booted, remains in-use state\neven the instance is deleted because instance has no host associated\nwith it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin shelved_offloaded state or has no host associated with it. This will\ncleanup both volumes and the networks.\n\nCurrently in test_servers.py, ""test_delete_server_instance"" executes\nsimilar to ""test_delete_server_instance_while_building"". This is because\n""test_delete_server_instance"" calls instance.save() method which updates\nvm_state to building where it should be in active state.\n\nFixed ""test_delete_server_instance"" to test deleting an instance which\nis in active state and has a valid host.\n\nCloses-Bug: #1404867\nCloses-Bug: #1408527\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 12, 'created': '2015-05-07 07:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cac90efa74fa357a15ca97ed7d412a6d3a4a7e70', 'message': 'Detach volume after deleting instance with no host\n\nIf an instance is booted from a volume, shelved, and goes into an error\nstate due to some reason. Volume from which instance is booted, remains\nin-use state even the instance is deleted because instance has no host\nassociated with it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin shelved_offloaded state or has no host associated with it. This will\ncleanup both volumes and the networks.\n\nCurrently in test_servers.py, ""test_delete_server_instance"" executes\nsimilar to ""test_delete_server_instance_while_building"". This is because\n""test_delete_server_instance"" calls instance.save() method which updates\nvm_state to building where it should be in active state.\n\nFixed ""test_delete_server_instance"" to test deleting an instance which\nis in active state and has a valid host.\n\nCloses-Bug: #1404867\nCloses-Bug: #1408527\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 13, 'created': '2015-05-08 06:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb19e6d4150e33927d6f1df15fef6236715d2f1c', 'message': 'Detach volume after deleting instance with no host\n\nIf an instance is booted from a volume, shelved, and goes into an error\nstate due to some reason. Volume from which instance is booted, remains\nin-use state even the instance is deleted because instance has no host\nassociated with it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin shelved_offloaded state or has no host associated with it. This will\ncleanup both volumes and the networks.\n\nCurrently in test_servers.py, ""test_delete_server_instance"" executes\nsimilar to ""test_delete_server_instance_while_building"". This is because\n""test_delete_server_instance"" calls instance.save() method which updates\nvm_state to building where it should be in active state.\n\nFixed ""test_delete_server_instance"" to test deleting an instance which\nis in active state and has a valid host.\n\nCloses-Bug: #1404867\nCloses-Bug: #1408527\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}, {'number': 14, 'created': '2015-05-11 21:12:49.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/api/openstack/compute/plugins/v3/test_servers.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/compute/test_servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d1baa9fe7eb342b63fc85cbb5ef70bb676de6566', 'message': 'Detach volume after deleting instance with no host\n\nIf an instance is booted from a volume, shelved, and goes into an error\nstate due to some reason. Volume from which instance is booted, remains\nin-use state even the instance is deleted because instance has no host\nassociated with it.\n\nCalled _local_delete() to detach volume and destroy bdm if instance is\nin shelved_offloaded state or has no host associated with it. This will\ncleanup both volumes and the networks.\n\nCurrently in test_servers.py, ""test_delete_server_instance"" executes\nsimilar to ""test_delete_server_instance_while_building"". This is because\n""test_delete_server_instance"" calls instance.save() method which updates\nvm_state to building where it should be in active state.\n\nFixed ""test_delete_server_instance"" to test deleting an instance which\nis in active state and has a valid host.\n\nCloses-Bug: #1404867\nCloses-Bug: #1408527\nChange-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb\n'}]",51,145738,d1baa9fe7eb342b63fc85cbb5ef70bb676de6566,241,30,14,10485,,,0,"Detach volume after deleting instance with no host

If an instance is booted from a volume, shelved, and goes into an error
state due to some reason. Volume from which instance is booted, remains
in-use state even the instance is deleted because instance has no host
associated with it.

Called _local_delete() to detach volume and destroy bdm if instance is
in shelved_offloaded state or has no host associated with it. This will
cleanup both volumes and the networks.

Currently in test_servers.py, ""test_delete_server_instance"" executes
similar to ""test_delete_server_instance_while_building"". This is because
""test_delete_server_instance"" calls instance.save() method which updates
vm_state to building where it should be in active state.

Fixed ""test_delete_server_instance"" to test deleting an instance which
is in active state and has a valid host.

Closes-Bug: #1404867
Closes-Bug: #1408527
Change-Id: Ic630ae7d026a9697afec46ac9ea40aea0f5b5ffb
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/145738/14 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/api/openstack/compute/plugins/v3/test_servers.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/compute/test_servers.py', 'nova/compute/api.py']",5,f2868a0c92e8a3e5f85c2bfd525508821e46ee11,bug/1404867," if (not instance.vm_state == vm_states.SHELVED_OFFLOADED and instance.host): # isn't up or if instance's vm_state is 'error' and # instance.host is None, delete instance from db and clean # bdms info and network info"," shelved_offloaded = (instance.vm_state == vm_states.SHELVED_OFFLOADED) if not instance.host and not shelved_offloaded: try: compute_utils.notify_about_instance_usage( self.notifier, context, instance, ""%s.start"" % delete_type) instance.destroy() compute_utils.notify_about_instance_usage( self.notifier, context, instance, ""%s.end"" % delete_type, system_metadata=instance.system_metadata) quotas.commit() return except exception.ObjectActionError: instance.refresh() if not shelved_offloaded: # isn't up, delete instance from db and clean bdms info and # network info",106,64
openstack%2Fbarbican~master~I4e4a1576f217f8443b9af8ff359de6e9b0f1c42b,openstack/barbican,master,I4e4a1576f217f8443b9af8ff359de6e9b0f1c42b,Splitting out PKCS11 plugin,MERGED,2015-05-18 21:58:47.000000000,2015-05-20 17:30:09.000000000,2015-05-20 17:30:07.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7764}, {'_account_id': 9234}, {'_account_id': 11970}, {'_account_id': 16429}]","[{'number': 1, 'created': '2015-05-18 21:58:47.000000000', 'files': ['barbican/plugin/crypto/p11_crypto.py', 'barbican/tests/plugin/crypto/test_p11_crypto.py', 'barbican/plugin/crypto/pkcs11.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/4241f53aa5d1bdb44418e484db711a76019c71b8', 'message': 'Splitting out PKCS11 plugin\n\nPreemptively splitting the PKCS11 plugin before removing\nthe HMAC and MKEK generation from barbican. This will\nenable other scripts to use the PKCS11 interface without\nloading the plugin. The tests were updated to reflect this\nchange as well.\n\nChange-Id: I4e4a1576f217f8443b9af8ff359de6e9b0f1c42b\n'}]",4,184135,4241f53aa5d1bdb44418e484db711a76019c71b8,14,7,1,11970,,,0,"Splitting out PKCS11 plugin

Preemptively splitting the PKCS11 plugin before removing
the HMAC and MKEK generation from barbican. This will
enable other scripts to use the PKCS11 interface without
loading the plugin. The tests were updated to reflect this
change as well.

Change-Id: I4e4a1576f217f8443b9af8ff359de6e9b0f1c42b
",git fetch https://review.opendev.org/openstack/barbican refs/changes/35/184135/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/plugin/crypto/p11_crypto.py', 'barbican/tests/plugin/crypto/test_p11_crypto.py', 'barbican/plugin/crypto/pkcs11.py']",3,4241f53aa5d1bdb44418e484db711a76019c71b8,rngeezus,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import base64 import collections import textwrap import cffi from cryptography.hazmat.primitives import padding from barbican.common import exception from barbican.common import utils from barbican import i18n as u from barbican.openstack.common import jsonutils as json LOG = utils.getLogger(__name__) Attribute = collections.namedtuple(""Attribute"", [""type"", ""value""]) CKAttributes = collections.namedtuple(""CKAttributes"", [""template"", ""cffivals""]) CKMechanism = collections.namedtuple(""CKMechanism"", [""mech"", ""cffivals""]) CKR_OK = 0 CKF_RW_SESSION = (1 << 1) CKF_SERIAL_SESSION = (1 << 2) CKU_SO = 0 CKU_USER = 1 CKO_SECRET_KEY = 4 CKK_AES = 0x1f CKA_CLASS = 0 CKA_TOKEN = 1 CKA_PRIVATE = 2 CKA_LABEL = 3 CKA_APPLICATION = 0x10 CKA_VALUE = 0x11 CKA_OBJECT_ID = 0x12 CKA_CERTIFICATE_TYPE = 0x80 CKA_ISSUER = 0x81 CKA_SERIAL_NUMBER = 0x82 CKA_AC_ISSUER = 0x83 CKA_OWNER = 0x84 CKA_ATTR_TYPES = 0x85 CKA_TRUSTED = 0x86 CKA_CERTIFICATE_CATEGORY = 0x87 CKA_JAVA_MIDP_SECURITY_DOMAIN = 0x88 CKA_URL = 0x89 CKA_HASH_OF_SUBJECT_PUBLIC_KEY = 0x8a CKA_HASH_OF_ISSUER_PUBLIC_KEY = 0x8b CKA_CHECK_VALUE = 0x90 CKA_KEY_TYPE = 0x100 CKA_SUBJECT = 0x101 CKA_ID = 0x102 CKA_SENSITIVE = 0x103 CKA_ENCRYPT = 0x104 CKA_DECRYPT = 0x105 CKA_WRAP = 0x106 CKA_UNWRAP = 0x107 CKA_SIGN = 0x108 CKA_SIGN_RECOVER = 0x109 CKA_VERIFY = 0x10a CKA_VERIFY_RECOVER = 0x10b CKA_DERIVE = 0x10c CKA_START_DATE = 0x110 CKA_END_DATE = 0x111 CKA_MODULUS = 0x120 CKA_MODULUS_BITS = 0x121 CKA_PUBLIC_EXPONENT = 0x122 CKA_PRIVATE_EXPONENT = 0x123 CKA_PRIME_1 = 0x124 CKA_PRIME_2 = 0x125 CKA_EXPONENT_1 = 0x126 CKA_EXPONENT_2 = 0x127 CKA_COEFFICIENT = 0x128 CKA_PRIME = 0x130 CKA_SUBPRIME = 0x131 CKA_BASE = 0x132 CKA_PRIME_BITS = 0x133 CKA_SUB_PRIME_BITS = 0x134 CKA_VALUE_BITS = 0x160 CKA_VALUE_LEN = 0x161 CKA_EXTRACTABLE = 0x162 CKA_LOCAL = 0x163 CKA_NEVER_EXTRACTABLE = 0x164 CKA_ALWAYS_SENSITIVE = 0x165 CKA_KEY_GEN_MECHANISM = 0x166 CKA_MODIFIABLE = 0x170 CKA_ECDSA_PARAMS = 0x180 CKA_EC_PARAMS = 0x180 CKA_EC_POINT = 0x181 CKA_SECONDARY_AUTH = 0x200 CKA_AUTH_PIN_FLAGS = 0x201 CKA_ALWAYS_AUTHENTICATE = 0x202 CKA_WRAP_WITH_TRUSTED = 0x210 CKA_HW_FEATURE_TYPE = 0x300 CKA_RESET_ON_INIT = 0x301 CKA_HAS_RESET = 0x302 CKA_PIXEL_X = 0x400 CKA_PIXEL_Y = 0x401 CKA_RESOLUTION = 0x402 CKA_CHAR_ROWS = 0x403 CKA_CHAR_COLUMNS = 0x404 CKA_COLOR = 0x405 CKA_BITS_PER_PIXEL = 0x406 CKA_CHAR_SETS = 0x480 CKA_ENCODING_METHODS = 0x481 CKA_MIME_TYPES = 0x482 CKA_MECHANISM_TYPE = 0x500 CKA_REQUIRED_CMS_ATTRIBUTES = 0x501 CKA_DEFAULT_CMS_ATTRIBUTES = 0x502 CKA_SUPPORTED_CMS_ATTRIBUTES = 0x503 CKM_SHA256_HMAC = 0x251 CKM_AES_KEY_GEN = 0x1080 CKM_AES_CBC_PAD = 0x1085 CKM_AES_KEY_WRAP = 0x1090 VENDOR_SAFENET_CKM_AES_GCM = 0x8000011c ERROR_CODES = { 1: 'CKR_CANCEL', 2: 'CKR_HOST_MEMORY', 3: 'CKR_SLOT_ID_INVALID', 5: 'CKR_GENERAL_ERROR', 6: 'CKR_FUNCTION_FAILED', 7: 'CKR_ARGUMENTS_BAD', 8: 'CKR_NO_EVENT', 9: 'CKR_NEED_TO_CREATE_THREADS', 0xa: 'CKR_CANT_LOCK', 0x10: 'CKR_ATTRIBUTE_READ_ONLY', 0x11: 'CKR_ATTRIBUTE_SENSITIVE', 0x12: 'CKR_ATTRIBUTE_TYPE_INVALID', 0x13: 'CKR_ATTRIBUTE_VALUE_INVALID', 0x20: 'CKR_DATA_INVALID', 0x21: 'CKR_DATA_LEN_RANGE', 0x30: 'CKR_DEVICE_ERROR', 0x31: 'CKR_DEVICE_MEMORY', 0x32: 'CKR_DEVICE_REMOVED', 0x40: 'CKR_ENCRYPTED_DATA_INVALID', 0x41: 'CKR_ENCRYPTED_DATA_LEN_RANGE', 0x50: 'CKR_FUNCTION_CANCELED', 0x51: 'CKR_FUNCTION_NOT_PARALLEL', 0x54: 'CKR_FUNCTION_NOT_SUPPORTED', 0x60: 'CKR_KEY_HANDLE_INVALID', 0x62: 'CKR_KEY_SIZE_RANGE', 0x63: 'CKR_KEY_TYPE_INCONSISTENT', 0x64: 'CKR_KEY_NOT_NEEDED', 0x65: 'CKR_KEY_CHANGED', 0x66: 'CKR_KEY_NEEDED', 0x67: 'CKR_KEY_INDIGESTIBLE', 0x68: 'CKR_KEY_FUNCTION_NOT_PERMITTED', 0x69: 'CKR_KEY_NOT_WRAPPABLE', 0x6a: 'CKR_KEY_UNEXTRACTABLE', 0x70: 'CKR_MECHANISM_INVALID', 0x71: 'CKR_MECHANISM_PARAM_INVALID', 0x82: 'CKR_OBJECT_HANDLE_INVALID', 0x90: 'CKR_OPERATION_ACTIVE', 0x91: 'CKR_OPERATION_NOT_INITIALIZED', 0xa0: 'CKR_PIN_INCORRECT', 0xa1: 'CKR_PIN_INVALID', 0xa2: 'CKR_PIN_LEN_RANGE', 0xa3: 'CKR_PIN_EXPIRED', 0xa4: 'CKR_PIN_LOCKED', 0xb0: 'CKR_SESSION_CLOSED', 0xb1: 'CKR_SESSION_COUNT', 0xb3: 'CKR_SESSION_HANDLE_INVALID', 0xb4: 'CKR_SESSION_PARALLEL_NOT_SUPPORTED', 0xb5: 'CKR_SESSION_READ_ONLY', 0xb6: 'CKR_SESSION_EXISTS', 0xb7: 'CKR_SESSION_READ_ONLY_EXISTS', 0xb8: 'CKR_SESSION_READ_WRITE_SO_EXISTS', 0xc0: 'CKR_SIGNATURE_INVALID', 0xc1: 'CKR_SIGNATURE_LEN_RANGE', 0xd0: 'CKR_TEMPLATE_INCOMPLETE', 0xd1: 'CKR_TEMPLATE_INCONSISTENT', 0xe0: 'CKR_TOKEN_NOT_PRESENT', 0xe1: 'CKR_TOKEN_NOT_RECOGNIZED', 0xe2: 'CKR_TOKEN_WRITE_PROTECTED', 0xf0: 'CKR_UNWRAPPING_KEY_HANDLE_INVALID', 0xf1: 'CKR_UNWRAPPING_KEY_SIZE_RANGE', 0xf2: 'CKR_UNWRAPPING_KEY_TYPE_INCONSISTENT', 0x100: 'CKR_USER_ALREADY_LOGGED_IN', 0x101: 'CKR_USER_NOT_LOGGED_IN', 0x102: 'CKR_USER_PIN_NOT_INITIALIZED', 0x103: 'CKR_USER_TYPE_INVALID', 0x104: 'CKR_USER_ANOTHER_ALREADY_LOGGED_IN', 0x105: 'CKR_USER_TOO_MANY_TYPES', 0x110: 'CKR_WRAPPED_KEY_INVALID', 0x112: 'CKR_WRAPPED_KEY_LEN_RANGE', 0x113: 'CKR_WRAPPING_KEY_HANDLE_INVALID', 0x114: 'CKR_WRAPPING_KEY_SIZE_RANGE', 0x115: 'CKR_WRAPPING_KEY_TYPE_INCONSISTENT', 0x120: 'CKR_RANDOM_SEED_NOT_SUPPORTED', 0x121: 'CKR_RANDOM_NO_RNG', 0x130: 'CKR_DOMAIN_PARAMS_INVALID', 0x150: 'CKR_BUFFER_TOO_SMALL', 0x160: 'CKR_SAVED_STATE_INVALID', 0x170: 'CKR_INFORMATION_SENSITIVE', 0x180: 'CKR_STATE_UNSAVEABLE', 0x190: 'CKR_CRYPTOKI_NOT_INITIALIZED', 0x191: 'CKR_CRYPTOKI_ALREADY_INITIALIZED', 0x1a0: 'CKR_MUTEX_BAD', 0x1a1: 'CKR_MUTEX_NOT_LOCKED', 0x200: 'CKR_FUNCTION_REJECTED', 1 << 31: 'CKR_VENDOR_DEFINED' } def build_ffi(): ffi = cffi.FFI() ffi.cdef(textwrap.dedent("""""" typedef unsigned char CK_BYTE; typedef unsigned long CK_ULONG; typedef unsigned long CK_RV; typedef unsigned long CK_SESSION_HANDLE; typedef unsigned long CK_OBJECT_HANDLE; typedef unsigned long CK_SLOT_ID; typedef unsigned long CK_FLAGS; typedef unsigned long CK_USER_TYPE; typedef unsigned char * CK_UTF8CHAR_PTR; typedef ... *CK_NOTIFY; typedef unsigned long ck_attribute_type_t; struct ck_attribute { ck_attribute_type_t type; void *value; unsigned long value_len; }; typedef struct ck_attribute CK_ATTRIBUTE; typedef CK_ATTRIBUTE *CK_ATTRIBUTE_PTR; typedef unsigned long ck_mechanism_type_t; struct ck_mechanism { ck_mechanism_type_t mechanism; void *parameter; unsigned long parameter_len; }; typedef struct ck_mechanism CK_MECHANISM; typedef CK_MECHANISM *CK_MECHANISM_PTR; typedef CK_BYTE *CK_BYTE_PTR; typedef CK_ULONG *CK_ULONG_PTR; typedef struct CK_AES_GCM_PARAMS { char * pIv; unsigned long ulIvLen; unsigned long ulIvBits; char * pAAD; unsigned long ulAADLen; unsigned long ulTagBits; } CK_AES_GCM_PARAMS; """""")) # FUNCTIONS ffi.cdef(textwrap.dedent("""""" CK_RV C_Initialize(void *); CK_RV C_OpenSession(CK_SLOT_ID, CK_FLAGS, void *, CK_NOTIFY, CK_SESSION_HANDLE *); CK_RV C_CloseSession(CK_SESSION_HANDLE); CK_RV C_Login(CK_SESSION_HANDLE, CK_USER_TYPE, CK_UTF8CHAR_PTR, CK_ULONG); CK_RV C_FindObjectsInit(CK_SESSION_HANDLE, CK_ATTRIBUTE *, CK_ULONG); CK_RV C_FindObjects(CK_SESSION_HANDLE, CK_OBJECT_HANDLE *, CK_ULONG, CK_ULONG *); CK_RV C_FindObjectsFinal(CK_SESSION_HANDLE); CK_RV C_GenerateKey(CK_SESSION_HANDLE, CK_MECHANISM *, CK_ATTRIBUTE *, CK_ULONG, CK_OBJECT_HANDLE *); CK_RV C_UnwrapKey(CK_SESSION_HANDLE, CK_MECHANISM *, CK_OBJECT_HANDLE, CK_BYTE *, CK_ULONG, CK_ATTRIBUTE *, CK_ULONG, CK_OBJECT_HANDLE *); CK_RV C_WrapKey(CK_SESSION_HANDLE, CK_MECHANISM_PTR, CK_OBJECT_HANDLE, CK_OBJECT_HANDLE, CK_BYTE_PTR, CK_ULONG_PTR); CK_RV C_EncryptInit(CK_SESSION_HANDLE, CK_MECHANISM_PTR, CK_OBJECT_HANDLE); CK_RV C_Encrypt(CK_SESSION_HANDLE, CK_BYTE_PTR, CK_ULONG, CK_BYTE_PTR, CK_ULONG_PTR); CK_RV C_DecryptInit(CK_SESSION_HANDLE, CK_MECHANISM_PTR, CK_OBJECT_HANDLE); CK_RV C_Decrypt(CK_SESSION_HANDLE, CK_BYTE_PTR, CK_ULONG, CK_BYTE_PTR, CK_ULONG_PTR); CK_RV C_SignInit(CK_SESSION_HANDLE, CK_MECHANISM_PTR, CK_OBJECT_HANDLE); CK_RV C_Sign(CK_SESSION_HANDLE, CK_BYTE_PTR, CK_ULONG, CK_BYTE_PTR, CK_ULONG_PTR); CK_RV C_VerifyInit(CK_SESSION_HANDLE, CK_MECHANISM_PTR, CK_OBJECT_HANDLE); CK_RV C_Verify(CK_SESSION_HANDLE, CK_BYTE_PTR, CK_ULONG, CK_BYTE_PTR, CK_ULONG); CK_RV C_GenerateRandom(CK_SESSION_HANDLE, CK_BYTE_PTR, CK_ULONG); """""")) return ffi class P11CryptoPluginKeyException(exception.BarbicanException): message = u._(""More than one key found for label"") class P11CryptoPluginException(exception.BarbicanException): message = u._(""General exception"") class PKCS11(object): def __init__(self, library_path, mkek_label, mkek_length, hmac_label, login_passphrase, slot_id, ffi=None): self.ffi = build_ffi() if not ffi else ffi self.lib = self.ffi.dlopen(library_path) # TODO(reaperhulk): abstract this so alternate algorithms/vendors # are possible. self.algorithm = VENDOR_SAFENET_CKM_AES_GCM self.block_size = 16 # in bytes self.key_handles = {} self.login_passphrase = login_passphrase self.slot_id = slot_id self.check_error(self.lib.C_Initialize(self.ffi.NULL)) # Open session to perform self-test and get/generate mkek and hmac session = self.create_working_session() self.perform_rng_self_test(session) self.current_mkek_label = mkek_label self.current_hmac_label = hmac_label LOG.debug(""Current mkek label: %s"", self.current_mkek_label) LOG.debug(""Current hmac label: %s"", self.current_hmac_label) # cache current MKEK handle in the dictionary self.get_or_generate_mkek( self.current_mkek_label, mkek_length, session ) self.get_or_generate_hmac_key(self.current_hmac_label, session) # Clean up the active session self.close_session(session) def perform_rng_self_test(self, session): test_random = self.generate_random(100, session) if self.ffi.buffer(test_random, 100)[:] == b""\x00"" * 100: raise P11CryptoPluginException(""Apparent RNG self-test failure."") def open_session(self, slot): session_ptr = self.ffi.new(""CK_SESSION_HANDLE *"") rv = self.lib.C_OpenSession( slot, CKF_RW_SESSION | CKF_SERIAL_SESSION, self.ffi.NULL, self.ffi.NULL, session_ptr ) self.check_error(rv) session = session_ptr[0] return session def close_session(self, session): rv = self.lib.C_CloseSession(session) self.check_error(rv) def login(self, password, session): rv = self.lib.C_Login( session, CKU_USER, password, len(password) ) self.check_error(rv) def create_working_session(self): """"""Automatically opens a session and performs a login."""""" session = self.open_session(self.slot_id) self.login(self.login_passphrase, session) return session def check_error(self, value): if value != CKR_OK: raise P11CryptoPluginException(u._( ""HSM returned response code: {hex_value} {code}"").format( hex_value=hex(value), code=ERROR_CODES.get(value, 'CKR_????') ) ) def build_attributes(self, attrs): attributes = self.ffi.new(""CK_ATTRIBUTE[{0}]"".format(len(attrs))) val_list = [] for index, attr in enumerate(attrs): attributes[index].type = attr.type if isinstance(attr.value, bool): if attr.value: val_list.append(self.ffi.new(""unsigned char *"", 1)) else: val_list.append(self.ffi.new(""unsigned char *"", 0)) attributes[index].value_len = 1 # sizeof(char) is 1 elif isinstance(attr.value, int): # second because bools are also considered ints val_list.append(self.ffi.new(""CK_ULONG *"", attr.value)) attributes[index].value_len = 8 elif isinstance(attr.value, str): val_list.append(self.ffi.new(""char []"", attr.value)) attributes[index].value_len = len(attr.value) else: raise TypeError(""Unknown attribute type provided."") attributes[index].value = val_list[-1] return CKAttributes(attributes, val_list) def get_or_generate_mkek(self, mkek_label, mkek_length, session): mkek = self.get_key_handle(mkek_label, session) if not mkek: # Generate a key that is persistent and not extractable ck_attributes = self.build_attributes([ Attribute(CKA_CLASS, CKO_SECRET_KEY), Attribute(CKA_KEY_TYPE, CKK_AES), Attribute(CKA_VALUE_LEN, mkek_length), Attribute(CKA_LABEL, mkek_label), Attribute(CKA_PRIVATE, True), Attribute(CKA_SENSITIVE, True), Attribute(CKA_ENCRYPT, True), Attribute(CKA_DECRYPT, True), Attribute(CKA_SIGN, True), Attribute(CKA_VERIFY, True), Attribute(CKA_TOKEN, True), Attribute(CKA_WRAP, True), Attribute(CKA_UNWRAP, True), Attribute(CKA_EXTRACTABLE, False) ]) mkek = self.generate_kek(ck_attributes.template, session) self.key_handles[mkek_label] = mkek return mkek def get_or_generate_hmac_key(self, hmac_label, session): hmac_key = self.get_key_handle(hmac_label, session) if not hmac_key: # Generate a key that is persistent and not extractable ck_attributes = self.build_attributes([ Attribute(CKA_CLASS, CKO_SECRET_KEY), Attribute(CKA_KEY_TYPE, CKK_AES), Attribute(CKA_VALUE_LEN, 32), Attribute(CKA_LABEL, hmac_label), Attribute(CKA_PRIVATE, True), Attribute(CKA_SENSITIVE, True), Attribute(CKA_SIGN, True), Attribute(CKA_VERIFY, True), Attribute(CKA_TOKEN, True), Attribute(CKA_EXTRACTABLE, False) ]) hmac_key = self.generate_kek(ck_attributes.template, session) self.key_handles[hmac_label] = hmac_key return hmac_key def get_key_handle(self, mkek_label, session): if mkek_label in self.key_handles: return self.key_handles[mkek_label] ck_attributes = self.build_attributes([ Attribute(CKA_CLASS, CKO_SECRET_KEY), Attribute(CKA_KEY_TYPE, CKK_AES), Attribute(CKA_LABEL, mkek_label) ]) rv = self.lib.C_FindObjectsInit( session, ck_attributes.template, len(ck_attributes.template) ) self.check_error(rv) returned_count = self.ffi.new(""CK_ULONG *"") object_handle_ptr = self.ffi.new(""CK_OBJECT_HANDLE *"") rv = self.lib.C_FindObjects( session, object_handle_ptr, 2, returned_count ) self.check_error(rv) if returned_count[0] == 1: key = object_handle_ptr[0] rv = self.lib.C_FindObjectsFinal(session) self.check_error(rv) if returned_count[0] == 1: return key elif returned_count[0] == 0: return None else: raise P11CryptoPluginKeyException() def generate_random(self, length, session): buf = self.ffi.new(""CK_BYTE[{0}]"".format(length)) rv = self.lib.C_GenerateRandom(session, buf, length) self.check_error(rv) return buf def build_gcm_mech(self, iv): mech = self.ffi.new(""CK_MECHANISM *"") mech.mechanism = self.algorithm gcm = self.ffi.new(""CK_AES_GCM_PARAMS *"") gcm.pIv = iv gcm.ulIvLen = 16 gcm.ulIvBits = 128 gcm.ulTagBits = 128 mech.parameter = gcm mech.parameter_len = 48 # sizeof(CK_AES_GCM_PARAMS) return CKMechanism(mech, gcm) def generate_kek(self, template, session): """"""Generates both master and project KEKs :param template: A tuple of tuples in (CKA_TYPE, VALUE) form """""" mech = self.ffi.new(""CK_MECHANISM *"") mech.mechanism = CKM_AES_KEY_GEN object_handle_ptr = self.ffi.new(""CK_OBJECT_HANDLE *"") rv = self.lib.C_GenerateKey( session, mech, template, len(template), object_handle_ptr ) self.check_error(rv) return object_handle_ptr[0] def generate_wrapped_kek(self, kek_label, key_length, session): # generate a non-persistent key that is extractable ck_attributes = self.build_attributes([ Attribute(CKA_CLASS, CKO_SECRET_KEY), Attribute(CKA_KEY_TYPE, CKK_AES), Attribute(CKA_VALUE_LEN, key_length), Attribute(CKA_LABEL, kek_label), Attribute(CKA_PRIVATE, True), Attribute(CKA_SENSITIVE, True), Attribute(CKA_ENCRYPT, True), Attribute(CKA_DECRYPT, True), Attribute(CKA_TOKEN, False), # not persistent Attribute(CKA_WRAP, True), Attribute(CKA_UNWRAP, True), Attribute(CKA_EXTRACTABLE, True) ]) kek = self.generate_kek(ck_attributes.template, session) mech = self.ffi.new(""CK_MECHANISM *"") mech.mechanism = CKM_AES_CBC_PAD iv = self.generate_random(16, session) mech.parameter = iv mech.parameter_len = 16 mkek = self.key_handles[self.current_mkek_label] # Since we're using CKM_AES_CBC_PAD the maximum length of the # padded key will be the key length + one block. We allocate the # worst case scenario as a CK_BYTE array. padded_length = key_length + self.block_size buf = self.ffi.new(""CK_BYTE[{0}]"".format(padded_length)) buf_len = self.ffi.new(""CK_ULONG *"", padded_length) rv = self.lib.C_WrapKey(session, mech, mkek, kek, buf, buf_len) self.check_error(rv) wrapped_key = self.ffi.buffer(buf, buf_len[0])[:] hmac = self.compute_hmac(wrapped_key, session) return { 'iv': base64.b64encode(self.ffi.buffer(iv)[:]), 'wrapped_key': base64.b64encode(wrapped_key), 'hmac': base64.b64encode(hmac), 'mkek_label': self.current_mkek_label, 'hmac_label': self.current_hmac_label } def compute_hmac(self, wrapped_key, session): mech = self.ffi.new(""CK_MECHANISM *"") mech.mechanism = CKM_SHA256_HMAC hmac_key = self.key_handles[self.current_hmac_label] rv = self.lib.C_SignInit(session, mech, hmac_key) self.check_error(rv) ck_bytes = self.ffi.new(""CK_BYTE[]"", wrapped_key) buf = self.ffi.new(""CK_BYTE[32]"") buf_len = self.ffi.new(""CK_ULONG *"", 32) rv = self.lib.C_Sign(session, ck_bytes, len(wrapped_key), buf, buf_len) self.check_error(rv) return self.ffi.buffer(buf, buf_len[0])[:] def verify_hmac(self, hmac_key, sig, wrapped_key, session): mech = self.ffi.new(""CK_MECHANISM *"") mech.mechanism = CKM_SHA256_HMAC rv = self.lib.C_VerifyInit(session, mech, hmac_key) self.check_error(rv) ck_bytes = self.ffi.new(""CK_BYTE[]"", wrapped_key) ck_sig = self.ffi.new(""CK_BYTE[]"", sig) rv = self.lib.C_Verify( session, ck_bytes, len(wrapped_key), ck_sig, len(sig) ) self.check_error(rv) def unwrap_key(self, plugin_meta, session): """"""Unwraps byte string to key handle in HSM. :param plugin_meta: kek_meta_dto plugin meta (json string) :returns: Key handle from HSM. No unencrypted bytes. """""" meta = json.loads(plugin_meta) iv = base64.b64decode(meta['iv']) hmac = base64.b64decode(meta['hmac']) wrapped_key = base64.b64decode(meta['wrapped_key']) mkek = self.get_key_handle(meta['mkek_label'], session) hmac_key = self.get_key_handle(meta['hmac_label'], session) LOG.debug(""Unwrapping key with %s mkek label"", meta['mkek_label']) LOG.debug(""Verifying key with %s hmac label"", meta['hmac_label']) self.verify_hmac(hmac_key, hmac, wrapped_key, session) unwrapped = self.ffi.new(""CK_OBJECT_HANDLE *"") mech = self.ffi.new(""CK_MECHANISM *"") mech.mechanism = CKM_AES_CBC_PAD iv = self.ffi.new(""CK_BYTE[]"", iv) mech.parameter = iv mech.parameter_len = 16 ck_attributes = self.build_attributes([ Attribute(CKA_CLASS, CKO_SECRET_KEY), Attribute(CKA_KEY_TYPE, CKK_AES), Attribute(CKA_ENCRYPT, True), Attribute(CKA_DECRYPT, True), Attribute(CKA_TOKEN, False), Attribute(CKA_WRAP, True), Attribute(CKA_UNWRAP, True), Attribute(CKA_EXTRACTABLE, True) ]) rv = self.lib.C_UnwrapKey( session, mech, mkek, wrapped_key, len(wrapped_key), ck_attributes.template, len(ck_attributes.template), unwrapped ) self.check_error(rv) return unwrapped[0] def pad(self, unencrypted): padder = padding.PKCS7(self.block_size * 8).padder() return padder.update(unencrypted) + padder.finalize() def unpad(self, unencrypted): unpadder = padding.PKCS7(self.block_size * 8).unpadder() return unpadder.update(unencrypted) + unpadder.finalize() ",,746,697
openstack%2Ftripleo-heat-templates~master~Ieb129d4cbe4b6d4184172631499ecd638073564f,openstack/tripleo-heat-templates,master,Ieb129d4cbe4b6d4184172631499ecd638073564f,Move sysctl settings into hieradata,MERGED,2015-05-19 09:31:01.000000000,2015-05-20 17:23:57.000000000,2015-05-20 17:23:55.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-05-19 09:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fddab678f3639027f7fe516d75df53295d11e78e', 'message': 'Move sysctl settings into hieradata\n\nThis will configure the sysctl settings via puppet instead of\nsysctl image element.\n\nChange-Id: Ieb129d4cbe4b6d4184172631499ecd638073564f\n'}, {'number': 2, 'created': '2015-05-19 10:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3c0a6ee9ccd84ee2c5fc6ca0b9847629af7ef8a9', 'message': 'Move sysctl settings into hieradata\n\nThis will configure the sysctl settings via puppet instead of\nsysctl image element.\n\nChange-Id: Ieb129d4cbe4b6d4184172631499ecd638073564f\n'}, {'number': 3, 'created': '2015-05-20 14:58:40.000000000', 'files': ['puppet/manifests/overcloud_cephstorage.pp', 'puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_compute.pp', 'puppet/manifests/overcloud_object.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/hieradata/common.yaml', 'puppet/all-nodes-config.yaml', 'puppet/manifests/overcloud_volume.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9669efa87ab0b7771d39b0f677456399465464c0', 'message': 'Move sysctl settings into hieradata\n\nThis will configure the sysctl settings via puppet instead of\nsysctl image element.\n\nChange-Id: Ieb129d4cbe4b6d4184172631499ecd638073564f\n'}]",0,184210,9669efa87ab0b7771d39b0f677456399465464c0,15,4,3,6796,,,0,"Move sysctl settings into hieradata

This will configure the sysctl settings via puppet instead of
sysctl image element.

Change-Id: Ieb129d4cbe4b6d4184172631499ecd638073564f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/10/184210/3 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_cephstorage.pp', 'puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_compute.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/manifests/overcloud_object.pp', 'puppet/hieradata/common.yaml', 'puppet/all-nodes-config.yaml', 'puppet/manifests/overcloud_volume.pp']",8,fddab678f3639027f7fe516d75df53295d11e78e,sysctl,include ::sysctl ,,16,4
openstack%2Fironic~master~Ib0cddf7541defbdfe1b17448b52becf8bd4ef3de,openstack/ironic,master,Ib0cddf7541defbdfe1b17448b52becf8bd4ef3de,Add simplegeneric to py34 requirements,MERGED,2015-05-20 07:58:48.000000000,2015-05-20 17:22:49.000000000,2015-05-20 17:22:47.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 7491}, {'_account_id': 7711}, {'_account_id': 9751}, {'_account_id': 10250}, {'_account_id': 10343}, {'_account_id': 12081}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-05-20 07:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/98ca0924a3386a60b08a9e2357c9c8374660a681', 'message': 'WIP: add simplegeneric\n\nChange-Id: Ib0cddf7541defbdfe1b17448b52becf8bd4ef3de\n'}, {'number': 2, 'created': '2015-05-20 13:44:22.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/fe2f445418ad7cb7741a7d237fd2ad69c27833a4', 'message': ""Add simplegeneric to py34 requirements\n\nsimplegeneric suppoosed to be installed by WSME, but for a some reasons\nit was missed in py3 env. We can't add this library to requirements.txt,\nbecause it missed in global requirements, so I've added simplegeneric\nto the `deps` section in py34 environment.\n\nThis if a fast-and-dirty way to unblock python34 gates for ironic.\n\nChange-Id: Ib0cddf7541defbdfe1b17448b52becf8bd4ef3de\n""}]",1,184429,fe2f445418ad7cb7741a7d237fd2ad69c27833a4,26,9,2,7491,,,0,"Add simplegeneric to py34 requirements

simplegeneric suppoosed to be installed by WSME, but for a some reasons
it was missed in py3 env. We can't add this library to requirements.txt,
because it missed in global requirements, so I've added simplegeneric
to the `deps` section in py34 environment.

This if a fast-and-dirty way to unblock python34 gates for ironic.

Change-Id: Ib0cddf7541defbdfe1b17448b52becf8bd4ef3de
",git fetch https://review.opendev.org/openstack/ironic refs/changes/29/184429/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,98ca0924a3386a60b08a9e2357c9c8374660a681,, simplegeneric,,1,0
openstack%2Fpython-openstackclient~master~I883058272c0293b8f5645376f25e690476f62642,openstack/python-openstackclient,master,I883058272c0293b8f5645376f25e690476f62642,[DO NOT MERGE] CI Test,ABANDONED,2015-05-20 17:07:20.000000000,2015-05-20 17:08:53.000000000,,[{'_account_id': 13752}],"[{'number': 1, 'created': '2015-05-20 17:07:20.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/66007b4583117c14871a8e51590a593885f65be2', 'message': '[DO NOT MERGE] CI Test\n\nChange-Id: I883058272c0293b8f5645376f25e690476f62642\n'}]",0,184546,66007b4583117c14871a8e51590a593885f65be2,3,1,1,13752,,,0,"[DO NOT MERGE] CI Test

Change-Id: I883058272c0293b8f5645376f25e690476f62642
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/46/184546/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,66007b4583117c14871a8e51590a593885f65be2,,,,0,0
openstack%2Fmurano-dashboard~master~If5fb90b6e5fbd05497d5c3ddcadcbee9566b7b98,openstack/murano-dashboard,master,If5fb90b6e5fbd05497d5c3ddcadcbee9566b7b98,[DO NOT MERGE] CI Test,ABANDONED,2015-05-20 16:28:33.000000000,2015-05-20 17:04:46.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 13752}]","[{'number': 1, 'created': '2015-05-20 16:28:33.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/15ce6e2fbde6bc2a35764947bd2ec296f7b30e62', 'message': '[DO NOT MERGE] CI Test\n\nChange-Id: If5fb90b6e5fbd05497d5c3ddcadcbee9566b7b98\n'}]",0,184536,15ce6e2fbde6bc2a35764947bd2ec296f7b30e62,8,3,1,13752,,,0,"[DO NOT MERGE] CI Test

Change-Id: If5fb90b6e5fbd05497d5c3ddcadcbee9566b7b98
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/36/184536/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,15ce6e2fbde6bc2a35764947bd2ec296f7b30e62,,,,0,0
openstack%2Fbarbican-specs~master~I185c5118c620412fb63752f4c57ce493c2d3235c,openstack/barbican-specs,master,I185c5118c620412fb63752f4c57ce493c2d3235c,Split validator module in to smaller modules,ABANDONED,2014-10-09 19:46:59.000000000,2015-05-20 17:00:29.000000000,,"[{'_account_id': 3}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-10-09 19:46:59.000000000', 'files': ['specs/kilo/split-validator-module.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/028ff76be29e0489c6ba18220c3b60cb7df2dbb0', 'message': 'Split validator module in to smaller modules\n\nChange-Id: I185c5118c620412fb63752f4c57ce493c2d3235c\n'}]",6,127328,028ff76be29e0489c6ba18220c3b60cb7df2dbb0,6,5,1,994,,,0,"Split validator module in to smaller modules

Change-Id: I185c5118c620412fb63752f4c57ce493c2d3235c
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/28/127328/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/split-validator-module.rst'],1,028ff76be29e0489c6ba18220c3b60cb7df2dbb0,split-validator,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================ Split validator module in to smaller modules ============================================ Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/barbican/+spec/split-validator-module-in-to-smaller-modules Current validator module is getting difficult to manage as it is grown very big. We have to split this module in to smaller units to make it more manageable. Problem Description =================== * Barbican REST request validation module 'barbican.common.validators' is growing big and getting unmanageable. * Current package for validator module is not appropriate. Proposed Change =============== * Split the validator module in to smaller manageable modules. * Refactor the validator in to multiple validators mapped to corresponding controllers. * Define new package ""barbican.api.controllers.validators"" and mode the new validators to new package. The new package structure for validators would be as below. barbican/ api/ controllers/ validators/ BaseValidator.py OrderValidator.py SecretValidator.py .... .... Alternatives ------------ None. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications & Audit Impact ---------------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Developer has to create new validators for each new REST resources. Implementation ============== Assignee(s) ----------- Primary assignee: <atiwari> Other contributors: <launchpad-id or None> Work Items ---------- * Refactor validator module and move to new package structure. * Define new validator modules for each controllers. * Rearrange the unit tests. Dependencies ============ None Testing ======= None Documentation Impact ==================== None References ========== https://review.openstack.org/#/c/87405/23/barbican/common/validators.py ",,135,0
openstack%2Fbarbican-specs~master~I14e88549b6ddf000ea14ff2493741aa5a6f2104c,openstack/barbican-specs,master,I14e88549b6ddf000ea14ff2493741aa5a6f2104c,Blueprint for supporting binary secret retrieval in text format,ABANDONED,2014-10-10 21:33:19.000000000,2015-05-20 16:58:50.000000000,,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 6783}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 13914}]","[{'number': 1, 'created': '2014-10-10 21:33:19.000000000', 'files': ['specs/kilo/support-for-text-plain-order.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/6ddc637d54acd73ebdfdd4e5d384a283d773cd86', 'message': 'Blueprint for supporting binary secret retrieval in text format\n\nMoved from juno (earlier review: https://review.openstack.org/#/c/115435/)\n\nChange-Id: I14e88549b6ddf000ea14ff2493741aa5a6f2104c\n'}]",0,127659,6ddc637d54acd73ebdfdd4e5d384a283d773cd86,8,6,1,1091,,,0,"Blueprint for supporting binary secret retrieval in text format

Moved from juno (earlier review: https://review.openstack.org/#/c/115435/)

Change-Id: I14e88549b6ddf000ea14ff2493741aa5a6f2104c
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/59/127659/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/support-for-text-plain-order.rst'],1,6ddc637d54acd73ebdfdd4e5d384a283d773cd86,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================================== Support for text/plain order request ==================================== https://blueprints.launchpad.net/barbican/+spec/support-for-text-plain-in-order-request Barbican currently supports secret generation in binary format. This blueprint is to add optional support for getting binary secret data in text format. Problem Description =================== Barbican allows retrieval of secret data in binary format which works well when its consumed directly by client application with no user (human) interaction. In cases where user interaction is involved either via a workflow or via UI, binary data cannot be used as-is as data may not be printable, can not be copied by editors. In those cases, it will be useful to have a standard way of representing binary secret data in human readable format. This blueprint is to address this issue. Proposed Change =============== Base64 encoding scheme is widely used to encode binary data to store and transport and is a standard mechanism for binary content encoding to ASCII string format. The proposal is to return binary secret data in base64 encoded format when secret retrieve requests sends `Accept` header as `text/plain`. This change can be useful in testing via curl where there is need to copy secret read from barbican and to pass it as encoded data point in another openstack service curl request. There is no change expected in secret data storage logic and format. In barbican, secret can be uploaded in `text/plain` format as well. For those cases, there would not be any encoding change made in secret retrieval API. For wrapped secret retrieval, binary secret is going to be base64 encoded if `Accept` header is passed as `text/plain`. Alternatives ------------ This is an optional feature which is currently missing in barbican. In absence of this, application and end-user which needs to print/share the secret data, they may have to wrap data internally which can lead to various encoding scheme/ representation. In some cases, this alternative apporach may not be practical like curl testing case mentioned above. Base64 encoding is a well understood format to transport binary data and end-client can decode it easily when it plans to use it. Same, base64, encoding is used in Barbican internally to store encrypted data. Data model impact ----------------- None REST API impact --------------- Change is expected for secret retrieval API where actual secret is returned. Get secret: GET /v1/secrets/<secret_ref> * Existing API returns secret metadata or actual secret depending on ``Accept`` header value. In case of missing ``Accept`` header, secret metadata is returned. * With this change, support for ``Accept`` header with ``text/plain`` is going to return binary secret as base64 encoded ASCII string. * Example: Binary secret with `text/plain` Accept header:: Request: curl -i -H ""Accept:text/plain"" -H ""X-Project-Id:12345"" \ http://localhost:9311/v1/secrets/acdc59ec-00e9-4643-839e-4f3d71fb81dc Response: HTTP/1.1 200 OK Content-Length: 64 Content-Type: text/plain; charset=UTF-8 5005EBD409C2F1E772B5784559751B75C1CA0E49ABC8CC931F94512613264136 * Example: Uploaded text secret with `text/plain` Accept header:: Request: curl -i -H ""Accept:text/plain"" -H ""X-Project-Id:12345"" \ http://localhost:9311/v1/secrets/b2abdd29-337f-4a98-a172-a4535d7d3bdd Response: HTTP/1.1 200 OK Content-Length: 14 Content-Type: text/plain; charset=UTF-8 my-secret-here Security impact --------------- None Notifications & Audit Impact ---------------------------- None. Other end user impact --------------------- There should not be any impact other than that returned value is base64 encoded in case of binary secret. Where secret is to be used for encrpyting some openstack service artifact, client can either request secret with `Accept` header as `application/octet-stream` or decode base64 encoded string value. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Documentation needs to reflect this optional Accept header support. Implementation ============== Assignee(s) ----------- Primary assignee: arun.kant@hp.com Work Items ---------- * For GET secret API, wrap with base64 encoding for binary secret data. * Update documentation to reflect the change. Dependencies ============ None Testing ======= Unit test will be added to show behvaior for binary secret and plain secret. Documentation Impact ==================== Update `Barbican Developer Guide` to reflect support for this header and provide sample to illustrate difference between binary and plain secret response. References ========== * https://blueprints.launchpad.net/barbican/+spec/support-for-text-plain-in-order-request ",,174,0
openstack%2Fbarbican-specs~master~I64cc8ccef3ef148ddff46eb2ac9fe7c76b31903e,openstack/barbican-specs,master,I64cc8ccef3ef148ddff46eb2ac9fe7c76b31903e,Spec for certificate REST api addition,ABANDONED,2014-10-20 18:13:39.000000000,2015-05-20 16:58:10.000000000,,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-10-20 18:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/4111b0c478d00232ee2d52e0f554bcc7109e8669', 'message': 'Spec for certificate REST api addition\n\nChange-Id: I64cc8ccef3ef148ddff46eb2ac9fe7c76b31903e\n'}, {'number': 2, 'created': '2014-10-20 18:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/d6d7ebd15c2761cd54713178cfaebd800b9ad2b2', 'message': 'Spec for certificate REST api addition\n\nChange-Id: I64cc8ccef3ef148ddff46eb2ac9fe7c76b31903e\n'}, {'number': 3, 'created': '2014-10-20 18:32:59.000000000', 'files': ['specs/kilo/add-certificate-type-to-order-resource.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/791bc2db3b24b478d0cb3237455294efe9f75127', 'message': 'Spec for certificate REST api addition\n\nChange-Id: I64cc8ccef3ef148ddff46eb2ac9fe7c76b31903e\n'}]",13,129695,791bc2db3b24b478d0cb3237455294efe9f75127,14,6,3,994,,,0,"Spec for certificate REST api addition

Change-Id: I64cc8ccef3ef148ddff46eb2ac9fe7c76b31903e
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/95/129695/3 && git format-patch -1 --stdout FETCH_HEAD,"['specs/kilo/atiwari-nat~', 'specs/kilo/Untitled Document~', 'specs/kilo/add-certificate-type-to-order-resource.rst']",3,4111b0c478d00232ee2d52e0f554bcc7109e8669,certificate-rest-api,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================== Add certificate type to the orders resource =========================================== https://blueprints.launchpad.net/barbican/+spec/api-orders-add-more-types Barbican's orders resource is used to generate secrets on behalf of clients. This blueprint addresses how the orders resources can be modified to generate signed certificates. Problem Description =================== Barbican is currently lacking generation support for the certificate order type. This should be generated via a separate order type (in addition to keys types also defined in the blueprint). Proposed Change =============== Barbican Order API will be updated to support certificate signing. This change does not talk about the required backend implementation, only the required API changes and how to interpret the submitted data. Alternatives ------------ None. Data model impact ----------------- Barbican Order model requires the attributes added in the add-more-types-to-the-order-resource spec. REST API impact --------------- The ordering resource will be updated to allow generating certificates. Same as with secret keys, the process is asynchronous and the submission of an order only initiates the process of certificate generation. Resource Structure For Certificate Signing:: { ""type"": ""--type--"", ""meta"": { ""name"": ""--name--"", ""mode"": ""--mode--"", ""expiration"": ""--expiration--"", ""status"": ""--status--"", ""payload_content_type"": ""--type--"", ""issuer"": ""--certificate_issuer--"", ""request"": ""--csr--"", ""valid_not_before"": ""--ISO-8601 time--"", ""valid_not_after"": ""--ISO-8601 time--"" } } Resource Structure For Certificate Generation:: { ""type"": ""--type--"", ""meta"": { ""name"": ""--name--"", ""mode"": ""--mode--"", ""expiration"": ""--expiration--"", ""status"": ""--status--"", ""payload_content_type"": ""--type--"", ""issuer"": ""--certificate_issuer--"", ""certificate_key"": ""--pem_key--"", ""certificate_key_ref"": ""--secret_name--"", ""key_usage"": [""--key_usage_id--""], ""subject"": ""--common_name--"", ""alternative_names"": { ""dns"": [""--domain_name--""], ""email"": [""--email_address--""], ""principal"": [""--principal_name--""] }, ""valid_not_before"": ""--ISO-8601 time--"", ""valid_not_after"": ""--ISO-8601 time--"" } } Required Attribute:: type (string) Type of the secret, supported option described here is certificate:: meta (string) Describes additional information regarding the secret:: meta.name (string) Human readable name for the secret:: meta.issuer (string) Chosen signing authority. This value should be interpreted by the backend. A certificate fingerprint must be accepted, but the backend may also accept specific names defined by the service provider. Required Attribute (for certificate signing only):: meta.request (string) The contents of the PKCS#10 signing request, encoded in PEM format with the usual header/footer Required Attribute (for certificate generation only):: meta.certificate_key_ref or meta.certificate_key (string) Id of the secret holding the key to be used by the certificate, or the key itself. The key must be in PEM format:: meta.subject (string) Value of the subject name in the generated certificate, encoded as RFC2253 compatible string (for example CN=the_person,O=org) Optional Attribute:: meta.key_usage (array of string) Used when generating a new certificate without a CSR. The list contains key usage names as defined in standards documents. The following are guaranteed to be supported: id-kp-serverAuth, id-kp-clientAuth, id-kp-codeSigning, id-kp-emailProtection, id-kp-timeStamping, id-kp-OCSPSigning The key usage field is set to match this selection. If left out, the default is ""id-kp-serverAuth"".:: meta.alternative_names (dictionary) Can be provided when generating a new certificate without a CSR. It may contain any of the keys: ""dns"", ""email"", ""principal"". The values are arrays of strings and mean, respectively, which dns names, email addresses and kerberos principals should be used in the alternative names section of the certificate. Default is empty dictionary and no alternative names requested.:: meta.valid_not_before (string) The requested time in ISO-8601 format, since when the generated certificate should be valid:: meta.valid_not_after (string) The requested time in ISO-8601 format, when the certificate should expire:: meta.mode (string) The type/mode of the algorithm associated with the secret information:: meta.expiration (string) The expiration date for the secret in ISO-8601 format. Once the secret has expired, it will no longer be returned by the API or agent. If this field is not supplied, then the secret has no expiration date:: meta.status (string) Status of the generated secret. The default is `Active`:: meta.payload_content_type (string) API --- Order Create Order: POST /v1/orders Example 01 - Certificate signing:: Request: POST /v1/orders { ""type"": ""certificate"", ""meta"": { ""name"": ""secretname"", ""issuer"": ""deadbeefdeadbeefdeadbeefdeadbeefdeadbeef"", ""request"": ""-----BEGIN CERTIFICATE REQUEST-----\nMIIBETCBvAIBADBXMQswCQYDVQQGEwJBVTETMBEGA1UECAwKU29tZS1TdGF0ZTEh\nMB8GA1UECgwYSW50ZXJuZXQgV2lkZ2l0cyBQdHkgTHRkMRAwDgYDVQQDDAdleGFt\ncGxlMFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALBLBQ3esWfS6HbJhNEUndZB8b/A\nl8oNGf+0DKkEeUhSu2NC0sq6pVl3Qmsp7tKrnxUXo+2oWmnmTYtWJ4Sc5wECAwEA\nAaAAMA0GCSqGSIb3DQEBCwUAA0EALmuXZIutdWhyMRM8kBE1C6ovZYzq5VjH6qpC\npUbbgDX3OFpbgVA1vCeMAPRhiQsRp8GQWqGl0tb+lbq2QIB4wg==\n-----END CERTIFICATE REQUEST-----\n"", ""valid_not_before"": ""2014-01-01T00:00:00.0"", ""valid_not_after"": ""2015-01-01T00:00:00.0"", ""expiration"": ""2015-02-28T19:14:44.180394"", ""payload_content_type"": ""application/octet-stream"" } } Response: Status: 201 Created { ""order_ref"": ""http://localhost:9311/v1/orders/439e1b22-3f48-48c7-86f4-84930eb23c11"" } Example 02 - Certificate generation:: Request: POST /v1/orders { ""type"": ""certificate"", ""meta"": { ""name"": ""secretname"", ""issuer"": ""deadbeefdeadbeefdeadbeefdeadbeefdeadbeef"", ""certificate_key_ref"": ""a8957047-16c6-4b05-ac57-8621edd0e9ee"", ""key_usage"": [""id-kp-serverAuth""], ""subject"": ""CN=host.example.net"", ""alternative_names"": { ""dns"": [""host.example.net"", ""alternative.example.net""], }, ""valid_not_before"": ""2014-01-01T00:00:00.0"", ""valid_not_after"": ""2015-01-01T00:00:00.0"", ""expiration"": ""2015-02-28T19:14:44.180394"", ""payload_content_type"": ""application/octet-stream"" } } Response: Status: 201 Created { ""order_ref"": ""http://localhost:9311/v1/orders/8dbe75fb-0074-49b8-a23d-90a84d1e6a73"" } Listing orders works the same as in the add-more-types-to-the-order-resource spec. Security impact --------------- None Notifications & Audit Impact ---------------------------- Not directly. Backend service signing the certificate request should handle appropriate operator notification and provide audit log of executed actions. Other end user impact --------------------- * Barbican-python client will need to be enhanced to accommodate API changes. Performance Impact ------------------ None Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Stanislaw Pitucha is leading this feature enhancement. Work Items ---------- * Enhance Order REST API to support certificate order type. (TBD) * Enhance Barbican python client to support certificate order type. (TBD) Dependencies ============ * Update to Orders model to support type, meta, container_id (done) * Full functionality testing will require certificate signing plugin (in progress) * Add Certificate Generation and Management To Orders (done) * Spec for removing tenant-id from api resource uri (in progess) Testing ======= * Unit tests required Documentation Impact ==================== * Order API request and response structure has to be explained in the docs. https://github.com/cloudkeep/barbican/wiki/Application-Programming-Interface#orders-resource * Barbican WADL and developer guide will be update for this API change. References ========== - https://blueprints.launchpad.net/barbican/+spec/api-orders-add-more-types ",,344,0
openstack%2Ffuel-main~master~I646dc7b09d2c2ffbeb5771b1d5d140860e277bc0,openstack/fuel-main,master,I646dc7b09d2c2ffbeb5771b1d5d140860e277bc0,CentOS: include kmod-openvswitch-lt package,MERGED,2015-05-20 11:50:58.000000000,2015-05-20 16:57:29.000000000,2015-05-20 16:57:28.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8777}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 11427}, {'_account_id': 11827}, {'_account_id': 12599}]","[{'number': 1, 'created': '2015-05-20 11:50:58.000000000', 'files': ['requirements-rpm.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/87d1e8bb43cfa836e441300bf494f6db05bf9249', 'message': 'CentOS: include kmod-openvswitch-lt package\n\nSo openvswitch can work with kernel 3.10.x\n\nRelated-Bug: #1456459\nChange-Id: I646dc7b09d2c2ffbeb5771b1d5d140860e277bc0\n'}]",0,184462,87d1e8bb43cfa836e441300bf494f6db05bf9249,13,8,1,13194,,,0,"CentOS: include kmod-openvswitch-lt package

So openvswitch can work with kernel 3.10.x

Related-Bug: #1456459
Change-Id: I646dc7b09d2c2ffbeb5771b1d5d140860e277bc0
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/62/184462/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements-rpm.txt'],1,87d1e8bb43cfa836e441300bf494f6db05bf9249,bug/1456459,kmod-openvswitch-lt,,1,0
openstack%2Fbarbican-specs~master~Ifa93232470c08a96e39ba419b98843f10b6d0b28,openstack/barbican-specs,master,Ifa93232470c08a96e39ba419b98843f10b6d0b28,spec to add type field on secrets resource,ABANDONED,2014-10-09 19:44:03.000000000,2015-05-20 16:56:52.000000000,,"[{'_account_id': 3}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-10-09 19:44:03.000000000', 'files': ['specs/kilo/add-type-field-to-secrets.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/e55b62a3c64c595865f4af264e6d7cd27f76aea5', 'message': 'spec to add type field on secrets resource\n\nChange-Id: Ifa93232470c08a96e39ba419b98843f10b6d0b28\n'}]",0,127325,e55b62a3c64c595865f4af264e6d7cd27f76aea5,4,2,1,994,,,0,"spec to add type field on secrets resource

Change-Id: Ifa93232470c08a96e39ba419b98843f10b6d0b28
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/25/127325/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/add-type-field-to-secrets.rst'],1,e55b62a3c64c595865f4af264e6d7cd27f76aea5,add-type-field-on-secret,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================= Add-type-field-to-secrets ========================= Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/barbican/+spec/add-type-field-to-secrets Currently Secret is generic resource, there is no way to distinguish what kind of secret is encapsulated in it. The type field on secrets will help identifying the Secrets and also improve the searches for particular type of secrets. Problem Description =================== * Secrets are generic resource, there is no way to identify what is stored in it. (SYMMETRIC, ASYMMETRIC, Password .....) * There is no way to search secrets based on type. Proposed Change =============== * Add a new field 'type' on Secret model to identify the secret type. * Enhance REST API to support filter based on secret type. Alternatives ------------ None Data model impact ----------------- * We have to add a new field on Secret model. * Data migration is required. REST API impact --------------- Following API to List of Secrets Per Tenant will be enhanced to support type filter. https://github.com/cloudkeep/barbican/wiki/Application-Programming-Interface#get---list-of-secrets-per-tenant Security impact --------------- None Notifications & Audit Impact ---------------------------- None Other end user impact --------------------- * python-novaclient need enhancement to incorporate the type filter. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Unit and functional tests need enhancement to accommodate tests for type filter. Implementation ============== Assignee(s) ----------- Primary assignee: <Arvind Tiwari atiwari> Other contributors: <launchpad-id or None> Work Items ---------- * Secret Data model change to add type field and unit test update. * Enhance REST API to support new filter based on type. Dependencies ============ None Testing ======= New tests has to be added in Tempest tests. Documentation Impact ==================== Below API doc will be enhanced to explain the use of new filter. https://github.com/cloudkeep/barbican/wiki/Application-Programming-Interface References ========== https://blueprints.launchpad.net/barbican/+spec/add-type-field-to-secrets ",,130,0
openstack%2Ftempest~master~I3487dfefe4a9b26b77fd5f7faf0a250fd85d35a3,openstack/tempest,master,I3487dfefe4a9b26b77fd5f7faf0a250fd85d35a3,DNM: Add ability to use an exclusion list when selecting tempest tests,ABANDONED,2015-03-04 10:03:56.000000000,2015-05-20 16:47:55.000000000,,"[{'_account_id': 3}, {'_account_id': 5044}, {'_account_id': 6735}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-03-04 10:03:56.000000000', 'files': ['tools/testr_wrapper.sh', 'tools/filter_tests.py', '.testr.conf'], 'web_link': 'https://opendev.org/openstack/tempest/commit/feb640553f4e81466c37e727c3f87aa317c1c622', 'message': 'DNM: Add ability to use an exclusion list when selecting tempest tests\n\nUseful for 3rd party CIs where not all tempest tests pass in their configuration.\n\nThe intention of this change is to allow moving of the exclusion lists to tempest\nso if a new test is added that passes in gate it can be excluded from 3rd party\nCIs without there being a period of breakage\n\nChange-Id: I3487dfefe4a9b26b77fd5f7faf0a250fd85d35a3\n'}]",0,161155,feb640553f4e81466c37e727c3f87aa317c1c622,5,4,1,6735,,,0,"DNM: Add ability to use an exclusion list when selecting tempest tests

Useful for 3rd party CIs where not all tempest tests pass in their configuration.

The intention of this change is to allow moving of the exclusion lists to tempest
so if a new test is added that passes in gate it can be excluded from 3rd party
CIs without there being a period of breakage

Change-Id: I3487dfefe4a9b26b77fd5f7faf0a250fd85d35a3
",git fetch https://review.opendev.org/openstack/tempest refs/changes/55/161155/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/testr_wrapper.sh', 'tools/filter_tests.py', '.testr.conf']",3,feb640553f4e81466c37e727c3f87aa317c1c622,xenapi_exclusions,test_command=tools/testr_wrapper.sh $LISTOPT $IDOPTION,test_command=OS_STDOUT_CAPTURE=${OS_STDOUT_CAPTURE:-1} \ OS_STDERR_CAPTURE=${OS_STDERR_CAPTURE:-1} \ OS_TEST_TIMEOUT=${OS_TEST_TIMEOUT:-500} \ OS_TEST_LOCK_PATH=${OS_TEST_LOCK_PATH:-${TMPDIR:-'/tmp'}} \ ${PYTHON:-python} -m subunit.run discover -t ./ ${OS_TEST_PATH:-./tempest/test_discover} $LISTOPT $IDOPTION,106,5
openstack%2Frally~master~Ide059648363cc24b31b18d83524c4b2717b31ada,openstack/rally,master,Ide059648363cc24b31b18d83524c4b2717b31ada,[DO-NOT-MERGE][Fuel] Test fuel job,ABANDONED,2015-05-15 14:10:25.000000000,2015-05-20 16:43:07.000000000,,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-15 14:10:25.000000000', 'files': ['tests/unit/benchmark/scenarios/fuel/test_environments.py', 'rally/benchmark/scenarios/fuel/utils.py', 'rally/benchmark/scenarios/fuel/environments.py', 'tests/unit/benchmark/scenarios/fuel/test_utils.py', 'samples/tasks/scenarios/fuel/list-environments.yaml', 'tests/unit/benchmark/scenarios/fuel/__init__.py', 'samples/tasks/scenarios/fuel/list-environments.json', 'optional-requirements.txt', 'rally/benchmark/scenarios/fuel/__init__.py', 'rally-jobs/fuel.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/f09059cb1956068941f1ad0990d1c884f9a4b454', 'message': '[DO-NOT-MERGE][Fuel] Test fuel job\n\nChange-Id: Ide059648363cc24b31b18d83524c4b2717b31ada\n'}]",0,183535,f09059cb1956068941f1ad0990d1c884f9a4b454,151,3,1,7369,,,0,"[DO-NOT-MERGE][Fuel] Test fuel job

Change-Id: Ide059648363cc24b31b18d83524c4b2717b31ada
",git fetch https://review.opendev.org/openstack/rally refs/changes/35/183535/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/fuel/utils.py', 'tests/unit/benchmark/scenarios/fuel/test_environments.py', 'rally/benchmark/scenarios/fuel/environments.py', 'tests/unit/benchmark/scenarios/fuel/test_utils.py', 'samples/tasks/scenarios/fuel/list-environments.yaml', 'tests/unit/benchmark/scenarios/fuel/__init__.py', 'optional-requirements.txt', 'samples/tasks/scenarios/fuel/list-environments.json', 'rally/benchmark/scenarios/fuel/__init__.py', 'rally-jobs/fuel.yaml']",10,f09059cb1956068941f1ad0990d1c884f9a4b454,test-fuel-job,"--- FuelEnvironments.list_environments: - runner: type: ""constant"" times: 200 concurrency: 10 sla: failure_rate: max: 0 ",,241,0
openstack%2Fcinder-specs~master~Ic44a35c01278fdc2fbe0a1614c32914542b01925,openstack/cinder-specs,master,Ic44a35c01278fdc2fbe0a1614c32914542b01925,Remove volume driver specs and move Liberty specs,MERGED,2015-05-15 18:01:03.000000000,2015-05-20 16:29:43.000000000,2015-05-20 16:29:41.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 9003}]","[{'number': 1, 'created': '2015-05-15 18:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/794377b5ddaa64ac9646bfb6ff8f341cb66392fd', 'message': ""Remove volume driver specs and move Liberty specs\n\nNew volume drivers don't need specs. Also some things need to be moved\nover to Liberty that weren't done in Kilo.\n\nChange-Id: Ic44a35c01278fdc2fbe0a1614c32914542b01925\n""}, {'number': 2, 'created': '2015-05-17 20:41:54.000000000', 'files': ['specs/liberty/huawei-sdshypervisor-driver.rst', 'specs/kilo/add-fibre-channel-support-to-netapp-drivers.rst', 'specs/liberty/get-vol-type-extra-specs.rst', 'specs/kilo/xio-iscsi-fc-volume-driver.rst', 'specs/kilo/huawei-dsware-driver.rst', 'specs/kilo/xio-volume-driver-1-1.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/6f2a2b1053968e007443f2fe05bbdf5cffb621b2', 'message': ""Remove volume driver specs and move Liberty specs\n\nNew volume drivers don't need specs. Also some things need to be moved\nover to Liberty that weren't done in Kilo.\n\nChange-Id: Ic44a35c01278fdc2fbe0a1614c32914542b01925\n""}]",0,183631,6f2a2b1053968e007443f2fe05bbdf5cffb621b2,10,3,2,170,,,0,"Remove volume driver specs and move Liberty specs

New volume drivers don't need specs. Also some things need to be moved
over to Liberty that weren't done in Kilo.

Change-Id: Ic44a35c01278fdc2fbe0a1614c32914542b01925
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/31/183631/2 && git format-patch -1 --stdout FETCH_HEAD,"['specs/liberty/huawei-sdshypervisor-driver.rst', 'specs/kilo/add-fibre-channel-support-to-netapp-drivers.rst', 'specs/liberty/get-vol-type-extra-specs.rst', 'specs/kilo/xio-iscsi-fc-volume-driver.rst', 'specs/kilo/huawei-dsware-driver.rst', 'specs/kilo/xio-volume-driver-1-1.rst']",6,794377b5ddaa64ac9646bfb6ff8f341cb66392fd,,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================================== Add QoS, media affinity and thin allocation support to X-IO volume driver ========================================================================== https://blueprints.launchpad.net/cinder/+spec/xio-volume-driver-1-1 This blueprint covers enhancements of X-IO volume driver to add support for: - QoS specs - add ability to pass down IOPSmin, IOPSmax and IOPSburst to ISE storage system. - Media affinity - add ability to pass down requested media type for volume. Media types supported: Flash, CADP (hybrid) and HDD only. - Add support for volume retype. - Thin allocation support. Problem description =================== QoS support: Allow the end user to specify IOPSmin, IOPSmax and IOPSburst for a volume. Affinity support: Allow the end user to specify media type for volume. Volume retype support: Allow the end user to change the volume type for an existing volume. The volume will be updated to align with the new type accordingly. Thin allocation support: Allow the end user to specify that the volume should be thinly allocated. Use Cases ========= Proposed change =============== Extra specs and QoS specs for the specified volume type will be parsed and passed to the ISE storage system as part of the REST call to create volume. Retype will use modify volume REST command to change volume attributes on ISE volume. Extra-specs: Affinity:Type - specifies media type. Valid options: flash, cadp, hdd. Example: To create volume type for flash media type. cinder type-create flash Affinity:Type=flash QoS-specs: QoS:IOPSmax - specifies max IOPS. QoS:IOPSmin - specifies min IOPS. QoS:IOPSburst - specifies burst IOPS. Alloc:Type - specifies allocation type. Valid options: thin, thick. Alternatives ------------ None Data model impact ----------------- None. Changes are local to X-IO volume driver. REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None. Existing cinderclient commands are used to create volume-types that specifies QoS, affinity. Performance Impact ------------------ None Other deployer impact --------------------- None. See above for new spec options supported. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: richard-hedlind Other contributors: None Work Items ---------- Affinity support: Rework driver to support extra-specs in create_volume API. Affinity attribute will be copied from source volume in case of clone. Implementation complete. QoS support: Rework driver to support qos-specs in create_volume API. Implemented. QoS attributes will be copied from source volume in case of clone. Implementation complete. Retype: Add retype API to driver. API uses REST API modify volume to change attributes for existing volume. Implementation complete. Thin allocation: Pass down thin allocation flag if ISE storage array has support for it. Implementation in progress. Additional unit tests: Add unit tests to test out APIs for affinity, qos, retype, thin. Implementation in progress. Dependencies ============ Dependent on approval of base version of X-IO volume driver: https://blueprints.launchpad.net/cinder/+spec/xio-iscsi-fc-volume-driver https://review.openstack.org/#/c/116186/ Testing ======= Test using existing test infrastructure according to driver submission steps. Tests will be added to test_xio.py to cover affinity, qos, retype and thin. Documentation Impact ==================== Support Matrix needs to be updated to include X-IO support. https://wiki.openstack.org/wiki/CinderSupportMatrix Block storage documentation needs to be updated to include X-IO volume driver information in the volume drivers section. http://docs.openstack.org/ References ========== None ",0,721
openstack%2Fcinder-specs~master~Ie417145bf82df6e67bd97b3ae4bed4da1a3036a9,openstack/cinder-specs,master,Ie417145bf82df6e67bd97b3ae4bed4da1a3036a9,Build Liberty and Kilo specs,MERGED,2015-05-17 20:41:54.000000000,2015-05-20 16:29:04.000000000,2015-05-20 16:29:03.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}]","[{'number': 1, 'created': '2015-05-17 20:41:54.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/3614b715884838e836c78958185ce671a18234df', 'message': 'Build Liberty and Kilo specs\n\nThese should be getting built to display on the OpenStack block storage\nspec site.\n\nChange-Id: Ie417145bf82df6e67bd97b3ae4bed4da1a3036a9\n'}]",0,183946,3614b715884838e836c78958185ce671a18234df,8,3,1,170,,,0,"Build Liberty and Kilo specs

These should be getting built to display on the OpenStack block storage
spec site.

Change-Id: Ie417145bf82df6e67bd97b3ae4bed4da1a3036a9
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/46/183946/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,3614b715884838e836c78958185ce671a18234df,,Liberty approved specs: .. toctree:: :glob: :maxdepth: 1 specs/liberty/* Kilo approved specs: .. toctree:: :glob: :maxdepth: 1 specs/kilo/* ,,16,0
openstack%2Fmurano-agent~master~I950feb79d6ade9129a79900b6fd95ae1f14003ff,openstack/murano-agent,master,I950feb79d6ade9129a79900b6fd95ae1f14003ff,[DO NOT MERGE] CI Test,ABANDONED,2015-05-20 13:43:32.000000000,2015-05-20 16:26:03.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 13752}]","[{'number': 1, 'created': '2015-05-20 13:43:32.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/ced4effc75ded552a6fb7b162086bff0a105d902', 'message': '[DO NOT MERGE] CI Test\n\nChange-Id: I950feb79d6ade9129a79900b6fd95ae1f14003ff\n'}]",0,184492,ced4effc75ded552a6fb7b162086bff0a105d902,11,3,1,13752,,,0,"[DO NOT MERGE] CI Test

Change-Id: I950feb79d6ade9129a79900b6fd95ae1f14003ff
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/92/184492/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,ced4effc75ded552a6fb7b162086bff0a105d902,,,,0,0
openstack%2Foslo.cache~master~Ib3e651c3e08284b46d5baf8c9e063ed29e92188b,openstack/oslo.cache,master,Ib3e651c3e08284b46d5baf8c9e063ed29e92188b,Fix name of oslotest base test case,MERGED,2015-05-10 00:54:23.000000000,2015-05-20 16:23:34.000000000,2015-05-20 16:23:33.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 15171}]","[{'number': 1, 'created': '2015-05-10 00:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/0efde7fbcea2b78f98b8360efb9df5980ccb732d', 'message': 'Fix name of oslotest base test case\n\nThis helps actually run the test case properly\nhttp://git.openstack.org/cgit/openstack/oslotest/tree/oslotest/base.py#n31\n\nChange-Id: Ib3e651c3e08284b46d5baf8c9e063ed29e92188b\n'}, {'number': 2, 'created': '2015-05-20 16:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/792f8d32cf78424f95c6aa018ca981cdf42f182b', 'message': 'Fix name of oslotest base test case\n\nThis helps actually run the test case properly\nhttp://git.openstack.org/cgit/openstack/oslotest/tree/oslotest/base.py#n31\n\nChange-Id: Ib3e651c3e08284b46d5baf8c9e063ed29e92188b\n'}]",0,181697,792f8d32cf78424f95c6aa018ca981cdf42f182b,23,4,2,5638,,,0,"Fix name of oslotest base test case

This helps actually run the test case properly
http://git.openstack.org/cgit/openstack/oslotest/tree/oslotest/base.py#n31

Change-Id: Ib3e651c3e08284b46d5baf8c9e063ed29e92188b
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/97/181697/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo_cache/tests/test_cache.py'],1,0efde7fbcea2b78f98b8360efb9df5980ccb732d,,class TestCache(base.BaseTestCase):,class TestCache(base.TestCase):,1,1
openstack%2Fglance_store~master~I53ec902f344d7d57bb6f29a1c8b7a953efa0ff4e,openstack/glance_store,master,I53ec902f344d7d57bb6f29a1c8b7a953efa0ff4e,Port glance_store to Python 3,ABANDONED,2015-05-19 18:04:44.000000000,2015-05-20 16:21:19.000000000,,"[{'_account_id': 3}, {'_account_id': 9107}]","[{'number': 1, 'created': '2015-05-19 18:04:44.000000000', 'files': ['glance_store/location.py', 'glance_store/_drivers/s3.py', 'glance_store/_drivers/vmware_datastore.py', 'glance_store/_drivers/rbd.py', 'glance_store/tests/base.py', 'glance_store/_drivers/swift/utils.py', 'glance_store/_drivers/swift/store.py', 'glance_store/backend.py', 'glance_store/_drivers/gridfs.py', 'glance_store/common/utils.py', 'glance_store/_drivers/filesystem.py', 'glance_store/_drivers/http.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/908ac1abbe9f72210801208d0422d915aeaacf85', 'message': 'Port glance_store to Python 3\n\n* Use six.moves to get configparser, http_client and urllib modules\n* Replace map(func, data) with [func(item) for item in data]\n* Replace it.next() with next(it): it works on Python 2 and Python 3\n* Replace dict.iteritems() with six.iteritems(dict)\n* Replace unicode with six.text_type\n\nChange-Id: I53ec902f344d7d57bb6f29a1c8b7a953efa0ff4e\n'}]",0,184303,908ac1abbe9f72210801208d0422d915aeaacf85,4,2,1,9107,,,0,"Port glance_store to Python 3

* Use six.moves to get configparser, http_client and urllib modules
* Replace map(func, data) with [func(item) for item in data]
* Replace it.next() with next(it): it works on Python 2 and Python 3
* Replace dict.iteritems() with six.iteritems(dict)
* Replace unicode with six.text_type

Change-Id: I53ec902f344d7d57bb6f29a1c8b7a953efa0ff4e
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/03/184303/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance_store/location.py', 'glance_store/_drivers/s3.py', 'glance_store/_drivers/vmware_datastore.py', 'glance_store/_drivers/rbd.py', 'glance_store/tests/base.py', 'glance_store/_drivers/swift/utils.py', 'glance_store/_drivers/swift/store.py', 'glance_store/backend.py', 'glance_store/_drivers/gridfs.py', 'glance_store/common/utils.py', 'glance_store/_drivers/filesystem.py', 'glance_store/_drivers/http.py']",12,908ac1abbe9f72210801208d0422d915aeaacf85,,"from six.moves import http_clientimport six from six.moves.urllib import parse pieces = urllib.parse.urlparse(uri) return next(self.wrapped) if resp.status == http_client.NOT_FOUND: return {'http': http_client.HTTPConnection, 'https': http_client.HTTPSConnection}[loc.scheme]","import httplibimport urlparse pieces = urlparse.urlparse(uri) return self.wrapped.next() if resp.status == httplib.NOT_FOUND: return {'http': httplib.HTTPConnection, 'https': httplib.HTTPSConnection}[loc.scheme]",36,32
openstack%2Ffuel-qa~master~I965bcd5a4badeec699ba2de589c000c54a6a19c5,openstack/fuel-qa,master,I965bcd5a4badeec699ba2de589c000c54a6a19c5,Add empty settings for vCenter glance,MERGED,2015-05-20 15:51:24.000000000,2015-05-20 16:19:27.000000000,2015-05-20 16:19:27.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 13516}, {'_account_id': 14167}, {'_account_id': 15005}, {'_account_id': 15660}]","[{'number': 1, 'created': '2015-05-20 15:51:24.000000000', 'files': ['fuelweb_test/tests/test_vcenter.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/389cc5f9b4750b4f36c8991ad4c9471b80e7b68f', 'message': ""Add empty settings for vCenter glance\n\nIf we don't use vCenter glance, we should still send empty settings\nto Master node\n\nChange-Id: I965bcd5a4badeec699ba2de589c000c54a6a19c5\nCloses-bug: #1456977\n""}]",0,184523,389cc5f9b4750b4f36c8991ad4c9471b80e7b68f,12,10,1,13306,,,0,"Add empty settings for vCenter glance

If we don't use vCenter glance, we should still send empty settings
to Master node

Change-Id: I965bcd5a4badeec699ba2de589c000c54a6a19c5
Closes-bug: #1456977
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/23/184523/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_vcenter.py'],1,389cc5f9b4750b4f36c8991ad4c9471b80e7b68f,," ""glance"": { ""vcenter_username"": """", ""datacenter"": """", ""vcenter_host"": """", ""vcenter_password"": """", ""datastore"": """", }, ""glance"": { ""vcenter_username"": """", ""datacenter"": """", ""vcenter_host"": """", ""vcenter_password"": """", ""datastore"": """", }, ""glance"": { ""vcenter_username"": """", ""datacenter"": """", ""vcenter_host"": """", ""vcenter_password"": """", ""datastore"": """", }, ""glance"": { ""vcenter_username"": """", ""datacenter"": """", ""vcenter_host"": """", ""vcenter_password"": """", ""datastore"": """", }, """""" ""glance"": { ""vcenter_username"": """", ""datacenter"": """", ""vcenter_host"": """", ""vcenter_password"": """", ""datastore"": """", }, ""glance"": { ""vcenter_username"": """", ""datacenter"": """", ""vcenter_host"": """", ""vcenter_password"": """", ""datastore"": """", }, ""glance"": { ""vcenter_username"": """", ""datacenter"": """", ""vcenter_host"": """", ""vcenter_password"": """", ""datastore"": """", },"," """"""",44,1
openstack%2Fbarbican-specs~master~I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d,openstack/barbican-specs,master,I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d,Add Quota support for Barbican resources,MERGED,2014-10-30 18:53:30.000000000,2015-05-20 16:19:16.000000000,2015-02-17 15:35:20.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 1091}, {'_account_id': 2846}, {'_account_id': 6783}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7874}, {'_account_id': 7973}, {'_account_id': 9234}, {'_account_id': 9237}, {'_account_id': 10035}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-10-30 18:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/b157a43d42c5f02fa4fc3bc6831fd5c6c031623e', 'message': 'Spec for adding quota support to Barbican\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\n'}, {'number': 2, 'created': '2014-10-30 18:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/63a94b04a7a35050e04f5a9739c2dad08362179e', 'message': 'Spec for adding quota support to Barbican\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\n'}, {'number': 3, 'created': '2015-01-07 16:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/254128238c2c16a19aa8af8a9bee68db6733797d', 'message': 'updated to use oslo.common.quota\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\n'}, {'number': 4, 'created': '2015-01-21 00:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/8f21f672728282a3a0ab954c1f030ead6f34f738', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 5, 'created': '2015-01-21 16:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/684af93f6dd4b94dd16dd0b02bd8ee2dc3b61fde', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nPS5 - fixed formatting error\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 6, 'created': '2015-01-21 17:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/24e09e34bbc1cc2cee9fefc2fe15feecf9461fb7', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nPS5 - fixed formatting error\nPS6 - adds clarification that only project level quotas will be\n      done in this spec and not user level quotas\n      JSON payload fix\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 7, 'created': '2015-01-21 20:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/f9d69f6dfa860dd7dcdf1c396bb4f369596015d6', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nPS5 - fixed formatting error\nPS6 - adds clarification that only project level quotas will be\n      done in this spec and not user level quotas\n      JSON payload fix\nPS6 - changing tenant to project, really this time!\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 8, 'created': '2015-01-23 23:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/77d066b5a08dcbdc869e135339141342de4f4c90', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nPS5 - fixed formatting error\nPS6 - adds clarification that only project level quotas will be\n      done in this spec and not user level quotas\n      JSON payload fix\nPS7 - changing tenant to project, really this time!\nPS8 - dropped admin requirement for couple of quota REST API list\n      calls\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 9, 'created': '2015-02-02 23:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/6a83c77a0667f2982686ee03169d475100c9dbda', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 10, 'created': '2015-02-05 00:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/54db3ad460550eb76faec56d3c384143e40c5f7b', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 11, 'created': '2015-02-13 22:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/e99a12bcd975d6b1301e702e5e51987752148e73', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nChanged quota admin REST API to be consistent with nova quota\nadmin API\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 12, 'created': '2015-02-14 04:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/d215561aebdc72823fc4bb445b35f6c216be14bd', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nChanged quota admin REST API to be consistent with nova quota\nadmin API\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 13, 'created': '2015-02-16 17:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/5708705a32a14c9d467966cc1d107beeb2c5df34', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nChanged quota admin REST API to be consistent with nova quota\nadmin API\nRemoved class level quota from this spec. Another spec will\ncover that.\nModifed PUT to return 204 status.\nFixed pagination field names to be consistent with rest of API.\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 14, 'created': '2015-02-16 18:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/12063212fc972bbd6427deaf38977eeb5a0debe9', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nChanged quota admin REST API to be consistent with nova quota\nadmin API\nRemoved class level quota from this spec. Another spec will\ncover that.\nModifed PUT to return 204 status.\nFixed pagination field names to be consistent with rest of API.\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 15, 'created': '2015-02-16 22:00:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/1a6b80cf40416f6fc0f52ef0f473cf0bee0140c3', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nChanged quota admin REST API to be consistent with nova quota\nadmin API\nRemoved class level quota from this spec. Another spec will\ncover that.\nModifed PUT to return 204 status.\nFixed pagination field names to be consistent with rest of API.\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}, {'number': 16, 'created': '2015-02-16 22:02:14.000000000', 'files': ['specs/kilo/quota-support-for-barbican-resources.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/2af53f128c0cd75815e98b66cabb8498be8b12c6', 'message': 'Add Quota support for Barbican resources\n\nThis spec aims at implementing quota support for the Barbican\nresources ""secrets"", ""orders"", ""containers"" and ""transport\nkeys"". It proposes using the oslo.common quota implemenation\nin addition to implementing the REST API changes and data model\nchanges.\n\nChanged quota admin REST API to be consistent with nova quota\nadmin API\nRemoved class level quota from this spec. Another spec will\ncover that.\nModifed PUT to return 204 status.\nFixed pagination field names to be consistent with rest of API.\n\nChange-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d\nImplements: blueprint quota-support-on-barbican-resources\n'}]",177,132091,2af53f128c0cd75815e98b66cabb8498be8b12c6,113,13,16,7874,,,0,"Add Quota support for Barbican resources

This spec aims at implementing quota support for the Barbican
resources ""secrets"", ""orders"", ""containers"" and ""transport
keys"". It proposes using the oslo.common quota implemenation
in addition to implementing the REST API changes and data model
changes.

Changed quota admin REST API to be consistent with nova quota
admin API
Removed class level quota from this spec. Another spec will
cover that.
Modifed PUT to return 204 status.
Fixed pagination field names to be consistent with rest of API.

Change-Id: I4ab94d14788e3b88cbb0a3ff3c46212f408c2b3d
Implements: blueprint quota-support-on-barbican-resources
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/91/132091/16 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/quota-support-for-barbican-resources.rst'],1,b157a43d42c5f02fa4fc3bc6831fd5c6c031623e,add_quota_support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Add quota support for Barbican resources ========================================== https://blueprints.launchpad.net/barbican/+spec/quota-support-on-barbican-resources Barbican REST API doesn't impose any limit on the number of resources allowed per project. This could result in resource explosion. This blueprint proposes a way to specify and enforce quotas with projects. Quotas are operational limits so that cloud resources are optimized. Problem Description =================== The current Barbican REST API for resource creation doesn't impose any limit on the maximum number of resources allowed per project. This could result in a resource explosion. Here are few scenarios that could impact the normal functioning of the Barbican server: * A client could place requests for several thousands of orders to create secrets for a single project. This might overwhelm the Barbican server both in terms of processing time and disk space consumed * If a buggy client script runs amok and attempts to create a generic type container with no associated secret, it could quickly fill-up the Barbican database! This is similar to the quota enforcement done by nova and cinder services. Proposed Change =============== Introduce quotas for all Barbican resources. The quotas should have reasonably high values as defaults. The following resources will have quota support: * secrets * orders * containers * transport_keys *Note:* This proposal is a simpler subset of the quota implemenation done for nova. Barbican does not have any reservable resources and so the quotas are much simpler in that there is no usage tracking and reservations. Also, project-user level quota enforcement is not considered at this time. ***Enforcing quotas:*** Barbican API controllers will be updated with quota logic for the create resource methods. Once implemented, the quota check will work as follows for resource creation requests: 1. Get the quotas for the project from the auth context. If per-project quotas have not been setup, use default quotas 2. Get a count of the resource for the context project 3. If the count equals or exceeds the quotas, reject the request with the following error message: HTTP 403 Forbidden {""error"": ""Quota exceeded for <project-id>. Only <count> <resource>s are allowed"" } 4. Continue with the resource creation Update the Barbican config file to include the following section for quota limits: :: [quotas] enabled = true # resource names that are supported in quota features # to disable quotas for a particular resource, remove from this list quota_items = secrets,orders,containers,transport_keys # number of secrets allowed per project quota_secrets = 100 # number of orders allowed per project quota_orders = 100 # number of containers allowed per project quota_containers = 50 # number of transport_keys allowed per project # Note, a negative value signifies unlimited quota_transport_keys = -1 # default driver to use for quota checks quota_driver = barbican.quota.ConfDriver no_quota_limits_for=<project id1>,<project id2>... A positive number for the quota_<value> indicates the max limit for that resource and a negative value means unlimited. While these generic quotas applies to all projects, there will be also support to enforce quotas per project and quota classes. The priority in which the quotas are enforce is then: [per tenant quotas] => [per class quotas] => [default quotas] The default quotas are stored in the config file (as shown above) but the per-tenant/class quotas are store in db. A REST API for the quota CRUD operations will be implemented as well. The details of this is discussed in a later section below. Alternatives ------------ The quota configuration and logic are derived by looking at quota implementations done by other OpenStack projects like nova, cinder and neutron. It would be ideal if much of the quota management logic is refactored and made part of a reusable project. Looks like Kevin Mitchell from Rackspace has already made an effort towards that: https://wiki.openstack.org/wiki/Boson Data model impact ----------------- The following new data models will be added: * Quota Represents a single quota override for a project. If there is no row for a given project id and resource, then the default for the quota class is used. If there is no row for a given quota class and resource, then the default for the deployment is used. If the row is present but the hard limit is Null, then the resource is unlimited. Schema: (table name: **quotas**) * id: Integer, Primary Key * project_id: String(255) * resource: String(255), nullable=False * hard_limit: Integer **Contraints**: project_id + resource should be unique * QuotaClass Represents a single quota override for a quota class. If there is no row for a given quota class and resource, then the default for the deployment is used. If the row is present but the hard limit is Null, then the resource is unlimited. Schema: (table name: **quota_classes**) * id: Integer, Primary Key * class_name: String(255), nullable=False * resource: String(255), nullable=False * hard_limit: Integer **Contraints**: class_name + resource should be unique * ProjectClass Associates a project with a particular class Ideally, the auth middleware (keystone) should supply the class that a project belongs to. This could be removed once keystone supplies that detail. Schema: (table name: **project_class**) * id: Integer, Primary Key * project_id: String(255), nullable=False * class_name: String(255), nullable=False **Contraints**: project_id + class_name should be unique A new Alembic migration version script will be added which will add the models to existing Barbican deployments. * Changes to existing models: No existing models will be impacted by this addition. However, it needs to be investigated if new indexes need to be built to speed up resource consumption lookups. REST API impact --------------- The following new REST API will be implemented to manage quotas CRUD operations: * List quotas * Returns a list of all resource quotas for the project. If there are no project specific quotas, returns the class specific quota. If the project has no associated class, returns the deployment default resource limits. * GET v2/quotas * Normal http response code(s) 200 OK * Expected error http response code(s) * 401 Unauthorized - If the auth token is not present or invalid * 404 Not Found - If using unauthenticated context and X-Project-Id header is not present in the request * Required request headers X-Auth-Token, if using keystone auth X-Project-Id, if using unauthenticated context * Parameters class=""<class name>"", optional. If specified, lists quotas for the specified class. Requires the caller to have Barbican admin role * JSON schema definition for the body data if allowed None * JSON schema definition for the response data if any common_quota = { 'type': ['integer', 'string'], 'pattern': '^-?[0-9]+$', # -1 is a flag value for unlimited 'minimum': -1 } EXAMPLE:: { 'type': 'object', 'properties': { 'type': 'object' 'quotas': { 'properties': { 'secrets': common_quota, 'orders': common_quota, 'containers': common_quota, 'transport_keys': common_quota }, 'additionalProperties': False } }, 'additionalProperties': False } * Example 1:: A non-admin user checking the resource quotas using a token scoped to a particular project Request: GET /v2/quotas X-Auth-Token:<token> Response: 200 OK Content-Type: application/json { ""quotas"": { ""secrets"": 10, ""orders"": 20, ""containers"": 10, ""transport_keys"": 50 } } * Example 2:: An admin user checking the default resource quotas Request: GET /v2/quotas?class=default X-Auth-Token:<token> Response: 200 OK Content-Type: application/json { ""quotas"": { ""secrets"": 5, ""orders"": 10, ""containers"": 5, ""transport_keys"": 25 } } * List quotas for a specific project (admin only) * Returns a list of all resource quotas for the specified project. If there are no project specific quotas, returns the class specific quota. If the project has no associated class, returns the deployment default resource limits. * GET v2/quotas/{project_id} * Normal http response code(s) 200 OK * Expected error http response code(s) * 401 Unauthorized - If the auth token is not present or invalid * 404 Not Found - If using unauthenticated context and X-Project-Id header is not present in the request * Required request headers X-Auth-Token, if using keystone auth *Note:* the caller should have barbican admin role X-Project-Id, if using unauthenticated context * JSON schema definition for the body data if allowed None * JSON schema definition for the response data if any common_quota = { 'type': ['integer', 'string'], 'pattern': '^-?[0-9]+$', # -1 is a flag value for unlimited 'minimum': -1 } Example:: { 'type': 'object', 'properties': { 'type': 'object' 'quotas': { 'properties': { 'secrets': common_quota, 'orders': common_quota, 'containers': common_quota, 'transport_keys': common_quota }, 'additionalProperties': False } }, 'additionalProperties': False } * Example:: Request: GET /v2/quotas/1234 X-Auth-Token:<token> Response: 200 OK Content-Type: application/json { ""quotas"": { ""secrets"": 10, ""orders"": 20, ""containers"": 10, ""transport_keys"": 50 } } * Update/Set quotas for a specific project (admin only) * Updates and returns a list of resource quotas for the specified project. It is not required to specify limits for all Barbican resources. If a resource is not specified, the class/default limits are used for that resource. * PATCH v2/quotas/{project_id} * Normal http response code(s) 200 OK * Expected error http response code(s) * 401 Unauthorized - If the auth token is not present or invalid * 404 Not Found - If using unauthenticated context and X-Project-Id header is not present in the request * 400 Bad Request - If the request payload doesn't confirm to schema * Required request headers X-Auth-Token, if using keystone auth *Note:* the caller should have barbican admin role X-Project-Id, if using unauthenticated context * JSON schema definition for the body data if allowed:: { 'type': 'object', 'properties': { 'type': 'object' 'quotas': { 'properties': { 'secrets': common_quota, 'orders': common_quota, 'containers': common_quota, 'transport_keys': common_quota }, 'additionalProperties': False } }, 'additionalProperties': False } * JSON schema definition for the response data if any common_quota = { 'type': ['integer', 'string'], 'pattern': '^-?[0-9]+$', # -1 is a flag value for unlimited 'minimum': -1 } Example:: { 'type': 'object', 'properties': { 'type': 'object' 'quotas': { 'properties': { 'secrets': common_quota, 'orders': common_quota, 'containers': common_quota, 'transport_keys': common_quota }, 'additionalProperties': False } }, 'additionalProperties': False } * Example:: Request: PATCH /v2/quotas/1234 X-Auth-Token:<token> Body:: { ""quotas"": { ""secrets"": 50, ""transport_keys"": 100 } } Response: 200 OK Content-Type: application/json { ""secrets"": 50, ""orders"": 20, ""containers"": 10, ""transport_keys"": 100 } * Delete quotas for a specific project (admin only) * Deletes project specific resource quotas for the specified project. After this call succeeds, the class/default resource quotas will be returned for subsequent calls to list the project quotas. * DELETE v2/quotas/{project_id} * Normal http response code(s) 204 No Content * Expected error http response code(s) * 401 Unauthorized - If the auth token is not present or invalid * 404 Not Found - If using unauthenticated context and X-Project-Id header is not present in the request * Required request headers X-Auth-Token, if using keystone auth *Note:* the caller should have barbican admin role X-Project-Id, if using unauthenticated context * Parameters None * JSON schema definition for the body data if allowed None * JSON schema definition for the response data if any None * Example:: Request: DELETE /v2/quotas/1234 X-Auth-Token:<token> Response: 204 No Content * Policy changes For all admin-only APIs, the caller is expected to have a barbican admin role. The check for this will be added to the Barbican policy.json Once implemented and enforced, all Barbican resource creation API could return a new error message back to the client if the request exceeded the allowed quota limits. Example:: Request:: POST /v2/secrets X-Auth-Token: <token> Content-Type: application/json { # payload to create secret } Response:: 403 Forbidden Retry-After: 0 Content-Type: application/json { ""error"": ""Quota exceeded for <project-id>. Only <count> <resource>s are allowed"" } Security impact --------------- None Notifications & Audit Impact ---------------------------- None Other end user impact --------------------- The Barbican client (python-barbicanclient) has to be enhanced to consume the Quota REST API mentioned. The following scenarios should be supported. Quota commands that a regular non-admin barbican user can make: * List all quotas barbican quota show Quota commands that only a barbican admin can make * List the default quotas applicable to all new projects barbican quota show --class default * List quotas for a specific project barbican quota show --project_id <project> * Update quotas for a specific project barbican quota update --project_id <project> --secrets 50 --orders 10 * Delete per-project quotas for a project barbican quota delete --project_id <project> Performance Impact ------------------ TBD Other deployer impact --------------------- The new data models introduced will be added by a new Alembic version file. If automatic migration is turned OFF, the db migration tool has to be run manually to effect the changes. Developer impact ---------------- Developers integrating with Barbican API/client now need to handle the case where the server could return a quota violation error Implementation ============== Assignee(s) ----------- Venkat Sundaram (tsv) will be leading the implementation of the code. Primary assignee: <tsv> Other assignees: <meera> Work Items ---------- * Quota driver source code (tsv) * Data model additions (tsv) * Updated default config file with quota section (tsv) * Alembic migration version file (tsv) * python-barbicanclient enhancements to support quota operations (tsv) * New unit tests to test quota related source changes (tsv) * Update existing resource unit tests to handle quota violation errors (tsv) * Functional tests (meera) Dependencies ============ TBD Testing ======= New functional tests and tempest tests need to be added. Details TBD Documentation Impact ==================== * A new section about Quotas has to be documented * Existing resource API documentation needs to be updated with quota violation specific errors References ========== TBD ",,709,0
openstack%2Ffuel-web~master~I5e51bd2bad878871047675a3d9a9d326cbc60938,openstack/fuel-web,master,I5e51bd2bad878871047675a3d9a9d326cbc60938,Contact Support link update,MERGED,2015-05-20 14:42:11.000000000,2015-05-20 15:50:10.000000000,2015-05-20 15:38:37.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}]","[{'number': 1, 'created': '2015-05-20 14:42:11.000000000', 'files': ['nailgun/static/js/views/support_page.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/403c6b7ea3c62bb4fda27eb9cedee37f7144558c', 'message': 'Contact Support link update\n\nCloses-Bug:#1457063\n\nChange-Id: I5e51bd2bad878871047675a3d9a9d326cbc60938\n'}]",0,184513,403c6b7ea3c62bb4fda27eb9cedee37f7144558c,12,5,1,9730,,,0,"Contact Support link update

Closes-Bug:#1457063

Change-Id: I5e51bd2bad878871047675a3d9a9d326cbc60938
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/13/184513/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/support_page.jsx'],1,403c6b7ea3c62bb4fda27eb9cedee37f7144558c,bug/1457063, <a className='btn' href='http://support.mirantis.com/requests/new' target='_blank'>, <a className='btn' href='http://support.mirantis.com' target='_blank'>,1,1
openstack%2Ftripleo-heat-templates~master~Id81f315768edd24b8978b8de7093e04904591ce2,openstack/tripleo-heat-templates,master,Id81f315768edd24b8978b8de7093e04904591ce2,Set up corosync using hostnames rather than IPs,MERGED,2015-04-27 12:09:48.000000000,2015-05-20 15:40:43.000000000,2015-05-20 15:40:43.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8399}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-04-27 12:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ad8da601c85c811e287eb4f28b067e1aeabaa10b', 'message': 'Set up corosync using hostnames rather than IPs\n\nThis ensures that the hosts in Corosync and in Pacemaker are the same,\nto make our cluster setup compatible with the recommended architecture.\n\nChange-Id: Id81f315768edd24b8978b8de7093e04904591ce2\nCloses-Bug: #1447497\nDepends-On: Ia8582883f737548e2911d3f36a1943e5b236281b\n'}, {'number': 2, 'created': '2015-04-28 11:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/78729b6da5305c2e0e88d28610c34f64213ab288', 'message': 'Set up corosync using hostnames rather than IPs\n\nThis ensures that the hosts in Corosync and in Pacemaker are the same,\nto make our cluster setup compatible with the recommended architecture.\n\nChange-Id: Id81f315768edd24b8978b8de7093e04904591ce2\nCloses-Bug: #1447497\nDepends-On: Idb9ad017ffb1048f38fedbd55cc974785f6b1c38\n'}, {'number': 3, 'created': '2015-04-29 14:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1e76ba7aebd14dceab399e45d711e360fa07cda0', 'message': 'Set up corosync using hostnames rather than IPs\n\nThis ensures that the hosts in Corosync and in Pacemaker are the same,\nto make our cluster setup compatible with the recommended architecture.\n\nChange-Id: Id81f315768edd24b8978b8de7093e04904591ce2\nCloses-Bug: #1447497\nDepends-On: Idb9ad017ffb1048f38fedbd55cc974785f6b1c38\n'}, {'number': 4, 'created': '2015-05-13 13:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6c80b7f9fafbff98c3a91d61545963ea4445a97d', 'message': 'Set up corosync using hostnames rather than IPs\n\nThis ensures that the hosts in Corosync and in Pacemaker are the same,\nto make our cluster setup compatible with the recommended architecture.\n\nChange-Id: Id81f315768edd24b8978b8de7093e04904591ce2\nCloses-Bug: #1447497\nDepends-On: Idb9ad017ffb1048f38fedbd55cc974785f6b1c38\n'}, {'number': 5, 'created': '2015-05-18 08:21:01.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/344c1593196ad6bf2fcbe8679d5d798c5f276015', 'message': 'Set up corosync using hostnames rather than IPs\n\nThis ensures that the hosts in Corosync and in Pacemaker are the same,\nto make our cluster setup compatible with the recommended architecture.\n\nChange-Id: Id81f315768edd24b8978b8de7093e04904591ce2\nCloses-Bug: #1447497\nDepends-On: Idb9ad017ffb1048f38fedbd55cc974785f6b1c38\n'}]",1,177735,344c1593196ad6bf2fcbe8679d5d798c5f276015,47,8,5,8042,,,0,"Set up corosync using hostnames rather than IPs

This ensures that the hosts in Corosync and in Pacemaker are the same,
to make our cluster setup compatible with the recommended architecture.

Change-Id: Id81f315768edd24b8978b8de7093e04904591ce2
Closes-Bug: #1447497
Depends-On: Idb9ad017ffb1048f38fedbd55cc974785f6b1c38
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/35/177735/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller.pp', 'puppet/all-nodes-config.yaml']",2,ad8da601c85c811e287eb4f28b067e1aeabaa10b,bug/1447497," controller_node_names: list_join: - ',' - {get_param: controller_names}",,5,1
openstack%2Fnova-specs~master~Ifd37410ea0009d2ee8a5720461377bef6e83eb18,openstack/nova-specs,master,Ifd37410ea0009d2ee8a5720461377bef6e83eb18,Cells: Add host mapping table and object,MERGED,2015-05-13 15:24:21.000000000,2015-05-20 15:28:18.000000000,2015-05-20 15:28:17.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 7166}]","[{'number': 1, 'created': '2015-05-13 15:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2cd9f4903016c44690c42eeee39512f853f037ab', 'message': 'Cells: Add host mapping table and object\n\nIn order to properly route RPC messages or database updates to the\nproper cell when given just a host we need a mapping of host to cell.\nWe will be provided only a host by the scheduler or for Host API\nrequests.\n\nChange-Id: Ifd37410ea0009d2ee8a5720461377bef6e83eb18\n'}, {'number': 2, 'created': '2015-05-18 17:27:58.000000000', 'files': ['specs/liberty/approved/cells-host-mapping.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b427a33326d6ff37c50a1efa8f314fcc5b13a315', 'message': 'Cells: Add host mapping table and object\n\nIn order to properly route RPC messages or database updates to the\nproper cell when given just a host we need a mapping of host to cell.\nWe will be provided only a host by the scheduler or for Host API\nrequests.\n\nChange-Id: Ifd37410ea0009d2ee8a5720461377bef6e83eb18\n'}]",4,182715,b427a33326d6ff37c50a1efa8f314fcc5b13a315,11,5,2,5441,,,0,"Cells: Add host mapping table and object

In order to properly route RPC messages or database updates to the
proper cell when given just a host we need a mapping of host to cell.
We will be provided only a host by the scheduler or for Host API
requests.

Change-Id: Ifd37410ea0009d2ee8a5720461377bef6e83eb18
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/15/182715/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/approved/cells-host-mapping.rst'],1,2cd9f4903016c44690c42eeee39512f853f037ab,cells_host_mapping,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================== Cells host mapping ================== https://blueprints.launchpad.net/nova/+spec/cells-host-mapping Since the scheduler will return a host rather than a cell we need to know which cell that host is in. A new table will be created which can store this mapping. Problem description =================== When Nova is partitioned into cells, the compute api needs to know which cell to communicate with in order to build a scheduled instance, or for host API requests. There is currently no mapping of host to cell so given just a host there is no way to know how to pass information to that host. Use Cases ---------- * Operators want to partition their deployments into cells for scaling, failure domain, and buildout reasons. When partitioned, we need a lookup table to know which partition a host is in. Project Priority ----------------- Priorities have not been decided for Liberty. Proposed change =============== The change being proposed is a new table in the 'nova_api' database for storing a mapping of host to cell and an object to interact with it. Migration of data into this table will be tackled in a separate spec. The following diagram may help visualize it.:: api/cell boundary scheduler returns a host | | | v | nova-api+-------------------->cell-db/rpc + + | | +----+ | | | | v v | host_mapping cell_mapping | Alternatives ------------ We could continue to use the nova-cells model in place today. Data model impact ----------------- A new 'host_mapping' table will be added to the 'nova_api' database. The table will look like::: CREATE TABLE `host_mapping` ( `created_at` datetime DEFAULT NULL, `updated_at` datetime DEFAULT NULL, `id` int(11) NOT NULL AUTO_INCREMENT, `host` varchar(255) NOT NULL, `cell_uuid` varchar(36) NOT NULL) And host will be an indexed column. Other indexes are possible as well and can be discussed in the code review. It should be noted that there is no 'deleted' or 'deleted_at' column here. If a host exists it should be mapped, it should only be deleted if the host is being permanently removed in which case there is no reason to keep it here. REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ On its own this change does not introduce a performance impact. When it's used by later specs it does introduce another database lookup for some actions within Nova. Other deployer impact --------------------- This introduces a new table into the 'nova_api' database. And as described in the ""Data model impact"" section above it should be considered when running any cleanup of hosts. If hosts are removed from a deployment they can be removed from the host_mapping table as well. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: alaski Other contributors: None Work Items ---------- * Add database migration for 'host_mapping' table. * Add HostMapping object. Dependencies ============ None Testing ======= Since this is designed to be an internal re-architecting of Nova with no user visible changes the current suite of Tempest or functional tests should suffice. At some point we will want to look at how to test multiple cells or potentially exposing the concept of a cell in the API and we will tackle testing requirements then. Documentation Impact ==================== Documentation should be added about the new table and what its usage will be. References ========== ``https://etherpad.openstack.org/p/kilo-nova-cells`` ",,173,0
openstack%2Foslo-specs~master~I42106f4948279984b4dc037ca17eb9bc1cbc8207,openstack/oslo-specs,master,I42106f4948279984b4dc037ca17eb9bc1cbc8207,oslo.messaging: remove double reply,MERGED,2015-05-07 14:13:57.000000000,2015-05-20 15:26:36.000000000,2015-05-20 15:26:33.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 7491}, {'_account_id': 13290}, {'_account_id': 14421}]","[{'number': 1, 'created': '2015-05-07 14:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/d70141094369ce67f03c2e68ec30df4938446c86', 'message': 'oslo.messaging: remove double reply\n\nChange-Id: I42106f4948279984b4dc037ca17eb9bc1cbc8207\n'}, {'number': 2, 'created': '2015-05-08 09:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/0f2afa525197c50466f29a4c11f57fc90a79504b', 'message': 'oslo.messaging: remove double reply\n\nCurrently, when we are  waiting for a RPC reply, for each call we\nreceive two AMQP messages - first one with the payload, a second one\nto ensure the other have finish to send the payload.\n\nWe are going to remove the second message for RPC reply.\n\nCo-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>\n\nChange-Id: I42106f4948279984b4dc037ca17eb9bc1cbc8207\n'}, {'number': 3, 'created': '2015-05-08 14:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/977229830524dda12a1e27f11a4b8c91752deedf', 'message': 'oslo.messaging: remove double reply\n\nCurrently, when we are  waiting for a RPC reply, for each call we\nreceive two AMQP messages - first one with the payload, a second one\nto ensure the other have finish to send the payload.\n\nWe are going to remove the second message for RPC reply.\n\nCo-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>\n\nChange-Id: I42106f4948279984b4dc037ca17eb9bc1cbc8207\n'}, {'number': 4, 'created': '2015-05-14 09:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/da527141798873900e385e0170239d160f33d7ae', 'message': 'oslo.messaging: remove double reply\n\nCurrently, when we are  waiting for a RPC reply, for each call we\nreceive two AMQP messages - first one with the payload, a second one\nto ensure the other have finish to send the payload.\n\nWe are going to remove the second message for RPC reply.\n\nCo-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>\n\nChange-Id: I42106f4948279984b4dc037ca17eb9bc1cbc8207\n'}, {'number': 5, 'created': '2015-05-14 09:10:46.000000000', 'files': ['specs/liberty/oslo.messaging-remove-double-reply.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/12014f2e5ffb4c83c7f56c7513833e5f42ad9628', 'message': 'oslo.messaging: remove double reply\n\nCurrently, when we are  waiting for a RPC reply, for each call we\nreceive two AMQP messages - first one with the payload, a second one\nto ensure the other have finish to send the payload.\n\nWe are going to remove the second message for RPC reply.\n\nCo-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>\n\nChange-Id: I42106f4948279984b4dc037ca17eb9bc1cbc8207\n'}]",25,181010,12014f2e5ffb4c83c7f56c7513833e5f42ad9628,32,9,5,2813,,,0,"oslo.messaging: remove double reply

Currently, when we are  waiting for a RPC reply, for each call we
receive two AMQP messages - first one with the payload, a second one
to ensure the other have finish to send the payload.

We are going to remove the second message for RPC reply.

Co-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>

Change-Id: I42106f4948279984b4dc037ca17eb9bc1cbc8207
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/10/181010/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/oslo.messaging-remove-double-reply.rst'],1,d70141094369ce67f03c2e68ec30df4938446c86,remove-double-reply,"===================================================== oslo.messaging: remove ending message for rpc reply ===================================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/oslo.messaging?searchtext=remove-double-reply Problem description =================== Currently, when we wait for a rpc reply, for each msg_id we receive two amqp messages - first one with the payload, a second one to ensure the other have finish to send the payload. This was made, because a long time ago 'reply' allowed generator as payload to send multiple messages on one 'rpc.call' - [1] It becomes useless to double RPC messages for each call, so we are going to remove this the second AMQP message sending. This change will be not backward compatible, so we have to choice how we handle this backward compatibility and the deprecation. This specs is the proposed change about that. Proposed change =============== * In liberty: We change the ReplyWaiters to handle reply in one message and two messages. (Like does https://review.openstack.org/#/c/180583/) We create a hidden boolean configuration option, defaulted to False. If this one is True, we sent the reply in one message otherwise we keep the current behavior of two messages. This configuration option will allow us to test the old and the future behavior into our tests suite. And deployer to switch to this new behavior earlier. * In L+2: (L+1 ???) We remove this option and support only the reply in one message. This will break backward compatibility with oslo.messaging<=kilo and oslo-incubator rpc legacy code. Alternatives ------------ * Using the oslo.messaging payload version but this have been designed for the content of the message itself. Not really for this purpose. And the deserialization occurs in lower layer of oslo.messaging. When we handle the reply the version fields have already been removed. This breaks backward compatibility too. We can already track the old and the new format because the old format have the attribut ""result"" OR ""ending"" the new one will have ""result"" AND ""ending"". * Any other idea are welcome. Note that issue is in the rpc call replies code. In case of rolling upgrade, we have to think about the fact that the client will wait message that can come from same or upper version of oslo.messaging. We already do not support lower version from the application PoV. Or from the server point of view, we will sent reply that must be understandable by a wide panel of versions. This is the first time (I guess), we encounter this kind of issue, some other bugs need to break the backward compatibility to be fixed, too. (Because we need to change rabbitmq queue attributes, or move a queue to another exchange) The main goal is to choice the version limit for backward compatibility and use the same king of deprecation in other change like this one. Impact on Existing APIs ----------------------- NA Security impact --------------- NA Performance Impact ------------------ This will reduce by 2 the number of reply messages that will transit on a RabbitMQ/QPID cluster. Configuration Impact -------------------- A hidden configuration option will allow to switch to the future behavior for early adopter and for testing purpose. Developer Impact ---------------- NA Testing Impact -------------- We must test that the new ReplyWaiters code can handle reply that come from a oslo.messaging version that sent reply in one message and from the one that sent the reply into two messages. Implementation ============== Assignee(s) ----------- Primary assignee: vsergeyev Other contributors: sileht Milestones ---------- Target Milestone for completion: Liberty for the step 1 M or N for the step 2 Work Items ---------- Incubation ========== NA Documentation Impact ==================== Inform deployer about futur incompatibilly with a too old oslo.messaging version Dependencies ============ NA References ========== WIP reviews: * https://review.openstack.org/#/c/180542/ * https://review.openstack.org/#/c/180583/ Legacy oslo rpc behavior [1]: https://github.com/openstack/oslo-incubator/blob/stable/icehouse/openstack/common/rpc/amqp.py#L464 .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,169,0
openstack%2Foslo.cache~master~I588a5fee5f92448ee9a0905a0973abc42e44d0b0,openstack/oslo.cache,master,I588a5fee5f92448ee9a0905a0973abc42e44d0b0,Get project basics configured,MERGED,2015-05-14 16:56:04.000000000,2015-05-20 15:24:28.000000000,2015-05-20 15:24:27.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-14 16:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/5a8d3e24bbd24ae705e9c00d6ed782310e141e6a', 'message': 'Update the README to reflect the scope and intent\n\n - Wrapping dogpile.cache\n - Supporting cache backends and memoization\n\nChange-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0\n'}, {'number': 2, 'created': '2015-05-14 20:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/3c7b5c2428761ff2e32ac6d1a10d6e6900ef7ea6', 'message': 'Get project basics configured\n\n - Update the README\n   - Wrapping dogpile.cache\n   - Supporting cache backends and memoization\n - Add a Makefile for bootstrapping an running the tests.\n - Add a dev_requirements.txt for installing test / dev requirements\n - Fix template test import to use oslocache.base.BaseTestCase\n\nChange-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0\n'}, {'number': 3, 'created': '2015-05-14 20:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/93757250bbb42dde48075cb4a9ecb082ce3d640a', 'message': 'Get project basics configured\n\n - Update the README\n   - Wrapping dogpile.cache\n   - Supporting cache backends and memoization\n - Add a Makefile for bootstrapping an running the tests.\n - Add a dev_requirements.txt for installing test / dev requirements\n - Fix template test import to use oslocache.base.BaseTestCase\n\nChange-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0\n'}, {'number': 4, 'created': '2015-05-14 20:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/fa2ea4e72b0d6f479e5548e442224500af3d2f2e', 'message': 'Get project basics configured\n\n - Update the README\n   - Wrapping dogpile.cache\n   - Supporting cache backends and memoization\n - Add a Makefile for bootstrapping an running the tests.\n - Add a dev_requirements.txt for installing test / dev requirements\n - Fix template test import to use oslocache.base.BaseTestCase\n\nChange-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0\n'}, {'number': 5, 'created': '2015-05-14 21:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/d6b655d389f0981356fe86fe14b462ce99a3c217', 'message': 'Get project basics configured\n\n - Update the README\n   - Wrapping dogpile.cache\n   - Supporting cache backends and memoization\n - Add a Makefile for bootstrapping an running the tests.\n - Add a dev_requirements.txt for installing test / dev requirements\n - Fix template test import to use oslocache.base.BaseTestCase\n\nChange-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0\n'}, {'number': 6, 'created': '2015-05-15 20:23:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/5df00fc133854f9ea6b463309af5e619583802da', 'message': 'Get project basics configured\n\n - Update the README\n   - Wrapping dogpile.cache\n   - Supporting cache backends and memoization\n - Add a Makefile for bootstrapping an running the tests, pep and\n   generating docs.\n - Add a test-requirements.txt for installing test / dev requirements\n - Fix template test import to use oslocache.base.BaseTestCase\n\nChange-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0\n'}, {'number': 7, 'created': '2015-05-15 20:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/b94cf77ed3563960c639a648e25f67f0470b2745', 'message': 'Get project basics configured\n\n - Update the README\n   - Wrapping dogpile.cache\n   - Supporting cache backends and memoization\n - Add a Makefile for bootstrapping an running the tests, pep and\n   generating docs.\n - Add a test-requirements.txt\n - Add a dev-requirements.txt for tox\n - Fix template test import to use oslocache.base.BaseTestCase\n\nChange-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0\n'}, {'number': 8, 'created': '2015-05-15 20:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/3ec6e98784048fa32ccfc965536310d69a5056d8', 'message': 'Get project basics configured\n\n - Update the README\n   - Wrapping dogpile.cache\n   - Supporting cache backends and memoization\n - Add a Makefile for bootstrapping an running the tests, pep and\n   generating docs.\n - Add a test-requirements.txt\n - Add a dev-requirements.txt for tox\n - Fix template test import to use oslocache.base.BaseTestCase\n\nChange-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0\n'}, {'number': 9, 'created': '2015-05-15 21:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/320e8e88e69c3c9f9b1cd7c73f86e0c33899aef9', 'message': 'Get project basics configured\n\n - Update the README\n   - Wrapping dogpile.cache\n   - Supporting cache backends and memoization\n - Add a Makefile for bootstrapping an running the tests, pep and\n   generating docs.\n - Add a test-requirements.txt\n - Add a dev-requirements.txt for tox\n - Update requirements from initial requirements in the template\n - Fix template test import to use oslocache.base.BaseTestCase\n\nChange-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0\n'}, {'number': 10, 'created': '2015-05-15 21:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/9592f04f7a5363c8a95ef940d3fb87d0fff6d7ff', 'message': 'Get project basics configured\n\n - Update the README\n   - Wrapping dogpile.cache\n   - Supporting cache backends and memoization\n - Add a Makefile for bootstrapping an running the tests, pep and\n   generating docs.\n - Add a test-requirements.txt\n - Add a dev-requirements.txt for tox\n - Update requirements from initial requirements in the template\n - Fix template test import to use oslocache.base.BaseTestCase\n\nChange-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0\n'}, {'number': 11, 'created': '2015-05-18 13:57:46.000000000', 'files': ['dev-requirements.txt', 'requirements.txt', 'oslo_cache/tests/test_cache.py', 'test-requirements.txt', 'README.rst'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/89edc9bed279b55e0bb83754d9ea35c5a53ec76f', 'message': 'Get project basics configured\n\n - Update the README\n   - Wrapping dogpile.cache\n   - Supporting cache backends and memoization\n - Add a test-requirements.txt\n - Add a dev-requirements.txt for tox\n - Update requirements from initial requirements in the template\n - Fix template test import to use oslocache.base.BaseTestCase\n\nChange-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0\n'}]",1,183108,89edc9bed279b55e0bb83754d9ea35c5a53ec76f,29,3,11,15171,,,0,"Get project basics configured

 - Update the README
   - Wrapping dogpile.cache
   - Supporting cache backends and memoization
 - Add a test-requirements.txt
 - Add a dev-requirements.txt for tox
 - Update requirements from initial requirements in the template
 - Fix template test import to use oslocache.base.BaseTestCase

Change-Id: I588a5fee5f92448ee9a0905a0973abc42e44d0b0
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/08/183108/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,5a8d3e24bbd24ae705e9c00d6ed782310e141e6a,readme-update,"==================== `oslo.cache` aims to provide a generic caching mechanism for OpenStack projects by wrapping the `dogpile.cache <http://dogpilecache.readthedocs.org/en/latest/>`_ library. The dogpile.cache library provides support memoization, key value storage and interfaces to common caching backends such as `Memcached <http://www.memcached.org/>`_. ",====================================================================== Cache storage for Openstack projects.,9,3
openstack%2Ffuel-qa~master~I7b3a3ceba4859b6ce4a3af95dbbeba040abd8fff,openstack/fuel-qa,master,I7b3a3ceba4859b6ce4a3af95dbbeba040abd8fff,Split bootstrap of 9 slaves into two stages,MERGED,2015-05-20 12:54:09.000000000,2015-05-20 15:22:40.000000000,2015-05-20 15:22:39.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 12867}, {'_account_id': 13306}, {'_account_id': 15005}]","[{'number': 1, 'created': '2015-05-20 12:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/95bf509f611086e45c31ed22bb166a7a3c7651ac', 'message': 'Split bootstrap of 9 slaves into two stages\n\nBootstrapping 9 slaves at one time reqires a lot of CPU power\n(>=10 real CPU cores), so it is better to bootstrap nodes in\ntwo stages to avoit timeouts and libvirt network failures.\n\nChange-Id: I7b3a3ceba4859b6ce4a3af95dbbeba040abd8fff\nCloses-Bug:#1455539\n'}, {'number': 2, 'created': '2015-05-20 12:57:04.000000000', 'files': ['fuelweb_test/tests/base_test_case.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/78d09b20eb3042d9b83e5bd36d8be5946e8c2721', 'message': 'Split bootstrap of 9 slaves into two stages\n\nBootstrapping 9 slaves at one time reqires a lot of CPU power\n(>=10 real CPU cores), so it is better to bootstrap nodes in\ntwo stages to avoid timeouts and libvirt network failures.\n\nChange-Id: I7b3a3ceba4859b6ce4a3af95dbbeba040abd8fff\nCloses-Bug:#1455539\n'}]",0,184475,78d09b20eb3042d9b83e5bd36d8be5946e8c2721,16,9,2,11969,,,0,"Split bootstrap of 9 slaves into two stages

Bootstrapping 9 slaves at one time reqires a lot of CPU power
(>=10 real CPU cores), so it is better to bootstrap nodes in
two stages to avoid timeouts and libvirt network failures.

Change-Id: I7b3a3ceba4859b6ce4a3af95dbbeba040abd8fff
Closes-Bug:#1455539
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/75/184475/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/base_test_case.py'],1,95bf509f611086e45c31ed22bb166a7a3c7651ac,bug/1455539," # Bootstrap 9 slaves in two stages to get lower load on the host self.env.bootstrap_nodes(self.env.d_env.nodes().slaves[:5], skip_timesync=True) self.env.bootstrap_nodes(self.env.d_env.nodes().slaves[5:9],"," self.env.bootstrap_nodes(self.env.d_env.nodes().slaves[:9],",4,1
openstack%2Fpuppet-sahara~master~I3a14cb1e742ba376265149191c2c4bae03f5148e,openstack/puppet-sahara,master,I3a14cb1e742ba376265149191c2c4bae03f5148e,Idempotency fix,MERGED,2015-05-18 18:36:29.000000000,2015-05-20 15:18:07.000000000,2015-05-20 15:18:07.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}]","[{'number': 1, 'created': '2015-05-18 18:36:29.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/9de78136d18d9ea9b821f2da0a6c24428611c64b', 'message': 'Idempotency fix\n\nTo keep Puppet run idempotent we have to avoid changing SELinux labels.\n\nChange-Id: I3a14cb1e742ba376265149191c2c4bae03f5148e\n'}]",0,184106,9de78136d18d9ea9b821f2da0a6c24428611c64b,7,3,1,5241,,,0,"Idempotency fix

To keep Puppet run idempotent we have to avoid changing SELinux labels.

Change-Id: I3a14cb1e742ba376265149191c2c4bae03f5148e
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/06/184106/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,9de78136d18d9ea9b821f2da0a6c24428611c64b,bug/1444736," ensure => directory, owner => 'root', group => 'sahara', require => Group['sahara'], selinux_ignore_defaults => true owner => 'root', group => 'sahara', require => File['/etc/sahara'], selinux_ignore_defaults => true"," ensure => directory, owner => 'root', group => 'sahara', require => Group['sahara'] owner => 'root', group => 'sahara', require => File['/etc/sahara']",9,7
openstack%2Fopenstacksdk~master~Iaa45fce0c8aacc9315070f8525a13f2e43f05a9e,openstack/openstacksdk,master,Iaa45fce0c8aacc9315070f8525a13f2e43f05a9e,Move from UserPreference to Profile,MERGED,2015-05-18 05:30:21.000000000,2015-05-20 15:05:55.000000000,2015-05-20 15:05:54.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-18 05:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/68a1b3749fecd77093e7ea18a2e14ba6feb641cd', 'message': 'Move from UserPreference to Profile\n\nThis is just a big name swap to move away from UserPreference to Profile\nso it can be properly referenced in the summit talk. See #1435953\n\nChange-Id: Iaa45fce0c8aacc9315070f8525a13f2e43f05a9e\nCloses-Bug: 1435953\n'}, {'number': 2, 'created': '2015-05-18 05:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2127008095a5919e6a66029a359b5caa2cb2a34c', 'message': 'Move from UserPreference to Profile\n\nThis is just a big name swap to move away from UserPreference to Profile\nso it can be properly referenced in the summit talk. See #1435953\n\nChange-Id: Iaa45fce0c8aacc9315070f8525a13f2e43f05a9e\nCloses-Bug: 1435953\n'}, {'number': 3, 'created': '2015-05-18 23:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3ca209c81216517b67308c7d5098b546987bacfe', 'message': 'Move from UserPreference to Profile\n\nThis is just a big name swap to move away from UserPreference to Profile\nso it can be properly referenced in the summit talk. See #1435953\n\nChange-Id: Iaa45fce0c8aacc9315070f8525a13f2e43f05a9e\nCloses-Bug: 1435953\n'}, {'number': 4, 'created': '2015-05-18 23:50:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f27fca24afbcbfaa1591bd2e9947af2708d23309', 'message': 'Move from UserPreference to Profile\n\nThis is just a big name swap to move away from UserPreference to Profile\nso it can be properly referenced in the summit talk. See #1435953\n\nChange-Id: Iaa45fce0c8aacc9315070f8525a13f2e43f05a9e\nCloses-Bug: 1435953\n'}, {'number': 5, 'created': '2015-05-20 14:58:25.000000000', 'files': ['openstack/session.py', 'openstack/auth/service_filter.py', 'openstack/tests/unit/test_user_preference.py', 'doc/source/users/index.rst', 'examples/common.py', 'doc/source/users/userguides/usage.rst', 'openstack/connection.py', 'doc/source/users/profile.rst', 'openstack/tests/functional/base.py', 'openstack/tests/unit/test_connection.py', 'openstack/tests/unit/test_profile.py', 'openstack/profile.py', 'doc/source/users/user_preference.rst', 'examples/connection.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7fc1888d19cb8a66783545cc700be958ed918ff6', 'message': 'Move from UserPreference to Profile\n\nThis is just a big name swap to move away from UserPreference to Profile\nso it can be properly referenced in the summit talk. See #1435953\n\nChange-Id: Iaa45fce0c8aacc9315070f8525a13f2e43f05a9e\nCloses-Bug: 1435953\n'}]",2,183974,7fc1888d19cb8a66783545cc700be958ed918ff6,19,3,5,8257,,,0,"Move from UserPreference to Profile

This is just a big name swap to move away from UserPreference to Profile
so it can be properly referenced in the summit talk. See #1435953

Change-Id: Iaa45fce0c8aacc9315070f8525a13f2e43f05a9e
Closes-Bug: 1435953
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/74/183974/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/session.py', 'openstack/auth/service_filter.py', 'openstack/tests/unit/test_user_preference.py', 'doc/source/users/index.rst', 'doc/source/users/userguides/usage.rst', 'openstack/connection.py', 'doc/source/users/profile.rst', 'openstack/tests/functional/base.py', 'openstack/tests/unit/test_connection.py', 'openstack/tests/unit/test_profile.py', 'openstack/profile.py', 'doc/source/users/user_preference.rst']",12,68a1b3749fecd77093e7ea18a2e14ba6feb641cd,bug/1435953,,UserPreference ============== .. automodule:: openstack.user_preference UserPreference Object --------------------- .. autoclass:: openstack.user_preference.UserPreference :members: ,136,136
openstack%2Ftempest~master~Ibc6e6289c349e7b5caf0fea2d0485c8cc4b9c32a,openstack/tempest,master,Ibc6e6289c349e7b5caf0fea2d0485c8cc4b9c32a,Move identity_version to class level,MERGED,2015-05-12 15:40:51.000000000,2015-05-20 15:02:24.000000000,2015-05-20 15:02:22.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 8871}]","[{'number': 1, 'created': '2015-05-12 15:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/37f8ecff3576e21b4077359bad96beaea7edf941', 'message': 'Move identity_version to class level\n\nRather than having to setup the client manager by passing the identity\nversion, read the identity version from a class level attribute, so\nthat the identity version can be overwritten from there by the\nidentity tests.\n\nChange-Id: Ibc6e6289c349e7b5caf0fea2d0485c8cc4b9c32a\n'}, {'number': 2, 'created': '2015-05-12 16:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d8f1a5b350884d861c0774d04b61f36eff7347be', 'message': 'Move identity_version to class level\n\nRather than having to setup the client manager by passing the identity\nversion, read the identity version from a class level attribute, so\nthat the identity version can be overwritten from there by the\nidentity tests.\n\nChange-Id: Ibc6e6289c349e7b5caf0fea2d0485c8cc4b9c32a\n'}, {'number': 3, 'created': '2015-05-13 10:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/583f28394d37772225d4ab36b9d6dfe5238b59de', 'message': 'Move identity_version to class level\n\nRather than having to setup the client manager by passing the identity\nversion, read the identity version from a class level attribute, so\nthat the identity version can be overwritten from there by the\nidentity tests.\n\nChange-Id: Ibc6e6289c349e7b5caf0fea2d0485c8cc4b9c32a\n'}, {'number': 4, 'created': '2015-05-13 15:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/01a5faf90e92b8aa0572ca5402169239dadfcb71', 'message': 'Move identity_version to class level\n\nRather than having to setup the client manager by passing the identity\nversion, read the identity version from a class level attribute, so\nthat the identity version can be overwritten from there by the\nidentity tests.\n\nChange-Id: Ibc6e6289c349e7b5caf0fea2d0485c8cc4b9c32a\n'}, {'number': 5, 'created': '2015-05-13 19:05:39.000000000', 'files': ['tempest/api/identity/base.py', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4160141291a59a310c02cfd08066aa719e997d38', 'message': 'Move identity_version to class level\n\nRather than having to setup the client manager by passing the identity\nversion, read the identity version from a class level attribute, so\nthat the identity version can be overwritten from there by the\nidentity tests.\n\nChange-Id: Ibc6e6289c349e7b5caf0fea2d0485c8cc4b9c32a\n'}]",6,182356,4160141291a59a310c02cfd08066aa719e997d38,27,6,5,1921,,,0,"Move identity_version to class level

Rather than having to setup the client manager by passing the identity
version, read the identity version from a class level attribute, so
that the identity version can be overwritten from there by the
identity tests.

Change-Id: Ibc6e6289c349e7b5caf0fea2d0485c8cc4b9c32a
",git fetch https://review.opendev.org/openstack/tempest refs/changes/56/182356/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/identity/base.py', 'tempest/test.py']",2,37f8ecff3576e21b4077359bad96beaea7edf941,bp/resource-cleanup," if hasattr(cls, 'identity_version'): if cls.identity_version == 'v2': if not CONF.identity_feature_enabled.api_v2: raise cls.skipException(""Identity api v2 is not enabled"") elif cls.identity_version == 'v3': if not CONF.identity_feature_enabled.api_v3: raise cls.skipException(""Identity api v3 is not enabled"") identity_version = getattr(cls, 'identity_version', None)", :param identity_version: string - v2 or v3,16,23
openstack%2Ffuel-docs~stable%2F6.0~I6c33fde1ed3f9302f0a3c6f413e757d3e13d6124,openstack/fuel-docs,stable/6.0,I6c33fde1ed3f9302f0a3c6f413e757d3e13d6124,MOS-RN6.0-Updates3: Other resolved issues,MERGED,2015-05-15 10:29:26.000000000,2015-05-20 14:59:01.000000000,2015-05-20 14:59:01.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}, {'_account_id': 13609}, {'_account_id': 14168}, {'_account_id': 14643}]","[{'number': 1, 'created': '2015-05-15 10:29:26.000000000', 'files': ['pages/release-notes/v6-0/updates/9010-others.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d5112e6e2fa842aafa32b15452b9c7669ebb42c7', 'message': 'MOS-RN6.0-Updates3: Other resolved issues\n\nAdds a new resolved issue: SeaBIOS 1.8.1 built by GCC 4.5\nfixing FreeBSD boot\n\nChange-Id: I6c33fde1ed3f9302f0a3c6f413e757d3e13d6124\n'}]",1,183470,d5112e6e2fa842aafa32b15452b9c7669ebb42c7,12,6,1,14962,,,0,"MOS-RN6.0-Updates3: Other resolved issues

Adds a new resolved issue: SeaBIOS 1.8.1 built by GCC 4.5
fixing FreeBSD boot

Change-Id: I6c33fde1ed3f9302f0a3c6f413e757d3e13d6124
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/70/183470/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-0/updates/9010-others.rst'],1,d5112e6e2fa842aafa32b15452b9c7669ebb42c7,relnotes6.0-updates, * The SeaBIOS package for Ubuntu Precise Pangolin was updated to version 1.8.1 and is now compiled by the GCC 4.5. This fixes the FreeBSD boot issue and does not introduce any regressions. See `LP1435501 <https://bugs.launchpad.net/fuel/+bug/1435501>`_.,,5,0
openstack%2Ffuel-docs~stable%2F6.0~I451c160313ccf96bd4372998ea31dd92fcd5c143,openstack/fuel-docs,stable/6.0,I451c160313ccf96bd4372998ea31dd92fcd5c143,MOS-RN6.0-Updates3: Ceilometer resolved issues,MERGED,2015-05-15 10:20:01.000000000,2015-05-20 14:58:24.000000000,2015-05-20 14:58:24.000000000,"[{'_account_id': 3}, {'_account_id': 7729}, {'_account_id': 7732}, {'_account_id': 8971}, {'_account_id': 13082}, {'_account_id': 14643}, {'_account_id': 14645}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-05-15 10:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/b83a2776761b2c68ade53c7407891b27cf4c3836', 'message': ""MOS-RN6.0-Updates3: Ceilometer resolved issues\n\nAdds 2 new resolved issues:\n1) Potential memory leak in Ceilometer compute agent;\n2) python-ceilometerclient doesn't support os_endpoint_type.\n\nChange-Id: I451c160313ccf96bd4372998ea31dd92fcd5c143\n""}, {'number': 2, 'created': '2015-05-18 13:14:30.000000000', 'files': ['pages/release-notes/v6-0/updates/5010-ceilometer.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d3e35d7388853b73427880b3027927240bd0e865', 'message': ""MOS-RN6.0-Updates3: Ceilometer resolved issues\n\nAdds 2 new resolved issues:\n1) Potential memory leak in Ceilometer compute agent;\n2) python-ceilometerclient doesn't support os_endpoint_type.\n\nChange-Id: I451c160313ccf96bd4372998ea31dd92fcd5c143\n""}]",2,183467,d3e35d7388853b73427880b3027927240bd0e865,21,8,2,14962,,,0,"MOS-RN6.0-Updates3: Ceilometer resolved issues

Adds 2 new resolved issues:
1) Potential memory leak in Ceilometer compute agent;
2) python-ceilometerclient doesn't support os_endpoint_type.

Change-Id: I451c160313ccf96bd4372998ea31dd92fcd5c143
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/67/183467/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-0/updates/5010-ceilometer.rst'],1,b83a2776761b2c68ade53c7407891b27cf4c3836,relnotes6.0-updates," * When ``self.timer`` is set to ``False``, each request's time is not recorded anymore, and therefore, it doesn’t cause unexpected memory leak. See `LP1439278 <https://bugs.launchpad.net/mos/+bug/1439278>`_. * Previously, python-ceilometerclient didn't support the ``os_endpoint_type`` option for the keystone authentication. The bug fix adds this support. See `LP1449649 <https://bugs.launchpad.net/mos/+bug/1449649>`_.",,8,0
openstack%2Ffuel-docs~stable%2F6.0~I1c664be07af4dcf67d59bde2e46df60390839b53,openstack/fuel-docs,stable/6.0,I1c664be07af4dcf67d59bde2e46df60390839b53,MOS-RN6.0-Updates3: Neutron resolved issues,MERGED,2015-05-15 09:22:21.000000000,2015-05-20 14:57:54.000000000,2015-05-20 14:57:54.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7604}, {'_account_id': 8971}, {'_account_id': 13082}, {'_account_id': 14610}, {'_account_id': 14643}, {'_account_id': 14689}]","[{'number': 1, 'created': '2015-05-15 09:22:21.000000000', 'files': ['pages/release-notes/v6-0/updates/3010-neutron.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/cb2dd7fbda4f11ca4e55ae2c7eea59cda6efb8cb', 'message': 'MOS-RN6.0-Updates3: Neutron resolved issues\n\nAdds 2 resolved issues:\n1. Neutron get_subnet is slow;\n2. Do not set notification_driver by default.\n\nChange-Id: I1c664be07af4dcf67d59bde2e46df60390839b53\n'}]",0,183444,cb2dd7fbda4f11ca4e55ae2c7eea59cda6efb8cb,13,8,1,14962,,,0,"MOS-RN6.0-Updates3: Neutron resolved issues

Adds 2 resolved issues:
1. Neutron get_subnet is slow;
2. Do not set notification_driver by default.

Change-Id: I1c664be07af4dcf67d59bde2e46df60390839b53
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/44/183444/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-0/updates/3010-neutron.rst'],1,cb2dd7fbda4f11ca4e55ae2c7eea59cda6efb8cb,relnotes6.0-updates," * Neutron ``get_subnet`` method was eagerly loading all the allocation pools and availability range objects associated with a given subnet. It caused performance issues on large subnets. The behavior was changed to load these objects only when they are explicitly referenced. See `LP1438540 <https://bugs.launchpad.net/mos/+bug/1438540>`_. * Neutron doesn't have a default ``notification_driver`` parameter anymore. It is set by Puppet during deployment in the `neutron.conf` file if Ceilometer is enabled; otherwise, the parameter is set twice and causes duplicated messages in the RabbitMQ queue. See `LP1443772 <https://bugs.launchpad.net/mos/+bug/1443772>`_.",,12,0
openstack%2Ffuel-docs~stable%2F6.0~If67dbfb0a26d696b7e61c06fd3925eaeb2f33c73,openstack/fuel-docs,stable/6.0,If67dbfb0a26d696b7e61c06fd3925eaeb2f33c73,RN6.0-updates3: Nova resolved issues,MERGED,2015-05-14 14:17:35.000000000,2015-05-20 14:57:18.000000000,2015-05-20 14:57:18.000000000,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 8971}, {'_account_id': 9545}, {'_account_id': 9569}, {'_account_id': 10618}, {'_account_id': 13082}, {'_account_id': 14168}, {'_account_id': 14396}, {'_account_id': 14421}, {'_account_id': 14645}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-05-14 14:17:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/20fe6cc6c22d3b45df58c1f8d504a735fbf1781f', 'message': 'RN6.0-updates3: Nova resolved issues\n\nAdds the description of nine Nova-related resolved issues.\n\nChange-Id: If67dbfb0a26d696b7e61c06fd3925eaeb2f33c73\n'}, {'number': 2, 'created': '2015-05-15 12:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/addae49c39774f204399e59a160d324cf80d836c', 'message': 'RN6.0-updates3: Nova resolved issues\n\nAdds the description of nine Nova-related resolved issues.\n\nChange-Id: If67dbfb0a26d696b7e61c06fd3925eaeb2f33c73\n'}, {'number': 3, 'created': '2015-05-18 13:21:16.000000000', 'files': ['pages/release-notes/v6-0/updates/2010-nova.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6378cd5348b981c5ed66a2471ff01f1c83cff927', 'message': 'RN6.0-updates3: Nova resolved issues\n\nAdds the description of eight Nova-related resolved issues.\n\nChange-Id: If67dbfb0a26d696b7e61c06fd3925eaeb2f33c73\n'}]",7,183055,6378cd5348b981c5ed66a2471ff01f1c83cff927,33,12,3,14643,,,0,"RN6.0-updates3: Nova resolved issues

Adds the description of eight Nova-related resolved issues.

Change-Id: If67dbfb0a26d696b7e61c06fd3925eaeb2f33c73
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/55/183055/3 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-0/updates/2010-nova.rst'],1,20fe6cc6c22d3b45df58c1f8d504a735fbf1781f,relnotes6.0-updates," See `LP1420273`_. See `LP1427892`_. See `LP1409661`_. See `LP1435712`_. * The update resolves nova-compute graceful shutdown issue: nova-compute no longer hangs waiting for the external events that cannot be processed. All tasks waiting for such events (plugging of VIFs by Neutron L2 agent, for example), are cancelled immediately upon the SIGTERM signal receiving. Previously, nova-compute did not exit properly, but waited for the external events which would never be triggered. See `LP1433605`_. * By now, Nova allows booting an instance from a QCOW2 image with the virtual size greater than the ``root_gb`` size specified in a flavor. See `LP1427839`_. * Previously, it was impossible to create a snapshot of a vitrual machine spun up from another snapshot as the location of the respective information in a glance image and a snapshot object differed. The update resolves the issue. See `LP1431951`_. * Juno controller and Icehouse compute are now able to backport a Service object correctly. Previously, when backporting the Service object to Icehouse version, the embedded ComputeNode object was sent back at the wrong version. See `LP1436819`_. * The deletion of an instance, when using Juno controller and Icehouse compute, does not cause an infinite loop anymore. This is achieved due to the backporting of a FixedIP object with an embedded version of a Network object added with this update. See `LP1436825`_. * Currently, Nova-compute is able to restart successfully, even if ``_init_instance`` fails. Previously, the compute process used to exit unexpectedly in case an unhandled exception was raised from an instance. See `LP1438680`_. * The update fixes the issue with detaching of multipath volumes when using different targets with the same portal. See `LP1443974`_. * The update fixes the multipath performance issues with the ``connect_volume`` and similar functions. See `LP1443977`_. .. Links .. _`LP1420273`: https://bugs.launchpad.net/mos/+bug/1420273 .. _`LP1427892`: https://bugs.launchpad.net/mos/+bug/1427892 .. _`LP1409661`: https://bugs.launchpad.net/mos/+bug/1409661 .. _`LP1435712`: https://bugs.launchpad.net/mos/+bug/1435712 .. _`LP1433605`: https://bugs.launchpad.net/mos/+bug/1433605 .. _`LP1427839`: https://bugs.launchpad.net/mos/+bug/1427839 .. _`LP1431951`: https://bugs.launchpad.net/mos/+bug/1431951 .. _`LP1436819`: https://bugs.launchpad.net/mos/+bug/1436819 .. _`LP1436825`: https://bugs.launchpad.net/mos/+bug/1436825 .. _`LP1438680`: https://bugs.launchpad.net/mos/+bug/1438680 .. _`LP1443974`: https://bugs.launchpad.net/mos/+bug/1443974 .. _`LP1443977`: https://bugs.launchpad.net/mos/+bug/1443977", See `LP1420273 <https://bugs.launchpad.net/mos/+bug/1420273>`_. See `LP1427892 <https://bugs.launchpad.net/mos/+bug/1427892>`_. See `LP1409661 <https://bugs.launchpad.net/mos/+bug/1409661>`_. See `LP1435712 <https://bugs.launchpad.net/mos/+bug/1435712>`_.,57,4
openstack%2Fopenstacksdk~master~Id8b06e08fb22e4af3b90c4b8ab6400378565d804,openstack/openstacksdk,master,Id8b06e08fb22e4af3b90c4b8ab6400378565d804,Update orchestration functional tests,MERGED,2015-05-16 14:03:32.000000000,2015-05-20 14:56:56.000000000,2015-05-20 14:56:55.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-16 14:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c5e7cb5cb7872338aafd96a183f1644b8c46e9e0', 'message': ""Update orchestration functional tests\n\nUpdate the orchestration functional tests to use the setup and\nteardown.  The test cleans up after itself now, but it doesn't\nwait for the deleted stack to complete which would be a good\nfeature, but we don't have a wait method that waits for something\nto be gone.\n\nChange-Id: Id8b06e08fb22e4af3b90c4b8ab6400378565d804\n""}, {'number': 2, 'created': '2015-05-20 01:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/30611c2fa9c075e0e0354a6bf2bd7950ff47a5a2', 'message': ""Update orchestration functional tests\n\nUpdate the orchestration functional tests to use the setup and\nteardown.  The test cleans up after itself now, but it doesn't\nwait for the deleted stack to complete which would be a good\nfeature, but we don't have a wait method that waits for something\nto be gone.\n\nChange-Id: Id8b06e08fb22e4af3b90c4b8ab6400378565d804\n""}, {'number': 3, 'created': '2015-05-20 14:16:31.000000000', 'files': ['openstack/tests/functional/orchestration/v1/test_stack.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b668949cf39d1a1a4f00d92a21662201f5cd7423', 'message': ""Update orchestration functional tests\n\nUpdate the orchestration functional tests to use the setup and\nteardown.  The test cleans up after itself now, but it doesn't\nwait for the deleted stack to complete which would be a good\nfeature, but we don't have a wait method that waits for something\nto be gone.\n\nChange-Id: Id8b06e08fb22e4af3b90c4b8ab6400378565d804\n""}]",1,183797,b668949cf39d1a1a4f00d92a21662201f5cd7423,11,2,3,8736,,,0,"Update orchestration functional tests

Update the orchestration functional tests to use the setup and
teardown.  The test cleans up after itself now, but it doesn't
wait for the deleted stack to complete which would be a good
feature, but we don't have a wait method that waits for something
to be gone.

Change-Id: Id8b06e08fb22e4af3b90c4b8ab6400378565d804
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/97/183797/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/orchestration/v1/test_stack.py'],1,c5e7cb5cb7872338aafd96a183f1644b8c46e9e0,stackfoo,"from openstack.orchestration.v1 import stack NAME = 'test_stack' ID = None @classmethod def setUpClass(cls): super(TestStack, cls).setUpClass() if cls.conn.compute.find_keypair(cls.NAME) is None: cls.conn.compute.create_keypair(name=cls.NAME) template_url = ('http://git.openstack.org/cgit/openstack/' + 'heat-templates/plain/hot/F20/WordPress_Native.yaml') args = { 'name': cls.NAME, 'parameters': {'key_name': cls.NAME, 'image_id': 'fedora-20.x86_64'}, 'template_url': template_url, } sot = cls.conn.orchestration.create_stack(**args) assert isinstance(sot, stack.Stack) cls.assertIs(True, (sot.id is not None)) cls.ID = sot.id cls.assertIs(cls.NAME, sot.name) cls.conn.orchestration.wait_for_stack(sot) @classmethod def tearDownClass(cls): super(TestStack, cls).tearDownClass() cls.conn.orchestration.delete_stack(cls.ID) cls.conn.compute.delete_keypair(cls.NAME) def test_list(self): names = [o.name for o in self.conn.orchestration.list_stacks()] self.assertIn(self.NAME, names)"," def test_create_stack(self): stack = self.conn.orchestration.create_stack( name='test_stack', parameters={'key_name': 'heat_key', 'image_id': 'fedora-20.x86_64'}, template_url='http://git.openstack.org/cgit/openstack/' + 'heat-templates/plain/hot/F20/WordPress_Native.yaml' ) self.conn.orchestration.wait_for_stack(stack) self.assertIsNotNone(stack.id) self.assertEqual('test_stack', stack.name)",31,11
openstack%2Fopenstacksdk~master~I285b8d1b106d172c032f77de69acb868c224d0aa,openstack/openstacksdk,master,I285b8d1b106d172c032f77de69acb868c224d0aa,AFT network network CRUD,MERGED,2015-05-19 00:30:27.000000000,2015-05-20 14:56:29.000000000,2015-05-20 14:56:27.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-19 00:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8e49ded545964696a40699d51c318bc4fd94d066', 'message': 'AFT network network CRUD\n\nChange-Id: I285b8d1b106d172c032f77de69acb868c224d0aa\n'}, {'number': 2, 'created': '2015-05-20 01:20:52.000000000', 'files': ['openstack/tests/functional/network/v2/test_network.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8b76a69d2c0f8ca70cf2c3b80424e94b9b47d82b', 'message': 'AFT network network CRUD\n\nChange-Id: I285b8d1b106d172c032f77de69acb868c224d0aa\n'}]",2,184162,8b76a69d2c0f8ca70cf2c3b80424e94b9b47d82b,10,3,2,8736,,,0,"AFT network network CRUD

Change-Id: I285b8d1b106d172c032f77de69acb868c224d0aa
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/62/184162/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_network.py'],1,8e49ded545964696a40699d51c318bc4fd94d066,aftnetworknetwork,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from openstack.network.v2 import network from openstack.tests.functional import base class TestNetwork(base.BaseFunctionalTest): NAME = uuid.uuid4().hex ID = None @classmethod def setUpClass(cls): super(TestNetwork, cls).setUpClass() sot = cls.conn.network.create_network(name=cls.NAME) assert isinstance(sot, network.Network) cls.assertIs(cls.NAME, sot.name) cls.ID = sot.id @classmethod def tearDownClass(cls): pass sot = cls.conn.network.delete_network(cls.NAME) cls.assertIs(None, sot) def test_find(self): sot = self.conn.network.find_network(self.NAME) self.assertEqual(self.ID, sot.id) def test_get(self): sot = self.conn.network.get_network(self.ID) self.assertEqual(self.NAME, sot.name) self.assertEqual(self.ID, sot.id) def test_list(self): names = [o.name for o in self.conn.network.networks()] self.assertIn(self.NAME, names) ",,49,0
openstack%2Ftripleo-heat-templates~master~I5644de2d6253ab762a1420560ecb5bee2fd83092,openstack/tripleo-heat-templates,master,I5644de2d6253ab762a1420560ecb5bee2fd83092,Clone params for pacemaker rabbitmq resource,MERGED,2015-05-19 15:03:08.000000000,2015-05-20 14:51:27.000000000,2015-05-20 14:51:26.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 7984}, {'_account_id': 8449}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-05-19 15:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7a9da999ca8653619b8b2748830e2d89d3a5be4', 'message': 'Clone params for pacemaker rabbitmq resource\n\nSet clone params according to [1].\n\n[1] https://github.com/beekhof/osp-ha-deploy/blob/f8a65ab4c34f94737edde7db60337b830bfe6311/pcmk/rabbitmq.scenario\n\nChange-Id: I5644de2d6253ab762a1420560ecb5bee2fd83092\n'}, {'number': 2, 'created': '2015-05-19 15:11:01.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/37ba7cd30acc86769bfc114cce62ae48a73406b1', 'message': 'Clone params for pacemaker rabbitmq resource\n\nSet clone params according to [1].\n\n[1] https://github.com/beekhof/osp-ha-deploy/blob/f8a65ab4c34f94737edde7db60337b830bfe6311/pcmk/rabbitmq.scenario\n\nChange-Id: I5644de2d6253ab762a1420560ecb5bee2fd83092\nCo-Authored-By: Giulio Fidente <gfidente@redhat.com>\n'}]",1,184263,37ba7cd30acc86769bfc114cce62ae48a73406b1,13,7,2,8042,,,0,"Clone params for pacemaker rabbitmq resource

Set clone params according to [1].

[1] https://github.com/beekhof/osp-ha-deploy/blob/f8a65ab4c34f94737edde7db60337b830bfe6311/pcmk/rabbitmq.scenario

Change-Id: I5644de2d6253ab762a1420560ecb5bee2fd83092
Co-Authored-By: Giulio Fidente <gfidente@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/63/184263/2 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,f7a9da999ca8653619b8b2748830e2d89d3a5be4,," clone_params => 'ordered=true interleave=true',"," clone_params => true,",1,1
openstack%2Ftripleo-heat-templates~master~I522d7520b383a280505e0e7c8fecba9ac02d2c9b,openstack/tripleo-heat-templates,master,I522d7520b383a280505e0e7c8fecba9ac02d2c9b,Provide RabbitMQ clients with a list of servers instead of VIP,MERGED,2015-05-07 17:07:12.000000000,2015-05-20 14:51:20.000000000,2015-05-20 14:51:19.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7984}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-05-07 17:07:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/869b12fccbdc8f9e8ece3ddfe6a25a639a5dfdca', 'message': 'Provide RabbitMQ clients with a list of servers instead of VIP\n\nThis will change the way how RabbitMQ clients get to the servers,\nthey will not go through HAProxy anymore.\n\nChange-Id: I522d7520b383a280505e0e7c8fecba9ac02d2c9b\n'}, {'number': 2, 'created': '2015-05-11 14:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/65de282629e269d5a45264e003c1370ad76eea53', 'message': 'Provide RabbitMQ clients with a list of servers instead of VIP\n\nThis will change the way how RabbitMQ clients get to the servers,\nthey will not go through HAProxy anymore.\n\nChange-Id: I522d7520b383a280505e0e7c8fecba9ac02d2c9b\n'}, {'number': 3, 'created': '2015-05-11 14:56:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/96f25b39a6dbb6b7c5851636abf18868460c18d1', 'message': 'Provide RabbitMQ clients with a list of servers instead of VIP\n\nThis will change the way how RabbitMQ clients get to the servers,\nthey will not go through HAProxy anymore.\n\nChange-Id: I522d7520b383a280505e0e7c8fecba9ac02d2c9b\n'}, {'number': 4, 'created': '2015-05-12 15:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b90fc1e399f600169e1db04bf5fb70d2f68293b4', 'message': 'Provide RabbitMQ clients with a list of servers instead of VIP\n\nThis will change the way how RabbitMQ clients get to the servers,\nthey will not go through HAProxy anymore.\n\nChange-Id: I522d7520b383a280505e0e7c8fecba9ac02d2c9b\n'}, {'number': 5, 'created': '2015-05-14 15:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/04cc9b8d0244c539dd16f6cad5b55342f2cbd45d', 'message': 'Provide RabbitMQ clients with a list of servers instead of VIP\n\nThis will change the way how RabbitMQ clients get to the servers,\nthey will not go through HAProxy anymore.\n\nChange-Id: I522d7520b383a280505e0e7c8fecba9ac02d2c9b\n'}, {'number': 6, 'created': '2015-05-15 09:02:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1b16bdde7f648a26bf973ae2ae0a958fb52eb2e4', 'message': 'Provide RabbitMQ clients with a list of servers instead of VIP\n\nThis will change the way how RabbitMQ clients get to the servers,\nthey will not go through HAProxy anymore.\n\nChange-Id: I522d7520b383a280505e0e7c8fecba9ac02d2c9b\n'}, {'number': 7, 'created': '2015-05-19 11:09:03.000000000', 'files': ['puppet/manifests/overcloud_controller.pp', 'puppet/cinder-storage-puppet.yaml', 'puppet/compute-puppet.yaml', 'puppet/hieradata/controller.yaml', 'puppet/controller-puppet.yaml', 'puppet/all-nodes-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7e96bb748561cfd13bae9f048ebbbf7a0f631fd1', 'message': 'Provide RabbitMQ clients with a list of servers instead of VIP\n\nThis will change the way how RabbitMQ clients get to the servers,\nthey will not go through HAProxy anymore.\n\nChange-Id: I522d7520b383a280505e0e7c8fecba9ac02d2c9b\n'}]",4,181081,7e96bb748561cfd13bae9f048ebbbf7a0f631fd1,54,7,7,6796,,,0,"Provide RabbitMQ clients with a list of servers instead of VIP

This will change the way how RabbitMQ clients get to the servers,
they will not go through HAProxy anymore.

Change-Id: I522d7520b383a280505e0e7c8fecba9ac02d2c9b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/81/181081/6 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller.pp', 'puppet/cinder-storage-puppet.yaml', 'puppet/compute-puppet.yaml', 'puppet/hieradata/compute.yaml', 'puppet/hieradata/volume.yaml', 'puppet/hieradata/controller.yaml', 'puppet/controller-puppet.yaml', 'puppet/all-nodes-config.yaml']",8,869b12fccbdc8f9e8ece3ddfe6a25a639a5dfdca,pcsk_resource_change," str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: controller_ips}"," list_join: - ',' - {get_param: controller_ips}",23,30
openstack%2Fhacking~master~I6f80ddb4e7b2f9bae688849e00c4c27c0d230260,openstack/hacking,master,I6f80ddb4e7b2f9bae688849e00c4c27c0d230260,"H311, H312: add checks for oslo.* | oslo_* imports",ABANDONED,2015-02-20 18:07:06.000000000,2015-05-20 14:46:14.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6486}, {'_account_id': 6601}, {'_account_id': 9656}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-02-20 18:07:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/hacking/commit/2d1a79d25da17b87acea7f95fa81d0ed4d94beee', 'message': 'H601, H602: add checks for oslo.* | oslo_* imports\n\nThose checks are mutually exclusive, only one of those should be enabled\nfor a project.\n\nH601 allows to forbid obsolete oslo.* imports.\n\nH602 allows to forbid new oslo_* imports (useful for stable branches).\n\nChange-Id: I6f80ddb4e7b2f9bae688849e00c4c27c0d230260\nTODO: we need to make H602 disabled by default.\n'}, {'number': 2, 'created': '2015-02-28 12:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/hacking/commit/6440034d981a92e02c6b8ee4d9fd9846cd4b62fa', 'message': 'H311, H312: add checks for oslo.* | oslo_* imports\n\nThose checks are mutually exclusive, only one of those should be enabled\nfor a project.\n\nH311 allows to forbid obsolete oslo.* imports.\n\nH312 allows to forbid new oslo_* imports (for stable branches; disabled\nby default).\n\nChange-Id: I6f80ddb4e7b2f9bae688849e00c4c27c0d230260\n'}, {'number': 3, 'created': '2015-02-28 12:24:49.000000000', 'files': ['hacking/tests/test_doctest.py', 'setup.cfg', 'HACKING.rst', 'hacking/checks/oslo.py'], 'web_link': 'https://opendev.org/openstack/hacking/commit/cbe932a53b27af4ab94f05db4fb51856f8d0e314', 'message': 'H311, H312: add checks for oslo.* | oslo_* imports\n\nThose checks are mutually exclusive, only one of those should be enabled\nfor a project.\n\nH311 allows to forbid obsolete oslo.* imports.\n\nH312 allows to forbid new oslo_* imports (for stable branches; disabled\nby default).\n\nChange-Id: I6f80ddb4e7b2f9bae688849e00c4c27c0d230260\n'}]",7,157894,cbe932a53b27af4ab94f05db4fb51856f8d0e314,18,8,3,9656,,,0,"H311, H312: add checks for oslo.* | oslo_* imports

Those checks are mutually exclusive, only one of those should be enabled
for a project.

H311 allows to forbid obsolete oslo.* imports.

H312 allows to forbid new oslo_* imports (for stable branches; disabled
by default).

Change-Id: I6f80ddb4e7b2f9bae688849e00c4c27c0d230260
",git fetch https://review.opendev.org/openstack/hacking refs/changes/94/157894/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'HACKING.rst', 'hacking/checks/oslo.py']",3,2d1a79d25da17b87acea7f95fa81d0ed4d94beee,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import re from hacking import core # Those apply to Kilo+ oslo_namespace_imports_dot = re.compile(r""import[\s]+oslo($|[.][^\s]+)"") oslo_namespace_imports_from_dot = re.compile(r""from[\s]+oslo[.]"") oslo_namespace_imports_from_root = re.compile(r""from[\s]+oslo[\s]+import[\s]+"") # those apply to Juno and below oslo_namespace_imports_underscore = re.compile( r""import[\s]+oslo_[^\s]+"") oslo_namespace_imports_from_underscore = re.compile( r""from[\s]+oslo_[^\s]+[\s]+import[\s]+"") @core.flake8ext def check_oslo_namespace_imports_post_kilo(logical_line): r""""""Check for oslo.* imports. H601: import oslo H601: import oslo.i18n H601: from oslo import messaging H601: from oslo.utils import importutils """""" if re.match(oslo_namespace_imports_from_dot, logical_line): msg = ( ""H601: '%s' must be used instead of '%s'."") % ( logical_line.replace('oslo.', 'oslo_'), logical_line) yield(0, msg) elif re.match(oslo_namespace_imports_from_root, logical_line): msg = ( ""H601: '%s' must be used instead of '%s'."") % ( logical_line.replace('from oslo import ', 'import oslo_'), logical_line) yield(0, msg) elif re.match(oslo_namespace_imports_dot, logical_line): msg = ( ""H601: '%s' must be used instead of '%s'."") % ( logical_line.replace('import', 'from').replace('.', ' import '), logical_line) yield(0, msg) @core.flake8ext def check_oslo_namespace_imports_juno(logical_line): r""""""Check for oslo_* imports. H602: import oslo_messaging H602: from oslo_utils import importutils """""" if re.match(oslo_namespace_imports_underscore, logical_line): msg = ( ""H602: '%s' must be used instead of '%s'."") % ( logical_line.replace('import', 'from').replace('_', ' import '), logical_line) yield(0, msg) elif re.match(oslo_namespace_imports_from_underscore, logical_line): msg = ( ""H602: '%s' must be used instead of '%s'."") % ( logical_line.replace('_', '.'), logical_line) yield(0, msg) ",,86,0
openstack%2Fapp-catalog~master~I956d0991869ff43508ac6a7b22316e3d75889984,openstack/app-catalog,master,I956d0991869ff43508ac6a7b22316e3d75889984,Adds Debian testing,MERGED,2015-05-19 16:40:18.000000000,2015-05-20 14:38:01.000000000,2015-05-20 14:37:51.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 9237}, {'_account_id': 9788}, {'_account_id': 16145}]","[{'number': 1, 'created': '2015-05-19 16:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/102cf6cd555fee4276600948a12520aeacb0fd1a', 'message': 'Adds Debian testing\n\nIn the current app catalog, only the Debian testing image is\npresent, and not the release of 8.0.0 Jessie. This patch\nfixes that, by renaming the current ""Debian"" into a more\nexplicit ""Debian testing weekly build"" and adds ""Debian Jessie"".\n\nChange-Id: I956d0991869ff43508ac6a7b22316e3d75889984\n'}, {'number': 2, 'created': '2015-05-20 06:43:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/970f550f1b06e9d5af28534a0ce87ddad0132851', 'message': 'Adds Debian testing\n\nIn the current app catalog, only the Debian testing image is\npresent, and not the release of 8.0.0 Jessie. This patch\nfixes that, by renaming the current ""Debian"" into a more\nexplicit ""Debian testing weekly build"" and adds ""Debian Jessie"".\n\nChange-Id: I956d0991869ff43508ac6a7b22316e3d75889984\n'}, {'number': 3, 'created': '2015-05-20 14:34:29.000000000', 'files': ['openstack_catalog/web/static/glance_images.yaml'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/79199b4651e2e9b3bf07b39cbace20cc0852ae97', 'message': 'Adds Debian testing\n\nIn the current app catalog, only the Debian testing image is\npresent, and not the release of 8.0.0 Jessie. This patch\nfixes that, by renaming the current ""Debian"" into a more\nexplicit ""Debian testing weekly build"" and adds ""Debian Jessie"".\n\nChange-Id: I956d0991869ff43508ac6a7b22316e3d75889984\n'}]",3,184287,79199b4651e2e9b3bf07b39cbace20cc0852ae97,18,5,3,6476,,,0,"Adds Debian testing

In the current app catalog, only the Debian testing image is
present, and not the release of 8.0.0 Jessie. This patch
fixes that, by renaming the current ""Debian"" into a more
explicit ""Debian testing weekly build"" and adds ""Debian Jessie"".

Change-Id: I956d0991869ff43508ac6a7b22316e3d75889984
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/87/184287/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/web/static/glance_images.yaml'],1,102cf6cd555fee4276600948a12520aeacb0fd1a,," name: Debian Jessie 8.0.0 This is a Debian Stalbe 8.0.0 (aka Jessie) official base image with cloud_init, cloud-utils, and cloud-initramfs-growroot pre-installed. format: QCOW2 attributes: url: http://cdimage.debian.org/cdimage/openstack/8.0.0/debian-8.0.0-openstack-amd64.qcow2 hash: 0fcf78a066da0fe489b61176eba11f12e55f60081556693a0c5652d1acfbda57 - name: Debian Testing weekly build provided_by: name: Debian href: http://debian.org company: Debian Community description: > Debian is a Unix-like computer operating system and a Linux distribution that is composed entirely of free and open-source software, most of which is under the GNU General Public License, and packaged by a group of individuals known as the Debian project. This is a Debian Testing (currently Stretch) official weekly built base image with cloud_init, cloud-utils, and cloud-initramfs-growroot pre-installed.", name: Debian This is a Debian base image with cloud_init pre-installed,25,2
openstack%2Factivity-board~master~If04d10c99925ac29e35c98a9635d64fe6e8d25ce,openstack/activity-board,master,If04d10c99925ac29e35c98a9635d64fe6e8d25ce,Update JS library and company panel to add top people by company.,MERGED,2015-05-14 10:06:33.000000000,2015-05-20 14:23:19.000000000,2015-05-20 14:23:19.000000000,"[{'_account_id': 3}, {'_account_id': 8000}]","[{'number': 1, 'created': '2015-05-14 10:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/activity-board/commit/2fa1ace9e8ea2cb3d89f95ff37d59188e9ff5ec3', 'message': 'Update JS library and company panel to add top people by company\n\nChange-Id: If04d10c99925ac29e35c98a9635d64fe6e8d25ce\n'}, {'number': 2, 'created': '2015-05-20 14:19:29.000000000', 'files': ['templates/common/company.tmpl', 'browser/company.html', 'browser/lib/vizgrimoire.min.js'], 'web_link': 'https://opendev.org/openstack/activity-board/commit/971203ab2e768a00d02c1967cca033b0c8ed1c08', 'message': 'Update JS library and company panel to add top people by company.\n\nThis second patchset removes the x scroll\n\nChange-Id: If04d10c99925ac29e35c98a9635d64fe6e8d25ce\n'}]",0,182995,971203ab2e768a00d02c1967cca033b0c8ed1c08,9,2,2,8710,,,0,"Update JS library and company panel to add top people by company.

This second patchset removes the x scroll

Change-Id: If04d10c99925ac29e35c98a9635d64fe6e8d25ce
",git fetch https://review.opendev.org/openstack/activity-board refs/changes/95/182995/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/common/company.tmpl', 'browser/company.html', 'browser/lib/vizgrimoire.min.js']",3,2fa1ace9e8ea2cb3d89f95ff37d59188e9ff5ec3,company-top-contributors,"var wgd=$w.coords().grid;var can_go_up=self.can_go_widget_up(wgd);if(can_go_up&&can_go_up!==wgd.row){self.move_widget_to($w,can_go_up)}});return this};fn.move_widget_up=function($widget,y_units){var el_grid_data=$widget.coords().grid;var actual_row=el_grid_data.row;var moved=[];var can_go_up=true;y_units||(y_units=1);if(!this.can_go_up($widget)){return false}this.for_each_column_occupied(el_grid_data,function(col){if($.inArray($widget,moved)===-1){var widget_grid_data=$widget.coords().grid;var next_row=actual_row-y_units;next_row=this.can_go_up_to_row(widget_grid_data,col,next_row);if(!next_row){return true}var $next_widgets=this.widgets_below($widget);this.remove_from_gridmap(widget_grid_data);widget_grid_data.row=next_row;this.add_to_gridmap(widget_grid_data);$widget.attr(""data-row"",widget_grid_data.row);this.$changed=this.$changed.add($widget);moved.push($widget);$next_widgets.each($.proxy(function(i,widget){this.move_widget_up($(widget),y_units)},this))}})};fn.move_widget_down=function($widget,y_units){var el_grid_data=$widget.coords().grid;var actual_row=el_grid_data.row;var moved=[];var y_diff=y_units;if(!$widget){return false}if($.inArray($widget,moved)===-1){var widget_grid_data=$widget.coords().grid;var next_row=actual_row+y_units;var $next_widgets=this.widgets_below($widget);this.remove_from_gridmap(widget_grid_data);$next_widgets.each($.proxy(function(i,widget){var $w=$(widget);var wd=$w.coords().grid;var tmp_y=this.displacement_diff(wd,widget_grid_data,y_diff);if(tmp_y>0){this.move_widget_down($w,tmp_y)}},this));widget_grid_data.row=next_row;this.update_widget_position(widget_grid_data,$widget);$widget.attr(""data-row"",widget_grid_data.row);this.$changed=this.$changed.add($widget);moved.push($widget)}};fn.can_go_up_to_row=function(widget_grid_data,col,row){var ga=this.gridmap;var result=true;var urc=[];var actual_row=widget_grid_data.row;var r;this.for_each_column_occupied(widget_grid_data,function(tcol){var grid_col=ga[tcol];urc[tcol]=[];r=actual_row;while(r--){if(this.is_empty(tcol,r)&&!this.is_placeholder_in(tcol,r)){urc[tcol].push(r)}else{break}}if(!urc[tcol].length){result=false;return true}});if(!result){return false}r=row;for(r=1;r<actual_row;r++){var common=true;for(var uc=0,ucl=urc.length;uc<ucl;uc++){if(urc[uc]&&$.inArray(r,urc[uc])===-1){common=false}}if(common===true){result=r;break}}return result};fn.displacement_diff=function(widget_grid_data,parent_bgd,y_units){var actual_row=widget_grid_data.row;var diffs=[];var parent_max_y=parent_bgd.row+parent_bgd.size_y;this.for_each_column_occupied(widget_grid_data,function(col){var temp_y_units=0;for(var r=parent_max_y;r<actual_row;r++){if(this.is_empty(col,r)){temp_y_units=temp_y_units+1}}diffs.push(temp_y_units)});var max_diff=Math.max.apply(Math,diffs);y_units=y_units-max_diff;return y_units>0?y_units:0};fn.widgets_below=function($el){var el_grid_data=$.isPlainObject($el)?$el:$el.coords().grid;var self=this;var ga=this.gridmap;var next_row=el_grid_data.row+el_grid_data.size_y-1;var $nexts=$([]);this.for_each_column_occupied(el_grid_data,function(col){self.for_each_widget_below(col,next_row,function(tcol,trow){if(!self.is_player(this)&&$.inArray(this,$nexts)===-1){$nexts=$nexts.add(this);return true}})});return this.sort_by_row_asc($nexts)};fn.set_cells_player_occupies=function(col,row){this.remove_from_gridmap(this.placeholder_grid_data);this.placeholder_grid_data.col=col;this.placeholder_grid_data.row=row;this.add_to_gridmap(this.placeholder_grid_data,this.$player);return this};fn.empty_cells_player_occupies=function(){this.remove_from_gridmap(this.placeholder_grid_data);return this};fn.can_go_up=function($el){var el_grid_data=$el.coords().grid;var initial_row=el_grid_data.row;var prev_row=initial_row-1;var ga=this.gridmap;var upper_rows_by_column=[];var result=true;if(initial_row===1){return false}this.for_each_column_occupied(el_grid_data,function(col){var $w=this.is_widget(col,prev_row);if(this.is_occupied(col,prev_row)||this.is_player(col,prev_row)||this.is_placeholder_in(col,prev_row)||this.is_player_in(col,prev_row)){result=false;return true}});return result};fn.can_move_to=function(widget_grid_data,col,row,max_row){var ga=this.gridmap;var $w=widget_grid_data.el;var future_wd={size_y:widget_grid_data.size_y,size_x:widget_grid_data.size_x,col:col,row:row};var result=true;var right_col=col+widget_grid_data.size_x-1;if(right_col>this.cols){return false}if(max_row&&max_row<row+widget_grid_data.size_y-1){return false}this.for_each_cell_occupied(future_wd,function(tcol,trow){var $tw=this.is_widget(tcol,trow);if($tw&&(!widget_grid_data.el||$tw.is($w))){result=false}});return result};fn.get_targeted_columns=function(from_col){var max=(from_col||this.player_grid_data.col)+(this.player_grid_data.size_x-1);var cols=[];for(var col=from_col;col<=max;col++){cols.push(col)}return cols};fn.get_targeted_rows=function(from_row){var max=(from_row||this.player_grid_data.row)+(this.player_grid_data.size_y-1);var rows=[];for(var row=from_row;row<=max;row++){rows.push(row)}return rows};fn.get_cells_occupied=function(el_grid_data){var cells={cols:[],rows:[]};var i;if(arguments[1]instanceof jQuery){el_grid_data=arguments[1].coords().grid}for(i=0;i<el_grid_data.size_x;i++){var col=el_grid_data.col+i;cells.cols.push(col)}for(i=0;i<el_grid_data.size_y;i++){var row=el_grid_data.row+i;cells.rows.push(row)}return cells};fn.for_each_cell_occupied=function(grid_data,callback){this.for_each_column_occupied(grid_data,function(col){this.for_each_row_occupied(grid_data,function(row){callback.call(this,col,row)})});return this};fn.for_each_column_occupied=function(el_grid_data,callback){for(var i=0;i<el_grid_data.size_x;i++){var col=el_grid_data.col+i;callback.call(this,col,el_grid_data)}};fn.for_each_row_occupied=function(el_grid_data,callback){for(var i=0;i<el_grid_data.size_y;i++){var row=el_grid_data.row+i;callback.call(this,row,el_grid_data)}};fn._traversing_widgets=function(type,direction,col,row,callback){var ga=this.gridmap;if(!ga[col]){return}var cr,max;var action=type+""/""+direction;if(arguments[2]instanceof jQuery){var el_grid_data=arguments[2].coords().grid;col=el_grid_data.col;row=el_grid_data.row;callback=arguments[3]}var matched=[];var trow=row;var methods={""for_each/above"":function(){while(trow--){if(trow>0&&this.is_widget(col,trow)&&$.inArray(ga[col][trow],matched)===-1){cr=callback.call(ga[col][trow],col,trow);matched.push(ga[col][trow]);if(cr){break}}}},""for_each/below"":function(){for(trow=row+1,max=ga[col].length;trow<max;trow++){if(this.is_widget(col,trow)&&$.inArray(ga[col][trow],matched)===-1){cr=callback.call(ga[col][trow],col,trow);matched.push(ga[col][trow]);if(cr){break}}}}};if(methods[action]){methods[action].call(this)}};fn.for_each_widget_above=function(col,row,callback){this._traversing_widgets(""for_each"",""above"",col,row,callback);return this};fn.for_each_widget_below=function(col,row,callback){this._traversing_widgets(""for_each"",""below"",col,row,callback);return this};fn.get_highest_occupied_cell=function(){var r;var gm=this.gridmap;var rows=[];var row_in_col=[];for(var c=gm.length-1;c>=1;c--){for(r=gm[c].length-1;r>=1;r--){if(this.is_widget(c,r)){rows.push(r);row_in_col[r]=c;break}}}var highest_row=Math.max.apply(Math,rows);this.highest_occupied_cell={col:row_in_col[highest_row],row:highest_row};return this.highest_occupied_cell};fn.get_widgets_from=function(col,row){var ga=this.gridmap;var $widgets=$();if(col){$widgets=$widgets.add(this.$widgets.filter(function(){var tcol=$(this).attr(""data-col"");return tcol===col||tcol>col}))}if(row){$widgets=$widgets.add(this.$widgets.filter(function(){var trow=$(this).attr(""data-row"");return trow===row||trow>row}))}return $widgets};fn.set_dom_grid_height=function(){var r=this.get_highest_occupied_cell().row;this.$el.css(""height"",r*this.min_widget_height);return this};fn.generate_stylesheet=function(opts){var styles="""";var max_size_x=this.options.max_size_x;var max_rows=0;var max_cols=0;var i;var rules;opts||(opts={});opts.cols||(opts.cols=this.cols);opts.rows||(opts.rows=this.rows);opts.namespace||(opts.namespace=this.options.namespace);opts.widget_base_dimensions||(opts.widget_base_dimensions=this.options.widget_base_dimensions);opts.widget_margins||(opts.widget_margins=this.options.widget_margins);opts.min_widget_width=opts.widget_margins[0]*2+opts.widget_base_dimensions[0];opts.min_widget_height=opts.widget_margins[1]*2+opts.widget_base_dimensions[1];var serialized_opts=$.param(opts);if($.inArray(serialized_opts,Gridster.generated_stylesheets)>=0){return false}Gridster.generated_stylesheets.push(serialized_opts);for(i=opts.cols;i>=0;i--){styles+=opts.namespace+' [data-col=""'+(i+1)+'""] { left:'+(i*opts.widget_base_dimensions[0]+i*opts.widget_margins[0]+(i+1)*opts.widget_margins[0])+""px;} ""}for(i=opts.rows;i>=0;i--){styles+=opts.namespace+' [data-row=""'+(i+1)+'""] { top:'+(i*opts.widget_base_dimensions[1]+i*opts.widget_margins[1]+(i+1)*opts.widget_margins[1])+""px;} ""}for(var y=1;y<=opts.rows;y++){styles+=opts.namespace+' [data-sizey=""'+y+'""] { height:'+(y*opts.widget_base_dimensions[1]+(y-1)*(opts.widget_margins[1]*2))+""px;}""}for(var x=1;x<=max_size_x;x++){styles+=opts.namespace+' [data-sizex=""'+x+'""] { width:'+(x*opts.widget_base_dimensions[0]+(x-1)*(opts.widget_margins[0]*2))+""px;}""}return this.add_style_tag(styles)};fn.add_style_tag=function(css){var d=document;var tag=d.createElement(""style"");d.getElementsByTagName(""head"")[0].appendChild(tag);tag.setAttribute(""type"",""text/css"");if(tag.styleSheet){tag.styleSheet.cssText=css}else{tag.appendChild(document.createTextNode(css))}return this};fn.generate_faux_grid=function(rows,cols){this.faux_grid=[];this.gridmap=[];var col;var row;for(col=cols;col>0;col--){this.gridmap[col]=[];for(row=rows;row>0;row--){this.add_faux_cell(row,col)}}return this};fn.add_faux_cell=function(row,col){var coords=$({left:this.baseX+(col-1)*this.min_widget_width,top:this.baseY+(row-1)*this.min_widget_height,width:this.min_widget_width,height:this.min_widget_height,col:col,row:row,original_col:col,original_row:row}).coords();if(!$.isArray(this.gridmap[col])){this.gridmap[col]=[]}this.gridmap[col][row]=false;this.faux_grid.push(coords);return this};fn.add_faux_rows=function(rows){var actual_rows=this.rows;var max_rows=actual_rows+(rows||1);for(var r=max_rows;r>actual_rows;r--){for(var c=this.cols;c>=1;c--){this.add_faux_cell(r,c)}}this.rows=max_rows;if(this.options.autogenerate_stylesheet){this.generate_stylesheet()}return this};fn.add_faux_cols=function(cols){var actual_cols=this.cols;var max_cols=actual_cols+(cols||1);for(var c=actual_cols;c<max_cols;c++){for(var r=this.rows;r>=1;r--){this.add_faux_cell(r,c)}}this.cols=max_cols;if(this.options.autogenerate_stylesheet){this.generate_stylesheet()}return this};fn.recalculate_faux_grid=function(){var aw=this.$wrapper.width();this.baseX=($(window).width()-aw)/2;this.baseY=this.$wrapper.offset().top;$.each(this.faux_grid,$.proxy(function(i,coords){this.faux_grid[i]=coords.update({left:this.baseX+(coords.data.col-1)*this.min_widget_width,top:this.baseY+(coords.data.row-1)*this.min_widget_height})},this));return this};fn.get_widgets_from_DOM=function(){this.$widgets.each($.proxy(function(i,widget){this.register_widget($(widget))},this));return this};fn.generate_grid_and_stylesheet=function(){var aw=this.$wrapper.width();var ah=this.$wrapper.height();var cols=Math.floor(aw/this.min_widget_width)+this.options.extra_cols;var actual_cols=this.$widgets.map(function(){return $(this).attr(""data-col"")});actual_cols=Array.prototype.slice.call(actual_cols,0);actual_cols.length||(actual_cols=[0]);var min_cols=Math.max.apply(Math,actual_cols);var max_rows=this.options.extra_rows;this.$widgets.each(function(i,w){max_rows+=+$(w).attr(""data-sizey"")});this.cols=Math.max(min_cols,cols,this.options.min_cols);this.rows=Math.max(max_rows,this.options.min_rows);this.baseX=($(window).width()-aw)/2;this.baseY=this.$wrapper.offset().top;if(this.options.autogenerate_stylesheet){this.generate_stylesheet()}return this.generate_faux_grid(this.rows,this.cols)};$.fn.gridster=function(options){return this.each(function(){if(!$(this).data(""gridster"")){$(this).data(""gridster"",new Gridster(this,options))}})};$.Gridster=fn})(jQuery,window,document);vizjslib_git_revision=""59734617be85559ec882386f66c9b5a096e6cd38"";vizjslib_git_tag=""15.02-61-g5973461"";(function(){var V=envision,global_data={};function getDefaultsMarkers(option,markers,dates){var mark="""";if(!markers||markers.length===0)return mark;for(var i=0;i<markers.date.length;i++){if(markers.date[i]==dates[option.index]){mark=markers.marks[i]}}return mark}function getEnvisionDefaultsGraph(name,gconfig){var graph={name:name,config:{colors:gconfig.colors,grid:{verticalLines:false,horizontalLines:false},mouse:{track:true,trackY:false,position:""ne""},yaxis:{min:0,autoscale:true},legend:{show:false,backgroundColor:""#FFFFFF"",backgroundOpacity:0}}};if(gconfig.gtype===""whiskers"")graph.config.whiskers={show:true,lineWidth:2};else graph.config[""lite-lines""]={lineWidth:2,show:true,fill:false,fillOpacity:.5};if(gconfig.y_labels)graph.config.yaxis={showLabels:true,min:0};if(gconfig.show_markers)graph.config.markers={show:true,position:""ct"",labelFormatter:function(o){return getDefaultsMarkers(o,gconfig.markers,gconfig.dates)}};return graph}function getDefaultsMetrics(DS,viz,metrics,default_config){var all_metrics=Report.getAllMetrics();var label=null;$.each(metrics,function(metric,value){config=default_config;if(value.envision)config=DataProcess.mergeConfig(default_config,value.envision);if($.inArray(metric,global_data.envision_hide)===-1){viz[metric]=getEnvisionDefaultsGraph(""report-""+DS.getName()+""-""+metric,config);label=metric;if(all_metrics[metric])label=all_metrics[metric].name;viz[metric].config.subtitle=label;if(DS.getMainMetric()==metric){viz[metric+""_relative""]=getEnvisionDefaultsGraph(""report-""+DS.getName()+""-""+metric+""_relative"",config);viz[metric].config[""lite-lines""]={show:false};viz[metric].config.lines={lineWidth:1,show:true,stacked:true,fill:true,fillOpacity:1}}}})}function getDefaults(ds){var defaults_colors=[""#ffa500"",""#00A8F0"",""#C0D800"",""#ffff00"",""#00ff00"",""#4DA74D"",""#9440ED""];var default_config={colors:defaults_colors,dates:global_data.dates,g_type:"""",markers:global_data.markers,y_labels:false};var data_sources=Report.getDataSources();var viz={};var metrics={};if(!ds){$.each(data_sources,function(i,DS){metrics=DS.getMetrics();getDefaultsMetrics(DS,viz,metrics,default_config)})}else{$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds)>-1){metrics=DS.getMetrics();getDefaultsMetrics(DS,viz,metrics,default_config)}})}config=default_config;viz.summary=getEnvisionDefaultsGraph(""report-summary"",config);viz.summary.config.xaxis={noTickets:10,showLabels:true};viz.summary.config.handles={show:true};viz.summary.config.selection={mode:""x""};viz.summary.config.mouse={};viz.connection={name:""report-connection"",adapterConstructor:V.components.QuadraticDrawing};return viz}function getOrderedDataSources(ds_list,main_metric){var ordered=[];var main_DS=null;$.each(ds_list,function(i,DS){if(DS.getMetrics()[main_metric]){main_DS=DS;return false}});ordered.push(main_DS);$.each(ds_list,function(i,DS){if(DS===main_DS)return;ordered.push(DS)});return ordered}function Envision_Report(options,data_sources){var main_metric=options.data.main_metric;global_data=options.data;if(!data_sources)data_sources=Report.getDataSources();data_sources=getOrderedDataSources(data_sources,main_metric);var ds=[];for(var i=0;i<data_sources.length;i++){if(data_sources[i].getData().length===0)continue;ds.push(data_sources[i].getName())}var data=options.data,defaults=getDefaults(ds),vis=new V.Visualization({name:""report-""+ds.join("","")}),selection=new V.Interaction,hit=new V.Interaction;var metrics={};$.each(data_sources,function(i,DS){if(DS.getData().length===0)return;metrics=$.extend(metrics,DS.getMetrics())});$.each(metrics,function(metric,value){if($.inArray(metric,data.envision_hide)!==-1)return;if(data[metric]===undefined)return;defaults[metric].data=data[metric];if(defaults[metric].data.length<Report.getProjectsList().length)defaults[metric].config.legend.show=true;if(data[metric+""_relative""])defaults[metric].data=data[metric+""_relative""]});defaults.summary.data=data.summary;defaults[main_metric].config.legend.show=true;if(options.legend_show===false)defaults[main_metric].config.legend.show=false;defaults[main_metric].config.mouse.trackFormatter=options.trackFormatter;if(options.xTickFormatter){defaults.summary.config.xaxis.tickFormatter=options.xTickFormatter}defaults[main_metric].config.yaxis.tickFormatter=options.yTickFormatter||function(n){return""$""+n};var components={};$.each(metrics,function(metric,value){if(data[metric]===undefined)return;if($.inArray(metric,data.envision_hide)===-1){components[metric]=new V.Component(defaults[metric])}});connection=new V.Component(defaults.connection);summary=new V.Component(defaults.summary);$.each(components,function(component,value){vis.add(value)});vis.add(connection).add(summary).render(options.container);$.each(components,function(component,value){selection.follower(value)});selection.follower(connection).leader(summary).add(V.actions.selection,options.selectionCallback?{callback:options.selectionCallback}:null);var hit_group=[];$.each(components,function(component,value){hit_group.push(value)});hit.group(hit_group).add(V.actions.hit);if(options.selection){summary.trigger(""select"",options.selection)}}V.templates.Envision_Report=Envision_Report})();if(Loader===undefined)var Loader={};(function(){var data_callbacks=[];var data_global_callbacks=[];var data_repos_callbacks=[];var check_companies=false,check_repos=false,check_countries=false;var ds_not_supported_company_top=[""scr"",""irc"",""mediawiki""];var ds_supporting_top_repos=[""scm"",""mls"",""its""];var all_data;Loader.data_ready=function(callback){data_callbacks.push(callback)};Loader.data_ready_global=function(callback){data_global_callbacks.push(callback)};Loader.set_all_data=function(data){all_data=data};function fillProjectInfo(data,dir){if(data.project_name===undefined){data.project_name=dir.replace(""data/json"","""").replace(/\.\.\//g,"""")}var projects_data=Report.getProjectsData();projects_data[data.project_name]={dir:dir,url:data.project_url}}Loader.data_load=function(){if(Report.getConfig()!==null&&Report.getConfig().project_info!==undefined){Report.setProjectData(Report.getConfig().project_info);if(Report.getConfig().markers)data_load_file(Report.getMarkersFile(),function(data,self){Report.setMarkers(data)})}else{data_load_file(Report.getProjectFile(),function(data,self){Report.setProjectData(data)});data_load_file(Report.getMarkersFile(),function(data,self){Report.setMarkers(data)})}var projects_dirs=Report.getProjectsDirs();for(var i=0;i<projects_dirs.length;i++){var data_dir=projects_dirs[i];var prj_file=Report.getDataDir()+""/project-info.json"";data_load_file(prj_file,fillProjectInfo,data_dir)}data_load_file(Report.getProjectsHierarchyFile(),Report.setProjectsHierarchy);data_load_file(Report.getVizConfigFile(),function(data,self){Report.setVizConfig(data)});data_load_metrics_definition();data_load_metrics();data_load_tops(""authors"");data_load_time_to_fix();data_load_time_to_attention();data_load_demographics();data_load_markov_table();if(Report.getConfig()!==null&&Report.getConfig().reports!==undefined){var active_reports=Report.getConfig().reports;if($.inArray(""companies"",active_reports)>-1)data_load_companies();if($.inArray(""repositories"",active_reports)>-1)data_load_repos();if($.inArray(""countries"",active_reports)>-1)data_load_countries();if($.inArray(""domains"",active_reports)>-1)data_load_domains();if($.inArray(""projects"",active_reports)>-1)data_load_projects();if($.inArray(""people"",active_reports)>-1){data_load_people();data_load_people_identities()}}else{data_load_companies();data_load_repos();data_load_countries();data_load_domains();data_load_projects();data_load_people();data_load_people_identities()}};Loader.get_file_data_div=function(file,cb,div){$.when($.getJSON(file)).done(function(history){cb(div,file,history)}).fail(function(){cb(file,null)})};function get_data_from_all(file,fn_data_set,self){all_data_found=false;if(all_data){file_no_path=file.replace(Report.getDataDir()+""/"","""");data=all_data[file_no_path];if(data){fn_data_set(data,self);end_data_load();all_data_found=true}else{if(window.console){Report.log(""Can't find in ""+Report.all_json_file+"" ""+file)}}}return all_data_found}function data_load_file(file,fn_data_set,self){if(get_data_from_all(file,fn_data_set,self))return;$.when($.getJSON(file)).done(function(history){fn_data_set(history,self);end_data_load()}).fail(function(){fn_data_set([],self);end_data_load()})}function data_load_companies(){var ds_not_supported=[""irc"",""mediawiki""];var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds_not_supported)>-1)DS.setCompaniesData([]);else data_load_file(DS.getCompaniesDataFile(),DS.setCompaniesData,DS)})}function data_load_repos(){var ds_not_supported=[""mediawiki""];var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds_not_supported)>-1){DS.setReposData([])}else{data_load_file(DS.getReposDataFile(),DS.setReposData,DS)}});data_load_file(Report.getReposMapFile(),Report.setReposMap)}function data_load_countries(){var ds_not_supported=[""irc"",""mediawiki""];var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds_not_supported)>-1)DS.setCountriesData([]);else data_load_file(DS.getCountriesDataFile(),DS.setCountriesData,DS)})}function data_load_domains(){var ds_not_supported=[""irc"",""mediawiki""];var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds_not_supported)>-1)DS.setDomainsData([]);else data_load_file(DS.getDomainsDataFile(),DS.setDomainsData,DS)})}function data_load_projects(){var ds_not_supported=[""irc"",""mediawiki""];var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds_not_supported)>-1)DS.setProjectsData([]);else data_load_file(DS.getProjectsDataFile(),DS.setProjectsData,DS)})}function data_load_time_to_fix(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if(DS.getName()===""its"")data_load_file(DS.getTimeToFixDataFile(),DS.setTimeToFixData,DS)})}function data_load_markov_table(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if(DS.getName()===""its"")data_load_file(DS.getMarkovTableDataFile(),DS.setMarkovTableData,DS)})}function data_load_time_to_attention(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if(DS.getName()===""mls"")data_load_file(DS.getTimeToAttentionDataFile(),DS.setTimeToAttentionData,DS)})}function data_load_demographics(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){data_load_file(DS.getDemographicsAgingFile(),DS.setDemographicsAgingData,DS);data_load_file(DS.getDemographicsBirthFile(),DS.setDemographicsBirthData,DS)})}function data_load_tops(metric){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){var file_all=DS.getTopDataFile();if(get_data_from_all(file_all,DS.setGlobalTopData,DS))return;$.when($.getJSON(file_all)).done(function(history){DS.setGlobalTopData(history);end_data_load()}).fail(function(){DS.setGlobalTopData([],DS);end_data_load()})})}Loader.check_filters_page=function(page){var check=true;var filters=[""repos"",""companies"",""countries""];$.each(filters,function(index,filter){if(!Loader.check_filter_page(page,filter)){check=false;return false}});return check};Loader.check_filter_page=function(page,filter){var check=true;if(page===undefined)page=1;var start=Report.getPageSize()*(page-1);var end=start+Report.getPageSize();$.each(Report.getDataSources(),function(index,DS){var total=0;if(filter===""repos"")total=DS.getReposData().length;if(filter===""companies"")total=DS.getCompaniesData().length;if(filter===""countries"")total=DS.getCountriesData().length;if(filter===""domains"")total=DS.getDomainsData().length;if(filter===""projects"")total=DS.getProjectsData().length;if(end>total)end=total;for(var i=start;i<end;i++){var item;if(filter===""repos""){item=DS.getReposData()[i];if(DS.getReposGlobalData()[item]===undefined||DS.getReposMetricsData()[item]===undefined){check=false;return false}}if(filter===""companies""){item=DS.getCompaniesData()[i];if(DS.getCompaniesGlobalData()[item]===undefined||DS.getCompaniesMetricsData()[item]===undefined){check=false;return false}}if(filter===""countries""){item=DS.getCountriesData()[i];if(DS.getCountriesGlobalData()[item]===undefined||DS.getCountriesMetricsData()[item]===undefined){check=false;return false}}if(filter===""domains""){item=DS.getDomainsData()[i];if(DS.getDomainsGlobalData()[item]===undefined||DS.getDomainsMetricsData()[item]===undefined){check=false;return false}}if(filter===""projects""){item=DS.getProjectsData()[i];if(DS.getProjectsGlobalData()[item]===undefined||DS.getProjectsMetricsData()[item]===undefined){check=false;return false}}}end=start+Report.getPageSize()});return check};function getItemDS(item,filter){var ds=null;$.each(Report.getDataSources(),function(index,DS){if(filter==""repos""){if($.inArray(item,DS.getReposData())>-1){ds=DS;return false}}if(filter==""companies""){if($.inArray(item,DS.getCompaniesData())>-1){ds=DS;return false}}if(filter==""countries""){if($.inArray(item,DS.getCountriesData())>-1){ds=DS;return false}}if(filter==""domains""){if($.inArray(item,DS.getDomainsData())>-1){ds=DS;return false}}if(filter==""projects""){if($.inArray(item,DS.getProjectsData())>-1){ds=DS;return false}}});return ds}Loader.filterTopCheck=function(item,filter){var check=true;if(filter===""repos""){if(Loader.check_item(item,filter,""top"")===false){ds=getItemDS(item,filter);if(ds===null){Report.log(""Can't find data source for ""+item);return true}if($.inArray(ds.getName(),ds_supporting_top_repos)>=0){Loader.data_load_item_top(item,ds,null,Convert.convertFilterTop,filter,""top"")}return false}}return check};Loader.FilterItemCheck=function(item,filter){var check=true,ds;var map=Report.getReposMap();if(filter===""repos""){if(Loader.check_item(item,filter)===false){ds=getItemDS(item,filter);if(ds===null){Report.log(""Can't find data source for ""+item);return true}Loader.data_load_item(item,ds,null,Convert.convertFilterStudyItem,filter,null);if($.inArray(ds.getName(),ds_supporting_top_repos)>=0){Loader.data_load_item_top(item,ds,null,Convert.convertFilterStudyItem,filter)}return false}if(map!==undefined&&map.length!==0){var items_map=[];$.each(Report.getDataSources(),function(index,DS){var itmap=Convert.getRealItem(DS,filter,item);if(itmap!==undefined&&itmap!==null)items_map.push(itmap)});if(Loader.check_items(items_map,filter)===false){for(var i=0;i<items_map.length;i++){if(Loader.check_item(items_map[i],filter)===false){ds=getItemDS(items_map[i],filter);if(ds===null){Report.log(""Can't find ""+items_map[i]);Report.log(""Check repos-map.json"");continue}Loader.data_load_item(items_map[i],ds,null,Convert.convertFilterStudyItem,filter,items_map)}}check=false}}}else{$.each(Report.getDataSources(),function(index,DS){if(Loader.check_item(item,filter)===false){check=false;Loader.data_load_item(item,DS,null,Convert.convertFilterStudyItem,filter,null);if(filter===""companies""){if($.inArray(DS.getName(),ds_not_supported_company_top)===-1)Loader.data_load_item_top(item,DS,null,Convert.convertFilterStudyItem,filter)}}})}return check};Loader.check_item=function(item,filter,optional_filter){var check=false;$.each(Report.getDataSources(),function(index,DS){if(filter===""repos""){if(optional_filter===""top""){if($.inArray(DS.getName(),ds_supporting_top_repos)>=0&&$.inArray(item,DS.getReposData())>=0&&DS.getRepositoriesTopData()[item]!==undefined){check=true;return false}}else{if(DS.getReposGlobalData()[item]!==undefined&&DS.getReposMetricsData()[item]!==undefined){check=true;return false}}}else if(filter===""companies""){var companies=DS.getCompaniesData();if(companies.length===0)check=true;else if($.inArray(item,companies)===-1)check=true;else if(DS.getCompaniesGlobalData()[item]===undefined||DS.getCompaniesMetricsData()[item]===undefined){check=false;return false}else if($.inArray(DS.getName(),ds_not_supported_company_top)===-1&&DS.getCompaniesTopData()[item]===undefined){check=false;return false}else check=true}else if(filter===""countries""){var countries=DS.getCountriesData();if(countries.length===0)check=true;else if($.inArray(item,countries)===-1)check=true;else if(DS.getCountriesGlobalData()[item]===undefined||DS.getCountriesMetricsData()[item]===undefined){check=false;return false}else check=true}else if(filter===""domains""){var domains=DS.getDomainsData();if(domains.length===0)check=true;else if($.inArray(item,domains)===-1)check=true;else if(DS.getDomainsGlobalData()[item]===undefined||DS.getDomainsMetricsData()[item]===undefined){check=false;return false}else check=true}else if(filter===""projects""){var projects=DS.getProjectsData();if(projects.length===0)check=true;else if($.inArray(item,projects)===-1)check=true;else if(DS.getProjectsGlobalData()[item]===undefined||DS.getProjectsMetricsData()[item]===undefined){check=false;return false}else check=true}});return check};Loader.check_items=function(items,filter){var check=true;$.each(items,function(id,item){if(Loader.check_item(item,filter)===false){check=false;return false}});return check};Loader.data_load_items_page=function(DS,page,cb,filter){if(page===undefined)page=1;if(filter===""repos"")if(DS.getReposData()===null)return false;if(filter===""companies"")if(DS.getCompaniesData()===null)return false;if(filter===""countries"")if(DS.getCountriesData()===null)return false;if(filter===""domains"")if(DS.getDomainsData()===null)return false;if(filter===""projects"")if(DS.getProjectsData()===null)return false;var total=0;if(filter===""repos"")total=DS.getReposData().length;if(filter===""companies"")total=DS.getCompaniesData().length;if(filter===""countries"")total=DS.getCountriesData().length;if(filter===""domains"")total=DS.getDomainsData().length;if(filter===""projects"")total=DS.getProjectsData().length;if(total===0)return true;var start=Report.getPageSize()*(page-1);var end=start+Report.getPageSize();if(end>total)end=total;for(var i=start;i<end;i++){if(filter===""repos""){var repo=DS.getReposData()[i];Loader.data_load_item(repo,DS,page,cb,""repos"")}else if(filter===""companies""){var company=DS.getCompaniesData()[i];Loader.data_load_item(company,DS,page,cb,""companies"")}else if(filter===""countries""){var country=DS.getCountriesData()[i];Loader.data_load_item(country,DS,page,cb,""countries"")}else if(filter===""domains""){var domain=DS.getDomainsData()[i];Loader.data_load_item(domain,DS,page,cb,""domains"")}else if(filter===""projects""){var project=DS.getProjectsData()[i];Loader.data_load_item(project,DS,page,cb,""projects"")}}};Loader.check_people_item=function(item){var check=true;$.each(Report.getDataSources(),function(index,DS){if(DS.getPeopleGlobalData()[item]===undefined||DS.getPeopleMetricsData()[item]===undefined){check=false;return false}});return check};Loader.data_load_people_item=function(upeople_id,DS,cb){var file=DS.getDataDir()+""/people-""+upeople_id+""-""+DS.getName();var file_evo=file+""-evolutionary.json"";var file_static=file+""-static.json"";if(all_data){file_evo_no_path=file_evo.replace(Report.getDataDir()+""/"","""");file_static_no_path=file_static.replace(Report.getDataDir()+""/"","""");data_evo=all_data[file_evo_no_path];data_static=all_data[file_static_no_path];if(data_evo&&data_static){DS.addPeopleMetricsData(upeople_id,data_evo,DS);DS.addPeopleGlobalData(upeople_id,data_static,DS);if(Loader.check_people_item(upeople_id))cb(upeople_id);return}}$.when($.getJSON(file_evo),$.getJSON(file_static)).done(function(evo,global){DS.addPeopleMetricsData(upeople_id,evo[0],DS);DS.addPeopleGlobalData(upeople_id,global[0],DS);if(Loader.check_people_item(upeople_id))cb(upeople_id)}).fail(function(){DS.addPeopleMetricsData(upeople_id,[],DS);DS.addPeopleGlobalData(upeople_id,[],DS); if(Loader.check_people_item(upeople_id))cb(upeople_id)})};function getFilterSuffix(filter){var filter_suffix="""";if(filter===""repos""){filter_suffix=""rep""}else if(filter===""companies""){filter_suffix=""com""}else if(filter===""countries""){filter_suffix=""cou""}else if(filter===""domains""){filter_suffix=""dom""}else if(filter===""projects""){filter_suffix=""prj""}return filter_suffix}Loader.data_load_item_top=function(item,DS,page,cb,filter,optional_filter){var file_top=DS.getDataDir()+""/""+item+""-""+DS.getName();file_top+=""-""+getFilterSuffix(filter)+""-top-"";if(DS.getName()===""scm"")file_top+=""authors"";else if(DS.getName()===""its"")file_top+=""closers"";else if(DS.getName()===""mls"")file_top+=""senders"";else return;file_top+="".json"";if(all_data){file_no_path=file_top.replace(Report.getDataDir()+""/"","""");data=all_data[file_no_path];if(data){if(filter===""companies"")DS.addCompanyTopData(item,data);else if(filter===""repos"")DS.addRepositoryTopData(item,data);if(Loader.check_item(item,filter,optional_filter)){if(!cb.called_item)cb(filter);cb.called_item=true}return}}$.when($.getJSON(file_top)).done(function(top){if(filter===""companies""){DS.addCompanyTopData(item,top)}else if(filter===""repos""){DS.addRepositoryTopData(item,top)}}).fail(function(){if(filter===""companies""){DS.addCompanyTopData(item,[])}else if(filter===""repos""){DS.addRepositoryTopData(item,[])}}).always(function(){if(Loader.check_item(item,filter,optional_filter)){if(!cb.called_item)cb(filter);cb.called_item=true}})};Loader.data_load_item=function(item,DS,page,cb,filter,items_map){var ds_not_supported_countries=[""irc"",""mediawiki""];var ds_not_supported_companies=[""irc"",""mediawiki""];var ds_not_supported_domains=[""irc"",""mediawiki""];var ds_not_supported_repos=[""mediawiki""];var ds_not_supported_projects=[""irc"",""mediawiki""];if(filter===""repos""){if($.inArray(DS.getName(),ds_not_supported_repos)>-1){DS.addRepoMetricsData(item,[],DS);DS.addRepoGlobalData(item,[],DS);return}}else if(filter===""companies""){if($.inArray(DS.getName(),ds_not_supported_companies)>-1){DS.addCompanyMetricsData(item,[],DS);DS.addCompanyGlobalData(item,[],DS);return}}else if(filter===""countries""){if($.inArray(DS.getName(),ds_not_supported_countries)>-1){DS.addCountryMetricsData(item,[],DS);DS.addCountryGlobalData(item,[],DS);return}}else if(filter===""domains""){if($.inArray(DS.getName(),ds_not_supported_domains)>-1){DS.addDomainMetricsData(item,[],DS);DS.addDomainGlobalData(item,[],DS);return}}else if(filter===""projects""){if($.inArray(DS.getName(),ds_not_supported_projects)>-1){DS.addDomainMetricsData(item,[],DS);DS.addDomainGlobalData(item,[],DS);return}}else return;var item_uri=encodeURIComponent(item);var file=DS.getDataDir()+""/""+item_uri+""-"";file+=DS.getName()+""-""+getFilterSuffix(filter);var file_evo=file+""-evolutionary.json"";var file_static=file+""-static.json"";function addData(item,evo,global,DS){if(filter===""repos""){DS.addRepoMetricsData(item,evo,DS);DS.addRepoGlobalData(item,global,DS)}else if(filter===""companies""){DS.addCompanyMetricsData(item,evo,DS);DS.addCompanyGlobalData(item,global,DS)}else if(filter===""countries""){DS.addCountryMetricsData(item,evo,DS);DS.addCountryGlobalData(item,global,DS)}else if(filter===""domains""){DS.addDomainMetricsData(item,evo,DS);DS.addDomainGlobalData(item,global,DS)}else if(filter===""projects""){DS.addProjectMetricsData(item,evo,DS);DS.addProjectGlobalData(item,global,DS)}}function check_data(){if(page!==null){if(Loader.check_filter_page(page,filter)){if(cb.called_page===undefined){cb.called_page={};cb.called_page[filter]=true;cb(filter)}else if(!cb.called_page[filter]){cb(filter);cb.called_page[filter]=true}}}else if(items_map!==null){if(Loader.check_items(items_map,filter)){if(cb.called_map===undefined){cb.called_map={};cb.called_map[filter]=true;cb(filter)}else if(!cb.called_map[filter]){cb(filter);cb.called_map[filter]=true}}}else{if(Loader.check_item(item,filter)){if(cb.called_item===undefined){cb.called_item={};cb.called_item[filter]=true;cb(filter,item)}else if(!cb.called_item[filter]){cb(filter,item);cb.called_item[filter]=true}}}}if(all_data){file_evo_no_path=decodeURIComponent(file_evo.replace(Report.getDataDir()+""/"",""""));file_static_no_path=decodeURIComponent(file_static.replace(Report.getDataDir()+""/"",""""));data_evo=all_data[file_evo_no_path];data_static=all_data[file_static_no_path];if(data_evo&&data_static){addData(item,data_evo,data_static,DS);check_data();return}}$.when($.getJSON(file_evo),$.getJSON(file_static)).done(function(evo,global){addData(item,evo[0],global[0],DS)}).always(function(){check_data()})};function data_load_metrics(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){data_load_file(DS.getDataFile(),DS.setData,DS);data_load_file(DS.getGlobalDataFile(),DS.setGlobalData,DS);if(DS instanceof MLS){data_load_file(DS.getListsFile(),DS.setListsData,DS)}})}function data_load_metrics_definition(){data_load_file(""VizGrimoireJS/data/metrics.json"",Report.setMetricsDefinition)}function data_load_people(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){data_load_file(DS.getPeopleDataFile(),DS.setPeopleData,DS)})}function data_load_people_identities(){data_load_file(Report.getDataDir()+""/people.json"",Report.setPeopleIdentities)}function check_companies_loaded(DS){if(DS.getCompaniesData()===null)return false;return true}function check_repos_loaded(DS){if(DS.getReposData()===null)return false;return true}function check_countries_loaded(DS){if(DS.getCountriesData()===null)return false;return true}function check_domains_loaded(DS){if(DS.getDomainsData()===null)return false;return true}function check_projects_loaded(DS){if(DS.getProjectsData()===null)return false;return true}function check_meta_projects_loaded(){var projects_loaded=0;var projects_data=Report.getProjectsData();var projects_dirs=Report.getProjectsDirs();for(var key in projects_data){projects_loaded++}if(projects_loaded<projects_dirs.length)return false;return true}function check_data_loaded_global(){var check=true;if(Report.getProjectData()===null||Report.getVizConfig()===null)return false;if(Report.getConfig()===null)if(Report.getMarkers()===null)return false;if(Report.getReposMap()===null)return false;if(Report.getConfig()===null)if(!check_meta_projects_loaded())return false;var data_sources=Report.getDataSources();$.each(data_sources,function(index,DS){if(DS.getData()===null){check=false;return false}if(DS.getGlobalData()===null){check=false;return false}if(DS.getGlobalTopData()===null){check=false;return false}if(DS.getDemographicsData().aging===undefined||DS.getDemographicsData().birth===undefined){check=false;return false}if(DS.getName()===""its"")if(DS.getTimeToFixData()===null){check=false;return false}if(DS.getName()===""mls"")if(DS.getTimeToAttentionData()===null){check=false;return false}});return check}Loader.check_data_loaded=function(){var check=true;if(!check_data_loaded_global())return false;var data_sources=Report.getDataSources();var active_reports=[""companies"",""repositories"",""countries"",""domains"",""projects""];if(Report.getConfig()!==null&&Report.getConfig().reports!==undefined)active_reports=Report.getConfig().reports;$.each(data_sources,function(index,DS){if(DS.getPeopleData()===null){check=false;return false}if($.inArray(""companies"",active_reports)>-1)if(!check_companies_loaded(DS)){check=false;return false}if($.inArray(""repositories"",active_reports)>-1)if(!check_repos_loaded(DS)){check=false;return false}if($.inArray(""countries"",active_reports)>-1)if(!check_countries_loaded(DS)){check=false;return false}if($.inArray(""domains"",active_reports)>-1)if(!check_domains_loaded(DS)){check=false;return false}if($.inArray(""projects"",active_reports)>-1)if(!check_projects_loaded(DS)){check=false;return false}if(DS instanceof MLS){if(DS.getListsData()===null){check=false;return false}}});return check};function end_data_load(){if(check_data_loaded_global()){for(var i=0;i<data_global_callbacks.length;i++){data_global_callbacks[i]()}data_global_callbacks=[]}if(Loader.check_data_loaded()){for(var j=0;j<data_callbacks.length;j++){if(data_callbacks[j].called!==true)data_callbacks[j]();data_callbacks[j].called=true}}}})();var DataProcess={};(function(){DataProcess.info=function(){};DataProcess.paginate=function(data,page){if(page===undefined||page===0||isNaN(page))return data;var page_items=[];var psize=Report.getPageSize();var start=(page-1)*psize;for(var i=start;i<psize*page;i++){if(data[i])page_items.push(data[i])}return page_items};DataProcess.convert=function(data,convert,metric_ids){if(convert===""aggregate""){data=DataProcess.aggregate(data,metric_ids)}else if(convert===""substract""){data=DataProcess.substract(data,metric_ids[0],metric_ids[1]);metric_ids=[""substract""]}else if(convert===""substract-aggregate""){data=DataProcess.substract(data,metric_ids[0],metric_ids[1]);metric_ids=[""substract""];data=DataProcess.aggregate(data,metric_ids)}else if(convert===""divide""){data=DataProcess.divide(data,metric_ids[0],metric_ids[1]);metric_ids=[""divide""]}return data};DataProcess.sortGlobal=function(ds,metric_id,kind){if(metric_id===undefined)metric_id=""scm_commits"";var metric=[];var data=[],sorted={};sorted.name=[];sorted[metric_id]=[];var metrics_data=null;if(kind===""companies""){data=ds.getCompaniesData();metrics_data=ds.getCompaniesDataFull()}else if(kind===""repos""){data=ds.getReposData();metrics_data=ds.getReposDataFull()}else if(kind===""countries""){data=ds.getCountriesData()}else if(kind===""domains""){data=ds.getDomainsData();metrics_data=ds.getDomainsDataFull()}else if(kind===""projects""){data=ds.getProjectsData()}if(data===null)return[];if(metrics_data===null)return data;if(metrics_data instanceof Array||metric_id in metrics_data===false)return data;for(var i=0;i<metrics_data[metric_id].length;i++){var value=metrics_data[metric_id][i];if(value===""NA"")value=0;metric.push([metrics_data.name[i],value])}metric.sort(function(a,b){return b[1]-a[1]});$.each(metric,function(id,value){sorted.name.push(value[0]);sorted[metric_id].push(value[1])});return sorted.name};DataProcess.orderItems=function(filter_order){$.each($(""[class^='FilterItems']""),function(id,div){order_by=$(this).data(""order-by"");if(order_by!==undefined){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;var filter=$(this).data(""filter"");if(filter===undefined)return;if(filter!==filter_order)return;Report.log(""Ordering with ""+order_by+"" ""+ds+"" for ""+filter);var data=DataProcess.sortGlobal(DS,order_by,filter);if(filter===""companies"")DS.setCompaniesData(data);if(filter===""repos"")DS.setReposData(data);if(filter===""countries"")DS.setCountriesData(data);if(filter===""domains"")DS.setDomainsData(data);return false}})};DataProcess.mergeConfig=function(config1,config2){var new_config={};$.each(config1,function(entry,value){new_config[entry]=value});$.each(config2,function(entry,value){new_config[entry]=value});return new_config};DataProcess.hideEmail=function(email){var clean=email;if(typeof email==""string""&&email.indexOf(""@"")>-1){clean=email.split(""@"")[0]}return clean};DataProcess.selectPersonName=function(person){var name="""",cname,ctype,i;if(person.identity){for(i=0;i<person.identity.length;i++){cname=person.identity[i];ctype=person.type[i];if(ctype===""name""){if(cname.length>name.length)name=cname}}}else if(person.name){if(person.name.constructor!==Array){person.name=[person.name]}for(i=0;i<person.name.length;i++){cname=person.name[i];if(cname!==null&&cname.length>name.length){name=cname}}}return name};DataProcess.selectPersonEmail=function(person){var email="""",cemail,ctype;if(person.identity===undefined)return;for(var i=0;i<person.identity.length;i++){cemail=person.identity[i];ctype=person.type[i];if(ctype===""email""){email=cemail}}return email};DataProcess.frameTime=function(history,metrics){var new_history={};var offset_start=-1;var offset_end=-1;var new_offset=0;if(metrics.length===0)return history;if(history[metrics[0]]===undefined)return history;var total=history[metrics[0]].length;var i=0;$.each(metrics,function(id,metric){new_offset=0;for(i=0;i<history[metric].length;i++){if(history[metric][i]===0)new_offset++;else{if(offset_start===-1)offset_start=new_offset;if(new_offset<offset_start)offset_start=new_offset;break}}});$.each(metrics,function(id,metric){new_offset=0;for(i=history[metric].length-1;i>=0;i--){if(history[metric][i]===0)new_offset++;else{if(offset_end===-1)offset_end=new_offset;if(new_offset<offset_end)offset_end=new_offset;break}}});for(var key in history){new_history[key]=[];for(i=0;i<history[key].length;i++){if(i<offset_start)continue;if(i>=total-offset_end)continue;new_history[key].push(history[key][i])}}return new_history};DataProcess.filterDates=function(start_id,end_id,history){var history_dates={};$.each(history,function(name,data){history_dates[name]=[];$.each(data,function(i,value){var id=history.unixtime[i];if(id>start_id)if(!end_id||end_id&&id<=end_id)history_dates[name].push(value)})});return history_dates};DataProcess.filterYear=function(year,history){year=parseInt(year,null);var min_id=new Date(year.toString()).getTime();var max_id=new Date((year+1).toString()).getTime();var history_year=filterDates(min_id,max_id,history);return history_year};DataProcess.fillDates=function(dates_orig,more_dates){if(dates_orig[0].length===0)return more_dates;var new_dates=[[],[]];var i=0;if(dates_orig[0][0]>more_dates[0][0]){for(i=0;i<more_dates[0].length;i++){new_dates[0][i]=more_dates[0][i];new_dates[1][i]=more_dates[1][i]}}for(i=0;i<dates_orig[0].length;i++){pos=new_dates[0].indexOf(dates_orig[0][i]);if(pos===-1){new_dates[0].push(dates_orig[0][i]);new_dates[1].push(dates_orig[1][i])}}if(dates_orig[0][dates_orig[0].length-1]<more_dates[0][more_dates[0].length-1]){for(i=0;i<more_dates[0].length;i++){pos=new_dates[0].indexOf(more_dates[0][i]);if(pos===-1){new_dates[0].push(more_dates[0][i]);new_dates[1].push(more_dates[1][i])}}}return new_dates};DataProcess.fillHistory=function(hist_complete_id,hist_partial){var new_history=[[],[]];for(var i=0;i<hist_complete_id.length;i++){pos=hist_partial[0].indexOf(hist_complete_id[i]);new_history[0][i]=hist_complete_id[i];if(pos!=-1){new_history[1][i]=hist_partial[1][pos]}else{new_history[1][i]=0}}return new_history};DataProcess.fillHistoryLines=function(hist_complete_id,hist_partial){var old_history=[[],[]];var new_history=[[],[]];var lines_history=[];for(var i=0;i<hist_partial.length;i++){old_history[0].push(hist_partial[i][0]);old_history[1].push(hist_partial[i][1])}new_history=DataProcess.fillHistory(hist_complete_id,old_history);for(i=0;i<hist_complete_id.length;i++){lines_history.push([new_history[0][i],new_history[1][i]])}return lines_history};DataProcess.addRelativeValues=function(metrics_data,metric){if(metrics_data[metric]===undefined)return;metrics_data[metric+""_relative""]=[];var added_values=[];$.each(metrics_data[metric],function(index,pdata){var metric_values=pdata.data[1];for(var i=0;i<metric_values.length;i++){if(added_values[i]===undefined)added_values[i]=0;added_values[i]+=metric_values[i]}});$.each(metrics_data[metric],function(index,pdata){var val_relative=[];for(var i=0;i<pdata.data[0].length;i++){if(added_values[i]===0)val_relative[i]=0;else{var rel_val=pdata.data[1][i]/added_values[i]*100;val_relative[i]=rel_val}}metrics_data[metric+""_relative""].push({label:pdata.label,data:[pdata.data[0],val_relative]})})};DataProcess.aggregate=function(data,metrics){var new_data={};if(!(metrics instanceof Array))metrics=[metrics];$.each(data,function(metric,mdata){if($.inArray(metric,metrics)>-1){var metric_agg=[];metric_agg[0]=data[metric][0];for(var i=1;i<data[metric].length;i++){metric_agg[i]=metric_agg[i-1]+data[metric][i]}new_data[metric]=metric_agg}else{new_data[metric]=data[metric]}});return new_data};DataProcess.substract=function(data,metric1,metric2){var new_data={};var substract=[];for(var i=0;i<data[metric1].length;i++){substract[i]=data[metric1][i]-data[metric2][i]}$.each(data,function(metric,mdata){new_data[metric]=data[metric]});new_data.substract=substract;return new_data};DataProcess.divide=function(data,metric1,metric2){var new_data={};var divide=[];for(var i=0;i<data[metric1].length;i++){if(data[metric1][i]===0||data[metric2][i]===0)divide[i]=0;else divide[i]=parseInt(data[metric1][i]/data[metric2][i],null)}$.each(data,function(metric,mdata){new_data[metric]=data[metric]});new_data.divide=divide;return new_data};DataProcess.revomeLastPoint=function(data){var new_data={};$.each(data,function(key,value){new_data[key]=[];for(var i=0;i<data[key].length-1;i++){new_data[key].push(data[key][i])}});return new_data}})();var Utils={};(function(){Utils.paramsInURL=paramsInURL;Utils.isReleasePage=isReleasePage;Utils.filenameInURL=filenameInURL;Utils.createLink=createLink;Utils.createReleaseLink=createReleaseLink;Utils.getParameter=getParameter;$.urlParam=function(name){var results=new RegExp(""[?&]""+name+""=([^&#]*)"").exec(window.location.href);if(results===null){return null}else{return results[1]||0}};function isReleasePage(){if($.urlParam(""release"")===null)return false;else return true}function paramsInURL(){params="""";if(document.URL.split(""?"").length>1){params=document.URL.split(""?"")[1]}return params}function filenameInURL(){aux=document.URL.split(""?"")[0].split(""/"");res=aux[aux.length-1];return res}function createLink(target){url=target;if(paramsInURL().length>0)url+=""?""+paramsInURL();return url}function createReleaseLink(target){url=target;if(isReleasePage()){if(url.indexOf(""?"")>=0){url+=""&release=""+$.urlParam(""release"")}else{url+=""?release=""+$.urlParam(""release"")}}return url}function getParameter(param){if($.urlParam(param)===null)return false;return $.urlParam(param)}})();String.prototype.supplant=function(o){return this.replace(/{([^{}]*)}/g,function(a,b){var r=o[b];return typeof r===""string""||typeof r===""number""?r:a})};var HTMLComposer={};(function(){HTMLComposer.personDSBlock=personDSBlock;HTMLComposer.filterDSBlock=filterDSBlock;HTMLComposer.DSBlock=DSBlock;HTMLComposer.DSBlockProject=DSBlockProject;HTMLComposer.repositorySummaryTable=repositorySummaryTable;HTMLComposer.personSummaryTable=personSummaryTable;HTMLComposer.personName=personName;HTMLComposer.itemName=itemName;HTMLComposer.releaseSelector=releaseSelector;HTMLComposer.sideBarLinks=sideBarLinks;HTMLComposer.overallSummaryBlock=overallSummaryBlock;HTMLComposer.smartLinks=smartLinks;HTMLComposer.TopByPeriod=TopByPeriod;HTMLComposer.companyFilters=companyFilters;function personDSBlock(ds_name,metric_name,ds_realname){var html='<div class=""col-md-12"">';html+='<div class=""well well-small"">';html+='<div class=""row"">';html+='<div class=""col-md-12"">';if(ds_realname===undefined){html+=""<p>""+title4DS(ds_name)+""</p>""}else{html+=""<p>""+title4DS(ds_realname)+""</p>""}html+=""</div>"";html+='<div class=""col-md-3"">';html+='<div class=""PersonSummary"" data-data-source=""'+ds_name+'""></div>';html+=""</div>"";html+='<div class=""col-md-9"">';html+='<div class=""PersonMetrics"" data-data-source=""'+ds_name+'""';html+='data-metrics=""'+metric_name+'"" data-min=""true""';html+='data-frame-time=""true""></div>';html+=""</div>"";html+=""</div>"";html+=""</div>"";html+=""</div>"";return html}function filterDSBlock(ds_name,filter_name,metric_names,ds_realname){var html='<div class=""col-md-12"">';html+='<div class=""row"">';html+='<div class=""col-md-3"">';html+='<div class=""well"">';if(ds_realname){html+='<div class=""FilterItemSummary"" data-data-source=""'+ds_name+'"" data-filter=""'+filter_name+'"" data-data-realname=""'+ds_realname+'""></div>'}else{html+='<div class=""FilterItemSummary"" data-data-source=""'+ds_name+'"" data-filter=""'+filter_name+'""></div>'}html+=""</div></div>"";html+='<div class=""col-md-9"">';html+='<div class=""well"">';$.each(metric_names,function(id,metric){html+='<div class=""row""><div class=""col-md-12""></br></br></div></div>';html+='<div class=""row"">';html+='<div class=""col-md-12"">';html+='<div class=""FilterItemMetricsEvol"" data-data-source=""'+ds_name+'""';html+='data-metrics=""'+metric+'"" data-min=""true""';html+='data-filter=""'+filter_name+'"" data-frame-time=""true""></div>';html+=""</div></div>""});html+=""</div></div></div></div>"";return html}function repositorySummaryTable(ds,global_data,id_label,ds_realname){var html=""<table class='table-condensed table-hover'>"",ds_title;if(ds_realname){ds_title=title4DS(ds_realname)}else{ds_title=title4DS(ds.getName())}html+='<tr><td colspan=""2""><p class=""subsection-title"">'+ds_title+""</p></td></tr>"";var html_irow=""<tr><td>"";var html_erow=""</td></tr>"";$.each(global_data,function(id,value){if(ds.getMetrics()[id]){html+=html_irow+ds.getMetrics()[id].name;if(id===""first_date""||id===""last_date""){html+='</td><td class=""numberInTD"">'+value+html_erow}else{html+='</td><td class=""numberInTD"">'+Report.formatValue(value)+html_erow}}else if(id_label[id]){html+=html_irow+id_label[id];if(id===""first_date""||id===""last_date""){html+='</td><td class=""numberInTD"">'+value+html_erow}else{html+='</td><td class=""numberInTD"">'+Report.formatValue(value)+html_erow}}});html+=""</table>"";return html}function personSummaryTable(ds_name,history){var html=""<table class='table-condensed table-hover'>"";html+=""<tr><td>"";html+=""First contribution: </br>"";html+=""&nbsp;&nbsp;""+history.first_date;html+=""</td></tr><tr><td>"";html+=""Last contribution: </br>"";html+=""&nbsp;&nbsp;""+history.last_date;html+=""</td></tr><tr><td>"";if(ds_name==""scm"")html+=""Commits:</br>&nbsp;&nbsp;""+history.scm_commits;else if(ds_name==""its"")html+=""Closed:</br>&nbsp;&nbsp;""+history.its_closed;else if(ds_name==""mls"")html+=""Sent:</br>&nbsp;&nbsp;""+history.mls_sent;else if(ds_name==""irc"")html+=""Sent:</br>&nbsp;&nbsp;""+history.irc_sent;else if(ds_name==""scr""){if(history.scr_closed!==undefined){html+=""Closed:</br>&nbsp;&nbsp;""+history.scr_closed}if(history.scr_submissions!==undefined){html+=""Submissions:</br>&nbsp;&nbsp;""+history.scr_submissions}}html+=""</td></tr>"";html+=""</table>"";return html}function personName(name,email){var html='<p class=""section-title"" style=""margin-bottom:0px;""><i class=""fa fa-user fa-lg""></i> &nbsp;&nbsp;';if(name.length>0)html+=name;else if(email.length>0){if(email.indexOf(""@"")>0)email=email.split(""@"")[0];html+=email}html+=""</p>"";return html}function itemName(text,filter_name){var html='<p class=""section-title"" style=""margin-bottom:0px;"">';if(filter_name===""companies"")html+='<i class=""fa fa-building-o""></i> &nbsp;&nbsp;';html+=text;html+=""</p>"";return html}function title4DS(ds_name){var title="""";if(ds_name===""scm"")title='<i class=""fa fa-code""></i> Source Code Management';else if(ds_name===""scr"")title='<i class=""fa fa-check""></i> Source Code Review';else if(ds_name===""its"")title='<i class=""fa fa-ticket""></i> Issue tracking system';else if(ds_name===""storyboard"")title='<i class=""fa fa-ticket""></i> StoryBoard';else if(ds_name===""mls"")title='<i class=""fa fa-envelope-o""></i> Mailing Lists';else if(ds_name===""irc"")title='<i class=""fa fa-comment-o""></i> IRC Channels';else if(ds_name===""slack"")title='<i class=""fa fa-comment-o""></i> Slack';else if(ds_name===""mediawiki"")title='<i class=""fa fa-pencil-square-o""></i> Wiki';else if(ds_name===""releases"")title='<i class=""fa fa-umbrella""></i> Forge Releases';else if(ds_name===""meetup"")title='<i class=""fa fa-users""></i> Meetup';return title}function releaseSelector(current_release,release_names){function get_label(url,labels){label="""";$.each(labels,function(pos,data){if(data[1]===url){label=data[0];return false}});return label}if(release_names.length===0)return"""";var release_names_labels=null;if(release_names[0]instanceof Array){var old_relase_names=[];$.each(release_names,function(pos,data){old_relase_names.push(data[1])});release_names_labels=release_names;release_names=old_relase_names}unsupported=[""irc.html"",""qaforums.html"",""project.html""];ah_label=""&nbsp;All history&nbsp;"";label=current_release;if(label===null)label=ah_label;else{label=decodeURIComponent(label);if(release_names_labels!==null){label=get_label(label,release_names_labels);label=""&nbsp; ""+label+"" &nbsp;""}else{label=""&nbsp; ""+label[0].toUpperCase()+label.substring(1)+"" release &nbsp;""}release_names.reverse().push(ah_label);release_names.reverse()}html='<div class=""input-group-btn"">';html+='<button type=""button"" class=""btn btn-default btn-lg btn-releaseselector dropdown-toggle""';html+='data-toggle=""dropdown"">';html+=label;html+='<span class=""caret""></span>';html+=""</button>"";html+='<ul class=""dropdown-menu pull-left"">';page_name=Utils.filenameInURL();if(unsupported.indexOf(page_name)<0){$.each(release_names,function(id,value){var final_p=[];params=Utils.paramsInURL().split(""&"");for(i=0;i<params.length;i++){sub_value=params[i];if(sub_value.length===0)continue;if(sub_value.indexOf(""release"")===0){if(value!=ah_label)final_p.push(""release=""+value)}else{final_p.push(sub_value)}}if($.urlParam(""release"")===null){final_p.push(""release=""+value)}if(value===ah_label){html+='<li><a href=""'+page_name+""?""+final_p.join(""&"")+'"" data-value=""'+value+'""> '+value+""</a></li>""}else{html+='<li><a href=""'+page_name+""?""+final_p.join(""&"")+'"" data-value=""'+value+'""> ';if(release_names_labels!==null){html+=get_label(value,release_names_labels)+""</li>""}else{html+=value[0].toUpperCase()+value.substring(1)+"" release</a></li>""}}})}else{html+=""<li><i>No releases for this section</i></li>""}html+=""</ul>"";html+=""</div>"";return html}function DSBlock(ds_name,box_labels,box_metrics,ts_metrics){html="""";html+=""<!-- irc -->"";html+='<div class=""row invisible-box"">';blabels=box_labels.split("","");bmetrics=box_metrics.split("","");html+=DSSummaryBox(ds_name,blabels,bmetrics,false,ds_realname);html+='<div class=""col-md-5"">';tsm=ts_metrics.split("","");html+=DSTimeSerie(ds_name,tsm[0],false,ds_realname);html+=""</div>"";html+='<div class=""col-md-5"">';html+=DSTimeSerie(ds_name,tsm[1],false,ds_realname);html+=""</div>"";html+=""</div>"";html+=""<!-- end irc -->"";return html}function DSBlockProject(ds_name,box_labels,box_metrics,ts_metrics,pname){html="""";html+=""<!-- irc -->"";html+='<div class=""row invisible-box"">';blabels=box_labels.split("","");bmetrics=box_metrics.split("","");html+=DSSummaryBox(ds_name,blabels,bmetrics,true);html+='<div class=""col-md-5"">';tsm=ts_metrics.split("","");html+=DSTimeSerie(ds_name,tsm[0],true);html+=""</div>"";html+='<div class=""col-md-5"">';html+=DSTimeSerie(ds_name,tsm[1],true);html+=""</div>"";html+=""</div>"";html+=""<!-- end irc -->"";return html}function linkToPanel(ds_name,ds_realname){if(ds_realname===undefined){target_page=Utils.createLink(ds_name+"".html"")}else{target_page=Utils.createLink(ds_realname+"".html"")}return target_page}function summaryCell(width,label,ds_name,metric,project_flag,ds_realname){var target_page=linkToPanel(ds_name,ds_realname);if(project_flag){widget_name=""ProjectData""}else{widget_name=""GlobalData""}html="""";html+='<div class=""col-xs-'+width+'"">';html+='<div class=""row thin-border"">';html+='<div class=""col-md-12"">'+label+""</div>"";html+=""</div>"";html+='<div class=""row"">';html+='<div class=""col-md-12 medium-fp-number"">';if(project_flag){html+='<span class=""'+widget_name+'""';html+='data-data-source=""'+ds_name+'"" data-field=""'+metric+'""></span>'}else{html+='<a href=""'+target_page+'""> <span class=""'+widget_name+'""';html+='data-data-source=""'+ds_name+'"" data-field=""'+metric+'""></span>';html+=""</a>""}html+=""</div>"";html+=""</div>"";html+=""</div>"";return html}function DSSummaryBox(ds_name,labels,metrics,project_flag,ds_realname){var target_page=linkToPanel(ds_name,ds_realname);if(project_flag){widget_name=""ProjectData""}else{widget_name=""GlobalData""}html="""";html+=""<!-- summary box-->"";html+='<div class=""col-md-2"">';html+='<div class=""well well-small"">';html+='<div class=""row thin-border"">';html+='<div class=""col-md-12"">'+labels[0]+""</div>"";html+=""</div>"";html+='<div class=""row grey-border"">';html+='<div class=""col-md-12 big-fp-number"">';if(ds_name===""releases"")target_page=Utils.createLink(""forge.html"");if(project_flag){html+='<span class=""'+widget_name+'""';html+='data-data-source=""'+ds_name+'"" data-field=""'+metrics[0]+'""></span>'}else{html+='<a href=""'+target_page+'""> <span class=""'+widget_name+'""';html+='data-data-source=""'+ds_name+'"" data-field=""'+metrics[0]+'""></span>';html+=""</a>""}html+=""</div>"";html+=""</div>"";html+='<div class=""row"" style=""padding: 5px 0px 0px 0px;"">';if(labels.length===2&&metrics.length===2){html+=summaryCell(""12"",labels[1],ds_name,metrics[1],project_flag,ds_realname)}else if(labels.length===3&&metrics.length===3){html+=summaryCell(""6"",labels[1],ds_name,metrics[1],project_flag,ds_realname);html+=summaryCell(""6"",labels[2],ds_name,metrics[2],project_flag,ds_realname)}else if(labels.length===4&&metrics.length===4){html+=summaryCell(""4"",labels[1],ds_name,metrics[1],project_flag,ds_realname);html+=summaryCell(""4"",labels[2],ds_name,metrics[2],project_flag,ds_realname);html+=summaryCell(""4"",labels[3],ds_name,metrics[3],project_flag,ds_realname)}html+=""</div>"";html+=""</div>"";html+=""</div>"";html+=""<!-- end summary box -->"";return html}function DSTimeSerie(ds_name,metric,project_flag,ds_realname){if(project_flag){ts_widget_name=""FilterItemMetricsEvol"";trend_widget_name=""FilterItemMicrodashText"";filter_name=""projects""}else{ts_widget_name=""MetricsEvol"";trend_widget_name=""MicrodashText"";filter_name=""""}html="""";html+='<div class=""well well-small"">';html+='<div class=""'+ts_widget_name+'"" data-data-source=""'+ds_name+'""';html+=' data-filter=""'+filter_name+'""';if(project_flag){html+=' data-frame-time=""true""'}html+=' data-metrics=""'+metric+'"" data-min=""true"" style=""height: 100px;""';html+=' data-light-style=""true""></div>';if(project_flag){html+=' <span class=""'+trend_widget_name+'""';html+=' data-filter=""'+filter_name+'""';html+=' data-metric=""'+metric+'""></span>'}else{if(ds_realname===undefined){html+='<a href=""'+ds_name+'.html"" style=""color: black;"">'}else{html+='<a href=""'+ds_realname+'.html"" style=""color: black;"">'}html+=' <span class=""'+trend_widget_name+'""';html+=' data-filter=""'+filter_name+'""';html+=' data-metric=""'+metric+'""></span>';html+=""</a>""}html+=""</div>"";return html}function sideBarLinks(icon_text,title,ds_name,elements){text={companies:""Companies"",""companies-summary"":""Companies summary"",contributors:""Contributors"",countries:""Countries"",domains:""Domains"",projects:""Projects"",repos:""Repositories"",tags:""Tags"",states:""States"",past_events:""Past Events""};html="""";html+='<li class=""dropdown"">';html+='<a href=""#"" class=""dropdown-toggle"" data-toggle=""dropdown"">';html+='<i class=""fa '+icon_text+'""></i>&nbsp;'+title+' <b class=""caret""></b></a>';html+='<ul class=""dropdown-menu navmenu-nav"">';var target_page="""";if(Utils.isReleasePage()){target_page=Utils.createReleaseLink(ds_name+"".html"")}else{target_page=ds_name+"".html""}html+='<li><a href=""'+target_page+'"">&nbsp;Overview</a></li>';$.each(elements,function(id,value){if(Utils.isReleasePage()){target_page=Utils.createReleaseLink(ds_name+""-""+value+"".html"")}else{target_page=ds_name+""-""+value+"".html""}if(text.hasOwnProperty(value)){var label=text[value];if(value===""repos""){if(ds_name==""storyboard""){ds_name=""its""}var DS;if(ds_name===""slack""){DS=Report.getDataSourceByName(""irc"")}else{DS=Report.getDataSourceByName(ds_name)}label=DS.getLabelForRepositories();label=label.charAt(0).toUpperCase()+label.slice(1)}html+='<li><a href=""'+target_page+'"">&nbsp;'+label+""</a></li>""}else{html+='<li><a href=""'+target_page+'"">&nbsp;'+value+""</a></li>""}});html+=""</ul></li>"";return html}function overallSummaryBlock(){html="""";html+=""<!-- summary bar -->"";html+='<div class=""capped-box overall-summary "">';html+='<div class=""stats-switcher-viewport js-stats-switcher-viewport"">';html+='<div class=""row numbers-summary"">';html+='<div class=""col-xs-3""><a href=""'+Utils.createReleaseLink(""scm.html"")+'""><span class=""GlobalData"" ';html+='data-data-source=""scm"" data-field=""scm_commits""></span></a> commits</div>';html+='<div class=""col-xs-3""><a href=""'+Utils.createReleaseLink(""scm.html"")+'""><span class=""GlobalData"" ';html+='data-data-source=""scm"" data-field=""scm_authors""></span></a> developers ';html+=""</div>"";html+='<div class=""col-xs-3""><a href=""'+Utils.createReleaseLink(""its.html"")+'""><span class=""GlobalData"" ';html+='data-data-source=""its"" data-field=""its_opened""></span></a> tickets</div>'; html+='<div class=""col-xs-3""><a href=""'+Utils.createReleaseLink(""mls.html"")+'""><span class=""GlobalData"" ';html+='data-data-source=""mls"" data-field=""mls_sent""></span></a> mail messages ';html+=""</div>"";html+=""</div>"";html+=""</div>"";html+=""</div>"";html+=""<!-- end of summary bar -->"";return html}function smartLinks(target_page,label){html="""";link_exists=false;try{fname=target_page.split(""."")[0];section=fname.split(""-"")[0];subsection=fname.split(""-"")[1];var mele=Report.getMenuElements();if(mele[section].indexOf(subsection)>=0)link_exists=true;if(Utils.isReleasePage()&&link_exists){link_to=Utils.createReleaseLink(target_page);html='<a href=""'+link_to+'"">'+label+""</a>""}else if(link_exists){html='<a href=""'+target_page+'"">'+label+""</a>""}else{html=label}}catch(err){html=label}return html}function TopByPeriod(ds_name,metric,npeople,is_release){if(is_release){periods=[""""]}else{periods=[""last month"",""last year"",""""]}width=12/periods.length;html='<div class=""row"">';$.each(periods,function(id,value){html+='<div class=""col-md-'+width+'"">';html+='<div class=""Top"" data-data-source=""'+ds_name+'"" data-metric=""'+metric+'""';html+=' data-period=""'+value+'"" data-limit=""'+npeople+'"" data-people_links=""true""></div>';html+=""</div>""});html+=""</div>"";return html}var defaultFilterValues={scm:{metric_names:""commits+authors"",order_by:""commits_365""},its:{metric_names:""closed+closers"",order_by:""closed_365""}};function getFilterName(ds_name,metric_one,metric_two){filters={scm:{company:{country:""SCM by country""}},its:{company:{country:""ITS by country""}}};return filters[ds_name][metric_one][metric_two]}function companyFilters(company_name){var html="""",filter_ds={};var mele=Report.getMenuElements();var menu_filters=mele.filter;if(menu_filters===undefined){return html}$.each(menu_filters,function(id,value){var ds_name=value.split("":"")[0],combo=value.split("":"")[1],mylen;if(Object.keys(filter_ds).indexOf(combo)<0){filter_ds[combo]=[]}mylen=filter_ds[combo].length;filter_ds[combo][mylen]=ds_name});$.each(Object.keys(filter_ds),function(id,value){switch(value){case""company+country"":$.each(filter_ds[value],function(subid,ds_name){if(subid===0){html='<div class=""btn-group"">'+'<button type=""button"" class=""btn btn-default dropdown-toggle"" data-toggle=""dropdown"" aria-expanded=""false"">'+'<i class=""fa fa-globe""></i> Activity by country <span class=""caret""></span>'+""</button>""+'<ul class=""dropdown-menu"" role=""menu"">'}var aux_obj={};aux_obj.company_name=company_name;aux_obj.ds_name=ds_name;aux_obj.value=value;aux_obj.metric_names=defaultFilterValues[ds_name].metric_names;aux_obj.order_by=defaultFilterValues[ds_name].order_by;aux_obj.filter_name=getFilterName(ds_name,value.split(""+"")[0],value.split(""+"")[1]);var aux_html='<li><a href=""'+""filter.html?filter_by_item=company&filter_item=""+""{company_name}""+""&filter_ds_name={ds_name}""+""&filter_names={value}""+""&filter_metric_names={metric_names}""+""&filter_order_by={order_by}""+'"">{filter_name}</a></button></li>';html+=aux_html.supplant(aux_obj);if(subid===filter_ds[value].length-1){html+=""</ul></div>""}})}});return html}})();var Convert={};(function(){Convert.convertMicrodashText=function(){var divs=$("".MicrodashText"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var metric=$(this).data(""metric"");var show_name=$(this).data(""name"");var ds=Report.getMetricDS(metric)[0];if(ds===undefined)return;var total=ds.getGlobalData()[metric];var html='<div class=""row"">';if(show_name){html+='<div class=""col-xs-3"">';html+='<span class=""dayschange"">'+ds.basic_metrics[metric].name+""</span>"";html+=""</div>""}$.each([365,30,7],function(index,period){var column=ds.getMetrics()[metric].column;var value=ds.getGlobalData()[metric+""_""+period];var netvalue=ds.getGlobalData()[""diff_net""+column+""_""+period];var percentagevalue=ds.getGlobalData()[""percentage_""+column+""_""+period];percentagevalue=Math.round(percentagevalue*10)/10;if(value===undefined)return;var str_percentagevalue="""";if(percentagevalue===0){str_percentagevalue=Math.abs(percentagevalue)}else if(netvalue>0){str_percentagevalue=""+""+percentagevalue}else if(netvalue<0){str_percentagevalue=""-""+Math.abs(percentagevalue)}if(show_name){html+='<div class=""col-xs-3"">'}else{html+='<div class=""col-xs-4"">'}html+='<span class=""dayschange"">Last '+period+"" days:</span>"";html+="" ""+Report.formatValue(value)+""<br>"";if(percentagevalue===0){html+='<i class=""fa fa-arrow-circle-right""></i> <span class=""zeropercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}else if(netvalue>0){html+='<i class=""fa fa-arrow-circle-up""></i> <span class=""pospercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}else if(netvalue<0){html+='<i class=""fa fa-arrow-circle-down""></i> <span class=""negpercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}html+=""</div><!--col-xs-4-->""});html+=""</div><!--row-->"";$(div).append(html)})}};Convert.convertMicrodash=function(){var divs=$("".Microdash"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var metric=$(this).data(""metric"");var text=$(this).data(""text"");var ds=Report.getMetricDS(metric)[0];var total=ds.getGlobalData()[metric];var html=""<div>"";html+='<div style=""float:left"">';html+='<span class=""medium-fp-number"">'+Report.formatValue(total);html+=""</span> ""+ds.getMetrics()[metric].name;html+=""</div>"";html+='<div id=""Microdash"" '+'class=""MetricsEvol"" data-data-source=""'+ds.getName()+'"" data-metrics=""'+metric+'"" data-min=true style=""margin-left:10px; float:left;width:100px; height:25px;""></div>';html+='<div style=""clear:both""></div><div>';$.each([365,30,7],function(index,period){var column=ds.getMetrics()[metric].column;var netvalue=ds.getGlobalData()[""diff_net""+column+""_""+period];var percentagevalue=ds.getGlobalData()[""percentage_""+column+""_""+period];var value=ds.getGlobalData()[metric+""_""+period];if(value===undefined)return;html+=""<span class='dayschange'>""+period+"" Days Change</span>:""+Report.formatValue(value)+""&nbsp;"";if(netvalue===0){html+=""""}else if(netvalue>0){html+='<i class=""icon-circle-arrow-up""></i>';html+=""<small>(+""+percentagevalue+""%)</small>&nbsp;""}else if(netvalue<0){html+='<i class=""icon-circle-arrow-down""></i>';html+=""<small>(-""+Math.abs(percentagevalue)+""%)</small>&nbsp;""}});html+=""</div>"";html+=""<div>"";$(div).append(html)})}};function getProjectTitle(project_id,hierarchy){if(hierarchy.hasOwnProperty(project_id)&&hierarchy[project_id].title){return hierarchy[project_id].title}else{return undefined}}function compareProjectTitles(a,b){if(a.project_id<b.project_id){return-1}else if(a.project_id>b.project_id){return 1}else{return 0}}function getParentProjects(project_id,hierarchy){var parent=[];var iterate_p=project_id;var parent_id="""";var aux={};while(hierarchy[iterate_p].hasOwnProperty(""parent_project"")){parent_id=hierarchy[iterate_p].parent_project;aux=hierarchy[parent_id];aux.project_id=parent_id;parent.push(aux);iterate_p=parent_id}return parent.reverse()}function getChildrenProjects(project_id,hierarchy){var children=[];var aux={};$.each(hierarchy,function(id,p){if(hierarchy[id].parent_project===project_id){aux=hierarchy[id];aux.project_id=id;children.push(aux)}});children.sort(compareProjectTitles);return children}function composePBreadcrumbsHTMLlast(project_id,children,hierarchy){var html="""";var clen=children.length;if(clen>0){children_sort=[];children_names=[];$.each(children,function(id,value){children_names.push(value.title)});children_names=children_names.sort();$.each(children_names,function(id,name){$.each(children,function(id,value){if(name===value.title){children_sort.push(value);return false}})});children=children_sort;html+='<li class=""dropdown"">';html+='<span data-toggle=""tooltip"" title=""Project name""> '+getProjectTitle(project_id,hierarchy)+""</span>"";html+='&nbsp;<a class=""dropdown-toggle"" data-toggle=""dropdown"" href=""#"">';html+='<span data-toggle=""tooltip"" title=""Select subproject"" class=""badge""> '+clen+"" Subprojects </span></a>"";html+='<ul class=""dropdown-menu scroll-menu"">';$.each(children,function(id,value){gchildren=getChildrenProjects(value.project_id,hierarchy);if(gchildren.length>0){html+='<li><a href=""project.html?project='+value.project_id+'"">'+value.title+'&nbsp;&nbsp;<span data-toggle=""tooltip"" title=""Number of suprojects"" class=""badge"">'+gchildren.length+'&nbsp;<i class=""fa fa-rocket""></i></span></a></li>'}else{html+='<li><a href=""project.html?project='+value.project_id+'"">'+value.title+""</a></li>""}});html+='<li class=""divider""></li>';html+='<li><a href=""./project_map.html""><i class=""fa fa-icon fa-sitemap""></i> Projects treemap</a></li>';html+=""</ul></li>""}else{html+=""<li>""+getProjectTitle(project_id,hierarchy)+""</li>""}return html}function composeProjectBreadcrumbs(project_id){var html='<ol class=""breadcrumbtitle"">';var hierarchy=Report.getProjectsHierarchy();if(hierarchy.length===0){return""""}if(project_id===undefined){project_id=""root""}var children=getChildrenProjects(project_id,hierarchy);var parents=getParentProjects(project_id,hierarchy);if(parents.length>0){$.each(parents,function(id,value){if(value.parent_project){html+='<li><a href=""project.html?project='+value.project_id+'"">'+value.title+""</a></li>""}else{html+='<li><a href=""./"">'+value.title+""</a></li>""}})}html+=composePBreadcrumbsHTMLlast(project_id,children,hierarchy);html+=""</ol>"";return html}function escapeString(string){var aux="""";aux=string.replace("" "",""_"");aux=aux.toLowerCase();return aux}function composeHTMLNestedProjects(project_id,children,hierarchy){var html="""";var clen=children.length;var epid=project_id;var divid=epid.replace(""."","""");if(clen>0){html+=""<li>"";html+='<a href=""project.html?project='+epid+'"">'+getProjectTitle(project_id,hierarchy)+""</a>"";html+='&nbsp;<a data-toggle=""collapse"" data-parent=""#accordion"" href=""#collapse'+divid+'"">';html+='<span class=""badge"">'+clen+""&nbsp;subprojects</span></a>"";html+='<div id=""collapse'+divid+'"" class=""panel-collapse collapse""><ul>';$.each(children,function(id,value){gchildren=getChildrenProjects(value.project_id,hierarchy);html+=composeHTMLNestedProjects(value.project_id,gchildren,hierarchy)});html+=""</ul></li>""}else{html+='<li><a href=""project.html?project='+project_id+'"">'+getProjectTitle(project_id,hierarchy)+""</a></li>""}return html}function composeProjectMap(){var html=""<ul>"";var hierarchy=Report.getProjectsHierarchy();if(hierarchy.length===0){return""""}project_id=""root"";var children=getChildrenProjects(project_id,hierarchy);var parents=getParentProjects(project_id,hierarchy);$.each(children,function(id,value){grandchildren=getChildrenProjects(value.project_id,hierarchy);html+=composeHTMLNestedProjects(value.project_id,grandchildren,hierarchy)});html+=""</ul>"";return html}function getSectionName4Release(){var result=[];var sections={data_sources:""Data sources"",project_map:""Project map"",people:""Contributor"",company:""Company"",country:""Country"",domain:""Domain"",""scm-companies"":""Activity on code repositories by companies"",""mls-companies"":""Activity on mailing lists by companies"",""its-companies"":""Activity on issue trackers by companies""};url_no_params=document.URL.split(""?"")[0];url_tokens=url_no_params.split(""/"");var section=url_tokens[url_tokens.length-1].split(""."")[0];if(section===""project""||section===""index""||section===""release""||section===""""){return[]}else{if(sections.hasOwnProperty(section)){result.push([section,sections[section]])}else{return[[""#"",""Unavailable section name""]]}return result}}function getSectionName(){var result=[];var sections={mls:""MLS overview"",irc:""IRC overview"",slack:""Slack Overview"",its:""ITS overview"",storyboard:""Storyboard overview"",qaforums:""QA Forums overview"",scr:""Code Review overview"",scm:""SCM overview"",wiki:""Wiki overview"",downloads:""Downloads"",forge:""Forge releases"",meetup:""Meetup"",demographics:""Demographics"",data_sources:""Data sources"",project_map:""Project map"",people:""Contributor"",company:""Company"",country:""Country"",domain:""Domain"",release:""Companies analysis by release"",project_comparison:""Project comparison""};var filters={companies:""Activity by companies"",contributors:""Activity by contributors"",countries:""Activity by countries"",domains:""Activity by domains"",projects:""Activity by project"",repos:""Activity by repositories"",states:""Activity by states"",tags:""Activity by tags"",past_events:""Past events""};var filters2={repository:""Repository"",countries:""Activity by countries""};url_no_params=document.URL.split(""?"")[0];url_tokens=url_no_params.split(""/"");var section=url_tokens[url_tokens.length-1].split(""."")[0];if(section===""project""||section===""index""||section===""""){return[]}else if(section===""filter""){var filter_by=$.urlParam(""filter_by_item"");var filter_names=$.urlParam(""filter_names"");switch(filter_names){case""company+country"":result=[[""company"",""Company""],[""Activity by country and company"",""Activity by country and company""]]}return result}else{var s_tokens=section.split(""-"");if(s_tokens[0]===""repository""){ds_name=$.urlParam(""ds"");s_tokens=[ds_name,""repos"",""repository""]}if(sections.hasOwnProperty(s_tokens[0])){result.push([s_tokens[0],sections[s_tokens[0]]]);if(s_tokens.length>0){if(filters.hasOwnProperty(s_tokens[1])){result.push([s_tokens[0]+""-""+s_tokens[1],filters[s_tokens[1]]]);if(s_tokens.length>2){if(filters2.hasOwnProperty(s_tokens[2])){result.push([s_tokens[0],filters2[s_tokens[2]]])}}}}}else{return[[""#"",""Unavailable section name""]]}return result}}function isURLRelease(){if($.urlParam(""release"")!==null&&$.urlParam(""release"").length>0)return true;else return false}function composeSideBar(project_id){if(project_id===undefined){project_id=""root""}var html="""";var html_extra="""";html+='<ul class=""nav navmenu-nav"">';var mele=Report.getMenuElements();if(Utils.isReleasePage()){if(Report.getMenuElementsReleases()!==undefined){mele=Report.getMenuElementsReleases()}}if(project_id===""root""){if(mele.hasOwnProperty(""scm"")){aux=mele.scm;aux_html=HTMLComposer.sideBarLinks(""fa-code"",""Source code management"",""scm"",aux);html+=aux_html}if(mele.hasOwnProperty(""scr"")){aux=mele.scr;aux_html=HTMLComposer.sideBarLinks(""fa-check"",""Code review"",""scr"",aux);html+=aux_html}if(mele.hasOwnProperty(""its"")){aux=mele.its;aux_html=HTMLComposer.sideBarLinks(""fa-ticket"",""Tickets"",""its"",aux);html+=aux_html}if(mele.hasOwnProperty(""its_1"")){aux=mele.its_1;aux_html=HTMLComposer.sideBarLinks(""fa-ticket"",""Tickets 1"",""its_1"",aux);html+=aux_html}if(mele.hasOwnProperty(""storyboard"")){aux=mele.storyboard;aux_html=HTMLComposer.sideBarLinks(""fa-ticket"",""Storyboard"",""storyboard"",aux);html+=aux_html}if(mele.hasOwnProperty(""mls"")){aux=mele.mls;aux_html=HTMLComposer.sideBarLinks(""fa-envelope-o"",""Mailing lists"",""mls"",aux);html+=aux_html}if(mele.hasOwnProperty(""qaforums"")){aux=mele.qaforums;aux_html=HTMLComposer.sideBarLinks(""fa-question"",""Q&A Forums"",""qaforums"",aux);html+=aux_html}if(mele.hasOwnProperty(""irc"")){aux=mele.irc;aux_html=HTMLComposer.sideBarLinks(""fa-comment-o"",""IRC"",""irc"",aux);html+=aux_html}if(mele.hasOwnProperty(""slack"")){aux=mele.slack;aux_html=HTMLComposer.sideBarLinks(""fa-comment-o"",""Slack"",""slack"",aux);html+=aux_html}if(mele.hasOwnProperty(""downloads"")){aux=mele.downloads;aux_html=HTMLComposer.sideBarLinks(""fa-download"",""Downloads"",""downloads"",aux);html+=aux_html}if(mele.hasOwnProperty(""forge"")){aux=mele.forge;aux_html=HTMLComposer.sideBarLinks(""fa-umbrella"",""Forge releases"",""forge"",aux);html+=aux_html}if(mele.hasOwnProperty(""wiki"")){aux=mele.wiki;aux_html=HTMLComposer.sideBarLinks(""fa-pencil-square-o"",""Wiki"",""wiki"",aux);html+=aux_html}if(mele.hasOwnProperty(""meetup"")){aux=mele.meetup;aux_html=HTMLComposer.sideBarLinks(""fa-users"",""Meetup"",""meetup"",aux);html+=aux_html}if(mele.hasOwnProperty(""studies"")){aux=mele.studies;html+='<li class=""dropdown"">';html+='<a href=""#"" class=""dropdown-toggle"" data-toggle=""dropdown"">';html+='<i class=""fa fa-lightbulb-o""></i>&nbsp;Studies <b class=""caret""></b></a>';html+='<ul class=""dropdown-menu navmenu-nav"">';if(aux.indexOf(""demographics"")>=0){html+='<li><a href=""demographics.html"">&nbsp;Demographics</a></li>'}if(aux.indexOf(""release"")>=0){aux=Report.getReleaseNames().reverse();latest_release=aux[0];html+='<li><a href=""release.html?release='+latest_release+'"">&nbsp;Companies by release</a></li>'}var e_studies=mele.studies_extra;if(e_studies){$.each(e_studies,function(id,value){var name,url;name=value[0];url=value[1];html+='<li><a href=""'+url+'"">&nbsp;'+name+""</a></li>""})}html+=""</ul></li>""}if(Utils.isReleasePage()===true){current_release=$.urlParam(""release"");html+='<li><a href=""data_sources.html?release='+current_release+'""><i class=""fa fa-database""></i> Data sources</a></li>';if(mele.hasOwnProperty(""project_map"")){html+='<li><a href=""project_map.html?release='+current_release+'""><i class=""fa fa-icon fa-sitemap""></i> Project map</a></li>'}}else{html+='<li><a href=""data_sources.html""><i class=""fa fa-database""></i> Data sources</a></li>';if(mele.hasOwnProperty(""project_map"")){html+='<li><a href=""project_map.html""><i class=""fa fa-icon fa-sitemap""></i> Project map</a></li>'}}if(mele.hasOwnProperty(""extra"")){aux=mele.extra;html_extra+='<li class=""sidemenu-divider""></li>';html_extra+='<li class=""sidemenu-smallheader"">More links:</li>';$.each(aux,function(id,value){html_extra+='<li><a href=""'+value[1]+'"">&nbsp;'+value[0]+""</a></li>""})}html+=html_extra}html+=""</ul>"";return html}Convert.convertSideBar=function(project_id){var divs=$("".SideNavBar"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if(!div.id)div.id=""SideNavBar"";var label;if(project_id){label=Report.cleanLabel(project_id)}var htmlaux=composeSideBar(label);$(""#""+div.id).append(htmlaux);data=Report.getProjectData();$("".report_name"").text(data.project_name);if(Utils.isReleasePage())$("".report_name"").attr(""href"",""./?release=""+$.urlParam(""release""))})}};Convert.convertProjectNavBar=function(project_id){var divs=$("".ProjectNavBar"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if(!div.id)div.id=""ProjectNavBar"";var label;if(project_id){label=Report.cleanLabel(project_id)}var htmlaux=composeProjectBreadcrumbs(label);$(""#""+div.id).append(htmlaux)})}};Convert.convertNavbar=function(){$.get(Report.getHtmlDir()+""navbar.html"",function(navigation){$(""#Navbar"").html(navigation);var project_id=Report.getParameterByName(""project"");Convert.convertProjectNavBar(project_id);Convert.convertReleaseSelector();Convert.convertSideBar(project_id)})};Convert.convertReleaseSelector=function(){var releases=Report.getReleaseNames();if(releases===undefined){return}if(releases.length>0){var divs=$("".ReleaseSelector"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if(!div.id)div.id=""ReleaseSelector""+getRandomId();var htmlaux=HTMLComposer.releaseSelector($.urlParam(""release""),releases);$(""#""+div.id).append(htmlaux)})}}};function composeSectionBreadCrumb(project_id){var html='<ol class=""breadcrumb"">';data=Report.getProjectData();document.title=data.project_name+"" Dashboard"";if(project_id===undefined){var subsects_b=getSectionName();var params=Utils.paramsInURL();if(subsects_b.length>0){html+='<li><a href=""./';if(Utils.isReleasePage())html+=""?release=""+$.urlParam(""release"");html+='"">Project Overview</a></li>';var cont_b=1;$.each(subsects_b,function(id,value){if(subsects_b.length===cont_b){html+='<li class=""active"">'+value[1]+""</li>"";document.title=value[1]+"" | ""+data.project_name+"" Dashboard""}else{if(Utils.isReleasePage()){html+='<li><a href=""'+value[0]+"".html"";html+=""?release=""+$.urlParam(""release"")+'"">';html+=value[1]+""</a></li>""}else{if(value[0]===""company""){var get_param=$.urlParam(""filter_item"");html+='<li><a href=""'+value[0]+"".html?company=""+get_param+'"">'+get_param[0].toUpperCase()+get_param.slice(1)+""</a></li>""}else{html+='<li><a href=""'+value[0]+'.html"">'+value[1]+""</a></li>""}}}cont_b+=1})}else{html+='<li class=""active"">Project Overview</li>';document.title=""Project Overview | ""+data.project_name+"" Dashboard""}}else{html+=""<li> ""+getSectionName()+""</li>"";document.title=getSectionName()+"" | ""+data.project_name+"" Dashboard""}html+=""</ol>"";return html}Convert.convertSectionBreadcrumb=function(project_id){var divs=$("".SectionBreadcrumb"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if(!div.id)div.id=""SectionBreadcrumb"";var label;if(project_id){label=Report.cleanLabel(project_id)}var htmlaux=composeSectionBreadCrumb(label);$(""#""+div.id).append(htmlaux)})}};Convert.convertProjectMap=function(){var divs=$("".ProjectMap"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if(!div.id)div.id=""ProjectMap"";var label;var htmlaux=composeProjectMap();$(""#""+div.id).append(htmlaux)})}};Convert.convertFooter=function(){$.get(Report.getHtmlDir()+""footer.html"",function(footer){$(""#Footer"").html(footer);$(""#vizjs-lib-version"").append(vizjslib_git_tag)})};Convert.convertSummary=function(){div_param=""Summary"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;div.id=ds+""-Summary"";DS.displayGlobalSummary(div.id)})}};function composeDropDownRepo(DS){var repository=Report.getParameterByName(""repository"");if(repository&&$.inArray(repository,DS.getReposData())<0)return"""";var dsname=DS.getName();var section="""";var label_repo=DS.getLabelForRepository();var label_repo_plural=DS.getLabelForRepositories();if(repository!==undefined){section=repository}else{section=""All ""+label_repo_plural}html='<div class=""row""><span class=""col-md-12"">';html='<ol class=""filterbar""><li>Filtered by '+label_repo+"":&nbsp;&nbsp;</li>"";html+='<li><div class=""dropdown""><button class=""btn btn-default dropdown-toggle"" ';html+='type=""button"" id=""dropdownMenu1"" data-toggle=""dropdown""> '+section+"" "";html+='<span class=""caret""></span></button>';html+='<ul class=""dropdown-menu scroll-menu"" role=""menu"" aria-labelledby=""dropdownMenu1"">';if(repository){html+='<li role=""presentation""><a role=""menuitem"" tabindex=""-1"" href=""'+dsname+'-contributors.html"">';html+=""All ""+label_repo_plural;html+=""</a></li>""}var repo_names=DS.getReposData();repo_names.sort();$.each(repo_names,function(id,value){if(value===repository)return;html+='<li role=""presentation""><a role=""menuitem"" tabindex=""-1"" href=""?repository=';html+=value;html+='"">';html+=value;html+=""</a></li>""});html+=""</ul></div></li></ol>"";html+=""</span></div>"";return html}Convert.convertRepositorySelector=function(){var divs=$("".repository-selector"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;div.id=ds+""-repository-selector"";var htmlaux=composeDropDownRepo(DS);$(""#""+div.id).append(htmlaux)})}};function displayReportData(){data=Report.getProjectData();document.title=data.project_name+"" Report by Bitergia"";if(data.title)document.title=data.title;$("".report_date"").text(data.date);$("".report_name"").text(data.project_name);str=data.blog_url;if(str&&str.length>0){$(""#blogEntry"").html(""<br><a href='""+str+""'>Blog post with some more details</a>"");$("".blog_url"").attr(""href"",data.blog_url)}else{$(""#more_info"").hide()}str=data.producer;if(str&&str.length>0){$(""#producer"").html(str)}else{$(""#producer"").html(""<a href='http://bitergia.com'>Bitergia</a>"")}$("".project_name"").text(data.project_name);$(""#project_url"").attr(""href"",data.project_url)}Convert.convertRefcard=function(){$.when($.get(Report.getHtmlDir()+""refcard.html""),$.get(Report.getHtmlDir()+""project-card.html"")).done(function(res1,res2){refcard=res1[0];projcard=res2[0];$(""#Refcard"").html(refcard);displayReportData();$.each(Report.getProjectsData(),function(prj_name,prj_data){var new_div=""card-""+prj_name.replace(""."","""").replace("" "","""");$(""#Refcard #projects_info"").append(projcard);$(""#Refcard #projects_info #new_card"").attr(""id"",new_div);$.each(Report.getDataSources(),function(i,DS){if(DS.getProject()!==prj_name){$(""#""+new_div+"" .""+DS.getName()+""-info"").hide();return}DS.displayData(new_div)});$(""#""+new_div+"" #project_name"").text(prj_name);if(Report.getProjectsDirs.length>1)$(""#""+new_div+"" .project_info"").append(' <a href=""VizGrimoireJS/browser/index.html?data_dir=../../'+prj_data.dir+'"">Report</a>');$(""#""+new_div+"" #project_url"").attr(""href"",prj_data.url)})})};Convert.convertGlobalData=function(){var divs=$("".GlobalData"");if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;var data=DS.getGlobalData();var key=$(this).data(""field"");$(this).text(Report.formatValue(data[key],key))})}};Convert.convertProjectData=function(){var divs=$("".ProjectData"");var p=Report.getParameterByName(""project"");if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;var data=DS.getProjectsGlobalData()[p];if(data===undefined){return}var key=$(this).data(""field"");$(this).text(Report.formatValue(data[key],key))})}};Convert.convertRadarActivity=function(){var div_param=""RadarActivity"";var divs=$(""#""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty()});Viz.displayRadarActivity(div_param)}};Convert.convertRadarCommunity=function(){var div_param=""RadarCommunity"";var divs=$(""#""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty()});Viz.displayRadarCommunity(""RadarCommunity"")}};Convert.convertTreemap=function(){var div_param=""Treemap"";var divs=$(""#""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty()});var file=$(""#Treemap"").data(""file"");$(""#Treemap"").empty();Viz.displayTreeMap(""Treemap"",file)}};Convert.convertBubbles=function(){div_param=""Bubbles"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;if(DS.getData().length===0)return;var radius=$(this).data(""radius"");div.id=ds+""-Bubbles"";DS.displayBubbles(div.id,radius)})}};function loadHTMLEvolParameters(htmldiv,config_viz){config_viz.help=true;var help=$(htmldiv).data(""help"");if(help!==undefined)config_viz.help=help;config_viz.show_legend=false;if($(htmldiv).data(""frame-time""))config_viz.frame_time=true;config_viz.graph=$(htmldiv).data(""graph"");if($(htmldiv).data(""min"")){config_viz.show_legend=false;config_viz.show_labels=true;config_viz.show_grid=true;config_viz.help=false}if($(htmldiv).data(""legend""))config_viz.show_legend=true;config_viz.ligth_style=false;if($(htmldiv).data(""light-style"")){config_viz.light_style=true}if($(htmldiv).data(""custom-title"")){config_viz.custom_title=$(htmldiv).data(""custom-title"")}if(config_viz.help&&$(htmldiv).data(""custom-help"")){config_viz.custom_help=$(htmldiv).data(""custom-help"")}else{config_viz.custom_help=""""}if($(htmldiv).data(""repo-filter"")){config_viz.repo_filter=$(htmldiv).data(""repo-filter"")}var start=$(htmldiv).data(""start"");if(start)config_viz.start_time=start;var end=$(htmldiv).data(""end"");if(end)config_viz.end_time=end;var remove_last_point=$(htmldiv).data(""remove-last-point"");if(remove_last_point)config_viz.remove_last_point=true;return config_viz}Convert.convertMetricsEvol=function(){var config_metric={};config_metric.show_desc=false;config_metric.show_title=true;config_metric.show_labels=true;var config=Report.getVizConfig();if(config){$.each(config,function(key,value){config_metric[key]=value})}var div_param=""MetricsEvol"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){var config_viz={};$.each(config_metric,function(key,value){config_viz[key]=value});$(this).empty();var metrics=$(this).data(""metrics"");var ds=$(this).data(""data-source"");config_viz.title=$(this).data(""title"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;config_viz=loadHTMLEvolParameters(div,config_viz);div.id=metrics.replace(/,/g,""-"")+""-""+ds+""-metrics-evol-""+this.id;div.id=div.id.replace(/\n|\s/g,"""");DS.displayMetricsEvol(metrics.split("",""),div.id,config_viz,$(this).data(""convert""))})}};Convert.convertMetricsEvolCustomized=function(filter){var config_metric={};config_metric.show_desc=false;config_metric.show_title=true;config_metric.show_labels=true;var config=Report.getVizConfig();if(config){$.each(config,function(key,value){config_metric[key]=value})}var div_param=""MetricsEvolCustomized"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){if(filter!==$(this).data(""filter""))return;var config_viz={};$.each(config_metric,function(key,value){config_viz[key]=value});$(this).empty();var metrics=$(this).data(""metrics"");var ds=$(this).data(""data-source"");config_viz.title=$(this).data(""title"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;config_viz=loadHTMLEvolParameters(div,config_viz);div.id=metrics.replace(/,/g,""-"")+""-""+ds+""-metrics-evol-""+this.id;div.id=div.id.replace(/\n|\s/g,"""");DS.displayMetricsEvol(metrics.split("",""),div.id,config_viz,$(this).data(""convert""))})}};Convert.convertMetricsEvolSelector=function(){var config_metric={};config_metric.show_desc=false;config_metric.show_title=true;config_metric.show_labels=true;var config=Report.getVizConfig();if(config){$.each(config,function(key,value){config_metric[key]=value})}var div_param=""MetricsEvol"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){var config_viz={};$.each(config_metric,function(key,value){config_viz[key]=value});$(this).empty();var metrics=$(this).data(""metrics"");var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;var repository=Report.getParameterByName(""repository"");config_viz.repo_filter=repository;config_viz=loadHTMLEvolParameters(div,config_viz);div.id=metrics.replace(/,/g,""-"")+""-""+ds+""-metrics-evol-""+repository;div.id=div.id.replace(/\n|\s/g,"""");DS.displayMetricsEvol(metrics.split("",""),div.id,config_viz,$(this).data(""convert""))})}};Convert.convertMetricsEvolSet=function(){div_param=""MetricsEvolSet"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var all=$(this).data(""all"");var relative=$(this).data(""relative"");var summary_graph=$(this).data(""summary-graph"");var legend=$(this).data(""legend-show"");div.id=ds+""-MetricsEvolSet-""+this.id;if(all===true){div.id=ds+""-All"";Viz.displayEnvisionAll(div.id,relative,legend,summary_graph);return false}var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;DS.displayEnvision(div.id,relative,legend,summary_graph)})}};Convert.convertTimeTo=function(){var div_tt=""TimeTo"";divs=$("".""+div_tt);if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;var quantil=$(this).data(""quantil"");var type=$(this).data(""type"");div.id=ds+""-time-to-""+type+""-""+quantil;if(type===""fix"")DS.displayTimeToFix(div.id,quantil);if(type===""attention"")DS.displayTimeToAttention(div.id,quantil)})}};Convert.convertMarkovTable=function(){var div_id_mt=""MarkovTable"";var divs=$("".""+div_id_mt);var DS,ds;if(divs.length>0){$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(DS.getData().length===0)return;var title=$(this).data(""title"");div.id=ds+""-markov-table"";DS.displayMarkovTable(div.id,title)})}};Convert.convertLastActivity=function(){var all_metrics=Report.getAllMetrics();function activityInfo(div,period,label){var html=""<h4>Last ""+label+""</h4>"";$.each(Report.getDataSources(),function(index,DS){var data=DS.getGlobalData();$.each(data,function(key,val){var suffix=""_""+period;if(key.indexOf(suffix,key.length-suffix.length)!==-1){var metric=key.substring(0,key.length-suffix.length);label=metric;if(all_metrics[metric])label=all_metrics[metric].name;html+=label+"":""+data[key]+""<br>""}})});$(div).append(html)}var divs=$("".LastActivity"");var period=null;var days={Week:7,Month:30,Quarter:90,Year:365};if(divs.length>0)$.each(divs,function(id,div){period=$(div).data(""period"");activityInfo(div,days[period],period)})};Convert.convertTopByPeriod=function(){var div_id_top=""TopByPeriod"";var divs=$("".""+div_id_top);var DS,ds;if(divs.length>0){var unique=0;$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return; if(DS.getData().length===0)return;var show_all=false;if($(this).data(""show_all""))show_all=true;var top_metric=$(this).data(""metric"");var npeople=$(this).data(""limit"");var is_release=Utils.isReleasePage();var html=HTMLComposer.TopByPeriod(ds,top_metric,npeople,is_release);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertTop=function(){var div_id_top=""Top"";var divs=$("".""+div_id_top);var DS,ds;if(divs.length>0){var unique=0;$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(DS.getData().length===0)return;var show_all=false;if($(this).data(""show_all""))show_all=true;var top_metric=$(this).data(""metric"");var limit=$(this).data(""limit"");var graph=$(this).data(""graph"");var people_links=$(this).data(""people_links"");var threads_links=$(this).data(""threads_links"");var period=$(this).data(""period"");var period_all=$(this).data(""period_all"");var repository=Report.getParameterByName(""repository"");div.id=ds+""-""+div_id_top+unique++;if(graph){div.id+=""-""+graph}if(period===undefined&&period_all===undefined){period_all=true}if(limit===undefined){limit=10}DS.displayTop(div,show_all,top_metric,period,period_all,graph,limit,people_links,threads_links,repository)})}};Convert.convertTopMultiColumn=function(){var div_id_top=""TopMultiColumn"";var divs=$("".""+div_id_top);var DS,ds;if(divs.length>0){var unique=0;$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");if(ds!==""meetup"")return;DS=Report.getDataSourceByName(ds);if(DS===null)return;if(DS.getData().length===0)return;var show_all=false;var top_metric=$(this).data(""metric"");var period=$(this).data(""period"");var period_all=$(this).data(""period_all"");var headers=$(this).data(""headers"");var columns=$(this).data(""columns"");var limit=$(this).data(""limit"");div.id=ds+""-""+div_id_top+unique++;if(period===undefined&&period_all===undefined){period_all=true}if(limit===undefined){limit=500}DS.displayTopMultiColumn(div,headers.split("",""),columns.split("",""))})}};Convert.convertPersonMetrics=function(upeople_id,upeople_identifier){var config_metric={};config_metric.show_desc=false;config_metric.show_title=false;config_metric.show_labels=true;divs=$("".PersonMetrics"");if(divs.length){$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;var metrics=$(this).data(""metrics"");config_metric.show_legend=false;config_metric.help=false;if($(this).data(""frame-time""))config_metric.frame_time=true;if($(this).data(""legend""))config_metric.show_legend=true;if($(this).data(""person_id""))upeople_id=$(this).data(""person_id"");if($(this).data(""person_name""))upeople_identifier=$(this).data(""person_name"");div.id=metrics.replace(/,/g,""-"")+""-people-metrics"";DS.displayMetricsPeople(upeople_id,upeople_identifier,metrics.split("",""),div.id,config_metric)})}};function getRandomId(){return Math.floor(Math.random()*1e3+1)}Convert.convertPersonData=function(upeople_id,upeople_identifier){var divs=$("".PersonData""),name,email;if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if($(this).data(""person_id""))upeople_id=$(this).data(""person_id"");if(!div.id)div.id=""PersonData""+""-""+upeople_id+""-""+getRandomId();var data=Report.getPeopleIdentities()[upeople_id];if(data){name=DataProcess.selectPersonName(data);email=DataProcess.selectPersonEmail(data);email=""(""+DataProcess.hideEmail(email)+"")""}else{if(upeople_identifier!==undefined)name=upeople_identifier;else name=upeople_id;email=""""}html=HTMLComposer.personName(name,email);$(""#""+div.id).append(html)})}};Convert.personSummaryBlock=function(upeople_id){var divs=$("".PersonSummaryBlock"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;ds_name=$(this).data(""data-source"");ds_realname=$(this).data(""data-realname"");metric_name=$(this).data(""metrics"");DS=Report.getDataSourceByName(ds_name);if(DS===null)return;if(DS.getData().length===0)return;if(DS.getPeopleMetricsData()[upeople_id].length===0)return;var html=HTMLComposer.personDSBlock(ds_name,metric_name,ds_realname);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertPersonSummary=function(upeople_id,upeople_identifier){var divs=$("".PersonSummary"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if($(this).data(""person_id""))upeople_id=$(this).data(""person_id"");if($(this).data(""person_name""))upeople_identifier=$(this).data(""person_name"");div.id=ds+""-refcard-people"";DS.displayPeopleSummary(div.id,upeople_id,upeople_identifier,DS)})}};Convert.convertPeople=function(upeople_id,upeople_identifier){if(upeople_id===undefined)upeople_id=Report.getParameterByName(""id"");if(upeople_identifier===undefined)upeople_identifier=Report.getParameterByName(""name"");if(upeople_id===undefined)return;if(Loader.check_people_item(upeople_id)===false){$.each(Report.getDataSources(),function(index,DS){Loader.data_load_people_item(upeople_id,DS,Convert.convertPeople)});return}Convert.personSummaryBlock(upeople_id);Convert.convertPersonData(upeople_id,upeople_identifier);Convert.convertPersonSummary(upeople_id,upeople_identifier);Convert.convertPersonMetrics(upeople_id,upeople_identifier);Convert.activateHelp()};function dataFilterAvailable(filter_name,item_name){if(filter_name===""repos""){if(DS.getReposGlobalData()[item_name]===undefined||DS.getReposGlobalData()[item_name].length===0)return false}else if(filter_name===""companies""){if(DS.getCompaniesGlobalData()[item_name]===undefined||DS.getCompaniesGlobalData()[item_name].length===0)return false}else if(filter_name===""countries""){if(DS.getCountriesGlobalData()[item_name]===undefined||DS.getCountriesGlobalData()[item_name].length===0)return false}else if(filter_name===""companies""){if(DS.getDomainsGlobalData()[item_name]===undefined||DS.getDomainsGlobalData()[item_name].length===0)return false}return true}Convert.repositoryDSBlock=function(repo_id){var divs=$("".FilterDSBlock"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;ds_name=$(this).data(""data-source"");ds_realname=$(this).data(""data-realname"");filter_name=$(this).data(""filter"");aux=$(this).data(""metrics"");metric_names=aux.split("","");$.each(metric_names,function(id,value){metric_names[id]=metric_names[id].replace(/:/g,"","")});DS=Report.getDataSourceByName(ds_name);if(DS===null)return;if(DS.getData().length===0)return;if(dataFilterAvailable(filter_name,repo_id)){var html=HTMLComposer.filterDSBlock(ds_name,filter_name,metric_names,ds_realname);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)}})}};Convert.convertDSSummaryBlock=function(upeople_id){var divs=$("".DSSummaryBlock"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;ds_name=$(this).data(""data-source"");ds_realname=$(this).data(""data-realname"");box_labels=$(this).data(""box-labels"");box_metrics=$(this).data(""box-metrics"");ts_metrics=$(this).data(""ts-metrics"");DS=Report.getDataSourceByName(ds_name);if(DS===null)return;if(DS.getData().length===0)return;var html=HTMLComposer.DSBlock(ds_name,box_labels,box_metrics,ts_metrics,ds_realname);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertDSSummaryBlockProjectFiltered=function(upeople_id){var divs=$("".DSSummaryBlockProjectFiltered"");var pname=Report.getParameterByName(""project"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;ds_name=$(this).data(""data-source"");box_labels=$(this).data(""box-labels"");box_metrics=$(this).data(""box-metrics"");ts_metrics=$(this).data(""ts-metrics"");DS=Report.getDataSourceByName(ds_name);if(DS===null)return;if(DS.getProjectsGlobalData()[pname]===undefined)return;if(DS.getProjectsGlobalData()[pname].length===0)return;var html=HTMLComposer.DSBlockProject(ds_name,box_labels,box_metrics,ts_metrics,pname);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertOverallSummaryBlock=function(){var divs=$("".OverallSummaryBlock"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;var html=HTMLComposer.overallSummaryBlock();if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertDemographics=function(){var divs=$("".Demographics"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;var period=$(this).data(""period"");div.id=""Demographics""+""-""+ds+""-""+""-""+period;DS.displayDemographics(div.id,period)})}};function filterItemsConfig(){var config_metric={};config_metric.show_desc=false;config_metric.show_title=false;config_metric.show_labels=true;config_metric.show_legend=false;return config_metric}Convert.getRealItem=function(ds,filter,item){var map=Report.getReposMap();if(map===undefined||map.length===0){if($.inArray(item,ds.getReposData())>-1)return item;else return null}var map_item=null;if(filter===""repos""){var rdata=ds.getReposMetricsData()[item];if(rdata===undefined){$.each(map,function(id,repos){$.each(Report.getDataSources(),function(index,DS){if(repos[DS.getName()]===item){map_item=repos[ds.getName()];return false}});if(map_item!==null)return false})}else map_item=item}else map_item=item;return map_item};Convert.convertFilterItemsSummary=function(filter){var divlabel=""FilterItemsSummary"";divs=$("".""+divlabel);if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;div.id=ds+""-""+divlabel;$(this).empty();if(filter===""repos"")DS.displayReposSummary(div.id,DS);if(filter===""countries"")DS.displayCountriesSummary(div.id,DS);if(filter===""companies"")DS.displayCompaniesSummary(div.id,DS);if(filter===""domains"")DS.displayDomainsSummary(div.id,DS);if(filter===""projects"")DS.displayProjectsSummary(div.id,DS)})}};Convert.convertFilterItemsGlobal=function(filter){var config_metric=filterItemsConfig();var divlabel=""FilterItemsGlobal"";divs=$("".""+divlabel);if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;var metric=$(this).data(""metric"");var show_others=$(this).data(""show-others"");var order_by=$(this).data(""order-by"");config_metric.show_legend=$(this).data(""legend"");if($(""#""+$(this).data(""legend-div"")).length>0){config_metric.legend={container:$(this).data(""legend-div"")}}else config_metric.legend={container:null};config_metric.graph=$(this).data(""graph"");config_metric.title=$(this).data(""title"");config_metric.show_title=1;div.id=metric+""-""+divlabel;$(this).empty();if(filter===""repos"")DS.displayMetricReposStatic(metric,div.id,config_metric,order_by,show_others);if(filter===""countries"")DS.displayMetricCountriesStatic(metric,div.id,config_metric,order_by,show_others);if(filter===""companies"")DS.displayMetricCompaniesStatic(metric,div.id,config_metric,order_by,show_others);if(filter===""domains"")DS.displayMetricDomainsStatic(metric,div.id,config_metric,order_by,show_others);if(filter===""projects"")DS.displayMetricProjectsStatic(metric,div.id,config_metric,order_by,show_others)})}};Convert.convertFilterItemsNav=function(filter,page){var divlabel=""FilterItemsNav"";divs=$("".""+divlabel);if(divs.length>0){var cont=0;$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;if($(this).data(""page""))page=$(this).data(""page"");order_by=$(this).data(""order-by"");div.id=ds+""-""+divlabel+""-""+cont;cont+=1;$(this).empty();if(filter===""repos"")DS.displayItemsNav(div.id,filter,page,order_by);else if(filter===""countries"")DS.displayItemsNav(div.id,filter,page);else if(filter===""companies"")DS.displayItemsNav(div.id,filter,page);else if(filter===""domains"")DS.displayItemsNav(div.id,filter,page);else if(filter===""projects"")DS.displayItemsNav(div.id,filter,page)})}};Convert.convertFilterItemsMetricsEvol=function(filter){var config_metric=filterItemsConfig();var divlabel=""FilterItemsMetricsEvol"";divs=$("".""+divlabel);if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;var metric=$(this).data(""metric"");var stacked=false;if($(this).data(""stacked""))stacked=true;if($(this).data(""min"")){config_viz.show_legend=false;config_viz.show_labels=true;config_viz.show_grid=true;config_viz.help=false}var start=$(this).data(""start"");var end=$(this).data(""end"");config_metric.lines={stacked:stacked};if($(""#""+$(this).data(""legend-div"")).length>0){config_metric.legend={container:$(this).data(""legend-div"")}}else config_metric.legend={container:null};config_metric.show_legend=$(this).data(""legend"");config_metric.mouse_tracker=$(this).data(""mouse_tracker"");var remove_last_point=$(this).data(""remove-last-point"");if(remove_last_point)config_metric.remove_last_point=true;div.id=metric+""-""+divlabel;$(this).empty();if(filter===""companies"")DS.displayMetricCompanies(metric,div.id,config_metric,start,end);else if(filter===""repos"")DS.displayMetricRepos(metric,div.id,config_metric,start,end);else if(filter===""domains"")DS.displayMetricDomains(metric,div.id,config_metric,start,end);else if(filter===""projects"")DS.displayMetricProjects(metric,div.id,config_metric,start,end)})}};Convert.convertFilterItemsMiniCharts=function(filter,page){var config_metric=filterItemsConfig();var divlabel=""FilterItemsMiniCharts"";divs=$("".""+divlabel);if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");ds_realname=$(this).data(""data-realname"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;if($(this).data(""page""))page=$(this).data(""page"");var metrics=$(this).data(""metrics"");var order_by=$(this).data(""order-by"");var show_links=true;if($(this).data(""show_links"")!==undefined)show_links=$(this).data(""show_links"");var start=$(this).data(""start"");var end=$(this).data(""end"");var convert=$(this).data(""convert"");if($(this).data(""frame-time""))config_metric.frame_time=true;var remove_last_point=$(this).data(""remove-last-point"");if(remove_last_point)config_metric.remove_last_point=true;div.id=metrics.replace(/,/g,""-"")+""-""+filter+""-""+divlabel;$(this).empty();if(filter===""repos"")DS.displayReposList(metrics.split("",""),div.id,config_metric,order_by,page,show_links,start,end,convert,ds_realname);else if(filter===""countries"")DS.displayCountriesList(metrics.split("",""),div.id,config_metric,order_by,page,show_links,start,end,convert);else if(filter===""companies"")DS.displayCompaniesList(metrics.split("",""),div.id,config_metric,order_by,page,show_links,start,end,convert);else if(filter===""domains"")DS.displayDomainsList(metrics.split("",""),div.id,config_metric,order_by,page,show_links,start,end,convert);else if(filter===""projects"")DS.displayProjectsList(metrics.split("",""),div.id,config_metric,order_by,page,show_links,start,end,convert)})}};Convert.convertFilterItemData=function(filter,item){var divs=$("".FilterItemData"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var label=Report.cleanLabel(item);if(!div.id)div.id=""FilterItemData""+getRandomId();html=HTMLComposer.itemName(label,filter);$(""#""+div.id).append(html)})}};Convert.convertFilterItemSummary=function(filter,item){var divlabel=""FilterItemSummary"";divs=$("".""+divlabel);if(item!==null&&divs.length>0){$.each(divs,function(id,div){var real_item=item;ds=$(this).data(""data-source"");ds_realname=$(this).data(""data-realname"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;if($(this).data(""item""))real_item=$(this).data(""item"");div.id=ds+""-""+filter+""-""+divlabel;$(this).empty();if(filter===""repos""){DS.displayRepoSummary(div.id,real_item,DS,ds_realname)}else if(filter===""countries"")DS.displayCountrySummary(div.id,real_item,DS);else if(filter===""companies"")DS.displayCompanySummary(div.id,real_item,DS);else if(filter===""domains"")DS.displayDomainSummary(div.id,real_item,DS);else if(filter===""projects"")DS.displayProjectSummary(div.id,real_item,DS)})}};Convert.convertFilterItemMicrodashText=function(filter,item){var divs=$("".FilterItemMicrodashText"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var global_data;var real_item=item;var metric=$(this).data(""metric"");var show_name=$(this).data(""name"");var ds=Report.getMetricDS(metric)[0];if(ds===undefined)return;if(filter===""projects""){global_data=ds.getProjectsGlobalData()[item];if(global_data===undefined){return}}else{return}var html='<div class=""row"">';if(show_name){html+='<div class=""col-md-3"">';html+='<span class=""dayschange"">'+ds.basic_metrics[metric].name+""</span>"";html+=""</div>""}$.each([365,30,7],function(index,period){var column=ds.getMetrics()[metric].column;var value=global_data[metric+""_""+period];var netvalue=global_data[""diff_net""+column+""_""+period];var percentagevalue=global_data[""percentage_""+column+""_""+period];percentagevalue=Math.round(percentagevalue*10)/10;if(value===undefined)return;var str_percentagevalue="""";if(netvalue>0)str_percentagevalue=""+""+percentagevalue;if(netvalue<0)str_percentagevalue=""-""+Math.abs(percentagevalue);if(show_name){html+='<div class=""col-md-3"">'}else{html+='<div class=""col-md-4"">'}html+='<span class=""dayschange"">Last '+period+"" days:</span>"";html+="" ""+Report.formatValue(value)+""<br>"";if(netvalue===0){html+='<i class=""fa fa-arrow-circle-right""></i> <span class=""zeropercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}else if(netvalue>0){html+='<i class=""fa fa-arrow-circle-up""></i> <span class=""pospercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}else if(netvalue<0){html+='<i class=""fa fa-arrow-circle-down""></i> <span class=""negpercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}html+=""</div><!--col-md-4-->""});html+=""</div><!--row-->"";$(div).append(html)})}};Convert.convertFilterItemMetricsEvol=function(filter,item){var config_metric=filterItemsConfig();var divlabel=""FilterItemMetricsEvol"";divs=$("".""+divlabel);if(item!==null&&divs.length>0){$.each(divs,function(id,div){var real_item=item;var metrics=$(this).data(""metrics"");ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;if($(this).data(""item""))real_item=$(this).data(""item"");config_metric=loadHTMLEvolParameters(div,config_metric);div.id=Report.cleanLabel(item).replace(/ /g,""_"")+""-"";div.id+=metrics.replace(/,/g,""-"")+""-""+ds+""-""+filter+""-""+divlabel;$(this).empty();if(filter===""repos""){DS.displayMetricsRepo(real_item,metrics.split("",""),div.id,config_metric)}else if(filter===""countries""){DS.displayMetricsCountry(real_item,metrics.split("",""),div.id,config_metric)}else if(filter===""companies""){DS.displayMetricsCompany(real_item,metrics.split("",""),div.id,config_metric)}else if(filter===""domains""){DS.displayMetricsDomain(real_item,metrics.split("",""),div.id,config_metric)}else if(filter===""projects""){DS.displayMetricsProject(real_item,metrics.split("",""),div.id,config_metric)}})}};Convert.convertFilterItemTop=function(filter,item){var divlabel=""FilterItemTop"";divs=$("".""+divlabel);if(divs.length>0){$.each(divs,function(id,div){var real_item=item;$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;if($(this).data(""item""))real_item=$(this).data(""item"");var metric=$(this).data(""metric"");var period=$(this).data(""period"");var titles=$(this).data(""titles"");var height=$(this).data(""height"");var people_links=$(this).data(""people_links"");div.id=metric+""-""+ds+""-""+filter+""-""+divlabel+""-""+getRandomId();$(this).empty();div.className="""";if(filter===""companies"")DS.displayTopCompany(real_item,div,metric,period,titles,height,people_links)})}};Convert.convertSmartLinks=function(){var divs=$("".SmartLinks"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;target_page=$(this).data(""target"");label=$(this).data(""label"");var html=HTMLComposer.smartLinks(target_page,label);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.companyFilters=function(){var divs=$("".CompanyFilters"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;company_name=Report.getParameterByName(""company"");var html=HTMLComposer.companyFilters(company_name);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertFilterStudyItem=function(filter,item){var convertfn=Convert.convertFilterStudyItem;if(convertfn.done===undefined){convertfn.done={}}else if(convertfn.done[filter]===true)return;if(filter===""repositories"")filter=""repos"";if(item===undefined){if(filter===""repos"")item=Report.getParameterByName(""repository"");if(filter===""countries"")item=Report.getParameterByName(""country"");if(filter===""companies"")item=Report.getParameterByName(""company"");if(filter===""domains"")item=Report.getParameterByName(""domain"");if(filter===""projects"")item=Report.getParameterByName(""project"")}if(!item)return;if(Loader.FilterItemCheck(item,filter)===false)return;Convert.repositoryDSBlock(item);Convert.convertDSSummaryBlockProjectFiltered();Convert.convertFilterItemData(filter,item);Convert.convertFilterItemSummary(filter,item);Convert.convertFilterItemMetricsEvol(filter,item);Convert.convertFilterItemTop(filter,item);Convert.convertFilterItemMicrodashText(filter,item);Convert.convertProjectData();Convert.activateHelp();Convert.convertMetricsEvolSelector();convertfn.done[filter]=true};Convert.activateHelp=function(){$("".help"").popover({html:true,trigger:""manual""}).click(function(e){$(this).popover(""toggle"");e.stopPropagation()})};Convert.convertFilterStudy=function(filter){var page=Report.getCurrentPage();if(page===null){page=Report.getParameterByName(""page"");if(page!==undefined)Report.setCurrentPage(page)}if(page===undefined){if($(""[class^='FilterItems']"").length>0){page=1;Report.setCurrentPage(page)}else return}if(filter===""repositories"")filter=""repos"";if(Loader.check_filter_page(page,filter)===false){$.each(Report.getDataSources(),function(index,DS){Loader.data_load_items_page(DS,page,Convert.convertFilterStudy,filter)});return}Convert.convertFilterItemsSummary(filter);Convert.convertFilterItemsGlobal(filter);Convert.convertFilterItemsNav(filter,page);Convert.convertFilterItemsMetricsEvol(filter);Convert.convertFilterItemsMiniCharts(filter,page)};Convert.convertDSTable=function(){var dst=""DataSourcesTable"";var divs=$("".""+dst);var DS,ds;if(divs.length>0){var unique=0;$.each(divs,function(id,div){$(this).empty();div.id=dst+unique++;Viz.displayDataSourcesTable(div)})}};Convert.convertBasicDivs=function(){Convert.convertNavbar();Convert.convertSmartLinks();Convert.convertSectionBreadcrumb();Convert.convertProjectMap();Convert.convertFooter();Convert.convertOverallSummaryBlock();Convert.convertDSSummaryBlock();Convert.convertDSTable();Convert.convertGlobalData();Convert.convertSummary();Convert.convertTopByPeriod();Convert.companyFilters()};Convert.convertBasicDivsMisc=function(){Convert.convertRadarActivity();Convert.convertRadarCommunity();Convert.convertTreemap();Convert.convertBubbles()};Convert.convertBasicMetrics=function(config){var item=Report.getParameterByName(""repository"");if(item===undefined)Convert.convertMetricsEvol();Convert.convertTimeTo();Convert.convertMarkovTable()};Convert.convertFilterTop=function(filter){var item=Report.getParameterByName(""repository"");if(item!==undefined){if(Loader.filterTopCheck(item,filter)===false)return}Convert.convertTop();Convert.convertTopMultiColumn();Convert.convertRepositorySelector()}})();if(Report===undefined)var Report={};(function(){var project_data=null,markers=null,viz_config=null,gridster={},data_sources=[],report_config=null,html_dir="""",menu_elements;var data_dir=""data/json"";var config_dir=""config"";var default_data_dir=""data/json"";var default_html_dir="""";var projects_dirs=[default_data_dir];var projects_data={};var projects_datasources={};var repos_map;Report.all_json_file=data_dir+""/all.json"";var project_file=config_dir+""/project-info.json"";viz_config_file=data_dir+""/viz_cfg.json"";markers_file=data_dir+""/markers.json"";repos_map_file=data_dir+""/repos-map.json"";projects_hierarchy_file=data_dir+""/projects_hierarchy.json"";menu_elements_file=config_dir+""/menu-elements.json"";var page_size=10,page=null;var project_people_identities={};Report.createDataSources=createDataSources;Report.getAllMetrics=getAllMetrics;Report.getMarkers=getMarkers;Report.getVizConfig=getVizConfig;Report.getProjectsHierarchy=getProjectsHierarchy;Report.getMenuElements=getMenuElements;Report.getMenuElementsReleases=getMenuElementsReleases;Report.getReleaseNames=getReleaseNames;Report.getThreadsSite=getThreadsSite;Report.getMetricDS=getMetricDS;Report.getGridster=getGridster;Report.setGridster=setGridster;Report.getCurrentPage=function(){return page};Report.setCurrentPage=function(current_page){page=current_page};Report.getPageSize=function(){return page_size};Report.setPageSize=function(size){page_size=size};Report.getProjectData=getProjectData;Report.getProjectsData=getProjectsData;Report.convertStudies=convertStudies;Report.getDataSources=function(){return data_sources};Report.registerDataSource=function(backend){data_sources.push(backend)};Report.setHtmlDir=function(dir){html_dir=dir};Report.getHtmlDir=function(){return html_dir};Report.getDataDir=function(){return data_dir};Report.setDataDir=function(dataDir){data_dir=dataDir;project_file=dataDir+""/project-info.json"";config_file=dataDir+""/viz_cfg.json"";markers_file=dataDir+""/markers.json"";repos_mapping_file=data_dir+""/repos-mapping.json"";projects_hierarchy_file=data_dir+""/projects_hierarchy.json""};function getMarkers(){return markers}Report.setMarkers=function(data){markers=data};Report.getMarkersFile=function(){return markers_file};Report.getReposMap=function(){return repos_map};Report.setReposMap=function(data){repos_map=data};Report.getReposMapFile=function(){return repos_map_file};function getVizConfig(){return viz_config}Report.setVizConfig=function(cfg){viz_config=cfg};Report.getVizConfigFile=function(){return viz_config_file};function getProjectsHierarchy(){return projects_hierarchy}Report.setProjectsHierarchy=function(data){projects_hierarchy=data};Report.getProjectsHierarchyFile=function(){return projects_hierarchy_file};function getMenuElements(){var elements;if(menu_elements!==undefined){elements=menu_elements.menu}return elements}function getMenuElementsReleases(){var releases;if(menu_elements!==undefined){releases=menu_elements.menu_releases}return releases}function getReleaseNames(){var names;if(menu_elements!==undefined){names=menu_elements.releases}return names}function getThreadsSite(){var site;if(menu_elements!==undefined){site=menu_elements.threads_site}return site}Report.setMenuElements=function(data){menu_elements=data};Report.getMenuElementsFile=function(){return menu_elements_file};function getGridster(){return gridster}function setGridster(grid){gridster=grid}function getProjectData(){return project_data}Report.setProjectData=function(data){project_data=data};Report.getProjectFile=function(){return project_file};function getProjectsData(){return projects_data}Report.getProjectsDirs=function(){return projects_dirs};Report.setProjectsDirs=function(dirs){projects_dirs=dirs};Report.getProjectsList=function(){var projects_list=[];$.each(getProjectsData(),function(key,val){projects_list.push(key)});return projects_list};Report.getProjectsDataSources=function(){return projects_datasources};Report.setMetricsDefinition=function(metrics){$.each(Report.getDataSources(),function(i,DS){DS.setMetricsDefinition(metrics[DS.getName()])})};Report.getPeopleIdentities=function(){return project_people_identities};Report.setPeopleIdentities=function(people){project_people_identities=people};Report.cleanLabel=function(item){var label=item;var aux=null;if(item.split(""___"").length===2){aux=item.split("" "");label=aux[0]}else if(item.lastIndexOf(""https:__api.github.com_repos_"")===0){label=label.replace(""https:__api.github.com_repos_"","""");label=label.split(""_"")[1]}else if(item.lastIndexOf(""http"")===0||item.split(""_"").length>3){aux=item.split(""_"");label=aux.pop();if(label==="""")label=aux.pop();label=label.replace(""buglist.cgi?product="","""");label=label.replace(""gmane.comp.sysutils."","""")}else if(item.lastIndexOf(""<"")===0)label=MLS.displayMLSListName(item);return label};function strNumberWithThousands(x){var parts=x.toString().split(""."");parts[0]=parts[0].replace(/\B(?=(\d{3})+(?!\d))/g,"","");return parts.join(""."")}Report.formatValue=function(number,field){if(number===undefined)return""-"";var date_fields=[""last_date"",""first_date""];var reports=[""repositories"",""companies"",""countries"",""domains"",""projects""];var value=number;try{value=parseFloat(number).toFixed(1).toString().replace(/\.0$/,"""");value=strNumberWithThousands(value);if(navigator.language===""es""){var parts=value.split(""."");parts[0]=parts[0].replace(/,/g,""."");value=parts.join("","")}}catch(err){}if(typeof value===""number""&&isNaN(value))value=number.toString();if(field!==undefined&&$.inArray(field,date_fields)>-1)value=number.toString();if(field!==undefined&&value===""0""){$.each(reports,function(i,report){if(field.indexOf(report)!=1){value=""-""}})}return value};Report.escapeHtml=function(unsafe){return unsafe.replace(/&/g,""&amp;"").replace(/</g,""&lt;"").replace(/>/g,""&gt;"").replace(/""/g,""&quot;"").replace(/'/g,""&#039;"")};Report.getParameterByName=function(name){name=name.replace(/[\[]/,""\\["").replace(/[\]]/,""\\]"");var regex=new RegExp(""[\\?&]""+name+""=([^&#]*)""),results=regex.exec(location.search);return results===null?undefined:Report.escapeHtml(decodeURIComponent(results[1].replace(/\+/g,"" "")))};function getMetricDS(metric_id){var ds=[];$.each(Report.getDataSources(),function(i,DS){if(DS.getMetrics()[metric_id]){ds.push(DS)}});return ds}Report.getDataSourceByName=function(ds){var DS=null;$.each(Report.getDataSources(),function(index,DSaux){if(DSaux.getName()===ds){DS=DSaux;return false}});return DS};function getAllMetrics(){var all={};$.each(Report.getDataSources(),function(index,DS){all=$.extend({},all,DS.getMetrics())});return all}Report.displayActiveMenu=function(){var active=window.location.href;var page=active.substr(active.lastIndexOf(""/"")+1,active.length);page=page.split("".html"")[0];if(page.indexOf(""scm"")===0){$("".scm-menu"")[0].className=$("".scm-menu"")[0].className+"" active""}else if(page.indexOf(""its"")===0){$("".its-menu"")[0].className=$("".its-menu"")[0].className+"" active""}else if(page.indexOf(""mls"")===0){$("".mls-menu"")[0].className=$("".mls-menu"")[0].className+"" active""}else if(page.indexOf(""scr"")===0){$("".scr-menu"")[0].className=$("".scr-menu"")[0].className+"" active""}else if(page.indexOf(""irc"")===0){$("".irc-menu"")[0].className=$("".irc-menu"")[0].className+"" active""}else if(page.indexOf(""qaforum"")===0){$("".qaforum-menu"")[0].className=$("".qaforum-menu"")[0].className+"" active""}else if(page.indexOf(""studies"")===0){$("".studies-menu"")[0].className=$("".studies-menu"")[0].className+"" active""}else if(page.indexOf(""wiki"")===0){$("".wiki-menu"")[0].className=$("".wiki-menu"")[0].className+"" active""}else if(page.indexOf(""downloads"")===0){$("".downloads-menu"")[0].className=$("".downloads-menu"")[0].className+"" active""}else if(page.indexOf(""projects"")===0){$("".listprojects-menu"")[0].className=$("".listprojects-menu"")[0].className+"" active"" }else if(page.indexOf(""index"")===0||page===""""){if($("".summary-menu"").length===0)return;$("".summary-menu"")[0].className=$("".summary-menu"")[0].className+"" active""}else{if($("".experimental-menu"")[0])$("".experimental-menu"")[0].className=$("".experimental-menu"")[0].className+"" active""}};function checkDynamicConfig(){var data_sources=[];var release=$.urlParam(""release"");if(release!==null&&release.length>0){data_sources.push(""data/json/""+release);Report.setDataDir(""data/json/""+release);if(data_sources.length>0)Report.setProjectsDirs(data_sources)}}function createDataSources(){checkDynamicConfig();var projects_dirs=Report.getProjectsDirs();var scm,its,its_1,mls,scr,irc,mediawiki,people,downloads,qaforums,releases,meetup;$.each(projects_dirs,function(i,project){if(Report.getConfig()===null||Report.getConfig()[""data-sources""]===undefined){its=new ITS;Report.registerDataSource(its);its_1=new ITS_1;Report.registerDataSource(its_1);mls=new MLS;Report.registerDataSource(mls);scm=new SCM;Report.registerDataSource(scm);scr=new SCR;Report.registerDataSource(scr);irc=new IRC;Report.registerDataSource(irc);mediawiki=new MediaWiki;Report.registerDataSource(mediawiki);people=new People;Report.registerDataSource(people);downloads=new Downloads;Report.registerDataSource(downloads);qaforums=new QAForums;Report.registerDataSource(qaforums);releases=new Releases;Report.registerDataSource(releases);meetup=new Meetup;Report.registerDataSource(meetup)}else{var active_ds=Report.getConfig()[""data-sources""];$.each(active_ds,function(i,name){if(name===""its""){its=new ITS;Report.registerDataSource(its)}else if(name===""its_1""){its_1=new ITS_1;Report.registerDataSource(its_1)}else if(name===""mls""){mls=new MLS;Report.registerDataSource(mls)}else if(name===""scm""){scm=new SCM;Report.registerDataSource(scm)}else if(name===""scr""){scr=new SCR;Report.registerDataSource(scr)}else if(name===""irc""){irc=new IRC;Report.registerDataSource(irc)}else if(name===""mediawiki""){mediawiki=new MediaWiki;Report.registerDataSource(mediawiki)}else if(name===""people""){people=new People;Report.registerDataSource(people)}else if(name===""downloads""){downloads=new Downloads;Report.registerDataSource(downloads)}else if(name===""qaforums""){qaforums=new QAForums;Report.registerDataSource(qaforums)}else if(name===""releases""){releases=new Releases;Report.registerDataSource(releases)}else if(name===""meetup""){meetup=new Meetup;Report.registerDataSource(meetup)}else Report.log(""Not support data source ""+name)})}if(its)its.setDataDir(project);if(its_1)its_1.setDataDir(project);if(mls)mls.setDataDir(project);if(scm)scm.setDataDir(project);if(scr)scr.setDataDir(project);if(irc)irc.setDataDir(project);if(mediawiki)mediawiki.setDataDir(project);if(people)people.setDataDir(project);if(downloads)downloads.setDataDir(project);if(qaforums)qaforums.setDataDir(project);if(releases)releases.setDataDir(project);if(scm&&its)scm.setITS(its);if(meetup)meetup.setDataDir(project)});return true}Report.addDataDir=function(){var addURL;var querystr=window.location.search.substr(1);if(querystr&&querystr.indexOf(""data_dir"")!==-1){addURL=window.location.search.substr(1)}return addURL};Report.configDataSources=function(){var prjs_dss=Report.getProjectsDataSources();$.each(Report.getDataSources(),function(index,ds){if(ds.getData()instanceof Array)return;$.each(projects_data,function(name,project){if(project.dir===ds.getDataDir()){if(prjs_dss[name]===undefined)prjs_dss[name]=[];$.each(prjs_dss[name],function(prj,prjds){if(ds.getName()===prjds.getName())return false});ds.setProject(name);prjs_dss[name].push(ds);return false}})})};Report.getConfig=function(){return report_config};Report.setConfig=function(data){report_config=data;if(data){Report.log(""Global config file found"");if(data[""global-html-dir""])Report.setHtmlDir(data[""global-html-dir""]);if(data[""global-data-dir""]){Report.setDataDir(data[""global-data-dir""]);Report.setProjectsDirs([data[""global-data-dir""]])}if(data[""projects-data-dirs""])Report.setProjectsDirs(data[""projects-data-dirs""])}};Report.convertGlobal=function(){Convert.convertBasicDivs();Convert.convertBasicDivsMisc();Convert.convertBasicMetrics();Convert.convertDemographics();Convert.convertMetricsEvolSet();Convert.convertLastActivity();Convert.convertMicrodash();Convert.convertMicrodashText()};Report.getActiveStudies=function(){var activeStudies=[];var reports;var reports_study=[""repositories"",""countries"",""companies"",""domains"",""projects""];if(Report.getConfig()!==null)reports=Report.getConfig().reports;else reports=reports_study;$.each(reports_study,function(i,study){if($.inArray(study,reports)>-1)activeStudies.push(study)});return activeStudies};Report.convertStudiesGlobal=function(){Convert.convertPeople()};function convertStudies(){$.each(Report.getActiveStudies(),function(i,study){var filter=study;if(study===""repositories"")filter=""repos"";DataProcess.orderItems(filter);Convert.convertFilterStudy(study);Convert.convertFilterStudyItem(study)})}var log_on=true;Report.getLog=function(){return log_on};Report.setLog=function(status){log_on=status};Report.log=function(msg){if(Report.getLog()===true)if(window.console)console.log(msg)}})();Loader.data_ready_global(function(){Report.configDataSources();Report.convertGlobal();Report.convertStudiesGlobal()});Loader.data_ready(function(){study=""repos"";Convert.convertFilterTop(study)});Loader.data_ready(function(){Report.convertStudies();$(""body"").css(""cursor"",""auto"");$(""html"").click(function(e){$("".help"").popover(""hide"")});Convert.activateHelp()});$(document).ready(function(){$.getJSON(Report.getMenuElementsFile(),function(data){Report.setMenuElements(data)}).fail(function(){if(window.console)Report.log(""Can't read global config file ""+Report.getMenuElementsFile())}).always(function(data){Report.createDataSources();$.getJSON(Report.all_json_file,function(data){if(window.console){Report.log(""Loaded all JSON data from ""+Report.all_json_file)}Loader.set_all_data(data)}).always(function(data){Loader.data_load()});$(""body"").css(""cursor"",""progress"")})});function resizedw(){if(true){return}Report.convertGlobal();Report.convertStudiesGlobal();Report.convertStudies();Convert.activateHelp()}var resized;$(window).resize(function(){clearTimeout(resized);resized=setTimeout(resizedw,100)});function DataSource(name,basic_metrics){this.top_data_file=this.data_dir+""/""+this.name+""-top.json"";this.getTopDataFile=function(){return this.top_data_file};this.getMetrics=function(){return this.basic_metrics};this.setMetrics=function(metrics){this.basic_metrics=metrics};this.setMetricsDefinition=function(metrics){if(metrics===undefined)return;this.setMetrics(metrics)};this.data_file=this.data_dir+""/""+this.name+""-evolutionary.json"";this.getDataFile=function(){return this.data_file};this.setDataFile=function(file){this.data_file=file};this.data=null;this.getData=function(){return this.data};function nameSpaceMetrics(plain_metrics,ds){if(plain_metrics instanceof Array)return plain_metrics;var metrics={};if(plain_metrics===null){return metrics}$.each(plain_metrics,function(name,value){var basic_name=name;var aux=name.split(""_"");if(isNaN(aux[aux.length-1])===false)basic_name=aux.slice(0,aux.length-1).join(""_"");var ns_basic_name=ds.getName()+""_""+basic_name;var ns_name=ds.getName()+""_""+name;if(ds.getMetrics()[ns_basic_name]===undefined)metrics[name]=value;else metrics[ns_name]=value});return metrics}this.setData=function(load_data,self){if(self===undefined)self=this;self.data=nameSpaceMetrics(load_data,self)};this.demographics_aging_file=this.data_dir+""/""+this.name+""-demographics-aging.json"";this.demographics_birth_file=this.data_dir+""/""+this.name+""-demographics-birth.json"";this.getDemographicsAgingFile=function(){return this.demographics_aging_file};this.getDemographicsBirthFile=function(){return this.demographics_birth_file};this.demographics_data={};this.getDemographicsData=function(){return this.demographics_data};this.setDemographicsAgingData=function(data,self){if(self===undefined)self=this;self.demographics_data.aging=data};this.setDemographicsBirthData=function(data,self){if(self===undefined)self=this;self.demographics_data.birth=data};this.data_dir=""data/json"";this.getDataDir=function(){return this.data_dir};this.setDataDir=function(dataDir){this.data_dir=dataDir;this.data_file=dataDir+""/""+this.name+""-evolutionary.json"";this.demographics_aging_file=dataDir+""/""+this.name+""-demographics-aging.json"";this.demographics_birth_file=dataDir+""/""+this.name+""-demographics-birth.json"";this.global_data_file=dataDir+""/""+this.name+""-static.json"";this.top_data_file=dataDir+""/""+this.name+""-top.json"";this.companies_data_file=dataDir+""/""+this.name+""-companies.json"";this.repos_data_file=dataDir+""/""+this.name+""-repos.json"";this.countries_data_file=dataDir+""/""+this.name+""-countries.json"";this.domains_data_file=dataDir+""/""+this.name+""-domains.json"";this.projects_data_file=dataDir+""/""+this.name+""-projects.json"";this.time_to_fix_data_file=dataDir+""/""+this.name+""-quantiles-month-time_to_fix_hour.json""};this.global_data_file=this.data_dir+""/""+this.name+""-static.json"";this.getGlobalDataFile=function(){return this.global_data_file};this.global_data=null;this.getGlobalData=function(){return this.global_data};this.setGlobalData=function(data,self){if(self===undefined)self=this;var aux=Report.getMenuElements();var active_companies=null;if(aux&&typeof aux.filter_companies!==undefined){active_companies=aux.filter_companies}if(active_companies&&active_companies.length>0&&Object.keys(data).indexOf(""companies"")>=0){data.companies=active_companies.length}self.global_data=nameSpaceMetrics(data,self)};this.global_top_data=null;this.getGlobalTopData=function(){return this.global_top_data};this.setGlobalTopData=function(data,self){if(self===undefined)self=this;self.global_top_data=data};this.name=name;this.getName=function(){return this.name};this.people_data_file=this.data_dir+""/""+this.name+""-people.json"";this.getPeopleDataFile=function(){return this.people_data_file};this.people=null;this.getPeopleData=function(){return this.people};this.setPeopleData=function(people,self){if(self===undefined)self=this;self.people=people};this.time_to_fix_data_file=this.data_dir+""/""+this.name+""-quantiles-month-time_to_fix_hour.json"";this.getTimeToFixDataFile=function(){return this.time_to_fix_data_file};this.time_to_fix_data=null;this.getTimeToFixData=function(){return this.time_to_fix_data};this.setTimeToFixData=function(data,self){if(self===undefined)self=this;self.time_to_fix_data=data};this.time_to_attention_data_file=this.data_dir+""/""+this.name+""-quantiles-month-time_to_attention_hour.json"";this.getTimeToAttentionDataFile=function(){return this.time_to_attention_data_file};this.time_to_attention_data=null;this.getTimeToAttentionData=function(){return this.time_to_attention_data};this.setTimeToAttentionData=function(data,self){if(self===undefined)self=this;self.time_to_attention_data=data};this.project=null;this.getProject=function(){return this.project};this.setProject=function(project){this.project=project};this.markov_table_data_file=this.data_dir+""/""+this.name+""-markov.json"";this.getMarkovTableDataFile=function(){return this.markov_table_data_file};this.markov_table_data=null;this.getMarkovTableData=function(){return this.markov_table_data};this.setMarkovTableData=function(data,self){if(self===undefined)self=this;self.markov_table_data=data};this.companies_data_file=this.data_dir+""/""+this.name+""-companies.json"";this.getCompaniesDataFile=function(){return this.companies_data_file};this.companies=null;this.getCompaniesDataFull=function(){return this.companies};this.getCompaniesData=function(){var items=this.companies;if(items instanceof Array===false){if(this.companies!==null){items=this.companies.name}}return items};function filterOutCompaniesArray(com_data){var aux=Report.getMenuElements(),active_companies=null,result=[];if(aux&&typeof aux.filter_companies!==undefined){active_companies=aux.filter_companies}if(active_companies&&active_companies.length>0){$.each(com_data,function(pos,name){if(active_companies.indexOf(name)>=0){result[result.length]=name}})}else{result=com_data}return result}function filterOutCompanies(com_data){var aux=Report.getMenuElements();var active_companies=null;if(aux&&typeof aux.filter_companies!==undefined){active_companies=aux.filter_companies}if(active_companies&&active_companies.length>0){var keys=Object.keys(com_data);var positions=[];$.each(com_data.name,function(pos,name){if(active_companies.indexOf(name)>=0){positions[positions.length]=pos}});var new_obj={};$.each(keys,function(id,k){new_obj[k]=[];$.each(positions,function(subid,pos){var l=new_obj[k].length;new_obj[k][l]=com_data[k][pos]})});com_data=new_obj}return com_data}this.setCompaniesData=function(companies,self){if(companies===null)companies=[];if(self===undefined)self=this;if(Array.isArray(companies)){self.companies=filterOutCompaniesArray(companies)}else if(typeof companies===""object""){self.companies=filterOutCompanies(companies)}};this.companies_metrics_data={};this.addCompanyMetricsData=function(company,data,self){if(self===undefined)self=this;self.companies_metrics_data[company]=nameSpaceMetrics(data,self)};this.getCompaniesMetricsData=function(){return this.companies_metrics_data};this.companies_global_data={};this.addCompanyGlobalData=function(company,data,self){if(self===undefined)self=this;self.companies_global_data[company]=nameSpaceMetrics(data,self)};this.getCompaniesGlobalData=function(){return this.companies_global_data};this.companies_top_data={};this.addCompanyTopData=function(company,data,self){if(self===undefined)self=this;if(self.companies_top_data[company]===undefined)self.companies_top_data[company]={};self.companies_top_data[company]=data};this.getCompaniesTopData=function(){return this.companies_top_data};this.setCompaniesTopData=function(data,self){if(self===undefined)self=this;self.companies_top_data=data};this.repos_data_file=this.data_dir+""/""+this.name+""-repos.json"";this.getReposDataFile=function(){return this.repos_data_file};this.repos=null;this.getReposDataFull=function(){return this.repos};this.getReposData=function(){var items=this.repos;if(items instanceof Array===false){if(this.repos!==null){items=this.repos.name}}return items};this.setReposData=function(repos,self){if(self===undefined)self=this;self.repos=repos;if(self.getName()!==""its"")return;repos_names=[];if(repos instanceof Array===true){self.repos={};self.repos.name=repos}var filtered_repos=[];for(var i=0;i<self.repos.name.length;i++){filtered_repos.push(self.repos.name[i].replace(/\//g,""_""))}self.repos.name=filtered_repos};this.repos_metrics_data={};this.addRepoMetricsData=function(repo,data,self){if(self===undefined)self=this;self.repos_metrics_data[repo]=nameSpaceMetrics(data,self)};this.getReposMetricsData=function(){return this.repos_metrics_data};this.repos_global_data={};this.addRepoGlobalData=function(repo,data,self){if(self===undefined)self=this;self.repos_global_data[repo]=nameSpaceMetrics(data,self)};this.getReposGlobalData=function(){return this.repos_global_data};this.repositories_top_data={};this.addRepositoryTopData=function(repository,data,self){if(self===undefined)self=this;if(self.repositories_top_data[repository]===undefined)self.repositories_top_data[repository]={};self.repositories_top_data[repository]=data};this.getRepositoriesTopData=function(){return this.repositories_top_data};this.setRepositoriesTopData=function(data,self){if(self===undefined)self=this;self.repositories_top_data=data};this.countries_data_file=this.data_dir+""/""+this.name+""-countries.json"";this.getCountriesDataFile=function(){return this.countries_data_file};this.countries=null;this.getCountriesData=function(){var items=this.countries;if(items instanceof Array===false){if(this.countries!==null){items=this.countries.name}}return items};this.setCountriesData=function(countries,self){if(self===undefined)self=this;self.countries=countries};this.countries_metrics_data={};this.addCountryMetricsData=function(country,data,self){if(self===undefined)self=this;self.countries_metrics_data[country]=nameSpaceMetrics(data,self)};this.getCountriesMetricsData=function(){return this.countries_metrics_data};this.countries_global_data={};this.addCountryGlobalData=function(country,data,self){if(self===undefined)self=this;self.countries_global_data[country]=nameSpaceMetrics(data,self)};this.getCountriesGlobalData=function(){return this.countries_global_data};this.domains_data_file=this.data_dir+""/""+this.name+""-domains.json"";this.getDomainsDataFile=function(){return this.domains_data_file};this.domains=null;this.getDomainsDataFull=function(){return this.domains};this.getDomainsData=function(){var items=this.domains;if(items instanceof Array===false){if(this.domains!==null){items=this.domains.name}}return items};this.setDomainsData=function(domains,self){if(domains===null)domains=[];if(self===undefined)self=this;self.domains=domains};this.domains_metrics_data={};this.addDomainMetricsData=function(domain,data,self){if(self===undefined)self=this;self.domains_metrics_data[domain]=nameSpaceMetrics(data,self)};this.getDomainsMetricsData=function(){return this.domains_metrics_data};this.domains_global_data={};this.addDomainGlobalData=function(domain,data,self){if(self===undefined)self=this;self.domains_global_data[domain]=nameSpaceMetrics(data,self)};this.getDomainsGlobalData=function(){return this.domains_global_data};this.projects_data_file=this.data_dir+""/""+this.name+""-projects.json"";this.getProjectsDataFile=function(){return this.projects_data_file};this.projects=null;this.getProjectsData=function(){return this.projects};this.setProjectsData=function(projects,self){if(projects===null)self.projects=[];if(self===undefined)self=this;if(Array.isArray(projects)){self.projects=projects}else if(typeof projects===""object""){self.projects=projects.name}};this.projects_metrics_data={};this.addProjectMetricsData=function(project,data,self){if(self===undefined)self=this;self.projects_metrics_data[project]=nameSpaceMetrics(data,self)};this.getProjectsMetricsData=function(){return this.projects_metrics_data};this.projects_global_data={};this.addProjectGlobalData=function(project,data,self){if(self===undefined)self=this;self.projects_global_data[project]=nameSpaceMetrics(data,self)};this.getProjectsGlobalData=function(){return this.projects_global_data};this.people_metrics_data={};this.addPeopleMetricsData=function(id,data,self){if(self===undefined)self=this;self.people_metrics_data[id]=nameSpaceMetrics(data,self)};this.getPeopleMetricsData=function(){return this.people_metrics_data};this.people_global_data={};this.addPeopleGlobalData=function(id,data,self){if(self===undefined)self=this;self.people_global_data[id]=nameSpaceMetrics(data,self)};this.getPeopleGlobalData=function(){return this.people_global_data};this.getCompanyQuery=function(){var company=null;var querystr=window.location.search.substr(1);if(querystr&&querystr.split(""&"")[0].split(""="")[0]===""company"")company=querystr.split(""&"")[0].split(""="")[1];return company};this.displayMetricCompanies=function(metric_id,div_target,config,start,end){var companies_data=this.getCompaniesMetricsData();Viz.displayMetricCompanies(metric_id,companies_data,div_target,config,start,end)};this.displayMetricMyCompanies=function(companies,metric_id,div_target,config,start,end){var companies_data={};var self=this;$.each(companies,function(i,name){companies_data[name]=self.getCompaniesMetricsData()[name]});Viz.displayMetricCompanies(metric_id,companies_data,div_target,config,start,end)};this.displayMetricRepos=function(metric_id,div_target,config,start,end){var repos_data=this.getReposMetricsData();Viz.displayMetricRepos(metric_id,repos_data,div_target,config,start,end)};this.displayBasicMetricMyRepos=function(repos,metric_id,div_target,config,start,end){var repos_data={};var reposMap=Report.getReposMap();var self=this;$.each(repos,function(i,name){var metrics=self.getReposMetricsData()[name];if(!metrics){if(reposMap[name]instanceof Object){name=reposMap[name][self.getName()]}else{name=reposMap[name]}metrics=self.getReposMetricsData()[name]}repos_data[name]=metrics});Viz.displayMetricRepos(metric_id,repos_data,div_target,config,start,end)};this.displayMetricDomains=function(metric_id,div_target,config,start,end){var domains_data=this.getDomainsMetricsData();Viz.displayMetricDomains(metric_id,domains_data,div_target,config,start,end)};this.displayMetricProjects=function(metric_id,div_target,config,start,end){var projects_data=this.getProjectsMetricsData();Viz.displayMetricProjects(metric_id,projects_data,div_target,config,start,end)};this.displayMetricCompaniesStatic=function(metric_id,div_target,config,order_by,show_others){this.displayMetricSubReportStatic(""companies"",metric_id,div_target,config,order_by,show_others)};this.displayMetricReposStatic=function(metric_id,div_target,config,order_by,show_others){this.displayMetricSubReportStatic(""repos"",metric_id,div_target,config,order_by,show_others)};this.displayMetricCountriesStatic=function(metric_id,div_target,config,order_by,show_others){this.displayMetricSubReportStatic(""countries"",metric_id,div_target,config,order_by,show_others)};this.displayMetricDomainsStatic=function(metric_id,div_target,config,order_by,show_others){this.displayMetricSubReportStatic(""domains"",metric_id,div_target,config,order_by,show_others)};this.displayMetricProjectsStatic=function(metric_id,div_target,config,order_by,show_others){this.displayMetricSubReportStatic(""projects"",metric_id,div_target,config,order_by,show_others)};this.displayMetricSubReportStatic=function(report,metric_id,div_target,config,order_by,show_others){if(order_by===undefined)order_by=metric_id;var data=null;if(report==""companies"")data=this.getCompaniesGlobalData();else if(report==""repos"")data=this.getReposGlobalData();else if(report==""countries"")data=this.getCountriesGlobalData();else if(report==""domains"")data=this.getDomainsGlobalData();else if(report==""projects"")data=this.getProjectsGlobalData();else return;if($.isEmptyObject(data))return;var order=DataProcess.sortGlobal(this,order_by,report);if(order instanceof Array===false){order=order.name}data_page=DataProcess.paginate(order,Report.getCurrentPage());Viz.displayMetricSubReportStatic(metric_id,data,data_page,div_target,config)};this.displayMetricsCompany=function(company,metrics,div_id,config){var data=this.getCompaniesMetricsData()[company];if(data===undefined){$(""#""+div_id).hide();return}Viz.displayMetricsCompany(this,company,metrics,data,div_id,config)};this.displayMetricsRepo=function(repo,metrics,div_id,config){var data=this.getReposMetricsData()[repo];if(data===undefined){$(""#""+div_id).hide();return}Viz.displayMetricsRepo(this,repo,metrics,data,div_id,config)};this.displayMetricsCountry=function(country,metrics,div_id,config){var data=this.getCountriesMetricsData()[country];if(data===undefined){$(""#""+div_id).hide();return}Viz.displayMetricsCountry(this,country,metrics,data,div_id,config)};this.displayMetricsDomain=function(domain,metrics,div_id,config){var data=this.getDomainsMetricsData()[domain];if(data===undefined)return;Viz.displayMetricsDomain(this,domain,metrics,data,div_id,config)};this.displayMetricsProject=function(project,metrics,div_id,config){var data=this.getProjectsMetricsData()[project];if(data===undefined)return;Viz.displayMetricsProject(this,project,metrics,data,div_id,config)};this.displayMetricsPeople=function(upeople_id,upeople_identifier,metrics,div_id,config){var history=this.getPeopleMetricsData()[upeople_id];if(history===undefined||history instanceof Array){$(""#""+div_id).hide();return}Viz.displayMetricsPeople(this,upeople_identifier,metrics,history,div_id,config)};this.displayMetricsEvol=function(metric_ids,div_target,config,convert){var data={};var repositories;if(config.repo_filter){repositories=config.repo_filter.split("","");var self=this;$.each(repositories,function(id,value){if($.inArray(value,self.getReposData())>=0){if(self.getName()===""mls""){var mls_name=MLS.displayMLSListName(value);data[mls_name]=self.getReposMetricsData()[value]}else{data[value]=self.getReposMetricsData()[value]}}})}else{data=this.getData()}if(convert){data=DataProcess.convert(data,convert,metric_ids);if(convert===""divide""){mlabel=this.getMetrics()[metric_ids[0]].name+""/"";mlabel+=this.getMetrics()[metric_ids[1]].name;metric_ids=[""divide""];this.getMetrics().divide={name:mlabel}}if(convert===""substract""){mlabel=this.getMetrics()[metric_ids[0]].name+""-"";mlabel+=this.getMetrics()[metric_ids[1]].name;metric_ids=[""substract""];this.getMetrics().substract={name:mlabel}}}Viz.displayMetricsEvol(this,metric_ids,data,div_target,config,repositories)};this.isPageDisplayed=function(visited,linked,total,displayed){var window=Math.floor((displayed-3)/2);var lowest_barrier=visited-window;var highest_barrier=visited+window;if(linked===1||linked===total||linked==visited){return true}else if(linked>=lowest_barrier&&linked<visited){return true}else if(linked<=highest_barrier&&linked>visited){return true}else{return false}};this.displayItemsNav=function(div_nav,type,page_str,order_by){var page=parseInt(page_str,null);if(isNaN(page))page=1;var items=null;var title="""";var total=0;var displayed_pages=5;if(type===""companies""){items=this.getCompaniesData();title=""List of companies""}else if(type===""repos""){items=this.getReposData();if(order_by)items=DataProcess.sortGlobal(this,order_by,type)}else if(type===""countries""){items=this.getCountriesData()}else if(type===""domains""){items=this.getDomainsData()}else if(type===""projects""){items=this.getProjectsData()}else{return}total=items.length;var nav="""";var psize=Report.getPageSize();if(page){nav+=""<div class='pagination'>"";var number_pages=Math.ceil(total/psize);var from_item=(page-1)*psize+1;var to_item=page*psize;if(to_item>total){to_item=total}nav+=""<ul class='pagination'>"";if(page>1){if(Utils.isReleasePage()){nav+=""<li><a href='""+Utils.createReleaseLink(""?page=""+(page-1))+""'>&laquo;</a></li>""}else{nav+=""<li><a href='?page=""+(page-1)+""'>&laquo;</a></li>""}}else{if(Utils.isReleasePage()){nav+=""<li class='disabled'><a href='""+Utils.createReleaseLink(""?page=""+page)+""'>&laquo;</a></li>""}else{nav+=""<li class='disabled'><a href='?page=""+page+""'>&laquo;</a></li>""}}for(var j=0;j*Report.getPageSize()<total;j++){if(this.isPageDisplayed(page,j+1,number_pages,displayed_pages)===true){if(page===j+1){if(Utils.isReleasePage()){nav+=""<li class='active'><a href='""+Utils.createReleaseLink(""?page=""+(j+1))+""'>""+(j+1)+""</a></li>""}else{nav+=""<li class='active'><a href='?page=""+(j+1)+""'>""+(j+1)+""</a></li>""}}else{if(Utils.isReleasePage()){nav+=""<li><a href='""+Utils.createReleaseLink(""?page=""+(j+1))+""'>""+(j+1)+""</a></li>""}else{nav+=""<li><a href='?page=""+(j+1)+""'>""+(j+1)+""</a></li>""}}}else{if(j+1+1===number_pages||j+1-1===1){nav+=""<li class='disabled'><a href='#'> .. </a></li>""}}}if(page*Report.getPageSize()<items.length){if(Utils.isReleasePage()){nav+=""<li><a href='""+Utils.createReleaseLink(""?page=""+(parseInt(page,null)+1))+""'>""}else{nav+=""<li><a href='?page=""+(parseInt(page,null)+1)+""'>""}nav+=""&raquo;</a></li>""}nav+=""</ul>"";nav+=""<span class='pagination-text'> (""+from_item+"" - ""+to_item+""/""+total+"")</span>"";nav+=""</div>""}if(Report.getPageSize()>10)$.each(items,function(id,item){var label=Report.cleanLabel(item);nav+=""<a href='#""+item+""-nav'>""+label+""</a> ""});$(""#""+div_nav).append(nav)};this.displayCompaniesLinks=function(div_links,limit,sort_metric){var sorted_companies=DataProcess.sortGlobal(this,sort_metric,""companies"");var links="""";var i=0;$.each(sorted_companies,function(id,company){links+='<a href=""company.html?company='+company;if(Report.addDataDir())links+=""&""+Report.addDataDir();links+='"">'+company+""</a>| "";if(i++>=limit-1)return false});$(""#""+div_links).append(links)};this.displayCompaniesList=function(metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert){this.displaySubReportList(""companies"",metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert)};this.displayReposList=function(metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert,ds_realname){this.displaySubReportList(""repos"",metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert,ds_realname)};this.displayCountriesList=function(metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert){this.displaySubReportList(""countries"",metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert)};this.displayDomainsList=function(metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert){this.displaySubReportList(""domains"",metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert)};this.displayProjectsList=function(metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert){this.displaySubReportList(""projects"",metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert)};this.displaySubReportList=function(report,metrics,div_id,config_metric,sort_metric,page_str,show_links,start,end,convert,ds_realname){var page=parseInt(page_str,null);if(isNaN(page))page=1;var list="""";var cont=(page-1)*Report.getPageSize()+1;var ds=this;var data=null,sorted=null;if(show_links===undefined)show_links=true;if(report===""companies""){data=this.getCompaniesMetricsData();sorted=DataProcess.sortGlobal(this,sort_metric,report)}else if(report===""repos""){data=this.getReposMetricsData();sorted=DataProcess.sortGlobal(this,sort_metric,report)}else if(report===""countries""){data=this.getCountriesMetricsData();sorted=DataProcess.sortGlobal(this,sort_metric,report)}else if(report===""domains""){data=this.getDomainsMetricsData();sorted=DataProcess.sortGlobal(this,sort_metric,report)}else if(report===""projects""){data=this.getProjectsMetricsData();sorted=DataProcess.sortGlobal(this,sort_metric,report)}else return;sorted=DataProcess.paginate(sorted,page);list+='<table class=""table table-hover table-repositories"">';list+=""<tr><th></th>"";$.each(metrics,function(id,metric){if(ds.getMetrics()[metric]){title=ds.getMetrics()[metric].name;list+=""<th>""+title+""</th>""}else{list+=""<th>""+metric+""</th>""}});list+=""</tr>"";$.each(sorted,function(id,item){list+=""<tr><td class='col-md-2 repository-name'>"";list+=""#""+cont+""&nbsp;"";cont++;var addURL=null;if(Report.addDataDir())addURL=Report.addDataDir();if(show_links){var release_var="""";if(Utils.isReleasePage())release_var=""&release=""+$.urlParam(""release"");if(report===""companies""){list+=""<a href='company.html?company=""+item;list+=release_var;if(addURL)list+=""&""+addURL;list+=""'>""}else if(report===""repos""){list+=""<a href='"";list+=""repository.html"";list+=""?repository=""+encodeURIComponent(item);list+=release_var;if(ds_realname){list+=""&ds=""+ds_realname}else{list+=""&ds=""+ds.getName()}if(addURL)list+=""&""+addURL;list+=""'>""}else if(report===""countries""){list+=""<a href='country.html?country=""+item;list+=release_var;if(addURL)list+=""&""+addURL;list+=""'>""}else if(report===""domains""){list+=""<a href='domain.html?domain=""+item;list+=release_var;if(addURL)list+=""&""+addURL;list+=""'>""}else if(report===""projects""){list+=""<a href='project.html?project=""+item;list+=release_var;if(addURL)list+=""&""+addURL;list+=""'>""}}list+=""<strong>"";list+=Report.cleanLabel(item);list+=""</strong>"";if(show_links)list+=""</a>"";list+=""</td>"";var width=Math.floor(10/metrics.length);$.each(metrics,function(id,metric){var mywidth=width;list+=""<td class='col-md-""+mywidth+""'>"";list+=""<div id='""+report+""-""+item+""-""+metric+""'"";list+="" class='subreport-list-item'>""});list+=""</td></tr>""});list+=""</table>"";$(""#""+div_id).append(list);var start_items=null,end_items=null,convert_items=null;if(start){if(typeof start===""number"")start_items=[start.toString()];else start_items=start.split("","")}if(end){if(typeof end===""number"")end_items=[end.toString()];else end_items=end.split("","")}if(convert)convert_items=convert.split("","");$.each(sorted,function(id,item){var i=0;$.each(metrics,function(id,metric){var mstart=null,mend=null,mconvert=null;if(start_items){if(start_items.length==1)mstart=start_items[0];else mstart=start_items[i]}if(end_items){if(end_items.length==1)mend=end_items[0]; else mend=end_items[i]}if(convert_items)mconvert=convert_items[i];if(item in data===false)return;var item_data=data[item];if(item_data[metric]===undefined)return;var div_id=report+""-""+item+""-""+metric;var items={};items[item]=item_data;var title="""";Viz.displayMetricSubReportLines(div_id,metric,items,title,config_metric,mstart,mend,mconvert);i++})})};this.displayGlobalSummary=function(divid){this.displaySummary(null,divid,null,this)};this.displayCompanySummary=function(divid,company,ds){this.displaySummary(""companies"",divid,company,ds)};this.displayRepoSummary=function(divid,repo,ds,ds_realname){this.displaySummary(""repositories"",divid,repo,ds,ds_realname)};this.displayCountrySummary=function(divid,repo,ds){this.displaySummary(""countries"",divid,repo,ds)};this.displayDomainSummary=function(divid,domain,ds){this.displaySummary(""domains"",divid,domain,ds)};this.displayProjectSummary=function(divid,project,ds){this.displaySummary(""projects"",divid,project,ds)};this.displayPeopleSummary=function(divid,upeople_id,upeople_identifier,ds){var history=ds.getPeopleGlobalData()[upeople_id];if(history===undefined||history instanceof Array)return;html=HTMLComposer.personSummaryTable(ds.getName(),history);$(""#""+divid).append(html)};this.displayCompaniesSummary=function(divid,ds){var html="""";var data=ds.getGlobalData();html+=""Total companies: ""+data.companies+""<br>"";if(data.companies_2006)html+=""Companies in 2006: ""+data.companies_2006+""<br>"";if(data.companies_2009)html+=""Companies in 2009: ""+data.companies_2009+""<br>"";if(data.companies_2012)html+=""Companies in 2012: ""+data.companies_2012+""<br>"";$(""#""+divid).append(html)};this.getSummaryLabels=function(){};this.getLabelForRepository=function(){return""repository""};this.getLabelForRepositories=function(){return""repositories""};this.displaySummary=function(report,divid,item,ds,ds_realname){if(!item)item="""";var html=""<h6>""+ds.getTitle()+""</h6>"";var id_label=this.getSummaryLabels();var global_data=null;if(report===""companies"")global_data=ds.getCompaniesGlobalData()[item];else if(report===""countries"")global_data=ds.getCountriesGlobalData()[item];else if(report===""repositories"")global_data=ds.getReposGlobalData()[item];else if(report===""domains"")global_data=ds.getDomainsGlobalData()[item];else if(report===""projects"")global_data=ds.getProjectsGlobalData()[item];else global_data=ds.getGlobalData();if(!global_data)return;html=HTMLComposer.repositorySummaryTable(ds,global_data,id_label,ds_realname);$(""#""+divid).append(html)};this.displayReposSummary=function(divid,ds){var html="""";var data=ds.getGlobalData();html+=""Total repositories: ""+data[ds.getName()+""_repositories""]+""<br>"";$(""#""+divid).append(html)};this.displayCountriesSummary=function(divid,ds){var html="""";var data=ds.getGlobalData();html+=""Total countries: ""+data[ds.getName()+""_countries""]+""<br>"";$(""#""+divid).append(html)};this.displayDomainsSummary=function(divid,ds){var html="""";var data=ds.getGlobalData();html+=""Total domains: ""+data.domains+""<br>"";$(""#""+divid).append(html)};this.displayProjectsSummary=function(divid,ds){var html="""";var data=ds.getGlobalData();html+=""Total projects: ""+data.projects+""<br>"";$(""#""+divid).append(html)};this.displayDemographics=function(divid,period){var data=this.getDemographicsData();Viz.displayDemographicsChart(divid,data,period)};this.displayTimeToAttention=function(div_id,column,labels,title){labels=true;title=""Time to Attention ""+column;var data=this.getTimeToAttentionData();if(data instanceof Array)return;Viz.displayTimeToAttention(div_id,data,column,labels,title)};this.displayTimeToFix=function(div_id,column,labels,title){labels=true;title=""Time to Fix ""+column;var data=this.getTimeToFixData();if(data instanceof Array)return;Viz.displayTimeToFix(div_id,this.getTimeToFixData(),column,labels,title)};this.displayMarkovTable=function(div_id,title){var data=this.getMarkovTableData();if(data===undefined){Report.log(""No Markov data available"");return}Viz.displayMarkovTable(div_id,data,title)};this.displayTop=function(div,all,show_metric,period,period_all,graph,limit,people_links,threads_links,repository){if(all===undefined)all=true;var titles=null;Viz.displayTop(div,this,all,show_metric,period,period_all,null,null,limit,people_links,threads_links,repository)};this.displayTopCompany=function(company,div,metric_id,period,titles,height,people_links){var data=this.getCompaniesTopData()[company];if(data===undefined)return;var metric=this.getMetrics()[metric_id];Viz.displayTopCompany(this,company,data,div,metric_id,period,titles,height,people_links)};this.displayTopGlobal=function(div,metric,period,titles){Viz.displayTopGlobal(div,this,metric,period,titles)};this.envisionEvo=function(div_id,history,relative,legend_show,summary_graph){config=Report.getVizConfig();var options=Viz.getEnvisionOptions(div_id,history,this.getName(),Report.getVizConfig()[this.getName()+""_hide""],summary_graph);options.legend_show=legend_show;if(relative)DataProcess.addRelativeValues(options.data,this.getMainMetric());new envision.templates.Envision_Report(options,[this])};this.displayEnvision=function(divid,relative,legend_show,summary_graph){var projects_full_data=Report.getProjectsDataSources();this.envisionEvo(divid,projects_full_data,relative,legend_show,summary_graph)}}if(Viz===undefined)var Viz={};(function(){var bitergiaColor=""#ffa500"";Viz.displayTop=displayTop;Viz.displayTopCompany=displayTopCompany;Viz.displayTopGlobal=displayTopGlobal;Viz.displayBasicChart=displayBasicChart;Viz.displayMetricCompanies=displayMetricCompanies;Viz.displayMetricSubReportStatic=displayMetricSubReportStatic;Viz.displayMetricsCompany=displayMetricsCompany;Viz.displayMetricsDomain=displayMetricsDomain;Viz.displayMetricsProject=displayMetricsProject;Viz.displayMetricsPeople=displayMetricsPeople;Viz.displayMetricsRepo=displayMetricsRepo;Viz.displayMetricRepos=displayMetricRepos;Viz.displayMetricsCountry=displayMetricsCountry;Viz.displayMetricDomains=displayMetricDomains;Viz.displayMetricProjects=displayMetricProjects;Viz.displayMetricsEvol=displayMetricsEvol;Viz.displayBubbles=displayBubbles;Viz.displayDemographicsChart=displayDemographicsChart;Viz.displayEnvisionAll=displayEnvisionAll;Viz.displayTimeToFix=displayTimeToFix;Viz.displayTimeToAttention=displayTimeToAttention;Viz.displayMetricSubReportLines=displayMetricSubReportLines;Viz.displayRadarActivity=displayRadarActivity;Viz.displayRadarCommunity=displayRadarCommunity;Viz.displayTreeMap=displayTreeMap;Viz.displayMarkovTable=displayMarkovTable;Viz.displayDataSourcesTable=displayDataSourcesTable;Viz.getEnvisionOptions=getEnvisionOptions;Viz.checkBasicConfig=checkBasicConfig;Viz.displayTimeZone=displayTimeZone;function findMetricDoer(history,metric_id){var doer="""";$.each(Report.getAllMetrics(),function(name,metric){if(metric.action===metric_id){doer=metric.column;return false}});return doer}function displayMarkovTable(div_id,data,title){var html=""<h4>""+title+""</h4>"";var table='<table id=""itsmarkovtable"" class=""table table-striped"">';table+=""<thead><tr><th>Transition</th><th>Number</th><th>Percent</th></tr></thead><tbody>"";$.each(data,function(i,val){subdata=data[i];old_value=""old_value"";new_value=""new_value"";percent=""f"";number=""issue"";for(var k=0;k<subdata[old_value].length;k++){var value_new=subdata[new_value][k];var value_p=subdata[percent][k];value_p=Math.round(value_p*100)/100;var value_num=subdata[number][k];table+=""<tr><td>""+i+"" -> ""+value_new+""</td>"";table+=""<td>""+value_num+""</td>"";table+=""<td>""+value_p+""</td></tr>""}});table+=""</tbody></table>"";html+=table;div=$(""#""+div_id);div.append(html);return}function translate(labels,l){if(labels.hasOwnProperty(l)){return labels[l]}else{return l}}function getTopVarsFromMetric(metric,ds_name){var var_names={};var_names.id=""id"";if(metric===""senders""&&(ds_name===""mls""||ds_name===""irc"")){var_names.name=""senders"";var_names.action=""sent""}if(metric===""authors""&&ds_name===""scm""){var_names.name=""authors"";var_names.action=""commits""}if(metric===""closers""&&(ds_name===""its""||ds_name===""its_1"")){var_names.name=""closers"";var_names.action=""closed""}if(ds_name===""scr""){if(metric===""mergers""){var_names.name=""mergers"";var_names.action=""merged""}if(metric===""openers""){var_names.name=""openers"";var_names.action=""opened""}if(metric===""reviewers""){var_names.name=""reviewers"";var_names.action=""reviews""}if(metric===""active_core_reviewers""){var_names.name=""identifier"";var_names.action=""reviews""}if(metric===""participants""){var_names.name=""identifier"";var_names.action=""events""}}if(ds_name===""downloads""){if(metric===""ips""){var_names.name=""ips"";var_names.action=""downloads""}if(metric===""packages""){var_names.name=""packages"";var_names.action=""downloads""}}if(ds_name===""mediawiki""){if(metric===""authors""){var_names.name=""authors"";var_names.action=""reviews""}}if(ds_name===""qaforums""){if(metric===""senders""||metric===""asenders""||metric===""qsenders""){var_names.name=""senders"";var_names.action=""sent""}else if(metric===""participants""){var_names.name=""name"";var_names.action=""messages_sent""}}if(ds_name===""releases""){if(metric===""authors""){var_names.name=""username"";var_names.action=""releases""}}return var_names}function getSortedPeriods(){return[""last month"",""last year"",""""]}function composeTopRowsDownloads(dl_data,limit,var_names){var rows_html="""";for(var j=0;j<dl_data[var_names.name].length;j++){if(limit&&limit<=j)break;var metric_value=dl_data[var_names.action][j];rows_html+=""<tr><td> ""+(j+1)+""</td>"";rows_html+=""<td>"";rows_html+=dl_data[var_names.name][j];rows_html+=""</td>"";rows_html+=""<td>""+metric_value+""</td></tr>""}return rows_html}function composeTopRowsThreads(threads_data,limit,threads_links){var rows_html="""";for(var i=0;i<threads_data.subject.length;i++){if(limit&&limit<=i)break;rows_html+=""<tr><td>#""+(i+1)+""</td>"";rows_html+=""<td>"";if(threads_links===true){var url=""http://www.google.com/search?output=search&q=X&btnI=1"";if(Report.getThreadsSite()!==undefined){url=""http://www.google.com/search?output=search&q=X%20site%3AY&btnI=1"";url=url.replace(/Y/g,Report.getThreadsSite())}else if(threads_data.hasOwnProperty(""url"")&&threads_data.url[i].length>0){url=""http://www.google.com/search?output=search&q=X%20site%3AY&btnI=1"";url=url.replace(/Y/g,threads_data.url[i])}url=url.replace(/X/g,threads_data.subject[i]);rows_html+=""<td>"";rows_html+='<a target=""_blank"" href=""'+url+'"">';rows_html+=threads_data.subject[i]+""</a>"";rows_html+='&nbsp;<i class=""fa fa-external-link""></i></td>'}else{rows_html+=""<td>""+threads_data.subject[i]+""</td>""}rows_html+=""<td>""+threads_data.initiator_name[i]+""</td>"";rows_html+=""<td>""+threads_data.length[i]+""</td>"";rows_html+=""</tr>""}return rows_html}function composeTopRowsPeople(people_data,limit,people_links,var_names){var rows_html="""";for(var j=0;j<people_data[var_names.id].length;j++){if(limit&&limit<=j)break;var metric_value=people_data[var_names.action][j];rows_html+=""<tr><td>""+(j+1)+""</td>"";rows_html+=""<td>"";if(people_links){rows_html+='<a href=""people.html?id='+people_data[var_names.id][j];get_params=Utils.paramsInURL();if(get_params.length>0)rows_html+=""&""+get_params;rows_html+='"">';rows_html+=DataProcess.hideEmail(people_data[var_names.name][j])+""</a>""}else{rows_html+=DataProcess.hideEmail(people_data[var_names.name][j])}rows_html+=""</td>"";rows_html+=""<td>""+metric_value+""</td>"";if(people_data.organization!==undefined){org=people_data.organization[j];if(org===null){org=""-""}rows_html+=""<td>""+org+""</td>""}rows_html+=""</tr>""}return rows_html}function composeTopTabs(periods,metric,data,ds_name){var tabs_html="""";var first=true;tabs_html+='<ul id=""myTab"" class=""nav nav-tabs"">';for(var i=0;i<periods.length;i++){var mykey=metric+"".""+periods[i];if(data[mykey]){var data_period=periods[i];var data_period_formatted=data_period;if(data_period===""""){data_period=""all"";data_period_formatted=""Complete history""}else if(data_period===""last month""){data_period_formatted=""Last 30 days""}else if(data_period===""last year""){data_period_formatted=""Last 365 days""}var data_period_nows=data_period.replace(/\ /g,"""");var html="""";if(first===true){html=' class=""active""';first=false}tabs_html+=""<li""+html+'><a href=""#'+ds_name+metric+data_period_nows+'""data-toogle=""tab"">';tabs_html+=data_period_formatted+""</a></li>""}}tabs_html+=""</ul>"";return tabs_html}function composeTitle(metric,ds_name,tabs,desc_metrics,selected_period){var key=ds_name+""_""+metric;var desc="""";var title="""";if(key in desc_metrics){desc=desc_metrics[key].desc;desc=desc.toLowerCase()}if(selected_period===""""){data_period_formatted=""Complete history""}else if(selected_period===""last month""){data_period_formatted=""Last 30 days""}else if(selected_period===""last year""){data_period_formatted=""Last 365 days""}if(Utils.isReleasePage())data_period_formatted=""Release history"";if(tabs===true){title+=""<h6>Top ""+desc+""</h6>""}else{title+='<div class=""toptable-title"">'+data_period_formatted+""</div>""}return title}String.prototype.capitalize=function(){return this.replace(/(?:^|\s)\S/g,function(a){return a.toUpperCase()})};function displayTopMetric(div_id,metric,metric_period,history,graph,titles,limit,people_links){var top_metric_id=metric.name;if(!history||$.isEmptyObject(history))return;var metric_id=metric.action;if(limit&&history[metric_id].length<limit){limit=history[metric_id].length;graph=false}var doer=metric.column;if(doer===undefined)doer=findMetricDoer(history,metric_id);var title=""Top ""+top_metric_id+"" ""+metric_period;var div=null;if(table===undefined)return;if(titles===false){div=$(""#""+div_id);div.append(table);return}var div_graph="""";var new_div="""";if(graph){div_graph=""top-""+graph+""-""+doer+""-"";div_graph+=metric_id+""-""+metric_period;new_div+=""<div id='""+div_graph+""' class='graph' style='float:right'></div>""}new_div+=table;div=$(""#""+div_id);div.append(new_div);if(graph){var labels=history[doer];var data=history[metric_id];if(limit){labels=[];data=[];for(var i=0;i<limit;i++){labels.push(history[doer][i]);data.push(history[metric_id][i])}}displayBasicChart(div_graph,labels,data,graph)}}function displayDataSourcesTable(div){dsources=Report.getDataSources();html='<table class=""table table-striped"">';html+=""<thead><th>Data Source</th><th>From</th>"";html+=""<th>To <small>(Updated on)</small></th></thead><tbody>"";$.each(dsources,function(key,ds){if(ds.getName()===""people"")return;var gdata=ds.getGlobalData();var ds_name=ds.getTitle();if(ds_name===undefined){ds_name=""-""}var last_date=gdata.last_date;if(last_date===undefined){return}var first_date=gdata.first_date;if(first_date===undefined){first_date=""-""}var type=gdata.type;html+=""<tr><td>""+ds_name;if(type!==undefined){type=type.toLowerCase();type=type.charAt(0).toUpperCase()+type.slice(1);html+="" (""+type+"")""}html+=""</td>"";html+=""<td>""+first_date+""</td>"";html+=""<td>""+last_date+""</td></tr>""});html+=""</tbody></table>"";$(div).append(html)}function showHelp(div_id,metrics,custom_help){var all_metrics=Report.getAllMetrics();var help='<a href=""#"" class=""help""';var content="""";if(custom_help===""""){var addContent=function(id,value){if(metrics[i]===id){content+=""<strong>""+value.name+""</strong>: ""+value.desc+""<br>"";return false}};for(var i=0;i<metrics.length;i++){$.each(all_metrics,addContent)}}else{content=""<strong>Description</strong>: ""+custom_help}help+='data-content=""'+content+'"" data-html=""true"">';help+='<img src=""qm_15.png""></a>';var old_help=$(""#""+div_id).prev()[0];if(old_help&&old_help.className===""help"")$(""#""+div_id).prev().empty();$(""#""+div_id).before(help)}function displayMetricsLines(div_id,metrics,history,title,config){if(!(config&&config.help===false))showHelp(div_id,metrics,config.custom_help);var lines_data=[];if(config.remove_last_point)history=DataProcess.revomeLastPoint(history);if(config.frame_time)history=DataProcess.frameTime(history,metrics);if(config.start_time)history=DataProcess.filterDates(config.start_time,config.end_time,history);$.each(metrics,function(id,metric){if(!history[metric])return;var mdata=[];$.each(history[metric],function(i,value){mdata[i]=[history.id[i],history[metric][i]]});var label=metric;if(Report.getAllMetrics()[metric])label=Report.getAllMetrics()[metric].name;lines_data.push({label:label,data:mdata})});displayDSLines(div_id,history,lines_data,title,config)}function displayMetricsLinesRepos(div_id,metrics,history,title,config,repositories){if(!(config&&config.help===false))showHelp(div_id,metrics,config.custom_help);var lines_data=[];var metric=metrics[0];var aux={};$.each(history,function(item,data){if(data===undefined)return false;if(data[metric]===undefined)return false;if(config.remove_last_point)data=DataProcess.revomeLastPoint(data);if(config.frame_time)data=DataProcess.frameTime(data,[metric]);if(config.start_time)data=DataProcess.filterDates(config.start_time,config.end_time,data);var mdata=[[],[]];$.each(data[metric],function(i,value){mdata[i]=[data.id[i],data[metric][i]]});lines_data.push({label:item,data:mdata});aux=data});displayDSLines(div_id,aux,lines_data,title,config)}function displayMetricSubReportLines(div_id,metric,items,title,config,start,end,convert,order){var lines_data=[];var history={};$.each(items,function(item,data){if(data===undefined)return false;if(data[metric]===undefined)return false;if(convert)data=DataProcess.convert(data,convert,metric);if(start)data=DataProcess.filterDates(start,end,data);if(config.frame_time)data=DataProcess.frameTime(data,[metric]);var cdata=[[],[]];for(var i=0;i<data.id.length;i++){cdata[i]=[data.id[i],data[metric][i]]}item=Report.cleanLabel(item);lines_data.push({label:item,data:cdata});history=data});if(lines_data.length===0)return;if(order){var order_lines_data=[];$.each(order,function(i,value_order){$.each(lines_data,function(j,value){if(value_order===value.label){order_lines_data.push(value);return false}})});lines_data=order_lines_data}displayDSLines(div_id,history,lines_data,title,config)}Viz.track_formatter_com_pending=function(o){scr=Report.getDataSourceByName(""scr"");companies=scr.getCompaniesMetricsData();dhistory=Viz._history;lines_data=Viz._lines_data;var label=dhistory.date[parseInt(o.index,10)];if(label===undefined)label="""";else label+=""<br>"";for(var i=0;i<lines_data.length;i++){var value=lines_data[i].data[o.index][1];if(value===undefined)continue;if(lines_data.length>1){if(lines_data[i].label!==undefined)company_name=lines_data[i].label;label+=lines_data[i].label+"":""}label+=""<strong>""+Report.formatValue(value)+""</strong>"";if(company_name){var pending;if(companies[company_name].pending!==undefined){pending=companies[company_name].pending[o.index]}else{pending=companies[company_name].scr_pending[o.index]}label+=""(""+pending+"")""}label+=""<br>""}return label};function getConfLinesChart(title,legend_div,history,lines_data,mouse_tracker_fn){var config={subtitle:title,legend:{show:true,container:legend_div},xaxis:{minorTickFreq:4,mode:""time"",timeUnit:""second"",timeFormat:""%b %y"",margin:true},yaxis:{min:null,noTicks:2,autoscale:true},grid:{verticalLines:false,color:""#000000"",outlineWidth:1,outline:""s""},mouse:{container:legend_div,track:true,trackY:false,relative:true,position:""ne"",trackFormatter:function(o){var label=history.date[parseInt(o.index,10)];if(label===undefined)label="""";else label+=""<br>"";for(var i=0;i<lines_data.length;i++){var value=lines_data[i].data[o.index][1];if(value===undefined)continue;if(lines_data.length>1){if(lines_data[i].label!==undefined){value_name=abbreviateLabel(lines_data[i].label);label+=value_name+"":""}}label+=""<strong>""+Report.formatValue(value)+""</strong><br>""}return label}},selection:{mode:""x"",fps:10},shadowSize:4};if(mouse_tracker_fn){Viz._history=history;Viz._lines_data=lines_data;config.mouse.trackFormatter=Viz[mouse_tracker_fn]}return config}function dropLastLineValue(history,lines_data){if(lines_data.length===0)return lines_data;if(lines_data.length>1){for(var j=0;j<lines_data.length;j++){var last=lines_data[j].data.length-1;lines_data[j].data[last][1]=undefined}}}function lastLineValueToPoint(history,lines_data){if(lines_data.length!==1)return lines_data;var last=lines_data[0].data.length;var dots=[];var utime=0;for(var i=0;i<last-1;i++){utime=parseInt(history.unixtime[i],10);dots.push([utime,undefined])}utime=parseInt(history.unixtime[last-1],10);dots.push([utime,lines_data[0].data[last-1][1]]);var dot_graph={data:dots};dot_graph.points={show:true,radius:3,lineWidth:1,fillColor:null,shadowSize:0};lines_data.push(dot_graph);lines_data[0].data[last-1][1]=undefined;lines_data[1].label=lines_data[0].label;return lines_data}function composeRangeText(former_title,starting_utime,end_utime){var months=[""Jan"",""Feb"",""Mar"",""Apr"",""May"",""Jun"",""Jul"",""Aug"",""Sep"",""Oct"",""Nov"",""Dec""];var date=new Date(parseInt(starting_utime,10)*1e3);var starting_date=months[date.getMonth()]+"" ""+date.getFullYear();date=new Date(parseInt(end_utime,10)*1e3);var end_date=months[date.getMonth()]+"" ""+date.getFullYear();return former_title+"" ( ""+starting_date+"" - ""+end_date+"" )""}function sortBiArray(bi_array){bi_array.sort(function(a,b){return a[1]>b[1]||b[1]===undefined?1:-1});return bi_array}function getMax(multiple_array,from_unixstamp,to_unixstamp){from_unixstamp=Math.round(from_unixstamp);to_unixstamp=Math.round(to_unixstamp);var narrays=multiple_array.length;var aux_array=[];for(var i=0;i<narrays;i++){for(var z=multiple_array[i].data.length-1;z>0;z--){var aux_value=multiple_array[i].data[z][0];var cond=aux_value<from_unixstamp||aux_value>to_unixstamp;if(cond){multiple_array[i].data.splice(z,1)}}}var res=[];for(i=0;i<narrays;i++){aux_array=multiple_array[i].data;aux_array=sortBiArray(aux_array);res.push(aux_array[aux_array.length-1][1])}res.sort(function(a,b){return a-b});return res[res.length-1]}function addEmptyValue(lines_data){if(lines_data[0].data.length==1){return}var step=lines_data[0].data[1][0]-lines_data[0].data[0][0];var narrays=lines_data.length;var last_date=0;for(var i=0;i<narrays;i++){var mylength=lines_data[i].data.length;last_date=lines_data[i].data[mylength-1][0];lines_data[i].data.push([last_date+step,undefined])}return lines_data}function displayDSLines(div_id,history,lines_data,title,config_metric){var use_stacked=false;if(config_metric){if(config_metric.lines&&config_metric.lines.stacked){use_stacked=true}}if(use_stacked){displayDSLinesStacked(div_id,history,lines_data,title,config_metric)}else if(history.unixtime===undefined){displayDSLinesStacked(div_id,history,lines_data,title,config_metric)}else{displayDSLinesZoom(div_id,history,lines_data,title,config_metric)}}function abbreviateLabel(string){if(string.length>=18){var l=string.length;return""..""+string.slice(string.length-16)}else{return string}}function displayDSLinesStacked(div_id,history,lines_data,title,config_metric){var container=document.getElementById(div_id);var legend_div=null;if(config_metric&&config_metric.legend&&config_metric.legend.container)legend_div=$(""#""+config_metric.legend.container);var config={subtitle:title,legend:{show:true,container:legend_div},xaxis:{minorTickFreq:4,tickFormatter:function(x){var index=null;for(var i=0;i<history.id.length;i++){if(parseInt(x,10)===history.id[i]){index=i;break}}return history.date[index]}},yaxis:{min:0,noTicks:2,autoscale:false},grid:{verticalLines:false,color:""#000000"",outlineWidth:1,outline:""s""},mouse:{container:legend_div,track:true,trackY:false,trackFormatter:function(o){var label=history.date[parseInt(o.index,10)];if(label===undefined)label="""";else label+=""<br>"";for(var i=0;i<lines_data.length;i++){var value=lines_data[i].data[o.index][1];if(value===undefined)continue;if(lines_data.length>1){if(lines_data[i].label!==undefined)label+=abbreviateLabel(lines_data[i].label)+"":""}label+=Report.formatValue(value)+""<br>""}return label}}};if(config_metric){if(!config_metric.show_title)config.title="""";if(""show_legend""in config_metric){if(config_metric.show_legend===true)config.legend.show=true;else config.legend.show=false}if(config_metric.lines&&config_metric.lines.stacked)config.lines={stacked:true,fill:true,fillOpacity:1,fillBorder:true,lineWidth:.01};if(!config_metric.show_labels){config.xaxis.showLabels=false;config.yaxis.showLabels=false}if(config_metric.show_grid===false){config.grid.verticalLines=false;config.grid.horizontalLines=false;config.grid.outlineWidth=0}if(config_metric.show_mouse===false){config.mouse.track=false}if(config_metric.graph===""bars""){config.bars={show:true}}if(config_metric.light_style===true){config.grid.color=""#ccc"";config.legend.show=false}if(config_metric.custom_title){config.subtitle=config_metric.custom_title}}var showLastPoint=false;if(config_metric.graph!==""bars""&&lines_data.length===1&&lines_data[0].data[0][0]===0){showLastPoint=true}if(showLastPoint){lines_data=lastLineValueToPoint(history,lines_data);var next_id=history.id[history.id.length-1]+1;lines_data[0].data.push([next_id,undefined]);lines_data[1].data.push([next_id,undefined]);history.date.push("""");history.id.push(next_id)}graph=Flotr.draw(container,lines_data,config);if(showLastPoint){if(history.date)history.date.pop();if(history.id)history.id.pop()}}function guessBarWidth(lines_data,history){var gap_size;var data_sets=lines_data.length;gap_size=parseInt(history.unixtime[1],10)-parseInt(history.unixtime[0],10);return gap_size/(data_sets+1)}function timeToUnixTime(lines_data,history,bars_flag,bar_width){var number_lines=lines_data.length;var data_length=lines_data[0].data.length;for(var z=0;z<number_lines;z++){for(var i=0;i<data_length;i++){if(bars_flag){lines_data[z].data[i][0]=parseInt(history.unixtime[i],10)+z*bar_width}else{lines_data[z].data[i][0]=parseInt(history.unixtime[i],10)}}}return lines_data}function displayDSLinesZoom(div_id,history,lines_data,title,config_metric){var bars_flag=false;var bar_width;if(lines_data.length===0)return;var container=document.getElementById(div_id);var legend_div=null;if(config_metric&&config_metric.legend&&config_metric.legend.container)legend_div=$(""#""+config_metric.legend.container);var config=getConfLinesChart(title,legend_div,history,lines_data,config_metric.mouse_tracker);if(config_metric){if(!config_metric.show_title)config.title="""";if(""show_legend""in config_metric){if(config_metric.show_legend===true)config.legend.show=true;else config.legend.show=false}if(config_metric.lines&&config_metric.lines.stacked){config.lines={stacked:true,fill:true,fillOpacity:1,fillBorder:true,lineWidth:.01}}if(!config_metric.show_labels){config.xaxis.showLabels=false;config.yaxis.showLabels=false}if(config_metric.show_grid===false){config.grid.verticalLines=false;config.grid.horizontalLines=false;config.grid.outlineWidth=0}if(config_metric.show_mouse===false){config.mouse.track=false}if(config_metric.graph===""bars""){config.bars={show:true,stacked:false,horizontal:false,barWidth:728e3,lineWidth:1};config.bars.barWidth=guessBarWidth(lines_data,history);bars_flag=true;bar_width=config.bars.barWidth}if(config_metric.light_style===true){config.grid.color=""#ccc"";config.legend.show=false}if(config_metric.custom_title){config.subtitle=config_metric.custom_title}config.mouse.position=""n"";config.mouse.margin=20}if(lines_data.length>1)config.legend.show=true;lines_data=timeToUnixTime(lines_data,history,bars_flag,bar_width);var showLastPoint=false;if(Utils.isReleasePage()===false){if(config_metric.graph!==""bars""&&lines_data.length===1){showLastPoint=true}if(showLastPoint){lines_data=lastLineValueToPoint(history,lines_data);addEmptyValue(lines_data)}else if(!showLastPoint&&lines_data.length>1){dropLastLineValue(history,lines_data)}}function drawGraph(opts){var o=Flotr._.extend(Flotr._.clone(config),opts||{});return Flotr.draw(container,lines_data,o)}graph=drawGraph();Flotr.EventAdapter.observe(container,""flotr:select"",function(area){var zoom_options={xaxis:{minorTickFreq:4,mode:""time"",timeUnit:""second"",timeFormat:""%b %y"",min:area.x1,max:area.x2},yaxis:{min:area.y1,autoscale:true},grid:{verticalLines:true,color:""#000000"",outlineWidth:1,outline:""s""}};zoom_options.subtitle=composeRangeText(config.subtitle,area.xfirst,area.xsecond);var new_lines_data_object=JSON.parse(JSON.stringify(lines_data));var max_value=getMax(new_lines_data_object,area.x1,area.x2);zoom_options.yaxis.max=max_value+max_value*.2;graph=drawGraph(zoom_options)});Flotr.EventAdapter.observe(container,""flotr:click"",function(){drawGraph()});$(window).resize(function(){drawGraph()})}function displayTimeZone(divid,labels,data,metric_name){var pretty_mname=metric_name.charAt(0).toUpperCase()+metric_name.slice(1);var title=pretty_mname+"" by Time Zone"";var container=document.getElementById(divid);var chart_data=[],i;var legend_div=null;for(i=0;i<data.length;i++){chart_data.push({data:[[labels[i],data[i]]],label:i})}var config={subtitle:title,grid:{verticalLines:false,outlineWidth:0,horizontalLines:true},xaxis:{tickFormatter:function(value){var label=""UTC "";if(value>0)label+=""+""+value;else label+=value;return label},color:""#000000"",tickDecimals:0},yaxis:{showLabels:true,min:0,noTicks:2,color:""#000000""},mouse:{track:true,trackY:false,relative:true,position:""n"",trackDecimals:0,trackFormatter:function(tuple){var label=""UTC "";if(tuple.x>0)label+=""+""+tuple.x;else label+=tuple.x;pretty_name=metric_name.charAt(0).toUpperCase()+metric_name.slice(1);label+=""<br/> ""+pretty_name+"": <strong>""+tuple.y+""</strong>"";return label}},legend:{show:false},bars:{show:true,color:""#008080"",fillColor:""#008080"",fillOpacity:.6}};graph=Flotr.draw(container,chart_data,config);$(window).resize(function(){graph=Flotr.draw(container,chart_data,config)})}function displayBasicChart(divid,labels,data,graph,title,config_metric,rotate,fixColor,yformatter){var horizontal=false;if(rotate)horizontal=true;var container=document.getElementById(divid);var legend_div=null;if(config_metric&&config_metric.legend&&config_metric.legend.container)legend_div=$(""#""+config_metric.legend.container);var chart_data=[],i;var label="""";if(!horizontal){for(i=0;i<data.length;i++){if(labels)label=DataProcess.hideEmail(labels[i]);chart_data.push({data:[[i,data[i]]],label:label})}}else{for(i=0;i<data.length;i++){if(labels)label=DataProcess.hideEmail(labels[i]);chart_data.push({data:[[data[i],i]],label:label})}}var config={subtitle:title,grid:{verticalLines:false,horizontalLines:false,outlineWidth:0},xaxis:{showLabels:false,min:0},yaxis:{showLabels:false,min:0},mouse:{container:legend_div,track:true,trackFormatter:function(o){var i=""x"";if(horizontal)i=""y"";var label="""";if(labels)label=DataProcess.hideEmail(labels[parseInt(o[i],10)])+"": "";return label+data[parseInt(o[i],10)]}},legend:{show:false,position:""se"",backgroundColor:""#D2E8FF"",container:legend_div}};if(config_metric){if(!config_metric.show_title)config.title="""";if(config_metric.show_legend)config.legend.show=true}if(graph===""bars""){config.bars={show:true,horizontal:horizontal};if(fixColor){config.bars.color=fixColor;config.bars.fillColor=fixColor}if(config_metric&&config_metric.show_legend!==false)config.legend={show:true,position:""ne"",container:legend_div};config.grid.horizontalLines=true;config.yaxis={showLabels:true,min:0};if(config_metric&&config_metric.xaxis)config.xaxis={showLabels:config_metric.xaxis,min:0};if(yformatter){config.yaxis={showLabels:true,min:0,tickFormatter:yformatter}}}if(graph===""pie""){config.pie={show:true};config.mouse.position=""ne""}graph=Flotr.draw(container,chart_data,config)}function displayMultiColumnChart(divid,labels,data,title,config_metric,rotate,yformatter,period_year){var bar_width=.4;var lseries=data[0].length;if(data[1].length>lseries)lseries=data[1].length;var horizontal=false;if(rotate)horizontal=true;var container=document.getElementById(divid);var legend_div=null;if(config_metric&&config_metric.legend&&config_metric.legend.container)legend_div=$(""#""+config_metric.legend.container);var serie1=[],i,serie2=[],data_viz=[];for(i=0;i<lseries;i++){var val1,val2;if(data[0].length>i)val1=data[0][i];else val1=undefined;if(data[1].length>i)val2=data[1][i];else val2=undefined;if(!horizontal){serie1.push([i-bar_width/2,val1]);serie2.push([i+bar_width/2,val2])}else{serie1.push([val1,i-bar_width/2]);serie2.push([val2,i+bar_width/2])}}data_viz=[{data:serie1,label:labels[0]},{data:serie2,label:labels[1]}];var config={title:title,bars:{show:true,horizontal:horizontal,barWidth:bar_width},grid:{verticalLines:false,horizontalLines:false,outlineWidth:0},xaxis:{showLabels:false,min:0},yaxis:{showLabels:true,min:0},mouse:{container:legend_div,track:true,trackFormatter:function(o){var index; var i=""x"";if(horizontal)i=""y"";var point=parseFloat(o[i],1);var point_down=Math.round((point-.2)*10)/10;var point_up=Math.round((point+.2)*10)/10;if(point_down===parseInt(point,10))index=point_down;else index=point_up;var years=index;if(period_year)years=index*period_year;var label=years+"" years: "";var val1,val2;if(serie1[index]===undefined)val1=0;else val1=parseInt(serie1[index][0],10);if(isNaN(val1))val1=0;if(serie2[index]===undefined)val2=0;else val2=parseInt(serie2[index][0],10);if(isNaN(val2))val2=0;label+=val1+"" ""+labels[0];label+="" , "";label+=val2+"" ""+labels[1];label+="" (""+parseInt(val1/val2*100,10)+""% )"";return label}},legend:{show:true,position:""ne"",backgroundColor:""#D2E8FF"",container:legend_div}};if(config_metric){if(!config_metric.show_title)config.title="""";if(config_metric.show_legend)config.legend.show=true}if(config_metric&&config_metric.show_legend!==false)config.legend={show:true,position:""ne"",container:legend_div};config.grid.horizontalLines=true;config.yaxis={showLabels:true,min:0};if(yformatter){config.yaxis={showLabels:true,min:0,tickFormatter:yformatter}}if(config_metric&&config_metric.xaxis)config.xaxis={showLabels:config_metric.xaxis,min:0};graph=Flotr.draw(container,data_viz,config)}function displayBubbles(divid,metric1,metric2,radius){var container=document.getElementById(divid);var DS=Report.getMetricDS(metric1)[0];var DS1=Report.getMetricDS(metric2)[0];var bdata=[];if(DS!=DS1){Report.log(""Metrics for bubbles have different data sources"");return}var full_data=[];var projects=[];$.each(Report.getDataSources(),function(index,ds){if(ds.getName()===DS.getName()){full_data.push(ds.getData());projects.push(ds.getProject())}});var dates=[[],[]];dates=[full_data[0].id,full_data[0].date];for(var i=0;i<full_data.length;i++){if(full_data[i]instanceof Array)return;dates=DataProcess.fillDates(dates,[full_data[i].id,full_data[i].date])}for(var j=0;j<full_data.length;j++){var serie=[];var data=full_data[j];var data1=DataProcess.fillHistory(dates[0],[data.id,data[metric1]]);var data2=DataProcess.fillHistory(dates[0],[data.id,data[metric2]]);for(i=0;i<dates[0].length;i++){serie.push([dates[0][i],data1[1][i],data2[1][i]])}bdata.push({label:projects[j],data:serie})}var config={bubbles:{show:true,baseRadius:5},mouse:{track:true,trackFormatter:function(o){var value=full_data[0].date[o.index]+"": "";value+=o.series.label+"" "";value+=o.series.data[o.index][1]+"" ""+metric1+"","";value+=o.series.data[o.index][2]+"" ""+metric2;return value}},xaxis:{tickFormatter:function(o){return full_data[0].date[parseInt(o,10)-full_data[0].id[0]]}}};if(DS.getName()===""its"")$.extend(config.bubbles,{baseRadius:1});if(radius){$.extend(config.bubbles,{baseRadius:radius})}Flotr.draw(container,bdata,config)}function displayDemographicsChart(divid,data,period_year){if(!data)return;if(!period_year)period_year=.25;else period=365*period_year;var period_data_aging=[];var period_data_birth=[];var labels=[],i;var config={show_legend:false,xaxis:true};var age,index;for(i=0;i<data.aging.persons.age.length;i++){age=data.aging.persons.age[i];age=age.toString().split("" "")[0];index=parseInt(age/period,10);if(!period_data_aging[index])period_data_aging[index]=0;period_data_aging[index]+=1}for(i=0;i<data.birth.persons.age.length;i++){age=data.birth.persons.age[i];age=age.toString().split("" "")[0];age=age.split("" "")[0];index=parseInt(age/period,10);if(!period_data_birth[index])period_data_birth[index]=0;period_data_birth[index]+=1}labels=[""Retained"",""Attracted""];yticks=function(val,axisOpts){var period=period_year;var unit=""years"";val=val*period_year;return val+"" ""+unit};var period_data=[period_data_aging,period_data_birth];if(data)displayMultiColumnChart(divid,labels,period_data,"""",config,true,yticks,period_year)}function displayRadarChart(div_id,ticks,data){var container=document.getElementById(div_id);var max=$(""#""+div_id).data(""max"");var border=.2;if(!max)max=0;for(var j=0;j<data.length;j++){for(var i=0;i<data[j].data.length;i++){var value=data[j].data[i][1];if(value>max){max=value;max=parseInt(max*(1+border),10)}}}(function(){var x=[data,ticks]})();graph=Flotr.draw(container,data,{radar:{show:true},mouse:{track:true,trackFormatter:function(o){var value="""";for(var i=0;i<data.length;i++){value+=data[i].label+"" "";value+=data[i].data[o.index][1]+"" "";value+=ticks[o.index][1]+""<br>""}return value}},grid:{circular:true,minorHorizontalLines:true},yaxis:{min:0,max:max,minorTickFreq:1},xaxis:{ticks:ticks}})}function displayRadar(div_id,metrics){var data=[],ticks=[];var radar_data=[];var projects=[];var i=0,j=0;for(i=0;i<metrics.length;i++){var DS=Report.getMetricDS(metrics[i]);for(j=0;j<DS.length;j++){if(!data[j]){data[j]=[];projects[j]=DS[j].getProject()}data[j].push([i,parseInt(DS[j].getGlobalData()[metrics[i]],10)])}ticks.push([i,DS[0].getMetrics()[metrics[i]].name])}for(j=0;j<data.length;j++){radar_data.push({label:projects[j],data:data[j]})}displayRadarChart(div_id,ticks,radar_data)}function displayRadarCommunity(div_id){var metrics=[""scm_committers"",""scm_authors"",""its_openers"",""its_closers"",""its_changers"",""mls_senders""];displayRadar(div_id,metrics)}function displayRadarActivity(div_id){var metrics=[""scm_commits"",""scm_files"",""its_opened"",""its_closed"",""its_changed"",""mls_sent""];displayRadar(div_id,metrics)}function displayTimeToAttention(div_id,ttf_data,column,labels,title){displayTimeTo(div_id,ttf_data,column,labels,title)}function displayTimeToFix(div_id,ttf_data,column,labels,title){displayTimeTo(div_id,ttf_data,column,labels,title)}function displayTimeTo(div_id,ttf_data,column,labels,title){var metrics=column.split("","");var history=ttf_data.data;if(!history[metrics[0]])return;var new_history={};new_history.date=history.date;$.each(history,function(name,data){if($.inArray(name,metrics)===-1)return;new_history[name]=[];for(var i=0;i<data.length;i++){var hours=parseFloat((parseInt(data[i],null)/24).toFixed(2),10);new_history[name].push(hours)}});new_history.id=[];for(var i=0;i<history[metrics[0]].length;i++){new_history.id.push(i)}var config={show_legend:true,show_labels:true};displayMetricsLines(div_id,metrics,new_history,column,config)}function displayTop(div,ds,all,selected_metric,period,period_all,graph,titles,limit,people_links,threads_links,repository){var desc_metrics=ds.getMetrics();if(all===undefined)all=true;var history;if(repository===undefined){history=ds.getGlobalTopData()}else{history=ds.getRepositoriesTopData()[repository]}if(Utils.isReleasePage()){period_all=false;period=""""}if(period_all===true){var filtered_history={};$.each(history,function(key,value){var aux=key.split(""."");var data_metric=aux[0];var data_period=aux[1];if(selected_metric&&selected_metric!==data_metric){return true}if(selected_metric&&selected_metric===data_metric){filtered_history[key]=history[key]}});var classname=ds.getName()+selected_metric;var opts={metric:selected_metric,class_name:classname,links_enabled:people_links,limit:limit,period:""all"",ds_name:ds.getName(),desc_metrics:desc_metrics};Table.displayTopTable(div,filtered_history,opts)}else{$.each(history,function(key,value){var aux=key.split(""."");var data_metric=aux[0];var data_period=aux[1];if(selected_metric&&selected_metric!==data_metric)return true;if(period!==undefined&&period!==data_period)return true;var classname=ds.getName()+selected_metric;var opts={metric:selected_metric,class_name:classname,links_enabled:people_links,limit:limit,period:data_period,ds_name:ds.getName(),desc_metrics:desc_metrics};Table.displayTopTable(div,history,opts)})}}function displayTopCompany(ds,company,data,div,selected_metric,period,titles,height,people_links){var graph=null,limit=0,desc_metrics=ds.getMetrics();var classname=ds.getName()+selected_metric;var opts={metric:selected_metric,class_name:classname,links_enabled:people_links,limit:limit,period:period,ds_name:ds.getName(),desc_metrics:desc_metrics,height:height};Table.displayTopTable(div,data,opts)}function displayTopGlobal(div,data_source,metric_id,period,titles){var project=data_source.getProject();var metric=data_source.getMetrics()[metric_id];var graph=null;if(!data_source.getGlobalTopData()[metric_id])return;data=data_source.getGlobalTopData()[metric_id][period];displayTopMetric(div,project,metric,period,data,graph,titles)}function displayTreeMap(divid,data_file,data){if(data===undefined){if(data_file===undefined)return;Loader.get_file_data_div(data_file,Viz.displayTreeMap,divid);return}else if(data===null)return;var color=d3.scale.category20c();var div=d3.select(""#""+divid);var width=$(""#""+divid).width(),height=$(""#""+divid).height();var treemap=d3.layout.treemap().size([width,height]).sticky(true).value(function(d){return d.size});var position=function(){this.style(""left"",function(d){return d.x+""px""}).style(""top"",function(d){return d.y+""px""}).style(""width"",function(d){return Math.max(0,d.dx-1)+""px""}).style(""height"",function(d){return Math.max(0,d.dy-1)+""px""})};var node=div.datum(data).selectAll("".node"").data(treemap.nodes).enter().append(""div"").attr(""class"",""treemap-node"").call(position).style(""background"",function(d){return d.children?color(d.name):null}).text(function(d){return d.children?null:d.name});d3.selectAll(""input"").on(""change"",function change(){var value=this.value===""count""?function(){return 1}:function(d){return d.size};node.data(treemap.value(value).nodes).transition().duration(1500).call(position)})}Viz.getEnvisionOptionsMin=function(div_id,history,hide){var firstMonth=history.id[0],container=document.getElementById(div_id),options;var markers=Report.getMarkers();var basic_metrics=Report.getAllMetrics();options={container:container,xTickFormatter:function(index){var label=history.date[index-firstMonth];if(label===""0"")label="""";return label},yTickFormatter:function(n){return n+""""},selection:{data:{x:{min:history.id[0],max:history.id[history.id.length-1]}}}};options.data={summary:[history.id,history.sent],markers:markers,dates:history.date,envision_hide:hide,main_metric:""sent""};var all_metrics=Report.getAllMetrics();var label=null;for(var metric in history){label=metric;if(all_metrics[metric])label=all_metrics[metric].name;options.data[metric]=[{label:label,data:[history.id,history[metric]]}]}options.trackFormatter=function(o){var sdata=o.series.data,index=sdata[o.index][0]-firstMonth;var value=history.date[index]+"":<br>"";for(var metric in basic_metrics){if(history[metric]===undefined)continue;value+=history[metric][index]+"" ""+metric+"" , ""}return value};return options};function getEnvisionOptions(div_id,projects_data,ds_name,hide,summary_graph){var basic_metrics=null,main_metric="""",summary_data=[[],[]];if(ds_name){$.each(Report.getDataSources(),function(i,DS){if(DS.getName()===ds_name){basic_metrics=DS.getMetrics();return false}})}else basic_metrics=Report.getAllMetrics();$.each(Report.getDataSources(),function(i,DS){main_metric=DS.getMainMetric();if(ds_name===null&&DS.getName()===""scm""||ds_name&&DS.getName()==ds_name){summary_data=[DS.getData().id,DS.getData()[main_metric]];if(summary_graph===false)summary_data=[DS.getData().id,[]];return false}});var dates=[[],[]];$.each(projects_data,function(project,data){$.each(data,function(index,DS){if(ds_name&&ds_name!==DS.getName())return;dates=DataProcess.fillDates(dates,[DS.getData().id,DS.getData().date])})});var firstMonth=dates[0][0],container=document.getElementById(div_id),options;var markers=Report.getMarkers();options={container:container,xTickFormatter:function(index){var label=dates[1][index-firstMonth];if(label===""0"")label="""";return label},yTickFormatter:function(n){return n+""""},selection:{data:{x:{min:dates[0][0],max:dates[0][dates[0].length-1]}}}};options.data={summary:DataProcess.fillHistory(dates[0],summary_data),markers:markers,dates:dates[1],envision_hide:hide,main_metric:main_metric};var project=null;var buildProjectInfo=function(index,ds){var data=ds.getData();if(data[metric]===undefined)return;if(options.data[metric]===undefined)options.data[metric]=[];var full_data=DataProcess.fillHistory(dates[0],[data.id,data[metric]]);if(metric===main_metric){options.data[metric].push({label:project,data:full_data});if(data[metric+""_relative""]===undefined)return;if(options.data[metric+""_relative""]===undefined)options.data[metric+""_relative""]=[];full_data=DataProcess.fillHistory(dates[0],[data.id,data[metric+""_relative""]]);options.data[metric+""_relative""].push({label:project,data:full_data})}else{options.data[metric].push({label:project,data:full_data})}};var buildProjectsInfo=function(name,pdata){project=name;$.each(pdata,buildProjectInfo)};for(var metric in basic_metrics){$.each(projects_data,buildProjectsInfo)}options.trackFormatter=function(o){var sdata=o.series.data,index=sdata[o.index][0]-firstMonth;var project_metrics={};var projects=Report.getProjectsList();for(var j=0;j<projects.length;j++){project_metrics[projects[j]]={}}var value=dates[1][index]+"":<br>"";for(var metric in basic_metrics){if(options.data[metric]===undefined)continue;if($.inArray(metric,options.data.envision_hide)>-1)continue;for(j=0;j<projects.length;j++){if(options.data[metric][j]===undefined)continue;var project_name=options.data[metric][j].label;var pdata=options.data[metric][j].data;value=pdata[1][index];project_metrics[project_name][metric]=value}}value=""<table><tr><td align='right'>""+dates[1][index]+""</td></tr>"";value+=""<tr>"";if(projects.length>1)value+=""<td></td>"";for(metric in basic_metrics){if(options.data[metric]===undefined)continue;if($.inArray(metric,options.data.envision_hide)>-1)continue;value+=""<td>""+basic_metrics[metric].name+""</td>""}value+=""</tr>"";$.each(project_metrics,function(project,metrics){var row=""<tr>"";for(var metric in basic_metrics){if(options.data[metric]===undefined)continue;if($.inArray(metric,options.data.envision_hide)>-1)continue;mvalue=project_metrics[project][metric];if(mvalue===undefined)mvalue=""n/a"";row+=""<td>""+mvalue+""</td>""}if(projects.length>1)row=""<td>""+project+""</td>""+row;row+=""</tr>"";value+=row});value+=""</table>"";return value};return options}function checkBasicConfig(config){if(config===undefined)config={};if(config.show_desc===undefined)config.show_desc=true;if(config.show_title===undefined)config.show_title=true;if(config.show_labels===undefined)config.show_labels=true;return config}function getMetricFriendlyName(ds,metrics){var desc_metrics=ds.getMetrics();var title="""";for(var i=0;i<metrics.length;i++){if(i!==0){title+="" vs. ""}if(metrics[i]in desc_metrics)title+=desc_metrics[metrics[i]].name;else title+=metrics[i]}return title}function displayMetricsEvol(ds,metrics,data,div_target,config,repositories){config=checkBasicConfig(config);var title="""";if(config.show_title){if(config.title===undefined){title=getMetricFriendlyName(ds,metrics)}else{title=config.title}}if(repositories!==undefined){displayMetricsLinesRepos(div_target,metrics,data,title,config)}else{displayMetricsLines(div_target,metrics,data,title,config)}}function displayMetricsCompany(ds,company,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricsRepo(ds,repo,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricsDomain(ds,domain,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricsProject(ds,project,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricsPeople(ds,upeople_identifier,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricRepos(metric,data,div_target,config,start,end){config=checkBasicConfig(config);if(config.show_legend!==false)config.show_legend=true;var title=metric;displayMetricSubReportLines(div_target,metric,data,title,config,start,end)}function displayMetricsCountry(ds,country,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricCompanies(metric,data,div_target,config,start,end,order){config=checkBasicConfig(config);if(config.show_legend!==false)config.show_legend=true;var title=metric;displayMetricSubReportLines(div_target,metric,data,title,config,start,end,null,order)}function displayMetricDomains(metric,data,div_target,config,start,end){config=checkBasicConfig(config);if(config.show_legend!==false)config.show_legend=true;var title=metric;displayMetricSubReportLines(div_target,metric,data,title,config,start,end)}function displayMetricProjects(metric,data,div_target,config,start,end){config=checkBasicConfig(config);if(config.show_legend!==false)config.show_legend=true;var title=metric;displayMetricSubReportLines(div_target,metric,data,title,config,start,end)}function displayMetricSubReportStatic(metric,data,order,div_id,config){config=checkBasicConfig(config);var title="""";if(config.title===undefined)title=metric;else title=config.title;var metric_data=[];var labels=[];var graph=""bars"";if(config.graph)graph=config.graph;$.each(order,function(i,name){var label=Report.cleanLabel(name);labels.push(label);metric_data.push(data[name][metric])});displayBasicChart(div_id,labels,metric_data,graph,title,config)}function displayEnvisionAll(div_id,relative,legend_show,summary_graph){var projects_full_data=Report.getProjectsDataSources();var config=Report.getVizConfig();var options=Viz.getEnvisionOptions(div_id,projects_full_data,null,config.summary_hide,summary_graph);options.legend_show=legend_show;if(relative){$.each(projects_full_data,function(project,data){$.each(data,function(index,DS){main_metric=DS.getMainMetric()})});DataProcess.addRelativeValues(options.data,main_metric)}new envision.templates.Envision_Report(options)}})();function IRC(){var self=this;this.basic_metrics={irc_sent:{divid:""irc_sent"",column:""sent"",name:""Sent"",desc:""Messages sent""},irc_senders:{divid:""irc_senders"",column:""senders"",name:""Senders"",desc:""Messages senders"",action:""sent""},irc_repositories:{divid:""irc_repositories"",column:""repositories"",name:""Repositories"",desc:""Number of active repositories""}};this.getMainMetric=function(){return""irc_sent""};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End""};return id_label};this.getLabelForRepository=function(){return""channel""};this.getLabelForRepositories=function(){return""channels""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .irc_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().irc_url}if(this.global_data.type)$(div_id+"" #irc_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #irc_url"").attr(""href"",url);$(div_id+"" #irc_name"").text(""IRC ""+this.global_data.type)}else{$(div_id+"" #irc_url"").attr(""href"",Report.getProjectData().irc_url);$(div_id+"" #irc_name"").text(Report.getProjectData().irc_name);$(div_id+"" #irc_type"").text(Report.getProjectData().irc_type)}var data=this.getGlobalData();$(div_id+"" #ircFirst"").text(data.first_date);$(div_id+"" #ircLast"").text(data.last_date);$(div_id+"" #ircSent"").text(data.irc_sent);$(div_id+"" #ircRepositories"").text(data.irc_repositories);if(data.repositories===1)$(div_id+"" #ircRepositories"").hide()};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""irc_sent"",""irc_senders"",radius)};this.getTitle=function(){return""IRC Messages""}}IRC.prototype=new DataSource(""irc"");function ITS(){this.basic_metrics={its_opened:{divid:""its_opened"",column:""opened"",name:""Opened"",desc:""Number of opened tickets"",envision:{y_labels:true,show_markers:true}},its_openers:{divid:""its_openers"",column:""openers"",name:""Openers"",desc:""Unique identities opening tickets"",action:""opened"",envision:{gtype:""whiskers""}},its_closed:{divid:""its_closed"",column:""closed"",name:""Closed"",desc:""Number of closed tickets""},its_closers:{divid:""its_closers"",column:""closers"",name:""Closers"",desc:""Number of identities closing tickets"",action:""closed"",envision:{gtype:""whiskers""}},its_bmitickets:{divid:""its_bmitickets"",column:""bmitickets"",name:""Efficiency"",desc:""Efficiency closing tickets: number of closed ticket out of the opened ones in a given period""},its_changed:{divid:""its_changed"",column:""changed"",name:""Changed"",desc:""Number of changes to the state of tickets""},its_changers:{divid:""its_changers"",column:""changers"",name:""Changers"",desc:""Number of identities changing the state of tickets"",action:""changed"",envision:{gtype:""whiskers""}},its_companies:{divid:""its_companies"",column:""companies"",name:""Companies"",desc:""Number of active companies""},its_organizations:{divid:""its_organizations"",column:""companies"",name:""Companies"",desc:""Number of active companies""},its_countries:{divid:""its_countries"",column:""countries"",name:""Countries"",desc:""Number of active countries""},its_repositories:{divid:""its_repositories"",column:""repositories"",name:""Respositories"",desc:""Number of active respositories""},its_domains:{divid:""its_domains"",column:""domains"",name:""Domains"",desc:""Number of active domains""}};this.getMainMetric=function(){return""its_opened""};this.getSummaryLabels=function(){var labels={first_date:""Start"",last_date:""End"",tickets:""Tickets"",trackers:""Trackers""};return labels};this.getLabelForRepository=function(){return""tracker""};this.getLabelForRepositories=function(){return""trackers""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .its-info"").hide();return}$(div_id+"" #its_type"").text(this.global_data.type);var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().its_url}if(url===undefined)url="""";if(this.global_data.type===""allura"")url=url.replace(""rest/"","""");else if(this.global_data.type===""github""){url=url.replace(""api."","""");url=url.replace(""repos/"","""")}$(div_id+"" #its_url"").attr(""href"",url);var tracker_str=this.global_data.type.charAt(0).toUpperCase()+this.global_data.type.slice(1);$(div_id+"" #its_name"").text(tracker_str+"" Tickets"");var data=this.getGlobalData();$(div_id+"" #itsFirst"").text(data.first_date);$(div_id+"" #itsLast"").text(data.last_date);$(div_id+"" #itsTickets"").text(data.its_opened);$(div_id+"" #itsOpeners"").text(data.its_openers);$(div_id+"" #itsRepositories"").text(data.its_repositories);if(data.repositories===1)$(div_id+"" #itsRepositories"").hide()};this.getTitle=function(){return""Tickets""};this.displayBubbles=function(divid,radius){Viz.displayBubbles(divid,""its_opened"",""its_openers"",radius)}}ITS.prototype=new DataSource(""its"");function ITS_1(){this.basic_metrics={its_1_opened:{divid:""its_1_opened"",column:""opened"",name:""Opened tickets"",desc:""Number of opened tickets"",envision:{y_labels:true,show_markers:true}},its_1_openers:{divid:""its_1_openers"",column:""openers"",name:""Openers"",desc:""Unique identities opening tickets"",action:""opened"",envision:{gtype:""whiskers""}},its_1_stories_opened:{divid:""its_1_stories_opened"",column:""stories_opened"",name:""Stories Opened"",desc:""Number of opened stories""},its_1_stories_openers:{divid:""its_1_stories_openers"",column:""stories_openers"",name:""Stories Openers"",desc:""Unique identities opening stories"",action:""opened""},its_1_closed:{divid:""its_1_closed"",column:""closed"",name:""Closed tickets"",desc:""Number of closed tickets""},its_1_closers:{divid:""its_1_closers"",column:""closers"",name:""Closers"",desc:""Number of identities closing tickets"",action:""closed"",envision:{gtype:""whiskers""}},its_1_stories_closed:{divid:""its_1_stories_closed"",column:""stories_closed"",name:""Closed stories"",desc:""Number of closed stories""},its_1_stories_pending:{divid:""its_1_stories_pending"",column:""stories_pending"",name:""Pending stories"",desc:""Number of pending stories""},its_1_bmitickets:{divid:""its_1_bmitickets"",column:""bmitickets"",name:""Efficiency"",desc:""Efficiency closing tickets: number of closed ticket out of the opened ones in a given period""},its_1_changed:{divid:""its_1_changed"",column:""changed"",name:""Changed"",desc:""Number of changes to the state of tickets""},its_1_changers:{divid:""its_1_changers"",column:""changers"",name:""Changers"",desc:""Number of identities changing the state of tickets"",action:""changed"",envision:{gtype:""whiskers""}},its_1_companies:{divid:""its_1_companies"",column:""companies"",name:""Companies"",desc:""Number of active companies""},its_1_countries:{divid:""its_1_countries"",column:""countries"",name:""Countries"",desc:""Number of active countries""},its_1_repositories:{divid:""its_1_repositories"",column:""repositories"",name:""Respositories"",desc:""Number of active respositories""},its_1_domains:{divid:""its_1_domains"",column:""domains"",name:""Domains"",desc:""Number of active domains""}};this.getMainMetric=function(){return""its_1_opened""};this.getSummaryLabels=function(){var labels={first_date:""Start"",last_date:""End"",tickets:""Tickets"",trackers:""Trackers""};return labels};this.getLabelForRepository=function(){return""tracker""};this.getLabelForRepositories=function(){return""trackers""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .its-info"").hide();return}$(div_id+"" #its_type"").text(this.global_data.type);var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().its_url}if(url===undefined)url="""";if(this.global_data.type===""allura"")url=url.replace(""rest/"","""");else if(this.global_data.type===""github""){url=url.replace(""api."","""");url=url.replace(""repos/"","""")}$(div_id+"" #its_url"").attr(""href"",url);var tracker_str=this.global_data.type.charAt(0).toUpperCase()+this.global_data.type.slice(1);$(div_id+"" #its_name"").text(tracker_str+"" Tickets"");var data=this.getGlobalData();$(div_id+"" #itsFirst"").text(data.first_date);$(div_id+"" #itsLast"").text(data.last_date);$(div_id+"" #itsTickets"").text(data.its_1_opened);$(div_id+"" #itsOpeners"").text(data.its_1_openers);$(div_id+"" #itsRepositories"").text(data.its_1_repositories);if(data.repositories===1)$(div_id+"" #itsRepositories"").hide()};this.getTitle=function(){return""Tickets""};this.displayBubbles=function(divid,radius){Viz.displayBubbles(divid,""its_1_opened"",""its_1_openers"",radius)}}ITS_1.prototype=new DataSource(""its_1"");function MediaWiki(){var self=this;this.basic_metrics={mediawiki_reviews:{divid:""mediawiki_reviews"",column:""reviews"",name:""Editions"",desc:""Wiki page editions""},mediawiki_authors:{divid:""mediawiki_authors"",column:""authors"",name:""Editors"",desc:""Editors doing editions"",action:""reviews""},mediawiki_pages:{divid:""mediawiki_pages"",column:""pages"",name:""Pages"",desc:""Wiki pages""}};this.getMainMetric=function(){return""mediawiki_reviews""};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End""};return id_label};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .mediawiki_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().mediawiki_url}if(this.global_data.type)$(div_id+"" #mediawiki_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #mediawiki_url"").attr(""href"",url);$(div_id+"" #mediawiki_name"").text(""MediaWiki ""+this.global_data.type)}else{$(div_id+"" #mediawiki_url"").attr(""href"",Report.getProjectData().mediawiki_url);$(div_id+"" #mediawiki_name"").text(Report.getProjectData().mediawiki_name);$(div_id+"" #mediawiki_type"").text(Report.getProjectData().mediawiki_type)}var data=this.getGlobalData();$(div_id+"" #mediawikiFirst"").text(data.first_date);$(div_id+"" #mediawikiLast"").text(data.last_date);$(div_id+"" #mediawikiSent"").text(data.mediawiki_reviews)};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""mediawiki_reviews"",""mediawiki_authors"",radius)};this.getTitle=function(){return""MediaWiki Reviews""}}MediaWiki.prototype=new DataSource(""mediawiki"");function MLS(){var self=this;this.basic_metrics={mls_responses:{divid:""mls_responses"",column:""responses"",name:""Responses"",desc:""Number of messages that are responses""},mls_sent:{divid:""mls_sent"",column:""sent"",name:""Sent"",desc:""Number of messages""},mls_senders:{divid:""mls_senders"",column:""senders"",name:""Senders"",desc:""Number of unique message senders"",action:""sent""},mls_threads:{divid:""mls_threads"",column:""threads"",name:""Threads"",desc:""Number of messages threads""},mls_companies:{divid:""mls_companies"",column:""companies"",name:""Companies"",desc:""Number of active companies""},mls_organizations:{divid:""mls_organizations"",column:""companies"",name:""Companies"",desc:""Number of active companies""},mls_countries:{divid:""mls_countries"",column:""countries"",name:""Countries"",desc:""Number of active countries""},mls_repositories:{divid:""mls_repositories"",column:""repositories"",name:""Respositories"",desc:""Number of active respositories""},mls_domains:{divid:""mls_domains"",column:""domains"",name:""Domains"",desc:""Number of active domains""},unanswered_posts:{name:""Unanswered Threads"",desc:""Unanswered Threads""}};this.data_lists_file=this.data_dir+""/mls-lists.json"";this.getListsFile=function(){return this.data_lists_file};this.data_lists=null;this.getListsData=function(){return this.data_lists};this.setListsData=function(lists,self){if(self===undefined)self=this;self.data_lists=lists};this.setDataDir=function(dataDir){this.data_dir=dataDir;this.data_lists_file=this.data_dir+""/mls-lists.json"";MLS.prototype.setDataDir.call(this,dataDir)};this.getMainMetric=function(){return""mls_sent""};this.getSummaryLabels=function(){var labels={first_date:""Start"",last_date:""End""};return labels};this.getLabelForRepository=function(){return""mailing list""};this.getLabelForRepositories=function(){return""mailing lists""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .mls_info"").hide()}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().mls_url}if(this.global_data.type)$(div_id+"" #mls_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #mls_url"").attr(""href"",url);$(div_id+"" #mls_name"").text(""MLS ""+this.global_data.type)}else{$(div_id+"" #mls_url"").attr(""href"",Report.getProjectData().mls_url);$(div_id+"" #mls_name"").text(Report.getProjectData().mls_name);$(div_id+"" #mls_type"").text(Report.getProjectData().mls_type)}var data=this.getGlobalData();$(div_id+"" #mlsFirst"").text(data.first_date);$(div_id+"" #mlsLast"").text(data.last_date);$(div_id+"" #mlsMessages"").text(data.mls_sent);$(div_id+"" #mlsSenders"").text(data.mls_senders);$(div_id+"" #mlsRepositories"").text(data.mls_repositories);if(data.repositories===1)$(div_id+"" #mlsRepositories"").hide()};this.displayBubbles=function(divid,radius){Viz.displayBubbles(divid,""mls_sent"",""mls_senders"",radius)};MLS.displayMLSListName=function(listinfo){var list_name_tokens=listinfo.split(""_"");var list_name="""";if(list_name_tokens.length>1){list_name=list_name_tokens[list_name_tokens.length-1];if(list_name==="""")list_name=list_name_tokens[list_name_tokens.length-2]}else{list_name=listinfo.replace(""<"","""");list_name=list_name.replace("">"","""");list_name_tokens=list_name.split(""."");list_name=list_name_tokens[0]}return list_name};function getUserLists(){var form=document.getElementById(""form_mls_selector"");var lists=[];for(var i=0;i<form.elements.length;i++){if(form.elements[i].checked)lists.push(form.elements[i].value)}if(localStorage){localStorage.setItem(getMLSId(),JSON.stringify(lists))}return lists}this.displayBasicUserAll=function(id,all){var form=document.getElementById(""form_mls_selector"");for(var i=0;i<form.elements.length;i++){if(form.elements[i].type==""checkbox"")form.elements[i].checked=all }this.displayBasicUser(id)};this.displayBasicUser=function(div_id){$(""#""+div_id).empty();lists=getUserLists();for(var i=0;i<lists.length;i++){var l=lists[i];file_messages=this.getDataDir()+""/mls-"";file_messages+=l;file_messages+=""-evolutionary.json"";displayBasicList(div_id,l,file_messages)}};this.displayBasic=function(div_id,config_metric){var lists=this.getListsData();lists_hide=Report.getConfig().mls_hide_lists;lists=lists.mailing_list;if(lists===undefined)return null;var user_pref=false;if(typeof lists===""string"")lists=[lists];if(localStorage){if(localStorage.length&&localStorage.getItem(getMLSId())){lists=JSON.parse(localStorage.getItem(getMLSId()));user_pref=true}}for(var i=0;i<lists.length;i++){var l=lists[i];if(!user_pref)if($.inArray(l,lists_hide)>-1)continue;file_messages=this.getDataDir()+""/mls-"";file_messages+=l;file_messages+=""-evolutionary.json"";displayBasicList(div_id,l,file_messages,config_metric)}};this.getTitle=function(){return""Mailing Lists""};function displayBasicList(div_id,l,mls_file,config_metric){var config=Viz.checkBasicConfig(config_metric);for(var id in basic_metrics){var metric=basic_metrics[id];var title="""";if(config.show_title)title=metric.name;if($.inArray(metric.column,Report.getConfig().mls_hide)>-1)continue;var new_div=""<div class='info-pill m0-box-div flotr2-""+metric.column+""'>"";new_div+=""<h4>""+metric.name+"" ""+MLS.displayMLSListName(l)+""</h4>"";new_div+=""<div id='""+metric.divid+""_""+l+""' class='m0-box flotr2-""+metric.column+""'></div>"";if(config.show_desc)new_div+=""<p>""+metric.desc+""</p>"";new_div+=""</div>"";$(""#""+div_id).append(new_div);Viz.displayBasicLinesFile(metric.divid+""_""+l,mls_file,metric.column,config.show_labels,title)}}function getReportId(){var project_data=Report.getProjectData();return project_data.date+""_""+project_data.project_name}function getMLSId(){return getReportId()+""_mls_lists""}this.displayEvoListsMain=function(id){if(localStorage){if(localStorage.length&&localStorage.getItem(getMLSId())){lists=JSON.parse(localStorage.getItem(getMLSId()));return this.displayEvoLists(id,lists)}}history=this.getListsData();lists=history.mailing_list;if(lists===undefined)return;var config=Report.getConfig();lists_hide=config.mls_hide_lists;if(typeof lists===""string""){lists=[lists]}var filtered_lists=[];for(var i=0;i<lists.length;i++){if($.inArray(lists[i],lists_hide)==-1)filtered_lists.push(lists[i])}if(localStorage){if(!localStorage.getItem(getMLSId())){localStorage.setItem(getMLSId(),JSON.stringify(filtered_lists))}}this.displayEvoLists(id,filtered_lists)};function cleanLocalStorage(){if(localStorage){if(localStorage.length&&localStorage.getItem(getMLSId())){localStorage.removeItem(getMLSId())}}}this.getDefaultLists=function(){var default_lists=[];var hide_lists=Report.getConfig().mls_hide_lists;$.each(this.getListsData().mailing_list,function(index,list){if($.inArray(list,hide_lists)===-1)default_lists.push(list)});return default_lists};this.displaySelectorCheckDefault=function(){var default_lists=this.getDefaultLists();var form=document.getElementById(""form_mls_selector"");for(var i=0;i<form.elements.length;i++){if(form.elements[i].type==""checkbox""){var id=form.elements[i].id;l=id.split(""_check"")[0];if($.inArray(l,default_lists)>-1)form.elements[i].checked=true;else form.elements[i].checked=false}}};this.displayBasicDefault=function(div_id){var obj=self;if(this instanceof MLS)obj=this;cleanLocalStorage();obj.displaySelectorCheckDefault();$(""#""+div_id).empty();obj.displayBasic(div_id)};this.displayEvoDefault=function(div_id){var obj=self;if(this instanceof MLS)obj=this;cleanLocalStorage();if(document.getElementById(""form_mls_selector""))obj.displaySelectorCheckDefault();$(""#""+div_id).empty();obj.displayEvoLists(div_id,obj.getDefaultLists())};this.displayEvoUserAll=function(id,all){var form=document.getElementById(""form_mls_selector"");for(var i=0;i<form.elements.length;i++){if(form.elements[i].type==""checkbox"")form.elements[i].checked=all}this.displayEvoUser(id)};this.displayEvoUser=function(id){$(""#""+id).empty();var obj=self;if(this instanceof MLS)obj=this;obj.displayEvoLists(id,getUserLists())};this.displayEvoListSelector=function(div_id_sel,div_id_mls){this.displayEvoBasicListSelector(div_id_sel,div_id_mls,null)};this.displayBasicListSelector=function(div_id_sel,div_id_mls){this.displayEvoBasicListSelector(div_id_sel,null,div_id_mls)};this.displayEvoBasicListSelector=function(div_id_sel,div_id_evo,div_id_basic){var res1=this.getListsData();var lists=res1.mailing_list;var user_lists=[];if(lists===undefined)return;if(localStorage){if(localStorage.length&&localStorage.getItem(getMLSId())){user_lists=JSON.parse(localStorage.getItem(getMLSId()))}}Report.displayBasicUser=this.displayBasicUser;Report.displayBasicUserAll=this.displayBasicUserAll;Report.displayBasicDefault=this.displayBasicDefault;Report.displayEvoDefault=this.displayEvoDefault;Report.displayEvoUser=this.displayEvoUser;Report.displayEvoUserAll=this.displayEvoUserAll;var html=""Mailing list selector:"";html+=""<form id='form_mls_selector'>"";if(typeof lists===""string""){lists=[lists]}for(var i=0;i<lists.length;i++){var l=lists[i];html+='<input type=checkbox name=""check_list"" value=""'+l+'"" ';html+='onClick=""';if(div_id_evo)html+=""Report.displayEvoUser('""+div_id_evo+""');"";if(div_id_basic)html+=""Report.displayBasicUser('""+div_id_basic+""')\"";"";html+='"" ';html+='id=""'+l+'_check"" ';if($.inArray(l,user_lists)>-1)html+=""checked "";html+="">"";html+=MLS.displayMLSListName(l);html+=""<br>""}html+='<input type=button value=""All"" ';html+='onClick=""';if(div_id_evo)html+=""Report.displayEvoUserAll('""+div_id_evo+""',true);"";if(div_id_basic)html+=""Report.displayBasicUserAll('""+div_id_basic+""',true);"";html+='"">';html+='<input type=button value=""None"" ';html+='onClick=""';if(div_id_evo)html+=""Report.displayEvoUserAll('""+div_id_evo+""',false);"";if(div_id_basic)html+=""Report.displayBasicUserAll('""+div_id_basic+""',false);"";html+='"">';html+='<input type=button value=""Default"" ';html+='onClick=""';if(div_id_evo)html+=""Report.displayEvoDefault('""+div_id_evo+""');"";if(div_id_basic)html+=""Report.displayBasicDefault('""+div_id_basic+""')"";html+='"">';html+=""</form>"";$(""#""+div_id_sel).html(html);if(Report.getProjectsList().length>1){$(""#""+div_id_sel).append(""Not supported in multiproject"");$(""#""+div_id_sel+"" :input"").attr(""disabled"",true)}};function filterHistory(history){if(typeof history.id===""number""){$.each(history,function(key,value){value=[value]})}return history}this.displayEvoLists=function(id,lists){for(var i=0;i<lists.length;i++){var l=lists[i];file_messages=this.getDataDir()+""/mls-"";file_messages+=l;file_messages+=""-evolutionary.json"";this.displayEvoList(MLS.displayMLSListName(l),id,file_messages)}};this.displayEvoList=function(list_label,id,mls_file){var self=this;$.getJSON(mls_file,function(history){self.envisionEvoList(list_label,id,history)})};this.envisionEvoList=function(list_label,div_id,history){var config=Report.getConfig();var options=Viz.getEnvisionOptionsMin(div_id,history,config.mls_hide);options.data.list_label=MLS.displayMLSListName(list_label);new envision.templates.Envision_Report(options,[this])}}MLS.prototype=new DataSource(""mls"");function SCM(){this.basic_metrics={scm_commits:{divid:""scm_commits"",column:""commits"",name:""Commits"",desc:""Evolution of the number of commits (aggregating branches)"",envision:{y_labels:true,show_markers:true}},scm_committers:{divid:""scm_committers"",column:""committers"",name:""Committers"",desc:""Unique committers making changes to the source code"",action:""commits"",envision:{gtype:""whiskers""}},scm_authors:{divid:""scm_authors"",column:""authors"",name:""Authors"",desc:""Unique authors making changes to the source code"",action:""commits"",envision:{gtype:""whiskers""}},scm_newauthors:{divid:""scm_newauthors"",column:""newauthors"",name:""New Authors"",desc:""Number of new people authoring commits (changes to source code)"",action:""commits"",envision:{gtype:""whiskers""}},scm_branches:{divid:""scm_branches"",column:""branches"",name:""Branches"",desc:""Evolution of the number of branches""},scm_files:{divid:""scm_files"",column:""files"",name:""Modified Files"",desc:""Evolution of the number of unique files handled by the community""},scm_added_lines:{divid:""scm_added_lines"",column:""added_lines"",name:""Lines Added"",desc:""Evolution of the source code lines added""},scm_removed_lines:{divid:""scm_removed_lines"",column:""removed_lines"",name:""Lines Removed"",desc:""Evolution of the source code lines removed""},scm_repositories:{divid:""scm_repositories"",column:""repositories"",name:""Repositories"",desc:""Evolution of the number of repositories"",envision:{gtype:""whiskers""}},scm_companies:{divid:""scm_companies"",column:""companies"",name:""Companies"",desc:""Number of active companies""},scm_organizations:{divid:""scm_organizations"",column:""companies"",name:""Companies"",desc:""Number of active companies""},scm_countries:{divid:""scm_countries"",column:""countries"",name:""Countries"",desc:""Number of active countries""},scm_domains:{divid:""scm_domains"",column:""domains"",name:""Domains"",desc:""Number of active domains""}};this.getMainMetric=function(){return""scm_commits""};this.setITS=function(its){this.its=its};this.getITS=function(its){return this.its};this.getTitle=function(){return""Source Code Management""};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End""};return id_label};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .scm-info"").hide();return}var repo_str=this.global_data.type.charAt(0).toUpperCase()+this.global_data.type.slice(1);$(div_id+"" #scm_type"").text(repo_str);var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().scm_url}if(this.global_data.type===""git"")if(url)url=url.replace(""git://"",""http://"");$(div_id+"" #scm_url"").attr(""href"",url);$(div_id+"" #scm_name"").text(repo_str);var data=this.getGlobalData();$(div_id+"" #scmFirst"").text(data.first_date);$(div_id+"" #scmLast"").text(data.last_date);$(div_id+"" #scmCommits"").text(data.scm_commits);$(div_id+"" #scmAuthors"").text(data.scm_authors);if(data.reviewers)$(div_id+"" #scmReviewers"").text(data.scm_reviewers);$(div_id+"" #scmCommitters"").text(data.scm_committers);$(div_id+"" #scmRepositories"").text(data.scm_repositories);if(data.repositories===1)$(div_id+"" #scmRepositories"").hide()};this.displayBubbles=function(divid,radius){Viz.displayBubbles(divid,""scm_commits"",""scm_committers"",radius)}}SCM.prototype=new DataSource(""scm"");function SCR(){var self=this;this.basic_metrics={scr_opened:{divid:""scr_opened"",column:""opened"",name:""Reviews opened"",desc:""Reviews in status new or inprogress""},scr_submissions:{divid:""scr_submissions"",column:""submissions"",name:""Reviews submitted"",desc:""Reviews submitted""},scr_closed:{divid:""scr_closed"",column:""closed"",name:""Reviews closed"",desc:""Reviews merged or abandoned""},scr_merged:{divid:""scr_merged"",column:""merged"",name:""Reviews merged"",desc:""Reviews merged""},scr_mergers:{divid:""scr_mergers"",column:""mergers"",name:""Reviews mergers"",action:""merged"",desc:""People merging reviews""},scr_new:{divid:""scr_new"",column:""new"",name:""Reviews new"",desc:""Reviews in status new""},scr_abandoned:{divid:""scr_abandoned"",column:""abandoned"",name:""Reviews abandoned"",desc:""Reviews abandoned""},scr_pending:{divid:""scr_pending"",column:""pending"",name:""Reviews pending"",desc:""Reviews pending to be attended""},scr_review_time_days_avg:{divid:""scr_review_time_days_avg"",column:""review_time_days_avg"",name:""Average review time"",desc:""Average review time in days""},scr_verified:{divid:""scr_verified"",column:""verified"",name:""Patches verified"",desc:""Patches verified""},scr_approved:{divid:""scr_approved"",column:""approved"",name:""Patches approved"",desc:""Patches approved""},scr_codereview:{divid:""scr_codereview"",column:""codereview"",name:""Patches codereview"",desc:""Patches in code review process""},scr_WaitingForReviewer:{divid:""scr_WaitingForReviewer"",column:""WaitingForReviewer"",name:""Patches waiting reviewer"",desc:""Patches waiting for reviewer""},scr_WaitingForSubmitter:{divid:""scr_WaitingForSubmitter"",column:""WaitingForSubmitter"",name:""Patches waiting submitter"",desc:""Patches waiting for a new version""},scr_submitted:{divid:""scr_submitted"",column:""submitted"",name:""Reviews submitted"",desc:""Reviews submitted""},scr_submitters:{divid:""scr_submitters"",column:""submitters"",name:""Reviews submitters"",desc:""Number of people submitting review processes.""},scr_sent:{divid:""scr_sent"",column:""sent"",name:""Patches Sent"",desc:""Patches sent""},scr_companies:{divid:""scr_companies"",column:""companies"",name:""Companies"",desc:""Number of active companies""},scr_organizations:{divid:""scr_organizations"",column:""companies"",name:""Companies"",desc:""Number of active companies""},scr_countries:{divid:""scr_countries"",column:""countries"",name:""Countries"",desc:""Number of active countries""},scr_repositories:{divid:""scr_repositories"",column:""repositories"",name:""Respositories"",desc:""Number of active respositories""},scr_closers:{divid:""scr_closers"",column:""closers"",name:""Closers"",desc:""Reviews closers"",action:""closed""},scr_submitters:{divid:""scr_submitters"",column:""openers"",name:""Submitters"",desc:""Reviews submitters"",action:""opened""},scr_reviewers:{divid:""scr_reviewers"",column:""reviewers"",name:""Reviewers"",desc:""Number of people reviewing contributions""},scr_timeto_merge_avg:{divid:""scr_timeto_merge_avg"",column:""timeto_merge_avg"",name:""Time to merge (average days)"",desc:""Number of average days a contribution waits to be merged""},scr_timeto_merge_median:{divid:""scr_timeto_merge_median"",column:""timeto_merge_median"",name:""Time to merge (median of the days)"",desc:""Median of the number of days a contribution waits to be merged""},scr_timeto_close_avg:{divid:""scr_timeto_close_avg"",column:""timeto_close_avg"",name:""Time to close (average days)"",desc:""Number of average days a contribution waits to be closed""},scr_timeto_close_median:{divid:""scr_timeto_close_median"",column:""timeto_close_median"",name:""Time to close (median of the days)"",desc:""Median of the number of days a contribution waits to be closed""},scr_participants:{divid:""scr_participants"",column:""participants"",name:""Participants"",desc:""Number of participants in the review process"",action:""events""},scr_active_core_reviewers:{divid:""scr_active_core_reviewers"",column:""active_core_reviewers"",name:""Active core reviewers"",desc:""Number of active core reviewers"",action:""reviews""}};this.getMainMetric=function(){return""scr_merged""};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End"",review_time_pending_ReviewsWaitingForReviewer_days_avg:""Review Time for reviewers (days, avg)"",review_time_pending_ReviewsWaitingForReviewer_days_median:""Review Time for reviewers (days, median)"",review_time_pending_update_ReviewsWaitingForReviewer_days_avg:""Update time for reviewers (days, avg)"",review_time_pending_update_ReviewsWaitingForReviewer_days_median:""Update time for reviewers (days, avg)"",review_time_pending_days_avg:""Review time (days, avg)"",review_time_pending_days_median:""Review time (days, median)"",review_time_pending_update_days_avg:""Update time (days, avg)"",review_time_pending_update_days_median:""Update time (days, median)""};return id_label};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .scr_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().scr_url}if(this.global_data.type)$(div_id+"" #scr_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #scr_url"").attr(""href"",url);$(div_id+"" #scr_name"").text(""SCR ""+this.global_data.type)}else{$(div_id+"" #scr_url"").attr(""href"",Report.getProjectData().mls_url);$(div_id+"" #scr_name"").text(Report.getProjectData().scr_name);$(div_id+"" #scr_type"").text(Report.getProjectData().scr_type)}var company=this.getCompanyQuery();var data=this.getGlobalData();if(company){data=this.getCompaniesGlobalData()[company]}$(div_id+"" #scrFirst"").text(data.first_date);$(div_id+"" #scrLast"").text(data.last_date);$(div_id+"" #scrReviews"").text(data.scr_opened)};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""scr_opened"",""scr_openers"",radius)};SCR.displaySCRListName=function(listinfo){var list_name_tokens=listinfo.split(""_"");var list_name="""";if(list_name_tokens.length>1){list_name=list_name_tokens[list_name_tokens.length-1];if(list_name==="""")list_name=list_name_tokens[list_name_tokens.length-2]}else{list_name=listinfo.replace(""<"","""");list_name=list_name.replace("">"","""");list_name_tokens=list_name.split(""."");list_name=list_name_tokens[0]}return list_name};this.getTitle=function(){return""Source Code Review""}}SCR.prototype=new DataSource(""scr"");function People(){this.basic_metrics={people_members:{column:""members"",name:""Members"",desc:""Community Members""}};this.getMainMetric=function(){return""people_members""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .mediawiki_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().mediawiki_url}if(this.global_data.type)$(div_id+"" #mediawiki_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #mediawiki_url"").attr(""href"",url);$(div_id+"" #mediawiki_name"").text(""MediaWiki ""+this.global_data.type)}else{$(div_id+"" #mediawiki_url"").attr(""href"",Report.getProjectData().mediawiki_url);$(div_id+"" #mediawiki_name"").text(Report.getProjectData().mediawiki_name);$(div_id+"" #mediawiki_type"").text(Report.getProjectData().mediawiki_type)}var data=this.getGlobalData();$(div_id+"" #mediawikiFirst"").text(data.first_date);$(div_id+"" #mediawikiLast"").text(data.last_date);$(div_id+"" #mediawikiSent"").text(data.mediawiki_reviews)};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""mediawiki_reviews"",""mediawiki_authors"",radius)};this.getTitle=function(){return""Community Members""}}People.prototype=new DataSource(""people"");function Downloads(){var self=this;this.basic_metrics={downloads_downloads:{name:""Total downloads"",column:""downloads""},downloads_packages:{divid:"""",column:""packages"",name:""Packages downloaded"",desc:"""",action:""downloads""},downloads_ips:{divid:"""",column:""ips"",name:""IP addresses"",desc:"""",action:""downloads""}};this.getMainMetric=function(){return""downloads_downloads""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .irc_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().irc_url}if(this.global_data.type)$(div_id+"" #irc_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #irc_url"").attr(""href"",url);$(div_id+"" #irc_name"").text(""IRC ""+this.global_data.type)}else{$(div_id+"" #irc_url"").attr(""href"",Report.getProjectData().irc_url);$(div_id+"" #irc_name"").text(Report.getProjectData().irc_name);$(div_id+"" #irc_type"").text(Report.getProjectData().irc_type)}var data=this.getGlobalData();$(div_id+"" #ircFirst"").text(data.first_date);$(div_id+"" #ircLast"").text(data.last_date);$(div_id+"" #ircSent"").text(data.irc_sent);$(div_id+"" #ircRepositories"").text(data.irc_repositories);if(data.repositories===1)$(div_id+"" #ircRepositories"").hide()};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""mediawiki_reviews"",""mediawiki_authors"",radius)};this.getTitle=function(){return""Downloads""}}Downloads.prototype=new DataSource(""downloads"");function QAForums(){var self=this;this.basic_metrics={qaforums_sent:{name:""Messages posted"",desc:""Number of messages posted to Q&A forums(s)"",column:""sent""},qaforums_qsent:{name:""Questions posted"",desc:""Number of questions posted to Q&A forums(s)"",column:""qsent""},qaforums_asent:{name:""Answers posted"",desc:""Number of answers posted to Q&A forums(s)"",column:""asent""},qaforums_unanswered:{name:""Unanswered questions"",desc:""Backlog of unanswered questions"",column:""unanswered""},qaforums_senders:{name:""Persons posting messages"",desc:""Number of persons posting messages to Q&A forums(s)"",column:""senders""},qaforums_asenders:{name:""Persons posting answers"",desc:""Number of persons answering in Q&A forums(s)"",column:""asenders""},qaforums_qsenders:{divid:""qaforums_qsenders"",name:""Persons posting questions"",desc:""Number of persons asking questions in Q&A forums(s)"",column:""qsenders""},qaforums_participants:{name:""Participants"",desc:""Number of persons posting messages"",column:""participants""}};this.getMainMetric=function(){return""qaforums_qsent""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .irc_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().irc_url}if(this.global_data.type)$(div_id+"" #irc_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #irc_url"").attr(""href"",url);$(div_id+"" #irc_name"").text(""IRC ""+this.global_data.type)}else{$(div_id+"" #irc_url"").attr(""href"",Report.getProjectData().irc_url);$(div_id+"" #irc_name"").text(Report.getProjectData().irc_name);$(div_id+"" #irc_type"").text(Report.getProjectData().irc_type)}var data=this.getGlobalData();$(div_id+"" #ircFirst"").text(data.first_date);$(div_id+"" #ircLast"").text(data.last_date);$(div_id+"" #ircSent"").text(data.irc_sent);$(div_id+"" #ircRepositories"").text(data.irc_repositories);if(data.repositories===1)$(div_id+"" #ircRepositories"").hide()};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""qaforums_quetions"",""qaforums_authors"",radius)};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End"",sent:""Messages posted"",qsent:""Questions posted"",asent:""Answers posted"",qunanswered:""Unanswered questions"",senders:""Persons posting messages"",asenders:""Persons posting answers"",qsenders:""Persons posting questions""};return id_label};this.getTitle=function(){return""QAForums""}}QAForums.prototype=new DataSource(""qaforums"");function Releases(){var self=this;this.basic_metrics={releases_modules:{name:""Modules created"",desc:""Number of modules created on the forge"",column:""modules""},releases_authors:{name:""Module authors"",desc:""Module authors"",column:""authors""},releases_releases:{name:""Number of module releases"",desc:""Number of module releases"",column:""releases""}};this.getMainMetric=function(){return""releases_modules""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .irc_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().irc_url}if(this.global_data.type)$(div_id+"" #irc_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #irc_url"").attr(""href"",url);$(div_id+"" #irc_name"").text(""IRC ""+this.global_data.type)}else{$(div_id+"" #irc_url"").attr(""href"",Report.getProjectData().irc_url);$(div_id+"" #irc_name"").text(Report.getProjectData().irc_name);$(div_id+"" #irc_type"").text(Report.getProjectData().irc_type)}var data=this.getGlobalData();$(div_id+"" #ircFirst"").text(data.first_date);$(div_id+"" #ircLast"").text(data.last_date);$(div_id+"" #ircSent"").text(data.irc_sent);$(div_id+"" #ircRepositories"").text(data.irc_repositories);if(data.repositories===1)$(div_id+"" #ircRepositories"").hide()};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""releases_modules"",""releases_releases"",radius)};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End"",modules:""Modules created"",releases:""Module releases created"",authors:""Persons creating/updating modules""};return id_label};this.getTitle=function(){return""Releases""}}Releases.prototype=new DataSource(""releases"");function Meetup(){var self=this;this.events={};this.basic_metrics={meetup_events:{divid:""meetup_events"",action:""attendees"",column:""opened"",name:""Meetup events"",desc:""Meetup events""},meetup_attendees:{divid:""meetup_attendees"",column:""attendees"",name:""Meetup attendees"",desc:""Meetup attendees""},meetup_cities:{name:""city"",action:""events"",desc:""Cities where events took place""},meetup_groups:{name:""group"",action:""events"",desc:""Meetup groups""}};this.getMainMetric=function(){return""meetup_events""};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End""};return id_label};this.displayData=function(divid){return""""};this.getTitle=function(){return""Meeetup events""};this.displayTopMultiColumn=function(div,headers,columns){loadMeetupEventsData(function(data){Table.simpleTable(div,data,headers,columns)})};function buildLink(data){if(data.hasOwnProperty(""event_name"")&&data.hasOwnProperty(""event_id"")&&data.hasOwnProperty(""group_id"")){$.each(data.event_name,function(id,value){data.event_name[id]='<a href=""http://www.meetup.com/'+data.group_id[id]+""/events/""+data.event_id[id]+'"">'+data.event_name[id]+""</a>""})}return data}function loadMeetupEventsData(cb){var json_file=""data/json/meetup-events.json"";$.when($.getJSON(json_file)).done(function(json_data){this.events=json_data;this.events=buildLink(this.events);cb(this.events)}).fail(function(){console.log(""Meetup events disabled. Missing ""+json_file)})}}Meetup.prototype=new DataSource(""meetup"");var Identity={};(function(){var unique_list=""unique-sortable"";function sortSelList(list_divid,list,name){var connect="""";if(list_divid===unique_list)connect="""";else connect=unique_list;$(""#""+name).sortable({handle:"".handle"",connectWith:""#""+connect,start:function(e,info){info.item.siblings("".ui-selected"").appendTo(info.item)},stop:function(e,info){if(info.item.parent()[0].id===unique_list)info.item.find("".handle"").remove();info.item.parent().append(info.item.find(""li""));info.item.parent().find(""li"").addClass(""mjs-nestedSortable-leaf"")}}).selectable().find(""li"").prepend(""<div class='handle'></div>"")}Identity.showListNested=function(list_divid,ds){list=""<ol id=""+unique_list+' class=""nested_sortable"" ';list+='style=""padding: 5px; background: #eee;""></ol>';$(""#""+list_divid).append(list);$(""#""+unique_list).nestedSortable({forcePlaceholderSize:true,handle:""div"",helper:""clone"",items:""li"",tolerance:""pointer"",toleranceElement:""> div"",maxLevels:2,isTree:true,expandOnHover:700,startCollapsed:true});$("".disclose"").on(""click"",function(){$(this).closest(""li"").toggleClass(""mjs-nestedSortable-collapsed"").toggleClass(""mjs-nestedSortable-expanded"")})};function showFilter(ds,filter_data){$(""#""+ds.getName()+""filter"").autocomplete({source:filter_data,select:function(event,ui){$(""#""+ds.getName()+""filter"").val("""");$(""#""+ds.getName()+""_people_""+ui.item.value).addClass(""ui-selected"");return false}})}Identity.showList=function(list_divid,ds){var list="""";var people=ds.getPeopleData();var filter_data=[];list='<ol id=""'+ds.getName()+'-sortable"" class=""sortable"">';for(var i=0;i<people.id.length;i++){var value=people.id[i];if(typeof value===""string""){value=value.replace(""@"",""_at_"").replace(""."",""_"")}filter_data.push({value:value,label:people.name[i]});list+='<li id=""'+ds.getName()+""_people_""+value+'"" ';list+='class=""ui-widget-content ui-selectee"">';list+='<div><span class=""disclose""><span></span></span>';list+=people.id[i]+"" ""+people.name[i];list+=""</div></li>""}list+=""</ol>"";$(""#""+list_divid).append(""<input id='""+ds.getName()+""filter'>"");showFilter(ds,filter_data);$(""#""+list_divid).append(list);sortSelList(list_divid,list,ds.getName()+""-sortable"")}})();var Charts={};(function(){Charts.plotLinesChart=plotLinesChart;function plotLinesChart(div_id,line_names,raw_data){var flt_data=buildFlotrData(line_names,raw_data);var config=getChartConfig(flt_data,raw_data.strdate);if(raw_data.max){config.yaxis.max=raw_data.max}if(flt_data.length>1)config.legend.show=true;config.subtitle=composeTitle(line_names);flt_data=decorateLines(flt_data);plotFlotr2LinesChart(div_id,flt_data,config)}function buildFlotrData(line_names,raw_data){var aux=[];$.each(raw_data.lines_data,function(id,array){var line=[];$.each(array,function(subid,value){line[line.length]=[raw_data.unixtime[subid],value]});var aux2={};aux2.data=line;aux2.label=line_names[id];aux[aux.length]=aux2});return aux}function decorateLines(flotr2_data){if(Utils.isReleasePage()===false){if(flotr2_data.length===1){flotr2_data=lastLineValueToPoint(flotr2_data);flotr2_data=addEmptyValue(flotr2_data)}else if(flotr2_data.length>1){flotr2_data=dropLastLineValue(flotr2_data)}}return flotr2_data}function lastLineValueToPoint(flotr2_data){if(flotr2_data.length!==1)return flotr2_data;var last=flotr2_data[0].data.length;var dots=[];var utime=0;for(var i=0;i<last-1;i++){utime=parseInt(flotr2_data[0].data[i][0],10);dots.push([utime,undefined])}utime=parseInt(flotr2_data[0].data[last-1][0],10);dots.push([utime,flotr2_data[0].data[last-1][1]]);var dot_graph={data:dots};dot_graph.points={show:true,radius:3,lineWidth:1,fillColor:null,shadowSize:0};flotr2_data.push(dot_graph);flotr2_data[0].data[last-1][1]=undefined;flotr2_data[1].label=flotr2_data[0].label;return flotr2_data}function composeTitle(unit_names){return unit_names.join("" & "")}function addEmptyValue(flotr2_data){var second=parseInt(flotr2_data[0].data[1][0],10);var first=parseInt(flotr2_data[0].data[0][0],10);var step=second-first;var narrays=flotr2_data.length;var last_date=0;for(var i=0;i<narrays;i++){var last=flotr2_data[i].data.length-1;last_date=parseInt(flotr2_data[i].data[last][0],10);flotr2_data[i].data.push([last_date+step,undefined])}return flotr2_data}function dropLastLineValue(flotr2_data){if(flotr2_data.length===0)return flotr2_data;if(flotr2_data.length>1){for(var j=0;j<flotr2_data.length;j++){var last=flotr2_data[j].data.length-1;flotr2_data[j].data[last][1]=undefined}}return flotr2_data}function plotFlotr2LinesChart(div_id,flotr2_data,config){if(flotr2_data.length===0)return;var container=document.getElementById(div_id);function drawGraph(opts){var o=Flotr._.extend(Flotr._.clone(config),opts||{});return Flotr.draw(container,flotr2_data,o)}graph=drawGraph();Flotr.EventAdapter.observe(container,""flotr:select"",function(area){var zoom_options={xaxis:{minorTickFreq:4,mode:""time"",timeUnit:""second"",timeFormat:""%b %y"",min:area.x1,max:area.x2},yaxis:{min:area.y1,autoscale:true},grid:{verticalLines:true,color:""#000000"",outlineWidth:1,outline:""s""}};zoom_options.subtitle=composeRangeText(config.subtitle,area.xfirst,area.xsecond);var new_lines_data_object=JSON.parse(JSON.stringify(flotr2_data));var y_max_value=getMax(new_lines_data_object,area.x1,area.x2);zoom_options.yaxis.max=y_max_value+y_max_value*.2;graph=drawGraph(zoom_options)});Flotr.EventAdapter.observe(container,""flotr:click"",function(){drawGraph()});$(window).resize(function(){drawGraph()})}function getChartConfig(flotr2_data,strdates,title){var legend_div=null;var config={subtitle:title,legend:{show:false,container:legend_div},xaxis:{minorTickFreq:4,mode:""time"",timeUnit:""second"",timeFormat:""%b %y"",margin:true},yaxis:{min:null,noTicks:2,autoscale:true},grid:{verticalLines:false,color:""#000000"",outlineWidth:1,outline:""s""},mouse:{container:legend_div,track:true,trackY:false,relative:true,margin:20,position:""n"",trackFormatter:function(o){var label=strdates[parseInt(o.index,10)];if(label===undefined)label="""";else label+=""<br>"";for(var i=0;i<flotr2_data.length;i++){var value=flotr2_data[i].data[o.index][1];if(value===undefined)continue;if(flotr2_data.length>1){if(flotr2_data[i].label!==undefined){value_name=flotr2_data[i].label;label+=value_name+"":""}}label+=""<strong>""+Report.formatValue(value)+""</strong><br>""}return label}},selection:{mode:""x"",fps:10},shadowSize:4};return config}function composeRangeText(former_title,starting_utime,end_utime){var months=[""Jan"",""Feb"",""Mar"",""Apr"",""May"",""Jun"",""Jul"",""Aug"",""Sep"",""Oct"",""Nov"",""Dec""]; var date=new Date(parseInt(starting_utime,10)*1e3);var starting_date=months[date.getMonth()]+"" ""+date.getFullYear();date=new Date(parseInt(end_utime,10)*1e3);var end_date=months[date.getMonth()]+"" ""+date.getFullYear();return former_title+"" ( ""+starting_date+"" - ""+end_date+"" )""}function getMax(flotr2_data,from_unixstamp,to_unixstamp){from_unixstamp=Math.round(from_unixstamp);to_unixstamp=Math.round(to_unixstamp);var narrays=flotr2_data.length;var aux_array=[];for(var i=0;i<narrays;i++){for(var z=flotr2_data[i].length-1;z>0;z--){var aux_value=flotr2_data[i][z][0];var cond=aux_value<from_unixstamp||aux_value>to_unixstamp;if(cond){flotr2_data[i].splice(z,1)}}}var res=[];for(i=0;i<narrays;i++){aux_array=flotr2_data[i].data;aux_array=sortBiArray(aux_array);res.push(aux_array[aux_array.length-1][1])}res.sort(function(a,b){return a-b});return res[res.length-1]}function sortBiArray(bi_array){bi_array.sort(function(a,b){return a[1]>b[1]||b[1]===undefined?1:-1});return bi_array}})();String.prototype.supplant=function(o){return this.replace(/{([^{}]*)}/g,function(a,b){var r=o[b];return typeof r===""string""||typeof r===""number""?r:a})};var Table={};(function(){Table.displayTopTable=displayTopTable;Table.simpleTable=displaySimpleTable;function displaySimpleTable(div,data,headers,cols){var tables,aux_html,random_id;random_id=""myTable""+Math.floor(Math.random()*9999+1);tables='<table id=""'+random_id+'"" class=""table table-striped tablesorter"">';aux_html=""<thead><th>#</th>"";$.each(headers,function(id,value){aux_html+=""<th>""+value+""</th>""});aux_html+=""</thead><tbody>"";aux_html+=""<tbody>"";var first_col,aux_col;if(typeof data[cols[0]]!==""object""){aux_col=[];aux_col[0]=data[cols[0]];first_col=aux_col}else{first_col=data[cols[0]]}$.each(first_col,function(id,value){aux_html+=""<tr>"";var cont=id+1;aux_html+=""<td>""+cont+""</td>"";$.each(cols,function(subid,name){if(typeof data[name]!==""object""){aux_html+=""<td>""+data[name]+""</td>""}else{aux_html+=""<td>""+data[name][id]+""</td>""}});aux_html+=""</tr>""});aux_html+=""</tbody>"";tables+=aux_html;tables+=""</table>"";tables+=""<script>$(document).ready(function(){""+'$(""#'+random_id+'"").tablesorter();}'+""); </script>"";$(""#""+div.id).append(tables)}function displayTopTable(div,data,opts){var first=true,gen_tabs=true,tabs="""",tables="""",periods;if(opts.period!==""all""){gen_tabs=false;periods=[opts.period];tables+=getHTMLTitleFromPeriod(opts.period)}else{tabs+=composeTopTabs(data,opts.metric,opts.class_name);periods=getSortedPeriods()}periods=getSortedPeriods();if(opts.height!==undefined){tables+='<div class=""tab-content"" style=""height: '+opts.height+'px !important;overflow: scroll;"">'}else{tables+='<div class=""tab-content"">'}var var_names=getTopVarsFromMetric(opts.metric,opts.ds_name);for(var k=0;k<periods.length;k++){html="""";var key=opts.metric+"".""+periods[k];if(data[key]){var data_period=periods[k];if(data_period===""""){data_period=""all""}if(first===true){html="" active in"";first=false}var data_period_nows=data_period.replace(/\ /g,"""");tables+='<div class=""tab-pane fade'+html+'"" id=""'+opts.class_name+opts.metric+data_period_nows+'"">';tables+='<table class=""table table-striped"">';unit=opts.desc_metrics[opts.ds_name+""_""+opts.metric].action;title=opts.desc_metrics[opts.ds_name+""_""+opts.metric].name;if(opts.metric===""threads""&&opts.ds_name===""mls""){tables+=""<thead><th>#</th>"";tables+=""<th> Subject </th>"";tables+=""<th> Creator </th>"";tables+=""<th> Length </th>"";tables+=""</thead><tbody>"";tables+=composeTopRowsThreads(data[key],opts.limit,opts.links_enabled);tables+=""</tbody>""}else{tables+=""<thead><th>#</th><th>""+title.capitalize()+""</th>"";if(unit!==undefined)tables+=""<th>""+unit.capitalize()+""</th>"";if(data[key].organization!==undefined){tables+=""<th>Organization</th>""}tables+=""</thead><tbody>"";tables+=composeTopRowsPeople(data[key],opts.limit,opts.links_enabled,var_names);tables+=""</tbody>""}tables+=""</table>"";tables+=""</div>""}}tables+=""</div>"";$(""#""+div.id).append(tabs+tables);if(gen_tabs===true){script=""<script>$('#myTab a').click(function (e) {e.preventDefault();$(this).tab('show');});</script>"";$(""#""+div.id).append(script)}}function composeTopRowsPeople(people_data,limit,people_links,var_names){var rows_html="""";for(var j=0;j<people_data[var_names.id].length;j++){if(limit&&limit<=j)break;var metric_value=people_data[var_names.action][j];rows_html+=""<tr><td>""+(j+1)+""</td>"";rows_html+=""<td>"";if(people_links){rows_html+='<a href=""people.html?id='+people_data[var_names.id][j];get_params=Utils.paramsInURL();if(get_params.length>0)rows_html+=""&""+get_params;rows_html+='"">';rows_html+=DataProcess.hideEmail(people_data[var_names.name][j])+""</a>""}else{rows_html+=DataProcess.hideEmail(people_data[var_names.name][j])}rows_html+=""</td>"";rows_html+=""<td>""+metric_value+""</td>"";if(people_data.organization!==undefined){org=people_data.organization[j];if(org===null){org=""-""}rows_html+=""<td>""+org+""</td>""}rows_html+=""</tr>""}return rows_html}function composeTopRowsThreads(threads_data,limit,threads_links){var rows_html="""";for(var i=0;i<threads_data.subject.length;i++){if(limit&&limit<=i)break;rows_html+=""<tr><td>""+(i+1)+""</td>"";if(threads_links===true){var url=""http://www.google.com/search?output=search&q=X&btnI=1"";if(Report.getThreadsSite()!==undefined){url=""http://www.google.com/search?output=search&q=X%20site%3AY&btnI=1"";url=url.replace(/Y/g,Report.getThreadsSite())}else if(threads_data.hasOwnProperty(""url"")&&threads_data.url[i].length>0){url=""http://www.google.com/search?output=search&q=X%20site%3AY&btnI=1"";url=url.replace(/Y/g,threads_data.url[i])}url=url.replace(/X/g,threads_data.subject[i]);rows_html+=""<td>"";rows_html+='<a target=""_blank"" href=""'+url+'"">';rows_html+=threads_data.subject[i]+""</a>"";rows_html+='&nbsp;<i class=""fa fa-external-link""></i></td>'}else{rows_html+=""<td>""+threads_data.subject[i]+""</td>""}rows_html+=""<td>""+threads_data.initiator_name[i]+""</td>"";rows_html+=""<td>""+threads_data.length[i]+""</td>"";rows_html+=""</tr>""}return rows_html}function getSortedPeriods(){return[""last month"",""last year"",""""]}function getTitleFromPeriod(period){if(period===""last month""){return""Last 30 days""}else if(period===""last year""){return""Last 365 days""}else{return""Complete history""}}function getHTMLTitleFromPeriod(period){return'<div class=""toptable-title"">'+getTitleFromPeriod(period)+""</div>""}function composeTopTabs(data,metric,class_name){var first=true,tabs_html='<ul id=""myTab"" class=""nav nav-tabs"">',periods=getSortedPeriods();$.each(periods,function(id,p){aux_obj={html:""""};if(p===""""){p=""all"";aux_obj.pretty_period=""Complete history""}else if(p===""last month""){aux_obj.pretty_period=""Last 30 days""}else if(p===""last year""){aux_obj.pretty_period=""Last 365 days""}aux_obj.myhref=class_name+metric+p.replace(/\ /g,"""");if(first===true){aux_obj.html=' class=""active""';first=false}var aux_html='<li{html}><a href=""#{myhref}"" data-toogle=""tab"">{pretty_period}</a></li>';tabs_html+=aux_html.supplant(aux_obj)});tabs_html+=""</ul>"";return tabs_html}function getTopVarsFromMetric(metric,ds_name){var var_names={};var_names.id=""id"";if(metric===""senders""&&(ds_name===""mls""||ds_name===""irc"")){var_names.name=""senders"";var_names.action=""sent""}if(metric===""authors""&&ds_name===""scm""){var_names.name=""authors"";var_names.action=""commits""}if(metric===""closers""&&ds_name===""its""){var_names.name=""closers"";var_names.action=""closed""}if(ds_name===""scr""){if(metric===""mergers""){var_names.name=""mergers"";var_names.action=""merged""}if(metric===""openers""){var_names.name=""openers"";var_names.action=""opened""}if(metric===""submitters""){var_names.name=""openers"";var_names.action=""opened""}if(metric===""reviewers""){var_names.name=""reviewers"";var_names.action=""reviews""}if(metric===""participants""){var_names.name=""identifier"";var_names.action=""events""}if(metric===""active_core_reviewers""){var_names.name=""identifier"";var_names.action=""reviews""}}if(ds_name===""downloads""){if(metric===""ips""){var_names.name=""ips"";var_names.action=""downloads""}if(metric===""packages""){var_names.name=""packages"";var_names.action=""downloads""}}if(ds_name===""mediawiki""){if(metric===""authors""){var_names.name=""authors"";var_names.action=""reviews""}}if(ds_name===""qaforums""){if(metric===""senders""||metric===""asenders""||metric===""qsenders""){var_names.name=""senders"";var_names.action=""sent""}else if(metric===""participants""){var_names.name=""name"";var_names.action=""messages_sent""}}if(ds_name===""releases""){if(metric===""authors""){var_names.name=""username"";var_names.action=""releases""}}if(ds_name===""meetup""){if(metric===""cities""){var_names.name=""city"";var_names.action=""events""}else if(metric===""events""){var_names.name=""event"";var_names.action=""attendees""}else if(metric===""groups""){var_names.name=""group"";var_names.action=""events""}}return var_names}})();var Demographics={};(function(){var data_dg={};Demographics.widget=function(){var divs=$("".DemographicsCompany""),ds_name,company_name,DS,period;if(divs.length>0){$.each(divs,function(id,div){ds_name="""";ds_name=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds_name);if(DS===null)return;if(DS.getData().length===0)return;period=$(this).data(""period"");company_name=Utils.getParameter(""company"");loadDemographicsData(div,ds_name,company_name,period,displayDemographics)})}};function loadDemographicsData(div,ds_name,company_name,period,cb){var suffix=ds_name.toLowerCase(),preffix,ag_file,b_file;preffix=""data/json/""+company_name+""-""+suffix+""-com-demographics-"";ag_file=preffix+""aging.json"";b_file=preffix+""birth.json"";$.when($.getJSON(ag_file),$.getJSON(b_file)).done(function(ag_data,b_data){data_dg[company_name]={};data_dg[company_name][ds_name]={aging:undefined,birth:undefined};data_dg[company_name][ds_name].aging=ag_data[0];data_dg[company_name][ds_name].birth=b_data[0];cb(div,ds_name,company_name,period)}).fail(function(){console.log(""Demographics Company widget disabled. Missing ""+ds_name+"" files for company ""+company_name)})}function displayDemographics(div,ds_name,company_name,period){if(!div.id)div.id=""Parsed""+getRandomId();if(data_dg[company_name]!==undefined&&data_dg[company_name][ds_name]!==undefined){Viz.displayDemographicsChart(div.id,data_dg[company_name][ds_name],period)}}function getRandomId(){return Math.floor(Math.random()*1e3+1)}})();Loader.data_ready(function(){Demographics.widget()});vizjslib_git_revision=""86fdfaddd3d52b4c08440fb2a5bf40c92f8bf29c"";vizjslib_git_tag=""15.04-18-g86fdfad"";","var wgd=$w.coords().grid;var can_go_up=self.can_go_widget_up(wgd);if(can_go_up&&can_go_up!==wgd.row){self.move_widget_to($w,can_go_up)}});return this};fn.move_widget_up=function($widget,y_units){var el_grid_data=$widget.coords().grid;var actual_row=el_grid_data.row;var moved=[];var can_go_up=true;y_units||(y_units=1);if(!this.can_go_up($widget)){return false}this.for_each_column_occupied(el_grid_data,function(col){if($.inArray($widget,moved)===-1){var widget_grid_data=$widget.coords().grid;var next_row=actual_row-y_units;next_row=this.can_go_up_to_row(widget_grid_data,col,next_row);if(!next_row){return true}var $next_widgets=this.widgets_below($widget);this.remove_from_gridmap(widget_grid_data);widget_grid_data.row=next_row;this.add_to_gridmap(widget_grid_data);$widget.attr(""data-row"",widget_grid_data.row);this.$changed=this.$changed.add($widget);moved.push($widget);$next_widgets.each($.proxy(function(i,widget){this.move_widget_up($(widget),y_units)},this))}})};fn.move_widget_down=function($widget,y_units){var el_grid_data=$widget.coords().grid;var actual_row=el_grid_data.row;var moved=[];var y_diff=y_units;if(!$widget){return false}if($.inArray($widget,moved)===-1){var widget_grid_data=$widget.coords().grid;var next_row=actual_row+y_units;var $next_widgets=this.widgets_below($widget);this.remove_from_gridmap(widget_grid_data);$next_widgets.each($.proxy(function(i,widget){var $w=$(widget);var wd=$w.coords().grid;var tmp_y=this.displacement_diff(wd,widget_grid_data,y_diff);if(tmp_y>0){this.move_widget_down($w,tmp_y)}},this));widget_grid_data.row=next_row;this.update_widget_position(widget_grid_data,$widget);$widget.attr(""data-row"",widget_grid_data.row);this.$changed=this.$changed.add($widget);moved.push($widget)}};fn.can_go_up_to_row=function(widget_grid_data,col,row){var ga=this.gridmap;var result=true;var urc=[];var actual_row=widget_grid_data.row;var r;this.for_each_column_occupied(widget_grid_data,function(tcol){var grid_col=ga[tcol];urc[tcol]=[];r=actual_row;while(r--){if(this.is_empty(tcol,r)&&!this.is_placeholder_in(tcol,r)){urc[tcol].push(r)}else{break}}if(!urc[tcol].length){result=false;return true}});if(!result){return false}r=row;for(r=1;r<actual_row;r++){var common=true;for(var uc=0,ucl=urc.length;uc<ucl;uc++){if(urc[uc]&&$.inArray(r,urc[uc])===-1){common=false}}if(common===true){result=r;break}}return result};fn.displacement_diff=function(widget_grid_data,parent_bgd,y_units){var actual_row=widget_grid_data.row;var diffs=[];var parent_max_y=parent_bgd.row+parent_bgd.size_y;this.for_each_column_occupied(widget_grid_data,function(col){var temp_y_units=0;for(var r=parent_max_y;r<actual_row;r++){if(this.is_empty(col,r)){temp_y_units=temp_y_units+1}}diffs.push(temp_y_units)});var max_diff=Math.max.apply(Math,diffs);y_units=y_units-max_diff;return y_units>0?y_units:0};fn.widgets_below=function($el){var el_grid_data=$.isPlainObject($el)?$el:$el.coords().grid;var self=this;var ga=this.gridmap;var next_row=el_grid_data.row+el_grid_data.size_y-1;var $nexts=$([]);this.for_each_column_occupied(el_grid_data,function(col){self.for_each_widget_below(col,next_row,function(tcol,trow){if(!self.is_player(this)&&$.inArray(this,$nexts)===-1){$nexts=$nexts.add(this);return true}})});return this.sort_by_row_asc($nexts)};fn.set_cells_player_occupies=function(col,row){this.remove_from_gridmap(this.placeholder_grid_data);this.placeholder_grid_data.col=col;this.placeholder_grid_data.row=row;this.add_to_gridmap(this.placeholder_grid_data,this.$player);return this};fn.empty_cells_player_occupies=function(){this.remove_from_gridmap(this.placeholder_grid_data);return this};fn.can_go_up=function($el){var el_grid_data=$el.coords().grid;var initial_row=el_grid_data.row;var prev_row=initial_row-1;var ga=this.gridmap;var upper_rows_by_column=[];var result=true;if(initial_row===1){return false}this.for_each_column_occupied(el_grid_data,function(col){var $w=this.is_widget(col,prev_row);if(this.is_occupied(col,prev_row)||this.is_player(col,prev_row)||this.is_placeholder_in(col,prev_row)||this.is_player_in(col,prev_row)){result=false;return true}});return result};fn.can_move_to=function(widget_grid_data,col,row,max_row){var ga=this.gridmap;var $w=widget_grid_data.el;var future_wd={size_y:widget_grid_data.size_y,size_x:widget_grid_data.size_x,col:col,row:row};var result=true;var right_col=col+widget_grid_data.size_x-1;if(right_col>this.cols){return false}if(max_row&&max_row<row+widget_grid_data.size_y-1){return false}this.for_each_cell_occupied(future_wd,function(tcol,trow){var $tw=this.is_widget(tcol,trow);if($tw&&(!widget_grid_data.el||$tw.is($w))){result=false}});return result};fn.get_targeted_columns=function(from_col){var max=(from_col||this.player_grid_data.col)+(this.player_grid_data.size_x-1);var cols=[];for(var col=from_col;col<=max;col++){cols.push(col)}return cols};fn.get_targeted_rows=function(from_row){var max=(from_row||this.player_grid_data.row)+(this.player_grid_data.size_y-1);var rows=[];for(var row=from_row;row<=max;row++){rows.push(row)}return rows};fn.get_cells_occupied=function(el_grid_data){var cells={cols:[],rows:[]};var i;if(arguments[1]instanceof jQuery){el_grid_data=arguments[1].coords().grid}for(i=0;i<el_grid_data.size_x;i++){var col=el_grid_data.col+i;cells.cols.push(col)}for(i=0;i<el_grid_data.size_y;i++){var row=el_grid_data.row+i;cells.rows.push(row)}return cells};fn.for_each_cell_occupied=function(grid_data,callback){this.for_each_column_occupied(grid_data,function(col){this.for_each_row_occupied(grid_data,function(row){callback.call(this,col,row)})});return this};fn.for_each_column_occupied=function(el_grid_data,callback){for(var i=0;i<el_grid_data.size_x;i++){var col=el_grid_data.col+i;callback.call(this,col,el_grid_data)}};fn.for_each_row_occupied=function(el_grid_data,callback){for(var i=0;i<el_grid_data.size_y;i++){var row=el_grid_data.row+i;callback.call(this,row,el_grid_data)}};fn._traversing_widgets=function(type,direction,col,row,callback){var ga=this.gridmap;if(!ga[col]){return}var cr,max;var action=type+""/""+direction;if(arguments[2]instanceof jQuery){var el_grid_data=arguments[2].coords().grid;col=el_grid_data.col;row=el_grid_data.row;callback=arguments[3]}var matched=[];var trow=row;var methods={""for_each/above"":function(){while(trow--){if(trow>0&&this.is_widget(col,trow)&&$.inArray(ga[col][trow],matched)===-1){cr=callback.call(ga[col][trow],col,trow);matched.push(ga[col][trow]);if(cr){break}}}},""for_each/below"":function(){for(trow=row+1,max=ga[col].length;trow<max;trow++){if(this.is_widget(col,trow)&&$.inArray(ga[col][trow],matched)===-1){cr=callback.call(ga[col][trow],col,trow);matched.push(ga[col][trow]);if(cr){break}}}}};if(methods[action]){methods[action].call(this)}};fn.for_each_widget_above=function(col,row,callback){this._traversing_widgets(""for_each"",""above"",col,row,callback);return this};fn.for_each_widget_below=function(col,row,callback){this._traversing_widgets(""for_each"",""below"",col,row,callback);return this};fn.get_highest_occupied_cell=function(){var r;var gm=this.gridmap;var rows=[];var row_in_col=[];for(var c=gm.length-1;c>=1;c--){for(r=gm[c].length-1;r>=1;r--){if(this.is_widget(c,r)){rows.push(r);row_in_col[r]=c;break}}}var highest_row=Math.max.apply(Math,rows);this.highest_occupied_cell={col:row_in_col[highest_row],row:highest_row};return this.highest_occupied_cell};fn.get_widgets_from=function(col,row){var ga=this.gridmap;var $widgets=$();if(col){$widgets=$widgets.add(this.$widgets.filter(function(){var tcol=$(this).attr(""data-col"");return tcol===col||tcol>col}))}if(row){$widgets=$widgets.add(this.$widgets.filter(function(){var trow=$(this).attr(""data-row"");return trow===row||trow>row}))}return $widgets};fn.set_dom_grid_height=function(){var r=this.get_highest_occupied_cell().row;this.$el.css(""height"",r*this.min_widget_height);return this};fn.generate_stylesheet=function(opts){var styles="""";var max_size_x=this.options.max_size_x;var max_rows=0;var max_cols=0;var i;var rules;opts||(opts={});opts.cols||(opts.cols=this.cols);opts.rows||(opts.rows=this.rows);opts.namespace||(opts.namespace=this.options.namespace);opts.widget_base_dimensions||(opts.widget_base_dimensions=this.options.widget_base_dimensions);opts.widget_margins||(opts.widget_margins=this.options.widget_margins);opts.min_widget_width=opts.widget_margins[0]*2+opts.widget_base_dimensions[0];opts.min_widget_height=opts.widget_margins[1]*2+opts.widget_base_dimensions[1];var serialized_opts=$.param(opts);if($.inArray(serialized_opts,Gridster.generated_stylesheets)>=0){return false}Gridster.generated_stylesheets.push(serialized_opts);for(i=opts.cols;i>=0;i--){styles+=opts.namespace+' [data-col=""'+(i+1)+'""] { left:'+(i*opts.widget_base_dimensions[0]+i*opts.widget_margins[0]+(i+1)*opts.widget_margins[0])+""px;} ""}for(i=opts.rows;i>=0;i--){styles+=opts.namespace+' [data-row=""'+(i+1)+'""] { top:'+(i*opts.widget_base_dimensions[1]+i*opts.widget_margins[1]+(i+1)*opts.widget_margins[1])+""px;} ""}for(var y=1;y<=opts.rows;y++){styles+=opts.namespace+' [data-sizey=""'+y+'""] { height:'+(y*opts.widget_base_dimensions[1]+(y-1)*(opts.widget_margins[1]*2))+""px;}""}for(var x=1;x<=max_size_x;x++){styles+=opts.namespace+' [data-sizex=""'+x+'""] { width:'+(x*opts.widget_base_dimensions[0]+(x-1)*(opts.widget_margins[0]*2))+""px;}""}return this.add_style_tag(styles)};fn.add_style_tag=function(css){var d=document;var tag=d.createElement(""style"");d.getElementsByTagName(""head"")[0].appendChild(tag);tag.setAttribute(""type"",""text/css"");if(tag.styleSheet){tag.styleSheet.cssText=css}else{tag.appendChild(document.createTextNode(css))}return this};fn.generate_faux_grid=function(rows,cols){this.faux_grid=[];this.gridmap=[];var col;var row;for(col=cols;col>0;col--){this.gridmap[col]=[];for(row=rows;row>0;row--){this.add_faux_cell(row,col)}}return this};fn.add_faux_cell=function(row,col){var coords=$({left:this.baseX+(col-1)*this.min_widget_width,top:this.baseY+(row-1)*this.min_widget_height,width:this.min_widget_width,height:this.min_widget_height,col:col,row:row,original_col:col,original_row:row}).coords();if(!$.isArray(this.gridmap[col])){this.gridmap[col]=[]}this.gridmap[col][row]=false;this.faux_grid.push(coords);return this};fn.add_faux_rows=function(rows){var actual_rows=this.rows;var max_rows=actual_rows+(rows||1);for(var r=max_rows;r>actual_rows;r--){for(var c=this.cols;c>=1;c--){this.add_faux_cell(r,c)}}this.rows=max_rows;if(this.options.autogenerate_stylesheet){this.generate_stylesheet()}return this};fn.add_faux_cols=function(cols){var actual_cols=this.cols;var max_cols=actual_cols+(cols||1);for(var c=actual_cols;c<max_cols;c++){for(var r=this.rows;r>=1;r--){this.add_faux_cell(r,c)}}this.cols=max_cols;if(this.options.autogenerate_stylesheet){this.generate_stylesheet()}return this};fn.recalculate_faux_grid=function(){var aw=this.$wrapper.width();this.baseX=($(window).width()-aw)/2;this.baseY=this.$wrapper.offset().top;$.each(this.faux_grid,$.proxy(function(i,coords){this.faux_grid[i]=coords.update({left:this.baseX+(coords.data.col-1)*this.min_widget_width,top:this.baseY+(coords.data.row-1)*this.min_widget_height})},this));return this};fn.get_widgets_from_DOM=function(){this.$widgets.each($.proxy(function(i,widget){this.register_widget($(widget))},this));return this};fn.generate_grid_and_stylesheet=function(){var aw=this.$wrapper.width();var ah=this.$wrapper.height();var cols=Math.floor(aw/this.min_widget_width)+this.options.extra_cols;var actual_cols=this.$widgets.map(function(){return $(this).attr(""data-col"")});actual_cols=Array.prototype.slice.call(actual_cols,0);actual_cols.length||(actual_cols=[0]);var min_cols=Math.max.apply(Math,actual_cols);var max_rows=this.options.extra_rows;this.$widgets.each(function(i,w){max_rows+=+$(w).attr(""data-sizey"")});this.cols=Math.max(min_cols,cols,this.options.min_cols);this.rows=Math.max(max_rows,this.options.min_rows);this.baseX=($(window).width()-aw)/2;this.baseY=this.$wrapper.offset().top;if(this.options.autogenerate_stylesheet){this.generate_stylesheet()}return this.generate_faux_grid(this.rows,this.cols)};$.fn.gridster=function(options){return this.each(function(){if(!$(this).data(""gridster"")){$(this).data(""gridster"",new Gridster(this,options))}})};$.Gridster=fn})(jQuery,window,document);vizjslib_git_revision=""b9507b20f12b48b57539eafb44179d6d3242a2da"";vizjslib_git_tag=""15.02-53-gb9507b2"";(function(){var V=envision,global_data={};function getDefaultsMarkers(option,markers,dates){var mark="""";if(!markers||markers.length===0)return mark;for(var i=0;i<markers.date.length;i++){if(markers.date[i]==dates[option.index]){mark=markers.marks[i]}}return mark}function getEnvisionDefaultsGraph(name,gconfig){var graph={name:name,config:{colors:gconfig.colors,grid:{verticalLines:false,horizontalLines:false},mouse:{track:true,trackY:false,position:""ne""},yaxis:{min:0,autoscale:true},legend:{show:false,backgroundColor:""#FFFFFF"",backgroundOpacity:0}}};if(gconfig.gtype===""whiskers"")graph.config.whiskers={show:true,lineWidth:2};else graph.config[""lite-lines""]={lineWidth:2,show:true,fill:false,fillOpacity:.5};if(gconfig.y_labels)graph.config.yaxis={showLabels:true,min:0};if(gconfig.show_markers)graph.config.markers={show:true,position:""ct"",labelFormatter:function(o){return getDefaultsMarkers(o,gconfig.markers,gconfig.dates)}};return graph}function getDefaultsMetrics(DS,viz,metrics,default_config){var all_metrics=Report.getAllMetrics();var label=null;$.each(metrics,function(metric,value){config=default_config;if(value.envision)config=DataProcess.mergeConfig(default_config,value.envision);if($.inArray(metric,global_data.envision_hide)===-1){viz[metric]=getEnvisionDefaultsGraph(""report-""+DS.getName()+""-""+metric,config);label=metric;if(all_metrics[metric])label=all_metrics[metric].name;viz[metric].config.subtitle=label;if(DS.getMainMetric()==metric){viz[metric+""_relative""]=getEnvisionDefaultsGraph(""report-""+DS.getName()+""-""+metric+""_relative"",config);viz[metric].config[""lite-lines""]={show:false};viz[metric].config.lines={lineWidth:1,show:true,stacked:true,fill:true,fillOpacity:1}}}})}function getDefaults(ds){var defaults_colors=[""#ffa500"",""#00A8F0"",""#C0D800"",""#ffff00"",""#00ff00"",""#4DA74D"",""#9440ED""];var default_config={colors:defaults_colors,dates:global_data.dates,g_type:"""",markers:global_data.markers,y_labels:false};var data_sources=Report.getDataSources();var viz={};var metrics={};if(!ds){$.each(data_sources,function(i,DS){metrics=DS.getMetrics();getDefaultsMetrics(DS,viz,metrics,default_config)})}else{$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds)>-1){metrics=DS.getMetrics();getDefaultsMetrics(DS,viz,metrics,default_config)}})}config=default_config;viz.summary=getEnvisionDefaultsGraph(""report-summary"",config);viz.summary.config.xaxis={noTickets:10,showLabels:true};viz.summary.config.handles={show:true};viz.summary.config.selection={mode:""x""};viz.summary.config.mouse={};viz.connection={name:""report-connection"",adapterConstructor:V.components.QuadraticDrawing};return viz}function getOrderedDataSources(ds_list,main_metric){var ordered=[];var main_DS=null;$.each(ds_list,function(i,DS){if(DS.getMetrics()[main_metric]){main_DS=DS;return false}});ordered.push(main_DS);$.each(ds_list,function(i,DS){if(DS===main_DS)return;ordered.push(DS)});return ordered}function Envision_Report(options,data_sources){var main_metric=options.data.main_metric;global_data=options.data;if(!data_sources)data_sources=Report.getDataSources();data_sources=getOrderedDataSources(data_sources,main_metric);var ds=[];for(var i=0;i<data_sources.length;i++){if(data_sources[i].getData().length===0)continue;ds.push(data_sources[i].getName())}var data=options.data,defaults=getDefaults(ds),vis=new V.Visualization({name:""report-""+ds.join("","")}),selection=new V.Interaction,hit=new V.Interaction;var metrics={};$.each(data_sources,function(i,DS){if(DS.getData().length===0)return;metrics=$.extend(metrics,DS.getMetrics())});$.each(metrics,function(metric,value){if($.inArray(metric,data.envision_hide)!==-1)return;if(data[metric]===undefined)return;defaults[metric].data=data[metric];if(defaults[metric].data.length<Report.getProjectsList().length)defaults[metric].config.legend.show=true;if(data[metric+""_relative""])defaults[metric].data=data[metric+""_relative""]});defaults.summary.data=data.summary;defaults[main_metric].config.legend.show=true;if(options.legend_show===false)defaults[main_metric].config.legend.show=false;defaults[main_metric].config.mouse.trackFormatter=options.trackFormatter;if(options.xTickFormatter){defaults.summary.config.xaxis.tickFormatter=options.xTickFormatter}defaults[main_metric].config.yaxis.tickFormatter=options.yTickFormatter||function(n){return""$""+n};var components={};$.each(metrics,function(metric,value){if(data[metric]===undefined)return;if($.inArray(metric,data.envision_hide)===-1){components[metric]=new V.Component(defaults[metric])}});connection=new V.Component(defaults.connection);summary=new V.Component(defaults.summary);$.each(components,function(component,value){vis.add(value)});vis.add(connection).add(summary).render(options.container);$.each(components,function(component,value){selection.follower(value)});selection.follower(connection).leader(summary).add(V.actions.selection,options.selectionCallback?{callback:options.selectionCallback}:null);var hit_group=[];$.each(components,function(component,value){hit_group.push(value)});hit.group(hit_group).add(V.actions.hit);if(options.selection){summary.trigger(""select"",options.selection)}}V.templates.Envision_Report=Envision_Report})();if(Loader===undefined)var Loader={};(function(){var data_callbacks=[];var data_global_callbacks=[];var data_repos_callbacks=[];var check_companies=false,check_repos=false,check_countries=false;var ds_not_supported_company_top=[""scr"",""irc"",""mediawiki""];var ds_supporting_top_repos=[""scm"",""mls"",""its""];var all_data;Loader.data_ready=function(callback){data_callbacks.push(callback)};Loader.data_ready_global=function(callback){data_global_callbacks.push(callback)};Loader.set_all_data=function(data){all_data=data};function fillProjectInfo(data,dir){if(data.project_name===undefined){data.project_name=dir.replace(""data/json"","""").replace(/\.\.\//g,"""")}var projects_data=Report.getProjectsData();projects_data[data.project_name]={dir:dir,url:data.project_url}}Loader.data_load=function(){if(Report.getConfig()!==null&&Report.getConfig().project_info!==undefined){Report.setProjectData(Report.getConfig().project_info);if(Report.getConfig().markers)data_load_file(Report.getMarkersFile(),function(data,self){Report.setMarkers(data)})}else{data_load_file(Report.getProjectFile(),function(data,self){Report.setProjectData(data)});data_load_file(Report.getMarkersFile(),function(data,self){Report.setMarkers(data)})}var projects_dirs=Report.getProjectsDirs();for(var i=0;i<projects_dirs.length;i++){var data_dir=projects_dirs[i];var prj_file=Report.getDataDir()+""/project-info.json"";data_load_file(prj_file,fillProjectInfo,data_dir)}data_load_file(Report.getProjectsHierarchyFile(),Report.setProjectsHierarchy);data_load_file(Report.getVizConfigFile(),function(data,self){Report.setVizConfig(data)});data_load_metrics_definition();data_load_metrics();data_load_tops(""authors"");data_load_time_to_fix();data_load_time_to_attention();data_load_demographics();data_load_markov_table();if(Report.getConfig()!==null&&Report.getConfig().reports!==undefined){var active_reports=Report.getConfig().reports;if($.inArray(""companies"",active_reports)>-1)data_load_companies();if($.inArray(""repositories"",active_reports)>-1)data_load_repos();if($.inArray(""countries"",active_reports)>-1)data_load_countries();if($.inArray(""domains"",active_reports)>-1)data_load_domains();if($.inArray(""projects"",active_reports)>-1)data_load_projects();if($.inArray(""people"",active_reports)>-1){data_load_people();data_load_people_identities()}}else{data_load_companies();data_load_repos();data_load_countries();data_load_domains();data_load_projects();data_load_people();data_load_people_identities()}};Loader.get_file_data_div=function(file,cb,div){$.when($.getJSON(file)).done(function(history){cb(div,file,history)}).fail(function(){cb(file,null)})};function get_data_from_all(file,fn_data_set,self){all_data_found=false;if(all_data){file_no_path=file.replace(Report.getDataDir()+""/"","""");data=all_data[file_no_path];if(data){fn_data_set(data,self);end_data_load();all_data_found=true}else{if(window.console){Report.log(""Can't find in ""+Report.all_json_file+"" ""+file)}}}return all_data_found}function data_load_file(file,fn_data_set,self){if(get_data_from_all(file,fn_data_set,self))return;$.when($.getJSON(file)).done(function(history){fn_data_set(history,self);end_data_load()}).fail(function(){fn_data_set([],self);end_data_load()})}function data_load_companies(){var ds_not_supported=[""irc"",""mediawiki""];var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds_not_supported)>-1)DS.setCompaniesData([]);else data_load_file(DS.getCompaniesDataFile(),DS.setCompaniesData,DS)})}function data_load_repos(){var ds_not_supported=[""mediawiki""];var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds_not_supported)>-1){DS.setReposData([])}else{data_load_file(DS.getReposDataFile(),DS.setReposData,DS)}});data_load_file(Report.getReposMapFile(),Report.setReposMap)}function data_load_countries(){var ds_not_supported=[""irc"",""mediawiki""];var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds_not_supported)>-1)DS.setCountriesData([]);else data_load_file(DS.getCountriesDataFile(),DS.setCountriesData,DS)})}function data_load_domains(){var ds_not_supported=[""irc"",""mediawiki""];var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds_not_supported)>-1)DS.setDomainsData([]);else data_load_file(DS.getDomainsDataFile(),DS.setDomainsData,DS)})}function data_load_projects(){var ds_not_supported=[""irc"",""mediawiki""];var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if($.inArray(DS.getName(),ds_not_supported)>-1)DS.setProjectsData([]);else data_load_file(DS.getProjectsDataFile(),DS.setProjectsData,DS)})}function data_load_time_to_fix(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if(DS.getName()===""its"")data_load_file(DS.getTimeToFixDataFile(),DS.setTimeToFixData,DS)})}function data_load_markov_table(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if(DS.getName()===""its"")data_load_file(DS.getMarkovTableDataFile(),DS.setMarkovTableData,DS)})}function data_load_time_to_attention(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){if(DS.getName()===""mls"")data_load_file(DS.getTimeToAttentionDataFile(),DS.setTimeToAttentionData,DS)})}function data_load_demographics(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){data_load_file(DS.getDemographicsAgingFile(),DS.setDemographicsAgingData,DS);data_load_file(DS.getDemographicsBirthFile(),DS.setDemographicsBirthData,DS)})}function data_load_tops(metric){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){var file_all=DS.getTopDataFile();if(get_data_from_all(file_all,DS.setGlobalTopData,DS))return;$.when($.getJSON(file_all)).done(function(history){DS.setGlobalTopData(history);end_data_load()}).fail(function(){DS.setGlobalTopData([],DS);end_data_load()})})}Loader.check_filters_page=function(page){var check=true;var filters=[""repos"",""companies"",""countries""];$.each(filters,function(index,filter){if(!Loader.check_filter_page(page,filter)){check=false;return false}});return check};Loader.check_filter_page=function(page,filter){var check=true;if(page===undefined)page=1;var start=Report.getPageSize()*(page-1);var end=start+Report.getPageSize();$.each(Report.getDataSources(),function(index,DS){var total=0;if(filter===""repos"")total=DS.getReposData().length;if(filter===""companies"")total=DS.getCompaniesData().length;if(filter===""countries"")total=DS.getCountriesData().length;if(filter===""domains"")total=DS.getDomainsData().length;if(filter===""projects"")total=DS.getProjectsData().length;if(end>total)end=total;for(var i=start;i<end;i++){var item;if(filter===""repos""){item=DS.getReposData()[i];if(DS.getReposGlobalData()[item]===undefined||DS.getReposMetricsData()[item]===undefined){check=false;return false}}if(filter===""companies""){item=DS.getCompaniesData()[i];if(DS.getCompaniesGlobalData()[item]===undefined||DS.getCompaniesMetricsData()[item]===undefined){check=false;return false}}if(filter===""countries""){item=DS.getCountriesData()[i];if(DS.getCountriesGlobalData()[item]===undefined||DS.getCountriesMetricsData()[item]===undefined){check=false;return false}}if(filter===""domains""){item=DS.getDomainsData()[i];if(DS.getDomainsGlobalData()[item]===undefined||DS.getDomainsMetricsData()[item]===undefined){check=false;return false}}if(filter===""projects""){item=DS.getProjectsData()[i];if(DS.getProjectsGlobalData()[item]===undefined||DS.getProjectsMetricsData()[item]===undefined){check=false;return false}}}end=start+Report.getPageSize()});return check};function getItemDS(item,filter){var ds=null;$.each(Report.getDataSources(),function(index,DS){if(filter==""repos""){if($.inArray(item,DS.getReposData())>-1){ds=DS;return false}}if(filter==""companies""){if($.inArray(item,DS.getCompaniesData())>-1){ds=DS;return false}}if(filter==""countries""){if($.inArray(item,DS.getCountriesData())>-1){ds=DS;return false}}if(filter==""domains""){if($.inArray(item,DS.getDomainsData())>-1){ds=DS;return false}}if(filter==""projects""){if($.inArray(item,DS.getProjectsData())>-1){ds=DS;return false}}});return ds}Loader.filterTopCheck=function(item,filter){var check=true;if(filter===""repos""){if(Loader.check_item(item,filter,""top"")===false){ds=getItemDS(item,filter);if(ds===null){Report.log(""Can't find data source for ""+item);return true}if($.inArray(ds.getName(),ds_supporting_top_repos)>=0){Loader.data_load_item_top(item,ds,null,Convert.convertFilterTop,filter,""top"")}return false}}return check};Loader.FilterItemCheck=function(item,filter){var check=true,ds;var map=Report.getReposMap();if(filter===""repos""){if(Loader.check_item(item,filter)===false){ds=getItemDS(item,filter);if(ds===null){Report.log(""Can't find data source for ""+item);return true}Loader.data_load_item(item,ds,null,Convert.convertFilterStudyItem,filter,null);if($.inArray(ds.getName(),ds_supporting_top_repos)>=0){Loader.data_load_item_top(item,ds,null,Convert.convertFilterStudyItem,filter)}return false}if(map!==undefined&&map.length!==0){var items_map=[];$.each(Report.getDataSources(),function(index,DS){var itmap=Convert.getRealItem(DS,filter,item);if(itmap!==undefined&&itmap!==null)items_map.push(itmap)});if(Loader.check_items(items_map,filter)===false){for(var i=0;i<items_map.length;i++){if(Loader.check_item(items_map[i],filter)===false){ds=getItemDS(items_map[i],filter);if(ds===null){Report.log(""Can't find ""+items_map[i]);Report.log(""Check repos-map.json"");continue}Loader.data_load_item(items_map[i],ds,null,Convert.convertFilterStudyItem,filter,items_map)}}check=false}}}else{$.each(Report.getDataSources(),function(index,DS){if(Loader.check_item(item,filter)===false){check=false;Loader.data_load_item(item,DS,null,Convert.convertFilterStudyItem,filter,null);if(filter===""companies""){if($.inArray(DS.getName(),ds_not_supported_company_top)===-1)Loader.data_load_item_top(item,DS,null,Convert.convertFilterStudyItem,filter)}}})}return check};Loader.check_item=function(item,filter,optional_filter){var check=false;$.each(Report.getDataSources(),function(index,DS){if(filter===""repos""){if(optional_filter===""top""){if($.inArray(DS.getName(),ds_supporting_top_repos)>=0&&$.inArray(item,DS.getReposData())>=0&&DS.getRepositoriesTopData()[item]!==undefined){check=true;return false}}else{if(DS.getReposGlobalData()[item]!==undefined&&DS.getReposMetricsData()[item]!==undefined){check=true;return false}}}else if(filter===""companies""){var companies=DS.getCompaniesData();if(companies.length===0)check=true;else if($.inArray(item,companies)===-1)check=true;else if(DS.getCompaniesGlobalData()[item]===undefined||DS.getCompaniesMetricsData()[item]===undefined){check=false;return false}else if($.inArray(DS.getName(),ds_not_supported_company_top)===-1&&DS.getCompaniesTopData()[item]===undefined){check=false;return false}else check=true}else if(filter===""countries""){var countries=DS.getCountriesData();if(countries.length===0)check=true;else if($.inArray(item,countries)===-1)check=true;else if(DS.getCountriesGlobalData()[item]===undefined||DS.getCountriesMetricsData()[item]===undefined){check=false;return false}else check=true}else if(filter===""domains""){var domains=DS.getDomainsData();if(domains.length===0)check=true;else if($.inArray(item,domains)===-1)check=true;else if(DS.getDomainsGlobalData()[item]===undefined||DS.getDomainsMetricsData()[item]===undefined){check=false;return false}else check=true}else if(filter===""projects""){var projects=DS.getProjectsData();if(projects.length===0)check=true;else if($.inArray(item,projects)===-1)check=true;else if(DS.getProjectsGlobalData()[item]===undefined||DS.getProjectsMetricsData()[item]===undefined){check=false;return false}else check=true}});return check};Loader.check_items=function(items,filter){var check=true;$.each(items,function(id,item){if(Loader.check_item(item,filter)===false){check=false;return false}});return check};Loader.data_load_items_page=function(DS,page,cb,filter){if(page===undefined)page=1;if(filter===""repos"")if(DS.getReposData()===null)return false;if(filter===""companies"")if(DS.getCompaniesData()===null)return false;if(filter===""countries"")if(DS.getCountriesData()===null)return false;if(filter===""domains"")if(DS.getDomainsData()===null)return false;if(filter===""projects"")if(DS.getProjectsData()===null)return false;var total=0;if(filter===""repos"")total=DS.getReposData().length;if(filter===""companies"")total=DS.getCompaniesData().length;if(filter===""countries"")total=DS.getCountriesData().length;if(filter===""domains"")total=DS.getDomainsData().length;if(filter===""projects"")total=DS.getProjectsData().length;if(total===0)return true;var start=Report.getPageSize()*(page-1);var end=start+Report.getPageSize();if(end>total)end=total;for(var i=start;i<end;i++){if(filter===""repos""){var repo=DS.getReposData()[i];Loader.data_load_item(repo,DS,page,cb,""repos"")}else if(filter===""companies""){var company=DS.getCompaniesData()[i];Loader.data_load_item(company,DS,page,cb,""companies"")}else if(filter===""countries""){var country=DS.getCountriesData()[i];Loader.data_load_item(country,DS,page,cb,""countries"")}else if(filter===""domains""){var domain=DS.getDomainsData()[i];Loader.data_load_item(domain,DS,page,cb,""domains"")}else if(filter===""projects""){var project=DS.getProjectsData()[i];Loader.data_load_item(project,DS,page,cb,""projects"")}}};Loader.check_people_item=function(item){var check=true;$.each(Report.getDataSources(),function(index,DS){if(DS.getPeopleGlobalData()[item]===undefined||DS.getPeopleMetricsData()[item]===undefined){check=false;return false}});return check};Loader.data_load_people_item=function(upeople_id,DS,cb){var file=DS.getDataDir()+""/people-""+upeople_id+""-""+DS.getName();var file_evo=file+""-evolutionary.json"";var file_static=file+""-static.json"";if(all_data){file_evo_no_path=file_evo.replace(Report.getDataDir()+""/"","""");file_static_no_path=file_static.replace(Report.getDataDir()+""/"","""");data_evo=all_data[file_evo_no_path];data_static=all_data[file_static_no_path];if(data_evo&&data_static){DS.addPeopleMetricsData(upeople_id,data_evo,DS);DS.addPeopleGlobalData(upeople_id,data_static,DS);if(Loader.check_people_item(upeople_id))cb(upeople_id);return}}$.when($.getJSON(file_evo),$.getJSON(file_static)).done(function(evo,global){DS.addPeopleMetricsData(upeople_id,evo[0],DS);DS.addPeopleGlobalData(upeople_id,global[0],DS);if(Loader.check_people_item(upeople_id))cb(upeople_id)}).fail(function(){DS.addPeopleMetricsData(upeople_id,[],DS);DS.addPeopleGlobalData(upeople_id,[],DS); if(Loader.check_people_item(upeople_id))cb(upeople_id)})};function getFilterSuffix(filter){var filter_suffix="""";if(filter===""repos""){filter_suffix=""rep""}else if(filter===""companies""){filter_suffix=""com""}else if(filter===""countries""){filter_suffix=""cou""}else if(filter===""domains""){filter_suffix=""dom""}else if(filter===""projects""){filter_suffix=""prj""}return filter_suffix}Loader.data_load_item_top=function(item,DS,page,cb,filter,optional_filter){var file_top=DS.getDataDir()+""/""+item+""-""+DS.getName();file_top+=""-""+getFilterSuffix(filter)+""-top-"";if(DS.getName()===""scm"")file_top+=""authors"";else if(DS.getName()===""its"")file_top+=""closers"";else if(DS.getName()===""mls"")file_top+=""senders"";else return;file_top+="".json"";if(all_data){file_no_path=file_top.replace(Report.getDataDir()+""/"","""");data=all_data[file_no_path];if(data){if(filter===""companies"")DS.addCompanyTopData(item,data);else if(filter===""repos"")DS.addRepositoryTopData(item,data);if(Loader.check_item(item,filter,optional_filter)){if(!cb.called_item)cb(filter);cb.called_item=true}return}}$.when($.getJSON(file_top)).done(function(top){if(filter===""companies""){DS.addCompanyTopData(item,top)}else if(filter===""repos""){DS.addRepositoryTopData(item,top)}}).fail(function(){if(filter===""companies""){DS.addCompanyTopData(item,[])}else if(filter===""repos""){DS.addRepositoryTopData(item,[])}}).always(function(){if(Loader.check_item(item,filter,optional_filter)){if(!cb.called_item)cb(filter);cb.called_item=true}})};Loader.data_load_item=function(item,DS,page,cb,filter,items_map){var ds_not_supported_countries=[""irc"",""mediawiki""];var ds_not_supported_companies=[""irc"",""mediawiki""];var ds_not_supported_domains=[""irc"",""mediawiki""];var ds_not_supported_repos=[""mediawiki""];var ds_not_supported_projects=[""irc"",""mediawiki""];if(filter===""repos""){if($.inArray(DS.getName(),ds_not_supported_repos)>-1){DS.addRepoMetricsData(item,[],DS);DS.addRepoGlobalData(item,[],DS);return}}else if(filter===""companies""){if($.inArray(DS.getName(),ds_not_supported_companies)>-1){DS.addCompanyMetricsData(item,[],DS);DS.addCompanyGlobalData(item,[],DS);return}}else if(filter===""countries""){if($.inArray(DS.getName(),ds_not_supported_countries)>-1){DS.addCountryMetricsData(item,[],DS);DS.addCountryGlobalData(item,[],DS);return}}else if(filter===""domains""){if($.inArray(DS.getName(),ds_not_supported_domains)>-1){DS.addDomainMetricsData(item,[],DS);DS.addDomainGlobalData(item,[],DS);return}}else if(filter===""projects""){if($.inArray(DS.getName(),ds_not_supported_projects)>-1){DS.addDomainMetricsData(item,[],DS);DS.addDomainGlobalData(item,[],DS);return}}else return;var item_uri=encodeURIComponent(item);var file=DS.getDataDir()+""/""+item_uri+""-"";file+=DS.getName()+""-""+getFilterSuffix(filter);var file_evo=file+""-evolutionary.json"";var file_static=file+""-static.json"";function addData(item,evo,global,DS){if(filter===""repos""){DS.addRepoMetricsData(item,evo,DS);DS.addRepoGlobalData(item,global,DS)}else if(filter===""companies""){DS.addCompanyMetricsData(item,evo,DS);DS.addCompanyGlobalData(item,global,DS)}else if(filter===""countries""){DS.addCountryMetricsData(item,evo,DS);DS.addCountryGlobalData(item,global,DS)}else if(filter===""domains""){DS.addDomainMetricsData(item,evo,DS);DS.addDomainGlobalData(item,global,DS)}else if(filter===""projects""){DS.addProjectMetricsData(item,evo,DS);DS.addProjectGlobalData(item,global,DS)}}function check_data(){if(page!==null){if(Loader.check_filter_page(page,filter)){if(cb.called_page===undefined){cb.called_page={};cb.called_page[filter]=true;cb(filter)}else if(!cb.called_page[filter]){cb(filter);cb.called_page[filter]=true}}}else if(items_map!==null){if(Loader.check_items(items_map,filter)){if(cb.called_map===undefined){cb.called_map={};cb.called_map[filter]=true;cb(filter)}else if(!cb.called_map[filter]){cb(filter);cb.called_map[filter]=true}}}else{if(Loader.check_item(item,filter)){if(cb.called_item===undefined){cb.called_item={};cb.called_item[filter]=true;cb(filter,item)}else if(!cb.called_item[filter]){cb(filter,item);cb.called_item[filter]=true}}}}if(all_data){file_evo_no_path=decodeURIComponent(file_evo.replace(Report.getDataDir()+""/"",""""));file_static_no_path=decodeURIComponent(file_static.replace(Report.getDataDir()+""/"",""""));data_evo=all_data[file_evo_no_path];data_static=all_data[file_static_no_path];if(data_evo&&data_static){addData(item,data_evo,data_static,DS);check_data();return}}$.when($.getJSON(file_evo),$.getJSON(file_static)).done(function(evo,global){addData(item,evo[0],global[0],DS)}).always(function(){check_data()})};function data_load_metrics(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){data_load_file(DS.getDataFile(),DS.setData,DS);data_load_file(DS.getGlobalDataFile(),DS.setGlobalData,DS);if(DS instanceof MLS){data_load_file(DS.getListsFile(),DS.setListsData,DS)}})}function data_load_metrics_definition(){data_load_file(""VizGrimoireJS/data/metrics.json"",Report.setMetricsDefinition)}function data_load_people(){var data_sources=Report.getDataSources();$.each(data_sources,function(i,DS){data_load_file(DS.getPeopleDataFile(),DS.setPeopleData,DS)})}function data_load_people_identities(){data_load_file(Report.getDataDir()+""/people.json"",Report.setPeopleIdentities)}function check_companies_loaded(DS){if(DS.getCompaniesData()===null)return false;return true}function check_repos_loaded(DS){if(DS.getReposData()===null)return false;return true}function check_countries_loaded(DS){if(DS.getCountriesData()===null)return false;return true}function check_domains_loaded(DS){if(DS.getDomainsData()===null)return false;return true}function check_projects_loaded(DS){if(DS.getProjectsData()===null)return false;return true}function check_meta_projects_loaded(){var projects_loaded=0;var projects_data=Report.getProjectsData();var projects_dirs=Report.getProjectsDirs();for(var key in projects_data){projects_loaded++}if(projects_loaded<projects_dirs.length)return false;return true}function check_data_loaded_global(){var check=true;if(Report.getProjectData()===null||Report.getVizConfig()===null)return false;if(Report.getConfig()===null)if(Report.getMarkers()===null)return false;if(Report.getReposMap()===null)return false;if(Report.getConfig()===null)if(!check_meta_projects_loaded())return false;var data_sources=Report.getDataSources();$.each(data_sources,function(index,DS){if(DS.getData()===null){check=false;return false}if(DS.getGlobalData()===null){check=false;return false}if(DS.getGlobalTopData()===null){check=false;return false}if(DS.getDemographicsData().aging===undefined||DS.getDemographicsData().birth===undefined){check=false;return false}if(DS.getName()===""its"")if(DS.getTimeToFixData()===null){check=false;return false}if(DS.getName()===""mls"")if(DS.getTimeToAttentionData()===null){check=false;return false}});return check}Loader.check_data_loaded=function(){var check=true;if(!check_data_loaded_global())return false;var data_sources=Report.getDataSources();var active_reports=[""companies"",""repositories"",""countries"",""domains"",""projects""];if(Report.getConfig()!==null&&Report.getConfig().reports!==undefined)active_reports=Report.getConfig().reports;$.each(data_sources,function(index,DS){if(DS.getPeopleData()===null){check=false;return false}if($.inArray(""companies"",active_reports)>-1)if(!check_companies_loaded(DS)){check=false;return false}if($.inArray(""repositories"",active_reports)>-1)if(!check_repos_loaded(DS)){check=false;return false}if($.inArray(""countries"",active_reports)>-1)if(!check_countries_loaded(DS)){check=false;return false}if($.inArray(""domains"",active_reports)>-1)if(!check_domains_loaded(DS)){check=false;return false}if($.inArray(""projects"",active_reports)>-1)if(!check_projects_loaded(DS)){check=false;return false}if(DS instanceof MLS){if(DS.getListsData()===null){check=false;return false}}});return check};function end_data_load(){if(check_data_loaded_global()){for(var i=0;i<data_global_callbacks.length;i++){data_global_callbacks[i]()}data_global_callbacks=[]}if(Loader.check_data_loaded()){for(var j=0;j<data_callbacks.length;j++){if(data_callbacks[j].called!==true)data_callbacks[j]();data_callbacks[j].called=true}}}})();var DataProcess={};(function(){DataProcess.info=function(){};DataProcess.paginate=function(data,page){if(page===undefined||page===0||isNaN(page))return data;var page_items=[];var psize=Report.getPageSize();var start=(page-1)*psize;for(var i=start;i<psize*page;i++){if(data[i])page_items.push(data[i])}return page_items};DataProcess.convert=function(data,convert,metric_ids){if(convert===""aggregate""){data=DataProcess.aggregate(data,metric_ids)}else if(convert===""substract""){data=DataProcess.substract(data,metric_ids[0],metric_ids[1]);metric_ids=[""substract""]}else if(convert===""substract-aggregate""){data=DataProcess.substract(data,metric_ids[0],metric_ids[1]);metric_ids=[""substract""];data=DataProcess.aggregate(data,metric_ids)}else if(convert===""divide""){data=DataProcess.divide(data,metric_ids[0],metric_ids[1]);metric_ids=[""divide""]}return data};DataProcess.sortGlobal=function(ds,metric_id,kind){if(metric_id===undefined)metric_id=""scm_commits"";var metric=[];var data=[],sorted={};sorted.name=[];sorted[metric_id]=[];var metrics_data=null;if(kind===""companies""){data=ds.getCompaniesData();metrics_data=ds.getCompaniesDataFull()}else if(kind===""repos""){data=ds.getReposData();metrics_data=ds.getReposDataFull()}else if(kind===""countries""){data=ds.getCountriesData()}else if(kind===""domains""){data=ds.getDomainsData();metrics_data=ds.getDomainsDataFull()}else if(kind===""projects""){data=ds.getProjectsData()}if(data===null)return[];if(metrics_data===null)return data;if(metrics_data instanceof Array||metric_id in metrics_data===false)return data;for(var i=0;i<metrics_data[metric_id].length;i++){var value=metrics_data[metric_id][i];if(value===""NA"")value=0;metric.push([metrics_data.name[i],value])}metric.sort(function(a,b){return b[1]-a[1]});$.each(metric,function(id,value){sorted.name.push(value[0]);sorted[metric_id].push(value[1])});return sorted.name};DataProcess.orderItems=function(filter_order){$.each($(""[class^='FilterItems']""),function(id,div){order_by=$(this).data(""order-by"");if(order_by!==undefined){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;var filter=$(this).data(""filter"");if(filter===undefined)return;if(filter!==filter_order)return;Report.log(""Ordering with ""+order_by+"" ""+ds+"" for ""+filter);var data=DataProcess.sortGlobal(DS,order_by,filter);if(filter===""companies"")DS.setCompaniesData(data);if(filter===""repos"")DS.setReposData(data);if(filter===""countries"")DS.setCountriesData(data);if(filter===""domains"")DS.setDomainsData(data);return false}})};DataProcess.mergeConfig=function(config1,config2){var new_config={};$.each(config1,function(entry,value){new_config[entry]=value});$.each(config2,function(entry,value){new_config[entry]=value});return new_config};DataProcess.hideEmail=function(email){var clean=email;if(typeof email==""string""&&email.indexOf(""@"")>-1){clean=email.split(""@"")[0]}return clean};DataProcess.selectPersonName=function(person){var name="""",cname,ctype,i;if(person.identity){for(i=0;i<person.identity.length;i++){cname=person.identity[i];ctype=person.type[i];if(ctype===""name""){if(cname.length>name.length)name=cname}}}else if(person.name){if(person.name.constructor!==Array){person.name=[person.name]}for(i=0;i<person.name.length;i++){cname=person.name[i];if(cname.length>name.length)name=cname}}return name};DataProcess.selectPersonEmail=function(person){var email="""",cemail,ctype;if(person.identity===undefined)return;for(var i=0;i<person.identity.length;i++){cemail=person.identity[i];ctype=person.type[i];if(ctype===""email""){email=cemail}}return email};DataProcess.frameTime=function(history,metrics){var new_history={};var offset_start=-1;var offset_end=-1;var new_offset=0;if(metrics.length===0)return history;if(history[metrics[0]]===undefined)return history;var total=history[metrics[0]].length;var i=0;$.each(metrics,function(id,metric){new_offset=0;for(i=0;i<history[metric].length;i++){if(history[metric][i]===0)new_offset++;else{if(offset_start===-1)offset_start=new_offset;if(new_offset<offset_start)offset_start=new_offset;break}}});$.each(metrics,function(id,metric){new_offset=0;for(i=history[metric].length-1;i>=0;i--){if(history[metric][i]===0)new_offset++;else{if(offset_end===-1)offset_end=new_offset;if(new_offset<offset_end)offset_end=new_offset;break}}});for(var key in history){new_history[key]=[];for(i=0;i<history[key].length;i++){if(i<offset_start)continue;if(i>=total-offset_end)continue;new_history[key].push(history[key][i])}}return new_history};DataProcess.filterDates=function(start_id,end_id,history){var history_dates={};$.each(history,function(name,data){history_dates[name]=[];$.each(data,function(i,value){var id=history.unixtime[i];if(id>start_id)if(!end_id||end_id&&id<=end_id)history_dates[name].push(value)})});return history_dates};DataProcess.filterYear=function(year,history){year=parseInt(year,null);var min_id=new Date(year.toString()).getTime();var max_id=new Date((year+1).toString()).getTime();var history_year=filterDates(min_id,max_id,history);return history_year};DataProcess.fillDates=function(dates_orig,more_dates){if(dates_orig[0].length===0)return more_dates;var new_dates=[[],[]];var i=0;if(dates_orig[0][0]>more_dates[0][0]){for(i=0;i<more_dates[0].length;i++){new_dates[0][i]=more_dates[0][i];new_dates[1][i]=more_dates[1][i]}}for(i=0;i<dates_orig[0].length;i++){pos=new_dates[0].indexOf(dates_orig[0][i]);if(pos===-1){new_dates[0].push(dates_orig[0][i]);new_dates[1].push(dates_orig[1][i])}}if(dates_orig[0][dates_orig[0].length-1]<more_dates[0][more_dates[0].length-1]){for(i=0;i<more_dates[0].length;i++){pos=new_dates[0].indexOf(more_dates[0][i]);if(pos===-1){new_dates[0].push(more_dates[0][i]);new_dates[1].push(more_dates[1][i])}}}return new_dates};DataProcess.fillHistory=function(hist_complete_id,hist_partial){var new_history=[[],[]];for(var i=0;i<hist_complete_id.length;i++){pos=hist_partial[0].indexOf(hist_complete_id[i]);new_history[0][i]=hist_complete_id[i];if(pos!=-1){new_history[1][i]=hist_partial[1][pos]}else{new_history[1][i]=0}}return new_history};DataProcess.fillHistoryLines=function(hist_complete_id,hist_partial){var old_history=[[],[]];var new_history=[[],[]];var lines_history=[];for(var i=0;i<hist_partial.length;i++){old_history[0].push(hist_partial[i][0]);old_history[1].push(hist_partial[i][1])}new_history=DataProcess.fillHistory(hist_complete_id,old_history);for(i=0;i<hist_complete_id.length;i++){lines_history.push([new_history[0][i],new_history[1][i]])}return lines_history};DataProcess.addRelativeValues=function(metrics_data,metric){if(metrics_data[metric]===undefined)return;metrics_data[metric+""_relative""]=[];var added_values=[];$.each(metrics_data[metric],function(index,pdata){var metric_values=pdata.data[1];for(var i=0;i<metric_values.length;i++){if(added_values[i]===undefined)added_values[i]=0;added_values[i]+=metric_values[i]}});$.each(metrics_data[metric],function(index,pdata){var val_relative=[];for(var i=0;i<pdata.data[0].length;i++){if(added_values[i]===0)val_relative[i]=0;else{var rel_val=pdata.data[1][i]/added_values[i]*100;val_relative[i]=rel_val}}metrics_data[metric+""_relative""].push({label:pdata.label,data:[pdata.data[0],val_relative]})})};DataProcess.aggregate=function(data,metrics){var new_data={};if(!(metrics instanceof Array))metrics=[metrics];$.each(data,function(metric,mdata){if($.inArray(metric,metrics)>-1){var metric_agg=[];metric_agg[0]=data[metric][0];for(var i=1;i<data[metric].length;i++){metric_agg[i]=metric_agg[i-1]+data[metric][i]}new_data[metric]=metric_agg}else{new_data[metric]=data[metric]}});return new_data};DataProcess.substract=function(data,metric1,metric2){var new_data={};var substract=[];for(var i=0;i<data[metric1].length;i++){substract[i]=data[metric1][i]-data[metric2][i]}$.each(data,function(metric,mdata){new_data[metric]=data[metric]});new_data.substract=substract;return new_data};DataProcess.divide=function(data,metric1,metric2){var new_data={};var divide=[];for(var i=0;i<data[metric1].length;i++){if(data[metric1][i]===0||data[metric2][i]===0)divide[i]=0;else divide[i]=parseInt(data[metric1][i]/data[metric2][i],null)}$.each(data,function(metric,mdata){new_data[metric]=data[metric]});new_data.divide=divide;return new_data};DataProcess.revomeLastPoint=function(data){var new_data={};$.each(data,function(key,value){new_data[key]=[];for(var i=0;i<data[key].length-1;i++){new_data[key].push(data[key][i])}});return new_data}})();var Utils={};(function(){Utils.paramsInURL=paramsInURL;Utils.isReleasePage=isReleasePage;Utils.filenameInURL=filenameInURL;Utils.createLink=createLink;Utils.createReleaseLink=createReleaseLink;Utils.getParameter=getParameter;$.urlParam=function(name){var results=new RegExp(""[?&]""+name+""=([^&#]*)"").exec(window.location.href);if(results===null){return null}else{return results[1]||0}};function isReleasePage(){if($.urlParam(""release"")===null)return false;else return true}function paramsInURL(){params="""";if(document.URL.split(""?"").length>1){params=document.URL.split(""?"")[1]}return params}function filenameInURL(){aux=document.URL.split(""?"")[0].split(""/"");res=aux[aux.length-1];return res}function createLink(target){url=target;if(paramsInURL().length>0)url+=""?""+paramsInURL();return url}function createReleaseLink(target){url=target;if(isReleasePage()){if(url.indexOf(""?"")>=0){url+=""&release=""+$.urlParam(""release"")}else{url+=""?release=""+$.urlParam(""release"")}}return url}function getParameter(param){if($.urlParam(param)===null)return false;return $.urlParam(param)}})();String.prototype.supplant=function(o){return this.replace(/{([^{}]*)}/g,function(a,b){var r=o[b];return typeof r===""string""||typeof r===""number""?r:a})};var HTMLComposer={};(function(){HTMLComposer.personDSBlock=personDSBlock;HTMLComposer.filterDSBlock=filterDSBlock;HTMLComposer.DSBlock=DSBlock;HTMLComposer.DSBlockProject=DSBlockProject;HTMLComposer.repositorySummaryTable=repositorySummaryTable;HTMLComposer.personSummaryTable=personSummaryTable;HTMLComposer.personName=personName;HTMLComposer.itemName=itemName;HTMLComposer.releaseSelector=releaseSelector;HTMLComposer.sideBarLinks=sideBarLinks;HTMLComposer.overallSummaryBlock=overallSummaryBlock;HTMLComposer.smartLinks=smartLinks;HTMLComposer.TopByPeriod=TopByPeriod;HTMLComposer.companyFilters=companyFilters;function personDSBlock(ds_name,metric_name,ds_realname){var html='<div class=""col-md-12"">';html+='<div class=""well well-small"">';html+='<div class=""row"">';html+='<div class=""col-md-12"">';if(ds_realname===undefined){html+=""<p>""+title4DS(ds_name)+""</p>""}else{html+=""<p>""+title4DS(ds_realname)+""</p>""}html+=""</div>"";html+='<div class=""col-md-3"">';html+='<div class=""PersonSummary"" data-data-source=""'+ds_name+'""></div>';html+=""</div>"";html+='<div class=""col-md-9"">';html+='<div class=""PersonMetrics"" data-data-source=""'+ds_name+'""';html+='data-metrics=""'+metric_name+'"" data-min=""true""';html+='data-frame-time=""true""></div>';html+=""</div>"";html+=""</div>"";html+=""</div>"";html+=""</div>"";return html}function filterDSBlock(ds_name,filter_name,metric_names){var html='<div class=""col-md-12"">';html+='<div class=""row"">';html+='<div class=""col-md-3"">';html+='<div class=""well"">';html+='<div class=""FilterItemSummary"" data-data-source=""'+ds_name+'"" data-filter=""'+filter_name+'""></div>';html+=""</div></div>"";html+='<div class=""col-md-9"">';html+='<div class=""well"">';$.each(metric_names,function(id,metric){html+='<div class=""row""><div class=""col-md-12""></br></br></div></div>';html+='<div class=""row"">';html+='<div class=""col-md-12"">';html+='<div class=""FilterItemMetricsEvol"" data-data-source=""'+ds_name+'""';html+='data-metrics=""'+metric+'"" data-min=""true""';html+='data-filter=""'+filter_name+'"" data-frame-time=""true""></div>';html+=""</div></div>""});html+=""</div></div></div></div>"";return html}function repositorySummaryTable(ds,global_data,id_label){var html=""<table class='table-condensed table-hover'>"";html+='<tr><td colspan=""2""><p class=""subsection-title"">'+title4DS(ds.getName())+""</p></td></tr>"";var html_irow=""<tr><td>"";var html_erow=""</td></tr>"";$.each(global_data,function(id,value){if(ds.getMetrics()[id]){html+=html_irow+ds.getMetrics()[id].name;if(id===""first_date""||id===""last_date""){html+='</td><td class=""numberInTD"">'+value+html_erow}else{html+='</td><td class=""numberInTD"">'+Report.formatValue(value)+html_erow}}else if(id_label[id]){html+=html_irow+id_label[id];if(id===""first_date""||id===""last_date""){html+='</td><td class=""numberInTD"">'+value+html_erow}else{html+='</td><td class=""numberInTD"">'+Report.formatValue(value)+html_erow}}});html+=""</table>"";return html}function personSummaryTable(ds_name,history){var html=""<table class='table-condensed table-hover'>"";html+=""<tr><td>"";html+=""First contribution: </br>"";html+=""&nbsp;&nbsp;""+history.first_date;html+=""</td></tr><tr><td>"";html+=""Last contribution: </br>"";html+=""&nbsp;&nbsp;""+history.last_date;html+=""</td></tr><tr><td>"";if(ds_name==""scm"")html+=""Commits:</br>&nbsp;&nbsp;""+history.scm_commits;else if(ds_name==""its"")html+=""Closed:</br>&nbsp;&nbsp;""+history.its_closed;else if(ds_name==""mls"")html+=""Sent:</br>&nbsp;&nbsp;""+history.mls_sent;else if(ds_name==""irc"")html+=""Sent:</br>&nbsp;&nbsp;""+history.irc_sent;else if(ds_name==""scr""){if(history.scr_closed!==undefined){html+=""Closed:</br>&nbsp;&nbsp;""+history.scr_closed}if(history.scr_submissions!==undefined){html+=""Submissions:</br>&nbsp;&nbsp;""+history.scr_submissions}}html+=""</td></tr>"";html+=""</table>"";return html}function personName(name,email){var html='<p class=""section-title"" style=""margin-bottom:0px;""><i class=""fa fa-user fa-lg""></i> &nbsp;&nbsp;';if(name.length>0)html+=name;else if(email.length>0){if(email.indexOf(""@"")>0)email=email.split(""@"")[0];html+=email}html+=""</p>"";return html}function itemName(text,filter_name){var html='<p class=""section-title"" style=""margin-bottom:0px;"">';if(filter_name===""companies"")html+='<i class=""fa fa-building-o""></i> &nbsp;&nbsp;';html+=text;html+=""</p>"";return html}function title4DS(ds_name){var title="""";if(ds_name===""scm"")title='<i class=""fa fa-code""></i> Source Code Management';else if(ds_name===""scr"")title='<i class=""fa fa-check""></i> Source Code Review';else if(ds_name===""its"")title='<i class=""fa fa-ticket""></i> Issue tracking system';else if(ds_name===""storyboard"")title='<i class=""fa fa-ticket""></i> StoryBoard';else if(ds_name===""mls"")title='<i class=""fa fa-envelope-o""></i> Mailing Lists';else if(ds_name===""irc"")title='<i class=""fa fa-comment-o""></i> IRC Channels';else if(ds_name===""mediawiki"")title='<i class=""fa fa-pencil-square-o""></i> Wiki';else if(ds_name===""releases"")title='<i class=""fa fa-umbrella""></i> Forge Releases';return title}function releaseSelector(current_release,release_names){function get_label(url,labels){label="""";$.each(labels,function(pos,data){if(data[1]===url){label=data[0];return false}});return label}if(release_names.length===0)return"""";var release_names_labels=null;if(release_names[0]instanceof Array){var old_relase_names=[];$.each(release_names,function(pos,data){old_relase_names.push(data[1])});release_names_labels=release_names;release_names=old_relase_names}unsupported=[""irc.html"",""qaforums.html"",""project.html""];ah_label=""&nbsp;All history&nbsp;"";label=current_release;if(label===null)label=ah_label;else{label=decodeURIComponent(label);if(release_names_labels!==null){label=get_label(label,release_names_labels);label=""&nbsp; ""+label+"" &nbsp;""}else{label=""&nbsp; ""+label[0].toUpperCase()+label.substring(1)+"" release &nbsp;""}release_names.reverse().push(ah_label);release_names.reverse()}html='<div class=""input-group-btn"">';html+='<button type=""button"" class=""btn btn-default btn-lg btn-releaseselector dropdown-toggle""';html+='data-toggle=""dropdown"">';html+=label;html+='<span class=""caret""></span>';html+=""</button>"";html+='<ul class=""dropdown-menu pull-left"">';page_name=Utils.filenameInURL();if(unsupported.indexOf(page_name)<0){$.each(release_names,function(id,value){var final_p=[];params=Utils.paramsInURL().split(""&"");for(i=0;i<params.length;i++){sub_value=params[i];if(sub_value.length===0)continue;if(sub_value.indexOf(""release"")===0){if(value!=ah_label)final_p.push(""release=""+value)}else{final_p.push(sub_value)}}if($.urlParam(""release"")===null){final_p.push(""release=""+value)}if(value===ah_label){html+='<li><a href=""'+page_name+""?""+final_p.join(""&"")+'"" data-value=""'+value+'""> '+value+""</a></li>""}else{html+='<li><a href=""'+page_name+""?""+final_p.join(""&"")+'"" data-value=""'+value+'""> ';if(release_names_labels!==null){html+=get_label(value,release_names_labels)+""</li>""}else{html+=value[0].toUpperCase()+value.substring(1)+"" release</a></li>""}}})}else{html+=""<li><i>No releases for this section</i></li>""}html+=""</ul>"";html+=""</div>"";return html}function DSBlock(ds_name,box_labels,box_metrics,ts_metrics){html="""";html+=""<!-- irc -->"";html+='<div class=""row invisible-box"">';blabels=box_labels.split("","");bmetrics=box_metrics.split("","");html+=DSSummaryBox(ds_name,blabels,bmetrics,false,ds_realname);html+='<div class=""col-md-5"">';tsm=ts_metrics.split("","");html+=DSTimeSerie(ds_name,tsm[0],false,ds_realname);html+=""</div>"";html+='<div class=""col-md-5"">';html+=DSTimeSerie(ds_name,tsm[1],false,ds_realname);html+=""</div>"";html+=""</div>"";html+=""<!-- end irc -->"";return html}function DSBlockProject(ds_name,box_labels,box_metrics,ts_metrics,pname){html="""";html+=""<!-- irc -->"";html+='<div class=""row invisible-box"">';blabels=box_labels.split("","");bmetrics=box_metrics.split("","");html+=DSSummaryBox(ds_name,blabels,bmetrics,true);html+='<div class=""col-md-5"">';tsm=ts_metrics.split("","");html+=DSTimeSerie(ds_name,tsm[0],true);html+=""</div>"";html+='<div class=""col-md-5"">';html+=DSTimeSerie(ds_name,tsm[1],true);html+=""</div>"";html+=""</div>"";html+=""<!-- end irc -->"";return html}function linkToPanel(ds_name,ds_realname){if(ds_realname===undefined){target_page=Utils.createLink(ds_name+"".html"")}else{target_page=Utils.createLink(ds_realname+"".html"")}return target_page}function summaryCell(width,label,ds_name,metric,project_flag,ds_realname){var target_page=linkToPanel(ds_name,ds_realname);if(project_flag){widget_name=""ProjectData""}else{widget_name=""GlobalData""}html="""";html+='<div class=""col-xs-'+width+'"">';html+='<div class=""row thin-border"">';html+='<div class=""col-md-12"">'+label+""</div>"";html+=""</div>"";html+='<div class=""row"">';html+='<div class=""col-md-12 medium-fp-number"">';if(project_flag){html+='<span class=""'+widget_name+'""';html+='data-data-source=""'+ds_name+'"" data-field=""'+metric+'""></span>'}else{html+='<a href=""'+target_page+'""> <span class=""'+widget_name+'""';html+='data-data-source=""'+ds_name+'"" data-field=""'+metric+'""></span>';html+=""</a>""}html+=""</div>"";html+=""</div>"";html+=""</div>"";return html}function DSSummaryBox(ds_name,labels,metrics,project_flag,ds_realname){var target_page=linkToPanel(ds_name,ds_realname);if(project_flag){widget_name=""ProjectData""}else{widget_name=""GlobalData""}html="""";html+=""<!-- summary box-->"";html+='<div class=""col-md-2"">';html+='<div class=""well well-small"">';html+='<div class=""row thin-border"">';html+='<div class=""col-md-12"">'+labels[0]+""</div>"";html+=""</div>"";html+='<div class=""row grey-border"">';html+='<div class=""col-md-12 big-fp-number"">';if(ds_name===""releases"")target_page=Utils.createLink(""forge.html"");if(project_flag){html+='<span class=""'+widget_name+'""';html+='data-data-source=""'+ds_name+'"" data-field=""'+metrics[0]+'""></span>'}else{html+='<a href=""'+target_page+'""> <span class=""'+widget_name+'""';html+='data-data-source=""'+ds_name+'"" data-field=""'+metrics[0]+'""></span>';html+=""</a>""}html+=""</div>"";html+=""</div>"";html+='<div class=""row"" style=""padding: 5px 0px 0px 0px;"">';if(labels.length===2&&metrics.length===2){html+=summaryCell(""12"",labels[1],ds_name,metrics[1],project_flag,ds_realname)}else if(labels.length===3&&metrics.length===3){html+=summaryCell(""6"",labels[1],ds_name,metrics[1],project_flag,ds_realname);html+=summaryCell(""6"",labels[2],ds_name,metrics[2],project_flag,ds_realname)}else if(labels.length===4&&metrics.length===4){html+=summaryCell(""4"",labels[1],ds_name,metrics[1],project_flag,ds_realname);html+=summaryCell(""4"",labels[2],ds_name,metrics[2],project_flag,ds_realname);html+=summaryCell(""4"",labels[3],ds_name,metrics[3],project_flag,ds_realname)}html+=""</div>"";html+=""</div>"";html+=""</div>"";html+=""<!-- end summary box -->"";return html}function DSTimeSerie(ds_name,metric,project_flag,ds_realname){if(project_flag){ts_widget_name=""FilterItemMetricsEvol"";trend_widget_name=""FilterItemMicrodashText"";filter_name=""projects""}else{ts_widget_name=""MetricsEvol"";trend_widget_name=""MicrodashText"";filter_name=""""}html="""";html+='<div class=""well well-small"">';html+='<div class=""'+ts_widget_name+'"" data-data-source=""'+ds_name+'""';html+=' data-filter=""'+filter_name+'""';if(project_flag){html+=' data-frame-time=""true""'}html+=' data-metrics=""'+metric+'"" data-min=""true"" style=""height: 100px;""';html+=' data-light-style=""true""></div>';if(project_flag){html+=' <span class=""'+trend_widget_name+'""';html+=' data-filter=""'+filter_name+'""';html+=' data-metric=""'+metric+'""></span>'}else{if(ds_realname===undefined){html+='<a href=""'+ds_name+'.html"" style=""color: black;"">'}else{html+='<a href=""'+ds_realname+'.html"" style=""color: black;"">'}html+=' <span class=""'+trend_widget_name+'""';html+=' data-filter=""'+filter_name+'""';html+=' data-metric=""'+metric+'""></span>';html+=""</a>""}html+=""</div>"";return html}function sideBarLinks(icon_text,title,ds_name,elements){text={companies:""Companies"",""companies-summary"":""Companies summary"",contributors:""Contributors"",countries:""Countries"",domains:""Domains"",projects:""Projects"",repos:""Repositories"",tags:""Tags"",states:""States""};html="""";html+='<li class=""dropdown"">';html+='<a href=""#"" class=""dropdown-toggle"" data-toggle=""dropdown"">';html+='<i class=""fa '+icon_text+'""></i>&nbsp;'+title+' <b class=""caret""></b></a>';html+='<ul class=""dropdown-menu navmenu-nav"">';var target_page="""";if(Utils.isReleasePage()){target_page=Utils.createReleaseLink(ds_name+"".html"")}else{target_page=ds_name+"".html""}html+='<li><a href=""'+target_page+'"">&nbsp;Overview</a></li>';$.each(elements,function(id,value){if(Utils.isReleasePage()){target_page=Utils.createReleaseLink(ds_name+""-""+value+"".html"")}else{target_page=ds_name+""-""+value+"".html""}if(text.hasOwnProperty(value)){var label=text[value];if(value===""repos""){if(ds_name==""storyboard""){ds_name=""its""}var DS=Report.getDataSourceByName(ds_name);label=DS.getLabelForRepositories();label=label.charAt(0).toUpperCase()+label.slice(1)}html+='<li><a href=""'+target_page+'"">&nbsp;'+label+""</a></li>""}else{html+='<li><a href=""'+target_page+'"">&nbsp;'+value+""</a></li>""}});html+=""</ul></li>"";return html}function overallSummaryBlock(){html="""";html+=""<!-- summary bar -->"";html+='<div class=""capped-box overall-summary "">';html+='<div class=""stats-switcher-viewport js-stats-switcher-viewport"">';html+='<div class=""row numbers-summary"">';html+='<div class=""col-xs-3""><a href=""'+Utils.createReleaseLink(""scm.html"")+'""><span class=""GlobalData"" ';html+='data-data-source=""scm"" data-field=""scm_commits""></span></a> commits</div>';html+='<div class=""col-xs-3""><a href=""'+Utils.createReleaseLink(""scm.html"")+'""><span class=""GlobalData"" ';html+='data-data-source=""scm"" data-field=""scm_authors""></span></a> developers ';html+=""</div>"";html+='<div class=""col-xs-3""><a href=""'+Utils.createReleaseLink(""its.html"")+'""><span class=""GlobalData"" ';html+='data-data-source=""its"" data-field=""its_opened""></span></a> tickets</div>';html+='<div class=""col-xs-3""><a href=""'+Utils.createReleaseLink(""mls.html"")+'""><span class=""GlobalData"" ';html+='data-data-source=""mls"" data-field=""mls_sent""></span></a> mail messages ';html+=""</div>"";html+=""</div>"";html+=""</div>"";html+=""</div>"";html+=""<!-- end of summary bar -->"";return html}function smartLinks(target_page,label){html="""";link_exists=false;try{fname=target_page.split(""."")[0];section=fname.split(""-"")[0];subsection=fname.split(""-"")[1];var mele=Report.getMenuElements();if(mele[section].indexOf(subsection)>=0)link_exists=true; if(Utils.isReleasePage()&&link_exists){link_to=Utils.createReleaseLink(target_page);html='<a href=""'+link_to+'"">'+label+""</a>""}else if(link_exists){html='<a href=""'+target_page+'"">'+label+""</a>""}else{html=label}}catch(err){html=label}return html}function TopByPeriod(ds_name,metric,npeople,is_release){if(is_release){periods=[""""]}else{periods=[""last month"",""last year"",""""]}width=12/periods.length;html='<div class=""row"">';$.each(periods,function(id,value){html+='<div class=""col-md-'+width+'"">';html+='<div class=""Top"" data-data-source=""'+ds_name+'"" data-metric=""'+metric+'""';html+=' data-period=""'+value+'"" data-limit=""'+npeople+'"" data-people_links=""true""></div>';html+=""</div>""});html+=""</div>"";return html}var defaultFilterValues={scm:{metric_names:""commits+authors"",order_by:""commits_365""},its:{metric_names:""closed+closers"",order_by:""closed_365""}};function getFilterName(ds_name,metric_one,metric_two){filters={scm:{company:{country:""SCM by country""}},its:{company:{country:""ITS by country""}}};return filters[ds_name][metric_one][metric_two]}function companyFilters(company_name){var html="""",filter_ds={};var mele=Report.getMenuElements();var menu_filters=mele.filter;if(menu_filters===undefined){return html}$.each(menu_filters,function(id,value){var ds_name=value.split("":"")[0],combo=value.split("":"")[1],mylen;if(Object.keys(filter_ds).indexOf(combo)<0){filter_ds[combo]=[]}mylen=filter_ds[combo].length;filter_ds[combo][mylen]=ds_name});$.each(Object.keys(filter_ds),function(id,value){switch(value){case""company+country"":$.each(filter_ds[value],function(subid,ds_name){if(subid===0){html='<div class=""btn-group"">'+'<button type=""button"" class=""btn btn-default dropdown-toggle"" data-toggle=""dropdown"" aria-expanded=""false"">'+'<i class=""fa fa-globe""></i> Activity by country <span class=""caret""></span>'+""</button>""+'<ul class=""dropdown-menu"" role=""menu"">'}var aux_obj={};aux_obj.company_name=company_name;aux_obj.ds_name=ds_name;aux_obj.value=value;aux_obj.metric_names=defaultFilterValues[ds_name].metric_names;aux_obj.order_by=defaultFilterValues[ds_name].order_by;aux_obj.filter_name=getFilterName(ds_name,value.split(""+"")[0],value.split(""+"")[1]);var aux_html='<li><a href=""'+""filter.html?filter_by_item=company&filter_item=""+""{company_name}""+""&filter_ds_name={ds_name}""+""&filter_names={value}""+""&filter_metric_names={metric_names}""+""&filter_order_by={order_by}""+'"">{filter_name}</a></button></li>';html+=aux_html.supplant(aux_obj);if(subid===filter_ds[value].length-1){html+=""</ul></div>""}})}});return html}})();var Convert={};(function(){Convert.convertMicrodashText=function(){var divs=$("".MicrodashText"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var metric=$(this).data(""metric"");var show_name=$(this).data(""name"");var ds=Report.getMetricDS(metric)[0];if(ds===undefined)return;var total=ds.getGlobalData()[metric];var html='<div class=""row"">';if(show_name){html+='<div class=""col-xs-3"">';html+='<span class=""dayschange"">'+ds.basic_metrics[metric].name+""</span>"";html+=""</div>""}$.each([365,30,7],function(index,period){var column=ds.getMetrics()[metric].column;var value=ds.getGlobalData()[metric+""_""+period];var netvalue=ds.getGlobalData()[""diff_net""+column+""_""+period];var percentagevalue=ds.getGlobalData()[""percentage_""+column+""_""+period];percentagevalue=Math.round(percentagevalue*10)/10;if(value===undefined)return;var str_percentagevalue="""";if(percentagevalue===0){str_percentagevalue=Math.abs(percentagevalue)}else if(netvalue>0){str_percentagevalue=""+""+percentagevalue}else if(netvalue<0){str_percentagevalue=""-""+Math.abs(percentagevalue)}if(show_name){html+='<div class=""col-xs-3"">'}else{html+='<div class=""col-xs-4"">'}html+='<span class=""dayschange"">Last '+period+"" days:</span>"";html+="" ""+Report.formatValue(value)+""<br>"";if(percentagevalue===0){html+='<i class=""fa fa-arrow-circle-right""></i> <span class=""zeropercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}else if(netvalue>0){html+='<i class=""fa fa-arrow-circle-up""></i> <span class=""pospercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}else if(netvalue<0){html+='<i class=""fa fa-arrow-circle-down""></i> <span class=""negpercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}html+=""</div><!--col-xs-4-->""});html+=""</div><!--row-->"";$(div).append(html)})}};Convert.convertMicrodash=function(){var divs=$("".Microdash"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var metric=$(this).data(""metric"");var text=$(this).data(""text"");var ds=Report.getMetricDS(metric)[0];var total=ds.getGlobalData()[metric];var html=""<div>"";html+='<div style=""float:left"">';html+='<span class=""medium-fp-number"">'+Report.formatValue(total);html+=""</span> ""+ds.getMetrics()[metric].name;html+=""</div>"";html+='<div id=""Microdash"" '+'class=""MetricsEvol"" data-data-source=""'+ds.getName()+'"" data-metrics=""'+metric+'"" data-min=true style=""margin-left:10px; float:left;width:100px; height:25px;""></div>';html+='<div style=""clear:both""></div><div>';$.each([365,30,7],function(index,period){var column=ds.getMetrics()[metric].column;var netvalue=ds.getGlobalData()[""diff_net""+column+""_""+period];var percentagevalue=ds.getGlobalData()[""percentage_""+column+""_""+period];var value=ds.getGlobalData()[metric+""_""+period];if(value===undefined)return;html+=""<span class='dayschange'>""+period+"" Days Change</span>:""+Report.formatValue(value)+""&nbsp;"";if(netvalue===0){html+=""""}else if(netvalue>0){html+='<i class=""icon-circle-arrow-up""></i>';html+=""<small>(+""+percentagevalue+""%)</small>&nbsp;""}else if(netvalue<0){html+='<i class=""icon-circle-arrow-down""></i>';html+=""<small>(-""+Math.abs(percentagevalue)+""%)</small>&nbsp;""}});html+=""</div>"";html+=""<div>"";$(div).append(html)})}};function getProjectTitle(project_id,hierarchy){if(hierarchy.hasOwnProperty(project_id)&&hierarchy[project_id].title){return hierarchy[project_id].title}else{return undefined}}function compareProjectTitles(a,b){if(a.project_id<b.project_id){return-1}else if(a.project_id>b.project_id){return 1}else{return 0}}function getParentProjects(project_id,hierarchy){var parent=[];var iterate_p=project_id;var parent_id="""";var aux={};while(hierarchy[iterate_p].hasOwnProperty(""parent_project"")){parent_id=hierarchy[iterate_p].parent_project;aux=hierarchy[parent_id];aux.project_id=parent_id;parent.push(aux);iterate_p=parent_id}return parent.reverse()}function getChildrenProjects(project_id,hierarchy){var children=[];var aux={};$.each(hierarchy,function(id,p){if(hierarchy[id].parent_project===project_id){aux=hierarchy[id];aux.project_id=id;children.push(aux)}});children.sort(compareProjectTitles);return children}function composePBreadcrumbsHTMLlast(project_id,children,hierarchy){var html="""";var clen=children.length;if(clen>0){children_sort=[];children_names=[];$.each(children,function(id,value){children_names.push(value.title)});children_names=children_names.sort();$.each(children_names,function(id,name){$.each(children,function(id,value){if(name===value.title){children_sort.push(value);return false}})});children=children_sort;html+='<li class=""dropdown"">';html+='<span data-toggle=""tooltip"" title=""Project name""> '+getProjectTitle(project_id,hierarchy)+""</span>"";html+='&nbsp;<a class=""dropdown-toggle"" data-toggle=""dropdown"" href=""#"">';html+='<span data-toggle=""tooltip"" title=""Select subproject"" class=""badge""> '+clen+"" Subprojects </span></a>"";html+='<ul class=""dropdown-menu scrollable-menu"">';$.each(children,function(id,value){gchildren=getChildrenProjects(value.project_id,hierarchy);if(gchildren.length>0){html+='<li><a href=""project.html?project='+value.project_id+'"">'+value.title+'&nbsp;&nbsp;<span data-toggle=""tooltip"" title=""Number of suprojects"" class=""badge"">'+gchildren.length+'&nbsp;<i class=""fa fa-rocket""></i></span></a></li>'}else{html+='<li><a href=""project.html?project='+value.project_id+'"">'+value.title+""</a></li>""}});html+='<li class=""divider""></li>';html+='<li><a href=""./project_map.html""><i class=""fa fa-icon fa-sitemap""></i> Projects treemap</a></li>';html+=""</ul></li>""}else{html+=""<li>""+getProjectTitle(project_id,hierarchy)+""</li>""}return html}function composeProjectBreadcrumbs(project_id){var html='<ol class=""breadcrumbtitle"">';var hierarchy=Report.getProjectsHierarchy();if(hierarchy.length===0){return""""}if(project_id===undefined){project_id=""root""}var children=getChildrenProjects(project_id,hierarchy);var parents=getParentProjects(project_id,hierarchy);if(parents.length>0){$.each(parents,function(id,value){if(value.parent_project){html+='<li><a href=""project.html?project='+value.project_id+'"">'+value.title+""</a></li>""}else{html+='<li><a href=""./"">'+value.title+""</a></li>""}})}html+=composePBreadcrumbsHTMLlast(project_id,children,hierarchy);html+=""</ol>"";return html}function escapeString(string){var aux="""";aux=string.replace("" "",""_"");aux=aux.toLowerCase();return aux}function composeHTMLNestedProjects(project_id,children,hierarchy){var html="""";var clen=children.length;var epid=project_id;var divid=epid.replace(""."","""");if(clen>0){html+=""<li>"";html+='<a href=""project.html?project='+epid+'"">'+getProjectTitle(project_id,hierarchy)+""</a>"";html+='&nbsp;<a data-toggle=""collapse"" data-parent=""#accordion"" href=""#collapse'+divid+'"">';html+='<span class=""badge"">'+clen+""&nbsp;subprojects</span></a>"";html+='<div id=""collapse'+divid+'"" class=""panel-collapse collapse""><ul>';$.each(children,function(id,value){gchildren=getChildrenProjects(value.project_id,hierarchy);html+=composeHTMLNestedProjects(value.project_id,gchildren,hierarchy)});html+=""</ul></li>""}else{html+='<li><a href=""project.html?project='+project_id+'"">'+getProjectTitle(project_id,hierarchy)+""</a></li>""}return html}function composeProjectMap(){var html=""<ul>"";var hierarchy=Report.getProjectsHierarchy();if(hierarchy.length===0){return""""}project_id=""root"";var children=getChildrenProjects(project_id,hierarchy);var parents=getParentProjects(project_id,hierarchy);$.each(children,function(id,value){grandchildren=getChildrenProjects(value.project_id,hierarchy);html+=composeHTMLNestedProjects(value.project_id,grandchildren,hierarchy)});html+=""</ul>"";return html}function getSectionName4Release(){var result=[];var sections={data_sources:""Data sources"",project_map:""Project map"",people:""Contributor"",company:""Company"",country:""Country"",domain:""Domain"",""scm-companies"":""Activity on code repositories by companies"",""mls-companies"":""Activity on mailing lists by companies"",""its-companies"":""Activity on issue trackers by companies""};url_no_params=document.URL.split(""?"")[0];url_tokens=url_no_params.split(""/"");var section=url_tokens[url_tokens.length-1].split(""."")[0];if(section===""project""||section===""index""||section===""release""||section===""""){return[]}else{if(sections.hasOwnProperty(section)){result.push([section,sections[section]])}else{return[[""#"",""Unavailable section name""]]}return result}}function getSectionName(){var result=[];var sections={mls:""MLS overview"",irc:""IRC overview"",its:""ITS overview"",storyboard:""Storyboard overview"",qaforums:""QA Forums overview"",scr:""Code Review overview"",scm:""SCM overview"",wiki:""Wiki overview"",downloads:""Downloads"",forge:""Forge releases"",demographics:""Demographics"",data_sources:""Data sources"",project_map:""Project map"",people:""Contributor"",company:""Company"",country:""Country"",domain:""Domain"",release:""Companies analysis by release"",project_comparison:""Project comparison""};var filters={companies:""Activity by companies"",contributors:""Activity by contributors"",countries:""Activity by countries"",domains:""Activity by domains"",projects:""Activity by project"",repos:""Activity by repositories"",states:""Activity by states"",tags:""Activity by tags""};var filters2={repository:""Repository"",countries:""Activity by countries""};url_no_params=document.URL.split(""?"")[0];url_tokens=url_no_params.split(""/"");var section=url_tokens[url_tokens.length-1].split(""."")[0];if(section===""project""||section===""index""||section===""""){return[]}else if(section===""filter""){var filter_by=$.urlParam(""filter_by_item"");var filter_names=$.urlParam(""filter_names"");switch(filter_names){case""company+country"":result=[[""company"",""Company""],[""Activity by country and company"",""Activity by country and company""]]}return result}else{var s_tokens=section.split(""-"");if(s_tokens[0]===""repository""){ds_name=$.urlParam(""ds"");s_tokens=[ds_name,""repos"",""repository""]}if(sections.hasOwnProperty(s_tokens[0])){result.push([s_tokens[0],sections[s_tokens[0]]]);if(s_tokens.length>0){if(filters.hasOwnProperty(s_tokens[1])){result.push([s_tokens[0]+""-""+s_tokens[1],filters[s_tokens[1]]]);if(s_tokens.length>2){if(filters2.hasOwnProperty(s_tokens[2])){result.push([s_tokens[0],filters2[s_tokens[2]]])}}}}}else{return[[""#"",""Unavailable section name""]]}return result}}function isURLRelease(){if($.urlParam(""release"")!==null&&$.urlParam(""release"").length>0)return true;else return false}function composeSideBar(project_id){if(project_id===undefined){project_id=""root""}var html="""";var html_extra="""";html+='<ul class=""nav navmenu-nav"">';var mele=Report.getMenuElements();if(Utils.isReleasePage()){if(Report.getMenuElementsReleases()!==undefined){mele=Report.getMenuElementsReleases()}}if(project_id===""root""){if(mele.hasOwnProperty(""scm"")){aux=mele.scm;aux_html=HTMLComposer.sideBarLinks(""fa-code"",""Source code management"",""scm"",aux);html+=aux_html}if(mele.hasOwnProperty(""scr"")){aux=mele.scr;aux_html=HTMLComposer.sideBarLinks(""fa-check"",""Code review"",""scr"",aux);html+=aux_html}if(mele.hasOwnProperty(""its"")){aux=mele.its;aux_html=HTMLComposer.sideBarLinks(""fa-ticket"",""Tickets"",""its"",aux);html+=aux_html}if(mele.hasOwnProperty(""its_1"")){aux=mele.its_1;aux_html=HTMLComposer.sideBarLinks(""fa-ticket"",""Tickets 1"",""its_1"",aux);html+=aux_html}if(mele.hasOwnProperty(""storyboard"")){aux=mele.storyboard;aux_html=HTMLComposer.sideBarLinks(""fa-ticket"",""Storyboard"",""storyboard"",aux);html+=aux_html}if(mele.hasOwnProperty(""mls"")){aux=mele.mls;aux_html=HTMLComposer.sideBarLinks(""fa-envelope-o"",""Mailing lists"",""mls"",aux);html+=aux_html}if(mele.hasOwnProperty(""qaforums"")){aux=mele.qaforums;aux_html=HTMLComposer.sideBarLinks(""fa-question"",""Q&A Forums"",""qaforums"",aux);html+=aux_html}if(mele.hasOwnProperty(""irc"")){aux=mele.irc;aux_html=HTMLComposer.sideBarLinks(""fa-comment-o"",""IRC"",""irc"",aux);html+=aux_html}if(mele.hasOwnProperty(""downloads"")){aux=mele.downloads;aux_html=HTMLComposer.sideBarLinks(""fa-download"",""Downloads"",""downloads"",aux);html+=aux_html}if(mele.hasOwnProperty(""forge"")){aux=mele.forge;aux_html=HTMLComposer.sideBarLinks(""fa-umbrella"",""Forge releases"",""forge"",aux);html+=aux_html}if(mele.hasOwnProperty(""wiki"")){aux=mele.wiki;aux_html=HTMLComposer.sideBarLinks(""fa-pencil-square-o"",""Wiki"",""wiki"",aux);html+=aux_html}if(mele.hasOwnProperty(""studies"")){aux=mele.studies;html+='<li class=""dropdown"">';html+='<a href=""#"" class=""dropdown-toggle"" data-toggle=""dropdown"">';html+='<i class=""fa fa-lightbulb-o""></i>&nbsp;Studies <b class=""caret""></b></a>';html+='<ul class=""dropdown-menu navmenu-nav"">';if(aux.indexOf(""demographics"")>=0){html+='<li><a href=""demographics.html"">&nbsp;Demographics</a></li>'}if(aux.indexOf(""release"")>=0){aux=Report.getReleaseNames().reverse();latest_release=aux[0];html+='<li><a href=""release.html?release='+latest_release+'"">&nbsp;Companies by release</a></li>'}var e_studies=mele.studies_extra;if(e_studies){$.each(e_studies,function(id,value){var name,url;name=value[0];url=value[1];html+='<li><a href=""'+url+'"">&nbsp;'+name+""</a></li>""})}html+=""</ul></li>""}if(Utils.isReleasePage()===true){current_release=$.urlParam(""release"");html+='<li><a href=""data_sources.html?release='+current_release+'""><i class=""fa fa-database""></i> Data sources</a></li>';if(mele.hasOwnProperty(""project_map"")){html+='<li><a href=""project_map.html?release='+current_release+'""><i class=""fa fa-icon fa-sitemap""></i> Project map</a></li>'}}else{html+='<li><a href=""data_sources.html""><i class=""fa fa-database""></i> Data sources</a></li>';if(mele.hasOwnProperty(""project_map"")){html+='<li><a href=""project_map.html""><i class=""fa fa-icon fa-sitemap""></i> Project map</a></li>'}}if(mele.hasOwnProperty(""extra"")){aux=mele.extra;html_extra+='<li class=""sidemenu-divider""></li>';html_extra+='<li class=""sidemenu-smallheader"">More links:</li>';$.each(aux,function(id,value){html_extra+='<li><a href=""'+value[1]+'"">&nbsp;'+value[0]+""</a></li>""})}html+=html_extra}html+=""</ul>"";return html}Convert.convertSideBar=function(project_id){var divs=$("".SideNavBar"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if(!div.id)div.id=""SideNavBar"";var label;if(project_id){label=Report.cleanLabel(project_id)}var htmlaux=composeSideBar(label);$(""#""+div.id).append(htmlaux);data=Report.getProjectData();$("".report_name"").text(data.project_name);if(Utils.isReleasePage())$("".report_name"").attr(""href"",""./?release=""+$.urlParam(""release""))})}};Convert.convertProjectNavBar=function(project_id){var divs=$("".ProjectNavBar"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if(!div.id)div.id=""ProjectNavBar"";var label;if(project_id){label=Report.cleanLabel(project_id)}var htmlaux=composeProjectBreadcrumbs(label);$(""#""+div.id).append(htmlaux)})}};Convert.convertNavbar=function(){$.get(Report.getHtmlDir()+""navbar.html"",function(navigation){$(""#Navbar"").html(navigation);var project_id=Report.getParameterByName(""project"");Convert.convertProjectNavBar(project_id);Convert.convertReleaseSelector();Convert.convertSideBar(project_id)})};Convert.convertReleaseSelector=function(){var releases=Report.getReleaseNames();if(releases===undefined){return}if(releases.length>0){var divs=$("".ReleaseSelector"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if(!div.id)div.id=""ReleaseSelector""+getRandomId();var htmlaux=HTMLComposer.releaseSelector($.urlParam(""release""),releases);$(""#""+div.id).append(htmlaux)})}}};function composeSectionBreadCrumb(project_id){var html='<ol class=""breadcrumb"">';data=Report.getProjectData();document.title=data.project_name+"" Dashboard"";if(project_id===undefined){var subsects_b=getSectionName();var params=Utils.paramsInURL();if(subsects_b.length>0){html+='<li><a href=""./';if(Utils.isReleasePage())html+=""?release=""+$.urlParam(""release"");html+='"">Project Overview</a></li>';var cont_b=1;$.each(subsects_b,function(id,value){if(subsects_b.length===cont_b){html+='<li class=""active"">'+value[1]+""</li>"";document.title=value[1]+"" | ""+data.project_name+"" Dashboard""}else{if(Utils.isReleasePage()){html+='<li><a href=""'+value[0]+"".html"";html+=""?release=""+$.urlParam(""release"")+'"">';html+=value[1]+""</a></li>""}else{if(value[0]===""company""){var get_param=$.urlParam(""filter_item"");html+='<li><a href=""'+value[0]+"".html?company=""+get_param+'"">'+get_param[0].toUpperCase()+get_param.slice(1)+""</a></li>""}else{html+='<li><a href=""'+value[0]+'.html"">'+value[1]+""</a></li>""}}}cont_b+=1})}else{html+='<li class=""active"">Project Overview</li>';document.title=""Project Overview | ""+data.project_name+"" Dashboard""}}else{html+=""<li> ""+getSectionName()+""</li>"";document.title=getSectionName()+"" | ""+data.project_name+"" Dashboard""}html+=""</ol>"";return html}Convert.convertSectionBreadcrumb=function(project_id){var divs=$("".SectionBreadcrumb"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if(!div.id)div.id=""SectionBreadcrumb"";var label;if(project_id){label=Report.cleanLabel(project_id)}var htmlaux=composeSectionBreadCrumb(label);$(""#""+div.id).append(htmlaux)})}};Convert.convertProjectMap=function(){var divs=$("".ProjectMap"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if(!div.id)div.id=""ProjectMap"";var label;var htmlaux=composeProjectMap();$(""#""+div.id).append(htmlaux)})}};Convert.convertFooter=function(){$.get(Report.getHtmlDir()+""footer.html"",function(footer){$(""#Footer"").html(footer);$(""#vizjs-lib-version"").append(vizjslib_git_tag)})};Convert.convertSummary=function(){div_param=""Summary"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;div.id=ds+""-Summary"";DS.displayGlobalSummary(div.id)})}};function composeDropDownRepo(DS){var repository=Report.getParameterByName(""repository"");if(repository&&$.inArray(repository,DS.getReposData())<0)return"""";var dsname=DS.getName();var section="""";var label_repo=DS.getLabelForRepository();var label_repo_plural=DS.getLabelForRepositories();if(repository!==undefined){section=repository}else{section=""All ""+label_repo_plural}html='<div class=""row""><span class=""col-md-12"">';html='<ol class=""filterbar""><li>Filtered by '+label_repo+"":&nbsp;&nbsp;</li>"";html+='<li><div class=""dropdown""><button class=""btn btn-default dropdown-toggle"" ';html+='type=""button"" id=""dropdownMenu1"" data-toggle=""dropdown""> '+section+"" "";html+='<span class=""caret""></span></button>';html+='<ul class=""dropdown-menu scroll-menu"" role=""menu"" aria-labelledby=""dropdownMenu1"">';if(repository){html+='<li role=""presentation""><a role=""menuitem"" tabindex=""-1"" href=""'+dsname+'-contributors.html"">';html+=""All ""+label_repo_plural;html+=""</a></li>""}var repo_names=DS.getReposData();repo_names.sort();$.each(repo_names,function(id,value){if(value===repository)return;html+='<li role=""presentation""><a role=""menuitem"" tabindex=""-1"" href=""?repository=';html+=value;html+='"">';html+=value;html+=""</a></li>""});html+=""</ul></div></li></ol>"";html+=""</span></div>"";return html}Convert.convertRepositorySelector=function(){var divs=$("".repository-selector"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;div.id=ds+""-repository-selector"";var htmlaux=composeDropDownRepo(DS);$(""#""+div.id).append(htmlaux)})}};function displayReportData(){data=Report.getProjectData();document.title=data.project_name+"" Report by Bitergia"";if(data.title)document.title=data.title;$("".report_date"").text(data.date);$("".report_name"").text(data.project_name);str=data.blog_url;if(str&&str.length>0){$(""#blogEntry"").html(""<br><a href='""+str+""'>Blog post with some more details</a>"");$("".blog_url"").attr(""href"",data.blog_url)}else{$(""#more_info"").hide()}str=data.producer;if(str&&str.length>0){$(""#producer"").html(str)}else{$(""#producer"").html(""<a href='http://bitergia.com'>Bitergia</a>"")}$("".project_name"").text(data.project_name);$(""#project_url"").attr(""href"",data.project_url)}Convert.convertRefcard=function(){$.when($.get(Report.getHtmlDir()+""refcard.html""),$.get(Report.getHtmlDir()+""project-card.html"")).done(function(res1,res2){refcard=res1[0];projcard=res2[0];$(""#Refcard"").html(refcard);displayReportData();$.each(Report.getProjectsData(),function(prj_name,prj_data){var new_div=""card-""+prj_name.replace(""."","""").replace("" "","""");$(""#Refcard #projects_info"").append(projcard);$(""#Refcard #projects_info #new_card"").attr(""id"",new_div);$.each(Report.getDataSources(),function(i,DS){if(DS.getProject()!==prj_name){$(""#""+new_div+"" .""+DS.getName()+""-info"").hide();return}DS.displayData(new_div)});$(""#""+new_div+"" #project_name"").text(prj_name);if(Report.getProjectsDirs.length>1)$(""#""+new_div+"" .project_info"").append(' <a href=""VizGrimoireJS/browser/index.html?data_dir=../../'+prj_data.dir+'"">Report</a>');$(""#""+new_div+"" #project_url"").attr(""href"",prj_data.url)})})};Convert.convertGlobalData=function(){var divs=$("".GlobalData"");if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;var data=DS.getGlobalData();var key=$(this).data(""field"");$(this).text(Report.formatValue(data[key],key))})}};Convert.convertProjectData=function(){var divs=$("".ProjectData"");var p=Report.getParameterByName(""project"");if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;var data=DS.getProjectsGlobalData()[p];if(data===undefined){return}var key=$(this).data(""field"");$(this).text(Report.formatValue(data[key],key))})}};Convert.convertRadarActivity=function(){var div_param=""RadarActivity"";var divs=$(""#""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty()});Viz.displayRadarActivity(div_param)}};Convert.convertRadarCommunity=function(){var div_param=""RadarCommunity"";var divs=$(""#""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty()});Viz.displayRadarCommunity(""RadarCommunity"")}};Convert.convertTreemap=function(){var div_param=""Treemap"";var divs=$(""#""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty()});var file=$(""#Treemap"").data(""file"");$(""#Treemap"").empty();Viz.displayTreeMap(""Treemap"",file)}};Convert.convertBubbles=function(){div_param=""Bubbles"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;if(DS.getData().length===0)return;var radius=$(this).data(""radius"");div.id=ds+""-Bubbles"";DS.displayBubbles(div.id,radius)})}};function loadHTMLEvolParameters(htmldiv,config_viz){config_viz.help=true;var help=$(htmldiv).data(""help"");if(help!==undefined)config_viz.help=help;config_viz.show_legend=false;if($(htmldiv).data(""frame-time""))config_viz.frame_time=true;config_viz.graph=$(htmldiv).data(""graph"");if($(htmldiv).data(""min"")){config_viz.show_legend=false;config_viz.show_labels=true;config_viz.show_grid=true;config_viz.help=false}if($(htmldiv).data(""legend""))config_viz.show_legend=true;config_viz.ligth_style=false;if($(htmldiv).data(""light-style"")){config_viz.light_style=true}if($(htmldiv).data(""custom-title"")){config_viz.custom_title=$(htmldiv).data(""custom-title"")}if(config_viz.help&&$(htmldiv).data(""custom-help"")){config_viz.custom_help=$(htmldiv).data(""custom-help"")}else{config_viz.custom_help=""""}if($(htmldiv).data(""repo-filter"")){config_viz.repo_filter=$(htmldiv).data(""repo-filter"")}var start=$(htmldiv).data(""start"");if(start)config_viz.start_time=start;var end=$(htmldiv).data(""end"");if(end)config_viz.end_time=end;var remove_last_point=$(htmldiv).data(""remove-last-point"");if(remove_last_point)config_viz.remove_last_point=true;return config_viz}Convert.convertMetricsEvol=function(){var config_metric={};config_metric.show_desc=false;config_metric.show_title=true;config_metric.show_labels=true;var config=Report.getVizConfig();if(config){$.each(config,function(key,value){config_metric[key]=value})}var div_param=""MetricsEvol"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){var config_viz={};$.each(config_metric,function(key,value){config_viz[key]=value});$(this).empty();var metrics=$(this).data(""metrics"");var ds=$(this).data(""data-source"");config_viz.title=$(this).data(""title"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;config_viz=loadHTMLEvolParameters(div,config_viz);div.id=metrics.replace(/,/g,""-"")+""-""+ds+""-metrics-evol-""+this.id;div.id=div.id.replace(/\n|\s/g,"""");DS.displayMetricsEvol(metrics.split("",""),div.id,config_viz,$(this).data(""convert""))})}};Convert.convertMetricsEvolCustomized=function(filter){var config_metric={};config_metric.show_desc=false;config_metric.show_title=true;config_metric.show_labels=true;var config=Report.getVizConfig();if(config){$.each(config,function(key,value){config_metric[key]=value})}var div_param=""MetricsEvolCustomized"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){if(filter!==$(this).data(""filter""))return;var config_viz={};$.each(config_metric,function(key,value){config_viz[key]=value});$(this).empty();var metrics=$(this).data(""metrics"");var ds=$(this).data(""data-source"");config_viz.title=$(this).data(""title"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;config_viz=loadHTMLEvolParameters(div,config_viz);div.id=metrics.replace(/,/g,""-"")+""-""+ds+""-metrics-evol-""+this.id;div.id=div.id.replace(/\n|\s/g,"""");DS.displayMetricsEvol(metrics.split("",""),div.id,config_viz,$(this).data(""convert""))})}};Convert.convertMetricsEvolSelector=function(){var config_metric={};config_metric.show_desc=false;config_metric.show_title=true;config_metric.show_labels=true;var config=Report.getVizConfig();if(config){$.each(config,function(key,value){config_metric[key]=value})}var div_param=""MetricsEvol"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){var config_viz={};$.each(config_metric,function(key,value){config_viz[key]=value});$(this).empty();var metrics=$(this).data(""metrics"");var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;var repository=Report.getParameterByName(""repository"");config_viz.repo_filter=repository;config_viz=loadHTMLEvolParameters(div,config_viz);div.id=metrics.replace(/,/g,""-"")+""-""+ds+""-metrics-evol-""+repository;div.id=div.id.replace(/\n|\s/g,"""");DS.displayMetricsEvol(metrics.split("",""),div.id,config_viz,$(this).data(""convert""))})}};Convert.convertMetricsEvolSet=function(){div_param=""MetricsEvolSet"";var divs=$("".""+div_param);if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var all=$(this).data(""all"");var relative=$(this).data(""relative"");var summary_graph=$(this).data(""summary-graph"");var legend=$(this).data(""legend-show"");div.id=ds+""-MetricsEvolSet-""+this.id;if(all===true){div.id=ds+""-All"";Viz.displayEnvisionAll(div.id,relative,legend,summary_graph);return false}var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;DS.displayEnvision(div.id,relative,legend,summary_graph)})}};Convert.convertTimeTo=function(){var div_tt=""TimeTo"";divs=$("".""+div_tt);if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var ds=$(this).data(""data-source"");var DS=Report.getDataSourceByName(ds);if(DS===null)return;var quantil=$(this).data(""quantil"");var type=$(this).data(""type"");div.id=ds+""-time-to-""+type+""-""+quantil;if(type===""fix"")DS.displayTimeToFix(div.id,quantil);if(type===""attention"")DS.displayTimeToAttention(div.id,quantil)})}};Convert.convertMarkovTable=function(){var div_id_mt=""MarkovTable"";var divs=$("".""+div_id_mt);var DS,ds;if(divs.length>0){$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(DS.getData().length===0)return;var title=$(this).data(""title"");div.id=ds+""-markov-table"";DS.displayMarkovTable(div.id,title)})}};Convert.convertLastActivity=function(){var all_metrics=Report.getAllMetrics();function activityInfo(div,period,label){var html=""<h4>Last ""+label+""</h4>"";$.each(Report.getDataSources(),function(index,DS){var data=DS.getGlobalData();$.each(data,function(key,val){var suffix=""_""+period;if(key.indexOf(suffix,key.length-suffix.length)!==-1){var metric=key.substring(0,key.length-suffix.length);label=metric;if(all_metrics[metric])label=all_metrics[metric].name;html+=label+"":""+data[key]+""<br>""}})});$(div).append(html)}var divs=$("".LastActivity"");var period=null;var days={Week:7,Month:30,Quarter:90,Year:365};if(divs.length>0)$.each(divs,function(id,div){period=$(div).data(""period"");activityInfo(div,days[period],period)})};Convert.convertTopByPeriod=function(){var div_id_top=""TopByPeriod"";var divs=$("".""+div_id_top);var DS,ds;if(divs.length>0){var unique=0;$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(DS.getData().length===0)return;var show_all=false;if($(this).data(""show_all""))show_all=true;var top_metric=$(this).data(""metric"");var npeople=$(this).data(""limit"");var is_release=Utils.isReleasePage();var html=HTMLComposer.TopByPeriod(ds,top_metric,npeople,is_release);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertTop=function(){var div_id_top=""Top"";var divs=$("".""+div_id_top);var DS,ds;if(divs.length>0){var unique=0;$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(DS.getData().length===0)return;var show_all=false;if($(this).data(""show_all""))show_all=true;var top_metric=$(this).data(""metric"");var limit=$(this).data(""limit"");var graph=$(this).data(""graph"");var people_links=$(this).data(""people_links"");var threads_links=$(this).data(""threads_links""); var period=$(this).data(""period"");var period_all=$(this).data(""period_all"");var repository=Report.getParameterByName(""repository"");div.id=ds+""-""+div_id_top+unique++;if(graph){div.id+=""-""+graph}if(period===undefined&&period_all===undefined){period_all=true}if(limit===undefined){limit=10}DS.displayTop(div.id,show_all,top_metric,period,period_all,graph,limit,people_links,threads_links,repository)})}};Convert.convertPersonMetrics=function(upeople_id,upeople_identifier){var config_metric={};config_metric.show_desc=false;config_metric.show_title=false;config_metric.show_labels=true;divs=$("".PersonMetrics"");if(divs.length){$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;var metrics=$(this).data(""metrics"");config_metric.show_legend=false;config_metric.help=false;if($(this).data(""frame-time""))config_metric.frame_time=true;if($(this).data(""legend""))config_metric.show_legend=true;if($(this).data(""person_id""))upeople_id=$(this).data(""person_id"");if($(this).data(""person_name""))upeople_identifier=$(this).data(""person_name"");div.id=metrics.replace(/,/g,""-"")+""-people-metrics"";DS.displayMetricsPeople(upeople_id,upeople_identifier,metrics.split("",""),div.id,config_metric)})}};function getRandomId(){return Math.floor(Math.random()*1e3+1)}Convert.convertPersonData=function(upeople_id,upeople_identifier){var divs=$("".PersonData""),name,email;if(divs.length>0){$.each(divs,function(id,div){$(this).empty();if($(this).data(""person_id""))upeople_id=$(this).data(""person_id"");if(!div.id)div.id=""PersonData""+""-""+upeople_id+""-""+getRandomId();var data=Report.getPeopleIdentities()[upeople_id];if(data){name=DataProcess.selectPersonName(data);email=DataProcess.selectPersonEmail(data);email=""(""+DataProcess.hideEmail(email)+"")""}else{if(upeople_identifier!==undefined)name=upeople_identifier;else name=upeople_id;email=""""}html=HTMLComposer.personName(name,email);$(""#""+div.id).append(html)})}};Convert.personSummaryBlock=function(upeople_id){var divs=$("".PersonSummaryBlock"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;ds_name=$(this).data(""data-source"");ds_realname=$(this).data(""data-realname"");metric_name=$(this).data(""metrics"");DS=Report.getDataSourceByName(ds_name);if(DS===null)return;if(DS.getData().length===0)return;if(DS.getPeopleMetricsData()[upeople_id].length===0)return;var html=HTMLComposer.personDSBlock(ds_name,metric_name,ds_realname);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertPersonSummary=function(upeople_id,upeople_identifier){var divs=$("".PersonSummary"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if($(this).data(""person_id""))upeople_id=$(this).data(""person_id"");if($(this).data(""person_name""))upeople_identifier=$(this).data(""person_name"");div.id=ds+""-refcard-people"";DS.displayPeopleSummary(div.id,upeople_id,upeople_identifier,DS)})}};Convert.convertPeople=function(upeople_id,upeople_identifier){if(upeople_id===undefined)upeople_id=Report.getParameterByName(""id"");if(upeople_identifier===undefined)upeople_identifier=Report.getParameterByName(""name"");if(upeople_id===undefined)return;if(Loader.check_people_item(upeople_id)===false){$.each(Report.getDataSources(),function(index,DS){Loader.data_load_people_item(upeople_id,DS,Convert.convertPeople)});return}Convert.personSummaryBlock(upeople_id);Convert.convertPersonData(upeople_id,upeople_identifier);Convert.convertPersonSummary(upeople_id,upeople_identifier);Convert.convertPersonMetrics(upeople_id,upeople_identifier);Convert.activateHelp()};function dataFilterAvailable(filter_name,item_name){if(filter_name===""repos""){if(DS.getReposGlobalData()[item_name]===undefined||DS.getReposGlobalData()[item_name].length===0)return false}else if(filter_name===""companies""){if(DS.getCompaniesGlobalData()[item_name]===undefined||DS.getCompaniesGlobalData()[item_name].length===0)return false}else if(filter_name===""countries""){if(DS.getCountriesGlobalData()[item_name]===undefined||DS.getCountriesGlobalData()[item_name].length===0)return false}else if(filter_name===""companies""){if(DS.getDomainsGlobalData()[item_name]===undefined||DS.getDomainsGlobalData()[item_name].length===0)return false}return true}Convert.repositoryDSBlock=function(repo_id){var divs=$("".FilterDSBlock"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;ds_name=$(this).data(""data-source"");filter_name=$(this).data(""filter"");aux=$(this).data(""metrics"");metric_names=aux.split("","");$.each(metric_names,function(id,value){metric_names[id]=metric_names[id].replace(/:/g,"","")});DS=Report.getDataSourceByName(ds_name);if(DS===null)return;if(DS.getData().length===0)return;if(dataFilterAvailable(filter_name,repo_id)){var html=HTMLComposer.filterDSBlock(ds_name,filter_name,metric_names);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)}})}};Convert.convertDSSummaryBlock=function(upeople_id){var divs=$("".DSSummaryBlock"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;ds_name=$(this).data(""data-source"");ds_realname=$(this).data(""data-realname"");box_labels=$(this).data(""box-labels"");box_metrics=$(this).data(""box-metrics"");ts_metrics=$(this).data(""ts-metrics"");DS=Report.getDataSourceByName(ds_name);if(DS===null)return;if(DS.getData().length===0)return;var html=HTMLComposer.DSBlock(ds_name,box_labels,box_metrics,ts_metrics,ds_realname);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertDSSummaryBlockProjectFiltered=function(upeople_id){var divs=$("".DSSummaryBlockProjectFiltered"");var pname=Report.getParameterByName(""project"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;ds_name=$(this).data(""data-source"");box_labels=$(this).data(""box-labels"");box_metrics=$(this).data(""box-metrics"");ts_metrics=$(this).data(""ts-metrics"");DS=Report.getDataSourceByName(ds_name);if(DS===null)return;if(DS.getProjectsGlobalData()[pname]===undefined)return;if(DS.getProjectsGlobalData()[pname].length===0)return;var html=HTMLComposer.DSBlockProject(ds_name,box_labels,box_metrics,ts_metrics,pname);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertOverallSummaryBlock=function(){var divs=$("".OverallSummaryBlock"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;var html=HTMLComposer.overallSummaryBlock();if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertDemographics=function(){var divs=$("".Demographics"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;var period=$(this).data(""period"");div.id=""Demographics""+""-""+ds+""-""+""-""+period;DS.displayDemographics(div.id,period)})}};function filterItemsConfig(){var config_metric={};config_metric.show_desc=false;config_metric.show_title=false;config_metric.show_labels=true;config_metric.show_legend=false;return config_metric}Convert.getRealItem=function(ds,filter,item){var map=Report.getReposMap();if(map===undefined||map.length===0){if($.inArray(item,ds.getReposData())>-1)return item;else return null}var map_item=null;if(filter===""repos""){var rdata=ds.getReposMetricsData()[item];if(rdata===undefined){$.each(map,function(id,repos){$.each(Report.getDataSources(),function(index,DS){if(repos[DS.getName()]===item){map_item=repos[ds.getName()];return false}});if(map_item!==null)return false})}else map_item=item}else map_item=item;return map_item};Convert.convertFilterItemsSummary=function(filter){var divlabel=""FilterItemsSummary"";divs=$("".""+divlabel);if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;div.id=ds+""-""+divlabel;$(this).empty();if(filter===""repos"")DS.displayReposSummary(div.id,DS);if(filter===""countries"")DS.displayCountriesSummary(div.id,DS);if(filter===""companies"")DS.displayCompaniesSummary(div.id,DS);if(filter===""domains"")DS.displayDomainsSummary(div.id,DS);if(filter===""projects"")DS.displayProjectsSummary(div.id,DS)})}};Convert.convertFilterItemsGlobal=function(filter){var config_metric=filterItemsConfig();var divlabel=""FilterItemsGlobal"";divs=$("".""+divlabel);if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;var metric=$(this).data(""metric"");var show_others=$(this).data(""show-others"");var order_by=$(this).data(""order-by"");config_metric.show_legend=$(this).data(""legend"");if($(""#""+$(this).data(""legend-div"")).length>0){config_metric.legend={container:$(this).data(""legend-div"")}}else config_metric.legend={container:null};config_metric.graph=$(this).data(""graph"");config_metric.title=$(this).data(""title"");config_metric.show_title=1;div.id=metric+""-""+divlabel;$(this).empty();if(filter===""repos"")DS.displayMetricReposStatic(metric,div.id,config_metric,order_by,show_others);if(filter===""countries"")DS.displayMetricCountriesStatic(metric,div.id,config_metric,order_by,show_others);if(filter===""companies"")DS.displayMetricCompaniesStatic(metric,div.id,config_metric,order_by,show_others);if(filter===""domains"")DS.displayMetricDomainsStatic(metric,div.id,config_metric,order_by,show_others);if(filter===""projects"")DS.displayMetricProjectsStatic(metric,div.id,config_metric,order_by,show_others)})}};Convert.convertFilterItemsNav=function(filter,page){var divlabel=""FilterItemsNav"";divs=$("".""+divlabel);if(divs.length>0){var cont=0;$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;if($(this).data(""page""))page=$(this).data(""page"");order_by=$(this).data(""order-by"");div.id=ds+""-""+divlabel+""-""+cont;cont+=1;$(this).empty();if(filter===""repos"")DS.displayItemsNav(div.id,filter,page,order_by);else if(filter===""countries"")DS.displayItemsNav(div.id,filter,page);else if(filter===""companies"")DS.displayItemsNav(div.id,filter,page);else if(filter===""domains"")DS.displayItemsNav(div.id,filter,page);else if(filter===""projects"")DS.displayItemsNav(div.id,filter,page)})}};Convert.convertFilterItemsMetricsEvol=function(filter){var config_metric=filterItemsConfig();var divlabel=""FilterItemsMetricsEvol"";divs=$("".""+divlabel);if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;var metric=$(this).data(""metric"");var stacked=false;if($(this).data(""stacked""))stacked=true;if($(this).data(""min"")){config_viz.show_legend=false;config_viz.show_labels=true;config_viz.show_grid=true;config_viz.help=false}var start=$(this).data(""start"");var end=$(this).data(""end"");config_metric.lines={stacked:stacked};if($(""#""+$(this).data(""legend-div"")).length>0){config_metric.legend={container:$(this).data(""legend-div"")}}else config_metric.legend={container:null};config_metric.show_legend=$(this).data(""legend"");config_metric.mouse_tracker=$(this).data(""mouse_tracker"");var remove_last_point=$(this).data(""remove-last-point"");if(remove_last_point)config_metric.remove_last_point=true;div.id=metric+""-""+divlabel;$(this).empty();if(filter===""companies"")DS.displayMetricCompanies(metric,div.id,config_metric,start,end);else if(filter===""repos"")DS.displayMetricRepos(metric,div.id,config_metric,start,end);else if(filter===""domains"")DS.displayMetricDomains(metric,div.id,config_metric,start,end);else if(filter===""projects"")DS.displayMetricProjects(metric,div.id,config_metric,start,end)})}};Convert.convertFilterItemsMiniCharts=function(filter,page){var config_metric=filterItemsConfig();var divlabel=""FilterItemsMiniCharts"";divs=$("".""+divlabel);if(divs.length>0){$.each(divs,function(id,div){ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;if($(this).data(""page""))page=$(this).data(""page"");var metrics=$(this).data(""metrics"");var order_by=$(this).data(""order-by"");var show_links=true;if($(this).data(""show_links"")!==undefined)show_links=$(this).data(""show_links"");var start=$(this).data(""start"");var end=$(this).data(""end"");var convert=$(this).data(""convert"");if($(this).data(""frame-time""))config_metric.frame_time=true;var remove_last_point=$(this).data(""remove-last-point"");if(remove_last_point)config_metric.remove_last_point=true;div.id=metrics.replace(/,/g,""-"")+""-""+filter+""-""+divlabel;$(this).empty();if(filter===""repos"")DS.displayReposList(metrics.split("",""),div.id,config_metric,order_by,page,show_links,start,end,convert);else if(filter===""countries"")DS.displayCountriesList(metrics.split("",""),div.id,config_metric,order_by,page,show_links,start,end,convert);else if(filter===""companies"")DS.displayCompaniesList(metrics.split("",""),div.id,config_metric,order_by,page,show_links,start,end,convert);else if(filter===""domains"")DS.displayDomainsList(metrics.split("",""),div.id,config_metric,order_by,page,show_links,start,end,convert);else if(filter===""projects"")DS.displayProjectsList(metrics.split("",""),div.id,config_metric,order_by,page,show_links,start,end,convert)})}};Convert.convertFilterItemData=function(filter,item){var divs=$("".FilterItemData"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var label=Report.cleanLabel(item);if(!div.id)div.id=""FilterItemData""+getRandomId();html=HTMLComposer.itemName(label,filter);$(""#""+div.id).append(html)})}};Convert.convertFilterItemSummary=function(filter,item){var divlabel=""FilterItemSummary"";divs=$("".""+divlabel);if(item!==null&&divs.length>0){$.each(divs,function(id,div){var real_item=item;ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;if($(this).data(""item""))real_item=$(this).data(""item"");div.id=ds+""-""+filter+""-""+divlabel;$(this).empty();if(filter===""repos""){DS.displayRepoSummary(div.id,real_item,DS)}else if(filter===""countries"")DS.displayCountrySummary(div.id,real_item,DS);else if(filter===""companies"")DS.displayCompanySummary(div.id,real_item,DS);else if(filter===""domains"")DS.displayDomainSummary(div.id,real_item,DS);else if(filter===""projects"")DS.displayProjectSummary(div.id,real_item,DS)})}};Convert.convertFilterItemMicrodashText=function(filter,item){var divs=$("".FilterItemMicrodashText"");if(divs.length>0){$.each(divs,function(id,div){$(this).empty();var global_data;var real_item=item;var metric=$(this).data(""metric"");var show_name=$(this).data(""name"");var ds=Report.getMetricDS(metric)[0];if(ds===undefined)return;if(filter===""projects""){global_data=ds.getProjectsGlobalData()[item];if(global_data===undefined){return}}else{return}var html='<div class=""row"">';if(show_name){html+='<div class=""col-md-3"">';html+='<span class=""dayschange"">'+ds.basic_metrics[metric].name+""</span>"";html+=""</div>""}$.each([365,30,7],function(index,period){var column=ds.getMetrics()[metric].column;var value=global_data[metric+""_""+period];var netvalue=global_data[""diff_net""+column+""_""+period];var percentagevalue=global_data[""percentage_""+column+""_""+period];percentagevalue=Math.round(percentagevalue*10)/10;if(value===undefined)return;var str_percentagevalue="""";if(netvalue>0)str_percentagevalue=""+""+percentagevalue;if(netvalue<0)str_percentagevalue=""-""+Math.abs(percentagevalue);if(show_name){html+='<div class=""col-md-3"">'}else{html+='<div class=""col-md-4"">'}html+='<span class=""dayschange"">Last '+period+"" days:</span>"";html+="" ""+Report.formatValue(value)+""<br>"";if(netvalue===0){html+='<i class=""fa fa-arrow-circle-right""></i> <span class=""zeropercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}else if(netvalue>0){html+='<i class=""fa fa-arrow-circle-up""></i> <span class=""pospercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}else if(netvalue<0){html+='<i class=""fa fa-arrow-circle-down""></i> <span class=""negpercent"">&nbsp;'+str_percentagevalue+""%</span>&nbsp;""}html+=""</div><!--col-md-4-->""});html+=""</div><!--row-->"";$(div).append(html)})}};Convert.convertFilterItemMetricsEvol=function(filter,item){var config_metric=filterItemsConfig();var divlabel=""FilterItemMetricsEvol"";divs=$("".""+divlabel);if(item!==null&&divs.length>0){$.each(divs,function(id,div){var real_item=item;var metrics=$(this).data(""metrics"");ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;if($(this).data(""item""))real_item=$(this).data(""item"");config_metric=loadHTMLEvolParameters(div,config_metric);div.id=Report.cleanLabel(item).replace(/ /g,""_"")+""-"";div.id+=metrics.replace(/,/g,""-"")+""-""+ds+""-""+filter+""-""+divlabel;$(this).empty();if(filter===""repos""){DS.displayMetricsRepo(real_item,metrics.split("",""),div.id,config_metric)}else if(filter===""countries""){DS.displayMetricsCountry(real_item,metrics.split("",""),div.id,config_metric)}else if(filter===""companies""){DS.displayMetricsCompany(real_item,metrics.split("",""),div.id,config_metric)}else if(filter===""domains""){DS.displayMetricsDomain(real_item,metrics.split("",""),div.id,config_metric)}else if(filter===""projects""){DS.displayMetricsProject(real_item,metrics.split("",""),div.id,config_metric)}})}};Convert.convertFilterItemTop=function(filter,item){var divlabel=""FilterItemTop"";divs=$("".""+divlabel);if(divs.length>0){$.each(divs,function(id,div){var real_item=item;$(this).empty();ds=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds);if(DS===null)return;if(filter===undefined)filter=$(this).data(""filter"");if(filter!==$(this).data(""filter""))return;if(!filter)return;if($(this).data(""item""))real_item=$(this).data(""item"");var metric=$(this).data(""metric"");var period=$(this).data(""period"");var titles=$(this).data(""titles"");div.id=metric+""-""+ds+""-""+filter+""-""+divlabel+""-""+getRandomId();$(this).empty();div.className="""";if(filter===""companies"")DS.displayTopCompany(real_item,div.id,metric,period,titles)})}};Convert.convertSmartLinks=function(){var divs=$("".SmartLinks"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;target_page=$(this).data(""target"");label=$(this).data(""label"");var html=HTMLComposer.smartLinks(target_page,label);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.companyFilters=function(){var divs=$("".CompanyFilters"");if(divs.length>0){$.each(divs,function(id,div){if(div.id.indexOf(""Parsed"")>=0)return;company_name=Report.getParameterByName(""company"");var html=HTMLComposer.companyFilters(company_name);if(!div.id)div.id=""Parsed""+getRandomId();$(""#""+div.id).append(html)})}};Convert.convertFilterStudyItem=function(filter,item){var convertfn=Convert.convertFilterStudyItem;if(convertfn.done===undefined){convertfn.done={}}else if(convertfn.done[filter]===true)return;if(filter===""repositories"")filter=""repos"";if(item===undefined){if(filter===""repos"")item=Report.getParameterByName(""repository"");if(filter===""countries"")item=Report.getParameterByName(""country"");if(filter===""companies"")item=Report.getParameterByName(""company"");if(filter===""domains"")item=Report.getParameterByName(""domain"");if(filter===""projects"")item=Report.getParameterByName(""project"")}if(!item)return;if(Loader.FilterItemCheck(item,filter)===false)return;Convert.repositoryDSBlock(item);Convert.convertDSSummaryBlockProjectFiltered();Convert.convertFilterItemData(filter,item);Convert.convertFilterItemSummary(filter,item);Convert.convertFilterItemMetricsEvol(filter,item);Convert.convertFilterItemTop(filter,item);Convert.convertFilterItemMicrodashText(filter,item);Convert.convertProjectData();Convert.activateHelp();Convert.convertMetricsEvolSelector();convertfn.done[filter]=true};Convert.activateHelp=function(){$("".help"").popover({html:true,trigger:""manual""}).click(function(e){$(this).popover(""toggle"");e.stopPropagation()})};Convert.convertFilterStudy=function(filter){var page=Report.getCurrentPage();if(page===null){page=Report.getParameterByName(""page"");if(page!==undefined)Report.setCurrentPage(page)}if(page===undefined){if($(""[class^='FilterItems']"").length>0){page=1;Report.setCurrentPage(page)}else return}if(filter===""repositories"")filter=""repos"";if(Loader.check_filter_page(page,filter)===false){$.each(Report.getDataSources(),function(index,DS){Loader.data_load_items_page(DS,page,Convert.convertFilterStudy,filter)});return}Convert.convertFilterItemsSummary(filter);Convert.convertFilterItemsGlobal(filter);Convert.convertFilterItemsNav(filter,page);Convert.convertFilterItemsMetricsEvol(filter);Convert.convertFilterItemsMiniCharts(filter,page)};Convert.convertDSTable=function(){var dst=""DataSourcesTable"";var divs=$("".""+dst);var DS,ds;if(divs.length>0){var unique=0;$.each(divs,function(id,div){$(this).empty();div.id=dst+unique++;Viz.displayDataSourcesTable(div)})}};Convert.convertBasicDivs=function(){Convert.convertNavbar();Convert.convertSmartLinks();Convert.convertSectionBreadcrumb();Convert.convertProjectMap();Convert.convertFooter();Convert.convertOverallSummaryBlock();Convert.convertDSSummaryBlock();Convert.convertDSTable();Convert.convertGlobalData();Convert.convertSummary();Convert.convertTopByPeriod();Convert.companyFilters()};Convert.convertBasicDivsMisc=function(){Convert.convertRadarActivity();Convert.convertRadarCommunity();Convert.convertTreemap();Convert.convertBubbles()};Convert.convertBasicMetrics=function(config){var item=Report.getParameterByName(""repository"");if(item===undefined)Convert.convertMetricsEvol();Convert.convertTimeTo();Convert.convertMarkovTable()};Convert.convertFilterTop=function(filter){var item=Report.getParameterByName(""repository"");if(item!==undefined){if(Loader.filterTopCheck(item,filter)===false)return}Convert.convertTop();Convert.convertRepositorySelector()}})();if(Report===undefined)var Report={};(function(){var project_data=null,markers=null,viz_config=null,gridster={},data_sources=[],report_config=null,html_dir="""",menu_elements;var data_dir=""data/json"";var config_dir=""config"";var default_data_dir=""data/json"";var default_html_dir="""";var projects_dirs=[default_data_dir];var projects_data={};var projects_datasources={};var repos_map;Report.all_json_file=data_dir+""/all.json"";var project_file=config_dir+""/project-info.json"";viz_config_file=data_dir+""/viz_cfg.json"";markers_file=data_dir+""/markers.json"";repos_map_file=data_dir+""/repos-map.json"";projects_hierarchy_file=data_dir+""/projects_hierarchy.json"";menu_elements_file=config_dir+""/menu-elements.json"";var page_size=10,page=null;var project_people_identities={};Report.createDataSources=createDataSources;Report.getAllMetrics=getAllMetrics;Report.getMarkers=getMarkers;Report.getVizConfig=getVizConfig;Report.getProjectsHierarchy=getProjectsHierarchy;Report.getMenuElements=getMenuElements;Report.getMenuElementsReleases=getMenuElementsReleases;Report.getReleaseNames=getReleaseNames;Report.getThreadsSite=getThreadsSite;Report.getMetricDS=getMetricDS;Report.getGridster=getGridster;Report.setGridster=setGridster;Report.getCurrentPage=function(){return page};Report.setCurrentPage=function(current_page){page=current_page};Report.getPageSize=function(){return page_size};Report.setPageSize=function(size){page_size=size};Report.getProjectData=getProjectData;Report.getProjectsData=getProjectsData;Report.convertStudies=convertStudies;Report.getDataSources=function(){return data_sources};Report.registerDataSource=function(backend){data_sources.push(backend)};Report.setHtmlDir=function(dir){html_dir=dir};Report.getHtmlDir=function(){return html_dir};Report.getDataDir=function(){return data_dir};Report.setDataDir=function(dataDir){data_dir=dataDir;project_file=dataDir+""/project-info.json"";config_file=dataDir+""/viz_cfg.json"";markers_file=dataDir+""/markers.json"";repos_mapping_file=data_dir+""/repos-mapping.json"";projects_hierarchy_file=data_dir+""/projects_hierarchy.json""};function getMarkers(){return markers}Report.setMarkers=function(data){markers=data};Report.getMarkersFile=function(){return markers_file};Report.getReposMap=function(){return repos_map};Report.setReposMap=function(data){repos_map=data};Report.getReposMapFile=function(){return repos_map_file};function getVizConfig(){return viz_config}Report.setVizConfig=function(cfg){viz_config=cfg};Report.getVizConfigFile=function(){return viz_config_file};function getProjectsHierarchy(){return projects_hierarchy}Report.setProjectsHierarchy=function(data){projects_hierarchy=data};Report.getProjectsHierarchyFile=function(){return projects_hierarchy_file};function getMenuElements(){var elements;if(menu_elements!==undefined){elements=menu_elements.menu}return elements}function getMenuElementsReleases(){var releases;if(menu_elements!==undefined){releases=menu_elements.menu_releases}return releases}function getReleaseNames(){var names;if(menu_elements!==undefined){names=menu_elements.releases}return names}function getThreadsSite(){var site;if(menu_elements!==undefined){site=menu_elements.threads_site}return site}Report.setMenuElements=function(data){menu_elements=data};Report.getMenuElementsFile=function(){return menu_elements_file};function getGridster(){return gridster}function setGridster(grid){gridster=grid}function getProjectData(){return project_data}Report.setProjectData=function(data){project_data=data};Report.getProjectFile=function(){return project_file};function getProjectsData(){return projects_data}Report.getProjectsDirs=function(){return projects_dirs};Report.setProjectsDirs=function(dirs){projects_dirs=dirs};Report.getProjectsList=function(){var projects_list=[];$.each(getProjectsData(),function(key,val){projects_list.push(key)});return projects_list};Report.getProjectsDataSources=function(){return projects_datasources};Report.setMetricsDefinition=function(metrics){$.each(Report.getDataSources(),function(i,DS){DS.setMetricsDefinition(metrics[DS.getName()])})};Report.getPeopleIdentities=function(){return project_people_identities};Report.setPeopleIdentities=function(people){project_people_identities=people};Report.cleanLabel=function(item){var label=item;var aux=null;if(item.split(""___"").length===2){aux=item.split("" "");label=aux[0]}else if(item.lastIndexOf(""https:__api.github.com_repos_"")===0){label=label.replace(""https:__api.github.com_repos_"","""");label=label.split(""_"")[1]}else if(item.lastIndexOf(""http"")===0||item.split(""_"").length>3){aux=item.split(""_"");label=aux.pop();if(label==="""")label=aux.pop();label=label.replace(""buglist.cgi?product="","""");label=label.replace(""gmane.comp.sysutils."","""")}else if(item.lastIndexOf(""<"")===0)label=MLS.displayMLSListName(item);return label};function strNumberWithThousands(x){var parts=x.toString().split(""."");parts[0]=parts[0].replace(/\B(?=(\d{3})+(?!\d))/g,"","");return parts.join(""."")}Report.formatValue=function(number,field){if(number===undefined)return""-"";var date_fields=[""last_date"",""first_date""];var reports=[""repositories"",""companies"",""countries"",""domains"",""projects""];var value=number;try{value=parseFloat(number).toFixed(1).toString().replace(/\.0$/,"""");value=strNumberWithThousands(value);if(navigator.language===""es""){var parts=value.split(""."");parts[0]=parts[0].replace(/,/g,""."");value=parts.join("","")}}catch(err){}if(typeof value===""number""&&isNaN(value))value=number.toString();if(field!==undefined&&$.inArray(field,date_fields)>-1)value=number.toString();if(field!==undefined&&value===""0""){$.each(reports,function(i,report){if(field.indexOf(report)!=1){value=""-""}})}return value};Report.escapeHtml=function(unsafe){return unsafe.replace(/&/g,""&amp;"").replace(/</g,""&lt;"").replace(/>/g,""&gt;"").replace(/""/g,""&quot;"").replace(/'/g,""&#039;"")};Report.getParameterByName=function(name){name=name.replace(/[\[]/,""\\["").replace(/[\]]/,""\\]"");var regex=new RegExp(""[\\?&]""+name+""=([^&#]*)""),results=regex.exec(location.search);return results===null?undefined:Report.escapeHtml(decodeURIComponent(results[1].replace(/\+/g,"" "")))};function getMetricDS(metric_id){var ds=[];$.each(Report.getDataSources(),function(i,DS){if(DS.getMetrics()[metric_id]){ds.push(DS)}});return ds}Report.getDataSourceByName=function(ds){var DS=null;$.each(Report.getDataSources(),function(index,DSaux){if(DSaux.getName()===ds){DS=DSaux;return false}});return DS};function getAllMetrics(){var all={};$.each(Report.getDataSources(),function(index,DS){all=$.extend({},all,DS.getMetrics())});return all}Report.displayActiveMenu=function(){var active=window.location.href;var page=active.substr(active.lastIndexOf(""/"")+1,active.length);page=page.split("".html"")[0];if(page.indexOf(""scm"")===0){$("".scm-menu"")[0].className=$("".scm-menu"")[0].className+"" active""}else if(page.indexOf(""its"")===0){$("".its-menu"")[0].className=$("".its-menu"")[0].className+"" active""}else if(page.indexOf(""mls"")===0){$("".mls-menu"")[0].className=$("".mls-menu"")[0].className+"" active""}else if(page.indexOf(""scr"")===0){$("".scr-menu"")[0].className=$("".scr-menu"")[0].className+"" active""}else if(page.indexOf(""irc"")===0){$("".irc-menu"")[0].className=$("".irc-menu"")[0].className+"" active""}else if(page.indexOf(""qaforum"")===0){$("".qaforum-menu"")[0].className=$("".qaforum-menu"")[0].className+"" active""}else if(page.indexOf(""studies"")===0){$("".studies-menu"")[0].className=$("".studies-menu"")[0].className+"" active""}else if(page.indexOf(""wiki"")===0){$("".wiki-menu"")[0].className=$("".wiki-menu"")[0].className+"" active""}else if(page.indexOf(""downloads"")===0){$("".downloads-menu"")[0].className=$("".downloads-menu"")[0].className+"" active""}else if(page.indexOf(""projects"")===0){$("".listprojects-menu"")[0].className=$("".listprojects-menu"")[0].className+"" active""}else if(page.indexOf(""index"")===0||page===""""){if($("".summary-menu"").length===0)return;$("".summary-menu"")[0].className=$("".summary-menu"")[0].className+"" active""}else{if($("".experimental-menu"")[0])$("".experimental-menu"")[0].className=$("".experimental-menu"")[0].className+"" active""}};function checkDynamicConfig(){var data_sources=[];var release=$.urlParam(""release"");if(release!==null&&release.length>0){data_sources.push(""data/json/""+release);Report.setDataDir(""data/json/""+release);if(data_sources.length>0)Report.setProjectsDirs(data_sources)}}function createDataSources(){checkDynamicConfig();var projects_dirs=Report.getProjectsDirs();var scm,its,its_1,mls,scr,irc,mediawiki,people,downloads,qaforums,releases;$.each(projects_dirs,function(i,project){if(Report.getConfig()===null||Report.getConfig()[""data-sources""]===undefined){its=new ITS;Report.registerDataSource(its);its_1=new ITS_1;Report.registerDataSource(its_1);mls=new MLS;Report.registerDataSource(mls);scm=new SCM;Report.registerDataSource(scm);scr=new SCR;Report.registerDataSource(scr);irc=new IRC;Report.registerDataSource(irc);mediawiki=new MediaWiki;Report.registerDataSource(mediawiki);people=new People;Report.registerDataSource(people);downloads=new Downloads;Report.registerDataSource(downloads);qaforums=new QAForums;Report.registerDataSource(qaforums);releases=new Releases;Report.registerDataSource(releases)}else{var active_ds=Report.getConfig()[""data-sources""];$.each(active_ds,function(i,name){if(name===""its""){its=new ITS;Report.registerDataSource(its)}else if(name===""its_1""){its_1=new ITS_1;Report.registerDataSource(its_1)}else if(name===""mls""){mls=new MLS;Report.registerDataSource(mls)}else if(name===""scm""){scm=new SCM;Report.registerDataSource(scm)}else if(name===""scr""){scr=new SCR;Report.registerDataSource(scr)}else if(name===""irc""){irc=new IRC;Report.registerDataSource(irc)}else if(name===""mediawiki""){mediawiki=new MediaWiki; Report.registerDataSource(mediawiki)}else if(name===""people""){people=new People;Report.registerDataSource(people)}else if(name===""downloads""){downloads=new Downloads;Report.registerDataSource(downloads)}else if(name===""qaforums""){qaforums=new QAForums;Report.registerDataSource(qaforums)}else if(name===""releases""){releases=new Releases;Report.registerDataSource(releases)}else Report.log(""Not support data source ""+name)})}if(its)its.setDataDir(project);if(its_1)its_1.setDataDir(project);if(mls)mls.setDataDir(project);if(scm)scm.setDataDir(project);if(scr)scr.setDataDir(project);if(irc)irc.setDataDir(project);if(mediawiki)mediawiki.setDataDir(project);if(people)people.setDataDir(project);if(downloads)downloads.setDataDir(project);if(qaforums)qaforums.setDataDir(project);if(releases)releases.setDataDir(project);if(scm&&its)scm.setITS(its)});return true}Report.addDataDir=function(){var addURL;var querystr=window.location.search.substr(1);if(querystr&&querystr.indexOf(""data_dir"")!==-1){addURL=window.location.search.substr(1)}return addURL};Report.configDataSources=function(){var prjs_dss=Report.getProjectsDataSources();$.each(Report.getDataSources(),function(index,ds){if(ds.getData()instanceof Array)return;$.each(projects_data,function(name,project){if(project.dir===ds.getDataDir()){if(prjs_dss[name]===undefined)prjs_dss[name]=[];$.each(prjs_dss[name],function(prj,prjds){if(ds.getName()===prjds.getName())return false});ds.setProject(name);prjs_dss[name].push(ds);return false}})})};Report.getConfig=function(){return report_config};Report.setConfig=function(data){report_config=data;if(data){Report.log(""Global config file found"");if(data[""global-html-dir""])Report.setHtmlDir(data[""global-html-dir""]);if(data[""global-data-dir""]){Report.setDataDir(data[""global-data-dir""]);Report.setProjectsDirs([data[""global-data-dir""]])}if(data[""projects-data-dirs""])Report.setProjectsDirs(data[""projects-data-dirs""])}};Report.convertGlobal=function(){Convert.convertBasicDivs();Convert.convertBasicDivsMisc();Convert.convertBasicMetrics();Convert.convertDemographics();Convert.convertMetricsEvolSet();Convert.convertLastActivity();Convert.convertMicrodash();Convert.convertMicrodashText()};Report.getActiveStudies=function(){var activeStudies=[];var reports;var reports_study=[""repositories"",""countries"",""companies"",""domains"",""projects""];if(Report.getConfig()!==null)reports=Report.getConfig().reports;else reports=reports_study;$.each(reports_study,function(i,study){if($.inArray(study,reports)>-1)activeStudies.push(study)});return activeStudies};Report.convertStudiesGlobal=function(){Convert.convertPeople()};function convertStudies(){$.each(Report.getActiveStudies(),function(i,study){var filter=study;if(study===""repositories"")filter=""repos"";DataProcess.orderItems(filter);Convert.convertFilterStudy(study);Convert.convertFilterStudyItem(study)})}var log_on=true;Report.getLog=function(){return log_on};Report.setLog=function(status){log_on=status};Report.log=function(msg){if(Report.getLog()===true)if(window.console)console.log(msg)}})();Loader.data_ready_global(function(){Report.configDataSources();Report.convertGlobal();Report.convertStudiesGlobal()});Loader.data_ready(function(){study=""repos"";Convert.convertFilterTop(study)});Loader.data_ready(function(){Report.convertStudies();$(""body"").css(""cursor"",""auto"");$(""html"").click(function(e){$("".help"").popover(""hide"")});Convert.activateHelp()});$(document).ready(function(){$.getJSON(Report.getMenuElementsFile(),function(data){Report.setMenuElements(data)}).fail(function(){if(window.console)Report.log(""Can't read global config file ""+Report.getMenuElementsFile())}).always(function(data){Report.createDataSources();$.getJSON(Report.all_json_file,function(data){if(window.console){Report.log(""Loaded all JSON data from ""+Report.all_json_file)}Loader.set_all_data(data)}).always(function(data){Loader.data_load()});$(""body"").css(""cursor"",""progress"")})});function resizedw(){if(true){return}Report.convertGlobal();Report.convertStudiesGlobal();Report.convertStudies();Convert.activateHelp()}var resized;$(window).resize(function(){clearTimeout(resized);resized=setTimeout(resizedw,100)});function DataSource(name,basic_metrics){this.top_data_file=this.data_dir+""/""+this.name+""-top.json"";this.getTopDataFile=function(){return this.top_data_file};this.getMetrics=function(){return this.basic_metrics};this.setMetrics=function(metrics){this.basic_metrics=metrics};this.setMetricsDefinition=function(metrics){if(metrics===undefined)return;this.setMetrics(metrics)};this.data_file=this.data_dir+""/""+this.name+""-evolutionary.json"";this.getDataFile=function(){return this.data_file};this.setDataFile=function(file){this.data_file=file};this.data=null;this.getData=function(){return this.data};function nameSpaceMetrics(plain_metrics,ds){if(plain_metrics instanceof Array)return plain_metrics;var metrics={};if(plain_metrics===null){return metrics}$.each(plain_metrics,function(name,value){var basic_name=name;var aux=name.split(""_"");if(isNaN(aux[aux.length-1])===false)basic_name=aux.slice(0,aux.length-1).join(""_"");var ns_basic_name=ds.getName()+""_""+basic_name;var ns_name=ds.getName()+""_""+name;if(ds.getMetrics()[ns_basic_name]===undefined)metrics[name]=value;else metrics[ns_name]=value});return metrics}this.setData=function(load_data,self){if(self===undefined)self=this;self.data=nameSpaceMetrics(load_data,self)};this.demographics_aging_file=this.data_dir+""/""+this.name+""-demographics-aging.json"";this.demographics_birth_file=this.data_dir+""/""+this.name+""-demographics-birth.json"";this.getDemographicsAgingFile=function(){return this.demographics_aging_file};this.getDemographicsBirthFile=function(){return this.demographics_birth_file};this.demographics_data={};this.getDemographicsData=function(){return this.demographics_data};this.setDemographicsAgingData=function(data,self){if(self===undefined)self=this;self.demographics_data.aging=data};this.setDemographicsBirthData=function(data,self){if(self===undefined)self=this;self.demographics_data.birth=data};this.data_dir=""data/json"";this.getDataDir=function(){return this.data_dir};this.setDataDir=function(dataDir){this.data_dir=dataDir;this.data_file=dataDir+""/""+this.name+""-evolutionary.json"";this.demographics_aging_file=dataDir+""/""+this.name+""-demographics-aging.json"";this.demographics_birth_file=dataDir+""/""+this.name+""-demographics-birth.json"";this.global_data_file=dataDir+""/""+this.name+""-static.json"";this.top_data_file=dataDir+""/""+this.name+""-top.json"";this.companies_data_file=dataDir+""/""+this.name+""-companies.json"";this.repos_data_file=dataDir+""/""+this.name+""-repos.json"";this.countries_data_file=dataDir+""/""+this.name+""-countries.json"";this.domains_data_file=dataDir+""/""+this.name+""-domains.json"";this.projects_data_file=dataDir+""/""+this.name+""-projects.json"";this.time_to_fix_data_file=dataDir+""/""+this.name+""-quantiles-month-time_to_fix_hour.json""};this.global_data_file=this.data_dir+""/""+this.name+""-static.json"";this.getGlobalDataFile=function(){return this.global_data_file};this.global_data=null;this.getGlobalData=function(){return this.global_data};this.setGlobalData=function(data,self){if(self===undefined)self=this;var aux=Report.getMenuElements();var active_companies=null;if(aux&&typeof aux.filter_companies!==undefined){active_companies=aux.filter_companies}if(active_companies&&active_companies.length>0&&Object.keys(data).indexOf(""companies"")>=0){data.companies=active_companies.length}self.global_data=nameSpaceMetrics(data,self)};this.global_top_data=null;this.getGlobalTopData=function(){return this.global_top_data};this.setGlobalTopData=function(data,self){if(self===undefined)self=this;self.global_top_data=data};this.name=name;this.getName=function(){return this.name};this.people_data_file=this.data_dir+""/""+this.name+""-people.json"";this.getPeopleDataFile=function(){return this.people_data_file};this.people=null;this.getPeopleData=function(){return this.people};this.setPeopleData=function(people,self){if(self===undefined)self=this;self.people=people};this.time_to_fix_data_file=this.data_dir+""/""+this.name+""-quantiles-month-time_to_fix_hour.json"";this.getTimeToFixDataFile=function(){return this.time_to_fix_data_file};this.time_to_fix_data=null;this.getTimeToFixData=function(){return this.time_to_fix_data};this.setTimeToFixData=function(data,self){if(self===undefined)self=this;self.time_to_fix_data=data};this.time_to_attention_data_file=this.data_dir+""/""+this.name+""-quantiles-month-time_to_attention_hour.json"";this.getTimeToAttentionDataFile=function(){return this.time_to_attention_data_file};this.time_to_attention_data=null;this.getTimeToAttentionData=function(){return this.time_to_attention_data};this.setTimeToAttentionData=function(data,self){if(self===undefined)self=this;self.time_to_attention_data=data};this.project=null;this.getProject=function(){return this.project};this.setProject=function(project){this.project=project};this.markov_table_data_file=this.data_dir+""/""+this.name+""-markov.json"";this.getMarkovTableDataFile=function(){return this.markov_table_data_file};this.markov_table_data=null;this.getMarkovTableData=function(){return this.markov_table_data};this.setMarkovTableData=function(data,self){if(self===undefined)self=this;self.markov_table_data=data};this.companies_data_file=this.data_dir+""/""+this.name+""-companies.json"";this.getCompaniesDataFile=function(){return this.companies_data_file};this.companies=null;this.getCompaniesDataFull=function(){return this.companies};this.getCompaniesData=function(){var items=this.companies;if(items instanceof Array===false){if(this.companies!==null){items=this.companies.name}}return items};function filterOutCompaniesArray(com_data){var aux=Report.getMenuElements(),active_companies=null,result=[];if(aux&&typeof aux.filter_companies!==undefined){active_companies=aux.filter_companies}if(active_companies&&active_companies.length>0){$.each(com_data,function(pos,name){if(active_companies.indexOf(name)>=0){result[result.length]=name}})}else{result=com_data}return result}function filterOutCompanies(com_data){var aux=Report.getMenuElements();var active_companies=null;if(aux&&typeof aux.filter_companies!==undefined){active_companies=aux.filter_companies}if(active_companies&&active_companies.length>0){var keys=Object.keys(com_data);var positions=[];$.each(com_data.name,function(pos,name){if(active_companies.indexOf(name)>=0){positions[positions.length]=pos}});var new_obj={};$.each(keys,function(id,k){new_obj[k]=[];$.each(positions,function(subid,pos){var l=new_obj[k].length;new_obj[k][l]=com_data[k][pos]})});com_data=new_obj}return com_data}this.setCompaniesData=function(companies,self){if(companies===null)companies=[];if(self===undefined)self=this;if(Array.isArray(companies)){self.companies=filterOutCompaniesArray(companies)}else if(typeof companies===""object""){self.companies=filterOutCompanies(companies)}};this.companies_metrics_data={};this.addCompanyMetricsData=function(company,data,self){if(self===undefined)self=this;self.companies_metrics_data[company]=nameSpaceMetrics(data,self)};this.getCompaniesMetricsData=function(){return this.companies_metrics_data};this.companies_global_data={};this.addCompanyGlobalData=function(company,data,self){if(self===undefined)self=this;self.companies_global_data[company]=nameSpaceMetrics(data,self)};this.getCompaniesGlobalData=function(){return this.companies_global_data};this.companies_top_data={};this.addCompanyTopData=function(company,data,self){if(self===undefined)self=this;if(self.companies_top_data[company]===undefined)self.companies_top_data[company]={};self.companies_top_data[company]=data};this.getCompaniesTopData=function(){return this.companies_top_data};this.setCompaniesTopData=function(data,self){if(self===undefined)self=this;self.companies_top_data=data};this.repos_data_file=this.data_dir+""/""+this.name+""-repos.json"";this.getReposDataFile=function(){return this.repos_data_file};this.repos=null;this.getReposDataFull=function(){return this.repos};this.getReposData=function(){var items=this.repos;if(items instanceof Array===false){if(this.repos!==null){items=this.repos.name}}return items};this.setReposData=function(repos,self){if(self===undefined)self=this;self.repos=repos;if(self.getName()!==""its"")return;repos_names=[];if(repos instanceof Array===true){self.repos={};self.repos.name=repos}var filtered_repos=[];for(var i=0;i<self.repos.name.length;i++){filtered_repos.push(self.repos.name[i].replace(/\//g,""_""))}self.repos.name=filtered_repos};this.repos_metrics_data={};this.addRepoMetricsData=function(repo,data,self){if(self===undefined)self=this;self.repos_metrics_data[repo]=nameSpaceMetrics(data,self)};this.getReposMetricsData=function(){return this.repos_metrics_data};this.repos_global_data={};this.addRepoGlobalData=function(repo,data,self){if(self===undefined)self=this;self.repos_global_data[repo]=nameSpaceMetrics(data,self)};this.getReposGlobalData=function(){return this.repos_global_data};this.repositories_top_data={};this.addRepositoryTopData=function(repository,data,self){if(self===undefined)self=this;if(self.repositories_top_data[repository]===undefined)self.repositories_top_data[repository]={};self.repositories_top_data[repository]=data};this.getRepositoriesTopData=function(){return this.repositories_top_data};this.setRepositoriesTopData=function(data,self){if(self===undefined)self=this;self.repositories_top_data=data};this.countries_data_file=this.data_dir+""/""+this.name+""-countries.json"";this.getCountriesDataFile=function(){return this.countries_data_file};this.countries=null;this.getCountriesData=function(){return this.countries};this.setCountriesData=function(countries,self){if(self===undefined)self=this;self.countries=countries};this.countries_metrics_data={};this.addCountryMetricsData=function(country,data,self){if(self===undefined)self=this;self.countries_metrics_data[country]=nameSpaceMetrics(data,self)};this.getCountriesMetricsData=function(){return this.countries_metrics_data};this.countries_global_data={};this.addCountryGlobalData=function(country,data,self){if(self===undefined)self=this;self.countries_global_data[country]=nameSpaceMetrics(data,self)};this.getCountriesGlobalData=function(){return this.countries_global_data};this.domains_data_file=this.data_dir+""/""+this.name+""-domains.json"";this.getDomainsDataFile=function(){return this.domains_data_file};this.domains=null;this.getDomainsDataFull=function(){return this.domains};this.getDomainsData=function(){var items=this.domains;if(items instanceof Array===false){if(this.domains!==null){items=this.domains.name}}return items};this.setDomainsData=function(domains,self){if(domains===null)domains=[];if(self===undefined)self=this;self.domains=domains};this.domains_metrics_data={};this.addDomainMetricsData=function(domain,data,self){if(self===undefined)self=this;self.domains_metrics_data[domain]=nameSpaceMetrics(data,self)};this.getDomainsMetricsData=function(){return this.domains_metrics_data};this.domains_global_data={};this.addDomainGlobalData=function(domain,data,self){if(self===undefined)self=this;self.domains_global_data[domain]=nameSpaceMetrics(data,self)};this.getDomainsGlobalData=function(){return this.domains_global_data};this.projects_data_file=this.data_dir+""/""+this.name+""-projects.json"";this.getProjectsDataFile=function(){return this.projects_data_file};this.projects=null;this.getProjectsData=function(){return this.projects};this.setProjectsData=function(projects,self){if(projects===null)projects=[];if(!(projects instanceof Array))projects=[projects];if(self===undefined)self=this;self.projects=projects};this.projects_metrics_data={};this.addProjectMetricsData=function(project,data,self){if(self===undefined)self=this;self.projects_metrics_data[project]=nameSpaceMetrics(data,self)};this.getProjectsMetricsData=function(){return this.projects_metrics_data};this.projects_global_data={};this.addProjectGlobalData=function(project,data,self){if(self===undefined)self=this;self.projects_global_data[project]=nameSpaceMetrics(data,self)};this.getProjectsGlobalData=function(){return this.projects_global_data};this.people_metrics_data={};this.addPeopleMetricsData=function(id,data,self){if(self===undefined)self=this;self.people_metrics_data[id]=nameSpaceMetrics(data,self)};this.getPeopleMetricsData=function(){return this.people_metrics_data};this.people_global_data={};this.addPeopleGlobalData=function(id,data,self){if(self===undefined)self=this;self.people_global_data[id]=nameSpaceMetrics(data,self)};this.getPeopleGlobalData=function(){return this.people_global_data};this.getCompanyQuery=function(){var company=null;var querystr=window.location.search.substr(1);if(querystr&&querystr.split(""&"")[0].split(""="")[0]===""company"")company=querystr.split(""&"")[0].split(""="")[1];return company};this.displayMetricCompanies=function(metric_id,div_target,config,start,end){var companies_data=this.getCompaniesMetricsData();Viz.displayMetricCompanies(metric_id,companies_data,div_target,config,start,end)};this.displayMetricMyCompanies=function(companies,metric_id,div_target,config,start,end){var companies_data={};var self=this;$.each(companies,function(i,name){companies_data[name]=self.getCompaniesMetricsData()[name]});Viz.displayMetricCompanies(metric_id,companies_data,div_target,config,start,end)};this.displayMetricRepos=function(metric_id,div_target,config,start,end){var repos_data=this.getReposMetricsData();Viz.displayMetricRepos(metric_id,repos_data,div_target,config,start,end)};this.displayBasicMetricMyRepos=function(repos,metric_id,div_target,config,start,end){var repos_data={};var reposMap=Report.getReposMap();var self=this;$.each(repos,function(i,name){var metrics=self.getReposMetricsData()[name];if(!metrics){if(reposMap[name]instanceof Object){name=reposMap[name][self.getName()]}else{name=reposMap[name]}metrics=self.getReposMetricsData()[name]}repos_data[name]=metrics});Viz.displayMetricRepos(metric_id,repos_data,div_target,config,start,end)};this.displayMetricDomains=function(metric_id,div_target,config,start,end){var domains_data=this.getDomainsMetricsData();Viz.displayMetricDomains(metric_id,domains_data,div_target,config,start,end)};this.displayMetricProjects=function(metric_id,div_target,config,start,end){var projects_data=this.getProjectsMetricsData();Viz.displayMetricProjects(metric_id,projects_data,div_target,config,start,end)};this.displayMetricCompaniesStatic=function(metric_id,div_target,config,order_by,show_others){this.displayMetricSubReportStatic(""companies"",metric_id,div_target,config,order_by,show_others)};this.displayMetricReposStatic=function(metric_id,div_target,config,order_by,show_others){this.displayMetricSubReportStatic(""repos"",metric_id,div_target,config,order_by,show_others)};this.displayMetricCountriesStatic=function(metric_id,div_target,config,order_by,show_others){this.displayMetricSubReportStatic(""countries"",metric_id,div_target,config,order_by,show_others)};this.displayMetricDomainsStatic=function(metric_id,div_target,config,order_by,show_others){this.displayMetricSubReportStatic(""domains"",metric_id,div_target,config,order_by,show_others)};this.displayMetricProjectsStatic=function(metric_id,div_target,config,order_by,show_others){this.displayMetricSubReportStatic(""projects"",metric_id,div_target,config,order_by,show_others)};this.displayMetricSubReportStatic=function(report,metric_id,div_target,config,order_by,show_others){if(order_by===undefined)order_by=metric_id;var data=null;if(report==""companies"")data=this.getCompaniesGlobalData();else if(report==""repos"")data=this.getReposGlobalData();else if(report==""countries"")data=this.getCountriesGlobalData();else if(report==""domains"")data=this.getDomainsGlobalData();else if(report==""projects"")data=this.getProjectsGlobalData();else return;if($.isEmptyObject(data))return;var order=DataProcess.sortGlobal(this,order_by,report);if(order instanceof Array===false){order=order.name}data_page=DataProcess.paginate(order,Report.getCurrentPage());Viz.displayMetricSubReportStatic(metric_id,data,data_page,div_target,config)};this.displayMetricsCompany=function(company,metrics,div_id,config){var data=this.getCompaniesMetricsData()[company];if(data===undefined){$(""#""+div_id).hide();return}Viz.displayMetricsCompany(this,company,metrics,data,div_id,config)};this.displayMetricsRepo=function(repo,metrics,div_id,config){var data=this.getReposMetricsData()[repo];if(data===undefined){$(""#""+div_id).hide();return}Viz.displayMetricsRepo(this,repo,metrics,data,div_id,config)};this.displayMetricsCountry=function(country,metrics,div_id,config){var data=this.getCountriesMetricsData()[country];if(data===undefined){$(""#""+div_id).hide();return}Viz.displayMetricsCountry(this,country,metrics,data,div_id,config)};this.displayMetricsDomain=function(domain,metrics,div_id,config){var data=this.getDomainsMetricsData()[domain];if(data===undefined)return;Viz.displayMetricsDomain(this,domain,metrics,data,div_id,config)};this.displayMetricsProject=function(project,metrics,div_id,config){var data=this.getProjectsMetricsData()[project];if(data===undefined)return;Viz.displayMetricsProject(this,project,metrics,data,div_id,config)};this.displayMetricsPeople=function(upeople_id,upeople_identifier,metrics,div_id,config){var history=this.getPeopleMetricsData()[upeople_id];if(history===undefined||history instanceof Array){$(""#""+div_id).hide();return}Viz.displayMetricsPeople(this,upeople_identifier,metrics,history,div_id,config)};this.displayMetricsEvol=function(metric_ids,div_target,config,convert){var data={};var repositories;if(config.repo_filter){repositories=config.repo_filter.split("","");var self=this;$.each(repositories,function(id,value){if($.inArray(value,self.getReposData())>=0){if(self.getName()===""mls""){var mls_name=MLS.displayMLSListName(value);data[mls_name]=self.getReposMetricsData()[value]}else{data[value]=self.getReposMetricsData()[value]}}})}else{data=this.getData()}if(convert){data=DataProcess.convert(data,convert,metric_ids);if(convert===""divide""){mlabel=this.getMetrics()[metric_ids[0]].name+""/"";mlabel+=this.getMetrics()[metric_ids[1]].name;metric_ids=[""divide""];this.getMetrics().divide={name:mlabel}}if(convert===""substract""){mlabel=this.getMetrics()[metric_ids[0]].name+""-"";mlabel+=this.getMetrics()[metric_ids[1]].name;metric_ids=[""substract""];this.getMetrics().substract={name:mlabel}}}Viz.displayMetricsEvol(this,metric_ids,data,div_target,config,repositories)};this.isPageDisplayed=function(visited,linked,total,displayed){var window=Math.floor((displayed-3)/2);var lowest_barrier=visited-window;var highest_barrier=visited+window;if(linked===1||linked===total||linked==visited){return true}else if(linked>=lowest_barrier&&linked<visited){return true}else if(linked<=highest_barrier&&linked>visited){return true}else{return false}};this.displayItemsNav=function(div_nav,type,page_str,order_by){var page=parseInt(page_str,null);if(isNaN(page))page=1;var items=null;var title="""";var total=0;var displayed_pages=5;if(type===""companies""){items=this.getCompaniesData();title=""List of companies""}else if(type===""repos""){items=this.getReposData();if(order_by)items=DataProcess.sortGlobal(this,order_by,type)}else if(type===""countries""){items=this.getCountriesData()}else if(type===""domains""){items=this.getDomainsData()}else if(type===""projects""){items=this.getProjectsData()}else{return}total=items.length;var nav="""";var psize=Report.getPageSize();if(page){nav+=""<div class='pagination'>"";var number_pages=Math.ceil(total/psize);var from_item=(page-1)*psize+1;var to_item=page*psize;if(to_item>total){to_item=total}nav+=""<ul class='pagination'>"";if(page>1){if(Utils.isReleasePage()){nav+=""<li><a href='""+Utils.createReleaseLink(""?page=""+(page-1))+""'>&laquo;</a></li>""}else{nav+=""<li><a href='?page=""+(page-1)+""'>&laquo;</a></li>""}}else{if(Utils.isReleasePage()){nav+=""<li class='disabled'><a href='""+Utils.createReleaseLink(""?page=""+page)+""'>&laquo;</a></li>""}else{nav+=""<li class='disabled'><a href='?page=""+page+""'>&laquo;</a></li>""}}for(var j=0;j*Report.getPageSize()<total;j++){if(this.isPageDisplayed(page,j+1,number_pages,displayed_pages)===true){if(page===j+1){if(Utils.isReleasePage()){nav+=""<li class='active'><a href='""+Utils.createReleaseLink(""?page=""+(j+1))+""'>""+(j+1)+""</a></li>""}else{nav+=""<li class='active'><a href='?page=""+(j+1)+""'>""+(j+1)+""</a></li>""}}else{if(Utils.isReleasePage()){nav+=""<li><a href='""+Utils.createReleaseLink(""?page=""+(j+1))+""'>""+(j+1)+""</a></li>""}else{nav+=""<li><a href='?page=""+(j+1)+""'>""+(j+1)+""</a></li>""}}}else{if(j+1+1===number_pages||j+1-1===1){nav+=""<li class='disabled'><a href='#'> .. </a></li>""}}}if(page*Report.getPageSize()<items.length){if(Utils.isReleasePage()){nav+=""<li><a href='""+Utils.createReleaseLink(""?page=""+(parseInt(page,null)+1))+""'>""}else{nav+=""<li><a href='?page=""+(parseInt(page,null)+1)+""'>""}nav+=""&raquo;</a></li>""}nav+=""</ul>"";nav+=""<span class='pagination-text'> (""+from_item+"" - ""+to_item+""/""+total+"")</span>"";nav+=""</div>""}if(Report.getPageSize()>10)$.each(items,function(id,item){var label=Report.cleanLabel(item);nav+=""<a href='#""+item+""-nav'>""+label+""</a> ""});$(""#""+div_nav).append(nav)};this.displayCompaniesLinks=function(div_links,limit,sort_metric){var sorted_companies=DataProcess.sortGlobal(this,sort_metric,""companies"");var links="""";var i=0;$.each(sorted_companies,function(id,company){links+='<a href=""company.html?company='+company;if(Report.addDataDir())links+=""&""+Report.addDataDir();links+='"">'+company+""</a>| "";if(i++>=limit-1)return false});$(""#""+div_links).append(links)};this.displayCompaniesList=function(metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert){this.displaySubReportList(""companies"",metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert)};this.displayReposList=function(metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert){this.displaySubReportList(""repos"",metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert)};this.displayCountriesList=function(metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert){this.displaySubReportList(""countries"",metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert)};this.displayDomainsList=function(metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert){this.displaySubReportList(""domains"",metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert)};this.displayProjectsList=function(metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert){this.displaySubReportList(""projects"",metrics,div_id,config_metric,sort_metric,page,show_links,start,end,convert)};this.displaySubReportList=function(report,metrics,div_id,config_metric,sort_metric,page_str,show_links,start,end,convert){var page=parseInt(page_str,null);if(isNaN(page))page=1;var list="""";var cont=(page-1)*Report.getPageSize()+1;var ds=this;var data=null,sorted=null;if(show_links===undefined)show_links=true;if(report===""companies""){data=this.getCompaniesMetricsData();sorted=DataProcess.sortGlobal(this,sort_metric,report)}else if(report===""repos""){data=this.getReposMetricsData();sorted=DataProcess.sortGlobal(this,sort_metric,report)}else if(report===""countries""){data=this.getCountriesMetricsData();sorted=DataProcess.sortGlobal(this,sort_metric,report)}else if(report===""domains""){data=this.getDomainsMetricsData();sorted=DataProcess.sortGlobal(this,sort_metric,report)}else if(report===""projects""){data=this.getProjectsMetricsData();sorted=DataProcess.sortGlobal(this,sort_metric,report)}else return;sorted=DataProcess.paginate(sorted,page);list+='<table class=""table table-hover table-repositories"">';list+=""<tr><th></th>"";$.each(metrics,function(id,metric){if(ds.getMetrics()[metric]){title=ds.getMetrics()[metric].name;list+=""<th>""+title+""</th>""}else{list+=""<th>""+metric+""</th>""}});list+=""</tr>"";$.each(sorted,function(id,item){list+=""<tr><td class='col-md-2 repository-name'>"";list+=""#""+cont+""&nbsp;"";cont++;var addURL=null;if(Report.addDataDir())addURL=Report.addDataDir();if(show_links){var release_var="""";if(Utils.isReleasePage())release_var=""&release=""+$.urlParam(""release"");if(report===""companies""){list+=""<a href='company.html?company=""+item;list+=release_var;if(addURL)list+=""&""+addURL;list+=""'>""}else if(report===""repos""){list+=""<a href='"";list+=""repository.html"";list+=""?repository=""+encodeURIComponent(item);list+=release_var;list+=""&ds=""+ds.getName();if(addURL)list+=""&""+addURL;list+=""'>""}else if(report===""countries""){list+=""<a href='country.html?country=""+item;list+=release_var;if(addURL)list+=""&""+addURL;list+=""'>""}else if(report===""domains""){list+=""<a href='domain.html?domain=""+item;list+=release_var;if(addURL)list+=""&""+addURL;list+=""'>""}else if(report===""projects""){list+=""<a href='project.html?project=""+item;list+=release_var;if(addURL)list+=""&""+addURL;list+=""'>""}}list+=""<strong>"";list+=Report.cleanLabel(item);list+=""</strong>"";if(show_links)list+=""</a>"";list+=""</td>"";var width=Math.floor(10/metrics.length);$.each(metrics,function(id,metric){var mywidth=width;list+=""<td class='col-md-""+mywidth+""'>"";list+=""<div id='""+report+""-""+item+""-""+metric+""'"";list+="" class='subreport-list-item'>""});list+=""</td></tr>""});list+=""</table>"";$(""#""+div_id).append(list);var start_items=null,end_items=null,convert_items=null;if(start){if(typeof start===""number"")start_items=[start.toString()];else start_items=start.split("","")}if(end){if(typeof end===""number"")end_items=[end.toString()];else end_items=end.split("","")}if(convert)convert_items=convert.split("","");$.each(sorted,function(id,item){var i=0;$.each(metrics,function(id,metric){var mstart=null,mend=null,mconvert=null;if(start_items){if(start_items.length==1)mstart=start_items[0];else mstart=start_items[i]}if(end_items){if(end_items.length==1)mend=end_items[0];else mend=end_items[i]}if(convert_items)mconvert=convert_items[i];if(item in data===false)return;var item_data=data[item];if(item_data[metric]===undefined)return;var div_id=report+""-""+item+""-""+metric;var items={};items[item]=item_data;var title="""";Viz.displayMetricSubReportLines(div_id,metric,items,title,config_metric,mstart,mend,mconvert);i++})})};this.displayGlobalSummary=function(divid){this.displaySummary(null,divid,null,this)};this.displayCompanySummary=function(divid,company,ds){this.displaySummary(""companies"",divid,company,ds)};this.displayRepoSummary=function(divid,repo,ds){this.displaySummary(""repositories"",divid,repo,ds)};this.displayCountrySummary=function(divid,repo,ds){this.displaySummary(""countries"",divid,repo,ds)};this.displayDomainSummary=function(divid,domain,ds){this.displaySummary(""domains"",divid,domain,ds)};this.displayProjectSummary=function(divid,project,ds){this.displaySummary(""projects"",divid,project,ds)};this.displayPeopleSummary=function(divid,upeople_id,upeople_identifier,ds){var history=ds.getPeopleGlobalData()[upeople_id];if(history===undefined||history instanceof Array)return;html=HTMLComposer.personSummaryTable(ds.getName(),history);$(""#""+divid).append(html)};this.displayCompaniesSummary=function(divid,ds){var html="""";var data=ds.getGlobalData();html+=""Total companies: ""+data.companies+""<br>"";if(data.companies_2006)html+=""Companies in 2006: ""+data.companies_2006+""<br>"";if(data.companies_2009)html+=""Companies in 2009: ""+data.companies_2009+""<br>"";if(data.companies_2012)html+=""Companies in 2012: ""+data.companies_2012+""<br>"";$(""#""+divid).append(html)};this.getSummaryLabels=function(){};this.getLabelForRepository=function(){return""repository""};this.getLabelForRepositories=function(){return""repositories""};this.displaySummary=function(report,divid,item,ds){if(!item)item="""";var html=""<h6>""+ds.getTitle()+""</h6>"";var id_label=this.getSummaryLabels();var global_data=null;if(report===""companies"")global_data=ds.getCompaniesGlobalData()[item];else if(report===""countries"")global_data=ds.getCountriesGlobalData()[item];else if(report===""repositories"")global_data=ds.getReposGlobalData()[item];else if(report===""domains"")global_data=ds.getDomainsGlobalData()[item];else if(report===""projects"")global_data=ds.getProjectsGlobalData()[item]; else global_data=ds.getGlobalData();if(!global_data)return;html=HTMLComposer.repositorySummaryTable(ds,global_data,id_label);$(""#""+divid).append(html)};this.displayReposSummary=function(divid,ds){var html="""";var data=ds.getGlobalData();html+=""Total repositories: ""+data[ds.getName()+""_repositories""]+""<br>"";$(""#""+divid).append(html)};this.displayCountriesSummary=function(divid,ds){var html="""";var data=ds.getGlobalData();html+=""Total countries: ""+data[ds.getName()+""_countries""]+""<br>"";$(""#""+divid).append(html)};this.displayDomainsSummary=function(divid,ds){var html="""";var data=ds.getGlobalData();html+=""Total domains: ""+data.domains+""<br>"";$(""#""+divid).append(html)};this.displayProjectsSummary=function(divid,ds){var html="""";var data=ds.getGlobalData();html+=""Total projects: ""+data.projects+""<br>"";$(""#""+divid).append(html)};this.displayDemographics=function(divid,period){var data=this.getDemographicsData();Viz.displayDemographicsChart(divid,data,period)};this.displayTimeToAttention=function(div_id,column,labels,title){labels=true;title=""Time to Attention ""+column;var data=this.getTimeToAttentionData();if(data instanceof Array)return;Viz.displayTimeToAttention(div_id,data,column,labels,title)};this.displayTimeToFix=function(div_id,column,labels,title){labels=true;title=""Time to Fix ""+column;var data=this.getTimeToFixData();if(data instanceof Array)return;Viz.displayTimeToFix(div_id,this.getTimeToFixData(),column,labels,title)};this.displayMarkovTable=function(div_id,title){var data=this.getMarkovTableData();if(data===undefined){Report.log(""No Markov data available"");return}Viz.displayMarkovTable(div_id,data,title)};this.displayTop=function(div,all,show_metric,period,period_all,graph,limit,people_links,threads_links,repository){if(all===undefined)all=true;var titles=null;Viz.displayTop(div,this,all,show_metric,period,period_all,null,null,limit,people_links,threads_links,repository)};this.displayTopCompany=function(company,div,metric_id,period,titles){var data=this.getCompaniesTopData()[company];if(data===undefined)return;var metric=this.getMetrics()[metric_id];Viz.displayTopCompany(company,data,div,metric,period,titles)};this.displayTopGlobal=function(div,metric,period,titles){Viz.displayTopGlobal(div,this,metric,period,titles)};this.envisionEvo=function(div_id,history,relative,legend_show,summary_graph){config=Report.getVizConfig();var options=Viz.getEnvisionOptions(div_id,history,this.getName(),Report.getVizConfig()[this.getName()+""_hide""],summary_graph);options.legend_show=legend_show;if(relative)DataProcess.addRelativeValues(options.data,this.getMainMetric());new envision.templates.Envision_Report(options,[this])};this.displayEnvision=function(divid,relative,legend_show,summary_graph){var projects_full_data=Report.getProjectsDataSources();this.envisionEvo(divid,projects_full_data,relative,legend_show,summary_graph)}}if(Viz===undefined)var Viz={};(function(){var bitergiaColor=""#ffa500"";Viz.displayTop=displayTop;Viz.displayTopCompany=displayTopCompany;Viz.displayTopGlobal=displayTopGlobal;Viz.displayBasicChart=displayBasicChart;Viz.displayMetricCompanies=displayMetricCompanies;Viz.displayMetricSubReportStatic=displayMetricSubReportStatic;Viz.displayMetricsCompany=displayMetricsCompany;Viz.displayMetricsDomain=displayMetricsDomain;Viz.displayMetricsProject=displayMetricsProject;Viz.displayMetricsPeople=displayMetricsPeople;Viz.displayMetricsRepo=displayMetricsRepo;Viz.displayMetricRepos=displayMetricRepos;Viz.displayMetricsCountry=displayMetricsCountry;Viz.displayMetricDomains=displayMetricDomains;Viz.displayMetricProjects=displayMetricProjects;Viz.displayMetricsEvol=displayMetricsEvol;Viz.displayBubbles=displayBubbles;Viz.displayDemographicsChart=displayDemographicsChart;Viz.displayEnvisionAll=displayEnvisionAll;Viz.displayTimeToFix=displayTimeToFix;Viz.displayTimeToAttention=displayTimeToAttention;Viz.displayMetricSubReportLines=displayMetricSubReportLines;Viz.displayRadarActivity=displayRadarActivity;Viz.displayRadarCommunity=displayRadarCommunity;Viz.displayTreeMap=displayTreeMap;Viz.displayMarkovTable=displayMarkovTable;Viz.displayDataSourcesTable=displayDataSourcesTable;Viz.getEnvisionOptions=getEnvisionOptions;Viz.checkBasicConfig=checkBasicConfig;Viz.displayTimeZone=displayTimeZone;function findMetricDoer(history,metric_id){var doer="""";$.each(Report.getAllMetrics(),function(name,metric){if(metric.action===metric_id){doer=metric.column;return false}});return doer}function displayMarkovTable(div_id,data,title){var html=""<h4>""+title+""</h4>"";var table='<table id=""itsmarkovtable"" class=""table table-striped"">';table+=""<thead><tr><th>Transition</th><th>Number</th><th>Percent</th></tr></thead><tbody>"";$.each(data,function(i,val){subdata=data[i];old_value=""old_value"";new_value=""new_value"";percent=""f"";number=""issue"";for(var k=0;k<subdata[old_value].length;k++){var value_new=subdata[new_value][k];var value_p=subdata[percent][k];value_p=Math.round(value_p*100)/100;var value_num=subdata[number][k];table+=""<tr><td>""+i+"" -> ""+value_new+""</td>"";table+=""<td>""+value_num+""</td>"";table+=""<td>""+value_p+""</td></tr>""}});table+=""</tbody></table>"";html+=table;div=$(""#""+div_id);div.append(html);return}function translate(labels,l){if(labels.hasOwnProperty(l)){return labels[l]}else{return l}}function getTopVarsFromMetric(metric,ds_name){var var_names={};var_names.id=""id"";if(metric===""senders""&&(ds_name===""mls""||ds_name===""irc"")){var_names.name=""senders"";var_names.action=""sent""}if(metric===""authors""&&ds_name===""scm""){var_names.name=""authors"";var_names.action=""commits""}if(metric===""closers""&&(ds_name===""its""||ds_name===""its_1"")){var_names.name=""closers"";var_names.action=""closed""}if(ds_name===""scr""){if(metric===""mergers""){var_names.name=""mergers"";var_names.action=""merged""}if(metric===""openers""){var_names.name=""openers"";var_names.action=""opened""}if(metric===""reviewers""){var_names.name=""reviewers"";var_names.action=""reviews""}if(metric===""active_core_reviewers""){var_names.name=""identifier"";var_names.action=""reviews""}if(metric===""participants""){var_names.name=""identifier"";var_names.action=""events""}}if(ds_name===""downloads""){if(metric===""ips""){var_names.name=""ips"";var_names.action=""downloads""}if(metric===""packages""){var_names.name=""packages"";var_names.action=""downloads""}}if(ds_name===""mediawiki""){if(metric===""authors""){var_names.name=""authors"";var_names.action=""reviews""}}if(ds_name===""qaforums""){if(metric===""senders""||metric===""asenders""||metric===""qsenders""){var_names.name=""senders"";var_names.action=""sent""}else if(metric===""participants""){var_names.name=""name"";var_names.action=""messages_sent""}}if(ds_name===""releases""){if(metric===""authors""){var_names.name=""username"";var_names.action=""releases""}}return var_names}function getSortedPeriods(){return[""last month"",""last year"",""""]}function composeTopRowsDownloads(dl_data,limit,var_names){var rows_html="""";for(var j=0;j<dl_data[var_names.name].length;j++){if(limit&&limit<=j)break;var metric_value=dl_data[var_names.action][j];rows_html+=""<tr><td> ""+(j+1)+""</td>"";rows_html+=""<td>"";rows_html+=dl_data[var_names.name][j];rows_html+=""</td>"";rows_html+=""<td>""+metric_value+""</td></tr>""}return rows_html}function composeTopRowsThreads(threads_data,limit,threads_links){var rows_html="""";for(var i=0;i<threads_data.subject.length;i++){if(limit&&limit<=i)break;rows_html+=""<tr><td>#""+(i+1)+""</td>"";rows_html+=""<td>"";if(threads_links===true){var url=""http://www.google.com/search?output=search&q=X&btnI=1"";if(Report.getThreadsSite()!==undefined){url=""http://www.google.com/search?output=search&q=X%20site%3AY&btnI=1"";url=url.replace(/Y/g,Report.getThreadsSite())}else if(threads_data.hasOwnProperty(""url"")&&threads_data.url[i].length>0){url=""http://www.google.com/search?output=search&q=X%20site%3AY&btnI=1"";url=url.replace(/Y/g,threads_data.url[i])}url=url.replace(/X/g,threads_data.subject[i]);rows_html+=""<td>"";rows_html+='<a target=""_blank"" href=""'+url+'"">';rows_html+=threads_data.subject[i]+""</a>"";rows_html+='&nbsp;<i class=""fa fa-external-link""></i></td>'}else{rows_html+=""<td>""+threads_data.subject[i]+""</td>""}rows_html+=""<td>""+threads_data.initiator_name[i]+""</td>"";rows_html+=""<td>""+threads_data.length[i]+""</td>"";rows_html+=""</tr>""}return rows_html}function composeTopRowsPeople(people_data,limit,people_links,var_names){var rows_html="""";for(var j=0;j<people_data[var_names.id].length;j++){if(limit&&limit<=j)break;var metric_value=people_data[var_names.action][j];rows_html+=""<tr><td>""+(j+1)+""</td>"";rows_html+=""<td>"";if(people_links){rows_html+='<a href=""people.html?id='+people_data[var_names.id][j];get_params=Utils.paramsInURL();if(get_params.length>0)rows_html+=""&""+get_params;rows_html+='"">';rows_html+=DataProcess.hideEmail(people_data[var_names.name][j])+""</a>""}else{rows_html+=DataProcess.hideEmail(people_data[var_names.name][j])}rows_html+=""</td>"";rows_html+=""<td>""+metric_value+""</td></tr>""}return rows_html}function composeTopTabs(periods,metric,data,ds_name){var tabs_html="""";var first=true;tabs_html+='<ul id=""myTab"" class=""nav nav-tabs"">';for(var i=0;i<periods.length;i++){var mykey=metric+"".""+periods[i];if(data[mykey]){var data_period=periods[i];var data_period_formatted=data_period;if(data_period===""""){data_period=""all"";data_period_formatted=""Complete history""}else if(data_period===""last month""){data_period_formatted=""Last 30 days""}else if(data_period===""last year""){data_period_formatted=""Last 365 days""}var data_period_nows=data_period.replace(/\ /g,"""");var html="""";if(first===true){html=' class=""active""';first=false}tabs_html+=""<li""+html+'><a href=""#'+ds_name+metric+data_period_nows+'""data-toogle=""tab"">';tabs_html+=data_period_formatted+""</a></li>""}}tabs_html+=""</ul>"";return tabs_html}function composeTitle(metric,ds_name,tabs,desc_metrics,selected_period){var key=ds_name+""_""+metric;var desc="""";var title="""";if(key in desc_metrics){desc=desc_metrics[key].desc;desc=desc.toLowerCase()}if(selected_period===""""){data_period_formatted=""Complete history""}else if(selected_period===""last month""){data_period_formatted=""Last 30 days""}else if(selected_period===""last year""){data_period_formatted=""Last 365 days""}if(Utils.isReleasePage())data_period_formatted=""Release history"";if(tabs===true){title+=""<h6>Top ""+desc+""</h6>""}else{title+='<div class=""toptable-title"">'+data_period_formatted+""</div>""}return title}String.prototype.capitalize=function(){return this.replace(/(?:^|\s)\S/g,function(a){return a.toUpperCase()})};function displayTopMetric_new(div_id,data,metric,limit,desc_metrics,people_links,threads_links,selected_period){var tabs="""";var tables="""";var title="""";var gen_tabs=true;var div=$(""#""+div_id);var ds_name=div.attr(""data-data-source"");if(Report.getParameterByName(""repository"")!==undefined){people_links=false}periods=getSortedPeriods();if(selected_period!==undefined){gen_tabs=false}title+=composeTitle(metric,ds_name,gen_tabs,desc_metrics,selected_period);if(gen_tabs===true){tabs+=composeTopTabs(periods,metric,data,ds_name)}tables+='<div class=""tab-content"">';var var_names=getTopVarsFromMetric(metric,ds_name);if(gen_tabs===true){var first=true;var html="""";for(var k=0;k<periods.length;k++){html="""";var key=metric+"".""+periods[k];if(data[key]){var data_period=periods[k];if(data_period===""""){data_period=""all""}var data_period_nows=data_period.replace(/\ /g,"""");if(first===true){html="" active in"";first=false}tables+='<div class=""tab-pane fade'+html+'"" id=""'+ds_name+metric+data_period_nows+'"">';tables+='<table class=""table table-striped"">';if(metric===""threads""){tables+=composeTopRowsThreads(data[key],limit,threads_links)}else if(metric===""packages""||metric===""ips""){unit=desc_metrics[ds_name+""_""+metric].action;metric_name=desc_metrics[ds_name+""_""+metric].name;tables+=""<thead><th>#</th><th>""+metric_name.capitalize()+""</th>"";if(unit!==undefined)tables+=""<th>""+unit.capitalize()+""</th>"";tables+=""</thead><tbody>"";tables+=composeTopRowsDownloads(data[key],limit,var_names)}else{unit=desc_metrics[ds_name+""_""+metric].action;metric_name=desc_metrics[ds_name+""_""+metric].name;tables+=""<thead><th>#</th><th>""+metric_name.capitalize()+""</th>"";if(unit!==undefined)tables+=""<th>""+unit.capitalize()+""</th>"";tables+=""</thead><tbody>"";tables+=composeTopRowsPeople(data[key],limit,people_links,var_names);tables+=""</tbody>""}tables+=""</table>"";tables+=""</div>""}}}else{tables+='<table class=""table table-striped""><tbody>';if(metric===""threads""){tables+=composeTopRowsThreads(data,limit,threads_links)}else if(metric===""packages""||metric===""ips""){unit=desc_metrics[ds_name+""_""+metric].action;tables+=""<thead><th>#</th><th>""+metric.capitalize()+""</th>"";if(unit!==undefined)tables+=""<th>""+unit.capitalize()+""</th>"";tables+=""</thead><tbody>"";tables+=composeTopRowsDownloads(data,limit,var_names)}else{unit=desc_metrics[ds_name+""_""+metric].action;tables+=""<thead><th>#</th><th>""+metric.capitalize()+""</th>"";if(unit!==undefined)tables+=""<th>""+unit.capitalize()+""</th>"";tables+=""</thead><tbody>"";tables+=composeTopRowsPeople(data,limit,people_links,var_names);tables+=""</tbody>""}tables+=""</tbody></table>""}tables+=""</div>"";if(gen_tabs===false){div.append(title)}div.append(tabs);div.append(tables);if(gen_tabs===true){script=""<script>$('#myTab a').click(function (e) {e.preventDefault();$(this).tab('show');});</script>"";div.append(script)}}function displayTopMetric(div_id,metric,metric_period,history,graph,titles,limit,people_links){var top_metric_id=metric.name;if(!history||$.isEmptyObject(history))return;var metric_id=metric.action;if(limit&&history[metric_id].length<limit){limit=history[metric_id].length;graph=false}var doer=metric.column;if(doer===undefined)doer=findMetricDoer(history,metric_id);var title=""Top ""+top_metric_id+"" ""+metric_period;var table=displayTopMetricTable(history,metric_id,doer,limit,people_links,title);var div=null;if(table===undefined)return;if(titles===false){div=$(""#""+div_id);div.append(table);return}var div_graph="""";var new_div="""";if(graph){div_graph=""top-""+graph+""-""+doer+""-"";div_graph+=metric_id+""-""+metric_period;new_div+=""<div id='""+div_graph+""' class='graph' style='float:right'></div>""}new_div+=table;div=$(""#""+div_id);div.append(new_div);if(graph){var labels=history[doer];var data=history[metric_id];if(limit){labels=[];data=[];for(var i=0;i<limit;i++){labels.push(history[doer][i]);data.push(history[metric_id][i])}}displayBasicChart(div_graph,labels,data,graph)}}function displayDataSourcesTable(div){dsources=Report.getDataSources();html='<table class=""table table-striped"">';html+=""<thead><th>Data Source</th><th>From</th>"";html+=""<th>To <small>(Updated on)</small></th></thead><tbody>"";$.each(dsources,function(key,ds){if(ds.getName()===""people"")return;var gdata=ds.getGlobalData();var ds_name=ds.getTitle();if(ds_name===undefined){ds_name=""-""}var last_date=gdata.last_date;if(last_date===undefined){return}var first_date=gdata.first_date;if(first_date===undefined){first_date=""-""}var type=gdata.type;html+=""<tr><td>""+ds_name;if(type!==undefined){type=type.toLowerCase();type=type.charAt(0).toUpperCase()+type.slice(1);html+="" (""+type+"")""}html+=""</td>"";html+=""<td>""+first_date+""</td>"";html+=""<td>""+last_date+""</td></tr>""});html+=""</tbody></table>"";$(div).append(html)}function showHelp(div_id,metrics,custom_help){var all_metrics=Report.getAllMetrics();var help='<a href=""#"" class=""help""';var content="""";if(custom_help===""""){var addContent=function(id,value){if(metrics[i]===id){content+=""<strong>""+value.name+""</strong>: ""+value.desc+""<br>"";return false}};for(var i=0;i<metrics.length;i++){$.each(all_metrics,addContent)}}else{content=""<strong>Description</strong>: ""+custom_help}help+='data-content=""'+content+'"" data-html=""true"">';help+='<img src=""qm_15.png""></a>';var old_help=$(""#""+div_id).prev()[0];if(old_help&&old_help.className===""help"")$(""#""+div_id).prev().empty();$(""#""+div_id).before(help)}function displayMetricsLines(div_id,metrics,history,title,config){if(!(config&&config.help===false))showHelp(div_id,metrics,config.custom_help);var lines_data=[];if(config.remove_last_point)history=DataProcess.revomeLastPoint(history);if(config.frame_time)history=DataProcess.frameTime(history,metrics);if(config.start_time)history=DataProcess.filterDates(config.start_time,config.end_time,history);$.each(metrics,function(id,metric){if(!history[metric])return;var mdata=[];$.each(history[metric],function(i,value){mdata[i]=[history.id[i],history[metric][i]]});var label=metric;if(Report.getAllMetrics()[metric])label=Report.getAllMetrics()[metric].name;lines_data.push({label:label,data:mdata})});displayDSLines(div_id,history,lines_data,title,config)}function displayMetricsLinesRepos(div_id,metrics,history,title,config,repositories){if(!(config&&config.help===false))showHelp(div_id,metrics,config.custom_help);var lines_data=[];var metric=metrics[0];var aux={};$.each(history,function(item,data){if(data===undefined)return false;if(data[metric]===undefined)return false;if(config.remove_last_point)data=DataProcess.revomeLastPoint(data);if(config.frame_time)data=DataProcess.frameTime(data,[metric]);if(config.start_time)data=DataProcess.filterDates(config.start_time,config.end_time,data);var mdata=[[],[]];$.each(data[metric],function(i,value){mdata[i]=[data.id[i],data[metric][i]]});lines_data.push({label:item,data:mdata});aux=data});displayDSLines(div_id,aux,lines_data,title,config)}function displayMetricSubReportLines(div_id,metric,items,title,config,start,end,convert,order){var lines_data=[];var history={};$.each(items,function(item,data){if(data===undefined)return false;if(data[metric]===undefined)return false;if(convert)data=DataProcess.convert(data,convert,metric);if(start)data=DataProcess.filterDates(start,end,data);if(config.frame_time)data=DataProcess.frameTime(data,[metric]);var cdata=[[],[]];for(var i=0;i<data.id.length;i++){cdata[i]=[data.id[i],data[metric][i]]}item=Report.cleanLabel(item);lines_data.push({label:item,data:cdata});history=data});if(lines_data.length===0)return;if(order){var order_lines_data=[];$.each(order,function(i,value_order){$.each(lines_data,function(j,value){if(value_order===value.label){order_lines_data.push(value);return false}})});lines_data=order_lines_data}displayDSLines(div_id,history,lines_data,title,config)}Viz.track_formatter_com_pending=function(o){scr=Report.getDataSourceByName(""scr"");companies=scr.getCompaniesMetricsData();dhistory=Viz._history;lines_data=Viz._lines_data;var label=dhistory.date[parseInt(o.index,10)];if(label===undefined)label="""";else label+=""<br>"";for(var i=0;i<lines_data.length;i++){var value=lines_data[i].data[o.index][1];if(value===undefined)continue;if(lines_data.length>1){if(lines_data[i].label!==undefined)company_name=lines_data[i].label;label+=lines_data[i].label+"":""}label+=""<strong>""+Report.formatValue(value)+""</strong>"";if(company_name)label+=""(""+companies[company_name].pending[o.index]+"")"";label+=""<br>""}return label};function getConfLinesChart(title,legend_div,history,lines_data,mouse_tracker_fn){var config={subtitle:title,legend:{show:true,container:legend_div},xaxis:{minorTickFreq:4,mode:""time"",timeUnit:""second"",timeFormat:""%b %y"",margin:true},yaxis:{min:null,noTicks:2,autoscale:true},grid:{verticalLines:false,color:""#000000"",outlineWidth:1,outline:""s""},mouse:{container:legend_div,track:true,trackY:false,relative:true,position:""ne"",trackFormatter:function(o){var label=history.date[parseInt(o.index,10)];if(label===undefined)label="""";else label+=""<br>"";for(var i=0;i<lines_data.length;i++){var value=lines_data[i].data[o.index][1];if(value===undefined)continue;if(lines_data.length>1){if(lines_data[i].label!==undefined){value_name=abbreviateLabel(lines_data[i].label);label+=value_name+"":""}}label+=""<strong>""+Report.formatValue(value)+""</strong><br>""}return label}},selection:{mode:""x"",fps:10},shadowSize:4};if(mouse_tracker_fn){Viz._history=history;Viz._lines_data=lines_data;config.mouse.trackFormatter=Viz[mouse_tracker_fn]}return config}function dropLastLineValue(history,lines_data){if(lines_data.length===0)return lines_data;if(lines_data.length>1){for(var j=0;j<lines_data.length;j++){var last=lines_data[j].data.length-1;lines_data[j].data[last][1]=undefined}}}function lastLineValueToPoint(history,lines_data){if(lines_data.length!==1)return lines_data;var last=lines_data[0].data.length;var dots=[];var utime=0;for(var i=0;i<last-1;i++){utime=parseInt(history.unixtime[i],10);dots.push([utime,undefined])}utime=parseInt(history.unixtime[last-1],10);dots.push([utime,lines_data[0].data[last-1][1]]);var dot_graph={data:dots};dot_graph.points={show:true,radius:3,lineWidth:1,fillColor:null,shadowSize:0};lines_data.push(dot_graph);lines_data[0].data[last-1][1]=undefined;lines_data[1].label=lines_data[0].label;return lines_data}function composeRangeText(former_title,starting_utime,end_utime){var months=[""Jan"",""Feb"",""Mar"",""Apr"",""May"",""Jun"",""Jul"",""Aug"",""Sep"",""Oct"",""Nov"",""Dec""];var date=new Date(parseInt(starting_utime,10)*1e3);var starting_date=months[date.getMonth()]+"" ""+date.getFullYear();date=new Date(parseInt(end_utime,10)*1e3);var end_date=months[date.getMonth()]+"" ""+date.getFullYear();return former_title+"" ( ""+starting_date+"" - ""+end_date+"" )""}function sortBiArray(bi_array){bi_array.sort(function(a,b){return a[1]>b[1]||b[1]===undefined?1:-1});return bi_array}function getMax(multiple_array,from_unixstamp,to_unixstamp){from_unixstamp=Math.round(from_unixstamp);to_unixstamp=Math.round(to_unixstamp);var narrays=multiple_array.length;var aux_array=[];for(var i=0;i<narrays;i++){for(var z=multiple_array[i].data.length-1;z>0;z--){var aux_value=multiple_array[i].data[z][0];var cond=aux_value<from_unixstamp||aux_value>to_unixstamp;if(cond){multiple_array[i].data.splice(z,1)}}}var res=[];for(i=0;i<narrays;i++){aux_array=multiple_array[i].data;aux_array=sortBiArray(aux_array);res.push(aux_array[aux_array.length-1][1])}res.sort(function(a,b){return a-b});return res[res.length-1]}function addEmptyValue(lines_data){if(lines_data[0].data.length==1){return}var step=lines_data[0].data[1][0]-lines_data[0].data[0][0];var narrays=lines_data.length;var last_date=0;for(var i=0;i<narrays;i++){var mylength=lines_data[i].data.length;last_date=lines_data[i].data[mylength-1][0];lines_data[i].data.push([last_date+step,undefined])}return lines_data}function displayDSLines(div_id,history,lines_data,title,config_metric){var use_stacked=false;if(config_metric){if(config_metric.lines&&config_metric.lines.stacked){use_stacked=true}}if(use_stacked){displayDSLinesStacked(div_id,history,lines_data,title,config_metric)}else if(history.unixtime===undefined){displayDSLinesStacked(div_id,history,lines_data,title,config_metric)}else{displayDSLinesZoom(div_id,history,lines_data,title,config_metric)}}function abbreviateLabel(string){if(string.length>=18){var l=string.length;return""..""+string.slice(string.length-16)}else{return string}}function displayDSLinesStacked(div_id,history,lines_data,title,config_metric){var container=document.getElementById(div_id);var legend_div=null;if(config_metric&&config_metric.legend&&config_metric.legend.container)legend_div=$(""#""+config_metric.legend.container);var config={subtitle:title,legend:{show:true,container:legend_div},xaxis:{minorTickFreq:4,tickFormatter:function(x){var index=null;for(var i=0;i<history.id.length;i++){if(parseInt(x,10)===history.id[i]){index=i;break}}return history.date[index]}},yaxis:{min:0,noTicks:2,autoscale:false},grid:{verticalLines:false,color:""#000000"",outlineWidth:1,outline:""s""},mouse:{container:legend_div,track:true,trackY:false,trackFormatter:function(o){var label=history.date[parseInt(o.index,10)];if(label===undefined)label="""";else label+=""<br>"";for(var i=0;i<lines_data.length;i++){var value=lines_data[i].data[o.index][1];if(value===undefined)continue;if(lines_data.length>1){if(lines_data[i].label!==undefined)label+=abbreviateLabel(lines_data[i].label)+"":""}label+=Report.formatValue(value)+""<br>""}return label}}};if(config_metric){if(!config_metric.show_title)config.title="""";if(""show_legend""in config_metric){if(config_metric.show_legend===true)config.legend.show=true;else config.legend.show=false}if(config_metric.lines&&config_metric.lines.stacked)config.lines={stacked:true,fill:true,fillOpacity:1,fillBorder:true,lineWidth:.01};if(!config_metric.show_labels){config.xaxis.showLabels=false;config.yaxis.showLabels=false}if(config_metric.show_grid===false){config.grid.verticalLines=false;config.grid.horizontalLines=false;config.grid.outlineWidth=0}if(config_metric.show_mouse===false){config.mouse.track=false}if(config_metric.graph===""bars""){config.bars={show:true}}if(config_metric.light_style===true){config.grid.color=""#ccc"";config.legend.show=false}if(config_metric.custom_title){config.subtitle=config_metric.custom_title}}var showLastPoint=false;if(config_metric.graph!==""bars""&&lines_data.length===1&&lines_data[0].data[0][0]===0){showLastPoint=true}if(showLastPoint){lines_data=lastLineValueToPoint(history,lines_data);var next_id=history.id[history.id.length-1]+1;lines_data[0].data.push([next_id,undefined]);lines_data[1].data.push([next_id,undefined]);history.date.push("""");history.id.push(next_id)}graph=Flotr.draw(container,lines_data,config);if(showLastPoint){if(history.date)history.date.pop();if(history.id)history.id.pop()}}function guessBarWidth(lines_data,history){var gap_size;var data_sets=lines_data.length;gap_size=parseInt(history.unixtime[1],10)-parseInt(history.unixtime[0],10);return gap_size/(data_sets+1)}function timeToUnixTime(lines_data,history,bars_flag,bar_width){var number_lines=lines_data.length;var data_length=lines_data[0].data.length;for(var z=0;z<number_lines;z++){for(var i=0;i<data_length;i++){if(bars_flag){lines_data[z].data[i][0]=parseInt(history.unixtime[i],10)+z*bar_width}else{lines_data[z].data[i][0]=parseInt(history.unixtime[i],10)}}}return lines_data}function displayDSLinesZoom(div_id,history,lines_data,title,config_metric){var bars_flag=false;var bar_width;if(lines_data.length===0)return;var container=document.getElementById(div_id);var legend_div=null;if(config_metric&&config_metric.legend&&config_metric.legend.container)legend_div=$(""#""+config_metric.legend.container);var config=getConfLinesChart(title,legend_div,history,lines_data,config_metric.mouse_tracker);if(config_metric){if(!config_metric.show_title)config.title="""";if(""show_legend""in config_metric){if(config_metric.show_legend===true)config.legend.show=true;else config.legend.show=false}if(config_metric.lines&&config_metric.lines.stacked){config.lines={stacked:true,fill:true,fillOpacity:1,fillBorder:true,lineWidth:.01}}if(!config_metric.show_labels){config.xaxis.showLabels=false;config.yaxis.showLabels=false}if(config_metric.show_grid===false){config.grid.verticalLines=false;config.grid.horizontalLines=false;config.grid.outlineWidth=0}if(config_metric.show_mouse===false){config.mouse.track=false}if(config_metric.graph===""bars""){config.bars={show:true,stacked:false,horizontal:false,barWidth:728e3,lineWidth:1};config.bars.barWidth=guessBarWidth(lines_data,history);bars_flag=true;bar_width=config.bars.barWidth}if(config_metric.light_style===true){config.grid.color=""#ccc"";config.legend.show=false}if(config_metric.custom_title){config.subtitle=config_metric.custom_title}config.mouse.position=""n"";config.mouse.margin=20}if(lines_data.length>1)config.legend.show=true;lines_data=timeToUnixTime(lines_data,history,bars_flag,bar_width);var showLastPoint=false;if(Utils.isReleasePage()===false){if(config_metric.graph!==""bars""&&lines_data.length===1){showLastPoint=true}if(showLastPoint){lines_data=lastLineValueToPoint(history,lines_data);addEmptyValue(lines_data)}else if(!showLastPoint&&lines_data.length>1){dropLastLineValue(history,lines_data)}}function drawGraph(opts){var o=Flotr._.extend(Flotr._.clone(config),opts||{});return Flotr.draw(container,lines_data,o)}graph=drawGraph();Flotr.EventAdapter.observe(container,""flotr:select"",function(area){var zoom_options={xaxis:{minorTickFreq:4,mode:""time"",timeUnit:""second"",timeFormat:""%b %y"",min:area.x1,max:area.x2},yaxis:{min:area.y1,autoscale:true},grid:{verticalLines:true,color:""#000000"",outlineWidth:1,outline:""s""}};zoom_options.subtitle=composeRangeText(config.subtitle,area.xfirst,area.xsecond);var new_lines_data_object=JSON.parse(JSON.stringify(lines_data));var max_value=getMax(new_lines_data_object,area.x1,area.x2);zoom_options.yaxis.max=max_value+max_value*.2;graph=drawGraph(zoom_options)});Flotr.EventAdapter.observe(container,""flotr:click"",function(){drawGraph()});$(window).resize(function(){drawGraph()})}function displayTimeZone(divid,labels,data,metric_name){var pretty_mname=metric_name.charAt(0).toUpperCase()+metric_name.slice(1);var title=pretty_mname+"" by Time Zone"";var container=document.getElementById(divid);var chart_data=[],i;var legend_div=null;for(i=0;i<data.length;i++){chart_data.push({data:[[labels[i],data[i]]],label:i})}var config={subtitle:title,grid:{verticalLines:false,outlineWidth:0,horizontalLines:true},xaxis:{tickFormatter:function(value){var label=""UTC "";if(value>0)label+=""+""+value;else label+=value;return label},color:""#000000"",tickDecimals:0},yaxis:{showLabels:true,min:0,noTicks:2,color:""#000000""},mouse:{track:true,trackY:false,relative:true,position:""n"",trackDecimals:0,trackFormatter:function(tuple){var label=""UTC "";if(tuple.x>0)label+=""+""+tuple.x;else label+=tuple.x;pretty_name=metric_name.charAt(0).toUpperCase()+metric_name.slice(1);label+=""<br/> ""+pretty_name+"": <strong>""+tuple.y+""</strong>"";return label}},legend:{show:false},bars:{show:true,color:""#008080"",fillColor:""#008080"",fillOpacity:.6}};graph=Flotr.draw(container,chart_data,config);$(window).resize(function(){graph=Flotr.draw(container,chart_data,config)})}function displayBasicChart(divid,labels,data,graph,title,config_metric,rotate,fixColor,yformatter){var horizontal=false;if(rotate)horizontal=true;var container=document.getElementById(divid);var legend_div=null;if(config_metric&&config_metric.legend&&config_metric.legend.container)legend_div=$(""#""+config_metric.legend.container);var chart_data=[],i;var label="""";if(!horizontal){for(i=0;i<data.length;i++){if(labels)label=DataProcess.hideEmail(labels[i]);chart_data.push({data:[[i,data[i]]],label:label})}}else{for(i=0;i<data.length;i++){if(labels)label=DataProcess.hideEmail(labels[i]);chart_data.push({data:[[data[i],i]],label:label})}}var config={subtitle:title,grid:{verticalLines:false,horizontalLines:false,outlineWidth:0},xaxis:{showLabels:false,min:0},yaxis:{showLabels:false,min:0},mouse:{container:legend_div,track:true,trackFormatter:function(o){var i=""x"";if(horizontal)i=""y"";var label="""";if(labels)label=DataProcess.hideEmail(labels[parseInt(o[i],10)])+"": "";return label+data[parseInt(o[i],10)]}},legend:{show:false,position:""se"",backgroundColor:""#D2E8FF"",container:legend_div}};if(config_metric){if(!config_metric.show_title)config.title="""";if(config_metric.show_legend)config.legend.show=true}if(graph===""bars""){config.bars={show:true,horizontal:horizontal};if(fixColor){config.bars.color=fixColor;config.bars.fillColor=fixColor}if(config_metric&&config_metric.show_legend!==false)config.legend={show:true,position:""ne"",container:legend_div};config.grid.horizontalLines=true;config.yaxis={showLabels:true,min:0};if(config_metric&&config_metric.xaxis)config.xaxis={showLabels:config_metric.xaxis,min:0};if(yformatter){config.yaxis={showLabels:true,min:0,tickFormatter:yformatter}}}if(graph===""pie""){config.pie={show:true};config.mouse.position=""ne""}graph=Flotr.draw(container,chart_data,config)}function displayMultiColumnChart(divid,labels,data,title,config_metric,rotate,yformatter,period_year){var bar_width=.4;var lseries=data[0].length;if(data[1].length>lseries)lseries=data[1].length;var horizontal=false;if(rotate)horizontal=true;var container=document.getElementById(divid);var legend_div=null;if(config_metric&&config_metric.legend&&config_metric.legend.container)legend_div=$(""#""+config_metric.legend.container);var serie1=[],i,serie2=[],data_viz=[];for(i=0;i<lseries;i++){var val1,val2;if(data[0].length>i)val1=data[0][i];else val1=undefined;if(data[1].length>i)val2=data[1][i];else val2=undefined;if(!horizontal){serie1.push([i-bar_width/2,val1]);serie2.push([i+bar_width/2,val2]) }else{serie1.push([val1,i-bar_width/2]);serie2.push([val2,i+bar_width/2])}}data_viz=[{data:serie1,label:labels[0]},{data:serie2,label:labels[1]}];var config={title:title,bars:{show:true,horizontal:horizontal,barWidth:bar_width},grid:{verticalLines:false,horizontalLines:false,outlineWidth:0},xaxis:{showLabels:false,min:0},yaxis:{showLabels:true,min:0},mouse:{container:legend_div,track:true,trackFormatter:function(o){var index;var i=""x"";if(horizontal)i=""y"";var point=parseFloat(o[i],1);var point_down=Math.round((point-.2)*10)/10;var point_up=Math.round((point+.2)*10)/10;if(point_down===parseInt(point,10))index=point_down;else index=point_up;var years=index;if(period_year)years=index*period_year;var label=years+"" years: "";var val1,val2;if(serie1[index]===undefined)val1=0;else val1=parseInt(serie1[index][0],10);if(isNaN(val1))val1=0;if(serie2[index]===undefined)val2=0;else val2=parseInt(serie2[index][0],10);if(isNaN(val2))val2=0;label+=val1+"" ""+labels[0];label+="" , "";label+=val2+"" ""+labels[1];label+="" (""+parseInt(val1/val2*100,10)+""% )"";return label}},legend:{show:true,position:""ne"",backgroundColor:""#D2E8FF"",container:legend_div}};if(config_metric){if(!config_metric.show_title)config.title="""";if(config_metric.show_legend)config.legend.show=true}if(config_metric&&config_metric.show_legend!==false)config.legend={show:true,position:""ne"",container:legend_div};config.grid.horizontalLines=true;config.yaxis={showLabels:true,min:0};if(yformatter){config.yaxis={showLabels:true,min:0,tickFormatter:yformatter}}if(config_metric&&config_metric.xaxis)config.xaxis={showLabels:config_metric.xaxis,min:0};graph=Flotr.draw(container,data_viz,config)}function displayBubbles(divid,metric1,metric2,radius){var container=document.getElementById(divid);var DS=Report.getMetricDS(metric1)[0];var DS1=Report.getMetricDS(metric2)[0];var bdata=[];if(DS!=DS1){Report.log(""Metrics for bubbles have different data sources"");return}var full_data=[];var projects=[];$.each(Report.getDataSources(),function(index,ds){if(ds.getName()===DS.getName()){full_data.push(ds.getData());projects.push(ds.getProject())}});var dates=[[],[]];dates=[full_data[0].id,full_data[0].date];for(var i=0;i<full_data.length;i++){if(full_data[i]instanceof Array)return;dates=DataProcess.fillDates(dates,[full_data[i].id,full_data[i].date])}for(var j=0;j<full_data.length;j++){var serie=[];var data=full_data[j];var data1=DataProcess.fillHistory(dates[0],[data.id,data[metric1]]);var data2=DataProcess.fillHistory(dates[0],[data.id,data[metric2]]);for(i=0;i<dates[0].length;i++){serie.push([dates[0][i],data1[1][i],data2[1][i]])}bdata.push({label:projects[j],data:serie})}var config={bubbles:{show:true,baseRadius:5},mouse:{track:true,trackFormatter:function(o){var value=full_data[0].date[o.index]+"": "";value+=o.series.label+"" "";value+=o.series.data[o.index][1]+"" ""+metric1+"","";value+=o.series.data[o.index][2]+"" ""+metric2;return value}},xaxis:{tickFormatter:function(o){return full_data[0].date[parseInt(o,10)-full_data[0].id[0]]}}};if(DS.getName()===""its"")$.extend(config.bubbles,{baseRadius:1});if(radius){$.extend(config.bubbles,{baseRadius:radius})}Flotr.draw(container,bdata,config)}function displayDemographicsChart(divid,data,period_year){if(!data)return;if(!period_year)period_year=.25;else period=365*period_year;var period_data_aging=[];var period_data_birth=[];var labels=[],i;var config={show_legend:false,xaxis:true};var age,index;for(i=0;i<data.aging.persons.age.length;i++){age=data.aging.persons.age[i];age=age.toString().split("" "")[0];index=parseInt(age/period,10);if(!period_data_aging[index])period_data_aging[index]=0;period_data_aging[index]+=1}for(i=0;i<data.birth.persons.age.length;i++){age=data.birth.persons.age[i];age=age.toString().split("" "")[0];age=age.split("" "")[0];index=parseInt(age/period,10);if(!period_data_birth[index])period_data_birth[index]=0;period_data_birth[index]+=1}labels=[""Retained"",""Attracted""];yticks=function(val,axisOpts){var period=period_year;var unit=""years"";val=val*period_year;return val+"" ""+unit};var period_data=[period_data_aging,period_data_birth];if(data)displayMultiColumnChart(divid,labels,period_data,"""",config,true,yticks,period_year)}function displayRadarChart(div_id,ticks,data){var container=document.getElementById(div_id);var max=$(""#""+div_id).data(""max"");var border=.2;if(!max)max=0;for(var j=0;j<data.length;j++){for(var i=0;i<data[j].data.length;i++){var value=data[j].data[i][1];if(value>max){max=value;max=parseInt(max*(1+border),10)}}}(function(){var x=[data,ticks]})();graph=Flotr.draw(container,data,{radar:{show:true},mouse:{track:true,trackFormatter:function(o){var value="""";for(var i=0;i<data.length;i++){value+=data[i].label+"" "";value+=data[i].data[o.index][1]+"" "";value+=ticks[o.index][1]+""<br>""}return value}},grid:{circular:true,minorHorizontalLines:true},yaxis:{min:0,max:max,minorTickFreq:1},xaxis:{ticks:ticks}})}function displayRadar(div_id,metrics){var data=[],ticks=[];var radar_data=[];var projects=[];var i=0,j=0;for(i=0;i<metrics.length;i++){var DS=Report.getMetricDS(metrics[i]);for(j=0;j<DS.length;j++){if(!data[j]){data[j]=[];projects[j]=DS[j].getProject()}data[j].push([i,parseInt(DS[j].getGlobalData()[metrics[i]],10)])}ticks.push([i,DS[0].getMetrics()[metrics[i]].name])}for(j=0;j<data.length;j++){radar_data.push({label:projects[j],data:data[j]})}displayRadarChart(div_id,ticks,radar_data)}function displayRadarCommunity(div_id){var metrics=[""scm_committers"",""scm_authors"",""its_openers"",""its_closers"",""its_changers"",""mls_senders""];displayRadar(div_id,metrics)}function displayRadarActivity(div_id){var metrics=[""scm_commits"",""scm_files"",""its_opened"",""its_closed"",""its_changed"",""mls_sent""];displayRadar(div_id,metrics)}function displayTimeToAttention(div_id,ttf_data,column,labels,title){displayTimeTo(div_id,ttf_data,column,labels,title)}function displayTimeToFix(div_id,ttf_data,column,labels,title){displayTimeTo(div_id,ttf_data,column,labels,title)}function displayTimeTo(div_id,ttf_data,column,labels,title){var metrics=column.split("","");var history=ttf_data.data;if(!history[metrics[0]])return;var new_history={};new_history.date=history.date;$.each(history,function(name,data){if($.inArray(name,metrics)===-1)return;new_history[name]=[];for(var i=0;i<data.length;i++){var hours=parseFloat((parseInt(data[i],null)/24).toFixed(2),10);new_history[name].push(hours)}});new_history.id=[];for(var i=0;i<history[metrics[0]].length;i++){new_history.id.push(i)}var config={show_legend:true,show_labels:true};displayMetricsLines(div_id,metrics,new_history,column,config)}function displayTop(div,ds,all,selected_metric,period,period_all,graph,titles,limit,people_links,threads_links,repository){var desc_metrics=ds.getMetrics();if(all===undefined)all=true;var history;if(repository===undefined){history=ds.getGlobalTopData()}else{history=ds.getRepositoriesTopData()[repository]}if(Utils.isReleasePage()){period_all=false;period=""""}if(period_all===true){var filtered_history={};$.each(history,function(key,value){var aux=key.split(""."");var data_metric=aux[0];var data_period=aux[1];if(selected_metric&&selected_metric!==data_metric){return true}if(selected_metric&&selected_metric===data_metric){filtered_history[key]=history[key]}});displayTopMetric_new(div,filtered_history,selected_metric,limit,desc_metrics,people_links,threads_links)}else{$.each(history,function(key,value){var aux=key.split(""."");var data_metric=aux[0];var data_period=aux[1];if(selected_metric&&selected_metric!==data_metric)return true;if(period!==undefined&&period!==data_period)return true;displayTopMetric_new(div,history[key],selected_metric,limit,desc_metrics,people_links,threads_links,period)})}}function displayTopCompany(company,data,div,metric,period,titles){var graph=null;displayTopMetric(div,metric,period,data,graph,titles)}function displayTopGlobal(div,data_source,metric_id,period,titles){var project=data_source.getProject();var metric=data_source.getMetrics()[metric_id];var graph=null;if(!data_source.getGlobalTopData()[metric_id])return;data=data_source.getGlobalTopData()[metric_id][period];displayTopMetric(div,project,metric,period,data,graph,titles)}function displayTreeMap(divid,data_file,data){if(data===undefined){if(data_file===undefined)return;Loader.get_file_data_div(data_file,Viz.displayTreeMap,divid);return}else if(data===null)return;var color=d3.scale.category20c();var div=d3.select(""#""+divid);var width=$(""#""+divid).width(),height=$(""#""+divid).height();var treemap=d3.layout.treemap().size([width,height]).sticky(true).value(function(d){return d.size});var position=function(){this.style(""left"",function(d){return d.x+""px""}).style(""top"",function(d){return d.y+""px""}).style(""width"",function(d){return Math.max(0,d.dx-1)+""px""}).style(""height"",function(d){return Math.max(0,d.dy-1)+""px""})};var node=div.datum(data).selectAll("".node"").data(treemap.nodes).enter().append(""div"").attr(""class"",""treemap-node"").call(position).style(""background"",function(d){return d.children?color(d.name):null}).text(function(d){return d.children?null:d.name});d3.selectAll(""input"").on(""change"",function change(){var value=this.value===""count""?function(){return 1}:function(d){return d.size};node.data(treemap.value(value).nodes).transition().duration(1500).call(position)})}Viz.getEnvisionOptionsMin=function(div_id,history,hide){var firstMonth=history.id[0],container=document.getElementById(div_id),options;var markers=Report.getMarkers();var basic_metrics=Report.getAllMetrics();options={container:container,xTickFormatter:function(index){var label=history.date[index-firstMonth];if(label===""0"")label="""";return label},yTickFormatter:function(n){return n+""""},selection:{data:{x:{min:history.id[0],max:history.id[history.id.length-1]}}}};options.data={summary:[history.id,history.sent],markers:markers,dates:history.date,envision_hide:hide,main_metric:""sent""};var all_metrics=Report.getAllMetrics();var label=null;for(var metric in history){label=metric;if(all_metrics[metric])label=all_metrics[metric].name;options.data[metric]=[{label:label,data:[history.id,history[metric]]}]}options.trackFormatter=function(o){var sdata=o.series.data,index=sdata[o.index][0]-firstMonth;var value=history.date[index]+"":<br>"";for(var metric in basic_metrics){if(history[metric]===undefined)continue;value+=history[metric][index]+"" ""+metric+"" , ""}return value};return options};function getEnvisionOptions(div_id,projects_data,ds_name,hide,summary_graph){var basic_metrics=null,main_metric="""",summary_data=[[],[]];if(ds_name){$.each(Report.getDataSources(),function(i,DS){if(DS.getName()===ds_name){basic_metrics=DS.getMetrics();return false}})}else basic_metrics=Report.getAllMetrics();$.each(Report.getDataSources(),function(i,DS){main_metric=DS.getMainMetric();if(ds_name===null&&DS.getName()===""scm""||ds_name&&DS.getName()==ds_name){summary_data=[DS.getData().id,DS.getData()[main_metric]];if(summary_graph===false)summary_data=[DS.getData().id,[]];return false}});var dates=[[],[]];$.each(projects_data,function(project,data){$.each(data,function(index,DS){if(ds_name&&ds_name!==DS.getName())return;dates=DataProcess.fillDates(dates,[DS.getData().id,DS.getData().date])})});var firstMonth=dates[0][0],container=document.getElementById(div_id),options;var markers=Report.getMarkers();options={container:container,xTickFormatter:function(index){var label=dates[1][index-firstMonth];if(label===""0"")label="""";return label},yTickFormatter:function(n){return n+""""},selection:{data:{x:{min:dates[0][0],max:dates[0][dates[0].length-1]}}}};options.data={summary:DataProcess.fillHistory(dates[0],summary_data),markers:markers,dates:dates[1],envision_hide:hide,main_metric:main_metric};var project=null;var buildProjectInfo=function(index,ds){var data=ds.getData();if(data[metric]===undefined)return;if(options.data[metric]===undefined)options.data[metric]=[];var full_data=DataProcess.fillHistory(dates[0],[data.id,data[metric]]);if(metric===main_metric){options.data[metric].push({label:project,data:full_data});if(data[metric+""_relative""]===undefined)return;if(options.data[metric+""_relative""]===undefined)options.data[metric+""_relative""]=[];full_data=DataProcess.fillHistory(dates[0],[data.id,data[metric+""_relative""]]);options.data[metric+""_relative""].push({label:project,data:full_data})}else{options.data[metric].push({label:project,data:full_data})}};var buildProjectsInfo=function(name,pdata){project=name;$.each(pdata,buildProjectInfo)};for(var metric in basic_metrics){$.each(projects_data,buildProjectsInfo)}options.trackFormatter=function(o){var sdata=o.series.data,index=sdata[o.index][0]-firstMonth;var project_metrics={};var projects=Report.getProjectsList();for(var j=0;j<projects.length;j++){project_metrics[projects[j]]={}}var value=dates[1][index]+"":<br>"";for(var metric in basic_metrics){if(options.data[metric]===undefined)continue;if($.inArray(metric,options.data.envision_hide)>-1)continue;for(j=0;j<projects.length;j++){if(options.data[metric][j]===undefined)continue;var project_name=options.data[metric][j].label;var pdata=options.data[metric][j].data;value=pdata[1][index];project_metrics[project_name][metric]=value}}value=""<table><tr><td align='right'>""+dates[1][index]+""</td></tr>"";value+=""<tr>"";if(projects.length>1)value+=""<td></td>"";for(metric in basic_metrics){if(options.data[metric]===undefined)continue;if($.inArray(metric,options.data.envision_hide)>-1)continue;value+=""<td>""+basic_metrics[metric].name+""</td>""}value+=""</tr>"";$.each(project_metrics,function(project,metrics){var row=""<tr>"";for(var metric in basic_metrics){if(options.data[metric]===undefined)continue;if($.inArray(metric,options.data.envision_hide)>-1)continue;mvalue=project_metrics[project][metric];if(mvalue===undefined)mvalue=""n/a"";row+=""<td>""+mvalue+""</td>""}if(projects.length>1)row=""<td>""+project+""</td>""+row;row+=""</tr>"";value+=row});value+=""</table>"";return value};return options}function checkBasicConfig(config){if(config===undefined)config={};if(config.show_desc===undefined)config.show_desc=true;if(config.show_title===undefined)config.show_title=true;if(config.show_labels===undefined)config.show_labels=true;return config}function getMetricFriendlyName(ds,metrics){var desc_metrics=ds.getMetrics();var title="""";for(var i=0;i<metrics.length;i++){if(i!==0){title+="" vs. ""}if(metrics[i]in desc_metrics)title+=desc_metrics[metrics[i]].name;else title+=metrics[i]}return title}function displayMetricsEvol(ds,metrics,data,div_target,config,repositories){config=checkBasicConfig(config);var title="""";if(config.show_title){if(config.title===undefined){title=getMetricFriendlyName(ds,metrics)}else{title=config.title}}if(repositories!==undefined){displayMetricsLinesRepos(div_target,metrics,data,title,config)}else{displayMetricsLines(div_target,metrics,data,title,config)}}function displayMetricsCompany(ds,company,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricsRepo(ds,repo,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricsDomain(ds,domain,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricsProject(ds,project,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricsPeople(ds,upeople_identifier,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricRepos(metric,data,div_target,config,start,end){config=checkBasicConfig(config);if(config.show_legend!==false)config.show_legend=true;var title=metric;displayMetricSubReportLines(div_target,metric,data,title,config,start,end)}function displayMetricsCountry(ds,country,metrics,data,div_id,config){config=checkBasicConfig(config);var title=getMetricFriendlyName(ds,metrics);displayMetricsLines(div_id,metrics,data,title,config)}function displayMetricCompanies(metric,data,div_target,config,start,end,order){config=checkBasicConfig(config);if(config.show_legend!==false)config.show_legend=true;var title=metric;displayMetricSubReportLines(div_target,metric,data,title,config,start,end,null,order)}function displayMetricDomains(metric,data,div_target,config,start,end){config=checkBasicConfig(config);if(config.show_legend!==false)config.show_legend=true;var title=metric;displayMetricSubReportLines(div_target,metric,data,title,config,start,end)}function displayMetricProjects(metric,data,div_target,config,start,end){config=checkBasicConfig(config);if(config.show_legend!==false)config.show_legend=true;var title=metric;displayMetricSubReportLines(div_target,metric,data,title,config,start,end)}function displayMetricSubReportStatic(metric,data,order,div_id,config){config=checkBasicConfig(config);var title="""";if(config.title===undefined)title=metric;else title=config.title;var metric_data=[];var labels=[];var graph=""bars"";if(config.graph)graph=config.graph;$.each(order,function(i,name){var label=Report.cleanLabel(name);labels.push(label);metric_data.push(data[name][metric])});displayBasicChart(div_id,labels,metric_data,graph,title,config)}function displayEnvisionAll(div_id,relative,legend_show,summary_graph){var projects_full_data=Report.getProjectsDataSources();var config=Report.getVizConfig();var options=Viz.getEnvisionOptions(div_id,projects_full_data,null,config.summary_hide,summary_graph);options.legend_show=legend_show;if(relative){$.each(projects_full_data,function(project,data){$.each(data,function(index,DS){main_metric=DS.getMainMetric()})});DataProcess.addRelativeValues(options.data,main_metric)}new envision.templates.Envision_Report(options)}})();function IRC(){var self=this;this.basic_metrics={irc_sent:{divid:""irc_sent"",column:""sent"",name:""Sent"",desc:""Messages sent""},irc_senders:{divid:""irc_senders"",column:""senders"",name:""Senders"",desc:""Messages senders"",action:""sent""},irc_repositories:{divid:""irc_repositories"",column:""repositories"",name:""Repositories"",desc:""Number of active repositories""}};this.getMainMetric=function(){return""irc_sent""};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End""};return id_label};this.getLabelForRepository=function(){return""channel""};this.getLabelForRepositories=function(){return""channels""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .irc_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().irc_url}if(this.global_data.type)$(div_id+"" #irc_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #irc_url"").attr(""href"",url);$(div_id+"" #irc_name"").text(""IRC ""+this.global_data.type)}else{$(div_id+"" #irc_url"").attr(""href"",Report.getProjectData().irc_url);$(div_id+"" #irc_name"").text(Report.getProjectData().irc_name);$(div_id+"" #irc_type"").text(Report.getProjectData().irc_type)}var data=this.getGlobalData();$(div_id+"" #ircFirst"").text(data.first_date);$(div_id+"" #ircLast"").text(data.last_date);$(div_id+"" #ircSent"").text(data.irc_sent);$(div_id+"" #ircRepositories"").text(data.irc_repositories);if(data.repositories===1)$(div_id+"" #ircRepositories"").hide()};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""irc_sent"",""irc_senders"",radius)};this.getTitle=function(){return""IRC Messages""}}IRC.prototype=new DataSource(""irc"");function ITS(){this.basic_metrics={its_opened:{divid:""its_opened"",column:""opened"",name:""Opened"",desc:""Number of opened tickets"",envision:{y_labels:true,show_markers:true}},its_openers:{divid:""its_openers"",column:""openers"",name:""Openers"",desc:""Unique identities opening tickets"",action:""opened"",envision:{gtype:""whiskers""}},its_closed:{divid:""its_closed"",column:""closed"",name:""Closed"",desc:""Number of closed tickets""},its_closers:{divid:""its_closers"",column:""closers"",name:""Closers"",desc:""Number of identities closing tickets"",action:""closed"",envision:{gtype:""whiskers""}},its_bmitickets:{divid:""its_bmitickets"",column:""bmitickets"",name:""Efficiency"",desc:""Efficiency closing tickets: number of closed ticket out of the opened ones in a given period""},its_changed:{divid:""its_changed"",column:""changed"",name:""Changed"",desc:""Number of changes to the state of tickets""},its_changers:{divid:""its_changers"",column:""changers"",name:""Changers"",desc:""Number of identities changing the state of tickets"",action:""changed"",envision:{gtype:""whiskers""}},its_companies:{divid:""its_companies"",column:""companies"",name:""Companies"",desc:""Number of active companies""},its_countries:{divid:""its_countries"",column:""countries"",name:""Countries"",desc:""Number of active countries""},its_repositories:{divid:""its_repositories"",column:""repositories"",name:""Respositories"",desc:""Number of active respositories""},its_domains:{divid:""its_domains"",column:""domains"",name:""Domains"",desc:""Number of active domains""}};this.getMainMetric=function(){return""its_opened""};this.getSummaryLabels=function(){var labels={first_date:""Start"",last_date:""End"",tickets:""Tickets"",trackers:""Trackers""};return labels};this.getLabelForRepository=function(){return""tracker""};this.getLabelForRepositories=function(){return""trackers""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .its-info"").hide();return}$(div_id+"" #its_type"").text(this.global_data.type);var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().its_url}if(url===undefined)url="""";if(this.global_data.type===""allura"")url=url.replace(""rest/"","""");else if(this.global_data.type===""github""){url=url.replace(""api."","""");url=url.replace(""repos/"","""")}$(div_id+"" #its_url"").attr(""href"",url);var tracker_str=this.global_data.type.charAt(0).toUpperCase()+this.global_data.type.slice(1);$(div_id+"" #its_name"").text(tracker_str+"" Tickets"");var data=this.getGlobalData();$(div_id+"" #itsFirst"").text(data.first_date);$(div_id+"" #itsLast"").text(data.last_date);$(div_id+"" #itsTickets"").text(data.its_opened);$(div_id+"" #itsOpeners"").text(data.its_openers);$(div_id+"" #itsRepositories"").text(data.its_repositories);if(data.repositories===1)$(div_id+"" #itsRepositories"").hide()};this.getTitle=function(){return""Tickets""};this.displayBubbles=function(divid,radius){Viz.displayBubbles(divid,""its_opened"",""its_openers"",radius)}}ITS.prototype=new DataSource(""its"");function ITS_1(){this.basic_metrics={its_1_opened:{divid:""its_1_opened"",column:""opened"",name:""Opened tickets"",desc:""Number of opened tickets"",envision:{y_labels:true,show_markers:true}},its_1_openers:{divid:""its_1_openers"",column:""openers"",name:""Openers"",desc:""Unique identities opening tickets"",action:""opened"",envision:{gtype:""whiskers""}},its_1_stories_opened:{divid:""its_1_stories_opened"",column:""stories_opened"",name:""Stories Opened"",desc:""Number of opened stories""},its_1_stories_openers:{divid:""its_1_stories_openers"",column:""stories_openers"",name:""Stories Openers"",desc:""Unique identities opening stories"",action:""opened""},its_1_closed:{divid:""its_1_closed"",column:""closed"",name:""Closed tickets"",desc:""Number of closed tickets""},its_1_closers:{divid:""its_1_closers"",column:""closers"",name:""Closers"",desc:""Number of identities closing tickets"",action:""closed"",envision:{gtype:""whiskers""}},its_1_stories_closed:{divid:""its_1_stories_closed"",column:""stories_closed"",name:""Closed stories"",desc:""Number of closed stories""},its_1_stories_pending:{divid:""its_1_stories_pending"",column:""stories_pending"",name:""Pending stories"",desc:""Number of pending stories""},its_1_bmitickets:{divid:""its_1_bmitickets"",column:""bmitickets"",name:""Efficiency"",desc:""Efficiency closing tickets: number of closed ticket out of the opened ones in a given period""},its_1_changed:{divid:""its_1_changed"",column:""changed"",name:""Changed"",desc:""Number of changes to the state of tickets""},its_1_changers:{divid:""its_1_changers"",column:""changers"",name:""Changers"",desc:""Number of identities changing the state of tickets"",action:""changed"",envision:{gtype:""whiskers""}},its_1_companies:{divid:""its_1_companies"",column:""companies"",name:""Companies"",desc:""Number of active companies""},its_1_countries:{divid:""its_1_countries"",column:""countries"",name:""Countries"",desc:""Number of active countries""},its_1_repositories:{divid:""its_1_repositories"",column:""repositories"",name:""Respositories"",desc:""Number of active respositories""},its_1_domains:{divid:""its_1_domains"",column:""domains"",name:""Domains"",desc:""Number of active domains""}};this.getMainMetric=function(){return""its_1_opened""};this.getSummaryLabels=function(){var labels={first_date:""Start"",last_date:""End"",tickets:""Tickets"",trackers:""Trackers""};return labels};this.getLabelForRepository=function(){return""tracker""};this.getLabelForRepositories=function(){return""trackers""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .its-info"").hide();return}$(div_id+"" #its_type"").text(this.global_data.type);var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().its_url}if(url===undefined)url="""";if(this.global_data.type===""allura"")url=url.replace(""rest/"","""");else if(this.global_data.type===""github""){url=url.replace(""api."","""");url=url.replace(""repos/"","""")}$(div_id+"" #its_url"").attr(""href"",url);var tracker_str=this.global_data.type.charAt(0).toUpperCase()+this.global_data.type.slice(1);$(div_id+"" #its_name"").text(tracker_str+"" Tickets"");var data=this.getGlobalData();$(div_id+"" #itsFirst"").text(data.first_date);$(div_id+"" #itsLast"").text(data.last_date);$(div_id+"" #itsTickets"").text(data.its_1_opened);$(div_id+"" #itsOpeners"").text(data.its_1_openers);$(div_id+"" #itsRepositories"").text(data.its_1_repositories);if(data.repositories===1)$(div_id+"" #itsRepositories"").hide()};this.getTitle=function(){return""Tickets""};this.displayBubbles=function(divid,radius){Viz.displayBubbles(divid,""its_1_opened"",""its_1_openers"",radius)}}ITS_1.prototype=new DataSource(""its_1"");function MediaWiki(){var self=this;this.basic_metrics={mediawiki_reviews:{divid:""mediawiki_reviews"",column:""reviews"",name:""Editions"",desc:""Wiki page editions""},mediawiki_authors:{divid:""mediawiki_authors"",column:""authors"",name:""Editors"",desc:""Editors doing editions"",action:""reviews""},mediawiki_pages:{divid:""mediawiki_pages"",column:""pages"",name:""Pages"",desc:""Wiki pages""}};this.getMainMetric=function(){return""mediawiki_reviews""};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End""};return id_label};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .mediawiki_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().mediawiki_url}if(this.global_data.type)$(div_id+"" #mediawiki_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #mediawiki_url"").attr(""href"",url);$(div_id+"" #mediawiki_name"").text(""MediaWiki ""+this.global_data.type)}else{$(div_id+"" #mediawiki_url"").attr(""href"",Report.getProjectData().mediawiki_url);$(div_id+"" #mediawiki_name"").text(Report.getProjectData().mediawiki_name);$(div_id+"" #mediawiki_type"").text(Report.getProjectData().mediawiki_type)}var data=this.getGlobalData();$(div_id+"" #mediawikiFirst"").text(data.first_date);$(div_id+"" #mediawikiLast"").text(data.last_date);$(div_id+"" #mediawikiSent"").text(data.mediawiki_reviews)};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""mediawiki_reviews"",""mediawiki_authors"",radius)};this.getTitle=function(){return""MediaWiki Reviews""}}MediaWiki.prototype=new DataSource(""mediawiki"");function MLS(){var self=this;this.basic_metrics={mls_responses:{divid:""mls_responses"",column:""responses"",name:""Responses"",desc:""Number of messages that are responses""},mls_sent:{divid:""mls_sent"",column:""sent"",name:""Sent"",desc:""Number of messages""},mls_senders:{divid:""mls_senders"",column:""senders"",name:""Senders"",desc:""Number of unique message senders"",action:""sent""},mls_threads:{divid:""mls_threads"",column:""threads"",name:""Threads"",desc:""Number of messages threads""},mls_companies:{divid:""mls_companies"",column:""companies"",name:""Companies"",desc:""Number of active companies""},mls_countries:{divid:""mls_countries"",column:""countries"",name:""Countries"",desc:""Number of active countries""},mls_repositories:{divid:""mls_repositories"",column:""repositories"",name:""Respositories"",desc:""Number of active respositories""},mls_domains:{divid:""mls_domains"",column:""domains"",name:""Domains"",desc:""Number of active domains""}};this.data_lists_file=this.data_dir+""/mls-lists.json"";this.getListsFile=function(){return this.data_lists_file};this.data_lists=null;this.getListsData=function(){return this.data_lists};this.setListsData=function(lists,self){if(self===undefined)self=this;self.data_lists=lists};this.setDataDir=function(dataDir){this.data_dir=dataDir;this.data_lists_file=this.data_dir+""/mls-lists.json"";MLS.prototype.setDataDir.call(this,dataDir)};this.getMainMetric=function(){return""mls_sent""};this.getSummaryLabels=function(){var labels={first_date:""Start"",last_date:""End""};return labels};this.getLabelForRepository=function(){return""mailing list""};this.getLabelForRepositories=function(){return""mailing lists""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .mls_info"").hide()}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().mls_url}if(this.global_data.type)$(div_id+"" #mls_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #mls_url"").attr(""href"",url);$(div_id+"" #mls_name"").text(""MLS ""+this.global_data.type)}else{$(div_id+"" #mls_url"").attr(""href"",Report.getProjectData().mls_url);$(div_id+"" #mls_name"").text(Report.getProjectData().mls_name);$(div_id+"" #mls_type"").text(Report.getProjectData().mls_type)}var data=this.getGlobalData();$(div_id+"" #mlsFirst"").text(data.first_date);$(div_id+"" #mlsLast"").text(data.last_date);$(div_id+"" #mlsMessages"").text(data.mls_sent);$(div_id+"" #mlsSenders"").text(data.mls_senders);$(div_id+"" #mlsRepositories"").text(data.mls_repositories);if(data.repositories===1)$(div_id+"" #mlsRepositories"").hide()};this.displayBubbles=function(divid,radius){Viz.displayBubbles(divid,""mls_sent"",""mls_senders"",radius)};MLS.displayMLSListName=function(listinfo){var list_name_tokens=listinfo.split(""_"");var list_name="""";if(list_name_tokens.length>1){list_name=list_name_tokens[list_name_tokens.length-1];if(list_name==="""")list_name=list_name_tokens[list_name_tokens.length-2]}else{list_name=listinfo.replace(""<"","""");list_name=list_name.replace("">"","""");list_name_tokens=list_name.split(""."");list_name=list_name_tokens[0]}return list_name};function getUserLists(){var form=document.getElementById(""form_mls_selector"");var lists=[];for(var i=0;i<form.elements.length;i++){if(form.elements[i].checked)lists.push(form.elements[i].value)}if(localStorage){localStorage.setItem(getMLSId(),JSON.stringify(lists))}return lists}this.displayBasicUserAll=function(id,all){var form=document.getElementById(""form_mls_selector"");for(var i=0;i<form.elements.length;i++){if(form.elements[i].type==""checkbox"")form.elements[i].checked=all}this.displayBasicUser(id)};this.displayBasicUser=function(div_id){$(""#""+div_id).empty();lists=getUserLists();for(var i=0;i<lists.length;i++){var l=lists[i];file_messages=this.getDataDir()+""/mls-"";file_messages+=l;file_messages+=""-evolutionary.json"";displayBasicList(div_id,l,file_messages)}};this.displayBasic=function(div_id,config_metric){var lists=this.getListsData(); lists_hide=Report.getConfig().mls_hide_lists;lists=lists.mailing_list;if(lists===undefined)return null;var user_pref=false;if(typeof lists===""string"")lists=[lists];if(localStorage){if(localStorage.length&&localStorage.getItem(getMLSId())){lists=JSON.parse(localStorage.getItem(getMLSId()));user_pref=true}}for(var i=0;i<lists.length;i++){var l=lists[i];if(!user_pref)if($.inArray(l,lists_hide)>-1)continue;file_messages=this.getDataDir()+""/mls-"";file_messages+=l;file_messages+=""-evolutionary.json"";displayBasicList(div_id,l,file_messages,config_metric)}};this.getTitle=function(){return""Mailing Lists""};function displayBasicList(div_id,l,mls_file,config_metric){var config=Viz.checkBasicConfig(config_metric);for(var id in basic_metrics){var metric=basic_metrics[id];var title="""";if(config.show_title)title=metric.name;if($.inArray(metric.column,Report.getConfig().mls_hide)>-1)continue;var new_div=""<div class='info-pill m0-box-div flotr2-""+metric.column+""'>"";new_div+=""<h4>""+metric.name+"" ""+MLS.displayMLSListName(l)+""</h4>"";new_div+=""<div id='""+metric.divid+""_""+l+""' class='m0-box flotr2-""+metric.column+""'></div>"";if(config.show_desc)new_div+=""<p>""+metric.desc+""</p>"";new_div+=""</div>"";$(""#""+div_id).append(new_div);Viz.displayBasicLinesFile(metric.divid+""_""+l,mls_file,metric.column,config.show_labels,title)}}function getReportId(){var project_data=Report.getProjectData();return project_data.date+""_""+project_data.project_name}function getMLSId(){return getReportId()+""_mls_lists""}this.displayEvoListsMain=function(id){if(localStorage){if(localStorage.length&&localStorage.getItem(getMLSId())){lists=JSON.parse(localStorage.getItem(getMLSId()));return this.displayEvoLists(id,lists)}}history=this.getListsData();lists=history.mailing_list;if(lists===undefined)return;var config=Report.getConfig();lists_hide=config.mls_hide_lists;if(typeof lists===""string""){lists=[lists]}var filtered_lists=[];for(var i=0;i<lists.length;i++){if($.inArray(lists[i],lists_hide)==-1)filtered_lists.push(lists[i])}if(localStorage){if(!localStorage.getItem(getMLSId())){localStorage.setItem(getMLSId(),JSON.stringify(filtered_lists))}}this.displayEvoLists(id,filtered_lists)};function cleanLocalStorage(){if(localStorage){if(localStorage.length&&localStorage.getItem(getMLSId())){localStorage.removeItem(getMLSId())}}}this.getDefaultLists=function(){var default_lists=[];var hide_lists=Report.getConfig().mls_hide_lists;$.each(this.getListsData().mailing_list,function(index,list){if($.inArray(list,hide_lists)===-1)default_lists.push(list)});return default_lists};this.displaySelectorCheckDefault=function(){var default_lists=this.getDefaultLists();var form=document.getElementById(""form_mls_selector"");for(var i=0;i<form.elements.length;i++){if(form.elements[i].type==""checkbox""){var id=form.elements[i].id;l=id.split(""_check"")[0];if($.inArray(l,default_lists)>-1)form.elements[i].checked=true;else form.elements[i].checked=false}}};this.displayBasicDefault=function(div_id){var obj=self;if(this instanceof MLS)obj=this;cleanLocalStorage();obj.displaySelectorCheckDefault();$(""#""+div_id).empty();obj.displayBasic(div_id)};this.displayEvoDefault=function(div_id){var obj=self;if(this instanceof MLS)obj=this;cleanLocalStorage();if(document.getElementById(""form_mls_selector""))obj.displaySelectorCheckDefault();$(""#""+div_id).empty();obj.displayEvoLists(div_id,obj.getDefaultLists())};this.displayEvoUserAll=function(id,all){var form=document.getElementById(""form_mls_selector"");for(var i=0;i<form.elements.length;i++){if(form.elements[i].type==""checkbox"")form.elements[i].checked=all}this.displayEvoUser(id)};this.displayEvoUser=function(id){$(""#""+id).empty();var obj=self;if(this instanceof MLS)obj=this;obj.displayEvoLists(id,getUserLists())};this.displayEvoListSelector=function(div_id_sel,div_id_mls){this.displayEvoBasicListSelector(div_id_sel,div_id_mls,null)};this.displayBasicListSelector=function(div_id_sel,div_id_mls){this.displayEvoBasicListSelector(div_id_sel,null,div_id_mls)};this.displayEvoBasicListSelector=function(div_id_sel,div_id_evo,div_id_basic){var res1=this.getListsData();var lists=res1.mailing_list;var user_lists=[];if(lists===undefined)return;if(localStorage){if(localStorage.length&&localStorage.getItem(getMLSId())){user_lists=JSON.parse(localStorage.getItem(getMLSId()))}}Report.displayBasicUser=this.displayBasicUser;Report.displayBasicUserAll=this.displayBasicUserAll;Report.displayBasicDefault=this.displayBasicDefault;Report.displayEvoDefault=this.displayEvoDefault;Report.displayEvoUser=this.displayEvoUser;Report.displayEvoUserAll=this.displayEvoUserAll;var html=""Mailing list selector:"";html+=""<form id='form_mls_selector'>"";if(typeof lists===""string""){lists=[lists]}for(var i=0;i<lists.length;i++){var l=lists[i];html+='<input type=checkbox name=""check_list"" value=""'+l+'"" ';html+='onClick=""';if(div_id_evo)html+=""Report.displayEvoUser('""+div_id_evo+""');"";if(div_id_basic)html+=""Report.displayBasicUser('""+div_id_basic+""')\"";"";html+='"" ';html+='id=""'+l+'_check"" ';if($.inArray(l,user_lists)>-1)html+=""checked "";html+="">"";html+=MLS.displayMLSListName(l);html+=""<br>""}html+='<input type=button value=""All"" ';html+='onClick=""';if(div_id_evo)html+=""Report.displayEvoUserAll('""+div_id_evo+""',true);"";if(div_id_basic)html+=""Report.displayBasicUserAll('""+div_id_basic+""',true);"";html+='"">';html+='<input type=button value=""None"" ';html+='onClick=""';if(div_id_evo)html+=""Report.displayEvoUserAll('""+div_id_evo+""',false);"";if(div_id_basic)html+=""Report.displayBasicUserAll('""+div_id_basic+""',false);"";html+='"">';html+='<input type=button value=""Default"" ';html+='onClick=""';if(div_id_evo)html+=""Report.displayEvoDefault('""+div_id_evo+""');"";if(div_id_basic)html+=""Report.displayBasicDefault('""+div_id_basic+""')"";html+='"">';html+=""</form>"";$(""#""+div_id_sel).html(html);if(Report.getProjectsList().length>1){$(""#""+div_id_sel).append(""Not supported in multiproject"");$(""#""+div_id_sel+"" :input"").attr(""disabled"",true)}};function filterHistory(history){if(typeof history.id===""number""){$.each(history,function(key,value){value=[value]})}return history}this.displayEvoLists=function(id,lists){for(var i=0;i<lists.length;i++){var l=lists[i];file_messages=this.getDataDir()+""/mls-"";file_messages+=l;file_messages+=""-evolutionary.json"";this.displayEvoList(MLS.displayMLSListName(l),id,file_messages)}};this.displayEvoList=function(list_label,id,mls_file){var self=this;$.getJSON(mls_file,function(history){self.envisionEvoList(list_label,id,history)})};this.envisionEvoList=function(list_label,div_id,history){var config=Report.getConfig();var options=Viz.getEnvisionOptionsMin(div_id,history,config.mls_hide);options.data.list_label=MLS.displayMLSListName(list_label);new envision.templates.Envision_Report(options,[this])}}MLS.prototype=new DataSource(""mls"");function SCM(){this.basic_metrics={scm_commits:{divid:""scm_commits"",column:""commits"",name:""Commits"",desc:""Evolution of the number of commits (aggregating branches)"",envision:{y_labels:true,show_markers:true}},scm_committers:{divid:""scm_committers"",column:""committers"",name:""Committers"",desc:""Unique committers making changes to the source code"",action:""commits"",envision:{gtype:""whiskers""}},scm_authors:{divid:""scm_authors"",column:""authors"",name:""Authors"",desc:""Unique authors making changes to the source code"",action:""commits"",envision:{gtype:""whiskers""}},scm_newauthors:{divid:""scm_newauthors"",column:""newauthors"",name:""New Authors"",desc:""Number of new people authoring commits (changes to source code)"",action:""commits"",envision:{gtype:""whiskers""}},scm_branches:{divid:""scm_branches"",column:""branches"",name:""Branches"",desc:""Evolution of the number of branches""},scm_files:{divid:""scm_files"",column:""files"",name:""Modified Files"",desc:""Evolution of the number of unique files handled by the community""},scm_added_lines:{divid:""scm_added_lines"",column:""added_lines"",name:""Lines Added"",desc:""Evolution of the source code lines added""},scm_removed_lines:{divid:""scm_removed_lines"",column:""removed_lines"",name:""Lines Removed"",desc:""Evolution of the source code lines removed""},scm_repositories:{divid:""scm_repositories"",column:""repositories"",name:""Repositories"",desc:""Evolution of the number of repositories"",envision:{gtype:""whiskers""}},scm_companies:{divid:""scm_companies"",column:""companies"",name:""Companies"",desc:""Number of active companies""},scm_countries:{divid:""scm_countries"",column:""countries"",name:""Countries"",desc:""Number of active countries""},scm_domains:{divid:""scm_domains"",column:""domains"",name:""Domains"",desc:""Number of active domains""}};this.getMainMetric=function(){return""scm_commits""};this.setITS=function(its){this.its=its};this.getITS=function(its){return this.its};this.getTitle=function(){return""Source Code Management""};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End""};return id_label};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .scm-info"").hide();return}var repo_str=this.global_data.type.charAt(0).toUpperCase()+this.global_data.type.slice(1);$(div_id+"" #scm_type"").text(repo_str);var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().scm_url}if(this.global_data.type===""git"")if(url)url=url.replace(""git://"",""http://"");$(div_id+"" #scm_url"").attr(""href"",url);$(div_id+"" #scm_name"").text(repo_str);var data=this.getGlobalData();$(div_id+"" #scmFirst"").text(data.first_date);$(div_id+"" #scmLast"").text(data.last_date);$(div_id+"" #scmCommits"").text(data.scm_commits);$(div_id+"" #scmAuthors"").text(data.scm_authors);if(data.reviewers)$(div_id+"" #scmReviewers"").text(data.scm_reviewers);$(div_id+"" #scmCommitters"").text(data.scm_committers);$(div_id+"" #scmRepositories"").text(data.scm_repositories);if(data.repositories===1)$(div_id+"" #scmRepositories"").hide()};this.displayBubbles=function(divid,radius){Viz.displayBubbles(divid,""scm_commits"",""scm_committers"",radius)}}SCM.prototype=new DataSource(""scm"");function SCR(){var self=this;this.basic_metrics={scr_opened:{divid:""scr_opened"",column:""opened"",name:""Reviews opened"",desc:""Reviews in status new or inprogress""},scr_submissions:{divid:""scr_submissions"",column:""submissions"",name:""Reviews submitted"",desc:""Reviews submitted""},scr_closed:{divid:""scr_closed"",column:""closed"",name:""Reviews closed"",desc:""Reviews merged or abandoned""},scr_merged:{divid:""scr_merged"",column:""merged"",name:""Reviews merged"",desc:""Reviews merged""},scr_mergers:{divid:""scr_mergers"",column:""mergers"",name:""Reviews mergers"",action:""merged"",desc:""People merging reviews""},scr_new:{divid:""scr_new"",column:""new"",name:""Reviews new"",desc:""Reviews in status new""},scr_abandoned:{divid:""scr_abandoned"",column:""abandoned"",name:""Reviews abandoned"",desc:""Reviews abandoned""},scr_pending:{divid:""scr_pending"",column:""pending"",name:""Reviews pending"",desc:""Reviews pending to be attended""},scr_review_time_days_avg:{divid:""scr_review_time_days_avg"",column:""review_time_days_avg"",name:""Average review time"",desc:""Average review time in days""},scr_verified:{divid:""scr_verified"",column:""verified"",name:""Patches verified"",desc:""Patches verified""},scr_approved:{divid:""scr_approved"",column:""approved"",name:""Patches approved"",desc:""Patches approved""},scr_codereview:{divid:""scr_codereview"",column:""codereview"",name:""Patches codereview"",desc:""Patches in code review process""},scr_WaitingForReviewer:{divid:""scr_WaitingForReviewer"",column:""WaitingForReviewer"",name:""Patches waiting reviewer"",desc:""Patches waiting for reviewer""},scr_WaitingForSubmitter:{divid:""scr_WaitingForSubmitter"",column:""WaitingForSubmitter"",name:""Patches waiting submitter"",desc:""Patches waiting for a new version""},scr_submitted:{divid:""scr_submitted"",column:""submitted"",name:""Reviews submitted"",desc:""Reviews submitted""},scr_submitters:{divid:""scr_submitters"",column:""submitters"",name:""Reviews submitters"",desc:""Number of people submitting review processes.""},scr_sent:{divid:""scr_sent"",column:""sent"",name:""Patches Sent"",desc:""Patches sent""},scr_companies:{divid:""scr_companies"",column:""companies"",name:""Companies"",desc:""Number of active companies""},scr_countries:{divid:""scr_countries"",column:""countries"",name:""Countries"",desc:""Number of active countries""},scr_repositories:{divid:""scr_repositories"",column:""repositories"",name:""Respositories"",desc:""Number of active respositories""},scr_closers:{divid:""scr_closers"",column:""closers"",name:""Closers"",desc:""Reviews closers"",action:""closed""},scr_openers:{divid:""scr_openers"",column:""openers"",name:""Openers"",desc:""Reviews openers"",action:""opened""},scr_reviewers:{divid:""scr_reviewers"",column:""reviewers"",name:""Reviewers"",desc:""Number of people reviewing contributions""},scr_timeto_merge_avg:{divid:""scr_timeto_merge_avg"",column:""timeto_merge_avg"",name:""Time to merge (average days)"",desc:""Number of average days a contribution waits to be merged""},scr_timeto_merge_median:{divid:""scr_timeto_merge_median"",column:""timeto_merge_median"",name:""Time to merge (median of the days)"",desc:""Median of the number of days a contribution waits to be merged""},scr_timeto_close_avg:{divid:""scr_timeto_close_avg"",column:""timeto_close_avg"",name:""Time to close (average days)"",desc:""Number of average days a contribution waits to be closed""},scr_timeto_close_median:{divid:""scr_timeto_close_median"",column:""timeto_close_median"",name:""Time to close (median of the days)"",desc:""Median of the number of days a contribution waits to be closed""},scr_participants:{divid:""scr_participants"",column:""participants"",name:""Participants"",desc:""Number of participants in the review process"",action:""events""},scr_active_core_reviewers:{divid:""scr_active_core_reviewers"",column:""active_core_reviewers"",name:""Active core reviewers"",desc:""Number of active core reviewers"",action:""reviews""}};this.getMainMetric=function(){return""scr_merged""};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End"",review_time_pending_ReviewsWaitingForReviewer_days_avg:""Review Time for reviewers (days, avg)"",review_time_pending_ReviewsWaitingForReviewer_days_median:""Review Time for reviewers (days, median)"",review_time_pending_update_ReviewsWaitingForReviewer_days_avg:""Update time for reviewers (days, avg)"",review_time_pending_update_ReviewsWaitingForReviewer_days_median:""Update time for reviewers (days, avg)"",review_time_pending_days_avg:""Review time (days, avg)"",review_time_pending_days_median:""Review time (days, median)"",review_time_pending_update_days_avg:""Update time (days, avg)"",review_time_pending_update_days_median:""Update time (days, median)""};return id_label};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .scr_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().scr_url}if(this.global_data.type)$(div_id+"" #scr_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #scr_url"").attr(""href"",url);$(div_id+"" #scr_name"").text(""SCR ""+this.global_data.type)}else{$(div_id+"" #scr_url"").attr(""href"",Report.getProjectData().mls_url);$(div_id+"" #scr_name"").text(Report.getProjectData().scr_name);$(div_id+"" #scr_type"").text(Report.getProjectData().scr_type)}var company=this.getCompanyQuery();var data=this.getGlobalData();if(company){data=this.getCompaniesGlobalData()[company]}$(div_id+"" #scrFirst"").text(data.first_date);$(div_id+"" #scrLast"").text(data.last_date);$(div_id+"" #scrReviews"").text(data.scr_opened)};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""scr_opened"",""scr_openers"",radius)};SCR.displaySCRListName=function(listinfo){var list_name_tokens=listinfo.split(""_"");var list_name="""";if(list_name_tokens.length>1){list_name=list_name_tokens[list_name_tokens.length-1];if(list_name==="""")list_name=list_name_tokens[list_name_tokens.length-2]}else{list_name=listinfo.replace(""<"","""");list_name=list_name.replace("">"","""");list_name_tokens=list_name.split(""."");list_name=list_name_tokens[0]}return list_name};this.getTitle=function(){return""Source Code Review""}}SCR.prototype=new DataSource(""scr"");function People(){this.basic_metrics={people_members:{column:""members"",name:""Members"",desc:""Community Members""}};this.getMainMetric=function(){return""people_members""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .mediawiki_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().mediawiki_url}if(this.global_data.type)$(div_id+"" #mediawiki_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #mediawiki_url"").attr(""href"",url);$(div_id+"" #mediawiki_name"").text(""MediaWiki ""+this.global_data.type)}else{$(div_id+"" #mediawiki_url"").attr(""href"",Report.getProjectData().mediawiki_url);$(div_id+"" #mediawiki_name"").text(Report.getProjectData().mediawiki_name);$(div_id+"" #mediawiki_type"").text(Report.getProjectData().mediawiki_type)}var data=this.getGlobalData();$(div_id+"" #mediawikiFirst"").text(data.first_date);$(div_id+"" #mediawikiLast"").text(data.last_date);$(div_id+"" #mediawikiSent"").text(data.mediawiki_reviews)};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""mediawiki_reviews"",""mediawiki_authors"",radius)};this.getTitle=function(){return""Community Members""}}People.prototype=new DataSource(""people"");function Downloads(){var self=this;this.basic_metrics={downloads_downloads:{name:""Total downloads"",column:""downloads""},downloads_packages:{divid:"""",column:""packages"",name:""Packages downloaded"",desc:"""",action:""downloads""},downloads_ips:{divid:"""",column:""ips"",name:""IP addresses"",desc:"""",action:""downloads""}};this.getMainMetric=function(){return""downloads_downloads""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .irc_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().irc_url}if(this.global_data.type)$(div_id+"" #irc_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #irc_url"").attr(""href"",url);$(div_id+"" #irc_name"").text(""IRC ""+this.global_data.type)}else{$(div_id+"" #irc_url"").attr(""href"",Report.getProjectData().irc_url);$(div_id+"" #irc_name"").text(Report.getProjectData().irc_name);$(div_id+"" #irc_type"").text(Report.getProjectData().irc_type)}var data=this.getGlobalData();$(div_id+"" #ircFirst"").text(data.first_date);$(div_id+"" #ircLast"").text(data.last_date);$(div_id+"" #ircSent"").text(data.irc_sent);$(div_id+"" #ircRepositories"").text(data.irc_repositories);if(data.repositories===1)$(div_id+"" #ircRepositories"").hide()};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""mediawiki_reviews"",""mediawiki_authors"",radius)};this.getTitle=function(){return""Downloads""}}Downloads.prototype=new DataSource(""downloads"");function QAForums(){var self=this;this.basic_metrics={qaforums_sent:{name:""Messages posted"",desc:""Number of messages posted to Q&A forums(s)"",column:""sent""},qaforums_qsent:{name:""Questions posted"",desc:""Number of questions posted to Q&A forums(s)"",column:""qsent""},qaforums_asent:{name:""Answers posted"",desc:""Number of answers posted to Q&A forums(s)"",column:""asent""},qaforums_unanswered:{name:""Unanswered questions"",desc:""Backlog of unanswered questions"",column:""unanswered""},qaforums_senders:{name:""Persons posting messages"",desc:""Number of persons posting messages to Q&A forums(s)"",column:""senders""},qaforums_asenders:{name:""Persons posting answers"",desc:""Number of persons answering in Q&A forums(s)"",column:""asenders""},qaforums_qsenders:{divid:""qaforums_qsenders"",name:""Persons posting questions"",desc:""Number of persons asking questions in Q&A forums(s)"",column:""qsenders""},qaforums_participants:{name:""Participants"",desc:""Number of persons posting messages"",column:""participants""}};this.getMainMetric=function(){return""qaforums_qsent""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .irc_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().irc_url}if(this.global_data.type)$(div_id+"" #irc_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #irc_url"").attr(""href"",url);$(div_id+"" #irc_name"").text(""IRC ""+this.global_data.type)}else{$(div_id+"" #irc_url"").attr(""href"",Report.getProjectData().irc_url);$(div_id+"" #irc_name"").text(Report.getProjectData().irc_name);$(div_id+"" #irc_type"").text(Report.getProjectData().irc_type)}var data=this.getGlobalData();$(div_id+"" #ircFirst"").text(data.first_date);$(div_id+"" #ircLast"").text(data.last_date);$(div_id+"" #ircSent"").text(data.irc_sent);$(div_id+"" #ircRepositories"").text(data.irc_repositories);if(data.repositories===1)$(div_id+"" #ircRepositories"").hide()};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""qaforums_quetions"",""qaforums_authors"",radius)};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End"",sent:""Messages posted"",qsent:""Questions posted"",asent:""Answers posted"",qunanswered:""Unanswered questions"",senders:""Persons posting messages"",asenders:""Persons posting answers"",qsenders:""Persons posting questions""};return id_label};this.getTitle=function(){return""QAForums""}}QAForums.prototype=new DataSource(""qaforums"");function Releases(){var self=this;this.basic_metrics={releases_modules:{name:""Modules created"",desc:""Number of modules created on the forge"",column:""modules""},releases_authors:{name:""Module authors"",desc:""Module authors"",column:""authors""},releases_releases:{name:""Number of module releases"",desc:""Number of module releases"",column:""releases""}};this.getMainMetric=function(){return""releases_modules""};this.displayData=function(divid){var div_id=""#""+divid;var str=this.global_data.url;if(!str||str.length===0){$(div_id+"" .irc_info"").hide();return}var url="""";if(this.global_data.repositories===1){url=this.global_data.url}else{url=Report.getProjectData().irc_url}if(this.global_data.type)$(div_id+"" #irc_type"").text(this.global_data.type);if(this.global_data.url&&this.global_data.url!=="".""&&this.global_data.type!==undefined){$(div_id+"" #irc_url"").attr(""href"",url);$(div_id+"" #irc_name"").text(""IRC ""+this.global_data.type)}else{$(div_id+"" #irc_url"").attr(""href"",Report.getProjectData().irc_url);$(div_id+"" #irc_name"").text(Report.getProjectData().irc_name);$(div_id+"" #irc_type"").text(Report.getProjectData().irc_type)}var data=this.getGlobalData();$(div_id+"" #ircFirst"").text(data.first_date);$(div_id+"" #ircLast"").text(data.last_date);$(div_id+"" #ircSent"").text(data.irc_sent);$(div_id+"" #ircRepositories"").text(data.irc_repositories);if(data.repositories===1)$(div_id+"" #ircRepositories"").hide()};this.displayBubbles=function(divid,radius){if(false)Viz.displayBubbles(divid,""releases_modules"",""releases_releases"",radius)};this.getSummaryLabels=function(){var id_label={first_date:""Start"",last_date:""End"",modules:""Modules created"",releases:""Module releases created"",authors:""Persons creating/updating modules""};return id_label};this.getTitle=function(){return""Releases""}}Releases.prototype=new DataSource(""releases"");var Identity={};(function(){var unique_list=""unique-sortable"";function sortSelList(list_divid,list,name){var connect="""";if(list_divid===unique_list)connect="""";else connect=unique_list;$(""#""+name).sortable({handle:"".handle"",connectWith:""#""+connect,start:function(e,info){info.item.siblings("".ui-selected"").appendTo(info.item)},stop:function(e,info){if(info.item.parent()[0].id===unique_list)info.item.find("".handle"").remove();info.item.parent().append(info.item.find(""li""));info.item.parent().find(""li"").addClass(""mjs-nestedSortable-leaf"")}}).selectable().find(""li"").prepend(""<div class='handle'></div>"")}Identity.showListNested=function(list_divid,ds){list=""<ol id=""+unique_list+' class=""nested_sortable"" ';list+='style=""padding: 5px; background: #eee;""></ol>';$(""#""+list_divid).append(list);$(""#""+unique_list).nestedSortable({forcePlaceholderSize:true,handle:""div"",helper:""clone"",items:""li"",tolerance:""pointer"",toleranceElement:""> div"",maxLevels:2,isTree:true,expandOnHover:700,startCollapsed:true});$("".disclose"").on(""click"",function(){$(this).closest(""li"").toggleClass(""mjs-nestedSortable-collapsed"").toggleClass(""mjs-nestedSortable-expanded"")})};function showFilter(ds,filter_data){$(""#""+ds.getName()+""filter"").autocomplete({source:filter_data,select:function(event,ui){$(""#""+ds.getName()+""filter"").val("""");$(""#""+ds.getName()+""_people_""+ui.item.value).addClass(""ui-selected"");return false}})}Identity.showList=function(list_divid,ds){var list="""";var people=ds.getPeopleData();var filter_data=[];list='<ol id=""'+ds.getName()+'-sortable"" class=""sortable"">';for(var i=0;i<people.id.length;i++){var value=people.id[i];if(typeof value===""string""){value=value.replace(""@"",""_at_"").replace(""."",""_"")}filter_data.push({value:value,label:people.name[i]});list+='<li id=""'+ds.getName()+""_people_""+value+'"" ';list+='class=""ui-widget-content ui-selectee"">';list+='<div><span class=""disclose""><span></span></span>';list+=people.id[i]+"" ""+people.name[i];list+=""</div></li>""}list+=""</ol>"";$(""#""+list_divid).append(""<input id='""+ds.getName()+""filter'>"");showFilter(ds,filter_data);$(""#""+list_divid).append(list);sortSelList(list_divid,list,ds.getName()+""-sortable"")}})();var Charts={};(function(){Charts.plotLinesChart=plotLinesChart;function plotLinesChart(div_id,line_names,raw_data){var flt_data=buildFlotrData(line_names,raw_data);var config=getChartConfig(flt_data,raw_data.strdate);if(raw_data.max){config.yaxis.max=raw_data.max}if(flt_data.length>1)config.legend.show=true;config.subtitle=composeTitle(line_names);flt_data=decorateLines(flt_data);plotFlotr2LinesChart(div_id,flt_data,config)}function buildFlotrData(line_names,raw_data){var aux=[];$.each(raw_data.lines_data,function(id,array){var line=[];$.each(array,function(subid,value){line[line.length]=[raw_data.unixtime[subid],value]});var aux2={};aux2.data=line;aux2.label=line_names[id];aux[aux.length]=aux2});return aux}function decorateLines(flotr2_data){if(Utils.isReleasePage()===false){if(flotr2_data.length===1){flotr2_data=lastLineValueToPoint(flotr2_data);flotr2_data=addEmptyValue(flotr2_data)}else if(flotr2_data.length>1){flotr2_data=dropLastLineValue(flotr2_data)}}return flotr2_data}function lastLineValueToPoint(flotr2_data){if(flotr2_data.length!==1)return flotr2_data;var last=flotr2_data[0].data.length;var dots=[];var utime=0;for(var i=0;i<last-1;i++){utime=parseInt(flotr2_data[0].data[i][0],10);dots.push([utime,undefined])}utime=parseInt(flotr2_data[0].data[last-1][0],10);dots.push([utime,flotr2_data[0].data[last-1][1]]);var dot_graph={data:dots};dot_graph.points={show:true,radius:3,lineWidth:1,fillColor:null,shadowSize:0};flotr2_data.push(dot_graph);flotr2_data[0].data[last-1][1]=undefined;flotr2_data[1].label=flotr2_data[0].label;return flotr2_data}function composeTitle(unit_names){return unit_names.join("" & "")}function addEmptyValue(flotr2_data){var second=parseInt(flotr2_data[0].data[1][0],10);var first=parseInt(flotr2_data[0].data[0][0],10);var step=second-first;var narrays=flotr2_data.length;var last_date=0;for(var i=0;i<narrays;i++){var last=flotr2_data[i].data.length-1;last_date=parseInt(flotr2_data[i].data[last][0],10);flotr2_data[i].data.push([last_date+step,undefined])}return flotr2_data}function dropLastLineValue(flotr2_data){if(flotr2_data.length===0)return flotr2_data;if(flotr2_data.length>1){for(var j=0;j<flotr2_data.length;j++){var last=flotr2_data[j].data.length-1;flotr2_data[j].data[last][1]=undefined}}return flotr2_data}function plotFlotr2LinesChart(div_id,flotr2_data,config){if(flotr2_data.length===0)return;var container=document.getElementById(div_id);function drawGraph(opts){var o=Flotr._.extend(Flotr._.clone(config),opts||{});return Flotr.draw(container,flotr2_data,o)}graph=drawGraph();Flotr.EventAdapter.observe(container,""flotr:select"",function(area){var zoom_options={xaxis:{minorTickFreq:4,mode:""time"",timeUnit:""second"",timeFormat:""%b %y"",min:area.x1,max:area.x2},yaxis:{min:area.y1,autoscale:true},grid:{verticalLines:true,color:""#000000"",outlineWidth:1,outline:""s""}};zoom_options.subtitle=composeRangeText(config.subtitle,area.xfirst,area.xsecond);var new_lines_data_object=JSON.parse(JSON.stringify(flotr2_data));var y_max_value=getMax(new_lines_data_object,area.x1,area.x2);zoom_options.yaxis.max=y_max_value+y_max_value*.2;graph=drawGraph(zoom_options)});Flotr.EventAdapter.observe(container,""flotr:click"",function(){drawGraph()});$(window).resize(function(){drawGraph()})}function getChartConfig(flotr2_data,strdates,title){var legend_div=null;var config={subtitle:title,legend:{show:false,container:legend_div},xaxis:{minorTickFreq:4,mode:""time"",timeUnit:""second"",timeFormat:""%b %y"",margin:true},yaxis:{min:null,noTicks:2,autoscale:true},grid:{verticalLines:false,color:""#000000"",outlineWidth:1,outline:""s""},mouse:{container:legend_div,track:true,trackY:false,relative:true,margin:20,position:""n"",trackFormatter:function(o){var label=strdates[parseInt(o.index,10)];if(label===undefined)label="""";else label+=""<br>"";for(var i=0;i<flotr2_data.length;i++){var value=flotr2_data[i].data[o.index][1];if(value===undefined)continue;if(flotr2_data.length>1){if(flotr2_data[i].label!==undefined){value_name=flotr2_data[i].label;label+=value_name+"":""}}label+=""<strong>""+Report.formatValue(value)+""</strong><br>""}return label}},selection:{mode:""x"",fps:10},shadowSize:4};return config}function composeRangeText(former_title,starting_utime,end_utime){var months=[""Jan"",""Feb"",""Mar"",""Apr"",""May"",""Jun"",""Jul"",""Aug"",""Sep"",""Oct"",""Nov"",""Dec""];var date=new Date(parseInt(starting_utime,10)*1e3);var starting_date=months[date.getMonth()]+"" ""+date.getFullYear();date=new Date(parseInt(end_utime,10)*1e3);var end_date=months[date.getMonth()]+"" ""+date.getFullYear();return former_title+"" ( ""+starting_date+"" - ""+end_date+"" )""}function getMax(flotr2_data,from_unixstamp,to_unixstamp){from_unixstamp=Math.round(from_unixstamp);to_unixstamp=Math.round(to_unixstamp);var narrays=flotr2_data.length;var aux_array=[];for(var i=0;i<narrays;i++){for(var z=flotr2_data[i].length-1;z>0;z--){var aux_value=flotr2_data[i][z][0];var cond=aux_value<from_unixstamp||aux_value>to_unixstamp;if(cond){flotr2_data[i].splice(z,1)}}}var res=[];for(i=0;i<narrays;i++){aux_array=flotr2_data[i].data;aux_array=sortBiArray(aux_array);res.push(aux_array[aux_array.length-1][1])}res.sort(function(a,b){return a-b});return res[res.length-1]}function sortBiArray(bi_array){bi_array.sort(function(a,b){return a[1]>b[1]||b[1]===undefined?1:-1});return bi_array}})();String.prototype.supplant=function(o){return this.replace(/{([^{}]*)}/g,function(a,b){var r=o[b];return typeof r===""string""||typeof r===""number""?r:a})};var Table={};(function(){Table.displayTopTable=displayTopTable;Table.simpleTable=displaySimpleTable;function displaySimpleTable(div,data,headers,cols){var tables,aux_html;tables='<table class=""table table-striped"">';aux_html=""<thead><th>#</th>"";$.each(headers,function(id,value){aux_html+=""<th>""+value+""</th>""});aux_html+=""</thead><tbody>"";aux_html+=""<tbody>"";var first_col,aux_col;if(typeof data[cols[0]]!==""object""){aux_col=[];aux_col[0]=data[cols[0]];first_col=aux_col}else{first_col=data[cols[0]]}$.each(first_col,function(id,value){aux_html+=""<tr>"";var cont=id+1;aux_html+=""<td>""+cont+""</td>"";$.each(cols,function(subid,name){if(typeof data[name]!==""object""){aux_html+=""<td>""+data[name]+""</td>""}else{aux_html+=""<td>""+data[name][id]+""</td>""}});aux_html+=""</tr>""});aux_html+=""</tbody>"";tables+=aux_html;tables+=""</table>"";$(""#""+div.id).append(tables)}function displayTopTable(div,data,opts){var first=true,gen_tabs=true,tabs="""",tables="""";if(opts.period!==""all""){gen_tabs=false }else{tabs+=composeTopTabs(data,opts.metric,opts.class_name)}periods=getSortedPeriods();tables+='<div class=""tab-content"">';var var_names=getTopVarsFromMetric(opts.metric,opts.ds_name);for(var k=0;k<periods.length;k++){html="""";var key=opts.metric+"".""+periods[k];if(data[key]){var data_period=periods[k];if(data_period===""""){data_period=""all""}if(first===true){html="" active in"";first=false}var data_period_nows=data_period.replace(/\ /g,"""");tables+='<div class=""tab-pane fade'+html+'"" id=""'+opts.class_name+opts.metric+data_period_nows+'"">';tables+='<table class=""table table-striped"">';unit=opts.desc_metrics[opts.ds_name+""_""+opts.metric].action;tables+=""<thead><th>#</th><th>""+opts.metric.capitalize()+""</th>"";if(unit!==undefined)tables+=""<th>""+unit.capitalize()+""</th>"";tables+=""</thead><tbody>"";tables+=composeTopRowsPeople(data[key],opts.limit,opts.links_enabled,var_names);tables+=""</tbody>"";tables+=""</table>"";tables+=""</div>""}}tables+=""</div>"";$(""#""+div.id).append(tabs+tables)}function composeTopRowsPeople(people_data,limit,people_links,var_names){var rows_html="""";for(var j=0;j<people_data[var_names.id].length;j++){if(limit&&limit<=j)break;var metric_value=people_data[var_names.action][j];rows_html+=""<tr><td>""+(j+1)+""</td>"";rows_html+=""<td>"";if(people_links){rows_html+='<a href=""people.html?id='+people_data[var_names.id][j];get_params=Utils.paramsInURL();if(get_params.length>0)rows_html+=""&""+get_params;rows_html+='"">';rows_html+=DataProcess.hideEmail(people_data[var_names.name][j])+""</a>""}else{rows_html+=DataProcess.hideEmail(people_data[var_names.name][j])}rows_html+=""</td>"";rows_html+=""<td>""+metric_value+""</td></tr>""}return rows_html}function getSortedPeriods(){return[""last month"",""last year"",""""]}function composeTopTabs(data,metric,class_name){var first=true,tabs_html='<ul id=""myTab"" class=""nav nav-tabs"">',periods=getSortedPeriods();$.each(periods,function(id,p){aux_obj={html:""""};if(p===""""){p=""all"";aux_obj.pretty_period=""Complete history""}else if(p===""last month""){aux_obj.pretty_period=""Last 30 days""}else if(p===""last year""){aux_obj.pretty_period=""Last 365 days""}aux_obj.myhref=class_name+metric+p.replace(/\ /g,"""");if(first===true){aux_obj.html=' class=""active""';first=false}var aux_html='<li{html}><a href=""#{myhref}"" data-toogle=""tab"">{pretty_period}</a></li>';tabs_html+=aux_html.supplant(aux_obj)});tabs_html+=""</ul>"";return tabs_html}function getTopVarsFromMetric(metric,ds_name){var var_names={};var_names.id=""id"";if(metric===""senders""&&(ds_name===""mls""||ds_name===""irc"")){var_names.name=""senders"";var_names.action=""sent""}if(metric===""authors""&&ds_name===""scm""){var_names.name=""authors"";var_names.action=""commits""}if(metric===""closers""&&ds_name===""its""){var_names.name=""closers"";var_names.action=""closed""}if(ds_name===""scr""){if(metric===""mergers""){var_names.name=""mergers"";var_names.action=""merged""}if(metric===""openers""){var_names.name=""openers"";var_names.action=""opened""}if(metric===""reviewers""){var_names.name=""reviewers"";var_names.action=""reviews""}}if(ds_name===""downloads""){if(metric===""ips""){var_names.name=""ips"";var_names.action=""downloads""}if(metric===""packages""){var_names.name=""packages"";var_names.action=""downloads""}}if(ds_name===""mediawiki""){if(metric===""authors""){var_names.name=""authors"";var_names.action=""reviews""}}if(ds_name===""qaforums""){if(metric===""senders""||metric===""asenders""||metric===""qsenders""){var_names.name=""senders"";var_names.action=""sent""}else if(metric===""participants""){var_names.name=""name"";var_names.action=""messages_sent""}}if(ds_name===""releases""){if(metric===""authors""){var_names.name=""username"";var_names.action=""releases""}}return var_names}})();var Demographics={};(function(){var data_dg={};Demographics.widget=function(){var divs=$("".DemographicsCompany""),ds_name,company_name,DS,period;if(divs.length>0){$.each(divs,function(id,div){ds_name="""";ds_name=$(this).data(""data-source"");DS=Report.getDataSourceByName(ds_name);if(DS===null)return;if(DS.getData().length===0)return;period=$(this).data(""period"");company_name=Utils.getParameter(""company"");loadDemographicsData(div,ds_name,company_name,period,displayDemographics)})}};function loadDemographicsData(div,ds_name,company_name,period,cb){var suffix=ds_name.toLowerCase(),preffix,ag_file,b_file;preffix=""data/json/""+company_name+""-""+suffix+""-com-demographics-"";ag_file=preffix+""aging.json"";b_file=preffix+""birth.json"";$.when($.getJSON(ag_file),$.getJSON(b_file)).done(function(ag_data,b_data){data_dg[company_name]={};data_dg[company_name][ds_name]={aging:undefined,birth:undefined};data_dg[company_name][ds_name].aging=ag_data[0];data_dg[company_name][ds_name].birth=b_data[0];cb(div,ds_name,company_name,period)}).fail(function(){console.log(""Demographics Company widget disabled. Missing ""+ds_name+"" files for company ""+company_name)})}function displayDemographics(div,ds_name,company_name,period){if(!div.id)div.id=""Parsed""+getRandomId();if(data_dg[company_name]!==undefined&&data_dg[company_name][ds_name]!==undefined){Viz.displayDemographicsChart(div.id,data_dg[company_name][ds_name],period)}}function getRandomId(){return Math.floor(Math.random()*1e3+1)}})();Loader.data_ready(function(){Demographics.widget()});vizjslib_git_revision=""b9507b20f12b48b57539eafb44179d6d3242a2da"";vizjslib_git_tag=""15.02-53-gb9507b2"";",87,23
openstack%2Fdjango_openstack_auth~master~I79e88e8729e79583973c1c3d47c40f5f0946c7f6,openstack/django_openstack_auth,master,I79e88e8729e79583973c1c3d47c40f5f0946c7f6,Imported Translations from Transifex,MERGED,2015-05-20 06:05:02.000000000,2015-05-20 14:22:32.000000000,2015-05-20 14:22:30.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6914}, {'_account_id': 9576}]","[{'number': 1, 'created': '2015-05-20 06:05:02.000000000', 'files': ['openstack_auth/locale/de/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/9f1b2df487095ce671e50c3e49778043033fdf85', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I79e88e8729e79583973c1c3d47c40f5f0946c7f6\n'}]",0,184414,9f1b2df487095ce671e50c3e49778043033fdf85,11,4,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I79e88e8729e79583973c1c3d47c40f5f0946c7f6
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/14/184414/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/locale/de/LC_MESSAGES/django.po'],1,9f1b2df487095ce671e50c3e49778043033fdf85,transifex/translations,"""POT-Creation-Date: 2015-05-20 06:05+0000\n"" ""PO-Revision-Date: 2015-05-19 10:04+0000\n"" ""Last-Translator: Robert Simai\n""msgid ""Unable to establish connection to keystone endpoint."" msgstr ""Es kann keine Verbindung zum Keystone Endpunkt aufgebaut werden."" ","""POT-Creation-Date: 2015-05-13 06:05+0000\n"" ""PO-Revision-Date: 2015-05-12 09:27+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""",6,3
openstack%2Ffuel-ostf~master~I83afc93d2f97be81470d811aba3275fffd7e8bb7,openstack/fuel-ostf,master,I83afc93d2f97be81470d811aba3275fffd7e8bb7,Skip neutron_objects_creation if no computes,MERGED,2015-05-20 09:56:28.000000000,2015-05-20 14:20:28.000000000,2015-05-20 14:18:13.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2015-05-20 09:56:28.000000000', 'files': ['fuel_health/tests/smoke/test_neutron_actions.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/0753595c1caea754a072cda54ce31f9b20c1a0b2', 'message': 'Skip neutron_objects_creation if no computes\n\nSkip tests test_check_neutron_objects_creation\nif there is not computes nodes\n\nChange-Id: I83afc93d2f97be81470d811aba3275fffd7e8bb7\nCloses-Bug: #1456630\n'}]",0,184451,0753595c1caea754a072cda54ce31f9b20c1a0b2,12,6,1,6719,,,0,"Skip neutron_objects_creation if no computes

Skip tests test_check_neutron_objects_creation
if there is not computes nodes

Change-Id: I83afc93d2f97be81470d811aba3275fffd7e8bb7
Closes-Bug: #1456630
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/51/184451/1 && git format-patch -1 --stdout FETCH_HEAD,['fuel_health/tests/smoke/test_neutron_actions.py'],1,0753595c1caea754a072cda54ce31f9b20c1a0b2,1456630, if not self.config.compute.compute_nodes: self.skipTest('There are no compute nodes'),,2,0
openstack%2Fcinder~master~I503edfb4f52b94e172d5671d727c75aa0ca6f6e1,openstack/cinder,master,I503edfb4f52b94e172d5671d727c75aa0ca6f6e1,WIP: Virtual Fabric Suport for Brocade FC switches.,ABANDONED,2015-01-24 02:31:58.000000000,2015-05-20 13:51:03.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 6491}, {'_account_id': 7664}, {'_account_id': 8757}, {'_account_id': 9008}, {'_account_id': 10549}, {'_account_id': 11660}, {'_account_id': 11811}, {'_account_id': 11903}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 12611}, {'_account_id': 12780}, {'_account_id': 14242}]","[{'number': 1, 'created': '2015-01-24 02:31:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3a36567f076f206272e06564b30699a0afe24406', 'message': 'WIP: Implementation of Virtual Fabric Suport for Brocade FC SAN\nswitches.\n\nBlueprint https://blueprints.launchpad.net/cinder/+spec/brocade-zone-driver-virtualfabrics-support\n\nChange-Id: I503edfb4f52b94e172d5671d727c75aa0ca6f6e1\n'}, {'number': 2, 'created': '2015-01-27 00:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/88ca1812ee0a604f08885b1e8b41fb9a7210433f', 'message': 'WIP: Virtual Fabric Suport for Brocade FC\nswitches.\n\nblueprint brocade-zone-driver-virtualfabrics-support\n\nChange-Id: I503edfb4f52b94e172d5671d727c75aa0ca6f6e1\n'}, {'number': 3, 'created': '2015-01-29 23:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fc8a591bb966e0194f42b8e8503b6369a9f5e6af', 'message': 'WIP: Virtual Fabric Suport for Brocade FC\nswitches.\n\nblueprint brocade-zone-driver-virtualfabrics-support\n\nChange-Id: I503edfb4f52b94e172d5671d727c75aa0ca6f6e1\n'}, {'number': 4, 'created': '2015-01-30 00:07:32.000000000', 'files': ['cinder/zonemanager/drivers/brocade/brcd_https_fc_zone_client.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_san_lookup_service.py', 'etc/cinder/cinder.conf.sample', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/tests/zonemanager/test_brcd_https_fc_zone_client.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_connector_factory.py', 'cinder/zonemanager/drivers/brocade/brcd_fabric_opts.py', 'cinder/zonemanager/drivers/brocade/fc_zone_constants.py', 'cinder/tests/zonemanager/test_brcd_fc_san_lookup_service.py', 'cinder/exception.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_client_cli.py', 'cinder/tests/zonemanager/test_brcd_lookup_service.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7d7c1737dd174ec7fd4c2eb8af8839d9ed746948', 'message': 'WIP: Virtual Fabric Suport for Brocade FC\nswitches.\n\nblueprint brocade-zone-driver-virtualfabrics-support\n\nChange-Id: I503edfb4f52b94e172d5671d727c75aa0ca6f6e1\n'}]",55,149804,7d7c1737dd174ec7fd4c2eb8af8839d9ed746948,41,22,4,11660,,,0,"WIP: Virtual Fabric Suport for Brocade FC
switches.

blueprint brocade-zone-driver-virtualfabrics-support

Change-Id: I503edfb4f52b94e172d5671d727c75aa0ca6f6e1
",git fetch https://review.opendev.org/openstack/cinder refs/changes/04/149804/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/zonemanager/drivers/brocade/brcd_fc_zone_connector_factory.py', 'cinder/zonemanager/drivers/brocade/brcd_https_fc_zone_client.py', 'cinder/zonemanager/drivers/brocade/brcd_fabric_opts.py', 'cinder/zonemanager/drivers/brocade/fc_zone_constants.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py']",8,3a36567f076f206272e06564b30699a0afe24406,bp/brocade-zone-driver-virtualfabrics-support,"from cinder.i18n import _LE switch_key = 'none' def __init__(self, ipaddress, username, password, port, key, vfid, protocol): self.switch_key = key # In case of parsing error here, it should be malformed CLI output. msg = _LE(""Malformed zone configuration: (switch=%(switch)s "" ""zone_config=%(zone_config)s)."" ) % {'switch': self.switch_ip, 'zone_config': switch_data} def add_zones(self, zones, activate): active_zone_set = self.get_active_zone_set() LOG.debug(""Active zone set:%s"", active_zone_set) LOG.debug(""Update call"") self.delete_zones(zone, activate) self._cfg_save() msg = _LE(""Creating and activating zone set failed: "" ""(Zone set=%(cfg_name)s error=%(err)s)."" ) % {'cfg_name': cfg_name, 'err': e} def delete_zones(self, zone_names, activate): active_zone_set = self.get_active_zone_set() # Active zoneset is being deleted, hence reset is_active self._cfg_save() except Exception as e: msg = _LE(""Deleting zones failed: "" ""(command=%(cmd)s error=%(err)s)."" ) % {'cmd': cmd, 'err': e} cli_output = self._get_switch_info([ZoneConstant.NS_SHOW]) try: cli_output = self._get_switch_info([ZoneConstant.NS_CAM_SHOW]) except exception.BrocadeZoningCliException: with excutils.save_and_reraise_exception(): LOG.error(_LE(""Failed collecting nscamshow "" ""info for fabric %s""), self.switch_ip) if (cli_output): return_list.extend(self._parse_ns_output(cli_output)) msg = _LE(""Error while checking transaction status: %s"") % stderr msg = _LE(""Error while running zoning CLI: (command=%(cmd)s "" ""error=%(err)s)."") % {'cmd': cmd_list, 'err': stdout} msg = _LE(""Error while getting data via ssh: (command=%(cmd)s "" ""error=%(err)s)."") % {'cmd': cmd, 'err': e} msg = (_LE(""Error while getting data via ssh: (command=%(cmd)s "" ""error=%(err)s)."") % {'cmd': cmd_list, 'err': e.getDescription()}) msg = _LE(""Malformed nameserver string: %s"") % line self.switch_key, self.switch_key, self.switch_key, LOG.debug(""_execute_cmd: stdout to return:%s"" % stdout)","from cinder.i18n import _, _LE def __init__(self, ipaddress, username, password, port): # Incase of parsing error here, it should be malformed cli output. msg = _(""Malformed zone configuration: (switch=%(switch)s "" ""zone_config=%(zone_config)s)."" ) % {'switch': self.switch_ip, 'zone_config': switch_data} def add_zones(self, zones, activate, active_zone_set=None): active_zone_set - active zone set dict retrieved from get_active_zone_set method if not active_zone_set: active_zone_set = self.get_active_zone_set() LOG.debug(""Active zone set:%s"", active_zone_set) self.delete_zones(zone, activate, active_zone_set) else: self._cfg_save() msg = _(""Creating and activating zone set failed: "" ""(Zone set=%(cfg_name)s error=%(err)s)."" ) % {'cfg_name': cfg_name, 'err': e} def delete_zones(self, zone_names, activate, active_zone_set=None): params active_zone_set: the active zone set dict retrieved from get_active_zone_set method active_zoneset_name = None zone_list = [] if not active_zone_set: active_zone_set = self.get_active_zone_set() # Active zoneset is being deleted, hence reset activate flag else: self._cfg_save() except Exception as e: msg = _(""Deleting zones failed: (command=%(cmd)s error=%(err)s)."" ) % {'cmd': cmd, 'err': e} cmd = '%(nsshow)s;%(nscamshow)s' % { 'nsshow': ZoneConstant.NS_SHOW, 'nscamshow': ZoneConstant.NS_CAM_SHOW} cli_output = self._get_switch_info([cmd]) msg = _(""Error while checking transaction status: %s"") % stderr msg = _(""Error while running zoning CLI: (command=%(cmd)s "" ""error=%(err)s)."") % {'cmd': cmd_list, 'err': stdout} msg = _(""Error while getting data via ssh: (command=%(cmd)s "" ""error=%(err)s)."") % {'cmd': cmd, 'err': e} msg = _(""Error while getting data via ssh: (command=%(cmd)s "" ""error=%(err)s)."") % {'cmd': cmd_list, 'err': e} msg = _(""Malformed nameserver string: %s"") % line",1145,149
openstack%2Fmurano~master~Id393344ec1f2c2022e7df8b64a4bbd266c151622,openstack/murano,master,Id393344ec1f2c2022e7df8b64a4bbd266c151622,[DO NOT MERGE] CI Test ,ABANDONED,2015-05-19 09:41:07.000000000,2015-05-20 13:47:43.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 13752}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-05-19 09:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/41cb3bf6b47aae79112dd542e802b867a309ba0f', 'message': '[DO NOT MERGE] CI Test\n\nChange-Id: Id393344ec1f2c2022e7df8b64a4bbd266c151622\n'}, {'number': 2, 'created': '2015-05-19 11:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0ef0d3439349d1ba045dca44a548e403c39ece99', 'message': '[DO NOT MERGE] CI Test\n\nChange-Id: Id393344ec1f2c2022e7df8b64a4bbd266c151622\n'}, {'number': 3, 'created': '2015-05-19 11:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/580517b6aaf15e060f6575e64e287229a9584486', 'message': '[DO NOT MERGE] CI Test\n\nChange-Id: Id393344ec1f2c2022e7df8b64a4bbd266c151622\n'}, {'number': 4, 'created': '2015-05-19 14:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/b0e61325cb07444cf4d7253c1597148bdcd004d5', 'message': '[DO NOT MERGE] CI Test\n\nChange-Id: Id393344ec1f2c2022e7df8b64a4bbd266c151622\n'}, {'number': 5, 'created': '2015-05-20 07:59:13.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/murano/commit/a0faaff6e4f52263ba17d5ceec6935cb24a7f306', 'message': '[DO NOT MERGE] CI Test \n\nChange-Id: Id393344ec1f2c2022e7df8b64a4bbd266c151622\n'}]",3,184214,a0faaff6e4f52263ba17d5ceec6935cb24a7f306,58,4,5,13752,,,0,"[DO NOT MERGE] CI Test 

Change-Id: Id393344ec1f2c2022e7df8b64a4bbd266c151622
",git fetch https://review.opendev.org/openstack/murano refs/changes/14/184214/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,41cb3bf6b47aae79112dd542e802b867a309ba0f,,,,0,0
openstack%2Fhorizon~master~I42fa4bfe5d2b9a90833bae25bd9ac44c614fd9ce,openstack/horizon,master,I42fa4bfe5d2b9a90833bae25bd9ac44c614fd9ce,Add a conditional judgement to avoid invalid dict index,MERGED,2015-05-18 12:01:28.000000000,2015-05-20 13:36:27.000000000,2015-05-20 13:36:26.000000000,"[{'_account_id': 3}, {'_account_id': 6914}, {'_account_id': 9622}, {'_account_id': 12071}, {'_account_id': 14151}]","[{'number': 1, 'created': '2015-05-18 12:01:28.000000000', 'files': ['openstack_dashboard/dashboards/project/data_processing/jobs/workflows/launch.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7fe5c80143aad1953d7de4df26b09dc4940f39af', 'message': ""Add a conditional judgement to avoid invalid dict index\n\nBefore index the job_configs by key 'args', we add a judgement\nto see whether key 'args' exists.\n\nCloses-Bug: #1456171\nChange-Id: I42fa4bfe5d2b9a90833bae25bd9ac44c614fd9ce\n""}]",0,184033,7fe5c80143aad1953d7de4df26b09dc4940f39af,9,5,1,13662,,,0,"Add a conditional judgement to avoid invalid dict index

Before index the job_configs by key 'args', we add a judgement
to see whether key 'args' exists.

Closes-Bug: #1456171
Change-Id: I42fa4bfe5d2b9a90833bae25bd9ac44c614fd9ce
",git fetch https://review.opendev.org/openstack/horizon refs/changes/33/184033/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/data_processing/jobs/workflows/launch.py'],1,7fe5c80143aad1953d7de4df26b09dc4940f39af,Bug1456171, if 'args' in job_configs: self.fields['job_args_array'].initial = ( json.dumps(job_configs['args'])), job_args = json.dumps(job_configs['args']) self.fields['job_args_array'].initial = job_args,4,2
openstack%2Ftempest~master~I09c538ed1139380f8cd8a662e60d69d3f605cd67,openstack/tempest,master,I09c538ed1139380f8cd8a662e60d69d3f605cd67,isolated creadentials are not cleaned up,MERGED,2015-05-20 08:22:38.000000000,2015-05-20 13:36:17.000000000,2015-05-20 13:36:16.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5689}]","[{'number': 1, 'created': '2015-05-20 08:22:38.000000000', 'files': ['tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5b0d92691983631200ff3f1fc9386b7bb076e3f8', 'message': 'isolated creadentials are not cleaned up\n\nDue to type introduced last weak, the isolated credentials are\nnot claned up.\nIn a neutron envoriements it can mean more than 1 Gigabyte memory used\nin dnsmasq and in the neutron-ns-metadata-proxy.\n\nChange-Id: I09c538ed1139380f8cd8a662e60d69d3f605cd67\n'}]",0,184434,5b0d92691983631200ff3f1fc9386b7bb076e3f8,7,3,1,5803,,,0,"isolated creadentials are not cleaned up

Due to type introduced last weak, the isolated credentials are
not claned up.
In a neutron envoriements it can mean more than 1 Gigabyte memory used
in dnsmasq and in the neutron-ns-metadata-proxy.

Change-Id: I09c538ed1139380f8cd8a662e60d69d3f605cd67
",git fetch https://review.opendev.org/openstack/tempest refs/changes/34/184434/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/test.py'],1,5b0d92691983631200ff3f1fc9386b7bb076e3f8,iso-leak-fix," if hasattr(cls, '_creds_provider'):"," if hasattr(cls, '_cred_provider'):",1,1
openstack%2Fdevstack~master~I6fd393390389c4c643b93198fa461fc2adc415ae,openstack/devstack,master,I6fd393390389c4c643b93198fa461fc2adc415ae,Add new options to baremetal config section,MERGED,2015-04-29 10:57:05.000000000,2015-05-20 13:32:03.000000000,2015-05-20 13:32:01.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 5803}, {'_account_id': 7118}, {'_account_id': 7715}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-04-29 10:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d423ed287ad7106335de180e35dc769ceb46cef1', 'message': 'Add new option to baremetal config section\n\nThis change adds setting of deploy_img_dir baremetal config option\nduring tempest configuration.\n\nChange-Id: I6fd393390389c4c643b93198fa461fc2adc415ae\n'}, {'number': 2, 'created': '2015-04-29 11:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2eddd461aff01b88a922b2b471ce4e35f8d28f2b', 'message': 'Add new option to baremetal config section\n\nThis change adds setting of deploy_img_dir baremetal config option\nduring tempest configuration.\nNeeded for change I171e85cb8a21fae4da45028f1f798988a36f6c95\n\nChange-Id: I6fd393390389c4c643b93198fa461fc2adc415ae\n'}, {'number': 3, 'created': '2015-05-08 13:17:33.000000000', 'files': ['lib/ironic', 'lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/41309002fa1a1c00f8485ef71acdec93fbfbd014', 'message': 'Add new options to baremetal config section\n\nThis change adds setting of deploy_img_dir and node_uuid baremetal\nconfig options during tempest configuration to enable ironic w/o\nglance scenario testing.\nNeeded for change I171e85cb8a21fae4da45028f1f798988a36f6c95\n\nChange-Id: I6fd393390389c4c643b93198fa461fc2adc415ae\n'}]",0,178606,41309002fa1a1c00f8485ef71acdec93fbfbd014,17,7,3,12356,,,0,"Add new options to baremetal config section

This change adds setting of deploy_img_dir and node_uuid baremetal
config options during tempest configuration to enable ironic w/o
glance scenario testing.
Needed for change I171e85cb8a21fae4da45028f1f798988a36f6c95

Change-Id: I6fd393390389c4c643b93198fa461fc2adc415ae
",git fetch https://review.opendev.org/openstack/devstack refs/changes/06/178606/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,d423ed287ad7106335de180e35dc769ceb46cef1,add-bm-opts, iniset $TEMPEST_CONFIG baremetal deploy_img_dir $FILES,,1,0
openstack%2Ffuel-qa~master~I777cb4f6930b1b40e850aafb4abd43f8d059b738,openstack/fuel-qa,master,I777cb4f6930b1b40e850aafb4abd43f8d059b738,Add speed limit for wget 100k,MERGED,2015-05-20 11:55:45.000000000,2015-05-20 13:20:58.000000000,2015-05-20 13:20:57.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2015-05-20 11:55:45.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_failover_base.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/e750c0a20e6fc610704c2fc7a80a8eb846122598', 'message': 'Add speed limit for wget 100k\n\nEnlarging download time of file\nto be sure file size checking\nwas applied during the downloading process\n\nChange-Id: I777cb4f6930b1b40e850aafb4abd43f8d059b738\nCloses-bug: #1457009\n'}]",0,184463,e750c0a20e6fc610704c2fc7a80a8eb846122598,10,6,1,9439,,,0,"Add speed limit for wget 100k

Enlarging download time of file
to be sure file size checking
was applied during the downloading process

Change-Id: I777cb4f6930b1b40e850aafb4abd43f8d059b738
Closes-bug: #1457009
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/63/184463/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_failover_base.py'],1,e750c0a20e6fc610704c2fc7a80a8eb846122598,speed_limit," "" cd {0} && wget --limit-rate=100k {1}'"".format(file_path, DOWNLOAD_LINK))"," "" cd {0} && wget {1}'"".format(file_path, DOWNLOAD_LINK))",2,1
openstack%2Fdevstack~master~I14ec726499d9dbd9f8074bc6d9b950d13689025c,openstack/devstack,master,I14ec726499d9dbd9f8074bc6d9b950d13689025c,Testing the theory that prebuilding wheels may be breaking things,ABANDONED,2015-05-05 21:24:05.000000000,2015-05-20 13:08:36.000000000,,"[{'_account_id': 3}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-05-05 21:24:05.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/76c6d77a5fafa8b3fd23921203ac5a78d03664ee', 'message': 'Testing the theory that prebuilding wheels may be breaking things\n\nChange-Id: I14ec726499d9dbd9f8074bc6d9b950d13689025c\nRelated-Bug: #1451992\n'}]",0,180330,76c6d77a5fafa8b3fd23921203ac5a78d03664ee,4,2,1,1849,,,0,"Testing the theory that prebuilding wheels may be breaking things

Change-Id: I14ec726499d9dbd9f8074bc6d9b950d13689025c
Related-Bug: #1451992
",git fetch https://review.opendev.org/openstack/devstack refs/changes/30/180330/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,76c6d77a5fafa8b3fd23921203ac5a78d03664ee,bug/1451992,#if [[ -n ${WHEELHOUSE:-} && ! -d ${WHEELHOUSE:-} ]]; then # source $TOP_DIR/tools/build_wheels.sh #fi,if [[ -n ${WHEELHOUSE:-} && ! -d ${WHEELHOUSE:-} ]]; then source $TOP_DIR/tools/build_wheels.sh fi,3,3
openstack%2Fdevstack~master~I1156ca7dd950582dec1eafe452982101ce479b98,openstack/devstack,master,I1156ca7dd950582dec1eafe452982101ce479b98,Fix no distributions matching with pip 6.0,ABANDONED,2014-12-22 21:00:57.000000000,2015-05-20 12:38:23.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 9656}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-22 21:00:57.000000000', 'files': ['tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0948804fa268ef8ad72f9311be544f97ec365789', 'message': ""Fix no distributions matching with pip 6.0\n\npip install 'prettytable>0.7' report no distributions matching(for pip\n6.0). This patch fixed the issue.\n\nChange-Id: I1156ca7dd950582dec1eafe452982101ce479b98\n""}]",0,143537,0948804fa268ef8ad72f9311be544f97ec365789,6,4,1,7761,,,0,"Fix no distributions matching with pip 6.0

pip install 'prettytable>0.7' report no distributions matching(for pip
6.0). This patch fixed the issue.

Change-Id: I1156ca7dd950582dec1eafe452982101ce479b98
",git fetch https://review.opendev.org/openstack/devstack refs/changes/37/143537/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,0948804fa268ef8ad72f9311be544f97ec365789,prettytable,pip_install 'prettytable>0.7.0',pip_install 'prettytable>0.7',1,1
openstack%2Ftempest~master~I3c313787b0f6f69edcc5ad16c6c186226f619692,openstack/tempest,master,I3c313787b0f6f69edcc5ad16c6c186226f619692,Tool for generation user accounts from spec,MERGED,2015-04-11 00:02:05.000000000,2015-05-20 12:22:00.000000000,2015-05-20 12:21:57.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7822}, {'_account_id': 8871}, {'_account_id': 9377}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-04-11 00:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3214d5e5b9e230aa2465a6be89170a50f9061b22', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\n\nSample of spec: etc/accounts_spec.yaml.sample\nBasic usage:\n\nGenerate accounts.yaml from spec\n    ./account_generator.py generate --tag foo\n        -s etc/accounts_spec.yaml.sample -c tempest.conf accounts.yaml\n\nDeploy accounts.yaml to cloud\n    ./account_generator.py deploy -c tempest.conf accounts.yaml\n\nCleanup cloud from artifacts\n    ./account_generator.py cleanup -c tempest.conf accounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 2, 'created': '2015-04-16 15:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e5829e3a0d744df4cb571918e9c779a023ec2176', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nSample of spec: etc/accounts_spec.yaml.sample\nBasic usage:\nGenerate accounts.yaml from spec\n    ./account_generator.py generate --tag foo\n        -s etc/accounts_spec.yaml.sample -c tempest.conf accounts.yaml\nDeploy accounts.yaml to cloud\n    ./account_generator.py deploy -c tempest.conf accounts.yaml\nCleanup cloud from artifacts\n    ./account_generator.py cleanup -c tempest.conf accounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 3, 'created': '2015-04-16 17:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f8dc46698afc2e717bcef843737633ac5bd3a2fd', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nSample of spec: etc/accounts_spec.yaml.sample\nBasic usage:\nGenerate accounts.yaml from spec\n    ./account_generator.py generate --tag foo\n        -s etc/accounts_spec.yaml.sample -c tempest.conf accounts.yaml\nDeploy accounts.yaml to cloud\n    ./account_generator.py deploy -c tempest.conf accounts.yaml\nCleanup cloud from artifacts\n    ./account_generator.py cleanup -c tempest.conf accounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 4, 'created': '2015-04-16 20:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/58f33cb3b2351f73a0af732d18a9bbcae767f776', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nSample of spec: etc/accounts_spec.yaml.sample\nBasic usage:\nGenerate accounts.yaml from spec\n    ./account_generator.py generate --tag foo\n        -s etc/accounts_spec.yaml.sample -c tempest.conf accounts.yaml\nDeploy accounts.yaml to cloud\n    ./account_generator.py deploy -c tempest.conf accounts.yaml\nCleanup cloud from artifacts\n    ./account_generator.py cleanup -c tempest.conf accounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 5, 'created': '2015-04-17 14:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/75ba4b065360996b2e86c2e5d4a906268d17e8c2', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nSample of spec: etc/accounts_spec.yaml.sample\nBasic usage:\nGenerate accounts.yaml from spec\n    ./account_generator.py generate --tag foo\n        -s etc/accounts_spec.yaml.sample -c tempest.conf accounts.yaml\nGenerate and deploy accounts.yaml\n    ./account_generator.py generate -d --tag foo\n        -s etc/accounts_spec.yaml.sample -c tempest.conf\n\t--os-username <auth-user-name>\n\t--os-password <auth-password>\n\t--os-tenant-name\n\taccounts.yaml\nDeploy accounts.yaml to cloud\n    ./account_generator.py deploy -c tempest.conf\n\t--os-username <auth-user-name>\n\t--os-password <auth-password>\n\t--os-tenant-name\n\taccounts.yaml\nCleanup cloud from artifacts\n    ./account_generator.py cleanup -c tempest.conf\n        --os-username <auth-user-name>\n        --os-password <auth-password>\n        --os-tenant-name\n        accounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 6, 'created': '2015-04-21 13:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5018e871aac1490d298ab301f00f58edacc3d8f7', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nThis tool can be used for creating user accounts for\ntempest runs in concurrency.\n\nBasic usage:\n    ./account_generator.py\n\t--tag foo\n        -c tempest.conf\n\t--os-username <admin-name>\n\t--os-password <admin-password>\n\t--os-tenant-name <admin-tenant>\n\t-r <concurrency count>\n\t--with-admin (optional)\n\taccounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 7, 'created': '2015-04-22 10:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5fc48ce741336b9e0ae228a53068148b53f7c3fa', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nThis tool can be used for creating user accounts for\ntempest runs in concurrency.\n\nBasic usage:\n    ./account_generator.py\n\t--tag foo\n        -c tempest.conf\n\t--os-username <admin-name>\n\t--os-password <admin-password>\n\t--os-tenant-name <admin-tenant>\n\t-r <concurrency count>\n\t--with-admin (optional)\n\taccounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 8, 'created': '2015-04-27 13:26:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a497e02114b649078beccdb8e958dfd9be70ee7d', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nThis tool can be used for creating user accounts for\ntempest runs in concurrency.\n\nBasic usage:\n    ./account_generator.py\n\t--tag foo\n        -c tempest.conf\n\t--os-username <admin-name>\n\t--os-password <admin-password>\n\t--os-tenant-name <admin-tenant>\n\t-r <concurrency count>\n\t--with-admin (optional)\n\taccounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 9, 'created': '2015-04-29 09:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/898e121518a2837e6cca64165cf4dfe1326fc5be', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nThis tool can be used for creating user accounts for\ntempest runs in concurrency.\n\nBasic usage:\n    ./account_generator.py\n\t--tag foo\n        -c tempest.conf\n\t--os-username <admin-name>\n\t--os-password <admin-password>\n\t--os-tenant-name <admin-tenant>\n\t-r <concurrency count>\n\t--with-admin (optional)\n\taccounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 10, 'created': '2015-04-30 10:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/120f01ed5b6d771e78e6a910661c704148fa419b', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nThis tool can be used for creating user accounts for\ntempest runs in concurrency.\n\nBasic usage:\n    ./account_generator.py\n\t--tag foo\n        -c tempest.conf\n\t--os-username <admin-name>\n\t--os-password <admin-password>\n\t--os-tenant-name <admin-tenant>\n\t-r <concurrency count>\n\t--with-admin (optional)\n\taccounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 11, 'created': '2015-05-06 15:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/67d24d2525823acb658f5c1648dc30c55c4826c8', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nThis tool can be used for creating user accounts for\ntempest runs in concurrency.\n\nBasic usage:\n    ./account_generator.py\n\t--tag foo\n        -c tempest.conf\n\t--os-username <admin-name>\n\t--os-password <admin-password>\n\t--os-tenant-name <admin-tenant>\n\t-r <concurrency count>\n\t--with-admin (optional)\n\taccounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 12, 'created': '2015-05-07 12:45:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/22dd210546ec8e04c915c3c7388fe29ea45726aa', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nThis tool can be used for creating user accounts for\ntempest runs in concurrency.\n\nBasic usage:\n    ./account_generator.py\n\t--tag foo\n        -c tempest.conf\n\t--os-username <admin-name>\n\t--os-password <admin-password>\n\t--os-tenant-name <admin-tenant>\n\t-r <concurrency count>\n\t--with-admin (optional)\n\taccounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 13, 'created': '2015-05-13 14:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/06909cd38bc73f6bcae8c5701460f94032a50c06', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nThis tool can be used for creating user accounts for\ntempest runs in concurrency.\n\nBasic usage:\n    ./account_generator.py\n\t--tag foo\n        -c tempest.conf\n\t--os-username <admin-name>\n\t--os-password <admin-password>\n\t--os-tenant-name <admin-tenant>\n\t-r <concurrency count>\n\t--with-admin (optional)\n\taccounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 14, 'created': '2015-05-13 15:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3fe845c1d5df9e5752398e71efe7845eb81c43dc', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nThis tool can be used for creating user accounts for\ntempest runs in concurrency.\n\nBasic usage:\n    ./account_generator.py\n\t--tag foo\n        -c tempest.conf\n\t--os-username <admin-name>\n\t--os-password <admin-password>\n\t--os-tenant-name <admin-tenant>\n\t-r <concurrency count>\n\t--with-admin (optional)\n\taccounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}, {'number': 15, 'created': '2015-05-15 14:39:22.000000000', 'files': ['tempest/cmd/account_generator.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0de7d059639b64e2429876b2f265bee3e756d7c6', 'message': 'Tool for generation user accounts from spec\n\nImplemented:\nhttps://etherpad.openstack.org/p/accounts-yaml-generation\nThis tool can be used for creating user accounts for\ntempest runs in concurrency.\n\nBasic usage:\n    ./account_generator.py\n\t--tag foo\n        -c tempest.conf\n\t--os-username <admin-name>\n\t--os-password <admin-password>\n\t--os-tenant-name <admin-tenant>\n\t-r <concurrency count>\n\t--with-admin (optional)\n\taccounts.yaml\n\nChange-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692\n'}]",34,172605,0de7d059639b64e2429876b2f265bee3e756d7c6,73,8,15,9377,,,0,"Tool for generation user accounts from spec

Implemented:
https://etherpad.openstack.org/p/accounts-yaml-generation
This tool can be used for creating user accounts for
tempest runs in concurrency.

Basic usage:
    ./account_generator.py
	--tag foo
        -c tempest.conf
	--os-username <admin-name>
	--os-password <admin-password>
	--os-tenant-name <admin-tenant>
	-r <concurrency count>
	--with-admin (optional)
	accounts.yaml

Change-Id: I3c313787b0f6f69edcc5ad16c6c186226f619692
",git fetch https://review.opendev.org/openstack/tempest refs/changes/05/172605/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cmd/javelin.py', 'tempest/cmd/account_generator.py', 'etc/accounts_spec.yaml.sample']",3,3214d5e5b9e230aa2465a6be89170a50f9061b22,account_generator,"# This is a yaml description for account/tenants creation spec # correctly. # Specify information about tenants in this section tenants: number: 3 # You can create anchor to role (or bunch in roles) in this section # In this section $CONF refers to tempest config. # You can specify user roles using refences to tempest.conf. roles: - &default $CONF.auth.tempest_roles - &admin $CONF.identity.admin_role - &swift_operator $CONF.object-storage.operator_role - &swift_reseller_admin $CONF.object-storage.reseller_admin_role - &heat_stack_owner $CONF.orchestration.stack_owner_role #You can specify groups of users with specific set of roles users: - number: 2 prefix: demo roles: [*default] - number: 1 prefix: admin roles: [*default, *admin] - number: 1 prefix: swift_operator roles: [*default, *swift_operator]",,318,6
openstack%2Ftempest~master~I9c1e3cdf53dbae723a9fee67ad96932709d2305f,openstack/tempest,master,I9c1e3cdf53dbae723a9fee67ad96932709d2305f,"Add py34 to readme, pkg metadata, and envlist",MERGED,2015-05-12 02:19:37.000000000,2015-05-20 12:21:49.000000000,2015-05-20 12:21:47.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7020}, {'_account_id': 7350}]","[{'number': 1, 'created': '2015-05-12 02:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a04fb66bc975fdfb79e6b800367f707552a0d16a', 'message': 'Add py34 to readme, pkg metadata, and envlist\n\nThis commit adds references explaining the current state of python 3.4\nand tempest to the readme, pkg metadata, and adds an etry to the tox\nenvlist for running the unit tests on python 3.4.\n\nChange-Id: I9c1e3cdf53dbae723a9fee67ad96932709d2305f\n'}, {'number': 2, 'created': '2015-05-12 18:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/25acd6346edfc6cc2e229c5bf5457f6aee6841d4', 'message': 'Add py34 to readme, pkg metadata, and envlist\n\nThis commit adds references explaining the current state of python 3.4\nand tempest to the readme, pkg metadata, and adds an etry to the tox\nenvlist for running the unit tests on python 3.4.\n\nChange-Id: I9c1e3cdf53dbae723a9fee67ad96932709d2305f\n'}, {'number': 3, 'created': '2015-05-12 19:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0005f73f488091c300161c4f5d9ea498b56d569b', 'message': 'Add py34 to readme, pkg metadata, and envlist\n\nThis commit adds references explaining the current state of python 3.4\nand tempest to the readme, pkg metadata, and adds an etry to the tox\nenvlist for running the unit tests on python 3.4.\n\nChange-Id: I9c1e3cdf53dbae723a9fee67ad96932709d2305f\n'}, {'number': 4, 'created': '2015-05-13 14:19:15.000000000', 'files': ['README.rst', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/3460aaaf3e1917e93d3cab7c060926f15333d8ab', 'message': 'Add py34 to readme, pkg metadata, and envlist\n\nThis commit adds references explaining the current state of python 3.4\nand tempest to the readme, pkg metadata, and adds an etry to the tox\nenvlist for running the unit tests on python 3.4.\n\nChange-Id: I9c1e3cdf53dbae723a9fee67ad96932709d2305f\n'}]",12,182139,3460aaaf3e1917e93d3cab7c060926f15333d8ab,17,7,4,5196,,,0,"Add py34 to readme, pkg metadata, and envlist

This commit adds references explaining the current state of python 3.4
and tempest to the readme, pkg metadata, and adds an etry to the tox
envlist for running the unit tests on python 3.4.

Change-Id: I9c1e3cdf53dbae723a9fee67ad96932709d2305f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/39/182139/4 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'setup.cfg', 'tox.ini']",3,a04fb66bc975fdfb79e6b800367f707552a0d16a,python3-support,"envlist = pep8,py27,py34","envlist = pep8,py27",18,3
openstack%2Fsahara~master~I6919d413c0c2a98905d1e805780d7a5b3bd1aadc,openstack/sahara,master,I6919d413c0c2a98905d1e805780d7a5b3bd1aadc,[DO NOT MERGE] Test patch for CI,ABANDONED,2015-05-20 12:16:14.000000000,2015-05-20 12:16:57.000000000,,[],"[{'number': 1, 'created': '2015-05-20 12:16:14.000000000', 'files': ['test_file'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9ade7b4f669759176bf8117de426b87e827d74ce', 'message': '[DO NOT MERGE] Test patch for CI\n\nChange-Id: I6919d413c0c2a98905d1e805780d7a5b3bd1aadc\n'}]",0,184468,9ade7b4f669759176bf8117de426b87e827d74ce,2,0,1,13919,,,0,"[DO NOT MERGE] Test patch for CI

Change-Id: I6919d413c0c2a98905d1e805780d7a5b3bd1aadc
",git fetch https://review.opendev.org/openstack/sahara refs/changes/68/184468/1 && git format-patch -1 --stdout FETCH_HEAD,['test_file'],1,9ade7b4f669759176bf8117de426b87e827d74ce,,,,0,0
openstack%2Ffuel-astute~master~I269a56b95857121856737d0927ccd98e92fd406e,openstack/fuel-astute,master,I269a56b95857121856737d0927ccd98e92fd406e,Update node hosts info in case of failed nodes,MERGED,2015-05-18 19:55:21.000000000,2015-05-20 12:05:08.000000000,2015-05-20 12:03:15.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-05-18 19:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/79deaedf592fb36076835e32604f26a0fe5d8b6a', 'message': 'Update node hosts information in case of failed to provision nodes\n\n* remove irrelevant pre/post tasks with empty uids;\n* exclude failed nodes from block nodes in deployment info;\n* remove failed nodes  from hosts post hooks.\n\nChange-Id: I269a56b95857121856737d0927ccd98e92fd406e\nCloses-Bug: #1456191\nRelated-Bug: #1446202\n'}, {'number': 2, 'created': '2015-05-18 19:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/42baa945341106dd8512c55f93f68639c8427bdc', 'message': 'Update node hosts info in case of failed nodes\n\n* remove irrelevant pre/post tasks with empty uids;\n* exclude failed nodes from block nodes in deployment info;\n* remove failed nodes  from hosts post hooks.\n* tests\n\nChange-Id: I269a56b95857121856737d0927ccd98e92fd406e\nCloses-Bug: #1456191\nRelated-Bug: #1446202\n'}, {'number': 3, 'created': '2015-05-19 14:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/c3503e5a513aaacd11a381cbcfbe48e17c128b2a', 'message': 'Update node hosts info in case of failed nodes\n\n* remove irrelevant pre/post tasks with empty uids;\n* exclude failed nodes from block nodes in deployment info;\n* tests.\n\nChange-Id: I269a56b95857121856737d0927ccd98e92fd406e\nCloses-Bug: #1456191\n'}, {'number': 4, 'created': '2015-05-20 12:00:47.000000000', 'files': ['lib/astute/deployment_engine.rb', 'spec/unit/deployment_engine_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/795f8a045400fe82ccc30ae018e85324b3fa1de5', 'message': 'Update node hosts info in case of failed nodes\n\n* remove irrelevant pre/post tasks with empty uids;\n* exclude failed nodes from block nodes in deployment info;\n* tests.\n\nChange-Id: I269a56b95857121856737d0927ccd98e92fd406e\nCloses-Bug: #1456191\n'}]",12,184115,795f8a045400fe82ccc30ae018e85324b3fa1de5,37,6,4,8776,,,0,"Update node hosts info in case of failed nodes

* remove irrelevant pre/post tasks with empty uids;
* exclude failed nodes from block nodes in deployment info;
* tests.

Change-Id: I269a56b95857121856737d0927ccd98e92fd406e
Closes-Bug: #1456191
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/15/184115/4 && git format-patch -1 --stdout FETCH_HEAD,"['lib/astute/deployment_engine.rb', 'spec/unit/deployment_engine_spec.rb']",2,79deaedf592fb36076835e32604f26a0fe5d8b6a,bug/1456191," {'uid' => ""1"", 'priority' => 10, 'role' => 'compute', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '3', 'role' => 'compute'}, {'uid' => '4', 'role' => 'compute'} ] }, {'uid' => ""3"", 'priority' => 10, 'role' => 'compute', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '3', 'role' => 'compute'}, {'uid' => '4', 'role' => 'compute'} ] }, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '3', 'role' => 'compute'}, {'uid' => '4', 'role' => 'compute'} ] } {'uid' => ""1"", 'priority' => 10, 'role' => 'compute', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ] }, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ] } {""priority""=>200, ""uids""=>[""1"", ""2""]}, {""priority""=>300, ""uids""=>[""1"", ""2"", ""3""]}, {""priority""=>300, ""uids""=>[""3""]} {""priority""=>200, ""uids""=>[""1"", ""2""]}, {""priority""=>300, ""uids""=>[""1"", ""2""]} {'uid' => ""1"", 'priority' => 10, 'role' => 'compute', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ]}, {'uid' => ""3"", 'priority' => 10, 'role' => 'compute', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ]}, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ] } {'uid' => ""1"", 'priority' => 10, 'role' => 'compute', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ] }, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ] } {'uid' => ""1"", 'priority' => 10, 'role' => 'compute', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ] }, {'uid' => ""3"", 'priority' => 10, 'role' => 'compute', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ] }, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller', 'fail_if_error' => true, 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ]} it 'should process info about nodes in pre/post tasks' do data = <<-EOF nodes: - {fqdn: node-3.test.domain.local, name: node-3, role: compute, swift_zone: '3', uid: '3', user_node_name: slave-03_compute} - {fqdn: node-1.test.domain.local, name: node-1, role: compute, swift_zone: '1', uid: '1', user_node_name: slave-01_compute} - {fqdn: node-2.test.domain.local, name: node-2, role: primary-controller, swift_zone: '2', uid: '2', user_node_name: slave-02_primary_controller} EOF correct_data = <<-EOF nodes: - {fqdn: node-1.test.domain.local, name: node-1, role: compute, swift_zone: '1', uid: '1', user_node_name: slave-01_compute} - {fqdn: node-2.test.domain.local, name: node-2, role: primary-controller, swift_zone: '2', uid: '2', user_node_name: slave-02_primary_controller} EOF correct_data = YAML.dump(YAML.load(correct_data)) non_host_nodes_data = <<-EOF nodes: - { name: node-1, role: compute, uid: '1' } - { name: node-2, role: primary-controller, uid: '2' } EOF tasks = [ {""priority""=>200, ""uids""=>[""1"", ""2""], 'type' => 'upload_file', 'parameters' => { 'path' => ""/etc/hiera/nodes.yaml"", 'data' => data } }, {""priority""=>300, ""uids""=>[""1"", ""2"", ""3""], 'type' => 'upload_file', 'parameters' => { 'path' => ""/etc/hiera/nodes.yaml"", 'data' => non_host_nodes_data } }, {""priority""=>300, ""uids""=>[""3""]} ] correct_tasks = [ {""priority""=>200, ""uids""=>[""1"", ""2""], 'type' => 'upload_file', 'parameters' => { 'path' => ""/etc/hiera/nodes.yaml"", 'data' => correct_data }}, {""priority""=>300, ""uids""=>[""1"", ""2""], 'type' => 'upload_file', 'parameters' => { 'path' => ""/etc/hiera/nodes.yaml"", 'data' => non_host_nodes_data } } ] nodes = [ {'uid' => ""1"", 'priority' => 10, 'role' => 'compute', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ]}, {'uid' => ""3"", 'priority' => 10, 'role' => 'compute', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ]}, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ] } ] correct_nodes = [ {'uid' => ""1"", 'priority' => 10, 'role' => 'compute', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ] }, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller', 'nodes' => [ {'uid' => '1', 'role' => 'compute'}, {'uid' => '2', 'role' => 'primary-controller'}, {'uid' => '4', 'role' => 'compute'} ] } ] res1 = {:data => {:node_type => ""target\n""}, :sender=>""1""} res2 = {:data => {:node_type => ""target""}, :sender=>""2""} mc_res1 = mock_mc_result(res1) mc_res2 = mock_mc_result(res2) mc_timeout = 10 rpcclient = mock_rpcclient(nodes, mc_timeout) rpcclient.expects(:get_type).once.returns([mc_res1, mc_res2]) ctx.stubs(:report_and_update_status) deployer.stubs(:deploy_piece).with(correct_nodes) deployer.expects(:pre_deployment_actions).with(correct_nodes, correct_tasks) deployer.expects(:post_deployment_actions).with(correct_nodes, correct_tasks) deployer.deploy(nodes, tasks, tasks) end "," {'uid' => ""1"", 'priority' => 10, 'role' => 'compute'}, {'uid' => ""3"", 'priority' => 10, 'role' => 'compute'}, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller'} {'uid' => ""1"", 'priority' => 10, 'role' => 'compute'}, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller'} {""priority""=>200, ""uids""=>[""1"", ""2""]}, {""priority""=>300, ""uids""=>[""1"", ""2"", ""3""]} {""priority""=>200, ""uids""=>[""1"", ""2""]}, {""priority""=>300, ""uids""=>[""1"", ""2""]} {'uid' => ""1"", 'priority' => 10, 'role' => 'compute'}, {'uid' => ""3"", 'priority' => 10, 'role' => 'compute'}, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller'} {'uid' => ""1"", 'priority' => 10, 'role' => 'compute'}, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller'} {'uid' => ""1"", 'priority' => 10, 'role' => 'compute'}, {'uid' => ""3"", 'priority' => 10, 'role' => 'compute'}, {'uid' => ""2"", 'priority' => 10, 'role' => 'primary-controller', 'fail_if_error' => true}",283,23
openstack%2Frally~master~I7fdc27ca48adc2678e76e96cccdc15e5f4274287,openstack/rally,master,I7fdc27ca48adc2678e76e96cccdc15e5f4274287,[Scenario] Split scenarios - P1,MERGED,2015-05-10 14:51:25.000000000,2015-05-20 11:00:42.000000000,2015-05-20 10:31:54.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 13919}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-10 14:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6b345b1c9a5fa0d6e354324c3b5eb40e381bad7d', 'message': 'Split scenarios under Plugins\n\nMove dummy under plugins/common\nMove the rest under plugins/openstack\n\nChange-Id: I7fdc27ca48adc2678e76e96cccdc15e5f4274287\n'}, {'number': 2, 'created': '2015-05-12 12:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d7ed600a73900fd956729f80cad6ae0ec6591a0d', 'message': 'Split scenarios under Plugins\n\nMove dummy under plugins/common\nMove the rest under plugins/openstack\n\nChange-Id: I7fdc27ca48adc2678e76e96cccdc15e5f4274287\n'}, {'number': 3, 'created': '2015-05-12 13:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8fdd4b6118f620dbbaa362181f48fdb3d0ce382e', 'message': 'Split scenarios under Plugins\n\nMove dummy under plugins/common\nMove the rest under plugins/openstack\n\nImplements: blueprint split-plugins\nChange-Id: I7fdc27ca48adc2678e76e96cccdc15e5f4274287\n'}, {'number': 4, 'created': '2015-05-12 13:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9d208eda2df938809d6d515671e75851f1743a02', 'message': 'Split scenarios under Plugins\n\nMove dummy under plugins/common\nMove the rest under plugins/openstack\n\nImplements: blueprint split-plugins\nChange-Id: I7fdc27ca48adc2678e76e96cccdc15e5f4274287\n'}, {'number': 5, 'created': '2015-05-17 10:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b9aae5b484051136456395a775aecaea08f48837', 'message': 'Split scenarios under Plugins\n\nMove dummy under plugins/common\nMove the rest under plugins/openstack\n\nImplements: blueprint split-plugins\nChange-Id: I7fdc27ca48adc2678e76e96cccdc15e5f4274287\n'}, {'number': 6, 'created': '2015-05-17 11:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a1a39e9a939d05f69b9b5db28d57f90ea05cd9db', 'message': 'Split scenarios under Plugins\n\nMove dummy under plugins/common\nMove the rest under plugins/openstack\n\nImplements: blueprint split-plugins\nChange-Id: I7fdc27ca48adc2678e76e96cccdc15e5f4274287\n'}, {'number': 7, 'created': '2015-05-17 14:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3c2cebfddd419d688e485a0c1e14155da5676c54', 'message': '[Scenario] Split scenarios under Plugins - dummy\n\nMove dummy under plugins/common\n\nImplements: blueprint split-plugins\nChange-Id: I7fdc27ca48adc2678e76e96cccdc15e5f4274287\n'}, {'number': 8, 'created': '2015-05-17 14:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a13a2e101f21363bb9a75ac768d496e330f4dc96', 'message': '[Scenario] Split scenarios under Plugins - dummy\n\nMove dummy under plugins/common\n\nImplements: blueprint split-plugins\nChange-Id: I7fdc27ca48adc2678e76e96cccdc15e5f4274287\n'}, {'number': 9, 'created': '2015-05-18 05:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a4198cfbc394d073c07e897ac98e04f93ea2b96a', 'message': '[Scenario] Split scenarios under Plugins - dummy\n\nMove dummy under plugins/common\n\nImplements: blueprint split-plugins\nChange-Id: I7fdc27ca48adc2678e76e96cccdc15e5f4274287\n'}, {'number': 10, 'created': '2015-05-18 06:33:37.000000000', 'files': ['tests/unit/plugins/common/scenarios/__init__.py', 'tests/unit/cmd/commands/test_info.py', 'tests/unit/plugins/common/scenarios/dummy/test_dummy.py', 'rally/plugins/common/scenarios/__init__.py', 'rally/plugins/common/scenarios/dummy/dummy.py', 'tests/unit/plugins/common/scenarios/dummy/__init__.py', 'tests/unit/benchmark/scenarios/test_base.py', 'rally/plugins/common/scenarios/dummy/__init__.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/55c3fcebd41b6a990ee4e0b2a4761f3bda2eb230', 'message': '[Scenario] Split scenarios - P1\n\nMove dummy under plugins/common\n\nImplements: blueprint split-plugins\n\nChange-Id: I7fdc27ca48adc2678e76e96cccdc15e5f4274287\n'}]",0,181738,55c3fcebd41b6a990ee4e0b2a4761f3bda2eb230,31,5,10,8576,,,0,"[Scenario] Split scenarios - P1

Move dummy under plugins/common

Implements: blueprint split-plugins

Change-Id: I7fdc27ca48adc2678e76e96cccdc15e5f4274287
",git fetch https://review.opendev.org/openstack/rally refs/changes/38/181738/8 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/plugins/openstack/scenarios/quotas/test_utils.py', 'rally/plugins/openstack/scenarios/swift/objects.py', 'tests/unit/plugins/common/scenarios/dummy/test_dummy.py', 'rally/plugins/openstack/scenarios/glance/__init__.py', 'tests/unit/plugins/openstack/scenarios/designate/__init__.py', 'tests/unit/plugins/openstack/scenarios/ec2/test_utils.py', 'tests/unit/plugins/openstack/scenarios/vm/test_utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_servers.py', 'rally/plugins/openstack/scenarios/heat/utils.py', 'rally/benchmark/context/cleanup/resources.py', 'rally/plugins/common/scenarios/dummy/dummy.py', 'rally/plugins/openstack/scenarios/requests/http_requests.py', 'tests/unit/plugins/openstack/scenarios/mistral/test_workbooks.py', 'tests/unit/plugins/openstack/scenarios/mistral/test_utils.py', 'rally/plugins/openstack/scenarios/ceilometer/resources.py', 'tests/unit/benchmark/context/cleanup/test_resources.py', 'tests/unit/plugins/openstack/scenarios/__init__.py', 'tests/unit/plugins/openstack/scenarios/neutron/__init__.py', 'rally/plugins/openstack/scenarios/zaqar/basic.py', 'tests/unit/plugins/openstack/scenarios/quotas/__init__.py', 'tests/unit/plugins/openstack/scenarios/nova/__init__.py', 'tests/unit/plugins/openstack/scenarios/requests/test_http_requests.py', 'rally/plugins/openstack/scenarios/tempest/tempest.py', 'tests/unit/plugins/openstack/scenarios/tempest/test_utils.py', 'rally/benchmark/context/sahara/sahara_cluster.py', 'rally/plugins/openstack/scenarios/zaqar/utils.py', 'rally/plugins/openstack/scenarios/sahara/__init__.py', 'rally/plugins/openstack/scenarios/nova/utils.py', 'tests/unit/benchmark/context/test_volumes.py', 'rally/plugins/openstack/scenarios/nova/hypervisors.py', 'rally/plugins/openstack/scenarios/swift/utils.py', 'rally/plugins/openstack/scenarios/designate/basic.py', 'tests/unit/plugins/common/scenarios/dummy/__init__.py', 'rally/plugins/openstack/scenarios/mistral/utils.py', 'tests/unit/plugins/openstack/scenarios/authenticate/test_authenticate.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/__init__.py', 'rally/plugins/openstack/scenarios/heat/stacks.py', 'rally/plugins/openstack/scenarios/ec2/__init__.py', 'tests/unit/plugins/openstack/scenarios/nova/test_utils.py', 'rally/plugins/openstack/scenarios/mistral/__init__.py', 'rally/plugins/openstack/scenarios/ec2/utils.py', 'tests/unit/benchmark/context/sahara/test_sahara_edp.py', 'rally/plugins/openstack/scenarios/quotas/utils.py', 'rally/plugins/openstack/scenarios/authenticate/__init__.py', 'rally/benchmark/context/vm/custom_image.py', 'tests/unit/plugins/openstack/scenarios/zaqar/test_utils.py', 'rally/plugins/openstack/scenarios/nova/keypairs.py', 'tests/unit/plugins/openstack/scenarios/swift/__init__.py', 'rally/benchmark/context/stacks.py', 'rally/plugins/openstack/scenarios/keystone/utils.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_clusters.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_jobs.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_resources.py', 'tests/unit/plugins/openstack/scenarios/neutron/test_utils.py', 'rally/plugins/openstack/scenarios/sahara/jobs.py', 'tests/unit/plugins/openstack/scenarios/keystone/__init__.py', 'tests/unit/plugins/openstack/scenarios/nova/test_security_group.py', 'tests/unit/plugins/openstack/scenarios/quotas/test_quotas.py', 'rally/benchmark/context/servers.py', 'rally/plugins/openstack/scenarios/quotas/quotas.py', 'rally/plugins/openstack/scenarios/vm/__init__.py', 'tests/unit/benchmark/context/test_servers.py', 'tests/unit/plugins/openstack/scenarios/cinder/__init__.py', 'rally/plugins/openstack/scenarios/cinder/volumes.py', 'tests/unit/plugins/openstack/scenarios/designate/test_utils.py', 'rally/plugins/openstack/scenarios/sahara/utils.py', 'rally/benchmark/context/images.py', 'tests/unit/plugins/openstack/scenarios/heat/__init__.py', 'tests/unit/plugins/common/scenarios/__init__.py', 'tests/unit/plugins/openstack/scenarios/glance/test_images.py', 'tests/unit/plugins/openstack/scenarios/requests/__init__.py', 'rally/plugins/openstack/scenarios/ceilometer/__init__.py', 'rally/plugins/openstack/scenarios/nova/servers.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_stats.py', 'tests/unit/plugins/openstack/scenarios/keystone/test_utils.py', 'rally/plugins/openstack/scenarios/heat/__init__.py', 'tests/unit/plugins/openstack/scenarios/nova/test_keypairs.py', 'rally/plugins/openstack/scenarios/mistral/workbooks.py', 'tests/unit/benchmark/scenarios/test_base.py', 'tests/unit/plugins/openstack/scenarios/authenticate/__init__.py', 'rally/common/opts.py', 'tests/unit/benchmark/context/sahara/test_sahara_cluster.py', 'rally/plugins/openstack/scenarios/quotas/__init__.py', 'rally/plugins/openstack/scenarios/ceilometer/alarms.py', 'rally/plugins/openstack/scenarios/sahara/node_group_templates.py', 'tests/unit/plugins/openstack/scenarios/nova/test_floating_ips_bulk.py', 'rally/plugins/openstack/scenarios/cinder/__init__.py', 'rally/plugins/openstack/scenarios/authenticate/authenticate.py', 'rally/plugins/openstack/scenarios/ceilometer/queries.py', 'tests/unit/plugins/openstack/scenarios/murano/test_environments.py', 'rally/plugins/openstack/scenarios/keystone/__init__.py', 'tests/unit/plugins/openstack/scenarios/zaqar/test_basic.py', 'rally/plugins/openstack/scenarios/nova/security_group.py', 'rally/plugins/openstack/scenarios/ceilometer/stats.py', 'rally/plugins/openstack/scenarios/requests/__init__.py', 'tests/unit/plugins/openstack/scenarios/designate/test_basic.py', 'tests/unit/plugins/openstack/scenarios/glance/__init__.py', 'tests/unit/benchmark/context/test_images.py', 'rally/plugins/openstack/scenarios/zaqar/__init__.py', 'rally/plugins/openstack/scenarios/murano/environments.py', 'rally/plugins/openstack/scenarios/nova/floating_ips_bulk.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_utils.py', 'rally/plugins/openstack/scenarios/neutron/__init__.py', 'rally/plugins/openstack/scenarios/ceilometer/samples.py', 'rally/plugins/openstack/scenarios/cinder/utils.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_samples.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_node_group_templates.py', 'tests/unit/plugins/openstack/scenarios/heat/test_stacks.py', 'rally/plugins/openstack/scenarios/designate/utils.py', 'rally/plugins/openstack/scenarios/murano/__init__.py', 'rally/plugins/openstack/scenarios/vm/vmtasks.py', 'tests/unit/plugins/openstack/scenarios/murano/test_utils.py', 'tests/unit/cmd/commands/test_info.py', 'tests/unit/plugins/openstack/scenarios/cinder/test_volumes.py', 'rally/plugins/common/scenarios/__init__.py', 'rally/plugins/openstack/scenarios/designate/__init__.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_meters.py', 'tests/unit/plugins/openstack/scenarios/nova/test_hypervisors.py', 'tests/unit/plugins/openstack/scenarios/heat/test_utils.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_alarms.py', 'tests/unit/plugins/openstack/scenarios/cinder/test_utils.py', 'tests/unit/plugins/openstack/scenarios/tempest/__init__.py', 'tests/unit/plugins/openstack/scenarios/test_authenticate.py', 'rally/plugins/openstack/scenarios/ec2/servers.py', 'rally/plugins/openstack/scenarios/murano/utils.py', 'tests/unit/plugins/openstack/scenarios/vm/__init__.py', 'tests/unit/plugins/openstack/scenarios/vm/test_vmtasks.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_utils.py', 'rally/plugins/openstack/scenarios/neutron/network.py', 'rally/plugins/openstack/scenarios/nova/__init__.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_queries.py', 'tests/unit/benchmark/context/test_stacks.py', 'tests/unit/plugins/openstack/scenarios/sahara/__init__.py', 'rally/benchmark/context/sahara/sahara_image.py', 'tests/unit/plugins/openstack/scenarios/tempest/test_tempest.py', 'rally/plugins/openstack/scenarios/swift/__init__.py', 'rally/plugins/openstack/scenarios/tempest/__init__.py', 'tests/unit/plugins/openstack/scenarios/swift/test_utils.py', 'rally/plugins/openstack/scenarios/ceilometer/meters.py', 'tests/unit/plugins/openstack/scenarios/neutron/test_network.py', 'tests/unit/plugins/openstack/scenarios/swift/test_objects.py', 'rally/plugins/openstack/scenarios/requests/utils.py', 'rally/plugins/openstack/scenarios/sahara/consts.py', 'rally/plugins/openstack/scenarios/neutron/utils.py', 'rally/plugins/common/scenarios/dummy/__init__.py', 'tests/unit/plugins/openstack/scenarios/requests/test_utils.py', 'rally/plugins/openstack/scenarios/sahara/clusters.py', 'rally/benchmark/context/volumes.py', 'rally/plugins/openstack/scenarios/keystone/basic.py', 'tests/unit/benchmark/context/sahara/test_sahara_image.py', 'tests/unit/plugins/openstack/scenarios/glance/test_utils.py', 'tests/unit/plugins/openstack/scenarios/ec2/__init__.py', 'rally/plugins/openstack/scenarios/glance/images.py', 'tests/unit/plugins/openstack/scenarios/murano/__init__.py', 'rally/plugins/openstack/scenarios/vm/utils.py', 'tests/unit/plugins/openstack/scenarios/zaqar/__init__.py', 'rally/plugins/openstack/scenarios/glance/utils.py', 'tests/unit/plugins/openstack/scenarios/ec2/test_servers.py', 'rally/plugins/openstack/scenarios/ceilometer/utils.py', 'rally/plugins/openstack/scenarios/__init__.py', 'tests/unit/plugins/openstack/scenarios/keystone/test_basic.py', 'rally/plugins/openstack/scenarios/tempest/utils.py']",162,6b345b1c9a5fa0d6e354324c3b5eb40e381bad7d,bp/split-plugins,,,197,169
openstack%2Ffuel-qa~master~Icf53ae41a197a8dc17d2ccf0b56c6693831294b7,openstack/fuel-qa,master,Icf53ae41a197a8dc17d2ccf0b56c6693831294b7,Update Fuel EMC plugin test to be suitable for CentOS,MERGED,2015-05-20 09:32:54.000000000,2015-05-20 10:55:08.000000000,2015-05-20 10:55:06.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 13306}]","[{'number': 1, 'created': '2015-05-20 09:32:54.000000000', 'files': ['fuelweb_test/tests/plugins/plugin_emc/test_plugin_emc.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/ec13dd4f06f45fc85d9092e6ce8efe4005056526', 'message': 'Update Fuel EMC plugin test to be suitable for CentOS\n\nOS version in method for checking navicli/naviseccli packages was changed\nfrom static ""Ubuntu"" to env-based settings.OPENSTACK_RELEASE option.\n\nChange-Id: Icf53ae41a197a8dc17d2ccf0b56c6693831294b7\nImplements: blueprint mos-emc-pugin-test\n'}]",0,184444,ec13dd4f06f45fc85d9092e6ce8efe4005056526,9,9,1,15692,,,0,"Update Fuel EMC plugin test to be suitable for CentOS

OS version in method for checking navicli/naviseccli packages was changed
from static ""Ubuntu"" to env-based settings.OPENSTACK_RELEASE option.

Change-Id: Icf53ae41a197a8dc17d2ccf0b56c6693831294b7
Implements: blueprint mos-emc-pugin-test
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/44/184444/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/plugins/plugin_emc/test_plugin_emc.py'],1,ec13dd4f06f45fc85d9092e6ce8efe4005056526,bp/mos-emc-pugin-test, os_type=CONF.OPENSTACK_RELEASE) os_type=CONF.OPENSTACK_RELEASE)," os_type=""Ubuntu"") os_type=""Ubuntu"")",2,2
openstack%2Frally~master~Ibd23f911c50889d244633ab34cf19787dabf0325,openstack/rally,master,Ibd23f911c50889d244633ab34cf19787dabf0325,[Scenario] Split Scenarios - P2,MERGED,2015-05-17 14:28:31.000000000,2015-05-20 10:48:19.000000000,2015-05-20 10:33:52.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 13919}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-17 14:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b63a506ecc7ce4ee0c66040fa16f599fb4ba1666', 'message': '[Scenario] Split Murano, Tempest under Plugins\n\nMove under plugins/openstack:\n\nImplements: blueprint split-plugins\n\nChange-Id: Ibd23f911c50889d244633ab34cf19787dabf0325\n'}, {'number': 2, 'created': '2015-05-17 14:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2026cd5d9a52891b3f23c7ed71d6801b5390e331', 'message': '[Scenario] Split Murano, Tempest under Plugins\n\nMove under plugins/openstack:\n\nImplements: blueprint split-plugins\n\nChange-Id: Ibd23f911c50889d244633ab34cf19787dabf0325\n'}, {'number': 3, 'created': '2015-05-18 05:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/43bb20b6007d7ec52f80bac7da5f437717429f9f', 'message': '[Scenario] Split Murano, Tempest under Plugins\n\nMove under plugins/openstack:\n\nImplements: blueprint split-plugins\n\nChange-Id: Ibd23f911c50889d244633ab34cf19787dabf0325\n'}, {'number': 4, 'created': '2015-05-18 06:33:37.000000000', 'files': ['tests/unit/plugins/openstack/scenarios/murano/test_environments.py', 'tests/unit/plugins/openstack/scenarios/tempest/test_tempest.py', 'rally/plugins/openstack/scenarios/tempest/__init__.py', 'rally/plugins/openstack/scenarios/tempest/tempest.py', 'tests/unit/plugins/openstack/scenarios/murano/__init__.py', 'tests/unit/plugins/openstack/scenarios/tempest/test_utils.py', 'rally/plugins/openstack/scenarios/murano/__init__.py', 'tests/unit/plugins/openstack/scenarios/murano/test_utils.py', 'tests/unit/plugins/openstack/scenarios/tempest/__init__.py', 'rally/plugins/openstack/scenarios/__init__.py', 'rally/plugins/openstack/scenarios/murano/environments.py', 'rally/plugins/openstack/scenarios/murano/utils.py', 'rally/plugins/openstack/scenarios/tempest/utils.py', 'tests/unit/plugins/openstack/scenarios/__init__.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/62eb19e1870d25441ba4eeb27b1fa2a69f90da5f', 'message': '[Scenario] Split Scenarios - P2\n\nMove under plugins/openstack:\n    * Murano\n    * Tempest\n\nImplements: blueprint split-plugins\n\nChange-Id: Ibd23f911c50889d244633ab34cf19787dabf0325\n'}]",0,183914,62eb19e1870d25441ba4eeb27b1fa2a69f90da5f,17,5,4,8576,,,0,"[Scenario] Split Scenarios - P2

Move under plugins/openstack:
    * Murano
    * Tempest

Implements: blueprint split-plugins

Change-Id: Ibd23f911c50889d244633ab34cf19787dabf0325
",git fetch https://review.opendev.org/openstack/rally refs/changes/14/183914/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/plugins/openstack/scenarios/murano/test_environments.py', 'tests/unit/plugins/openstack/scenarios/tempest/test_tempest.py', 'rally/plugins/openstack/scenarios/tempest/__init__.py', 'rally/plugins/openstack/scenarios/tempest/tempest.py', 'tests/unit/plugins/openstack/scenarios/murano/__init__.py', 'tests/unit/plugins/openstack/scenarios/tempest/test_utils.py', 'rally/plugins/openstack/scenarios/murano/__init__.py', 'tests/unit/plugins/openstack/scenarios/murano/test_utils.py', 'tests/unit/plugins/openstack/scenarios/tempest/__init__.py', 'rally/plugins/openstack/scenarios/__init__.py', 'rally/plugins/openstack/scenarios/murano/environments.py', 'rally/plugins/openstack/scenarios/murano/utils.py', 'rally/plugins/openstack/scenarios/tempest/utils.py', 'tests/unit/plugins/openstack/scenarios/__init__.py']",14,b63a506ecc7ce4ee0c66040fa16f599fb4ba1666,bp/split-plugins,,,11,11
openstack%2Fhorizon~master~I38d59161dcf8dfe7215231971071dbe82006349d,openstack/horizon,master,I38d59161dcf8dfe7215231971071dbe82006349d,Imported Translations from Transifex,MERGED,2015-05-20 06:20:15.000000000,2015-05-20 10:15:39.000000000,2015-05-20 10:15:38.000000000,"[{'_account_id': 3}, {'_account_id': 6914}, {'_account_id': 9576}]","[{'number': 1, 'created': '2015-05-20 06:20:15.000000000', 'files': ['openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/bc90f065c05002e17bbf3b7a760804746d47e600', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I38d59161dcf8dfe7215231971071dbe82006349d\n'}]",0,184417,bc90f065c05002e17bbf3b7a760804746d47e600,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I38d59161dcf8dfe7215231971071dbe82006349d
",git fetch https://review.opendev.org/openstack/horizon refs/changes/17/184417/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po']",5,bc90f065c05002e17bbf3b7a760804746d47e600,transifex/translations,"# SOME DESCRIPTIVE TITLE. # Copyright (C) YEAR THE PACKAGE'S COPYRIGHT HOLDER # This file is distributed under the same license as the PACKAGE package. # # Translators: msgid """" msgstr """" ""Project-Id-Version: Horizon\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2015-05-19 06:10-0500\n"" ""PO-Revision-Date: 2015-05-19 12:24+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n"" ""Language-Team: Marathi (http://www.transifex.com/projects/p/horizon/language/"" ""mr/)\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Language: mr\n"" ""Plural-Forms: nplurals=2; plural=(n != 1);\n"" msgid ""CPU time used"" msgstr ""CPU वापरलेला वेळ"" msgid ""Average CPU utilization"" msgstr ""सरासरी CPU वापर"" msgid ""Number of VCPUs"" msgstr ""VCPUs ची संख्या"" msgid ""Number of read requests"" msgstr ""विनंती करण्यात आलेल्या वाचनाची संख्या"" msgid ""Number of write requests"" msgstr ""विनंती करण्यात आलेल्या लेखनांची संख्या"" msgid ""Number of incoming bytes on the network for a VM interface"" msgstr ""VM ईंटरफेस साठी नेटवर्क वर येणाऱ्या बाईट ची संख्या"" msgid ""Number of outgoing bytes on the network for a VM interface"" msgstr ""VM ईंटरफेस साठी नेटवर्क वर जाणाऱ्या बाईट ची संख्या"" msgid ""Number of incoming packets for a VM interface"" msgstr ""VM ईंटरफेस साठी नेटवर्क वर येणाऱ्या पॅकेट ची संख्या"" msgid ""Number of outgoing packets for a VM interface"" msgstr ""VM ईंटरफेस साठी नेटवर्क वर जाणाऱ्या पॅकेट ची संख्या"" #, python-format msgid ""Duration of instance type %s (openstack flavor)"" msgstr ""%s प्रकारच्या इंस्टेंस चा कालावधी (ओपनस्टॅक फ्लेवर)"" msgid ""Creation requests for this network"" msgstr ""या नेटवर्क साठी निर्माण विनंती संख्या"" msgid ""Update requests for this network"" msgstr ""या सबनेट साठी निर्माण विनंती संख्या"" msgid ""Creation requests for this subnet"" msgstr ""या सबनेट साठी निर्माण विनंती संख्या"" msgid ""Update requests for this subnet"" msgstr ""या सबनेट साठी अद्यावतीकरण विनंती संख्या"" msgid ""Creation requests for this port"" msgstr ""या पोर्ट साठी निर्माण विनंती संख्या"" msgid ""Update requests for this port"" msgstr ""या पोर्ट साठी अद्यावतीकरण विनंती संख्या"" msgid ""Creation requests for this router"" msgstr ""या राउटर साठी निर्माण विनंती संख्या"" msgid ""Update requests for this router"" msgstr ""या राउटर साठी अद्यावतीकरण विनंती संख्या"" msgid ""Creation requests for this floating ip"" msgstr ""हा बदलता आयपी तयार करण्यासाठी विनंत्या"" msgid ""Update requests for this floating ip"" msgstr ""या बदलत्या आयपीसाठी सुधारित विनंत्या"" msgid ""Image existence check"" msgstr ""चित्र घटक तपासणी"" msgid ""Uploaded image size"" msgstr ""अपलोड करण्यात आलेल्या चित्राचा आकार"" msgid ""Image is downloaded"" msgstr ""चित्र डाउनलोड करण्यात आले आहे"" msgid ""Image is served out"" msgstr ""हे चित्र वापरण्यात आले आहे"" msgid ""Size of volume"" msgstr ""ध्वनीचा आकार"" msgid ""Number of objects"" msgstr ""वस्तुंची संख्या"" msgid ""Total size of stored objects"" msgstr ""साठविलेल्या वस्तुंचा एकूण आकार"" msgid ""Number of containers"" msgstr ""पात्रांची संख्या"" msgid ""Number of incoming bytes"" msgstr ""आत येणा-या बाईटची संख्या"" msgid ""Number of outgoing bytes"" msgstr ""बाहेर जाणा-या बाईटची संख्या"" msgid ""Number of API requests against swift"" msgstr ""स्विफ्टवर केलेल्या एपीआय विनंत्यांची संख्या"" msgid ""Amount of energy"" msgstr ""उर्जेचे प्रमाण"" msgid ""Power consumption"" msgstr ""विजेचा वापर"" msgid ""back-end"" msgstr ""पार्श्वभाग"" msgid ""front-end"" msgstr ""अग्रभाग"" msgctxt ""Both of front-end and back-end"" msgid ""both"" msgstr ""दोन्ही [अग्रभाग व पार्श्वभाग दोन्ही]"" msgid ""Unknown instance"" msgstr ""अज्ञात घटक"" #, python-format msgid ""%(type)s (%(backend)s backend)"" msgstr ""%(type)s (%(backend)s backend)"" msgid ""Identity service does not allow editing user data."" msgstr ""ओळख सेवा वापरकर्ता डाटा संपादित करण्याची परवानगी देत नाही."" #, python-format msgid ""User %s has no role defined for that project."" msgstr ""वापरकर्ता %s ची त्या प्रकल्पामध्ये निश्चित भूमिका नाही."" #, python-format msgid ""ALLOW %(ethertype)s %(proto_port)s %(direction)s %(remote)s"" msgstr ""परवानगी द्या %(ethertype)s %(proto_port)s %(direction)s %(remote)s"" msgid ""Unable to connect to Neutron."" msgstr ""न्यूट्रॉनशी संपर्क स्थापित करता येत नाही."" #, python-format msgid ""Unable to parse IP address %s."" msgstr ""आयपी पत्त्याचे पदनिरुपण करण्यास असमर्थ %s."" #. Translators: Only used inside Horizon code and invisible to users #, python-format msgid """" ""The requested feature '%(feature)s' is unknown. Please make sure to specify "" ""a feature defined in FEATURE_MAP."" msgstr """" ""विनंती करण्यात आलेले वैशिष्ट्य '%(feature)s' अज्ञात आहे. कृपया FEATURE_MAP मध्ये व्याख्या "" ""करण्यात आलेले वैशिष्ट्य नमूद केले जाईल याची खात्री करा."" #. Translators: Only used inside Horizon code and invisible to users #, python-format msgid """" ""The 'operation' parameter for get_feature_permission '%(feature)s' is "" ""invalid. It should be one of %(allowed)s"" msgstr """" ""get_feature_permission '%(feature)s' साठीचा 'operation' निर्देशांक अवैध आहे. ते "" ""%(allowed)s पैकी एक असले पाहिजे"" #, python-format msgid ""Failed to check Neutron '%s' extension is not supported"" msgstr ""न्यूट्रॉन '%s' विस्तारास सहाय्य नसल्याचे तपासण्यात अपयशी"" msgid ""-"" msgstr ""-"" #, python-format msgid ""ALLOW %(from)s:%(to)s from %(group)s"" msgstr ""परवानगी द्या %(from)s:%(to)s पासून %(group)s"" #, python-format msgid ""ALLOW %(from)s:%(to)s from %(cidr)s"" msgstr ""परवानगी द्या %(from)s:%(to)s पासून %(cidr)s"" msgid ""Couldn't get security group list."" msgstr ""सुरक्षा गट यादी मिळाली नाही."" #, python-format msgid ""Couldn't get current security group list for instance %s."" msgstr ""घटकासाठी सध्याची सुरक्षा गट यादी मिळाली नाही %s."" #, python-format msgid """" ""Failed to modify %(num_groups_to_modify)d instance security groups: %(err)s"" msgstr """" ""सुधारणा करण्यात अपयशी %(num_groups_to_modify)d उदाहरणार्थ सुरक्षा गटs: %(err)s"" #, python-format msgid ""Failed to modify %d instance security groups"" msgstr ""सुधारणा करण्यात अपयशी %d घटक सुरक्षा गट"" #, python-format msgid ""Name: %(name)s ID: %(uuid)s"" msgstr ""नाव: %(name)s ओळखक्रमांक: %(uuid)s"" #, python-format msgid ""Failed to evacuate instances: %s"" msgstr ""घटक रिक्त करण्यात अपयशी: %s"" msgid ""The container cannot be deleted since it is not empty."" msgstr ""हे पात्र नष्ट करता येत नाही कारण ते रिकामे नाही."" msgid ""The pseudo folder cannot be deleted since it is not empty."" msgstr ""आभासी धारक नष्ट करता येत नाही कारण ते रिक्त नाही."" msgid ""Name"" msgstr ""नाव"" msgid ""Availability Zone"" msgstr ""उपलब्धता विभाग"" #, python-format msgid ""Successfully updated aggregate: \""%s.\"""" msgstr ""यशस्वीपणे सुधारित सरासरी: \""%s.\"""" msgid ""Unable to update the aggregate."" msgstr ""सरासरी सुधारित करता येत नाही."" msgid ""Metadata successfully updated."" msgstr ""मेटाडाटा यशस्वीपणे सुधारित करण्यात आला."" msgid ""Unable to update the aggregate metadata."" msgstr ""सरासरी मेटाडाटा सुधारित करता आला नाही."" msgid ""Host Aggregates"" msgstr ""होस्ट सरासरी."" msgid ""Create Host Aggregate"" msgstr ""होस्ट सरासरी तयार करा"" msgid ""Manage Hosts"" msgstr ""होस्टचे व्यवस्थापन करा"" msgid ""Update Metadata"" msgstr ""मेटाडाटा सुधारित करा"" msgid ""Edit Host Aggregate"" msgstr ""होस्ट सरासरी संपादित करा"" msgid ""Services Up"" msgstr ""सेवा वर"" msgid ""Services Down"" msgstr ""सेवा खाली"" msgid ""Hosts"" msgstr ""होस्ट"" msgid ""Metadata"" msgstr ""मेटाडाटा"" msgid ""Availability Zone Name"" msgstr ""उपलब्धता विभाग नाव"" msgid ""Available"" msgstr ""उपलब्ध"" msgid ""Availability Zones"" msgstr ""उपलब्धता विभाग"" msgid ""Description:"" msgstr ""वर्णन:"" msgid """" ""Host aggregates divide an availability zone into logical units by grouping "" ""together hosts. Edit the aggregate host to select hosts contained in it."" msgstr """" ""होस्ट सरासरी होस्टचे एकत्र वर्गीकरण करुन उपलब्धता विभागांना तर्कशुद्ध विभागांमध्ये विभागते. "" ""त्यामध्ये समाविष्ट होस्ट निवडण्यासाठी सरासरी होस्टचे संपादन करा."" msgid ""Save"" msgstr ""सुरक्षित करा"" msgid ""Cancel"" msgstr ""रद्द करा"" msgid ""Update Aggregate Metadata"" msgstr ""सरासरी मेटाडाटा सुधारित करा"" msgid ""Manage Hosts Aggregate"" msgstr ""होस्ट सरासरीचे व्यवस्थापन करा"" msgid ""Unable to retrieve host aggregates list."" msgstr ""होस्ट सरासरी यादी मिळवण्यास असमर्थ."" msgid ""Unable to retrieve availability zone list."" msgstr ""उपलब्धता विभाग यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve the aggregate to be updated"" msgstr ""सुधारित करायची सरासरी मिळविण्यास असमर्थ"" msgid ""Unable to retrieve available metadata for aggregate."" msgstr ""सरासरीसाठी उपलब्ध मेटाडाटा मिळविण्यास असमर्थ."" msgid ""Unable to retrieve the aggregate to be updated."" msgstr ""सुधारणा करायची सरासरी मिळविण्यास असमर्थ."" msgid ""Host Aggregate Information"" msgstr ""होस्ट सरासरी माहिती"" msgid """" ""Host aggregates divide an availability zone into logical units by grouping "" ""together hosts. Create a host aggregate then select the hosts contained in "" ""it."" msgstr """" ""होस्ट सरासरीमुळे होस्टची तर्कशुद्ध विभागांमध्ये वर्गीकरण करुन उपलब्धता विभाग विभागले "" ""जातात. होस्ट सरासरी तयार करा त्यानंतर त्यामधील होस्ट निवडा."" msgid ""Unable to get host aggregate list"" msgstr ""होस्ट सरासरी यादी मिळण्यास असमर्थ"" #, python-format msgid ""The name \""%s\"" is already used by another host aggregate."" msgstr "" \""%s\"" हे नाव आधीपासूनच दुस-या होस्ट सरासरीद्वारे वापरले जात आहे."" msgid ""Unable to get the available hosts"" msgstr ""उपलब्ध होस्ट मिळू शकत नाहीत"" msgid ""Manage Hosts within Aggregate"" msgstr ""सरासरीमधील होस्टचे व्यवस्थापन करा"" msgid ""Add hosts to this aggregate. Hosts can be in multiple aggregates."" msgstr ""या सरासरीमध्ये होस्ट समाविष्ट करा. होस्ट अनेक सरासरींमध्ये असू शकतात."" msgid ""All available hosts"" msgstr ""सर्व उपलब्ध होस्ट"" msgid ""Selected hosts"" msgstr ""निवडेले होस्ट"" msgid ""No hosts found."" msgstr ""एकही होस्ट सापडला नाही."" msgid ""No host selected."" msgstr ""कोणताही होस्ट निवडला नाही."" msgid """" ""Add hosts to this aggregate or remove hosts from it. Hosts can be in "" ""multiple aggregates."" msgstr """" ""या सरासरीमध्ये होस्ट समाविष्ट करा किंवा त्यातून होस्ट काढून टाका. होस्ट अनेक सरासरींच्या "" ""स्वरुपात असू शकतात."" msgid ""All Available Hosts"" msgstr ""सर्व उपलब्ध होस्ट"" msgid ""Selected Hosts"" msgstr ""निवडलेले होस्ट"" msgid ""No Hosts found."" msgstr ""कोणतेही होस्ट सापडले नाहीत."" msgid ""No Host selected."" msgstr ""कोणतेही होस्ट निवडले नाहीत."" #, python-format msgid ""Created new host aggregate \""%s\""."" msgstr ""नवीन होस्ट सरासरी तयार केली \""%s\""."" #, python-format msgid ""Unable to create host aggregate \""%s\""."" msgstr ""होस्ट सरासरी तयार करण्यास असमर्थ \""%s\""."" msgid ""Unable to create host aggregate."" msgstr ""होस्ट सरासरी करण्यास असमर्थ."" msgid ""Error adding Hosts to the aggregate."" msgstr ""सरासरीमध्ये होस्ट समाविष्ट करण्यात चूक."" msgid ""Add/Remove Hosts to Aggregate"" msgstr ""सरासरीमध्ये होस्ट समाविष्ट/नष्ट करा"" msgid ""The Aggregate was updated."" msgstr ""सरासरी सुधारित करण्यात आली."" msgid ""Error when adding or removing hosts."" msgstr ""होस्ट समाविष्ट करताना किंवा काढून टाकताना चूक."" msgid ""System"" msgstr ""यंत्रणा"" msgid ""Admin"" msgstr ""प्रशासक"" msgid ""Defaults"" msgstr ""पूर्वनिर्धारित"" msgid ""Update Defaults"" msgstr ""पूर्वनिर्धारित सुधारित करा"" msgid ""Injected File Content Bytes"" msgstr ""समाविष्ट धारिका मजकूर बाईट्स"" msgid ""Length of Injected File Path"" msgstr ""समाविष्ट केलेल्या धारिकेच्या मार्गाची लांबी"" msgid ""Metadata Items"" msgstr ""मेटाडाटा घटक"" msgid ""VCPUs"" msgstr ""व्हीसीपीयू"" msgid ""Instances"" msgstr ""घटक"" msgid ""Injected Files"" msgstr ""समाविष्ट धारिका"" msgid ""Volumes"" msgstr ""खंड"" msgid ""Volume Snapshots"" msgstr ""खंडाची क्षणचित्रे"" msgid ""Total Size of Volumes and Snapshots (GB)"" msgstr ""खंडांचा व क्षणचित्रांचा एकूण आकार (जीबी)"" msgid ""RAM (MB)"" msgstr ""रॅम (एमबी)"" msgid ""Floating IPs"" msgstr ""बदलते आयपी"" msgid ""Security Groups"" msgstr ""सुरक्षा गट"" msgid ""Security Group Rules"" msgstr ""सुरक्षा गट नियम"" msgid ""Key Pairs"" msgstr ""मुख्य जोड्या"" msgid ""Fixed IPs"" msgstr ""स्थिर आयपी"" msgid ""LUKS Volumes"" msgstr ""एलयूकेएस खंड"" msgid ""LUKS Volume Snapshots"" msgstr ""एलयूकेएस खंड क्षणचित्रे"" msgid ""Total Size of LUKS Volumes and Snapshots (GB)"" msgstr ""एलयूकेएस खंड व क्षणचित्रांचा एकूण आकार (जीबी)"" msgid ""dm-crypt"" msgstr ""डीएम-गृहिका"" msgid ""Backups"" msgstr ""राखीव साठा"" msgid ""Quota Name"" msgstr ""वाटा नाव"" msgid ""Limit"" msgstr ""मर्यादा"" msgid ""Quotas"" msgstr ""वाटे"" msgid ""Default Quotas"" msgstr ""पूर्वनिर्धारित वाटे"" msgid ""Unable to get quota info."" msgstr ""वाट्याविषयी माहिती मिळवता येत नाही."" msgid ""Unable to retrieve default quota values."" msgstr ""वाट्याची पूर्वनिर्धारित मूल्य मिळवता येत नाहीत."" msgid ""From here you can update the default quotas (max limits)."" msgstr ""येथून तुम्ही पूर्वनिर्धारित वाटे सुधारित करु शकता (कमाल मर्यादा)."" msgid ""Update Default Quotas"" msgstr ""पूर्वनिर्धारित वाटे सुधारित करा"" msgid ""Default quotas updated."" msgstr ""पूर्वनिर्धारित वाटे सुधारित."" msgid ""Unable to update default quotas."" msgstr ""पूर्वनिर्धारित वाटे सुधारित करण्यास असमर्थ."" msgid ""Unable to update the flavor metadata."" msgstr ""मेटाडाटांचे साचे सुधारित करतायेत नाहीत."" msgid ""Flavors"" msgstr ""साचे"" msgid ""Create Flavor"" msgstr ""साचा तयार करा"" msgid ""Edit Flavor"" msgstr ""साचा संपादित करा"" msgid ""Modify Access"" msgstr ""उपलब्धतेत बदल करा"" #, python-format msgid ""%sMB"" msgstr ""%sएमबी"" #, python-format msgid ""%sGB"" msgstr ""%sजीबी"" msgid ""Flavor Name"" msgstr ""साच्याचे नाव"" msgid ""RAM"" msgstr ""रॅम"" msgid ""Root Disk"" msgstr ""मूळ मार्गदर्शिका असलेली डिस्क"" msgid ""Ephemeral Disk"" msgstr ""तात्पुरती डिस्क"" msgid ""Swap Disk"" msgstr ""देवाणघेवाण डिस्क"" msgid ""ID"" msgstr ""आयडी"" msgid ""Public"" msgstr ""सार्वजनिक"" msgid ""Update Flavor Metadata"" msgstr ""साचा मेटाडाटा सुधारित करा"" msgid ""Unable to retrieve flavor list."" msgstr ""साचा यादी घेण्यास असमर्थ."" msgid ""Unable to retrieve flavor details."" msgstr ""साच्याचे तपशील मिळविण्यास असमर्थ."" msgid ""Unable to retrieve available metadata for flavors."" msgstr ""साच्यांसाठी उपलब्ध मेटाडाटा मिळविण्यास असमर्थ."" msgid ""Unable to retrieve the flavor metadata."" msgstr ""साच्याचा मेटाडाटा मिळविण्यास असमर्थ."" msgid """" ""Flavor ID should be UUID4 or integer. Leave this field blank or use 'auto' "" ""to set a random UUID4."" msgstr """" ""साचा ओळख क्रमांक यूयूआयडी४ किंवा पूर्णांक संख्या असली पाहिजे. हे क्षेत्र रिक्त ठेवा किंवा स्वैर "" ""यूयूआयडी४ची रचना करण्यासाठी 'स्वयंचलित वापरा'."" msgid """" ""Name may only contain letters, numbers, underscores, periods and hyphens."" msgstr ""नावामध्ये फक्त अक्षरे, संख्या, अधोरेखा, कालावधी व संयोगी चिन्हांचा समावेश असू शकतो."" msgid ""Root Disk (GB)"" msgstr ""मूळ मार्गदर्शिका असलेली डिस्क (जीबी)"" msgid ""Ephemeral Disk (GB)"" msgstr ""तात्पुरती डिस्क (जीबी)"" msgid ""Swap Disk (MB)"" msgstr ""देवाणघेवाण डिस्क (एमबी)"" msgid ""Flavor Information"" msgstr ""साचा माहिती"" msgid """" ""Flavors define the sizes for RAM, disk, number of cores, and other resources "" ""and can be selected when users deploy instances."" msgstr """" ""साचे रॅमसाठी आकार, डिस्क, कामांची संख्या, व इतर संसाधने निश्चित करतात व वापरकर्ते जेव्हा "" ""घटक तैनात करतात तेव्हा निवडता येतात."" msgid ""Unable to get flavor list"" msgstr ""साचा यादी मिळवता आली नाही"" #, python-format msgid ""The name \""%s\"" is already used by another flavor."" msgstr ""\""%s\""हे नाव आधीपासूनच दुस-या साच्याद्वारे वापरले जात आहे."" #, python-format msgid ""The ID \""%s\"" is already used by another flavor."" msgstr ""\""%s\"" हा ओळख क्रमांक आधीपासूनच दुस-या साच्याद्वारे वापरला जात आहे."" msgid ""Unable to retrieve flavor access list. Please try again later."" msgstr ""साचा उपलब्धता यादी मिळविण्यास असमर्थ. कृपया थोड्या वेळाने पुन्हा प्रयत्न करा."" msgid ""Flavor Access"" msgstr ""साचा उपलब्धता"" msgid """" ""Select the projects where the flavors will be used. If no projects are "" ""selected, then the flavor will be available in all projects."" msgstr """" ""ज्या ठिकाणी साचे वापरले जातील ते प्रकल्प निवडा. कोणतेही प्रकल्प निवडले नाहीत, तर साचे "" ""सर्व प्रकल्पांमध्ये उपलब्ध होतील."" msgid ""All Projects"" msgstr ""सर्व प्रकल्प"" msgid ""Selected Projects"" msgstr ""निवडलेले प्रकल्प"" msgid ""No projects found."" msgstr ""कोणतेही प्रकल्प सापडले नाहीत."" msgid ""No projects selected. All projects can use the flavor."" msgstr ""कोणतेही प्रकल्प निवडले नाहीत. सर्व प्रकल्प साचे वापरु शकतात."" #, python-format msgid ""Created new flavor \""%s\""."" msgstr ""नवीन साचा तयार करण्यात आला \""%s\""."" #, python-format msgid ""Unable to create flavor \""%s\""."" msgstr ""नवीन साचा तयार करण्यास असमर्थ\""%s\""."" msgid ""Unable to create flavor."" msgstr ""नवीन साचा तयार करण्यास असमर्थ."" #, python-format msgid ""Unable to set flavor access for project %s."" msgstr ""प्रकल्पासाठी साचा उपलब्धता निश्चित करण्यास असमर्थ %s."" msgid """" ""Edit the flavor details. Flavors define the sizes for RAM, disk, number of "" ""cores, and other resources. Flavors are selected when users deploy instances."" msgstr """" ""साच्याचे तपशील संपादित करा. साचे रॅमचा आकार, डिस्क, कामांची संख्या, व इतर संसाधने "" ""निश्चित करतात. वापरकर्ते घटक तैनात करतात तेव्हा साचे निवडले जातात."" #, python-format msgid ""Modified flavor \""%s\""."" msgstr ""सुधारित साचा \""%s\""."" #, python-format msgid ""Unable to modify flavor \""%s\""."" msgstr ""साचा सुधारण्यास असमर्थ \""%s\""."" msgid ""Modified flavor information, but unable to modify flavor access."" msgstr ""सुधारित साचा माहिती, मात्र साचा उपलब्धता सुधारण्यास असमर्थ."" msgid ""Current Host"" msgstr ""सध्याचा होस्ट"" msgid ""Target Host"" msgstr ""लक्ष्य होस्ट"" msgid ""Choose a Host to evacuate servers to."" msgstr ""ज्या होस्टवर सर्वर रिकामे करायचे आहेत तो निवडा."" msgid ""Shared Storage"" msgstr ""विभागलेला साठा"" msgid ""Select a target host"" msgstr ""लक्ष्य होस्ट निवडा"" msgid ""No other hosts available."" msgstr ""इतर कोणताही होस्ट उपलब्ध नाही."" #, python-format msgid ""Starting evacuation from %(current)s to %(target)s."" msgstr ""%(current)s पासून %(target)s पर्यंत रिकामे करणे सुरु."" #, python-format msgid ""Failed to evacuate host: %s."" msgstr ""होस्टला रिकामे करण्यात अपयशी: %s."" msgid ""Host"" msgstr ""होस्ट"" msgid ""Reason"" msgstr ""कारण"" #, python-format msgid ""Disabled compute service for host: %s."" msgstr ""होस्टसाठी संगणन सेवा असमर्थ: %s."" #, python-format msgid ""Failed to disable compute service for host: %s."" msgstr ""होस्टसाठी संगणन सेवा असमर्थ करण्यात अपयशी: %s."" msgid ""Live Migrate"" msgstr ""थेट स्थलांतर"" msgid ""Disk Over Commit"" msgstr ""डिस्क संपली करा"" msgid ""Block Migration"" msgstr ""स्थलांतर थांबवा"" msgid ""Evacuate Host"" msgstr ""होस्ट रिकामा करा"" msgid ""Disable Service"" msgstr ""सेवा असमर्थ करा"" msgctxt ""Current status of a Hypervisor"" msgid ""Enabled"" msgstr ""समर्थ करण्यात आलेले"" msgctxt ""Current status of a Hypervisor"" msgid ""Disabled"" msgstr ""असमर्थ करण्यात आलेले"" msgctxt ""Current state of a Hypervisor"" msgid ""Up"" msgstr ""वर"" msgctxt ""Current state of a Hypervisor"" msgid ""Down"" msgstr ""खाली"" msgid ""Zone"" msgstr ""विभाग"" msgid ""Status"" msgstr ""स्थिती"" msgid ""State"" msgstr ""राज्य"" msgid ""Updated At"" msgstr ""रोजी सुधारणा"" msgid ""Compute Host"" msgstr ""संगणन होस्ट"" msgid ""Unable to get nova services list."" msgstr ""नोव्हा सेवा यादी मिळू शकली नाही."" msgid ""Unable to retrieve compute host information."" msgstr ""संगणन होस्ट माहिती मिळविण्यास असमर्थ."" msgid ""Hypervisors"" msgstr ""व्हर्च्युअल यंत्र निरीक्षक"" msgid ""Hostname"" msgstr ""होस्टनाव"" msgid ""Type"" msgstr ""प्रकार"" msgid ""VCPUs (used)"" msgstr ""व्हीसीपीयू (वापरलेले)"" msgid ""VCPUs (total)"" msgstr ""व्हीसीपीयू (एकूण)"" msgid ""RAM (used)"" msgstr ""रॅम (वापरलेली)"" msgid ""RAM (total)"" msgstr ""रॅम (एकूण)"" msgid ""Local Storage (used)"" msgstr ""साठवण्याची एकूण जागा (वापरलेली)"" msgid ""Local Storage (total)"" msgstr ""साठविण्याची स्थानिक जागा (एकूण)"" msgid ""Instance Name"" msgstr ""घटना नाव"" msgid ""Instance ID"" msgstr ""घटना ओळख क्रमांक"" msgid ""Hypervisor Instances"" msgstr ""व्हर्च्युअल यंत्र निरीक्षक घटक"" msgid ""Hypervisor"" msgstr ""व्हर्च्युअल यंत्र निरीक्षक"" msgid ""Unable to retrieve hypervisor information."" msgstr ""व्हर्च्युअल यंत्र निरीक्षक माहिती मिळविण्यास असमर्थ"" msgid ""Disable the compute service."" msgstr ""संगणन सेवा असमर्थ करा"" msgid """" ""Evacuate the servers from the selected down host to an active target host."" msgstr ""निवडक डाउन होस्टवरुन सक्रिय लक्ष्य होस्टवर सर्वर रिक्त करा."" msgid ""Hypervisor Servers"" msgstr ""व्हर्च्युअल यंत्र निरीक्षक सर्वर "" msgid ""Hypervisor Summary"" msgstr ""व्हर्च्युअल यंत्र निरीक्षक सर्वर सारांश"" msgid ""VCPU Usage"" msgstr ""व्हीसीपीयू वापर"" #, python-format msgid ""Used <span> %(used)s </span> of <span> %(available)s </span>"" msgstr """" ""वापरलेले <विस्तार> <span> %(used)s </span> पैकी <span> %(available)s </span>"" msgid ""Memory Usage"" msgstr ""मेमरी वापर"" msgid ""Local Disk Usage"" msgstr ""स्थानिक डिस्क वापर"" msgid ""All Hypervisors"" msgstr ""सर्व व्हर्च्युअल यंत्र निरीक्षक सर्वर"" msgid ""Unable to retrieve hypervisor statistics."" msgstr ""व्हर्च्युअल यंत्र निरीक्षक सांख्यिकी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve hypervisor instances list."" msgstr ""व्हर्च्युअल यंत्र निरीक्षक घटक यादी मिळविण्यास असमर्थ."" msgid ""Unable to update the image metadata."" msgstr ""हा चित्र मेटाडाटा सुधारित करण्यास असमर्थ."" msgid ""Images"" msgstr ""चित्रे"" msgid ""Image Name ="" msgstr ""चित्राचे नाव ="" msgid ""Status ="" msgstr ""स्थिती ="" msgid ""Format ="" msgstr ""स्वरुप ="" msgid ""Min. Size (MB)"" msgstr ""किमान आकार (एमबी)"" msgid ""Max. Size (MB)"" msgstr ""कमाल आकार (एमबी)"" msgid ""Image Name"" msgstr ""चित्राचे नाव"" msgid ""Specify an image to upload to the Image Service."" msgstr ""चित्र सेवेवर अपलोड करायचे चित्र स्पष्ट करा."" msgid """" ""Currently only images available via an HTTP URL are supported. The image "" ""location must be accessible to the Image Service. Compressed image binaries "" ""are supported (.zip and .tar.gz.)"" msgstr """" ""सध्या केवळ एचटीटीपी यूआरएलद्वारे उपलब्ध चित्रांनाच सहाय्य आहे. चित्राचे ठिकाण चित्र "" ""सेवेसाठी उपलब्ध असले पाहिजे. संपीडित चित्र द्विअंकींना सहाय्य आहे (.झिप व .टीएआर.जीझेड.)"" msgid ""Please note: "" msgstr ""कृपया नोंद घ्या: "" msgid """" ""The Image Location field MUST be a valid and direct URL to the image binary. "" ""URLs that redirect or serve error pages will result in unusable images."" msgstr """" ""चित्र ठिकाण क्षेत्र ही चित्र द्विअंकांची वैध व थेट यूआरएल असली पाहिजे. ज्या यूआरएल "" ""पुनर्निदेशित करतात किंवा सर्वर चूक पाने दाखवतात त्यावर विचित्र चित्रे दिसू शकतात."" msgid ""Edit the image details."" msgstr ""चित्राचे तपशील संपादित करा"" msgid ""Create An Image"" msgstr ""एक चित्र तयार करा"" msgid ""Update Image"" msgstr ""चित्र सुधारित करा"" msgid ""Update Image Metadata"" msgstr ""चित्राचा मेटाडाटा सुधारित करा"" msgid ""Unable to retrieve image list."" msgstr ""चित्र यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve available properties for image."" msgstr ""चित्रासाठी उपलब्ध वैशिष्ट्ये मिळविण्यास असमर्थ."" msgid ""Unable to retrieve the image to be updated."" msgstr ""सुधारित करायचे चित्र मिळविण्यास असमर्थ."" msgid ""System Information"" msgstr ""यंत्रणा माहिती"" msgid ""Enabled"" msgstr ""समर्थ करण्यात आलेले"" msgid ""Disabled"" msgstr ""असमर्थ करण्यात आलेले"" msgid ""Up"" msgstr ""वर"" msgid ""Down"" msgstr ""खाली"" msgid ""Service"" msgstr ""सेवा"" msgid ""Services"" msgstr ""सेवा"" msgctxt ""Time since the last update"" msgid ""Last Updated"" msgstr ""शेवटची सुधारणा [शेवटच्या सुधारणेची वेळ]"" msgid ""Compute Services"" msgstr ""संगणन सेवा"" msgid ""Block Storage Services"" msgstr ""साठवणूक सेवा प्रतिबंधित करा"" msgid ""Network Agents"" msgstr ""नेटवर्क प्रतिनिधी"" msgid ""Unable to get cinder services list."" msgstr ""सिंडर सेवा यादी मिळविण्यास असमर्थ."" msgid ""Unable to get network agents info."" msgstr ""नेटवर्क प्रतिनिधींची माहिती मिळविण्यास असमर्थ."" msgid ""Unable to get network agents list."" msgstr ""नेटवर्क प्रतिनिधी यादी मिळविण्यास असमर्थ."" #, python-format msgid ""Reason: %(disabled_reason)s"" msgstr ""कारण: %(disabled_reason)s"" #, python-format msgid """" ""Version: %(version_info)s\n"" "" "" msgstr """" ""आवृत्ती: %(version_info)s\n"" "" "" msgid ""Unable to retrieve version information."" msgstr ""आवृत्तीची माहिती मिळविण्यास असमर्थ."" msgid ""New Host"" msgstr ""नवीन होस्ट"" msgid ""Choose a Host to migrate to."" msgstr ""कोणत्या होस्टवर स्थलांतर करायचे ते निवडा."" msgid ""Select a new host"" msgstr ""नवीन होस्ट निवडा"" #, python-format msgid ""The instance is preparing the live migration to host \""%s\""."" msgstr ""घटक होस्टवर थेट स्थलांतरासाठी तयारी करत आहे \""%s\""."" #, python-format msgid ""Failed to live migrate instance to host \""%s\""."" msgstr ""घटक होस्टवर थेट स्थलांतरित करण्यास अपयशी \""%s\""."" msgid ""Live Migrate Instance"" msgstr ""थेट स्थलांतर घटक"" msgid ""Host ="" msgstr ""होस्ट ="" msgid ""IPv4 Address ="" msgstr ""आयपीव्ही४ पत्ता ="" msgid ""IPv6 Address ="" msgstr ""आयपीव्ही६ पत्ता ="" msgid ""Image ID ="" msgstr ""चित्र ओळख क्रमांक ="" msgid ""Flavor ID ="" msgstr ""साचा ओळख क्रमांक ="" msgid ""Project"" msgstr ""प्रकल्प"" msgid ""IP Address"" msgstr ""आयपी पत्ती"" msgid ""Size"" msgstr ""आकार"" msgid ""Task"" msgstr ""काम"" msgid ""Power State"" msgstr ""विजेचा वापर"" msgid ""Time since created"" msgstr ""तयार केल्यापासूनची वेळ"" msgid ""Live migrate an instance to a specific host."" msgstr ""एखाद्या घटकाचे विशिष्ट होस्टकडे थेट स्थलांतर."" msgid ""Unable to retrieve instance project information."" msgstr ""घटक प्रकल्प माहिती मिळवता येत नाही."" msgid ""Unable to retrieve instance list."" msgstr ""घटक यादी मिळवता येत नाही."" msgid ""Unable to retrieve IP addresses from Neutron."" msgstr ""न्यूट्रॉनमधून आयपी पत्ता मिळवता येत नाही."" msgid ""Unable to retrieve instance size information."" msgstr ""घटक आकार पत्ता मिळवता येत नाही."" msgid ""Unable to retrieve host information."" msgstr ""होस्ट माहिती मिळवता येत नाही."" msgid ""Unable to retrieve instance details."" msgstr ""घटक पत्ता मिळवता येत नाही."" msgid ""Direct Input"" msgstr ""थेट टंकलेखन"" msgid ""Protected"" msgstr ""सुरक्षित"" msgid ""Description"" msgstr ""वर्णन"" msgid ""Info"" msgstr ""माहिती"" msgid ""None"" msgstr ""एकही नाही"" msgid ""Created"" msgstr ""तयार करण्यात आले"" msgid ""Unknown"" msgstr ""अज्ञात"" msgid ""Updated"" msgstr ""सुधारित"" msgid ""Never updated"" msgstr ""कधीही सुधारित केले नाही"" msgid ""Filter"" msgstr ""चाळणी"" msgid ""Last day"" msgstr ""शेवटचा दिवस"" msgid ""Last week"" msgstr ""शेवटचा आठवडा"" msgid ""Month to date"" msgstr ""महिन्याचा दिवस"" msgid ""Last 15 days"" msgstr ""शेवटचे १५ दिवस"" msgid ""Last 30 days"" msgstr ""शेवटचे ३० दिवस"" msgid ""Last year"" msgstr ""शेवटचे वर्ष"" msgid ""Other"" msgstr ""इतर"" msgid ""Period"" msgstr ""कालावधी"" msgid ""From"" msgstr ""कडून"" msgid ""To"" msgstr ""प्रति"" msgid ""Must specify start of period"" msgstr ""कालावधीची सुरुवात नमूद करणे बंधनकारक"" msgid ""Start must be earlier than end of period."" msgstr ""सुरुवात कालावधी संपण्यापूर्वी असली पाहिजे."" msgid ""Resource Usage"" msgstr ""संसाधनांचा वापर"" msgid ""Modify Usage Report Parameters"" msgstr ""वापर अहवाल निर्देशांकात सुधारणा करा"" msgid ""Download CSV Summary"" msgstr ""सीएसव्ही सारांश डाउनलोड करा"" msgid ""Meter"" msgstr ""मीटर"" msgid ""Day"" msgstr ""दिवस"" msgid ""Value (Avg)"" msgstr ""मूल्य (सरासरी)"" msgid ""Daily Usage Report"" msgstr ""दैनंदिन वापर अहवाल"" msgid ""Stats"" msgstr ""राज्ये"" msgid ""There are no meters defined yet."" msgstr ""अजून कोणतीही मीटर निश्चित करण्यात आलेली नाहीत."" msgid ""Usage Report"" msgstr ""वापर अहवाल"" msgid ""Nova"" msgstr ""नोव्हा"" msgid ""Neutron"" msgstr ""न्यूट्रॉन"" msgid ""Glance"" msgstr ""दृष्टिक्षेप"" msgid ""Cinder"" msgstr ""सिंडर"" msgid ""Swift_meters"" msgstr ""जलद_मीटर"" msgid ""Kwapi"" msgstr ""क्वापी"" msgid ""Dates cannot be recognized."" msgstr ""तारखा ओळखता येत नाहीत."" msgid ""Unable to retrieve project list."" msgstr ""प्रकल्प यादी मिळवता आली नाही."" msgid ""Select a pre-defined period or specify date."" msgstr ""पूर्व-निर्धआरित कालावधी निवडा व तारीख निश्चित करा."" msgid ""View Usage Report"" msgstr ""वापर अहवाल पाहा"" msgid ""Resources Usage Overview"" msgstr ""संसाधन वापर आढावा"" msgid ""Metric:"" msgstr ""मितीय:"" msgid ""Compute (Nova)"" msgstr ""संगणन करा (नोव्हा)"" msgid ""Network (Neutron)"" msgstr ""नेटवर्क (न्यूट्रॉन)"" msgid ""Image (Glance)"" msgstr ""चित्र (ग्लान्स)"" msgid ""Volume (Cinder)"" msgstr ""प्रमाण (सिंडर)"" msgid ""Object Storage (Swift)"" msgstr ""घटक संग्रह (स्विफ्ट)"" msgid ""Energy (Kwapi)"" msgstr ""ऊर्जा (क्वापी)"" msgid ""Group by:"" msgstr ""वर्गीकरण द्वारे:"" msgid ""--"" msgstr ""--"" msgid ""Value:"" msgstr ""मूल्य:"" msgid ""Avg."" msgstr ""सरासरी."" msgid ""Min."" msgstr ""किमान."" msgid ""Max."" msgstr ""कमाल."" msgid ""Sum."" msgstr ""बेरीज."" msgid ""Period:"" msgstr ""कालावधी:"" msgid ""From:"" msgstr ""कडून:"" msgid ""To:"" msgstr ""प्रति:"" msgid ""Statistics of all resources"" msgstr ""सर्व संसाधनांची सांख्यिकी"" msgid ""Project Name"" msgstr ""प्रकल्प नाव"" msgid ""Time"" msgstr ""वेळ"" msgid ""Network Name"" msgstr ""नेटवर्कचे नाव"" msgid ""New DHCP Agent"" msgstr ""नवीन डीएचसीपी प्रतिनिधी"" msgid ""Choose an DHCP Agent to attach to."" msgstr ""ज्याला जोडायचा आहे असा डीएचसीपी प्रतिनिधी निवडा."" msgid ""Select a new agent"" msgstr ""नवीन प्रतिनिधी निवडा"" msgid ""No other agents available."" msgstr ""इतर कोणताही प्रतिनिधी उपलब्ध नाही."" msgid ""Unable to list dhcp agents hosting network."" msgstr ""डीएचसीपी प्रतिनिधी होस्टिंग नेटवर्कची यादी तयार करण्यास असमर्थ."" #, python-format msgid ""Agent %s was successfully added."" msgstr ""प्रतिनिधी %s यशस्वीपणे समाविष्ट करण्यात आला."" #, python-format msgid ""Failed to add agent %(agent_name)s for network %(network)s."" msgstr ""प्रतिनिधी समाविष्ट करण्यात अपयशी %(agent_name)s नेटवर्कसाठी %(network)s."" #, python-format msgid ""Failed to delete agent: %s"" msgstr ""प्रतिनिधी नष्ट करण्यात अपयशी: %s"" msgid ""Add DHCP Agent"" msgstr ""डीएचसीपी प्रतिनिधी समाविष्ट करा"" msgid ""Admin State"" msgstr ""प्रशासकीय स्थिती"" msgid ""DHCP Agents"" msgstr ""डीएचसीपी प्रतिनिधी"" msgid ""Unable to retrieve network."" msgstr ""नेटवर्क मिळविण्यात अपयशी."" msgid ""Unable to retrieve agent list."" msgstr ""प्रतिनिधी यादी मिळविण्यात अपयशी."" msgid ""Local"" msgstr ""स्थानिक"" msgid ""Flat"" msgstr ""सपाट"" msgid ""VLAN"" msgstr ""व्हीलॅन"" msgid ""GRE"" msgstr ""जीआरई"" msgid ""VXLAN"" msgstr ""व्हीएक्सलॅन"" msgid ""Network Profile"" msgstr ""नेटवर्क स्वरुप"" msgid ""Provider Network Type"" msgstr ""पुरवठादार नेटवर्क प्रकार"" msgid ""The physical mechanism by which the virtual network is implemented."" msgstr ""व्हर्च्युअल नेटवर्क ज्याप्रकारे राबवले जाईल त्याचे प्रत्यक्ष यंत्रणा."" msgid ""Physical Network"" msgstr ""प्रत्यक्ष नेटवर्क"" msgid """" ""The name of the physical network over which the virtual network is "" ""implemented."" msgstr ""व्हर्च्युअल नेटवर्क ज्यावर राबविण्यात आले असेल त्या प्रत्यक्ष नेटवर्कचे नाव."" msgid ""Segmentation ID"" msgstr ""वर्गीकरण ओळख क्रमांक"" msgid ""Shared"" msgstr ""विभाजित"" msgid ""External Network"" msgstr ""बाह्य नेटवर्क"" msgid ""Select a project"" msgstr ""प्रकल्प निवडा"" #, python-format msgid """" ""For VLAN networks, the VLAN VID on the physical network that realizes the "" ""virtual network. Valid VLAN VIDs are %(vlan_min)s through %(vlan_max)s. For "" ""GRE or VXLAN networks, the tunnel ID. Valid tunnel IDs for GRE networks are "" ""%(gre_min)s through %(gre_max)s. For VXLAN networks, %(vxlan_min)s through "" ""%(vxlan_max)s."" msgstr """" ""व्हीलॅन नेटवर्कसाठी, प्रत्यक्ष नेटवर्कवरील व्हीलॅन व्हीआयडी जे व्हर्च्युअल नेटवर्कचे कार्य पार "" ""पाडते. वैध व्हीलॅन व्हीआयडी आहेत %(vlan_min)s पैकी %(vlan_max)s. जीआरई किंवा व्हीलॅन "" ""नेटवर्कसाठी, टनल ओळख क्रमांक. जीआरई नेटवर्कसाठी वैध टनल ओळख क्रमांक आहे %(gre_min)s "" ""द्वारे %(gre_max)s. व्हीएक्सलॅन नेटवर्कसाठी, %(vxlan_min)s पैकी %(vxlan_max)s."" msgid ""Select a profile"" msgstr ""स्वरुप निवडा"" msgid ""Network Profiles could not be retrieved."" msgstr ""नेटवर्कचे स्वरुप मिळू शकले नाही."" #, python-format msgid ""Network %s was successfully created."" msgstr ""नेटवर्क %s यशस्वीपणे तयार करण्यात आले."" #, python-format msgid ""Failed to create network %s"" msgstr ""नेटवर्क तयार करण्यात अपयशी %s"" #, python-format msgid ""For VLAN networks, valid VLAN IDs are %(min)s through %(max)s."" msgstr ""व्हीलॅन नेटवर्कसाठी, वैध व्हीलॅन ओळख क्रमांक आहे %(min)s पैकी %(max)s."" #, python-format msgid ""For GRE networks, valid tunnel IDs are %(min)s through %(max)s."" msgstr ""जीआरई नेटवर्कसाठी, वैध टनल ओळख क्रमांक %(min)s पैकी %(max)s."" #, python-format msgid ""For VXLAN networks, valid tunnel IDs are %(min)s through %(max)s."" msgstr ""व्हीएक्सलॅन नेटवर्कसाठी, वैध टनल ओळखक्रमांक आहे %(min)s पैकी %(max)s."" #, python-format msgid ""Network %s was successfully updated."" msgstr ""नेटवर्क %s मध्ये यशस्वीपणे सुधारणा करण्यात आली."" #, python-format msgid ""Failed to update network %s"" msgstr ""नेटवर्कमध्ये सुधारणा करण्यात अपयशी %s"" msgid ""Networks"" msgstr ""नेटवर्क"" msgid ""Normal"" msgstr ""सामान्य"" msgid ""Network ID"" msgstr ""नेटवर्क ओळख क्रमांक"" msgid ""Device ID"" msgstr ""साधन ओळख क्रमांक "" msgid ""Device ID attached to the port"" msgstr ""पोर्टला जोडलेल्या साधनाचा ओळख क्रमांक"" msgid ""Device Owner"" msgstr ""साधनाचा मालक"" msgid ""Device owner attached to the port"" msgstr ""पोर्टला जोडलेल्या साधनाचा मालक"" msgid ""MAC Learning State"" msgstr ""मॅक अध्ययन स्थिती"" #, python-format msgid ""Port %s was successfully created."" msgstr ""पोर्ट %s यशस्वीपणे तयार करण्यात आले."" #, python-format msgid ""Failed to create a port for network %s"" msgstr ""नेटवर्कसाठी पोर्ट तयार करण्यात अपयशी %s"" #, python-format msgid ""Port %s was successfully updated."" msgstr ""पोर्ट %s मध्ये यशस्वीपणे सुधारणा करण्यात आली."" #, python-format msgid ""Failed to update port %s"" msgstr ""पोर्टमध्ये सुधारणा करण्यात अपयशी %s"" #, python-format msgid ""Failed to delete port: %s"" msgstr ""पोर्ट नष्ट करण्यात अपयशी: %s"" msgid ""Create Port"" msgstr ""पोर्ट तयार करा"" msgid ""Ports"" msgstr ""पोर्ट"" #, python-format msgid ""Failed to delete subnet %s"" msgstr ""उपनेट नष्ट करण्यात अपयशी%s"" msgid ""Create Subnet"" msgstr ""उपनेट तयार करा"" msgid ""Edit Subnet"" msgstr ""उपनेट संपादित करा"" msgid ""CIDR"" msgstr ""सीआयडीआर"" msgid ""IP Version"" msgstr ""आयपी आवृत्ती"" msgid ""Gateway IP"" msgstr ""गेटवे पत्ता"" #, python-format msgid ""Unable to retrieve details for network \""%s\""."" msgstr ""नेटवर्कसाठी तपशील मिळवता आले नाही \""%s\""."" msgid ""Subnets"" msgstr ""उपनेट"" #, python-format msgid ""Failed to retrieve network %s for a subnet"" msgstr ""उपनेटसाठी नेटवर्क %s मिळविण्यात अपयशी"" #, python-format msgid ""Failed to delete network %s"" msgstr ""नेटवर्क नष्ट करण्यात अपयशी %s"" msgid ""Create Network"" msgstr ""नेटवर्क तयार करा"" msgid ""Edit Network"" msgstr ""नेटवर्क संपादित करा"" msgid ""Subnets Associated"" msgstr ""जोडलेली उप नेट"" msgid ""Create a new network for any project as you need."" msgstr ""तुमच्या गरजेप्रमाणे कोणत्याही प्रकल्पासाठी नवीन नेटवर्क तयार करा."" msgid """" ""Provider specified network can be created. You can specify a physical "" ""network type (like Flat, VLAN, GRE, and VXLAN) and its segmentation_id or "" ""physical network name for a new virtual network."" msgstr """" ""पुरवठादार विशिष्ट नेटवर्क तयार करता येते. तुम्ही नव्या व्हर्च्युअल नेटवर्कसाठी एक प्रत्यक्ष "" ""नेटवर्क प्रकार (उदाहरणार्थ फ्लॅट, व्हीलॅन, जीआरई, व व्हीएक्सलॅन) व त्याचा वर्गीकरण_ओळख "" ""क्रमांर किंवा प्रत्यक्ष नेटवर्क नाव निश्चित करु शकता."" msgid """" ""In addition, you can create an external network or a shared network by "" ""checking the corresponding checkbox."" msgstr """" ""त्याशिवाय, तुम्ही योग्य त्या चौकटीवर बरोबरची खूण करुन बाह्य नेटवर्क किंवा विभागलेले "" ""नेटवर्गही तयार करु शकता."" msgid ""You may update the editable properties of your network here."" msgstr ""तुम्हाला येथे तुमच्या नेटवर्कची संपादन करण्यायोग्य वैशिष्ट्ये येथे सुधारित करु शकता."" msgid ""From here you can add a DHCP agent for the network."" msgstr ""इथून तुम्ही नेटवर्कमधील सीएचसीपी प्रतिनिधी समाविष्ट करु शकताk."" msgid """" ""You can create a port for the network. If you specify device ID to be "" ""attached, the device specified will be attached to the port created."" msgstr """" ""तुम्ही नेटवर्कसाठी एक पोर्ट तयार करु शकता. तुम्ही जे साधन जोडायचे आहे त्याचा ओळख क्रमांक "" ""नमूद केला, तर नमूद केलेले साधन तयार करण्यात आलेल्या पोर्टला जोडले जाईल."" msgid ""Project ID"" msgstr ""प्रकल्प ओळख क्रमांक"" msgid ""Fixed IP"" msgstr ""निश्चित आयपी"" msgid ""Subnet ID"" msgstr ""उपनेट आयडी"" msgid ""Attached Device"" msgstr ""जोडलेले साधन"" msgid ""No attached device"" msgstr ""कोणतेही साधन जोडलेले नाही"" msgid ""You may update the editable properties of your port here."" msgstr ""तुम्ही इथे तुमच्या पोर्टची संपादन करण्यायोग्य वैशिष्ट्ये सुधारित करु शकता."" msgid ""Update Port"" msgstr ""पोर्टमध्ये सुधारणा करा"" msgid ""Update Network"" msgstr ""नेटवर्कमध्ये सुधारणा करा"" msgid ""Network list can not be retrieved."" msgstr ""नेटवर्क यादी मिळवता येत नाही."" msgid ""Subnet list can not be retrieved."" msgstr ""उपनेट यादी मिळवता आली नाही."" msgid ""Port list can not be retrieved."" msgstr ""पोर्ट यादी मिळवता आली नाही."" msgid ""Overview"" msgstr ""आढावा"" msgid ""Usage Overview"" msgstr ""वापर आढावा"" msgid ""Monitoring:"" msgstr ""निरीक्षण:"" msgid ""Disk (GB)"" msgstr ""डिस्क (जीबी)"" msgid ""Usage (Hours)"" msgstr ""वापर (तास)"" msgid ""Deleted"" msgstr ""नष्ट करण्यात आले"" msgid ""Routers"" msgstr ""राउटर"" msgid ""Interfaces"" msgstr ""आंतरपृष्ठे"" msgid ""Router Details"" msgstr ""राउटरचे तपशील"" msgid ""Update Router"" msgstr ""राउटरमध्ये सुधारणा करा"" msgid ""Unable to retrieve router list."" msgstr ""राउटरची यादी मिळविण्यास असमर्थ."" msgid ""Creating"" msgstr ""तयार करत आहे"" msgid ""Deleting"" msgstr ""नष्ट करत आहे"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgid ""Error Deleting"" msgstr ""चूक नष्ट करत आहे"" #, python-format msgid ""Successfully updated volume snapshot status: \""%s\""."" msgstr ""यशस्वीपणे खंड क्षणचित्र स्थितीमध्ये सुधारणा केली: \""%s\""."" msgid ""Unable to update volume snapshot status."" msgstr ""खंड क्षणचित्रे स्थिती सुधारित करण्यास असमर्थ."" msgid ""Update Status"" msgstr ""सुधारित स्थिती"" msgid ""Unable to retrieve volume project information."" msgstr ""खंड प्रकल्पाची माहिती मिळू शकली नाही."" msgid ""Volume Name"" msgstr ""खंडाचे नाव"" msgid ""Update Volume Snapshot Status"" msgstr ""खंड क्षणचित्र स्थिती सुधारित करा"" msgid ""Unable to retrieve volume snapshot."" msgstr ""खंड क्षणचित्रे मिळू शकली नाहीत."" msgid ""Volume Types"" msgstr ""खंड प्रकार"" msgid ""Unable to retrieve volume types"" msgstr ""खंडाचे प्रकार मिळू शकले नाहीत."" msgid ""Unable to retrieve volume type encryption information."" msgstr ""खंड प्रकार सांकेतिकरण माहिती मिळू शकली नाही."" msgid ""Unable to retrieve QoS specs"" msgstr ""क्यूओएस निर्देश मिळू शकले नाहीत"" msgid ""Unable to retrieve volume snapshots."" msgstr ""खंड क्षणचित्रे मिळू शकली नाहीत."" msgid ""Volume Snapshot Overview"" msgstr ""खंड क्षणचित्र आढावा"" msgid ""Information"" msgstr ""माहिती"" msgid ""Volume"" msgstr ""खंड"" msgid ""Specs"" msgstr ""निर्देश"" msgid ""GB"" msgstr ""जीबी"" msgid """" ""\n"" "" The status of a volume snapshot is normally managed automatically. In "" ""some circumstances\n"" "" an administrator may need to explicitly update the status value. This is "" ""equivalent to\n"" "" the <tt>cinder snapshot-reset-state</tt> command.\n"" "" "" msgstr """" ""\n"" "" खंड क्षणचित्र स्थितीचे सामान्यपणे स्वयंचलितपणे व्यवस्थापन केले जाते. काही परिस्थितींमध्ये\n"" "" एखाद्या प्रशासकाला स्थिती मूल्य स्पष्टपणे सुधारावे लागेल. हे\n"" "" <tt>सिंडर क्षणचित्र-मूळस्थिती-स्थिती</tt> आज्ञेसारखे आहे.\n"" "" "" msgid """" ""\n"" "" Volume type is a type or label that can be selected at volume "" ""creation\n"" "" time in OpenStack. It usually maps to a set of capabilities of the "" ""storage\n"" "" back-end driver to be used for this volume. Examples: \""Performance"" ""\"",\n"" "" \""SSD\"", \""Backup\"", etc. This is equivalent to the\n"" "" <tt>cinder type-create</tt> command. Once the volume type gets "" ""created,\n"" "" click the \""View Extra Specs\"" button to set up extra specs key-value\n"" "" pair(s) for that volume type.\n"" "" "" msgstr """" ""\n"" "" खंड प्रकार हा प्रकार किंवा खूणचिठ्ठी असते जी खंड तयार करण्याच्या वेळी \n"" "" ओपनस्टेकमध्ये निवडता येते. ती सामान्यपणे संग्रहाच्या काही क्षमतांचा शोध घेते\n"" "" या खंडासाठी पार्श्व-भाग ड्रायव्हर वापरायचा आहे. उदाहरण: \""कामगिरी\"",\n"" "" \""एसएसडी\"", \""राखीव साठा\"", इत्यादी. हे\n"" "" <tt>सिंडर प्रकार-तयार करा</tt> आज्ञेसारखे आहे. एकदा खंड प्रकार तयार झाल्यानंतर,\n"" "" \""अतिरिक्त निर्देश पाहा\"" बटणावर क्लिक करा ज्याद्वारे त्या खंड प्रकारासाठी "" ""अतिरिक्त निर्देश मुख्य-मूल्य\n"" "" जोडी (ड्या) तयार केल्या जातील.\n"" "" "" msgid """" ""Creating encryption for a volume type causes all volumes with that volume "" ""type to be encrypted. Encryption information cannot be added to a volume "" ""type if volumes are currently in use with that volume type."" msgstr """" ""खंड प्रकारासाठी सांकेतिकरण तयार केल्याने त्या खंड प्रकारातील सर्व खंडांचे सांकेतिकरण केले जाते. "" ""त्या खंड प्रकारातील खंड सध्या वापरात असतील तर सांकेतिकरण माहिती त्या खंड प्रकारामध्ये "" ""समाविष्ट करता येत नाही."" msgid """" ""The <strong>Provider</strong> is the class providing encryption support (e."" ""g. LuksEncryptor)."" msgstr ""<सशक्त> पुरवठादार</सशक्त> हा वर्ग सांकेतिकरण सहाय्य देतो (उदा. ल्यूक्सएन्क्रिप्टर)."" msgid """" ""The <strong>Control Location</strong> is the notional service where "" ""encryption is performed (e.g., front-end=Nova). The default value is 'front-"" ""end.'"" msgstr """" ""<सशक्त>नियंत्रण ठिकाण</सशक्त> ही राष्ट्रीय सेवा आहे जेथे सांकेतिकरण केले जाते (उदा., अग्र-"" ""भाग=नोव्हा). पूर्वनिर्धारित मूल्य 'अग्र-भाग' असते."" msgid """" ""The <strong>Cipher</strong> is the encryption algorithm/mode to use (e.g., "" ""aes-xts-plain64). If the field is left empty, the provider default will be "" ""used."" msgstr """" ""<सशक्त>सायफर</सशक्त>हा सांकेतिकरण गणनविधी/पद्धत वापरली जातेe (उदा., एईएस-एक्सटीएस-"" ""प्लेन६४). जर क्षेत्र रिक्त सोडण्यात आले, तर पुरवठादार पूर्वनिर्धारित वापरला जाईल."" msgid """" ""The <strong>Key Size</strong> is the size of the encryption key, in bits (e."" ""g., 128, 256). If the field is left empty, the provider default will be used."" msgstr """" ""<सशक्त>कळ आकार</सशक्त> हा सांकेतिकरण कळीचा आकार आहे, बिट्समध्ये (उदा. १२८, २५६). "" ""क्षेत्र रिक्त सोडण्यात आल्यास, पूर्वनिर्धारित पुरवठादार वापरला जाईल."" msgid """" ""\n"" "" Each QoS Specs entity will have a \""Consumer\"" value which indicates "" ""where the\n"" "" administrator would like the QoS policy to be enforced. This value can "" ""be \""front-end\""\n"" "" (Nova Compute), \""back-end\"" (Cinder back-end), or \""both\"".\n"" "" "" msgstr """" ""\n"" "" प्रत्येक क्यूओएस निर्देश घटकाचे एक \""ग्राहक\"" मूल्य असेल जे\n"" "" प्रशासकाला क्यूओएस धोरण कुठे राबवायला आवडेल हे दर्शवते. हे मूल्य \""अग्र-भाग\""\n"" "" (नोव्हा संगणन), \""पार्श्व-भाग\"" (सिंडर पार्श्व-भाग), किंवा \""दोन्ही\"" असू शकते.\n"" "" "" msgid ""Volume Type Encryption Overview"" msgstr ""खंड प्रकार सांकेतिकरण आढावा"" msgid ""Provider"" msgstr ""पुरवठादार"" msgid ""Control Location"" msgstr ""नियंत्रण स्थान"" msgid ""Cipher"" msgstr ""सांकेतिकरण"" msgid ""Key Size (bits)"" msgstr ""कळीची आकार (बिट्स)"" msgid ""Volume Type is Unencrypted."" msgstr ""खंडाच्या प्रकाराचे सांकेतिकरण केलेले नाही."" msgid ""Associate QoS Spec"" msgstr ""क्यूओएस निर्देश जोडा"" msgid ""Create QoS Spec"" msgstr ""क्यूओएस निर्देश तयार करा"" msgid ""Create Volume Type"" msgstr ""खंड प्रकार तयार करा"" msgid ""Create Encrypted Volume Type"" msgstr ""सांकेतिकरण करण्यात आलेला खंड प्रकार तयार करा"" msgid ""Edit QoS Spec Consumer"" msgstr ""क्यूओएस निर्देश ग्राहक संपादित करा"" msgid ""Create a new \""extra spec\"" key-value pair for a volume type."" msgstr ""एक नवीन \""अतिरिक्त निर्देश\"" मुख्य- मूल्य जोडी खंड प्रकारासाठी तयार करा."" #, python-format msgid ""Update the \""extra spec\"" value for \""%(key)s\"""" msgstr ""सुधारित करा \""extra spec\"" मूल्य साठी \""%(key)s\"""" msgid ""Volume Type Extra Specs"" msgstr ""अतिरिक्त निर्देशांसाठी मूल्य प्रकार"" msgid ""Close"" msgstr ""बंद करा"" msgid ""Create Volume Type Extra Spec"" msgstr ""खंड प्रकार अतिरिक्त निर्देश तयार करा"" #, python-format msgid ""Volume Type: %(volume_type_name)s "" msgstr ""खंड प्रकार: %(volume_type_name)s "" msgid ""Edit Volume Type Extra Spec"" msgstr ""संपादित खंड प्रकार अतिरिक्त निर्देश"" #, python-format msgid ""Volume Type: %(volume_type_name)s"" msgstr ""खंड प्रकार: %(volume_type_name)s"" #, python-format msgid ""Create a new \""spec\"" key-value pair for QoS Spec \""%(qos_spec_name)s\"""" msgstr """" ""नवीन तयार करा \""spec\"" कळ-मूल्य जोडी क्यूओएस निर्देशासाठी \""%(qos_spec_name)s\"""" #, python-format msgid ""Update the spec value for \""%(key)s\"""" msgstr ""\""%(key)s\"" साठी निर्देश मूल्य सुधारित करा"" msgid ""Create Spec"" msgstr ""निर्देश तयार करा"" msgid ""Edit Spec"" msgstr ""निर्देश संपादित करा"" msgid ""QoS Spec: "" msgstr ""क्यूओएस निर्देश: "" msgid ""Volume Type Encryption Details"" msgstr ""खंड प्रकार सांकेतिकरण तपशील"" msgid """" ""\n"" "" The status of a volume is normally managed automatically. In some "" ""circumstances an\n"" "" administrator may need to explicitly update the status value. This is "" ""equivalent to\n"" "" the <tt>cinder reset-state</tt> command.\n"" "" "" msgstr """" ""\n"" "" खंडाच्या स्थितीचे सामान्यपणे स्वयंचलितपणे व्यवस्थापन केले जाते. काही परिस्थितीमध्ये "" ""एखाद्या\n"" "" प्रशासकाला कदाचित स्थिती मूल्य स्पष्टपणे सुधारित करावे लागेल. हे\n"" "" <tt>सिंडर पुनर्मांडणी-स्थिती</tt>आदेशाप्रमाणे आहे.\n"" "" "" msgid ""Volume Details"" msgstr ""खंड तपशील"" msgid ""Update Volume Status"" msgstr ""खंड स्थिती सुधारित करा"" msgid ""Key"" msgstr ""कळ"" msgid ""Value"" msgstr ""मूल्य"" #, python-format msgid ""Created extra spec \""%s\""."" msgstr ""अतिरिक्त निर्देश तयार करा\""%s\""."" msgid ""Unable to create volume type extra spec."" msgstr ""खंड प्रकार अतिरिक्त निर्देश तयार करण्यास असमर्थ."" #, python-format msgid ""Saved extra spec \""%s\""."" msgstr ""सुरक्षित केलेले अतिरिक्त निर्देश \""%s\""."" msgid ""Unable to edit volume type extra spec."" msgstr ""खंड प्रकार अतिरिक्त निर्देश संपादित करण्यास असमर्थ."" msgid ""Create"" msgstr ""तयार करा"" msgid ""Edit"" msgstr ""संपादित करा"" msgid ""Extra Specs"" msgstr ""अतिरिक्त निर्देश"" msgid ""Unable to retrieve volume type details."" msgstr ""खंड प्रकार तपशील मिळविण्यास असमर्थ."" msgid ""Unable to retrieve extra spec list."" msgstr ""अतिरि्क्त निर्देश यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve volume type extra spec details."" msgstr ""खंड प्रकार अतिरिक्त निर्देश तपशील मिळविण्यास असमर्थ."" #, python-format msgid ""Successfully created encryption for volume type: %s"" msgstr ""खंड प्रकारासाठी सांकेतिकरण यशस्वीपणे तयार केले: %s"" msgid ""Unable to create encrypted volume type."" msgstr ""सांकेतिकरण केलेला खंड प्रकार तयार करण्यास असमर्थ."" msgid ""QoS Spec to be associated"" msgstr ""जोडायचे क्यूओएस निर्देश "" msgid ""Choose associated QoS Spec."" msgstr ""जोडलेले क्यूओएस निर्देश निवडा."" msgid """" ""New associated QoS Spec must be different than the current associated QoS "" ""Spec."" msgstr """" ""नवीन जोडलेला क्यूओएस निर्देश सध्याच्या जोडलेल्या क्यूओएस निर्देशापेक्षा वेगळा असला पाहिजे."" msgid ""Successfully updated QoS Spec association."" msgstr ""क्यूओएस निर्देश संबंध यशस्वीपणे सुधारित करण्यात आला."" msgid ""Error updating QoS Spec association."" msgstr ""क्यूओएस निर्देश संबंध सुधारित करण्यात चूक."" msgid ""QoS Spec Consumer"" msgstr ""क्यूओएस निर्देश ग्राहक"" msgid ""Choose consumer for this QoS Spec."" msgstr ""या क्यूओएस निर्देशासाठी ग्राहक निवडा."" msgid """" ""QoS Spec consumer value must be different than the current consumer value."" msgstr ""सध्याच्या ग्राहक मूल्यापेक्षा क्यूओएस निर्देश ग्राहक मूल्य वेगळे असले पाहिजे."" msgid ""Successfully modified QoS Spec consumer."" msgstr ""क्यूओएस निर्देश ग्राहक यशस्वीपणे सुधारित केला."" msgid ""Error editing QoS Spec consumer."" msgstr ""क्यूओएस निर्देश ग्राहक संपादित करताना चूक."" #, python-format msgid ""Created spec \""%s\""."" msgstr ""तयार केलेले निर्देश \""%s\""."" msgid ""Unable to create spec."" msgstr ""निर्देश तयार करण्यास असमर्थ."" #, python-format msgid ""Saved spec \""%s\""."" msgstr ""साठवलेले निर्देश \""%s\""."" msgid ""Unable to edit spec."" msgstr ""निर्देश संपादित करता येत नाहीत."" msgid ""Spec"" msgstr ""निर्देश"" msgid ""Key-Value Pairs"" msgstr ""कळ-मूल्य जोड्या"" msgid ""undefined"" msgstr ""अनिश्चित"" msgid ""Unable to retrieve QoS spec list."" msgstr ""क्यूओएस निर्देश यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve QoS spec details."" msgstr ""क्यूओएस निर्देश तपशील मिळविण्यास असमर्थ."" msgid ""View Extra Specs"" msgstr ""पाहा अतिरिक्त निर्देश"" msgid ""Manage QoS Spec Association"" msgstr ""क्यूओएस निर्देश संबंधांचे व्यवस्थापन करा"" msgid ""Create Encryption"" msgstr ""सांकेतिकरण तयार करा"" msgid ""Unable to determine if volume type encryption is supported."" msgstr ""खंड प्रकार सांकेतिकरणाला सहाय्य आहे का हे निश्चित करण्यास असमर्थ."" msgid ""Associated QoS Spec"" msgstr ""संबंधित क्यूओएस निर्देश"" msgid ""Encryption"" msgstr ""सांकेतिकरण"" msgid ""Manage Specs"" msgstr ""निर्देशांचे व्यवस्थापन करा"" msgid ""Edit Consumer"" msgstr ""ग्राहक संपादित करा"" msgid ""Consumer"" msgstr ""ग्राहक"" msgid ""QoS Specs"" msgstr ""क्यूओएस निर्देश"" msgid ""Create a Volume Type"" msgstr ""खंड प्रकार तयार करा"" msgid ""Unable to retrieve volume type encryption details."" msgstr ""खंड प्रकार सांकेतिकरण तपशील मिळविण्यास असमर्थ."" msgid ""Create Volume Type Encryption"" msgstr ""खंड प्रकार सांकेतिकरण तयार करा"" msgid ""Create an Encrypted Volume Type"" msgstr ""सांकेतिकरण करण्यात आलेला खंड प्रकार तयार करा"" msgid ""Unable to retrieve volume type name."" msgstr ""खंड प्रकार नाव मिळविण्यास असमर्थ."" msgid ""Create a QoS Spec"" msgstr ""एक क्यूओएस निर्देश तयार करा"" msgid ""Edit Consumer of QoS Spec"" msgstr ""क्यूओएस निर्देशांचे ग्राहक संपादित करा"" msgid ""Modify Consumer"" msgstr ""ग्राहकात सुधारणा करा"" msgid ""Unable to retrieve QoS Spec details."" msgstr ""क्यूओएस निर्देश तपशील मिळविण्यास असमर्थ."" msgid ""Associate QoS Spec with Volume Type"" msgstr ""क्यूओएस निर्देश खंड प्रकाराशी जोडा"" msgid ""Associate"" msgstr ""संबंध जोडा"" msgid ""Unable to retrieve QoS Specs."" msgstr ""क्यूओएस निर्देश मिळविण्यास असमर्थ."" msgid ""Unable to retrieve QoS Spec association."" msgstr ""क्यूओएस निर्देश संबंध मिळविण्यास असमर्थ."" msgid ""Bootable"" msgstr ""पुन्हा सुरु करण्यायोग्य"" msgid ""No volume type"" msgstr ""कोणताही खंड प्रकार नाही"" #, python-format msgid ""Successfully created volume type: %s"" msgstr ""यशस्वीपणे खंड प्रकार तयार केला: %s"" msgid ""Unable to create volume type."" msgstr ""खंड प्रकार तयार करण्यास असमर्थ."" msgid ""Attaching"" msgstr ""जोडत आहे"" msgid ""Detaching"" msgstr ""विलग करत आहे"" msgid ""In Use"" msgstr ""वापरामध्ये"" #, python-format msgid ""Successfully updated volume status to \""%s\""."" msgstr ""खंड स्थितीमध्ये \""%s\"" ची यशस्वीपणे सुधारणा केली."" #, python-format msgid ""Unable to update volume status to \""%s\""."" msgstr ""खंड स्थितीमध्ये \""%s\"" ची सुधारणा करण्यास असमर्थ."" #, python-format msgid ""Successfully created QoS Spec: %s"" msgstr ""शस्वीपणे क्यूओएस निर्देश तयार केला: %s"" msgid ""Unable to create QoS Spec."" msgstr ""क्यूओएस निर्देश तयार करण्यास असमर्थ."" msgid ""Unable to retrieve volume details."" msgstr ""खंड तपशील मिळविण्यास असमर्थ."" msgid ""Identity"" msgstr ""ओळख"" msgid ""Domains"" msgstr ""कार्यक्षेत्र"" msgid ""Manage Members"" msgstr ""सदस्यांचे व्यवस्थापन करा"" msgid ""Modify Groups"" msgstr ""गटात सुधारणा करा"" msgid ""Create Domain"" msgstr ""कार्यक्षेत्र तयार करा"" #, python-format msgid ""Domain \""%s\"" must be disabled before it can be deleted."" msgstr ""कार्यक्षेत्र \""%s\"" नष्ट करण्यापूर्वी ते असमर्थ केले पाहिजे."" msgid ""Set Domain Context"" msgstr ""कार्यक्षेत्र संदर्भ निश्चित करा"" #, python-format msgid ""Domain Context updated to Domain %s."" msgstr ""कार्यक्षेत्र संदर्भ सुधारित कार्यक्षेत्रापर्यंत %s."" msgid ""Unable to set Domain Context."" msgstr ""कार्यक्षेत्र संदर्भ निश्चित करण्यास असमर्थ."" msgid ""Clear Domain Context"" msgstr ""कार्यक्षेत्र संदर्भ पुसून टाका"" msgid ""Domain Context cleared."" msgstr ""कार्यक्षेत्र संदर्भ पुसून टाकले."" msgid ""Domain ID"" msgstr ""कार्यक्षेत्र ओळख क्रमांक"" msgid ""Unable to retrieve domain list."" msgstr ""कार्यक्षेत्र यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve domain information."" msgstr ""कार्यक्षेत्र माहिती मिळविण्यास असमर्थ."" msgid ""Insufficient privilege level to view domain information."" msgstr ""कार्यक्षेत्र माहिती पाहण्यासाठी अपुरी विशेषाधिकार पातळी."" msgid ""Unable to retrieve domain details."" msgstr ""कार्यक्षेत्र तपशील मिळविण्यास असमर्थ."" msgid ""Domain Information"" msgstr ""कार्यक्षेत्र माहिती"" msgid """" ""Domains provide separation between users and infrastructure used by "" ""different organizations."" msgstr """" ""कार्यक्षेत्रांमुळे वापरकर्ते व विविध संघटनांद्वारे वापरल्या पायाभूत सुविधांदरम्यान विभाजन करता "" ""येते."" #, python-format msgid ""Could not find default role \""%s\"" in Keystone"" msgstr ""कीस्टोनमध्ये पूर्वनिर्धारित भूमिका सापडली नाही \""%s\"" "" msgid ""Unable to find default role."" msgstr ""पूर्वनिर्धारित भूमिका शोधण्यास असमर्थ."" msgid ""Unable to retrieve user list."" msgstr ""वापरकर्ता यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve role list."" msgstr ""भूमिका यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve user domain role assignments."" msgstr ""वापरकर्ता कार्यक्षेत्र भूमिका निर्धारण मिळविण्यास असमर्थ."" msgid ""Domain Members"" msgstr ""कार्यक्षेत्र सदस्य"" msgid ""All Users"" msgstr ""सर्व वापरकर्ते"" msgid ""No users found."" msgstr ""एकही वापरकर्ता सापडला नाही."" msgid ""No users."" msgstr ""वापरकर्ते नाहीत."" msgid ""Unable to retrieve group list. Please try again later."" msgstr ""गट यादी मिळविण्यास असमर्थ. कृपया नंतर प्रयत्न करा."" msgid ""Domain Groups"" msgstr ""कार्यक्षेत्र गट"" msgid ""All Groups"" msgstr ""सर्व गट"" msgid ""No groups found."" msgstr ""एकही गट सापडला नाही."" msgid ""No groups."" msgstr ""एकही गट नाही."" #, python-format msgid ""Created new domain \""%s\""."" msgstr ""नवीन कार्यक्षेत्र तयार केले \""%s\""."" #, python-format msgid ""Unable to create domain \""%s\""."" msgstr ""कार्यक्षेत्र तयार करण्यास असमर्थ \""%s\""."" msgid """" ""Domains provide separation between users and infrastructure used by "" ""different organizations. Edit the domain details to add or remove groups in "" ""the domain."" msgstr """" ""कार्यक्षेत्रामुळे वापरकर्ते व विविध संघटनांद्वारे वापरल्या जाणा-या पायाभूत सुविधांचे विभाजन "" ""करता येते. कार्यक्षेत्रामध्ये गट समाविष्ट करण्यासाठी किंवा काढून टाकण्यासाठी कार्यक्षेत्र "" ""तपशील संपादित करा."" msgid ""Edit Domain"" msgstr ""कार्यक्षेत्र संपादित करा"" #, python-format msgid ""Modified domain \""%s\""."" msgstr ""सुधारित कार्यक्षेत्र \""%s\""."" #, python-format msgid ""Unable to modify domain \""%s\""."" msgstr ""कार्यक्षेत्र सुधारित करण्यास असमर्थ \""%s\""."" msgid """" ""You cannot revoke your administrative privileges from the domain you are "" ""currently logged into. Please switch to another domain with administrative "" ""privileges or remove the administrative role manually via the CLI."" msgstr """" ""तुम्ही सध्या ज्या कार्यक्षेत्रामध्ये लॉग इन केलेले आहे त्यातील तुमचे प्रशासकीय विशेषाधिकार वापरु "" ""शकत नाही. कृपया प्रशासकीय विशेषाधिकार असलेल्या दुस-या कार्यक्षेत्रात जा किंवा "" ""सीएलआयद्वारे हाताने प्रशासकीय भूमिका काढून टाका."" #, python-format msgid ""Failed to modify %s project members and update domain groups."" msgstr ""प्रकल्प सदस्य सुधारणा करण्यात %s व कार्यक्षेत्र गट सुधारणा करण्यास अपयशी."" #, python-format msgid ""Failed to modify %s domain groups."" msgstr ""कार्यक्षेत्र गट %s सुधारणा करण्यास अपयशी."" #, python-format msgid ""Group \""%s\"" was successfully created."" msgstr ""गट \""%s\"" यशस्वीपणे तयार करण्यात आला."" msgid ""Unable to create group."" msgstr ""गट तयार करण्यास असमर्थ."" msgid ""Group has been updated successfully."" msgstr ""गट यशस्वीपणे सुधारित करण्यात आला."" msgid ""Unable to update the group."" msgstr ""गट सुधारित करण्यास असमर्थ."" msgid ""Groups"" msgstr ""गट"" msgid ""Create Group"" msgstr ""गट तयार करा"" msgid ""Edit Group"" msgstr ""गट संपादित करा"" msgid ""Group ID"" msgstr ""गट ओळख क्रमांक"" msgid ""Add Users"" msgstr ""वापरकर्ते समाविष्ट करा"" msgid ""User Name"" msgstr ""वापरकर्ता नाव"" msgid ""Email"" msgstr ""ईमेल"" msgid ""User ID"" msgstr ""वापरकर्ता ओळखक्रमांक"" msgid ""Group Members"" msgstr ""गट सदस्य"" msgid ""Non-Members"" msgstr ""बिगर-सदस्य"" msgid ""Add Group Assignment"" msgstr ""गट निर्धारण समाविष्ट करा"" msgid """" ""Groups are used to manage access and assign roles to multiple users at once. "" ""After creating the group, edit the group to add users."" msgstr """" ""उपलब्धतेचे व्यवस्थापन करण्यासाठी व एकाचवेळी अनेक वापरकर्त्यांना भूमिका वाटून देण्यासाठी गट "" ""वापरले जातात. गट तयार केल्यानंतर, वापरकर्ते समाविष्ट करण्यासाठी गट संपादित करा."" msgid """" ""Groups are used to manage access and assign roles to multiple users at once. "" ""Edit the group to add users."" msgstr """" ""गट उपलब्धतेचे व्यवस्थापन करण्यासाठी व एकाचवेळी अनेक वापरकर्त्यांना भूमिका वाटून देण्यासाठी "" ""वापरले जातात. वापरकर्ते समाविष्ट करण्यासाठी गट संपादित करा."" msgid ""Add User to Group"" msgstr ""गटात वापरकर्ते समाविष्ट करा"" msgid ""Group Management"" msgstr ""गट व्यवस्थापन"" msgid ""Update Group"" msgstr ""गट सुधारित करा"" msgid ""Unable to retrieve group list."" msgstr ""गट यादी मिळविण्यास असमर्थ."" msgid ""Insufficient privilege level to view group information."" msgstr ""गट माहिती पाहण्यास अपुरी विशेषाधिकार पातळी."" msgid ""Unable to update group."" msgstr ""गट सुधारणा करण्यास असमर्थ."" msgid ""Unable to retrieve group users."" msgstr ""गट वापरकर्ते मिळविण्यास असमर्थ."" msgid ""Unable to retrieve users."" msgstr ""वापरकर्ते मिळविण्यास असमर्थ."" msgid ""Projects"" msgstr ""प्रकल्प"" msgid ""Set as Active Project"" msgstr ""सक्रिय प्रकल्प म्हणून रचना करा"" msgid ""View Usage"" msgstr ""वापर पाहा"" msgid ""Create Project"" msgstr ""प्रकल्प तयार करा"" msgid ""Edit Project"" msgstr ""प्रकल्प संपादित करा"" msgid ""Modify Quotas"" msgstr ""वाटा सुधारित करा"" msgid ""This name is already taken."" msgstr ""हे नाव आधीच घेण्यात आले आहे."" msgid ""Project Usage Overview"" msgstr ""प्रकल्प वापर आढावा"" msgid ""Unable to retrieve project information."" msgstr ""प्रकल्प माहिती मिळविण्यास असमर्थ."" msgid ""Insufficient privilege level to view project information."" msgstr ""प्रकल्प माहिती पाहण्यासाठी अपुरी विशेषाधिकार पातळी."" msgid ""Project Usage"" msgstr ""प्रकल्प वापर"" msgid ""Unable to retrieve default Neutron quota values."" msgstr ""पूर्वनिर्धारित न्यूट्रॉन वाटा मूल्ये मिळविण्यास असमर्थ. "" msgid ""Unable to retrieve project domain."" msgstr ""प्रकल्प कार्यक्षेत्र मिळविण्यास असमर्थ."" msgid ""Unable to retrieve project details."" msgstr ""प्रकल्पाचे तपशील मिळविण्यास असमर्थ."" msgid ""Injected File Content (Bytes)"" msgstr ""समाविष्ट धारिका मजकूर (बाईट्स)"" #, python-format msgid ""%(used)s %(key)s used"" msgstr ""%(used)s %(key)s वापरलेली"" #, python-format msgid ""Quota value(s) cannot be less than the current usage value(s): %s."" msgstr ""वाटा मूल्य(ल्ये) सध्याच्या वापर मूल्यापेक्षा (ल्यां) कमी असू शकत नाहीत: %s."" msgid ""Quota"" msgstr ""वाटा"" msgid ""Set maximum quotas for the project."" msgstr ""प्रकल्पासाठी कमाल वाट्याची रचना करा."" msgid ""Domain Name"" msgstr ""कार्यक्षेत्र नाव"" msgid ""Project Information"" msgstr ""प्रकल्प माहिती"" msgid ""Create a project to organize users."" msgstr ""वापरकर्त्यांना संघटित करण्यासाठी प्रकल्पा तयार करा."" msgid ""Unable to retrieve user list. Please try again later."" msgstr ""वापरकर्ता यादी मिळविण्यास असमर्थ. कृपया नंतर प्रयत्न करा."" msgid ""Project Members"" msgstr ""प्रकल्प सदस्य"" msgid ""Project Groups"" msgstr ""प्रकल्प गट"" #, python-format msgid ""Created new project \""%s\""."" msgstr ""नवीन प्रकल्प तयार केला \""%s\""."" #, python-format msgid ""Unable to create project \""%s\""."" msgstr ""प्रकल्प तयार करण्यास असमर्थ \""%s\""."" msgid "", add project groups"" msgstr "", प्रकल्प गट समाविष्ट करा"" #, python-format msgid """" ""Failed to add %(users_to_add)s project members%(group_msg)s and set project "" ""quotas."" msgstr """" ""समाविष्ट करण्यास अपयशी %(users_to_add)s प्रकल्प सदस्य%(group_msg)s व प्रकल्प वाटा "" ""रचना करा."" #, python-format msgid ""Failed to add %s project groups and update project quotas."" msgstr ""प्रकल्प गट समाविष्ट करण्यास %s व प्रकल्प वाटा सुधारित करण्यास अपयशी."" msgid ""Unable to set project quotas."" msgstr ""प्रकल्प वाटा रचना करण्यास असमर्थ."" msgid ""Edit the project details."" msgstr ""प्रकल्पाच्या तपशीलांचे संपादन करा."" #, python-format msgid ""Modified project \""%s\""."" msgstr ""सुधारित प्रकल्प \""%s\""."" #, python-format msgid ""Unable to modify project \""%s\""."" msgstr ""प्रकल्पात सुधारणा करण्यास असमर्थ \""%s\""."" msgid """" ""You cannot revoke your administrative privileges from the project you are "" ""currently logged into. Please switch to another project with administrative "" ""privileges or remove the administrative role manually via the CLI."" msgstr """" ""तुम्ही सध्या ज्या प्रकल्पामध्ये लॉग इन केलेले आहे त्यातून तुमचे प्रशासकीय विशेषाधिकार वापरु शकत "" ""नाही. कृपया प्रशासकीय विशेषाधिकार असलेल्या दुस-या प्रकल्पात जा किंवा प्रशासकीय भूमिका "" ""सीएलआयद्वारे हाताने काढून टाका."" msgid "", update project groups"" msgstr "", सुधारित प्रकल्प गट"" #, python-format msgid """" ""Failed to modify %(users_to_modify)s project members%(group_msg)s and update "" ""project quotas."" msgstr """" ""सुधारणा करण्यात अपयशी %(users_to_modify)s प्रकल्प सदस्य%(group_msg)s व सुधारित "" ""प्रकल्प वाटे."" #, python-format msgid """" ""Failed to modify %s project members, update project groups and update "" ""project quotas."" msgstr """" ""प्रकल्प सदस्यांमध्ये बदल करण्यात %s अपयशी, प्रकल्प गट सुधारित करा व प्रकल्प वाटे सुधारित "" ""करा."" msgid """" ""Modified project information and members, but unable to modify project "" ""quotas."" msgstr ""सुधारित प्रकल्प माहिती व सदस्य, मात्र प्रकल्प वाट्यात बदल करण्यास असमर्थ."" msgid ""Role Name"" msgstr ""भूमिकेचे नाव"" msgid ""Role created successfully."" msgstr ""भूमिका यशस्वीपणे तयार करण्यात आली."" msgid ""Unable to create role."" msgstr ""भूमिका तयार करण्यास असमर्थ."" msgid ""Role updated successfully."" msgstr ""भूमिका यशस्वीपणे सुधारित करण्यात आली."" msgid ""Unable to update role."" msgstr ""भूमिका सुधारित करण्यास असमर्थ."" msgid ""Roles"" msgstr ""भूमिका"" msgid ""Create Role"" msgstr ""भूमिका तयार करा"" msgid ""Role ID"" msgstr ""भूमिका ओळख क्रमांक"" msgid ""Create a new role."" msgstr ""नवीन भूमिका तयार करा."" msgid ""Edit the role's details."" msgstr ""भूमिकेचे तपशील सुधारित करा."" msgid ""Update Role"" msgstr ""भूमिका सुधारित करा"" msgid ""Unable to retrieve roles list."" msgstr ""भूमिकेची यादी मिळविण्यास असमर्थ."" msgid ""Insufficient privilege level to view role information."" msgstr ""भूमिका माहिती पाहण्यासाठी अपुरी विशेषाधिकार पातळी."" msgid ""Password"" msgstr ""पासवर्ड"" msgid ""Confirm Password"" msgstr ""पासवर्डची खात्री करा"" msgid ""Passwords do not match."" msgstr ""पासवर्ड जुळत नाहीत."" msgid ""No available projects"" msgstr ""कोणतेही प्रकल्प उपलब्ध नाहीत"" msgid ""Primary Project"" msgstr ""प्राथमिक प्रकल्प"" msgid ""Role"" msgstr ""भूमिका"" #, python-format msgid ""User \""%s\"" was successfully created."" msgstr ""वापरकर्ता \""%s\"" यशस्वीपणे तयार करण्यात आला."" msgid ""Unable to add user to primary project."" msgstr ""प्राथमिक प्रकल्पात वापरकर्ता समाविष्ट करण्यास असमर्थ."" #, python-format msgid ""User name \""%s\"" is already used."" msgstr ""वापरकर्ता नाव \""%s\"" आधीपासूनच वापरात आहे."" msgid ""Unable to create user."" msgstr ""वापरकर्ता तयार करण्यास असमर्थ."" msgid ""User has been updated successfully."" msgstr ""वापरकर्ता यशस्वीपणे सुधारित करण्यात आला."" msgid ""Unable to update the user."" msgstr ""वापरकर्ता सुधारित करण्यास असमर्थ."" msgid ""Admin Password"" msgstr ""प्रशासक पासवर्ड"" msgid ""Users"" msgstr ""वापरकर्ते"" msgid ""Create User"" msgstr ""वापरकर्ता तयार करा"" msgid ""Change Password"" msgstr ""पासवर्ड बदला"" msgid ""You cannot disable the user you are currently logged in as."" msgstr ""तुम्ही सध्या ज्या वापरकर्त्याच्या नावाने लॉग इन केलेले आहे तो असमर्थ करु शकत नाही."" msgid """" ""Create a new user and set related properties including the Primary Project "" ""and Role."" msgstr """" ""नवीन वापरकर्ता तयार करा व प्राथमिक प्रकल्प व भूमिकेसह संबंधित वैशिष्ट्य्यांची रचना करा."" msgid ""Update User"" msgstr ""वापरकर्ता सुधारित करा"" msgid ""Unable to retrieve user information."" msgstr ""वापरकर्ता माहिती मिळविण्यास असमर्थ."" msgid ""Insufficient privilege level to view user information."" msgstr ""वापरकर्ता माहिती पाहण्यासाठी अपुरी विशेषाधिकार पातळी."" msgid ""Unable to retrieve user roles."" msgstr ""वापरकर्ता भूमिका मिळविण्यास असमर्थ."" msgid ""Download EC2 Credentials"" msgstr ""ईसी२ ओळखपत्रे डाउनलोड करा"" msgid ""Download OpenStack RC File"" msgstr ""ओपनस्टेक आरसी धारिका डाउनलोड करा"" msgid ""View Credentials"" msgstr ""ओळखपत्रे पाहा"" msgid ""Service Endpoint"" msgstr ""सेवा अंतिमबिंदू"" msgid ""API Endpoints"" msgstr ""एपीआय अंतिमबिंदू"" msgid ""Unable to fetch EC2 credentials."" msgstr ""ईसी२ ओळखपत्रे मिळविण्यास असमर्थ"" #, python-format msgid ""Error writing zipfile: %(exc)s"" msgstr ""झिप धारिका लिहीण्यात चूक: %(exc)s"" #, python-format msgid ""Error Downloading RC File: %s"" msgstr ""आरसी धारिका डाउनलोड करण्यात चूक: %s"" msgid ""User Credentials Details"" msgstr ""वापरकर्ता ओळखपत्रे तपशील"" msgid ""Unable to get openrc credentials"" msgstr ""मुक्तआरसी ओळखपत्रे मिळविण्यास असमर्थ"" msgid ""Unable to get EC2 credentials"" msgstr ""ईसी२ ओळखपत्रे मिळविण्यास असमर्थ"" msgid ""Pool"" msgstr ""गट"" msgid ""You are already using all of your available floating IPs."" msgstr ""तुम्ही आधीच तुम्हाला उपलब्ध सर्व बदलते आयपी वापरत आहात."" #, python-format msgid ""Allocated Floating IP %(ip)s."" msgstr ""वितरित करण्यात आलेले बदलते आयपी %(ip)s."" msgid ""Unable to allocate Floating IP."" msgstr ""बदलता आयपी वितरित करण्यास असमर्थ"" msgid ""Allocate IP To Project"" msgstr ""प्रकल्पाला आयपी वितरित करा"" msgid ""(Quota exceeded)"" msgstr ""(वाटा संपला)"" msgid ""Disassociate"" msgstr ""वेगळे करा"" #, python-format msgid ""Successfully disassociated Floating IP: %s"" msgstr ""बदलते आयपी यशस्वीपणे वेगळा केला: %s"" msgid ""Unable to disassociate floating IP."" msgstr ""बदलता आयपी वेगळा करता येत नाही."" #, python-format msgid ""%(instance_name)s %(fixed_ip)s"" msgstr ""%(instance_name)s %(fixed_ip)s"" #, python-format msgid ""Load Balancer VIP %s"" msgstr ""भार संतुलक व्हर्च्युअल आयपी %s"" msgctxt ""Current status of a Floating IP"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of a Floating IP"" msgid ""Down"" msgstr ""खाली"" msgctxt ""Current status of a Floating IP"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgid ""Mapped Fixed IP Address"" msgstr ""निश्चित आयपी पत्ता शोधला"" msgid ""Allocate Floating IP"" msgstr ""बदलत्या आयपीचे वितरण करा"" msgid ""Allocate IP"" msgstr ""आयपी वितरित करा"" msgid ""Unable to retrieve floating IP pools."" msgstr ""बदलते आयपी गट मिळविण्यास असमर्थ."" msgid ""No floating IP pools available"" msgstr ""कोणताही बदलता आयपी गट उपलब्ध नाही"" msgid ""Instance"" msgstr ""घटक"" msgid ""Port to be associated"" msgstr ""जोडावयाचे पोर्ट"" msgid ""Instance to be associated"" msgstr ""जोडावयाचा घटक"" msgid ""Unable to retrieve floating IP addresses."" msgstr ""बदलते आयपी पत्ते मिळविण्यास असमर्थ."" msgid ""Select an IP address"" msgstr ""एक आयपी पत्ता निवडा"" msgid ""No floating IP addresses allocated"" msgstr ""कोणताही आयपी पत्ता वितरित करण्यात आला नाही"" msgid ""Select a port"" msgstr ""एक पोर्ट निवडा"" msgid ""Select an instance"" msgstr ""एक घटक निवडा"" msgid ""No ports available"" msgstr ""कोणतेही पोर्ट उपलब्ध नाहीत"" msgid ""No instances available"" msgstr ""कोणतेही घटक उपलब्ध नाहीत"" msgid ""Manage Floating IP Associations"" msgstr ""बदलत्या आयपी जोडण्यांचे व्यवस्थापन करा"" #, python-format msgid ""IP address %s associated."" msgstr ""जोडलेला %s आयपी पत्ता."" #, python-format msgid ""Unable to associate IP address %s."" msgstr ""आयपी पत्ता जोडण्यास असमर्थ%s."" msgid ""unknown IP address"" msgstr ""अज्ञात आयपी पत्ता"" msgid """" ""The requested instance port is already associated with another floating IP."" msgstr ""विनंती करण्यात आलेला घटक पोर्ट आधीपासूनच दुस-या बदलत्या आयपीशी जोडलेला आहे."" msgid """" ""Key pair name may only contain letters, numbers, underscores, spaces and "" ""hyphens."" msgstr """" ""कळ जोडी नावात केवळ अक्षरे, संख्या, अधोरेखा, रिक्त जागा व जोड चिन्हे यांचा समावेश असू "" ""शकतो. "" msgid ""Key Pair Name"" msgstr ""कळ जोडी नाव"" msgid ""Public Key"" msgstr ""सार्वजनिक कळ"" #, python-format msgid ""Successfully imported public key: %s"" msgstr ""यशस्वीपणे सार्वजनिक कळ आयात केली: %s"" msgid ""Unable to import key pair."" msgstr ""कळ जोडी आयात करण्यास असमर्थ."" msgid ""Import Key Pair"" msgstr ""कळ जोडी आयात करा"" msgid ""Create Key Pair"" msgstr ""कळ जोडी तयार करा"" msgid ""Fingerprint"" msgstr ""बोटाचा ठसा"" msgid ""Download Key Pair"" msgstr ""कळ जोडी डाउनलोड करा"" #, python-format msgid ""Unable to create key pair: %(exc)s"" msgstr ""कळ जोडी तयार करण्यास असमर्थ: %(exc)s"" msgid ""Access & Security"" msgstr ""उपलब्धता व सुरक्षा"" #, python-format msgid ""Successfully created security group: %s"" msgstr ""यशस्वीपणे सुरक्षा गट तयार केला: %s"" #, python-format msgid ""Successfully updated security group: %s"" msgstr ""यशस्वीपणे सुरक्षा गट सुधारित केला: %s"" msgid ""Rule"" msgstr ""नियम"" msgid ""Direction"" msgstr ""दिशा"" msgid ""IP Protocol"" msgstr ""आयपी प्रोटोकॉल"" msgid ""Enter an integer value between 0 and 255 (or -1 which means wildcard)."" msgstr """" ""० ते २५५ दरम्यानची पूर्णांक संख्या घाला (किंवा -१ज्याचा अर्थ वाईल्डकार्ड असा होतो)."" msgid ""Open Port"" msgstr ""खुले पोर्ट"" msgid ""Port"" msgstr ""पोर्ट"" msgid ""Port Range"" msgstr ""पोर्ट श्रेणी"" msgid ""Enter an integer value between 1 and 65535."" msgstr ""१ ते ६५५३५ दरम्यानची पूर्ण संख्या घाला."" msgid ""From Port"" msgstr ""पोर्टपासून"" msgid ""To Port"" msgstr ""पोर्टपर्यंत"" msgid ""Enter a value for ICMP type in the range (-1: 255)"" msgstr ""श्रेणीमध्ये आयसीएमपी प्रकारासाठी मूल्य घाला (-१: २५५)"" msgid ""Code"" msgstr ""संकेत"" msgid ""Enter a value for ICMP code in the range (-1: 255)"" msgstr ""श्रेणीमध्ये आयसीएमपी संकेतासाठी मूल्य घाला (-१: २५५)"" msgid ""Remote"" msgstr ""दूरस्थ"" msgid ""Security Group"" msgstr ""सुरक्षा गट"" msgid """" ""To specify an allowed IP range, select &quot;CIDR&quot;. To allow access "" ""from all members of another security group select &quot;Security Group&quot;."" msgstr """" ""परवानगी असलेली आयपी श्रेणी स्पष्ट करण्यासाठी, निवडा व क्यूयूओटी;सीआयडीआर व क्यूयूओटी;. "" ""दुस-या सुरक्षा गटातील सर्व सदस्यांसाठीच्या उपलब्धतेला परवानगी देण्यासाठी निवडा व "" ""क्यूयूओटी; सुरक्षा गट व क्यूयूओटी;."" msgid ""Classless Inter-Domain Routing (e.g. 192.168.0.0/24)"" msgstr ""वर्गरहित आंतर-कार्यक्षेत्र मार्गनिश्चिती (उदा. १९२.१६८.०.०/२४)"" msgid ""Ether Type"" msgstr ""इथर प्रकार"" msgid ""IPv4"" msgstr ""आयपीव्ही४"" msgid ""IPv6"" msgstr ""आयपीव्ही६"" msgid ""No security groups available"" msgstr ""कोणतेही सुरक्षा गट उपलब्ध नाहीत"" msgid ""Custom TCP Rule"" msgstr ""स्वपसंत टीसीपी नियम"" msgid ""Custom UDP Rule"" msgstr ""स्वपसंत यूडीपी नियम"" msgid ""Custom ICMP Rule"" msgstr ""स्वपसंत आय़सीएमपी नियम"" msgid ""Other Protocol"" msgstr ""इतर प्रोटोकॉल"" msgid ""Ingress"" msgstr ""इनग्रेस"" msgid ""Egress"" msgstr ""एनग्रेस"" msgid ""The ICMP type is invalid."" msgstr ""आयसीएमपी प्रकार अवैध आहे."" msgid ""The ICMP code is invalid."" msgstr ""आयसीएमपी संकेत अवैध आहे."" msgid ""The ICMP type not in range (-1, 255)"" msgstr ""आयसीएमपी प्रकार श्रेणीमध्ये नाही (-१, २५५)"" msgid ""The ICMP code not in range (-1, 255)"" msgstr ""आयसीएमपी संकेत श्रेणीमध्ये नाही (-१, २५५)"" msgid ""The specified port is invalid."" msgstr ""विनिर्दिष्ट पोर्ट अवैध आहे."" msgid ""The \""from\"" port number is invalid."" msgstr ""\""पासून\"" पोर्ट क्रमांक अवैध आहे."" msgid ""The \""to\"" port number is invalid."" msgstr ""\""पर्यंत\"" पोर्ट क्रमांक अवैध आहे."" msgid """" ""The \""to\"" port number must be greater than or equal to the \""from\"" port "" ""number."" msgstr """" ""\""पर्यंत\"" पोर्ट क्रमांक \""पासून\"" पोर्ट क्रमांकापेक्षा अधिक किंवा समान असला पाहिजे."" msgid ""CIDR must be specified."" msgstr ""सीआयडीआर नमूद केला असला पाहिजे."" #, python-format msgid ""Successfully added rule: %s"" msgstr ""यशस्वीपणे नियम समाविष्ट केला: %s"" msgid ""Unable to add rule to security group."" msgstr ""सुरक्षा गटाच नियम समाविष्ट करण्यास असमर्थ."" msgid ""Create Security Group"" msgstr ""सुरक्षा गट तयार करा करा"" msgid ""Create Security Group (Quota exceeded)"" msgstr ""सुरक्षा गट तयार करा (वाटा संपला)"" msgid ""Edit Security Group"" msgstr ""सुरक्षा गट संपादित करा"" msgid ""Manage Rules"" msgstr ""नियमांचे व्यवस्थापन करा"" msgid ""Add Rule"" msgstr ""नियम समाविष्ट करा"" msgid ""Any"" msgstr ""कोणतेही"" msgid ""Unable to retrieve security group."" msgstr ""सुरक्षा गट मिळविण्यास असमर्थ"" msgid ""Add"" msgstr ""समाविष्ट करा"" msgid ""Unable to retrieve security groups."" msgstr ""सुरक्षा गट मिळविण्यास असमर्थ."" #, python-format msgid ""%s (current)"" msgstr ""%s (सध्याचे)"" msgid ""Unable to retrieve key pair list."" msgstr ""कळ जोडी यादी मिळविण्यास असमर्थ."" msgid ""API Access"" msgstr ""एपीआय उपलब्धता"" msgid ""User Credentials"" msgstr ""वापरकर्ता ओळखपत्रे"" msgid ""Authentication URL"" msgstr ""प्रमाणीकरण यूआरएल"" msgid ""EC2 URL"" msgstr ""ईसी२ यूआरएल"" msgid ""S3 URL"" msgstr ""एस३ यूआरएल"" msgid ""EC2 Access Key"" msgstr ""ईसी२ उपलब्धता कळ"" msgid ""EC2 Secret Key"" msgstr ""ईसी२ गुप्त कळ"" msgid ""Allocate a floating IP from a given floating IP pool."" msgstr ""दिलेल्या बदलत्या आयपी गटातून बदलता आयपी वितरित करा."" msgid ""Project Quotas"" msgstr ""प्रकल्प वाटे"" msgid ""Floating IP"" msgstr ""बदलता आयपी"" msgid ""Access &amp; Security"" msgstr ""उपलब्धता व एएमपी; सुरक्षा"" msgid """" ""Key pairs are ssh credentials which are injected into images when they are "" ""launched. Creating a new key pair registers the public key and downloads the "" ""private key (a .pem file)."" msgstr """" ""कळ जोड्या एसएसएच ओळखपत्रे असतात जेव्हा चित्रे उघडली प्रदर्शित केली जातात तेव्हा त्यामध्ये "" ""त्या समाविष्ट केल्या जातात. नवीन कळ जोडी तयार केल्याने सार्वजनिक कळ नोंदवली जाते व "" ""खाजगी कळ डाउनलोड केली जाते (एक .पीईएम धारिका)."" msgid ""Protect and use the key as you would any normal ssh private key."" msgstr """" ""तुम्ही कोणतीही सामान्य एसएसएच खाजगी कळ करता त्याप्रमाणे कळ सुरक्षित करा व वापरा."" msgid ""Key Pairs are how you login to your instance after it is launched."" msgstr ""तुमचा घटक प्रदर्शित झाल्यानंतर कळ जोडीद्वारे तुम्ही त्यामध्ये लॉग इन करता."" msgid """" ""Choose a key pair name you will recognise and paste your SSH public key into "" ""the space provided."" msgstr """" ""तुम्हाला ओळखू येईल असे कळ जोडी नाव निवडा व दिलेल्या जागेमध्ये एसएसएच सार्वजनिक कळ "" ""चिटकवा."" msgid ""SSH key pairs can be generated with the ssh-keygen command:"" msgstr ""एसएसएच-कीजेन आज्ञेद्वारे एसएसएच कळ जोड्या तयार करता येऊ शकतात:"" msgid """" ""This generates a pair of keys: a key you keep private (cloud.key) and a "" ""public key (cloud.key.pub). Paste the contents of the public key file here."" msgstr """" ""याद्वारे कळींची जोडी तयार होते: एक कळ तुम्ही खाजगी ठेवा (क्लाउड.की) व एक सार्वजनिक कळ "" ""ठेवा (क्लाउड.की.पब). सार्वजनिक कळ धारिकेचे घटक येथे चिटकवा."" msgid """" ""After launching an instance, you login using the private key (the username "" ""might be different depending on the image you launched):"" msgstr """" ""एखादा घटक प्रदर्शित केल्यानंतर, तुम्ही खाजगी कळ वापरुन लॉगइन करा (तुम्ही कोणते चित्र "" ""प्रदर्शित केले आहे त्यानुसार तुमचे वापरकर्ता नाव वेगळे असू शकते):"" #, python-format msgid """" ""The key pair &quot;%(keypair_name)s&quot; should download automatically. If "" ""not use the link below."" msgstr """" ""कळ जोडी &quot;%(keypair_name)s&quot; आपोआप डाउनलोड झाली पाहिजे. झाली नाही तर "" ""खालील दुवा वापरा."" #, python-format msgid ""Download key pair &quot;%(keypair_name)s&quot;"" msgstr ""कळ जोडी डाउनलोड करा &quot;%(keypair_name)s&quot;"" msgid """" ""Rules define which traffic is allowed to instances assigned to the security "" ""group. A security group rule consists of three main parts:"" msgstr """" ""सुरक्षा गटांकडे निर्धारित घटकांकडे कोणती रहदारी जाण्यास परवानगी आहे हे नियमांद्वारे "" ""निश्चित केले जाते. एका सुरक्षा गट नियमांमध्ये तीन मुख्य भागांचा समावेश असतो:"" msgid ""Rule:"" msgstr ""नियम:"" msgid """" ""You can specify the desired rule template or use custom rules, the options "" ""are Custom TCP Rule, Custom UDP Rule, or Custom ICMP Rule."" msgstr """" ""तुम्ही हवा तो नियम साचा स्पष्ट करु शकता किंवा स्वपसंत नियम वापरु शकता, स्वपसंत टीसीपी "" ""नियम, स्वपसंत यूडीपी नियम, किंवा स्वपसंत आयसीएमपी नियम हे पर्याय आहेत."" msgid ""Open Port/Port Range:"" msgstr ""खुले पोर्ट/पोर्ट श्रेणी"" msgid """" ""For TCP and UDP rules you may choose to open either a single port or a range "" ""of ports. Selecting the \""Port Range\"" option will provide you with space to "" ""provide both the starting and ending ports for the range. For ICMP rules you "" ""instead specify an ICMP type and code in the spaces provided."" msgstr """" ""टीसीपी व यूडीपी नियमांसाठी तुम्ही एकतर एक पोर्ट किंवा पोर्टची श्रेणी उघडण्याचा पर्याय "" ""निवडू शकता. \""पोर्ट श्रेणी\"" पर्याय निवडल्याने तुम्हाला त्या श्रेणीसाठी सुरुवातीचा व अंतिम "" ""पोर्ट पुरविण्यासाठी जागा मिळेल. आयसीएमपी नियमासाठी तुम्हाला आय़सीएमपी प्रकार व "" ""दिलेल्या जागेमध्ये संकेत स्पष्ट करावा लागेल."" msgid ""Remote:"" msgstr ""दूरस्थ:"" msgid """" ""You must specify the source of the traffic to be allowed via this rule. You "" ""may do so either in the form of an IP address block (CIDR) or via a source "" ""group (Security Group). Selecting a security group as the source will allow "" ""any other instance in that security group access to any other instance via "" ""this rule."" msgstr """" ""तुम्ही या नियमाद्वारे ज्या रहदारीला परवानगी द्यायची आहे त्याचा स्रोत स्पष्ट करु शकता. "" ""तुम्ही ते एकतर आयपी पत्ता गटाच्या स्वरुपात (सीआयडीआर) किंवा स्रोत गटाद्वारे (सुरक्षा गट) "" ""करु शकता. या नियमाद्वारे एक सुरक्षा गट स्रोत म्हणून निवडल्याने त्या सुरक्षा गटातील इतर "" ""कोणत्याही घटकाला इतर कोणताही घटक उपलब्ध होऊ शकेल."" msgid """" ""Security groups are sets of IP filter rules that are applied to the network "" ""settings for the VM. After the security group is created, you can add rules "" ""to the security group."" msgstr """" ""सुरक्षा गट आयपी गाळणी नियमांचे संच आहेत जे व्हीएमसाठी नेटवर्क मांडणीसाठी वापरले जातात. "" ""सुरक्षा गट तयार केल्यानंतर, तुम्ही सुरक्षा गटात नियम समाविष्ट करु शकता."" msgid """" ""Security groups are sets of IP filter rules that are applied to the network "" ""settings for the VM. Edit the security group to add and change the rules."" msgstr """" ""सुरक्षा गट हे आयपी गाळणी नियमांचे संच आहेत जे व्हीएमसाठी नेटवर्कच्या रचनेसाठी वापरले "" ""जातात. नियम समाविष्ट करण्यासाठी व बदलण्यासाठी सुरक्षा गट संपादित करा."" msgid ""Manage Security Group Rules"" msgstr ""सुरक्षा गट नियमांचे व्यवस्थापन करा"" msgid ""Swift"" msgstr ""जलद"" msgid ""Container"" msgstr ""पात्र"" msgid ""Slash is not an allowed character."" msgstr ""तिरपी रेघ या अक्षराला परवानगी नाही"" msgid ""Private"" msgstr ""खाजगी"" msgid ""Container Name"" msgstr ""पात्राचे नाव"" msgid ""Container Access"" msgstr ""पात्र उपलब्धता"" msgid ""Container created successfully."" msgstr ""पात्र यशस्वीपणे तयार करण्यात आले."" msgid ""Folder created successfully."" msgstr ""धारक यशस्वीपणे तयार करण्यात आले."" msgid ""Unable to create container."" msgstr ""पात्र तयार करण्यास असमर्थ."" msgid ""File"" msgstr ""धारिका"" msgid ""Object Name"" msgstr ""घटक नाव"" msgid """" ""Slashes are allowed, and are treated as pseudo-folders by the Object Store."" msgstr """" ""तिरप्या रेघेस परवानगी नाही, व घटक संग्रहाद्वारे त्यांना आभासी-धारक म्हणून वागवले जाईल."" msgid ""Object was successfully uploaded."" msgstr ""घटक यशस्वीपणे अपलोड करण्यात आला."" msgid ""Unable to upload object."" msgstr ""घटक अपलोड करण्यास असमर्थ."" msgid ""Object was successfully updated."" msgstr ""घटक यशस्वीपणे सुधारित करण्यात आला."" msgid ""Unable to update object."" msgstr ""घटक सुधारित करण्यास असमर्थ."" msgid ""Pseudo-folder Name"" msgstr ""आभासी-धारक नाव"" msgid ""Pseudo-folder was successfully created."" msgstr ""आभासी-धारक यशस्वीपणे तयार करण्यात आला."" msgid ""Unable to create pseudo-folder."" msgstr ""आभासी-धारक तयार करण्यास असमर्थ."" msgid ""Destination container"" msgstr ""लक्ष्य पात्र"" msgctxt ""Swift pseudo folder path"" msgid ""Path"" msgstr ""मार्ग [जलद आभासी धारक मार्ग]"" msgid ""Destination object name"" msgstr ""लक्ष्य घटक नाव"" #, python-format msgid ""Copied \""%(orig)s\"" to \""%(dest)s\"" as \""%(new)s\""."" msgstr ""प्रत तयार केली \""%(orig)s\"" प्रति \""%(dest)s\"" स्वरुपात \""%(new)s\""."" msgid ""Unable to copy object."" msgstr ""घटकाची प्रत तयार करण्यास असमर्थ."" msgid ""Containers"" msgstr ""पात्रे"" msgid ""View Details"" msgstr ""तपशील पाहा"" msgid ""Make Public"" msgstr ""सार्वजनिक करा"" msgid ""Successfully updated container access to public."" msgstr ""पात्र उपलब्धता सार्वजनिक म्हणून यशस्वीपणे सुधारणा."" msgid ""Unable to update container access."" msgstr ""पात्र उपलब्धता सुधारित करण्यास असमर्थ."" msgid ""Make Private"" msgstr ""खाजगी करा"" msgid ""Successfully updated container access to private."" msgstr ""पात्र उपलब्धता खाजगी म्हणून यशस्वीपणे सुधारणा."" msgid ""Unable to delete container."" msgstr ""पात्र नष्ट करण्यास अमसर्थ."" msgid ""Create Container"" msgstr ""पात्र तयार करा"" msgid ""View Container"" msgstr ""पात्र पाहा"" msgid ""Create Pseudo-folder"" msgstr ""आभासी-धारक तयार करा"" msgid ""Upload Object"" msgstr ""घटक अपलोड करा"" msgid ""Container Details"" msgstr ""पात्र तपशील"" msgid ""Copy"" msgstr ""प्रत तयार करा"" msgid ""Download"" msgstr ""डाउनलोड करा"" msgid ""pseudo-folder"" msgstr ""आभासी-धारक"" msgid ""Objects"" msgstr ""घटक"" msgid ""Public URL"" msgstr ""सार्वजनिक यूआरएल"" msgid ""Object Count"" msgstr ""घटक संख्या"" msgid ""Object Count: "" msgstr ""घटक संख्या: "" msgid ""Size: "" msgstr ""आकार: "" msgid ""Access: "" msgstr ""उपलब्धता: "" #, python-format msgid ""Copy Object: %(object_name)s"" msgstr ""घटकाची प्रत तयार करा: %(object_name)s"" msgid """" ""Make a new copy of an existing object to store in this or another container. "" ""You may additionally specify the path within the selected container where "" ""the new copy should be stored."" msgstr """" ""यामध्ये किंवा दुस-या पात्रात साठविण्यासाठी सध्याच्या घटकाची एक नवीन प्रत तयार करा. "" ""तुम्ही निवडलेल्या पात्रामध्ये अतिरिक्त मार्ग स्पष्ट करु शकता जेथे नवीन प्रत साठवली जाईल."" msgid ""Copy Object"" msgstr ""घटकाची प्रत तयार करा"" msgid """" ""A container is a storage compartment for your data and provides a way for "" ""you to organize your data. You can think of a container as a folder in "" ""Windows &reg; or a directory in UNIX &reg;. The primary difference between a "" ""container and these other file system concepts is that containers cannot be "" ""nested. You can, however, create an unlimited number of containers within "" ""your account. Data must be stored in a container so you must have at least "" ""one container defined in your account prior to uploading data."" msgstr """" ""पात्र हा तुमच्या डाटासाठी साठवणुकीचा कप्पा आहे व त्यामुळे तुम्हाला तुमचा डाटा व्यवस्थित "" ""ठेवता येतो. तुम्ही पात्राचा विंडोजच्या एका धारकाप्रमाणे व आरईजी; किंवा युनिक्समधील "" ""मार्गदर्शिकेप्रमाणे विचार करु शकता व आरईजी;. पात्र व या इतर धारिका यंत्रणेच्या संकल्पनेतील "" ""मूलभूत फरक म्हणजे पात्रामध्ये डाटाची रचना स्तरांमध्ये करता येत नाही. मात्र, तुम्ही तुमच्या "" ""खात्यांतर्गत अमर्याद पात्रे तयार करु शकता. डाटा पात्रामध्ये साठवलेला असला पाहिजे म्हणजे "" ""तुम्ही डाटा अपलोड करण्यापूर्वी तुमच्या खात्यामध्ये किमान एक धारक निश्चित केलेला असला "" ""पाहिजे."" msgid """" ""Note: A Public Container will allow anyone with the Public URL to gain "" ""access to your objects in the container."" msgstr """" ""सूचना: सार्वजनिक पात्रामुळे सार्वजनिक यूआरएल असलेल्या कुणालाही पात्रातील तुमचे घटक उपलब्ध "" ""होऊ शकतील."" msgid ""Pseudo-folder:"" msgstr ""आभासी-धारक:"" msgid """" ""Within a container you can group your objects into pseudo-folders, which "" ""behave similarly to folders in your desktop operating system, with the "" ""exception that they are virtual collections defined by a common prefix on "" ""the object's name. A slash (/) character is used as the delimiter for pseudo-"" ""folders in the Object Store."" msgstr """" ""पात्रामध्ये तुम्ही तुमच्या घटकांचे आभासी-धारकांमध्ये वर्गीकरण करु शकता, जे तुमच्या डेस्कटॉप "" ""संचालन यंत्रणेतील धारकांसारखेच कार्य करतात, मात्र यात एक अपवाद असतो तो म्हणजे एका "" ""व्हर्च्युअल संग्रहाचा जो घटकाच्या नावापुढे सामाईक पूर्वप्रत्यय लावून निश्चित केला जातो. घटक "" ""संग्रहकातील आभासी-धारकासाठी परिसीमक म्हणून तिपरी रेघ (/) हे अक्षर वापरले जाते."" msgid ""Object Details"" msgstr ""घटकाचे तपशील"" msgid ""Hash"" msgstr ""हॅश"" msgid ""Content Type"" msgstr ""मजकूर प्रकार"" msgid ""Last Modified"" msgstr ""शेवटचा बदल"" msgid ""Edit Object"" msgstr ""घटक संपादित करा"" msgid ""Object:"" msgstr ""घटक:"" msgid """" ""An object is the basic storage entity that represents a file you store in "" ""the OpenStack Object Storage system. When you upload data to OpenStack "" ""Object Storage, the data is stored as-is (no compression or encryption) and "" ""consists of a location (container), the object's name, and any metadata "" ""consisting of key/value pairs."" msgstr """" ""एक घटक ही मूलभूत साठवणूक तत्व असते ते तुम्ही ओपनस्टेक घटक साठवणूक यंत्रणेमध्ये साठवलेली "" ""धारिका दर्शवते. तुम्ही जेव्हा ओपनस्टेक घटक संग्रहात डाटा अपलोड करता तेव्हा, डाटा आहे तसा "" ""साठवला जातो (तो दाबला जात नाही किंवा सांकेतिकरण केले जात नाही) व त्यामध्ये ठिकाण "" ""(पात्र), घटकाचे नाव, कळ/मूल्य जोड्यांचा समावेश असलेला कोणताही मेटाडाटा असतो."" msgid ""File:"" msgstr ""धारिका:"" msgid ""A new uploaded file will replace the content of the current object"" msgstr ""नवीन अपलोड केलेली धारिका सध्याच्या घटकातील मजकुराची जागा घेईल"" msgid ""Update Object"" msgstr ""घटक सुधारित करा"" #, python-format msgid ""Upload Object To Container: %(container_name)s"" msgstr ""घटक पात्रामध्ये अपलोड करा: %(container_name)s"" msgid ""Unable to retrieve container list."" msgstr ""धारक यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve object list."" msgstr ""घटक यादी मिळविण्यास असमर्थ."" msgid ""Upload Objects"" msgstr ""घटक अपलोड करा"" msgid ""Unable to retrieve object."" msgstr ""घटक मिळविण्यास असमर्थ."" msgid ""Unable to list containers."" msgstr ""पात्रांची यादी तयार करण्यास असमर्थ."" msgid ""Unable to retrieve details."" msgstr ""तपशील मिळविण्यास असमर्थ."" msgid ""Compute"" msgstr ""संगणन करा"" msgid ""Network"" msgstr ""नेटवर्क"" msgid ""Object Store"" msgstr ""घटक संग्रह"" msgid ""Orchestration"" msgstr ""समन्वय"" msgid ""Database"" msgstr ""डाटाबेस"" msgid ""Data Processing"" msgstr ""डाटा प्रक्रिया"" msgid ""Cluster Template Name"" msgstr ""समूह साचा नाव"" msgid ""Template"" msgstr ""साचा"" msgid ""Unable to upload cluster template file"" msgstr ""समूह साचा धारिका अपलोड करण्यास असमर्थ"" msgid ""Cluster Templates"" msgstr ""समूह साचे"" msgid ""Plugin"" msgstr ""प्लगइन"" msgid ""Version"" msgstr ""आवृत्ती"" msgid ""Upload Template"" msgstr ""साचा अपलोड करा"" msgid ""Launch Cluster"" msgstr ""समूह सुरु करा"" msgid ""Copy Template"" msgstr ""साच्याची प्रत तयार करा"" msgid ""Create Template"" msgstr ""साचा तयार करा"" msgid ""Configure Cluster Template"" msgstr ""समूह साच्याची मांडणीकरा"" msgid ""Node Groups"" msgstr ""नोड गट"" msgid ""General Info"" msgstr ""सर्वसाधारण माहिती"" msgid ""Unable to fetch cluster template details."" msgstr ""समूह साचा तपशील मिळविण्यास असमर्थ."" msgid ""Unable to fetch node group details."" msgstr ""नोड गट तपशील मिळविण्यास असमर्थ."" msgid ""This Cluster Template will be created for:"" msgstr ""हा समूह साचा च्यासाठी तयार केला जाईल:"" msgid """" ""The Cluster Template object should specify Node Group Templates that will be "" ""used to build a Cluster.\n"" "" You can add Node Groups using Node Group Templates on a &quot;Node "" ""Groups&quot; tab."" msgstr """" ""या समूह साचा घटकामध्ये नोड गट साचा नमूद केला असला पाहिजे जो समूह तयार करण्यासाठी "" ""वापरला जाईल.\n"" "" तुम्ही व क्यूयूओटी; नोड गट व क्यूयूओटी; टॅबवरन नोट गट साचा वापरुन नोड गट समाविष्ट करु "" ""शकता."" msgid ""You may set <b>cluster</b> scoped configurations on corresponding tabs."" msgstr ""तुम्ही <b>समूह</b> कक्षा मांडणीची सुसंगत टॅबवर रचना करु शकता."" msgid """" ""The Cluster Template object may specify a list of processes in anti-affinity "" ""group.\n"" "" That means these processes may not be launched more than once on a "" ""single host."" msgstr """" ""समूह साचा घटक आकर्षण-प्रतिबंधक गटातील प्रक्रियांची यादी स्पष्ट करु शकतो.\n"" "" याचा अर्थ असा होतो की या प्रक्रिया एका होस्टवर एकापेक्षा अधिका वेळा सुरु करता येऊ "" ""शकत नाहीत."" msgid ""Select a plugin and version for a new Cluster template."" msgstr ""नव्या समूह साच्यासाठी एक प्लगइन व आवृत्ती निवडा."" msgid ""Template Overview"" msgstr ""साचा आढावा"" msgid ""Anti-affinity enabled for"" msgstr ""आकर्षण-प्रतिबंधक च्यासाठी समर्थ केले"" msgid ""no processes"" msgstr ""प्रक्रिया नाहीत"" msgid ""Node Configurations"" msgstr ""नोड मांडणी"" #, python-format msgid ""%(conf_name)s: %(conf_value)s"" msgstr ""%(conf_name)s: %(conf_value)s"" msgid ""No configurations"" msgstr ""मांडण्या नाहीत"" msgid ""Cluster configurations are not specified"" msgstr ""समूह मांडण्या स्पष्ट केलेल्या नाहीत"" #, python-format msgid ""Node Group: %(node_group_name)s"" msgstr ""नोड समूह: %(node_group_name)s"" msgid ""Nodes Count"" msgstr ""नोड संख्या"" msgid ""Flavor"" msgstr ""साचा"" msgid ""Flavor is not specified"" msgstr ""साचा स्पष्ट करण्यात आला नाही"" msgid ""Template not specified"" msgstr ""साचा स्पष्ट करण्यात आला नाही"" msgid ""Auto Security Group"" msgstr ""स्व सुरक्षा गट"" msgid ""Node Processes"" msgstr ""नोड प्रक्रिया"" msgid ""Node processes are not specified"" msgstr ""नोड प्रक्रिया स्पष्ट केलेल्या नाहीत"" msgid ""Node configurations are not specified"" msgstr ""नोड मांडणी स्पष्ट केलेली नाही"" msgid ""Upload"" msgstr ""अपलोड करा"" msgid ""Select a Node Group Template to add:"" msgstr ""समाविष्ट करण्यासाठी नोड गट साचा निवडा:"" msgid ""Add Node Group"" msgstr ""नोड गट समाविष्ट करा"" msgid ""Create Cluster Template"" msgstr ""समूह साचा तयार करा"" msgid ""Cluster Template Details"" msgstr ""समूह साचा तपशील"" msgid ""Unable to fetch cluster template list"" msgstr ""समूह साचा यादी मिळविण्यास असमर्थ"" msgid ""Unable to fetch cluster template."" msgstr ""समूह साचा मिळविण्यास असमर्थ."" #, python-format msgid ""Cluster Template copy %s created"" msgstr ""समूह साचा प्रत %s तयार केली"" msgid ""Unable to fetch template to copy."" msgstr ""प्रत तयार करण्यास साचा मिळविण्यास असमर्थ."" msgid ""Unable to fetch plugin list."" msgstr ""प्लगइन यादी मिळविण्यास असमर्थ."" msgid ""Plugin name"" msgstr ""प्लगइन नाव"" msgid ""Select plugin and hadoop version for cluster template"" msgstr ""समूह साच्यासाठी प्लगइन व हडूप आवृत्ती निवडा "" msgid ""Next"" msgstr ""पुढे"" msgid ""Could not create"" msgstr ""तयार करता येत नाही"" msgid ""Template Name"" msgstr ""साचा नाव"" msgid ""Details"" msgstr ""तपशील"" #, python-format msgid ""Created Cluster Template %s"" msgstr ""समूह साचा तयार केला %s"" msgid ""Cluster template creation failed"" msgstr ""समूह साचा तयार करणे अपयशी"" msgid ""Clusters"" msgstr ""समूह"" msgid ""Scale Cluster"" msgstr ""स्केल समूह"" msgid ""Unable to update row"" msgstr ""ओळ सुधारित करण्यास असमर्थ"" msgid ""Configure Cluster"" msgstr ""समूहाची मांडणी करा"" msgid ""Instances Count"" msgstr ""घटक संख्या"" msgid ""Unable to get node group details."" msgstr ""नोड समूह तपशील मिळविण्यास असमर्थ."" msgid ""Internal IP"" msgstr ""अंतर्गत आयपी"" msgid ""Management IP"" msgstr ""व्यवस्थापन आयपी"" msgid ""Cluster Instances"" msgstr ""समूह उदाहरणे"" msgid ""Unable to fetch instance details."" msgstr ""घटक तपशील मिळविण्यास असमर्थ."" msgid ""This Cluster will be started with:"" msgstr ""हा समूह च्याद्वारे सुरु होईल:"" msgid ""Cluster can be launched using existing Cluster Templates."" msgstr ""सध्याचे समूह साचे वापरुन समूह सुरु करता येईल."" msgid """" ""The Cluster object should specify OpenStack Image to boot instances for "" ""Cluster."" msgstr """" ""समूह घटकाने ओपनस्टेक चित्र नमूद केले पाहिजे ज्यामुळे समूहासाठी घटक पुन्हा सुरु करता येईल."" msgid ""User has to choose a keypair to have access to clusters instances."" msgstr ""वापरकर्त्याने समूह घटक उपलब्ध होण्यासाठी कळजोडी निवडली पाहिजे."" msgid "" Done"" msgstr ""झाले"" msgid ""Select a plugin and version for a new Cluster."" msgstr ""नव्या समूहासाठी प्लगइन व आवृत्ती निवडा."" msgid ""Cluster Overview"" msgstr ""समूह आढावा"" msgid ""Error Details"" msgstr ""चूक तपशील"" msgid ""Base Image"" msgstr ""आधार चित्र"" msgid ""Neutron Management Network"" msgstr ""न्यूट्रॉन व्यवस्थापन नेटवर्क"" msgid ""Keypair"" msgstr ""कळजोडी"" #, python-format msgid ""%(key)s: %(val)s"" msgstr ""%(key)s: %(val)s"" #, python-format msgid ""Name: %(node_group_name)s"" msgstr ""नाव: %(node_group_name)s"" msgid ""Number of Nodes"" msgstr ""नोडची संख्या"" msgid ""Floating IP Pool"" msgstr ""बदलचा आयपी गट"" msgid ""Cluster Details"" msgstr ""समूह तपशील"" msgid ""Unable to fetch cluster list"" msgstr ""समूह यादी मिळविण्यास असमर्थ"" msgid ""Select plugin and hadoop version for cluster"" msgstr ""समूहासाठी प्लगइन व हडूप आवृत्ती निवडा"" msgid ""Cluster Name"" msgstr ""समूह नाव"" msgid ""Cluster Template"" msgstr ""समूह साचा"" msgid ""Which keypair to use for authentication."" msgstr ""प्रमाणीकरणासाठी कोणती कळजोडी निवडायची."" msgid ""Unable to fetch image choices."" msgstr ""चित्र पर्याय मिळविण्यास असमर्थ."" msgid ""No Images Available"" msgstr ""कोणतीही चित्रे उपलब्ध नाहीत"" msgid ""Unable to fetch keypair choices."" msgstr ""कळजोडी पर्याय मिळविण्यास असमर्थ."" msgid ""No keypair"" msgstr ""कळजोडी नाही"" msgid ""No Templates Available"" msgstr ""कोणताही साचा उपलब्ध नाही"" msgid ""Launch"" msgstr ""सुरु करा"" msgid ""Unable to create the cluster"" msgstr ""समूह तयार करण्यास असमर्थ"" msgid ""Scale"" msgstr ""पट्टी"" msgid ""Scaled cluster successfully started."" msgstr ""मोजलेले समूह यशस्वीपणे सुरु झाले."" msgid ""Unable to fetch cluster to scale"" msgstr ""समूह पट्टी आणण्यास असमर्थ"" msgid ""Unable to fetch cluster to scale."" msgstr ""समूह पट्टीकडे आणण्यास असमर्थ."" msgid ""Scale cluster operation failed"" msgstr ""पट्टी समूह संचालन अपयशी"" msgid ""Successfully updated image."" msgstr ""यशस्वीपणे चित्रात सुधारणा केली."" msgid ""Failed to update image."" msgstr ""चित्रात सुधारणा करण्यात अपयशी."" msgid ""Image"" msgstr ""चित्र"" msgid ""Select Image"" msgstr ""चित्र निवडा"" msgid ""No images available."" msgstr ""कोणतीही चित्रे उपलब्ध नाहीत."" #, python-format msgid ""Unable to retrieve images with filter %s."" msgstr ""चाळणीसह चित्रे मिळविण्यास असमर्थ %s."" msgid ""Unable to fetch available images."" msgstr ""उपलब्ध चित्रे मिळविण्यास असमर्थ."" msgid ""Image Registry"" msgstr ""चित्र नोंदणी"" msgid ""Edit Tags"" msgstr ""खूण चिठ्ठ्या संपादित करा"" msgid ""Register Image"" msgstr ""चित्राची नोंदणी करा"" msgid ""Tags"" msgstr ""खूण चिठ्ठ्या"" msgid ""Edit Image Tags"" msgstr ""चित्र खूण चिठ्ठ्या संपादित करा"" msgid ""Done"" msgstr ""झाले"" msgid ""Image Registry tool:"" msgstr ""चित्र नोंदणी साधन:"" msgid """" ""Image Registry is used to provide additional information about images for "" ""Data Processing."" msgstr """" ""डाटा प्रक्रियेसाठी चित्रांविषयी अतिरिक्त माहिती देण्यासाठी चित्र नोंदणी वापरली जाते."" msgid """" ""Specified User Name will be used by Data Processing to apply configs and "" ""manage processes on instances."" msgstr """" ""डाटा प्रक्रियेद्वारे विनिर्दिष्ट वापरकर्ता नाव वापरले जाईल जे मांडणीसाठी व घटकांवरील "" ""प्रक्रियेचे व्यवस्थापन करण्यासाठी वापरले जाईल."" msgid """" ""Tags are used for filtering images suitable for each plugin and each Data "" ""Processing version.\n"" "" To add required tags, select a plugin and a Data Processing version "" ""and click &quot;Add plugin tags&quot; button."" msgstr """" ""प्रत्येक प्लगइन व प्रत्येक डाटा प्रक्रिया आवृत्तीसाठी योग्य चाळणी चित्रांसाठी खूण चिठ्ठ्या "" ""वापरल्या जातात.\n"" "" आवश्यक त्या खूण चिठ्ठ्या समाविष्ट करण्यासाठी, एक प्लगइन व डाटा प्रक्रिया आवृत्ती "" ""निवडा व क्यूयूओटी; प्लगइन समाविष्ट करा व क्यूयूओटी; बटणावर क्लिक करा."" msgid ""You may also add any custom tag."" msgstr ""तुम्हाला इतर कोणत्याही स्वपसंत खूण चिठ्ठ्या समाविष्ट करता येतील. "" msgid ""Unnecessary tags may be removed by clicking a cross near tag's name."" msgstr ""खूणचिठ्ठीच्या नावाजवळील फुलीवर क्लिक करुन अनावश्यक खूण चिठ्ठ्या काढून टाकता येतील."" msgid """" ""Register tags required for the Plugin with specified Data Processing Version"" msgstr ""विशिष्ट डाटा प्रक्रिया आवृत्तीसह प्लगइनसाठी आवश्यक खूणचिठ्ठ्यांची नोंदणी करा"" msgid ""Add plugin tags"" msgstr ""प्लगइन खूणचिठ्ठ्या समाविष्ट करा"" msgid ""Add custom tag"" msgstr ""स्वपसंत खूणचिठ्ठी समाविष्ट करा"" msgid ""Unable to retrieve image list"" msgstr ""चित्र यादी मिळविण्यास असमर्थ"" msgid ""Unable to process plugin tags"" msgstr ""प्लगइन खूण चिठ्ठ्यांवर प्रक्रिया करण्यास असमर्थ"" msgid ""Unable to fetch the image details"" msgstr ""चित्राचे तपशील मिळविण्यास असमर्थ"" msgid ""Plugins"" msgstr ""प्लगइन"" msgid ""Title"" msgstr ""शीर्षक"" msgid ""Supported Versions"" msgstr ""सहाय्य असलेल्या आवृत्त्या"" msgid ""Unable to retrieve plugin."" msgstr ""प्लगइन मिळविण्यास असमर्थ."" msgid ""Data Processing Plugin Overview"" msgstr ""डाटा प्रक्रिया प्लगइन आढावा"" msgid ""Data Processing Plugin Details"" msgstr ""डाटा प्रक्रिया प्लगइन तपशील"" msgid ""Data Processing Plugins"" msgstr ""डाटा प्रक्रिया प्लगइन"" msgid ""Unable to retrieve data processing plugins."" msgstr ""डाटा प्रक्रिया प्लगइन मिळविण्यास असमर्थ."" msgid ""Data Sources"" msgstr ""डाटा स्रोत"" msgid ""Create Data Source"" msgstr ""डाटा स्रोत तयार करा"" msgid ""Unable to retrieve data source details"" msgstr ""डाटा स्रोत मिळविण्यास असमर्थ"" msgid ""Create a Data Source with a specified name."" msgstr ""विनिर्दिष्ट नावासह डाटा स्रोत तयार करा."" msgid ""Select the type of your Data Source."" msgstr ""तुमच्या डाटा स्रोताचा प्रकार निवडा."" msgid ""You may need to enter the username and password for your Data Source."" msgstr ""तुम्हाला कदाचित तुमच्या डाटा स्रोतासाठी वापरकर्ता व पासवर्ड घालावा लागेल."" msgid ""You may also enter an optional description for your Data Source."" msgstr ""तुम्हाला कदाचित तुमच्या डाटा स्रोतासाठी पर्यायी वर्णन घालावे लागेल."" msgid ""Data Source Overview"" msgstr ""डाटा स्रोत आढावा"" msgid ""URL"" msgstr ""यूआरएल"" msgid ""Create time"" msgstr ""वेळ तयार करा"" msgid ""Data Source Details"" msgstr ""डाटा स्रोत तपशील"" msgid ""Unable to fetch data sources."" msgstr ""डाटा स्रोत मिळविण्यास असमर्थ."" msgid ""Data Source Type"" msgstr ""डाटा स्रोत प्रकार"" msgid ""Source username"" msgstr ""स्रोत वापरकर्ता नाव"" msgid ""Source password"" msgstr ""स्रोत पासवर्ड"" msgid ""Data source created"" msgstr ""डाटा स्रोत तयार करण्यात आला"" msgid ""Could not create data source"" msgstr ""डाटा स्रोत तयार करता येत नाही"" msgid ""Storage type"" msgstr ""साठवणूक प्रकार"" msgid ""Internal binary"" msgstr ""अंतर्गत द्विअंकी"" msgid ""Upload File"" msgstr ""धारिका अपलोड करा"" msgid ""Script name"" msgstr ""लिपि नाव"" msgid ""Script text"" msgstr ""लिपि मजकूर"" msgid ""Username"" msgstr ""वापरकर्ता"" msgid ""Failed to get list of internal binaries."" msgstr ""अंतर्गत द्विअंकांची यादी मिळविण्यात अपयशी."" msgid ""Unable to create job binary"" msgstr ""कार्य द्विअंकी तयार करण्यास असमर्थ"" msgid ""Create Job Binary"" msgstr ""कार्य द्विअंकी तयार करा"" msgid ""Unable to upload job binary"" msgstr ""कार्य द्विअंकी अपलोड करण्यास असमर्थ"" msgid ""Failed to fetch internal binary list"" msgstr ""अंतर्गत द्विअंकी यादी मिळविण्यास असमर्थ"" msgid ""Job Binaries"" msgstr ""कार्य द्विअंकी"" msgid ""Download Job Binary"" msgstr ""कार्य द्विअंकी डाउनलोड करा"" msgid ""Url"" msgstr ""यूआरएल"" msgid ""Unable to fetch job binary."" msgstr ""कार्य द्विअंकी मिळिविण्यास असमर्थ."" msgid """" ""<b>Important</b>: The name that you give your job binary will be the name "" ""used in your job execution.\n"" "" If your binary requires a particular name or extension (ie: \"".jar\""), be "" ""sure to include it here."" msgstr """" ""<b>महत्वाचे</b>: तुम्ही तुमच्या कार्य द्विअंकास जे नाव देता ते तुमचे कार्य करताना वापरले "" ""जाईल.\n"" "" तुमच्या द्विअंकासाठी काही विशिष्ट नाव किंवा विस्तार आवश्यक असेल (म्हणजे: \"".जेएआर\""), "" ""तर तो येथे समाविष्ट केल्याची खात्री करुन घ्या."" msgid ""Select the storage type for your job binary."" msgstr ""तुमच्या कार्य द्विअंकासाठी साठवणूक प्रकार निवडा."" msgid ""Data Processing internal database"" msgstr ""डाटा प्रक्रिया अंतर्गत डाटाबेस"" msgid """" ""For Data Processing internal job binaries, you may choose from the following:"" msgstr """" ""डाटा प्रक्रिया अंतर्गत कार्य द्विअंकांसाठी, तुम्हाला खालील पर्यायांमधून निवड करता येईल:"" msgid ""Choose an existing file"" msgstr ""सध्याची धारिका निवडा"" msgid ""Upload a new file"" msgstr ""नवीन धारिका अपलोड करा"" msgid ""Create a script to be uploaded dynamically"" msgstr ""गतीशीलपणे अपलोड करण्यासाठी लिपि तयार करा"" msgid ""For Object Store job binaries, you must:"" msgstr ""घटक साठवणूर कार्य द्विअंकांसाठी, तुम्ही केलेच पाहिजे:"" msgid ""Enter the URL for the file"" msgstr ""धारिकेसाठी यूआरएल घाला"" msgid ""Enter the username and password required to access that file"" msgstr ""धारिका उपलब्ध होण्यासाठी वापरकर्ता नाव व पासवर्ड घाला"" msgid ""You may also enter an optional description for your job binary."" msgstr ""तुम्हाला तुमच्या कार्य द्विअंकांसाठी पर्यायी वर्णनही घालता येईल."" msgid ""Job Binary Overview"" msgstr ""कार्य द्विअंक आढावा"" msgid ""Download job binary"" msgstr ""कार्य द्विअंक डाउनलोड करा"" msgid ""Job Binary Details"" msgstr ""कार्य द्विअंक तपशील"" msgid ""Unable to fetch job binary list."" msgstr ""कार्य द्विअंकी यादी मिळविण्यास असमर्थ."" #, python-format msgid ""Unable to fetch job binary: %(exc)s"" msgstr ""कार्य द्विअंकी मिळविण्यास असमर्थ: %(exc)s"" msgid ""Jobs"" msgstr ""कार्ये"" msgid ""Job"" msgstr ""कार्य"" msgid ""Cluster"" msgstr ""समूह"" msgid ""Relaunch On Existing Cluster"" msgstr ""सध्याचा समूह पुन्हा सुरु करा"" msgid ""Relaunch On New Cluster"" msgstr ""नवीन समूह पुन्हा सुरु करा"" msgid ""Not available"" msgstr ""उपलब्ध नाही"" msgctxt ""Current status of a Job"" msgid ""Failed"" msgstr ""अपयशी"" msgid ""Input Data Source"" msgstr ""टंकलेखन डाटा स्रोत"" msgid ""Output Data Source"" msgstr ""उत्पादन डाटा स्रोत"" msgid ""Last Updated"" msgstr ""शेवटची सुधारणा [शेवटच्या सुधारणेची वेळ]"" msgctxt ""Start time"" msgid ""Started"" msgstr ""सुरुवात [सुरुवात झाल्याची वेळ]"" msgctxt ""End time"" msgid ""Ended"" msgstr ""समाप्त [समाप्तीची वेळ]"" msgid ""Return Code"" msgstr ""परतणे संकेत"" msgid ""Oozie Job ID"" msgstr ""उझी कार्य ओळख क्रमांक"" msgctxt ""Created time"" msgid ""Created"" msgstr ""तयार करण्यात आले"" msgid ""Job Configuration"" msgstr ""कार्य मांडणी"" #, python-format msgid ""%(group)s:"" msgstr ""%(group)s:"" msgid ""Job Details"" msgstr ""कार्य तपशील"" msgid ""Unable to fetch job executions."" msgstr ""कार्य अंमलबजावणी मिळविण्यास असमर्थ."" msgid ""Job Execution Details"" msgstr ""कार्य अंमलबजावणी तपशील"" msgid ""Launch On Existing Cluster"" msgstr ""सध्याच्या समूहात सुरुवात करा"" msgid ""Launch On New Cluster"" msgstr ""नवीन समूहात सुरुवात करा"" msgid ""Select the type of your job:"" msgstr ""तुमच्या कार्याचा प्रकरा निवडा:"" msgid ""Pig"" msgstr ""पिग"" msgid ""Hive"" msgstr ""हाईव"" msgid ""Spark"" msgstr ""स्पार्क"" msgid ""MapReduce"" msgstr ""मॅपरेड्यूस"" msgid ""Java Action"" msgstr ""जावा कृती"" msgid """" ""Choose or create your main binary. Additional libraries can be added from "" ""the \""Libs\"" tab."" msgstr """" ""तुमचा मुख्य द्विअंक निवडा किंवा तयार करा. अतिरिक्त वाचनालये \""लिब\"" टॅबवरुन समाविष्ट "" ""केली जाऊ शकतात."" msgid ""For Spark jobs, only a main is required, \""libs\"" are optional."" msgstr ""स्पार्क कार्यांसाठी, केवळ मुख्य आवश्यक असते, \""वाचनालये\"" ऐच्छिक आहेत."" msgid """" ""For MapReduce or Java Action jobs, \""mains\"" are not applicable. You are "" ""required to add one\n"" "" or more \""libs\"" for these jobs."" msgstr """" ""मॅपरेड्यूस किंवा जावा कृती कार्यांसाठी, \""मुख्य\"" लागू होत नाहीत. तुम्हाला या कार्यासाठी "" ""एक किंवा अधिक\n"" "" \""वाचनालये\"" समाविष्ट करावी लागतील."" msgid ""Mains"" msgstr ""मुख्य"" msgid ""Libs"" msgstr ""वाचनालये"" msgid ""Never"" msgstr ""कधीही नाही"" msgid ""Enter any custom configuration required for your job's execution."" msgstr ""तुमचे कार्य करण्यासाठी आवश्यक असलेली कोणतीही स्वपसंत मांडणी घाला."" msgid ""Choose the Input Data Source (n/a for Java jobs)."" msgstr ""टंकलेखन डाटा स्रोत निवडा (जावा कार्यांसाठी उपलब्ध/नाही)."" msgid ""Choose the Output Data Source (n/a for Java jobs)."" msgstr ""उत्पादन डाटा स्रोत निवडा (जावा कार्यांसाठी उपलब्ध/नाही)."" msgid ""Select property name"" msgstr ""संपत्तीचे नाव निवडा"" msgid ""Remove"" msgstr ""काढून टाका"" msgid ""Configuration"" msgstr ""मांडणी"" msgid ""Parameters"" msgstr ""निर्देशांक"" msgid ""Arguments"" msgstr ""कार्य संदर्भ"" msgid ""Choose"" msgstr ""निवडा"" msgid ""Chosen Libraries"" msgstr ""निवडलेली वाचनालये"" msgid ""Unable to fetch jobs."" msgstr ""कार्ये मिळविण्यास असमर्थ."" msgid ""Choose libraries"" msgstr ""वाचनालये निवडा"" msgid ""-- not selected --"" msgstr ""-- निवडली नाहीत --"" msgid ""Job Type"" msgstr ""कार्य प्रकार"" msgid ""Choose a main binary"" msgstr ""मुख्य द्विअंक निवडा"" msgid ""Choose the binary which should be used in this Job."" msgstr ""या कार्यामध्ये वापरणे आवश्यक असलेला द्विअंक निवडा."" msgid ""Job created"" msgstr ""तयार केलेले कार्य"" msgid ""Input"" msgstr ""टंकलेखन"" msgid ""Output"" msgstr ""उत्पादन"" msgid ""Unable to fetch clusters."" msgstr ""समूह मिळविण्यास असमर्थ."" msgid ""Main Class"" msgstr ""मुख्य वर्ग"" msgid ""Java Opts"" msgstr ""जावा पर्याय"" msgid ""Mapper"" msgstr ""मॅपर"" msgid ""Reducer"" msgstr ""क्षपणक"" msgid ""Configure"" msgstr ""मांडणी करा"" msgid ""Persist cluster after job exit"" msgstr ""कार्यातून बाहेर पडल्यानंतर समूह कायम ठेवा"" msgid ""Job launched"" msgstr ""कार्य सुरु केले"" msgid ""Could not launch job"" msgstr ""कार्य सुरु करु शकत नाही"" msgid ""Job configs"" msgstr ""कार्य मांडणी"" msgid ""Job args"" msgstr ""कार्य एआरजीएस"" msgid ""Job params"" msgstr ""कार्य निर्देशांक"" msgid ""Job Execution ID"" msgstr ""कार्य अंमलबजावणी ओळख क्रमांक"" msgid ""Unable to create new cluster for job."" msgstr ""कार्यासाठी नवीन समूह तयार करण्यास असमर्थ."" msgid ""Unable to launch job."" msgstr ""कार्य सुरु करण्यास असमर्थ."" msgid ""Node Group Templates"" msgstr ""नोड समूह साचे"" msgid ""Configure Template"" msgstr ""साच्याची मांडणी करा"" msgid ""Unable to fetch node group template."" msgstr ""नोड समूह साचे मिळविण्यास असमर्थ."" msgid ""Unable to fetch flavor for template."" msgstr ""साच्यासाठी नमुना (फ्लेवर) मिळविण्यास असमर्थ. "" msgid ""Unable to fetch floating ip pools."" msgstr ""बदलते आयपी गट मिळविण्यास असमर्थ."" msgid ""Service Configurations"" msgstr ""सेवा मांडण्या"" msgid ""This Node Group Template will be created for:"" msgstr ""हा नोड गट साचा च्यासाठी तयार केला जाईल:"" msgid """" ""Data Processing provides different storage location options. You may choose "" ""Ephemeral Drive or a Cinder Volume to be attached to instances."" msgstr """" ""डाटा प्रक्रियेमध्ये विविध साठवणूक ठिकाणाचे पर्याय दिले जातात. तुम्ही तात्पुरता ड्राईव्ह "" ""निवडू शकता किंवा घटकास जोडायचा सिंडर खंड निवडू शकता."" msgid ""HDFS placement"" msgstr ""एचडीएफएस पदनियोजन"" msgid ""Cinder volumes"" msgstr ""सिंडर खंड"" msgid ""Volumes per node"" msgstr ""प्रति नोड खंड"" msgid ""Volumes size"" msgstr ""खंड आकार"" msgid ""Ephemeral drive"" msgstr ""तात्पुरता ड्राईव्ह"" msgid ""Show full configuration"" msgstr ""संपूर्ण मांडणी दाखवा"" msgid ""Hide full configuration"" msgstr ""संपूर्ण मांडणी लपवा"" #, python-format msgid ""%(conf_name)s: %(conf_val)s"" msgstr ""%(conf_name)s: %(conf_val)s"" msgid ""Create Node Group Template"" msgstr ""नोड गट साचा तयार करा"" msgid ""Nodegroup Template Details"" msgstr ""नोडगट साचा तपशील"" msgid ""Unable to fetch node group template list."" msgstr ""नोड गट साचा यादी मिळविण्यास असमर्थ."" msgid ""Node Group Template Details"" msgstr ""नोड गट साचा तपशील"" msgid ""Unable to fetch template object."" msgstr ""साचा घटक मिळविण्यास असमर्थ."" #, python-format msgid ""Node Group Template copy %s created"" msgstr ""नोड गट साचा प्रत %s तयार केली"" msgid ""Unable to fetch plugin details."" msgstr ""प्लगइन तपशील मिळविण्यास असमर्थ."" msgid ""OpenStack Flavor"" msgstr ""ओपनस्टेक साचा"" msgid ""Launch instances in this availability zone."" msgstr ""या उपलब्धता विभागामध्ये घटक सुरु करा."" msgid ""Storage location"" msgstr ""साठवणूक ठिकाण"" msgid ""Choose a storage location"" msgstr ""साठवणूक ठिकाण निवडा"" msgid ""Volumes size (GB)"" msgstr ""खंड आकार (जीबी)"" msgid ""Unable to generate process choices."" msgstr ""प्रक्रियेचे पर्याय तयार करण्यास असमर्थ."" msgid ""Processes"" msgstr ""प्रक्रिया"" msgid ""Processes to be launched in node group"" msgstr ""या नोड गटामध्ये सुरु करायच्या प्रक्रिया"" msgid ""No availability zone specified"" msgstr ""कोणताही उपलब्धता विभाग स्पष्टपणे सांगितला नाही"" msgid ""Configure Node Group Template"" msgstr ""नोड गट साचा मांडणी करा"" msgid ""Create security group for this Node Group."" msgstr ""या नोड गटासाठी सुरक्षा गट तयार करा."" msgid ""Launch instances in these security groups."" msgstr ""या सुरक्षा गटांमध्ये घटक सुरु करा."" #, python-format msgid ""Created Node Group Template %s"" msgstr ""नोड गट साचा तयार केला%s"" msgid ""Select plugin and hadoop version"" msgstr ""प्लगइन व हडूप आवृत्ती निवडा"" msgid ""Use anti-affinity groups for: "" msgstr ""च्यासाठी आकर्षण-प्रतिबंध गट वापरा: "" msgid ""Use anti-affinity groups for processes"" msgstr ""प्रक्रियांसाठी आकर्षण-प्रतिबंधक गट वापरा"" msgid ""Unable to populate anti-affinity processes."" msgstr ""आकर्षण-प्रतिबंधक प्रक्रियांचा प्रसार करण्यास असमर्थ."" msgid ""Streaming MapReduce"" msgstr ""परिगमन मॅपरेड्यूस"" msgid ""Unable to retrieve networks."" msgstr ""नेटवर्क मिळविण्यास असमर्थ."" msgid ""Node group cluster"" msgstr ""नोड गट समूह"" msgid ""Count"" msgstr ""संख्या"" msgid ""Plugin Name"" msgstr ""प्लगइन नाव"" msgctxt ""Current status of a Database Backup"" msgid ""Building"" msgstr ""पुनर्बांधणी"" msgctxt ""Current status of a Database Backup"" msgid ""Failed"" msgstr ""अपयशी"" msgid ""Create Backup"" msgstr ""राखीव साठा तयार करा"" msgid ""Restore Backup"" msgstr ""राखीव साठा पूर्ववत करा"" msgid ""Download Backup"" msgstr ""राखीव साठा डाउनलोड करा"" msgid ""Datastore"" msgstr ""डाटासाठवणूक"" msgid ""Datastore Version"" msgstr ""डाटासाठवणूक आवृत्ती"" msgid ""Incremental"" msgstr ""वाढीव"" msgid ""Specify the details for the database backup."" msgstr ""डाटाबेस पाठपुराव्यासाठी तपशील स्पष्ट करा."" msgid """" ""You can perform an incremental backup by specifying a parent backup. "" ""<strong>However,</strong> not all databases support incremental backups in "" ""which case this operation will result in an error."" msgstr """" ""तुम्ही एक पालक पाठपुरावा स्पष्ट करुन वाढीव राखीव साठा तयार करु शकता. <strong>मात्र,</"" ""strong> सर्व डाटाबेस वाढीव राखीव साठ्यांना मदत करत नाहीत अशा परिस्थितीत या कृतीमुळे "" ""चूक होईल."" msgid ""Backup Database"" msgstr ""राखीव साठा डाटाबेस"" msgid ""Backup Details"" msgstr ""राखीव साठ्याचे तपशील"" msgid ""Backup Overview"" msgstr ""राखीव साठा आढावा"" msgid ""Backup File Location"" msgstr ""राखीव साठा धारिका स्थान"" msgid ""Initial Volume Size"" msgstr ""सुरुवातीचा खंड आकार"" msgid ""Backup Duration"" msgstr ""राखीव साठा कालावधी"" msgid ""Incremental Backup"" msgstr ""वाढीव राखीव साठा"" msgid ""Parent Backup"" msgstr ""पालक राखीव साठा"" msgid ""Database Info"" msgstr ""डाटाबेस माहिती"" msgid ""Database Backups"" msgstr ""डाटाबेस राखीवसाठे"" msgid ""Not Found"" msgstr ""सापडले नाही"" msgid ""Error getting database backup list."" msgstr ""डाटाबेस राखीव साठा यादी मिळविण्यात चूक"" #, python-format msgid ""Unable to retrieve details for backup: %s"" msgstr ""राखीव साठ्यासाठी तपशील मिळविण्यास असमर्थ: %s"" #, python-format msgid ""Unable to retrieve details for parent backup: %s"" msgstr ""मूळ राखीव साठ्यासाठी तपशील मिळविण्यास असमर्थ: %s"" msgid ""Database Instance"" msgstr ""डाटाबेस घटक"" msgid ""Optional Backup Description"" msgstr ""ऐच्छिक राखीव साठा वर्णन"" msgid ""Optional parent backup"" msgstr ""ऐच्छिक पालक राखीव साठा"" msgid ""Unable to list database instances to backup."" msgstr ""राखीव साठ्यामध्ये डाटाबेस घटकांची यादी करण्यास असमर्थ."" msgid ""Unable to list database backups for parent."" msgstr ""पालकासाठी डाटाबेस राखीव साठ्याची यादी करण्यास असमर्थ."" msgid ""Select parent backup"" msgstr ""पालक राखीव साठी निवडा"" msgid ""No backups available"" msgstr ""कोणतेही राखीव साठे उपलब्ध नाहीत"" msgid ""Backup"" msgstr ""राखीव साठा"" #, python-format msgid ""Scheduled backup \""%(name)s\""."" msgstr ""नियोजित राखीव साठा \""%(name)s\""."" #, python-format msgid ""Unable to launch %(count)s named \""%(name)s\""."" msgstr ""सुरुवात करण्यास असमर्थ %(count)s नावाचे \""%(name)s\""."" msgid ""instance"" msgstr ""घटक"" msgid ""Error creating database backup."" msgstr ""डाटाबेस राखीव साठा तयार करण्यात चूक."" msgid ""Current Size (GB)"" msgstr ""सध्याचा आकार (जीबी)"" msgid ""New Size (GB)"" msgstr ""नवीन आकार (जीबी)"" msgid ""New size for volume must be greater than current size."" msgstr ""खंडासाठी नवीन आकार सध्याच्या आकारापेक्षा मोठा असला पाहिजे."" #, python-format msgid ""Resizing volume \""%s\"""" msgstr ""खंडाच्या आकारात फेरबदल करणे \""%s\"""" #, python-format msgid ""Unable to resize volume. %s"" msgstr ""खंडाच्या आकारात फेरबदल करण्यास असमर्थ. %s"" msgid ""Old Flavor"" msgstr ""जुना साचा"" msgid ""New Flavor"" msgstr ""नवीन साचा"" msgid ""No flavors available"" msgstr ""कोणतेही साचे उपलब्ध नाहीत"" msgid ""Error deleting database user."" msgstr ""डाटाबेस वापरकर्ता नष्ट करण्यात चूक"" msgid ""Error deleting database on instance."" msgstr ""घटकावरील डाटाबेस नष्ट करण्यास असमर्थ."" msgid ""Launch Instance"" msgstr ""घटक सुरु करा"" msgid ""Resize Volume"" msgstr ""खंडाचा आकार बदला"" msgid ""Resize Instance"" msgstr ""घटकाचा आकार बदला"" msgid ""Not Assigned"" msgstr ""दिलेला नाही"" #, python-format msgid ""%(name)s | %(RAM)s RAM"" msgstr ""%(name)s | %(RAM)s रॅम"" msgctxt ""Current status of a Database Instance"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of a Database Instance"" msgid ""Blocked"" msgstr ""प्रतिबंधित"" msgctxt ""Current status of a Database Instance"" msgid ""Build"" msgstr ""बांधणी"" msgctxt ""Current status of a Database Instance"" msgid ""Failed"" msgstr ""अपयशी"" msgctxt ""Current status of a Database Instance"" msgid ""Reboot"" msgstr ""पुन्हा सुरु करा"" msgctxt ""Current status of a Database Instance"" msgid ""Resize"" msgstr ""आकार बदला"" msgctxt ""Current status of a Database Instance"" msgid ""Backup"" msgstr ""राखीव साठा"" msgctxt ""Current status of a Database Instance"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgid ""Volume Size"" msgstr ""खंडाचा आकार"" msgid ""Allowed Host"" msgstr ""वितरित होस्ट"" msgid ""Databases"" msgstr ""डाटाबेस"" msgid ""Database Name"" msgstr ""डाटाबेस नाव"" msgid ""Backup File"" msgstr ""राखीव साठा धारिका"" msgid ""Unable to get user data."" msgstr ""वापरकर्ता डाटा मिळविण्यास असमर्थ."" msgid ""Unable to get databases data."" msgstr ""डाटाबेस डाटा मिळविण्यास असमर्थ."" msgid ""Unable to get database backup data."" msgstr ""डाटाबेस राखीव साठा डाटा मिळविण्यास असमर्थ."" msgid ""Instance Overview"" msgstr ""घटक आढावा"" msgid ""Connection Info"" msgstr ""जोडणी माहिती"" msgid ""Database Port"" msgstr ""डाटाबेस पोर्ट"" msgid ""Connection Examples"" msgstr ""जोडणी उदाहरणे"" msgid ""USERNAME"" msgstr ""वापरकर्ता नाव"" msgid ""PASSWORD"" msgstr ""पासवर्ड"" msgid ""DATABASE"" msgstr ""डाटाबेस"" msgid ""Specify the details for launching an instance."" msgstr ""घटक सुरु करण्यासाठी तपशील स्पष्ट करा."" msgid """" ""<strong>Please note:</strong> The value specified in the Volume Size field "" ""should be greater than 0, however, some configurations do not support "" ""specifying volume size. If specifying the volume size results in an error "" ""stating volume support is not enabled, enter 0."" msgstr """" ""<strong>कृपया नोंद घ्या:</strong> खंड आकार क्षेत्रात नमूद केलेले मूल्य ० पेक्षा जास्त असले "" ""पाहिजे, मात्र, काही मांडण्या खंड आकार स्पष्ट करण्यास मदत करत नाहीत. खंडाचा आकार स्पष्ट "" ""केल्याने चूक दिसून आली तर खंड सहाय्य समर्थ करण्यात आलेले नाही, ० घाला."" msgid ""Initial Databases"" msgstr ""प्राथमिक डाटाबेस"" msgid ""Optionally provide a comma separated list of databases to create:"" msgstr ""स्वल्पविरामाने स्वतंत्र केलेली डाटाबेसची यादी तयार करण्यासाठी देण्याचा पर्याय आहे:"" msgid ""Initial Admin User"" msgstr ""प्रारंभिक प्रशासकीय वापरकर्ता"" msgid """" ""Create an optional initial user.\n"" "" This user will have access to all databases you create."" msgstr """" ""ऐच्छिक प्रारंभिक वापरकर्ता तयार करा.\n"" "" या वापरकर्त्याला तुम्ही तयार केलेले सर्व डाटाबेस उपलब्ध होतील."" msgid ""Username (required)"" msgstr ""वापरकर्ता नाव (आवश्यक)"" msgid ""Password (required)"" msgstr ""पासवर्ड (आवश्यक)"" msgid ""Allowed Host (optional)"" msgstr ""परवानगी देण्यात आलेला होस्ट (ऐच्छिक)"" msgid """" ""Allow the user to connect from this host\n"" "" only. If not provided this user will be allowed to connect from "" ""anywhere.\n"" "" "" msgstr """" ""वापरकर्त्याला या केवळ होस्टवरुन जोडण्याची परवानगी द्या\n"" "" . ती दिली नाही तर वापरकर्त्याला कुठूनही जोडण्याची परवानगी दिली जाईल.\n"" "" "" msgid """" ""\n"" "" Move networks from 'Available Networks' to 'Selected Networks' by\n"" "" clicking the button, or dragging and dropping. You can change the\n"" "" NIC order by dragging and dropping as well.\n"" "" "" msgstr """" ""\n"" "" बटण क्लिक करुन, किंवा खेचून व सोडून नेटवर्क 'उपलब्ध नेटवर्क' वरुन 'निवडलेल्या नेटवर्कवर' "" ""हलवा \n"" "" . तसेच तुम्ही एनआयसी क्रम खेचून व सोडून\n"" "" बदलू शकता.\n"" "" "" msgid ""Selected networks"" msgstr ""निवडलेली नेटवर्क"" msgid ""Available networks"" msgstr ""उपलब्ध नेटवर्क"" msgid ""Resize Database Volume"" msgstr ""डाटाबेस खंडाचा आकार बदला"" msgid ""Specify the new volume size for the database instance."" msgstr ""डाटाबेस घटकासाठी नवीन खंडाचा आकार स्पष्ट करा."" msgid """" ""<strong>Please note:</strong> The new value must be greater than the "" ""existing volume size."" msgstr """" ""<strong>कृपया नोंद घ्या:</strong> नवीन मूल्य सध्याच्या खंड मूल्यापेक्षा अधिक असले पाहिजे."" msgid ""Instance Details"" msgstr ""घटक तपशील"" msgid ""Unable to retrieve database size information."" msgstr ""डाटाबेस आकार माहिती मिळविण्यास असमर्थ."" msgid ""Unable to retrieve database instances."" msgstr ""डाटाबेस घटक मिळविण्यास असमर्थ."" msgid ""Launch Database"" msgstr ""डाटाबेस सुरु करा"" #, python-format msgid ""Unable to retrieve details for database instance: %s"" msgstr ""डाटाबेस घटकासाठी तपशील मिळविण्यास असमर्थ: %s"" msgid ""Unable to retrieve flavors."" msgstr ""साचे मिळविण्यास असमर्थ."" msgid ""Size of image to launch."" msgstr ""प्रदर्शित करायच्या चित्राचा आकार."" msgid ""Size of the volume in GB."" msgstr ""खंडाचा आकार जीबीमध्ये."" msgid ""Type and version of datastore."" msgstr ""डाटासाठवणुकीचा प्रकार व आवृत्ती."" msgid ""You must select a datastore type and version."" msgstr ""तुम्ही डाटासाठवणूक प्रकार व आवृत्ती निवडली पाहिजे."" msgid ""Unable to obtain flavors."" msgstr ""साचे मिळविण्यास असमर्थ."" msgid ""Select datastore type and version"" msgstr ""डाटासाठवणूक प्रकार व आवृत्ती निवडा"" msgid ""At least one network must be specified."" msgstr ""किमान एक नेटवर्क स्पष्ट केले पाहिजे."" msgid ""Launch instance with these networks"" msgstr ""या नेटवर्कवर घटक सुरु करा"" msgid ""Networking"" msgstr ""नेटवर्किंग"" msgid ""Select networks for your instance."" msgstr ""तुमच्या घटकासाठी नेटवर्क निवडा."" msgid ""Comma separated list of databases to create"" msgstr ""डाटाबेसची स्वल्पविरामाने स्वतंत्र केलेली यादी तयार करा"" msgid ""Initial admin user to add"" msgstr ""प्रारंभिक प्रशासकीय वापरकर्ता समाविष्ट करा"" msgid ""Host or IP that the user is allowed to connect through."" msgstr ""वापरकर्त्याला ज्या होस्ट किंवा आयपीशी जोडण्याची परवानगी आहे."" msgid ""Initialize Databases"" msgstr ""डाटाबेस सुरु करा"" msgid ""You must specify a password if you create a user."" msgstr ""तुम्ही एक वापरकर्ता तयार केला तर एक पासवर्ड नमूद केला पाहिजे."" msgid ""You must specify at least one database if you create a user."" msgstr ""तुम्ही एक वापरकर्ता तयार केला तर तुम्ही किमान एक डाटाबेस नमूद केलाच पाहिजे."" msgid ""Backup Name"" msgstr ""राखीव साठा नाव"" msgid ""Select a backup to restore"" msgstr ""पुनर्स्थापित करण्यासाठी एक राखीव साठा निवडा"" msgid ""Select backup"" msgstr ""राखीव साठा निवडा"" msgid ""Unable to find backup!"" msgstr ""राखीव साठा शोधण्यास असमर्थ!"" #, python-format msgid ""Launched %(count)s named \""%(name)s\""."" msgstr ""सुरुवात केली %(count)s नावाचे \""%(name)s\""."" msgid ""Protocol"" msgstr ""प्रोटोकॉल"" msgid ""TCP"" msgstr ""टीसीपी"" msgid ""UDP"" msgstr ""यूडीपी"" msgid ""ICMP"" msgstr ""आयसीएमपी"" msgid ""ANY"" msgstr ""कोणताही"" msgid ""Protocol for the firewall rule"" msgstr ""फायरवॉल नियमासाठी प्रोटोकॉल"" msgid ""Action"" msgstr ""कृती"" msgid ""ALLOW"" msgstr ""परवानगी द्या"" msgid ""DENY"" msgstr ""नकार द्या"" msgid ""Action for the firewall rule"" msgstr ""फायरवॉल नियमासाठी कृती"" msgid ""Source IP Address/Subnet"" msgstr ""स्रोत आयपी पत्ता/उपनेट"" msgid ""Source IP address or subnet"" msgstr ""स्रोत आयपी पत्ता किंवा उपनेट"" msgid ""Destination IP Address/Subnet"" msgstr ""लक्ष्य आयपी पत्ता/उपनेट"" msgid ""Destination IP address or subnet"" msgstr ""लक्ष्य आयपी पत्ता किंवा उपनेट"" msgid ""Source Port/Port Range"" msgstr ""स्रोत पोर्ट/पोर्ट श्रेणी"" msgid ""Source port (integer in [1, 65535] or range in a:b)"" msgstr ""स्रोत पोर्ट (पूर्णांक [१, ६५५३५] दरम्यान किंवा श्रेणी ए:बी मध्ये)"" msgid ""Destination Port/Port Range"" msgstr ""लक्ष्य पोर्ट/पोर्ट श्रेणी"" msgid ""Destination port (integer in [1, 65535] or range in a:b)"" msgstr ""लक्ष्य पोर्ट (पूर्णांक [१, ६५५३५] दरम्यान किंवा श्रेणी ए:बी मध्ये)"" #, python-format msgid ""Rule %s was successfully updated."" msgstr ""नियमात %s यशस्वीपणे सुधारणा करण्यात आली."" #, python-format msgid ""Failed to update rule %(name)s: %(reason)s"" msgstr ""नियमात सुधारणा करण्यात अपयशी %(name)s: %(reason)s"" msgid ""Audited"" msgstr ""लेखा परीक्षण झालेले"" #, python-format msgid ""Policy %s was successfully updated."" msgstr ""धोरण %s यशस्वीपणे सुधारित करण्यात आले."" #, python-format msgid ""Failed to update policy %(name)s: %(reason)s"" msgstr ""धोरणात सुधारणा करण्यात अपयशी %(name)s: %(reason)s"" msgid ""Policy"" msgstr ""धोरण"" msgid ""Unable to retrieve policy list."" msgstr ""धोरण यादी मिळविण्यास असमर्थ."" #, python-format msgid ""Firewall %s was successfully updated."" msgstr ""फायरवॉलमध्ये %s यशस्वीपणे सुधारणा करण्यात आली."" #, python-format msgid ""Failed to update firewall %(name)s: %(reason)s"" msgstr ""फायरवॉल सुधारित करण्यात अपयशी %(name)s: %(reason)s"" msgid ""Insert Rule"" msgstr ""नियम समाविष्ट करा"" msgid ""Before"" msgstr ""आधी"" msgid ""After"" msgstr ""नंतर"" #, python-format msgid ""Failed to retrieve available rules: %s"" msgstr ""उपलब्ध नियम मिळविण्यास अपयशी: %s"" #, python-format msgid ""Rule %(rule)s was successfully inserted to policy %(policy)s."" msgstr ""नियम %(rule)s धोरणामध्ये यशस्वीपणे समाविष्ट करण्यात आला %(policy)s."" #, python-format msgid ""Failed to insert rule to policy %(name)s: %(reason)s"" msgstr ""धोरणात नियम समाविष्ट करण्यास अपयशी %(name)s: %(reason)s"" msgid ""Remove Rule"" msgstr ""नियम काढून टाका"" #, python-format msgid ""Failed to retrieve current rules in policy %(name)s: %(reason)s"" msgstr ""धोरणातील सध्याचे नियम मिळविण्यात अपयशी %(name)s: %(reason)s"" #, python-format msgid ""Rule %(rule)s was successfully removed from policy %(policy)s."" msgstr ""नियम %(rule)s धोरणामधून यशस्वीपणे काढून टाकण्यात आला %(policy)s."" #, python-format msgid ""Failed to remove rule from policy %(name)s: %(reason)s"" msgstr ""धोरणातून नियम काढून टाकण्यात अपयशी %(name)s: %(reason)s"" msgid ""Firewalls"" msgstr ""फायरवॉल"" msgid ""Add Policy"" msgstr ""धोरण समाविष्ट करा"" msgid ""Create Firewall"" msgstr ""फायरवॉल तयार करा"" msgid ""Edit Rule"" msgstr ""नियम संपादित करा"" msgid ""Edit Policy"" msgstr ""धोरण संपादित करा"" msgid ""Edit Firewall"" msgstr ""फायरवॉल संपादित करा"" msgctxt ""Action Name of a Firewall Rule"" msgid ""ALLOW"" msgstr ""परवानगी द्या"" msgctxt ""Action Name of a Firewall Rule"" msgid ""DENY"" msgstr ""नकार द्या"" msgid ""Source IP"" msgstr ""स्रोत आयपी"" msgid ""Source Port"" msgstr ""स्रोत पोर्ट"" msgid ""Destination IP"" msgstr ""लक्ष्य आयपी"" msgid ""Destination Port"" msgstr ""लक्ष्य पोर्ट"" msgid ""In Policy"" msgstr ""प्रवेश धोरण"" msgid ""Rules"" msgstr ""नियम"" msgid ""Policies"" msgstr ""धोरणे"" msgctxt ""Current status of a Firewall"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of a Firewall"" msgid ""Down"" msgstr ""खाली"" msgctxt ""Current status of a Firewall"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of a Firewall"" msgid ""Created"" msgstr ""तयार करण्यात आले"" msgid ""Firewall Rules"" msgstr ""फायरवॉल नियम"" msgid ""Unable to retrieve rules list."" msgstr ""नियम यादी मिळविण्यास असमर्थ."" msgid ""Firewall Policies"" msgstr ""फायरवॉल धोरणे"" msgid ""Unable to retrieve policies list."" msgstr ""धोरणांची यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve firewall list."" msgstr ""फायरवॉल यादी मिळविण्यास असमर्थ."" msgid ""Firewall Rule Details"" msgstr ""फायरवॉल यादी तपशील"" msgid ""Unable to retrieve rule details."" msgstr ""नियमांचे तपशील मिळविण्यास असमर्थ."" msgid ""Firewall Policy Details"" msgstr ""फायरवॉल धोरणांचे तपशील"" msgid ""Unable to retrieve policy details."" msgstr ""धोरणांचे तपशील मिळविण्यास असमर्थ."" msgid ""Firewall Details"" msgstr ""फायरवॉल तपशील"" msgid ""Unable to retrieve firewall details."" msgstr ""फायरवॉल तपशील मिळविण्यास असमर्थ."" msgid ""Policy ID"" msgstr ""पॉलिसी ओळखक्रमांक"" msgid ""Admin State Up"" msgstr ""प्रशासक स्थिती वर"" msgid ""Choose the rule you want to remove."" msgstr ""तुम्हाला जो नियम काढून टाकायचा आहे तो निवडा."" msgid ""Source IP Address"" msgstr ""स्रोत आयपी पत्ता"" msgid ""Destination IP Address"" msgstr ""लक्ष्य आयपी पत्ता"" msgid ""Used in Policy"" msgstr ""धोरणामध्ये वापरलेला"" msgid ""Position in Policy"" msgstr ""धोरणामध्ये स्थान"" msgid """" ""Choose rule(s) from Available Rules to Selected Rule by push button or drag "" ""and drop,\n"" ""you may change their order by drag and drop as well. "" msgstr """" ""उपलब्ध नियम ते निवडलेल्या नियमांमधून पुश बटण वापरुन किंवा खेचून व सोडून नियम (अनेक नियम) "" ""निवडा,\n"" ""तुम्हाला खेचून व सोडून त्यांचा क्रमही कदाचित बदलता येईल. "" msgid ""Selected Rules"" msgstr ""निवडलेले नियम"" msgid ""Available Rules"" msgstr ""उपलब्ध नियम"" msgid ""You may update firewall details here."" msgstr ""तुम्हाला इथे फायरवॉलचे तपशील सुधारित करु शकता."" msgid """" ""You may update policy details here. Use 'Insert Rule' or 'Remove Rule' links "" ""instead to insert or remove a rule"" msgstr """" ""तुम्ही येथे पॉलिसीचे तपशील सुधारित करु शकता. नियम समाविष्ट करण्यासाठी किंवा काढून "" ""टाकण्यासाठी 'नियम समाविष्ट करा' किंवा 'नियम काढून टाका' दुवे वापरा"" msgid ""You may update rule details here."" msgstr ""तुम्ही इथे नियमाचे तपशील सुधारित करु शकता."" msgid ""Add New Firewall"" msgstr ""नवीन फायवॉल समाविष्ट करा"" msgid ""Add New Policy"" msgstr ""नवीन धोरण समाविष्ट करा"" msgid ""Add New Rule"" msgstr ""नवीन नियम समाविष्ट करा"" msgid ""Insert Rule to Policy"" msgstr ""धोरणामध्ये नियम समाविष्ट करा"" msgid ""Remove Rule from Policy"" msgstr ""धोरणातून नियम काढून टाका"" #, python-format msgid ""Deleted rule %s"" msgstr ""नष्ट केलेला नियम %s"" #, python-format msgid ""Unable to delete rule. %s"" msgstr ""नियम नष्ट करण्यास असमर्थ. %s"" #, python-format msgid ""Deleted policy %s"" msgstr ""नष्ट केलेले धोरण %s"" #, python-format msgid ""Unable to delete policy. %s"" msgstr ""धोरण नष्ट करण्यास असमर्थ. %s"" #, python-format msgid ""Deleted firewall %s"" msgstr ""नष्ट केलेली फायरवॉल %s"" #, python-format msgid ""Unable to delete firewall. %s"" msgstr ""फायरवॉल नष्ट करण्यास असमर्थ. %s"" msgid ""Save Changes"" msgstr ""बदल सुरक्षित करा"" msgid ""AddRule"" msgstr ""नियमसमाविष्ट करा"" msgid """" ""Create a firewall rule.\n"" ""\n"" ""Protocol and action must be specified. Other fields are optional."" msgstr """" ""फायरवॉल नियम तयार करा.\n"" ""\n"" ""प्रोटोकॉल व कृती नमूद केली पाहिजे. इतर क्षेत्रे ऐच्छिक आहेत."" #, python-format msgid ""Added Rule \""%s\""."" msgstr ""समाविष्ट नियम \""%s\""."" #, python-format msgid ""Unable to add Rule \""%s\""."" msgstr ""नियम समाविष्ट करण्यास असमर्थ \""%s\""."" msgid ""Create a policy with selected rules."" msgstr ""निवडक नियमांसह धोरण तयार करा."" msgid ""Select rules for your policy."" msgstr ""तुमच्या धोरणासाठी नियम निवडा."" #, python-format msgid ""Unable to retrieve rules (%(error)s)."" msgstr ""नियम मिळविण्यास असमर्थ (%(error)s)."" msgid ""AddPolicy"" msgstr ""धोरण समाविष्ट करा"" msgid """" ""Create a firewall policy with an ordered list of firewall rules.\n"" ""\n"" ""A name must be given. Firewall rules are added in the order placed under the "" ""Rules tab."" msgstr """" ""फायरवॉल नियमांच्या क्रमवार यादीने फायरवॉल धोरण तयार करा.\n"" ""\n"" ""एक नाव दिले पाहिजे. नियम टॅबअंतर्गत दिलेल्या क्रमाने फायरवॉल नियम समाविष्ट केले जातात."" #, python-format msgid ""Added Policy \""%s\""."" msgstr ""समाविष्ट धोरण \""%s\""."" #, python-format msgid ""Unable to add Policy \""%s\""."" msgstr ""धोरण समाविष्ट करण्यास असमर्थ \""%s\""."" msgid ""Select a Policy"" msgstr ""धोरण निवडा"" #, python-format msgid ""Unable to retrieve policy list (%(error)s)."" msgstr ""धोरण यादी मिळविण्यास असमर्थ (%(error)s)."" msgid ""AddFirewall"" msgstr ""फायरवॉलसमाविष्टकरा"" msgid """" ""Create a firewall based on a policy.\n"" ""\n"" ""A policy must be selected. Other fields are optional."" msgstr """" ""धोरणावर आधारित फायरवॉल तयार करा.\n"" ""\n"" ""एक धोरण निवडणे आवश्यक आहे. इतर क्षेत्रे ऐच्छिक आहेत."" msgid ""Add Firewall"" msgstr ""फायरवॉल समाविष्ट करा"" #, python-format msgid ""Added Firewall \""%s\""."" msgstr ""समाविष्ट फायरवॉल \""%s\""."" #, python-format msgid ""Unable to add Firewall \""%s\""."" msgstr ""फायरवॉल समाविष्ट करण्यास असमर्थ \""%s\""."" msgid ""Image Source"" msgstr ""चित्र स्रोत"" msgid ""Image Location"" msgstr ""चित्र ठिकाण"" msgid ""Image File"" msgstr ""चित्र धारिका"" msgid ""An external (HTTP) URL to load the image from."" msgstr ""च्यामधून चित्र उघडण्यासाठी एक बाह्य (एचटीटीपी) यूआरएल."" msgid ""A local image to upload."" msgstr ""अपलोड करण्यासाठी एक स्थानिक चित्र."" msgid ""Format"" msgstr ""स्वरुप"" msgid ""Architecture"" msgstr ""वास्तुरचनाशास्त्र"" msgid ""Minimum Disk (GB)"" msgstr ""किमान डिस्क (जीबी)"" msgid """" ""The minimum disk size required to boot the image. If unspecified, this value "" ""defaults to 0 (no minimum)."" msgstr """" ""चित्र पुन्हा उघडण्यासाठी आवश्यक डिस्कचा किमान आकार. स्पष्ट केलेला नसेल, तर हे मूल्य "" ""पूर्वनिर्धारितपणे ० होते (किमान नाही)."" msgid ""Minimum RAM (MB)"" msgstr ""किमान रॅम (एमबी)"" msgid """" ""The minimum memory size required to boot the image. If unspecified, this "" ""value defaults to 0 (no minimum)."" msgstr """" ""हे चित्र पुन्हा उघडण्यासाठी आवश्यक मेमरी आकार. स्पष्ट केले नसेल, तर हे मूल्य पूर्वनिर्धारितपणे "" ""० होते (किमान नाही)."" msgid ""A image or external image location must be specified."" msgstr ""एक चित्र किंवा बाह्य चित्र ठिकाण नमूद केले असले पाहिजे."" msgid ""Can not specify both image and external image location."" msgstr ""चित्र व बाह्य चित्र ठिकाण नमूद करु शकत नाही."" #, python-format msgid ""Your image %s has been queued for creation."" msgstr ""तुमचे चित्र %s तयार करण्यासाठी रांगेत ठेवण्यात आले आहे."" msgid ""Kernel ID"" msgstr ""कर्नल ओळख क्रमांक"" msgid ""Ramdisk ID"" msgstr ""रॅमडिस्क ओळख क्रमांक"" #, python-format msgid ""Unable to update image \""%s\""."" msgstr ""चित्र सुधारित करण्यास असमर्थ \""%s\""."" msgid ""Image was successfully updated."" msgstr ""चित्र यशस्वीपणे सुधारित करण्यात आले."" msgid ""Create Image"" msgstr ""चित्र तयार करा"" msgid ""Create Volume"" msgstr ""खंड तयार करा"" msgid ""Shared with Me"" msgstr ""माझ्यासोबत वाटून घेतले"" msgctxt ""Image format for display in table"" msgid ""Raw"" msgstr ""कच्चा"" msgctxt ""Current status of an Image"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of an Image"" msgid ""Deleted"" msgstr ""नष्ट करण्यात आले"" msgctxt ""Type of an image"" msgid ""Image"" msgstr ""चित्र"" msgctxt ""Type of an image"" msgid ""Snapshot"" msgstr ""क्षणचित्र"" msgid ""Unable to retrieve image."" msgstr ""चित्र मिळविण्यास असमर्थ."" msgid ""Unable to retrieve image details."" msgstr ""चित्राचे तपशील मिळविण्यास असमर्थ."" msgid ""Snapshot Name"" msgstr ""क्षणचित्राचे नाव"" #, python-format msgid ""Snapshot \""%(name)s\"" created for instance \""%(inst)s\"""" msgstr ""क्षणचित्र \""%(name)s\"" घटकासाठी तयार करण्यात आले \""%(inst)s\"""" msgid ""Unable to create snapshot."" msgstr ""क्षणचित्र तयार करण्यास असमर्थ."" msgid ""Create Snapshot"" msgstr ""क्षणचित्र तयार करा"" msgid ""Create a Snapshot"" msgstr ""क्षणचित्र तयार करा"" msgid ""Unable to retrieve instance."" msgstr ""घटक मिळविण्यास असमर्थ."" msgid """" ""Images can be provided via an HTTP URL or be uploaded from your local file "" ""system. Compressed image binaries are supported (.zip and .tar.gz.)"" msgstr """" ""चित्रे एचटीटीपी यूआरएलद्वारे दिली जाऊ शकतात किंवा तुमच्या स्थानिक धारिका यंत्रणेवरुन "" ""अपलोड केली जाऊ शकतात. संपीडित चित्र द्विअंकांना सहाय्य आहे (.झिप व .टीएआर.जीझेड.)"" msgid """" ""If you select an image via an HTTP URL, the Image Location field MUST be a "" ""valid and direct URL to the image binary; it must also be accessible to the "" ""Image Service. URLs that redirect or serve error pages will result in "" ""unusable images."" msgstr """" ""तुम्ही एखाद्या एचटीटीपी यूआरएलद्वारे एखादे चित्र निवडले, तर चित्र ठिकाण क्षेत्र वैध असले "" ""पाहिजे व चित्र द्विंअंकास थेट यूआरएल असली पाहिजे; त्याद्वारे चित्र सेवा उपलब्धही झाली "" ""पाहिजे. जी यूआरएल पुनर्निदेशित करते किंवा सर्वर चूक दाखवते त्यामुळे न वापरण्यासारखी चित्रे "" ""दिसू लागतात."" msgid ""Image Overview"" msgstr ""चित्र आढावा"" msgid ""Owner"" msgstr ""मालक"" msgid ""Checksum"" msgstr ""चेकसम"" msgid ""Container Format"" msgstr ""पात्र स्वरुप"" msgid ""Disk Format"" msgstr ""डिस्क स्वरुप"" msgid ""Min Disk"" msgstr ""किमान डिस्क"" msgid ""Min RAM"" msgstr ""किमान रॅम"" msgid ""Custom Properties"" msgstr ""स्वपसंत गुणधर्म"" msgid ""Image Details"" msgstr ""चित्र तपशील"" msgid ""Unable to retrieve public images."" msgstr ""सार्वजनिक चित्रे मिळविण्यास असमर्थ."" msgid ""Unable to retrieve images for the current project."" msgstr ""सध्याच्या प्रकल्पासाठी चित्रे मिळविण्यास असमर्थ."" msgid ""No images available"" msgstr ""कोणतेही चित्र उपलब्ध नाही"" msgid ""Unable to retrieve images."" msgstr ""चित्रे मिळविण्यास असमर्थ."" msgctxt ""Action log of an instance"" msgid ""Create"" msgstr ""तयार करा"" msgctxt ""Action log of an instance"" msgid ""Rebuild"" msgstr ""पुनर्बांधणी"" msgctxt ""Action log of an instance"" msgid ""Resize"" msgstr ""आकार बदला"" msgctxt ""Action log of an instance"" msgid ""Reboot"" msgstr ""पुन्हा सुरु करा"" msgctxt ""Action log of an instance"" msgid ""Start"" msgstr ""सुरु"" msgid ""Request ID"" msgstr ""ओळख क्रमांकाची विनंती करा"" msgid ""Start Time"" msgstr ""सुरु होण्याची वेळ"" msgid ""Message"" msgstr ""संदेश"" msgid ""Instance Action List"" msgstr ""घटक कृती यादी"" #, python-format msgid ""Console type \""%s\"" not supported."" msgstr ""घटक प्रकारांना \""%s\"" सहाय्य नाही."" msgid ""No available console found."" msgstr ""कोणताही उपलब्ध घटक सापडला नाही."" msgid ""Rebuild Password"" msgstr ""पासवर्ड पुन्हा तयार करा"" msgid ""Confirm Rebuild Password"" msgstr ""पुन्हा तयार केलेल्या पासवर्डची खात्री करा"" msgid ""Disk Partition"" msgstr ""डिस्क विभाजन"" msgid ""Automatic"" msgstr ""स्वयंचलित"" msgid ""Manual"" msgstr ""मानवी"" msgid ""Unable to retrieve extensions information."" msgstr ""विस्तार माहिती मिळविण्यास असमर्थ."" #, python-format msgid ""Rebuilding instance %s."" msgstr ""घटकांची पुनर्बांधणी करत आहे %s."" msgid ""Unable to rebuild instance."" msgstr ""घटकांची पुनर्बांधणी करण्यास असमर्थ."" msgid ""The Key Pair name that was associated with the instance"" msgstr ""घटकाशी संबंधित कळ जोडीचे नाव"" msgid ""The instance password encrypted with your public key."" msgstr ""तुमच्या सार्वजनिक कळीसोबत सांकेतिकरण करण्यात आलेला घटक पासवर्ड."" msgid ""Encrypted Password"" msgstr ""सांकेतिकरण करण्यात आलेला पासवर्ड"" msgid ""Instance Password is not set or is not yet available"" msgstr ""घटक पासवर्डची रचना केलेली नाही किंवा अजून उपलब्ध नाही"" msgid ""Private Key File"" msgstr ""खाजगी कळ धारिका"" msgid ""OR Copy/Paste your Private Key"" msgstr ""किंवा तुमच्या खाजगी कळीची प्रत तयार करा/चिटकवा"" msgid ""Unable to retrieve instance password."" msgstr ""घटक पासवर्ड मिळविण्यास असमर्थ."" msgid ""Edit Instance"" msgstr ""घटक संपादित करा"" msgid ""Edit Security Groups"" msgstr ""सुरक्षा गट संपादित करा"" msgid ""Console"" msgstr ""कन्सोल"" msgid ""View Log"" msgstr ""नोंद पाहा"" msgid ""Confirm Resize/Migrate"" msgstr ""आकार बदलण्याची/स्थलांतराची पुष्टी करा"" msgid ""Revert Resize/Migrate"" msgstr ""बदललेला आकार/स्थलांतर पूर्ववत करा [घटकाची सद्यस्थिती]"" msgid ""Rebuild Instance"" msgstr ""घटकाची पुनर्बांधणी करा"" msgid ""Retrieve Password"" msgstr ""पासवर्ड परत मिळवा"" msgid ""Associate Floating IP"" msgstr ""बदलता आयपी जोडा"" #, python-format msgid ""Successfully associated floating IP: %s"" msgstr ""यशस्वीपणे बदलता आयपी जोडला: %s"" msgid ""Unable to associate floating IP."" msgstr ""बदलता आयपी जोडण्यास असमर्थ."" msgid ""Disassociate Floating IP"" msgstr ""बदलता आयपी विलग करा"" #, python-format msgid ""Successfully disassociated floating IP: %s"" msgstr ""बदलता आयपी यशस्वीपणे विलग केला: %s"" msgid ""No floating IPs to disassociate."" msgstr ""कोणताही बदलता आयपी विलग केला नाही."" #, python-format msgid ""Please try again later [Error: %s]."" msgstr ""कृपया नंतर पुन्हा प्रयत्न करा [चूक: %s]."" msgid """" ""There is not enough capacity for this flavor in the selected availability "" ""zone. Try again later or select a different availability zone."" msgstr """" ""निवडलेल्या उपलब्धता विभागात या साच्यासाठी पुरेशी क्षमता नाही. नंतर पुन्हा प्रयत्न करा "" ""किंवा वेगळा उपलब्धता विभाग निवडा."" #, python-format msgid ""Unable to retrieve flavor information for instance \""%s\""."" msgstr ""घटकासाठी साचा माहिती मिळविण्यास असमर्थ \""%s\""."" #, python-format msgid ""%s GB"" msgstr ""%s जीबी"" msgctxt ""Current status of an Instance"" msgid ""Deleted"" msgstr ""नष्ट करण्यात आले"" msgctxt ""Current status of an Instance"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of an Instance"" msgid ""Shutoff"" msgstr ""बंद [घटकाची सद्यस्थिती]"" msgctxt ""Current status of an Instance"" msgid ""Suspended"" msgstr ""निलंबित"" msgctxt ""Current status of an Instance"" msgid ""Paused"" msgstr ""थांबवलेले"" msgctxt ""Current status of an Instance"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of an Instance"" msgid ""Resize/Migrate"" msgstr ""आकार बदला/स्थलांतर करा [घटकाची सद्यस्थिती]"" msgctxt ""Current status of an Instance"" msgid ""Confirm or Revert Resize/Migrate"" msgstr ""बदललेल्या आकाराची/स्थलांतराची खात्री करा किंवा पूर्ववत करा"" msgctxt ""Current status of an Instance"" msgid ""Revert Resize/Migrate"" msgstr ""बदललेला आकार/स्थलांतर पूर्ववत करा [घटकाची सद्यस्थिती]"" msgctxt ""Current status of an Instance"" msgid ""Reboot"" msgstr ""पुन्हा सुरु करा"" msgctxt ""Current status of an Instance"" msgid ""Hard Reboot"" msgstr ""हार्ड पुन्हा सुरु "" msgctxt ""Current status of an Instance"" msgid ""Password"" msgstr ""पासवर्ड"" msgctxt ""Current status of an Instance"" msgid ""Rebuild"" msgstr ""पुनर्बांधणी"" msgctxt ""Current status of an Instance"" msgid ""Migrating"" msgstr ""स्थलांतर करत आहे"" msgctxt ""Current status of an Instance"" msgid ""Build"" msgstr ""बांधणी"" msgctxt ""Current status of an Instance"" msgid ""Rescue"" msgstr ""सुटका"" msgctxt ""Current status of an Instance"" msgid ""Soft Deleted"" msgstr ""सॉफ्ट नष्ट करण्यात आलेला"" msgctxt ""Current status of an Instance"" msgid ""Shelved"" msgstr ""साठवून ठेवला"" msgctxt ""Current status of an Instance"" msgid ""Shelved Offloaded"" msgstr ""साठवून ठेवलेला काढून घेतला"" msgctxt ""Task status of an Instance"" msgid ""None"" msgstr ""एकही नाही"" msgctxt ""Task status of an Instance"" msgid ""Scheduling"" msgstr ""नियोजन"" msgctxt ""Task status of an Instance"" msgid ""Block Device Mapping"" msgstr ""साधनाचा शोध प्रतिबंधित करा"" msgctxt ""Task status of an Instance"" msgid ""Networking"" msgstr ""नेटवर्किंग"" msgctxt ""Task status of an Instance"" msgid ""Spawning"" msgstr ""स्पॉनिंग"" msgctxt ""Task status of an Instance"" msgid ""Snapshotting"" msgstr ""क्षणचित्र तयार करणे"" msgctxt ""Task status of an Instance"" msgid ""Image Snapshot Pending"" msgstr ""चित्र क्षणचित्र प्रलंबित"" msgctxt ""Task status of an Instance"" msgid ""Image Pending Upload"" msgstr ""चित्र अपलोड प्रलंबित"" msgctxt ""Task status of an Instance"" msgid ""Image Uploading"" msgstr ""चित्र अपलोडिंग"" msgctxt ""Task status of an Instance"" msgid ""Image Backup"" msgstr ""चित्र राखीव साठा"" msgctxt ""Task status of an Instance"" msgid ""Updating Password"" msgstr ""पासवर्ड सुधारित करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Preparing Resize or Migrate"" msgstr ""आकार बदलण्यासाठी किंवा स्थलांतरासाठी तयारी करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Resizing or Migrating"" msgstr ""आकार बदलत आहे किंवा स्थलांतर करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Resized or Migrated"" msgstr ""आकार बदलला किंवा स्थलांतर केले"" msgctxt ""Task status of an Instance"" msgid ""Finishing Resize or Migrate"" msgstr ""आकार बदलणे किंवा स्थलांतर करणे संपवत आहे"" msgctxt ""Task status of an Instance"" msgid ""Reverting Resize or Migrate"" msgstr ""बदललेला आकार किंवा स्थलांतर पूर्ववत करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Confirming Resize or Migrate"" msgstr ""बदललेला आकार किंवा स्थलांतराची खात्री करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Rebooting"" msgstr ""पुन्हा सुरु करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Rebooting Hard"" msgstr ""हार्ड पुन्हा सुरु करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Pausing"" msgstr ""थांबवत आहे"" msgctxt ""Task status of an Instance"" msgid ""Resuming"" msgstr ""पुन्हा सुरु करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Suspending"" msgstr ""निलंबित करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Powering Off"" msgstr ""वीज पुरवठा बंद"" msgctxt ""Task status of an Instance"" msgid ""Powering On"" msgstr ""वीज पुरवठा सुरु"" msgctxt ""Task status of an Instance"" msgid ""Rescuing"" msgstr ""सुटका करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Unrescuing"" msgstr ""सुटका करत नाही"" msgctxt ""Task status of an Instance"" msgid ""Rebuilding"" msgstr ""पुनर्बांधणी करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Rebuild Block Device Mapping"" msgstr ""गट साधन शोध पुनर्बांधणी करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Rebuild Spawning"" msgstr ""स्पॉनिंग पुनर्बांधणी करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Migrating"" msgstr ""स्थलांतर करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Deleting"" msgstr ""नष्ट करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Soft Deleting"" msgstr ""सॉफ्ट नष्ट करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Restoring"" msgstr ""पुनर्स्थापित करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Shelving"" msgstr ""साठवून ठेवत आहे"" msgctxt ""Task status of an Instance"" msgid ""Shelving Image Pending Upload"" msgstr ""चित्र साठवून ठेवत आहे अपलोड प्रलंबित"" msgctxt ""Task status of an Instance"" msgid ""Shelving Image Uploading"" msgstr ""साठवलेले चित्र अपलोड करत आहे"" msgctxt ""Task status of an Instance"" msgid ""Shelving Offloading"" msgstr ""उतरवलेले साठवून ठेवत आहे"" msgctxt ""Task status of an Instance"" msgid ""Unshelving"" msgstr ""साठवणूक रद्द करत आहे"" msgctxt ""Power state of an Instance"" msgid ""No State"" msgstr ""काहीही स्थिती नाही"" msgctxt ""Power state of an Instance"" msgid ""Running"" msgstr ""सुरु आहे"" msgctxt ""Power state of an Instance"" msgid ""Blocked"" msgstr ""प्रतिबंधित"" msgctxt ""Power state of an Instance"" msgid ""Paused"" msgstr ""थांबवलेले"" msgctxt ""Power state of an Instance"" msgid ""Shut Down"" msgstr ""बंद"" msgctxt ""Power state of an Instance"" msgid ""Shut Off"" msgstr ""बंद"" msgctxt ""Power state of an Instance"" msgid ""Crashed"" msgstr ""अचानक बंद पडले"" msgctxt ""Power state of an Instance"" msgid ""Suspended"" msgstr ""निलंबित"" msgctxt ""Power state of an Instance"" msgid ""Failed"" msgstr ""अपयशी"" msgctxt ""Power state of an Instance"" msgid ""Building"" msgstr ""पुनर्बांधणी"" msgid ""Key Pair"" msgstr ""कळ जोडी"" msgid ""Log"" msgstr ""लॉग"" #, python-format msgid ""Unable to get log for instance \""%s\""."" msgstr ""घटकासाठी नोंद मिळविण्यास असमर्थ\""%s\""."" msgid ""Action Log"" msgstr ""कृती नोंद"" msgid ""Unable to retrieve instance action list."" msgstr ""घटक कृती यादी मिळविण्यास असमर्थ."" msgid ""Retrieve Instance Password"" msgstr ""घटक पासवर्ड मिळविण्यास असमर्थ"" msgid """" ""To decrypt your password you will need the private key of your key pair for "" ""this instance. Select the private key file, or copy and paste the content of "" ""your private key file into the text area below, then click Decrypt Password."" msgstr """" ""तुमच्या पासवर्डचे सांकेतिकरण काढून टाकण्यासाठी तुम्हाला या घटकासाठीच्या तुमच्या कळ जोडीतून "" ""तुमची खाजगी कळ लागेल. खाजगी कळ धारिका निवडा, किंवा खाली दिलेल्या मजकूर क्षेत्रामध्ये "" ""तुमच्या खाजगी कळ धारिकेतील मजकूर चिटकवा, त्यानंतर पासवर्डचे सांकेतिकरण रद्द करावर क्लिक "" ""करा."" msgid ""Note: "" msgstr ""सूचना:"" msgid """" ""The private key will be only used in your browser and will not be sent to "" ""the server"" msgstr """" ""खाजगी कळ केवळ तुमच्या ब्राउजरमध्ये वापरली जाईल व तुमच्या सर्वरला पाठवली जाणार नाही"" msgid ""Decrypt Password"" msgstr ""पासवर्डचे सांकेतिकीकरण रद्द करा"" msgid ""Instance Console"" msgstr ""घटक कन्सोल"" msgid """" ""If console is not responding to keyboard input: click the grey status bar "" ""below."" msgstr """" ""जर कन्सोल कळफलकाच्या टंकलेखनाला प्रतिसाद देत नसेल: खाली दिलेली करड्या रंगाची स्थिती "" ""पट्टी क्लिक करा."" msgid ""Click here to show only console"" msgstr ""कोणतेही कन्सोल दाखविण्यासाठी येथे क्लिक करा"" msgid ""To exit the fullscreen mode, click the browser's back button."" msgstr ""संपूर्ण पटल पद्धतीमधून बाहेर करण्यासाठी, ब्राउजरच्या बॅक बटणावर क्लिक करा."" msgid ""console is currently unavailable. Please try again later."" msgstr ""कन्सोल सध्या उपलब्ध नाही. कृपया नंतर पुन्हा प्रयत्न करा."" msgid ""Reload"" msgstr ""पुन्हा उघडा"" msgid ""Instance Console Log"" msgstr ""घटक कन्सोल नोंद"" msgid ""Log Length"" msgstr ""लॉग लांबी"" msgid ""Go"" msgstr ""जा"" msgid ""View Full Log"" msgstr ""संपूर्ण नोंद पाहा"" msgid ""Fault"" msgstr ""चूक"" msgid ""VCPU"" msgstr ""व्हीसीपीयू"" msgid ""Disk"" msgstr ""डिस्क"" msgid ""IP Addresses"" msgstr ""आयपी पत्ता"" msgid ""No rules defined."" msgstr ""कोणतेही नियम निश्चित करण्यात आले नाहीत."" msgid ""Key Name"" msgstr ""कळ नाव"" msgid ""N/A"" msgstr ""उपलब्ध/नाही"" msgid ""Volumes Attached"" msgstr ""जोडलेले खंड"" msgid ""Attached To"" msgstr ""ला जोडलेले"" #, python-format msgid """" ""\n"" "" <a href=\""%(volume_url)s\"">%(volume_label)s</a> on "" ""%(volume_device)s\n"" "" "" msgstr """" ""\n"" "" <a href=\""%(volume_url)s\"">%(volume_label)s</a> on "" ""%(volume_device)s\n"" "" "" msgid ""No volumes attached."" msgstr ""कोणतेही खंड जोडलेले नाहीत."" msgid ""Flavor Details"" msgstr ""साचे तपशील"" msgid ""Total Disk"" msgstr ""एकूण डिस्क"" msgid ""MB"" msgstr ""एमबी"" msgid ""Project Limits"" msgstr ""प्रकल्प मर्यादा"" msgid ""Number of Instances"" msgstr ""घटकांची संख्या"" #, python-format msgid ""<p>%(used)s of %(quota)s Used</p>"" msgstr ""<p>%(used)s of %(quota)s वापरलेला</p>"" msgid ""Total RAM"" msgstr ""एकूण रॅम"" #, python-format msgid ""<p>%(used)s of %(quota)s MB Used</p>"" msgstr ""<p>%(used)s of %(quota)s एमबी वापरलेला</p>"" msgid ""Some flavors not meeting minimum image requirements have been disabled."" msgstr ""जे साचे किमान चित्र आवश्यकता पूर्ण करत नाहीत ते असमर्थ करण्यात आले आहेत."" msgid ""No flavors meet minimum criteria for selected image."" msgstr ""कोणचेही साचे निवडलेल्या चित्रासाठी किमान निकष पूर्ण करत नाहीत."" #, python-format msgid ""Flavor Details: %(name)s\"">%(name)s"" msgstr ""साचा तपशील: %(name)s\"">%(name)s"" msgid ""Specify advanced options to use when launching an instance."" msgstr ""घटक सुरु करताना वापराचा प्रगत पर्याय नमूद करा."" msgid """" ""You can customize your instance after it has launched using the options "" ""available here."" msgstr ""तुम्ही घटक सुरु केल्यानंतर येथे उपलब्ध पर्याय वापरुन तो स्वपसंत करु शकता."" msgid """" ""\""Customization Script\"" is analogous to \""User Data\"" in other systems."" msgstr ""\""स्वपसंत करण्यासाठी लिपी\""दुस-या यंत्रणेतील \""वापरकर्ता डाटा\"" सदृश असते."" msgid """" ""The chart below shows the resources used by this project in relation to the "" ""project's quotas."" msgstr """" ""खालील तक्ता या प्रकल्पाच्या वाट्याच्या संबंधी या प्रकल्पाने वापरलेली संसाधने दाखवतो. "" msgid """" ""Choose network from Available networks to Selected networks by push button "" ""or drag and drop, you may change NIC order by drag and drop as well. "" msgstr """" ""उपलब्ध नेटवर्कमधून निवडलेल्या नेटवर्कमध्ये पुश बटणाद्वारे किंवा खेचून व सोडून नेटवर्क निवडा, "" ""तुम्ही खेचून व सोडून एनआयसी क्रमही बदलू शकता. "" msgid """" ""An instance can be launched with varying types of attached storage. You may "" ""select from those options here."" msgstr """" ""जोडलेल्या विविध प्रकारच्या साठ्यांसोबतही घटकाची सुरुवात करता येते. तुम्हाला कदाचित येथील "" ""पर्यायामधून निवड करता येईल."" msgid ""Select the image to rebuild your instance."" msgstr ""तुमच्या घटकांची पुनर्बांधणी करण्यासाठी एक चित्र निवडा."" msgid ""You may optionally set a password on the rebuilt instance."" msgstr ""तुम्ही पुनर्बांधणी घटकावर इच्छा असल्यास पासवर्डची रचना करु शकता."" msgid ""Instance Admin Password"" msgstr ""घटक प्रशासक पासवर्ड"" msgid ""Unable to retrieve instance flavors."" msgstr ""घटक साचे मिळविण्यास असमर्थ."" msgid ""Unable to sort instance flavors."" msgstr ""घटकांच्या साच्यांचे वर्गीकरण करण्यास असमर्थ."" msgid ""Unable to retrieve Nova availability zones."" msgstr ""नोव्हा उपलब्धता विभाग मिळविण्यास असमर्थ."" msgid ""No networks available"" msgstr ""कोणतेही नेटवर्क उपलब्ध नाही"" msgid ""Unable to retrieve key pairs."" msgstr ""कळ जोड्या मिळविण्यास असमर्थ."" msgid ""No key pairs available"" msgstr ""कोणतीही कळ जोडी उपलब्ध नाही"" msgid ""Select a key pair"" msgstr ""कळ जोडी निवडा"" msgid ""Unable to retrieve instances."" msgstr ""घटक मिळविण्यास असमर्थ."" #, python-format msgid ""Unable to get VNC console for instance \""%s\""."" msgstr ""घटकासाठी व्हीएनसी कन्सोल मिळविण्यास असमर्थ \""%s\""."" #, python-format msgid ""Unable to get SPICE console for instance \""%s\""."" msgstr ""घटकासाठी स्पाईस कन्सोल मिळविण्यास असमर्थ \""%s\""."" #, python-format msgid ""Unable to get RDP console for instance \""%s\""."" msgstr ""घटकासाठी आरडीपी कन्सोल मिळविण्यास असमर्थ \""%s\""."" #, python-format msgid ""Unable to retrieve details for instance \""%s\""."" msgstr ""घटकासाठी तपशील मिळविण्यास असमर्थ \""%s\""."" #, python-format msgid ""Unable to retrieve volume list for instance \""%(name)s\"" (%(id)s)."" msgstr ""घटकासाठी खंड यादी मिळविण्यास असमर्थ \""%(name)s\"" (%(id)s)."" #, python-format msgid """" ""Unable to retrieve flavor information for instance \""%(name)s\"" (%(id)s)."" msgstr ""घटकासाठी साचा माहिती मिळविण्यास असमर्थ \""%(name)s\"" (%(id)s)."" #, python-format msgid ""Unable to retrieve security groups for instance \""%(name)s\"" (%(id)s)."" msgstr ""घटकासाठी सुरक्षा गट मिळविण्यास असमर्थ \""%(name)s\"" (%(id)s)."" #, python-format msgid """" ""Unable to retrieve IP addresses from Neutron for instance \""%(name)s"" ""\"" (%(id)s)."" msgstr ""घटकासाठी न्यूट्रॉनकडून आयपी पत्ते मिळविण्यास असमर्थ \""%(name)s\"" (%(id)s)."" msgid ""User"" msgstr ""वापरकर्ता"" msgid ""Project & User"" msgstr ""प्रकल्प व वापरकर्ता"" msgid ""Instance Count"" msgstr ""घटक संख्या"" msgid ""Number of instances to launch."" msgstr ""सुरु करायच्या घटकांची संख्या."" msgid ""Instance Boot Source"" msgstr ""घटक पुन्हा सुरुवात"" msgid ""Choose Your Boot Source Type."" msgstr ""तुमचा पुन्हा सुरुवात प्रकार निवडा."" msgid ""Instance Snapshot"" msgstr ""घटक क्षणचित्र"" msgid ""Volume Snapshot"" msgstr ""खंड क्षणचित्र"" msgid ""Device size (GB)"" msgstr ""साधन आकार (जीबी)"" msgid ""Volume size in gigabytes (integer value)."" msgstr ""खंड आकार गिगाबाईट्समध्ये (पूर्णांक मूल्य)"" msgid ""Device Name"" msgstr ""साधन नाव"" msgid """" ""Volume mount point (e.g. 'vda' mounts at '/dev/vda'). Leave this field blank "" ""to let the system choose a device name for you."" msgstr """" ""खंड आरोपण बिंदू (उदा. 'व्हीडीए' आरोपण '/डीईव्ही/व्हीडीए' येथे). यंत्रणेला तुमच्यासाठी "" ""साधन नाव निवडता यावे यासाठी हे क्षेत्र रिक्त सोडा."" msgid ""Delete on Terminate"" msgstr ""संपल्यावर नष्ट करा"" msgid ""Delete volume on instance terminate"" msgstr ""घटक संपल्यानंतर खंड नष्ट करा"" msgid ""Select source"" msgstr ""स्रोत निवडा"" msgid ""Boot from image"" msgstr ""चित्रातून सुरुवात करा"" msgid ""Boot from snapshot"" msgstr ""क्षणचित्रातून सुरुवात करा"" msgid ""Boot from volume"" msgstr ""खंडातून सुरुवात करा"" msgid ""Boot from image (creates a new volume)"" msgstr ""चित्रातून सुरुवात करा (नवीन चित्र तयार होते)"" msgid ""Boot from volume snapshot (creates a new volume)"" msgstr ""खंड क्षणचित्रातून सुरुवात करा (नवीन खंड तयार करा)"" #, python-format msgid ""Cores(Available: %(avail)s, Requested: %(req)s)"" msgstr ""घटक(उपलब्ध: %(avail)s, विनंती केलेले: %(req)s)"" #, python-format msgid ""RAM(Available: %(avail)s, Requested: %(req)s)"" msgstr ""रॅम(उपलब्ध: %(avail)s, विनंती केलेली: %(req)s)"" #, python-format msgid """" ""The requested instance cannot be launched. The following requested resource"" ""(s) exceed quota(s): %s."" msgstr """" ""विनंती करण्यात आलेले घटक सुरु करता येत नाहीत. पुढील विनंती करण्यात आलेले संसाधन (संसाधने) "" ""वाट्यापेक्षा अधिक आहे (आहेत): %s."" #, python-format msgid """" ""The flavor '%(flavor)s' is too small for requested image.\n"" ""Minimum requirements: %(min_ram)s MB of RAM and %(min_disk)s GB of Root Disk."" msgstr """" ""साचा '%(flavor)s' विनंती केलेल्या चित्रासाठी अतिशय लहान आहे.\n"" ""किमान आवश्यकता: %(min_ram)s एमबी रॅम व %(min_disk)s जीबी मूळ डिस्क."" #, python-format msgid """" ""The Volume size is too small for the '%(image_name)s' image and has to be "" ""greater than or equal to '%(smallest_size)d' GB."" msgstr """" ""खंड आकार '%(image_name)s' चित्रासाठी अतिशय लहान आहे व तो '%(smallest_size)d' "" ""जीबीपेक्षा अधिक किंवा त्याऐवढा असला पाहिजे."" msgid ""You must select an image."" msgstr ""तुम्ही एक चित्र निवडले पाहिजे."" msgid ""You must set volume size"" msgstr ""तुम्ही खंड आकाराची रचना केली पाहिजे"" msgid ""Volume size must be greater than 0"" msgstr ""खंड आकार ० पेक्षा अधिक असला पाहिजे"" msgid ""You must select a snapshot."" msgstr ""तुम्ही एक क्षणचित्र निवडले पाहिजे."" msgid ""You must select a volume."" msgstr ""तुम्ही एक खंड निवडला पाहिजे."" msgid """" ""Launching multiple instances is only supported for images and instance "" ""snapshots."" msgstr ""केवळ चित्र व घटक क्षणचित्रांसाठी अनेक घटक सुरु करण्यास सहाय्य केले जाते."" msgid ""Unable to retrieve availability zones."" msgstr ""उपलब्धता विभाग मिळविण्यास असमर्थ."" msgid ""No availability zones found"" msgstr ""कोणताही उपलब्धता विभाग सापडला नाही"" msgid ""Any Availability Zone"" msgstr ""कोणताही उपलब्धता विभाग"" msgid ""Unable to retrieve quota information."" msgstr ""वाटा माहिती मिळविण्यास असमर्थ."" msgid ""Snapshot"" msgstr ""क्षणचित्र"" #, python-format msgid ""%(name)s - %(size)s GB (%(label)s)"" msgstr ""%(name)s - %(size)s जीबी (%(label)s)"" msgid ""Select Instance Snapshot"" msgstr ""घटक क्षणचित्र निवडा"" msgid ""No snapshots available"" msgstr ""कोणतेही क्षणचित्र उपलब्ध नाही"" msgid ""Unable to retrieve list of volumes."" msgstr ""खंडांमधून यादी मिळविण्यास असमर्थ."" msgid ""Select Volume"" msgstr ""खंड निवडा"" msgid ""No volumes available"" msgstr ""कोणतेही खंड उपलब्ध नाहीत"" msgid ""Unable to retrieve list of volume snapshots."" msgstr ""खंड क्षणचित्र यादी मिळविण्यास असमर्थ."" msgid ""Select Volume Snapshot"" msgstr ""खंड क्षणचित्र निवडा"" msgid ""No volume snapshots available"" msgstr ""कोणतीही खंड क्षणचित्रे उपलब्ध नाहीत"" msgid ""Key pair to use for authentication."" msgstr ""प्रमाणीकरणासाठी वापरायची कळ जोडी."" msgid ""Confirm Admin Password"" msgstr ""प्रशासक पासवर्डची खात्री करा"" msgid ""Launch instance in these security groups."" msgstr ""या सुरक्षा गटात घटक सुरु करा. "" msgid """" ""Control access to your instance via key pairs, security groups, and other "" ""mechanisms."" msgstr ""कळ जोड्या, सुरक्षा गट, व इतर यंत्रणांद्वारे तुमच्या घटकाची उपलब्धता नियंत्रित करा."" msgid ""Unable to retrieve list of security groups"" msgstr ""सुरक्षा गटांची यादी मिळविण्यास असमर्थ"" msgid ""Post-Creation"" msgstr ""निर्मिती-नंतर"" msgid ""Select Script Source"" msgstr ""लिपी स्रोत निवडा"" msgid ""Customization Script Source"" msgstr ""लिपी स्रोत स्वपसंत करा"" msgid """" ""A script or set of commands to be executed after the instance has been built "" ""(max 16kb)."" msgstr ""घटक बांधल्यानंतर वापरायची लिपी किंवा आज्ञांचा संच (कमाल १६केबी)."" msgid ""Script File"" msgstr ""लिपी धारिका"" msgid ""Script Data"" msgstr ""लिपी डाटा"" msgid ""File exceeds maximum size (16kb)"" msgstr ""धारिका कमाल आकारापेक्षा मोठी आहे (१६केबी)"" #, python-format msgid ""There was a problem parsing the %(prefix)s: %(error)s"" msgstr ""%(prefix)s पदनिरुपण करताना एक समस्या आली: %(error)s"" msgid ""Policy Profiles"" msgstr ""धोरण स्वरुपे"" msgid ""Launch instance with this policy profile"" msgstr ""या धोरण स्वरुपाद्वारे घटक सुरु करा"" msgid """" ""Automatic: The entire disk is a single partition and automatically resizes. "" ""Manual: Results in faster build times but requires manual partitioning."" msgstr """" ""स्वयंचलित: संपूर्ण डिस्क एकच विभाग विभाग आहे व स्वयंचलितपणे आकार बदलते. हाताने: यामुळे "" ""वेगाने तयार करता येते मात्र हाताने विभाजन करावे लागते."" msgid ""Configuration Drive"" msgstr ""मांडणी ड्राईव्ह"" msgid """" ""Configure OpenStack to write metadata to a special configuration drive that "" ""attaches to the instance when it boots."" msgstr """" ""घटक सुरु होतो तेव्हा त्याला जोडल्या जाणा-या विशेष मांडणी ड्राईव्हवर मेटाडाटा "" ""लिहीण्यासाठी ओपनस्टेकची मांडणी करा."" msgid ""Advanced Options"" msgstr ""प्रगत पर्याय"" #, python-format msgid ""%s instances"" msgstr ""%s घटक"" msgid ""Choose the flavor to launch."" msgstr ""सुरुवात करण्यासाठी साचा निवडा."" msgid ""Flavor Choice"" msgstr ""साचा पर्याय"" msgid ""Select a New Flavor"" msgstr ""नवीन साचा निवडा"" msgid ""Resize"" msgstr ""आकार बदला"" #, python-format msgid ""Scheduled resize of instance \""%s\""."" msgstr ""घटकाचा नियोजित आकार बदलणे \""%s\""."" #, python-format msgid ""Unable to resize instance \""%s\""."" msgstr ""घटकाचा आकार बदलण्यास असमर्थ \""%s\""."" msgid ""Unable to retrieve security group list. Please try again later."" msgstr ""सुरक्षा गट यादी मिळविण्यास असमर्थ. कृपया नंतर प्रयत्न करा."" msgid """" ""Add and remove security groups to this project from the list of available "" ""security groups."" msgstr ""उपलब्ध सुरक्षा गटाच्या यादीतून या प्रकल्पात सुरक्षा गट समाविष्ट करा व काढून टाका."" msgid ""All Security Groups"" msgstr ""सर्व सुरक्षा गट"" msgid ""Instance Security Groups"" msgstr ""घटक सुरक्षा गट"" msgid ""No security groups found."" msgstr ""कोणताही सुरक्षा गट सापडला नाही."" msgid ""No security groups enabled."" msgstr ""कोणताही सुरक्षा गट समर्थ करण्यात आला नाही."" msgid ""Edit the instance details."" msgstr ""घटकांचे तपशील समर्थ करा."" #, python-format msgid ""Modified instance \""%s\""."" msgstr ""सुधारित घटक \""%s\""."" #, python-format msgid ""Unable to modify instance \""%s\""."" msgstr ""घटकामध्ये बदल करण्यास असमर्थ \""%s\""."" msgid ""Load Balancing Method"" msgstr ""संतुलन पद्धत सुरु करा"" #, python-format msgid ""Pool %s was successfully updated."" msgstr ""गट%s यशस्वीपणे सुधारित करण्यात आला."" #, python-format msgid ""Failed to update pool %s"" msgstr ""गट सुधारित करण्यात अपयशी %s"" msgid ""Session Persistence"" msgstr ""सत्र सातत्य"" msgid ""Cookie Name"" msgstr ""कुकी नाव"" msgid ""Required for APP_COOKIE persistence; Ignored otherwise."" msgstr ""एपीपी_कुकी सातत्यासाठी आवश्यक; नाहीतर दुर्लक्ष करा."" msgid ""Connection Limit"" msgstr ""जोडणी मर्यादा"" msgid """" ""Maximum number of connections allowed for the VIP or '-1' if the limit is "" ""not set"" msgstr """" ""व्हीआयपीसाठी परवानगी देण्यात आलेल्या जोडण्यांची कमाल संख्या किंवा '-१' जर मर्यादा "" ""निश्चित करण्यात आली नसेल"" msgid ""Unable to retrieve pools list."" msgstr ""गट यादी मिळविण्यास असमर्थ."" msgid ""No session persistence"" msgstr ""सत्र सातत्य नाही"" msgid ""Cookie name is required for APP_COOKIE persistence."" msgstr ""एपीपी_कुकी सातत्यासाठी कुकी नाव आवश्यक."" #, python-format msgid ""VIP %s was successfully updated."" msgstr ""व्हीआयपी %s यशस्वीपणे सुधारणा करण्यात आली."" #, python-format msgid ""Failed to update VIP %s"" msgstr ""व्हीआयपी सुधारणा करण्यात अपयशी %s"" msgid ""Weight"" msgstr ""वजन"" msgid ""Relative part of requests this pool member serves compared to others"" msgstr ""या गटातील सदस्य इतरांच्या तुलनेत ज्या विनंत्या पूर्ण करतात त्यांचा संबंधित भाग"" #, python-format msgid ""Member %s was successfully updated."" msgstr ""सदस्य %sयशस्वीपणे सुधारित करण्यात आला."" #, python-format msgid ""Failed to update member %s"" msgstr ""सदस्य सुधारित करण्यात अपयशी %s"" msgid ""Delay"" msgstr ""उशीर"" msgid ""The minimum time in seconds between regular checks of a member"" msgstr ""सदस्याच्या नियमित तपासणी दरम्यानचा किमान वेळ सेकंदांमध्ये"" msgid ""Timeout"" msgstr ""वेळ संपली"" msgid ""The maximum time in seconds for a monitor to wait for a reply"" msgstr ""निरीक्षकाने उत्तराची वाट पाहण्यासाठी कमाल वेळ सेकंदांमध्ये "" msgid ""Max Retries (1~10)"" msgstr ""कमाल पुनर्प्रयत्न (१~१०)"" msgid """" ""Number of permissible failures before changing the status of member to "" ""inactive"" msgstr ""सदस्याची स्थिती निष्क्रिय म्हणून बदलण्यापूर्वी मान्य अपयशांची संख्या "" #, python-format msgid ""Health monitor %s was successfully updated."" msgstr ""आरोग्य निरीक्षकांची %s यशस्वीपणे सुधारणा करण्यात आली."" #, python-format msgid ""Failed to update health monitor %s"" msgstr ""आरोग्य निरीक्षक सुधारित करण्यास अपयशी %s"" msgid ""Load Balancers"" msgstr ""संतुलक उघडा"" msgid ""Add Pool"" msgstr ""गट समाविष्ट करा"" msgid ""Add VIP"" msgstr ""व्हीआयपी समाविष्ट करा"" msgid ""Add Member"" msgstr ""सदस्य समाविष्ट करा"" msgid ""Add Monitor"" msgstr ""निरीक्षक समाविष्ट करा"" msgid ""Edit Pool"" msgstr ""गट संपादित करा"" msgid ""Edit VIP"" msgstr ""व्हीआयपी संपादित करा"" msgid ""Edit Member"" msgstr ""सदस्य संपादित करा"" msgid ""Edit Monitor"" msgstr ""निरीक्षक संपादित करा"" msgid ""Associate Monitor"" msgstr ""सहाय्यक निरीक्षक"" msgid ""Failed to retrieve health monitors."" msgstr ""आरोग्य निरीक्षक मिळविण्यास असमर्थ."" msgid ""Disassociate Monitor"" msgstr ""निरीक्षक विलग करा"" msgctxt ""Current status of a Pool"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of a Pool"" msgid ""Down"" msgstr ""खाली"" msgctxt ""Current status of a Pool"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of a Pool"" msgid ""Created"" msgstr ""तयार करण्यात आले"" msgid ""Subnet"" msgstr ""उपनेट"" msgid ""VIP"" msgstr ""व्हीआयपी"" msgid ""Pools"" msgstr ""गट"" msgid ""Protocol Port"" msgstr ""प्रोटोकॉल पोर्ट"" msgid ""Members"" msgstr ""सदस्य"" msgid ""Monitor Type"" msgstr ""मॉनिटर प्रकार"" msgid ""Max Retries"" msgstr ""कमाल पुनर्प्रयत्न"" msgid ""Monitors"" msgstr ""निरीक्षक"" msgid ""Unable to retrieve member list."" msgstr ""सदस्ययादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve monitor list."" msgstr ""निरीक्षक यादी मिळविण्यास असमर्थ."" msgid ""Pool Details"" msgstr ""गट तपशील"" msgid ""VIP Details"" msgstr ""व्हीआयपी तपशील"" msgid ""Unable to retrieve VIP details."" msgstr ""व्हीआयपी तपशील मिळविण्यास असमर्थ."" msgid ""Member Details"" msgstr ""सदस्या तपशील"" msgid ""Monitor Details"" msgstr ""निरीक्षक तपशील"" msgid ""Address"" msgstr ""पत्ता"" msgid ""HTTP Method"" msgstr ""एचटीटीपी पद्धत"" msgid ""URL Path"" msgstr ""यूआरएल मार्ग"" msgid ""Expected Codes"" msgstr ""अपेक्षित संकेत"" msgid ""Health Monitors"" msgstr ""आरोग्य निरीक्षक"" msgid """" ""You may update member attributes here: edit pool, weight or admin state."" msgstr """" ""तुम्ही येथे सदस्यांची वैशिष्ट्ये सुधारित करु शकता: गट, वजन किंवा प्रशासन स्थिती संपादित करा."" msgid """" ""You may update health monitor attributes here: edit delay, timeout, max "" ""retries or admin state."" msgstr """" ""तुम्ही येथे आरोग्य निरीक्षक वैशिष्ट्ये सुधारित करु शकता: उशीर, वेळ संपली, कमाल पुनर्प्रयत्न "" ""किंवा प्रशासक स्थिती संपादित करा."" msgid """" ""You may update pool attributes here: edit name, description, load balancing "" ""method or admin state."" msgstr """" ""तुम्ही येथे गट वैशिष्ट्ये येथे सुधारित करु शकता: नाव, वर्णन, भार संतुलन पद्धत किंवा प्रशासक "" ""स्थिती संपादित करा."" msgid """" ""You may update VIP attributes here: edit name, description, pool, session "" ""persistence, connection limit or admin state."" msgstr """" ""तुम्ही येथे व्हीआयपी वैशिष्ट्ये येथे सुधारित करु शकता: नाव, वर्णन, गट, सत्र सातत्य, जोडणी "" ""मर्यादा किंवा प्रशासक स्थिती संपादित करा."" msgid ""Port ID"" msgstr ""पोर्ट ओळख क्रमांक"" #, python-format msgid ""Type: %(persistence_type)s"" msgstr ""प्रकार: %(persistence_type)s"" #, python-format msgid ""Cookie Name: %(cookie_name)s"" msgstr ""कुकी नाव: %(cookie_name)s"" msgid ""Load Balancer"" msgstr ""भार संतुलक"" #, python-format msgid """" ""%(type)s: url:%(url_path)s method:%(http_method)s codes:%(expected_codes)s "" ""delay:%(delay)d retries:%(max_retries)d timeout:%(timeout)d"" msgstr """" ""%(type)s: यूआरएल:%(url_path)s पद्धत:%(http_method)s संकेत:%(expected_codes)s "" ""उशीर:%(delay)d पुनर्प्रयत्न:%(max_retries)d वेळसंपली:%(timeout)d"" #, python-format msgid ""%(type)s delay:%(delay)d retries:%(max_retries)d timeout:%(timeout)d"" msgstr ""%(type)s उशीर:%(delay)d पुनर्प्रयत्न:%(max_retries)d वेळ संपली:%(timeout)d"" #, python-format msgid ""Deleted monitor %s"" msgstr ""नष्ट केलेले निरीक्षक %s"" #, python-format msgid ""Unable to delete monitor. %s"" msgstr ""निरीक्षक नष्ट करण्यास असमर्थ. %s"" #, python-format msgid ""Deleted pool %s"" msgstr ""गट नष्ट करा %s"" #, python-format msgid ""Unable to delete pool. %s"" msgstr ""गट नष्ट करण्यास असमर्थ. %s"" #, python-format msgid ""Deleted member %s"" msgstr ""नष्ट केलेला सदस्य %s"" #, python-format msgid ""Unable to delete member. %s"" msgstr ""सदस्य नष्ट करण्यास असमर्थ. %s"" #, python-format msgid ""Unable to locate VIP to delete. %s"" msgstr ""नष्ट कऱण्यासाठी व्हीआयपी शोधण्यास असमर्थ. %s"" #, python-format msgid ""Deleted VIP %s"" msgstr ""नष्ट केलेला व्हीआयपी%s"" #, python-format msgid ""Unable to delete VIP. %s"" msgstr ""व्हीआयपी नष्ट करण्यास असमर्थ. %s"" #, python-format msgid ""Unable to retrieve pool subnet. %s"" msgstr ""गट उपनेट मिळविण्यास असमर्थ. %s"" msgid ""Unable to retrieve pool details."" msgstr ""गट तपशील मिळविण्यास असमर्थ."" msgid ""Unable to retrieve member details."" msgstr ""सदस्य तपशील मिळविण्यास असमर्थ."" msgid ""Unable to retrieve monitor details."" msgstr ""निरीक्षक तपशील मिळविण्यास असमर्थ."" #, python-format msgid ""Unable to retrieve pool details. %s"" msgstr ""गट तपशील मिळविण्यास असमर्थ. %s"" #, python-format msgid ""Unable to retrieve VIP details. %s"" msgstr ""व्हीआयपी तपशील मिळविण्यास असमर्थ. %s"" #, python-format msgid ""Unable to retrieve member details. %s"" msgstr ""सदस्य तपशील मिळविण्यास असमर्थ. %s"" #, python-format msgid ""Unable to retrieve health monitor details. %s"" msgstr ""आरोग्य निरीक्षक तपशील मिळविण्यास असमर्थ. %s"" #, python-format msgid ""Unable to retrieve pool. %s"" msgstr ""गट मिळविण्यास असमर्थ. %s"" msgid ""Select a Subnet"" msgstr ""उपनेट निवडा"" msgid ""Unable to retrieve networks list."" msgstr ""नेटवर्क यादी मिळविण्यास असमर्थ."" msgid ""Select a Protocol"" msgstr ""एक प्रोटोकॉल निवडा"" msgid ""Select a Method"" msgstr ""एक पद्धती निवडा"" msgid ""Unable to retrieve providers list."" msgstr ""पुरवठादारांची यादी मिळविण्यास असमर्थ."" #, python-format msgid ""%s (default)"" msgstr ""%s (पूर्वनिर्धारित)"" msgid ""Provider for Load Balancer is not supported"" msgstr ""भार संतुलकाच्या पुरवठादारास सहाय्य नाही"" msgid ""No provider is available"" msgstr ""कोणताही पुरवठादार उपलब्ध नाही"" msgid ""Add New Pool"" msgstr ""नवीन गट समाविष्ट करा"" #, python-format msgid ""Added pool \""%s\""."" msgstr ""समाविष्ट गट \""%s\""."" #, python-format msgid ""Unable to add pool \""%s\""."" msgstr ""गट समाविष्ट करण्यास असमर्थ\""%s\""."" msgid ""VIP Subnet"" msgstr ""व्हीआयपी उपनेट"" msgid ""Specify a free IP address from the selected subnet"" msgstr ""निवडलेल्या उपनेटमधून मुक्त आयपी पत्ती नमूद करा"" msgid ""No Session Persistence"" msgstr ""सत्राचे सातत्य नाही"" msgid ""Specify VIP"" msgstr ""व्हीआयपी नमूद करा"" msgid """" ""Create a VIP for this pool. Assign a name, description, IP address, port, "" ""and maximum connections allowed for the VIP. Choose the protocol and session "" ""persistence method for the VIP. Admin State is UP (checked) by default."" msgstr """" ""या गटासाठी व्हीआयपी तयार करा. व्हीआयपीसाठी एक नाव, वर्णन, आयपी पत्ता, पोर्ट, व "" ""कमाल किती जोडण्यांची परवानगी आहे ते द्या. व्हीआयपीसाठी प्रोटोकॉल व सत्र सातत्य पद्धत "" ""निवडा. पूर्वनिर्धारितपणे प्रशासक स्थिती सुरु (तपासलेली) आहे."" #, python-format msgid ""Added VIP \""%s\""."" msgstr ""व्हीआयपी समाविष्ट \""%s\""."" #, python-format msgid ""Unable to add VIP \""%s\""."" msgstr ""व्हीआयपी समाविष्ट करण्यास असमर्थ \""%s\""."" #, python-format msgid ""Unable to retrieve the specified pool. Unable to add VIP \""%s\""."" msgstr ""विनिर्दिष्ट गट मिळविण्यास असमर्थ. व्हीआयपी समाविष्ट करण्यास असमर्थ \""%s\""."" msgid ""Member Source"" msgstr ""सदस्य स्रोत"" msgid ""Select from active instances"" msgstr ""सक्रिय घटकातून निवडा"" msgid ""Specify member IP address"" msgstr ""सदस्य आयपी पत्ती नमूद करा"" msgid ""Member(s)"" msgstr ""सदस्य(अनेक सदस्य)"" msgid ""Select members for this pool "" msgstr ""या गटासाठी सदस्य निवडा"" msgid ""Member address"" msgstr ""सदस्य पत्ता"" msgid """" ""Relative part of requests this pool member serves compared to others. \n"" ""The same weight will be applied to all the selected members and can be "" ""modified later. Weight must be in the range 1 to 256."" msgstr """" ""या गटाचा सदस्य इतरांच्या तुलनेत जेवढ्या विनंती पूर्ण करतो त्यांचा तुलनात्मक भाग. \n"" ""सर्व निवडलेल्या सदस्यांसाठी तेवढेच वजन वापरले जाईल व त्यामध्ये नंतर सुधारणा करता येईल. वजन "" ""१ ते २५६ या दरम्यान असले पाहिजे."" msgid """" ""Enter an integer value between 1 and 65535. The same port will be used for "" ""all the selected members and can be modified later."" msgstr """" ""१ ते ६५५३५ या दरम्यानचे पूर्ण मूल्य घातले पाहिजे. हाच पोर्ट सर्व निवडलेल्या सदस्यांसाठी "" ""वापरला जाईल व त्यात नंतर सुधारणा केली जाईल."" msgid ""Select a Pool"" msgstr ""एक गट निवडा"" msgid ""Unable to retrieve instances list."" msgstr ""घटकांची यादी मिळविण्यास असमर्थ."" msgid """" ""No servers available. To add a member, you need at least one running "" ""instance."" msgstr """" ""कोणतेही सर्वर उपलब्ध नाहीत. सदस्य समाविष्ट करण्यासाठी, तुम्हाला केवळ एक चालू घटक आवश्यक "" ""आहे."" msgid ""At least one member must be specified"" msgstr ""किमान एक सदस्य नमूद केला पाहिजे"" msgid ""Member IP address must be specified"" msgstr ""सदस्य आयपी पत्ता नमूद केलाच पाहिजे"" msgid ""Add New Member"" msgstr ""नवीन सदस्य समाविष्ट करा"" msgid """" ""Add member(s) to the selected pool.\n"" ""\n"" ""Choose one or more listed instances to be added to the pool as member(s). "" ""Assign a numeric weight and port number for the selected member(s) to operate"" ""(s) on; e.g., 80. \n"" ""\n"" ""Only one port can be associated with each instance."" msgstr """" ""निवडलेल्या गटामध्ये सदस्य (अनेक सदस्य) समाविष्ट करा.\n"" ""\n"" ""गटामध्ये सदस्य (अनेक सदस्य) म्हणून समाविष्ट करण्यासाठी एक किंवा अधिक यादीत समाविष्ट घटक "" ""निवडा. निवडलेल्या सदस्यासाठी (सदस्यांसाठी) संचालनासाठी (संचालनांसाठी) एक सांख्यिक वजन "" ""व पोर्ट क्रमांक नमूद करा; उदा., ८०. \n"" ""\n"" ""केवळ प्रत्येक घटकासोबत एकच पोर्टच जोडता येईल."" msgid ""Added member(s)."" msgstr ""सदस्य (अनेक सदस्य) समाविष्ट करा"" msgid ""Unable to add member(s)"" msgstr ""सदस्य (अनेक सदस्य) समाविष्ट करण्यास असमर्थ"" msgid ""Unable to retrieve the specified pool."" msgstr ""विनिर्दिष्ट गट मिळविण्यास असमर्थ."" msgid ""PING"" msgstr ""पिंग"" msgid ""HTTP"" msgstr ""एचटीटीपी"" msgid ""HTTPS"" msgstr ""एचटीटीपीएस"" msgid ""GET"" msgstr ""जीईटी"" msgid ""HTTP method used to check health status of a member"" msgstr ""सदस्यची आरोग्य स्थिती तपासण्यासाठी वापरलेली एचटीटीपी पद्धत"" msgid ""Expected HTTP Status Codes"" msgstr ""अपेक्षित एचटीटीपी स्थिती संकेत"" msgid """" ""Expected code may be a single value (e.g. 200), a list of values (e.g. 200, "" ""202), or range of values (e.g. 200-204)"" msgstr """" ""अपेक्षित संकेत एक मूल्य असू शकते (उदा. २००),मूल्यांची यादी (उदा. २००, २०२), किंवा मूल्यांची "" ""श्रेणी (उदा. २००-२०४)"" msgid ""Please choose a HTTP method"" msgstr ""कृपया एचटीटीपी पद्धत निवडा"" msgid ""Please specify an URL"" msgstr ""कृपया एक यूआरएल स्पष्ट करा"" msgid """" ""Please enter a single value (e.g. 200), a list of values (e.g. 200, 202), or "" ""range of values (e.g. 200-204)"" msgstr """" ""कृपया एक मूल्य (उदा. २००), मूल्यांची यादी (उदा. २००, २०२), किंवा मूल्य श्रेणी (उदा. "" ""२००-२०४) घाला"" msgid ""Add New Monitor"" msgstr ""नवीन निरीक्षक समाविष्ट करा"" msgid """" ""Create a monitor template.\n"" ""\n"" ""Select type of monitoring. Specify delay, timeout, and retry limits required "" ""by the monitor. Specify method, URL path, and expected HTTP codes upon "" ""success."" msgstr """" ""निरीक्षक साचा तयार करा.\n"" ""\n"" ""निरीक्षणाचा प्रकार निवडा. निरीक्षकाद्वारे आवश्यक उशीर, वेळ संपली, व पुन्हा प्रयत्नाच्या "" ""मर्यादा नमूद करा. पद्धत, यूआरएल मार्ग, व यशस्वी झाल्यानंतर अपेक्षित एचटीटीपी संकेत नमूद "" ""करा."" msgid ""Added monitor"" msgstr ""निरीक्षक समाविष्ट करा"" msgid ""Unable to add monitor"" msgstr ""निरीक्षक समाविष्ट करण्यास असमर्थ"" msgid ""Unable to add monitor."" msgstr ""निरीक्षक समाविष्ट करण्यास असमर्थ."" msgid ""Monitor"" msgstr ""निरीक्षक"" #, python-format msgid ""Select a monitor template for %s"" msgstr ""च्यासाठी निरीक्षक साचा निवडा%s"" msgid ""Select a Monitor"" msgstr ""निरीक्षक निवडा"" msgid ""Unable to retrieve monitors list."" msgstr ""निरीक्षक यादी मिळविण्यास असमर्थ."" msgid ""Association Details"" msgstr ""संबंध तपशील"" msgid ""Associate a health monitor with target pool."" msgstr ""लक्ष्य गटाशी आरोग्य निरीक्षकांचा संबंध जोडा."" msgid ""Associated monitor."" msgstr ""संबंधित निरीक्षक."" msgid ""Unable to associate monitor."" msgstr ""निरीक्षकाशी संबंध जोडण्यास असमर्थ."" #, python-format msgid ""Select a health monitor of %s"" msgstr ""चा आरोग्य निरीक्षक निवडा %s"" msgid ""Disassociate a health monitor from target pool. "" msgstr ""लक्ष्य गटातून आरोग्य निरीक्षक विलग करा. "" msgid ""Disassociated monitor."" msgstr ""विलग केलेला निरीक्षक."" msgid ""Unable to disassociate monitor."" msgstr ""निरीक्षक विलक करण्यास असमर्थ."" msgid ""Network Topology"" msgstr ""नेटवर्क रचना अभ्यास"" msgid ""Create Router"" msgstr ""राउटर तयार करा"" msgid ""Router"" msgstr ""राउटर"" msgid ""This pane needs javascript support."" msgstr ""या चौकटीला जावास्क्रिप्टचे सहाय्य आवश्यक आहे."" msgid ""Small"" msgstr ""लहान"" msgid ""Launch Instance (Quota exceeded)"" msgstr ""घटक सुरु करा (वाटा समाप्त)"" msgid ""Create Network (Quota exceeded)"" msgstr ""नेटवर्क तयार करा (वाटा समाप्त)"" msgid ""Create Router (Quota exceeded)"" msgstr ""राउटर तयार करा (वाटा समाप्त)"" msgid ""There are no networks, routers, or connected instances to display."" msgstr ""प्रदर्शित करण्यासाठी कोणतीही नेटवर्क, राउटर, किंवा जोडलेले घटक नाहीत."" msgid ""Create a Router"" msgstr ""एक राउटर तयार करा "" msgid ""Attached"" msgstr ""जोडलेले"" msgid ""Detached"" msgstr ""विलग केलेले"" msgid ""Edit Port"" msgstr ""पोर्ट संपादित करा"" msgctxt ""status of a network port"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""status of a network port"" msgid ""Down"" msgstr ""खाली"" msgctxt ""status of a neteork port"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""status of a network port"" msgid ""Build"" msgstr ""बांधणी"" msgid ""Port Details"" msgstr ""पोर्टचे तपशील"" msgid ""Unable to retrieve port details."" msgstr ""पोर्टचे तपशील मिळविण्यास असमर्थ."" msgid ""Unable to retrieve port details"" msgstr ""पोर्टचे तपशील मिळविण्यात अपयशी"" msgid ""Create Subnet (Quota exceeded)"" msgstr ""उपनेट तयार करा (वाटा समाप्त)"" msgid ""Network Address"" msgstr ""नेटवर्क पत्ता"" msgid ""No options specified"" msgstr ""कोणतेही पर्याय नमूद केले नाहीत"" msgid ""Unable to retrieve subnet details"" msgstr ""उपनेट तपशील मिळविसण्यास असमर्थ"" msgid ""Subnet Details"" msgstr ""उपनेट तपशील"" msgid ""Unable to retrieve subnet details."" msgstr ""उपनेट तपशील मिळविण्यास असमर्थ."" msgid ""Specify \""Network Address\"""" msgstr ""नमूद करा\""नेटवर्क पत्ता\"""" msgid """" ""Create a subnet associated with the network. Advanced configuration is "" ""available by clicking on the \""Subnet Details\"" tab."" msgstr """" ""नेटवर्कशी संबंधित उपनेट तयार करा. \""उपनेट तपशील\"" टॅबवर क्लिक करुन प्रगत मांडणी उपलब्ध "" ""आहे."" #, python-format msgid ""Created subnet \""%s\""."" msgstr ""तयार केलेले उपनेट \""%s\""."" #, python-format msgid ""Unable to create subnet \""%s\""."" msgstr ""उपनेट तयार करण्यास असमर्थ \""%s\""."" msgid ""Network address in CIDR format (e.g. 192.168.0.0/24)"" msgstr ""नेटवर्क पत्ता सीआयडीआर प्रारुपामध्ये (उदा. १९२.१६८.०.०/२४)"" msgid ""Gateway IP (optional)"" msgstr ""गेटवे आयपी (ऐच्छिक)"" msgid """" ""IP address of Gateway (e.g. 192.168.0.254). Specify an explicit address to "" ""set the gateway. If you do not want to use a gateway, check 'Disable "" ""Gateway' below."" msgstr """" ""गेटवेचा आयपी पत्ता (उदा. १९२.१६८.०.२५४). गेटवे निश्चित करण्यासाठी स्पष्ट पत्ता नमूद "" ""करा. तुम्हाला गेटवे वापरायचा नसेल तर, खालील 'गेटवे असमर्थ करा' वर बरोबरची खूण करा."" msgid ""Disable Gateway"" msgstr ""गेटवे असमर्थ करा"" msgid """" ""Update a subnet associated with the network. Advanced configuration are "" ""available at \""Subnet Details\"" tab."" msgstr """" ""नेटवर्कशी जोडलेले उपनेट सुधारित करा. \""उपनेट तपशील\"" टॅबवर प्रगत मांडणी उपलब्ध आहे."" msgid ""Specify additional attributes for the subnet."" msgstr ""उपनेटसाठी अतिरिक्त वैशिष्ट्ये नमूद करा."" #, python-format msgid ""Updated subnet \""%s\""."" msgstr ""सुधारित उपनेट\""%s\""."" #, python-format msgid ""Unable to update subnet \""%s\""."" msgstr ""उपनेट सुधारित करण्यास असमर्थ\""%s\""."" #, python-format msgid ""Subnet \""%s\"" was successfully updated."" msgstr ""उपनेट \""%s\"" यशस्वीपणे सुधारित करण्यात आले."" #, python-format msgid ""Failed to update subnet \""%(sub)s\"": %(reason)s"" msgstr ""उपनेट सुधारित करण्यास अपयशी \""%(sub)s\"": %(reason)s"" msgid ""Add Subnet"" msgstr ""उपनेट समाविष्ट करा"" msgid ""Add Subnet (Quota exceeded)"" msgstr ""उपनेट समाविष्ट करा (वाटा समाप्त)"" msgctxt ""Current status of a Network"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of a Network"" msgid ""Build"" msgstr ""बांधणी"" msgctxt ""Current status of a Network"" msgid ""Down"" msgstr ""खाली"" msgctxt ""Current status of a Network"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgid ""Select a name for your network."" msgstr ""तुमच्या नेटवर्कसाठी एक नाव निवडा."" msgid ""Network Overview"" msgstr ""नेटवर्क आढावा"" msgid ""MTU"" msgstr ""एमटीयू"" msgid ""Provider Network"" msgstr ""पुरवठादार नेटवर्क"" msgid ""Network Type:"" msgstr ""नेटवर्क प्रकार:"" msgid ""Physical Network:"" msgstr ""प्रत्यक्ष नेटवर्क:"" msgid ""Segmentation ID:"" msgstr ""वर्गीकरण ओळख क्रमांक:"" msgid ""Network Details"" msgstr ""नेटवर्कचे तपशील"" msgid ""Subnet Overview"" msgstr ""उपनेट आढावा"" msgid ""IP version"" msgstr ""आयपी आवृत्ती"" msgid ""IP allocation pool"" msgstr ""आयपी वितरण गट "" msgid ""Start"" msgstr ""सुरु"" msgid "" - End"" msgstr ""-समाप्त"" msgid ""DHCP Enable"" msgstr ""डीएचसीपी समर्थ"" msgid ""IPv6 Address Configuration Mode"" msgstr ""आयपीव्ही६ पत्ता मांडणी पद्धत"" #, python-format msgid """" ""\n"" "" Other IPv6 modes: ipv6_ra_mode=%(ra_mode)s, ipv6_address_mode="" ""%(addr_mode)s\n"" "" "" msgstr """" ""\n"" "" इतर आयपीव्ही६ पद्धती: ipv6_ra_mode=%(ra_mode)s, ipv6_address_mode="" ""%(addr_mode)s\n"" "" "" msgid ""Additional routes"" msgstr ""अतिरिक्त मार्ग"" msgid ""Destination"" msgstr ""इच्छित ठिकाण"" msgid "" : Next hop"" msgstr "" : पुढील उडी"" msgid ""DNS name server"" msgstr ""डीएनएस नाव सर्वर"" msgid ""Unable to retrieve network details."" msgstr ""नेटवर्कचे तपशील मिळविण्यास असमर्थ."" msgid ""The state to start the network in."" msgstr ""च्यामध्ये नेटवर्क सुरु करण्याची स्थिती."" msgid ""Subnet Name"" msgstr ""उपनेटचे नाव"" msgid ""Network address in CIDR format (e.g. 192.168.0.0/24, 2001:DB8::/48)"" msgstr ""नेटवर्क पत्ता सीआयडीआर प्रारुपामध्ये (उदा. १९२.१६८.०.०/२४, २००१:डीबी८::/४८)"" msgid """" ""IP address of Gateway (e.g. 192.168.0.254) The default value is the first IP "" ""of the network address (e.g. 192.168.0.1 for 192.168.0.0/24, 2001:DB8::1 for "" ""2001:DB8::/48). If you use the default, leave blank. If you do not want to "" ""use a gateway, check 'Disable Gateway' below."" msgstr """" ""गेटवेचा आयपी पत्ता (उदा. १९२.१६८.०.२५४) पूर्वनिर्धारित मूल्य आहे नेटवर्क पत्त्याचा पहिला "" ""आयपी (उदा. १९२.१६८.०.१ साठी १९२.१६८.०.०/२४, २००१:डीबी८::१ साठी २००१:"" ""डीबी८::/४८). तुम्ही पूर्वनिर्धारित वापरल्यास, रिक्त सोडा. तुम्हाला गेटवे वापरायचा नसेल, "" ""खालील 'गेटवे असमर्थ करा' तपासा."" msgid ""Specify \""Network Address\"" or clear \""Create Subnet\"" checkbox."" msgstr ""नमूद करा \""नेटवर्क पत्ता\"" किंवा पुसून टाका \""उपनेट तयार करा\"" तपासचौकट."" msgid """" ""Create a subnet associated with the new network, in which case \""Network "" ""Address\"" must be specified. If you wish to create a network without a "" ""subnet, uncheck the \""Create Subnet\"" checkbox."" msgstr """" ""नवीन नेटवर्कशी संबंधित उपनेट तयार करा, ज्यामध्ये \""नेटवर्क पत्ता\"" नमूद केला पाहिजे. "" ""तुम्हाला उपनेटशिवाय एखादे नेटवर्क तयार करायचे असेल, तर चौकटीतील \""उपनेट तयार करा\"" "" ""बरोबरची खूण रद्द करा."" msgid ""Network Address and IP version are inconsistent."" msgstr ""नेटवर्क पत्ता व आयपी आवृत्तीमध्ये सातत्य नाही"" #, python-format msgid ""The subnet in the Network Address is too small (/%s)."" msgstr ""नेटवर्क पत्त्यातील उपनेट अतिशय लहान आहे (/%s)."" msgid ""Gateway IP and IP version are inconsistent."" msgstr ""गेटवे आयपी व आयपी आवृत्तीमध्ये सातत्य नाही."" msgid ""Specify IP address of gateway or check \""Disable Gateway\""."" msgstr ""गेटवेचा आयपी पत्ता नमूद करा किंवा \""गेटवे असमर्थ करा\"" वर बरोबरची खूण करा."" msgid ""Enable DHCP"" msgstr ""डीएचसीपी समर्थ करा"" msgid """" ""Specifies how IPv6 addresses and additional information are configured. We "" ""can specify SLAAC/DHCPv6 stateful/DHCPv6 stateless provided by OpenStack, or "" ""specify no option. 'No options specified' means addresses are configured "" ""manually or configured by a non-OpenStack system."" msgstr """" ""आयपीव्ही६ व अतिरिक्त माहितीची कशी मांडणी केली जाईल हे नमूद करते. आपण एसएलएएसी/"" ""डीएचसीपीव्ही६ स्थितीपूर्ण/डीएचसीपीव्ही६ स्थितीरहित ओपनस्टेकद्वारे देण्यात आलेले नमूद करु "" ""शकतो, किंवा कोणताही पर्याय नसल्याचे नमूद करु शकतो. 'कोणतेही पर्याय नमूद नाहीत' म्हणजे "" ""पत्त्यांची हाताने मांडणी करण्यात आली आहे किंवा बिगर-ओपनस्टेक यंत्रणेद्वारे मांजणी करण्यात आली "" ""आहे."" msgid ""Allocation Pools"" msgstr ""वितरण गट"" msgid """" ""IP address allocation pools. Each entry is: start_ip_address,end_ip_address "" ""(e.g., 192.168.1.100,192.168.1.120) and one entry per line."" msgstr """" ""आयपी पत्ता वितरण गट. प्रत्येक नोंद आहे: सुरुवात_आयपी_पत्ता,समाप्त_आयपी_पत्ता (उदा., "" ""१९२.१६८.१.१००,१९२.१६८.१.१२०) व एका ओळीवर एक नोंद."" msgid ""DNS Name Servers"" msgstr ""डीएनएस नाव सर्वर"" msgid """" ""IP address list of DNS name servers for this subnet. One entry per line."" msgstr ""या उपनेटसाठी डीएनएस नाव सर्वरची आयपी पत्ता यादी. केवळ एका ओळीवर एक नोंद."" msgid ""Host Routes"" msgstr ""होस्ट मार्ग"" msgid """" ""Additional routes announced to the hosts. Each entry is: destination_cidr,"" ""nexthop (e.g., 192.168.200.0/24,10.56.1.254) and one entry per line."" msgstr """" ""होस्टसाठी घोषित अतिरिक्त मार्ग. प्रत्येक प्रवेश आहे: लक्ष्य_सीआयडीआर,पुढीलउडी (उदा., "" ""१९२.१६८.२००.०/२४,१०.५६.१.२५४) व एका ओळीवर एक नोंद."" #, python-format msgid ""%s (Default)"" msgstr ""%s (पूर्वनिर्धारित)"" #, python-format msgid ""%(field_name)s: Invalid IP address (value=%(ip)s)"" msgstr ""%(field_name)s: अवैध आयपी पत्ता (value=%(ip)s)"" #, python-format msgid ""%(field_name)s: Invalid IP address (value=%(network)s)"" msgstr ""%(field_name)s: अवैध आयपी पत्ता (value=%(network)s)"" #, python-format msgid ""Start and end addresses must be specified (value=%s)"" msgstr ""सुरुवात व समाप्तीचा पत्ते नमूद केले पाहिजेत (मूल्य=%s)"" #, python-format msgid ""Start address is larger than end address (value=%s)"" msgstr ""सुरुवात पत्ता समाप्तीच्या पत्त्यापेक्षा मोठा आहे (मूल्य=%s)"" #, python-format msgid """" ""Host Routes format error: Destination CIDR and nexthop must be specified "" ""(value=%s)"" msgstr ""होस्ट मार्ग प्रारुप चूक: लक्ष्य सीआयडीआर व पुढील उडी स्पष्ट केली पाहिजे (मूल्य=%s)"" #, python-format msgid ""Created network \""%s\""."" msgstr ""तयार केलेले नेटवर्क \""%s\""."" #, python-format msgid ""Unable to create network \""%s\""."" msgstr ""नेटवर्क तयार करण्यास असमर्थ \""%s\""."" #, python-format msgid ""Network \""%s\"" was successfully created."" msgstr ""नेटवर्क \""%s\"" यशस्वीपणे तयार करण्यात आले."" #, python-format msgid ""Failed to create network \""%(network)s\"": %(reason)s"" msgstr ""नेटवर्क तयार करण्यात अपयशी \""%(network)s\"": %(reason)s"" #, python-format msgid ""Subnet \""%s\"" was successfully created."" msgstr ""उपनेट \""%s\"" यशस्वीपणे तयार करण्यात आले."" #, python-format msgid """" ""Failed to create subnet \""%(sub)s\"" for network \""%(net)s\"": %(reason)s"" msgstr ""उपनेट तयार करण्यास अपयशी \""%(sub)s\"" नेटवर्कसाठी \""%(net)s\"": %(reason)s"" #, python-format msgid ""Delete the created network \""%s\"" due to subnet creation failure."" msgstr ""तयार केलेली नेटवर्क नष्ट करा \""%s\"" उपनेट निर्मिती अपयशी झाल्यामुळे."" #, python-format msgid ""Failed to delete network \""%s\"""" msgstr ""नेटवर्क नष्ट करण्यात अपयशी \""%s\"""" msgid ""Destination CIDR"" msgstr ""लक्ष्य सीआयडीआर"" msgid ""Unable to retrieve router."" msgstr ""राउटर मिळविण्यास असमर्थ."" msgid ""Input must be in CIDR format"" msgstr ""टंकलेखन सीआयडीआर प्रारुपात असले पाहिजे"" msgid ""Source CIDR"" msgstr ""स्रोत सीआयडीआर"" msgid ""Optional: Next Hop Addresses (comma delimited)"" msgstr ""ऐच्छिक: पुढील उडीचे पत्ते (स्वल्पविरामाने सीमांकन करण्यात आलेले)"" msgid ""Router ID"" msgstr ""राउटर ओळख क्रमांक"" msgid ""Permit"" msgstr ""परवाना"" msgid ""Deny"" msgstr ""अमान्य करा"" msgid ""Unable to delete router rule."" msgstr ""राउटर नियम नष्ट करण्यास असमर्थ."" msgid ""Router rule added"" msgstr ""राउटर नियम समाविष्ट"" #, python-format msgid ""Failed to add router rule %s"" msgstr ""राउटल नियम समाविष्ट करण्यात अपयशी %s"" msgid ""Add Router Rule"" msgstr ""राउटर नियम समाविष्ट करा"" msgid ""Next Hops"" msgstr ""सर्वात जवळचा पुढील राउटर"" msgid ""Router Rules"" msgstr ""राउटरचे नियम"" msgid ""Router Rules Grid"" msgstr ""राउटर नियम जाळे"" msgid ""Router Name"" msgstr ""राउटर नाव"" msgid ""Router Type"" msgstr ""राउटर प्रकार"" msgid ""High Availability Mode"" msgstr ""उच्च उपलब्धता पद्धत"" msgid ""Use Server Default"" msgstr ""सर्वर पूर्वनिर्धारित वापरा"" msgid ""Centralized"" msgstr ""केंद्रीय"" msgid ""Distributed"" msgstr ""वितरित"" msgid ""Enable HA mode"" msgstr ""एचए पद्धत समर्थ करा"" msgid ""Disable HA mode"" msgstr ""एचए पद्धत असमर्थ"" msgid ""Select network"" msgstr ""नेटवर्क निवडा"" #, python-format msgid ""Router %s was successfully created."" msgstr ""राउटर %s यशस्वीपणे तयार करण्यात आला."" msgid ""Quota exceeded for resource router."" msgstr ""स्रोत राउटरसाठी वाटा समाप्त."" #, python-format msgid ""Failed to create router \""%s\""."" msgstr ""राउटर तयार करण्यात अपयशी \""%s\""."" #, python-format msgid ""Router %s was successfully updated."" msgstr ""राउटर %s यशस्वीपण सुधारित करण्यात आला."" #, python-format msgid ""Failed to update router %s"" msgstr ""राउटर सुधारित करण्यास अपयशी %s"" msgid ""IP Address (optional)"" msgstr ""आयपी पत्ता (ऐच्छिक)"" msgid ""Specify an IP address for the interface created (e.g. 192.168.0.254)."" msgstr ""तयार करण्यात आलेल्या आंतरपृष्ठासाठी आयपी पत्ता नमूद करा (उदा. १९२.१६८.०.२५४)."" #, python-format msgid ""Failed to get network list %s"" msgstr ""नेटवर्क यादी मिळविण्यात अपयशी %s"" msgid ""Select Subnet"" msgstr ""उपनेट निवडा"" msgid ""No subnets available"" msgstr ""कोणतीही उपनेट उपलब्ध नाही"" msgid ""Interface added"" msgstr ""आंतरपृष्ट समाविष्ट"" #, python-format msgid ""Unable to get subnet \""%s\"""" msgstr ""उपनेट समाविष्ट करण्यास असमर्थ \""%s\"""" #, python-format msgid ""Failed to add_interface: %s"" msgstr ""आंतरपृष्ठ_समाविष्ट करण्यास अपयशी: %s"" #, python-format msgid ""Failed to delete port %s"" msgstr ""पोर्ट नष्ट करण्यात अपयशी %s"" msgid ""Gateway interface is added"" msgstr ""गेटवे आंतरपृष्ट समाविष्ट आहे"" #, python-format msgid ""Failed to set gateway %s"" msgstr ""गेटवेची रचना करण्यास अपयशी %s"" msgid ""External Gateway"" msgstr ""बाह्य गेटवे"" msgid ""Internal Interface"" msgstr ""अंतर्गत आंतरपृष्ठ"" msgid ""Add Interface"" msgstr ""आंतरपृष्ट समाविष्ट करा"" #, python-format msgid ""Failed to delete interface %s"" msgstr ""आंतरपृष्ट नष्ट करण्यास अपयशी %s"" msgctxt ""current status of port"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""current status of port"" msgid ""Build"" msgstr ""बांधणी"" msgctxt ""current status of port"" msgid ""Down"" msgstr ""खाली"" msgctxt ""current status of port"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgid ""Set Gateway"" msgstr ""गेटवेची रचना करा"" msgid ""Unable to set gateway."" msgstr ""गेटवेची रचना करण्यास असमर्थ."" #, python-format msgid ""Unable to delete router \""%s\"""" msgstr ""राउटर नष्ट करु शकत नाही \""%s\"""" msgid ""Edit Router"" msgstr ""राउटर संपादित करा"" #, python-format msgid ""Unable to clear gateway for router \""%(name)s\"": \""%(msg)s\"""" msgstr ""राउटरसाठी गेटवे पुसण्यास असमर्थ \""%(name)s\"": \""%(msg)s\"""" msgctxt ""current status of router"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""current status of router"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" #. Translators: High Availability mode of Neutron router msgid ""HA mode"" msgstr ""एचए पद्धत"" msgid ""You may update the editable properties of your router here."" msgstr ""तुम्ही इथे तुमच्या राउटरच्या संपादन करण्यायोग्य वैशिष्ट्यांमध्ये सुधारणा करु शकता."" msgid """" ""Routing rules to apply to router. Rules are matched by most specific source "" ""first and then by most specific destination."" msgstr """" ""राउटरसाठी वापरायचे मार्गक्रमण नियम. नियम प्रथम सर्वात नेमक्या स्रोताशी व त्यानंतर "" ""सर्वात विशिष्ट ठिकाणाशी जुळवले जातात."" msgid """" ""The next hop addresses can be used to override the router used by the client."" msgstr ""पुढील ठिकाणाचा पत्ता ग्राहकाद्वारे राउटरचे उल्लंघन करण्यासाठी वापरला जाऊ शकतो."" msgid ""Add rule"" msgstr ""नियम समाविष्ट करा"" msgid ""Router Rule Grid"" msgstr ""राउटर नियम जाळे"" msgid ""Reset to Default"" msgstr ""पूर्वनिर्धारितवर पुनर्रचना करा"" msgid ""Source"" msgstr ""स्रोत"" #, python-format msgid ""Subnet: %(dest_subnetname)s"" msgstr ""उपनेट: %(dest_subnetname)s"" #, python-format msgid ""Subnet: %(row_source_subnetname)s"" msgstr ""उपनेट: %(row_source_subnetname)s"" msgid ""Rule Conflict"" msgstr ""नियम संघर्ष"" msgid """" ""A more specific rule affects a portion of this traffic so a rule cannot be "" ""automatically generated to control the behavior of the entire source/"" ""destination combination."" msgstr """" ""अधिक विशिष्ट नियम या रहदारीच्या भागावर परिणाम करतो त्यामुळे संपूर्ण स्रोत/इच्छित ठिकाण "" ""जोडीचे वर्तन नियंत्रित करण्यासाठी नियम स्वयंचलितपणे तयार करता येत नाही."" msgid ""Conflicting Rule"" msgstr ""परस्परविरोधी नियम"" msgid ""Source:"" msgstr ""स्रोत:"" msgid ""Destination:"" msgstr ""इच्छित ठिकाण:"" msgid ""Action:"" msgstr ""कृती:"" msgid """" ""The color and icon of an intersection indicates whether or not traffic is "" ""permitted from the source (row) to the destination (column).\n"" "" Clicking the <i class=\""fa fa-random\""></i> button in the intersection "" ""will install a rule to switch the traffic behavior.<br/>\n"" ""\n"" "" <b>Note:</b> Rules only affect one direction of traffic. The opposite "" ""direction is outlined when hovering over an intersection.\n"" "" "" msgstr """" ""छेदनबिंदूचा रंग व चित्र स्रोताकडून (ओळ) इच्छित ठिकाणाकडे (स्तंभ) रहदारीला परवानी आहे "" ""किंवा नाही हे दर्शवतात.\n"" "" छेदनबिंदूवरील<i वर्ग=\""फा फा- स्वै\""></i> बटण क्लिक केल्याने रहदारीचे वर्तन बदलणारा "" ""नियम स्थापित केला जाईल.<br/>\n"" ""\n"" "" <b>नोंद घ्या:</b> नियम रहदारीच्या केवळ एका दिशेवर परिणाम करतात. एका छेदनबिंदूवर "" ""तरंगताना विरुद्ध दिशेची रुपरेखा तयार केली जाते.\n"" "" "" msgid ""You can connect a specified subnet to the router."" msgstr ""तुम्ही राउटरच्या विशिष्ट उपनेटशी संपर्क साधू शकता."" msgid """" ""The default IP address of the interface created is a gateway of the selected "" ""subnet. You can specify another IP address of the interface here. You must "" ""select a subnet to which the specified IP address belongs to from the above "" ""list."" msgstr """" ""तयार केलेल्या आंतरपृष्ठाचा पूर्वनिर्धारित आयपी पत्ता निवडलेल्या उपनेटचा गेटवे आहे. तुम्ही येथे "" ""इंटरफेसचा आणखी एक आयपी पत्ता नमूद करु शकता. तुम्ही एक उपनेट निवडले पाहिजे ज्यामध्ये वरील "" ""यादीमधून विनिर्दिष्ट आयपी पत्ता आहे."" msgid ""Add interface"" msgstr ""आंतरपृष्ट समाविष्ट करा"" msgid """" ""You can connect a specified external network to the router. The external "" ""network is regarded as a default route of the router and the router acts as "" ""a gateway for external connectivity."" msgstr """" ""तुम्ही राउटरशी विनिर्दिष्ट बाह्य नेटवर्क जोडू शकता. बाह्य नेटवर्क राउटरचा पूर्वनिर्धारित "" ""मार्ग मानले जाते व राउटर बाह्य जोडणीसाठी गेटवे म्हणून कार्य करतो."" #, python-format msgid ""Unable to retrieve a list of external networks \""%s\""."" msgstr ""बाह्य नेटवर्कची यादी मिळविण्यास असमर्थ \""%s\""."" #, python-format msgid """" ""External network \""%(ext_net_id)s\"" expected but not found for router "" ""\""%(router_id)s\""."" msgstr """" ""बाह्य नेटवर्क \""%(ext_net_id)s\"" अपेक्षित मात्र राउटरसाठी सापडले नाहीत "" ""\""%(router_id)s\""."" #. Translators: The usage is ""<UUID of ext_net> (Not Found)"" #, python-format msgctxt ""External network not found"" msgid ""%s (Not Found)"" msgstr ""%s (सापडले नाही)"" #, python-format msgid ""Unable to retrieve details for router \""%s\""."" msgstr ""राउटरसाठी तपशील मिळविण्यास असमर्थ \""%s\""."" #, python-format msgid ""Unable to retrieve an external network \""%s\""."" msgstr ""एक बाह्य नेटवर्क मिळविण्यास असमर्थ \""%s\""."" msgid ""Unable to retrieve router details."" msgstr ""राउटर तपशील मिळविण्यास असमर्थ."" msgid ""Select Template"" msgstr ""साचा निवडा"" msgid ""Select a template to launch a stack."" msgstr ""मर्यादित डाटा रचना सुरु करण्यासाठी एक साचा निवडा."" msgid ""Template Source"" msgstr ""साचा स्रोत"" msgid ""Template File"" msgstr ""साचा धारिका"" msgid ""A local template to upload."" msgstr ""अपलोड करण्यासाठी स्थानिक साचा."" msgid ""Template URL"" msgstr ""साचा यूआरएल"" msgid ""An external (HTTP) URL to load the template from."" msgstr ""साचा उघडण्यासाठी बाह्य (एचटीटीपी) यूआरएल."" msgid ""Template Data"" msgstr ""साचा डाटा"" msgid ""The raw contents of the template."" msgstr ""साच्याचे कच्चे घटक."" msgid ""Environment Source"" msgstr ""पर्यावरण स्रोत"" msgid ""Environment File"" msgstr ""पर्यावरण धारिका"" msgid ""A local environment to upload."" msgstr ""अपलोड करण्यासाठी स्थानिक पर्यावरण."" msgid ""Environment Data"" msgstr ""पर्यावरण डाटा"" msgid ""The raw contents of the environment file."" msgstr ""पर्यावरण धारिकेचे कच्चे घटक."" msgid ""template"" msgstr ""साचा"" msgid ""environment"" msgstr ""पर्यावरण"" #, python-format msgid ""Please specify a %s using only one source method."" msgstr ""कृपया नमूद करा %s केवळ एक स्रोत पद्धत वापरुन."" msgid ""You must specify a template via one of the available sources."" msgstr ""तुम्ही उपलब्ध स्रोतांपैकी एकाद्वारे एक साचा नमूद केला पाहिजे."" msgid ""Edit Template"" msgstr ""साचा संपादित करा"" msgid ""Select a new template to re-launch a stack."" msgstr ""मर्यादित डाटा रचना पुन्हा सुरु करण्यासाठी एक नवीन साचा निवडा."" msgid ""Stack ID"" msgstr ""मर्यादित डाटा रचना ओळख क्रमांक "" msgid ""Stack Name"" msgstr ""मर्यादित डाटा रचना नाव"" msgid ""Create Stack"" msgstr ""मर्यादित डाटा रचना तयार करा"" msgid ""Name of the stack to create."" msgstr ""तयार करायच्या मर्यादित डाटा रचनेचे नाव."" msgid """" ""Name must start with a letter and may only contain letters, numbers, "" ""underscores, periods and hyphens."" msgstr """" ""नाव अक्षराने सुरु झाले पाहिते व त्यामध्ये केवळ अक्षरे, संख्या, अधोरेखा, कालावधी व संयोगचिन्हे "" ""असू शकतात."" msgid ""Creation Timeout (minutes)"" msgstr ""निर्मिती वेळ संपली (मिनिटे)"" msgid ""Stack creation timeout in minutes."" msgstr ""मर्यादित डाटा रचना निर्मिती वेळ संपली मिनिटांमध्ये."" msgid ""Rollback On Failure"" msgstr ""अपयश परतवणे"" msgid ""Enable rollback on create/update failure."" msgstr ""अपयश निर्मिती/सुधारणा परतवणे समर्थ करा."" #, python-format msgid ""Password for user \""%s\"""" msgstr ""वापरकर्त्यांसाठी पासवर्ड \""%s\"""" msgid """" ""This is required for operations to be performed throughout the lifecycle of "" ""the stack"" msgstr ""मर्यादित डाटा रचनेच्या संपूर्ण जीवनचक्रात संचालन करण्यासाठी हे आवश्यक असते"" msgid ""Stack creation started."" msgstr ""मर्यादित डाटा रचना निर्मिती सुरु."" msgid ""Update Stack Parameters"" msgstr ""मर्यादित डाटा रचना निर्देशांक सुधारित करा"" msgid ""Stack update started."" msgstr ""मर्यादित डाटा रचना सुधारणा सुरु."" msgid ""Stacks"" msgstr ""मर्यादित डाटा रचना"" msgid ""Resource"" msgstr ""संसाधन"" msgid ""Launch Stack"" msgstr ""मर्यादित डाटा रचना सुरु करा"" msgid ""Change Stack Template"" msgstr ""मर्यादित डाटा रचना साचा बदला"" msgid ""Stack Resource"" msgstr ""मर्यादित डाटा रचना संसाधन"" msgid ""Time Since Event"" msgstr ""घटनेपासूनचा कालावधी"" msgid ""Status Reason"" msgstr ""स्थिती कारण"" msgid ""Stack Events"" msgstr ""मर्यादित डाटा रचना घटना"" msgid ""Stack Resource Type"" msgstr ""मर्यादित डाटा रचना संसाधन प्रकार"" msgid ""Date Updated"" msgstr ""तारीख सुधारित"" msgid ""Stack Resources"" msgstr ""मर्यादित डाटा रचना संसाधने"" msgid ""Topology"" msgstr ""रचना अभ्यास"" msgid ""Events"" msgstr ""घटना"" #, python-format msgid ""Unable to get events for stack \""%s\""."" msgstr ""मर्यादित डाटा रचनेसाठी घटना मिळविण्यास असमर्थ \""%s\""."" msgid ""Resources"" msgstr ""संसाधने"" #, python-format msgid ""Unable to get resources for stack \""%s\""."" msgstr ""मर्यादित डाटा रचनेसाठी संसाधने मिळविण्यास असमर्थ \""%s\""."" msgid """" ""Use one of the available template source options to specify the template to "" ""be used in creating this stack."" msgstr """" ""ही मर्यादित डाटा रचना तयार करण्यासाठी वापरायचा साचा नमूद करण्यासाठी उपलब्ध साचा "" ""स्रोत पर्यायांपैकी एक वापरा."" msgid ""Create a new stack with the provided values."" msgstr ""दिलेल्या मूल्यांसह नवीन मर्यादित डाटा रचना तयार करा."" msgid ""Stack Overview"" msgstr ""मर्यादित डाटा रचना आढावा"" #, python-format msgid ""%(stack_status_title)s: %(stack_status_reason)s"" msgstr ""%(stack_status_title)s: %(stack_status_reason)s"" msgid ""Outputs"" msgstr ""उत्पादने"" msgid ""Stack Parameters"" msgstr ""मर्यादित डाटा रचना निर्देशांक"" msgid ""Launch Parameters"" msgstr ""सुरु करण्याचे निर्देशांक"" msgid ""Minutes"" msgstr ""मिनिटे"" msgid ""Rollback"" msgstr ""परतवणे"" msgid ""Resource Overview"" msgstr ""संसाधन आढावा"" msgid ""Stack Resource ID"" msgstr ""मर्यादित डाटा रचना संसाधन ओळख क्रमांक"" msgid ""Resource ID"" msgstr ""संसाधन ओळख क्रमांक"" #, python-format msgid ""%(resource_status)s: %(resource_status_reason)s"" msgstr ""%(resource_status)s: %(resource_status_reason)s"" msgid ""Resource Metadata"" msgstr ""संसाधन मेटाडाटा"" msgid ""Stack Template"" msgstr ""मर्यादित डाटा रचना साचा"" msgid """" ""Update a stack with the provided values. Please note that any encrypted "" ""parameters, such as passwords, will be reset to default if you do not change "" ""them here."" msgstr """" ""दिलेल्या मूल्यांसह मर्यादित डाटा रचना सुधारित करा. पासवर्डेसारखे कोणतेही सांकेतिक "" ""निर्देशांक, तुम्ही ते इथे बदलले नाही तर त्यांची पूर्वनिर्धारित पुनर्रचना केली जाईल."" msgid ""Change Template"" msgstr ""साचा बदला"" msgid ""Stack Details"" msgstr ""मर्यादित डाटा रचना"" msgid ""Resource Details"" msgstr ""संसाधन तपशील"" msgid ""Unable to retrieve stack list."" msgstr ""मर्यादित डाटा रचना यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve stack."" msgstr ""मर्यादित डाटा रचना मिळविण्यास असमर्थ"" msgid ""Update"" msgstr ""सुधारणा"" msgid ""Update Stack"" msgstr ""मर्यादित डाटा रचना सुधारणा करा"" msgid ""Unable to retrieve stack template."" msgstr ""मर्यादित डाटा रचना साचा मिळविण्यास असमर्थ."" msgid ""Unable to retrieve resource."" msgstr ""संसाधन मिळविण्यास असमर्थ."" msgid ""Unable to retrieve metadata."" msgstr ""मेटाडाटा मिळविण्यास असमर्थ."" #, python-format msgid ""Creating volume backup \""%s\"""" msgstr ""खंड राखीव साठा तयार करत आहे \""%s\"""" msgid ""Unable to create volume backup."" msgstr ""खंड राखीव साठा तयार करण्यास असमर्थ."" msgid ""Unable to lookup volume or backup information."" msgstr ""खंड किंवा राखीव साठा माहिती शोधण्यास असमर्थ."" msgid ""Create a New Volume"" msgstr ""नवीन खंड तयार करा"" #, python-format msgid """" ""Successfully restored backup %(backup_name)s to volume with id: %(volume_id)s"" msgstr """" ""राखीव साठा यशस्वीपणे %(backup_name)s खंडामध्ये पुनर्स्थापित केला ओळखक्रमांकासह: "" ""%(volume_id)s"" msgid ""Unable to restore backup."" msgstr ""राखीव साठा पुनर्स्थापित करण्यास असमर्थ."" msgid ""Volume Backup"" msgstr ""खंड राखीव साठा"" msgid ""Volume Backups"" msgstr ""खंड राखीव साठे"" #, python-format msgid ""Scheduled deletion of %(data_type)s"" msgstr ""नियोजितपणे नष्ट करणे %(data_type)s"" msgctxt ""Current status of a Volume Backup"" msgid ""Available"" msgstr ""उपलब्ध"" msgctxt ""Current status of a Volume Backup"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of a Volume Backup"" msgid ""Creating"" msgstr ""तयार करत आहे"" msgctxt ""Current status of a Volume Backup"" msgid ""Restoring"" msgstr ""पुनर्स्थापित करत आहे"" msgctxt ""Current status of a Volume Backup"" msgid ""Deleting"" msgstr ""नष्ट करत आहे"" msgid ""Unable to retrieve backup details."" msgstr ""राखीव साठा तपशील मिळविण्यास असमर्थ."" msgid ""Create Volume Backup"" msgstr ""खंड राखीव साठा तयार करा"" msgid ""Create a Volume Backup"" msgstr ""खंड राखीव साठा तयार करा"" msgid ""Restore Volume Backup"" msgstr ""खंड राखीव साठा पुनर्स्थापित करा"" msgid ""Restore Backup to Volume"" msgstr ""खंडामध्ये राखीवसाठा पुनर्स्थापित करा"" msgid ""Restore a Volume Backup"" msgstr ""खंड राखीव साठा पुनर्स्थापित करा"" #, python-format msgid ""Updating volume snapshot \""%s\"""" msgstr ""खंड क्षणचित्र सुधारित करत आहे\""%s\"""" msgid ""Unable to update volume snapshot."" msgstr ""खंड क्षणचित्र सुधारित करण्यास असमर्थ."" msgid ""Edit Snapshot"" msgstr ""क्षणचित्र संपादित करा"" msgid ""Unable to retrieve snapshot details."" msgstr ""क्षणचित्र तपशील मिळविण्यास असमर्थ."" msgid ""Unable to retrieve volume list."" msgstr ""खंड यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve volume/instance attachment information"" msgstr ""खंड/घटक जोडणी माहिती मिळविण्यास असमर्थ"" msgid ""Unable to retrieve snapshot list."" msgstr ""क्षणचित्र यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve volume backups."" msgstr ""खंड राखीवसाठे मिळविण्यास असमर्थ."" msgid ""Volume Backup:"" msgstr ""खंड राखीव साठा:"" msgid """" ""Volume Backups are stored using the Object Storage service. You must have "" ""this service activated in order to create a backup."" msgstr """" ""घटक संग्रह सेवा वापरुन खंड राखीव साठे संग्रहित केले जातात. राखीव साठा तयार करण्यासाठी "" ""तुम्ही ही सेवा सक्रिय केली पाहिजे."" msgid """" ""If no container name is provided, a default container named volumebackups "" ""will be provisioned for you. Backups will be the same size as the volume "" ""they originate from."" msgstr """" ""पात्राचे नाव देण्यात आले नसेल, तर एक खंड राखीवसाठे नावाच्या पूर्वनिर्धारित पात्राची "" ""तुमच्यासाठी तरतूद केली जाईल. राखीव साठे ज्या खंडातून तयार झाले त्याच आकाराचे असतील."" #, python-format msgid ""Volume Backup Overview: %(backup_display_name)s"" msgstr ""खंड राखीव साठा आढावा: %(backup_display_name)s"" msgid ""Restore Backup:"" msgstr ""राखीव साठा पुनर्स्थापित करा:"" msgid ""Select a volume to restore to."" msgstr ""च्यामध्ये पुनर्स्थापित करण्यासाठी एक खंड निवडा."" msgid ""Optionally, you may choose to create a new volume."" msgstr ""तुम्हाला नवीन खंड तयार करण्याची निवड करण्याचा पर्यायही असेल."" msgid ""Volume Backup Details"" msgstr ""खंड राखीव साठा तपशील"" msgid ""Modify the name and description of a snapshot."" msgstr ""क्षणचित्राचे नाव व वर्णन सुधारित करा."" msgid ""Volume Snapshot Details"" msgstr ""खंड क्षणचित्र तपशील."" msgid ""Attach To Instance"" msgstr ""घटकाला जोडा"" msgid ""Attach Volume"" msgstr ""खंड जोडा"" msgid ""Create Volume Snapshot (Force)"" msgstr ""खंड क्षणचित्र तयार करा (सक्ती)"" msgid ""Create Volume Snapshot"" msgstr ""खंड क्षणचित्र तयार करा"" msgid ""Volume Overview"" msgstr ""खंड आढावा"" msgid ""Attachments"" msgstr ""पुरवण्या"" msgid ""Not attached"" msgstr ""जोडलेले नाहीत"" msgid ""Volume Source"" msgstr ""खंड स्रोत"" msgid ""Extend the size of a volume."" msgstr ""खंडाचा आकार विस्तारित करा."" msgid ""Volume Limits"" msgstr ""खंड मर्यादा"" msgid ""Total Gigabytes"" msgstr ""एकूण गिगाबाईट्स"" msgid ""Volumes are block devices that can be attached to instances."" msgstr ""खंड ही गट साधने असतात जी घटकांना जोडता येतात."" msgid ""Number of Volumes"" msgstr ""खंडांची संख्या"" msgid ""From here you can create a snapshot of a volume."" msgstr ""येथून तुम्ही खंडाचे क्षणचित्र तयार करु शकता."" msgid ""Snapshot Limits"" msgstr ""क्षणचित्र मर्यादा"" msgid ""Number of Snapshots"" msgstr ""क्षणचित्रांची संख्या"" msgid ""Modify name and description of a volume."" msgstr ""खंडाचे नाव व वर्णनात सुधारणा करा."" msgid ""Manage Volume Attachments"" msgstr ""खंड पुरवणी व्यवस्थापन करा"" msgid ""Extend Volume"" msgstr ""खंड विस्तार करा"" msgid ""Change Volume Type"" msgstr ""खंड प्रकार बदला"" msgid ""Edit Volume"" msgstr ""खंड संपादित करा"" msgid ""Upload Volume to Image"" msgstr ""चित्रामध्ये खंड अपलोड करा"" msgid ""Unable to determine if availability zones extension is supported."" msgstr ""उपलब्धता विभाग विस्तारास सहाय्य आहे किंवा नाही हे निश्चित करण्यास असमर्थ."" msgid ""Use snapshot as a source"" msgstr ""क्षणचित्र स्रोत म्हणून वापरा"" msgid ""Use image as a source"" msgstr ""चित्र स्रोत म्हणून वापरा"" msgid ""Use a volume as source"" msgstr ""खंड स्रोत म्हणून वापरा"" msgid ""Size (GB)"" msgstr ""आकार (जीबी)"" #, python-format msgid ""Volume size must be equal to or greater than the snapshot size (%sGB)"" msgstr ""खंड आकार क्षणचित्र आकाराऐवढा किंवा त्यापेक्षा मोठा असला पाहिजे (%sजीबी)"" msgid ""Unable to load the specified snapshot."" msgstr ""विनिर्दिष्ट क्षणचित्र लोड करण्यास असमर्थ."" #, python-format msgid ""Volume size must be equal to or greater than the image size (%s)"" msgstr ""खंड आकार चित्र आकाराऐवढा किंवा त्यापेक्षा मोठा असू शकतो (%s)"" #, python-format msgid """" ""Volume size must be equal to or greater than the image minimum disk size "" ""(%sGB)"" msgstr ""खंड आकार चित्र किमान डिस्क आकाराऐवढा किंवा मोठा असला पाहिजे (%sजीबी)"" #, python-format msgid ""Unable to load the specified image. %s"" msgstr ""विनिर्दिष्ट चित्र लोड करण्यास असमर्थ. %s"" #, python-format msgid ""Unable to load the specified volume. %s"" msgstr ""विनिर्दिष्ट खंड लोड करण्यास असमर्थ. %s"" #, python-format msgid """" ""Volume size must be equal to or greater than the origin volume size (%s)"" msgstr ""खंड आकार मूळ खंड आकाराऐवढा किंवा त्यापेक्षा अधिक मोठा असला पाहिजे (%s)"" msgid ""Choose a snapshot"" msgstr ""एक क्षणचित्र निवडा"" msgid ""Choose an image"" msgstr ""एक चित्र निवडा"" msgid ""Choose a volume"" msgstr ""एक खंड निवडा"" msgid ""No source, empty volume"" msgstr ""कोणताही स्रोत नाही, रिक्त खंड"" msgid ""Image source must be specified"" msgstr ""चित्र स्रोत नमूद केला पाहिजे"" msgid ""Snapshot source must be specified"" msgstr ""क्षणचित्र स्रोत नमूद केला पाहिजे"" msgid ""Volume source must be specified"" msgstr ""खंड स्रोत नमूद केला पाहिजे"" #, python-format msgid ""The volume size cannot be less than the snapshot size (%sGB)"" msgstr ""खंड आकार क्षणचित्र आकारापेक्षा कमी असू शकत नाही (%sजीबी)"" #, python-format msgid ""The volume size cannot be less than the image size (%s)"" msgstr ""खंड आकार चित्र आकारापेक्षा कमी असू शकत नाही (%s)"" #, python-format msgid ""The volume size cannot be less than the image minimum disk size (%sGB)"" msgstr ""खंड आकार चित्र किमान डिस्क आकारापेक्षा कमी असू शकत नाही (%sGB)"" #, python-format msgid ""The volume size cannot be less than the source volume size (%sGB)"" msgstr ""खंच आकार स्रोत खंड आकारापेक्षा कमी असू शकत नाही (%sजीबी)"" #, python-format msgid """" ""A volume of %(req)iGB cannot be created as you only have %(avail)iGB of your "" ""quota available."" msgstr """" ""%(req)i आय जीबी खंड तयार करता येणार नाही कारण तुमच्याकडे केवळ %(avail)iआयजीबी तुमचा "" ""वाटा शिल्लक आहे."" msgid ""You are already using all of your available volumes."" msgstr ""तुम्ही आधीपासूनच तुमचे सर्व खंड वापरत आहात."" #, python-format msgid ""Creating volume \""%s\"""" msgstr ""खंड तयार करणे \""%s\"""" msgid ""Unable to create volume."" msgstr ""खंड तयार करण्यास असमर्थ."" msgid ""Attach to Instance"" msgstr ""घटकाशी जोडा"" msgid ""Select an instance to attach to."" msgstr ""एका घटकाला जोडण्यासाठी तो निवडा."" msgid """" ""Actual device name may differ due to hypervisor settings. If not specified, "" ""then hypervisor will select a device name."" msgstr """" ""व्हर्च्युअल यंत्रणा निरीक्षकामुळे प्रत्यक्ष साधन नाव वेगळे असू शकते. स्पष्ट केले नसल्यास, व्हर्च्युअल "" ""यंत्रणा निरीक्षक साधनाचे एक नाव निवडेल."" msgid ""Unknown instance (None)"" msgstr ""अज्ञात घटक (एकही नाही)"" #, python-format msgid ""Attaching volume %(vol)s to instance %(inst)s on %(dev)s."" msgstr ""खंड जोडत आहे %(vol)s घटकाला %(inst)s च्यावर %(dev)s."" msgid ""Unable to attach volume."" msgstr ""खंड जोडण्यास असमर्थ."" #, python-format msgid ""Creating volume snapshot \""%s\""."" msgstr ""खंड क्षणचित्रे तयार करत आहे \""%s\""."" #, python-format msgid ""Forcing to create snapshot \""%s\"" from attached volume."" msgstr ""जोडलेल्या खंडातून क्षणचित्रे तयार करण्याची \""%s\"" सक्ती करत आहे."" msgid ""Unable to create volume snapshot."" msgstr ""खंड क्षणचित्र तयार करण्यास असमर्थ."" msgid ""Unable to update volume."" msgstr ""खंड सुधारित करण्यास असमर्थ."" #, python-format msgid ""Updating volume \""%s\"""" msgstr ""खंड सुधारित करत आहे\""%s\"""" msgctxt ""Force upload volume in in-use status to image"" msgid ""Force"" msgstr ""सक्ती"" #, python-format msgid """" ""Successfully sent the request to upload volume to image for volume: \""%s\"""" msgstr ""खंडासाठी चित्रामध्ये खंड अपलोड करण्याची विनंती यशस्वीपणे पाठवली: \""%s\"""" #, python-format msgid ""Unable to upload volume to image for volume: \""%s\"""" msgstr ""खंडासाठी चित्रावर खंड अपलोड करण्यास असमर्थ: \""%s\"""" msgid ""New size must be greater than current size."" msgstr ""नवीन आकार सध्याच्या आकारापेक्षा मोठा असला पाहिजे."" #, python-format msgid """" ""Volume cannot be extended to %(req)iGB as you only have %(avail)iGB of your "" ""quota available."" msgstr """" ""खंड %(req)i जीबी पर्यंत वाढविता येणार नाही कारण तुमचा केवळ %(avail)iजीबी वाटा "" ""उपलब्ध आहे."" #, python-format msgid ""Extending volume: \""%s\"""" msgstr ""खंड विस्तारित करत आहे: \""%s\"""" msgid ""Unable to extend volume."" msgstr ""खंड विस्तारित करण्यास असमर्थ."" msgid ""On Demand"" msgstr ""मागणीनुसार"" msgid ""Migration Policy"" msgstr ""स्थलांतर धोरण"" msgid ""Unable to retrieve the volume type list."" msgstr ""खंट प्रकार यादी मिळविण्यास असमर्थ."" #, python-format msgid ""New volume type must be different from the original volume type \""%s\""."" msgstr ""नवीन खंड प्रकार मूळ खंड प्रकारापेक्षा वेगळा असला पाहिजे \""%s\""."" #, python-format msgid """" ""Successfully sent the request to change the volume type to \""%(vtype)s\"" for "" ""volume: \""%(name)s\"""" msgstr """" ""खंड प्रकार \""%(vtype)s\"" मध्ये बदलण्यासाठी यशस्वीपणे विनंती पाठवली खंडासाठी: "" ""\""%(name)s\"""" #, python-format msgid ""Unable to change the volume type for volume: \""%s\"""" msgstr ""खंडासाठी खंड प्रकार बदलण्यास असमर्थ: \""%s\"""" msgid ""Launch as Instance"" msgstr ""घटक म्हणून सुरु करा"" msgid ""Manage Attachments"" msgstr ""पुरवण्यांचे व्यवस्थापन करा"" msgid ""Unable to retrieve tenant limits."" msgstr ""भाडेकरु मर्यादा मिळविण्यास असमर्थ."" msgid ""Upload to Image"" msgstr ""चित्रामध्ये अपलोड करा"" msgid ""Unable to retrieve attachment information."" msgstr ""पुरवणी माहिती मिळविण्यास असमर्थ."" #, python-format msgid ""Attached to %(instance)s on %(dev)s"" msgstr ""%(instance)s जोडलेले %(dev)s वर"" msgid ""No"" msgstr ""नाही"" msgid ""Yes"" msgstr ""होय"" msgctxt ""Current status of a Volume"" msgid ""Available"" msgstr ""उपलब्ध"" msgctxt ""Current status of a Volume"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of a Volume"" msgid ""Creating"" msgstr ""तयार करत आहे"" msgctxt ""Current status of a Volume"" msgid ""Attaching"" msgstr ""जोडत आहे"" msgctxt ""Current status of a Volume"" msgid ""Deleting"" msgstr ""नष्ट करत आहे"" msgid ""Encrypted"" msgstr ""सांकेतिक"" msgid ""Device"" msgstr ""साधन"" #, python-format msgid ""Volume %(volume_name)s on instance %(instance_name)s"" msgstr ""%(volume_name)s घटकावरील %(instance_name)s"" msgid ""Create a Volume"" msgstr ""खंड तयार करा"" msgid ""Unable to retrieve volume information."" msgstr ""खंडाची माहिती मिळविण्यास असमर्थ."" msgid ""Create a Volume Snapshot"" msgstr ""खंड क्षणचित्र तयार करा"" msgid """" ""This volume is currently attached to an instance. In some cases, creating a "" ""snapshot from an attached volume can result in a corrupted snapshot."" msgstr """" ""हा खंड सध्या एका घटकाला जोडलेला आहे. काही प्रकरणांमध्ये, जोडलेल्या खंडामधून क्षणचित्र तयार "" ""केल्याने क्षणचित्र खराब होऊ शकते."" #, python-format msgid ""Unable to retrieve volume information for volume: \""%s\"""" msgstr ""खंडातून खंड माहिती मिळविण्यास असमर्थ: \""%s\"""" msgid ""Unable to retrieve volume."" msgstr ""खंड मिळविण्यास असमर्थ."" #, python-format msgid ""VPN Service %s was successfully updated."" msgstr ""व्हीपीएन सेवा %s यशस्वीपणे सुधारित करण्यात आली."" #, python-format msgid ""Failed to update VPN Service %s"" msgstr ""व्हीपीएन सेवा सुधारित करण्यास अपयशी %s"" msgid ""Authorization algorithm"" msgstr ""अधिकृत करण्याचा गणनविधी"" msgid ""sha1"" msgstr ""एसएचए १"" msgid ""Encryption algorithm"" msgstr ""सांकेतिकरण गणनविधी"" msgid ""3des"" msgstr ""३डीईएस"" msgid ""aes-128"" msgstr ""एईएस-१२८"" msgid ""aes-192"" msgstr ""एईएस-१९२"" msgid ""aes-256"" msgstr ""एईएस-२५६"" msgid ""IKE version"" msgstr ""आयकेई आवृत्ती"" msgid ""v1"" msgstr ""व्ही१"" msgid ""v2"" msgstr ""व्ही२"" msgid ""Lifetime units for IKE keys"" msgstr ""आयकेई कळींसाठी जीवनकाळ विभाग"" msgid ""seconds"" msgstr ""सेकंद"" msgid ""Lifetime value for IKE keys"" msgstr ""आयकेई कळींसाठी जीवनकाळ मूल्य"" msgid ""Equal to or greater than 60"" msgstr ""६० ऐवढे किंवा त्यापेक्षा अधिक"" msgid ""Perfect Forward Secrecy"" msgstr ""अचूक पुढील गोपनीयता"" msgid ""group2"" msgstr ""गट२"" msgid ""group5"" msgstr ""गट५"" msgid ""group14"" msgstr ""गट१४"" msgid ""IKE Phase1 negotiation mode"" msgstr ""आयकेई टप्पा १ वाटाघाटी पद्धत"" #, python-format msgid ""IKE Policy %s was successfully updated."" msgstr ""आयकेई धोरण %s यशस्वीपणे सुधारित करण्यात आले."" #, python-format msgid ""Failed to update IKE Policy %s"" msgstr ""आयकेई धोरण सुधारणा करण्यात अपयशी %s"" msgid ""Encapsulation mode"" msgstr ""संपुटन पद्धत"" msgid ""tunnel"" msgstr ""बोगदा"" msgid ""transport"" msgstr ""परिवहन"" msgid ""Lifetime units"" msgstr ""जीवनकाळ विभाग"" msgid ""Lifetime value"" msgstr ""जीवनकाळ मूल्य"" msgid ""Transform Protocol"" msgstr ""प्रोटोकॉल रुपांतरित करा"" msgid ""esp"" msgstr ""ईएसपी"" msgid ""ah"" msgstr ""एएच"" msgid ""ah-esp"" msgstr ""एच-ईएसपी"" #, python-format msgid ""IPSec Policy %s was successfully updated."" msgstr ""आयपीएसईसी धोरण %s यशस्वीपणे सुधारित करण्यात आले."" #, python-format msgid ""Failed to update IPSec Policy %s"" msgstr ""आयपीएसईसी धोरण सुधारित करण्यास अपयशी %s"" msgid ""Peer gateway public IPv4/IPv6 Address or FQDN"" msgstr ""समकक्ष गेटवे सार्वजनिक आयपीव्ही४/आयपीव्ही६ पत्ता किंवा एफक्यूडीएन"" msgid ""Peer gateway public IPv4/IPv6 address or FQDN for the VPN Connection"" msgstr """" ""समकक्ष गेटवे सार्वजनिक आयपीव्ही४/आयपीव्ही पत्ता किंवा एफक्यूडीएन व्हीपीएन जोडणीसाठी"" msgid ""Peer router identity for authentication (Peer ID)"" msgstr ""समकक्ष राउटर ओळख प्रमाणीकरणासाठी (समकक्ष ओळख क्रमांक)"" msgid """" ""Peer router identity for authentication. Can be IPv4/IPv6 address, e-mail, "" ""key ID, or FQDN"" msgstr """" ""प्रमाणीकरणासाठी समकक्ष राउटर ओळख. आयपीव्ही४/आयपीव्ही६ पत्ता, ई-मेल, कळ ओळख क्रमांक, "" ""किंवा एफक्यूडीएन असू शकते"" msgid ""Remote peer subnet(s)"" msgstr ""दूरस्थ समकक्ष उपनेट (अनेक उपनेट)"" msgid """" ""Remote peer subnet(s) address(es) with mask(s) in CIDR format separated with "" ""commas if needed (e.g. 20.1.0.0/24, 21.1.0.0/24)"" msgstr """" ""दूरस्थ समकक्ष उपनेट (अनेक उपनेट) पत्ता (पत्ते) मुखवट्यासह (मुखवट्यांसह) सीआयडीआर प्रारुपामध्ये "" ""आवश्यक असल्यास स्वल्पविरामाने विलग केलेले (उदा. २०.१.०.०/२४, २१.१.०.०/२४)"" msgid ""Pre-Shared Key (PSK) string"" msgstr ""आधीपासून- विभागलेली कळ (पीएसके) श्रृंखला"" msgid ""Maximum Transmission Unit size for the connection"" msgstr ""जोडणीसाठी कमाल प्रसारण विभाग आकार"" msgid """" ""Equal to or greater than 68 if the local subnet is IPv4. Equal to or greater "" ""than 1280 if the local subnet is IPv6."" msgstr """" ""स्थानिक उपनेट आयपीव्ही४ असेल ६८ ऐवढे किंवा त्यापेक्षा अधिक. स्थानिक उपनेट आयपीव्ही६ असेल "" ""तर १२८० ऐवढे किंवा त्यापेक्षा अधिक."" msgid ""Dead peer detection actions"" msgstr ""मृत समकक्ष शोध कृती"" msgid ""hold"" msgstr ""धरुन ठेवा"" msgid ""clear"" msgstr ""पुसून टाका"" msgid ""disabled"" msgstr ""असमर्थ "" msgid ""restart"" msgstr ""पुन्हा सुरु करा"" msgid ""restart-by-peer"" msgstr ""समकक्षाद्वारे-पुन्हा-सुरु करा"" msgid ""Dead peer detection interval"" msgstr ""मृत समकक्ष शोध मध्यंतर"" msgid ""Dead peer detection timeout"" msgstr ""मृत समकक्ष शोध वेळ संपली"" msgid ""Valid integer greater than the DPD interval"" msgstr ""वैध पूर्णांक डीपीडी मध्यंतरापेक्षा मोठा"" msgid ""Initiator state"" msgstr ""सुरुवातीची स्थिती"" msgid ""bi-directional"" msgstr ""द्वी-दिशात्मक"" msgid ""response-only"" msgstr ""केवळ-प्रतिसाद"" #, python-format msgid ""IPSec Site Connection %s was successfully updated."" msgstr ""आयपीएसईसी केंद्र जोडणी %s यशस्वीपणे सुधारित करण्यात आली."" #, python-format msgid ""Failed to update IPSec Site Connection %s"" msgstr ""आयपीएसईसी केंद्र जोडणी सुधारित करण्यात अपयशी %s"" msgid ""VPN"" msgstr ""व्हीपीएन"" msgid ""Add IKE Policy"" msgstr ""आयकेई धोरण समाविष्ट करा"" msgid ""Add IPSec Policy"" msgstr ""आयपीएसईसी धोरण समाविष्ट करा"" msgid ""Add VPN Service"" msgstr ""व्हीपीएन सेवा समाविष्ट करा"" msgid ""Add IPSec Site Connection"" msgstr ""आयपीएसईसी केंद्र जोडणी समाविष्ट करा"" msgid ""Edit VPN Service"" msgstr ""व्हीपीएन सेवा संपादित करा"" msgid ""Edit IKE Policy"" msgstr ""आयकेई धोरण संपादित करा"" msgid ""Edit IPSec Policy"" msgstr ""आयपीएसईसी धोरण संपादित करा"" msgid ""Edit Connection"" msgstr ""जोडणी संपादित करा"" msgctxt ""Current status of an IPSec Site Connection"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of an IPSec Site Connection"" msgid ""Down"" msgstr ""खाली"" msgctxt ""Current status of an IPSec Site Connection"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgid ""VPN Service"" msgstr ""व्हीपीएन सेवा"" msgid ""IKE Policy"" msgstr ""आयकेई धोरण"" msgid ""IPSec Policy"" msgstr ""आयपीएसईसी धोरण"" msgid ""IPSec Site Connections"" msgstr ""आयपीएसईसी केंद्र जोडण्या"" msgctxt ""Current status of a VPN Service"" msgid ""Active"" msgstr ""सक्रिय [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of a VPN Service"" msgid ""Down"" msgstr ""खाली"" msgctxt ""Current status of a VPN Service"" msgid ""Error"" msgstr ""चूक [बदलत्या आयपीची सध्याची स्थिती]"" msgctxt ""Current status of a VPN Service"" msgid ""Created"" msgstr ""तयार करण्यात आले"" msgid ""VPN Services"" msgstr ""व्हीपीएन सेवा"" msgid ""PFS"" msgstr ""पीएफएस"" msgid ""IKE Policies"" msgstr ""आयकेएई धोरणे"" msgid ""IPSec Policies"" msgstr ""आयपीएसईसी धोरणे"" msgid ""Unable to retrieve IPSec Site Connections list."" msgstr ""आयपीएसईसी केंद्र जोडण्या यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve VPN Services list."" msgstr ""व्हीपीएन सेवा यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve IKE Policies list."" msgstr ""आयकेई धोरणे यादी मिळविण्यास असमर्थ."" msgid ""Unable to retrieve IPSec Policies list."" msgstr ""आयपीएसईसी धोरणे यादी मिळविण्यास असमर्थ."" msgid ""IKE Policy Details"" msgstr ""आयकेई धोरण तपशील"" msgid ""IPSec Policy Details"" msgstr ""आयपीएसईसी धोरण तपशील"" msgid ""VPN Service Details"" msgstr ""व्हीपीएन सेवा तपशील"" msgid ""IPSec Site Connection Details"" msgstr ""आयपीएसईसी केंद्र जोडणी तपशील"" msgid ""Lifetime Units"" msgstr ""जीवनकाळ विभाग"" msgid ""Lifetime Value"" msgstr ""जीवनकाळ मूल्य"" msgid ""Remote peer subnet"" msgstr ""दूरस्थ समकक्ष उपनेट"" msgid ""Pre-Shared Key string"" msgstr ""पूर्व-विभाजित कळ श्रृंखला"" msgid ""Dead peer detection action"" msgstr ""मृत समकक्ष शोध कृती"" msgid ""Authorization mode"" msgstr ""अधिकृत करण्याची पद्धत"" msgid ""Route mode"" msgstr ""मार्ग पद्धत"" msgid ""You may update IKE Policy details here."" msgstr ""तुम्ही येथे आयकेई धोरण तपशील सुधारित करु शकता."" msgid ""You may update IPSec Policy details here."" msgstr ""तुम्ही येथे आयपीएसईसी धोरण तपशील सुधारित करु शकता."" msgid ""You may update IPSec Site Connection details here."" msgstr ""तुम्ही येथे आयपीएसईसी केंद्र जोडणी तपशील सुधारित करु शकता."" msgid ""You may update VPN Service details here."" msgstr ""तुम्ही येथे व्हीपीएन सेवा तपशील सुधारित करु शकता."" msgid ""VPN Connections"" msgstr ""व्हीपीएन जोडण्या"" msgid ""Virtual Private Network"" msgstr ""व्हर्च्युअल खाजगी नेटवर्क"" msgid ""Edit IPSec Site Connection"" msgstr ""आयपीएसईसी केंद्र जोडणी संपादित करा"" #, python-format msgid ""Deleted VPN Service %s"" msgstr ""नष्ट केलेली व्हीपीएन सेवा %s"" #, python-format msgid ""Unable to delete VPN Service: %s"" msgstr ""व्हीपीएन सेवा नष्ट करण्यास असमर्थ: %s"" #, python-format msgid ""Deleted IKE Policy %s"" msgstr ""नष्ट केलेले आयकेई धोरण %s"" #, python-format msgid ""Unable to delete IKE Policy: %s"" msgstr ""आयकेई धोरण नष्ट करण्यास असमर्थ: %s"" #, python-format msgid ""Deleted IPSec Policy %s"" msgstr ""नष्ट केलेले आयपीएसईसी धोरण %s"" #, python-format msgid ""Unable to delete IPSec Policy: %s"" msgstr ""आयपीएसईसी धोरण नष्ट करण्यास असमर्थ: %s"" #, python-format msgid ""Deleted IPSec Site Connection %s"" msgstr ""नष्ट केलेली आयपीएसईसी केंद्र जोडणी %s"" #, python-format msgid ""Unable to delete IPSec Site Connection: %s"" msgstr ""आयपीएसईसी केंद्र जोडणी नष्ट करण्यास असमर्थ: %s"" msgid ""Unable to retrieve IKE Policy details."" msgstr ""आयकेई धोरण तपशील मिळविण्यास असमर्थ."" msgid ""Unable to retrieve IPSec Policy details."" msgstr ""आयपीएसईसी धोरण तपशील मिळविण्यास असमर्थ."" msgid ""Unable to retrieve VPN Service details."" msgstr ""व्हीपीएन सेवा तपशील मिळविण्यास असमर्थ."" msgid ""Unable to retrieve IPSec Site Connection details."" msgstr ""आयपीएसईसी केंद्र जोडणी तपशील मिळविण्यास असमर्थ."" #, python-format msgid ""Unable to retrieve VPN Service details. %s"" msgstr ""व्हीपीएन सेवा तपशील मिळविण्यास असमर्थ. %s"" #, python-format msgid ""Unable to retrieve IKE Policy details. %s"" msgstr ""आयकेई धोरण तपशील मिळविण्यास असमर्थ. %s"" #, python-format msgid ""Unable to retrieve IPSec Policy details. %s"" msgstr ""आयपीएसईसी धोरण तपशील मिळविण्यास असमर्थ. %s"" #, python-format msgid ""Unable to retrieve IPSec Site Connection details. %s"" msgstr ""आयपीएसईसी केंद्र जोडणी तपशील मिळविण्यास असमर्थ. %s"" msgid ""The state to start in."" msgstr ""सुरुवात करण्याची स्थिती."" msgid ""Select a Router"" msgstr ""एक राउटर निवडा"" msgid ""Unable to retrieve routers list."" msgstr ""राउटर यादी मिळविण्यास असमर्थ."" msgid ""Add New VPN Service"" msgstr ""नवीन व्हीपीएन सेवा समाविष्ट करा"" msgid """" ""Create VPN Service for current project.\n"" ""\n"" ""Specify a name, description, router, and subnet for the VPN Service. Admin "" ""State is Up (checked) by default."" msgstr """" ""सध्याच्या प्रकल्पासाठी व्हीपीएन सेवा तयार करा.\n"" ""\n"" ""व्हीपीएन सेवेसाठी एक नाव, वर्णन, राउटर, व एक उपनेट नमूद करा. पूर्वनिर्धारितपणे प्रशासक "" ""स्थिती सुरु (बरोबरची खूण केलेली) आहे."" #, python-format msgid ""Added VPN Service \""%s\""."" msgstr ""समाविष्ट व्हीपीएन सेवा \""%s\""."" #, python-format msgid ""Unable to add VPN Service \""%s\""."" msgstr ""व्हीपीएन सेवा समाविष्ट करण्यास असमर्थ \""%s\""."" msgid ""Add New IKE Policy"" msgstr ""नवीन आयकेई धोरण समाविष्ट करा"" msgid """" ""Create IKE Policy for current project.\n"" ""\n"" ""Assign a name and description for the IKE Policy. "" msgstr """" ""सध्याच्या प्रकल्पासाठी आयकेई धोरण तयार करा.\n"" ""\n"" ""आयकेई धोरणासाठी नाव द्या व वर्णन करा. "" #, python-format msgid ""Added IKE Policy \""%s\""."" msgstr ""समाविष्ट आयकेई धोरण \""%s\""."" #, python-format msgid ""Unable to add IKE Policy \""%s\""."" msgstr ""आयकेई धोरण समाविष्ट करण्यास असमर्थ \""%s\""."" msgid ""Lifetime value for IKE keys "" msgstr ""आयकेई कळींसाठी जीवनकाळ मूल्य"" msgid ""Add New IPSec Policy"" msgstr ""नवीन आयपीएसईसी धोरण समाविष्ट करा"" msgid """" ""Create IPSec Policy for current project.\n"" ""\n"" ""Assign a name and description for the IPSec Policy. "" msgstr """" ""सध्याच्या प्रकल्पासाठी आयपीएसईसी धोरण तयार करा.\n"" ""\n"" ""आयपीएसईसी धोरणाला नाव द्या व वर्णन करा. "" #, python-format msgid ""Added IPSec Policy \""%s\""."" msgstr ""समाविष्ट आयपीएसईसी धोरण \""%s\""."" #, python-format msgid ""Unable to add IPSec Policy \""%s\""."" msgstr ""आयपीएसईसी धोरण समाविष्ट करण्यास असमर्थ \""%s\""."" msgid ""VPN Service associated with this connection"" msgstr ""या जोडणीशी संबंधित व्हीपीएन सेवा"" msgid ""IKE Policy associated with this connection"" msgstr ""या जोडणीशी संबंधित आयकेई धोरण"" msgid ""IPSec Policy associated with this connection"" msgstr ""या जोडणीशी संबंधित आयपीएसईसी धोरण"" msgid ""Select IKE Policy"" msgstr ""आयकेई धोरण निवडा"" msgid ""Select IPSec Policy"" msgstr ""आयपीएसईसी धोरण निवडा"" msgid ""Select VPN Service"" msgstr ""व्हीपीएन सेवा निवडा"" msgid ""Add New IPSec Site Connection"" msgstr ""नवीन आयपीएसईसी केंद्र जोडणी समाविष्ट करा"" msgid """" ""Create IPSec Site Connection for current project.\n"" ""\n"" ""Assign a name and description for the IPSec Site Connection. All fields in "" ""this tab are required."" msgstr """" ""सध्याच्या प्रकल्पासाठी आयपीएसईसी केंद्र जोडणी तयार करा.\n"" ""\n"" ""आयपीएसईसी केंद्र जोडणीला नाव द्या व वर्णन करा. या टॅबवरील सर्व क्षेत्रे आवश्यक आहेत."" msgid ""Optional Parameters"" msgstr ""ऐच्छिक निर्देशांक"" msgid """" ""Fields in this tab are optional. You can configure the detail of IPSec site "" ""connection created."" msgstr """" ""या टॅबवरील क्षेत्रे ऐच्छिक आहेत. तुम्ही तयार केलेल्या आयपीएसईसी केंद्र जोडणीच्या तपशीलाची "" ""मांडणी करु शकता."" #, python-format msgid ""Added IPSec Site Connection \""%s\""."" msgstr ""समाविष्ट आयपीएसईसी केंद्र जोडणी\""%s\""."" #, python-format msgid ""Unable to add IPSec Site Connection \""%s\""."" msgstr ""आयपीएसईसी केंद्र जोडणी समाविष्ट करण्यास असमर्थ\""%s\""."" msgid ""Projects could not be retrieved."" msgstr ""प्रकल्प मिळविता येणार नाहीत."" msgid ""Segment Type"" msgstr ""खंड प्रकार"" msgid ""Overlay"" msgstr ""अधिचित्र"" msgid ""Trunk"" msgstr ""ट्रंक"" msgid ""Sub Type"" msgstr ""उप प्रकार"" msgid ""Native VXLAN"" msgstr ""स्थानिक व्हीएक्सलॅन"" msgid ""Enhanced VXLAN"" msgstr ""वाढीव व्हीएक्सलॅन"" msgid ""Segment Range"" msgstr ""खंड श्रेणी"" msgid ""1-4093 for VLAN; 5000 and above for Overlay"" msgstr ""व्हीलॅनसाठी १-४०९३; ५००० व त्यापेक्षा अधिक ओव्हरलेसाठी"" msgid ""Multicast IP Range"" msgstr ""बहुभूमिका आयपी श्रेणी"" msgid ""Multicast IPv4 range(e.g. 224.0.1.0-224.0.1.100)"" msgstr ""बहुभूमिका आयपीव्ही४ श्रेणी (उदा. २२४.०.१.०-२२४.०.१.१००)"" msgid ""Sub Type Value (Manual Input)"" msgstr ""उप प्रकार मूल्य (हाताने टंकलेखन)"" msgid ""Enter parameter (e.g. GRE)"" msgstr ""निर्देशांक घाला (उदा. जीआरई)"" #, python-format msgid ""Network Profile %s was successfully created."" msgstr ""नेटवर्क स्वरुप %s यशस्वीपणे तयार करण्यात आले."" #, python-format msgid ""Failed to create network profile %s"" msgstr ""नेटवर्क स्वरुप तयार करण्यात अपयशी %s"" #, python-format msgid ""Network Profile %s was successfully updated."" msgstr ""नेटवर्क स्वरुप %s यशस्वीपणे सुधारित करण्यात आले."" #, python-format msgid ""Failed to update network profile (%s)."" msgstr ""नेटवर्क स्वरुप सुधारित करण्यास अपयशी (%s)."" msgid ""Cisco Nexus 1000v"" msgstr ""सिस्को परस्परसंबंध १०००व्ही"" msgid ""Create Network Profile"" msgstr ""नेटवर्क स्वरुप तयार करा"" #, python-format msgid ""Failed to delete network profile (%s)."" msgstr ""नेटवर्क स्वरुप नष्ट करण्यात अपयशी (%s)."" msgid ""Edit Network Profile"" msgstr ""नेटवर्क स्वरुप संपादित करा"" msgid ""Physical Network Name"" msgstr ""प्रत्यक्ष नेटवर्क नाव"" msgid ""Policy Profile"" msgstr ""पॉलिसी स्वरुप"" msgid ""Name:"" msgstr ""नाव:"" msgid "" Select a name for your network profile."" msgstr ""तुमच्या नेटवर्क प्रारुपासाठी नाव निवडा."" msgid ""Segment Type:"" msgstr ""खंड प्रकार:"" msgid "" Segment types available are VLAN, Overlay and Trunk."" msgstr ""व्हीलॅन, अधिचित्र व ट्रंक हे खंड प्रकार उपलब्ध आहेत."" msgid ""Segment Sub Type:"" msgstr ""खंड उप प्रकार:"" msgid """" "" Sub types available are for the Overlay and Trunk segments. Available sub-"" ""types for Overlay are: Native-VXLAN, Enhanced-VXLAN or 'Other' (eg. GRE) "" ""which can be manually inputed as a text parameter for subtype. Available sub-"" ""type for Trunk is: VLAN."" msgstr """" "" उपलब्ध उपप्रकार अधिचित्र व ट्रंक खंडांसाठी आहेत. अधिचित्रासाठी उपलब्ध उप-प्रकार आहेत: "" ""स्थानिक-व्हीएक्सलॅन, वाढीव-व्हीएक्सलॅन किंवा 'इतर' (उदा. जीआरई) ज्याचे उपप्रकारासाठी "" ""मजकूर निर्देशांक म्हणून हाताने टंकलेखन करता येऊ शकते. ट्रंकसाठी उपलब्ध उप-प्रकार आहे: व्हीलॅन."" msgid ""Segment Range:"" msgstr ""खंड श्रेणी:"" msgid """" "" Segment Ranges are 1-4093 for VLAN and above 5000 for Enhanced-VXLAN "" ""Overlay."" msgstr """" "" व्हीलॅनसाठी खंड श्रेणी आहे १-४०९३ व वाढीव-व्हीएक्सलॅन अधिचित्रासाठी ५००० पेक्षा अधिक."" msgid """" ""Edit the network profile to update name, segment range or multicast IP range."" msgstr """" ""नाव, खंड श्रेणी किंवा बहुभूमिका आयपी श्रेणी सुधारित करण्यासाठी नेटवर्क स्वरुप संपादित करा."" msgid ""Cisco Nexus 1000V Networking"" msgstr ""सिस्को परस्परसंबंध १०००व्ही नेटवर्किंग"" msgid ""Update Network Profile"" msgstr ""नेटवर्क स्वरुप सुधारित करा"" msgid ""Cisco Nexus 1000V"" msgstr ""सिस्को परस्परसंबंध १०००व्ही"" msgid ""Unable to retrieve network profile details."" msgstr ""नेटवर्क स्वरुप तपशील मिळविण्यास असमर्थ."" msgid ""Failed to obtain network profile binding"" msgstr ""नेटवर्क स्वरुप बंधन मिळविण्यात अपयशी"" msgid ""Settings"" msgstr ""मांडण्या"" msgid ""Current password"" msgstr ""सध्याचा पासवर्ड"" msgid ""New password"" msgstr ""नवीन पासवर्ड"" msgid ""Confirm new password"" msgstr ""नवीन पासवर्डची खात्री करा"" msgid ""Password changed. Please log in again to continue."" msgstr ""पासवर्ड बदलला. सुरु ठेवण्यासाठी कृपया पुन्हा लॉग इन करा"" msgid ""Unable to change password."" msgstr ""पासवर्ड बदलण्यास असमर्थ."" msgid ""Changing password is not supported."" msgstr ""पासवर्ड बदलण्यास सहाय्य नाही."" msgid ""Change your password. We highly recommend you create a strong one. "" msgstr ""तुमचा पासवर्ड बदला. तुम्ही एक सशक्त पासवर्ड तयार करावा अशी आमची शिफारस आहे."" msgid ""Change"" msgstr ""बदला"" msgid ""Language"" msgstr ""भाषा"" msgid ""Timezone"" msgstr ""वेळ विभाग"" msgid ""Items Per Page"" msgstr ""प्रत्येक पानावरील घटक"" #, python-format msgid ""UTC %(hour)s:%(min)s"" msgstr ""UTC %(hour)s:%(min)s"" msgid ""UTC"" msgstr ""यूटीसी"" msgid ""GMT"" msgstr ""जीएमटी"" #. Translators: UTC offset and timezone label #, python-format msgid ""%(offset)s: %(label)s"" msgstr ""%(offset)s: %(label)s"" msgid ""Settings saved."" msgstr ""मांडणी साठविण्यात आली."" msgid ""User Settings"" msgstr ""वापरकर्ता मांडण्या"" msgid ""Modify dashboard settings for your user."" msgstr ""तुमच्या वापरकर्त्यासाठी डॅशबोर्ड मांडण्या सुधारित करा."" msgid ""Select format"" msgstr ""प्रारूप निवडा"" msgid ""AKI - Amazon Kernel Image"" msgstr ""AKI - ॲमॅझॉन कर्नेल प्रतिमा "" msgid ""AMI - Amazon Machine Image"" msgstr ""AMI - ॲमॅझॉन मशिन इमेज"" msgid ""ARI - Amazon Ramdisk Image"" msgstr ""ARI - ॲमॅझॉन रॅमडिस्क इमेज"" msgid ""ISO - Optical Disk Image"" msgstr ""ISO- ऑप्टीकल डिस्क ईमेज"" msgid ""QCOW2 - QEMU Emulator"" msgstr ""क्यूसीओडब्ल्यू२- क्यूईएमयू प्रतिकृती कर्ता"" msgid ""Raw"" msgstr ""कच्चा"" msgid ""All TCP"" msgstr ""सर्व TCP"" msgid ""All UDP"" msgstr ""सर्व UDP"" msgid ""All ICMP"" msgstr ""सर्व ICMP"" msgid ""Forbidden"" msgstr ""प्रतिबंधित"" msgid ""Home"" msgstr ""गृह"" msgid ""Page Not Found"" msgstr ""पान सापडले नाही"" msgid ""The page you were looking for doesn't exist"" msgstr ""तुम्ही शोधत असलेले पान अस्तित्वात नाही"" msgid ""You may have mistyped the address or the page may have moved."" msgstr """" ""तुम्ही कदाचित पत्ता चुकीचा टंकलिखित केला असेल किंवा पान कदाचित हलविण्यात आले असेल."" msgid ""Server error"" msgstr ""सर्वर चूक"" msgid ""Something went wrong!"" msgstr ""काहीतरी चूक झाली!"" msgid """" ""An unexpected error has occurred. Try refreshing the page. If that doesn't "" ""help, contact your local administrator."" msgstr """" ""एक अनपेक्षित चूक झाली आहे. पान पुन्हा ताजे करण्याचा प्रयत्न करा. त्याचा उपयोग झाला "" ""नाही, तर तुमच्या स्थानिक प्रशासकाला संपर्क करा."" msgid ""Help"" msgstr ""मदत"" msgid ""More Projects"" msgstr ""अधिक प्रकल्प"" msgid ""Sign Out"" msgstr ""बाहेर पडा"" msgid ""Domains:"" msgstr ""कार्यक्षेत्रे:"" msgid ""Projects:"" msgstr ""प्रकल्प:"" msgid ""Regions:"" msgstr ""प्रदेश:"" msgid ""Invalid date format: Using today as default."" msgstr ""अवैध तारीख प्रारुप: आज पूर्वनिर्धारित म्हणून वापरत आहोत."" msgid ""Unable to retrieve network quota information."" msgstr ""नेटवर्क वाटा माहिती मिळविण्यास असमर्थ."" msgid ""Unable to retrieve volume limit information."" msgstr ""खंड मर्यादा माहिती मिळविण्यास असमर्थ."" msgid ""Unable to retrieve limit information."" msgstr ""मर्यादा माहिती मिळविण्यास असमर्थ."" msgid ""Unable to retrieve usage information."" msgstr ""वापर माहिती मिळविण्यास असमर्थ."" msgid """" ""Invalid time period. The end date should be more recent than the start date."" msgstr """" ""अवैध कालावधी. समाप्तीची तारीख सुरुवातीच्या तारखेपेक्षा थोडी अलिकडची असली पाहिजे."" msgid """" ""Invalid time period. You are requesting data from the future which may not "" ""exist."" msgstr """" ""अवैध कालावधी. तुम्ही भविष्यातील डाटाची विनंती करत आहात जो कदाचित अस्तित्वात नसेल."" msgid ""Injected File Path Bytes"" msgstr ""समाविष्ट धारिका मार्ग बाईट्स"" msgid ""Unable to retrieve compute limit information."" msgstr ""संगणन मर्यादा माहिती मिळविण्यास असमर्थ."" msgid ""VCPU Hours"" msgstr ""व्हीसीपीयू तास"" msgid ""Disk GB Hours"" msgstr ""डिस्क जीबी तास"" msgid ""Total disk usage (GB * Hours Used) for the project"" msgstr ""एकूण डिस्क वापर (जीबी * तास वापरले) प्रकल्पासाठी"" msgid ""Usage"" msgstr ""वापर"" msgid ""To date to must be greater than From date."" msgstr ""पर्यंत तारीख पासून तारखेपेक्षा नंतरची असली पाहिजे."" ",,18019,8
openstack%2Ffreezer~master~I34ba17da9de978ba2f6ca2c1d8a5417c8e355749,openstack/freezer,master,I34ba17da9de978ba2f6ca2c1d8a5417c8e355749,Cinder Volumes Backup Implements blueprint: cinder-backup,MERGED,2015-04-16 11:02:51.000000000,2015-05-20 10:11:45.000000000,2015-05-20 10:11:45.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 12211}, {'_account_id': 14123}, {'_account_id': 14159}, {'_account_id': 14340}, {'_account_id': 15358}]","[{'number': 1, 'created': '2015-04-16 11:02:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/2bcd8d7f005ee849dc94596da78adfad4717c86a', 'message': 'test commit - should be ammended\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 2, 'created': '2015-05-01 16:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/deef7e67141fcb523afa3bcd1fdb445e55884009', 'message': 'Cinder Volumes Backup\nImplements bluepring: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 3, 'created': '2015-05-01 16:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/6cf7f971f4249621c0a69ef7c264ca4777353514', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 4, 'created': '2015-05-06 16:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/a90779ec9d022ef04ce02e8230623d3c0134bd66', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 5, 'created': '2015-05-07 13:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/769ee2585120f038ce5de15410b2ede075c1c0a7', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 6, 'created': '2015-05-08 14:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/913aa146e61ba3b0b64ac6a5a72072f2b96069fc', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 7, 'created': '2015-05-08 15:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/54b1349abaefe1c0d027c5afdf6b7ed8a016b41c', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 8, 'created': '2015-05-13 17:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/7780bb659afc3309493d2cfccbc99a5bd2eff955', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 9, 'created': '2015-05-14 16:53:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/3bb881ac3ee8a7771871c7cf09d08bf3b63df2fd', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 10, 'created': '2015-05-15 12:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/c00849fc77e4d8648ec7d6687fe0044dfb0035c5', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 11, 'created': '2015-05-15 13:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/c4731edb017d072e17bdc5fe021e4788a1e66406', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 12, 'created': '2015-05-18 11:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/78f9aa30c64feb000dda891abad074d5794757a8', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 13, 'created': '2015-05-19 10:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/be2a65d49aef2758ddc872a777e25bd23b23fdf3', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 14, 'created': '2015-05-19 13:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/ef1eb7a3b8dc85f99abda0212b2e862bc77c81b6', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 15, 'created': '2015-05-19 14:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/eab7fc5fac2be6eb76427539e6632abe1cfb2126', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 16, 'created': '2015-05-19 20:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/76ec7c5b1a4ffaaab582d4a3201de4182c2d6514', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 17, 'created': '2015-05-19 21:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/df51831095a7dcd5d99a8cfeed2581be5b1a3403', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 18, 'created': '2015-05-20 08:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/33883e44a2c2bf4c9cb2768de7f7a2e5605c1717', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 19, 'created': '2015-05-20 08:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/2d5ee5dfea76fb088e31119582c4851157e595c3', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}, {'number': 20, 'created': '2015-05-20 09:39:12.000000000', 'files': ['freezer/bandwidth.py', 'freezer/swift.py', 'freezer/arguments.py', 'freezer/glance.py', 'tests/commons.py', 'README.rst', 'freezer/cinder.py', 'tests/test_backup.py', 'requirements.txt', 'freezer/job.py', 'freezer/backup.py', 'freezer/restore.py', 'tests/test_bandwidth.py', 'tests/test_restore.py', 'tests/test_swift.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/5f4d2974e32420071c0d42ca947001891ce2f30a', 'message': 'Cinder Volumes Backup\nImplements blueprint: cinder-backup\n\nChange-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749\n'}]",5,174305,5f4d2974e32420071c0d42ca947001891ce2f30a,49,7,20,15358,,,0,"Cinder Volumes Backup
Implements blueprint: cinder-backup

Change-Id: I34ba17da9de978ba2f6ca2c1d8a5417c8e355749
",git fetch https://review.opendev.org/openstack/freezer refs/changes/05/174305/8 && git format-patch -1 --stdout FETCH_HEAD,"['freezer/clients/cinder.py', 'freezer/clients/nova.py', 'freezer/clients/__init__.py', 'freezer/clients/nova_script.py', 'freezer/clients/glance.py', 'freezer/clients/cinder_script.py']",6,2bcd8d7f005ee849dc94596da78adfad4717c86a,bp/cinder-backup,""""""" Copyright 2014 Hewlett-Packard Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. This product includes cryptographic software written by Eric Young (eay@cryptsoft.com). This product includes software written by Tim Hudson (tjh@cryptsoft.com). ======================================================================== Freezer LVM related functions """""" #from freezer.utils import ( # create_dir, get_vol_fs_type, validate_all_args, get_mount_from_path) import re import os import subprocess import logging import time import cinderclient from cinderclient.v2 import client as ciclient ### Func ### def clean_up(obj, skip_id=None): for elem in obj.list(): if elem.id == skip_id: continue try: while elem.status == 'available': print 'Delete: ', elem.id obj.delete(elem.id) elem = obj.get(elem.id) time.sleep(1) except cinderclient.exceptions.BadRequest: pass except cinderclient.exceptions.NotFound: pass ### MAIN ### #os.environ['no_proxy'] += ',10.199.199.200' #print os.environ['no_proxy'] for i in os.environ: if i.startswith(""OS_"") and ""PASSWORD"" not in i: print i, os.environ[i] CINDER_CONN = ciclient.Client( auth_url=os.environ[""OS_AUTH_URL""], username=os.environ[""OS_USERNAME""], api_key=os.environ[""OS_PASSWORD""], project_id=os.environ[""OS_TENANT_NAME""], region_name=os.environ[""OS_REGION_NAME""], service_type='volume' ) volume_new = False try: volume_new = CINDER_CONN.volumes.create( 1, name='additional_space', description='A disk to attach to VMs' ) except cinderclient.exceptions.OverLimit: pass time.sleep(2) assert volume_new and volume_new in CINDER_CONN.volumes.list() print CINDER_CONN.volumes.list() # Delete volumes without just creates #clean_up(CINDER_CONN.volumes, volume_new.id) clean_up(CINDER_CONN.backups) timestamp = int(time.time()) backup = CINDER_CONN.backups.create( volume_id=volume_new.id, container='cinder_container', name='cinder_backup_%s' % timestamp, description=str(timestamp) ) print ""BACKUP INFO:"" print backup.status print backup.id print backup.container print backup.name while backup.status != ""available"": time.sleep(2) backup = CINDER_CONN.backups.get(backup.id) print backup.status # Delete volumes print CINDER_CONN.volumes.list() #clean_up(CINDER_CONN.volumes) restore = CINDER_CONN.restores.restore( backup_id=backup.id ) print ""RESTORE INFO:"" print restore.__dict__ print restore.volume_id",,302,0
openstack%2Ffuel-main~master~Idd27399428bb0e847eba7bbb97de1c78b3d20385,openstack/fuel-main,master,Idd27399428bb0e847eba7bbb97de1c78b3d20385,Add sourcing of upstream docker images during mirror build.,ABANDONED,2014-11-11 16:20:41.000000000,2015-05-20 10:08:33.000000000,,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 3009}, {'_account_id': 7195}, {'_account_id': 8777}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10474}]","[{'number': 1, 'created': '2014-11-11 16:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d7097017508b863fb6c5b3b8e9359b50535720ba', 'message': 'Add sourcing of upstream docker images during mirror build\n\nChange-Id: Idd27399428bb0e847eba7bbb97de1c78b3d20385\nCloses-Bug: 1378833\n'}, {'number': 2, 'created': '2014-11-12 09:44:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/651ac32a7c8c7013a3785de311ce92d7366ac2f2', 'message': 'Add sourcing of upstream docker images during mirror build.\n\nDocker images for busybox and centos:centos6 will be pulled from upstream and put to local mirror if USE_MIRROR=none option is set.\n\nChange-Id: Idd27399428bb0e847eba7bbb97de1c78b3d20385\nCloses-Bug: 1378833\n'}, {'number': 3, 'created': '2014-11-12 09:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3aca321942a94feddafa8d462c8c190964754e2c', 'message': 'Add sourcing of upstream docker images during mirror build.\n\nDocker images for busybox and centos:centos6 are pulled from\nupstream and put to local mirror if USE_MIRROR=none option\nis set.\n\nChange-Id: Idd27399428bb0e847eba7bbb97de1c78b3d20385\nCloses-Bug: 1378833\n'}, {'number': 4, 'created': '2014-11-12 11:07:23.000000000', 'files': ['mirror/docker/base-images.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ace0bc34bf3e477e205ef67f11daaf398d894e9f', 'message': 'Add sourcing of upstream docker images during mirror build.\n\nDocker images for busybox and centos:centos6 are pulled from\nupstream and put to local mirror if USE_MIRROR=none option\nis set.\n\nChange-Id: Idd27399428bb0e847eba7bbb97de1c78b3d20385\nCloses-Bug: #1378833\n'}]",0,133748,ace0bc34bf3e477e205ef67f11daaf398d894e9f,21,9,4,10474,,,0,"Add sourcing of upstream docker images during mirror build.

Docker images for busybox and centos:centos6 are pulled from
upstream and put to local mirror if USE_MIRROR=none option
is set.

Change-Id: Idd27399428bb0e847eba7bbb97de1c78b3d20385
Closes-Bug: #1378833
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/48/133748/2 && git format-patch -1 --stdout FETCH_HEAD,['mirror/docker/base-images.mk'],1,d7097017508b863fb6c5b3b8e9359b50535720ba,bug/1378833,"BASE_UPSTREAM_IMAGE_FILES:=busybox.tar.xz centos-centos6.tar.xz# docker base image files from upstream ifeq ($(USE_MIRROR),none) $(addprefix $(LOCAL_MIRROR_DOCKER_BASEURL)/,$(BASE_UPSTREAM_IMAGE_FILES)): @mkdir -p $(@D) sudo docker pull $(subst -,:,$(subst .tar.xz,,$(@F))) sudo docker save $(subst -,:,$(subst .tar.xz,,$(@F))) | xz -c -T0 -4 > $(LOCAL_MIRROR_DOCKER_BASEURL)/$(@F) endif ifeq ($(USE_MIRROR),none) $(BUILD_DIR)/mirror/docker/base-images.done: \ $(addprefix $(LOCAL_MIRROR_DOCKER_BASEURL)/,$(BASE_UPSTREAM_IMAGE_FILES)) \ $(addprefix $(LOCAL_MIRROR_DOCKER_BASEURL)/,$(BASE_IMAGE_FILES)) elseendif $(BUILD_DIR)/mirror/docker/base-images.done: $(ACTION.TOUCH)", $(ACTION.TOUCH) ,18,1
openstack%2Ffuel-library~master~I1d323bc028d076d80fe2a2c6748a1653f0d789a5,openstack/fuel-library,master,I1d323bc028d076d80fe2a2c6748a1653f0d789a5,Change non-flexible log rotation process,ABANDONED,2015-03-25 17:53:56.000000000,2015-05-20 09:46:12.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 13948}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-03-25 17:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1f3faa96c2dfbbc8be0b7ebaa0f6b46d8f10a339', 'message': ""Change non-flexible log rotation process\n\nAdd daily logrotation option. Replace 'size' parameter\nwith 'minsize' and 'maxsize'.\n\nChange-Id: I1d323bc028d076d80fe2a2c6748a1653f0d789a5\nCloses-Bug: #1436465\n""}, {'number': 2, 'created': '2015-03-25 18:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/69494576991e530e680c09638e8e1467efba5241', 'message': ""Change non-flexible log rotation process\n\nAdd daily logrotation option. Replace 'size' parameter\nwith 'minsize' and 'maxsize'.\n\nChange-Id: I1d323bc028d076d80fe2a2c6748a1653f0d789a5\nCloses-Bug: #1436465\n""}, {'number': 3, 'created': '2015-03-25 18:26:49.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/logging/logging.pp', 'deployment/puppet/openstack/manifests/logrotate.pp', 'deployment/puppet/openstack/templates/20-fuel.conf.erb', 'deployment/puppet/openstack/manifests/logging.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ccbee4349e4a2443644784bc871f069eb66ea4fc', 'message': ""Change non-flexible log rotation process\n\nAdd daily logrotation option. Replace 'size' parameter\nwith 'minsize' and 'maxsize'.\n\nChange-Id: I1d323bc028d076d80fe2a2c6748a1653f0d789a5\nCloses-Bug: #1436465\n""}]",0,167720,ccbee4349e4a2443644784bc871f069eb66ea4fc,41,6,3,12559,,,0,"Change non-flexible log rotation process

Add daily logrotation option. Replace 'size' parameter
with 'minsize' and 'maxsize'.

Change-Id: I1d323bc028d076d80fe2a2c6748a1653f0d789a5
Closes-Bug: #1436465
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/20/167720/3 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/modular/logging/logging.pp', 'deployment/puppet/openstack/templates/20-fuel.conf.erb', 'deployment/puppet/openstack/manifests/logging.pp']",3,1f3faa96c2dfbbc8be0b7ebaa0f6b46d8f10a339,bug/1436465," $maxsize = '30M', $minsize = '100k', maxsize => $maxsize, minsize => $minsize,",,16,6
openstack%2Ftempest~master~I959d22c7e28f999bba473cc863283f7fd54e6272,openstack/tempest,master,I959d22c7e28f999bba473cc863283f7fd54e6272,Fix typo in cleanup_service class name,MERGED,2015-05-19 16:00:20.000000000,2015-05-20 09:28:52.000000000,2015-05-20 09:28:51.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7428}, {'_account_id': 8556}, {'_account_id': 11075}, {'_account_id': 13962}, {'_account_id': 14510}, {'_account_id': 14614}, {'_account_id': 14691}, {'_account_id': 16233}]","[{'number': 1, 'created': '2015-05-19 16:00:20.000000000', 'files': ['tempest/cmd/cleanup_service.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/13379bb0becf76db60d9ffd39d3445529d752ecc', 'message': 'Fix typo in cleanup_service class name\n\nChange-Id: I959d22c7e28f999bba473cc863283f7fd54e6272\n'}]",0,184276,13379bb0becf76db60d9ffd39d3445529d752ecc,18,12,1,13454,,,0,"Fix typo in cleanup_service class name

Change-Id: I959d22c7e28f999bba473cc863283f7fd54e6272
",git fetch https://review.opendev.org/openstack/tempest refs/changes/76/184276/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cmd/cleanup_service.py'],1,13379bb0becf76db60d9ffd39d3445529d752ecc,fix_classname,class NetworkMeteringLabelRuleService(NetworkService):class NetworkMeteringLabelService(NetworkService): tenant_services.append(NetworkMeteringLabelRuleService) tenant_services.append(NetworkMeteringLabelService),class NetworMeteringLabelRuleService(NetworkService):class NetworMeteringLabelService(NetworkService): tenant_services.append(NetworMeteringLabelRuleService) tenant_services.append(NetworMeteringLabelService),4,4
openstack%2Ffuel-qa~master~Ie5d55a537ce3125a20e0926864cba5d42190cbe9,openstack/fuel-qa,master,Ie5d55a537ce3125a20e0926864cba5d42190cbe9,Align tests for bonding with linux bridges/bonds,MERGED,2015-05-19 15:43:07.000000000,2015-05-20 09:27:52.000000000,2015-05-20 09:27:52.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}]","[{'number': 1, 'created': '2015-05-19 15:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/704df571f2ece0583cb233e22e079a24c5b02372', 'message': ""Align tests for bonding with linux bridges/bonds\n\nIn 6.1 Fuel switched to use Linux bonds and bridges for all\ndeployments instead of OVS ones. So we should test deployments\nusing all available bonding types, which do not require\nspecial switch configuration: active-backup, balance-xor,\nbalance-alb, balance-tlb. Also now it's possible to use Nova\nNetwork (both Vlan and FlatDHCP modes) with network bonds, so\nadd modify 50% of cases to use it instead of Neutron.\n\nChange-Id: Ie5d55a537ce3125a20e0926864cba5d42190cbe9\nPartial-bug: #1319413\nRelated-bug: #1455762\n""}, {'number': 2, 'created': '2015-05-19 16:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/d783fbe7121d4cc2cb78e420c138eb229da6c13c', 'message': ""Align tests for bonding with linux bridges/bonds\n\nIn 6.1 Fuel switched to use Linux bonds and bridges for all\ndeployments instead of OVS ones. So we should test deployments\nusing all available bonding types, which do not require\nspecial switch configuration: active-backup, balance-xor,\nbalance-alb, balance-tlb. Also now it's possible to use Nova\nNetwork (both Vlan and FlatDHCP modes) with network bonds, so\nmodify 50% of existing cases to use it instead of Neutron.\n\nChange-Id: Ie5d55a537ce3125a20e0926864cba5d42190cbe9\nPartial-bug: #1319413\nRelated-bug: #1455762\n""}, {'number': 3, 'created': '2015-05-20 08:42:28.000000000', 'files': ['fuelweb_test/tests/test_bonding.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/595c43c655e2b84ce096b25b60797ea6d6d2ae26', 'message': ""Align tests for bonding with linux bridges/bonds\n\nIn 6.1 Fuel switched to use Linux bonds and bridges for all\ndeployments instead of OVS ones. So we should test deployments\nusing all available bonding types, which do not require\nspecial switch configuration: active-backup, balance-xor,\nbalance-alb, balance-tlb. Also now it's possible to use Nova\nNetwork (both Vlan and FlatDHCP modes) with network bonds, so\nmodify 50% of existing cases to use it instead of Neutron.\n\nChange-Id: Ie5d55a537ce3125a20e0926864cba5d42190cbe9\nPartial-bug: #1319413\nRelated-bug: #1455762\nPartial-implements: blueprint linux-bonds-system-tests\n""}]",2,184269,595c43c655e2b84ce096b25b60797ea6d6d2ae26,22,12,3,11081,,,0,"Align tests for bonding with linux bridges/bonds

In 6.1 Fuel switched to use Linux bonds and bridges for all
deployments instead of OVS ones. So we should test deployments
using all available bonding types, which do not require
special switch configuration: active-backup, balance-xor,
balance-alb, balance-tlb. Also now it's possible to use Nova
Network (both Vlan and FlatDHCP modes) with network bonds, so
modify 50% of existing cases to use it instead of Neutron.

Change-Id: Ie5d55a537ce3125a20e0926864cba5d42190cbe9
Partial-bug: #1319413
Related-bug: #1455762
Partial-implements: blueprint linux-bonds-system-tests
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/69/184269/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_bonding.py'],1,704df571f2ece0583cb233e22e079a24c5b02372,bp/linux-bonds-system-tests,"@test(groups=[""bonding_nova"", ""bonding_ha_one_controller"", ""bonding""]) """"""Deploy cluster with active-backup bonding and Nova Network 4. Setup bonding for all interfaces except admin/pxe 'slave-02': ['compute'], 'slave-03': ['cinder'] 'name': 'lnx-bond0', 'lnx-bond0': [ 'fixed', groups=[""deploy_bonding_balance_xor""]) def deploy_bonding_balance_xor(self): """"""Deploy cluster with balance-xor bonding and Nova Network 4. Setup bonding for all interfaces except admin/pxe Snapshot deploy_bonding_balance_xor 'slave-02': ['compute'], 'slave-03': ['cinder'] 'mode': 'balance-xor', 'name': 'lnx-bond0', 'lnx-bond0': [ 'fixed' self.fuel_web.update_vlan_network_fixed( cluster_id, amount=8, network_size=32) self.env.make_snapshot(""deploy_bonding_balance_xor"") @test(groups=[""bonding_neutron"", ""bonding_ha"", ""bonding""]) groups=[""deploy_bonding_balance_alb""]) def deploy_bonding_balance_alb(self): """"""Deploy cluster with balance-alb bonding and Neutron VLAN 4. Setup bonding for all interfaces except admin/pxe Snapshot deploy_bonding_balance_alb 'slave-05': ['cinder'] 'mode': 'balance-alb', 'name': 'lnx-bond0', 'lnx-bond0': [ self.env.make_snapshot(""deploy_bonding_balance_alb"") groups=[""deploy_bonding_balance_tlb""]) def deploy_bonding_ha_balance_tlb(self): """"""Deploy cluster with balance-alb bonding and Neutron VLAN Snapshot deploy_bonding_ha_balance_tlb 'slave-05': ['cinder'] 'mode': 'balance-tlb', 'name': 'lnx-bond0', 'lnx-bond0': [ self.env.make_snapshot(""deploy_bonding_ha_balance_tlb"")","from proboscis import SkipTestfrom fuelweb_test.settings import OPENSTACK_RELEASE from fuelweb_test.settings import OPENSTACK_RELEASE_REDHAT@test(groups=[""bonding_ha_one_controller"", ""bonding""]) """"""Deploy cluster in ha mode with one controller bonding 4. Setup bonding for all interfaces if OPENSTACK_RELEASE == OPENSTACK_RELEASE_REDHAT: raise SkipTest() segment_type = 'gre' settings={ ""net_provider"": 'neutron', ""net_segment_type"": segment_type, } 'slave-02': ['compute'] 'name': 'ovs-bond0', 'ovs-bond0': [ 'private', net_params = self.fuel_web.client.get_networks(cluster_id) cluster = self.fuel_web.client.get_cluster(cluster_id) assert_equal(str(cluster['net_provider']), 'neutron') assert_equal(str(net_params[""networking_parameters""] ['segmentation_type']), segment_type) groups=[""deploy_bonding_balance_slb""]) def deploy_bonding_balance_slb(self): """"""Deploy cluster in ha mode with 1 controller and bonding 4. Setup bonding for all interfaces Snapshot deploy_bonding_balance_slb if OPENSTACK_RELEASE == OPENSTACK_RELEASE_REDHAT: raise SkipTest() segment_type = 'vlan' settings={ ""net_provider"": 'neutron', ""net_segment_type"": segment_type, } 'slave-02': ['compute'] 'mode': 'balance-slb', 'name': 'ovs-bond0', 'ovs-bond0': [ 'private' net_params = self.fuel_web.client.get_networks(cluster_id) cluster = self.fuel_web.client.get_cluster(cluster_id) assert_equal(str(cluster['net_provider']), 'neutron') assert_equal(str(net_params[""networking_parameters""] ['segmentation_type']), segment_type) self.env.make_snapshot(""deploy_bonding_balance_slb"") @test(groups=[""bonding_ha"", ""bonding""]) groups=[""deploy_bonding_ha_active_backup""]) def deploy_bonding_ha_active_backup(self): """"""Deploy cluster in HA mode with bonding (active backup) 4. Setup bonding for all interfaces Snapshot deploy_bonding_ha_active_backup if OPENSTACK_RELEASE == OPENSTACK_RELEASE_REDHAT: raise SkipTest() 'slave-05': ['compute'] 'mode': 'active-backup', 'name': 'ovs-bond0', 'ovs-bond0': [ self.env.make_snapshot(""deploy_bonding_ha_active_backup"") groups=[""deploy_bonding_ha_balance_slb""]) def deploy_bonding_ha_balance_slb(self): """"""Deploy cluster in HA mode with bonding (balance SLB) Snapshot deploy_bonding_ha_balance_slb if OPENSTACK_RELEASE == OPENSTACK_RELEASE_REDHAT: raise SkipTest() 'slave-05': ['compute'] 'mode': 'balance-slb', 'name': 'ovs-bond0', 'ovs-bond0': [ self.env.make_snapshot(""deploy_bonding_ha_balance_slb"")",42,80
openstack%2Ffuel-web~master~I8a4cde8fe7f681f04efdcbc2e3926e1da1adbaea,openstack/fuel-web,master,I8a4cde8fe7f681f04efdcbc2e3926e1da1adbaea,Update repo configuration control description,MERGED,2015-05-18 16:52:33.000000000,2015-05-20 09:23:34.000000000,2015-05-20 09:11:42.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2015-05-18 16:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fd9f5e23a4e8e577c1c2d4aac8d1126a44a6bc59', 'message': 'Update repo configuration control description\n\nChange-Id: I8a4cde8fe7f681f04efdcbc2e3926e1da1adbaea\nCloses-Bug: #1455661\n'}, {'number': 2, 'created': '2015-05-20 09:00:51.000000000', 'files': ['nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bf62070961ec0599fe4eebafd3f14c1f8563f8a4', 'message': 'Update repo configuration control description\n\nChange-Id: I8a4cde8fe7f681f04efdcbc2e3926e1da1adbaea\nRelated-Bug: #1455661\n'}]",0,184095,bf62070961ec0599fe4eebafd3f14c1f8563f8a4,19,6,2,8735,,,0,"Update repo configuration control description

Change-Id: I8a4cde8fe7f681f04efdcbc2e3926e1da1adbaea
Related-Bug: #1455661
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/95/184095/2 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/fixtures/openstack.yaml'],1,fd9f5e23a4e8e577c1c2d4aac8d1126a44a6bc59,bug/1455661," description: | To create a local repository mirror on the Fuel master node, please follow the instructions provided by running ""fuel-createmirror --help"" on the Fuel master node. Please make sure your Fuel master node has Internet access to the repository before attempting to create a mirror. For more details, please refer to the documentation (https://www.mirantis.com/openstack-documentation/). description: | Please note: the first repository will be considered the operating system mirror that will be used during node provisioning. To create a local repository mirror on the Fuel master node, please follow the instructions provided by running ""fuel-createmirror --help"" on the Fuel master node. Please make sure your Fuel master node has Internet access to the repository before attempting to create a mirror. For more details, please refer to the documentation (https://www.mirantis.com/openstack-documentation/)."," description: ""To create a local repository mirror on the Fuel master node, please follow the instructions provided by running \""fuel-createmirror --help\"" on the Fuel master node.\nPlease make sure your Fuel master node has internet access before attempting to create a mirror.\nFor more detail, please refer to the documentation (https://www.mirantis.com/openstack-documentation/)."" description: ""Please note, the first repo will be considered as Ubuntu mirror and that fact will be used during provisioning procedure.\nTo create a local repository mirror on the Fuel master node, please follow the instructions provided by running \""fuel-createmirror --help\"" on the Fuel master node.\nPlease make sure your Fuel master node has internet access before attempting to create a mirror.\nFor more detail, please refer to the documentation (https://www.mirantis.com/openstack-documentation/).""",9,2
openstack%2Foslo.db~master~I48450ad9d472d4377913ad391a0f5e3ba0f1471f,openstack/oslo.db,master,I48450ad9d472d4377913ad391a0f5e3ba0f1471f,Remove pre-SQLAlchemy-0.9.7 compat utilities,MERGED,2015-04-14 17:55:20.000000000,2015-05-20 08:59:01.000000000,2015-05-20 08:59:01.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 11816}]","[{'number': 1, 'created': '2015-04-14 17:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/fc05b1d6e175dbecc0aee77bd28bc05aa2621b28', 'message': 'Remove pre-SQLAlchemy-0.9.7 compat utilities\n\nNow that requirements.txt is at SQLAlchemy 0.9.7 at the minimum,\nwe can remove the engine_connect compatibility module as well\nas part of the handle_error compatibility module.\n\nIn particular, this gives us the ability to add and remove\nengine_connect events using the event API directly which\ncan be handy in test fixtures.\n\nChange-Id: I48450ad9d472d4377913ad391a0f5e3ba0f1471f\n'}, {'number': 2, 'created': '2015-04-27 23:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/3af89946a2820b6b44920abab2ecc4b3a4b6be0c', 'message': 'Remove pre-SQLAlchemy-0.9.7 compat utilities\n\nNow that requirements.txt is at SQLAlchemy 0.9.7 at the minimum,\nwe can remove the engine_connect compatibility module as well\nas part of the handle_error compatibility module.\n\nIn particular, this gives us the ability to add and remove\nengine_connect events using the event API directly which\ncan be handy in test fixtures.\n\nChange-Id: I48450ad9d472d4377913ad391a0f5e3ba0f1471f\n'}, {'number': 3, 'created': '2015-04-28 14:56:10.000000000', 'files': ['oslo_db/tests/old_import_api/sqlalchemy/test_engine_connect.py', 'oslo/db/sqlalchemy/compat/__init__.py', 'oslo_db/tests/old_import_api/sqlalchemy/test_exc_filters.py', 'oslo_db/sqlalchemy/compat/handle_error.py', 'oslo_db/sqlalchemy/compat/engine_connect.py', 'oslo_db/sqlalchemy/session.py', 'oslo_db/tests/sqlalchemy/test_exc_filters.py', 'oslo_db/tests/sqlalchemy/test_engine_connect.py', 'oslo_db/sqlalchemy/compat/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/4d3a7a662e2049cc7b2bf9b85abb1178d3849139', 'message': 'Remove pre-SQLAlchemy-0.9.7 compat utilities\n\nNow that requirements.txt is at SQLAlchemy 0.9.7 at the minimum,\nwe can remove the engine_connect compatibility module as well\nas part of the handle_error compatibility module.\n\nIn particular, this gives us the ability to add and remove\nengine_connect events using the event API directly which\ncan be handy in test fixtures.\n\nChange-Id: I48450ad9d472d4377913ad391a0f5e3ba0f1471f\n'}]",1,173439,4d3a7a662e2049cc7b2bf9b85abb1178d3849139,16,5,3,11816,,,0,"Remove pre-SQLAlchemy-0.9.7 compat utilities

Now that requirements.txt is at SQLAlchemy 0.9.7 at the minimum,
we can remove the engine_connect compatibility module as well
as part of the handle_error compatibility module.

In particular, this gives us the ability to add and remove
engine_connect events using the event API directly which
can be handy in test fixtures.

Change-Id: I48450ad9d472d4377913ad391a0f5e3ba0f1471f
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/39/173439/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/tests/old_import_api/sqlalchemy/test_engine_connect.py', 'oslo_db/tests/old_import_api/sqlalchemy/test_exc_filters.py', 'oslo_db/sqlalchemy/compat/handle_error.py', 'oslo_db/sqlalchemy/compat/engine_connect.py', 'oslo_db/sqlalchemy/session.py', 'oslo_db/tests/sqlalchemy/test_exc_filters.py', 'oslo_db/tests/sqlalchemy/test_engine_connect.py', 'oslo_db/sqlalchemy/compat/__init__.py']",8,fc05b1d6e175dbecc0aee77bd28bc05aa2621b28,update_for_sqla_097,__all__ = ['handle_error'],"from oslo_db.sqlalchemy.compat import engine_connect as _e_connengine_connect = _e_conn.engine_connect__all__ = [ 'engine_connect', 'handle_error']",21,321
openstack%2Foslo.db~master~I702be362a58155a28482e733e60539d36c039509,openstack/oslo.db,master,I702be362a58155a28482e733e60539d36c039509,Add a keys() method to SQLAlchemy ModelBase,MERGED,2015-05-13 23:14:20.000000000,2015-05-20 08:58:46.000000000,2015-05-20 08:58:44.000000000,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 9107}, {'_account_id': 14027}]","[{'number': 1, 'created': '2015-05-13 23:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/5265ceded0648bb1effd1441910a55deffb55b49', 'message': ""Add a keys() method to SQLAlchemy ModelBase\n\nWith this additional method, it now possible to write directly\ndict(obj), instead of dict(obj.iteritems()), to cast an object to a\ndictionary.\n\nModify also ModelIterator: it doesn't inherit from ModelBase anymore.\n\nChange-Id: I702be362a58155a28482e733e60539d36c039509\n""}, {'number': 2, 'created': '2015-05-19 21:54:21.000000000', 'files': ['oslo_db/tests/sqlalchemy/test_models.py', 'oslo_db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/60f80b5ded35613f5d3fda235e18b81ffd0f45d1', 'message': ""Add a keys() method to SQLAlchemy ModelBase\n\nWith this additional method, it now possible to write directly\ndict(obj), instead of dict(obj.iteritems()), to cast an object to a\ndictionary.\n\nModify also ModelIterator: it doesn't inherit from ModelBase anymore.\n\nChange-Id: I702be362a58155a28482e733e60539d36c039509\n""}]",3,182877,60f80b5ded35613f5d3fda235e18b81ffd0f45d1,14,5,2,9107,,,0,"Add a keys() method to SQLAlchemy ModelBase

With this additional method, it now possible to write directly
dict(obj), instead of dict(obj.iteritems()), to cast an object to a
dictionary.

Modify also ModelIterator: it doesn't inherit from ModelBase anymore.

Change-Id: I702be362a58155a28482e733e60539d36c039509
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/77/182877/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/tests/sqlalchemy/test_models.py', 'oslo_db/sqlalchemy/models.py']",2,5265ceded0648bb1effd1441910a55deffb55b49,py3_keys," local = dict((key, value) for key, value in self) def keys(self): """"""Make the model object behave like a dict."""""" keys = [] for key, value in self.iteritems(): keys.append(key) return keys class ModelIterator(six.Iterator):"," local = dict(self) class ModelIterator(ModelBase, six.Iterator):",31,3
openstack%2Ftripleo-heat-templates~master~I497538510f80a356e876d476024671b787b77fc9,openstack/tripleo-heat-templates,master,I497538510f80a356e876d476024671b787b77fc9,Consolidate use of $pacemaker_master in step 2,MERGED,2015-05-18 14:59:53.000000000,2015-05-20 08:55:19.000000000,2015-05-20 08:55:18.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 7984}, {'_account_id': 8042}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-05-18 14:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/64b109d1e4c33291c6ea028adb29813c3a7fdf28', 'message': 'Consolidate use of $pacemaker_master in step 2\n\nAlso moves configuration of clustercheck script into step 3, this\nwill eventually be used by HAProxy when an appropriate resource\nto monitor the service will be added.\n\nChange-Id: I497538510f80a356e876d476024671b787b77fc9\n'}, {'number': 2, 'created': '2015-05-18 16:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1a887653677a593da23237825fe6e621bdda75cb', 'message': 'Consolidate use of $pacemaker_master in step 2\n\nAims at having the Pacemaker resources configuration happening\nin a single if condition.\n\nChange-Id: I497538510f80a356e876d476024671b787b77fc9\n'}, {'number': 3, 'created': '2015-05-18 16:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9e44e44e92609ef2c043e10bbf8e71675d442547', 'message': 'Consolidate use of $pacemaker_master in step 2\n\nAims at having the Pacemaker resources configuration happening\nin a single if condition.\n\nChange-Id: I497538510f80a356e876d476024671b787b77fc9\n'}, {'number': 4, 'created': '2015-05-19 11:09:03.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e4165af938510ff1352b9657e1e3942f1803e0a7', 'message': 'Consolidate use of $pacemaker_master in step 2\n\nAims at having the Pacemaker resources configuration happening\nin a single if condition.\n\nChange-Id: I497538510f80a356e876d476024671b787b77fc9\n'}]",0,184078,e4165af938510ff1352b9657e1e3942f1803e0a7,22,5,4,6796,,,0,"Consolidate use of $pacemaker_master in step 2

Aims at having the Pacemaker resources configuration happening
in a single if condition.

Change-Id: I497538510f80a356e876d476024671b787b77fc9
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/78/184078/4 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,64b109d1e4c33291c6ea028adb29813c3a7fdf28,pcsk_resource_change," pacemaker::resource::ocf { 'rabbitmq': ocf_agent_name => 'heartbeat:rabbitmq-cluster', resource_params => 'set_policy=\'ha-all ^(?!amq\.).* {""ha-mode"":""all""}\'', clone_params => true, require => Class['::rabbitmq'], } pacemaker::resource::service { $::mongodb::params::service_name : op_params => 'start timeout=120s', clone_params => true, require => Class['::mongodb::server'], before => Exec['mongodb-ready'], } # NOTE (spredzy) : The replset can only be run # once all the nodes have joined the cluster. $mongodb_cluster_ready_command = join(suffix(prefix($mongo_node_ips, '/bin/nc -w1 '), ' 27017 < /dev/null'), ' && ') exec { 'mongodb-ready' : command => $mongodb_cluster_ready_command, timeout => 600, tries => 60, try_sleep => 10, } mongodb_replset { $mongodb_replset : members => $mongo_node_ips_with_port, require => Exec['mongodb-ready'], } pacemaker::resource::ocf { 'galera' : ocf_agent_name => 'heartbeat:galera', op_params => 'promote timeout=300s on-fail=block --master', meta_params => ""master-max=${galera_nodes_count} ordered=true"", resource_params => ""additional_parameters='--open-files-limit=16384' enable_creation=true wsrep_cluster_address='gcomm://${galera_nodes}'"", require => Class['::mysql::server'], before => Exec['galera-ready'], } exec { 'galera-ready' : command => '/bin/mysql -e ""SHOW GLOBAL VARIABLES LIKE \'read_only\'"" | /bin/grep -i off', timeout => 3600, tries => 60, try_sleep => 60, environment => 'HOME=/root', } mysql_user { 'clustercheckuser@localhost' : password_hash => mysql_password($clustercheck_password), require => Exec['galera-ready'], # TODO: add monitoring service to HAProxy file { '/etc/sysconfig/clustercheck' : ensure => file, content => ""MYSQL_USERNAME=clustercheckuser\n MYSQL_PASSWORD=${clustercheck_password}\n"", } xinetd::service { 'galera-monitor' : port => '9200', server => '/usr/bin/clustercheck', per_source => 'UNLIMITED', log_on_success => '', log_on_failure => 'HOST', flags => 'REUSE', service_type => 'UNLISTED', user => 'root', group => 'root', require => File['/etc/sysconfig/clustercheck'], } $mongo_node_string = join($mongo_node_ips_with_port, ',') $ceilometer_mongodb_conn_string = ""mongodb://${mongo_node_string}/ceilometer?replicaSet=${mongodb_replset}""} #END STEP 3/4"," } # MongoDB if downcase(hiera('ceilometer_backend')) == 'mongodb' { $mongo_node_string = join($mongo_node_ips_with_port, ',') $ceilometer_mongodb_conn_string = ""mongodb://${mongo_node_string}/ceilometer?replicaSet=${mongodb_replset}"" if downcase(hiera('bootstrap_nodeid')) == $::hostname { pacemaker::resource::service { $::mongodb::params::service_name : op_params => 'start timeout=120s', clone_params => true, require => Class['::mongodb::server'], before => Exec['mongodb-ready'], } # NOTE (spredzy) : The replset can only be run # once all the nodes have joined the cluster. $mongodb_cluster_ready_command = join(suffix(prefix($mongo_node_ips, '/bin/nc -w1 '), ' 27017 < /dev/null'), ' && ') exec { 'mongodb-ready' : command => $mongodb_cluster_ready_command, timeout => 600, tries => 60, try_sleep => 10, before => Mongodb_replset[$mongodb_replset], } mongodb_replset { $mongodb_replset : members => $mongo_node_ips_with_port, } # Galera if $pacemaker_master { pacemaker::resource::ocf { 'galera' : ocf_agent_name => 'heartbeat:galera', op_params => 'promote timeout=300s on-fail=block --master', meta_params => ""master-max=${galera_nodes_count} ordered=true"", resource_params => ""additional_parameters='--open-files-limit=16384' enable_creation=true wsrep_cluster_address='gcomm://${galera_nodes}'"", require => Class['::mysql::server'], before => Exec['galera-ready'], } mysql_user { 'clustercheckuser@localhost' : password_hash => mysql_password($clustercheck_password), require => Exec['galera-ready'], } } exec { 'galera-ready' : command => '/bin/mysql -e ""SHOW GLOBAL VARIABLES LIKE \'read_only\'"" | /bin/grep -i off', timeout => 3600, tries => 60, try_sleep => 60, environment => 'HOME=/root', require => Class['::mysql::server'], } file { '/etc/sysconfig/clustercheck' : ensure => file, content => ""MYSQL_USERNAME=clustercheckuser\n MYSQL_PASSWORD=${clustercheck_password}\n MYSQL_HOST=localhost\n"", require => Exec['galera-ready'], } xinetd::service { 'galera-monitor' : port => '9200', server => '/usr/bin/clustercheck', per_source => 'UNLIMITED', log_on_success => '', log_on_failure => 'HOST', flags => 'REUSE', service_type => 'UNLISTED', user => 'root', group => 'root', require => File['/etc/sysconfig/clustercheck'], } # RabbitMQ if $pacemaker_master { pacemaker::resource::ocf { 'rabbitmq': ocf_agent_name => 'heartbeat:rabbitmq-cluster', resource_params => 'set_policy=\'ha-all ^(?!amq\.).* {""ha-mode"":""all""}\'', clone_params => true, require => Class['::rabbitmq'], } } } #END STEP 3",66,85
openstack%2Ffuel-web~master~Ia9ec311ecaeaf11ada51886934e4fe1406b81720,openstack/fuel-web,master,Ia9ec311ecaeaf11ada51886934e4fe1406b81720,Fix grammatical errors in documentation,MERGED,2015-05-19 20:12:41.000000000,2015-05-20 08:54:42.000000000,2015-05-20 08:43:02.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8749}, {'_account_id': 8777}, {'_account_id': 8789}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10474}]","[{'number': 1, 'created': '2015-05-19 20:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9806cdcda6229e3fd6721b05f86d2140251258e4', 'message': 'Fix grammatical errors in documentation\n\nThere were a few grammatical errors in the documentation for\nthe new fuel-createmirror command.  Fixed these errors for\nbetter presentation and readability.\n\nChange-Id: Ia9ec311ecaeaf11ada51886934e4fe1406b81720\n'}, {'number': 2, 'created': '2015-05-19 20:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1985a760936d111a816aed5906136c7202af3b45', 'message': 'Fix grammatical errors in documentation\n\nThere were a few grammatical errors in the documentation for\nthe new fuel-createmirror command.  Fixed these errors for\nbetter presentation and readability.\n\nChange-Id: Ia9ec311ecaeaf11ada51886934e4fe1406b81720\n'}, {'number': 3, 'created': '2015-05-19 22:07:25.000000000', 'files': ['nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7e6d0722e5207dffa14871e7cad0eb47d0aa6a27', 'message': 'Fix grammatical errors in documentation\n\nThere were a few grammatical errors in the documentation for\nthe new fuel-createmirror command.  Fixed these errors for\nbetter presentation and readability.\n\nChange-Id: Ia9ec311ecaeaf11ada51886934e4fe1406b81720\n'}]",1,184320,7e6d0722e5207dffa14871e7cad0eb47d0aa6a27,25,9,3,14953,,,0,"Fix grammatical errors in documentation

There were a few grammatical errors in the documentation for
the new fuel-createmirror command.  Fixed these errors for
better presentation and readability.

Change-Id: Ia9ec311ecaeaf11ada51886934e4fe1406b81720
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/20/184320/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/fixtures/openstack.yaml'],1,9806cdcda6229e3fd6721b05f86d2140251258e4,fix-grammatical-error," description: ""Please note, the first repo will be considered an Ubuntu mirror and will be used during provisioning procedure.\nTo create a local repository mirror on the Fuel master node, please follow the instructions provided by running \""fuel-createmirror --help\"" on the Fuel master node.\nPlease make sure your Fuel master node has internet access before attempting to create a mirror.\nFor more detail, please refer to the documentation (https://www.mirantis.com/openstack-documentation/)."""," description: ""Please note, the first repo will be considered as Ubuntu mirror and that fact will be used during provisioning procedure.\nTo create a local repository mirror on the Fuel master node, please follow the instructions provided by running \""fuel-createmirror --help\"" on the Fuel master node.\nPlease make sure your Fuel master node has internet access before attempting to create a mirror.\nFor more detail, please refer to the documentation (https://www.mirantis.com/openstack-documentation/).""",1,1
openstack%2Fnova~master~I899c053246f9eb4ac9b13a8434161a82193d1cef,openstack/nova,master,I899c053246f9eb4ac9b13a8434161a82193d1cef,Incorrect argument order passed to swap_volume,MERGED,2015-05-05 19:31:41.000000000,2015-05-20 08:52:51.000000000,2015-05-06 16:15:31.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4523}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-05 19:31:41.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/80832d9bb42da2b86853748874ad38dd30b9342d', 'message': 'Incorrect argument order passed to swap_volume\n\nswap_volume method in _ComputeV4Proxy has incorrect\nargument ordering, due to which attach volume migration\nis failing with AttributeError\nModified the _ComputeV4Proxy detach_volume to have correct\nargument ordering.\n\nChange-Id: I899c053246f9eb4ac9b13a8434161a82193d1cef\nCloses-Bug: #1451860\n'}]",1,180279,80832d9bb42da2b86853748874ad38dd30b9342d,25,14,1,14806,,,0,"Incorrect argument order passed to swap_volume

swap_volume method in _ComputeV4Proxy has incorrect
argument ordering, due to which attach volume migration
is failing with AttributeError
Modified the _ComputeV4Proxy detach_volume to have correct
argument ordering.

Change-Id: I899c053246f9eb4ac9b13a8434161a82193d1cef
Closes-Bug: #1451860
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/180279/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,80832d9bb42da2b86853748874ad38dd30b9342d,fix-bug-1451860," return self.manager.swap_volume(ctxt, old_volume_id, new_volume_id, instance)"," return self.manager.swap_volume(ctxt, instance, old_volume_id, new_volume_id)",2,2
openstack%2Ftripleo-heat-templates~master~I724c341f148fedf725f3b3da778e491741b754ae,openstack/tripleo-heat-templates,master,I724c341f148fedf725f3b3da778e491741b754ae,Enable VIPs via Pacemaker from step 2 instead of step 1,MERGED,2015-05-18 14:29:04.000000000,2015-05-20 08:51:26.000000000,2015-05-20 08:51:26.000000000,"[{'_account_id': 3}, {'_account_id': 7984}, {'_account_id': 8042}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-05-18 14:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4719b6dae229c5d2e7e3f308abc12b1bb5e89592', 'message': 'Enable VIPs and HAProxy from Pacemaker in step 2\n\nAlso moves ntp synchronization to step 1, where Pacemaker is setup\nand Memacached to step 2, to make sure it is up before the OpenStack\nservices.\n\nChange-Id: I724c341f148fedf725f3b3da778e491741b754ae\n'}, {'number': 2, 'created': '2015-05-18 14:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1b6e252f3cc9336b694b78d649ec7d674c765375', 'message': 'Enable VIPs and HAProxy from Pacemaker in step 2\n\nAlso moves ntp synchronization to step 1, where Pacemaker is setup\nand Memacached to step 2, to make sure it is up before the OpenStack\nservices.\n\nChange-Id: I724c341f148fedf725f3b3da778e491741b754ae\n'}, {'number': 3, 'created': '2015-05-18 15:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b04782afce72f5cc9ac5fdd0de0538c9a4eb188f', 'message': 'Enable VIPs and HAProxy via Pacemaker from step 2\n\nChange-Id: I724c341f148fedf725f3b3da778e491741b754ae\n'}, {'number': 4, 'created': '2015-05-19 08:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/37f4381383cdb45caca338de88add95a6813b2c1', 'message': 'Enable VIPs via Pacemaker from step 2 instead of step 1\n\nChange-Id: I724c341f148fedf725f3b3da778e491741b754ae'}, {'number': 5, 'created': '2015-05-19 11:09:03.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5f83a28bd43c85ff4355cbc33071c1eb97d3816e', 'message': 'Enable VIPs via Pacemaker from step 2 instead of step 1\n\nChange-Id: I724c341f148fedf725f3b3da778e491741b754ae\n'}]",0,184072,5f83a28bd43c85ff4355cbc33071c1eb97d3816e,21,4,5,6796,,,0,"Enable VIPs via Pacemaker from step 2 instead of step 1

Change-Id: I724c341f148fedf725f3b3da778e491741b754ae
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/72/184072/4 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,4719b6dae229c5d2e7e3f308abc12b1bb5e89592,pcsk_resource_change," if count(hiera('ntp::servers')) > 0 { include ::ntp } if $pacemaker_master { $control_vip = hiera('tripleo::loadbalancer::controller_virtual_ip') pacemaker::resource::ip { 'control_vip': ip_address => $control_vip, } $public_vip = hiera('tripleo::loadbalancer::public_virtual_ip') pacemaker::resource::ip { 'public_vip': ip_address => $public_vip, } pacemaker::resource::service { 'haproxy': clone_params => true, } # Memcached include ::memcached "," if $pacemaker_master { $control_vip = hiera('tripleo::loadbalancer::controller_virtual_ip') pacemaker::resource::ip { 'control_vip': ip_address => $control_vip, } $public_vip = hiera('tripleo::loadbalancer::public_virtual_ip') pacemaker::resource::ip { 'public_vip': ip_address => $public_vip, } } Class['::pacemaker::corosync'] -> Pacemaker::Resource::Ip <| |> Class['::pacemaker::corosync'] -> Pacemaker::Resource::Ocf <| |> Class['::pacemaker::corosync'] -> Pacemaker::Resource::Service <| |> pacemaker::resource::service { 'haproxy': clone_params => true, } if count(hiera('ntp::servers')) > 0 { include ::ntp include ::memcached",19,21
openstack%2Ffuel-library~master~I3bd5d2eb3e4ea8f1cf55dbbe1c99ce40066a9063,openstack/fuel-library,master,I3bd5d2eb3e4ea8f1cf55dbbe1c99ce40066a9063,Enable Compute v3 API,ABANDONED,2014-11-24 14:02:26.000000000,2015-05-20 08:50:47.000000000,,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-11-24 14:02:26.000000000', 'files': ['deployment/puppet/nova/manifests/keystone/auth.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/427f6e4497f61e298d53daea08991de262792dea', 'message': 'Enable Compute v3 API\n\nChange-Id: I3bd5d2eb3e4ea8f1cf55dbbe1c99ce40066a9063\n'}]",0,136761,427f6e4497f61e298d53daea08991de262792dea,9,3,1,13454,,,0,"Enable Compute v3 API

Change-Id: I3bd5d2eb3e4ea8f1cf55dbbe1c99ce40066a9063
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/61/136761/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nova/manifests/keystone/auth.pp'],1,427f6e4497f61e298d53daea08991de262792dea,fix_enable_compute_v3_api," $configure_v3_endpoint = true, keystone_service { ""${auth_name}_v3"": ensure => present, type => 'computev3', description => 'Openstack Compute Service v3', } if $configure_v3_endpoint { keystone_endpoint { ""${region}/${auth_name}_v3"": ensure => present, public_url => ""${public_protocol}://${public_address}:${compute_port}/v3/%(tenant_id)s"", admin_url => ""${admin_protocol}://${admin_address}:${compute_port}/v3/%(tenant_id)s"", internal_url => ""${internal_protocol}://${internal_address}:${compute_port}/v3/%(tenant_id)s"", } } nova_config { 'osapi_v3/enabled': value => 'true' }",,16,0
openstack%2Ffuel-library~master~I2f66a386097b7fa5bfd05c0d732965c0384dddcd,openstack/fuel-library,master,I2f66a386097b7fa5bfd05c0d732965c0384dddcd,start_guests_on_host_boot was removed in grizzly release.,ABANDONED,2014-11-11 15:48:04.000000000,2015-05-20 08:50:21.000000000,,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 8971}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-11-11 15:48:04.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3f2f2ed779f1921467b28d2c3f96ee26a6bf60cf', 'message': 'start_guests_on_host_boot was removed in grizzly release.\n\nChange-Id: I2f66a386097b7fa5bfd05c0d732965c0384dddcd\n'}]",0,133730,3f2f2ed779f1921467b28d2c3f96ee26a6bf60cf,9,4,1,13454,,,0,"start_guests_on_host_boot was removed in grizzly release.

Change-Id: I2f66a386097b7fa5bfd05c0d732965c0384dddcd
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/30/133730/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp']",2,3f2f2ed779f1921467b28d2c3f96ee26a6bf60cf,fix_puppet_manifest,, nova_config { 'DEFAULT/start_guests_on_host_boot': value => $::fuel_settings['start_guests_on_host_boot'] },0,2
openstack%2Ftripleo-heat-templates~master~I84121a687ee5ddb522239ecefd4d1d76c2f910b5,openstack/tripleo-heat-templates,master,I84121a687ee5ddb522239ecefd4d1d76c2f910b5,Move NTP and Memacache respectively into step 1 and step 2,MERGED,2015-05-18 13:44:06.000000000,2015-05-20 08:48:15.000000000,2015-05-20 08:48:15.000000000,"[{'_account_id': 3}, {'_account_id': 7984}, {'_account_id': 8042}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-05-18 13:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7019b2ce4e47b5c14ee5deb674a1b6f65c5ef1c', 'message': 'Let sync_db param alone orchestrate on which node db_sync run\n\nChange-Id: I84121a687ee5ddb522239ecefd4d1d76c2f910b5\n'}, {'number': 2, 'created': '2015-05-18 15:47:38.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5b6bcf0245061db1ca5bdaf59fc371d982f00b12', 'message': 'Move NTP and Memacache respectively into step 1 and step 2\n\nNTP synchronization is moved to to step 1 where initial Pacemaker\nconfiguration is performed.\n\nMemacached is moved to step 2 to make sure it is up before the\nOpenStack services are started.\n\nChange-Id: I84121a687ee5ddb522239ecefd4d1d76c2f910b5\n'}]",1,184063,5b6bcf0245061db1ca5bdaf59fc371d982f00b12,13,4,2,6796,,,0,"Move NTP and Memacache respectively into step 1 and step 2

NTP synchronization is moved to to step 1 where initial Pacemaker
configuration is performed.

Memacached is moved to step 2 to make sure it is up before the
OpenStack services are started.

Change-Id: I84121a687ee5ddb522239ecefd4d1d76c2f910b5
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/63/184063/2 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,f7019b2ce4e47b5c14ee5deb674a1b6f65c5ef1c,pcsk_resource_change, $sync_db = true $sync_db = false," $sync_db = true } else { $sync_db = false # FIXME: this should only occur on the bootstrap host (ditto for db syncs) # Create all the database schemas # Example DSN format: mysql://user:password@host/dbname if $sync_db { $allowed_hosts = ['%',hiera('controller_host')] $keystone_dsn = split(hiera('keystone::database_connection'), '[@:/?]') class { 'keystone::db::mysql': user => $keystone_dsn[3], password => $keystone_dsn[4], host => $keystone_dsn[5], dbname => $keystone_dsn[6], allowed_hosts => $allowed_hosts, require => Exec['galera-ready'], } $glance_dsn = split(hiera('glance::api::database_connection'), '[@:/?]') class { 'glance::db::mysql': user => $glance_dsn[3], password => $glance_dsn[4], host => $glance_dsn[5], dbname => $glance_dsn[6], allowed_hosts => $allowed_hosts, require => Exec['galera-ready'], } $nova_dsn = split(hiera('nova::database_connection'), '[@:/?]') class { 'nova::db::mysql': user => $nova_dsn[3], password => $nova_dsn[4], host => $nova_dsn[5], dbname => $nova_dsn[6], allowed_hosts => $allowed_hosts, require => Exec['galera-ready'], } $neutron_dsn = split(hiera('neutron::server::database_connection'), '[@:/?]') class { 'neutron::db::mysql': user => $neutron_dsn[3], password => $neutron_dsn[4], host => $neutron_dsn[5], dbname => $neutron_dsn[6], allowed_hosts => $allowed_hosts, require => Exec['galera-ready'], } $cinder_dsn = split(hiera('cinder::database_connection'), '[@:/?]') class { 'cinder::db::mysql': user => $cinder_dsn[3], password => $cinder_dsn[4], host => $cinder_dsn[5], dbname => $cinder_dsn[6], allowed_hosts => $allowed_hosts, require => Exec['galera-ready'], } $heat_dsn = split(hiera('heat::database_connection'), '[@:/?]') class { 'heat::db::mysql': user => $heat_dsn[3], password => $heat_dsn[4], host => $heat_dsn[5], dbname => $heat_dsn[6], allowed_hosts => $allowed_hosts, require => Exec['galera-ready'], } if downcase(hiera('ceilometer_backend')) == 'mysql' { $ceilometer_dsn = split(hiera('ceilometer_mysql_conn_string'), '[@:/?]') class { 'ceilometer::db::mysql': user => $ceilometer_dsn[3], password => $ceilometer_dsn[4], host => $ceilometer_dsn[5], dbname => $ceilometer_dsn[6], allowed_hosts => $allowed_hosts, require => Exec['galera-ready'], } } } ",2,76
openstack%2Ftempest~master~Id4b50ca81e6b9909d94762243aaa41e303870c65,openstack/tempest,master,Id4b50ca81e6b9909d94762243aaa41e303870c65,Added cleanup for tenant quotas,MERGED,2015-05-04 23:37:06.000000000,2015-05-20 08:48:06.000000000,2015-05-20 08:48:03.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7020}, {'_account_id': 10300}, {'_account_id': 10385}, {'_account_id': 10644}]","[{'number': 1, 'created': '2015-05-04 23:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cba16402fae2db6e5f258661970a31890a485f33', 'message': ""Added cleanup for tenant quotas\n\nBoth the tenant's volume and compute quotas should\nbe reset when cleanup is processing a tenant.\nAdded two new cleanup service classes for this purpose:\nVolumeQuotaService and NovaQuotaService.\n\nChange-Id: Id4b50ca81e6b9909d94762243aaa41e303870c65\n""}, {'number': 2, 'created': '2015-05-13 13:46:05.000000000', 'files': ['tempest/cmd/cleanup_service.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/35c8df0cda92b15d82e673e60f96cb6fd094cb06', 'message': ""Added cleanup for tenant quotas\n\nBoth the tenant's volume and compute quotas should\nbe reset when cleanup is processing a tenant.\nAdded two new cleanup service classes for this purpose:\nVolumeQuotaService and NovaQuotaService.\n\nChange-Id: Id4b50ca81e6b9909d94762243aaa41e303870c65\n""}]",0,179971,35c8df0cda92b15d82e673e60f96cb6fd094cb06,17,7,2,10644,,,0,"Added cleanup for tenant quotas

Both the tenant's volume and compute quotas should
be reset when cleanup is processing a tenant.
Added two new cleanup service classes for this purpose:
VolumeQuotaService and NovaQuotaService.

Change-Id: Id4b50ca81e6b9909d94762243aaa41e303870c65
",git fetch https://review.opendev.org/openstack/tempest refs/changes/71/179971/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cmd/cleanup_service.py'],1,cba16402fae2db6e5f258661970a31890a485f33,cleanup-quotas," if (item_list is None or len(item_list) == 0 or not hasattr(self, 'tenant_id') or self.tenant_id is None or 'tenant_id' not in item_list[0]):class VolumeQuotaService(BaseService): def __init__(self, manager, **kwargs): super(VolumeQuotaService, self).__init__(kwargs) self.client = manager.volume_quotas_client def delete(self): client = self.client try: client.delete_quota_set(self.tenant_id) except Exception as e: LOG.exception(""Delete Volume Quotas exception: %s"" % e) pass def dry_run(self): quotas = self.client.show_quota_usage(self.tenant_id) self.data['volume_quotas'] = quotas class NovaQuotaService(BaseService): def __init__(self, manager, **kwargs): super(NovaQuotaService, self).__init__(kwargs) self.client = manager.quotas_client self.limits_client = manager.limits_client def delete(self): client = self.client try: client.delete_quota_set(self.tenant_id) except Exception as e: LOG.exception(""Delete Quotas exception: %s"" % e) pass def dry_run(self): client = self.limits_client quotas = client.get_absolute_limits() self.data['compute_quotas'] = quotas pid = port['id'] client.remove_router_interface_with_port_id(rid, pid) self.saved_state_json['roles'].keys() and role['name'] != CONF.identity.admin_role)] not in self.saved_state_json['tenants'].keys() and tenant['name'] != CONF.identity.admin_tenant_name)] tenant_services.append(NovaQuotaService) tenant_services.append(VolumeQuotaService)"," if (item_list is None or len(item_list) == 0 or not hasattr(self, 'tenant_id') or self.tenant_id is None or 'tenant_id' not in item_list[0]): self.saved_state_json['roles'].keys() and role['name'] != CONF.identity.admin_role)] not in self.saved_state_json['tenants'].keys() and tenant['name'] != CONF.identity.admin_tenant_name)]",51,9
openstack%2Ftripleo-heat-templates~master~Ia8cb04b214c71afc884647fb20be3cc1a309c194,openstack/tripleo-heat-templates,master,Ia8cb04b214c71afc884647fb20be3cc1a309c194,Ensure sync_db is consumed by Keystone and Cinder classes,MERGED,2015-05-18 13:38:14.000000000,2015-05-20 08:46:24.000000000,2015-05-20 08:45:15.000000000,"[{'_account_id': 3}, {'_account_id': 7984}, {'_account_id': 8042}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-05-18 13:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/924a197e4589ba2ceee223f0d3d72264defa1eee', 'message': 'Ensure sync_db is consumed by Keystone and Cinder classes\n\nChange-Id: Ia8cb04b214c71afc884647fb20be3cc1a309c194\n'}, {'number': 2, 'created': '2015-05-18 15:47:38.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7b6c2a4a7d596df25f249e653086ffb9225d3a37', 'message': 'Ensure sync_db is consumed by Keystone and Cinder classes\n\nChange-Id: Ia8cb04b214c71afc884647fb20be3cc1a309c194\n'}]",0,184059,7b6c2a4a7d596df25f249e653086ffb9225d3a37,13,4,2,6796,,,0,"Ensure sync_db is consumed by Keystone and Cinder classes

Change-Id: Ia8cb04b214c71afc884647fb20be3cc1a309c194
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/59/184059/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,924a197e4589ba2ceee223f0d3d72264defa1eee,pcsk_resource_change," class { '::keystone': sync_db => $sync_db, } class { '::cinder::api': sync_db => $sync_db, }", include ::keystone include ::cinder::api,6,2
openstack%2Ffuel-astute~master~Iceac5103fa7512aeb2a9e10d7e573a200f3c33e3,openstack/fuel-astute,master,Iceac5103fa7512aeb2a9e10d7e573a200f3c33e3,Create required directories before creating a file,MERGED,2015-05-20 08:10:15.000000000,2015-05-20 08:28:55.000000000,2015-05-20 08:27:04.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8971}, {'_account_id': 11082}, {'_account_id': 12200}, {'_account_id': 13445}, {'_account_id': 13948}, {'_account_id': 14543}]","[{'number': 1, 'created': '2015-05-20 08:10:15.000000000', 'files': ['mcagents/erase_node.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/79f913569759836102104953ed6eba32dd4a47d2', 'message': 'Create required directories before creating a file\n\nChange-Id: Iceac5103fa7512aeb2a9e10d7e573a200f3c33e3\nCloses-bug: #1456895\n'}]",0,184431,79f913569759836102104953ed6eba32dd4a47d2,15,9,1,8954,,,0,"Create required directories before creating a file

Change-Id: Iceac5103fa7512aeb2a9e10d7e573a200f3c33e3
Closes-bug: #1456895
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/31/184431/1 && git format-patch -1 --stdout FETCH_HEAD,['mcagents/erase_node.rb'],1,79f913569759836102104953ed6eba32dd4a47d2,bug/1456895,require 'pathname' FileUtils.mkdir_p(Pathname.new(lock_path).dirname),,2,0
openstack%2Frally~master~Ifb2af9780e1391900fffdffd39626869fd2ab97d,openstack/rally,master,Ifb2af9780e1391900fffdffd39626869fd2ab97d,[CTX] Moves context.cleanup under plugins,MERGED,2015-05-17 10:35:46.000000000,2015-05-20 08:28:10.000000000,2015-05-20 08:17:18.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8576}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-17 10:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7eab3abad66f893062720cedcb52f1dc79b2d8fa', 'message': '[CTX] Moves cleanup under plugins.openstack.context\n\nSplit from previous commit for easier reivew\n\nImplements: blueprint split-plugins\nChange-Id: Ifb2af9780e1391900fffdffd39626869fd2ab97d\n'}, {'number': 2, 'created': '2015-05-17 11:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8cf7984293616b1c067cd27517ba5fe43b0a14b0', 'message': '[CTX] Moves cleanup under plugins.openstack.context\n\nSplit from previous commit for easier reivew\n\nImplements: blueprint split-plugins\nChange-Id: Ifb2af9780e1391900fffdffd39626869fd2ab97d\n'}, {'number': 3, 'created': '2015-05-17 14:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7c6a922ff669afcd616a3d47c706ae27f466032b', 'message': '[CTX] Moves cleanup under plugins.openstack.context\n\nSplit from previous commit for easier reivew\n\nImplements: blueprint split-plugins\nChange-Id: Ifb2af9780e1391900fffdffd39626869fd2ab97d\n'}, {'number': 4, 'created': '2015-05-18 05:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/eaa1501ed79810191c85b551bface36732346f3a', 'message': '[CTX] Moves cleanup under plugins.openstack.context\n\nSplit from previous commit for easier reivew\n\nImplements: blueprint split-plugins\nChange-Id: Ifb2af9780e1391900fffdffd39626869fd2ab97d\n'}, {'number': 5, 'created': '2015-05-18 06:33:37.000000000', 'files': ['tests/unit/plugins/openstack/context/cleanup/test_manager.py', 'doc/source/miscellaneous/concepts.rst', 'rally/plugins/openstack/context/servers.py', 'tests/unit/plugins/openstack/context/cleanup/test_resources.py', 'rally/plugins/openstack/context/cleanup/manager.py', 'tests/unit/plugins/openstack/context/cleanup/test_base.py', 'tests/unit/plugins/openstack/context/cleanup/test_context.py', 'rally/plugins/openstack/context/cleanup/context.py', 'rally/plugins/openstack/context/cleanup/resources.py', 'rally/plugins/openstack/context/sahara/sahara_cluster.py', 'rally/plugins/openstack/context/sahara/sahara_image.py', 'rally/plugins/openstack/context/cleanup/base.py', 'rally/plugins/openstack/context/keypair.py', 'tests/unit/plugins/openstack/context/cleanup/__init__.py', 'rally/plugins/openstack/context/images.py', 'rally/plugins/openstack/context/cleanup/__init__.py', 'rally/plugins/openstack/context/stacks.py', 'rally/plugins/openstack/context/sahara/sahara_edp.py', 'rally/plugins/openstack/context/volumes.py', 'rally/plugins/openstack/context/murano_packages.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/d5161001d47900ba2ea0a9737f01ceca6f96cbe8', 'message': '[CTX] Moves context.cleanup under plugins\n\nSplit from previous commit for easier reivew\n\nImplements: blueprint split-plugins\n\nChange-Id: Ifb2af9780e1391900fffdffd39626869fd2ab97d\n'}]",0,183906,d5161001d47900ba2ea0a9737f01ceca6f96cbe8,24,5,5,8576,,,0,"[CTX] Moves context.cleanup under plugins

Split from previous commit for easier reivew

Implements: blueprint split-plugins

Change-Id: Ifb2af9780e1391900fffdffd39626869fd2ab97d
",git fetch https://review.opendev.org/openstack/rally refs/changes/06/183906/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/plugins/openstack/context/cleanup/test_manager.py', 'doc/source/miscellaneous/concepts.rst', 'rally/plugins/openstack/context/servers.py', 'tests/unit/plugins/openstack/context/cleanup/test_resources.py', 'rally/plugins/openstack/context/cleanup/manager.py', 'tests/unit/plugins/openstack/context/cleanup/test_base.py', 'tests/unit/plugins/openstack/context/cleanup/test_context.py', 'rally/plugins/openstack/context/cleanup/context.py', 'rally/plugins/openstack/context/cleanup/resources.py', 'rally/plugins/openstack/context/sahara/sahara_cluster.py', 'rally/plugins/openstack/context/sahara/sahara_image.py', 'rally/plugins/openstack/context/cleanup/base.py', 'rally/plugins/openstack/context/keypair.py', 'tests/unit/plugins/openstack/context/cleanup/__init__.py', 'rally/plugins/openstack/context/images.py', 'rally/plugins/openstack/context/cleanup/__init__.py', 'rally/plugins/openstack/context/stacks.py', 'rally/plugins/openstack/context/sahara/sahara_edp.py', 'rally/plugins/openstack/context/volumes.py', 'rally/plugins/openstack/context/murano_packages.py']",20,7eab3abad66f893062720cedcb52f1dc79b2d8fa,bp/split-plugins,from rally.plugins.openstack.context.cleanup import manager as resource_manager,from rally.benchmark.context.cleanup import manager as resource_manager,23,23
openstack%2Ffuel-web~master~Ic80e1421eea6a3227fc8d890bfdbab933da72fbc,openstack/fuel-web,master,Ic80e1421eea6a3227fc8d890bfdbab933da72fbc,Do not include pending deletion node in upgradable nodes,MERGED,2015-05-19 13:24:32.000000000,2015-05-20 08:27:04.000000000,2015-05-20 08:15:10.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11082}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-05-19 13:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9bba1848341b9e617923381cf75da6f2d32e18d6', 'message': 'Do not include pending deletion node in upgradable nodes\n\nChange-Id: Ic80e1421eea6a3227fc8d890bfdbab933da72fbc\n'}, {'number': 2, 'created': '2015-05-19 13:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e43ebd867f7f0719b79fc1dd0f14d50b0c700be8', 'message': 'Do not include pending deletion node in upgradable nodes\n\nPreviously pending for deletion nodes were included in deployment\nif they were selected for update, by deploying other roles\n\nYou can observe one example of this behaviour in test\n\nChange-Id: Ic80e1421eea6a3227fc8d890bfdbab933da72fbc\n'}, {'number': 3, 'created': '2015-05-19 13:49:25.000000000', 'files': ['nailgun/nailgun/test/unit/test_deployment_nodes_filtering.py', 'nailgun/nailgun/task/helpers.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ea7ea8ffff4b3f0f54ea21d6ef6ca9a01fe2f7aa', 'message': 'Do not include pending deletion node in upgradable nodes\n\nPreviously pending for deletion nodes were included in deployment\nif they were selected for update, by deploying other roles\n\nYou can observe one example of this behaviour in test\n\nCloses-Bug: 1446202\nChange-Id: Ic80e1421eea6a3227fc8d890bfdbab933da72fbc\n'}]",0,184245,ea7ea8ffff4b3f0f54ea21d6ef6ca9a01fe2f7aa,26,9,3,8907,,,0,"Do not include pending deletion node in upgradable nodes

Previously pending for deletion nodes were included in deployment
if they were selected for update, by deploying other roles

You can observe one example of this behaviour in test

Closes-Bug: 1446202
Change-Id: Ic80e1421eea6a3227fc8d890bfdbab933da72fbc
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/45/184245/3 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/integration/test_apply_changes_filtering.py', 'nailgun/nailgun/task/helpers.py']",2,9bba1848341b9e617923381cf75da6f2d32e18d6,bug/1446202, if (node not in nodes_to_deploy and not node.pending_deletion and, if (node not in nodes_to_deploy and,51,1
openstack%2Fopenstack-manuals~master~I3cb6982035180d54b70e37692f7a2cd8795d4225,openstack/openstack-manuals,master,I3cb6982035180d54b70e37692f7a2cd8795d4225,Imported Translations from Transifex,MERGED,2015-05-20 06:13:32.000000000,2015-05-20 07:58:20.000000000,2015-05-20 07:58:17.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-05-20 06:13:32.000000000', 'files': ['doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/common/locale/common.pot', 'doc/image-guide/locale/zh_CN.po', 'doc/image-guide/locale/fr.po', 'doc/common/locale/ja.po', 'doc/common/locale/zh_CN.po', 'doc/image-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/629eb8253f29b21660d8b4712c8fac25b2eee2e4', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I3cb6982035180d54b70e37692f7a2cd8795d4225\n'}]",0,184416,629eb8253f29b21660d8b4712c8fac25b2eee2e4,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I3cb6982035180d54b70e37692f7a2cd8795d4225
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/16/184416/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/common/locale/common.pot', 'doc/image-guide/locale/zh_CN.po', 'doc/image-guide/locale/fr.po', 'doc/common/locale/ja.po', 'doc/common/locale/zh_CN.po', 'doc/image-guide/locale/ja.po']",8,629eb8253f29b21660d8b4712c8fac25b2eee2e4,transifex/translations,"""POT-Creation-Date: 2015-05-19 21:50+0000\n"" ""PO-Revision-Date: 2015-05-19 09:26+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgid ""<literal>aki</literal>. An Amazon kernel image."" msgstr ""<literal>aki</literal>。Amazon カーネルイメージ。"" msgid ""<literal>ari</literal>. An Amazon ramdisk image."" msgstr ""<literal>ari</literal>。Amazon ラムディスクイメージ。"" msgid ""<literal>ami</literal>. An Amazon machine image."" msgstr ""<literal>ami</literal>。Amazon マシンイメージ。"" ","""POT-Creation-Date: 2015-05-07 20:19+0000\n"" ""PO-Revision-Date: 2015-05-08 04:11+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""msgid """" ""<literal>raw</literal>. An unstructured disk image format; if you have a "" ""file without an extension it is possibly a raw format"" msgstr """" ""<literal>raw</literal>。非構造化ディスクイメージ形式。拡張しないファイルの場"" ""合、おそらく raw 形式です。"" msgid """" ""<literal>vhd</literal>. The VHD disk format, a common disk format used by "" ""virtual machine monitors from VMware, Xen, Microsoft, VirtualBox, and others"" msgstr """" ""<literal>vhd</literal>。VMware, Xen, Microsoft, VirtualBox, およびその他か"" ""ら、仮想マシンモニターにより使用される一般的なディスク形式である VHD ディスク"" ""形式です。"" msgid """" ""<literal>vmdk</literal>. Common disk format supported by many common virtual "" ""machine monitors"" msgstr """" ""<literal>vmdk</literal>。多くの仮想マシンモニターによりサポートされる一般的な"" ""ディスク形式です。"" msgid """" ""<literal>vdi</literal>. Supported by VirtualBox virtual machine monitor and "" ""the QEMU emulator"" msgstr """" ""<literal>vdi</literal>。VirtualBox 仮想マシンモニターおよび QEMU エミュレー"" ""ターによりサポートされます。"" msgid """" ""<literal>iso</literal>. An archive format for the data contents of an "" ""optical disc, such as CD-ROM."" msgstr """" ""<literal>iso</literal>。CD-ROM などの光学ディスクのデータコンテンツ用のアーカ"" ""イブ形式です。"" msgid """" ""<literal>qcow2</literal>. Supported by the QEMU emulator that can expand "" ""dynamically and supports Copy on Write"" msgstr """" ""<literal>qcow2</literal>。QEMU エミュレーターによりサポートされ、動的に拡張で"" ""き、コピー・オン・ライトをサポートします。"" msgid ""<literal>aki</literal>. An Amazon kernel image."" msgstr ""<literal>aki</literal>。Amazon カーネルイメージ。"" msgid ""<literal>ari</literal>. An Amazon ramdisk image."" msgstr ""<literal>ari</literal>。Amazon ラムディスクイメージ。"" msgid ""<literal>ami</literal>. An Amazon machine image."" msgstr ""<literal>ami</literal>。Amazon マシンイメージ。"" ""<link href=\""http://libguestfs.org/virt-sparsify.1.html\"">virt-sparsify</"" ""link> for making an image sparse"" msgstr """" ""<link href=\""http://libguestfs.org/virt-sparsify.1.html\"">virt-sparsify</"" ""link> は、イメージをスパース化できます。"" msgid """" ""<link href=\""http://libguestfs.org/virt-v2v/\"">virt-p2v</link> for "" ""converting a physical machine to an image that runs on KVM"" msgstr """" ""<link href=\""http://libguestfs.org/virt-v2v/\"">virt-p2v</link> は、物理マシン"" ""を KVM で動作するイメージに変換できます。"" msgid """" ""<link href=\""http://libguestfs.org/virt-v2v/\"">virt-v2v</link> for "" ""converting Xen and VMware images to KVM images"" msgstr """" ""<link href=\""http://libguestfs.org/virt-v2v/\"">virt-v2v</link> は、Xen や "" ""VMware のイメージを KVM のイメージに変換できます。"" msgid """"""Here's a simple of example of how to use <placeholder-1/> to resize an "" ""image. Assume we have a 16GB Windows image in qcow2 format that we want to "" ""resize to 50GB. First, we use to identify the partitions:"" msgstr """" ""これは、イメージの容量を変更するために、<placeholder-1/> を使用する方法の簡単"" ""な例です。容量を 50GB に変更したい、qcow2 形式の 16GB Windows イメージがある"" ""と仮定します。まず、パーティションを識別するために使用します。"" msgid """"""If you have a raw virtual machine image that is not using LVM to manage its "" ""partitions. First, use the <placeholder-1/> command to find an unused loop "" ""device. <placeholder-2/>"" msgstr """" ""パーティション管理に LVM を使用していない raw 形式の仮想マシンイメージがある"" ""場合、まず、<placeholder-1/> コマンドを使用して未使用の loop デバイスを見つけ"" ""ます。<placeholder-2/>"" msgid """"""If your partitions are managed with LVM, use losetup and kpartx as in the "" ""previous example to expose the partitions to the host:"" msgstr """" ""LVM を用いてパーティションを管理している場合、パーティションをホストに公開す"" ""るために、前の例にあるとおり losetup と kpartx を使用します。"" msgid """"""The installer installs necessary prerequisites and downloads and installs "" ""the latest <package>bsd-cloudinit</package>."" msgstr """" ""インストーラーは、必要な依存パッケージをインストールし、最新の <package>bsd-"" ""cloudinit</package> をダウンロードしてインストールします。"" msgid """"msgid """" ""Virtual machine images come in different formats, some of which are "" ""described below. In a later chapter, we'll describe how to convert between "" ""formats."" msgstr """" ""仮想マシンイメージは、さまざまな形式があります。いくつかは以下に記載していま"" ""す。後ほどの章で、形式を変換する方法について説明します。"" msgid ""Using sparse representation, so the image size is smaller"" msgstr ""スパースな形式を使用するため、イメージ容量が小さいです。"" msgid ""Support for snapshots"" msgstr ""スナップショットのサポート"" ""Depending on the version of CentOS, the net installer requires that the user "" ""specify either a URL or the web site and a CentOS directory that corresponds "" ""to one of the CentOS mirrors. If the installer asks for a single URL, a "" ""valid URL might be <literal>http://mirror.umd.edu/centos/6/os/x86_64</"" ""literal>."" msgstr """" ""CentOS のバージョンによっては、ユーザーが CentOS のミラーに応じた、URL や "" ""Web サイト、および CentOS のディレクトリをネットワークインストーラーに指定す"" ""る必要があります。インストーラーが URL だけを要求する場合、有効な URL の 1 つ"" ""は <literal>http://mirror.umd.edu/centos/6/os/x86_64</literal> です。"" msgid """"msgid """" ""After the install completes, the <guilabel>Congratulations, your CentOS "" ""installation is complete</guilabel> screen appears."" msgstr """" ""インストール完了後、<guilabel>Congratulations, your CentOS installation is "" ""complete</guilabel> 画面が表示されます。"" ""As of this writing, there are no Oz packages for Ubuntu, so you will need to "" ""either install from source or build your own .deb file."" msgstr """" ""執筆時点で、Ubuntu 用 Oz パッケージがありません。そのため、ソースからインス"" ""トールするか、自分で .deb ファイルをビルドする必要があります。"" msgid """"""After Oz does the initial OS install using the kickstart file, it updates "" ""the image's install packages with <placeholder-1/>. It also removes any "" ""reference to the eth0 device that libvirt creates while Oz does the "" ""customizing, as specified in the <literal>command</literal> section of the "" ""XML file."" msgstr """" ""Oz が、kickstart ファイルを用いて、初期 OS をインストールした後、"" ""<placeholder-1/> を用いてイメージのインストールパッケージを更新します。Oz に"" ""よるカスタマイズ中、XML ファイルの <literal>command</literal> セクションに指"" ""定されたとおり、libvirt が作成した eth0 デバイスへのすべての参照を削除しま"" ""す。"" msgid ""To run this, do, as root:"" msgstr ""root として、このとおり実行します。"" msgid """"msgid """" ""<link href=\""http://www.packer.io/\""> Packer</link> is a tool for creating "" ""machine images for multiple platforms from a single source configuration."" msgstr """" ""<link href=\""http://www.packer.io/\"">Packer</link> は、単一のソース設定から複"" ""数のプラットフォームに対して、マシンイメージを作成するためのツールです。"" msgid ""The CentOS project maintains official images for direct download:"" msgstr """" ""CentOS プロジェクトは、直接ダウンロードできる公式イメージを維持しています。"" msgid """" ""If your deployment uses QEMU or KVM, we recommend using the images in qcow2 "" ""format. The most recent 64-bit qcow2 image as of this writing is <link href="" ""\""http://download.cirros-cloud.net/0.3.3/cirros-0.3.3-x86_64-disk.img"" ""\"">cirros-0.3.3-x86_64-disk.img</link><placeholder-1/>"" msgstr """" ""お使いの環境で QEMU や KVM を使用している場合、qcow2 形式のイメージを使用する"" ""ことを推奨します。執筆時点で最新の 64 ビット qcow2 イメージは <link href="" ""\""http://download.cirros-cloud.net/0.3.3/cirros-0.3.3-x86_64-disk.img"" ""\"">cirros-0.3.3-x86_64-disk.img</link> です。<placeholder-1/>"" msgid """" ""Red Hat maintains official Red Hat Enterprise Linux cloud images. A valid "" ""Red Hat Enterprise Linux subscription is required to download these images:"" msgstr """" ""Red Hat は、Red Hat Enterprise Linux の公式クラウドイメージを作成しています。"" ""これらのイメージをダウンロードするために、Red Hat Enterprise Linux の有効なサ"" ""ブスクリプションが必要になります。"" ""For a Linux-based image to have full functionality in an OpenStack Compute "" ""cloud, there are a few requirements. For some of these, you can fulfill the "" ""requirement by installing the <link href=\""https://cloudinit.readthedocs.org/"" ""en/latest/\""><package>cloud-init</package></link> package. Read this section "" ""before you create your own image to be sure that the image supports the "" ""OpenStack features that you plan to use."" msgstr """" ""Linux イメージが OpenStack クラウドで全機能を利用する場合、いくつかの要件があ"" ""ります。これらのいくつかは、<link href=\""https://cloudinit.readthedocs.org/"" ""en/latest/\""><package>cloud-init</package></link> をインストールすることによ"" ""り、要件を満たせます。イメージを作成する前に、使用する OpenStack の機能をイ"" ""メージがきちんとサポートするために、このセクションを確認してください。"" msgid """"msgid """" ""The partition table for the image describes the original size of the image"" msgstr """" ""イメージのパーティションテーブルは、イメージの元々の容量を記載しています。"" msgid ""The file system for the image fills the original size of the image"" msgstr ""イメージのファイルシステムは、イメージの元々の容量になっています。"" ""You must remove the network persistence rules in the image because they "" ""cause the network interface in the instance to come up as an interface other "" ""than eth0. This is because your image has a record of the MAC address of the "" ""network interface card when it was first installed, and this MAC address is "" ""different each time that the instance boots. You should alter the following "" ""files:"" msgstr """" ""ネットワーク永続化ルールにより、インスタンスのネットワークインターフェースが "" ""eth0 以外のインターフェースとして起動するため、イメージでそのルールを削除する"" ""必要があります。これは、最初にインストールしたときに、ネットワークインター"" ""フェースカードの MAC が記録されるため、インスタンスの起動ごとに別の MAC アド"" ""レスになるためです。以下のファイルを変更します。"" msgid """" ""Replace <filename>/etc/udev/rules.d/70-persistent-net.rules</filename> with "" ""an empty file (contains network persistence rules, including MAC address)"" msgstr """" ""<filename>/etc/udev/rules.d/70-persistent-net.rules</filename> (MAC アドレス"" ""など、ネットワークの永続化設定) を空ファイルで置き換えます。"" msgid """" ""Replace <filename>/lib/udev/rules.d/75-persistent-net-generator.rules</"" ""filename> with an empty file (this generates the file above)"" msgstr """" ""<filename>/lib/udev/rules.d/75-persistent-net-generator.rules</filename> (上"" ""のファイルを生成) を空ファイルで置き換えます。"" msgid """" ""Remove the HWADDR line from <filename>/etc/sysconfig/network-scripts/ifcfg-"" ""eth0</filename> on Fedora-based images"" msgstr """" ""Fedora ベースのイメージの <filename>/etc/sysconfig/network-scripts/ifcfg-"" ""eth0</filename> から HWADDR 行を削除します。"" msgid """"#. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. msgid """" ""@@image: 'figures/virt-manager-new.png'; md5=3528ebfc1b945b7dd80a34897b8fe98e"" msgstr """" ""@@image: 'figures/virt-manager-new.png'; md5=3528ebfc1b945b7dd80a34897b8fe98e"" ""To create a new image, you will need the installation CD or DVD ISO file for "" ""the guest operating system. You'll also need access to a virtualization "" ""tool. You can use KVM for this. Or, if you have a GUI desktop virtualization "" ""tool (such as, VMware Fusion and VirtualBox), you can use that instead and "" ""just convert the file to raw once you're done."" msgstr """" ""新しいイメージを作成するために、ゲストオペレーティングシステムのインストール "" ""CD/DVD の ISO ファイルが必要になります。また、仮想化のツールにアクセスする必"" ""要があります。このために KVM を使用できます。または、(VMware Fusion や "" ""VirtualBox などの) GUI デスクトップ仮想化ツールを持っている場合、代わりにそれ"" ""を使用し、完了後にファイルを raw に変更できます。"" msgid """"""If you plan to create a virtual machine image on a machine that can run X11 "" ""applications, the simplest way to do so is to use the <placeholder-1/> GUI, "" ""which is installable as the <literal>virt-manager</literal> package on both "" ""Fedora-based and Debian-based systems. This GUI has an embedded VNC client "" ""in it that will let you view and interact with the guest's graphical console."" msgstr """" ""X11 アプリケーションを実行できるマシンに仮想マシンイメージを作成する予定なら"" ""ば、最も簡単にそうする方法は、<placeholder-1/> GUI を使用することです。これ"" ""は、Fedora 系と Debian 系のシステムにおいて、<literal>virt-manager</literal> "" ""パッケージとしてインストールできます。この GUI は、ゲストのグラフィカルコン"" ""ソールを表示および操作できる、組み込みの VNC クライアントを持ちます。"" msgid """"",192,987
openstack%2Fproject-config~master~I4f4dc9c2ef15f23b1ca35df6bfb1474068fc2911,openstack/project-config,master,I4f4dc9c2ef15f23b1ca35df6bfb1474068fc2911,surveil-specs: use surveil acl,MERGED,2015-05-14 19:00:56.000000000,2015-05-20 07:50:59.000000000,2015-05-20 07:50:56.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 11312}]","[{'number': 1, 'created': '2015-05-14 19:00:56.000000000', 'files': ['gerrit/projects.yaml', 'gerrit/acls/stackforge/surveil-specs.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/dfabbeafc4120a94ae1fcc00b145cfcad9336985', 'message': 'surveil-specs: use surveil acl\n\nChange-Id: I4f4dc9c2ef15f23b1ca35df6bfb1474068fc2911\n'}]",0,183172,dfabbeafc4120a94ae1fcc00b145cfcad9336985,13,4,1,11312,,,0,"surveil-specs: use surveil acl

Change-Id: I4f4dc9c2ef15f23b1ca35df6bfb1474068fc2911
",git fetch https://review.opendev.org/openstack/project-config refs/changes/72/183172/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/projects.yaml', 'gerrit/acls/stackforge/surveil-specs.config']",2,dfabbeafc4120a94ae1fcc00b145cfcad9336985,,,"[access ""refs/heads/*""] abandon = group surveil-core label-Code-Review = -2..+2 group surveil-core label-Workflow = -1..+1 group surveil-core [access ""refs/tags/*""] pushSignedTag = group surveil-core [receive] requireChangeId = true requireContributorAgreement = true [submit] mergeContent = true ",1,14
openstack%2Fnova~master~Icfd13b3294a9fa0881a5ab01f50864ebcbce393e,openstack/nova,master,Icfd13b3294a9fa0881a5ab01f50864ebcbce393e,Mark ironic credential config as secret,MERGED,2015-05-04 18:21:37.000000000,2015-05-20 07:50:40.000000000,2015-05-07 18:40:13.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 8119}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-04 18:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f3cbf655b76b117e09b3febe6e85ec0eb38b102', 'message': ""Mark ironic credential config as secret\n\nMark ironic credentials as secret so we don't log the values.\n\nDetected with bandit while testing out :\nI3026b81317f0a6322acfc94784899a7453af586f\n\nChange-Id: Icfd13b3294a9fa0881a5ab01f50864ebcbce393e\n""}, {'number': 2, 'created': '2015-05-04 21:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16b47765cc788e1de5cdcc113eaf8afed9d87290', 'message': ""Mark ironic credential config as secret\n\nMark ironic credentials as secret so we don't log the values.\n\nDetected with bandit while testing out:\nI3026b81317f0a6322acfc94784899a7453af586f\n\nChange-Id: Icfd13b3294a9fa0881a5ab01f50864ebcbce393e\n""}, {'number': 3, 'created': '2015-05-05 16:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/792d39100ad04da18730e2931b153d8dc0ebfd74', 'message': ""Mark ironic credential config as secret\n\nMark ironic credentials as secret so we don't log the values.\n\nDetected with bandit while testing out:\nI3026b81317f0a6322acfc94784899a7453af586f\n\nChange-Id: Icfd13b3294a9fa0881a5ab01f50864ebcbce393e\nCloses-Bug: #179857\n""}, {'number': 4, 'created': '2015-05-05 18:13:15.000000000', 'files': ['nova/virt/ironic/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/63aa353c676a094fbf02e799115a884c70a48002', 'message': ""Mark ironic credential config as secret\n\nMark ironic credentials as secret so we don't log the values.\n\nDetected with bandit while testing out:\nI3026b81317f0a6322acfc94784899a7453af586f\n\nChange-Id: Icfd13b3294a9fa0881a5ab01f50864ebcbce393e\nCloses-Bug: #1451931\n""}]",3,179857,63aa353c676a094fbf02e799115a884c70a48002,47,16,4,1849,,,0,"Mark ironic credential config as secret

Mark ironic credentials as secret so we don't log the values.

Detected with bandit while testing out:
I3026b81317f0a6322acfc94784899a7453af586f

Change-Id: Icfd13b3294a9fa0881a5ab01f50864ebcbce393e
Closes-Bug: #1451931
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/179857/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/ironic/driver.py'],1,2f3cbf655b76b117e09b3febe6e85ec0eb38b102,ironic," secret=True, secret=True, secret=True,",,3,0
openstack%2Ffuel-plugins~master~I4ac51d929ee92bd2f2796c886297b9aefc417f2e,openstack/fuel-plugins,master,I4ac51d929ee92bd2f2796c886297b9aefc417f2e,Check exit code for dpkg-scanpackages,MERGED,2015-05-19 09:54:36.000000000,2015-05-20 07:36:16.000000000,2015-05-20 07:35:08.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-05-19 09:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/3792fee47cc11053bea8f68d2b9e79b0c5bc341a', 'message': 'Check exit code for dpkg-scanpackages\n\nChange-Id: I4ac51d929ee92bd2f2796c886297b9aefc417f2e\nPartial-Bug: #1455130\nCloses-Bug: #1447981\n'}, {'number': 2, 'created': '2015-05-19 10:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/71b45ef4bcdb48136138b99bab3975bf280d7226', 'message': 'Check exit code for dpkg-scanpackages\n\nCheck exit code of command and separates stdout and\nstderr data from pipe which prevents merging metadata with\ncommand warning or info output in packages index file.\n\nChange-Id: I4ac51d929ee92bd2f2796c886297b9aefc417f2e\nPartial-Bug: #1455130\nCloses-Bug: #1447981\n'}, {'number': 3, 'created': '2015-05-19 10:47:36.000000000', 'files': ['fuel_plugin_builder/fuel_plugin_builder/actions/build.py', 'fuel_plugin_builder/fuel_plugin_builder/tests/test_utils.py', 'fuel_plugin_builder/fuel_plugin_builder/tests/test_build.py', 'fuel_plugin_builder/fuel_plugin_builder/utils.py'], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/6ceee58ab38033454ca3a3de2d3522b61633b041', 'message': 'Check exit code for dpkg-scanpackages\n\nCheck exit code of command and separates stdout and\nstderr data from pipe which prevents merging metadata with\ncommand warning or info output in packages index file.\n\nChange-Id: I4ac51d929ee92bd2f2796c886297b9aefc417f2e\nPartial-Bug: #1455130\nCloses-Bug: #1447981\n'}]",2,184217,6ceee58ab38033454ca3a3de2d3522b61633b041,26,6,3,14167,,,0,"Check exit code for dpkg-scanpackages

Check exit code of command and separates stdout and
stderr data from pipe which prevents merging metadata with
command warning or info output in packages index file.

Change-Id: I4ac51d929ee92bd2f2796c886297b9aefc417f2e
Partial-Bug: #1455130
Closes-Bug: #1447981
",git fetch https://review.opendev.org/openstack/fuel-plugins refs/changes/17/184217/3 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_plugin_builder/fuel_plugin_builder/actions/build.py', 'fuel_plugin_builder/fuel_plugin_builder/tests/test_utils.py', 'fuel_plugin_builder/fuel_plugin_builder/tests/test_build.py', 'fuel_plugin_builder/fuel_plugin_builder/utils.py']",4,3792fee47cc11053bea8f68d2b9e79b0c5bc341a,bug/1455130,"def exec_piped_cmds(cmds, cwd=None): """"""Execute pipe of commands with logging. Ouput of stdout and stderr of last command will be written in log. :param cmds: list of shell commands :type cmds: list :param cwd: current working directory :type cwd: string or None """""" logger.debug(u'Executing commands ""{0}""'.format("" | "".join(cmds))) std_out = None for cmd in cmds: child = subprocess.Popen( cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE, shell=True, cwd=cwd) std_out, std_err = child.communicate(input=std_out) exit_code = child.returncode if exit_code != 0: logger.debug(u'Stderr of command ""{0}"":'.format(cmd)) logger.debug(std_err) raise errors.ExecutedErrorNonZeroExitCode( u'Shell command executed with ""{0}"" ' 'exit code: {1} '.format(exit_code, cmd)) logger.debug(u'Stdout of command ""{0}"":'.format("" | "".join(cmds))) logger.debug(std_out) logger.debug( u'Command ""{0}"" successfully executed'.format("" | "".join(cmds)) ) ",,67,9
openstack%2Fpython-fuelclient~master~Iaafaa4e190e3ce6749f162972b0b9d60558bf400,openstack/python-fuelclient,master,Iaafaa4e190e3ce6749f162972b0b9d60558bf400,Remove `mode` option and set it internally to ha,ABANDONED,2015-05-19 12:10:29.000000000,2015-05-20 07:11:48.000000000,,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8392}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 14543}]","[{'number': 1, 'created': '2015-05-19 12:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/d5d339a4f41dcaac0cba53e6a298edfb853a18fe', 'message': 'Remove `mode` option and set it internally to ha\n\nAs multinode mode is deprecated, the only possible mode is ha. Therefore\nthe `mode` option for fuel cli is removed.\n\nChange-Id: Iaafaa4e190e3ce6749f162972b0b9d60558bf400\nCloses-Bug: #1456540\n'}, {'number': 2, 'created': '2015-05-19 12:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/d07b1aec4bd3be04df3a73a2584b932c03713f50', 'message': 'Remove `mode` option and set it internally to ha\n\nAs multinode mode is deprecated, the only possible mode is ha. Therefore\nthe `mode` option for fuel cli is removed.\n\nChange-Id: Iaafaa4e190e3ce6749f162972b0b9d60558bf400\nCloses-Bug: #1456540\n'}, {'number': 3, 'created': '2015-05-19 12:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/e89bb8349703e983397d59d31254b80dbcb8a75e', 'message': 'Remove `mode` option and set it internally to ha\n\nAs multinode mode is deprecated, the only possible mode is ha. Therefore\nthe `mode` option for fuel cli is removed.\n\nChange-Id: Iaafaa4e190e3ce6749f162972b0b9d60558bf400\nCloses-Bug: #1456540\n'}, {'number': 4, 'created': '2015-05-19 13:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/290b60931921372550caca3f5089b20a8121640e', 'message': 'Remove `mode` option and set it internally to ha\n\nAs multinode mode is deprecated, the only possible mode is ha. Therefore\nthe `mode` option for fuel cli is removed.\n\nChange-Id: Iaafaa4e190e3ce6749f162972b0b9d60558bf400\nCloses-Bug: #1456540\n'}, {'number': 5, 'created': '2015-05-19 13:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/305906e8ff297c18e27f3569f6aa0a955e8e7e3d', 'message': 'Remove `mode` option and set it internally to ha\n\nAs multinode mode is deprecated, the only possible mode is ha. Therefore\nthe `mode` option for fuel cli is removed.\n\nChange-Id: Iaafaa4e190e3ce6749f162972b0b9d60558bf400\nCloses-Bug: #1456540\n'}, {'number': 6, 'created': '2015-05-19 13:46:27.000000000', 'files': ['fuelclient/cli/actions/environment.py', 'fuelclient/objects/environment.py', 'fuelclient/tests/utils/fake_env.py', 'fuelclient/tests/v1/integration/test_client.py', 'fuelclient/cli/arguments.py', 'fuelclient/v1/environment.py'], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/4b4b58d6fc64eaebff607c5e4683ccf4ddb549c0', 'message': 'Remove `mode` option and set it internally to ha\n\nAs multinode mode is deprecated, the only possible mode is ha. Therefore\nthe `mode` option for fuel cli is removed.\n\nChange-Id: Iaafaa4e190e3ce6749f162972b0b9d60558bf400\nCloses-Bug: #1456540\n'}]",1,184232,4b4b58d6fc64eaebff607c5e4683ccf4ddb549c0,30,10,6,14543,,,0,"Remove `mode` option and set it internally to ha

As multinode mode is deprecated, the only possible mode is ha. Therefore
the `mode` option for fuel cli is removed.

Change-Id: Iaafaa4e190e3ce6749f162972b0b9d60558bf400
Closes-Bug: #1456540
",git fetch https://review.opendev.org/openstack/python-fuelclient refs/changes/32/184232/5 && git format-patch -1 --stdout FETCH_HEAD,"['fuelclient/objects/environment.py', 'fuelclient/tests/utils/fake_env.py', 'fuelclient/tests/v1/integration/test_client.py', 'fuelclient/cli/arguments.py']",4,d5d339a4f41dcaac0cba53e6a298edfb853a18fe,bug/1456540,,"def get_mode_arg(help_msg): return get_arg(""mode"", action=""store"", choices=(""multinode"", ""ha""), default=False, flags=(""-m"", ""--deployment-mode""), help_=help_msg) ",2,17
openstack%2Fpython-barbicanclient~master~I2948ad881109a444bfba7772d303187cdb3a1a89,openstack/python-barbicanclient,master,I2948ad881109a444bfba7772d303187cdb3a1a89,Re-merge CLI test update for auth URL and version,MERGED,2015-05-14 17:28:31.000000000,2015-05-20 07:00:11.000000000,2015-05-20 07:00:10.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 13510}]","[{'number': 1, 'created': '2015-05-14 17:28:31.000000000', 'files': ['functionaltests/cli/v1/behaviors/base_behaviors.py'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/2b5bd9e685a57e8cd9a794fd04312fb44a99ad87', 'message': 'Re-merge CLI test update for auth URL and version\n\nA merge/move lost these changes.  Restoring them.\n\nChange-Id: I2948ad881109a444bfba7772d303187cdb3a1a89\n'}]",0,183120,2b5bd9e685a57e8cd9a794fd04312fb44a99ad87,9,13,1,9234,,,0,"Re-merge CLI test update for auth URL and version

A merge/move lost these changes.  Restoring them.

Change-Id: I2948ad881109a444bfba7772d303187cdb3a1a89
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/20/183120/1 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/cli/v1/behaviors/base_behaviors.py'],1,2b5bd9e685a57e8cd9a794fd04312fb44a99ad87,authuri," arg_list.extend(['--os-project-name', CONF.keymanager.project_name]) # config? arg_list.extend(['--os-identity-api-version', '3.0']) else: arg_list.extend(['--os-auth-url', CONF.identity.uri]) arg_list.extend(['--os-identity-api-version', '2.0'])"," arg_list.extend( ['--os-project-name', CONF.keymanager.project_name]) # config? else: arg_list.extend(['--os-auth-url', CONF.identity.auth_uri])",6,4
openstack%2Fcinder-specs~master~Ie7866e09a4580490f57c375bc706ac22cefedc1d,openstack/cinder-specs,master,Ie7866e09a4580490f57c375bc706ac22cefedc1d,Add volume replication support,MERGED,2014-06-06 06:57:47.000000000,2015-05-20 06:51:40.000000000,2014-06-19 15:28:50.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 4418}, {'_account_id': 4523}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 7265}, {'_account_id': 11079}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-06-06 06:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/028487c6fbbff2fa8f8cba6db4fb730a19764007', 'message': 'Add volume replication support\n\nEnable Cinder to leverage volume replication feature available\nin the storage backends (drivers).\n\nChange-Id: Ie7866e09a4580490f57c375bc706ac22cefedc1d\nImplements: blueprint volume-replication\n'}, {'number': 2, 'created': '2014-06-06 07:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/929e015d159a0debd0612b6c77ca61f2723b2d4b', 'message': 'Add volume replication support\n\nEnable Cinder to leverage volume replication feature available\nin the storage backends (drivers).\n\nChange-Id: Ie7866e09a4580490f57c375bc706ac22cefedc1d\nImplements: blueprint volume-replication\n'}, {'number': 3, 'created': '2014-06-06 07:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/b1e5eac58dbd58a2d26b99726183065cafe1fad4', 'message': 'Add volume replication support\n\nEnable Cinder to leverage volume replication feature available\nin the storage backends (drivers).\n\nChange-Id: Ie7866e09a4580490f57c375bc706ac22cefedc1d\nImplements: blueprint volume-replication\n'}, {'number': 4, 'created': '2014-06-07 20:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/8df0182cdc03b46c3b80be443bb74b3a74135ae1', 'message': 'Add volume replication support\n\nEnable Cinder to leverage volume replication feature available\nin the storage backends (drivers).\n\nChange-Id: Ie7866e09a4580490f57c375bc706ac22cefedc1d\nImplements: blueprint volume-replication\n'}, {'number': 5, 'created': '2014-06-08 06:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/82badc98a21f7bfd65957f44c5ae011e934f544d', 'message': 'Add volume replication support\n\nEnable Cinder to leverage volume replication feature available\nin the storage backends (drivers).\n\nChange-Id: Ie7866e09a4580490f57c375bc706ac22cefedc1d\nImplements: blueprint volume-replication\n'}, {'number': 6, 'created': '2014-06-09 11:05:13.000000000', 'files': ['specs/juno/volume-replication.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/d7d3ac33f81ed5f44451d6b0bc97ec07eb3b253d', 'message': 'Add volume replication support\n\nEnable Cinder to leverage volume replication feature available\nin the storage backends (drivers).\n\nChange-Id: Ie7866e09a4580490f57c375bc706ac22cefedc1d\nImplements: blueprint volume-replication\n'}]",45,98308,d7d3ac33f81ed5f44451d6b0bc97ec07eb3b253d,35,11,6,4418,,,0,"Add volume replication support

Enable Cinder to leverage volume replication feature available
in the storage backends (drivers).

Change-Id: Ie7866e09a4580490f57c375bc706ac22cefedc1d
Implements: blueprint volume-replication
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/08/98308/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/volume-replication.rst'],1,028487c6fbbff2fa8f8cba6db4fb730a19764007,bp/volume-replication," .. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Volume Replication ========================================== https://blueprints.launchpad.net/cinder/+spec/volume-replication Volume replication is a key storage feature and an a requirement for features such as high-availability and disaster recovery of applications running on top of OpenStack clouds. This blueprint is an attempt to add initial support for volume replication in Cinder, and is considered a first take, and will include support for: * Replicate volumes (primary to secondary approach) * Promote a secondary to primary (and stop replication) * Synchronize replication with direction This would further be enhanced in the future. While this blueprint focuses on volume replication, a related blueprint focuses on consistency groups, and replication would be extended to support it. Problem description =================== The main use of volume replication is resiliency in presence of failures. Examples of possible failures are: * Storage system failure * Rack(s) level failure * Datacenter level failure Here we specifically exclude failures like media failures, disk failures, etc. Such failures are typically addressed by local resiliency schemes. Replication can be implemented in the following ways: * Host-based - Requires Nova integration * Storage-based - Typical block based approach - replication is specified between two existing volumes (or group of volumes) on the controllers. - Typically file system based approach - a file (in Cinder context, the file representing a block device) placed in a directory (or group or fileset, etc) that is automatically copied to a specified remote location. Assumptions: * Replication should be transparent to the end-user, failover and failback should be executed by the cloud admin, while test may involve the end-user. * The storage admin will provide the setup and configuration to enable the actual replication between the storage systems. This could be performed at the storage back-end or storage driver level depending on the storage back-end.Specifically, storage drivers are expected to report with whom they can replicate and report this to the scheduler. * The cloud admin will enable the replication feature through the use of volume types. * The end-user will not be directly exposed to the replication feature. Selecting a volume-type will determine if the volume will be replicated, based on the actual extra-spec definition of the volume type (defined by the cloud admin). Proposed change =============== Each Cinder host will report replication capabilities: * Replication_support: indicate if replication is enabled for this driver instance * Replication_unit_id: device specific id used for replication * Replication_partners: list of device specific ids that this node can replicate with * Replication_rpo_range - supported RPO by this driver instance <min,max> * replication_supported_methods - list of methods supported by the back-end. to start with <async>. Add extra-specs in the volume type to indicate replication: * Replication_enabled - volume to be replicated if exists as extra specs * replica_same_az - indicate if replica should be in the same AZ * replica_volume_backend_name - specify back-end to used as target * replication_target_rpo - requested RPO (numeric, minutes) for the volume Create volume with replication enabled: * Scheduler selects two hosts for volume placement and setup the replication DB entry * Manager on primary creates the primary volume (as as done today) * Manager on secondary creates the replica volume * Manager on primary set up the replication Re-type volume: * Replication_enabled: True->False: drop the replication and continue with the regular retype logic. * Replication_enabled: False->True: after the retype logic selects back-ends (scheduler) enable replication. Promote to primary: * Manager on secondary stop the replication. * Switch between volume ids of primary and secondary (user see no change in volume ids) Sync replication: * Manager on primary restarts the replication Test: * Create a clone of the secondary volume. Notes: * Manager acts via the driver for back-end replication specific functions. * Failover is ""primary to primary"". * Failback is ""sync replication"" + ""promote to primary"". Driver API: * create_replica: to be run on secondary to create the volume * enable_replica: to be run on primary to start replication * disable_replica: to be run on primary, stops the replication * delete_replica: to be run on secondary, deletes the replica target volume * replication_status_check: to be run on all hosts, updating the replication status as observed from the back-end perspective * promote_replica: to be run on secondary, make secondary the primary Alternatives ------------ Replication can be performed outside of Cinder, and OpenStack can be unaware of it. However, this requires vendor specific scripts, and is not visible to the user. Data model impact ----------------- * A new replication relationship table will be created. (with its database migration support). * On promote to primary, the ids of the primary and secondary volume entries will change (switch). Replication relationship db table: * id = Column(String(36), primary_key=True) * deleted = Column(Boolean, default=False) * primary_id = Column(String(36), ForeignKey('volumes.id'), nullable=False) * secondary_id = Column(String(36), ForeignKey('volumes.id'), nullable=False) * primary_replication_unit_id = Column(String(255)) * secondary_replication_unit_id = Column(String(255)) * status = Column(Enum('error', 'starting', 'copying', 'active', 'stopping', 'deleting', 'deleted', name='replicationrelationship_status')) * extended_status = Column(String(255)) * driver_data = Column(String(255)) REST API impact --------------- * Show replication relationship * Show information about a volume replication relationship. * Method type: GET * Normal Response Code: 200 * Expected error http response code(s) * 404: replication relationship not found * /v2/<tenant id>/os-volume-replication/<replication uuid> * JSON schema definition for the response data:: { 'relationship': { 'id': 'relationship id' 'primary_id': 'primary volume uuid' 'status': 'status of relationship' 'links': '{ ... }' } } * Show replication relationship with details * Show detailed information about a volume replication relationship. * Method type: GET * Normal Response Code: 200 * Expected error http response code(s) * 404: replication relationship not found * /v2/<tenant id>/os-volume-replication/<replication uuid>/detail * JSON schema definition for the response data:: { 'relationship': { 'id': 'relationship id' 'primary_id': 'primary volume uuid' 'secondary_id': 'secondary volume uuid' 'status': 'status of relationship' 'extended_status': 'extended status' 'links': { ... } } } * List replication relationship with details * List detailed information about a volume replication relationship. * Method type: GET * Normal Response Code: 200 * Expected error http response code(s) * TBD * /v2/<tenant id>/os-volume-replication/detail * Parameters: *status* filter by replication relationship status *primary_id* Filter by primary volume id *secondary_id* Filter by secondary volume id * JSON schema definition for the response data:: { 'relationship': { 'id': 'relationship id' 'primary_id': 'primary volume uuid' 'secondary_id': 'secondary volume uuid' 'status': 'status of relationship' 'extended_status': 'extended status' 'links': { ... } } } * Promote volume to be the primary volume * Switch between the uuids of the primary and secondary volumes, and make the secondary volume the primary volume. * Method type: PUT * Normal Response Code: 202 * Expected error http response code(s) * 404: replication relationship not found * /v2/<tenant id>/os-volume-replication/<replication uuid> * JSON schema definition for the body data:: { 'relationship': { 'promote': None } } * Sync between the primary and secondary volume. * Resync the replication between the primary and secondary volume. Typically follows a promote operation on the replication. * Method type: PUT * Normal Response Code: 202 * Expected error http response code(s) * 404: replication relationship not found * /v2/<tenant id>/os-volume-replication/<replication uuid> * JSON schema definition for the body data:: { 'relationship': { 'sync': None } } * Test replication by make a copy of the secondary volume available * Test the volume replication. Create a clone of the secondary volume and make it accessible, so the promote process can be tested. * Method type: POST * Normal Response Code: 202 * Expected error http response code(s) * 404: replication relationship not found * /v2/<tenant id>/os-volume-replication/<replication uuid>/test * JSON schema definition for the response data:: { 'relationship': { 'volume_id': 'volume id of the cloned secondary' } } Security impact --------------- * Does this change touch sensitive data such as tokens, keys, or user data? *No*. * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? *No*. * Does this change involve cryptography or hashing? *No*. * Does this change require the use of sudo or any elevated privileges? *No*. * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. *No*. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. *Yes*, enabling replication consume cloud and storage resources. Notifications impact -------------------- Will add notification for enabling replication, promoting, syncing and dropping replication. Other end user impact --------------------- * End-user to use volume types to enable/disable replication. * Cloud admin to use the *promote*, *sync* and *test* commands in the python-cinderclient to execute failover, failback and test. Performance Impact ------------------ * Scheduler now needs to choose two hosts instead of one based on additional input from the driver and volume type. * The periodic task will query the driver and back-end for status of all replicated volumes - running on the primary and secondary. * Extra db calls identifying if replication exists are added to retype, snapshot operations, etc will add a small latency to these functions. Other deployer impact --------------------- * Added options for volume types (see above) * Add new driver capabilities, needs to be supported by the volume drivers, which may imply changes to the driver configuration options. * This change will require explicit enablement (to be used by users) from the cloud administrator. Developer impact ---------------- * Change to the driver API is noted above. Basically new functions are needed to support using replication. * The API will expand to include consistency groups following merging consistency group support to Cinder. Implementation ============== Assignee(s) ----------- Primary assignee: ronenkat Other contributors: None Work Items ---------- * Cinder public (admin) APIs for replication * DB schema for replication * Cinder scheduler support for replication * Cinder driver API additions for replication * Cinder manager update for replication * Testing Note: Code is based on https://review.openstack.org/#/c/64026/ which was submitted in the Icehouse development cycle. Dependencies ============ * Related blueprints: Consistency groups https://blueprints.launchpad.net/cinder/+spec/consistency-groups * LVM to support replication using DRBD, in a separate contribution. Testing ======= * Testing in gate is not supported due to the following considerations: * LVM has no replication support, to be addressed using DRBD in a separate contribution. * requires setting up at least two nodes using DRBD * Should be discussed/addressed as support for LVM is added. * 3rd party driver CI will be expected to test replication. Documentation Impact ==================== * Public (admin) API changes. * Details how replication is used by leveraging volume types. * Driver docs explaining how replication is setup for each driver. References ========== * Volume replication design session https://etherpad.openstack.org/p/juno-cinder-volume-replication ",,443,0
openstack%2Ftripleo-common~master~I284cb72b15ffd92a9e50550d84374dfe9e5f94c0,openstack/tripleo-common,master,I284cb72b15ffd92a9e50550d84374dfe9e5f94c0,Scale out heat stack,MERGED,2015-04-14 12:12:24.000000000,2015-05-20 06:47:34.000000000,2015-05-20 06:22:47.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 8042}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-04-14 12:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/da139f2a2faa9039afdaa3bc2cf08ce86b37c2cd', 'message': 'Scale out heat stack\n\nAdds a module which allows scaling nodes in a heat stack\ndeployed using tuskar templates - typically Overcloud in TripleO.\nThis module will be used from CLI/UI.\n\nChange-Id: I284cb72b15ffd92a9e50550d84374dfe9e5f94c0\n'}, {'number': 2, 'created': '2015-04-15 11:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0d3498a69404edc2a1a5f71bb0c35b033325a7b7', 'message': 'Scale out heat stack\n\nAdds a module which allows scaling nodes in a heat stack\ndeployed using tuskar templates - typically Overcloud in TripleO.\nThis module will be used from CLI/UI.\n\nChange-Id: I284cb72b15ffd92a9e50550d84374dfe9e5f94c0\n'}, {'number': 3, 'created': '2015-04-29 12:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/40225d487e5701bf24bc8a86c7f30a028f5c1b53', 'message': 'Scale out heat stack\n\nAdds a module which allows scaling nodes in a heat stack\ndeployed using tuskar templates - typically Overcloud in TripleO.\nThis module will be used from CLI/UI.\n\nChange-Id: I284cb72b15ffd92a9e50550d84374dfe9e5f94c0\n'}, {'number': 4, 'created': '2015-05-07 20:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/86bd3a1daa50571c024aff37cb50d2b6f494cf7f', 'message': 'Scale out heat stack\n\nAdds a module which allows scaling nodes in a heat stack\ndeployed using tuskar templates - typically Overcloud in TripleO.\nThis module will be used from CLI/UI.\n\nChange-Id: I284cb72b15ffd92a9e50550d84374dfe9e5f94c0\n'}, {'number': 5, 'created': '2015-05-11 10:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5fdfd722a9033e7eaa0cc5d9cdc22ae5bebb017a', 'message': 'Scale out heat stack\n\nAdds a module which allows scaling nodes in a heat stack\ndeployed using tuskar templates - typically Overcloud in TripleO.\nThis module will be used from CLI/UI.\n\nChange-Id: I284cb72b15ffd92a9e50550d84374dfe9e5f94c0\n'}, {'number': 6, 'created': '2015-05-12 15:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/79256b1585e20921b43fd335e4e710f18687a856', 'message': 'Scale out heat stack\n\nAdds a module which allows scaling nodes in a heat stack\ndeployed using tuskar templates - typically Overcloud in TripleO.\nThis module will be used from CLI/UI.\n\nChange-Id: I284cb72b15ffd92a9e50550d84374dfe9e5f94c0\n'}, {'number': 7, 'created': '2015-05-19 10:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ae18f8de4fa6daa6b625b23c4b57b0509cc20500', 'message': 'Scale out heat stack\n\nAdds a module which allows scaling nodes in a heat stack\ndeployed using tuskar templates - typically Overcloud in TripleO.\nThis module will be used from CLI/UI.\n\nChange-Id: I284cb72b15ffd92a9e50550d84374dfe9e5f94c0\n'}, {'number': 8, 'created': '2015-05-19 11:24:02.000000000', 'files': ['requirements.txt', 'tripleo_common/libutils.py', 'tripleo_common/tests/test_scale.py', 'tripleo_common/scale.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/606ae04a62d82a0737b9c886bd4a4a8c3649ebe1', 'message': 'Scale out heat stack\n\nAdds a module which allows scaling nodes in a heat stack\ndeployed using tuskar templates - typically Overcloud in TripleO.\nThis module will be used from CLI/UI.\n\nChange-Id: I284cb72b15ffd92a9e50550d84374dfe9e5f94c0\n'}]",4,173283,606ae04a62d82a0737b9c886bd4a4a8c3649ebe1,33,7,8,7582,,,0,"Scale out heat stack

Adds a module which allows scaling nodes in a heat stack
deployed using tuskar templates - typically Overcloud in TripleO.
This module will be used from CLI/UI.

Change-Id: I284cb72b15ffd92a9e50550d84374dfe9e5f94c0
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/83/173283/8 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'tripleo_common/libutils.py', 'tripleo_common/tests/test_scale.py', 'tripleo_common/scale.py']",4,da139f2a2faa9039afdaa3bc2cf08ce86b37c2cd,scale2,"# Copyright 2015 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import libutils import logging from tuskarclient.common import utils as tuskarutils LOG = logging.getLogger(__name__) class ScaleManager(object): def __init__(self, tuskarclient, heatclient, plan_id=None, stack_id=None): self.tuskarclient = tuskarclient self.heatclient = heatclient self.stack_id = stack_id self.plan = tuskarutils.find_resource(self.tuskarclient.plans, plan_id) def scaleup(self, role, num): LOG.debug('updating role %s count to %d', role, num) self.plan = self.tuskarclient.plans.patch( self.plan.uuid, [{'name': '{0}::count'.format(role), 'value': num}]) params = libutils.heat_params_from_templates( self.tuskarclient.plans.templates(self.plan.uuid)) self.heatclient.stacks.update(self.stack_id, **params) ",,143,0
openstack%2Ftacker~master~Idbc302119440081c48e7e7893220cad365efa4fc,openstack/tacker,master,Idbc302119440081c48e7e7893220cad365efa4fc,configure after respawn,MERGED,2015-05-20 06:26:15.000000000,2015-05-20 06:29:46.000000000,2015-05-20 06:29:45.000000000,"[{'_account_id': 3}, {'_account_id': 333}]","[{'number': 1, 'created': '2015-05-20 06:26:15.000000000', 'files': ['tacker/vm/plugin.py', 'tacker/vm/monitor.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/1f2cb05d6729aeda2b303ac66af56e5284c16c6c', 'message': 'configure after respawn\n\nChange-Id: Idbc302119440081c48e7e7893220cad365efa4fc\n'}]",0,184418,1f2cb05d6729aeda2b303ac66af56e5284c16c6c,6,2,1,333,,,0,"configure after respawn

Change-Id: Idbc302119440081c48e7e7893220cad365efa4fc
",git fetch https://review.opendev.org/openstack/tacker refs/changes/18/184418/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/vm/plugin.py', 'tacker/vm/monitor.py']",2,1f2cb05d6729aeda2b303ac66af56e5284c16c6c,refresh," config = attributes.get('config') LOG.debug(_('device config %s dead'), config) if config: new_device_dict.setdefault('attributes', {})['config'] = config",,11,6
openstack%2Fproject-config~master~Iec6237006e2bfc61130c5b48433913e4e427d51e,openstack/project-config,master,Iec6237006e2bfc61130c5b48433913e4e427d51e,Normalize projects.yaml,MERGED,2015-05-20 06:02:01.000000000,2015-05-20 06:20:05.000000000,2015-05-20 06:20:03.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-05-20 06:02:01.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/100060e9a204c4aeb042b2346d8399b8415be714', 'message': 'Normalize projects.yaml\n\nChange-Id: Iec6237006e2bfc61130c5b48433913e4e427d51e\n'}]",0,184413,100060e9a204c4aeb042b2346d8399b8415be714,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: Iec6237006e2bfc61130c5b48433913e4e427d51e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/13/184413/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,100060e9a204c4aeb042b2346d8399b8415be714,project-yaml-normalization, description: Watcher takes advantage of CEP and ML algorithms/metaheuristics to improve physical resources usage through better VM placement., description: 'Watcher takes advantage of CEP and ML algorithms/metaheuristics to improve physical resources usage through better VM placement.',2,2
openstack%2Frally~master~Ia71193163f7d178c8a9e2904b59a1591b1e39010,openstack/rally,master,Ia71193163f7d178c8a9e2904b59a1591b1e39010,[CTX] Split context into plugins,MERGED,2015-05-12 13:13:21.000000000,2015-05-20 06:15:06.000000000,2015-05-20 06:03:10.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8576}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-05-12 13:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b1b19c164ae6429641fce03cc14b584d08a8602f', 'message': '[Context] Split context into plugins\n\nMove openstack related contexts under rally/plugins/openstack/context\n\nNOTE(yfried): cleanup context is untouched. Need to look into it\n\nImplements: blueprint split-plugins\nChange-Id: Ia71193163f7d178c8a9e2904b59a1591b1e39010\n'}, {'number': 2, 'created': '2015-05-12 13:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e858cf5009217d57c8f92b8917573495bc02d689', 'message': '[Context] Split context into plugins\n\nMove openstack related contexts under rally/plugins/openstack/context\n\nNOTE(yfried): cleanup context is untouched. Need to look into it\n\nImplements: blueprint split-plugins\nChange-Id: Ia71193163f7d178c8a9e2904b59a1591b1e39010\n'}, {'number': 3, 'created': '2015-05-17 10:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a1e4554303bf44e09d5c725f26451a7fd4e1567a', 'message': '[Context] Split context into plugins\n\nMove openstack related contexts under rally/plugins/openstack/context\n\nNOTE(yfried): cleanup context is handled in next patch\n\nImplements: blueprint split-plugins\nChange-Id: Ia71193163f7d178c8a9e2904b59a1591b1e39010\n'}, {'number': 4, 'created': '2015-05-17 11:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6d08dc663654ef2843d658a9ac2b5c2aaa1f6f28', 'message': '[Context] Split context into plugins\n\nMove openstack related contexts under rally/plugins/openstack/context\n\nNOTE(yfried): cleanup context is handled in next patch\n\nImplements: blueprint split-plugins\nChange-Id: Ia71193163f7d178c8a9e2904b59a1591b1e39010\n'}, {'number': 5, 'created': '2015-05-17 14:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e049b74ca873ead2599c2ca4432cda32f6e38e94', 'message': '[Context] Split context into plugins\n\nMove openstack related contexts under rally/plugins/openstack/context/\n\nNOTE(yfried): cleanup context is handled in next patch\n\nImplements: blueprint split-plugins\nChange-Id: Ia71193163f7d178c8a9e2904b59a1591b1e39010\n'}, {'number': 6, 'created': '2015-05-18 05:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ab33e26724fcce0dfe2b758ff4164bfa84a5bf14', 'message': '[Context] Split context into plugins\n\nMove openstack related contexts under rally/plugins/openstack/context/\n\nNOTE(yfried): cleanup context is handled in next patch\n\nImplements: blueprint split-plugins\nChange-Id: Ia71193163f7d178c8a9e2904b59a1591b1e39010\n'}, {'number': 7, 'created': '2015-05-18 06:33:37.000000000', 'files': ['rally/plugins/openstack/context/quotas/cinder_quotas.py', 'rally/plugins/common/context/dummy.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_cluster.py', 'rally/plugins/openstack/context/flavors.py', 'tests/unit/plugins/openstack/context/__init__.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_image.py', 'rally/plugins/openstack/context/quotas/__init__.py', 'rally/plugins/openstack/context/tempest.py', 'rally/plugins/openstack/context/keypair.py', 'tests/unit/plugins/openstack/context/test_network.py', 'rally/plugins/openstack/context/images.py', 'tests/unit/plugins/common/context/__init__.py', 'tests/unit/plugins/openstack/context/quotas/__init__.py', 'tests/unit/plugins/openstack/context/vm/test_custom_image.py', 'rally/plugins/openstack/context/stacks.py', 'rally/plugins/openstack/context/volumes.py', 'tests/unit/plugins/openstack/context/test_murano_packages.py', 'rally/plugins/openstack/context/roles.py', 'rally/plugins/openstack/context/servers.py', 'tests/unit/plugins/openstack/context/quotas/test_designate_quotas.py', 'rally/plugins/openstack/context/quotas/designate_quotas.py', 'tests/unit/plugins/openstack/context/sahara/__init__.py', 'rally/plugins/openstack/context/vm/custom_image.py', 'rally/benchmark/engine.py', 'rally/plugins/openstack/context/sahara/sahara_cluster.py', 'rally/plugins/openstack/context/sahara/sahara_image.py', 'rally/plugins/openstack/context/users.py', 'tests/unit/plugins/openstack/context/test_existing_users.py', 'tests/unit/plugins/openstack/context/quotas/test_cinder_quotas.py', 'tests/unit/plugins/openstack/context/test_servers.py', 'rally/plugins/openstack/context/sahara/__init__.py', 'tests/unit/plugins/openstack/context/test_roles.py', 'tests/unit/plugins/openstack/context/test_ceilometer.py', 'tests/unit/plugins/openstack/context/test_volumes.py', 'tests/unit/plugins/openstack/context/test_keypair.py', 'rally/plugins/common/context/__init__.py', 'rally/plugins/openstack/context/ceilometer.py', 'tests/unit/plugins/openstack/context/vm/__init__.py', 'tests/unit/plugins/openstack/context/test_flavors.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_edp.py', 'rally/plugins/openstack/context/__init__.py', 'tests/unit/plugins/openstack/context/test_tempest.py', 'rally/plugins/openstack/context/network.py', 'rally/plugins/openstack/context/quotas/quotas.py', 'tests/unit/plugins/openstack/context/quotas/test_nova_quotas.py', 'tests/unit/plugins/openstack/context/quotas/test_quotas.py', 'tests/unit/plugins/openstack/context/test_users.py', 'rally/plugins/openstack/context/quotas/neutron_quotas.py', 'tests/unit/plugins/openstack/context/test_stacks.py', 'rally/common/opts.py', 'rally/benchmark/validation.py', 'tests/unit/plugins/openstack/context/test_images.py', 'rally/plugins/openstack/context/quotas/nova_quotas.py', 'tests/unit/plugins/common/context/test_dummy.py', 'tests/unit/benchmark/test_engine.py', 'tests/unit/plugins/openstack/context/quotas/test_neutron_quotas.py', 'tests/unit/plugins/openstack/context/test_secgroup.py', 'rally/plugins/openstack/context/sahara/sahara_edp.py', 'rally/plugins/openstack/context/murano_packages.py', 'rally/plugins/openstack/context/secgroup.py', 'rally/plugins/openstack/context/existing_users.py', 'rally/plugins/openstack/context/vm/__init__.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/35b011fdd81a9042fe26a19cc31e0dae57b41e7b', 'message': '[CTX] Split context into plugins\n\nMove openstack related contexts under rally/plugins/openstack/context/\n\nNOTE(yfried): cleanup context is handled in next patch\n\nImplements: blueprint split-plugins\n\nChange-Id: Ia71193163f7d178c8a9e2904b59a1591b1e39010\n'}]",3,182284,35b011fdd81a9042fe26a19cc31e0dae57b41e7b,37,5,7,8576,,,0,"[CTX] Split context into plugins

Move openstack related contexts under rally/plugins/openstack/context/

NOTE(yfried): cleanup context is handled in next patch

Implements: blueprint split-plugins

Change-Id: Ia71193163f7d178c8a9e2904b59a1591b1e39010
",git fetch https://review.opendev.org/openstack/rally refs/changes/84/182284/5 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/plugins/openstack/scenarios/murano/test_environments.py', 'rally/plugins/openstack/context/quotas/cinder_quotas.py', 'rally/plugins/common/context/dummy.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_cluster.py', 'rally/plugins/openstack/context/flavors.py', 'tests/unit/plugins/openstack/context/__init__.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_image.py', 'rally/plugins/openstack/context/quotas/__init__.py', 'rally/plugins/openstack/context/tempest.py', 'rally/plugins/openstack/context/keypair.py', 'tests/unit/plugins/openstack/context/test_network.py', 'rally/plugins/openstack/context/images.py', 'tests/unit/plugins/common/context/__init__.py', 'tests/unit/plugins/openstack/context/quotas/__init__.py', 'tests/unit/plugins/openstack/context/vm/test_custom_image.py', 'rally/plugins/openstack/context/stacks.py', 'rally/plugins/openstack/context/volumes.py', 'tests/unit/plugins/openstack/context/test_murano_packages.py', 'rally/plugins/openstack/context/roles.py', 'rally/plugins/openstack/context/servers.py', 'tests/unit/plugins/openstack/context/quotas/test_designate_quotas.py', 'rally/plugins/openstack/context/quotas/designate_quotas.py', 'tests/unit/plugins/openstack/context/sahara/__init__.py', 'rally/plugins/openstack/context/vm/custom_image.py', 'rally/benchmark/engine.py', 'rally/plugins/openstack/context/sahara/sahara_cluster.py', 'rally/plugins/openstack/context/sahara/sahara_image.py', 'rally/plugins/openstack/context/users.py', 'tests/unit/plugins/openstack/context/test_existing_users.py', 'tests/unit/plugins/openstack/context/quotas/test_cinder_quotas.py', 'tests/unit/plugins/openstack/context/test_servers.py', 'rally/plugins/openstack/context/sahara/__init__.py', 'tests/unit/plugins/openstack/context/test_roles.py', 'tests/unit/plugins/openstack/context/test_ceilometer.py', 'tests/unit/plugins/openstack/context/test_volumes.py', 'tests/unit/plugins/openstack/context/test_keypair.py', 'rally/plugins/common/context/__init__.py', 'rally/plugins/openstack/context/ceilometer.py', 'tests/unit/plugins/openstack/context/vm/__init__.py', 'tests/unit/plugins/openstack/context/test_flavors.py', 'tests/unit/plugins/openstack/context/sahara/test_sahara_edp.py', 'rally/plugins/openstack/context/__init__.py', 'tests/unit/plugins/openstack/context/test_tempest.py', 'rally/plugins/openstack/context/network.py', 'rally/plugins/openstack/context/quotas/quotas.py', 'tests/unit/plugins/openstack/context/quotas/test_nova_quotas.py', 'tests/unit/plugins/openstack/context/quotas/test_quotas.py', 'tests/unit/plugins/openstack/context/test_users.py', 'rally/plugins/openstack/context/quotas/neutron_quotas.py', 'tests/unit/plugins/openstack/context/test_stacks.py', 'rally/common/opts.py', 'rally/benchmark/validation.py', 'tests/unit/plugins/openstack/context/test_images.py', 'rally/plugins/openstack/context/quotas/nova_quotas.py', 'tests/unit/plugins/common/context/test_dummy.py', 'tests/unit/benchmark/test_engine.py', 'tests/unit/plugins/openstack/context/quotas/test_neutron_quotas.py', 'tests/unit/plugins/openstack/context/test_secgroup.py', 'rally/plugins/openstack/context/sahara/sahara_edp.py', 'rally/plugins/openstack/context/murano_packages.py', 'rally/plugins/openstack/context/secgroup.py', 'rally/plugins/openstack/context/existing_users.py', 'rally/plugins/openstack/context/vm/__init__.py']",63,b1b19c164ae6429641fce03cc14b584d08a8602f,bp/split-plugins,,,126,102
openstack%2Fnetworking-bgpvpn~master~Ib914bcf3e06ede5218926dedde2ab83ab70b8485,openstack/networking-bgpvpn,master,Ib914bcf3e06ede5218926dedde2ab83ab70b8485,Adding initial unit tests,MERGED,2015-05-12 14:49:45.000000000,2015-05-20 06:13:06.000000000,2015-05-20 06:13:06.000000000,"[{'_account_id': 3}, {'_account_id': 2888}]","[{'number': 1, 'created': '2015-05-12 14:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/4b0dd530062372cd696110f0257a822363fe414a', 'message': 'Adding initial unit tests\n\nThis change adds an initial framework to run unit tests with tox.\nA first unit test is provided : test_bgpvpn_connection_create\n\nChange-Id: Ib914bcf3e06ede5218926dedde2ab83ab70b8485\n'}, {'number': 2, 'created': '2015-05-14 20:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/66b3922a761bdc35afdf10521986355c3fcde19f', 'message': 'Adding initial unit tests\n\nThis change adds an initial framework to run unit tests with tox.\nA first set of unit test is provided to test the extension part.\n\nChange-Id: Ib914bcf3e06ede5218926dedde2ab83ab70b8485\n'}, {'number': 3, 'created': '2015-05-18 14:03:04.000000000', 'files': ['networking_bgpvpn/tests/test_networking_bgpvpn.py', 'networking_bgpvpn/tests/unit/extensions/__init__.py', 'networking_bgpvpn/tests/unit/extensions/test_bgpvpn.py', 'requirements.txt', 'networking_bgpvpn/tests/unit/__init__.py', 'test-requirements.txt', '.testr.conf', 'networking_bgpvpn/tests/base.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/289477f9d5c4a241b0fee0c4aedae715f2ff4415', 'message': 'Adding initial unit tests\n\nThis change adds an initial framework to run unit tests with tox.\nA first set of unit tests is provided to test the extension part.\n\nChange-Id: Ib914bcf3e06ede5218926dedde2ab83ab70b8485\n'}]",0,182333,289477f9d5c4a241b0fee0c4aedae715f2ff4415,10,2,3,2888,,,0,"Adding initial unit tests

This change adds an initial framework to run unit tests with tox.
A first set of unit tests is provided to test the extension part.

Change-Id: Ib914bcf3e06ede5218926dedde2ab83ab70b8485
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/33/182333/2 && git format-patch -1 --stdout FETCH_HEAD,"['networking_bgpvpn/tests/test_networking_bgpvpn.py', 'networking_bgpvpn/tests/unit/extensions/__init__.py', 'networking_bgpvpn/tests/unit/extensions/test_bgpvpn.py', 'requirements.txt', 'networking_bgpvpn/tests/unit/__init__.py', 'test-requirements.txt', '.testr.conf', 'networking_bgpvpn/tests/base.py', 'tox.ini']",9,4b0dd530062372cd696110f0257a822363fe414a,unit_test,deps = -egit+https://git.openstack.org/openstack/neutron#egg=neutron -r{toxinidir}/requirements.txt,deps = -r{toxinidir}/requirements.txt,92,53
openstack%2Fopenstacksdk~master~I53c6307bb1c691404059d054471e6aa910aa5167,openstack/openstacksdk,master,I53c6307bb1c691404059d054471e6aa910aa5167,proxy find keystore,MERGED,2015-05-19 04:12:03.000000000,2015-05-20 06:01:49.000000000,2015-05-20 06:01:48.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-19 04:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/44c7af69cae5ccb36982cdb22c159616906dd337', 'message': 'proxy find keystore\n\nChange-Id: I53c6307bb1c691404059d054471e6aa910aa5167\n'}, {'number': 2, 'created': '2015-05-20 01:21:12.000000000', 'files': ['openstack/keystore/v1/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/5b96d07997d4dfadfe3285f890a55ea28fb15077', 'message': 'proxy find keystore\n\nChange-Id: I53c6307bb1c691404059d054471e6aa910aa5167\n'}]",0,184185,5b96d07997d4dfadfe3285f890a55ea28fb15077,8,2,2,8736,,,0,"proxy find keystore

Change-Id: I53c6307bb1c691404059d054471e6aa910aa5167
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/85/184185/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/keystore/v1/_proxy.py'],1,44c7af69cae5ccb36982cdb22c159616906dd337,proxyfindkeystore," """"""Find a single container :param name_or_id: The name or ID of a container. :returns: One :class:`~openstack.compute.v2.container.Container` or None """""" """"""Find a single order :param name_or_id: The name or ID of a order. :returns: One :class:`~openstack.compute.v2.order.Order` or None """""" """"""Find a single secret :param name_or_id: The name or ID of a secret. :returns: One :class:`~openstack.compute.v2.secret.Secret` or None """"""",,16,0
openstack%2Fopenstacksdk~master~I96e78e19e3440ef800c528899a596a35761bd8f8,openstack/openstacksdk,master,I96e78e19e3440ef800c528899a596a35761bd8f8,AFT compute extension,MERGED,2015-05-19 00:40:30.000000000,2015-05-20 06:01:43.000000000,2015-05-20 06:01:42.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-19 00:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9a8b25ca54cec48f9aac7c24627c73ba5ac4fb44', 'message': 'AFT compute extension\n\nChange-Id: I96e78e19e3440ef800c528899a596a35761bd8f8\n'}, {'number': 2, 'created': '2015-05-20 01:20:56.000000000', 'files': ['openstack/tests/functional/compute/v2/test_extension.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8a62716297676744fc985591e4f89e26e8669c6e', 'message': 'AFT compute extension\n\nChange-Id: I96e78e19e3440ef800c528899a596a35761bd8f8\n'}]",0,184164,8a62716297676744fc985591e4f89e26e8669c6e,10,2,2,8736,,,0,"AFT compute extension

Change-Id: I96e78e19e3440ef800c528899a596a35761bd8f8
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/64/184164/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/compute/v2/test_extension.py'],1,9a8b25ca54cec48f9aac7c24627c73ba5ac4fb44,aftcomputeextension,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import six from openstack.tests.functional import base class TestExtension(base.BaseFunctionalTest): def test_list(self): extensions = list(self.conn.compute.extensions()) self.assertGreater(len(extensions), 0) for ext in extensions: self.assertIsInstance(ext.name, six.string_types) self.assertIsInstance(ext.namespace, six.string_types) self.assertIsInstance(ext.alias, six.string_types) ",,27,0
openstack%2Fopenstacksdk~master~I6c84903584dfe2c875b77f560eda289aac3248f2,openstack/openstacksdk,master,I6c84903584dfe2c875b77f560eda289aac3248f2,proxy image find,MERGED,2015-05-19 04:11:37.000000000,2015-05-20 06:01:36.000000000,2015-05-20 06:01:35.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-19 04:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/028e1514888e262d8c37f250703322c431bffaaf', 'message': 'proxy image find\n\nChange-Id: I6c84903584dfe2c875b77f560eda289aac3248f2\n'}, {'number': 2, 'created': '2015-05-20 01:21:09.000000000', 'files': ['openstack/image/v1/_proxy.py', 'openstack/image/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8f12463179e8544e8458c52be598f1e5282d4293', 'message': 'proxy image find\n\nChange-Id: I6c84903584dfe2c875b77f560eda289aac3248f2\n'}]",0,184184,8f12463179e8544e8458c52be598f1e5282d4293,8,2,2,8736,,,0,"proxy image find

Change-Id: I6c84903584dfe2c875b77f560eda289aac3248f2
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/84/184184/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/image/v1/_proxy.py', 'openstack/image/v2/_proxy.py']",2,028e1514888e262d8c37f250703322c431bffaaf,proxyfindimage," """"""Find a single image :param name_or_id: The name or ID of a image. :returns: One :class:`~openstack.compute.v2.image.Image` or None """""" """"""Find a single member :param name_or_id: The name or ID of a member. :returns: One :class:`~openstack.compute.v2.member.Member` or None """"""",,15,0
openstack%2Fopenstacksdk~master~I394f5932872a43c16a2ff1b196413ec42d90aa15,openstack/openstacksdk,master,I394f5932872a43c16a2ff1b196413ec42d90aa15,proxy find database,MERGED,2015-05-19 04:11:10.000000000,2015-05-20 06:01:03.000000000,2015-05-20 06:01:01.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-19 04:11:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/239288916a82c4ccf34052ca59ea8924903541b1', 'message': 'proxy find database\n\nChange-Id: I394f5932872a43c16a2ff1b196413ec42d90aa15\n'}, {'number': 2, 'created': '2015-05-20 01:21:01.000000000', 'files': ['openstack/database/v1/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d53c34ccbb8ed04d8dacb171fea99139a5a8686f', 'message': 'proxy find database\n\nChange-Id: I394f5932872a43c16a2ff1b196413ec42d90aa15\n'}]",0,184182,d53c34ccbb8ed04d8dacb171fea99139a5a8686f,8,2,2,8736,,,0,"proxy find database

Change-Id: I394f5932872a43c16a2ff1b196413ec42d90aa15
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/82/184182/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/database/v1/_proxy.py'],1,239288916a82c4ccf34052ca59ea8924903541b1,proxyfinddatabase," """"""Find a single database :param name_or_id: The name or ID of a database. :returns: One :class:`~openstack.compute.v2.database.Database` or None """""" """"""Find a single flavor :param name_or_id: The name or ID of a flavor. :returns: One :class:`~openstack.compute.v2.flavor.Flavor` or None """""" """"""Find a single instance :param name_or_id: The name or ID of a instance. :returns: One :class:`~openstack.compute.v2.instance.Instance` or None """""" """"""Find a single user :param name_or_id: The name or ID of a user. :returns: One :class:`~openstack.compute.v2.user.User` or None """"""",,20,0
openstack%2Fmagnum~master~I56ecd8003594fd436874681670bb9ead19b95dea,openstack/magnum,master,I56ecd8003594fd436874681670bb9ead19b95dea,Make functional test work with new tox env,MERGED,2015-05-18 06:16:19.000000000,2015-05-20 05:56:19.000000000,2015-05-20 05:56:19.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7049}, {'_account_id': 7494}]","[{'number': 1, 'created': '2015-05-18 06:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8bbcde89cb3503fd3a27c1e301b90f46196d2ec6', 'message': '[WIP] Make functional test work with new tox env\n\nChange-Id: I56ecd8003594fd436874681670bb9ead19b95dea\n'}, {'number': 2, 'created': '2015-05-18 06:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/443f68cbaaba475461895ebb9720ac4335add88c', 'message': '[WIP] Make functional test work with new tox env\n\nChange-Id: I56ecd8003594fd436874681670bb9ead19b95dea\n'}, {'number': 3, 'created': '2015-05-18 07:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/9818ecf9687be32065b6f9d25403b21c4ea7b7eb', 'message': '[WIP] Make functional test work with new tox env\n\nChange-Id: I56ecd8003594fd436874681670bb9ead19b95dea\n'}, {'number': 4, 'created': '2015-05-18 08:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6ff83abe5308af03fe14916fc6890de4df308b0a', 'message': '[WIP] Make functional test work with new tox env\n\nChange-Id: I56ecd8003594fd436874681670bb9ead19b95dea\n'}, {'number': 5, 'created': '2015-05-18 08:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/890cafe98406711342fc6d580d5fa0617c4eaa5b', 'message': 'Make functional test work with new tox env\n\nThe check-functional-dsvm-magnum gate job was failing due to the\nfunctional tests not picking up valid OpenStack credentials.\n\nUpdate how we aquire credentials -- fixes side effect of how tox 2.0\nhandles environment variables\n\nCloses-Bug: #1455102\nChange-Id: I56ecd8003594fd436874681670bb9ead19b95dea\n'}, {'number': 6, 'created': '2015-05-19 01:45:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/2aa603709955488e670629ae6548215af6ad557d', 'message': 'Make functional test work with new tox env\n\nThe check-functional-dsvm-magnum gate job was failing due to the\nfunctional tests not picking up valid OpenStack credentials.\n\nUpdate how we aquire credentials -- fixes side effect of how tox 2.0\nhandles environment variables\n\nCloses-Bug: #1455102\nChange-Id: I56ecd8003594fd436874681670bb9ead19b95dea\n'}, {'number': 7, 'created': '2015-05-19 02:16:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c3ecaacef70ab50d575080c7c8a470743c30298a', 'message': 'Make functional test work with new tox env\n\nThe check-functional-dsvm-magnum gate job was failing due to the\nfunctional tests not picking up valid OpenStack credentials.\n\nUpdate how we aquire credentials -- fixes side effect of how tox 2.0\nhandles environment variables\n\nCloses-Bug: #1455102\nChange-Id: I56ecd8003594fd436874681670bb9ead19b95dea\n'}, {'number': 8, 'created': '2015-05-19 03:07:51.000000000', 'files': ['magnum/tests/contrib/post_test_hook.sh', 'functional_creds.conf.sample', 'magnum/tests/functional/test_magnum_python_client.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/986aac0b3e670b127422334fa2f640792e8093ea', 'message': 'Make functional test work with new tox env\n\nThe check-functional-dsvm-magnum gate job was failing due to the\nfunctional tests not picking up valid OpenStack credentials.\n\nUpdate how we aquire credentials -- fixes side effect of how tox 2.0\nhandles environment variables\n\nCloses-Bug: #1455102\nChange-Id: I56ecd8003594fd436874681670bb9ead19b95dea\n'}]",0,183983,986aac0b3e670b127422334fa2f640792e8093ea,27,4,8,7049,,,0,"Make functional test work with new tox env

The check-functional-dsvm-magnum gate job was failing due to the
functional tests not picking up valid OpenStack credentials.

Update how we aquire credentials -- fixes side effect of how tox 2.0
handles environment variables

Closes-Bug: #1455102
Change-Id: I56ecd8003594fd436874681670bb9ead19b95dea
",git fetch https://review.opendev.org/openstack/magnum refs/changes/83/183983/8 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/contrib/post_test_hook.sh', 'functional_creds.conf.sample', 'magnum/tests/functional/test_magnum_python_client.py']",3,8bbcde89cb3503fd3a27c1e301b90f46196d2ec6,fixfvt,"import ConfigParser user = cliutils.env('OS_USERNAME') passwd = cliutils.env('OS_PASSWORD') tenant = cliutils.env('OS_TENANT_NAME') tenant_id = cliutils.env('OS_TENANT_ID') auth_url = cliutils.env('OS_AUTH_URL') region_name = cliutils.env('OS_REGION_NAME') magnum_url = cliutils.env('BYPASS_URL') config = ConfigParser.RawConfigParser() if config.read('functional_creds.conf'): user = user or config.get('admin', 'user') passwd = passwd or config.get('admin', 'pass') tenant = tenant or config.get('admin', 'tenant') auth_url = auth_url or config.get('auth', 'uri') magnum_url = magnum_url or config.get('auth', 'magnum_url') self.cs = client.Client(username=user, api_key=passwd, project_id=tenant_id, project_name=tenant, auth_url=auth_url, region_name=region_name, magnum_url=magnum_url)"," self.cs = client.Client(username=cliutils.env('OS_USERNAME'), api_key=cliutils.env('OS_PASSWORD'), project_id=cliutils.env('OS_TENANT_ID'), project_name=cliutils.env('OS_TENANT_NAME'), auth_url=cliutils.env('OS_AUTH_URL'), region_name=cliutils.env('OS_REGION_NAME'), magnum_url=cliutils.env('BYPASS_URL'))",44,7
openstack%2Fopenstacksdk~master~I608de2cc9c1ec1bfe68f6a5ce185bf36348e04a8,openstack/openstacksdk,master,I608de2cc9c1ec1bfe68f6a5ce185bf36348e04a8,proxy find identity,MERGED,2015-05-19 04:11:28.000000000,2015-05-20 05:56:01.000000000,2015-05-20 05:56:01.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-19 04:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b553a390fc2a44a70525a487a811fbc8e20b9546', 'message': 'proxy find identity\n\nChange-Id: I608de2cc9c1ec1bfe68f6a5ce185bf36348e04a8\n'}, {'number': 2, 'created': '2015-05-20 01:21:05.000000000', 'files': ['openstack/identity/v3/_proxy.py', 'openstack/identity/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e9c9a6fbec839834364b6b1c9b83a99452a0c14d', 'message': 'proxy find identity\n\nChange-Id: I608de2cc9c1ec1bfe68f6a5ce185bf36348e04a8\n'}]",0,184183,e9c9a6fbec839834364b6b1c9b83a99452a0c14d,8,2,2,8736,,,0,"proxy find identity

Change-Id: I608de2cc9c1ec1bfe68f6a5ce185bf36348e04a8
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/83/184183/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/identity/v3/_proxy.py', 'openstack/identity/v2/_proxy.py']",2,b553a390fc2a44a70525a487a811fbc8e20b9546,proxyfindidentity," """"""Find a single role :param name_or_id: The name or ID of a role. :returns: One :class:`~openstack.compute.v2.role.Role` or None """""" """"""Find a single tenant :param name_or_id: The name or ID of a tenant. :returns: One :class:`~openstack.compute.v2.tenant.Tenant` or None """""" """"""Find a single user :param name_or_id: The name or ID of a user. :returns: One :class:`~openstack.compute.v2.user.User` or None """"""",,61,0
openstack%2Fopenstacksdk~master~I6c897b5c50329e2f14c731fe76d0bef7611a7b05,openstack/openstacksdk,master,I6c897b5c50329e2f14c731fe76d0bef7611a7b05,AFT network,MERGED,2015-05-18 18:52:55.000000000,2015-05-20 05:55:55.000000000,2015-05-20 05:55:54.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-18 18:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/72b14ea9acc710861aca03a6a1a56fe569fe6464', 'message': 'AFT network\n\nChange-Id: I6c897b5c50329e2f14c731fe76d0bef7611a7b05\n'}, {'number': 2, 'created': '2015-05-18 19:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f6da059c2dffd452f6cc500c2b37fc492f6e1517', 'message': 'AFT network\n\nChange-Id: I6c897b5c50329e2f14c731fe76d0bef7611a7b05\n'}, {'number': 3, 'created': '2015-05-20 01:20:37.000000000', 'files': ['openstack/tests/functional/network/v2/test_extension.py', 'openstack/tests/functional/network/v2/__init__.py', 'openstack/tests/functional/network/__init__.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c222abc1a090220fb4dbe47a3f6f44df7e128c74', 'message': 'AFT network\n\nChange-Id: I6c897b5c50329e2f14c731fe76d0bef7611a7b05\n'}]",0,184109,c222abc1a090220fb4dbe47a3f6f44df7e128c74,12,3,3,8736,,,0,"AFT network

Change-Id: I6c897b5c50329e2f14c731fe76d0bef7611a7b05
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/09/184109/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/functional/network/v2/test_extension.py', 'openstack/tests/functional/network/v2/__init__.py', 'openstack/tests/functional/network/__init__.py']",3,72b14ea9acc710861aca03a6a1a56fe569fe6464,aftnetwork,,,31,0
openstack%2Fopenstacksdk~master~I4f6fb7840b684e024ceca37bc5b7e2c858574665,openstack/openstacksdk,master,I4f6fb7840b684e024ceca37bc5b7e2c858574665,Enable occ cloud region for example,MERGED,2015-05-17 14:46:40.000000000,2015-05-20 05:55:43.000000000,2015-05-20 05:55:42.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-17 14:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/de98407579c1ad608e9433bb87b4a9603a8d668f', 'message': 'Enable occ cloud region for example\n\nChange-Id: I4f6fb7840b684e024ceca37bc5b7e2c858574665\n'}, {'number': 2, 'created': '2015-05-20 01:20:33.000000000', 'files': ['examples/connection.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0fa0d792bfc8ea22cd807b3b822edeb67a97943a', 'message': 'Enable occ cloud region for example\n\nChange-Id: I4f6fb7840b684e024ceca37bc5b7e2c858574665\n'}]",0,183920,0fa0d792bfc8ea22cd807b3b822edeb67a97943a,8,2,2,8736,,,0,"Enable occ cloud region for example

Change-Id: I4f6fb7840b684e024ceca37bc5b7e2c858574665
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/20/183920/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/connection.py'],1,de98407579c1ad608e9433bb87b4a9603a8d668f,images," opts.user_preferences.set_region(opts.user_preferences.ALL, cloud.region)",,1,0
openstack%2Fopenstacksdk~master~I2e56e26fe4dfbc886cf346d72aac6419ecdd5ebb,openstack/openstacksdk,master,I2e56e26fe4dfbc886cf346d72aac6419ecdd5ebb,proxy find orchestration,MERGED,2015-05-19 04:12:28.000000000,2015-05-20 05:53:23.000000000,2015-05-20 05:53:23.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-19 04:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/efe272e8aef0dba245bd049f198436bc8c6df48a', 'message': 'proxy find orchestration\n\nChange-Id: I2e56e26fe4dfbc886cf346d72aac6419ecdd5ebb\n'}, {'number': 2, 'created': '2015-05-20 01:21:19.000000000', 'files': ['openstack/orchestration/v1/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d9bbea26d26caff8802c79b17803ab4b271eef16', 'message': 'proxy find orchestration\n\nChange-Id: I2e56e26fe4dfbc886cf346d72aac6419ecdd5ebb\n'}]",0,184187,d9bbea26d26caff8802c79b17803ab4b271eef16,8,2,2,8736,,,0,"proxy find orchestration

Change-Id: I2e56e26fe4dfbc886cf346d72aac6419ecdd5ebb
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/87/184187/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/orchestration/v1/_proxy.py'],1,efe272e8aef0dba245bd049f198436bc8c6df48a,proxyfindorchestration," """"""Find a single stack :param name_or_id: The name or ID of a stack. :returns: One :class:`~openstack.compute.v2.stack.Stack` or None """"""",,5,0
openstack%2Fopenstacksdk~master~I0d790847b2f47f00e7aba0fb1303603e653e0c7b,openstack/openstacksdk,master,I0d790847b2f47f00e7aba0fb1303603e653e0c7b,Add proxy docs and empty user guides,MERGED,2015-05-12 20:19:28.000000000,2015-05-20 05:51:45.000000000,2015-05-20 05:51:44.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-12 20:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e577f4d959c2916ad3f249f7a4a8d5aa774ab7e3', 'message': ""Add proxy docs and empty user guides\n\nIn order to review the proxy docs, I wanted to have the\nproxy docs added.  I created some place holder user guides\nso we'd have the framework for everything.\n\nChange-Id: I0d790847b2f47f00e7aba0fb1303603e653e0c7b\n""}, {'number': 2, 'created': '2015-05-20 01:22:11.000000000', 'files': ['doc/source/users/userguides/keystore.rst', 'doc/source/users/userguides/cdn.rst', 'doc/source/users/index.rst', 'doc/source/users/userguides/metric.rst', 'doc/source/users/proxies/database.rst', 'doc/source/users/proxies/keystore.rst', 'doc/source/users/userguides/object_store.rst', 'doc/source/users/userguides/database.rst', 'doc/source/users/proxies/metric.rst', 'doc/source/users/proxies/volume.rst', 'doc/source/users/userguides/telemetry.rst', 'doc/source/users/userguides/network.rst', 'doc/source/users/userguides/volume.rst', 'doc/source/users/proxies/compute.rst', 'doc/source/users/userguides/image.rst', 'doc/source/users/userguides/orchestration.rst', 'doc/source/users/proxies/telemetry.rst', 'doc/source/users/proxies/cdn.rst', 'doc/source/users/proxies/orchestration.rst', 'doc/source/users/proxies/network.rst', 'doc/source/users/userguides/identity.rst', 'doc/source/users/userguides/compute.rst', 'doc/source/users/proxies/identity.rst', 'doc/source/users/proxies/image.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3a5f76519f5938b7d01031cfb22bbaf0c34ca986', 'message': ""Add proxy docs and empty user guides\n\nIn order to review the proxy docs, I wanted to have the\nproxy docs added.  I created some place holder user guides\nso we'd have the framework for everything.\n\nChange-Id: I0d790847b2f47f00e7aba0fb1303603e653e0c7b\n""}]",0,182441,3a5f76519f5938b7d01031cfb22bbaf0c34ca986,8,2,2,8736,,,0,"Add proxy docs and empty user guides

In order to review the proxy docs, I wanted to have the
proxy docs added.  I created some place holder user guides
so we'd have the framework for everything.

Change-Id: I0d790847b2f47f00e7aba0fb1303603e653e0c7b
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/41/182441/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/users/userguides/keystore.rst', 'doc/source/users/userguides/cdn.rst', 'doc/source/users/index.rst', 'doc/source/users/userguides/metric.rst', 'doc/source/users/proxies/database.rst', 'doc/source/users/proxies/keystore.rst', 'doc/source/users/userguides/object_store.rst', 'doc/source/users/userguides/database.rst', 'doc/source/users/proxies/metric.rst', 'doc/source/users/proxies/volume.rst', 'doc/source/users/userguides/telemetry.rst', 'doc/source/users/userguides/network.rst', 'doc/source/users/userguides/volume.rst', 'doc/source/users/proxies/compute.rst', 'doc/source/users/userguides/image.rst', 'doc/source/users/userguides/orchestration.rst', 'doc/source/users/proxies/telemetry.rst', 'doc/source/users/proxies/cdn.rst', 'doc/source/users/proxies/orchestration.rst', 'doc/source/users/proxies/network.rst', 'doc/source/users/userguides/identity.rst', 'doc/source/users/userguides/compute.rst', 'doc/source/users/proxies/identity.rst', 'doc/source/users/proxies/image.rst']",24,e577f4d959c2916ad3f249f7a4a8d5aa774ab7e3,proxydocs,"Image API v1 ============ For details on how to use image, see :doc:`/users/userguides/image` .. automodule:: openstack.image.v1._proxy The Image v1 Class ------------------ The image high-level interface is available through the ``image`` member of a :class:`~openstack.connection.Connection` object. The ``image`` member will only be added if the service is detected. .. autoclass:: openstack.image.v1._proxy.Proxy :members: Image API v2 ============ For details on how to use image, see :doc:`/users/userguides/image` .. automodule:: openstack.image.v2._proxy The Image v2 Class ------------------ The image high-level interface is available through the ``image`` member of a :class:`~openstack.connection.Connection` object. The ``image`` member will only be added if the service is detected. .. autoclass:: openstack.image.v2._proxy.Proxy :members: ",,336,4
openstack%2Fopenstacksdk~master~I8c5632fc0a569ede31a0d08829b3ab3ef74194c2,openstack/openstacksdk,master,I8c5632fc0a569ede31a0d08829b3ab3ef74194c2,proxy find telemetry,MERGED,2015-05-19 04:12:47.000000000,2015-05-20 05:37:18.000000000,2015-05-20 05:37:17.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-19 04:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/da11b3409b71eaa493e4ee278c8fe72cf19e21cc', 'message': 'proxy find telemetry\n\nChange-Id: I8c5632fc0a569ede31a0d08829b3ab3ef74194c2\n'}, {'number': 2, 'created': '2015-05-20 01:21:25.000000000', 'files': ['openstack/telemetry/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a5534c96198dffedd2503e884904c389626cee5e', 'message': 'proxy find telemetry\n\nChange-Id: I8c5632fc0a569ede31a0d08829b3ab3ef74194c2\n'}]",0,184188,a5534c96198dffedd2503e884904c389626cee5e,14,3,2,8736,,,0,"proxy find telemetry

Change-Id: I8c5632fc0a569ede31a0d08829b3ab3ef74194c2
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/88/184188/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/telemetry/v2/_proxy.py'],1,da11b3409b71eaa493e4ee278c8fe72cf19e21cc,proxyfindtelemetry," """"""Find a single alarm :param name_or_id: The name or ID of a alarm. :returns: One :class:`~openstack.compute.v2.alarm.Alarm` or None """""" """"""Find a single alarm change :param name_or_id: The name or ID of a alarm change. :returns: One :class:`~openstack.compute.v2.alarm_change.AlarmChange` or None """""" """"""Find a single capability :param name_or_id: The name or ID of a capability. :returns: One :class:`~openstack.compute.v2.capability.Capability` or None """""" """"""Find a single meter :param name_or_id: The name or ID of a meter. :returns: One :class:`~openstack.compute.v2.meter.Meter` or None """""" """"""Find a single resource :param name_or_id: The name or ID of a resource. :returns: One :class:`~openstack.compute.v2.resource.Resource` or None """""" """"""Find a single sample :param name_or_id: The name or ID of a sample. :returns: One :class:`~openstack.compute.v2.sample.Sample` or None """""" """"""Find a single statistics :param name_or_id: The name or ID of a statistics. :returns: One :class:`~openstack.compute.v2.statistics.Statistics` or None """"""",,38,0
openstack%2Fopenstacksdk~master~I06caf3ec67d1fbc12a254a0c005f195364621361,openstack/openstacksdk,master,I06caf3ec67d1fbc12a254a0c005f195364621361,proxy find network,MERGED,2015-05-19 04:12:19.000000000,2015-05-20 05:32:19.000000000,2015-05-20 05:32:17.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2015-05-19 04:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/50af62d81fff75ad552505c53c3a5d827c067434', 'message': 'proxy find network\n\nChange-Id: I06caf3ec67d1fbc12a254a0c005f195364621361\n'}, {'number': 2, 'created': '2015-05-20 01:21:15.000000000', 'files': ['openstack/network/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a80b929c5f1a552f3dcf4f92b6a1224502f91953', 'message': 'proxy find network\n\nChange-Id: I06caf3ec67d1fbc12a254a0c005f195364621361\n'}]",0,184186,a80b929c5f1a552f3dcf4f92b6a1224502f91953,8,2,2,8736,,,0,"proxy find network

Change-Id: I06caf3ec67d1fbc12a254a0c005f195364621361
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/86/184186/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/network/v2/_proxy.py'],1,50af62d81fff75ad552505c53c3a5d827c067434,proxyfindnetwork," """"""Find a single extension :param name_or_id: The name or ID of a extension. :returns: One :class:`~openstack.compute.v2.extension.Extension` or None """""" """"""Find an available IP :returns: One :class:`~openstack.compute.v2.floating_ip.FloatingIP` or None """""" """"""Find a single IP :param name_or_id: The name or ID of an IP. :returns: One :class:`~openstack.compute.v2.floating_ip.FloatingIP` or None """""" """"""Find a single health monitor :param name_or_id: The name or ID of a health monitor. :returns: One :class:`~openstack.compute.v2.health_monitor. HealthMonitor` or None """""" """"""Find a single listener :param name_or_id: The name or ID of a listener. :returns: One :class:`~openstack.compute.v2.listener.Listener` or None """""" """"""Find a single load balancer :param name_or_id: The name or ID of a load balancer. :returns: One :class:`~openstack.compute.v2.load_balancer.LoadBalancer` or None """""" """"""Find a single metering label :param name_or_id: The name or ID of a metering label. :returns: One :class:`~openstack.compute.v2.metering_label. MeteringLabel` or None """""" """"""Find a single metering label rule :param name_or_id: The name or ID of a metering label rule. :returns: One :class:`~openstack.compute.v2.metering_label_rule. MeteringLabelRule` or None """""" """"""Find a single network :param name_or_id: The name or ID of a network. :returns: One :class:`~openstack.compute.v2.network.Network` or None """""" """"""Find a single pool :param name_or_id: The name or ID of a pool. :returns: One :class:`~openstack.compute.v2.pool.Pool` or None """""" """"""Find a single pool member :param name_or_id: The name or ID of a pool member. :returns: One :class:`~openstack.compute.v2.pool_member.PoolMember` or None """""" """"""Find a single port :param name_or_id: The name or ID of a port. :returns: One :class:`~openstack.compute.v2.port.Port` or None """""" """"""Find a single router :param name_or_id: The name or ID of a router. :returns: One :class:`~openstack.compute.v2.router.Router` or None """""" """"""Find a single security group :param name_or_id: The name or ID of a security group. :returns: One :class:`~openstack.compute.v2.security_group. SecurityGroup` or None """""" """"""Find a single security group rule :param name_or_id: The name or ID of a security group rule. :returns: One :class:`~openstack.compute.v2.security_group_rule. SecurityGroupRule` or None """""" """"""Find a single subnet :param name_or_id: The name or ID of a subnet. :returns: One :class:`~openstack.compute.v2.subnet.Subnet` or None """"""",,89,0
openstack%2Ftacker~master~I476c8581dca05cf6c127b277bd56fbd774507870,openstack/tacker,master,I476c8581dca05cf6c127b277bd56fbd774507870,copy description when respawn,MERGED,2015-05-20 05:24:43.000000000,2015-05-20 05:26:56.000000000,2015-05-20 05:26:55.000000000,"[{'_account_id': 3}, {'_account_id': 333}]","[{'number': 1, 'created': '2015-05-20 05:24:43.000000000', 'files': ['tacker/db/vm/vm_db.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/40746a71744d6733ee5669c79a2afe6d943f9fbc', 'message': 'copy description when respawn\n\nChange-Id: I476c8581dca05cf6c127b277bd56fbd774507870\n'}]",0,184411,40746a71744d6733ee5669c79a2afe6d943f9fbc,6,2,1,333,,,0,"copy description when respawn

Change-Id: I476c8581dca05cf6c127b277bd56fbd774507870
",git fetch https://review.opendev.org/openstack/tacker refs/changes/11/184411/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/db/vm/vm_db.py'],1,40746a71744d6733ee5669c79a2afe6d943f9fbc,refresh," description=device_db.description,",,1,0
openstack%2Fkeystoneauth~master~I7a3cb78bcfe448c22a9d21f134f354e71702bba3,openstack/keystoneauth,master,I7a3cb78bcfe448c22a9d21f134f354e71702bba3,Fix how arguments are passed to the request function,ABANDONED,2015-05-19 22:24:31.000000000,2015-05-20 05:22:48.000000000,,"[{'_account_id': 3}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-19 22:24:31.000000000', 'files': ['keystoneauth/session.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/3eb074ba20e8ade6ce04cac38574eaeca79c50b3', 'message': 'Fix how arguments are passed to the request function\n\nIn its existing state, keystoneauth.session.request was not correctly\nusing keyword arguments.\n\n    python -c \'import requests; \\\n               requests.Session().request(""https://httpbin.org/get"", \\\n                    method=""GET"")\'\n    Traceback (most recent call last):\n      File ""<string>"", line 1, in <module>\n    TypeError: request() got multiple values for keyword argument \'method\'\n\nChange-Id: I7a3cb78bcfe448c22a9d21f134f354e71702bba3\n'}]",0,184346,3eb074ba20e8ade6ce04cac38574eaeca79c50b3,4,2,1,12000,,,0,"Fix how arguments are passed to the request function

In its existing state, keystoneauth.session.request was not correctly
using keyword arguments.

    python -c 'import requests; \
               requests.Session().request(""https://httpbin.org/get"", \
                    method=""GET"")'
    Traceback (most recent call last):
      File ""<string>"", line 1, in <module>
    TypeError: request() got multiple values for keyword argument 'method'

Change-Id: I7a3cb78bcfe448c22a9d21f134f354e71702bba3
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/46/184346/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneauth/session.py'],1,3eb074ba20e8ade6ce04cac38574eaeca79c50b3,fix-session-request," return Session().request(url=url, method=method, **kwargs)"," return Session().request(url, method=method, **kwargs)",1,1
openstack%2Fopenstacksdk~master~Ie12e31bc02ba9793f3e17004ee9046cf1050c40d,openstack/openstacksdk,master,Ie12e31bc02ba9793f3e17004ee9046cf1050c40d,Set OS_CLOUD for functional tests,MERGED,2015-05-19 17:24:15.000000000,2015-05-20 05:08:33.000000000,2015-05-20 05:08:32.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-19 17:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3280c9052129604c04a342e25d9f9c2264ed9520', 'message': 'Set OS_CLOUD for functional tests\n\nChange-Id: Ie12e31bc02ba9793f3e17004ee9046cf1050c40d\n'}, {'number': 2, 'created': '2015-05-19 18:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4e4f9aabc73d1506edab31967ce6bf53acd03696', 'message': 'Set OS_CLOUD for functional tests\n\nChange-Id: Ie12e31bc02ba9793f3e17004ee9046cf1050c40d\n'}, {'number': 3, 'created': '2015-05-20 01:21:30.000000000', 'files': ['post_test_hook.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/575155b738c8c3a468506072c2615af0cc05bf0c', 'message': 'Set OS_CLOUD for functional tests\n\nChange-Id: Ie12e31bc02ba9793f3e17004ee9046cf1050c40d\n'}]",0,184299,575155b738c8c3a468506072c2615af0cc05bf0c,20,3,3,8736,,,0,"Set OS_CLOUD for functional tests

Change-Id: Ie12e31bc02ba9793f3e17004ee9046cf1050c40d
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/99/184299/1 && git format-patch -1 --stdout FETCH_HEAD,['post_test_hook.sh'],1,3280c9052129604c04a342e25d9f9c2264ed9520,aft,export OS_CLOUD=envvars,,1,0
openstack%2Fnova~master~I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f,openstack/nova,master,I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f,Skip only one host weight calculation,MERGED,2014-11-26 05:47:34.000000000,2015-05-20 03:09:05.000000000,2015-05-06 15:36:14.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 8688}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}, {'_account_id': 11103}, {'_account_id': 11303}, {'_account_id': 11530}, {'_account_id': 12175}, {'_account_id': 12909}, {'_account_id': 14271}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15888}]","[{'number': 1, 'created': '2014-11-26 05:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3061caca4cdb5423da8672c953e12153931040f0', 'message': 'Skip only one host weight calculation\n\nIf there is only one host available, calculate the weight\nmake no sense because whatever the weight it is, nova will\nuse the host.\n\nChange-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f\n'}, {'number': 2, 'created': '2014-11-26 06:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d0a2a61b66e1c0972df18fb5be06e643fc7d909', 'message': 'Skip only one host weight calculation\n\nIf there is only one host available, calculate the weight\nmake no sense because whatever the weight it is, nova will\nuse the host.\n\nChange-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f\n'}, {'number': 3, 'created': '2014-12-12 05:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/493351c1f78788da939a9781d762dfcc5169b21a', 'message': 'Skip only one host weight calculation\n\nIf there is only one host available, calculate the weight\nmake no sense because whatever the weight it is, nova will\nuse the host.\n\nChange-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f\n'}, {'number': 4, 'created': '2014-12-12 16:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/756d4374b16ab208fe33e2406e23494f45117e4e', 'message': 'Skip only one host weight calculation\n\nIf there is only one host available, calculate the weight\nmake no sense because whatever the weight it is, nova will\nuse the host.\n\nChange-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f\n'}, {'number': 5, 'created': '2015-02-06 11:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/644b0efe4282d3f107063f4712aede096e0bfdc1', 'message': 'Skip only one host weight calculation\n\nIf there is only one host available, calculate the weight\nmake no sense because whatever the weight it is, nova will\nuse the host.\n\nChange-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f\n'}, {'number': 6, 'created': '2015-02-12 21:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a888cfe1255d2d65e1486aaa4e7a868a7731d89', 'message': 'Skip only one host weight calculation\n\nIf there is only one host available, calculate the weight\nmake no sense because whatever the weight it is, nova will\nuse the host.\n\nChange-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f\n'}, {'number': 7, 'created': '2015-02-26 13:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d96bf34d96472ebe34f13c8bc782f00d9f336ab7', 'message': 'Skip only one host weight calculation\n\nIf there is only one host available, calculate the weight\nmake no sense because whatever the weight it is, nova will\nuse the host.\n\nChange-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f\n'}, {'number': 8, 'created': '2015-03-26 16:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/006644ef75d308e14f5fee0e30a9c72ef30eb68a', 'message': 'Skip only one host weight calculation\n\nIf there is only one host available, calculate the weight\nmake no sense because whatever the weight it is, nova will\nuse the host.\n\nChange-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f\n'}, {'number': 9, 'created': '2015-04-24 09:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3251ca82c356e99c923fdf7aaa135fea6cec4e4e', 'message': 'Skip only one host weight calculation\n\nIf there is only one host available, calculate the weight\nmake no sense because whatever the weight it is, nova will\nuse the host.\n\nCloses-Bug: 1448015\n\nChange-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f\n'}, {'number': 10, 'created': '2015-05-05 15:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef425126a46d6a6cdb67d9cf990bcdbd4ae4523f', 'message': 'Skip only one host weight calculation\n\nIf there is only one host available, calculate the weight\nmake no sense because whatever the weight it is, nova will\nuse the host.\n\nCloses-Bug: 1448015\n\nChange-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f\n'}, {'number': 11, 'created': '2015-05-05 15:58:41.000000000', 'files': ['nova/tests/unit/test_weights.py', 'nova/weights.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/139835900f630a698127e1637b1c887f17389a03', 'message': 'Skip only one host weight calculation\n\nIf there is only one host available, calculate the weight\nmake no sense because whatever the weight it is, nova will\nuse the host.\n\nCloses-Bug: 1448015\n\nChange-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f\n'}]",10,137275,139835900f630a698127e1637b1c887f17389a03,139,30,11,6062,,,0,"Skip only one host weight calculation

If there is only one host available, calculate the weight
make no sense because whatever the weight it is, nova will
use the host.

Closes-Bug: 1448015

Change-Id: I38aed6a6e45d24dc0daf2e96c353f394f3ef5e3f
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/137275/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/weights.py'],1,3061caca4cdb5423da8672c953e12153931040f0,bug/1448015," if len(weighed_objs) == 1: return weighed_objs else: for weigher_cls in weigher_classes: weigher = weigher_cls() weights = weigher.weigh_objects(weighed_objs, weighing_properties) # Normalize the weights weights = normalize(weights, minval=weigher.minval, maxval=weigher.maxval) for i, weight in enumerate(weights): obj = weighed_objs[i] obj.weight += weigher.weight_multiplier() * weight return sorted(weighed_objs, key=lambda x: x.weight, reverse=True)"," for weigher_cls in weigher_classes: weigher = weigher_cls() weights = weigher.weigh_objects(weighed_objs, weighing_properties) # Normalize the weights weights = normalize(weights, minval=weigher.minval, maxval=weigher.maxval) for i, weight in enumerate(weights): obj = weighed_objs[i] obj.weight += weigher.weight_multiplier() * weight return sorted(weighed_objs, key=lambda x: x.weight, reverse=True)",15,11
openstack%2Ftempest~master~I3a16a24863162c8691c9125700ffa58eaebc1a57,openstack/tempest,master,I3a16a24863162c8691c9125700ffa58eaebc1a57,Drop v2 and v3 tokens clients,MERGED,2015-05-05 15:58:40.000000000,2015-05-20 02:56:21.000000000,2015-05-06 18:23:26.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-05-05 15:58:40.000000000', 'files': ['tempest/services/identity/v3/json/token_client.py', 'tempest/services/identity/v2/json/token_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/3d2d963ebecc178a175300ee792cf6b20a667946', 'message': 'Drop v2 and v3 tokens clients\n\nToken clients have been migrated to tempest_lib.\nAll their consumers in tempest already use the tempest_lib version.\nDrop them from tempest.\n\nChange-Id: I3a16a24863162c8691c9125700ffa58eaebc1a57\n'}]",0,180213,3d2d963ebecc178a175300ee792cf6b20a667946,13,5,1,1921,,,0,"Drop v2 and v3 tokens clients

Token clients have been migrated to tempest_lib.
All their consumers in tempest already use the tempest_lib version.
Drop them from tempest.

Change-Id: I3a16a24863162c8691c9125700ffa58eaebc1a57
",git fetch https://review.opendev.org/openstack/tempest refs/changes/13/180213/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/identity/v3/json/token_client.py', 'tempest/services/identity/v2/json/token_client.py']",2,3d2d963ebecc178a175300ee792cf6b20a667946,drop_token_client,,"# Copyright 2015 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import json from tempest_lib.common import rest_client from tempest_lib import exceptions as lib_exc from tempest.common import service_client from tempest import exceptions class TokenClientJSON(rest_client.RestClient): def __init__(self, auth_url, disable_ssl_certificate_validation=None, ca_certs=None, trace_requests=None): dscv = disable_ssl_certificate_validation super(TokenClientJSON, self).__init__( None, None, None, disable_ssl_certificate_validation=dscv, ca_certs=ca_certs, trace_requests=trace_requests) # Normalize URI to ensure /tokens is in it. if 'tokens' not in auth_url: auth_url = auth_url.rstrip('/') + '/tokens' self.auth_url = auth_url def auth(self, user, password, tenant=None): creds = { 'auth': { 'passwordCredentials': { 'username': user, 'password': password, }, } } if tenant: creds['auth']['tenantName'] = tenant body = json.dumps(creds) resp, body = self.post(self.auth_url, body=body) self.expected_success(200, resp.status) return service_client.ResponseBody(resp, body['access']) def auth_token(self, token_id, tenant=None): creds = { 'auth': { 'token': { 'id': token_id, }, } } if tenant: creds['auth']['tenantName'] = tenant body = json.dumps(creds) resp, body = self.post(self.auth_url, body=body) self.expected_success(200, resp.status) return service_client.ResponseBody(resp, body['access']) def request(self, method, url, extra_headers=False, headers=None, body=None): """"""A simple HTTP request interface."""""" if headers is None: headers = self.get_headers(accept_type=""json"") elif extra_headers: try: headers.update(self.get_headers(accept_type=""json"")) except (ValueError, TypeError): headers = self.get_headers(accept_type=""json"") resp, resp_body = self.raw_request(url, method, headers=headers, body=body) self._log_request(method, url, resp) if resp.status in [401, 403]: resp_body = json.loads(resp_body) raise lib_exc.Unauthorized(resp_body['error']['message']) elif resp.status not in [200, 201]: raise exceptions.IdentityError( 'Unexpected status code {0}'.format(resp.status)) if isinstance(resp_body, str): resp_body = json.loads(resp_body) return resp, resp_body def get_token(self, user, password, tenant, auth_data=False): """""" Returns (token id, token data) for supplied credentials """""" body = self.auth(user, password, tenant) if auth_data: return body['token']['id'], body else: return body['token']['id'] ",0,282
openstack%2Fcinder~master~I48e7de0606318e4140928a8209691f752a3fbb0c,openstack/cinder,master,I48e7de0606318e4140928a8209691f752a3fbb0c,Convert mox to mock: tests/compute/test_service.py,MERGED,2014-12-20 22:25:51.000000000,2015-05-20 01:34:22.000000000,2015-05-09 10:48:13.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5538}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 12952}, {'_account_id': 13394}, {'_account_id': 13527}, {'_account_id': 13636}, {'_account_id': 13900}, {'_account_id': 14173}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14314}, {'_account_id': 14428}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}]","[{'number': 1, 'created': '2014-12-20 22:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c6d3a3f330df5818374cb85fd936412887c566f8', 'message': 'Convert mox to mock: tests/compute/test_service.py\n\nReplace mox testing library by mock in the file\ncinder/tests/compute/test_service.py\n\nImplements: blueprint mox-to-mock-conversion\nChange-Id: I48e7de0606318e4140928a8209691f752a3fbb0c\n'}, {'number': 2, 'created': '2014-12-23 05:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b03c57c40b6a5cce0cca1ccce537287ed535774d', 'message': 'Convert mox to mock: tests/compute/test_service.py\n\nReplace mox testing library by mock in the file\ncinder/tests/compute/test_service.py\n\nImplements: blueprint mox-to-mock-conversion\nChange-Id: I48e7de0606318e4140928a8209691f752a3fbb0c\n'}, {'number': 3, 'created': '2014-12-24 12:18:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b67fd97f17befc57176439c988579cf1df976b11', 'message': 'Convert mox to mock: tests/compute/test_service.py\n\nReplace mox testing library by mock in the file\ncinder/tests/compute/test_service.py\n\nImplements: blueprint mox-to-mock-conversion\nChange-Id: I48e7de0606318e4140928a8209691f752a3fbb0c\n'}, {'number': 4, 'created': '2014-12-24 13:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d81bffddfbb7e601f1d7a191caf462e7937419ea', 'message': 'Convert mox to mock: tests/compute/test_service.py\n\nReplace mox testing library by mock in the file\ncinder/tests/compute/test_service.py\n\nImplements: blueprint mox-to-mock-conversion\nChange-Id: I48e7de0606318e4140928a8209691f752a3fbb0c\n'}, {'number': 5, 'created': '2015-05-08 22:15:43.000000000', 'files': ['cinder/tests/unit/test_service.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c4c5d1e49ad874035c7601fa2d5f2dfe15c05af5', 'message': 'Convert mox to mock: tests/compute/test_service.py\n\nReplace mox testing library by mock in the file\ncinder/tests/compute/test_service.py\n\nImplements: blueprint mox-to-mock-conversion\nChange-Id: I48e7de0606318e4140928a8209691f752a3fbb0c\n'}]",5,143281,c4c5d1e49ad874035c7601fa2d5f2dfe15c05af5,86,35,5,14314,,,0,"Convert mox to mock: tests/compute/test_service.py

Replace mox testing library by mock in the file
cinder/tests/compute/test_service.py

Implements: blueprint mox-to-mock-conversion
Change-Id: I48e7de0606318e4140928a8209691f752a3fbb0c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/81/143281/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_service.py'],1,c6d3a3f330df5818374cb85fd936412887c566f8,bp/mox-to-mock-conversion,"import contextlib # NOTE(vish): Create was moved out of mock replay to make sure that with contextlib.nested( mock.patch.object(service, 'db') ) as (mock_db,): mock_db.service_get_by_args.side_effect = exception.NotFound() mock_db.service_create.return_value = service_ref mock_db.service_get.side_effect = db_exc.DBConnectionError() serv = service.Service(host, binary, topic, 'cinder.tests.test_service.FakeManager') serv.start() serv.report_state() self.assertTrue(serv.model_disconnected) with contextlib.nested( mock.patch.object(service, 'db') ) as (mock_db,): mock_db.service_get_by_args.side_effect = exception.NotFound() mock_db.service_create.return_value = service_ref mock_db.service_get.return_value = service_ref serv = service.Service(host, binary, topic, 'cinder.tests.test_service.FakeManager') serv.start() serv.model_disconnected = True serv.report_state() self.assertFalse(serv.model_disconnected) #wsgi.Loader.load_app = mock.MagicMock() with contextlib.nested( mock.patch.object(wsgi.Loader, 'load_app') ) as (mock_load_app,): test_service = service.WSGIService(""test_service"") self.assertEqual(0, test_service.port) test_service.start() self.assertNotEqual(0, test_service.port) test_service.stop() self.assertTrue(mock_load_app.called) with contextlib.nested( mock.patch.object(wsgi.Loader, 'load_app') ) as (mock_load_app,): test_service = service.WSGIService(""test_service"") test_service.start() # Stopping the service, which in turn sets pool size to 0 test_service.stop() self.assertEqual(test_service.server._pool.size, 0) # Resetting pool size to default test_service.reset() test_service.start() self.assertEqual(test_service.server._pool.size, 1000) self.assertTrue(mock_load_app.called)","import mox self.mox.StubOutWithMock(service, 'db') # NOTE(vish): Create was moved out of mox replay to make sure that service_create = {'host': host, 'binary': binary, 'topic': topic, 'report_count': 0, 'availability_zone': 'nova'} service.db.service_get_by_args(mox.IgnoreArg(), host, binary).AndRaise(exception.NotFound()) service.db.service_create(mox.IgnoreArg(), service_create).AndReturn(service_ref) service.db.service_get( mox.IgnoreArg(), mox.IgnoreArg()).AndRaise(db_exc.DBConnectionError()) self.mox.ReplayAll() serv = service.Service(host, binary, topic, 'cinder.tests.test_service.FakeManager') serv.start() serv.report_state() self.assertTrue(serv.model_disconnected) service_create = {'host': host, 'binary': binary, 'topic': topic, 'report_count': 0, 'availability_zone': 'nova'} service.db.service_get_by_args(mox.IgnoreArg(), host, binary).AndRaise(exception.NotFound()) service.db.service_create(mox.IgnoreArg(), service_create).AndReturn(service_ref) service.db.service_get(mox.IgnoreArg(), service_ref['id']).AndReturn(service_ref) service.db.service_update(mox.IgnoreArg(), service_ref['id'], mox.ContainsKeyValue('report_count', 1)) self.mox.ReplayAll() serv = service.Service(host, binary, topic, 'cinder.tests.test_service.FakeManager') serv.start() serv.model_disconnected = True serv.report_state() self.assertFalse(serv.model_disconnected) self.stubs.Set(wsgi.Loader, ""load_app"", mox.MockAnything()) test_service = service.WSGIService(""test_service"") self.assertEqual(0, test_service.port) test_service.start() self.assertNotEqual(0, test_service.port) test_service.stop() test_service = service.WSGIService(""test_service"") test_service.start() # Stopping the service, which in turn sets pool size to 0 test_service.stop() self.assertEqual(test_service.server._pool.size, 0) # Resetting pool size to default test_service.reset() test_service.start() self.assertEqual(test_service.server._pool.size, 1000)",53,65
openstack%2Fdiskimage-builder~master~I311a54ff614596fe7ee23bf44b44b55f9d04690d,openstack/diskimage-builder,master,I311a54ff614596fe7ee23bf44b44b55f9d04690d,Export DIB_RELEASE in centos,MERGED,2015-05-01 17:44:21.000000000,2015-05-20 01:29:15.000000000,2015-05-20 01:29:12.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 9369}, {'_account_id': 10035}, {'_account_id': 12092}]","[{'number': 1, 'created': '2015-05-01 17:44:21.000000000', 'files': ['elements/centos/environment.d/10-centos6-distro-name.bash', 'elements/centos/root.d/10-centos6-cloud-image'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/28d32f1b5f95b680ebd16688e9dbdbe27d0d620c', 'message': 'Export DIB_RELEASE in centos\n\nWe export this variable by convention in the other OS elements.\n\nChange-Id: I311a54ff614596fe7ee23bf44b44b55f9d04690d\n'}]",0,179433,28d32f1b5f95b680ebd16688e9dbdbe27d0d620c,23,8,1,10035,,,0,"Export DIB_RELEASE in centos

We export this variable by convention in the other OS elements.

Change-Id: I311a54ff614596fe7ee23bf44b44b55f9d04690d
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/33/179433/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/centos/environment.d/10-centos6-distro-name.bash', 'elements/centos/root.d/10-centos6-cloud-image']",2,28d32f1b5f95b680ebd16688e9dbdbe27d0d620c,fix/centos-export-dib-release,, DIB_RELEASE=${DIB_RELEASE:-GenericCloud-20141129_01},1,1
openstack%2Fopenstacksdk~master~Ica56e82ab1e53a3a490c5f3d14632bfa1e1c2014,openstack/openstacksdk,master,Ica56e82ab1e53a3a490c5f3d14632bfa1e1c2014,proxy find compute,MERGED,2015-05-19 04:10:43.000000000,2015-05-20 01:10:27.000000000,2015-05-20 01:10:24.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-19 04:10:43.000000000', 'files': ['openstack/compute/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f8099f0c4dfa58543473fb0c037e914956fdbd5d', 'message': 'proxy find compute\n\nChange-Id: Ica56e82ab1e53a3a490c5f3d14632bfa1e1c2014\n'}]",0,184181,f8099f0c4dfa58543473fb0c037e914956fdbd5d,9,3,1,8736,,,0,"proxy find compute

Change-Id: Ica56e82ab1e53a3a490c5f3d14632bfa1e1c2014
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/81/184181/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/compute/v2/_proxy.py'],1,f8099f0c4dfa58543473fb0c037e914956fdbd5d,proxyfindcompute," """"""Find a single extension :param name_or_id: The name or ID of an extension. :returns: One :class:`~openstack.compute.v2.extension.Extension` or None """""" """"""Find a single flavor :param name_or_id: The name or ID of a flavor. :returns: One :class:`~openstack.compute.v2.flavor.Flavor` or None """""" :returns: The results of flavor creation attempting to delete a nonexistent flavor. attempting to delete a nonexistent image. """"""Find a single image :param name_or_id: The name or ID of a image. :returns: One :class:`~openstack.compute.v2.image.Image` or None """""" :returns: The results of keypair creation attempting to delete a nonexistent keypair. """"""Find a single keypair :param name_or_id: The name or ID of a keypair. :returns: One :class:`~openstack.compute.v2.keypair.Keypair` or None """""" """"""Find a single server :param name_or_id: The name or ID of a server. :returns: One :class:`~openstack.compute.v2.server.Server` or None """""" :returns: The results of server interface creation attempting to delete a nonexistent server interface. """"""Find a single server interface :param name_or_id: The name or ID of a server interface. :returns: One :class:`~openstack.compute.v2.server_interface. ServerInterface` or None """""" """"""Find a single server IP :param name_or_id: The name or ID of a server IP. :returns: One :class:`~openstack.compute.v2.server_ip.ServerIP` or None """"""", :returns: The results of server creation attempting to delete a nonexistent server. attempting to delete a nonexistent server. :returns: The results of server creation attempting to delete a nonexistent server. :returns: The results of server creation attempting to delete a nonexistent server.,44,7
openstack%2Fneutron-vpnaas~master~I4fcc863cce2659d6dd49dc8e1f1ee9bb8ce64125,openstack/neutron-vpnaas,master,I4fcc863cce2659d6dd49dc8e1f1ee9bb8ce64125,Updated from global requirements,MERGED,2015-05-07 23:33:22.000000000,2015-05-20 01:00:21.000000000,2015-05-20 01:00:20.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 10980}, {'_account_id': 14216}]","[{'number': 1, 'created': '2015-05-07 23:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/db9ef0ba034a6226ac632b15a4c7b8911e1675f6', 'message': 'Updated from global requirements\n\nChange-Id: I4fcc863cce2659d6dd49dc8e1f1ee9bb8ce64125\n'}, {'number': 2, 'created': '2015-05-14 22:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/95da1ee00c03706d35d6424fa33e45187d380f03', 'message': 'Updated from global requirements\n\nChange-Id: I4fcc863cce2659d6dd49dc8e1f1ee9bb8ce64125\n'}, {'number': 3, 'created': '2015-05-19 21:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/212d67fe182d8505c11c3fd58049a88858f12ba3', 'message': 'Updated from global requirements\n\nChange-Id: I4fcc863cce2659d6dd49dc8e1f1ee9bb8ce64125\n'}, {'number': 4, 'created': '2015-05-19 23:30:46.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/25a1a1d596fa2ec298d2b5c23ccf056a9fce57ec', 'message': 'Updated from global requirements\n\nChange-Id: I4fcc863cce2659d6dd49dc8e1f1ee9bb8ce64125\n'}]",0,181209,25a1a1d596fa2ec298d2b5c23ccf056a9fce57ec,22,6,4,11131,,,0,"Updated from global requirements

Change-Id: I4fcc863cce2659d6dd49dc8e1f1ee9bb8ce64125
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/09/181209/4 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,db9ef0ba034a6226ac632b15a4c7b8911e1675f6,openstack/requirements,"pbr>=0.11,<2.0","pbr>=0.6,!=0.7,<1.0",1,1
openstack%2Ffuel-library~master~I7b6cb2ea7caad31ffaf690f4b5ffb72262a96815,openstack/fuel-library,master,I7b6cb2ea7caad31ffaf690f4b5ffb72262a96815,Wait for virtual ip to start,MERGED,2015-05-19 01:22:01.000000000,2015-05-20 00:31:19.000000000,2015-05-20 00:30:43.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-19 01:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7563e4e639d116ba34e0f229021d659eff427f4b', 'message': 'Wait for virtual ip to start\n\nThis fix makes puppet wait\nfor virtual ip start after\ncorresponding ping location\nis added\n\nChange-Id: I7b6cb2ea7caad31ffaf690f4b5ffb72262a96815\nCloses-bug: #1455910\n'}, {'number': 2, 'created': '2015-05-19 07:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/466f292a4ae61c5d98def87b9d2b711794f33025', 'message': 'Wait for virtual ip to start\n\nThis fix makes puppet wait\nfor virtual ip start after\ncorresponding ping location\nis added\n\nChange-Id: I7b6cb2ea7caad31ffaf690f4b5ffb72262a96815\nCloses-bug: #1455910\n'}, {'number': 3, 'created': '2015-05-19 20:52:28.000000000', 'files': ['deployment/puppet/cluster/manifests/virtual_ip_ping.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/855e1a16c95bf7ee484fdd53e504dd32da733efb', 'message': 'Wait for virtual ip to start\n\nThis fix makes puppet wait\nfor virtual ip start after\ncorresponding ping location\nis added\n\nChange-Id: I7b6cb2ea7caad31ffaf690f4b5ffb72262a96815\nCloses-bug: #1455910\n'}]",0,184168,855e1a16c95bf7ee484fdd53e504dd32da733efb,62,9,3,8786,,,0,"Wait for virtual ip to start

This fix makes puppet wait
for virtual ip start after
corresponding ping location
is added

Change-Id: I7b6cb2ea7caad31ffaf690f4b5ffb72262a96815
Closes-bug: #1455910
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/68/184168/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cluster/manifests/virtual_ip_ping.pp'],1,7563e4e639d116ba34e0f229021d659eff427f4b,bug/1455910," service { ${vip_name}: ensure => 'running', enable => true, provider => 'pacamaker' } Service[""ping_${vip_name}""] -> Service <| title == ${vip_name} |>"," Service<| title == $vip_name |> -> Service[""ping_${vip_name}""]",8,2
openstack%2Fpbr~master~I4202e165e076ea6a4845102ce430a031b043bed7,openstack/pbr,master,I4202e165e076ea6a4845102ce430a031b043bed7,Add pointers to various resources,ABANDONED,2015-01-03 13:26:27.000000000,2015-05-20 00:09:05.000000000,,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4190}, {'_account_id': 5638}, {'_account_id': 6039}, {'_account_id': 14500}]","[{'number': 1, 'created': '2015-01-03 13:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/3cfc66aeb0f33eac2578040feb4e5b16c0799577', 'message': 'Add pointers to various resources\n\nAdd urls for the git repo, github mirror and license information.\n\nChange-Id: I4202e165e076ea6a4845102ce430a031b043bed7\nCloses-Bug: #1406666\n'}, {'number': 2, 'created': '2015-01-06 23:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/9765c2065b07c2b26b67e1515b6c3f6a2660bb74', 'message': 'Add pointers to various resources\n\nAdd urls for the git repo, github mirror and license information.\n\nChange-Id: I4202e165e076ea6a4845102ce430a031b043bed7\nCloses-Bug: #1406666\n'}, {'number': 3, 'created': '2015-01-06 23:14:38.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/pbr/commit/e25ae442283940cb6c6b942579bd307717f5037b', 'message': 'Add pointers to various resources\n\nAdd urls for the git repo, github mirror and license information.\n\nChange-Id: I4202e165e076ea6a4845102ce430a031b043bed7\nCloses-Bug: #1406666\n'}]",3,144838,e25ae442283940cb6c6b942579bd307717f5037b,15,7,3,5638,,,0,"Add pointers to various resources

Add urls for the git repo, github mirror and license information.

Change-Id: I4202e165e076ea6a4845102ce430a031b043bed7
Closes-Bug: #1406666
",git fetch https://review.opendev.org/openstack/pbr refs/changes/38/144838/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3cfc66aeb0f33eac2578040feb4e5b16c0799577,bug/1406666,You can read more in `the documentation`_. Openstack's git repository hosts the `source code`_ for PBR under the `apache license 2.0`_ license. A `github mirror`_ is also available. Bugs are tracked using launchpad_... _github mirror: https://github.com/openstack-dev/pbr/ .. _source code: http://git.openstack.org/cgit .. _apache license 2.0: http://www.apache.org/licenses/LICENSE-2.0,You can read more in `the documentation`_. Bugs are tracked using launchpad_.,6,3
openstack%2Fopenstacksdk~master~I3dcdc9630a60b6ef550530cc729f846605a1ec44,openstack/openstacksdk,master,I3dcdc9630a60b6ef550530cc729f846605a1ec44,change hacking requirements and fix hacking problems,MERGED,2015-05-19 22:36:19.000000000,2015-05-20 00:08:15.000000000,2015-05-20 00:08:15.000000000,"[{'_account_id': 3}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-19 22:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/189b705f95fe647a21f12822ac629fe4e5dce4c4', 'message': 'limit hacking\n\nChange-Id: I3dcdc9630a60b6ef550530cc729f846605a1ec44\n'}, {'number': 2, 'created': '2015-05-19 23:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b225e451aff3406ab284da30d76601b4314d3f89', 'message': 'limit hacking\n\nChange-Id: I3dcdc9630a60b6ef550530cc729f846605a1ec44\n'}, {'number': 3, 'created': '2015-05-19 23:59:19.000000000', 'files': ['openstack/image/v2/image.py', 'test-requirements.txt', 'openstack/tests/unit/test_resource.py', 'openstack/tests/unit/database/v1/test_user.py', 'openstack/tests/unit/image/v2/test_image.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/711cea6f5f84b79378f6aa4f5bf9886dda0c2b9a', 'message': 'change hacking requirements and fix hacking problems\n\nChange-Id: I3dcdc9630a60b6ef550530cc729f846605a1ec44\n'}]",0,184348,711cea6f5f84b79378f6aa4f5bf9886dda0c2b9a,10,2,3,8736,,,0,"change hacking requirements and fix hacking problems

Change-Id: I3dcdc9630a60b6ef550530cc729f846605a1ec44
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/48/184348/3 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,189b705f95fe647a21f12822ac629fe4e5dce4c4,,"hacking>=0.10.0,<0.11","hacking>=0.9.2,<0.10",1,1
openstack%2Fpython-barbicanclient~master~Icf3a462d6f24ce887977c07ed310b39c9d928a29,openstack/python-barbicanclient,master,Icf3a462d6f24ce887977c07ed310b39c9d928a29,Add CLI smoke functional tests for containers,MERGED,2015-05-03 17:24:35.000000000,2015-05-19 23:39:55.000000000,2015-05-19 23:39:54.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 9234}, {'_account_id': 10873}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-05-03 17:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/550684ec18ccaea5a55d32b834b9afaacf57cacb', 'message': 'Add CLI smoke functional tests for containers\n\nAdded tests and behaviors for containers.  Also refactored the\nPrettyTable parsing to make it more generic so we can use it with\nmore than just secrets.\n\nChange-Id: Icf3a462d6f24ce887977c07ed310b39c9d928a29\n'}, {'number': 2, 'created': '2015-05-04 16:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/84d8d36ef22ec0f6e60b61a98c333dc0cca7d3fd', 'message': 'Add CLI smoke functional tests for containers\n\nAdded tests and behaviors for containers.  Also refactored the\nPrettyTable parsing to make it more generic so we can use it with\nmore than just secrets.\n\nChange-Id: Icf3a462d6f24ce887977c07ed310b39c9d928a29\n'}, {'number': 3, 'created': '2015-05-06 19:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/a224abbce1c78d51e3f46cef63a2844d74d2fbae', 'message': 'Add CLI smoke functional tests for containers\n\nAdded tests and behaviors for containers.  Also refactored the\nPrettyTable parsing to make it more generic so we can use it with\nmore than just secrets.\n\nChange-Id: Icf3a462d6f24ce887977c07ed310b39c9d928a29\n'}, {'number': 4, 'created': '2015-05-11 16:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/d51d89f18cde633aafc8518b5b5a6a9b517f798e', 'message': 'Add CLI smoke functional tests for containers\n\nAdded tests and behaviors for containers.  Also refactored the\nPrettyTable parsing to make it more generic so we can use it with\nmore than just secrets.\n\nChange-Id: Icf3a462d6f24ce887977c07ed310b39c9d928a29\n'}, {'number': 5, 'created': '2015-05-11 16:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/797fa68b0df846b00becbf0f9fd61531e46a9645', 'message': 'Add CLI smoke functional tests for containers\n\nAdded tests and behaviors for containers.  Also refactored the\nPrettyTable parsing to make it more generic so we can use it with\nmore than just secrets.\n\nChange-Id: Icf3a462d6f24ce887977c07ed310b39c9d928a29\n'}, {'number': 6, 'created': '2015-05-12 16:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/f954e258feb9bcc6030f6427111e4092e4ad3606', 'message': 'Add CLI smoke functional tests for containers\n\nAdded tests and behaviors for containers.  Also refactored the\nPrettyTable parsing to make it more generic so we can use it with\nmore than just secrets.\n\nChange-Id: Icf3a462d6f24ce887977c07ed310b39c9d928a29\n'}, {'number': 7, 'created': '2015-05-12 18:01:57.000000000', 'files': ['functionaltests/cli/v1/behaviors/container_behaviors.py', 'functionaltests/cli/v1/smoke/test_container.py', 'functionaltests/cli/v1/behaviors/secret_behaviors.py'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/8f1e12eabf1d9541e1a26751401c0712bdfa246b', 'message': 'Add CLI smoke functional tests for containers\n\nAdded tests and behaviors for containers.  Also refactored the\nPrettyTable parsing to make it more generic so we can use it with\nmore than just secrets.\n\nChange-Id: Icf3a462d6f24ce887977c07ed310b39c9d928a29\n'}]",6,179659,8f1e12eabf1d9541e1a26751401c0712bdfa246b,24,6,7,9234,,,0,"Add CLI smoke functional tests for containers

Added tests and behaviors for containers.  Also refactored the
PrettyTable parsing to make it more generic so we can use it with
more than just secrets.

Change-Id: Icf3a462d6f24ce887977c07ed310b39c9d928a29
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/59/179659/2 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/cli/v1/behaviors/container_behaviors.py', 'functionaltests/cli/v1/smoke/test_container.py', 'functionaltests/cli/base.py', 'functionaltests/cli/v1/behaviors/base_behaviors.py', 'functionaltests/cli/v1/behaviors/secret_behaviors.py']",5,550684ec18ccaea5a55d32b834b9afaacf57cacb,containerscli2, secret_list = self._prettytable_to_list(stdout) self.delete_secret(href) , secret_list = self._prettytable_to_secret_list(stdout) self.delete_secret(href),176,20
openstack%2Ftripleo-incubator~master~I7390a5585b078fda0b15ce28d032cf6ba52609f7,openstack/tripleo-incubator,master,I7390a5585b078fda0b15ce28d032cf6ba52609f7,Write tripleorc near start of devtest run,ABANDONED,2014-07-22 18:39:40.000000000,2015-05-19 23:31:18.000000000,,"[{'_account_id': 3}, {'_account_id': 7471}, {'_account_id': 8449}, {'_account_id': 9453}, {'_account_id': 10035}, {'_account_id': 10206}, {'_account_id': 12385}, {'_account_id': 12459}, {'_account_id': 14611}]","[{'number': 1, 'created': '2014-07-22 18:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/56b1cc26676ea3b00736b9488ac7c26b07746090', 'message': ""Write tripleorc in devtest_variables.sh\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc\nwon't get written. This change moves the tripleorc write to\ndevtest_variables.sh so it will get written before a failure may\noccur.\n\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 2, 'created': '2014-07-22 19:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/879e52fc8881c8d2df3f03505f74c607deda9a03', 'message': ""Write tripleorc in devtest_variables.sh\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc\nwon't get written. This change moves the tripleorc write to\ndevtest_variables.sh so it will get written before a failure may\noccur.\n\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 3, 'created': '2014-07-24 17:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/35dcd75141303cb3dd549d389cde1690a2ec182e', 'message': ""Write tripleorc in devtest_variables.sh\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc\nwon't get written. This change moves the tripleorc write to\ndevtest_variables.sh so it will get written before a failure may\noccur.\n\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 4, 'created': '2014-07-24 20:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/e8ab41aa7ee7331b0b58ad244506810d12b82b0d', 'message': ""Write tripleorc in devtest_variables.sh\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc\nwon't get written. This change moves the tripleorc write to\ndevtest_variables.sh so it will get written before a failure may\noccur.\n\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 5, 'created': '2014-09-29 20:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/412de04b6a08f436fd8d51f389fc8b85ac32924f', 'message': 'Rebase required.\n\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n'}, {'number': 6, 'created': '2014-09-29 20:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/49eea77bab786512e6e0e6672fedf23de781d6fe', 'message': ""Write tripleorc in devtest_variables.sh\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc\nwon't get written. This change moves the tripleorc write to\ndevtest_variables.sh so it will get written before a failure may\noccur.\n\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 7, 'created': '2014-09-29 20:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/60fc84781d3d5e82833500db808951e58af5dbf4', 'message': ""Write tripleorc in devtest_variables.sh\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc\nwon't get written. This change moves the tripleorc write to\ndevtest_variables.sh so it will get written before a failure may\noccur.\n\npartial-bug: 1342333\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 8, 'created': '2015-01-30 15:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/83d2bc159cf44d624083b511c2a674231790bf38', 'message': ""Write tripleorc in devtest_variables.sh\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc\nwon't get written. This change moves the tripleorc write to\ndevtest_variables.sh so it will get written before a failure may\noccur.\n\npartial-bug: 1298949\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 9, 'created': '2015-01-30 21:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/40e955f28c6c077ba01287828d59a2c2e74f7d78', 'message': ""Write tripleorc in devtest_variables.sh\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc\nwon't get written. This change moves the tripleorc write to\ndevtest_variables.sh so it will get written before a failure may\noccur.\n\npartial-bug: 1298949\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 10, 'created': '2015-02-05 21:20:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/265951852c862b217afca5eed6fecf04c769a11c', 'message': ""Write tripleorc in devtest_variables.sh\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc\nwon't get written. This change moves the tripleorc write to\ndevtest_variables.sh so it will get written before a failure may\noccur.\n\npartial-bug: 1298949\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 11, 'created': '2015-02-05 22:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/55a5f4aa1521cfe95e4a662210f3c7165a3d39de', 'message': ""Write tripleorc in devtest_variables.sh\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc\nwon't get written. This change moves the tripleorc write to\ndevtest_variables.sh so it will get written before a failure may\noccur.\n\npartial-bug: 1298949\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 12, 'created': '2015-02-09 18:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/54ad701a24f144572af6163a4a7aac377a973c6b', 'message': ""Write tripleorc near start of devtest run\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc won't\nget written. This change adds an additional write of the tripleorc so\nit will get written before a failure may occur. To facilitate writing\ntripleorc early, I've had to move the assignment of some variables to\ndevtest_variables.sh. I've also refashioned devtest_end.sh into the\nmore generic devtest_write.sh for reusability.\n\npartial-bug: 1298949\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 13, 'created': '2015-02-09 19:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/0d5e56bac72285b4a4d97c6f8181248c5f834bcc', 'message': ""Write tripleorc near start of devtest run\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc won't\nget written. This change adds an additional write of the tripleorc so\nit will get written before a failure may occur. To facilitate writing\ntripleorc early, I've had to move the assignment of some variables to\ndevtest_variables.sh. I've also refashioned devtest_end.sh into the\nmore generic devtest_write.sh for reusability.\n\npartial-bug: 1298949\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 14, 'created': '2015-02-09 19:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/91fcc1815049a35267d9c37e68524c108a719d6b', 'message': ""Write tripleorc near start of devtest run\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc won't\nget written. This change adds an additional write of the tripleorc so\nit will get written before a failure may occur. To facilitate writing\ntripleorc early, I've had to move the assignment of some variables to\ndevtest_variables.sh. I've also refashioned devtest_end.sh into the\nmore generic devtest_write.sh for reusability.\n\npartial-bug: 1298949\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 15, 'created': '2015-02-09 19:12:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/4a68a6371d43f780d8e5d3d6f4b8a1c5451d6ea4', 'message': ""Write tripleorc near start of devtest run\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc won't\nget written. This change adds an additional write of the tripleorc so\nit will get written before a failure may occur. To facilitate writing\ntripleorc early, I've had to move the assignment of some variables to\ndevtest_variables.sh. I've also refashioned devtest_end.sh into the\nmore generic devtest_write.sh for reusability.\n\npartial-bug: 1298949\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 16, 'created': '2015-02-09 19:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/9ea165d69830d95fc658cced82a21e2cb4f6abb1', 'message': ""Write tripleorc near start of devtest run\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc won't\nget written. This change adds an additional write of the tripleorc so\nit will get written before a failure may occur. To facilitate writing\ntripleorc early, I've had to move the assignment of some variables to\ndevtest_variables.sh. I've also refashioned devtest_end.sh into the\nmore generic devtest_write.sh for reusability.\n\npartial-bug: 1298949\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 17, 'created': '2015-02-09 22:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/e4c5d2e1a2e801687925e00b15cc16bc61bcc5e0', 'message': ""Write tripleorc near start of devtest run\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc won't\nget written. This change adds an additional write of the tripleorc so\nit will get written before a failure may occur. To facilitate writing\ntripleorc early, I've had to move the assignment of some variables to\ndevtest_variables.sh. I've also refashioned devtest_end.sh into the\nmore generic devtest_write.sh for reusability.\n\npartial-bug: 1298949\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}, {'number': 18, 'created': '2015-02-11 18:38:30.000000000', 'files': ['scripts/devtest_end.sh', 'doc/source/index.rst', 'scripts/devtest_undercloud.sh', 'scripts/devtest_variables.sh', 'scripts/devtest_overcloud.sh', 'scripts/boot-seed-vm', 'scripts/devtest.sh', 'scripts/devtest_writerc.sh', 'scripts/write-tripleorc'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/e2520308771eb49860492f15271f10d18ed099dd', 'message': ""Write tripleorc near start of devtest run\n\nCurrently, tripleorc doesn't get written until devtest_end.sh is run.\nThis means that if devtest fails prior to the end, the tripleorc won't\nget written. This change adds an additional write of the tripleorc so\nit will get written before a failure may occur. To facilitate writing\ntripleorc early, I've had to move the assignment of some variables to\ndevtest_variables.sh. I've also refashioned devtest_end.sh into the\nmore generic devtest_write.sh for reusability.\n\npartial-bug: 1298949\nChange-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7\n""}]",13,108801,e2520308771eb49860492f15271f10d18ed099dd,88,9,18,12459,,,0,"Write tripleorc near start of devtest run

Currently, tripleorc doesn't get written until devtest_end.sh is run.
This means that if devtest fails prior to the end, the tripleorc won't
get written. This change adds an additional write of the tripleorc so
it will get written before a failure may occur. To facilitate writing
tripleorc early, I've had to move the assignment of some variables to
devtest_variables.sh. I've also refashioned devtest_end.sh into the
more generic devtest_write.sh for reusability.

partial-bug: 1298949
Change-Id: I7390a5585b078fda0b15ce28d032cf6ba52609f7
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/01/108801/18 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/devtest_end.sh', 'scripts/devtest_variables.sh', 'scripts/devtest_overcloud.sh', 'scripts/devtest_ramdisk.sh']",4,56b1cc26676ea3b00736b9488ac7c26b07746090,bug/1342333,,"## #. Choose the deploy image element to be used. `deploy-kexec` will relieve you of ## the need to wait for long hardware POST times, however it has known stability ## issues (please see https://bugs.launchpad.net/diskimage-builder/+bug/1240933). ## If stability is preferred over speed, use `deploy` image element (default). ## :: if [ $USE_IRONIC -eq 0 ]; then # nova baremetal DEPLOY_IMAGE_ELEMENT=${DEPLOY_IMAGE_ELEMENT:-deploy-baremetal} DEPLOY_NAME=deploy-ramdisk else # Ironic DEPLOY_IMAGE_ELEMENT=${DEPLOY_IMAGE_ELEMENT:-deploy-ironic} DEPLOY_NAME=deploy-ramdisk-ironic fi ",27,35
openstack%2Frequirements~master~Ia399c65e62c2306c9a2d082c6219fcb030b5946b,openstack/requirements,master,Ia399c65e62c2306c9a2d082c6219fcb030b5946b,Add os-testr to global requirements list,MERGED,2015-04-02 20:19:25.000000000,2015-05-19 23:25:56.000000000,2015-05-19 23:25:55.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 4190}, {'_account_id': 5196}, {'_account_id': 6786}, {'_account_id': 8871}]","[{'number': 1, 'created': '2015-04-02 20:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/9e278cabff01b90dc1a9fd50e3afea1eb58ff17e', 'message': ""Add os-testr to global requirements list\n\nThis commit adds os-testr to global requirements since it will be\nthe default runner of testr for most projects' tests. Also the direct\ntestrepository (and possibly subunit) requirement will be removed from\nprojects in favor of letting os-testr dictate that requirement. So it\nis also added to the projects list.\n\nChange-Id: Ia399c65e62c2306c9a2d082c6219fcb030b5946b\n""}, {'number': 2, 'created': '2015-04-23 16:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/b422a181772b4ff0dbac5140ed23b58ec7f349ed', 'message': ""Add os-testr to global requirements list\n\nThis commit adds os-testr to global requirements since it will be\nthe default runner of testr for most projects' tests. Also the direct\ntestrepository (and possibly subunit) requirement will be removed from\nprojects in favor of letting os-testr dictate that requirement. So it\nis also added to the projects list.\n\nChange-Id: Ia399c65e62c2306c9a2d082c6219fcb030b5946b\n""}, {'number': 3, 'created': '2015-04-27 13:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/e7748bb7996db08de7f95f1881881ae91dfbd0a8', 'message': ""Add os-testr to global requirements list\n\nThis commit adds os-testr to global requirements since it will be\nthe default runner of testr for most projects' tests.\n\nChange-Id: Ia399c65e62c2306c9a2d082c6219fcb030b5946b\n""}, {'number': 4, 'created': '2015-05-14 20:19:28.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a20f362d0dff8af60fe6696c2e8d7fd2b0d98da0', 'message': ""Add os-testr to global requirements list\n\nThis commit adds os-testr to global requirements since it will be\nthe default runner of testr for most projects' tests.\n\nChange-Id: Ia399c65e62c2306c9a2d082c6219fcb030b5946b\n""}]",2,170268,a20f362d0dff8af60fe6696c2e8d7fd2b0d98da0,33,7,4,5196,,,0,"Add os-testr to global requirements list

This commit adds os-testr to global requirements since it will be
the default runner of testr for most projects' tests.

Change-Id: Ia399c65e62c2306c9a2d082c6219fcb030b5946b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/68/170268/4 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'projects.txt']",2,9e278cabff01b90dc1a9fd50e3afea1eb58ff17e,170268,openstack/os-testr,,2,0
openstack%2Ftempest~master~Ib2885dbb04af3dc12724fe50bed8ce73ec3c426c,openstack/tempest,master,Ib2885dbb04af3dc12724fe50bed8ce73ec3c426c,Only create a TokenClient if api_v2 is enabled,MERGED,2015-05-13 11:51:37.000000000,2015-05-19 23:24:12.000000000,2015-05-19 23:24:10.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9142}]","[{'number': 1, 'created': '2015-05-13 11:51:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0ea7f79eda44f10a81f776b1b6ad81248f9e4e2b', 'message': 'Only create a TokenClient is api_v2 is enabled\n\nToken clients should only be setup if the corresponding API\nversion is marked as available. If they are configured as\navailable but the URI is not set, the configuration is invalid.\n\nChange-Id: Ib2885dbb04af3dc12724fe50bed8ce73ec3c426c\nCloses-bug: #1451987\n'}, {'number': 2, 'created': '2015-05-13 11:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fd4e27d8aff9d3181d5c55d1973f09564c06f2b3', 'message': 'Only create a TokenClient is api_v2 is enabled\n\nToken clients should only be setup if the corresponding API\nversion is marked as available. If they are configured as\navailable but the URI is not set, the configuration is invalid.\n\nChange-Id: Ib2885dbb04af3dc12724fe50bed8ce73ec3c426c\nCloses-bug: #1451987\n'}, {'number': 3, 'created': '2015-05-13 12:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8f1276cb2a89132b5ea6a10db1d4e019b2cd05b3', 'message': 'Only create a TokenClient is api_v2 is enabled\n\nToken clients should only be setup if the corresponding API\nversion is marked as available. If they are configured as\navailable but the URI is not set, the configuration is invalid.\n\nChange-Id: Ib2885dbb04af3dc12724fe50bed8ce73ec3c426c\nCloses-bug: #1451987\n'}, {'number': 4, 'created': '2015-05-14 09:01:04.000000000', 'files': ['tempest/clients.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/03e546fe038f5d7617e7e450c471cd578c0c2e82', 'message': 'Only create a TokenClient if api_v2 is enabled\n\nToken clients should only be setup if the corresponding API\nversion is marked as available. If they are configured as\navailable but the URI is not set, the configuration is invalid.\n\nChange-Id: Ib2885dbb04af3dc12724fe50bed8ce73ec3c426c\nCloses-bug: #1451987'}]",1,182629,03e546fe038f5d7617e7e450c471cd578c0c2e82,29,6,4,1921,,,0,"Only create a TokenClient if api_v2 is enabled

Token clients should only be setup if the corresponding API
version is marked as available. If they are configured as
available but the URI is not set, the configuration is invalid.

Change-Id: Ib2885dbb04af3dc12724fe50bed8ce73ec3c426c
Closes-bug: #1451987",git fetch https://review.opendev.org/openstack/tempest refs/changes/29/182629/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/clients.py'],1,0ea7f79eda44f10a81f776b1b6ad81248f9e4e2b,bug/1451987,"from tempest import exceptions # They read auth_url, so they should only be set if the corresponding # API version is marked as enabled if CONF.identity_feature_enabled.api_v2: if CONF.identity.uri: self.token_client = TokenClientJSON( CONF.identity.uri, **self.default_params) else: msg = 'Identity v2 API enabled, but no conf.identity.uri set' raise exceptions.InvalidConfiguration(msg) if CONF.identity_feature_enabled.api_v3: if CONF.identity.uri_v3: self.token_v3_client = V3TokenClientJSON( CONF.identity.uri_v3, **self.default_params) else: msg = 'Identity v3 API enabled, but no conf.identity.uri_v3 set' raise exceptions.InvalidConfiguration(msg)"," self.token_client = TokenClientJSON(CONF.identity.uri, **self.default_params) if CONF.identity_feature_enabled.api_v3: self.token_v3_client = V3TokenClientJSON(CONF.identity.uri_v3, **self.default_params)",16,4
openstack%2Fpuppet-manila~master~I03f7cd95809eba8fb6b1679a5669fbc72a9bc82c,openstack/puppet-manila,master,I03f7cd95809eba8fb6b1679a5669fbc72a9bc82c,Bring Redhat support to acceptance tests,MERGED,2015-05-18 11:17:53.000000000,2015-05-19 23:20:31.000000000,2015-05-19 23:20:31.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}]","[{'number': 1, 'created': '2015-05-18 11:17:53.000000000', 'files': ['spec/acceptance/basic_manila_spec.rb', 'spec/acceptance/nodesets/nodepool-trusty.yml', 'Gemfile', 'spec/spec_helper_acceptance.rb', 'spec/acceptance/nodesets/nodepool-centos7.yml'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/ce1fa24cfdbb1073a1fedbb373b690b92b35c43f', 'message': 'Bring Redhat support to acceptance tests\n\nOpenStack Infra has jobs to run this on both Ubuntu Trusty and CentOS7.\n\n* Add minitest to Gemfile (dependency to run beaker on centos - see\n  http://projects.theforeman.org/issues/2650 for details)\n* separate nodepool files to have trusty & centos7 support in OS infra\n* basic_manila_spec: add case for repo configuration and support\n  RH systems.\n* rabbitmq: install module from source\n* apt: pin the module\n\nChange-Id: I03f7cd95809eba8fb6b1679a5669fbc72a9bc82c\nCloses-bug: #1444736\n'}]",0,184022,ce1fa24cfdbb1073a1fedbb373b690b92b35c43f,7,3,1,5241,,,0,"Bring Redhat support to acceptance tests

OpenStack Infra has jobs to run this on both Ubuntu Trusty and CentOS7.

* Add minitest to Gemfile (dependency to run beaker on centos - see
  http://projects.theforeman.org/issues/2650 for details)
* separate nodepool files to have trusty & centos7 support in OS infra
* basic_manila_spec: add case for repo configuration and support
  RH systems.
* rabbitmq: install module from source
* apt: pin the module

Change-Id: I03f7cd95809eba8fb6b1679a5669fbc72a9bc82c
Closes-bug: #1444736
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/22/184022/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/acceptance/basic_manila_spec.rb', 'spec/acceptance/nodesets/nodepool-trusty.yml', 'Gemfile', 'spec/spec_helper_acceptance.rb', 'spec/acceptance/nodesets/nodepool-centos7.yml']",5,ce1fa24cfdbb1073a1fedbb373b690b92b35c43f,bug/1444736,HOSTS: centos-70-x64: roles: - master platform: el-7-x86_64 hypervisor : none ip: 127.0.0.1 CONFIG: type: foss ,,44,5
openstack%2Fpuppet-manila~master~I587f1e00ab431a39a44fff72a8c662f33cce5749,openstack/puppet-manila,master,I587f1e00ab431a39a44fff72a8c662f33cce5749,Beaker: install APT repo with openstack_extras,MERGED,2015-05-18 11:17:53.000000000,2015-05-19 23:19:23.000000000,2015-05-19 23:19:23.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}]","[{'number': 1, 'created': '2015-05-18 11:17:53.000000000', 'files': ['spec/acceptance/basic_manila_spec.rb', 'spec/spec_helper_acceptance.rb'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/64240b02ddf888a5def1c599effe739f0472eb18', 'message': 'Beaker: install APT repo with openstack_extras\n\nUse openstack_extras module to manage Ubuntu Cloud Archive repository.\n\nChange-Id: I587f1e00ab431a39a44fff72a8c662f33cce5749\n'}]",0,184021,64240b02ddf888a5def1c599effe739f0472eb18,7,3,1,5241,,,0,"Beaker: install APT repo with openstack_extras

Use openstack_extras module to manage Ubuntu Cloud Archive repository.

Change-Id: I587f1e00ab431a39a44fff72a8c662f33cce5749
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/21/184021/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/acceptance/basic_manila_spec.rb', 'spec/spec_helper_acceptance.rb']",2,64240b02ddf888a5def1c599effe739f0472eb18,bug/1444736, shell('git clone https://git.openstack.org/stackforge/puppet-openstack_extras /etc/puppet/modules/openstack_extras'),,4,13
openstack%2Fstevedore~master~Ie64901feb49a3313016057fa7992f8a93e69c73a,openstack/stevedore,master,Ie64901feb49a3313016057fa7992f8a93e69c73a,Updated from global requirements,MERGED,2015-05-04 18:51:42.000000000,2015-05-19 23:09:38.000000000,2015-05-19 23:09:38.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 7575}, {'_account_id': 11356}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-04 18:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stevedore/commit/1f84cc307de693f4cf28d9f23e1d5c8ee3654b01', 'message': 'Updated from global requirements\n\nChange-Id: Ie64901feb49a3313016057fa7992f8a93e69c73a\n'}, {'number': 2, 'created': '2015-05-07 23:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stevedore/commit/5bda1528c30060b7be4d88f3d33763ae7c38e9c9', 'message': 'Updated from global requirements\n\nChange-Id: Ie64901feb49a3313016057fa7992f8a93e69c73a\n'}, {'number': 3, 'created': '2015-05-12 14:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stevedore/commit/acdf52ca1b022d97f2b180cc4a5c3ef08d791302', 'message': 'Updated from global requirements\n\nChange-Id: Ie64901feb49a3313016057fa7992f8a93e69c73a\n'}, {'number': 4, 'created': '2015-05-13 16:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/stevedore/commit/d2510e2806a419fcb001281db0d2464464c7ab7a', 'message': 'Updated from global requirements\n\nChange-Id: Ie64901feb49a3313016057fa7992f8a93e69c73a\n'}, {'number': 5, 'created': '2015-05-19 21:39:46.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/stevedore/commit/fd4626172b774997eb56e7b301d98e67addbc31e', 'message': 'Updated from global requirements\n\nChange-Id: Ie64901feb49a3313016057fa7992f8a93e69c73a\n'}]",0,179877,fd4626172b774997eb56e7b301d98e67addbc31e,17,5,5,11131,,,0,"Updated from global requirements

Change-Id: Ie64901feb49a3313016057fa7992f8a93e69c73a
",git fetch https://review.opendev.org/openstack/stevedore refs/changes/77/179877/4 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,1f84cc307de693f4cf28d9f23e1d5c8ee3654b01,openstack/requirements,Pillow>=2.4.0 # MIT,Pillow==2.4.0 # MIT,1,1
openstack%2Fmagnum~master~I8cb78f990c08cb527ebce3fa720537b5c03eb942,openstack/magnum,master,I8cb78f990c08cb527ebce3fa720537b5c03eb942,Fix the docker build image issue,MERGED,2015-05-18 03:14:40.000000000,2015-05-19 22:54:58.000000000,2015-05-19 22:54:58.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 11650}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-05-18 03:14:40.000000000', 'files': ['Dockerfile'], 'web_link': 'https://opendev.org/openstack/magnum/commit/19aaa9edf6a43c206cd454e5a523d7c044a32075', 'message': 'Fix the docker build image issue\n\nThe python cryptography issue, check\nhttp://www.123code.blogspot.com/2014/10/fixed-installing-python-cryptography.html\n\nThe ubuntu pip issue, check\nhttp://stackoverflow.com/questions/27341064/how-do-i-fix-importerror-cannot-import-name-incompleteread\n\nCloses-Bug: #1455420\nChange-Id: I8cb78f990c08cb527ebce3fa720537b5c03eb942\n'}]",0,183964,19aaa9edf6a43c206cd454e5a523d7c044a32075,8,4,1,7049,,,0,"Fix the docker build image issue

The python cryptography issue, check
http://www.123code.blogspot.com/2014/10/fixed-installing-python-cryptography.html

The ubuntu pip issue, check
http://stackoverflow.com/questions/27341064/how-do-i-fix-importerror-cannot-import-name-incompleteread

Closes-Bug: #1455420
Change-Id: I8cb78f990c08cb527ebce3fa720537b5c03eb942
",git fetch https://review.opendev.org/openstack/magnum refs/changes/64/183964/1 && git format-patch -1 --stdout FETCH_HEAD,['Dockerfile'],1,19aaa9edf6a43c206cd454e5a523d7c044a32075,fixdocker,RUN apt-get update && apt-get install -y tar git curl nano wget dialog net-tools build-essential libssl-dev libffi-dev python python-dev python-distribute python-pip# Upgrade pip since ubuntu pip package has bug RUN easy_install -U pip ,RUN apt-get update && apt-get install -y tar git curl nano wget dialog net-tools build-essential python python-dev python-distribute python-pip,4,1
openstack%2Fmonasca-agent~master~I5bbaf93753135b6a394573f785a96e707036fa05,openstack/monasca-agent,master,I5bbaf93753135b6a394573f785a96e707036fa05,Detect the port of the api before setting up an http check,MERGED,2015-05-19 17:44:35.000000000,2015-05-19 22:42:40.000000000,2015-05-19 22:42:40.000000000,"[{'_account_id': 3}, {'_account_id': 11809}, {'_account_id': 12133}]","[{'number': 1, 'created': '2015-05-19 17:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/67f73138193b5db6210055011926bc23ac02169b', 'message': 'Detect the port of the api before setting up an http check\n\nChange-Id: I5bbaf93753135b6a394573f785a96e707036fa05\n'}, {'number': 2, 'created': '2015-05-19 22:29:14.000000000', 'files': ['monasca_setup/detection/plugins/mon.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/80e621b07357843caa7a7a670fd421c3dfc84165', 'message': 'Detect the port of the api before setting up an http check\n\nChange-Id: I5bbaf93753135b6a394573f785a96e707036fa05\n'}]",1,184301,80e621b07357843caa7a7a670fd421c3dfc84165,10,3,2,11094,,,0,"Detect the port of the api before setting up an http check

Change-Id: I5bbaf93753135b6a394573f785a96e707036fa05
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/01/184301/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_setup/detection/plugins/mon.py'],1,67f73138193b5db6210055011926bc23ac02169b,feature/detect_port,"import yaml # Find the right port from the config, this is specific to the Java version try: with open('/etc/monasca/api-config.yml', 'r') as config: self.api_config = yaml.load(config.read()) except Exception: self.available = False return api_port = self.api_config['server']['applicationConnectors'][0]['port'] for conn in monasca_api.connections('inet'): if conn.laddr[1] == api_port: admin_port = self.api_config['server']['adminConnectors'][0]['port'] return dropwizard_health_check('monitoring', 'api', 'http://localhost:{0}/healthcheck'.format(admin_port))"," for conn in monasca_api.connections('inet'): if conn.laddr[1] == 8080: return dropwizard_health_check('monitoring', 'api', 'http://localhost:8081/healthcheck')",12,2
openstack%2Ftaskflow~master~I7953621f925fadfa18efb6c9b1bbba24d9ba496c,openstack/taskflow,master,I7953621f925fadfa18efb6c9b1bbba24d9ba496c,Remove script already nuked from oslo-incubator,MERGED,2015-05-16 20:03:41.000000000,2015-05-19 22:34:41.000000000,2015-05-19 22:34:39.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-16 20:03:41.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9c4520e989127fa89496ef1d8e9e71edb21ed187', 'message': 'Remove script already nuked from oslo-incubator\n\nChange-Id: I7953621f925fadfa18efb6c9b1bbba24d9ba496c\n'}]",0,183833,9c4520e989127fa89496ef1d8e9e71edb21ed187,26,3,1,5638,,,0,"Remove script already nuked from oslo-incubator

Change-Id: I7953621f925fadfa18efb6c9b1bbba24d9ba496c
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/33/183833/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,9c4520e989127fa89496ef1d8e9e71edb21ed187,,,# The list of modules to copy from oslo-incubator.git script=tools/run_cross_tests.sh ,0,3
openstack%2Fpbr~master~I2118f2a96d0c9984797424e5dda47547c8e24621,openstack/pbr,master,I2118f2a96d0c9984797424e5dda47547c8e24621,Remove self.pre_run calls in packaging.py,MERGED,2015-05-19 15:49:01.000000000,2015-05-19 22:34:29.000000000,2015-05-19 22:34:28.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4190}, {'_account_id': 5950}, {'_account_id': 7293}, {'_account_id': 11904}]","[{'number': 1, 'created': '2015-05-19 15:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/5eeb4cee6403cb1939de8ced29080d7a5a297fe8', 'message': 'Remove self.pre_run calls in packaging.py\n\npre_run was a method of _PipInstallTestRequires class which was\nremoved by https://review.openstack.org/#/c/181785/.\n\nChange-Id: I2118f2a96d0c9984797424e5dda47547c8e24621\nCloses-Bug: #1456663\n'}, {'number': 2, 'created': '2015-05-19 16:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/58c379fa1e4edada411265d2bfee49967910353d', 'message': 'Remove self.pre_run calls in packaging.py\n\npre_run was a method of _PipInstallTestRequires class which was\nremoved by https://review.openstack.org/#/c/181785/.\n\nChange-Id: I2118f2a96d0c9984797424e5dda47547c8e24621\nCloses-Bug: #1456663\n'}, {'number': 3, 'created': '2015-05-19 17:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/cd8a39aeaab5ace7e7301ff8c9674ae79770f397', 'message': 'Remove self.pre_run calls in packaging.py\n\npre_run was a method of _PipInstallTestRequires class which was\nremoved by https://review.openstack.org/#/c/181785/.\n\nChange-Id: I2118f2a96d0c9984797424e5dda47547c8e24621\nCloses-Bug: #1456663\n'}, {'number': 4, 'created': '2015-05-19 21:01:13.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/b72e4467e1332cd441def32328249ace99c21b18', 'message': 'Remove self.pre_run calls in packaging.py\n\npre_run was a method of _PipInstallTestRequires class which was\nremoved by https://review.openstack.org/#/c/181785/.\n\nChange-Id: I2118f2a96d0c9984797424e5dda47547c8e24621\nCloses-Bug: #1456663\n'}]",0,184273,b72e4467e1332cd441def32328249ace99c21b18,21,6,4,7293,,,0,"Remove self.pre_run calls in packaging.py

pre_run was a method of _PipInstallTestRequires class which was
removed by https://review.openstack.org/#/c/181785/.

Change-Id: I2118f2a96d0c9984797424e5dda47547c8e24621
Closes-Bug: #1456663
",git fetch https://review.opendev.org/openstack/pbr refs/changes/73/184273/4 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,5eeb4cee6403cb1939de8ced29080d7a5a297fe8,bug/1456663,, self.pre_run() self.pre_run(),0,2
openstack%2Fdiskimage-builder~master~Idaff33096bf32865020b85ee776abd6691ac45ad,openstack/diskimage-builder,master,Idaff33096bf32865020b85ee776abd6691ac45ad,Update install docs to be more user friendly,MERGED,2015-04-12 16:08:45.000000000,2015-05-19 22:31:22.000000000,2015-05-19 22:31:19.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-04-12 16:08:45.000000000', 'files': ['doc/source/user_guide/installation.rst'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/d98e6dcff9fa47f40998fe3807d4bb5af6dbcac1', 'message': 'Update install docs to be more user friendly\n\nOur install docs are out of date and not very user friendly. Lets fix\nthat.\n\nChange-Id: Idaff33096bf32865020b85ee776abd6691ac45ad\n'}]",0,172723,d98e6dcff9fa47f40998fe3807d4bb5af6dbcac1,19,4,1,10035,,,0,"Update install docs to be more user friendly

Our install docs are out of date and not very user friendly. Lets fix
that.

Change-Id: Idaff33096bf32865020b85ee776abd6691ac45ad
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/23/172723/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user_guide/installation.rst'],1,d98e6dcff9fa47f40998fe3807d4bb5af6dbcac1,feature/new-install-guide,"Diskimage-builder can either be run directly out of the source repository or installed via pip. If you plan on doing development on diskimage-builder or the elements then we recommend you run the tool out of the source repository as this installation requires minimal extra effort and does not require an extra install step for your changes to take effect. Once installed, you will be able to `build images <building_an_image>` using disk-image-create and the elements included in the main diskimage-builder repository. Most image formats require the qemu-img tool which is provided by the qemu-utils package on Ubuntu/Debian or the qemu package on Fedora/RHEL/opensuse. Some image formats, such as VHD, may require additional tools. Please see the disk-image-create help output for more information. Individual elements can also have additional dependencies for the build host. It is recommended you check the documentation for each element you are using to determine if there are any additional dependencies. Source Installation ------------------- Clone the diskimage-builder and dib-utils repositories locally: :: git clone https://git.openstack.org/openstack/diskimage-builder git clone https://git.openstack.org/openstack/dib-utils Add the bin dirs to your path: :: export PATH=$PATH:$(pwd)/diskimage-builder/bin:$(pwd)/dib-utils/bin Pip Installation ---------------- Installing via pip is as simple as: :: pip install diskimage-builder Speedups -------- If you have 4GB of available physical RAM (As reported by /proc/meminfo MemTotal), or more, diskimage-builder will create a tmpfs mount to build the image in. This will improve image build time by building in RAM.","Diskimage-builder is run directly out of the source repository.If you have 4GB of available physical RAM (As reported by /proc/meminfo MemTotal), or more, diskimage-builder will create a tmpfs mount to build the image in. This will improve image build time by building in RAM.Installation ------------ * Clone the repository locally, then add bin to your path. * Make sure you have qemu-img (qemu-utils package on Ubuntu/Debian, qemu on Fedora/RHEL/openSUSE) and kpartx installed.",56,11
openstack%2Fneutron-vpnaas~master~Ie6108dbe15749480098c2d9e7792327a3042ada8,openstack/neutron-vpnaas,master,Ie6108dbe15749480098c2d9e7792327a3042ada8,Add neutron-vpnaas/tests/unit/extensions/__init__,MERGED,2015-05-12 01:11:23.000000000,2015-05-19 22:31:16.000000000,2015-05-19 22:31:14.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2888}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 10980}, {'_account_id': 14216}]","[{'number': 1, 'created': '2015-05-12 01:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/9dbe27adcb7845ef390509c94f5232491ab1c700', 'message': 'Add neutron-vpnaas/tests/unit/extensions/__init__\n\nThe absence of this file was preventing tests in the target\ndirectory from being discoverable.\n\nChange-Id: Ie6108dbe15749480098c2d9e7792327a3042ada8\nCloses-Bug: #1453965\n'}, {'number': 2, 'created': '2015-05-14 20:17:12.000000000', 'files': ['neutron_vpnaas/tests/unit/extensions/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/66f2fcbdb63d0622906a062d0624da7f2bccf833', 'message': 'Add neutron-vpnaas/tests/unit/extensions/__init__\n\nThe absence of this file was preventing tests in the target\ndirectory from being discoverable.\n\nChange-Id: Ie6108dbe15749480098c2d9e7792327a3042ada8\nCloses-Bug: #1453965\n'}]",0,182135,66f2fcbdb63d0622906a062d0624da7f2bccf833,16,8,2,2035,,,0,"Add neutron-vpnaas/tests/unit/extensions/__init__

The absence of this file was preventing tests in the target
directory from being discoverable.

Change-Id: Ie6108dbe15749480098c2d9e7792327a3042ada8
Closes-Bug: #1453965
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/35/182135/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas/tests/unit/extensions/__init__.py'],1,9dbe27adcb7845ef390509c94f5232491ab1c700,,,,0,0
openstack%2Fneutron-fwaas~master~I483f7d029c35e1d99105695ee7b62b1ad852c10e,openstack/neutron-fwaas,master,I483f7d029c35e1d99105695ee7b62b1ad852c10e,vendor code should refer to Brocade,MERGED,2015-05-13 14:15:14.000000000,2015-05-19 22:31:07.000000000,2015-05-19 22:31:06.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 6995}, {'_account_id': 8645}, {'_account_id': 10119}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12525}, {'_account_id': 15330}]","[{'number': 1, 'created': '2015-05-13 14:15:14.000000000', 'files': ['neutron_fwaas/services/firewall/agents/vyatta/vyatta_utils.py', 'neutron_fwaas/services/firewall/drivers/vyatta/vyatta_fwaas.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/24fe5bc02ba9c9b8e00964bde7c87cd92a51f155', 'message': 'vendor code should refer to Brocade\n\nCopyright text in vendor code should refer to Brocade\ninstead of OpenStack foundation\n\nChange-Id: I483f7d029c35e1d99105695ee7b62b1ad852c10e\nCloses-Bug: #1453708\n'}]",0,182687,24fe5bc02ba9c9b8e00964bde7c87cd92a51f155,20,11,1,14081,,,0,"vendor code should refer to Brocade

Copyright text in vendor code should refer to Brocade
instead of OpenStack foundation

Change-Id: I483f7d029c35e1d99105695ee7b62b1ad852c10e
Closes-Bug: #1453708
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/87/182687/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/services/firewall/agents/vyatta/vyatta_utils.py', 'neutron_fwaas/services/firewall/drivers/vyatta/vyatta_fwaas.py']",2,24fe5bc02ba9c9b8e00964bde7c87cd92a51f155,fix_copyright_text,"# Copyright 2015 Brocade Communications System, Inc.",# Copyright 2015 OpenStack Foundation.,2,2
openstack%2Fneutron-lbaas~master~I8f1d9ced2c919aa1d675253f78823c85a0b77b4c,openstack/neutron-lbaas,master,I8f1d9ced2c919aa1d675253f78823c85a0b77b4c,Updated from global requirements,MERGED,2015-05-07 23:33:04.000000000,2015-05-19 22:30:48.000000000,2015-05-19 22:30:48.000000000,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 9008}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 12040}, {'_account_id': 13438}]","[{'number': 1, 'created': '2015-05-07 23:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/ffdd34a015d7e7cdc2187de55e6adb279da69e33', 'message': 'Updated from global requirements\n\nChange-Id: I8f1d9ced2c919aa1d675253f78823c85a0b77b4c\n'}, {'number': 2, 'created': '2015-05-11 14:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/c300d6d75c45a6c687a5a15a5d05838f4d99e14e', 'message': 'Updated from global requirements\n\nChange-Id: I8f1d9ced2c919aa1d675253f78823c85a0b77b4c\n'}, {'number': 3, 'created': '2015-05-12 14:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/61b6371612c3bc8ae38e977a55ca7a66ecd36ac2', 'message': 'Updated from global requirements\n\nChange-Id: I8f1d9ced2c919aa1d675253f78823c85a0b77b4c\n'}, {'number': 4, 'created': '2015-05-14 22:45:26.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/715295bcc04ba21c595d8f95313259c7817fe32b', 'message': 'Updated from global requirements\n\nChange-Id: I8f1d9ced2c919aa1d675253f78823c85a0b77b4c\n'}]",0,181208,715295bcc04ba21c595d8f95313259c7817fe32b,28,7,4,11131,,,0,"Updated from global requirements

Change-Id: I8f1d9ced2c919aa1d675253f78823c85a0b77b4c
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/08/181208/4 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,ffdd34a015d7e7cdc2187de55e6adb279da69e33,openstack/requirements,"pbr>=0.11,<2.0","pbr>=0.6,!=0.7,<1.0",1,1
openstack%2Fapp-catalog~master~I144a6988d9f69b46a660c6c168cb0108cd4a2103,openstack/app-catalog,master,I144a6988d9f69b46a660c6c168cb0108cd4a2103,Add openSUSE 13.2 image,MERGED,2015-05-19 17:28:46.000000000,2015-05-19 22:19:16.000000000,2015-05-19 22:19:08.000000000,"[{'_account_id': 3}, {'_account_id': 4460}, {'_account_id': 6593}, {'_account_id': 7007}, {'_account_id': 7604}, {'_account_id': 9788}, {'_account_id': 16145}]","[{'number': 1, 'created': '2015-05-19 17:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/b87b843ca84b1aa728db315ae8e9812b1e0bab5e', 'message': 'Add openSUSE 13.2 image\n\nChange-Id: I144a6988d9f69b46a660c6c168cb0108cd4a2103\n'}, {'number': 2, 'created': '2015-05-19 19:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/2e21a18be949f3c40e2e7bc4d52cba318f489360', 'message': 'Add openSUSE 13.2 image\n\nImage-URL: http://download.opensuse.org/repositories/Cloud:/Images:/openSUSE_13.2/images/openSUSE-13.2-OpenStack-Guest.x86_64.qcow2\n\nChange-Id: I144a6988d9f69b46a660c6c168cb0108cd4a2103\n'}, {'number': 3, 'created': '2015-05-19 21:17:47.000000000', 'files': ['openstack_catalog/web/static/glance_images.yaml'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/8ff9c9ada350545abe5c3dcbfd6b85b4e846e75e', 'message': 'Add openSUSE 13.2 image\n\nImage-URL: http://download.opensuse.org/repositories/Cloud:/Images:/openSUSE_13.2/images/openSUSE-13.2-OpenStack-Guest.x86_64.qcow2\nImage-hash: Unknown\n\nChange-Id: I144a6988d9f69b46a660c6c168cb0108cd4a2103\n'}]",4,184300,8ff9c9ada350545abe5c3dcbfd6b85b4e846e75e,20,7,3,4460,,,0,"Add openSUSE 13.2 image

Image-URL: http://download.opensuse.org/repositories/Cloud:/Images:/openSUSE_13.2/images/openSUSE-13.2-OpenStack-Guest.x86_64.qcow2
Image-hash: Unknown

Change-Id: I144a6988d9f69b46a660c6c168cb0108cd4a2103
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/00/184300/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/web/static/glance_images.yaml'],1,b87b843ca84b1aa728db315ae8e9812b1e0bab5e,opensuse-13.2, - name: openSUSE 13.2 provided_by: name: openSUSE Project href: http://www.opensuse.org company: openSUSE Project Community description: Base openSUSE 13.2 with cloud-init format: QCOW2 attributes: url: http://download.opensuse.org/repositories/Cloud:/Images:/openSUSE_13.2/images/openSUSE-13.2-OpenStack-Guest.x86_64.qcow2 hash: unknown,,11,0
openstack%2Fswift~master~I2e0c814eed2b771a500e01275c7af549ab1ebaca,openstack/swift,master,I2e0c814eed2b771a500e01275c7af549ab1ebaca,Generate log warning messages when PUTs are smaller than segment size,ABANDONED,2015-05-19 22:07:05.000000000,2015-05-19 22:12:03.000000000,,[],"[{'number': 1, 'created': '2015-05-19 22:07:05.000000000', 'files': ['test/unit/proxy/controllers/test_obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e1f6d1a9fc8dd4be8ad9945564bcf803a29f0431', 'message': 'Generate log warning messages when PUTs are smaller than segment size\n\nAdded a warning message to notify when the PUT objects are smaller\nthan the given segment size in the EC Storage Policy.\n\nChange-Id: I2e0c814eed2b771a500e01275c7af549ab1ebaca\n'}]",0,184340,e1f6d1a9fc8dd4be8ad9945564bcf803a29f0431,2,0,1,15932,,,0,"Generate log warning messages when PUTs are smaller than segment size

Added a warning message to notify when the PUT objects are smaller
than the given segment size in the EC Storage Policy.

Change-Id: I2e0c814eed2b771a500e01275c7af549ab1ebaca
",git fetch https://review.opendev.org/openstack/swift refs/changes/40/184340/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/proxy/controllers/test_obj.py'],1,e1f6d1a9fc8dd4be8ad9945564bcf803a29f0431,,, segment_size = self.policy.ec_segment_size etag = md5(test_body).hexdigest() size = len(test_body),0,3
openstack%2Fnova-specs~master~I5f91e28f8d5d55397ba7d9f0c9881cce477a4e6b,openstack/nova-specs,master,I5f91e28f8d5d55397ba7d9f0c9881cce477a4e6b,Make backlog usable,MERGED,2015-05-13 19:09:34.000000000,2015-05-19 22:10:45.000000000,2015-05-19 22:10:43.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2271}]","[{'number': 1, 'created': '2015-05-13 19:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fe656bc2027d843404db11a2302430b7437351e6', 'message': 'Make backlog usable\n\n* Link to Liberty template\n* Add empty backlog/approved directory\n* Update backlog index\n\nChange-Id: I5f91e28f8d5d55397ba7d9f0c9881cce477a4e6b\n'}, {'number': 2, 'created': '2015-05-13 19:39:42.000000000', 'files': ['specs/backlog-template.rst', 'doc/source/specs/backlog/index.rst', 'doc/source/specs/backlog/approved', 'specs/backlog/approved/backlog-template.rst', 'doc/source/specs/backlog/template.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/58e465d2bf63a5380447733980be7a7682a21c86', 'message': 'Make backlog usable\n\n* Link to Liberty template\n* Add empty backlog/approved directory\n* Update backlog index\n* Since we cannot have an empty approved directory, link to\n  backlog-template for now.\n\nChange-Id: I5f91e28f8d5d55397ba7d9f0c9881cce477a4e6b\n'}]",0,182793,58e465d2bf63a5380447733980be7a7682a21c86,9,3,2,1849,,,0,"Make backlog usable

* Link to Liberty template
* Add empty backlog/approved directory
* Update backlog index
* Since we cannot have an empty approved directory, link to
  backlog-template for now.

Change-Id: I5f91e28f8d5d55397ba7d9f0c9881cce477a4e6b
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/93/182793/2 && git format-patch -1 --stdout FETCH_HEAD,"['specs/backlog-template.rst', 'doc/source/specs/backlog/index.rst', 'specs/backlog/approved/.placeholder', 'doc/source/specs/backlog/approved', 'doc/source/specs/backlog/template.rst']",5,fe656bc2027d843404db11a2302430b7437351e6,backlog,../../../../specs/backlog-template.rst,,13,3
openstack%2Ffuel-library~master~I2092cf2a8c7407b814abcef28e843cf2da84444e,openstack/fuel-library,master,I2092cf2a8c7407b814abcef28e843cf2da84444e,Add option to set Horizon memcache driver to correct template,MERGED,2015-05-19 11:45:40.000000000,2015-05-19 22:05:08.000000000,2015-05-19 22:04:31.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9546}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14007}, {'_account_id': 14525}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-19 11:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/94505a7d5ff67369694e46d71f4cdd5f2664517b', 'message': 'Add option to set horizon memcache driver to correct template\n\nChangeset Ice172b07fa765daff1a2e0feea7a5bee2f826b88 introduced changes\nto local_settings.py template not used during deployment. This commit\nreverts those and ports them to the template used in actual deployment.\n\nChange-Id: I2092cf2a8c7407b814abcef28e843cf2da84444e\nCloses-Bug: 1367767\n'}, {'number': 2, 'created': '2015-05-19 12:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c71a4ee54732564835617c6cd26d5d501d33d7f8', 'message': 'Add option to set Horizon memcache driver to correct template\n\nChangeset Ice172b07fa765daff1a2e0feea7a5bee2f826b88 introduced changes\nto local_settings.py template not used during deployment. This commit\nreverts those and ports them to the template used in actual deployment.\n\nAdditionally some of ERB tags were not substituted correctly, resulting\nin broken Horizon config.\n\nChange-Id: I2092cf2a8c7407b814abcef28e843cf2da84444e\nCloses-Bug: 1367767\n'}, {'number': 3, 'created': '2015-05-19 14:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/06fe6ad7c1a2d8d85d0fc0a9163cdf034db5e797', 'message': 'Add option to set Horizon memcache driver to correct template\n\nChangeset Ice172b07fa765daff1a2e0feea7a5bee2f826b88 introduced changes\nto local_settings.py template not used during deployment. This commit\nreverts those and ports them to the template used in actual deployment.\n\nAdditionally some of ERB tags were not substituted or iterated correctly,\nresulting in broken Horizon config.\n\nChange-Id: I2092cf2a8c7407b814abcef28e843cf2da84444e\nCloses-Bug: 1367767\n'}, {'number': 4, 'created': '2015-05-19 15:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/065cdc4d39d0d5373e9b412d148d27fe167c6724', 'message': 'Add option to set Horizon memcache driver to correct template\n\nChangeset Ice172b07fa765daff1a2e0feea7a5bee2f826b88 introduced changes\nto local_settings.py template not used during deployment. This commit\nreverts those and ports them to the template used in actual deployment.\n\nAdditionally some of ERB tags were not substituted or iterated correctly,\nresulting in broken Horizon config.\n\nChange-Id: I2092cf2a8c7407b814abcef28e843cf2da84444e\nCloses-Bug: 1367767\n'}, {'number': 5, 'created': '2015-05-19 18:18:13.000000000', 'files': ['deployment/puppet/horizon/templates/local_settings.py.erb', 'deployment/puppet/openstack/templates/horizon/local_settings.py.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cf58ee929dc6941e69fc8dcf85f19c38754daa80', 'message': 'Add option to set Horizon memcache driver to correct template\n\nChangeset Ice172b07fa765daff1a2e0feea7a5bee2f826b88 introduced changes\nto local_settings.py template not used during deployment. This commit\nreverts those and ports them to the template used in actual deployment.\n\nAdditionally some of ERB tags were not substituted or iterated correctly,\nresulting in broken Horizon config.\n\nChange-Id: I2092cf2a8c7407b814abcef28e843cf2da84444e\nCloses-Bug: 1367767\n'}]",2,184227,cf58ee929dc6941e69fc8dcf85f19c38754daa80,115,17,5,13948,,,0,"Add option to set Horizon memcache driver to correct template

Changeset Ice172b07fa765daff1a2e0feea7a5bee2f826b88 introduced changes
to local_settings.py template not used during deployment. This commit
reverts those and ports them to the template used in actual deployment.

Additionally some of ERB tags were not substituted or iterated correctly,
resulting in broken Horizon config.

Change-Id: I2092cf2a8c7407b814abcef28e843cf2da84444e
Closes-Bug: 1367767
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/27/184227/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/horizon/templates/local_settings.py.erb', 'deployment/puppet/openstack/templates/horizon/local_settings.py.erb']",2,94505a7d5ff67369694e46d71f4cdd5f2664517b,bug/1367767," <% if @cache_server_ip %> <% if @cache_options and @cache_options.kind_of?(Array) %> OPTIONS : { <% @cache_options.join(',') %> } <% end %> 'BACKEND': <% @cache_backend %>"," <% if @cache_server_ip %> # 'BACKEND': 'django.core.cache.backends.locmem.LocMemCache' 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',",10,9
openstack%2Frequirements~master~I109f3726fff27de2b61bc3423615207c12bb0af2,openstack/requirements,master,I109f3726fff27de2b61bc3423615207c12bb0af2,Add mysqlclient dependency,ABANDONED,2015-05-04 09:52:19.000000000,2015-05-19 22:01:38.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 6476}, {'_account_id': 9107}, {'_account_id': 11343}, {'_account_id': 11816}, {'_account_id': 14027}]","[{'number': 1, 'created': '2015-05-04 09:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/85e62af28d79d59a826bf5fdacf67517b3ede2c9', 'message': 'Add mysqlclient dependency\n\nmysqlclient is a MySQL driver supporting Python 2 and Python 3.\n\nmysqlclient is a fork of MySQL-python. It was created by INADA Naoki,\nwho is also the author of PyMySQL (a pure Python driver for MySQL).\nmysqlclient adds Python 3 support, some new features and various\nbugfixes.\n\nmysqlclient and MySQL-python are exclusive, they cannot be used at the\nsame time (with the same Python version), since both packages provide\nthe same Python module (""MySQLdb""). An application can use MySQL-python\non Python 2 and mysqlclient on Python 3, or mysqlclient on Python 2 and\nPython 3.\n\nmysqlclient is distributed under the same license than MySQL-Python: GNU\nGPL.\n\nChange-Id: I109f3726fff27de2b61bc3423615207c12bb0af2\n'}, {'number': 2, 'created': '2015-05-04 14:58:50.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/366f3d30003e50fbd0c7547c402873b75dd57b70', 'message': 'Add mysqlclient dependency\n\nmysqlclient is a MySQL driver supporting Python 2 and Python 3.\n\nmysqlclient is a fork of MySQL-python. It was created by INADA Naoki,\nwho is also the author of PyMySQL (a pure Python driver for MySQL).\nmysqlclient adds Python 3 support, some new features and various\nbugfixes.\n\nmysqlclient and MySQL-python are exclusive, they cannot be used at the\nsame time (with the same Python version), since both packages provide\nthe same Python module (""MySQLdb""). An application can use MySQL-python\non Python 2 and mysqlclient on Python 3, or mysqlclient on Python 2 and\nPython 3.\n\nmysqlclient is distributed under the same license than MySQL-Python: GNU\nGPL.\n\nAdd also the license of MySQL-python which was missing.\n\nChange-Id: I109f3726fff27de2b61bc3423615207c12bb0af2\n'}]",1,179745,366f3d30003e50fbd0c7547c402873b75dd57b70,19,7,2,9107,,,0,"Add mysqlclient dependency

mysqlclient is a MySQL driver supporting Python 2 and Python 3.

mysqlclient is a fork of MySQL-python. It was created by INADA Naoki,
who is also the author of PyMySQL (a pure Python driver for MySQL).
mysqlclient adds Python 3 support, some new features and various
bugfixes.

mysqlclient and MySQL-python are exclusive, they cannot be used at the
same time (with the same Python version), since both packages provide
the same Python module (""MySQLdb""). An application can use MySQL-python
on Python 2 and mysqlclient on Python 3, or mysqlclient on Python 2 and
Python 3.

mysqlclient is distributed under the same license than MySQL-Python: GNU
GPL.

Add also the license of MySQL-python which was missing.

Change-Id: I109f3726fff27de2b61bc3423615207c12bb0af2
",git fetch https://review.opendev.org/openstack/requirements refs/changes/45/179745/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,85e62af28d79d59a826bf5fdacf67517b3ede2c9,mysqlclient,mysqlclient,,1,0
openstack%2Fopenstack-manuals~master~Id08854dd3b51ce23b00f5012c111a1b1589c1b25,openstack/openstack-manuals,master,Id08854dd3b51ce23b00f5012c111a1b1589c1b25,Rename nova-xvnvncproxy file,MERGED,2015-05-18 11:31:24.000000000,2015-05-19 21:46:50.000000000,2015-05-19 21:46:47.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6732}, {'_account_id': 7923}, {'_account_id': 10705}]","[{'number': 1, 'created': '2015-05-18 11:31:24.000000000', 'files': ['doc/common/tables/nova-xvpvncproxy.xml', 'tools/autogenerate-config-flagmappings/nova.flagmappings', 'doc/config-reference/compute/section_compute-options-reference.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/86f5abbd7b2d9db8969ebf1a7e7a96adba937372', 'message': 'Rename nova-xvnvncproxy file\n\nThe proper name is nova-xvpvncproxy.xml, rename it.\n\nChange-Id: Id08854dd3b51ce23b00f5012c111a1b1589c1b25\nRelated-Bug: #1456098\n'}]",0,184025,86f5abbd7b2d9db8969ebf1a7e7a96adba937372,13,5,1,6547,,,0,"Rename nova-xvnvncproxy file

The proper name is nova-xvpvncproxy.xml, rename it.

Change-Id: Id08854dd3b51ce23b00f5012c111a1b1589c1b25
Related-Bug: #1456098
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/25/184025/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/tables/nova-xvpvncproxy.xml', 'tools/autogenerate-config-flagmappings/nova.flagmappings', 'doc/config-reference/compute/section_compute-options-reference.xml']",3,86f5abbd7b2d9db8969ebf1a7e7a96adba937372,bug/1456098," <xi:include href=""../../common/tables/nova-xvpvncproxy.xml""/>"," <xi:include href=""../../common/tables/nova-xvpnvncproxy.xml""/>",4,4
openstack%2Fec2-api~master~I0e090f1d8dca70235615242f8993081c71ae6615,openstack/ec2-api,master,I0e090f1d8dca70235615242f8993081c71ae6615,Implement customer gateway,MERGED,2015-05-16 09:37:22.000000000,2015-05-19 21:39:28.000000000,2015-05-19 21:39:25.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-05-16 09:37:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/dbcb2c7effb2cfb35d64861b84c77510887fedc2', 'message': 'Implement customer gateway\n\nChange-Id: I0e090f1d8dca70235615242f8993081c71ae6615\n'}, {'number': 2, 'created': '2015-05-16 09:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/cc00b9ac749b6a41f2e0627b228fb8e7e1628978', 'message': 'Implement customer gateway\n\nChange-Id: I0e090f1d8dca70235615242f8993081c71ae6615\n'}, {'number': 3, 'created': '2015-05-16 12:35:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/9eafbd9b7294339bb5fa42d6dac4938e86979a11', 'message': 'Implement customer gateway\n\nChange-Id: I0e090f1d8dca70235615242f8993081c71ae6615\n'}, {'number': 4, 'created': '2015-05-16 14:29:43.000000000', 'files': ['ec2api/tests/unit/test_ec2utils.py', 'ec2api/api/validator.py', 'ec2api/api/cloud.py', 'ec2api/tests/unit/test_ec2_validate.py', 'ec2api/api/common.py', 'ec2api/tests/unit/fakes.py', 'ec2api/api/ec2utils.py', 'ec2api/exception.py', 'ec2api/tests/unit/test_customer_gateway.py', 'ec2api/api/customer_gateway.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/54690d10956781254f981f939087b33a5f4a969f', 'message': 'Implement customer gateway\n\nChange-Id: I0e090f1d8dca70235615242f8993081c71ae6615\n'}]",0,183784,54690d10956781254f981f939087b33a5f4a969f,13,4,4,10224,,,0,"Implement customer gateway

Change-Id: I0e090f1d8dca70235615242f8993081c71ae6615
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/84/183784/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/unit/test_ec2utils.py', 'ec2api/api/validator.py', 'ec2api/api/cloud.py', 'ec2api/api/common.py', 'ec2api/tests/unit/fakes.py', 'ec2api/api/ec2utils.py', 'ec2api/exception.py', 'ec2api/tests/unit/test_customer_gateway.py', 'ec2api/api/customer_gateway.py']",9,dbcb2c7effb2cfb35d64861b84c77510887fedc2,vpn,"# Copyright 2014 # The Cloudscaling Group, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from ec2api.api import common from ec2api.api import ec2utils from ec2api.db import api as db_api from ec2api import exception from ec2api.i18n import _ Validator = common.Validator DEFAULT_BGP_ASN = 65000 def create_customer_gateway(context, ip_address, type, bgp_asn=None): if bgp_asn and bgp_asn != DEFAULT_BGP_ASN: raise exception.Unsupported(""BGP dynamic routing is unsupported"") cgw = next((cgw for cgw in db_api.get_items(context, 'cgw') if cgw['ip_address'] == ip_address), None) if not cgw: cgw = db_api.add_item(context, 'cgw', {'ip_address': ip_address}) return {'customerGateway': _format_customer_gateway(cgw)} def delete_customer_gateway(context, customer_gateway_id): cgw = ec2utils.get_db_item(context, customer_gateway_id) vpn_connections = db_api.get_items(context, 'vpn') if any(vpn['customer_gateway_id'] == cgw['id'] for vpn in vpn_connections): raise exception.IncorrectState( reason=_('The customer gateway is in use.')) db_api.delete_item(context, cgw['id']) return True def describe_customer_gateways(context, customer_gateway_id=None, filter=None): formatted_cgws = CustomerGatewayDescriber().describe( context, ids=customer_gateway_id, filter=filter) return {'customerGatewaySet': formatted_cgws} class CustomerGatewayDescriber(common.TaggableItemsDescriber, common.NonOpenstackItemsDescriber): KIND = 'cgw' FILTER_MAP = {'bgp-asn': 'bgpAsn', 'customer-gateway-id': 'customerGatewayId', 'ip-address': 'ipAddress', 'state': 'state', 'type': 'type'} def format(self, cgw): return _format_customer_gateway(cgw) def _format_customer_gateway(cgw): return {'customerGatewayId': cgw['id'], 'ipAddress': cgw['ip_address'], 'state': 'available', 'type': 'ipsec.1', 'bgpAsn': DEFAULT_BGP_ASN} ",,318,1
openstack%2Fneutron~master~I467db0d48e4b82fdaad8d851e294e639a84a8160,openstack/neutron,master,I467db0d48e4b82fdaad8d851e294e639a84a8160,Add unit tests for ML2 DVR port binding and fix PortContext inconsistencies,MERGED,2015-05-12 01:11:09.000000000,2015-05-19 21:38:44.000000000,2015-05-19 21:38:41.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5217}, {'_account_id': 6524}, {'_account_id': 6558}, {'_account_id': 6694}, {'_account_id': 6697}, {'_account_id': 6854}, {'_account_id': 7018}, {'_account_id': 7962}, {'_account_id': 8645}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 15296}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-05-12 01:11:09.000000000', 'files': ['neutron/plugins/ml2/rpc.py', 'neutron/plugins/ml2/driver_context.py', 'neutron/tests/unit/plugins/ml2/_test_mech_agent.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/tests/unit/plugins/ml2/drivers/mechanism_logger.py', 'neutron/tests/unit/plugins/ml2/test_port_binding.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/plugins/ml2/drivers/mechanism_test.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/922dae45d0a223f9256bdff1faa65d469cbc9275', 'message': 'Add unit tests for ML2 DVR port binding and fix PortContext inconsistencies\n\nExtends the existing ML2 port binding unit tests to cover the\ndistributed port bindings used for DVR. Within the test mechanism\ndriver, bindings are tracked per-host, and additional assertions are\nadded.\n\nFixes issues with PortContext attributes that were exposed by these\nnew tests. Adds new vif_type, original_vif_type, vif_details, and\noriginal_vif_details PortContext attributes, similar to the exising\nhost, original_host, status, and original_status attributes, to\nreflect host-specific details of distributed (or normal) port\nbindings. Also fixes original_host and original_status to return None\nwhen in the context of an operation other than an update, and fixes\noriginal_host to reflect the specific host being bound for a\ndistributed port.\n\nCloses-bug: 1453943\nCloses-bug: 1453955\nChange-Id: I467db0d48e4b82fdaad8d851e294e639a84a8160\n'}]",0,182134,922dae45d0a223f9256bdff1faa65d469cbc9275,36,34,1,1689,,,0,"Add unit tests for ML2 DVR port binding and fix PortContext inconsistencies

Extends the existing ML2 port binding unit tests to cover the
distributed port bindings used for DVR. Within the test mechanism
driver, bindings are tracked per-host, and additional assertions are
added.

Fixes issues with PortContext attributes that were exposed by these
new tests. Adds new vif_type, original_vif_type, vif_details, and
original_vif_details PortContext attributes, similar to the exising
host, original_host, status, and original_status attributes, to
reflect host-specific details of distributed (or normal) port
bindings. Also fixes original_host and original_status to return None
when in the context of an operation other than an update, and fixes
original_host to reflect the specific host being bound for a
distributed port.

Closes-bug: 1453943
Closes-bug: 1453955
Change-Id: I467db0d48e4b82fdaad8d851e294e639a84a8160
",git fetch https://review.opendev.org/openstack/neutron refs/changes/34/182134/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/rpc.py', 'neutron/plugins/ml2/driver_context.py', 'neutron/tests/unit/plugins/ml2/_test_mech_agent.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/tests/unit/plugins/ml2/drivers/mechanism_logger.py', 'neutron/tests/unit/plugins/ml2/test_port_binding.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/plugins/ml2/drivers/mechanism_test.py']",8,922dae45d0a223f9256bdff1faa65d469cbc9275,bug/1453943," self._check_port_info(context.current, context.host, context.vif_type, context.vif_details) if context.vif_type in (portbindings.VIF_TYPE_UNBOUND, portbindings.VIF_TYPE_BINDING_FAILED): assert((context.current['id'], context.host) not in self.bound_ports) assert((context.current['id'], context.host) in self.bound_ports) self._check_port_info(context.original, context.original_host, context.original_vif_type, context.original_vif_details) if (context.original_vif_type in (portbindings.VIF_TYPE_UNBOUND, portbindings.VIF_TYPE_BINDING_FAILED)): assert(context.original_host is None) assert(context.original_vif_type is None) assert(context.original_vif_details is None) assert(context.original_status is None) def _check_port_info(self, port, host, vif_type, vif_details): assert(isinstance(port, dict)) assert(port['id'] is not None) assert(vif_type in (portbindings.VIF_TYPE_UNBOUND, portbindings.VIF_TYPE_BINDING_FAILED, portbindings.VIF_TYPE_DISTRIBUTED, portbindings.VIF_TYPE_OVS, portbindings.VIF_TYPE_BRIDGE)) if port['device_owner'] == const.DEVICE_OWNER_DVR_INTERFACE: assert(port[portbindings.HOST_ID] == '') assert(port[portbindings.VIF_TYPE] == portbindings.VIF_TYPE_DISTRIBUTED) assert(port[portbindings.VIF_DETAILS] == {}) else: assert(port[portbindings.HOST_ID] == host) assert(port[portbindings.VIF_TYPE] != portbindings.VIF_TYPE_DISTRIBUTED) assert(port[portbindings.VIF_TYPE] == vif_type) assert(isinstance(vif_details, dict)) assert(port[portbindings.VIF_DETAILS] == vif_details) self.bound_ports.remove((context.original['id'], context.original_host)) self.bound_ports.add((context.current['id'], host)) self.bound_ports.add((context.current['id'], host)) self.bound_ports.add((context.current['id'], host)) self.bound_ports.add((context.current['id'], host))"," assert(isinstance(context.current, dict)) assert(context.current['id'] is not None) vif_type = context.current.get(portbindings.VIF_TYPE) assert(vif_type is not None) if vif_type in (portbindings.VIF_TYPE_UNBOUND, portbindings.VIF_TYPE_BINDING_FAILED): assert(context.current['id'] not in self.bound_ports) assert(context.current['id'] in self.bound_ports) assert(isinstance(context.original, dict)) vif_type = context.original.get(portbindings.VIF_TYPE) assert(vif_type is not None) if vif_type in (portbindings.VIF_TYPE_UNBOUND, portbindings.VIF_TYPE_BINDING_FAILED): self.bound_ports.remove(context.original['id']) self.bound_ports.add(context.current['id']) self.bound_ports.add(context.current['id']) self.bound_ports.add(context.current['id']) self.bound_ports.add(context.current['id'])",308,29
openstack%2Fdevstack-gate~master~I2280d300caf78a09261ce81b9dd2ff83cc5d7b9f,openstack/devstack-gate,master,I2280d300caf78a09261ce81b9dd2ff83cc5d7b9f,Add Heat to features.yaml,MERGED,2015-05-14 17:40:33.000000000,2015-05-19 21:38:22.000000000,2015-05-19 21:38:21.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4220}, {'_account_id': 6786}]","[{'number': 1, 'created': '2015-05-14 17:40:33.000000000', 'files': ['features.yaml'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f90ba507c0e4b615c83e8a8ae62e135dd1c7dcc5', 'message': 'Add Heat to features.yaml\n\nThe Heat service was not enabled in features.yaml leading to the\ntempest-dsvm-heat job skipping all the tests.\n\nChange-Id: I2280d300caf78a09261ce81b9dd2ff83cc5d7b9f\nCloses-Bug: #1455169\n'}]",0,183126,f90ba507c0e4b615c83e8a8ae62e135dd1c7dcc5,9,4,1,6899,,,0,"Add Heat to features.yaml

The Heat service was not enabled in features.yaml leading to the
tempest-dsvm-heat job skipping all the tests.

Change-Id: I2280d300caf78a09261ce81b9dd2ff83cc5d7b9f
Closes-Bug: #1455169
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/26/183126/1 && git format-patch -1 --stdout FETCH_HEAD,['features.yaml'],1,f90ba507c0e4b615c83e8a8ae62e135dd1c7dcc5,, heat: features: [heat],,2,0
openstack%2Fhacking~master~Ia3d31f1ad9a89d03300dd98bd983db2922e5453f,openstack/hacking,master,Ia3d31f1ad9a89d03300dd98bd983db2922e5453f,Fix a typo,MERGED,2015-05-19 21:24:11.000000000,2015-05-19 21:35:20.000000000,2015-05-19 21:35:19.000000000,"[{'_account_id': 3}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-19 21:24:11.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/hacking/commit/12938a13c59e3b4bb99aa69b86579de41b3ac1d0', 'message': 'Fix a typo\n\nprefered => preferred\n\nChange-Id: Ia3d31f1ad9a89d03300dd98bd983db2922e5453f\n'}]",0,184331,12938a13c59e3b4bb99aa69b86579de41b3ac1d0,6,2,1,1849,,,0,"Fix a typo

prefered => preferred

Change-Id: Ia3d31f1ad9a89d03300dd98bd983db2922e5453f
",git fetch https://review.opendev.org/openstack/hacking refs/changes/31/184331/1 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,12938a13c59e3b4bb99aa69b86579de41b3ac1d0,docs,- It is preferred to wrap long lines in parentheses and not a backslash,- It is prefered to wrap long lines in parentheses and not a backslash,1,1
openstack%2Frequirements~master~I42eee53513c51778447df4c8d89fd1c725da45fa,openstack/requirements,master,I42eee53513c51778447df4c8d89fd1c725da45fa,Add sphinxcontrib-blockdiag,MERGED,2015-05-13 23:21:15.000000000,2015-05-19 21:31:49.000000000,2015-05-19 21:31:47.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 6476}, {'_account_id': 6786}]","[{'number': 1, 'created': '2015-05-13 23:21:15.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e58494ed960455a5fa056a30169b1a91c2d8265d', 'message': 'Add sphinxcontrib-blockdiag\n\nThis has the potential of allowing architecture diagrams being written\nin markup and automatically transformed to images.\n\nsphinxcontrib-seqdiag from the same parent project is already a dependency\nso adding blockdiag should not be controversial.\n\nChange-Id: I42eee53513c51778447df4c8d89fd1c725da45fa\n'}]",0,182880,e58494ed960455a5fa056a30169b1a91c2d8265d,11,5,1,4571,,,0,"Add sphinxcontrib-blockdiag

This has the potential of allowing architecture diagrams being written
in markup and automatically transformed to images.

sphinxcontrib-seqdiag from the same parent project is already a dependency
so adding blockdiag should not be controversial.

Change-Id: I42eee53513c51778447df4c8d89fd1c725da45fa
",git fetch https://review.opendev.org/openstack/requirements refs/changes/80/182880/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,e58494ed960455a5fa056a30169b1a91c2d8265d,blockdiag,sphinxcontrib-blockdiag,,1,0
openstack%2Fbarbican~master~If5433f6fd5b295e5e758a75ea2eac3892e78e681,openstack/barbican,master,If5433f6fd5b295e5e758a75ea2eac3892e78e681,Move policy options to the oslo_policy group in the config,MERGED,2015-05-19 18:04:26.000000000,2015-05-19 21:29:07.000000000,2015-05-19 21:29:07.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-05-19 18:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/91c633724f9002af8da4e63e89d3472686a2bf77', 'message': 'Move policy options to the oslo_policy group in the config\n\nHaving the policy-related options in the DEFAULT section in the config\nhas been deprecated in favor of having an oslo_policy group. This CR\neffectively changes that in the configuration we give as an example.\n\nChange-Id: If5433f6fd5b295e5e758a75ea2eac3892e78e681\n'}, {'number': 2, 'created': '2015-05-19 18:07:15.000000000', 'files': ['etc/barbican/barbican-api.conf'], 'web_link': 'https://opendev.org/openstack/barbican/commit/afde0a52b0e0ef0547fc84d8830d12287075d77e', 'message': 'Move policy options to the oslo_policy group in the config\n\nHaving the policy-related options in the DEFAULT section in the config\nhas been deprecated in favor of having an oslo_policy group. This CR\neffectively changes that in the configuration we give as an example.\n\nChange-Id: If5433f6fd5b295e5e758a75ea2eac3892e78e681\n'}]",1,184302,afde0a52b0e0ef0547fc84d8830d12287075d77e,11,13,2,10873,,,0,"Move policy options to the oslo_policy group in the config

Having the policy-related options in the DEFAULT section in the config
has been deprecated in favor of having an oslo_policy group. This CR
effectively changes that in the configuration we give as an example.

Change-Id: If5433f6fd5b295e5e758a75ea2eac3892e78e681
",git fetch https://review.opendev.org/openstack/barbican refs/changes/02/184302/2 && git format-patch -1 --stdout FETCH_HEAD,['etc/barbican/barbican-api.conf'],1,91c633724f9002af8da4e63e89d3472686a2bf77,policy_conf,# ======== OpenStack policy =============== [oslo_policy] # ======== OpenStack policy integration # JSON file representing policy (string value) policy_file=/etc/barbican/policy.json # Rule checked when requested rule is not found (string value) policy_default_rule=default ,"# Accepts a class imported from the sqlalchemy.pool module, and handles the # details of building the pool for you. If commented out, SQLAlchemy # will select based on the database dialect. Other options are QueuePool # (for SQLAlchemy-managed connections) and NullPool (to disabled SQLAlchemy # management of connections). # See http://docs.sqlalchemy.org/en/latest/core/pooling.html for more details. #sql_pool_class = QueuePool # Show SQLAlchemy pool-related debugging output in logs (sets DEBUG log level # output) if specified. #sql_pool_logging = True # Size of pool used by SQLAlchemy. This is the largest number of connections # that will be kept persistently in the pool. Can be set to 0 to indicate no # size limit. To disable pooling, use a NullPool with sql_pool_class instead. # Comment out to allow SQLAlchemy to select the default. #sql_pool_size = 5 # The maximum overflow size of the pool used by SQLAlchemy. When the number of # checked-out connections reaches the size set in sql_pool_size, additional # connections will be returned up to this limit. It follows then that the # total number of simultaneous connections the pool will allow is # sql_pool_size + sql_pool_max_overflow. Can be set to -1 to indicate no # overflow limit, so no limit will be placed on the total number of concurrent # connections. Comment out to allow SQLAlchemy to select the default. #sql_pool_max_overflow = 10 # ======== OpenStack policy integration # JSON file representing policy (string value) policy_file=/etc/barbican/policy.json # Rule checked when requested rule is not found (string value) policy_default_rule=default ",11,35
openstack%2Fheat-specs~master~I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43,openstack/heat-specs,master,I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43,Spec for Add lock and unlock stack actions.,MERGED,2015-04-08 19:17:29.000000000,2015-05-19 21:24:01.000000000,2015-05-19 21:24:00.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7193}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 9408}, {'_account_id': 9542}, {'_account_id': 10068}, {'_account_id': 10487}, {'_account_id': 12259}, {'_account_id': 12606}, {'_account_id': 15353}, {'_account_id': 15881}, {'_account_id': 16002}, {'_account_id': 16358}]","[{'number': 1, 'created': '2015-04-08 19:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/440050613dd9fe14ba3cc3850a1f484fcbaec86e', 'message': 'Spec for Add lock and unlock stack actions.\nWhile stack is locked heat will not allow any actions on the stack to\ntake place, and will ignore signals that invoke actions such as scaling.\nAPIImpact\n\nChange-Id: I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43\n'}, {'number': 2, 'created': '2015-04-16 15:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/e6f46e64f42afd7903bbec647e2e0d2739b3a64e', 'message': 'Spec for Add lock and unlock stack actions.\n\nWhile stack is locked heat will not allow any actions on the stack to\ntake place, and will ignore signals that invoke actions such as scaling.\n\nblueprint lock-stack\n\nAPIImpact\nDocImpact\n\nChange-Id: I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43\n'}, {'number': 3, 'created': '2015-04-16 15:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/4b87b44f00ab8d2c7fd483d9a1f568540cc98989', 'message': 'Spec for Add lock and unlock stack actions.\n\nWhile stack is locked heat will not allow any actions on the stack to\ntake place, and will ignore signals that invoke actions such as scaling.\n\nblueprint lock-stack\n\nAPIImpact\nDocImpact\n\nChange-Id: I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43\n'}, {'number': 4, 'created': '2015-04-16 15:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/e9bff67cec334d4e09ff8268f3028e017b595492', 'message': 'Spec for Add lock and unlock stack actions.\n\nWhile stack is locked heat will not allow any actions on the stack to\ntake place, and will ignore signals that invoke actions such as scaling.\n\nblueprint lock-stack\n\nAPIImpact\nDocImpact\n\nChange-Id: I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43\n'}, {'number': 5, 'created': '2015-04-20 14:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/9c3477f4e686809420221b7eb677d868d9e218b5', 'message': 'Spec for Add lock and unlock stack actions.\n\nWhile stack is locked heat will not allow any actions on the stack to\ntake place, and will ignore signals that invoke actions such as scaling.\n\nblueprint lock-stack\n\nAPIImpact\nDocImpact\n\nChange-Id: I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43\n'}, {'number': 6, 'created': '2015-04-20 14:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/b33d95ea3115abd45a5048208ec2026830700b8f', 'message': 'Spec for Add lock and unlock stack actions.\n\nWhile stack is locked heat will not allow any actions on the stack to\ntake place, and will ignore signals that invoke actions such as scaling.\n\nblueprint lock-stack\n\nAPIImpact\nDocImpact\n\nChange-Id: I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43\n'}, {'number': 7, 'created': '2015-05-12 12:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/2b74ae7d282205b8dd0bab2f43eb54a0e6575400', 'message': 'Spec for Add lock and unlock stack actions.\n\nWhile stack is locked heat will not allow any actions on the stack to\ntake place, and will ignore signals that invoke actions such as scaling.\n\nblueprint lock-stack\n\nAPIImpact\nDocImpact\n\nChange-Id: I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43\n'}, {'number': 8, 'created': '2015-05-12 15:22:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/40a77268a8298352daeb830ac76f54205cddeae1', 'message': 'Spec for Add lock and unlock stack actions.\n\nWhile stack is locked heat will not allow any actions on the stack to\ntake place, and will ignore signals that invoke actions such as scaling.\n\nblueprint lock-stack\n\nAPIImpact\nDocImpact\n\nChange-Id: I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43\n'}, {'number': 9, 'created': '2015-05-13 07:14:36.000000000', 'files': ['specs/liberty/lock-stack.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/a88dfc528eca0d580722ebef71ffb1edbec58d56', 'message': 'Spec for Add lock and unlock stack actions.\n\nWhile stack is locked heat will not allow any actions on the stack to\ntake place, and will ignore signals that invoke actions such as scaling.\n\nblueprint lock-stack\n\nAPIImpact\nDocImpact\n\nChange-Id: I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43\n'}]",36,171781,a88dfc528eca0d580722ebef71ffb1edbec58d56,60,17,9,15353,,,0,"Spec for Add lock and unlock stack actions.

While stack is locked heat will not allow any actions on the stack to
take place, and will ignore signals that invoke actions such as scaling.

blueprint lock-stack

APIImpact
DocImpact

Change-Id: I3ecad2e61deb2f7f6b69b3fcc5a948614c446b43
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/81/171781/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/lock-stack.rst'],1,440050613dd9fe14ba3cc3850a1f484fcbaec86e,bp/lock-stack,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. =================================== Add lock and unlock stack actions =================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/heat/+spec/lock-stack Introduction paragraph -- why are we doing anything? Problem description =================== use cases: 1. application vendors are interested in a ""maintenance mode"" for their application. When in maintenance no topology changes are permitted. For example a maintenance mode is required for a clustered DB app that needs a manual reboot of one of its servers - when the server reboots all the other servers are redistributing the data among themselves which causes high CPU levels which in turn might cause an undesired scale out (which will cause another CPU spike and so on...). 2. some cloud-admins have a configuration stack that initializes the cloud (Creating networks, flavors, images, ...) and these resources should always exist while the cloud exists. Locking these configuration stacks, ill prevent someone from accidentally deleting/modifying the stack or its resources. This feature might even raise in significance, once convergence phase 2 is in place, and many other automatic actions are performed by heat. The ability to manually perform admin actions on the stack with no interruptions is important. Proposed change =============== The proposal is to add a ""Lock"" operation to be performed on the stack. Similar to: nova server ""lock"" or glance-image ""--is-protected"" flag. Once a stack is locked, the only operation allowed on the stack is ""unlock"" - heat engine should reject any stack operations and ignore signals that modify the stack (such as scaling). This API calls would be additional to the stack-actions API, of 'lock' and 'unlock'. The lock operation should have a ""lock_resources"" flag (default = True): when False: perform heat lock - which would lock the stack and all nested stacks (actions on resources will not be effected). When True: perform heat lock and enable lock/protect for each stack resource that supports it (nova server, glance image,...). Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: noa-koffman moshe-elisha-alu avi-vachnis Milestones ---------- Target Milestone for completion: liberty-1 Work Items ---------- - Support 'lock' and 'unlock' actions in stack-action API. - Develop a lock stack logic in heat which prevents stack actions (suspend/resume), update-stack, auto-scaling,..., from taking place. - Heat should call a lock/protect method for each stack resource that belongs to the stack. Dependencies ============ None ",,87,0
openstack%2Fhacking~0.9.x~I77f2b7e661c4de067e39596765d36a4463a2d143,openstack/hacking,0.9.x,I77f2b7e661c4de067e39596765d36a4463a2d143,Bump pbr cap to <2.0,MERGED,2015-05-19 11:05:28.000000000,2015-05-19 21:17:55.000000000,2015-05-19 21:17:54.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6547}, {'_account_id': 6873}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-19 11:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/hacking/commit/0a5263f3382f076bc7d977f5b8b584d00b8e2d3a', 'message': ""Bump pbr cap to <2.0\n\nHacking's pbr cap of <1.0 is breaking things (see bug for a lot more\ndetail). Trunk hacking has already moved to the new pbr cap, but it\nthere is a backwards incompatible change on trunk\n(I819d2069f169cabd1fcf333057a80790678e3745) that prevents us from\nreleasing 0.10.2 from there. So I created a 0.10.x branch and am\nchanging the pbr requirement here so that we can cut hacking 0.10.2 to\nfix the bug.\n\nChange-Id: I77f2b7e661c4de067e39596765d36a4463a2d143\nCloses-Bug: #1456376\n(cherry picked from commit bc4b1118e155784bc306c01733375ffec56b89b3)\n""}, {'number': 2, 'created': '2015-05-19 13:42:05.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/hacking/commit/f63394c9a427bdad21bf219135eeb030c2e01145', 'message': ""Bump pbr cap to <2.0\n\nHacking's pbr cap of <1.0 is breaking things (see bug for a lot more\ndetail). Since projects are still using hacking 0.9.x bump the PBR cap\nto unbreak projects still on 0.9.x.\n\nChange-Id: I77f2b7e661c4de067e39596765d36a4463a2d143\nCloses-Bug: #1456376\n(cherry picked from commit bc4b1118e155784bc306c01733375ffec56b89b3)\n""}]",0,184224,f63394c9a427bdad21bf219135eeb030c2e01145,12,5,2,1849,,,0,"Bump pbr cap to <2.0

Hacking's pbr cap of <1.0 is breaking things (see bug for a lot more
detail). Since projects are still using hacking 0.9.x bump the PBR cap
to unbreak projects still on 0.9.x.

Change-Id: I77f2b7e661c4de067e39596765d36a4463a2d143
Closes-Bug: #1456376
(cherry picked from commit bc4b1118e155784bc306c01733375ffec56b89b3)
",git fetch https://review.opendev.org/openstack/hacking refs/changes/24/184224/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,0a5263f3382f076bc7d977f5b8b584d00b8e2d3a,bug/1456376,"pbr>=0.11,<2.0","pbr>=0.6,!=0.7,<1.0",1,1
openstack%2Ffuel-library~master~Iaf159736d68774bd8b785af7078d4e9f17b1a30c,openstack/fuel-library,master,Iaf159736d68774bd8b785af7078d4e9f17b1a30c,Add timeout to restore,MERGED,2015-05-18 16:20:44.000000000,2015-05-19 20:45:26.000000000,2015-05-19 20:44:49.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-18 16:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3fb4410a15484f01db507dc8103aad6534f05db2', 'message': 'Add timeout to restore\n\nOn restore containers need to apply all settings. We need\nto wait when it happens.\n\nChange-Id: Iaf159736d68774bd8b785af7078d4e9f17b1a30c\nCloses-Bug: #1448211\n'}, {'number': 2, 'created': '2015-05-19 15:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9ac059a1c77b4b033f553b6251b4aa3b248a5703', 'message': 'Add timeout to restore\n\nOn restore containers need to apply all settings. We need\nto wait when it happens.\n\nChange-Id: Iaf159736d68774bd8b785af7078d4e9f17b1a30c\nCloses-Bug: #1448211\n'}, {'number': 3, 'created': '2015-05-19 16:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ec54b9ea53bdb583a859d785401d698bc911cb95', 'message': 'Add timeout to restore\n\nOn restore containers need to apply all settings. We need\nto wait when it happens.\n\nChange-Id: Iaf159736d68774bd8b785af7078d4e9f17b1a30c\nCloses-Bug: #1448211\n'}, {'number': 4, 'created': '2015-05-19 16:00:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/51c86b6892108d709b26eb644ecce88a9c284d2d', 'message': 'Add timeout to restore\n\nOn restore containers need to apply all settings. We need\nto wait when it happens.\n\nChange-Id: Iaf159736d68774bd8b785af7078d4e9f17b1a30c\nCloses-Bug: #1448211\n'}, {'number': 5, 'created': '2015-05-19 16:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ba18715c37bef6a2941a43439dbad6a8de670c19', 'message': 'Add timeout to restore\n\nOn restore containers need to apply all settings. We need\nto wait when it happens.\n\nChange-Id: Iaf159736d68774bd8b785af7078d4e9f17b1a30c\nCloses-Bug: #1448211\n'}, {'number': 6, 'created': '2015-05-19 17:31:21.000000000', 'files': ['files/fuel-docker-utils/functions.sh', 'deployment/puppet/docker/templates/dockerctl_config.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6b7fefcc2bea077bb00d5300316d090856938227', 'message': 'Add timeout to restore\n\nOn restore containers need to apply all settings. We need\nto wait when it happens.\n\nChange-Id: Iaf159736d68774bd8b785af7078d4e9f17b1a30c\nCloses-Bug: #1448211\n'}]",7,184090,6b7fefcc2bea077bb00d5300316d090856938227,117,10,6,11827,,,0,"Add timeout to restore

On restore containers need to apply all settings. We need
to wait when it happens.

Change-Id: Iaf159736d68774bd8b785af7078d4e9f17b1a30c
Closes-Bug: #1448211
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/90/184090/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-docker-utils/functions.sh'],1,3fb4410a15484f01db507dc8103aad6534f05db2,bug/1448211," echo ""Wait 180 seconds while containers apply all settings..."" sleep 180",,2,0
openstack%2Ffuel-library~master~I5013edc915b78687e1eebe5c61fe5a9befd222f6,openstack/fuel-library,master,I5013edc915b78687e1eebe5c61fe5a9befd222f6,add property 'delay_while_up' for port or bond,MERGED,2015-05-15 19:44:10.000000000,2015-05-19 20:36:56.000000000,2015-05-19 20:36:18.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 13343}, {'_account_id': 14316}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-15 19:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/48ee9258fb997ac52ca70715aec7ff737d121660', 'message': ""add property 'delay_while_up' for port or bond\n\nIn some cases (for example slow LACP bonds or optical links)\nsystem administrator need make delay between interface stay UP and\ncontinue of boot process. This option allow make delay after interface UP.\n\nChange-Id: I5013edc915b78687e1eebe5c61fe5a9befd222f6\nFuel-CI: disable\nCloses-bug: #1441435\n""}, {'number': 2, 'created': '2015-05-15 21:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/dc4aceb4e5a8e617d7452023afbb4d3e845da917', 'message': ""add property 'delay_while_up' for port or bond\n\nIn some cases (for example slow LACP bonds or optical links)\nsystem administrator need make delay between interface stay UP and\ncontinue of boot process. This option allow make delay after interface UP.\n\nChange-Id: I5013edc915b78687e1eebe5c61fe5a9befd222f6\nCloses-bug: #1441435\n""}, {'number': 3, 'created': '2015-05-16 01:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a9ca1c11d333a522bc3e3bc019cf20f059b295d8', 'message': ""add property 'delay_while_up' for port or bond\n\nIn some cases (for example slow LACP bonds or optical links)\nsystem administrator need make delay between interface stay UP and\ncontinue of boot process. This option allow make delay after interface UP.\n\nChange-Id: I5013edc915b78687e1eebe5c61fe5a9befd222f6\nCloses-bug: #1441435\n""}, {'number': 4, 'created': '2015-05-16 06:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1d1fa0dcb11254d3a66a001f106e1357d8b04a66', 'message': ""add property 'delay_while_up' for port or bond\n\nIn some cases (for example slow LACP bonds or optical links)\nsystem administrator need make delay between interface stay UP and\ncontinue of boot process. This option allow make delay after interface UP.\n\nCloses-bug: #1441435\nChange-Id: I5013edc915b78687e1eebe5c61fe5a9befd222f6\n""}, {'number': 5, 'created': '2015-05-18 04:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/83d524007814103d49a8d717386c23ad03369726', 'message': ""add property 'delay_while_up' for port or bond\n\nIn some cases (for example slow LACP bonds or optical links)\nsystem administrator need make delay between interface stay UP and\ncontinue of boot process. This option allow make delay after interface UP.\n\nCloses-bug: #1441435\nChange-Id: I5013edc915b78687e1eebe5c61fe5a9befd222f6\n""}, {'number': 6, 'created': '2015-05-19 03:20:27.000000000', 'files': ['deployment/puppet/l23network/lib/puppet/provider/l23_stored_config_ubuntu.rb', 'deployment/puppet/l23network/templates/centos_post_up.erb', 'deployment/puppet/l23network/manifests/l2/bond.pp', 'deployment/puppet/l23network/lib/puppet/type/l23_stored_config.rb', 'deployment/puppet/l23network/spec/unit/puppet/provider/l23_stored_config_ubuntu__spec.rb', 'deployment/puppet/l23network/manifests/l2/port.pp', 'deployment/puppet/l23network/lib/puppet/provider/l23_stored_config_centos6.rb', 'deployment/puppet/l23network/spec/fixtures/provider/l23_stored_config/lnx_ubuntu_spec/ifcfg-eth1', 'deployment/puppet/l23network/spec/classes/port_with__delay_while_up__option__spec.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/generate_network_config.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1fd24d32f0d7fb0a03ccdf0e3c91b868d4c4fa64', 'message': ""add property 'delay_while_up' for port or bond\n\nIn some cases (for example slow LACP bonds or optical links)\nsystem administrator need make delay between interface stay UP and\ncontinue of boot process. This option allow make delay after interface UP.\n\nCloses-bug: #1441435\nChange-Id: I5013edc915b78687e1eebe5c61fe5a9befd222f6\n""}]",2,183669,1fd24d32f0d7fb0a03ccdf0e3c91b868d4c4fa64,126,8,6,7468,,,0,"add property 'delay_while_up' for port or bond

In some cases (for example slow LACP bonds or optical links)
system administrator need make delay between interface stay UP and
continue of boot process. This option allow make delay after interface UP.

Closes-bug: #1441435
Change-Id: I5013edc915b78687e1eebe5c61fe5a9befd222f6
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/69/183669/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/l23network/lib/puppet/provider/l23_stored_config_ubuntu.rb', 'deployment/puppet/l23network/templates/centos_post_up.erb', 'deployment/puppet/l23network/manifests/l2/bond.pp', 'deployment/puppet/l23network/lib/puppet/type/l23_stored_config.rb', 'deployment/puppet/l23network/manifests/l2/port.pp', 'deployment/puppet/l23network/lib/puppet/parser/functions/generate_network_config.rb']",6,48ee9258fb997ac52ca70715aec7ff737d121660,bug/1441435," :delay_while_up => nil, :delay_while_up => nil, debug(""generate_network_config(): Transformation '#{trans[:name]}' will be produced as \n#{trans.to_yaml.gsub('!ruby/sym ','')}"") debug(""generate_network_config(): Endpoint '#{endpoint_name}' will be created with additional properties \n#{endpoints[endpoint_name].to_yaml.gsub('!ruby/sym ','')}"")"," debug(""generate_network_config(): Transformation '#{trans[:name]}' will be produced as \n#{trans.to_yaml.gsub('!ruby/sym ',':')}"") debug(""generate_network_config(): Endpoint '#{endpoint_name}' will be created with additional properties \n#{endpoints[endpoint_name].to_yaml.gsub('!ruby/sym ',':')}"")",91,2
openstack%2Fswift~master~Ia2205fdbecf8fb16e280c4cee945cf64c3638f10,openstack/swift,master,Ia2205fdbecf8fb16e280c4cee945cf64c3638f10,WIP: single-process,ABANDONED,2015-01-22 16:09:56.000000000,2015-05-19 20:34:12.000000000,,"[{'_account_id': 3}, {'_account_id': 6198}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7350}, {'_account_id': 7479}, {'_account_id': 7652}, {'_account_id': 8542}, {'_account_id': 9625}, {'_account_id': 13471}, {'_account_id': 13777}]","[{'number': 1, 'created': '2015-01-22 16:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2b2b1a078f52daecdf88abc14149b87c972c8963', 'message': 'WIP: single-process\n\nthis is a first draft of the single-process work\nstarted during the last hackathon in Westford.\n\nChange-Id: Ia2205fdbecf8fb16e280c4cee945cf64c3638f10\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 2, 'created': '2015-02-06 08:40:43.000000000', 'files': ['doc/saio/swift/proxy-server.conf', 'doc/saio/swift/single_process.conf', 'test/unit/proxy/test_server.py', 'test/unit/proxy/controllers/test_obj.py', 'test/functional/tests.py', 'test/functional/__init__.py', 'swift/common/swob.py', 'swift/common/wsgi.py', 'swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c9ff72657f4fac5a3e412ad8676e1db59fecca2b', 'message': 'WIP: single-process\n\nthis is a first draft of the single-process work\nstarted during the last hackathon in Westford.\n\nCo-Authored-By: Nicolas Trangez <ikke@nicolast.be>\n\nChange-Id: Ia2205fdbecf8fb16e280c4cee945cf64c3638f10\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}]",5,149329,c9ff72657f4fac5a3e412ad8676e1db59fecca2b,10,11,2,9625,,,0,"WIP: single-process

this is a first draft of the single-process work
started during the last hackathon in Westford.

Co-Authored-By: Nicolas Trangez <ikke@nicolast.be>

Change-Id: Ia2205fdbecf8fb16e280c4cee945cf64c3638f10
Signed-off-by: Thiago da Silva <thiago@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/29/149329/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/saio/swift/proxy-server.conf', 'doc/saio/swift/single_process.conf', 'test/unit/proxy/test_server.py', 'test/unit/proxy/controllers/test_obj.py', 'test/functional/__init__.py', 'test/functional/tests.py', 'swift/common/swob.py', 'swift/common/wsgi.py', 'swift/proxy/controllers/obj.py']",9,2b2b1a078f52daecdf88abc14149b87c972c8963,single_process,"from eventlet import GreenPile, spawn from eventlet.queue import Queue, LightQueuefrom eventlet.event import Eventclass TransferQueue(): def __init__(self, maxsize=None): self.queue = LightQueue(maxsize) self._evt = Event() self.unfinished_tasks = True def put(self, x): self.queue.put(x) def get(self): return self.queue.get() def join(self): self._evt.wait() def done(self): self.unfinished_tasks = False self._evt.send() def task_done(self): pass class LocalConn(): def __init__(self, node): # this is None so that _send_file is Noop'ed self.send = None self.node = node self.bytes_transferred = 0 self.resp = None # if conn.send is available then use it, otherwise, # it's a local call and the object-server will be doing the gets if not conn.send: return logger_thread_locals, req): # bypass if storing locally at we have the object server if 'paco.object_server' in req.environ and \ node['port'] == int(req.environ['paco.bind_port']) \ and node['ip'] in ['localhost', '127.0.0.1']: object_server = req.environ['paco.object_server'] environ = req.environ.copy() environ.update(headers) local_req = Request.blank( path, headers=headers, environ=environ) # fix path to include device local_req.environ['PATH_INFO'] = '/' + node['device'] + \ '/' + str(part) + path conn = LocalConn(node) conn.queue = TransferQueue(self.app.put_queue_depth) # hack in so that the object servers reads the data # directly from the queue class Dummy(): pass reader = Dummy() size = int(local_req.environ['Content-Length']) def read(lenth): if conn.bytes_transferred == size: conn.queue.done() return """" x = conn.queue.get() conn.bytes_transferred += len(x) return x reader.read = read local_req.environ['wsgi.input'] = reader # this is where the response will be looked up # by _get_responses evt = Event() def process_request(): conn.resp = local_req.get_response(object_server) # make the status be just the code conn.resp.use_status_int = True evt.send() def get_response(): evt.wait() return conn.resp conn.getresponse = get_response # spawn work on a separate thread spawn(process_request) return conn except Exception as ex: self.app.logger.exception(""exception: %s"" % ex.message) raise ex try: self.app.logger.thread_locals, req) if not hasattr(conn, 'queue'): # bypass for local conn conn.queue = Queue(self.app.put_queue_depth)",from eventlet import GreenPile from eventlet.queue import Queue logger_thread_locals): self.app.logger.thread_locals) conn.queue = Queue(self.app.put_queue_depth),174,10
openstack%2Fswift~master~Id855d5ed7365f0becf9d1549313cfe6f045d7282,openstack/swift,master,Id855d5ed7365f0becf9d1549313cfe6f045d7282,WIP: refactor the PUT method into separate classes,ABANDONED,2015-02-26 21:09:07.000000000,2015-05-19 20:32:52.000000000,,"[{'_account_id': 3}, {'_account_id': 7652}, {'_account_id': 8542}, {'_account_id': 9625}, {'_account_id': 13052}]","[{'number': 1, 'created': '2015-02-26 21:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cf00f21e4abe72c13dd0f39b35fade1e8078760c', 'message': ""WIP: refactor the PUT method into separate classes\n\nFor now there's only the ReplicatedObjectController class,\nsimilar to the changes in feature/ec branch.\n\nThe Base class containes all public API handling, while\nReplicatedObjectController only handles data transfer\nto object server.\n\nChange-Id: Id855d5ed7365f0becf9d1549313cfe6f045d7282\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n""}, {'number': 2, 'created': '2015-02-26 21:24:17.000000000', 'files': ['test/unit/proxy/test_server.py', 'swift/proxy/controllers/__init__.py', 'test/unit/proxy/controllers/test_obj.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/1ab3634e23b1dd7f7fbbfe3bb7f6105c7071b560', 'message': ""WIP: refactor the PUT method into separate classes\n\nFor now there's only the ReplicatedObjectController class,\nsimilar to the changes in feature/ec branch.\n\nThe Base class containes all public API handling, while\nReplicatedObjectController only handles data transfer\nto object server.\n\nChange-Id: Id855d5ed7365f0becf9d1549313cfe6f045d7282\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n""}]",4,159610,1ab3634e23b1dd7f7fbbfe3bb7f6105c7071b560,10,5,2,9625,,,0,"WIP: refactor the PUT method into separate classes

For now there's only the ReplicatedObjectController class,
similar to the changes in feature/ec branch.

The Base class containes all public API handling, while
ReplicatedObjectController only handles data transfer
to object server.

Change-Id: Id855d5ed7365f0becf9d1549313cfe6f045d7282
Signed-off-by: Thiago da Silva <thiago@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/10/159610/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/proxy/controllers/__init__.py', 'test/unit/proxy/test_server.py', 'test/unit/proxy/controllers/test_obj.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/server.py']",5,cf00f21e4abe72c13dd0f39b35fade1e8078760c,refactor_put,"from swift.proxy.controllers import AccountController, \ ReplicatedObjectController, ContainerController, InfoController return ReplicatedObjectController, d","from swift.proxy.controllers import AccountController, ObjectController, \ ContainerController, InfoController return ObjectController, d",382,349
openstack%2Fdevstack~master~I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574,openstack/devstack,master,I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574,Support for running Nova with oslo.rootwrap daemon,MERGED,2015-05-07 13:38:06.000000000,2015-05-19 20:26:16.000000000,2015-05-19 20:26:14.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5638}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 8871}]","[{'number': 1, 'created': '2015-05-07 13:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/43bc8bae369f186ecf2238b77868b54b2d2d717e', 'message': '[WIP] Support for Nova rootwrap-daemon\n\nNeeded by:\nI57dc2efa39b86fa1fa20730ad70d056e87617c96\n\nChange-Id: I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574\n'}, {'number': 2, 'created': '2015-05-07 14:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c64fc3741518d6ddf09c7d952019ab49f6c5bd42', 'message': '[WIP] Support for Nova rootwrap-daemon\n\nNeeded by:\nI57dc2efa39b86fa1fa20730ad70d056e87617c96\n\nChange-Id: I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574\n'}, {'number': 3, 'created': '2015-05-07 15:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/bb11adedd08e42df9b6a8b768a565336508e8e52', 'message': '[WIP] Support for Nova rootwrap-daemon\n\nNeeded by:\nI57dc2efa39b86fa1fa20730ad70d056e87617c96\n\nChange-Id: I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574\n'}, {'number': 4, 'created': '2015-05-07 17:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a4aedf30ba693add76be43928edc7b1e82985917', 'message': '[WIP] Support for Nova rootwrap-daemon\n\nNeeded by:\nI57dc2efa39b86fa1fa20730ad70d056e87617c96\n\nChange-Id: I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574\n'}, {'number': 5, 'created': '2015-05-07 18:58:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/703de4adec742b72f55e2166e761096f729ce6ed', 'message': 'Support for running Nova with oslo.rootwrap daemon\n\nNova is being enhanced to use rootwrap as a daemon. For this effort,\nwe need an additional entry for nova-rootwrap-daemon in the \nsudoers.d/ directory. Also the command line for nova-rootwrap-daemon\ndoes not take any parameters as well. Note that the comment just above\nconfigure_rootwrap talks about making assumptions, do we just look\nat the parameter already being passed in to figure out that we have\ntoggle the two things mentioned above instead of adding more\nparameters.\n\n\nNeeded by:\nI57dc2efa39b86fa1fa20730ad70d056e87617c96\n\nChange-Id: I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574'}, {'number': 6, 'created': '2015-05-11 01:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/df7fe3b3fee4cb0059a835ebf2813ecd63e16127', 'message': 'Support for running Nova with oslo.rootwrap daemon\n\nNova is being enhanced to use rootwrap as a daemon. For this effort,\nwe need an additional entry for nova-rootwrap-daemon in the \nsudoers.d/ directory. Also the command line for nova-rootwrap-daemon\ndoes not take any parameters as well. Note that the comment just above\nconfigure_rootwrap talks about making assumptions, do we just look\nat the parameter already being passed in to figure out that we have\ntoggle the two things mentioned above instead of adding more\nparameters.\n\n\nNeeded by:\nI57dc2efa39b86fa1fa20730ad70d056e87617c96\n\nChange-Id: I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574'}, {'number': 7, 'created': '2015-05-13 16:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3208f645fec7d5c64c5a338cacea44c7e1d676ab', 'message': 'Support for running Nova with oslo.rootwrap daemon\n\nNova is being enhanced to use rootwrap as a daemon. For this effort,\nwe need an additional entry for nova-rootwrap-daemon in the\nsudoers.d/ directory.\n\nSplit the existing configure_rootwrap into two. one method that\ncopies the filters and another that just creates the sudoers.d\nentry.\n\nNeeded by:\nI57dc2efa39b86fa1fa20730ad70d056e87617c96\n\nChange-Id: I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574\n'}, {'number': 8, 'created': '2015-05-14 00:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/068309f8a257bb8e19ebdd3a897835496c9f3e74', 'message': 'Support for running Nova with oslo.rootwrap daemon\n\nNova is being enhanced to use rootwrap as a daemon. For this effort,\nwe need an additional entry for nova-rootwrap-daemon in the\nsudoers.d/ directory.\n\nNeeded by:\nI57dc2efa39b86fa1fa20730ad70d056e87617c96\n\nChange-Id: I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574\n'}, {'number': 9, 'created': '2015-05-14 01:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/66aa0fb7a77f8814121b55000368f07cd0c0dae1', 'message': 'Support for running Nova with oslo.rootwrap daemon\n\nNova is being enhanced to use rootwrap as a daemon. For this effort,\nwe need an additional entry for nova-rootwrap-daemon in the\nsudoers.d/ directory.\n\nNeeded by:\nI57dc2efa39b86fa1fa20730ad70d056e87617c96\n\nChange-Id: I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574\n'}, {'number': 10, 'created': '2015-05-15 04:26:04.000000000', 'files': ['inc/rootwrap'], 'web_link': 'https://opendev.org/openstack/devstack/commit/8afbaa1c80d54d7f6591f8f2c1a26c34f60c77e1', 'message': 'Support for running Nova with oslo.rootwrap daemon\n\nNova is being enhanced to use rootwrap as a daemon. For this effort,\nwe need an additional entry for nova-rootwrap-daemon in the\nsudoers.d/ directory.\n\nNeeded by:\nI57dc2efa39b86fa1fa20730ad70d056e87617c96\n\nChange-Id: I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574\n'}]",1,180992,8afbaa1c80d54d7f6591f8f2c1a26c34f60c77e1,30,6,10,5638,,,0,"Support for running Nova with oslo.rootwrap daemon

Nova is being enhanced to use rootwrap as a daemon. For this effort,
we need an additional entry for nova-rootwrap-daemon in the
sudoers.d/ directory.

Needed by:
I57dc2efa39b86fa1fa20730ad70d056e87617c96

Change-Id: I80c7b9dd8e9e0f940aa4e54a95b241dfc40d3574
",git fetch https://review.opendev.org/openstack/devstack refs/changes/92/180992/10 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,43bc8bae369f186ecf2238b77868b54b2d2d717e,, configure_rootwrap nova $NOVA_BIN_DIR/nova-rootwrap-daemon $NOVA_DIR/etc/nova,,1,0
openstack%2Fdevstack~master~I7c6a9fa106948ae5cbcf52555ade6154623798f1,openstack/devstack,master,I7c6a9fa106948ae5cbcf52555ade6154623798f1,Infer rootwrap arguments from project,MERGED,2015-05-14 00:07:44.000000000,2015-05-19 20:24:35.000000000,2015-05-19 20:24:33.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 5638}, {'_account_id': 6854}, {'_account_id': 7118}]","[{'number': 1, 'created': '2015-05-14 00:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c1251e73fbac9e57e918fec51d542c622feedab4', 'message': 'Infer rootwrap arguments from project\n\nWe can infer the binary and configuration paths just from the project\nname and expanding this to the known *_DIR & *_BIN_DIR variables.  A\nsimilar thing is done for policyd settings\n\nChange-Id: I7c6a9fa106948ae5cbcf52555ade6154623798f1\n'}, {'number': 2, 'created': '2015-05-14 01:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c2f0824814a53ed4c9732ba9eddd9a5644665e6b', 'message': 'Infer rootwrap arguments from project\n\nWe can infer the binary and configuration paths just from the project\nname and expanding this to the known *_DIR & *_BIN_DIR variables.  A\nsimilar thing is done for policyd settings\n\nChange-Id: I7c6a9fa106948ae5cbcf52555ade6154623798f1\n'}, {'number': 3, 'created': '2015-05-15 04:01:35.000000000', 'files': ['lib/ceilometer', 'lib/cinder', 'lib/nova', 'inc/rootwrap'], 'web_link': 'https://opendev.org/openstack/devstack/commit/c6782413081cbdc72c7b24e34acec383a1cf2f46', 'message': 'Infer rootwrap arguments from project\n\nWe can infer the binary and configuration paths just from the project\nname and expanding this to the known *_DIR & *_BIN_DIR variables.  A\nsimilar thing is done for policyd settings\n\nChange-Id: I7c6a9fa106948ae5cbcf52555ade6154623798f1\n'}]",6,182896,c6782413081cbdc72c7b24e34acec383a1cf2f46,18,6,3,7118,,,0,"Infer rootwrap arguments from project

We can infer the binary and configuration paths just from the project
name and expanding this to the known *_DIR & *_BIN_DIR variables.  A
similar thing is done for policyd settings

Change-Id: I7c6a9fa106948ae5cbcf52555ade6154623798f1
",git fetch https://review.opendev.org/openstack/devstack refs/changes/96/182896/3 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ceilometer', 'lib/cinder', 'lib/nova', 'inc/rootwrap']",4,c1251e73fbac9e57e918fec51d542c622feedab4,rootwrap-less-args,"# configure_rootwrap project local project_uc=$(echo $1|tr a-z A-Z) local bin_dir=""${project_uc}_BIN_DIR"" bin_dir=""${!bin_dir}"" local project_dir=""${project_uc}_DIR"" project_dir=""${!project_dir}"" local rootwrap_conf_src_dir=""{$project_dir}/etc/${project}"" local rootwrap_bin=""${bin_dir}/${project}-rootwrap""",# configure_rootwrap project bin conf-src-dir local rootwrap_bin=$2 # /opt/stack/xx.venv/bin/xx-rootwrap local rootwrap_conf_src_dir=$3 # /opt/stack/xx/etc/xx,12,6
openstack%2Fhorizon~master~I2edabd6c43f811a4bb2e3abe982dbc24958ddf93,openstack/horizon,master,I2edabd6c43f811a4bb2e3abe982dbc24958ddf93,ngReorg - create 'widgets' module,MERGED,2015-05-14 00:43:17.000000000,2015-05-19 20:24:24.000000000,2015-05-19 20:24:22.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 9048}, {'_account_id': 9576}, {'_account_id': 12071}, {'_account_id': 13785}, {'_account_id': 13805}, {'_account_id': 14307}]","[{'number': 1, 'created': '2015-05-14 00:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/affb8f63a4ff693111ad9ff1063a327c157cd78c', 'message': ""ngReorg - create 'widgets' module\n\nThis commit collects UI components into a new\n'horizon.framework.widgets' module. It also standardizes\nthe naming pattern for .scss files and makes them hierarchical.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I2edabd6c43f811a4bb2e3abe982dbc24958ddf93\nPartial-Bug: #1454880\n""}, {'number': 2, 'created': '2015-05-14 00:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c1253d5c051eb6e492afc6143d133591adeabad3', 'message': ""ngReorg - create 'widgets' module\n\nThis commit collects UI components into a new\n'horizon.framework.widgets' module. It also standardizes\nthe naming pattern for .scss files and makes them hierarchical.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I2edabd6c43f811a4bb2e3abe982dbc24958ddf93\nPartial-Bug: #1454880\n""}, {'number': 3, 'created': '2015-05-14 01:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/dcc4068da4301a574a4df85357851ac63b7ae7d9', 'message': ""ngReorg - create 'widgets' module\n\nThis commit collects UI components into a new\n'horizon.framework.widgets' module. It also standardizes\nthe naming pattern for .scss files and makes them hierarchical.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I2edabd6c43f811a4bb2e3abe982dbc24958ddf93\nPartial-Bug: #1454880\n""}, {'number': 4, 'created': '2015-05-14 01:14:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f0ae714c26e2ee4da1db1f31c625af979fa72cd9', 'message': ""ngReorg - create 'widgets' module\n\nThis commit collects UI components into a new\n'horizon.framework.widgets' module. It also standardizes\nthe naming pattern for .scss files and makes them hierarchical.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I2edabd6c43f811a4bb2e3abe982dbc24958ddf93\nPartial-Bug: #1454880\n""}, {'number': 5, 'created': '2015-05-14 01:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e1e27e97c74e6b793c27e0130f742ef0e625b765', 'message': ""ngReorg - create 'widgets' module\n\nThis commit collects UI components into a new\n'horizon.framework.widgets' module. It also standardizes\nthe naming pattern for .scss files and makes them hierarchical.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I2edabd6c43f811a4bb2e3abe982dbc24958ddf93\nPartial-Bug: #1454880\n""}, {'number': 6, 'created': '2015-05-14 01:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7cb892148d355703be1dbc05751874d8ac48a444', 'message': ""ngReorg - create 'widgets' module\n\nThis commit collects UI components into a new\n'horizon.framework.widgets' module. It also standardizes\nthe naming pattern for .scss files and makes them hierarchical.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I2edabd6c43f811a4bb2e3abe982dbc24958ddf93\nPartial-Bug: #1454880\n""}, {'number': 7, 'created': '2015-05-19 15:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4095fc5f21ef350a85bc3ff1e644054365916662', 'message': ""ngReorg - create 'widgets' module\n\nThis commit collects UI components into a new\n'horizon.framework.widgets' module. It also standardizes\nthe naming pattern for .scss files and makes them hierarchical.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I2edabd6c43f811a4bb2e3abe982dbc24958ddf93\nPartial-Bug: #1454880\n""}, {'number': 8, 'created': '2015-05-19 15:56:13.000000000', 'files': ['horizon/static/framework/widgets/toast/toast.spec.js', 'horizon/static/framework/widgets/widgets.scss', 'horizon/static/framework/widgets/form/form.spec.js', 'horizon/static/framework/widgets/wizard/wizard.spec.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.spec.js', 'horizon/static/framework/widgets/charts/chart-tooltip.js', 'horizon/static/framework/framework.scss', 'horizon/static/framework/widgets/charts/pie-chart.spec.js', 'horizon/static/framework/widgets/transfer-table/allocated.html.example', 'horizon/static/framework/util/validators/validators.spec.js', 'horizon/static/framework/widgets/metadata-display/metadata-display.scss', 'horizon/static/framework/widgets/modal/modal.spec.js', 'horizon/static/framework/widgets/metadata-display/metadata-display.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.html', 'horizon/static/framework/widgets/table/basic-table.js', 'horizon/static/framework/widgets/toast/toast.js', 'horizon/static/framework/widgets/table/table.spec.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.scss', 'horizon/static/framework/widgets/modal/modal.js', 'openstack_dashboard/static/dashboard/scss/horizon.scss', 'horizon/static/framework/widgets/metadata-tree/metadata-tree-service.js', 'horizon/static/framework/widgets/action-list/action-list.scss', 'horizon/static/framework/widgets/i18n/i18n.spec.js', 'horizon/static/framework/widgets/action-list/menu.html', 'horizon/static/framework/widgets/action-list/action-list.spec.js', 'horizon/static/framework/widgets/help-panel/help-panel.spec.js', 'horizon/static/framework/widgets/charts/charts.js', 'horizon/static/framework/widgets/action-list/action-list.js', 'horizon/static/framework/widgets/form/form.js', 'horizon/static/framework/widgets/magic-search/magic-search.scss', 'horizon/static/framework/widgets/transfer-table/available.html.example', 'horizon/static/framework/widgets/action-list/warning-tooltip.html', 'horizon/static/framework/widgets/action-list/button-tooltip.js', 'horizon/static/framework/widgets/metadata-display/metadata-display.html', 'horizon/static/framework/widgets/login/login.spec.js', 'horizon/static/framework/widgets/table/table.scss', 'horizon/static/framework/widgets/table/table.js', 'horizon/static/framework/widgets/metadata-display/metadata-display.spec.js', 'horizon/static/framework/util/bind-scope/bind-scope.spec.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.spec.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.html', 'horizon/static/framework/widgets/transfer-table/transfer-table.scss', 'horizon/static/framework/widgets/widgets.module.js', 'horizon/static/framework/widgets/action-list/menu-item.html', 'horizon/static/framework/widgets/toast/toast.html', 'horizon/static/framework/widgets/metadata-tree/metadata-tree-item.html', 'horizon/static/framework/widgets/action-list/split-button.html', 'horizon/static/framework/widgets/wizard/wizard.html', 'horizon/static/framework/widgets/wizard/wizard.scss', 'horizon/static/framework/widgets/modal/modal-wait-spinner.scss', 'horizon/static/framework/widgets/charts/pie-chart.js', 'horizon/static/framework/widgets/charts/pie-chart.scss', 'horizon/static/framework/widgets/magic-search/magic-search.html', 'horizon/static/framework/widgets/help-panel/help-panel.js', 'horizon/static/framework/widgets/magic-search/magic-search.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.js', 'horizon/static/framework/widgets/charts/pie-chart.html', 'horizon/static/framework/widgets/wizard/wizard.js', 'horizon/static/framework/widgets/modal/simple-modal.html', 'horizon/static/framework/widgets/table/basic-table.spec.js', 'horizon/static/horizon/js/angular/horizon.js', 'horizon/static/framework/widgets/charts/chart-tooltip.scss', 'horizon/templates/horizon/_scripts.html', 'horizon/test/jasmine/jasmine_tests.py', 'horizon/static/framework/widgets/charts/chart-tooltip.html', 'horizon/static/framework/widgets/login/login.js', 'horizon/static/framework/widgets/modal/modal-wait-spinner.js', 'horizon/static/framework/framework.module.js', 'horizon/static/framework/widgets/modal/modal-wait-spinner.spec.js', 'horizon/static/framework/widgets/i18n/i18n.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.js', 'horizon/static/framework/widgets/action-list/action.html', 'horizon/static/framework/widgets/help-panel/help-panel.html', 'horizon/static/framework/widgets/action-list/single-button.html', 'horizon/static/framework/widgets/help-panel/help-panel.scss', 'horizon/static/framework/widgets/table/search-bar.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5762d0deee5f093c03a1dd73e3694a33b8a1e07a', 'message': ""ngReorg - create 'widgets' module\n\nThis commit collects UI components into a new\n'horizon.framework.widgets' module. It also standardizes\nthe naming pattern for .scss files and makes them hierarchical.\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I2edabd6c43f811a4bb2e3abe982dbc24958ddf93\nPartial-Bug: #1454880\n""}]",1,182904,5762d0deee5f093c03a1dd73e3694a33b8a1e07a,25,8,8,14307,,,0,"ngReorg - create 'widgets' module

This commit collects UI components into a new
'horizon.framework.widgets' module. It also standardizes
the naming pattern for .scss files and makes them hierarchical.

This is one step in a larger effort to restructure the Angular
source. See https://review.openstack.org/#/c/176152/ for the
full set of planned changes.

Change-Id: I2edabd6c43f811a4bb2e3abe982dbc24958ddf93
Partial-Bug: #1454880
",git fetch https://review.opendev.org/openstack/horizon refs/changes/04/182904/8 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/widgets/toast/toast.spec.js', 'horizon/static/framework/widgets/widgets.scss', 'horizon/static/framework/widgets/form/form.spec.js', 'horizon/static/framework/widgets/wizard/wizard.spec.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.spec.js', 'horizon/static/framework/widgets/charts/chart-tooltip.js', 'horizon/static/framework/framework.scss', 'horizon/static/framework/widgets/charts/pie-chart.spec.js', 'horizon/static/framework/widgets/transfer-table/allocated.html.example', 'horizon/static/framework/util/validators/validators.spec.js', 'horizon/static/framework/widgets/metadata-display/metadata-display.scss', 'horizon/static/framework/widgets/modal/modal.spec.js', 'horizon/static/framework/widgets/metadata-display/metadata-display.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.html', 'horizon/static/framework/widgets/table/basic-table.js', 'horizon/static/framework/widgets/toast/toast.js', 'horizon/static/framework/widgets/table/table.spec.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.scss', 'horizon/static/framework/widgets/modal/modal.js', 'openstack_dashboard/static/dashboard/scss/horizon.scss', 'horizon/static/framework/widgets/metadata-tree/metadata-tree-service.js', 'horizon/static/framework/widgets/action-list/action-list.scss', 'horizon/static/framework/widgets/i18n/i18n.spec.js', 'horizon/static/framework/widgets/action-list/menu.html', 'horizon/static/framework/widgets/action-list/action-list.spec.js', 'horizon/static/framework/widgets/help-panel/help-panel.spec.js', 'horizon/static/framework/widgets/charts/charts.js', 'horizon/static/framework/widgets/action-list/action-list.js', 'horizon/static/framework/widgets/form/form.js', 'horizon/static/framework/widgets/magic-search/magic-search.scss', 'horizon/static/framework/widgets/transfer-table/available.html.example', 'horizon/static/framework/widgets/action-list/warning-tooltip.html', 'horizon/static/framework/widgets/action-list/button-tooltip.js', 'horizon/static/framework/widgets/metadata-display/metadata-display.html', 'horizon/static/framework/widgets/login/login.spec.js', 'horizon/static/framework/widgets/table/table.scss', 'horizon/static/framework/widgets/table/table.js', 'horizon/static/framework/widgets/metadata-display/metadata-display.spec.js', 'horizon/static/framework/util/bind-scope/bind-scope.spec.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.spec.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.html', 'horizon/static/framework/widgets/transfer-table/transfer-table.scss', 'horizon/static/framework/widgets/widgets.module.js', 'horizon/static/framework/widgets/action-list/menu-item.html', 'horizon/static/framework/widgets/toast/toast.html', 'horizon/static/framework/widgets/metadata-tree/metadata-tree-item.html', 'horizon/static/framework/widgets/action-list/split-button.html', 'horizon/static/framework/widgets/wizard/wizard.html', 'horizon/static/framework/widgets/wizard/wizard.scss', 'horizon/static/framework/widgets/modal/modal-wait-spinner.scss', 'horizon/static/framework/widgets/charts/pie-chart.js', 'horizon/static/framework/widgets/charts/pie-chart.scss', 'horizon/static/framework/widgets/magic-search/magic-search.html', 'horizon/static/framework/widgets/help-panel/help-panel.js', 'horizon/static/framework/widgets/magic-search/magic-search.js', 'horizon/static/framework/widgets/metadata-tree/metadata-tree.js', 'horizon/static/framework/widgets/charts/pie-chart.html', 'horizon/static/framework/widgets/wizard/wizard.js', 'horizon/static/framework/widgets/modal/simple-modal.html', 'horizon/static/framework/widgets/table/basic-table.spec.js', 'horizon/static/horizon/js/angular/horizon.js', 'horizon/static/framework/widgets/charts/chart-tooltip.scss', 'horizon/templates/horizon/_scripts.html', 'horizon/test/jasmine/jasmine_tests.py', 'horizon/static/framework/widgets/charts/chart-tooltip.html', 'horizon/static/framework/widgets/login/login.js', 'horizon/static/framework/widgets/modal/modal-wait-spinner.js', 'horizon/static/framework/framework.module.js', 'horizon/static/framework/widgets/modal/modal-wait-spinner.spec.js', 'horizon/static/framework/widgets/i18n/i18n.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.js', 'horizon/static/framework/widgets/action-list/action.html', 'horizon/static/framework/widgets/help-panel/help-panel.html', 'horizon/static/framework/widgets/action-list/single-button.html', 'horizon/static/framework/widgets/help-panel/help-panel.scss', 'horizon/static/framework/widgets/table/search-bar.html']",76,affb8f63a4ff693111ad9ff1063a327c157cd78c,bug/1454880,,,93,80
openstack%2Fneutron~master~I51b36ce912194abd89ed46fad9943802f271444a,openstack/neutron,master,I51b36ce912194abd89ed46fad9943802f271444a,Take Daemon stdin/stdout/stderr args as file objects,MERGED,2015-05-14 07:39:40.000000000,2015-05-19 20:20:51.000000000,2015-05-19 20:20:46.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 11279}, {'_account_id': 14208}, {'_account_id': 14571}, {'_account_id': 15296}]","[{'number': 1, 'created': '2015-05-14 07:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c2f158525ab34614266104cd4a783172f0b03fc', 'message': 'Take Daemon stdin/stdout/stderr args as file objects\n\nPreviously Daemon constructor took stdin/stdout/stderr as\npaths (defaulting to \'/dev/null\') and opened them as regular files.\nThis greatly limits the type of filehandles supported (no pipes, for\nexample), and doesn\'t allow simple things like reusing existing fds.\n\nThis change switches to accepting file objects rather than strings,\nand uses a sentinal value to represent the previous ""open /dev/null""\ndefault behaviour.\n\nChange-Id: I51b36ce912194abd89ed46fad9943802f271444a\n'}, {'number': 2, 'created': '2015-05-15 07:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f09e2a126f6944cf21d334941d947c2e504efa9c', 'message': 'Take Daemon stdin/stdout/stderr args as file objects\n\nPreviously Daemon constructor took stdin/stdout/stderr as\npaths (defaulting to \'/dev/null\') and opened them as regular files.\nThis greatly limits the type of filehandles supported (no pipes, for\nexample), and doesn\'t allow simple things like reusing existing fds.\n\nThis change switches to accepting file objects rather than strings,\nand uses a sentinal value to represent the previous ""open /dev/null""\ndefault behaviour.\n\nChange-Id: I51b36ce912194abd89ed46fad9943802f271444a\n'}, {'number': 3, 'created': '2015-05-15 08:01:07.000000000', 'files': ['neutron/tests/unit/agent/linux/test_daemon.py', 'neutron/agent/linux/daemon.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/274713450c4f4cc1f5c466e153b72c9764dd96c9', 'message': 'Take Daemon stdin/stdout/stderr args as file objects\n\nPreviously Daemon constructor took stdin/stdout/stderr as\npaths (defaulting to \'/dev/null\') and opened them as regular files.\nThis greatly limits the type of filehandles supported (no pipes, for\nexample), and doesn\'t allow simple things like reusing existing fds.\n\nThis change switches to accepting file objects rather than strings,\nand uses a sentinal value to represent the previous ""open /dev/null""\ndefault behaviour.\n\nChange-Id: I51b36ce912194abd89ed46fad9943802f271444a\n'}]",10,182962,274713450c4f4cc1f5c466e153b72c9764dd96c9,51,22,3,11279,,,0,"Take Daemon stdin/stdout/stderr args as file objects

Previously Daemon constructor took stdin/stdout/stderr as
paths (defaulting to '/dev/null') and opened them as regular files.
This greatly limits the type of filehandles supported (no pipes, for
example), and doesn't allow simple things like reusing existing fds.

This change switches to accepting file objects rather than strings,
and uses a sentinal value to represent the previous ""open /dev/null""
default behaviour.

Change-Id: I51b36ce912194abd89ed46fad9943802f271444a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/182962/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/daemon.py'],1,5c2f158525ab34614266104cd4a783172f0b03fc,privsep,"DEVNULL = object() def __init__(self, pidfile, stdin=DEVNULL, stdout=DEVNULL, stderr=DEVNULL, procname='python', uuid=None, os._exit(0) devnull = open(os.devnull, 'w+') stdin = devnull if self.stdin is DEVNULL else self.stdin stdout = devnull if self.stdout is DEVNULL else self.stdout stderr = devnull if self.stderr is DEVNULL else self.stderr"," def __init__(self, pidfile, stdin='/dev/null', stdout='/dev/null', stderr='/dev/null', procname='python', uuid=None, sys.exit(0) stdin = open(self.stdin, 'r') stdout = open(self.stdout, 'a+') stderr = open(self.stderr, 'a+', 0)",9,6
openstack%2Fos-brick~master~Ib523337c13c49e7fd63bab8ab8738a5b60c1cee2,openstack/os-brick,master,Ib523337c13c49e7fd63bab8ab8738a5b60c1cee2,Preparing for the 0.1.1 release,MERGED,2015-05-17 20:28:09.000000000,2015-05-19 19:41:33.000000000,2015-05-19 19:41:33.000000000,"[{'_account_id': 3}, {'_account_id': 170}]","[{'number': 1, 'created': '2015-05-17 20:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/87dde1cb2968fa5034d22c922e7c282a2d18b41d', 'message': ""Preparing for 0.1.1 release\n\nThis is to resolve some conflict issues we're seeing in\nglobal-requirements.\n\nChange-Id: Ib523337c13c49e7fd63bab8ab8738a5b60c1cee2\n""}, {'number': 2, 'created': '2015-05-19 19:19:24.000000000', 'files': ['doc/source/changelog.rst'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/28f3d0950f7fdbfa5ba3c7d6dc842d9ac00fbbb3', 'message': ""Preparing for the 0.1.1 release\n\nThis is to resolve some conflict issues we're seeing in\nglobal-requirements.\n\nChange-Id: Ib523337c13c49e7fd63bab8ab8738a5b60c1cee2\n""}]",0,183943,28f3d0950f7fdbfa5ba3c7d6dc842d9ac00fbbb3,11,2,2,170,,,0,"Preparing for the 0.1.1 release

This is to resolve some conflict issues we're seeing in
global-requirements.

Change-Id: Ib523337c13c49e7fd63bab8ab8738a5b60c1cee2
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/43/183943/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/changelog.rst'],1,87dde1cb2968fa5034d22c922e7c282a2d18b41d,,0.1.1 ----- * This release is primarily to resolve some OpenStack global requirements conflict issues. .. _1453992 http://bugs.launchpad.net/cinder/+bug/1453992 0.1.0,1.0.0,8,1
openstack%2Fhorizon~master~I67f080a7d563c37e5dd4d89e5906471e443d4302,openstack/horizon,master,I67f080a7d563c37e5dd4d89e5906471e443d4302,ngReorg - create 'util' module,MERGED,2015-05-13 23:43:18.000000000,2015-05-19 19:22:03.000000000,2015-05-19 19:22:01.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 7665}, {'_account_id': 9048}, {'_account_id': 9576}, {'_account_id': 12071}, {'_account_id': 13785}, {'_account_id': 13805}, {'_account_id': 14307}]","[{'number': 1, 'created': '2015-05-13 23:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3fd0e505127cf9afccb2264c0975613a099962a5', 'message': ""ngReorg - create 'util' module\n\nThis commit collects some utilties into a new\n'horizon.framework.util' module\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I67f080a7d563c37e5dd4d89e5906471e443d4302\nPartial-Bug: #1454880\n""}, {'number': 2, 'created': '2015-05-13 23:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3bb3ae98dce31bd5cd13438f7b46822ca1f5b236', 'message': ""ngReorg - create 'util' module\n\nThis commit collects some utilties into a new\n'horizon.framework.util' module\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I67f080a7d563c37e5dd4d89e5906471e443d4302\nPartial-Bug: #1454880\n""}, {'number': 3, 'created': '2015-05-14 01:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cfc330d6a83d9bdbf032df65e343b8af0894953a', 'message': ""ngReorg - create 'util' module\n\nThis commit collects some utilties into a new\n'horizon.framework.util' module\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I67f080a7d563c37e5dd4d89e5906471e443d4302\nPartial-Bug: #1454880\n""}, {'number': 4, 'created': '2015-05-14 01:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7339cbc502f9349ae3556b824fa24e413cd56cc0', 'message': ""ngReorg - create 'util' module\n\nThis commit collects some utilties into a new\n'horizon.framework.util' module\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I67f080a7d563c37e5dd4d89e5906471e443d4302\nPartial-Bug: #1454880\n""}, {'number': 5, 'created': '2015-05-19 15:47:32.000000000', 'files': ['horizon/static/framework/util/validators/validators.js', 'horizon/static/framework/util/bind-scope/bind-scope.js', 'horizon/static/framework/widget.module.js', 'horizon/static/framework/util/workflow/workflow.spec.js', 'horizon/static/framework/util/util.module.js', 'horizon/static/framework/util/validators/validators.spec.js', 'horizon/templates/horizon/_scripts.html', 'horizon/test/jasmine/jasmine_tests.py', 'horizon/static/framework/util/workflow/workflow.js', 'horizon/static/framework/util/bind-scope/bind-scope.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/317023e2e2c492a782e81d54a687b6889e03b42e', 'message': ""ngReorg - create 'util' module\n\nThis commit collects some utilties into a new\n'horizon.framework.util' module\n\nThis is one step in a larger effort to restructure the Angular\nsource. See https://review.openstack.org/#/c/176152/ for the\nfull set of planned changes.\n\nChange-Id: I67f080a7d563c37e5dd4d89e5906471e443d4302\nPartial-Bug: #1454880\n""}]",0,182891,317023e2e2c492a782e81d54a687b6889e03b42e,29,9,5,14307,,,0,"ngReorg - create 'util' module

This commit collects some utilties into a new
'horizon.framework.util' module

This is one step in a larger effort to restructure the Angular
source. See https://review.openstack.org/#/c/176152/ for the
full set of planned changes.

Change-Id: I67f080a7d563c37e5dd4d89e5906471e443d4302
Partial-Bug: #1454880
",git fetch https://review.opendev.org/openstack/horizon refs/changes/91/182891/4 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/util/validators/validators.js', 'horizon/static/framework/util/bind-scope/bind-scope.js', 'horizon/static/framework/widget.module.js', 'horizon/static/framework/util/workflow/workflow.spec.js', 'horizon/static/framework/util/util.module.js', 'horizon/static/framework/util/validators/validators.spec.js', 'horizon/templates/horizon/_scripts.html', 'horizon/test/jasmine/jasmine_tests.py', 'horizon/static/framework/util/bind-scope/bind-scope.spec.js', 'horizon/static/framework/util/workflow/workflow.js']",10,3fd0e505127cf9afccb2264c0975613a099962a5,bug/1454880,,,29,12
openstack%2Fproject-config~master~I09885a899dd0e3f7b5380e9b65398ab385b64eb7,openstack/project-config,master,I09885a899dd0e3f7b5380e9b65398ab385b64eb7,Update networking-ovn job,MERGED,2015-05-14 16:05:06.000000000,2015-05-19 19:16:48.000000000,2015-05-19 19:16:48.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 5756}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 11343}, {'_account_id': 13070}]","[{'number': 1, 'created': '2015-05-14 16:05:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5b46c793dd0dad158fad0d0a7c87f8e51c54f21e', 'message': 'Update networking-ovn job\n\nThe service name has changed in networking-ovn and now\nis ovn-northd and ovn-controller\n\nChange-Id: I09885a899dd0e3f7b5380e9b65398ab385b64eb7\n'}, {'number': 2, 'created': '2015-05-14 16:08:25.000000000', 'files': ['jenkins/jobs/networking-ovn.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/06deb47db555dcceb2658796985e8f046c98c5e8', 'message': 'Update networking-ovn job\n\nThe service name has changed in networking-ovn and now\nis ovn-northd and ovn-controller\n\nChange-Id: I09885a899dd0e3f7b5380e9b65398ab385b64eb7\n'}]",0,183100,06deb47db555dcceb2658796985e8f046c98c5e8,13,11,2,11343,,,0,"Update networking-ovn job

The service name has changed in networking-ovn and now
is ovn-northd and ovn-controller

Change-Id: I09885a899dd0e3f7b5380e9b65398ab385b64eb7
",git fetch https://review.opendev.org/openstack/project-config refs/changes/00/183100/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/networking-ovn.yaml'],1,5b46c793dd0dad158fad0d0a7c87f8e51c54f21e,update_networking_ovn_job," export OVERRIDE_ENABLED_SERVICES=ovn-northd,ovn-controller,q-svc,q-dhcp,q-l3,key,mysql,rabbit"," export OVERRIDE_ENABLED_SERVICES=ovn,q-svc,q-dhcp,q-l3,key,mysql,rabbit",1,1
