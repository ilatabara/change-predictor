id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fdevstack~master~I7f39bbdf7b8cb544b8b4a59effe16f04b85d1425,openstack/devstack,master,I7f39bbdf7b8cb544b8b4a59effe16f04b85d1425,Fix Neutron issues related to Baremetal service,MERGED,2013-08-29 15:31:42.000000000,2013-09-06 18:09:47.000000000,2013-09-06 18:09:47.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7166}]","[{'number': 1, 'created': '2013-08-29 15:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e3127096e8f258991e1efb29c7cab46426f6d939', 'message': ""Fix Neutron issues related to Baremetal service\n\nWhen deploying devstack on a single host with a single NIC and\nbaremetal and neutron services enabled, the host looses Internet\naccess as default route is deleted.\n\nAlso, if localrc is not correctly set with correct values, OVS ports\nand Neutron net and subnet aren't created (commands missing\narguments), we need devstack to properly fail.\n\nChange-Id: I7f39bbdf7b8cb544b8b4a59effe16f04b85d1425\n""}, {'number': 2, 'created': '2013-09-04 11:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/636f2ed0828ca23624c798b44ddcbabf31cfd69b', 'message': ""Fix Neutron issues related to Baremetal service\n\nWhen deploying devstack on a single host with a single NIC and\nbaremetal and neutron services enabled, the host looses Internet\naccess as default route is deleted.\n\nAlso, if localrc is not correctly set with correct values, OVS ports\nand Neutron net and subnet aren't created (commands missing\narguments), we need devstack to properly fail.\n\nChange-Id: I7f39bbdf7b8cb544b8b4a59effe16f04b85d1425\n""}, {'number': 3, 'created': '2013-09-04 11:55:57.000000000', 'files': ['lib/neutron'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e2c4ee23642a00ebed0343ad2086b5c250f24516', 'message': ""Fix Neutron issues related to Baremetal service\n\nWhen deploying devstack on a single host with a single NIC and\nbaremetal and neutron services enabled, the host looses Internet\naccess as default route is deleted.\n\nAlso, if localrc is not correctly set with correct values, OVS ports\nand Neutron net and subnet aren't created (commands missing\narguments), we need devstack to properly fail.\n\nChange-Id: I7f39bbdf7b8cb544b8b4a59effe16f04b85d1425\n""}]",4,44304,e2c4ee23642a00ebed0343ad2086b5c250f24516,11,4,3,7166,,,0,"Fix Neutron issues related to Baremetal service

When deploying devstack on a single host with a single NIC and
baremetal and neutron services enabled, the host looses Internet
access as default route is deleted.

Also, if localrc is not correctly set with correct values, OVS ports
and Neutron net and subnet aren't created (commands missing
arguments), we need devstack to properly fail.

Change-Id: I7f39bbdf7b8cb544b8b4a59effe16f04b85d1425
",git fetch https://review.opendev.org/openstack/devstack refs/changes/04/44304/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron'],1,e3127096e8f258991e1efb29c7cab46426f6d939,bug/neutron-baremetal-support," if [[ $PUBLIC_INTERFACE == '' || $OVS_PHYSICAL_BRIDGE == '' ]]; then die $LINENO ""Neutron settings for baremetal not set.. exiting"" fi sudo ip route add default via $NETWORK_GATEWAY dev $OVS_PHYSICAL_BRIDGE",,4,0
openstack%2Fhorizon~master~Ie69c8d0b990e53678262457094852b1ef4966b8b,openstack/horizon,master,Ie69c8d0b990e53678262457094852b1ef4966b8b,Remove test string from translation files,MERGED,2013-09-06 06:53:57.000000000,2013-09-06 17:35:22.000000000,2013-09-06 16:33:05.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4264}, {'_account_id': 4978}, {'_account_id': 6413}]","[{'number': 1, 'created': '2013-09-06 06:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/88d883f52fd01c82b21d7f862d7a06a4e76823b5', 'message': 'Remove test string from translation files\n\nCloses-Bug: #1221123\n\nRemoving unnecessary translation strings reduces translation work.\nString Freeze is enabled so this patch also update en PO files.\n\nChange-Id: Ie69c8d0b990e53678262457094852b1ef4966b8b\n'}, {'number': 2, 'created': '2013-09-06 06:56:24.000000000', 'files': ['horizon/test/test_dashboards/cats/dashboard.py', 'horizon/test/test_dashboards/cats/kittens/panel.py', 'horizon/test/customization/cust_test1.py', 'horizon/test/test_dashboards/dogs/dashboard.py', 'horizon/test/test_dashboards/cats/tigers/templates/tigers/index.html', 'horizon/test/tests/base.py', 'horizon/test/test_dashboards/cats/tigers/panel.py', 'horizon/test/tests/tabs.py', 'horizon/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/test/settings.py', 'horizon/test/test_dashboards/cats/kittens/templates/kittens/index.html', 'horizon/test/test_dashboards/dogs/puppies/templates/puppies/index.html', 'horizon/test/tests/messages.py', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'horizon/test/tests/workflows.py', 'horizon/test/settings.py', 'horizon/test/tests/tables.py', 'horizon/test/test_dashboards/dogs/puppies/panel.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a2d6c1f1434b5e529b2a902c3e75003bbb7f2aa5', 'message': 'Remove test string from translation files\n\nCloses-Bug: #1221123\n\nRemoving unnecessary translation strings reduces translation work.\nString Freeze is enabled so this patch also update en PO files.\n\nChange-Id: Ie69c8d0b990e53678262457094852b1ef4966b8b\n'}]",2,45382,a2d6c1f1434b5e529b2a902c3e75003bbb7f2aa5,12,5,2,841,,,0,"Remove test string from translation files

Closes-Bug: #1221123

Removing unnecessary translation strings reduces translation work.
String Freeze is enabled so this patch also update en PO files.

Change-Id: Ie69c8d0b990e53678262457094852b1ef4966b8b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/82/45382/2 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/test/test_dashboards/cats/dashboard.py', 'horizon/test/test_dashboards/cats/kittens/panel.py', 'horizon/test/customization/cust_test1.py', 'horizon/test/test_dashboards/dogs/dashboard.py', 'horizon/locale/en/LC_MESSAGES/djangojs.po', 'horizon/test/test_dashboards/cats/tigers/templates/tigers/index.html', 'horizon/test/tests/base.py', 'horizon/test/test_dashboards/cats/tigers/panel.py', 'horizon/test/tests/tabs.py', 'horizon/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/test/settings.py', 'horizon/test/test_dashboards/cats/kittens/templates/kittens/index.html', 'horizon/test/test_dashboards/dogs/puppies/templates/puppies/index.html', 'horizon/test/tests/messages.py', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'horizon/test/tests/workflows.py', 'horizon/test/settings.py', 'horizon/test/tests/tables.py', 'horizon/test/test_dashboards/dogs/puppies/panel.py']",19,88d883f52fd01c82b21d7f862d7a06a4e76823b5,bug/1221123," name = ""Puppies""","from django.utils.translation import ugettext_lazy as _ # noqa name = _(""Puppies"")",67,253
openstack%2Fopenstack-manuals~master~If3eb434f09c26e461e133db0f87ac24d63e3403d,openstack/openstack-manuals,master,If3eb434f09c26e461e133db0f87ac24d63e3403d,Update CLI chapter in the Admin User Guide,MERGED,2013-08-30 01:06:11.000000000,2013-09-06 17:15:44.000000000,2013-09-06 17:15:44.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 1177}, {'_account_id': 2448}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-08-30 01:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3ed20f03b799e8d29a191102335f92abc37d4e6e', 'message': 'Update CLI chapter in the Admin User Guide\n\nbug: #1218683\n\nChange-Id: If3eb434f09c26e461e133db0f87ac24d63e3403d\nauthor: diane fleming\n'}, {'number': 2, 'created': '2013-09-05 17:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6d58141ee816bdfae1577ed6782010f4e327f217', 'message': 'Update CLI chapter in the Admin User Guide\n\nbug: #1218683\n\nChange-Id: If3eb434f09c26e461e133db0f87ac24d63e3403d\nauthor: diane fleming\n'}, {'number': 3, 'created': '2013-09-05 21:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/61ec552e3a5127a998bab7e22dcb0d644021b071', 'message': 'Update CLI chapter in the Admin User Guide\n\nbug: #1218683\n\nChange-Id: If3eb434f09c26e461e133db0f87ac24d63e3403d\nauthor: diane fleming\n'}, {'number': 4, 'created': '2013-09-06 03:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ec2710105a3167c9d724867c721f345d1a67d37e', 'message': 'Update CLI chapter in the Admin User Guide\n\nbug: #1218683\n\nChange-Id: If3eb434f09c26e461e133db0f87ac24d63e3403d\nauthor: diane fleming\n'}, {'number': 5, 'created': '2013-09-06 04:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4c0294db08296b446c6b92aff202620168bf1b84', 'message': 'Update CLI chapter in the Admin User Guide\n\nbug: #1218683\n\nChange-Id: If3eb434f09c26e461e133db0f87ac24d63e3403d\nauthor: diane fleming\n'}, {'number': 6, 'created': '2013-09-06 05:08:35.000000000', 'files': ['doc/src/docbkx/openstack-user/src/section_cli_version.xml', 'doc/src/docbkx/openstack-user/src/ch_cli.xml', 'doc/src/docbkx/cli-guide/src/ch_client_overview.xml', 'doc/src/docbkx/openstack-user-admin/src/ch_cli.xml', 'doc/src/docbkx/common/section_cli_openrc.xml', 'doc/src/docbkx/openstack-user-admin/src/section_keystone_cli_manage_projects_users.xml', 'doc/src/docbkx/openstack-compute-admin/ch_identity_mgmt.xml', 'doc/src/docbkx/common/section_cli_version.xml', 'doc/src/docbkx/openstack-user-admin/src/section_keystone_cli_set_quotas.xml', 'doc/src/docbkx/openstack-user-admin/src/section_nova_cli_manage_flavors.xml', 'doc/src/docbkx/common/section_cli_help.xml', 'doc/src/docbkx/common/section_keystone_cli_example_usage.xml', 'doc/src/docbkx/common/section_cli_install.xml', 'doc/src/docbkx/common/section_keystone_cli_services.xml', 'doc/src/docbkx/openstack-user-admin/src/section_cli_set_compute_quotas.xml', 'doc/src/docbkx/openstack-user-admin/src/section_cinder_cli_quotas.xml', 'doc/src/docbkx/openstack-user-admin/src/section_nova_cli_quotas.xml', 'doc/src/docbkx/openstack-user/src/section_cli_help.xml', 'doc/src/docbkx/common/section_glance_cli_manage_images.xml', 'doc/src/docbkx/openstack-user-admin/src/section_keystone_cli_manage_projects_users_roles.xml', 'doc/src/docbkx/openstack-user/src/section_cli_install.xml', 'doc/src/docbkx/openstack-compute-admin/bk-compute-adminguide.xml', 'doc/src/docbkx/openstack-user-admin/src/section_cli_set_block_storage_quotas.xml', 'doc/src/docbkx/common/section_cli_overview.xml', 'doc/src/docbkx/openstack-user-admin/src/section_cinder_cli_manage_volumes.xml', 'doc/src/docbkx/common/section_keystone_cli_users_tenants_roles.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/431d94cb5570dfb88434e1ab3a3d09fa7aa3ef9c', 'message': 'Update CLI chapter in the Admin User Guide\n\nbug: #1218683\n\nChange-Id: If3eb434f09c26e461e133db0f87ac24d63e3403d\nauthor: diane fleming\n'}]",0,44382,431d94cb5570dfb88434e1ab3a3d09fa7aa3ef9c,28,6,6,2448,,,0,"Update CLI chapter in the Admin User Guide

bug: #1218683

Change-Id: If3eb434f09c26e461e133db0f87ac24d63e3403d
author: diane fleming
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/82/44382/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-user/src/section_cli_install.xml'],1,3ed20f03b799e8d29a191102335f92abc37d4e6e,1218683," Linux system, use <command>pip</command>. It is easy to use, ensures that you get the latest version of the clients from the <link xlink:href=""http://pypi.python.org/pypi/python-novaclient/"" >Python Package Index</link>, and lets you update or remove the packages later on.</para> system:</para> <formalpara><title>Mac OS X</title> <para> <screen><prompt>$</prompt> <userinput>sudo easy_install pip</userinput></screen></para> </formalpara> <formalpara><title>Ubuntu 12.04</title> to use <command>dpkg</command> or <command>aptitude</command> to install the python-novaclient:<screen><prompt>#</prompt> <userinput>aptitude install python-novaclient</userinput></screen></para></formalpara> <formalpara><title>Ubuntu</title> <para><screen><prompt>#</prompt> <userinput>aptitude install python-pip</userinput></screen></para></formalpara> <formalpara><title>RHEL, CentOS, or Fedora</title> <link xlink:href=""http://openstack.redhat.com/"" >RDO</link> enables you to use <command>yum</command> to install the clients: <screen><prompt>#</prompt> <userinput>yum install python-<replaceable>PROJECT</replaceable>client</userinput></screen>Alternatively, install <command>pip</command> and use it to manage client installation: <screen><prompt>#</prompt> <userinput>yum install python-pip</userinput></screen></para> </formalpara> <formalpara><title>openSUSE 12.2 and earlier</title> xlink:href=""https://build.opensuse.org/package/show?package=python-novaclient&amp;project=Cloud:OpenStack:Master"" >packaged version available in the Open Build Service</link> enables you to use <command>rpm</command> or <command>zypper</command> to install the python-novaclient:<screen><prompt>#</prompt> <userinput>zypper install python-<replaceable>PROJECT</replaceable></userinput></screen>Alternatively, install <command>pip</command> and use it to manage client installation: <screen><prompt>#</prompt> <userinput>zypper install python-pip</userinput></screen></para></formalpara> <formalpara><title>openSUSE 12.3</title> to use <command>rpm</command> or <command>zypper</command> to install the clients: <screen><prompt>#</prompt> <userinput>zypper install python-<replaceable>PROJECT</replaceable>client</userinput></screen><note><para>For each command, replace <replaceable>PROJECT</replaceable> with the lower case name of the client to install, such as <literal>nova</literal>. Repeat for each client.</para></note></para> </formalpara> "," Linux system, use <command>pip</command>. It is easy to use and ensures that you get the latest version of the clients from the <link xlink:href=""http://pypi.python.org/pypi/python-novaclient/"" >Python Package Index</link>. Also, it lets you update or remove the packages later on.</para> system:</para><itemizedlist> <listitem> <para>Mac OS X <screen><prompt>$</prompt> <userinput>sudo easy_install pip</userinput></screen></para> </listitem> <listitem> <para>Ubuntu 12.04</para> to use <command>dpkg</command> or <command>aptitude</command> to install the python-novaclient.</para> <screen><prompt>#</prompt> aptitude install python-novaclient</screen> </listitem> <listitem> <para>Ubuntu <screen><prompt>#</prompt> aptitude install python-pip</screen></para> </listitem> <listitem> <para>RHEL, CentOS, or Fedora</para> <link xlink:href=""http://openstack.redhat.com/"" >RDO</link> enables you to use <command>yum</command> to install the clients: <screen><prompt>#</prompt> yum install python-<replaceable>PROJECT</replaceable>client</screen> Replace <replaceable>PROJECT</replaceable> with the lower case name of the client to install, such as <literal>nova</literal>. Repeat this step for each client.</para> <para>Alternatively install <command>pip</command> and use it to manage client installation: <screen><prompt>#</prompt> yum install python-pip</screen> </para> </listitem> <listitem> <para>openSUSE 12.2 and earlier</para> xlink:href=""https://build.opensuse.org/package/show?package=python-novaclient&amp;project=Cloud:OpenStack:Master"" >packaged version available in the Open Build Service</link> enables you to use <command>rpm</command> or <command>zypper</command> to install the python-novaclient. <screen><prompt>#</prompt> zypper install python-<replaceable>PROJECT</replaceable></screen> Replace <replaceable>PROJECT</replaceable> with the lowercase name of the client to install, such as <literal>nova</literal>. Repeat this step for each desired client.</para> <para>Alternatively install <command>pip</command> and use it to manage client installation: <screen><prompt>#</prompt> zypper install python-pip </screen></para> </listitem> <listitem> <para>openSUSE 12.3</para> to use <command>rpm</command> or <command>zypper</command> to install the clients: <screen><prompt>#</prompt> zypper install python-<replaceable>PROJECT</replaceable>client</screen> Replace <replaceable>PROJECT</replaceable> with the lowercase name of the client to install, such as <literal>nova</literal>. Repeat this step for each desired client. </para> </listitem> </itemizedlist>",52,82
openstack%2Fopenstack-manuals~master~I4f0bd0d2edd72b4aae1121a8334917980f267f56,openstack/openstack-manuals,master,I4f0bd0d2edd72b4aae1121a8334917980f267f56,NFS section for block storage Nexenta driver,MERGED,2013-09-04 23:50:22.000000000,2013-09-06 17:09:38.000000000,2013-09-06 17:09:37.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2401}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-09-04 23:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cc95158d55d627bef0f4e783ee671e05ad3094ea', 'message': 'NFS section for block storage Nexenta driver\n\nAdd NFS section for Openstack Block Storage Nexenta volume driver.\n\nChange-Id: I4f0bd0d2edd72b4aae1121a8334917980f267f56\n'}, {'number': 2, 'created': '2013-09-05 23:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c8ec2542017a9b6f07eae3ac897fcf1060706738', 'message': 'NFS section for block storage Nexenta driver\n\n1. Add table with list of options to iSCSI section of Nexenta volume\ndriver.\n2. Add NFS section for Openstack Block Storage Nexenta volume driver.\n\nChange-Id: I4f0bd0d2edd72b4aae1121a8334917980f267f56\n'}, {'number': 3, 'created': '2013-09-05 23:57:54.000000000', 'files': ['doc/src/docbkx/openstack-config/block-storage/drivers/nexenta-volume-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fe95e5305a149b1d7dfb5496a1aafed59ffc6530', 'message': 'NFS section for block storage Nexenta driver\n\n1. Add table with list of options to iSCSI section of Nexenta volume\ndriver.\n2. Add NFS section for Openstack Block Storage Nexenta volume driver.\n\nChange-Id: I4f0bd0d2edd72b4aae1121a8334917980f267f56\n'}]",2,45140,fe95e5305a149b1d7dfb5496a1aafed59ffc6530,12,5,3,2401,,,0,"NFS section for block storage Nexenta driver

1. Add table with list of options to iSCSI section of Nexenta volume
driver.
2. Add NFS section for Openstack Block Storage Nexenta volume driver.

Change-Id: I4f0bd0d2edd72b4aae1121a8334917980f267f56
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/40/45140/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-config/block-storage/drivers/nexenta-volume-driver.xml'],1,cc95158d55d627bef0f4e783ee671e05ad3094ea,block-storage-nexenta-driver-nfs-section," <para> With the NFS option, every Compute volume is represented by a directory designated to be its own file system in the ZFS file system. These file systems are exported using NFS. </para> <para> With either option some minimal setup is required to tell OpenStack which NexentaStor servers are being used, whether they are supporting iSCSI and/or NFS and how to access each of the servers. </para> <para> Typically the only operation required on the NexentaStor servers is to create the containing directory for the iSCSI or NFS exports. There is no software that must be installed on the NexentaStor servers; they are controlled using existing management plane interfaces. </para> <!-- NFS driver section --> <section xml:id=""nexenta-nfs-driver""> <title>Nexenta NFS driver</title> <!-- TODO: Add description for NFS driver here --> <para> To use Compute with Nexenta Storage Appliance NFS driver, you should first set the <code>volume_driver</code> in <filename>cinder.conf</filename>: </para> <para> <code> volume_driver= cinder.volume.drivers.nexenta.nfs.NexentaNfsDriver </code> </para> <para> The following table contains the options supported by the Nexenta NFS driver. </para> <table rules=""all""> <caption> List of configuration flags for Nexenta NFS driver </caption> <col width=""35%""/> <col width=""15%""/> <col width=""15%""/> <col width=""35%""/> <thead> <tr> <td>Flag Name</td> <td>Type</td> <td>Default</td> <td>Description</td> </tr> </thead> <tbody> <tr> <td> <para> <code>nexenta_shares_config</code> </para> </td> <td><para>Mandatory</para></td> <td> <para> <filename>/etc/cinder/nfs_shares</filename> </para> </td> <td> <para> (StrOpt) File with the list of available NFS shares. </para> </td> </tr> <tr> <td><para><code>nexenta_mount_point_base</code></para></td> <td><para>Optional</para></td> <td><para><code>$state_path/mnt</code></para></td> <td> <para> (StrOpt) Base dir where NFS shares are expected to be mounted. </para> </td> </tr> <tr> <td><para><code>nexenta_sparsed_volumes</code></para></td> <td><para>Optional</para></td> <td><para>True</para></td> <td> <para> (BoolOpt) Create volumes as sparsed files which take no space. If set to False, volume is created as regular file. In such case volume creation takes a lot of time. </para> </td> </tr> <tr> <td> <para><code>nexenta_volume_compression</code></para> </td> <td><para>Optional</para></td> <td><para>on</para></td> <td> <para> (StrOpt) ZFS compression value for new volumes. </para> </td> </tr> <tr> <td><para><code>nexenta_mount_options</code></para></td> <td><para>Optional</para></td> <td><para><code>None</code></para></td> <td> <para> (StrOpt) Mount options passed to the NFS client. See section of the nfs man page for details. </para> </td> </tr> <tr> <td><para><code>nexenta_used_ratio</code></para></td> <td><para>Optional</para></td> <td><para><code>0.95</code></para></td> <td> <para> (FloatOpt) Percent of ACTUAL usage of the underlying volume before no new volumes can be allocated to the volume destination. </para> </td> </tr> <tr> <td><para><code>nexenta_oversub_ratio</code></para></td> <td><para>Optional</para></td> <td><para><code>1.0</code></para></td> <td> <para> (FloatOpt) This compares the allocated to available space on the volume destination. If the ratio exceeds this number, the destination is no longer valid. </para> </td> </tr> </tbody> </table> <para> Add your list of Nexenta NFS servers to the file you specified with the nexenta_shares_config option. For example, if the value of this option was set to /etc/cinder/nfs_shares, then: </para> <programlisting> # cat /etc/cinder/nfs_shares 192.168.1.200:/storage http://admin:nexenta@192.168.1.200:2000 192.168.1.201:/storage http://admin:nexenta@192.168.1.201:2000 192.168.1.202:/storage http://admin:nexenta@192.168.1.202:2000 </programlisting> <para> Comments are allowed in this file. They begin with a <code>#</code>. </para> <para> Each line in this file represent NFS share. First part of line is NFS share URL, second is connection URL to NexentaStor Appliance. </para> </section> <!-- / NFS driver section -->",,166,0
openstack%2Fnova~master~I8698997d211d7617ee14a1c6113056a694d70620,openstack/nova,master,I8698997d211d7617ee14a1c6113056a694d70620,add conf for number of conductor workers,MERGED,2013-08-16 13:23:12.000000000,2013-09-06 17:07:22.000000000,2013-09-06 17:07:19.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5600}, {'_account_id': 5638}, {'_account_id': 7500}]","[{'number': 1, 'created': '2013-08-16 13:23:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a934cb55b304069c63e8ad447aa2f13a1749976b', 'message': ""add conf for number of conductor workers\n\nFixes bug #1213080.\n\nMake it easy to launch a bunch of conductor processes on a host.\n\nDeploying multiple conductor workers per host avoids serialization on\ndatabase accesses caused by libmysqlclient.so blocking eventlet's\nsingle thread. In an experiment on a 24-core machine, when creating 20\nVMs in parallel, maximum creation time was reduced by approx. 10s when\nusing 20 conductor processes vis-a-vis a single conductor process.\nProfiling showed that all of the savings came from faster calls into\nnova.db.sqlalchemy.api.\n\nNote that there are alternative methods for preventing the eventlet\nthread from blocking during database calls. However, none of these\nalternatives performed as well as multiple nova-conductor processes.\n\n    * Instead of using the native database driver like _mysql.so, you\n      can use a pure-python driver, like pymysql by setting\n      sql_connection=mysql+pymysql://... in the [DEFAULT] section of\n      /etc/nova/nova.conf, which eventlet will monkeypatch to avoid\n      blocking. The problem with this approach is the vastly greater\n      CPU demand of the pure-python driver compared to the native\n      driver. Since the pure-python driver is so much more CPU\n      intensive, the eventlet thread spends most of its time talking to\n      the database, which effectively the problem we had before!\n\n    * Instead of making database calls from eventlet’s thread, you can\n      submit them to eventlet’s pool of worker threads and wait for the\n      results. Try this by setting dbapi_use_tpool=True in the\n      [DEFAULT] section of /etc/nova/nova.conf.  The problem I found\n      with this approach was the overhead of synchronizing with the\n      worker threads. In particular, the time elapsed between the\n      worker thread finishing and the waiting coroutine being resumed\n      was typically several times greater than the duration of the\n      database call itself.\n\nChange-Id: I8698997d211d7617ee14a1c6113056a694d70620\n""}, {'number': 2, 'created': '2013-08-19 18:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ade2d788b9ea30c3f3a05e70734608c28ad478b', 'message': ""add conf for number of conductor workers\n\nFixes bug #1213080.\n\nMake it easy to launch a bunch of conductor processes on a host.\n\nDeploying multiple conductor workers per host avoids serialization on\ndatabase accesses caused by libmysqlclient.so blocking eventlet's\nsingle thread. In an experiment on a 24-core machine, when creating 20\nVMs in parallel, maximum creation time was reduced by approx. 10s when\nusing 20 conductor processes vis-a-vis a single conductor process.\nProfiling showed that all of the savings came from faster calls into\nnova.db.sqlalchemy.api.\n\nNote that there are alternative methods for preventing the eventlet\nthread from blocking during database calls. However, none of these\nalternatives performed as well as multiple nova-conductor processes.\n\n    * Instead of using the native database driver like _mysql.so, you\n      can use a pure-python driver, like pymysql by setting\n      sql_connection=mysql+pymysql://... in the [DEFAULT] section of\n      /etc/nova/nova.conf, which eventlet will monkeypatch to avoid\n      blocking. The problem with this approach is the vastly greater\n      CPU demand of the pure-python driver compared to the native\n      driver. Since the pure-python driver is so much more CPU\n      intensive, the eventlet thread spends most of its time talking to\n      the database, which effectively the problem we had before!\n\n    * Instead of making database calls from eventlet’s thread, you can\n      submit them to eventlet’s pool of worker threads and wait for the\n      results. Try this by setting dbapi_use_tpool=True in the\n      [DEFAULT] section of /etc/nova/nova.conf.  The problem I found\n      with this approach was the overhead of synchronizing with the\n      worker threads. In particular, the time elapsed between the\n      worker thread finishing and the waiting coroutine being resumed\n      was typically several times greater than the duration of the\n      database call itself.\n\nChange-Id: I8698997d211d7617ee14a1c6113056a694d70620\n""}, {'number': 3, 'created': '2013-08-19 18:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c8a00256d584a9f831f8ecf14e566cf8c0fdf3c4', 'message': ""add conf for number of conductor workers\n\nFixes bug #1213080.\n\nMake it easy to launch a bunch of conductor processes on a host.\n\nDeploying multiple conductor workers per host avoids serialization on\ndatabase accesses caused by libmysqlclient.so blocking eventlet's\nsingle thread. In an experiment on a 24-core machine, when creating 20\nVMs in parallel, maximum creation time was reduced by approx. 10s when\nusing 20 conductor processes vis-a-vis a single conductor process.\nProfiling showed that all of the savings came from faster calls into\nnova.db.sqlalchemy.api.\n\nNote that there are alternative methods for preventing the eventlet\nthread from blocking during database calls. However, none of these\nalternatives performed as well as multiple nova-conductor processes.\n\n    * Instead of using the native database driver like _mysql.so, you\n      can use a pure-python driver, like pymysql by setting\n      sql_connection=mysql+pymysql://... in the [DEFAULT] section of\n      /etc/nova/nova.conf, which eventlet will monkeypatch to avoid\n      blocking. The problem with this approach is the vastly greater\n      CPU demand of the pure-python driver compared to the native\n      driver. Since the pure-python driver is so much more CPU\n      intensive, the eventlet thread spends most of its time talking to\n      the database, which effectively the problem we had before!\n\n    * Instead of making database calls from eventlet’s thread, you can\n      submit them to eventlet’s pool of worker threads and wait for the\n      results. Try this by setting dbapi_use_tpool=True in the\n      [DEFAULT] section of /etc/nova/nova.conf.  The problem I found\n      with this approach was the overhead of synchronizing with the\n      worker threads. In particular, the time elapsed between the\n      worker thread finishing and the waiting coroutine being resumed\n      was typically several times greater than the duration of the\n      database call itself.\n\nChange-Id: I8698997d211d7617ee14a1c6113056a694d70620\n""}, {'number': 4, 'created': '2013-08-21 13:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7cc084013e57b16304a46a51df4c5f5a95fee76', 'message': ""add conf for number of conductor workers\n\nFixes bug #1213080.\n\nMake it easy to launch a bunch of conductor processes on a host.\n\nDeploying multiple conductor workers per host avoids serialization on\ndatabase accesses caused by libmysqlclient.so blocking eventlet's\nsingle thread. In an experiment on a 24-core machine, when creating 20\nVMs in parallel, maximum creation time was reduced by approx. 10s when\nusing 20 conductor processes vis-a-vis a single conductor process.\nProfiling showed that all of the savings came from faster calls into\nnova.db.sqlalchemy.api.\n\nNote that there are alternative methods for preventing the eventlet\nthread from blocking during database calls. However, none of these\nalternatives performed as well as multiple nova-conductor processes.\n\n    * Instead of using the native database driver like _mysql.so, you\n      can use a pure-python driver, like pymysql by setting\n      sql_connection=mysql+pymysql://... in the [DEFAULT] section of\n      /etc/nova/nova.conf, which eventlet will monkeypatch to avoid\n      blocking. The problem with this approach is the vastly greater\n      CPU demand of the pure-python driver compared to the native\n      driver. Since the pure-python driver is so much more CPU\n      intensive, the eventlet thread spends most of its time talking to\n      the database, which effectively the problem we had before!\n\n    * Instead of making database calls from eventlet’s thread, you can\n      submit them to eventlet’s pool of worker threads and wait for the\n      results. Try this by setting dbapi_use_tpool=True in the\n      [DEFAULT] section of /etc/nova/nova.conf.  The problem I found\n      with this approach was the overhead of synchronizing with the\n      worker threads. In particular, the time elapsed between the\n      worker thread finishing and the waiting coroutine being resumed\n      was typically several times greater than the duration of the\n      database call itself.\n\nChange-Id: I8698997d211d7617ee14a1c6113056a694d70620\n""}, {'number': 5, 'created': '2013-09-05 20:08:52.000000000', 'files': ['nova/conductor/api.py', 'etc/nova/nova.conf.sample', 'nova/cmd/conductor.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5450f09370883799fd835fca725a6fb94efcc97c', 'message': ""add conf for number of conductor workers\n\nFixes bug #1213080 and implements blueprint condutor-workers.\n\nMake it easy to launch a bunch of conductor processes on a host.\n\nDeploying multiple conductor workers per host avoids serialization on\ndatabase accesses caused by libmysqlclient.so blocking eventlet's\nsingle thread. In an experiment on a 24-core machine, when creating 20\nVMs in parallel, maximum creation time was reduced by approx. 10s when\nusing 20 conductor processes vis-a-vis a single conductor process.\nProfiling showed that all of the savings came from faster calls into\nnova.db.sqlalchemy.api.\n\nNote that there are alternative methods for preventing the eventlet\nthread from blocking during database calls. However, none of these\nalternatives performed as well as multiple nova-conductor processes.\n\n    * Instead of using the native database driver like _mysql.so, you\n      can use a pure-python driver, like pymysql by setting\n      sql_connection=mysql+pymysql://... in the [DEFAULT] section of\n      /etc/nova/nova.conf, which eventlet will monkeypatch to avoid\n      blocking. The problem with this approach is the vastly greater\n      CPU demand of the pure-python driver compared to the native\n      driver. Since the pure-python driver is so much more CPU\n      intensive, the eventlet thread spends most of its time talking to\n      the database, which effectively the problem we had before!\n\n    * Instead of making database calls from eventlet’s thread, you can\n      submit them to eventlet’s pool of worker threads and wait for the\n      results. Try this by setting dbapi_use_tpool=True in the\n      [DEFAULT] section of /etc/nova/nova.conf.  The problem I found\n      with this approach was the overhead of synchronizing with the\n      worker threads. In particular, the time elapsed between the\n      worker thread finishing and the waiting coroutine being resumed\n      was typically several times greater than the duration of the\n      database call itself.\n\nChange-Id: I8698997d211d7617ee14a1c6113056a694d70620\n""}]",3,42342,5450f09370883799fd835fca725a6fb94efcc97c,39,10,5,7500,,,0,"add conf for number of conductor workers

Fixes bug #1213080 and implements blueprint condutor-workers.

Make it easy to launch a bunch of conductor processes on a host.

Deploying multiple conductor workers per host avoids serialization on
database accesses caused by libmysqlclient.so blocking eventlet's
single thread. In an experiment on a 24-core machine, when creating 20
VMs in parallel, maximum creation time was reduced by approx. 10s when
using 20 conductor processes vis-a-vis a single conductor process.
Profiling showed that all of the savings came from faster calls into
nova.db.sqlalchemy.api.

Note that there are alternative methods for preventing the eventlet
thread from blocking during database calls. However, none of these
alternatives performed as well as multiple nova-conductor processes.

    * Instead of using the native database driver like _mysql.so, you
      can use a pure-python driver, like pymysql by setting
      sql_connection=mysql+pymysql://... in the [DEFAULT] section of
      /etc/nova/nova.conf, which eventlet will monkeypatch to avoid
      blocking. The problem with this approach is the vastly greater
      CPU demand of the pure-python driver compared to the native
      driver. Since the pure-python driver is so much more CPU
      intensive, the eventlet thread spends most of its time talking to
      the database, which effectively the problem we had before!

    * Instead of making database calls from eventlet’s thread, you can
      submit them to eventlet’s pool of worker threads and wait for the
      results. Try this by setting dbapi_use_tpool=True in the
      [DEFAULT] section of /etc/nova/nova.conf.  The problem I found
      with this approach was the overhead of synchronizing with the
      worker threads. In particular, the time elapsed between the
      worker thread finishing and the waiting coroutine being resumed
      was typically several times greater than the duration of the
      database call itself.

Change-Id: I8698997d211d7617ee14a1c6113056a694d70620
",git fetch https://review.opendev.org/openstack/nova refs/changes/42/42342/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conductor/api.py', 'nova/cmd/conductor.py']",2,a934cb55b304069c63e8ad447aa2f13a1749976b,bug/1213080," service.serve(server, workers=CONF.conductor.workers)", service.serve(server),4,1
openstack%2Fopenstack-manuals~master~I3a96ce3965443c73636ff2ba124dfbf51d17af6b,openstack/openstack-manuals,master,I3a96ce3965443c73636ff2ba124dfbf51d17af6b,Add further openSUSE information Install Guide,MERGED,2013-09-05 20:13:01.000000000,2013-09-06 17:06:34.000000000,2013-09-06 17:06:34.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-09-05 20:13:01.000000000', 'files': ['doc/src/docbkx/openstack-install/identity-install-keystone.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7df979add00fd7d5a26378c2e42a62c1b364c65f', 'message': 'Add further openSUSE information Install Guide\n\nThis adds further openSUSE specific information.\n\nChange-Id: I3a96ce3965443c73636ff2ba124dfbf51d17af6b\n'}]",0,45316,7df979add00fd7d5a26378c2e42a62c1b364c65f,5,2,1,6547,,,0,"Add further openSUSE information Install Guide

This adds further openSUSE specific information.

Change-Id: I3a96ce3965443c73636ff2ba124dfbf51d17af6b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/16/45316/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-install/identity-install-keystone.xml'],1,7df979add00fd7d5a26378c2e42a62c1b364c65f,install-identiy," <screen os=""rhel;centos;fedora""><prompt>$</prompt> <userinput>yum install openstack-utils openstack-keystone python-keystoneclient</userinput></screen> <screen os=""opensuse""><prompt>$</prompt> <userinput>zypper install openstack-utils openstack-keystone python-keystoneclient</userinput></screen> <para os=""rhel;centos;fedora;opensuse"">Delete the <filename>keystone.db</filename> file created in <para>On Fedora, RHEL, CentOS, and openSUSE, you can configure the Keystone command.<screen os=""rhel;centos;fedora;opensuse""><prompt>$</prompt> <userinput>sudo openstack-db --init --service keystone</userinput> </screen></para> <screen os=""rhel;centos;fedora;opensuse""><prompt>$</prompt> <userinput>export ADMIN_TOKEN=$(openssl rand -hex 10)</userinput> <screen os=""opensuse""><prompt>#</prompt> <userinput>keystone-manage pki_setup</userinput> <prompt>#</prompt> <userinput>chown -R keystone:keystone /etc/keystone/* /var/log/keystone/keystone.log</userinput></screen> <screen os=""opensuse""><prompt>#</prompt> <userinput>systemctl restart openstack-keystone.service</userinput> <prompt>#</prompt> <userinput>systemctl enable openstack-keystone.service</userinput></screen> <literal>demo</literal> in this example. There is an <parameter>--enabled</parameter>"," <screen os=""rhel;centos;fedora""><prompt>$</prompt> <userinput>yum install openstack-utils openstack-keystone python-keystoneclient</userinput> </screen> <para os=""rhel;centos;fedora"">Delete the <filename>keystone.db</filename> file created in <para>On Fedora, RHEL, and CentOS, you can configure the Keystone command.<screen os=""rhel;centos;fedora""><prompt>$</prompt> <userinput>sudo openstack-db --init --service keystone</userinput> </screen></para> <screen os=""rhel;centos;fedora""><prompt>$</prompt> <userinput>export ADMIN_TOKEN=$(openssl rand -hex 10)</userinput> <literal>demo</literal> in this example. There is an --enabled",11,6
openstack%2Fopenstack-manuals~master~If201d68c1e72a24c57a61775bc22d1784beea324,openstack/openstack-manuals,master,If201d68c1e72a24c57a61775bc22d1784beea324,"Removes openstack-object-storage-admin directory, moving content.",MERGED,2013-09-05 21:30:59.000000000,2013-09-06 17:06:27.000000000,2013-09-06 17:06:27.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-09-05 21:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b8528034438db3fae180498bfd349289d63684a2', 'message': 'Removes openstack-object-storage-admin directory, moving content.\n\nMoves config info to Config Ref\nMoves Admin CLI task to Admin User Guide\nMoves CLI tasks to User Guide\nMoves Monitoring section to Cloud Admin Guide\nRemoves anything that was a copy/paste from dev docs completely, refers\nto developer docs instead\n\nChange-Id: If201d68c1e72a24c57a61775bc22d1784beea324\nCloses-bug: 1216037\n'}, {'number': 2, 'created': '2013-09-06 15:56:50.000000000', 'files': ['doc/src/docbkx/openstack-object-storage-admin/locale/openstack-object-storage-admin.pot', 'doc/src/docbkx/common/section_about-object-storage.xml', 'doc/src/docbkx/openstack-user-admin/src/ch_cli.xml', 'doc/src/docbkx/admin-guide-cloud/section_object-storage-admin.xml', 'doc/src/docbkx/openstack-user/src/section_swift_cli_howto.xml', 'doc/src/docbkx/openstack-object-storage-admin/bk-objectstorage-adminguide.xml', 'doc/src/docbkx/openstack-object-storage-admin/figures/cyberduck_swift_connection.png', 'doc/src/docbkx/openstack-object-storage-admin/objectstorage-config-reference.xml', 'doc/src/docbkx/openstack-object-storage-admin/pom.xml', 'doc/src/docbkx/openstack-object-storage-admin/objectstorageadmin.xml', 'doc/src/docbkx/admin-guide-cloud/bk-admin-guide-cloud.xml', 'doc/src/docbkx/openstack-object-storage-admin/figures/horizon-screenshot.jpg', 'doc/src/docbkx/openstack-config/ch_objectstorageconfigure.xml', 'doc/src/docbkx/admin-guide-cloud/ch_objectstorage.xml', 'doc/src/docbkx/openstack-object-storage-admin/figures/cyberduck_swift_uploads.png', 'doc/src/docbkx/openstack-object-storage-admin/figures/swift_install_arch.svg', 'doc/src/docbkx/admin-guide-cloud/section_object-storage-monitoring.xml', 'doc/src/docbkx/openstack-object-storage-admin/aboutobjectstorage.xml', 'doc/src/docbkx/openstack-object-storage-admin/figures/swift_install_arch.png', 'doc/src/docbkx/openstack-user-admin/src/section_swift_cli_analyze_log_files.xml', 'doc/src/docbkx/openstack-object-storage-admin/objectstoragetutorials.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/82fa21b9d0553f51b13277539d170805b5058e07', 'message': 'Removes openstack-object-storage-admin directory, moving content.\n\nMoves config info to Config Ref\nMoves Admin CLI task to Admin User Guide\nMoves CLI tasks to User Guide\nMoves Monitoring section to Cloud Admin Guide\nRemoves anything that was a copy/paste from dev docs completely, refers\nto developer docs instead\n\nChange-Id: If201d68c1e72a24c57a61775bc22d1784beea324\nCloses-bug: 1216037\n'}]",1,45332,82fa21b9d0553f51b13277539d170805b5058e07,10,4,2,964,,,0,"Removes openstack-object-storage-admin directory, moving content.

Moves config info to Config Ref
Moves Admin CLI task to Admin User Guide
Moves CLI tasks to User Guide
Moves Monitoring section to Cloud Admin Guide
Removes anything that was a copy/paste from dev docs completely, refers
to developer docs instead

Change-Id: If201d68c1e72a24c57a61775bc22d1784beea324
Closes-bug: 1216037
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/32/45332/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-object-storage-admin/locale/openstack-object-storage-admin.pot', 'doc/src/docbkx/openstack-config/object-storage/section_about-object-storage.xml', 'doc/src/docbkx/openstack-user-admin/src/ch_cli.xml', 'doc/src/docbkx/admin-guide-cloud/section_object-storage-admin.xml', 'doc/src/docbkx/openstack-user/src/section_swift_cli_howto.xml', 'doc/src/docbkx/openstack-object-storage-admin/bk-objectstorage-adminguide.xml', 'doc/src/docbkx/openstack-object-storage-admin/figures/cyberduck_swift_connection.png', 'doc/src/docbkx/openstack-object-storage-admin/objectstorage-config-reference.xml', 'doc/src/docbkx/openstack-object-storage-admin/pom.xml', 'doc/src/docbkx/openstack-object-storage-admin/objectstorageadmin.xml', 'doc/src/docbkx/admin-guide-cloud/bk-admin-guide-cloud.xml', 'doc/src/docbkx/openstack-object-storage-admin/figures/horizon-screenshot.jpg', 'doc/src/docbkx/openstack-config/ch_objectstorageconfigure.xml', 'doc/src/docbkx/admin-guide-cloud/ch_objectstorage.xml', 'doc/src/docbkx/openstack-object-storage-admin/figures/cyberduck_swift_uploads.png', 'doc/src/docbkx/openstack-object-storage-admin/figures/swift_install_arch.svg', 'doc/src/docbkx/admin-guide-cloud/section_object-storage-monitoring.xml', 'doc/src/docbkx/openstack-object-storage-admin/aboutobjectstorage.xml', 'doc/src/docbkx/openstack-object-storage-admin/figures/swift_install_arch.png', 'doc/src/docbkx/openstack-user-admin/src/section_swift_cli_analyze_log_files.xml', 'doc/src/docbkx/openstack-object-storage-admin/objectstoragetutorials.xml']",21,b8528034438db3fae180498bfd349289d63684a2,bug/1216037,,"<?xml version=""1.0"" encoding=""UTF-8""?> <chapter xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""ch_openstack-object-storage-tutorials""> <title>OpenStack Object Storage Tutorials</title> <para>We want people to use OpenStack for practical problem solving, and the increasing size and density of web content makes for a great use-case for object storage. These tutorials show you how to use your OpenStack Object Storage installation for practical purposes, and it assumes Object Storage is already installed.</para> <section xml:id=""storing-large-photos-or-videos-on-the-cloud""> <title>Storing Large Photos or Videos on the Cloud</title> <para>In this OpenStack tutorial, we’ll walk through using an Object Storage installation to back up all your photos or videos. As the sensors on consumer-grade and pro-sumer grade cameras generate more and more megapixels, we all need a place to back our files to and know they are safe.</para> <para>We'll go through this tutorial in parts:</para> <itemizedlist> <listitem> <para>Setting up secure access to Object Storage.</para></listitem> <listitem><para>Configuring Cyberduck for connecting to OpenStack Object Storage.</para></listitem> <listitem><para>Copying files to the cloud.</para></listitem> </itemizedlist> <section xml:id=""part-i-setting-up-secure-access""> <title>Part I: Setting Up Secure Access</title> <para>In this part, we'll get the proxy server running with SSL on the Object Storage installation. It's a requirement for using Cyberduck as a client interface to Object Storage.</para> <para>You will need a key and certificate to do this, which we can create as a self-signed for the tutorial since we can do the extra steps to have Cyberduck accept it. Creating a self-signed cert can usually be done with these commands on the proxy server:</para> <screen><prompt>$</prompt> <userinput>cd /etc/swift</userinput> <prompt>$</prompt> <userinput>openssl req -new -x509 -nodes -out cert.crt -keyout cert.key</userinput> </screen> <para>Ensure these generated files are in /etc/swift/cert.crt and /etc/swift/cert.key.</para> <para>You also should configure your iptables to enable https traffic. Here's an example setup that works.</para> <programlisting>Chain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 76774 1543M ACCEPT all -- lo any localhost anywhere 416K 537M ACCEPT all -- any any anywhere anywhere state RELATED,ESTABLISHED 106 6682 ACCEPT tcp -- any any anywhere anywhere tcp dpt:https 13 760 ACCEPT tcp -- any any anywhere anywhere tcp dpt:ssh 3 124 ACCEPT icmp -- any any anywhere anywhere icmp echo-request 782 38880 DROP all -- any any anywhere anywhere Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 0 0 DROP all -- any any anywhere anywhere Chain OUTPUT (policy ACCEPT 397K packets, 1561M bytes) pkts bytes target prot opt in out source destination</programlisting> <para>If you don't have access to the Object Storage installation to configure these settings, ask your service provider to set up secure access for you.</para><para>Then, edit your <filename>proxy-server.conf</filename> file to include the following in the [DEFAULT] sections.</para> <programlisting> [DEFAULT] bind_port = 443 cert_file = /etc/swift/cert.crt key_file = /etc/swift/cert.key </programlisting> <para>Also, make sure you use https: for all references to the URL for the server in the .conf files as needed.</para> <para>Verify that you can connect using the Public URL to Object Storage by using the ""swift"" tool:</para> <para> <screen><prompt>$</prompt> <userinput>swift -A https://yourswiftinstall.com:11000/v1.0 -U test:tester -K testing stat</userinput></screen> </para> <para>Okay, you've created the access that Cyberduck expects for your Object Storage installation. Let's start configuring the Cyberduck side of things.</para> </section> <section xml:id=""part-ii-configuring-cyberduck""> <title>Part II: Configuring Cyberduck</title> <note> <para> See the <link xlink:href=""http://trac.cyberduck.ch/wiki/help/en/howto/openstack"">Cyberduck website</link> for further details. </para> </note> <para> After installing Cyberduck you'll need to change the path/context used for the authentication URL. The default value shipped with Cyberduck is incorrect. </para> <para> On OS X open a Terminal window and execute, <screen><prompt>$</prompt> <userinput>defaults write ch.sudo.cyberduck cf.authentication.context /auth/v1.0</userinput></screen> </para> <para>On Windows open the preferences file in a text editor. The exact location of this file is described <link xlink:href=""http://trac.cyberduck.ch/wiki/help/en/faq#Windows1"" >here</link>. If this path doesn't exist you may need to start and stop Cyberduck to have it generate the config file. Once you've opened the file add the setting, <programlisting>&lt;setting name=""cf.authentication.context"" value=""/auth/v1.0"" /&gt;</programlisting> </para> <para> To connect to Swift start Cyberduck and click the <emphasis>Open Connection</emphasis> toolbar button or choose <emphasis>File > Open Connection</emphasis>. Select <emphasis>Swift (OpenStack Object Storage)</emphasis> in the dropdown and enter your cluster details. <variablelist> <varlistentry> <term>Server</term> <listitem> <para>your proxy server's hostname or IP address</para> </listitem> </varlistentry> <varlistentry> <term>Port</term> <listitem><para>443</para></listitem> </varlistentry> <varlistentry> <term>Username</term> <listitem> <para> account name followed by a colon and then the user name, for example test:tester </para> </listitem> </varlistentry> <varlistentry> <term>Password</term> <listitem> <para> password for the account and user name entered above </para> </listitem> </varlistentry> </variablelist> <figure> <title>Example Cyberduck Swift Connection</title> <mediaobject> <imageobject> <imagedata fileref=""figures/cyberduck_swift_connection.png""/> </imageobject> </mediaobject> </figure> </para> <simplesect> <title>Connecting to a Unsecured Swift Cluster</title> <para>An Unsecured Swift Cluster does not use https connections. Download the <link xlink:href=""http://trac.cyberduck.ch/raw-attachment/wiki/help/en/howto/openstack/Swift%20Unsecure.cyberduckprofile"" >Unsecured Swift profile file</link> and double click it to import it into Cyberduck.</para> <para> When creating a new connection select <emphasis>Swift (HTTP)</emphasis>. Enter your connection details as described above. You'll need to change the port since presumably you won't want to use 443. </para> </simplesect> </section> <section xml:id=""part-iii-copying-files""> <title>Part III: Creating Containers (Folders) and Uploading Files</title> <para>Now you want to create containers to hold your files. Without containers, Object Storage doesn't know where to put the files. In the Action menu, choose New Folder and name the folder.</para> <para>Next you can drag and drop files into the created folder or select File > Upload to select files to upload to the OpenStack Object Storage service. <figure> <title>Example Cyberduck Swift Showing Uploads</title> <mediaobject> <imageobject> <imagedata fileref=""figures/cyberduck_swift_uploads.png""/> </imageobject> </mediaobject> </figure></para><para>Et voila! You can back up terabytes of data if you just have the space and the data. That's a lot of pictures or video, so get snapping and rolling!</para> </section> </section> </chapter> ",256,25948
openstack%2Fnova~master~Id8c2f13ca96908317d271a84fd685104b64f87e9,openstack/nova,master,Id8c2f13ca96908317d271a84fd685104b64f87e9,Avoid errors on some actions when image not usable,MERGED,2013-08-26 21:23:43.000000000,2013-09-06 16:49:11.000000000,2013-09-06 16:49:09.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4468}, {'_account_id': 5511}, {'_account_id': 7069}, {'_account_id': 7808}, {'_account_id': 8029}]","[{'number': 1, 'created': '2013-08-26 21:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1eab3be42c2e117f2ae47ba11d4c20dd4c9df697', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes #1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}, {'number': 2, 'created': '2013-08-26 21:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a37f9c3993d8c40bdb0f9f882e1761aa2e83298', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes bug #1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}, {'number': 3, 'created': '2013-08-26 21:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf66693c85330220eea77e583076059e2438d152', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes bug #1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}, {'number': 4, 'created': '2013-09-02 16:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/331cdc3ad31ac272f274e7f6f3ab3de9dd44d254', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes bug 1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}, {'number': 5, 'created': '2013-09-02 20:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48905f1b142a0b6b7950cd57c4345b727818aca2', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes bug 1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}, {'number': 6, 'created': '2013-09-04 09:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4b1a17041763d24620a5fb3e77e6eca806f1924', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes bug 1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}, {'number': 7, 'created': '2013-09-05 12:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3391ef3291ebbf39d463a1a516ab0f188ae1b205', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes bug 1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}, {'number': 8, 'created': '2013-09-05 13:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eec1a580046adf2f4e48178912b209669509692c', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes bug 1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}, {'number': 9, 'created': '2013-09-05 14:57:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4912ecbf1874aea3956a4bfe6158e28e007cf5c', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes bug 1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}, {'number': 10, 'created': '2013-09-05 16:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6bd12f0a6daa8f76d970fe7798bb5b0d6261dbce', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes bug 1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}, {'number': 11, 'created': '2013-09-06 09:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06e0db3bca601fe820cb98d908f4bfcc2a6958c6', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes bug 1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}, {'number': 12, 'created': '2013-09-06 10:22:02.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/vm_utils.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py', 'nova/virt/powervm/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4389f2292a0177c8eedc0a398ceb3c5535a9ef82', 'message': ""Avoid errors on some actions when image not usable\n\nUsing the metadata saved on instance creation, we can now get all the\nimage related metadata we need from the instance itself.\n\nThis patch replace the logic for getting the image metadata on some\nactions that shouldn't fail when the image is not accessible (create\nan snapshot, resize, migrate, rescue an instance or attach an\ninterface).\n\nFixes bug 1039662\n\nChange-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9\n""}]",0,43784,4389f2292a0177c8eedc0a398ceb3c5535a9ef82,62,11,12,7808,,,0,"Avoid errors on some actions when image not usable

Using the metadata saved on instance creation, we can now get all the
image related metadata we need from the instance itself.

This patch replace the logic for getting the image metadata on some
actions that shouldn't fail when the image is not accessible (create
an snapshot, resize, migrate, rescue an instance or attach an
interface).

Fixes bug 1039662

Change-Id: Id8c2f13ca96908317d271a84fd685104b64f87e9
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/43784/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/virt/xenapi/vm_utils.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py', 'nova/virt/powervm/driver.py']",8,1eab3be42c2e117f2ae47ba11d4c20dd4c9df697,bug/1221200,"from nova.compute import utils as compute_utils image_meta = compute_utils.get_image_metadata( context, glance_service, old_image_id, instance)"," image_meta = glance_service.show(context, old_image_id) img_props = image_meta['properties']",142,104
openstack%2Fnova~master~I2130caf19858585571b1199e27f0a98ad5f08701,openstack/nova,master,I2130caf19858585571b1199e27f0a98ad5f08701,Add methods to get image metadata from instance,MERGED,2013-08-26 21:23:42.000000000,2013-09-06 16:48:39.000000000,2013-09-06 16:48:37.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4468}, {'_account_id': 5511}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-08-26 21:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1016f7b505bc6cedc214fbd15d524925f28c68d', 'message': ""Add methods to get image metadata from instance\n\nThis patch adds a couple of utility functions that enclose all the logic\nfor getting and parsing the image metadata stored in the instance's\nsystem metadata.\n\nFirst, this will try to fetch the metadata from the real image and will\nprevent it from failing if it is not available. It will be then merged\nwith the image metadata stored during the instance creation.\n\nRelated to bug #1039662\n\nChange-Id: I2130caf19858585571b1199e27f0a98ad5f08701\n""}, {'number': 2, 'created': '2013-09-02 16:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/94131344faaaed94a03264714f970fd674f20ed7', 'message': ""Add methods to get image metadata from instance\n\nThis patch adds a couple of utility functions that enclose all the logic\nfor getting and parsing the image metadata stored in the instance's\nsystem metadata.\n\nFirst, this will try to fetch the metadata from the real image and will\nprevent it from failing if it is not available. It will be then merged\nwith the image metadata stored during the instance creation.\n\nRelated to bug #1039662\n\nChange-Id: I2130caf19858585571b1199e27f0a98ad5f08701\n""}, {'number': 3, 'created': '2013-09-02 20:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69abba200096d22222579b7a08c2458b647de8d8', 'message': ""Add methods to get image metadata from instance\n\nThis patch adds a couple of utility functions that enclose all the logic\nfor getting and parsing the image metadata stored in the instance's\nsystem metadata.\n\nFirst, this will try to fetch the metadata from the real image and will\nprevent it from failing if it is not available. It will be then merged\nwith the image metadata stored during the instance creation.\n\nRelated to bug #1039662\n\nChange-Id: I2130caf19858585571b1199e27f0a98ad5f08701\n""}, {'number': 4, 'created': '2013-09-04 09:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b1cd28bbcdeeeabcad050b3b2ee14ae77c3199f7', 'message': ""Add methods to get image metadata from instance\n\nThis patch adds a couple of utility functions that enclose all the logic\nfor getting and parsing the image metadata stored in the instance's\nsystem metadata.\n\nFirst, this will try to fetch the metadata from the real image and will\nprevent it from failing if it is not available. It will be then merged\nwith the image metadata stored during the instance creation.\n\nRelated to bug #1039662\n\nChange-Id: I2130caf19858585571b1199e27f0a98ad5f08701\n""}, {'number': 5, 'created': '2013-09-05 12:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd5c75347793393000a1b6cdd3e1bdb8238b3f01', 'message': ""Add methods to get image metadata from instance\n\nThis patch adds a couple of utility functions that enclose all the logic\nfor getting and parsing the image metadata stored in the instance's\nsystem metadata.\n\nFirst, this will try to fetch the metadata from the real image and will\nprevent it from failing if it is not available. It will be then merged\nwith the image metadata stored during the instance creation.\n\nRelated to bug #1039662\n\nChange-Id: I2130caf19858585571b1199e27f0a98ad5f08701\n""}, {'number': 6, 'created': '2013-09-05 13:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5db55546a7d21574799cc0b476a1241268552dd4', 'message': ""Add methods to get image metadata from instance\n\nThis patch adds a couple of utility functions that enclose all the logic\nfor getting and parsing the image metadata stored in the instance's\nsystem metadata.\n\nFirst, this will try to fetch the metadata from the real image and will\nprevent it from failing if it is not available. It will be then merged\nwith the image metadata stored during the instance creation.\n\nRelated to bug #1039662\n\nChange-Id: I2130caf19858585571b1199e27f0a98ad5f08701\n""}, {'number': 7, 'created': '2013-09-05 14:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69c3cfb2d653cda38f8c502186f37b59fa25bcb9', 'message': ""Add methods to get image metadata from instance\n\nThis patch adds a couple of utility functions that enclose all the logic\nfor getting and parsing the image metadata stored in the instance's\nsystem metadata.\n\nFirst, this will try to fetch the metadata from the real image and will\nprevent it from failing if it is not available. It will be then merged\nwith the image metadata stored during the instance creation.\n\nRelated to bug #1039662\n\nChange-Id: I2130caf19858585571b1199e27f0a98ad5f08701\n""}, {'number': 8, 'created': '2013-09-05 15:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9533f7ad5fab750e2a123d035abf0cdc1b4d827f', 'message': ""Add methods to get image metadata from instance\n\nThis patch adds a couple of utility functions that enclose all the logic\nfor getting and parsing the image metadata stored in the instance's\nsystem metadata.\n\nFirst, this will try to fetch the metadata from the real image and will\nprevent it from failing if it is not available. It will be then merged\nwith the image metadata stored during the instance creation.\n\nRelated to bug #1039662\n\nChange-Id: I2130caf19858585571b1199e27f0a98ad5f08701\n""}, {'number': 9, 'created': '2013-09-05 16:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e77e80385ced778abf20303323ea29b1faf1e968', 'message': ""Add methods to get image metadata from instance\n\nThis patch adds a couple of utility functions that enclose all the logic\nfor getting and parsing the image metadata stored in the instance's\nsystem metadata.\n\nFirst, this will try to fetch the metadata from the real image and will\nprevent it from failing if it is not available. It will be then merged\nwith the image metadata stored during the instance creation.\n\nRelated to bug #1039662\n\nChange-Id: I2130caf19858585571b1199e27f0a98ad5f08701\n""}, {'number': 10, 'created': '2013-09-06 09:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a470d37a79121dcbd33f4aaa5507f45be992c3c', 'message': ""Add methods to get image metadata from instance\n\nThis patch adds a couple of utility functions that enclose all the logic\nfor getting and parsing the image metadata stored in the instance's\nsystem metadata.\n\nFirst, this will try to fetch the metadata from the real image and will\nprevent it from failing if it is not available. It will be then merged\nwith the image metadata stored during the instance creation.\n\nRelated to bug #1039662\n\nChange-Id: I2130caf19858585571b1199e27f0a98ad5f08701\n""}, {'number': 11, 'created': '2013-09-06 10:22:04.000000000', 'files': ['nova/tests/compute/test_compute_utils.py', 'nova/utils.py', 'nova/tests/test_utils.py', 'nova/compute/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8e575be75c80ea71a6ad8fb73e6ace1ed708938f', 'message': ""Add methods to get image metadata from instance\n\nThis patch adds a couple of utility functions that enclose all the logic\nfor getting and parsing the image metadata stored in the instance's\nsystem metadata.\n\nFirst, this will try to fetch the metadata from the real image and will\nprevent it from failing if it is not available. It will be then merged\nwith the image metadata stored during the instance creation.\n\nRelated to bug #1039662\n\nChange-Id: I2130caf19858585571b1199e27f0a98ad5f08701\n""}]",5,43783,8e575be75c80ea71a6ad8fb73e6ace1ed708938f,60,10,11,7808,,,0,"Add methods to get image metadata from instance

This patch adds a couple of utility functions that enclose all the logic
for getting and parsing the image metadata stored in the instance's
system metadata.

First, this will try to fetch the metadata from the real image and will
prevent it from failing if it is not available. It will be then merged
with the image metadata stored during the instance creation.

Related to bug #1039662

Change-Id: I2130caf19858585571b1199e27f0a98ad5f08701
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/43783/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_utils.py', 'nova/utils.py', 'nova/tests/test_utils.py', 'nova/compute/utils.py']",4,c1016f7b505bc6cedc214fbd15d524925f28c68d,bug/1221200,"def get_image_metadata(context, image_service, image_id, instance, db_api=None): # If the base image is still available, get its metadata try: image = image_service.show(context, image_id) except Exception as e: LOG.warning(_(""Can't access image %(image_id)s: %(error)s""), {""image_id"": image_id, ""error"": e}) image_system_meta = {} else: instance_type = flavors.extract_flavor(instance) image_system_meta = utils.get_system_metadata_from_image( image, instance_type) # Get the system metadata from the instance if db_api: system_meta = db_api.instance_system_metadata_get( context, instance['uuid']) else: system_meta = utils.instance_sys_meta(instance) # Merge the metadata from the instance with the image's, if any system_meta.update(image_system_meta) # Convert the system metadata to image metadata return utils.get_image_from_system_metadata(system_meta) ",,205,0
openstack%2Fpython-novaclient~master~Ie30a4c319125c3d4fb704254f8553bc8fd960eae,openstack/python-novaclient,master,Ie30a4c319125c3d4fb704254f8553bc8fd960eae,Update oslo from oslo-incubator,MERGED,2013-09-06 12:03:27.000000000,2013-09-06 16:47:11.000000000,2013-09-06 16:47:10.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-09-06 12:03:27.000000000', 'files': ['novaclient/openstack/common/py3kcompat/urlutils.py', 'novaclient/openstack/common/timeutils.py', 'novaclient/openstack/common/gettextutils.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/cab46172253add86a5a25431a1af4066d29418bc', 'message': 'Update oslo from oslo-incubator\n\nUpdate oslo from oslo-incubator includes various python3\nfixes.\n\nChange-Id: Ie30a4c319125c3d4fb704254f8553bc8fd960eae\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",0,45417,cab46172253add86a5a25431a1af4066d29418bc,6,3,1,24,,,0,"Update oslo from oslo-incubator

Update oslo from oslo-incubator includes various python3
fixes.

Change-Id: Ie30a4c319125c3d4fb704254f8553bc8fd960eae
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/17/45417/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/openstack/common/py3kcompat/urlutils.py', 'novaclient/openstack/common/timeutils.py', 'novaclient/openstack/common/gettextutils.py']",3,cab46172253add86a5a25431a1af4066d29418bc,,"import loggingtry: import UserString as _userString except ImportError: import collections as _userString_AVAILABLE_LANGUAGES = {} USE_LAZY = False def enable_lazy(): """"""Convenience function for configuring _() to use lazy gettext Call this at the start of execution to enable the gettextutils._ function to use lazy gettext functionality. This is useful if your project is importing _ directly instead of using the gettextutils.install() way of importing the _ function. """""" global USE_LAZY USE_LAZY = True if USE_LAZY: return Message(msg, 'novaclient') else: return _t.ugettext(msg)class Message(_userString.UserString, object): return _userString.UserString.__getattribute__(self, name) if domain in _AVAILABLE_LANGUAGES: return copy.copy(_AVAILABLE_LANGUAGES[domain]) language_list = ['en_US'] language_list.append(i) _AVAILABLE_LANGUAGES[domain] = language_list return copy.copy(language_list) if isinstance(message, Message):","import logging.handlersimport UserString_AVAILABLE_LANGUAGES = [] return _t.ugettext(msg)class Message(UserString.UserString, object): return UserString.UserString.__getattribute__(self, name) if _AVAILABLE_LANGUAGES: return _AVAILABLE_LANGUAGES _AVAILABLE_LANGUAGES.append('en_US') _AVAILABLE_LANGUAGES.append(i) return _AVAILABLE_LANGUAGES if (isinstance(message, Message)):",41,13
openstack%2Fdevstack~master~I333501a405fbc552c575d26cfbac083646d05dfd,openstack/devstack,master,I333501a405fbc552c575d26cfbac083646d05dfd,Support OpenSwan in Neturon VPNaaS,MERGED,2013-08-16 01:33:09.000000000,2013-09-06 16:32:58.000000000,2013-09-06 16:32:58.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2031}, {'_account_id': 2750}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-08-16 01:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d0c0e02e4ade5f034940d78c365e8cc07d1692a8', 'message': 'Support OpenSwan in Neturon VPNaaS\n\nCurrently. WIP.\n\nChange-Id: I333501a405fbc552c575d26cfbac083646d05dfd\n'}, {'number': 2, 'created': '2013-09-05 05:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/38d10d5cbb070dc054e08b0cbac4b2ac222a8ba2', 'message': 'Support OpenSwan in Neturon VPNaaS\n\nNeutron VPNaaS chagned ipsec package for\nOpenSwan. This commit updates the package.\n\nChange-Id: I333501a405fbc552c575d26cfbac083646d05dfd\n'}, {'number': 3, 'created': '2013-09-05 05:21:22.000000000', 'files': ['lib/neutron_plugins/services/vpn'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1e3d318c861565ddc26746bed4818daee77e2f47', 'message': 'Support OpenSwan in Neturon VPNaaS\n\nNeutron VPNaaS chagned ipsec package for\nOpenSwan. This commit updates the package.\n\nChange-Id: I333501a405fbc552c575d26cfbac083646d05dfd\n'}]",2,42265,1e3d318c861565ddc26746bed4818daee77e2f47,15,5,3,2031,,,0,"Support OpenSwan in Neturon VPNaaS

Neutron VPNaaS chagned ipsec package for
OpenSwan. This commit updates the package.

Change-Id: I333501a405fbc552c575d26cfbac083646d05dfd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/65/42265/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/services/vpn'],1,d0c0e02e4ade5f034940d78c365e8cc07d1692a8,openswan,"IPSEC_PACKAGE=${IPSEC_PACKAGE:-""strongswan""} install_package $IPSEC_PACKAGE", install_package strongswan,2,1
openstack%2Fdevstack~master~I6619cc02874f6f59c43ba2952325e9d0533e395d,openstack/devstack,master,I6619cc02874f6f59c43ba2952325e9d0533e395d,Rename ceilometer alarm service name,MERGED,2013-09-05 10:43:10.000000000,2013-09-06 16:32:51.000000000,2013-09-06 16:32:51.000000000,"[{'_account_id': 3}, {'_account_id': 595}, {'_account_id': 970}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 2813}, {'_account_id': 4277}, {'_account_id': 4491}, {'_account_id': 4573}, {'_account_id': 4715}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-09-05 10:43:10.000000000', 'files': ['lib/ceilometer'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b53bce1c262e59e1a39b8dd1d2cfcc2ab2e187ef', 'message': 'Rename ceilometer alarm service name\n\nRename service name ""ceilometer-alarm-eval"" to\n""ceilometer-alarm-singleton"" and ""ceilometer-alarm-notify"" to\nceilometer-alarm-notifier"" in this patch.\n\nChange-Id: I6619cc02874f6f59c43ba2952325e9d0533e395d\n'}]",0,45214,b53bce1c262e59e1a39b8dd1d2cfcc2ab2e187ef,9,13,1,7203,,,0,"Rename ceilometer alarm service name

Rename service name ""ceilometer-alarm-eval"" to
""ceilometer-alarm-singleton"" and ""ceilometer-alarm-notify"" to
ceilometer-alarm-notifier"" in this patch.

Change-Id: I6619cc02874f6f59c43ba2952325e9d0533e395d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/14/45214/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceilometer'],1,b53bce1c262e59e1a39b8dd1d2cfcc2ab2e187ef,rename_alarm_service_name,"# enable_service ceilometer-alarm-notifier ceilometer-alarm-singleton screen_it ceilometer-alarm-notifier ""ceilometer-alarm-notifier --config-file $CEILOMETER_CONF"" screen_it ceilometer-alarm-singleton ""ceilometer-alarm-singleton --config-file $CEILOMETER_CONF"" for serv in ceilometer-acompute ceilometer-acentral ceilometer-collector ceilometer-api ceilometer-alarm-notifier ceilometer-alarm-singleton; do","# enable_service ceilometer-alarm-notify ceilometer-alarm-eval screen_it ceilometer-alarm-notify ""ceilometer-alarm-notifier --config-file $CEILOMETER_CONF"" screen_it ceilometer-alarm-eval ""ceilometer-alarm-singleton --config-file $CEILOMETER_CONF"" for serv in ceilometer-acompute ceilometer-acentral ceilometer-collector ceilometer-api ceilometer-alarm-notify ceilometer-alarm-eval; do",4,4
openstack%2Fswift~master~I3af71c64dd4c61e665fe128a0b5241fd87ba71e0,openstack/swift,master,I3af71c64dd4c61e665fe128a0b5241fd87ba71e0,Rename DiskFile.writer to create,MERGED,2013-09-03 14:27:08.000000000,2013-09-06 16:32:49.000000000,2013-09-06 16:32:49.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-09-03 14:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0883a55e7bd34541b9a987bb64d0a953b3f1774a', 'message': 'Rename DiskFile.writer to create\n\nChange-Id: I3af71c64dd4c61e665fe128a0b5241fd87ba71e0\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-09-05 23:49:52.000000000', 'files': ['test/unit/obj/test_auditor.py', 'swift/obj/server.py', 'test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/9e7c56a2c98907c6eb0f4ce41302efd682106f80', 'message': 'Rename DiskFile.writer to create\n\nChange-Id: I3af71c64dd4c61e665fe128a0b5241fd87ba71e0\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",0,44883,9e7c56a2c98907c6eb0f4ce41302efd682106f80,19,5,2,6198,,,0,"Rename DiskFile.writer to create

Change-Id: I3af71c64dd4c61e665fe128a0b5241fd87ba71e0
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/83/44883/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_auditor.py', 'swift/obj/server.py', 'test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py']",4,0883a55e7bd34541b9a987bb64d0a953b3f1774a,create," requests. Serves as the context manager object for DiskFile's create() def create(self, size=None): Context manager to create a file. We create a temporary file first, and with self.create() as writer:"," requests. Serves as the context manager object for DiskFile's writer() def writer(self, size=None): Context manager to write a file. We create a temporary file first, and with self.writer() as writer:",17,17
openstack%2Fdevstack~master~I3f836a701f17a4fea888ec51da62e7137cf0e6db,openstack/devstack,master,I3f836a701f17a4fea888ec51da62e7137cf0e6db,Use 1.4.1 of pip.,MERGED,2013-09-06 14:16:40.000000000,2013-09-06 16:32:18.000000000,2013-09-06 16:32:18.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-09-06 14:16:40.000000000', 'files': ['tools/install_pip.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/5917868e75b0bd1a76bbf0e80eef50645e5b5c96', 'message': 'Use 1.4.1 of pip.\n\n- This is where the option pip install --pre is.\n\nChange-Id: I3f836a701f17a4fea888ec51da62e7137cf0e6db\n'}]",0,45436,5917868e75b0bd1a76bbf0e80eef50645e5b5c96,6,4,1,866,,,0,"Use 1.4.1 of pip.

- This is where the option pip install --pre is.

Change-Id: I3f836a701f17a4fea888ec51da62e7137cf0e6db
",git fetch https://review.opendev.org/openstack/devstack refs/changes/36/45436/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_pip.sh'],1,5917868e75b0bd1a76bbf0e80eef50645e5b5c96,,"INSTALL_PIP_VERSION=${INSTALL_PIP_VERSION:-""1.4.1""}","INSTALL_PIP_VERSION=${INSTALL_PIP_VERSION:-""1.4""}",1,1
openstack%2Frally~master~I3844a29d42fa2bab6b52093636d6cd07e6734ab3,openstack/rally,master,I3844a29d42fa2bab6b52093636d6cd07e6734ab3,Add .gitreview file,MERGED,2013-09-06 15:16:56.000000000,2013-09-06 16:02:31.000000000,2013-09-06 16:02:31.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-09-06 15:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/94dfd23287860db6d63e1376f6ff57d291ca5bb8', 'message': 'Add .gitreview file.\n\nChange-Id: I3844a29d42fa2bab6b52093636d6cd07e6734ab3\n'}, {'number': 2, 'created': '2013-09-06 15:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5f7423753c03902e9acf47aaeef51339481489d9', 'message': 'Add .gitreview file\n\nChange-Id: I3844a29d42fa2bab6b52093636d6cd07e6734ab3\n'}, {'number': 3, 'created': '2013-09-06 15:37:57.000000000', 'files': ['.gitreview', 'rally/benchmark/temp/__init__.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/08d5d95cff1f003df439f5e313c0598738c48372', 'message': 'Add .gitreview file\n\nChange-Id: I3844a29d42fa2bab6b52093636d6cd07e6734ab3\n'}]",0,45443,08d5d95cff1f003df439f5e313c0598738c48372,11,2,3,6172,,,0,"Add .gitreview file

Change-Id: I3844a29d42fa2bab6b52093636d6cd07e6734ab3
",git fetch https://review.opendev.org/openstack/rally refs/changes/43/45443/2 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,94dfd23287860db6d63e1376f6ff57d291ca5bb8,add-gitreview,[gerrit] host=review.openstack.org port=29418 project=stackforge/rally.git ,,4,0
openstack%2Fopenstack-manuals~master~I38bd71af696ba75d21ba837d32a6cf6e466db362,openstack/openstack-manuals,master,I38bd71af696ba75d21ba837d32a6cf6e466db362,Update the dashboard chapter in the Admin User Guide,MERGED,2013-08-30 00:46:55.000000000,2013-09-06 15:52:36.000000000,2013-09-06 15:52:36.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-08-30 00:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3817e0ff4ee10516f89055d3fb5723c694f6ea32', 'message': 'Update the dashboard chapter in the Admin User Guide\n\nbug: #1218649\n\nChange-Id: I38bd71af696ba75d21ba837d32a6cf6e466db362\nauthor: diane fleming\n'}, {'number': 2, 'created': '2013-08-31 22:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/18de200dd6fb08802dc7fad4abff1c1270014011', 'message': 'Update the dashboard chapter in the Admin User Guide\n\nbug: #1218649\n\nChange-Id: I38bd71af696ba75d21ba837d32a6cf6e466db362\nauthor: diane fleming\n'}, {'number': 3, 'created': '2013-08-31 22:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d58b85a9361df39a34d2262182ecf55b2ab85b31', 'message': 'Update the dashboard chapter in the Admin User Guide\n\nbug: #1218649\n\nChange-Id: I38bd71af696ba75d21ba837d32a6cf6e466db362\nauthor: diane fleming\n'}, {'number': 4, 'created': '2013-08-31 22:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/98cf3f11d2d1b02f4208e4dbe6a72a832edee751', 'message': 'Update the dashboard chapter in the Admin User Guide\n\nbug: #1218649\n\nChange-Id: I38bd71af696ba75d21ba837d32a6cf6e466db362\nauthor: diane fleming\n'}, {'number': 5, 'created': '2013-08-31 22:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c78db6860f32323ce091b20a918441754be91a80', 'message': 'Update the dashboard chapter in the Admin User Guide\n\nbug: #1218649\n\nChange-Id: I38bd71af696ba75d21ba837d32a6cf6e466db362\nauthor: diane fleming\n'}, {'number': 6, 'created': '2013-09-05 16:46:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c901afe3a143b404b523fba4c292cec77d873710', 'message': 'Update the dashboard chapter in the Admin User Guide\n\nbug: #1218649\n\nChange-Id: I38bd71af696ba75d21ba837d32a6cf6e466db362\nauthor: diane fleming\n'}, {'number': 7, 'created': '2013-09-05 16:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6b29e44a9f63b4033020b4f531dacdcff3c5a122', 'message': 'Update the dashboard chapter in the Admin User Guide\n\nbug: #1218649\n\nChange-Id: I38bd71af696ba75d21ba837d32a6cf6e466db362\nauthor: diane fleming\n'}, {'number': 8, 'created': '2013-09-05 20:04:02.000000000', 'files': ['doc/src/docbkx/openstack-user-admin/src/section_dashboard_manage_images.xml', 'doc/src/docbkx/openstack-user/src/ch_dashboard.xml', 'doc/src/docbkx/openstack-user-admin/src/ch_dashboard.xml', 'doc/src/docbkx/openstack-user/src/section_dashboard_manage_instances.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_admin_manage_volumes.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_manage_projects_users.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_manage_flavors.xml', 'doc/src/docbkx/common/section_dashboard_manage_images.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_set_quotas.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_admin_manage_images.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_admin_manage_flavors.xml', 'doc/src/docbkx/openstack-user/src/section_dashboard_manage_volumes.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_admin_manage_projects_users.xml', 'doc/src/docbkx/openstack-user-admin/src/bk-admin-user-guide.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_admin_set_quotas.xml', 'doc/src/docbkx/common/section_dashboard_access.xml', 'doc/src/docbkx/openstack-user-admin/src/section_cinder_cli_manage_volumes.xml', 'doc/src/docbkx/openstack-user/src/section_dashboard_manage_images.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_admin_manage_instances.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_admin_manage_services.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d5baa108c40bcbf84c30603c900c71e2b1816d14', 'message': 'Update the dashboard chapter in the Admin User Guide\n\nbug: #1218649\n\nChange-Id: I38bd71af696ba75d21ba837d32a6cf6e466db362\nauthor: diane fleming\n'}]",2,44381,d5baa108c40bcbf84c30603c900c71e2b1816d14,27,4,8,2448,,,0,"Update the dashboard chapter in the Admin User Guide

bug: #1218649

Change-Id: I38bd71af696ba75d21ba837d32a6cf6e466db362
author: diane fleming
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/81/44381/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-user-admin/src/bk-admin-user-guide.xml', 'doc/src/docbkx/openstack-user-admin/src/ch_dashboard.xml', 'doc/src/docbkx/common/section_dashboard_access.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_manage_projects_users.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_manage_flavors.xml', 'doc/src/docbkx/common/section_dashboard_manage_images.xml', 'doc/src/docbkx/openstack-user-admin/src/section_dashboard_set_quotas.xml']",7,3817e0ff4ee10516f89055d3fb5723c694f6ea32,1218640," <?dbhtml_stop-chunking?> the number of gigabytes allowed for each project. Quotas are currently enforced at the project, or tenant, level rather than at the user level.</para> <para>Typically, you change quotas when a project needs more than 10 volumes or 1 TB on a Compute node.</para> <table rules=""all"" width=""75%""> <th>Defines the number of</th> <para>Metadata items allowed for each instance.</para> <para><systemitem class=""service"" >Compute</systemitem></para> <para>Instance cores allowed for each project.</para> <para><systemitem class=""service"" >Compute</systemitem></para> <para>Instances allowed for each project.</para> <para><systemitem class=""service"" >Compute</systemitem></para> <para>Injected files allowed for each project.</para> <para><systemitem class=""service"" >Compute</systemitem></para> <para>Content bytes allowed for each injected file.</para> <para><systemitem class=""service"" >Compute</systemitem></para> <para>Volumes allowed for each project.</para> <para><systemitem class=""service"">Block Storage</systemitem></para> <para>Volume GBs allowed for each project.</para> <para><systemitem class=""service"">Block Storage</systemitem></para> <para>MBs of RAM allowed for each instance.</para> <para><systemitem class=""service"" >Compute</systemitem></para> <para>Floating IP addresses allowed for each project.</para> <para><systemitem class=""service"" >Compute</systemitem></para> <para>Fixed IP addresses allowed for each project. This number must be equal to or greater than the number of allowed instances.</para> <para><systemitem class=""service"" >Compute</systemitem></para> <para>Security groups allowed for each project.</para> <para><systemitem class=""service"" >Compute</systemitem></para> <para>Rules allowed for each security group.</para> <para><systemitem class=""service"" >Compute</systemitem></para> </para> <para>As an administrative user, you can set quotas when you <xref linkend=""dashboard_create_project""/> or update quotas for an <section xml:id=""dashboard_view_project_quotas""> <title>View default project quotas</title> <procedure> <step> <para>Log in to the OpenStack dashboard and choose the <guilabel>admin</guilabel> project from the <guilabel>CURRENT PROJECT</guilabel> drop-down list.</para> </step> <step> <para>On the <guilabel>Admin</guilabel> tab, click the <guilabel>System Info</guilabel> category.</para> </step> <step> <para>Click the <guilabel>Default Quotas</guilabel> tab to view the default quotas for the Compute and Block Storage services.</para> </step> </procedure> </section> <section xml:id=""dashboard_project_quotas""> <title>Update project quotas</title> <procedure> <step> <para>On the <guilabel>Admin</guilabel> tab, click the <guilabel>Projects</guilabel> category.</para> </step> <step> <para>Select the project to change its quota values.</para> </step> <step> <para>In the <guilabel>More</guilabel> drop-down list, click <guilabel>Modify Quotas</guilabel>.</para> </step> <step> <para>On the <guilabel>Quota</guilabel> tab in the <guilabel>Edit Project</guilabel> window, edit quota values. Then, click <guibutton>Save</guibutton>.</para> </step> </procedure> <note> <para>The dashboard does not show all possible project quotas. To view and update the quotas for a service, use the keystone command-line client. See <xref linkend=""cli_set_quotas""/>.</para> </note> </section></section> "," <?dbhtml stop-chunking?> the number of gigabytes allowed for each project, also known as a tenant. Quotas are currently enforced at the project level rather than at the user level.</para> <para>Typically, you change default values because a project requires more than 10 volumes, or more than 1 TB on a Compute node.</para> <table rules=""all"" width=""624""> <th>Description</th> <para>Number of metadata items allowed per instance.</para> <para><systemitem class=""service"">Compute</systemitem></para> <para>Number of instance cores allowed per tenant.</para> <para><systemitem class=""service"">Compute</systemitem></para> <para>Number of instances allowed per tenant.</para> <para><systemitem class=""service"">Compute</systemitem></para> <para>Number of injected files allowed per tenant.</para> <para><systemitem class=""service"">Compute</systemitem></para> <para>Number of content bytes allowed per injected file.</para> <para><systemitem class=""service"">Compute</systemitem></para> <para>Number of volumes allowed per tenant.</para> <para><systemitem class=""service"">Block Storage</systemitem></para> <para>Number of volume gigabtyes allowed per tenant.</para> <para><systemitem class=""service"">Block Storage</systemitem></para> <para>Megabytes of ram allowed per instance.</para> <para><systemitem class=""service"">Compute</systemitem></para> <para>Number of floating IP addresses allowed per tenant.</para> <para><systemitem class=""service"">Compute</systemitem></para> <para>Number of fixed IP addresses allowed per tenant. This number must be equal to or greater than the number of allowed instances.</para> <para><systemitem class=""service"">Compute</systemitem></para> <para>Number of security groups allowed per tenant.</para> <para><systemitem class=""service"">Compute</systemitem></para> <para>Number of rules per security group.</para> <para><systemitem class=""service"">Compute</systemitem></para> </para> <para>As an administrative user in the dashboard, you can set quotas when you <xref linkend=""dashboard_create_project""/> or update quotas for an <procedure> <title>To view default quotas</title> <step> <para>On the <guilabel>Admin</guilabel> tab in the navigation sidebar, click the <guilabel>System Info</guilabel> category.</para> </step> <step> <para>Click the <guilabel>Default Quotas</guilabel> tab in the main page.</para> </step> </procedure> <procedure> <title>To update project quotas</title> <step> <para>On the <guilabel>Admin</guilabel> tab in the navigation sidebar, click the <guilabel>Projects</guilabel> category.</para> </step> <step> <para>Select the project for which to change quota values.</para> </step> <step> <para>From the <guilabel>More</guilabel> drop-down list, click <guilabel>Modify Quotas</guilabel>.</para> </step> <step> <para>On the <guilabel>Quota</guilabel> tab in the <guilabel>Edit Project</guilabel> window, edit quota values. Then, click <guibutton>Save</guibutton>.</para> </step> </procedure> <note> <para>Not all possible project quotas are displayed in the dashboard. To obtain and update the complete list for a service, use the keystone command-line client. See <xref linkend=""cli_set_quotas""/>.</para> </note></section>",732,360
openstack%2Fsahara~master~Ic134dc9200dcf1b424b5e7ccabd72a1a029c696e,openstack/sahara,master,Ic134dc9200dcf1b424b5e7ccabd72a1a029c696e,"Trusts for longrunning tasks:  * Create trusts from current user to savanna user when cluster is created  * Auth savanna user with trust  * use savanna user with trust for nova and cinder, when cluster is deleted",ABANDONED,2013-08-30 16:20:32.000000000,2013-09-06 15:06:27.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6823}, {'_account_id': 7213}, {'_account_id': 7600}]","[{'number': 1, 'created': '2013-08-30 16:20:32.000000000', 'files': ['savanna/context.py', 'savanna/utils/openstack/cinder.py', 'savanna/utils/openstack/nova.py', 'savanna/utils/openstack/keystone.py', 'savanna/main.py', 'savanna/service/instances.py', 'savanna/service/trusts.py', 'savanna/service/periodic.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/7b8a56154a73986b316f1813230358c86ea34048', 'message': 'Trusts for longrunning tasks:\n * Create trusts from current user to savanna user when cluster is created\n * Auth savanna user with trust\n * use savanna user with trust for nova and cinder, when cluster is deleted\n\nChange-Id: Ic134dc9200dcf1b424b5e7ccabd72a1a029c696e\n'}]",4,44493,7b8a56154a73986b316f1813230358c86ea34048,5,5,1,7729,,,0,"Trusts for longrunning tasks:
 * Create trusts from current user to savanna user when cluster is created
 * Auth savanna user with trust
 * use savanna user with trust for nova and cinder, when cluster is deleted

Change-Id: Ic134dc9200dcf1b424b5e7ccabd72a1a029c696e
",git fetch https://review.opendev.org/openstack/sahara refs/changes/93/44493/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/context.py', 'savanna/utils/openstack/cinder.py', 'savanna/utils/openstack/nova.py', 'savanna/main.py', 'savanna/utils/openstack/keystone.py', 'savanna/service/instances.py', 'savanna/service/periodic.py', 'savanna/service/trusts.py']",8,7b8a56154a73986b316f1813230358c86ea34048,,"# Copyright (c) 2013 Mirantis Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import pdb import json from oslo.config import cfg from savanna import conductor as c from savanna import context from savanna.utils.openstack import keystone conductor = c.API CONF = cfg.CONF def create_trust(cluster): client = keystone.client_v3(auth_url=get_auth_url()) trust = client.trusts.create(trustor_user=client.user_id, trustee_user=CONF.savanna_username, impersonation=True, project=client.tenant_id) conductor.cluster_update(context.current(), cluster, {'trust_id': trust.id}) def get_auth_url(): return ""%s:%s/v3"" % (CONF.os_auth_host, CONF.os_auth_port) def auth_savanna_token(cluster): if cluster.trust_id: client = keystone.client_v3( username=CONF.savanna_username, password=CONF.savanna_password, tenant=cluster.tenant_id, trust_id=cluster.trust_id, auth_url=get_auth_url()) ctx = context.current() ctx.service['username'] = CONF.savanna_username ctx.service['auth-token'] = client.auth_token ctx.service['tenant-id'] = cluster.tenant_id ctx.service['X-Service-Catalog'] = json.dumps( client.service_catalog.catalog['catalog']) def delete_trust(cluster): keystone_client = keystone.client_v3() keystone_client.trusts.delete(cluster.trust_id)",,174,11
openstack%2Foperations-guide~master~I555f43b8ffdb2d3592592d484b12c1c702f4eef4,openstack/operations-guide,master,I555f43b8ffdb2d3592592d484b12c1c702f4eef4,upgrade: check for deleted instances,MERGED,2013-08-10 01:16:46.000000000,2013-09-06 15:00:11.000000000,2013-09-06 15:00:11.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 1112}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-08-10 01:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/1f8d3c6066eada60a789569b390fac5beb6063b0', 'message': ""upgrade: check for deleted instances\n\nAs noted during recent Folsom->Grizzly upgrade\ndiscussion, it's a good idea to check for this.\n\nChange-Id: I555f43b8ffdb2d3592592d484b12c1c702f4eef4\n""}, {'number': 2, 'created': '2013-08-10 01:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/bf541b981dbb5d2dfdadf510900741c97f462e84', 'message': ""upgrade: check for deleted instances\n\nAs noted during recent Folsom->Grizzly upgrade\ndiscussion, it's a good idea to check for this.\n\nChange-Id: I555f43b8ffdb2d3592592d484b12c1c702f4eef4\n""}, {'number': 3, 'created': '2013-09-04 21:33:53.000000000', 'files': ['doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/a4593656119afda742be866117250308bfb58623', 'message': ""upgrade: check for deleted instances\n\nAs noted during recent Folsom->Grizzly upgrade\ndiscussion, it's a good idea to check for this.\n\nChange-Id: I555f43b8ffdb2d3592592d484b12c1c702f4eef4\n""}]",0,41226,a4593656119afda742be866117250308bfb58623,26,6,3,612,,,0,"upgrade: check for deleted instances

As noted during recent Folsom->Grizzly upgrade
discussion, it's a good idea to check for this.

Change-Id: I555f43b8ffdb2d3592592d484b12c1c702f4eef4
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/26/41226/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml'],1,1f8d3c6066eada60a789569b390fac5beb6063b0,41226, <para>Performing some 'cleaning' of the cluster prior to starting the upgrade is also a good idea. For example some have reported issues with instances that were not fully removed from the system after their deletion. Running a command equivalent to: <screen><prompt>$</prompt> <userinput>virsh list --all</userinput></screen> to find deleted instances that are still registered in the hypervisor and removing them prior to running the upgrade can avoid issues. </para>,,10,0
openstack%2Fpython-zaqarclient~master~I1e56f44c370a444b99bd2a60ebe2d3843a9648b6,openstack/python-zaqarclient,master,I1e56f44c370a444b99bd2a60ebe2d3843a9648b6,Added support for running the tests under PyPy with tox,MERGED,2013-08-28 17:41:46.000000000,2013-09-06 14:50:03.000000000,2013-09-06 14:50:03.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6944}, {'_account_id': 8257}]","[{'number': 1, 'created': '2013-08-28 17:41:46.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/fa7ff0a7df008f69e12e11d32263ec0039c2fa70', 'message': 'Added support for running the tests under PyPy with tox\n\nThis is a precursor to having them run under check and gate.\n\nChange-Id: I1e56f44c370a444b99bd2a60ebe2d3843a9648b6\n'}]",0,44104,fa7ff0a7df008f69e12e11d32263ec0039c2fa70,9,5,1,7680,,,0,"Added support for running the tests under PyPy with tox

This is a precursor to having them run under check and gate.

Change-Id: I1e56f44c370a444b99bd2a60ebe2d3843a9648b6
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/04/44104/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,fa7ff0a7df008f69e12e11d32263ec0039c2fa70,tox-pypy,"envlist = py26,py27,py33,pypy,pep8","envlist = py26,py27,py33,pep8",1,1
openstack%2Fneutron~master~Id502cfbc210c6c3fe0a256d5350e159ffa220141,openstack/neutron,master,Id502cfbc210c6c3fe0a256d5350e159ffa220141,Replace assertEquals with assertEqual,MERGED,2013-09-06 07:28:35.000000000,2013-09-06 14:49:52.000000000,2013-09-06 14:49:52.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6072}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-09-06 07:28:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad08c92081aa6070387e9f844c4fbd51227a772a', 'message': 'Replace assertEquals with assertEqual\n\nThe method assertEquals has been deprecated since python 2.7.\nhttp://docs.python.org/2/library/unittest.html#deprecated-aliases\n\nAlso in Python 3, a deprecated warning is raised when using assertEquals\ntherefore we should use assertEqual instead.\n\nChange-Id: Id502cfbc210c6c3fe0a256d5350e159ffa220141\n'}, {'number': 2, 'created': '2013-09-06 08:19:56.000000000', 'files': ['neutron/tests/unit/test_iptables_manager.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/902dc88b4c511859f164fed4c4ac8ce0c60b09ee', 'message': 'Replace assertEquals with assertEqual\n\nThe method assertEquals has been deprecated since python 2.7.\nhttp://docs.python.org/2/library/unittest.html#deprecated-aliases\n\nAlso in Python 3, a deprecated warning is raised when using assertEquals\ntherefore we should use assertEqual instead.\n\nFixes bug #1221601\n\nChange-Id: Id502cfbc210c6c3fe0a256d5350e159ffa220141\n'}]",0,45385,902dc88b4c511859f164fed4c4ac8ce0c60b09ee,13,7,2,1994,,,0,"Replace assertEquals with assertEqual

The method assertEquals has been deprecated since python 2.7.
http://docs.python.org/2/library/unittest.html#deprecated-aliases

Also in Python 3, a deprecated warning is raised when using assertEquals
therefore we should use assertEqual instead.

Fixes bug #1221601

Change-Id: Id502cfbc210c6c3fe0a256d5350e159ffa220141
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/45385/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_iptables_manager.py', 'neutron/tests/unit/test_l3_agent.py']",2,ad08c92081aa6070387e9f844c4fbd51227a772a,assert_equal," self.assertEqual(args, ('snat', '-j $float-snat')) self.assertEqual(kwargs, {})"," self.assertEquals(args, ('snat', '-j $float-snat')) self.assertEquals(kwargs, {})",6,6
openstack%2Fneutron~master~I614716c45d91cdf152650fba5ec8ced1e9c5aad4,openstack/neutron,master,I614716c45d91cdf152650fba5ec8ced1e9c5aad4,Load ML2 mech drivers as listed in ml2_conf.ini,MERGED,2013-09-06 12:52:02.000000000,2013-09-06 14:45:36.000000000,2013-09-06 14:45:36.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6694}]","[{'number': 1, 'created': '2013-09-06 12:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4fa89a532e92895c71d0562593e911890ee8928e', 'message': 'ML2 mechanism drivers should be loaded as listed in the ml2_conf.ini file.\n\nstevedore requires an additional parameter to be used (name_order=True) to\nsort the loaded extensions to match the order used in the parameter ""names"".\n\nbug 1221490\n\nChange-Id: I614716c45d91cdf152650fba5ec8ced1e9c5aad4\n'}, {'number': 2, 'created': '2013-09-06 13:29:21.000000000', 'files': ['neutron/plugins/ml2/managers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5bae5828d3ae5e614c88c5c0f1ffa768a1228feb', 'message': 'Load ML2 mech drivers as listed in ml2_conf.ini\n\nstevedore requires an additional parameter to be used (name_order=True) to\nsort the loaded extensions to match the order used in the parameter ""names"".\n\nbug 1221490\n\nChange-Id: I614716c45d91cdf152650fba5ec8ced1e9c5aad4\n'}]",0,45420,5bae5828d3ae5e614c88c5c0f1ffa768a1228feb,17,8,2,6694,,,0,"Load ML2 mech drivers as listed in ml2_conf.ini

stevedore requires an additional parameter to be used (name_order=True) to
sort the loaded extensions to match the order used in the parameter ""names"".

bug 1221490

Change-Id: I614716c45d91cdf152650fba5ec8ced1e9c5aad4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/45420/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/managers.py'],1,4fa89a532e92895c71d0562593e911890ee8928e,bug/1221490," invoke_on_load=True, name_order=True)", invoke_on_load=True),2,1
openstack%2Fzaqar~master~I8b5cfee1cc6f185ebf53e98fad95a5fc30e021da,openstack/zaqar,master,I8b5cfee1cc6f185ebf53e98fad95a5fc30e021da,fix(storage.mongodb): Race condition when creating a claim,MERGED,2013-09-05 18:32:37.000000000,2013-09-06 14:44:09.000000000,2013-09-06 14:44:08.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 7044}, {'_account_id': 8093}, {'_account_id': 8497}]","[{'number': 1, 'created': '2013-09-05 18:32:37.000000000', 'files': ['marconi/storage/mongodb/claims.py', 'marconi/storage/mongodb/messages.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/8d544d643dfa79634813052292bfeacf9a268be9', 'message': 'fix(storage.mongodb): Race condition when creating a claim\n\nThis patch forces MessageController.claimed to always query the primary in\norder to resolve a race condition in ClaimController.create. The latter\nmethod tags a batch of messages with a claim ID, then immediately\ncalles claimed() to get a list of messages that were actually updated.\n\nMessageController.claimed is also used by ClaimController.update, so that\nrequest will no longer read from secondaries either. This shouldn\'t put\nmuch more load on the primary, and may even be desired behavior in the case\nthat a client creates a claim and immediately attempts to update it, in\nwhich case they could get a ""not found"" if the new claim hasn\'t propagated\nyet to the secondary being queried.\n\nChange-Id: I8b5cfee1cc6f185ebf53e98fad95a5fc30e021da\nPartial-Bug: #1218990\n'}]",2,45299,8d544d643dfa79634813052292bfeacf9a268be9,11,6,1,6427,,,0,"fix(storage.mongodb): Race condition when creating a claim

This patch forces MessageController.claimed to always query the primary in
order to resolve a race condition in ClaimController.create. The latter
method tags a batch of messages with a claim ID, then immediately
calles claimed() to get a list of messages that were actually updated.

MessageController.claimed is also used by ClaimController.update, so that
request will no longer read from secondaries either. This shouldn't put
much more load on the primary, and may even be desired behavior in the case
that a client creates a claim and immediately attempts to update it, in
which case they could get a ""not found"" if the new claim hasn't propagated
yet to the secondary being queried.

Change-Id: I8b5cfee1cc6f185ebf53e98fad95a5fc30e021da
Partial-Bug: #1218990
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/99/45299/1 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/storage/mongodb/claims.py', 'marconi/storage/mongodb/messages.py']",2,8d544d643dfa79634813052292bfeacf9a268be9,bug/1218990-alt,"import pymongo.read_preferences # NOTE(kgriffs): Claimed messages bust be queried from # the primary to avoid a race condition caused by the # multi-phased ""create claim"" algorithm. preference = pymongo.read_preferences.ReadPreference.PRIMARY msgs = self._col.find(query, sort=[('k', 1)], read_preference=preference)"," msgs = self._col.find(query, sort=[('k', 1)])",13,1
openstack%2Fcinder~master~I68f614164803729ea26e65f8868b0031e724d324,openstack/cinder,master,I68f614164803729ea26e65f8868b0031e724d324,Fixes misuse of assertTrue in test scripts,MERGED,2013-09-06 04:14:10.000000000,2013-09-06 14:38:58.000000000,2013-09-06 14:38:57.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2417}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 5997}]","[{'number': 1, 'created': '2013-09-06 04:14:10.000000000', 'files': ['cinder/tests/brick/test_brick_connector.py', 'cinder/tests/brick/test_brick_linuxscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b2e0f75ddaea0c12e154432da7a860725af8e344', 'message': ""Fixes misuse of assertTrue in test scripts\n\nMisuse of assertTrue in places where assertEqual should be used.\n\nIf assertTrue is used instead of assertEquals, the test will always pass\nif the first argument's boolean cast is True. The second argument\npassed to assertTrue() will be regarded as the error message\nwhen the assertion fails. Using assertEqual will actually check\nif two arguments are same value.\n\nFixes bug #1221517\n\nChange-Id: I68f614164803729ea26e65f8868b0031e724d324\n""}]",0,45370,b2e0f75ddaea0c12e154432da7a860725af8e344,7,6,1,1994,,,0,"Fixes misuse of assertTrue in test scripts

Misuse of assertTrue in places where assertEqual should be used.

If assertTrue is used instead of assertEquals, the test will always pass
if the first argument's boolean cast is True. The second argument
passed to assertTrue() will be regarded as the error message
when the assertion fails. Using assertEqual will actually check
if two arguments are same value.

Fixes bug #1221517

Change-Id: I68f614164803729ea26e65f8868b0031e724d324
",git fetch https://review.opendev.org/openstack/cinder refs/changes/70/45370/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/brick/test_brick_connector.py', 'cinder/tests/brick/test_brick_linuxscsi.py']",2,b2e0f75ddaea0c12e154432da7a860725af8e344,bug/1221517," self.assertEqual(name, device_name)"," self.assertTrue(name, device_name)",6,11
openstack%2Fceilometer~master~I28c28fe94703d55d06696315e66de02597f17d83,openstack/ceilometer,master,I28c28fe94703d55d06696315e66de02597f17d83,Fix wrong index in 10 migration for mysql,ABANDONED,2013-08-30 20:08:43.000000000,2013-09-06 14:20:07.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 6507}]","[{'number': 1, 'created': '2013-08-30 20:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/df0d4849c129e8ce46caca7eb7f03e991b919e66', 'message': 'Fix wrong migrations\n\nErrors was found in migrations during testing of models with migrations\non different versions of different backends.\nBugs consist in:\n1) for some of version in mysql we can get an error\n""Specified key was too long; max key length is 1000 bytes"";\n2) for some of  alembic migrations a rollback for failed transaction\n   is missing.\n\nThis patch fixes wrong migration.\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I28c28fe94703d55d06696315e66de02597f17d83\n'}, {'number': 2, 'created': '2013-09-02 07:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a3897bd9c36e1b9f5ed145276b5e91b9d7de2bf0', 'message': 'Fix wrong migrations\n\nErrors was found in migrations during testing of models with migrations\non different versions of different backends.\nBugs consist in:\n1) for some of version in mysql we can get an error\n""Specified key was too long; max key length is 1000 bytes"";\n2) for some of  alembic migrations a rollback for failed transaction\n   is missing.\n\nThis patch fixes wrong migration.\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I28c28fe94703d55d06696315e66de02597f17d83\n'}, {'number': 3, 'created': '2013-09-02 09:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8cee300557601d5c0e70b6480f7da3ddda94b81d', 'message': 'Fix wrong migrations\n\nErrors was found in migrations during testing of models with migrations\non different versions of different backends.\nBugs consist in:\n1) for some of version in mysql we can get an error\n""Specified key was too long; max key length is 1000 bytes"";\n2) for some of  alembic migrations a rollback for failed transaction\n   is missing.\n\nThis patch fixes wrong migration.\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I28c28fe94703d55d06696315e66de02597f17d83\n'}, {'number': 4, 'created': '2013-09-03 11:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/391722bedae62b9b10bc1660f99564d4c361ad50', 'message': 'Fix wrong migrations\n\nErrors was found in migrations during testing of models with migrations\non different versions of different backends.\nBugs consist in:\n1) for some of version in mysql we can get an error\n""Specified key was too long; max key length is 1000 bytes"";\n2) for some of  alembic migrations a rollback for failed transaction\n   is missing.\n\nThis patch fixes wrong migration.\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I28c28fe94703d55d06696315e66de02597f17d83\n'}, {'number': 5, 'created': '2013-09-03 12:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2063d5426c7cb98beed216e24c396edeab752e72', 'message': 'Fix wrong migrations\n\nErrors was found in migrations during testing of models with migrations\non different versions of different backends.\nBugs consist in:\n1) for some of version in mysql we can get an error\n""Specified key was too long; max key length is 1000 bytes"";\n2) for some of  alembic migrations a rollback for failed transaction\n   is missing.\n\nThis patch fixes wrong migration.\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I28c28fe94703d55d06696315e66de02597f17d83\n'}, {'number': 6, 'created': '2013-09-05 08:55:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/68e02cc236edb1eb316aaf77f342ff6cbe61cc92', 'message': 'Fix wrong migrations\n\nErrors was found in migration during testing of models with migrations\non different versions of different backends.\nBug consist in:\n- for some of version in mysql we can get an error\n""Specified key was too long; max key length is 1000 bytes"".\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I28c28fe94703d55d06696315e66de02597f17d83\n'}, {'number': 7, 'created': '2013-09-05 08:57:20.000000000', 'files': ['ceilometer/storage/sqlalchemy/migrate_repo/versions/010_add_index_to_meter.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d0aef1ec1c7a804661d1d711f26213d1bcc6ef10', 'message': 'Fix wrong index in 10 migration for mysql\n\nErrors was found in migration during testing of models with migrations\non different versions of different backends.\nBug consist in:\n- for some of version in mysql we can get an error\n""Specified key was too long; max key length is 1000 bytes"".\n\nbp: ceilometer-db-sync-models-with-migrations\n\nChange-Id: I28c28fe94703d55d06696315e66de02597f17d83\n'}]",1,44539,d0aef1ec1c7a804661d1d711f26213d1bcc6ef10,29,5,7,6507,,,0,"Fix wrong index in 10 migration for mysql

Errors was found in migration during testing of models with migrations
on different versions of different backends.
Bug consist in:
- for some of version in mysql we can get an error
""Specified key was too long; max key length is 1000 bytes"".

bp: ceilometer-db-sync-models-with-migrations

Change-Id: I28c28fe94703d55d06696315e66de02597f17d83
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/39/44539/4 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/sqlalchemy/alembic/versions/b6ae66d05e3_remove_extra_indexes.py', 'ceilometer/storage/sqlalchemy/alembic/versions/2c3ccda5a3ad_fix_uniq_name.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/010_add_index_to_meter.py']",3,df0d4849c129e8ce46caca7eb7f03e991b919e66,bp/ceilometer-db-sync-models-with-migrations,"from sqlalchemy import Index, MetaData, Table TABLE_NAME = 'meter' INDEX_NAME = 'idx_meter_rid_cname' COLUMNS = ('resource_id', 'counter_name') COLUMNS_MYSQL = (c + ""(100)"" for c in COLUMNS) table = Table(TABLE_NAME, meta, autoload=True) if migrate_engine.name != 'mysql': index = Index( INDEX_NAME, *[getattr(table.c, col) for col in COLUMNS] ) index.create() else: sql = (""create index %s ON %s (%s)"" % (INDEX_NAME, table, "","".join(COLUMNS_MYSQL))) migrate_engine.execute(sql) table = Table(TABLE_NAME, meta, autoload=True) if migrate_engine.name != 'mysql': index = Index( INDEX_NAME, *[getattr(table.c, col) for col in COLUMNS] ) index.drop() else: for idx in getattr(table, 'indexes'): if idx.name == INDEX_NAME: break else: raise Exception(""Index '%s' not found!"" % INDEX_NAME) idx.drop(migrate_engine) table.indexes.remove(idx)","from sqlalchemy import MetaData from sqlalchemy import Index from ceilometer.storage.sqlalchemy.models import Meter index = Index('idx_meter_rid_cname', Meter.resource_id, Meter.counter_name) index.create(bind=migrate_engine) index = Index('idx_meter_rid_cname', Meter.resource_id, Meter.counter_name) index.drop(bind=migrate_engine)",43,13
openstack%2Fnova~stable%2Ffolsom~I2f0e88435748bab631d969573d3a598d9e1f7fef,openstack/nova,stable/folsom,I2f0e88435748bab631d969573d3a598d9e1f7fef,Fix problem with long messages in Qpid (from oslo),MERGED,2013-09-06 13:18:18.000000000,2013-09-06 14:18:11.000000000,2013-09-06 14:18:09.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1812}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-09-06 13:18:18.000000000', 'files': ['nova/openstack/common/rpc/impl_qpid.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ef5730a4620b409a3b46e46966e3bc6f3a306464', 'message': 'Fix problem with long messages in Qpid (from oslo)\n\nThis is commit 478ac3a3e in oslo-incubator\n\nQpid has a limitation where it cannot serialize a dict containing a\nstring greater than 65535 characters. This change alters the Qpid\nimplementation to JSON encode the dict before sending it, but only if\nQpid would fail to serialize it. This maintains as much backward\ncompatibility as possible, though long messages will still fail if they\nare sent to an older receiver.\n\nEven though this change will modify the message format, it will only do\nit when messages are longer than 65K which would be broken anyway and\ncould cause serious bugs like the one linked below.\n\nFixes bug 1215091\n\nChange-Id: I2f0e88435748bab631d969573d3a598d9e1f7fef\n'}]",0,45426,ef5730a4620b409a3b46e46966e3bc6f3a306464,7,4,1,7808,,,0,"Fix problem with long messages in Qpid (from oslo)

This is commit 478ac3a3e in oslo-incubator

Qpid has a limitation where it cannot serialize a dict containing a
string greater than 65535 characters. This change alters the Qpid
implementation to JSON encode the dict before sending it, but only if
Qpid would fail to serialize it. This maintains as much backward
compatibility as possible, though long messages will still fail if they
are sent to an older receiver.

Even though this change will modify the message format, it will only do
it when messages are longer than 65K which would be broken anyway and
could cause serious bugs like the one linked below.

Fixes bug 1215091

Change-Id: I2f0e88435748bab631d969573d3a598d9e1f7fef
",git fetch https://review.opendev.org/openstack/nova refs/changes/26/45426/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/openstack/common/rpc/impl_qpid.py'],1,ef5730a4620b409a3b46e46966e3bc6f3a306464,bug/1215091,"import qpid.codec010 as qpid_codecJSON_CONTENT_TYPE = 'application/json; charset=utf8' def _unpack_json_msg(self, msg): """"""Load the JSON data in msg if msg.content_type indicates that it is necessary. Put the loaded data back into msg.content and update msg.content_type appropriately. A Qpid Message containing a dict will have a content_type of 'amqp/map', whereas one containing a string that needs to be converted back from JSON will have a content_type of JSON_CONTENT_TYPE. :param msg: a Qpid Message object :returns: None """""" if msg.content_type == JSON_CONTENT_TYPE: msg.content = jsonutils.loads(msg.content) msg.content_type = 'amqp/map' self._unpack_json_msg(message) def _pack_json_msg(self, msg): """"""Qpid cannot serialize dicts containing strings longer than 65535 characters. This function dumps the message content to a JSON string, which Qpid is able to handle. :param msg: May be either a Qpid Message object or a bare dict. :returns: A Qpid Message with its content field JSON encoded. """""" try: msg.content = jsonutils.dumps(msg.content) except AttributeError: # Need to have a Qpid message so we can set the content_type. msg = qpid.messaging.Message(jsonutils.dumps(msg)) msg.content_type = JSON_CONTENT_TYPE return msg try: # Check if Qpid can encode the message check_msg = msg if not hasattr(check_msg, 'content_type'): check_msg = qpid.messaging.Message(msg) content_type = check_msg.content_type enc, dec = qpid.messaging.message.get_codec(content_type) enc(check_msg.content) except qpid_codec.CodecException: # This means the message couldn't be serialized as a dict. msg = self._pack_json_msg(msg)",,47,0
openstack%2Fdevstack~master~Ie0f5c66f635b4a7c6ba51581ad01bab624158e61,openstack/devstack,master,Ie0f5c66f635b4a7c6ba51581ad01bab624158e61,Fix Heat's signing_dir,MERGED,2013-09-06 02:12:55.000000000,2013-09-06 14:17:10.000000000,2013-09-06 14:17:09.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-09-06 02:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/cc25c815c7b887e6e6b0d729448822700ede9a6f', 'message': ""Fix Heat's signing_dir\n\nThis is not critical but looks odd using api-cfn.\n\nChange-Id: Ie0f5c66f635b4a7c6ba51581ad01bab624158e61\n""}, {'number': 2, 'created': '2013-09-06 03:35:33.000000000', 'files': ['lib/heat'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e118655028bfb093c5dd0cde4d615a23a0abbc7c', 'message': ""Fix Heat's signing_dir\n\nThis is not critical but looks odd using api-cfn.\n\nChange-Id: Ie0f5c66f635b4a7c6ba51581ad01bab624158e61\n""}]",1,45364,e118655028bfb093c5dd0cde4d615a23a0abbc7c,11,6,2,4715,,,0,"Fix Heat's signing_dir

This is not critical but looks odd using api-cfn.

Change-Id: Ie0f5c66f635b4a7c6ba51581ad01bab624158e61
",git fetch https://review.opendev.org/openstack/devstack refs/changes/64/45364/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/heat'],1,cc25c815c7b887e6e6b0d729448822700ede9a6f,master, iniset $HEAT_CONF keystone_authtoken signing_dir $HEAT_AUTH_CACHE_DIR, iniset $HEAT_CONF keystone_authtoken signing_dir $HEAT_AUTH_CACHE_DIR/api-cfn sudo mkdir -p $HEAT_AUTH_CACHE_DIR/api-cfn sudo chown $STACK_USER $HEAT_AUTH_CACHE_DIR/api-cfn sudo mkdir -p $HEAT_AUTH_CACHE_DIR/api-cloudwatch sudo chown $STACK_USER $HEAT_AUTH_CACHE_DIR/api-cloudwatch,1,5
openstack%2Ftempest~master~I60ee8947be27bc850ebccdd6b24b155214099439,openstack/tempest,master,I60ee8947be27bc850ebccdd6b24b155214099439,Fix colon in create volume logging output,MERGED,2013-09-05 00:52:43.000000000,2013-09-06 14:16:04.000000000,2013-09-06 14:16:04.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5586}, {'_account_id': 5803}]","[{'number': 1, 'created': '2013-09-05 00:52:43.000000000', 'files': ['tempest/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2d26f1bde821c9f07f8db87f893f340b6e421fa6', 'message': 'Fix colon in create volume logging output\n\nThis colon was misplaced.\n\nChange-Id: I60ee8947be27bc850ebccdd6b24b155214099439\n'}]",1,45149,2d26f1bde821c9f07f8db87f893f340b6e421fa6,8,5,1,159,,,0,"Fix colon in create volume logging output

This colon was misplaced.

Change-Id: I60ee8947be27bc850ebccdd6b24b155214099439
",git fetch https://review.opendev.org/openstack/tempest refs/changes/49/45149/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/manager.py'],1,2d26f1bde821c9f07f8db87f893f340b6e421fa6,fix-colon-create-volume," LOG.debug(""Creating a volume (size: %s, name: %s)"", size, name)"," LOG.debug(""Creating a volume (size :%s, name: %s)"", size, name)",1,1
openstack%2Ftempest~master~If7816e534200c54826c1da0d0464f643163b8657,openstack/tempest,master,If7816e534200c54826c1da0d0464f643163b8657,"Add device name, ssh password to Tempest config",MERGED,2013-09-04 04:49:34.000000000,2013-09-06 14:15:45.000000000,2013-09-06 14:15:45.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 7139}, {'_account_id': 8302}]","[{'number': 1, 'created': '2013-09-04 04:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a4741a9b52ec725e7698b6d5193fe2f2ca379aff', 'message': 'Moves hardcoded device name and ssh password in attach volumes test to config\n\nThe test_attach_volumes tests currently hardcode the values for:\n\n1) ssh password used to access instance with attached volume\n2) expected device name for an attached volume\n\nThe values are now taken from the values ""ssh_password"" and\n""volume_device_name"" in the Tempest configuration file\n\nCloses-Bug: #1220514\n\nChange-Id: If7816e534200c54826c1da0d0464f643163b8657\n'}, {'number': 2, 'created': '2013-09-04 04:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/60f7adb386274126a3620ad454cc20083da7471e', 'message': 'Move hardcoded values in test_attach_volumes to Tempest configuration\n\nThe test_attach_volumes tests currently hardcode the values for:\n  1) ssh password used to access instance with attached volume\n  2) expected device name for an attached volume\nThe hardcoded values have been removed and are now retrieved from the\noptions ""ssh_password"" and ""volume_device_name"" in the compute group of\nthe Tempest configuration.\n\nCloses-Bug: #1220514\nChange-Id: If7816e534200c54826c1da0d0464f643163b8657\n'}, {'number': 3, 'created': '2013-09-04 05:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b0eda4ac76ab446133e6f37aceb3ee5c865641d2', 'message': 'Move hardcoded values in test_attach_volumes to Tempest configuration\n\nThe test_attach_volumes tests currently hardcode the values for:\n  1) ssh password used to access instance with attached volume\n  2) expected device name for an attached volume\nThe hardcoded values have been removed and are now retrieved from the\noptions ""ssh_password"" and ""volume_device_name"" in the compute group of\nthe Tempest configuration.\n\nCloses-Bug: #1220514\nChange-Id: If7816e534200c54826c1da0d0464f643163b8657\n'}, {'number': 4, 'created': '2013-09-06 01:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3c2597b7ddbca2c5f37c3b1a1d19dec8801e8d96', 'message': 'Add volume device name and ssh user password options to Tempest configuration\n\nThe following options have been added to the compute section of the\nTempest configuration:\n\n- image_ssh_password\n- image_alt_ssh_password\n- volume_device_name\n\nThe ""volume_device_name"" is being added to rid the test_attach_volume\ntest of hardcoded data. In the effort to remove a hardcoded password\nfrom the same test, we introduce the option ""image_ssh_password"" to\nstore the password instead. Then, the deprecated ""ssh_user"" in the\ntest is swapped out in favor of ""image_ssh_user"". Finally, we add an\n""image_alt_ssh_password"" so the option remains symmetrical to the\n""image_ssh_password"" option.\n\nCloses-Bug: #1220514\nChange-Id: If7816e534200c54826c1da0d0464f643163b8657\n'}, {'number': 5, 'created': '2013-09-06 02:28:47.000000000', 'files': ['tempest/api/compute/base.py', 'etc/tempest.conf.sample', 'tempest/config.py', 'tempest/api/compute/volumes/test_attach_volume.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/cb2e12505adafc5aa47df360507e0dc7441f5fa8', 'message': 'Add device name, ssh password to Tempest config\n\nThe following options have been added to the compute section of the\nTempest configuration:\n\n- image_ssh_password\n- image_alt_ssh_password\n- volume_device_name\n\nThe ""volume_device_name"" is being added to rid the test_attach_volume\ntest of hardcoded data. In the effort to remove a hardcoded password\nfrom the same test, we introduce the option ""image_ssh_password"" to\nstore the password instead. Then, the deprecated ""ssh_user"" in the\ntest is swapped out in favor of ""image_ssh_user"". Finally, we add an\n""image_alt_ssh_password"" so the option remains symmetrical to the\n""image_ssh_password"" option.\n\nCloses-Bug: #1220514\nChange-Id: If7816e534200c54826c1da0d0464f643163b8657\n'}]",2,45003,cb2e12505adafc5aa47df360507e0dc7441f5fa8,22,5,5,8302,,,0,"Add device name, ssh password to Tempest config

The following options have been added to the compute section of the
Tempest configuration:

- image_ssh_password
- image_alt_ssh_password
- volume_device_name

The ""volume_device_name"" is being added to rid the test_attach_volume
test of hardcoded data. In the effort to remove a hardcoded password
from the same test, we introduce the option ""image_ssh_password"" to
store the password instead. Then, the deprecated ""ssh_user"" in the
test is swapped out in favor of ""image_ssh_user"". Finally, we add an
""image_alt_ssh_password"" so the option remains symmetrical to the
""image_ssh_password"" option.

Closes-Bug: #1220514
Change-Id: If7816e534200c54826c1da0d0464f643163b8657
",git fetch https://review.opendev.org/openstack/tempest refs/changes/03/45003/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/base.py', 'etc/tempest.conf.sample', 'tempest/config.py', 'tempest/api/compute/volumes/test_attach_volume.py']",4,a4741a9b52ec725e7698b6d5193fe2f2ca379aff,unhardcode_test_attach_volume, device = tempest.config.TempestConfig().compute.volume_device_name adminPass=self.ssh_password), cls.device = 'vdb' adminPass='password'),16,3
openstack%2Fopenstack-manuals~master~Id905d9ad57f7e967a3e595b400f40678f157b6d0,openstack/openstack-manuals,master,Id905d9ad57f7e967a3e595b400f40678f157b6d0,modication including sets,MERGED,2013-09-04 20:37:32.000000000,2013-09-06 14:02:48.000000000,2013-09-06 14:02:47.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 964}, {'_account_id': 5222}, {'_account_id': 6547}, {'_account_id': 6923}]","[{'number': 1, 'created': '2013-09-04 20:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e527b92cf88b71a063a44acce64499b76dc68318', 'message': 'modication including sets\n\nset added as superset to book, chapter, and section.\n\nblueprint training-manuals\n\nChange-Id: Id905d9ad57f7e967a3e595b400f40678f157b6d0\n'}, {'number': 2, 'created': '2013-09-04 20:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5729cfff7e468acbed04eab1cc1a9a7aa7ccc79c', 'message': 'modication including sets\n\nset added as superset to book, chapter, and section.\n\nadds st-training-guides.xml to validation exception.\n\nblueprint training-manuals\n\nChange-Id: Id905d9ad57f7e967a3e595b400f40678f157b6d0\n'}, {'number': 3, 'created': '2013-09-05 22:19:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7a61d0fbe271a84d3191fc740f76f6bf2d3e12da', 'message': 'modication including sets\n\nset added as superset to book, chapter, and section.\nadds st-training-guides.xml to validation exception.\n\nblueprint training-manuals\n\nChange-Id: Id905d9ad57f7e967a3e595b400f40678f157b6d0\n'}, {'number': 4, 'created': '2013-09-06 13:28:49.000000000', 'files': ['doc/src/docbkx/openstack-training/bk004-ch003-architect-general.xml', 'doc/src/docbkx/openstack-training/bk002-ch002-operator-getting-started.xml', 'doc/src/docbkx/openstack-training/bk001-ch002-associate-getting-started.xml', 'tools/validate.py', 'doc/src/docbkx/openstack-training/operator-editing-code.xml', 'doc/src/docbkx/openstack-training/under-contruction-notice.xml', 'doc/src/docbkx/openstack-training/bk002-ch008-operator-assessment.xml', 'doc/src/docbkx/openstack-training/bk004-devops-training-guide.xml', 'doc/src/docbkx/openstack-training/bk002-ch003-operator-general.xml', 'doc/src/docbkx/openstack-training/bk003-ch003-developer-general.xml', 'doc/src/docbkx/openstack-training/bk004-ch010-architect-assessment.xml', 'doc/src/docbkx/openstack-training/bk003-ch002-developer-getting-started.xml', 'doc/src/docbkx/openstack-training/bk003-ch001-developer-what-does-this-book-intend-to-teach.xml', 'doc/src/docbkx/openstack-training/bk002-ch001-operator-what-does-this-book-intend-to-teach.xml', 'doc/src/docbkx/openstack-training/bk001-ch001-associate-what-does-this-book-intend-to-teach.xml', 'doc/src/docbkx/openstack-training/bk003-developer-training-guide.xml', 'doc/src/docbkx/openstack-training/bk004-ch001-architect-what-does-this-book-intend-to-teach.xml', 'doc/src/docbkx/openstack-training/bk001-ch003-associate-general.xml', 'doc/src/docbkx/openstack-training/bk002-operator-training-guide.xml', 'doc/src/docbkx/openstack-training/bk004-architect-training-guide.xml', 'doc/src/docbkx/openstack-training/bk002-operations-training-guide.xml', 'doc/src/docbkx/openstack-training/bk004-ch002-architect-getting-started.xml', 'doc/src/docbkx/openstack-training/bk000-preface.xml', 'doc/src/docbkx/openstack-training/bk001-ch004-associate-assessment.xml', 'doc/src/docbkx/openstack-training/bk003-ch010-developer-assessment.xml', 'doc/src/docbkx/openstack-training/st-training-guides.xml', 'doc/src/docbkx/openstack-training/bk001-associate-training-guide.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c7772f9d2293d8a78d2a1ab5f0e089a2ba9cfd45', 'message': 'modication including sets\n\nset added as superset to book, chapter, and section.\nadds st-training-guides.xml to validation exception.\n\nRevises XML editing steps to reflect that floating licenses are out\n\nblueprint training-manuals\n\nChange-Id: Id905d9ad57f7e967a3e595b400f40678f157b6d0\n'}]",0,45119,c7772f9d2293d8a78d2a1ab5f0e089a2ba9cfd45,16,6,4,6923,,,0,"modication including sets

set added as superset to book, chapter, and section.
adds st-training-guides.xml to validation exception.

Revises XML editing steps to reflect that floating licenses are out

blueprint training-manuals

Change-Id: Id905d9ad57f7e967a3e595b400f40678f157b6d0
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/19/45119/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-training/bk000-preface.xml', 'doc/src/docbkx/openstack-training/st-training-guides.xml', 'doc/src/docbkx/openstack-training/under-contruction-notice.xml', 'doc/src/docbkx/openstack-training/bk001-associate-training-guide.xml']",4,e527b92cf88b71a063a44acce64499b76dc68318,bp/training-manuals," xml:id=""bk001-associate-training-guide""> <xi:include href=""bk001-ch001-associate-what-does-this-book-intend-to-teach.xml""/> <xi:include href=""bk001-ch002-associate-getting-started.xml""/> <xi:include href=""bk001-ch003-associate-general.xml""/> <xi:include href=""bk001-ch004-associate-assessment.xml""/>"," xml:id=""bk002-associate-training-guide""> <xi:include href=""bk002-ch001-associate-getting-started.xml""/> <xi:include href=""bk002-ch050-associate-assessment.xml""/>",18,28
openstack%2Ftripleo-ci~master~I21af8f1c8b7803ccdb32a1de6654f84efc3c19cd,openstack/tripleo-ci,master,I21af8f1c8b7803ccdb32a1de6654f84efc3c19cd,"Remove wait for ""Updating host status""",MERGED,2013-09-06 09:47:31.000000000,2013-09-06 13:58:42.000000000,2013-09-06 13:58:42.000000000,"[{'_account_id': 3}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-09-06 09:47:31.000000000', 'files': ['toci_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7c6c82ef6f956b92acdb473c2e2fcc19bc466484', 'message': 'Remove wait for ""Updating host status""\n\nAs of I749204d7d6461993d0c42bf5877b65c5ec17c62f this message is no\nlonger reported, testing suggests we no longer need to wait for it.\nIn fact it would appear the sleep statements after these lines are also\nno longer required, I\'ll also remove these if further testing proves\nthis to be true.\n\nChange-Id: I21af8f1c8b7803ccdb32a1de6654f84efc3c19cd\n'}]",0,45409,7c6c82ef6f956b92acdb473c2e2fcc19bc466484,5,2,1,1926,,,0,"Remove wait for ""Updating host status""

As of I749204d7d6461993d0c42bf5877b65c5ec17c62f this message is no
longer reported, testing suggests we no longer need to wait for it.
In fact it would appear the sleep statements after these lines are also
no longer required, I'll also remove these if further testing proves
this to be true.

Change-Id: I21af8f1c8b7803ccdb32a1de6654f84efc3c19cd
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/09/45409/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_test.sh'],1,7c6c82ef6f956b92acdb473c2e2fcc19bc466484,remove-wait, wait_for 40 10 ssh_noprompt root@$SEED_IP grep 'record\\ updated\\ for' /var/log/upstart/nova-compute.log wait_for 40 10 ssh_noprompt root@$SEED_IP journalctl -u nova-compute -u openstack-nova-compute \| grep \'record updated for\' wait_for 40 10 ssh_noprompt heat-admin@$UNDERCLOUD_IP grep 'record\\ updated\\ for' /var/log/upstart/nova-compute.log wait_for 40 10 ssh_noprompt heat-admin@$UNDERCLOUD_IP sudo journalctl -u nova-compute -u openstack-nova-compute \| grep \'record updated for\', wait_for 40 10 ssh_noprompt root@$SEED_IP grep 'record\\ updated\\ for' /var/log/upstart/nova-compute.log -A 100 \| grep \'Updating host status\' wait_for 40 10 ssh_noprompt root@$SEED_IP journalctl -u nova-compute -u openstack-nova-compute \| grep \'record updated for\' -A 100 \| grep \'Updating host status\' wait_for 40 10 ssh_noprompt heat-admin@$UNDERCLOUD_IP grep 'record\\ updated\\ for' /var/log/upstart/nova-compute.log -A 100 \| grep \'Updating host status\' wait_for 40 10 ssh_noprompt heat-admin@$UNDERCLOUD_IP sudo journalctl -u nova-compute -u openstack-nova-compute \| grep \'record updated for\' -A 100 \| grep \'Updating host status\',4,4
openstack%2Fopenstack-manuals~master~Id03d30c1a645fc93b14c08d6e69d25fd67bff241,openstack/openstack-manuals,master,Id03d30c1a645fc93b14c08d6e69d25fd67bff241,Fix whitespace,MERGED,2013-09-05 17:44:36.000000000,2013-09-06 13:58:34.000000000,2013-09-06 13:58:34.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 5201}, {'_account_id': 6547}, {'_account_id': 6657}, {'_account_id': 8574}]","[{'number': 1, 'created': '2013-09-05 17:44:36.000000000', 'files': ['doc/src/docbkx/common/section_compute-configure-spice.xml', 'doc/src/docbkx/openstack-config/block-storage/drivers/emc-volume-driver.xml', 'doc/src/docbkx/admin-guide-cloud/ch_networking.xml', 'doc/src/docbkx/admin-guide-cloud/ch_dashboard.xml', 'doc/src/docbkx/openstack-training/operator-editing-code.xml', 'doc/src/docbkx/admin-guide-cloud/bk-admin-guide-cloud.xml', 'doc/src/docbkx/openstack-config/compute/section_compute-configure-service-groups.xml', 'doc/src/docbkx/admin-guide-cloud/ch_objectstorage.xml', 'doc/src/docbkx/openstack-user/src/section_nova_cli_config-drive.xml', 'doc/src/docbkx/admin-guide-cloud/ch_compute.xml', 'doc/src/docbkx/openstack-config/block-storage/drivers/nfs-volume-driver.xml', 'doc/src/docbkx/openstack-config/block-storage/drivers/hp-lefthand-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e525e51e40e40085270cb2e37ebec71ad3a042eb', 'message': 'Fix whitespace\n\nRemove extra whitespace, replace tabs by spaces\n\nChange-Id: Id03d30c1a645fc93b14c08d6e69d25fd67bff241\n'}]",0,45287,e525e51e40e40085270cb2e37ebec71ad3a042eb,20,6,1,6547,,,0,"Fix whitespace

Remove extra whitespace, replace tabs by spaces

Change-Id: Id03d30c1a645fc93b14c08d6e69d25fd67bff241
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/87/45287/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/common/section_compute-configure-spice.xml', 'doc/src/docbkx/openstack-config/block-storage/drivers/emc-volume-driver.xml', 'doc/src/docbkx/admin-guide-cloud/ch_networking.xml', 'doc/src/docbkx/admin-guide-cloud/ch_dashboard.xml', 'doc/src/docbkx/openstack-training/operator-editing-code.xml', 'doc/src/docbkx/admin-guide-cloud/bk-admin-guide-cloud.xml', 'doc/src/docbkx/openstack-config/compute/section_compute-configure-service-groups.xml', 'doc/src/docbkx/admin-guide-cloud/ch_objectstorage.xml', 'doc/src/docbkx/openstack-user/src/section_nova_cli_config-drive.xml', 'doc/src/docbkx/admin-guide-cloud/ch_compute.xml', 'doc/src/docbkx/openstack-config/block-storage/drivers/nfs-volume-driver.xml', 'doc/src/docbkx/openstack-config/block-storage/drivers/hp-lefthand-driver.xml']",12,e525e51e40e40085270cb2e37ebec71ad3a042eb,whitespace, Console.</para>, Console. </para>,311,318
openstack%2Fpython-zaqarclient~master~I40b053e5487348f524753db517b79bf4ca81d569,openstack/python-zaqarclient,master,I40b053e5487348f524753db517b79bf4ca81d569,"Revert ""Add apiclient library""",MERGED,2013-08-20 19:10:46.000000000,2013-09-06 13:57:43.000000000,2013-09-06 13:57:43.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6943}, {'_account_id': 6944}]","[{'number': 1, 'created': '2013-08-20 19:10:46.000000000', 'files': ['marconiclient/openstack/common/importutils.py', 'marconiclient/common/apiclient/auth/keystone.py', 'marconiclient/openstack/common/timeutils.py', 'tests/common/apiclient/auth/test_response.py', 'marconiclient/openstack/common/strutils.py', 'marconiclient/openstack/__init__.py', 'tests/common/apiclient/auth/test_base.py', 'marconiclient/common/apiclient/auth/endpoint.py', 'marconiclient/common/apiclient/auth/base.py', 'requirements.txt', 'tests/common/apiclient/test_exceptions.py', 'marconiclient/common/apiclient/base.py', 'marconiclient/common/apiclient/fake_client.py', 'marconiclient/common/apiclient/client.py', 'openstack-common.conf', 'tests/common/apiclient/auth/test_nova.py', 'marconiclient/openstack/common/gettextutils.py', 'marconiclient/common/apiclient/auth/nova.py', 'marconiclient/openstack/common/__init__.py', 'tests/common/apiclient/auth/__init__.py', 'tests/common/apiclient/__init__.py', 'marconiclient/common/apiclient/exceptions.py', 'marconiclient/common/apiclient/auth/__init__.py', 'marconiclient/common/cliutils.py', 'tests/utils.py', 'tests/common/apiclient/test_client.py', 'tests/common/test_cliutils.py', 'marconiclient/common/apiclient/auth/response.py', 'marconiclient/common/__init__.py', 'tests/common/apiclient/auth/test_keystone.py', 'tests/common/apiclient/test_base.py', 'tests/common/__init__.py', 'setup.cfg', 'marconiclient/common/apiclient/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/78d9a06dd8d03d9ee2233efb4c544d3e7473e3fa', 'message': 'Revert ""Add apiclient library""\n\nThis reverts commit 4b9b0139641f0e85805783d69dfc3650885cd24a.\n\nRationale: the apiclient library needs many fixes and updates that we\nare not able to address at this time. In the future, we may consider\nreturning to using it, but for now, we will implement a base\nconnection module from which this client will be able to speak to\nmarconi servers.\n\nChange-Id: I40b053e5487348f524753db517b79bf4ca81d569\n'}]",0,42976,78d9a06dd8d03d9ee2233efb4c544d3e7473e3fa,8,4,1,6944,,,0,"Revert ""Add apiclient library""

This reverts commit 4b9b0139641f0e85805783d69dfc3650885cd24a.

Rationale: the apiclient library needs many fixes and updates that we
are not able to address at this time. In the future, we may consider
returning to using it, but for now, we will implement a base
connection module from which this client will be able to speak to
marconi servers.

Change-Id: I40b053e5487348f524753db517b79bf4ca81d569
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/76/42976/1 && git format-patch -1 --stdout FETCH_HEAD,"['marconiclient/openstack/common/importutils.py', 'marconiclient/common/apiclient/auth/keystone.py', 'marconiclient/openstack/common/timeutils.py', 'tests/common/apiclient/auth/test_response.py', 'marconiclient/openstack/common/strutils.py', 'marconiclient/openstack/__init__.py', 'tests/common/apiclient/auth/test_base.py', 'marconiclient/common/apiclient/auth/endpoint.py', 'marconiclient/common/apiclient/auth/base.py', 'requirements.txt', 'tests/common/apiclient/test_exceptions.py', 'marconiclient/common/apiclient/base.py', 'marconiclient/common/apiclient/fake_client.py', 'marconiclient/common/apiclient/client.py', 'openstack-common.conf', 'tests/common/apiclient/auth/test_nova.py', 'marconiclient/openstack/common/gettextutils.py', 'marconiclient/common/apiclient/auth/nova.py', 'marconiclient/openstack/common/__init__.py', 'tests/common/apiclient/auth/__init__.py', 'tests/common/apiclient/__init__.py', 'marconiclient/common/apiclient/exceptions.py', 'marconiclient/common/apiclient/auth/__init__.py', 'marconiclient/common/cliutils.py', 'tests/utils.py', 'tests/common/apiclient/test_client.py', 'tests/common/test_cliutils.py', 'marconiclient/common/apiclient/auth/response.py', 'marconiclient/common/__init__.py', 'tests/common/apiclient/auth/test_keystone.py', 'tests/common/apiclient/test_base.py', 'tests/common/__init__.py', 'setup.cfg', 'marconiclient/common/apiclient/__init__.py']",34,78d9a06dd8d03d9ee2233efb4c544d3e7473e3fa,revert_apiclient,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2013 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",0,4694
openstack%2Fsahara~master~I181bb8813091e8f61e8cba550363cd145c375e72,openstack/sahara,master,I181bb8813091e8f61e8cba550363cd145c375e72,Add Hive + MySQL configuration,MERGED,2013-09-02 13:43:33.000000000,2013-09-06 13:52:32.000000000,2013-09-06 13:52:32.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6823}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7478}, {'_account_id': 7555}, {'_account_id': 7700}, {'_account_id': 8304}]","[{'number': 1, 'created': '2013-09-02 13:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/28d2ff169e8ff8b94297ad127a7ffc60b2551ee8', 'message': 'Add Hive + MySQL configuration\n\n * Added MySQL config for Hive\n * Apply config if MySQL is enabled\n * Run MySQL if oozie and hive instances are not the same\n * Create Hive DB schema\n * Start metastore server\n\nPartially implements blueprint edp-vanilla-plugin-hive-pig\n\nChange-Id: I181bb8813091e8f61e8cba550363cd145c375e72\n'}, {'number': 2, 'created': '2013-09-05 11:09:15.000000000', 'files': ['savanna/plugins/vanilla/config_helper.py', 'savanna/plugins/vanilla/run_scripts.py', 'savanna/plugins/vanilla/plugin.py', 'savanna/plugins/vanilla/mysql_helper.py', 'savanna/plugins/vanilla/oozie_helper.py', 'savanna/tests/unit/plugins/vanilla/test_plugin.py', 'savanna/plugins/vanilla/resources/create_hive_db.sql'], 'web_link': 'https://opendev.org/openstack/sahara/commit/d32d46c3b3a5e14a9d01134078be1016e19af2b0', 'message': 'Add Hive + MySQL configuration\n\n * Added MySQL config for Hive\n * Apply config if MySQL is enabled\n * Run MySQL if oozie and hive instances are not the same\n * Create Hive DB schema\n * Start metastore server\n\nPartially implements blueprint edp-vanilla-plugin-hive-pig\n\nChange-Id: I181bb8813091e8f61e8cba550363cd145c375e72\n'}]",8,44704,d32d46c3b3a5e14a9d01134078be1016e19af2b0,21,9,2,7700,,,0,"Add Hive + MySQL configuration

 * Added MySQL config for Hive
 * Apply config if MySQL is enabled
 * Run MySQL if oozie and hive instances are not the same
 * Create Hive DB schema
 * Start metastore server

Partially implements blueprint edp-vanilla-plugin-hive-pig

Change-Id: I181bb8813091e8f61e8cba550363cd145c375e72
",git fetch https://review.opendev.org/openstack/sahara refs/changes/04/44704/2 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/plugins/vanilla/config_helper.py', 'savanna/plugins/vanilla/run_scripts.py', 'savanna/plugins/vanilla/plugin.py', 'savanna/plugins/vanilla/mysql_helper.py', 'savanna/plugins/vanilla/oozie_helper.py', 'savanna/plugins/vanilla/resources/create_hive_db.sql']",6,28d2ff169e8ff8b94297ad127a7ffc60b2551ee8,bp/edp-vanilla-plugin-hive-pig,"CREATE DATABASE metastore; USE metastore; SOURCE /opt/hive/scripts/metastore/upgrade/mysql/hive-schema-0.10.0.mysql.sql; CREATE USER 'hive'@'localhost' IDENTIFIED BY 'hive'; REVOKE ALL PRIVILEGES, GRANT OPTION FROM 'hive'@'localhost'; GRANT SELECT,INSERT,UPDATE,DELETE,LOCK TABLES,EXECUTE ON metastore.* TO 'hive'@'localhost'; FLUSH PRIVILEGES; exit",,83,17
openstack%2Fsahara~master~I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b,openstack/sahara,master,I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b,Add an ability to configure a job,MERGED,2013-08-30 12:11:42.000000000,2013-09-06 13:52:31.000000000,2013-09-06 13:52:31.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6823}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7478}, {'_account_id': 7555}, {'_account_id': 7700}, {'_account_id': 8091}, {'_account_id': 8304}]","[{'number': 1, 'created': '2013-08-30 12:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f356d5488eed4e0c7c72f27b90d99f07f8fe6342', 'message': 'Add an ability to configure job\n\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}, {'number': 2, 'created': '2013-08-30 16:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/26d4da5abaf0daeabf29e97afbc3c8b7b907137a', 'message': 'Add an ability to configure job\n\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}, {'number': 3, 'created': '2013-09-02 14:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a23dedac3b98602e8a9e98cc810399c078af6f04', 'message': 'Add an ability to configure job\n\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}, {'number': 4, 'created': '2013-09-02 15:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/06c150d0f2f31a973d32dd757a5fddcec0c23872', 'message': 'Add an ability to configure job\n\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}, {'number': 5, 'created': '2013-09-03 08:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2d2616c2ad4a0642f8af1b60c9bc784e9fcf2343', 'message': 'Add an ability to configure job\n\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}, {'number': 6, 'created': '2013-09-03 15:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ca19c5f4371b33cd86d2c76a812802bd0ac25c5c', 'message': 'Add an ability to configure job\n\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}, {'number': 7, 'created': '2013-09-04 08:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7e94df1f18a8ca94b2f88f5063cb6561297159be', 'message': 'Add an ability to configure job\n\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}, {'number': 8, 'created': '2013-09-04 10:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ca112864a5f9b0f7b263c91f2fffb9f589c70538', 'message': 'Add an ability to configure job\n\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}, {'number': 9, 'created': '2013-09-05 18:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/61bd17342faecbece906708e1db0c281744f9b06', 'message': 'Add an ability to configure job\n\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}, {'number': 10, 'created': '2013-09-06 08:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2866df8eb5b0f663191e8aa45756fd2e5a4d8cda', 'message': 'Add an ability to configure job\n\nAdds an ability to fulfil <configuration> block in workflow.xml\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}, {'number': 11, 'created': '2013-09-06 12:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1e266b216b9a94b47bc7699413eb6c5345f08c4e', 'message': 'Add an ability to configure job\n\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}, {'number': 12, 'created': '2013-09-06 13:46:01.000000000', 'files': ['savanna/utils/api_validator.py', 'savanna/service/edp/job_manager.py', 'savanna/tests/unit/service/validation/edp/test_job_creation.py', 'savanna/service/validations/edp/job_executor.py', 'savanna/api/v11.py', 'savanna/service/validations/edp/job.py', 'savanna/conductor/manager.py', 'savanna/service/edp/api.py', 'savanna/service/validations/base.py', 'savanna/tests/unit/service/edp/test_job_manager.py', 'savanna/service/validations/edp/base.py', 'savanna/db/sqlalchemy/models.py', 'savanna/tests/unit/conductor/manager/test_edp.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/8f50a22b357a0e89014a9240e47a50d5db0003fe', 'message': 'Add an ability to configure a job\n\nAdds an ability to fulfil <configuration> block in workflow.xml\nPartially implements blueprint edp-job-configs-params\n\nChange-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b\n'}]",20,44442,8f50a22b357a0e89014a9240e47a50d5db0003fe,64,10,12,7478,,,0,"Add an ability to configure a job

Adds an ability to fulfil <configuration> block in workflow.xml
Partially implements blueprint edp-job-configs-params

Change-Id: I5c6dda92efc43aa4c56dd6b41b7b36bd94f4be5b
",git fetch https://review.opendev.org/openstack/sahara refs/changes/42/44442/11 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/service/edp/job_manager.py', 'savanna/tests/unit/service/edp/test_job_manager.py', 'savanna/service/validations/edp/job_executor.py', 'savanna/api/v11.py', 'savanna/service/validations/edp/base.py', 'savanna/service/validations/edp/job.py', 'savanna/db/sqlalchemy/models.py', 'savanna/service/edp/api.py', 'savanna/service/validations/base.py']",9,f356d5488eed4e0c7c72f27b90d99f07f8fe6342,edp/config,"def check_cluster_exists(id): if not api.get_cluster(id): raise ex.InvalidException(""Cluster with id '%s'"" "" doesn't exist"" % id) ",,166,26
openstack%2Fpython-neutronclient~master~I5e07942e83c48eff1c04c7d00bd9c98658dcfb58,openstack/python-neutronclient,master,I5e07942e83c48eff1c04c7d00bd9c98658dcfb58,Add provider attribute to lb-pool-create command,MERGED,2013-07-25 12:15:38.000000000,2013-09-06 13:45:38.000000000,2013-09-06 13:45:37.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-07-25 12:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/6f06d49547d5d82cb85901000ab1d5fc5d05a38b', 'message': 'Add commands to associate and disassociate providers and pools\n\nAlso, add attribute to lb-pool-create command\n\nChange-Id: I5e07942e83c48eff1c04c7d00bd9c98658dcfb58\n'}, {'number': 2, 'created': '2013-08-01 11:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/1d785bf6691ff7cf8c4928f6e2d0f9620a05db10', 'message': 'Add commands to associate providers and pools\n\nAlso, add provider attribute to lb-pool-create command\n\nChange-Id: I5e07942e83c48eff1c04c7d00bd9c98658dcfb58\n'}, {'number': 3, 'created': '2013-08-05 04:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/bb5f79cd1bd9c3fd2f46c7e792b716005df8c1a1', 'message': 'Add commands to associate providers and pools\n\nAlso, add provider attribute to lb-pool-create command\n\nChange-Id: I5e07942e83c48eff1c04c7d00bd9c98658dcfb58\n'}, {'number': 4, 'created': '2013-08-05 07:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/0220ac131a6f2fd700950cbbc85e9e9a8bce496f', 'message': 'Add commands to associate providers and pools\n\nAlso, add provider attribute to lb-pool-create command\n\nChange-Id: I5e07942e83c48eff1c04c7d00bd9c98658dcfb58\n'}, {'number': 5, 'created': '2013-08-05 08:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e7477dab967c5926c3d5eeb6b704a341418f5bea', 'message': 'Add commands to associate providers and pools\n\nAlso, add provider attribute to lb-pool-create command\n\nChange-Id: I5e07942e83c48eff1c04c7d00bd9c98658dcfb58\n'}, {'number': 6, 'created': '2013-08-05 11:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b2f67cdcba1d65b76aeeb1ed763178faa84ebb62', 'message': 'Add commands to associate providers and pools\n\nAlso, add provider attribute to lb-pool-create command\n\nChange-Id: I5e07942e83c48eff1c04c7d00bd9c98658dcfb58\n'}, {'number': 7, 'created': '2013-08-21 13:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/cc54e306f9e3dc28ad03095c64ee98a1a68916e2', 'message': 'Add provider attribute to lb-pool-create command\n\nChange-Id: I5e07942e83c48eff1c04c7d00bd9c98658dcfb58\n'}, {'number': 8, 'created': '2013-09-04 07:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/5d33fcab912ff8f69f2f773c7498e3d7ac1b559b', 'message': 'Add provider attribute to lb-pool-create command\n\nChange-Id: I5e07942e83c48eff1c04c7d00bd9c98658dcfb58\n'}, {'number': 9, 'created': '2013-09-04 07:40:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/1c3a6d2823d29f78cf209fe40efaf66d5172dde2', 'message': 'Add provider attribute to lb-pool-create command\n\nChange-Id: I5e07942e83c48eff1c04c7d00bd9c98658dcfb58\n'}, {'number': 10, 'created': '2013-09-05 12:16:02.000000000', 'files': ['neutronclient/neutron/v2_0/lb/pool.py', 'neutronclient/tests/unit/lb/test_cli20_pool.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/11157b812d39904a1aee70ed47a2931b8da3f20c', 'message': ""Add provider attribute to lb-pool-create command\n\nAlso add formatter for the provider attribute,\nso if provider is empty or absent, it displayed as 'N/A'\n\nChange-Id: I5e07942e83c48eff1c04c7d00bd9c98658dcfb58\n""}]",20,38625,11157b812d39904a1aee70ed47a2931b8da3f20c,50,6,10,6072,,,0,"Add provider attribute to lb-pool-create command

Also add formatter for the provider attribute,
so if provider is empty or absent, it displayed as 'N/A'

Change-Id: I5e07942e83c48eff1c04c7d00bd9c98658dcfb58
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/25/38625/10 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/lb/pool.py', 'neutronclient/v2_0/client.py', 'neutronclient/shell.py']",3,6f06d49547d5d82cb85901000ab1d5fc5d05a38b,bp/lbaas-integration-with-servicetypes," 'lb-pool-associate-provider': lb_pool.AssociateProvider, 'lb-pool-disassociate-provider': lb_pool.DisassociateProvider,",,72,2
openstack%2Fopenstack-manuals~stable%2Fgrizzly~Ifebb9af8fcc4096ca9051c597537214f058dfc87,openstack/openstack-manuals,stable/grizzly,Ifebb9af8fcc4096ca9051c597537214f058dfc87,"For the enable a simple NAT step, change eth0 to eth1",MERGED,2013-09-06 13:37:59.000000000,2013-09-06 13:38:37.000000000,2013-09-06 13:38:37.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-09-06 13:37:59.000000000', 'files': ['doc/src/docbkx/basic-install/src/basic-install_network-services.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0bc7b15d59dda6ddca5a570590e85def7c158b2b', 'message': 'For the enable a simple NAT step, change eth0 to eth1\n\nChange-Id: Ifebb9af8fcc4096ca9051c597537214f058dfc87\nCloses-bug: 1218375\n'}]",0,45431,0bc7b15d59dda6ddca5a570590e85def7c158b2b,5,2,1,964,,,0,"For the enable a simple NAT step, change eth0 to eth1

Change-Id: Ifebb9af8fcc4096ca9051c597537214f058dfc87
Closes-bug: 1218375
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/31/45431/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/basic-install/src/basic-install_network-services.xml'],1,0bc7b15d59dda6ddca5a570590e85def7c158b2b,bug/1218375, <screen><prompt>#</prompt> <userinput>iptables -A FORWARD -i eth1 -o br-ex -s 10.10.10.0/24 -m conntrack --ctstate NEW -j ACCEPT</userinput>, <screen><prompt>#</prompt> <userinput>iptables -A FORWARD -i eth0 -o br-ex -s 10.10.10.0/24 -m conntrack --ctstate NEW -j ACCEPT</userinput>,1,1
openstack%2Fopenstack-manuals~master~I2464f5c63cb0da110e1871a09a59380dad9b6b27,openstack/openstack-manuals,master,I2464f5c63cb0da110e1871a09a59380dad9b6b27,Make swift config tables the source of truth,MERGED,2013-09-03 00:45:09.000000000,2013-09-06 13:33:01.000000000,2013-09-06 13:33:00.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-09-03 00:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/431b492ca3027f1c8756e3040ed73bc9bae73f27', 'message': ""Make swift config tables the source of truth\n\nAs discussed on the mailing list, this patch will make the swift\nconfiguration tables found in common a source of truth for the\nhelptext. The script that generates them has been updated for this,\nand will now only add/remove options, update default values, and\nreplace helptext where it does not exist in the tables. Another\nrun of the script was done and tables were updated.\n\nBackstory: All projects other than Swift use OpenStack Common for\nconfiguration, and define option, default value and help text in the\ncode in a way that it's possible to extract.\n\nSince the code is able to act in this way, we can stop maintaining\nseparate instructive lines for configuration options, and instead\nfix any text problems in the code itself. This both improves the\nquality of the code and fixes our double maintenance problem.\n\nFor swift, we needed a different approach. Unfortunately, I think we\ndon't have the ability to treat the code as the definitive source and\nmove all maintenance there. The lack of instruction for every option,\nand absence of structure precludes this.\n\nSo I wrote some nasty scraping things (from RST and sample conf file)\nto seed an initial list of configuration options.\n\nMy plan from here was to make the 'update' portion of the script\ntreat the textual descriptions in common/tables/swift-*.xml as\ndefinitive.\n\nThe script would still search the swift code to add or remove\noptions, so we could guarantee completeness, and after an initial\npush to write out proper help text the maintenance becomes far\nsimpler.\n\nChange-Id: I2464f5c63cb0da110e1871a09a59380dad9b6b27\n""}, {'number': 2, 'created': '2013-09-04 17:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cb24f494b42806a9f7257c5f3a481b1651ad1220', 'message': ""Make swift config tables the source of truth\n\nAs discussed on the mailing list, this patch will make the swift\nconfiguration tables found in common a source of truth for the\nhelptext. The script that generates them has been updated for this,\nand will now only add/remove options, update default values, and\nreplace helptext where it does not exist in the tables. Another\nrun of the script was done and tables were updated.\n\nBackstory: All projects other than Swift use OpenStack Common for\nconfiguration, and define option, default value and help text in the\ncode in a way that it's possible to extract.\n\nSince the code is able to act in this way, we can stop maintaining\nseparate instructive lines for configuration options, and instead\nfix any text problems in the code itself. This both improves the\nquality of the code and fixes our double maintenance problem.\n\nFor swift, we needed a different approach. Unfortunately, I think we\ndon't have the ability to treat the code as the definitive source and\nmove all maintenance there. The lack of instruction for every option,\nand absence of structure precludes this.\n\nSo I wrote some nasty scraping things (from RST and sample conf file)\nto seed an initial list of configuration options.\n\nMy plan from here was to make the 'update' portion of the script\ntreat the textual descriptions in common/tables/swift-*.xml as\ndefinitive.\n\nThe script would still search the swift code to add or remove\noptions, so we could guarantee completeness, and after an initial\npush to write out proper help text the maintenance becomes far\nsimpler.\n\nChange-Id: I2464f5c63cb0da110e1871a09a59380dad9b6b27\n""}, {'number': 3, 'created': '2013-09-05 18:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/df9d6cf6f747624efdf6b231d82688c227578e7b', 'message': ""Make swift config tables the source of truth\n\nAs discussed on the mailing list, this patch will make the swift\nconfiguration tables found in common a source of truth for the\nhelptext. The script that generates them has been updated for this,\nand will now only add/remove options, update default values, and\nreplace helptext where it does not exist in the tables. Another\nrun of the script was done and tables were updated.\n\nBackstory: All projects other than Swift use OpenStack Common for\nconfiguration, and define option, default value and help text in the\ncode in a way that it's possible to extract.\n\nSince the code is able to act in this way, we can stop maintaining\nseparate instructive lines for configuration options, and instead\nfix any text problems in the code itself. This both improves the\nquality of the code and fixes our double maintenance problem.\n\nFor swift, we needed a different approach. Unfortunately, I think we\ndon't have the ability to treat the code as the definitive source and\nmove all maintenance there. The lack of instruction for every option,\nand absence of structure precludes this.\n\nSo I wrote some nasty scraping things (from RST and sample conf file)\nto seed an initial list of configuration options.\n\nMy plan from here was to make the 'update' portion of the script\ntreat the textual descriptions in common/tables/swift-*.xml as\ndefinitive.\n\nThe script would still search the swift code to add or remove\noptions, so we could guarantee completeness, and after an initial\npush to write out proper help text the maintenance becomes far\nsimpler.\n\nChange-Id: I2464f5c63cb0da110e1871a09a59380dad9b6b27\n""}, {'number': 4, 'created': '2013-09-05 18:23:30.000000000', 'files': ['doc/src/docbkx/common/tables/swift-container-server-container-sync.xml', 'doc/src/docbkx/common/tables/swift-memcache-memcache.xml', 'doc/src/docbkx/common/tables/swift-object-server-filter-healthcheck.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-container-quotas.xml', 'doc/src/docbkx/common/tables/swift-drive-audit-drive-audit.xml', 'doc/src/docbkx/common/tables/swift-object-server-pipeline-main.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-name_check.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-slo.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-object-expirer.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-list-endpoints.xml', 'doc/src/docbkx/common/tables/swift-container-server-pipeline-main.xml', 'doc/src/docbkx/common/tables/swift-container-server-filter-recon.xml', 'doc/src/docbkx/common/tables/swift-object-server-object-updater.xml', 'doc/src/docbkx/common/tables/swift-account-server-pipeline-main.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-ratelimit.xml', 'doc/src/docbkx/common/tables/swift-account-server-filter-healthcheck.xml', 'doc/src/docbkx/common/tables/swift-swift-swift-constraints.xml', 'doc/src/docbkx/common/tables/swift-account-server-account-reaper.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-filter-cache.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-catch_errors.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-DEFAULT.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-pipeline-main.xml', 'doc/src/docbkx/common/tables/swift-account-server-filter-recon.xml', 'doc/src/docbkx/common/tables/swift-container-server-filter-healthcheck.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-authtoken.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-tempurl.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-filter-catch_errors.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-proxy-logging.xml', 'doc/src/docbkx/common/tables/swift-account-server-account-replicator.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-account-quotas.xml', 'doc/src/docbkx/common/tables/swift-object-server-object-replicator.xml', 'doc/src/docbkx/common/tables/swift-container-server-container-replicator.xml', 'doc/src/docbkx/common/tables/swift-rsyncd-account.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-staticweb.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-tempauth.xml', 'tools/autogenerate-config-docs/extract_swift_flags.py', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-formpost.xml', 'doc/src/docbkx/common/tables/swift-container-server-DEFAULT.xml', 'doc/src/docbkx/common/tables/swift-rsyncd-container.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-domain_remap.xml', 'doc/src/docbkx/common/tables/swift-swift-swift-hash.xml', 'doc/src/docbkx/common/tables/swift-container-server-app-container-server.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-keystoneauth.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-bulk.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-app-proxy-server.xml', 'doc/src/docbkx/common/tables/swift-object-server-DEFAULT.xml', 'doc/src/docbkx/common/tables/swift-account-server-app-account-server.xml', 'doc/src/docbkx/common/tables/swift-object-server-filter-recon.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-app-proxy-server.xml', 'doc/src/docbkx/common/tables/swift-account-server-DEFAULT.xml', 'doc/src/docbkx/common/tables/swift-account-server-account-auditor.xml', 'doc/src/docbkx/common/tables/swift-rsyncd-object.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-cache.xml', 'doc/src/docbkx/common/tables/swift-swift-bench-bench.xml', 'doc/src/docbkx/common/tables/swift-container-server-container-updater.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-pipeline-main.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-DEFAULT.xml', 'doc/src/docbkx/common/tables/swift-container-server-container-auditor.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-cname_lookup.xml', 'doc/src/docbkx/common/tables/swift-object-server-app-object-server.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-healthcheck.xml', 'doc/src/docbkx/common/tables/swift-object-server-object-auditor.xml', 'doc/src/docbkx/common/tables/swift-dispersion-dispersion.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dea0e970d1d4863efdca49b3fc3c71477ea350db', 'message': ""Make swift config tables the source of truth\n\nAs discussed on the mailing list, this patch will make the swift\nconfiguration tables found in common a source of truth for the\nhelptext. The script that generates them has been updated for this,\nand will now only add/remove options, update default values, and\nreplace helptext where it does not exist in the tables. Another\nrun of the script was done and tables were updated.\n\nBackstory: All projects other than Swift use OpenStack Common for\nconfiguration, and define option, default value and help text in the\ncode in a way that it's possible to extract.\n\nSince the code is able to act in this way, we can stop maintaining\nseparate instructive lines for configuration options, and instead\nfix any text problems in the code itself. This both improves the\nquality of the code and fixes our double maintenance problem.\n\nFor swift, we needed a different approach. Unfortunately, I think we\ndon't have the ability to treat the code as the definitive source and\nmove all maintenance there. The lack of instruction for every option,\nand absence of structure precludes this.\n\nSo I wrote some nasty scraping things (from RST and sample conf file)\nto seed an initial list of configuration options.\n\nMy plan from here was to make the 'update' portion of the script\ntreat the textual descriptions in common/tables/swift-*.xml as\ndefinitive.\n\nThe script would still search the swift code to add or remove\noptions, so we could guarantee completeness, and after an initial\npush to write out proper help text the maintenance becomes far\nsimpler.\n\nChange-Id: I2464f5c63cb0da110e1871a09a59380dad9b6b27\n""}]",1,44779,dea0e970d1d4863efdca49b3fc3c71477ea350db,15,4,4,612,,,0,"Make swift config tables the source of truth

As discussed on the mailing list, this patch will make the swift
configuration tables found in common a source of truth for the
helptext. The script that generates them has been updated for this,
and will now only add/remove options, update default values, and
replace helptext where it does not exist in the tables. Another
run of the script was done and tables were updated.

Backstory: All projects other than Swift use OpenStack Common for
configuration, and define option, default value and help text in the
code in a way that it's possible to extract.

Since the code is able to act in this way, we can stop maintaining
separate instructive lines for configuration options, and instead
fix any text problems in the code itself. This both improves the
quality of the code and fixes our double maintenance problem.

For swift, we needed a different approach. Unfortunately, I think we
don't have the ability to treat the code as the definitive source and
move all maintenance there. The lack of instruction for every option,
and absence of structure precludes this.

So I wrote some nasty scraping things (from RST and sample conf file)
to seed an initial list of configuration options.

My plan from here was to make the 'update' portion of the script
treat the textual descriptions in common/tables/swift-*.xml as
definitive.

The script would still search the swift code to add or remove
options, so we could guarantee completeness, and after an initial
push to write out proper help text the maintenance becomes far
simpler.

Change-Id: I2464f5c63cb0da110e1871a09a59380dad9b6b27
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/79/44779/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/common/tables/swift-container-server-container-sync.xml', 'doc/src/docbkx/common/tables/swift-memcache-memcache.xml', 'doc/src/docbkx/common/tables/swift-object-server-filter-healthcheck.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-container-quotas.xml', 'doc/src/docbkx/common/tables/swift-drive-audit-drive-audit.xml', 'doc/src/docbkx/common/tables/swift-object-server-pipeline-main.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-name_check.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-slo.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-object-expirer.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-list-endpoints.xml', 'doc/src/docbkx/common/tables/swift-container-server-pipeline-main.xml', 'doc/src/docbkx/common/tables/swift-container-server-filter-recon.xml', 'doc/src/docbkx/common/tables/swift-object-server-object-updater.xml', 'doc/src/docbkx/common/tables/swift-account-server-pipeline-main.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-ratelimit.xml', 'doc/src/docbkx/common/tables/swift-account-server-filter-healthcheck.xml', 'doc/src/docbkx/common/tables/swift-swift-swift-constraints.xml', 'doc/src/docbkx/common/tables/swift-account-server-account-reaper.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-filter-cache.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-catch_errors.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-DEFAULT.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-pipeline-main.xml', 'doc/src/docbkx/common/tables/swift-account-server-filter-recon.xml', 'doc/src/docbkx/common/tables/swift-container-server-filter-healthcheck.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-authtoken.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-tempurl.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-filter-catch_errors.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-proxy-logging.xml', 'doc/src/docbkx/common/tables/swift-account-server-account-replicator.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-account-quotas.xml', 'doc/src/docbkx/common/tables/swift-object-server-object-replicator.xml', 'doc/src/docbkx/common/tables/swift-container-server-container-replicator.xml', 'doc/src/docbkx/common/tables/swift-rsyncd-account.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-staticweb.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-tempauth.xml', 'tools/autogenerate-config-docs/extract_swift_flags.py', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-formpost.xml', 'doc/src/docbkx/common/tables/swift-container-server-DEFAULT.xml', 'doc/src/docbkx/common/tables/swift-rsyncd-container.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-domain_remap.xml', 'doc/src/docbkx/common/tables/swift-swift-swift-hash.xml', 'doc/src/docbkx/common/tables/swift-container-server-app-container-server.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-keystoneauth.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-bulk.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-app-proxy-server.xml', 'doc/src/docbkx/common/tables/swift-object-server-DEFAULT.xml', 'doc/src/docbkx/common/tables/swift-account-server-app-account-server.xml', 'doc/src/docbkx/common/tables/swift-object-server-filter-recon.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-app-proxy-server.xml', 'doc/src/docbkx/common/tables/swift-account-server-DEFAULT.xml', 'doc/src/docbkx/common/tables/swift-account-server-account-auditor.xml', 'doc/src/docbkx/common/tables/swift-rsyncd-object.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-cache.xml', 'doc/src/docbkx/common/tables/swift-swift-bench-bench.xml', 'doc/src/docbkx/common/tables/swift-container-server-container-updater.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-pipeline-main.xml', 'doc/src/docbkx/common/tables/swift-object-expirer-DEFAULT.xml', 'doc/src/docbkx/common/tables/swift-container-server-container-auditor.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-cname_lookup.xml', 'doc/src/docbkx/common/tables/swift-object-server-app-object-server.xml', 'doc/src/docbkx/common/tables/swift-proxy-server-filter-healthcheck.xml', 'doc/src/docbkx/common/tables/swift-object-server-object-auditor.xml', 'doc/src/docbkx/common/tables/swift-dispersion-dispersion.xml']",63,431b492ca3027f1c8756e3040ed73bc9bae73f27,bug/1195563, <td>keystone_api_insecure=no</td><td>No help text available for this option</td> </tr> <tr> <td>dispersion_coverage=1.0</td><td>No help text available for this option</td>, <!-- Warning: Do not edit this file. It is automatically generated and your changes will be overwritten. The tool to do so lives in the tools directory of this repository --> <td>dispersion_coverage=1</td><td>No help text available for this option</td>,233,417
openstack%2Fopenstack-manuals~master~Id69cbcc5fe2fbd59f72dcbd884524424aa6d372f,openstack/openstack-manuals,master,Id69cbcc5fe2fbd59f72dcbd884524424aa6d372f,Remove Social Integration buttons from Guides,MERGED,2013-09-06 08:56:55.000000000,2013-09-06 13:32:54.000000000,2013-09-06 13:32:53.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-09-06 08:56:55.000000000', 'files': ['doc/src/docbkx/openstack-user/pom.xml', 'doc/src/docbkx/openstack-user-admin/pom.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0dc03c9fc9444516c664db9383615fadaad5bed8', 'message': 'Remove Social Integration buttons from Guides\n\npom.xml should not set socialIcons, otherwise the Facebook and\nTwitter buttons are shown.\n\nChange-Id: Id69cbcc5fe2fbd59f72dcbd884524424aa6d372f\nCloses-Bug: #1221220\n'}]",0,45397,0dc03c9fc9444516c664db9383615fadaad5bed8,5,2,1,6547,,,0,"Remove Social Integration buttons from Guides

pom.xml should not set socialIcons, otherwise the Facebook and
Twitter buttons are shown.

Change-Id: Id69cbcc5fe2fbd59f72dcbd884524424aa6d372f
Closes-Bug: #1221220
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/97/45397/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-user/pom.xml', 'doc/src/docbkx/openstack-user-admin/pom.xml']",2,0dc03c9fc9444516c664db9383615fadaad5bed8,bug/1221220,, <socialIcons>1</socialIcons>,0,2
openstack%2Fopenstack-manuals~master~Ia793907b46487b346e43d347a1a82c5df9c559d5,openstack/openstack-manuals,master,Ia793907b46487b346e43d347a1a82c5df9c559d5,Fix typos in Hyper V description,MERGED,2013-09-06 09:21:58.000000000,2013-09-06 13:31:52.000000000,2013-09-06 13:31:51.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-09-06 09:21:58.000000000', 'files': ['doc/src/docbkx/common/section_hyper-v.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/03fd037b57835f67b9084cee32b99571d24174f1', 'message': 'Fix typos in Hyper V description\n\nChange-Id: Ia793907b46487b346e43d347a1a82c5df9c559d5\n'}]",0,45405,03fd037b57835f67b9084cee32b99571d24174f1,5,2,1,6547,,,0,"Fix typos in Hyper V description

Change-Id: Ia793907b46487b346e43d347a1a82c5df9c559d5
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/05/45405/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/common/section_hyper-v.xml'],1,03fd037b57835f67b9084cee32b99571d24174f1,typos-hyperv," <systemitem class=""service"">nova-compute</systemitem> service runs as ""openstack-compute,"" a 32-bit service directly upon the Windows <title>""Python Requirements""</title>"," <systemitem class=""service"">nova-compute</systemitem> service runs as ""openstack-compute,"" a 32bit service directly upon the Windows <title>""Python Requirements""></title>",2,2
openstack%2Fopenstack-manuals~master~Ieac1dafd34e100700f04b6ec2b4695496bfded91,openstack/openstack-manuals,master,Ieac1dafd34e100700f04b6ec2b4695496bfded91,Remove Object Storage Guide from trunk index page,MERGED,2013-09-06 09:04:48.000000000,2013-09-06 13:31:45.000000000,2013-09-06 13:31:44.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-09-06 09:04:48.000000000', 'files': ['www/trunk/index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a96338ca0a94072850db3ec6afb941f82b2aed46', 'message': 'Remove Object Storage Guide from trunk index page\n\nThe guide has been removed, drop a reference to it.\n\nChange-Id: Ieac1dafd34e100700f04b6ec2b4695496bfded91\n'}]",0,45398,a96338ca0a94072850db3ec6afb941f82b2aed46,5,2,1,6547,,,0,"Remove Object Storage Guide from trunk index page

The guide has been removed, drop a reference to it.

Change-Id: Ieac1dafd34e100700f04b6ec2b4695496bfded91
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/98/45398/1 && git format-patch -1 --stdout FETCH_HEAD,['www/trunk/index.html'],1,a96338ca0a94072850db3ec6afb941f82b2aed46,remove-object-storage,," <dd><a href=""http://docs.openstack.org/trunk/openstack-object-storage/admin/content/"" >Object Storage Administration Guide</a> </dd>",0,5
openstack%2Foslo-incubator~stable%2Ffolsom~I2f0e88435748bab631d969573d3a598d9e1f7fef,openstack/oslo-incubator,stable/folsom,I2f0e88435748bab631d969573d3a598d9e1f7fef,Fix problem with long messages in Qpid,MERGED,2013-09-02 13:08:55.000000000,2013-09-06 13:10:07.000000000,2013-09-06 13:10:07.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1561}, {'_account_id': 6928}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-09-02 13:08:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c31d0d8a04ef07fd9da53fec5d59cd56db277d1d', 'message': 'Fix problem with long messages in Qpid\n\nQpid has a limitation where it cannot serialize a dict containing a\nstring greater than 65535 characters. This change alters the Qpid\nimplementation to JSON encode the dict before sending it, but only if\nQpid would fail to serialize it. This maintains as much backward\ncompatibility as possible, though long messages will still fail if they\nare sent to an older receiver.\n\nEven though this change will modify the message format, it will only do\nit when messages are longer than 65K which would be broken anyway and\ncould cause serious bugs like the one linked below.\n\nFixes bug 1215091\n\n(cherry picked from commit 7ce54410485b33cffc39c7ffb96eae422b88601c)\n\nConflicts:\n\topenstack/common/rpc/impl_qpid.py\n\nChange-Id: I2f0e88435748bab631d969573d3a598d9e1f7fef\n'}, {'number': 2, 'created': '2013-09-02 13:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/dcda3e6c02b92bebc7eabf5d88fe1594ca110444', 'message': 'Fix problem with long messages in Qpid\n\nQpid has a limitation where it cannot serialize a dict containing a\nstring greater than 65535 characters. This change alters the Qpid\nimplementation to JSON encode the dict before sending it, but only if\nQpid would fail to serialize it. This maintains as much backward\ncompatibility as possible, though long messages will still fail if they\nare sent to an older receiver.\n\nEven though this change will modify the message format, it will only do\nit when messages are longer than 65K which would be broken anyway and\ncould cause serious bugs like the one linked below.\n\nFixes bug 1215091\n\n(cherry picked from commit 7ce54410485b33cffc39c7ffb96eae422b88601c)\n\nConflicts:\n\topenstack/common/rpc/impl_qpid.py\n\nChange-Id: I2f0e88435748bab631d969573d3a598d9e1f7fef\n'}, {'number': 3, 'created': '2013-09-02 13:42:31.000000000', 'files': ['openstack/common/rpc/impl_qpid.py', 'tests/unit/rpc/test_qpid.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/478ac3a3ec4b2dd9adb32891123b6e33c483bdf2', 'message': 'Fix problem with long messages in Qpid\n\nQpid has a limitation where it cannot serialize a dict containing a\nstring greater than 65535 characters. This change alters the Qpid\nimplementation to JSON encode the dict before sending it, but only if\nQpid would fail to serialize it. This maintains as much backward\ncompatibility as possible, though long messages will still fail if they\nare sent to an older receiver.\n\nEven though this change will modify the message format, it will only do\nit when messages are longer than 65K which would be broken anyway and\ncould cause serious bugs like the one linked below.\n\nFixes bug 1215091\n\n(cherry picked from commit 7ce54410485b33cffc39c7ffb96eae422b88601c)\n\nConflicts:\n\topenstack/common/rpc/impl_qpid.py\n\nChange-Id: I2f0e88435748bab631d969573d3a598d9e1f7fef\n'}]",0,44700,478ac3a3ec4b2dd9adb32891123b6e33c483bdf2,16,5,3,7808,,,0,"Fix problem with long messages in Qpid

Qpid has a limitation where it cannot serialize a dict containing a
string greater than 65535 characters. This change alters the Qpid
implementation to JSON encode the dict before sending it, but only if
Qpid would fail to serialize it. This maintains as much backward
compatibility as possible, though long messages will still fail if they
are sent to an older receiver.

Even though this change will modify the message format, it will only do
it when messages are longer than 65K which would be broken anyway and
could cause serious bugs like the one linked below.

Fixes bug 1215091

(cherry picked from commit 7ce54410485b33cffc39c7ffb96eae422b88601c)

Conflicts:
	openstack/common/rpc/impl_qpid.py

Change-Id: I2f0e88435748bab631d969573d3a598d9e1f7fef
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/00/44700/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/rpc/impl_qpid.py', 'tests/unit/rpc/test_qpid.py']",2,c31d0d8a04ef07fd9da53fec5d59cd56db277d1d,bug/1215091,"from openstack.common import jsonutils def _test_publisher(self, message=True): """"""Test that messages containing long strings are correctly serialized in a way that Qpid can handle. :param message: The publisher may be passed either a Qpid Message object or a bare dict. This parameter controls which of those the test will send. """""" self.sent_msg = None def send_stub(msg): self.sent_msg = msg # Qpid cannot serialize a dict containing a string > 65535 chars. raw_msg = {'test': 'a' * 65536} if message: base_msg = qpid.messaging.Message(raw_msg) else: base_msg = raw_msg expected_msg = qpid.messaging.Message(jsonutils.dumps(raw_msg)) expected_msg.content_type = impl_qpid.JSON_CONTENT_TYPE mock_session = self.mox.CreateMock(self.orig_session) mock_sender = self.mox.CreateMock(self.orig_sender) mock_session.sender(mox.IgnoreArg()).AndReturn(mock_sender) self.stubs.Set(mock_sender, 'send', send_stub) self.mox.ReplayAll() publisher = impl_qpid.Publisher(mock_session, 'test_node') publisher.send(base_msg) self.assertEqual(self.sent_msg.content, expected_msg.content) self.assertEqual(self.sent_msg.content_type, expected_msg.content_type) def test_publisher_long_message(self): self._test_publisher(message=True) def test_publisher_long_dict(self): self._test_publisher(message=False) def _test_consumer_long_message(self, json=True): """"""Verify that the Qpid implementation correctly deserializes message content. :param json: For compatibility, this code needs to support both messages that are and are not JSON encoded. This param specifies which is being tested. """""" def fake_callback(msg): self.received_msg = msg # The longest string Qpid can handle itself chars = 65535 if json: # The first length that requires JSON encoding chars = 65536 raw_msg = {'test': 'a' * chars} if json: fake_message = qpid.messaging.Message(jsonutils.dumps(raw_msg)) fake_message.content_type = impl_qpid.JSON_CONTENT_TYPE else: fake_message = qpid.messaging.Message(raw_msg) mock_session = self.mox.CreateMock(self.orig_session) mock_receiver = self.mox.CreateMock(self.orig_receiver) mock_session.receiver(mox.IgnoreArg()).AndReturn(mock_receiver) mock_receiver.fetch().AndReturn(fake_message) mock_session.acknowledge(mox.IgnoreArg()) self.mox.ReplayAll() consumer = impl_qpid.DirectConsumer(None, mock_session, 'bogus_msg_id', fake_callback) consumer.consume() self.assertEqual(self.received_msg, raw_msg) def test_consumer_long_message(self): self._test_consumer_long_message(json=True) def test_consumer_long_message_no_json(self): self._test_consumer_long_message(json=False) ",,134,0
openstack%2Fzaqar~master~I82bbbf1b6d0735dc2d15faee715175fc724b9423,openstack/zaqar,master,I82bbbf1b6d0735dc2d15faee715175fc724b9423,fix(transport.wsgi): JSON home doc missing GET and HEAD hints,MERGED,2013-09-05 22:40:15.000000000,2013-09-06 12:28:44.000000000,2013-09-06 12:28:44.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6944}, {'_account_id': 6971}]","[{'number': 1, 'created': '2013-09-05 22:40:15.000000000', 'files': ['marconi/transport/wsgi/v1.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c8e9242b1ac7ba2c0b8d9604d1f2914ff0e73bf3', 'message': 'fix(transport.wsgi): JSON home doc missing GET and HEAD hints\n\nGET and HEAD support was added for /v1/queues/{queue_name} but\nthe home document was not updated accordingly. This patch adds\nthose methods (AKA verbs) to the home document.\n\nChange-Id: I82bbbf1b6d0735dc2d15faee715175fc724b9423\n'}]",0,45341,c8e9242b1ac7ba2c0b8d9604d1f2914ff0e73bf3,6,4,1,6427,,,0,"fix(transport.wsgi): JSON home doc missing GET and HEAD hints

GET and HEAD support was added for /v1/queues/{queue_name} but
the home document was not updated accordingly. This patch adds
those methods (AKA verbs) to the home document.

Change-Id: I82bbbf1b6d0735dc2d15faee715175fc724b9423
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/41/45341/1 && git format-patch -1 --stdout FETCH_HEAD,['marconi/transport/wsgi/v1.py'],1,c8e9242b1ac7ba2c0b8d9604d1f2914ff0e73bf3,json-home," 'allow': ['GET', 'HEAD', 'PUT', 'DELETE'],"," 'allow': ['PUT', 'DELETE'],",1,1
openstack%2Fneutron~master~I874308f83a54defeb77336acc1c0318172db1bb6,openstack/neutron,master,I874308f83a54defeb77336acc1c0318172db1bb6,Imported Translations from Transifex,MERGED,2013-09-06 06:09:50.000000000,2013-09-06 11:56:26.000000000,2013-09-06 11:56:25.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-09-06 06:09:50.000000000', 'files': ['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/es_MX/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/sk/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ne/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/hi/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/394741cb9015910c39d4643d9e30998c7b0d2c2e', 'message': 'Imported Translations from Transifex\n\nChange-Id: I874308f83a54defeb77336acc1c0318172db1bb6\n'}]",0,45379,394741cb9015910c39d4643d9e30998c7b0d2c2e,7,4,1,3,,,0,"Imported Translations from Transifex

Change-Id: I874308f83a54defeb77336acc1c0318172db1bb6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/45379/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/es_MX/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/sk/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ne/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/hi/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po']",44,394741cb9015910c39d4643d9e30998c7b0d2c2e,transifex/translations,"""POT-Creation-Date: 2013-09-06 06:08+0000\n""#: neutron/services/metering/drivers/iptables/iptables_driver.py:42#: neutron/services/metering/drivers/iptables/iptables_driver.py:39#: neutron/services/metering/drivers/iptables/iptables_driver.py:98#: neutron/services/firewall/agents/varmour/varmour_router.py:100#: neutron/services/firewall/agents/varmour/varmour_router.py:103#: neutron/plugins/midonet/agent/midonet_driver.py:129#: neutron/plugins/midonet/agent/midonet_driver.py:137#: neutron/agent/linux/iptables_manager.py:586 #, python-format msgid ""Attempted to get traffic counters of chain %s which does not exist"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:641#: neutron/api/v2/base.py:601 neutron/extensions/allowedaddresspairs.py:65 #: neutron/extensions/multiprovidernet.py:53#: neutron/db/l3_db.py:605 neutron/plugins/nicira/NeutronPlugin.py:1730#: neutron/extensions/allowedaddresspairs.py:26 msgid ""AllowedAddressPair must contain ip_address"" msgstr """" #: neutron/extensions/allowedaddresspairs.py:30 msgid """" ""Port Security must be enabled in order to have allowed address pairs on a"" "" port."" msgstr """" #: neutron/extensions/allowedaddresspairs.py:35 #, python-format msgid """" ""Request contains duplicate address pair: mac_address %(mac_address)s "" ""ip_address %(ip_address)s."" msgstr """" #: neutron/extensions/allowedaddresspairs.py:40 msgid ""Port's Fixed IP and Mac Address match an address pair entry."" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:379#: neutron/plugins/midonet/plugin.py:187#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:100#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:118 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:138 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:153#: neutron/plugins/ml2/drivers/cisco/exceptions.py:23#: neutron/plugins/ml2/drivers/cisco/exceptions.py:28#: neutron/plugins/ml2/drivers/cisco/exceptions.py:39#: neutron/plugins/ml2/drivers/cisco/exceptions.py:44#: neutron/plugins/ml2/drivers/cisco/exceptions.py:49#: neutron/plugins/ml2/drivers/cisco/exceptions.py:63#: neutron/plugins/ml2/drivers/cisco/exceptions.py:68#: neutron/plugins/ml2/drivers/cisco/exceptions.py:73#: neutron/plugins/ml2/drivers/cisco/exceptions.py:78msgid ""Network Profile %(profile)s could not be found.""#: neutron/plugins/ml2/drivers/cisco/config.py:21#: neutron/plugins/ml2/drivers/cisco/config.py:23msgid ""N1K default network profile""msgid ""N1K default policy profile"" msgstr """" #: neutron/plugins/cisco/common/config.py:78 msgid ""N1K policy profile for network node"" msgstr """" #: neutron/plugins/cisco/common/config.py:80#: neutron/plugins/cisco/db/n1kv_db_v2.py:581#: neutron/plugins/cisco/db/n1kv_db_v2.py:585#: neutron/plugins/cisco/db/n1kv_db_v2.py:613#: neutron/plugins/cisco/db/n1kv_db_v2.py:618#: neutron/plugins/cisco/db/n1kv_db_v2.py:622#: neutron/plugins/cisco/db/n1kv_db_v2.py:632#: neutron/plugins/cisco/db/n1kv_db_v2.py:670#: neutron/plugins/cisco/db/n1kv_db_v2.py:701#: neutron/plugins/cisco/db/n1kv_db_v2.py:703#: neutron/plugins/cisco/db/n1kv_db_v2.py:725#: neutron/plugins/cisco/db/n1kv_db_v2.py:729#: neutron/plugins/cisco/db/n1kv_db_v2.py:732#: neutron/plugins/cisco/db/n1kv_db_v2.py:840#: neutron/plugins/cisco/db/n1kv_db_v2.py:861#: neutron/plugins/cisco/db/n1kv_db_v2.py:875#: neutron/plugins/cisco/db/n1kv_db_v2.py:884#: neutron/plugins/cisco/db/n1kv_db_v2.py:909#: neutron/plugins/cisco/db/n1kv_db_v2.py:920#: neutron/plugins/cisco/db/n1kv_db_v2.py:929#: neutron/plugins/cisco/db/n1kv_db_v2.py:938#: neutron/plugins/cisco/db/n1kv_db_v2.py:965#: neutron/plugins/cisco/db/n1kv_db_v2.py:972#: neutron/plugins/cisco/db/n1kv_db_v2.py:980#: neutron/plugins/cisco/db/n1kv_db_v2.py:989#: neutron/plugins/cisco/db/n1kv_db_v2.py:996""ID %(tenant_id)s""#: neutron/plugins/cisco/db/n1kv_db_v2.py:1010#: neutron/plugins/cisco/db/n1kv_db_v2.py:1224#: neutron/plugins/cisco/db/n1kv_db_v2.py:1234#: neutron/plugins/cisco/db/n1kv_db_v2.py:1243 msgid ""segment_type should either be vlan, overlay, multi-segment or trunk""#: neutron/plugins/cisco/db/n1kv_db_v2.py:1249#: neutron/plugins/cisco/db/n1kv_db_v2.py:1256 msgid ""argument sub_type missing for network profile""#: neutron/plugins/cisco/db/n1kv_db_v2.py:1263#: neutron/plugins/cisco/db/n1kv_db_v2.py:1292#: neutron/plugins/cisco/db/n1kv_db_v2.py:1309#: neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py:30#: neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py:39#: neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py:45#: neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py:58#: neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py:74#: neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py:76#: neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py:87#: neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py:94#: neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py:102#: neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py:114#: neutron/plugins/cisco/n1kv/n1kv_client.py:256#: neutron/plugins/cisco/n1kv/n1kv_client.py:276#: neutron/plugins/cisco/n1kv/n1kv_client.py:316#: neutron/plugins/cisco/n1kv/n1kv_client.py:433#: neutron/plugins/cisco/n1kv/n1kv_client.py:442#: neutron/plugins/cisco/n1kv/n1kv_client.py:447#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:218#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:229#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:235#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:263 msgid ""No policy profile updated from VSM"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:322#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:386#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:326 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:340#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:396 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:415#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:329#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:334 msgid ""provider:physical_network specified for Overlay network""#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:343#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:347#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:431#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:353#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:359#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:443#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:537#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:576#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:581#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:582#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:611#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:616#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:622#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:627#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:632#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:635#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:640#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:687 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:690#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:701#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:722#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:732#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:747#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:779#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:801#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:802#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:826#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:866#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:880#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:897#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:938#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:953#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:995#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1003#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1015 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1025#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1068#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:487#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1126#, python-format msgid ""Cannot delete network '%s' that is member of a trunk segment"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1145 #, python-format msgid ""Cannot delete network '%s' that is a member of a multi-segment network"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1153#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1164#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1174#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1196#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1241#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1254#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1274#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1301#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1321#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1337#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1345#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1356#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1370#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1385#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1405#: neutron/plugins/ml2/drivers/cisco/nexus_network_driver.py:130 #: neutron/plugins/ml2/drivers/cisco/nexus_network_driver.py:161 #: neutron/plugins/ml2/drivers/cisco/nexus_network_driver.py:168 #: neutron/plugins/ml2/drivers/cisco/nexus_network_driver.py:181 #: neutron/plugins/ml2/drivers/cisco/nexus_network_driver.py:188 #: neutron/plugins/ml2/drivers/cisco/nexus_network_driver.py:208 #: neutron/plugins/ml2/drivers/cisco/nexus_network_driver.py:214#: neutron/plugins/ml2/drivers/cisco/nexus_network_driver.py:195#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:340#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:126#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:390#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:399#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:419#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:425#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:437#: neutron/plugins/midonet/midonet_lib.py:46#: neutron/plugins/midonet/midonet_lib.py:50#: neutron/plugins/midonet/midonet_lib.py:66#: neutron/plugins/midonet/midonet_lib.py:78#: neutron/plugins/midonet/midonet_lib.py:88#: neutron/plugins/midonet/midonet_lib.py:102#: neutron/plugins/midonet/midonet_lib.py:118""MidoClient.create_dhcp called: bridge=%(bridge)s, cidr=%(cidr)s, "" ""gateway_ip=%(gateway_ip)s""#: neutron/plugins/midonet/midonet_lib.py:135""MidoClient.add_dhcp_host called: bridge=%(bridge)s, cidr=%(cidr)s, "" ""ip=%(ip)s, mac=%(mac)s""#: neutron/plugins/midonet/midonet_lib.py:140 msgid ""Tried to add tonon-existent DHCP"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:154""MidoClient.remove_dhcp_host called: bridge=%(bridge)s, cidr=%(cidr)s, "" ""ip=%(ip)s, mac=%(mac)s""#: neutron/plugins/midonet/midonet_lib.py:159 msgid ""Tried to delete mapping from non-existent subnet"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:164 #, python-format msgid ""MidoClient.remove_dhcp_host: Deleting %(dh)r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:177 #, python-format msgid """" ""MidoClient.delete_dhcp_host called: bridge_id=%(bridge_id)s, "" ""cidr=%(cidr)s, ip=%(ip)s, mac=%(mac)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:191#: neutron/plugins/midonet/midonet_lib.py:204msgid ""MidoClient.delete_port called: id=%(id)s, delete_chains=%(delete_chains)s""#: neutron/plugins/midonet/midonet_lib.py:219#: neutron/plugins/midonet/midonet_lib.py:232msgid ""MidoClient.add_bridge_port called: bridge=%(bridge)s""#: neutron/plugins/midonet/midonet_lib.py:253#: neutron/plugins/midonet/midonet_lib.py:265#: neutron/plugins/midonet/midonet_lib.py:275#: neutron/plugins/midonet/midonet_lib.py:289#: neutron/plugins/midonet/midonet_lib.py:309""MidoClient.add_dhcp_route_option called: bridge=%(bridge)s, "" ""cidr=%(cidr)s, gw_ip=%(gw_ip)sdst_ip=%(dst_ip)s""#: neutron/plugins/midonet/midonet_lib.py:317 msgid ""Tried to access non-existent DHCP"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:346msgid ""MidoClient.unlink called: port=%(port)s""#: neutron/plugins/midonet/midonet_lib.py:351 #, python-format msgid ""Attempted to unlink a port that was not linked. %s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:357""MidoClient.remove_rules_by_property called: tenant_id=%(tenant_id)s, "" ""chain_name=%(chain_name)skey=%(key)s, value=%(value)s""#: neutron/plugins/midonet/midonet_lib.py:384""MidoClient.create_router_chains called: router=%(router)s, "" ""inbound_chain_name=%(in_chain)s, outbound_chain_name=%(out_chain)s""#: neutron/plugins/midonet/midonet_lib.py:407 #, python-format msgid ""MidoClient.delete_router_chains called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:422 #, python-format msgid ""MidoClient.delete_port_chains called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:434""MidoClient.get_link_port called: router=%(router)s, "" ""peer_router_id=%(peer_router_id)s""#: neutron/plugins/midonet/midonet_lib.py:473""MidoClient.add_static_nat called: tenant_id=%(tenant_id)s, "" ""chain_name=%(chain_name)s, from_ip=%(from_ip)s, to_ip=%(to_ip)s, "" ""port_id=%(port_id)s, nat_type=%(nat_type)s""#: neutron/plugins/midonet/midonet_lib.py:481msgid ""Invalid NAT type passed in %s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:533 #, python-format msgid ""MidoClient.remote_static_route called: router=%(router)s, ip=%(ip)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:544 #, python-format msgid """" ""MidoClient.update_port_chains called: "" ""port=%(port)sinbound_chain_id=%(inbound_chain_id)s, "" ""outbound_chain_id=%(outbound_chain_id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:555 #, python-format msgid ""MidoClient.create_chain called: tenant_id=%(tenant_id)s name=%(name)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:563 #, python-format msgid ""MidoClient.delete_chain called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:569 #, python-format msgid """" ""MidoClient.delete_chains_by_names called: tenant_id=%(tenant_id)s "" ""names=%(names)s "" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:580 #, python-format msgid """" ""MidoClient.get_chain_by_name called: tenant_id=%(tenant_id)s "" ""name=%(name)s """"MidoClient.get_port_group_by_name called: tenant_id=%(tenant_id)s "" ""name=%(name)s ""#: neutron/plugins/midonet/midonet_lib.py:605msgid ""MidoClient.create_port_group called: tenant_id=%(tenant_id)s name=%(name)s""#: neutron/plugins/midonet/midonet_lib.py:614""MidoClient.delete_port_group_by_name called: tenant_id=%(tenant_id)s "" ""name=%(name)s ""#: neutron/plugins/midonet/midonet_lib.py:620 #, python-format msgid ""Deleting pg %(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:626""MidoClient.add_port_to_port_group_by_name called: tenant_id=%(tenant_id)s"" "" name=%(name)s port_id=%(port_id)s""#: neutron/plugins/midonet/midonet_lib.py:640msgid ""MidoClient.remove_port_from_port_groups called: port_id=%(port_id)s""#: neutron/plugins/midonet/plugin.py:74msgid ""Invalid nat_type %s""#: neutron/plugins/midonet/plugin.py:131msgid ""Unrecognized direction %s""#: neutron/plugins/midonet/plugin.py:165msgid ""There is no %(name)s with ID %(id)s in MidoNet.""#: neutron/plugins/midonet/plugin.py:216 msgid ""provider_router_id should be configured in the plugin config file""#: neutron/plugins/midonet/plugin.py:365#: neutron/plugins/midonet/plugin.py:386#: neutron/plugins/midonet/plugin.py:395#: neutron/plugins/midonet/plugin.py:410#: neutron/plugins/midonet/plugin.py:417#: neutron/plugins/midonet/plugin.py:431#: neutron/plugins/midonet/plugin.py:440#: neutron/plugins/midonet/plugin.py:448#: neutron/plugins/midonet/plugin.py:456#: neutron/plugins/midonet/plugin.py:461#: neutron/plugins/midonet/plugin.py:466#: neutron/plugins/midonet/plugin.py:471#: neutron/plugins/midonet/plugin.py:477#: neutron/plugins/midonet/plugin.py:530msgid ""Failed to create a port on network %(net_id)s: %(err)s""#: neutron/plugins/midonet/plugin.py:535 #, python-format msgid ""MidonetPluginV2.create_port exiting: port=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:540#: neutron/plugins/midonet/plugin.py:547msgid ""There is no port with ID %(id)s in MidoNet.""#: neutron/plugins/midonet/plugin.py:551 #, python-format msgid ""MidonetPluginV2.get_port exiting: port=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:556#: neutron/plugins/midonet/plugin.py:565#: neutron/plugins/midonet/plugin.py:598msgid ""Failed to delete DHCP mapping for port %(id)s""#: neutron/plugins/midonet/plugin.py:644msgid ""MidonetPluginV2.create_router called: router=%(router)s""#: neutron/plugins/midonet/plugin.py:680msgid ""MidonetPluginV2.create_router exiting: router_data=%(router_data)s.""#: neutron/plugins/midonet/plugin.py:692 #, python-format msgid """" ""MidonetPluginV2.set_router_gateway called: id=%(id)s, "" ""gw_router=%(gw_router)s, gw_ip=%(gw_ip)s"" msgstr """" #: neutron/plugins/midonet/plugin.py:736 #, python-format msgid ""MidonetPluginV2.remove_router_gateway called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/plugin.py:756#: neutron/plugins/midonet/plugin.py:794msgid ""MidonetPluginV2.update_router exiting: router=%r""#: neutron/plugins/midonet/plugin.py:805#: neutron/plugins/midonet/plugin.py:905#: neutron/plugins/midonet/plugin.py:929 msgid """" ""DHCP agent is not working correctly. No port to reach the Metadata server"" "" on this network""#: neutron/plugins/midonet/plugin.py:936""Failed to create MidoNet resources to add router interface. "" ""info=%(info)s, router_id=%(router_id)s""#: neutron/plugins/midonet/plugin.py:943 #, python-format msgid ""MidonetPluginV2.add_router_interface exiting: info=%r""#: neutron/plugins/midonet/plugin.py:949#: neutron/plugins/midonet/plugin.py:1003#: neutron/plugins/midonet/plugin.py:1013#: neutron/plugins/midonet/plugin.py:1042msgid ""Failed to create MidoNet resources for sg %(sg)r""#: neutron/plugins/midonet/plugin.py:1049 #, python-format msgid ""MidonetPluginV2.create_security_group exiting: sg=%r"" msgstr """" #: neutron/plugins/midonet/plugin.py:1055#: neutron/plugins/midonet/plugin.py:1087#: neutron/plugins/midonet/plugin.py:1097msgid ""MidonetPluginV2.create_security_group_rule exiting: rule=%r""#: neutron/plugins/midonet/plugin.py:1107msgid ""MidonetPluginV2.delete_security_group_rule called: sg_rule_id=%s""#: neutron/plugins/midonet/agent/midonet_driver.py:119msgid ""Failed to create a if-vport mapping on host=%s""#: neutron/plugins/midonet/agent/midonet_driver.py:126 msgid ""Faild binding vport=%(vport) to device=%(device)"" msgstr """" #: neutron/plugins/midonet/common/config.py:25 #: neutron/tests/unit/midonet/test_midonet_driver.py:54 msgid ""MidoNet API server URI."" msgstr """" #: neutron/plugins/midonet/common/config.py:27 #: neutron/tests/unit/midonet/test_midonet_driver.py:56 msgid ""MidoNet admin username."" msgstr """" #: neutron/plugins/midonet/common/config.py:30 #: neutron/tests/unit/midonet/test_midonet_driver.py:59 msgid ""MidoNet admin password."" msgstr """" #: neutron/plugins/midonet/common/config.py:33 #: neutron/tests/unit/midonet/test_midonet_driver.py:62 msgid ""ID of the project that MidoNet admin userbelongs to."" msgstr """" #: neutron/plugins/midonet/common/config.py:37 msgid ""Virtual provider router ID."" msgstr """" #: neutron/plugins/midonet/common/config.py:40 msgid ""Operational mode. Internal dev use only."" msgstr """" #: neutron/plugins/midonet/common/config.py:43 msgid ""Path to midonet host uuid file""#: neutron/plugins/ml2/plugin.py:113#: neutron/plugins/ml2/plugin.py:145#: neutron/plugins/ml2/plugin.py:184#: neutron/plugins/ml2/plugin.py:280#: neutron/plugins/ml2/plugin.py:322#: neutron/plugins/ml2/plugin.py:407#: neutron/plugins/ml2/plugin.py:468#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:409#: neutron/plugins/ml2/drivers/cisco/exceptions.py:33 #, python-format msgid ""Credential %(credential_id)s already exists for tenant %(tenant_id)s."" msgstr """" #: neutron/plugins/ml2/drivers/cisco/exceptions.py:54 #, python-format msgid ""Nexus Port Binding (%(filters)s) is not present"" msgstr """" #: neutron/plugins/ml2/drivers/cisco/mech_cisco_nexus.py:45 #, python-format msgid ""nexus_switches found = %s"" msgstr """" #: neutron/plugins/ml2/drivers/cisco/mech_cisco_nexus.py:101 #, python-format msgid ""Nexus: create & trunk vlan %s"" msgstr """" #: neutron/plugins/ml2/drivers/cisco/mech_cisco_nexus.py:108 #, python-format msgid ""Nexus: trunk vlan %s"" msgstr """" #: neutron/plugins/ml2/drivers/cisco/mech_cisco_nexus.py:120 #, python-format msgid ""Nexus: delete & untrunk vlan %s"" msgstr """" #: neutron/plugins/ml2/drivers/cisco/mech_cisco_nexus.py:124 #, python-format msgid ""Nexus: delete vlan %s"" msgstr """" #: neutron/plugins/ml2/drivers/cisco/mech_cisco_nexus.py:127 #, python-format msgid ""Nexus: untrunk vlan %s"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:338msgid ""Unknown network type %(network_type)s for network %(network_id)s""#: neutron/plugins/nec/nec_plugin.py:501#: neutron/plugins/nec/nec_plugin.py:561#: neutron/plugins/nec/nec_plugin.py:584#: neutron/plugins/nec/nec_plugin.py:594#: neutron/plugins/nec/nec_plugin.py:654#: neutron/plugins/nec/nec_plugin.py:685#: neutron/plugins/nec/nec_plugin.py:695#: neutron/plugins/nec/nec_plugin.py:714#: neutron/plugins/nec/nec_plugin.py:719#, python-format msgid ""Operation on OFC failed: status=%(status)s, detail=%(detail)s""#: neutron/plugins/nicira/NeutronPlugin.py:239#: neutron/plugins/nicira/NeutronPlugin.py:274#: neutron/plugins/nicira/NeutronPlugin.py:276#: neutron/plugins/nicira/NeutronPlugin.py:279#: neutron/plugins/nicira/NeutronPlugin.py:354#: neutron/plugins/nicira/NeutronPlugin.py:360#: neutron/plugins/nicira/NeutronPlugin.py:366#: neutron/plugins/nicira/NeutronPlugin.py:412#: neutron/plugins/nicira/NeutronPlugin.py:443#: neutron/plugins/nicira/NeutronPlugin.py:455 #: neutron/plugins/nicira/NeutronPlugin.py:492 #: neutron/plugins/nicira/NeutronPlugin.py:677#: neutron/plugins/nicira/NeutronPlugin.py:477#: neutron/plugins/nicira/NeutronPlugin.py:499#: neutron/plugins/nicira/NeutronPlugin.py:508#: neutron/plugins/nicira/NeutronPlugin.py:514#: neutron/plugins/nicira/NeutronPlugin.py:533 #: neutron/plugins/nicira/NeutronPlugin.py:1045#: neutron/plugins/nicira/NeutronPlugin.py:545#: neutron/plugins/nicira/NeutronPlugin.py:568#: neutron/plugins/nicira/NeutronPlugin.py:581#: neutron/plugins/nicira/NeutronPlugin.py:589#: neutron/plugins/nicira/NeutronPlugin.py:626#: neutron/plugins/nicira/NeutronPlugin.py:658 #: neutron/plugins/nicira/NeutronPlugin.py:1671#: neutron/plugins/nicira/NeutronPlugin.py:662 #: neutron/plugins/nicira/NeutronPlugin.py:1675#: neutron/plugins/nicira/NeutronPlugin.py:664#: neutron/plugins/nicira/NeutronPlugin.py:705#: neutron/plugins/nicira/NeutronPlugin.py:743#: neutron/plugins/nicira/NeutronPlugin.py:772#: neutron/plugins/nicira/NeutronPlugin.py:776#: neutron/plugins/nicira/NeutronPlugin.py:780#: neutron/plugins/nicira/NeutronPlugin.py:784 #: neutron/plugins/nicira/NeutronPlugin.py:800#: neutron/plugins/nicira/NeutronPlugin.py:806#: neutron/plugins/nicira/NeutronPlugin.py:851#: neutron/plugins/nicira/NeutronPlugin.py:873#: neutron/plugins/nicira/NeutronPlugin.py:963#: neutron/plugins/nicira/NeutronPlugin.py:1027#: neutron/plugins/nicira/NeutronPlugin.py:1055#: neutron/plugins/nicira/NeutronPlugin.py:1058#: neutron/plugins/nicira/NeutronPlugin.py:1091 msgid ""admin_state_up=False networks are not supported."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1166#: neutron/plugins/nicira/NeutronPlugin.py:1182#: neutron/plugins/nicira/NeutronPlugin.py:1193#: neutron/plugins/nicira/NeutronPlugin.py:1280#: neutron/plugins/nicira/NeutronPlugin.py:1307#: neutron/plugins/nicira/NeutronPlugin.py:1409 #: neutron/plugins/nicira/NeutronPlugin.py:1483#: neutron/plugins/nicira/NeutronPlugin.py:1426#: neutron/plugins/nicira/NeutronPlugin.py:1433#: neutron/plugins/nicira/NeutronPlugin.py:1441#: neutron/plugins/nicira/NeutronPlugin.py:1451#: neutron/plugins/nicira/NeutronPlugin.py:1492#: neutron/plugins/nicira/NeutronPlugin.py:1508#: neutron/plugins/nicira/NeutronPlugin.py:1512#: neutron/plugins/nicira/NeutronPlugin.py:1514#: neutron/plugins/nicira/NeutronPlugin.py:1548#: neutron/plugins/nicira/NeutronPlugin.py:1552#: neutron/plugins/nicira/NeutronPlugin.py:1609#: neutron/plugins/nicira/NeutronPlugin.py:1697#: neutron/plugins/nicira/NeutronPlugin.py:1703#: neutron/plugins/nicira/NeutronPlugin.py:1769#: neutron/plugins/nicira/NeutronPlugin.py:1793#: neutron/plugins/nicira/NeutronPlugin.py:1836#: neutron/plugins/nicira/NeutronPlugin.py:1839#: neutron/plugins/nicira/NeutronPlugin.py:1865#: neutron/plugins/nicira/NeutronPlugin.py:1887#: neutron/plugins/nicira/NeutronPlugin.py:1975#: neutron/plugins/nicira/nvplib.py:692 neutron/plugins/nicira/nvplib.py:753#: neutron/plugins/nicira/nvplib.py:748#: neutron/plugins/nicira/nvplib.py:786#: neutron/plugins/nicira/nvplib.py:810#: neutron/plugins/nicira/nvplib.py:840#: neutron/plugins/nicira/nvplib.py:850#: neutron/plugins/nicira/nvplib.py:916#: neutron/plugins/nicira/nvplib.py:1038#: neutron/plugins/nicira/nvplib.py:1064#: neutron/plugins/nicira/nvplib.py:1083#: neutron/plugins/nicira/nvplib.py:1089#: neutron/plugins/nicira/nvplib.py:1103#: neutron/plugins/nicira/nvplib.py:1238#: neutron/plugins/nicira/nvplib.py:1243#: neutron/plugins/nicira/nvplib.py:1281#: neutron/plugins/nicira/nvplib.py:1289#: neutron/plugins/nicira/nvplib.py:1305#: neutron/plugins/nicira/nvplib.py:1316#: neutron/plugins/nicira/common/config.py:128 msgid ""User name for vsm"" msgstr """" #: neutron/plugins/nicira/common/config.py:132 msgid ""Password for vsm"" msgstr """" #: neutron/plugins/nicira/common/config.py:134 msgid ""uri for vsm"" msgstr """" #: neutron/plugins/nicira/common/config.py:136 msgid ""Optional parameter identifying the ID of datacenter to deploy NSX Edges"" msgstr """" #: neutron/plugins/nicira/common/config.py:139 #: neutron/plugins/nicira/common/config.py:145 msgid ""Optional parameter identifying the ID of datastore to deploy NSX Edges"" msgstr """" #: neutron/plugins/nicira/common/config.py:142 msgid ""Optional parameter identifying the ID of resource to deploy NSX Edges"" msgstr """" #: neutron/plugins/nicira/common/config.py:148 msgid ""Network ID for physical network connectivity"" msgstr """" #: neutron/plugins/nicira/common/config.py:151 msgid ""Task status check interval"" msgstr """" #: neutron/plugins/nicira/common/config.py:164#: neutron/plugins/nicira/common/sync.py:213#: neutron/plugins/nicira/common/sync.py:234#: neutron/plugins/nicira/common/sync.py:256#: neutron/plugins/nicira/common/sync.py:323#: neutron/plugins/nicira/common/sync.py:387#: neutron/plugins/nicira/common/sync.py:462#: neutron/plugins/nicira/common/sync.py:493#: neutron/plugins/nicira/common/sync.py:513#: neutron/plugins/nicira/common/sync.py:517#: neutron/plugins/nicira/common/sync.py:533#: neutron/plugins/nicira/common/sync.py:543#: neutron/plugins/nicira/common/sync.py:547#: neutron/plugins/nicira/common/sync.py:554#: neutron/plugins/nicira/common/sync.py:570#: neutron/plugins/nicira/common/sync.py:583#: neutron/plugins/nicira/common/sync.py:595#: neutron/plugins/nicira/dhcp_meta/rpc.py:117#: neutron/plugins/nicira/dhcp_meta/rpc.py:120#: neutron/plugins/nicira/dhcp_meta/rpc.py:140#: neutron/plugins/nicira/dhcp_meta/rpc.py:148#: neutron/plugins/nicira/vshield/edge_appliance_driver.py:127 #, python-format msgid """" ""VCNS: Failed to get edge status:\n"" ""%s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:153 #, python-format msgid ""VCNS: start updating vnic %s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:157 #, python-format msgid """" ""VCNS: Failed to update vnic %(config)s:\n"" ""%(response)s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:163 #, python-format msgid ""VCNS: Failed to update vnic %d"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:172 #, python-format msgid ""VCNS: update vnic %(index)d: %(addr)s %(netmask)s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:181 #, python-format msgid ""Vnic %d currently not supported"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:202 #, python-format msgid ""VCNS: start deploying edge %s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:210 #, python-format msgid ""VCNS: deploying edge %s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:214 #, python-format msgid ""VCNS: deploy edge failed for router %s."" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:233 #, python-format msgid ""VCNS: Edge %s status query failed."" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:239 #, python-format msgid ""VCNS: Unable to retrieve edge %(edge_id)s status. Retry %(retries)d."" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:246 #, python-format msgid ""VCNS: Unable to retrieve edge %s status. Abort."" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:250 #, python-format msgid ""VCNS: Edge %s status"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:257 #, python-format msgid ""VCNS: Failed to deploy edge %(edge_id)s for %(name)s, status %(status)d"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:264 #, python-format msgid ""VCNS: Edge %(edge_id)s deployed for router %(name)s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:271 #, python-format msgid ""VCNS: start destroying edge %s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:279 #, python-format msgid """" ""VCNS: Failed to delete %{edge_id)s:\n"" ""%(response)s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:285 #, python-format msgid ""VCNS: Failed to delete %s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:294 #, python-format msgid """" ""VCNS: Failed to get edges:\n"" ""%s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:370 #, python-format msgid """" ""VCNS: Failed to get nat config:\n"" ""%s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:378 #, python-format msgid ""VCNS: start creating nat rules: %s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:394 #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:518 #, python-format msgid """" ""VCNS: Failed to create snat rule:\n"" ""%s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:402 #, python-format msgid ""VCNS: create snat rule %(src)s/%(translated)s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:425 #, python-format msgid ""VCNS: start deleting %(type)s rules: %(addr)s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:436 #, python-format msgid """" ""VCNS: Failed to delete snat rule:\n"" ""%s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:443 #, python-format msgid ""VCNS: delete snat rule %s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:461 #, python-format msgid ""VCNS: create dnat rule %(dst)s/%(translated)s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:482 #, python-format msgid ""VCNS: delete dnat rule %s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:506 #, python-format msgid ""VCNS: start updating nat rules: %s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:526 #, python-format msgid """" ""VCNS: update nat rule\n"" ""SNAT:%(snat)s\n"" ""DNAT:%(dnat)s\n"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:564 #, python-format msgid ""VCNS: start updating routes for %s"" msgstr """" #: neutron/plugins/nicira/vshield/edge_appliance_driver.py:590 #, python-format msgid """" ""VCNS: Failed to update routes:\n"" ""%s"" msgstr """" #: neutron/plugins/nicira/vshield/vcns.py:45 #, python-format msgid ""VcnsApiHelper('%(method)s', '%(uri)s', '%(body)s')"" msgstr """" #: neutron/plugins/nicira/vshield/vcns.py:53 #, python-format msgid ""Header: '%s'"" msgstr """" #: neutron/plugins/nicira/vshield/vcns.py:54 #, python-format msgid ""Content: '%s'"" msgstr """" #: neutron/plugins/nicira/vshield/common/exceptions.py:33 #, python-format msgid ""An unknown exception %(status)s occurred: %(response)s."" msgstr """" #: neutron/plugins/nicira/vshield/common/exceptions.py:44 #, python-format msgid ""Resource %(uri)s has been redirected"" msgstr """" #: neutron/plugins/nicira/vshield/common/exceptions.py:48 #, python-format msgid ""Request %(uri)s is Bad, response %(response)s"" msgstr """" #: neutron/plugins/nicira/vshield/common/exceptions.py:52 #, python-format msgid ""Forbidden: %(uri)s"" msgstr """" #: neutron/plugins/nicira/vshield/common/exceptions.py:56 #, python-format msgid ""Resource %(uri)s not found"" msgstr """" #: neutron/plugins/nicira/vshield/common/exceptions.py:60 #, python-format msgid ""Media Type %(uri)s is not supported"" msgstr """" #: neutron/plugins/nicira/vshield/common/exceptions.py:64 #, python-format msgid ""Service on available: %(uri)s"" msgstr """" #: neutron/plugins/nicira/vshield/tasks/tasks.py:50 #, python-format msgid ""Invalid state %(state)d"" msgstr """" #: neutron/plugins/nicira/vshield/tasks/tasks.py:54 #, python-format msgid ""State %(state)d skipped. Current state %(current)d"" msgstr """" #: neutron/plugins/nicira/vshield/tasks/tasks.py:100 #, python-format msgid ""Task %(task)s encountered exception in %(func)s at state %(state)s"" msgstr """" #: neutron/plugins/nicira/vshield/tasks/tasks.py:184 #, python-format msgid ""Start task %s"" msgstr """" #: neutron/plugins/nicira/vshield/tasks/tasks.py:190 #: neutron/plugins/nicira/vshield/tasks/tasks.py:210 #: neutron/plugins/nicira/vshield/tasks/tasks.py:234 #, python-format msgid ""Task %(task)s encountered exception in %(cb)s"" msgstr """" #: neutron/plugins/nicira/vshield/tasks/tasks.py:196 #: neutron/plugins/nicira/vshield/tasks/tasks.py:215 #, python-format msgid ""Task %(task)s return %(status)s"" msgstr """" #: neutron/plugins/nicira/vshield/tasks/tasks.py:308 msgid ""TaskManager terminated"" msgstr """" #: neutron/plugins/nicira/vshield/tasks/tasks.py:367 msgid ""Exception in _check_pending_tasks"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:145#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:288#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:304#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:349#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:353#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:406#: neutron/services/firewall/agents/varmour/varmour_api.py:31 msgid ""vArmour director ip"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_api.py:33 msgid ""vArmour director port"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_api.py:35 msgid ""vArmour director username"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_api.py:37 msgid ""vArmour director password"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_api.py:47 msgid ""An unknown exception."" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_api.py:61 msgid ""Invalid login credential."" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_api.py:67 msgid ""vArmourRestAPI: started"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_api.py:100 #, python-format msgid ""vArmourRestAPI: %(server)s %(port)s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_api.py:106 #, python-format msgid ""vArmourRestAPI Sending: %(method)s %(action)s %(headers)s %(body_data)s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_api.py:117 #, python-format msgid ""vArmourRestAPI Response: %(status)s %(resp_str)s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_api.py:125 msgid ""vArmourRestAPI: Could not establish HTTP connection"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:47 msgid ""vArmourL3NATAgent: __init__"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:61 #, python-format msgid ""_router_added: %s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:68 #, python-format msgid ""_router_removed: %s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:109 #, python-format msgid ""_va_unset_zone_interfaces: %s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:141 #, python-format msgid ""_va_set_interface_ip: %(pif)s %(cidr)s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:161 #, python-format msgid ""_va_config_trusted_zone: %s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:192 #, python-format msgid ""_va_config_untrusted_zone: %s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:207 #, python-format msgid ""_va_config_untrusted_zone: gw=%r"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:220 #, python-format msgid ""_va_config_router_snat_rules: %s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:252 #, python-format msgid ""_va_config_floating_ips: %s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:274 #, python-format msgid ""process_router: %s"" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:285 msgid ""unable to parse interface mapping."" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:288 msgid ""unable to read interface mapping."" msgstr """" #: neutron/services/firewall/agents/varmour/varmour_router.py:307 #, python-format msgid ""external_gateway_added: %s"" msgstr """" #: neutron/services/firewall/drivers/varmour/varmour_fwaas.py:30 msgid ""Initializing fwaas vArmour driver"" msgstr """" #: neutron/services/firewall/drivers/varmour/varmour_fwaas.py:35 #, python-format msgid ""create_firewall (%s)"" msgstr """" #: neutron/services/firewall/drivers/varmour/varmour_fwaas.py:40 #, python-format msgid ""update_firewall (%s)"" msgstr """" #: neutron/services/firewall/drivers/varmour/varmour_fwaas.py:48 #, python-format msgid ""delete_firewall (%s)"" msgstr """" #: neutron/services/firewall/drivers/varmour/varmour_fwaas.py:53 #, python-format msgid ""apply_default_policy (%s)"" msgstr """" #: neutron/services/firewall/drivers/varmour/varmour_fwaas.py:63 #, python-format msgid ""Updating firewall (%s)"" msgstr """" #: neutron/services/firewall/drivers/varmour/varmour_fwaas.py:112 msgid ""Unsupported IP version rule."" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py:253#: neutron/services/metering/drivers/iptables/iptables_driver.py:99 #, python-format msgid ""Loading interface driver %s"" msgstr """" #: neutron/tests/unit/nicira/vshield/fake_vcns.py:82 #, python-format msgid ""Job %s does not nexist"" msgstr """" #: neutron/tests/unit/nicira/vshield/fake_vcns.py:94 #: neutron/tests/unit/nicira/vshield/fake_vcns.py:105 #: neutron/tests/unit/nicira/vshield/fake_vcns.py:122 #: neutron/tests/unit/nicira/vshield/fake_vcns.py:140 #: neutron/tests/unit/nicira/vshield/fake_vcns.py:162 #: neutron/tests/unit/nicira/vshield/fake_vcns.py:184 #, python-format msgid ""Edge %s does not exist"" msgstr """" #: neutron/tests/unit/nicira/vshield/fake_vcns.py:172 #, python-format msgid ""Rule id %d doest not exist"" msgstr """" #: neutron/tests/unit/nicira/vshield/fake_vcns.py:235 #, python-format msgid ""Lswitch %s does not exist"" msgstr """" #~ msgid ""Network Profile %(profile_id)s could not be found."" #~ msgstr """" #~ msgid """" #~ ""Profile-Tenant binding missing for "" #~ ""profile ID %(profile_id)s and tenant ID"" #~ "" %(tenant_id)"" #~ msgstr """" #~ msgid ""segment_type should either be vlan, vxlan, multi-segment or trunk"" #~ msgstr """" #~ msgid ""argument sub_type missing for trunk network profile"" #~ msgstr """" #~ msgid ""seg id %s\n"" #~ msgstr """" #~ msgid ""Cannot delete a network that is a member of a trunk segment"" #~ msgstr """" #~ msgid ""Cannot delete a network that is a member of a multi-segment network"" #~ msgstr """" #~ msgid ""Virtual metadata router ID."" #~ msgstr """" #~ msgid """" #~ ""MidoClient.create_dhcp called: bridge=%(bridge)s, "" #~ ""net_addr=%(net_addr)s, net_len=%(net_len)s, "" #~ ""gateway_ip=%(gateway_ip)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.create_dhcp_hosts called: bridge=%(bridge)s,"" #~ "" ip=%(ip)s, mac=%(mac)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.delete_dhcp_hosts called: "" #~ ""bridge_id=%(bridge_id)s, ip=%(ip)s, mac=%(mac)s"" #~ msgstr """" #~ msgid ""MidoClient.delete_port called: id=%(id)s"" #~ msgstr """" #~ msgid ""MidoClient.create_exterior_bridge_port called: bridge=%(bridge)s"" #~ msgstr """" #~ msgid ""MidoClient.create_interior_bridge_port called: bridge=%(bridge)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.create_tenant_router called: "" #~ ""tenant_id=%(tenant_id)s, name=%(name)s, "" #~ ""metadata_router=%(metadata_router)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.delete_tenant_router called: id=%(id)s, "" #~ ""metadata_router=%(metadata_router)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.link_bridge_port_to_router called: "" #~ ""port_id=%(port_id)s, router_id=%(router_id)s, "" #~ ""gateway_ip=%(gateway_ip)s net_addr=%(net_addr)s, "" #~ ""net_len=%(net_len)s, metadata_router=%(metadata_router)s"" #~ msgstr """" #~ msgid ""Couldn't find a md router port for the router=%r"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.unlink_bridge_port_from_router called: "" #~ ""port_id=%(port_id)s, net_addr=%(net_addr)s, "" #~ ""net_len=%(net_len)s, metadata_router=%(metadata_router)s"" #~ msgstr """" #~ msgid ""Deleting route=%r ..."" #~ msgstr """" #~ msgid """" #~ ""MidoClient.link_bridge_to_provider_router called: "" #~ ""bridge=%(bridge)s, provider_router=%(provider_router)s, "" #~ ""gateway_ip=%(gateway_ip)s, net_addr=%(net_addr)s, "" #~ ""net_len=%(net_len)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.unlink_bridge_from_provider_router called: "" #~ ""bridge=%(bridge)s, provider_router=%(provider_router)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.set_router_external_gateway called: id=%(id)s,"" #~ "" provider_router=%(provider_router)s, snat_ip=%(snat_ip)s)"" #~ msgstr """" #~ msgid ""MidoClient.clear_router_external_gateway called: id=%(id)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.get_router_chains called: "" #~ ""tenant_id=%(tenant_id)s router_id=%(router_id)s"" #~ msgstr """" #~ msgid ""MidoClient.create_router_chains called: router=%(router)s"" #~ msgstr """" #~ msgid ""MidoClient.destroy_router_chains called: id=%(id)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.link_router_to_metadata_router called: "" #~ ""router=%(router)s, metadata_router=%(metadata_router)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.unlink_router_from_metadata_router called: "" #~ ""id=%(id)s, metadata_router=%(metadata_router)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.setup_floating_ip called: "" #~ ""router_id=%(router_id)s, "" #~ ""provider_router=%(provider_router)sfloating_ip=%(floating_ip)s, "" #~ ""fixed_ip=%(fixed_ip)sidentifier=%(identifier)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.clear_floating_ip called: "" #~ ""router_id=%(router_id)s, "" #~ ""provider_router=%(provider_router)sfloating_ip=%(floating_ip)s, "" #~ ""identifier=%(identifier)s"" #~ msgstr """" #~ msgid ""deleting rule=%r"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.create_for_sg called: tenant_id=%(tenant_id)s"" #~ "" sg_id=%(sg_id)s sg_name=%(sg_name)s "" #~ msgstr """" #~ msgid """" #~ ""MidoClient.delete_for_sg called: tenant_id=%(tenant_id)s"" #~ "" sg_id=%(sg_id)s sg_name=%(sg_name)s "" #~ msgstr """" #~ msgid ""MidoClient.delete_for_sg: deleting chain=%r"" #~ msgstr """" #~ msgid ""MidoClient.delete_for_sg: deleting pg=%r"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.get_sg_chains called: tenant_id=%(tenant_id)s"" #~ "" sg_id=%(sg_id)s"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.get_port_groups_for_sg called: "" #~ ""tenant_id=%(tenant_id)s sg_id=%(sg_id)s"" #~ msgstr """" #~ msgid ""MidoClient.get_port_groups_for_sg exiting: pg=%r"" #~ msgstr """" #~ msgid ""MidoClient.create_for_sg_rule called: rule=%r"" #~ msgstr """" #~ msgid ""Don't know what to do with rule=%r"" #~ msgstr """" #~ msgid """" #~ ""MidoClient.create_for_sg_rule: adding accept rule"" #~ "" %(rule_id)s in portgroup %(port_group_id)s"" #~ msgstr """" #~ msgid ""MidoClient.delete_for_sg_rule called: rule=%r"" #~ msgstr """" #~ msgid ""MidoClient.delete_for_sg_rule: deleting rule %r"" #~ msgstr """" #~ msgid """" #~ ""No provider router and metadata device"" #~ "" ids found. But skipping because "" #~ ""running in dev env."" #~ msgstr """" #~ msgid """" #~ ""provider_router_id and metadata_router_id should "" #~ ""be configured in the plugin config "" #~ ""file"" #~ msgstr """" #~ msgid ""MidoNet doesn't support IPv6."" #~ msgstr """" #~ msgid ""MidoNet doesn't support multiple subnets on the same network."" #~ msgstr """" #~ msgid """" #~ ""Ignoring admin_state_up=False for network=%r "" #~ ""because it is not yet supported"" #~ msgstr """" #~ msgid ""MidonetPluginV2.create_port exiting: port_db_entry=%r"" #~ msgstr """" #~ msgid ""MidonetPluginV2.get_port exiting: port_db_entry=%r"" #~ msgstr """" #~ msgid ""MidonetPluginV2.create_router called: router=%r"" #~ msgstr """" #~ msgid ""Ignoring admin_state_up=False for router=%r. Overriding with True"" #~ msgstr """" #~ msgid ""MidonetPluginV2.create_router exiting: qrouter=%r"" #~ msgstr """" #~ msgid ""admin_state_up=False routers are not supported."" #~ msgstr """" #~ msgid ""MidonetPluginV2.update_router exiting: qrouter=%r"" #~ msgstr """" #~ msgid ""MidonetPluginV2.delete_router exiting: result=%s"" #~ msgstr """" #~ msgid ""MidonetPluginV2.add_router_interface exiting: qport=%r"" #~ msgstr """" #~ msgid """" #~ ""MidonetPluginV2.remove_router_interface called: "" #~ ""router_id=%(router_id)s interface_info=%(interface_info)r"" #~ msgstr """" #~ msgid ""MidonetPluginV2.remove_router_interface exiting"" #~ msgstr """" #~ msgid ""MidonetPluginV2.create_security_group exiting: sg_db_entry=%r"" #~ msgstr """" #~ msgid """" #~ ""MidonetPluginV2.get_security_groups called: "" #~ ""filters=%(filters)r fields=%(fields)r"" #~ msgstr """" #~ msgid """" #~ ""MidonetPluginV2.get_security_group called: id=%(id)s "" #~ ""fields=%(fields)r tenant_id=%(tenant_id)s"" #~ msgstr """" #~ msgid ""MidonetPluginV2.create_security_group_rule exiting: rule_db_entry=%r"" #~ msgstr """" #~ msgid ""MidonetPluginV2.delete_security_group_rule called: sgrid=%s"" #~ msgstr """" #~ msgid """" #~ ""MidonetPluginV2.get_security_group_rules called: "" #~ ""filters=%(filters)r fields=%(fields)r"" #~ msgstr """" #~ msgid """" #~ ""MidonetPluginV2.get_security_group_rule called: id=%(id)s"" #~ "" fields=%(fields)r"" #~ msgstr """" #~ msgid ""Unknown network type %(network_type) for network %(network_id)"" #~ msgstr """" #~ msgid ""Operation on OFC failed: status=%(status), detail=%(detail)"" #~ msgstr """" ","""POT-Creation-Date: 2013-09-05 06:13+0000\n""#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:629#: neutron/api/v2/base.py:601 neutron/extensions/multiprovidernet.py:53#: neutron/db/l3_db.py:605 neutron/plugins/nicira/NeutronPlugin.py:1688#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:366#: neutron/plugins/midonet/plugin.py:42#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:98#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:116 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:136 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:151msgid ""Network Profile %(profile_id)s could not be found.""msgid ""N1K default policy profile""#: neutron/plugins/cisco/db/n1kv_db_v2.py:578#: neutron/plugins/cisco/db/n1kv_db_v2.py:582#: neutron/plugins/cisco/db/n1kv_db_v2.py:610#: neutron/plugins/cisco/db/n1kv_db_v2.py:615#: neutron/plugins/cisco/db/n1kv_db_v2.py:619#: neutron/plugins/cisco/db/n1kv_db_v2.py:629#: neutron/plugins/cisco/db/n1kv_db_v2.py:667#: neutron/plugins/cisco/db/n1kv_db_v2.py:698#: neutron/plugins/cisco/db/n1kv_db_v2.py:700#: neutron/plugins/cisco/db/n1kv_db_v2.py:722#: neutron/plugins/cisco/db/n1kv_db_v2.py:726#: neutron/plugins/cisco/db/n1kv_db_v2.py:729#: neutron/plugins/cisco/db/n1kv_db_v2.py:837#: neutron/plugins/cisco/db/n1kv_db_v2.py:858#: neutron/plugins/cisco/db/n1kv_db_v2.py:872#: neutron/plugins/cisco/db/n1kv_db_v2.py:881#: neutron/plugins/cisco/db/n1kv_db_v2.py:906#: neutron/plugins/cisco/db/n1kv_db_v2.py:917#: neutron/plugins/cisco/db/n1kv_db_v2.py:926#: neutron/plugins/cisco/db/n1kv_db_v2.py:935#: neutron/plugins/cisco/db/n1kv_db_v2.py:962#: neutron/plugins/cisco/db/n1kv_db_v2.py:969#: neutron/plugins/cisco/db/n1kv_db_v2.py:977#: neutron/plugins/cisco/db/n1kv_db_v2.py:986#: neutron/plugins/cisco/db/n1kv_db_v2.py:993""ID %(tenant_id)""#: neutron/plugins/cisco/db/n1kv_db_v2.py:1007#: neutron/plugins/cisco/db/n1kv_db_v2.py:1221#: neutron/plugins/cisco/db/n1kv_db_v2.py:1231#: neutron/plugins/cisco/db/n1kv_db_v2.py:1240 msgid ""segment_type should either be vlan, vxlan, multi-segment or trunk""#: neutron/plugins/cisco/db/n1kv_db_v2.py:1246#: neutron/plugins/cisco/db/n1kv_db_v2.py:1252 msgid ""argument sub_type missing for trunk network profile""#: neutron/plugins/cisco/db/n1kv_db_v2.py:1259#: neutron/plugins/cisco/db/n1kv_db_v2.py:1285#: neutron/plugins/cisco/db/n1kv_db_v2.py:1302#: neutron/plugins/cisco/n1kv/n1kv_client.py:201 #, python-format msgid ""seg id %s\n"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_client.py:252#: neutron/plugins/cisco/n1kv/n1kv_client.py:272#: neutron/plugins/cisco/n1kv/n1kv_client.py:312#: neutron/plugins/cisco/n1kv/n1kv_client.py:429#: neutron/plugins/cisco/n1kv/n1kv_client.py:434#: neutron/plugins/cisco/n1kv/n1kv_client.py:439#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:217#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:225#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:232#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:309#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:382#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:313 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:327#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:392 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:411#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:316#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:321 msgid ""provider:physical_network specified for VXLAN network""#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:330#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:334#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:427#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:340#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:346#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:439#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:525#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:564#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:569#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:570#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:599#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:604#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:610#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:615#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:620#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:623#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:628#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:675 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:678#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:689#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:710#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:720#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:735#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:767#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:789#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:790#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:814#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:854#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:868#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:885#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:926#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:941#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:983#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:991#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1003 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1013#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1056#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:483#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1114#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1129 msgid ""Cannot delete a network that is a member of a trunk segment"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1133 msgid ""Cannot delete a network that is a member of a multi-segment network"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1152#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1162#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1184#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1222#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1235#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1255#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1282#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1302#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1318#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1326#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1337#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1351#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1366#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1386#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:336#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:124#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:386#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:395#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:415#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:421#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:433#: neutron/plugins/midonet/config.py:25 msgid ""MidoNet API server URI."" msgstr """" #: neutron/plugins/midonet/config.py:27 msgid ""MidoNet admin username."" msgstr """" #: neutron/plugins/midonet/config.py:30 msgid ""MidoNet admin password."" msgstr """" #: neutron/plugins/midonet/config.py:33 msgid ""ID of the project that MidoNet admin userbelongs to."" msgstr """" #: neutron/plugins/midonet/config.py:37 msgid ""Virtual provider router ID."" msgstr """" #: neutron/plugins/midonet/config.py:40 msgid ""Virtual metadata router ID."" msgstr """" #: neutron/plugins/midonet/config.py:43 msgid ""Operational mode. Internal dev use only."" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:79#: neutron/plugins/midonet/midonet_lib.py:83#: neutron/plugins/midonet/midonet_lib.py:99#: neutron/plugins/midonet/midonet_lib.py:111#: neutron/plugins/midonet/midonet_lib.py:121#: neutron/plugins/midonet/midonet_lib.py:135#: neutron/plugins/midonet/midonet_lib.py:152""MidoClient.create_dhcp called: bridge=%(bridge)s, net_addr=%(net_addr)s, "" ""net_len=%(net_len)s, gateway_ip=%(gateway_ip)s""#: neutron/plugins/midonet/midonet_lib.py:169""MidoClient.create_dhcp_hosts called: bridge=%(bridge)s, ip=%(ip)s, "" ""mac=%(mac)s""#: neutron/plugins/midonet/midonet_lib.py:186""MidoClient.delete_dhcp_hosts called: bridge_id=%(bridge_id)s, ip=%(ip)s, "" ""mac=%(mac)s""#: neutron/plugins/midonet/midonet_lib.py:202#: neutron/plugins/midonet/midonet_lib.py:215msgid ""MidoClient.delete_port called: id=%(id)s""#: neutron/plugins/midonet/midonet_lib.py:225#: neutron/plugins/midonet/midonet_lib.py:238msgid ""MidoClient.create_exterior_bridge_port called: bridge=%(bridge)s""#: neutron/plugins/midonet/midonet_lib.py:249 #, python-format msgid ""MidoClient.create_interior_bridge_port called: bridge=%(bridge)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:261#: neutron/plugins/midonet/midonet_lib.py:276 #, python-format msgid """" ""MidoClient.create_tenant_router called: tenant_id=%(tenant_id)s, "" ""name=%(name)s, metadata_router=%(metadata_router)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:292 #, python-format msgid """" ""MidoClient.delete_tenant_router called: id=%(id)s, "" ""metadata_router=%(metadata_router)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:307#: neutron/plugins/midonet/midonet_lib.py:317#: neutron/plugins/midonet/midonet_lib.py:331#: neutron/plugins/midonet/midonet_lib.py:350""MidoClient.link_bridge_port_to_router called: port_id=%(port_id)s, "" ""router_id=%(router_id)s, gateway_ip=%(gateway_ip)s net_addr=%(net_addr)s,"" "" net_len=%(net_len)s, metadata_router=%(metadata_router)s""#: neutron/plugins/midonet/midonet_lib.py:382msgid ""Couldn't find a md router port for the router=%r""#: neutron/plugins/midonet/midonet_lib.py:399""MidoClient.unlink_bridge_port_from_router called: port_id=%(port_id)s, "" ""net_addr=%(net_addr)s, net_len=%(net_len)s, "" ""metadata_router=%(metadata_router)s""#: neutron/plugins/midonet/midonet_lib.py:414 #, python-format msgid ""Deleting route=%r ..."" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:429""MidoClient.link_bridge_to_provider_router called: bridge=%(bridge)s, "" ""provider_router=%(provider_router)s, gateway_ip=%(gateway_ip)s, "" ""net_addr=%(net_addr)s, net_len=%(net_len)s""#: neutron/plugins/midonet/midonet_lib.py:458""MidoClient.unlink_bridge_from_provider_router called: bridge=%(bridge)s, "" ""provider_router=%(provider_router)s""#: neutron/plugins/midonet/midonet_lib.py:489""MidoClient.set_router_external_gateway called: id=%(id)s, "" ""provider_router=%(provider_router)s, snat_ip=%(snat_ip)s)""#: neutron/plugins/midonet/midonet_lib.py:548msgid ""MidoClient.clear_router_external_gateway called: id=%(id)s""""MidoClient.get_router_chains called: tenant_id=%(tenant_id)s "" ""router_id=%(router_id)s""#: neutron/plugins/midonet/midonet_lib.py:613msgid ""MidoClient.create_router_chains called: router=%(router)s""#: neutron/plugins/midonet/midonet_lib.py:637 #, python-format msgid ""MidoClient.destroy_router_chains called: id=%(id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:652""MidoClient.link_router_to_metadata_router called: router=%(router)s, "" ""metadata_router=%(metadata_router)s""#: neutron/plugins/midonet/midonet_lib.py:678""MidoClient.unlink_router_from_metadata_router called: id=%(id)s, "" ""metadata_router=%(metadata_router)s""#: neutron/plugins/midonet/midonet_lib.py:701msgid """" ""MidoClient.setup_floating_ip called: router_id=%(router_id)s, "" ""provider_router=%(provider_router)sfloating_ip=%(floating_ip)s, "" ""fixed_ip=%(fixed_ip)sidentifier=%(identifier)s""#: neutron/plugins/midonet/midonet_lib.py:765msgid """" ""MidoClient.clear_floating_ip called: router_id=%(router_id)s, "" ""provider_router=%(provider_router)sfloating_ip=%(floating_ip)s, "" ""identifier=%(identifier)s""#: neutron/plugins/midonet/midonet_lib.py:786 #: neutron/plugins/midonet/midonet_lib.py:793msgid ""deleting rule=%r""#: neutron/plugins/midonet/midonet_lib.py:804msgid """" ""MidoClient.create_for_sg called: tenant_id=%(tenant_id)s sg_id=%(sg_id)s "" ""sg_name=%(sg_name)s ""#: neutron/plugins/midonet/midonet_lib.py:826 #, python-format msgid """" ""MidoClient.delete_for_sg called: tenant_id=%(tenant_id)s sg_id=%(sg_id)s "" ""sg_name=%(sg_name)s ""#: neutron/plugins/midonet/midonet_lib.py:835 #, python-format msgid ""MidoClient.delete_for_sg: deleting chain=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:843 #, python-format msgid ""MidoClient.delete_for_sg: deleting pg=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:850 #, python-format msgid ""MidoClient.get_sg_chains called: tenant_id=%(tenant_id)s sg_id=%(sg_id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:870 #, python-format msgid """" ""MidoClient.get_port_groups_for_sg called: tenant_id=%(tenant_id)s "" ""sg_id=%(sg_id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:879 #, python-format msgid ""MidoClient.get_port_groups_for_sg exiting: pg=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:886 #, python-format msgid ""MidoClient.create_for_sg_rule called: rule=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:912 #: neutron/plugins/midonet/midonet_lib.py:945 #, python-format msgid ""Don't know what to do with rule=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:949 #, python-format msgid """" ""MidoClient.create_for_sg_rule: adding accept rule %(rule_id)s in "" ""portgroup %(port_group_id)s"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:960 #, python-format msgid ""MidoClient.delete_for_sg_rule called: rule=%r"" msgstr """" #: neutron/plugins/midonet/midonet_lib.py:973 #, python-format msgid ""MidoClient.delete_for_sg_rule: deleting rule %r"" msgstr """" #: neutron/plugins/midonet/plugin.py:76 msgid """" ""No provider router and metadata device ids found. But skipping because "" ""running in dev env."" msgstr """" #: neutron/plugins/midonet/plugin.py:80 msgid """" ""provider_router_id and metadata_router_id should be configured in the "" ""plugin config file"" msgstr """" #: neutron/plugins/midonet/plugin.py:92#: neutron/plugins/midonet/plugin.py:96 msgid ""MidoNet doesn't support IPv6."" msgstr """" #: neutron/plugins/midonet/plugin.py:102 msgid ""MidoNet doesn't support multiple subnets on the same network."" msgstr """" #: neutron/plugins/midonet/plugin.py:125#: neutron/plugins/midonet/plugin.py:134#: neutron/plugins/midonet/plugin.py:149#: neutron/plugins/midonet/plugin.py:156#: neutron/plugins/midonet/plugin.py:160 #, python-format msgid """" ""Ignoring admin_state_up=False for network=%r because it is not yet "" ""supported"" msgstr """" #: neutron/plugins/midonet/plugin.py:178#: neutron/plugins/midonet/plugin.py:187#: neutron/plugins/midonet/plugin.py:193 #: neutron/plugins/nicira/NeutronPlugin.py:1086 msgid ""admin_state_up=False networks are not supported."" msgstr """" #: neutron/plugins/midonet/plugin.py:203#: neutron/plugins/midonet/plugin.py:211#: neutron/plugins/midonet/plugin.py:217#: neutron/plugins/midonet/plugin.py:222#: neutron/plugins/midonet/plugin.py:227#: neutron/plugins/midonet/plugin.py:233#: neutron/plugins/midonet/plugin.py:274msgid ""MidonetPluginV2.create_port exiting: port_db_entry=%r""#: neutron/plugins/midonet/plugin.py:280#: neutron/plugins/midonet/plugin.py:289msgid ""MidonetPluginV2.get_port exiting: port_db_entry=%r""#: neutron/plugins/midonet/plugin.py:295#: neutron/plugins/midonet/plugin.py:309#: neutron/plugins/midonet/plugin.py:339msgid ""MidonetPluginV2.create_router called: router=%r""#: neutron/plugins/midonet/plugin.py:342msgid ""Ignoring admin_state_up=False for router=%r. Overriding with True""#: neutron/plugins/midonet/plugin.py:360msgid ""MidonetPluginV2.create_router exiting: qrouter=%r""#: neutron/plugins/midonet/plugin.py:365#: neutron/plugins/midonet/plugin.py:369 msgid ""admin_state_up=False routers are not supported."" msgstr """" #: neutron/plugins/midonet/plugin.py:419msgid ""MidonetPluginV2.update_router exiting: qrouter=%r""#: neutron/plugins/midonet/plugin.py:424#: neutron/plugins/midonet/plugin.py:429 #, python-format msgid ""MidonetPluginV2.delete_router exiting: result=%s"" msgstr """" #: neutron/plugins/midonet/plugin.py:434#: neutron/plugins/midonet/plugin.py:456 #, python-format msgid ""MidonetPluginV2.add_router_interface exiting: qport=%r""#: neutron/plugins/midonet/plugin.py:462""MidonetPluginV2.remove_router_interface called: router_id=%(router_id)s "" ""interface_info=%(interface_info)r""#: neutron/plugins/midonet/plugin.py:509 msgid ""MidonetPluginV2.remove_router_interface exiting""#: neutron/plugins/midonet/plugin.py:513#: neutron/plugins/midonet/plugin.py:537#: neutron/plugins/midonet/plugin.py:546#: neutron/plugins/midonet/plugin.py:562msgid ""MidonetPluginV2.create_security_group exiting: sg_db_entry=%r""#: neutron/plugins/midonet/plugin.py:568#: neutron/plugins/midonet/plugin.py:597 #, python-format msgid """" ""MidonetPluginV2.get_security_groups called: filters=%(filters)r "" ""fields=%(fields)r"" msgstr """" #: neutron/plugins/midonet/plugin.py:604 #, python-format msgid """" ""MidonetPluginV2.get_security_group called: id=%(id)s fields=%(fields)r "" ""tenant_id=%(tenant_id)s"" msgstr """" #: neutron/plugins/midonet/plugin.py:611#: neutron/plugins/midonet/plugin.py:621msgid ""MidonetPluginV2.create_security_group_rule exiting: rule_db_entry=%r""#: neutron/plugins/midonet/plugin.py:626msgid ""MidonetPluginV2.delete_security_group_rule called: sgrid=%s""#: neutron/plugins/midonet/plugin.py:641msgid """" ""MidonetPluginV2.get_security_group_rules called: filters=%(filters)r "" ""fields=%(fields)r""#: neutron/plugins/midonet/plugin.py:648 #, python-format msgid """" ""MidonetPluginV2.get_security_group_rule called: id=%(id)s "" ""fields=%(fields)r""#: neutron/plugins/ml2/plugin.py:110#: neutron/plugins/ml2/plugin.py:142#: neutron/plugins/ml2/plugin.py:181#: neutron/plugins/ml2/plugin.py:277#: neutron/plugins/ml2/plugin.py:319#: neutron/plugins/ml2/plugin.py:404#: neutron/plugins/ml2/plugin.py:461#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:405#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:334msgid ""Unknown network type %(network_type) for network %(network_id)""#: neutron/plugins/nec/nec_plugin.py:498#: neutron/plugins/nec/nec_plugin.py:558#: neutron/plugins/nec/nec_plugin.py:581#: neutron/plugins/nec/nec_plugin.py:591#: neutron/plugins/nec/nec_plugin.py:651#: neutron/plugins/nec/nec_plugin.py:682#: neutron/plugins/nec/nec_plugin.py:692#: neutron/plugins/nec/nec_plugin.py:711#: neutron/plugins/nec/nec_plugin.py:716msgid ""Operation on OFC failed: status=%(status), detail=%(detail)""#: neutron/plugins/nicira/NeutronPlugin.py:235#: neutron/plugins/nicira/NeutronPlugin.py:270#: neutron/plugins/nicira/NeutronPlugin.py:272#: neutron/plugins/nicira/NeutronPlugin.py:275#: neutron/plugins/nicira/NeutronPlugin.py:350#: neutron/plugins/nicira/NeutronPlugin.py:356#: neutron/plugins/nicira/NeutronPlugin.py:362#: neutron/plugins/nicira/NeutronPlugin.py:408#: neutron/plugins/nicira/NeutronPlugin.py:438#: neutron/plugins/nicira/NeutronPlugin.py:450 #: neutron/plugins/nicira/NeutronPlugin.py:487 #: neutron/plugins/nicira/NeutronPlugin.py:672#: neutron/plugins/nicira/NeutronPlugin.py:472#: neutron/plugins/nicira/NeutronPlugin.py:494#: neutron/plugins/nicira/NeutronPlugin.py:503#: neutron/plugins/nicira/NeutronPlugin.py:509#: neutron/plugins/nicira/NeutronPlugin.py:528 #: neutron/plugins/nicira/NeutronPlugin.py:1040#: neutron/plugins/nicira/NeutronPlugin.py:540#: neutron/plugins/nicira/NeutronPlugin.py:563#: neutron/plugins/nicira/NeutronPlugin.py:576#: neutron/plugins/nicira/NeutronPlugin.py:584#: neutron/plugins/nicira/NeutronPlugin.py:621#: neutron/plugins/nicira/NeutronPlugin.py:653 #: neutron/plugins/nicira/NeutronPlugin.py:1629#: neutron/plugins/nicira/NeutronPlugin.py:657 #: neutron/plugins/nicira/NeutronPlugin.py:1633#: neutron/plugins/nicira/NeutronPlugin.py:659#: neutron/plugins/nicira/NeutronPlugin.py:700#: neutron/plugins/nicira/NeutronPlugin.py:738#: neutron/plugins/nicira/NeutronPlugin.py:767#: neutron/plugins/nicira/NeutronPlugin.py:771#: neutron/plugins/nicira/NeutronPlugin.py:775#: neutron/plugins/nicira/NeutronPlugin.py:779 #: neutron/plugins/nicira/NeutronPlugin.py:795#: neutron/plugins/nicira/NeutronPlugin.py:801#: neutron/plugins/nicira/NeutronPlugin.py:846#: neutron/plugins/nicira/NeutronPlugin.py:868#: neutron/plugins/nicira/NeutronPlugin.py:958#: neutron/plugins/nicira/NeutronPlugin.py:1022#: neutron/plugins/nicira/NeutronPlugin.py:1050#: neutron/plugins/nicira/NeutronPlugin.py:1053#: neutron/plugins/nicira/NeutronPlugin.py:1149#: neutron/plugins/nicira/NeutronPlugin.py:1165#: neutron/plugins/nicira/NeutronPlugin.py:1176#: neutron/plugins/nicira/NeutronPlugin.py:1239#: neutron/plugins/nicira/NeutronPlugin.py:1265#: neutron/plugins/nicira/NeutronPlugin.py:1367 #: neutron/plugins/nicira/NeutronPlugin.py:1441#: neutron/plugins/nicira/NeutronPlugin.py:1384#: neutron/plugins/nicira/NeutronPlugin.py:1391#: neutron/plugins/nicira/NeutronPlugin.py:1399#: neutron/plugins/nicira/NeutronPlugin.py:1409#: neutron/plugins/nicira/NeutronPlugin.py:1450#: neutron/plugins/nicira/NeutronPlugin.py:1466#: neutron/plugins/nicira/NeutronPlugin.py:1470#: neutron/plugins/nicira/NeutronPlugin.py:1472#: neutron/plugins/nicira/NeutronPlugin.py:1506#: neutron/plugins/nicira/NeutronPlugin.py:1510#: neutron/plugins/nicira/NeutronPlugin.py:1567#: neutron/plugins/nicira/NeutronPlugin.py:1655#: neutron/plugins/nicira/NeutronPlugin.py:1661#: neutron/plugins/nicira/NeutronPlugin.py:1727#: neutron/plugins/nicira/NeutronPlugin.py:1751#: neutron/plugins/nicira/NeutronPlugin.py:1794#: neutron/plugins/nicira/NeutronPlugin.py:1797#: neutron/plugins/nicira/NeutronPlugin.py:1823#: neutron/plugins/nicira/NeutronPlugin.py:1845#: neutron/plugins/nicira/NeutronPlugin.py:1933#: neutron/plugins/nicira/nvplib.py:692 neutron/plugins/nicira/nvplib.py:747#: neutron/plugins/nicira/nvplib.py:742#: neutron/plugins/nicira/nvplib.py:779#: neutron/plugins/nicira/nvplib.py:803#: neutron/plugins/nicira/nvplib.py:833#: neutron/plugins/nicira/nvplib.py:843#: neutron/plugins/nicira/nvplib.py:909#: neutron/plugins/nicira/nvplib.py:1031#: neutron/plugins/nicira/nvplib.py:1057#: neutron/plugins/nicira/nvplib.py:1076#: neutron/plugins/nicira/nvplib.py:1082#: neutron/plugins/nicira/nvplib.py:1096#: neutron/plugins/nicira/nvplib.py:1231#: neutron/plugins/nicira/nvplib.py:1236#: neutron/plugins/nicira/nvplib.py:1274#: neutron/plugins/nicira/nvplib.py:1282#: neutron/plugins/nicira/nvplib.py:1298#: neutron/plugins/nicira/nvplib.py:1309#: neutron/plugins/nicira/common/config.py:133#: neutron/plugins/nicira/common/sync.py:214#: neutron/plugins/nicira/common/sync.py:233#: neutron/plugins/nicira/common/sync.py:255#: neutron/plugins/nicira/common/sync.py:322#: neutron/plugins/nicira/common/sync.py:386#: neutron/plugins/nicira/common/sync.py:461#: neutron/plugins/nicira/common/sync.py:492#: neutron/plugins/nicira/common/sync.py:512#: neutron/plugins/nicira/common/sync.py:516#: neutron/plugins/nicira/common/sync.py:532#: neutron/plugins/nicira/common/sync.py:542#: neutron/plugins/nicira/common/sync.py:546#: neutron/plugins/nicira/common/sync.py:553#: neutron/plugins/nicira/common/sync.py:569#: neutron/plugins/nicira/common/sync.py:582#: neutron/plugins/nicira/common/sync.py:594#: neutron/plugins/nicira/dhcp_meta/rpc.py:121#: neutron/plugins/nicira/dhcp_meta/rpc.py:124#: neutron/plugins/nicira/dhcp_meta/rpc.py:146#: neutron/plugins/nicira/dhcp_meta/rpc.py:154#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:143#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:284#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:300#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:345#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:349#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:402#: neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py:251#~ msgid """" #~ ""In _notify_port_updated() for port %(port_id),"" #~ "" network %(network_id) has no segments"" #~ msgstr """" #~ msgid """" #~ ""Device %(device)s requested by agent "" #~ ""%(agent_id)s has network %(network_id) with"" #~ "" no segments"" #~ msgstr """" #~ msgid """" #~ ""Current network status:%(nvp_net_status)s; Status"" #~ "" in Neutron DB:%(neutron_status)s"" #~ msgstr """" #~ msgid """" #~ ""Found %s logical switches not bound "" #~ ""to Neutron networks. Neutron and NVP "" #~ ""are potentially out of sync"" #~ msgstr """" #~ msgid """" #~ ""Found %s logical ports not bound "" #~ ""to Neutron ports. Neutron and NVP "" #~ ""are potentially out of sync"" #~ msgstr """" #~ msgid """" #~ ""Current router status:%(router_status)s;Status in"" #~ "" Neutron DB:%(db_router_status)s"" #~ msgstr """" #~ msgid """" #~ ""Found %s logical routers not bound "" #~ ""to Neutron routers. Neutron and NVP "" #~ ""are potentially out of sync"" #~ msgstr """" ",62021,27253
openstack%2Fsahara-image-elements~master~I9da4ab70199ed05980508e03aa36d3bb7b360c36,openstack/sahara-image-elements,master,I9da4ab70199ed05980508e03aa36d3bb7b360c36,"Add diskimage-creating script, elements for mirrors",ABANDONED,2013-09-05 15:52:48.000000000,2013-09-06 11:53:11.000000000,,"[{'_account_id': 3}, {'_account_id': 7732}]","[{'number': 1, 'created': '2013-09-05 15:52:48.000000000', 'files': ['elements/yum-mirror/pre-install.d/00-yum', 'diskimage-create/README.rst', 'elements/apt-mirror/pre-install.d/00-apt', 'README.rst', 'elements/apt-mirror/README.md', 'diskimage-create/diskimage-create.sh', 'elements/apt-mirror/finalise.d/99-setup', 'elements/yum-mirror/README.md', 'elements/yum-mirror/finalise.d/99-setup', 'elements/apt-mirror/root.d/0-check', 'elements/yum-mirror/root.d/0-check'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/2d944a4d4b2c294521837184437c3e1c42e902dd', 'message': 'Add diskimage-creating script, elements for mirrors\n\n* Automatic building Fedora and Ubuntu cloud images with all elements from savanna-extra repository\n* Using mirrors for updating images\n\nChange-Id: I9da4ab70199ed05980508e03aa36d3bb7b360c36\n'}]",0,45256,2d944a4d4b2c294521837184437c3e1c42e902dd,2,2,1,6786,,,0,"Add diskimage-creating script, elements for mirrors

* Automatic building Fedora and Ubuntu cloud images with all elements from savanna-extra repository
* Using mirrors for updating images

Change-Id: I9da4ab70199ed05980508e03aa36d3bb7b360c36
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/56/45256/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/yum-mirror/pre-install.d/00-yum', 'diskimage-create/README.rst', 'elements/apt-mirror/pre-install.d/00-apt', 'README.rst', 'elements/apt-mirror/README.md', 'diskimage-create/diskimage-create.sh', 'elements/apt-mirror/finalise.d/99-setup', 'elements/yum-mirror/README.md', 'elements/yum-mirror/finalise.d/99-setup', 'elements/apt-mirror/root.d/0-check', 'elements/yum-mirror/root.d/0-check']",11,2d944a4d4b2c294521837184437c3e1c42e902dd,,"#!/bin/bash if [ -z ""$FEDORA_MIRROR"" ]; then echo ""You should specify parameter 'FEDORA_MIRROR'"" exit 2 fi ",,142,0
openstack%2Fpuppet-sahara~master~I6a1c758ecbbeb07674cbe616d1ef0972e11ce9a3,openstack/puppet-sahara,master,I6a1c758ecbbeb07674cbe616d1ef0972e11ce9a3,Add README,MERGED,2013-09-05 15:47:55.000000000,2013-09-06 11:43:12.000000000,2013-09-06 11:43:12.000000000,"[{'_account_id': 3}, {'_account_id': 7555}]","[{'number': 1, 'created': '2013-09-05 15:47:55.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/60e5f653ce44b72fb89ba955d137c5cac238e754', 'message': 'Add README\n\nChange-Id: I6a1c758ecbbeb07674cbe616d1ef0972e11ce9a3\n'}]",0,45254,60e5f653ce44b72fb89ba955d137c5cac238e754,5,2,1,6786,,,0,"Add README

Change-Id: I6a1c758ecbbeb07674cbe616d1ef0972e11ce9a3
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/54/45254/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,60e5f653ce44b72fb89ba955d137c5cac238e754,,This repo will contain puppet manifests for Savanna ,,1,0
openstack%2Fglance~master~I07a66d0ba7c0f0233d0d03310d83b33f0b92bbe9,openstack/glance,master,I07a66d0ba7c0f0233d0d03310d83b33f0b92bbe9,Remove unused import,MERGED,2013-08-21 14:45:23.000000000,2013-09-06 11:40:25.000000000,2013-09-06 11:40:24.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 6159}, {'_account_id': 6282}, {'_account_id': 6484}, {'_account_id': 6493}, {'_account_id': 7491}]","[{'number': 1, 'created': '2013-08-21 14:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/be3ccf2c7e215bb1a5f1acc44ee199ea11bb2624', 'message': 'Remove unused import\n\nRemove unused import in tests.functional.store modules to make codes\ncleaner.\n\nChange-Id: I07a66d0ba7c0f0233d0d03310d83b33f0b92bbe9\n'}, {'number': 2, 'created': '2013-08-22 00:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5c96013e335526920076fcf4a5923e5f47739498', 'message': 'Remove unused import\n\nRemove unused import in tests.functional.store modules to make codes\ncleaner.\n\nChange-Id: I07a66d0ba7c0f0233d0d03310d83b33f0b92bbe9\n'}, {'number': 3, 'created': '2013-08-24 09:49:07.000000000', 'files': ['glance/tests/functional/store/test_filesystem.py', 'glance/tests/functional/store/test_gridfs.py', 'glance/tests/functional/store/test_http.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/6bd098efe5c8a965a5a6927d06153a66c4a34871', 'message': 'Remove unused import\n\nRemove unused import in tests.functional.store modules to make codes\ncleaner.\n\nChange-Id: I07a66d0ba7c0f0233d0d03310d83b33f0b92bbe9\n'}]",8,43144,6bd098efe5c8a965a5a6927d06153a66c4a34871,17,7,3,6282,,,0,"Remove unused import

Remove unused import in tests.functional.store modules to make codes
cleaner.

Change-Id: I07a66d0ba7c0f0233d0d03310d83b33f0b92bbe9
",git fetch https://review.opendev.org/openstack/glance refs/changes/44/43144/3 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/functional/store/test_filesystem.py', 'glance/tests/functional/store/test_swift.py', 'glance/tests/functional/store/test_gridfs.py', 'glance/tests/functional/store/test_s3.py', 'glance/tests/functional/store/test_http.py']",5,be3ccf2c7e215bb1a5f1acc44ee199ea11bb2624,unusedImport,,import os import os.pathimport glance.tests.utils,0,9
openstack%2Fsahara~master~I07497fea33e095a5ddef02809a25a5ee0741e83a,openstack/sahara,master,I07497fea33e095a5ddef02809a25a5ee0741e83a,Fix developer install guide from horizon,MERGED,2013-09-05 12:47:30.000000000,2013-09-06 11:33:57.000000000,2013-09-06 11:33:57.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6823}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7600}, {'_account_id': 7710}]","[{'number': 1, 'created': '2013-09-05 12:47:30.000000000', 'files': ['doc/source/horizon/dev.environment.guide.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/ea6a310264bd93d99f640e74712834835b374c98', 'message': 'Fix developer install guide from horizon\n\nChange-Id: I07497fea33e095a5ddef02809a25a5ee0741e83a\n'}]",0,45224,ea6a310264bd93d99f640e74712834835b374c98,10,7,1,7710,,,0,"Fix developer install guide from horizon

Change-Id: I07497fea33e095a5ddef02809a25a5ee0741e83a
",git fetch https://review.opendev.org/openstack/sahara refs/changes/24/45224/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/horizon/dev.environment.guide.rst'],1,ea6a310264bd93d99f640e74712834835b374c98,fix_doc_horizon, $ sudo apt-get install git-core python-dev gcc python-setuptools python-virtualenv node-less libssl-dev, $ sudo apt-get install git-core python-dev gcc python-setuptools python-virtualenv node-less,1,1
openstack%2Ftempest~master~Ifcb57f873c2522d2a2103d6adab2f4a9f53a39c8,openstack/tempest,master,Ifcb57f873c2522d2a2103d6adab2f4a9f53a39c8,Added missing xml tests of volume,MERGED,2013-08-29 18:08:29.000000000,2013-09-06 11:11:10.000000000,2013-09-05 13:13:27.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 5511}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6796}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 8698}]","[{'number': 1, 'created': '2013-08-29 18:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/687c79544d2f3182b823e3c77f2cc566386ce64a', 'message': 'Added missing xml tests of volume\n\nVolume test is only running for json\nbecause some tests are missing in xml\nHere added these missing tests in xml:-\n*attach-volume\n*detach-volume\n*upload volume\nadded ""xml"" interface also for running the xml tests.\n\nChange-Id: Ifcb57f873c2522d2a2103d6adab2f4a9f53a39c8\n'}, {'number': 2, 'created': '2013-08-29 18:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5f97ccfe55cdbe1aeaf6b1536b3cfb486e30a0bd', 'message': 'Added missing xml tests of volume\n\nVolume test is only running for json\nbecause some tests are missing in xml\nHere added these missing tests in xml:-\n*attach-volume\n*detach-volume\n*upload volume\nadded ""xml"" interface also for running the xml tests.\n\nChange-Id: Ifcb57f873c2522d2a2103d6adab2f4a9f53a39c8\n'}, {'number': 3, 'created': '2013-08-30 04:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c4fe33dec7e14c2c589f9877085e4cbe13579d4c', 'message': 'Added missing xml tests of volume\n\nVolume test is only running for json\nbecause some tests are missing in xml\nHere added these missing tests in xml:-\n*attach-volume\n*detach-volume\n*upload volume\nadded ""xml"" interface also for running the xml tests.\n\nChange-Id: Ifcb57f873c2522d2a2103d6adab2f4a9f53a39c8\n'}, {'number': 4, 'created': '2013-09-02 12:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2c335747d91f323c99b0fc511547ae1490a843b4', 'message': 'Added missing xml tests of volume\n\nVolume test is only running for json\nbecause some tests are missing in xml\nHere added these missing tests in xml:-\n*attach-volume\n*detach-volume\n*upload volume\nadded ""xml"" interface also for running the xml tests.\n\nAlso fixes: bug #1219779\n\nChange-Id: Ifcb57f873c2522d2a2103d6adab2f4a9f53a39c8\n'}, {'number': 5, 'created': '2013-09-02 13:21:02.000000000', 'files': ['tempest/services/volume/xml/volumes_client.py', 'tempest/services/volume/json/volumes_client.py', 'tempest/api/volume/test_volumes_actions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/789449a321e98f1a5399cf3f607141d975df85c3', 'message': 'Added missing xml tests of volume\n\nVolume test is only running for json\nbecause some tests are missing in xml\nHere added these missing tests in xml:-\n*attach-volume\n*detach-volume\n*upload volume\nadded ""xml"" interface also for running the xml tests.\n\nAlso fixes: bug #1219779\n\nChange-Id: Ifcb57f873c2522d2a2103d6adab2f4a9f53a39c8\n'}]",8,44330,789449a321e98f1a5399cf3f607141d975df85c3,26,11,5,8625,,,0,"Added missing xml tests of volume

Volume test is only running for json
because some tests are missing in xml
Here added these missing tests in xml:-
*attach-volume
*detach-volume
*upload volume
added ""xml"" interface also for running the xml tests.

Also fixes: bug #1219779

Change-Id: Ifcb57f873c2522d2a2103d6adab2f4a9f53a39c8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/30/44330/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/volume/xml/volumes_client.py', 'tempest/api/volume/test_volumes_actions.py']",2,687c79544d2f3182b823e3c77f2cc566386ce64a,bug/1219779," class VolumesActionsTestXML(VolumesActionsTest): _interface = ""xml"" ",,36,0
openstack%2Fsahara~master~I39f1b10ada291a8ff817e7a8bbc21c9024eed27e,openstack/sahara,master,I39f1b10ada291a8ff817e7a8bbc21c9024eed27e,DO NOT MERGE: check sqla 0.7.X,ABANDONED,2013-08-30 19:12:37.000000000,2013-09-06 10:57:33.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-08-30 19:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/71c9ddba7a62f3f476a774cf78aad8ba89fa94c9', 'message': 'DO NOT MERGE: check sqla 0.7.X\n\nChange-Id: I39f1b10ada291a8ff817e7a8bbc21c9024eed27e\n'}, {'number': 2, 'created': '2013-08-31 06:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c7d5089bcc8b360e10d37f5cca0f8567b1a46468', 'message': 'DO NOT MERGE: check sqla 0.7.X\n\nChange-Id: I39f1b10ada291a8ff817e7a8bbc21c9024eed27e\n'}, {'number': 3, 'created': '2013-09-03 05:13:30.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/8adafd93ae5bb621dd8d97fe1fb72ff6aa6d93d0', 'message': 'DO NOT MERGE: check sqla 0.7.X\n\nChange-Id: I39f1b10ada291a8ff817e7a8bbc21c9024eed27e\n'}]",0,44529,8adafd93ae5bb621dd8d97fe1fb72ff6aa6d93d0,11,3,3,6786,,,0,"DO NOT MERGE: check sqla 0.7.X

Change-Id: I39f1b10ada291a8ff817e7a8bbc21c9024eed27e
",git fetch https://review.opendev.org/openstack/sahara refs/changes/29/44529/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,71c9ddba7a62f3f476a774cf78aad8ba89fa94c9,,"SQLAlchemy>=0.7.8,<=0.7.99","SQLAlchemy>=0.7.8,<=0.8.99",1,1
openstack%2Fglance~milestone-proposed~If0e5ffe117200fbfb967c8c95a63608f12dbba58,openstack/glance,milestone-proposed,If0e5ffe117200fbfb967c8c95a63608f12dbba58,Publish recent api changes as v2.2,MERGED,2013-09-05 22:02:08.000000000,2013-09-06 09:58:53.000000000,2013-09-06 09:58:53.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 616}]","[{'number': 1, 'created': '2013-09-05 22:02:08.000000000', 'files': ['glance/tests/unit/test_versions.py', 'glance/tests/functional/test_api.py', 'glance/tests/functional/v1/test_ssl.py', 'glance/api/middleware/version_negotiation.py', 'glance/api/versions.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/ef64e0a29ce3d187dfd0c41bfab7a1a966a5c580', 'message': 'Publish recent api changes as v2.2\n\nThroughout the Havana development cycle, we have added several\nfeatures to the v2 api, without breaking backwards compatibility.\nSo this change bumps up our minor version number.\n\nChange-Id: If0e5ffe117200fbfb967c8c95a63608f12dbba58\n(cherry picked from commit 249f800de13867af31590df557a715cabbc2e1d6)\n'}]",0,45337,ef64e0a29ce3d187dfd0c41bfab7a1a966a5c580,12,3,1,616,,,0,"Publish recent api changes as v2.2

Throughout the Havana development cycle, we have added several
features to the v2 api, without breaking backwards compatibility.
So this change bumps up our minor version number.

Change-Id: If0e5ffe117200fbfb967c8c95a63608f12dbba58
(cherry picked from commit 249f800de13867af31590df557a715cabbc2e1d6)
",git fetch https://review.opendev.org/openstack/glance refs/changes/37/45337/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_versions.py', 'glance/tests/functional/test_api.py', 'glance/tests/functional/v1/test_ssl.py', 'glance/api/middleware/version_negotiation.py', 'glance/api/versions.py']",5,ef64e0a29ce3d187dfd0c41bfab7a1a966a5c580,," build_version_object(2.2, 'v2', 'CURRENT'), build_version_object(2.1, 'v2', 'SUPPORTED'),"," build_version_object(2.1, 'v2', 'CURRENT'),",40,8
openstack%2Fhorizon~master~I126291ca5eb7c607b86446c2351062ce87600bbb,openstack/horizon,master,I126291ca5eb7c607b86446c2351062ce87600bbb,Sync English PO files with the latest code for Havana-3,MERGED,2013-09-06 06:32:16.000000000,2013-09-06 09:40:08.000000000,2013-09-06 09:40:08.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 4978}]","[{'number': 1, 'created': '2013-09-06 06:32:16.000000000', 'files': ['horizon/locale/en/LC_MESSAGES/djangojs.po', 'horizon/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6469afe386274f3df4dc34e95e62ecc372f3a668', 'message': 'Sync English PO files with the latest code for Havana-3\n\nCloses-Bug: #1221539\n\nThis commit updates English PO files only which requires for\ntranslation. Other languages are not updated since they will\nbe update by importing translations from Transifex.\n\nChange-Id: I126291ca5eb7c607b86446c2351062ce87600bbb\n'}]",0,45381,6469afe386274f3df4dc34e95e62ecc372f3a668,6,3,1,841,,,0,"Sync English PO files with the latest code for Havana-3

Closes-Bug: #1221539

This commit updates English PO files only which requires for
translation. Other languages are not updated since they will
be update by importing translations from Transifex.

Change-Id: I126291ca5eb7c607b86446c2351062ce87600bbb
",git fetch https://review.opendev.org/openstack/horizon refs/changes/81/45381/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/en/LC_MESSAGES/djangojs.po', 'horizon/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po']",3,6469afe386274f3df4dc34e95e62ecc372f3a668,bug/1221539,"""POT-Creation-Date: 2013-09-06 06:25+0000\n""#: settings.py:165#: settings.py:166#: settings.py:167#: settings.py:168#: settings.py:169#: settings.py:170#: settings.py:171#: settings.py:172#: settings.py:173#: settings.py:174#: settings.py:175#: settings.py:176#: settings.py:177#: settings.py:178#: api/cinder.py:90#: api/keystone.py:322#: api/keystone.py:348#: api/neutron.py:191#: api/neutron.py:588 #, python-format msgid ""profile_list(): profile_type=%(profile_type)s, params=%(params)s"" msgstr """" #: api/neutron.py:601 #, python-format msgid ""profile_get(): profileid=%(profileid)s, params=%(params)s"" msgstr """" #: api/neutron.py:610 #, python-format msgid ""profile_create(): kwargs=%s"" msgstr """" #: api/neutron.py:619 #, python-format msgid ""profile_delete(): profile_id=%s"" msgstr """" #: api/neutron.py:624 #, python-format msgid ""profile_modify(): profileid=%(profileid)s, kwargs=%(kwargs)s"" msgstr """" #: api/neutron.py:634 #, python-format msgid """" ""profile_bindings_list(): profile_type=%(profile_type)s params=%(params)s"" msgstr """" #: api/nova.py:249#: api/nova.py:266#: api/swift.py:165#: dashboards/admin/defaults/panel.py:25 #: dashboards/admin/defaults/templates/defaults/index.html:3 #: dashboards/admin/defaults/templates/defaults/index.html:6 msgid ""Defaults"" msgstr """" #: dashboards/admin/defaults/tables.py:41 #: dashboards/admin/defaults/workflows.py:81 msgid ""Update Defaults"" msgstr """" #: dashboards/admin/defaults/tables.py:47 #: dashboards/admin/defaults/workflows.py:37 #: dashboards/admin/flavors/tables.py:99 #: dashboards/admin/flavors/workflows.py:48 #: dashboards/admin/overview/views.py:34 #: dashboards/admin/projects/workflows.py:49 #: dashboards/project/databases/templates/databases/_launch_details_help.html:10 #: dashboards/project/instances/templates/instances/_detail_overview.html:31 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:10 #: dashboards/project/overview/views.py:33 usage/tables.py:20 msgid ""VCPUs"" msgstr """" #: dashboards/admin/defaults/tables.py:47 #: dashboards/admin/defaults/workflows.py:49 #: dashboards/admin/projects/workflows.py:59 #: dashboards/admin/projects/workflows.py:67 #: dashboards/project/access_and_security/tabs.py:76 #: dashboards/project/access_and_security/floating_ips/tables.py:66 #: dashboards/project/access_and_security/floating_ips/tables.py:147 msgid ""Floating IPs"" msgstr """" #: dashboards/admin/defaults/tables.py:52 msgid ""Quota Name"" msgstr """" #: dashboards/admin/defaults/tables.py:53 msgid ""Limit"" msgstr """" #: dashboards/admin/defaults/tables.py:60 msgid ""Quotas"" msgstr """" #: dashboards/admin/defaults/tabs.py:30 #: dashboards/admin/defaults/workflows.py:67 msgid ""Default Quotas"" msgstr """" #: dashboards/admin/defaults/tabs.py:47 msgid ""Unable to get quota info."" msgstr """" #: dashboards/admin/defaults/views.py:51 #: dashboards/admin/projects/views.py:141 msgid ""Unable to retrieve default quota values."" msgstr """" #: dashboards/admin/defaults/workflows.py:33 #: dashboards/admin/projects/workflows.py:46 msgid ""Injected File Content Bytes"" msgstr """" #: dashboards/admin/defaults/workflows.py:34 msgid ""Injected File Path Bytes"" msgstr """" #: dashboards/admin/defaults/workflows.py:36 #: dashboards/admin/projects/workflows.py:48 msgid ""Metadata Items"" msgstr """" #: dashboards/admin/defaults/workflows.py:38 #: dashboards/admin/hypervisors/tables.py:73 #: dashboards/admin/instances/panel.py:29 #: dashboards/admin/instances/tables.py:43 #: dashboards/admin/instances/tables.py:128 #: dashboards/admin/instances/templates/instances/index.html:3 #: dashboards/admin/projects/workflows.py:50 #: dashboards/project/databases/tables.py:43 #: dashboards/project/instances/panel.py:25 #: dashboards/project/instances/tables.py:78 #: dashboards/project/instances/tables.py:93 #: dashboards/project/instances/tables.py:122 #: dashboards/project/instances/tables.py:154 #: dashboards/project/instances/tables.py:451 #: dashboards/project/instances/tables.py:465 #: dashboards/project/instances/tables.py:579 #: dashboards/project/instances/templates/instances/index.html:3 #: dashboards/project/instances/templates/instances/index.html:6 msgid ""Instances"" msgstr """" #: dashboards/admin/defaults/workflows.py:40 #: dashboards/admin/projects/workflows.py:52 msgid ""Injected Files"" msgstr """" #: dashboards/admin/defaults/workflows.py:45 #: dashboards/admin/projects/workflows.py:55 #: dashboards/admin/volumes/panel.py:9 dashboards/admin/volumes/tables.py:42 #: dashboards/admin/volumes/templates/volumes/index.html:3 #: dashboards/admin/volumes/templates/volumes/index.html:6 #: dashboards/project/volumes/panel.py:25 #: dashboards/project/volumes/tables.py:43 #: dashboards/project/volumes/tables.py:209 #: dashboards/project/volumes/tables.py:221 #: dashboards/project/volumes/templates/volumes/index.html:3 #: dashboards/project/volumes/templates/volumes/index.html:6 msgid ""Volumes"" msgstr """" #: dashboards/admin/defaults/workflows.py:46 #: dashboards/admin/projects/workflows.py:56 msgid ""Snapshots"" msgstr """" #: dashboards/admin/defaults/workflows.py:47 #: dashboards/admin/projects/workflows.py:57 msgid ""Gigabytes"" msgstr """" #: dashboards/admin/defaults/workflows.py:48 #: dashboards/admin/projects/workflows.py:58 msgid ""RAM (MB)"" msgstr """" #: dashboards/admin/defaults/workflows.py:51 #: dashboards/admin/projects/workflows.py:62 #: dashboards/project/access_and_security/tabs.py:44 #: dashboards/project/access_and_security/security_groups/tables.py:34 #: dashboards/project/access_and_security/security_groups/tables.py:80 #: dashboards/project/instances/templates/instances/_detail_overview.html:58 #: dashboards/project/instances/workflows/create_instance.py:394 #: dashboards/project/instances/workflows/update_instance.py:82 msgid ""Security Groups"" msgstr """" #: dashboards/admin/defaults/workflows.py:53 #: dashboards/admin/projects/workflows.py:64 #: dashboards/project/access_and_security/security_groups/tables.py:178 msgid ""Security Group Rules"" msgstr """" #: dashboards/admin/defaults/workflows.py:54 msgid ""Key Pairs"" msgstr """" #: dashboards/admin/defaults/workflows.py:69 msgid ""From here you can update the default quotas (max limits)."" msgstr """" #: dashboards/admin/defaults/workflows.py:80 msgid ""Update Default Quotas"" msgstr """" #: dashboards/admin/defaults/workflows.py:82 #, python-format msgid ""Default quotas updated \""%s\""."" msgstr """" #: dashboards/admin/defaults/workflows.py:83 #, python-format msgid ""Unable to update default quotas \""%s\""."" msgstr """" #: dashboards/admin/defaults/workflows.py:100 msgid ""Unable to update default quotas."" msgstr """" #: dashboards/admin/domains/panel.py:26 dashboards/admin/domains/tables.py:75 #: dashboards/admin/domains/tables.py:174#: dashboards/admin/domains/tables.py:39 #: dashboards/admin/projects/tables.py:32 msgid ""Modify Groups"" msgstr """" #: dashboards/admin/domains/tables.py:52 #: dashboards/admin/domains/workflows.py:157 #: dashboards/admin/domains/workflows.py:158#: dashboards/admin/domains/tables.py:63#: dashboards/admin/roles/tables.py:42 dashboards/admin/users/tables.py:33#: dashboards/admin/domains/tables.py:74#: dashboards/admin/domains/tables.py:84#: dashboards/admin/domains/tables.py:114#: dashboards/admin/domains/tables.py:139#: dashboards/admin/domains/tables.py:143#: dashboards/admin/domains/tables.py:148#: dashboards/admin/domains/tables.py:162#: dashboards/admin/domains/tables.py:166 #: dashboards/admin/domains/workflows.py:35 #: dashboards/admin/flavors/workflows.py:37 #: dashboards/admin/groups/forms.py:32 dashboards/admin/groups/forms.py:58 #: dashboards/admin/groups/tables.py:100 dashboards/admin/info/tables.py:43 #: dashboards/admin/info/tables.py:73 dashboards/admin/info/tables.py:106 #: dashboards/admin/info/tables.py:137 dashboards/admin/info/tables.py:182#: dashboards/admin/networks/forms.py:35 #: dashboards/admin/networks/forms.py:100#: dashboards/admin/projects/tables.py:117 #: dashboards/admin/projects/workflows.py:104#: dashboards/project/access_and_security/security_groups/forms.py:71 #: dashboards/project/access_and_security/security_groups/tables.py:72#: dashboards/project/database_backups/tables.py:102 #: dashboards/project/database_backups/templates/database_backups/details.html:18 #: dashboards/project/database_backups/templates/database_backups/details.html:42 #: dashboards/project/database_backups/workflows/create_backup.py:31 #: dashboards/project/databases/tables.py:218 #: dashboards/project/databases/templates/databases/_detail_overview.html:9 #: dashboards/project/databases/templates/databases/_launch_details_help.html:9 #: dashboards/project/images_and_snapshots/images/forms.py:47 #: dashboards/project/images_and_snapshots/images/forms.py:154#: dashboards/router/nexus1000v/forms.py:52 #: dashboards/router/nexus1000v/forms.py:123#: dashboards/admin/domains/tables.py:168 #: dashboards/admin/domains/workflows.py:38 #: dashboards/admin/flavors/templates/flavors/_update.html:18#: dashboards/admin/groups/tables.py:102#: dashboards/admin/projects/tables.py:119 #: dashboards/admin/projects/workflows.py:106#: dashboards/project/access_and_security/security_groups/forms.py:77 #: dashboards/project/access_and_security/security_groups/tables.py:73#: dashboards/project/access_and_security/templates/access_and_security/security_groups/_update.html:18#: dashboards/project/database_backups/templates/database_backups/details.html:20 #: dashboards/project/database_backups/workflows/create_backup.py:33 #: dashboards/project/images_and_snapshots/images/forms.py:49 #: dashboards/project/images_and_snapshots/images/forms.py:156#: dashboards/project/volumes/forms.py:304#: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:18#: dashboards/admin/domains/tables.py:169 #: dashboards/admin/projects/workflows.py:98 #: dashboards/admin/users/forms.py:71 dashboards/admin/users/forms.py:140#: dashboards/admin/domains/tables.py:170 #: dashboards/admin/domains/workflows.py:40 #: dashboards/admin/groups/tables.py:166 dashboards/admin/info/tables.py:47 #: dashboards/admin/info/tables.py:168 dashboards/admin/projects/tables.py:121 #: dashboards/admin/projects/workflows.py:108 #: dashboards/admin/projects/workflows.py:463 #: dashboards/admin/users/tables.py:49 dashboards/admin/users/tables.py:128#: dashboards/admin/domains/workflows.py:45 #: dashboards/admin/domains/workflows.py:185#: dashboards/admin/domains/workflows.py:47#: dashboards/admin/domains/workflows.py:64 #: dashboards/admin/projects/workflows.py:240 msgid ""Unable to retrieve group list. Please try again later."" msgstr """" #: dashboards/admin/domains/workflows.py:76 #: dashboards/admin/projects/workflows.py:157 #: dashboards/admin/projects/workflows.py:254 #, python-format msgid ""Could not find default role \""%s\"" in Keystone"" msgstr """" #: dashboards/admin/domains/workflows.py:129 #: dashboards/admin/domains/workflows.py:136 msgid ""Domain Groups"" msgstr """" #: dashboards/admin/domains/workflows.py:135 #: dashboards/admin/projects/workflows.py:312 msgid ""All Groups"" msgstr """" #: dashboards/admin/domains/workflows.py:137 #: dashboards/admin/projects/workflows.py:314 msgid ""No groups found."" msgstr """" #: dashboards/admin/domains/workflows.py:138 #: dashboards/admin/projects/workflows.py:315 msgid ""No groups."" msgstr """" #: dashboards/admin/domains/workflows.py:146 #: dashboards/admin/projects/workflows.py:323 msgid ""Unable to retrieve role list."" msgstr """" #: dashboards/admin/domains/workflows.py:159#: dashboards/admin/domains/workflows.py:160#: dashboards/admin/domains/workflows.py:187#: dashboards/admin/domains/workflows.py:200#: dashboards/admin/domains/workflows.py:201 #: dashboards/admin/flavors/workflows.py:260 #: dashboards/admin/flavors/templates/flavors/_update.html:25#: dashboards/admin/projects/workflows.py:484#: dashboards/admin/domains/workflows.py:202#: dashboards/admin/domains/workflows.py:203#: dashboards/admin/domains/workflows.py:289 #, python-format msgid ""Failed to modify %s domain groups."" msgstr """" #: dashboards/admin/flavors/panel.py:29 dashboards/admin/flavors/tables.py:38 #: dashboards/admin/flavors/tables.py:117 #: dashboards/admin/flavors/templates/flavors/index.html:3 #: dashboards/admin/flavors/templates/flavors/index.html:6 msgid ""Flavors"" msgstr """" #: dashboards/admin/flavors/tables.py:37 #: dashboards/admin/flavors/templates/flavors/extras/create.html:7 #: dashboards/admin/flavors/templates/flavors/extras/edit.html:7 #: dashboards/admin/flavors/templates/flavors/extras/index.html:7 #: dashboards/project/databases/workflows/create_instance.py:33 #: dashboards/project/instances/templates/instances/_detail_overview.html:27 #: dashboards/project/instances/workflows/create_instance.py:92 msgid ""Flavor"" msgstr """" #: dashboards/admin/flavors/tables.py:46 #: dashboards/admin/flavors/workflows.py:175 #: dashboards/admin/flavors/workflows.py:176 #: dashboards/admin/flavors/templates/flavors/create.html:3 #: dashboards/admin/flavors/templates/flavors/create.html:6 msgid ""Create Flavor"" msgstr """" #: dashboards/admin/flavors/tables.py:53 #: dashboards/admin/flavors/workflows.py:259 #: dashboards/admin/flavors/templates/flavors/_update.html:9 #: dashboards/admin/flavors/templates/flavors/update.html:3 #: dashboards/admin/flavors/templates/flavors/update.html:6 msgid ""Edit Flavor"" msgstr """" #: dashboards/admin/flavors/tables.py:60 msgid ""View Extra Specs"" msgstr """" #: dashboards/admin/flavors/tables.py:90 dashboards/admin/flavors/tables.py:94 #, python-format msgid ""%sMB"" msgstr """" #: dashboards/admin/flavors/tables.py:98 msgid ""Flavor Name"" msgstr """" #: dashboards/admin/flavors/tables.py:101 #: dashboards/project/databases/templates/databases/_detail_overview.html:15 #: dashboards/project/databases/templates/databases/_launch_details_help.html:14 #: dashboards/project/instances/templates/instances/_detail_overview.html:29 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:14 #: usage/tables.py:23 msgid ""RAM"" msgstr """" #: dashboards/admin/flavors/tables.py:103 #: dashboards/project/databases/templates/databases/_launch_details_help.html:11 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:11 msgid ""Root Disk"" msgstr """" #: dashboards/admin/flavors/tables.py:105 #: dashboards/project/databases/templates/databases/_launch_details_help.html:12 #: dashboards/project/instances/templates/instances/_detail_overview.html:36 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:12 msgid ""Ephemeral Disk"" msgstr """" #: dashboards/admin/flavors/tables.py:107 msgid ""Swap Disk"" msgstr """" #: dashboards/admin/flavors/tables.py:111 #: dashboards/project/images_and_snapshots/images/forms.py:95 #: dashboards/project/images_and_snapshots/images/forms.py:176 #: dashboards/project/images_and_snapshots/images/tables.py:135 #: dashboards/project/images_and_snapshots/images/tables.py:212 #: dashboards/project/images_and_snapshots/templates/images_and_snapshots/images/_detail_overview.html:19 msgid ""Public"" msgstr """" #: dashboards/admin/flavors/views.py:55 msgid ""Unable to retrieve flavor list."" msgstr """" #: dashboards/admin/flavors/views.py:78 #: dashboards/admin/flavors/extras/views.py:48 msgid ""Unable to retrieve flavor data."" msgstr """" #: dashboards/admin/flavors/workflows.py:34#: dashboards/admin/flavors/workflows.py:40#: dashboards/admin/flavors/workflows.py:43 #: dashboards/admin/networks/forms.py:102#: dashboards/admin/users/forms.py:146 #: dashboards/project/database_backups/templates/database_backups/details.html:22 #: dashboards/project/database_backups/templates/database_backups/details.html:44 #: dashboards/project/databases/templates/databases/_detail_overview.html:11#: dashboards/router/nexus1000v/forms.py:120#: dashboards/admin/flavors/workflows.py:49#: dashboards/admin/flavors/workflows.py:50#: dashboards/admin/flavors/workflows.py:51#: dashboards/admin/flavors/workflows.py:52#: dashboards/admin/flavors/workflows.py:55 #: dashboards/admin/flavors/workflows.py:222 msgid ""Flavor Info"" msgstr """" #: dashboards/admin/flavors/workflows.py:56 msgid ""From here you can create a new flavor to organize projects."" msgstr """" #: dashboards/admin/flavors/workflows.py:68 #: dashboards/admin/flavors/workflows.py:233#: dashboards/admin/flavors/workflows.py:75 #: dashboards/admin/flavors/workflows.py:241#: dashboards/admin/flavors/workflows.py:80#: dashboards/admin/flavors/workflows.py:102 msgid ""Unable to retrieve flavor access list. Please try again later.""#: dashboards/admin/flavors/workflows.py:146 msgid ""Flavor Access"" msgstr """" #: dashboards/admin/flavors/workflows.py:152 msgid """" ""You can control access to this flavor by moving projects from the left "" ""column to the right column. Only projects in the right column can use the "" ""flavor. If there are no projects in the right column, all projects can use "" ""the flavor."" msgstr """" #: dashboards/admin/flavors/workflows.py:157 #, fuzzy msgid ""All Projects"" msgstr ""Projects"" #: dashboards/admin/flavors/workflows.py:158 msgid ""Selected projects"" msgstr """" #: dashboards/admin/flavors/workflows.py:159 msgid ""No projects found."" msgstr """" #: dashboards/admin/flavors/workflows.py:160 msgid ""No projects selected. All projects can use the flavor."" msgstr """" #: dashboards/admin/flavors/workflows.py:177 #, python-format msgid ""Created new flavor \""%s\""."" msgstr """" #: dashboards/admin/flavors/workflows.py:178 #, python-format msgid ""Unable to create flavor \""%s\""."" msgstr """" #: dashboards/admin/flavors/workflows.py:203#: dashboards/admin/flavors/workflows.py:214msgid ""Unable to set flavor access for project %s.""#: dashboards/admin/flavors/workflows.py:224 msgid ""From here you can edit the flavor details.""#: dashboards/admin/flavors/workflows.py:261msgid ""Modified flavor \""%s\"".""#: dashboards/admin/flavors/workflows.py:262 #, python-format msgid ""Unable to modify flavor \""%s\"".""#: dashboards/admin/flavors/workflows.py:308 msgid ""Modified flavor information, but unable to modify flavor access.""#: dashboards/admin/metering/templates/metering/stats.html:81#: dashboards/project/networks/workflows.py:268#: dashboards/admin/flavors/templates/flavors/_update.html:19 msgid ""From here you can alter the sizing of the current flavor.""#: dashboards/admin/flavors/templates/flavors/_update.html:20 msgid """" ""Note: this will not affect the resources allocated to any existing instances "" ""using this flavor."" msgstr """" #: dashboards/admin/flavors/templates/flavors/_update.html:26#: dashboards/project/access_and_security/templates/access_and_security/security_groups/_update.html:25#: dashboards/project/network_topology/templates/network_topology/_create_router.html:20#: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:25 #: dashboards/router/nexus1000v/templates/nexus1000v/_update_network_profile.html:24#: dashboards/admin/groups/panel.py:26 dashboards/admin/groups/tables.py:63 #: dashboards/admin/groups/tables.py:107#: dashboards/admin/groups/tables.py:51#: dashboards/admin/groups/tables.py:62#: dashboards/admin/groups/tables.py:76 dashboards/admin/projects/tables.py:17#: dashboards/admin/groups/tables.py:103#: dashboards/admin/groups/tables.py:124#: dashboards/admin/groups/tables.py:125#: dashboards/admin/groups/tables.py:126 dashboards/admin/groups/tables.py:183 #: dashboards/admin/metering/tables.py:51 dashboards/admin/users/tables.py:50 #: dashboards/admin/users/tables.py:93 #: dashboards/project/databases/tables.py:70 #: dashboards/project/instances/workflows/create_instance.py:50#: dashboards/admin/groups/tables.py:127 dashboards/admin/groups/tables.py:184 #: dashboards/admin/users/panel.py:29 dashboards/admin/users/tables.py:51 #: dashboards/admin/users/tables.py:94 dashboards/admin/users/tables.py:135#: dashboards/project/databases/tables.py:71 #: dashboards/project/databases/tabs.py:37#: dashboards/admin/groups/tables.py:148#: dashboards/admin/groups/tables.py:162 dashboards/admin/users/forms.py:77 #: dashboards/admin/users/forms.py:147 dashboards/admin/users/tables.py:121 #: dashboards/project/databases/tables.py:188#: dashboards/admin/groups/tables.py:163 dashboards/admin/users/forms.py:79 #: dashboards/admin/users/forms.py:149 dashboards/admin/users/tables.py:122#: dashboards/admin/groups/tables.py:165 dashboards/admin/users/tables.py:127#: dashboards/admin/groups/tables.py:175#: dashboards/admin/groups/tables.py:181#: dashboards/admin/groups/tables.py:182#: dashboards/admin/groups/tables.py:213#: dashboards/admin/info/tables.py:181#: dashboards/project/access_and_security/security_groups/forms.py:175 #: dashboards/project/access_and_security/security_groups/forms.py:182#: dashboards/project/instances/workflows/create_instance.py:115#: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:18#: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:15#: dashboards/router/nexus1000v/templates/nexus1000v/_update_network_profile.html:17#: dashboards/admin/info/tables.py:42#: dashboards/admin/info/tables.py:44#: dashboards/admin/info/tables.py:45 dashboards/admin/info/tables.py:107 #: dashboards/admin/info/tables.py:183 dashboards/admin/instances/tables.py:92#: dashboards/admin/info/tables.py:52 dashboards/admin/info/tabs.py:32#: dashboards/admin/info/tables.py:67#: dashboards/admin/info/tables.py:67#: dashboards/admin/info/tables.py:75 dashboards/admin/info/tables.py:141#: dashboards/admin/info/tables.py:79#: dashboards/admin/info/tables.py:88 dashboards/admin/info/tabs.py:48#: dashboards/admin/info/tables.py:108#: dashboards/admin/info/tables.py:109 dashboards/admin/info/tables.py:184#: dashboards/admin/metering/tables.py:186#: dashboards/project/database_backups/tables.py:112 #: dashboards/project/database_backups/templates/database_backups/details.html:24 #: dashboards/project/database_backups/templates/database_backups/details.html:46 #: dashboards/project/databases/tables.py:173 #: dashboards/project/databases/tables.py:226 #: dashboards/project/databases/templates/databases/_detail_overview.html:13#: dashboards/admin/info/tables.py:110 dashboards/admin/info/tables.py:185 #: dashboards/project/overview/views.py:35#: dashboards/admin/info/tables.py:112 dashboards/admin/info/tables.py:187#: dashboards/admin/info/tables.py:121 dashboards/admin/info/tabs.py:81#: dashboards/admin/info/tables.py:139 #: dashboards/project/instances/workflows/create_instance.py:87#: dashboards/admin/info/tables.py:145#: dashboards/admin/info/tables.py:151 dashboards/admin/info/tabs.py:65#: dashboards/admin/info/tables.py:170 dashboards/admin/users/tables.py:49 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:64 msgid ""Disabled""#: dashboards/admin/info/tables.py:175 msgid ""Up""#: dashboards/admin/info/tables.py:177 msgid ""Down"" msgstr """" #: dashboards/admin/info/tables.py:196 dashboards/admin/info/tabs.py:99 msgid ""Network Agents"" msgstr """" #: dashboards/admin/info/tabs.py:58#: dashboards/admin/info/tabs.py:75#: dashboards/admin/info/tabs.py:90#: dashboards/admin/info/tabs.py:111 msgid ""Unable to get network agents list."" msgstr """" #: dashboards/project/databases/tables.py:42#: dashboards/admin/metering/templates/metering/stats.html:76 #: dashboards/admin/networks/forms.py:37#: dashboards/admin/projects/tables.py:91#: dashboards/project/dashboard.py:61#: dashboards/project/instances/workflows/create_instance.py:49 #: dashboards/router/nexus1000v/forms.py:82 #: dashboards/router/nexus1000v/forms.py:135 #: dashboards/router/nexus1000v/tables.py:62 #: dashboards/router/nexus1000v/tables.py:89#: dashboards/project/databases/tables.py:167#: dashboards/project/databases/tables.py:169#: dashboards/admin/metering/panel.py:22 msgid ""Resource Usage"" msgstr """" #: dashboards/admin/metering/tables.py:42 msgid ""up"" msgstr """" #: dashboards/admin/metering/tables.py:44 msgid ""none"" msgstr """" #: dashboards/admin/metering/tables.py:49 #: dashboards/admin/metering/tables.py:59 #: dashboards/admin/metering/tables.py:83 #: dashboards/admin/metering/tables.py:112 #: dashboards/admin/metering/tables.py:180 msgid ""Tenant"" msgstr """" #: dashboards/admin/metering/tables.py:54 #: dashboards/admin/metering/tables.py:189 #: dashboards/project/stacks/tables.py:107 #: dashboards/project/stacks/tables.py:151 msgid ""Resource"" msgstr """" #: dashboards/admin/metering/tables.py:62 msgid ""Disk Read Bytes"" msgstr """" #: dashboards/admin/metering/tables.py:65 msgid ""Disk Read Requests"" msgstr """" #: dashboards/admin/metering/tables.py:68 msgid ""Disk Write Bytes"" msgstr """" #: dashboards/admin/metering/tables.py:72 msgid ""Disk Write Requests"" msgstr """" #: dashboards/admin/metering/tables.py:77 msgid ""Global Disk Usage (average of last 30 days)"" msgstr """" #: dashboards/admin/metering/tables.py:86 msgid ""Network Incoming Bytes"" msgstr """" #: dashboards/admin/metering/tables.py:91 msgid ""Network Incoming Packets"" msgstr """" #: dashboards/admin/metering/tables.py:95 msgid ""Network Outgoing Bytes"" msgstr """" #: dashboards/admin/metering/tables.py:100 msgid ""Network Outgoing Packets"" msgstr """" #: dashboards/admin/metering/tables.py:105 msgid ""Global Network Traffic Usage (average of last 30 days)"" msgstr """" #: dashboards/admin/metering/tables.py:114 msgid ""Network Duration"" msgstr """" #: dashboards/admin/metering/tables.py:118 msgid ""Network Creation Requests"" msgstr """" #: dashboards/admin/metering/tables.py:121 msgid ""Subnet Duration"" msgstr """" #: dashboards/admin/metering/tables.py:124 msgid ""Subnet Creation Requests"" msgstr """" #: dashboards/admin/metering/tables.py:127 #: dashboards/admin/metering/tables.py:139 msgid ""Port Duration"" msgstr """" #: dashboards/admin/metering/tables.py:130 #: dashboards/admin/metering/tables.py:142 msgid ""Port Creation Requests"" msgstr """" #: dashboards/admin/metering/tables.py:133 msgid ""Router Duration"" msgstr """" #: dashboards/admin/metering/tables.py:136 msgid ""Router Creation Requests"" msgstr """" #: dashboards/admin/metering/tables.py:146 msgid ""Floating IP Duration"" msgstr """" #: dashboards/admin/metering/tables.py:150 msgid ""Floating IP Creation Requests"" msgstr """" #: dashboards/admin/metering/tables.py:155 msgid ""Global Network Usage (average of last 30 days)"" msgstr """" #: dashboards/admin/metering/tables.py:174 #: dashboards/admin/metering/tabs.py:74 dashboards/admin/metering/tabs.py:148 #: dashboards/admin/metering/views.py:131 msgid ""Unable to retrieve statistics."" msgstr """" #: dashboards/admin/metering/tables.py:193 msgid ""Object Storage Incoming Bytes"" msgstr """" #: dashboards/admin/metering/tables.py:198 msgid ""Object Storage Outgoing Bytes"" msgstr """" #: dashboards/admin/metering/tables.py:203 msgid ""Total Number of Objects"" msgstr """" #: dashboards/admin/metering/tables.py:208 msgid ""Total Size of Objects "" msgstr """" #: dashboards/admin/metering/tables.py:213 msgid ""Global Object Store Usage (average of last 30 days)"" msgstr """" #: dashboards/admin/metering/tabs.py:38 dashboards/admin/metering/views.py:92 msgid ""Unable to retrieve tenant list."" msgstr """" #: dashboards/admin/metering/tabs.py:81 msgid ""Global Disk Usage"" msgstr """" #: dashboards/admin/metering/tabs.py:95 msgid ""Global Network Traffic Usage"" msgstr """" #: dashboards/admin/metering/tabs.py:108 msgid ""Global Network Usage"" msgstr """" #: dashboards/admin/metering/tabs.py:125 msgid ""Global Object Store Usage"" msgstr """" #: dashboards/admin/metering/tabs.py:157 msgid ""Stats"" msgstr """" #: dashboards/admin/metering/tabs.py:172 msgid ""Unable to retrieve Nova Ceilometer resources."" msgstr """" #: dashboards/admin/metering/tabs.py:182 msgid ""Duration of instance"" msgstr """" #: dashboards/admin/metering/tabs.py:183 msgid ""Duration of instance <type> (openstack types)"" msgstr """" #: dashboards/admin/metering/tabs.py:185 msgid ""Volume of RAM in MB"" msgstr """" #: dashboards/admin/metering/tabs.py:186 msgid ""CPU time used"" msgstr """" #: dashboards/admin/metering/tabs.py:187 msgid ""Average CPU utilisation"" msgstr """" #: dashboards/admin/metering/tabs.py:188 #: dashboards/project/databases/templates/databases/_launch_details_help.html:29 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:28 msgid ""Number of VCPUs"" msgstr """" #: dashboards/admin/metering/tabs.py:189 msgid ""Number of read requests"" msgstr """" #: dashboards/admin/metering/tabs.py:190 msgid ""Number of write requests"" msgstr """" #: dashboards/admin/metering/tabs.py:191 msgid ""Volume of reads in B"" msgstr """" #: dashboards/admin/metering/tabs.py:192 msgid ""Volume of writes in B"" msgstr """" #: dashboards/admin/metering/tabs.py:193 msgid ""Size of root disk in GB"" msgstr """" #: dashboards/admin/metering/tabs.py:194 msgid ""Size of ephemeral disk in GB"" msgstr """" #: dashboards/admin/metering/tabs.py:196 msgid ""Number of incoming bytes on the network for a VM interface"" msgstr """" #: dashboards/admin/metering/tabs.py:198 msgid ""Number of outgoing bytes on the network for a VM interface"" msgstr """" #: dashboards/admin/metering/tabs.py:200 msgid ""Number of incoming packets for a VM interface"" msgstr """" #: dashboards/admin/metering/tabs.py:202 msgid ""Number of outgoing packets for a VM interface"" msgstr """" #: dashboards/admin/metering/templates/metering/index.html:3 msgid ""Resources usage Overview"" msgstr """" #: dashboards/admin/metering/templates/metering/index.html:6 msgid ""Resources Usage Overview"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:10 msgid ""Metric"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:14 msgid ""Compute (Nova)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:22 msgid ""Network (Neutron)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:23 msgid ""Duration of network"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:24 msgid ""Creation requests for this network"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:25 msgid ""Update requests for this network"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:26 msgid ""Duration of subnet"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:27 msgid ""Creation requests for this subnet"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:28 msgid ""Update requests for this subnet"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:29 msgid ""Creation requests for this port"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:30 msgid ""Update requests for this port"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:31 msgid ""Duration of router"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:32 msgid ""Creation requests for this router"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:33 msgid ""Update requests for this router"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:34 msgid ""Duration of floating ip"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:35 msgid ""Creation requests for this floating ip"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:36 msgid ""Update requests for this floating ip"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:39 msgid ""Image (Glance)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:40 msgid ""Uploaded image size"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:41 msgid ""Number of update on the image"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:42 msgid ""Number of upload of the image"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:43 msgid ""Number of delete on the image"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:44 msgid ""Image is downloaded"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:45 msgid ""Image is served out"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:48 msgid ""Volume (Cinder)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:49 msgid ""Duration of volume"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:50 msgid ""Size of volume"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:53 msgid ""Object Storage (Swift)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:54 msgid ""Number of objects"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:55 msgid ""Total size of stored objects"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:56 msgid ""Number of containers"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:57 msgid ""Number of incoming bytes"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:58 msgid ""Number of outgoing bytes"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:59 msgid ""Number of API requests against swift"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:62 msgid ""Energy (Kwapi)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:63 msgid ""Amount of energy"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:64 msgid ""Power consumption"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:71 msgid ""Group by"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:75 msgid ""--"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:86 msgid ""Avg."" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:87 msgid ""Min."" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:88 msgid ""Max."" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:89 msgid ""Sum."" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:94 msgid ""Period"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:98 msgid ""Last day"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:99 msgid ""Last week"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:100 msgid ""Last 15 days"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:101 msgid ""Last 30 days"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:102 msgid ""Last year"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:103 msgid ""Other"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:108 msgid ""From"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:115 msgid ""To"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:127 msgid ""Statistics of all resources"" msgstr """" #: dashboards/admin/networks/forms.py:39 #: dashboards/project/networks/workflows.py:41 #: dashboards/router/nexus1000v/tables.py:39 #: dashboards/router/nexus1000v/tables.py:61 #: dashboards/router/nexus1000v/tables.py:74 #: dashboards/router/nexus1000v/tabs.py:24 msgid ""Network Profile"" msgstr """" #: dashboards/admin/networks/forms.py:40 #: dashboards/admin/networks/forms.py:105#: dashboards/admin/networks/forms.py:42 #: dashboards/admin/networks/forms.py:106#: dashboards/admin/networks/forms.py:44 #: dashboards/admin/networks/forms.py:107#: dashboards/admin/networks/forms.py:53 dashboards/admin/users/forms.py:43#: dashboards/project/networks/workflows.py:53 msgid ""Select a profile"" msgstr """" #: dashboards/admin/networks/forms.py:75 #: dashboards/project/networks/workflows.py:63 #: dashboards/router/nexus1000v/views.py:56 msgid ""Network Profiles could not be retrieved."" msgstr """" #: dashboards/admin/networks/forms.py:89#: dashboards/admin/networks/forms.py:95#: dashboards/admin/networks/forms.py:118#: dashboards/admin/networks/forms.py:123#: dashboards/admin/projects/workflows.py:68 #: dashboards/project/instances/workflows/create_instance.py:480#: dashboards/project/networks/workflows.py:70#: dashboards/project/networks/workflows.py:267#: dashboards/project/access_and_security/security_groups/forms.py:133 #: dashboards/project/access_and_security/security_groups/forms.py:142 #: dashboards/project/access_and_security/security_groups/forms.py:149#: dashboards/admin/projects/workflows.py:69#: dashboards/project/databases/tabs.py:27#: dashboards/project/networks/workflows.py:116#: dashboards/admin/projects/workflows.py:71#: dashboards/project/networks/workflows.py:85#: dashboards/project/access_and_security/security_groups/forms.py:198 #: dashboards/project/access_and_security/security_groups/forms.py:210 #: dashboards/project/access_and_security/security_groups/forms.py:220#: dashboards/project/networks/workflows.py:98#: dashboards/project/networks/workflows.py:100#: dashboards/router/nexus1000v/templates/nexus1000v/_update_network_profile.html:23#: dashboards/router/nexus1000v/templates/nexus1000v/update_network_profile.html:3#: dashboards/admin/overview/views.py:66 dashboards/admin/projects/views.py:92#: dashboards/admin/projects/tables.py:92 #: dashboards/admin/projects/tables.py:125#: dashboards/admin/projects/tables.py:48#: dashboards/admin/projects/tables.py:56 #: dashboards/admin/projects/workflows.py:334 #: dashboards/admin/projects/workflows.py:335#: dashboards/admin/projects/tables.py:67 #: dashboards/admin/projects/workflows.py:483#: dashboards/admin/projects/tables.py:120#: dashboards/admin/projects/views.py:61 #: dashboards/router/nexus1000v/views.py:45#: dashboards/admin/projects/views.py:133 msgid ""Unable to retrieve default Neutron quota values.""#: dashboards/admin/projects/views.py:171 dashboards/admin/users/views.py:97 msgid ""Unable to retrieve project domain."" msgstr """" #: dashboards/admin/projects/views.py:185#: dashboards/admin/projects/workflows.py:70 #: dashboards/admin/routers/panel.py:25 dashboards/admin/routers/tables.py:71 #: dashboards/admin/routers/templates/routers/index.html:3 #: dashboards/admin/routers/templates/routers/index.html:6 #: dashboards/project/routers/panel.py:25 #: dashboards/project/routers/tables.py:34 #: dashboards/project/routers/tables.py:138 #: dashboards/project/routers/templates/routers/index.html:3 #: dashboards/project/routers/templates/routers/index.html:6 msgid ""Routers""#: dashboards/admin/projects/workflows.py:84#: dashboards/admin/projects/workflows.py:86#: dashboards/admin/projects/workflows.py:101 #: dashboards/admin/users/forms.py:74 dashboards/admin/users/forms.py:143 msgid ""Domain Name"" msgstr """" #: dashboards/admin/projects/workflows.py:123 #: dashboards/admin/projects/workflows.py:466#: dashboards/admin/projects/workflows.py:124#: dashboards/admin/projects/workflows.py:143#: dashboards/admin/projects/workflows.py:209 #: dashboards/admin/projects/workflows.py:216#: dashboards/admin/projects/workflows.py:215#: dashboards/admin/projects/workflows.py:217#: dashboards/admin/projects/workflows.py:218#: dashboards/admin/projects/workflows.py:226#: dashboards/admin/projects/workflows.py:306 #: dashboards/admin/projects/workflows.py:313#: dashboards/admin/projects/workflows.py:336#: dashboards/admin/projects/workflows.py:337#: dashboards/admin/projects/workflows.py:399#: dashboards/admin/projects/workflows.py:402#: dashboards/admin/projects/workflows.py:433#: dashboards/admin/projects/workflows.py:458#: dashboards/admin/projects/workflows.py:468#: dashboards/admin/projects/workflows.py:485#: dashboards/admin/projects/workflows.py:486#: dashboards/admin/projects/workflows.py:581#: dashboards/admin/projects/workflows.py:616#: dashboards/admin/projects/workflows.py:619#: dashboards/admin/projects/workflows.py:691#: dashboards/admin/projects/workflows.py:721#: dashboards/admin/roles/tables.py:72#: dashboards/admin/roles/panel.py:26 dashboards/admin/roles/tables.py:53 #: dashboards/admin/roles/tables.py:77#: dashboards/admin/roles/tables.py:52 dashboards/admin/users/forms.py:92#: dashboards/admin/roles/tables.py:73#: dashboards/admin/users/forms.py:62 dashboards/project/instances/forms.py:73 #: dashboards/project/instances/workflows/create_instance.py:438 #: dashboards/settings/password/forms.py:48#: dashboards/admin/users/forms.py:82 dashboards/admin/users/forms.py:152 #: dashboards/project/databases/workflows/create_instance.py:96#: dashboards/admin/users/forms.py:87 dashboards/admin/users/forms.py:158#: dashboards/admin/users/forms.py:90 dashboards/admin/users/forms.py:161#: dashboards/admin/users/forms.py:121#: dashboards/admin/users/forms.py:131#: dashboards/admin/users/forms.py:135#: dashboards/admin/users/forms.py:190#: dashboards/admin/users/forms.py:193#: dashboards/admin/users/tables.py:19#: dashboards/admin/users/tables.py:48#: dashboards/admin/users/tables.py:48#: dashboards/admin/users/tables.py:81#: dashboards/admin/users/views.py:123#: dashboards/project/dashboard.py:54 msgid ""Manage Databases"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:402#: dashboards/project/access_and_security/security_groups/views.py:125#: dashboards/project/volumes/forms.py:266#: dashboards/project/volumes/forms.py:268#: dashboards/project/instances/workflows/create_instance.py:379#: dashboards/project/access_and_security/security_groups/forms.py:73#: dashboards/project/access_and_security/security_groups/forms.py:74#: dashboards/project/access_and_security/security_groups/forms.py:86 #, python-format msgid ""Successfully updated security group: %s"" msgstr """" #: dashboards/project/access_and_security/security_groups/forms.py:92 msgid ""Unable to update security group."" msgstr """" #: dashboards/project/access_and_security/security_groups/forms.py:98 #: dashboards/project/access_and_security/security_groups/tables.py:96#: dashboards/project/access_and_security/security_groups/forms.py:107 #: dashboards/project/access_and_security/security_groups/forms.py:112 #: dashboards/project/access_and_security/security_groups/forms.py:113 #: dashboards/project/access_and_security/security_groups/forms.py:114 #: dashboards/project/access_and_security/security_groups/forms.py:115 #: dashboards/project/access_and_security/security_groups/forms.py:116 #: dashboards/project/access_and_security/security_groups/forms.py:117 #: dashboards/project/access_and_security/security_groups/forms.py:118 #: dashboards/project/access_and_security/security_groups/tables.py:159#: dashboards/project/access_and_security/security_groups/forms.py:122 #: dashboards/project/access_and_security/security_groups/forms.py:129 #: dashboards/project/access_and_security/security_groups/tables.py:164#: dashboards/project/access_and_security/security_groups/forms.py:123#: dashboards/project/access_and_security/security_groups/forms.py:132 #: dashboards/project/access_and_security/security_groups/forms.py:139 #: dashboards/project/access_and_security/security_groups/forms.py:140#: dashboards/project/access_and_security/security_groups/forms.py:134 #: dashboards/project/access_and_security/security_groups/tables.py:167#: dashboards/project/access_and_security/security_groups/forms.py:144 #: dashboards/project/access_and_security/security_groups/forms.py:155 #: dashboards/project/access_and_security/security_groups/forms.py:166#: dashboards/project/access_and_security/security_groups/forms.py:153 #: dashboards/project/access_and_security/security_groups/forms.py:160#: dashboards/project/access_and_security/security_groups/forms.py:164 #: dashboards/project/access_and_security/security_groups/forms.py:171#: dashboards/project/access_and_security/security_groups/forms.py:177#: dashboards/project/access_and_security/security_groups/forms.py:186 #: dashboards/project/access_and_security/security_groups/forms.py:193#: dashboards/project/access_and_security/security_groups/forms.py:188#: dashboards/project/access_and_security/security_groups/forms.py:197 #: dashboards/project/access_and_security/security_groups/tables.py:168#: dashboards/project/access_and_security/security_groups/forms.py:199 #: dashboards/project/access_and_security/security_groups/forms.py:222 #: dashboards/project/access_and_security/security_groups/forms.py:227#: dashboards/project/access_and_security/security_groups/forms.py:200#: dashboards/project/access_and_security/security_groups/forms.py:213#: dashboards/project/access_and_security/security_groups/forms.py:231 #: dashboards/project/access_and_security/security_groups/forms.py:239 #: dashboards/project/access_and_security/security_groups/tables.py:162#: dashboards/project/access_and_security/security_groups/forms.py:233#: dashboards/project/access_and_security/security_groups/forms.py:234#: dashboards/project/access_and_security/security_groups/forms.py:249#: dashboards/project/access_and_security/security_groups/forms.py:259#: dashboards/project/access_and_security/security_groups/forms.py:260#: dashboards/project/access_and_security/security_groups/forms.py:261#: dashboards/project/access_and_security/security_groups/forms.py:263#: dashboards/project/access_and_security/security_groups/forms.py:268 #: dashboards/project/access_and_security/security_groups/tables.py:133#: dashboards/project/access_and_security/security_groups/forms.py:269 #: dashboards/project/access_and_security/security_groups/tables.py:135#: dashboards/project/access_and_security/security_groups/forms.py:295#: dashboards/project/access_and_security/security_groups/forms.py:298#: dashboards/project/access_and_security/security_groups/forms.py:301#: dashboards/project/access_and_security/security_groups/forms.py:304#: dashboards/project/access_and_security/security_groups/forms.py:314#: dashboards/project/access_and_security/security_groups/forms.py:318#: dashboards/project/access_and_security/security_groups/forms.py:321#: dashboards/project/access_and_security/security_groups/forms.py:324#: dashboards/project/access_and_security/security_groups/forms.py:355#: dashboards/project/access_and_security/security_groups/forms.py:378#: dashboards/project/access_and_security/security_groups/forms.py:384#: dashboards/project/access_and_security/templates/access_and_security/security_groups/_update.html:8 #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_update.html:24 #: dashboards/project/access_and_security/templates/access_and_security/security_groups/update.html:3 #: dashboards/project/access_and_security/templates/access_and_security/security_groups/update.html:6 msgid ""Edit Security Group"" msgstr """" #: dashboards/project/access_and_security/security_groups/tables.py:66#: dashboards/project/access_and_security/security_groups/tables.py:87#: dashboards/project/access_and_security/security_groups/tables.py:97#: dashboards/project/access_and_security/security_groups/tables.py:140#: dashboards/project/access_and_security/security_groups/views.py:83#: dashboards/project/access_and_security/security_groups/views.py:132#: dashboards/project/databases/templates/databases/_launch_details_help.html:19#: dashboards/project/access_and_security/templates/access_and_security/security_groups/_update.html:19 msgid ""From here you can modify name and description of a security group."" msgstr """" #: dashboards/project/stacks/forms.py:67#: dashboards/project/database_backups/tables.py:105 #: dashboards/project/databases/tables.py:221#: dashboards/project/database_backups/panel.py:25 #: dashboards/project/database_backups/templates/database_backups/index.html:3 msgid ""Database Backups"" msgstr """" #: dashboards/project/database_backups/tables.py:43 #: dashboards/project/databases/tables.py:107 msgid ""Create Backup"" msgstr """" #: dashboards/project/database_backups/tables.py:50 msgid ""Restore Backup"" msgstr """" #: dashboards/project/database_backups/tables.py:61 #: dashboards/project/databases/tables.py:68 #: dashboards/project/databases/tables.py:84 #: dashboards/project/loadbalancers/tables.py:72 #: dashboards/project/loadbalancers/tables.py:85 #: dashboards/project/loadbalancers/tables.py:93 #: dashboards/project/loadbalancers/tables.py:101 #: dashboards/project/loadbalancers/workflows.py:596 #: dashboards/project/stacks/tables.py:43 msgid ""Delete"" msgstr """" #: dashboards/project/database_backups/tables.py:62 #: dashboards/project/images_and_snapshots/volume_snapshots/tables.py:39 #: dashboards/project/loadbalancers/tables.py:73 #: dashboards/project/loadbalancers/tables.py:86 #: dashboards/project/loadbalancers/tables.py:94 #: dashboards/project/loadbalancers/tables.py:102 #: dashboards/project/stacks/tables.py:44 #: dashboards/project/volumes/tables.py:44 msgid ""Scheduled deletion of"" msgstr """" #: dashboards/project/database_backups/tables.py:63 #: dashboards/project/database_backups/workflows/create_backup.py:62 #: dashboards/project/databases/workflows/create_instance.py:127 msgid ""Backup"" msgstr """" #: dashboards/project/database_backups/tables.py:64 #: dashboards/project/database_backups/tables.py:118 #: dashboards/project/database_backups/templates/database_backups/index.html:6 #: dashboards/project/databases/tables.py:232 #: dashboards/project/databases/tabs.py:90 msgid ""Backups"" msgstr """" #: dashboards/project/database_backups/tables.py:103 #: dashboards/project/databases/tables.py:219 msgid ""Created At"" msgstr """" #: dashboards/project/database_backups/tables.py:107 #: dashboards/project/databases/tables.py:223 msgid ""Backup File"" msgstr """" #: dashboards/project/database_backups/tables.py:109 #: dashboards/project/databases/tables.py:54 #: dashboards/project/databases/tables.py:86 msgid ""Database"" msgstr """" #: dashboards/project/database_backups/views.py:52 #, fuzzy msgid ""Not Found"" msgstr ""Page Not Found"" #: dashboards/project/database_backups/views.py:64 msgid ""Error getting database backup list."" msgstr """" #: dashboards/project/database_backups/views.py:92 #, python-format msgid ""Unable to retrieve details for backup: %s"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/_backup_details_help.html:3 msgid ""Specify the details for the backup."" msgstr """" #: dashboards/project/database_backups/templates/database_backups/backup.html:3 #: dashboards/project/database_backups/templates/database_backups/backup.html:6 #: dashboards/project/database_backups/workflows/create_backup.py:61 msgid ""Backup Database"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:3 msgid ""Backup Detail"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:12 msgid ""Backup Overview"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:15 #: dashboards/project/databases/templates/databases/_detail_overview.html:6 #: dashboards/project/images_and_snapshots/templates/images_and_snapshots/images/_detail_overview.html:6 #: dashboards/project/images_and_snapshots/templates/images_and_snapshots/snapshots/_detail_overview.html:7 #: dashboards/project/instances/templates/instances/_detail_overview.html:7 #: dashboards/project/instances/workflows/update_instance.py:120 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:6 #: dashboards/project/stacks/templates/stacks/_resource_overview.html:6 #: dashboards/project/volumes/templates/volumes/_detail_overview.html:7 msgid ""Info"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:26 msgid ""Backup File Location"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:28 msgid ""Initial Volume Size"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:29 #: dashboards/project/databases/templates/databases/_launch_details_help.html:11 #: dashboards/project/databases/templates/databases/_launch_details_help.html:12 #: dashboards/project/databases/templates/databases/_launch_details_help.html:13 #: dashboards/project/images_and_snapshots/templates/images_and_snapshots/snapshots/_detail_overview.html:38 #: dashboards/project/instances/templates/instances/_detail_overview.html:34 #: dashboards/project/instances/templates/instances/_detail_overview.html:37 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:11 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:12 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:13 #: dashboards/project/volumes/templates/volumes/_detail_overview.html:28 #: dashboards/project/volumes/templates/volumes/_limits.html:10 #: dashboards/project/volumes/templates/volumes/_limits.html:11 msgid ""GB"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:30 msgid ""Created On"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:32 msgid ""Backup Duration"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:39 msgid ""Database Info"" msgstr """" #: dashboards/project/database_backups/workflows/create_backup.py:32 msgid ""Database Instance"" msgstr """" #: dashboards/project/database_backups/workflows/create_backup.py:36 msgid ""Optional Backup Description"" msgstr """" #: dashboards/project/database_backups/workflows/create_backup.py:39 #: dashboards/project/databases/workflows/create_instance.py:41 #: dashboards/project/instances/workflows/create_instance.py:140 msgid ""Details"" msgstr """" #: dashboards/project/database_backups/workflows/create_backup.py:49 msgid ""Unable to list database instance to backup."" msgstr """" #: dashboards/project/database_backups/workflows/create_backup.py:63 #, python-format msgid ""Scheduled backup \""%(name)s\""."" msgstr """" #: dashboards/project/database_backups/workflows/create_backup.py:64 #: dashboards/project/databases/workflows/create_instance.py:169 #: dashboards/project/instances/workflows/create_instance.py:553 #, python-format msgid ""Unable to launch %(count)s named \""%(name)s\""."" msgstr """" #: dashboards/project/database_backups/workflows/create_backup.py:74 #: dashboards/project/databases/workflows/create_instance.py:175 #: dashboards/project/instances/workflows/create_instance.py:568 msgid ""instance"" msgstr """" #: dashboards/project/database_backups/workflows/create_backup.py:86 msgid ""Error creating database backup."" msgstr """" #: dashboards/project/databases/panel.py:25 msgid ""Database Instances"" msgstr """" #: dashboards/project/databases/tables.py:40 #: dashboards/project/instances/tables.py:75 msgid ""Terminate"" msgstr """" #: dashboards/project/databases/tables.py:41 #: dashboards/project/instances/tables.py:76 msgid ""Scheduled termination of"" msgstr """" #: dashboards/project/databases/tables.py:52 msgid ""Restart"" msgstr """" #: dashboards/project/databases/tables.py:53 msgid ""Restarted"" msgstr """" #: dashboards/project/databases/tables.py:55 #: dashboards/project/databases/tables.py:87 #: dashboards/project/databases/tables.py:179 #: dashboards/project/databases/tables.py:190 #: dashboards/project/databases/tables.py:207 #: dashboards/project/databases/tabs.py:65 #: dashboards/project/databases/templates/databases/index.html:3 #: dashboards/project/databases/templates/databases/index.html:6 msgid ""Databases"" msgstr """" #: dashboards/project/databases/tables.py:69 #: dashboards/project/databases/tables.py:85 msgid ""Deleted"" msgstr """" #: dashboards/project/databases/tables.py:78 msgid ""Error deleting database user."" msgstr """" #: dashboards/project/databases/tables.py:94 msgid ""Error deleting database on instance."" msgstr """" #: dashboards/project/databases/tables.py:100 #: dashboards/project/databases/templates/databases/launch.html:3 #: dashboards/project/instances/tables.py:183 #: dashboards/project/instances/tables.py:204 #: dashboards/project/instances/workflows/create_instance.py:550 #: dashboards/project/network_topology/templates/network_topology/index.html:27 msgid ""Launch Instance"" msgstr """" #: dashboards/project/databases/tables.py:136 msgid ""Not Assigned"" msgstr """" #: dashboards/project/databases/tables.py:141 #, python-format msgid ""%(name)s | %(RAM)s RAM"" msgstr """" #: dashboards/project/databases/tables.py:145 #: dashboards/project/instances/tables.py:492 #: dashboards/project/instances/tables.py:499 msgid ""Not available"" msgstr """" #: dashboards/project/databases/tables.py:153 msgid ""-"" msgstr """" #: dashboards/project/databases/tables.py:166 #: dashboards/project/databases/tables.py:203 #: dashboards/project/databases/workflows/create_instance.py:32 msgid ""Database Name"" msgstr """" #: dashboards/project/databases/tables.py:189 msgid ""Allowed Hosts"" msgstr """" #: dashboards/project/databases/tables.py:194 msgid ""Database Instance Users"" msgstr """" #: dashboards/project/databases/views.py:53 msgid ""Unable to retrieve database size information."" msgstr """" #: dashboards/project/databases/views.py:72 msgid ""Unable to retrieve database instances."" msgstr """" #: dashboards/project/databases/views.py:106 #, python-format msgid ""Unable to retrieve details for database instance: %s"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview.html:3 #: dashboards/project/instances/templates/instances/_detail_overview.html:4 #: dashboards/project/overview/templates/overview/usage.html:3 msgid ""Instance Overview"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview.html:21 msgid ""Connection Info"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview.html:25 msgid ""Instance IP Address"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview.html:27 msgid ""Database Port"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview.html:29 msgid ""Connection Examples"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_details_help.html:3 #: dashboards/project/instances/templates/instances/_launch_details_help.html:5 msgid ""Specify the details for launching an instance."" msgstr """" #: dashboards/project/databases/templates/databases/_launch_details_help.html:4 #: dashboards/project/instances/templates/instances/_launch_details_help.html:6 msgid """" ""The chart below shows the resources used by this project in relation to the "" ""project's quotas."" msgstr """" #: dashboards/project/databases/templates/databases/_launch_details_help.html:6 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:6 msgid ""Flavor Details"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_details_help.html:13 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:13 msgid ""Total Disk"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_details_help.html:14 #: dashboards/project/databases/templates/databases/_launch_details_help.html:37 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:14 msgid ""MB"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_details_help.html:21 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:21 msgid ""Number of Instances"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_details_help.html:37 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:35 msgid ""Total RAM"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:3 msgid ""Create an initial database and/or add initial users."" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:5 msgid ""Create Initial Databases"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:6 msgid ""Optionally provide a comma separated list of databases to create:"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:9 msgid ""Create Initial Admin User"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:10 msgid """" ""Create an optional initial user.\n"" "" This user will have access to all databases you create."" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:13 msgid ""Username (required)"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:14 msgid ""Password (required)"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:15 #: dashboards/project/databases/workflows/create_instance.py:98 msgid ""Host (optional)"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:16 msgid """" ""Allow the user to connect from this host\n"" "" only. If not provided this use will be allowed to connect from "" ""anywhere.\n"" "" "" msgstr """" #: dashboards/project/databases/templates/databases/_launch_restore_help.html:3 msgid ""Create this database from a previous backup."" msgstr """" #: dashboards/project/databases/templates/databases/detail.html:3 msgid ""Database Detail"" msgstr """" #: dashboards/project/databases/templates/databases/launch.html:6 #: dashboards/project/databases/workflows/create_instance.py:166 msgid ""Launch Database"" msgstr """" #: dashboards/project/databases/templates/databases/update.html:3 #: dashboards/project/databases/templates/databases/update.html:6 #: dashboards/project/instances/tables.py:217 #: dashboards/project/instances/workflows/update_instance.py:133 msgid ""Edit Instance"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:34 #: dashboards/project/instances/workflows/create_instance.py:93 msgid ""Size of image to launch."" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:35 msgid ""Volume Size"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:38 msgid ""Size of the volume in GB."" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:66 #: dashboards/project/instances/workflows/create_instance.py:281 #: dashboards/project/instances/workflows/resize_instance.py:80 #: usage/base.py:184 msgid ""Unable to retrieve quota information."" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:88 msgid ""Initial Database"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:90 msgid ""Comma separated list of databases to create"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:92 msgid ""Initial Admin User"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:94 msgid ""Initial admin user to add"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:100 msgid ""Host or IP that the user is allowed to connect through."" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:104 msgid ""Initialize Databases"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:112 msgid ""You must specify a password if you create a user."" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:115 msgid ""You must specify at least one database if you create a user."" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:129 msgid ""Select a backup to Restore"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:132 msgid ""Restore From Backup"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:155 msgid ""Unable to find backup!"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:167 #: dashboards/project/images_and_snapshots/images/tables.py:37 #: dashboards/project/instances/workflows/create_instance.py:551 #: dashboards/project/stacks/templates/stacks/_create.html:24 msgid ""Launch"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:168 #: dashboards/project/instances/workflows/create_instance.py:552 #, python-format msgid ""Launched %(count)s named \""%(name)s\""."" msgstr """" #: dashboards/project/volumes/forms.py:120#: dashboards/project/images_and_snapshots/images/forms.py:53#: dashboards/project/images_and_snapshots/images/forms.py:54 #: dashboards/project/images_and_snapshots/images/forms.py:61 #: dashboards/project/images_and_snapshots/images/forms.py:67#: dashboards/project/images_and_snapshots/images/forms.py:55 #: dashboards/project/images_and_snapshots/images/forms.py:69 #: dashboards/project/images_and_snapshots/images/forms.py:74#: dashboards/project/images_and_snapshots/images/forms.py:62#: dashboards/project/images_and_snapshots/images/forms.py:70#: dashboards/project/images_and_snapshots/images/forms.py:76 #: dashboards/project/images_and_snapshots/images/forms.py:172#: dashboards/project/images_and_snapshots/images/forms.py:81#: dashboards/project/images_and_snapshots/images/forms.py:82 #: dashboards/project/images_and_snapshots/images/forms.py:89#: dashboards/project/images_and_snapshots/images/forms.py:88#: dashboards/project/images_and_snapshots/images/forms.py:96 #: dashboards/project/images_and_snapshots/images/forms.py:177#: dashboards/project/images_and_snapshots/images/forms.py:108#: dashboards/project/images_and_snapshots/images/forms.py:111#: dashboards/project/images_and_snapshots/images/forms.py:145#: dashboards/project/images_and_snapshots/images/forms.py:149#: dashboards/project/images_and_snapshots/images/forms.py:158#: dashboards/project/images_and_snapshots/images/forms.py:163#: dashboards/project/images_and_snapshots/images/forms.py:168#: dashboards/project/images_and_snapshots/images/forms.py:181#: dashboards/project/images_and_snapshots/images/forms.py:208#: dashboards/project/volumes/forms.py:126#: dashboards/project/volumes/forms.py:302#: dashboards/project/instances/templates/instances/_detail_overview.html:113 #: dashboards/project/instances/workflows/create_instance.py:109 #: dashboards/project/instances/workflows/create_instance.py:294#: dashboards/project/instances/workflows/create_instance.py:111#: dashboards/project/instances/workflows/create_instance.py:149#: dashboards/project/instances/workflows/create_instance.py:90#: dashboards/project/instances/templates/instances/_detail_overview.html:110#: dashboards/project/instances/templates/instances/_detail_overview.html:114#: dashboards/project/instances/workflows/create_instance.py:64#: dashboards/project/instances/workflows/create_instance.py:77 msgid ""--- Select source ---""#: dashboards/project/instances/workflows/create_instance.py:78 msgid ""Boot from image."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:79 msgid ""Boot from snapshot."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:80#: dashboards/project/instances/workflows/create_instance.py:81 msgid ""Boot from image (creates a new volume)."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:83#: dashboards/project/instances/workflows/create_instance.py:98#: dashboards/project/instances/workflows/create_instance.py:100 msgid ""Instance Boot Source""#: dashboards/project/instances/workflows/create_instance.py:103 msgid ""Choose Your Boot Source Type.""#: dashboards/project/instances/workflows/create_instance.py:106 msgid ""Instance Snapshot""#: dashboards/project/instances/workflows/create_instance.py:122 msgid ""Device size (GB)""#: dashboards/project/instances/workflows/create_instance.py:124 msgid ""Volume size in gigabytes (integer value).""#: dashboards/project/instances/workflows/create_instance.py:127 #: dashboards/project/volumes/forms.py:232 msgid ""Device Name"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:130 msgid ""Volume mount point (e.g. 'vda' mounts at '/dev/vda')."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:133 msgid ""Delete on Terminate"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:136 msgid ""Delete volume on instance terminate"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:160 msgid ""Unable to retrieve list of images ."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:170""quota available. ""#: dashboards/project/instances/workflows/create_instance.py:188 msgid """" ""There are no image sources available; you must first create an image before "" ""attemtping to launch an instance.""#: dashboards/project/instances/workflows/create_instance.py:196 msgid """" ""There are no snapshot sources available; you must first create an snapshot "" ""before attemtping to launch an instance.""#: dashboards/project/instances/workflows/create_instance.py:204 msgid """" ""You can't select an instance source when booting from a Volume. The Volume "" ""is your source and should contain the operating system."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:213 msgid """" ""Launching multiple instances is only supported for images and instance "" ""snapshots."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:219 msgid ""volume_image_id"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:222 msgid ""You must set volume size"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:224 #: dashboards/project/instances/workflows/create_instance.py:231 msgid ""You must set device name"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:229 msgid ""You must select a snapshot."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:251#: dashboards/project/instances/workflows/create_instance.py:260#: dashboards/project/instances/workflows/create_instance.py:266#: dashboards/project/instances/workflows/create_instance.py:268#: dashboards/project/instances/workflows/create_instance.py:291 #: dashboards/project/volumes/forms.py:113 msgid ""Snapshot""#: dashboards/project/instances/workflows/create_instance.py:296 #, python-format msgid ""%(name)s - %(size)s GB (%(label)s)""#: dashboards/project/instances/workflows/create_instance.py:310 msgid ""Select Instance Snapshot""#: dashboards/project/instances/workflows/create_instance.py:312 msgid ""No snapshots available."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:316 msgid ""Select Volume"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:324 msgid ""Unable to retrieve list of volumes."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:328 msgid ""Select Volume Snapshot"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:337 msgid ""Unable to retrieve list of volume snapshots.""msgid ""Which keypair to use for authentication."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:385 msgid ""Admin Pass"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:391 msgid ""Confirm Admin Pass"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:398#: dashboards/project/instances/workflows/create_instance.py:403#: dashboards/project/instances/workflows/create_instance.py:413#: dashboards/project/instances/workflows/create_instance.py:417#: dashboards/project/instances/workflows/create_instance.py:419#: dashboards/project/instances/workflows/create_instance.py:428#: dashboards/project/instances/workflows/create_instance.py:460#: dashboards/project/instances/workflows/create_instance.py:462#: dashboards/project/instances/workflows/create_instance.py:469#: dashboards/project/instances/workflows/create_instance.py:485#: dashboards/project/instances/workflows/create_instance.py:487#: dashboards/project/instances/workflows/create_instance.py:490 msgid ""Policy Profiles"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:492 msgid ""Launch instance with this policy profile"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:496#: dashboards/project/instances/workflows/create_instance.py:498#: dashboards/project/instances/workflows/create_instance.py:510#: dashboards/project/instances/workflows/create_instance.py:519 msgid ""Unable to retrieve profiles.""#: dashboards/project/instances/workflows/create_instance.py:565#: dashboards/project/instances/workflows/create_instance.py:616 #, python-format msgid ""Horizon->Create Port with %(netid)s %(profile_id)s"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:623 #, python-format msgid ""Port not created for profile-id (%s).""#: dashboards/project/stacks/forms.py:66msgid ""ID:""msgid ""Tenant ID:""msgid ""Pool ID:""msgid ""Address:""msgid ""Protocol Port:""msgid ""Weight:""msgid ""Admin State Up:""msgid ""Status:""msgid ""Type:""msgid ""Delay:""msgid ""Timeout:""msgid ""Max Retries:""msgid ""HTTP Method:""msgid ""URL Path:""msgid ""Expected Codes:""msgid ""VIP ID:""msgid ""Name:""msgid ""Subnet ID:""msgid ""Protocol:""msgid ""Load Balancing Method:""msgid ""Members:""msgid ""Health Monitors:""msgid ""Session Persistence:""msgid ""Cookie Name:""#, fuzzy msgid ""Connection Limit:"" msgstr ""Projects""#: dashboards/project/network_topology/instances/tables.py:24 msgid ""NT_Instances""#: dashboards/project/network_topology/ports/tables.py:30 msgid ""NT_Interfaces"" msgstr """" #: dashboards/project/network_topology/routers/tables.py:31 msgid ""NT_Routers"" msgstr """" #: dashboards/project/network_topology/templates/network_topology/_create_router.html:8 #: dashboards/project/network_topology/templates/network_topology/_create_router.html:19 #: dashboards/project/routers/templates/routers/_create.html:9 #: dashboards/project/routers/templates/routers/_create.html:20 msgid ""Create router"" msgstr """" #: dashboards/project/network_topology/templates/network_topology/create_router.html:3#: dashboards/project/network_topology/templates/network_topology/create_router.html:6 msgid ""Create a Router"" msgstr """" #: dashboards/project/network_topology/templates/network_topology/index.html:13 msgid ""This pane needs javascript support."" msgstr """" #: dashboards/project/network_topology/templates/network_topology/index.html:22 msgid ""Small"" msgstr """" #: dashboards/project/network_topology/templates/network_topology/index.html:23 msgid ""Normal"" msgstr """" msgid ""There are no networks, routers, or connected instances to display.""#: dashboards/project/networks/workflows.py:71#: dashboards/project/networks/workflows.py:88#: dashboards/project/networks/workflows.py:90#: dashboards/project/networks/workflows.py:93#: dashboards/project/networks/workflows.py:103#: dashboards/project/networks/workflows.py:112#: dashboards/project/networks/workflows.py:117#: dashboards/project/networks/workflows.py:128#: dashboards/project/networks/workflows.py:134#: dashboards/project/networks/workflows.py:138#: dashboards/project/networks/workflows.py:143#: dashboards/project/networks/workflows.py:146#: dashboards/project/networks/workflows.py:166#: dashboards/project/networks/workflows.py:170#: dashboards/project/networks/workflows.py:171#: dashboards/project/networks/workflows.py:178#: dashboards/project/networks/workflows.py:179#: dashboards/project/networks/workflows.py:184#: dashboards/project/networks/workflows.py:185""destination_cidr&gt;,&lt;nexthop&gt; (e.g., 192.168.200.0/24,10.56.1.254) "" ""and one entry per line.""#: dashboards/project/networks/workflows.py:192#: dashboards/project/networks/workflows.py:193#: dashboards/project/networks/workflows.py:199#: dashboards/project/networks/workflows.py:208#: dashboards/project/networks/workflows.py:220#: dashboards/project/networks/workflows.py:226#: dashboards/project/networks/workflows.py:244#: dashboards/project/networks/workflows.py:269#: dashboards/project/networks/workflows.py:270#: dashboards/project/networks/workflows.py:294#: dashboards/project/networks/workflows.py:298#: dashboards/project/networks/workflows.py:354#: dashboards/project/networks/workflows.py:358#: dashboards/project/networks/workflows.py:374#: dashboards/project/networks/workflows.py:382#: dashboards/project/networks/subnets/workflows.py:107 msgid ""Gateway IP (optional)"" msgstr """" #: dashboards/router/nexus1000v/forms.py:75 #: dashboards/router/nexus1000v/forms.py:81 #: dashboards/router/nexus1000v/forms.py:133#: dashboards/project/routers/tables.py:33 dashboards/router/dashboard.py:25#: dashboards/project/stacks/forms.py:61#: dashboards/project/stacks/forms.py:62#: dashboards/project/stacks/forms.py:65#: dashboards/project/stacks/forms.py:68#: dashboards/project/stacks/forms.py:73 dashboards/project/stacks/forms.py:77#: dashboards/project/stacks/forms.py:74#: dashboards/project/stacks/forms.py:80 dashboards/project/stacks/forms.py:84#: dashboards/project/stacks/forms.py:81#: dashboards/project/stacks/forms.py:87 dashboards/project/stacks/forms.py:92#: dashboards/project/stacks/forms.py:88#: dashboards/project/stacks/forms.py:116#: dashboards/project/stacks/forms.py:122#: dashboards/project/stacks/forms.py:127#: dashboards/project/stacks/forms.py:144#: dashboards/project/stacks/forms.py:166#: dashboards/project/stacks/forms.py:179#: dashboards/project/stacks/forms.py:180#: dashboards/project/stacks/forms.py:184#: dashboards/project/stacks/forms.py:185#: dashboards/project/stacks/forms.py:188#: dashboards/project/stacks/forms.py:189#: dashboards/project/stacks/forms.py:200#: dashboards/project/stacks/forms.py:201#: dashboards/project/stacks/forms.py:263#: dashboards/project/stacks/forms.py:267#: dashboards/project/volumes/forms.py:49#: dashboards/project/volumes/forms.py:81#: dashboards/project/volumes/forms.py:88#: dashboards/project/volumes/forms.py:98#: dashboards/project/volumes/forms.py:104#: dashboards/project/volumes/forms.py:114#: dashboards/project/volumes/forms.py:127#: dashboards/project/volumes/forms.py:138#: dashboards/project/volumes/forms.py:166#: dashboards/project/volumes/forms.py:178#: dashboards/project/volumes/forms.py:187#: dashboards/project/volumes/forms.py:194#: dashboards/project/volumes/forms.py:208#: dashboards/project/volumes/forms.py:216#: dashboards/project/volumes/forms.py:229#: dashboards/project/volumes/forms.py:230#: dashboards/project/volumes/forms.py:274#: dashboards/project/volumes/forms.py:288#: dashboards/project/volumes/forms.py:297#: dashboards/project/volumes/forms.py:321#: dashboards/project/volumes/forms.py:327#: dashboards/router/nexus1000v/forms.py:34 msgid ""Select a tenant"" msgstr """" #: dashboards/router/nexus1000v/forms.py:39 msgid ""Projects could not be retrieved."" msgstr """" #: dashboards/router/nexus1000v/forms.py:54 #: dashboards/router/nexus1000v/forms.py:124 #: dashboards/router/nexus1000v/tables.py:64 msgid ""Segment Type"" msgstr """" #: dashboards/router/nexus1000v/forms.py:55 msgid ""VLAN"" msgstr """" #: dashboards/router/nexus1000v/forms.py:56 msgid ""VXLAN"" msgstr """" #: dashboards/router/nexus1000v/forms.py:61 #: dashboards/router/nexus1000v/forms.py:130 #: dashboards/router/nexus1000v/tables.py:66 msgid ""Segment Range"" msgstr """" #: dashboards/router/nexus1000v/forms.py:63 msgid ""1-4093 for VLAN"" msgstr """" #: dashboards/router/nexus1000v/forms.py:66 #: dashboards/router/nexus1000v/forms.py:73 #: dashboards/router/nexus1000v/tables.py:68 msgid ""Multicast IP Range"" msgstr """" #: dashboards/router/nexus1000v/forms.py:91 #: dashboards/router/nexus1000v/forms.py:139 #, python-format msgid ""request = %(req)s, params = %(params)s"" msgstr """" #: dashboards/router/nexus1000v/forms.py:104 #, python-format msgid ""Network Profile %s was successfully created."" msgstr """" #: dashboards/router/nexus1000v/forms.py:111 #, python-format msgid ""Failed to create network profile %s"" msgstr """" #: dashboards/router/nexus1000v/forms.py:150 #, python-format msgid ""Network Profile %s was successfully updated."" msgstr """" #: dashboards/router/nexus1000v/forms.py:156 #, python-format msgid ""Failed to update network profile (%s)."" msgstr """" #: dashboards/router/nexus1000v/panel.py:26 msgid ""Cisco Nexus 1000v"" msgstr """" #: dashboards/router/nexus1000v/tables.py:33 #: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:9 #: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:24 #: dashboards/router/nexus1000v/templates/nexus1000v/create_network_profile.html:3 #: dashboards/router/nexus1000v/templates/nexus1000v/create_network_profile.html:6 msgid ""Create Network Profile"" msgstr """" #: dashboards/router/nexus1000v/tables.py:40 msgid ""Netork Profiles"" msgstr """" #: dashboards/router/nexus1000v/tables.py:46 #, python-format msgid ""Failed to delete network profile (%s)."" msgstr """" #: dashboards/router/nexus1000v/tables.py:54 #: dashboards/router/nexus1000v/templates/nexus1000v/_update_network_profile.html:8 msgid ""Edit Network Profile"" msgstr """" #: dashboards/router/nexus1000v/tables.py:60 #: dashboards/router/nexus1000v/tables.py:87 msgid ""Profile ID"" msgstr """" #: dashboards/router/nexus1000v/tables.py:70 msgid ""Physical Network Name"" msgstr """" #: dashboards/router/nexus1000v/tables.py:81 msgid ""Edit Policy Profile"" msgstr """" #: dashboards/router/nexus1000v/tables.py:88 #: dashboards/router/nexus1000v/tables.py:93 #: dashboards/router/nexus1000v/tabs.py:33 msgid ""Policy Profile"" msgstr """" #: dashboards/router/nexus1000v/views.py:128 #, python-format msgid ""Network Profile object=%s"" msgstr """" #: dashboards/router/nexus1000v/views.py:131 msgid ""Unable to retrieve network profile details."" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:19 msgid ""Select a name for your network profile."" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/_update_network_profile.html:18 msgid ""You may update the editable properties of your network profile here."" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/index.html:3 #: dashboards/router/nexus1000v/templates/nexus1000v/network_profile/index.html:3 #: dashboards/router/nexus1000v/templates/nexus1000v/policy_profile/index.html:3 msgid ""Cisco Nexus 1000V Networking"" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/index.html:6 #: dashboards/router/nexus1000v/templates/nexus1000v/network_profile/index.html:6 #: dashboards/router/nexus1000v/templates/nexus1000v/policy_profile/index.html:6 msgid ""Cisco Nexus 1000V"" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/update_network_profile.html:6 msgid ""Update Network Profile"" msgstr """" #: dashboards/settings/password/forms.py:33#: dashboards/settings/password/forms.py:35#: dashboards/settings/password/forms.py:40#: dashboards/settings/password/forms.py:63 msgid ""Password changed. Please log in again to continue.""#: dashboards/settings/password/forms.py:68#: dashboards/settings/password/forms.py:71#: local/local_settings.py:171 test/settings.py:112 msgid ""AKI - Amazon Kernel Image"" msgstr """" #: local/local_settings.py:172 test/settings.py:113 msgid ""AMI - Amazon Machine Image"" msgstr """" #: local/local_settings.py:173 test/settings.py:114 msgid ""ARI - Amazon Ramdisk Image"" msgstr """" #: local/local_settings.py:174 test/settings.py:115 msgid ""ISO - Optical Disk Image"" msgstr """" #: local/local_settings.py:175 test/settings.py:116 msgid ""QCOW2 - QEMU Emulator"" msgstr """" #: local/local_settings.py:176 test/settings.py:117 msgid ""Raw"" msgstr """" #: local/local_settings.py:177 test/settings.py:118 msgid ""VDI"" msgstr """" #: local/local_settings.py:178 test/settings.py:119 msgid ""VHD"" msgstr """" #: local/local_settings.py:179 test/settings.py:120 msgid ""VMDK"" msgstr """" #: test/settings.py:66#: usage/base.py:136#: usage/base.py:146#: usage/base.py:163#: usage/base.py:166#: usage/base.py:170","""POT-Creation-Date: 2013-08-28 14:31+0800\n""#: settings.py:156#: settings.py:157#: settings.py:158#: settings.py:159#: settings.py:160#: settings.py:161#: settings.py:162#: settings.py:163#: settings.py:164#: settings.py:165#: settings.py:166#: settings.py:167#: settings.py:168#: settings.py:169#: api/cinder.py:87#: api/keystone.py:296#: api/keystone.py:322#: api/neutron.py:173#: api/nova.py:245#: api/nova.py:262#: api/swift.py:163#: dashboards/admin/domains/panel.py:26 dashboards/admin/domains/tables.py:58 #: dashboards/admin/domains/tables.py:154#: dashboards/admin/domains/tables.py:37 #: dashboards/admin/domains/workflows.py:59 #: dashboards/admin/domains/workflows.py:60#: dashboards/admin/domains/tables.py:47#: dashboards/admin/roles/tables.py:41 dashboards/admin/users/tables.py:30#: dashboards/admin/domains/tables.py:57#: dashboards/admin/domains/tables.py:66#: dashboards/admin/domains/tables.py:96#: dashboards/admin/domains/tables.py:120#: dashboards/admin/domains/tables.py:124#: dashboards/admin/domains/tables.py:129#: dashboards/admin/domains/tables.py:142#: dashboards/admin/domains/tables.py:146 #: dashboards/admin/domains/workflows.py:33 #: dashboards/admin/flavors/forms.py:41 dashboards/admin/groups/forms.py:32 #: dashboards/admin/groups/forms.py:58 dashboards/admin/groups/tables.py:95 #: dashboards/admin/info/tables.py:77 dashboards/admin/info/tables.py:107 #: dashboards/admin/info/tables.py:140 dashboards/admin/info/tables.py:170#: dashboards/admin/networks/forms.py:34 dashboards/admin/networks/forms.py:76#: dashboards/admin/projects/tables.py:111 #: dashboards/admin/projects/workflows.py:90#: dashboards/project/access_and_security/security_groups/tables.py:60#: dashboards/project/images_and_snapshots/images/forms.py:43 #: dashboards/project/images_and_snapshots/images/forms.py:166#: dashboards/admin/domains/tables.py:148 #: dashboards/admin/domains/workflows.py:36 #: dashboards/admin/flavors/templates/flavors/_create.html:18 #: dashboards/admin/flavors/templates/flavors/_edit.html:18#: dashboards/admin/groups/tables.py:97#: dashboards/admin/projects/tables.py:113 #: dashboards/admin/projects/workflows.py:92#: dashboards/project/access_and_security/security_groups/tables.py:61#: dashboards/project/images_and_snapshots/images/forms.py:45 #: dashboards/project/images_and_snapshots/images/forms.py:168#: dashboards/project/volumes/forms.py:324#: dashboards/admin/domains/tables.py:149#: dashboards/admin/domains/tables.py:150 #: dashboards/admin/domains/workflows.py:38 #: dashboards/admin/groups/tables.py:158 dashboards/admin/info/tables.py:81 #: dashboards/admin/projects/tables.py:115 #: dashboards/admin/projects/workflows.py:94 #: dashboards/admin/projects/workflows.py:427 #: dashboards/admin/users/tables.py:41 dashboards/admin/users/tables.py:113#: dashboards/admin/domains/workflows.py:43 #: dashboards/admin/domains/workflows.py:88#: dashboards/admin/domains/workflows.py:45#: dashboards/admin/domains/workflows.py:61#: dashboards/admin/domains/workflows.py:62#: dashboards/admin/domains/workflows.py:90#: dashboards/admin/domains/workflows.py:103#: dashboards/admin/domains/workflows.py:104 #: dashboards/admin/flavors/templates/flavors/_edit.html:25#: dashboards/admin/projects/workflows.py:446#: dashboards/admin/domains/workflows.py:105#: dashboards/admin/domains/workflows.py:106#: dashboards/admin/flavors/forms.py:38#: dashboards/admin/flavors/forms.py:44#: dashboards/admin/flavors/forms.py:47 dashboards/admin/networks/forms.py:78#: dashboards/admin/users/forms.py:128#: dashboards/admin/flavors/forms.py:52 dashboards/admin/flavors/tables.py:52 #: dashboards/admin/info/tables.py:28 dashboards/admin/overview/views.py:34 #: dashboards/admin/projects/workflows.py:49 #: dashboards/project/instances/templates/instances/_detail_overview.html:31 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:10 #: dashboards/project/overview/views.py:33 usage/tables.py:20 msgid ""VCPUs"" msgstr """" #: dashboards/admin/flavors/forms.py:53#: dashboards/admin/flavors/forms.py:54#: dashboards/admin/flavors/forms.py:55#: dashboards/admin/flavors/forms.py:56#: dashboards/admin/flavors/forms.py:64 dashboards/admin/flavors/forms.py:82#: dashboards/admin/flavors/forms.py:71#: dashboards/admin/flavors/forms.py:89#: dashboards/admin/flavors/forms.py:104 #, python-format msgid ""Created flavor \""%s\"".""#: dashboards/admin/flavors/forms.py:108#: dashboards/admin/flavors/forms.py:140msgid ""Updated flavor \""%s\"".""#: dashboards/admin/flavors/forms.py:144 msgid ""Unable to update flavor.""#: dashboards/admin/flavors/panel.py:29 dashboards/admin/flavors/tables.py:15 #: dashboards/admin/flavors/tables.py:66 #: dashboards/admin/flavors/templates/flavors/index.html:3 #: dashboards/admin/flavors/templates/flavors/index.html:6 msgid ""Flavors"" msgstr """" #: dashboards/admin/flavors/tables.py:14 #: dashboards/admin/flavors/templates/flavors/extras/create.html:7 #: dashboards/admin/flavors/templates/flavors/extras/edit.html:7 #: dashboards/admin/flavors/templates/flavors/extras/index.html:7 #: dashboards/project/instances/templates/instances/_detail_overview.html:27 #: dashboards/project/instances/workflows/create_instance.py:189 msgid ""Flavor"" msgstr """" #: dashboards/admin/flavors/tables.py:23 #: dashboards/admin/flavors/templates/flavors/_create.html:9 #: dashboards/admin/flavors/templates/flavors/_create.html:24 #: dashboards/admin/flavors/templates/flavors/create.html:3 #: dashboards/admin/flavors/templates/flavors/create.html:6 msgid ""Create Flavor"" msgstr """" #: dashboards/admin/flavors/tables.py:30 #: dashboards/admin/flavors/templates/flavors/_edit.html:9 #: dashboards/admin/flavors/templates/flavors/edit.html:3 #: dashboards/admin/flavors/templates/flavors/edit.html:6 msgid ""Edit Flavor"" msgstr """" #: dashboards/admin/flavors/tables.py:37 msgid ""View Extra Specs"" msgstr """" #: dashboards/admin/flavors/tables.py:43 dashboards/admin/flavors/tables.py:47msgid ""%sMB""#: dashboards/admin/flavors/tables.py:51 msgid ""Flavor Name""#: dashboards/admin/flavors/tables.py:54 #: dashboards/project/instances/templates/instances/_detail_overview.html:29 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:14 #: usage/tables.py:23 msgid ""RAM"" msgstr """" #: dashboards/admin/flavors/tables.py:56 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:11 msgid ""Root Disk"" msgstr """" #: dashboards/admin/flavors/tables.py:58 #: dashboards/project/instances/templates/instances/_detail_overview.html:36 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:12 msgid ""Ephemeral Disk"" msgstr """" #: dashboards/admin/flavors/tables.py:60 msgid ""Swap Disk"" msgstr """" #: dashboards/admin/flavors/views.py:52 msgid ""Unable to retrieve flavor list."" msgstr """" #: dashboards/admin/flavors/views.py:79 #: dashboards/admin/flavors/extras/views.py:48 msgid ""Unable to retrieve flavor data.""#: dashboards/project/networks/workflows.py:243#: dashboards/admin/flavors/templates/flavors/_create.html:19 msgid ""From here you can define the sizing of a new flavor.""#: dashboards/admin/flavors/templates/flavors/_create.html:25 #: dashboards/admin/flavors/templates/flavors/_edit.html:26#: dashboards/admin/flavors/templates/flavors/_edit.html:19 msgid ""From here you can alter the sizing of the current flavor."" msgstr """" #: dashboards/admin/flavors/templates/flavors/_edit.html:20 msgid """" ""Note: this will not affect the resources allocated to any existing instances "" ""using this flavor."" msgstr """" #: dashboards/admin/groups/panel.py:26 dashboards/admin/groups/tables.py:61 #: dashboards/admin/groups/tables.py:102#: dashboards/admin/groups/tables.py:50#: dashboards/admin/groups/tables.py:60#: dashboards/admin/groups/tables.py:73 dashboards/admin/projects/tables.py:18#: dashboards/admin/groups/tables.py:98#: dashboards/admin/groups/tables.py:119#: dashboards/admin/groups/tables.py:120#: dashboards/admin/groups/tables.py:121 dashboards/admin/groups/tables.py:175 #: dashboards/admin/users/tables.py:42 dashboards/admin/users/tables.py:79 #: dashboards/project/instances/workflows/create_instance.py:48#: dashboards/admin/groups/tables.py:122 dashboards/admin/groups/tables.py:176 #: dashboards/admin/users/panel.py:29 dashboards/admin/users/tables.py:43 #: dashboards/admin/users/tables.py:80 dashboards/admin/users/tables.py:120#: dashboards/admin/groups/tables.py:142#: dashboards/admin/groups/tables.py:154 dashboards/admin/users/forms.py:72 #: dashboards/admin/users/forms.py:129 dashboards/admin/users/tables.py:106#: dashboards/admin/groups/tables.py:155 dashboards/admin/users/forms.py:74 #: dashboards/admin/users/forms.py:131 dashboards/admin/users/tables.py:107#: dashboards/admin/groups/tables.py:157 dashboards/admin/users/tables.py:112#: dashboards/admin/groups/tables.py:167#: dashboards/admin/groups/tables.py:173#: dashboards/admin/groups/tables.py:174#: dashboards/admin/groups/tables.py:204#: dashboards/project/access_and_security/security_groups/forms.py:148 #: dashboards/project/access_and_security/security_groups/forms.py:155#: dashboards/admin/hypervisors/tables.py:73 #: dashboards/admin/instances/panel.py:29 #: dashboards/admin/instances/tables.py:43 #: dashboards/admin/instances/tables.py:128 #: dashboards/admin/instances/templates/instances/index.html:3 #: dashboards/admin/projects/workflows.py:50 #: dashboards/project/instances/panel.py:25 #: dashboards/project/instances/tables.py:78 #: dashboards/project/instances/tables.py:93 #: dashboards/project/instances/tables.py:122 #: dashboards/project/instances/tables.py:154 #: dashboards/project/instances/tables.py:451 #: dashboards/project/instances/tables.py:465 #: dashboards/project/instances/tables.py:579 #: dashboards/project/instances/templates/instances/index.html:3 #: dashboards/project/instances/templates/instances/index.html:6 msgid ""Instances"" msgstr """" #: dashboards/admin/info/tables.py:30 #: dashboards/admin/projects/workflows.py:59 #: dashboards/project/access_and_security/tabs.py:76 #: dashboards/project/access_and_security/floating_ips/tables.py:66 #: dashboards/project/access_and_security/floating_ips/tables.py:147 msgid ""Floating IPs"" msgstr """" #: dashboards/admin/info/tables.py:35 msgid ""Quota Name"" msgstr """" #: dashboards/admin/info/tables.py:36 msgid ""Limit"" msgstr """" #: dashboards/admin/info/tables.py:43 msgid ""Quotas"" msgstr """" #: dashboards/admin/info/tables.py:76#: dashboards/admin/info/tables.py:78#: dashboards/admin/info/tables.py:79 dashboards/admin/info/tables.py:141 #: dashboards/admin/instances/tables.py:92#: dashboards/admin/info/tables.py:86 dashboards/admin/info/tabs.py:55#: dashboards/admin/info/tables.py:101#: dashboards/admin/info/tables.py:101#: dashboards/admin/info/tables.py:109 dashboards/admin/info/tables.py:174#: dashboards/admin/info/tables.py:113#: dashboards/admin/info/tables.py:122 dashboards/admin/info/tabs.py:71#: dashboards/admin/info/tables.py:142#: dashboards/admin/info/tables.py:143#: dashboards/admin/info/tables.py:144 dashboards/project/overview/views.py:35#: dashboards/admin/info/tables.py:146#: dashboards/admin/info/tables.py:154 dashboards/admin/info/tabs.py:104#: dashboards/admin/info/tables.py:172 #: dashboards/project/instances/workflows/create_instance.py:186#: dashboards/admin/info/tables.py:178#: dashboards/admin/info/tables.py:184 dashboards/admin/info/tabs.py:88#: dashboards/admin/info/tabs.py:32 msgid ""Default Quotas""#: dashboards/admin/info/tabs.py:49 msgid ""Unable to get quota info.""#: dashboards/admin/info/tabs.py:81#: dashboards/admin/info/tabs.py:98#: dashboards/admin/info/tabs.py:113#: dashboards/admin/networks/forms.py:36#: dashboards/admin/projects/tables.py:86#: dashboards/project/dashboard.py:54#: dashboards/project/instances/workflows/create_instance.py:47#: dashboards/admin/networks/forms.py:37 dashboards/admin/networks/forms.py:81#: dashboards/admin/networks/forms.py:39 dashboards/admin/networks/forms.py:82#: dashboards/admin/networks/forms.py:41 dashboards/admin/networks/forms.py:83#: dashboards/admin/networks/forms.py:50 dashboards/admin/users/forms.py:44#: dashboards/admin/networks/forms.py:71#: dashboards/admin/networks/forms.py:94#: dashboards/admin/networks/forms.py:99#: dashboards/project/instances/workflows/create_instance.py:463#: dashboards/project/networks/workflows.py:46#: dashboards/project/networks/workflows.py:242#: dashboards/project/access_and_security/security_groups/forms.py:106 #: dashboards/project/access_and_security/security_groups/forms.py:115 #: dashboards/project/access_and_security/security_groups/forms.py:122#: dashboards/project/networks/workflows.py:91#: dashboards/project/networks/workflows.py:58#: dashboards/project/access_and_security/security_groups/forms.py:171 #: dashboards/project/access_and_security/security_groups/forms.py:183 #: dashboards/project/access_and_security/security_groups/forms.py:193#: dashboards/project/networks/workflows.py:73#: dashboards/admin/overview/views.py:66 dashboards/admin/projects/views.py:89#: dashboards/admin/projects/tables.py:87 #: dashboards/admin/projects/tables.py:119#: dashboards/admin/projects/tables.py:31 msgid ""Modify Groups"" msgstr """" #: dashboards/admin/projects/tables.py:47#: dashboards/admin/projects/tables.py:54 #: dashboards/admin/projects/workflows.py:306 #: dashboards/admin/projects/workflows.py:307#: dashboards/admin/projects/tables.py:64 #: dashboards/admin/projects/workflows.py:445#: dashboards/admin/projects/tables.py:114#: dashboards/admin/projects/views.py:58#: dashboards/admin/projects/views.py:116 msgid ""Unable to retrieve default quota values.""#: dashboards/admin/projects/views.py:145#: dashboards/admin/projects/workflows.py:46 msgid ""Injected File Content Bytes""#: dashboards/admin/projects/workflows.py:48 msgid ""Metadata Items"" msgstr """" #: dashboards/admin/projects/workflows.py:52 msgid ""Injected Files"" msgstr """" #: dashboards/admin/projects/workflows.py:55 #: dashboards/admin/volumes/panel.py:9 dashboards/admin/volumes/tables.py:42 #: dashboards/admin/volumes/templates/volumes/index.html:3 #: dashboards/admin/volumes/templates/volumes/index.html:6 #: dashboards/project/volumes/panel.py:25 #: dashboards/project/volumes/tables.py:43 #: dashboards/project/volumes/tables.py:209 #: dashboards/project/volumes/tables.py:221 #: dashboards/project/volumes/templates/volumes/index.html:3 #: dashboards/project/volumes/templates/volumes/index.html:6 msgid ""Volumes"" msgstr """" #: dashboards/admin/projects/workflows.py:56 msgid ""Snapshots"" msgstr """" #: dashboards/admin/projects/workflows.py:57 msgid ""Gigabytes"" msgstr """" #: dashboards/admin/projects/workflows.py:58 msgid ""RAM (MB)"" msgstr """" #: dashboards/admin/projects/workflows.py:62 #: dashboards/project/access_and_security/tabs.py:44 #: dashboards/project/access_and_security/security_groups/tables.py:34 #: dashboards/project/access_and_security/security_groups/tables.py:68 #: dashboards/project/instances/templates/instances/_detail_overview.html:58 #: dashboards/project/instances/workflows/create_instance.py:377 #: dashboards/project/instances/workflows/update_instance.py:82 msgid ""Security Groups"" msgstr """" #: dashboards/admin/projects/workflows.py:64 #: dashboards/project/access_and_security/security_groups/tables.py:166 msgid ""Security Group Rules"" msgstr """" #: dashboards/admin/projects/workflows.py:77#: dashboards/admin/projects/workflows.py:79#: dashboards/admin/projects/workflows.py:99 #: dashboards/admin/projects/workflows.py:430#: dashboards/admin/projects/workflows.py:100#: dashboards/admin/projects/workflows.py:117#: dashboards/admin/projects/workflows.py:129 #: dashboards/admin/projects/workflows.py:225 #, python-format msgid ""Could not find default role \""%s\"" in Keystone"" msgstr """" #: dashboards/admin/projects/workflows.py:182 #: dashboards/admin/projects/workflows.py:189#: dashboards/admin/projects/workflows.py:188#: dashboards/admin/projects/workflows.py:190#: dashboards/admin/projects/workflows.py:191#: dashboards/admin/projects/workflows.py:199#: dashboards/admin/projects/workflows.py:213 msgid ""Unable to retrieve group list. Please try again later."" msgstr """" #: dashboards/admin/projects/workflows.py:278 #: dashboards/admin/projects/workflows.py:285#: dashboards/admin/projects/workflows.py:284 msgid ""All Groups"" msgstr """" #: dashboards/admin/projects/workflows.py:286 msgid ""No groups found."" msgstr """" #: dashboards/admin/projects/workflows.py:287 msgid ""No groups."" msgstr """" #: dashboards/admin/projects/workflows.py:295 msgid ""Unable to retrieve role list."" msgstr """" #: dashboards/admin/projects/workflows.py:308#: dashboards/admin/projects/workflows.py:309#: dashboards/admin/projects/workflows.py:371#: dashboards/admin/projects/workflows.py:374#: dashboards/admin/projects/workflows.py:405#: dashboards/admin/projects/workflows.py:422#: dashboards/admin/projects/workflows.py:432#: dashboards/admin/projects/workflows.py:447#: dashboards/admin/projects/workflows.py:448#: dashboards/admin/projects/workflows.py:540#: dashboards/admin/projects/workflows.py:575#: dashboards/admin/projects/workflows.py:578#: dashboards/admin/projects/workflows.py:650#: dashboards/admin/projects/workflows.py:672#: dashboards/admin/roles/tables.py:69#: dashboards/admin/roles/panel.py:26 dashboards/admin/roles/tables.py:51 #: dashboards/admin/roles/tables.py:74#: dashboards/admin/roles/tables.py:50 dashboards/admin/users/forms.py:87#: dashboards/admin/roles/tables.py:70#: dashboards/admin/routers/panel.py:25 dashboards/admin/routers/tables.py:71 #: dashboards/admin/routers/templates/routers/index.html:3 #: dashboards/admin/routers/templates/routers/index.html:6 #: dashboards/project/routers/panel.py:25 #: dashboards/project/routers/tables.py:34 #: dashboards/project/routers/tables.py:138 #: dashboards/project/routers/templates/routers/index.html:3 #: dashboards/project/routers/templates/routers/index.html:6 msgid ""Routers"" msgstr """" #: dashboards/admin/users/forms.py:64 dashboards/project/instances/forms.py:73 #: dashboards/project/instances/workflows/create_instance.py:421 #: dashboards/settings/password/forms.py:45#: dashboards/admin/users/forms.py:77 dashboards/admin/users/forms.py:134#: dashboards/admin/users/forms.py:82 dashboards/admin/users/forms.py:140#: dashboards/admin/users/forms.py:85 dashboards/admin/users/forms.py:143#: dashboards/admin/users/forms.py:110#: dashboards/admin/users/forms.py:120#: dashboards/admin/users/forms.py:124#: dashboards/admin/users/forms.py:164#: dashboards/admin/users/forms.py:167#: dashboards/admin/users/tables.py:20#: dashboards/admin/users/tables.py:40#: dashboards/admin/users/tables.py:40#: dashboards/admin/users/tables.py:41 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:64 msgid ""Disabled"" msgstr """" #: dashboards/admin/users/tables.py:67#: dashboards/admin/users/views.py:110#: dashboards/project/instances/workflows/create_instance.py:385#: dashboards/project/access_and_security/security_groups/views.py:96#: dashboards/project/volumes/forms.py:286#: dashboards/project/volumes/forms.py:288#: dashboards/project/instances/workflows/create_instance.py:362#: dashboards/project/access_and_security/security_groups/forms.py:71 #: dashboards/project/access_and_security/security_groups/tables.py:84#: dashboards/project/access_and_security/security_groups/forms.py:80 #: dashboards/project/access_and_security/security_groups/forms.py:85 #: dashboards/project/access_and_security/security_groups/forms.py:86 #: dashboards/project/access_and_security/security_groups/forms.py:87 #: dashboards/project/access_and_security/security_groups/forms.py:88 #: dashboards/project/access_and_security/security_groups/forms.py:89 #: dashboards/project/access_and_security/security_groups/forms.py:90 #: dashboards/project/access_and_security/security_groups/forms.py:91 #: dashboards/project/access_and_security/security_groups/tables.py:147#: dashboards/project/access_and_security/security_groups/forms.py:95 #: dashboards/project/access_and_security/security_groups/forms.py:102 #: dashboards/project/access_and_security/security_groups/tables.py:152#: dashboards/project/access_and_security/security_groups/forms.py:96#: dashboards/project/access_and_security/security_groups/forms.py:105 #: dashboards/project/access_and_security/security_groups/forms.py:112 #: dashboards/project/access_and_security/security_groups/forms.py:113#: dashboards/project/access_and_security/security_groups/forms.py:107 #: dashboards/project/access_and_security/security_groups/tables.py:155#: dashboards/project/access_and_security/security_groups/forms.py:117 #: dashboards/project/access_and_security/security_groups/forms.py:128 #: dashboards/project/access_and_security/security_groups/forms.py:139#: dashboards/project/access_and_security/security_groups/forms.py:126 #: dashboards/project/access_and_security/security_groups/forms.py:133#: dashboards/project/access_and_security/security_groups/forms.py:137 #: dashboards/project/access_and_security/security_groups/forms.py:144#: dashboards/project/access_and_security/security_groups/forms.py:150#: dashboards/project/access_and_security/security_groups/forms.py:159 #: dashboards/project/access_and_security/security_groups/forms.py:166#: dashboards/project/access_and_security/security_groups/forms.py:161#: dashboards/project/access_and_security/security_groups/forms.py:170 #: dashboards/project/access_and_security/security_groups/tables.py:156#: dashboards/project/access_and_security/security_groups/forms.py:172 #: dashboards/project/access_and_security/security_groups/forms.py:195 #: dashboards/project/access_and_security/security_groups/forms.py:200#: dashboards/project/access_and_security/security_groups/forms.py:173#: dashboards/project/access_and_security/security_groups/forms.py:186#: dashboards/project/access_and_security/security_groups/forms.py:204 #: dashboards/project/access_and_security/security_groups/forms.py:212 #: dashboards/project/access_and_security/security_groups/tables.py:150#: dashboards/project/access_and_security/security_groups/forms.py:206#: dashboards/project/access_and_security/security_groups/forms.py:207#: dashboards/project/access_and_security/security_groups/forms.py:222#: dashboards/project/access_and_security/security_groups/forms.py:232#: dashboards/project/access_and_security/security_groups/forms.py:233#: dashboards/project/access_and_security/security_groups/forms.py:234#: dashboards/project/access_and_security/security_groups/forms.py:236#: dashboards/project/access_and_security/security_groups/forms.py:241 #: dashboards/project/access_and_security/security_groups/tables.py:121#: dashboards/project/access_and_security/security_groups/forms.py:242 #: dashboards/project/access_and_security/security_groups/tables.py:123#: dashboards/project/access_and_security/security_groups/forms.py:268#: dashboards/project/access_and_security/security_groups/forms.py:271#: dashboards/project/access_and_security/security_groups/forms.py:274#: dashboards/project/access_and_security/security_groups/forms.py:277#: dashboards/project/access_and_security/security_groups/forms.py:287#: dashboards/project/access_and_security/security_groups/forms.py:291#: dashboards/project/access_and_security/security_groups/forms.py:294#: dashboards/project/access_and_security/security_groups/forms.py:297#: dashboards/project/access_and_security/security_groups/forms.py:328#: dashboards/project/access_and_security/security_groups/forms.py:351#: dashboards/project/access_and_security/security_groups/forms.py:357#: dashboards/project/access_and_security/security_groups/tables.py:75#: dashboards/project/access_and_security/security_groups/tables.py:85#: dashboards/project/access_and_security/security_groups/tables.py:128#: dashboards/project/access_and_security/security_groups/views.py:103#: dashboards/project/stacks/forms.py:60#: dashboards/project/volumes/forms.py:137#: dashboards/project/images_and_snapshots/images/forms.py:49#: dashboards/project/images_and_snapshots/images/forms.py:50 #: dashboards/project/images_and_snapshots/images/forms.py:57 #: dashboards/project/images_and_snapshots/images/forms.py:63#: dashboards/project/images_and_snapshots/images/forms.py:51 #: dashboards/project/images_and_snapshots/images/forms.py:65 #: dashboards/project/images_and_snapshots/images/forms.py:70#: dashboards/project/images_and_snapshots/images/forms.py:58#: dashboards/project/images_and_snapshots/images/forms.py:66#: dashboards/project/images_and_snapshots/images/forms.py:72 #: dashboards/project/images_and_snapshots/images/forms.py:184#: dashboards/project/images_and_snapshots/images/forms.py:76 msgid ""AKI - Amazon Kernel Image"" msgstr """" #: dashboards/project/images_and_snapshots/images/forms.py:79 msgid ""AMI - Amazon Machine Image"" msgstr """" #: dashboards/project/images_and_snapshots/images/forms.py:82 msgid ""ARI - Amazon Ramdisk Image"" msgstr """" #: dashboards/project/images_and_snapshots/images/forms.py:85 msgid ""ISO - Optical Disk Image"" msgstr """" #: dashboards/project/images_and_snapshots/images/forms.py:87 msgid ""QCOW2 - QEMU Emulator"" msgstr """" #: dashboards/project/images_and_snapshots/images/forms.py:94#: dashboards/project/images_and_snapshots/images/forms.py:95 #: dashboards/project/images_and_snapshots/images/forms.py:102#: dashboards/project/images_and_snapshots/images/forms.py:101#: dashboards/project/images_and_snapshots/images/forms.py:108 #: dashboards/project/images_and_snapshots/images/forms.py:188 #: dashboards/project/images_and_snapshots/images/tables.py:135 #: dashboards/project/images_and_snapshots/images/tables.py:212 #: dashboards/project/images_and_snapshots/templates/images_and_snapshots/images/_detail_overview.html:19 msgid ""Public"" msgstr """" #: dashboards/project/images_and_snapshots/images/forms.py:109 #: dashboards/project/images_and_snapshots/images/forms.py:189#: dashboards/project/images_and_snapshots/images/forms.py:120#: dashboards/project/images_and_snapshots/images/forms.py:123#: dashboards/project/images_and_snapshots/images/forms.py:157#: dashboards/project/images_and_snapshots/images/forms.py:161#: dashboards/project/images_and_snapshots/images/forms.py:170#: dashboards/project/images_and_snapshots/images/forms.py:175#: dashboards/project/images_and_snapshots/images/forms.py:180#: dashboards/project/images_and_snapshots/images/forms.py:193#: dashboards/project/images_and_snapshots/images/forms.py:220#: dashboards/project/images_and_snapshots/images/tables.py:37 #: dashboards/project/instances/workflows/create_instance.py:511 #: dashboards/project/stacks/templates/stacks/_create.html:24 msgid ""Launch"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:178 #: dashboards/project/instances/workflows/create_instance.py:183 #: dashboards/project/volumes/forms.py:143#: dashboards/project/volumes/forms.py:322#: dashboards/project/images_and_snapshots/templates/images_and_snapshots/images/_detail_overview.html:6 #: dashboards/project/images_and_snapshots/templates/images_and_snapshots/snapshots/_detail_overview.html:7 #: dashboards/project/instances/templates/instances/_detail_overview.html:7 #: dashboards/project/instances/workflows/update_instance.py:120 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:6 #: dashboards/project/stacks/templates/stacks/_resource_overview.html:6 #: dashboards/project/volumes/templates/volumes/_detail_overview.html:7 msgid ""Info"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:106 #: dashboards/project/instances/workflows/create_instance.py:84 #: dashboards/project/instances/workflows/create_instance.py:119#: dashboards/project/images_and_snapshots/templates/images_and_snapshots/snapshots/_detail_overview.html:38 #: dashboards/project/instances/templates/instances/_detail_overview.html:34 #: dashboards/project/instances/templates/instances/_detail_overview.html:37 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:11 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:12 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:13 #: dashboards/project/volumes/templates/volumes/_detail_overview.html:28 #: dashboards/project/volumes/templates/volumes/_limits.html:10 #: dashboards/project/volumes/templates/volumes/_limits.html:11 msgid ""GB"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:85#: dashboards/project/images_and_snapshots/volume_snapshots/tables.py:39 #: dashboards/project/loadbalancers/tables.py:73 #: dashboards/project/loadbalancers/tables.py:86 #: dashboards/project/loadbalancers/tables.py:94 #: dashboards/project/loadbalancers/tables.py:102 #: dashboards/project/stacks/tables.py:44 #: dashboards/project/volumes/tables.py:44 msgid ""Scheduled deletion of"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:266#: dashboards/project/instances/workflows/create_instance.py:268#: dashboards/project/instances/tables.py:75 msgid ""Terminate"" msgstr """" #: dashboards/project/instances/tables.py:76 msgid ""Scheduled termination of"" msgstr """" #: dashboards/project/instances/tables.py:183 #: dashboards/project/instances/tables.py:204 #: dashboards/project/instances/workflows/create_instance.py:510 #: dashboards/project/network_topology/templates/network_topology/index.html:27 msgid ""Launch Instance"" msgstr """" #: dashboards/project/instances/tables.py:217 #: dashboards/project/instances/workflows/update_instance.py:133 msgid ""Edit Instance"" msgstr """" #: dashboards/project/instances/tables.py:492 #: dashboards/project/instances/tables.py:499 msgid ""Not available"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:188#: dashboards/project/instances/templates/instances/_detail_overview.html:4 #: dashboards/project/overview/templates/overview/usage.html:3 msgid ""Instance Overview"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:103#: dashboards/project/instances/templates/instances/_detail_overview.html:107#: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:6 msgid ""Flavor Details"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:13 msgid ""Total Disk"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:14 msgid ""MB"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:21 msgid ""Number of Instances"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:28 msgid ""Number of VCPUs"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:35 msgid ""Total RAM"" msgstr """" #: dashboards/project/instances/templates/instances/_launch_details_help.html:5 msgid ""Specify the details for launching an instance."" msgstr """" #: dashboards/project/instances/templates/instances/_launch_details_help.html:6 msgid """" ""The chart below shows the resources used by this project in relation to the "" ""project's quotas."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:62#: dashboards/project/instances/workflows/create_instance.py:75 msgid ""Don't boot from a volume.""#: dashboards/project/instances/workflows/create_instance.py:76#: dashboards/project/instances/workflows/create_instance.py:77#: dashboards/project/instances/workflows/create_instance.py:81 #: dashboards/project/instances/workflows/create_instance.py:99 msgid ""Volume Options"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:87 #: dashboards/project/volumes/forms.py:252 msgid ""Device Name"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:90 msgid ""Volume mount point (e.g. 'vda' mounts at '/dev/vda')."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:92 msgid ""Delete on Terminate"" msgstr """" msgid ""Delete volume on instance terminate"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:109 #, python-format msgid ""Please choose a volume, or select %s."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:116 #: dashboards/project/instances/workflows/create_instance.py:179 #: dashboards/project/volumes/forms.py:130 msgid ""Snapshot"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:121 #, python-format msgid ""%(name)s - %(size)s GB (%(label)s)"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:127 msgid ""Select Volume"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:135 msgid ""Unable to retrieve list of volumes."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:139 msgid ""Select Volume Snapshot"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:148 msgid ""Unable to retrieve list of volume snapshots."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:181 msgid ""Instance Source"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:184 msgid ""Instance Snapshot"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:190 msgid ""Size of image to launch."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:191#: dashboards/project/instances/workflows/create_instance.py:194#: dashboards/project/instances/workflows/create_instance.py:197 msgid ""Details""#: dashboards/project/instances/workflows/create_instance.py:211 msgid """" ""You can't select an instance source when booting from a Volume. The Volume "" ""is your source and should contain the operating system.""#: dashboards/project/instances/workflows/create_instance.py:219 msgid """" ""There are no image sources available; you must first create an image before "" ""attemtping to launch an instance.""#: dashboards/project/instances/workflows/create_instance.py:225 msgid ""Please select an option for the instance source.""#: dashboards/project/instances/workflows/create_instance.py:233 msgid """" ""Launching multiple instances is only supported for images and instance "" ""snapshots.""#: dashboards/project/instances/workflows/create_instance.py:241""quota available.""#: dashboards/project/instances/workflows/create_instance.py:279 msgid ""Select Instance Snapshot""#: dashboards/project/instances/workflows/create_instance.py:281 msgid ""No snapshots available.""#: dashboards/project/instances/workflows/create_instance.py:300#: dashboards/project/instances/workflows/create_instance.py:309#: dashboards/project/instances/workflows/create_instance.py:315#: dashboards/project/instances/workflows/create_instance.py:317#: dashboards/project/instances/workflows/create_instance.py:330 #: dashboards/project/instances/workflows/resize_instance.py:80 #: usage/base.py:186 msgid ""Unable to retrieve quota information.""#: dashboards/project/instances/workflows/create_instance.py:364 msgid ""Which keypair to use for authentication.""#: dashboards/project/instances/workflows/create_instance.py:368 msgid ""Admin Pass""#: dashboards/project/instances/workflows/create_instance.py:374 msgid ""Confirm Admin Pass""#: dashboards/project/instances/workflows/create_instance.py:386#: dashboards/project/instances/workflows/create_instance.py:396#: dashboards/project/instances/workflows/create_instance.py:400#: dashboards/project/instances/workflows/create_instance.py:402#: dashboards/project/instances/workflows/create_instance.py:411#: dashboards/project/instances/workflows/create_instance.py:443#: dashboards/project/instances/workflows/create_instance.py:445#: dashboards/project/instances/workflows/create_instance.py:452#: dashboards/project/instances/workflows/create_instance.py:468#: dashboards/project/instances/workflows/create_instance.py:470#: dashboards/project/instances/workflows/create_instance.py:474#: dashboards/project/instances/workflows/create_instance.py:476#: dashboards/project/instances/workflows/create_instance.py:488#: dashboards/project/instances/workflows/create_instance.py:512 #, python-format msgid ""Launched %(count)s named \""%(name)s\"".""#: dashboards/project/instances/workflows/create_instance.py:513 #, python-format msgid ""Unable to launch %(count)s named \""%(name)s\""."" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:526#: dashboards/project/instances/workflows/create_instance.py:529 msgid ""instance""#: dashboards/project/loadbalancers/tables.py:72 #: dashboards/project/loadbalancers/tables.py:85 #: dashboards/project/loadbalancers/tables.py:93 #: dashboards/project/loadbalancers/tables.py:101 #: dashboards/project/loadbalancers/workflows.py:596 #: dashboards/project/stacks/tables.py:43 msgid ""Delete"" msgstr """" #: dashboards/project/stacks/forms.py:59msgid ""ID: ""msgid ""Tenant ID: ""msgid ""Pool ID: ""msgid ""Address: ""msgid ""Protocol Port: ""msgid ""Weight: ""msgid ""Admin State Up: ""msgid ""Status: ""msgid ""Type: ""msgid ""Delay: ""msgid ""Timeout: ""msgid ""Max Retries: ""msgid ""HTTP Method: ""msgid ""URL Path: ""msgid ""Expected Codes: ""msgid ""VIP ID: ""msgid ""Name: "" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:18 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:15 msgid ""Description: ""msgid ""Subnet ID: ""msgid ""Protocol: ""msgid ""Load Balancing Method: ""msgid ""Members: ""msgid ""Health Monitors: ""msgid ""Session Persistence: ""msgid ""Cookie Name: ""msgid ""Connection Limit: "" msgstr """"#: dashboards/project/network_topology/templates/network_topology/index.html:24 msgid ""This pane needs javascript support.""msgid ""There are no networks, routers, or connected instances to display. ""#: dashboards/project/networks/workflows.py:39 msgid ""Network Name. This field is optional."" msgstr """" #: dashboards/project/networks/workflows.py:47#: dashboards/project/networks/workflows.py:61#: dashboards/project/networks/workflows.py:62 msgid ""Subnet Name. This field is optional."" msgstr """" #: dashboards/project/networks/workflows.py:65#: dashboards/project/networks/workflows.py:68#: dashboards/project/networks/workflows.py:75 #: dashboards/project/networks/subnets/workflows.py:107 msgid ""Gateway IP (optional)"" msgstr """" #: dashboards/project/networks/workflows.py:78#: dashboards/project/networks/workflows.py:87#: dashboards/project/networks/workflows.py:92#: dashboards/project/networks/workflows.py:103#: dashboards/project/networks/workflows.py:109#: dashboards/project/networks/workflows.py:113#: dashboards/project/networks/workflows.py:118#: dashboards/project/networks/workflows.py:121#: dashboards/project/networks/workflows.py:141#: dashboards/project/networks/workflows.py:145#: dashboards/project/networks/workflows.py:146#: dashboards/project/networks/workflows.py:153#: dashboards/project/networks/workflows.py:154#: dashboards/project/networks/workflows.py:159#: dashboards/project/networks/workflows.py:160""destination_cidr&gt;,&lt;nexthop&gt; (e.g., 192.168.200.0/24,10.56.1.254)and "" ""one entry per line.""#: dashboards/project/networks/workflows.py:167#: dashboards/project/networks/workflows.py:168#: dashboards/project/networks/workflows.py:174#: dashboards/project/networks/workflows.py:183#: dashboards/project/networks/workflows.py:195#: dashboards/project/networks/workflows.py:201#: dashboards/project/networks/workflows.py:219#: dashboards/project/networks/workflows.py:244#: dashboards/project/networks/workflows.py:245#: dashboards/project/networks/workflows.py:267#: dashboards/project/networks/workflows.py:271#: dashboards/project/networks/workflows.py:327#: dashboards/project/networks/workflows.py:331#: dashboards/project/networks/workflows.py:347#: dashboards/project/networks/workflows.py:355#: dashboards/project/routers/tables.py:33#: dashboards/project/routers/templates/routers/_create.html:9 #: dashboards/project/routers/templates/routers/_create.html:20 msgid ""Create router"" msgstr """" #: dashboards/project/stacks/forms.py:54#: dashboards/project/stacks/forms.py:55#: dashboards/project/stacks/forms.py:58#: dashboards/project/stacks/forms.py:61#: dashboards/project/stacks/forms.py:66 dashboards/project/stacks/forms.py:70#: dashboards/project/stacks/forms.py:67#: dashboards/project/stacks/forms.py:73 dashboards/project/stacks/forms.py:77#: dashboards/project/stacks/forms.py:74#: dashboards/project/stacks/forms.py:80 dashboards/project/stacks/forms.py:85#: dashboards/project/stacks/forms.py:81#: dashboards/project/stacks/forms.py:109#: dashboards/project/stacks/forms.py:115#: dashboards/project/stacks/forms.py:120#: dashboards/project/stacks/forms.py:137#: dashboards/project/stacks/forms.py:159#: dashboards/project/stacks/forms.py:172#: dashboards/project/stacks/forms.py:173#: dashboards/project/stacks/forms.py:177#: dashboards/project/stacks/forms.py:178#: dashboards/project/stacks/forms.py:181#: dashboards/project/stacks/forms.py:182#: dashboards/project/stacks/forms.py:193#: dashboards/project/stacks/forms.py:194#: dashboards/project/stacks/forms.py:256#: dashboards/project/stacks/forms.py:260#: dashboards/project/stacks/tables.py:107 #: dashboards/project/stacks/tables.py:151 msgid ""Resource"" msgstr """" msgid ""Encryption"" msgstr """" #: dashboards/project/volumes/forms.py:38#: dashboards/project/volumes/forms.py:48#: dashboards/project/volumes/forms.py:98#: dashboards/project/volumes/forms.py:105#: dashboards/project/volumes/forms.py:115#: dashboards/project/volumes/forms.py:121#: dashboards/project/volumes/forms.py:131#: dashboards/project/volumes/forms.py:144#: dashboards/project/volumes/forms.py:155#: dashboards/project/volumes/forms.py:183#: dashboards/project/volumes/forms.py:195#: dashboards/project/volumes/forms.py:204#: dashboards/project/volumes/forms.py:211#: dashboards/project/volumes/forms.py:228#: dashboards/project/volumes/forms.py:236#: dashboards/project/volumes/forms.py:249#: dashboards/project/volumes/forms.py:250#: dashboards/project/volumes/forms.py:294#: dashboards/project/volumes/forms.py:308#: dashboards/project/volumes/forms.py:317#: dashboards/project/volumes/forms.py:341#: dashboards/project/volumes/forms.py:347#: dashboards/settings/password/forms.py:30#: dashboards/settings/password/forms.py:32#: dashboards/settings/password/forms.py:37#: dashboards/settings/password/forms.py:59 msgid ""Password changed.""#: dashboards/settings/password/forms.py:62#: dashboards/settings/password/forms.py:65#: test/settings.py:51#: usage/base.py:138#: usage/base.py:148#: usage/base.py:165#: usage/base.py:168#: usage/base.py:172",2383,1030
openstack%2Fopenstack-planet~master~I662d3f3671dec72b817db99c733e3532975f12c1,openstack/openstack-planet,master,I662d3f3671dec72b817db99c733e3532975f12c1,OSReactions: Use a category for OS planet,MERGED,2013-09-06 09:25:00.000000000,2013-09-06 09:30:55.000000000,2013-09-06 09:30:55.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 866}, {'_account_id': 3153}]","[{'number': 1, 'created': '2013-09-06 09:25:00.000000000', 'files': ['planet.ini'], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/db251f9bc838179de49dbc94330c7222f28640a3', 'message': ""OSReactions: Use a category for OS planet\n\nIn order to manage posts publication frequency, we created a new\ncategory under the which we'll publicizing posts meant to be read by\nopenstack's planet.\n\nThis category doesn't have any post yet, which makes this patch safe\nsince old posts won't be read again by the planet.\n\nChange-Id: I662d3f3671dec72b817db99c733e3532975f12c1\n""}]",0,45407,db251f9bc838179de49dbc94330c7222f28640a3,6,4,1,6159,,,0,"OSReactions: Use a category for OS planet

In order to manage posts publication frequency, we created a new
category under the which we'll publicizing posts meant to be read by
openstack's planet.

This category doesn't have any post yet, which makes this patch safe
since old posts won't be read again by the planet.

Change-Id: I662d3f3671dec72b817db99c733e3532975f12c1
",git fetch https://review.opendev.org/openstack/openstack-planet refs/changes/07/45407/1 && git format-patch -1 --stdout FETCH_HEAD,['planet.ini'],1,db251f9bc838179de49dbc94330c7222f28640a3,,[http://openstackreactions.enovance.com/category/planet/feed/],[http://openstackreactions.enovance.com/feed],1,1
openstack%2Fpython-novaclient~master~I423d95390f6a1ef4f33b8669909199bf3fb5fa70,openstack/python-novaclient,master,I423d95390f6a1ef4f33b8669909199bf3fb5fa70,Added some unit tests for nova client v1_1 and v3,ABANDONED,2013-09-06 08:11:08.000000000,2013-09-06 08:35:52.000000000,,[],"[{'number': 1, 'created': '2013-09-06 08:11:08.000000000', 'files': ['novaclient/tests/fakes.py', 'novaclient/tests/test_client.py', 'novaclient/v3/client.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/a17d37a71fdb798395b27dfe09ecb30ef9612675', 'message': 'Added some unit tests for nova client v1_1 and v3\n\nChange-Id: I423d95390f6a1ef4f33b8669909199bf3fb5fa70\n'}]",0,45392,a17d37a71fdb798395b27dfe09ecb30ef9612675,3,0,1,8689,,,0,"Added some unit tests for nova client v1_1 and v3

Change-Id: I423d95390f6a1ef4f33b8669909199bf3fb5fa70
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/92/45392/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/fakes.py', 'novaclient/tests/test_client.py', 'novaclient/v3/client.py']",3,a17d37a71fdb798395b27dfe09ecb30ef9612675,master," os_cache=os_cache,"," os_cache=self.os_cache,",69,1
openstack%2Fceilometer~milestone-proposed~Id4d349bbc49cdc957076b3e211f70db9838cd4cb,openstack/ceilometer,milestone-proposed,Id4d349bbc49cdc957076b3e211f70db9838cd4cb,Fix wrong migrations and fix tests in nova_notifier,MERGED,2013-09-06 07:21:42.000000000,2013-09-06 08:24:50.000000000,2013-09-06 08:24:49.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2013-09-06 07:21:42.000000000', 'files': ['ceilometer/storage/sqlalchemy/alembic/versions/b6ae66d05e3_remove_extra_indexes.py', 'nova_tests/test_notifier.py', 'ceilometer/storage/sqlalchemy/alembic/versions/2c3ccda5a3ad_fix_uniq_name.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/774513b52e16abdf16f61032ae462d52488e92ff', 'message': 'Fix wrong migrations and fix tests in nova_notifier\n\nThis is a joint commit of 2 other commits from master:\n\nFor Postgres migrations are failed.\nMore then we can get for mysql an error\n""Specified key was too long; max key length is 1000 bytes"" in b6ae66d05e3\nmigration in some versions of dialect.\nFixes-Bug: #1219776\n(cherry-picked from aae3f55304ff161b401b803769350e9cb66b0e8c)\n\nThe prototype for instance_update_and_get_original changed, so let\'s\nignore it completely for the future.\nFixes-Bug: #1221173\n(cherry-picked from d2a87a9dfd3cd9ef034eed3d693683972c842576)\n\nChange-Id: Id4d349bbc49cdc957076b3e211f70db9838cd4cb\n'}]",0,45384,774513b52e16abdf16f61032ae462d52488e92ff,5,2,1,1669,,,0,"Fix wrong migrations and fix tests in nova_notifier

This is a joint commit of 2 other commits from master:

For Postgres migrations are failed.
More then we can get for mysql an error
""Specified key was too long; max key length is 1000 bytes"" in b6ae66d05e3
migration in some versions of dialect.
Fixes-Bug: #1219776
(cherry-picked from aae3f55304ff161b401b803769350e9cb66b0e8c)

The prototype for instance_update_and_get_original changed, so let's
ignore it completely for the future.
Fixes-Bug: #1221173
(cherry-picked from d2a87a9dfd3cd9ef034eed3d693683972c842576)

Change-Id: Id4d349bbc49cdc957076b3e211f70db9838cd4cb
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/84/45384/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/sqlalchemy/alembic/versions/b6ae66d05e3_remove_extra_indexes.py', 'nova_tests/test_notifier.py', 'ceilometer/storage/sqlalchemy/alembic/versions/2c3ccda5a3ad_fix_uniq_name.py']",3,774513b52e16abdf16f61032ae462d52488e92ff,,"UNIQ_NAME = 'uniq_sourceassoc0meter_id0user_id'def change_uniq(table_name, uniq_name, columns, downgrade=False): bind = op.get_bind() engine = bind.engine if downgrade: op.drop_constraint(uniq_name, table_name=table_name, type_='unique') else: op.create_unique_constraint(uniq_name, table_name, columns) change_uniq(TABLE_NAME, UNIQ_NAME, COLUMNS) change_uniq(TABLE_NAME, UNIQ_NAME, COLUMNS, downgrade=True)","OLD_NAME = 'uniq_sourceassoc0meter_id' NEW_NAME = 'uniq_sourceassoc0meter_id0user_id'def change_uniq(table_name, old_name, new_name, columns): engine = op.get_bind().engine try: # For some versions of dialects constraint can be skipped. op.drop_constraint(old_name, table_name=table_name, type_='unique') except Exception: pass op.create_unique_constraint(new_name, table_name, columns) change_uniq(TABLE_NAME, OLD_NAME, NEW_NAME, COLUMNS) change_uniq(TABLE_NAME, NEW_NAME, OLD_NAME, COLUMNS)",42,32
openstack%2Fceilometer~milestone-proposed~Id9b0e1eb0e685053291367f7eb62fef68b6b2f84,openstack/ceilometer,milestone-proposed,Id9b0e1eb0e685053291367f7eb62fef68b6b2f84,Fix wrong migrations,ABANDONED,2013-09-05 21:30:39.000000000,2013-09-06 07:27:30.000000000,,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1669}, {'_account_id': 6507}]","[{'number': 1, 'created': '2013-09-05 21:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ae2a21fac5d8c79e9dcc7eabd52186ebe187c5d4', 'message': 'Fix wrong migrations\n\nFor Postgres migrations are failed.\nMore then we can get for mysql an error\n""Specified key was too long; max key length is 1000 bytes"" in b6ae66d05e3\nmigration in some versions of dialect.\n\nFixes-Bug: #1219776\n\nChange-Id: Id9b0e1eb0e685053291367f7eb62fef68b6b2f84\n'}, {'number': 2, 'created': '2013-09-05 21:32:23.000000000', 'files': ['ceilometer/storage/sqlalchemy/alembic/versions/b6ae66d05e3_remove_extra_indexes.py', 'ceilometer/storage/sqlalchemy/alembic/versions/2c3ccda5a3ad_fix_uniq_name.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b97e4b2e1199c0fba496efb3acd1a56920df10b9', 'message': 'Fix wrong migrations\n\nFor Postgres migrations are failed.\nMore then we can get for mysql an error\n""Specified key was too long; max key length is 1000 bytes"" in b6ae66d05e3\nmigration in some versions of dialect.\n\nFixes-Bug: #1219776\n(cherry-picked from aae3f55304ff161b401b803769350e9cb66b0e8c)\n\nChange-Id: Id9b0e1eb0e685053291367f7eb62fef68b6b2f84\n'}]",0,45330,b97e4b2e1199c0fba496efb3acd1a56920df10b9,7,4,2,1669,,,0,"Fix wrong migrations

For Postgres migrations are failed.
More then we can get for mysql an error
""Specified key was too long; max key length is 1000 bytes"" in b6ae66d05e3
migration in some versions of dialect.

Fixes-Bug: #1219776
(cherry-picked from aae3f55304ff161b401b803769350e9cb66b0e8c)

Change-Id: Id9b0e1eb0e685053291367f7eb62fef68b6b2f84
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/30/45330/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/sqlalchemy/alembic/versions/b6ae66d05e3_remove_extra_indexes.py', 'ceilometer/storage/sqlalchemy/alembic/versions/2c3ccda5a3ad_fix_uniq_name.py']",2,ae2a21fac5d8c79e9dcc7eabd52186ebe187c5d4,,"UNIQ_NAME = 'uniq_sourceassoc0meter_id0user_id'def change_uniq(table_name, uniq_name, columns, downgrade=False): bind = op.get_bind() engine = bind.engine if downgrade: op.drop_constraint(uniq_name, table_name=table_name, type_='unique') else: op.create_unique_constraint(uniq_name, table_name, columns) change_uniq(TABLE_NAME, UNIQ_NAME, COLUMNS) change_uniq(TABLE_NAME, UNIQ_NAME, COLUMNS, downgrade=True)","OLD_NAME = 'uniq_sourceassoc0meter_id' NEW_NAME = 'uniq_sourceassoc0meter_id0user_id'def change_uniq(table_name, old_name, new_name, columns): engine = op.get_bind().engine try: # For some versions of dialects constraint can be skipped. op.drop_constraint(old_name, table_name=table_name, type_='unique') except Exception: pass op.create_unique_constraint(new_name, table_name, columns) change_uniq(TABLE_NAME, OLD_NAME, NEW_NAME, COLUMNS) change_uniq(TABLE_NAME, NEW_NAME, OLD_NAME, COLUMNS)",41,30
openstack%2Fceilometer~milestone-proposed~Icfa161109e76e2717f64084ddce829f6c68aeb57,openstack/ceilometer,milestone-proposed,Icfa161109e76e2717f64084ddce829f6c68aeb57,nova_notifier: fix tests,ABANDONED,2013-09-05 21:30:39.000000000,2013-09-06 07:27:16.000000000,,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1669}]","[{'number': 1, 'created': '2013-09-05 21:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/047a9671b6467cc5213b33098170e011334594af', 'message': ""nova_notifier: fix tests\n\nThe prototype for instance_update_and_get_original changed, so let's\nignore it completely for the future.\n\nChange-Id: Icfa161109e76e2717f64084ddce829f6c68aeb57\nFixes-Bug: #1221173\n""}, {'number': 2, 'created': '2013-09-05 21:32:23.000000000', 'files': ['nova_tests/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bb615a412c75f0848b9ba5c056a2012dad78a644', 'message': ""nova_notifier: fix tests\n\nThe prototype for instance_update_and_get_original changed, so let's\nignore it completely for the future.\n\nFixes-Bug: #1221173\n(cherry-picked from d2a87a9dfd3cd9ef034eed3d693683972c842576)\n\nChange-Id: Icfa161109e76e2717f64084ddce829f6c68aeb57\n""}]",0,45331,bb615a412c75f0848b9ba5c056a2012dad78a644,6,3,2,1669,,,0,"nova_notifier: fix tests

The prototype for instance_update_and_get_original changed, so let's
ignore it completely for the future.

Fixes-Bug: #1221173
(cherry-picked from d2a87a9dfd3cd9ef034eed3d693683972c842576)

Change-Id: Icfa161109e76e2717f64084ddce829f6c68aeb57
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/31/45331/2 && git format-patch -1 --stdout FETCH_HEAD,['nova_tests/test_notifier.py'],1,047a9671b6467cc5213b33098170e011334594af,," lambda *args, **kwargs: (self.instance, self.instance))"," lambda context, uuid, kwargs, update_cells: (self.instance, self.instance))",1,2
openstack%2Fpython-glanceclient~master~I5b6b35aa30d067b4fdac4b1ee72f0b49fe7137e4,openstack/python-glanceclient,master,I5b6b35aa30d067b4fdac4b1ee72f0b49fe7137e4,Sync of new oslo-incubator libraries needed by image-tools.,ABANDONED,2013-06-25 07:15:06.000000000,2013-09-06 07:24:09.000000000,,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 1726}, {'_account_id': 2472}, {'_account_id': 4463}, {'_account_id': 6159}]","[{'number': 1, 'created': '2013-06-25 07:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/fdd2aace6e4bc27aab24dcdeb36d271a054d5780', 'message': 'Sync of new oslo-incubator libraries needed by image-tools.\n\nAdded to openstack-common.conf:\n - context\n - fixture\n - jsonutils\n\nAdded by dependencies:\n - timeutils\n - uuidutils\n\nImplements: blueprint image-tools\n\nChange-Id: I5b6b35aa30d067b4fdac4b1ee72f0b49fe7137e4\n'}, {'number': 2, 'created': '2013-07-01 16:20:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/27180a8626a1a23434f9b9127ecdaba335aa413e', 'message': 'Sync of new oslo-incubator libraries needed by image-tools.\n\nAdded to openstack-common.conf:\n - context\n - fixture\n - jsonutils\n - timeutils\n\nAdded by dependencies:\n - uuidutils (context)\n\nImplements: blueprint image-tools\n\nChange-Id: I5b6b35aa30d067b4fdac4b1ee72f0b49fe7137e4\n'}, {'number': 3, 'created': '2013-07-10 07:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/cc4c281605ec3cbdee2085d25d7c60c50988c9cc', 'message': 'Sync of new oslo-incubator libraries needed by image-tools.\n\nAdded to openstack-common.conf:\n - context\n - fixture\n - jsonutils\n - timeutils\n\nAdded by dependencies:\n - uuidutils (context)\n\nImplements: blueprint image-tools\n\nChange-Id: I5b6b35aa30d067b4fdac4b1ee72f0b49fe7137e4\n'}, {'number': 4, 'created': '2013-07-19 09:40:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/b72b2b40e6c2bc471d779bbac50a33952a86c401', 'message': 'Sync of new oslo-incubator libraries needed by image-tools.\n\nAdded to openstack-common.conf:\n - context\n - fixture\n - jsonutils\n - timeutils\n\nAdded by dependencies:\n - uuidutils (context)\n\nImplements: blueprint image-tools\n\nChange-Id: I5b6b35aa30d067b4fdac4b1ee72f0b49fe7137e4\n'}, {'number': 5, 'created': '2013-08-01 10:21:15.000000000', 'files': ['glanceclient/openstack/common/fixture/mockpatch.py', 'glanceclient/openstack/common/jsonutils.py', 'glanceclient/openstack/common/fixture/moxstubout.py', 'glanceclient/openstack/common/timeutils.py', 'openstack-common.conf', 'glanceclient/openstack/common/uuidutils.py', 'glanceclient/openstack/common/fixture/__init__.py', 'glanceclient/openstack/common/context.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/9dafa0a8287af5f0a61a4de09fa270d37967e3f9', 'message': 'Sync of new oslo-incubator libraries needed by image-tools.\n\nAdded to openstack-common.conf:\n - context\n - fixture\n - jsonutils\n - timeutils\n\nAdded by dependencies:\n - uuidutils (context)\n\nImplements: blueprint image-tools\n\nChange-Id: I5b6b35aa30d067b4fdac4b1ee72f0b49fe7137e4\n'}]",1,34320,9dafa0a8287af5f0a61a4de09fa270d37967e3f9,16,6,5,1726,,,0,"Sync of new oslo-incubator libraries needed by image-tools.

Added to openstack-common.conf:
 - context
 - fixture
 - jsonutils
 - timeutils

Added by dependencies:
 - uuidutils (context)

Implements: blueprint image-tools

Change-Id: I5b6b35aa30d067b4fdac4b1ee72f0b49fe7137e4
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/20/34320/3 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/openstack/common/fixture/mockpatch.py', 'glanceclient/openstack/common/jsonutils.py', 'glanceclient/openstack/common/fixture/moxstubout.py', 'glanceclient/openstack/common/timeutils.py', 'openstack-common.conf', 'glanceclient/openstack/common/uuidutils.py', 'glanceclient/openstack/common/fixture/__init__.py', 'glanceclient/openstack/common/context.py']",8,fdd2aace6e4bc27aab24dcdeb36d271a054d5780,bp/image-tools,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Simple class that stores security context information in the web request. Projects should subclass this class if they wish to enhance the request context or provide additional information in their specific WSGI pipeline. """""" import itertools from glanceclient.openstack.common import uuidutils def generate_request_id(): return 'req-%s' % uuidutils.generate_uuid() class RequestContext(object): """"""Helper class to represent useful information about a request context. Stores information about the security context under which the user accesses the system, as well as additional request information. """""" def __init__(self, auth_token=None, user=None, tenant=None, is_admin=False, read_only=False, show_deleted=False, request_id=None): self.auth_token = auth_token self.user = user self.tenant = tenant self.is_admin = is_admin self.read_only = read_only self.show_deleted = show_deleted if not request_id: request_id = generate_request_id() self.request_id = request_id def to_dict(self): return {'user': self.user, 'tenant': self.tenant, 'is_admin': self.is_admin, 'read_only': self.read_only, 'show_deleted': self.show_deleted, 'auth_token': self.auth_token, 'request_id': self.request_id} def get_admin_context(show_deleted=""no""): context = RequestContext(None, tenant=None, is_admin=True, show_deleted=show_deleted) return context def get_context_from_function_and_args(function, args, kwargs): """"""Find an arg of type RequestContext and return it. This is useful in a couple of decorators where we don't know much about the function we're wrapping. """""" for arg in itertools.chain(kwargs.values(), args): if isinstance(arg, RequestContext): return arg return None ",,569,0
openstack%2Fcinder~master~I37be5d97a890501fc1b31ddc0e2e6318c9d1eb7f,openstack/cinder,master,I37be5d97a890501fc1b31ddc0e2e6318c9d1eb7f,Alter column `deleted` type from bool to `id` type,ABANDONED,2013-08-07 15:58:31.000000000,2013-09-06 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2889}, {'_account_id': 6172}, {'_account_id': 6802}, {'_account_id': 7491}]","[{'number': 1, 'created': '2013-08-07 15:58:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e75b5eea3e13b87d95bd9a380d60a8f6c9389bd4', 'message': ""Change column type from boolean to `id` type.\n\nMain issue is that we can't create unique constraint for columns, because\nwe are using soft deletion of entries (set `deleted` column to True).\nThe main idea is to use `deleted` columns to create unique constraint for\ncolumns. For example (`col1`, `deleted`).\nTo make (`col1`, `deleted`) unique after entry deletion, we should assign the\nvalue of `id` to `deleted` column.\n\nUpdated `openstack.common.db.sqlalchemy.utils` file (from Oslo).\nChange type of `deleted` column from Boolean to table.id.type for all\ntables in migration 017. Models, api functions, and tests modified.\n\nPart of blueprint db-unique-keys\n\nChange-Id: I37be5d97a890501fc1b31ddc0e2e6318c9d1eb7f\n""}, {'number': 2, 'created': '2013-08-08 06:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/61327b403d5d7ec0baa9819da39accc6b8495446', 'message': ""Change column type from boolean to `id` type.\n\nWe can't create unique constraint for columns, because we are using\nsoft deletion of entries (set `deleted` column to True).\nThe main idea is to use `deleted` columns to create unique constraint\nfor columns. For example (`col1`, `deleted`).\nTo make (`col1`, `deleted`) unique after entry deletion, we should\nassign the value of `id` to `deleted` column.\n\nUpdated `openstack.common.db.sqlalchemy.utils` file (from Oslo). Added\nrequired exception module.\nChange type of `deleted` column from Boolean to table.id.type for all\ntables in migration 017. Models, api functions, and tests modified.\n\nPart of blueprint db-unique-keys\n\nChange-Id: I37be5d97a890501fc1b31ddc0e2e6318c9d1eb7f\n""}, {'number': 3, 'created': '2013-08-08 14:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b42df2c3508d2259eff50038cdec7f3a6d866d75', 'message': ""Change column type from boolean to `id` type.\n\nWe can't create unique constraint for columns, because we are using\nsoft deletion of entries (set `deleted` column to True).\nThe main idea is to use `deleted` columns to create unique constraint\nfor columns. For example (`col1`, `deleted`).\nTo make (`col1`, `deleted`) unique after entry deletion, we should\nassign the value of `id` to `deleted` column.\n\nUpdated `openstack.common.db.sqlalchemy.utils` file (from Oslo). Added\nrequired exception module.\nChange type of `deleted` column from Boolean to table.id.type for all\ntables in migration 017. Models, api functions, and tests modified.\n\nPart of blueprint db-unique-keys\n\nChange-Id: I37be5d97a890501fc1b31ddc0e2e6318c9d1eb7f\n""}, {'number': 4, 'created': '2013-08-08 15:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a46de3df18adddc31afd2e34876a8116433ec499', 'message': ""Change column type from boolean to `id` type.\n\nWe can't create unique constraint for columns, because we are using\nsoft deletion of entries (set `deleted` column to True).\nThe main idea is to use `deleted` columns to create unique constraint\nfor columns. For example (`col1`, `deleted`).\nTo make (`col1`, `deleted`) unique after entry deletion, we should\nassign the value of `id` to `deleted` column.\n\nUpdated `openstack.common.db.sqlalchemy.utils` file (from Oslo). Added\nrequired exception module.\nChange type of `deleted` column from Boolean to table.id.type for all\ntables in migration 017. Models, api functions, and tests modified.\n\nPart of blueprint db-unique-keys\n\nChange-Id: I37be5d97a890501fc1b31ddc0e2e6318c9d1eb7f\n""}, {'number': 5, 'created': '2013-08-09 08:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f85bb3d12b94b6374b7703a55724b290d3c061cb', 'message': ""Change column type from boolean to `id` type.\n\nWe can't create unique constraint for columns, because we are using\nsoft deletion of entries (set `deleted` column to True).\nThe main idea is to use `deleted` columns to create unique constraint\nfor columns. For example (`col1`, `deleted`).\nTo make (`col1`, `deleted`) unique after entry deletion, we should\nassign the value of `id` to `deleted` column.\n\nUpdated `openstack.common.db.sqlalchemy.utils` file (from Oslo). Added\nrequired exception module.\nChange type of `deleted` column from Boolean to table.id.type for all\ntables in migration 017. Models, api functions, and tests modified.\n\nPart of blueprint db-unique-keys\n\nChange-Id: I37be5d97a890501fc1b31ddc0e2e6318c9d1eb7f\n""}, {'number': 6, 'created': '2013-08-09 14:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fb361ca77746c251b98ad697193806e2c60006f7', 'message': ""Change column type from boolean to `id` type.\n\nWe can't create unique constraint for columns, because we are using\nsoft deletion of entries (set `deleted` column to True).\nThe main idea is to use `deleted` columns to create unique constraint\nfor columns. For example (`col1`, `deleted`).\nTo make (`col1`, `deleted`) unique after entry deletion, we should\nassign the value of `id` to `deleted` column.\n\nUpdated `openstack.common.db.sqlalchemy.utils` file (from Oslo). Added\nrequired exception module.\nChange type of `deleted` column from Boolean to table.id.type for all\ntables in migration 017. Models, api functions, and tests modified.\n\nPart of blueprint db-unique-keys\n\nChange-Id: I37be5d97a890501fc1b31ddc0e2e6318c9d1eb7f\n""}, {'number': 7, 'created': '2013-08-12 08:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8c9fd087a086771b9b9c919655e118ced7804cdc', 'message': ""Change column type from boolean to `id` type.\n\nWe can't create unique constraint for columns, because we are using\nsoft deletion of entries (set `deleted` column to True).\nThe main idea is to use `deleted` columns to create unique constraint\nfor columns. For example (`col1`, `deleted`).\nTo make (`col1`, `deleted`) unique after entry deletion, we should\nassign the value of `id` to `deleted` column.\n\nUpdated `openstack.common.db.sqlalchemy.utils` file (from Oslo). Added\nrequired exception module.\nChange type of `deleted` column from Boolean to table.id.type for all\ntables in migration 017. Models, api functions, and tests modified.\n\nPart of blueprint db-unique-keys\n\nChange-Id: I37be5d97a890501fc1b31ddc0e2e6318c9d1eb7f\n""}, {'number': 8, 'created': '2013-08-14 09:35:36.000000000', 'files': ['cinder/db/sqlalchemy/api.py', 'cinder/tests/test_volume.py', 'cinder/db/sqlalchemy/migrate_repo/versions/017_change_type_of_deleted_column.py', 'cinder/openstack/common/db/sqlalchemy/utils.py', 'cinder/tests/test_hp3par.py', 'cinder/tests/test_backup.py', 'cinder/tests/image/fake.py', 'cinder/openstack/common/exception.py', 'cinder/tests/api/v2/test_types.py', 'cinder/tests/api/v1/test_types.py', 'cinder/tests/test_quota.py', 'cinder/tests/db/test_transfers.py', 'cinder/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e748be7d2933fa6a2a5c45d65295645eeccb5363', 'message': ""Alter column `deleted` type from bool to `id` type\n\nWe can't create unique constraint for columns, because we are using\nsoft deletion of entries (set `deleted` column to True).\nThe main idea is to use `deleted` columns to create unique constraint\nfor columns. For example (`col1`, `deleted`).\nTo make (`col1`, `deleted`) unique after entry deletion, we should\nassign the value of `id` to `deleted` column.\n\nUpdated `openstack.common.db.sqlalchemy.utils` file (from Oslo). Added\nrequired exception module.\nChange type of `deleted` column from Boolean to table.id.type for all\ntables in migration 017. Models, api functions, and tests modified.\n\nPart of blueprint db-unique-keys\n\nChange-Id: I37be5d97a890501fc1b31ddc0e2e6318c9d1eb7f\n""}]",2,40660,e748be7d2933fa6a2a5c45d65295645eeccb5363,37,8,8,7491,,,0,"Alter column `deleted` type from bool to `id` type

We can't create unique constraint for columns, because we are using
soft deletion of entries (set `deleted` column to True).
The main idea is to use `deleted` columns to create unique constraint
for columns. For example (`col1`, `deleted`).
To make (`col1`, `deleted`) unique after entry deletion, we should
assign the value of `id` to `deleted` column.

Updated `openstack.common.db.sqlalchemy.utils` file (from Oslo). Added
required exception module.
Change type of `deleted` column from Boolean to table.id.type for all
tables in migration 017. Models, api functions, and tests modified.

Part of blueprint db-unique-keys

Change-Id: I37be5d97a890501fc1b31ddc0e2e6318c9d1eb7f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/60/40660/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/db/sqlalchemy/api.py', 'cinder/tests/test_volume.py', 'cinder/db/sqlalchemy/migrate_repo/versions/017_change_type_of_deleted_column.py', 'cinder/openstack/common/db/sqlalchemy/utils.py', 'cinder/tests/db/test_transfers.py', 'cinder/db/sqlalchemy/models.py', 'cinder/tests/test_backup.py']",7,e75b5eea3e13b87d95bd9a380d60a8f6c9389bd4,bp/db-unique-keys," self.assertEqual(backup.deleted, backup.id)"," self.assertEqual(backup.deleted, True)",456,53
openstack%2Fhorizon~master~Icd3af47dc60c4051a59b402de4ae05db80f9983e,openstack/horizon,master,Icd3af47dc60c4051a59b402de4ae05db80f9983e,Don't change name of volume when selecting the image,ABANDONED,2013-08-28 14:58:29.000000000,2013-09-06 06:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 4978}, {'_account_id': 8291}]","[{'number': 1, 'created': '2013-08-28 14:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2b60be95ab76b4283369557524e84c89d8d78b9f', 'message': 'Don\'t changes name of volume when selecting the image\n\nBehaviour for ""Create Volume"" form changed.\n::Now it doesn\'t overwrite the user-specified values with\nthe name of the source image if user already\nhas written name for a new volume.\n\nFixes bug 1213953\n\nChange-Id: Icd3af47dc60c4051a59b402de4ae05db80f9983e\n'}, {'number': 2, 'created': '2013-08-28 14:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2777f4486d3258b4b8d5ca899706eecb9f0f32de', 'message': 'Don\'t change name of volume when selecting the image.\n\nBehaviour for ""Create Volume"" form changed.\n::Now it doesn\'t overwrite the user-specified values with\nthe name of the source image if user already\nhas written name for a new volume.\n\nFixes bug 1213953\n\nChange-Id: Icd3af47dc60c4051a59b402de4ae05db80f9983e\n'}, {'number': 3, 'created': '2013-08-28 15:01:51.000000000', 'files': ['horizon/static/horizon/js/horizon.forms.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c284133d0159a9017ab288eb02d528de39332675', 'message': 'Don\'t change name of volume when selecting the image\n\nBehaviour for ""Create Volume"" form changed.\nNow it doesn\'t overwrite the user-specified values with\nthe name of the source image if user already\nhas written name for a new volume.\n\nFixes bug 1213953\n\nChange-Id: Icd3af47dc60c4051a59b402de4ae05db80f9983e\n'}]",0,44063,c284133d0159a9017ab288eb02d528de39332675,10,3,3,8291,,,0,"Don't change name of volume when selecting the image

Behaviour for ""Create Volume"" form changed.
Now it doesn't overwrite the user-specified values with
the name of the source image if user already
has written name for a new volume.

Fixes bug 1213953

Change-Id: Icd3af47dc60c4051a59b402de4ae05db80f9983e
",git fetch https://review.opendev.org/openstack/horizon refs/changes/63/44063/3 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.forms.js'],1,2b60be95ab76b4283369557524e84c89d8d78b9f,bug/1213953," if (!$volName.val()){ $volName.val($option.data(""name"")); }"," $volName.val($option.data(""name""));",3,1
openstack%2Fnova~master~I50854015e5817de281936814e9b6b39639a6edf5,openstack/nova,master,I50854015e5817de281936814e9b6b39639a6edf5,Adding glance-version in nova-conf,ABANDONED,2013-07-17 07:24:07.000000000,2013-09-06 06:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 1132}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 5347}, {'_account_id': 5441}, {'_account_id': 6159}, {'_account_id': 7701}]","[{'number': 1, 'created': '2013-07-17 07:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4cd81ddd0fc3b3e9d92601ef569705f94cd77808', 'message': 'Adding glanceclient-version in nova-conf\n\nNova should be configured to use glanceclient V1 or V2. Adds an extra\nparameter in the conf to specify this value. Currently it is hardcoded\nto 1 in all the glanceclient calls.\n\nChange-Id: I50854015e5817de281936814e9b6b39639a6edf5\nImplements: blueprint glanceclient-version-in-nova-conf\n'}, {'number': 2, 'created': '2013-07-17 14:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/82196580c77580d076ac2ad8943892d024c17f8a', 'message': 'Adding glanceclient-version in nova-conf\n\nNova should be configured to use glanceclient V1 or V2. Adds an extra\nparameter in the conf to specify this value. Currently it is hardcoded\nto 1 in all the glanceclient calls.\n\nChange-Id: I50854015e5817de281936814e9b6b39639a6edf5\nImplements: blueprint glanceclient-version-in-nova-conf\n'}, {'number': 3, 'created': '2013-08-19 16:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96d07bfc3c297c89c283862a11e9933bc6f5c97e', 'message': 'Adding glance-version in nova-conf\n\nNova should be configured to use either V1 or V2 of glance. Adds an extra\nparameter in the conf to specify this value. Currently it is hardcoded\nto 1 in all the glanceclient calls.\n\nChange-Id: I50854015e5817de281936814e9b6b39639a6edf5\nImplements: blueprint glanceclient-version-in-nova-conf\n'}, {'number': 4, 'created': '2013-08-20 06:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a81ee767a78dc226904cfb5f050050a37b7842e', 'message': 'Adding glance-version in nova-conf\n\nNova should be configured to use either V1 or V2 of glance. Adds an extra\nparameter in the conf to specify this value. Currently it is hardcoded\nto 1 in all the glanceclient calls.\n\nChange-Id: I50854015e5817de281936814e9b6b39639a6edf5\nImplements: blueprint glanceclient-version-in-nova-conf\n'}, {'number': 5, 'created': '2013-08-20 08:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9db8c00112b10013d97e5addc11e92a0396057b6', 'message': 'Adding glance-version in nova-conf\n\nNova should be configured to use either V1 or V2 of glance. Adds an extra\nparameter in the conf to specify this value. Currently it is hardcoded\nto 1 in all the glanceclient calls.\n\nChange-Id: I50854015e5817de281936814e9b6b39639a6edf5\nImplements: blueprint glanceclient-version-in-nova-conf\n'}, {'number': 6, 'created': '2013-08-23 09:42:43.000000000', 'files': ['etc/nova/nova.conf.sample', 'nova/image/glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a2613e4b8c4741beb8869056435ce98d8ec00f88', 'message': 'Adding glance-version in nova-conf\n\nNova should be configured to use either V1 or V2 of glance. Adds an\nextra parameter in the conf to specify this value. Currently it is hardcoded\nto 1 in all the glanceclient calls.\n\nChange-Id: I50854015e5817de281936814e9b6b39639a6edf5\nImplements: blueprint glanceclient-version-in-nova-conf\n'}]",2,37411,a2613e4b8c4741beb8869056435ce98d8ec00f88,36,10,6,7701,,,0,"Adding glance-version in nova-conf

Nova should be configured to use either V1 or V2 of glance. Adds an
extra parameter in the conf to specify this value. Currently it is hardcoded
to 1 in all the glanceclient calls.

Change-Id: I50854015e5817de281936814e9b6b39639a6edf5
Implements: blueprint glanceclient-version-in-nova-conf
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/37411/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/nova/nova.conf.sample', 'nova/image/glance.py']",2,4cd81ddd0fc3b3e9d92601ef569705f94cd77808,bp/glanceclient-version-in-nova-conf," cfg.IntOpt('glanceclient_version', default=1, help='default glanceclient version'), images = self._client.call(context, CONF.glanceclient_version, 'list', **params) image = self._client.call(context, CONF.glanceclient_version, 'get', image_id) image_meta = client.call(context, CONF.glanceclient_version, 'get', image_id) image_chunks = self._client.call(context, CONF.glanceclient_version, 'data', image_id) context, CONF.glanceclient_version, 'create', **sent_service_image_meta) image_meta = self._client.call(context, CONF.glanceclient_version, 'update', image_id, **image_meta) self._client.call(context, CONF.glanceclient_version, 'delete', image_id)"," images = self._client.call(context, 1, 'list', **params) image = self._client.call(context, 1, 'get', image_id) image_meta = client.call(context, 2, 'get', image_id) image_chunks = self._client.call(context, 1, 'data', image_id) context, 1, 'create', **sent_service_image_meta) image_meta = self._client.call(context, 1, 'update', image_id, **image_meta) self._client.call(context, 1, 'delete', image_id)",22,8
openstack%2Fheat~master~Ib474f368aded03df9f1258a01cd88147ea73202b,openstack/heat,master,Ib474f368aded03df9f1258a01cd88147ea73202b,Add a template function to run strings through jinja2,ABANDONED,2013-08-14 07:51:52.000000000,2013-09-06 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 7193}, {'_account_id': 7385}]","[{'number': 1, 'created': '2013-08-14 07:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dec6daf341767fd8dcd5e90753f928442e67c755', 'message': 'Add a template function to run strings through jinja2\n\nChange-Id: Ib474f368aded03df9f1258a01cd88147ea73202b\n'}, {'number': 2, 'created': '2013-08-14 11:29:53.000000000', 'files': ['requirements.txt', 'heat/engine/parser.py', 'heat/engine/template.py', 'heat/tests/test_parser.py', 'doc/source/template_guide/functions.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/a90f0c9387dc5b890d9d56160f2b752599cdb539', 'message': 'Add a template function to run strings through jinja2\n\nChange-Id: Ib474f368aded03df9f1258a01cd88147ea73202b\n'}]",0,41858,a90f0c9387dc5b890d9d56160f2b752599cdb539,15,8,2,4715,,,0,"Add a template function to run strings through jinja2

Change-Id: Ib474f368aded03df9f1258a01cd88147ea73202b
",git fetch https://review.opendev.org/openstack/heat refs/changes/58/41858/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/parser.py', 'heat/engine/template.py', 'heat/tests/test_parser.py', 'doc/source/template_guide/functions.rst']",4,dec6daf341767fd8dcd5e90753f928442e67c755,master, ---------- Fn::Jinja2 ---------- Run a string snippet through Jinja2. Note that the result will be loaded as yaml. The parameters can be accessed via ``parameters.<parameter name>``. Parameters ~~~~~~~~~~ string : string A string to process with jinja2. Usage ~~~~~ :: 'Fn::Jinja2': | <% for d in parameters.Dimensions %> << d.Name >>: << d.Value >> <% endfor %> returns: group: 'very important' instance: 'inst-4545' ,,99,0
openstack%2Fneutron~master~I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44,openstack/neutron,master,I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44,Enable multihost network with DHCP agent,ABANDONED,2013-07-19 14:55:58.000000000,2013-09-06 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1970}, {'_account_id': 2031}, {'_account_id': 2035}, {'_account_id': 2166}, {'_account_id': 2468}, {'_account_id': 2874}]","[{'number': 1, 'created': '2013-07-19 14:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a184c473dbc95d0a986a90a0b31b87523e55c9b0', 'message': 'Enable multihost network with DHCP agent\n\nThis is phase one of multihost blureprint. This patch\nenables the multihost network. Next phase will enable\nmultihost L3 router.\n\nCurrently, we will have one DHCP IP for each DHCP enabled\nsubnet of multihost network on each host. Following patches\nwill consider use shared DHCP IP.\n\nPure multihost network without multihost L3 router is valuable\nfor Use Case Single Flat Network in networking administration guide.\n\nimplements: blueprint quantum-multihost\n\nChange-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44\n'}, {'number': 2, 'created': '2013-07-22 02:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5cd5fdc3c9bdc2f4e8b9112e018376dd60bfa906', 'message': 'Enable multihost network with DHCP agent\n\nThis is phase one of multihost blureprint. This patch\nenables the multihost network. Next phase will enable\nmultihost L3 router.\n\nCurrently, we will have one DHCP IP for each DHCP enabled\nsubnet of multihost network on each host. Following patches\nwill consider use shared DHCP IP. OVS plugin is the fisrt\nplugin to support this feature.\n\nPure multihost network without multihost L3 router is valuable\nfor Use Case Single Flat Network in networking administration guide.\n\nimplements: blueprint quantum-multihost\n\nChange-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44\n'}, {'number': 3, 'created': '2013-08-08 09:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4631159d57aaeac49c116a93bd8ed24627451fb3', 'message': 'Enable multihost network with DHCP agent\n\nThis is phase one of multihost blureprint. This patch\nenables the multihost network. Next phase will enable\nmultihost L3 router.\n\nwhen a network is multihost one,\n--addn-hosts is used to record all the dns entries of\nthe VMs of the network, --dhcp-hostsfile will only record\nthe VMs on local host.\n\nCurrently, we will have one DHCP IP for each DHCP enabled\nsubnet of multihost network on each host. Following patches\nwill consider use shared DHCP IP. OVS plugin is the fisrt\nplugin to support this feature.\n\nPure multihost network without multihost L3 router is valuable\nfor Use Case Single Flat Network in networking administration guide.\n\nimplements: blueprint quantum-multihost\n\nChange-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44\n'}, {'number': 4, 'created': '2013-08-08 09:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/df3682f79b96eb0b7df5baa4910724abfcf540cb', 'message': 'Enable multihost network with DHCP agent\n\nThis is phase one of multihost blureprint. This patch\nenables the multihost network. Next phase will enable\nmultihost L3 router.\n\nwhen a network is multihost one,\n--addn-hosts is used to record all the dns entries of\nthe VMs of the network, --dhcp-hostsfile will only record\nthe VMs on local host.\n\nCurrently, we will have one DHCP IP for each DHCP enabled\nsubnet of multihost network on each host. Following patches\nwill consider use shared DHCP IP. OVS plugin is the fisrt\nplugin to support this feature.\n\nPure multihost network without multihost L3 router is valuable\nfor Use Case Single Flat Network in networking administration guide.\n\nimplements: blueprint quantum-multihost\n\nChange-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44\n'}, {'number': 5, 'created': '2013-08-08 14:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eaa6c523032cfee266f6b92b39872e20fd46705d', 'message': 'Enable multihost network with DHCP agent\n\nThis is phase one of multihost blureprint. This patch\nenables the multihost network. Next phase will enable\nmultihost L3 router.\n\nwhen a network is multihost one,\n--addn-hosts is used to record all the dns entries of\nthe VMs of the network, --dhcp-hostsfile will only record\nthe VMs on local host.\n\nCurrently, we will have one DHCP IP for each DHCP enabled\nsubnet of multihost network on each host. Following patches\nwill consider use shared DHCP IP. OVS plugin is the fisrt\nplugin to support this feature.\n\nPure multihost network without multihost L3 router is valuable\nfor Use Case Single Flat Network in networking administration guide.\n\nimplements: blueprint quantum-multihost\n\nChange-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44\n'}, {'number': 6, 'created': '2013-08-19 04:30:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/794193f619ff0081eddf9ab0cb7c074122e922fb', 'message': 'Enable multihost network with DHCP agent\n\nThis is phase one of multihost blureprint. This patch\nenables the multihost network. Next phase will enable\nmultihost L3 router.\n\nwhen a network is multihost one,\n--addn-hosts is used to record all the dns entries of\nthe VMs of the network, --dhcp-hostsfile will only record\nthe VMs on local host.\n\nCurrently, we will have one DHCP IP for each DHCP enabled\nsubnet of multihost network on each host. Following patches\nwill consider use shared DHCP IP. Ml2 and OVS plugins are the fisrt\nplugins to support this feature.\n\nPure multihost network without multihost L3 router is valuable\nfor Use Case Single Flat Network in networking administration guide.\n\nimplements: blueprint quantum-multihost\n\nChange-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44\n'}, {'number': 7, 'created': '2013-08-21 09:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4aff1c1f449cc1184b974e824bbddb375f0b50e0', 'message': 'Enable multihost network with DHCP agent\n\nThis is phase one of multihost blureprint. This patch\nenables the multihost network. Next phase will enable\nmultihost L3 router.\n\nwhen a network is multihost one,\n--addn-hosts is used to record all the dns entries of\nthe VMs of the network, --dhcp-hostsfile will only record\nthe VMs on local host.\n\nCurrently, we will have one DHCP IP for each DHCP enabled\nsubnet of multihost network on each host. Following patches\nwill consider use shared DHCP IP. Ml2 and OVS plugins are the fisrt\nplugins to support this feature.\n\nPure multihost network without multihost L3 router is valuable\nfor Use Case Single Flat Network in networking administration guide.\n\nimplements: blueprint quantum-multihost\n\nChange-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44\n'}, {'number': 8, 'created': '2013-08-22 00:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/10cc2c2d58b487bb98e1d09204a060d52ef7e749', 'message': 'Enable multihost network with DHCP agent\n\nThis is phase one of multihost blureprint. This patch\nenables the multihost network. Next phase will enable\nmultihost L3 router.\n\nwhen a network is multihost one,\n--addn-hosts is used to record all the dns entries of\nthe VMs of the network, --dhcp-hostsfile will only record\nthe VMs on local host.\n\nCurrently, we will have one DHCP IP for each DHCP enabled\nsubnet of multihost network on each host. Following patches\nwill consider use shared DHCP IP. Ml2 and OVS plugins are the fisrt\nplugins to support this feature.\n\nPure multihost network without multihost L3 router is valuable\nfor Use Case Single Flat Network in networking administration guide.\n\nimplements: blueprint quantum-multihost\n\nChange-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44\n'}, {'number': 9, 'created': '2013-08-23 08:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7083abe6b0eb173e3228fc23bf35f4025c0dd42b', 'message': 'Enable multihost network with DHCP agent\n\nThis is phase one of multihost blureprint. This patch\nenables the multihost network. Next phase will enable\nmultihost L3 router.\n\nwhen a network is multihost one,\n--addn-hosts is used to record all the dns entries of\nthe VMs of the network, --dhcp-hostsfile will only record\nthe VMs on local host.\n\nCurrently, we will have one DHCP IP for each DHCP enabled\nsubnet of multihost network on each host. Following patches\nwill consider use shared DHCP IP. Ml2 and OVS plugins are the fisrt\nplugins to support this feature.\n\nPure multihost network without multihost L3 router is valuable\nfor Use Case Single Flat Network in networking administration guide.\n\nimplements: blueprint quantum-multihost\n\nChange-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44\n'}, {'number': 10, 'created': '2013-08-23 10:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a0352eb90a503f6fc07f30614981249d0f8f95aa', 'message': 'Enable multihost network with DHCP agent\n\nThis is phase one of multihost blureprint. This patch\nenables the multihost network. Next phase will enable\nmultihost L3 router.\n\nwhen a network is multihost one,\n--addn-hosts is used to record all the dns entries of\nthe VMs of the network, --dhcp-hostsfile will only record\nthe VMs on local host.\n\nCurrently, we will have one DHCP IP for each DHCP enabled\nsubnet of multihost network on each host. Following patches\nwill consider use shared DHCP IP. Ml2 and OVS plugins are the fisrt\nplugins to support this feature.\n\nPure multihost network without multihost L3 router is valuable\nfor Use Case Single Flat Network in networking administration guide.\n\nimplements: blueprint quantum-multihost\n\nChange-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44\n'}, {'number': 11, 'created': '2013-08-25 01:56:30.000000000', 'files': ['neutron/plugins/linuxbridge/lb_neutron_plugin.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/tests/unit/_test_extension_mutihost_network.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/extensions/multihostnetwork.py', 'etc/dhcp_agent.ini', 'neutron/plugins/openvswitch/ovs_neutron_plugin.py', 'neutron/agent/linux/dhcp.py', 'neutron/db/migration/alembic_migrations/versions/bedee3b5550_network_multihost.py', 'neutron/plugins/ml2/plugin.py', 'neutron/db/agents_db.py', 'neutron/common/constants.py', 'neutron/agent/dhcp_agent.py', 'neutron/db/multihost_network_db.py', 'neutron/extensions/agent.py', 'neutron/common/topics.py', 'neutron/tests/unit/linuxbridge/test_linuxbridge_plugin.py', 'neutron/db/dhcp_rpc_base.py', 'neutron/tests/unit/test_linux_dhcp.py', 'etc/policy.json', 'neutron/tests/unit/openvswitch/test_openvswitch_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c5470a975d893a126d9a63ca56d7572947c33a1d', 'message': 'Enable multihost network with DHCP agent\n\nThis is phase one of multihost blureprint. This patch\nenables the multihost network. Next phase will enable\nmultihost L3 router.\n\nwhen a network is multihost one,\n--addn-hosts is used to record all the dns entries of\nthe VMs of the network, --dhcp-hostsfile will only record\nthe VMs on local host.\n\nCurrently, we will have one DHCP IP for each DHCP enabled\nsubnet of multihost network on each host. Following patches\nwill consider use shared DHCP IP. Ml2, linuxbridge, and\nOVS plugins are the fisrt plugins to support this feature.\n\nPure multihost network without multihost L3 router is valuable\nfor Use Case Single Flat Network in networking administration guide.\n\nimplements: blueprint quantum-multihost\n\nChange-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44\n'}]",22,37919,c5470a975d893a126d9a63ca56d7572947c33a1d,67,11,11,2874,,,0,"Enable multihost network with DHCP agent

This is phase one of multihost blureprint. This patch
enables the multihost network. Next phase will enable
multihost L3 router.

when a network is multihost one,
--addn-hosts is used to record all the dns entries of
the VMs of the network, --dhcp-hostsfile will only record
the VMs on local host.

Currently, we will have one DHCP IP for each DHCP enabled
subnet of multihost network on each host. Following patches
will consider use shared DHCP IP. Ml2, linuxbridge, and
OVS plugins are the fisrt plugins to support this feature.

Pure multihost network without multihost L3 router is valuable
for Use Case Single Flat Network in networking administration guide.

implements: blueprint quantum-multihost

Change-Id: I9b4b9e4d68829cf556b2cc32287cf8fc8472fc44
",git fetch https://review.opendev.org/openstack/neutron refs/changes/19/37919/10 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/tests/unit/_test_extension_mutihost_network.py', 'neutron/extensions/multihostnetwork.py', 'etc/dhcp_agent.ini', 'neutron/plugins/openvswitch/ovs_neutron_plugin.py', 'neutron/db/agents_db.py', 'neutron/common/constants.py', 'neutron/agent/dhcp_agent.py', 'neutron/db/multihost_network_db.py', 'neutron/extensions/agent.py', 'neutron/common/topics.py', 'neutron/db/dhcp_rpc_base.py', 'etc/policy.json', 'neutron/tests/unit/test_dhcp_agent.py', 'neutron/tests/unit/openvswitch/test_openvswitch_plugin.py']",15,a184c473dbc95d0a986a90a0b31b87523e55c9b0,bp/quantum-multihost,"import mock from neutron.api import extensions from neutron.api.rpc.agentnotifiers import dhcp_rpc_agent_api from neutron import contextfrom neutron.tests.unit import _test_extension_mutihost_networkfrom neutron.tests.unit import test_agent_ext_pluginfrom neutron.tests.unit import test_extensions class TestOpenvswitchMultihostNetwork( test_agent_ext_plugin.AgentDBTestMixIn, _test_extension_mutihost_network.MultihostNetworkDbTestCaseMixin, OpenvswitchPluginV2TestCase): def setUp(self): self.dhcp_notifier = dhcp_rpc_agent_api.DhcpAgentNotifyAPI() self.dhcp_notifier_cls_p = mock.patch( 'quantum.api.rpc.agentnotifiers.dhcp_rpc_agent_api.' 'DhcpAgentNotifyAPI') self.dhcp_notifier_cls = self.dhcp_notifier_cls_p.start() self.dhcp_notifier_cls.return_value = self.dhcp_notifier super(TestOpenvswitchMultihostNetwork, self).setUp() ext_mgr = extensions.PluginAwareExtensionManager.get_instance() self.ext_api = test_extensions.setup_extensions_middleware(ext_mgr) self.adminContext = context.get_admin_context() self.addCleanup(self.dhcp_notifier_cls_p.stop)",,467,15
openstack%2Fnova~master~I7481bf6ff944088057728fa3dd11f58d678d06f3,openstack/nova,master,I7481bf6ff944088057728fa3dd11f58d678d06f3,Correct server action confirm_resize v3 API return code,ABANDONED,2013-08-13 16:28:21.000000000,2013-09-06 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 5174}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 7231}]","[{'number': 1, 'created': '2013-08-13 16:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/88fba8845cd2c2b79db17c01ca898c033d023ae9', 'message': 'Correct confirm_resize v3 API return code\n\nThe confirm_resize method currently returns 204 instead of\nthe expected 202.\n\nFixes bug 1088695\nDocImpact\n\nChange-Id: I7481bf6ff944088057728fa3dd11f58d678d06f3\n'}, {'number': 2, 'created': '2013-08-13 17:32:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91ecc2a939fc569a7d9a026b4bb3df0e41958825', 'message': 'Correct confirm_resize v3 API return code\n\nThe confirm_resize method currently returns 204 instead of\nthe expected 202.\n\nFixes bug 1088695\nDocImpact\n\nChange-Id: I7481bf6ff944088057728fa3dd11f58d678d06f3\n'}, {'number': 3, 'created': '2013-08-14 14:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80ed1a57294462f3d70e59d19a81bd5d6a420991', 'message': 'Correct confirm_resize v3 API return code\n\nThe confirm_resize method currently returns 204 instead of\nthe expected 202.\n\nFixes bug 1088695\nDocImpact\n\nChange-Id: I7481bf6ff944088057728fa3dd11f58d678d06f3\n'}, {'number': 4, 'created': '2013-08-29 15:28:20.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_server_actions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/df15e14ce383ad9d4f976dc624e55103d5601fba', 'message': 'Correct server action confirm_resize v3 API return code\n\nThe confirm_resize method currently returns 204 instead of\nthe expected 202.  This change also removes unnecessary\nreturns when @wsgi.response() is used.\n\nFixes bug 1088695\nDocImpact\n\nChange-Id: I7481bf6ff944088057728fa3dd11f58d678d06f3\n'}]",1,41724,df15e14ce383ad9d4f976dc624e55103d5601fba,17,7,4,7231,,,0,"Correct server action confirm_resize v3 API return code

The confirm_resize method currently returns 204 instead of
the expected 202.  This change also removes unnecessary
returns when @wsgi.response() is used.

Fixes bug 1088695
DocImpact

Change-Id: I7481bf6ff944088057728fa3dd11f58d678d06f3
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/41724/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py']",2,88fba8845cd2c2b79db17c01ca898c033d023ae9,bug/1088695," class ActionTest(test.TestCase): def setUp(self): super(ActionsTest, self).setUp() ext_info = plugins.LoadedExtensionInfo() self.controller = servers.ServersController(extension_info=ext_info) def _create_instance_object(self, context, instance_id): instance = instance_obj.Instance() instance._context = context instance.id = instance_id instance.uuid = str(uuid.uuid4()) return instance def test_confirm_resize(self): instance_id = '1234' req = fakes.HTTPRequestV3.blank('/servers/%s/action' % instance_id) ctxt = req.environ['nova.context'] instance = self._create_instance_object(ctxt, instance_id) def _fake_instance_get(*args, **kwargs): return instance self.stubs.Set(self.controller.compute_api, 'get', _fake_instance_get) self.mox.StubOutWithMock(self.controller.compute_api, 'confirm_resize') self.controller.compute_api.confirm_resize(ctxt, instance) self.mox.ReplayAll() response = self.controller._action_confirm_resize(req, instance_id, {}) self.assertEqual(response.status_int, 202)",,35,1
openstack%2Fkeystone~master~I987f053f906df93914e85f0305ba26dd84c23901,openstack/keystone,master,I987f053f906df93914e85f0305ba26dd84c23901,Use common Oslo code for work with database,ABANDONED,2013-07-20 09:15:08.000000000,2013-09-06 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2166}, {'_account_id': 5046}, {'_account_id': 7491}]","[{'number': 1, 'created': '2013-07-20 09:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/97e4418d3086571a6cd1f2d03aae0815ca64c979', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nparent and removed duplicated code\nUse common oslo code wor work with session and engine.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 2, 'created': '2013-07-20 09:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1119465dcc6927a88a0d66cd8bab9afc8b20e524', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nparent and removed duplicated code\nUse common oslo code wor work with session and engine.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 3, 'created': '2013-07-20 09:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1021defd62b147470ff6e83a9af4df468d592032', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nparent and removed duplicated code\nUse common oslo code wor work with session and engine.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 4, 'created': '2013-07-20 09:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3d4653695a445936f551d40fa09310aa91be61c5', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nparent and removed duplicated code\nUse common oslo code wor work with session and engine.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 5, 'created': '2013-07-20 11:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e48f7224696fbfed8fde7098a2172330f1f330e1', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nparent and removed duplicated code\nUse common oslo code wor work with session and engine.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\n`keystone/common/sql/migration.py`\nAdded monkey patching to sqlalchemy-migrate. It allow use use\n`UniqueConstrain(...).drop()` for sqlite.\n\n`keystone/identity/backends/sql.py`\n`keystone/assignment/backends/sql.py`\n`keystone/common/sql/migrate_repo/versions/030_rename_unique_constraints.py`\nRenamed unique constraints due to common name convention.\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 6, 'created': '2013-07-22 07:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/51622a0601a9c520a7364252c1addb838ed9e43c', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nparent and removed duplicated code\nUse common oslo code wor work with session and engine.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 7, 'created': '2013-07-22 08:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3a05564f94a20b5bee92cb419a880b80d64458d2', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nparent and removed duplicated code\nUse common oslo code wor work with session and engine.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 9, 'created': '2013-07-22 09:39:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2d2b4ba0ab5087bdbfff21f361ed757afd71ddb2', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nparent and removed duplicated code\nUse common oslo code wor work with session and engine.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 8, 'created': '2013-07-22 09:39:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fe31df94d45f197b263357a569b426e4dc11df95', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nparent and removed duplicated code\nUse common oslo code wor work with session and engine.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 10, 'created': '2013-08-09 13:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6ba17ad80fe76837aa315093239c156a1e26cf01', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nbase class instead of object and removed duplicated code.\nUsed ping_listener() frunction from common oslo code instead of keystone\nimplementation.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 12, 'created': '2013-08-12 12:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dcd848af6874e6c2979a057aae6e5079c0ea647a', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nbase class instead of object and removed duplicated code.\nUsed ping_listener() frunction from common oslo code instead of keystone\nimplementation.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 11, 'created': '2013-08-12 12:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/703694db52ba0beb464595d4076d15f76b8337a2', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nbase class instead of object and removed duplicated code.\nUsed ping_listener() frunction from common oslo code instead of keystone\nimplementation.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 13, 'created': '2013-08-15 09:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e931f298ffe19ed59318c3fa209b444424efc078', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nbase class instead of object and removed duplicated code.\nUsed ping_listener() frunction from common oslo code instead of keystone\nimplementation.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}, {'number': 14, 'created': '2013-08-16 10:34:19.000000000', 'files': ['etc/keystone.conf.sample', 'keystone/tests/backend_mysql.conf', 'requirements.txt', 'keystone/common/config.py', 'keystone/tests/backend_sql.conf', 'keystone/common/sql/core.py', 'keystone/tests/backend_ldap_sql.conf', 'keystone/common/sql/migration.py', 'keystone/tests/backend_postgresql.conf', 'keystone/tests/backend_db2.conf', 'keystone/tests/backend_sql_disk.conf'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1c3de7476faada9a46f44176959249fd19531234', 'message': 'Use common Oslo code for work with database\n\n`keystone/common/sql/core.py`\nModified DictBase class - added common `models.ModelBase` class as\nbase class instead of object and removed duplicated code.\nUsed ping_listener() frunction from common oslo code instead of keystone\nimplementation.\n\n`requirements.txt`\nAdded new oslo.config version\n\n`keystone/common/config.py`\nRemoved options, that duplicates in common oslo config\n\n`keystone/common/sql/migration.py`\n`tests/backend_db2.conf`\n`tests/backend_ldap_sql.conf`\n`tests/backend_mysql.conf`\n`tests/backend_postgresql.conf`\n`tests/backend_sql.conf`\n`tests/backend_sql_disk.conf`\nRenamed `sql` section to `database`\n\nblueprint use-common-oslo-db-code\n\nChange-Id: I987f053f906df93914e85f0305ba26dd84c23901\n'}]",2,38030,1c3de7476faada9a46f44176959249fd19531234,55,5,14,7491,,,0,"Use common Oslo code for work with database

`keystone/common/sql/core.py`
Modified DictBase class - added common `models.ModelBase` class as
base class instead of object and removed duplicated code.
Used ping_listener() frunction from common oslo code instead of keystone
implementation.

`requirements.txt`
Added new oslo.config version

`keystone/common/config.py`
Removed options, that duplicates in common oslo config

`keystone/common/sql/migration.py`
`tests/backend_db2.conf`
`tests/backend_ldap_sql.conf`
`tests/backend_mysql.conf`
`tests/backend_postgresql.conf`
`tests/backend_sql.conf`
`tests/backend_sql_disk.conf`
Renamed `sql` section to `database`

blueprint use-common-oslo-db-code

Change-Id: I987f053f906df93914e85f0305ba26dd84c23901
",git fetch https://review.opendev.org/openstack/keystone refs/changes/30/38030/14 && git format-patch -1 --stdout FETCH_HEAD,"['tests/backend_sql_disk.conf', 'tests/backend_db2.conf', 'requirements.txt', 'keystone/common/config.py', 'tests/backend_sql.conf', 'keystone/common/sql/core.py', 'keystone/common/sql/migration.py', 'tests/backend_mysql.conf', 'tests/backend_ldap_sql.conf', 'tests/backend_postgresql.conf']",10,97e4418d3086571a6cd1f2d03aae0815ca64c979,bp/use-common-oslo-db-code,[database],[sql],61,119
openstack%2Fnova~stable%2Fgrizzly~Id4e07582526ad27c6e181e5d0618f6ded1a4a6cb,openstack/nova,stable/grizzly,Id4e07582526ad27c6e181e5d0618f6ded1a4a6cb,Filter network by project id,ABANDONED,2013-08-29 09:58:45.000000000,2013-09-06 05:30:39.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1561}, {'_account_id': 2711}, {'_account_id': 5313}, {'_account_id': 6486}, {'_account_id': 6526}, {'_account_id': 7996}]","[{'number': 1, 'created': '2013-08-29 09:58:45.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_networks.py', 'nova/network/api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bcb91f4340d145ce10c1dbd01715cfe9dd14f24b', 'message': 'Filter network by project id\n\nNeed filter the networks by project id when show the networks with\nnormal user\n\nFix bug 1186867\n\nChange-Id: I10b5880070a569614f54fa7dbcf08e548bcbc924\n(cherry picked from commit 2a7f08ae4abca51dc60a02deee06a108ad1c4dcc)\n\nConflicts:\n\tnova/db/sqlalchemy/api.py\n\tnova/tests/db/test_db_api.py\n\nChange-Id: Id4e07582526ad27c6e181e5d0618f6ded1a4a6cb\n'}]",6,44256,bcb91f4340d145ce10c1dbd01715cfe9dd14f24b,12,8,1,6526,,,0,"Filter network by project id

Need filter the networks by project id when show the networks with
normal user

Fix bug 1186867

Change-Id: I10b5880070a569614f54fa7dbcf08e548bcbc924
(cherry picked from commit 2a7f08ae4abca51dc60a02deee06a108ad1c4dcc)

Conflicts:
	nova/db/sqlalchemy/api.py
	nova/tests/db/test_db_api.py

Change-Id: Id4e07582526ad27c6e181e5d0618f6ded1a4a6cb
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/44256/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_networks.py', 'nova/network/api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py']",4,bcb91f4340d145ce10c1dbd01715cfe9dd14f24b,bug/1186867,"def network_get_all(context, project_only): result = model_query(context, models.Network, read_deleted=""no"", project_only=project_only).all()def network_get_all_by_uuids(context, network_uuids, project_only):","def network_get_all(context): result = model_query(context, models.Network, read_deleted=""no"").all()def network_get_all_by_uuids(context, network_uuids, project_only=""allow_none""):",38,9
openstack%2Fopenstack-manuals~master~I867c7af8659044791c8b54cc3ebfaec73c9ae52f,openstack/openstack-manuals,master,I867c7af8659044791c8b54cc3ebfaec73c9ae52f,amend text in accordance to further review on 43650:,MERGED,2013-08-26 03:46:48.000000000,2013-09-06 04:04:18.000000000,2013-09-06 04:04:17.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 3153}, {'_account_id': 6547}, {'_account_id': 7150}]","[{'number': 1, 'created': '2013-08-26 03:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cf3e3139a3feb0caf1370bcde26a6e116951b50b', 'message': 'fix ugly ""IP\'s"" plural reference; add mdashes to nicely separate list headings\nfrom their content\n\nChange-Id: I867c7af8659044791c8b54cc3ebfaec73c9ae52f\n'}, {'number': 2, 'created': '2013-09-03 00:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d645ca3d261b2d1d041cd8aa5a9240f03a628de1', 'message': 'add fixes from inline comments - 43650\nfix ugly ""IP\'s"" plural reference; add mdashes to nicely separate list headings\nfrom their content\n\nChange-Id: I867c7af8659044791c8b54cc3ebfaec73c9ae52f\n'}, {'number': 3, 'created': '2013-09-04 23:06:43.000000000', 'files': ['doc/src/docbkx/openstack-security/ch032_networking-best-practices.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/aac968bccbbd905cf43edd8d8116dfdd2507816c', 'message': 'amend text in accordance to further review on 43650:\n\n- re-word section, to do a better job of explaining that DHCP and L3 agents need Linux network namespace support if overlappping IP addresses are in use on the same host.\n\nChange-Id: I867c7af8659044791c8b54cc3ebfaec73c9ae52f\n'}]",6,43650,aac968bccbbd905cf43edd8d8116dfdd2507816c,18,7,3,7150,,,0,"amend text in accordance to further review on 43650:

- re-word section, to do a better job of explaining that DHCP and L3 agents need Linux network namespace support if overlappping IP addresses are in use on the same host.

Change-Id: I867c7af8659044791c8b54cc3ebfaec73c9ae52f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/50/43650/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-security/ch032_networking-best-practices.xml'],1,cf3e3139a3feb0caf1370bcde26a6e116951b50b,doc/grammarhunt," <para><emphasis role=""bold"">Overlapping IP addresses</emphasis> &#x2014; Linux network namespaces are required on nodes running neutron-l3-agent or neutron-dhcp-agent if overlapping IP addresses are in use. In order to support overlapping IP addresses, the OpenStack Networking DHCP and L3 agents use Linux network namespaces by default. If the host does not support namespaces then the <literal>neutron-l3-agent</literal> and <literal>neutron-dhcp-agent</literal> should be run on different hosts.</para> <para><emphasis role=""bold"">Multi-Host DHCP-agent</emphasis> &#x2014; OpenStack Networking now supports running multiple l3-agent and dhcp-agents with load being split across those agents, but the tight coupling of that scheduling with the location of the VM is not supported in Grizzly. The Havana release is expected to include an exact replacement for the --multi_host flag in nova-network.</para> <para><emphasis role=""bold"">No IPv6 Support for L3 agents</emphasis> &#x2014; The neutron-l3-agent, used by many plugins to implement L3 forwarding, supports only IPv4 forwarding.</para>"," <para><emphasis role=""bold"">Overlapping IP addresses</emphasis>Linux network namespaces are required on nodes running neutron-l3-agent or neutron-dhcp-agent if overlapping IP's are in use. In order to support overlapping IP addresses, the OpenStack Networking DHCP and L3 agents use Linux network namespaces by default. If the host does not support namespaces then the <literal>neutron-l3-agent</literal> and <literal>neutron-dhcp-agent</literal> should be run on different hosts.</para> <para><emphasis role=""bold"">Multi-Host DHCP-agent</emphasis>OpenStack Networking now supports running multiple l3-agent and dhcp-agents with load being split across those agents, but the tight coupling of that scheduling with the location of the VM is not supported in Grizzly. The Havana release is expected to include an exact replacement for the --multi_host flag in nova-network.</para> <para><emphasis role=""bold"">No IPv6 Support for L3 agents</emphasis>The neutron-l3-agent, used by many plugins to implement L3 forwarding, supports only IPv4 forwarding.</para>",3,3
openstack%2Fheat~master~Ic40c3be10b32eb3011bc0733cee9c1faaf8f1240,openstack/heat,master,Ic40c3be10b32eb3011bc0733cee9c1faaf8f1240,Run cfg.CONF.reset() on test cleanup,MERGED,2013-09-05 23:49:25.000000000,2013-09-06 04:04:11.000000000,2013-09-06 04:04:10.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-09-05 23:49:25.000000000', 'files': ['heat/tests/common.py', 'heat/tests/test_auth_password.py', 'heat/tests/test_heatclient.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/8a0043f5d63c7f918eb103d7922ff6a1c2c5d588', 'message': 'Run cfg.CONF.reset() on test cleanup\n\nThis means clear_override and clear_default do not\nneed to be called explicitly for each set_override and set_default\ncall.\n\nThis also fixes any potential test execution order issues\nwhere an option has been set without being cleared at all.\n\nChange-Id: Ic40c3be10b32eb3011bc0733cee9c1faaf8f1240\nFixes-Bug: #1221476\n'}]",0,45354,8a0043f5d63c7f918eb103d7922ff6a1c2c5d588,6,3,1,4571,,,0,"Run cfg.CONF.reset() on test cleanup

This means clear_override and clear_default do not
need to be called explicitly for each set_override and set_default
call.

This also fixes any potential test execution order issues
where an option has been set without being cleared at all.

Change-Id: Ic40c3be10b32eb3011bc0733cee9c1faaf8f1240
Fixes-Bug: #1221476
",git fetch https://review.opendev.org/openstack/heat refs/changes/54/45354/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/common.py', 'heat/tests/test_auth_password.py', 'heat/tests/test_heatclient.py']",3,8a0043f5d63c7f918eb103d7922ff6a1c2c5d588,bug/1217617,," def tearDown(self): super(KeystoneClientTest, self).tearDown() cfg.CONF.clear_override('deferred_auth_method') cfg.CONF.clear_override('auth_uri', group='keystone_authtoken') cfg.CONF.clear_override('admin_user', group='keystone_authtoken') cfg.CONF.clear_override('admin_password', group='keystone_authtoken') cfg.CONF.clear_override('admin_tenant_name', group='keystone_authtoken') ",1,14
openstack%2Fheat~master~I99f05996711b3851811940ad5741e96d5ae61ed6,openstack/heat,master,I99f05996711b3851811940ad5741e96d5ae61ed6,Fix H233 in sphinx config,MERGED,2013-09-04 22:49:39.000000000,2013-09-06 04:04:04.000000000,2013-09-06 04:04:03.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-09-04 22:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/994eb03c8bfd73ac212e1351ff5f3d5281610157', 'message': 'Fix H233 in sphinx config\n\nThis is being flagged in local flake8 runs.\n\nChange-Id: I99f05996711b3851811940ad5741e96d5ae61ed6\n'}, {'number': 2, 'created': '2013-09-04 23:03:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5fea89db5b2d2bd13a13d307be61ca519d3c4ffd', 'message': 'Fix H233 in sphinx config\n\nThis is being flagged in local flake8 runs.\n\nChange-Id: I99f05996711b3851811940ad5741e96d5ae61ed6\n'}, {'number': 3, 'created': '2013-09-05 23:49:26.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/8282ab4ddbda95b16a84cf974d520c74cb132bf5', 'message': 'Fix H233 in sphinx config\n\nThis is being flagged in local flake8 runs.\n\nChange-Id: I99f05996711b3851811940ad5741e96d5ae61ed6\n'}]",0,45137,8282ab4ddbda95b16a84cf974d520c74cb132bf5,13,4,3,4571,,,0,"Fix H233 in sphinx config

This is being flagged in local flake8 runs.

Change-Id: I99f05996711b3851811940ad5741e96d5ae61ed6
",git fetch https://review.opendev.org/openstack/heat refs/changes/37/45137/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,994eb03c8bfd73ac212e1351ff5f3d5281610157,bug/1217617," print(""SEARCHING %s"" % sourcedir) #print(result) print(""Excluded module %s."" % module) print(""Module %s updated, generating new documentation."" % module) print(""Removing outdated file for %s"" % old_file)"," print ""SEARCHING %s"" % sourcedir #print result print ""Excluded module %s."" % module print ""Module %s updated, generating new documentation."" \ % module print ""Removing outdated file for %s"" % old_file",6,6
openstack%2Fheat~master~I834c4755abf33793a9484138f9dac97d7d8194da,openstack/heat,master,I834c4755abf33793a9484138f9dac97d7d8194da,Fix TemplateResource list property conversion,MERGED,2013-09-05 04:19:51.000000000,2013-09-06 03:04:25.000000000,2013-09-06 03:04:24.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 7256}]","[{'number': 1, 'created': '2013-09-05 04:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/234c664cf36e4fc5beb34f2379f9600fa1124d38', 'message': 'Fix TemplateResource list property conversion\n\nIn the convertion from ""a,b,c"" to [\'a\', \'b\', \'c\'] we are\nnot checking for the case of an empty list.\n\nChange-Id: I834c4755abf33793a9484138f9dac97d7d8194da\nCloses-bug: #1221009\n'}, {'number': 2, 'created': '2013-09-05 07:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c2e31b289aa67d4b27dcd3827c664404f0c7220c', 'message': 'Fix TemplateResource list property conversion\n\nIn the convertion from ""a,b,c"" to [\'a\', \'b\', \'c\'] we are\nnot checking for the case of an empty list.\n\nChange-Id: I834c4755abf33793a9484138f9dac97d7d8194da\nCloses-bug: #1221009\n'}, {'number': 3, 'created': '2013-09-05 10:13:56.000000000', 'files': ['heat/tests/test_provider_template.py', 'heat/engine/resources/template_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/46dcceb8986b7e93a4a4bd4370b317d522c7d516', 'message': 'Fix TemplateResource list property conversion\n\nIn the convertion from ""a,b,c"" to [\'a\', \'b\', \'c\'] we are\nnot checking for the case of an empty list.\n\nChange-Id: I834c4755abf33793a9484138f9dac97d7d8194da\nCloses-bug: #1221009\n'}]",0,45167,46dcceb8986b7e93a4a4bd4370b317d522c7d516,19,5,3,4715,,,0,"Fix TemplateResource list property conversion

In the convertion from ""a,b,c"" to ['a', 'b', 'c'] we are
not checking for the case of an empty list.

Change-Id: I834c4755abf33793a9484138f9dac97d7d8194da
Closes-bug: #1221009
",git fetch https://review.opendev.org/openstack/heat refs/changes/67/45167/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_provider_template.py', 'heat/engine/resources/template_resource.py']",2,234c664cf36e4fc5beb34f2379f9600fa1124d38,bug/1215797," if len(val) == 0: val = '' elif isinstance(val[0], dict):"," if isinstance(val[0], dict):",6,1
openstack%2Fcinder~master~I9b060c1e1129b3fe30145227712d0234e0f42504,openstack/cinder,master,I9b060c1e1129b3fe30145227712d0234e0f42504,Fix brick remotefs dependency on cinder,MERGED,2013-09-05 17:03:27.000000000,2013-09-06 03:04:09.000000000,2013-09-06 03:04:09.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 6043}]","[{'number': 1, 'created': '2013-09-05 17:03:27.000000000', 'files': ['cinder/exception.py', 'cinder/brick/exception.py', 'cinder/brick/remotefs/remotefs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/12f3d782e6eebc35d9bbde2624ca0d5f10927f27', 'message': 'Fix brick remotefs dependency on cinder\n\nThis patch moves an exception from cinder.exception\ninto brick.exception to fix an import in remotefs.\n\nFixes Bug #1221309\n\nChange-Id: I9b060c1e1129b3fe30145227712d0234e0f42504\n'}]",0,45279,12f3d782e6eebc35d9bbde2624ca0d5f10927f27,8,5,1,5997,,,0,"Fix brick remotefs dependency on cinder

This patch moves an exception from cinder.exception
into brick.exception to fix an import in remotefs.

Fixes Bug #1221309

Change-Id: I9b060c1e1129b3fe30145227712d0234e0f42504
",git fetch https://review.opendev.org/openstack/cinder refs/changes/79/45279/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/exception.py', 'cinder/brick/exception.py', 'cinder/brick/remotefs/remotefs.py']",3,12f3d782e6eebc35d9bbde2624ca0d5f10927f27,bug/1221309,from cinder.brick import exception,from cinder import exception,5,5
openstack%2Ftaskflow~master~I3a8b96179f336d1defe269728ebae0caa3d832d7,openstack/taskflow,master,I3a8b96179f336d1defe269728ebae0caa3d832d7,"Engine, task, linear_flow unification",MERGED,2013-09-04 23:22:54.000000000,2013-09-06 03:02:51.000000000,2013-09-06 03:02:51.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 7366}]","[{'number': 1, 'created': '2013-09-04 23:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f4973e12ae2ae3cba7395f7c0d8b68156ec3fa4d', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 2, 'created': '2013-09-05 01:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f9c982b6abab83ed9cb839c7a9fd44d1e50bb90e', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 3, 'created': '2013-09-05 01:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2bb95df7c8345535d1c59c17698bd86931ad4bba', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 4, 'created': '2013-09-05 01:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b7e19a5b1fa35f224c75f015bb2a3c96353154ec', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 5, 'created': '2013-09-05 03:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dfb2f45b31e5fd7805034bcb4b7279ecfef5ee47', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 6, 'created': '2013-09-05 03:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7e3536f9abb93714d1b8c00c43ca924f4fee1051', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 7, 'created': '2013-09-05 03:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/20c1e8f55e034682e575dacdec07d2410cbb21f9', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 8, 'created': '2013-09-05 03:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0676fbd7a53c634bf0a42ad05186e7545ecac536', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 9, 'created': '2013-09-05 03:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e7807fcc19ec59baaebb1df8197131404c67276f', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 10, 'created': '2013-09-05 04:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d31c26996cd875b86e2a5c76491956253b693935', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 11, 'created': '2013-09-05 04:29:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f02c7f6ea9b730eac6266627fb588352d4d340dc', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 12, 'created': '2013-09-05 04:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/154387c38665ca1dc37bd06d0946533e5cf344b3', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 13, 'created': '2013-09-05 04:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/05d95470a2323c904cf2d651cc3b13d93e52642e', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 14, 'created': '2013-09-05 04:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a013af776d5c826818428ee5548a7ce15254d575', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 15, 'created': '2013-09-05 04:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/589781b5586f0c66d31ac10f68159565493ee87b', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 16, 'created': '2013-09-05 04:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f9e8a64e6cfc722667974750fc5e9174f497f81d', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 17, 'created': '2013-09-05 05:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/018fb146e3ed8cf04668888d49361433ab532b92', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 18, 'created': '2013-09-05 05:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1b019bcceaa832d7b4c5702d6bbbd41d5d88fdb5', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 19, 'created': '2013-09-05 10:24:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/410eb388a2ac8356e5340f8cbe4f7196d1034cfa', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nThreaded flow and graph flow are broken by this commit, so we\ntemporarily disable their tests.\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 20, 'created': '2013-09-05 11:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f5b0bcd6ac598e066209021d36203cde0705e284', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nThreaded flow and graph flow are broken by this commit, so we\ntemporarily disable their tests.\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 21, 'created': '2013-09-05 12:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/901f29bb662dee75fe054f136800c44948c2ca08', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nThreaded flow and graph flow are broken by this commit, so we\ntemporarily disable their tests.\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 22, 'created': '2013-09-05 12:21:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0d169477aede6365976fef491121476682606c1d', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nThreaded flow and graph flow are broken by this commit, so we\ntemporarily disable their tests.\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 23, 'created': '2013-09-05 13:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0d4a03e2d7fd103df89e147b48598fd72624c604', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nThreaded flow and graph flow are broken by this commit, so we\ntemporarily disable their tests.\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 24, 'created': '2013-09-05 17:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a1427af04c4b36f52cf6be84fc38bace85f10f08', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nThreaded flow and graph flow are broken by this commit, so we\ntemporarily disable their tests.\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 25, 'created': '2013-09-05 19:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/bb79446078a9d7439bd99a3479f1fafd07b8fb94', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nThreaded flow and graph flow are broken by this commit, so we\ntemporarily disable their tests.\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 26, 'created': '2013-09-05 19:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3f7d231e1aebdf39045bbbb8d5b2d8da31446fd9', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nThreaded flow and graph flow are broken by this commit, so we\ntemporarily disable their tests.\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 27, 'created': '2013-09-05 21:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d21dfcf504e0e1ce5af7cb463eb21003f6ab0352', 'message': 'Engine, task, linear_flow unification\n\nIn order to move away from the existing flows having their\nown implementation of running, start moving the existing\nflows to be  patterns that only structure tasks (and impose\nconstraints about how the group of tasks can run) in useful\nways.\n\nLet the concept of running those patterns be handled by an\nengine instead of being handled by the flow itself. This\nwill allow for varying engines to be able to run flows in\nwhichever way the engine chooses (as long as the constraints\nset up by the flow are observed).\n\nCurrently threaded flow and graph flow are broken by this\ncommit, since they have not been converted to being a\nstructure of tasks + constraints. The existing engine has\nnot yet been modified to run those structures either, work\nis underway  to remediate this.\n\nPart of: blueprint patterns-and-engines\n\nFollowup bugs that must be addressed:\n  Bug: 1221448\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}, {'number': 28, 'created': '2013-09-06 02:26:51.000000000', 'files': ['taskflow/tests/unit/test_linear_flow.py', 'taskflow/blocks/patterns.py', 'taskflow/examples/simple_linear_listening.out.txt', 'taskflow/examples/complex_graph.py', 'taskflow/utils/reflection.py', 'taskflow/blocks/__init__.py', 'taskflow/examples/simple_linear_listening.py', 'taskflow/flow.py', 'taskflow/storage.py', 'taskflow/tests/utils.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/examples/reverting_linear.py', 'taskflow/examples/calculate_in_parallel.py', 'taskflow/blocks/base.py', 'taskflow/blocks/task.py', 'taskflow/tests/unit/test_task.py', 'taskflow/examples/fake_boot_vm.py', 'taskflow/engines/action_engine/seq_action.py', 'taskflow/engines/action_engine/parallel_action.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/utils/flow_utils.py', 'taskflow/tests/unit/test_threaded_flow.py', 'taskflow/examples/calculate_linear.py', 'taskflow/patterns/graph_flow.py', 'taskflow/patterns/threaded_flow.py', 'taskflow/tests/unit/test_decorators.py', 'taskflow/patterns/linear_flow.py', 'taskflow/tests/unit/test_graph_flow.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/examples/simple_linear.py', 'taskflow/task.py', 'taskflow/patterns/unordered_flow.py', 'taskflow/engines/action_engine/base_action.py', 'taskflow/tests/unit/test_functor_task.py', 'taskflow/tests/unit/test_utils.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/23dfff410587d0f137bc59e10d953396802455d7', 'message': 'Engine, task, linear_flow unification\n\nIn order to move away from the existing flows having their\nown implementation of running, start moving the existing\nflows to be  patterns that only structure tasks (and impose\nconstraints about how the group of tasks can run) in useful\nways.\n\nLet the concept of running those patterns be handled by an\nengine instead of being handled by the flow itself. This\nwill allow for varying engines to be able to run flows in\nwhichever way the engine chooses (as long as the constraints\nset up by the flow are observed).\n\nCurrently threaded flow and graph flow are broken by this\ncommit, since they have not been converted to being a\nstructure of tasks + constraints. The existing engine has\nnot yet been modified to run those structures either, work\nis underway  to remediate this.\n\nPart of: blueprint patterns-and-engines\n\nFollowup bugs that must be addressed:\n  Bug: 1221448\n  Bug: 1221505\n\nChange-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7\n'}]",11,45139,23dfff410587d0f137bc59e10d953396802455d7,64,4,28,1297,,,0,"Engine, task, linear_flow unification

In order to move away from the existing flows having their
own implementation of running, start moving the existing
flows to be  patterns that only structure tasks (and impose
constraints about how the group of tasks can run) in useful
ways.

Let the concept of running those patterns be handled by an
engine instead of being handled by the flow itself. This
will allow for varying engines to be able to run flows in
whichever way the engine chooses (as long as the constraints
set up by the flow are observed).

Currently threaded flow and graph flow are broken by this
commit, since they have not been converted to being a
structure of tasks + constraints. The existing engine has
not yet been modified to run those structures either, work
is underway  to remediate this.

Part of: blueprint patterns-and-engines

Followup bugs that must be addressed:
  Bug: 1221448
  Bug: 1221505

Change-Id: I3a8b96179f336d1defe269728ebae0caa3d832d7
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/39/45139/25 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/tests/unit/test_linear_flow.py', 'taskflow/blocks/patterns.py', 'taskflow/utils/flow_utils.py', 'taskflow/blocks/__init__.py', 'taskflow/flow.py', 'taskflow/patterns/linear_flow.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/task.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/blocks/base.py', 'taskflow/blocks/task.py', 'taskflow/utils/misc.py']",12,f4973e12ae2ae3cba7395f7c0d8b68156ec3fa4d,bug/1221448,"class TransitionNotifier(object): """"""A utility helper class that can be used to subscribe to notifications of events occuring as well as allow a entity to post said notifications to subscribers. """""" RESERVED_KEYS = ('details',) ANY = '*' def __init__(self): self._listeners = collections.defaultdict(list) def reset(self): self._listeners = collections.defaultdict(list) def notify(self, state, details): listeners = list(self._listeners.get(self.ANY, [])) for i in self._listeners[state]: if i not in listeners: listeners.append(i) if not listeners: return for (callback, args, kwargs) in listeners: if args is None: args = [] if kwargs is None: kwargs = {} kwargs['details'] = details try: callback(state, *args, **kwargs) except Exception: LOG.exception((""Failure calling callback %s to notify about"" "" state transition %s""), callback, state) def register(self, state, callback, args=None, kwargs=None): assert isinstance(callback, collections.Callable) for i, (cb, args, kwargs) in enumerate(self._listeners.get(state, [])): if cb is callback: raise ValueError(""Callback %s already registered"" % (callback)) if kwargs: for k in self.RESERVED_KEYS: if k in kwargs: raise KeyError((""Reserved key '%s' not allowed in "" ""kwargs"") % k) kwargs = copy.copy(kwargs) if args: args = copy.copy(args) self._listeners[state].append((callback, args, kwargs)) def deregister(self, state, callback): if state not in self._listeners: return for i, (cb, args, kwargs) in enumerate(self._listeners[state]): if cb is callback: self._listeners[state].pop(i) break ",,212,956
openstack%2Ftaskflow~master~Iea9feb915001f48a11cd9e86e2ac370f2726a219,openstack/taskflow,master,Iea9feb915001f48a11cd9e86e2ac370f2726a219,Warn when multiple provider mappings are being created,ABANDONED,2013-09-05 20:10:38.000000000,2013-09-06 02:58:35.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2013-09-05 20:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/bb1f3fc2f27fa1e75ef115c902ec584c5d232c94', 'message': 'Warn when multiple provider mappings are being created\n\nChange-Id: Iea9feb915001f48a11cd9e86e2ac370f2726a219\n'}, {'number': 2, 'created': '2013-09-05 22:33:32.000000000', 'files': ['taskflow/storage.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/898f2bfa607646d17b0f689de7f61cb9f5d89ac6', 'message': 'Warn when multiple provider mappings are being created\n\nChange-Id: Iea9feb915001f48a11cd9e86e2ac370f2726a219\n'}]",0,45315,898f2bfa607646d17b0f689de7f61cb9f5d89ac6,4,2,2,1297,,,0,"Warn when multiple provider mappings are being created

Change-Id: Iea9feb915001f48a11cd9e86e2ac370f2726a219
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/15/45315/2 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/storage.py'],1,bb1f3fc2f27fa1e75ef115c902ec584c5d232c94,,"import logging LOG = logging.getLogger(__name__) if len(entries) > 1: LOG.warn(""Multiple provider mappings being created for %r"", name) if len(entries) > 1: LOG.warn(""Multiple provider mappings being created for %r"", name)",,10,0
openstack%2Fkeystone~master~I95b874584f2e4e9dff2cce182e454e2b72e2992e,openstack/keystone,master,I95b874584f2e4e9dff2cce182e454e2b72e2992e,Install latest webtest for testing,ABANDONED,2013-09-02 12:48:43.000000000,2013-09-06 02:27:08.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2166}, {'_account_id': 5046}, {'_account_id': 6676}, {'_account_id': 7774}]","[{'number': 1, 'created': '2013-09-02 12:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b535a2c326f38e00d08e814eedbf22b1ebaac186', 'message': 'Install latest webtest for testing\n\nwhile run tox -epy27 or run_tests.sh, webtest will be installed for\ntesting. But old version of webtest may induce many failures.\nsuch as ""PATH_INFO is not a string"".\n\nIn latest webtest:\nassert type(environ[key]) in METADATA_TYPE, (\n    ""Environmental variable %s is not a string: %r (value: %r)""\n    % (key, type(environ[key]), environ[key]))\n\nIn old webtest:\nassert type(environ[key]) is str, (\n    ""Environmental variable %s is not a string: %r (value: %r)""\n    % (key, type(environ[key]), environ[key]))\n\nDesignate version for webtest in test-requirements.txt.\n\n-----------\ntest method\n-----------\ntox -epy27 -- --tests=keystone.tests.test_associate_project_endpoint_extension\ntox -epy27\n\nChange-Id: I95b874584f2e4e9dff2cce182e454e2b72e2992e\n'}, {'number': 2, 'created': '2013-09-02 22:27:50.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2c1e9ff7cec0784aa2356c7eb2f782a8e7f00a75', 'message': 'Install latest webtest for testing\n\nwhile run tox -epy27 or run_tests.sh, webtest will be installed for\ntesting. But old version of webtest may induce many failures.\nsuch as ""PATH_INFO is not a string"".\n\nIn latest webtest(2.0.7):\nassert type(environ[key]) in METADATA_TYPE, (\n    ""Environmental variable %s is not a string: %r (value: %r)""\n    % (key, type(environ[key]), environ[key]))\n\nIn old webtest(1.3.3):\nassert type(environ[key]) is str, (\n    ""Environmental variable %s is not a string: %r (value: %r)""\n    % (key, type(environ[key]), environ[key]))\n\nDesignate version for webtest in test-requirements.txt.\n\n-----------\ntest method\n-----------\ntox -epy27 -- --tests=keystone.tests.test_associate_project_endpoint_extension\ntox -epy27\n\nPartial-Bug #1219808\nChange-Id: I95b874584f2e4e9dff2cce182e454e2b72e2992e\n'}]",0,44697,2c1e9ff7cec0784aa2356c7eb2f782a8e7f00a75,10,6,2,7774,,,0,"Install latest webtest for testing

while run tox -epy27 or run_tests.sh, webtest will be installed for
testing. But old version of webtest may induce many failures.
such as ""PATH_INFO is not a string"".

In latest webtest(2.0.7):
assert type(environ[key]) in METADATA_TYPE, (
    ""Environmental variable %s is not a string: %r (value: %r)""
    % (key, type(environ[key]), environ[key]))

In old webtest(1.3.3):
assert type(environ[key]) is str, (
    ""Environmental variable %s is not a string: %r (value: %r)""
    % (key, type(environ[key]), environ[key]))

Designate version for webtest in test-requirements.txt.

-----------
test method
-----------
tox -epy27 -- --tests=keystone.tests.test_associate_project_endpoint_extension
tox -epy27

Partial-Bug #1219808
Change-Id: I95b874584f2e4e9dff2cce182e454e2b72e2992e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/97/44697/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,b535a2c326f38e00d08e814eedbf22b1ebaac186,bug/1219808,webtest>=2.0.7,webtest,1,1
openstack%2Fkeystone~master~I3915b3d6ecf41f6a5773da8f5ca99aeeb0f33845,openstack/keystone,master,I3915b3d6ecf41f6a5773da8f5ca99aeeb0f33845,Fix some errors of format string missing object type,ABANDONED,2013-09-05 10:25:45.000000000,2013-09-06 01:48:14.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-09-05 10:25:45.000000000', 'files': ['keystone/openstack/common/log.py', 'keystone/tests/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2fbc242cc2fbe8c5c5ed1245cfcf5d77d6b1a641', 'message': ""Fix some errors of format string missing object type\n\nSome format strings miss the object type like below:\n\n if CONF.logging_exception_prefix.find('%(asctime)') != -1:\n\nThe correct code should be .find('%(asctime)s').\nThis patch fixes this kind of errors in keystone.\n\nFixes Bug #1221130\n\nChange-Id: I3915b3d6ecf41f6a5773da8f5ca99aeeb0f33845\n""}]",0,45209,2fbc242cc2fbe8c5c5ed1245cfcf5d77d6b1a641,5,4,1,6348,,,0,"Fix some errors of format string missing object type

Some format strings miss the object type like below:

 if CONF.logging_exception_prefix.find('%(asctime)') != -1:

The correct code should be .find('%(asctime)s').
This patch fixes this kind of errors in keystone.

Fixes Bug #1221130

Change-Id: I3915b3d6ecf41f6a5773da8f5ca99aeeb0f33845
",git fetch https://review.opendev.org/openstack/keystone refs/changes/09/45209/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/openstack/common/log.py', 'keystone/tests/test_backend.py']",2,2fbc242cc2fbe8c5c5ed1245cfcf5d77d6b1a641,bug/1221130," ""http://%(foo)s"","," ""http://%(foo)"",",2,2
openstack%2Fneutron~master~I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a,openstack/neutron,master,I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a,vArmour gateway agent and FWaaS driver,MERGED,2013-08-21 02:58:44.000000000,2013-09-06 00:44:27.000000000,2013-09-06 00:34:03.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 2031}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 6522}, {'_account_id': 7576}]","[{'number': 1, 'created': '2013-08-21 02:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/86566b1ea7345115636687a2fd701c86ca4667c5', 'message': 'vArmour FWaaS driver\n\nThe first code review for vArmour firewall implementation based on FWaaS framework. The implementation contains driver implementation and L3 agent replacement to enable vArmour firewall and a NAT gateway\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n'}, {'number': 2, 'created': '2013-08-22 18:54:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/97c40940bff99b451d46d1713918f59cfb2d1e08', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 3, 'created': '2013-08-27 23:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/59a544b37f296718ea1a5e3a6e2a5678401d1e11', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 4, 'created': '2013-08-28 01:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/628587a76f80eb12286319af9df3afb26abc60c3', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 5, 'created': '2013-08-29 22:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/636f9554680ab445438ec6a6f92162eae74a0600', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 6, 'created': '2013-08-30 18:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/084e404d7c5cdc037dab8a06916244edd7232dfc', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 7, 'created': '2013-09-01 00:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3e54f1445ddaf1ef0ef1974c4742775c247583a', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 8, 'created': '2013-09-02 07:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b33819dc820e910f4c1f1c657f8368ba146b9771', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 9, 'created': '2013-09-02 09:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ccb98175ac002ca6763a5f7a6f5d1743d7a4bc2', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 10, 'created': '2013-09-03 16:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/16fdac0f92bc65e90dc0458ac02c34ecbd1a3763', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 11, 'created': '2013-09-03 22:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a830afa54db51d5c4a518de88cccf4fe8079814e', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 12, 'created': '2013-09-04 03:17:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0526b58fecfc3dd4c482bd221cfea2c4c3d2b4e1', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 13, 'created': '2013-09-04 05:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3570cf99aa2f8a520c7f8b5a5724e17b48cc7034', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 14, 'created': '2013-09-04 06:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f24277e4f618192e2b368abc718505be71d8fdc', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}, {'number': 15, 'created': '2013-09-05 04:03:21.000000000', 'files': ['neutron/services/firewall/drivers/varmour/__init__.py', 'neutron/services/firewall/agents/varmour/varmour_router.py', 'neutron/services/firewall/agents/varmour/varmour_utils.py', 'neutron/tests/unit/services/firewall/agents/varmour/__init__.py', 'neutron/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron/services/firewall/agents/varmour/__init__.py', 'neutron/services/firewall/agents/varmour/varmour_api.py', 'neutron/services/firewall/drivers/varmour/varmour_fwaas.py', 'neutron/tests/unit/services/firewall/drivers/varmour/__init__.py', 'neutron/tests/unit/services/firewall/agents/varmour/test_varmour_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d6f28ffc9b36d272d23e0d089d2bbfc6193aa30a', 'message': ""vArmour gateway agent and FWaaS driver\n\nThis patch enables vArmour's routing and firewall services to be deployed in\nopenstack environment.\n- as gateway for internal networks\n- support SNAT and DNAT (floating IP)\n- FWaaS services\n\nImplements: blueprint varmour-fwaas-driver\nChange-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a\n""}]",153,43034,d6f28ffc9b36d272d23e0d089d2bbfc6193aa30a,108,10,15,7576,,,0,"vArmour gateway agent and FWaaS driver

This patch enables vArmour's routing and firewall services to be deployed in
openstack environment.
- as gateway for internal networks
- support SNAT and DNAT (floating IP)
- FWaaS services

Implements: blueprint varmour-fwaas-driver
Change-Id: I6ddfa3137ed7e2a3fcf16a764d1340a8eae9359a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/34/43034/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/firewall/drivers/varmour/__init__.py', 'neutron/plugins/varmour/varmour_rest.py', '.gitreview', 'neutron/plugins/varmour/varmour_router.py', 'neutron/plugins/varmour/__init__.py', 'neutron/plugins/varmour/varmour_utils.py', 'neutron/services/firewall/drivers/varmour/varmour_fwaas.py']",7,86566b1ea7345115636687a2fd701c86ca4667c5,bp/varmour-fwaas-driver,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Copyright 2013 # Copyright 2013 vArmour Networks Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Gary Duan, gduan@varmour.com, vArmour Networks import httplib import re import json from neutron.openstack.common import log as logging from neutron.services.firewall.drivers import fwaas_base from neutron.plugins.varmour import varmour_rest from neutron.plugins.varmour import varmour_utils LOG = logging.getLogger(__name__) REST_URL_CONF = '/config' class vArmourFwaasDriver(fwaas_base.FwaasDriverBase): def __init__(self): LOG.debug(_(""Initializing fwaas vArmour driver"")) self.rest = varmour_rest.vArmourRestAPI() self.rmap = dict() def create_firewall(self, apply_list, firewall): LOG.debug(_('Creating firewall for tenant (%s)'), firewall['tenant_id']) return self.update_firewall(apply_list, firewall); def update_firewall(self, apply_list, firewall): LOG.debug(_(""Updating firewall for tenant (%s)""), firewall['tenant_id']) if firewall['admin_state_up']: return self._update_firewall(apply_list, firewall) else: return self.apply_default_policy(apply_list, firewall) def delete_firewall(self, apply_list, firewall): LOG.debug(_(""Deleting firewall for tenant (%s)""), firewall['tenant_id']) self.apply_default_policy(apply_list, firewall) return True def apply_default_policy(self, apply_list, firewall): LOG.debug(_(""Applying default policy for tenant (%s)""), firewall['tenant_id']) self.rest.auth() for ri in apply_list: self._clear_policy(ri, firewall) return True def _update_firewall(self, apply_list, firewall): LOG.debug(_(""Updating firewall (%s)""), firewall['id']) self.rest.auth() for ri in apply_list: self._clear_policy(ri, firewall) self._setup_policy(ri, firewall) return True def _setup_policy(self, ri, fw): # create zones in case they don't exist. Interfaces are added by router json = dict() json['type'] = 'L3' json['interface'] = [] json['name'] = varmour_utils.get_trusted_zone_name(ri) self.rest.rest_api('POST', REST_URL_CONF + '/zone', json) json['name'] = varmour_utils.get_untrusted_zone_name(ri) self.rest.rest_api('POST', REST_URL_CONF + '/zone', json) self.rest.commit() serv_set = set() addr_set = set() for rule in fw['firewall_rule_list']: if not rule['enabled']: continue if rule['ip_version'] == 4: service = self._make_service_name(ri, fw, rule) if service and (service not in serv_set): serv_set.add(service) json = self._make_service(service) self.rest.rest_api('POST', REST_URL_CONF + '/service', json) json = self._make_service_rule(rule) self.rest.rest_api('POST', REST_URL_CONF + '/service/""name:%s""/rule' % service, json) self.rest.commit() s_addr = self._make_address_name(ri, fw, rule, True) if s_addr and (s_addr not in addr_set): addr_set.add(s_addr) json = self._make_address(s_addr, rule, True) self.rest.rest_api('POST', REST_URL_CONF + '/address', json) self.rest.commit() d_addr = self._make_address_name(ri, fw, rule, False) if d_addr and (d_addr not in addr_set): addr_set.add(d_addr) json = self._make_address(d_addr, rule, True) self.rest.rest_api('POST', REST_URL_CONF + '/address', json) self.rest.commit() policy = self._make_policy_name(ri, fw, rule) z0 = varmour_utils.get_trusted_zone_name(ri) z1 = varmour_utils.get_untrusted_zone_name(ri) json = self._make_policy(policy + '_0', rule, z0, z0, s_addr, d_addr, service) self.rest.rest_api('POST', REST_URL_CONF + '/policy', json) json = self._make_policy(policy + '_1', rule, z0, z1, s_addr, d_addr, service) self.rest.rest_api('POST', REST_URL_CONF + '/policy', json) json = self._make_policy(policy + '_2', rule, z1, z0, s_addr, d_addr, service) self.rest.rest_api('POST', REST_URL_CONF + '/policy', json) self.rest.commit() def _clear_policy(self, ri, fw): prefix = varmour_utils.get_firewall_object_prefix(ri, fw) self.rest.delete_config_objects(REST_URL_CONF + '/policy', prefix) self.rest.delete_config_objects(REST_URL_CONF + '/address', prefix) self.rest.delete_config_objects(REST_URL_CONF + '/service', prefix) '''service''' def _make_service_name(self, ri, fw, rule): '''fw_valid_protocol_values = [None, constants.TCP, constants.UDP, constants.ICMP] ''' name = varmour_utils.get_firewall_object_prefix(ri, fw) if rule.get('protocol'): name += '-' + rule.get('protocol') if rule.get('source_port'): name += '-' + rule.get('source_port') if rule.get('destination_port'): name += '-' + rule.get('destination_port') else: return None return name def _make_service(self, name): json = dict() json['name'] = name return json def _make_service_rule(self, rule): json = dict() json['name'] = '1' json['protocol'] = rule.get('protocol') if rule.get('source_port'): json['source-start'] = rule.get('source_port') json['source-end'] = rule.get('source_port') if rule.get('destination_port'): json['dest-start'] = rule.get('destination_port') json['dest-end'] = rule.get('destination_port') return json '''address''' def _make_address_name(self, ri, fw, rule, is_src): name = varmour_utils.get_firewall_object_prefix(ri, fw) if is_src: if rule.get('source_ip_address'): name += '-' + re.sub('[./]', '_', rule.get('source_ip_address')) else: return None else: if rule.get('destination_ip_address'): name += '-' + re.sub('[./]', '_', rule.get('destination_ip_address')) else: return None return name def _make_address(self, name, rule, is_src): json = dict() json['name'] = name json['type'] = 'ipv4' if is_src: if rule.get('source_ip_address'): json['ipv4'] = rule.get('source_ip_address') else: if rule.get('destination_port'): json['ipv4'] = rule.get('destination_ip_address') return json '''policy''' def _make_policy_name(self, ri, fw, rule): name = varmour_utils.get_firewall_object_prefix(ri, fw) return name + '-' + rule.get('name') def _make_policy(self, name, rule, zone0, zone1, s_addr, d_addr, service): json = dict() json['name'] = name if rule.get('action') == 'allow': json['action'] = 'permit' else: json['action'] = 'deny' json['from'] = zone0 json['to'] = zone1 json['match-source-address'] = [] if s_addr: json['match-source-address'].append(s_addr) else: json['match-source-address'].append('Any') json['match-dest-address'] = [] if d_addr: json['match-dest-address'].append(d_addr) else: json['match-dest-address'].append('Any') json['match-service'] = [] if service: json['match-service'].append(service) else: json['match-service'].append('Any') return json ",,771,4
openstack%2Fcinder~master~Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977,openstack/cinder,master,Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977,Added copy-on-write support for all RBD cloning,MERGED,2013-08-12 16:51:29.000000000,2013-09-06 00:34:01.000000000,2013-09-06 00:34:00.000000000,"[{'_account_id': 3}, {'_account_id': 1107}, {'_account_id': 1207}, {'_account_id': 2166}, {'_account_id': 6094}, {'_account_id': 6737}, {'_account_id': 6743}, {'_account_id': 6939}, {'_account_id': 6984}, {'_account_id': 7593}]","[{'number': 1, 'created': '2013-08-12 16:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c248fd83e5bfdf0754f3111b9e278b139423484a', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till no we had copy-on-write for volume snapshots only.\nThis change allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}, {'number': 2, 'created': '2013-08-13 23:16:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/77d8fbe75f090bbc11417cc1f93dc0ec42586cd7', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till now we had copy-on-write for volume snapshots only.\nThis change allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}, {'number': 3, 'created': '2013-08-14 17:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e25fd2723af7a6229d52658318d59177e59c3c8', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till now we had copy-on-write for volume snapshots only.\nThis change allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}, {'number': 4, 'created': '2013-08-15 17:49:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e26565c375baaf3c3d253b3e21773d01ae11e06b', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till now we had copy-on-write for volume snapshots only.\nThis change allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}, {'number': 5, 'created': '2013-08-15 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/10657bb1f33b2d2e44ffae058cdbe245b5388195', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till now we had copy-on-write for volume snapshots only.\nThis change allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}, {'number': 6, 'created': '2013-08-16 14:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bb4e0c313255a4c911e9b83a99140b3ed3e0fdd6', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till now we only had copy-on-write for cloning from snapshot. This\nchange optionally allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time. This should increase speed\nand reduce nearterm storage consumtion but could introduce some new\nrisks e.g. excessively long clone chains and flatten storms. To avoid\nthis, a new config option has been providedons are provided -\nrbd_max_clone_depth - which allows the user to limit the depth of a\nchain of clones i.e.\n\n    a->b->c->d as opposed to a->b\n                              ->c\n                              ->d\n\nThis will avoid flatten storms by breaking chains as they are formed\nand at an early, predefined stage.\n\nA second option - rbd_clone_from_volume_force_copy - allows the user\nto use a full copy as before i.e. disable COW for volume clones.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}, {'number': 7, 'created': '2013-08-16 14:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/aafd738069d34d9e589f273a0f8a67ebe934052e', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till now we only had copy-on-write for cloning from snapshot. This\nchange optionally allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time. This should increase speed\nand reduce nearterm storage consumtion but could introduce some new\nrisks e.g. excessively long clone chains and flatten storms. To avoid\nthis, a new config option has been providedons are provided -\nrbd_max_clone_depth - which allows the user to limit the depth of a\nchain of clones i.e.\n\n    a->b->c->d as opposed to a->b\n                              ->c\n                              ->d\n\nThis will avoid flatten storms by breaking chains as they are formed\nand at an early, predefined stage.\n\nA second option - rbd_clone_from_volume_force_copy - allows the user\nto use a full copy as before i.e. disable COW for volume clones.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}, {'number': 8, 'created': '2013-08-16 20:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/836d502802d42e2efcfdb8eaea8ca28d1d211a2c', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till now we only had copy-on-write for cloning from snapshot. This\nchange optionally allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time. This should increase speed\nand reduce nearterm storage consumtion but could introduce some new\nrisks e.g. excessively long clone chains and flatten storms. To avoid\nthis, a new config option has been providedons are provided -\nrbd_max_clone_depth - which allows the user to limit the depth of a\nchain of clones i.e.\n\n    a->b->c->d as opposed to a->b\n                              ->c\n                              ->d\n\nThis will avoid flatten storms by breaking chains as they are formed\nand at an early, predefined stage.\n\nA second option - rbd_clone_from_volume_force_copy - allows the user\nto use a full copy as before i.e. disable COW for volume clones.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}, {'number': 9, 'created': '2013-08-18 21:35:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/78b69f663760e2753e1ef63a8f981f5f40551ae3', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till now we only had copy-on-write for cloning from snapshot. This\nchange optionally allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time. This should increase speed\nand reduce nearterm storage consumtion but could introduce some new\nrisks e.g. excessively long clone chains and flatten storms. To avoid\nthis, a new config option has been providedons are provided -\nrbd_max_clone_depth - which allows the user to limit the depth of a\nchain of clones i.e.\n\n    a->b->c->d as opposed to a->b\n                              ->c\n                              ->d\n\nThis will avoid flatten storms by breaking chains as they are formed\nand at an early, predefined stage.\n\nA second option - rbd_clone_from_volume_force_copy - allows the user\nto use a full copy as before i.e. disable COW for volume clones.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}, {'number': 10, 'created': '2013-09-05 10:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/22fc2d1f5e6c591e6ba15c79863e8669eeecaca2', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till now we only had copy-on-write for cloning from snapshot. This\nchange optionally allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time. This should increase speed\nand reduce nearterm storage consumtion but could introduce some new\nrisks e.g. excessively long clone chains and flatten storms. To avoid\nthis, a new config option has been providedons are provided -\nrbd_max_clone_depth - which allows the user to limit the depth of a\nchain of clones i.e.\n\n    a->b->c->d as opposed to a->b\n                              ->c\n                              ->d\n\nThis will avoid flatten storms by breaking chains as they are formed\nand at an early, predefined stage.\n\nA second option - rbd_clone_from_volume_force_copy - allows the user\nto use a full copy as before i.e. disable COW for volume clones.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}, {'number': 11, 'created': '2013-09-05 12:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e15b2e5aac9b4e1cb1182a4ba98093b11d065daf', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till now we only had copy-on-write for cloning from snapshot. This\nchange optionally allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time. This should increase speed\nand reduce nearterm storage consumtion but could introduce some new\nrisks e.g. excessively long clone chains and flatten storms. To avoid\nthis, a new config option has been providedons are provided -\nrbd_max_clone_depth - which allows the user to limit the depth of a\nchain of clones i.e.\n\n    a->b->c->d as opposed to a->b\n                              ->c\n                              ->d\n\nThis will avoid flatten storms by breaking chains as they are formed\nand at an early, predefined stage.\n\nA second option - rbd_clone_from_volume_force_copy - allows the user\nto use a full copy as before i.e. disable COW for volume clones.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}, {'number': 12, 'created': '2013-09-05 13:26:11.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'etc/cinder/cinder.conf.sample', 'cinder/tests/backup/fake_rados.py', 'cinder/tests/test_rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/52291d6554f2275b228d7039d222bccfab164106', 'message': 'Added copy-on-write support for all RBD cloning\n\nUp till now we only had copy-on-write for cloning from snapshot. This\nchange optionally allows clone from volume to use copy-on-write\ninstead of a doing a full copy each time. This should increase speed\nand reduce nearterm storage consumtion but could introduce some new\nrisks e.g. excessively long clone chains and flatten storms. To avoid\nthis, a new config option has been providedons are provided -\nrbd_max_clone_depth - which allows the user to limit the depth of a\nchain of clones i.e.\n\n    a->b->c->d as opposed to a->b\n                              ->c\n                              ->d\n\nThis will avoid flatten storms by breaking chains as they are formed\nand at an early, predefined stage.\n\nA second option - rbd_clone_from_volume_force_copy - allows the user\nto use a full copy as before i.e. disable COW for volume clones.\n\nImplements: blueprint use-copy-on-write-for-all-volume-cloning\nFixes: bug #1209199\n\nChange-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977\n'}]",52,41469,52291d6554f2275b228d7039d222bccfab164106,57,10,12,6737,,,0,"Added copy-on-write support for all RBD cloning

Up till now we only had copy-on-write for cloning from snapshot. This
change optionally allows clone from volume to use copy-on-write
instead of a doing a full copy each time. This should increase speed
and reduce nearterm storage consumtion but could introduce some new
risks e.g. excessively long clone chains and flatten storms. To avoid
this, a new config option has been providedons are provided -
rbd_max_clone_depth - which allows the user to limit the depth of a
chain of clones i.e.

    a->b->c->d as opposed to a->b
                              ->c
                              ->d

This will avoid flatten storms by breaking chains as they are formed
and at an early, predefined stage.

A second option - rbd_clone_from_volume_force_copy - allows the user
to use a full copy as before i.e. disable COW for volume clones.

Implements: blueprint use-copy-on-write-for-all-volume-cloning
Fixes: bug #1209199

Change-Id: Ia4a8a10c797cda2cf1ef3a2e9bd49f8c084ec977
",git fetch https://review.opendev.org/openstack/cinder refs/changes/69/41469/7 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/rbd.py'],1,c248fd83e5bfdf0754f3111b9e278b139423484a,bug/1209199,"import pickleCLONE_MAP_NAME = ""cinder.rbd.clone.map"" def _map_contains_clone(self, client, clone): obj = rados.Object(client.ioctx, CLONE_MAP_NAME) map = obj.read() if map is None or (map == """"): return False _map = pickle.loads(map) _map.get(clone, False) return def _get_clone_parent(self, client, clone): obj = rados.Object(client.ioctx, CLONE_MAP_NAME) map = obj.read() LOG.debug(""%s"" % (str(map))) if map is None or (map == """"): return None return (clone in map) def _del_clone_from_map(self, client, parent, clone): obj = rados.Object(client.ioctx, CLONE_MAP_NAME) map = obj.read() if map is None or (map == """"): raise Exception(""clone map is empty"") _map = pickle.loads(map) _map.pop(clone) map = pickle.dumps(_map) obj.write(map) LOG.debug(""clone '%s' of parent '%s' removed from map"") def _add_clone_to_map(self, client, parent, clone): obj = rados.Object(client.ioctx, CLONE_MAP_NAME) map = obj.read() if map is None or (map == """"): map = pickle.dumps({parent: clone}) else: _map = pickle.loads(map) _map[clone] = parent map = pickle.dumps(_map) obj.write(map) LOG.debug(""clone '%s' of parent '%s' added to map"") src_name = str(src_vref['name']) dest_name = str(volume['name']) clone_snap = str(""%s.clone_snap"" % (src_name)) lookup_name = str(""%s.map"" % (src_name)) snap_created = False LOG.debug(""cloning volume '%s' to '%s'"" % (src_name, dest_name)) with RADOSClient(self) as client: volume = self.rbd.Image(client.ioctx, src_name) try: snaps = volume.list_snaps() if not self._snap_exists(clone_snap, snaps): volume.create_snap(clone_snap) volume.protect_snap(clone_snap) snap_created = True except: volume.close() raise try: self.rbd.RBD().clone(client.ioctx, src_name, clone_snap, client.ioctx, dest_name, features=self.rbd.RBD_FEATURE_LAYERING) except: # Tidy up if snap was created in this operation if snap_created: volume.unprotect_snap(clone_snap) volume.remove_snap(clone_snap) # Then re-raise raise try: self._add_clone_to_map(client, src_name, dest_name) except: self.rbd.RBD().remove(dest_name) raise Exception(""FAILED TO CREATE CLONE"") # FIXME finally: volume.close() LOG.debug(""clone created successfully"") LOG.debug(""creating volume '%s'"" % (volume['name'])) def _delete_cloned_volume(self, client, volume_name): parent = self._get_clone_parent(client, volume_name) rbd_image = self.rbd.Image() clone_snap = ""%s.clone_snap"" % parent rbd_image.set_snap(clone_snap) clones = rbd_image.list_children() if not clones: rbd_image.set_snap(None) rbd_image.unprotect_snap(clone_snap) rbd_image.remove_snap(clone_snap) self.rbd.RBD().remove(parent) self._del_clone_from_map(client, parent, volume_name) def _snap_exists(self, snap_name, snap_list): if not snap_list: return False for snap in snap_list: if snap['name'] == snap_name: return True return snap_list def _delete_backup_snaps(self, client, volume_name): rbd_image = self.rbd.Image(client.ioctx, volume_name) try: backup_snaps = self._get_backup_snaps(rbd_image) if backup_snaps: for snap in backup_snaps: rbd_image.remove_snap(snap['name']) finally: rbd_image.close() volume_name = str(volume['name']) self._delete_backup_snaps(client, volume_name) # If the volume has non-clone snapshots this delete is expected to # raise VolumeIsBusy so do so straight away. rbd_image = self.rbd.Image(client.ioctx, volume_name) try: if len(rbd_image.list_snaps()) > 2: raise exception.VolumeIsBusy(volume_name=volume_name) # If it is a clone ... if self._map_contains_clone(client, volume_name): self._delete_cloned_volume(client, volume_name) return # If the volume has copy-on-write clones we will not be able to # delete it. We will keep it as a silent volume which will be # deleted when it's snapshot and clones are deleted. clone_snap = str(""%s.clone_snap"" % (volume_name)) rename_and_exit = False rbd_image = self.rbd.Image(client.ioctx, volume_name) try: snaps = rbd_image.list_snaps() if self._snap_exists(clone_snap, snaps): if rbd_image.is_protected_snap(clone_snap): rename_and_exit = True finally: rbd_image.close() if rename_and_exit: self.rbd.RBD().rename(client.ioctx, volume_name, ""%s.deleted"" % (volume_name)) return self.rbd.RBD().remove(client.ioctx, volume_name)"," with RBDVolumeProxy(self, src_vref['name'], read_only=True) as vol: vol.copy(vol.ioctx, str(volume['name'])) rbd_image = self.rbd.Image(client.ioctx, str(volume['name'])) try: backup_snaps = self._get_backup_snaps(rbd_image) if backup_snaps: for snap in backup_snaps: rbd_image.remove_snap(snap['name']) try: self.rbd.RBD().remove(client.ioctx, str(volume['name'])) except self.rbd.ImageHasSnapshots: raise exception.VolumeIsBusy(volume_name=volume['name'])",163,10
openstack%2Fnova~master~Ibf423f14a5c37aa298b2115bfd4936f660c6f530,openstack/nova,master,Ibf423f14a5c37aa298b2115bfd4936f660c6f530,Updated from global requirements,MERGED,2013-08-07 22:16:23.000000000,2013-09-06 00:33:25.000000000,2013-09-06 00:33:23.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2835}, {'_account_id': 5652}, {'_account_id': 6928}]","[{'number': 1, 'created': '2013-08-07 22:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f42f3d26368a32371cb0c1c60415101090ef08a3', 'message': 'Updated from global requirements\n\nChange-Id: Ibf423f14a5c37aa298b2115bfd4936f660c6f530\n'}, {'number': 2, 'created': '2013-08-16 17:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f7bdedba825a514ce8e4fdcf1d2308f8b117573', 'message': 'Updated from global requirements\n\nChange-Id: Ibf423f14a5c37aa298b2115bfd4936f660c6f530\n'}, {'number': 3, 'created': '2013-09-05 15:13:22.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/446967ac0c423eabfd087e42ea872f2f541aa849', 'message': 'Updated from global requirements\n\nChange-Id: Ibf423f14a5c37aa298b2115bfd4936f660c6f530\n'}]",1,40754,446967ac0c423eabfd087e42ea872f2f541aa849,22,7,3,2,,,0,"Updated from global requirements

Change-Id: Ibf423f14a5c37aa298b2115bfd4936f660c6f530
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/40754/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,f42f3d26368a32371cb0c1c60415101090ef08a3,openstack/requirements,"# THIS FILE IS MANAGED BY THE GLOBAL REQUIREMENTS REPO - DO NOT EDIT setup_requires=['pbr>=0.5.21,<1.0'], pbr=True)"," setup_requires=['d2to1>=0.2.10,<0.3', 'pbr>=0.5,<0.6'], d2to1=True)",24,25
openstack%2Fnova~master~Id4b376a92ad23db2cb5380be85d4fe937f1a5cb7,openstack/nova,master,Id4b376a92ad23db2cb5380be85d4fe937f1a5cb7,fix conversion type missing,MERGED,2013-09-05 05:51:48.000000000,2013-09-06 00:32:53.000000000,2013-09-06 00:32:51.000000000,"[{'_account_id': 3}, {'_account_id': 1812}, {'_account_id': 1849}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-09-05 05:51:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3903a69f085a060e13ef9591f71d97bb1902879c', 'message': 'fix conversion type missing\n\nConversion type is missing in some places which would cause some\nunexcepted error. By using \'grep -rn ""%([a-zA-Z_]*) ""\', we could find\nall cases of \'%(variable_a)\' and fix them.\n\nChange-Id: Id4b376a92ad23db2cb5380be85d4fe937f1a5cb7\nCloses-Bug: #1221026\n'}, {'number': 2, 'created': '2013-09-05 09:06:39.000000000', 'files': ['nova/exception.py', 'nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fcceb93bc842ee2ba61dd21205d09c66d1f08634', 'message': 'fix conversion type missing\n\nConversion type is missing in some places which would cause some\nunexcepted error. By using \'grep -rn ""%(\\w\\+)[^\\%a-z0-9\\.\\-]""\',\nwe could find all cases of \'%(variable_a)\' and fix them.\n\nChange-Id: Id4b376a92ad23db2cb5380be85d4fe937f1a5cb7\nCloses-Bug: #1221026\n'}]",0,45172,fcceb93bc842ee2ba61dd21205d09c66d1f08634,12,6,2,6835,,,0,"fix conversion type missing

Conversion type is missing in some places which would cause some
unexcepted error. By using 'grep -rn ""%(\w\+)[^\%a-z0-9\.\-]""',
we could find all cases of '%(variable_a)' and fix them.

Change-Id: Id4b376a92ad23db2cb5380be85d4fe937f1a5cb7
Closes-Bug: #1221026
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/45172/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py']",2,3903a69f085a060e13ef9591f71d97bb1902879c,bug/1221026," ""%(left)s bytes left to copy""),"," ""%(left) bytes left to copy""),",2,2
openstack%2Fnova~master~I622161eb9abe5d36b5cf9690e7c7a43cf1a0bbf2,openstack/nova,master,I622161eb9abe5d36b5cf9690e7c7a43cf1a0bbf2,Fix missing d on LOG statements,ABANDONED,2013-09-05 20:18:24.000000000,2013-09-06 00:04:38.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 4395}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-09-05 20:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/05fa0b999a91c59b70048e6a3b648aa0b0b1f442', 'message': 'Fix missing d on LOG statements\n\nChange-Id: I622161eb9abe5d36b5cf9690e7c7a43cf1a0bbf2\n'}, {'number': 2, 'created': '2013-09-05 21:29:47.000000000', 'files': ['nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/785f0d49d0cefe560fccddb2c0b6af4720cd41a6', 'message': 'Fix missing d on LOG statements\n\nFixes bug: 1221446\n\nChange-Id: I622161eb9abe5d36b5cf9690e7c7a43cf1a0bbf2\n'}]",0,45317,785f0d49d0cefe560fccddb2c0b6af4720cd41a6,10,6,2,4395,,,0,"Fix missing d on LOG statements

Fixes bug: 1221446

Change-Id: I622161eb9abe5d36b5cf9690e7c7a43cf1a0bbf2
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/45317/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py']",2,05fa0b999a91c59b70048e6a3b648aa0b0b1f442,bug/1221446," ""%(left)d bytes left to copy""),"," ""%(left) bytes left to copy""),",2,2
openstack%2Fdevstack-gate~master~Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081,openstack/devstack-gate,master,Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081,Add support for large_ops tempest test,MERGED,2013-08-26 21:05:58.000000000,2013-09-06 00:03:21.000000000,2013-09-06 00:03:21.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4146}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-08-26 21:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8a133f9cd9dd2054ae0f73af8e6ea8da7bd5b071', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 2, 'created': '2013-08-26 21:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f321fa404b491971b82ed7b87ca7895517e076ab', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 3, 'created': '2013-08-26 23:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/b4df68e4e8da712f5ea9ede7d4e820c17819e18b', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 4, 'created': '2013-08-29 18:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8af77bbafd0b551f0dce7b1c8780e9eeb9941e17', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 5, 'created': '2013-08-29 18:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/bd845c95924ebd389d7fa51d99110ea8248b05ff', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nWIP\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 6, 'created': '2013-08-29 19:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8f1b75d5d16a6b13689d976336eba6f5fd71c960', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nWIP, seeing how many VMs I can run before things fail\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 7, 'created': '2013-08-29 19:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/2c52beaf5718b1b9d744c9f7d345873abc0f404c', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nWIP, seeing how many VMs I can run before things fail\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 8, 'created': '2013-08-29 21:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/42b300e9e23532da168efe4636b41d92d2a9061a', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nWIP, seeing how many VMs I can run before things fail\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 9, 'created': '2013-08-30 15:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f9f0f6109a20d721470547146d19101a381b69fb', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nWIP, seeing how many VMs I can run before things fail\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 10, 'created': '2013-08-30 16:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/6a6240a89a73a3dcc1cadc286fa01d527ba0df8a', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nWIP, seeing how many VMs I can run before things fail\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 11, 'created': '2013-08-30 16:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/45016581e50011670d03d7e10aa0f3bb855c7a70', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nWIP, seeing how many VMs I can run before things fail\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 12, 'created': '2013-08-30 17:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/69987bf31136d7664c930770bb425f7d4b9dc3ae', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nWIP, seeing how many VMs I can run before things fail\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 13, 'created': '2013-08-30 17:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/c2610e692e64224f78c8861c16ef4971792e9d99', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nWIP, seeing how many VMs I can run before things fail\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 14, 'created': '2013-08-30 17:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/df3086e4e4dd4a6941b3b9643bd6d784d8e5227a', 'message': 'Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 45.  The number 45 is picked because its a number that used to\nnot work before this bug was fixed.\n\nWIP, seeing how many VMs I can run before things fail\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n'}, {'number': 15, 'created': '2013-08-30 18:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8c93b0177d954b96f014811a58086888286ed82f', 'message': ""Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 200.  The number 200 is picked via trial and error.  Before the\nrelated bug was fixed, one couldn't even spawn 50 instances.\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n""}, {'number': 16, 'created': '2013-08-30 19:28:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ee10ce427bb960009c5126c2eb5c494b30f1f55c', 'message': ""Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nWIP: Still finding right number, 200 just failed\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of vms to attempt to spawn at\nonce to 200.  The number 200 is picked via trial and error.  Before the\nrelated bug was fixed, one couldn't even spawn 50 instances.\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n""}, {'number': 17, 'created': '2013-08-30 21:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/df53a1e821bbf487da79c838051037b748a7c4f3', 'message': ""Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of instances to attempt to spawn at\nonce to 150.  The number 150 is picked via trial and error.  Before the\nrelated bug was fixed, one couldn't even spawn 50 instances.\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n""}, {'number': 18, 'created': '2013-09-03 17:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/9a6dace33a35cca51308722180345add42ba3670', 'message': ""Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of instances to attempt to spawn at\nonce to 150.  The number 150 is picked via trial and error.  Before the\nrelated bug was fixed, one couldn't even spawn 50 instances.\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n""}, {'number': 19, 'created': '2013-09-03 20:26:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/1baaa9ea382ce3c75c2f622f720e8b8fd6a62e20', 'message': ""Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of instances to attempt to spawn at\nonce to 150.  The number 150 is picked via trial and error.  Before the\nrelated bug was fixed, one couldn't even spawn 50 instances.\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n""}, {'number': 20, 'created': '2013-09-05 21:45:46.000000000', 'files': ['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/a3d247bcd82147a8973f8ec87eaae6fb9c648ea2', 'message': ""Add support for large_ops tempest test\n\nThis test launches a bunch of instances at once (in attempt to find any\nperformance/scale issues).  This is the regression test for bug 1199433\n\nSet TEMPEST_LARGE_OPS_NUMBER, the number of instances to attempt to spawn at\nonce to 150.  The number 150 is picked via trial and error.  Before the\nrelated bug was fixed, one couldn't even spawn 50 instances.\n\nChange-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081\n""}]",0,43779,a3d247bcd82147a8973f8ec87eaae6fb9c648ea2,92,6,20,1849,,,0,"Add support for large_ops tempest test

This test launches a bunch of instances at once (in attempt to find any
performance/scale issues).  This is the regression test for bug 1199433

Set TEMPEST_LARGE_OPS_NUMBER, the number of instances to attempt to spawn at
once to 150.  The number 150 is picked via trial and error.  Before the
related bug was fixed, one couldn't even spawn 50 instances.

Change-Id: Ic9b4872ae9ecccff8b4876b4c9d9572cb1233081
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/79/43779/17 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,8a133f9cd9dd2054ae0f73af8e6ea8da7bd5b071,bug/1199433," if [ ""$DEVSTACK_GATE_TEMPEST_LARGE_OPS"" -eq ""1"" ]; then # use fake virt driver and 10 copies of nova-compute echo ""VIRT_DRIVER=fake"" >> localrc echo ""NUMBER_FAKE_NOVA_COMPUTE=10"" >>localrc fi elif [[ ""$DEVSTACK_GATE_TEMPEST_LARGE_OPS"" -eq ""1"" ]] ; then echo ""Running large ops tests"" sudo -H -u stack tox -eall tempest.scenario.test_large_ops",,11,0
openstack%2Freviewstats~master~I2ab03d74e5664ee3674020e752ed13b620b42596,openstack/reviewstats,master,I2ab03d74e5664ee3674020e752ed13b620b42596,Update nova-core.,MERGED,2013-09-05 23:56:12.000000000,2013-09-05 23:56:28.000000000,2013-09-05 23:56:28.000000000,"[{'_account_id': 3}, {'_account_id': 1561}]","[{'number': 1, 'created': '2013-09-05 23:56:12.000000000', 'files': ['projects/nova.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/6dc648940aea4f10bc368f59a700e17076a08977', 'message': 'Update nova-core.\n\nChange-Id: I2ab03d74e5664ee3674020e752ed13b620b42596\n'}]",0,45356,6dc648940aea4f10bc368f59a700e17076a08977,5,2,1,1561,,,0,"Update nova-core.

Change-Id: I2ab03d74e5664ee3674020e752ed13b620b42596
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/56/45356/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/nova.json'],1,6dc648940aea4f10bc368f59a700e17076a08977,,"{""name"": ""nova"", ""subprojects"": [""openstack/nova"", ""openstack/python-novaclient"", ""openstack/compute-api""], ""core-team"": [""jogo"", ""sdague"", ""danms"", ""p-draigbrady"", ""mikalstill"", ""russellb"", ""cerberus"", ""markmc"", ""cbehrens"", ""klmitch"", ""cyeoh-0"", ""vishvananda"", ""belliott"", ""ndipanov"", ""alaski"", ""berrange"", ""johngarbutt""]}","{""name"": ""nova"", ""subprojects"": [""openstack/nova"", ""openstack/python-novaclient"", ""openstack/compute-api""], ""core-team"": [""jogo"", ""sdague"", ""danms"", ""yunmao"", ""p-draigbrady"", ""mikalstill"", ""russellb"", ""cerberus"", ""markmc"", ""cbehrens"", ""klmitch"", ""cyeoh-0"", ""vishvananda"", ""belliott"", ""tr3buchet"", ""ndipanov"", ""alaski"", ""berrange"", ""johngarbutt""]}",1,1
openstack%2Fnova~master~Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3,openstack/nova,master,Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3,Create mixin class for common DB fields,MERGED,2013-08-02 19:43:31.000000000,2013-09-05 22:57:56.000000000,2013-09-05 22:57:54.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5371}, {'_account_id': 5511}, {'_account_id': 5652}, {'_account_id': 6172}]","[{'number': 1, 'created': '2013-08-02 19:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fd80c4c01cbd48461e0a0117736a01df2ad7382', 'message': 'Split NovaObject into 2 base classes\n\nCreates a new NovaDBObject base class for DB-backed objects to use.\nNovaObject becomes a base class to use for non-DB-backed objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 2, 'created': '2013-08-03 08:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad2504069aeb287e6310d7ac6928ecca5a5d5223', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 3, 'created': '2013-08-03 09:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a38094fd86fd98e8e4d554bdb656dabcbb5d4227', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 4, 'created': '2013-08-07 17:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/afe808757723d6e8702f8d32525a429bff90b882', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 5, 'created': '2013-08-23 19:02:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62d6990bf4c044f448ff0ee1e720293d76fc320a', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 6, 'created': '2013-08-23 19:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e9f0e07e86da04aaef64ced29701cdf12a814cf', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 7, 'created': '2013-08-23 22:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/604a67ee1b65af3b9e0627f86c053966e31e29dc', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 8, 'created': '2013-08-24 05:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63d54cf6797a231d58a7af6c99f9bb6d356f8649', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 9, 'created': '2013-08-24 21:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bacc3f3cbfb8b2623f7e1f62da6cd97680eaec83', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 10, 'created': '2013-08-28 10:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37b92605859268ef642cdfbc9ea03e36c30ba722', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 11, 'created': '2013-08-28 20:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6691a7447dd20afc38a785bcd623fd6272dc79be', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 12, 'created': '2013-08-30 14:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56bd62369b4b474116daf5bfbb8dfbda86d93360', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 13, 'created': '2013-08-30 18:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/127c64bdebb9e84db4286bd1a2677c9f6502c5e6', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 14, 'created': '2013-09-03 22:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14ce7af807e17f57cafa76ab948c96a006c3ff68', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 15, 'created': '2013-09-04 17:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/315a1f95a2d0e5d0ff43404d7619bb8f2852b159', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}, {'number': 16, 'created': '2013-09-04 17:40:27.000000000', 'files': ['nova/objects/base.py', 'nova/objects/service.py', 'nova/tests/objects/test_objects.py', 'nova/objects/instance_fault.py', 'nova/objects/keypair.py', 'nova/objects/instance_action.py', 'nova/objects/instance_info_cache.py', 'nova/objects/pci_device.py', 'nova/objects/compute_node.py', 'nova/objects/instance_group.py', 'nova/objects/instance.py', 'nova/objects/aggregate.py', 'nova/objects/security_group.py', 'nova/objects/migration.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/71eb06f6742b957b48d89ac1de5483d34a83abec', 'message': 'Create mixin class for common DB fields\n\nCreates a new DBObjectMixin class for DB-backed objects to use.  This\nallows us to create non-DB-backed objects without having the common DB\nfields automagically added to them.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3\n'}]",6,39985,71eb06f6742b957b48d89ac1de5483d34a83abec,87,12,16,1030,,,0,"Create mixin class for common DB fields

Creates a new DBObjectMixin class for DB-backed objects to use.  This
allows us to create non-DB-backed objects without having the common DB
fields automagically added to them.

Related to blueprint unified-object-model

Change-Id: Iaf2d8500505e9acdbffffb1d4bd3db0870ae82a3
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/39985/16 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/tests/objects/test_objects.py', 'nova/objects/instance_fault.py', 'nova/objects/instance.py', 'nova/objects/security_group.py', 'nova/objects/instance_info_cache.py']",6,4fd80c4c01cbd48461e0a0117736a01df2ad7382,bp/compute-api-objects,class InstanceInfoCache(base.NovaDBObject):,class InstanceInfoCache(base.NovaObject):,31,28
openstack%2Fpython-zaqarclient~master~I2c8d4072a4fbf9228da8303acdf2ef34b8962481,openstack/python-zaqarclient,master,I2c8d4072a4fbf9228da8303acdf2ef34b8962481,Fixed a number of simple Python 3 issues.,ABANDONED,2013-08-16 17:40:29.000000000,2013-09-05 22:53:56.000000000,,"[{'_account_id': 3}, {'_account_id': 6944}]","[{'number': 1, 'created': '2013-08-16 17:40:29.000000000', 'files': ['marconiclient/common/apiclient/auth/response.py', 'marconiclient/common/apiclient/auth/keystone.py', 'tests/common/apiclient/test_exceptions.py', 'marconiclient/common/apiclient/exceptions.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/509241bbd41efbf8339de35dfa20ac1d99c57d08', 'message': 'Fixed a number of simple Python 3 issues.\n\nSpecifically removed usage of the dict.iter* methods. Also corrected a\nparse error.\n\nChange-Id: I2c8d4072a4fbf9228da8303acdf2ef34b8962481\n'}]",0,42391,509241bbd41efbf8339de35dfa20ac1d99c57d08,3,2,1,7680,,,0,"Fixed a number of simple Python 3 issues.

Specifically removed usage of the dict.iter* methods. Also corrected a
parse error.

Change-Id: I2c8d4072a4fbf9228da8303acdf2ef34b8962481
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/91/42391/1 && git format-patch -1 --stdout FETCH_HEAD,"['marconiclient/common/apiclient/auth/response.py', 'marconiclient/common/apiclient/auth/keystone.py', 'tests/common/apiclient/test_exceptions.py', 'marconiclient/common/apiclient/exceptions.py']",4,509241bbd41efbf8339de35dfa20ac1d99c57d08,improve-py3-support, error = next(iter(body.values())), error = body.itervalues().next(),4,4
openstack%2Fpython-zaqarclient~master~I8dd2b34113ea64495e55612da6372e5a4dbdbb74,openstack/python-zaqarclient,master,I8dd2b34113ea64495e55612da6372e5a4dbdbb74,Begin exposing a Connection class.,ABANDONED,2013-08-16 17:12:57.000000000,2013-09-05 22:53:46.000000000,,"[{'_account_id': 3}, {'_account_id': 6944}]","[{'number': 1, 'created': '2013-08-16 17:12:57.000000000', 'files': ['marconiclient/connection.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/c78f8b84147b8fda52c9619885362343829637a5', 'message': 'Begin exposing a Connection class.\n\nThis is the first step in giving marconiclient a usable interface. Thus\nfar it does absolutely nothing of interest.\n\nChange-Id: I8dd2b34113ea64495e55612da6372e5a4dbdbb74\n'}]",0,42385,c78f8b84147b8fda52c9619885362343829637a5,3,2,1,7680,,,0,"Begin exposing a Connection class.

This is the first step in giving marconiclient a usable interface. Thus
far it does absolutely nothing of interest.

Change-Id: I8dd2b34113ea64495e55612da6372e5a4dbdbb74
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/85/42385/1 && git format-patch -1 --stdout FETCH_HEAD,['marconiclient/connection.py'],1,c78f8b84147b8fda52c9619885362343829637a5,expose-connection,from marconiclient.common.apiclient import client class Connection(client.HttpClient): pass ,,5,0
openstack%2Fneutron~milestone-proposed~I83c4e4e0cfd6605930acfcc4f69ea9ece35abc24,openstack/neutron,milestone-proposed,I83c4e4e0cfd6605930acfcc4f69ea9ece35abc24,Install metering_agent.ini and vpn_agent.ini,MERGED,2013-09-05 22:25:00.000000000,2013-09-05 22:46:08.000000000,2013-09-05 22:46:08.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 4375}]","[{'number': 1, 'created': '2013-09-05 22:25:00.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d5adb7cf166704e0499510679dae7cefe2b4abb', 'message': 'Install metering_agent.ini and vpn_agent.ini\n\nFixes Bug: 1221451\nChange-Id: I83c4e4e0cfd6605930acfcc4f69ea9ece35abc24\n'}]",0,45339,4d5adb7cf166704e0499510679dae7cefe2b4abb,4,3,1,2592,,,0,"Install metering_agent.ini and vpn_agent.ini

Fixes Bug: 1221451
Change-Id: I83c4e4e0cfd6605930acfcc4f69ea9ece35abc24
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/45339/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,4d5adb7cf166704e0499510679dae7cefe2b4abb,bug/1221451, etc/metering_agent.ini etc/vpn_agent.ini,,2,0
openstack%2Fapi-site~master~I8ba4caae11f10f23945f5cb597bef511e96195b3,openstack/api-site,master,I8ba4caae11f10f23945f5cb597bef511e96195b3,Bug 1218617 corrected examples,MERGED,2013-08-29 21:20:01.000000000,2013-09-05 22:36:28.000000000,2013-09-05 22:36:28.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 5314}]","[{'number': 1, 'created': '2013-08-29 21:20:01.000000000', 'files': ['api-ref/src/wadls/compute-api/src/ext/samples/os-extended-status-detail-response.json', 'api-ref/src/wadls/compute-api/src/ext/samples/os-extended-status-show-response.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/5c0adb7aaecdf0c06547e130c35600ab76b5c59f', 'message': 'Bug 1218617 corrected examples\n\nChange-Id: I8ba4caae11f10f23945f5cb597bef511e96195b3\n'}]",0,44358,5c0adb7aaecdf0c06547e130c35600ab76b5c59f,7,4,1,5314,,,0,"Bug 1218617 corrected examples

Change-Id: I8ba4caae11f10f23945f5cb597bef511e96195b3
",git fetch https://review.opendev.org/openstack/api-site refs/changes/58/44358/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/compute-api/src/ext/samples/os-extended-status-detail-response.json', 'api-ref/src/wadls/compute-api/src/ext/samples/os-extended-status-show-response.json']",2,5c0adb7aaecdf0c06547e130c35600ab76b5c59f,bug/1218617," ""server"": { ""id"": ""52415800-8b69-11e0-9b19-734f6af67565"", ""tenant_id"": ""1234"", ""user_id"": ""5678"", ""name"": ""sample-server"", ""updated"": ""2010-10-10T12:00:00Z"", ""created"": ""2010-08-10T12:00:00Z"", ""hostId"": ""e4d909c290d0fb1ca068ffaddf22cbd0"", ""status"": ""BUILD"", ""progress"": 60, ""accessIPv4"": ""67.23.10.132"", ""accessIPv6"": ""::babe:67.23.10.132"", ""OS-EXT-STS:vm_state"": ""building"", ""OS-EXT-STS:task_state"": ""networking"", ""OS-EXT-STS:power_state"": 1, ""image"" : { ""id"": ""52415800-8b69-11e0-9b19-734f6f006e54"", ""links"": [ { ""rel"": ""self"", ""href"": ""http://servers.api.openstack.org/v1.1/1234/images/52415800-8b69-11e0-9b19-734f6f006e54"" }, { ""rel"": ""bookmark"", ""href"": ""http://servers.api.openstack.org/1234/images/52415800-8b69-11e0-9b19-734f6f006e54"" } ] ""flavor"" : { ""id"": ""52415800-8b69-11e0-9b19-734f216543fd"", ""links"": [ { ""rel"": ""self"", ""href"": ""http://servers.api.openstack.org/v1.1/1234/flavors/52415800-8b69-11e0-9b19-734f216543fd"" }, { ""rel"": ""bookmark"", ""href"": ""http://servers.api.openstack.org/1234/flavors/52415800-8b69-11e0-9b19-734f216543fd"" } ] }, ""addresses"": { ""public"" : [ { ""version"": 4, ""addr"": ""67.23.10.132"" }, { ""version"": 6, ""addr"": ""::babe:67.23.10.132"" }, { ""version"": 4, ""addr"": ""67.23.10.131"" }, { ""version"": 6, ""addr"": ""::babe:4317:0A83"" } ], ""private"" : [ { ""version"": 4, ""addr"": ""10.176.42.16"" }, { ""version"": 6, ""addr"": ""::babe:10.176.42.16"" } ] }, ""metadata"": { ""Server Label"": ""Web Head 1"", ""Image Version"": ""2.1"" }, ""href"": ""http://servers.api.openstack.org/v1.1/1234/servers/52415800-8b69-11e0-9b19-734f6af67565"" ""href"": ""http://servers.api.openstack.org/1234/servers/52415800-8b69-11e0-9b19-734f6af67565""}"," ""id"": ""52415800-8b69-11e0-9b19-734f6af67565"", ""tenant_id"": ""1234"", ""user_id"": ""5678"", ""name"": ""sample-server"", ""updated"": ""2010-10-10T12:00:00Z"", ""created"": ""2010-08-10T12:00:00Z"", ""hostId"": ""e4d909c290d0fb1ca068ffaddf22cbd0"", ""status"": ""BUILD"", ""progress"": 60, ""accessIPv4"" : ""67.23.10.132"", ""accessIPv6"" : ""::babe:67.23.10.132"", ""OS-EXT-STS:vm_state"" : ""building"", ""OS-EXT-STS:task_state"" : ""networking"", ""OS-EXT-STS:power_state"" : ""running"", ""image"" : { ""id"": ""52415800-8b69-11e0-9b19-734f6f006e54"", ""links"": [ { ""rel"": ""self"", ""href"": ""http://servers.api.openstack.org/v1.1/1234/images/52415800-8b69-11e0-9b19-734f6f006e54"" }, { ""rel"": ""bookmark"", ""href"": ""http://servers.api.openstack.org/1234/images/52415800-8b69-11e0-9b19-734f6f006e54"" } ] }, ""flavor"" : { ""id"": ""52415800-8b69-11e0-9b19-734f216543fd"", ""links"": [ { ""rel"": ""self"", ""href"": ""http://servers.api.openstack.org/v1.1/1234/flavors/52415800-8b69-11e0-9b19-734f216543fd"" }, { ""rel"": ""bookmark"", ""href"": ""http://servers.api.openstack.org/1234/flavors/52415800-8b69-11e0-9b19-734f216543fd"" } ] }, ""addresses"": { ""public"" : [ { ""version"": 4, ""addr"": ""67.23.10.132"" }, { ""version"": 6, ""addr"": ""::babe:67.23.10.132"" }, { ""version"": 4, ""addr"": ""67.23.10.131"" }, { ""version"": 6, ""addr"": ""::babe:4317:0A83"" } ], ""private"" : [ { ""version"": 4, ""addr"": ""10.176.42.16"" }, { ""version"": 6, ""addr"": ""::babe:10.176.42.16"" } ] }, ""metadata"": { ""Server Label"": ""Web Head 1"", ""Image Version"": ""2.1"" }, ""links"": [ { ""rel"": ""self"", ""href"": ""http://servers.api.openstack.org/v1.1/1234/servers/52415800-8b69-11e0-9b19-734f6af67565"" { ""rel"": ""bookmark"", ""href"": ""http://servers.api.openstack.org/1234/servers/52415800-8b69-11e0-9b19-734f6af67565"" } ] }, { ""id"": ""52415800-8b69-11e0-9b19-734f1f1350e5"", ""user_id"": ""5678"", ""name"": ""sample-server2"", ""tenant_id"": ""1234"", ""updated"": ""2010-10-10T12:00:00Z"", ""created"": ""2010-08-10T12:00:00Z"", ""hostId"": ""9e107d9d372bb6826bd81d3542a419d6"", ""status"": ""ACTIVE"", ""accessIPv4"" : ""67.23.10.133"", ""accessIPv6"" : ""::babe:67.23.10.133"", ""OS-EXT-SRV-ATTR:instance_name"" : ""instance-00000002"", ""OS-EXT-SRV-ATTR:host"" : ""other_compute_hostname"", ""image"" : { ""id"": ""52415800-8b69-11e0-9b19-734f5736d2a2"", ""href"": ""http://servers.api.openstack.org/v1.1/1234/images/52415800-8b69-11e0-9b19-734f5736d2a2"" ""href"": ""http://servers.api.openstack.org/1234/images/52415800-8b69-11e0-9b19-734f5736d2a2"" } ] }, ""flavor"" : { ""id"": ""52415800-8b69-11e0-9b19-734f216543fd"", ""links"": [ { ""rel"": ""self"", ""href"": ""http://servers.api.openstack.org/v1.1/1234/flavors/52415800-8b69-11e0-9b19-734f216543fd"" }, { ""rel"": ""bookmark"", ""href"": ""http://servers.api.openstack.org/1234/flavors/52415800-8b69-11e0-9b19-734f216543fd""",87,124
openstack%2Fneutron~master~I6120abb5abb9a869eb7310453cf27dd8f72bfd1d,openstack/neutron,master,I6120abb5abb9a869eb7310453cf27dd8f72bfd1d,Allow default network and policy profiles,MERGED,2013-08-31 00:47:54.000000000,2013-09-05 22:26:49.000000000,2013-09-05 22:26:49.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6524}, {'_account_id': 6785}, {'_account_id': 7018}]","[{'number': 1, 'created': '2013-08-31 00:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/33731303625f097f83fe97f07aa1dbd205dc7d65', 'message': 'Allow default network and policy profiles\n\nAllow for default network/policy profile to be used if\nno network/policy profile is specified during network/port creation\nin the Cisco N1KV plugin.\n\nChange-Id: I6120abb5abb9a869eb7310453cf27dd8f72bfd1d\nCloses-Bug: #1218588\n'}, {'number': 2, 'created': '2013-09-05 00:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee9975a1a3ce7eeb4a1a29314d87c890f189b0b2', 'message': 'Allow default network and policy profiles\n\nAllow for default network/policy profile to be used if\nno network/policy profile is specified during network/port creation\nin the Cisco N1KV plugin.\n\nChange-Id: I6120abb5abb9a869eb7310453cf27dd8f72bfd1d\nCloses-Bug: #1218588\n'}, {'number': 3, 'created': '2013-09-05 18:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c0b2ed2690136096a000d062d7c244318cc27b24', 'message': 'Allow default network and policy profiles\n\nAllow for default network/policy profile to be used if\nno network/policy profile is specified during network/port creation\nin the Cisco N1KV plugin.\n\nChange-Id: I6120abb5abb9a869eb7310453cf27dd8f72bfd1d\nCloses-Bug: #1218588\n'}, {'number': 4, 'created': '2013-09-05 19:36:28.000000000', 'files': ['etc/neutron/plugins/cisco/cisco_plugins.ini', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py', 'neutron/plugins/cisco/common/cisco_exceptions.py', 'neutron/plugins/cisco/n1kv/n1kv_client.py', 'neutron/plugins/cisco/db/n1kv_db_v2.py', 'neutron/plugins/cisco/common/config.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc48ac1a9c02c236157347f715190a2b1107ec70', 'message': 'Allow default network and policy profiles\n\nAllow for default network/policy profile to be used if\nno network/policy profile is specified during network/port creation\nin the Cisco N1KV plugin.\n\nChange-Id: I6120abb5abb9a869eb7310453cf27dd8f72bfd1d\nCloses-Bug: #1218588\n'}]",6,44569,dc48ac1a9c02c236157347f715190a2b1107ec70,27,7,4,7018,,,0,"Allow default network and policy profiles

Allow for default network/policy profile to be used if
no network/policy profile is specified during network/port creation
in the Cisco N1KV plugin.

Change-Id: I6120abb5abb9a869eb7310453cf27dd8f72bfd1d
Closes-Bug: #1218588
",git fetch https://review.opendev.org/openstack/neutron refs/changes/69/44569/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py', 'neutron/plugins/cisco/db/n1kv_db_v2.py', 'neutron/plugins/cisco/n1kv/n1kv_client.py', 'neutron/plugins/cisco/common/config.py']",4,33731303625f097f83fe97f07aa1dbd205dc7d65,bug/1218588," cfg.StrOpt('default_network_profile', default='default_network_profile', help=_(""N1K default network profile"")), cfg.StrOpt('network_node_policy_profile', default='dhcp_pp', help=_(""N1K policy profile for network node"")),",,36,9
openstack%2Fneutron~master~I83c4e4e0cfd6605930acfcc4f69ea9ece35abc24,openstack/neutron,master,I83c4e4e0cfd6605930acfcc4f69ea9ece35abc24,Install metering_agent.ini and vpn_agent.ini,MERGED,2013-09-05 08:27:56.000000000,2013-09-05 22:18:38.000000000,2013-09-05 22:18:37.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 4375}, {'_account_id': 5948}]","[{'number': 1, 'created': '2013-09-05 08:27:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a781778e77a54e4a94ed3ade550ee045cb513b0', 'message': 'Install metering_agent.ini and vpn_agent.ini\n\nThey seem to have been forgotten.\n\nChange-Id: I83c4e4e0cfd6605930acfcc4f69ea9ece35abc24\n'}, {'number': 2, 'created': '2013-09-05 21:42:21.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c25d74026211587999d9a54aa5ffc0747d8acb2c', 'message': 'Install metering_agent.ini and vpn_agent.ini\n\nFixes Bug: 1221451\nChange-Id: I83c4e4e0cfd6605930acfcc4f69ea9ece35abc24\n'}]",0,45191,c25d74026211587999d9a54aa5ffc0747d8acb2c,13,6,2,4375,,,0,"Install metering_agent.ini and vpn_agent.ini

Fixes Bug: 1221451
Change-Id: I83c4e4e0cfd6605930acfcc4f69ea9ece35abc24
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/45191/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,8a781778e77a54e4a94ed3ade550ee045cb513b0,neutron-metering-vpn-agent-confs-install, etc/metering_agent.ini etc/vpn_agent.ini,,2,0
openstack%2Fglance~master~I4a648ce1bcdb96bc385939ae2546e489a9d12a3c,openstack/glance,master,I4a648ce1bcdb96bc385939ae2546e489a9d12a3c,basic async poc,ABANDONED,2013-06-05 22:30:53.000000000,2013-09-05 22:16:57.000000000,,"[{'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 2537}, {'_account_id': 4463}, {'_account_id': 6159}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-06-05 22:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cdb646a699144ee27f897c50dd4c2a72189f58c9', 'message': 'basic async poc\n\nChange-Id: I4a648ce1bcdb96bc385939ae2546e489a9d12a3c\n'}, {'number': 2, 'created': '2013-06-06 14:55:06.000000000', 'files': ['glance/api/v2/tasks.py', 'glance/domain/async.py', 'glance/api/v2/images.py', 'glance/domain/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/81fa4ae7f3ba6443d266cd13ccb5a0cb755e2a32', 'message': 'basic async poc\n\nChange-Id: I4a648ce1bcdb96bc385939ae2546e489a9d12a3c\n'}]",4,31874,81fa4ae7f3ba6443d266cd13ccb5a0cb755e2a32,8,6,2,616,,,0,"basic async poc

Change-Id: I4a648ce1bcdb96bc385939ae2546e489a9d12a3c
",git fetch https://review.opendev.org/openstack/glance refs/changes/74/31874/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/api/v2/images.py', 'glance/api/v2/tasks.py', 'glance/domain/async.py', 'glance/domain/__init__.py']",4,cdb646a699144ee27f897c50dd4c2a72189f58c9,async," def import_image(self, source): return self.task_factory.new_task( request='import_image', parameters={'source': source}, ) def export(self, destination): return self.task_factory.new_task( request=""export_image"", parameters={'destination': destination}, ) def copy_data_from(self, location): return self.task_factory.new_task( request='image_copy_from', parameters={ 'image': self, 'location': location, }, ) ",,153,0
openstack%2Fneutron~master~Ic21b310608bb98be29ea50ab7c56ca859a9ed5c0,openstack/neutron,master,Ic21b310608bb98be29ea50ab7c56ca859a9ed5c0,LBaaS: make haproxy stats parsing more safe,MERGED,2013-09-04 13:51:07.000000000,2013-09-05 22:12:49.000000000,2013-09-05 22:12:48.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6659}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-09-04 13:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f4d543d803ba1075f37bd42b91dc7be22226348', 'message': 'LBaaS: make haproxy stats parsing more safely\n\nChange-Id: Ic21b310608bb98be29ea50ab7c56ca859a9ed5c0\nCloses-Bug: #1220692\n'}, {'number': 2, 'created': '2013-09-04 14:07:16.000000000', 'files': ['neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py', 'neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d1037335bbe969cfbc6d9657c24865ca226c7e9', 'message': 'LBaaS: make haproxy stats parsing more safe\n\nChange-Id: Ic21b310608bb98be29ea50ab7c56ca859a9ed5c0\nCloses-Bug: #1220692\n'}]",6,45060,6d1037335bbe969cfbc6d9657c24865ca226c7e9,17,8,2,5948,,,0,"LBaaS: make haproxy stats parsing more safe

Change-Id: Ic21b310608bb98be29ea50ab7c56ca859a9ed5c0
Closes-Bug: #1220692
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/45060/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py', 'neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py']",2,1f4d543d803ba1075f37bd42b91dc7be22226348,bug/1220692, if stats.get('type') == TYPE_BACKEND_RESPONSE: if stats.get('type') == TYPE_SERVER_RESPONSE: if not raw_values: continue, if stats['type'] == TYPE_BACKEND_RESPONSE: if stats['type'] == TYPE_SERVER_RESPONSE:,5,3
openstack%2Fcinder~master~Id01a310481353b272e103643d053957b65cd4ce3,openstack/cinder,master,Id01a310481353b272e103643d053957b65cd4ce3,Remove quota fetch race condition,MERGED,2013-09-05 16:31:45.000000000,2013-09-05 22:04:49.000000000,2013-09-05 22:04:48.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4159}, {'_account_id': 5997}, {'_account_id': 6316}]","[{'number': 1, 'created': '2013-09-05 16:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/abffdc5ae82125734d68be5b467acd34748d8ab5', 'message': ""Remove quota fetch race condition.\n\nWhen displaying quotas, we shouldn't pull the latest resources\njust to convert the results to the dict.\n\nCloses-Bug: #1220436\n\nChange-Id: Id01a310481353b272e103643d053957b65cd4ce3\n""}, {'number': 2, 'created': '2013-09-05 17:00:23.000000000', 'files': ['cinder/api/contrib/quotas.py', 'cinder/api/contrib/quota_classes.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4fe60f6192abdf154cbf7f65021a47d7e339aa76', 'message': ""Remove quota fetch race condition\n\nWhen displaying quotas, we shouldn't pull the latest resources\njust to convert the results to the dict.\n\nCloses-Bug: #1220436\n\nChange-Id: Id01a310481353b272e103643d053957b65cd4ce3\n""}]",0,45271,4fe60f6192abdf154cbf7f65021a47d7e339aa76,21,6,2,4159,,,0,"Remove quota fetch race condition

When displaying quotas, we shouldn't pull the latest resources
just to convert the results to the dict.

Closes-Bug: #1220436

Change-Id: Id01a310481353b272e103643d053957b65cd4ce3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/71/45271/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/contrib/quotas.py', 'cinder/api/contrib/quota_classes.py']",2,abffdc5ae82125734d68be5b467acd34748d8ab5,bug/1220436, quota_set['id'] = str(quota_class) return dict(quota_class_set=quota_set), result = dict(id=str(quota_class)) for resource in QUOTAS.resources: result[resource] = quota_set[resource] return dict(quota_class_set=result),4,10
openstack%2Fglance~master~Iac6be532b7b9bb911b745712712d1be363e8ff01,openstack/glance,master,Iac6be532b7b9bb911b745712712d1be363e8ff01,emit warning while running flake8 without virtual env,MERGED,2013-08-22 22:08:51.000000000,2013-09-05 21:53:41.000000000,2013-09-05 21:53:41.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 1669}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 6159}, {'_account_id': 6493}, {'_account_id': 7774}]","[{'number': 1, 'created': '2013-08-22 22:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1464650e9f4bd330294f870f792bbb34fdebd92b', 'message': 'emit warning while running flake8 without virtual env\n\nrun_tests.sh -N -p\n\nit will call the flake8 installed on your host to detect PEP8, and\nthe flake8 plugin ""OpenStack hacking"" may not installed on your\nhost, so this command may not detect the OpenStack Style Commandment\nsupplied by hacking(e.g H202).\n\nrun_tests.sh -p\nit will call the flake8 from virtual env, flake8 plugin ""OpenStack\nhacking"" installed in virtual env will be triggered.\n\nThe result from ""run_tests.sh -p"" should be trusted, and jenkins uses\nvirtual env to run flake8 too.\n\nWhen ""-N"" is enabled, emit warning to remind user.\n\nBug #1215396\n\nChange-Id: Iac6be532b7b9bb911b745712712d1be363e8ff01\n'}, {'number': 2, 'created': '2013-08-27 23:09:24.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/glance/commit/fe897c0b79064ef374af8170e1ea8e7d6182081a', 'message': 'emit warning while running flake8 without virtual env\n\nrun_tests.sh -N -p\n\nit will call the flake8 installed on your host to detect PEP8, and\nthe flake8 plugin ""OpenStack hacking"" may not installed on your\nhost, so this command may not detect the OpenStack Style Commandment\nsupplied by hacking(e.g H202).\n\nrun_tests.sh -p\nit will call the flake8 from virtual env, flake8 plugin ""OpenStack\nhacking"" installed in virtual env will be triggered.\n\nThe result from ""run_tests.sh -p"" should be trusted, and jenkins uses\nvirtual env to run flake8 too.\n\nWhen ""-N"" is enabled, emit warning to stderr to remind user.\n\nBug #1215396\n\nChange-Id: Iac6be532b7b9bb911b745712712d1be363e8ff01\n'}]",0,43360,fe897c0b79064ef374af8170e1ea8e7d6182081a,11,8,2,7774,,,0,"emit warning while running flake8 without virtual env

run_tests.sh -N -p

it will call the flake8 installed on your host to detect PEP8, and
the flake8 plugin ""OpenStack hacking"" may not installed on your
host, so this command may not detect the OpenStack Style Commandment
supplied by hacking(e.g H202).

run_tests.sh -p
it will call the flake8 from virtual env, flake8 plugin ""OpenStack
hacking"" installed in virtual env will be triggered.

The result from ""run_tests.sh -p"" should be trusted, and jenkins uses
virtual env to run flake8 too.

When ""-N"" is enabled, emit warning to stderr to remind user.

Bug #1215396

Change-Id: Iac6be532b7b9bb911b745712712d1be363e8ff01
",git fetch https://review.opendev.org/openstack/glance refs/changes/60/43360/2 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,1464650e9f4bd330294f870f792bbb34fdebd92b,bug/1215396," if [ $never_venv -eq 1 ]; then echo ""**WARNING**:"" echo ""Running flake8 without virtual env may miss OpenStack HACKING detection"" fi",,4,0
openstack%2Fnova~master~I07d2f136a12c08cbbc24bf3a3cf72235aed1b232,openstack/nova,master,I07d2f136a12c08cbbc24bf3a3cf72235aed1b232,xenapi: Add efficient impl of instance_exists(),MERGED,2013-09-05 15:38:26.000000000,2013-09-05 21:34:21.000000000,2013-09-05 21:34:18.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 475}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2835}]","[{'number': 1, 'created': '2013-09-05 15:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e89c8e9878c98e7f141b2faf01a945704151a04', 'message': 'xenapi: Add efficient impl of instance_exists()\n\nOverride the base class implementation of instance_exists\nfor efficiency.  This saves a lot of calls to XenAPI.\n\nChange-Id: I07d2f136a12c08cbbc24bf3a3cf72235aed1b232\n'}, {'number': 2, 'created': '2013-09-05 18:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f64590f15d12281a8d9c8876c9d75ecb22b0ef0', 'message': 'xenapi: Add efficient impl of instance_exists()\n\nOverride the base class implementation of instance_exists\nfor efficiency.  This saves a lot of calls to XenAPI.\n\nChange-Id: I07d2f136a12c08cbbc24bf3a3cf72235aed1b232\n'}, {'number': 3, 'created': '2013-09-05 19:22:45.000000000', 'files': ['nova/virt/xenapi/driver.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/virt/xenapi/vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b6e9bd94503cdb8a644d8af49c9f67ee06ed03be', 'message': 'xenapi: Add efficient impl of instance_exists()\n\nOverride the base class implementation of instance_exists\nfor efficiency.  This saves a lot of calls to XenAPI.\n\nChange-Id: I07d2f136a12c08cbbc24bf3a3cf72235aed1b232\n'}]",2,45252,b6e9bd94503cdb8a644d8af49c9f67ee06ed03be,25,8,3,2835,,,0,"xenapi: Add efficient impl of instance_exists()

Override the base class implementation of instance_exists
for efficiency.  This saves a lot of calls to XenAPI.

Change-Id: I07d2f136a12c08cbbc24bf3a3cf72235aed1b232
",git fetch https://review.opendev.org/openstack/nova refs/changes/52/45252/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/xenapi/driver.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/virt/xenapi/vmops.py']",3,6e89c8e9878c98e7f141b2faf01a945704151a04,xenapi_faster_instance_exists," def instance_exists(self, name_label): return vm_utils.lookup(self._session, name_label) is not None ",,33,0
openstack%2Fceilometer~master~Ia53a8518defd386a8531f62a3a3d19f5fbafbdc4,openstack/ceilometer,master,Ia53a8518defd386a8531f62a3a3d19f5fbafbdc4,Fix wrong migrations,ABANDONED,2013-09-05 16:15:42.000000000,2013-09-05 21:30:34.000000000,,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6507}]","[{'number': 1, 'created': '2013-09-05 16:15:42.000000000', 'files': ['ceilometer/storage/sqlalchemy/alembic/versions/b6ae66d05e3_remove_extra_indexes.py', 'ceilometer/storage/sqlalchemy/alembic/versions/2c3ccda5a3ad_fix_uniq_name.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/45ad8283f4c4ae535b53cacb4f4cb3c6aec09aa5', 'message': 'Fix wrong migrations\n\nFor Postgres migrations are failed.\nMore then we can get for mysql an error\n""Specified key was too long; max key length is 1000 bytes"" in b6ae66d05e3\nmigration in some versions of dialect.\n\nFixes-Bug: #1219776\n\n(cherry picked from commit aae3f55304ff161b401b803769350e9cb66b0e8c)\n\nChange-Id: Ia53a8518defd386a8531f62a3a3d19f5fbafbdc4\n'}]",0,45265,45ad8283f4c4ae535b53cacb4f4cb3c6aec09aa5,4,3,1,1669,,,0,"Fix wrong migrations

For Postgres migrations are failed.
More then we can get for mysql an error
""Specified key was too long; max key length is 1000 bytes"" in b6ae66d05e3
migration in some versions of dialect.

Fixes-Bug: #1219776

(cherry picked from commit aae3f55304ff161b401b803769350e9cb66b0e8c)

Change-Id: Ia53a8518defd386a8531f62a3a3d19f5fbafbdc4
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/65/45265/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/sqlalchemy/alembic/versions/b6ae66d05e3_remove_extra_indexes.py', 'ceilometer/storage/sqlalchemy/alembic/versions/2c3ccda5a3ad_fix_uniq_name.py']",2,45ad8283f4c4ae535b53cacb4f4cb3c6aec09aa5,milestone-proposed,"UNIQ_NAME = 'uniq_sourceassoc0meter_id0user_id'def change_uniq(table_name, uniq_name, columns, downgrade=False): bind = op.get_bind() engine = bind.engine if downgrade: op.drop_constraint(uniq_name, table_name=table_name, type_='unique') else: op.create_unique_constraint(uniq_name, table_name, columns) change_uniq(TABLE_NAME, UNIQ_NAME, COLUMNS) change_uniq(TABLE_NAME, UNIQ_NAME, COLUMNS, downgrade=True)","OLD_NAME = 'uniq_sourceassoc0meter_id' NEW_NAME = 'uniq_sourceassoc0meter_id0user_id'def change_uniq(table_name, old_name, new_name, columns): engine = op.get_bind().engine try: # For some versions of dialects constraint can be skipped. op.drop_constraint(old_name, table_name=table_name, type_='unique') except Exception: pass op.create_unique_constraint(new_name, table_name, columns) change_uniq(TABLE_NAME, OLD_NAME, NEW_NAME, COLUMNS) change_uniq(TABLE_NAME, NEW_NAME, OLD_NAME, COLUMNS)",41,30
openstack%2Fceilometer~master~I060926aa300dc34bd6f592824ebfd2fa9d761268,openstack/ceilometer,master,I060926aa300dc34bd6f592824ebfd2fa9d761268,nova_notifier: fix tests,ABANDONED,2013-09-05 16:15:42.000000000,2013-09-05 21:30:27.000000000,,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2013-09-05 16:15:42.000000000', 'files': ['nova_tests/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f48c96a4de6adbb4f96362fa8b2d850b3ade0697', 'message': ""nova_notifier: fix tests\n\nThe prototype for instance_update_and_get_original changed, so let's\nignore it completely for the future.\n\nFixes-Bug: #1221173\n(cherry picked from commit d2a87a9dfd3cd9ef034eed3d693683972c842576)\n\nChange-Id: I060926aa300dc34bd6f592824ebfd2fa9d761268\n""}]",0,45266,f48c96a4de6adbb4f96362fa8b2d850b3ade0697,3,2,1,1669,,,0,"nova_notifier: fix tests

The prototype for instance_update_and_get_original changed, so let's
ignore it completely for the future.

Fixes-Bug: #1221173
(cherry picked from commit d2a87a9dfd3cd9ef034eed3d693683972c842576)

Change-Id: I060926aa300dc34bd6f592824ebfd2fa9d761268
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/66/45266/1 && git format-patch -1 --stdout FETCH_HEAD,['nova_tests/test_notifier.py'],1,f48c96a4de6adbb4f96362fa8b2d850b3ade0697,milestone-proposed," lambda *args, **kwargs: (self.instance, self.instance))"," lambda context, uuid, kwargs, update_cells: (self.instance, self.instance))",1,2
openstack%2Fcookbook-openstack-telemetry~master~If80cd5264a02eeb7c94655716839642dd7993906,openstack/cookbook-openstack-telemetry,master,If80cd5264a02eeb7c94655716839642dd7993906,Add optional host to ceilometer.conf,MERGED,2013-09-05 18:45:31.000000000,2013-09-05 21:03:28.000000000,2013-09-05 21:03:28.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 26}, {'_account_id': 4277}, {'_account_id': 7220}]","[{'number': 1, 'created': '2013-09-05 18:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/86bf3a166f7ec8ddcded9c79388934e3ecab2545', 'message': 'Add optional host to ceilometer.conf\n\nBy default cfg.CONF.host is the `hostname` of local node, however, not all envs\nregister their hosts by the fqdn.  This allows a configurable attr to add to\nthe ceilometer.conf\n\nChange-Id: If80cd5264a02eeb7c94655716839642dd7993906\n'}, {'number': 2, 'created': '2013-09-05 20:27:04.000000000', 'files': ['templates/default/ceilometer.conf.erb', 'CHANGELOG.md', 'metadata.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/f19a0d9d0077bc08297875f4e61e519067cf58a9', 'message': 'Add optional host to ceilometer.conf\n\nBy default cfg.CONF.host is the `hostname` of local node, however, not all envs\nregister their hosts by the fqdn.  This allows a configurable attr to add to\nthe ceilometer.conf\n\nChange-Id: If80cd5264a02eeb7c94655716839642dd7993906\n'}]",1,45302,f19a0d9d0077bc08297875f4e61e519067cf58a9,10,5,2,4277,,,0,"Add optional host to ceilometer.conf

By default cfg.CONF.host is the `hostname` of local node, however, not all envs
register their hosts by the fqdn.  This allows a configurable attr to add to
the ceilometer.conf

Change-Id: If80cd5264a02eeb7c94655716839642dd7993906
",git fetch https://review.opendev.org/openstack/cookbook-openstack-telemetry refs/changes/02/45302/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/default/ceilometer.conf.erb', 'CHANGELOG.md', 'metadata.rb']",3,86bf3a166f7ec8ddcded9c79388934e3ecab2545,master,"version ""7.0.2""","version ""7.0.1""",9,1
openstack%2Fkeystone~master~I0da323113030c6a68b3c4bbdd94053639312c594,openstack/keystone,master,I0da323113030c6a68b3c4bbdd94053639312c594,Changes template header for translation catalogs,MERGED,2013-09-05 18:06:34.000000000,2013-09-05 20:32:51.000000000,2013-09-05 20:32:51.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}]","[{'number': 1, 'created': '2013-09-05 18:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/75e03c1c4a010b4f72f9b2cbd8de0a244fbcfb7e', 'message': ""Changes template header for translation catalogs\n\nNew translation catalogs will be generated with the organization set to\n'OpenStack Foundation' in the header.\n\nChange-Id: I0da323113030c6a68b3c4bbdd94053639312c594\nPartial-Bug: #1214176\n""}, {'number': 2, 'created': '2013-09-05 18:23:34.000000000', 'files': ['keystone/locale/ko/LC_MESSAGES/keystone.po', 'keystone/locale/tl/LC_MESSAGES/keystone.po', 'keystone/locale/en_GB/LC_MESSAGES/keystone.po', 'keystone/locale/id/LC_MESSAGES/keystone.po', 'keystone/locale/sw_KE/LC_MESSAGES/keystone.po', 'keystone/locale/ru/LC_MESSAGES/keystone.po', 'keystone/locale/ms/LC_MESSAGES/keystone.po', 'keystone/locale/bs/LC_MESSAGES/keystone.po', 'keystone/locale/pt/LC_MESSAGES/keystone.po', 'keystone/locale/de/LC_MESSAGES/keystone.po', 'keystone/locale/hu/LC_MESSAGES/keystone.po', 'keystone/locale/ne/LC_MESSAGES/keystone.po', 'keystone/locale/sk/LC_MESSAGES/keystone.po', 'keystone/locale/it/LC_MESSAGES/keystone.po', 'keystone/locale/ro/LC_MESSAGES/keystone.po', 'keystone/locale/bg_BG/LC_MESSAGES/keystone.po', 'keystone/locale/cs/LC_MESSAGES/keystone.po', 'keystone/locale/en_US/LC_MESSAGES/keystone.po', 'keystone/locale/da/LC_MESSAGES/keystone.po', 'keystone/locale/es/LC_MESSAGES/keystone.po', 'keystone/locale/hr/LC_MESSAGES/keystone.po', 'keystone/locale/ru_RU/LC_MESSAGES/keystone.po', 'keystone/locale/zh_TW/LC_MESSAGES/keystone.po', 'keystone/locale/fi_FI/LC_MESSAGES/keystone.po', 'keystone/locale/keystone.pot', 'keystone/locale/pl_PL/LC_MESSAGES/keystone.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/locale/ko_KR/LC_MESSAGES/keystone.po', 'keystone/locale/fr/LC_MESSAGES/keystone.po', 'keystone/locale/ka_GE/LC_MESSAGES/keystone.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone.po', 'keystone/locale/vi_VN/LC_MESSAGES/keystone.po', 'keystone/locale/it_IT/LC_MESSAGES/keystone.po', 'keystone/locale/nl_NL/LC_MESSAGES/keystone.po', 'keystone/locale/tr_TR/LC_MESSAGES/keystone.po', 'keystone/locale/zh_HK/LC_MESSAGES/keystone.po', 'keystone/locale/sl_SI/LC_MESSAGES/keystone.po', 'keystone/locale/hi/LC_MESSAGES/keystone.po', 'keystone/locale/uk/LC_MESSAGES/keystone.po', 'keystone/locale/nb/LC_MESSAGES/keystone.po', 'keystone/locale/es_MX/LC_MESSAGES/keystone.po', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/keystone/commit/8d2f53c403e51022947943815b34dd9e0deca835', 'message': ""Changes template header for translation catalogs\n\nNew translation catalogs will be generated with the organization set to\n'OpenStack Foundation' in the header.\n\nChange-Id: I0da323113030c6a68b3c4bbdd94053639312c594\nPartial-Bug: #1214176\n""}]",0,45293,8d2f53c403e51022947943815b34dd9e0deca835,10,6,2,7725,,,0,"Changes template header for translation catalogs

New translation catalogs will be generated with the organization set to
'OpenStack Foundation' in the header.

Change-Id: I0da323113030c6a68b3c4bbdd94053639312c594
Partial-Bug: #1214176
",git fetch https://review.opendev.org/openstack/keystone refs/changes/93/45293/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,75e03c1c4a010b4f72f9b2cbd8de0a244fbcfb7e,(detached,copyright_holder = OpenStack Foundation msgid_bugs_address = https://bugs.launchpad.net/keystone,,2,0
openstack%2Fneutron~master~I05cbaac73976c70be8428bf5a2d0017ea7059cb3,openstack/neutron,master,I05cbaac73976c70be8428bf5a2d0017ea7059cb3,fix conversion type missing,MERGED,2013-09-05 06:23:27.000000000,2013-09-05 20:30:24.000000000,2013-09-05 20:30:23.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1994}, {'_account_id': 2031}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6676}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-09-05 06:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f0fdbd458d7365b0366cd9b4f299ca3715ffe25', 'message': 'fix conversion type missing\n\nConversion type is missing in some places which would cause some\nunexcepted error. By using \'grep -rn ""%([a-zA-Z_]*) ""\', we could find\nall cases of \'%(variable_a)\' and fix them.\n\nChange-Id: I05cbaac73976c70be8428bf5a2d0017ea7059cb3\nCloses-Bug: #1221036\n'}, {'number': 2, 'created': '2013-09-05 09:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c52f7f8f6c1b9246a21363d47ecb675dde4c354', 'message': 'fix conversion type missing\n\nConversion type is missing in some places which would cause some\nunexcepted error. By using \'grep -rn ""%(\\w\\+)\\W""\', we could find\nall cases of \'%(variable_a)\' and fix them.\n\nChange-Id: I05cbaac73976c70be8428bf5a2d0017ea7059cb3\nCloses-Bug: #1221036\n'}, {'number': 3, 'created': '2013-09-05 16:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a7bac6770bf1484a28918d189638f195a962648', 'message': 'fix conversion type missing\n\n[temp one]\nConversion type is missing in some places which would cause some\nunexcepted error. By using \'grep -rn ""%(\\w\\+)\\W""\', we could find\nall cases of \'%(variable_a)\' and fix them.\n\nChange-Id: I05cbaac73976c70be8428bf5a2d0017ea7059cb3\nCloses-Bug: #1221036\n'}, {'number': 4, 'created': '2013-09-05 17:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3259da5aae7a6c575bff7d617d3f06cc1d6e9b09', 'message': 'fix conversion type missing and add hacking rule\n\nConversion type is missing in some places which would cause some\nunexcepted error. By using \'grep -rn ""%(\\w\\+)\\W""\', we could find\nall cases of \'%(variable_a)\' and fix them.\n\nAnd add hacking rule for this.\n\nCloses-Bug: #1221036\nCloses-Bug: #1221051\nChange-Id: I05cbaac73976c70be8428bf5a2d0017ea7059cb3\n'}, {'number': 5, 'created': '2013-09-05 17:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ac21122885219a56fba0cd589ba60028c731557', 'message': 'fix conversion type missing and add hacking rule\n\nConversion type is missing in some places which would cause some\nunexcepted error. By using \'grep -rn ""%(\\w\\+)\\W""\', we could find\nall cases of \'%(variable_a)\' and fix them.\n\nAnd add hacking rule for this.\n\nCloses-Bug: #1221036\nCloses-Bug: #1221051\nChange-Id: I05cbaac73976c70be8428bf5a2d0017ea7059cb3\n'}, {'number': 6, 'created': '2013-09-05 17:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e287c1ceb0752480c61914f7d01d65b68ac3bb5', 'message': 'fix conversion type missing and add hacking rule\n\nConversion type is missing in some places which would cause some\nunexcepted error. By using \'grep -rn ""%(\\w\\+)\\W""\', we could find\nall cases of \'%(variable_a)\' and fix them.\n\nAnd add hacking rule for this.\n\nCloses-Bug: #1221036\nCloses-Bug: #1221051\nChange-Id: I05cbaac73976c70be8428bf5a2d0017ea7059cb3\n'}, {'number': 7, 'created': '2013-09-05 18:16:42.000000000', 'files': ['neutron/plugins/nec/common/ofc_client.py', 'neutron/plugins/mlnx/agent/eswitch_neutron_agent.py', '.mailmap', 'neutron/plugins/cisco/db/n1kv_db_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee26de1ed22fc67591a7b5465132f78af1f1c0f4', 'message': 'fix conversion type missing\n\nConversion type is missing in some places which would cause some\nunexcepted error. By using \'grep -rn ""%(\\w\\+)\\W""\', we could find\nall cases of \'%(variable_a)\' and fix them.\n\nChange-Id: I05cbaac73976c70be8428bf5a2d0017ea7059cb3\nCloses-Bug: #1221036\n'}]",3,45180,ee26de1ed22fc67591a7b5465132f78af1f1c0f4,44,11,7,6835,,,0,"fix conversion type missing

Conversion type is missing in some places which would cause some
unexcepted error. By using 'grep -rn ""%(\w\+)\W""', we could find
all cases of '%(variable_a)' and fix them.

Change-Id: I05cbaac73976c70be8428bf5a2d0017ea7059cb3
Closes-Bug: #1221036
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/45180/6 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/mlnx/agent/eswitch_neutron_agent.py'],1,9f0fdbd458d7365b0366cd9b4f299ca3715ffe25,bug/1221036," LOG.error(_(""Unknown network type %(network_type)s "" ""for network %(network_id)s""),"," LOG.error(_(""Unknown network type %(network_type) "" ""for network %(network_id)""),",2,2
openstack%2Fglance~master~I6d1624a00e89721f5c9af969e191951fdcb2ee43,openstack/glance,master,I6d1624a00e89721f5c9af969e191951fdcb2ee43,Fix typo in IMAGE_META_HEADERS,MERGED,2013-09-03 08:42:06.000000000,2013-09-05 20:30:16.000000000,2013-09-05 20:30:16.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 6484}, {'_account_id': 8330}]","[{'number': 1, 'created': '2013-09-03 08:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2acfe2484979ed502d0cf8837d85f203a30752cc', 'message': 'Closes-Bug:#1220067\n\nx-image-meta-deleted-at replaced with x-image-meta-deleted_at\nThis prevents a problem when running the add_image method.\n\nThe bug was entered as part of the following commit: c3e58bd943ccb4e1457914c3c2b5366bd0afee5a\n\nChange-Id: I6d1624a00e89721f5c9af969e191951fdcb2ee43\n'}, {'number': 2, 'created': '2013-09-03 13:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/78df88bf3a56a8f5344d0c420ba3ac1b7daf6e26', 'message': 'Fix typo in IMAGE_META_HEADERS\n\nx-image-meta-deleted-at replaced with x-image-meta-deleted_at\nThis prevents a problem when running the add_image method.\n\nThe bug was entered as part of the following commit: c3e58bd943ccb4e1457914c3c2b5366bd0afee5a\n\nCloses-Bug:#1220067\nChange-Id: I6d1624a00e89721f5c9af969e191951fdcb2ee43\n'}, {'number': 3, 'created': '2013-09-03 14:06:33.000000000', 'files': ['glance/common/utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/57f312c566ad83884b3a9ed720b470204c01dbae', 'message': 'Fix typo in IMAGE_META_HEADERS\n\nx-image-meta-deleted-at replaced with x-image-meta-deleted_at\nThis prevents a problem when running the add_image method.\n\nThe bug was entered as part of the following commit:\nc3e58bd943ccb4e1457914c3c2b5366bd0afee5a\n\nCloses-Bug:#1220067\nChange-Id: I6d1624a00e89721f5c9af969e191951fdcb2ee43\n'}]",1,44812,57f312c566ad83884b3a9ed720b470204c01dbae,20,7,3,8330,,,0,"Fix typo in IMAGE_META_HEADERS

x-image-meta-deleted-at replaced with x-image-meta-deleted_at
This prevents a problem when running the add_image method.

The bug was entered as part of the following commit:
c3e58bd943ccb4e1457914c3c2b5366bd0afee5a

Closes-Bug:#1220067
Change-Id: I6d1624a00e89721f5c9af969e191951fdcb2ee43
",git fetch https://review.opendev.org/openstack/glance refs/changes/12/44812/2 && git format-patch -1 --stdout FETCH_HEAD,['glance/common/utils.py'],1,2acfe2484979ed502d0cf8837d85f203a30752cc,fix_for_bug_Bug_#1220067," 'x-image-meta-deleted_at', 'x-image-meta-min_ram',"," 'x-image-meta-deleted-at', 'x-image-meta-min_ram',",1,1
openstack%2Fkeystone~master~Icef7f9c161c1e02077a8a031d814e41defea2ee6,openstack/keystone,master,Icef7f9c161c1e02077a8a031d814e41defea2ee6,Fixed serialization for role lists,ABANDONED,2013-02-05 16:07:08.000000000,2013-09-05 20:26:57.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6}, {'_account_id': 2166}, {'_account_id': 2998}]","[{'number': 1, 'created': '2013-02-05 16:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/381d51cf4938efce03bd093b1a6c2c566e310d0e', 'message': 'Fixed serialization for lists\n\nPreviously container elements were not inserted when required.\n\nChange-Id: Icef7f9c161c1e02077a8a031d814e41defea2ee6\nFixes: bug #1065233\n'}, {'number': 2, 'created': '2013-02-06 09:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/38838b64ecf7b9b7bd7a2c455a844d999211830e', 'message': 'Fixed serialization for role lists\n\nPreviously container elements `roles` was not inserted around list of `role` tags.\n\nChange-Id: Icef7f9c161c1e02077a8a031d814e41defea2ee6\nFixes: bug #1065233\n'}, {'number': 3, 'created': '2013-02-06 11:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0e03773fca7ee5dec5dc46078709bd66c2d4171d', 'message': 'Fixed serialization for role lists\n\nPreviously container elements `roles` was not inserted around list of `role` tags.\n\nChange-Id: Icef7f9c161c1e02077a8a031d814e41defea2ee6\nFixes: bug #1065233\n'}, {'number': 4, 'created': '2013-02-06 11:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9adbf6f316a3471ee8f9cdb7422bd7ddeb4207df', 'message': 'Fixed serialization for role lists\n\nPreviously container elements `roles` was not inserted around list of `role` tags.\n\nChange-Id: Icef7f9c161c1e02077a8a031d814e41defea2ee6\nFixes: bug #1065233\n'}, {'number': 5, 'created': '2013-02-19 13:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b071a2b98d7bfdf07e261abfe56741f2a5e7d847', 'message': 'Fixed serialization for role lists\n\nPreviously container elements `roles` was not inserted around list of `role` tags.\n\nChange-Id: Icef7f9c161c1e02077a8a031d814e41defea2ee6\nFixes: bug #1065233\n'}, {'number': 6, 'created': '2013-02-19 14:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3d4f6d0e8026d12c9f3d3018a21fcd2a98f2ffee', 'message': 'Fixed serialization for role lists\n\nPreviously container elements `roles` was not inserted around list of `role` tags.\n\nChange-Id: Icef7f9c161c1e02077a8a031d814e41defea2ee6\nFixes: bug #1065233\n'}, {'number': 7, 'created': '2013-02-20 14:37:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/17e4dabbb329db9f1e1b95dd99f3f9e30166bf2b', 'message': 'Fixed serialization for role lists\n\nPreviously container elements `roles` was not inserted around list of `role` tags.\n\nChange-Id: Icef7f9c161c1e02077a8a031d814e41defea2ee6\nFixes: bug #1065233\n'}, {'number': 8, 'created': '2013-02-20 14:48:36.000000000', 'files': ['keystone/common/serializer.py', 'tests/test_content_types.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/887ca1f9c0ebf909930b7b078336cc2c3fb8dff8', 'message': 'Fixed serialization for role lists\n\nPreviously container elements `roles` was not inserted around list of `role` tags.\n\nChange-Id: Icef7f9c161c1e02077a8a031d814e41defea2ee6\nFixes: bug #1065233\n'}]",7,21224,887ca1f9c0ebf909930b7b078336cc2c3fb8dff8,33,5,8,2998,,,0,"Fixed serialization for role lists

Previously container elements `roles` was not inserted around list of `role` tags.

Change-Id: Icef7f9c161c1e02077a8a031d814e41defea2ee6
Fixes: bug #1065233
",git fetch https://review.opendev.org/openstack/keystone refs/changes/24/21224/5 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/serializer.py', 'tests/test_serializer.py']",2,381d51cf4938efce03bd093b1a6c2c566e310d0e,bug/1065233," def test_container_serialization(self): d = {'user': {'id': 1, 'name': 'fdfd', 'roles': [{'id': '1'}]}} xml = """""" <?xml version=""1.0"" encoding=""UTF-8""?> <user xmlns=""http://docs.openstack.org/identity/api/v2.0"" id=""1"" name=""fdfd""> <roles xmlns=""http://docs.openstack.org/identity/api/v2.0""> <role id=""1""/> </roles> </user> """""" self.assertEqualIgnoreWhitespace(serializer.to_xml(d), xml)",,14,0
openstack%2Fneutron~master~If553a84b7221f8c98d758654d317217a909c43dc,openstack/neutron,master,If553a84b7221f8c98d758654d317217a909c43dc,Fix NVP plugin to send notifications for gateway-less subnets,MERGED,2013-09-05 01:13:20.000000000,2013-09-05 20:25:05.000000000,2013-09-05 20:25:05.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2166}, {'_account_id': 4395}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-09-05 01:13:20.000000000', 'files': ['neutron/tests/unit/nicira/test_agent_scheduler.py', 'neutron/plugins/nicira/dhcp_meta/rpc.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3e00a45ff766e049951981614013a8d425fa34fd', 'message': 'Fix NVP plugin to send notifications for gateway-less subnets\n\nIt was noted that an update notification should be sent\nregardless; this patch addresses that. Since there is\nno longer the need to distinguish on whether to send\nthe RPC message or not, the operation has been factored\nout to avoid code duplication.\n\nCloses-Bug: 1220881\n\nChange-Id: If553a84b7221f8c98d758654d317217a909c43dc\n'}]",0,45153,3e00a45ff766e049951981614013a8d425fa34fd,8,5,1,748,,,0,"Fix NVP plugin to send notifications for gateway-less subnets

It was noted that an update notification should be sent
regardless; this patch addresses that. Since there is
no longer the need to distinguish on whether to send
the RPC message or not, the operation has been factored
out to avoid code duplication.

Closes-Bug: 1220881

Change-Id: If553a84b7221f8c98d758654d317217a909c43dc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/53/45153/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/nicira/test_agent_scheduler.py', 'neutron/plugins/nicira/dhcp_meta/rpc.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py']",3,3e00a45ff766e049951981614013a8d425fa34fd,bug/1220881," def _network_port_create( self, hosts, gateway=attributes.ATTR_NOT_SPECIFIED, owner=None): gateway_ip=gateway, do_delete=False) as subnet1: if owner: with self.port(subnet=subnet1, no_delete=True, device_owner=owner) as port: return [mock_dhcp, net1, subnet1, port] else: with self.port(subnet=subnet1, no_delete=True) as port: return [mock_dhcp, net1, subnet1, port]"," def _network_port_create(self, hosts): do_delete=False) as subnet1: with self.port(subnet=subnet1, no_delete=True) as port: return [mock_dhcp, net1, subnet1, port]",44,19
openstack%2Fswift~master~Ia8e62eef5af9e849e86c3ff14ce7f8aaa5f21abf,openstack/swift,master,Ia8e62eef5af9e849e86c3ff14ce7f8aaa5f21abf,add reseller_admin_role to sample config,MERGED,2013-09-05 19:27:26.000000000,2013-09-05 20:22:32.000000000,2013-09-05 20:22:31.000000000,"[{'_account_id': 3}, {'_account_id': 794}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-09-05 19:27:26.000000000', 'files': ['etc/proxy-server.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/a9aec73098d5f4a7ab490bb16faab0834598243a', 'message': 'add reseller_admin_role to sample config\n\nChange-Id: Ia8e62eef5af9e849e86c3ff14ce7f8aaa5f21abf\n'}]",0,45310,a9aec73098d5f4a7ab490bb16faab0834598243a,8,5,1,330,,,0,"add reseller_admin_role to sample config

Change-Id: Ia8e62eef5af9e849e86c3ff14ce7f8aaa5f21abf
",git fetch https://review.opendev.org/openstack/swift refs/changes/10/45310/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/proxy-server.conf-sample'],1,a9aec73098d5f4a7ab490bb16faab0834598243a,config_update,# The reseller admin role has the ability to create and delete accounts # reseller_admin_role = ResellerAdmin,,2,0
openstack%2Fceilometer~master~I0622d735935f1eae34542b782beae317416e230c,openstack/ceilometer,master,I0622d735935f1eae34542b782beae317416e230c,add MAINTAINERS file,MERGED,2013-09-05 16:13:53.000000000,2013-09-05 20:22:25.000000000,2013-09-05 20:22:24.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 6537}, {'_account_id': 7399}]","[{'number': 1, 'created': '2013-09-05 16:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1178bdd72536951628e047a13490f98e0ba00906', 'message': 'add MAINTAINERS file\n\nadd MAINTAINERS file to list specialist maintainers for unique\ncomponents of ceilometer\n\nChange-Id: I0622d735935f1eae34542b782beae317416e230c\n'}, {'number': 2, 'created': '2013-09-05 16:19:08.000000000', 'files': ['MAINTAINERS'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a9f147c62a3cc985bd321d193f4f41e3744ae9e0', 'message': 'add MAINTAINERS file\n\nadd MAINTAINERS file to list specialist maintainers for unique\ncomponents of ceilometer\n\nChange-Id: I0622d735935f1eae34542b782beae317416e230c\n'}]",7,45264,a9f147c62a3cc985bd321d193f4f41e3744ae9e0,14,5,2,6537,,,0,"add MAINTAINERS file

add MAINTAINERS file to list specialist maintainers for unique
components of ceilometer

Change-Id: I0622d735935f1eae34542b782beae317416e230c
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/64/45264/2 && git format-patch -1 --stdout FETCH_HEAD,['MAINTAINERS'],1,1178bdd72536951628e047a13490f98e0ba00906,maintainers,"= Generalist Code Reviewers = The current members of ceilometer-core are listed here: https://launchpad.net/~ceilometer-core/+members#active This group can +2 and approve patches in Ceilometer. However, they may choose to seek feedback from the appropriate specialist maintainer before approving a patch if it is in any way controversial or risky. = List of Maintainers = Each has an entry with the following keys: M: Maintainer (irc) <email address> S: Status, one of the following: Maintained: Has an active maintainer Orphan: No current maintainer, feel free to step up! Obsolete: Replaced by newer code, or a dead end, or out-dated F: Wildcard patterns, relative to ceilometer/ == alarms == M: Eoghan Glynn (eglynn) M: Mehdi Abaakouk (sileht) S: Maintained F: alarm/ == api == M: Doug Hellmann (dhellmann) <doug.hellmann@dreamhost.com> S: Maintained F: api/ == events == M: Sandy Walsh (sandywalsh) M: Monsyne Dragon (dragondm) S: Maintained F: collector/, storage/ == pipeline == M: Julien Danjou (jd__) S: Maintained F: publisher/, transformer/, pipeline.py == storage == -- DB2 -- M: Tong Li (litong) <litong01@us.ibm.com> S: Maintained F: storage/impl_db2.py -- HBase -- M: S: Orphan F: storage/impl_hbase.py -- MongoDB -- M: S: Orphan F: storage/impl_mongodb.py -- SQLAlchemy -- M: S: Orphan F: storage/sqlalchemy/, storage/impl_sqlalchemy.py ",,70,0
openstack%2Fglance~master~I5b8bd9e4465d9fe70e9311474bc2b00d9afcf046,openstack/glance,master,I5b8bd9e4465d9fe70e9311474bc2b00d9afcf046,Removes duplicate options registration in registry clients,MERGED,2013-07-24 05:52:41.000000000,2013-09-05 20:17:05.000000000,2013-09-05 20:17:04.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6493}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-07-24 05:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/16d4a3b266518d5cb317eb3cab5e453161990a20', 'message': 'Removes duplicate option registration in registry.client.v2.api\n\nFixes bug #1204359\n\nChange-Id: I5b8bd9e4465d9fe70e9311474bc2b00d9afcf046\n'}, {'number': 2, 'created': '2013-07-25 03:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1a902d2010cfc24c3a603db6b63abbd9523b93cf', 'message': 'Removes duplicate options registration in registry client versions\n\nFixes bug #1204359\n\nChange-Id: I5b8bd9e4465d9fe70e9311474bc2b00d9afcf046\n'}, {'number': 3, 'created': '2013-07-25 03:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/011fb744c39c35aef312e7f502615d0fb13b94be', 'message': 'Removes duplicate options registration in registry clients\n\nFixes bug #1204359\n\nChange-Id: I5b8bd9e4465d9fe70e9311474bc2b00d9afcf046\n'}, {'number': 4, 'created': '2013-07-25 03:14:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e5b6496ff73d1372fa3b2c7aae677cf37747ac35', 'message': 'Removes duplicate options registration in registry clients\n\nFixes bug #1204359\n\nChange-Id: I5b8bd9e4465d9fe70e9311474bc2b00d9afcf046\n'}, {'number': 5, 'created': '2013-07-25 04:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/00d1745c38c7d579e54d75a2dec8795b6db542e2', 'message': 'Removes duplicate options registration in registry clients\n\nFixes bug #1204359\n\nChange-Id: I5b8bd9e4465d9fe70e9311474bc2b00d9afcf046\n'}, {'number': 7, 'created': '2013-07-25 04:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/425f90c23322efbdaddeba123ae729950bbf804c', 'message': 'Removes duplicate options registration in registry clients\n\nFixes bug #1204359\n\nChange-Id: I5b8bd9e4465d9fe70e9311474bc2b00d9afcf046\n'}, {'number': 6, 'created': '2013-07-25 04:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/829d5f03b00c141b31ebce21464b2eefb71c2eb4', 'message': 'Removes duplicate options registration in registry clients\n\nFixes bug #1204359\n\nChange-Id: I5b8bd9e4465d9fe70e9311474bc2b00d9afcf046\n'}, {'number': 8, 'created': '2013-07-25 04:47:49.000000000', 'files': ['glance/registry/client/v2/api.py', 'glance/registry/client/__init__.py', 'glance/registry/client/v1/api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/dbcc1b78ec12e86bc513924e3f3afa9f3b88e3b5', 'message': 'Removes duplicate options registration in registry clients\n\nFixes bug #1204359\n\nChange-Id: I5b8bd9e4465d9fe70e9311474bc2b00d9afcf046\n'}]",3,38417,dbcc1b78ec12e86bc513924e3f3afa9f3b88e3b5,43,8,8,1994,,,0,"Removes duplicate options registration in registry clients

Fixes bug #1204359

Change-Id: I5b8bd9e4465d9fe70e9311474bc2b00d9afcf046
",git fetch https://review.opendev.org/openstack/glance refs/changes/17/38417/5 && git format-patch -1 --stdout FETCH_HEAD,['glance/registry/client/v1/api.py'],1,16d4a3b266518d5cb317eb3cab5e453161990a20,bug/1204359,"_v2_api_mod = 'glance.registry.client.v2.api' CONF.import_opt('registry_client_protocol', _v2_api_mod) CONF.import_opt('registry_client_key_file', _v2_api_mod) CONF.import_opt('registry_client_cert_file', _v2_api_mod) CONF.import_opt('registry_client_ca_file', _v2_api_mod) CONF.import_opt('registry_client_insecure', _v2_api_mod) CONF.import_opt('registry_client_timeout', _v2_api_mod) CONF.import_opt('use_user_token', _v2_api_mod) CONF.import_opt('admin_user', _v2_api_mod) CONF.import_opt('admin_password', _v2_api_mod) CONF.import_opt('admin_tenant_name', _v2_api_mod) CONF.import_opt('auth_url', _v2_api_mod) CONF.import_opt('auth_strategy', _v2_api_mod) CONF.import_opt('auth_region', _v2_api_mod)","registry_client_opts = [ cfg.StrOpt('registry_client_protocol', default='http', help=_('The protocol to use for communication with the ' 'registry server. Either http or https.')), cfg.StrOpt('registry_client_key_file', help=_('The path to the key file to use in SSL connections ' 'to the registry server.')), cfg.StrOpt('registry_client_cert_file', help=_('The path to the cert file to use in SSL connections ' 'to the registry server.')), cfg.StrOpt('registry_client_ca_file', help=_('The path to the certifying authority cert file to ' 'use in SSL connections to the registry server.')), cfg.BoolOpt('registry_client_insecure', default=False, help=_('When using SSL in connections to the registry server, ' 'do not require validation via a certifying ' 'authority.')), cfg.IntOpt('registry_client_timeout', default=600, help=_('The period of time, in seconds, that the API server ' 'will wait for a registry request to complete. A ' 'value of 0 implies no timeout.')), ] registry_client_ctx_opts = [ cfg.BoolOpt('use_user_token', default=True, help=_('Whether to pass through the user token when ' 'making requests to the registry.')), cfg.StrOpt('admin_user', secret=True, help=_('The administrators user name.')), cfg.StrOpt('admin_password', secret=True, help=_('The administrators password.')), cfg.StrOpt('admin_tenant_name', secret=True, help=_('The tenant name of the adminstrative user.')), cfg.StrOpt('auth_url', help=_('The URL to the keystone service.')), cfg.StrOpt('auth_strategy', default='noauth', help=_('The strategy to use for authentication.')), cfg.StrOpt('auth_region', help=_('The region for the authentication service.')), ] CONF.register_opts(registry_client_opts) CONF.register_opts(registry_client_ctx_opts)",14,42
openstack%2Fswift~master~I4ea984780ac2eac458c98fe181684eef4e04beaf,openstack/swift,master,I4ea984780ac2eac458c98fe181684eef4e04beaf,Pep8 final two unit test modules and enforce (12 of 12),MERGED,2013-09-01 19:15:54.000000000,2013-09-05 20:11:10.000000000,2013-09-05 20:11:10.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-09-01 19:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/53e620c6a98b0516ccfd1dbd94e357a499e3dea3', 'message': 'Pep8 final two unit test modules and enforce (12 of 12)\n\nChange-Id: I4ea984780ac2eac458c98fe181684eef4e04beaf\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-09-01 20:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cdcf95bc0110e0afb8085a3d75d4fa7cbcf6a3bc', 'message': 'Pep8 final two unit test modules and enforce (12 of 12)\n\nChange-Id: I4ea984780ac2eac458c98fe181684eef4e04beaf\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 3, 'created': '2013-09-01 20:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f969f3b8cc4842695fd869157a5e741a3cabac6e', 'message': 'Pep8 final two unit test modules and enforce (12 of 12)\n\nChange-Id: I4ea984780ac2eac458c98fe181684eef4e04beaf\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 4, 'created': '2013-09-05 02:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/330a3c39eb435ab910ce703d723731358a80d762', 'message': 'Pep8 final two unit test modules and enforce (12 of 12)\n\nChange-Id: I4ea984780ac2eac458c98fe181684eef4e04beaf\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 5, 'created': '2013-09-05 03:36:44.000000000', 'files': ['test/unit/__init__.py', 'test/unit/obj/test_server.py', 'test/unit/container/test_server.py', 'test/unit/obj/test_diskfile.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/swift/commit/22451b22cb7ec1fbc9b9940ae8f0ef346a36e3ca', 'message': 'Pep8 final two unit test modules and enforce (12 of 12)\n\nWe also fix up any other pep8 failures that snuck in from merges along\nthe way.\n\nChange-Id: I4ea984780ac2eac458c98fe181684eef4e04beaf\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",2,44626,22451b22cb7ec1fbc9b9940ae8f0ef346a36e3ca,25,6,5,6198,,,0,"Pep8 final two unit test modules and enforce (12 of 12)

We also fix up any other pep8 failures that snuck in from merges along
the way.

Change-Id: I4ea984780ac2eac458c98fe181684eef4e04beaf
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/26/44626/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_server.py', 'test/unit/container/test_server.py', 'tox.ini']",3,53e620c6a98b0516ccfd1dbd94e357a499e3dea3,pep8-test,"exclude = .venv,.tox,dist,doc,*egg","exclude = .venv,.tox,dist,doc,test,*egg",927,640
openstack%2Ftrove~master~I9d7c78ea1d11ac89b2692ed069f01e102ad708d2,openstack/trove,master,I9d7c78ea1d11ac89b2692ed069f01e102ad708d2,jenkins tests,ABANDONED,2013-09-05 15:32:27.000000000,2013-09-05 20:05:52.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}]","[{'number': 1, 'created': '2013-09-05 15:32:27.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/trove/commit/74b57316de0bad3e7c4ba9a967aec196fda39f06', 'message': 'jenkins tests\n\nChange-Id: I9d7c78ea1d11ac89b2692ed069f01e102ad708d2\n'}]",0,45251,74b57316de0bad3e7c4ba9a967aec196fda39f06,4,2,1,8415,,,0,"jenkins tests

Change-Id: I9d7c78ea1d11ac89b2692ed069f01e102ad708d2
",git fetch https://review.opendev.org/openstack/trove refs/changes/51/45251/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,74b57316de0bad3e7c4ba9a967aec196fda39f06,123,Trove is Database as a Service for Open Stack..,Trove is Database as a Service for Open Stack.,1,1
openstack%2Fnova~master~I3c7f11c53594118456d0cd62eb1ddf74634b77c3,openstack/nova,master,I3c7f11c53594118456d0cd62eb1ddf74634b77c3,"Port ""Make flavors is_public option .."" to v3 tree",MERGED,2013-08-14 05:37:28.000000000,2013-09-05 20:01:05.000000000,2013-09-05 20:01:03.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2835}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}]","[{'number': 1, 'created': '2013-08-14 05:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/588416ab1ecf0eb56f7348ac9d32ff35b226fafe', 'message': 'Port ""Make flavors is_public option .."" to v3 tree\n\nThe following commit(I5b37fa0bb19683fe1642fd81222547d4a317054e) have\nnot been merged to v3 tree now, because the commit was merged to the\nexisting api after porting flavors.py to v3 tree.\n\n    commit b65d506a5f9d9b2b20777a9aceb44a8ffed6a5de\n    Author: Russell Bryant <rbryant@redhat.com>\n    Date:   Thu Jun 27 21:00:05 2013 +0000\n\n        Make flavors is_public option actually work\n\nThis patch ports the commit to v3 tree.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I3c7f11c53594118456d0cd62eb1ddf74634b77c3\n'}, {'number': 2, 'created': '2013-08-14 07:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfb674055fed5fcf70b47eb2bcb22d954b7b3253', 'message': 'Port ""Make flavors is_public option .."" to v3 tree\n\nThe following commit(I5b37fa0bb19683fe1642fd81222547d4a317054e) have\nnot been merged to v3 tree now, because the commit was merged to the\nexisting api after porting flavors.py to v3 tree.\n\n    commit b65d506a5f9d9b2b20777a9aceb44a8ffed6a5de\n    Author: Russell Bryant <rbryant@redhat.com>\n    Date:   Thu Jun 27 21:00:05 2013 +0000\n\n        Make flavors is_public option actually work\n\nThis patch ports the commit to v3 tree.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I3c7f11c53594118456d0cd62eb1ddf74634b77c3\n'}, {'number': 3, 'created': '2013-09-04 23:46:01.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/flavor_access.py', 'nova/tests/api/openstack/compute/plugins/v3/test_flavors.py', 'nova/tests/api/openstack/compute/plugins/v3/test_flavor_access.py', 'nova/api/openstack/compute/plugins/v3/flavors.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e220baf1b10ebeec11151cb8e8a50a230ab42c49', 'message': 'Port ""Make flavors is_public option .."" to v3 tree\n\nThe following commit(I5b37fa0bb19683fe1642fd81222547d4a317054e) have\nnot been merged to v3 tree now, because the commit was merged to the\nexisting api after porting flavors.py to v3 tree.\n\n    commit b65d506a5f9d9b2b20777a9aceb44a8ffed6a5de\n    Author: Russell Bryant <rbryant@redhat.com>\n    Date:   Thu Jun 27 21:00:05 2013 +0000\n\n        Make flavors is_public option actually work\n\nThis patch ports the commit to v3 tree.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: I3c7f11c53594118456d0cd62eb1ddf74634b77c3\n'}]",0,41843,e220baf1b10ebeec11151cb8e8a50a230ab42c49,19,7,3,6167,,,0,"Port ""Make flavors is_public option .."" to v3 tree

The following commit(I5b37fa0bb19683fe1642fd81222547d4a317054e) have
not been merged to v3 tree now, because the commit was merged to the
existing api after porting flavors.py to v3 tree.

    commit b65d506a5f9d9b2b20777a9aceb44a8ffed6a5de
    Author: Russell Bryant <rbryant@redhat.com>
    Date:   Thu Jun 27 21:00:05 2013 +0000

        Make flavors is_public option actually work

This patch ports the commit to v3 tree.

Partially implements blueprint nova-v3-api

Change-Id: I3c7f11c53594118456d0cd62eb1ddf74634b77c3
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/41843/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/flavor_access.py', 'nova/tests/api/openstack/compute/plugins/v3/test_flavors.py', 'nova/tests/api/openstack/compute/plugins/v3/test_flavor_access.py', 'nova/api/openstack/compute/plugins/v3/flavors.py']",4,588416ab1ecf0eb56f7348ac9d32ff35b226fafe,bp/nova-v3-api," flavor = flavors.get_flavor_by_flavor_id(id, ctxt=context)", flavor = flavors.get_flavor_by_flavor_id(id),5,5
openstack%2Ftaskflow~master~I95e3c6000beef33002e45716d708551f1b8baa70,openstack/taskflow,master,I95e3c6000beef33002e45716d708551f1b8baa70,Use pattern -> action translators,ABANDONED,2013-09-04 20:36:43.000000000,2013-09-05 19:49:00.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-09-04 20:36:43.000000000', 'files': ['taskflow/engines/action_engine/seq_action.py', 'taskflow/blocks/patterns.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/parallel_action.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/engines/action_engine/base_action.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d470e825ecc127bc82de9241af0127069bb1357c', 'message': 'Use pattern -> action translators\n\nInstead of having an action map allow for engines to instead\njust use a provided translator class to do the pattern to\naction translation. This makes actions require less logic to\nthemselves recursively go over given patterns. Also introduces\nthe concept of compilation which activates this translation.\n\n- Also includes a drive by commit for a lock around running so\n  that 2 users can not run the same engine at the same time.\n\nChange-Id: I95e3c6000beef33002e45716d708551f1b8baa70\n'}]",0,45118,d470e825ecc127bc82de9241af0127069bb1357c,2,1,1,1297,,,0,"Use pattern -> action translators

Instead of having an action map allow for engines to instead
just use a provided translator class to do the pattern to
action translation. This makes actions require less logic to
themselves recursively go over given patterns. Also introduces
the concept of compilation which activates this translation.

- Also includes a drive by commit for a lock around running so
  that 2 users can not run the same engine at the same time.

Change-Id: I95e3c6000beef33002e45716d708551f1b8baa70
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/18/45118/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/seq_action.py', 'taskflow/blocks/patterns.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/parallel_action.py', 'taskflow/engines/action_engine/base_action.py', 'taskflow/tests/unit/test_action_engine.py']",6,d470e825ecc127bc82de9241af0127069bb1357c,, engine.compile() with self.assertRaises(TypeError) as err: engine = self._make_engine(flow) engine.compile(), with self.assertRaises(ValueError) as err: self._make_engine(flow),98,41
openstack%2Ftaskflow~master~I6a87f5259d22760a4e6d64a7ea121c840c6cad78,openstack/taskflow,master,I6a87f5259d22760a4e6d64a7ea121c840c6cad78,Avoid exposing the failures,ABANDONED,2013-09-04 19:49:09.000000000,2013-09-05 19:48:42.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-09-04 19:49:09.000000000', 'files': ['taskflow/engines/action_engine/engine.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e08696f2e23459d37189600808638f35cb0568fa', 'message': 'Avoid exposing the failures\n\nFailures are an internal list held by the action engine\nand likely should not be exposed. Also if an engine is ran\ntwice then the failures should be reset so that previous\nfailures are not rethrown.\n\nChange-Id: I6a87f5259d22760a4e6d64a7ea121c840c6cad78\n'}]",0,45109,e08696f2e23459d37189600808638f35cb0568fa,2,1,1,1297,,,0,"Avoid exposing the failures

Failures are an internal list held by the action engine
and likely should not be exposed. Also if an engine is ran
twice then the failures should be reset so that previous
failures are not rethrown.

Change-Id: I6a87f5259d22760a4e6d64a7ea121c840c6cad78
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/09/45109/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/action_engine/engine.py'],1,e08696f2e23459d37189600808638f35cb0568fa,,from taskflow import exceptions as exc self._failures = [] if self._failures: if len(self._failures) == 1: self._failures[0].reraise() else: exc_infos = [f.exc_info for f in self._failures] raise exc.LinkedException.link(exc_infos) def _reset(self): self._failures = [] def run(self): self._reset() self._failures.append(result), self.failures = [] if self.failures: self.failures[0].reraise() def run(self): self.failures.append(result),13,4
openstack%2Ftaskflow~master~I3247a1c8815ff0de8fb95e853b042e691278b80f,openstack/taskflow,master,I3247a1c8815ff0de8fb95e853b042e691278b80f,Allow reverting to be a normal flow,ABANDONED,2013-09-02 01:52:40.000000000,2013-09-05 19:48:27.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2013-09-02 01:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ea76f0c31c84d623e77336badc3ffa2c5c82c5f9', 'message': 'Allow reverting to be a normal task\n\nInstead of always requiring reverting to be different\nand requiring reverting to use only a rollback accumulator\nit is nicer if reverting can just be another type of flow\nthat is created by the flow running a set of tasks.\n\nThis creates the ability to do that making reverting just\nlike a normal flow, allowing it to be customized to the\nflow developers desires.\n\nChange-Id: I3247a1c8815ff0de8fb95e853b042e691278b80f\n'}, {'number': 2, 'created': '2013-09-02 01:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cb996cc5df3995faf3d24191795cdd89d1466a79', 'message': 'Allow reverting to be a normal task\n\nInstead of always requiring reverting to be different\nand requiring reverting to use only a rollback accumulator\nit is nicer if reverting can just be another type of flow\nthat is created by the flow running a set of tasks.\n\nThis creates the ability to do that making reverting just\nlike a normal flow, allowing it to be customized to the\nflow developers desires.\n\nChange-Id: I3247a1c8815ff0de8fb95e853b042e691278b80f\n'}, {'number': 3, 'created': '2013-09-02 01:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f3d9f72fd1f2b5656880df167264525d07ea839c', 'message': 'Allow reverting to be a normal task\n\nInstead of always requiring reverting to be different\nand requiring reverting to use only a rollback accumulator\nit is nicer if reverting can just be another type of flow\nthat is created by the flow running a set of tasks.\n\nThis creates the ability to do that making reverting just\nlike a normal flow, allowing it to be customized to the\nflow developers desires.\n\nChange-Id: I3247a1c8815ff0de8fb95e853b042e691278b80f\n'}, {'number': 4, 'created': '2013-09-02 02:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/434af315d16594b3ae47c53294eaaebcdc48dab4', 'message': 'Allow reverting to be a normal task\n\nInstead of always requiring reverting to be different\nand requiring reverting to use only a rollback accumulator\nit is nicer if reverting can just be another type of flow\nthat is created by the flow running a set of tasks.\n\nThis creates the ability to do that making reverting just\nlike a normal flow, allowing it to be customized to the\nflow developers desires.\n\nChange-Id: I3247a1c8815ff0de8fb95e853b042e691278b80f\n'}, {'number': 5, 'created': '2013-09-03 06:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0e7af1f35ee51f4f43f86e1bf0d466af77bc1cb8', 'message': 'Allow reverting to be a normal task\n\nInstead of always requiring reverting to be different\nand requiring reverting to use only a rollback accumulator\nit is nicer if reverting can just be another type of flow\nthat is created by the active flow.\n\nThis creates the ability to make reverting just\na normal flow, allowing it to be customized to the\nflow developers desires.\n\nChange-Id: I3247a1c8815ff0de8fb95e853b042e691278b80f\n'}, {'number': 6, 'created': '2013-09-03 06:41:01.000000000', 'files': ['taskflow/flow.py', 'taskflow/tests/unit/test_linear_flow.py', 'taskflow/patterns/linear_flow.py', 'taskflow/task.py', 'taskflow/utils.py', 'taskflow/tests/unit/test_utils.py', 'taskflow/patterns/graph_flow.py', 'taskflow/patterns/threaded_flow.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ba5b4172335a6896cb0bfec91f2c40964f0ec83d', 'message': 'Allow reverting to be a normal flow\n\nInstead of always requiring reverting to be different\nand requiring reverting to use only a rollback accumulator\nit is nicer if reverting can just be another type of flow\nthat is created by the active flow.\n\nThis creates the ability to make reverting just\na normal flow, allowing it to be customized to the\nflow developers desires.\n\nChange-Id: I3247a1c8815ff0de8fb95e853b042e691278b80f\n'}]",0,44633,ba5b4172335a6896cb0bfec91f2c40964f0ec83d,12,2,6,1297,,,0,"Allow reverting to be a normal flow

Instead of always requiring reverting to be different
and requiring reverting to use only a rollback accumulator
it is nicer if reverting can just be another type of flow
that is created by the active flow.

This creates the ability to make reverting just
a normal flow, allowing it to be customized to the
flow developers desires.

Change-Id: I3247a1c8815ff0de8fb95e853b042e691278b80f
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/33/44633/4 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/flow.py', 'taskflow/patterns/linear_flow.py', 'taskflow/tests/unit/test_linear_flow.py', 'taskflow/task.py', 'taskflow/utils.py', 'taskflow/tests/unit/test_utils.py', 'taskflow/patterns/graph_flow.py', 'taskflow/patterns/threaded_flow.py']",8,ea76f0c31c84d623e77336badc3ffa2c5c82c5f9,revert-flow,"from taskflow.patterns import linear_flow as lffrom taskflow import task def add(self, task, uuid=None, timeout=None, infer=True): runner = ThreadRunner(task, uuid, self, timeout) def _get_undoer(self, context, cause): """"""Form a linear flow that will be used to go back through the tasks that we finished or were partially started in reverse order. This method can be overriden to create other types of reverting flows and/or strategies that may be more specific or better suited to your desired way of reverting the set of side-effects this flow may have caused. """""" which_ran = [r for r in self._graph.nodes_iter() if r.has_ran()] # TODO(harlowja): consolidate this with the one in linear_flow since # they are pretty much the same logic. undoer = lf.Flow(utils.reverse_text(self.name)) undoer._task_state_map[states.STARTED] = states.REVERTING undoer._task_state_map[states.SUCCESS] = states.REVERTED undoer.task_notifier = self.task_notifier for r in which_ran: undoer.add(task.RevertTask(r.task, result=r.result), uuid=r.uuid) return undoer undoer = self._get_undoer(context, cause) if undoer is not None: undoer.run(context, cause) def __init__(self, task, uuid, flow, timeout): super(ThreadRunner, self).__init__(task, uuid)"," def add(self, task, timeout=None, infer=True): runner = ThreadRunner(task, self, timeout) accum = utils.RollbackAccumulator() for r in self._graph.nodes_iter(): if r.has_ran(): accum.add(utils.Rollback(context, r, self, self.task_notifier)) accum.rollback(cause) def __init__(self, task, flow, timeout): super(ThreadRunner, self).__init__(task)",112,161
openstack%2Ftaskflow~master~Id9527f095703aaebe3fa51cb941f3141905e43e9,openstack/taskflow,master,Id9527f095703aaebe3fa51cb941f3141905e43e9,Convert runners -> execute,ABANDONED,2013-09-03 22:35:28.000000000,2013-09-05 19:48:07.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-09-03 22:35:28.000000000', 'files': ['taskflow/patterns/linear_flow.py', 'taskflow/utils/flow_utils.py', 'taskflow/patterns/threaded_flow.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/77f00021d6df8b4258a3775e5fc8f88cd21042b1', 'message': 'Convert runners -> execute\n\nIn order to have parity with the underlying task we\nshould also rename the runners __call__ -> execute.\n\nChange-Id: Id9527f095703aaebe3fa51cb941f3141905e43e9\n'}]",0,44968,77f00021d6df8b4258a3775e5fc8f88cd21042b1,2,1,1,1297,,,0,"Convert runners -> execute

In order to have parity with the underlying task we
should also rename the runners __call__ -> execute.

Change-Id: Id9527f095703aaebe3fa51cb941f3141905e43e9
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/68/44968/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/patterns/linear_flow.py', 'taskflow/utils/flow_utils.py', 'taskflow/patterns/threaded_flow.py']",3,77f00021d6df8b4258a3775e5fc8f88cd21042b1,," def run_single(r, *args, **kwargs): return r.execute(*args, **kwargs) def run_all(result_cb, args, kwargs): executor.submit(functools.partial(run_single, r), *args, **kwargs) run_all(get_resumer_cb(), args, kwargs) def execute(self, context, *args, **kwargs): super(ThreadRunner, self).execute(*args, **kwargs)"," def run_it(result_cb, args, kwargs): executor.submit(r, *args, **kwargs) run_it(get_resumer_cb(), args, kwargs) def __call__(self, context, *args, **kwargs): super(ThreadRunner, self).__call__(*args, **kwargs)",11,7
openstack%2Fzaqar~master~Id38295f1e607226a4259be7744e6ce2d7b6de12e,openstack/zaqar,master,Id38295f1e607226a4259be7744e6ce2d7b6de12e,feat(storage): configurable default paging size,MERGED,2013-08-20 15:54:52.000000000,2013-09-05 19:26:12.000000000,2013-09-05 19:26:12.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 6944}]","[{'number': 1, 'created': '2013-08-20 15:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/8db728f8ab7ad29c1c0f81402629c830cff9aba5', 'message': 'feat(storage): configurable default paging size\n\nThis change add the following options to the config file:\n\n    [limits:storage]\n    default_queue_paging = 10\n    default_message_paging = 10\n\nSo that the default value of the  ""limit"" URI param is now configurable.\n\nThis patch also removes the ""actions"" cruft.\n\nChange-Id: Id38295f1e607226a4259be7744e6ce2d7b6de12e\n'}, {'number': 2, 'created': '2013-08-20 16:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/60fd9598c795c107561b3a331d59653ff1327edc', 'message': 'feat(storage): configurable default paging size\n\nThis change add the following options to the config file:\n\n    [limits:storage]\n    default_queue_paging = 10\n    default_message_paging = 10\n\nSo that the default value of the  ""limit"" URI param is now configurable.\n\nThis patch also removes the ""actions"" cruft.\n\nChange-Id: Id38295f1e607226a4259be7744e6ce2d7b6de12e\n'}, {'number': 3, 'created': '2013-08-20 16:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/bf26a7f21171161ddab16aac56ceaf8fc3f3a719', 'message': 'feat(storage): configurable default paging size\n\nThis change add the following options to the config file:\n\n    [limits:storage]\n    default_queue_paging = 10\n    default_message_paging = 10\n\nSo that the default value of the  ""limit"" URI param is now configurable.\n\nThis patch also removes the ""actions"" cruft.\n\nImplements: blueprint configurable-default-paging\nChange-Id: Id38295f1e607226a4259be7744e6ce2d7b6de12e\n'}, {'number': 4, 'created': '2013-08-21 18:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/2490d8f50c4272bfbd4b3737e898e1529188a637', 'message': 'feat(storage): configurable default paging size\n\nThis change add the following options to the config file:\n\n    [limits:storage]\n    default_queue_paging = 10\n    default_message_paging = 10\n\nSo that the default value of the  ""limit"" URI param is now configurable.\n\nThis patch also removes the ""actions"" cruft.\n\nImplements: blueprint configurable-default-paging\nChange-Id: Id38295f1e607226a4259be7744e6ce2d7b6de12e\n'}, {'number': 5, 'created': '2013-08-26 13:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9386d249336cfc4f6d4839820c76b86850306f45', 'message': 'feat(storage): configurable default paging size\n\nThis change add the following options to the config file:\n\n    [limits:storage]\n    default_queue_paging = 10\n    default_message_paging = 10\n\nSo that the default value of the  ""limit"" URI param is now configurable.\n\nThis patch also removes the ""actions"" cruft.\n\nImplements: blueprint configurable-default-paging\nChange-Id: Id38295f1e607226a4259be7744e6ce2d7b6de12e\n'}, {'number': 6, 'created': '2013-09-05 18:45:46.000000000', 'files': ['marconi/storage/mongodb/queues.py', 'marconi/storage/sqlite/messages.py', 'etc/marconi.conf-sample', 'marconi/storage/sqlite/claims.py', 'marconi/storage/sqlite/queues.py', 'marconi/tests/transport/wsgi/test_default_limits.py', 'marconi/storage/base.py', 'marconi/storage/mongodb/claims.py', 'marconi/storage/mongodb/messages.py', 'marconi/tests/util/faulty_storage.py', 'marconi/tests/etc/wsgi_sqlite_default_limits.conf'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9e5754695df34587ca6545a67c48f8c78584978d', 'message': 'feat(storage): configurable default paging size\n\nThis change add the following options to the config file:\n\n    [limits:storage]\n    default_queue_paging = 10\n    default_message_paging = 10\n\nSo that the default value of the  ""limit"" URI param is now configurable.\n\nThis patch also removes the ""actions"" cruft.\n\nImplements: blueprint configurable-default-paging\nChange-Id: Id38295f1e607226a4259be7744e6ce2d7b6de12e\n'}]",2,42933,9e5754695df34587ca6545a67c48f8c78584978d,26,5,6,6943,,,0,"feat(storage): configurable default paging size

This change add the following options to the config file:

    [limits:storage]
    default_queue_paging = 10
    default_message_paging = 10

So that the default value of the  ""limit"" URI param is now configurable.

This patch also removes the ""actions"" cruft.

Implements: blueprint configurable-default-paging
Change-Id: Id38295f1e607226a4259be7744e6ce2d7b6de12e
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/33/42933/4 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/storage/mongodb/queues.py', 'marconi/storage/sqlite/messages.py', 'etc/marconi.conf-sample', 'marconi/storage/sqlite/claims.py', 'marconi/storage/sqlite/queues.py', 'marconi/storage/base.py', 'marconi/storage/mongodb/claims.py', 'marconi/storage/mongodb/messages.py', 'marconi/tests/util/faulty_storage.py']",9,8db728f8ab7ad29c1c0f81402629c830cff9aba5,bp/configurable-default-paging,," def actions(self, name, project=None, marker=None, limit=10): raise NotImplementedError() ",45,31
openstack%2Frequirements~master~I50e69323dcbc42843778f49f62b8c8b5ffee1331,openstack/requirements,master,I50e69323dcbc42843778f49f62b8c8b5ffee1331,Drop Cheetah global requirement,MERGED,2013-08-05 11:50:16.000000000,2013-09-05 19:22:00.000000000,2013-09-05 19:22:00.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 4375}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-08-05 11:50:16.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/3af5517040d593d2badde8456fb886f6b181c674', 'message': 'Drop Cheetah global requirement\n\nNova was the last project depending on it but moved to Jinja2.\n\nChange-Id: I50e69323dcbc42843778f49f62b8c8b5ffee1331\n'}]",0,40206,3af5517040d593d2badde8456fb886f6b181c674,18,6,1,4375,,,0,"Drop Cheetah global requirement

Nova was the last project depending on it but moved to Jinja2.

Change-Id: I50e69323dcbc42843778f49f62b8c8b5ffee1331
",git fetch https://review.opendev.org/openstack/requirements refs/changes/06/40206/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,3af5517040d593d2badde8456fb886f6b181c674,master-drop-cheetah,,Cheetah>=2.4.4,0,1
openstack%2Fpython-ceilometerclient~master~I42ed34362bb840fe3a6d1d22e28beba8963fdb85,openstack/python-ceilometerclient,master,I42ed34362bb840fe3a6d1d22e28beba8963fdb85,Added support for running the tests under PyPy with tox,MERGED,2013-09-05 16:57:54.000000000,2013-09-05 18:53:31.000000000,2013-09-05 18:53:31.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-09-05 16:57:54.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/3569e6586167f18682acc5843e4d5143355ac2ba', 'message': 'Added support for running the tests under PyPy with tox\n\nThis is a precursor to having them run under check and gate.\n\nChange-Id: I42ed34362bb840fe3a6d1d22e28beba8963fdb85\n'}]",0,45276,3569e6586167f18682acc5843e4d5143355ac2ba,6,3,1,7680,,,0,"Added support for running the tests under PyPy with tox

This is a precursor to having them run under check and gate.

Change-Id: I42ed34362bb840fe3a6d1d22e28beba8963fdb85
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/76/45276/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,3569e6586167f18682acc5843e4d5143355ac2ba,tox-pypy,"envlist = py26,py27,pypy,pep8","envlist = py26,py27,pep8",1,1
openstack%2Fpycadf~master~Icd90e96264725ee274893bbd25f4b25cdb830598,openstack/pycadf,master,Icd90e96264725ee274893bbd25f4b25cdb830598,ensure unique id and timestamp defaults,MERGED,2013-09-05 18:40:08.000000000,2013-09-05 18:53:25.000000000,2013-09-05 18:53:25.000000000,"[{'_account_id': 3}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-09-05 18:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/5fecde4d131490ca580fd7b73b9663818f4d3a38', 'message': 'ensure unique id and timestamp defaults\n\nceilometer CADF_EVENT.id and CADF_EVENT.eventTime always default\nto the same id and timestamp.\nfix other bad default values in __init__()\n\nChange-Id: Icd90e96264725ee274893bbd25f4b25cdb830598\nFixes: Bug #1221379\n'}, {'number': 2, 'created': '2013-09-05 18:44:48.000000000', 'files': ['pycadf/resource.py', 'pycadf/event.py', 'pycadf/tests/test_cadf_spec.py', 'pycadf/metric.py'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/20e65dda8232bd30dc585d2184ed307474b4bcb6', 'message': 'ensure unique id and timestamp defaults\n\nceilometer CADF_EVENT.id and CADF_EVENT.eventTime always default\nto the same id and timestamp.\nfix other bad default values in __init__()\n\nChange-Id: Icd90e96264725ee274893bbd25f4b25cdb830598\nFixes: Bug #1221379\n'}]",0,45301,20e65dda8232bd30dc585d2184ed307474b4bcb6,7,2,2,6537,,,0,"ensure unique id and timestamp defaults

ceilometer CADF_EVENT.id and CADF_EVENT.eventTime always default
to the same id and timestamp.
fix other bad default values in __init__()

Change-Id: Icd90e96264725ee274893bbd25f4b25cdb830598
Fixes: Bug #1221379
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/01/45301/2 && git format-patch -1 --stdout FETCH_HEAD,"['pycadf/resource.py', 'pycadf/event.py', 'pycadf/metric.py', 'pycadf/tests/test_cadf_spec.py']",4,5fecde4d131490ca580fd7b73b9663818f4d3a38,bug/1221379,"from time import sleep def test_event_unique(self): ev = event.Event(eventType='activity', initiator=resource.Resource(typeURI='storage'), initiatorId=identifier.generate_uuid(), action='read', target=resource.Resource(typeURI='storage'), targetId=identifier.generate_uuid(), observer='target', outcome='success') sleep(1) ev2 = event.Event(eventType='activity', initiator=resource.Resource(typeURI='storage'), initiatorId=identifier.generate_uuid(), action='read', target=resource.Resource(typeURI='storage'), targetId=identifier.generate_uuid(), observer='target', outcome='success') self.assertNotEqual(ev.id, ev2.id) self.assertNotEqual(ev.eventTime, ev2.eventTime)",,33,11
openstack%2Fglance~master~If0e5ffe117200fbfb967c8c95a63608f12dbba58,openstack/glance,master,If0e5ffe117200fbfb967c8c95a63608f12dbba58,Publish recent api changes as v2.2,MERGED,2013-09-05 00:10:45.000000000,2013-09-05 18:53:15.000000000,2013-09-05 18:53:14.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-09-05 00:10:45.000000000', 'files': ['glance/tests/unit/test_versions.py', 'glance/tests/functional/test_api.py', 'glance/tests/functional/v1/test_ssl.py', 'glance/api/middleware/version_negotiation.py', 'glance/api/versions.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/249f800de13867af31590df557a715cabbc2e1d6', 'message': 'Publish recent api changes as v2.2\n\nThroughout the Havana development cycle, we have added several\nfeatures to the v2 api, without breaking backwards compatibility.\nSo this change bumps up our minor version number.\n\nChange-Id: If0e5ffe117200fbfb967c8c95a63608f12dbba58\n'}]",0,45142,249f800de13867af31590df557a715cabbc2e1d6,10,4,1,616,,,0,"Publish recent api changes as v2.2

Throughout the Havana development cycle, we have added several
features to the v2 api, without breaking backwards compatibility.
So this change bumps up our minor version number.

Change-Id: If0e5ffe117200fbfb967c8c95a63608f12dbba58
",git fetch https://review.opendev.org/openstack/glance refs/changes/42/45142/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_versions.py', 'glance/tests/functional/test_api.py', 'glance/tests/functional/v1/test_ssl.py', 'glance/api/middleware/version_negotiation.py', 'glance/api/versions.py']",5,249f800de13867af31590df557a715cabbc2e1d6,v2.2," build_version_object(2.2, 'v2', 'CURRENT'), build_version_object(2.1, 'v2', 'SUPPORTED'),"," build_version_object(2.1, 'v2', 'CURRENT'),",40,8
openstack%2Fpython-cinderclient~master~Ide99a836cd601453624c7a562b7256c86bd46811,openstack/python-cinderclient,master,Ide99a836cd601453624c7a562b7256c86bd46811,Don't need to init testr explicitly,MERGED,2013-09-03 10:19:53.000000000,2013-09-05 18:53:13.000000000,2013-09-05 18:53:13.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 6969}, {'_account_id': 7774}]","[{'number': 1, 'created': '2013-09-03 10:19:53.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/b757c348b758fb5517cc0a08675b6c3ae8a7538e', 'message': 'Don\'t need to init testr explicitly\n\nIn run_tests.sh, function init_testr will initialize testr if the\ndirectory .testrepository is not existed. Actually, testr will do\nthe check before run the test:\n\nIn Python package testrepository, setuptools_command.py:Testr.run\n\n68 def run(self):\n69 """"""Set up testr repo, then run testr""""""\n70     if not os.path.isdir("".testrepository""):\n71     self._run_testr(""init"")\n\nSo, init_testr can be removed safely.\n\nFixes Bug #1220147\n\nChange-Id: Ide99a836cd601453624c7a562b7256c86bd46811\n'}]",0,44841,b757c348b758fb5517cc0a08675b6c3ae8a7538e,11,5,1,7774,,,0,"Don't need to init testr explicitly

In run_tests.sh, function init_testr will initialize testr if the
directory .testrepository is not existed. Actually, testr will do
the check before run the test:

In Python package testrepository, setuptools_command.py:Testr.run

68 def run(self):
69 """"""Set up testr repo, then run testr""""""
70     if not os.path.isdir("".testrepository""):
71     self._run_testr(""init"")

So, init_testr can be removed safely.

Fixes Bug #1220147

Change-Id: Ide99a836cd601453624c7a562b7256c86bd46811
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/41/44841/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,b757c348b758fb5517cc0a08675b6c3ae8a7538e,bug/1220147,,function init_testr { if [ ! -d .testrepository ]; then ${wrapper} testr init fi }init_testr,0,6
openstack%2Fopenstack-manuals~stable%2Fgrizzly~I94cb46cb989385bcb2fe00dd9c91e61d3e00f994,openstack/openstack-manuals,stable/grizzly,I94cb46cb989385bcb2fe00dd9c91e61d3e00f994,"For Ubuntu/Debian, users reported problems with rootwrap and sudoers.",MERGED,2013-09-05 16:23:50.000000000,2013-09-05 18:13:46.000000000,2013-09-05 18:13:46.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-09-05 16:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/70bf3d55d2ad47895568fb94c46c068cd2671a0b', 'message': 'For Ubuntu/Debian, users reported problems with rootwrap and sudoers.\n\nAdds a conditional step for those users to check the settings.\n\nFix bug 1218665\n\nChange-Id: I94cb46cb989385bcb2fe00dd9c91e61d3e00f994\n'}, {'number': 2, 'created': '2013-09-05 18:08:15.000000000', 'files': ['doc/src/docbkx/basic-install/src/basic-install_network-services.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5b07c487ae544100a5d2105bc9a446cd8fb4e1f6', 'message': 'For Ubuntu/Debian, users reported problems with rootwrap and sudoers.\n\nAdds a conditional step for those users to check the settings.\n\nCloses-bug: 1218665\n\nChange-Id: I94cb46cb989385bcb2fe00dd9c91e61d3e00f994\n'}]",0,45268,5b07c487ae544100a5d2105bc9a446cd8fb4e1f6,9,3,2,964,,,0,"For Ubuntu/Debian, users reported problems with rootwrap and sudoers.

Adds a conditional step for those users to check the settings.

Closes-bug: 1218665

Change-Id: I94cb46cb989385bcb2fe00dd9c91e61d3e00f994
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/68/45268/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/basic-install/src/basic-install_network-services.xml'],1,70bf3d55d2ad47895568fb94c46c068cd2671a0b,bug/1218665," <step os=""ubuntu;debian""><para>Check the settings in <filename>/etc/quantum/rootwrap.conf</filename> to ensure the sudoers file matches the settings for root_helper in <filename>/etc/quantum/quantum.conf</filename>.</para></step>",,1,0
openstack%2Fcookbook-openstack-telemetry~master~I0a17e065f630f8506a5dd94b3a1ff8ed44482adc,openstack/cookbook-openstack-telemetry,master,I0a17e065f630f8506a5dd94b3a1ff8ed44482adc,Fix naming inconsistency for db password databag,MERGED,2013-09-05 06:04:52.000000000,2013-09-05 17:32:51.000000000,2013-09-05 17:32:51.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 4277}, {'_account_id': 6530}]","[{'number': 1, 'created': '2013-09-05 06:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/05799fe255ca5b85f8573f5d9ccf9b55e687663b', 'message': ""Fix naming inconsistency for db password databag\n\nThe other openstack services cookbooks refer to the db password databag by the\nservice name (nova, swift, quantum) and therefore openstack-metering cookbook\nshould call the db password databag by service name 'ceilometer' to make it\nconsistent\n\nChange-Id: I0a17e065f630f8506a5dd94b3a1ff8ed44482adc\n""}, {'number': 2, 'created': '2013-09-05 17:24:04.000000000', 'files': ['CHANGELOG.md', 'metadata.rb', 'recipes/common.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/93e308a16322d2c9f3e56a468406093ceafee8e4', 'message': ""Fix naming inconsistency for db password databag\n\nThe other openstack services cookbooks refer to the db password databag by the\nservice name (nova, swift, quantum) and therefore openstack-metering cookbook\nshould call the db password databag by service name 'ceilometer' to make it\nconsistent\n\nChange-Id: I0a17e065f630f8506a5dd94b3a1ff8ed44482adc\n""}]",0,45174,93e308a16322d2c9f3e56a468406093ceafee8e4,9,4,2,4277,,,0,"Fix naming inconsistency for db password databag

The other openstack services cookbooks refer to the db password databag by the
service name (nova, swift, quantum) and therefore openstack-metering cookbook
should call the db password databag by service name 'ceilometer' to make it
consistent

Change-Id: I0a17e065f630f8506a5dd94b3a1ff8ed44482adc
",git fetch https://review.opendev.org/openstack/cookbook-openstack-telemetry refs/changes/74/45174/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.rb', 'recipes/common.rb']",2,05799fe255ca5b85f8573f5d9ccf9b55e687663b,master,"db_pass = db_password ""ceilometer""","db_pass = db_password ""openstack-metering""",2,2
openstack%2Fpuppet-ceilometer~master~Ic09f5232b322cde687d663d1ef38ef0fd12f32ff,openstack/puppet-ceilometer,master,Ic09f5232b322cde687d663d1ef38ef0fd12f32ff,Inline a custom file_line provider to fix agent.,MERGED,2013-08-29 17:02:58.000000000,2013-09-05 17:13:42.000000000,2013-09-05 16:11:01.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1607}, {'_account_id': 1918}, {'_account_id': 2265}, {'_account_id': 5241}]","[{'number': 1, 'created': '2013-08-29 17:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/4369af4f7c1677480f47439be76f81ffc5c21e2f', 'message': ""Inline a custom file_line provider to fix agent.\n\nFixes an issue in the ceilometer::agent::compute manifest\nwhere nova.conf config values for the notification_driver\nwould get added to the wrong section (always to the end of\nthe file).\n\nAs part of the fix a custom file_line 'after' provider which\nsupports a new after option has been added.\nThis allows us to have some control over which section *new*\nfile lines go into. If there are any pre-existing matching\nlines in the file the assumption is that they are already in\nthe correct section and can be edited in place.\n\nNOTE: I've submitted a pull request to the upstream stdlib repo here\nto add the new 'after' option:\n\n  https://github.com/puppetlabs/puppetlabs-stdlib/pull/174\n\nOnce this (or something better) lands in stdlib we can update\npuppet-ceilometer to use it.\n\nFixes LP Bug #1217867\n\nChange-Id: Ic09f5232b322cde687d663d1ef38ef0fd12f32ff\n""}, {'number': 2, 'created': '2013-08-29 17:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/fa051be5016a0c10f7a46f625cabd635bf514636', 'message': ""Inline a custom file_line provider to fix agent.\n\nFixes an issue in the ceilometer::agent::compute manifest\nwhere nova.conf config values for the notification_driver\nwould get added to the wrong section (always to the end of\nthe file).\n\nAs part of the fix a custom file_line 'after' provider which\nsupports a new after option has been added.\nThis allows us to have some control over which section *new*\nfile lines go into. If there are any pre-existing matching\nlines in the file the assumption is that they are already in\nthe correct section and can be edited in place.\n\nNOTE: I've submitted a pull request to the upstream stdlib repo here\nto add the new 'after' option:\n\n  https://github.com/puppetlabs/puppetlabs-stdlib/pull/174\n\nOnce this (or something better) lands in stdlib we can update\npuppet-ceilometer to use it.\n\nFixes LP Bug #1217867\n\nChange-Id: Ic09f5232b322cde687d663d1ef38ef0fd12f32ff\n""}, {'number': 3, 'created': '2013-09-03 17:17:38.000000000', 'files': ['spec/classes/ceilometer_agent_compute_spec.rb', 'lib/puppet/provider/file_line_after/ruby.rb', 'manifests/agent/compute.pp', 'lib/puppet/type/file_line_after.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/a3b324dba249f5db38a4ff71b9bb5bc0f7d68147', 'message': ""Inline a custom file_line provider to fix agent.\n\nFixes an issue in the ceilometer::agent::compute manifest\nwhere nova.conf config values for the notification_driver\nwould get added to the wrong section (always to the end of\nthe file).\n\nAs part of the fix a custom file_line 'after' provider which\nsupports a new after option has been added.\nThis allows us to have some control over which section *new*\nfile lines go into. If there are any pre-existing matching\nlines in the file the assumption is that they are already in\nthe correct section and can be edited in place.\n\nNOTE: I've submitted a pull request to the upstream stdlib repo here\nto add the new 'after' option:\n\n  https://github.com/puppetlabs/puppetlabs-stdlib/pull/174\n\nOnce this (or something better) lands in stdlib we can update\npuppet-ceilometer to use it.\n\nFixes LP Bug #1217867\n\nChange-Id: Ic09f5232b322cde687d663d1ef38ef0fd12f32ff\n""}]",0,44324,a3b324dba249f5db38a4ff71b9bb5bc0f7d68147,16,6,3,360,,,0,"Inline a custom file_line provider to fix agent.

Fixes an issue in the ceilometer::agent::compute manifest
where nova.conf config values for the notification_driver
would get added to the wrong section (always to the end of
the file).

As part of the fix a custom file_line 'after' provider which
supports a new after option has been added.
This allows us to have some control over which section *new*
file lines go into. If there are any pre-existing matching
lines in the file the assumption is that they are already in
the correct section and can be edited in place.

NOTE: I've submitted a pull request to the upstream stdlib repo here
to add the new 'after' option:

  https://github.com/puppetlabs/puppetlabs-stdlib/pull/174

Once this (or something better) lands in stdlib we can update
puppet-ceilometer to use it.

Fixes LP Bug #1217867

Change-Id: Ic09f5232b322cde687d663d1ef38ef0fd12f32ff
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/24/44324/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/file_line_after/ruby.rb', 'manifests/agent/compute.pp', 'lib/puppet/type/file_line_after.rb']",3,4369af4f7c1677480f47439be76f81ffc5c21e2f,bug/1217867,"Puppet::Type.newtype(:file_line_after) do desc <<-EOT Ensures that a given line is contained within a file. The implementation matches the full line, including whitespace at the beginning and end. If the line is not contained in the given file, Puppet will add the line to ensure the desired state. Multiple resources may be declared to manage multiple lines in the same file. Example: file_line_after { 'sudo_rule': path => '/etc/sudoers', line => '%sudo ALL=(ALL) ALL', } file_line_after { 'sudo_rule_nopw': path => '/etc/sudoers', line => '%sudonopw ALL=(ALL) NOPASSWD: ALL', } In this example, Puppet will ensure both of the specified lines are contained in the file /etc/sudoers. EOT ensurable do defaultvalues defaultto :present end newparam(:name, :namevar => true) do desc 'An arbitrary name used as the identity of the resource.' end newparam(:match) do desc 'An optional regular expression to run against existing lines in the file;\n' + 'if a match is found, we replace that line rather than adding a new line.' end newparam(:multiple) do desc 'An optional value to determine if match can change multiple lines.' newvalues(true, false) end newparam(:after) do desc 'An optional value used to specify the line after which we will add any new lines. (Existing lines are added in place)' end newparam(:line) do desc 'The line to be appended to the file located by the path parameter.' end newparam(:path) do desc 'The file Puppet will ensure contains the line specified by the line parameter.' validate do |value| unless (Puppet.features.posix? and value =~ /^\//) or (Puppet.features.microsoft_windows? and (value =~ /^.:\// or value =~ /^\/\/[^\/]+\/[^\/]+/)) raise(Puppet::Error, ""File paths must be fully qualified, not '#{value}'"") end end end # Autorequire the file resource if it's being managed autorequire(:file) do self[:path] end validate do unless self[:line] and self[:path] raise(Puppet::Error, ""Both line and path are required attributes"") end if (self[:match]) unless Regexp.new(self[:match]).match(self[:line]) raise(Puppet::Error, ""When providing a 'match' parameter, the value must be a regex that matches against the value of your 'line' parameter"") end end end end ",,165,2
openstack%2Fnova~master~Id26f23ad7f975a3a50750927adbedb86bf80871d,openstack/nova,master,Id26f23ad7f975a3a50750927adbedb86bf80871d,Call safe_encode() instead of str(),MERGED,2013-08-30 07:04:51.000000000,2013-09-05 17:09:38.000000000,2013-09-01 10:04:44.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 5638}, {'_account_id': 5660}, {'_account_id': 6983}]","[{'number': 1, 'created': '2013-08-30 07:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f0cd51733dd144a0e7d88e8912c58730af32ffc', 'message': 'Call safe_encode() instead of str()\n\nTo avoid the error in python2.6:\n""UnicodeEncodeError: \'ascii\' codec can\'t encode characters"",\nuse safe_encode() instead of str().\n\nFix bug #1218719\n\nChange-Id: Id26f23ad7f975a3a50750927adbedb86bf80871d\n'}, {'number': 2, 'created': '2013-08-30 07:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f638246d70d2956ba6373a43d98f79e660becc0c', 'message': 'Call safe_encode() instead of str()\n\nTo avoid the error in python2.6:\n""UnicodeEncodeError: \'ascii\' codec can\'t encode characters"",\nuse safe_encode() instead of str().\n\nFix bug #1218719\n\nChange-Id: Id26f23ad7f975a3a50750927adbedb86bf80871d\n'}, {'number': 3, 'created': '2013-08-30 08:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1366841876b2045e26ef0c125c9ae42e8deb6ae', 'message': 'Call safe_encode() instead of str()\n\nTo avoid the error in python2.6:\n""UnicodeEncodeError: \'ascii\' codec can\'t encode characters"",\nuse safe_encode() to encode basestring instead of str().\n\nFix bug #1218719\n\nChange-Id: Id26f23ad7f975a3a50750927adbedb86bf80871d\n'}, {'number': 4, 'created': '2013-08-30 09:24:01.000000000', 'files': ['nova/tests/objects/test_objects.py', 'nova/objects/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/df44a7e25d47329fd863a5830b053c1cc3a0251f', 'message': 'Call safe_encode() instead of str()\n\nTo avoid the error in python2.6:\n""UnicodeEncodeError: \'ascii\' codec can\'t encode characters"",\nuse safe_encode() to encode basestring instead of str().\n\nFix bug #1218719\n\nChange-Id: Id26f23ad7f975a3a50750927adbedb86bf80871d\n'}]",0,44415,df44a7e25d47329fd863a5830b053c1cc3a0251f,20,8,4,6983,,,0,"Call safe_encode() instead of str()

To avoid the error in python2.6:
""UnicodeEncodeError: 'ascii' codec can't encode characters"",
use safe_encode() to encode basestring instead of str().

Fix bug #1218719

Change-Id: Id26f23ad7f975a3a50750927adbedb86bf80871d
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/44415/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/objects/utils.py'],1,6f0cd51733dd144a0e7d88e8912c58730af32ffc,bug/1218719,from nova.openstack.common import strutils return strutils.safe_encode(val), return str(val),2,1
openstack%2Ftripleo-ci~master~I6974617d43eb273eadf893e8d2facda1b1092904,openstack/tripleo-ci,master,I6974617d43eb273eadf893e8d2facda1b1092904,Use 192.0.2.1 for seed endpoint,MERGED,2013-09-02 11:06:25.000000000,2013-09-05 16:47:58.000000000,2013-09-05 16:47:58.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-09-02 11:06:25.000000000', 'files': ['toci_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bed1bb1c7f0ed712a5695697b598825b17b68759', 'message': 'Use 192.0.2.1 for seed endpoint\n\ndevtest uses 192.0.2.1 we should too, also moving the route add for\n192.0.2.0/24 so it happens before we try to use the endpoints.\n\nChange-Id: I6974617d43eb273eadf893e8d2facda1b1092904\n'}]",0,44677,bed1bb1c7f0ed712a5695697b598825b17b68759,7,3,1,1926,,,0,"Use 192.0.2.1 for seed endpoint

devtest uses 192.0.2.1 we should too, also moving the route add for
192.0.2.0/24 so it happens before we try to use the endpoints.

Change-Id: I6974617d43eb273eadf893e8d2facda1b1092904
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/77/44677/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_test.sh'],1,bed1bb1c7f0ed712a5695697b598825b17b68759,seed-ip,# Add a route to the baremetal bridge via the seed node sudo ip route del 192.0.2.0/24 dev virbr0 || true sudo ip route add 192.0.2.0/24 dev virbr0 via $SEED_IP SERVICE_TOKEN=unset setup-endpoints 192.0.2.1,SERVICE_TOKEN=unset setup-endpoints $SEED_IPsudo ip route del 192.0.2.0/24 dev virbr0 || true sudo ip route add 192.0.2.0/24 dev virbr0 via $SEED_IP ,5,4
openstack%2Fkeystone~master~I17233c8a79d01a37abdbd46934ad486ddc8caec9,openstack/keystone,master,I17233c8a79d01a37abdbd46934ad486ddc8caec9,Support timezone in memcached token backend,MERGED,2013-08-06 09:28:11.000000000,2013-09-05 16:27:03.000000000,2013-09-05 16:27:03.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 866}, {'_account_id': 2166}, {'_account_id': 2903}, {'_account_id': 4234}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-08-06 09:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/39234e4c237f4629597fa1bc338a7246c77dbf13', 'message': 'Support timezone in memcached token backend.\n\nIn keystone configuration manual, UTC timezone is required when\noperators use memcached token backend.\nIt is inconvenient for operators.\n\nBy this patch, memcached token backend works well without UTC.\n\nI guess the cause is incorrect time is set as expiration.\n\nbackends/memcache.py uses utils.unixtime() and it calls\ntime.mktime().\nBut mktime() returns local time, not UTC time.\n\nThis patch replaces time.mktime() with calendar.timegm().\n\nutils.unixtime() is only called by memcache.py and\ntest_backend_memcache.py.\nThere is no impact to other codes.\n\nhttp://docs.openstack.org/developer/keystone/configuration.html\n\nChange-Id: I17233c8a79d01a37abdbd46934ad486ddc8caec9\n'}, {'number': 2, 'created': '2013-08-13 09:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/862dd7296db3796bd7e7741dca5432a68eaaf2ff', 'message': 'Support timezone in memcached token backend.\n\nIn keystone configuration manual, UTC timezone is required when\noperators use memcached token backend.\nIt is inconvenient for operators.\n\nBy this patch, memcached token backend works well without UTC.\n\nI guess the cause is incorrect time is set as expiration.\n\nbackends/memcache.py uses utils.unixtime() and it calls\ntime.mktime().\nBut mktime() returns local time, not UTC time.\n\nThis patch replaces time.mktime() with calendar.timegm().\n\nutils.unixtime() is only called by memcache.py and\ntest_backend_memcache.py.\nThere is no impact to other codes.\n\nhttp://docs.openstack.org/developer/keystone/configuration.html\n\nDocImpact\n\nChange-Id: I17233c8a79d01a37abdbd46934ad486ddc8caec9\n'}, {'number': 3, 'created': '2013-08-15 08:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bb6409e1654a80c27ec22cd30388c181bd5f7173', 'message': 'Support timezone in memcached token backend.\n\nIn keystone configuration manual, UTC timezone is required when\noperators use memcached token backend.\nIt is inconvenient for operators.\n\nBy this patch, memcached token backend works well without UTC.\n\nI guess the cause is incorrect time is set as expiration.\n\nbackends/memcache.py uses utils.unixtime() and it calls\ntime.mktime().\nBut mktime() returns local time, not UTC time.\n\nThis patch replaces time.mktime() with calendar.timegm().\n\nutils.unixtime() is only called by memcache.py and\ntest_backend_memcache.py.\nThere is no impact to other codes.\n\nhttp://docs.openstack.org/developer/keystone/configuration.html\n\nDocImpact\n\nChange-Id: I17233c8a79d01a37abdbd46934ad486ddc8caec9\n'}, {'number': 4, 'created': '2013-08-20 03:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2028556aeeb3cc5be191ee3ca532b7b3b29d70a6', 'message': 'Support timezone in memcached token backend.\n\nIn keystone configuration manual, UTC timezone is required when\noperators use memcached token backend.\nIt is inconvenient for operators.\n\nBy this patch, memcached token backend works well without UTC.\n\nI guess the cause is incorrect time is set as expiration.\n\nbackends/memcache.py uses utils.unixtime() and it calls\ntime.mktime().\nBut mktime() returns local time, not UTC time.\n\nThis patch replaces time.mktime() with calendar.timegm().\n\nutils.unixtime() is only called by memcache.py and\ntest_backend_memcache.py.\n\nThere is no impact to other codes.\n\nDocImpact\n\nChange-Id: I17233c8a79d01a37abdbd46934ad486ddc8caec9\n'}, {'number': 5, 'created': '2013-08-28 06:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2661b634d3e5fce27320c6f73438b1b384306ac6', 'message': 'Support timezone in memcached token backend.\n\nIn keystone configuration manual, UTC timezone is required when\noperators use memcached token backend.\nIt is inconvenient for operators.\n\nBy this patch, memcached token backend works well without UTC.\n\nbackends/memcache.py uses utils.unixtime() and it calls\ntime.mktime().\nBut mktime() returns local time, not UTC time.\n\nThis patch replaces time.mktime() with calendar.timegm().\n\nutils.unixtime() is only called by memcache.py and\ntest_backend_memcache.py.\n\nThere is no impact to other codes.\n\nDocImpact\n\nChange-Id: I17233c8a79d01a37abdbd46934ad486ddc8caec9\n'}, {'number': 6, 'created': '2013-09-05 09:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/57409b89a904a34434eda1487afa126371486d70', 'message': 'Support timezone in memcached token backend.\n\nThis patch fixes bug #1221087.\n\nReplaces time.mktime() to calendar.timegm() in utils.unixtime()\nto get correct expiration time.\n\nAfter this patch, Memcached token backend does not depend on timezone.\nSo remove the section ""Memcached and System Time"" in configuration manual.\n\nDocImpact\n\nChange-Id: I17233c8a79d01a37abdbd46934ad486ddc8caec9\n'}, {'number': 7, 'created': '2013-09-05 09:46:17.000000000', 'files': ['doc/source/configuration.rst', 'keystone/tests/test_backend_memcache.py', 'keystone/tests/test_utils.py', 'keystone/common/utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1bb67a74aca9823e6d1d8335b150841adef3ee73', 'message': 'Support timezone in memcached token backend\n\nThis patch fixes bug #1221087.\n\nReplaces time.mktime() to calendar.timegm() in utils.unixtime()\nto get correct expiration time.\n\nAfter this patch, Memcached token backend does not depend on timezone.\nSo remove the section ""Memcached and System Time"" in configuration manual.\n\nDocImpact\n\nChange-Id: I17233c8a79d01a37abdbd46934ad486ddc8caec9\n'}]",15,40378,1bb67a74aca9823e6d1d8335b150841adef3ee73,42,10,7,4234,,,0,"Support timezone in memcached token backend

This patch fixes bug #1221087.

Replaces time.mktime() to calendar.timegm() in utils.unixtime()
to get correct expiration time.

After this patch, Memcached token backend does not depend on timezone.
So remove the section ""Memcached and System Time"" in configuration manual.

DocImpact

Change-Id: I17233c8a79d01a37abdbd46934ad486ddc8caec9
",git fetch https://review.opendev.org/openstack/keystone refs/changes/78/40378/7 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/utils.py'],1,39234e4c237f4629597fa1bc338a7246c77dbf13,bug/1221087,import calendar return calendar.timegm(dt_obj.utctimetuple()),import time return time.mktime(dt_obj.utctimetuple()),2,2
openstack%2Fironic~master~I94e8c2d8fec70175e294f9b67156f13cd11ee642,openstack/ironic,master,I94e8c2d8fec70175e294f9b67156f13cd11ee642,Removed  templates directory in api config,MERGED,2013-08-05 10:55:31.000000000,2013-09-05 16:21:24.000000000,2013-09-05 16:21:24.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2889}, {'_account_id': 4919}, {'_account_id': 6773}, {'_account_id': 7625}]","[{'number': 1, 'created': '2013-08-05 10:55:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a753a41929aec2aa139986bd011e443be27cd32f', 'message': 'Fixed templates directory in api config\n\nChange-Id: I94e8c2d8fec70175e294f9b67156f13cd11ee642\n'}, {'number': 2, 'created': '2013-09-02 11:33:49.000000000', 'files': ['ironic/api/config.py', 'ironic/api/app.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/2c752dbf5420761fd1c25bca4639f09cad4793e6', 'message': 'Removed  templates directory in api config\n\nThis patch removes the template_path config\noption in the API config file.  The path currently\npoints to a non existing directory.\n\nSince we are no longer supporting templates in ironic\nthen we can simply remove this option altogether\n\nChange-Id: I94e8c2d8fec70175e294f9b67156f13cd11ee642\n'}]",4,40202,2c752dbf5420761fd1c25bca4639f09cad4793e6,16,6,2,7625,,,0,"Removed  templates directory in api config

This patch removes the template_path config
option in the API config file.  The path currently
points to a non existing directory.

Since we are no longer supporting templates in ironic
then we can simply remove this option altogether

Change-Id: I94e8c2d8fec70175e294f9b67156f13cd11ee642
",git fetch https://review.opendev.org/openstack/ironic refs/changes/02/40202/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/api/config.py'],1,a753a41929aec2aa139986bd011e443be27cd32f,fix_templates," 'template_path': '%(confdir)s/templates',"," 'template_path': '%(confdir)s/ironic/api/templates',",1,1
openstack%2Fopenstack-manuals~master~Ia63300167f192c5f39b44800936a1e20f74afa4b,openstack/openstack-manuals,master,Ia63300167f192c5f39b44800936a1e20f74afa4b,Cleanup Basic Install Guide,MERGED,2013-09-02 12:35:03.000000000,2013-09-05 16:17:58.000000000,2013-09-05 16:17:58.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 1177}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-09-02 12:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0afaf2ab615105e3b4965aefccec03f3f3fbd444', 'message': 'Cleanup Basic Install Guide\n\nUse filename instead of emphasis, remove tabs\n\nChange-Id: Ia63300167f192c5f39b44800936a1e20f74afa4b\n'}, {'number': 2, 'created': '2013-09-05 13:45:01.000000000', 'files': ['doc/src/docbkx/basic-install/src/basic-install_controller-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_compute-common.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-dashboard.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-neutron.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-keystone.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a06dc09f4ab379c4a4298b6394f24eba165fbd91', 'message': 'Cleanup Basic Install Guide\n\nUse filename instead of emphasis, remove tabs\n\nChange-Id: Ia63300167f192c5f39b44800936a1e20f74afa4b\n'}]",3,44692,a06dc09f4ab379c4a4298b6394f24eba165fbd91,16,5,2,6547,,,0,"Cleanup Basic Install Guide

Use filename instead of emphasis, remove tabs

Change-Id: Ia63300167f192c5f39b44800936a1e20f74afa4b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/92/44692/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/basic-install/src/basic-install_compute-common.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-dashboard.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-neutron.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-keystone.xml']",5,0afaf2ab615105e3b4965aefccec03f3f3fbd444,filename," <screen os=""opensuse""><prompt>#</prompt> <userinput>zypper install openstack-keystone python-keystoneclient</userinput></screen> </para> <para>Edit <filename>/etc/keystone/keystone.conf</filename>: <listitem os=""opensuse""> <para>Setup keystone default catalog: </para> </listitem> <listitem os=""opensuse""> <para>Enable the identity service: <screen><prompt>#</prompt> <userinput>systemctl enable openstack-keystone.service</userinput></screen> </para> </listitem> <para>Create a file called <filename>~/openrc</filename>. This file contains the OpenStack admin"," <screen os=""opensuse""><prompt>#</prompt> <userinput>zypper install openstack-keystone python-keystoneclient</userinput></screen> </para> <para>Edit <emphasis role=""bold"">/etc/keystone/keystone.conf</emphasis>: <listitem os=""opensuse""> <para>Setup keystone default catalog: </para> </listitem> <listitem os=""opensuse""> <para>Enable the identity service: <screen><prompt>#</prompt> <userinput>systemctl enable openstack-keystone.service</userinput></screen> </para> </listitem> <para>Create a file called <emphasis role=""bold"">~/openrc</emphasis>. This file contains the OpenStack admin",23,23
openstack%2Fnova~master~I4000c8ab550e032363f138a86e1b87f6ab2f5ff2,openstack/nova,master,I4000c8ab550e032363f138a86e1b87f6ab2f5ff2,Handle port over-quota when allocating network for instance,MERGED,2013-08-09 19:28:17.000000000,2013-09-05 16:13:31.000000000,2013-09-05 16:13:29.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 4395}, {'_account_id': 4694}, {'_account_id': 6316}, {'_account_id': 6873}, {'_account_id': 7069}]","[{'number': 1, 'created': '2013-08-09 19:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d70bc7d56778853b7cc4dae44edfc998f3b522ff', 'message': ""WIP: Handle port over-quota when allocating network for instance\n\nThis patch adds a check in the neutron API for a port create failure due\nto over-quota in neutron and raises the new exception PortLimitExceeded.\n\nAlso moves the port-create block of code into it's own method to\ntry and clean up some of the large allocate_for_instance method.\n\nCloses-Bug: #1207914\nRelated-Bug: #1209446\n\nChange-Id: I4000c8ab550e032363f138a86e1b87f6ab2f5ff2\n""}, {'number': 2, 'created': '2013-08-09 19:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9909e5edf69c2103050ecfe5c436424a268422a8', 'message': ""Handle port over-quota when allocating network for instance\n\nThis patch adds a check in the neutron API for a port create failure due\nto over-quota in neutron and raises the new exception PortLimitExceeded.\n\nAlso moves the port-create block of code into it's own method to\ntry and clean up some of the large allocate_for_instance method.\n\nCloses-Bug: #1207914\nRelated-Bug: #1209446\n\nChange-Id: I4000c8ab550e032363f138a86e1b87f6ab2f5ff2\n""}, {'number': 3, 'created': '2013-08-09 20:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd84e535797182c86399b47ba165ac5127a4070e', 'message': ""Handle port over-quota when allocating network for instance\n\nThis patch adds a check in the neutron API for a port create failure due\nto over-quota in neutron and raises the new exception PortLimitExceeded.\n\nAlso moves the port-create block of code into it's own method to\ntry and clean up some of the large allocate_for_instance method.\n\nCloses-Bug: #1207914\nRelated-Bug: #1209446\n\nChange-Id: I4000c8ab550e032363f138a86e1b87f6ab2f5ff2\n""}, {'number': 4, 'created': '2013-08-12 21:36:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0d879102af1865b78337c3601aedff814dbb396', 'message': ""Handle port over-quota when allocating network for instance\n\nThis patch adds a check in the neutron API for a port create failure due\nto over-quota in neutron and raises the new exception PortLimitExceeded.\n\nAlso moves the port-create block of code into it's own method to\ntry and clean up some of the large allocate_for_instance method.\n\nCloses-Bug: #1207914\nRelated-Bug: #1209446\n\nChange-Id: I4000c8ab550e032363f138a86e1b87f6ab2f5ff2\n""}, {'number': 5, 'created': '2013-08-30 20:32:10.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/exception.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2d20b87aef5a7d00cb36826b8907032912fb17fc', 'message': ""Handle port over-quota when allocating network for instance\n\nThis patch adds a check in the neutron API for a port create failure due\nto over-quota in neutron and raises the new exception PortLimitExceeded.\n\nAlso moves the port-create block of code into it's own method to\ntry and clean up some of the large allocate_for_instance method.\n\nCloses-Bug: #1207914\nRelated-Bug: #1209446\n\nChange-Id: I4000c8ab550e032363f138a86e1b87f6ab2f5ff2\n""}]",20,41177,2d20b87aef5a7d00cb36826b8907032912fb17fc,36,11,5,6873,,,0,"Handle port over-quota when allocating network for instance

This patch adds a check in the neutron API for a port create failure due
to over-quota in neutron and raises the new exception PortLimitExceeded.

Also moves the port-create block of code into it's own method to
try and clean up some of the large allocate_for_instance method.

Closes-Bug: #1207914
Related-Bug: #1209446

Change-Id: I4000c8ab550e032363f138a86e1b87f6ab2f5ff2
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/41177/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/exception.py']",2,d70bc7d56778853b7cc4dae44edfc998f3b522ff,bug/1207914,"class PortLimitExceeded(QuotaError): msg_fmt = _(""Maximum number of ports exceeded for network '%(network)s'."") ",,53,18
openstack%2Fceilometer~master~If009166be450f2e1bba0e68ce74699b5a032543e,openstack/ceilometer,master,If009166be450f2e1bba0e68ce74699b5a032543e,Clean-ups related to alarm history patches,MERGED,2013-09-04 22:24:48.000000000,2013-09-05 16:13:25.000000000,2013-09-05 16:13:25.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2860}, {'_account_id': 4491}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-09-04 22:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/af516907fd4119c5d234c8f89ef957d498f13b09', 'message': 'Clean-ups related to alarm history patches.\n\nSome non-blocking clean-ups requested in reviews of the alarm\nhistory patches.\n\nChange-Id: If009166be450f2e1bba0e68ce74699b5a032543e\n'}, {'number': 2, 'created': '2013-09-04 22:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ca14a24032551764dac3ae96acbde1ce6bdb9b71', 'message': 'Clean-ups related to alarm history patches\n\nSome non-blocking clean-ups requested in reviews of the alarm\nhistory patches.\n\nChange-Id: If009166be450f2e1bba0e68ce74699b5a032543e\n'}, {'number': 3, 'created': '2013-09-04 22:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/95e4f298175579cd3a3083c74ce9345780c74eba', 'message': 'Clean-ups related to alarm history patches\n\nSome non-blocking clean-ups requested in reviews of the alarm\nhistory patches.\n\nChange-Id: If009166be450f2e1bba0e68ce74699b5a032543e\n'}, {'number': 4, 'created': '2013-09-04 22:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3c21e2fd9798ce02b1f605c3bf4e408b33053307', 'message': 'Clean-ups related to alarm history patches\n\nSome non-blocking clean-ups requested in reviews of the alarm\nhistory patches.\n\nChange-Id: If009166be450f2e1bba0e68ce74699b5a032543e\n'}, {'number': 5, 'created': '2013-09-05 10:02:26.000000000', 'files': ['tests/api/v2/test_alarm_scenarios.py', 'ceilometer/storage/base.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/impl_log.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/storage/impl_db2.py', 'ceilometer/storage/impl_sqlalchemy.py', 'tests/api/v2/test_query.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a09ef3261c240079f848d562b0f9e2255a0afc6b', 'message': 'Clean-ups related to alarm history patches\n\nSome non-blocking clean-ups requested in reviews of the alarm\nhistory patches.\n\nChange-Id: If009166be450f2e1bba0e68ce74699b5a032543e\n'}]",1,45135,a09ef3261c240079f848d562b0f9e2255a0afc6b,26,8,5,2284,,,0,"Clean-ups related to alarm history patches

Some non-blocking clean-ups requested in reviews of the alarm
history patches.

Change-Id: If009166be450f2e1bba0e68ce74699b5a032543e
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/35/45135/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/api/v2/test_alarm_scenarios.py', 'ceilometer/storage/base.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/impl_log.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/storage/impl_db2.py', 'ceilometer/storage/impl_sqlalchemy.py', 'tests/api/v2/test_query.py']",9,af516907fd4119c5d234c8f89ef957d498f13b09,,"import datetime from ceilometer.api.controllers.v2 import _query_to_kwargs def _fake_db_func(self, resource, on_behalf_of, x, y, metaquery={}, user=None, project=None, start_timestamp=None, start_timestamp_op=None, end_timestamp=None, end_timestamp_op=None, **kwargs): pass def test_query_to_kwargs_exclude_internal(self): queries = [Query(field=f, op='eq', value='fake', type='string') for f in ['y', 'on_behalf_of', 'x']] self.assertRaises(wsme.exc.ClientSideError, _query_to_kwargs, queries, self._fake_db_func, headers={'X-ProjectId': 'foobar'}, internal_keys=['on_behalf_of']) def test_query_to_kwargs_self_always_excluded(self): queries = [Query(field=f, op='eq', value='fake', type='string') for f in ['x', 'y']] kwargs = _query_to_kwargs(queries, self._fake_db_func, headers={'X-ProjectId': 'foobar'}) self.assertFalse('self' in kwargs) def test_query_to_kwargs_timestamp_mapping(self): start = datetime.datetime.utcnow() end = datetime.datetime.utcnow() queries = [Query(field='timestamp', op='gt', value=start.isoformat(), type='string'), Query(field='timestamp', op='le', value=end.isoformat(), type='string')] kwargs = _query_to_kwargs(queries, self._fake_db_func, headers={'X-ProjectId': 'foobar'}) self.assertEqual(kwargs.get('start_timestamp'), start) self.assertEqual(kwargs.get('start_timestamp_op'), 'gt') self.assertEqual(kwargs.get('end_timestamp'), end) self.assertEqual(kwargs.get('end_timestamp_op'), 'le') def test_query_to_kwargs_non_equality_on_metadata(self): queries = [Query(field='resource_metadata.image_id', op='gt', value='image', type='string'), Query(field='metadata.ramdisk_id', op='le', value='ramdisk', type='string')] kwargs = _query_to_kwargs(queries, self._fake_db_func, headers={'X-ProjectId': 'foobar'}) self.assertFalse('metaquery' in kwargs) def test_query_to_kwargs_equality_on_metadata(self): queries = [Query(field='resource_metadata.image_id', op='eq', value='image', type='string'), Query(field='metadata.ramdisk_id', op='eq', value='ramdisk', type='string')] kwargs = _query_to_kwargs(queries, self._fake_db_func, headers={'X-ProjectId': 'foobar'}) self.assertTrue('metaquery' in kwargs) metaquery = kwargs['metaquery'] self.assertEqual(metaquery.get('metadata.image_id'), 'image') self.assertEqual(metaquery.get('metadata.ramdisk_id'), 'ramdisk') def test_query_to_kwargs_translation(self): queries = [Query(field=f, op='eq', value='fake_%s' % f, type='string') for f in ['user_id', 'project_id', 'resource_id']] kwargs = _query_to_kwargs(queries, self._fake_db_func, headers={'X-ProjectId': 'foobar'}) for o in ['user', 'project', 'resource']: self.assertEqual(kwargs.get(o), 'fake_%s_id' % o) def test_query_to_kwargs_unrecognized(self): queries = [Query(field=f, op='eq', value='fake', type='string') for f in ['y', 'z', 'x']] self.assertRaises(wsme.exc.ClientSideError, _query_to_kwargs, queries, self._fake_db_func, headers={'X-ProjectId': 'foobar'})",,214,12
openstack%2Fneutron~master~I3899b01f316902d1139e47b153a9db7ecb3ff982,openstack/neutron,master,I3899b01f316902d1139e47b153a9db7ecb3ff982,Add sub-type field to VXLAN network profiles for Cisco N1KV plugin,MERGED,2013-08-20 05:04:15.000000000,2013-09-05 16:13:17.000000000,2013-09-05 16:13:17.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 1689}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6676}, {'_account_id': 6785}, {'_account_id': 7018}]","[{'number': 1, 'created': '2013-08-20 05:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6fbdb23391cf7d77f920614c64fc65729e58b7b2', 'message': 'Add sub-type field to VXLAN network profiles for Cisco N1KV plugin\n\nRename VXLAN type of network profiles to Overlay network profiles.\nAdd a new sub type column to Overlay network profiles. Support\nenhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to\nbe flexible to support newer sub types.\n\nChange-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982\nImplements: blueprint cisco-plugin-n1k-enh-vxlan-support\n'}, {'number': 2, 'created': '2013-08-23 00:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e35fb8a1646dd95efa42df79ff456cefc944711', 'message': 'Add sub-type field to VXLAN network profiles for Cisco N1KV plugin\n\nRename VXLAN type of network profiles to Overlay network profiles.\nAdd a new sub type column to Overlay network profiles. Support\nenhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to\nbe flexible to support newer sub types.\n\nChange-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982\nImplements: blueprint cisco-plugin-n1k-enh-vxlan-support\n'}, {'number': 3, 'created': '2013-09-04 00:37:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4699ed89a1a33cd9691175bcc9de768958e44b1', 'message': 'Add sub-type field to VXLAN network profiles for Cisco N1KV plugin\n\nRename VXLAN type of network profiles to Overlay network profiles.\nAdd a new sub type column to Overlay network profiles. Support\nenhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to\nbe flexible to support newer sub types.\n\nChange-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982\nImplements: blueprint cisco-plugin-n1k-enh-vxlan-support\n'}, {'number': 4, 'created': '2013-09-04 01:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20ddc303899e53359562b496012c5930ff5d5a93', 'message': 'Add sub-type field to VXLAN network profiles for Cisco N1KV plugin\n\nRename VXLAN type of network profiles to Overlay network profiles.\nAdd a new sub type column to Overlay network profiles. Support\nenhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to\nbe flexible to support newer sub types.\n\nChange-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982\nImplements: blueprint cisco-plugin-n1k-enh-vxlan-support\n'}, {'number': 5, 'created': '2013-09-04 01:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e36af1f12a49d84d68e8f814eb19252a10ce0c3', 'message': 'Add sub-type field to VXLAN network profiles for Cisco N1KV plugin\n\nRename VXLAN type of network profiles to Overlay network profiles.\nAdd a new sub type column to Overlay network profiles. Support\nenhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to\nbe flexible to support newer sub types.\n\nChange-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982\nImplements: blueprint cisco-plugin-n1k-enh-vxlan-support\n'}, {'number': 6, 'created': '2013-09-04 19:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/30eface9aa97b240eba410b7639984a1a9cfc1f2', 'message': 'Add sub-type field to VXLAN network profiles for Cisco N1KV plugin\n\nRename VXLAN type of network profiles to Overlay network profiles.\nAdd a new sub type column to Overlay network profiles. Support\nenhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to\nbe flexible to support newer sub types.\n\nChange-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982\nImplements: blueprint cisco-plugin-n1k-enh-vxlan-support\n'}, {'number': 7, 'created': '2013-09-05 12:24:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3074e16ba3bc0c865e185c53d001de47a50d242b', 'message': 'Add sub-type field to VXLAN network profiles for Cisco N1KV plugin\n\nRename VXLAN type of network profiles to Overlay network profiles.\nAdd a new sub type column to Overlay network profiles. Support\nenhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to\nbe flexible to support newer sub types.\n\n(Trivial change to bump this from the gate, as this is failing on\ndevstack setup due to alembic collision of some sort.)\n\nChange-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982\nImplements: blueprint cisco-plugin-n1k-enh-vxlan-support\n'}, {'number': 8, 'created': '2013-09-05 12:58:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/993f08a7bdc9ec0f9b20f7462b3c2d15c1cf1b7c', 'message': 'Add sub-type field to VXLAN network profiles for Cisco N1KV plugin\n\nRename VXLAN type of network profiles to Overlay network profiles.\nAdd a new sub type column to Overlay network profiles. Support\nenhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to\nbe flexible to support newer sub types.\n\n(Trivial change to bump this from the gate, as this is failing on\ndevstack setup due to alembic collision of some sort.)\n\nChange-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982\nImplements: blueprint cisco-plugin-n1k-enh-vxlan-support\n'}, {'number': 9, 'created': '2013-09-05 13:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5564ce15e7220660ed9b2e82220032c8cfecb2ac', 'message': 'Add sub-type field to VXLAN network profiles for Cisco N1KV plugin\n\nRename VXLAN type of network profiles to Overlay network profiles.\nAdd a new sub type column to Overlay network profiles. Support\nenhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to\nbe flexible to support newer sub types.\n\n(Trivial change to bump this from the gate, as this is failing on\ndevstack setup due to alembic collision of some sort.)\n\nChange-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982\nImplements: blueprint cisco-plugin-n1k-enh-vxlan-support\n'}, {'number': 10, 'created': '2013-09-05 13:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f320d2737a47a3431dace58528a86dd5e8a2f2ed', 'message': 'Add sub-type field to VXLAN network profiles for Cisco N1KV plugin\n\nRename VXLAN type of network profiles to Overlay network profiles.\nAdd a new sub type column to Overlay network profiles. Support\nenhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to\nbe flexible to support newer sub types.\n\n(Trivial change to bump this from the gate, as this is failing on\ndevstack setup due to alembic collision of some sort.)\n\nChange-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982\nImplements: blueprint cisco-plugin-n1k-enh-vxlan-support\n'}, {'number': 11, 'created': '2013-09-05 15:00:15.000000000', 'files': ['neutron/plugins/cisco/common/cisco_constants.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_db.py', 'neutron/plugins/cisco/db/n1kv_models_v2.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py', 'neutron/db/migration/alembic_migrations/versions/38fc1f6789f8_cisco_n1kv_overlay.py', 'neutron/plugins/cisco/n1kv/n1kv_client.py', 'neutron/plugins/cisco/db/n1kv_db_v2.py', 'neutron/plugins/cisco/extensions/credential.py', 'neutron/plugins/cisco/extensions/network_profile.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/50c9199d6a83409e6cb5ebc3ca4eefce9a2f0531', 'message': 'Add sub-type field to VXLAN network profiles for Cisco N1KV plugin\n\nRename VXLAN type of network profiles to Overlay network profiles.\nAdd a new sub type column to Overlay network profiles. Support\nenhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to\nbe flexible to support newer sub types.\n\nChange-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982\nImplements: blueprint cisco-plugin-n1k-enh-vxlan-support\n'}]",21,42806,50c9199d6a83409e6cb5ebc3ca4eefce9a2f0531,67,12,11,7018,,,0,"Add sub-type field to VXLAN network profiles for Cisco N1KV plugin

Rename VXLAN type of network profiles to Overlay network profiles.
Add a new sub type column to Overlay network profiles. Support
enhanced VXLAN and native VXLAN as Overlay sub types. Allow plugin to
be flexible to support newer sub types.

Change-Id: I3899b01f316902d1139e47b153a9db7ecb3ff982
Implements: blueprint cisco-plugin-n1k-enh-vxlan-support
",git fetch https://review.opendev.org/openstack/neutron refs/changes/06/42806/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/cisco/common/cisco_constants.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_db.py', 'neutron/plugins/cisco/db/n1kv_models_v2.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py', 'neutron/plugins/cisco/db/n1kv_db_v2.py', 'neutron/plugins/cisco/extensions/policy_profile.py', 'neutron/plugins/cisco/n1kv/n1kv_client.py', 'neutron/plugins/cisco/extensions/credential.py', 'neutron/plugins/cisco/extensions/network_profile.py']",9,6fbdb23391cf7d77f920614c64fc65729e58b7b2,bp/cisco-plugin-n1k-enh-vxlan-support," 'sub_type': {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': ''},",,136,86
openstack%2Fneutron~master~Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac,openstack/neutron,master,Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac,Implement Allowed Address Pairs,MERGED,2013-07-22 23:59:27.000000000,2013-09-05 16:13:08.000000000,2013-09-05 16:13:07.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 2166}, {'_account_id': 2468}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6274}, {'_account_id': 6524}, {'_account_id': 6676}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7562}, {'_account_id': 8578}]","[{'number': 1, 'created': '2013-07-22 23:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1fa9ff407cd5aac4c81f5c56a28710ebf2f97da1', 'message': 'wip\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 2, 'created': '2013-07-23 19:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e5888f6c8edaf21ac3beb16e2ca898d677d3d47c', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add addition ip/mac address pairs on a port to\nallow traffic on those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp.\n\nTODO: more tests, db migration\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 3, 'created': '2013-07-24 00:33:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fa85ccb9e7b32a4872c96569f4d9b3894c0de6bc', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add addition ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin and the OVS plugin.\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 4, 'created': '2013-07-30 20:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bdf2590724dec83ba0233499c882ef5afb4f948a', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add addition ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin and the OVS plugin.\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 5, 'created': '2013-07-30 22:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/71827dff1d1db9767f17a0104bcf127b391d30a5', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add addition ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin and the OVS plugin.\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 6, 'created': '2013-07-31 22:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f140ae18f22b675b229f2859b38ab4d41103182', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin and the OVS plugin.\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 7, 'created': '2013-08-02 00:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c85579b92efabdabdf01d22ae47841ffa4f5f542', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 8, 'created': '2013-08-21 21:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4dccfa1bc21a93608b906e4556de13d49866d52d', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 9, 'created': '2013-08-27 23:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e335ce0eb147008940b118637b7fd03d3a829d3d', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 10, 'created': '2013-09-03 18:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20296bc58cb3861b29aba6ff6171eccac40b30ce', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 11, 'created': '2013-09-03 19:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a9910a14f6ec486c90e849a26cf409f68976705c', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 12, 'created': '2013-09-03 23:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ebd61b9e8ce84ec632d014b1478879190ae1b164', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 13, 'created': '2013-09-04 04:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bfdc666d85afe69b1cedded8d3ef278e52680b18', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 14, 'created': '2013-09-04 05:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/74041f8af8297019f057169d68d9fde0179b3db9', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 15, 'created': '2013-09-04 06:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/57c984e6d10d501fe3f44e60790075ba7f0c1bc6', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 16, 'created': '2013-09-04 17:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c99f22b58502ccbdd199306bf2d2e0269b044d4', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 17, 'created': '2013-09-04 19:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5a8142846f180b26584750ad234b4b498cf889f4', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 18, 'created': '2013-09-04 22:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/25fb416404bc4f38751c72e9d486561f73b533b7', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 19, 'created': '2013-09-04 22:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f17017df6b5ef563a23aab9d46c883c4cb62199f', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 20, 'created': '2013-09-04 22:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/83b4cf09284b488617b96ad39996a8419d606847', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 21, 'created': '2013-09-05 03:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1a18977138bc491a4dbf72c3604521de40d6b74', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 22, 'created': '2013-09-05 07:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca5d73834c7a78ba4f404abffe97900bc90ca0bf', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}, {'number': 23, 'created': '2013-09-05 11:04:52.000000000', 'files': ['neutron/extensions/allowedaddresspairs.py', 'neutron/tests/unit/test_security_groups_rpc.py', 'neutron/agent/linux/iptables_firewall.py', 'neutron/db/migration/alembic_migrations/versions/1efb85914233_allowedaddresspairs.py', 'neutron/plugins/nicira/nvplib.py', 'neutron/tests/unit/openvswitch/test_ovs_security_group.py', 'neutron/tests/unit/test_extension_allowedaddresspairs.py', 'neutron/plugins/openvswitch/ovs_neutron_plugin.py', 'neutron/plugins/ml2/plugin.py', 'neutron/db/securitygroups_rpc_base.py', 'neutron/plugins/nicira/NeutronPlugin.py', 'neutron/tests/unit/nicira/test_nicira_plugin.py', 'neutron/tests/unit/ml2/test_security_group.py', 'neutron/db/allowedaddresspairs_db.py', 'neutron/tests/unit/test_iptables_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0efce6195fa7be80e110bd841dc9b3537a94c376', 'message': 'Implement Allowed Address Pairs\n\nThe following patch adds the concept of allowed address pairs.\nThis allows one to add additional ip/mac address pairs on a port to\nallow traffic that matches those specified values. This is useful in order\nto leverage dataplane failover mechanisms like vrrp. This patch adds support\nfor the NVP plugin, the OVS plugin, and Ml2.\n\nDocImpact\n\nimplements blueprint: allowed-address-pairs\n\nChange-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac\n'}]",207,38230,0efce6195fa7be80e110bd841dc9b3537a94c376,168,20,23,4395,,,0,"Implement Allowed Address Pairs

The following patch adds the concept of allowed address pairs.
This allows one to add additional ip/mac address pairs on a port to
allow traffic that matches those specified values. This is useful in order
to leverage dataplane failover mechanisms like vrrp. This patch adds support
for the NVP plugin, the OVS plugin, and Ml2.

DocImpact

implements blueprint: allowed-address-pairs

Change-Id: Ie73b3886c5be8e1fc4ade86a0cfb854267f345ac
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/38230/19 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/extensions/allowedaddresspairs.py', 'neutron/plugins/nicira/NeutronPlugin.py', 'neutron/tests/unit/nicira/test_nicira_plugin.py', 'neutron/db/allowedaddresspairs_db.py', 'neutron/plugins/nicira/nvplib.py', 'neutron/tests/unit/test_extension_allowedaddresspairs.py']",6,1fa9ff407cd5aac4c81f5c56a28710ebf2f97da1,bp/allowed-address-pairs,"# Copyright (c) 2012 OpenStack Foundation. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from neutron.api.v2 import attributes as attr from neutron.common.test_lib import test_config from neutron.db import allowedaddresspairs_db as addr_pair_db from neutron.db import db_base_plugin_v2 from neutron.db import portsecurity_db from neutron.extensions import allowedaddresspairs as addr_pair from neutron.extensions import portsecurity as psec from neutron.manager import NeutronManager from neutron import policy from neutron.tests.unit import test_db_plugin from neutron.tests.unit import test_extension_portsecurity as test_psec DB_PLUGIN_KLASS = ('neutron.tests.unit.test_extension_allowedaddresspairs.' 'AllowedAddressPairTestPlugin') class AllowedAddressPairTestCase(test_db_plugin.NeutronDbPluginV2TestCase): def setUp(self, plugin=None): super(AllowedAddressPairTestCase, self).setUp() # Check if a plugin supports security groups plugin_obj = NeutronManager.get_plugin() self._skip_port_security = ('port-security' not in plugin_obj.supported_extension_aliases) def tearDown(self): super(AllowedAddressPairTestCase, self).tearDown() self._skip_port_security = None class AllowedAddressPairTestPlugin(portsecurity_db.PortSecurityDbMixin, db_base_plugin_v2.NeutronDbPluginV2, addr_pair_db.AllowedAddressPairMixin): """"""Test plugin that implements necessary calls on create/delete port for associating ports with port security and allowed address pairs. """""" supported_extension_aliases = [""allowed-address-pairs"", ""port-security""] def _enforce_set_auth(self, context, resource, action): return policy.enforce(context, action, resource) def create_network(self, context, network): return test_psec.PortSecurityTestPlugin().create_network(context, network) def update_network(self, context, id, network): return test_psec.PortSecurityTestPlugin().update_network(context, id, network) def get_network(self, context, id, fields=None): return test_psec.PortSecurityTestPlugin().get_network(context, id, fields) def create_port(self, context, port): p = port['port'] with context.session.begin(subtransactions=True): neutron_db = super(AllowedAddressPairTestPlugin, self).create_port( context, port) p.update(neutron_db) (port_security, has_ip) = self._determine_port_security_and_has_ip( context, p) p[psec.PORTSECURITY] = port_security if attr.is_attr_set(p.get(addr_pair.ADDRESS_PAIRS)): if not port_security: raise addr_pair.AddressPairAndPortSecurityRequired() elif port_security: self.create_allowed_address_pairs( context, p['id'], p[addr_pair.ADDRESS_PAIRS]) else: p[addr_pair.ADDRESS_PAIRS] = None self._process_port_security_create(context, p) self._extend_port_port_security_dict(context, p) return port['port'] def update_port(self, context, id, port): delete_addr_pairs = self._check_update_deletes_allowed_address_pairs( port) has_addr_pairs = self._check_update_has_allowed_address_pairs(port) with context.session.begin(subtransactions=True): ret_port = super(AllowedAddressPairTestPlugin, self).update_port( context, id, port) # copy values over - but not fixed_ips port['port'].pop('fixed_ips', None) ret_port.update(port['port']) # populate port_security setting if psec.PORTSECURITY not in ret_port: ret_port[psec.PORTSECURITY] = self._get_port_security_binding( context, id) if not ret_port[psec.PORTSECURITY]: if has_addr_pairs: raise addr_pair.AddressPairAndPortSecurityRequired() elif not delete_addr_pairs: # check if address pairs are in db ret_port[addr_pair.ADDRESS_PAIRS] = ( self.get_allowed_address_pairs(context, id)) if ret_port[addr_pair.ADDRESS_PAIRS]: raise addr_pair.AddressPairAndPortSecurityRequired() if (delete_addr_pairs or has_addr_pairs): # delete address pairds and readd them self._delete_allowed_address_pairs(context, id) self.create_allowed_address_pairs( context, id, ret_port[addr_pair.ADDRESS_PAIRS]) if psec.PORTSECURITY in port['port']: self._update_port_security_binding( context, id, ret_port[psec.PORTSECURITY]) self._extend_port_port_security_dict(context, ret_port) return ret_port class AllowedAddressPairDBTestCase(AllowedAddressPairTestCase): def setUp(self, plugin=None): test_config['plugin_name_v2'] = DB_PLUGIN_KLASS super(AllowedAddressPairDBTestCase, self).setUp() def tearDown(self): del test_config['plugin_name_v2'] super(AllowedAddressPairDBTestCase, self).tearDown() class TestAllowedAddressPairs(AllowedAddressPairDBTestCase): def test_create_port_security_true_allowed_address_pairs(self): with self.network() as net: address_pairs = [{'mac_address': '00:00:00:00:00:01', 'ip_address': '10.0.0.1'}] res = self._create_port(self.fmt, net['network']['id'], arg_list=('port_security_enabled', addr_pair.ADDRESS_PAIRS,), port_security_enabled=True, allowed_address_pairs=address_pairs) port = self.deserialize(self.fmt, res) self.assertEqual(port['port'][psec.PORTSECURITY], True) self.assertEqual(port['port'][addr_pair.ADDRESS_PAIRS], address_pairs) self._delete('ports', port['port']['id']) def test_create_port_security_false_allowed_address_pairs(self): with self.network() as net: address_pairs = [{'mac_address': '00:00:00:00:00:01', 'ip_address': '10.0.0.1'}] res = self._create_port(self.fmt, net['network']['id'], arg_list=('port_security_enabled', addr_pair.ADDRESS_PAIRS,), port_security_enabled=False, allowed_address_pairs=address_pairs) self.deserialize(self.fmt, res) self.assertEqual(res.status_int, 400) def test_create_port_bad_mac(self): address_pairs = [{'mac_address': 'invalid_mac', 'ip_address': '10.0.0.1'}] self._create_port_with_address_pairs(address_pairs, 400) def test_create_port_bad_ip(self): address_pairs = [{'mac_address': 'invalid_mac', 'ip_address': '10.0.0.1222'}] self._create_port_with_address_pairs(address_pairs, 400) def test_create_missing_mac_field(self): address_pairs = [{'ip_address': '10.0.0.1'}] self._create_port_with_address_pairs(address_pairs, 400) def test_create_missing_ip_field(self): address_pairs = [{'mac_address': 'invalid_mac'}] self._create_port_with_address_pairs(address_pairs, 400) def test_create_duplicate_mac_ip(self): address_pairs = [{'mac_address': '00:00:00:00:00:01', 'ip_address': '10.0.0.1'}, {'mac_address': '00:00:00:00:00:01', 'ip_address': '10.0.0.1'}] self._create_port_with_address_pairs(address_pairs, 400) def test_create_port_extra_args(self): address_pairs = [{'mac_address': '00:00:00:00:00:01', 'ip_address': '10.0.0.1', 'icbb': 'agreed'}] self._create_port_with_address_pairs(address_pairs, 400) def _create_port_with_address_pairs(self, address_pairs, ret_code): with self.network() as net: res = self._create_port(self.fmt, net['network']['id'], arg_list=('port_security_enabled', addr_pair.ADDRESS_PAIRS,), port_security_enabled=True, allowed_address_pairs=address_pairs) self.deserialize(self.fmt, res) self.assertEqual(res.status_int, 400) def test_update_add_address_pairs(self): with self.network() as net: res = self._create_port(self.fmt, net['network']['id']) port = self.deserialize(self.fmt, res) address_pairs = [{'mac_address': '00:00:00:00:00:01', 'ip_address': '10.0.0.1'}] update_port = {'port': {addr_pair.ADDRESS_PAIRS: address_pairs}} req = self.new_update_request('ports', update_port, port['port']['id']) port = self.deserialize(self.fmt, req.get_response(self.api)) self.assertEqual(port['port'][addr_pair.ADDRESS_PAIRS], address_pairs) self._delete('ports', port['port']['id']) def test_update_port_security_off_address_pairs(self): with self.network() as net: with self.subnet(network=net): address_pairs = [{'mac_address': '00:00:00:00:00:01', 'ip_address': '10.0.0.1'}] res = self._create_port(self.fmt, net['network']['id'], arg_list=('port_security_enabled', addr_pair.ADDRESS_PAIRS,), port_security_enabled=True, allowed_address_pairs=address_pairs) port = self.deserialize(self.fmt, res) update_port = {'port': {psec.PORTSECURITY: False}} # If plugin implements security groups we also need to remove # the security group on port. plugin_obj = NeutronManager.get_plugin() if 'security-groups' in plugin_obj.supported_extension_aliases: update_port['port']['security_groups'] = [] req = self.new_update_request('ports', update_port, port['port']['id']) res = req.get_response(self.api) self.assertEqual(res.status_int, 400) self._delete('ports', port['port']['id']) def test_create_port_remove_allowed_address_pairs(self): with self.network() as net: address_pairs = [{'mac_address': '00:00:00:00:00:01', 'ip_address': '10.0.0.1'}] res = self._create_port(self.fmt, net['network']['id'], arg_list=(addr_pair.ADDRESS_PAIRS,), allowed_address_pairs=address_pairs) port = self.deserialize(self.fmt, res) update_port = {'port': {addr_pair.ADDRESS_PAIRS: []}} req = self.new_update_request('ports', update_port, port['port']['id']) port = self.deserialize(self.fmt, req.get_response(self.api)) self.assertEqual(port['port'][addr_pair.ADDRESS_PAIRS], []) self._delete('ports', port['port']['id']) ",,554,9
openstack%2Fdiskimage-builder~master~I8ceb97626d389c5bcb66fa3058f74388009ea677,openstack/diskimage-builder,master,I8ceb97626d389c5bcb66fa3058f74388009ea677,Delete -new image once copied,MERGED,2013-09-04 12:24:52.000000000,2013-09-05 16:11:12.000000000,2013-09-05 16:11:12.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-09-04 12:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/409667553500bfef2a1823765bc6ac5d1351488b', 'message': 'Delete -new image once copied\n\nBefore, this was created on /tmp/image.XXX so was removed at the\nend of the script.\n\nChange-Id: I8ceb97626d389c5bcb66fa3058f74388009ea677\n'}, {'number': 2, 'created': '2013-09-05 09:39:50.000000000', 'files': ['lib/img-functions'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/a495079695e914fa7ec93292497bfc2471f41510', 'message': 'Delete -new image once copied\n\nBefore, this was created on /tmp/image.XXX so was removed at the\nend of the script.\n\nChange-Id: I8ceb97626d389c5bcb66fa3058f74388009ea677\n'}]",1,45042,a495079695e914fa7ec93292497bfc2471f41510,12,4,2,1726,,,0,"Delete -new image once copied

Before, this was created on /tmp/image.XXX so was removed at the
end of the script.

Change-Id: I8ceb97626d389c5bcb66fa3058f74388009ea677
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/42/45042/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/img-functions'],1,409667553500bfef2a1823765bc6ac5d1351488b,ghe/new-image, rm $1-new,,1,0
openstack%2Ftripleo-image-elements~master~I1f1b9574cafe14a66aeecb64e499f0a4beecd078,openstack/tripleo-image-elements,master,I1f1b9574cafe14a66aeecb64e499f0a4beecd078,Fix dir install location in o-r-c README,MERGED,2013-09-04 07:10:34.000000000,2013-09-05 16:08:48.000000000,2013-09-05 16:08:48.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1926}]","[{'number': 1, 'created': '2013-09-04 07:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ada5859ff098e1d792cd26a2c80d2985eeaf2874', 'message': 'Fix typo on os-refresh-config install dir\n\nChange-Id: I1f1b9574cafe14a66aeecb64e499f0a4beecd078\n'}, {'number': 2, 'created': '2013-09-05 09:50:46.000000000', 'files': ['elements/os-refresh-config/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/124329a40e8dc05952bf7632a01bec91abc71abe', 'message': 'Fix dir install location in o-r-c README\n\nChange-Id: I1f1b9574cafe14a66aeecb64e499f0a4beecd078\n'}]",0,45016,124329a40e8dc05952bf7632a01bec91abc71abe,13,3,2,1726,,,0,"Fix dir install location in o-r-c README

Change-Id: I1f1b9574cafe14a66aeecb64e499f0a4beecd078
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/16/45016/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/os-refresh-config/install.d/01-os-refresh-config'],1,ada5859ff098e1d792cd26a2c80d2985eeaf2874,ghe/ocr-orc, install -m 0755 -o root -g root -d /opt/stack/os-refresh-config/$d, install -m 0755 -o root -g root -d /opt/stack/os-config-refresh/$d,1,1
openstack%2Fdevstack~master~I74c3c436d009fed898c5ae4ffb82763e9a337d90,openstack/devstack,master,I74c3c436d009fed898c5ae4ffb82763e9a337d90,Switch Ceilometer default backend to MySQL,MERGED,2013-08-27 09:46:06.000000000,2013-09-05 16:02:08.000000000,2013-09-05 16:02:08.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 595}, {'_account_id': 970}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 4277}, {'_account_id': 4491}, {'_account_id': 4573}, {'_account_id': 4715}, {'_account_id': 6537}]","[{'number': 2, 'created': '2013-08-27 09:46:06.000000000', 'files': ['lib/ceilometer'], 'web_link': 'https://opendev.org/openstack/devstack/commit/69f745748d4f2bcfd3e678037187bce1f8e53ccf', 'message': 'Switch Ceilometer default backend to MySQL\n\nMongoDB 2.4 not being available in Ubuntu cloud archive for a while now,\nand the catch up done by this driver allows me to think it might be a\ngood idea to switch by default on SQL for now on devstack.\n\nWe can add another job to have Ceilometer tested on MongoDB too later.\n\nChange-Id: I74c3c436d009fed898c5ae4ffb82763e9a337d90\n'}, {'number': 1, 'created': '2013-08-27 09:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/aa9af935674f52d3df7deeade5b03f4742ff3163', 'message': 'Switch Ceilometer default backend to MySQL\n\nMongoDB 2.4 not being available in Ubuntu cloud archive for a while now,\nand the catch up done by this driver allows me to think it might be a\ngood idea to switch by default on SQL for now on devstack.\n\nWe can add another job to have Ceilometer tested on MongoDB too later.\n\nChange-Id: I74c3c436d009fed898c5ae4ffb82763e9a337d90\n'}]",0,43851,69f745748d4f2bcfd3e678037187bce1f8e53ccf,21,13,2,1669,,,0,"Switch Ceilometer default backend to MySQL

MongoDB 2.4 not being available in Ubuntu cloud archive for a while now,
and the catch up done by this driver allows me to think it might be a
good idea to switch by default on SQL for now on devstack.

We can add another job to have Ceilometer tested on MongoDB too later.

Change-Id: I74c3c436d009fed898c5ae4ffb82763e9a337d90
",git fetch https://review.opendev.org/openstack/devstack refs/changes/51/43851/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceilometer'],1,69f745748d4f2bcfd3e678037187bce1f8e53ccf,jd/ceilometer-default-sql,CEILOMETER_BACKEND=${CEILOMETER_BACKEND:-mysql},CEILOMETER_BACKEND=${CEILOMETER_BACKEND:-mongodb},1,1
openstack%2Fnova~master~I8efd6af6706a097fb540e040a86ccbeaf131631f,openstack/nova,master,I8efd6af6706a097fb540e040a86ccbeaf131631f,Enable libvirt driver to use the new BDM format,MERGED,2013-08-17 15:06:42.000000000,2013-09-05 16:01:40.000000000,2013-09-05 16:01:37.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5511}, {'_account_id': 7593}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-08-17 15:06:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7598520f98f1671772254176c3119865f52cfd92', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus.\n\nIt also modifies some of the code paths in the libvirt driver that use\nthe block device info directly (and not through the blockinfo module) to\nbe aware of the new format. Due to very nicely factored code - there\nwere only a few instances of this in the driver itself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 2, 'created': '2013-08-17 15:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5da0c7f2722b3b5d0437a08e3b931b1780874494', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this.\n\nIt also modifies some of the code paths in the libvirt driver that use\nthe block device info directly (and not through the blockinfo module) to\nbe aware of the new format. Due to very nicely factored code - there\nwere only a few instances of this in the driver itself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 3, 'created': '2013-08-19 08:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f6643bba92c3c23d6ee673250b9b6deffa42d27b', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this.\n\nIt also modifies some of the code paths in the libvirt driver that use\nthe block device info directly (and not through the blockinfo module) to\nbe aware of the new format. Due to very nicely factored code - there\nwere only a few instances of this in the driver itself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nAdds mock to test-requirements - it is already present in the\nrequirements project.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 4, 'created': '2013-08-19 16:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec429a8828baa583036dc85f898a52f0445d82ee', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this.\n\nIt also modifies some of the code paths in the libvirt driver that use\nthe block device info directly (and not through the blockinfo module) to\nbe aware of the new format. Due to very nicely factored code - there\nwere only a few instances of this in the driver itself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nAdds mock to test-requirements - it is already present in the\nrequirements project.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 5, 'created': '2013-08-22 10:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2bf5d188bd2fb222d6051cb3f98987495320b73e', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this. Some of the libvirt specific code paths in the\ngeneral defaulting function in compute utils have been removed as they\nare not needed since the driver now takes care of this.\n\nFurther to that, this patch modifies some of the code paths in the\nlibvirt driver that use the block device info directly (and not through\nthe blockinfo module) to be aware of the new format. Due to very nicely\nfactored code - there were only a few instances of this in the driver\nitself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nAdds mock to test-requirements - it is already present in the\nrequirements project.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 6, 'created': '2013-08-23 14:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64d41dc483fa9a2057d737db653c6267d05c8520', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this. Some of the libvirt specific code paths in the\ngeneral defaulting function in compute utils have been removed as they\nare not needed since the driver now takes care of this.\n\nFurther to that, this patch modifies some of the code paths in the\nlibvirt driver that use the block device info directly (and not through\nthe blockinfo module) to be aware of the new format. Due to very nicely\nfactored code - there were only a few instances of this in the driver\nitself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nAdds mock to test-requirements - it is already present in the\nrequirements project.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 7, 'created': '2013-08-26 08:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea7ada80aae914a0c806d47640f6f77111364faf', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this. Some of the libvirt specific code paths in the\ngeneral defaulting function in compute utils have been removed as they\nare not needed since the driver now takes care of this.\n\nFurther to that, this patch modifies some of the code paths in the\nlibvirt driver that use the block device info directly (and not through\nthe blockinfo module) to be aware of the new format. Due to very nicely\nfactored code - there were only a few instances of this in the driver\nitself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nAdds mock to test-requirements - it is already present in the\nrequirements project.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 8, 'created': '2013-08-29 17:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/81d83d2ce3154f2a4d339ab383016e3a27aeba8d', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this. Some of the libvirt specific code paths in the\ngeneral defaulting function in compute utils have been removed as they\nare not needed since the driver now takes care of this.\n\nFurther to that, this patch modifies some of the code paths in the\nlibvirt driver that use the block device info directly (and not through\nthe blockinfo module) to be aware of the new format. Due to very nicely\nfactored code - there were only a few instances of this in the driver\nitself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nAdds mock to test-requirements - it is already present in the\nrequirements project.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 9, 'created': '2013-09-02 13:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9fd6c860749a22add3beac847eb9618b38e45fe', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this. Some of the libvirt specific code paths in the\ngeneral defaulting function in compute utils have been removed as they\nare not needed since the driver now takes care of this.\n\nFurther to that, this patch modifies some of the code paths in the\nlibvirt driver that use the block device info directly (and not through\nthe blockinfo module) to be aware of the new format. Due to very nicely\nfactored code - there were only a few instances of this in the driver\nitself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nAdds mock to test-requirements - it is already present in the\nrequirements project.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 10, 'created': '2013-09-04 09:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/620527f0d85a0dac233f58b7046afb8cb9db2093', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this. Some of the libvirt specific code paths in the\ngeneral defaulting function in compute utils have been removed as they\nare not needed since the driver now takes care of this.\n\nFurther to that, this patch modifies some of the code paths in the\nlibvirt driver that use the block device info directly (and not through\nthe blockinfo module) to be aware of the new format. Due to very nicely\nfactored code - there were only a few instances of this in the driver\nitself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nAdds mock to test-requirements - it is already present in the\nrequirements project.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 11, 'created': '2013-09-04 11:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91148afb41ec5a5f528dea95de7c8360e251cf11', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this. Some of the libvirt specific code paths in the\ngeneral defaulting function in compute utils have been removed as they\nare not needed since the driver now takes care of this.\n\nFurther to that, this patch modifies some of the code paths in the\nlibvirt driver that use the block device info directly (and not through\nthe blockinfo module) to be aware of the new format. Due to very nicely\nfactored code - there were only a few instances of this in the driver\nitself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 12, 'created': '2013-09-04 14:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ece3d669df22834fa63b7b7b9b5ce0521525e9b9', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this. Some of the libvirt specific code paths in the\ngeneral defaulting function in compute utils have been removed as they\nare not needed since the driver now takes care of this.\n\nFurther to that, this patch modifies some of the code paths in the\nlibvirt driver that use the block device info directly (and not through\nthe blockinfo module) to be aware of the new format. Due to very nicely\nfactored code - there were only a few instances of this in the driver\nitself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}, {'number': 13, 'created': '2013-09-05 08:06:48.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/blockinfo.py', 'nova/virt/libvirt/driver.py', 'nova/virt/fake.py', 'nova/tests/virt/libvirt/test_libvirt_blockinfo.py', 'nova/tests/compute/test_compute_utils.py', 'nova/virt/virtapi.py', 'nova/block_device.py', 'nova/compute/manager.py', 'nova/tests/compute/test_virtapi.py', 'nova/compute/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f9f247ef42c690bf1bd1ae65135c6e7fbd0d3c8c', 'message': ""Enable libvirt driver to use the new BDM format\n\nThis patch makes the necessary changes in the libvirt driver to enable\nit to use some of the features of the new block device mapping format.\n\nAfter this patch it will be possible to set the bus, and device_type per\nblock device, and libvirt driver will honor these when spawning an\ninstance (note that attaching a volume still does not use the new data\nformat).\n\nIt utilizes some of the existing code in the blockinfo module to be able\nto default device names (it does so by overriding the methods introduced\nin I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default\nvalues to fields like device_type and disk_bus if it is not provided or\nif it is bogus. As this implies the driver changing the block devices in\nthe database, a new virtapi method block_device_mapping_update is added\nto accommodate this. Some of the libvirt specific code paths in the\ngeneral defaulting function in compute utils have been removed as they\nare not needed since the driver now takes care of this.\n\nFurther to that, this patch modifies some of the code paths in the\nlibvirt driver that use the block device info directly (and not through\nthe blockinfo module) to be aware of the new format. Due to very nicely\nfactored code - there were only a few instances of this in the driver\nitself.\n\nIt also overrides the libvirt driver's need_legacy_block_device_info\nmethod to tell the compute manager to feed it the new format when\nneeded.\n\nThis patch concludes the blueprint: improve-block-device-handling\n\nChange-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f\n""}]",12,42474,f9f247ef42c690bf1bd1ae65135c6e7fbd0d3c8c,53,11,13,5511,,,0,"Enable libvirt driver to use the new BDM format

This patch makes the necessary changes in the libvirt driver to enable
it to use some of the features of the new block device mapping format.

After this patch it will be possible to set the bus, and device_type per
block device, and libvirt driver will honor these when spawning an
instance (note that attaching a volume still does not use the new data
format).

It utilizes some of the existing code in the blockinfo module to be able
to default device names (it does so by overriding the methods introduced
in I84541f8ff6e1b5978734e5def69946d014c66fdf), and also assign default
values to fields like device_type and disk_bus if it is not provided or
if it is bogus. As this implies the driver changing the block devices in
the database, a new virtapi method block_device_mapping_update is added
to accommodate this. Some of the libvirt specific code paths in the
general defaulting function in compute utils have been removed as they
are not needed since the driver now takes care of this.

Further to that, this patch modifies some of the code paths in the
libvirt driver that use the block device info directly (and not through
the blockinfo module) to be aware of the new format. Due to very nicely
factored code - there were only a few instances of this in the driver
itself.

It also overrides the libvirt driver's need_legacy_block_device_info
method to tell the compute manager to feed it the new format when
needed.

This patch concludes the blueprint: improve-block-device-handling

Change-Id: I8efd6af6706a097fb540e040a86ccbeaf131631f
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/42474/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/blockinfo.py', 'nova/virt/libvirt/driver.py', 'nova/virt/fake.py', 'nova/tests/virt/libvirt/test_libvirt_blockinfo.py', 'nova/block_device.py', 'nova/virt/virtapi.py', 'nova/compute/manager.py', 'nova/tests/compute/test_virtapi.py']",9,7598520f98f1671772254176c3119865f52cfd92,bp/improve-block-device-handling," def test_block_device_mapping_update(self): self.assertExpected('block_device_mapping_update', 'fake_bdm', 'fake_values') ",,567,100
openstack%2Ftempest~master~I13ca20a249e9eba0a52e6eb3c6e82baaa38fc5a0,openstack/tempest,master,I13ca20a249e9eba0a52e6eb3c6e82baaa38fc5a0,Added test case to check floating IP API operations,MERGED,2013-08-09 07:22:49.000000000,2013-09-05 16:01:34.000000000,2013-09-05 16:01:34.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1687}, {'_account_id': 1795}, {'_account_id': 2035}, {'_account_id': 4694}, {'_account_id': 5292}, {'_account_id': 5803}, {'_account_id': 6455}]","[{'number': 1, 'created': '2013-08-09 07:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6c64acc750ed0ec04140b1ff9ff06ea21ef91b0a', 'message': ""Added test case to check floating IP API operations\n\nAdded a test case by the name\n'test_create_list_show_update_delete_floating_ip' to check\nfloating IP API operations. Also added supporting methods\nin network_client.py\n\nImplements blueprint: quantum-test-l2-abstraction\n\nChange-Id: I13ca20a249e9eba0a52e6eb3c6e82baaa38fc5a0\n""}, {'number': 2, 'created': '2013-08-09 08:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/421754edb6c8839ed44f35fddc533d3ee6826486', 'message': ""Added test case to check floating IP API operations\n\nAdded a test case by the name\n'test_create_list_show_update_delete_floating_ip' to check\nfloating IP API operations. Also added supporting methods\nin network_client.py\n\nImplements blueprint: quantum-test-l2-abstraction\n\nChange-Id: I13ca20a249e9eba0a52e6eb3c6e82baaa38fc5a0\n""}, {'number': 3, 'created': '2013-08-13 12:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2e5ef59938088356286982bb69af6b9523e99dc2', 'message': ""Added test case to check floating IP API operations\n\nAdded a test case by the name\n'test_create_list_show_update_delete_floating_ip' to check\nfloating IP API operations. Also added supporting methods\nin network_client.py\n\nImplements blueprint: quantum-test-l2-abstraction\n\nChange-Id: I13ca20a249e9eba0a52e6eb3c6e82baaa38fc5a0\n""}, {'number': 4, 'created': '2013-08-19 09:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/929d9bfc360d47878453546fba72fa5540a9a0a6', 'message': ""Added test case to check floating IP API operations\n\nAdded a test case by the name\n'test_create_list_show_update_delete_floating_ip' to check\nfloating IP API operations. Also added supporting methods\nin network_client.py\n\nImplements blueprint: quantum-test-l2-abstraction\n\nChange-Id: I13ca20a249e9eba0a52e6eb3c6e82baaa38fc5a0\n""}, {'number': 5, 'created': '2013-08-19 11:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/57eed0bd196070a9bceec43338500689032b781a', 'message': ""Added test case to check floating IP API operations\n\nAdded a test case by the name\n'test_create_list_show_update_delete_floating_ip' to check\nfloating IP API operations. Also added supporting methods\nin network_client.py\n\nImplements blueprint: quantum-test-l2-abstraction\n\nChange-Id: I13ca20a249e9eba0a52e6eb3c6e82baaa38fc5a0\n""}, {'number': 6, 'created': '2013-08-26 06:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b77c27f35d329dc6d90ca5089f655e20c2e4aae8', 'message': ""Added test case to check floating IP API operations\n\nAdded a test case by the name\n'test_create_list_show_update_delete_floating_ip' to check\nfloating IP API operations. Also added supporting methods\nin network_client.py\n\nImplements blueprint: quantum-test-l2-abstraction\n\nChange-Id: I13ca20a249e9eba0a52e6eb3c6e82baaa38fc5a0\n""}, {'number': 7, 'created': '2013-09-04 10:44:34.000000000', 'files': ['tempest/api/network/test_floating_ips.py', 'tempest/services/network/json/network_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f1a291524ef70d59025abeafcffeaa3d83dd6546', 'message': ""Added test case to check floating IP API operations\n\nAdded a test case by the name\n'test_create_list_show_update_delete_floating_ip' to check\nfloating IP API operations. Also added supporting methods\nin network_client.py\n\nImplements blueprint: quantum-test-l2-abstraction\n\nChange-Id: I13ca20a249e9eba0a52e6eb3c6e82baaa38fc5a0\n""}]",22,41038,f1a291524ef70d59025abeafcffeaa3d83dd6546,44,9,7,1687,,,0,"Added test case to check floating IP API operations

Added a test case by the name
'test_create_list_show_update_delete_floating_ip' to check
floating IP API operations. Also added supporting methods
in network_client.py

Implements blueprint: quantum-test-l2-abstraction

Change-Id: I13ca20a249e9eba0a52e6eb3c6e82baaa38fc5a0
",git fetch https://review.opendev.org/openstack/tempest refs/changes/38/41038/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/network/test_floating_ips.py', 'tempest/services/network/json/network_client.py']",2,6c64acc750ed0ec04140b1ff9ff06ea21ef91b0a,bp/quantum-test-l2-abstraction," Implements create, delete, update, list and show for the basic Neutron abstractions (networks, sub-networks ports and floating IPs): def create_floating_ip(self, ext_network_id, **kwargs): post_body = { 'floatingip': { 'floating_network_id': ext_network_id, 'port_id': kwargs.get('port_id', None) } } body = json.dumps(post_body) uri = '%s/floatingips' % (self.uri_prefix) resp, body = self.post(uri, headers=self.headers, body=body) body = json.loads(body) return resp, body def show_floating_ip(self, floating_ip_id): uri = '%s/floatingips/%s' % (self.uri_prefix, floating_ip_id) resp, body = self.get(uri, self.headers) body = json.loads(body) return resp, body def list_floating_ips(self): uri = '%s/floatingips' % (self.uri_prefix) resp, body = self.get(uri, self.headers) body = json.loads(body) return resp, body def delete_floating_ip(self, floating_ip_id): uri = '%s/floatingips/%s' % (self.uri_prefix, floating_ip_id) resp, body = self.delete(uri, self.headers) return resp, body def update_floating_ip(self, floating_ip_id, port_id): post_body = { 'floatingip': { 'port_id': port_id } } body = json.dumps(post_body) uri = '%s/floatingips/%s' % (self.uri_prefix, floating_ip_id) resp, body = self.put(uri, headers=self.headers, body=body) body = json.loads(body) return resp, body def create_router(self, name, **kwargs): post_body = { 'router': { 'name': name, } } post_body['router']['admin_state_up'] = kwargs.get( 'admin_state_up', True) post_body['router']['external_gateway_info'] = kwargs.get( 'external_gateway_info', None) body = json.dumps(post_body) uri = '%s/routers' % (self.uri_prefix) resp, body = self.post(uri, headers=self.headers, body=body) body = json.loads(body) return resp, body def add_router_interface_with_subnet_id(self, router_id, subnet_id): uri = '%s/routers/%s/add_router_interface' % (self.uri_prefix, router_id) update_body = {""subnet_id"": subnet_id} update_body = json.dumps(update_body) resp, body = self.put(uri, update_body, self.headers) body = json.loads(body) return resp, body def remove_router_interface_with_subnet_id(self, router_id, subnet_id): uri = '%s/routers/%s/remove_router_interface' % (self.uri_prefix, router_id) update_body = {""subnet_id"": subnet_id} update_body = json.dumps(update_body) resp, body = self.put(uri, update_body, self.headers) body = json.loads(body) return resp, body def delete_router(self, router_id): uri = '%s/routers/%s' % (self.uri_prefix, router_id) resp, body = self.delete(uri, self.headers) return resp, body"," Implements create, delete, list and show for the basic Neutron abstractions (networks, sub-networks and ports):",218,2
openstack%2Fmurano-deployment~release-0.2~Iaac43376f9e3514fe924920035a5a779a303ff11,openstack/murano-deployment,release-0.2,Iaac43376f9e3514fe924920035a5a779a303ff11,Default branch name fixed.,MERGED,2013-09-05 15:59:29.000000000,2013-09-05 16:01:26.000000000,2013-09-05 16:01:26.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-09-05 15:59:29.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/2a829d59d0daac3052ab255ad6e18d7d98fe4f29', 'message': 'Default branch name fixed.\n\nChange-Id: Iaac43376f9e3514fe924920035a5a779a303ff11\n'}]",0,45261,2a829d59d0daac3052ab255ad6e18d7d98fe4f29,5,3,1,7562,,,0,"Default branch name fixed.

Change-Id: Iaac43376f9e3514fe924920035a5a779a303ff11
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/61/45261/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,2a829d59d0daac3052ab255ad6e18d7d98fe4f29,murano-git-install-branch-fix,BRANCH_NAME='release-0.2',BRANCH_NAME='master',1,1
openstack%2Ftempest~master~I37d27f8b890941d9333e71c64b1af6127505d766,openstack/tempest,master,I37d27f8b890941d9333e71c64b1af6127505d766,raise assertion error if output is falsy,MERGED,2013-08-21 16:09:40.000000000,2013-09-05 15:59:58.000000000,2013-09-05 15:59:58.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2340}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 6796}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-08-21 16:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e5e32f3e140c57393170312c54b16e09befa4b6f', 'message': 'raise assertion error if output is falsy\n\nNo error was being raised when output was {}, but the following line\n""output.split(\'\\n\')"" raised an AssertionError.\n\nChange-Id: I37d27f8b890941d9333e71c64b1af6127505d766\n'}, {'number': 2, 'created': '2013-08-22 10:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8457299fc6dad664eb1f99a494f88ceeaed3eda0', 'message': 'raise assertion error if output is falsy\n\nNo error was being raised when output was {}, but the following line\n""output.split(\'\\n\')"" raised an AssertionError.\n\nChange-Id: I37d27f8b890941d9333e71c64b1af6127505d766\n'}, {'number': 3, 'created': '2013-09-02 09:41:11.000000000', 'files': ['tempest/api/compute/servers/test_server_actions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a767b52b1028bacc37e6a8e0d6e95a4cda18877a', 'message': 'raise assertion error if output is falsy\n\nNo error was being raised when output was {}, but the following line\n""output.split(\'\\n\')"" raised an AssertionError.\n\nChange-Id: I37d27f8b890941d9333e71c64b1af6127505d766\n'}]",3,43155,a767b52b1028bacc37e6a8e0d6e95a4cda18877a,30,7,3,2340,,,0,"raise assertion error if output is falsy

No error was being raised when output was {}, but the following line
""output.split('\n')"" raised an AssertionError.

Change-Id: I37d27f8b890941d9333e71c64b1af6127505d766
",git fetch https://review.opendev.org/openstack/tempest refs/changes/55/43155/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_server_actions.py'],1,e5e32f3e140c57393170312c54b16e09befa4b6f,no-console-output," assert output, ""Console output was empty."""," self.assertNotEqual(output, None)",1,1
openstack%2Fnova~master~Ic98db496a3e175c9dee98657609a66934c41d557,openstack/nova,master,Ic98db496a3e175c9dee98657609a66934c41d557,Adding VIF Driver to support Mellanox Plugin,MERGED,2013-07-01 20:34:21.000000000,2013-09-05 15:58:44.000000000,2013-09-05 15:58:41.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 704}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2166}, {'_account_id': 4727}, {'_account_id': 7629}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-01 20:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/219d6168d49e25184534212479057442ac696468', 'message': 'Adding VIF Driver to support Mellanox Plugin\n\nblueprint mellanox-vif-driver\n\nChange-Id: Ic98db496a3e175c9dee98657609a66934c41d557\n'}, {'number': 2, 'created': '2013-07-01 23:12:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f4579d11f849c4b60cf834d23174560575d1ffc', 'message': 'Adding VIF Driver to support Mellanox Plugin\n\nblueprint mellanox-vif-driver\n\nChange-Id: Ic98db496a3e175c9dee98657609a66934c41d557\n'}, {'number': 3, 'created': '2013-07-07 10:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9005f97cd7ea3fc5b371ca3a9bc336e096b5103e', 'message': 'Adding VIF Driver to support Mellanox Plugin\n\nblueprint mellanox-vif-driver\n\nDocImpact\n\nChange-Id: Ic98db496a3e175c9dee98657609a66934c41d557\n'}, {'number': 4, 'created': '2013-07-12 07:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a23f797ff3e7547b3fde7ecbcd67372d0ce7b93', 'message': 'Adding VIF Driver to support Mellanox Plugin\n\nblueprint mellanox-vif-driver\n\nDocImpact\n\nChange-Id: Ic98db496a3e175c9dee98657609a66934c41d557\n'}, {'number': 5, 'created': '2013-07-12 08:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9d552442023cb2b443fc41c4367cbd7cfe2caba', 'message': 'Adding VIF Driver to support Mellanox Plugin\n\nblueprint mellanox-vif-driver\n\nDocImpact\n\nChange-Id: Ic98db496a3e175c9dee98657609a66934c41d557\n'}, {'number': 6, 'created': '2013-07-25 21:39:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/016e0b9b6063444f2a7213595cdfd3df01a071c5', 'message': 'Adding VIF Driver to support Mellanox Plugin\n\nblueprint mellanox-vif-driver\n\nDocImpact\n\nChange-Id: Ic98db496a3e175c9dee98657609a66934c41d557\n'}, {'number': 7, 'created': '2013-08-08 10:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71880fbcad609eb983ef7b851ff1c7db215cf232', 'message': 'Adding VIF Driver to support Mellanox Plugin\n\nblueprint mellanox-vif-driver\n\nDocImpact\n\nChange-Id: Ic98db496a3e175c9dee98657609a66934c41d557\n'}, {'number': 8, 'created': '2013-08-29 06:33:59.000000000', 'files': ['nova/network/neutronv2/api.py', 'etc/nova/rootwrap.d/network.filters', 'nova/virt/libvirt/vif.py', 'nova/tests/virt/libvirt/test_libvirt_config.py', 'nova/network/model.py', 'nova/virt/libvirt/designer.py', 'nova/tests/network/test_manager.py', 'nova/tests/virt/libvirt/test_libvirt_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/87e6697906d577690404815a6cf98ef922952b90', 'message': 'Adding VIF Driver to support Mellanox Plugin\n\nblueprint mellanox-vif-driver\n\nDocImpact\n\nChange-Id: Ic98db496a3e175c9dee98657609a66934c41d557\n'}]",35,35189,87e6697906d577690404815a6cf98ef922952b90,62,11,8,4727,,,0,"Adding VIF Driver to support Mellanox Plugin

blueprint mellanox-vif-driver

DocImpact

Change-Id: Ic98db496a3e175c9dee98657609a66934c41d557
",git fetch https://review.opendev.org/openstack/nova refs/changes/89/35189/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/vif.py', 'nova/tests/virt/libvirt/test_libvirt_config.py', 'nova/network/model.py', 'nova/virt/libvirt/designer.py', 'nova/network/quantumv2/api.py', 'nova/tests/network/test_manager.py', 'nova/tests/virt/libvirt/test_libvirt_vif.py']",7,219d6168d49e25184534212479057442ac696468,bp/mellanox-vif-driver," mapping_direct = { 'mac': 'ca:fe:de:ad:be:ef', 'vif_uuid': 'vif-xxx-yyy-zzz', 'vif_type': network_model.VIF_TYPE_DIRECT, 'vif_devname': 'tap-xxx-yyy-zzz', } net_direct = { 'cidr': '192.168.1.0/24', 'netmask': '255.255.255.0', 'vlan': 99, 'gateway': '192.168.1.1', 'broadcast': '192.168.1.255', 'dns1': '8.8.8.8', 'id': 'network-id-xxx-yyy-zzz' } def test_direct_vif_driver(self): def get_connection(): return fakelibvirt.Connection(""qemu:///session"", False) d = vif.LibvirtGenericVIFDriver(get_connection) xml = self._get_instance_xml(d, self.net_direct, self.mapping_direct) doc = etree.fromstring(xml) ret = doc.findall('./devices/interface') self.assertEqual(len(ret), 1) node = ret[0] self.assertEqual(node.get(""type""), ""direct"") mac = node.find(""mac"").get(""address"") self.assertEqual(mac, self.mapping_direct['mac']) source = node.find(""source"") dev_name = source.get(""dev"") mode = source.get(""mode"") self.assertEqual(dev_name, ""eth-xxx-yyy-zzz"") self.assertEqual(mode, ""passthrough"") model = node.find(""model"").get(""type"") self.assertEqual(model, ""virtio"") ",,126,2
openstack%2Fkeystone~master~Ic3ae662ce418f2548006de27ae22941a31adcb8d,openstack/keystone,master,Ic3ae662ce418f2548006de27ae22941a31adcb8d,Imported Translations from Transifex,MERGED,2013-09-05 06:01:25.000000000,2013-09-05 15:56:42.000000000,2013-09-05 15:56:41.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-09-05 06:01:25.000000000', 'files': ['keystone/locale/ko/LC_MESSAGES/keystone.po', 'keystone/locale/tl/LC_MESSAGES/keystone.po', 'keystone/locale/en_GB/LC_MESSAGES/keystone.po', 'keystone/locale/id/LC_MESSAGES/keystone.po', 'keystone/locale/sw_KE/LC_MESSAGES/keystone.po', 'keystone/locale/ru/LC_MESSAGES/keystone.po', 'keystone/locale/ms/LC_MESSAGES/keystone.po', 'keystone/locale/bs/LC_MESSAGES/keystone.po', 'keystone/locale/pt/LC_MESSAGES/keystone.po', 'keystone/locale/de/LC_MESSAGES/keystone.po', 'keystone/locale/hu/LC_MESSAGES/keystone.po', 'keystone/locale/ne/LC_MESSAGES/keystone.po', 'keystone/locale/sk/LC_MESSAGES/keystone.po', 'keystone/locale/it/LC_MESSAGES/keystone.po', 'keystone/locale/ro/LC_MESSAGES/keystone.po', 'keystone/locale/ca/LC_MESSAGES/keystone.po', 'keystone/locale/bg_BG/LC_MESSAGES/keystone.po', 'keystone/locale/cs/LC_MESSAGES/keystone.po', 'keystone/locale/en_US/LC_MESSAGES/keystone.po', 'keystone/locale/da/LC_MESSAGES/keystone.po', 'keystone/locale/es/LC_MESSAGES/keystone.po', 'keystone/locale/hr/LC_MESSAGES/keystone.po', 'keystone/locale/ru_RU/LC_MESSAGES/keystone.po', 'keystone/locale/zh_TW/LC_MESSAGES/keystone.po', 'keystone/locale/fi_FI/LC_MESSAGES/keystone.po', 'keystone/locale/keystone.pot', 'keystone/locale/pl_PL/LC_MESSAGES/keystone.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/locale/ko_KR/LC_MESSAGES/keystone.po', 'keystone/locale/fr/LC_MESSAGES/keystone.po', 'keystone/locale/ka_GE/LC_MESSAGES/keystone.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone.po', 'keystone/locale/vi_VN/LC_MESSAGES/keystone.po', 'keystone/locale/it_IT/LC_MESSAGES/keystone.po', 'keystone/locale/ja/LC_MESSAGES/keystone.po', 'keystone/locale/nl_NL/LC_MESSAGES/keystone.po', 'keystone/locale/tr_TR/LC_MESSAGES/keystone.po', 'keystone/locale/zh_HK/LC_MESSAGES/keystone.po', 'keystone/locale/sl_SI/LC_MESSAGES/keystone.po', 'keystone/locale/hi/LC_MESSAGES/keystone.po', 'keystone/locale/uk/LC_MESSAGES/keystone.po', 'keystone/locale/nb/LC_MESSAGES/keystone.po', 'keystone/locale/es_MX/LC_MESSAGES/keystone.po'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ddac90e78eeefb50534fb1fb5194e5f62fafcf5a', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic3ae662ce418f2548006de27ae22941a31adcb8d\n'}]",0,45173,ddac90e78eeefb50534fb1fb5194e5f62fafcf5a,6,3,1,3,,,0,"Imported Translations from Transifex

Change-Id: Ic3ae662ce418f2548006de27ae22941a31adcb8d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/73/45173/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/locale/ko/LC_MESSAGES/keystone.po', 'keystone/locale/tl/LC_MESSAGES/keystone.po', 'keystone/locale/en_GB/LC_MESSAGES/keystone.po', 'keystone/locale/id/LC_MESSAGES/keystone.po', 'keystone/locale/sw_KE/LC_MESSAGES/keystone.po', 'keystone/locale/ru/LC_MESSAGES/keystone.po', 'keystone/locale/ms/LC_MESSAGES/keystone.po', 'keystone/locale/bs/LC_MESSAGES/keystone.po', 'keystone/locale/pt/LC_MESSAGES/keystone.po', 'keystone/locale/de/LC_MESSAGES/keystone.po', 'keystone/locale/hu/LC_MESSAGES/keystone.po', 'keystone/locale/ne/LC_MESSAGES/keystone.po', 'keystone/locale/sk/LC_MESSAGES/keystone.po', 'keystone/locale/it/LC_MESSAGES/keystone.po', 'keystone/locale/ro/LC_MESSAGES/keystone.po', 'keystone/locale/ca/LC_MESSAGES/keystone.po', 'keystone/locale/bg_BG/LC_MESSAGES/keystone.po', 'keystone/locale/cs/LC_MESSAGES/keystone.po', 'keystone/locale/en_US/LC_MESSAGES/keystone.po', 'keystone/locale/da/LC_MESSAGES/keystone.po', 'keystone/locale/es/LC_MESSAGES/keystone.po', 'keystone/locale/hr/LC_MESSAGES/keystone.po', 'keystone/locale/ru_RU/LC_MESSAGES/keystone.po', 'keystone/locale/zh_TW/LC_MESSAGES/keystone.po', 'keystone/locale/fi_FI/LC_MESSAGES/keystone.po', 'keystone/locale/keystone.pot', 'keystone/locale/pl_PL/LC_MESSAGES/keystone.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/locale/ko_KR/LC_MESSAGES/keystone.po', 'keystone/locale/fr/LC_MESSAGES/keystone.po', 'keystone/locale/ka_GE/LC_MESSAGES/keystone.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone.po', 'keystone/locale/vi_VN/LC_MESSAGES/keystone.po', 'keystone/locale/it_IT/LC_MESSAGES/keystone.po', 'keystone/locale/ja/LC_MESSAGES/keystone.po', 'keystone/locale/nl_NL/LC_MESSAGES/keystone.po', 'keystone/locale/tr_TR/LC_MESSAGES/keystone.po', 'keystone/locale/zh_HK/LC_MESSAGES/keystone.po', 'keystone/locale/sl_SI/LC_MESSAGES/keystone.po', 'keystone/locale/hi/LC_MESSAGES/keystone.po', 'keystone/locale/uk/LC_MESSAGES/keystone.po', 'keystone/locale/nb/LC_MESSAGES/keystone.po', 'keystone/locale/es_MX/LC_MESSAGES/keystone.po']",44,ddac90e78eeefb50534fb1fb5194e5f62fafcf5a,transifex/translations,"""POT-Creation-Date: 2013-09-05 06:01+0000\n""#: keystone/cli.py:80 keystone/cli.py:116#: keystone/assignment/core.py:221#: keystone/assignment/core.py:636 keystone/identity/core.py:212#: keystone/common/utils.py:75#: keystone/common/utils.py:186 keystone/credential/controllers.py:40#: keystone/common/utils.py:265msgid ""CACHE_GET: Key: \""%(key)s\"" Value: \""%(value)s\""""msgid ""CACHE_GET_MULTI: \""%(keys)s\"" Values: \""%(values)s\""""msgid ""CACHE_SET: Key: \""%(key)s\"" Value: \""%(value)s\""""msgid ""CACHE_SET_MULTI: \""%s\""""msgid ""CACHE_DELETE: \""%s\""""msgid ""CACHE_DELETE_MULTI: \""%s\""""msgid ""Invalid LDAP TLS certs option: %(option)s. Choose one of: %(options)s""#: keystone/token/provider.py:81#: keystone/token/provider.py:89#: keystone/token/provider.py:99#: keystone/token/provider.py:187#: keystone/token/provider.py:191 keystone/token/providers/uuid.py:548#~ msgid ""CACHE_GET: Key: \""%(key)s)\"" \""%(value)s\"""" #~ msgstr """" #~ msgid ""CACHE_GET_MULTI: \""%(key)s\"" \""%(value)s\"""" #~ msgstr """" #~ msgid ""CACHE_SET: Key: %(key)s Value: %(value)s"" #~ msgstr """" #~ msgid ""CACHE_SET_MULTI: %s"" #~ msgstr """" #~ msgid ""CACHE_DELETE: %s"" #~ msgstr """" #~ msgid ""CACHE_DELETE_MULTI: %s"" #~ msgstr """" #~ msgid ""Invalid LDAP TLS certs option: %(option). Choose one of: %(options)s"" #~ msgstr """" ","""POT-Creation-Date: 2013-08-30 06:00+0000\n""#: keystone/cli.py:81 keystone/cli.py:117#: keystone/assignment/core.py:204#: keystone/assignment/core.py:560 keystone/identity/core.py:212#: keystone/common/utils.py:73#: keystone/common/utils.py:184 keystone/credential/controllers.py:40#: keystone/common/utils.py:263msgid ""CACHE_GET: Key: \""%(key)s)\"" \""%(value)s\""""msgid ""CACHE_GET_MULTI: \""%(key)s\"" \""%(value)s\""""msgid ""CACHE_SET: Key: %(key)s Value: %(value)s""msgid ""CACHE_SET_MULTI: %s""msgid ""CACHE_DELETE: %s""msgid ""CACHE_DELETE_MULTI: %s""msgid ""Invalid LDAP TLS certs option: %(option). Choose one of: %(options)s""#: keystone/token/provider.py:79#: keystone/token/provider.py:87#: keystone/token/provider.py:97#: keystone/token/provider.py:156#: keystone/token/provider.py:160 keystone/token/providers/uuid.py:548",3397,831
openstack%2Fzaqar~master~I505fb530e8047f478e98ce2fd6c01776b147d87f,openstack/zaqar,master,I505fb530e8047f478e98ce2fd6c01776b147d87f,Make tox use develop instead of sdist,MERGED,2013-09-05 12:59:27.000000000,2013-09-05 15:55:49.000000000,2013-09-05 15:55:49.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}]","[{'number': 1, 'created': '2013-09-05 12:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d55e2f81aec2e90ed7f82a5941ffbf674431a9a4', 'message': 'Make tox use develop instead of sdist\n\ntox 1.6 was released, which means that we can now take advantage of the\nfeature we added to it - which is using setup.py develop to install the\ncode into the virtualenv. The logic was taken from run_tests.sh - so the\nperformance issues around using tox vs. using install_venv should now be\ngone.\n\nThis patch requires tox >=1.6.\n\nChange-Id: I505fb530e8047f478e98ce2fd6c01776b147d87f\n'}, {'number': 2, 'created': '2013-09-05 15:12:21.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0a032631543b70c7400b79c9a2359f10508fa04f', 'message': 'Make tox use develop instead of sdist\n\ntox 1.6 was released, which means that we can now take advantage of the\nfeature we added to it - which is using setup.py develop to install the\ncode into the virtualenv. The logic was taken from run_tests.sh - so the\nperformance issues around using tox vs. using install_venv should now be\ngone.\n\nThis patch requires tox >=1.6.\n\nChange-Id: I505fb530e8047f478e98ce2fd6c01776b147d87f\n'}]",0,45227,0a032631543b70c7400b79c9a2359f10508fa04f,7,3,2,6159,,,0,"Make tox use develop instead of sdist

tox 1.6 was released, which means that we can now take advantage of the
feature we added to it - which is using setup.py develop to install the
code into the virtualenv. The logic was taken from run_tests.sh - so the
performance issues around using tox vs. using install_venv should now be
gone.

This patch requires tox >=1.6.

Change-Id: I505fb530e8047f478e98ce2fd6c01776b147d87f
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/27/45227/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d55e2f81aec2e90ed7f82a5941ffbf674431a9a4,,minversion = 1.6skipsdist = Trueusedevelop = True install_command = pip install -U {opts} {packages},,4,0
openstack%2Fmurano-deployment~release-0.2~I62240939c742cfc18527b5e79ef578a8bee7224a,openstack/murano-deployment,release-0.2,I62240939c742cfc18527b5e79ef578a8bee7224a,Fixed list of guides for v0.2,MERGED,2013-09-05 15:53:49.000000000,2013-09-05 15:54:19.000000000,2013-09-05 15:54:19.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-09-05 15:53:49.000000000', 'files': ['docs-builder/builder.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/5d31ee6b3a2483edb1bca63fab58a7ba0ed87a7c', 'message': 'Fixed list of guides for v0.2\n\nChange-Id: I62240939c742cfc18527b5e79ef578a8bee7224a\n'}]",0,45258,5d31ee6b3a2483edb1bca63fab58a7ba0ed87a7c,5,2,1,7225,,,0,"Fixed list of guides for v0.2

Change-Id: I62240939c742cfc18527b5e79ef578a8bee7224a
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/58/45258/1 && git format-patch -1 --stdout FETCH_HEAD,['docs-builder/builder.sh'],1,5d31ee6b3a2483edb1bca63fab58a7ba0ed87a7c,," guides=""developers-guide administrators-guide user-guide"""," guides=""developers-guide murano-deployment-guide user-guide""",1,1
openstack%2Fmurano-deployment~release-0.2~I837ba3af097f7f59123abdd99d9dc7029568ce4d,openstack/murano-deployment,release-0.2,I837ba3af097f7f59123abdd99d9dc7029568ce4d,Correct pip version now installing by murano-git-install.,MERGED,2013-09-05 14:30:27.000000000,2013-09-05 15:50:26.000000000,2013-09-05 15:50:26.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-09-05 14:30:27.000000000', 'files': ['devbox-scripts/murano-git-install.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/ea6b694234d77f745fe957363b45b0262a244876', 'message': 'Correct pip version now installing by murano-git-install.\n\nBug #1221256\n\nChange-Id: I837ba3af097f7f59123abdd99d9dc7029568ce4d\n'}]",0,45239,ea6b694234d77f745fe957363b45b0262a244876,5,3,1,7562,,,0,"Correct pip version now installing by murano-git-install.

Bug #1221256

Change-Id: I837ba3af097f7f59123abdd99d9dc7029568ce4d
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/39/45239/1 && git format-patch -1 --stdout FETCH_HEAD,['devbox-scripts/murano-git-install.sh'],1,ea6b694234d77f745fe957363b45b0262a244876,bug/1221256," log ""** Upgrading pip ..."" pip install --upgrade pip #rm /usr/bin/pip #ln -s /usr/local/bin/pip /usr/bin/pip apt-get install -y node-less python-pip log ""** Upgrading pip ..."" pip install --upgrade pip rm /usr/bin/pip ln -s /usr/local/bin/pip /usr/bin/pip", apt-get install -y node-less,11,1
openstack%2Fsahara~master~I3bd446508172e37ed2d1c5a22e311d5d2510570d,openstack/sahara,master,I3bd446508172e37ed2d1c5a22e311d5d2510570d,Add a method to retrieve job binary data from a JobOrigin record,ABANDONED,2013-08-30 19:02:48.000000000,2013-09-05 15:43:47.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6823}, {'_account_id': 7213}, {'_account_id': 7478}, {'_account_id': 8090}, {'_account_id': 8091}]","[{'number': 1, 'created': '2013-08-30 19:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a732441ff4463a3c4eb5778b4be42036a50c87ed', 'message': 'Add a method to retrieve job binary data from a JobOrigin record\n\nThis change adds a job_origin.py module to savanna/service/edp.  The\nmodule contains a method to retrieve job binary data from a JobOrigin\nrecord based on the storage type and url in the JobOrigin.  The REST\napi also contains a method to retrieve job binary data based on a\nJobOrigin id.\n\nChange-Id: I3bd446508172e37ed2d1c5a22e311d5d2510570d\n'}, {'number': 2, 'created': '2013-08-30 21:12:09.000000000', 'files': ['savanna/service/edp/job_origin.py', 'savanna/api/v11.py', 'savanna/exceptions.py', 'savanna/service/validations/edp/job_origin.py', 'savanna/service/edp/api.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/854f5759267762f14521de4a48c0b9142ee3f305', 'message': 'Add a method to retrieve job binary data from a JobOrigin record\n\nThis change adds a job_origin.py module to savanna/service/edp.  The\nmodule contains a method to retrieve job binary data from a JobOrigin\nrecord based on the storage type and url in the JobOrigin.  The REST\napi also contains a method to retrieve job binary data based on a\nJobOrigin id.\n\nChange-Id: I3bd446508172e37ed2d1c5a22e311d5d2510570d\n'}]",5,44526,854f5759267762f14521de4a48c0b9142ee3f305,13,7,2,8091,,,0,"Add a method to retrieve job binary data from a JobOrigin record

This change adds a job_origin.py module to savanna/service/edp.  The
module contains a method to retrieve job binary data from a JobOrigin
record based on the storage type and url in the JobOrigin.  The REST
api also contains a method to retrieve job binary data based on a
JobOrigin id.

Change-Id: I3bd446508172e37ed2d1c5a22e311d5d2510570d
",git fetch https://review.opendev.org/openstack/sahara refs/changes/26/44526/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/service/edp/job_origin.py', 'savanna/api/v11.py', 'savanna/exceptions.py', 'savanna/service/validations/edp/job_origin.py', 'savanna/service/edp/api.py']",5,a732441ff4463a3c4eb5778b4be42036a50c87ed,edp-job-origin,from savanna.service.edp import job_origin as j_odef get_job_origin_data(job_origin_id): return j_o.get_job_origin_data(job_origin_id) ,,94,1
openstack%2Ftrove~master~I1e051978b2363eaa9fd11abf1b107bd1e9c0edcb,openstack/trove,master,I1e051978b2363eaa9fd11abf1b107bd1e9c0edcb,Adds includedir back to templates,MERGED,2013-08-30 12:46:28.000000000,2013-09-05 15:34:24.000000000,2013-09-05 15:34:24.000000000,"[{'_account_id': 3}, {'_account_id': 739}, {'_account_id': 4954}, {'_account_id': 5293}, {'_account_id': 6268}, {'_account_id': 7092}, {'_account_id': 8259}, {'_account_id': 8491}]","[{'number': 1, 'created': '2013-08-30 12:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/226e47777930f107af31968d3988931f1cb893ef', 'message': 'Adds includedir to bottom of mysql my.cnf template\n\nChange-Id: I1e051978b2363eaa9fd11abf1b107bd1e9c0edcb\nFixes: bug #1218613\n'}, {'number': 2, 'created': '2013-08-30 17:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0c6e73886cfb7e29b96238fbe67bf9f2cf2823a2', 'message': 'Adds includedir back to templates\n\nChange-Id: I1e051978b2363eaa9fd11abf1b107bd1e9c0edcb\nFixes: bug #1218613\n'}, {'number': 3, 'created': '2013-09-03 12:53:12.000000000', 'files': ['trove/templates/mysql.config.template', 'trove/guestagent/manager/mysql_service.py', 'trove/templates/percona.config.template'], 'web_link': 'https://opendev.org/openstack/trove/commit/8ee9e9ce143377a82e13f45a02a2c8aa06225d57', 'message': ""Adds includedir back to templates\n\nThis adds includedir to the mysql templates, which allows overriding of\ndefault my.cnf settings. Additionally, /etc/mysql/conf.d is created if it\ndoesn't already exist to prevent mysql from failing.\n\nChange-Id: I1e051978b2363eaa9fd11abf1b107bd1e9c0edcb\nFixes: bug #1218613\n""}]",0,44451,8ee9e9ce143377a82e13f45a02a2c8aa06225d57,24,8,3,4954,,,0,"Adds includedir back to templates

This adds includedir to the mysql templates, which allows overriding of
default my.cnf settings. Additionally, /etc/mysql/conf.d is created if it
doesn't already exist to prevent mysql from failing.

Change-Id: I1e051978b2363eaa9fd11abf1b107bd1e9c0edcb
Fixes: bug #1218613
",git fetch https://review.opendev.org/openstack/trove refs/changes/51/44451/3 && git format-patch -1 --stdout FETCH_HEAD,['trove/templates/mysql.config.template'],1,226e47777930f107af31968d3988931f1cb893ef,bug/1218613,!includedir /etc/mysql/conf.d/,,1,0
openstack%2Fcinder~master~Ie27d004bad4053baa2ac8eb84bb8b7cdc05a954d,openstack/cinder,master,Ie27d004bad4053baa2ac8eb84bb8b7cdc05a954d,Fix tuple usage error,MERGED,2013-09-04 19:22:44.000000000,2013-09-05 15:32:02.000000000,2013-09-05 15:32:02.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-09-04 19:22:44.000000000', 'files': ['cinder/volume/flows/create_volume/__init__.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d9eb3535254ca2d198c84cde6b2ea02997ab8808', 'message': ""Fix tuple usage error\n\nThe exc_info is just a tuple (captured in taskflow)\nand isn't itself a callable object so we should not\nneed to use it like one to extract the exception type\nand value.\n\nFixes bug #1220867\n\nChange-Id: Ie27d004bad4053baa2ac8eb84bb8b7cdc05a954d\n""}]",0,45105,d9eb3535254ca2d198c84cde6b2ea02997ab8808,16,8,1,1297,,,0,"Fix tuple usage error

The exc_info is just a tuple (captured in taskflow)
and isn't itself a callable object so we should not
need to use it like one to extract the exception type
and value.

Fixes bug #1220867

Change-Id: Ie27d004bad4053baa2ac8eb84bb8b7cdc05a954d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/05/45105/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/flows/create_volume/__init__.py'],1,d9eb3535254ca2d198c84cde6b2ea02997ab8808,bug/1220867," # Figure out the type of the causes exception and compare it against # our black-list of exception types that will not cause rescheduling. exc_type, value = cause.exc_info[:2] # If we don't have a type from exc_info but we do have a exception in # the cause, try to get the type from that instead. if not value: value = cause.exc if not exc_type and value: exc_type = type(value) if exc_type and exc_type in self.no_reschedule_types: # Couldn't figure it out, by default assume whatever the cause was can # be fixed by rescheduling. # # NOTE(harlowja): Crosses fingers."," exc_type, value = cause.exc_info()[:2] if not exc_type and cause.exc: exc_type = type(cause.exc) if not exc_type: return True if exc_type in self.no_reschedule_types:",14,6
openstack%2Fnova~master~Ia5464948cc30b9b744450f9c301c4f3afaff717b,openstack/nova,master,Ia5464948cc30b9b744450f9c301c4f3afaff717b,VMware: Multiple cluster support using single compute service,MERGED,2013-05-23 15:00:12.000000000,2013-09-05 15:31:33.000000000,2013-09-05 15:31:31.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 447}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5638}, {'_account_id': 5652}, {'_account_id': 6498}, {'_account_id': 6499}, {'_account_id': 7239}, {'_account_id': 7400}, {'_account_id': 7575}, {'_account_id': 7586}, {'_account_id': 7629}, {'_account_id': 7631}, {'_account_id': 7693}, {'_account_id': 8163}]","[{'number': 1, 'created': '2013-05-23 15:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da841b54581ad5f889b75f638d8501acef0e2634', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 2, 'created': '2013-05-24 05:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7e100afabbdffe263f168b2ef39a9d34859d51d', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 3, 'created': '2013-05-31 15:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d265dc3f3f5c9e851ab419dd76bac2871442a15', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 4, 'created': '2013-05-31 16:12:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f61546e0fab31822a2919dd4fb8d44e2da40473', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 5, 'created': '2013-06-05 06:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6638d1b532eb6de7e3807aca59aa06120ac81619', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 6, 'created': '2013-06-11 10:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5ce5f8af63d51bb5d321b8315f91f0ae681bc077', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 7, 'created': '2013-06-11 12:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96d56596a0a03f2157102dee12a352f2832dd073', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 8, 'created': '2013-06-17 13:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32b43a1c1a07c409101733c7f3c7f7d1179e39a3', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 9, 'created': '2013-06-19 11:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a70843187e7f26ed98a53d19dced3c5b6ec39329', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 10, 'created': '2013-06-20 11:03:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/57a4358f78eb7a8e0ef0fda0c83583e784fd2865', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 11, 'created': '2013-06-25 12:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9fc2270ef5c6ed57abf58862b5539f1546d6c724', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 12, 'created': '2013-07-03 10:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ab914165a314d934dd21410f00ab822cef47103', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 13, 'created': '2013-07-19 05:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e9c936c8ef5b150ad4b96a15118edcddc91e3d4', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 14, 'created': '2013-07-19 06:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d54357d1ba8f622f8dd32e49e90dc9e660b1d6e', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 15, 'created': '2013-07-24 15:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9928b2cb4e7bc8ee5ea8e411b976652aaf899dc', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 16, 'created': '2013-07-24 16:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4ec5400098502964eeecc3bbee808c33857ea71', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 17, 'created': '2013-07-25 04:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53e28b85f60a92c7bb2886be9072c3d6172030e7', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 18, 'created': '2013-07-25 11:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/52c448e7af072c2a60b30ef5b8ef249ab2417ffb', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 19, 'created': '2013-07-25 14:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e93016b2a704a1429fcd973085c8ee91eb17384', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 20, 'created': '2013-08-12 04:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b5859eb36478a0e05c2bb48b67e7189c598123a', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 21, 'created': '2013-08-13 05:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd87bd84f0dbfcb0b3338c6866c8fe01b128fa21', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 22, 'created': '2013-08-14 05:38:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a810bfe64124969323338e4df77360b57ce76e54', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\n as multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes.\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 23, 'created': '2013-08-14 13:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc25458eef46ee26c46330ec9b5d132cd5092652', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 24, 'created': '2013-08-14 14:01:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d9ea6787cae77f5bea9fd6304ae3c66ebf1a9fd', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 25, 'created': '2013-08-16 06:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a412781c491898550d6c123cbf6c1c6d6e64b4f9', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 26, 'created': '2013-08-22 08:38:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86b65426db7ac89a19b15219d6388052bcb31c6a', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 27, 'created': '2013-08-23 06:41:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80af7664349427e96ecbca82de44bb078020390d', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 28, 'created': '2013-08-23 23:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7cba571fae7729e618a663ad309f58047578484b', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 29, 'created': '2013-08-24 00:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/54871cf667b8cb724b83af605e136d982f17204f', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 30, 'created': '2013-08-24 17:19:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a058669bc42bffa7c1ff683ba829867b6505d44', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 31, 'created': '2013-08-30 03:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f83f13fc848540eff8681c634636d276f6dbfeb7', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 32, 'created': '2013-08-30 22:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9710cbbc444b58d84a82db9fb1dae65aa22e60f6', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 33, 'created': '2013-08-30 23:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ca1581b3ffb91df517a26525f23410eb94b0f32', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 34, 'created': '2013-08-30 23:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ba7325f95fc598f24725d88af1e1616802a8416', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 35, 'created': '2013-08-30 23:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f028904a61f56842a4a896a203e93b46e2e8313d', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 36, 'created': '2013-08-31 00:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/82c3be748e7f95963882d4bcb34e39f017107d96', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 37, 'created': '2013-08-31 00:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63b8e98133c3e03f4e27bb7ca31fc277195b1eff', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 38, 'created': '2013-09-01 07:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7b9ae16f952a8043040ad174ad27a2060c6a42e', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 39, 'created': '2013-09-03 14:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4027800cb4491f33f3e96a3b2c13671c612f59d4', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 40, 'created': '2013-09-03 14:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0cacfa86782251ae2e34c786a0846b387fad15fa', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 41, 'created': '2013-09-03 19:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/661ea361c24284d66c5f92613d22aa5cefd4c319', 'message': 'Multiple Clusters using single compute service\n\nTo allow a single VC driver to model multiple Clusters in vCenter\nas multiple nova-compute nodes.\nTo allow the VC driver to be configured to represent a set of\nclusters as compute nodes. For example to specify two clusters\nnamed cluster-A and cluster-B, the nova.conf should have\ncluster_name=cluster-A\ncluster_name=cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 42, 'created': '2013-09-04 06:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b2677bc2995503406fcbda7eaf0f8f2c419d9f18', 'message': 'VMware: Multiple cluster support using single compute service\n\nTo allow a single VC driver to model multiple clusters in vCenter\nas multiple nova-compute nodes. The VC driver will be configured\nto represent a set of clusters as compute nodes.\nFor example to specify two clusters named cluster-A and cluster-B,\nthe nova.conf should have:\n    cluster_name = cluster-A\n    cluster_name = cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}, {'number': 43, 'created': '2013-09-04 16:20:48.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_configdrive.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'etc/nova/nova.conf.sample', 'nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/fake.py', 'nova/virt/vmwareapi/vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9408d79e7413aadcba52a61b7a33164090785e4f', 'message': 'VMware: Multiple cluster support using single compute service\n\nTo allow a single VC driver to model multiple clusters in vCenter\nas multiple nova-compute nodes. The VC driver will be configured\nto represent a set of clusters as compute nodes.\nFor example to specify two clusters named cluster-A and cluster-B,\nthe nova.conf should have:\n    cluster_name = cluster-A\n    cluster_name = cluster-B\n\nDocImpact\nChange-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b\nBlueprint: multiple-clusters-managed-by-one-service\n'}]",292,30282,9408d79e7413aadcba52a61b7a33164090785e4f,240,22,43,7239,,,0,"VMware: Multiple cluster support using single compute service

To allow a single VC driver to model multiple clusters in vCenter
as multiple nova-compute nodes. The VC driver will be configured
to represent a set of clusters as compute nodes.
For example to specify two clusters named cluster-A and cluster-B,
the nova.conf should have:
    cluster_name = cluster-A
    cluster_name = cluster-B

DocImpact
Change-Id: Ia5464948cc30b9b744450f9c301c4f3afaff717b
Blueprint: multiple-clusters-managed-by-one-service
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/30282/42 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/vmwareapi/db_fakes.py', 'nova/virt/vmwareapi/vmops.py', 'nova/virt/vmwareapi/__init__.py', 'nova/tests/test_vmwareapi.py', 'nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/fake.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/tests/test_vmwareapi_vm_util.py']",8,da841b54581ad5f889b75f638d8501acef0e2634,bp/multiple-clusters-managed-by-one-service,"# Copyright (c) 2013 Hewlett-Packard Development Company, L.P. self.assertEquals(result[2], 1024 * 1024 * 1024 * 1024) self.assertEquals(result[3], 1024 * 1024 * 1024 * 500)"," self.assertEquals(result[2], 1024 * 1024 * 1024) self.assertEquals(result[3], 1024 * 1024 * 500)",632,20
openstack%2Fneutron~master~Idd416fe0841f6aea80da3a3b66a80a451e0360fd,openstack/neutron,master,Idd416fe0841f6aea80da3a3b66a80a451e0360fd,Use admin context to retrieve metadata ports in NVP plugin,MERGED,2013-09-05 01:07:40.000000000,2013-09-05 15:31:21.000000000,2013-09-05 15:31:20.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2711}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-09-05 01:07:40.000000000', 'files': ['neutron/plugins/nicira/dhcp_meta/rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d834935648655f56a813dfa44a57bf5801fdba51', 'message': 'Use admin context to retrieve metadata ports in NVP plugin\n\nThe port that connects the router and the metadata\nnetwork is created with admin context, so use the\nelevated one.\n\nChange-Id: Idd416fe0841f6aea80da3a3b66a80a451e0360fd\nCloses-Bug: 1220877\n'}]",0,45152,d834935648655f56a813dfa44a57bf5801fdba51,12,7,1,748,,,0,"Use admin context to retrieve metadata ports in NVP plugin

The port that connects the router and the metadata
network is created with admin context, so use the
elevated one.

Change-Id: Idd416fe0841f6aea80da3a3b66a80a451e0360fd
Closes-Bug: 1220877
",git fetch https://review.opendev.org/openstack/neutron refs/changes/52/45152/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/nicira/dhcp_meta/rpc.py'],1,d834935648655f56a813dfa44a57bf5801fdba51,bug/1220877," plugin, ctx_elevated, filters=device_filter)"," # As we'll use a different device_owner for metadata interface # this query will return only 'real' router interfaces plugin, context, filters=device_filter)",1,3
openstack%2Ftrove~master~I64b524c589620fb81867bee1ea5dd69ea9017132,openstack/trove,master,I64b524c589620fb81867bee1ea5dd69ea9017132,Implementing heat as an optional provisioning system,MERGED,2013-08-30 19:18:17.000000000,2013-09-05 15:27:50.000000000,2013-09-05 15:27:50.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 739}, {'_account_id': 4257}, {'_account_id': 7092}, {'_account_id': 8188}, {'_account_id': 8415}]","[{'number': 1, 'created': '2013-08-30 19:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/70012c45e6f8ee1499dc9ab7696646fc5364022f', 'message': 'Implementing heat as an optional provisioning system\n\n* Adds a template\n* Adds create and delete functionality\n\nimplements blueprint heat-integration\n\nChange-Id: I64b524c589620fb81867bee1ea5dd69ea9017132\n'}, {'number': 2, 'created': '2013-09-02 16:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/dfe9c38d4609487233b22fd532f7b2b10655590e', 'message': 'Implementing heat as an optional provisioning system\n\n* Adds a template\n* Adds create and delete functionality\n\nimplements blueprint heat-integration\n\nChange-Id: I64b524c589620fb81867bee1ea5dd69ea9017132\n'}, {'number': 3, 'created': '2013-09-03 08:53:12.000000000', 'files': ['requirements.txt', 'trove/common/cfg.py', 'trove/taskmanager/models.py', 'trove/common/template.py', 'trove/common/remote.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/98d3de26722c195b33f91168cf67ec35673069a4', 'message': 'Implementing heat as an optional provisioning system\n\n* Adds a template\n* Adds create and delete functionality\n\nimplements blueprint heat-integration\n\nChange-Id: I64b524c589620fb81867bee1ea5dd69ea9017132\n'}]",3,44530,98d3de26722c195b33f91168cf67ec35673069a4,28,7,3,739,,,0,"Implementing heat as an optional provisioning system

* Adds a template
* Adds create and delete functionality

implements blueprint heat-integration

Change-Id: I64b524c589620fb81867bee1ea5dd69ea9017132
",git fetch https://review.opendev.org/openstack/trove refs/changes/30/44530/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'trove/common/cfg.py', 'trove/taskmanager/models.py', 'trove/common/template.py', 'trove/common/remote.py']",5,70012c45e6f8ee1499dc9ab7696646fc5364022f,bp/heat-integration,"from heatclient.v1 import client as HeatClientHEAT_URL = CONF.heat_urldef heat_client(context): endpoint = ""%s/%s/"" % (HEAT_URL, context.tenant) client = HeatClient.Client(username=context.user, password=""radmin"", token=context.auth_token, os_no_client_auth=True, endpoint=endpoint) return client create_heat_client = import_class(CONF.remote_heat_client)",,140,2
openstack%2Fdevstack~master~I911e0644dc062ac1ffb6afba294eacb8f54bf580,openstack/devstack,master,I911e0644dc062ac1ffb6afba294eacb8f54bf580,vmware - vsphere v5.0 - WSDL cleanup script.,ABANDONED,2013-08-14 01:46:10.000000000,2013-09-05 15:20:15.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 7629}, {'_account_id': 8027}]","[{'number': 1, 'created': '2013-08-14 01:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9beedfd2e7547071fbe11d1a5d59a4c887935f67', 'message': 'vmware - vsphere v5.0 - WSDL cleanup script.\n\nfixes bug 1211853\n\nWhen using DevStack with vSphere 5.0, it may be desirable to locally cache the WSDL on the server where the nova-compute driver for vCenter or ESXi are running.\n\nChange-Id: I911e0644dc062ac1ffb6afba294eacb8f54bf580\n'}, {'number': 2, 'created': '2013-08-14 01:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/05b4a80d0ef6e0229ae93ae9604ebfc5fac6ff1d', 'message': 'vmware - vsphere v5.0 - WSDL cleanup script.\n\nfixes bug 1211853\n\nWhen using DevStack with vSphere 5.0, it may be\nnecessary to locally cache the WSDL locally to\nthe nova-compute driver for vCenter or ESXi.\nThis will allow an administrator to modify their\nlocal copy of the WSDL to be more easily parsed\nby the driver.\n\nChange-Id: I911e0644dc062ac1ffb6afba294eacb8f54bf580\n'}, {'number': 3, 'created': '2013-08-14 01:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/786263374a7f79ef40c9e36df8e079901d64284d', 'message': 'vmware - vsphere v5.0 - WSDL cleanup script.\n\nfixes bug 1211853\n\nWhen using DevStack with vSphere 5.0, it may be\nnecessary to locally cache the WSDL locally to\nthe nova-compute driver for vCenter or ESXi.\nThis will allow an administrator to modify their\nlocal copy of the WSDL to be more easily parsed\nby the driver.\n\nChange-Id: I911e0644dc062ac1ffb6afba294eacb8f54bf580\n'}, {'number': 4, 'created': '2013-08-14 02:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/dccd405d2c70ebcd5a4fc2d71ce8a9b76414384d', 'message': 'vmware - vsphere v5.0 - WSDL cleanup script.\n\nfixes bug 1211853\n\nWhen using DevStack with vSphere 5.0, it may be\nnecessary to locally cache the WSDL locally to\nthe nova-compute driver for vCenter or ESXi.\nThis will allow an administrator to modify their\nlocal copy of the WSDL to be more easily parsed\nby the driver.\n\nChange-Id: I911e0644dc062ac1ffb6afba294eacb8f54bf580\n'}, {'number': 5, 'created': '2013-08-15 19:58:24.000000000', 'files': ['tools/wsdl/vmware_cache_wsdl.py'], 'web_link': 'https://opendev.org/openstack/devstack/commit/adf534d464b6a8e1b9d1ece7f7a5da034b1b9f9b', 'message': 'vmware - vsphere v5.0 - WSDL cleanup script.\n\nfixes bug 1211853\n\nWhen using DevStack with vSphere 5.0, it may be\nnecessary to locally cache the WSDL locally to\nthe nova-compute driver for vCenter or ESXi.\nThis will allow an administrator to modify their\nlocal copy of the WSDL to be more easily parsed\nby the driver.\n\nChange-Id: I911e0644dc062ac1ffb6afba294eacb8f54bf580\n'}]",13,41824,adf534d464b6a8e1b9d1ece7f7a5da034b1b9f9b,17,6,5,7629,,,0,"vmware - vsphere v5.0 - WSDL cleanup script.

fixes bug 1211853

When using DevStack with vSphere 5.0, it may be
necessary to locally cache the WSDL locally to
the nova-compute driver for vCenter or ESXi.
This will allow an administrator to modify their
local copy of the WSDL to be more easily parsed
by the driver.

Change-Id: I911e0644dc062ac1ffb6afba294eacb8f54bf580
",git fetch https://review.opendev.org/openstack/devstack refs/changes/24/41824/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/wsdl/vmware_cache_wsdl.py'],1,9beedfd2e7547071fbe11d1a5d59a4c887935f67,bug/1211853,"#!/usr/bin/python import collections import optparse import os import sys import urllib ROOT_WSDL_FILE = 'vimService.wsdl' WSDL_FILES = frozenset([ 'vimService.wsdl', 'vim.wsdl', 'core-types.xsd', 'query-messagetypes.xsd', 'query-types.xsd', 'reflect-messagetypes.xsd', 'reflect-types.xsd', 'vim-messagetypes.xsd']) XSD_WITH_404 = """"""<?xml version=""1.0"" encoding=""UTF-8""?> <schema targetNamespace=""urn:reflect"" xmlns=""http://www.w3.org/2001/XMLSchema"" xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" elementFormDefault=""qualified""> </schema> """""" parser = optparse.OptionParser(""usage: %prog [options]"") parser.add_option(""-H"", ""--host"", dest=""hostname"", default=None, type=""string"", help=""specify hostname extract WSDL from"") parser.add_option(""-D"", ""--dest"", dest=""dest_directory"", default=""/opt/stack/wsdl"", type=""string"", help=""specify destination directory for WSDL files"") (options, args) = parser.parse_args() if not( options.hostname and options.dest_directory ): parser.print_help() sys.exit() for wsdl_file in WSDL_FILES: remote_file_path = ""https://%s/sdk/%s"" % (options.hostname, wsdl_file) local_file_path = os.path.join(options.dest_directory, wsdl_file) local_file = open(local_file_path, 'w') remote_file = None try: remote_file = urllib.urlopen(remote_file_path) except IOError as e: print e.message print ""Could not open %s"" % remote_file_path os.sys.exit(1) code = remote_file.getcode() if code == 200: print ""%d: downloading %s"" % (code, wsdl_file) local_file.write(remote_file.read()) elif code == 404: print ""404: fixing missing %s"" % wsdl_file local_file.write(XSD_WITH_404) else: print ""%s returned code %d"" % (remote_file_path, code) remote_file.close() local_file.close() local_file = open(os.path.join( options.dest_directory, ROOT_WSDL_FILE ), 'r') local_file_name = os.path.dirname(local_file.name) local_file.close() print ""# use the following location for your driver"" print ""VMWAREAPI_WSDL_LOC=file://%s"" % local_file_path ",,79,0
openstack%2Fnova~master~Ibb7a54261b50f73100f4ab4acd59d8e7cd2901a0,openstack/nova,master,Ibb7a54261b50f73100f4ab4acd59d8e7cd2901a0,xenapi: support raw tgz image download,MERGED,2013-08-08 16:25:22.000000000,2013-09-05 15:19:06.000000000,2013-09-05 15:19:03.000000000,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 5044}, {'_account_id': 6735}, {'_account_id': 7369}, {'_account_id': 7952}]","[{'number': 1, 'created': '2013-08-08 16:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2427e5ce29d2b465adfc604024965591bc88bf95', 'message': 'xenapi: ovf - decompress image stream\n\nThis change implements the last bit of the image download.\nget_stream_funct_for will return a different streaming function if it is\nused on images with ovf container format.\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: Ibb7a54261b50f73100f4ab4acd59d8e7cd2901a0\n'}, {'number': 2, 'created': '2013-08-08 22:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e9d4cdc960ebd67ecb38549047e7388fbbe3dc5', 'message': 'xenapi: ovf - decompress image stream\n\nThis change implements the last bit of the image download.\nget_stream_funct_for will return a different streaming function if it is\nused on images with ovf container format.\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: Ibb7a54261b50f73100f4ab4acd59d8e7cd2901a0\n'}, {'number': 3, 'created': '2013-08-22 18:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ff8715b59b1a8b8ed5a59b931f518ba9f37307f', 'message': 'xenapi: ovf - decompress image stream\n\nThis change implements the last bit of the image download.\nA class, GlanceImage was created to support caching of glance\noperations. This object is used by higher-level objects, RawTGZImage and\nRawImage, which provide the get_virtual_size and get_stream_func\noperations for download.\n\nRawTGZImage uses the underlying glance image stream as a tar file. As\nthe client asks for the image size, the first tar info is read, and\ncached (_RawTGZInfoReadState).  Subsequent calls for size are safe, and\nwill not read the stream. The client can ask the image to write its\ncontents to a file (stream_to).  This will result in writing the targz\nfile entry to the specified file.  The RawTGZImage considered to be\nclosed after its read, and will raise exceptions (_RawTGZFinishedState).\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: Ibb7a54261b50f73100f4ab4acd59d8e7cd2901a0\n'}, {'number': 4, 'created': '2013-08-28 14:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70d3d9afd75dfd4a33d004f5f6ac27aec51c1c93', 'message': ""xenapi: support raw tgz image download\n\nSupport the download of raw tgz images. The image's size is retrieved\nby reading the first tarinfo from the stream.\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: Ibb7a54261b50f73100f4ab4acd59d8e7cd2901a0\n""}, {'number': 5, 'created': '2013-08-31 12:15:12.000000000', 'files': ['nova/tests/virt/xenapi/image/test_utils.py', 'nova/virt/xenapi/image/utils.py', 'nova/virt/xenapi/vm_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bf3c74563bdb6e0019db2af14c3df629d429f56b', 'message': ""xenapi: support raw tgz image download\n\nSupport the download of raw tgz images. The image's size is retrieved\nby reading the first tarinfo from the stream.\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: Ibb7a54261b50f73100f4ab4acd59d8e7cd2901a0\n""}]",40,40909,bf3c74563bdb6e0019db2af14c3df629d429f56b,34,9,5,5044,,,0,"xenapi: support raw tgz image download

Support the download of raw tgz images. The image's size is retrieved
by reading the first tarinfo from the stream.

related to blueprint xenapi-supported-image-import-export

Change-Id: Ibb7a54261b50f73100f4ab4acd59d8e7cd2901a0
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/40909/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py']",2,2427e5ce29d2b465adfc604024965591bc88bf95,bp/xenapi-supported-image-import-export," def test_stream_to(self): source_tar = self.mox.CreateMock(tarfile.TarFile) first_tarinfo = self.mox.CreateMock(tarfile.TarInfo) target_file = self.mox.CreateMock(file) source_file = self.mox.CreateMock(file) image = vm_utils.RawTGZImage('ctx', 'service', 'id') self.mox.StubOutWithMock(image, 'as_tarfile', source_tar) self.mox.StubOutWithMock(vm_utils.shutil, 'copyfileobj') image.as_tarfile().AndReturn(source_tar) source_tar.next().AndReturn(first_tarinfo) source_tar.extractfile(first_tarinfo).AndReturn(source_file) vm_utils.shutil.copyfileobj(source_file, target_file) self.mox.ReplayAll() image.stream_to(target_file) class TestGetStreamFunctFor(test.TestCase): def test_non_ovf_image(self): image_service = FakeImageService() self.mox.StubOutWithMock(vm_utils, 'create_raw_image_streamer') vm_utils.create_raw_image_streamer('ctx', image_service, 'id') self.mox.ReplayAll() result = vm_utils.get_stream_funct_for( 'ctx', image_service, 'id') def test_ovf_image(self): image_service = FakeImageService({'container_format': 'ovf'}) self.mox.StubOutWithMock(vm_utils, 'raw_tgz_create_streamer') vm_utils.raw_tgz_create_streamer('ctx', image_service, 'id') self.mox.ReplayAll() result = vm_utils.get_stream_funct_for( 'ctx', image_service, 'id') class TestRawTGZCreateStreamer(test.TestCase): def test_call_delegated(self): image = self.mox.CreateMock(vm_utils.RawTGZImage) self.mox.StubOutWithMock(vm_utils, 'RawTGZImage') vm_utils.RawTGZImage('ctx', 'service', 'id').AndReturn(image) self.mox.ReplayAll() result = vm_utils.raw_tgz_create_streamer('ctx', 'service', 'id') self.assertEquals(image.stream_to, result)",,74,3
openstack%2Fnova~master~Iffe363a40af046c5c2841ecd1a981c5672eca584,openstack/nova,master,Iffe363a40af046c5c2841ecd1a981c5672eca584,xenapi: refactor - extract image_utils,MERGED,2013-08-08 16:25:21.000000000,2013-09-05 15:18:33.000000000,2013-09-05 15:18:31.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 5044}, {'_account_id': 6735}, {'_account_id': 7952}]","[{'number': 1, 'created': '2013-08-08 16:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70f62813e01f69e6d671b272b325f9079f522353', 'message': ""xenapi: ovf - virtual size retrieved from stream\n\nIf the image's container format is ovf, we look at the first tar info of\nthe image to come up with a virtual size.\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: Iffe363a40af046c5c2841ecd1a981c5672eca584\n""}, {'number': 2, 'created': '2013-08-08 22:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5075bff47ac68ec44c6bbac34bc0b9537f47d9cc', 'message': ""xenapi: ovf - virtual size retrieved from stream\n\nIf the image's container format is ovf, we look at the first tar info of\nthe image to come up with a virtual size.\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: Iffe363a40af046c5c2841ecd1a981c5672eca584\n""}, {'number': 3, 'created': '2013-08-22 18:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/692f5c6fbccfc0cb44316f1f5de6e17567df0f77', 'message': ""xenapi: ovf - virtual size retrieved from stream\n\nIf the image's container format is ovf, we look at the first tar info of\nthe image to come up with a virtual size.\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: Iffe363a40af046c5c2841ecd1a981c5672eca584\n""}, {'number': 4, 'created': '2013-08-28 12:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/44f24fca248696a982643568483722860c790730', 'message': ""xenapi: refactor - extract image_utils\n\nExtract GlanceImage and RawImage. With these abstractions in place, it's\nmuch more easier to implement support for new container and image\nformats.\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: Iffe363a40af046c5c2841ecd1a981c5672eca584\n""}, {'number': 5, 'created': '2013-08-31 12:15:11.000000000', 'files': ['nova/tests/virt/xenapi/image/test_utils.py', 'nova/virt/xenapi/image/utils.py', 'nova/virt/xenapi/vm_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/928a119ac0f8d750f616f3eff4fadc82b23fc7c6', 'message': ""xenapi: refactor - extract image_utils\n\nExtract GlanceImage and RawImage. With these abstractions in place, it's\nmuch more easier to implement support for new container and image\nformats.\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: Iffe363a40af046c5c2841ecd1a981c5672eca584\n""}]",10,40908,928a119ac0f8d750f616f3eff4fadc82b23fc7c6,32,7,5,5044,,,0,"xenapi: refactor - extract image_utils

Extract GlanceImage and RawImage. With these abstractions in place, it's
much more easier to implement support for new container and image
formats.

related to blueprint xenapi-supported-image-import-export

Change-Id: Iffe363a40af046c5c2841ecd1a981c5672eca584
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/40908/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py']",2,70f62813e01f69e6d671b272b325f9079f522353,bp/xenapi-supported-image-import-export,"import pkg_resources import tarfile import urlparsefrom nova.image import glance class FakeImageService(object): def __init__(self, metadata=None): self.metadata = metadata or {} def show(self, context, image_id): return self.metadata class TestGetVirtualSize(test.TestCase): def test_non_ovf_returns_size_from_meta(self): image_service = FakeImageService({'size': '123'}) result = vm_utils.get_virtual_size('context', image_service, 'id') self.assertEquals(123, result) def test_ovf_image_returns_with_raw_tgz_get_size(self): self.mox.StubOutWithMock(vm_utils, 'raw_tgz_get_size') image_service = FakeImageService( {'size': '123', 'container_format': 'ovf'}) vm_utils.raw_tgz_get_size( 'context', image_service, 'id').AndReturn(1024) self.mox.ReplayAll() result = vm_utils.get_virtual_size('context', image_service, 'id') self.assertEquals(1024, result) class TestRawTGZ(test.TestCase): def test_raw_tgz_get_size_delegates(self): image = self.mox.CreateMock(vm_utils.RawTGZImage) self.mox.StubOutWithMock(vm_utils, 'RawTGZImage') image_service = FakeImageService() vm_utils.RawTGZImage('ctx', image_service, 'id').AndReturn(image) image.get_size().AndReturn(123) self.mox.ReplayAll() result = vm_utils.raw_tgz_get_size('ctx', image_service, 'id') self.assertEquals(123, result) def test_constructor(self): image = vm_utils.RawTGZImage('ctx', 'service', 'id') self.assertEquals('ctx', image.context) self.assertEquals('service', image.image_service) self.assertEquals('id', image.image_id) def test_get_size(self): tar_file = self.mox.CreateMock(tarfile.TarFile) tar_info = self.mox.CreateMock(tarfile.TarInfo) image = vm_utils.RawTGZImage(None, None, None) self.mox.StubOutWithMock(image, 'as_tarfile') image.as_tarfile().AndReturn(tar_file) tar_file.next().AndReturn(tar_info) tar_info.size = 124 self.mox.ReplayAll() result = image.get_size() self.assertEquals(124, result) def test_as_tarfile(self): image = vm_utils.RawTGZImage(None, None, None) self.mox.StubOutWithMock(image, 'as_file') self.mox.StubOutWithMock(vm_utils.tarfile, 'open') image.as_file().AndReturn('the_file') vm_utils.tarfile.open(mode='r|gz', fileobj='the_file').AndReturn('tf') self.mox.ReplayAll() result = image.as_tarfile() self.assertEquals('tf', result) def test_as_file(self): self.mox.StubOutWithMock(vm_utils, 'IterableBasedFile') image_service = self.mox.CreateMock(glance.GlanceImageService) image = vm_utils.RawTGZImage('ctx', image_service, 'id') image_service.download('ctx', 'id').AndReturn('iterable') vm_utils.IterableBasedFile('iterable').AndReturn('file') self.mox.ReplayAll() result = image.as_file() self.assertEquals('file', result) class TestIterableBasedFile(test.TestCase): def test_constructor(self): class FakeIterable(object): def __iter__(_self): return 'iterator' the_file = vm_utils.IterableBasedFile(FakeIterable()) self.assertEquals('iterator', the_file.iterator) def test_read_one_character(self): the_file = vm_utils.IterableBasedFile([ 'chunk1', 'chunk2' ]) self.assertEquals('c', the_file.read(1)) def test_read_stores_remaining_characters(self): the_file = vm_utils.IterableBasedFile([ 'chunk1', 'chunk2' ]) the_file.read(1) self.assertEquals('hunk1', the_file.remaining_data) def test_read_remaining_characters(self): the_file = vm_utils.IterableBasedFile([ 'chunk1', 'chunk2' ]) self.assertEquals('c', the_file.read(1)) self.assertEquals('h', the_file.read(1)) def test_read_reached_end_of_file(self): the_file = vm_utils.IterableBasedFile([ 'chunk1', 'chunk2' ]) self.assertEquals('chunk1', the_file.read(100)) self.assertEquals('chunk2', the_file.read(100)) self.assertEquals('', the_file.read(100)) def test_empty_chunks(self): the_file = vm_utils.IterableBasedFile([ '', '', 'chunk2' ]) self.assertEquals('chunk2', the_file.read(100))",,192,0
openstack%2Fnova~master~I7541b8fef3a55939179b6355ed178146c1f8f9d6,openstack/nova,master,I7541b8fef3a55939179b6355ed178146c1f8f9d6,xenapi: through-dev raw-tgz image upload to glance,MERGED,2013-08-13 11:22:16.000000000,2013-09-05 15:18:01.000000000,2013-09-05 15:17:58.000000000,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5044}, {'_account_id': 6735}, {'_account_id': 7802}, {'_account_id': 7952}, {'_account_id': 8430}]","[{'number': 1, 'created': '2013-08-13 11:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ae11e354f07666efaa2ab56215d5b94585ac135', 'message': 'xenapi: prototype implementation of image upload\n\nThis is a prototype implementation of the image upload process using\nsupported xenapi calls.\n\nChange-Id: I7541b8fef3a55939179b6355ed178146c1f8f9d6\n'}, {'number': 2, 'created': '2013-08-14 08:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1969b5ed4da96c38ed3cbe4114a7c3859a2764e3', 'message': 'xenapi: through-dev raw-tgz image upload to glance\n\nUpload tgz compressed raw disk images to glance using supported xapi\ninterfaces. The supported interface at the moment is to attach the disk\nto the compute domU as a block device. As we want sparse format, the\ndisk\'s content is read by a separate process ""create-targz"", which is\nproducing the tar.gz stream on its standard output. This separate\nutility is a new console script, implemented in python. This stream is\npassed to glance to update the image\'s contents.\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: I7541b8fef3a55939179b6355ed178146c1f8f9d6\n'}, {'number': 3, 'created': '2013-08-14 08:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e08cf03c656c527bd58401cc18352a53b248bfb8', 'message': 'xenapi: through-dev raw-tgz image upload to glance\n\nUpload tgz compressed raw disk images to glance using supported xapi\ninterfaces. The supported interface at the moment is to attach the disk\nto the compute domU as a block device. As we want sparse format, the\ndisk\'s content is read by a separate process ""create-targz"", which is\nproducing the tar.gz stream on its standard output. This separate\nutility is a new console script, implemented in python. This stream is\npassed to glance to update the image\'s contents.\n\nrelated to blueprint xenapi-supported-image-import-export\n\nChange-Id: I7541b8fef3a55939179b6355ed178146c1f8f9d6\n'}, {'number': 4, 'created': '2013-08-15 13:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/238fa26f63623848a527cb8171e552245148bc5e', 'message': ""xenapi: through-dev raw-tgz image upload to glance\n\nUpload tgz compressed raw disk images to glance using supported xapi\ninterfaces. The supported interface at the moment is to attach the disk\nto the compute domU as a block device. As we want sparse format, the\ndisk's content is put to a tar.gz file.\n\nin nova.conf, you need to specify:\n\n    xenapi_image_upload_handler =\n    nova.virt.xenapi.image.vdi_through_dev.VdiThroughDev\n\nDocImpact\n\nimplements blueprint xenapi-supported-image-import-export\n\nChange-Id: I7541b8fef3a55939179b6355ed178146c1f8f9d6\n""}, {'number': 5, 'created': '2013-08-15 13:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28a025524d5e50275a514a83eee6c4a29ef9d58c', 'message': ""xenapi: through-dev raw-tgz image upload to glance\n\nUpload tgz compressed raw disk images to glance using supported xapi\ninterfaces. The supported interface at the moment is to attach the disk\nto the compute domU as a block device. As we want sparse format, the\ndisk's content is put to a tar.gz file.\n\nin nova.conf, you need to specify:\n\n    xenapi_image_upload_handler =\n    nova.virt.xenapi.image.vdi_through_dev.VdiThroughDev\n\nDocImpact\n\nimplements blueprint xenapi-supported-image-import-export\n\nChange-Id: I7541b8fef3a55939179b6355ed178146c1f8f9d6\n""}, {'number': 6, 'created': '2013-08-22 10:17:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/397789faf6ce7b5effe4f0cf3feb7708d16aa675', 'message': 'xenapi: through-dev raw-tgz image upload to glance\n\nUpload tgz compressed raw disk images to glance using supported xapi\ninterfaces.\n\nAt the moment, image upload could only be done with dom0 plugins.\nThese plugins are not supported by Citrix. This change adds an alternate\nmethod, which only uses supported interfaces:\n\n - Attach the virtual disk to be uploaded to the nova domU as a block\n   device.\n - nova reads the block device, and creates a tar.gz stream.\n - glance client reads the stream, and updates the image.\n\nIn order to use this functionality, in nova.conf, you need to specify:\n\n    xenapi_image_upload_handler =\n    nova.virt.xenapi.image.vdi_through_dev.VdiThroughDevStore\n\nDocImpact\n\nimplements blueprint xenapi-supported-image-import-export\n\nChange-Id: I7541b8fef3a55939179b6355ed178146c1f8f9d6\n'}, {'number': 7, 'created': '2013-08-27 16:33:00.000000000', 'files': ['nova/virt/xenapi/vmops.py', 'nova/tests/virt/xenapi/image/test_vdi_through_dev.py', 'nova/virt/xenapi/image/vdi_through_dev.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ef8017ff798c2a1bc548af6f0356b1aab3cfb0e2', 'message': ""xenapi: through-dev raw-tgz image upload to glance\n\nUpload tgz compressed raw disk images to glance using supported xapi\ninterfaces.\n\nAt the moment, image upload could only be done with dom0 plugins.\nThese plugins are not supported by Citrix. This change adds an alternate\nmethod, which only uses supported interfaces:\n\n - Attach the virtual disk to be uploaded to the nova domU as a block\n   device.\n - nova reads the block device, and creates a tar.gz stream. The tar.gz\n   stream contains only one file, disk.raw, with the block device's\n   contents.\n - glance client reads the stream, and updates the image.\n\nIn order to use this functionality, in nova.conf, you need to specify:\n\n    xenapi_image_upload_handler =\n    nova.virt.xenapi.image.vdi_through_dev.VdiThroughDevStore\n\nDocImpact\n\nimplements blueprint xenapi-supported-image-import-export\n\nChange-Id: I7541b8fef3a55939179b6355ed178146c1f8f9d6\n""}]",8,41651,ef8017ff798c2a1bc548af6f0356b1aab3cfb0e2,49,11,7,5044,,,0,"xenapi: through-dev raw-tgz image upload to glance

Upload tgz compressed raw disk images to glance using supported xapi
interfaces.

At the moment, image upload could only be done with dom0 plugins.
These plugins are not supported by Citrix. This change adds an alternate
method, which only uses supported interfaces:

 - Attach the virtual disk to be uploaded to the nova domU as a block
   device.
 - nova reads the block device, and creates a tar.gz stream. The tar.gz
   stream contains only one file, disk.raw, with the block device's
   contents.
 - glance client reads the stream, and updates the image.

In order to use this functionality, in nova.conf, you need to specify:

    xenapi_image_upload_handler =
    nova.virt.xenapi.image.vdi_through_dev.VdiThroughDevStore

DocImpact

implements blueprint xenapi-supported-image-import-export

Change-Id: I7541b8fef3a55939179b6355ed178146c1f8f9d6
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/41651/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/cmd/create_targz.py', 'nova/virt/xenapi/image/blockthrough.py', 'setup.cfg']",3,6ae11e354f07666efaa2ab56215d5b94585ac135,bp/xenapi-supported-image-import-export, create-targz = nova.cmd.create_targz:main,,97,0
openstack%2Fsahara-image-elements~master~I3af9462de5f11ed7d8b16a0cd6fc8a535555df26,openstack/sahara-image-elements,master,I3af9462de5f11ed7d8b16a0cd6fc8a535555df26,Correct .gitreview file,ABANDONED,2013-09-04 14:26:44.000000000,2013-09-05 15:17:35.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-09-04 14:26:44.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/4c63a9be3925a057d765e84fe16589d92a40a852', 'message': 'Correct .gitreview file\n\nChange-Id: I3af9462de5f11ed7d8b16a0cd6fc8a535555df26\n'}]",0,45068,4c63a9be3925a057d765e84fe16589d92a40a852,2,1,1,2,,,0,"Correct .gitreview file

Change-Id: I3af9462de5f11ed7d8b16a0cd6fc8a535555df26
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/68/45068/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,4c63a9be3925a057d765e84fe16589d92a40a852,,project=stackforge/savanna-image-elements.git,project=stackforge/savanna-extra.git,1,1
openstack%2Fnova~master~I6b5115df53f2e159ea506ef966cd49cedd35f83d,openstack/nova,master,I6b5115df53f2e159ea506ef966cd49cedd35f83d,Refresh network info cache for secgroups,MERGED,2013-09-04 19:45:11.000000000,2013-09-05 15:17:29.000000000,2013-09-05 15:17:26.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4395}]","[{'number': 1, 'created': '2013-09-04 19:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/129b36e967b5c437ada045da57d6dd608f43a5e5', 'message': 'Refresh network info cache for secgroups\n\nBefore updating security group rules, we need to make sure that\nthe info cache is up-to-date. Without this source groups are not\nupdated properly. This was a regression introduced in commit\n85aac04704350566d6b06aa7a3b99649946c672c which fixed a potential\nDOS using source groups.\n\nFixes bug 1216720\n\nChange-Id: I6b5115df53f2e159ea506ef966cd49cedd35f83d\n'}, {'number': 2, 'created': '2013-09-04 22:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7cb038da090550af2f600d10c671cefa67685cc', 'message': 'Refresh network info cache for secgroups\n\nBefore updating security group rules, we need to make sure that\nthe info cache is up-to-date. Without this source groups are not\nupdated properly. This was a regression introduced in commit\n85aac04704350566d6b06aa7a3b99649946c672c which fixed a potential\nDOS using source groups.\n\nFixes bug 1216720\n\nChange-Id: I6b5115df53f2e159ea506ef966cd49cedd35f83d\n'}, {'number': 3, 'created': '2013-09-05 00:58:53.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py', 'nova/virt/firewall.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8679b2c8e7f9fddc31a74ad00f6705bca00a762b', 'message': 'Refresh network info cache for secgroups\n\nBefore updating security group rules, we need to make sure that\nthe info cache is up-to-date. Without this source groups are not\nupdated properly. This was a regression introduced in commit\n85aac04704350566d6b06aa7a3b99649946c672c which fixed a potential\nDOS using source groups.\n\nFixes bug 1216720\n\nChange-Id: I6b5115df53f2e159ea506ef966cd49cedd35f83d\n'}]",0,45107,8679b2c8e7f9fddc31a74ad00f6705bca00a762b,15,6,3,67,,,0,"Refresh network info cache for secgroups

Before updating security group rules, we need to make sure that
the info cache is up-to-date. Without this source groups are not
updated properly. This was a regression introduced in commit
85aac04704350566d6b06aa7a3b99649946c672c which fixed a potential
DOS using source groups.

Fixes bug 1216720

Change-Id: I6b5115df53f2e159ea506ef966cd49cedd35f83d
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/45107/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/virt/firewall.py']",2,129b36e967b5c437ada045da57d6dd608f43a5e5,bug/1216720, if instance['info_cache']['deleted']: LOG.debug('ignoring deleted cache') continue,,32,14
openstack%2Fglance~master~I592424b464b91c2be9e253402986e673ce33c8d0,openstack/glance,master,I592424b464b91c2be9e253402986e673ce33c8d0,Call _post_downgrade_### after downgrade migration is run,MERGED,2013-08-19 20:48:06.000000000,2013-09-05 15:12:56.000000000,2013-09-05 06:11:20.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 177}, {'_account_id': 475}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-08-19 20:48:06.000000000', 'files': ['glance/tests/unit/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/18374238c5265968c68f17431dab52584b5f268a', 'message': 'Call _post_downgrade_### after downgrade migration is run\n\nFixes bug 1195470\n\nTests are currently only run after a upgrade during the database migration\nunit tests and never during a downgrade. This change calls an optional\n_post_downgrade_### method after running the downgrade migration to allow\nit to be tested as well.\n\nChange-Id: I592424b464b91c2be9e253402986e673ce33c8d0\n'}]",4,42734,18374238c5265968c68f17431dab52584b5f268a,15,8,1,100,,,0,"Call _post_downgrade_### after downgrade migration is run

Fixes bug 1195470

Tests are currently only run after a upgrade during the database migration
unit tests and never during a downgrade. This change calls an optional
_post_downgrade_### method after running the downgrade migration to allow
it to be tested as well.

Change-Id: I592424b464b91c2be9e253402986e673ce33c8d0
",git fetch https://review.opendev.org/openstack/glance refs/changes/34/42734/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/test_migrations.py'],1,18374238c5265968c68f17431dab52584b5f268a,migration-012-unit-test," self._migrate_down(engine, version - 1, with_data=True) def _migrate_down(self, engine, version, with_data=False): # NOTE(sirp): `version` is what we're downgrading to (i.e. the 'target' # version). So if we have any downgrade checks, they need to be run for # the previous (higher numbered) migration. if with_data: post_downgrade = getattr(self, ""_post_downgrade_%03d"" % (version + 1), None) if post_downgrade: post_downgrade(engine) "," self._migrate_down(engine, version - 1) def _migrate_down(self, engine, version):",11,2
openstack%2Fnova~master~I4ea99141027274a9173d7f40ba5fb88bd5aa8fe9,openstack/nova,master,I4ea99141027274a9173d7f40ba5fb88bd5aa8fe9,VMware: validate summary fields exist prior to accessing,ABANDONED,2013-08-28 08:44:35.000000000,2013-09-05 15:05:52.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 8151}]","[{'number': 1, 'created': '2013-08-28 08:44:35.000000000', 'files': ['nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/virt/vmwareapi/fake.py', 'nova/virt/vmwareapi/host.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c63500ef19eb0f26fece38058ec0848f26aa1141', 'message': 'VMware: validate summary fields exist prior to accessing\n\nThe data returned by HostConfigSummary may have some fields\nthat are not set by the backend. The patch validates that the\nfields are set. If they are not set then a default value is\nreturned instead.\n\nFixes bug: 1217541\n\nChange-Id: I4ea99141027274a9173d7f40ba5fb88bd5aa8fe9\n'}]",0,44006,c63500ef19eb0f26fece38058ec0848f26aa1141,8,5,1,1653,,,0,"VMware: validate summary fields exist prior to accessing

The data returned by HostConfigSummary may have some fields
that are not set by the backend. The patch validates that the
fields are set. If they are not set then a default value is
returned instead.

Fixes bug: 1217541

Change-Id: I4ea99141027274a9173d7f40ba5fb88bd5aa8fe9
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/44006/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/virt/vmwareapi/fake.py', 'nova/virt/vmwareapi/host.py']",3,c63500ef19eb0f26fece38058ec0848f26aa1141,bug/1217541,"def update_host_hardware_values(data, hardware): data['vcpus'] = hardware.numCpuThreads data['cpu_info'] = {'vendor': hardware.vendor, 'model': hardware.cpuModel, 'topology': {'cores': hardware.numCpuCores, 'sockets': hardware.numCpuPkgs, 'threads': hardware.numCpuThreads} } data['host_memory_total'] = hardware.memorySize / (1024 * 1024) def update_host_hardware_values_none(data): data['vcpus'] = 0 data['cpu_info'] = {'vendor': '', 'model': '', 'topology': {'cores': 0, 'sockets': 0, 'threads': 0} } data['host_memory_total'] = 0 def update_host_data(data, summary, host_name): if hasattr(summary, 'hardware'): update_host_hardware_values(data, summary.hardware) else: update_host_hardware_values_none(data) if hasattr(summary, 'quickStats'): overall = summary.quickStats.overallMemoryUsage else: overall = 0 data['host_memory_free'] = data['host_memory_total'] - overall if hasattr(summary.config, 'product'): data['hypervisor_type'] = summary.config.product.name data['hypervisor_version'] = summary.config.product.version else: data['hypervisor_type'] = '' data['hypervisor_version'] = '' data['hypervisor_hostname'] = host_name data['supported_instances'] = [('i686', 'vmware', 'hvm'), ('x86_64', 'vmware', 'hvm')] # update common host data update_host_data(data, summary, self._host_name) # update disk data # update common host data update_host_data(data, summary, self._host_name) # update disk data"," data[""vcpus""] = summary.hardware.numCpuThreads data[""cpu_info""] = \ {""vendor"": summary.hardware.vendor, ""model"": summary.hardware.cpuModel, ""topology"": {""cores"": summary.hardware.numCpuCores, ""sockets"": summary.hardware.numCpuPkgs, ""threads"": summary.hardware.numCpuThreads} } data[""host_memory_total""] = summary.hardware.memorySize / (1024 * 1024) data[""host_memory_free""] = data[""host_memory_total""] - \ summary.quickStats.overallMemoryUsage data[""hypervisor_type""] = summary.config.product.name data[""hypervisor_version""] = summary.config.product.version data[""hypervisor_hostname""] = self._host_name data[""supported_instances""] = [('i686', 'vmware', 'hvm'), ('x86_64', 'vmware', 'hvm')] data[""vcpus""] = summary.hardware.numCpuThreads data[""cpu_info""] =\ {""vendor"": summary.hardware.vendor, ""model"": summary.hardware.cpuModel, ""topology"": {""cores"": summary.hardware.numCpuCores, ""sockets"": summary.hardware.numCpuPkgs, ""threads"": summary.hardware.numCpuThreads} } data[""host_memory_total""] = summary.hardware.memorySize / (1024 * 1024) data[""host_memory_free""] = data[""host_memory_total""] -\ summary.quickStats.overallMemoryUsage data[""hypervisor_type""] = summary.config.product.name data[""hypervisor_version""] = summary.config.product.version data[""hypervisor_hostname""] = self._host_name data[""supported_instances""] = [('i686', 'vmware', 'hvm'), ('x86_64', 'vmware', 'hvm')]",88,44
openstack%2Fironic~master~Ia6f7eca79097aba0aaf8021f05181f30fbeda516,openstack/ironic,master,Ia6f7eca79097aba0aaf8021f05181f30fbeda516,Fix docstring typo,MERGED,2013-09-05 07:48:44.000000000,2013-09-05 14:55:23.000000000,2013-09-05 14:55:23.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 7794}]","[{'number': 1, 'created': '2013-09-05 07:48:44.000000000', 'files': ['ironic/api/controllers/v1/port.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/27a8487e7c54689f1cb7c57c4bc5a35d5c376856', 'message': 'Fix docstring typo\n\ns/Ceate/Create/\n\nChange-Id: Ia6f7eca79097aba0aaf8021f05181f30fbeda516\n'}]",0,45186,27a8487e7c54689f1cb7c57c4bc5a35d5c376856,9,6,1,6509,,,0,"Fix docstring typo

s/Ceate/Create/

Change-Id: Ia6f7eca79097aba0aaf8021f05181f30fbeda516
",git fetch https://review.opendev.org/openstack/ironic refs/changes/86/45186/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/port.py', 'ironic/api/controllers/v1/node.py']",2,27a8487e7c54689f1cb7c57c4bc5a35d5c376856,," """"""Create a new node."""""""," """"""Ceate a new node.""""""",2,2
openstack%2Fironic~master~If4640d09a19bbd1548375fa6817e9d926c805c7c,openstack/ironic,master,If4640d09a19bbd1548375fa6817e9d926c805c7c,Add missing unique constraint,MERGED,2013-08-29 15:49:55.000000000,2013-09-05 14:51:40.000000000,2013-09-05 14:51:39.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 7491}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-08-29 15:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0e306502328dbfcb692b6d158dc812a94c10a52a', 'message': 'Add missing unique constraint\n\nThere is missing unique constraint in chassis table.\nThis patch adds missing UC in separate migration.\n\nChange-Id: If4640d09a19bbd1548375fa6817e9d926c805c7c\n'}, {'number': 2, 'created': '2013-09-05 08:20:04.000000000', 'files': ['ironic/db/sqlalchemy/migrate_repo/versions/011_add_chassis_uc.py', 'ironic/tests/db/sqlalchemy/test_migrations.py', 'ironic/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d5602a87efeab67b677cd76c0ff27045868bc40b', 'message': 'Add missing unique constraint\n\nThere is missing unique constraint in chassis table.\nThis patch adds missing UC in separate migration.\n\nChange-Id: If4640d09a19bbd1548375fa6817e9d926c805c7c\n'}]",2,44313,d5602a87efeab67b677cd76c0ff27045868bc40b,16,6,2,7711,,,0,"Add missing unique constraint

There is missing unique constraint in chassis table.
This patch adds missing UC in separate migration.

Change-Id: If4640d09a19bbd1548375fa6817e9d926c805c7c
",git fetch https://review.opendev.org/openstack/ironic refs/changes/13/44313/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/db/sqlalchemy/migrate_repo/versions/011_add_chassis_uc.py', 'ironic/tests/db/sqlalchemy/test_migrations.py', 'ironic/db/sqlalchemy/models.py']",3,0e306502328dbfcb692b6d158dc812a94c10a52a,missing-uc,"from sqlalchemy import Integer, schema, String __table_args__ = ( schema.UniqueConstraint('uuid', name='uniq_chassis0uuid'), )","from sqlalchemy import Integer, String",42,1
openstack%2Fnova~master~I92e49b1e759e18a537351d727b3ceeb6e854e97f,openstack/nova,master,I92e49b1e759e18a537351d727b3ceeb6e854e97f,Add notifiers when starting attaching/detaching of volumes Implements: add a notifier for attaching and detaching a volume Fixes: bug #1216060,ABANDONED,2013-09-05 13:37:04.000000000,2013-09-05 14:25:06.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 6499}, {'_account_id': 7482}]","[{'number': 1, 'created': '2013-09-05 13:37:04.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7cd6bfba8a98d3977d1f32ca86056d14796fa858', 'message': 'Add notifiers when starting attaching/detaching of volumes\nImplements: add a notifier for attaching and detaching a volume\nFixes: bug #1216060\n\nChange-Id: I92e49b1e759e18a537351d727b3ceeb6e854e97f\n'}]",0,45231,7cd6bfba8a98d3977d1f32ca86056d14796fa858,5,5,1,8562,,,0,"Add notifiers when starting attaching/detaching of volumes
Implements: add a notifier for attaching and detaching a volume
Fixes: bug #1216060

Change-Id: I92e49b1e759e18a537351d727b3ceeb6e854e97f
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/45231/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,7cd6bfba8a98d3977d1f32ca86056d14796fa858,bug/1216060," self.assertEqual(4, len(fake_notifier.NOTIFICATIONS)) self.assertEquals(8, len(fake_notifier.NOTIFICATIONS)) self.assertEquals('compute.instance.volume.attaching.start', msg.event_type) msg = fake_notifier.NOTIFICATIONS[1] self.assertEquals('compute.instance.volume.attaching.end', msg.event_type) self.assertEquals('compute.instance.volume.attach', msg.event_type) msg = fake_notifier.NOTIFICATIONS[4] msg = fake_notifier.NOTIFICATIONS[5] self.assertEquals('compute.instance.volume.detaching.start', msg.event_type) msg = fake_notifier.NOTIFICATIONS[6] self.assertEquals('compute.instance.volume.detaching.end', msg.event_type) msg = fake_notifier.NOTIFICATIONS[7]"," self.assertEqual(2, len(fake_notifier.NOTIFICATIONS)) self.assertEquals(4, len(fake_notifier.NOTIFICATIONS)) self.assertEquals('compute.instance.volume.attach', msg.event_type) msg = fake_notifier.NOTIFICATIONS[3]",27,7
openstack%2Fnova~master~I84541f8ff6e1b5978734e5def69946d014c66fdf,openstack/nova,master,I84541f8ff6e1b5978734e5def69946d014c66fdf,Allow block devices without device_name,MERGED,2013-08-05 14:06:58.000000000,2013-09-05 14:09:56.000000000,2013-09-05 14:09:53.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5292}, {'_account_id': 5511}, {'_account_id': 7593}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-08-05 14:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3edd3fd92673d6e60ca7d0da32abc1808720ea54', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will check each one of the\nblock devices that should be attached and verify that all of them have a\ndevice_name assigned. If any of them doesn't, it will try to guess a\nvalid name using the method `get_next_device_name', which should be\nimplemented by the drivers, or by calling the generic method from the\nutils module `get_device_name_for_instance'.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nkept in the instance.\n\nPart of blueprint: improve-block-device-handling\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 2, 'created': '2013-08-05 14:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c630cf240ea67b7bd779d788722dd68890c76ffe', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will check each one of the\nblock devices that should be attached and verify that all of them have a\ndevice_name assigned. If any of them doesn't, it will try to guess a\nvalid name using the method `get_next_device_name', which should be\nimplemented by the drivers, or by calling the generic method from the\nutils module `get_device_name_for_instance'.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nkept in the instance.\n\nPart of blueprint: improve-block-device-handling\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 3, 'created': '2013-08-06 08:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c670060ad07a5c01be32d9f8bceb40a9e95e07ab', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will check each one of the\nblock devices that should be attached and verify that all of them have a\ndevice_name assigned. If any of them doesn't, it will try to guess a\nvalid name using the method `get_next_device_name', which should be\nimplemented by the drivers, or by calling the generic method from the\nutils module `get_device_name_for_instance'.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nkept in the instance.\n\nPart of blueprint: improve-block-device-handling\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 4, 'created': '2013-08-06 22:13:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e65536c865df2285e179a076e195fca820fcf806', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will check each one of the\nblock devices that should be attached and verify that all of them have a\ndevice_name assigned. If any of them doesn't, it will try to guess a\nvalid name using the method `get_next_device_name', which should be\nimplemented by the drivers, or by calling the generic method from the\nutils module `get_device_name_for_instance'.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 5, 'created': '2013-08-07 08:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7138e80b25726ad1a4f07cd4559456171f833d37', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will check each one of the\nblock devices that should be attached and verify that all of them have a\ndevice_name assigned. If any of them doesn't, it will try to guess a\nvalid name using the method `get_next_device_name', which should be\nimplemented by the drivers, or by calling the generic method from the\nutils module `get_device_name_for_instance'.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 6, 'created': '2013-08-07 11:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ebdf988fae3ef044711702142fc2ce8d9e57311', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will check each one of the\nblock devices that should be attached and verify that all of them have a\ndevice_name assigned. If any of them doesn't, it will try to guess a\nvalid name using the method `get_next_device_name', which should be\nimplemented by the drivers, or by calling the generic method from the\nutils module `get_device_name_for_instance'.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 7, 'created': '2013-08-09 14:44:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ee5299ca2772d88e23ca5b9079d3eaf80f95251', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nPatch was co-authored by Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 8, 'created': '2013-08-09 15:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8118fa30a78057815c408303cc2b7e885a04a11a', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 9, 'created': '2013-08-12 09:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28d994ee089b49b3173c2a32736430e5773590e3', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 10, 'created': '2013-08-12 11:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27922a407293c76dd6bc8af13e772e26ad444d83', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 11, 'created': '2013-08-13 12:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39056c81d2ceeed426f7f0d8e6e7bc840def2f86', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 12, 'created': '2013-08-14 19:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8058ae82dfd9a5a4e9a173782c4e438ec5462a52', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 13, 'created': '2013-08-16 17:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3cdc2dd30f37849992f03a3d4ad7e63bab087335', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 14, 'created': '2013-08-17 11:20:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bdb7232c77e63cb34b7ea98bbb1185ffe257d5a7', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above expect top be passed the standard\nblock device mapping format, and not the one used in other driver\nmethods.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 15, 'created': '2013-08-19 08:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3de5b67d6f92bcd00ffec9ebf9a1a32de332cdb4', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above expect top be passed the standard\nblock device mapping format, and not the one used in other driver\nmethods.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 16, 'created': '2013-08-19 16:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/729e1d013bda34db0bc237d31b08ba278a4938db', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above expect top be passed the standard\nblock device mapping format, and not the one used in other driver\nmethods.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 17, 'created': '2013-08-22 10:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a0852803d82e6c2fe3d3fa91ff353fa25069c7a', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above expect to be passed the standard\nblock device mapping format, and not the one used in other driver\nmethods.\n\nget_device_name_for_instance is also reused to guess a missing\nroot_device_name when converting legacy_bdm on the API side of things.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 18, 'created': '2013-08-23 14:15:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f0cdc6bd698971b93d8c04f42265f9090d84e1f', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above expect to be passed the standard\nblock device mapping format, and not the one used in other driver\nmethods.\n\nget_device_name_for_instance is also reused to guess a missing\nroot_device_name when converting legacy_bdm on the API side of things.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 19, 'created': '2013-08-26 08:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ceef9200f83d0a1422f9c8d7500a3c19ed247b4', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above expect to be passed the standard\nblock device mapping format, and not the one used in other driver\nmethods.\n\nget_device_name_for_instance is also reused to guess a missing\nroot_device_name when converting legacy_bdm on the API side of things.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 20, 'created': '2013-08-29 17:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c2bb8c999212c15194381f2897f6c4b48170950', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above expect to be passed the standard\nblock device mapping format, and not the one used in other driver\nmethods.\n\nget_device_name_for_instance is also reused to guess a missing\nroot_device_name when converting legacy_bdm on the API side of things.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 21, 'created': '2013-09-02 13:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08144be8d1cf1ff234f65e1ae655d87eb32017fe', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above expect to be passed the standard\nblock device mapping format, and not the one used in other driver\nmethods.\n\nget_device_name_for_instance is also reused to guess a missing\nroot_device_name when converting legacy_bdm on the API side of things.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 22, 'created': '2013-09-04 09:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/523f965b5879b3fabc6ec401db14a7833208810b', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above, the code should expect to be passed the\nstandard block device mapping format, and not the one used in other\ndriver methods.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 23, 'created': '2013-09-04 11:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/875b706273e45e105b25758abcbceff6b3fbac86', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above, the code should expect to be passed the\nstandard block device mapping format, and not the one used in other\ndriver methods.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 24, 'created': '2013-09-04 14:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c9ac00f7dc782a17ab64b2b83764486e5600ecda', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above, the code should expect to be passed the\nstandard block device mapping format, and not the one used in other\ndriver methods.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}, {'number': 25, 'created': '2013-09-05 08:06:47.000000000', 'files': ['nova/tests/virt/test_block_device.py', 'nova/tests/compute/test_compute_utils.py', 'nova/virt/driver.py', 'nova/compute/manager.py', 'nova/tests/db/test_db_api.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py', 'nova/db/sqlalchemy/api.py', 'nova/compute/utils.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3b1f7c55c10eec9d438a7d147aba1124b5ff9452', 'message': ""Allow block devices without device_name\n\nThis patch removes the check in the API that prevented having block\ndevices without 'device_name' and makes the compute manager capable of\nguessing those names.\n\nBefore creating the instance, the manager will try to guess a valid name\nusing the method 'default_device_names_for_instance',  which should be\nimplemented by the drivers, or defer to the generic function from the\nutils module 'default_device_names_for_instance' which uses the already\nexisting 'get_device_name_for_instance' function.\n\nIt also takes care of assigning the correct device name to the root\ndevice (boot_index=0) to make it agree with the field `root_device_name'\nfrom the instance. If none were supplied - it will try to guess it by\ncalling driver 'default_root_device_name' or defer to the generic\n'get_device_name_for_instance'. if driver does not provide it.\n\nWhat is worth noting also is that, should the drivers override the\ntwo methods mentioned above, the code should expect to be passed the\nstandard block device mapping format, and not the one used in other\ndriver methods.\n\nDocImpact\n\nPart of blueprint: improve-block-device-handling\n\nCo-authored-by: Xavier Queralt <xqueralt@redhat.com>\n\nChange-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf\n""}]",26,40229,3b1f7c55c10eec9d438a7d147aba1124b5ff9452,113,10,25,7808,,,0,"Allow block devices without device_name

This patch removes the check in the API that prevented having block
devices without 'device_name' and makes the compute manager capable of
guessing those names.

Before creating the instance, the manager will try to guess a valid name
using the method 'default_device_names_for_instance',  which should be
implemented by the drivers, or defer to the generic function from the
utils module 'default_device_names_for_instance' which uses the already
existing 'get_device_name_for_instance' function.

It also takes care of assigning the correct device name to the root
device (boot_index=0) to make it agree with the field `root_device_name'
from the instance. If none were supplied - it will try to guess it by
calling driver 'default_root_device_name' or defer to the generic
'get_device_name_for_instance'. if driver does not provide it.

What is worth noting also is that, should the drivers override the
two methods mentioned above, the code should expect to be passed the
standard block device mapping format, and not the one used in other
driver methods.

DocImpact

Part of blueprint: improve-block-device-handling

Co-authored-by: Xavier Queralt <xqueralt@redhat.com>

Change-Id: I84541f8ff6e1b5978734e5def69946d014c66fdf
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/40229/24 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/test_servers.py', 'nova/virt/driver.py', 'nova/compute/manager.py', 'nova/tests/db/test_db_api.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py', 'nova/api/openstack/compute/servers.py', 'nova/compute/utils.py', 'nova/db/sqlalchemy/api.py']",9,3edd3fd92673d6e60ca7d0da32abc1808720ea54,bp/improve-block-device-handling," result = None # NOTE(xqueralt): Only update when device_name is provided. We want to # allow empty device names that will be set by the driver later. if values['device_name']: result = ( _block_device_mapping_get_query(context, session=session). filter_by(instance_uuid=values['instance_uuid']). filter_by(device_name=values['device_name']). first())"," result = _block_device_mapping_get_query(context, session=session).\ filter_by(instance_uuid=values['instance_uuid']).\ filter_by(device_name=values['device_name']).\ first()",243,39
openstack%2Fopenstack-manuals~master~I1efa33de2899493fefccbd617303f84259368d77,openstack/openstack-manuals,master,I1efa33de2899493fefccbd617303f84259368d77,registration to be added,MERGED,2013-09-04 03:53:26.000000000,2013-09-05 14:05:43.000000000,2013-09-05 14:05:42.000000000,"[{'_account_id': 3}, {'_account_id': 1177}, {'_account_id': 6547}, {'_account_id': 7653}]","[{'number': 1, 'created': '2013-09-04 03:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/53c3adbf892ae690bc5293a1245e451336f93dc6', 'message': 'registration to be added\n\nresistering on openstack.org/register\n\nFixes Bug 1215743\n\nChange-Id: I1efa33de2899493fefccbd617303f84259368d77\n'}, {'number': 3, 'created': '2013-09-04 04:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/11bb92658aae4444f396584688cd375e1247e61c', 'message': 'registration to be added\n\nresistering on openstack.org/register\n\nFixes Bug 1215743\n\nChange-Id: I1efa33de2899493fefccbd617303f84259368d77\n'}, {'number': 2, 'created': '2013-09-04 04:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0c588a15ba571e0215baf50e83133712b994c73c', 'message': 'registration to be added\n\nresistering on openstack.org/register\n\nFixes Bug 1215743\n\nChange-Id: I1efa33de2899493fefccbd617303f84259368d77\n'}, {'number': 4, 'created': '2013-09-05 09:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1e84a77a1b5d6f778679583f2f557640cec30525', 'message': 'registration to be added\n\nresistering on openstack.org/register\n\nFixes Bug 1215743\n\nChange-Id: I1efa33de2899493fefccbd617303f84259368d77\n'}, {'number': 5, 'created': '2013-09-05 11:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9ef4587b2cbe54f2d181213c71d85eabfcf9d207', 'message': 'registration to be added\n\nresistering on openstack.org/register\n\nFixes Bug 1215743\n\nChange-Id: I1efa33de2899493fefccbd617303f84259368d77\n'}, {'number': 6, 'created': '2013-09-05 11:26:01.000000000', 'files': ['doc/src/docbkx/openstack-training/operator-editing-code.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5a0555ac1146880485603b16b11abd46268ddd94', 'message': 'registration to be added\n\nresistering on openstack.org/register\n\nFixes Bug 1215743\n\nChange-Id: I1efa33de2899493fefccbd617303f84259368d77\n'}]",4,45000,5a0555ac1146880485603b16b11abd46268ddd94,21,4,6,7653,,,0,"registration to be added

resistering on openstack.org/register

Fixes Bug 1215743

Change-Id: I1efa33de2899493fefccbd617303f84259368d77
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/00/45000/6 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-training/operator-editing-code.xml'],1,53c3adbf892ae690bc5293a1245e451336f93dc6,bug/1215743," on https://help.launchpad.net/YourAccount/CreatingAnSSHKeyPair.</para> <para>Join The OpenStack Foundation: Visit https://www.openstack.org/join. Among other privileges, this also allows you to vote in elections and run for elected positions within The OpenStack Project. When signing up for Foundation Membership, make sure to give the same E-mail address you'll use for Launchpad account.</para> </step> <step> the CLA: Every developer and contributor needs to", onhttps://help.launchpad.net/YourAccount/CreatingAnSSHKeyPair.</para> <para>Sign the CLA: Every developer and contributor needs to,8,2
openstack%2Fglance~master~If38604d812c34416b8369bf6f868a0f2509c2649,openstack/glance,master,If38604d812c34416b8369bf6f868a0f2509c2649,Enable protected properties in gateway,MERGED,2013-08-27 15:35:58.000000000,2013-09-05 13:44:36.000000000,2013-09-05 06:01:54.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 616}, {'_account_id': 1390}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 8158}]","[{'number': 1, 'created': '2013-08-27 15:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/96bbc26c5fd6c51219d36b5eb58c37553120173c', 'message': 'Adds property protection layer to gateway\n\nRelated to bp api-v2-property-protection\n\nActivates property protection by adding the layer to the\ngateway. Accompanied by relevant functional and unit tests.\n\nChange-Id: If38604d812c34416b8369bf6f868a0f2509c2649\n'}, {'number': 2, 'created': '2013-08-28 14:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ef7b75ecc0a826c6b475e0ffa02a6640a78ba385', 'message': 'Adds property protection layer to gateway\n\nRelated to bp api-v2-property-protection\n\nActivates property protection by adding the layer to the\ngateway. Accompanied by relevant functional and unit tests.\n\nChange-Id: If38604d812c34416b8369bf6f868a0f2509c2649\n'}, {'number': 3, 'created': '2013-08-28 16:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6e49755c41306f1fddb6bde680fe278ebea89352', 'message': 'Adds property protection layer to gateway\n\nRelated to bp api-v2-property-protection\n\nActivates property protection by adding the layer to the\ngateway. Accompanied by relevant functional and unit tests.\n\nChange-Id: If38604d812c34416b8369bf6f868a0f2509c2649\n'}, {'number': 4, 'created': '2013-08-31 01:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/17f71f7e1b60b1ed596f64d03ba8d54b0162dd66', 'message': 'Enable protected properties in gateway\n\nRelated to bp api-v2-property-protection\n\nActivate property protections if the config value is set.\nAdded the corresponding functional and unit tests.\n\nChange-Id: If38604d812c34416b8369bf6f868a0f2509c2649\n'}, {'number': 5, 'created': '2013-09-02 13:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/03f8f12d5784d13531855a444132c76bce8af221', 'message': 'Enable protected properties in gateway\n\nRelated to bp api-v2-property-protection\n\nActivate property protections if the config value is set.\nAdded the corresponding functional and unit tests.\n\nChange-Id: If38604d812c34416b8369bf6f868a0f2509c2649\n'}, {'number': 6, 'created': '2013-09-03 20:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/78b69e8943a8753d2eb9bcf8d79ecd35c6faf00a', 'message': 'Enable protected properties in gateway\n\nRelated to bp api-v2-property-protection\n\nActivate property protections if the config value is set.\nAdded the corresponding functional and unit tests.\n\nChange-Id: If38604d812c34416b8369bf6f868a0f2509c2649\n'}, {'number': 7, 'created': '2013-09-04 03:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0e4c0ace282a83994427e3661cef90ba63238566', 'message': 'Enable protected properties in gateway\n\nRelated to bp api-v2-property-protection\n\nActivate property protections if the config value is set.\nAdded the corresponding functional and unit tests.\n\nChange-Id: If38604d812c34416b8369bf6f868a0f2509c2649\n'}, {'number': 8, 'created': '2013-09-04 14:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6e04e316a6a7d81c0065331304eb2adb8f198264', 'message': 'Enable protected properties in gateway\n\nRelated to bp api-v2-property-protection\n\nActivate property protections if the config value is set.\nAdded the corresponding functional and unit tests.\n\nChange-Id: If38604d812c34416b8369bf6f868a0f2509c2649\n'}, {'number': 9, 'created': '2013-09-04 18:05:03.000000000', 'files': ['glance/tests/functional/v2/test_images.py', 'glance/gateway.py', 'glance/common/property_utils.py', 'glance/tests/functional/__init__.py', 'glance/tests/unit/v2/test_images_resource.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/fe7198a6ecf45edd8b5ca2030586c746f204fe3f', 'message': 'Enable protected properties in gateway\n\nRelated to bp api-v2-property-protection\n\nActivate property protections if the config value is set.\nAdded the corresponding functional and unit tests.\n\nChange-Id: If38604d812c34416b8369bf6f868a0f2509c2649\n'}]",15,43904,fe7198a6ecf45edd8b5ca2030586c746f204fe3f,45,9,9,4463,,,0,"Enable protected properties in gateway

Related to bp api-v2-property-protection

Activate property protections if the config value is set.
Added the corresponding functional and unit tests.

Change-Id: If38604d812c34416b8369bf6f868a0f2509c2649
",git fetch https://review.opendev.org/openstack/glance refs/changes/04/43904/3 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/functional/v2/test_images.py', 'glance/api/v2/images.py', 'glance/gateway.py', 'glance/tests/functional/__init__.py', 'glance/domain/__init__.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/tests/etc/property-protections.conf']",7,96bbc26c5fd6c51219d36b5eb58c37553120173c,bp/api-v2-property-protection,"[type] create = admin,member read = admin,member update = admin,member delete = admin,member ",,324,61
openstack%2Fopenstack-manuals~master~I77c29698c67e3a7c9f8d963321ae5c52e065e85d,openstack/openstack-manuals,master,I77c29698c67e3a7c9f8d963321ae5c52e065e85d,Install Guide for openSUSE,MERGED,2013-09-03 08:41:27.000000000,2013-09-05 13:43:46.000000000,2013-09-05 13:43:45.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-09-03 08:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0a9678923448b9d98660ae4d5ec6cb3a9bd8dfcc', 'message': 'Install Guide for openSUSE\n\nAdd instructions for openSUSE\n\nChange-Id: I77c29698c67e3a7c9f8d963321ae5c52e065e85d\n'}, {'number': 2, 'created': '2013-09-03 08:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3d488b50a702d6e6a112effb70f982b0c5afbefe', 'message': 'Install Guide for openSUSE\n\nAdd instructions for openSUSE\n\nChange-Id: I77c29698c67e3a7c9f8d963321ae5c52e065e85d\n'}, {'number': 3, 'created': '2013-09-03 10:33:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9ac6157769fead0e52e5bdba9c7a80b9f5369ad7', 'message': 'Install Guide for openSUSE\n\nAdd instructions for openSUSE\n\nChange-Id: I77c29698c67e3a7c9f8d963321ae5c52e065e85d\n'}, {'number': 4, 'created': '2013-09-03 11:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fd64a1c50cd23fe7f8e6721f465bd6422476db4d', 'message': 'Install Guide for openSUSE\n\nAdd instructions for openSUSE\n\nChange-Id: I77c29698c67e3a7c9f8d963321ae5c52e065e85d\n'}, {'number': 5, 'created': '2013-09-05 05:00:35.000000000', 'files': ['doc/src/docbkx/openstack-install/installing-rabbitmq.xml', 'doc/src/docbkx/openstack-install/ch_installing-openstack-overview.xml', 'doc/src/docbkx/openstack-install/installing-mysql.xml', 'doc/src/docbkx/openstack-install/bk_openstackinstallguide.xml', 'doc/src/docbkx/openstack-install/installing-ntp.xml', 'doc/src/docbkx/openstack-install/ch_assumptions.xml', 'doc/src/docbkx/openstack-install/compute-sys-requirements.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6678254f05eb2948982277e39f92ee31b09e76cf', 'message': 'Install Guide for openSUSE\n\nAdd instructions for openSUSE\n\nChange-Id: I77c29698c67e3a7c9f8d963321ae5c52e065e85d\n'}]",0,44811,6678254f05eb2948982277e39f92ee31b09e76cf,19,4,5,6547,,,0,"Install Guide for openSUSE

Add instructions for openSUSE

Change-Id: I77c29698c67e3a7c9f8d963321ae5c52e065e85d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/11/44811/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-install/installing-mysql.xml', 'doc/src/docbkx/openstack-install/bk_openstackinstallguide.xml', 'doc/src/docbkx/openstack-install/installing-ntp.xml', 'doc/src/docbkx/openstack-install/compute-sys-requirements.xml']",4,0a9678923448b9d98660ae4d5ec6cb3a9bd8dfcc,openSUSE-install," <para os=""opensuse"">Packages for openSUSE are available in the Open Build Service.</para> </note></para>", </note></para>,21,4
openstack%2Fceilometer~master~Id9b0e1eb0e685053291367f7eb62fef68b6b2f84,openstack/ceilometer,master,Id9b0e1eb0e685053291367f7eb62fef68b6b2f84,Fix wrong migrations,MERGED,2013-09-05 08:53:03.000000000,2013-09-05 13:41:51.000000000,2013-09-05 13:41:51.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-09-05 08:53:03.000000000', 'files': ['ceilometer/storage/sqlalchemy/alembic/versions/b6ae66d05e3_remove_extra_indexes.py', 'ceilometer/storage/sqlalchemy/alembic/versions/2c3ccda5a3ad_fix_uniq_name.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/aae3f55304ff161b401b803769350e9cb66b0e8c', 'message': 'Fix wrong migrations\n\nFor Postgres migrations are failed.\nMore then we can get for mysql an error\n""Specified key was too long; max key length is 1000 bytes"" in b6ae66d05e3\nmigration in some versions of dialect.\n\nFixes-Bug: #1219776\n\nChange-Id: Id9b0e1eb0e685053291367f7eb62fef68b6b2f84\n'}]",0,45196,aae3f55304ff161b401b803769350e9cb66b0e8c,6,3,1,6507,,,0,"Fix wrong migrations

For Postgres migrations are failed.
More then we can get for mysql an error
""Specified key was too long; max key length is 1000 bytes"" in b6ae66d05e3
migration in some versions of dialect.

Fixes-Bug: #1219776

Change-Id: Id9b0e1eb0e685053291367f7eb62fef68b6b2f84
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/96/45196/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/sqlalchemy/alembic/versions/b6ae66d05e3_remove_extra_indexes.py', 'ceilometer/storage/sqlalchemy/alembic/versions/2c3ccda5a3ad_fix_uniq_name.py']",2,aae3f55304ff161b401b803769350e9cb66b0e8c,,"UNIQ_NAME = 'uniq_sourceassoc0meter_id0user_id'def change_uniq(table_name, uniq_name, columns, downgrade=False): bind = op.get_bind() engine = bind.engine if downgrade: op.drop_constraint(uniq_name, table_name=table_name, type_='unique') else: op.create_unique_constraint(uniq_name, table_name, columns) change_uniq(TABLE_NAME, UNIQ_NAME, COLUMNS) change_uniq(TABLE_NAME, UNIQ_NAME, COLUMNS, downgrade=True)","OLD_NAME = 'uniq_sourceassoc0meter_id' NEW_NAME = 'uniq_sourceassoc0meter_id0user_id'def change_uniq(table_name, old_name, new_name, columns): engine = op.get_bind().engine try: # For some versions of dialects constraint can be skipped. op.drop_constraint(old_name, table_name=table_name, type_='unique') except Exception: pass op.create_unique_constraint(new_name, table_name, columns) change_uniq(TABLE_NAME, OLD_NAME, NEW_NAME, COLUMNS) change_uniq(TABLE_NAME, NEW_NAME, OLD_NAME, COLUMNS)",41,30
openstack%2Fnova~master~Ifb08047623e1da3dd818bc316216d1df1ec6007d,openstack/nova,master,Ifb08047623e1da3dd818bc316216d1df1ec6007d,Fix typo and indent error in isolated_hosts_filter.py,MERGED,2013-09-03 00:13:30.000000000,2013-09-05 13:41:13.000000000,2013-09-05 13:41:11.000000000,"[{'_account_id': 3}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 7069}, {'_account_id': 7494}, {'_account_id': 8495}, {'_account_id': 8574}]","[{'number': 1, 'created': '2013-09-03 00:13:30.000000000', 'files': ['nova/scheduler/filters/isolated_hosts_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5839620a87aeda7f1065f440a02f4433e0041b0f', 'message': 'Fix typo and indent error in isolated_hosts_filter.py\n\nFix typo and indent error in isolated_hosts_filter.py\n\nChange-Id: Ifb08047623e1da3dd818bc316216d1df1ec6007d\n'}]",2,44777,5839620a87aeda7f1065f440a02f4433e0041b0f,15,10,1,8495,,,0,"Fix typo and indent error in isolated_hosts_filter.py

Fix typo and indent error in isolated_hosts_filter.py

Change-Id: Ifb08047623e1da3dd818bc316216d1df1ec6007d
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/44777/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/filters/isolated_hosts_filter.py'],1,5839620a87aeda7f1065f440a02f4433e0041b0f,master, # The configuration values do not change within a request, # The configurtaion values do not change within a request,1,1
openstack%2Fceilometer~master~Icfa161109e76e2717f64084ddce829f6c68aeb57,openstack/ceilometer,master,Icfa161109e76e2717f64084ddce829f6c68aeb57,nova_notifier: fix tests,MERGED,2013-09-05 12:40:45.000000000,2013-09-05 13:31:19.000000000,2013-09-05 13:31:18.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-09-05 12:40:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3136068cab026f3e991b9ddc7e50292b93d91448', 'message': ""nova_notifier: fix tests wrt instance_update_and_get_original proto change\n\nThe prototype for this function changed, so let's ignore it completely\nfor the future.\n\nChange-Id: Icfa161109e76e2717f64084ddce829f6c68aeb57\nFixes-Bug: #1221173\n""}, {'number': 2, 'created': '2013-09-05 12:57:37.000000000', 'files': ['nova_tests/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d2a87a9dfd3cd9ef034eed3d693683972c842576', 'message': ""nova_notifier: fix tests\n\nThe prototype for instance_update_and_get_original changed, so let's\nignore it completely for the future.\n\nChange-Id: Icfa161109e76e2717f64084ddce829f6c68aeb57\nFixes-Bug: #1221173\n""}]",0,45222,d2a87a9dfd3cd9ef034eed3d693683972c842576,8,3,2,1669,,,0,"nova_notifier: fix tests

The prototype for instance_update_and_get_original changed, so let's
ignore it completely for the future.

Change-Id: Icfa161109e76e2717f64084ddce829f6c68aeb57
Fixes-Bug: #1221173
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/22/45222/1 && git format-patch -1 --stdout FETCH_HEAD,['nova_tests/test_notifier.py'],1,3136068cab026f3e991b9ddc7e50292b93d91448,jd/bug1221173-fix-nova-notifier," lambda *args, **kwargs: (self.instance, self.instance))"," lambda context, uuid, kwargs, update_cells: (self.instance, self.instance))",1,2
openstack%2Fceilometer~master~I89226c4eb7350e61ad7ee810fbbb75ae85fb985e,openstack/ceilometer,master,I89226c4eb7350e61ad7ee810fbbb75ae85fb985e,Fix PostgreSQL migrations,ABANDONED,2013-09-02 12:33:59.000000000,2013-09-05 13:28:31.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 6507}]","[{'number': 1, 'created': '2013-09-02 12:33:59.000000000', 'files': ['ceilometer/storage/sqlalchemy/alembic/versions/b6ae66d05e3_remove_extra_indexes.py', 'ceilometer/storage/sqlalchemy/alembic/versions/2c3ccda5a3ad_fix_uniq_name.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/13dbd54c1e68b4e097e21290e8546f1041536fe8', 'message': 'Fix PostgreSQL migrations\n\nPostgreSQL migrations were wrong and tried to remove nonexistent\nindexes.\n\nChange-Id: I89226c4eb7350e61ad7ee810fbbb75ae85fb985e\nFixes-Bug: #1219776\n'}]",5,44691,13dbd54c1e68b4e097e21290e8546f1041536fe8,9,4,1,1669,,,0,"Fix PostgreSQL migrations

PostgreSQL migrations were wrong and tried to remove nonexistent
indexes.

Change-Id: I89226c4eb7350e61ad7ee810fbbb75ae85fb985e
Fixes-Bug: #1219776
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/91/44691/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/sqlalchemy/alembic/versions/b6ae66d05e3_remove_extra_indexes.py', 'ceilometer/storage/sqlalchemy/alembic/versions/2c3ccda5a3ad_fix_uniq_name.py']",2,13dbd54c1e68b4e097e21290e8546f1041536fe8,jd/fix-postgresql-migration,"def change_uniq(table_name, new_name, columns): change_uniq(TABLE_NAME, NEW_NAME, COLUMNS) change_uniq(TABLE_NAME, NEW_NAME, COLUMNS)","OLD_NAME = 'uniq_sourceassoc0meter_id'def change_uniq(table_name, old_name, new_name, columns): try: # For some versions of dialects constraint can be skipped. op.drop_constraint(old_name, table_name=table_name, type_='unique') except Exception: pass change_uniq(TABLE_NAME, OLD_NAME, NEW_NAME, COLUMNS) change_uniq(TABLE_NAME, NEW_NAME, OLD_NAME, COLUMNS)",4,10
openstack%2Fpython-neutronclient~master~Id6e41a0896150a62384fcd3fe9b42f1d7555109b,openstack/python-neutronclient,master,Id6e41a0896150a62384fcd3fe9b42f1d7555109b,"bp:pxeboot-ports, provide pxboot on ports",MERGED,2013-07-06 16:06:52.000000000,2013-09-05 13:14:50.000000000,2013-09-05 13:14:50.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 5572}, {'_account_id': 7166}]","[{'number': 4, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/87a14031fe06fa6540d6c0e122bd9d7ad5529bb1', 'message': 'bp:pxeboot-ports, provide pxboot on ports\n\nTeach quantum how to manage PXE boot.\n\nAllow pxe boot parameters to be specified when creating a network port.\n\nImplements bp:pxeboot-ports\n\nChange-Id: Id6e41a0896150a62384fcd3fe9b42f1d7555109b\n'}, {'number': 1, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ac730e3e901d7b053c82a67dce25a62445db1b4c', 'message': 'pxeboot-ports\n\nChange-Id: Id6e41a0896150a62384fcd3fe9b42f1d7555109b\n'}, {'number': 2, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/60dacf031e6db456376a7506f84bfc867503990b', 'message': 'blueprint pxeboot-ports\n\nChange-Id: Id6e41a0896150a62384fcd3fe9b42f1d7555109b\n'}, {'number': 3, 'created': '2013-07-06 16:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/77b34268bcb6b7d77070c0a7dbd0ac0198886b23', 'message': 'bp:pxeboot-ports, provide pxboot on ports\n\nTeach quantum how to manage PXE boot.\n\nAllow pxe boot parameters to be specified when creating a network port.\n\nImplements bp:pxeboot-ports\n\nChange-Id: Id6e41a0896150a62384fcd3fe9b42f1d7555109b\n'}, {'number': 5, 'created': '2013-07-16 17:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/dbd442f9fc5730ca7fe439de9aac67d7b523b90f', 'message': 'bp:pxeboot-ports, provide pxboot on ports\n\nTeach quantum how to manage PXE boot.\n\nAllow pxe boot parameters to be specified when creating a network port.\n\nImplements bp:pxeboot-ports\n\nChange-Id: Id6e41a0896150a62384fcd3fe9b42f1d7555109b\n'}, {'number': 6, 'created': '2013-08-05 12:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/a42ed51723ec50e4f66f2f2c553e6c0644401ab3', 'message': 'Add CLI support of extra_dhcp_options for port\n\nextra_dhcp_opts extension allows us to specify extra dhcp options\nsuch as pxboot options on ports.\n\nImplements bp:pxeboot-ports\n\nChange-Id: Id6e41a0896150a62384fcd3fe9b42f1d7555109b\n'}, {'number': 7, 'created': '2013-08-05 17:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/907caf54d07235291d7cdaf7500b6fa8f08916a9', 'message': 'bp:pxeboot-ports, provide pxboot on ports\n\nTeach neutron how to manage PXE boot.\n\nAllow pxe boot parameters to be specified when creating a network port.\n\nImplements bp:pxeboot-ports\n\nChange-Id: Id6e41a0896150a62384fcd3fe9b42f1d7555109b\n'}, {'number': 8, 'created': '2013-08-27 23:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/428200c6b87366690af50aeaafd46646e32c513f', 'message': 'bp:pxeboot-ports, provide pxboot on ports\n\nTeach neutron how to manage PXE boot.\n\nAllow pxe boot parameters to be specified when creating a network port.\n\nImplements bp:pxeboot-ports\n\nChange-Id: Id6e41a0896150a62384fcd3fe9b42f1d7555109b\n'}, {'number': 9, 'created': '2013-08-28 19:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/a6b3767c4ccccdff97f8ffa05ff52152d6466399', 'message': 'bp:pxeboot-ports, provide pxboot on ports\n\nTeach neutron how to manage PXE boot.\n\nAllow pxe boot parameters to be specified when creating a network port.\n\nImplements bp:pxeboot-ports\n\nChange-Id: Id6e41a0896150a62384fcd3fe9b42f1d7555109b\n'}, {'number': 10, 'created': '2013-09-02 16:38:10.000000000', 'files': ['neutronclient/tests/unit/test_cli20_port.py', 'neutronclient/neutron/v2_0/port.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/eeb1f3278be90757d53c6514ddd3a0907e25dbd0', 'message': 'bp:pxeboot-ports, provide pxboot on ports\n\nTeach neutron how to manage PXE boot.\n\nAllow pxe boot parameters to be specified when creating a network port.\n\nImplements bp:pxeboot-ports\n\nChange-Id: Id6e41a0896150a62384fcd3fe9b42f1d7555109b\n'}]",55,30447,eeb1f3278be90757d53c6514ddd3a0907e25dbd0,51,8,10,5572,,,0,"bp:pxeboot-ports, provide pxboot on ports

Teach neutron how to manage PXE boot.

Allow pxe boot parameters to be specified when creating a network port.

Implements bp:pxeboot-ports

Change-Id: Id6e41a0896150a62384fcd3fe9b42f1d7555109b
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/47/30447/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_cli20_port.py', 'quantumclient/quantum/v2_0/port.py']",2,87a14031fe06fa6540d6c0e122bd9d7ad5529bb1,bp/pxeboot-ports,"from quantumclient.common import exceptions '--extra-dhcp-opt', action='append', dest='extra_dhcp_opt', help='extra dhcp options to be assinged to this port: ' 'opt_name=<dhcp_option_name>,opt_value=<value>, ' '(This option can be repeated.)') parser.add_argument( ops = [] if parsed_args.extra_dhcp_opt: # the extra_dhcp_opt parms (opt_name & opt_value) # must come in pairs, if there is a parm error # both must be thrown out. optlist = parsed_args.extra_dhcp_opt[0].split(',') opt_ele = {} parm_cnt = 0 edo_err_msg = (""invalid --extra-dhcp-opt option, can only be: "" ""opt_name=<dhcp_option_name>,opt_value=<value>, "" ""(This option can be repeated."") for opt in optlist: parm_cnt += 1 if opt.split('=')[0] in ['opt_value', 'opt_name']: opt_ele.update(utils.str2dict(opt)) if parm_cnt == 2: if (('opt_name' in opt_ele) and ('opt_value' in opt_ele)): ops.append(opt_ele) opt_ele = {} parm_cnt = 0 else: raise exceptions.CommandError(edo_err_msg) else: raise exceptions.CommandError(edo_err_msg) if ops: body['port'].update({'extra_dhcp_opts': ops}) parser.add_argument( '--extra-dhcp-opt', action='append', help='extra dhcp options to be assinged to this port: ' 'opt_name=<name>,opt_value=<value>, ' '(This option can be repeated.)') ops = [] if parsed_args.extra_dhcp_opt: # the extra_dhcp_opt parms (opt_name & opt_value) # must come in pairs, if there is a parm error # both must be thrown out. optlist = parsed_args.extra_dhcp_opt[0].split(',') opt_ele = {} parm_cnt = 0 edo_err_msg = (""invalid --extra-dhcp-opt option, can only be: "" ""opt_name=<name>,opt_value=<value>, "" ""(This option can be repeated."") for opt in optlist: parm_cnt += 1 if opt.split('=')[0] in ['opt_value', 'opt_name']: opt_ele.update(utils.str2dict(opt)) if parm_cnt == 2: if (('opt_name' in opt_ele) and ('opt_value' in opt_ele)): ops.append(opt_ele) opt_ele = {} parm_cnt = 0 else: raise exceptions.CommandError(edo_err_msg) else: raise exceptions.CommandError(edo_err_msg) if ops: body['port'].update({'extra_dhcp_opts': ops}) ",,106,0
openstack%2Fnova~master~I45bdd1d0dabfcc7c80314c28072950cfc5a59615,openstack/nova,master,I45bdd1d0dabfcc7c80314c28072950cfc5a59615,Remove indirect dependency from requirements.txt,MERGED,2013-07-21 14:09:24.000000000,2013-09-05 13:13:41.000000000,2013-09-05 13:13:38.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-07-21 14:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6262bfa5622d24d08decbed746c1db3650bea126', 'message': 'Clean up dependencies\n\nOnly direct dependencies need to be listed in requirements.txt.\nMove Babel to test-requires, as it is not used at runtime.\n\nChange-Id: I45bdd1d0dabfcc7c80314c28072950cfc5a59615\n'}, {'number': 2, 'created': '2013-08-04 14:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1daff26b0d27897b1597262a878574113fd4142', 'message': 'Remove indirect dependencies from requirements.txt\n\nOnly direct dependencies need to be listed in requirements.txt.\npyparsing and python-keystoneclient were previously added to\nworkaround installation ordering issues, which is no longer\nnecessary.\n\nMove Babel to test-requires, as it is not used at runtime,\nonly for the extracting the message catalog run.\n\nChange-Id: I45bdd1d0dabfcc7c80314c28072950cfc5a59615\n'}, {'number': 3, 'created': '2013-08-14 10:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1583bb0905f2340a5a0f17b839758588e4390985', 'message': 'Remove indirect dependencies from requirements.txt\n\nOnly direct dependencies need to be listed in requirements.txt.\npyparsing and python-keystoneclient were previously added to\nworkaround installation ordering issues, which is no longer\nnecessary.\n\nChange-Id: I45bdd1d0dabfcc7c80314c28072950cfc5a59615\n'}, {'number': 4, 'created': '2013-08-22 20:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f07061a18e09ad681e4252445670e318d2c15114', 'message': 'Remove indirect dependency from requirements.txt\n\nOnly direct dependencies need to be listed in requirements.txt.\npyparsing was previously added to workaround installation ordering\nissues, which is no longer necessary.\n\nChange-Id: I45bdd1d0dabfcc7c80314c28072950cfc5a59615\n'}, {'number': 5, 'created': '2013-09-05 12:03:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/12b104751a2f13fff0954744782bc9c68a8b59bc', 'message': 'Remove indirect dependency from requirements.txt\n\nOnly direct dependencies need to be listed in requirements.txt.\npyparsing was previously added to workaround installation ordering\nissues, which is no longer necessary.\n\nChange-Id: I45bdd1d0dabfcc7c80314c28072950cfc5a59615\n'}]",6,38068,12b104751a2f13fff0954744782bc9c68a8b59bc,36,8,5,6593,,,0,"Remove indirect dependency from requirements.txt

Only direct dependencies need to be listed in requirements.txt.
pyparsing was previously added to workaround installation ordering
issues, which is no longer necessary.

Change-Id: I45bdd1d0dabfcc7c80314c28072950cfc5a59615
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/38068/5 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,6262bfa5622d24d08decbed746c1db3650bea126,no_pyparsing,Babel>=0.9.6,,1,4
openstack%2Fpython-neutronclient~master~I33cdf62244f2217379c40a8cd4c776382935ef17,openstack/python-neutronclient,master,I33cdf62244f2217379c40a8cd4c776382935ef17,Allow 'any' option for protocol in the firewall rule,MERGED,2013-08-29 02:10:55.000000000,2013-09-05 13:13:34.000000000,2013-09-05 13:13:34.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 6676}, {'_account_id': 7752}]","[{'number': 1, 'created': '2013-08-29 02:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/967f2546e0625719dfb45a2e802a2b6a435cef66', 'message': ""Allow 'any' option for protocol in the firewall rule\n\nCloses-Bug: #1217212\n\nThe current allowed values for\nprotocol are tcp, udp and icmp. Adding\n'any' as allowed option. Since the\nAPI expects 'None' value for 'any',\nthe 'create' and 'update' changes the\nargs to 'None' when 'any' is set.\n\nChange-Id: I33cdf62244f2217379c40a8cd4c776382935ef17\n""}, {'number': 2, 'created': '2013-08-30 00:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/7300e1568e122453d4dae6fa3805d00ef298a5ca', 'message': ""Allow 'any' option for protocol in the firewall rule\n\nCloses-Bug: #1217212\n\nThe current allowed values for\nprotocol are tcp, udp and icmp. Adding\n'any' as allowed option. Since the\nAPI expects 'None' value for 'any',\nthe 'create' and 'update' changes the\nargs to 'None' when 'any' is set.\n\nChange-Id: I33cdf62244f2217379c40a8cd4c776382935ef17\n""}, {'number': 3, 'created': '2013-09-01 02:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/25918bc935d34b19e4a6d24c994165121a63c9bf', 'message': ""Allow 'any' option for protocol in the firewall rule\n\nCloses-Bug: #1217212\n\nThe current allowed values for\nprotocol are tcp, udp and icmp. Adding\n'any' as allowed option. Since the\nAPI expects 'None' value for 'any',\nthe 'create' and 'update' changes the\nargs to 'None' when 'any' is set.\n\nChange-Id: I33cdf62244f2217379c40a8cd4c776382935ef17\n""}, {'number': 4, 'created': '2013-09-01 17:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f63e41091d1f930eed40498dcca383c53e57e6b8', 'message': ""Allow 'any' option for protocol in the firewall rule\n\nCloses-Bug: #1217212\n\nThe current allowed values for\nprotocol are tcp, udp and icmp. Adding\n'any' as allowed option. Since the\nAPI expects 'None' value for 'any',\nthe 'create' and 'update' changes the\nargs to 'None' when 'any' is set.\n\nChange-Id: I33cdf62244f2217379c40a8cd4c776382935ef17\n""}, {'number': 5, 'created': '2013-09-03 18:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ce8630a8f7bde0cb948ca52713b6ab00afad2f8d', 'message': ""Allow 'any' option for protocol in the firewall rule\n\nCloses-Bug: #1217212\n\nThe current allowed values for\nprotocol are tcp, udp and icmp. Adding\n'any' as allowed option. Since the\nAPI expects 'None' value for 'any',\nthe 'create' and 'update' changes the\nargs to 'None' when 'any' is set.\n\nChange-Id: I33cdf62244f2217379c40a8cd4c776382935ef17\n""}, {'number': 6, 'created': '2013-09-03 23:53:44.000000000', 'files': ['neutronclient/neutron/v2_0/fw/firewallrule.py', 'neutronclient/tests/unit/fw/test_cli20_firewallrule.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f208a893c880b6ef5209b4a13290451bb2328904', 'message': ""Allow 'any' option for protocol in the firewall rule\n\nCloses-Bug: #1217212\n\nThe current allowed values for\nprotocol are tcp, udp and icmp. Adding\n'any' as allowed option. Since the\nAPI expects 'None' value for 'any',\nthe 'create' and 'update' changes the\nargs to 'None' when 'any' is set.\n\nChange-Id: I33cdf62244f2217379c40a8cd4c776382935ef17\n""}]",25,44200,f208a893c880b6ef5209b4a13290451bb2328904,35,5,6,7752,,,0,"Allow 'any' option for protocol in the firewall rule

Closes-Bug: #1217212

The current allowed values for
protocol are tcp, udp and icmp. Adding
'any' as allowed option. Since the
API expects 'None' value for 'any',
the 'create' and 'update' changes the
args to 'None' when 'any' is set.

Change-Id: I33cdf62244f2217379c40a8cd4c776382935ef17
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/00/44200/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/fw/firewallrule.py'],1,967f2546e0625719dfb45a2e802a2b6a435cef66,patch2,"from neutronclient.common import exceptionsfrom neutronclient.openstack.common.gettextutils import _ '--protocol', choices=['tcp', 'udp', 'icmp', 'any'], if (hasattr(parsed_args, 'protocol') and getattr(parsed_args, 'protocol') == 'any'): setattr(parsed_args, 'protocol', None) def run(self, parsed_args): self.log.debug('run(%s)' % parsed_args) neutron_client = self.get_client() neutron_client.format = parsed_args.request_format _extra_values = neutronv20.parse_args_to_dict(self.values_specs) if (_extra_values['protocol'] and _extra_values['protocol'] == 'any'): _extra_values['protocol'] = None neutronv20._merge_args(self, parsed_args, _extra_values, self.values_specs) body = self.args2body(parsed_args) if self.resource in body: body[self.resource].update(_extra_values) else: body[self.resource] = _extra_values if not body[self.resource]: raise exceptions.CommandError( ""Must specify new values to update %s"" % self.resource) _id = neutronv20.find_resourceid_by_name_or_id(neutron_client, self.resource, parsed_args.id) obj_updator = getattr(neutron_client, ""update_%s"" % self.resource) obj_updator(_id, body) print >>self.app.stdout, ( _('Updated %(resource)s: %(id)s') % {'id': parsed_args.id, 'resource': self.resource}) return "," '--protocol', choices=['tcp', 'udp', 'icmp'],",35,1
openstack%2Fnova~master~Ib7be13c53231220eec232442cb1836626b4b580f,openstack/nova,master,Ib7be13c53231220eec232442cb1836626b4b580f,Deprecate conductor migration_get(),MERGED,2013-08-21 11:43:45.000000000,2013-09-05 13:12:56.000000000,2013-09-05 13:12:54.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-08-21 11:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc26bdb24fa1593729df4a8ec702eccbaa2ce5e7', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 2, 'created': '2013-08-21 21:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9f6e8e76455ce1bc42764df8fce7f9768046514', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 3, 'created': '2013-08-23 17:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf63285b63970f26e32cc0f8ef065824bb68f32f', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 4, 'created': '2013-08-23 17:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/36a9828b67735c321df965c7a75369130d56051d', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 5, 'created': '2013-08-23 19:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/137175a79c08e67581ac4f9e5a08493ba06b063f', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 6, 'created': '2013-08-23 19:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae2d6777f9a476d71de5d98862d8cad6514fc6ff', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 7, 'created': '2013-08-23 22:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b19c635349f9c4ed5d372987ad4a5f13dbfa957b', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 8, 'created': '2013-08-24 05:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c8252327909f3fbd814d5658e94477cc1f86c13', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 9, 'created': '2013-08-24 21:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d414424f40b6f0d859c2f43d0656fd5f6d3600d6', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 10, 'created': '2013-08-28 10:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d583090a1f78660796769d14fc24a79d3f9a9cf', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 11, 'created': '2013-08-28 20:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b4cf383200d1b498693cd1f9cb6cc418c29ef18', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 12, 'created': '2013-08-30 14:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4df0f5898b31a17b40b078ccfaf78ec86d39e0a', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 13, 'created': '2013-08-30 18:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d327fc0f7202fae09179f7a84ce3b21b4682699d', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 14, 'created': '2013-09-03 22:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/984734f40f1ced6f8a5ff080abbe0205c4ee16a4', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}, {'number': 15, 'created': '2013-09-04 17:28:36.000000000', 'files': ['nova/conductor/rpcapi.py', 'nova/conductor/api.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/94a860a10ede1c429d7ecac7417e09e45d3b146d', 'message': ""Deprecate conductor migration_get()\n\nIt's no longer used.  Deprecate it.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ib7be13c53231220eec232442cb1836626b4b580f\n""}]",2,43108,94a860a10ede1c429d7ecac7417e09e45d3b146d,62,9,15,1030,,,0,"Deprecate conductor migration_get()

It's no longer used.  Deprecate it.

Related to blueprint unified-object-model

Change-Id: Ib7be13c53231220eec232442cb1836626b4b580f
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/43108/13 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conductor/rpcapi.py', 'nova/conductor/api.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py']",4,cc26bdb24fa1593729df4a8ec702eccbaa2ce5e7,bp/compute-api-objects, RPC_API_VERSION = '1.58' # NOTE(comstud): This method is now deprecated and can be removed in # version v2.0 of the RPC API, RPC_API_VERSION = '1.57',12,16
openstack%2Fopenstack-manuals~master~I21cf53e26c25d75ad1b75ec7449e8e1a7e4b9bb2,openstack/openstack-manuals,master,I21cf53e26c25d75ad1b75ec7449e8e1a7e4b9bb2,Fix bug#1220351 Create Cloud Administrator Guide,MERGED,2013-09-04 09:27:12.000000000,2013-09-05 13:10:48.000000000,2013-09-05 13:10:47.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 8047}]","[{'number': 1, 'created': '2013-09-04 09:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7bd7b4977871c3d060690b7749dcbde1d29c55eb', 'message': 'Fix bug#1220351 Create Cloud Administrator Guide\n\nCreate a new guide from the remains of Compute, Object Storage, Block Storage, and Networking Administration Guides left over from removal of install and config specific info.\n\nRemove gerunds from the headings based on the OS Docs Style, correct links refs, insert chapter and section tags.\n\nAuthor: Nermina Miller\n\nChange-Id: I21cf53e26c25d75ad1b75ec7449e8e1a7e4b9bb2\n'}, {'number': 2, 'created': '2013-09-04 10:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4390f430079efd5c19109157701567ad73244d08', 'message': 'Fix bug#1220351 Create Cloud Administrator Guide\n\nCreate a new guide from the remains of Compute, Object Storage, Block Storage, and Networking Administration Guides left over from removal of install and config specific info.\n\nRemove gerunds from the headings based on the OS Docs Style, correct links refs, insert chapter and section tags.\n\nAuthor: Nermina Miller\n\nChange-Id: I21cf53e26c25d75ad1b75ec7449e8e1a7e4b9bb2\n'}, {'number': 3, 'created': '2013-09-04 21:43:21.000000000', 'files': ['doc/src/docbkx/admin-guide-cloud/ch_blockstorage.xml', 'doc/src/docbkx/common/figures/FlatNetworkMultInterface.png', 'doc/src/docbkx/common/figures/Flavors-–-TGen-Cloud-Dashboard.png', 'doc/src/docbkx/common/figures/SCH_5003_V00_NUAC-Network_mode_KVM_LDAP_OpenStack.vsd', 'doc/src/docbkx/common/figures/SCH_5004_V00_NUAC-Network_mode_KVM_Flat_OpenStack.svg', 'doc/src/docbkx/common/figures/LaunchInstance.png', 'doc/src/docbkx/common/figures/instance-lifecycle.svg', 'doc/src/docbkx/common/figures/NOVA_compute_nodes.png', 'doc/src/docbkx/common/figures/NOVA_install_arch.svg', 'doc/src/docbkx/common/figures/cloudpipe/cloudpipe-viscosity-step4.jpg', 'doc/src/docbkx/common/figures/text6070-0.png', 'doc/src/docbkx/common/figures/cloudpipe/cloudpipe-viscosity-step2.jpg', 'doc/src/docbkx/common/figures/FlatNetworkSingleInterface.png', 'doc/src/docbkx/common/figures/cyberduck_swift_uploads.png', 'doc/src/docbkx/common/figures/MultiInterfaceOutbound_2.png', 'doc/src/docbkx/common/section_identity-troubleshooting.xml', 'doc/src/docbkx/admin-guide-cloud/ch_objectstorage.xml', 'doc/src/docbkx/common/figures/Security-Group.png', 'doc/src/docbkx/common/figures/SCH_5007_V00_NUAC-multi_nic_OpenStack.vsd', 'doc/src/docbkx/common/figures/dashboard-overview.png', 'doc/src/docbkx/admin-guide-cloud/section_rootwrap.xml', 'doc/src/docbkx/common/figures/MultiInterfaceOutbound_1.png', 'doc/src/docbkx/common/figures/cloudpipe/cloudpipe-viscosity-step3.jpg', 'doc/src/docbkx/common/figures/SCH_5003_V00_NUAC-Network_mode_KVM_LDAP_OpenStack.png', 'doc/src/docbkx/common/section_nova_cli_volumes.xml', 'doc/src/docbkx/common/figures/instance-life-1.png', 'doc/src/docbkx/common/figures/instance-life-2.png', 'doc/src/docbkx/common/figures/KeyPair.png', 'doc/src/docbkx/admin-guide-cloud/bk-admin-guide-cloud.xml', 'doc/src/docbkx/common/figures/SCH_5004_V00_NUAC-Network_mode_KVM_Flat_OpenStack.vsd', 'doc/src/docbkx/common/figures/ha-net.png', 'doc/src/docbkx/common/figures/swift_install_arch.svg', 'doc/src/docbkx/common/figures/Images.png', 'doc/src/docbkx/common/figures/SCH_5007_V00_NUAC-multi_nic_OpenStack-VLAN-manager.jpg', 'doc/src/docbkx/common/section_keystone-concepts.xml', 'doc/src/docbkx/common/figures/NOVA_ARCH.svg', 'doc/src/docbkx/common/figures/instance-life-3.png', 'doc/src/docbkx/common/section_dashboard_sessions.xml', 'doc/src/docbkx/common/figures/cloudpipe/cloudpipe-viscosity-step1.jpg', 'doc/src/docbkx/common/figures/NOVA_compute_nodes.svg', 'doc/src/docbkx/common/figures/cyberduck_swift_connection.png', 'doc/src/docbkx/common/figures/SCH_5005_V00_NUAC-Network_mode_XEN_Flat_OpenStack.svg', 'doc/src/docbkx/admin-guide-cloud/section_backup-block-storage-disks.xml', 'doc/src/docbkx/admin-guide-cloud/ch_networking.xml', 'doc/src/docbkx/common/figures/SCH_5007_V00_NUAC-multi_nic_OpenStack-Flat-DHCP-manager.jpg', 'doc/src/docbkx/admin-guide-cloud/ch_dashboard.xml', 'doc/src/docbkx/common/figures/NOVA_install_arch.png', 'doc/src/docbkx/common/figures/Login-–-OpenStack-Dashboard.png', 'doc/src/docbkx/common/figures/SingleInterfaceOutbound_1.png', 'doc/src/docbkx/admin-guide-cloud/section_adding-images.xml', 'doc/src/docbkx/admin-guide-cloud/section_multi_backend.xml', 'doc/src/docbkx/common/section_keystone_certificates-for-pki.xml', 'doc/src/docbkx/common/figures/flatdchp-net.jpg', 'doc/src/docbkx/admin-guide-cloud/section_volume-migration.xml', 'doc/src/docbkx/common/figures/SingleInterfaceOutbound_2.png', 'doc/src/docbkx/common/ch_getstart.xml', 'doc/src/docbkx/common/figures/XenApiFlatDHCPMultInterfaceHA.png', 'doc/src/docbkx/common/figures/SCH_5007_V00_NUAC-multi_nic_OpenStack-Flat-manager.jpg', 'doc/src/docbkx/common/figures/InstanceReady.png', 'doc/src/docbkx/common/figures/SCH_5005_V00_NUAC-Network_mode_XEN_Flat_OpenStack.vsd', 'doc/src/docbkx/common/figures/ha-net.jpg', 'doc/src/docbkx/common/figures/SCH_5003_V00_NUAC-Network_mode_KVM_LDAP_OpenStack.svg', 'doc/src/docbkx/admin-guide-cloud/pom.xml', 'doc/src/docbkx/common/figures/FlatNetworkSingleInterfaceAllInOne.png', 'doc/src/docbkx/common/figures/net-diagrams.pptx', 'doc/src/docbkx/common/figures/swift_install_arch.png', 'doc/src/docbkx/admin-guide-cloud/ch_compute.xml', 'doc/src/docbkx/admin-guide-cloud/section_troubleshoot-cinder.xml', 'doc/src/docbkx/common/figures/NOVA_ARCH.png', 'doc/src/docbkx/common/section_customize_flavors.xml', 'doc/src/docbkx/common/figures/XenApiVLANMultInterfaceHA.png'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2fcbd6e70c6dfc2143b0e7c889a548510b8aa08d', 'message': 'Fix bug#1220351 Create Cloud Administrator Guide\n\nCreate a new guide from the remains of Compute, Object Storage, Block Storage, and Networking Administration Guides left over from removal of install and config specific info.\n\nRemove gerunds from the headings based on the OS Docs Style, correct links refs, insert chapter and section tags.\n\nUpdate pom file to reflect the appropriate disqus registration\n\nUpdate section names for loose xi:include files\n\nMove figures to Common folder and update xrefs\n\nAuthor: Nermina Miller\n\nChange-Id: I21cf53e26c25d75ad1b75ec7449e8e1a7e4b9bb2\n'}]",6,45023,2fcbd6e70c6dfc2143b0e7c889a548510b8aa08d,12,5,3,8047,,,0,"Fix bug#1220351 Create Cloud Administrator Guide

Create a new guide from the remains of Compute, Object Storage, Block Storage, and Networking Administration Guides left over from removal of install and config specific info.

Remove gerunds from the headings based on the OS Docs Style, correct links refs, insert chapter and section tags.

Update pom file to reflect the appropriate disqus registration

Update section names for loose xi:include files

Move figures to Common folder and update xrefs

Author: Nermina Miller

Change-Id: I21cf53e26c25d75ad1b75ec7449e8e1a7e4b9bb2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/23/45023/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/common/section_keystone_certificates-for-pki.xml', 'doc/src/docbkx/common/section_identity-troubleshooting.xml', 'doc/src/docbkx/common/section_nova_cli_volumes.xml', 'doc/src/docbkx/common/section_keystone-concepts.xml', 'doc/src/docbkx/common/section_customize_flavors.xml', 'doc/src/docbkx/common/ch_getstart.xml']",6,7bd7b4977871c3d060690b7749dcbde1d29c55eb,bug/1220351, <title>Get started with OpenStack</title> <title>Logical architecture</title>, <title>Getting Started with OpenStack</title> <title>Logical Architecture</title>,11,11
openstack%2Fpython-openstackclient~master~I4363508f562f62b16c856bc072cdb4b37e37b418,openstack/python-openstackclient,master,I4363508f562f62b16c856bc072cdb4b37e37b418,Update tox.ini for new tox 1.6 config,MERGED,2013-09-04 19:47:13.000000000,2013-09-05 13:06:46.000000000,2013-09-05 13:06:45.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-09-04 19:47:13.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c8723ce175b48bdde016a6efb4945b6b3766080f', 'message': 'Update tox.ini for new tox 1.6 config\n\nChange-Id: I4363508f562f62b16c856bc072cdb4b37e37b418\n'}]",0,45108,c8723ce175b48bdde016a6efb4945b6b3766080f,6,3,1,970,,,0,"Update tox.ini for new tox 1.6 config

Change-Id: I4363508f562f62b16c856bc072cdb4b37e37b418
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/08/45108/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c8723ce175b48bdde016a6efb4945b6b3766080f,update-tox,minversion = 1.6skipdist = Trueusedevelop = True install_command = pip install -U {opts} {packages}commands = python setup.py test --coverage --testr-args='{posargs}',commands = python setup.py testr --coverage --testr-args='{posargs}',5,1
openstack%2Fmurano-deployment~release-0.2~I07b2562545e891490bdc6e2d41a804aad8f3ba7f,openstack/murano-deployment,release-0.2,I07b2562545e891490bdc6e2d41a804aad8f3ba7f,Folder for Murano Getting Started created.,MERGED,2013-09-04 10:52:50.000000000,2013-09-05 13:03:46.000000000,2013-09-05 13:03:46.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7562}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-09-04 10:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/97910abe499734e4f0643fa954a4a16fa9d78d92', 'message': 'Folder for Murano Getting Started created.\n\nChange-Id: I07b2562545e891490bdc6e2d41a804aad8f3ba7f\n'}, {'number': 2, 'created': '2013-09-04 11:07:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/9dd3532377aa4c4e7d0fb4a2063279260dcf3dcb', 'message': 'Folder for Murano Getting Started created.\n\nREADME updated.\n\nChange-Id: I07b2562545e891490bdc6e2d41a804aad8f3ba7f\n'}, {'number': 3, 'created': '2013-09-04 11:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/3b30a8595ac3b4bfa1d96a16f37418b59f3c1ce2', 'message': 'Folder for Murano Getting Started created.\n\n* README updated.\n* Files to start Vagrant box added.\n\nChange-Id: I07b2562545e891490bdc6e2d41a804aad8f3ba7f\n'}, {'number': 4, 'created': '2013-09-04 11:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/f7d2b9ff542cf379de4b2aadbb088f3b5ad98ed9', 'message': ""Folder for Murano Getting Started created.\n\n* README updated.\n* Files to start Vagrant box added.\n* devstack's files added.\n* Permissions on local.sh changed.\n\nChange-Id: I07b2562545e891490bdc6e2d41a804aad8f3ba7f\n""}, {'number': 5, 'created': '2013-09-04 11:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/e3d07605cf301e31f1937437313af51f69cda984', 'message': ""Folder for Murano Getting Started created.\n\n* README updated.\n* Files to start Vagrant box added.\n* devstack's files added.\n* Permissions on local.sh changed.\n* devstack's files updated.\n\nChange-Id: I07b2562545e891490bdc6e2d41a804aad8f3ba7f\n""}, {'number': 6, 'created': '2013-09-04 11:50:05.000000000', 'files': ['getting-started/launch-the-box.sh', 'getting-started/localrc', 'getting-started/local.sh', 'getting-started/README.rst', 'getting-started/lab-binding.rc', 'getting-started/Vagrantfile', 'getting-started/provision.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/2dc524f73ddc8d978b94b787b34b98d2a3fa7ec8', 'message': ""Folder for Murano Getting Started created.\n\n* README updated.\n* Files to start Vagrant box added.\n* devstack's files added.\n* Permissions on local.sh changed.\n* devstack's files updated.\n\nChange-Id: I07b2562545e891490bdc6e2d41a804aad8f3ba7f\n""}]",0,45033,2dc524f73ddc8d978b94b787b34b98d2a3fa7ec8,16,4,6,7562,,,0,"Folder for Murano Getting Started created.

* README updated.
* Files to start Vagrant box added.
* devstack's files added.
* Permissions on local.sh changed.
* devstack's files updated.

Change-Id: I07b2562545e891490bdc6e2d41a804aad8f3ba7f
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/33/45033/4 && git format-patch -1 --stdout FETCH_HEAD,['getting-started/README.rst'],1,97910abe499734e4f0643fa954a4a16fa9d78d92,,Murano Getting Started ====================== This folder contains files mentioned in Murano Getting Started guide. SEE ALSO ======== * `Murano <http://murano.mirantis.com>`__ ,,9,0
openstack%2Fneutron~master~I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a,openstack/neutron,master,I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a,Implement MidoNet Neutron plugin for Havana,MERGED,2013-08-24 00:18:06.000000000,2013-09-05 12:45:58.000000000,2013-09-05 12:45:57.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 841}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 4146}, {'_account_id': 4726}, {'_account_id': 5948}, {'_account_id': 6676}, {'_account_id': 6788}]","[{'number': 1, 'created': '2013-08-24 00:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/85b7ec82ded7485b09c00c463d924ab9a8fab157', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}, {'number': 2, 'created': '2013-08-26 10:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/741430b202fb83d700d02163f72c44db6df34b07', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}, {'number': 3, 'created': '2013-08-26 14:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee62b6ef728ea750ef298dc8233726cc57bdea8d', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}, {'number': 4, 'created': '2013-08-26 15:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd38692a8e38f0b047b8fe7fa0600acf66bec3c6', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}, {'number': 5, 'created': '2013-08-27 10:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e1ea1c3db56cf5c41a738e1b0d4bcf774c6b506', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}, {'number': 6, 'created': '2013-08-28 18:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/77f6d3e75eb54ef1f5b42d2c6c1bd1865e0e38fa', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nblueprint https://blueprints.launchpad.net/neutron/+spec/midonet-plugin-havana\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}, {'number': 7, 'created': '2013-08-29 08:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff31bf997449ece97b51550954f5c249575f0908', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nblueprint https://blueprints.launchpad.net/neutron/+spec/midonet-plugin-havana\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}, {'number': 8, 'created': '2013-08-29 10:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/de74685656eeae6de1e163f2cf14b49372fe8538', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nblueprint midonet-plugin-havana\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}, {'number': 9, 'created': '2013-08-31 15:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/181f3297f1f7b0a0df2e29a6e9bb7274a87a9462', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nblueprint midonet-plugin-havana\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}, {'number': 10, 'created': '2013-09-03 09:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/29bfeba3762d9d628aeb8efdfd1d2112a675ad2c', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nblueprint midonet-plugin-havana\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}, {'number': 11, 'created': '2013-09-03 13:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/204c9c31674051132ca544f721ae5c7d8adaa6b3', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nblueprint midonet-plugin-havana\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}, {'number': 12, 'created': '2013-09-03 16:39:42.000000000', 'files': ['neutron/plugins/midonet/plugin.py', 'neutron/plugins/midonet/agent/__init__.py', 'etc/neutron/plugins/midonet/midonet.ini', 'neutron/plugins/midonet/common/net_util.py', 'neutron/plugins/midonet/common/__init__.py', 'neutron/tests/unit/midonet/test_midonet_lib.py', 'neutron/plugins/midonet/midonet_lib.py', 'neutron/plugins/midonet/common/config.py', 'neutron/tests/unit/midonet/mock_lib.py', 'neutron/tests/unit/midonet/test_midonet_driver.py', 'neutron/plugins/midonet/agent/midonet_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0253740a23d5cb58db539230dd8513b2f845afe1', 'message': 'Implement MidoNet Neutron plugin for Havana\n\nImplement L2, L3, security groups, metadata server support for\nMidoNet Neutron plugin for Havana.\n\nblueprint midonet-plugin-havana\n\nChange-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a\n'}]",101,43558,0253740a23d5cb58db539230dd8513b2f845afe1,68,10,12,6788,,,0,"Implement MidoNet Neutron plugin for Havana

Implement L2, L3, security groups, metadata server support for
MidoNet Neutron plugin for Havana.

blueprint midonet-plugin-havana

Change-Id: I0dd1a2ca17d760443c4c7a464a66b6d0a2cf194a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/58/43558/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/midonet/plugin.py', 'neutron/plugins/midonet/agent/__init__.py', 'neutron/plugins/midonet/midonet_lib.py', 'neutron/tests/unit/midonet/test_midonet_lib.py', 'neutron/tests/unit/midonet/mock_lib.py', 'neutron/plugins/midonet/agent/midonet_agent.py']",6,85b7ec82ded7485b09c00c463d924ab9a8fab157,bp/midonet-plugin-havana,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (C) 2013 Midokura PTE LTD # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Rossella Sblendido, Midokura Japan KK # @author: Tomoe Sugihara, Midokura Japan KK # @author: Ryu Ishimoto, Midokura Japan KK from midonetclient import api from oslo.config import cfg from webob import exc as w_exc from neutron.agent.linux import dhcp from neutron.agent.linux import interface from neutron.agent.linux import ip_lib from neutron.openstack.common import log as logging from neutron.plugins.midonet import config # noqa LOG = logging.getLogger(__name__) class DhcpNoOpDriver(dhcp.DhcpBase): @classmethod def existing_dhcp_networks(cls, conf, root_helper): """"""Return a list of existing networks ids that we have configs for."""""" return [] @classmethod def check_version(cls): """"""Execute version checks on DHCP server."""""" return float(1) def enable(self): """"""Enables DHCP for this network."""""" self.device_delegate.setup(self.network, reuse_existing=True) def disable(self, retain_port=False): """"""Disable DHCP for this network."""""" pass def active(self): """"""Boolean representing the running state of the DHCP server."""""" return True def release_lease(self, mac_address, removed_ips): """"""Release a DHCP lease."""""" pass def reload_allocations(self): """"""Force the DHCP server to reload the assignment database."""""" pass def spawn_process(self, mac_address, removed_ips): pass midonet_interface_driver_opts = [ cfg.StrOpt('midonet_host_uuid_path', default='/etc/midolman/host_uuid.properties', help='path to midonet host uuid file'), ] cfg.CONF.register_opts(midonet_interface_driver_opts) class MidonetInterfaceDriver(interface.LinuxInterfaceDriver): def __init__(self, conf): super(MidonetInterfaceDriver, self).__init__(conf) # Read config values midonet_conf = conf.MIDONET midonet_uri = midonet_conf.midonet_uri admin_user = midonet_conf.username admin_pass = midonet_conf.password admin_project_id = midonet_conf.project_id self.mido_api = api.MidonetApi(midonet_uri, admin_user, admin_pass, project_id=admin_project_id) def _get_host_uuid(self): """""" Get MidoNet host id from host_uuid.properties file. """""" f = open(cfg.CONF.midonet_host_uuid_path) lines = f.readlines() host_uuid = filter(lambda x: x.startswith('host_uuid='), lines)[0].strip()[len('host_uuid='):] return host_uuid def plug(self, network_id, port_id, device_name, mac_address, bridge=None, namespace=None, prefix=None): """""" This method is called by the Dhcp agent or by the L3 agent when a new network is created """""" if not ip_lib.device_exists(device_name, self.root_helper, namespace=namespace): ip = ip_lib.IPWrapper(self.root_helper) tap_name = device_name.replace(prefix or 'tap', 'tap') # Create ns_dev in a namespace if one is configured. root_dev, ns_dev = ip.add_veth(tap_name, device_name, namespace2=namespace) ns_dev.link.set_address(mac_address) # Add an interface created by ovs to the namespace. namespace_obj = ip.ensure_namespace(namespace) namespace_obj.add_device_to_namespace(ns_dev) ns_dev.link.set_up() root_dev.link.set_up() vport_id = port_id host_dev_name = device_name # create if-vport mapping. host_uuid = self._get_host_uuid() try: host = self.mido_api.get_host(host_uuid) except w_exc.HTTPError as e: LOG.error('Failed to create a if-vport mapping on host=%s', host_uuid) raise e try: host.add_host_interface_port().port_id(vport_id) \ .interface_name(host_dev_name).create() except w_exc.HTTPError as e: LOG.warn('Faild binding vport=%r to device=%r', vport_id, host_dev_name) else: LOG.warn(_(""Device %s already exists""), device_name) def unplug(self, device_name, bridge=None, namespace=None, prefix=None): # the port will be deleted by the dhcp agent that will call the plugin device = ip_lib.IPDevice(device_name, self.root_helper, namespace) device.link.delete() LOG.debug(_(""Unplugged interface '%s'""), device_name) ip_lib.IPWrapper( self.root_helper, namespace).garbage_collect_namespace() ",,1484,1200
openstack%2Fnova~master~I69f47351fe83e54775e0147a27450c21196f9bfd,openstack/nova,master,I69f47351fe83e54775e0147a27450c21196f9bfd,XenAPI: Allow 10GB overhead on VHD file check size,MERGED,2013-08-10 03:26:37.000000000,2013-09-05 12:33:29.000000000,2013-09-05 12:33:26.000000000,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2835}, {'_account_id': 6735}, {'_account_id': 7802}]","[{'number': 1, 'created': '2013-08-10 03:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a1a2785642391b1d028a1d309c8b7170e69a436', 'message': 'XenAPI: Allow 40% overhead on VHD file check size\n\n_check_vdi_size call does not account for inevitable VHD growth, where\nthe chain grows past the root_gb size. This allows for up to a 40%\noverhead so that builds can go through.\n\nChange-Id: I69f47351fe83e54775e0147a27450c21196f9bfd\n'}, {'number': 2, 'created': '2013-08-20 19:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a11b00710f1e5b7e77ff750a3344826822a9cf79', 'message': 'XenAPI: Allow 10GB overhead on VHD file check size\n\n_check_vdi_size call does not account for VHD file overhead, where the chain\ngrows slightly past the root_gb size. This allows for up to a 10GB overhead so\nthat builds can go through.\n\nChange-Id: I69f47351fe83e54775e0147a27450c21196f9bfd\n'}, {'number': 3, 'created': '2013-08-21 23:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f79fb36fc934a61b246f76820cbb214f2a105192', 'message': 'XenAPI: Allow 10GB overhead on VHD file check size\n\n_check_vdi_size call does not account for VHD file overhead, where the chain\ngrows slightly past the root_gb size. This allows for up to a 10GB overhead so\nthat builds can go through.\n\nChange-Id: I69f47351fe83e54775e0147a27450c21196f9bfd\n'}, {'number': 4, 'created': '2013-08-22 17:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39f8a2ebb04836be5ccd0b367c29a1a9d7807f22', 'message': 'XenAPI: Allow 10GB overhead on VHD file check size\n\n_check_vdi_size call does not account for VHD file overhead, where the chain\ngrows slightly past the root_gb size. This allows for up to a 10GB overhead so\nthat builds can go through.\n\nChange-Id: I69f47351fe83e54775e0147a27450c21196f9bfd\n'}, {'number': 5, 'created': '2013-08-23 17:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c61a443e209a0b005e07c0504d860943fc24993', 'message': 'XenAPI: Allow 10GB overhead on VHD file check size\n\n_check_vdi_size call does not account for VHD overhead, where the chain grows\nslightly past the root_gb size, both from file format overhead and from\nmultiple VHDs with redundant blocks in a single chain. This allows for up to a\n10GB overhead so that these otherwise legitimate builds can go through.\n\nFixes: bug #1216042\n\nChange-Id: I69f47351fe83e54775e0147a27450c21196f9bfd\n'}, {'number': 6, 'created': '2013-09-02 18:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/174bab7c4ce0d2579c3dcba5829ceb0a5e0b6a29', 'message': ""XenAPI: Allow 10GB overhead on VHD file check size\n\n_check_vdi_size in vm_utils.py does not account for VHD overhead. Builds\nwill fail if on disk VHD file usage is even slightly greater than the\nroot_gb partition allocation size to the VM.\n\nWith VHDs, VM root disks usually come from two-file chains (one, if a\nsnapshot has never been taken or it was not a fast copy build). There is\na mild file format overhead involved and additionally, once a block has\nbeen written to, the space is never freed or compressed from the VHD\nfile. The two VHD files in the chain may have overlapping blocks adding\nto the total amount of overhead over the actual utilization. This can\nresult in a VM's partition internally not even being full, with the\nexternal VHD File chain being even just a few MB larger than the allowed\nsize. Building from an image of such a VM will fail due to this check\nexpecting external/on-disk usage to never be greater than the internal\npartion size granted.\n\nThis patch adds a 10GB tolerance which should fix almost all cases of\nbuild failures due to this bug.\n\nFixes: bug #1216042\n\nChange-Id: I69f47351fe83e54775e0147a27450c21196f9bfd\n""}, {'number': 7, 'created': '2013-09-03 20:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24288cb7850ab23c3ed80e02a06f5ac85e0280cb', 'message': ""XenAPI: Allow 10GB overhead on VHD file check size\n\n_check_vdi_size in vm_utils.py does not account for VHD overhead. Builds\nwill fail if on disk VHD file usage is even slightly greater than the\nroot_gb partition allocation size to the VM.\n\nWith VHDs, VM root disks usually come from two-file chains (one, if a\nsnapshot has never been taken or it was not a fast copy build). There is\na mild file format overhead involved and additionally, once a block has\nbeen written to, the space is never freed or compressed from the VHD\nfile. The two VHD files in the chain may have overlapping blocks adding\nto the total amount of overhead over the actual utilization. This can\nresult in a VM's partition internally not even being full, with the\nexternal VHD File chain being even just a few MB larger than the allowed\nsize. Building from an image of such a VM will fail due to this check\nexpecting external/on-disk usage to never be greater than the internal\npartion size granted.\n\nThis patch adds a 10GB tolerance which should fix almost all cases of\nbuild failures due to this bug.\n\nFixes: bug #1216042\n\nChange-Id: I69f47351fe83e54775e0147a27450c21196f9bfd\n""}, {'number': 8, 'created': '2013-09-04 18:43:45.000000000', 'files': ['nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/xenapi/test_vm_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9dc6784340117e469f46d2c3a2c5717b4f5a6d60', 'message': ""XenAPI: Allow 10GB overhead on VHD file check size\n\n_check_vdi_size in vm_utils.py does not account for VHD overhead. Builds\nwill fail if on disk VHD file usage is even slightly greater than the\nroot_gb partition allocation size to the VM.\n\nWith VHDs, VM root disks usually come from two-file chains (one, if a\nsnapshot has never been taken or it was not a fast copy build). There is\na mild file format overhead involved and additionally, once a block has\nbeen written to, the space is never freed or compressed from the VHD\nfile. The two VHD files in the chain may have overlapping blocks adding\nto the total amount of overhead over the actual utilization. This can\nresult in a VM's partition internally not even being full, with the\nexternal VHD File chain being even just a few MB larger than the allowed\nsize. Building from an image of such a VM will fail due to this check\nexpecting external/on-disk usage to never be greater than the internal\npartion size granted.\n\nThis patch adds a 10GB tolerance which should fix almost all cases of\nbuild failures due to this bug.\n\nFixes: bug #1216042\n\nChange-Id: I69f47351fe83e54775e0147a27450c21196f9bfd\n""}]",10,41229,9dc6784340117e469f46d2c3a2c5717b4f5a6d60,61,9,8,7802,,,0,"XenAPI: Allow 10GB overhead on VHD file check size

_check_vdi_size in vm_utils.py does not account for VHD overhead. Builds
will fail if on disk VHD file usage is even slightly greater than the
root_gb partition allocation size to the VM.

With VHDs, VM root disks usually come from two-file chains (one, if a
snapshot has never been taken or it was not a fast copy build). There is
a mild file format overhead involved and additionally, once a block has
been written to, the space is never freed or compressed from the VHD
file. The two VHD files in the chain may have overlapping blocks adding
to the total amount of overhead over the actual utilization. This can
result in a VM's partition internally not even being full, with the
external VHD File chain being even just a few MB larger than the allowed
size. Building from an image of such a VM will fail due to this check
expecting external/on-disk usage to never be greater than the internal
partion size granted.

This patch adds a 10GB tolerance which should fix almost all cases of
build failures due to this bug.

Fixes: bug #1216042

Change-Id: I69f47351fe83e54775e0147a27450c21196f9bfd
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/41229/5 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/xenapi/vm_utils.py'],1,9a1a2785642391b1d028a1d309c8b7170e69a436,bug/1216042, if size * 1.4 > allowed_size:, if size > allowed_size:,1,1
openstack%2Fnova~master~I5a562253788f93b932ccd99bd1dc6630444bd430,openstack/nova,master,I5a562253788f93b932ccd99bd1dc6630444bd430,Fix the multi-instance quota message,MERGED,2013-08-12 15:49:20.000000000,2013-09-05 12:32:14.000000000,2013-09-05 12:32:12.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1528}, {'_account_id': 1561}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-08-12 15:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f7fee7e6a7fe4a77df53a06d13ca38025727ece', 'message': 'Fix the multi-instance quota message\n\nMake sure that when spawning multiple instance, the quota exceeded\nerror still makes sense. Instead of reporting min_count (1) as the\nrequested number, report ""between min_count and max_count"".\n\nFixes bug 1211347\n\nChange-Id: I5a562253788f93b932ccd99bd1dc6630444bd430\n'}, {'number': 2, 'created': '2013-08-12 17:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9b12b6657bc3d6b9c018e0a82a5695fce1571f4', 'message': 'Fix the multi-instance quota message\n\nMake sure that when spawning multiple instance, the quota exceeded\nerror still makes sense. Instead of reporting min_count (1) as the\nrequested number, report ""between min_count and max_count"".\n\nFixes bug 1211347\n\nChange-Id: I5a562253788f93b932ccd99bd1dc6630444bd430\n'}, {'number': 3, 'created': '2013-08-27 14:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58778278bc115ff1d64970dc40df515bb33255e4', 'message': 'Fix the multi-instance quota message\n\nMake sure that when spawning multiple instance, the quota exceeded\nerror still makes sense. Instead of reporting min_count (1) as the\nrequested number, report ""between min_count and max_count"".\n\nFixes bug 1211347\n\nChange-Id: I5a562253788f93b932ccd99bd1dc6630444bd430\n'}, {'number': 4, 'created': '2013-08-30 18:05:20.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8c169aa41b9fe68c1f5b426d656a283bd982099b', 'message': 'Fix the multi-instance quota message\n\nMake sure that when spawning multiple instance, the quota exceeded\nerror still makes sense. Instead of reporting min_count (1) as the\nrequested number, report ""between min_count and max_count"".\n\nFixes bug 1211347\n\nChange-Id: I5a562253788f93b932ccd99bd1dc6630444bd430\n'}]",2,41453,8c169aa41b9fe68c1f5b426d656a283bd982099b,21,6,4,1528,,,0,"Fix the multi-instance quota message

Make sure that when spawning multiple instance, the quota exceeded
error still makes sense. Instead of reporting min_count (1) as the
requested number, report ""between min_count and max_count"".

Fixes bug 1211347

Change-Id: I5a562253788f93b932ccd99bd1dc6630444bd430
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/41453/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,9f7fee7e6a7fe4a77df53a06d13ca38025727ece,bug/1211347," if min_count == max_count: requested_instances_text = str(min_count) else: requested_instances_text = _(""between %s and %s"") % (min_count, max_count) "" tried to run %(count)s instances. %(msg)s""), 'count': requested_instances_text, 'msg': msg}) requested = dict(instances=requested_instances_text, cores=req_cores, ram=req_ram)"," "" tried to run %(min_count)s instances. %(msg)s""), 'min_count': min_count, 'msg': msg}) requested = dict(instances=min_count, cores=req_cores, ram=req_ram)",9,3
openstack%2Fglance~master~I4c456bbde4314b63a8026d849b23f29cd848a8f6,openstack/glance,master,I4c456bbde4314b63a8026d849b23f29cd848a8f6,Fixes bug #1213197,ABANDONED,2013-09-05 12:18:22.000000000,2013-09-05 12:19:07.000000000,,[],"[{'number': 1, 'created': '2013-09-05 12:18:22.000000000', 'files': ['glance/cmd/manage.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/1d0ee36984f9a2c2d476ec135539e3f4b05b5cd8', 'message': 'Fixes bug #1213197\n\nChange-Id: I4c456bbde4314b63a8026d849b23f29cd848a8f6\n'}]",0,45221,1d0ee36984f9a2c2d476ec135539e3f4b05b5cd8,1,0,1,7531,,,0,"Fixes bug #1213197

Change-Id: I4c456bbde4314b63a8026d849b23f29cd848a8f6
",git fetch https://review.opendev.org/openstack/glance refs/changes/21/45221/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/cmd/manage.py'],1,1d0ee36984f9a2c2d476ec135539e3f4b05b5cd8,bp/remove-sensitive-data-from-locations,,,1,0
openstack%2Fzaqar~master~Icde4ce493a76ef145e99300b67d8344d5092e38d,openstack/zaqar,master,Icde4ce493a76ef145e99300b67d8344d5092e38d,fix: Claim can return 404,MERGED,2013-08-30 19:53:43.000000000,2013-09-05 12:13:29.000000000,2013-09-05 12:13:29.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 6944}, {'_account_id': 6971}, {'_account_id': 7498}]","[{'number': 1, 'created': '2013-08-30 19:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/2bed8c0b72b4dc7bb7e51963d85d8b2f163d9f20', 'message': 'fix: Claim can return 404\n\nThis patch changes the way creating a claim behaves when the\nqueue does not exist. Instead of returning 404, it returns\n204, meaning the claim was not able to find any messages to\nclaim.\n\nThis was done for two reasons:\n\n1. For eventually-consistent backends, a brand new queue may\nnot appear to exist, so this new semantic allows the driver\nto just try to grab some messages without checking first\nwhether the queue ""exists"".\n2. For backends like MongoDB that require an extra check to\ndetermine whether a queue exists, this removes an extra\nround trip to the DB in order to perform the operation.\n\nNote that the SQLite driver was updated in order to be\nconsistent with the new behavior.\n\nChange-Id: Icde4ce493a76ef145e99300b67d8344d5092e38d\nCloses-Bug: #1218990\n'}, {'number': 2, 'created': '2013-08-30 20:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fee8c0f98fd9be2abad98c12c595a251c29e453a', 'message': 'fix: Claim can return 404\n\nThis patch changes the way creating a claim behaves when the\nqueue does not exist. Instead of returning 404, it returns\n204, meaning the claim was not able to find any messages to\nclaim.\n\nThis was done for two reasons:\n\n1. For eventually-consistent backends, a brand new queue may\nnot appear to exist, so this new semantic allows the driver\nto just try to grab some messages without checking first\nwhether the queue ""exists"".\n2. For backends like MongoDB that require an extra check to\ndetermine whether a queue exists, this removes an extra\nround trip to the DB in order to perform the operation.\n\nNote that the SQLite driver was updated in order to be\nconsistent with the new behavior.\n\nChange-Id: Icde4ce493a76ef145e99300b67d8344d5092e38d\nCloses-Bug: #1218990\n'}, {'number': 3, 'created': '2013-09-04 14:24:32.000000000', 'files': ['marconi/storage/sqlite/claims.py', 'marconi/tests/transport/wsgi/test_claims.py', 'marconi/storage/mongodb/claims.py', 'marconi/transport/wsgi/claims.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c1a564b4444a557cda037e57d7766b7b86661b4a', 'message': 'fix: Claim can return 404\n\nThis patch changes the way creating a claim behaves when the\nqueue does not exist. Instead of returning 404, it returns\n204, meaning the claim was not able to find any messages to\nclaim.\n\nThis was done for two reasons:\n\n1. For eventually-consistent backends, a brand new queue may\nnot appear to exist, so this new semantic allows the driver\nto just try to grab some messages without checking first\nwhether the queue ""exists"".\n2. For backends like MongoDB that require an extra check to\ndetermine whether a queue exists, this removes an extra\nround trip to the DB in order to perform the operation.\n\nNote that the SQLite driver was updated in order to be\nconsistent with the new behavior.\n\nChange-Id: Icde4ce493a76ef145e99300b67d8344d5092e38d\nPartial-Bug: #1218990\n'}]",1,44536,c1a564b4444a557cda037e57d7766b7b86661b4a,14,7,3,6427,,,0,"fix: Claim can return 404

This patch changes the way creating a claim behaves when the
queue does not exist. Instead of returning 404, it returns
204, meaning the claim was not able to find any messages to
claim.

This was done for two reasons:

1. For eventually-consistent backends, a brand new queue may
not appear to exist, so this new semantic allows the driver
to just try to grab some messages without checking first
whether the queue ""exists"".
2. For backends like MongoDB that require an extra check to
determine whether a queue exists, this removes an extra
round trip to the DB in order to perform the operation.

Note that the SQLite driver was updated in order to be
consistent with the new behavior.

Change-Id: Icde4ce493a76ef145e99300b67d8344d5092e38d
Partial-Bug: #1218990
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/36/44536/3 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/storage/sqlite/claims.py', 'marconi/tests/transport/wsgi/test_claims.py', 'marconi/storage/mongodb/claims.py', 'marconi/transport/wsgi/claims.py']",4,2bed8c0b72b4dc7bb7e51963d85d8b2f163d9f20,bug/1218990,, except storage_exceptions.DoesNotExist: raise falcon.HTTPNotFound() ,6,9
openstack%2Fhorizon~master~I6ad2704100447c5a3be12c2ebeec824726e3bd0b,openstack/horizon,master,I6ad2704100447c5a3be12c2ebeec824726e3bd0b,PEP8 E121 has been resolved,MERGED,2013-09-05 07:16:57.000000000,2013-09-05 12:07:18.000000000,2013-09-05 12:07:18.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 4264}, {'_account_id': 6835}]","[{'number': 1, 'created': '2013-09-05 07:16:57.000000000', 'files': ['openstack_dashboard/dashboards/project/networks/subnets/tables.py', 'horizon/management/commands/startdash.py', 'openstack_dashboard/dashboards/admin/instances/tests.py', 'openstack_dashboard/dashboards/project/networks/views.py', 'openstack_dashboard/dashboards/admin/networks/ports/forms.py', 'openstack_dashboard/dashboards/project/databases/tables.py', 'openstack_dashboard/dashboards/admin/flavors/workflows.py', 'openstack_dashboard/test/helpers.py', 'horizon/management/commands/startpanel.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/forms.py', 'openstack_dashboard/dashboards/admin/projects/views.py', 'openstack_dashboard/dashboards/project/instances/workflows/resize_instance.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/tests.py', 'openstack_dashboard/test/test_data/keystone_data.py', 'openstack_dashboard/dashboards/project/containers/views.py', 'openstack_dashboard/dashboards/admin/users/tables.py', 'openstack_dashboard/dashboards/project/access_and_security/security_groups/forms.py', 'tox.ini', 'openstack_dashboard/dashboards/project/instances/views.py', 'openstack_dashboard/api/nova.py', 'openstack_dashboard/dashboards/project/volumes/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ec727ac39426c2a6be70a7c9cf75c00e4ae0c91c', 'message': 'PEP8 E121 has been resolved\n\nChange-Id: I6ad2704100447c5a3be12c2ebeec824726e3bd0b\nPartial-Bug: #1085346\n'}]",0,45182,ec727ac39426c2a6be70a7c9cf75c00e4ae0c91c,6,4,1,7980,,,0,"PEP8 E121 has been resolved

Change-Id: I6ad2704100447c5a3be12c2ebeec824726e3bd0b
Partial-Bug: #1085346
",git fetch https://review.opendev.org/openstack/horizon refs/changes/82/45182/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/networks/subnets/tables.py', 'horizon/management/commands/startdash.py', 'openstack_dashboard/dashboards/admin/instances/tests.py', 'openstack_dashboard/dashboards/project/networks/views.py', 'openstack_dashboard/dashboards/admin/networks/ports/forms.py', 'openstack_dashboard/dashboards/project/databases/tables.py', 'openstack_dashboard/dashboards/admin/flavors/workflows.py', 'openstack_dashboard/test/helpers.py', 'horizon/management/commands/startpanel.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/forms.py', 'openstack_dashboard/dashboards/admin/projects/views.py', 'openstack_dashboard/dashboards/project/instances/workflows/resize_instance.py', 'openstack_dashboard/dashboards/project/images_and_snapshots/tests.py', 'openstack_dashboard/test/test_data/keystone_data.py', 'openstack_dashboard/dashboards/project/containers/views.py', 'openstack_dashboard/dashboards/admin/users/tables.py', 'openstack_dashboard/dashboards/project/access_and_security/security_groups/forms.py', 'tox.ini', 'openstack_dashboard/dashboards/project/instances/views.py', 'openstack_dashboard/api/nova.py', 'openstack_dashboard/dashboards/project/volumes/forms.py']",21,ec727ac39426c2a6be70a7c9cf75c00e4ae0c91c,bug/1085346," snapshot_source = forms.ChoiceField( label=_(""Use snapshot as a source""), widget=fields.SelectWidget( attrs={'class': 'snapshot-selector'}, data_attrs=('size', 'display_name'), transform=lambda x: (""%s (%sGB)"" % (x.display_name, x.size))), required=False) image_source = forms.ChoiceField( label=_(""Use image as a source""), widget=fields.SelectWidget( attrs={'class': 'image-selector'}, data_attrs=('size', 'name'), transform=lambda x: (""%s (%s)"" % (x.name, filesizeformat(x.bytes)))), required=False)"," snapshot_source = forms.ChoiceField(label=_(""Use snapshot as a source""), widget=fields.SelectWidget( attrs={'class': 'snapshot-selector'}, data_attrs=('size', 'display_name'), transform=lambda x: (""%s (%sGB)"" % (x.display_name, x.size))), required=False) image_source = forms.ChoiceField(label=_(""Use image as a source""), widget=fields.SelectWidget( attrs={'class': 'image-selector'}, data_attrs=('size', 'name'), transform=lambda x: (""%s (%s)"" % (x.name, filesizeformat(x.bytes)))), required=False)",179,177
openstack%2Fneutron~master~I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d,openstack/neutron,master,I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d,Iptables metering driver,MERGED,2013-07-12 11:06:51.000000000,2013-09-05 12:07:10.000000000,2013-09-05 12:07:09.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1580}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 7141}]","[{'number': 1, 'created': '2013-07-12 11:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/945f00f41900c97204d5463c7fdced589b8b1505', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 2, 'created': '2013-07-12 15:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0fab60ed5a025899c70c9af5917c515f94a020f6', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 3, 'created': '2013-07-15 14:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6833eefec9143d0d5543fb9f884157f6accdadbf', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 4, 'created': '2013-07-15 14:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/526b2b78230041a750b89c9c26a85539e2c82aee', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 5, 'created': '2013-07-15 14:51:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b40877585036c90d2a804e8897659b5ea2d962a', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 6, 'created': '2013-07-15 14:51:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b0cecb7c88574b3f2c63a0b9788ee4c33017b69a', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 7, 'created': '2013-07-25 09:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f14e4b23150ba60541d0a9675487383dd6112954', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 8, 'created': '2013-07-25 10:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1357841746ad66fd4f9475f72a477906762b4c00', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 9, 'created': '2013-08-12 11:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f9b9d08306d9a63fb1e4af4ed039ec850cb7731', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 10, 'created': '2013-08-12 12:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a17d28b840f974e0e9548249fc3ac8b3a1d00e6', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 11, 'created': '2013-08-12 13:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0234646ac000c735d608c16115b7311e3222981b', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 12, 'created': '2013-08-14 11:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b49ad2316715192c1b22ad0c6825a2f2882a3216', 'message': 'Iptables metering drivers\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 13, 'created': '2013-08-26 17:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d4770e8bad5949ab518d035786e0ac86cffee3e', 'message': 'Iptables metering driver\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 14, 'created': '2013-08-26 19:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/02e15818db4b42f7d4f09677ce01a5dae8bc442d', 'message': 'Iptables metering driver\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 15, 'created': '2013-09-02 09:09:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee9930af1c9523997e751236b31d9b5bf39b77d3', 'message': 'Iptables metering driver\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}, {'number': 16, 'created': '2013-09-02 10:39:51.000000000', 'files': ['etc/metering_agent.ini', 'neutron/tests/unit/services/metering/drivers/__init__.py', 'neutron/tests/unit/services/metering/drivers/test_iptables_driver.py', 'neutron/services/metering/drivers/iptables/iptables_driver.py', 'neutron/services/metering/drivers/iptables/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e19178e1469abb015fe0af8275c032b6e38b0112', 'message': 'Iptables metering driver\n\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d\n'}]",43,36813,e19178e1469abb015fe0af8275c032b6e38b0112,70,10,16,7141,,,0,"Iptables metering driver

this is a part of the blueprint bandwidth-router-measurement

Change-Id: I37e4dc5abeaca4e13b32155bb7e2f07883ef9b2d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/36813/16 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/constants.py', 'neutron/tests/unit/services/metering/drivers/__init__.py', 'neutron/tests/unit/services/metering/drivers/test_iptables_driver.py', 'neutron/services/metering/drivers/iptables/iptables_driver.py', 'neutron/services/metering/drivers/iptables/__init__.py']",5,945f00f41900c97204d5463c7fdced589b8b1505,review/sylvain_afchain/bp/bandwidth-router-measurement-l3,"# Copyright (C) 2013 eNovance SAS <licensing@enovance.com> # # Author: Sylvain Afchain <sylvain.afchain@enovance.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",,519,0
openstack%2Fneutron~master~I6485d1239085e46398126c81e674e399952a4597,openstack/neutron,master,I6485d1239085e46398126c81e674e399952a4597,Add method to get iptables traffic counters,MERGED,2013-07-06 16:06:39.000000000,2013-09-05 12:07:01.000000000,2013-09-05 12:07:01.000000000,"[{'_account_id': 3}, {'_account_id': 107}, {'_account_id': 308}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1206}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 2166}, {'_account_id': 2583}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 7141}]","[{'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/966a1f79319e9a634671620b5f727e11f059fb67', 'message': 'Add method to get iptables traffic counters\n\nAdd a method to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d3052041d0d772dd3818dd4e46c80b5e692eb09d', 'message': 'Add method to get iptables traffic counters\n\nAdd a method to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1985b74db44802d7320b2dc43ace9a0b0a9f1462', 'message': 'Add method to get iptables traffic counters\n\nAdd a method to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 4, 'created': '2013-07-09 15:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/409d5bb8c42bc3d9b3ac96883d22f496e99c9d17', 'message': 'Add method to get iptables traffic counters\n\nAdd a method to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 5, 'created': '2013-07-11 16:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b38180959be7feeb2cb94118ad4148f6f5fa1f8', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 6, 'created': '2013-07-15 08:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e41dae4035676e5a221a5c73d18c2de3ad4fc12', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 7, 'created': '2013-07-15 12:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c5adb9a583536a645a55446b8ea388037cbb1b5', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 8, 'created': '2013-07-15 12:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3acf2ff7fe92962c6506aff659d2f9c20a0fb726', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 9, 'created': '2013-07-15 14:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/04699cf01bebad2b887948811526d92badd95511', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 10, 'created': '2013-07-15 14:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f395502f044a23213e406860ff441178dc0b7a34', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 11, 'created': '2013-07-25 09:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/be41855ca937bfb18897c5bdf8fb62c7537a62dc', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 12, 'created': '2013-07-25 09:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3d2a844cbb9631398c780aef37621c8fae2fdfa', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 13, 'created': '2013-07-25 09:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/70a7ef95787a90985a225f30570a1e670d1bce5f', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 14, 'created': '2013-07-30 14:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/72dd3bac62852ee17dca5e1b8a9664bf22ed4974', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 15, 'created': '2013-08-09 09:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a0d903d560f0589c52359a8ce23660b6db16ac8', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 16, 'created': '2013-08-12 11:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f1d890fcba3f44763fefd75bff35d4581469106', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 17, 'created': '2013-08-12 11:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99000b6578310f2a3d24b9d28c6a428ab12f1abb', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 18, 'created': '2013-08-12 16:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9667fe438a602702e577f933504200afa54dc739', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 19, 'created': '2013-08-13 08:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc74c92801b01c85c21bc97069273ac33ca7acc8', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 20, 'created': '2013-08-21 11:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/25bb6f8e0dd9950828fcc97c804c92bbaee47c63', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 21, 'created': '2013-08-21 20:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01e939bf2a3ba496c0a7ebc46acffb3c707600df', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 22, 'created': '2013-08-22 11:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/31d83dcf7ca18eb3b356d696a3dcf0e18b06af48', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 23, 'created': '2013-08-22 11:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/363808a3872ee69084c961c82f822178a25b192b', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 24, 'created': '2013-08-26 17:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0229020c8db3cab3e2e00a5d64901c8f1ad5bc0b', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 25, 'created': '2013-09-02 08:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/678642b2cb637fd4ef9f9929bc4d327492332858', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 26, 'created': '2013-09-02 09:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9d0e81b3fc2d669df0a3740a29bc8f2e4b8e6957', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}, {'number': 27, 'created': '2013-09-02 10:39:51.000000000', 'files': ['neutron/tests/unit/test_iptables_manager.py', 'neutron/agent/linux/iptables_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5619bc7121879d36ceafceef8c9f76d27791ca6b', 'message': 'Add method to get iptables traffic counters\n\nAdd methods to iptables_manager to get traffic counters.\nthis is a part of the blueprint bandwidth-router-measurement\n\nChange-Id: I6485d1239085e46398126c81e674e399952a4597\n'}]",38,35624,5619bc7121879d36ceafceef8c9f76d27791ca6b,103,14,27,7141,,,0,"Add method to get iptables traffic counters

Add methods to iptables_manager to get traffic counters.
this is a part of the blueprint bandwidth-router-measurement

Change-Id: I6485d1239085e46398126c81e674e399952a4597
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/35624/4 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/tests/unit/test_iptables_manager.py', 'quantum/agent/linux/iptables_manager.py']",2,966a1f79319e9a634671620b5f727e11f059fb67,review/sylvain_afchain/bp/bandwidth-router-measurement-l3,"import re def get_traffic_counters(self, chain): acc = {'pkts': 0, 'bytes': 0} s = [('iptables', 'filter')] if self.use_ipv6: s += [('ip6tables', 'filter')] for cmd, table in s: args = [cmd, '-L', '-nvx', '-t', table] if self.namespace: args = ['ip', 'netns', 'exec', self.namespace] + args current_table = (self.execute(args, root_helper=self.root_helper)) current_lines = current_table.split('\n') chain_flag = False count_flag = False chain_pattern = ""Chain "" for i in xrange(len(current_lines)): line = current_lines[i] if count_flag: if len(line) == 0: count_flag = False chain_flag = False continue data = re.findall(r'\S+', line) if data[2] == chain: acc['pkts'] += int(data[0]) acc['bytes'] += int(data[1]) if line.startswith(chain_pattern): chain_flag = True elif chain_flag and not count_flag: count_flag = True return acc",,69,0
openstack%2Fneutron~master~I146afe961cd445a023adc7233588d8034fdb8437,openstack/neutron,master,I146afe961cd445a023adc7233588d8034fdb8437,Allow None for binding:profile attribute,MERGED,2013-09-03 13:05:20.000000000,2013-09-05 12:06:32.000000000,2013-09-05 12:06:32.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 308}, {'_account_id': 841}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 5127}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-09-03 13:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d30ab27d53fa9f88975a176ff28747770b544470', 'message': 'Allow None for binding:profile attribute\n\nWe need to pass None in binding:profile to allow an administrator\nto clear binding:profile attribute.\n\nCloses-Bug: #1220011\n\nThe unit tests are added to the plugins which uses binding:profile\nattribute (Mellanox and NEC plugins at now).\n\nChange-Id: I146afe961cd445a023adc7233588d8034fdb8437\n'}, {'number': 2, 'created': '2013-09-04 14:15:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/60701f9c89312b506d0c64948e6919bd7e33fd70', 'message': 'Allow None for binding:profile attribute\n\nWe need to pass None in binding:profile to allow an administrator\nto clear binding:profile attribute.\n\nCloses-Bug: #1220011\n\nAdds dedicated unit tests to the plugins which uses binding:profile\nattribute (Mellanox and NEC plugins at now).\n\nThis commit also adds common unit tests for binding:profile to\nthe common PortBindingTestCase class.\n- create_port with binding:profile whose value is None or {}\n- update_port with binding:profile whose value is None or {}\n- Reject binding:profile from non-admin user\n\nNote that _make_port() in BigSwitch plugin test is updated\nto allow passing arg_list() from the base test class.\n\nFix a bug in NEC plugin that 500 is returned when putting\nbinding:profile None to a port whose binding:profile is\nalready None (Closes-Bug: #1220720)\n\nChange-Id: I146afe961cd445a023adc7233588d8034fdb8437\n'}, {'number': 3, 'created': '2013-09-04 16:17:07.000000000', 'files': ['neutron/tests/unit/nec/test_portbindings.py', 'neutron/extensions/portbindings.py', 'neutron/tests/unit/_test_extension_portbindings.py', 'neutron/tests/unit/bigswitch/test_restproxy_plugin.py', 'neutron/plugins/nec/nec_plugin.py', 'neutron/tests/unit/mlnx/test_mlnx_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d632b66dc8b701ca777af4335b6505b4c4cd7828', 'message': 'Allow None for binding:profile attribute\n\nWe need to pass None in binding:profile to allow an administrator\nto clear binding:profile attribute.\n\nCloses-Bug: #1220011\n\nAdds dedicated unit tests to the plugins which uses binding:profile\nattribute (Mellanox and NEC plugins at now).\n\nThis commit also adds common unit tests for binding:profile to\nthe common PortBindingTestCase class.\n- create_port with binding:profile whose value is None or {}\n- update_port with binding:profile whose value is None or {}\n- Reject binding:profile from non-admin user\n\nNote that _make_port() in BigSwitch plugin test is updated\nto allow passing arg_list() from the base test class.\n\nFix a bug in NEC plugin that 500 is returned when putting\nbinding:profile None to a port whose binding:profile is\nalready None (Closes-Bug: #1220720)\n\nChange-Id: I146afe961cd445a023adc7233588d8034fdb8437\n'}]",1,44869,d632b66dc8b701ca777af4335b6505b4c4cd7828,21,8,3,841,,,0,"Allow None for binding:profile attribute

We need to pass None in binding:profile to allow an administrator
to clear binding:profile attribute.

Closes-Bug: #1220011

Adds dedicated unit tests to the plugins which uses binding:profile
attribute (Mellanox and NEC plugins at now).

This commit also adds common unit tests for binding:profile to
the common PortBindingTestCase class.
- create_port with binding:profile whose value is None or {}
- update_port with binding:profile whose value is None or {}
- Reject binding:profile from non-admin user

Note that _make_port() in BigSwitch plugin test is updated
to allow passing arg_list() from the base test class.

Fix a bug in NEC plugin that 500 is returned when putting
binding:profile None to a port whose binding:profile is
already None (Closes-Bug: #1220720)

Change-Id: I146afe961cd445a023adc7233588d8034fdb8437
",git fetch https://review.opendev.org/openstack/neutron refs/changes/69/44869/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/extensions/portbindings.py', 'neutron/tests/unit/nec/test_portbindings.py', 'neutron/tests/unit/mlnx/test_mlnx_plugin.py']",3,d30ab27d53fa9f88975a176ff28747770b544470,bug/1220011,"from neutron.extensions import portbindings def _check_default_port_binding_profole(self, port, expected_vif_type=None): if expected_vif_type is None: expected_vif_type = constants.VIF_TYPE_DIRECT p = port['port'] self.assertIn('id', p) self.assertEqual(expected_vif_type, p[portbindings.VIF_TYPE]) self.assertEqual({'physical_network': 'default'}, p[portbindings.PROFILE]) def test_create_port_no_binding_profile(self): with self.port() as port: self._check_default_port_binding_profole(port) def test_create_port_binding_profile_none(self): profile_arg = {portbindings.PROFILE: None} with self.port(arg_list=(portbindings.PROFILE,), **profile_arg) as port: self._check_default_port_binding_profole(port) def test_create_port_binding_profile_vif_type(self): for vif_type in [constants.VIF_TYPE_HOSTDEV, constants.VIF_TYPE_DIRECT]: profile_arg = {portbindings.PROFILE: {constants.VNIC_TYPE: vif_type}} with self.port(arg_list=(portbindings.PROFILE,), **profile_arg) as port: self._check_default_port_binding_profole( port, expected_vif_type=vif_type) ",,72,2
openstack%2Fglance~master~I01211894d0d76d69cbf92fe726fbed56326d950d,openstack/glance,master,I01211894d0d76d69cbf92fe726fbed56326d950d,Prefetcher should perform data integrity check,MERGED,2013-06-27 16:52:07.000000000,2013-09-05 11:52:57.000000000,2013-09-05 11:52:57.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 6159}, {'_account_id': 6493}, {'_account_id': 6662}, {'_account_id': 8001}]","[{'number': 1, 'created': '2013-06-27 16:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/459bb80c9046daf1ff15b5236744304a5387ce56', 'message': 'Prefetcher should perform data integrity check\n\nWhen prefetching into cache we should verify the image data checksum.\n\nFixes bug 882585.\n\nChange-Id: I01211894d0d76d69cbf92fe726fbed56326d950d\n'}, {'number': 2, 'created': '2013-06-28 14:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6a3a4b609a887fb8b12f810b1176ce5097427699', 'message': 'Prefetcher should perform data integrity check\n\nWhen prefetching into cache we should verify the image data checksum.\n\nFixes bug 882585.\n\nChange-Id: I01211894d0d76d69cbf92fe726fbed56326d950d\n'}, {'number': 4, 'created': '2013-07-24 14:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d37cd3502c0116cdeecf0db4ec5d5968ff1f0711', 'message': 'Prefetcher should perform data integrity check\n\nWhen prefetching into cache we should verify the image data checksum.\n\nFixes bug 882585.\n\nChange-Id: I01211894d0d76d69cbf92fe726fbed56326d950d\n'}, {'number': 3, 'created': '2013-07-24 14:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/dc48aa3feeaf17069a4e6ad7c8515afb80db4c7f', 'message': 'Prefetcher should perform data integrity check\n\nWhen prefetching into cache we should verify the image data checksum.\n\nFixes bug 882585.\n\nChange-Id: I01211894d0d76d69cbf92fe726fbed56326d950d\n'}, {'number': 5, 'created': '2013-08-14 11:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a0e051449c37c954c092a7890dce66b650303b95', 'message': 'Prefetcher should perform data integrity check\n\nWhen prefetching into cache we should verify the image data checksum.\n\nFixes bug 882585.\n\nChange-Id: I01211894d0d76d69cbf92fe726fbed56326d950d\n'}, {'number': 6, 'created': '2013-08-15 13:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8d6542821dd3f6bd5b2b8a5d8a09c66ea9ae5581', 'message': 'Prefetcher should perform data integrity check\n\nWhen prefetching into cache we should verify the image data checksum.\n\nFixes bug 882585.\n\nChange-Id: I01211894d0d76d69cbf92fe726fbed56326d950d\n'}, {'number': 7, 'created': '2013-08-15 14:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5b55e8710b972b2b333756c1c3042d4551d8bdb3', 'message': 'Prefetcher should perform data integrity check\n\nWhen prefetching into cache we should verify the image data checksum.\n\nFixes bug 882585.\n\nChange-Id: I01211894d0d76d69cbf92fe726fbed56326d950d\n'}, {'number': 8, 'created': '2013-08-22 11:57:06.000000000', 'files': ['glance/image_cache/prefetcher.py', 'glance/image_cache/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/5d6e1a91f9f39c994a493fb6607ce809b50fb42b', 'message': 'Prefetcher should perform data integrity check\n\nWhen prefetching into cache we should verify the image data checksum.\n\nFixes bug 882585.\n\nChange-Id: I01211894d0d76d69cbf92fe726fbed56326d950d\n'}]",8,34765,5d6e1a91f9f39c994a493fb6607ce809b50fb42b,37,8,8,455,,,0,"Prefetcher should perform data integrity check

When prefetching into cache we should verify the image data checksum.

Fixes bug 882585.

Change-Id: I01211894d0d76d69cbf92fe726fbed56326d950d
",git fetch https://review.opendev.org/openstack/glance refs/changes/65/34765/8 && git format-patch -1 --stdout FETCH_HEAD,"['glance/image_cache/prefetcher.py', 'glance/image_cache/__init__.py']",2,459bb80c9046daf1ff15b5236744304a5387ce56,bug/882585," def cache_image_iter(self, image_id, image_iter, image_checksum=None): :param image_checksum: Checksum of image for chunk in self.get_caching_iter(image_id, image_checksum, image_iter): pass"," def cache_image_iter(self, image_id, image_iter): with self.driver.open_for_write(image_id) as cache_file: for chunk in image_iter: cache_file.write(chunk) cache_file.flush()",7,6
openstack%2Fdevstack~master~I837ea515457fbfc50e9ce138ea9de9db12baa8be,openstack/devstack,master,I837ea515457fbfc50e9ce138ea9de9db12baa8be,xenapi: enable block device access for stack user,MERGED,2013-08-29 11:07:11.000000000,2013-09-05 11:52:56.000000000,2013-09-05 11:52:55.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5044}]","[{'number': 1, 'created': '2013-08-29 11:07:11.000000000', 'files': ['tools/xen/prepare_guest.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b1dc9bd5e43568e0fc96b4e2be4520be12a1d955', 'message': 'xenapi: enable block device access for stack user\n\nAlthough nova is setting the permissions on block devices, sometimes it\nfails, and that results in an instance failing to launch. It is only an\nissue for 3-part images, and images accessed through block devices. This\npatch adds an udev rule, so that devices will be accessible.\n\nfixes bug 1218251\n\nChange-Id: I837ea515457fbfc50e9ce138ea9de9db12baa8be\n'}]",0,44268,b1dc9bd5e43568e0fc96b4e2be4520be12a1d955,11,4,1,5044,,,0,"xenapi: enable block device access for stack user

Although nova is setting the permissions on block devices, sometimes it
fails, and that results in an instance failing to launch. It is only an
issue for 3-part images, and images accessed through block devices. This
patch adds an udev rule, so that devices will be accessible.

fixes bug 1218251

Change-Id: I837ea515457fbfc50e9ce138ea9de9db12baa8be
",git fetch https://review.opendev.org/openstack/devstack refs/changes/68/44268/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/xen/prepare_guest.sh'],1,b1dc9bd5e43568e0fc96b4e2be4520be12a1d955,bug/1218251,"# Add an udev rule, so that new block devices could be written by stack user cat > /etc/udev/rules.d/50-openstack-blockdev.rules << EOF KERNEL==""xvd[b-z]"", GROUP=""$STACK_USER"", MODE=""0660"" EOF ",,5,0
openstack%2Fglance~master~I1635abdd2665b463473b283cc0e15f057caf4195,openstack/glance,master,I1635abdd2665b463473b283cc0e15f057caf4195,Fixes files with wrong bitmode,MERGED,2013-08-22 03:53:50.000000000,2013-09-05 11:26:53.000000000,2013-09-05 11:26:52.000000000,"[{'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 2166}, {'_account_id': 6159}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-08-22 03:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bb149d0126fac95a9b27b72e2ed208bc9196819f', 'message': 'Fixes files with wrong bitmode\n\nSome modules have bitmode 755. Changed to 644\n\nChange-Id: I1635abdd2665b463473b283cc0e15f057caf4195\n'}, {'number': 2, 'created': '2013-08-22 03:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c8da38e01f97b13188d66fe186e1a8448444b021', 'message': 'Fixes files with wrong bitmode\n\nSome modules have bitmode 755. Changed to 644\n\nChange-Id: I1635abdd2665b463473b283cc0e15f057caf4195\n'}, {'number': 3, 'created': '2013-08-30 02:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a723075cd5ec21993d533a48da519597b4f94edd', 'message': 'Fixes files with wrong bitmode\n\nSome modules have bitmode 755. Changed to 644\n\nChange-Id: I1635abdd2665b463473b283cc0e15f057caf4195\n'}, {'number': 4, 'created': '2013-09-02 00:46:45.000000000', 'files': ['glance/cmd/cache_pruner.py', 'glance/cmd/cache_cleaner.py', 'glance/cmd/control.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/e09424651e126489b3bdced1e3a7a7290d5642c2', 'message': 'Fixes files with wrong bitmode\n\nSome modules have bitmode 755. Changed to 644\n\nChange-Id: I1635abdd2665b463473b283cc0e15f057caf4195\n'}]",0,43240,e09424651e126489b3bdced1e3a7a7290d5642c2,20,5,4,1994,,,0,"Fixes files with wrong bitmode

Some modules have bitmode 755. Changed to 644

Change-Id: I1635abdd2665b463473b283cc0e15f057caf4195
",git fetch https://review.opendev.org/openstack/glance refs/changes/40/43240/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/cmd/registry.py', 'glance/cmd/cache_pruner.py', 'glance/cmd/cache_cleaner.py', 'glance/cmd/cache_prefetcher.py', 'glance/cmd/manage.py', 'glance/cmd/scrubber.py', 'glance/cmd/api.py', 'glance/cmd/control.py', 'glance/cmd/replicator.py', 'glance/cmd/cache_manage.py']",10,bb149d0126fac95a9b27b72e2ed208bc9196819f,chmod644,,#!/usr/bin/env python,0,14
openstack%2Fcinder~master~I5c4569c1c09751d53817ee9577581e530a3a8352,openstack/cinder,master,I5c4569c1c09751d53817ee9577581e530a3a8352,This adds a README to brick,MERGED,2013-09-04 18:40:42.000000000,2013-09-05 11:24:38.000000000,2013-09-05 11:24:37.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 5997}]","[{'number': 1, 'created': '2013-09-04 18:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c08c832471d87d7961906fdd22b7f5ce1e845971', 'message': ""This adds a README to brick.\n\nWe need to let folks know where brick is\ncurrently being maintained for the Havana\nrelease and where to file defects.\nOnce this simple patch lands, we'll pull this into\nthe Nova patch.\n\nChange-Id: I5c4569c1c09751d53817ee9577581e530a3a8352\n""}, {'number': 2, 'created': '2013-09-04 19:33:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e08898454e35388e704f91de1ecfca0d7127183f', 'message': ""This adds a README to brick\n\nWe need to let folks know where brick is\ncurrently being maintained for the Havana\nrelease and where to file defects.\nOnce this simple patch lands, we'll pull this into\nthe Nova patch.\n\n(fixed to pass hacking, due to bad first line of\ncommit. Please DON'T hit +A on patches until they\nreturn with a +1 from the Jenkins check queue.)\n\nChange-Id: I5c4569c1c09751d53817ee9577581e530a3a8352\n""}, {'number': 3, 'created': '2013-09-04 19:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7e3434602126ba17ba535996668e52529269b95f', 'message': ""This adds a README to brick.\n\nWe need to let folks know where brick is\ncurrently being maintained for the Havana\nrelease and where to file defects.\nOnce this simple patch lands, we'll pull this into\nthe Nova patch.\n\nChange-Id: I5c4569c1c09751d53817ee9577581e530a3a8352\n""}, {'number': 4, 'created': '2013-09-04 20:09:09.000000000', 'files': ['cinder/brick/README.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/04e3c531f718ae83e61c6498a04f6ed7d96632c6', 'message': ""This adds a README to brick\n\nWe need to let folks know where brick is\ncurrently being maintained for the Havana\nrelease and where to file defects.\nOnce this simple patch lands, we'll pull this into\nthe Nova patch.\n\n(fix hacking violation in commit message for the 2nd\ntime on this patch. To prevent it from blocking the\nmerge queue on feature freeze day.)\n\nPLEASE DON'T +A PATCHES UNTIL THEY PASS JENKINS CHECK\n\nChange-Id: I5c4569c1c09751d53817ee9577581e530a3a8352\n""}]",0,45093,04e3c531f718ae83e61c6498a04f6ed7d96632c6,18,6,4,5997,,,0,"This adds a README to brick

We need to let folks know where brick is
currently being maintained for the Havana
release and where to file defects.
Once this simple patch lands, we'll pull this into
the Nova patch.

(fix hacking violation in commit message for the 2nd
time on this patch. To prevent it from blocking the
merge queue on feature freeze day.)

PLEASE DON'T +A PATCHES UNTIL THEY PASS JENKINS CHECK

Change-Id: I5c4569c1c09751d53817ee9577581e530a3a8352
",git fetch https://review.opendev.org/openstack/cinder refs/changes/93/45093/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/brick/README.txt'],1,c08c832471d87d7961906fdd22b7f5ce1e845971,brick_readme,"Brick is a new library that currently is maintained in Cinder for the Havana release. It will eventually be moved external to Cinder, possibly oslo, or pypi. Any defects found in Brick, should be submitted against Cinder and fixed there, then pulled into other projects that are using brick. * Brick is used outside of Cinder and therefore cannot have any dependencies on Cinder and/or it's database. ",,9,0
openstack%2Fglance~master~I8e0e38df15ec61a0ccbfa41c3ccaed3a01d1d4d5,openstack/glance,master,I8e0e38df15ec61a0ccbfa41c3ccaed3a01d1d4d5,Fix localisation string usage,MERGED,2013-09-02 17:47:07.000000000,2013-09-05 11:24:22.000000000,2013-09-05 11:24:22.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2537}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-09-02 17:47:07.000000000', 'files': ['glance/common/utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/8196381a4b73a1e0b98d7e43b625de0a695732d7', 'message': 'Fix localisation string usage\n\nThe format string for localisation needs to be a fixed\nliteral, otherwise translation tools do not work.\n\nChange-Id: I8e0e38df15ec61a0ccbfa41c3ccaed3a01d1d4d5\n'}]",0,44755,8196381a4b73a1e0b98d7e43b625de0a695732d7,9,6,1,6593,,,0,"Fix localisation string usage

The format string for localisation needs to be a fixed
literal, otherwise translation tools do not work.

Change-Id: I8e0e38df15ec61a0ccbfa41c3ccaed3a01d1d4d5
",git fetch https://review.opendev.org/openstack/glance refs/changes/55/44755/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/common/utils.py'],1,8196381a4b73a1e0b98d7e43b625de0a695732d7,H701," msg = _(""Bad header: %(header_name)s"") % {'header_name': key}"," msg = _((""Bad header: %s"") % key)",1,1
openstack%2Fmurano-deployment~release-0.2~If487a82bd1d68a13577b3c640117f6c737f48885,openstack/murano-deployment,release-0.2,If487a82bd1d68a13577b3c640117f6c737f48885,Resolved issues with different guide names for different vers,MERGED,2013-09-05 11:10:33.000000000,2013-09-05 11:10:47.000000000,2013-09-05 11:10:47.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-09-05 11:10:33.000000000', 'files': ['docs-builder/builder.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/2bad285972ff27f7553a9394635aeaf033c5188f', 'message': 'Resolved issues with different guide names for different vers\n\nChange-Id: If487a82bd1d68a13577b3c640117f6c737f48885\n'}]",0,45217,2bad285972ff27f7553a9394635aeaf033c5188f,5,2,1,7225,,,0,"Resolved issues with different guide names for different vers

Change-Id: If487a82bd1d68a13577b3c640117f6c737f48885
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/17/45217/1 && git format-patch -1 --stdout FETCH_HEAD,['docs-builder/builder.sh'],1,2bad285972ff27f7553a9394635aeaf033c5188f,," guides=""murano-manual murano-deployment-guide"" elif [ ${version} = ""0.2"" ]; then guides=""developers-guide murano-deployment-guide user-guide"" branch=""release-${version}"" elif [ ${version} = ""0.1"" ]; then guides=""murano-manual murano-deployment-guide"" branch=""release-${version}"" guides=""developers-guide murano-deployment-guide"" cd docs-${version} && git pull && cd .. for guide in ${guides} cd ""${TEMP}/docs-${version}/src/${guide}"" built_manual=${TEMP}/murano-docs/${version}/${guide} cp -r ""target/docbkx/webhelp/${guide}""/* ""${built_manual}"" cp ""target/docbkx/pdf/${guide}.pdf"" ""${built_manual}"""," for manual in ""developers-guide"" ""murano-deployment-guide"" cd ""${TEMP}/docs-${version}/src/${manual}"" built_manual=${TEMP}/murano-docs/${version}/${manual} cp -r ""target/docbkx/webhelp/${manual}""/* ""${built_manual}"" cp ""target/docbkx/pdf/${manual}.pdf"" ""${built_manual}""",14,5
openstack%2Fneutron~master~I73a1eb8ecdb7c6d46ff12afba549dd27095b7202,openstack/neutron,master,I73a1eb8ecdb7c6d46ff12afba549dd27095b7202,Ensure unit tests do not let looping calls roam freely,MERGED,2013-09-04 19:20:54.000000000,2013-09-05 11:04:35.000000000,2013-09-05 10:59:40.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 2166}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-09-04 19:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5ad2921c0c2dbe02fe173dd5438a81b0845be6ae', 'message': 'Ensure tests do not let looping calls roam freely\n\nBug 1220871\n\nThis patch does minimal changes in neutron.plugins.nicira.common.sync\nproviding unit tests with a reference to the looping call object, so\nthat they can control its lifecycle.\n\nChange-Id: I73a1eb8ecdb7c6d46ff12afba549dd27095b7202\n'}, {'number': 2, 'created': '2013-09-04 19:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e311a3c46b3627377a9b634bf5307f6626ff88cf', 'message': 'Ensure tests do not let looping calls roam freely\n\nBug 1220871\n\nThis patch does minimal changes in neutron.plugins.nicira.common.sync\nproviding unit tests with a reference to the looping call object, so\nthat they can control its lifecycle.\n\nChange-Id: I73a1eb8ecdb7c6d46ff12afba549dd27095b7202\n'}, {'number': 3, 'created': '2013-09-04 23:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/30e2f9afdcf38333ba850a6c7397acf36f0239b5', 'message': 'Ensure unit tests do not let looping calls roam freely\n\nBug 1220871\n\nThis patch does minimal changes in neutron.plugins.nicira.common.sync\nproviding unit tests with a reference to the looping call object, so\nthat they can control its lifecycle.\nAlso, it perform a bit of refactoring in test_l3_agent.py in the way\nmocks are created and started.\n\nChange-Id: I73a1eb8ecdb7c6d46ff12afba549dd27095b7202\n'}, {'number': 4, 'created': '2013-09-04 23:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ef4b23d5837434de00266351e431c5325544f32', 'message': 'Ensure unit tests do not let looping calls roam freely\n\nBug 1220871\n\nThis patch does minimal changes in neutron.plugins.nicira.common.sync\nproviding unit tests with a reference to the looping call object, so\nthat they can control its lifecycle.\nAlso, it perform a bit of refactoring in test_l3_agent.py in the way\nmocks are created and started.\n\nChange-Id: I73a1eb8ecdb7c6d46ff12afba549dd27095b7202\n'}, {'number': 5, 'created': '2013-09-05 00:16:17.000000000', 'files': ['neutron/plugins/nicira/common/sync.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py', 'neutron/tests/unit/nicira/test_nvp_sync.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/tests/unit/services/metering/test_metering_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dabbb1bfc567b06573b55a3e250cd3d5d98ade16', 'message': 'Ensure unit tests do not let looping calls roam freely\n\nBug 1220871\n\nThis patch does minimal changes in neutron.plugins.nicira.common.sync\nproviding unit tests with a reference to the looping call object, so\nthat they can control its lifecycle.\nAlso, it perform a bit of refactoring in test_l3_agent.py in the way\nmocks are created and started.\n\nChange-Id: I73a1eb8ecdb7c6d46ff12afba549dd27095b7202\n'}]",2,45104,dabbb1bfc567b06573b55a3e250cd3d5d98ade16,19,6,5,261,,,0,"Ensure unit tests do not let looping calls roam freely

Bug 1220871

This patch does minimal changes in neutron.plugins.nicira.common.sync
providing unit tests with a reference to the looping call object, so
that they can control its lifecycle.
Also, it perform a bit of refactoring in test_l3_agent.py in the way
mocks are created and started.

Change-Id: I73a1eb8ecdb7c6d46ff12afba549dd27095b7202
",git fetch https://review.opendev.org/openstack/neutron refs/changes/04/45104/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/nicira/common/sync.py', 'neutron/tests/unit/nicira/test_nvp_sync.py']",2,5ad2921c0c2dbe02fe173dd5438a81b0845be6ae,bug/1220871, synchronizer._sync_looping_call.stop() self._plugin._synchronizer._sync_looping_call.stop(),,7,4
openstack%2Fhorizon~master~Ibb7ed5f97f64cfc9e56b317ed9d4b5e8cbf8cc8c,openstack/horizon,master,Ibb7ed5f97f64cfc9e56b317ed9d4b5e8cbf8cc8c,Do not run preemptive actions twice,MERGED,2013-09-04 11:59:40.000000000,2013-09-05 10:54:18.000000000,2013-09-05 10:54:18.000000000,"[{'_account_id': 3}, {'_account_id': 1816}, {'_account_id': 4264}, {'_account_id': 6650}, {'_account_id': 7553}, {'_account_id': 7585}]","[{'number': 1, 'created': '2013-09-04 11:59:40.000000000', 'files': ['horizon/tables/base.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3548435547957bc79c034a90b35405831501cafc', 'message': 'Do not run preemptive actions twice\n\nWhen table action is preemptive , it needs to run\nonly once, before the table data is loaded.\n\nFixes bug 1182661\nChange-Id: Ibb7ed5f97f64cfc9e56b317ed9d4b5e8cbf8cc8c\n'}]",0,45038,3548435547957bc79c034a90b35405831501cafc,9,6,1,7585,,,0,"Do not run preemptive actions twice

When table action is preemptive , it needs to run
only once, before the table data is loaded.

Fixes bug 1182661
Change-Id: Ibb7ed5f97f64cfc9e56b317ed9d4b5e8cbf8cc8c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/38/45038/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/tables/base.py'],1,3548435547957bc79c034a90b35405831501cafc,bug/1182661," action_names = [action.name for action in self.base_actions.values() if not action.preempt] # do not run preemptive actions here if action_name in action_names: return self.take_action(action_name, obj_id)"," return self.take_action(action_name, obj_id)",5,1
openstack%2Fnova~master~I032f99e4313206bb2415635f99b6931f8f97bb13,openstack/nova,master,I032f99e4313206bb2415635f99b6931f8f97bb13,Fixe misusing assertTrue in unit test,ABANDONED,2013-09-05 09:34:10.000000000,2013-09-05 10:23:57.000000000,,"[{'_account_id': 1994}, {'_account_id': 6722}, {'_account_id': 8688}]","[{'number': 1, 'created': '2013-09-05 09:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f3aacc99a0e19dec3b2e573f416fc1f5b18e9f0', 'message': ""Fixe misusing assertTrue in unit test\n\nMisusing assertTrue lead to invalid unit test , can't detect\nthe real issue. I didn't fix these misusing that in another review\nsee https://review.openstack.org/#/c/45151/\n\nChange-Id: I032f99e4313206bb2415635f99b6931f8f97bb13\n""}, {'number': 2, 'created': '2013-09-05 10:05:49.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/tests/compute/test_compute_mgr.py', 'nova/tests/cells/test_cells_utils.py', 'nova/tests/cells/test_cells_messaging.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/tests/integrated/test_multiprocess_api.py', 'nova/tests/virt/libvirt/test_imagecache.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9abfbc3e0972980198a73f4b0e0d50e4f3098583', 'message': ""Fixe misusing assertTrue in unit test\n\nMisusing assertTrue lead to invalid unit test , can't detect\nthe real issue.\n\nChange-Id: I032f99e4313206bb2415635f99b6931f8f97bb13\n""}]",0,45205,9abfbc3e0972980198a73f4b0e0d50e4f3098583,6,3,2,6722,,,0,"Fixe misusing assertTrue in unit test

Misusing assertTrue lead to invalid unit test , can't detect
the real issue.

Change-Id: I032f99e4313206bb2415635f99b6931f8f97bb13
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/45205/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_api.py', 'nova/tests/compute/test_compute_mgr.py', 'nova/tests/cells/test_cells_utils.py', 'nova/tests/cells/test_cells_messaging.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/tests/integrated/test_multiprocess_api.py', 'nova/tests/virt/libvirt/test_imagecache.py']",7,1f3aacc99a0e19dec3b2e573f416fc1f5b18e9f0,Fixes_assertTrue_missusage," self.assertEqual(len(image_cache_manager.corrupt_base_files), 0)"," self.assertTrue(len(image_cache_manager.corrupt_base_files), 0)",18,18
openstack%2Fneutron~master~I6d5621e3af8df67133ab4689bd6df52c1a82cb75,openstack/neutron,master,I6d5621e3af8df67133ab4689bd6df52c1a82cb75,Imported Translations from Transifex,MERGED,2013-09-05 06:14:29.000000000,2013-09-05 10:13:04.000000000,2013-09-05 10:13:04.000000000,"[{'_account_id': 3}, {'_account_id': 2031}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-09-05 06:14:29.000000000', 'files': ['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/es_MX/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/sk/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ne/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/hi/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/18eea486012a158c9cfa3df0b28eeda36e65015d', 'message': 'Imported Translations from Transifex\n\nChange-Id: I6d5621e3af8df67133ab4689bd6df52c1a82cb75\n'}]",0,45178,18eea486012a158c9cfa3df0b28eeda36e65015d,6,3,1,3,,,0,"Imported Translations from Transifex

Change-Id: I6d5621e3af8df67133ab4689bd6df52c1a82cb75
",git fetch https://review.opendev.org/openstack/neutron refs/changes/78/45178/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/es_MX/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/sk/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ne/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/hi/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po']",44,18eea486012a158c9cfa3df0b28eeda36e65015d,transifex/translations,"""POT-Creation-Date: 2013-09-05 06:13+0000\n""#: neutron/agent/dhcp_agent.py:558 neutron/agent/l3_agent.py:818 #: neutron/services/metering/agents/metering_agent.py:268#: neutron/agent/dhcp_agent.py:564 neutron/agent/l3_agent.py:823#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:227 #: neutron/services/metering/agents/metering_agent.py:273#: neutron/agent/dhcp_agent.py:572 neutron/agent/l3_agent.py:828#: neutron/services/metering/agents/metering_agent.py:276#: neutron/agent/l3_agent.py:343 neutron/db/l3_db.py:929#: neutron/agent/l3_agent.py:481#: neutron/agent/l3_agent.py:618#: neutron/agent/l3_agent.py:623#: neutron/agent/l3_agent.py:631#: neutron/agent/l3_agent.py:635#: neutron/agent/l3_agent.py:642#: neutron/agent/l3_agent.py:698 neutron/agent/l3_agent.py:729 #: neutron/services/metering/agents/metering_agent.py:58#: neutron/agent/l3_agent.py:725#: neutron/agent/l3_agent.py:733#: neutron/agent/l3_agent.py:753#: neutron/agent/l3_agent.py:761#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:262#: neutron/agent/linux/dhcp.py:548#: neutron/agent/linux/dhcp.py:553#: neutron/agent/linux/dhcp.py:601#: neutron/agent/linux/dhcp.py:611#: neutron/agent/linux/dhcp.py:652#: neutron/agent/linux/dhcp.py:688 neutron/debug/debug_agent.py:75#: neutron/services/vpn/service_drivers/ipsec.py:83#: neutron/api/v2/attributes.py:46#: neutron/api/v2/attributes.py:57#: neutron/api/v2/attributes.py:71#: neutron/api/v2/attributes.py:79#: neutron/api/v2/attributes.py:84#: neutron/api/v2/attributes.py:94#: neutron/api/v2/attributes.py:113 neutron/api/v2/attributes.py:414#: neutron/api/v2/attributes.py:117 #, python-format msgid ""'%(data)s' is too small - must be at least '%(limit)d'"" msgstr """" #: neutron/api/v2/attributes.py:122 #, python-format msgid ""'%(data)s' is too large - must be no larger than '%(limit)d'"" msgstr """" #: neutron/api/v2/attributes.py:131 #, python-format msgid ""'%s' contains whitespace"" msgstr """" #: neutron/api/v2/attributes.py:141 #, python-format msgid ""'%s' is not a valid MAC address"" msgstr """" #: neutron/api/v2/attributes.py:150 #, python-format msgid ""'%s' is not a valid IP address"" msgstr """" #: neutron/api/v2/attributes.py:161 #, python-format msgid ""Invalid data format for IP pool: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:180 neutron/api/v2/attributes.py:187 #, python-format msgid ""Invalid data format for fixed IP: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:195 #, python-format msgid ""Duplicate IP address '%s'"" msgstr """" #: neutron/api/v2/attributes.py:211 #, python-format msgid ""Invalid data format for nameserver: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:222 #, python-format msgid ""'%s' is not a valid nameserver"" msgstr """" #: neutron/api/v2/attributes.py:226 #, python-format msgid ""Duplicate nameserver '%s'"" msgstr """" #: neutron/api/v2/attributes.py:234 #, python-format msgid ""Invalid data format for hostroute: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:254 #, python-format msgid ""Duplicate hostroute '%s'"" msgstr """" #: neutron/api/v2/attributes.py:272 neutron/tests/unit/test_attributes.py:404 #: neutron/tests/unit/test_attributes.py:413 #: neutron/tests/unit/test_attributes.py:422 #: neutron/tests/unit/test_attributes.py:431 #, python-format msgid ""'%(data)s' isn't a recognized IP subnet cidr, '%(cidr)s' is recommended"" msgstr """" #: neutron/api/v2/attributes.py:278 #, python-format msgid ""'%s' is not a valid IP subnet"" msgstr """" #: neutron/api/v2/attributes.py:286 neutron/api/v2/attributes.py:327 #, python-format msgid ""'%s' is not a list"" msgstr """" #: neutron/api/v2/attributes.py:291 neutron/api/v2/attributes.py:338 #, python-format msgid ""Duplicate items in the list: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:308 #, python-format msgid ""'%s' is not a valid input"" msgstr """" #: neutron/api/v2/attributes.py:315 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:629 #, python-format msgid ""'%s' is not a valid UUID"" msgstr """" #: neutron/api/v2/attributes.py:358 #, python-format msgid ""Validator '%s' does not exist."" msgstr """" #: neutron/api/v2/attributes.py:368 #, python-format msgid ""'%s' is not a dictionary"" msgstr """" #: neutron/api/v2/attributes.py:419#: neutron/api/v2/attributes.py:438#: neutron/api/v2/attributes.py:446#: neutron/api/v2/attributes.py:459#: neutron/db/db_base_plugin_v2.py:298#: neutron/db/db_base_plugin_v2.py:304#: neutron/db/db_base_plugin_v2.py:308#: neutron/db/db_base_plugin_v2.py:356#: neutron/db/db_base_plugin_v2.py:360#: neutron/db/db_base_plugin_v2.py:367#: neutron/db/db_base_plugin_v2.py:379#: neutron/db/db_base_plugin_v2.py:388#: neutron/db/db_base_plugin_v2.py:393#: neutron/db/db_base_plugin_v2.py:402#: neutron/db/db_base_plugin_v2.py:421#: neutron/db/db_base_plugin_v2.py:430#: neutron/db/db_base_plugin_v2.py:454#: neutron/db/db_base_plugin_v2.py:459#: neutron/db/db_base_plugin_v2.py:466#: neutron/db/db_base_plugin_v2.py:572#: neutron/db/db_base_plugin_v2.py:584#: neutron/db/db_base_plugin_v2.py:590#: neutron/db/db_base_plugin_v2.py:610#: neutron/db/db_base_plugin_v2.py:619 neutron/db/db_base_plugin_v2.py:652#: neutron/db/db_base_plugin_v2.py:667#: neutron/db/db_base_plugin_v2.py:674#: neutron/db/db_base_plugin_v2.py:729#: neutron/db/db_base_plugin_v2.py:734#: neutron/db/db_base_plugin_v2.py:754#: neutron/db/db_base_plugin_v2.py:761#: neutron/db/db_base_plugin_v2.py:768#: neutron/db/db_base_plugin_v2.py:772#: neutron/db/db_base_plugin_v2.py:777#: neutron/db/db_base_plugin_v2.py:790#: neutron/db/db_base_plugin_v2.py:801#: neutron/db/db_base_plugin_v2.py:814 neutron/db/db_base_plugin_v2.py:818#: neutron/db/db_base_plugin_v2.py:938#: neutron/db/db_base_plugin_v2.py:1032#: neutron/db/db_base_plugin_v2.py:1056#: neutron/db/db_base_plugin_v2.py:1076 neutron/db/db_base_plugin_v2.py:1090#: neutron/db/db_base_plugin_v2.py:1083#: neutron/db/db_base_plugin_v2.py:1345#: neutron/db/db_base_plugin_v2.py:1420#: neutron/db/dhcp_rpc_base.py:54#: neutron/db/dhcp_rpc_base.py:61#: neutron/db/dhcp_rpc_base.py:81#: neutron/db/dhcp_rpc_base.py:110#: neutron/db/dhcp_rpc_base.py:144#: neutron/db/dhcp_rpc_base.py:177#: neutron/db/dhcp_rpc_base.py:194#: neutron/db/dhcp_rpc_base.py:218#: neutron/db/dhcp_rpc_base.py:225#: neutron/db/dhcp_rpc_base.py:242#: neutron/db/l3_db.py:210#: neutron/db/l3_db.py:230 neutron/db/l3_db.py:637#: neutron/db/l3_db.py:316#: neutron/db/l3_db.py:330#: neutron/db/l3_db.py:339 neutron/db/l3_db.py:415#: neutron/db/l3_db.py:346#: neutron/db/l3_db.py:356#: neutron/db/l3_db.py:371#: neutron/db/l3_db.py:497 neutron/plugins/nec/nec_router.py:197#: neutron/db/l3_db.py:536#: neutron/db/l3_db.py:540#: neutron/db/l3_db.py:552#: neutron/db/l3_db.py:559#: neutron/db/l3_db.py:563#: neutron/db/l3_db.py:605 neutron/plugins/nicira/NeutronPlugin.py:1688#: neutron/db/l3_db.py:761#: neutron/db/l3_db.py:779#: neutron/db/l3_db.py:935#: neutron/db/l3_rpc_base.py:56#: neutron/db/l3_rpc_base.py:87#: neutron/db/loadbalancer/loadbalancer_db.py:70#: neutron/db/loadbalancer/loadbalancer_db.py:260#: neutron/db/loadbalancer/loadbalancer_db.py:264#: neutron/db/vpn/vpn_db.py:631 #, python-format msgid ""vpnservice %s in db is already deleted"" msgstr """" #: neutron/extensions/extra_dhcp_opt.py:25 #, python-format msgid ""ExtraDhcpOpt %(id)s could not be found"" msgstr """" #: neutron/extensions/extra_dhcp_opt.py:29 #, python-format msgid ""Invalid data format for extra-dhcp-opt, provide a list of dicts: %(data)s"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:366msgid ""ipsec_site_connection %(attr)s is equal to or less than dpd_interval""#: neutron/extensions/vpnaas.py:48 #, python-format msgid ""ipsec_site_connection MTU %(mtu)d is too small for ipv%(version)s"" msgstr """" #: neutron/extensions/vpnaas.py:53#: neutron/extensions/vpnaas.py:57#: neutron/extensions/vpnaas.py:61#: neutron/extensions/vpnaas.py:65#: neutron/extensions/vpnaas.py:69#: neutron/extensions/vpnaas.py:73#: neutron/extensions/vpnaas.py:77 #, python-format msgid ""Can not load driver :%(device_driver)s"" msgstr """" #: neutron/openstack/common/rpc/amqp.py:75#: neutron/openstack/common/rpc/amqp.py:200#: neutron/openstack/common/rpc/amqp.py:203#: neutron/openstack/common/rpc/amqp.py:210#: neutron/openstack/common/rpc/amqp.py:293#: neutron/openstack/common/rpc/amqp.py:339#: neutron/openstack/common/rpc/amqp.py:411#: neutron/openstack/common/rpc/amqp.py:419#: neutron/openstack/common/rpc/amqp.py:420#: neutron/openstack/common/rpc/amqp.py:448#: neutron/openstack/common/rpc/amqp.py:456#: neutron/openstack/common/rpc/amqp.py:530#: neutron/openstack/common/rpc/amqp.py:533#: neutron/openstack/common/rpc/amqp.py:559#: neutron/openstack/common/rpc/amqp.py:568#: neutron/openstack/common/rpc/amqp.py:596#: neutron/openstack/common/rpc/impl_kombu.py:166 #: neutron/openstack/common/rpc/impl_qpid.py:183#: neutron/openstack/common/rpc/impl_kombu.py:478#: neutron/openstack/common/rpc/impl_kombu.py:500#: neutron/openstack/common/rpc/impl_kombu.py:537#: neutron/openstack/common/rpc/impl_kombu.py:553#: neutron/openstack/common/rpc/impl_kombu.py:607 #: neutron/openstack/common/rpc/impl_qpid.py:560#: neutron/openstack/common/rpc/impl_kombu.py:625 #: neutron/openstack/common/rpc/impl_qpid.py:575#: neutron/openstack/common/rpc/impl_kombu.py:629 #: neutron/openstack/common/rpc/impl_qpid.py:579#: neutron/openstack/common/rpc/impl_kombu.py:668 #: neutron/openstack/common/rpc/impl_qpid.py:614#: neutron/openstack/common/rpc/impl_qpid.py:88 #, python-format msgid ""Invalid value for qpid_topology_version: %d"" msgstr """" #: neutron/openstack/common/rpc/impl_qpid.py:502#: neutron/openstack/common/rpc/impl_qpid.py:508#: neutron/openstack/common/rpc/impl_qpid.py:521#: neutron/openstack/common/rpc/impl_qpid.py:587#: neutron/plugins/ml2/drivers/mech_arista/exceptions.py:23 #: neutron/plugins/ml2/drivers/mech_arista/exceptions.py:27#: neutron/plugins/bigswitch/plugin.py:88#: neutron/plugins/bigswitch/plugin.py:95#: neutron/plugins/bigswitch/plugin.py:98#: neutron/plugins/bigswitch/plugin.py:101#: neutron/plugins/bigswitch/plugin.py:103#: neutron/plugins/bigswitch/plugin.py:107#: neutron/plugins/bigswitch/plugin.py:109#: neutron/plugins/bigswitch/plugin.py:118#: neutron/plugins/bigswitch/plugin.py:123#: neutron/plugins/bigswitch/plugin.py:130#: neutron/plugins/bigswitch/plugin.py:137#: neutron/plugins/bigswitch/plugin.py:144#: neutron/plugins/bigswitch/plugin.py:173#: neutron/plugins/bigswitch/plugin.py:209#: neutron/plugins/bigswitch/plugin.py:213#: neutron/plugins/bigswitch/plugin.py:222#: neutron/plugins/bigswitch/plugin.py:229#: neutron/plugins/bigswitch/plugin.py:246#: neutron/plugins/bigswitch/plugin.py:250#: neutron/plugins/bigswitch/plugin.py:300msgid """" ""ServerProxy: Error details: status=%(status)d, reason=%(reason)r, "" ""ret=%(ret)s, data=%(data)r"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:313 #, python-format#: neutron/plugins/bigswitch/plugin.py:332 msgid ""NeutronRestProxyV2: "" msgstr """" #: neutron/plugins/bigswitch/plugin.py:335 #, python-format msgid """" ""NeutronRestProxyV2: Received and ignored error code %(code)s on "" ""%(action)s action to resource %(resource)s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:345 #, python-format msgid ""Unable to create remote router: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:351 #, python-format msgid ""Unable to update remote router: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:356 #, python-format msgid ""Unable to delete remote router: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:362 #, python-format msgid ""Unable to add router interface: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:367 #, python-format msgid ""Unable to delete remote intf: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:373 #, python-format msgid ""Unable to create remote network: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:379 #: neutron/plugins/bigswitch/plugin.py:384 #, python-format msgid ""Unable to update remote network: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:390 #, python-format msgid ""Unable to create remote port: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:396 #, python-format msgid ""Unable to update remote port: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:401 #, python-format msgid ""Unable to delete remote port: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:413 #, python-format msgid ""Unable to plug in interface: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:418 #, python-format msgid ""Unable to unplug interface: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:438#: neutron/plugins/bigswitch/plugin.py:480#: neutron/plugins/bigswitch/plugin.py:506#: neutron/plugins/bigswitch/plugin.py:551#: neutron/plugins/bigswitch/plugin.py:576#: neutron/plugins/bigswitch/plugin.py:624#: neutron/plugins/bigswitch/plugin.py:715#: neutron/plugins/bigswitch/plugin.py:775#: neutron/plugins/bigswitch/plugin.py:819#: neutron/plugins/bigswitch/plugin.py:835#: neutron/plugins/bigswitch/plugin.py:851#: neutron/plugins/bigswitch/plugin.py:889#: neutron/plugins/bigswitch/plugin.py:911#: neutron/plugins/bigswitch/plugin.py:930#: neutron/plugins/bigswitch/plugin.py:959#: neutron/plugins/bigswitch/plugin.py:987#: neutron/plugins/bigswitch/plugin.py:1020#: neutron/plugins/bigswitch/plugin.py:1036msgid ""NeutronRestProxyV2: Unable to create remote floating IP: %s""#: neutron/plugins/bigswitch/plugin.py:1042#: neutron/plugins/bigswitch/plugin.py:1057#: neutron/plugins/bigswitch/plugin.py:1131msgid ""Unable to update remote topology: %s""#: neutron/plugins/bigswitch/plugin.py:1223#: neutron/plugins/bigswitch/plugin.py:1229#: neutron/plugins/bigswitch/plugin.py:1256#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:98#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:116 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:136 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:151#: neutron/plugins/embrane/agent/dispatcher.py:143 #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:240#: neutron/plugins/cisco/network_plugin.py:288#: neutron/plugins/cisco/network_plugin.py:294#: neutron/plugins/cisco/network_plugin.py:299#: neutron/plugins/cisco/network_plugin.py:304#: neutron/plugins/cisco/network_plugin.py:310#: neutron/plugins/cisco/network_plugin.py:319#: neutron/plugins/cisco/network_plugin.py:329#: neutron/plugins/cisco/network_plugin.py:341#: neutron/plugins/cisco/network_plugin.py:348#: neutron/plugins/cisco/common/cisco_exceptions.py:219 msgid ""No service cluster found to perform multi-segment bridging."" msgstr """" #: neutron/plugins/cisco/db/n1kv_db_v2.py:334#: neutron/plugins/cisco/db/n1kv_db_v2.py:459#: neutron/plugins/cisco/db/n1kv_db_v2.py:578#: neutron/plugins/cisco/db/n1kv_db_v2.py:582#: neutron/plugins/cisco/db/n1kv_db_v2.py:610#: neutron/plugins/cisco/db/n1kv_db_v2.py:615#: neutron/plugins/cisco/db/n1kv_db_v2.py:619#: neutron/plugins/cisco/db/n1kv_db_v2.py:629#: neutron/plugins/cisco/db/n1kv_db_v2.py:667#: neutron/plugins/cisco/db/n1kv_db_v2.py:698#: neutron/plugins/cisco/db/n1kv_db_v2.py:700#: neutron/plugins/cisco/db/n1kv_db_v2.py:722#: neutron/plugins/cisco/db/n1kv_db_v2.py:726#: neutron/plugins/cisco/db/n1kv_db_v2.py:729#: neutron/plugins/cisco/db/n1kv_db_v2.py:837#: neutron/plugins/cisco/db/n1kv_db_v2.py:858#: neutron/plugins/cisco/db/n1kv_db_v2.py:872#: neutron/plugins/cisco/db/n1kv_db_v2.py:881#: neutron/plugins/cisco/db/n1kv_db_v2.py:906#: neutron/plugins/cisco/db/n1kv_db_v2.py:917#: neutron/plugins/cisco/db/n1kv_db_v2.py:926#: neutron/plugins/cisco/db/n1kv_db_v2.py:935#: neutron/plugins/cisco/db/n1kv_db_v2.py:962#: neutron/plugins/cisco/db/n1kv_db_v2.py:969#: neutron/plugins/cisco/db/n1kv_db_v2.py:977#: neutron/plugins/cisco/db/n1kv_db_v2.py:986#: neutron/plugins/cisco/db/n1kv_db_v2.py:993#: neutron/plugins/cisco/db/n1kv_db_v2.py:1007#: neutron/plugins/cisco/db/n1kv_db_v2.py:1221#: neutron/plugins/cisco/db/n1kv_db_v2.py:1231 msgid ""arguments segment_type missing for network profile""#: neutron/plugins/cisco/db/n1kv_db_v2.py:1240 msgid ""segment_type should either be vlan, vxlan, multi-segment or trunk""#: neutron/plugins/cisco/db/n1kv_db_v2.py:1246 msgid ""argument physical_network missing for network profile"" msgstr """" #: neutron/plugins/cisco/db/n1kv_db_v2.py:1252 msgid ""argument sub_type missing for trunk network profile"" msgstr """" #: neutron/plugins/cisco/db/n1kv_db_v2.py:1259 msgid ""argument segment_range missing for network profile"" msgstr """" #: neutron/plugins/cisco/db/n1kv_db_v2.py:1285#: neutron/plugins/cisco/db/n1kv_db_v2.py:1302#: neutron/plugins/cisco/n1kv/n1kv_client.py:201#: neutron/plugins/cisco/n1kv/n1kv_client.py:252#: neutron/plugins/cisco/n1kv/n1kv_client.py:272#: neutron/plugins/cisco/n1kv/n1kv_client.py:312#: neutron/plugins/cisco/n1kv/n1kv_client.py:429#: neutron/plugins/cisco/n1kv/n1kv_client.py:434#: neutron/plugins/cisco/n1kv/n1kv_client.py:439#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:193#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:214#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:217#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:225#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:232#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:309#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:382#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:313 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:327#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:392 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:411#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:316#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:321#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:330#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:334#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:427#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:340#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:346#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:439#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:525 #, python-format msgid ""_populate_member_segments %s"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:564 msgid ""Invalid pairing supplied"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:569 #, python-format msgid ""Invalid UUID supplied in %s"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:570 msgid ""Invalid UUID supplied"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:599 #, python-format msgid ""Cannot add a trunk segment '%s' as a member of another trunk segment"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:604 #, python-format msgid ""Cannot add vlan segment '%s' as a member of a vxlan trunk segment"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:610 #, python-format msgid ""Network UUID '%s' belongs to a different physical network"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:615 #, python-format msgid ""Cannot add vxlan segment '%s' as a member of a vlan trunk segment"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:620 #, python-format msgid ""Vlan tag '%s' is out of range"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:623 #, python-format msgid ""Vlan tag '%s' is not an integer value"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:628 #, python-format msgid ""%s is not a valid uuid"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:675 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:678#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:689#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:710#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:720#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:735#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:767#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:789 #, python-format msgid ""add_segments=%s"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:790 #, python-format msgid ""del_segments=%s"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:814#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:854#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:868#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:885#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:926#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:941#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:983#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:991#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1003 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1013 #, python-format msgid ""seg list %s "" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1056#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:483#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1114#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1129 msgid ""Cannot delete a network that is a member of a trunk segment"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1133 msgid ""Cannot delete a network that is a member of a multi-segment network"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1141 msgid ""Delete failed in VSM"" msgstr """" #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1152#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1162#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1184#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1222#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1235#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1255#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1282#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1302#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1318#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1326#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1337#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1351#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1366#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:1386#: neutron/plugins/common/utils.py:32#: neutron/plugins/common/utils.py:36#: neutron/plugins/embrane/base_plugin.py:109 #: neutron/plugins/embrane/agent/dispatcher.py:145 msgid ""Unhandled exception occurred"" msgstr """" #: neutron/plugins/embrane/base_plugin.py:136 #: neutron/plugins/embrane/base_plugin.py:173 msgid ""there must be only one gateway port per router at once"" msgstr """" #: neutron/plugins/embrane/base_plugin.py:207 #: neutron/plugins/embrane/base_plugin.py:226 #, python-format msgid ""The following routers have not physical match: %s"" msgstr """" #: neutron/plugins/embrane/base_plugin.py:212 #, python-format msgid ""Requested router: %s"" msgstr """" #: neutron/plugins/embrane/base_plugin.py:265 #, python-format msgid ""Deleting router=%s"" msgstr """" #: neutron/plugins/embrane/agent/operations/router_operations.py:99 #, python-format msgid ""The router %s had no physical representation,likely already deleted"" msgstr """" #: neutron/plugins/embrane/agent/operations/router_operations.py:128 #, python-format msgid ""Interface %s not found in the heleos back-end,likely already deleted"" msgstr """" #: neutron/plugins/embrane/common/config.py:26 msgid ""ESM management root address"" msgstr """" #: neutron/plugins/embrane/common/config.py:28 msgid ""ESM admin username."" msgstr """" #: neutron/plugins/embrane/common/config.py:31 msgid ""ESM admin password."" msgstr """" #: neutron/plugins/embrane/common/config.py:33 msgid ""Router image id (Embrane FW/VPN)"" msgstr """" #: neutron/plugins/embrane/common/config.py:35 msgid ""In band Security Zone id"" msgstr """" #: neutron/plugins/embrane/common/config.py:37 msgid ""Out of band Security Zone id"" msgstr """" #: neutron/plugins/embrane/common/config.py:39 msgid ""Management Security Zone id"" msgstr """" #: neutron/plugins/embrane/common/config.py:41 msgid ""Dummy user traffic Security Zone id"" msgstr """" #: neutron/plugins/embrane/common/config.py:43 msgid ""Shared resource pool id"" msgstr """" #: neutron/plugins/embrane/common/config.py:45 msgid ""define if the requests have run asynchronously or not"" msgstr """" #: neutron/plugins/embrane/common/constants.py:63 #, python-format msgid ""Dva is pending for the following reason: %s"" msgstr """" #: neutron/plugins/embrane/common/constants.py:64 msgid """" ""Dva can't be found to execute the operation, probably was cancelled "" ""through the heleos UI"" msgstr """" #: neutron/plugins/embrane/common/constants.py:66 #, python-format msgid ""Dva seems to be broken for reason %s"" msgstr """" #: neutron/plugins/embrane/common/constants.py:67 #, python-format msgid ""Dva interface seems to be broken for reason %s"" msgstr """" #: neutron/plugins/embrane/common/constants.py:69 #, python-format msgid ""Dva creation failed reason %s"" msgstr """" #: neutron/plugins/embrane/common/constants.py:70 #, python-format msgid ""Dva creation is in pending state for reason %s"" msgstr """" #: neutron/plugins/embrane/common/constants.py:72 #, python-format msgid ""Dva configuration failed for reason %s"" msgstr """" #: neutron/plugins/embrane/common/constants.py:73 #, python-format msgid """" ""Failed to delete the backend router for reason %s. Please remove it "" ""manually through the heleos UI"" msgstr """" #: neutron/plugins/embrane/common/exceptions.py:24 #, python-format msgid ""An unexpected error occurred:%(err_msg)s"" msgstr """" #: neutron/plugins/embrane/common/exceptions.py:33 #, python-format msgid """" ""Operation not permitted due to state constraint violation:%(operation)s "" ""not allowed for DVA %(dva_id)s in state %(state)s"" msgstr """" #: neutron/plugins/embrane/common/utils.py:40 msgid ""No ip allocation set"" msgstr """" #: neutron/plugins/embrane/l2base/support_exceptions.py:24 #, python-format msgid ""cannot retrieve utif info for the following reason: %(err_msg)s"" msgstr """" #: neutron/plugins/embrane/l2base/openvswitch/openvswitch_support.py:45 msgid """" ""No segmentation_id found for the network, please be sure that "" ""tenant_network_type is vlan"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:336#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:124#: neutron/plugins/nec/common/config.py:32#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:57 msgid """" ""Enables metrics collections for switch ports by using Hyper-V's metric "" ""APIs. Collected data can by retrieved by other apps and services, e.g.: "" ""Ceilometer. Requires Hyper-V / Windows Server 2012 and above"" msgstr """" #: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:103#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:124#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:130#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:133#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:138#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:271#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:159#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:172#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:184#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:192#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:205#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:218#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:226#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:230#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:256#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:261#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:268#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:274#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:289#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:296#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:321#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:900#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:329#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:914#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:334#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:342#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:356#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1044#: neutron/plugins/hyperv/agent/utilsv2.py:95#: neutron/plugins/hyperv/agent/utils.py:248 msgid ""Metrics collection is not supported on this version of Hyper-V"" msgstr """" #: neutron/plugins/hyperv/agent/utilsv2.py:118#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:386#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:395#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:415#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:421#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:433#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:260#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:296#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:764#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:770 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:799#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:777#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:786 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:824 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:845#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:810 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:831#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:816 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:837#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:821 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:842#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:937#: neutron/plugins/nicira/NeutronPlugin.py:1086#: neutron/plugins/ml2/db.py:45#: neutron/plugins/ml2/db.py:91#: neutron/plugins/ml2/db.py:99#: neutron/plugins/ml2/managers.py:38#: neutron/plugins/ml2/managers.py:43#: neutron/plugins/ml2/managers.py:51#: neutron/plugins/ml2/managers.py:59#: neutron/plugins/ml2/managers.py:67#: neutron/plugins/ml2/managers.py:71#: neutron/plugins/ml2/managers.py:75#: neutron/plugins/ml2/managers.py:84#: neutron/plugins/ml2/managers.py:116#: neutron/plugins/ml2/managers.py:121#: neutron/plugins/ml2/managers.py:133#: neutron/plugins/ml2/managers.py:138#: neutron/plugins/ml2/managers.py:158#: neutron/plugins/ml2/managers.py:437 #, python-format msgid ""Attempting to bind port %(port)s on host %(host)s"" msgstr """" #: neutron/plugins/ml2/managers.py:445 #, python-format msgid """" ""Bound port: %(port)s, host: %(host)s, driver: %(driver)s, vif_type: "" ""%(vif_type)s, cap_port_filter: %(cap_port_filter)s, segment: %(segment)s"" msgstr """" #: neutron/plugins/ml2/managers.py:457 #, python-format msgid ""Mechanism driver %s failed in bind_port"" msgstr """" #: neutron/plugins/ml2/managers.py:461 #, python-format msgid ""Failed to bind port %(port)s on host %(host)s"" msgstr """" #: neutron/plugins/ml2/managers.py:481 #, python-format msgid ""Mechanism driver %s failed in validate_port_binding"" msgstr """" #: neutron/plugins/ml2/managers.py:501 #, python-format msgid ""Mechanism driver %s failed in unbind_port"" msgstr """" #: neutron/plugins/ml2/plugin.py:110msgid ""network_type required""#: neutron/plugins/ml2/plugin.py:181#: neutron/plugins/ml2/plugin.py:277 #, python-format""In _notify_port_updated(), no bound segment for port %(port_id)s on "" ""network %(network_id)s""#: neutron/plugins/ml2/plugin.py:319#: neutron/plugins/ml2/plugin.py:404#: neutron/plugins/ml2/plugin.py:461#: neutron/plugins/ml2/rpc.py:103""%(network_id)s with no segments""#: neutron/plugins/ml2/rpc.py:113 #, python-format msgid """" ""Device %(device)s requested by agent %(agent_id)s on network "" ""%(network_id)s not bound, vif_type: %(vif_type)s"" msgstr """" #: neutron/plugins/ml2/rpc.py:124 #, python-format msgid """" ""Device %(device)s requested by agent %(agent_id)s on network "" ""%(network_id)s invalid segment, vif_type: %(vif_type)s"" msgstr """" #: neutron/plugins/ml2/rpc.py:144#: neutron/plugins/ml2/rpc.py:157#: neutron/plugins/ml2/rpc.py:166#: neutron/plugins/ml2/rpc.py:180#: neutron/plugins/ml2/rpc.py:188#: neutron/plugins/ml2/drivers/mech_agent.py:54 #, python-format msgid ""Attempting to bind port %(port)s on network %(network)s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_agent.py:59 #: neutron/plugins/ml2/drivers/mech_agent.py:78 #, python-format msgid ""Checking agent: %s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_agent.py:66 #, python-format msgid ""Bound using segment: %s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_agent.py:69 #, python-format msgid ""Attempting to bind with dead agent: %s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_agent.py:73 #, python-format msgid ""Validating binding for port %(port)s on network %(network)s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_agent.py:81 msgid ""Binding valid"" msgstr """" #: neutron/plugins/ml2/drivers/mech_agent.py:83 #, python-format msgid ""Binding invalid for port: %s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_agent.py:87 #, python-format msgid ""Unbinding port %(port)s on network %(network)s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_hyperv.py:42 #: neutron/plugins/ml2/drivers/mech_linuxbridge.py:43 #, python-format msgid ""Checking segment: %(segment)s for mappings: %(mappings)s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_openvswitch.py:44 #, python-format msgid """" ""Checking segment: %(segment)s for mappings: %(mappings)s with "" ""tunnel_types: %(tunnel_types)s"" msgstr """" #: neutron/plugins/ml2/drivers/mechanism_ncs.py:29 msgid ""HTTP URL of Tail-f NCS REST interface."" msgstr """" #: neutron/plugins/ml2/drivers/mechanism_ncs.py:31 msgid ""HTTP username for authentication"" msgstr """" #: neutron/plugins/ml2/drivers/mechanism_ncs.py:33 msgid ""HTTP password for authentication"" msgstr """" #: neutron/plugins/ml2/drivers/mechanism_ncs.py:35 msgid ""HTTP timeout in seconds."" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:405#: neutron/plugins/ml2/drivers/mech_arista/config.py:31 msgid """" ""Username for Arista EOS. This is required field.if not set, all "" ""communications to Arista EOSwill fail"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/config.py:37 msgid """" ""Password for Arista EOS. This is required field.if not set, all "" ""communications to Arista EOSwill fail"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/config.py:42 msgid """" ""Arista EOS IP address. This is required field.If not set, all "" ""communications to Arista EOSwill fail"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/config.py:47 msgid """" ""Defines if hostnames are sent to Arista EOS as "" ""FQDNs(\""node1.domain.com\"") or as short names (\""node1\"").This is "" ""optional. If not set, a value of \""True\""is assumed."" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/config.py:53 msgid """" ""Sync interval in seconds between Neutron plugin andEOS. This interval "" ""defines how often thesynchronization is performed. This is an "" ""optionalfield. If not set, a value of 180 seconds is assumed"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/config.py:59 msgid """" ""Defines Region Name that is assigned to this OpenStackController. This is"" "" useful when multipleOpenStack/Neutron controllers are managing the "" ""sameArista HW clusters. Note that this name must match withthe region "" ""name registered (or known) to keystoneservice. Authentication with "" ""Keysotne is performed byEOS. This is optional. If not set, a value "" ""of\""RegionOne\"" is assumed"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:226 #, python-format msgid ""Executing command on Arista EOS: %s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:259 #, python-format msgid ""Required option %s is not set"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:282 msgid ""EOS is not available, will try sync later"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:292 #, python-format msgid """" ""No Tenants configured in Neutron DB. But %d tenants disovered in EOS "" ""during synchronization.Enitre EOS region is cleared"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:296 msgid ""EOS is not available, failed to delete this region"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:307 #, python-format msgid ""EOS is not available,failed to delete tenant %s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:337 #, python-format msgid ""EOS is not available,failed to delete vm %s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:348 #, python-format msgid ""EOS is not available,failed to delete network %s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:363 #, python-format msgid ""EOS is not available, failed to createnetwork id %s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:385 #, python-format msgid ""EOS is not available, failed to createvm id %s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:461 #, python-format msgid ""Network %s is not created as it is not found inArista DB"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:475 #, python-format msgid ""Network name changed to %s"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:502 #, python-format msgid ""Network %s is not updated as it is not found inArista DB"" msgstr """" #: neutron/plugins/ml2/drivers/mech_arista/mechanism_arista.py:600 #, python-format msgid ""VM %s is not created as it is not found inArista DB"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:334#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:928#: neutron/tests/unit/openvswitch/test_ovs_tunnel.py:440#: neutron/plugins/nec/nec_plugin.py:178msgid ""_cleanup_ofc_tenant: No OFC tenant for %s""#: neutron/plugins/nec/nec_plugin.py:181#: neutron/plugins/nec/nec_plugin.py:197 msgid ""activate_port_if_ready(): skip, port.admin_state_up is False."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:201 msgid ""activate_port_if_ready(): skip, network.admin_state_up is False."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:205 msgid ""activate_port_if_ready(): skip, no portinfo for this port."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:209 msgid ""activate_port_if_ready(): skip, ofc_port already exists."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:217 #, python-format msgid ""create_ofc_port() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:230 msgid ""deactivate_port(): skip, ofc_port does not exist."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:238 #, python-format msgid ""delete_ofc_port() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:259 #, python-format msgid ""NECPluginV2.create_network() called, network=%s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:276 #, python-format msgid ""failed to create network id=%(id)s on OFC: %(exc)s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:292 #, python-format msgid ""NECPluginV2.update_network() called, id=%(id)s network=%(network)s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:332 #, python-format msgid ""NECPluginV2.delete_network() called, id=%s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:351 #, python-format msgid ""Failed to delete port(s)=%s from OFC."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:365 #, python-format msgid ""delete_network() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:498#: neutron/plugins/nec/nec_plugin.py:558#: neutron/plugins/nec/nec_plugin.py:581#: neutron/plugins/nec/nec_plugin.py:591#: neutron/plugins/nec/nec_plugin.py:651#: neutron/plugins/nec/nec_plugin.py:682#: neutron/plugins/nec/nec_plugin.py:692#: neutron/plugins/nec/nec_plugin.py:711#: neutron/plugins/nec/nec_plugin.py:716#: neutron/plugins/nec/nec_router.py:59 #, python-format msgid ""RouterMixin.create_router() called, router=%s ."" msgstr """" #: neutron/plugins/nec/nec_router.py:84 #, python-format msgid ""RouterMixin.update_router() called, id=%(id)s, router=%(router)s ."" msgstr """" #: neutron/plugins/nec/nec_router.py:102 #, python-format msgid ""RouterMixin.delete_router() called, id=%s."" msgstr """" #: neutron/plugins/nec/nec_router.py:121 #, python-format msgid """" ""RouterMixin.add_router_interface() called, id=%(id)s, "" ""interface=%(interface)s."" msgstr """" #: neutron/plugins/nec/nec_router.py:128 #, python-format msgid """" ""RouterMixin.remove_router_interface() called, id=%(id)s, "" ""interface=%(interface)s."" msgstr """" #: neutron/plugins/nec/nec_router.py:311 #, python-format msgid """" ""OFC does not support router with provider=%(provider)s, so removed it "" ""from supported provider (new router driver map=%(driver_map)s)"" msgstr """" #: neutron/plugins/nec/nec_router.py:319 #, python-format msgid """" ""default_router_provider %(default)s is supported! Please specify one of "" ""%(supported)s"" msgstr """" #: neutron/plugins/nec/nec_router.py:333 #, python-format msgid ""Enabled router drivers: %s"" msgstr """" #: neutron/plugins/nec/nec_router.py:336 #, python-format msgid """" ""No router provider is enabled. neutron-server terminated! "" ""(supported=%(supported)s, configured=%(config)s)"" msgstr """" #: neutron/plugins/nec/router_drivers.py:126 #, python-format msgid ""create_router() failed due to %s"" msgstr """" #: neutron/plugins/nec/router_drivers.py:155 #, python-format msgid ""_update_ofc_routes() failed due to %s"" msgstr """" #: neutron/plugins/nec/router_drivers.py:168 #, python-format msgid ""delete_router() failed due to %s"" msgstr """" #: neutron/plugins/nec/router_drivers.py:179 #, python-format msgid """" ""RouterOpenFlowDriver.add_interface(): the requested port has no subnet. "" ""add_interface() is skipped. router_id=%(id)s, port=%(port)s)"" msgstr """" #: neutron/plugins/nec/router_drivers.py:199 #, python-format msgid ""add_router_interface() failed due to %s"" msgstr """" #: neutron/plugins/nec/router_drivers.py:217 #, python-format msgid ""delete_router_interface() failed due to %s"" msgstr """" #: neutron/plugins/nec/common/config.py:27#: neutron/plugins/nec/common/config.py:38#: neutron/plugins/nec/common/config.py:40#: neutron/plugins/nec/common/config.py:42#: neutron/plugins/nec/common/config.py:44#: neutron/plugins/nec/common/config.py:46#: neutron/plugins/nec/common/config.py:48#: neutron/plugins/nec/common/config.py:50#: neutron/plugins/nec/common/config.py:56 msgid ""Default router provider to use."" msgstr """" #: neutron/plugins/nec/common/config.py:59 msgid ""List of enabled router providers."" msgstr """" #: neutron/plugins/nec/common/exceptions.py:32#: neutron/plugins/nec/common/exceptions.py:36#: neutron/plugins/nec/common/exceptions.py:41#: neutron/plugins/nec/common/exceptions.py:45 msgid """" ""Invalid input for operation: portinfo:datapath_id should be a hex string "" ""with at most 8 bytes"" msgstr """" #: neutron/plugins/nec/common/exceptions.py:51 msgid ""Invalid input for operation: portinfo:port_no should be [0:65535]"" msgstr """" #: neutron/plugins/nec/common/exceptions.py:56 #, python-format msgid ""Router (provider=%(provider)s) does not support an external network"" msgstr """" #: neutron/plugins/nec/common/exceptions.py:61 #, python-format msgid ""Provider %(provider)s could not be found"" msgstr """" #: neutron/plugins/nec/common/exceptions.py:65 #, python-format msgid ""Cannot create more routers with provider=%(provider)s"" msgstr """" #: neutron/plugins/nec/common/exceptions.py:69 #, python-format msgid """" ""Provider of Router %(router_id)s is %(provider)s. This operation is "" ""supported only for router provider %(expected_provider)s."" msgstr """" #: neutron/plugins/nec/common/ofc_client.py:67 #, python-format msgid ""Operation on OFC failed: %(status)s%(msg)s"" msgstr """" #: neutron/plugins/nec/common/ofc_client.py:71#: neutron/plugins/nec/common/ofc_client.py:83#: neutron/plugins/nec/common/ofc_client.py:99 msgid ""Operation on OFC failed: status=%(status), detail=%(detail)""#: neutron/plugins/nec/common/ofc_client.py:102 msgid ""Operation on OFC failed"" msgstr """" #: neutron/plugins/nec/common/ofc_client.py:111#: neutron/plugins/nec/db/api.py:134#: neutron/plugins/nec/db/api.py:147#: neutron/plugins/nec/db/api.py:173#: neutron/plugins/nec/db/api.py:206#: neutron/plugins/nec/db/api.py:212#: neutron/plugins/nec/db/router.py:87 #, python-format msgid ""Add provider binding (router=%(router_id)s, provider=%(provider)s)"" msgstr """" #: neutron/plugins/nec/drivers/__init__.py:37#: neutron/plugins/nicira/NeutronPlugin.py:235#: neutron/plugins/nicira/NeutronPlugin.py:270#: neutron/plugins/nicira/NeutronPlugin.py:272#: neutron/plugins/nicira/NeutronPlugin.py:275#: neutron/plugins/nicira/NeutronPlugin.py:350#: neutron/plugins/nicira/NeutronPlugin.py:356#: neutron/plugins/nicira/NeutronPlugin.py:362#: neutron/plugins/nicira/NeutronPlugin.py:408#: neutron/plugins/nicira/NeutronPlugin.py:438#: neutron/plugins/nicira/NeutronPlugin.py:450 #: neutron/plugins/nicira/NeutronPlugin.py:487 #: neutron/plugins/nicira/NeutronPlugin.py:672#: neutron/plugins/nicira/NeutronPlugin.py:472#: neutron/plugins/nicira/NeutronPlugin.py:494#: neutron/plugins/nicira/NeutronPlugin.py:503#: neutron/plugins/nicira/NeutronPlugin.py:509#: neutron/plugins/nicira/NeutronPlugin.py:528 #: neutron/plugins/nicira/NeutronPlugin.py:1040#: neutron/plugins/nicira/NeutronPlugin.py:540#: neutron/plugins/nicira/NeutronPlugin.py:563#: neutron/plugins/nicira/NeutronPlugin.py:576#: neutron/plugins/nicira/NeutronPlugin.py:584#: neutron/plugins/nicira/NeutronPlugin.py:621#: neutron/plugins/nicira/NeutronPlugin.py:653 #: neutron/plugins/nicira/NeutronPlugin.py:1629#: neutron/plugins/nicira/NeutronPlugin.py:657 #: neutron/plugins/nicira/NeutronPlugin.py:1633#: neutron/plugins/nicira/NeutronPlugin.py:659#: neutron/plugins/nicira/NeutronPlugin.py:700#: neutron/plugins/nicira/NeutronPlugin.py:738#: neutron/plugins/nicira/NeutronPlugin.py:767#: neutron/plugins/nicira/NeutronPlugin.py:771#: neutron/plugins/nicira/NeutronPlugin.py:775#: neutron/plugins/nicira/NeutronPlugin.py:779 #: neutron/plugins/nicira/NeutronPlugin.py:795#: neutron/plugins/nicira/NeutronPlugin.py:801#: neutron/plugins/nicira/NeutronPlugin.py:846#: neutron/plugins/nicira/NeutronPlugin.py:868#: neutron/plugins/nicira/NeutronPlugin.py:958#: neutron/plugins/nicira/NeutronPlugin.py:1022#: neutron/plugins/nicira/NeutronPlugin.py:1050#: neutron/plugins/nicira/NeutronPlugin.py:1053#: neutron/plugins/nicira/NeutronPlugin.py:1149#: neutron/plugins/nicira/NeutronPlugin.py:1165#: neutron/plugins/nicira/NeutronPlugin.py:1176#: neutron/plugins/nicira/NeutronPlugin.py:1239#: neutron/plugins/nicira/NeutronPlugin.py:1265#: neutron/plugins/nicira/NeutronPlugin.py:1367 #: neutron/plugins/nicira/NeutronPlugin.py:1441#: neutron/plugins/nicira/NeutronPlugin.py:1384 msgid """" ""Cannot create a distributed router with the NVP platform currently in "" ""execution. Please, try without specifying the 'distributed' attribute."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1391#: neutron/plugins/nicira/NeutronPlugin.py:1399#: neutron/plugins/nicira/NeutronPlugin.py:1409#: neutron/plugins/nicira/NeutronPlugin.py:1450#: neutron/plugins/nicira/NeutronPlugin.py:1466#: neutron/plugins/nicira/NeutronPlugin.py:1470#: neutron/plugins/nicira/NeutronPlugin.py:1472#: neutron/plugins/nicira/NeutronPlugin.py:1506#: neutron/plugins/nicira/NeutronPlugin.py:1510msgid ""Unable to delete logical router '%s'on NVP Platform""#: neutron/plugins/nicira/NeutronPlugin.py:1567#: neutron/plugins/nicira/NeutronPlugin.py:1655#: neutron/plugins/nicira/NeutronPlugin.py:1661#: neutron/plugins/nicira/NeutronPlugin.py:1727#: neutron/plugins/nicira/NeutronPlugin.py:1751#: neutron/plugins/nicira/NeutronPlugin.py:1794#: neutron/plugins/nicira/NeutronPlugin.py:1797#: neutron/plugins/nicira/NeutronPlugin.py:1823#: neutron/plugins/nicira/NeutronPlugin.py:1845#: neutron/plugins/nicira/NeutronPlugin.py:1933 #, python-format msgid ""Port values not valid for protocol: %s"" msgstr """" #: neutron/plugins/nicira/nvplib.py:139#: neutron/plugins/nicira/nvplib.py:159#: neutron/plugins/nicira/nvplib.py:242#: neutron/plugins/nicira/nvplib.py:258 neutron/plugins/nicira/nvplib.py:622#: neutron/plugins/nicira/nvplib.py:533#: neutron/plugins/nicira/nvplib.py:649#: neutron/plugins/nicira/nvplib.py:667#: neutron/plugins/nicira/nvplib.py:675#: neutron/plugins/nicira/nvplib.py:684#: neutron/plugins/nicira/nvplib.py:692 neutron/plugins/nicira/nvplib.py:747#: neutron/plugins/nicira/nvplib.py:742#: neutron/plugins/nicira/nvplib.py:779#: neutron/plugins/nicira/nvplib.py:803#: neutron/plugins/nicira/nvplib.py:833#: neutron/plugins/nicira/nvplib.py:843#: neutron/plugins/nicira/nvplib.py:909#: neutron/plugins/nicira/nvplib.py:1031#: neutron/plugins/nicira/nvplib.py:1057#: neutron/plugins/nicira/nvplib.py:1076#: neutron/plugins/nicira/nvplib.py:1082#: neutron/plugins/nicira/nvplib.py:1096#: neutron/plugins/nicira/nvplib.py:1231#: neutron/plugins/nicira/nvplib.py:1236#: neutron/plugins/nicira/nvplib.py:1274#: neutron/plugins/nicira/nvplib.py:1282#: neutron/plugins/nicira/nvplib.py:1298#: neutron/plugins/nicira/nvplib.py:1309#: neutron/plugins/nicira/common/config.py:34#: neutron/plugins/nicira/common/config.py:37#: neutron/plugins/nicira/common/config.py:40#: neutron/plugins/nicira/common/config.py:42#: neutron/plugins/nicira/common/config.py:45#: neutron/plugins/nicira/common/config.py:53#: neutron/plugins/nicira/common/config.py:56 msgid ""The mode used to implement DHCP/metadata services."" msgstr """" #: neutron/plugins/nicira/common/config.py:61 msgid """" ""Interval in seconds between runs of the state synchronization task. Set "" ""it to 0 to disable it"" msgstr """" #: neutron/plugins/nicira/common/config.py:64 msgid """" ""Maximum value for the additional random delay in seconds between runs of "" ""the state synchronization task"" msgstr """" #: neutron/plugins/nicira/common/config.py:68 msgid """" ""Minimum delay, in seconds, between two state synchronization queries to "" ""NVP. It must not exceed state_sync_interval"" msgstr """" #: neutron/plugins/nicira/common/config.py:72 msgid """" ""Minimum number of resources to be retrieved from NVP during state "" ""synchronization"" msgstr """" #: neutron/plugins/nicira/common/config.py:79#: neutron/plugins/nicira/common/config.py:83#: neutron/plugins/nicira/common/config.py:86#: neutron/plugins/nicira/common/config.py:89#: neutron/plugins/nicira/common/config.py:92#: neutron/plugins/nicira/common/config.py:95#: neutron/plugins/nicira/common/config.py:97#: neutron/plugins/nicira/common/config.py:102#: neutron/plugins/nicira/common/config.py:107#: neutron/plugins/nicira/common/config.py:111#: neutron/plugins/nicira/common/config.py:115#: neutron/plugins/nicira/common/config.py:118#: neutron/plugins/nicira/common/config.py:133#: neutron/plugins/nicira/common/sync.py:214""Minimum request delay:%(req_delay)s must not exceed synchronization "" ""interval:%(sync_interval)s""#: neutron/plugins/nicira/common/sync.py:233 #, python-format msgid ""Updating status for neutron resource %(q_id)s to: %(status)s"" msgstr """" #: neutron/plugins/nicira/common/sync.py:255 #, python-format msgid ""Logical switch for neutron network %s not found on NVP."" msgstr """" #: neutron/plugins/nicira/common/sync.py:322 #, python-format msgid ""Logical router for neutron router %s not found on NVP."" msgstr """" #: neutron/plugins/nicira/common/sync.py:386 #, python-format msgid ""Logical switch port for neutron port %s not found on NVP."" msgstr """" #: neutron/plugins/nicira/common/sync.py:461""Requested page size is %(cur_chunk_size)d.It might be necessary to do "" ""%(num_requests)d round-trips to NVP for fetching data. Please tune sync "" ""parameters to ensure chunk size is less than %(max_page_size)d"" msgstr """" #: neutron/plugins/nicira/common/sync.py:492 #, python-format msgid ""Fetching up to %s resources from NVP backend"" msgstr """" #: neutron/plugins/nicira/common/sync.py:512 #, python-format msgid ""Total data size: %d"" msgstr """" #: neutron/plugins/nicira/common/sync.py:516 #, python-format msgid """" ""Fetched %(num_lswitches)d logical switches, %(num_lswitchports)d logical "" ""switch ports,%(num_lrouters)d logical routers"" msgstr """" #: neutron/plugins/nicira/common/sync.py:532 #, python-format msgid ""Running state synchronization task. Chunk: %s"" msgstr """" #: neutron/plugins/nicira/common/sync.py:542 #, python-format msgid """" ""An error occured while communicating with NVP backend. Will retry "" ""synchronization in %d seconds"" msgstr """" #: neutron/plugins/nicira/common/sync.py:546 #, python-format msgid ""Time elapsed querying NVP: %s"" msgstr """" #: neutron/plugins/nicira/common/sync.py:553 #, python-format msgid ""Number of chunks: %d"" msgstr """" #: neutron/plugins/nicira/common/sync.py:569 #, python-format msgid ""Time elapsed hashing data: %s"" msgstr """" #: neutron/plugins/nicira/common/sync.py:582 #, python-format msgid ""Synchronization for chunk %(chunk_num)d of %(total_chunks)d performed"" msgstr """" #: neutron/plugins/nicira/common/sync.py:594 #, python-format msgid ""Time elapsed at end of sync: %s""#: neutron/plugins/nicira/dhcp_meta/rpc.py:121 msgid ""Metadata access network is disabled"" msgstr """" #: neutron/plugins/nicira/dhcp_meta/rpc.py:124 msgid """" ""Overlapping IPs must be enabled in order to setup the metadata access "" ""network"" msgstr """" #: neutron/plugins/nicira/dhcp_meta/rpc.py:146 #, python-format msgid """" ""No router interface found for router '%s'. No metadata access network "" ""should be created or destroyed"" msgstr """" #: neutron/plugins/nicira/dhcp_meta/rpc.py:154 #, python-format msgid """" ""An error occurred while operating on the metadata access network for "" ""router:'%s'"" msgstr """" #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:143#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:284#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:300#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:345#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:349#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:402#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:268#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:299#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:308#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:311#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:338#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:341#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:365#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:384#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:404#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:413#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:425#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:461#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:504#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:650#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:656#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:729#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:738#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:794#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:885#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:907#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:947#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:955#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:966#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:973#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:978#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:993#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1013#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1016#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1032#: neutron/services/provider_configuration.py:46 #, python-format msgid ""Provider name is limited by 255 characters: %s"" msgstr """" msgid """" ""Service provider '%(provider)s' could not be found for service type "" ""%(service_type)s""#: neutron/services/provider_configuration.py:93 #, python-format msgid """" ""Resource '%(resource_id)s' is already associated with provider "" ""'%(provider)s' for service type '%(service_type)s'"" msgstr """" #: neutron/services/provider_configuration.py:106#: neutron/services/provider_configuration.py:116#: neutron/services/provider_configuration.py:127#: neutron/services/service_base.py:69 #, python-format msgid ""No providers specified for '%s' service, exiting"" msgstr """" #: neutron/services/service_base.py:80 #, python-format msgid ""Loaded '%(provider)s' provider for service %(service_type)s"" msgstr """" #: neutron/services/service_base.py:85 #, python-format msgid ""Error loading provider '%(provider)s' for service %(service_type)s"" msgstr """" #: neutron/services/service_base.py:97 #, python-format msgid ""Default provider is not specified for service type %s"" msgstr """" #: neutron/services/loadbalancer/plugin.py:80 #, python-format msgid ""Delete associated loadbalancer pools before removing providers %s""#: neutron/services/loadbalancer/plugin.py:89msgid ""Error retrieving driver for provider %s"" msgstr """" #: neutron/services/loadbalancer/plugin.py:97 #, python-format msgid ""Error retrieving provider for pool %s""#: neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py:120#: neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py:162 #, python-format msgid ""Error while connecting to stats socket: %s"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py:251#: neutron/services/metering/agents/metering_agent.py:67 msgid ""Metering driver"" msgstr """" #: neutron/services/metering/agents/metering_agent.py:69 msgid ""Interval between two metering measures"" msgstr """" #: neutron/services/metering/agents/metering_agent.py:71 msgid ""Interval between two metering reports"" msgstr """" #: neutron/services/metering/agents/metering_agent.py:95 #, python-format msgid ""Loading Metering driver %s"" msgstr """" #: neutron/services/metering/agents/metering_agent.py:97 msgid ""A metering driver must be specified"" msgstr """" #: neutron/services/metering/agents/metering_agent.py:179 #, python-format msgid ""Driver %(driver)s does not implement %(func)s"" msgstr """" #: neutron/services/metering/agents/metering_agent.py:214 msgid ""Get router traffic counters"" msgstr """" #: neutron/services/metering/agents/metering_agent.py:218 msgid ""Update metering rules from agent"" msgstr """" #: neutron/services/metering/agents/metering_agent.py:223 msgid ""Creating a metering label from agent"" msgstr """" #: neutron/services/metering/agents/metering_agent.py:230 msgid ""Delete a metering label from agent"" msgstr """" #: neutron/services/vpn/agent.py:28 msgid ""The vpn device drivers Neutron will use"" msgstr """" #: neutron/services/vpn/device_drivers/ipsec.py:48 msgid ""Location to store ipsec server config files"" msgstr """" #: neutron/services/vpn/device_drivers/ipsec.py:51 msgid ""Interval for checking ipsec status"" msgstr """" #: neutron/services/vpn/device_drivers/ipsec.py:244 #, python-format msgid ""Failed to enable vpn process on router %s"" msgstr """" #: neutron/services/vpn/device_drivers/ipsec.py:255 #, python-format msgid ""Failed to disable vpn process on router %s"" msgstr """" #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:163 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:187 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:208 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:233#: neutron/tests/unit/nec/stub_ofc_driver.py:67 #, python-format msgid ""(create_tenant) OFC tenant %s already exists"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:79 #, python-format msgid ""(delete_tenant) OFC tenant %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:81 msgid ""delete_tenant: SUCCEED"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:88 #, python-format msgid ""(create_network) OFC tenant %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:91 #, python-format msgid ""(create_network) OFC network %s already exists"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:102 #, python-format msgid ""(update_network) OFC network %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:106 msgid ""update_network: SUCCEED"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:114 #, python-format msgid ""(delete_network) OFC network %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:116 msgid ""delete_network: SUCCEED"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:123 #, python-format msgid ""(create_port) OFC network %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:126 #, python-format msgid ""(create_port) OFC port %s already exists"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:138 #, python-format msgid ""(delete_port) OFC port %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:140 msgid ""delete_port: SUCCEED"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:173 #, python-format msgid ""(create_router) OFC tenant %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:176 #, python-format msgid ""(create_router) OFC router %s already exists"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:179 msgid ""Operation on OFC is failed"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:193 #: neutron/tests/unit/nec/stub_ofc_driver.py:283 #, python-format msgid ""(delete_router) OFC router %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:195 msgid ""delete_router: SUCCEED"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:203 #, python-format msgid ""(add_router_interface) ip_address %s is not a valid format (a.b.c.d/N)."" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:208 #, python-format msgid ""(add_router_interface) OFC router %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:211 #, python-format msgid ""(add_router_interface) OFC network %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:218 #, python-format msgid ""add_router_interface: SUCCEED (if_id=%s)"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:226 #: neutron/tests/unit/nec/stub_ofc_driver.py:243 #, python-format msgid ""(delete_router_interface) OFC router interface %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:235 msgid ""update_router_route: SUCCEED"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:246 msgid ""delete_router_interface: SUCCEED"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:256 #, python-format msgid ""(add_router_route) OFC router %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:261 #, python-format msgid ""(add_router_route) route to \""%s\"" already exists"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:266 #, python-format msgid ""add_router_route: SUCCEED (route_id=%s)"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:275 #, python-format msgid ""(delete_router_route) OFC router route %s not found"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:277 msgid ""delete_router_route: SUCCEED"" msgstr """" #: neutron/tests/unit/nec/stub_ofc_driver.py:290 #, python-format msgid ""list_router_routes: routes=%s"" msgstr """" #: neutron/tests/unit/nec/test_ofc_client.py:76 #: neutron/tests/unit/nec/test_ofc_client.py:82 #: neutron/tests/unit/nec/test_ofc_client.py:91 msgid ""An OFC exception has occurred: Operation on OFC failed"" msgstr """" #: neutron/tests/unit/nec/test_ofc_client.py:101 msgid ""An OFC exception has occurred: Failed to connect OFC : "" msgstr """" #: neutron/tests/unit/nicira/fake_nvpapiclient.py:398#: neutron/tests/unit/nicira/fake_nvpapiclient.py:407#~ msgid ""'%(data)s' is not in range %(min_value)s through %(max_value)s"" #~ msgstr """" #~ msgid ""ipsec_site_connection %(attribute_a)s less than dpd_interval"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2:Unable to create remote network: %s"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2: Unable to update remote network: %s"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2: Unable to create remote port: %s"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2: Unable to update remote port: %s"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2: _plug_interface() called"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2:Unable to update remote network: %s"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2: _unplug_interface() called"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2: Unable to create remote router: %s"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2: Unable to update remote router: %s"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2: Unable to delete remote router: %s"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2: Unable to create interface: %s"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2:Unable to delete remote intf: %s"" #~ msgstr """" #~ msgid ""NeutronRestProxyV2: Unable to create remote floatin IP: %s"" #~ msgstr """" #~ msgid ""NeutronRestProxy: Unable to update remote topology: %s"" #~ msgstr """" #~ msgid ""arguments segment_type and segment_range missing for network profile"" #~ msgstr """" #~ msgid ""segment_type should either be vlan or vxlan"" #~ msgstr """" #~ msgid ""Mechanism driver '%s' ignored because driver is already registered"" #~ msgstr """" #~ msgid ""network_type required if other provider attributes specified"" #~ msgstr """" #~ msgid """" #~ ""In _notify_port_updated() for port %(port_id),"" #~ "" network %(network_id) has no segments"" #~ msgstr """" #~ msgid """" #~ ""Device %(device)s requested by agent "" #~ ""%(agent_id)s has network %(network_id) with"" #~ "" no segments"" #~ msgstr """" #~ msgid ""An operation on OFC is failed."" #~ msgstr """" #~ msgid """" #~ ""Current network status:%(nvp_net_status)s; Status"" #~ "" in Neutron DB:%(neutron_status)s"" #~ msgstr """" #~ msgid ""Unable to get logical switches"" #~ msgstr """" #~ msgid ""Logical Switch %s found in neutron database but not in NVP."" #~ msgstr """" #~ msgid """" #~ ""Found %s logical switches not bound "" #~ ""to Neutron networks. Neutron and NVP "" #~ ""are potentially out of sync"" #~ msgstr """" #~ msgid ""get_networks() completed for tenant %s"" #~ msgstr """" #~ msgid ""Lswitch %s not found in NVP"" #~ msgstr """" #~ msgid ""Unable to get ports"" #~ msgstr """" #~ msgid ""Neutron logical port %s was not found on NVP"" #~ msgstr """" #~ msgid """" #~ ""Found %s logical ports not bound "" #~ ""to Neutron ports. Neutron and NVP "" #~ ""are potentially out of sync"" #~ msgstr """" #~ msgid ""Unable to delete logical routeron NVP Platform"" #~ msgstr """" #~ msgid """" #~ ""Current router status:%(router_status)s;Status in"" #~ "" Neutron DB:%(db_router_status)s"" #~ msgstr """" #~ msgid ""Unable to get logical routers from NVP controller"" #~ msgstr """" #~ msgid """" #~ ""Found %s logical routers not bound "" #~ ""to Neutron routers. Neutron and NVP "" #~ ""are potentially out of sync"" #~ msgstr """" #~ msgid ""Service provider could not be found for service type %(service_type)s"" #~ msgstr """" #~ msgid ""LBaaS driver Fully Qualified Name"" #~ msgstr """" #~ msgid ""Error loading LBaaS driver %s"" #~ msgstr """" ","""POT-Creation-Date: 2013-08-30 06:13+0000\n""#: neutron/agent/dhcp_agent.py:558 neutron/agent/l3_agent.py:814#: neutron/agent/dhcp_agent.py:564 neutron/agent/l3_agent.py:819#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:225#: neutron/agent/dhcp_agent.py:572 neutron/agent/l3_agent.py:824#: neutron/agent/l3_agent.py:343 neutron/db/l3_db.py:924#: neutron/agent/l3_agent.py:477#: neutron/agent/l3_agent.py:614#: neutron/agent/l3_agent.py:619#: neutron/agent/l3_agent.py:627#: neutron/agent/l3_agent.py:631#: neutron/agent/l3_agent.py:638#: neutron/agent/l3_agent.py:694 neutron/agent/l3_agent.py:725#: neutron/agent/l3_agent.py:721#: neutron/agent/l3_agent.py:729#: neutron/agent/l3_agent.py:749#: neutron/agent/l3_agent.py:757#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:260#: neutron/agent/linux/dhcp.py:528#: neutron/agent/linux/dhcp.py:533#: neutron/agent/linux/dhcp.py:581#: neutron/agent/linux/dhcp.py:591#: neutron/agent/linux/dhcp.py:632#: neutron/agent/linux/dhcp.py:668 neutron/debug/debug_agent.py:75#: neutron/api/v2/attributes.py:43#: neutron/api/v2/attributes.py:54#: neutron/api/v2/attributes.py:68#: neutron/api/v2/attributes.py:76#: neutron/api/v2/attributes.py:81#: neutron/api/v2/attributes.py:91#: neutron/api/v2/attributes.py:100 #, python-format msgid ""'%(data)s' is not in range %(min_value)s through %(max_value)s"" msgstr """" #: neutron/api/v2/attributes.py:111 #, python-format msgid ""'%s' contains whitespace"" msgstr """" #: neutron/api/v2/attributes.py:121 #, python-format msgid ""'%s' is not a valid MAC address"" msgstr """" #: neutron/api/v2/attributes.py:130 #, python-format msgid ""'%s' is not a valid IP address"" msgstr """" #: neutron/api/v2/attributes.py:141 #, python-format msgid ""Invalid data format for IP pool: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:160 neutron/api/v2/attributes.py:167 #, python-format msgid ""Invalid data format for fixed IP: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:175 #, python-format msgid ""Duplicate IP address '%s'"" msgstr """" #: neutron/api/v2/attributes.py:191 #, python-format msgid ""Invalid data format for nameserver: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:202 #, python-format msgid ""'%s' is not a valid nameserver"" msgstr """" #: neutron/api/v2/attributes.py:206 #, python-format msgid ""Duplicate nameserver '%s'"" msgstr """" #: neutron/api/v2/attributes.py:214 #, python-format msgid ""Invalid data format for hostroute: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:234 #, python-format msgid ""Duplicate hostroute '%s'"" msgstr """" #: neutron/api/v2/attributes.py:252 neutron/tests/unit/test_attributes.py:383 #: neutron/tests/unit/test_attributes.py:392 #: neutron/tests/unit/test_attributes.py:401 #: neutron/tests/unit/test_attributes.py:410 #, python-format msgid ""'%(data)s' isn't a recognized IP subnet cidr, '%(cidr)s' is recommended"" msgstr """" #: neutron/api/v2/attributes.py:258 #, python-format msgid ""'%s' is not a valid IP subnet"" msgstr """" #: neutron/api/v2/attributes.py:266 neutron/api/v2/attributes.py:307 #, python-format msgid ""'%s' is not a list"" msgstr """" #: neutron/api/v2/attributes.py:271 neutron/api/v2/attributes.py:318 #, python-format msgid ""Duplicate items in the list: '%s'"" msgstr """" #: neutron/api/v2/attributes.py:288 #, python-format msgid ""'%s' is not a valid input"" msgstr """" #: neutron/api/v2/attributes.py:295 #, python-format msgid ""'%s' is not a valid UUID"" msgstr """" #: neutron/api/v2/attributes.py:338 #, python-format msgid ""Validator '%s' does not exist."" msgstr """" #: neutron/api/v2/attributes.py:348 #, python-format msgid ""'%s' is not a dictionary"" msgstr """" #: neutron/api/v2/attributes.py:394#: neutron/api/v2/attributes.py:399#: neutron/api/v2/attributes.py:418#: neutron/api/v2/attributes.py:426#: neutron/api/v2/attributes.py:439#: neutron/db/db_base_plugin_v2.py:285#: neutron/db/db_base_plugin_v2.py:291#: neutron/db/db_base_plugin_v2.py:295#: neutron/db/db_base_plugin_v2.py:343#: neutron/db/db_base_plugin_v2.py:347#: neutron/db/db_base_plugin_v2.py:354#: neutron/db/db_base_plugin_v2.py:366#: neutron/db/db_base_plugin_v2.py:375#: neutron/db/db_base_plugin_v2.py:380#: neutron/db/db_base_plugin_v2.py:389#: neutron/db/db_base_plugin_v2.py:408#: neutron/db/db_base_plugin_v2.py:417#: neutron/db/db_base_plugin_v2.py:441#: neutron/db/db_base_plugin_v2.py:446#: neutron/db/db_base_plugin_v2.py:453#: neutron/db/db_base_plugin_v2.py:559#: neutron/db/db_base_plugin_v2.py:571#: neutron/db/db_base_plugin_v2.py:577#: neutron/db/db_base_plugin_v2.py:597#: neutron/db/db_base_plugin_v2.py:606 neutron/db/db_base_plugin_v2.py:639#: neutron/db/db_base_plugin_v2.py:654#: neutron/db/db_base_plugin_v2.py:661#: neutron/db/db_base_plugin_v2.py:716#: neutron/db/db_base_plugin_v2.py:721#: neutron/db/db_base_plugin_v2.py:741#: neutron/db/db_base_plugin_v2.py:748#: neutron/db/db_base_plugin_v2.py:755#: neutron/db/db_base_plugin_v2.py:759#: neutron/db/db_base_plugin_v2.py:764#: neutron/db/db_base_plugin_v2.py:777#: neutron/db/db_base_plugin_v2.py:788#: neutron/db/db_base_plugin_v2.py:801 neutron/db/db_base_plugin_v2.py:805#: neutron/db/db_base_plugin_v2.py:927#: neutron/db/db_base_plugin_v2.py:1021#: neutron/db/db_base_plugin_v2.py:1045#: neutron/db/db_base_plugin_v2.py:1065 neutron/db/db_base_plugin_v2.py:1079#: neutron/db/db_base_plugin_v2.py:1072#: neutron/db/db_base_plugin_v2.py:1334#: neutron/db/db_base_plugin_v2.py:1409#: neutron/db/dhcp_rpc_base.py:53#: neutron/db/dhcp_rpc_base.py:60#: neutron/db/dhcp_rpc_base.py:80#: neutron/db/dhcp_rpc_base.py:109#: neutron/db/dhcp_rpc_base.py:143#: neutron/db/dhcp_rpc_base.py:176#: neutron/db/dhcp_rpc_base.py:193#: neutron/db/dhcp_rpc_base.py:217#: neutron/db/dhcp_rpc_base.py:224#: neutron/db/dhcp_rpc_base.py:240#: neutron/db/l3_db.py:205#: neutron/db/l3_db.py:225 neutron/db/l3_db.py:632#: neutron/db/l3_db.py:311#: neutron/db/l3_db.py:325#: neutron/db/l3_db.py:334 neutron/db/l3_db.py:410#: neutron/db/l3_db.py:341#: neutron/db/l3_db.py:351#: neutron/db/l3_db.py:366#: neutron/db/l3_db.py:492#: neutron/db/l3_db.py:531#: neutron/db/l3_db.py:535#: neutron/db/l3_db.py:547#: neutron/db/l3_db.py:554#: neutron/db/l3_db.py:558#: neutron/db/l3_db.py:600 neutron/plugins/nicira/NeutronPlugin.py:2011#: neutron/db/l3_db.py:756#: neutron/db/l3_db.py:774#: neutron/db/l3_db.py:930#: neutron/db/l3_rpc_base.py:52#: neutron/db/l3_rpc_base.py:65#: neutron/db/loadbalancer/loadbalancer_db.py:68#: neutron/db/loadbalancer/loadbalancer_db.py:249#: neutron/db/loadbalancer/loadbalancer_db.py:253#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:356msgid ""ipsec_site_connection %(attribute_a)s less than dpd_interval""#: neutron/extensions/vpnaas.py:47#: neutron/extensions/vpnaas.py:51#: neutron/extensions/vpnaas.py:55#: neutron/extensions/vpnaas.py:59#: neutron/extensions/vpnaas.py:63#: neutron/extensions/vpnaas.py:67#: neutron/openstack/common/rpc/amqp.py:61#: neutron/openstack/common/rpc/amqp.py:186#: neutron/openstack/common/rpc/amqp.py:189#: neutron/openstack/common/rpc/amqp.py:196#: neutron/openstack/common/rpc/amqp.py:279#: neutron/openstack/common/rpc/amqp.py:325#: neutron/openstack/common/rpc/amqp.py:397#: neutron/openstack/common/rpc/amqp.py:405#: neutron/openstack/common/rpc/amqp.py:406#: neutron/openstack/common/rpc/amqp.py:434#: neutron/openstack/common/rpc/amqp.py:442#: neutron/openstack/common/rpc/amqp.py:516#: neutron/openstack/common/rpc/amqp.py:519#: neutron/openstack/common/rpc/amqp.py:545#: neutron/openstack/common/rpc/amqp.py:554#: neutron/openstack/common/rpc/amqp.py:582#: neutron/openstack/common/rpc/impl_kombu.py:169 #: neutron/openstack/common/rpc/impl_qpid.py:153#: neutron/openstack/common/rpc/impl_kombu.py:481#: neutron/openstack/common/rpc/impl_kombu.py:503#: neutron/openstack/common/rpc/impl_kombu.py:540#: neutron/openstack/common/rpc/impl_kombu.py:556#: neutron/openstack/common/rpc/impl_kombu.py:610 #: neutron/openstack/common/rpc/impl_qpid.py:457#: neutron/openstack/common/rpc/impl_kombu.py:628 #: neutron/openstack/common/rpc/impl_qpid.py:472#: neutron/openstack/common/rpc/impl_kombu.py:632 #: neutron/openstack/common/rpc/impl_qpid.py:476#: neutron/openstack/common/rpc/impl_kombu.py:671 #: neutron/openstack/common/rpc/impl_qpid.py:511#: neutron/openstack/common/rpc/impl_qpid.py:399#: neutron/openstack/common/rpc/impl_qpid.py:405#: neutron/openstack/common/rpc/impl_qpid.py:418#: neutron/openstack/common/rpc/impl_qpid.py:484#: neutron/plugins/bigswitch/plugin.py:85#: neutron/plugins/bigswitch/plugin.py:92#: neutron/plugins/bigswitch/plugin.py:95#: neutron/plugins/bigswitch/plugin.py:98#: neutron/plugins/bigswitch/plugin.py:100#: neutron/plugins/bigswitch/plugin.py:104#: neutron/plugins/bigswitch/plugin.py:106#: neutron/plugins/bigswitch/plugin.py:115#: neutron/plugins/bigswitch/plugin.py:120#: neutron/plugins/bigswitch/plugin.py:127#: neutron/plugins/bigswitch/plugin.py:134#: neutron/plugins/bigswitch/plugin.py:141#: neutron/plugins/bigswitch/plugin.py:170#: neutron/plugins/bigswitch/plugin.py:206#: neutron/plugins/bigswitch/plugin.py:210#: neutron/plugins/bigswitch/plugin.py:219#: neutron/plugins/bigswitch/plugin.py:226#: neutron/plugins/bigswitch/plugin.py:243#: neutron/plugins/bigswitch/plugin.py:247#: neutron/plugins/bigswitch/plugin.py:297#: neutron/plugins/bigswitch/plugin.py:340#: neutron/plugins/bigswitch/plugin.py:382#: neutron/plugins/bigswitch/plugin.py:408#: neutron/plugins/bigswitch/plugin.py:433 #, python-format msgid ""NeutronRestProxyV2:Unable to create remote network: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:465#: neutron/plugins/bigswitch/plugin.py:482 #: neutron/plugins/bigswitch/plugin.py:530 #: neutron/plugins/bigswitch/plugin.py:1286 #, python-format msgid ""NeutronRestProxyV2: Unable to update remote network: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:503#: neutron/plugins/bigswitch/plugin.py:560#: neutron/plugins/bigswitch/plugin.py:596 #: neutron/plugins/bigswitch/plugin.py:688 #, python-format msgid ""NeutronRestProxyV2: Unable to create remote port: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:651#: neutron/plugins/bigswitch/plugin.py:709#: neutron/plugins/bigswitch/plugin.py:743 #: neutron/plugins/bigswitch/plugin.py:801 #, python-format msgid ""NeutronRestProxyV2: Unable to update remote port: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:760 msgid ""NeutronRestProxyV2: _plug_interface() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:778 #, python-format msgid ""NeutronRestProxyV2:Unable to update remote network: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:792 msgid ""NeutronRestProxyV2: _unplug_interface() called"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:806#: neutron/plugins/bigswitch/plugin.py:827#: neutron/plugins/bigswitch/plugin.py:850#: neutron/plugins/bigswitch/plugin.py:891#: neutron/plugins/bigswitch/plugin.py:916 #, python-format msgid ""NeutronRestProxyV2: Unable to create remote router: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:927#: neutron/plugins/bigswitch/plugin.py:949 #, python-format msgid ""NeutronRestProxyV2: Unable to update remote router: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:961#: neutron/plugins/bigswitch/plugin.py:992 #, python-format msgid ""NeutronRestProxyV2: Unable to delete remote router: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:998#: neutron/plugins/bigswitch/plugin.py:1026 #, python-format msgid ""NeutronRestProxyV2: Unable to create interface: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1037#: neutron/plugins/bigswitch/plugin.py:1070 #, python-format msgid ""NeutronRestProxyV2:Unable to delete remote intf: %s"" msgstr """" #: neutron/plugins/bigswitch/plugin.py:1078#: neutron/plugins/bigswitch/plugin.py:1091msgid ""NeutronRestProxyV2: Unable to create remote floatin IP: %s""#: neutron/plugins/bigswitch/plugin.py:1101#: neutron/plugins/bigswitch/plugin.py:1124#: neutron/plugins/bigswitch/plugin.py:1207msgid ""NeutronRestProxy: Unable to update remote topology: %s""#: neutron/plugins/bigswitch/plugin.py:1303#: neutron/plugins/bigswitch/plugin.py:1309#: neutron/plugins/bigswitch/plugin.py:1336#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:96#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:114 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:134 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:149#: neutron/plugins/cisco/network_plugin.py:293#: neutron/plugins/cisco/network_plugin.py:299#: neutron/plugins/cisco/network_plugin.py:309#: neutron/plugins/cisco/network_plugin.py:320#: neutron/plugins/cisco/network_plugin.py:326#: neutron/plugins/cisco/network_plugin.py:335#: neutron/plugins/cisco/network_plugin.py:345#: neutron/plugins/cisco/network_plugin.py:357#: neutron/plugins/cisco/network_plugin.py:364#: neutron/plugins/cisco/db/n1kv_db_v2.py:101#: neutron/plugins/cisco/db/n1kv_db_v2.py:226#: neutron/plugins/cisco/db/n1kv_db_v2.py:344#: neutron/plugins/cisco/db/n1kv_db_v2.py:348#: neutron/plugins/cisco/db/n1kv_db_v2.py:376#: neutron/plugins/cisco/db/n1kv_db_v2.py:381#: neutron/plugins/cisco/db/n1kv_db_v2.py:385#: neutron/plugins/cisco/db/n1kv_db_v2.py:395#: neutron/plugins/cisco/db/n1kv_db_v2.py:433#: neutron/plugins/cisco/db/n1kv_db_v2.py:464#: neutron/plugins/cisco/db/n1kv_db_v2.py:466#: neutron/plugins/cisco/db/n1kv_db_v2.py:488#: neutron/plugins/cisco/db/n1kv_db_v2.py:492#: neutron/plugins/cisco/db/n1kv_db_v2.py:495#: neutron/plugins/cisco/db/n1kv_db_v2.py:603#: neutron/plugins/cisco/db/n1kv_db_v2.py:621#: neutron/plugins/cisco/db/n1kv_db_v2.py:635#: neutron/plugins/cisco/db/n1kv_db_v2.py:644#: neutron/plugins/cisco/db/n1kv_db_v2.py:670#: neutron/plugins/cisco/db/n1kv_db_v2.py:681#: neutron/plugins/cisco/db/n1kv_db_v2.py:690#: neutron/plugins/cisco/db/n1kv_db_v2.py:699#: neutron/plugins/cisco/db/n1kv_db_v2.py:726#: neutron/plugins/cisco/db/n1kv_db_v2.py:733#: neutron/plugins/cisco/db/n1kv_db_v2.py:742#: neutron/plugins/cisco/db/n1kv_db_v2.py:751#: neutron/plugins/cisco/db/n1kv_db_v2.py:758#: neutron/plugins/cisco/db/n1kv_db_v2.py:772#: neutron/plugins/cisco/db/n1kv_db_v2.py:991#: neutron/plugins/cisco/db/n1kv_db_v2.py:1001 msgid ""arguments segment_type and segment_range missing for network profile""#: neutron/plugins/cisco/db/n1kv_db_v2.py:1008 msgid ""segment_type should either be vlan or vxlan""#: neutron/plugins/cisco/db/n1kv_db_v2.py:1036#: neutron/plugins/cisco/db/n1kv_db_v2.py:1048#: neutron/plugins/cisco/n1kv/n1kv_client.py:195#: neutron/plugins/cisco/n1kv/n1kv_client.py:233#: neutron/plugins/cisco/n1kv/n1kv_client.py:253#: neutron/plugins/cisco/n1kv/n1kv_client.py:293#: neutron/plugins/cisco/n1kv/n1kv_client.py:410#: neutron/plugins/cisco/n1kv/n1kv_client.py:415#: neutron/plugins/cisco/n1kv/n1kv_client.py:420#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:191#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:212#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:215#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:223#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:230#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:299#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:378#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:303 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:317#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:388 #: neutron/plugins/openvswitch/ovs_neutron_plugin.py:407#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:306#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:311#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:320#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:324#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:423#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:330#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:336#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:435#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:388 #: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:391#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:402#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:423#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:433#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:446#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:460#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:477#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:491#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:505#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:522#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:563#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:578#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:619#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:627#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:670#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:479#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:691#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:717#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:727#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:748#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:786#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:799#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:819#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:846#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:866#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:882#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:890#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:901#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:915#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:930#: neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py:950#: neutron/plugins/common/utils.py:31#: neutron/plugins/common/utils.py:35#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:332#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:122#: neutron/plugins/nec/common/config.py:31#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:96#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:117#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:123#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:126#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:131#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:269#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:152#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:165#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:177#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:185#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:198#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:211#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:216#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:220#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:246#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:251#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:258#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:264#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:279#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:286#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:311#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:899#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:319#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:913#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:324#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:332#: neutron/plugins/hyperv/agent/hyperv_neutron_agent.py:346#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1043#: neutron/plugins/hyperv/agent/utilsv2.py:87#: neutron/plugins/hyperv/agent/utilsv2.py:110#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:382#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:391#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:411#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:417#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:429#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:258#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:294#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:763#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:769 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:798#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:776#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:785 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:823 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:844#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:809 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:830#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:815 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:836#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:820 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:841#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:936#: neutron/plugins/nicira/NeutronPlugin.py:1214#: neutron/plugins/ml2/db.py:44#: neutron/plugins/ml2/db.py:73#: neutron/plugins/ml2/db.py:81#: neutron/plugins/ml2/managers.py:41#: neutron/plugins/ml2/managers.py:46#: neutron/plugins/ml2/managers.py:54#: neutron/plugins/ml2/managers.py:62#: neutron/plugins/ml2/managers.py:70#: neutron/plugins/ml2/managers.py:74#: neutron/plugins/ml2/managers.py:78#: neutron/plugins/ml2/managers.py:87#: neutron/plugins/ml2/managers.py:129#: neutron/plugins/ml2/managers.py:134#: neutron/plugins/ml2/managers.py:145 #, python-format msgid ""Mechanism driver '%s' ignored because driver is already registered"" msgstr """" #: neutron/plugins/ml2/managers.py:151#: neutron/plugins/ml2/managers.py:156#: neutron/plugins/ml2/managers.py:176#: neutron/plugins/ml2/plugin.py:108msgid ""network_type required if other provider attributes specified""#: neutron/plugins/ml2/plugin.py:156#: neutron/plugins/ml2/plugin.py:188""In _notify_port_updated() for port %(port_id), network %(network_id) has "" ""no segments""#: neutron/plugins/ml2/plugin.py:231#: neutron/plugins/ml2/plugin.py:325#: neutron/plugins/ml2/plugin.py:382#: neutron/plugins/ml2/rpc.py:102""%(network_id) with no segments""#: neutron/plugins/ml2/rpc.py:122#: neutron/plugins/ml2/rpc.py:130#: neutron/plugins/ml2/rpc.py:139#: neutron/plugins/ml2/rpc.py:153#: neutron/plugins/ml2/rpc.py:161#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:401#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:330#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:927#: neutron/tests/unit/openvswitch/test_ovs_tunnel.py:439#: neutron/plugins/nec/nec_plugin.py:150 msgid ""activate_port_if_ready(): skip, port.admin_state_up is False."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:154 msgid ""activate_port_if_ready(): skip, network.admin_state_up is False."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:158 msgid ""activate_port_if_ready(): skip, no portinfo for this port."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:162 msgid ""activate_port_if_ready(): skip, ofc_port already exists."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:170msgid ""create_ofc_port() failed due to %s""#: neutron/plugins/nec/nec_plugin.py:183 msgid ""deactivate_port(): skip, ofc_port does not exist."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:191 #, python-format msgid ""delete_ofc_port() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:212 #, python-format msgid ""NECPluginV2.create_network() called, network=%s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:229 #, python-format msgid ""failed to create network id=%(id)s on OFC: %(exc)s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:245 #, python-format msgid ""NECPluginV2.update_network() called, id=%(id)s network=%(network)s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:285 #, python-format msgid ""NECPluginV2.delete_network() called, id=%s ."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:304 #, python-format msgid ""Failed to delete port(s)=%s from OFC."" msgstr """" #: neutron/plugins/nec/nec_plugin.py:319 #, python-format msgid ""delete_network() failed due to %s"" msgstr """" #: neutron/plugins/nec/nec_plugin.py:334#: neutron/plugins/nec/nec_plugin.py:347#: neutron/plugins/nec/nec_plugin.py:371#: neutron/plugins/nec/nec_plugin.py:400#: neutron/plugins/nec/nec_plugin.py:408#: neutron/plugins/nec/nec_plugin.py:468#: neutron/plugins/nec/nec_plugin.py:499#: neutron/plugins/nec/nec_plugin.py:509#: neutron/plugins/nec/nec_plugin.py:528#: neutron/plugins/nec/nec_plugin.py:533#: neutron/plugins/nec/common/config.py:26#: neutron/plugins/nec/common/config.py:37#: neutron/plugins/nec/common/config.py:39#: neutron/plugins/nec/common/config.py:41#: neutron/plugins/nec/common/config.py:43#: neutron/plugins/nec/common/config.py:45#: neutron/plugins/nec/common/config.py:47#: neutron/plugins/nec/common/config.py:49#: neutron/plugins/nec/common/exceptions.py:26#: neutron/plugins/nec/common/exceptions.py:30#: neutron/plugins/nec/common/exceptions.py:35#: neutron/plugins/nec/common/ofc_client.py:57#: neutron/plugins/nec/common/ofc_client.py:76#: neutron/plugins/nec/common/ofc_client.py:86 msgid ""An operation on OFC is failed.""#: neutron/plugins/nec/common/ofc_client.py:89#: neutron/plugins/nec/db/api.py:129#: neutron/plugins/nec/db/api.py:142#: neutron/plugins/nec/db/api.py:168#: neutron/plugins/nec/db/api.py:201#: neutron/plugins/nec/db/api.py:207#: neutron/plugins/nec/drivers/__init__.py:35#: neutron/plugins/nicira/NeutronPlugin.py:254#: neutron/plugins/nicira/NeutronPlugin.py:289#: neutron/plugins/nicira/NeutronPlugin.py:291#: neutron/plugins/nicira/NeutronPlugin.py:294#: neutron/plugins/nicira/NeutronPlugin.py:369#: neutron/plugins/nicira/NeutronPlugin.py:375#: neutron/plugins/nicira/NeutronPlugin.py:381#: neutron/plugins/nicira/NeutronPlugin.py:427#: neutron/plugins/nicira/NeutronPlugin.py:457#: neutron/plugins/nicira/NeutronPlugin.py:469 #: neutron/plugins/nicira/NeutronPlugin.py:506 #: neutron/plugins/nicira/NeutronPlugin.py:691#: neutron/plugins/nicira/NeutronPlugin.py:491#: neutron/plugins/nicira/NeutronPlugin.py:513#: neutron/plugins/nicira/NeutronPlugin.py:522#: neutron/plugins/nicira/NeutronPlugin.py:528#: neutron/plugins/nicira/NeutronPlugin.py:547 #: neutron/plugins/nicira/NeutronPlugin.py:1070#: neutron/plugins/nicira/NeutronPlugin.py:559#: neutron/plugins/nicira/NeutronPlugin.py:582#: neutron/plugins/nicira/NeutronPlugin.py:595#: neutron/plugins/nicira/NeutronPlugin.py:603#: neutron/plugins/nicira/NeutronPlugin.py:640#: neutron/plugins/nicira/NeutronPlugin.py:672 #: neutron/plugins/nicira/NeutronPlugin.py:1952#: neutron/plugins/nicira/NeutronPlugin.py:676 #: neutron/plugins/nicira/NeutronPlugin.py:1956#: neutron/plugins/nicira/NeutronPlugin.py:678#: neutron/plugins/nicira/NeutronPlugin.py:719#: neutron/plugins/nicira/NeutronPlugin.py:757#: neutron/plugins/nicira/NeutronPlugin.py:786#: neutron/plugins/nicira/NeutronPlugin.py:790#: neutron/plugins/nicira/NeutronPlugin.py:794#: neutron/plugins/nicira/NeutronPlugin.py:798 #: neutron/plugins/nicira/NeutronPlugin.py:814#: neutron/plugins/nicira/NeutronPlugin.py:820#: neutron/plugins/nicira/NeutronPlugin.py:865#: neutron/plugins/nicira/NeutronPlugin.py:887#: neutron/plugins/nicira/NeutronPlugin.py:989#: neutron/plugins/nicira/NeutronPlugin.py:1052#: neutron/plugins/nicira/NeutronPlugin.py:1080#: neutron/plugins/nicira/NeutronPlugin.py:1083#: neutron/plugins/nicira/NeutronPlugin.py:1109 #, python-format msgid """" ""Current network status:%(nvp_net_status)s; Status in Neutron "" ""DB:%(neutron_status)s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1119 #: neutron/plugins/nicira/NeutronPlugin.py:1165 msgid ""Unable to get logical switches"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1178 #, python-format msgid ""Logical Switch %s found in neutron database but not in NVP."" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1193 #, python-format msgid """" ""Found %s logical switches not bound to Neutron networks. Neutron and NVP "" ""are potentially out of sync"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1197 #, python-format msgid ""get_networks() completed for tenant %s"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1277 #, python-format msgid ""Lswitch %s not found in NVP"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1286 msgid ""Unable to get ports"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1313 #, python-format msgid ""Neutron logical port %s was not found on NVP"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1320 #, python-format msgid """" ""Found %s logical ports not bound to Neutron ports. Neutron and NVP are "" ""potentially out of sync"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1379#: neutron/plugins/nicira/NeutronPlugin.py:1395#: neutron/plugins/nicira/NeutronPlugin.py:1406#: neutron/plugins/nicira/NeutronPlugin.py:1475#: neutron/plugins/nicira/NeutronPlugin.py:1501#: neutron/plugins/nicira/NeutronPlugin.py:1626 #: neutron/plugins/nicira/NeutronPlugin.py:1694#: neutron/plugins/nicira/NeutronPlugin.py:1644#: neutron/plugins/nicira/NeutronPlugin.py:1652#: neutron/plugins/nicira/NeutronPlugin.py:1662#: neutron/plugins/nicira/NeutronPlugin.py:1703#: neutron/plugins/nicira/NeutronPlugin.py:1719#: neutron/plugins/nicira/NeutronPlugin.py:1723#: neutron/plugins/nicira/NeutronPlugin.py:1725#: neutron/plugins/nicira/NeutronPlugin.py:1758#: neutron/plugins/nicira/NeutronPlugin.py:1762 msgid ""Unable to delete logical routeron NVP Platform"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1782msgid """" ""Current router status:%(router_status)s;Status in Neutron "" ""DB:%(db_router_status)s""#: neutron/plugins/nicira/NeutronPlugin.py:1809 msgid ""Unable to get logical routers from NVP controller"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1831 #, python-format msgid """" ""Found %s logical routers not bound to Neutron routers. Neutron and NVP "" ""are potentially out of sync"" msgstr """" #: neutron/plugins/nicira/NeutronPlugin.py:1890#: neutron/plugins/nicira/NeutronPlugin.py:1978#: neutron/plugins/nicira/NeutronPlugin.py:1984#: neutron/plugins/nicira/NeutronPlugin.py:2050#: neutron/plugins/nicira/NeutronPlugin.py:2074#: neutron/plugins/nicira/NeutronPlugin.py:2117#: neutron/plugins/nicira/NeutronPlugin.py:2120#: neutron/plugins/nicira/NeutronPlugin.py:2146#: neutron/plugins/nicira/NeutronPlugin.py:2168#: neutron/plugins/nicira/nvplib.py:136#: neutron/plugins/nicira/nvplib.py:156#: neutron/plugins/nicira/nvplib.py:226#: neutron/plugins/nicira/nvplib.py:242 neutron/plugins/nicira/nvplib.py:602#: neutron/plugins/nicira/nvplib.py:513#: neutron/plugins/nicira/nvplib.py:629#: neutron/plugins/nicira/nvplib.py:647#: neutron/plugins/nicira/nvplib.py:655#: neutron/plugins/nicira/nvplib.py:664#: neutron/plugins/nicira/nvplib.py:672 neutron/plugins/nicira/nvplib.py:727#: neutron/plugins/nicira/nvplib.py:722#: neutron/plugins/nicira/nvplib.py:759#: neutron/plugins/nicira/nvplib.py:783#: neutron/plugins/nicira/nvplib.py:813#: neutron/plugins/nicira/nvplib.py:823#: neutron/plugins/nicira/nvplib.py:889#: neutron/plugins/nicira/nvplib.py:1011#: neutron/plugins/nicira/nvplib.py:1037#: neutron/plugins/nicira/nvplib.py:1056#: neutron/plugins/nicira/nvplib.py:1062#: neutron/plugins/nicira/nvplib.py:1076#: neutron/plugins/nicira/nvplib.py:1211#: neutron/plugins/nicira/nvplib.py:1216#: neutron/plugins/nicira/nvplib.py:1254#: neutron/plugins/nicira/nvplib.py:1262#: neutron/plugins/nicira/nvplib.py:1278#: neutron/plugins/nicira/nvplib.py:1289#: neutron/plugins/nicira/common/config.py:21#: neutron/plugins/nicira/common/config.py:24#: neutron/plugins/nicira/common/config.py:27#: neutron/plugins/nicira/common/config.py:29#: neutron/plugins/nicira/common/config.py:32#: neutron/plugins/nicira/common/config.py:40#: neutron/plugins/nicira/common/config.py:47#: neutron/plugins/nicira/common/config.py:51#: neutron/plugins/nicira/common/config.py:54#: neutron/plugins/nicira/common/config.py:57#: neutron/plugins/nicira/common/config.py:60#: neutron/plugins/nicira/common/config.py:63#: neutron/plugins/nicira/common/config.py:65#: neutron/plugins/nicira/common/config.py:70#: neutron/plugins/nicira/common/config.py:75#: neutron/plugins/nicira/common/config.py:79#: neutron/plugins/nicira/common/config.py:83#: neutron/plugins/nicira/common/config.py:86#: neutron/plugins/nicira/common/config.py:99#: neutron/plugins/nicira/common/metadata_access.py:135 msgid ""Metadata access network is disabled"" msgstr """" #: neutron/plugins/nicira/common/metadata_access.py:138 msgid """" ""Overlapping IPs must be enabled in order to setup the metadata access "" ""network"" msgstr """" #: neutron/plugins/nicira/common/metadata_access.py:161""No router interface found for router '%s'. No metadata access network "" ""should be created or destroyed""#: neutron/plugins/nicira/common/metadata_access.py:169""An error occurred while operating on the metadata access network for "" ""router:'%s'""#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:141#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:280#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:296#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:341#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:345#: neutron/plugins/openvswitch/ovs_neutron_plugin.py:398#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:266#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:297#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:306#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:309#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:336#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:339#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:363#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:382#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:402#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:411#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:423#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:459#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:502#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:649#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:655#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:728#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:737#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:793#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:884#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:906#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:946#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:954#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:965#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:972#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:977#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:992#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1012#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1015#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1031msgid ""Service provider could not be found for service type %(service_type)s""#: neutron/services/provider_configuration.py:101#: neutron/services/provider_configuration.py:111#: neutron/services/provider_configuration.py:122#: neutron/services/loadbalancer/plugin.py:36 msgid ""LBaaS driver Fully Qualified Name""#: neutron/services/loadbalancer/plugin.py:75msgid ""Error loading LBaaS driver %s""#: neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py:123 #, python-format msgid ""Error while connecting to stats socket: %s"" msgstr """" #: neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py:126#: neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py:216#: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:162 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:186 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:207 #: neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py:232#: neutron/tests/unit/nicira/fake_nvpapiclient.py:385#: neutron/tests/unit/nicira/fake_nvpapiclient.py:394",98678,38934
openstack%2Fcinder~master~I00d22861f4e01ae0862dbf4b60af314c475b7d38,openstack/cinder,master,I00d22861f4e01ae0862dbf4b60af314c475b7d38,VMDK copy_image_to_volume and copy_volume_to_image,MERGED,2013-08-23 13:24:29.000000000,2013-09-05 10:00:29.000000000,2013-09-05 10:00:29.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 6043}, {'_account_id': 7198}, {'_account_id': 7629}, {'_account_id': 7948}, {'_account_id': 8302}]","[{'number': 1, 'created': '2013-08-23 13:24:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/217f3f14e0844a7c802b3031b61204ff96187032', 'message': ""VMDK copy_image_to_volume and copy_volume_to_image\n\nImplemented copy_image_to_volume that creates a new volume backing (vm) and\ncopies over the vmdk file from the glance image. Only glance images of disk\nformat 'vmdk' can be used to create a volume using this driver.\n\nAlso implemented copy_volume_to_image that creates a new glance image using\nthe volume's vmdk file. The steps involved are to take a snapshot of volume\nvmdk, take a copy of this read only file and upload to glance.\n\nImplements: blueprint vmware-vmdk-cinder-driver\nChange-Id: I00d22861f4e01ae0862dbf4b60af314c475b7d38\n""}, {'number': 2, 'created': '2013-08-23 14:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/229d301dae5aa901f8ec9bdc2be3e5934c21283d', 'message': ""VMDK copy_image_to_volume and copy_volume_to_image\n\nImplemented copy_image_to_volume that creates a new volume backing (vm) and\ncopies over the vmdk file from the glance image. Only glance images of disk\nformat 'vmdk' can be used to create a volume using this driver.\n\nAlso implemented copy_volume_to_image that creates a new glance image using\nthe volume's vmdk file. The steps involved are to take a snapshot of volume\nvmdk, take a copy of this read only file and upload to glance.\n\nImplements: blueprint vmware-vmdk-cinder-driver\nChange-Id: I00d22861f4e01ae0862dbf4b60af314c475b7d38\n""}, {'number': 3, 'created': '2013-08-24 17:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c62a76970338abb86944d612f38ff075ba1eb799', 'message': ""VMDK copy_image_to_volume and copy_volume_to_image\n\nImplemented copy_image_to_volume that creates a new volume backing (vm) and\ncopies over the vmdk file from the glance image. Only glance images of disk\nformat 'vmdk' can be used to create a volume using this driver.\n\nAlso implemented copy_volume_to_image that creates a new glance image using\nthe volume's vmdk file. The steps involved are to take a snapshot of volume\nvmdk, take a copy of this read only file and upload to glance.\n\nImplements: blueprint vmware-vmdk-cinder-driver\nChange-Id: I00d22861f4e01ae0862dbf4b60af314c475b7d38\n""}, {'number': 4, 'created': '2013-08-24 17:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b8441ac67c52a74282deffcd47a2b4fc4f749ec5', 'message': ""VMDK copy_image_to_volume and copy_volume_to_image\n\nImplemented copy_image_to_volume that creates a new volume backing (vm) and\ncopies over the vmdk file from the glance image. Only glance images of disk\nformat 'vmdk' can be used to create a volume using this driver.\n\nAlso implemented copy_volume_to_image that creates a new glance image using\nthe volume's vmdk file. The steps involved are to take a snapshot of volume\nvmdk, take a copy of this read only file and upload to glance.\n\nImplements: blueprint vmware-vmdk-cinder-driver\nChange-Id: I00d22861f4e01ae0862dbf4b60af314c475b7d38\n""}, {'number': 5, 'created': '2013-08-27 09:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9bfbab7de8878f19d80f23822c80a743c0b38509', 'message': ""VMDK copy_image_to_volume and copy_volume_to_image\n\nImplemented copy_image_to_volume that creates a new volume backing (vm) and\ncopies over the vmdk file from the glance image. Only glance images of disk\nformat 'vmdk' can be used to create a volume using this driver.\n\nAlso implemented copy_volume_to_image that creates a new glance image using\nthe volume's vmdk file. The steps involved are to take a snapshot of volume\nvmdk, take a copy of this read only file and upload to glance.\n\nImplements: blueprint vmware-vmdk-cinder-driver\nChange-Id: I00d22861f4e01ae0862dbf4b60af314c475b7d38\n""}, {'number': 6, 'created': '2013-08-27 09:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6145a5768ae92162b7a537013072aad3f60365c6', 'message': ""VMDK copy_image_to_volume and copy_volume_to_image\n\nImplemented copy_image_to_volume that creates a new volume backing (vm) and\ncopies over the vmdk file from the glance image. Only glance images of disk\nformat 'vmdk' can be used to create a volume using this driver.\n\nAlso implemented copy_volume_to_image that creates a new glance image using\nthe volume's vmdk file. The steps involved are to take a snapshot of volume\nvmdk, take a copy of this read only file and upload to glance.\n\nImplements: blueprint vmware-vmdk-cinder-driver\nChange-Id: I00d22861f4e01ae0862dbf4b60af314c475b7d38\n""}, {'number': 7, 'created': '2013-08-27 14:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71065ff3ddf32b7636c4484537c5f344dbfd3610', 'message': ""VMDK copy_image_to_volume and copy_volume_to_image\n\nImplemented copy_image_to_volume that creates a new volume backing (vm) and\ncopies over the vmdk file from the glance image. Only glance images of disk\nformat 'vmdk' can be used to create a volume using this driver.\n\nAlso implemented copy_volume_to_image that creates a new glance image using\nthe volume's vmdk file. The steps involved are to take a snapshot of volume\nvmdk, take a copy of this read only file and upload to glance.\n\nImplements: blueprint vmware-vmdk-cinder-driver\nChange-Id: I00d22861f4e01ae0862dbf4b60af314c475b7d38\n""}, {'number': 8, 'created': '2013-08-29 07:09:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c4cf762f58259cb7e7035f39ff5728fff28314bb', 'message': ""VMDK copy_image_to_volume and copy_volume_to_image\n\nImplemented copy_image_to_volume that creates a new volume backing (vm) and\ncopies over the vmdk file from the glance image. Only glance images of disk\nformat 'vmdk' can be used to create a volume using this driver.\n\nAlso implemented copy_volume_to_image that creates a new glance image using\nthe volume's vmdk file. The steps involved are to take a snapshot of volume\nvmdk, take a copy of this read only file and upload to glance.\n\nCleaned up docstrings as pointed out in earlier reviews.\n\nImplements: blueprint vmware-vmdk-cinder-driver\nChange-Id: I00d22861f4e01ae0862dbf4b60af314c475b7d38\n""}, {'number': 9, 'created': '2013-09-02 10:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cf8c2be3ab4141ca9756b9e573ea6b3d107c34fc', 'message': ""VMDK copy_image_to_volume and copy_volume_to_image\n\nImplemented copy_image_to_volume that creates a new volume backing (vm) and\ncopies over the vmdk file from the glance image. Only glance images of disk\nformat 'vmdk' can be used to create a volume using this driver.\n\nAlso implemented copy_volume_to_image that creates a new glance image using\nthe volume's vmdk file. The steps involved are to take a snapshot of volume\nvmdk, take a copy of this read only file and upload to glance.\n\nCleaned up docstrings as pointed out in earlier reviews.\n\nAdded timeout to avoid blocking wait on read/write threads and also fixed a\nbug to upload image from copy of vmdk instead of from original vmdk during\nupload to glance.\n\nImplements: blueprint vmware-vmdk-cinder-driver\nChange-Id: I00d22861f4e01ae0862dbf4b60af314c475b7d38\n""}, {'number': 10, 'created': '2013-09-04 23:56:28.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/vmware/vmware_images.py', 'cinder/volume/drivers/vmware/io_util.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/tests/test_vmware_vmdk.py', 'cinder/image/glance.py', 'cinder/volume/drivers/vmware/read_write_util.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b9d33d44cb1456b63f731f23b21245ecaa75f497', 'message': ""VMDK copy_image_to_volume and copy_volume_to_image\n\nImplemented copy_image_to_volume that creates a new volume backing (vm) and\ncopies over the vmdk file from the glance image. Only glance images of disk\nformat 'vmdk' can be used to create a volume using this driver.\n\nAlso implemented copy_volume_to_image that creates a new glance image using\nthe volume's vmdk file. The steps involved are to take a snapshot of volume\nvmdk, take a copy of this read only file and upload to glance.\n\nCleaned up docstrings as pointed out in earlier reviews.\n\nAdded timeout to avoid blocking wait on read/write threads and also fixed a\nbug to upload image from copy of vmdk instead of from original vmdk during\nupload to glance.\n\nImplements: blueprint vmware-vmdk-cinder-driver\nChange-Id: I00d22861f4e01ae0862dbf4b60af314c475b7d38\n""}]",60,43465,b9d33d44cb1456b63f731f23b21245ecaa75f497,46,9,10,7948,,,0,"VMDK copy_image_to_volume and copy_volume_to_image

Implemented copy_image_to_volume that creates a new volume backing (vm) and
copies over the vmdk file from the glance image. Only glance images of disk
format 'vmdk' can be used to create a volume using this driver.

Also implemented copy_volume_to_image that creates a new glance image using
the volume's vmdk file. The steps involved are to take a snapshot of volume
vmdk, take a copy of this read only file and upload to glance.

Cleaned up docstrings as pointed out in earlier reviews.

Added timeout to avoid blocking wait on read/write threads and also fixed a
bug to upload image from copy of vmdk instead of from original vmdk during
upload to glance.

Implements: blueprint vmware-vmdk-cinder-driver
Change-Id: I00d22861f4e01ae0862dbf4b60af314c475b7d38
",git fetch https://review.opendev.org/openstack/cinder refs/changes/65/43465/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/vmware/vmware_images.py', 'cinder/volume/drivers/vmware/io_util.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/tests/test_vmware_vmdk.py', 'cinder/image/glance.py', 'cinder/volume/drivers/vmware/read_write_util.py']",7,217f3f14e0844a7c802b3031b61204ff96187032,bp/vmware-vmdk-cinder-driver,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (c) 2013 VMware, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Classes to handle image files. Collection of classes to handle image upload/download to/from Image service (like Glance image storage and retrieval service) from/to VMware server. """""" import httplib import urllib import urllib2 import urlparse from cinder.openstack.common import log as logging LOG = logging.getLogger(__name__) USER_AGENT = 'OpenStack-ESX-Adapter' READ_CHUNKSIZE = 65536 class GlanceFileRead(object): """"""Glance file read handler class."""""" def __init__(self, glance_read_iter): self.glance_read_iter = glance_read_iter self.iter = self.get_next() def read(self, chunk_size): """"""Read an item from the queue. The chunk size is ignored for the Client ImageBodyIterator uses its own CHUNKSIZE. """""" try: return self.iter.next() except StopIteration: return """" def get_next(self): """"""Get the next item from the image iterator."""""" for data in self.glance_read_iter: yield data def close(self): """"""A dummy close just to maintain consistency."""""" pass class VMwareHTTPFile(object): """"""Base class for HTTP file."""""" def __init__(self, file_handle): self.eof = False self.file_handle = file_handle def set_eof(self, eof): """"""Set the end of file marker."""""" self.eof = eof def get_eof(self): """"""Check if the end of file has been reached."""""" return self.eof def close(self): """"""Close the file handle."""""" try: self.file_handle.close() except Exception as exc: LOG.exception(exc) def __del__(self): """"""Close the file handle on garbage collection."""""" self.close() def _build_vim_cookie_headers(self, vim_cookies): """"""Build ESX host session cookie headers."""""" cookie_header = """" for vim_cookie in vim_cookies: cookie_header = vim_cookie.name + '=' + vim_cookie.value break return cookie_header def write(self, data): """"""Write data to the file."""""" raise NotImplementedError() def read(self, chunk_size): """"""Read a chunk of data."""""" raise NotImplementedError() def get_size(self): """"""Get size of the file to be read."""""" raise NotImplementedError() class VMwareHTTPWriteFile(VMwareHTTPFile): """"""VMware file write handler class."""""" def __init__(self, host, data_center_name, datastore_name, cookies, file_path, file_size, scheme='https'): base_url = '%s://%s/folder/%s' % (scheme, host, file_path) param_list = {'dcPath': data_center_name, 'dsName': datastore_name} base_url = base_url + '?' + urllib.urlencode(param_list) _urlparse = urlparse.urlparse(base_url) scheme, netloc, path, params, query, fragment = _urlparse if scheme == 'http': conn = httplib.HTTPConnection(netloc) elif scheme == 'https': conn = httplib.HTTPSConnection(netloc) conn.putrequest('PUT', path + '?' + query) conn.putheader('User-Agent', USER_AGENT) conn.putheader('Content-Length', file_size) conn.putheader('Cookie', self._build_vim_cookie_headers(cookies)) conn.endheaders() self.conn = conn VMwareHTTPFile.__init__(self, conn) def write(self, data): """"""Write to the file."""""" self.file_handle.send(data) def close(self): """"""Get the response and close the connection."""""" try: self.conn.getresponse() except Exception as excep: LOG.debug(_(""Exception during HTTP connection close in "" ""VMwareHTTPWrite. Exception is %s."") % excep) super(VMwareHTTPWriteFile, self).close() class VMwareHTTPReadFile(VMwareHTTPFile): """"""VMware file read handler class."""""" def __init__(self, host, data_center_name, datastore_name, cookies, file_path, scheme='https'): base_url = '%s://%s/folder/%s' % (scheme, host, urllib.pathname2url(file_path)) param_list = {'dcPath': data_center_name, 'dsName': datastore_name} base_url = base_url + '?' + urllib.urlencode(param_list) headers = {'User-Agent': USER_AGENT, 'Cookie': self._build_vim_cookie_headers(cookies)} request = urllib2.Request(base_url, None, headers) conn = urllib2.urlopen(request) VMwareHTTPFile.__init__(self, conn) def read(self, chunk_size): """"""Read a chunk of data."""""" # We are ignoring the chunk size passed for we want the pipe to hold # data items of the chunk-size that Glance Client uses for read # while writing. return self.file_handle.read(READ_CHUNKSIZE) def get_size(self): """"""Get size of the file to be read."""""" return self.file_handle.headers.get('Content-Length', -1) ",,1059,30
openstack%2Fglance~master~I08b92532d1469ee03b976e2522e12a4540f0dae2,openstack/glance,master,I08b92532d1469ee03b976e2522e12a4540f0dae2,Add unit test for migration 012,MERGED,2013-07-31 17:50:14.000000000,2013-09-05 10:00:27.000000000,2013-09-05 10:00:27.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 177}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 6493}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-07-31 17:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b60782800e07f008eeb730f8e0f6d5091e78cc98', 'message': 'Add unit test for migration 012\n\nThis continues implementing unit tests for the migrations that are\ncurrently missing them\n\nChange-Id: I08b92532d1469ee03b976e2522e12a4540f0dae2\n'}, {'number': 2, 'created': '2013-08-19 20:48:06.000000000', 'files': ['glance/tests/unit/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/ad6c535314ba9770d90818213b0de339399a6e3d', 'message': 'Add unit test for migration 012\n\nThis continues implementing unit tests for the migrations that are\ncurrently missing them\n\nChange-Id: I08b92532d1469ee03b976e2522e12a4540f0dae2\n'}]",2,39536,ad6c535314ba9770d90818213b0de339399a6e3d,17,7,2,100,,,0,"Add unit test for migration 012

This continues implementing unit tests for the migrations that are
currently missing them

Change-Id: I08b92532d1469ee03b976e2522e12a4540f0dae2
",git fetch https://review.opendev.org/openstack/glance refs/changes/36/39536/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/test_migrations.py'],1,b60782800e07f008eeb730f8e0f6d5091e78cc98,migration-012-unit-test," def _prerun_012(self, engine): """"""Test rows in images have id changes from int to varchar(32) and value changed from int to UUID. Also test image_members and image_properties gets updated to point to new UUID keys"""""" images = get_table(engine, 'images') image_members = get_table(engine, 'image_members') image_properties = get_table(engine, 'image_properties') # Insert kernel, ramdisk and normal images now = timeutils.utcnow() data = {'created_at': now, 'updated_at': now, 'status': 'active', 'deleted': False, 'is_public': True, 'min_disk': 0, 'min_ram': 0} test_data = {} for name in ('kernel', 'ramdisk', 'normal'): data['name'] = '%s migration 012 test' % name result = images.insert().values(data).execute() test_data[name] = result.inserted_primary_key[0] # Insert image_members and image_properties rows data = {'created_at': now, 'updated_at': now, 'deleted': False, 'image_id': test_data['normal'], 'member': 'foobar', 'can_share': False} result = image_members.insert().values(data).execute() test_data['member'] = result.inserted_primary_key[0] data = {'created_at': now, 'updated_at': now, 'deleted': False, 'image_id': test_data['normal'], 'name': 'ramdisk_id', 'value': test_data['ramdisk']} result = image_properties.insert().values(data).execute() test_data['properties'] = [result.inserted_primary_key[0]] data.update({'name': 'kernel_id', 'value': test_data['kernel']}) result = image_properties.insert().values(data).execute() test_data['properties'].append(result.inserted_primary_key) return test_data def _check_012(self, engine, test_data): images = get_table(engine, 'images') image_members = get_table(engine, 'image_members') image_properties = get_table(engine, 'image_properties') # Find kernel, ramdisk and normal images. Make sure id has been # updated uuids = {} for name in ('kernel', 'ramdisk', 'normal'): image_name = '%s migration 012 test' % name rows = images.select()\ .where(images.c.name == image_name)\ .execute().fetchall() self.assertEquals(len(rows), 1) self.assertTrue(uuidutils.is_uuid_like(rows[0]['id'])) uuids[name] = rows[0]['id'] # Find all image_members to ensure image_id has been updated results = image_members.select()\ .where(image_members.c.image_id == uuids['normal'])\ .execute().fetchall() self.assertEquals(len(results), 1) # Find all image_properties to ensure image_id has been updated # as well as ensure kernel_id and ramdisk_id values have been # updated too results = image_properties.select()\ .where(image_properties.c.image_id == uuids['normal'])\ .execute().fetchall() self.assertEquals(len(results), 2) for row in results: self.assertIn(row['name'], ('kernel_id', 'ramdisk_id')) if row['name'] == 'kernel_id': self.assertEqual(row['value'], uuids['kernel']) if row['name'] == 'ramdisk_id': self.assertEqual(row['value'], uuids['ramdisk']) ",,80,0
openstack%2Ftempest~master~I7a5d4b473588757d21b461337df493e8046e1d09,openstack/tempest,master,I7a5d4b473588757d21b461337df493e8046e1d09,Restrict Volume type deletion with volumes assoc,MERGED,2013-09-02 16:29:39.000000000,2013-09-05 10:00:25.000000000,2013-09-05 10:00:25.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 2759}, {'_account_id': 5292}, {'_account_id': 7051}, {'_account_id': 8625}]","[{'number': 1, 'created': '2013-09-02 16:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3622b0e69c8ccc462e27f53a817053bb2e36a7dc', 'message': 'Restrict Volume type deletion with volumes assoc\n\nUpdated volume_type_destroy method to throw exception\nfor volume type delete with associated volumes.\n\nCloses-Bug: #1215329\n\ntag:doc-impact\n\nChange-Id: I7a5d4b473588757d21b461337df493e8046e1d09\n'}, {'number': 2, 'created': '2013-09-02 16:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/869260e92306f909768c5e2104e52aa2c016f869', 'message': 'Restrict Volume type deletion with volumes assoc\n\nUpdated the delete_volume method to wait till the\nvolume is deleted before type is delted.\n\nCloses-Bug: #1215329\n\ntag:doc-impact\n\nChange-Id: I7a5d4b473588757d21b461337df493e8046e1d09\n'}, {'number': 3, 'created': '2013-09-02 17:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/99eeb63daa693a5f0d748abdf27d6aee7c140920', 'message': 'Restrict Volume type deletion with volumes assoc\n\nUpdated the delete_volume method to wait till the\nvolume is deleted before type is delted.\n\nCloses-Bug: #1215329\n\ntag:doc-impact\n\nChange-Id: I7a5d4b473588757d21b461337df493e8046e1d09\n'}, {'number': 4, 'created': '2013-09-03 06:19:59.000000000', 'files': ['tempest/api/volume/admin/test_volume_types.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/82bd818cebf0c6907af0d4844b1e80ec71be01ff', 'message': 'Restrict Volume type deletion with volumes assoc\n\nUpdated the delete_volume method to wait till the\nvolume is deleted before type is delted.\n\nCloses-Bug: #1215329\n\ntag:doc-impact\n\nChange-Id: I7a5d4b473588757d21b461337df493e8046e1d09\n'}]",0,44743,82bd818cebf0c6907af0d4844b1e80ec71be01ff,15,8,4,7051,,,0,"Restrict Volume type deletion with volumes assoc

Updated the delete_volume method to wait till the
volume is deleted before type is delted.

Closes-Bug: #1215329

tag:doc-impact

Change-Id: I7a5d4b473588757d21b461337df493e8046e1d09
",git fetch https://review.opendev.org/openstack/tempest refs/changes/43/44743/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/volume/admin/test_volume_types.py'],1,3622b0e69c8ccc462e27f53a817053bb2e36a7dc,bug/1215329, while not self.volumes_client.is_resource_deleted(volume_id): pass,,2,1
openstack%2Fswift~master~Ie06ed2955838556d5399a49ba3599dfbca4f7512,openstack/swift,master,Ie06ed2955838556d5399a49ba3599dfbca4f7512,Flake8 container test_server.py (11 of 12),MERGED,2013-09-01 19:15:54.000000000,2013-09-05 10:00:23.000000000,2013-09-05 10:00:23.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-09-01 19:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1fe17b9922fbe745f8c92e87ea95dc30c7102459', 'message': 'Flake8 container test_server.py (11 of 12)\n\nChange-Id: Ie06ed2955838556d5399a49ba3599dfbca4f7512\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-09-01 20:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f5e340cf91e95928af5069b1879160ed5d08fee3', 'message': 'Flake8 container test_server.py (11 of 12)\n\nChange-Id: Ie06ed2955838556d5399a49ba3599dfbca4f7512\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 3, 'created': '2013-09-01 20:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f82c01ce831d1864627f55bb877f10e33b23c776', 'message': 'Flake8 container test_server.py (11 of 12)\n\nChange-Id: Ie06ed2955838556d5399a49ba3599dfbca4f7512\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 4, 'created': '2013-09-05 02:26:41.000000000', 'files': ['test/unit/container/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/14037b46e694399eb722c89665680a05684c2d33', 'message': 'Flake8 container test_server.py (11 of 12)\n\nChange-Id: Ie06ed2955838556d5399a49ba3599dfbca4f7512\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",0,44625,14037b46e694399eb722c89665680a05684c2d33,20,7,4,6198,,,0,"Flake8 container test_server.py (11 of 12)

Change-Id: Ie06ed2955838556d5399a49ba3599dfbca4f7512
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/25/44625/4 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/container/test_server.py'],1,1fe17b9922fbe745f8c92e87ea95dc30c7102459,pep8-test, resp = req.get_response(self.controller) self.assert_(resp.status.startswith('201')) self.assert_(resp.status.startswith('204')) self.assert_(resp.status.startswith('204')) self.assert_(resp.status.startswith('201')), req.get_response(self.controller),5,1
openstack%2Fnova~master~I262163c7e05e6a6fb79265e904ce761fc3ac5806,openstack/nova,master,I262163c7e05e6a6fb79265e904ce761fc3ac5806,Port to oslo.messaging.Notifier API,MERGED,2013-08-29 23:59:51.000000000,2013-09-05 09:59:55.000000000,2013-09-05 09:59:52.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5511}]","[{'number': 1, 'created': '2013-08-29 23:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96d76a39ac86235b61a5ddab5b70773af3626f08', 'message': ""Port to oslo.messaging.Notifier API\n\nAdd a temporary nova.notifier.Notifier helper class which translates\noslo.messaging.Notifier compatible calls into openstack.common.notifier\ncompatible calls.\n\nThis allows us to port the notifier code over to the oslo.messaging API\nbefore actually switching over oslo.messaging fully.\n\nThis patch contains no functional changes at all, except that all\nnotifications go through this temporary helper class.\n\nSome notes on the new API:\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify().\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nblueprint: oslo-messaging\nChange-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806\n""}, {'number': 2, 'created': '2013-08-30 00:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d34977bd17f7230dd50d5ae4d1cfd38d615b896', 'message': ""Port to oslo.messaging.Notifier API\n\nAdd a temporary nova.notifier.Notifier helper class which translates\noslo.messaging.Notifier compatible calls into openstack.common.notifier\ncompatible calls.\n\nThis allows us to port the notifier code over to the oslo.messaging API\nbefore actually switching over oslo.messaging fully.\n\nThis patch contains no functional changes at all, except that all\nnotifications go through this temporary helper class.\n\nSome notes on the new API:\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify().\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nblueprint: oslo-messaging\nChange-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806\n""}, {'number': 3, 'created': '2013-08-30 06:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2176a405d436a883d084f2f2345b95c90d1ffa13', 'message': ""Port to oslo.messaging.Notifier API\n\nAdd a temporary nova.notifier.Notifier helper class which translates\noslo.messaging.Notifier compatible calls into openstack.common.notifier\ncompatible calls.\n\nThis allows us to port the notifier code over to the oslo.messaging API\nbefore actually switching over oslo.messaging fully.\n\nThis patch contains no functional changes at all, except that all\nnotifications go through this temporary helper class.\n\nSome notes on the new API:\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify().\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nblueprint: oslo-messaging\nChange-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806\n""}, {'number': 4, 'created': '2013-09-02 16:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80422ce66b42a08000cb60b2b559cb8a3caca39f', 'message': ""Port to oslo.messaging.Notifier API\n\nAdd a temporary nova.notifier.Notifier helper class which translates\noslo.messaging.Notifier compatible calls into openstack.common.notifier\ncompatible calls.\n\nThis allows us to port the notifier code over to the oslo.messaging API\nbefore actually switching over oslo.messaging fully.\n\nThis patch contains no functional changes at all, except that all\nnotifications go through this temporary helper class.\n\nSome notes on the new API:\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify().\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nblueprint: oslo-messaging\nChange-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806\n""}, {'number': 5, 'created': '2013-09-03 18:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0cd097cec57c0978e8fd8a444c328c319cab6d3', 'message': ""Port to oslo.messaging.Notifier API\n\nAdd a temporary nova.notifier.Notifier helper class which translates\noslo.messaging.Notifier compatible calls into openstack.common.notifier\ncompatible calls.\n\nThis allows us to port the notifier code over to the oslo.messaging API\nbefore actually switching over oslo.messaging fully.\n\nThis patch contains no functional changes at all, except that all\nnotifications go through this temporary helper class.\n\nSome notes on the new API:\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify().\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nblueprint: oslo-messaging\nChange-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806\n""}, {'number': 6, 'created': '2013-09-03 20:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e664242746dd3403accb1d893a693e3eb100cd3', 'message': ""Port to oslo.messaging.Notifier API\n\nAdd a temporary nova.notifier.Notifier helper class which translates\noslo.messaging.Notifier compatible calls into openstack.common.notifier\ncompatible calls.\n\nThis allows us to port the notifier code over to the oslo.messaging API\nbefore actually switching over oslo.messaging fully.\n\nThis patch contains no functional changes at all, except that all\nnotifications go through this temporary helper class.\n\nSome notes on the new API:\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify().\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    who we call it.\n\nblueprint: oslo-messaging\nChange-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806\n""}, {'number': 7, 'created': '2013-09-04 06:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06d87db94fcc0512338809fd09d031325a64d051', 'message': ""Port to oslo.messaging.Notifier API\n\nAdd a temporary nova.notifier.Notifier helper class which translates\noslo.messaging.Notifier compatible calls into openstack.common.notifier\ncompatible calls.\n\nThis allows us to port the notifier code over to the oslo.messaging API\nbefore actually switching over oslo.messaging fully.\n\nThis patch contains no functional changes at all, except that all\nnotifications go through this temporary helper class.\n\nSome notes on the new API:\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify().\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    how we call it.\n\nblueprint: oslo-messaging\nChange-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806\n""}, {'number': 8, 'created': '2013-09-04 16:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd18136569ef86f33093d3349b1b83859d528f7e', 'message': ""Port to oslo.messaging.Notifier API\n\nAdd a temporary nova.notifier.Notifier helper class which translates\noslo.messaging.Notifier compatible calls into openstack.common.notifier\ncompatible calls.\n\nThis allows us to port the notifier code over to the oslo.messaging API\nbefore actually switching over oslo.messaging fully.\n\nThis patch contains no functional changes at all, except that all\nnotifications go through this temporary helper class.\n\nSome notes on the new API:\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify().\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    how we call it.\n\nblueprint: oslo-messaging\nChange-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806\n""}, {'number': 9, 'created': '2013-09-04 16:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/091948c1021befbcdfd21af7185de54cd9051aaf', 'message': ""Port to oslo.messaging.Notifier API\n\nAdd a temporary nova.notifier.Notifier helper class which translates\noslo.messaging.Notifier compatible calls into openstack.common.notifier\ncompatible calls.\n\nThis allows us to port the notifier code over to the oslo.messaging API\nbefore actually switching over oslo.messaging fully.\n\nThis patch contains no functional changes at all, except that all\nnotifications go through this temporary helper class.\n\nSome notes on the new API:\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify().\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    how we call it.\n\nblueprint: oslo-messaging\nChange-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806\n""}, {'number': 10, 'created': '2013-09-04 20:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1682dfcc532c7ea2335de8ebfb91f3e4a78148af', 'message': ""Port to oslo.messaging.Notifier API\n\nAdd a temporary nova.notifier.Notifier helper class which translates\noslo.messaging.Notifier compatible calls into openstack.common.notifier\ncompatible calls.\n\nThis allows us to port the notifier code over to the oslo.messaging API\nbefore actually switching over oslo.messaging fully.\n\nThis patch contains no functional changes at all, except that all\nnotifications go through this temporary helper class.\n\nSome notes on the new API:\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify().\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    how we call it.\n\nblueprint: oslo-messaging\nChange-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806\n""}, {'number': 11, 'created': '2013-09-05 05:27:09.000000000', 'files': ['nova/scheduler/utils.py', 'nova/tests/test_notifications.py', 'nova/tests/conductor/test_conductor.py', 'nova/scheduler/driver.py', 'nova/tests/fake_notifier.py', 'nova/tests/compute/test_compute.py', 'nova/tests/test_exception.py', 'nova/notifications.py', 'nova/virt/libvirt/driver.py', 'nova/tests/compute/test_compute_utils.py', 'nova/scheduler/filter_scheduler.py', 'nova/notifier.py', 'nova/utils.py', 'nova/compute/manager.py', 'nova/compute/api.py', 'nova/compute/utils.py', 'nova/tests/scheduler/test_scheduler_utils.py', 'nova/network/floating_ips.py', 'nova/tests/compute/test_compute_api.py', 'nova/exception.py', 'etc/nova/nova.conf.sample', 'nova/manager.py', 'nova/tests/scheduler/test_scheduler.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/60a91f475a352e5e86bbd07b510cb32874110fef', 'message': ""Port to oslo.messaging.Notifier API\n\nAdd a temporary nova.notifier.Notifier helper class which translates\noslo.messaging.Notifier compatible calls into openstack.common.notifier\ncompatible calls.\n\nThis allows us to port the notifier code over to the oslo.messaging API\nbefore actually switching over oslo.messaging fully.\n\nThis patch contains no functional changes at all, except that all\nnotifications go through this temporary helper class.\n\nSome notes on the new API:\n\n  * The notifier API is changed so that what was previously global state\n    is now encapsulated in a Notifier object. This object also includes\n    the publisher_id and has error()/info()/etc. methods rather than\n    just notify().\n\n  * The notify_decorator() helper wasn't carried across to the new API\n    because its semantics are a bit weird. Something along these lines\n    could be added in future, though.\n\n  * We use a fake Notifier implementation for tests because there's no\n    API in oslo.messaging to actually get the notifications queued\n    up in the fake notification driver, which is a bit dumb. However,\n    this feels like the right thing to do anyway. We're not wanting\n    to test oslo.messaging.Notifier itself, but rather we want to test\n    how we call it.\n\nblueprint: oslo-messaging\nChange-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806\n""}]",13,44377,60a91f475a352e5e86bbd07b510cb32874110fef,64,8,11,1247,,,0,"Port to oslo.messaging.Notifier API

Add a temporary nova.notifier.Notifier helper class which translates
oslo.messaging.Notifier compatible calls into openstack.common.notifier
compatible calls.

This allows us to port the notifier code over to the oslo.messaging API
before actually switching over oslo.messaging fully.

This patch contains no functional changes at all, except that all
notifications go through this temporary helper class.

Some notes on the new API:

  * The notifier API is changed so that what was previously global state
    is now encapsulated in a Notifier object. This object also includes
    the publisher_id and has error()/info()/etc. methods rather than
    just notify().

  * The notify_decorator() helper wasn't carried across to the new API
    because its semantics are a bit weird. Something along these lines
    could be added in future, though.

  * We use a fake Notifier implementation for tests because there's no
    API in oslo.messaging to actually get the notifications queued
    up in the fake notification driver, which is a bit dumb. However,
    this feels like the right thing to do anyway. We're not wanting
    to test oslo.messaging.Notifier itself, but rather we want to test
    how we call it.

blueprint: oslo-messaging
Change-Id: I262163c7e05e6a6fb79265e904ce761fc3ac5806
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/44377/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/utils.py', 'nova/tests/test_notifications.py', 'nova/tests/conductor/test_conductor.py', 'nova/tests/scheduler/test_scheduler_utils.py', 'nova/scheduler/driver.py', 'nova/tests/fake_notifier.py', 'nova/tests/compute/test_compute.py', 'nova/network/floating_ips.py', 'nova/tests/test_exception.py', 'nova/tests/compute/test_compute_api.py', 'nova/exception.py', 'nova/notifications.py', 'nova/virt/libvirt/driver.py', 'nova/manager.py', 'nova/tests/compute/test_compute_utils.py', 'nova/scheduler/filter_scheduler.py', 'nova/tests/scheduler/test_scheduler.py', 'nova/conductor/manager.py', 'nova/notifier.py', 'nova/utils.py', 'nova/compute/manager.py', 'nova/compute/api.py', 'nova/compute/utils.py']",23,96d76a39ac86235b61a5ddab5b70773af3626f08,bp/oslo-messaging,"from nova import notifier as notifydef notify_usage_exists(notifier, context, instance_ref, current_period=False, :param notifier: a messaging.Notifier notify_about_instance_usage(notifier, context, instance_ref, 'exists',def notify_about_instance_usage(notifier, context, instance, event_suffix, :param notifier: a messaging.Notifier method = notifier.error else: method = notifier.info method(context, 'compute.instance.%s' % event_suffix, usage_info) notifier = notify.get_notifier(service='aggregate', host=aggregate_identifier) notifier.info(context, 'aggregate.%s' % event_suffix, aggregate_payload)","from nova.openstack.common.notifier import api as notifier_apidef notify_usage_exists(context, instance_ref, current_period=False, notify_about_instance_usage(context, instance_ref, 'exists',def notify_about_instance_usage(context, instance, event_suffix, level = notifier_api.ERROR else: level = notifier_api.INFO notifier_api.notify(context, 'compute.%s' % host, 'compute.instance.%s' % event_suffix, level, usage_info) notifier_api.notify(context, 'aggregate.%s' % aggregate_identifier, 'aggregate.%s' % event_suffix, notifier_api.INFO, aggregate_payload)",538,381
openstack%2Fnova~master~I06c8ba323cff02804d0aef3bf56892c111f67226,openstack/nova,master,I06c8ba323cff02804d0aef3bf56892c111f67226,Fix ArchiveTestCase on PostgreSQL,MERGED,2013-08-12 13:27:03.000000000,2013-09-05 09:59:23.000000000,2013-09-05 09:59:20.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 2166}, {'_account_id': 5652}, {'_account_id': 6172}, {'_account_id': 6849}]","[{'number': 1, 'created': '2013-08-12 13:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74bfdc03d8f341081bd87997b52d94fcf9d0e9be', 'message': ""Fix ArchiveTestCase on PostgreSQL\n\ntest_archive_deleted_rows_no_id_column() filters DnsDomain instances by\nvalue of 'deleted' column (which is of type Boolean). Integer value 1\nis passed instead of boolean value True. This works great on MySQL and\nSQLite, but fails on PostgreSQL which is more strict when checking data\ntypes of passed values.\n\nBlueprint: db-api-tests-on-all-backends\n\nChange-Id: I06c8ba323cff02804d0aef3bf56892c111f67226\n""}, {'number': 2, 'created': '2013-09-02 14:15:20.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c3797dc5e2532482327c5e8c94964b1d54e9c719', 'message': ""Fix ArchiveTestCase on PostgreSQL\n\ntest_archive_deleted_rows_no_id_column() filters DnsDomain instances by\nvalue of 'deleted' column (which is of type Boolean). Integer value 1\nis passed instead of boolean value True. This works great on MySQL and\nSQLite, but fails on PostgreSQL which is more strict when checking data\ntypes of passed values.\n\nBlueprint: db-api-tests-on-all-backends\n\nChange-Id: I06c8ba323cff02804d0aef3bf56892c111f67226\n""}]",0,41410,c3797dc5e2532482327c5e8c94964b1d54e9c719,23,7,2,6849,,,0,"Fix ArchiveTestCase on PostgreSQL

test_archive_deleted_rows_no_id_column() filters DnsDomain instances by
value of 'deleted' column (which is of type Boolean). Integer value 1
is passed instead of boolean value True. This works great on MySQL and
SQLite, but fails on PostgreSQL which is more strict when checking data
types of passed values.

Blueprint: db-api-tests-on-all-backends

Change-Id: I06c8ba323cff02804d0aef3bf56892c111f67226
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/41410/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,74bfdc03d8f341081bd87997b52d94fcf9d0e9be,bp/db-api-tests-on-all-backends, values(deleted=True), values(deleted=1),1,1
openstack%2Fnova~master~If55648e5cc2ed5b7ea44aad08205689d99338856,openstack/nova,master,If55648e5cc2ed5b7ea44aad08205689d99338856,PCI passthrough Libvirt vm config,MERGED,2013-08-02 10:32:29.000000000,2013-09-05 09:58:51.000000000,2013-09-05 09:58:48.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 642}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 4458}, {'_account_id': 4491}, {'_account_id': 4573}, {'_account_id': 5441}, {'_account_id': 6524}, {'_account_id': 6904}, {'_account_id': 7543}, {'_account_id': 7641}]","[{'number': 1, 'created': '2013-08-02 10:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6eff8c36a83507e4f1f47a0a9958904dcb1f3003', 'message': ""PCI passthrough Libvirt vm config\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\n""}, {'number': 2, 'created': '2013-08-02 10:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/afa0788176e9dd5f34d833e558dec9c74d205dff', 'message': ""PCI passthrough Libvirt vm config\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\n""}, {'number': 3, 'created': '2013-08-05 09:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/88d4bb38c3fba11ac84337aa7ae10f5ec10fe04b', 'message': ""PCI passthrough Libvirt vm config\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\n""}, {'number': 4, 'created': '2013-08-08 11:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8257c6cdd817e90f9b868587e1821c39f5e0dc59', 'message': ""PCI passthrough Libvirt vm config\n\n    base on Boris Pavlovic's PCI passthrough Libvirt layer WIP\n    https://review.openstack.org/#/c/27130/\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\n""}, {'number': 5, 'created': '2013-08-08 12:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9807ecdade4cfb0779ea732aa11a38116de9ce22', 'message': ""PCI passthrough Libvirt vm config\n\n    base on Boris Pavlovic's PCI passthrough Libvirt layer WIP\n    https://review.openstack.org/#/c/27130/\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\n""}, {'number': 6, 'created': '2013-08-09 08:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bcb35c4c10d5a718e2901dd64d79a3f741b37f39', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 7, 'created': '2013-08-11 07:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95e82a60ee0dcd2308038225574b5e8165ee062f', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 8, 'created': '2013-08-11 23:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5f15e277c4ac14dfdc488eb1e35fc68d33c55eb', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 9, 'created': '2013-08-12 09:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5adc8b21925f9b1eb4603245b162eba6677a395', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 10, 'created': '2013-08-13 00:08:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b29fa1d9b9368e31c8d8879aafcab63a2f1447a2', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 11, 'created': '2013-08-13 08:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bdda66a64ecf4aa73be694647cd833fc5ee91d11', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 12, 'created': '2013-08-17 00:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/674a390eed8d8d3ddd3db4bb70d4695b5ad87d5f', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 14, 'created': '2013-08-18 04:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff6d1eb5fe7f119d22618c922b993a990bd7c148', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 13, 'created': '2013-08-18 04:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d336a79fab7c1801aaa3acd23f24464f84bd2fab', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 15, 'created': '2013-08-19 06:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c31f9f0fd173036967fe33b4467fe308f3754270', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 16, 'created': '2013-08-19 07:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9394ba0946672e5e12c94384a9315346fbfdce86', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 17, 'created': '2013-08-21 03:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a836b90d13eed97cced5210f2343523d5de0e809', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbase on Boris Pavlovic's PCI passthrough Libvirt layer WIP\nhttps://review.openstack.org/#/c/27130/\n\nbp:pci-passthrough-libvirt\n\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 18, 'created': '2013-08-23 08:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8117f9ed784839710501a657885abe4967dc331', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 19, 'created': '2013-08-26 07:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d012925e0d18f695457ae612b5f76fbaad982ab', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 20, 'created': '2013-08-27 08:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a28257b6a7875acbd32052559e8444083cbb430', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 21, 'created': '2013-08-29 08:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e2cbc2779d8f9c7006fdd31e7f58283bbd29d50', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 22, 'created': '2013-08-29 08:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9454c41152c960d2515ccf6af9b460dddfab5e51', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 23, 'created': '2013-08-30 05:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9e0e19d1d597a0ecea6872c9d61e24727fb6f1b', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 24, 'created': '2013-08-30 20:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f35c134184c823cad4aaf74b18322f2e608ed61', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 25, 'created': '2013-08-30 23:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e905f20281316f4d5868cd964dab41a2be33605b', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 26, 'created': '2013-08-31 05:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc5601cd0231a7d989a4b7763112e10ea2828efd', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 27, 'created': '2013-09-02 08:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a99d3b3186eaa3ad966d33e48b3e9ab468071489', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 28, 'created': '2013-09-02 09:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c3e8e4e8ab9d93cbf372c5c5f872ba6d1381b0f', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 29, 'created': '2013-09-02 09:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b950d4acf2254c594081636c1c5135da2ef8b42', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 30, 'created': '2013-09-03 06:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e82bb140ac70dcb449fa599d82a045b703d68093', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 31, 'created': '2013-09-03 16:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f16c6f82c2c9f9ef9823efd0b64d53f9cf6df639', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 32, 'created': '2013-09-03 22:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/821e06487f2ad26217802849954f887f910b2028', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 33, 'created': '2013-09-03 23:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/791449501e560237e789d223372954985ec2dac0', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 34, 'created': '2013-09-04 03:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/357cf9c354075ad1c8e11f367dd55168bdcb3dbb', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 35, 'created': '2013-09-04 04:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c35f0e09e6ddcbb1d5cb9be0a5a28099c2f8c0e', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 36, 'created': '2013-09-04 10:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f604bb85ef1ef93cfbbac907555da711ecb9ba3d', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 38, 'created': '2013-09-04 11:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e2fdd9387daba9a13781fa46899aa5f18ad8f4c', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 37, 'created': '2013-09-04 11:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/378247dff72e3dd0d5bb24e5214c1a7b9a3c184f', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 39, 'created': '2013-09-04 18:19:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78e1f5fa2e4259fe1ca146938efeb277430b3d51', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}, {'number': 40, 'created': '2013-09-04 19:16:58.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/exception.py', 'nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_libvirt_config.py', 'nova/virt/libvirt/config.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fe760bc3278d177f9006605e7a60d4374a9cb7ca', 'message': ""PCI passthrough Libvirt vm config\n\nPCI passthrough device's xml config formatter. adding pci\npassthrough device to VM, and detach it from a VM. adapter the\nhypervisor PCI passthrough devices management interface given a\nunify interface to other PCI passthrough components.\n\nbp:pci-passthrough-libvirt\n\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\nChange-Id: If55648e5cc2ed5b7ea44aad08205689d99338856\nSigned-off-by: Yongli He <yongli.he@intel.com>\n""}]",117,39891,fe760bc3278d177f9006605e7a60d4374a9cb7ca,213,16,40,7543,,,0,"PCI passthrough Libvirt vm config

PCI passthrough device's xml config formatter. adding pci
passthrough device to VM, and detach it from a VM. adapter the
hypervisor PCI passthrough devices management interface given a
unify interface to other PCI passthrough components.

bp:pci-passthrough-libvirt

Co-authored-by: Boris Pavlovic <boris@pavlovic.me>
Change-Id: If55648e5cc2ed5b7ea44aad08205689d99338856
Signed-off-by: Yongli He <yongli.he@intel.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/39891/11 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_libvirt_config.py', 'nova/virt/libvirt/config.py']",4,6eff8c36a83507e4f1f47a0a9958904dcb1f3003,pci-passthrough-enhancement,"class LibvirtConfigGuestPciPassthrough(LibvirtConfigGuestDevice): def __init__(self, **kwargs): super(LibvirtConfigGuestPciPassthrough, self).\ __init__(root_name=""hostdev"", **kwargs) self.mode = 'subsystem' self.type = 'pci' self.managed = 'yes' self.domain = None self.bus = None self.slot = None self.function = None def format_dom(self): dev = super(LibvirtConfigGuestPciPassthrough, self).format_dom() dev.set(""mode"", self.mode) dev.set(""type"", self.type) dev.set(""managed"", self.managed) address = etree.Element(""address"", domain='0x' + self.domain, bus='0x' + self.bus, slot='0x' + self.slot, function='0x' + self.function) source = etree.Element(""source"") source.append(address) dev.append(source) return dev ",,201,6
openstack%2Fnova~master~Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba,openstack/nova,master,Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba,Add columns_to_join to instance_update_and_get_original,MERGED,2013-09-02 08:17:59.000000000,2013-09-05 09:58:19.000000000,2013-09-05 09:58:16.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 4573}, {'_account_id': 7543}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-09-02 08:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b26d9bb226bc28dfd9522a50bc6e5c1539669e8c', 'message': ""fix buggy lazy loading 'pci_devices'\n\nlibvirt:snapshot -> instance.save() expect 'pci_devices', but instance\nsave will not join loading the pci_devices, then  _from_db_object try\nto access db_inst['pci_devices'] will tigger a buggy lazy loading.\n\nChange-Id: Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba\nSigned-off-by: Yongli He\n""}, {'number': 2, 'created': '2013-09-02 09:22:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ccd3d727fe84d27b4be2674489e05c91ecadc936', 'message': ""fix buggy lazy loading 'pci_devices'\n\nlibvirt:snapshot -> instance.save() expect 'pci_devices', but instance\nsave will not join loading the pci_devices, then  _from_db_object try\nto access db_inst['pci_devices'] will tigger a buggy lazy loading.\n\nChange-Id: Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba\nSigned-off-by: Yongli He\n""}, {'number': 3, 'created': '2013-09-03 16:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/087b37b454e08c3716776d40c539864f3b955d7a', 'message': ""fix buggy lazy loading 'pci_devices' in instance.save\n\nIf 'pci_devices' is set in an instance object, instance.save() expects\n'pci_devices' attribute when calling _from_db_object(), but instance\nsave will not join loading the pci_devices. When _from_db_object()\naccesses db_inst['pci_devices'], it will tigger a buggy lazy loading.\n\nChange-Id: Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba\nSigned-off-by: Yongli He\n""}, {'number': 4, 'created': '2013-09-03 22:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/23f3f5bdc9362af528254d56a02ff80b353fc37d', 'message': 'Add columns_to_join to instance_update_and_get_original\n\nAdd a parameter to instance_update_and_get_original() to specify the\nexpecected columns to be returned.\n\nChange-Id: Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba\nSigned-off-by: Yongli He\n'}, {'number': 5, 'created': '2013-09-04 03:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e19e844a78d304cf74332733b87f3ef33854c6c5', 'message': 'Add columns_to_join to instance_update_and_get_original\n\nAdd a parameter to instance_update_and_get_original() to specify the\nexpecected columns to be returned.\n\nChange-Id: Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba\nSigned-off-by: Yongli He\n'}, {'number': 7, 'created': '2013-09-04 04:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47e35ced8192eff3b0c0324372527fdc5c051cbe', 'message': 'Add columns_to_join to instance_update_and_get_original\n\nAdd a parameter to instance_update_and_get_original() to specify the\nexpecected columns to be returned.\n\nChange-Id: Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba\nSigned-off-by: Yongli He\n'}, {'number': 6, 'created': '2013-09-04 04:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b81ff9a6d1bd8d11bf027e8f9400b5f5e5a733e3', 'message': 'Add columns_to_join to instance_update_and_get_original\n\nAdd a parameter to instance_update_and_get_original() to specify the\nexpecected columns to be returned.\n\nChange-Id: Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba\nSigned-off-by: Yongli He\n'}, {'number': 8, 'created': '2013-09-04 18:19:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/facea482d064a0ffe55850dd9329197a37eb1d81', 'message': 'Add columns_to_join to instance_update_and_get_original\n\nAdd a parameter to instance_update_and_get_original() to specify the\nexpecected columns to be returned.\n\nChange-Id: Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba\nSigned-off-by: Yongli He\n'}, {'number': 9, 'created': '2013-09-04 19:16:58.000000000', 'files': ['nova/tests/objects/test_instance.py', 'nova/tests/api/openstack/compute/plugins/v3/test_multiple_create.py', 'nova/tests/api/openstack/compute/test_servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py', 'nova/tests/api/openstack/compute/test_server_actions.py', 'nova/objects/instance.py', 'nova/tests/compute/test_shelve.py', 'nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/tests/compute/test_compute.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b058b00c5fd58a4b820555a1788d019cdf1d1531', 'message': 'Add columns_to_join to instance_update_and_get_original\n\nAdd a parameter to instance_update_and_get_original() to specify the\nexpecected columns to be returned.\n\nChange-Id: Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba\nSigned-off-by: Yongli He\n'}]",5,44645,b058b00c5fd58a4b820555a1788d019cdf1d1531,43,7,9,7543,,,0,"Add columns_to_join to instance_update_and_get_original

Add a parameter to instance_update_and_get_original() to specify the
expecected columns to be returned.

Change-Id: Ib324fdf02f3d462970cdf7c7065ddc3d87f72fba
Signed-off-by: Yongli He
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/44645/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/objects/test_instance.py', 'nova/tests/utils.py', 'nova/objects/instance.py']",3,b26d9bb226bc28dfd9522a50bc6e5c1539669e8c,pci-passthrough-enhancement," if 'pci_devices' in db_inst: if db_inst['pci_devices'] is not None: pci_devices = pci_device._make_pci_list( context, pci_device.PciDeviceList(), db_inst['pci_devices']) else: pci_devices = None else: # instance had 'pci_devices' before instance.save, reload it # form DB cause of instance.save does not join loading # pci_devices pci_devices = pci_device.PciDeviceList.\ get_by_instance_uuid(context, instance.uuid) "," if db_inst['pci_devices'] is None: pci_devices = None else: pci_devices = pci_device._make_pci_list( context, pci_device.PciDeviceList(), db_inst['pci_devices'])",81,7
openstack%2Fheat~master~I49fb4ad64dd4245b61fad28a401174b11f2b8272,openstack/heat,master,I49fb4ad64dd4245b61fad28a401174b11f2b8272,parallelize StackResource delete,MERGED,2013-08-29 18:27:01.000000000,2013-09-05 09:58:12.000000000,2013-09-05 09:58:12.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 7135}, {'_account_id': 7230}]","[{'number': 1, 'created': '2013-08-29 18:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f4f5e2e6e4355ec91c4f8987503cd6859a0f5c56', 'message': 'parallelize StackResource delete\n\nThis is fourth and last  patch in the series to implement\nparallel delete. In this patch, parallelizing StackResource\ndeletion.\n\nBlueprint parallel-delete\n\nChange-Id: I49fb4ad64dd4245b61fad28a401174b11f2b8272\n'}, {'number': 2, 'created': '2013-08-30 21:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3f569276f11f3c3eafcfc7754dd250b4258e8560', 'message': 'parallelize StackResource delete\n\nThis is fourth and last  patch in the series to implement\nparallel delete. In this patch, parallelizing StackResource\ndeletion.\n\nBlueprint parallel-delete\n\nChange-Id: I49fb4ad64dd4245b61fad28a401174b11f2b8272\n'}, {'number': 3, 'created': '2013-09-03 17:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c5bbe1fc3a34f43681c9aeb64b64dfcfd6a5e726', 'message': 'parallelize StackResource delete\n\nThis is fourth and last  patch in the series to implement\nparallel delete. In this patch, parallelizing StackResource\ndeletion.\n\nBlueprint parallel-delete\n\nChange-Id: I49fb4ad64dd4245b61fad28a401174b11f2b8272\n'}, {'number': 4, 'created': '2013-09-03 17:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a1a4b07f9572ec3c9f97433746d60450dc451b7e', 'message': 'parallelize StackResource delete\n\nThis is fourth and last  patch in the series to implement\nparallel delete. In this patch, parallelizing StackResource\ndeletion.\n\nBlueprint parallel-delete\n\nChange-Id: I49fb4ad64dd4245b61fad28a401174b11f2b8272\n'}, {'number': 5, 'created': '2013-09-04 20:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c6939e1bee4ed58b17ca3f061cdcacd3d77c4564', 'message': 'parallelize StackResource delete\n\nThis is fourth and last  patch in the series to implement\nparallel delete. In this patch, parallelizing StackResource\ndeletion.\n\nBlueprint parallel-delete\n\nChange-Id: I49fb4ad64dd4245b61fad28a401174b11f2b8272\n'}, {'number': 6, 'created': '2013-09-04 20:02:31.000000000', 'files': ['heat/engine/stack_resource.py', 'heat/engine/resources/stack.py', 'heat/engine/resources/template_resource.py', 'heat/engine/resources/dbinstance.py', 'heat/engine/resources/loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a560ca0a1bea2b20a8aab42369a2319ca53d16f8', 'message': 'parallelize StackResource delete\n\nThis is fourth and last  patch in the series to implement\nparallel delete. In this patch, parallelizing StackResource\ndeletion.\n\nBlueprint parallel-delete\n\nChange-Id: I49fb4ad64dd4245b61fad28a401174b11f2b8272\n'}]",4,44339,a560ca0a1bea2b20a8aab42369a2319ca53d16f8,31,5,6,7230,,,0,"parallelize StackResource delete

This is fourth and last  patch in the series to implement
parallel delete. In this patch, parallelizing StackResource
deletion.

Blueprint parallel-delete

Change-Id: I49fb4ad64dd4245b61fad28a401174b11f2b8272
",git fetch https://review.opendev.org/openstack/heat refs/changes/39/44339/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/stack_resource.py', 'heat/engine/resources/stack.py', 'heat/engine/resources/dbinstance.py', 'heat/engine/resources/template_resource.py', 'heat/engine/resources/loadbalancer.py']",5,f4f5e2e6e4355ec91c4f8987503cd6859a0f5c56,bp/parallel-delete, return self.delete_nested(), self.delete_nested(),17,5
openstack%2Fcinder~master~Idc603dcfab18601dd4246c623d34be5933434f84,openstack/cinder,master,Idc603dcfab18601dd4246c623d34be5933434f84,Fixes brick Nova pep8 violation for lvm.py,MERGED,2013-09-04 18:30:48.000000000,2013-09-05 09:58:10.000000000,2013-09-05 09:58:10.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2759}]","[{'number': 1, 'created': '2013-09-04 18:30:48.000000000', 'files': ['cinder/brick/local_dev/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9faa32599cf86c4111d0d6cd0a7c377061f2ee6d', 'message': 'Fixes brick Nova pep8 violation for lvm.py\n\nRunning pep8 tests in Nova gives a violation\nin lvm.py for not importing a module.  This\nis a simple fix to import the module itself\ninstead of only importing a function in the\nmodule.\n\nFixes bug #1220849\n\nChange-Id: Idc603dcfab18601dd4246c623d34be5933434f84\n'}]",0,45090,9faa32599cf86c4111d0d6cd0a7c377061f2ee6d,9,4,1,5997,,,0,"Fixes brick Nova pep8 violation for lvm.py

Running pep8 tests in Nova gives a violation
in lvm.py for not importing a module.  This
is a simple fix to import the module itself
instead of only importing a function in the
module.

Fixes bug #1220849

Change-Id: Idc603dcfab18601dd4246c623d34be5933434f84
",git fetch https://review.opendev.org/openstack/cinder refs/changes/90/45090/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/brick/local_dev/lvm.py'],1,9faa32599cf86c4111d0d6cd0a7c377061f2ee6d,bug/1220849,"import itertools for vg, name, size in itertools.izip(*[iter(volumes)] * 3):","from itertools import izip for vg, name, size in izip(*[iter(volumes)] * 3):",2,2
openstack%2Fneutron~master~I881bde907f4c90de4c919d008b76b8c2a2d0e1fd,openstack/neutron,master,I881bde907f4c90de4c919d008b76b8c2a2d0e1fd,VCNS driver implementation,MERGED,2013-08-20 21:35:22.000000000,2013-09-05 09:58:01.000000000,2013-09-05 09:58:00.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 5201}, {'_account_id': 5948}, {'_account_id': 5983}, {'_account_id': 6461}, {'_account_id': 6522}, {'_account_id': 6676}, {'_account_id': 7317}]","[{'number': 1, 'created': '2013-08-20 21:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3c6e0f69e155b300291084c6dfb9a65311f62290', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 2, 'created': '2013-08-21 01:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/85d9bcf297dfc757fc644f6cbb087022051c79c9', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 3, 'created': '2013-08-21 18:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c1987e188e811dbbc4710b962e193c28dfd4483b', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 4, 'created': '2013-08-21 18:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1881be7f6264b5ee6b35a8f80fa6cbd09ea17398', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 5, 'created': '2013-08-22 15:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a6162a3dc10f8ac0232d727f6cc854b01d94c4d', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 6, 'created': '2013-08-23 03:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7eb00446a5fe3c6daa4ecc23d8b0efc22fbac283', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 7, 'created': '2013-08-23 04:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a2b67766bba1ce5e52a05dfe846a393e33f98d98', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 8, 'created': '2013-08-23 04:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/df8df8737562fd8751f53521ce1224a9e13cba49', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 9, 'created': '2013-08-23 04:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/788ad8dd48b7c98cb14598f4314b75bc1a34980e', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 10, 'created': '2013-08-23 05:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2cbd90bf3a6cd4782ef8f76fe0a352f9b0c65e32', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 11, 'created': '2013-08-23 05:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ce7c0f6437bc564e1ed8eb649c5ad0a154c2769', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 12, 'created': '2013-08-27 07:08:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/03f448ca08c009d348bb21574a72adef2135ac90', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 13, 'created': '2013-08-28 10:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3d5dc97a04a55c13926c3813d48fd93f5983e4b', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 14, 'created': '2013-08-28 19:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9b720fbe050471a1891a7b5f995f21a89fd61619', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 15, 'created': '2013-08-29 08:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bab59b2dd650a3f9bb3b9ae217fc676397843ee3', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 16, 'created': '2013-08-29 21:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2790180286483ba139873908b4cac898ac2de36f', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 17, 'created': '2013-08-30 09:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/14301b6eda3ff982fd7b1a40e7ebabdfa9223284', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 18, 'created': '2013-08-30 17:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/837a650a937191000b621a64cc6d4b18257862ff', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 19, 'created': '2013-08-31 06:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e70febb15e323b35a6224cb370b02c7700d47289', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 20, 'created': '2013-09-02 23:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ee9115bb3b059e32f993c13deb446af6eefc700', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 21, 'created': '2013-09-03 09:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c6fb5728d52bc5634d4920099e924c654d97a160', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 22, 'created': '2013-09-03 18:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/968d44db13cb331e50b6c8b88cd041b7321d0de6', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 23, 'created': '2013-09-03 23:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f6c4bb6fbee8a8a66344f2c5d18f34dbe5105759', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 24, 'created': '2013-09-04 02:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/88c3a96e59bbca711f921267e35416fe23f4cf61', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 25, 'created': '2013-09-04 18:11:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13af8e3db3f5d83fb95cda58c5358b289075b9fb', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}, {'number': 26, 'created': '2013-09-05 00:18:11.000000000', 'files': ['neutron/tests/unit/nicira/vshield/common/__init__.py', 'neutron/plugins/nicira/vshield/tasks/tasks.py', 'neutron/tests/unit/nicira/vshield/__init__.py', 'neutron/plugins/nicira/vshield/vcns_driver.py', 'neutron/plugins/nicira/vshield/tasks/constants.py', 'neutron/tests/unit/nicira/test_vcns_driver.py', 'neutron/plugins/nicira/vshield/tasks/__init__.py', 'neutron/tests/unit/nicira/etc/vcns.ini.test', 'neutron/tests/unit/nicira/vshield/fake_vcns.py', 'neutron/plugins/nicira/vshield/edge_appliance_driver.py', 'neutron/plugins/nicira/common/config.py', 'neutron/plugins/nicira/vshield/__init__.py', 'neutron/tests/unit/nicira/__init__.py', 'neutron/plugins/nicira/vshield/common/exceptions.py', 'neutron/plugins/nicira/vshield/common/VcnsApiClient.py', 'neutron/plugins/nicira/vshield/common/__init__.py', 'neutron/plugins/nicira/vshield/vcns.py', 'neutron/plugins/nicira/vshield/common/constants.py', 'etc/neutron/plugins/nicira/nvp.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f96cf93e70f8c434499efb903820aa72665a7fd4', 'message': 'VCNS driver implementation\n\nImplement API/driver interface for configuring vShield Edge Appliance.\n\nCurrently implemented functions:\n    - Deploy an Edge\n    - Destroy an Edge\n    - Configuring interfaces\n    - Configuring SNAT/DNAT rules\n    - Configuring default gateway and static routes\n    - Query Edge status\n    - Task-based asynchronous model\n    - Allow old routes/nat config to be skipped if new updates are coming\n\nImplements: blueprint vcns-driver\nChange-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd\n'}]",237,43003,f96cf93e70f8c434499efb903820aa72665a7fd4,128,14,26,6461,,,0,"VCNS driver implementation

Implement API/driver interface for configuring vShield Edge Appliance.

Currently implemented functions:
    - Deploy an Edge
    - Destroy an Edge
    - Configuring interfaces
    - Configuring SNAT/DNAT rules
    - Configuring default gateway and static routes
    - Query Edge status
    - Task-based asynchronous model
    - Allow old routes/nat config to be skipped if new updates are coming

Implements: blueprint vcns-driver
Change-Id: I881bde907f4c90de4c919d008b76b8c2a2d0e1fd
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/43003/26 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/nicira/vshield/tasks/tasks.py', 'neutron/plugins/nicira/vshield/tasks/constants.py', 'neutron/plugins/nicira/vshield/vcns/vcns_driver.py', 'neutron/tests/unit/nicira/vcns/common/__init__.py', 'neutron/plugins/nicira/vshield/vcns/common/exceptions.py', 'neutron/plugins/nicira/vshield/vcns/common/VcnsApiClient.py', 'neutron/plugins/nicira/vshield/tasks/__init__.py', 'neutron/plugins/nicira/vshield/vcns/common/constants.py', 'neutron/plugins/nicira/vshield/vcns/edge_appliance_driver.py', 'neutron/plugins/nicira/common/config.py', 'neutron/plugins/nicira/vshield/__init__.py', 'neutron/tests/unit/nicira/vcns/fake_vcns.py', 'neutron/tests/unit/nicira/__init__.py', 'neutron/plugins/nicira/vshield/vcns/vcns.py', 'neutron/plugins/nicira/vshield/vcns/common/__init__.py', 'neutron/plugins/nicira/vshield/vcns/__init__.py', 'neutron/tests/unit/nicira/vcns/__init__.py']",17,3c6e0f69e155b300291084c6dfb9a65311f62290,bp/vcns-driver,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2013 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",,1641,0
openstack%2Fceilometer~master~I7b39818ecce595351593040f43ee7486e66cc042,openstack/ceilometer,master,I7b39818ecce595351593040f43ee7486e66cc042,doc: Fix service name for devstack,ABANDONED,2013-09-05 09:33:11.000000000,2013-09-05 09:57:22.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 7203}]","[{'number': 1, 'created': '2013-09-05 09:33:11.000000000', 'files': ['doc/source/install/development.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a5aff2416a8afa68b25ba887d66500f544721e9f', 'message': ""doc: Fix service name for devstack\n\nceilometer-alarm-singleton's name is ceilometer-alarm-eval in devstack.\nceilometer-alarm-notifier's name is ceilometer-alarm-notify in devstack.\n\nChange-Id: I7b39818ecce595351593040f43ee7486e66cc042\n""}]",0,45204,a5aff2416a8afa68b25ba887d66500f544721e9f,4,3,1,7203,,,0,"doc: Fix service name for devstack

ceilometer-alarm-singleton's name is ceilometer-alarm-eval in devstack.
ceilometer-alarm-notifier's name is ceilometer-alarm-notify in devstack.

Change-Id: I7b39818ecce595351593040f43ee7486e66cc042
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/04/45204/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/development.rst'],1,a5aff2416a8afa68b25ba887d66500f544721e9f,fix_devstack_service_name," enable_service ceilometer-alarm-eval,ceilometer-alarm-notify"," enable_service ceilometer-alarm-singleton,ceilometer-alarm-notifier",1,1
openstack%2Fnova~master~I0d4edfa5a53c3b9a9fa43864f5daaa17a0d024a1,openstack/nova,master,I0d4edfa5a53c3b9a9fa43864f5daaa17a0d024a1,Add nova.utils.get_root_helper(),MERGED,2013-09-04 15:44:32.000000000,2013-09-05 09:51:41.000000000,2013-09-05 09:51:38.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5997}, {'_account_id': 6722}]","[{'number': 1, 'created': '2013-09-04 15:44:32.000000000', 'files': ['nova/tests/virt/test_virt_disk_vfs_localfs.py', 'nova/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/38ecf82efb0765deddf1e96e70231601a518c9bb', 'message': ""Add nova.utils.get_root_helper()\n\nThe pattern for the 'sudo nova-rootwrap' command was duplicated\nthroughout the code.  Put it in one place in nova.utils.\n\nChange-Id: I0d4edfa5a53c3b9a9fa43864f5daaa17a0d024a1\n""}]",0,45074,38ecf82efb0765deddf1e96e70231601a518c9bb,12,7,1,1561,,,0,"Add nova.utils.get_root_helper()

The pattern for the 'sudo nova-rootwrap' command was duplicated
throughout the code.  Put it in one place in nova.utils.

Change-Id: I0d4edfa5a53c3b9a9fa43864f5daaa17a0d024a1
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/45074/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/test_virt_disk_vfs_localfs.py', 'nova/utils.py']",2,38ecf82efb0765deddf1e96e70231601a518c9bb,get_root_helper,def get_root_helper(): return 'sudo nova-rootwrap %s' % CONF.rootwrap_config kwargs['root_helper'] = get_root_helper() kwargs['root_helper'] = get_root_helper(), kwargs['root_helper'] = 'sudo nova-rootwrap %s' % CONF.rootwrap_config kwargs['root_helper'] = 'sudo nova-rootwrap %s' % CONF.rootwrap_config,14,9
openstack%2Ftripleo-ci~master~I4d3484f270a09f10dbc4c448cf8b1dd360754899,openstack/tripleo-ci,master,I4d3484f270a09f10dbc4c448cf8b1dd360754899,Update patch of diskimage-builder,MERGED,2013-09-02 09:40:54.000000000,2013-09-05 09:32:58.000000000,2013-09-05 09:32:58.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4190}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-09-02 09:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/34503a6cae92b4dc1ecfd5f58d3ea1f15112c65f', 'message': 'Update patch of diskimage-builder\n\nThe file being patched was changed by\nI451d24bdd6fa0983414244135dff5e96c0549833\n\nAlos no longer move firstboot log.\n\nChange-Id: I4d3484f270a09f10dbc4c448cf8b1dd360754899\n'}, {'number': 2, 'created': '2013-09-02 11:28:05.000000000', 'files': ['patches_dev/diskimage-builder-Save-images-in-a-toci-cache-file-or-use-if-present.patch'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/28477daeb85b103b7867d747396017c73634056b', 'message': 'Update patch of diskimage-builder\n\nThe file being patched was changed by\nI451d24bdd6fa0983414244135dff5e96c0549833\n\nAlso no longer move firstboot log.\n\nChange-Id: I4d3484f270a09f10dbc4c448cf8b1dd360754899\n'}]",1,44667,28477daeb85b103b7867d747396017c73634056b,11,4,2,1926,,,0,"Update patch of diskimage-builder

The file being patched was changed by
I451d24bdd6fa0983414244135dff5e96c0549833

Also no longer move firstboot log.

Change-Id: I4d3484f270a09f10dbc4c448cf8b1dd360754899
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/67/44667/2 && git format-patch -1 --stdout FETCH_HEAD,['patches_dev/diskimage-builder-Save-images-in-a-toci-cache-file-or-use-if-present.patch'],1,34503a6cae92b4dc1ecfd5f58d3ea1f15112c65f,update-patch," bin/disk-image-create | 8 ++++++++ 1 file changed, 8 insertions(+)index de14433..fba1e1e 100755@@ -105,6 +105,13 @@ arg_to_elements ""$@""@@ -151,6 +158,7 @@ unmount_image compress_and_save_image $IMAGE_NAME.$IMAGE_TYPE"," bin/disk-image-create | 8 ++++++++ elements/base/dib-first-boot | 2 +- 2 files changed, 9 insertions(+), 1 deletion(-)index efbcf85..e7fc46f 100755@@ -97,6 +97,13 @@ arg_to_elements ""$@""@@ -144,6 +151,7 @@ unmount_image compress_image save_image $IMAGE_NAME.$IMAGE_TYPEdiff --git a/elements/base/dib-first-boot b/elements/base/dib-first-boot index 1e39860..c13a930 100755 --- a/elements/base/dib-first-boot +++ b/elements/base/dib-first-boot @@ -6,6 +6,6 @@ touch /var/log/first-boot.d.log chmod 0600 /var/log/first-boot.d.log /usr/local/bin/dib-run-parts /etc/first-boot.d >> /var/log/first-boot.d.log 2>&1 -rm -fr /etc/first-boot.d +mv /etc/first-boot.d /etc/first-boot.d_ # delete itself rm $0",7,20
openstack%2Foslo.messaging~master~Ie299c2695d81d0473cea81d40114326b89de0011,openstack/oslo.messaging,master,Ie299c2695d81d0473cea81d40114326b89de0011,Implement the server side of ZmqDriver,MERGED,2013-08-28 13:06:57.000000000,2013-09-05 09:25:05.000000000,2013-09-05 09:25:05.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2013-08-28 13:06:57.000000000', 'files': ['oslo/messaging/_drivers/impl_zmq.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b6d808774683bb0dab13fddddf49543f6bf00627', 'message': ""Implement the server side of ZmqDriver\n\nThis implements the server side of the driver without modifying the\nexisting code by allowing the driver to spawn off multiple greenthreads\nas before, but queueing any dispatched messages so that the executor\ncan still do listener.poll() to dispatch messages itself.\n\nThis is a hack, but it's a starting point.\n\nChange-Id: Ie299c2695d81d0473cea81d40114326b89de0011\n""}]",0,44047,b6d808774683bb0dab13fddddf49543f6bf00627,6,2,1,1247,,,0,"Implement the server side of ZmqDriver

This implements the server side of the driver without modifying the
existing code by allowing the driver to spawn off multiple greenthreads
as before, but queueing any dispatched messages so that the executor
can still do listener.poll() to dispatch messages itself.

This is a hack, but it's a starting point.

Change-Id: Ie299c2695d81d0473cea81d40114326b89de0011
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/47/44047/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/impl_zmq.py'],1,b6d808774683bb0dab13fddddf49543f6bf00627,zmq,"import collectionsimport Queueimport threading 'IP address. Must match ""host"" option, if running Nova.'), cfg.IntOpt('rpc_cast_timeout', default=30, help='Seconds to wait before a cast expires (TTL). ' 'Only supported by impl_zmq.'), _msg_id=None, allowed_remote_exmods=[]): envelope=False, allowed_remote_exmods=[]): raise rpc_common.deserialize_remote_exception( resp['exc'], allowed_remote_exmods) envelope=False, _msg_id=None, allowed_remote_exmods=[]): envelope, allowed_remote_exmods)class ZmqIncomingMessage(base.IncomingMessage): ReceivedReply = collections.namedtuple( 'ReceivedReply', ['reply', 'failure', 'log_failure']) def __init__(self, listener, ctxt, message): super(ZmqIncomingMessage, self).__init__(listener, ctxt, message) self.condition = threading.Condition() self.received = None def reply(self, reply=None, failure=None, log_failure=True): self.received = self.ReceivedReply(reply, failure, log_failure) with self.condition: self.condition.notify() class ZmqListener(base.Listener): def __init__(self, driver, target): super(ZmqListener, self).__init__(driver, target) self.incoming_queue = Queue.Queue() def dispatch(self, ctxt, version, method, namespace, **kwargs): message = { 'method': method, 'args': kwargs } if version: message['version'] = version if namespace: message['namespace'] = namespace incoming = ZmqIncomingMessage(self, ctxt.to_dict(), message) self.incoming_queue.put(incoming) with incoming.condition: incoming.condition.wait() assert incoming.received if incoming.received.failure: raise incoming.received.failure else: return incoming.received.reply def poll(self): while True: return self.incoming_queue.get() envelope=envelope, allowed_remote_exmods=self._allowed_remote_exmods) conn = create_connection(self.conf) listener = ZmqListener(self, target) conn.create_consumer(target.topic, listener) conn.create_consumer('%s.%s' % (target.topic, target.server), listener) conn.create_consumer(target.topic, listener, fanout=True) conn.consume_in_thread() return listener"," 'IP address. Must match ""host"" option, if running Nova.') _msg_id=None): envelope=False): raise rpc_common.deserialize_remote_exception(CONF, resp['exc']) envelope=False, _msg_id=None): envelope) envelope=envelope) raise NotImplementedError()",82,8
openstack%2Foslo.messaging~master~I9384f486e44b0b0cbca028e219ad66f1990d5181,openstack/oslo.messaging,master,I9384f486e44b0b0cbca028e219ad66f1990d5181,Add zmq-receiver,MERGED,2013-08-28 13:06:57.000000000,2013-09-05 09:25:04.000000000,2013-09-05 09:25:04.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2013-08-28 13:06:57.000000000', 'files': ['oslo/messaging/_cmd/zmq_receiver.py', 'oslo/messaging/_drivers/impl_zmq.py', 'setup.cfg', 'oslo/messaging/_cmd/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a2d113198c684e585c5bab9e313b4ede8a6aee4f', 'message': 'Add zmq-receiver\n\nThis is the ZeroMQ server which acts as a proxy for all messages\ndestined to a particular host. Again, there are a bunch of FIXMEs\nhere. This still needs work.\n\nChange-Id: I9384f486e44b0b0cbca028e219ad66f1990d5181\n'}]",0,44046,a2d113198c684e585c5bab9e313b4ede8a6aee4f,7,2,1,1247,,,0,"Add zmq-receiver

This is the ZeroMQ server which acts as a proxy for all messages
destined to a particular host. Again, there are a bunch of FIXMEs
here. This still needs work.

Change-Id: I9384f486e44b0b0cbca028e219ad66f1990d5181
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/46/44046/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_cmd/zmq_receiver.py', 'oslo/messaging/_drivers/impl_zmq.py', 'setup.cfg', 'oslo/messaging/_cmd/__init__.py']",4,a2d113198c684e585c5bab9e313b4ede8a6aee4f,zmq," # Copyright 2013 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",,60,0
openstack%2Fpuppet-cinder~master~Idf4bfea0d21bfb4a0ca2c3c426961340a7d84be5,openstack/puppet-cinder,master,Idf4bfea0d21bfb4a0ca2c3c426961340a7d84be5,Check the parameter enabled before db_sync,MERGED,2013-09-03 13:45:17.000000000,2013-09-05 09:24:48.000000000,2013-09-05 09:24:48.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 2166}, {'_account_id': 6773}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-09-03 13:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/c2451a465e5afb4f3e0d5e656415b8531e845cbe', 'message': 'Check the parameter enabled before db_sync\n\nSetting enabled to false ensures that the api service is not running\nand the db schema is not create/migrated.\n\nChange-Id: Idf4bfea0d21bfb4a0ca2c3c426961340a7d84be5\n'}, {'number': 2, 'created': '2013-09-04 10:16:13.000000000', 'files': ['manifests/api.pp', 'spec/classes/cinder_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/e54f61ae59ef6111a6d47e113e855534f05a465d', 'message': 'Check the parameter enabled before db_sync\n\nSetting enabled to false ensures that the api service is not running\nand the db schema is not create/migrated.\n\nChange-Id: Idf4bfea0d21bfb4a0ca2c3c426961340a7d84be5\n'}]",2,44877,e54f61ae59ef6111a6d47e113e855534f05a465d,13,6,2,6773,,,0,"Check the parameter enabled before db_sync

Setting enabled to false ensures that the api service is not running
and the db schema is not create/migrated.

Change-Id: Idf4bfea0d21bfb4a0ca2c3c426961340a7d84be5
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/77/44877/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/api.pp'],1,c2451a465e5afb4f3e0d5e656415b8531e845cbe,check-enabled-parameter," Cinder_config<||> ~> Exec['cinder-manage db_sync'] exec { 'cinder-manage db_sync': command => $::cinder::params::db_sync_command, path => '/usr/bin', user => 'cinder', refreshonly => true, logoutput => 'on_failure', require => Package['cinder'], }"," Cinder_config<||> ~> Exec['cinder-manage db_sync'] exec { 'cinder-manage db_sync': command => $::cinder::params::db_sync_command, path => '/usr/bin', user => 'cinder', refreshonly => true, logoutput => 'on_failure', require => Package['cinder'], } ",11,11
openstack%2Foslo.messaging~master~I6d69ebc9ae3b3999832209e0c4100ffe26e35919,openstack/oslo.messaging,master,I6d69ebc9ae3b3999832209e0c4100ffe26e35919,Implement the client side of ZmqDriver,MERGED,2013-08-28 13:06:57.000000000,2013-09-05 09:23:14.000000000,2013-09-05 09:23:14.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2013-08-28 13:06:57.000000000', 'files': ['oslo/messaging/_drivers/impl_zmq.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5d3fc9c18cd030da27b8d2fc0b24b87a69d6d17a', 'message': ""Implement the client side of ZmqDriver\n\nGet sending working with an initial version of the driver. There's a\nbunch of FIXMEs inline reflecting that even the client side needs a\ntonne of work yet.\n\nChange-Id: I6d69ebc9ae3b3999832209e0c4100ffe26e35919\n""}]",0,44045,5d3fc9c18cd030da27b8d2fc0b24b87a69d6d17a,6,2,1,1247,,,0,"Implement the client side of ZmqDriver

Get sending working with an initial version of the driver. There's a
bunch of FIXMEs inline reflecting that even the client side needs a
tonne of work yet.

Change-Id: I6d69ebc9ae3b3999832209e0c4100ffe26e35919
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/45/44045/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/impl_zmq.py'],1,5d3fc9c18cd030da27b8d2fc0b24b87a69d6d17a,zmq,"from oslo.messaging._drivers import base default=('oslo.messaging._drivers.' class ZmqDriver(base.BaseDriver): # FIXME(markmc): allow this driver to be used without eventlet def __init__(self, conf, url, default_exchange=None, allowed_remote_exmods=[]): conf.register_opts(zmq_opts) super(ZmqDriver, self).__init__(conf, url, default_exchange, allowed_remote_exmods) # FIXME(markmc): handle default_exchange # FIXME(markmc): handle transport URL if self._url.hosts: raise NotImplementedError('The ZeroMQ driver does not yet support ' 'transport URLs') # FIXME(markmc): use self.conf everywhere if self.conf is not CONF: raise NotImplementedError('The ZeroMQ driver currently only works ' 'with oslo.config.cfg.CONF') def _send(self, target, ctxt, message, wait_for_reply=None, timeout=None, envelope=True): # FIXME(markmc): remove this temporary hack class Context(object): def __init__(self, d): self.d = d def to_dict(self): return self.d context = Context(ctxt) if wait_for_reply: method = _call else: method = _cast topic = target.topic if target.fanout: # NOTE(ewindisch): fanout~ is used because it avoid splitting on # and acts as a non-subtle hint to the matchmaker and ZmqProxy. topic = 'fanout~' + topic reply = _multi_send(method, context, topic, message, envelope=envelope) if wait_for_reply: return reply[-1] def send(self, target, ctxt, message, wait_for_reply=None, timeout=None): return self._send(target, ctxt, message, wait_for_reply, timeout) def send_notification(self, target, ctxt, message, version): # NOTE(ewindisch): dot-priority in rpc notifier does not # work with our assumptions. target = target(topic=target.topic.replace('.', '-')) return self._send(target, ctxt, message, envelope=(version == 2.0)) def listen(self, target): raise NotImplementedError() def cleanup(self): cleanup()", default=('openstack.common.rpc.'CONF.register_opts(zmq_opts),71,3
openstack%2Foslo.messaging~master~I87b85b79a33dec65e51ed95fff90cc56042240c5,openstack/oslo.messaging,master,I87b85b79a33dec65e51ed95fff90cc56042240c5,Import zmq driver code with minimal modifications,MERGED,2013-08-28 13:06:57.000000000,2013-09-05 09:23:13.000000000,2013-09-05 09:23:13.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2013-08-28 13:06:57.000000000', 'files': ['oslo/messaging/_drivers/matchmaker_ring.py', 'oslo/messaging/_drivers/matchmaker.py', 'oslo/messaging/_drivers/matchmaker_redis.py', 'oslo/messaging/_drivers/impl_zmq.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/ff3a4155bffc7a535e0098a5e5523940b40d7b9e', 'message': ""Import zmq driver code with minimal modifications\n\nModifications are:\n\n  - use stdlib logging; no huge need for oslo logging here\n\n  - stub out the _() function; we don't have any l10n infrastructure in\n    the project and may never have\n\n  - change imports to oslo.messaging.openstack.common and\n    oslo.messaging._drivers as appropriate\n\nChange-Id: I87b85b79a33dec65e51ed95fff90cc56042240c5\n""}]",0,44044,ff3a4155bffc7a535e0098a5e5523940b40d7b9e,6,2,1,1247,,,0,"Import zmq driver code with minimal modifications

Modifications are:

  - use stdlib logging; no huge need for oslo logging here

  - stub out the _() function; we don't have any l10n infrastructure in
    the project and may never have

  - change imports to oslo.messaging.openstack.common and
    oslo.messaging._drivers as appropriate

Change-Id: I87b85b79a33dec65e51ed95fff90cc56042240c5
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/44/44044/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/matchmaker_ring.py', 'oslo/messaging/_drivers/matchmaker.py', 'oslo/messaging/_drivers/matchmaker_redis.py', 'oslo/messaging/_drivers/impl_zmq.py']",4,ff3a4155bffc7a535e0098a5e5523940b40d7b9e,zmq,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 Cloudscaling Group, Inc # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging import os import pprint import re import socket import sys import types import uuid import eventlet import greenlet from oslo.config import cfg from oslo.messaging._drivers import common as rpc_common from oslo.messaging.openstack.common import excutils from oslo.messaging.openstack.common import importutils from oslo.messaging.openstack.common import jsonutils zmq = importutils.try_import('eventlet.green.zmq') # for convenience, are not modified. pformat = pprint.pformat Timeout = eventlet.timeout.Timeout LOG = logging.getLogger(__name__) RemoteError = rpc_common.RemoteError RPCException = rpc_common.RPCException # FIXME(markmc): remove this _ = lambda s: s zmq_opts = [ cfg.StrOpt('rpc_zmq_bind_address', default='*', help='ZeroMQ bind address. Should be a wildcard (*), ' 'an ethernet interface, or IP. ' 'The ""host"" option should point or resolve to this ' 'address.'), # The module.Class to use for matchmaking. cfg.StrOpt( 'rpc_zmq_matchmaker', default=('openstack.common.rpc.' 'matchmaker.MatchMakerLocalhost'), help='MatchMaker driver', ), # The following port is unassigned by IANA as of 2012-05-21 cfg.IntOpt('rpc_zmq_port', default=9501, help='ZeroMQ receiver listening port'), cfg.IntOpt('rpc_zmq_contexts', default=1, help='Number of ZeroMQ contexts, defaults to 1'), cfg.IntOpt('rpc_zmq_topic_backlog', default=None, help='Maximum number of ingress messages to locally buffer ' 'per topic. Default is unlimited.'), cfg.StrOpt('rpc_zmq_ipc_dir', default='/var/run/openstack', help='Directory for holding IPC sockets'), cfg.StrOpt('rpc_zmq_host', default=socket.gethostname(), help='Name of this node. Must be a valid hostname, FQDN, or ' 'IP address. Must match ""host"" option, if running Nova.') ] CONF = cfg.CONF CONF.register_opts(zmq_opts) ZMQ_CTX = None # ZeroMQ Context, must be global. matchmaker = None # memoized matchmaker object def _serialize(data): """"""Serialization wrapper. We prefer using JSON, but it cannot encode all types. Error if a developer passes us bad data. """""" try: return jsonutils.dumps(data, ensure_ascii=True) except TypeError: with excutils.save_and_reraise_exception(): LOG.error(_(""JSON serialization failed."")) def _deserialize(data): """"""Deserialization wrapper."""""" LOG.debug(_(""Deserializing: %s""), data) return jsonutils.loads(data) class ZmqSocket(object): """"""A tiny wrapper around ZeroMQ. Simplifies the send/recv protocol and connection management. Can be used as a Context (supports the 'with' statement). """""" def __init__(self, addr, zmq_type, bind=True, subscribe=None): self.sock = _get_ctxt().socket(zmq_type) self.addr = addr self.type = zmq_type self.subscriptions = [] # Support failures on sending/receiving on wrong socket type. self.can_recv = zmq_type in (zmq.PULL, zmq.SUB) self.can_send = zmq_type in (zmq.PUSH, zmq.PUB) self.can_sub = zmq_type in (zmq.SUB, ) # Support list, str, & None for subscribe arg (cast to list) do_sub = { list: subscribe, str: [subscribe], type(None): [] }[type(subscribe)] for f in do_sub: self.subscribe(f) str_data = {'addr': addr, 'type': self.socket_s(), 'subscribe': subscribe, 'bind': bind} LOG.debug(_(""Connecting to %(addr)s with %(type)s""), str_data) LOG.debug(_(""-> Subscribed to %(subscribe)s""), str_data) LOG.debug(_(""-> bind: %(bind)s""), str_data) try: if bind: self.sock.bind(addr) else: self.sock.connect(addr) except Exception: raise RPCException(_(""Could not open socket."")) def socket_s(self): """"""Get socket type as string."""""" t_enum = ('PUSH', 'PULL', 'PUB', 'SUB', 'REP', 'REQ', 'ROUTER', 'DEALER') return dict(map(lambda t: (getattr(zmq, t), t), t_enum))[self.type] def subscribe(self, msg_filter): """"""Subscribe."""""" if not self.can_sub: raise RPCException(""Cannot subscribe on this socket."") LOG.debug(_(""Subscribing to %s""), msg_filter) try: self.sock.setsockopt(zmq.SUBSCRIBE, msg_filter) except Exception: return self.subscriptions.append(msg_filter) def unsubscribe(self, msg_filter): """"""Unsubscribe."""""" if msg_filter not in self.subscriptions: return self.sock.setsockopt(zmq.UNSUBSCRIBE, msg_filter) self.subscriptions.remove(msg_filter) def close(self): if self.sock is None or self.sock.closed: return # We must unsubscribe, or we'll leak descriptors. if self.subscriptions: for f in self.subscriptions: try: self.sock.setsockopt(zmq.UNSUBSCRIBE, f) except Exception: pass self.subscriptions = [] try: # Default is to linger self.sock.close() except Exception: # While this is a bad thing to happen, # it would be much worse if some of the code calling this # were to fail. For now, lets log, and later evaluate # if we can safely raise here. LOG.error(""ZeroMQ socket could not be closed."") self.sock = None def recv(self, **kwargs): if not self.can_recv: raise RPCException(_(""You cannot recv on this socket."")) return self.sock.recv_multipart(**kwargs) def send(self, data, **kwargs): if not self.can_send: raise RPCException(_(""You cannot send on this socket."")) self.sock.send_multipart(data, **kwargs) class ZmqClient(object): """"""Client for ZMQ sockets."""""" def __init__(self, addr): self.outq = ZmqSocket(addr, zmq.PUSH, bind=False) def cast(self, msg_id, topic, data, envelope): msg_id = msg_id or 0 if not envelope: self.outq.send(map(bytes, (msg_id, topic, 'cast', _serialize(data)))) return rpc_envelope = rpc_common.serialize_msg(data[1], envelope) zmq_msg = reduce(lambda x, y: x + y, rpc_envelope.items()) self.outq.send(map(bytes, (msg_id, topic, 'impl_zmq_v2', data[0]) + zmq_msg)) def close(self): self.outq.close() class RpcContext(rpc_common.CommonRpcContext): """"""Context that supports replying to a rpc.call."""""" def __init__(self, **kwargs): self.replies = [] super(RpcContext, self).__init__(**kwargs) def deepcopy(self): values = self.to_dict() values['replies'] = self.replies return self.__class__(**values) def reply(self, reply=None, failure=None, ending=False): if ending: return self.replies.append(reply) @classmethod def marshal(self, ctx): ctx_data = ctx.to_dict() return _serialize(ctx_data) @classmethod def unmarshal(self, data): return RpcContext.from_dict(_deserialize(data)) class InternalContext(object): """"""Used by ConsumerBase as a private context for - methods."""""" def __init__(self, proxy): self.proxy = proxy self.msg_waiter = None def _get_response(self, ctx, proxy, topic, data): """"""Process a curried message and cast the result to topic."""""" LOG.debug(_(""Running func with context: %s""), ctx.to_dict()) data.setdefault('version', None) data.setdefault('args', {}) try: result = proxy.dispatch( ctx, data['version'], data['method'], data.get('namespace'), **data['args']) return ConsumerBase.normalize_reply(result, ctx.replies) except greenlet.GreenletExit: # ignore these since they are just from shutdowns pass except rpc_common.ClientException as e: LOG.debug(_(""Expected exception during message handling (%s)"") % e._exc_info[1]) return {'exc': rpc_common.serialize_remote_exception(e._exc_info, log_failure=False)} except Exception: LOG.error(_(""Exception during message handling"")) return {'exc': rpc_common.serialize_remote_exception(sys.exc_info())} def reply(self, ctx, proxy, msg_id=None, context=None, topic=None, msg=None): """"""Reply to a casted call."""""" # NOTE(ewindisch): context kwarg exists for Grizzly compat. # this may be able to be removed earlier than # 'I' if ConsumerBase.process were refactored. if type(msg) is list: payload = msg[-1] else: payload = msg response = ConsumerBase.normalize_reply( self._get_response(ctx, proxy, topic, payload), ctx.replies) LOG.debug(_(""Sending reply"")) _multi_send(_cast, ctx, topic, { 'method': '-process_reply', 'args': { 'msg_id': msg_id, # Include for Folsom compat. 'response': response } }, _msg_id=msg_id) class ConsumerBase(object): """"""Base Consumer."""""" def __init__(self): self.private_ctx = InternalContext(None) @classmethod def normalize_reply(self, result, replies): #TODO(ewindisch): re-evaluate and document this method. if isinstance(result, types.GeneratorType): return list(result) elif replies: return replies else: return [result] def process(self, proxy, ctx, data): data.setdefault('version', None) data.setdefault('args', {}) # Method starting with - are # processed internally. (non-valid method name) method = data.get('method') if not method: LOG.error(_(""RPC message did not include method."")) return # Internal method # uses internal context for safety. if method == '-reply': self.private_ctx.reply(ctx, proxy, **data['args']) return proxy.dispatch(ctx, data['version'], data['method'], data.get('namespace'), **data['args']) class ZmqBaseReactor(ConsumerBase): """"""A consumer class implementing a centralized casting broker (PULL-PUSH). Used for RoundRobin requests. """""" def __init__(self, conf): super(ZmqBaseReactor, self).__init__() self.proxies = {} self.threads = [] self.sockets = [] self.subscribe = {} self.pool = eventlet.greenpool.GreenPool(conf.rpc_thread_pool_size) def register(self, proxy, in_addr, zmq_type_in, in_bind=True, subscribe=None): LOG.info(_(""Registering reactor"")) if zmq_type_in not in (zmq.PULL, zmq.SUB): raise RPCException(""Bad input socktype"") # Items push in. inq = ZmqSocket(in_addr, zmq_type_in, bind=in_bind, subscribe=subscribe) self.proxies[inq] = proxy self.sockets.append(inq) LOG.info(_(""In reactor registered"")) def consume_in_thread(self): def _consume(sock): LOG.info(_(""Consuming socket"")) while True: self.consume(sock) for k in self.proxies.keys(): self.threads.append( self.pool.spawn(_consume, k) ) def wait(self): for t in self.threads: t.wait() def close(self): for s in self.sockets: s.close() for t in self.threads: t.kill() class ZmqProxy(ZmqBaseReactor): """"""A consumer class implementing a topic-based proxy. Forwards to IPC sockets. """""" def __init__(self, conf): super(ZmqProxy, self).__init__(conf) pathsep = set((os.path.sep or '', os.path.altsep or '', '/', '\\')) self.badchars = re.compile(r'[%s]' % re.escape(''.join(pathsep))) self.topic_proxy = {} def consume(self, sock): ipc_dir = CONF.rpc_zmq_ipc_dir data = sock.recv(copy=False) topic = data[1].bytes if topic.startswith('fanout~'): sock_type = zmq.PUB topic = topic.split('.', 1)[0] elif topic.startswith('zmq_replies'): sock_type = zmq.PUB else: sock_type = zmq.PUSH if topic not in self.topic_proxy: def publisher(waiter): LOG.info(_(""Creating proxy for topic: %s""), topic) try: # The topic is received over the network, # don't trust this input. if self.badchars.search(topic) is not None: emsg = _(""Topic contained dangerous characters."") LOG.warn(emsg) raise RPCException(emsg) out_sock = ZmqSocket(""ipc://%s/zmq_topic_%s"" % (ipc_dir, topic), sock_type, bind=True) except RPCException: waiter.send_exception(*sys.exc_info()) return self.topic_proxy[topic] = eventlet.queue.LightQueue( CONF.rpc_zmq_topic_backlog) self.sockets.append(out_sock) # It takes some time for a pub socket to open, # before we can have any faith in doing a send() to it. if sock_type == zmq.PUB: eventlet.sleep(.5) waiter.send(True) while(True): data = self.topic_proxy[topic].get() out_sock.send(data, copy=False) wait_sock_creation = eventlet.event.Event() eventlet.spawn(publisher, wait_sock_creation) try: wait_sock_creation.wait() except RPCException: LOG.error(_(""Topic socket file creation failed."")) return try: self.topic_proxy[topic].put_nowait(data) except eventlet.queue.Full: LOG.error(_(""Local per-topic backlog buffer full for topic "" ""%(topic)s. Dropping message."") % {'topic': topic}) def consume_in_thread(self): """"""Runs the ZmqProxy service."""""" ipc_dir = CONF.rpc_zmq_ipc_dir consume_in = ""tcp://%s:%s"" % \ (CONF.rpc_zmq_bind_address, CONF.rpc_zmq_port) consumption_proxy = InternalContext(None) try: os.makedirs(ipc_dir) except os.error: if not os.path.isdir(ipc_dir): with excutils.save_and_reraise_exception(): LOG.error(_(""Required IPC directory does not exist at"" "" %s"") % (ipc_dir, )) try: self.register(consumption_proxy, consume_in, zmq.PULL) except zmq.ZMQError: if os.access(ipc_dir, os.X_OK): with excutils.save_and_reraise_exception(): LOG.error(_(""Permission denied to IPC directory at"" "" %s"") % (ipc_dir, )) with excutils.save_and_reraise_exception(): LOG.error(_(""Could not create ZeroMQ receiver daemon. "" ""Socket may already be in use."")) super(ZmqProxy, self).consume_in_thread() def unflatten_envelope(packenv): """"""Unflattens the RPC envelope. Takes a list and returns a dictionary. i.e. [1,2,3,4] => {1: 2, 3: 4} """""" i = iter(packenv) h = {} try: while True: k = i.next() h[k] = i.next() except StopIteration: return h class ZmqReactor(ZmqBaseReactor): """"""A consumer class implementing a consumer for messages. Can also be used as a 1:1 proxy """""" def __init__(self, conf): super(ZmqReactor, self).__init__(conf) def consume(self, sock): #TODO(ewindisch): use zero-copy (i.e. references, not copying) data = sock.recv() LOG.debug(_(""CONSUMER RECEIVED DATA: %s""), data) proxy = self.proxies[sock] if data[2] == 'cast': # Legacy protocol packenv = data[3] ctx, msg = _deserialize(packenv) request = rpc_common.deserialize_msg(msg) ctx = RpcContext.unmarshal(ctx) elif data[2] == 'impl_zmq_v2': packenv = data[4:] msg = unflatten_envelope(packenv) request = rpc_common.deserialize_msg(msg) # Unmarshal only after verifying the message. ctx = RpcContext.unmarshal(data[3]) else: LOG.error(_(""ZMQ Envelope version unsupported or unknown."")) return self.pool.spawn_n(self.process, proxy, ctx, request) class Connection(rpc_common.Connection): """"""Manages connections and threads."""""" def __init__(self, conf): self.topics = [] self.reactor = ZmqReactor(conf) def create_consumer(self, topic, proxy, fanout=False): # Register with matchmaker. _get_matchmaker().register(topic, CONF.rpc_zmq_host) # Subscription scenarios if fanout: sock_type = zmq.SUB subscribe = ('', fanout)[type(fanout) == str] topic = 'fanout~' + topic.split('.', 1)[0] else: sock_type = zmq.PULL subscribe = None topic = '.'.join((topic.split('.', 1)[0], CONF.rpc_zmq_host)) if topic in self.topics: LOG.info(_(""Skipping topic registration. Already registered."")) return # Receive messages from (local) proxy inaddr = ""ipc://%s/zmq_topic_%s"" % \ (CONF.rpc_zmq_ipc_dir, topic) LOG.debug(_(""Consumer is a zmq.%s""), ['PULL', 'SUB'][sock_type == zmq.SUB]) self.reactor.register(proxy, inaddr, sock_type, subscribe=subscribe, in_bind=False) self.topics.append(topic) def close(self): _get_matchmaker().stop_heartbeat() for topic in self.topics: _get_matchmaker().unregister(topic, CONF.rpc_zmq_host) self.reactor.close() self.topics = [] def wait(self): self.reactor.wait() def consume_in_thread(self): _get_matchmaker().start_heartbeat() self.reactor.consume_in_thread() def _cast(addr, context, topic, msg, timeout=None, envelope=False, _msg_id=None): timeout_cast = timeout or CONF.rpc_cast_timeout payload = [RpcContext.marshal(context), msg] with Timeout(timeout_cast, exception=rpc_common.Timeout): try: conn = ZmqClient(addr) # assumes cast can't return an exception conn.cast(_msg_id, topic, payload, envelope) except zmq.ZMQError: raise RPCException(""Cast failed. ZMQ Socket Exception"") finally: if 'conn' in vars(): conn.close() def _call(addr, context, topic, msg, timeout=None, envelope=False): # timeout_response is how long we wait for a response timeout = timeout or CONF.rpc_response_timeout # The msg_id is used to track replies. msg_id = uuid.uuid4().hex # Replies always come into the reply service. reply_topic = ""zmq_replies.%s"" % CONF.rpc_zmq_host LOG.debug(_(""Creating payload"")) # Curry the original request into a reply method. mcontext = RpcContext.marshal(context) payload = { 'method': '-reply', 'args': { 'msg_id': msg_id, 'topic': reply_topic, # TODO(ewindisch): safe to remove mcontext in I. 'msg': [mcontext, msg] } } LOG.debug(_(""Creating queue socket for reply waiter"")) # Messages arriving async. # TODO(ewindisch): have reply consumer with dynamic subscription mgmt with Timeout(timeout, exception=rpc_common.Timeout): try: msg_waiter = ZmqSocket( ""ipc://%s/zmq_topic_zmq_replies.%s"" % (CONF.rpc_zmq_ipc_dir, CONF.rpc_zmq_host), zmq.SUB, subscribe=msg_id, bind=False ) LOG.debug(_(""Sending cast"")) _cast(addr, context, topic, payload, envelope) LOG.debug(_(""Cast sent; Waiting reply"")) # Blocks until receives reply msg = msg_waiter.recv() LOG.debug(_(""Received message: %s""), msg) LOG.debug(_(""Unpacking response"")) if msg[2] == 'cast': # Legacy version raw_msg = _deserialize(msg[-1])[-1] elif msg[2] == 'impl_zmq_v2': rpc_envelope = unflatten_envelope(msg[4:]) raw_msg = rpc_common.deserialize_msg(rpc_envelope) else: raise rpc_common.UnsupportedRpcEnvelopeVersion( _(""Unsupported or unknown ZMQ envelope returned."")) responses = raw_msg['args']['response'] # ZMQError trumps the Timeout error. except zmq.ZMQError: raise RPCException(""ZMQ Socket Error"") except (IndexError, KeyError): raise RPCException(_(""RPC Message Invalid."")) finally: if 'msg_waiter' in vars(): msg_waiter.close() # It seems we don't need to do all of the following, # but perhaps it would be useful for multicall? # One effect of this is that we're checking all # responses for Exceptions. for resp in responses: if isinstance(resp, types.DictType) and 'exc' in resp: raise rpc_common.deserialize_remote_exception(CONF, resp['exc']) return responses[-1] def _multi_send(method, context, topic, msg, timeout=None, envelope=False, _msg_id=None): """"""Wraps the sending of messages. Dispatches to the matchmaker and sends message to all relevant hosts. """""" conf = CONF LOG.debug(_(""%(msg)s"") % {'msg': ' '.join(map(pformat, (topic, msg)))}) queues = _get_matchmaker().queues(topic) LOG.debug(_(""Sending message(s) to: %s""), queues) # Don't stack if we have no matchmaker results if not queues: LOG.warn(_(""No matchmaker results. Not casting."")) # While not strictly a timeout, callers know how to handle # this exception and a timeout isn't too big a lie. raise rpc_common.Timeout(_(""No match from matchmaker."")) # This supports brokerless fanout (addresses > 1) for queue in queues: (_topic, ip_addr) = queue _addr = ""tcp://%s:%s"" % (ip_addr, conf.rpc_zmq_port) if method.__name__ == '_cast': eventlet.spawn_n(method, _addr, context, _topic, msg, timeout, envelope, _msg_id) return return method(_addr, context, _topic, msg, timeout, envelope) def create_connection(conf, new=True): return Connection(conf) def multicall(conf, *args, **kwargs): """"""Multiple calls."""""" return _multi_send(_call, *args, **kwargs) def call(conf, *args, **kwargs): """"""Send a message, expect a response."""""" data = _multi_send(_call, *args, **kwargs) return data[-1] def cast(conf, *args, **kwargs): """"""Send a message expecting no reply."""""" _multi_send(_cast, *args, **kwargs) def fanout_cast(conf, context, topic, msg, **kwargs): """"""Send a message to all listening and expect no reply."""""" # NOTE(ewindisch): fanout~ is used because it avoid splitting on . # and acts as a non-subtle hint to the matchmaker and ZmqProxy. _multi_send(_cast, context, 'fanout~' + str(topic), msg, **kwargs) def notify(conf, context, topic, msg, envelope): """"""Send notification event. Notifications are sent to topic-priority. This differs from the AMQP drivers which send to topic.priority. """""" # NOTE(ewindisch): dot-priority in rpc notifier does not # work with our assumptions. topic = topic.replace('.', '-') cast(conf, context, topic, msg, envelope=envelope) def cleanup(): """"""Clean up resources in use by implementation."""""" global ZMQ_CTX if ZMQ_CTX: ZMQ_CTX.term() ZMQ_CTX = None global matchmaker matchmaker = None def _get_ctxt(): if not zmq: raise ImportError(""Failed to import eventlet.green.zmq"") global ZMQ_CTX if not ZMQ_CTX: ZMQ_CTX = zmq.Context(CONF.rpc_zmq_contexts) return ZMQ_CTX def _get_matchmaker(*args, **kwargs): global matchmaker if not matchmaker: mm = CONF.rpc_zmq_matchmaker if mm.endswith('matchmaker.MatchMakerRing'): mm.replace('matchmaker', 'matchmaker_ring') LOG.warn(_('rpc_zmq_matchmaker = %(orig)s is deprecated; use' ' %(new)s instead') % dict( orig=CONF.rpc_zmq_matchmaker, new=mm)) matchmaker = importutils.import_object(mm, *args, **kwargs) return matchmaker ",,1399,0
openstack%2Fceilometer~master~Ie81f5ee5a8f7835f0600a4f4f46b25920d424e71,openstack/ceilometer,master,Ie81f5ee5a8f7835f0600a4f4f46b25920d424e71,Update to tox 1.6 and setup.py develop,MERGED,2013-09-04 20:49:59.000000000,2013-09-05 09:21:09.000000000,2013-09-05 09:21:09.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2013-09-04 20:49:59.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d264a713d0bcea08ed272638809d4bb1b65d4d30', 'message': 'Update to tox 1.6 and setup.py develop\n\nChange-Id: Ie81f5ee5a8f7835f0600a4f4f46b25920d424e71\n'}]",0,45124,d264a713d0bcea08ed272638809d4bb1b65d4d30,12,3,1,2,,,0,"Update to tox 1.6 and setup.py develop

Change-Id: Ie81f5ee5a8f7835f0600a4f4f46b25920d424e71
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/24/45124/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d264a713d0bcea08ed272638809d4bb1b65d4d30,upgrade-tox,minversion = 1.6 skipsdist = Trueinstall_command = pip install -U {opts} {packages} usedevelop = True LANG=en_US.UTF-8 LANGUAGE=en_US:en LC_ALL=C,,7,0
openstack%2Ftripleo-ci~master~I10acce1096b46a17a54ed2e7b7ab574234e9f3cf,openstack/tripleo-ci,master,I10acce1096b46a17a54ed2e7b7ab574234e9f3cf,"Devtest update, heat-cfntools no longer in images",MERGED,2013-09-04 10:14:26.000000000,2013-09-05 09:17:16.000000000,2013-09-05 09:17:16.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-09-04 10:14:26.000000000', 'files': ['toci_test.sh', 'toci_setup.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fba70ab3d78c0ab7757ba237c02391cf62752ee0', 'message': 'Devtest update, heat-cfntools no longer in images\n\nChange-Id: I10acce1096b46a17a54ed2e7b7ab574234e9f3cf\n'}]",0,45027,fba70ab3d78c0ab7757ba237c02391cf62752ee0,7,3,1,1926,,,0,"Devtest update, heat-cfntools no longer in images

Change-Id: I10acce1096b46a17a54ed2e7b7ab574234e9f3cf
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/27/45027/1 && git format-patch -1 --stdout FETCH_HEAD,"['toci_test.sh', 'toci_setup.sh']",2,fba70ab3d78c0ab7757ba237c02391cf62752ee0,devtest-update,$TOCI_WORKING_DIR/diskimage-builder/bin/disk-image-create -a $TOCI_DIB_ARCH -o $TOCI_WORKING_DIR/undercloud $TOCI_DISTROELEMENT boot-stack nova-baremetal os-collect-config stackuser local-config,$TOCI_WORKING_DIR/diskimage-builder/bin/disk-image-create -a $TOCI_DIB_ARCH -o $TOCI_WORKING_DIR/undercloud $TOCI_DISTROELEMENT boot-stack nova-baremetal heat-cfntools stackuser local-config,3,3
openstack%2Fopenstack-manuals~master~Ifb04dc88c62c7fcba7d72e81e4af8eb77a175a2c,openstack/openstack-manuals,master,Ifb04dc88c62c7fcba7d72e81e4af8eb77a175a2c,Change-Id: Ifb04dc88c62c7fcba7d72e81e4af8eb77a175a2c,ABANDONED,2013-09-05 08:51:11.000000000,2013-09-05 09:14:46.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-09-05 08:51:11.000000000', 'files': ['doc/src/docbkx/openstack-training/operator-editing-code.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/eb3e95df44c30ab4278cc442cb6b204b75c0ddf8', 'message': 'Change-Id: Ifb04dc88c62c7fcba7d72e81e4af8eb77a175a2c\n\nadd a step to register on openstack.org\n\nFixes Bug 1215743\n\nChange-Id: Ifb04dc88c62c7fcba7d72e81e4af8eb77a175a2c\n'}]",0,45194,eb3e95df44c30ab4278cc442cb6b204b75c0ddf8,3,2,1,7653,,,0,"Change-Id: Ifb04dc88c62c7fcba7d72e81e4af8eb77a175a2c

add a step to register on openstack.org

Fixes Bug 1215743

Change-Id: Ifb04dc88c62c7fcba7d72e81e4af8eb77a175a2c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/94/45194/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-training/operator-editing-code.xml'],1,eb3e95df44c30ab4278cc442cb6b204b75c0ddf8,bug/1215743," on https://help.launchpad.net/YourAccount/CreatingAnSSHKeyPair.</para> </step> <step> <para>If you haven't already, join The Openstack Foundation.Please visit https://www.openstack.org/join/. Among other privileges, this also allows you to vote in elections and run for elected positions within The OpenStack Project. When signing up for Foundation Membership, make sure to give the same E-mail address you'll use for code contributions, since the Primary Email Address in your Foundation Profile will need to match the Preferred Email you set later in your Gerrit contact information.</para> sign the Individual Contributor License agreement. Visit", onhttps://help.launchpad.net/YourAccount/CreatingAnSSHKeyPair.</para> sign the Individual Contributor License agreement and join the OpenStack Foundation. Visit,12,3
openstack%2Fceilometer~master~Ie4c74620937816ed0592f5ac72de99dee3173ad8,openstack/ceilometer,master,Ie4c74620937816ed0592f5ac72de99dee3173ad8,Disable the pymongo pooling feature for tests,MERGED,2013-08-30 15:10:57.000000000,2013-09-05 09:04:43.000000000,2013-09-05 09:04:42.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7399}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-08-30 15:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4d3fbf2c0cf0bf82f91ed7be554596960ce09743', 'message': ""Disable the pymongo pooling feature\n\nBecause pymongo don't close correctly the connection when we use its\npool, we disable the MongoClient pooling feature\n\nThis allow the use a normal number of connection in mongod for test.\n\nChange-Id: Ie4c74620937816ed0592f5ac72de99dee3173ad8\n""}, {'number': 2, 'created': '2013-08-30 15:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6eb9a5fb443b642b246cbc456eccdbf5a50c7560', 'message': ""Disable the pymongo pooling feature\n\nBecause pymongo don't close correctly the connection when we use its\npool, we disable the MongoClient pooling feature\n\nThis allow to use a normal number of connection in mongod for test.\n\nChange-Id: Ie4c74620937816ed0592f5ac72de99dee3173ad8\n""}, {'number': 3, 'created': '2013-09-02 07:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/14c599d6dbbdd5e96dbf22dc27151130d11d1bed', 'message': ""Disable the pymongo pooling feature\n\nBecause pymongo don't close correctly the connection when we use its\npool, we disable the MongoClient pooling feature\n\nThis allow to use a normal number of connection in mongod for test.\n\nFixes bug #1218488\n\nChange-Id: Ie4c74620937816ed0592f5ac72de99dee3173ad8\n""}, {'number': 4, 'created': '2013-09-04 21:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0bad329eb1f432e4f4d1b9794510848a416a69ab', 'message': ""Disable the pymongo pooling feature for tests\n\nBecause pymongo doesn't close connection on .close() when we use its\npool, we disable the MongoClient pooling feature for running tests.\n\nThis allow to use a normal number of connection in mongod for test.\n\nFixes bug #1218488\n\nChange-Id: Ie4c74620937816ed0592f5ac72de99dee3173ad8\n""}, {'number': 5, 'created': '2013-09-05 08:54:46.000000000', 'files': ['ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/impl_db2.py', 'run-tests.sh'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2152627f1aea1bd8c976b49c7c7a4decd3b22721', 'message': ""Disable the pymongo pooling feature for tests\n\nBecause pymongo doesn't close connection on .close() when we use its\npool, we disable the MongoClient pooling feature for running tests.\n\nThis allow to use a normal number of connection in mongod for test.\n\nFixes bug #1218488\n\nChange-Id: Ie4c74620937816ed0592f5ac72de99dee3173ad8\n""}]",2,44465,2152627f1aea1bd8c976b49c7c7a4decd3b22721,30,7,5,2813,,,0,"Disable the pymongo pooling feature for tests

Because pymongo doesn't close connection on .close() when we use its
pool, we disable the MongoClient pooling feature for running tests.

This allow to use a normal number of connection in mongod for test.

Fixes bug #1218488

Change-Id: Ie4c74620937816ed0592f5ac72de99dee3173ad8
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/65/44465/5 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/impl_db2.py', 'run-tests.sh']",3,4d3fbf2c0cf0bf82f91ed7be554596960ce09743,bug/1218488,"mongod --maxConns 32 --nojournal --noprealloc --smallfiles --quiet --noauth --port 29000 --dbpath ""${MONGO_DATA}"" --bind_ip localhost &>${MONGO_DATA}/out &","mongod --maxConns 128 --nojournal --noprealloc --smallfiles --quiet --noauth --port 29000 --dbpath ""${MONGO_DATA}"" --bind_ip localhost &>${MONGO_DATA}/out &",7,3
openstack%2Fceilometer~master~I49d82bcc2c1ac6481b0f5d321db2f70549a95d55,openstack/ceilometer,master,I49d82bcc2c1ac6481b0f5d321db2f70549a95d55,Fixed nova notifier unit test,MERGED,2013-09-05 06:09:27.000000000,2013-09-05 08:50:14.000000000,2013-09-05 08:50:14.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 4491}]","[{'number': 1, 'created': '2013-09-05 06:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/58787fb4250da3ce5b12061fd9eebecb5e61dd37', 'message': 'Fixed nova nofitier unit test\n\nThis fixed the bug #1221033 caused by the latest nova chagnes.\n\nChange-Id: I49d82bcc2c1ac6481b0f5d321db2f70549a95d55\n'}, {'number': 2, 'created': '2013-09-05 06:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/42ccdc99ddde840bc5b4bb450e52c630b5b2a6b8', 'message': 'Fixed nova nofitier unit test\n\nThis fixed the bug #1221033 caused by the latest nova chagnes.\n\nTemproarily enlarge the max allowed connection to mongoDB as a\nworkaround for bug #1218488. That bug should be addressed by\nhttps://review.openstack.org/44465\n\nChange-Id: I49d82bcc2c1ac6481b0f5d321db2f70549a95d55\n'}, {'number': 3, 'created': '2013-09-05 08:18:32.000000000', 'files': ['nova_tests/test_notifier.py', 'run-tests.sh'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/27937c395d4de5a1e10cc3b8a87cf18a740429df', 'message': 'Fixed nova notifier unit test\n\nThis fixed the bug #1221033 caused by the latest nova chagnes.\n\nTemproarily enlarge the max allowed connection to mongoDB as a\nworkaround for bug #1218488. That bug should be addressed by\nhttps://review.openstack.org/44465\n\nChange-Id: I49d82bcc2c1ac6481b0f5d321db2f70549a95d55\n'}]",7,45176,27937c395d4de5a1e10cc3b8a87cf18a740429df,18,5,3,4491,,,0,"Fixed nova notifier unit test

This fixed the bug #1221033 caused by the latest nova chagnes.

Temproarily enlarge the max allowed connection to mongoDB as a
workaround for bug #1218488. That bug should be addressed by
https://review.openstack.org/44465

Change-Id: I49d82bcc2c1ac6481b0f5d321db2f70549a95d55
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/76/45176/1 && git format-patch -1 --stdout FETCH_HEAD,['nova_tests/test_notifier.py'],1,58787fb4250da3ce5b12061fd9eebecb5e61dd37,bug/1221033," ""system_metadata"": {}, ""user_data"": None, ""cleaned"": 0, ""deleted"": None, ""vm_mode"": None, ""deleted_at"": None, ""disable_terminate"": False, ""root_device_name"": None, ""default_swap_device"": None, ""launched_on"": None, ""display_description"": None, ""key_data"": None, ""key_name"": None, ""config_drive"": None, ""power_state"": None, ""default_ephemeral_device"": None, ""progress"": 0, ""scheduled_at"": None, ""updated_at"": None, ""shutdown_terminate"": False, ""cell_name"": 'cell', ""locked"": False, ""locked_by"": None, ""launch_index"": 0, ""auto_disk_config"": False, } self.instance = nova_instance.Instance._from_db_object( context, self.instance, self.instance_data, expected_attrs=['metadata', 'system_metadata']) #for key, value in self.instance_data.iteritems(): # setattr(self.instance, key, value) #self.instance._context = self.context lambda context, uuid, kwargs, update_cells: (self.instance,"," ""system_metadata"": {}} for key, value in self.instance_data.iteritems(): setattr(self.instance, key, value) lambda context, uuid, kwargs: (self.instance,",33,4
openstack%2Fneutron~master~Ifdd03bec554a08266de859387f1901858a3be4a1,openstack/neutron,master,Ifdd03bec554a08266de859387f1901858a3be4a1,ML2 Mechanism Driver for Cisco Nexus,MERGED,2013-08-21 22:14:59.000000000,2013-09-05 07:47:07.000000000,2013-09-05 07:47:06.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 107}, {'_account_id': 1689}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6694}, {'_account_id': 6695}, {'_account_id': 7712}]","[{'number': 1, 'created': '2013-08-21 22:14:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/226deda9c9a413339e2c868c40089df475152aa6', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}, {'number': 2, 'created': '2013-08-23 23:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/791426f0276dc1e12e789dbcc10347fb09e12bee', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}, {'number': 3, 'created': '2013-08-29 22:55:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f3960a55ab1cd30486c788b9424aa7b61f5212f4', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}, {'number': 4, 'created': '2013-08-30 15:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/76d737dc6ada927d0a69b18254b96a3d495934d8', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}, {'number': 5, 'created': '2013-08-30 19:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1aee1b3293f2f06eafa2dd0135fee44197f37369', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}, {'number': 6, 'created': '2013-08-30 21:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ab1cfafd36622cc61d929a7907c44230c1d3d2e', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}, {'number': 7, 'created': '2013-08-31 18:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4a1551b969cc157fdaa2e7376bac4a3de44d5165', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}, {'number': 8, 'created': '2013-08-31 19:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd519a85c88806c52146ec6440e57fe0cf8b1f0b', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}, {'number': 9, 'created': '2013-08-31 23:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0accc0a3a4fe7dcb5ca32d9b2feae05f6ecef715', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}, {'number': 10, 'created': '2013-09-02 15:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1b1b17355bb11fe354df62d13fd587f9ead7ceab', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}, {'number': 11, 'created': '2013-09-02 16:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9332ae3cddcb056ea2dc79e443fd18ff72dff741', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}, {'number': 12, 'created': '2013-09-04 18:10:35.000000000', 'files': ['neutron/plugins/ml2/drivers/cisco/credentials_v2.py', 'neutron/plugins/ml2/drivers/cisco/config.py', 'neutron/plugins/ml2/drivers/cisco/network_models_v2.py', 'neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py', 'neutron/plugins/ml2/drivers/cisco/__init__.py', 'neutron/plugins/ml2/drivers/cisco/network_db_v2.py', 'neutron/plugins/ml2/drivers/cisco/mech_cisco_nexus.py', 'neutron/plugins/ml2/drivers/cisco/README', 'neutron/plugins/ml2/drivers/cisco/nexus_network_driver.py', 'neutron/plugins/ml2/drivers/cisco/nexus_snippets.py', 'neutron/db/migration/alembic_migrations/versions/51b4de912379_cisco_nexus_ml2_mech.py', 'neutron/plugins/ml2/drivers/cisco/exceptions.py', 'neutron/tests/unit/ml2/drivers/test_cisco_mech.py', 'etc/neutron/plugins/ml2/ml2_conf_cisco.ini', 'neutron/plugins/ml2/drivers/cisco/constants.py', 'setup.cfg', 'neutron/plugins/ml2/drivers/cisco/nexus_models_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b6d0c40f20a74d61fc1f34a2a948fbeb838fdf45', 'message': 'ML2 Mechanism Driver for Cisco Nexus\n\nPort of the quantum/plugin/cisco/nexus plugin to run under the Modular\nLayer 2 (ML2) infrastructure as defined in\nhttps://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers\n\nImplements blueprint ml2-md-cisco-nexus\n\nChange-Id: Ifdd03bec554a08266de859387f1901858a3be4a1\n'}]",186,43196,b6d0c40f20a74d61fc1f34a2a948fbeb838fdf45,98,12,12,6694,,,0,"ML2 Mechanism Driver for Cisco Nexus

Port of the quantum/plugin/cisco/nexus plugin to run under the Modular
Layer 2 (ML2) infrastructure as defined in
https://blueprints.launchpad.net/quantum/+spec/ml2-mechanism-drivers

Implements blueprint ml2-md-cisco-nexus

Change-Id: Ifdd03bec554a08266de859387f1901858a3be4a1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/96/43196/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/cisco/credentials_v2.py', 'neutron/plugins/ml2/drivers/cisco/config.py', 'neutron/plugins/ml2/drivers/cisco/network_models_v2.py', 'neutron/plugins/ml2/drivers/cisco/nexus_db_v2.py', 'neutron/plugins/ml2/drivers/cisco/__init__.py', 'neutron/plugins/ml2/drivers/cisco/network_db_v2.py', 'neutron/plugins/ml2/drivers/cisco/mech_cisco_nexus.py', 'neutron/plugins/ml2/drivers/cisco/nexus_network_driver.py', 'neutron/plugins/ml2/drivers/cisco/nexus_snippets.py', 'neutron/db/migration/alembic_migrations/versions/51b4de912379_cisco_nexus_ml2_mech.py', 'neutron/plugins/ml2/drivers/cisco/exceptions.py', 'etc/neutron/plugins/ml2/ml2_conf_cisco.ini', 'neutron/plugins/ml2/drivers/cisco/constants.py', 'setup.cfg', 'neutron/plugins/ml2/drivers/cisco/nexus_models_v2.py']",15,226deda9c9a413339e2c868c40089df475152aa6,bp/s,"# Copyright (c) 2013 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import sqlalchemy as sa from neutron.db import model_base class NexusPortBinding(model_base.BASEV2): """"""Represents a binding of VM's to nexus ports."""""" __tablename__ = ""cisco_nexusport_bindings"" id = sa.Column(sa.Integer, primary_key=True, autoincrement=True) port_id = sa.Column(sa.String(255)) vlan_id = sa.Column(sa.Integer, nullable=False) switch_ip = sa.Column(sa.String(255)) instance_id = sa.Column(sa.String(255)) def __repr__(self): """"""Just the binding, without the id key."""""" return (""<NexusPortBinding(%s,%s,%s,%s)>"" % (self.port_id, self.vlan_id, self.switch_ip, self.instance_id)) def __eq__(self, other): """"""Compare only the binding, without the id key."""""" return ( self.port_id == other.port_id and self.vlan_id == other.vlan_id and self.switch_ip == other.switch_ip and self.instance_id == other.instance_id ) ",,1735,0
openstack%2Fhorizon~master~Ie53c5552159304e1f1304ac6211b3accfd9aa623,openstack/horizon,master,Ie53c5552159304e1f1304ac6211b3accfd9aa623,Display a message on the login page,MERGED,2013-08-28 15:32:25.000000000,2013-09-05 07:47:04.000000000,2013-09-05 07:47:03.000000000,"[{'_account_id': 3}, {'_account_id': 1816}, {'_account_id': 4978}, {'_account_id': 5280}, {'_account_id': 5623}, {'_account_id': 6230}, {'_account_id': 7585}]","[{'number': 1, 'created': '2013-08-28 15:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/74a57eb33acf58cad6748e00a8f41bc3bfa11031', 'message': ""Display a message on the login page\n\nIn some cases, particularly when having to log the user out after\nperforming some action (e.g. password change), we want to display a\nfriendly message on the login screen to explain to the user why they\nhave been redirected to the login page.\n\nThis adds a function to do so, and uses it in a couple of places:\n - When updating one's own password using the Settings panel\n - Session time out\n - HTTP 401\n\nChange-Id: Ie53c5552159304e1f1304ac6211b3accfd9aa623\nImplements: blueprint messages-on-login-page\n""}, {'number': 2, 'created': '2013-09-04 12:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ba15ebba8204b6b4407a6d9a21b22b0fab026b2e', 'message': ""Display a message on the login page\n\nIn some cases, particularly when having to log the user out after\nperforming some action (e.g. password change), we want to display a\nfriendly message on the login screen to explain to the user why they\nhave been redirected to the login page.\n\nThis adds a function to do so, and uses it in a couple of places:\n - When updating one's own password using the Settings panel\n - Session time out\n - HTTP 401\n\nChange-Id: Ie53c5552159304e1f1304ac6211b3accfd9aa623\nImplements: blueprint messages-on-login-page\n""}, {'number': 3, 'created': '2013-09-04 13:59:23.000000000', 'files': ['horizon/templates/auth/_login.html', 'openstack_dashboard/dashboards/settings/password/forms.py', 'horizon/test/helpers.py', 'horizon/utils/functions.py', 'horizon/middleware.py', 'openstack_dashboard/dashboards/settings/password/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/85f4c8b473cf550cf3b0df04ae26b8684801f0e8', 'message': ""Display a message on the login page\n\nIn some cases, particularly when having to log the user out after\nperforming some action (e.g. password change), we want to display a\nfriendly message on the login screen to explain to the user why they\nhave been redirected to the login page.\n\nThis adds a function to do so, and uses it in a couple of places:\n - When updating one's own password using the Settings panel\n - Session time out\n - HTTP 401\n\nChange-Id: Ie53c5552159304e1f1304ac6211b3accfd9aa623\nImplements: blueprint messages-on-login-page\n""}]",7,44077,85f4c8b473cf550cf3b0df04ae26b8684801f0e8,31,7,3,4978,,,0,"Display a message on the login page

In some cases, particularly when having to log the user out after
performing some action (e.g. password change), we want to display a
friendly message on the login screen to explain to the user why they
have been redirected to the login page.

This adds a function to do so, and uses it in a couple of places:
 - When updating one's own password using the Settings panel
 - Session time out
 - HTTP 401

Change-Id: Ie53c5552159304e1f1304ac6211b3accfd9aa623
Implements: blueprint messages-on-login-page
",git fetch https://review.opendev.org/openstack/horizon refs/changes/77/44077/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/auth/_login.html', 'openstack_dashboard/dashboards/settings/password/forms.py', 'horizon/utils/functions.py', 'horizon/middleware.py', 'openstack_dashboard/dashboards/settings/password/tests.py']",5,74a57eb33acf58cad6748e00a8f41bc3bfa11031,bp/messages-on-login-page," 'oldpwd', 'normalpwd',).AndReturn(None) @test.create_stubs({api.keystone: ('user_update_own_password', )}) def test_change_password_shows_message_on_login_page(self): api.keystone.user_update_own_password(IsA(http.HttpRequest), 'oldpwd', 'normalpwd').AndReturn(None) self.mox.ReplayAll() formData = {'method': 'PasswordForm', 'current_password': 'oldpwd', 'new_password': 'normalpwd', 'confirm_password': 'normalpwd'} res = self.client.post(INDEX_URL, formData, follow=True) info_msg = ""Password changed. Please log in again to continue."" self.assertContains(res, info_msg)"," 'oldpwd', 'normalpwd',).AndReturn(None) ",46,11
openstack%2Fnova~master~Iee4a47b3dbe96f66c061b51ae9512dad9b86a870,openstack/nova,master,Iee4a47b3dbe96f66c061b51ae9512dad9b86a870,Change finish_revert_resize paths to use objects,MERGED,2013-08-21 11:43:44.000000000,2013-09-05 07:08:46.000000000,2013-09-05 07:08:44.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-08-21 11:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d8c981e6a6d3a26351a8d1dd9b5923232d9d7cc', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 2, 'created': '2013-08-21 21:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/abe12a4be007a5284c9db3de735a1cc86f1340f7', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 3, 'created': '2013-08-23 17:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bfb516f575ef7630bf7e8c827b3047fa09de8361', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 4, 'created': '2013-08-23 17:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7fd0774e41b36314973ef8cd7b24b7daf0e0b8d3', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 5, 'created': '2013-08-23 19:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/381c11fd48d723f312d6ec356874c5b133114793', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 6, 'created': '2013-08-23 19:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2081fabab2da887b4de3801c4d580d67290ce5c1', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 7, 'created': '2013-08-23 22:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9611cefe4ec10b478d3886a660dc955e2130dd0c', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 8, 'created': '2013-08-24 05:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a6949c1ae8976b9b072f9a73d582b4ca97aa017', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 9, 'created': '2013-08-24 21:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63b9673b24c1ff1e575af62051b99b8f747a6feb', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 10, 'created': '2013-08-28 10:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b258532150dc4eaae1cbbae2119231c382c4e9f', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 11, 'created': '2013-08-28 20:26:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc0b10699e701476043eb265083d62f77437ac8c', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 12, 'created': '2013-08-30 14:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3861c8ab74e72b9055aa96b7a5758fb578fd1d29', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 13, 'created': '2013-08-30 18:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/81246627ea1232b0af2afd80626322ccf623bc5f', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 14, 'created': '2013-09-03 22:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4baf6fe31ee4627a417cf09a68a93657f58cac97', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}, {'number': 15, 'created': '2013-09-04 17:28:38.000000000', 'files': ['nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ca4a048ca1df65c69b3bb57ae54adea1fdf81b53', 'message': ""Change finish_revert_resize paths to use objects\n\nConverts calls to compute's finish_revert_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870\n""}]",0,43107,ca4a048ca1df65c69b3bb57ae54adea1fdf81b53,61,9,15,1030,,,0,"Change finish_revert_resize paths to use objects

Converts calls to compute's finish_revert_resize to pass new-world instance
and migration objects.

Related to blueprint unified-object-model

Change-Id: Iee4a47b3dbe96f66c061b51ae9512dad9b86a870
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/43107/11 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/tests/compute/test_compute.py']",4,8d8c981e6a6d3a26351a8d1dd9b5923232d9d7cc,bp/compute-api-objects," sys_meta = inst.system_metadata migration=migration, instance=instance, reservations=reservations) instance = self._create_fake_instance_obj() instance.system_metadata = dict(instance_type_id=old) sys_meta = dict(instance.system_metadata)"," sys_meta = utils.metadata_to_dict(inst['system_metadata']) instance_p = obj_base.obj_to_primitive(instance) migration_p = obj_base.obj_to_primitive(migration) migration=migration_p, instance=instance_p, reservations=reservations) instance.refresh() instance = dict(system_metadata=list()) instance['system_metadata'].append(dict(key='instance_type_id', value=old)) sys_meta = dict(instance_type_id=old)",52,48
openstack%2Fnova~master~Ic513b826087ced39c8aa939e93fe6c0d250dc1a5,openstack/nova,master,Ic513b826087ced39c8aa939e93fe6c0d250dc1a5,Change finish_resize paths to use objects,MERGED,2013-08-21 09:20:16.000000000,2013-09-05 07:08:14.000000000,2013-09-05 07:08:12.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1247}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-08-21 09:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ca1a36591593e0ac53a58a9a7d5d224fac8ddb4', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 2, 'created': '2013-08-21 11:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f38bfda60a1bb0dc8f55f3f93a08a27f42d450d', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 3, 'created': '2013-08-21 21:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ab2b97d4cc7b714e8f82e929333c5fc23f53ed2', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 4, 'created': '2013-08-23 17:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93a00a96ab675943b0be60228645dd38cbec8ddf', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 5, 'created': '2013-08-23 17:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c66e2385353a23002b7acf0477285ead6f7a56bf', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 6, 'created': '2013-08-23 19:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16e8b5098ef8f2e53ecf9aeb2f3c8ed93c6176b0', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 7, 'created': '2013-08-23 19:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5313ca64632ba934f2939fb99f7994e418d5e8e6', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 8, 'created': '2013-08-23 22:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/552b1b00245762aa0fa96f02e1856db8d01f0262', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 9, 'created': '2013-08-24 05:23:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a25ed92bb0f1450692a8a950e84d9a866d49fd5d', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 10, 'created': '2013-08-24 21:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/829cbc4076a751665e0dff8d3c0e799020e85636', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 11, 'created': '2013-08-28 10:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d40fe91bb8d38d8c1013a346fd36784d6efd24b5', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 12, 'created': '2013-08-28 20:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de796e8231ecb1ef6a6b8129399daf13b993c152', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 13, 'created': '2013-08-30 14:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dde301cdfa5109ba8f64298048eecae154a3d8c9', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 14, 'created': '2013-08-30 18:25:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f9931fd778708822ca791ab6358c07b84f1144a', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 15, 'created': '2013-09-03 22:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8bb264fbf94d4962e00096d1db13d34a72ae284b', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}, {'number': 16, 'created': '2013-09-04 17:28:34.000000000', 'files': ['nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/608c67439c8fcfa1a2fddd1087ca1fe998a8f9fd', 'message': ""Change finish_resize paths to use objects\n\nConverts calls to compute's finish_resize to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5\n""}]",0,43080,608c67439c8fcfa1a2fddd1087ca1fe998a8f9fd,69,7,16,1030,,,0,"Change finish_resize paths to use objects

Converts calls to compute's finish_resize to pass new-world instance
and migration objects.

Related to blueprint unified-object-model

Change-Id: Ic513b826087ced39c8aa939e93fe6c0d250dc1a5
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/43080/16 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/tests/compute/test_compute.py']",4,4ca1a36591593e0ac53a58a9a7d5d224fac8ddb4,bp/compute-api-objects," image = 'fake-image' disk_info = 'fake-disk-info' migration = migration_obj.Migration.get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') orig_mig_save = migration.save orig_inst_save = instance.save self.mox.StubOutWithMock(self.compute, '_get_instance_nw_info') self.mox.StubOutWithMock(self.compute, '_legacy_nw_info') self.mox.StubOutWithMock(self.compute, '_notify_about_instance_usage') self.mox.StubOutWithMock(self.compute.driver, 'finish_migration') self.mox.StubOutWithMock(self.compute, '_refresh_block_device_connection_info') self.mox.StubOutWithMock(self.compute, '_get_instance_volume_block_device_info') self.mox.StubOutWithMock(migration, 'save') self.mox.StubOutWithMock(instance, 'save') def _mig_save(): self.assertEqual(migration.status, 'finished') self.assertEqual(vm_state, instance.vm_state) self.assertEqual(task_states.RESIZE_FINISH, instance.task_state) orig_mig_save() def _instance_save1(): self.assertEqual(instance_type['id'], instance.instance_type_id) orig_inst_save() def _instance_save2(expected_task_state=None): self.assertEqual(task_states.RESIZE_MIGRATED, expected_task_state) self.assertEqual(task_states.RESIZE_FINISH, instance.task_state) orig_inst_save(expected_task_state=expected_task_state) def _instance_save3(expected_task_state=None): self.assertEqual(task_states.RESIZE_FINISH, expected_task_state) self.assertEqual(vm_states.RESIZED, instance.vm_state) self.assertEqual(None, instance.task_state) self.assertIn('launched_at', instance.obj_what_changed()) orig_inst_save(expected_task_state=expected_task_state) # First save to update flavor instance.save().WithSideEffects(_instance_save1) self.compute._get_instance_nw_info( self.context, instance).AndReturn('fake-nwinfo1') # 2nd save to update task state exp_kwargs = dict(expected_task_state=task_states.RESIZE_MIGRATED) instance.save(**exp_kwargs).WithSideEffects(_instance_save2) self.compute._notify_about_instance_usage( self.context, instance, 'finish_resize.start', network_info='fake-nwinfo1') self.compute._refresh_block_device_connection_info( self.context, instance).AndReturn('fake-bdms') self.compute._get_instance_volume_block_device_info( self.context, instance, bdms='fake-bdms').AndReturn('fake-bdminfo') self.compute._legacy_nw_info( 'fake-nwinfo1').AndReturn('fake-nwinfo2') # nova.conf sets the default flavor to m1.small and the test # sets the default flavor to m1.tiny so they should be different # which makes this a resize self.compute.driver.finish_migration(self.context, migration, instance, disk_info, 'fake-nwinfo2', image, True, 'fake-bdminfo', power_on) # Ensure instance status updates is after the migration finish migration.save().WithSideEffects(_mig_save) exp_kwargs = dict(expected_task_state=task_states.RESIZE_FINISH) instance.save(**exp_kwargs).WithSideEffects(_instance_save3) self.compute._notify_about_instance_usage( self.context, instance, 'finish_resize.end', network_info='fake-nwinfo1') # NOTE(comstud): This actually does the mox.ReplayAll() reservations = self._ensure_quota_reservations_committed() migration=migration, disk_info=disk_info, image=image, instance=instance, migration=migration, disk_info={}, image={}, instance=instance, migration = migration_obj.Migration.get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') migration=migration, disk_info={}, image={}, instance=instance, migration=migration, disk_info={}, image={}, instance=instance) migration=migration, disk_info={}, image={}, instance=instance) migration=migration, disk_info={}, image={}, instance=instance) migration_p = obj_base.obj_to_primitive(migration)"," self.power_on = power_on self.fake_finish_migration_called = False def fake_finish_migration(context, migration, instance, disk_info, network_info, image_meta, resize_instance, block_device_info=None, power_on=True): # nova.conf sets the default flavor to m1.small and the test # sets the default flavor to m1.tiny so they should be different # which makes this a resize self.assertTrue(resize_instance) # ensure the power_on value is what we expect self.assertEqual(self.power_on, power_on) self.fake_finish_migration_called = True def fake_migration_update(context, id, values): # Ensure instance status updates is after the migration finish migration_ref = db.migration_get(context, id) instance_uuid = migration_ref['instance_uuid'] instance = db.instance_get_by_uuid(context, instance_uuid) self.assertFalse(instance['vm_state'] == vm_states.RESIZED) self.assertEqual(instance['task_state'], task_states.RESIZE_FINISH) self.stubs.Set(self.compute.driver, 'finish_migration', fake_finish_migration) self.stubs.Set(db, 'migration_update', fake_migration_update) reservations = self._ensure_quota_reservations_committed() migration_ref = db.migration_get_by_instance_and_status( self.context.elevated(), instance['uuid'], 'pre-migrating') instance_p = obj_base.obj_to_primitive(instance) migration=jsonutils.to_primitive(migration_ref), disk_info={}, image={}, instance=instance_p, self.assertTrue(self.fake_finish_migration_called) instance_p = obj_base.obj_to_primitive(instance) migration_p = obj_base.obj_to_primitive(migration) migration=migration_p, disk_info={}, image={}, instance=instance_p, instance.refresh() migration_ref = db.migration_get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') instance_p = obj_base.obj_to_primitive(instance) migration=jsonutils.to_primitive(migration_ref), disk_info={}, image={}, instance=instance_p, instance_p = obj_base.obj_to_primitive(instance) migration_p = obj_base.obj_to_primitive(migration) migration=migration_p, disk_info={}, image={}, instance=instance_p) instance.refresh() instance_p = obj_base.obj_to_primitive(instance) migration_p = obj_base.obj_to_primitive(migration) migration=migration_p, disk_info={}, image={}, instance=instance_p) instance.refresh() instance_p = obj_base.obj_to_primitive(instance) migration_p = obj_base.obj_to_primitive(migration) migration=migration_p, disk_info={}, image={}, instance=instance_p) instance.refresh()",149,104
openstack%2Foslo-incubator~master~I89cf868c0b515b6caf20987bfa2d6b73c860672a,openstack/oslo-incubator,master,I89cf868c0b515b6caf20987bfa2d6b73c860672a,Introduces The Guru Meditation Report,MERGED,2013-07-09 18:34:33.000000000,2013-09-05 07:03:23.000000000,2013-09-05 07:03:23.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1779}, {'_account_id': 1994}, {'_account_id': 2271}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 7677}]","[{'number': 1, 'created': '2013-07-09 18:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/9c16cac9a55be61e781097794d5c5d8ced661f90', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actuall Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introducted in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 2, 'created': '2013-07-09 19:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/07366320de07f2c991f57930fe1bd7884604efd6', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actuall Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introducted in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 3, 'created': '2013-07-10 16:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a7da925813a01e37d0c4d142eea39962e72ddb02', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actuall Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introducted in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 4, 'created': '2013-07-10 17:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/1e0003d93839dece4bf2560974f8fb6189ed5850', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actuall Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introducted in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 5, 'created': '2013-07-11 15:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/6ba9fecb00ef227853e67bb3fd374c7067a2cd9d', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actuall Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introducted in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 6, 'created': '2013-07-11 18:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/135168800067d69a2821d9254c3d3aa083c8e04c', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actuall Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introducted in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 7, 'created': '2013-07-16 15:39:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/e218961f84f01ebcf68d2a9a563e4f9057e5a681', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actuall Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introducted in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 8, 'created': '2013-07-17 13:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c1801891d8e8c281cd352db89d363d52d75e6f46', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actuall Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introducted in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 9, 'created': '2013-07-17 14:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/1ae5a94b78634e6fd55d70d91d8761c08d74919a', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actuall Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introducted in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 10, 'created': '2013-07-18 13:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/6e0926c0b7e7061a9865665814b3ca99ae70dfcb', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actuall Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introducted in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 11, 'created': '2013-07-22 18:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/9e97a85336421008bcfcc8783df4da1b7838b686', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actual Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introduced in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 12, 'created': '2013-07-23 16:37:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/24fc279eb8b2f400fba13545ae1774964c934a3f', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actual Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introduced in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 13, 'created': '2013-07-24 15:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/8e1ec3e9aa9b33f19e16ec946fc4df0784e29171', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actual Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introduced in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 14, 'created': '2013-07-30 18:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3981b0d359798521b023c8a671f1cee8350fda23', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actual Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introduced in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 15, 'created': '2013-08-14 15:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c313c39535ef3ce3a6a77f5d0dc67cd666c19e3f', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actual Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introduced in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 16, 'created': '2013-08-27 14:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/719b2dc9a0a033a762137b209181ec0f36009166', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actual Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introduced in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 17, 'created': '2013-08-31 01:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/252f5ef7a10433cb6c1c8054435ccfa1d6d01ccb', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actual Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introduced in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}, {'number': 18, 'created': '2013-09-03 20:56:50.000000000', 'files': ['openstack/common/report/guru_meditation_report.py', 'tests/unit/reports/test_guru_meditation_report.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/851d0ec901dbcac18a9a57b3f8cf6faf20851441', 'message': 'Introduces The Guru Meditation Report\n\nIntroduces the classes for the actual Guru Meditation Report,\nand utilities for creating a hook to autorun it on SIGUSR1.\nThe Text version is introduced in this commit; it is called\nTextGuruMeditation.  This is the last of the Guru Meditation\nReport/Openstack Common Reporting Framework commits.\n\nChange-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a\nImplements: bp guru-meditation-report\n'}]",28,36318,851d0ec901dbcac18a9a57b3f8cf6faf20851441,82,8,18,7677,,,0,"Introduces The Guru Meditation Report

Introduces the classes for the actual Guru Meditation Report,
and utilities for creating a hook to autorun it on SIGUSR1.
The Text version is introduced in this commit; it is called
TextGuruMeditation.  This is the last of the Guru Meditation
Report/Openstack Common Reporting Framework commits.

Change-Id: I89cf868c0b515b6caf20987bfa2d6b73c860672a
Implements: bp guru-meditation-report
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/18/36318/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/report/guru_meditation_report.py', 'tests/unit/reports/test_guru_meditation_report.py']",2,9c16cac9a55be61e781097794d5c5d8ced661f90,bp/guru-meditation-report,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from __future__ import print_function from openstack.common.report import guru_meditation_report as gmr from openstack.common.report.models import with_default_views as mwdv from tests import utils import os import signal import sys from StringIO import StringIO # needed to get greenthreads import greenlet class FakeVersionObj(object): def vendor_string(self): return 'Cheese Shoppe' def product_string(self): return 'Sharp Cheddar' def version_string_with_package(self): return '1.0.0' def skip_body_lines(start_line, report_lines): curr_line = start_line while (len(report_lines[curr_line]) == 0 or report_lines[curr_line][0] != '='): curr_line += 1 return curr_line class TestGuruMeditationReport(utils.BaseTestCase): def setUp(self): super(TestGuruMeditationReport, self).setUp() self.curr_g = greenlet.getcurrent() self.report = gmr.TextGuruMeditation(FakeVersionObj()) self.old_stderr = None def test_basic_report(self): report_lines = self.report.run().split('\n') target_str_header = ['========================================================================', # noqa '==== Guru Meditation ====', # noqa '========================================================================', # noqa '||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||', # noqa '', '', '========================================================================', # noqa '==== Package ====', # noqa '========================================================================', # noqa 'product = Sharp Cheddar', 'version = 1.0.0', 'vendor = Cheese Shoppe', '========================================================================', # noqa '==== Threads ====', # noqa '========================================================================'] # noqa # first the header and version info... self.assertEquals(target_str_header, report_lines[0:len(target_str_header)]) # followed by at least one thread... self.assertRegexpMatches(report_lines[len(target_str_header)], r'------(\s+)Thread #\d+\1\s?------') self.assertEquals('', report_lines[len(target_str_header) + 1]) # followed by more thread stuff stuff... curr_line = skip_body_lines(len(target_str_header) + 2, report_lines) # followed by at least one green thread target_str_gt = ['========================================================================', # noqa '==== Green Threads ====', # noqa '========================================================================', # noqa '------ Green Thread ------', # noqa ''] end_bound = curr_line + len(target_str_gt) self.assertEquals(target_str_gt, report_lines[curr_line:end_bound]) # followed by some more green thread stuff curr_line = skip_body_lines(curr_line + len(target_str_gt), report_lines) # followed finally by the configuration target_str_config = ['========================================================================', # noqa '==== Configuration ====', # noqa '========================================================================', # noqa '', 'default: '] end_bound = curr_line + len(target_str_config) self.assertEquals(target_str_config, report_lines[curr_line:end_bound]) def test_reg_persistent_section(self): def fake_gen(): fake_data = {'cheddar': ['sharp', 'mild'], 'swiss': ['with holes', 'with lots of holes'], 'american': ['orange', 'yellow']} return mwdv.ModelWithDefaultViews(data=fake_data) gmr.TextGuruMeditation.register_section('Cheese Types', fake_gen) report_lines = self.report.run() target_lst = ['========================================================================', # noqa '==== Cheese Types ====', # noqa '========================================================================', # noqa 'swiss = ', ' with holes', ' with lots of holes', 'american = ', ' orange', ' yellow', 'cheddar = ', ' sharp', ' mild'] target_str = '\n'.join(target_lst) self.assertIn(target_str, report_lines) def test_register_autorun(self): gmr.TextGuruMeditation.setup_autorun(FakeVersionObj()) self.old_stderr = sys.stderr sys.stderr = StringIO() os.kill(os.getpid(), signal.SIGUSR1) self.assertIn('Guru Meditation', sys.stderr.getvalue()) def tearDown(self): super(TestGuruMeditationReport, self).tearDown() if self.old_stderr is not None: sys.stderr = self.old_stderr ",,313,0
openstack%2Fmurano-deployment~release-0.2~I2f14b97232f0ad772a339cd7d0ebf25e831a76cf,openstack/murano-deployment,release-0.2,I2f14b97232f0ad772a339cd7d0ebf25e831a76cf,Three occurences of 'bad' character replaced.,MERGED,2013-09-04 19:28:07.000000000,2013-09-05 07:02:59.000000000,2013-09-05 07:02:59.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7562}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-09-04 19:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/9204f10d69fa2c127f211d437e8aa93c964554bf', 'message': ""Three occurences of 'bad' character replaced.\n\nChange-Id: I2f14b97232f0ad772a339cd7d0ebf25e831a76cf\n""}, {'number': 2, 'created': '2013-09-04 19:29:21.000000000', 'files': ['image-builder/share/scripts/wpi.ps1', 'image-builder/share/files/ws-2012-core/autounattend.xml', 'image-builder/share/files/ws-2012-std/autounattend.xml'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/02877d9af7e002f34a5dac99bcccb0a41ca725eb', 'message': ""Three occurences of 'bad' character replaced.\n\nFixes: MRN-947\n\nChange-Id: I2f14b97232f0ad772a339cd7d0ebf25e831a76cf\n""}]",0,45106,02877d9af7e002f34a5dac99bcccb0a41ca725eb,8,5,2,7562,,,0,"Three occurences of 'bad' character replaced.

Fixes: MRN-947

Change-Id: I2f14b97232f0ad772a339cd7d0ebf25e831a76cf
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/06/45106/2 && git format-patch -1 --stdout FETCH_HEAD,"['image-builder/share/scripts/wpi.ps1', 'image-builder/share/files/ws-2012-core/autounattend.xml', 'image-builder/share/files/ws-2012-std/autounattend.xml']",3,9204f10d69fa2c127f211d437e8aa93c964554bf,bad-character-fix, <CommandLine>%WINDIR%\System32\WindowsPowerShell\v1.0\powershell.exe Import-Module ServerManager; Install-WindowsFeature NET-Framework-Core -Source D:\Sources\SxS</CommandLine> , <CommandLine>%WINDIR%\System32\WindowsPowerShell\v1.0\powershell.exe Import-Module ServerManager; Install-WindowsFeature NET-Framework-Core –Source D:\Sources\SxS</CommandLine> ,3,3
openstack%2Fheat~master~Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6,openstack/heat,master,Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6,Adding IPsec site connection to Heat resources,MERGED,2013-07-19 22:35:37.000000000,2013-09-05 06:40:46.000000000,2013-09-05 06:40:46.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 2031}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6917}, {'_account_id': 7385}, {'_account_id': 7787}]","[{'number': 1, 'created': '2013-07-19 22:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5b698573f6d445a3810f37d74a62e583a923ad86', 'message': 'Adding VPNaaS to Heat resources.\n\nAdds VPNaaS components:\n- VPNService\n- VPNConnection\n- IKEPolicy\n- IPsecPolicy\nto resources supported by Heat.\n\nImplements: blueprint vpnaas-support\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\n'}, {'number': 2, 'created': '2013-07-22 13:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/409dc4e627a82f5dec586e6bac24e8f3ed32b1c3', 'message': 'Adding VPNaaS to Heat resources.\n\nAdds VPNaaS components:\n- VPNService\n- VPNConnection\n- IKEPolicy\n- IPsecPolicy\nto resources supported by Heat.\n\nImplements: blueprint vpnaas-support\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\n'}, {'number': 3, 'created': '2013-08-13 09:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c6003ecabdbb3e11d3d06639e662b5bf2b221f4e', 'message': 'Adding VPNaaS to Heat resources.\n\nAdds VPNaaS components:\n- VPNService\n- IPsecSiteConnection\n- IKEPolicy\n- IPsecPolicy\nto resources supported by Heat.\n\nImplements: blueprint vpnaas-support\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\n'}, {'number': 4, 'created': '2013-08-13 10:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7aba7a5722272d54e0944f3b55e88fe68967804b', 'message': 'Adding VPNaaS to Heat resources.\n\nAdds VPNaaS components:\n- VPNService\n- IPsecSiteConnection\n- IKEPolicy\n- IPsecPolicy\nto resources supported by Heat.\n\nImplements: blueprint vpnaas-support\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\n'}, {'number': 5, 'created': '2013-08-13 10:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/14c06eb8c50ec151b0891aa6637ac566d1f52167', 'message': 'Adding VPNaaS to Heat resources.\n\nAdds VPNaaS components:\n- VPNService\n- IPsecSiteConnection\n- IKEPolicy\n- IPsecPolicy\nto resources supported by Heat.\n\nImplements: blueprint vpnaas-support\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\n'}, {'number': 6, 'created': '2013-08-13 13:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dd3f3fb28c635b69a8af1667dadb638c512c3e73', 'message': 'Adding VPNaaS to Heat resources.\n\nAdds VPNaaS components:\n- VPNService\n- IPsecSiteConnection\n- IKEPolicy\n- IPsecPolicy\nto resources supported by Heat.\n\nImplements: blueprint vpnaas-support\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\n'}, {'number': 8, 'created': '2013-08-14 16:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3571ab01c718012567b3064245d7c8341fd4f903', 'message': 'Adding VPNaaS to Heat resources.\n\nAdds VPNaaS components:\n- VPNService\n- IPsecSiteConnection\n- IKEPolicy\n- IPsecPolicy\nto resources supported by Heat.\n\nImplements: blueprint vpnaas-support\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\n'}, {'number': 7, 'created': '2013-08-14 16:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6649986bdb594d270ec0e2b43ea0575553de2a97', 'message': 'Adding VPNaaS to Heat resources.\n\nAdds VPNaaS components:\n- VPNService\n- IPsecSiteConnection\n- IKEPolicy\n- IPsecPolicy\nto resources supported by Heat.\n\nImplements: blueprint vpnaas-support\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\n'}, {'number': 9, 'created': '2013-08-30 15:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3cfaa85c35d6bb08718bd943cb96d29c8d2d6d27', 'message': 'Adding VPNaaS to Heat resources.\n\nAdds VPNaaS components:\n- VPNService\n- IPsecSiteConnection\n- IKEPolicy\n- IPsecPolicy\nto resources supported by Heat with unit tests.\n\nImplements: blueprint vpnaas-support\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\n'}, {'number': 10, 'created': '2013-09-03 15:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a7d26b9b8ac42a0d18fa2789efb017171b259049', 'message': 'Adding IPsec site connection to Heat resources\n\nAdds Neutron IPsec site connection component to resources\nsupported by Heat with unit tests.\n\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\nImplements: blueprint vpnaas-support\n'}, {'number': 11, 'created': '2013-09-04 09:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2f1ba6c840713d1acdc66fb24c1460de640179b0', 'message': 'Adding IPsec site connection to Heat resources\n\nAdds Neutron IPsec site connection component to resources\nsupported by Heat with unit tests.\n\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\nImplements: blueprint vpnaas-support\n'}, {'number': 12, 'created': '2013-09-04 22:59:57.000000000', 'files': ['heat/engine/resources/neutron/vpnservice.py', 'heat/tests/test_neutron_vpnservice.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/452f1ec16709abf541ad6bf1a3216ba549661895', 'message': 'Adding IPsec site connection to Heat resources\n\nAdds Neutron IPsec site connection component to resources\nsupported by Heat with unit tests.\n\nChange-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6\nImplements: blueprint vpnaas-support\n'}]",4,37994,452f1ec16709abf541ad6bf1a3216ba549661895,40,12,12,6917,,,0,"Adding IPsec site connection to Heat resources

Adds Neutron IPsec site connection component to resources
supported by Heat with unit tests.

Change-Id: Idf3c92b9a7ac513e7f7ab0d2501668405189ebc6
Implements: blueprint vpnaas-support
",git fetch https://review.opendev.org/openstack/heat refs/changes/94/37994/12 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/quantum/vpnservice.py', 'heat/engine/clients.py']",2,5b698573f6d445a3810f37d74a62e583a923ad86,bp/vpnaas-support, from neutronclient.v2_0 import client as quantumclient, from quantumclient.v2_0 import client as quantumclient,224,1
openstack%2Fheat~master~I5014c50d51afe6a3a9b62cf3e88cbd6f7f60a62e,openstack/heat,master,I5014c50d51afe6a3a9b62cf3e88cbd6f7f60a62e,Adding IPsec policy to Heat resources,MERGED,2013-09-03 15:42:16.000000000,2013-09-05 06:39:31.000000000,2013-09-05 06:39:31.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6917}, {'_account_id': 7385}]","[{'number': 1, 'created': '2013-09-03 15:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/669bbd50f03c70a225ba191916fb23a662714c9e', 'message': 'Adding IPsec policy to Heat resources\n\nAdds Neutron IPsec policy component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I5014c50d51afe6a3a9b62cf3e88cbd6f7f60a62e\nImplements: blueprint vpnaas-support\n'}, {'number': 2, 'created': '2013-09-04 09:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b54c23160c624144cce1c027e6cb1cdd4ced2642', 'message': 'Adding IPsec policy to Heat resources\n\nAdds Neutron IPsec policy component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I5014c50d51afe6a3a9b62cf3e88cbd6f7f60a62e\nImplements: blueprint vpnaas-support\n'}, {'number': 3, 'created': '2013-09-04 09:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8658c464594c3524807342582446379ac55c95ac', 'message': 'Adding IPsec policy to Heat resources\n\nAdds Neutron IPsec policy component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I5014c50d51afe6a3a9b62cf3e88cbd6f7f60a62e\nImplements: blueprint vpnaas-support\n'}, {'number': 4, 'created': '2013-09-04 22:59:56.000000000', 'files': ['heat/engine/resources/neutron/vpnservice.py', 'heat/tests/test_neutron_vpnservice.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/aa8a3b87a23bf24729cfbba5f0b65722d6fc86c5', 'message': 'Adding IPsec policy to Heat resources\n\nAdds Neutron IPsec policy component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I5014c50d51afe6a3a9b62cf3e88cbd6f7f60a62e\nImplements: blueprint vpnaas-support\n'}]",0,44907,aa8a3b87a23bf24729cfbba5f0b65722d6fc86c5,19,8,4,6917,,,0,"Adding IPsec policy to Heat resources

Adds Neutron IPsec policy component to resources
supported by Heat with unit tests.

Change-Id: I5014c50d51afe6a3a9b62cf3e88cbd6f7f60a62e
Implements: blueprint vpnaas-support
",git fetch https://review.opendev.org/openstack/heat refs/changes/07/44907/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/neutron/vpnservice.py', 'heat/tests/test_neutron_vpnservice.py']",2,669bbd50f03c70a225ba191916fb23a662714c9e,bp/vpnaas-support,"ipsecpolicy_template = ''' { ""AWSTemplateFormatVersion"" : ""2010-09-09"", ""Description"" : ""Template to test IPsec policy resource"", ""Parameters"" : {}, ""Resources"" : { ""IPsecPolicy"" : { ""Type"" : ""OS::Neutron::IPsecPolicy"", ""Properties"" : { ""name"" : ""IPsecPolicy"", ""description"" : ""My new IPsec policy"", ""transform_protocol"": ""esp"", ""encapsulation_mode"" : ""tunnel"", ""auth_algorithm"" : ""sha1"", ""encryption_algorithm"" : ""3des"", ""lifetime"" : { ""units"" : ""seconds"", ""value"" : 3600 }, ""pfs"" : ""group5"" } } } } ''' @skipIf(neutronclient is None, 'neutronclient unavailable') class IPsecPolicyTest(HeatTestCase): IPSEC_POLICY_CONF = { 'ipsecpolicy': { 'name': 'IPsecPolicy', 'description': 'My new IPsec policy', 'transform_protocol': 'esp', 'encapsulation_mode': 'tunnel', 'auth_algorithm': 'sha1', 'encryption_algorithm': '3des', 'lifetime': { 'units': 'seconds', 'value': 3600 }, 'pfs': 'group5' } } def setUp(self): super(IPsecPolicyTest, self).setUp() self.m.StubOutWithMock(neutronclient.Client, 'create_ipsecpolicy') self.m.StubOutWithMock(neutronclient.Client, 'delete_ipsecpolicy') self.m.StubOutWithMock(neutronclient.Client, 'show_ipsecpolicy') self.m.StubOutWithMock(neutronclient.Client, 'update_ipsecpolicy') self.m.StubOutWithMock(clients.OpenStackClients, 'keystone') utils.setup_dummy_db() def create_ipsecpolicy(self): clients.OpenStackClients.keystone().AndReturn( fakes.FakeKeystoneClient()) neutronclient.Client.create_ipsecpolicy( self.IPSEC_POLICY_CONF).AndReturn( {'ipsecpolicy': {'id': 'ips123'}}) snippet = template_format.parse(ipsecpolicy_template) self.stack = utils.parse_stack(snippet) return vpnservice.IPsecPolicy('ipsecpolicy', snippet['Resources']['IPsecPolicy'], self.stack) @utils.stack_delete_after def test_create(self): rsrc = self.create_ipsecpolicy() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_create_failed(self): clients.OpenStackClients.keystone().AndReturn( fakes.FakeKeystoneClient()) neutronclient.Client.create_ipsecpolicy( self.IPSEC_POLICY_CONF).AndRaise( vpnservice.NeutronClientException()) self.m.ReplayAll() snippet = template_format.parse(ipsecpolicy_template) self.stack = utils.parse_stack(snippet) rsrc = vpnservice.IPsecPolicy( 'ipsecpolicy', snippet['Resources']['IPsecPolicy'], self.stack) error = self.assertRaises(exception.ResourceFailure, scheduler.TaskRunner(rsrc.create)) self.assertEqual( 'NeutronClientException: An unknown exception occurred.', str(error)) self.assertEqual((rsrc.CREATE, rsrc.FAILED), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_delete(self): neutronclient.Client.delete_ipsecpolicy('ips123') neutronclient.Client.show_ipsecpolicy('ips123').AndRaise( vpnservice.NeutronClientException(status_code=404)) rsrc = self.create_ipsecpolicy() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() scheduler.TaskRunner(rsrc.delete)() self.assertEqual((rsrc.DELETE, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_delete_already_gone(self): neutronclient.Client.delete_ipsecpolicy('ips123').AndRaise( vpnservice.NeutronClientException(status_code=404)) rsrc = self.create_ipsecpolicy() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() scheduler.TaskRunner(rsrc.delete)() self.assertEqual((rsrc.DELETE, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_delete_failed(self): neutronclient.Client.delete_ipsecpolicy('ips123').AndRaise( vpnservice.NeutronClientException(status_code=400)) rsrc = self.create_ipsecpolicy() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() error = self.assertRaises(exception.ResourceFailure, scheduler.TaskRunner(rsrc.delete)) self.assertEqual( 'NeutronClientException: An unknown exception occurred.', str(error)) self.assertEqual((rsrc.DELETE, rsrc.FAILED), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_attribute(self): rsrc = self.create_ipsecpolicy() neutronclient.Client.show_ipsecpolicy( 'ips123').MultipleTimes().AndReturn(self.IPSEC_POLICY_CONF) self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() self.assertEqual('IPsecPolicy', rsrc.FnGetAtt('name')) self.assertEqual('My new IPsec policy', rsrc.FnGetAtt('description')) self.assertEqual('esp', rsrc.FnGetAtt('transform_protocol')) self.assertEqual('tunnel', rsrc.FnGetAtt('encapsulation_mode')) self.assertEqual('sha1', rsrc.FnGetAtt('auth_algorithm')) self.assertEqual('3des', rsrc.FnGetAtt('encryption_algorithm')) self.assertEqual('seconds', rsrc.FnGetAtt('lifetime')['units']) self.assertEqual(3600, rsrc.FnGetAtt('lifetime')['value']) self.assertEqual('group5', rsrc.FnGetAtt('pfs')) self.m.VerifyAll() @utils.stack_delete_after def test_attribute_failed(self): rsrc = self.create_ipsecpolicy() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() error = self.assertRaises(exception.InvalidTemplateAttribute, rsrc.FnGetAtt, 'non-existent_property') self.assertEqual( 'The Referenced Attribute (ipsecpolicy non-existent_property) is ' 'incorrect.', str(error)) self.m.VerifyAll() @utils.stack_delete_after def test_update(self): rsrc = self.create_ipsecpolicy() neutronclient.Client.update_ipsecpolicy( 'ips123', {'ipsecpolicy': {'name': 'New IPsecPolicy'}}) self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() update_template = copy.deepcopy(rsrc.t) update_template['Properties']['name'] = 'New IPsecPolicy' scheduler.TaskRunner(rsrc.update, update_template)() self.m.VerifyAll()",,264,1
openstack%2Fheat~master~I54a83aededc779ddcf44ce72b0a1bb2b69a26094,openstack/heat,master,I54a83aededc779ddcf44ce72b0a1bb2b69a26094,Adding IKE policy to Heat resources,MERGED,2013-09-03 15:31:50.000000000,2013-09-05 06:39:29.000000000,2013-09-05 06:39:28.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6917}, {'_account_id': 7385}]","[{'number': 1, 'created': '2013-09-03 15:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3904137c47f77e49a88f3b0314d5691d3abf19b8', 'message': 'Adding IKE policy to Heat resources\n\nAdds Neutron IKE policy component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I54a83aededc779ddcf44ce72b0a1bb2b69a26094\nImplements: blueprint vpnaas-support\n'}, {'number': 2, 'created': '2013-09-04 09:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/51db415886c4d83f5b3efdc10aae04c785edc9ad', 'message': 'Adding IKE policy to Heat resources\n\nAdds Neutron IKE policy component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I54a83aededc779ddcf44ce72b0a1bb2b69a26094\nImplements: blueprint vpnaas-support\n'}, {'number': 3, 'created': '2013-09-04 09:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/13d2f817d48bacc168a67ea1ba325532aabbf182', 'message': 'Adding IKE policy to Heat resources\n\nAdds Neutron IKE policy component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I54a83aededc779ddcf44ce72b0a1bb2b69a26094\nImplements: blueprint vpnaas-support\n'}, {'number': 4, 'created': '2013-09-04 22:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/85ea7682ffa2c96936b03ecc990e99cc5d426b10', 'message': 'Adding IKE policy to Heat resources\n\nAdds Neutron IKE policy component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I54a83aededc779ddcf44ce72b0a1bb2b69a26094\nImplements: blueprint vpnaas-support\n'}, {'number': 5, 'created': '2013-09-04 22:59:56.000000000', 'files': ['heat/engine/resources/neutron/vpnservice.py', 'heat/tests/test_neutron_vpnservice.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/51d0d6407f07ad9a1f918ef1896f2cfede74a95b', 'message': 'Adding IKE policy to Heat resources\n\nAdds Neutron IKE policy component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I54a83aededc779ddcf44ce72b0a1bb2b69a26094\nImplements: blueprint vpnaas-support\n'}]",0,44902,51d0d6407f07ad9a1f918ef1896f2cfede74a95b,20,8,5,6917,,,0,"Adding IKE policy to Heat resources

Adds Neutron IKE policy component to resources
supported by Heat with unit tests.

Change-Id: I54a83aededc779ddcf44ce72b0a1bb2b69a26094
Implements: blueprint vpnaas-support
",git fetch https://review.opendev.org/openstack/heat refs/changes/02/44902/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/neutron/vpnservice.py', 'heat/tests/test_neutron_vpnservice.py']",2,3904137c47f77e49a88f3b0314d5691d3abf19b8,bp/vpnaas-support,"ikepolicy_template = ''' { ""AWSTemplateFormatVersion"" : ""2010-09-09"", ""Description"" : ""Template to test IKE policy resource"", ""Parameters"" : {}, ""Resources"" : { ""IKEPolicy"" : { ""Type"" : ""OS::Neutron::IKEPolicy"", ""Properties"" : { ""name"" : ""IKEPolicy"", ""description"" : ""My new IKE policy"", ""auth_algorithm"" : ""sha1"", ""encryption_algorithm"" : ""3des"", ""phase1_negotiation_mode"" : ""main"", ""lifetime"" : { ""units"" : ""seconds"", ""value"" : 3600 }, ""pfs"" : ""group5"", ""ike_version"" : ""v1"" } } } } ''' @skipIf(neutronclient is None, 'neutronclient unavailable') class IKEPolicyTest(HeatTestCase): IKE_POLICY_CONF = { 'ikepolicy': { 'name': 'IKEPolicy', 'description': 'My new IKE policy', 'auth_algorithm': 'sha1', 'encryption_algorithm': '3des', 'phase1_negotiation_mode': 'main', 'lifetime': { 'units': 'seconds', 'value': 3600 }, 'pfs': 'group5', 'ike_version': 'v1' } } def setUp(self): super(IKEPolicyTest, self).setUp() self.m.StubOutWithMock(neutronclient.Client, 'create_ikepolicy') self.m.StubOutWithMock(neutronclient.Client, 'delete_ikepolicy') self.m.StubOutWithMock(neutronclient.Client, 'show_ikepolicy') self.m.StubOutWithMock(neutronclient.Client, 'update_ikepolicy') self.m.StubOutWithMock(clients.OpenStackClients, 'keystone') utils.setup_dummy_db() def create_ikepolicy(self): clients.OpenStackClients.keystone().AndReturn( fakes.FakeKeystoneClient()) neutronclient.Client.create_ikepolicy( self.IKE_POLICY_CONF).AndReturn( {'ikepolicy': {'id': 'ike123'}}) snippet = template_format.parse(ikepolicy_template) self.stack = utils.parse_stack(snippet) return vpnservice.IKEPolicy('ikepolicy', snippet['Resources']['IKEPolicy'], self.stack) @utils.stack_delete_after def test_create(self): rsrc = self.create_ikepolicy() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_create_failed(self): clients.OpenStackClients.keystone().AndReturn( fakes.FakeKeystoneClient()) neutronclient.Client.create_ikepolicy( self.IKE_POLICY_CONF).AndRaise( vpnservice.NeutronClientException()) self.m.ReplayAll() snippet = template_format.parse(ikepolicy_template) self.stack = utils.parse_stack(snippet) rsrc = vpnservice.IKEPolicy( 'ikepolicy', snippet['Resources']['IKEPolicy'], self.stack) error = self.assertRaises(exception.ResourceFailure, scheduler.TaskRunner(rsrc.create)) self.assertEqual( 'NeutronClientException: An unknown exception occurred.', str(error)) self.assertEqual((rsrc.CREATE, rsrc.FAILED), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_delete(self): neutronclient.Client.delete_ikepolicy('ike123') neutronclient.Client.show_ikepolicy('ike123').AndRaise( vpnservice.NeutronClientException(status_code=404)) rsrc = self.create_ikepolicy() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() scheduler.TaskRunner(rsrc.delete)() self.assertEqual((rsrc.DELETE, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_delete_already_gone(self): neutronclient.Client.delete_ikepolicy('ike123').AndRaise( vpnservice.NeutronClientException(status_code=404)) rsrc = self.create_ikepolicy() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() scheduler.TaskRunner(rsrc.delete)() self.assertEqual((rsrc.DELETE, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_delete_failed(self): neutronclient.Client.delete_ikepolicy('ike123').AndRaise( vpnservice.NeutronClientException(status_code=400)) rsrc = self.create_ikepolicy() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() error = self.assertRaises(exception.ResourceFailure, scheduler.TaskRunner(rsrc.delete)) self.assertEqual( 'NeutronClientException: An unknown exception occurred.', str(error)) self.assertEqual((rsrc.DELETE, rsrc.FAILED), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_attribute(self): rsrc = self.create_ikepolicy() neutronclient.Client.show_ikepolicy( 'ike123').MultipleTimes().AndReturn(self.IKE_POLICY_CONF) self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() self.assertEqual('IKEPolicy', rsrc.FnGetAtt('name')) self.assertEqual('My new IKE policy', rsrc.FnGetAtt('description')) self.assertEqual('sha1', rsrc.FnGetAtt('auth_algorithm')) self.assertEqual('3des', rsrc.FnGetAtt('encryption_algorithm')) self.assertEqual('main', rsrc.FnGetAtt('phase1_negotiation_mode')) self.assertEqual('seconds', rsrc.FnGetAtt('lifetime')['units']) self.assertEqual(3600, rsrc.FnGetAtt('lifetime')['value']) self.assertEqual('group5', rsrc.FnGetAtt('pfs')) self.assertEqual('v1', rsrc.FnGetAtt('ike_version')) self.m.VerifyAll() @utils.stack_delete_after def test_attribute_failed(self): rsrc = self.create_ikepolicy() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() error = self.assertRaises(exception.InvalidTemplateAttribute, rsrc.FnGetAtt, 'non-existent_property') self.assertEqual( 'The Referenced Attribute (ikepolicy non-existent_property) is ' 'incorrect.', str(error)) self.m.VerifyAll() @utils.stack_delete_after def test_update(self): rsrc = self.create_ikepolicy() neutronclient.Client.update_ikepolicy('ike123', {'ikepolicy': { 'name': 'New IKEPolicy'}}) self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() update_template = copy.deepcopy(rsrc.t) update_template['Properties']['name'] = 'New IKEPolicy' scheduler.TaskRunner(rsrc.update, update_template)() self.m.VerifyAll()",,261,0
openstack%2Fheat~master~I3a626166253bcb33d8875cf406b293688f53ffa3,openstack/heat,master,I3a626166253bcb33d8875cf406b293688f53ffa3,Adding VPN Service to Heat resources,MERGED,2013-09-03 14:52:23.000000000,2013-09-05 06:39:27.000000000,2013-09-05 06:39:26.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6917}, {'_account_id': 7385}]","[{'number': 1, 'created': '2013-09-03 14:52:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4b9aed74d644bc4cb0aca61d35086bdc08b8bc94', 'message': 'Adding VPN Service to Heat resources\n\nAdds Neutron VPN service component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I3a626166253bcb33d8875cf406b293688f53ffa3\nImplements: blueprint vpnaas-support\n'}, {'number': 2, 'created': '2013-09-04 09:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eb240ea0adf6a5bb23a53b591fccb014ad424b35', 'message': 'Adding VPN Service to Heat resources\n\nAdds Neutron VPN service component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I3a626166253bcb33d8875cf406b293688f53ffa3\nImplements: blueprint vpnaas-support\n'}, {'number': 3, 'created': '2013-09-04 15:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3e3312ccccac3a661fa96989095a6e7e10ef2cfd', 'message': 'Adding VPN Service to Heat resources\n\nAdds Neutron VPN service component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I3a626166253bcb33d8875cf406b293688f53ffa3\nImplements: blueprint vpnaas-support\n'}, {'number': 4, 'created': '2013-09-04 22:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9cab62a80ed416b09e55429e1993eb7a23852a86', 'message': 'Adding VPN Service to Heat resources\n\nAdds Neutron VPN service component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I3a626166253bcb33d8875cf406b293688f53ffa3\nImplements: blueprint vpnaas-support\n'}, {'number': 5, 'created': '2013-09-04 22:59:57.000000000', 'files': ['heat/engine/resources/neutron/vpnservice.py', 'heat/tests/test_neutron_vpnservice.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/109d01c50fec51cb77ed78c9a9dac0f43ff30fdb', 'message': 'Adding VPN Service to Heat resources\n\nAdds Neutron VPN service component to resources\nsupported by Heat with unit tests.\n\nChange-Id: I3a626166253bcb33d8875cf406b293688f53ffa3\nImplements: blueprint vpnaas-support\n'}]",2,44892,109d01c50fec51cb77ed78c9a9dac0f43ff30fdb,21,8,5,6917,,,0,"Adding VPN Service to Heat resources

Adds Neutron VPN service component to resources
supported by Heat with unit tests.

Change-Id: I3a626166253bcb33d8875cf406b293688f53ffa3
Implements: blueprint vpnaas-support
",git fetch https://review.opendev.org/openstack/heat refs/changes/92/44892/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/neutron/vpnservice.py', 'heat/tests/test_neutron_vpnservice.py']",2,4b9aed74d644bc4cb0aca61d35086bdc08b8bc94,bp/vpnaas-support,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy from testtools import skipIf from heat.common import exception from heat.common import template_format from heat.engine import clients from heat.engine import scheduler from heat.engine.resources.neutron import vpnservice from heat.openstack.common.importutils import try_import from heat.tests import fakes from heat.tests import utils from heat.tests.common import HeatTestCase neutronclient = try_import('neutronclient.v2_0.client') vpnservice_template = ''' { ""AWSTemplateFormatVersion"" : ""2010-09-09"", ""Description"" : ""Template to test VPN service resource"", ""Parameters"" : {}, ""Resources"" : { ""VPNService"" : { ""Type"" : ""OS::Neutron::VPNService"", ""Properties"" : { ""name"" : ""VPNService"", ""description"" : ""My new VPN service"", ""admin_state_up"" : true, ""router_id"" : ""rou123"", ""subnet_id"" : ""sub123"" } } } } ''' @skipIf(neutronclient is None, 'neutronclient unavailable') class VPNServiceTest(HeatTestCase): VPN_SERVICE_CONF = { 'vpnservice': { 'name': 'VPNService', 'description': 'My new VPN service', 'admin_state_up': True, 'router_id': 'rou123', 'subnet_id': 'sub123' } } def setUp(self): super(VPNServiceTest, self).setUp() self.m.StubOutWithMock(neutronclient.Client, 'create_vpnservice') self.m.StubOutWithMock(neutronclient.Client, 'delete_vpnservice') self.m.StubOutWithMock(neutronclient.Client, 'show_vpnservice') self.m.StubOutWithMock(neutronclient.Client, 'update_vpnservice') self.m.StubOutWithMock(clients.OpenStackClients, 'keystone') utils.setup_dummy_db() def create_vpnservice(self): clients.OpenStackClients.keystone().AndReturn( fakes.FakeKeystoneClient()) neutronclient.Client.create_vpnservice( self.VPN_SERVICE_CONF).AndReturn({'vpnservice': {'id': 'vpn123'}}) snippet = template_format.parse(vpnservice_template) self.stack = utils.parse_stack(snippet) return vpnservice.VPNService('vpnservice', snippet['Resources']['VPNService'], self.stack) @utils.stack_delete_after def test_create(self): rsrc = self.create_vpnservice() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_create_failed(self): clients.OpenStackClients.keystone().AndReturn( fakes.FakeKeystoneClient()) neutronclient.Client.create_vpnservice(self.VPN_SERVICE_CONF).AndRaise( vpnservice.NeutronClientException()) self.m.ReplayAll() snippet = template_format.parse(vpnservice_template) self.stack = utils.parse_stack(snippet) rsrc = vpnservice.VPNService('vpnservice', snippet['Resources']['VPNService'], self.stack) error = self.assertRaises(exception.ResourceFailure, scheduler.TaskRunner(rsrc.create)) self.assertEqual( 'NeutronClientException: An unknown exception occurred.', str(error)) self.assertEqual((rsrc.CREATE, rsrc.FAILED), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_delete(self): neutronclient.Client.delete_vpnservice('vpn123') neutronclient.Client.show_vpnservice('vpn123').AndRaise( vpnservice.NeutronClientException(status_code=404)) rsrc = self.create_vpnservice() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() scheduler.TaskRunner(rsrc.delete)() self.assertEqual((rsrc.DELETE, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_delete_already_gone(self): neutronclient.Client.delete_vpnservice('vpn123').AndRaise( vpnservice.NeutronClientException(status_code=404)) rsrc = self.create_vpnservice() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() scheduler.TaskRunner(rsrc.delete)() self.assertEqual((rsrc.DELETE, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_delete_failed(self): neutronclient.Client.delete_vpnservice('vpn123').AndRaise( vpnservice.NeutronClientException(status_code=400)) rsrc = self.create_vpnservice() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() error = self.assertRaises(exception.ResourceFailure, scheduler.TaskRunner(rsrc.delete)) self.assertEqual( 'NeutronClientException: An unknown exception occurred.', str(error)) self.assertEqual((rsrc.DELETE, rsrc.FAILED), rsrc.state) self.m.VerifyAll() @utils.stack_delete_after def test_attribute(self): rsrc = self.create_vpnservice() neutronclient.Client.show_vpnservice('vpn123').MultipleTimes( ).AndReturn(self.VPN_SERVICE_CONF) self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() self.assertEqual('VPNService', rsrc.FnGetAtt('name')) self.assertEqual('My new VPN service', rsrc.FnGetAtt('description')) self.assertEqual(True, rsrc.FnGetAtt('admin_state_up')) self.assertEqual('rou123', rsrc.FnGetAtt('router_id')) self.assertEqual('sub123', rsrc.FnGetAtt('subnet_id')) self.m.VerifyAll() @utils.stack_delete_after def test_attribute_failed(self): rsrc = self.create_vpnservice() self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() error = self.assertRaises(exception.InvalidTemplateAttribute, rsrc.FnGetAtt, 'non-existent_property') self.assertEqual( 'The Referenced Attribute (vpnservice non-existent_property) is ' 'incorrect.', str(error)) self.m.VerifyAll() @utils.stack_delete_after def test_update(self): rsrc = self.create_vpnservice() neutronclient.Client.update_vpnservice( 'vpn123', {'vpnservice': {'admin_state_up': False}}) self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() update_template = copy.deepcopy(rsrc.t) update_template['Properties']['admin_state_up'] = False scheduler.TaskRunner(rsrc.update, update_template)() self.m.VerifyAll() ",,281,0
openstack%2Fheat~master~I01a6899c43ae6ff63794267d2dd4ab32f06fa643,openstack/heat,master,I01a6899c43ae6ff63794267d2dd4ab32f06fa643,update neutronclient to 2.3.0 minimum version,MERGED,2013-09-03 21:44:49.000000000,2013-09-05 06:39:25.000000000,2013-09-05 06:39:24.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6917}]","[{'number': 1, 'created': '2013-09-03 21:44:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/482dcda5000ce6c7c9319caf731eb41455d0ce13', 'message': 'update neutronclient to 2.3.0 minimum version\n\nChange-Id: I01a6899c43ae6ff63794267d2dd4ab32f06fa643\n'}, {'number': 2, 'created': '2013-09-04 22:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7c646210448c70c5f2592edc9b6d70f1228c63cd', 'message': 'update neutronclient to 2.3.0 minimum version\n\nChange-Id: I01a6899c43ae6ff63794267d2dd4ab32f06fa643\n'}, {'number': 3, 'created': '2013-09-04 22:59:56.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/524a1e32a53f6b66f298dc3055edf019300b507c', 'message': 'update neutronclient to 2.3.0 minimum version\n\nChange-Id: I01a6899c43ae6ff63794267d2dd4ab32f06fa643\n'}]",0,44957,524a1e32a53f6b66f298dc3055edf019300b507c,22,6,3,2592,,,0,"update neutronclient to 2.3.0 minimum version

Change-Id: I01a6899c43ae6ff63794267d2dd4ab32f06fa643
",git fetch https://review.opendev.org/openstack/heat refs/changes/57/44957/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,482dcda5000ce6c7c9319caf731eb41455d0ce13,bp/vpnaas-support,"python-neutronclient>=2.3.0,<3","python-neutronclient>=2.2.3,<3",1,1
openstack%2Fhorizon~master~If6e797ac28c8486cfa92e02742c409d193d9ec84,openstack/horizon,master,If6e797ac28c8486cfa92e02742c409d193d9ec84,Add Cisco N1K plugin support in Horizon,MERGED,2013-08-01 15:51:50.000000000,2013-09-05 06:39:13.000000000,2013-09-05 06:39:13.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1816}, {'_account_id': 4264}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 6620}, {'_account_id': 6659}, {'_account_id': 7018}]","[{'number': 1, 'created': '2013-08-01 15:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/20ee17b7d48f5b155426f4812ede892812b9e4aa', 'message': 'blueprint Horizon-Cisco-N1K\n\nAdd Cisco N1K plugin support in Horizon (Work in Progress)\nNeutron plugin under review\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 2, 'created': '2013-08-19 18:39:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/453ee12011d8d1a374f3502fafc411496490d5dc', 'message': 'Implements: blueprint horizon-cisco-n1k\n\nAdd Cisco N1K plugin support in Horizon\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 3, 'created': '2013-08-19 20:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/caf6f72c0241e4477dd36c53fb01002ece28c65f', 'message': 'Add Cisco N1K plugin support in Horizon\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 4, 'created': '2013-08-20 17:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a4ff79a1741cd0aa31a26b2d5b5ae8d96a534c5e', 'message': 'Add Cisco N1K plugin support in Horizon\n\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 5, 'created': '2013-08-27 17:28:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ca3771f3471203f8e2ed1c750a79c0e4adc59888', 'message': 'Add Cisco N1K plugin support in Horizon\n\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 6, 'created': '2013-08-27 21:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bb982abcadab228d83c62e0c58b40f20a4b9ddb9', 'message': 'Add Cisco N1K plugin support in Horizon\n\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 7, 'created': '2013-08-28 01:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e488a1a1f1170ab941ff353e1c5b05ab04b1d8a1', 'message': 'Add Cisco N1K plugin support in Horizon\n\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 8, 'created': '2013-08-30 18:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3bb85edd28f75b3e2afcca8c3b8fff8380f581fe', 'message': 'Add Cisco N1K plugin support in Horizon\n\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 9, 'created': '2013-08-31 10:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/37eaf9912d7c9c6c1b809f5e792b60357afd4c50', 'message': 'Add Cisco N1K plugin support in Horizon\n\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 10, 'created': '2013-09-03 19:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6d184aea4208906b1f7765cd2077af30dcd31498', 'message': 'Add Cisco N1K plugin support in Horizon\n\nThis adds Horizon capability to configure and\nuse network profiles and policy profiles\non the Cisco Nexus 1000V to be used with\nnetworks and instances as is done via neutron\nCLI.\n\nTo turn on the new dashboard the local_settings\nfile needs to turn the profile_settings NEUTRON\nconfig variable to cisco.\n\nTODO items include creating a better palate\nof unit tests that will run not only when\nthe cisco n1k subplugin is being used but\nin default setting as well.\n\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 11, 'created': '2013-09-03 21:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/abd6d9c0b2136cb71408813ca5ab4ad71632c0d9', 'message': 'Add Cisco N1K plugin support in Horizon\n\nThis adds Horizon capability to configure and\nuse network profiles and policy profiles\non the Cisco Nexus 1000V to be used with\nnetworks and instances as is done via neutron\nCLI.\n\nTo turn on the new dashboard the local_settings\nfile needs to turn the profile_settings NEUTRON\nconfig variable to cisco.\n\nTODO items include creating a better palate\nof unit tests that will run not only when\nthe cisco n1k subplugin is being used but\nin default setting as well.\n\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 12, 'created': '2013-09-04 13:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/904dd0f2468d07a23a6ea71c8fb94ce9be978c9e', 'message': 'Add Cisco N1K plugin support in Horizon\n\nThis adds Horizon capability to configure and\nuse network profiles and policy profiles\non the Cisco Nexus 1000V to be used with\nnetworks and instances as is done via neutron\nCLI.\n\nTo turn on the new dashboard the local_settings\nfile needs to turn the profile_settings NEUTRON\nconfig variable to cisco.\n\nTODO items include creating a better palate\nof unit tests that will run not only when\nthe cisco n1k subplugin is being used but\nin default setting as well.\nNeed to remove the conditional statements\nin the unit tests and make it inclusive.\nAdditionally need to get a better solution\nfor how the dashboard/panel registration will\nwork. Should it be a boolean or check for vendor\nspecific names.\n\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 13, 'created': '2013-09-04 18:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/10429b0fd419b1b908cdf6f0382ef23e3477a407', 'message': 'Add Cisco N1K plugin support in Horizon\n\nThis adds Horizon capability to configure and\nuse network profiles and policy profiles\non the Cisco Nexus 1000V to be used with\nnetworks and instances as is done via neutron\nCLI.\n\nTo turn on the new dashboard the local_settings\nfile needs to turn the profile_settings NEUTRON\nconfig variable to cisco.\n\nTODO items include creating a better palate\nof unit tests that will run not only when\nthe cisco n1k subplugin is being used but\nin default setting as well.\nNeed to remove the conditional statements\nin the unit tests and make it inclusive.\nAdditionally need to get a better solution\nfor how the dashboard/panel registration will\nwork. Should it be a boolean or check for vendor\nspecific names.\nAlso some cleanup and refactoring of commonly\nused code everywhere.\n\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}, {'number': 14, 'created': '2013-09-04 19:27:59.000000000', 'files': ['openstack_dashboard/dashboards/router/dashboard.py', 'openstack_dashboard/dashboards/router/nexus1000v/views.py', 'openstack_dashboard/dashboards/router/nexus1000v/templates/nexus1000v/create_network_profile.html', 'openstack_dashboard/dashboards/router/__init__.py', 'openstack_dashboard/dashboards/router/nexus1000v/templates/nexus1000v/update_network_profile.html', 'openstack_dashboard/dashboards/project/networks/tests.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/router/nexus1000v/urls.py', 'openstack_dashboard/dashboards/admin/networks/tests.py', 'openstack_dashboard/dashboards/router/nexus1000v/templates/nexus1000v/network_profile/index.html', 'openstack_dashboard/dashboards/router/nexus1000v/tests.py', 'openstack_dashboard/dashboards/project/instances/workflows/create_instance.py', 'openstack_dashboard/dashboards/router/nexus1000v/panel.py', 'openstack_dashboard/dashboards/router/models.py', 'openstack_dashboard/dashboards/router/nexus1000v/templates/nexus1000v/index.html', 'openstack_dashboard/dashboards/router/nexus1000v/tables.py', 'openstack_dashboard/dashboards/admin/networks/forms.py', 'openstack_dashboard/dashboards/router/nexus1000v/templates/nexus1000v/_update_network_profile.html', 'openstack_dashboard/dashboards/router/nexus1000v/__init__.py', 'openstack_dashboard/dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html', 'openstack_dashboard/api/neutron.py', 'openstack_dashboard/dashboards/router/nexus1000v/forms.py', 'openstack_dashboard/dashboards/router/nexus1000v/templates/nexus1000v/policy_profile/index.html', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/settings.py', 'openstack_dashboard/dashboards/project/networks/workflows.py', 'openstack_dashboard/test/settings.py', 'openstack_dashboard/test/test_data/neutron_data.py', 'openstack_dashboard/dashboards/router/nexus1000v/tabs.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/38ba3df8b889716f2429922c1d8cda2239521cff', 'message': 'Add Cisco N1K plugin support in Horizon\n\nThis adds Horizon capability to configure and\nuse network profiles and policy profiles\non the Cisco Nexus 1000V to be used with\nnetworks and instances as is done via neutron\nCLI.\n\nTo turn on the new dashboard the local_settings\nfile needs to turn the profile_settings NEUTRON\nconfig variable to cisco.\n\nTODO items include creating a better palate\nof unit tests that will run not only when\nthe cisco n1k subplugin is being used but\nin default setting as well.\nNeed to remove the conditional statements\nin the unit tests and make it inclusive.\nAdditionally need to get a better solution\nfor how the dashboard/panel registration will\nwork. Should it be a boolean or check for vendor\nspecific names.\nAlso some cleanup and refactoring of commonly\nused code everywhere.\n\nImplements: blueprint horizon-cisco-n1k\n\nChange-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84\n'}]",242,39739,38ba3df8b889716f2429922c1d8cda2239521cff,69,9,14,6620,,,0,"Add Cisco N1K plugin support in Horizon

This adds Horizon capability to configure and
use network profiles and policy profiles
on the Cisco Nexus 1000V to be used with
networks and instances as is done via neutron
CLI.

To turn on the new dashboard the local_settings
file needs to turn the profile_settings NEUTRON
config variable to cisco.

TODO items include creating a better palate
of unit tests that will run not only when
the cisco n1k subplugin is being used but
in default setting as well.
Need to remove the conditional statements
in the unit tests and make it inclusive.
Additionally need to get a better solution
for how the dashboard/panel registration will
work. Should it be a boolean or check for vendor
specific names.
Also some cleanup and refactoring of commonly
used code everywhere.

Implements: blueprint horizon-cisco-n1k

Change-Id: If6e797ac28c8486cfa92e02742c409d193d9ec84
",git fetch https://review.opendev.org/openstack/horizon refs/changes/39/39739/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/cisco/nexus1000v/tabs.py', 'openstack_dashboard/dashboards/cisco/nexus1000v/urls.py', 'openstack_dashboard/dashboards/cisco/nexus1000v/templates/nexus1000v/_update_network_profile.html', 'openstack_dashboard/dashboards/cisco/nexus1000v/templates/nexus1000v/update.html', 'openstack_dashboard/dashboards/cisco/nexus1000v/templates/nexus1000v/_create_network_profile.html', 'openstack_dashboard/dashboards/cisco/nexus1000v/templates/nexus1000v/index.html', 'openstack_dashboard/dashboards/cisco/nexus1000v/views.py', 'openstack_dashboard/dashboards/cisco/__init__.py', 'openstack_dashboard/dashboards/cisco/nexus1000v/tables.py', 'openstack_dashboard/dashboards/cisco/nexus1000v/templates/nexus1000v/create_network_profile.html', 'openstack_dashboard/dashboards/cisco/nexus1000v/templates/nexus1000v/update_network_profile.html', 'openstack_dashboard/dashboards/cisco/dashboard.py', 'openstack_dashboard/dashboards/cisco/models.py', 'openstack_dashboard/dashboards/cisco/nexus1000v/templates/nexus1000v/network_profile/index.html', 'openstack_dashboard/dashboards/cisco/nexus1000v/forms.py', 'openstack_dashboard/dashboards/cisco/nexus1000v/panel.py', 'openstack_dashboard/dashboards/cisco/nexus1000v/templates/nexus1000v/policy_profile/index.html', 'openstack_dashboard/dashboards/cisco/nexus1000v/__init__.py']",18,20ee17b7d48f5b155426f4812ede892812b9e4aa,bp/horizon-cisco-n1k,,,679,0
openstack%2Fheat~master~I834138a833042449293f7b96a6c5bcfba8424d73,openstack/heat,master,I834138a833042449293f7b96a6c5bcfba8424d73,Remove some heat-cfnclients only exceptions,MERGED,2013-09-03 06:48:16.000000000,2013-09-05 06:37:03.000000000,2013-09-05 06:37:02.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-09-03 06:48:16.000000000', 'files': ['heat/common/exception.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6c5c47fa0e7daa9d61e87b4e3335b0f07aab3a9d', 'message': 'Remove some heat-cfnclients only exceptions\n\nRemove some exceptions that were written specifically for\nheat-cfnclients and are unlikely to be referenced anywhere\nelse in the future.\n\nChange-Id: I834138a833042449293f7b96a6c5bcfba8424d73\n'}]",0,44802,6c5c47fa0e7daa9d61e87b4e3335b0f07aab3a9d,6,3,1,7135,,,0,"Remove some heat-cfnclients only exceptions

Remove some exceptions that were written specifically for
heat-cfnclients and are unlikely to be referenced anywhere
else in the future.

Change-Id: I834138a833042449293f7b96a6c5bcfba8424d73
",git fetch https://review.opendev.org/openstack/heat refs/changes/02/44802/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/common/exception.py'],1,6c5c47fa0e7daa9d61e87b4e3335b0f07aab3a9d,bug/1215501,,"class MultipleChoices(HeatException): message = _(""The request returned a 302 Multiple Choices. This generally "" ""means that you have not included a version indicator in a "" ""request URI.\n\nThe body of response returned:\n%(body)s"") class LimitExceeded(HeatException): message = _(""The request returned a 413 Request Entity Too Large. This "" ""generally means that rate limiting or a quota threshold was "" ""breached.\n\nThe response body:\n%(body)s"") def __init__(self, *args, **kwargs): self.retry_after = (int(kwargs['retry']) if kwargs.get('retry') else None) super(LimitExceeded, self).__init__(*args, **kwargs) class ServiceUnavailable(HeatException): message = _(""The request returned a 503 ServiceUnavilable. This "" ""generally occurs on service overload or other transient "" ""outage."") def __init__(self, *args, **kwargs): self.retry_after = (int(kwargs['retry']) if kwargs.get('retry') else None) super(ServiceUnavailable, self).__init__(*args, **kwargs) ",0,28
openstack%2Fnova~master~I3eb2b7faca9777494d7edffe89b4e2a803d01c49,openstack/nova,master,I3eb2b7faca9777494d7edffe89b4e2a803d01c49,Remove _expire_reservations from periodic tasks,ABANDONED,2013-08-28 02:32:56.000000000,2013-09-05 06:23:36.000000000,,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 4458}, {'_account_id': 4491}, {'_account_id': 7069}, {'_account_id': 7138}, {'_account_id': 7641}]","[{'number': 1, 'created': '2013-08-28 02:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f31025145fe0e573adbcd30d519788d0448ebac0', 'message': ""Move _expire_reservations from periodic tasks\n\nif the scheduler hasn't done anything for the past few minutes there is no\nreason to keep running this task. Instead it can be restarted upon the\nnext scheduling event.\n\nFix bug 1212028\n\nChange-Id: I3eb2b7faca9777494d7edffe89b4e2a803d01c49\n""}, {'number': 2, 'created': '2013-09-03 09:07:20.000000000', 'files': ['nova/scheduler/manager.py', 'etc/nova/nova.conf.sample', 'nova/tests/scheduler/test_scheduler.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9105b6748d1404670801ee3f6ae398d04a625c5f', 'message': ""Remove _expire_reservations from periodic tasks\n\nif the scheduler hasn't done anything for the past few minutes there is no\nreason to keep running this task. Instead it can be restarted upon the\nnext scheduling event.\n\nFix bug 1212028\n\nChange-Id: I3eb2b7faca9777494d7edffe89b4e2a803d01c49\n""}]",4,43981,9105b6748d1404670801ee3f6ae398d04a625c5f,17,10,2,7641,,,0,"Remove _expire_reservations from periodic tasks

if the scheduler hasn't done anything for the past few minutes there is no
reason to keep running this task. Instead it can be restarted upon the
next scheduling event.

Fix bug 1212028

Change-Id: I3eb2b7faca9777494d7edffe89b4e2a803d01c49
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/43981/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/manager.py', 'nova/tests/scheduler/test_scheduler.py']",2,f31025145fe0e573adbcd30d519788d0448ebac0,bug/1212028," self.mox.StubOutWithMock(self.manager, '_expire_reservations') self.manager._expire_reservations(mox.IgnoreArg())",,4,2
openstack%2Fnova~master~I67f1118ad619759b37a47ce818289969e236aedf,openstack/nova,master,I67f1118ad619759b37a47ce818289969e236aedf,Use yield in nova.cmd.manage.methods_of(),ABANDONED,2013-08-17 20:04:39.000000000,2013-09-05 06:03:10.000000000,,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7069}, {'_account_id': 7491}]","[{'number': 1, 'created': '2013-08-17 20:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7ef5c1ad2b490ec903d9526f1fb858f10902d1a', 'message': 'Use in nova.cmd.manage.methods_of() yield\n\nWe are able to avoid extra array creation and make from this method generator.\nThis change clean up code and improve a little bit performance.\n\nChange-Id: I67f1118ad619759b37a47ce818289969e236aedf\n'}, {'number': 2, 'created': '2013-08-18 09:02:53.000000000', 'files': ['nova/cmd/manage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/709ac081166006764498eb5e0f3a82ecf74c9fa4', 'message': 'Use yield in nova.cmd.manage.methods_of()\n\nWe are able to avoid an extra list creation in this method.\nThis change cleans up code and improves performance a little bit.\n\nChange-Id: I67f1118ad619759b37a47ce818289969e236aedf\n'}]",1,42485,709ac081166006764498eb5e0f3a82ecf74c9fa4,13,4,2,6172,,,0,"Use yield in nova.cmd.manage.methods_of()

We are able to avoid an extra list creation in this method.
This change cleans up code and improves performance a little bit.

Change-Id: I67f1118ad619759b37a47ce818289969e236aedf
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/42485/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/cmd/manage.py'],1,d7ef5c1ad2b490ec903d9526f1fb858f10902d1a,imporve_nova_manage," yield (i, getattr(obj, i))"," result = [] result.append((i, getattr(obj, i))) return result",1,3
openstack%2Fsahara~stable%2F0.2~I8a0e75df65cfe23e47aa5551fdf74d26403bb106,openstack/sahara,stable/0.2,I8a0e75df65cfe23e47aa5551fdf74d26403bb106,Allow Ambari port to be specified in configuration,ABANDONED,2013-08-28 01:21:05.000000000,2013-09-05 06:03:09.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7213}, {'_account_id': 7710}]","[{'number': 1, 'created': '2013-08-28 01:21:05.000000000', 'files': ['savanna/plugins/hdp/resources/ambari-config-resource.json', 'savanna/tests/unit/plugins/hdp/ambariplugin_test.py', 'savanna/plugins/hdp/ambariplugin.py', 'savanna/plugins/hdp/resources/default-cluster.template', 'savanna/plugins/hdp/hadoopserver.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/bf32096a07d0edea5515438ee6cb6f75a7e51605', 'message': 'Allow Ambari port to be specified in configuration\n\nAmbari port can now be specified in standard and advanced configuration\n\nFixes: bug #1212333\n\nChange-Id: I8a0e75df65cfe23e47aa5551fdf74d26403bb106\n'}]",0,43980,bf32096a07d0edea5515438ee6cb6f75a7e51605,7,5,1,8304,,,0,"Allow Ambari port to be specified in configuration

Ambari port can now be specified in standard and advanced configuration

Fixes: bug #1212333

Change-Id: I8a0e75df65cfe23e47aa5551fdf74d26403bb106
",git fetch https://review.opendev.org/openstack/sahara refs/changes/80/43980/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/plugins/hdp/resources/ambari-config-resource.json', 'savanna/plugins/hdp/ambariplugin.py', 'savanna/tests/unit/plugins/hdp/ambariplugin_test.py', 'savanna/plugins/hdp/resources/default-cluster.template', 'savanna/plugins/hdp/hadoopserver.py']",5,bf32096a07d0edea5515438ee6cb6f75a7e51605,bug/1212333," def provision_ambari(self, ambari_info): self._setup_and_start_ambari_server(ambari_info.port) self._setup_and_start_ambari_agent(ambari_info.host.internal_ip) def _setup_and_start_ambari_server(self, port): self._execute_on_vm_interactive( 'ambari-server setup', DefaultPromptMatcher( ""Ambari Server 'setup' finished successfully"", LOG)) self._configure_ambari_server_api_port(port) def _configure_ambari_server_api_port(self, port): # do nothing if port is not specified or is default if port is None or port == 8080: return ambari_config_file = '/etc/ambari-server/conf/ambari.properties' LOG.debug('Configuring Ambari Server API port: {0}'.format(port)) # read the current contents data = self._remote.read_file_from(ambari_config_file) data = '{0}\nclient.api.port={1}\n'.format(data, port) # write the file back self._remote.write_file_to(ambari_config_file, data) "," def provision_ambari(self, ambari_server_ip): self._setup_and_start_ambari_server() self._setup_and_start_ambari_agent(ambari_server_ip) def _setup_and_start_ambari_server(self): self._execute_on_vm_interactive('ambari-server setup', DefaultPromptMatcher( ""Ambari Server 'setup' finished "" ""successfully"", LOG))",240,176
openstack%2Fnova~stable%2Fgrizzly~I56b6b027e1370fc2cfdb4d87c10b80574a81b225,openstack/nova,stable/grizzly,I56b6b027e1370fc2cfdb4d87c10b80574a81b225,Fixes host stats for VMWareVCDriver,ABANDONED,2013-08-24 12:30:44.000000000,2013-09-05 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5638}, {'_account_id': 7629}, {'_account_id': 8151}]","[{'number': 1, 'created': '2013-08-24 12:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f250d2f372caf68c20b7acedfa73319988986619', 'message': 'Fixes host stats for VMWareVCDriver\n\nHost stats for VCDriver should collect aggregate cluster stats\nrather than that of a single host in the cluster.\n\nFixes: bug #1190515\n\n(cherry picked from commit fddcde6a063d59596f687f0651af94f498f7d9b7)\n\nChange-Id: I56b6b027e1370fc2cfdb4d87c10b80574a81b225\n'}, {'number': 2, 'created': '2013-08-24 12:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e812fc7946bc490206863da333a4a1ffa1fee885', 'message': 'Fixes host stats for VMWareVCDriver\n\nHost stats for VCDriver should collect aggregate cluster stats\nrather than that of a single host in the cluster.\n\nFixes: bug #1190515\n\n(cherry picked from commit fddcde6a063d59596f687f0651af94f498f7d9b7)\n\nChange-Id: I56b6b027e1370fc2cfdb4d87c10b80574a81b225\n'}, {'number': 3, 'created': '2013-08-26 06:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a481570bfbcd67b26ad9d00f5370264aa34e2b7', 'message': 'Fixes host stats for VMWareVCDriver\n\nHost stats for VCDriver should collect aggregate cluster stats\nrather than that of a single host in the cluster.\n\nFixes: bug #1190515\n\n(cherry picked from commit fddcde6a063d59596f687f0651af94f498f7d9b7)\n\nChange-Id: I56b6b027e1370fc2cfdb4d87c10b80574a81b225\n'}, {'number': 4, 'created': '2013-08-26 07:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6be11ebe75120821408df3f3bbebf2117a10804f', 'message': 'Fixes host stats for VMWareVCDriver\n\nHost stats for VCDriver should collect aggregate cluster stats\nrather than that of a single host in the cluster.\n\nFixes: bug #1190515\n\n(cherry picked from commit fddcde6a063d59596f687f0651af94f498f7d9b7)\n\nChange-Id: I56b6b027e1370fc2cfdb4d87c10b80574a81b225\n'}, {'number': 5, 'created': '2013-08-26 07:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9ae3592b3f29110d51bf0cc3e765c9746bdff95', 'message': 'Fixes host stats for VMWareVCDriver\n\nHost stats for VCDriver should collect aggregate cluster stats\nrather than that of a single host in the cluster.\n\nFixes: bug #1190515\n\n(cherry picked from commit fddcde6a063d59596f687f0651af94f498f7d9b7)\n\nChange-Id: I56b6b027e1370fc2cfdb4d87c10b80574a81b225\n'}, {'number': 6, 'created': '2013-08-26 13:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae590e63237b82c373d8bb80f41a054dc3ccc718', 'message': 'Fixes host stats for VMWareVCDriver\n\nHost stats for VCDriver should collect aggregate cluster stats\nrather than that of a single host in the cluster.\n\nFixes: bug #1190515\n\n(cherry picked from commit fddcde6a063d59596f687f0651af94f498f7d9b7)\n\nChange-Id: I56b6b027e1370fc2cfdb4d87c10b80574a81b225\n'}, {'number': 7, 'created': '2013-08-26 13:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e1df90b137617904445ffc6fdf218d6d208a3ba', 'message': 'Fixes host stats for VMWareVCDriver\n\nHost stats for VCDriver should collect aggregate cluster stats\nrather than that of a single host in the cluster.\n\nFixes: bug #1190515\n\n(cherry picked from commit fddcde6a063d59596f687f0651af94f498f7d9b7)\n\nChange-Id: I56b6b027e1370fc2cfdb4d87c10b80574a81b225\n'}, {'number': 8, 'created': '2013-08-26 14:23:57.000000000', 'files': ['nova/tests/test_vmwareapi.py', 'nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/fake.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/virt/vmwareapi/host.py', 'nova/virt/vmwareapi/vim_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1be4b9c187b446f5dec24c072f95a8af5f8f98bb', 'message': 'Fixes host stats for VMWareVCDriver\n\nHost stats for VCDriver should collect aggregate cluster stats\nrather than that of a single host in the cluster.\n\nFixes: bug #1190515\n\n(cherry picked from commit fddcde6a063d59596f687f0651af94f498f7d9b7)\n\nChange-Id: I56b6b027e1370fc2cfdb4d87c10b80574a81b225\n'}]",0,43582,1be4b9c187b446f5dec24c072f95a8af5f8f98bb,18,5,8,8151,,,0,"Fixes host stats for VMWareVCDriver

Host stats for VCDriver should collect aggregate cluster stats
rather than that of a single host in the cluster.

Fixes: bug #1190515

(cherry picked from commit fddcde6a063d59596f687f0651af94f498f7d9b7)

Change-Id: I56b6b027e1370fc2cfdb4d87c10b80574a81b225
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/43582/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_vmwareapi.py', 'nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/fake.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/virt/vmwareapi/host.py', 'nova/virt/vmwareapi/vim_util.py']",6,f250d2f372caf68c20b7acedfa73319988986619,bug/1190515,"def get_object_properties(vim, collector, mobj, type, properties, max_object = 0): if max_object != 0: options = client_factory.create('ns0:RetrieveOptions') options.maxObjects = max_object return vim.RetrievePropertiesEx(usecoll, specSet=[property_filter_spec], options=options) else: return vim.RetrieveProperties(usecoll, specSet=[property_filter_spec])def get_dynamic_property_ex(vim, mobj, type, property_name): """"""Gets a particular property of the Managed Object."""""" property_dict = get_dynamic_properties(vim, mobj, type, [property_name]) return property_dict.get(property_name) def get_dynamic_properties(vim, mobj, type, property_names): """"""Gets the specified properties of the Managed Object."""""" obj_content = get_object_properties(vim, None, mobj, type, property_names, 100) property_dict = {} if obj_content.objects: dynamic_properties = obj_content.objects[0].propSet if dynamic_properties: for prop in dynamic_properties: property_dict[prop.name] = prop.val return property_dict obj_list, properties, max_object = 0): if max_object != 0: options = client_factory.create('ns0:RetrieveOptions') options.maxObjects = max_object return vim.RetrievePropertiesEx( vim.get_service_content().propertyCollector, specSet=[prop_filter_spec], options=options) else: return vim.RetrieveProperties(vim.get_service_content().propertyCollector, def get_about_info(vim): """"""Get the About Info from the service content."""""" return vim.get_service_content().about","def get_object_properties(vim, collector, mobj, type, properties): return vim.RetrieveProperties(usecoll, specSet=[property_filter_spec]) obj_list, properties): return vim.RetrieveProperties(vim.get_service_content().propertyCollector,",251,40
openstack%2Fneutron~master~I93276b059e8e273dc3d01dc3b9ced7f237a53ad9,openstack/neutron,master,I93276b059e8e273dc3d01dc3b9ced7f237a53ad9,Multiple processes support for API server,ABANDONED,2013-07-10 15:34:35.000000000,2013-09-05 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1038}, {'_account_id': 1994}, {'_account_id': 2592}, {'_account_id': 4428}, {'_account_id': 5948}, {'_account_id': 7369}, {'_account_id': 7448}]","[{'number': 1, 'created': '2013-07-10 15:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1da8550eff36beb0703c59596e184d429bc6987c', 'message': ""Multiple precesses support for API server\n\nAdd option 'api_workers' to use multiple processes for api server\n\nImplement blueprint multi-workers-for-api-server\n\nChange-Id: I93276b059e8e273dc3d01dc3b9ced7f237a53ad9\n""}, {'number': 2, 'created': '2013-07-11 00:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/16f8edba161ccac0e4dba294f637e17f62114909', 'message': ""Multiple precesses support for API server\n\nAdd option 'api_workers' to use multiple processes for api server\n\nImplement blueprint multi-workers-for-api-server\n\nChange-Id: I93276b059e8e273dc3d01dc3b9ced7f237a53ad9\n""}, {'number': 3, 'created': '2013-07-12 00:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/932fefa9e565821a747d6d79a2304b00416af47b', 'message': ""Multiple precesses support for API server\n\nAdd option 'api_workers' to use multiple processes for api server\n\nImplement blueprint multi-workers-for-api-server\n\nChange-Id: I93276b059e8e273dc3d01dc3b9ced7f237a53ad9\n""}, {'number': 4, 'created': '2013-07-12 03:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7542df9d1b7dc4d99f30ef76a9974ae02944b960', 'message': ""Multiple precesses support for API server\n\nAdd option 'api_workers' to use multiple processes for api server\n\nImplement blueprint multi-workers-for-api-server\n\nChange-Id: I93276b059e8e273dc3d01dc3b9ced7f237a53ad9\n""}, {'number': 5, 'created': '2013-07-16 14:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cbb55e6fe27747aae12ba106f3029eb1946a533c', 'message': ""Multiple precesses support for API server\n\nAdd option 'api_workers' to use multiple processes for api server\n\nImplement blueprint multi-workers-for-api-server\n\nChange-Id: I93276b059e8e273dc3d01dc3b9ced7f237a53ad9\n""}, {'number': 6, 'created': '2013-07-25 02:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/514695ea2c883776552829a746d4b00d8c9c0b07', 'message': ""Multiple precesses support for API server\n\nAdd option 'api_workers' to use multiple processes for api server\n\nImplement blueprint multi-workers-for-api-server\n\nChange-Id: I93276b059e8e273dc3d01dc3b9ced7f237a53ad9\n""}, {'number': 7, 'created': '2013-08-12 23:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/51aece68a5ece33afcb696cfa0c7371ef6f1b2c1', 'message': ""Multiple precesses support for API server\n\nAdd option 'api_workers' to use multiple processes for api server\n\nImplement blueprint multi-workers-for-api-server\n\nChange-Id: I93276b059e8e273dc3d01dc3b9ced7f237a53ad9\n""}, {'number': 8, 'created': '2013-08-14 00:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a631f67236686ffda02cf1d72cb411b257f2cd91', 'message': ""Multiple processes support for API server\n\nAdd option 'api_workers' to use multiple processes for api server\n\nImplement blueprint multi-workers-for-api-server\n\nChange-Id: I93276b059e8e273dc3d01dc3b9ced7f237a53ad9\n""}, {'number': 9, 'created': '2013-08-14 08:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4bf514113f661b7fd08038006aa5939b73f502e', 'message': ""Multiple processes support for API server\n\nAdd option 'api_workers' to use multiple processes for api server\n\nImplement blueprint multi-workers-for-api-server\n\nChange-Id: I93276b059e8e273dc3d01dc3b9ced7f237a53ad9\n""}, {'number': 10, 'created': '2013-08-28 10:43:12.000000000', 'files': ['neutron/tests/unit/test_metadata_namespace_proxy.py', 'neutron/wsgi.py', 'etc/neutron.conf', 'neutron/agent/metadata/agent.py', 'neutron/agent/metadata/namespace_proxy.py', 'neutron/service.py', 'neutron/tests/unit/test_wsgi.py', 'neutron/server/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d704e774b2688c9c4c80b38753a63d2b633dc2e6', 'message': ""Multiple processes support for API server\n\nAdd option 'api_workers' to use multiple processes for api server\n\nImplement blueprint multi-workers-for-api-server\n\nDocImpact\n\nChange-Id: I93276b059e8e273dc3d01dc3b9ced7f237a53ad9\n""}]",7,36487,d704e774b2688c9c4c80b38753a63d2b633dc2e6,44,8,10,4428,,,0,"Multiple processes support for API server

Add option 'api_workers' to use multiple processes for api server

Implement blueprint multi-workers-for-api-server

DocImpact

Change-Id: I93276b059e8e273dc3d01dc3b9ced7f237a53ad9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/87/36487/8 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/wsgi.py', 'neutron/service.py', 'neutron/tests/unit/test_wsgi.py', 'neutron/server/__init__.py', 'neutron/common/exceptions.py']",5,1da8550eff36beb0703c59596e184d429bc6987c,bp/multi-workers-for-api-server," class PasteAppNotFound(NeutronException): message = _(""Could not load paste app '%(name)s' from %(path)s"")",,344,82
openstack%2Fnova~master~Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb,openstack/nova,master,Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb,"Add a new property ""status"" to hosts index function",ABANDONED,2013-08-10 02:44:55.000000000,2013-09-05 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 8230}, {'_account_id': 8334}]","[{'number': 1, 'created': '2013-08-10 02:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08f97026edb21706d83ccb236a20d252ac01ef6b', 'message': ""Add service status to 'host-list'\n\nwhen we execute 'nova host-list' command, except the basic information about the host,\nwe also want to know the services'status on the hosts just by one time. Whether the service\nis up,just like 'nova-manage service list', so I added this feature through using servicegroup.API.\n\nChange-Id: Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb\nFixes: bug 1076521\n""}, {'number': 2, 'created': '2013-08-10 06:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ded288e4e59cf590bc327f3a73f4e1d0a18f3aba', 'message': ""Add service status to 'host-list'\n\nwhen we execute 'nova host-list' command, except the basic information about the host,\nwe also want to know the services'status on the hosts just by one time. Whether the service\nis up,just like 'nova-manage service list', so I added this feature through using servicegroup.API.\n\nChange-Id: Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb\nFixes: bug 1076521\n""}, {'number': 3, 'created': '2013-08-10 12:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e18b901181aa76ae44732dc7d2d3d754768518bf', 'message': ""Add service status to 'host-list'\n\nwhen we execute 'nova host-list' command, except the basic information about the host,\nwe also want to know the services'status on the hosts just by one time. Whether the service\nis up,just like 'nova-manage service list', so I added this feature through using servicegroup.API.\n\nChange-Id: Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb\nFixes: bug 1076521\n""}, {'number': 4, 'created': '2013-08-13 12:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/572567ee6fd78c9b025a637124269e457a5347ef', 'message': ""Add service status to 'host-list'\n\nwhen we execute 'nova host-list' command, except the basic information about the host,\nwe also want to know the services'status on the hosts just by one time. Whether the service\nis up,just like 'nova-manage service list', so I added this feature through using servicegroup.API.\n\nChange-Id: Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb\nFixes: bug 1076521\n""}, {'number': 5, 'created': '2013-08-14 01:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27d9a9b3a141fbcb903e4a34411057a4980a7ea7', 'message': ""Add service status to 'host-list'\n\nwhen we execute 'nova host-list' command, except the basic information about the host,\nwe also want to know the services'status on the hosts just by one time. Whether the service\nis up,just like 'nova-manage service list', so I added this feature through using servicegroup.API.\n\nChange-Id: Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb\nFixes: bug 1076521\n""}, {'number': 6, 'created': '2013-08-16 04:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cdd5c01dcdcc3853e36d9069b53384844b74d10c', 'message': 'Add a new property ""status"" to hosts index function\n\nwhen we execute \'nova host-list\' command, except the basic information about the host,\nwe also want to know the services\'status on the hosts just by one time. Whether the service\nis up,just like \'nova-manage service list\', so I added this new feature to index function in\ncontrib/hosts.py and plugins/v3/hosts.py.\n\nAt the same time, I refactor the test data for hosts-list test case both in xml and json formats.\nNow, when using the command \'nova host-list\', you can get ""host_name,service,status,zone"" properties.\n\nChange-Id: Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb\nFixes: bug 1076521\n'}, {'number': 7, 'created': '2013-08-19 07:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89181599b3266e4b222a7c2402a36f787102ef0f', 'message': 'Add a new property ""status"" to hosts index function\n\nWhen we execute \'nova host-list\' command, except the basic information about the host,\nwe also want to know the services\' status on the hosts just by one time. Whether the service\nis up, just like \'nova-manage service list\', so I added this new feature to index function in\ncontrib/hosts.py and plugins/v3/hosts.py by using service_group.API().\n\nAt the same time, I refactor the test data for hosts-list test case both in xml and json formats.\nNow, when using the command \'nova host-list\', you can get ""host_name, service, status, zone"" properties.\n\nChange-Id: Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb\nFixes: bug 1076521\n'}, {'number': 8, 'created': '2013-08-26 05:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dfbafc3bd0a2571067a2a9a78883f739caa59747', 'message': 'Add a new property ""status"" to hosts index function\n\nWhen we execute \'nova host-list\' command, except the basic information about the host,\nwe also want to know the services\' status on the hosts just by one time. Whether the service\nis up, just like \'nova-manage service list\', so I added this new feature to index function in\ncontrib/hosts.py and plugins/v3/hosts.py by using service_group.API().\n\nAt the same time, I refactor the test data for hosts-list test case both in xml and json formats.\nNow, when using the command \'nova host-list\', you can get ""host_name, service, status, zone"" properties.\n\nBecause this is a new feature, so I register a blueprint associated with this bug.\n\nChange-Id: Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb\nRelated Bug 1076521\nBlueprint host-list\n'}, {'number': 9, 'created': '2013-08-26 07:40:29.000000000', 'files': ['doc/api_samples/os-hosts/hosts-list-resp.xml', 'nova/tests/integrated/api_samples/os-hosts/hosts-list-resp.json.tpl', 'nova/tests/integrated/api_samples/os-hosts/hosts-list-resp.xml.tpl', 'nova/api/openstack/compute/contrib/hosts.py', 'doc/api_samples/os-hosts/hosts-list-resp.json', 'nova/api/openstack/compute/plugins/v3/hosts.py', 'nova/tests/fake_hosts.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f179bfe1e71b98400855475ac58bca6a9d94f58f', 'message': 'Add a new property ""status"" to hosts index function\n\nWhen we execute \'nova host-list\' command, except the basic information about the host,\nwe also want to know the services\' status on the hosts just by one time. Whether the service\nis up, just like \'nova-manage service list\', so I added this new feature to index function in\ncontrib/hosts.py and plugins/v3/hosts.py by using service_group.API().\n\nAt the same time, I refactor the test data for hosts-list test case both in xml and json formats.\nNow, when using the command \'nova host-list\', you can get ""host_name, service, status, zone"" properties.\n\nChange-Id: Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb\nRelated Bug 1076521\nBlueprint host-list\n'}]",13,41228,f179bfe1e71b98400855475ac58bca6a9d94f58f,42,7,9,8230,,,0,"Add a new property ""status"" to hosts index function

When we execute 'nova host-list' command, except the basic information about the host,
we also want to know the services' status on the hosts just by one time. Whether the service
is up, just like 'nova-manage service list', so I added this new feature to index function in
contrib/hosts.py and plugins/v3/hosts.py by using service_group.API().

At the same time, I refactor the test data for hosts-list test case both in xml and json formats.
Now, when using the command 'nova host-list', you can get ""host_name, service, status, zone"" properties.

Change-Id: Ib3c59bc74cd2dbf552a897c90053d7d0e2a07ffb
Related Bug 1076521
Blueprint host-list
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/41228/7 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/contrib/hosts.py'],1,08f97026edb21706d83ccb236a20d252ac01ef6b,bug/1076521,"from nova import servicegroup 'status': ':-) | XXX', 'status': ':-) | XXX', 'status': ':-) | XXX', 'status': ':-) | XXX', 'status': ':-) | XXX', 'status': ':-) | XXX', 'status': ':-) | XXX', 'status': ':-) | XXX', 'status': ':-) | XXX', 'status': ':-) | XXX', 'status': ':-) | XXX', servicegroup_api = servicegroup.API() alive = servicegroup_api.service_is_up(service) art = (alive and "":-)"") or ""XXX"" 'status':art,",from nova.openstack.common.gettextutils import _,17,1
openstack%2Fneutron~master~Iaf4b0a16593ac505cb548dc99d5b53cf2999e0b1,openstack/neutron,master,Iaf4b0a16593ac505cb548dc99d5b53cf2999e0b1,Add the shared flag when creating a Firewall,ABANDONED,2013-08-22 07:54:33.000000000,2013-09-05 06:03:05.000000000,,"[{'_account_id': 490}, {'_account_id': 2166}, {'_account_id': 5948}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-08-22 07:54:33.000000000', 'files': ['test-requirements.txt', 'neutron/db/firewall/firewall_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3c8bc437f82f0745e38d81340f8d66c40ff7ea1e', 'message': 'Add the shared flag when creating a Firewall\n\nWhen creating a firewall, the shared flag was not being passed to\nthe Firewall class. This fix adds the missing flag.\n\nChange-Id: Iaf4b0a16593ac505cb548dc99d5b53cf2999e0b1\nFixes: bug #1215191\n'}]",1,43253,3c8bc437f82f0745e38d81340f8d66c40ff7ea1e,7,4,1,5162,,,0,"Add the shared flag when creating a Firewall

When creating a firewall, the shared flag was not being passed to
the Firewall class. This fix adds the missing flag.

Change-Id: Iaf4b0a16593ac505cb548dc99d5b53cf2999e0b1
Fixes: bug #1215191
",git fetch https://review.opendev.org/openstack/neutron refs/changes/53/43253/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'neutron/db/firewall/firewall_db.py']",2,3c8bc437f82f0745e38d81340f8d66c40ff7ea1e,bug/1215191," shared=fw['shared'],",,2,1
openstack%2Fpython-keystoneclient~master~I37fbb7fd816b91dd80f71455cd666bb1f960139a,openstack/python-keystoneclient,master,I37fbb7fd816b91dd80f71455cd666bb1f960139a,Client support for catalog-optional API token argument,ABANDONED,2013-08-21 15:41:10.000000000,2013-09-05 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-08-21 15:41:10.000000000', 'files': ['keystoneclient/v3/client.py', 'tests/v3/test_auth.py', 'keystoneclient/httpclient.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/8311df7be623016767b035f4fae7ead6bad3c79c', 'message': 'Client support for catalog-optional API token argument\n\nAdds client support for passing the nocatalog option to the v3\ntokens API, uses API functionality added under the catalog-optional\nblueprint\n\nChange-Id: I37fbb7fd816b91dd80f71455cd666bb1f960139a\n'}]",2,43150,8311df7be623016767b035f4fae7ead6bad3c79c,9,3,1,4328,,,0,"Client support for catalog-optional API token argument

Adds client support for passing the nocatalog option to the v3
tokens API, uses API functionality added under the catalog-optional
blueprint

Change-Id: I37fbb7fd816b91dd80f71455cd666bb1f960139a
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/50/43150/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/v3/client.py', 'tests/v3/test_auth.py', 'keystoneclient/httpclient.py']",3,8311df7be623016767b035f4fae7ead6bad3c79c,bp/Change-Id," project_domain_name=None, nocatalog=False): :param string nocatalog: Omit catalog entry, v3 API only. (optional) self.nocatalog = False # catalog selection setup if nocatalog: self.nocatalog = nocatalog project_domain_name=None, nocatalog=False): With the v3 API nocatalog may be specified to reduce the size of the token response by omitting catalog data nocatalog = nocatalog or self.nocatalog 'token': token, 'nocatalog': nocatalog", project_domain_name=None): project_domain_name=None): 'token': token,52,7
openstack%2Fpython-keystoneclient~master~I1f0aa5b469adea78cce7481f2788eae97e967d10,openstack/python-keystoneclient,master,I1f0aa5b469adea78cce7481f2788eae97e967d10,add compat for rackspace's create user impl (bug 1214686),ABANDONED,2013-08-21 04:02:01.000000000,2013-09-05 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 866}, {'_account_id': 1228}, {'_account_id': 1916}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-08-21 04:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/8d3d77f143e9f536252837afac0a406213b61ff5', 'message': 'add compat for rackspace\'s create user impl (bug 1214686)\n\nAccording to the Identity API v2.0 spec, create user uses a \'username\'\nattribute instead of a \'name\' attribute. Rackspace implemented the spec\ncorrectly and Keystone did not. We now have two conflicting sources of\n""truth,"" so revising the contract to reflect the ""truth"" isn\'t really an\noption. As a compromise, we can handle both implementations on the\nclient side.\n\nChange-Id: I1f0aa5b469adea78cce7481f2788eae97e967d10\n'}, {'number': 2, 'created': '2013-08-21 17:31:35.000000000', 'files': ['keystoneclient/v2_0/users.py', 'tests/v2_0/test_client.py', 'keystoneclient/httpclient.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/e6867c20670b74132f7f219a6fc4985f8a23be30', 'message': 'add compat for rackspace\'s create user impl (bug 1214686)\n\nAccording to the Identity API v2.0 spec, create user uses a \'username\'\nattribute instead of a \'name\' attribute. Rackspace implemented the spec\ncorrectly and Keystone did not. We now have two conflicting sources of\n""truth,"" so revising the contract to reflect the ""truth"" isn\'t really an\noption. As a compromise, we can handle both implementations on the\nclient side.\n\nChange-Id: I1f0aa5b469adea78cce7481f2788eae97e967d10\n'}]",4,43042,e6867c20670b74132f7f219a6fc4985f8a23be30,17,6,2,4,,,0,"add compat for rackspace's create user impl (bug 1214686)

According to the Identity API v2.0 spec, create user uses a 'username'
attribute instead of a 'name' attribute. Rackspace implemented the spec
correctly and Keystone did not. We now have two conflicting sources of
""truth,"" so revising the contract to reflect the ""truth"" isn't really an
option. As a compromise, we can handle both implementations on the
client side.

Change-Id: I1f0aa5b469adea78cce7481f2788eae97e967d10
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/42/43042/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/v2_0/users.py', 'tests/v2_0/test_client.py', 'keystoneclient/httpclient.py']",3,8d3d77f143e9f536252837afac0a406213b61ff5,bug/1214686," def use_rackspace_proprietary_code_path(self): """"""A non-OpenStack implementation of the Identity API may vary."""""" RACKSPACE_IDENTITY_NETLOC = 'identity.api.rackspacecloud.com' def is_rackspace(url): if url is None: return False return urlparse.urlparse(url).netloc == RACKSPACE_IDENTITY_NETLOC return bool(sum( (is_rackspace(self.auth_url), is_rackspace(self.management_url)))) @property",,33,0
openstack%2Fneutron~master~I925e76bb2c75279b384712e8f3d3679878d58006,openstack/neutron,master,I925e76bb2c75279b384712e8f3d3679878d58006,remove openstack.common.context,ABANDONED,2013-08-09 04:14:34.000000000,2013-09-05 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-08-09 04:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1bc6d2a8bde84dab2c61a15ae92b0b185f82cc08', 'message': 'remove openstack.common.context\n\nThe context module is no longer maintained by oslo-incubator\n\nCloses-Bug: #1210261\n\nChange-Id: I925e76bb2c75279b384712e8f3d3679878d58006\n'}, {'number': 2, 'created': '2013-08-09 11:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/16ee974b6b3d5fe3ae480d1623ff5a966f47afe2', 'message': ""remove openstack.common.context\n\nThe context module is no longer maintained by oslo-incubator. This\npatch removes dependency of openstack.common.context from neutron\ncodebase, the openstack.common.notifier still depends on it but it\nis oslo's own problem. This behaviour is same as nova, cinder and\nglance.\n\nFixes: Bug #1210261\n\nChange-Id: I925e76bb2c75279b384712e8f3d3679878d58006\n""}, {'number': 3, 'created': '2013-08-09 23:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cb5b0735fd6e19577bf0dd25c09442e4b3116def', 'message': ""remove openstack.common.context\n\nThe context module is no longer maintained by oslo-incubator. This\npatch removes dependency of openstack.common.context from neutron\ncodebase, the openstack.common.notifier still depends on it but it\nis oslo's own problem. This behaviour is same as nova, cinder and\nglance.\n\nFixes: Bug #1210261\n\nChange-Id: I925e76bb2c75279b384712e8f3d3679878d58006\n""}, {'number': 4, 'created': '2013-08-10 00:40:52.000000000', 'files': ['neutron/plugins/brocade/NeutronPlugin.py', 'neutron/tests/unit/mlnx/test_rpcapi.py', 'neutron/tests/unit/test_agent_rpc.py', 'neutron/tests/unit/ml2/test_rpcapi.py', 'neutron/tests/unit/brocade/test_brocade_vlan.py', 'neutron/context.py', 'neutron/tests/unit/hyperv/test_hyperv_rpcapi.py', 'neutron/tests/unit/openvswitch/test_ovs_rpcapi.py', 'neutron/tests/unit/linuxbridge/test_rpcapi.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a9d6d24b3ea44562596e6f1140156e3cd04f8bdf', 'message': ""remove openstack.common.context\n\nThe context module is no longer maintained by oslo-incubator. This\npatch removes dependency of openstack.common.context from neutron\ncodebase, the openstack.common.notifier still depends on it but it\nis oslo's own problem. This behaviour is same as nova, cinder and\nglance.\n\nFixes: Bug #1210261\n\nChange-Id: I925e76bb2c75279b384712e8f3d3679878d58006\n""}]",0,41022,a9d6d24b3ea44562596e6f1140156e3cd04f8bdf,17,3,4,6676,,,0,"remove openstack.common.context

The context module is no longer maintained by oslo-incubator. This
patch removes dependency of openstack.common.context from neutron
codebase, the openstack.common.notifier still depends on it but it
is oslo's own problem. This behaviour is same as nova, cinder and
glance.

Fixes: Bug #1210261

Change-Id: I925e76bb2c75279b384712e8f3d3679878d58006
",git fetch https://review.opendev.org/openstack/neutron refs/changes/22/41022/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/openstack/common/notifier/rpc_notifier2.py', 'neutron/openstack/common/notifier/rpc_notifier.py', 'neutron/plugins/brocade/NeutronPlugin.py', 'neutron/tests/unit/test_agent_rpc.py', 'neutron/tests/unit/ml2/test_rpcapi.py', 'neutron/openstack/common/notifier/api.py', 'neutron/tests/unit/openvswitch/test_ovs_rpcapi.py', 'neutron/tests/unit/mlnx/test_rpcapi.py', 'neutron/tests/unit/brocade/test_brocade_vlan.py', 'openstack-common.conf', 'neutron/context.py', 'neutron/tests/unit/hyperv/test_hyperv_rpcapi.py', 'neutron/openstack/common/context.py', 'neutron/tests/unit/linuxbridge/test_rpcapi.py']",14,1bc6d2a8bde84dab2c61a15ae92b0b185f82cc08,bug/1210261,"from neutron import context ctxt = context.Context('fake_user', 'fake_project')","from neutron.openstack.common import context ctxt = context.RequestContext('fake_user', 'fake_project')",48,109
openstack%2Ftempest~master~I89612a0dd66513f10e8bf53632f6a3d81ccf4129,openstack/tempest,master,I89612a0dd66513f10e8bf53632f6a3d81ccf4129,Updating HACKING.rst,MERGED,2013-08-16 07:23:51.000000000,2013-09-05 06:01:56.000000000,2013-09-05 06:01:56.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 2976}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6796}, {'_account_id': 7872}, {'_account_id': 8085}]","[{'number': 1, 'created': '2013-08-16 07:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7bbf2ee4fc07da7e4ce5e5b8247bb4e5a0ea317a', 'message': 'Updating HACKING.rst\n\n* Adding a test case independce rule\n* Encouraging  matcher usage for assertion\n\nChange-Id: I89612a0dd66513f10e8bf53632f6a3d81ccf4129\n'}, {'number': 2, 'created': '2013-08-16 13:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d4d9e5bb588b3b887caac279ac61ed4627c1c5d8', 'message': 'Updating HACKING.rst\n\n* Adding a test case independce rule\n* Encouraging  matcher usage for assertion\n\nChange-Id: I89612a0dd66513f10e8bf53632f6a3d81ccf4129\n'}, {'number': 3, 'created': '2013-08-21 19:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/517cdc8f411da4b0447489135289e4055c66e73e', 'message': 'Updating HACKING.rst\n\n* Adding a test case independence rule\n* Encouraging  matcher usage for assertion\n\nChange-Id: I89612a0dd66513f10e8bf53632f6a3d81ccf4129\n'}, {'number': 4, 'created': '2013-08-23 07:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/16078b6d92d73db46b007d1fb702675355078daa', 'message': 'Updating HACKING.rst\n\n* Adding a test case independence rule\n* assertTrue/assertFalse msg argument\n* Encouraging  matcher usage for assertion\n\nChange-Id: I89612a0dd66513f10e8bf53632f6a3d81ccf4129\n'}, {'number': 5, 'created': '2013-08-26 20:16:37.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7899d312ad5e13824b827189ace1d89b046a36ce', 'message': 'Updating HACKING.rst\n\n* Adding a test case independence rule\n* assertTrue/assertFalse msg argument\n* Encouraging  matcher usage for assertion\n\nChange-Id: I89612a0dd66513f10e8bf53632f6a3d81ccf4129\n'}]",7,42296,7899d312ad5e13824b827189ace1d89b046a36ce,39,11,5,5803,,,0,"Updating HACKING.rst

* Adding a test case independence rule
* assertTrue/assertFalse msg argument
* Encouraging  matcher usage for assertion

Change-Id: I89612a0dd66513f10e8bf53632f6a3d81ccf4129
",git fetch https://review.opendev.org/openstack/tempest refs/changes/96/42296/3 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,7bbf2ee4fc07da7e4ce5e5b8247bb4e5a0ea317a,individual,"Recommended to use testtools matcher for more tricky assertion. You can implement your own specific matcher as well. Test cases are independent -------------------------- Every ``test_method`` must be callable individually and MUST NOT depends on, any other ``test_method`` or ``test_method`` ordering. Test cases MAY depend on commonly initialized resources/facilities, like credentials management, testresources and so on. These facilities, MUST be able to work even if just one ``test_method`` selected for execution. ",,12,0
openstack%2Fglance~master~Iaf2111bf07377ef6a4c89a621888077cc14be776,openstack/glance,master,Iaf2111bf07377ef6a4c89a621888077cc14be776,Property Protection Layer,MERGED,2013-08-26 16:20:36.000000000,2013-09-05 06:01:52.000000000,2013-09-05 06:01:51.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 1390}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 8158}]","[{'number': 1, 'created': '2013-08-26 16:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fa77d7086cecf8cf3f541bf1eed8c96bdbb70423', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 2, 'created': '2013-08-26 17:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fcb9ef926ddb28ece3e10eb7dcdb7c86953237de', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 3, 'created': '2013-08-26 17:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7f5ee5b59f98c0c50a822384543e4a500fabdff2', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 4, 'created': '2013-08-27 15:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6c952b7c3df013753588d838fa7fe3a1a64b5045', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 5, 'created': '2013-08-28 14:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/df59297c856084612bd47d1d4a08e754867c6d97', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 6, 'created': '2013-08-28 16:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cf3426220eabdb67461f6a5f836a7477f5df8536', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 7, 'created': '2013-08-30 20:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/86dc4e1a78409834c22004b6aea1c7a75d25d61e', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 8, 'created': '2013-08-30 20:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0b930230e9956b028f24a9b2c405998d138fe3d7', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 9, 'created': '2013-08-30 21:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e0dec5ecb43496039a89c0956e738a033aa0fb51', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 10, 'created': '2013-09-02 13:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e99129e1c1d1b6108bc6af040a2e31640c002eb6', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 11, 'created': '2013-09-03 19:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/eec05ef128a9dff75817a8ffeaef85e8c1b0715f', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 12, 'created': '2013-09-04 02:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2cb4e8eb05421dd8f7b7da09e31030bf8c4742e4', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 13, 'created': '2013-09-04 03:09:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0bddf69d20c54f2b82420b4a3f19918b64cbf74f', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 14, 'created': '2013-09-04 14:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b01c64182d36af3f14b2521f8a9813f2919de573', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 15, 'created': '2013-09-04 15:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/00f9f8efc7acea2a754287de00d89878f4d7f9b8', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}, {'number': 16, 'created': '2013-09-04 17:57:08.000000000', 'files': ['glance/tests/unit/utils.py', 'glance/tests/unit/api/test_property_protections.py', 'glance/domain/__init__.py', 'glance/api/property_protections.py', 'glance/tests/unit/test_domain.py', 'glance/tests/etc/property-protections.conf', 'glance/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/262bdf68b45058fedffda614336d7e75a5b36d4a', 'message': 'Property Protection Layer\n\nThis patch introduces the property protection layer and the tests\nassociated with it\n\nRelated to bp api-v2-property-protection\n\nChange-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776\n'}]",42,43733,262bdf68b45058fedffda614336d7e75a5b36d4a,65,8,16,4463,,,0,"Property Protection Layer

This patch introduces the property protection layer and the tests
associated with it

Related to bp api-v2-property-protection

Change-Id: Iaf2111bf07377ef6a4c89a621888077cc14be776
",git fetch https://review.opendev.org/openstack/glance refs/changes/33/43733/13 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/utils.py', 'glance/tests/unit/test_property_protections.py', 'glance/domain/__init__.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/api/property_protections.py', 'glance/tests/etc/property-protections.conf', 'glance/tests/unit/test_domain.py', 'glance/tests/utils.py']",8,fa77d7086cecf8cf3f541bf1eed8c96bdbb70423,bp/api-v2-property-protection,from glance.common import property_utils,,509,4
openstack%2Fglance~master~I3d24cacccf3f51b07a4090b8a5db1f2451090762,openstack/glance,master,I3d24cacccf3f51b07a4090b8a5db1f2451090762,Rule parser for property protections,MERGED,2013-08-22 22:44:33.000000000,2013-09-05 06:01:49.000000000,2013-09-05 06:01:49.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 455}, {'_account_id': 616}, {'_account_id': 1390}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 8158}]","[{'number': 1, 'created': '2013-08-22 22:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b0de1c1e8c50a742380635a99f3ee7f0c0dfdd08', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to api-v2-property-protection\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 2, 'created': '2013-08-23 22:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3a677369536dea6894fb79f111d018f2070d56bd', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to api-v2-property-protection\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 3, 'created': '2013-08-26 15:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1d3ebadc0ca8e8b3c2fac8307853eaa50452244d', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 4, 'created': '2013-08-26 15:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/16470211677821fe8d90f08e4269b73346b10cb7', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 5, 'created': '2013-08-26 16:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c117576dbbf54812a75d5d152b9613a812e7e3cd', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 6, 'created': '2013-08-26 17:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/80d92143e43562c4ebbb8e45b9ce2dbb0bbf7311', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 7, 'created': '2013-08-26 17:38:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ee94868881267c704a72f0d9f9be3574684908c1', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 8, 'created': '2013-08-27 15:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/822e211d152245d342502edcfbbf534a67e08b3a', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 9, 'created': '2013-08-28 14:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/233442af0d85e48a011fc04966ffb6cfc3935a65', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 10, 'created': '2013-08-28 16:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/795ff931fb497f2482654577ab0c07561a5992e1', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 11, 'created': '2013-08-28 16:32:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e04aa1912d75ee51ca457d9c952b5a4a918ed8e2', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\ndocImpact\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 12, 'created': '2013-08-30 16:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a7db2aa4761fda4a95590331cb6c5ddc83cdd9a9', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\ndocImpact\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 13, 'created': '2013-08-30 16:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/99280cdbea359053be8836d48fe7ac55356c0467', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\ndocImpact\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 14, 'created': '2013-08-30 18:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fadd654a3a96dc7bb45ebd7fdfb46571aee4a50e', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\ndocImpact\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 15, 'created': '2013-08-30 18:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/236f3a0f6ef9b38c4bfa8b6d5b415c01a9574643', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\ndocImpact\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 16, 'created': '2013-09-02 13:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/558a13751cd1b5eb7c874fc617af9230f997c9b7', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\ndocImpact\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 17, 'created': '2013-09-03 14:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a0b6a5aebf4df152b7b6541c601df5f9c4f3e92d', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\ndocImpact\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 18, 'created': '2013-09-03 19:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/75fe3aa3e042cdb04f1800436713c49da9c48354', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\ndocImpact\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 19, 'created': '2013-09-04 14:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1ab2a21cb27ad5d574110210223f72f05c352100', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\ndocImpact\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 20, 'created': '2013-09-04 15:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a700f7d75ba95a37b38a00fbc137c38891af1ff7', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\ndocImpact\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}, {'number': 21, 'created': '2013-09-04 17:47:39.000000000', 'files': ['glance/tests/unit/common/test_property_utils.py', 'etc/property-protections.conf.sample', 'etc/glance-api.conf', 'glance/common/property_utils.py', 'glance/tests/etc/property-protections.conf', 'glance/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/e8440d1ee8da2cbf4304bbbc0bf43ce78d7a6d1f', 'message': 'Rule parser for property protections\n\nThis patch introduces the way protected properties\nwill be configured and parsed.\n\nRelated to bp api-v2-property-protection\ndocImpact\n\nChange-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762\n'}]",38,43368,e8440d1ee8da2cbf4304bbbc0bf43ce78d7a6d1f,97,10,21,4463,,,0,"Rule parser for property protections

This patch introduces the way protected properties
will be configured and parsed.

Related to bp api-v2-property-protection
docImpact

Change-Id: I3d24cacccf3f51b07a4090b8a5db1f2451090762
",git fetch https://review.opendev.org/openstack/glance refs/changes/68/43368/9 && git format-patch -1 --stdout FETCH_HEAD,"['etc/property-protections.conf', 'etc/glance-api.conf', 'glance/tests/unit/test_domain_property_utils.py', 'glance/domain/property_utils.py', 'glance/tests/etc/property-protections.conf', 'glance/tests/utils.py']",6,b0de1c1e8c50a742380635a99f3ee7f0c0dfdd08,bp/api-v2-property-protection,"import shutilimport fixtures self.test_dir = self.useFixture(fixtures.TempDir()).path self.property_file = self._copy_data_file('property-protections.conf', self.test_dir) self.config(property_protection_file=self.property_file) def _copy_data_file(self, file_name, dst_dir): src_file_name = os.path.join('glance/tests/etc', file_name) shutil.copy(src_file_name, dst_dir) dst_file_name = os.path.join(dst_dir, file_name) return dst_file_name def set_property_protections(self, protections): fap = open(CONF.property_protection_file, 'w') fap.write(protections) fap.close() ",,192,0
openstack%2Fkeystone~master~I13e155cf04dd478d575c8d66216d0fde08875ba2,openstack/keystone,master,I13e155cf04dd478d575c8d66216d0fde08875ba2,OAuth authorizing user should propose roles to delegate,MERGED,2013-08-25 04:53:08.000000000,2013-09-05 06:01:42.000000000,2013-09-05 06:01:41.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2166}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}]","[{'number': 1, 'created': '2013-08-25 04:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a219476eb439602cfbdfd5ccca5e55caff0a49e6', 'message': 'OAuth authorizing user should propose roles to delegate\n\nCurrently in the oauth1 extension the consumer specifies roles\ninstead of delegator. This is a design fault that should be fixed\nby having the authorizing user provide a set of roles (ids)\nduring the authorize request token phase.\n\nfixes bug: #1216408\n\nChange-Id: I13e155cf04dd478d575c8d66216d0fde08875ba2\n'}, {'number': 2, 'created': '2013-08-25 04:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c3785bfb10e762c938d419def4ed2529e1f78120', 'message': 'OAuth authorizing user should propose roles to delegate\n\nCurrently in the oauth1 extension the consumer specifies roles\ninstead of delegator. This is a design fault that should be fixed\nby having the authorizing user provide a set of roles (ids)\nduring the authorize request token phase.\n\nfixes bug: #1216408\n\nChange-Id: I13e155cf04dd478d575c8d66216d0fde08875ba2\n'}, {'number': 3, 'created': '2013-08-30 17:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/88f5390c61800a126224653ede92ab02bc71bda4', 'message': 'OAuth authorizing user should propose roles to delegate\n\nCurrently in the oauth1 extension the consumer specifies roles\ninstead of delegator. This is a design fault that should be fixed\nby having the authorizing user provide a set of roles (ids)\nduring the authorize request token phase.\n\nfixes bug: #1216408\n\nChange-Id: I13e155cf04dd478d575c8d66216d0fde08875ba2\n'}, {'number': 4, 'created': '2013-09-04 18:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9f30072e8c17913c1af5571c48c36fa420c8fd0e', 'message': 'OAuth authorizing user should propose roles to delegate\n\nCurrently in the oauth1 extension the consumer specifies roles\ninstead of delegator. This is a design fault that should be fixed\nby having the authorizing user provide a set of roles (ids)\nduring the authorize request token phase.\n\nfixes bug: #1216408\n\nChange-Id: I13e155cf04dd478d575c8d66216d0fde08875ba2\n'}, {'number': 5, 'created': '2013-09-04 20:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/78c822c8589cfa7225050eab6328d9fe00a0ac28', 'message': 'OAuth authorizing user should propose roles to delegate\n\nCurrently in the oauth1 extension the consumer specifies roles\ninstead of delegator. This is a design fault that should be fixed\nby having the authorizing user provide a set of roles (ids)\nduring the authorize request token phase.\n\nfixes bug: #1216408\n\nChange-Id: I13e155cf04dd478d575c8d66216d0fde08875ba2\n'}, {'number': 6, 'created': '2013-09-04 21:41:25.000000000', 'files': ['keystone/contrib/oauth1/backends/sql.py', 'keystone/tests/test_v3_oauth1.py', 'keystone/token/providers/uuid.py', 'keystone/contrib/oauth1/controllers.py', 'keystone/contrib/oauth1/core.py', 'keystone/contrib/oauth1/migrate_repo/versions/004_request_token_roles_nullable.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3b43bca897e507f3db34c14047d48182761a4014', 'message': 'OAuth authorizing user should propose roles to delegate\n\nCurrently in the oauth1 extension the consumer specifies roles\ninstead of delegator. This is a design fault that should be fixed\nby having the authorizing user provide a set of roles (ids)\nduring the authorize request token phase.\n\nfixes bug: #1216408\n\nChange-Id: I13e155cf04dd478d575c8d66216d0fde08875ba2\n'}]",6,43610,3b43bca897e507f3db34c14047d48182761a4014,33,6,6,6482,,,0,"OAuth authorizing user should propose roles to delegate

Currently in the oauth1 extension the consumer specifies roles
instead of delegator. This is a design fault that should be fixed
by having the authorizing user provide a set of roles (ids)
during the authorize request token phase.

fixes bug: #1216408

Change-Id: I13e155cf04dd478d575c8d66216d0fde08875ba2
",git fetch https://review.opendev.org/openstack/keystone refs/changes/10/43610/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/contrib/oauth1/backends/sql.py', 'keystone/tests/test_v3_oauth1.py', 'keystone/contrib/oauth1/controllers.py', 'keystone/contrib/oauth1/core.py', 'keystone/contrib/oauth1/migrate_repo/versions/004_request_token_roles_nullable.py']",5,a219476eb439602cfbdfd5ccca5e55caff0a49e6,bug1216408,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2013 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import sqlalchemy as sql def upgrade(migrate_engine): meta = sql.MetaData() meta.bind = migrate_engine request_token_table = sql.Table('request_token', meta, autoload=True) request_token_table.c.requested_roles.alter(nullable=True) def downgrade(migrate_engine): meta = sql.MetaData() meta.bind = migrate_engine request_token_table = sql.Table('request_token', meta, autoload=True) request_token_table.c.requested_roles.alter(nullable=False) ",,77,73
openstack%2Fglance~master~I8c8b94732c219fe61caa584527921b65217bea30,openstack/glance,master,I8c8b94732c219fe61caa584527921b65217bea30,Update schema descriptions to indicate readonly,MERGED,2013-09-04 18:51:44.000000000,2013-09-05 06:01:39.000000000,2013-09-05 06:01:39.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 4463}]","[{'number': 1, 'created': '2013-09-04 18:51:44.000000000', 'files': ['glance/api/v2/images.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/cc1839ecd2681f96f00e9154d4caa8dc61ae4859', 'message': 'Update schema descriptions to indicate readonly\n\nLonger term we may look into using the json hyper-schema readonly\nattribute, but for now this will allow the user to see up-front\nwhich properties are actually read-only and cannot be changed.\n\nChange-Id: I8c8b94732c219fe61caa584527921b65217bea30\n'}]",0,45095,cc1839ecd2681f96f00e9154d4caa8dc61ae4859,8,4,1,5347,,,0,"Update schema descriptions to indicate readonly

Longer term we may look into using the json hyper-schema readonly
attribute, but for now this will allow the user to see up-front
which properties are actually read-only and cannot be changed.

Change-Id: I8c8b94732c219fe61caa584527921b65217bea30
",git fetch https://review.opendev.org/openstack/glance refs/changes/95/45095/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/v2/images.py'],1,cc1839ecd2681f96f00e9154d4caa8dc61ae4859,," 'description': _('Status of the image (READ-ONLY)'), 'description': _('md5 hash of image contents. (READ-ONLY)'), 'description': _('Size of image file in bytes (READ-ONLY)'), 'description': _('Date and time of image registration' ' (READ-ONLY)'), 'description': _('Date and time of the last image modification' ' (READ-ONLY)'), 'store (READ-ONLY)'), 'self': { 'type': 'string', 'description': '(READ-ONLY)' }, 'file': { 'type': 'string', 'description': '(READ-ONLY)' }, 'schema': { 'type': 'string', 'description': '(READ-ONLY)' },"," 'description': _('Status of the image'), 'description': _('md5 hash of image contents.'), 'description': _('Size of image file in bytes'), 'description': _('Date and time of image registration'), 'description': _('Date and time of the last image modification'), 'store'), 'self': {'type': 'string'}, 'file': {'type': 'string'}, 'schema': {'type': 'string'},",20,9
openstack%2Fneutron~master~Id6fc22841fddabfbe685de9605d4a4682ee1102d,openstack/neutron,master,Id6fc22841fddabfbe685de9605d4a4682ee1102d,Add support for the multiprovider API to ML2,MERGED,2013-08-24 03:05:17.000000000,2013-09-05 06:01:31.000000000,2013-09-05 06:01:30.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 1689}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6676}, {'_account_id': 6820}]","[{'number': 1, 'created': '2013-08-24 03:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/12bf8b1dcb3aa9ee5cdf00873b2017ef868988d1', 'message': 'Add support for the multiprovider API to ML2.\n\nThis implements support for creating provider networks with\nmultiple different segments with the ML2 plugin.\n\nImplements: blueprint ml2-multi-segment-api\n\nChange-Id: Id6fc22841fddabfbe685de9605d4a4682ee1102d\n'}, {'number': 2, 'created': '2013-09-03 19:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f6eea7bdbe794267937fe08fc6695aeace09b07', 'message': 'Add support for the multiprovider API to ML2\n\nThis implements support for creating provider networks with\nmultiple different segments with the ML2 plugin.\n\nImplements: blueprint ml2-multi-segment-api\n\nChange-Id: Id6fc22841fddabfbe685de9605d4a4682ee1102d\n'}, {'number': 3, 'created': '2013-09-04 02:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f7aa801f52070886ea3fc54ed67f5b56d909a09', 'message': 'Add support for the multiprovider API to ML2\n\nThis implements support for creating provider networks with\nmultiple different segments with the ML2 plugin.\n\nImplements: blueprint ml2-multi-segment-api\n\nChange-Id: Id6fc22841fddabfbe685de9605d4a4682ee1102d\n'}, {'number': 4, 'created': '2013-09-04 13:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/512afdd92c4dad5163264669bdbbd00a839159d1', 'message': 'Add support for the multiprovider API to ML2\n\nThis implements support for creating provider networks with\nmultiple different segments with the ML2 plugin.\n\nImplements: blueprint ml2-multi-segment-api\n\nChange-Id: Id6fc22841fddabfbe685de9605d4a4682ee1102d\n'}, {'number': 5, 'created': '2013-09-04 13:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b50d29752101643297f463a9de20c072be07d07', 'message': 'Add support for the multiprovider API to ML2\n\nThis implements support for creating provider networks with\nmultiple different segments with the ML2 plugin.\n\nImplements: blueprint ml2-multi-segment-api\n\nChange-Id: Id6fc22841fddabfbe685de9605d4a4682ee1102d\n'}, {'number': 6, 'created': '2013-09-04 20:56:45.000000000', 'files': ['neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d5b09d891ab52c2eb1dc21bab4faa45e2b18ad81', 'message': 'Add support for the multiprovider API to ML2\n\nThis implements support for creating provider networks with\nmultiple different segments with the ML2 plugin.\n\nImplements: blueprint ml2-multi-segment-api\n\nChange-Id: Id6fc22841fddabfbe685de9605d4a4682ee1102d\n'}]",55,43569,d5b09d891ab52c2eb1dc21bab4faa45e2b18ad81,59,10,6,105,,,0,"Add support for the multiprovider API to ML2

This implements support for creating provider networks with
multiple different segments with the ML2 plugin.

Implements: blueprint ml2-multi-segment-api

Change-Id: Id6fc22841fddabfbe685de9605d4a4682ee1102d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/69/43569/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/plugins/ml2/plugin.py']",2,12bf8b1dcb3aa9ee5cdf00873b2017ef868988d1,bp/ml2-multi-segment-api,"from neutron.extensions import multiprovidernet as mpnet ""dhcp_agent_scheduler"", ""ext-gw-mode"", ""multi-provider""] def _validate_provider_create(self, context, network): if not attributes.is_attr_set(network.get(mpnet.SEGMENTS)): return segments = [] for segment in network[mpnet.SEGMENTS]: network_type = segment.get(provider.NETWORK_TYPE) physical_network = segment.get(provider.PHYSICAL_NETWORK) segmentation_id = segment.get(provider.SEGMENTATION_ID) if attributes.is_attr_set(network_type): segment = {api.NETWORK_TYPE: network_type, api.PHYSICAL_NETWORK: physical_network, api.SEGMENTATION_ID: segmentation_id} self.type_manager.validate_provider_segment(segment) segments.append(segment) elif (attributes.is_attr_set(segment.get(provider.PHYSICAL_NETWORK)) or attributes.is_attr_set(segment. get(provider.SEGMENTATION_ID))): msg = _(""network_type required if other provider attributes "" ""specified"") raise exc.InvalidInput(error_message=msg) return segments def _extend_network_dict_provider(self, context, network, multiprovider=False): #elif len(segments) > 1: elif multiprovider: network[mpnet.SEGMENTS] = [ {provider.NETWORK_TYPE: segment[api.NETWORK_TYPE], provider.PHYSICAL_NETWORK: segment[api.PHYSICAL_NETWORK], provider.SEGMENTATION_ID: segment[api.SEGMENTATION_ID]} for segment in segments] def _convert_to_multi_provider(self, network): """"""Converts the provider request body to multiprovider. Returns: True if request is multiprovider False if provider and None if neither. """""" if any(attributes.is_attr_set(network.get(f)) for f in (provider.NETWORK_TYPE, provider.PHYSICAL_NETWORK, provider.SEGMENTATION_ID)): if attributes.is_attr_set(network.get(mpnet.SEGMENTS)): raise mpnet.SegmentsSetInConjunctionWithProviders() # convert to transport zone list network[mpnet.SEGMENTS] = [ {provider.NETWORK_TYPE: network[provider.NETWORK_TYPE], provider.PHYSICAL_NETWORK: network[provider. PHYSICAL_NETWORK], provider.SEGMENTATION_ID: network[provider.SEGMENTATION_ID]}] del network[provider.NETWORK_TYPE] del network[provider.PHYSICAL_NETWORK] del network[provider.SEGMENTATION_ID] return False if attributes.is_attr_set(mpnet.SEGMENTS): return True def create_network(self, context, network): net_data = network['network'] multiprovider = self._convert_to_multi_provider(net_data) segments = self._validate_provider_create(context, net_data) tenant_id = self._get_tenant_id_for_create(context, network) self._process_l3_create(context, result, network) if (net_data.get(mpnet.SEGMENTS)): for segment in segments: self.type_manager.reserve_provider_segment(session, segment) db.add_network_segment(session, id, segment) self._extend_network_dict_provider(context, result, multiprovider=multiprovider) mech_context = driver_context.NetworkContext( self, context, result, segments=segments) else: segment = self.type_manager.allocate_tenant_segment(session) db.add_network_segment(session, id, segment) self._extend_network_dict_provider(context, result) mech_context = driver_context.NetworkContext( self, context, result, segments=[segment]) multiprovider = self._convert_to_multi_provider(updated_network) self._extend_network_dict_provider(context, updated_network, multiprovider=multiprovider) multiprovider = self._convert_to_multi_provider(result) self._extend_network_dict_provider(context, result, multiprovider=multiprovider) multiprovider = self._convert_to_multi_provider(net) self._extend_network_dict_provider(context, net, multiprovider=multiprovider)"," ""dhcp_agent_scheduler"", ""ext-gw-mode""] def _process_provider_create(self, context, attrs): network_type = self._get_attribute(attrs, provider.NETWORK_TYPE) physical_network = self._get_attribute(attrs, provider.PHYSICAL_NETWORK) segmentation_id = self._get_attribute(attrs, provider.SEGMENTATION_ID) if attributes.is_attr_set(network_type): segment = {api.NETWORK_TYPE: network_type, api.PHYSICAL_NETWORK: physical_network, api.SEGMENTATION_ID: segmentation_id} self.type_manager.validate_provider_segment(segment) return segment if (attributes.is_attr_set(attrs.get(provider.PHYSICAL_NETWORK)) or attributes.is_attr_set(attrs.get(provider.SEGMENTATION_ID))): msg = _(""network_type required if other provider attributes "" ""specified"") raise exc.InvalidInput(error_message=msg) def _extend_network_dict_provider(self, context, network): elif len(segments) > 1: network[provider.NETWORK_TYPE] = TYPE_MULTI_SEGMENT network[provider.PHYSICAL_NETWORK] = None network[provider.SEGMENTATION_ID] = None def create_network(self, context, network): attrs = network['network'] segment = self._process_provider_create(context, attrs) tenant_id = self._get_tenant_id_for_create(context, attrs) if segment: self.type_manager.reserve_provider_segment(session, segment) else: segment = self.type_manager.allocate_tenant_segment(session) self._process_l3_create(context, result, attrs) db.add_network_segment(session, id, segment) self._extend_network_dict_provider(context, result) mech_context = driver_context.NetworkContext(self, context, result, segments=[segment]) self._extend_network_dict_provider(context, updated_network) self._extend_network_dict_provider(context, result) self._extend_network_dict_provider(context, net)",205,43
openstack%2Fglance~master~Ie38307f514c1716dce31403d9ef57eae8290450d,openstack/glance,master,Ie38307f514c1716dce31403d9ef57eae8290450d,Notify error not called on upload errors in V2,MERGED,2013-08-28 14:37:36.000000000,2013-09-05 05:57:12.000000000,2013-09-05 05:57:12.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 5347}, {'_account_id': 6484}, {'_account_id': 6493}, {'_account_id': 7701}]","[{'number': 1, 'created': '2013-08-28 14:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8e1b0f9b3c56556e650f4decd885b06316304caa', 'message': ""Notify error not called on upload errors in V2\n\nThe 'upload' method in glance/api/v2/image_data.py catches a couple of\nexceptions, but does not send notifications for any of them. They should\nalso be sending notifications as is being done in v1.\n\nFixes: Bug #1217837\nChange-Id: Ie38307f514c1716dce31403d9ef57eae8290450d\n""}, {'number': 2, 'created': '2013-08-29 10:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fbc365177b882c2ec5d05ab396e68c42fe101d27', 'message': ""Notify error not called on upload errors in V2\n\nThe 'upload' method in glance/api/v2/image_data.py catches a couple of\nexceptions, but does not send notifications for any of them. They should\nalso be sending notifications as is being done in v1.\n\nFixes: Bug #1217837\nChange-Id: Ie38307f514c1716dce31403d9ef57eae8290450d\n""}, {'number': 3, 'created': '2013-08-30 08:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a36782e83b21a2c8d1c7fc7c908c806396c85188', 'message': ""Notify error not called on upload errors in V2\n\nThe 'upload' method in glance/api/v2/image_data.py catches a couple of\nexceptions, but does not send notifications for any of them. They should\nalso be sending notifications as is being done in v1.\n\nFixes: Bug #1217837\nChange-Id: Ie38307f514c1716dce31403d9ef57eae8290450d\n""}, {'number': 4, 'created': '2013-08-31 08:15:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3b49a16a94578cd26ad77430e8145deb6e4a33bf', 'message': ""Notify error not called on upload errors in V2\n\nThe 'upload' method in glance/api/v2/image_data.py catches a couple of\nexceptions, but does not send notifications for any of them. They should\nalso be sending notifications as is being done in v1.\n\nFixes: Bug #1217837\nChange-Id: Ie38307f514c1716dce31403d9ef57eae8290450d\n""}, {'number': 5, 'created': '2013-09-02 11:19:18.000000000', 'files': ['glance/notifier/__init__.py', 'glance/tests/unit/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/437a283f24e9791f113665036e090967b8747bd2', 'message': ""Notify error not called on upload errors in V2\n\nThe 'upload' method in glance/api/v2/image_data.py catches a couple of\nexceptions, but does not send notifications for any of them. They should\nalso be sending notifications as is being done in v1.\n\nFixes: Bug #1217837\nChange-Id: Ie38307f514c1716dce31403d9ef57eae8290450d\n""}]",6,44060,437a283f24e9791f113665036e090967b8747bd2,26,8,5,7701,,,0,"Notify error not called on upload errors in V2

The 'upload' method in glance/api/v2/image_data.py catches a couple of
exceptions, but does not send notifications for any of them. They should
also be sending notifications as is being done in v1.

Fixes: Bug #1217837
Change-Id: Ie38307f514c1716dce31403d9ef57eae8290450d
",git fetch https://review.opendev.org/openstack/glance refs/changes/60/44060/4 && git format-patch -1 --stdout FETCH_HEAD,['glance/notifier/__init__.py'],1,8e1b0f9b3c56556e650f4decd885b06316304caa,bug/1217837,"import webob except ValueError as e: msg = _(""Cannot save data for image %s:"") % e self.notifier.error('image.upload', msg) except exception.Duplicate as e: msg = _(""Unable to upload duplicate image data for image: %s"") % e self.notifier.error('image.upload', msg) except exception.Forbidden as e: msg = (_(""Not allowed to upload image data for image %s: %s"") % e % self.image.image_id) self.notifier.error('image.upload', msg) except exception.NotFound as e: msg = _(""Image %s could not be found after upload. The image may "" ""have been deleted during the upload: %s"")\ % e % self.image.image_id self.notifier.error('image.upload', msg) except webob.exc.HTTPError as e: msg = _(""Failed to upload image data due to HTTP error: %s"") % e self.notifier.error('image.upload', msg) except Exception as e: msg = _(""Failed to upload image data due to internal error: %s"")\ % e self.notifier.error('image.upload', msg)",,23,0
openstack%2Fnova~master~Ibd25f4479d49f456bcb49e3eb003edf3d4b2b334,openstack/nova,master,Ibd25f4479d49f456bcb49e3eb003edf3d4b2b334,Add missing Aggregate object tests,MERGED,2013-09-03 22:33:20.000000000,2013-09-05 05:55:28.000000000,2013-09-05 05:55:25.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-09-03 22:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2406f31b51fc30a9c8cfe7e9987a8d3061b5a39e', 'message': ""Add missing Aggregate object tests\n\nThis file was not properly git-add'd to commit:\n\n  f2252de974e1bf3b40f8dce0e768597e31ac2a05\n\nRelated to blueprint compute-api-objects\n\nChange-Id: Ibd25f4479d49f456bcb49e3eb003edf3d4b2b334\n""}, {'number': 2, 'created': '2013-09-04 21:32:53.000000000', 'files': ['nova/tests/objects/test_aggregate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d201d9ed66eb14c6bdf52ea8094c30444e06bfaf', 'message': ""Add missing Aggregate object tests\n\nThis file was not properly git-add'd to commit:\n\n  f2252de974e1bf3b40f8dce0e768597e31ac2a05\n\nRelated to blueprint compute-api-objects\n\nChange-Id: Ibd25f4479d49f456bcb49e3eb003edf3d4b2b334\n""}]",0,44966,d201d9ed66eb14c6bdf52ea8094c30444e06bfaf,15,5,2,4393,,,0,"Add missing Aggregate object tests

This file was not properly git-add'd to commit:

  f2252de974e1bf3b40f8dce0e768597e31ac2a05

Related to blueprint compute-api-objects

Change-Id: Ibd25f4479d49f456bcb49e3eb003edf3d4b2b334
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/44966/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/objects/test_aggregate.py'],1,2406f31b51fc30a9c8cfe7e9987a8d3061b5a39e,bp/compute-api-objects,"# Copyright 2013 IBM Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime from nova import db from nova import exception from nova.objects import aggregate from nova.openstack.common import timeutils from nova.tests.objects import test_objects NOW = timeutils.utcnow().replace(microsecond=0) fake_aggregate = { 'created_at': NOW, 'updated_at': None, 'deleted_at': None, 'deleted': False, 'id': 123, 'name': 'fake-aggregate', 'hosts': ['foo', 'bar'], 'metadetails': {'this': 'that'}, } def compare(obj, db_obj): for key in obj.fields: obj_val = obj[key] if isinstance(obj_val, datetime.datetime): obj_val = obj_val.replace(tzinfo=None) if key == 'metadata': key = 'metadetails' db_val = db_obj[key] assert db_val == obj_val, '%s != %s' % (db_val, obj_val) class _TestAggregateObject(object): def test_get_by_id(self): self.mox.StubOutWithMock(db, 'aggregate_get') db.aggregate_get(self.context, 123).AndReturn(fake_aggregate) self.mox.ReplayAll() agg = aggregate.Aggregate.get_by_id(self.context, 123) compare(agg, fake_aggregate) def test_create(self): self.mox.StubOutWithMock(db, 'aggregate_create') db.aggregate_create(self.context, {'name': 'foo'}, metadata={'one': 'two'}).AndReturn(fake_aggregate) self.mox.ReplayAll() agg = aggregate.Aggregate() agg.name = 'foo' agg.metadata = {'one': 'two'} agg.create(self.context) compare(agg, fake_aggregate) def test_save(self): self.mox.StubOutWithMock(db, 'aggregate_update') db.aggregate_update(self.context, 123, {'name': 'baz'}).AndReturn( fake_aggregate) self.mox.ReplayAll() agg = aggregate.Aggregate() agg.id = 123 agg.name = 'baz' agg.save(self.context) compare(agg, fake_aggregate) def test_save_and_create_no_hosts(self): agg = aggregate.Aggregate() agg.id = 123 agg.hosts = ['foo', 'bar'] self.assertRaises(exception.ObjectActionError, agg.create, self.context) self.assertRaises(exception.ObjectActionError, agg.save, self.context) def test_update_metadata(self): self.mox.StubOutWithMock(db, 'aggregate_metadata_delete') self.mox.StubOutWithMock(db, 'aggregate_metadata_add') db.aggregate_metadata_delete(self.context, 123, 'todelete') db.aggregate_metadata_add(self.context, 123, {'toadd': 'myval'}) self.mox.ReplayAll() agg = aggregate.Aggregate() agg._context = self.context agg.id = 123 agg.metadata = {'foo': 'bar'} agg.obj_reset_changes() agg.update_metadata({'todelete': None, 'toadd': 'myval'}) self.assertEqual({'foo': 'bar', 'toadd': 'myval'}, agg.metadata) def test_destroy(self): self.mox.StubOutWithMock(db, 'aggregate_delete') db.aggregate_delete(self.context, 123) self.mox.ReplayAll() agg = aggregate.Aggregate() agg.id = 123 agg.destroy(self.context) def test_add_host(self): self.mox.StubOutWithMock(db, 'aggregate_host_add') db.aggregate_host_add(self.context, 123, 'bar' ).AndReturn({'host': 'bar'}) self.mox.ReplayAll() agg = aggregate.Aggregate() agg.id = 123 agg.hosts = ['foo'] agg._context = self.context agg.add_host('bar') self.assertEqual(agg.hosts, ['foo', 'bar']) def test_delete_host(self): self.mox.StubOutWithMock(db, 'aggregate_host_delete') db.aggregate_host_delete(self.context, 123, 'foo') self.mox.ReplayAll() agg = aggregate.Aggregate() agg.id = 123 agg.hosts = ['foo', 'bar'] agg._context = self.context agg.delete_host('foo') self.assertEqual(agg.hosts, ['bar']) def test_availability_zone(self): agg = aggregate.Aggregate() agg.metadata = {'availability_zone': 'foo'} self.assertEqual('foo', agg.availability_zone) def test_get_all(self): self.mox.StubOutWithMock(db, 'aggregate_get_all') db.aggregate_get_all(self.context).AndReturn([fake_aggregate]) self.mox.ReplayAll() aggs = aggregate.AggregateList.get_all(self.context) self.assertEqual(1, len(aggs)) compare(aggs[0], fake_aggregate) def test_by_host(self): self.mox.StubOutWithMock(db, 'aggregate_get_by_host') db.aggregate_get_by_host(self.context, 'fake-host' ).AndReturn([fake_aggregate]) self.mox.ReplayAll() aggs = aggregate.AggregateList.get_by_host(self.context, 'fake-host') self.assertEqual(1, len(aggs)) compare(aggs[0], fake_aggregate) class TestAggregateObject(test_objects._LocalTest, _TestAggregateObject): pass class TestRemoteAggregateObject(test_objects._RemoteTest, _TestAggregateObject): pass ",,162,0
openstack%2Fnova~master~Ic910f39087ebc167b2b930979f7951116caf8598,openstack/nova,master,Ic910f39087ebc167b2b930979f7951116caf8598,Generalize the _make_list() function for objects,MERGED,2013-08-26 18:55:23.000000000,2013-09-05 05:54:55.000000000,2013-09-05 05:54:52.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5652}, {'_account_id': 6873}, {'_account_id': 7629}]","[{'number': 1, 'created': '2013-08-26 18:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc886cc3aed4720cebec1ca8df4f404af8b75c82', 'message': 'Generalize the _make_list() function for objects\n\nEach object with a list duplicated the _make_list() method in its\nown module. This removes that duplication and adds a generalized\nhelper in objects/base.py. The instance object still uses its own\nbecause it has to do a bunch of other stuff in the loop for\nefficiency.\n\nChange-Id: Ic910f39087ebc167b2b930979f7951116caf8598\n'}, {'number': 2, 'created': '2013-08-29 16:31:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e00efe92b3b3592b39df8a3670846639a647ac83', 'message': 'Generalize the _make_list() function for objects\n\nEach object with a list duplicated the _make_list() method in its\nown module. This removes that duplication and adds a generalized\nhelper in objects/base.py. The instance object still uses its own\nbecause it has to do a bunch of other stuff in the loop for\nefficiency.\n\nChange-Id: Ic910f39087ebc167b2b930979f7951116caf8598\n'}, {'number': 3, 'created': '2013-08-29 20:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a57b0c88d6c64b339f8c8dc57bf2eee57e0f3bc', 'message': 'Generalize the _make_list() function for objects\n\nEach object with a list duplicated the _make_list() method in its\nown module. This removes that duplication and adds a generalized\nhelper in objects/base.py. The instance object still uses its own\nbecause it has to do a bunch of other stuff in the loop for\nefficiency.\n\nChange-Id: Ic910f39087ebc167b2b930979f7951116caf8598\n'}, {'number': 4, 'created': '2013-09-03 20:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86fd6158f2baaad7a775414219f40cf2bfa1ff74', 'message': 'Generalize the _make_list() function for objects\n\nEach object with a list duplicated the _make_list() method in its\nown module. This removes that duplication and adds a generalized\nhelper in objects/base.py. The instance object still uses its own\nbecause it has to do a bunch of other stuff in the loop for\nefficiency.\n\nChange-Id: Ic910f39087ebc167b2b930979f7951116caf8598\n'}, {'number': 5, 'created': '2013-09-04 21:32:54.000000000', 'files': ['nova/objects/base.py', 'nova/compute/cells_api.py', 'nova/objects/compute_node.py', 'nova/objects/service.py', 'nova/tests/objects/test_objects.py', 'nova/objects/keypair.py', 'nova/objects/aggregate.py', 'nova/objects/instance_action.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ee600da2b6f57a51b6830a5e8fa5b29cd1f877c8', 'message': 'Generalize the _make_list() function for objects\n\nEach object with a list duplicated the _make_list() method in its\nown module. This removes that duplication and adds a generalized\nhelper in objects/base.py. The instance object still uses its own\nbecause it has to do a bunch of other stuff in the loop for\nefficiency.\n\nChange-Id: Ic910f39087ebc167b2b930979f7951116caf8598\n'}]",0,43754,ee600da2b6f57a51b6830a5e8fa5b29cd1f877c8,30,10,5,4393,,,0,"Generalize the _make_list() function for objects

Each object with a list duplicated the _make_list() method in its
own module. This removes that duplication and adds a generalized
helper in objects/base.py. The instance object still uses its own
because it has to do a bunch of other stuff in the loop for
efficiency.

Change-Id: Ic910f39087ebc167b2b930979f7951116caf8598
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/43754/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/compute/cells_api.py', 'nova/objects/compute_node.py', 'nova/objects/service.py', 'nova/tests/objects/test_objects.py', 'nova/objects/keypair.py', 'nova/objects/aggregate.py', 'nova/objects/instance_action.py']",8,fc886cc3aed4720cebec1ca8df4f404af8b75c82,bp/compute-api-objects," return base.obj_make_list(context, cls(), InstanceAction, db_actions) return base.obj_make_list(context, cls(), InstanceActionEvent, db_events)","def _make_list(context, list_obj, item_cls, db_list): list_obj.objects = [] for db_item in db_list: item = item_cls._from_db_object(context, item_cls(), db_item) list_obj.objects.append(item) list_obj.obj_reset_changes() return list_obj return _make_list(context, cls(), InstanceAction, db_actions) return _make_list(context, cls(), InstanceActionEvent, db_events)",63,56
openstack%2Ftempest~master~I56c6d5a21a36cf052d3bde86c454d7be72b22a7c,openstack/tempest,master,I56c6d5a21a36cf052d3bde86c454d7be72b22a7c,refactor - _is_timed_out using instance timeout,MERGED,2013-08-23 11:08:49.000000000,2013-09-05 05:54:48.000000000,2013-09-05 05:54:48.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5044}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-08-23 11:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ee54470b7b326b8e559016b9444454e7bd31e593', 'message': 'refactor - _is_timed_out using instance timeout\n\nEach _is_timed_out client specified self.timeout as timeout parameter.\nAs _is_timed_out is an instance method, timeout parameter could be\nretrieved from the object itself.\n\nChange-Id: I56c6d5a21a36cf052d3bde86c454d7be72b22a7c\n'}, {'number': 2, 'created': '2013-08-23 12:53:36.000000000', 'files': ['tempest/common/ssh.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c3f8cd671685e3b985112c9460e700015c2aac49', 'message': 'refactor - _is_timed_out using instance timeout\n\nEach _is_timed_out client specified self.timeout as timeout parameter.\nAs _is_timed_out is an instance method, timeout parameter could be\nretrieved from the object itself.\n\nChange-Id: I56c6d5a21a36cf052d3bde86c454d7be72b22a7c\n'}]",0,43434,c3f8cd671685e3b985112c9460e700015c2aac49,9,5,2,5044,,,0,"refactor - _is_timed_out using instance timeout

Each _is_timed_out client specified self.timeout as timeout parameter.
As _is_timed_out is an instance method, timeout parameter could be
retrieved from the object itself.

Change-Id: I56c6d5a21a36cf052d3bde86c454d7be72b22a7c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/34/43434/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/ssh.py'],1,ee54470b7b326b8e559016b9444454e7bd31e593,fix-ssh," while not self._is_timed_out(_start_time): def _is_timed_out(self, start_time): return (time.time() - self.timeout) > start_time _timed_out = self._is_timed_out(_start_time) _timed_out = self._is_timed_out(_start_time) if not self._is_timed_out(start_time)"," while not self._is_timed_out(self.timeout, _start_time): def _is_timed_out(self, timeout, start_time): return (time.time() - timeout) > start_time _timed_out = self._is_timed_out(self.timeout, _start_time) _timed_out = self._is_timed_out(self.timeout, _start_time) if not self._is_timed_out(self.timeout, start_time)",6,6
openstack%2Ftempest~master~I259f4202978ac20d341349d1d227c6ef14c31d9b,openstack/tempest,master,I259f4202978ac20d341349d1d227c6ef14c31d9b,fix test_flavors_extra_specs failure,MERGED,2013-09-03 06:02:59.000000000,2013-09-05 05:23:23.000000000,2013-09-05 05:23:22.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 7139}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-09-03 06:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4862df667fa54646bee7cbbe038560ed073ed81b', 'message': 'fix test_flavors_extra_specs failure\n\ntempest.api.compute.admin.test_flavors_extra_specs.FlavorsExtraSpecsTestXML\nfailed due to test_flavor2 already exists\n\nFixing Bug 1220034\n\nChange-Id: I259f4202978ac20d341349d1d227c6ef14c31d9b\n'}, {'number': 2, 'created': '2013-09-03 06:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/471d4a0c2905726fcb81425c3e9fd348a9a067e1', 'message': 'fix test_flavors_extra_specs failure\n\ntempest.api.compute.admin.test_flavors_extra_specs.FlavorsExtraSpecsTestXML\nfailed due to test_flavor2 already exists\n\nFixing Bug 1220034\n\nChange-Id: I259f4202978ac20d341349d1d227c6ef14c31d9b\n'}, {'number': 3, 'created': '2013-09-03 07:04:07.000000000', 'files': ['tempest/api/compute/admin/test_flavors_extra_specs.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/58febcc6eb34ac7318b928037cc90576bf24fcbc', 'message': 'fix test_flavors_extra_specs failure\n\ntempest.api.compute.admin.test_flavors_extra_specs.FlavorsExtraSpecsTestXML\nfailed due to test_flavor2 already exists\n\nFixing Bug 1220034\n\nChange-Id: I259f4202978ac20d341349d1d227c6ef14c31d9b\n'}]",0,44797,58febcc6eb34ac7318b928037cc90576bf24fcbc,10,5,3,7139,,,0,"fix test_flavors_extra_specs failure

tempest.api.compute.admin.test_flavors_extra_specs.FlavorsExtraSpecsTestXML
failed due to test_flavor2 already exists

Fixing Bug 1220034

Change-Id: I259f4202978ac20d341349d1d227c6ef14c31d9b
",git fetch https://review.opendev.org/openstack/tempest refs/changes/97/44797/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/admin/test_flavors_extra_specs.py', 'tempest/services/compute/json/flavors_client.py']",2,4862df667fa54646bee7cbbe038560ed073ed81b,bug/1220034," def is_resource_deleted(self, id): # Did not use get_flavor_details(id) for verification as it gives # 200 ok even for deleted id. LP #981263 # we can remove the loop here and use get by ID when bug gets sortedout resp, flavors = self.list_flavors_with_detail() for flavor in flavors: if flavor['id'] == id: return False return True ",,12,0
openstack%2Fpuppet-neutron~master~I525a9fceb7b86b3a1443f8c9a1a8ee4daf546e50,openstack/puppet-neutron,master,I525a9fceb7b86b3a1443f8c9a1a8ee4daf546e50,Add syslog support to the neutron module,MERGED,2013-09-04 12:59:10.000000000,2013-09-05 05:17:13.000000000,2013-09-05 05:17:12.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 4128}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-09-04 12:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/da5a5e2b2951faa60e6c847f0e46459a16deb8d2', 'message': 'Add syslog support to the neutron module\n\nChange-Id: I525a9fceb7b86b3a1443f8c9a1a8ee4daf546e50\n'}, {'number': 2, 'created': '2013-09-04 13:22:50.000000000', 'files': ['spec/classes/neutron_init_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/18f1cfcc636bb95b931d42bc8c8ed1223c10f60d', 'message': 'Add syslog support to the neutron module\n\nChange-Id: I525a9fceb7b86b3a1443f8c9a1a8ee4daf546e50\n'}]",0,45056,18f1cfcc636bb95b931d42bc8c8ed1223c10f60d,10,4,2,4128,,,0,"Add syslog support to the neutron module

Change-Id: I525a9fceb7b86b3a1443f8c9a1a8ee4daf546e50
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/56/45056/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_init_spec.rb', 'manifests/init.pp']",2,da5a5e2b2951faa60e6c847f0e46459a16deb8d2,,"# [*use_syslog*] # (optional) Use syslog for logging # Defaults to false # # [*syslog_facility*] # (optional) Syslog facility to receive log lines # Defaults to LOG_USER # $qpid_reconnect_interval = 0, $use_syslog = false, $syslog_facility = 'LOG_USER', if $use_syslog { neutron_config { 'DEFAULT/use_syslog': value => true; 'DEFAULT/syslog_log_facility': value => $syslog_facility; } } else { neutron_config { 'DEFAULT/use_syslog': value => false; } }", $qpid_reconnect_interval = 0,56,1
openstack%2Fpuppet-glance~stable%2Fgrizzly~Ibe3a22a996016d1a80efb69fd7d401d1834d011b,openstack/puppet-glance,stable/grizzly,Ibe3a22a996016d1a80efb69fd7d401d1834d011b,Add syslog support to the glance module,MERGED,2013-09-04 12:31:57.000000000,2013-09-05 05:16:40.000000000,2013-09-05 05:16:40.000000000,"[{'_account_id': 3}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-09-04 12:31:57.000000000', 'files': ['manifests/registry.pp', 'manifests/api.pp', 'spec/classes/glance_registry_spec.rb', 'spec/classes/glance_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/6b0bdd0dd2be954cfa9db95f49884fc3f95ae89e', 'message': 'Add syslog support to the glance module\n\nChange-Id: Ibe3a22a996016d1a80efb69fd7d401d1834d011b\n(cherry picked from commit a79c1916813087f720946d0e153d9558d9f0a828)\n'}]",0,45047,6b0bdd0dd2be954cfa9db95f49884fc3f95ae89e,6,2,1,4128,,,0,"Add syslog support to the glance module

Change-Id: Ibe3a22a996016d1a80efb69fd7d401d1834d011b
(cherry picked from commit a79c1916813087f720946d0e153d9558d9f0a828)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/47/45047/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/registry.pp', 'manifests/api.pp', 'spec/classes/glance_api_spec.rb', 'spec/classes/glance_registry_spec.rb']",4,6b0bdd0dd2be954cfa9db95f49884fc3f95ae89e,grizzly," describe 'with syslog disabled by default' do let :params do default_params end it { should contain_glance_registry_config('DEFAULT/use_syslog').with_value(false) } it { should_not contain_glance_registry_config('DEFAULT/syslog_log_facility') } end describe 'with syslog enabled' do let :params do default_params.merge({ :use_syslog => 'true', }) end it { should contain_glance_registry_config('DEFAULT/use_syslog').with_value(true) } it { should contain_glance_registry_config('DEFAULT/syslog_log_facility').with_value('LOG_USER') } end describe 'with syslog enabled and custom settings' do let :params do default_params.merge({ :use_syslog => 'true', :log_facility => 'LOG_LOCAL0' }) end it { should contain_glance_registry_config('DEFAULT/use_syslog').with_value(true) } it { should contain_glance_registry_config('DEFAULT/syslog_log_facility').with_value('LOG_LOCAL0') } end ",,105,1
openstack%2Fpuppet-keystone~stable%2Fgrizzly~I64a1959b88f1a5d7a8ce96bd1a0dbab2e9723a00,openstack/puppet-keystone,stable/grizzly,I64a1959b88f1a5d7a8ce96bd1a0dbab2e9723a00,Add syslog support to the keystone module,MERGED,2013-09-04 13:29:37.000000000,2013-09-05 05:16:29.000000000,2013-09-05 05:16:29.000000000,"[{'_account_id': 3}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-09-04 13:29:37.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/900e9b9649eba548eadf8fcbe37866d89c675e47', 'message': 'Add syslog support to the keystone module\n\nChange-Id: I64a1959b88f1a5d7a8ce96bd1a0dbab2e9723a00\n(cherry picked from commit 64474d170d5f7b38d4a221d1ade6009f44147c79)\n'}]",0,45058,900e9b9649eba548eadf8fcbe37866d89c675e47,6,2,1,4128,,,0,"Add syslog support to the keystone module

Change-Id: I64a1959b88f1a5d7a8ce96bd1a0dbab2e9723a00
(cherry picked from commit 64474d170d5f7b38d4a221d1ade6009f44147c79)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/58/45058/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_spec.rb', 'manifests/init.pp']",2,900e9b9649eba548eadf8fcbe37866d89c675e47,grizzly,"# [use_syslog] Use syslog for logging. Optional.# [log_facility] Syslog facility to receive log lines. Optional. $log_facility = 'LOG_USER', # Syslog configuration if $use_syslog { keystone_config { 'DEFAULT/use_syslog': value => true; 'DEFAULT/syslog_log_facility': value => $log_facility; } } else { keystone_config { 'DEFAULT/use_syslog': value => false; } }",# [use_syslog] Rather or not keystone should log to syslog. Optional. # TODO implement syslog features if ( $use_syslog != false) { fail('use syslog currently only accepts false') } ,48,7
openstack%2Fpuppet-nova~stable%2Fgrizzly~Ife82ad19e06c267b5dfe223583d86333e93015fc,openstack/puppet-nova,stable/grizzly,Ife82ad19e06c267b5dfe223583d86333e93015fc,Add syslog support to the nova module,MERGED,2013-09-04 12:31:39.000000000,2013-09-05 05:16:25.000000000,2013-09-05 05:16:25.000000000,"[{'_account_id': 3}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-09-04 12:31:39.000000000', 'files': ['manifests/init.pp', 'spec/classes/nova_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/c9f2f7dc92e47aa064d205fa1a6d84c7a3c3eafd', 'message': 'Add syslog support to the nova module\n\nChange-Id: Ife82ad19e06c267b5dfe223583d86333e93015fc\n(cherry picked from commit a3cadd09e70f560b78d2dbd20a4ca6c187fe1531)\n'}]",0,45045,c9f2f7dc92e47aa064d205fa1a6d84c7a3c3eafd,6,2,1,4128,,,0,"Add syslog support to the nova module

Change-Id: Ife82ad19e06c267b5dfe223583d86333e93015fc
(cherry picked from commit a3cadd09e70f560b78d2dbd20a4ca6c187fe1531)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/45/45045/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/nova_init_spec.rb']",2,c9f2f7dc92e47aa064d205fa1a6d84c7a3c3eafd,grizzly," describe 'with syslog disabled' do it { should contain_nova_config('DEFAULT/use_syslog').with_value(false) } end describe 'with syslog enabled' do let :params do { :use_syslog => 'true', } end it { should contain_nova_config('DEFAULT/use_syslog').with_value(true) } it { should contain_nova_config('DEFAULT/syslog_log_facility').with_value('LOG_USER') } end describe 'with syslog enabled and custom settings' do let :params do { :use_syslog => 'true', :log_facility => 'LOG_LOCAL0' } end it { should contain_nova_config('DEFAULT/use_syslog').with_value(true) } it { should contain_nova_config('DEFAULT/syslog_log_facility').with_value('LOG_LOCAL0') } end ",,45,1
openstack%2Fpuppet-cinder~stable%2Fgrizzly~I6e974fddfb77901827ca06bab18250529f970bae,openstack/puppet-cinder,stable/grizzly,I6e974fddfb77901827ca06bab18250529f970bae,Add syslog support to cinder module,MERGED,2013-09-04 11:54:16.000000000,2013-09-05 05:15:09.000000000,2013-09-05 05:15:09.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-09-04 11:54:16.000000000', 'files': ['manifests/init.pp', 'spec/classes/cinder_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/4825b71934af737c0ad99b43272ccda86faa1fcd', 'message': 'Add syslog support to cinder module\n\nChange-Id: I6e974fddfb77901827ca06bab18250529f970bae\n(cherry picked from commit 9bd451830d124703ab4b50dcab10e0a697c85ad6)\n'}]",0,45037,4825b71934af737c0ad99b43272ccda86faa1fcd,7,3,1,4128,,,0,"Add syslog support to cinder module

Change-Id: I6e974fddfb77901827ca06bab18250529f970bae
(cherry picked from commit 9bd451830d124703ab4b50dcab10e0a697c85ad6)
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/37/45037/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/cinder_spec.rb']",2,4825b71934af737c0ad99b43272ccda86faa1fcd,grizzly," describe 'with syslog disabled' do let :params do req_params end it { should contain_cinder_config('DEFAULT/use_syslog').with_value(false) } end describe 'with syslog enabled' do let :params do req_params.merge({ :use_syslog => 'true', }) end it { should contain_cinder_config('DEFAULT/use_syslog').with_value(true) } it { should contain_cinder_config('DEFAULT/syslog_log_facility').with_value('LOG_USER') } end describe 'with syslog enabled and custom settings' do let :params do req_params.merge({ :use_syslog => 'true', :log_facility => 'LOG_LOCAL0' }) end it { should contain_cinder_config('DEFAULT/use_syslog').with_value(true) } it { should contain_cinder_config('DEFAULT/syslog_log_facility').with_value('LOG_LOCAL0') } end ",,51,0
openstack%2Fpuppet-ceilometer~master~I0feb52f7a9140ea750254f80b6a3e6855b25f1d3,openstack/puppet-ceilometer,master,I0feb52f7a9140ea750254f80b6a3e6855b25f1d3,Add default auth_uri setting for auth token.,MERGED,2013-08-29 14:42:13.000000000,2013-09-05 05:14:15.000000000,2013-09-05 05:14:15.000000000,"[{'_account_id': 3}, {'_account_id': 5241}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-08-29 14:42:13.000000000', 'files': ['manifests/api.pp', 'spec/classes/ceilometer_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/17711d8230432a883753b2f2ebece4fb1cf7ab16', 'message': ""Add default auth_uri setting for auth token.\n\nThe latest keystoneclient code now gives a Warning if auth_uri\nisn't explicitly specified.\n\nChange-Id: I0feb52f7a9140ea750254f80b6a3e6855b25f1d3\n""}]",0,44296,17711d8230432a883753b2f2ebece4fb1cf7ab16,7,3,1,360,,,0,"Add default auth_uri setting for auth token.

The latest keystoneclient code now gives a Warning if auth_uri
isn't explicitly specified.

Change-Id: I0feb52f7a9140ea750254f80b6a3e6855b25f1d3
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/96/44296/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/api.pp', 'spec/classes/ceilometer_api_spec.rb']",2,17711d8230432a883753b2f2ebece4fb1cf7ab16,auth_uri," should contain_ceilometer_config('keystone_authtoken/auth_uri').with_value( params[:keystone_protocol] + ""://"" + params[:keystone_host] + "":5000/"" ) describe 'with custom auth_uri' do let :facts do { :osfamily => 'RedHat' } end before do params.merge!({ :keystone_auth_uri => 'https://foo.bar:1234/', }) end it 'should configure custom auth_uri correctly' do should contain_ceilometer_config('keystone_authtoken/auth_uri').with_value( 'https://foo.bar:1234/' ) end end ",,27,0
openstack%2Ftempest~master~Ib914ffe4b45b96276b4f1f20d3e9828d04958d14,openstack/tempest,master,Ib914ffe4b45b96276b4f1f20d3e9828d04958d14,Add tests for Swift's StaticWeb middelware,MERGED,2013-09-03 09:31:00.000000000,2013-09-05 04:50:52.000000000,2013-09-05 04:50:51.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 6847}, {'_account_id': 6889}]","[{'number': 1, 'created': '2013-09-03 09:31:00.000000000', 'files': ['tempest/api/object_storage/test_container_staticweb.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b06cf45897fbe09f4b98f6e916f27a504af513e5', 'message': ""Add tests for Swift's StaticWeb middelware\n\nCreates the tests in a new file and test 2 headers:\n + web-index\n + web-listings\n\nblueprint test-swift-staticweb-middelware\nChange-Id: Ib914ffe4b45b96276b4f1f20d3e9828d04958d14\n""}]",0,44826,b06cf45897fbe09f4b98f6e916f27a504af513e5,6,5,1,7020,,,0,"Add tests for Swift's StaticWeb middelware

Creates the tests in a new file and test 2 headers:
 + web-index
 + web-listings

blueprint test-swift-staticweb-middelware
Change-Id: Ib914ffe4b45b96276b4f1f20d3e9828d04958d14
",git fetch https://review.opendev.org/openstack/tempest refs/changes/26/44826/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/object_storage/test_container_staticweb.py'],1,b06cf45897fbe09f4b98f6e916f27a504af513e5,bp/test-swift-staticweb-middelware,"# Copyright (C) 2013 eNovance SAS <licensing@enovance.com> # # Author: Joe H. Rahme <joe.hakim.rahme@enovance.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.api.object_storage import base from tempest.common.utils.data_utils import arbitrary_string from tempest.common.utils.data_utils import rand_name from tempest.test import attr class StaticWebTest(base.BaseObjectTest): @classmethod def setUpClass(cls): super(StaticWebTest, cls).setUpClass() cls.container_name = rand_name(name=""TestContainer"") # This header should be posted on the container before every test cls.headers_public_read_acl = {'Read': '.r:*'} # Create test container and create one object in it cls.container_client.create_container(cls.container_name) cls.object_name = rand_name(name=""TestObject"") cls.object_data = arbitrary_string() cls.object_client.create_object(cls.container_name, cls.object_name, cls.object_data) cls.container_client.update_container_metadata( cls.container_name, metadata=cls.headers_public_read_acl, metadata_prefix=""X-Container-"") @classmethod def tearDownClass(cls): cls.delete_containers([cls.container_name]) cls.data.teardown_all() super(StaticWebTest, cls).tearDownClass() @attr('gate') def test_web_index(self): headers = {'web-index': self.object_name} self.container_client.update_container_metadata( self.container_name, metadata=headers) # test GET on http://account_url/container_name # we should retrieve the self.object_name file resp, body = self.custom_account_client.request(""GET"", self.container_name) self.assertEqual(resp['status'], '200') self.assertEqual(body, self.object_data) # clean up before exiting self.container_client.update_container_metadata(self.container_name, {'web-index': """"}) _, body = self.container_client.list_container_metadata( self.container_name) self.assertNotIn('x-container-meta-web-index', body) @attr('gate') def test_web_listing(self): headers = {'web-listings': 'true'} self.container_client.update_container_metadata( self.container_name, metadata=headers) # test GET on http://account_url/container_name # we should retrieve a listing of objects resp, body = self.custom_account_client.request(""GET"", self.container_name) self.assertEqual(resp['status'], '200') self.assertIn(self.object_name, body) # clean up before exiting self.container_client.update_container_metadata(self.container_name, {'web-listings': """"}) _, body = self.container_client.list_container_metadata( self.container_name) self.assertNotIn('x-container-meta-web-listings', body) ",,94,0
openstack%2Fnova~master~Ic2104ddda759dbfb3f352b547b417c910d75d9db,openstack/nova,master,Ic2104ddda759dbfb3f352b547b417c910d75d9db,VMware: Nova boot from cinder volume,MERGED,2013-08-12 11:49:43.000000000,2013-09-05 04:50:24.000000000,2013-09-05 04:50:21.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5638}, {'_account_id': 7400}, {'_account_id': 7629}]","[{'number': 1, 'created': '2013-08-12 11:49:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/35d6963091dfb55a02b4060775c79ab957729870', 'message': 'VMware: Nova boot from cinder volume\n\nPart of blueprint vmware-nova-cinder-support\n\nThis patch adds support for booting from a cinder volume.\n\nChange-Id: Ic2104ddda759dbfb3f352b547b417c910d75d9db\n'}, {'number': 2, 'created': '2013-08-20 11:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f943b7d4d8532491c58579af5506983a5eb8ddf9', 'message': 'VMware: Nova boot from cinder volume\n\nPart of blueprint vmware-nova-cinder-support\n\nThis patch adds support for booting from a cinder volume.\n\nChange-Id: Ic2104ddda759dbfb3f352b547b417c910d75d9db\n'}, {'number': 3, 'created': '2013-08-20 11:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9578b818edc8dbae62f697e670b782ffb850293f', 'message': 'VMware: Nova boot from cinder volume\n\nPart of blueprint vmware-nova-cinder-support\n\nThis patch adds support for booting from a cinder volume.\n\nChange-Id: Ic2104ddda759dbfb3f352b547b417c910d75d9db\n'}, {'number': 4, 'created': '2013-09-01 13:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f88a58b900dd1433ffa88478e76c96c5ae855132', 'message': 'VMware: Nova boot from cinder volume\n\nPart of blueprint vmware-nova-cinder-support\n\nThis patch adds support for booting from a cinder volume.\n\nChange-Id: Ic2104ddda759dbfb3f352b547b417c910d75d9db\n'}, {'number': 5, 'created': '2013-09-01 13:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c9689c5547d41d8cf1316006ef86fb32bb816898', 'message': 'VMware: Nova boot from cinder volume\n\nPart of blueprint vmware-nova-cinder-support\n\nThis patch adds support for booting from a cinder volume.\n\nChange-Id: Ic2104ddda759dbfb3f352b547b417c910d75d9db\n'}, {'number': 6, 'created': '2013-09-01 13:12:17.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/virt/vmwareapi/volumeops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b97072ab9bd6d4ebc2c0d7eb9b6db65e4087bd4f', 'message': 'VMware: Nova boot from cinder volume\n\nPart of blueprint vmware-nova-cinder-support\n\nThis patch adds support for booting from a cinder volume.\n\nChange-Id: Ic2104ddda759dbfb3f352b547b417c910d75d9db\n'}]",5,41387,b97072ab9bd6d4ebc2c0d7eb9b6db65e4087bd4f,41,9,6,1653,,,0,"VMware: Nova boot from cinder volume

Part of blueprint vmware-nova-cinder-support

This patch adds support for booting from a cinder volume.

Change-Id: Ic2104ddda759dbfb3f352b547b417c910d75d9db
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/41387/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/virt/vmwareapi/volumeops.py']",3,35d6963091dfb55a02b4060775c79ab957729870,bp/qemu-assisted-snapshots," In the case of a volume boot the we need to ensure that the volume is on the datastore of the instance. def _get_vmdk_backed_disk_device(self, vm_ref, data): return device def _detach_volume_vmdk(self, connection_info, instance, mountpoint): """"""Detach volume storage to VM instance."""""" instance_name = instance['name'] vm_ref = vm_util.get_vm_ref(self._session, instance) # Detach Volume from VM LOG.debug(_(""Detach_volume: %(instance_name)s, %(mountpoint)s""), {'mountpoint': mountpoint, 'instance_name': instance_name}) data = connection_info['data'] device = self._get_vmdk_backed_disk_device(vm_ref, data) def attach_root_volume(self, connection_info, instance, mountpoint): """"""Attach a root volume to the VM instance."""""" driver_type = connection_info['driver_volume_type'] LOG.debug(_(""Root volume attach. Driver type: %s""), driver_type, instance=instance) if driver_type == 'vmdk': vm_ref = vm_util.get_vm_ref(self._session, instance) data = connection_info['data'] device = self._get_vmdk_backed_disk_device(vm_ref, data) # Get the volume ref volume_ref = self._get_volume_ref(data['volume']) self._consolidate_vmdk_volume(instance, vm_ref, device, volume_ref) self.attach_volume(connection_info, instance, mountpoint)"," def _detach_volume_vmdk(self, connection_info, instance, mountpoint): """"""Detach volume storage to VM instance."""""" instance_name = instance['name'] vm_ref = vm_util.get_vm_ref(self._session, instance) # Detach Volume from VM LOG.debug(_(""Detach_volume: %(instance_name)s, %(mountpoint)s""), {'mountpoint': mountpoint, 'instance_name': instance_name}) data = connection_info['data'] ",91,11
openstack%2Ftempest~master~Ic439cdf6b8ff99c7b13efc849afb92b4b0865392,openstack/tempest,master,Ic439cdf6b8ff99c7b13efc849afb92b4b0865392,add flavor creation tests,MERGED,2013-09-02 16:40:07.000000000,2013-09-05 04:47:57.000000000,2013-09-05 04:47:57.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5689}]","[{'number': 1, 'created': '2013-09-02 16:40:07.000000000', 'files': ['tempest/api/compute/admin/test_flavors.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/20f1322a2c79d4ade1df728500967a7ce9e43ebc', 'message': 'add flavor creation tests\n\n1. verify that it can deal with string ram parameter\n2. make sure it can detect invalid ram and vcpus\n\nChange-Id: Ic439cdf6b8ff99c7b13efc849afb92b4b0865392\n'}]",0,44746,20f1322a2c79d4ade1df728500967a7ce9e43ebc,7,4,1,7139,,,0,"add flavor creation tests

1. verify that it can deal with string ram parameter
2. make sure it can detect invalid ram and vcpus

Change-Id: Ic439cdf6b8ff99c7b13efc849afb92b4b0865392
",git fetch https://review.opendev.org/openstack/tempest refs/changes/46/44746/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_flavors.py'],1,20f1322a2c79d4ade1df728500967a7ce9e43ebc,flavors-test," @attr(type='gate') def test_create_flavor_using_string_ram(self): flavor_name = rand_name(self.flavor_name_prefix) new_flavor_id = rand_int_id(start=1000) ram = "" 1024 "" resp, flavor = self.client.create_flavor(flavor_name, ram, self.vcpus, self.disk, new_flavor_id) self.addCleanup(self.flavor_clean_up, flavor['id']) self.assertEqual(200, resp.status) self.assertEqual(flavor['name'], flavor_name) self.assertEqual(flavor['vcpus'], self.vcpus) self.assertEqual(flavor['disk'], self.disk) self.assertEqual(flavor['ram'], int(ram)) self.assertEqual(int(flavor['id']), new_flavor_id) @attr(type=['negative', 'gate']) def test_create_flavor_using_invalid_ram(self): flavor_name = rand_name(self.flavor_name_prefix) new_flavor_id = rand_int_id(start=1000) self.assertRaises(exceptions.BadRequest, self.client.create_flavor, flavor_name, -1, self.vcpus, self.disk, new_flavor_id) @attr(type=['negative', 'gate']) def test_create_flavor_using_invalid_vcpus(self): flavor_name = rand_name(self.flavor_name_prefix) new_flavor_id = rand_int_id(start=1000) self.assertRaises(exceptions.BadRequest, self.client.create_flavor, flavor_name, self.ram, 0, self.disk, new_flavor_id) ",,38,0
openstack%2Fnova~master~I749204d7d6461993d0c42bf5877b65c5ec17c62f,openstack/nova,master,I749204d7d6461993d0c42bf5877b65c5ec17c62f,Remove _report_driver_status from compute/manager.py,MERGED,2013-09-02 13:08:24.000000000,2013-09-05 03:53:53.000000000,2013-09-05 03:53:51.000000000,"[{'_account_id': 3}, {'_account_id': 1313}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 7494}, {'_account_id': 8495}]","[{'number': 1, 'created': '2013-09-02 13:08:24.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/680cc7becc38178f47e13b3aa11c8544b1949de7', 'message': 'Remove _report_driver_status from compute/manager.py\n\nAfter the blueprint no-compute-fanout-to-scheduler, there is no\nneed for nova compute to fanout its capabilities to nova scheduler,\nso we can remove _report_driver_status as it is no use now.\n\nChange-Id: I749204d7d6461993d0c42bf5877b65c5ec17c62f\n'}]",0,44699,680cc7becc38178f47e13b3aa11c8544b1949de7,13,7,1,8495,,,0,"Remove _report_driver_status from compute/manager.py

After the blueprint no-compute-fanout-to-scheduler, there is no
need for nova compute to fanout its capabilities to nova scheduler,
so we can remove _report_driver_status as it is no use now.

Change-Id: I749204d7d6461993d0c42bf5877b65c5ec17c62f
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/44699/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,680cc7becc38178f47e13b3aa11c8544b1949de7,bp/no-compute-fanout-to-scheduler,," self._report_driver_status(context) @periodic_task.periodic_task def _report_driver_status(self, context): curr_time = time.time() if curr_time - self._last_host_check > CONF.host_state_interval: self._last_host_check = curr_time LOG.info(_(""Updating host status"")) # This will grab info about the host and queue it # to be sent to the Schedulers. capabilities = self.driver.get_host_stats(refresh=True) for capability in (capabilities if isinstance(capabilities, list) else [capabilities]): capability['host_ip'] = CONF.my_ip self.update_service_capabilities(capabilities) ",0,16
openstack%2Fnova~master~Ic6fc15d1cf876aa4fd99e17c582c1ab55e3a18c1,openstack/nova,master,Ic6fc15d1cf876aa4fd99e17c582c1ab55e3a18c1,Interpret BDM None size field as 0 on compute side,MERGED,2013-09-02 09:57:38.000000000,2013-09-05 03:53:22.000000000,2013-09-05 03:53:19.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 2166}, {'_account_id': 5511}]","[{'number': 1, 'created': '2013-09-02 09:57:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5dee7cae63db5a4a57c444ba9320c84a7dd2564d', 'message': 'Interpret BDM None size field as 0 on compute side\n\nThis patch makes sure that even if we receive an ephemeral or swap BDM\nwithout size information - it is defaulted to 0 by the compute service\nprior to booting the VM, as the size is expected to be present and an\ninteger number by the driver code that uses it.\n\nCloses-bug: #1218861\n\nChange-Id: Ic6fc15d1cf876aa4fd99e17c582c1ab55e3a18c1\n'}, {'number': 2, 'created': '2013-09-02 12:01:18.000000000', 'files': ['nova/tests/virt/test_block_device.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a957beb94720ca3f171149155f9dcabd20e6141b', 'message': 'Interpret BDM None size field as 0 on compute side\n\nThis patch makes sure that even if we receive an ephemeral or swap BDM\nwithout size information - it is defaulted to 0 by the compute service\nprior to booting the VM, as the size is expected to be present and an\ninteger number by the driver code that uses it.\n\nCloses-bug: #1218861\n\nChange-Id: Ic6fc15d1cf876aa4fd99e17c582c1ab55e3a18c1\n'}]",0,44669,a957beb94720ca3f171149155f9dcabd20e6141b,11,6,2,5511,,,0,"Interpret BDM None size field as 0 on compute side

This patch makes sure that even if we receive an ephemeral or swap BDM
without size information - it is defaulted to 0 by the compute service
prior to booting the VM, as the size is expected to be present and an
integer number by the driver code that uses it.

Closes-bug: #1218861

Change-Id: Ic6fc15d1cf876aa4fd99e17c582c1ab55e3a18c1
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/44669/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/test_block_device.py', 'nova/virt/block_device.py']",2,5dee7cae63db5a4a57c444ba9320c84a7dd2564d,1218861/manager_default_bdm_size_to_zero," 'swap_size': bdm.get('volume_size', 0) or 0, 'size': bdm.get('volume_size', 0) or 0,"," 'swap_size': bdm.get('volume_size', 0), 'size': bdm.get('volume_size', 0),",21,2
openstack%2Fnova~master~Ibaf0ca7a766b6a279a83f56165edbf8ced29d5fa,openstack/nova,master,Ibaf0ca7a766b6a279a83f56165edbf8ced29d5fa,Fix to disallow server name with all blank spaces (v3 API),MERGED,2013-08-14 04:12:47.000000000,2013-09-05 03:52:49.000000000,2013-09-05 03:52:47.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 7069}, {'_account_id': 8125}]","[{'number': 1, 'created': '2013-08-14 04:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/378d10e5f9843790a7374fec65c45a785c60ecbd', 'message': 'Fix to disallow server name with all blank spaces (v3 API)\n\nPrevents a server name to be created with all blank characters.\nA fix for the V2 API was merged in commit 98ff29d13af9e0c1fa96e49e68939634c24ad2c3\nbut was not applied to the V3 API.\n\nFixes bug 1212096\n\nChange-Id: Ibaf0ca7a766b6a279a83f56165edbf8ced29d5fa\n'}, {'number': 2, 'created': '2013-08-16 03:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e373d942c12d3627d21310764a296bb0b26acd40', 'message': 'Fix to disallow server name with all blank spaces (v3 API)\n\nPrevents a server name to be created with all blank characters.\nA fix for the V2 API was merged in commit 98ff29d13af9e0c1fa96e49e68939634c24ad2c3\nbut was not applied to the V3 API.\n\nFixes bug 1212096\n\nChange-Id: Ibaf0ca7a766b6a279a83f56165edbf8ced29d5fa\n'}, {'number': 3, 'created': '2013-08-29 02:47:11.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f11dc79a6e0cd8133421161d61c0feeb0a03717a', 'message': 'Fix to disallow server name with all blank spaces (v3 API)\n\nPrevents a server name to be created, updated or rebuilt with all blank characters.\nA fix for the V2 API was merged in commit 98ff29d13af9e0c1fa96e49e68939634c24ad2c3\nbut was not applied to the V3 API.\n\nFixes bug 1212096\n\nChange-Id: Ibaf0ca7a766b6a279a83f56165edbf8ced29d5fa\n'}]",2,41836,f11dc79a6e0cd8133421161d61c0feeb0a03717a,26,10,3,5292,,,0,"Fix to disallow server name with all blank spaces (v3 API)

Prevents a server name to be created, updated or rebuilt with all blank characters.
A fix for the V2 API was merged in commit 98ff29d13af9e0c1fa96e49e68939634c24ad2c3
but was not applied to the V3 API.

Fixes bug 1212096

Change-Id: Ibaf0ca7a766b6a279a83f56165edbf8ced29d5fa
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/41836/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/api/openstack/compute/plugins/v3/test_servers.py']",2,378d10e5f9843790a7374fec65c45a785c60ecbd,bug/1212096," def test_update_server_name_all_blank_spaces(self): self.stubs.Set(db, 'instance_get', fakes.fake_instance_get(name='server_test')) req = fakes.HTTPRequest.blank('/v3/servers/%s' % FAKE_UUID) req.method = 'PUT' req.content_type = 'application/json' body = {'server': {'name': ' ' * 64}} req.body = jsonutils.dumps(body) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, FAKE_UUID, body) def test_create_instance_name_all_blank_spaces(self): # proper local hrefs must start with 'http://localhost/v2/' image_uuid = '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6' image_href = 'http://localhost/v3/images/%s' % image_uuid flavor_ref = 'http://localhost/123/flavors/3' body = { 'server': { 'name': ' ' * 64, 'imageRef': image_href, 'flavorRef': flavor_ref, 'metadata': { 'hello': 'world', 'open': 'stack', }, 'personality': [ { ""path"": ""/etc/banner.txt"", ""contents"": ""MQ=="", }, ], }, } req = fakes.HTTPRequest.blank('/v3/servers') req.method = 'POST' req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" self.assertRaises(webob.exc.HTTPBadRequest, self.controller.create, req, body) ",,44,0
openstack%2Fnova~master~Idf95085a5c1f4e71f3f0fc92618607073602eed3,openstack/nova,master,Idf95085a5c1f4e71f3f0fc92618607073602eed3,VlanManager creates superfluous quota reservations,MERGED,2013-07-25 00:49:51.000000000,2013-09-05 03:52:17.000000000,2013-09-05 03:52:15.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2835}, {'_account_id': 3189}, {'_account_id': 5652}, {'_account_id': 6873}]","[{'number': 1, 'created': '2013-07-25 00:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2aab780143975f3d38e0b5d73bba1f18914f3db4', 'message': 'VlanManager creates superfluous quota reservations\n\nThe VlanManager does not enforce quotas on fixed IPs because it\nallocates an entire network to a project. However the process\nof deallocating an IP address still creates an entry in the\nreservations table.\n\nThe VlanManager now loads the NoopQuotaDriver and no longer\nwrites superflously to the database.\n\nChange-Id: Idf95085a5c1f4e71f3f0fc92618607073602eed3\nFixes: Bug #1204714\n'}, {'number': 2, 'created': '2013-08-09 22:59:47.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0224bca0cf0a159b096633c776d14279e33a5730', 'message': 'VlanManager creates superfluous quota reservations\n\nThe VlanManager does not enforce quotas on fixed IPs because it\nallocates an entire network to a project. However the process\nof deallocating an IP address still creates an entry in the\nreservations table.\n\nThe VlanManager now loads the NoopQuotaDriver and no longer\nwrites superflously to the database.\n\nChange-Id: Idf95085a5c1f4e71f3f0fc92618607073602eed3\nFixes: Bug #1204714\n'}]",0,38574,0224bca0cf0a159b096633c776d14279e33a5730,14,7,2,3189,,,0,"VlanManager creates superfluous quota reservations

The VlanManager does not enforce quotas on fixed IPs because it
allocates an entire network to a project. However the process
of deallocating an IP address still creates an entry in the
reservations table.

The VlanManager now loads the NoopQuotaDriver and no longer
writes superflously to the database.

Change-Id: Idf95085a5c1f4e71f3f0fc92618607073602eed3
Fixes: Bug #1204714
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/38574/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/manager.py'],1,2aab780143975f3d38e0b5d73bba1f18914f3db4,bug/1204714," self.quotas = quota.QUOTAS reservations = self.quotas.reserve(context, fixed_ips=1) self.quotas.commit(context, reservations) self.quotas.rollback(context, reservations) reservations = self.quotas.reserve(context, fixed_ips=-1) self.quotas.commit(context, reservations) def __init__(self, network_driver=None, *args, **kwargs): super(VlanManager, self).__init__(network_driver=network_driver, *args, **kwargs) # NOTE(cfb) VlanManager doesn't enforce quotas on fixed IP addresses # because a project is assigned an entire network. self.quotas = quota.QuotaEngine( quota_driver_class='nova.quota.NoopQuotaDriver') ","QUOTAS = quota.QUOTAS reservations = QUOTAS.reserve(context, fixed_ips=1) QUOTAS.commit(context, reservations) QUOTAS.rollback(context, reservations) reservations = QUOTAS.reserve(context, fixed_ips=-1) QUOTAS.commit(context, reservations)",15,7
openstack%2Fopenstack-manuals~master~I78a1fb124eeb0770761ad4afd4228c5a49250355,openstack/openstack-manuals,master,I78a1fb124eeb0770761ad4afd4228c5a49250355,change database's ip to localhost in cinder.conf,ABANDONED,2013-09-03 11:09:36.000000000,2013-09-05 01:55:00.000000000,,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-09-03 11:09:36.000000000', 'files': ['doc/src/docbkx/openstack-install/cinder-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/71121b05e9b6cc03b91c15de9cc264c70f9b53f7', 'message': 'change database\'s ip to localhost in cinder.conf\n\nAs mentioned in ""Set up the cinder database."",\nthe ""PRIVILEGES"" giving to cinder are local, so the\nlocalhost will be given permission\n\nfixes Bug1214764\n\nChange-Id: I78a1fb124eeb0770761ad4afd4228c5a49250355\n'}]",0,44851,71121b05e9b6cc03b91c15de9cc264c70f9b53f7,4,2,1,7653,,,0,"change database's ip to localhost in cinder.conf

As mentioned in ""Set up the cinder database."",
the ""PRIVILEGES"" giving to cinder are local, so the
localhost will be given permission

fixes Bug1214764

Change-Id: I78a1fb124eeb0770761ad4afd4228c5a49250355
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/51/44851/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-install/cinder-install.xml'],1,71121b05e9b6cc03b91c15de9cc264c70f9b53f7,bug/1214764,sql_connection = mysql://cinder:openstack@localhost/cinder,sql_connection = mysql://cinder:openstack@192.168.127.130/cinder,1,1
openstack%2Fnova~master~Iaee5379edd51f215a51d55263196dd6c0d2de0c3,openstack/nova,master,Iaee5379edd51f215a51d55263196dd6c0d2de0c3,Use utils.execute instead of subprocess,MERGED,2013-09-03 06:08:00.000000000,2013-09-05 01:47:51.000000000,2013-09-05 01:47:49.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 5652}, {'_account_id': 7069}]","[{'number': 1, 'created': '2013-09-03 06:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/360274c1f7f3d4f0aa06d5f7fc764ef5540bd266', 'message': 'Use utils.execute instead of subprocess\n\nRemoves rogue subprocess.Popen calls to make better use of\nnova.utils.execute where appropriate to benefit from the\npatches pushed into oslo.\n\nFixes bug bug/1053382\n\nChange-Id: Iaee5379edd51f215a51d55263196dd6c0d2de0c3\n'}, {'number': 2, 'created': '2013-09-04 06:21:00.000000000', 'files': ['nova/virt/hyperv/pathutils.py', 'nova/virt/hyperv/volumeutils.py', 'nova/tests/db/test_sqlite.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4c2f36bfe006cb0ef89ca7a706223f30488a182e', 'message': 'Use utils.execute instead of subprocess\n\nRemoves rogue subprocess.Popen calls to make better use of\nnova.utils.execute where appropriate to benefit from the\npatches pushed into oslo.\n\nFixes bug 1053382\n\nChange-Id: Iaee5379edd51f215a51d55263196dd6c0d2de0c3\n'}]",0,44799,4c2f36bfe006cb0ef89ca7a706223f30488a182e,13,6,2,7069,,,0,"Use utils.execute instead of subprocess

Removes rogue subprocess.Popen calls to make better use of
nova.utils.execute where appropriate to benefit from the
patches pushed into oslo.

Fixes bug 1053382

Change-Id: Iaee5379edd51f215a51d55263196dd6c0d2de0c3
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/44799/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/pathutils.py', 'nova/virt/hyperv/volumeutils.py', 'nova/tests/db/test_sqlite.py']",3,360274c1f7f3d4f0aa06d5f7fc764ef5540bd266,bug/1053382,"from nova import utils output, _ = utils.execute(get_schema_cmd, shell=True)","import subprocess process = subprocess.Popen(get_schema_cmd, shell=True, stdout=subprocess.PIPE) output, _ = process.communicate()",6,15
openstack%2Fswift~master~Ib83d164997b0d98be921c8b4857caa2429344aa4,openstack/swift,master,Ib83d164997b0d98be921c8b4857caa2429344aa4,Pep8 account and proxy server unit tests (10 of 12),MERGED,2013-09-01 19:15:53.000000000,2013-09-05 01:46:22.000000000,2013-09-05 01:46:22.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-09-01 19:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7557e350823ef3f6ab9752c34eb2f9fb733528d8', 'message': 'Pep8 account and proxy server unit tests (10 of 12)\n\nChange-Id: Ib83d164997b0d98be921c8b4857caa2429344aa4\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-09-01 20:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4a41aca327a72c99c01a78b84a7af035d9e4c7fc', 'message': 'Pep8 account and proxy server unit tests (10 of 12)\n\nChange-Id: Ib83d164997b0d98be921c8b4857caa2429344aa4\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 3, 'created': '2013-09-01 20:13:01.000000000', 'files': ['test/unit/account/test_server.py', 'test/unit/proxy/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/6ae4e17af1bf6f0cbc6a5266564b8097260277ca', 'message': 'Pep8 account and proxy server unit tests (10 of 12)\n\nChange-Id: Ib83d164997b0d98be921c8b4857caa2429344aa4\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",0,44624,6ae4e17af1bf6f0cbc6a5266564b8097260277ca,13,6,3,6198,,,0,"Pep8 account and proxy server unit tests (10 of 12)

Change-Id: Ib83d164997b0d98be921c8b4857caa2429344aa4
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/24/44624/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/account/test_server.py', 'test/unit/proxy/test_server.py']",2,7557e350823ef3f6ab9752c34eb2f9fb733528d8,pep8-test," account_ring_path = os.path.join(_testdir, 'account.ring.gz') with closing(GzipFile(account_ring_path, 'wb')) as f: container_ring_path = os.path.join(_testdir, 'container.ring.gz') with closing(GzipFile(container_ring_path, 'wb')) as f: object_ring_path = os.path.join(_testdir, 'object.ring.gz') with closing(GzipFile(object_ring_path, 'wb')) as f: assert headers[:len(exp)] == exp, ""Expected '%s', encountered '%s'"" % ( exp, headers[:len(exp)]) 'container_count': None, # internally keep None set_http_connect(200, # account_info is found 200, headers=headers) # container_info is found set_http_connect(503, 204, # account_info found 504, 404, 404) # container_info 'NotFound' set_http_connect(503, 404, 404) # account_info 'NotFound' set_http_connect(200, 200, # account, container 201, 201, 201, # 3 working backends self.assertEqual(0, written_to[0][1] % 2) # it's (ip, port, device) '', # HEAD /a '', # HEAD /a/c proxy_server.ObjectController(self.app, 'account', 'container', 'object') req.get_response(self.app) req.get_response(self.app) body=copy_from_obj_body) body=copy_from_obj_body) self.assertEqual( seen_headers, [ self.assertEqual( seen_headers, [ self.assertEqual( seen_headers, [ self.assertEqual( seen_headers, [ self.assertEquals( res.environ['swift.container/a/c']['status'], c_expected) self.assertEquals( res.environ['swift.container/a/c']['status'], c_expected) # This should make no difference self.app.account_autocreate = True # fail to retrieve account info (503, 503, 503), # account_info fails on 503 404, missing_container=True) (404, 404, 404, # account_info fails on 404 201, 201, 201, # PUT account 404, 404, 404), # account_info fail 404, missing_container=True) (503, 503, 404, # account_info fails on 404 503, 503, 503, # PUT account 503, 503, 404), # account_info fail 404, missing_container=True) # put fails (404, 404, 404, # account_info fails on 404 201, 201, 201, # PUT account 200, # account_info success 503, 503, 201), # put container fail 503, missing_container=True) (404, 404, 404, # account_info fails on 404 201, 201, 201, # PUT account 200, # account_info success 201, 201, 201), # put container success 201, missing_container=True) (503, 404, 404, # account_info fails on 404 503, 201, 201, # PUT account 503, 200, # account_info success 503, 201, 201), # put container success 201, missing_container=True) self.assertEquals( res.environ['swift.container/a/c']['status'], 204) **kwargs): req = Request.blank( '/account', {'REQUEST_METHOD': 'OPTIONS'}, 'Access-Control-Request-Method': 'GET'}) (404, 404, 404), 404) self.assert_status_map( controller.POST, self.assert_status_map( controller.POST, (404, 404, 503, 201, 201, 503, 204, 204, 504), 204) self.assert_status_map( controller.POST, req = Request.blank( '/v1/a', headers={'Accept': 'application/json'}, environ={'REQUEST_METHOD': 'GET', 'PATH_INFO': '/v1/a'}) self.assertEquals( self.controller.GETorHEAD_base_args[-1][4], '/a/lc/o2') self.assertEquals( self.controller.GETorHEAD_base_args[-1][4], '/a/lc/o2') self.assertEquals( str(self.controller.GETorHEAD_base_args[-1][0].range), 'bytes=1-')"," with closing(GzipFile(os.path.join(_testdir, 'account.ring.gz'), 'wb')) \ as f: with closing(GzipFile(os.path.join(_testdir, 'container.ring.gz'), 'wb')) \ as f: with closing(GzipFile(os.path.join(_testdir, 'object.ring.gz'), 'wb')) \ as f: assert headers[:len(exp)] == exp, ""Expected '%s', encountered '%s'"" % (exp, headers[:len(exp)]) 'container_count': None, # internally keep None set_http_connect(200, # account_info is found 200, headers=headers) # container_info is found set_http_connect(503, 204, # account_info found 504, 404, 404) # container_info 'NotFound' set_http_connect(503, 404, 404)# account_info 'NotFound' set_http_connect(200, 200, # account, container 201, 201, 201, # 3 working backends self.assertEqual(0, written_to[0][1] % 2) # it's (ip, port, device) '', # HEAD /a '', # HEAD /a/c controller = proxy_server.ObjectController(self.app, 'account', 'container', 'object') res = req.get_response(self.app) res = req.get_response(self.app) body=copy_from_obj_body) body=copy_from_obj_body) self.assertEqual(seen_headers, [ self.assertEqual(seen_headers, [ self.assertEqual(seen_headers, [ self.assertEqual(seen_headers, [ self.assertEquals(res.environ['swift.container/a/c']['status'], c_expected) self.assertEquals(res.environ['swift.container/a/c']['status'], c_expected) self.app.account_autocreate = True # This should make no difference #fail to retrieve account info (503, 503, 503), # account_info fails on 503 404, missing_container=True) (404, 404, 404, # account_info fails on 404 201, 201, 201, # PUT account 404, 404, 404), # account_info fail 404, missing_container=True) (503, 503, 404, # account_info fails on 404 503, 503, 503, # PUT account 503, 503, 404), # account_info fail 404, missing_container=True) #put fails (404, 404, 404, # account_info fails on 404 201, 201, 201, # PUT account 200, # account_info success 503, 503, 201), # put container fail 503, missing_container=True) (404, 404, 404, # account_info fails on 404 201, 201, 201, # PUT account 200, # account_info success 201, 201, 201), # put container success 201, missing_container=True) (503, 404, 404, # account_info fails on 404 503, 201, 201, # PUT account 503, 200, # account_info success 503, 201, 201), # put container success 201, missing_container=True) self.assertEquals(res.environ['swift.container/a/c']['status'], 204) **kwargs): req = Request.blank('/account', {'REQUEST_METHOD': 'OPTIONS'}, 'Access-Control-Request-Method': 'GET'}) (404, 404, 404), 404) self.assert_status_map(controller.POST, self.assert_status_map(controller.POST, (404, 404, 503, 201, 201, 503, 204, 204, 504), 204) self.assert_status_map(controller.POST, req = Request.blank('/v1/a', headers={'Accept': 'application/json'}, environ={'REQUEST_METHOD': 'GET', 'PATH_INFO': '/v1/a'}) self.assertEquals(self.controller.GETorHEAD_base_args[-1][4], '/a/lc/o2') self.assertEquals(self.controller.GETorHEAD_base_args[-1][4], '/a/lc/o2') self.assertEquals(str(self.controller.GETorHEAD_base_args[-1][0].range), 'bytes=1-')",224,170
openstack%2Fnova~master~I21f9ae030a173621db3d21db018c3a416d050813,openstack/nova,master,I21f9ae030a173621db3d21db018c3a416d050813,update neutronclient to 2.3.0 minimum,MERGED,2013-09-03 21:44:42.000000000,2013-09-05 01:45:27.000000000,2013-09-05 01:45:24.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 4395}]","[{'number': 1, 'created': '2013-09-03 21:44:42.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/a77a28d3f787ea70f4fab63dbdfa306fe06936bc', 'message': 'update neutronclient to 2.3.0 minimum\n\nChange-Id: I21f9ae030a173621db3d21db018c3a416d050813\n'}]",0,44956,a77a28d3f787ea70f4fab63dbdfa306fe06936bc,10,6,1,2592,,,0,"update neutronclient to 2.3.0 minimum

Change-Id: I21f9ae030a173621db3d21db018c3a416d050813
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/44956/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a77a28d3f787ea70f4fab63dbdfa306fe06936bc,neutronclient,"python-neutronclient>=2.3.0,<3.0.0","python-neutronclient>=2.2.3,<3.0.0",1,1
openstack%2Fnova~master~I4f4e45160008d3eb57f4f0935f13e22b6a561430,openstack/nova,master,I4f4e45160008d3eb57f4f0935f13e22b6a561430,vm_state and task_state not updated during instance delete,MERGED,2013-08-18 20:47:17.000000000,2013-09-05 01:12:53.000000000,2013-09-05 01:12:50.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 1613}, {'_account_id': 1970}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-08-18 20:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/613bd15ece12033f99d436624498fa917b6b403f', 'message': 'vm_state and task_state not updated during instance delete\n\nFixes: bug #1212496\nChange-Id: I4f4e45160008d3eb57f4f0935f13e22b6a561430\n'}, {'number': 2, 'created': '2013-08-19 20:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9d5a343a3c4aa0e719dea3173063bceb317a96b', 'message': 'vm_state and task_state not updated during instance delete\n\nFixes: bug #1212496\nChange-Id: I4f4e45160008d3eb57f4f0935f13e22b6a561430\n'}, {'number': 3, 'created': '2013-08-20 15:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a7d39e971a7238605c59be61c0a111f0fd15e6d', 'message': 'vm_state and task_state not updated during instance delete\n\nFixes: bug #1212496\nChange-Id: I4f4e45160008d3eb57f4f0935f13e22b6a561430\n'}, {'number': 4, 'created': '2013-08-26 02:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45b2e43f4419df439659450cc5bf52af513d1c16', 'message': 'vm_state and task_state not updated during instance delete\n\nThis bug was recently introduced during conversion of the\nterminate_instance to the new object models.\nhttps://review.openstack.org/#/c/36363\nFixed by calling the save method of the new model.\nAlso updated tests to use primitive instance so it is\nconverted to new object model by object_compat decorator\nin the compute manager.\n\nRelated to: blueprint compute-api-objects\nFixes: bug #1212496\nChange-Id: I4f4e45160008d3eb57f4f0935f13e22b6a561430\n'}, {'number': 5, 'created': '2013-08-30 15:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8bd08ff85b2cf5e8eb8e281d942f4bb13cfa423a', 'message': 'vm_state and task_state not updated during instance delete\n\nThis bug was recently introduced during conversion of the\nterminate_instance to the new object models.\nhttps://review.openstack.org/#/c/36363\nFixed by calling the save method of the new model.\nAlso updated tests to use primitive instance so it is\nconverted to new object model by object_compat decorator\nin the compute manager.\n\nRelated to: blueprint compute-api-objects\nFixes: bug #1212496\nChange-Id: I4f4e45160008d3eb57f4f0935f13e22b6a561430\n'}, {'number': 6, 'created': '2013-09-02 05:55:08.000000000', 'files': ['nova/tests/compute/test_compute_utils.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9378dbcf75bc110a31687ce4c44f399ecbc10691', 'message': 'vm_state and task_state not updated during instance delete\n\nThis bug was recently introduced during conversion of the\nterminate_instance to the new object models.\nhttps://review.openstack.org/#/c/36363\nFixed by calling the save method of the new model.\nAlso updated tests to use primitive instance so it is\nconverted to new object model by object_compat decorator\nin the compute manager.\n\nRelated to: blueprint compute-api-objects\nFixes: bug #1212496\nChange-Id: I4f4e45160008d3eb57f4f0935f13e22b6a561430\n'}]",2,42534,9378dbcf75bc110a31687ce4c44f399ecbc10691,33,8,6,1613,,,0,"vm_state and task_state not updated during instance delete

This bug was recently introduced during conversion of the
terminate_instance to the new object models.
https://review.openstack.org/#/c/36363
Fixed by calling the save method of the new model.
Also updated tests to use primitive instance so it is
converted to new object model by object_compat decorator
in the compute manager.

Related to: blueprint compute-api-objects
Fixes: bug #1212496
Change-Id: I4f4e45160008d3eb57f4f0935f13e22b6a561430
",git fetch https://review.opendev.org/openstack/nova refs/changes/34/42534/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_utils.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",3,613bd15ece12033f99d436624498fa917b6b403f,bug/1212496," admin_deleted_context = context.get_admin_context( read_deleted=""only"") instance = db.instance_get_by_uuid(admin_deleted_context, instance['uuid']) self.assertEqual(instance['vm_state'], vm_states.DELETED) self.assertEqual(instance['task_state'], None) self.compute.terminate_instance(self.context, instance=jsonutils.to_primitive(instance)) self.compute.terminate_instance(self.context, instance=jsonutils.to_primitive(instance)) self.compute.terminate_instance(self.context, jsonutils.to_primitive(instance))"," self.compute.terminate_instance(self.context, instance=instance) self.compute.terminate_instance(self.context, instance=instance) self.compute.terminate_instance(self.context, instance)",23,7
openstack%2Fswift~master~I505e8b15ca41c52cd4942a0a7dd34996a1849bb3,openstack/swift,master,I505e8b15ca41c52cd4942a0a7dd34996a1849bb3,Rename param to avoid use of built-in name hash,MERGED,2013-09-04 02:33:02.000000000,2013-09-05 01:12:07.000000000,2013-09-05 01:12:06.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}]","[{'number': 1, 'created': '2013-09-04 02:33:02.000000000', 'files': ['swift/common/utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/aae122dd4c2fad215c6ce886efc8189914918c3a', 'message': 'Rename param to avoid use of built-in name hash\n\nChange-Id: I505e8b15ca41c52cd4942a0a7dd34996a1849bb3\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",0,44994,aae122dd4c2fad215c6ce886efc8189914918c3a,7,4,1,6198,,,0,"Rename param to avoid use of built-in name hash

Change-Id: I505e8b15ca41c52cd4942a0a7dd34996a1849bb3
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/94/44994/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/utils.py'],1,aae122dd4c2fad215c6ce886efc8189914918c3a,name-hash,"def storage_directory(datadir, partition, name_hash): :param name_hash: Account, container or object name hash return os.path.join(datadir, str(partition), name_hash[-3:], name_hash)","def storage_directory(datadir, partition, hash): :param hash: Account, container or object hash return os.path.join(datadir, str(partition), hash[-3:], hash)",3,3
openstack%2Fnova~master~I0b5d6b55ccdc981efcd507c45184fb2d528bf9c1,openstack/nova,master,I0b5d6b55ccdc981efcd507c45184fb2d528bf9c1,Adds ephemeral storage support for Hyper-V,MERGED,2013-08-19 12:23:14.000000000,2013-09-05 01:11:34.000000000,2013-09-05 01:11:32.000000000,"[{'_account_id': 3}, {'_account_id': 752}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 3185}, {'_account_id': 5511}]","[{'number': 1, 'created': '2013-08-19 12:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d7f5dd9fb253b683f1da444b3bbd1b923c27e1b', 'message': 'Adds ephemeral storage support for Hyper-V\n\nBlueprint: hyper-v-ephemeral-storage\n\nThis patchset adds support for creating an ephemeral storage dynamic\nVHD or VHDX (based on the versions of vhdutils used) when an instance is\nspawned.\n\nThe ephemeral disk is correctly migrated during migration/resize and\nlive migration.\n\nThe ephemeral virtual disk is not partitioned or formatted, leaving the\ntask to guest side tools (e.g.: cloud-init or cloudbase-init).\n\nChange-Id: I0b5d6b55ccdc981efcd507c45184fb2d528bf9c1\n'}, {'number': 2, 'created': '2013-08-21 14:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b7f312016f5114ac280dba2b778effc6203f65f7', 'message': 'Adds ephemeral storage support for Hyper-V\n\nBlueprint: hyper-v-ephemeral-storage\n\nThis patchset adds support for creating an ephemeral storage dynamic\nVHD or VHDX (based on the versions of vhdutils used) when an instance is\nspawned.\n\nThe ephemeral disk is correctly migrated during migration/resize and\nlive migration.\n\nThe ephemeral virtual disk is not partitioned or formatted, leaving the\ntask to guest side tools (e.g.: cloud-init or cloudbase-init).\n\nChange-Id: I0b5d6b55ccdc981efcd507c45184fb2d528bf9c1\n'}, {'number': 3, 'created': '2013-08-23 18:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dce8d0a86c1af5edb5f8e24ab8022e412b60e8c6', 'message': 'Adds ephemeral storage support for Hyper-V\n\nBlueprint: hyper-v-ephemeral-storage\n\nThis patchset adds support for creating an ephemeral storage dynamic\nVHD or VHDX (based on the versions of vhdutils used) when an instance is\nspawned.\n\nThe ephemeral disk is correctly migrated during migration/resize and\nlive migration.\n\nThe ephemeral virtual disk is not partitioned or formatted, leaving the\ntask to guest side tools (e.g.: cloud-init or cloudbase-init).\n\nChange-Id: I0b5d6b55ccdc981efcd507c45184fb2d528bf9c1\n'}, {'number': 4, 'created': '2013-08-31 21:19:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28baa584ba96c676ef15eb704e3c1a37de52328d', 'message': 'Adds ephemeral storage support for Hyper-V\n\nBlueprint: hyper-v-ephemeral-storage\n\nThis patchset adds support for creating an ephemeral storage dynamic\nVHD or VHDX (based on the versions of vhdutils used) when an instance is\nspawned.\n\nThe ephemeral disk is correctly migrated during migration/resize and\nlive migration.\n\nThe ephemeral virtual disk is not partitioned or formatted, leaving the\ntask to guest side tools (e.g.: cloud-init or cloudbase-init).\n\nChange-Id: I0b5d6b55ccdc981efcd507c45184fb2d528bf9c1\n'}, {'number': 5, 'created': '2013-08-31 22:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c9868f10d7bd44535a00de4a4cf98ad69ab42a8c', 'message': 'Adds ephemeral storage support for Hyper-V\n\nBlueprint: hyper-v-ephemeral-storage\n\nThis patchset adds support for creating an ephemeral storage dynamic\nVHD or VHDX (based on the versions of vhdutils used) when an instance is\nspawned.\n\nThe ephemeral disk is correctly migrated during migration/resize and\nlive migration.\n\nThe ephemeral virtual disk is not partitioned or formatted, leaving the\ntask to guest side tools (e.g.: cloud-init or cloudbase-init).\n\nChange-Id: I0b5d6b55ccdc981efcd507c45184fb2d528bf9c1\n'}, {'number': 6, 'created': '2013-09-03 20:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ffbdd0f517977b43e3ae0bb79ce3564fd3bcf6fc', 'message': 'Adds ephemeral storage support for Hyper-V\n\nBlueprint: hyper-v-ephemeral-storage\n\nThis patchset adds support for creating an ephemeral storage dynamic\nVHD or VHDX (based on the versions of vhdutils used) when an instance is\nspawned.\n\nThe ephemeral disk is correctly migrated during migration/resize and\nlive migration.\n\nThe ephemeral virtual disk is not partitioned or formatted, leaving the\ntask to guest side tools (e.g.: cloud-init or cloudbase-init).\n\nChange-Id: I0b5d6b55ccdc981efcd507c45184fb2d528bf9c1\n'}, {'number': 7, 'created': '2013-09-04 18:14:45.000000000', 'files': ['nova/virt/hyperv/pathutils.py', 'nova/virt/hyperv/vhdutilsv2.py', 'nova/virt/hyperv/vmops.py', 'nova/tests/virt/hyperv/fake.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'nova/virt/hyperv/vhdutils.py', 'nova/virt/hyperv/migrationops.py', 'nova/tests/virt/hyperv/test_vhdutilsv2.py', 'nova/tests/virt/hyperv/test_vhdutils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ca821483afeee9cbddc7d005cbf1af7986c8b882', 'message': 'Adds ephemeral storage support for Hyper-V\n\nBlueprint: hyper-v-ephemeral-storage\n\nThis patchset adds support for creating an ephemeral storage dynamic\nVHD or VHDX (based on the versions of vhdutils used) when an instance is\nspawned.\n\nThe ephemeral disk is correctly migrated during migration/resize and\nlive migration.\n\nThe ephemeral virtual disk is not partitioned or formatted, leaving the\ntask to guest side tools (e.g.: cloud-init or cloudbase-init).\n\nChange-Id: I0b5d6b55ccdc981efcd507c45184fb2d528bf9c1\n'}]",0,42623,ca821483afeee9cbddc7d005cbf1af7986c8b882,30,6,7,3185,,,0,"Adds ephemeral storage support for Hyper-V

Blueprint: hyper-v-ephemeral-storage

This patchset adds support for creating an ephemeral storage dynamic
VHD or VHDX (based on the versions of vhdutils used) when an instance is
spawned.

The ephemeral disk is correctly migrated during migration/resize and
live migration.

The ephemeral virtual disk is not partitioned or formatted, leaving the
task to guest side tools (e.g.: cloud-init or cloudbase-init).

Change-Id: I0b5d6b55ccdc981efcd507c45184fb2d528bf9c1
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/42623/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/pathutils.py', 'nova/virt/hyperv/vhdutilsv2.py', 'nova/virt/hyperv/vmops.py', 'nova/tests/virt/hyperv/fake.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'nova/virt/hyperv/vhdutils.py', 'nova/virt/hyperv/migrationops.py']",7,1d7f5dd9fb253b683f1da444b3bbd1b923c27e1b,bp/hyper-v-ephemeral-storage," eph_vhd_path = self._pathutils.lookup_ephemeral_vhd_path(instance_name) root_vhd_path, eph_vhd_path) def _check_resize_vhd(self, vhd_path, vhd_info, new_size): curr_size = vhd_info['MaxInternalSize'] if new_size < curr_size: raise vmutils.VHDResizeException(_(""Cannot resize a VHD "" ""to a smaller size"")) elif new_size > curr_size: self._resize_vhd(vhd_path, new_size) root_vhd_info = self._vhdutils.get_vhd_info(root_vhd_path) src_base_disk_path = root_vhd_info.get(""ParentPath"") self._check_resize_vhd(root_vhd_path, root_vhd_info, new_size) eph_vhd_path = self._pathutils.lookup_ephemeral_vhd_path(instance_name) if resize_instance: new_size = instance.get('ephemeral_gb', 0) * 1024 ** 3 if not eph_vhd_path: if new_size: eph_vhd_path = self._vmops.create_ephemeral_vhd(instance) else: eph_vhd_info = self._vhdutils.get_vhd_info(eph_vhd_path) self._check_resize_vhd(eph_vhd_path, eph_vhd_info, new_size) root_vhd_path, eph_vhd_path)"," root_vhd_path) vhd_info = self._vhdutils.get_vhd_info(root_vhd_path) src_base_disk_path = vhd_info.get(""ParentPath"") curr_size = vhd_info['MaxInternalSize'] if new_size < curr_size: raise vmutils.VHDResizeException(_(""Cannot resize a VHD "" ""to a smaller size"")) elif new_size > curr_size: self._resize_vhd(root_vhd_path, new_size) root_vhd_path)",176,28
openstack%2Fnova~master~Idddec06b9639e22d69426562d1b5a0cbf2890ccf,openstack/nova,master,Idddec06b9639e22d69426562d1b5a0cbf2890ccf,Adds Hyper-V VHDX support,MERGED,2013-08-03 23:21:06.000000000,2013-09-05 01:11:01.000000000,2013-09-05 01:10:59.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 2166}, {'_account_id': 3185}, {'_account_id': 5511}]","[{'number': 1, 'created': '2013-08-03 23:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85585f61cad38105152aa4877dd3046518770324', 'message': 'Adds Hyper-V VHDX support\n\nBlueprint: hyper-v-vhdx\n\nThe VHDX virtual disk format has been introduced with Hyper-V Server 2012\nproviding performance and management improvements.\n\nUnlike the VHD format, VHDX allows to resize differencing disks. This\nreduces the requirements for local disk space in case of CoW images and\nimproves the performance of the first spawn operation for any given image\nand flavor combination.\n\nSupporting the VHDX format in Hyper-V requires the WMI V2 namespace.\n\nUnit tests have been added accordingly.\n\nChange-Id: Idddec06b9639e22d69426562d1b5a0cbf2890ccf\n'}, {'number': 2, 'created': '2013-08-18 21:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8521008d88143e576d9ce9ef97a973875ca5c70d', 'message': 'Adds Hyper-V VHDX support\n\nBlueprint: hyper-v-vhdx\n\nThe VHDX virtual disk format has been introduced with Hyper-V Server 2012\nproviding performance and management improvements.\n\nUnlike the VHD format, VHDX allows to resize differencing disks. This\nreduces the requirements for local disk space in case of CoW images and\nimproves the performance of the first spawn operation for any given image\nand flavor combination.\n\nSupporting the VHDX format in Hyper-V requires the WMI V2 namespace.\n\nUnit tests have been added accordingly.\n\nChange-Id: Idddec06b9639e22d69426562d1b5a0cbf2890ccf\n'}, {'number': 3, 'created': '2013-08-18 22:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d51f9e32b32540a87b96632222275a9bdaaabe2d', 'message': 'Adds Hyper-V VHDX support\n\nBlueprint: hyper-v-vhdx\n\nThe VHDX virtual disk format has been introduced with Hyper-V Server 2012\nproviding performance and management improvements.\n\nUnlike the VHD format, VHDX allows to resize differencing disks. This\nreduces the requirements for local disk space in case of CoW images and\nimproves the performance of the first spawn operation for any given image\nand flavor combination.\n\nSupporting the VHDX format in Hyper-V requires the WMI V2 namespace.\n\nUnit tests have been added accordingly.\n\nChange-Id: Idddec06b9639e22d69426562d1b5a0cbf2890ccf\n'}, {'number': 4, 'created': '2013-08-18 22:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/944ef4be60b32829ec2fea1142a678f1cd06aa4e', 'message': 'Adds Hyper-V VHDX support\n\nBlueprint: hyper-v-vhdx\n\nThe VHDX virtual disk format has been introduced with Hyper-V Server 2012\nproviding performance and management improvements.\n\nUnlike the VHD format, VHDX allows to resize differencing disks. This\nreduces the requirements for local disk space in case of CoW images and\nimproves the performance of the first spawn operation for any given image\nand flavor combination.\n\nSupporting the VHDX format in Hyper-V requires the WMI V2 namespace.\n\nUnit tests have been added accordingly.\n\nChange-Id: Idddec06b9639e22d69426562d1b5a0cbf2890ccf\n'}, {'number': 5, 'created': '2013-08-21 14:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84e4012ffec0f6810931513ed73693138eda9d52', 'message': 'Adds Hyper-V VHDX support\n\nBlueprint: hyper-v-vhdx\n\nThe VHDX virtual disk format has been introduced with Hyper-V Server 2012\nproviding performance and management improvements.\n\nUnlike the VHD format, VHDX allows to resize differencing disks. This\nreduces the requirements for local disk space in case of CoW images and\nimproves the performance of the first spawn operation for any given image\nand flavor combination.\n\nSupporting the VHDX format in Hyper-V requires the WMI V2 namespace.\n\nUnit tests have been added accordingly.\n\nChange-Id: Idddec06b9639e22d69426562d1b5a0cbf2890ccf\n'}, {'number': 6, 'created': '2013-08-23 18:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eade9297863934b4b77a4679efddd0e51f40b30a', 'message': 'Adds Hyper-V VHDX support\n\nBlueprint: hyper-v-vhdx\n\nThe VHDX virtual disk format has been introduced with Hyper-V Server 2012\nproviding performance and management improvements.\n\nUnlike the VHD format, VHDX allows to resize differencing disks. This\nreduces the requirements for local disk space in case of CoW images and\nimproves the performance of the first spawn operation for any given image\nand flavor combination.\n\nSupporting the VHDX format in Hyper-V requires the WMI V2 namespace.\n\nUnit tests have been added accordingly.\n\nChange-Id: Idddec06b9639e22d69426562d1b5a0cbf2890ccf\n'}, {'number': 8, 'created': '2013-08-27 00:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/795a798bc10602fb3daa32928e6e0504ec1ffbf0', 'message': 'Adds Hyper-V VHDX support\n\nBlueprint: hyper-v-vhdx\n\nThe VHDX virtual disk format has been introduced with Hyper-V Server 2012\nproviding performance and management improvements.\n\nUnlike the VHD format, VHDX allows to resize differencing disks. This\nreduces the requirements for local disk space in case of CoW images and\nimproves the performance of the first spawn operation for any given image\nand flavor combination.\n\nSupporting the VHDX format in Hyper-V requires the WMI V2 namespace.\n\nUnit tests have been added accordingly.\n\nChange-Id: Idddec06b9639e22d69426562d1b5a0cbf2890ccf\n'}, {'number': 7, 'created': '2013-08-27 00:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/76c61e7b043166f1134858fdc77249ae2a8b273e', 'message': 'Adds Hyper-V VHDX support\n\nBlueprint: hyper-v-vhdx\n\nThe VHDX virtual disk format has been introduced with Hyper-V Server 2012\nproviding performance and management improvements.\n\nUnlike the VHD format, VHDX allows to resize differencing disks. This\nreduces the requirements for local disk space in case of CoW images and\nimproves the performance of the first spawn operation for any given image\nand flavor combination.\n\nSupporting the VHDX format in Hyper-V requires the WMI V2 namespace.\n\nUnit tests have been added accordingly.\n\nChange-Id: Idddec06b9639e22d69426562d1b5a0cbf2890ccf\n'}, {'number': 9, 'created': '2013-09-03 20:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c8fad062f43a1426b9102218904389d00e934d8', 'message': 'Adds Hyper-V VHDX support\n\nBlueprint: hyper-v-vhdx\n\nThe VHDX virtual disk format has been introduced with Hyper-V Server 2012\nproviding performance and management improvements.\n\nUnlike the VHD format, VHDX allows to resize differencing disks. This\nreduces the requirements for local disk space in case of CoW images and\nimproves the performance of the first spawn operation for any given image\nand flavor combination.\n\nSupporting the VHDX format in Hyper-V requires the WMI V2 namespace.\n\nUnit tests have been added accordingly.\n\nChange-Id: Idddec06b9639e22d69426562d1b5a0cbf2890ccf\n'}, {'number': 10, 'created': '2013-09-04 18:02:32.000000000', 'files': ['nova/virt/hyperv/pathutils.py', 'nova/virt/hyperv/vmops.py', 'nova/tests/virt/hyperv/fake.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'nova/virt/hyperv/imagecache.py', 'nova/virt/hyperv/vhdutils.py', 'nova/virt/hyperv/constants.py', 'nova/virt/hyperv/migrationops.py', 'nova/virt/hyperv/snapshotops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8f28ddd13a91eb25f0f2f3a312068223500ded97', 'message': 'Adds Hyper-V VHDX support\n\nBlueprint: hyper-v-vhdx\n\nThe VHDX virtual disk format has been introduced with Hyper-V Server 2012\nproviding performance and management improvements.\n\nUnlike the VHD format, VHDX allows to resize differencing disks. This\nreduces the requirements for local disk space in case of CoW images and\nimproves the performance of the first spawn operation for any given image\nand flavor combination.\n\nSupporting the VHDX format in Hyper-V requires the WMI V2 namespace.\n\nUnit tests have been added accordingly.\n\nChange-Id: Idddec06b9639e22d69426562d1b5a0cbf2890ccf\n'}]",9,40076,8f28ddd13a91eb25f0f2f3a312068223500ded97,38,6,10,3185,,,0,"Adds Hyper-V VHDX support

Blueprint: hyper-v-vhdx

The VHDX virtual disk format has been introduced with Hyper-V Server 2012
providing performance and management improvements.

Unlike the VHD format, VHDX allows to resize differencing disks. This
reduces the requirements for local disk space in case of CoW images and
improves the performance of the first spawn operation for any given image
and flavor combination.

Supporting the VHDX format in Hyper-V requires the WMI V2 namespace.

Unit tests have been added accordingly.

Change-Id: Idddec06b9639e22d69426562d1b5a0cbf2890ccf
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/40076/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/pathutils.py', 'nova/virt/hyperv/vmops.py', 'nova/tests/virt/hyperv/fake.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'nova/virt/hyperv/imagecache.py', 'nova/virt/hyperv/vhdutils.py', 'nova/virt/hyperv/migrationops.py', 'nova/virt/hyperv/snapshotops.py']",8,85585f61cad38105152aa4877dd3046518770324,bp/hyper-v-vhdx, src_vhd_path = self._pathutils.lookup_root_vhd_path(instance_name), src_vhd_path = self._pathutils.get_vhd_path(instance_name),105,40
openstack%2Fnova~master~I036eaa3e739d995c6a5bcfb022bf2ed0a999085e,openstack/nova,master,I036eaa3e739d995c6a5bcfb022bf2ed0a999085e,Adds Hyper-V dynamic memory support,MERGED,2013-07-26 12:04:13.000000000,2013-09-05 01:09:58.000000000,2013-09-05 01:09:56.000000000,"[{'_account_id': 3}, {'_account_id': 752}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 2166}, {'_account_id': 3185}, {'_account_id': 4393}, {'_account_id': 5371}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 7934}, {'_account_id': 8367}]","[{'number': 1, 'created': '2013-07-26 12:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b7b4b83d2b2c64154c6235dfe378caffb6bce8b3', 'message': 'Adds Hyper-V dynamic memory support\n\nBlueprint: hyper-v-dynamic-memory\n\nMemory overcommit in Hyper-V is handled with a feature called dynamic\nmemory (memory ballooning). This change adds a configuration option to\nenable it along with the required changes for both V1 and V2 WMI APIs.\n\nThe initial startup memory is obtained from the ""ram_allocation_ratio"".\nThis will mantain a consistent behavior among nova-scheduler and Hyper-V\ncompute nodes withot requiring additional configuration options.\n\nUnit tests have been added for this feature as well.\n\nSigned-off-by: Robert Tingirica <rtingirica@cloudbasesolutions.com>\n\nChange-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e\n'}, {'number': 2, 'created': '2013-07-29 15:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a507da06601ca2aa0473b41cebf4e40e32948d6', 'message': 'Adds Hyper-V dynamic memory support\n\nBlueprint: hyper-v-dynamic-memory\n\nMemory overcommit in Hyper-V is handled with a feature called dynamic\nmemory (memory ballooning). This change adds a configuration option to\nenable it along with the required changes for both V1 and V2 WMI APIs.\n\nThe initial startup memory is obtained from the ""ram_allocation_ratio"".\nThis will mantain a consistent behavior among nova-scheduler and Hyper-V\ncompute nodes without requiring additional configuration options.\n\nUnit tests have been added for this feature as well.\n\nSigned-off-by: Robert Tingirica <rtingirica@cloudbasesolutions.com>\n\nChange-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e\n'}, {'number': 3, 'created': '2013-08-09 16:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/099c9612285dcfc8730dbfd3f62f0cd8cac4ac09', 'message': 'Adds Hyper-V dynamic memory support\n\nBlueprint: hyper-v-dynamic-memory\n\nMemory overcommit in Hyper-V is handled with a feature called dynamic\nmemory (memory ballooning). This change adds a configuration option to\nenable it.\n\nThe value of dynamic_memory_ratio expresses the ratio between the total\nRAM assigned to an instance and its startup RAM amount. For example a\nratio of 2.0 for an instance with 1024MB of RAM implies 512MB of RAM\nallocated at startup.\n\nUnit tests have been added for this feature as well.\n\nChange-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e\n'}, {'number': 4, 'created': '2013-08-09 18:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3593af466c2f0d0bee0221df326ae3dd37ad68a', 'message': 'Adds Hyper-V dynamic memory support\n\nBlueprint: hyper-v-dynamic-memory\n\nMemory overcommit in Hyper-V is handled with a feature called dynamic\nmemory (memory ballooning). This change adds a configuration option to\nenable it.\n\nThe value of dynamic_memory_ratio expresses the ratio between the total\nRAM assigned to an instance and its startup RAM amount. For example a\nratio of 2.0 for an instance with 1024MB of RAM implies 512MB of RAM\nallocated at startup.\n\nUnit tests have been added for this feature as well.\n\nChange-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e\n'}, {'number': 5, 'created': '2013-08-10 13:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ae896f04dc77f2dc5f8e30612970bfcecf4124a', 'message': 'Adds Hyper-V dynamic memory support\n\nBlueprint: hyper-v-dynamic-memory\n\nMemory overcommit in Hyper-V is handled with a feature called dynamic\nmemory (memory ballooning). This change adds a configuration option to\nenable it.\n\nThe value of dynamic_memory_ratio expresses the ratio between the total\nRAM assigned to an instance and its startup RAM amount. For example a\nratio of 2.0 for an instance with 1024MB of RAM implies 512MB of RAM\nallocated at startup.\n\nUnit tests have been added for this feature as well.\n\nChange-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e\n'}, {'number': 6, 'created': '2013-08-23 17:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba40731b628357793c73799e7d16e38655f29fc0', 'message': 'Adds Hyper-V dynamic memory support\n\nBlueprint: hyper-v-dynamic-memory\n\nMemory overcommit in Hyper-V is handled with a feature called dynamic\nmemory (memory ballooning). This change adds a configuration option to\nenable it.\n\nThe value of dynamic_memory_ratio expresses the ratio between the total\nRAM assigned to an instance and its startup RAM amount. For example a\nratio of 2.0 for an instance with 1024MB of RAM implies 512MB of RAM\nallocated at startup.\n\nUnit tests have been added for this feature as well.\n\nChange-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e\n'}, {'number': 7, 'created': '2013-08-23 17:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b5cd941a20cbbef071e34c44e318c6fc76224bf', 'message': 'Adds Hyper-V dynamic memory support\n\nBlueprint: hyper-v-dynamic-memory\n\nMemory overcommit in Hyper-V is handled with a feature called dynamic\nmemory (memory ballooning). This change adds a configuration option to\nenable it.\n\nThe value of dynamic_memory_ratio expresses the ratio between the total\nRAM assigned to an instance and its startup RAM amount. For example a\nratio of 2.0 for an instance with 1024MB of RAM implies 512MB of RAM\nallocated at startup.\n\nUnit tests have been added for this feature as well.\n\nChange-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e\n'}, {'number': 8, 'created': '2013-08-23 17:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b340c711a70efbf63f9ddb20ef9f45ff1a3b48f', 'message': 'Adds Hyper-V dynamic memory support\n\nBlueprint: hyper-v-dynamic-memory\n\nMemory overcommit in Hyper-V is handled with a feature called dynamic\nmemory (memory ballooning). This change adds a configuration option to\nenable it.\n\nThe value of dynamic_memory_ratio expresses the ratio between the total\nRAM assigned to an instance and its startup RAM amount. For example a\nratio of 2.0 for an instance with 1024MB of RAM implies 512MB of RAM\nallocated at startup.\n\nUnit tests have been added for this feature as well.\n\nChange-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e\n'}, {'number': 9, 'created': '2013-09-04 11:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92485d51bee8b6cca25a6ee65b817108b2087204', 'message': 'Adds Hyper-V dynamic memory support\n\nBlueprint: hyper-v-dynamic-memory\n\nMemory overcommit in Hyper-V is handled with a feature called dynamic\nmemory (memory ballooning). This change adds a configuration option to\nenable it.\n\nThe value of dynamic_memory_ratio expresses the ratio between the total\nRAM assigned to an instance and its startup RAM amount. For example a\nratio of 2.0 for an instance with 1024MB of RAM implies 512MB of RAM\nallocated at startup.\n\nUnit tests have been added for this feature as well.\n\nDocImpact\nChange-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e\n'}, {'number': 10, 'created': '2013-09-04 12:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/23efdfb8c997108d67530a001a823c332b47009e', 'message': 'Adds Hyper-V dynamic memory support\n\nBlueprint: hyper-v-dynamic-memory\n\nMemory overcommit in Hyper-V is handled with a feature called dynamic\nmemory (memory ballooning). This change adds a configuration option to\nenable it.\n\nThe value of dynamic_memory_ratio expresses the ratio between the total\nRAM assigned to an instance and its startup RAM amount. For example a\nratio of 2.0 for an instance with 1024MB of RAM implies 512MB of RAM\nallocated at startup.\n\nUnit tests have been added for this feature as well.\n\nDocImpact\nChange-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e\n'}, {'number': 11, 'created': '2013-09-04 15:26:16.000000000', 'files': ['nova/virt/hyperv/vmops.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'etc/nova/nova.conf.sample', 'nova/tests/virt/hyperv/test_vmutilsv2.py', 'nova/virt/hyperv/vmutils.py', 'nova/tests/virt/hyperv/test_vmutils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a1b6ea5d03f5324f31fc21aa9e9e019318238adf', 'message': 'Adds Hyper-V dynamic memory support\n\nBlueprint: hyper-v-dynamic-memory\n\nMemory overcommit in Hyper-V is handled with a feature called dynamic\nmemory (memory ballooning). This change adds a configuration option to\nenable it.\n\nThe value of dynamic_memory_ratio expresses the ratio between the total\nRAM assigned to an instance and its startup RAM amount. For example a\nratio of 2.0 for an instance with 1024MB of RAM implies 512MB of RAM\nallocated at startup.\n\nUnit tests have been added for this feature as well.\n\nDocImpact\nChange-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e\n'}]",7,38791,a1b6ea5d03f5324f31fc21aa9e9e019318238adf,67,13,11,7934,,,0,"Adds Hyper-V dynamic memory support

Blueprint: hyper-v-dynamic-memory

Memory overcommit in Hyper-V is handled with a feature called dynamic
memory (memory ballooning). This change adds a configuration option to
enable it.

The value of dynamic_memory_ratio expresses the ratio between the total
RAM assigned to an instance and its startup RAM amount. For example a
ratio of 2.0 for an instance with 1024MB of RAM implies 512MB of RAM
allocated at startup.

Unit tests have been added for this feature as well.

DocImpact
Change-Id: I036eaa3e739d995c6a5bcfb022bf2ed0a999085e
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/38791/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/vmops.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'etc/nova/nova.conf.sample', 'nova/virt/hyperv/vmutilsv2.py', 'nova/virt/hyperv/vmutils.py']",5,b7b4b83d2b2c64154c6235dfe378caffb6bce8b3,bp/hyper-v-dynamic-memory," def _set_vm_memory(self, vm, vmsetting, memory_mb, dynamic_memory, mem_allocation_ratio): max_mem = long(memory_mb) memsetting.Limit = max_mem memsetting.DynamicMemoryEnabled = dynamic_memory if dynamic_memory: # Must be a multiple of 2 reserved_mem = min(long(max_mem / mem_allocation_ratio) >> 1 << 1, max_mem) else: reserved_mem = max_mem memsetting.Reservation = reserved_mem # Start with the minimum memory memsetting.VirtualQuantity = reserved_mem def update_vm(self, vm_name, memory_mb, vcpus_num, limit_cpu_features, dynamic_memory, mem_allocation_ratio): self._set_vm_memory(vm, vmsetting, memory_mb, dynamic_memory, mem_allocation_ratio) def create_vm(self, vm_name, memory_mb, vcpus_num, limit_cpu_features, dynamic_memory, mem_allocation_ratio): self._set_vm_memory(vm, vmsetting, memory_mb, dynamic_memory, mem_allocation_ratio)"," def _set_vm_memory(self, vm, vmsetting, memory_mb): #No Dynamic Memory, so reservation, limit and quantity are identical. mem = long(memory_mb) memsetting.VirtualQuantity = mem memsetting.Reservation = mem memsetting.Limit = mem def update_vm(self, vm_name, memory_mb, vcpus_num, limit_cpu_features): self._set_vm_memory(vm, vmsetting, memory_mb) def create_vm(self, vm_name, memory_mb, vcpus_num, limit_cpu_features): self._set_vm_memory(vm, vmsetting, memory_mb)",62,22
openstack%2Foperations-guide~master~I74c269020209323d69b5bd293e7d8fcd3ad5e3fe,openstack/operations-guide,master,I74c269020209323d69b5bd293e7d8fcd3ad5e3fe,Closes-Bug: #1195571 -- Updated quotas section with new info.,MERGED,2013-08-26 03:06:10.000000000,2013-09-05 01:09:53.000000000,2013-09-05 01:09:53.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 7264}]","[{'number': 1, 'created': '2013-08-26 03:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/14ddf027902c2f91037ea4d900c4805a2d56fa37', 'message': 'Closes-Bug: #1195571 -- Updated quotas section with new info.\n\nUpdated quotas section with already updated Admin User Guide info.\nNow contains info for both Compute and Block Storage quotas. Also\nswitched out <> for <replaceable> tags, and deleted a couple of\nwhite spaces.\n\nChange-Id: I74c269020209323d69b5bd293e7d8fcd3ad5e3fe\n'}, {'number': 2, 'created': '2013-08-26 22:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/9a09098454fa7ee8037daa592f2e5115fdae0067', 'message': 'Closes-Bug: #1195571 -- Updated quotas section with new info.\n\nUpdated quotas section with already updated Admin User Guide info.\nNow contains info for both Compute and Block Storage quotas. Also\nswitched out <> for <replaceable> tags, and deleted a couple of\nwhite spaces.\n\nChange-Id: I74c269020209323d69b5bd293e7d8fcd3ad5e3fe\n'}, {'number': 3, 'created': '2013-09-04 21:21:58.000000000', 'files': ['doc/src/docbkx/openstack-ops/pom.xml', 'doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/c1bb0f3852bab2f29d7a2523ef0107ca5bb7fa15', 'message': 'Closes-Bug: #1195571 -- Updated quotas section with new info.\n\nUpdated quotas section with already updated Admin User Guide info.\nNow contains info for both Compute and Block Storage quotas. Also\nswitched out <> for <replaceable> tags, and deleted a couple of\nwhite spaces.\n\nUpdates to 1.9.2 of maven plugin in pom.xml.\n\nChange-Id: I74c269020209323d69b5bd293e7d8fcd3ad5e3fe\n'}]",4,43644,c1bb0f3852bab2f29d7a2523ef0107ca5bb7fa15,17,5,3,7264,,,0,"Closes-Bug: #1195571 -- Updated quotas section with new info.

Updated quotas section with already updated Admin User Guide info.
Now contains info for both Compute and Block Storage quotas. Also
switched out <> for <replaceable> tags, and deleted a couple of
white spaces.

Updates to 1.9.2 of maven plugin in pom.xml.

Change-Id: I74c269020209323d69b5bd293e7d8fcd3ad5e3fe
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/44/43644/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml'],1,14ddf027902c2f91037ea4d900c4805a2d56fa37,Bug#1195571," of ""project"":</para> <replaceable>tenant-description</replaceable></code> which can be <para>To prevent system capacities from being exhausted without notification, you can set up quotas. Quotas are operational limits. For example, the number of gigabytes allowed per tenant can be controlled so that cloud resources are optimized. Quotas are currently enforced at the tenant (or project) level, rather than by user. </para> <para>Using the command-line interface, you can manage quotas for the OpenStack Compute Service and the Block Storage Service. </para> <para>Typically, default values are changed because a tenant requires more than 10 volumes, or more than 1TB on a Compute node. </para> <note><para>To view all tenants, run: <screen><prompt>$</prompt> <userinput>keystone tenant-list</userinput> <computeroutput>+----------------------------------+----------+---------+ | id | name | enabled | +----------------------------------+----------+---------+ | a981642d22c94e159a4a6540f70f9f8d | admin | True | | 934b662357674c7b9f5e4ec6ded4d0e7 | tenant01 | True | | 7bc1dbfd7d284ec4a856ea1eb82dca80 | tenant02 | True | | 9c554aaef7804ba49e1b21cbd97d218a | services | True | +----------------------------------+----------+---------+</computeroutput></screen> </para></note> <section xml:id=""cli_set_compute_quotas""> <title>Set Compute Service Quotas</title> <para>As an administrative user, you can update the Compute Service quotas for a tenant, as well as update the quota defaults for a new tenant. </para> <table rules=""all""> <caption>Compute Quota Descriptions</caption> <col width=""20%""/> <col width=""45%""/> <col width=""35%""/> <thead> <tr> <td> Quota </td> <td> Description </td> <td> Property Name </td> </tr> </thead> <tbody> <tr> <td> <para> Fixed Ips </para> </td> <td> <para> Number of fixed IP addresses allowed per tenant. This number must be equal to or greater than the number of allowed instances. </para> </td> <td> <para> <systemitem>fixed-ips</systemitem> </para> </td> </tr> <tr> <td> <para> Floating Ips </para> </td> <td> <para> Number of floating IP addresses allowed per tenant. </para> </td> <td> <para> <systemitem>floating-ips</systemitem> </para> </td> </tr> <tr> <td> <para> Injected File Content Bytes </para> </td> <td> <para> Number of content bytes allowed per injected file. </para> </td> <td> <para> <systemitem>injected-file-content-bytes</systemitem> </para> </td> </tr> <tr> <td> <para> Injected File Path Bytes </para> </td> <td> <para> Number of bytes allowed per injected file path. </para> </td> <td> <para> <systemitem>injected-file-path-bytes</systemitem> </para> </td> </tr> <tr> <td> <para> Injected Files </para> </td> <td> <para> Number of injected files allowed per tenant. </para> </td> <td> <para> <systemitem>injected-files</systemitem> </para> </td> </tr> <tr> <td> <para> Instances </para> </td> <td> <para> Number of instances allowed per tenant. </para> </td> <td> <para> <systemitem>instances</systemitem> </para> </td> </tr> <tr> <td> <para> Key Pairs </para> </td> <td> <para> Number of key pairs allowed per user. </para> </td> <td> <para> <systemitem>key-pairs</systemitem> </para> </td> </tr> <tr> <td> <para> Metadata Items </para> </td> <td> <para> Number of metadata items allowed per instance. </para> </td> <td> <para> <systemitem>metadata-items</systemitem> </para> </td> </tr> <tr> <td> <para> Ram </para> </td> <td> <para> Megabytes of instance ram allowed per tenant. </para> </td> <td> <para> <systemitem>ram</systemitem> </para> </td> </tr> <tr> <td> <para> Security Group Rules </para> </td> <td> <para> Number of rules per security group. </para> </td> <td> <para> <systemitem>security-group-rules</systemitem> </para> </td> </tr> <tr> <td> <para> Security Groups </para> </td> <td> <para> Number of security groups per tenant. </para> </td> <td> <para> <systemitem>security-groups</systemitem> </para> </td> </tr> <tr> <td> <para> VCPUs </para> </td> <td> <para> Number of instance cores allowed per tenant. </para> </td> <td> <para> <systemitem>cores</systemitem> </para> </td> </tr> </tbody> </table> <section xml:id=""cli_set_compute_quotas_procedure""> <title>View and update Compute quotas for a tenant (project)</title> <para>As an administrative user, you can use the <command>nova quota-*</command> commands, which are provided by the <literal>python-novaclient</literal> package, to view and update tenant quotas.</para> <procedure> <title>To view and update default quota values</title> <step> <para>List all default quotas for all tenants, as follows:</para> <screen><prompt>$</prompt> <userinput>nova quota-defaults</userinput></screen> <para>For example: </para> <screen><prompt>$</prompt> <userinput>nova quota-defaults</userinput> <computeroutput>+-----------------------------+-------+ | Property | Value | +-----------------------------+-------+ | metadata_items | 128 | | injected_file_content_bytes | 10240 | | ram | 51200 | | floating_ips | 10 | | key_pairs | 100 | | instances | 10 | | security_group_rules | 20 | | injected_files | 5 | | cores | 20 | | fixed_ips | -1 | | injected_file_path_bytes | 255 | | security_groups | 10 | +-----------------------------+-------+</computeroutput></screen> </step> <step> <para>Update a default value for a new tenant, as follows: </para> <screen><prompt>$</prompt> <userinput>nova quota-class-update default <replaceable>key</replaceable> <replaceable>value</replaceable></userinput></screen> <para>For example: </para> <screen><prompt>$</prompt> <userinput>nova quota-class-update default instances 15</userinput></screen> </step> </procedure> <procedure> <title>To view quota values for a tenant (project)</title> <step><para>Place the tenant ID in a useable variable, as follows:</para> <screen><prompt>$</prompt> <userinput>tenant=$(keystone tenant-list | awk '/<replaceable>tenantName</replaceable>/ {print $2}')</userinput></screen> </step> <step> <para>List the currently set quota values for a tenant, as follows:</para> <screen><prompt>$</prompt> <userinput>nova quota-show --tenant $tenant</userinput></screen> <para>For example:</para> <screen><prompt>$</prompt> <userinput>nova quota-show --tenant $tenant</userinput> <computeroutput>+-----------------------------+-------+ | Property | Value | +-----------------------------+-------+ | metadata_items | 128 | | injected_file_content_bytes | 10240 | | ram | 51200 | | floating_ips | 12 | | key_pairs | 100 | | instances | 10 | | security_group_rules | 20 | | injected_files | 5 | | cores | 20 | | fixed_ips | -1 | | injected_file_path_bytes | 255 | | security_groups | 10 | +-----------------------------+-------+</computeroutput></screen> </step> </procedure> <procedure> <title>To update quota values for a tenant (project)</title> <step><para>Obtain the tenant ID, as follows:</para> <screen><prompt>$</prompt> <userinput>tenant=$(keystone tenant-list | awk '/<replaceable>tenantName</replaceable>/ {print $2}')</userinput></screen> </step> <step> <para>Update a particular quota value, as follows:</para> <screen><prompt>#</prompt> <userinput>nova quota-update --<replaceable>quotaName</replaceable> <replaceable>quotaValue</replaceable> <replaceable>tenantID</replaceable></userinput></screen> <para>For example:</para> <screen><prompt>#</prompt> <userinput>nova quota-update --floating-ips 20 $tenant <prompt>#</prompt> nova quota-show --tenant $tenant</userinput> <computeroutput>+-----------------------------+-------+ | Property | Value | +-----------------------------+-------+ | metadata_items | 128 | | injected_file_content_bytes | 10240 | | ram | 51200 | | floating_ips | 20 | | key_pairs | 100 | | instances | 10 | | security_group_rules | 20 | | injected_files | 5 | | cores | 20 | | fixed_ips | -1 | | injected_file_path_bytes | 255 | | security_groups | 10 | +-----------------------------+-------+</computeroutput></screen> <note> <para>To view a list of options for the <command>quota-update</command> command, run: </para> <screen><prompt>$</prompt> <userinput>nova help quota-update</userinput></screen></note> </step> </procedure> </section> </section> <section xml:id=""cli_set_block_storage_quotas""> <title>Set Block Storage quotas</title> <para>As an administrative user, you can update the Block Storage Service quotas for a tenant, as well as update the quota defaults for a new tenant. </para> <para> <table rules=""all""> <caption>Block Storage Quota Descriptions</caption> <col width=""20%""/> <col width=""80%""/> <thead> <tr> <td> Property Name </td> <td> Description </td> </tr> </thead> <tbody> <tr> <td> <para> gigabytes </para> </td> <td> <para> Number of volume gigabytes allowed per tenant. </para> </td> </tr> <tr> <td> <para> snapshots </para> </td> <td> <para> Number of Block Storage snapshots allowed per tenant. </para> </td> </tr> <tr> <td> <para> volumes </para> </td> <td> <para> Number of Block Storage volumes allowed per tenant. </para> </td> </tr> </tbody> </table> </para> <section xml:id=""cli_set_block_storage_quotas_procedure""> <title>View and update Block Storage quotas for a tenant (project)</title> <para>As an administrative user, you can use the <command>cinder quota-*</command> commands, which are provided by the <literal>python-cinderclient</literal> package, to view and update tenant quotas.</para> <procedure> <title>To view and update default Block Storage quota values</title> <step> <para>List all default quotas for all tenants, as follows:</para> <screen><prompt>$</prompt> <userinput>cinder quota-defaults</userinput></screen> <para>For example:</para> <screen><prompt>$</prompt> <userinput>cinder quota-defaults</userinput> <computeroutput>+-----------+-------+ | Property | Value | +-----------+-------+ | gigabytes | 1000 | | snapshots | 10 | | volumes | 10 | +-----------+-------+</computeroutput></screen> </step> <step> <para>To update a default value for a new tenant, update the property in the <filename>/etc/cinder/cinder.conf</filename> file. </para> </step> </procedure> <procedure> <title>To view Block Storage quotas for a tenant</title> <step> <para>View quotas for the tenant, as follows:</para> <screen><prompt>#</prompt> <userinput>cinder quota-show <replaceable>tenantName</replaceable></userinput></screen> <para>For example:</para> <screen><prompt>#</prompt> <userinput>cinder quota-show tenant01</userinput> <computeroutput>+-----------+-------+ | Property | Value | +-----------+-------+ | gigabytes | 1000 | | snapshots | 10 | | volumes | 10 | +-----------+-------+</computeroutput></screen> </step> </procedure> <procedure> <title>To update Compute service quotas</title> <step><para>Place the tenant ID in a useable variable, as follows:</para> <screen><prompt>$</prompt> <userinput>tenant=$(keystone tenant-list | awk '/<replaceable>tenantName</replaceable>/ {print $2}')</userinput></screen> </step> <step> <para>Update a particular quota value, as follows:</para> <screen><prompt>#</prompt> <userinput>cinder quota-update --<replaceable>quotaName</replaceable> <replaceable>NewValue</replaceable> <replaceable>tenantID</replaceable></userinput></screen> <para>For example:</para> <screen><prompt>#</prompt> <userinput>cinder quota-update --volumes 15 $tenant</userinput> <prompt>#</prompt> <userinput>cinder quota-show tenant01</userinput> <computeroutput>+-----------+-------+ | Property | Value | +-----------+-------+ | gigabytes | 1000 | | snapshots | 10 | | volumes | 15 | +-----------+-------+</computeroutput></screen> </step> </procedure> </section> </section> <para>""member"": a typical user.</para> <para>""admin"": an administrative super user which has"," of ""project"": </para> &lt;tenant-description&gt;,</code> which can be <para>OpenStack provides a number of quotas which are all enforced at the project (rather than user) level. As an administrative user in the Dashboard you can see (but not edit) the default quotas using the ""Quotas"" link in the navigation sidebar. These default project quotas are specified in the <code>nova.conf</code> file on your cloud controller.</para> <para>If you do not make quota-related changes, the system uses the following defaults.</para> <table xml:id=""nova_conf"" rules=""all""> <caption>Description of nova.conf file configuration options for quotas<!--<superscript xmlns:db=""http://docbook.org/ns/docbook""> <link xlink:href=""#InsertNoteID_1"">???? </link> </superscript> --> </caption> <colgroup> <col width=""50%""/> <col width=""50%""/> </colgroup> <thead> <tr> <th>Configuration option=Default value </th> <th>(Type) Description </th> </tr> </thead> <tbody> <tr> <td> <para>quota_cores=20</para> </td> <td> <para>(IntOpt) number of instance cores allowed per project (tenant)</para> </td> </tr> <tr> <td> <para>quota_floating_ips=10</para> </td> <td> <para>(IntOpt) number of floating ips allowed per project (tenant)</para> </td> </tr> <tr> <td> <para>quota_fixed_ips=-1</para> </td> <td> <para>(IntOpt) number of fixed ips allowed per project (this should be at least the number of instances allowed). -1 is unlimited</para> </td> </tr> <tr> <td> <para>quota_gigabytes=1000</para> </td> <td> <para>(IntOpt) number of volume gigabytes allowed per project (tenant)</para> </td> </tr> <tr> <td> <para>quota_injected_file_content_bytes=10240</para> </td> <td> <para>(IntOpt) number of bytes allowed per injected file</para> </td> </tr> <tr> <td> <para>quota_injected_file_path_bytes=255</para> </td> <td> <para>(IntOpt) number of bytes allowed per injected file path</para> </td> </tr> <tr> <td> <para>quota_injected_files=5</para> </td> <td> <para>(IntOpt) number of injected files allowed</para> </td> </tr> <tr> <td> <para>quota_instances=10</para> </td> <td> <para>(IntOpt) number of instances allowed per project (tenant)</para> </td> </tr> <tr> <td> <para>quota_key_pairs=100</para> </td> <td> <para>(IntOpt) number of key pairs allowed per user</para> </td> </tr> <tr> <td> <para>quota_metadata_items=128</para> </td> <td> <para>(IntOpt) number of metadata items allowed per instance</para> </td> </tr> <tr> <td> <para>quota_ram=51200</para> </td> <td> <para>(IntOpt) megabytes of instance ram allowed per project (tenant)</para> </td> </tr> <tr> <td> <para>quota_security_group_rules=20</para> </td> <td> <para>(IntOpt) number of security rules per security group</para> </td> </tr> <tr> <td> <para>quota_security_groups=10</para> </td> <td> <para>(IntOpt) number of security groups per project (tenant)</para> </td> </tr> <tr> <td> <para>quota_volumes=10</para> </td> <td> <para>(IntOpt) number of volumes allowed per project (tenant)</para> </td> </tr> </tbody> </table> <para>Configuration table excerpted from http://docs.openstack.org/folsom/openstack-compute/admin/content/list-of-compute-config-options.html.</para> <para>The simplest way to change the default project quotas is to edit the <code>nova.conf</code> file on your cloud controller. Quotas are enforced by the <code>nova-scheduler</code> service, so you must restart that service once you change these options.</para> <para>If your site implementation varies from our example architecture, ensure any changes you make to quota default options in <code>/etc/nova/nova.conf</code> are applied to the host(s) running the <code>nova-scheduler</code> service. It is critical for consistent quota enforcement that all schedulers have identical quotas. Assuming you are following the best practices recommended in this guide, your configuration management system will automatically ensure all your schedulers have consistent configurations.</para> <para>To view and edit quotas for an individual project through the Dashboard:</para> <orderedlist> <listitem> <para>Use the ""Projects"" navigation link to get a list of your existing projects.</para> </listitem> <listitem> <para>Locate the project you want to modify and select ""Modify Quotas"" from the ""Actions"" drop down menu a the end of the line. </para> </listitem> </orderedlist> <para>To view and edit quotas for an individual project through the CLI, follow these steps:</para> <para>You can access and modify quotas from the command line but it is a bit complicated. This is done using Keystone to get the ID and then <code>nova-manage.</code> </para> <orderedlist><listitem> <para>To list a project's quota, you must first find its ID using the Keystone CLI tool.</para> <programlisting><?db-font-size 65%?># keystone tenant-list | grep &lt;tenant-name&gt; | 98333a1a28e746fa8c629c83a818ad57 | &lt;tenant-name&gt; | True | </programlisting> </listitem> <listitem> <para>Recall that the Keystone CLI tool uses ""tenant"" where the Nova CLI tool uses ""project"" for the same concept. </para> <para>To show the quota for the project, for the example above, we must use the ID <code>98333a1a28e746fa8c629c83a818ad57</code>:</para> <programlisting language=""bash""># nova-manage project quota 98333a1a28e746fa8c629c83a818ad57</programlisting> <programlisting language=""bash"">metadata_items: 128 volumes: 10 gigabytes: 1000 ram: 6291456 security_group_rules: 20 instances: 1024 security_groups: 10 injected_file_content_bytes: 10240 floating_ips: 10 injected_files: 5 cores: 2048</programlisting> <note> <para>Confusingly, <code>nova-manage project quota</code> silently accepts any string at the end of the command and reports the default quotas. In particular, if you enter the project name rather than the ID, <code>nova-manage</code> does not complain, it just lies.</para> </note> <para>To change these values you append <code>--key</code> and <code>--value</code> flags to the above command. To increase the tenant quota of Floating IPs from 10 to 20:</para> <programlisting><?db-font-size 65%?># nova-manage project quota 98333a1a28e746fa8c629c83a818ad57 --key floating_ips --value 20 </programlisting> <programlisting><?db-font-size 65%?>metadata_items: 128 volumes: 10 gigabytes: 1000 ram: 6291456 security_group_rules: 20 instances: 1024 security_groups: 10 injected_file_content_bytes: 10240 floating_ips: 20 injected_files: 5 cores: 2048</programlisting> </listitem> </orderedlist> <para>""member"": a typical user.</para> <para>""admin"": an administrative super user which has",488,250
openstack%2Fopenstack-manuals~master~Ib213d1937a70ddd88a22009d168f924d9adeceae,openstack/openstack-manuals,master,Ib213d1937a70ddd88a22009d168f924d9adeceae,Remove keystone-manage import_nova_auth,MERGED,2013-09-04 18:58:23.000000000,2013-09-05 01:06:45.000000000,2013-09-05 01:06:44.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-09-04 18:58:23.000000000', 'files': ['doc/src/docbkx/openstack-compute-admin/ch_identity_mgmt.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6b8170cf59c582794a9fb588f68081c03cb2f3dc', 'message': 'Remove keystone-manage import_nova_auth\n\nimport_nova_auth has been dropped as part of change\nIf7277e912f11c9bf3bec15f9addd848e0774f14f. Remove it from the\ndocumentation as well.\n\nChange-Id: Ib213d1937a70ddd88a22009d168f924d9adeceae\nCloses-Bug: #1202354\n'}]",0,45097,6b8170cf59c582794a9fb588f68081c03cb2f3dc,6,3,1,6547,,,0,"Remove keystone-manage import_nova_auth

import_nova_auth has been dropped as part of change
If7277e912f11c9bf3bec15f9addd848e0774f14f. Remove it from the
documentation as well.

Change-Id: Ib213d1937a70ddd88a22009d168f924d9adeceae
Closes-Bug: #1202354
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/97/45097/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-compute-admin/ch_identity_mgmt.xml'],1,6b8170cf59c582794a9fb588f68081c03cb2f3dc,bug/1202354,, <listitem> <para> <literal>import_nova_auth</literal>: Load auth data from a dump created with <command>keystone-manage</command>.</para> </listitem>,0,5
openstack%2Fapi-site~master~I64104c0d2c683bd4ea746556f7036da05becea0a,openstack/api-site,master,I64104c0d2c683bd4ea746556f7036da05becea0a,Corrected errors in Identity v2.0 wadls,MERGED,2013-08-26 16:55:43.000000000,2013-09-05 01:04:26.000000000,2013-09-05 01:04:26.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}]","[{'number': 1, 'created': '2013-08-26 16:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/d94a10ca791d4568b0b4659226c7ce09cb3efc6f', 'message': 'Corrected errors in Identity v2.0 wadls\n\nChange-Id: I64104c0d2c683bd4ea746556f7036da05becea0a\nauthor: diane fleming\n'}, {'number': 2, 'created': '2013-08-29 21:10:12.000000000', 'files': ['api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSS3-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-KSGRP-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSEC2-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-GRPADM.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/11619ac98cc65b6a60dfd03f307dab56c0ffdd38', 'message': 'Corrected errors in Identity v2.0 wadls\n\nChange-Id: I64104c0d2c683bd4ea746556f7036da05becea0a\nauthor: diane fleming\n'}]",1,43738,11619ac98cc65b6a60dfd03f307dab56c0ffdd38,9,4,2,2448,,,0,"Corrected errors in Identity v2.0 wadls

Change-Id: I64104c0d2c683bd4ea746556f7036da05becea0a
author: diane fleming
",git fetch https://review.opendev.org/openstack/api-site refs/changes/38/43738/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSS3-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-KSGRP-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSEC2-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/RAX-GRPADM.wadl']",4,d94a10ca791d4568b0b4659226c7ce09cb3efc6f,fix-os-ksec2-ext," <!--<method href=""#listUsersForGroup""/> --> <method href=""#listUsersForGroup""/> <method id=""getGroup"" name=""GET""> <doc xml:lang=""EN"" title=""Get Group Information""> Gets information for a group by ID. <method id=""listUsersForGroup"" name=""GET""> <doc xml:lang=""EN"" title=""List Users for Group"">"," <method href=""#getUsersForGroup""/> <method href=""#getUsersForGroup""/> <p xmlns=""http://www.w3.org/1999/xhtml""> Lists available groups. Use the <parameter>name</parameter> to display only those groups that match a specified name. </p> <method id=""getGroup"" name=""GET""> <doc xml:lang=""EN"" title=""Get Group""> Get group by id. <method id=""getUsersForGroup"" name=""GET""> <doc xml:lang=""EN"" title=""Get Users for Group""> <p xmlns=""http://www.w3.org/1999/xhtml""> A list of users that belong to a specified group. </p>",45,43
openstack%2Fapi-site~master~Ifbfd6d3609c2e2fac51c60d7be34be50f2339911,openstack/api-site,master,Ifbfd6d3609c2e2fac51c60d7be34be50f2339911,Add Heat's API v1.0 initial documentation,MERGED,2013-08-22 19:19:31.000000000,2013-09-05 01:04:26.000000000,2013-09-05 01:04:26.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2834}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6456}]","[{'number': 1, 'created': '2013-08-22 19:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/fcda1db9d876275027a7c8c1ea51016762c17bb7', 'message': ""Add Heat's API v1.0 initial documentation\n\nThis patch adds the initial documention for Heat.  This documentation\nis sourced from:\nhttps://github.com/openstack/heat/blob/master/docs/api.md#\n  heat-openstack-api-reference\n\nChange-Id: Ifbfd6d3609c2e2fac51c60d7be34be50f2339911\n""}, {'number': 2, 'created': '2013-08-27 19:13:32.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/samples/template_validate.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack_update.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack_create.json', 'api-ref/src/docbkx/api-ref.xml'], 'web_link': 'https://opendev.org/openstack/api-site/commit/ae9e1657d561170be3316bba957c1ccf0b96a833', 'message': ""Add Heat's API v1.0 initial documentation\n\nThis patch adds the initial documention for Heat.  This documentation\nis sourced from:\n\nhttps://github.com/openstack/heat/tree/master/doc/docbkx/api-ref/src/\n   wadls/heat-api/src\n\nChange-Id: Ifbfd6d3609c2e2fac51c60d7be34be50f2339911\n""}]",13,43332,ae9e1657d561170be3316bba957c1ccf0b96a833,18,8,2,2834,,,0,"Add Heat's API v1.0 initial documentation

This patch adds the initial documention for Heat.  This documentation
is sourced from:

https://github.com/openstack/heat/tree/master/doc/docbkx/api-ref/src/
   wadls/heat-api/src

Change-Id: Ifbfd6d3609c2e2fac51c60d7be34be50f2339911
",git fetch https://review.opendev.org/openstack/api-site refs/changes/32/43332/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/samples/template_validate.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack_create.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack_update.json', 'api-ref/src/docbkx/api-ref.xml']",5,fcda1db9d876275027a7c8c1ea51016762c17bb7,master," <chapter xml:id=""orchestration-api""> <title>Orchestration API v1.0</title> <para>Orchestrates OpenStack services using a template language</para> <wadl:resources href=""../wadls/orchestration-api/src/v1/orchestration-api.wadl"" xmlns:wadl=""http://wadl.dev.java.net/2009/02""/> </chapter>",,416,0
openstack%2Fheat~master~I86d2e25901b330dcf4b0e512eec66fb71199727b,openstack/heat,master,I86d2e25901b330dcf4b0e512eec66fb71199727b,parallelize instance delete,MERGED,2013-08-29 18:27:01.000000000,2013-09-05 00:39:31.000000000,2013-09-05 00:39:31.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 7135}, {'_account_id': 7230}]","[{'number': 1, 'created': '2013-08-29 18:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7b5b657f7e4594e2eeb5bb3b4ac7c4e57e0059bb', 'message': 'parallelize instance delete\n\nThis is third patch in the series to implement parallel delete.\nIn this patch, parallelizing instance deletion\n\nBlueprint parallel-delete\n\nChange-Id: I86d2e25901b330dcf4b0e512eec66fb71199727b\n'}, {'number': 2, 'created': '2013-09-03 17:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c821012fa7f437e79bd289357ca654beccfcf75c', 'message': 'parallelize instance delete\n\nThis is third patch in the series to implement parallel delete.\nIn this patch, parallelizing instance deletion\n\nBlueprint parallel-delete\n\nChange-Id: I86d2e25901b330dcf4b0e512eec66fb71199727b\n'}, {'number': 3, 'created': '2013-09-03 17:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/35d051affa87a907df1d4a91fe4131d95c794a18', 'message': 'parallelize instance delete\n\nThis is third patch in the series to implement parallel delete.\nIn this patch, parallelizing instance deletion\n\nBlueprint parallel-delete\n\nChange-Id: I86d2e25901b330dcf4b0e512eec66fb71199727b\n'}, {'number': 4, 'created': '2013-09-04 20:02:31.000000000', 'files': ['heat/engine/resources/instance.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/00f751b2c479aee91d97a8d04b0cd6e5dbc0dbfa', 'message': 'parallelize instance delete\n\nThis is third patch in the series to implement parallel delete.\nIn this patch, parallelizing instance deletion\n\nBlueprint parallel-delete\n\nChange-Id: I86d2e25901b330dcf4b0e512eec66fb71199727b\n'}]",0,44338,00f751b2c479aee91d97a8d04b0cd6e5dbc0dbfa,18,4,4,7230,,,0,"parallelize instance delete

This is third patch in the series to implement parallel delete.
In this patch, parallelizing instance deletion

Blueprint parallel-delete

Change-Id: I86d2e25901b330dcf4b0e512eec66fb71199727b
",git fetch https://review.opendev.org/openstack/heat refs/changes/38/44338/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/instance.py'],1,7b5b657f7e4594e2eeb5bb3b4ac7c4e57e0059bb,bp/parallel-delete," @scheduler.wrappertask def _delete_server(self, server): ''' Return a co-routine that deletes the server and waits for it to disappear from Nova. ''' yield self._detach_volumes_task()() server.delete() while True: yield try: server.get() except clients.novaclient.exceptions.NotFound: self.resource_id = None break self.resource_id = None return server_delete_task = scheduler.TaskRunner(self._delete_server, server=server) server_delete_task.start() return server_delete_task def check_delete_complete(self, server_delete_task): # if the resource was already deleted, server_delete_task will be None if server_delete_task is None: return True else: return server_delete_task.step()"," scheduler.TaskRunner(self._detach_volumes_task())() pass else: delete = scheduler.TaskRunner( nova_utils.delete_server, server) delete(wait_time=0.2) self.resource_id = None",31,8
openstack%2Fheat~master~Iaded5951618c2ac52c26d6d6437f152c658ad9cf,openstack/heat,master,Iaded5951618c2ac52c26d6d6437f152c658ad9cf,parallelize volume deletion,MERGED,2013-08-29 18:27:01.000000000,2013-09-05 00:37:21.000000000,2013-09-05 00:37:20.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 7135}, {'_account_id': 7230}]","[{'number': 1, 'created': '2013-08-29 18:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c6503a1ebdf601f89314e819fbf0056f28345f5b', 'message': 'parallelize volume deletion\n\nThis is second patch in the series to implement parallel delete\nIn this patch, parallelizing volume deletion and updating relevant\ntests\n\nBlueprint parallel-delete\n\nChange-Id: Iaded5951618c2ac52c26d6d6437f152c658ad9cf\n'}, {'number': 2, 'created': '2013-09-03 17:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2db5ae392eb75d77a8be8ebfc2e61955270cfea8', 'message': 'parallelize volume deletion\n\nThis is second patch in the series to implement parallel delete\nIn this patch, parallelizing volume deletion and updating relevant\ntests\n\nBlueprint parallel-delete\n\nChange-Id: Iaded5951618c2ac52c26d6d6437f152c658ad9cf\n'}, {'number': 3, 'created': '2013-09-03 17:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/08896f691f88ffb644eae7effbfcf753bac35fd5', 'message': 'parallelize volume deletion\n\nThis is second patch in the series to implement parallel delete\nIn this patch, parallelizing volume deletion and updating relevant\ntests\n\nBlueprint parallel-delete\n\nChange-Id: Iaded5951618c2ac52c26d6d6437f152c658ad9cf\n'}, {'number': 4, 'created': '2013-09-04 20:02:31.000000000', 'files': ['heat/engine/resources/volume.py', 'heat/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/bf65eedf3f1335088e332f26f54fa39c0bb2801d', 'message': 'parallelize volume deletion\n\nThis is second patch in the series to implement parallel delete\nIn this patch, parallelizing volume deletion and updating relevant\ntests\n\nBlueprint parallel-delete\n\nChange-Id: Iaded5951618c2ac52c26d6d6437f152c658ad9cf\n'}]",0,44337,bf65eedf3f1335088e332f26f54fa39c0bb2801d,18,4,4,7230,,,0,"parallelize volume deletion

This is second patch in the series to implement parallel delete
In this patch, parallelizing volume deletion and updating relevant
tests

Blueprint parallel-delete

Change-Id: Iaded5951618c2ac52c26d6d6437f152c658ad9cf
",git fetch https://review.opendev.org/openstack/heat refs/changes/37/44337/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/volume.py', 'heat/tests/test_volume.py']",2,c6503a1ebdf601f89314e819fbf0056f28345f5b,bp/parallel-delete," def _stubout_delete_volume(self, fv): self.m.StubOutWithMock(fv, 'delete') fv.delete().AndReturn(True) self.m.StubOutWithMock(fv, 'get') fv.get().AndReturn(None) fv.get().AndRaise( clients.cinderclient.exceptions.NotFound('Not found')) self.m.ReplayAll() self._stubout_delete_volume(fv) self._stubout_delete_volume(fv) self._stubout_delete_volume(fv) def delete(self): pass ", self.cinder_fc.volumes.delete('vol-123').AndReturn(None) self.cinder_fc.volumes.get('vol-123').AndRaise( clients.cinderclient.exceptions.NotFound('Not found')) self.cinder_fc.volumes.delete('vol-123').AndReturn(None) self.cinder_fc.volumes.delete('vol-123').AndReturn(None),34,11
openstack%2Fheat~master~I8a96b1a956388372c29f9f45445f397467667110,openstack/heat,master,I8a96b1a956388372c29f9f45445f397467667110,Implement parallel delete,MERGED,2013-08-29 18:27:01.000000000,2013-09-05 00:37:19.000000000,2013-09-05 00:37:18.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 5263}, {'_account_id': 7135}, {'_account_id': 7230}, {'_account_id': 7385}]","[{'number': 1, 'created': '2013-08-29 18:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/08ac593f956d854e0a3e220f30657e0d46f4e135', 'message': 'Implement parallel delete\n\nThis is first patch in the series to implement parallel delete\nand it includes following changes.\n\n1. changing Stack.delete to use stack_task\n2. In Resource.delete polling for check_delete_complete\n3. Updating unit tests to use TaskRunner for resource.delete and\n   resource.destroy\n\nBlueprint parallel-delete\n\nChange-Id: I8a96b1a956388372c29f9f45445f397467667110\n'}, {'number': 2, 'created': '2013-09-03 15:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/34057248723dc785bad635ae71e31e9cb686ad59', 'message': 'Implement parallel delete\n\nThis is first patch in the series to implement parallel delete\nand it includes following changes.\n\n1. changing Stack.delete to use stack_task\n2. In Resource.delete polling for check_delete_complete\n3. Updating unit tests to use TaskRunner for resource.delete and\n   resource.destroy\n\nBlueprint parallel-delete\n\nChange-Id: I8a96b1a956388372c29f9f45445f397467667110\n'}, {'number': 3, 'created': '2013-09-03 17:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/122e89ca6fe7e02121c2110f044bcd0001c35857', 'message': 'Implement parallel delete\n\nThis is first patch in the series to implement parallel delete\nand it includes following changes.\n\n1. changing Stack.delete to use stack_task\n2. In Resource.delete polling for check_delete_complete\n3. Updating unit tests to use TaskRunner for resource.delete and\n   resource.destroy\n\nBlueprint parallel-delete\n\nChange-Id: I8a96b1a956388372c29f9f45445f397467667110\n'}, {'number': 5, 'created': '2013-09-03 17:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bd0f26b84371003e9263765cc679cab09afcbbb0', 'message': 'Implement parallel delete\n\nThis is first patch in the series to implement parallel delete\nand it includes following changes:\n\n1. changing Stack.delete to use stack_task\n2. In Resource.delete polling for check_delete_complete\n3. Updating unit tests to use TaskRunner for resource.delete and\n   resource.destroy\n\nBlueprint parallel-delete\n\nChange-Id: I8a96b1a956388372c29f9f45445f397467667110\n'}, {'number': 4, 'created': '2013-09-03 17:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8dee237816494647a38b97f8578868b12548b197', 'message': 'Implement parallel delete\n\nThis is first patch in the series to implement parallel delete\nand it includes following changes:\n\n1. changing Stack.delete to use stack_task\n2. In Resource.delete polling for check_delete_complete\n3. Updating unit tests to use TaskRunner for resource.delete and\n   resource.destroy\n\nBlueprint parallel-delete\n\nChange-Id: I8a96b1a956388372c29f9f45445f397467667110\n'}, {'number': 6, 'created': '2013-09-04 20:02:31.000000000', 'files': ['heat/tests/test_vpc.py', 'heat/tests/test_s3.py', 'heat/tests/test_eip.py', 'heat/tests/test_instance.py', 'heat/tests/test_swift.py', 'heat/tests/test_waitcondition.py', 'heat/tests/test_security_group.py', 'heat/tests/test_volume.py', 'heat/tests/test_cw_alarm.py', 'heat/tests/test_user.py', 'heat/tests/test_resource.py', 'heat/tests/test_metadata_refresh.py', 'heat/engine/parser.py', 'heat/tests/test_rackspace_cloud_server.py', 'heat/tests/test_server.py', 'heat/tests/test_neutron.py', 'heat/tests/test_sqlalchemy_api.py', 'heat/engine/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/49d414e44551b3ec1513e7beb3c9ca7828aefd6d', 'message': 'Implement parallel delete\n\nThis is first patch in the series to implement parallel delete\nand it includes following changes:\n\n1. changing Stack.delete to use stack_task\n2. In Resource.delete polling for check_delete_complete\n3. Updating unit tests to use TaskRunner for resource.delete and\n   resource.destroy\n\nBlueprint parallel-delete\n\nChange-Id: I8a96b1a956388372c29f9f45445f397467667110\n'}]",11,44336,49d414e44551b3ec1513e7beb3c9ca7828aefd6d,38,7,6,7230,,,0,"Implement parallel delete

This is first patch in the series to implement parallel delete
and it includes following changes:

1. changing Stack.delete to use stack_task
2. In Resource.delete polling for check_delete_complete
3. Updating unit tests to use TaskRunner for resource.delete and
   resource.destroy

Blueprint parallel-delete

Change-Id: I8a96b1a956388372c29f9f45445f397467667110
",git fetch https://review.opendev.org/openstack/heat refs/changes/36/44336/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_vpc.py', 'heat/tests/test_s3.py', 'heat/tests/test_eip.py', 'heat/tests/test_instance.py', 'heat/tests/test_swift.py', 'heat/tests/test_waitcondition.py', 'heat/tests/test_security_group.py', 'heat/tests/test_volume.py', 'heat/tests/test_cw_alarm.py', 'heat/tests/test_user.py', 'heat/tests/test_resource.py', 'heat/tests/test_metadata_refresh.py', 'heat/engine/parser.py', 'heat/tests/test_rackspace_cloud_server.py', 'heat/tests/test_server.py', 'heat/tests/test_neutron.py', 'heat/tests/test_sqlalchemy_api.py', 'heat/engine/resource.py']",18,08ac593f956d854e0a3e220f30657e0d46f4e135,bp/parallel-delete,"from heat.engine import scheduler handle_data = None handle_data = self.handle_delete() yield handle_data = self.handle_snapshot_delete(initial_state) yield if (deletion_policy != 'Retain' and callable(getattr(self, 'check_delete_complete', None))): while not self.check_delete_complete(handle_data): yield @scheduler.wrappertask yield self.delete()", self.handle_delete() self.handle_snapshot_delete(initial_state) self.delete(),103,92
openstack%2Fhorizon~master~I84e8087ba557d69d7fc35029f8c1b741f1e326a3,openstack/horizon,master,I84e8087ba557d69d7fc35029f8c1b741f1e326a3,update neutronclient to 2.3.0 minimum,MERGED,2013-09-03 21:44:56.000000000,2013-09-05 00:09:56.000000000,2013-09-05 00:09:56.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1816}, {'_account_id': 2592}, {'_account_id': 4978}, {'_account_id': 7553}]","[{'number': 1, 'created': '2013-09-03 21:44:56.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e83d584c9d00b25ff47368194baebceccc9e6a18', 'message': 'update neutronclient to 2.3.0 minimum\n\nChange-Id: I84e8087ba557d69d7fc35029f8c1b741f1e326a3\n'}]",0,44958,e83d584c9d00b25ff47368194baebceccc9e6a18,11,6,1,2592,,,0,"update neutronclient to 2.3.0 minimum

Change-Id: I84e8087ba557d69d7fc35029f8c1b741f1e326a3
",git fetch https://review.opendev.org/openstack/horizon refs/changes/58/44958/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e83d584c9d00b25ff47368194baebceccc9e6a18,neutronclient_2_3_0,"python-neutronclient>=2.3.0,<3","python-neutronclient>=2.2.3,<3",1,1
openstack%2Fnova~master~I4712c5d91c22b3b531048340f3cc827ce5ac438d,openstack/nova,master,I4712c5d91c22b3b531048340f3cc827ce5ac438d,Fix AggregateDBApiTestCase on PostreSQL and MySQL,MERGED,2013-08-12 13:27:02.000000000,2013-09-05 00:09:29.000000000,2013-09-05 00:09:26.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 2166}, {'_account_id': 5652}, {'_account_id': 6172}, {'_account_id': 6849}]","[{'number': 1, 'created': '2013-08-12 13:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/41a7cacabfe02f9c9d7b5d782d9a2f97583ece9d', 'message': 'Fix AggregateDBApiTestCase on PostreSQL and MySQL\n\nTest methods of AggregateDBApiTestCase use hard-coded\ninstance ids values instead of ones returned by *_create()\nDB API methods. This imposes the following restriction on\nautoincrement behavior: it must always start with 1 (which\nmight not be true, if a DB is not recreated for each test\ncase).\n\nBlueprint: db-api-tests-on-all-backends\n\nChange-Id: I4712c5d91c22b3b531048340f3cc827ce5ac438d\n'}, {'number': 2, 'created': '2013-09-02 14:15:17.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/89c364917087d3eae57067c917b9f57de4c3ac38', 'message': 'Fix AggregateDBApiTestCase on PostreSQL and MySQL\n\nTest methods of AggregateDBApiTestCase use hard-coded\ninstance ids values instead of ones returned by *_create()\nDB API methods. This imposes the following restriction on\nautoincrement behavior: it must always start with 1 (which\nmight not be true, if a DB is not recreated for each test\ncase).\n\nBlueprint: db-api-tests-on-all-backends\n\nChange-Id: I4712c5d91c22b3b531048340f3cc827ce5ac438d\n'}]",0,41409,89c364917087d3eae57067c917b9f57de4c3ac38,23,7,2,6849,,,0,"Fix AggregateDBApiTestCase on PostreSQL and MySQL

Test methods of AggregateDBApiTestCase use hard-coded
instance ids values instead of ones returned by *_create()
DB API methods. This imposes the following restriction on
autoincrement behavior: it must always start with 1 (which
might not be true, if a DB is not recreated for each test
case).

Blueprint: db-api-tests-on-all-backends

Change-Id: I4712c5d91c22b3b531048340f3cc827ce5ac438d
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/41409/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,41a7cacabfe02f9c9d7b5d782d9a2f97583ece9d,bp/db-api-tests-on-all-backends," self.assertEqual(aggregate['deleted'], result['id']) updated = db.aggregate_update(ctxt, result['id'], new_values) db.aggregate_update(ctxt, result['id'], values) db.aggregate_update(ctxt, result['id'], values)"," self.assertEqual(aggregate['deleted'], True) updated = db.aggregate_update(ctxt, 1, new_values) db.aggregate_update(ctxt, 1, values) db.aggregate_update(ctxt, 1, values)",4,4
openstack%2Fswift~master~I469e3b75b6846fddb5e9d2b8317506129836d0a6,openstack/swift,master,I469e3b75b6846fddb5e9d2b8317506129836d0a6,Pep8 container test_sync and test_diskfile (9 of 12),MERGED,2013-09-01 19:15:53.000000000,2013-09-05 00:09:23.000000000,2013-09-05 00:09:22.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-09-01 19:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b94cf2ba0de814db984b6132827fe9a02a5e276a', 'message': 'Pep8 container test_sync and test_diskfile (9 of 12)\n\nChange-Id: I469e3b75b6846fddb5e9d2b8317506129836d0a6\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-09-01 20:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/049f0da3f090ae237f737efc5cdb33e17d78cbb0', 'message': 'Pep8 container test_sync and test_diskfile (9 of 12)\n\nChange-Id: I469e3b75b6846fddb5e9d2b8317506129836d0a6\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 3, 'created': '2013-09-01 20:13:01.000000000', 'files': ['test/unit/container/test_sync.py', 'test/unit/obj/test_diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/1d9213bed4c930ba2d0f75e9e0e17944b09b96a7', 'message': 'Pep8 container test_sync and test_diskfile (9 of 12)\n\nChange-Id: I469e3b75b6846fddb5e9d2b8317506129836d0a6\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",0,44623,1d9213bed4c930ba2d0f75e9e0e17944b09b96a7,12,6,3,6198,,,0,"Pep8 container test_sync and test_diskfile (9 of 12)

Change-Id: I469e3b75b6846fddb5e9d2b8317506129836d0a6
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/23/44623/3 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/container/test_sync.py', 'test/unit/obj/test_diskfile.py']",2,b94cf2ba0de814db984b6132827fe9a02a5e276a,pep8-test," FakeLogger()) FakeLogger(), keep_data_fp=keep_data_fp) FakeLogger()) FakeLogger()) FakeLogger(), keep_data_fp=True) FakeLogger(), keep_data_fp=True) 'o', FakeLogger()).writer(): FakeLogger(), keep_data_fp=True) obj_name, FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger())","import time FakeLogger()) FakeLogger(), keep_data_fp=keep_data_fp) FakeLogger()) FakeLogger()) FakeLogger(), keep_data_fp=True) FakeLogger(), keep_data_fp=True) 'o', FakeLogger()).writer(): FakeLogger(), keep_data_fp=True) obj_name, FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger()) FakeLogger())",146,105
openstack%2Fhorizon~master~I5d945deba7062fe42bcee2e7636ca4a8f4607a31,openstack/horizon,master,I5d945deba7062fe42bcee2e7636ca4a8f4607a31,Moves SECRET_KEY generation to base settings.py file,MERGED,2013-09-03 18:16:52.000000000,2013-09-05 00:09:21.000000000,2013-09-05 00:09:20.000000000,"[{'_account_id': 3}, {'_account_id': 1816}, {'_account_id': 4264}, {'_account_id': 5623}]","[{'number': 1, 'created': '2013-09-03 18:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/95b7e09b2a8dfd84069467ff3f63d3869bb93504', 'message': ""Moves SECRET_KEY generation to base settings.py file\n\nBy putting the fallback SECRET_KEY generation into the base\nsettings.py file we can ensure there is always a SECRET_KEY\neven if local_settings.py doesn't exist. All this really does\nis move the current default in local_settings.py into\nsettings.py.\n\nThis fixes the failures during docs building, etc. due to\nSECRET_KEY not being set.\n\nContains a few changes to fix errors/warnings during\ndocs building as well.\n\nFixes bug 1188622 and fixes bug 1178663.\n\nChange-Id: I5d945deba7062fe42bcee2e7636ca4a8f4607a31\n""}, {'number': 2, 'created': '2013-09-03 18:59:33.000000000', 'files': ['horizon/test/customization/cust_test2.py', 'horizon/tables/actions.py', 'horizon/test/customization/cust_test1.py', 'openstack_dashboard/settings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/41aa5f906c6e6836259113473e9e46f55674e43b', 'message': ""Moves SECRET_KEY generation to base settings.py file\n\nBy putting the fallback SECRET_KEY generation into the base\nsettings.py file we can ensure there is always a SECRET_KEY\neven if local_settings.py doesn't exist. All this really does\nis move the current default in local_settings.py into\nsettings.py.\n\nThis fixes the failures during docs building, etc. due to\nSECRET_KEY not being set.\n\nContains a few changes to fix errors/warnings during\ndocs building as well.\n\nFixes bug 1188622 and fixes bug 1178663.\n\nChange-Id: I5d945deba7062fe42bcee2e7636ca4a8f4607a31\n""}]",0,44929,41aa5f906c6e6836259113473e9e46f55674e43b,9,4,2,1816,,,0,"Moves SECRET_KEY generation to base settings.py file

By putting the fallback SECRET_KEY generation into the base
settings.py file we can ensure there is always a SECRET_KEY
even if local_settings.py doesn't exist. All this really does
is move the current default in local_settings.py into
settings.py.

This fixes the failures during docs building, etc. due to
SECRET_KEY not being set.

Contains a few changes to fix errors/warnings during
docs building as well.

Fixes bug 1188622 and fixes bug 1178663.

Change-Id: I5d945deba7062fe42bcee2e7636ca4a8f4607a31
",git fetch https://review.opendev.org/openstack/horizon refs/changes/29/44929/2 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/test/customization/cust_test2.py', 'horizon/tables/actions.py', 'horizon/test/customization/cust_test1.py', 'openstack_dashboard/settings.py']",4,95b7e09b2a8dfd84069467ff3f63d3869bb93504,bug/1188622,"# Ensure that we always have a SECRET_KEY set, even when no local_settings.py # file is present. See local_settings.py.example for full documentation on the # horizon.utils.secret_key module and its use. from horizon.utils import secret_key LOCAL_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'local') SECRET_KEY = secret_key.generate_or_read_from_file(os.path.join(LOCAL_PATH, '.secret_key_store')) ",,43,21
openstack%2Fkeystone~master~Ic31b78dda0a66ddc4c4214bca4ba3b683d554886,openstack/keystone,master,Ic31b78dda0a66ddc4c4214bca4ba3b683d554886,Move _generate_paste_config to tests.core,MERGED,2013-08-30 18:13:22.000000000,2013-09-05 00:09:13.000000000,2013-09-05 00:09:12.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6738}]","[{'number': 1, 'created': '2013-08-30 18:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/423d472b2b6370aed6b61285e031b64257d08b6d', 'message': ""Move _generate_paste_file to tests.core\n\nSeeing as how tests for oauth1 and endpoint filtering each have\ntheir own private functions for creating a new paste-ini file,\nI think it's best to move these to tests.core.\nFuture extensions will benefit from this too.\n\nfixes bug: #1218720\n\nChange-Id: Ic31b78dda0a66ddc4c4214bca4ba3b683d554886\n""}, {'number': 2, 'created': '2013-08-30 21:38:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5a4a699924d33b93eaecbe230da9936fe9001b54', 'message': ""Move _generate_paste_config to tests.core\n\nSeeing as how tests for oauth1 and endpoint filtering each have\ntheir own private functions for creating a new paste-ini file,\nI think it's best to move these to tests.core.\nFuture extensions will benefit from this too.\n\nfixes bug: #1218720\n\nChange-Id: Ic31b78dda0a66ddc4c4214bca4ba3b683d554886\n""}, {'number': 3, 'created': '2013-09-04 05:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a3f896988fc5bdafd7ace39a5e05de1b874efb87', 'message': ""Move _generate_paste_config to tests.core\n\nSeeing as how tests for oauth1 and endpoint filtering each have\ntheir own private functions for creating a new paste-ini file,\nI think it's best to move these to tests.core.\nFuture extensions will benefit from this too.\n\nfixes bug: #1218720\n\nChange-Id: Ic31b78dda0a66ddc4c4214bca4ba3b683d554886\n""}, {'number': 4, 'created': '2013-09-04 06:02:58.000000000', 'files': ['keystone/tests/core.py', 'keystone/tests/test_v3_oauth1.py', 'keystone/tests/test_associate_project_endpoint_extension.py', 'keystone/tests/test_v3.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/55a4c06d26c8751fefa6d64ddb4a2e0ecd9a189f', 'message': ""Move _generate_paste_config to tests.core\n\nSeeing as how tests for oauth1 and endpoint filtering each have\ntheir own private functions for creating a new paste-ini file,\nI think it's best to move these to tests.core.\nFuture extensions will benefit from this too.\n\nfixes bug: #1218720\n\nChange-Id: Ic31b78dda0a66ddc4c4214bca4ba3b683d554886\n""}]",10,44509,55a4c06d26c8751fefa6d64ddb4a2e0ecd9a189f,23,8,4,6482,,,0,"Move _generate_paste_config to tests.core

Seeing as how tests for oauth1 and endpoint filtering each have
their own private functions for creating a new paste-ini file,
I think it's best to move these to tests.core.
Future extensions will benefit from this too.

fixes bug: #1218720

Change-Id: Ic31b78dda0a66ddc4c4214bca4ba3b683d554886
",git fetch https://review.opendev.org/openstack/keystone refs/changes/09/44509/4 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/core.py', 'keystone/tests/test_v3_oauth1.py', 'keystone/tests/test_associate_project_endpoint_extension.py']",3,423d472b2b6370aed6b61285e031b64257d08b6d,bug1218720," test.generate_paste_config(self.EXTENSION_FILTER_NAME, self._paste_file_name)","# TODO(gyee): we need to generalize this one and stash it into tests.core def _generate_paste_config(filter_name, new_paste_file_name): # Generate a file, based on keystone-paste.ini, that includes # endpoint_filter_extension in the pipeline with open(test.etcdir('keystone-paste.ini'), 'r') as f: contents = f.read() new_contents = contents.replace(' service_v3', ' %s service_v3' % (filter_name)) with open(new_paste_file_name, 'w') as f: f.write(new_contents) _generate_paste_config(self.EXTENSION_FILTER_NAME, self._paste_file_name)",33,47
openstack%2Fneutron~master~I8a706887f89f21ede88177e441a3b562fd8f74dc,openstack/neutron,master,I8a706887f89f21ede88177e441a3b562fd8f74dc,ensure that Arista test destroys the database,MERGED,2013-09-04 18:38:09.000000000,2013-09-05 00:09:05.000000000,2013-09-05 00:09:04.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6524}, {'_account_id': 6558}]","[{'number': 1, 'created': '2013-09-04 18:38:09.000000000', 'files': ['neutron/tests/unit/ml2/drivers/test_arista_mechanism_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9b76de161d690faee341a87e8066d40329b4f5b0', 'message': 'ensure that Arista test destroys the database\n\nOut of order test execution has revealed that the database was not\nproperly cleaned up after each test run.  This patch adds a call to\nclear the database after each test.\n\nFixes bug: 1220784\n\nChange-Id: I8a706887f89f21ede88177e441a3b562fd8f74dc\n'}]",0,45091,9b76de161d690faee341a87e8066d40329b4f5b0,14,8,1,2592,,,0,"ensure that Arista test destroys the database

Out of order test execution has revealed that the database was not
properly cleaned up after each test run.  This patch adds a call to
clear the database after each test.

Fixes bug: 1220784

Change-Id: I8a706887f89f21ede88177e441a3b562fd8f74dc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/45091/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/ml2/drivers/test_arista_mechanism_driver.py'],1,9b76de161d690faee341a87e8066d40329b4f5b0,bug/1220784, self.addCleanup(ndb.clear_db),,1,0
openstack%2Fnova~master~I3fa97820771e71a135f9c1f57b9bda98a9fc0843,openstack/nova,master,I3fa97820771e71a135f9c1f57b9bda98a9fc0843,No need to construct instance type when resize VM,ABANDONED,2013-08-08 01:57:26.000000000,2013-09-04 23:57:19.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2667}, {'_account_id': 4393}, {'_account_id': 5292}, {'_account_id': 5371}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 7494}, {'_account_id': 7800}, {'_account_id': 8495}]","[{'number': 1, 'created': '2013-08-08 01:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dde597af0d88cd0d7fd78509cb1829a3a74b41a8', 'message': 'No need to construct instance type when resize VM\n\nFix bug 1209288\n\nWhen resize a VM, the instance_type in request_spec is still\nold flavor, this might cause some problem if scheduler want to\nget new instance type from rquest_spec.\n\nSince when resize a VM, the new flavor is already passed to\nmigrate_server, so when build request_spec, use the new flavor\ndirectly without constructing it from instance.\n\nChange-Id: I3fa97820771e71a135f9c1f57b9bda98a9fc0843\n'}, {'number': 2, 'created': '2013-08-10 06:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9b007ffc9b71926772f0588ccb58cae5f866bfa', 'message': 'No need to construct instance type when resize VM\n\nFix bug 1209288\n\nWhen resize a VM, the instance_type in request_spec is still\nold flavor, this might cause some problem if scheduler want to\nget new instance type from rquest_spec.\n\nSince when resize a VM, the new flavor is already passed to\nmigrate_server, so when build request_spec, use the new flavor\ndirectly without constructing it from instance.\n\nChange-Id: I3fa97820771e71a135f9c1f57b9bda98a9fc0843\n'}, {'number': 3, 'created': '2013-08-17 04:09:15.000000000', 'files': ['nova/scheduler/utils.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/36cbfee648cf6cf9a6e4a58ee22ae7f382f4d257', 'message': 'No need to construct instance type when resize VM\n\nWhen resize a VM, the instance_type in request_spec is still\nold flavor, this will cause some problem if scheduler want to\nget new instance type from rquest_spec. An example would be\nwhen resize with CoreFilter or RamFilter.\n\nSince when resize a VM, the new flavor is already passed to\nmigrate_server, so when build request_spec, use the new flavor\ndirectly without constructing it from instance.\n\nFix bug 1209288\n\nChange-Id: I3fa97820771e71a135f9c1f57b9bda98a9fc0843\n'}]",5,40780,36cbfee648cf6cf9a6e4a58ee22ae7f382f4d257,25,13,3,7494,,,0,"No need to construct instance type when resize VM

When resize a VM, the instance_type in request_spec is still
old flavor, this will cause some problem if scheduler want to
get new instance type from rquest_spec. An example would be
when resize with CoreFilter or RamFilter.

Since when resize a VM, the new flavor is already passed to
migrate_server, so when build request_spec, use the new flavor
directly without constructing it from instance.

Fix bug 1209288

Change-Id: I3fa97820771e71a135f9c1f57b9bda98a9fc0843
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/40780/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/utils.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py']",3,dde597af0d88cd0d7fd78509cb1829a3a74b41a8,bug/1209288," context, image, [instance], flavor)"," context, image, [instance])",7,4
openstack%2Fpuppet-swift~master~I97a14f0210aa472876188e66249ea53f34afff72,openstack/puppet-swift,master,I97a14f0210aa472876188e66249ea53f34afff72,Use swift_bench_config,MERGED,2013-08-26 03:16:39.000000000,2013-09-04 23:55:35.000000000,2013-09-04 23:55:35.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1607}, {'_account_id': 2166}, {'_account_id': 3153}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-08-26 03:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/c33eef5571baf68cf679d1be9f8c54ba890df408', 'message': 'Use swift_bench_config\n\nUse swift_bench_config to configure swift-bench.conf\n\nImplements: blueprint puppet-swift-ini-settings\nChange-Id: I97a14f0210aa472876188e66249ea53f34afff72\n'}, {'number': 2, 'created': '2013-08-26 06:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/03eb49dc1fa0644236f39d75a2e498bd1d557c19', 'message': 'Use swift_bench_config\n\nUse swift_bench_config to configure swift-bench.conf\n\nImplements: blueprint puppet-swift-ini-settings\nChange-Id: I97a14f0210aa472876188e66249ea53f34afff72\n'}, {'number': 3, 'created': '2013-08-31 05:13:22.000000000', 'files': ['templates/swift-bench.conf.erb', 'manifests/bench.pp', 'spec/classes/swift_bench_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/49d6801247fd3969de89661a0098c109cac1f755', 'message': 'Use swift_bench_config\n\nUse swift_bench_config to configure swift-bench.conf\n\nImplements: blueprint puppet-swift-ini-settings\nChange-Id: I97a14f0210aa472876188e66249ea53f34afff72\n'}]",0,43645,49d6801247fd3969de89661a0098c109cac1f755,19,6,3,7156,,,0,"Use swift_bench_config

Use swift_bench_config to configure swift-bench.conf

Implements: blueprint puppet-swift-ini-settings
Change-Id: I97a14f0210aa472876188e66249ea53f34afff72
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/45/43645/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/swift-bench.conf.erb', 'manifests/bench.pp', 'spec/classes/swift_bench_spec.rb']",3,c33eef5571baf68cf679d1be9f8c54ba890df408,bp/puppet-swift-ini-settings," { :auth_url => 'http://localhost:8080/auth/v1.0', :swift_user => 'test:tester', :swift_key => 'testing', :auth_version => '1.0', :log_level => 'INFO', :test_timeout => '10', :put_concurrency => '10', :get_concurrency => '10', :del_concurrency => '10', :lower_object_size => '10', :upper_object_size => '10', :object_size => '1', :num_objects => '1000', :num_gets => '10000', :num_containers => '20', :delete => 'yes' } end shared_examples 'swift-bench.conf' do it 'configures swift-bench.conf' do should contain_swift_bench_config( 'bench/auth').with_value(p[:auth_url]) should contain_swift_bench_config( 'bench/user').with_value(p[:swift_user]) should contain_swift_bench_config( 'bench/key').with_value(p[:swift_key]) should contain_swift_bench_config( 'bench/auth_version').with_value(p[:auth_version]) should contain_swift_bench_config( 'bench/log-level').with_value(p[:log_level]) should contain_swift_bench_config( 'bench/timeout').with_value(p[:test_timeout]) should contain_swift_bench_config( 'bench/put_concurrency').with_value(p[:put_concurrency]) should contain_swift_bench_config( 'bench/get_concurrency').with_value(p[:get_concurrency]) should contain_swift_bench_config( 'bench/get_concurrency').with_value(p[:get_concurrency]) should contain_swift_bench_config( 'bench/lower_object_size').with_value(p[:lower_object_size]) should contain_swift_bench_config( 'bench/upper_object_size').with_value(p[:upper_object_size]) should contain_swift_bench_config( 'bench/object_size').with_value(p[:object_size]) should contain_swift_bench_config( 'bench/num_objects').with_value(p[:num_objects]) should contain_swift_bench_config( 'bench/num_gets').with_value(p[:num_gets]) should contain_swift_bench_config( 'bench/num_containers').with_value(p[:num_containers]) should contain_swift_bench_config( 'bench/delete').with_value(p[:delete]) end let (:p) { default_params } include_examples 'swift-bench.conf' { :auth_url => 'http://127.0.0.1:8080/auth/v1.0', :put_concurrency => '20' } let (:p) { default_params.merge!(params) } include_examples 'swift-bench.conf'"," {:auth_url => 'http://localhost:8080/auth/v1.0'} let :params do default_params end it 'should create a reasonable swift-bench file' do verify_contents(subject, '/etc/swift/swift-bench.conf', [ ""auth = http://localhost:8080/auth/v1.0"", ""user = test:tester"", ""key = testing"", ""auth_version = 1.0"", ""log-level = INFO"", ""timeout = 10"", ""put_concurrency = 10"", ""get_concurrency = 10"", ""del_concurrency = 10"", ""lower_object_size = 10"", ""upper_object_size = 10"", ""object_size = 1"", ""num_objects = 1000"", ""num_gets = 10000"", ""num_containers = 20"", ""delete = yes"" ] ) end default_params.merge({ :auth_url => 'http://127.0.0.1:8080/auth/v1.0', :put_concurrency => '20' }) it 'should create a configured swift-bench file' do verify_contents(subject, '/etc/swift/swift-bench.conf', [ ""auth = http://127.0.0.1:8080/auth/v1.0"", ""user = admin:admin"", ""key = admin"", ""auth_version = 1.0"", ""log-level = INFO"", ""timeout = 10"", ""put_concurrency = 20"", ""get_concurrency = 10"", ""del_concurrency = 10"", ""lower_object_size = 10"", ""upper_object_size = 10"", ""object_size = 1"", ""num_objects = 1000"", ""num_gets = 10000"", ""num_containers = 20"", ""delete = yes"" ] ) end ",77,121
openstack%2Fcinder~master~Icb0fc7e85c5e59a346b8e51f67a0d4f06aed872c,openstack/cinder,master,Icb0fc7e85c5e59a346b8e51f67a0d4f06aed872c,Add in place update of type on existing volume,ABANDONED,2013-09-03 21:09:04.000000000,2013-09-04 23:48:21.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}]","[{'number': 1, 'created': '2013-09-03 21:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/07355bf870b7b50d8b2d0fd1a299f47c7d356247', 'message': 'Add in place update of type on existing volume\n\nAdds the ability to change the volume_type of an existing\nvolume without migration.  This will allow things like forcing\nthe driver to re-read and update behaviors contained in extra-specs.\n\nUtilizes the filter scheduler to determine if the current volume\nhost supports the desired type change, if not the retype will\nnot succeed.\n\n******************* WIP ***********************\n\nImplements bg volume_retype\n\nChange-Id: Icb0fc7e85c5e59a346b8e51f67a0d4f06aed872c\n'}, {'number': 2, 'created': '2013-09-03 21:10:24.000000000', 'files': ['cinder/scheduler/rpcapi.py', 'cinder/volume/manager.py', 'cinder/volume/driver.py', 'cinder/scheduler/manager.py', 'cinder/exception.py', 'cinder/volume/rpcapi.py', 'cinder/api/contrib/volume_actions.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7b10a74cd20c1c66b9876eaca9a103ed49e2c646', 'message': 'Add in place update of type on existing volume\n\nAdds the ability to change the volume_type of an existing\nvolume without migration.  This will allow things like forcing\nthe driver to re-read and update behaviors contained in extra-specs.\n\nUtilizes the filter scheduler to determine if the current volume\nhost supports the desired type change, if not the retype will\nnot succeed.\n\n******************* WIP ***********************\n\nImplements bp volume_retype\n\nChange-Id: Icb0fc7e85c5e59a346b8e51f67a0d4f06aed872c\n'}]",0,44954,7b10a74cd20c1c66b9876eaca9a103ed49e2c646,7,3,2,2243,,,0,"Add in place update of type on existing volume

Adds the ability to change the volume_type of an existing
volume without migration.  This will allow things like forcing
the driver to re-read and update behaviors contained in extra-specs.

Utilizes the filter scheduler to determine if the current volume
host supports the desired type change, if not the retype will
not succeed.

******************* WIP ***********************

Implements bp volume_retype

Change-Id: Icb0fc7e85c5e59a346b8e51f67a0d4f06aed872c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/54/44954/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/scheduler/rpcapi.py', 'cinder/volume/manager.py', 'cinder/volume/driver.py', 'cinder/scheduler/manager.py', 'cinder/exception.py', 'cinder/volume/rpcapi.py', 'cinder/api/contrib/volume_actions.py', 'cinder/volume/api.py']",8,07355bf870b7b50d8b2d0fd1a299f47c7d356247,bp/volume_retype," def _check_new_type_quotas(self, context, volume, type_id): # First we need to the quotas for the updated type try: reserve_opts = {'volumes': 1, 'gigabytes': volume['size']} QUOTAS.add_volume_type_opts(context, reserve_opts, type_id) reservations = QUOTAS.reserve(context, **reserve_opts) except exception.OverQuota as e: overs = e.kwargs['overs'] usages = e.kwargs['usages'] quotas = e.kwargs['quotas'] def _consumed(name): return (usages[name]['reserved'] + usages[name]['in_use']) for over in overs: if 'gigabytes' in over: msg = _(""Quota exceeded for %(s_pid)s, tried to retype "" ""%(s_size)sG volume (%(d_consumed)dG of "" ""%(d_quota)dG already consumed)"") LOG.warn(msg % {'s_pid': context.project_id, 's_size': volume['size'], 'd_consumed': _consumed(over), 'd_quota': quotas[over]}) raise exception.VolumeSizeExceedsAvailableQuota() elif 'volumes' in over: msg = _(""Quota exceeded for %(s_pid)s, tried to retype "" ""volume (%(d_consumed)d volumes"" ""already consumed)"") LOG.warn(msg % {'s_pid': context.project_id, 'd_consumed': _consumed(over)}) raise exception.VolumeLimitExceeded( allowed=quotas[over]) return reservations def retype(self, context, volume, type_id): """"""Attempt to modify the type associated with an existing volume."""""" if 'error' in volume['status']: msg = _('Unable to update type due to error status ' 'on volume: %s') % volume['id'] LOG.warn(msg) raise exception.InvalidVolume(reason=msg) self.update(context, volume, {'status': 'converting-type'}) try: new_type = volume_types.get_volume_type(context, type_id) except exception.VolumeTypeNotFound: msg = _('Invalid volume type id specified ' 'for retype: %s') % type_id LOG.error(msg) raise exception.InvalidInput(reason=msg) # NOTE(jdg): We're checking here, but never committing # reason being is there are a number of things that can go # wrong in the filtering (is the current host able to support # the requested type. This way we can give a quota error # back if that's going to be a problem before we send the thread out self._check_new_type_quotas(context, volume, type_id) # NOTE(jdg): For now only supporting retype w/out migration # follow up later to consider expanding this request_spec = {'volume_properties': volume, 'volume_id': volume['id'], 'volume_type': new_type} #'volume_type': dict(new_type).iteritems()} filter_properties = {} filter_properties['size'] = 0 filter_properties['availability_zone'] =\ volume.get('availability_zone') filter_properties['user_id'] = volume.get('user_id') filter_properties['metadata'] = volume.get('metadata') filter_properties['qos_specs'] = volume.get('qos_specs') self.scheduler_rpcapi.modify_type(context, CONF.volume_topic, volume['id'], request_spec, filter_properties) ",,216,1
openstack%2Fnova~master~Idad237ca76b4a28dc80792ad195b95db224161ae,openstack/nova,master,Idad237ca76b4a28dc80792ad195b95db224161ae,Change resize_instance paths to use objects,MERGED,2013-08-21 02:52:10.000000000,2013-09-04 23:39:29.000000000,2013-09-04 23:39:26.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1247}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-08-21 02:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84adacc387d4d70c8f53a71ac18bb512539eabb7', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 2, 'created': '2013-08-21 09:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edf8e3925ac94ba760038e74a95181910bd10f84', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 3, 'created': '2013-08-21 11:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed5edcd9dc34d0b05a38156c7771b7bcccadd007', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 4, 'created': '2013-08-21 21:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a3a822cd007d0e93953b3bdb145348c57d741104', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 5, 'created': '2013-08-23 17:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11650a05a66251197c36f7a6e212fe4445364a7f', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 6, 'created': '2013-08-23 17:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99db0940ebc948ac1e1166bde9d72ab804ab9114', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 7, 'created': '2013-08-23 19:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89dc6a533e91a81499d8d9e92dba182966da1a62', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 8, 'created': '2013-08-23 19:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6711504e1880228f3a9561ec5a524d81889e2b2', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 9, 'created': '2013-08-23 22:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8a791a509350170821458db18334891adac2f1e', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 10, 'created': '2013-08-24 05:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11ff0f0df9c8be9d67937fa84919d095bd69e1f6', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 11, 'created': '2013-08-24 21:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c30218e290ba03302fbbcb6145df91533f5796d3', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 12, 'created': '2013-08-28 10:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08436f4f0901cf75795836bd9f25f50675415119', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 13, 'created': '2013-08-28 20:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2f59b45023f7306d2a285413d83655a7dc6551f', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 14, 'created': '2013-08-30 14:36:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cdc4dc3efc066fccfad5b5ec9d9b4e3b2bed34ba', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 15, 'created': '2013-08-30 18:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/599280fb3bc060c142be605a21457795c7417701', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 16, 'created': '2013-09-03 22:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/feef1a133cff776621f9871b05c0af02113514dc', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}, {'number': 17, 'created': '2013-09-04 17:28:37.000000000', 'files': ['nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4790e19853c64f5e01440d62b183373701bc2e3c', 'message': ""Change resize_instance paths to use objects\n\nConverts calls to compute's resize_instance to pass new-world instance\nand migration objects.\n\nRelated to blueprint unified-object-model\n\nChange-Id: Idad237ca76b4a28dc80792ad195b95db224161ae\n""}]",0,43031,4790e19853c64f5e01440d62b183373701bc2e3c,67,7,17,1030,,,0,"Change resize_instance paths to use objects

Converts calls to compute's resize_instance to pass new-world instance
and migration objects.

Related to blueprint unified-object-model

Change-Id: Idad237ca76b4a28dc80792ad195b95db224161ae
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/43031/17 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/tests/compute/test_compute.py']",4,84adacc387d4d70c8f53a71ac18bb512539eabb7,bp/compute-api-objects," migration = migration_obj.Migration.get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') self.compute.resize_instance(self.context, instance=instance, migration=migration, image={}, migration_p = obj_base.obj_to_primitive(migration) migration=migration_p, migration = migration_obj.Migration.get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') self.compute.resize_instance(self.context, instance=instance, migration=migration, image={}, instance_type=new_type) migration_p = obj_base.obj_to_primitive(migration) migration=migration_p, migration = migration_obj.Migration.get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') self.context, instance=instance, migration=migration, image={}, migration = migration_obj.Migration.get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') self.context, instance=instance, migration=migration, image={}, migration = migration_obj.Migration.get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') self.compute.resize_instance(self.context, instance=instance, migration=migration, image={}, self.assertEqual(migration.dest_compute, instance.host) self.compute.resize_instance(self.context, instance=instance, migration=migration, migration_p = obj_base.obj_to_primitive(migration) migration=migration_p, self.compute.resize_instance(self.context, instance=instance, migration=migration, instance_p = obj_base.obj_to_primitive(instance) migration_p = obj_base.obj_to_primitive(migration) migration = migration_obj.Migration.get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') self.context, instance=instance, migration=migration, image={},"," migration_ref = db.migration_get_by_instance_and_status( self.context.elevated(), instance['uuid'], 'pre-migrating') instance_p = obj_base.obj_to_primitive(instance) self.compute.resize_instance(self.context, instance=instance_p, migration=migration_ref, image={}, migration=jsonutils.to_primitive(migration_ref), migration_ref = db.migration_get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') instance_p = obj_base.obj_to_primitive(instance) self.compute.resize_instance(self.context, instance=instance_p, migration=migration_ref, image={}, instance_type=new_type) migration=jsonutils.to_primitive(migration_ref), migration_ref = db.migration_get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') instance_p = obj_base.obj_to_primitive(instance) self.context, instance=instance_p, migration=migration_ref, image={}, migration_ref = db.migration_get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') instance_p = obj_base.obj_to_primitive(instance) self.context, instance=instance_p, migration=migration_ref, image={}, migration_ref = db.migration_get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') instance_p = obj_base.obj_to_primitive(instance) self.compute.resize_instance(self.context, instance=instance_p, migration=migration_ref, image={}, self.assertEqual(migration_ref['dest_compute'], instance.host) migration_p = obj_base.obj_to_primitive(migration) instance_p = obj_base.obj_to_primitive(instance) self.compute.resize_instance(self.context, instance=instance_p, migration=migration_p, migration=jsonutils.to_primitive(migration_p), migration_p = obj_base.obj_to_primitive(migration) instance_p = obj_base.obj_to_primitive(instance) self.compute.resize_instance(self.context, instance=instance_p, migration=migration_p, migration_ref = db.migration_get_by_instance_and_status( self.context.elevated(), instance.uuid, 'pre-migrating') instance_p = obj_base.obj_to_primitive(instance) self.context, instance=instance_p, migration=migration_ref, image={},",91,84
openstack%2Fopenstack-manuals~master~Ibb125dab9c676e84e52f628679bf178e5c9f2266,openstack/openstack-manuals,master,Ibb125dab9c676e84e52f628679bf178e5c9f2266,Update Nexenta driver doc,MERGED,2013-08-30 19:50:27.000000000,2013-09-04 23:30:41.000000000,2013-09-04 23:30:40.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 1177}, {'_account_id': 2401}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-08-30 19:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8d1df3a9973882173ca3243fe204c1e31aafde63', 'message': 'Update Nexenta driver doc\n\nReplace Nova with Cinder\n\nChange-Id: Ibb125dab9c676e84e52f628679bf178e5c9f2266\n'}, {'number': 2, 'created': '2013-09-02 15:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3a3a52f4aac3bc40e0c32d66bc53a8bb3f31a500', 'message': 'Update Nexenta driver doc\n\nReplace Nova with Cinder\n\nChange-Id: Ibb125dab9c676e84e52f628679bf178e5c9f2266\n'}, {'number': 3, 'created': '2013-09-03 15:14:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/45323e0f524cbde16602ef6b4b2e9764f4a70b2d', 'message': 'Update Nexenta driver doc\n\nReplace Nova with Cinder\n\nChange-Id: Ibb125dab9c676e84e52f628679bf178e5c9f2266\n'}, {'number': 4, 'created': '2013-09-04 21:29:13.000000000', 'files': ['.gitignore', 'doc/src/docbkx/openstack-config/block-storage/drivers/nexenta-volume-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7c288dc20c240a2ae620cf6e902513bb8d25dbd4', 'message': 'Update Nexenta driver doc\n\nReplace Nova with Cinder\n\nChange-Id: Ibb125dab9c676e84e52f628679bf178e5c9f2266\n'}]",5,44535,7c288dc20c240a2ae620cf6e902513bb8d25dbd4,20,7,4,2401,,,0,"Update Nexenta driver doc

Replace Nova with Cinder

Change-Id: Ibb125dab9c676e84e52f628679bf178e5c9f2266
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/35/44535/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-config/block-storage/drivers/nexenta-volume-driver.xml'],1,8d1df3a9973882173ca3243fe204c1e31aafde63,nexenta-driver," <title>Nexenta Drivers</title> <para> NexentaStor Appliance is NAS/SAN software platform designed for building reliable and fast network storage arrays. The the OpenSolaris and uses ZFS as a disk management system. NexentaStor can serve as a storage node for the OpenStack and for the virtual servers via iSCSI protocol. </para> <para> The Nexenta driver allows you to use Nexenta SA to store Cinder volumes. Every Cinder volume is represented by a single zvol in a predefined Nexenta volume. For every new volume the driver creates a iSCSI target and iSCSI target group that are used to access it from compute hosts. </para> <!-- iSCSI driver section --> <section xml:id=""nexenta-iscsi-driver""> <title>Nexenta iSCSI driver</title> <para>To use Cinder with Nexenta Storage Appliance, you should:</para> <itemizedlist> <listitem> <para>set <literal>volume_driver = cinder.volume.drivers.nexenta.volume.NexentaDriver </literal>; </para> </listitem> <listitem> <para> set <literal>nexenta_host</literal> flag to the hostname or IP of your NexentaStor; </para> </listitem> <listitem> <para> set <literal>nexenta_user</literal> and <literal>nexenta_password</literal> to the username and password of the user with all necessary privileges on the appliance, including the access to REST API; </para> </listitem> <listitem> <para> set <literal>nexenta_volume</literal> to the name of the volume on the appliance that you would like to use in Cinder, or create a volume named <literal>cinder</literal> (it will be used by default) </para> </listitem> </itemizedlist> <para> Nexenta driver has a lot of tunable flags. Some of them you might want to change: </para> <itemizedlist> <listitem> <para> <literal>nexenta_target_prefix</literal> defines the prefix that will be prepended to volume id to form target name on Nexenta; </para> </listitem> <listitem> <para> <literal>nexenta_target_group_prefix</literal> defines the prefix for target groups; </para> </listitem> <listitem> <para> <literal>nexenta_blocksize</literal> can be set to the size of the blocks in newly created zvols on appliance, with the suffix; for example, the default 8K means 8 kilobytes; </para> </listitem> <listitem> <para> <literal>nexenta_sparse</literal> is boolean and can be set to use sparse zvols to save space on appliance; </para> </listitem> </itemizedlist> <para> Some flags that you might want to keep with the default values: </para> <itemizedlist> <listitem> <para> <literal>nexenta_rest_port</literal> is the port where Nexenta listens for REST requests (the same port where the NMV works) </para> </listitem> <listitem> <para> <literal>nexenta_rest_protocol</literal> can be set to <literal>http</literal> or <literal>https</literal>, but the default is <literal>auto</literal> which makes the driver try to use HTTP and switch to HTTPS in case of failure </para> </listitem> <listitem> <para> <literal>nexenta_iscsi_target_portal_port</literal> is the port to connect to Nexenta over iSCSI </para> </listitem> </itemizedlist> </section> <!-- / iSCSI driver section -->"," <title>Nexenta</title> <para>NexentaStor Appliance is NAS/SAN software platform designed for building reliable and fast network storage arrays. The the OpenSolaris and uses ZFS as a disk management system. NexentaStor can serve as a storage node for the OpenStack and for the virtual servers via iSCSI protocol.</para> <para>The Nexenta driver allows you to use Nexenta SA to store Nova volumes. Every Nova volume is represented by a single zvol in a predefined Nexenta volume. For every new volume the driver creates a iSCSI target and iSCSI target group that are used to access it from compute hosts.</para> <para>To use Nova with Nexenta Storage Appliance, you should:</para> <itemizedlist> <listitem><para>set <literal>volume_driver=nova.volume.nexenta.volume.NexentaDriver</literal>.</para></listitem> <listitem><para>set <literal>--nexenta_host</literal> flag to the hostname or IP of your NexentaStor</para></listitem> <listitem><para>set <literal>--nexenta_user</literal> and <literal>--nexenta_password</literal> to the username and password of the user with all necessary privileges on the appliance, including the access to REST API</para></listitem> <listitem><para>set <literal>--nexenta_volume</literal> to the name of the volume on the appliance that you would like to use in Nova, or create a volume named <literal>nova</literal> (it will be used by default)</para></listitem> </itemizedlist> <para>Nexenta driver has a lot of tunable flags. Some of them you might want to change:</para> <itemizedlist> <listitem><para><literal>nexenta_target_prefix</literal> defines the prefix that will be prepended to volume id to form target name on Nexenta</para></listitem> <listitem><para><literal>nexenta_target_group_prefix</literal> defines the prefix for target groups</para></listitem> <listitem><para><literal>nexenta_blocksize</literal> can be set to the size of the blocks in newly created zvols on appliance, with the suffix; for example, the default 8K means 8 kilobytes</para></listitem> <listitem><para><literal>nexenta_sparse</literal> is boolean and can be set to use sparse zvols to save space on appliance</para></listitem> </itemizedlist> <para>Some flags that you might want to keep with the default values:</para> <itemizedlist> <listitem><para><literal>nexenta_rest_port</literal> is the port where Nexenta listens for REST requests (the same port where the NMV works)</para></listitem> <listitem><para><literal>nexenta_rest_protocol</literal> can be set to <literal>http</literal> or <literal>https</literal>, but the default is <literal>auto</literal> which makes the driver try to use HTTP and switch to HTTPS in case of failure</para></listitem> <listitem><para><literal>nexenta_iscsi_target_portal_port</literal> is the port to connect to Nexenta over iSCSI</para></listitem> </itemizedlist>",111,57
openstack%2Fkeystone~master~I87328080facd4d9b1349a677c00a93d118993538,openstack/keystone,master,I87328080facd4d9b1349a677c00a93d118993538,Fix the code miss to show the correct error messages,MERGED,2013-09-04 09:40:27.000000000,2013-09-04 23:26:42.000000000,2013-09-04 23:26:41.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6348}, {'_account_id': 6676}, {'_account_id': 7353}]","[{'number': 1, 'created': '2013-09-04 09:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/60e86836fd3dcb29a1d36a648212b8982eca472d', 'message': 'In keystone/common/ldap/core.py I found the code like below:\n\n 86 raise ValueError(_(\n 87 \'Invalid LDAP TLS certs option: %(option). \'\n 88 \'Choose one of: %(options)s\') % {\n\nThe code ""%(option)"" in line 87 should be fixed to ""%(option)s"" to\nshow the correct error messages when the exception happens.\nThis patch fixes this error.\n\nFixes bug #1220601\n\nChange-Id: I87328080facd4d9b1349a677c00a93d118993538\n'}, {'number': 2, 'created': '2013-09-04 09:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1280f32592c2f2147d602120a0f063600e8db2ff', 'message': 'Fix the code miss to show the correct error messages\nIn keystone/common/ldap/core.py I found the code like below:\n\n 86 raise ValueError(_(\n 87 \'Invalid LDAP TLS certs option: %(option). \'\n 88 \'Choose one of: %(options)s\') % {\n\nThe code ""%(option)"" in line 87 should be fixed to ""%(option)s"" to\nshow the correct error messages when the exception happens.\nThis patch fixes this error.\n\nFixes bug #1220601\n\nChange-Id: I87328080facd4d9b1349a677c00a93d118993538\n'}, {'number': 3, 'created': '2013-09-04 09:45:59.000000000', 'files': ['keystone/common/ldap/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/356d246aa083486cf1b6d70440ba13da376ea249', 'message': 'Fix the code miss to show the correct error messages\n\nIn keystone/common/ldap/core.py I found the code like below:\n\n 86 raise ValueError(_(\n 87 \'Invalid LDAP TLS certs option: %(option). \'\n 88 \'Choose one of: %(options)s\') % {\n\nThe code ""%(option)"" in line 87 should be fixed to ""%(option)s"" to\nshow the correct error messages when the exception happens.\nThis patch fixes this error.\n\nFixes bug #1220601\n\nChange-Id: I87328080facd4d9b1349a677c00a93d118993538\n'}]",0,45024,356d246aa083486cf1b6d70440ba13da376ea249,13,9,3,6348,,,0,"Fix the code miss to show the correct error messages

In keystone/common/ldap/core.py I found the code like below:

 86 raise ValueError(_(
 87 'Invalid LDAP TLS certs option: %(option). '
 88 'Choose one of: %(options)s') % {

The code ""%(option)"" in line 87 should be fixed to ""%(option)s"" to
show the correct error messages when the exception happens.
This patch fixes this error.

Fixes bug #1220601

Change-Id: I87328080facd4d9b1349a677c00a93d118993538
",git fetch https://review.opendev.org/openstack/keystone refs/changes/24/45024/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/ldap/core.py'],1,60e86836fd3dcb29a1d36a648212b8982eca472d,bug/1220601, 'Invalid LDAP TLS certs option: %(option)s. ', 'Invalid LDAP TLS certs option: %(option). ',1,1
openstack%2Fswift~master~I6fa3291eeacb7ee5c095ad9bccbd33f027bf11e3,openstack/swift,master,I6fa3291eeacb7ee5c095ad9bccbd33f027bf11e3,Pep8 remaining unit test modules in common (8 of 12),MERGED,2013-09-01 19:15:53.000000000,2013-09-04 23:26:23.000000000,2013-09-04 23:26:22.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-09-01 19:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1217411b0437c6b4052bfd7831c68cd4a7ab93bf', 'message': 'Pep8 remaining unit test modules in common (8 of 12)\n\nChange-Id: I6fa3291eeacb7ee5c095ad9bccbd33f027bf11e3\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-09-01 20:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d1e834d9f17377bfd2d320683d44d2caf53987b0', 'message': 'Pep8 remaining unit test modules in common (8 of 12)\n\nChange-Id: I6fa3291eeacb7ee5c095ad9bccbd33f027bf11e3\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 3, 'created': '2013-09-01 20:13:01.000000000', 'files': ['test/unit/common/test_constraints.py', 'test/unit/common/ring/test_ring.py', 'test/unit/common/test_db.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b5a0b830e247517f9ec717b03d77b37806ac66e5', 'message': 'Pep8 remaining unit test modules in common (8 of 12)\n\nChange-Id: I6fa3291eeacb7ee5c095ad9bccbd33f027bf11e3\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",1,44622,b5a0b830e247517f9ec717b03d77b37806ac66e5,12,6,3,6198,,,0,"Pep8 remaining unit test modules in common (8 of 12)

Change-Id: I6fa3291eeacb7ee5c095ad9bccbd33f027bf11e3
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/22/44622/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_constraints.py', 'test/unit/common/ring/test_ring.py', 'test/unit/common/test_db.py']",3,1217411b0437c6b4052bfd7831c68cd4a7ab93bf,pep8-test,"""""""Tests for swift.common.db"""""" 'No valid database connection', timeout=1357) self.assertEquals( chexor('d41d8cd98f00b204e9800998ecf8427e', 'new name', normalize_timestamp(1)), 'd41d8cd98f00b204e9800998ecf8427e', None, normalize_timestamp(1)) self.assertEquals(test_size[0], 1024 * 1024) broker.initialize, normalize_timestamp('1')) for v in m2.itervalues())) self.assertEquals( str(exc), self.assertEquals( str(exc), points = [(r[0], r[1]) for r in conn.execute( 'SELECT sync_point, ' points = [(r[0], r[1]) for r in conn.execute( 'SELECT sync_point, ' points = [(r[0], r[1]) for r in conn.execute( 'SELECT sync_point, ' {'Test': ('Value', normalize_timestamp(1))}) or '' self.assertEquals(info, { 'count': 0, self.assertEquals(info, { 'count': 1, self.assertEquals(info, { 'count': 0, 'd41d8cd98f00b204e9800998ecf8427e') 'd41d8cd98f00b204e9800998ecf8427e') 'd41d8cd98f00b204e9800998ecf8427e') 'd41d8cd98f00b204e9800998ecf8427e') listing = broker.list_objects_iter(10, '2/', None, None, '/') ['3/0045/', '3/0046', '3/0046/', '3/0047', '3/0047/', '3/0048', '3/0048/', '3/0049', '3/0049/', '3/0050']) self.assertEquals( [row[0] for row in listing], '3/0049/0049', '3/0050', '3/0050/0049', '3/0051', '3/0051/0049', '3/0052', '3/0052/0049']) self.assertEquals( [row[0] for row in listing], '3/0050/', '3/0051', '3/0051/', '3/0052', '3/0052/', '3/0053']) self.assertEquals( [row[0] for row in listing], listing = broker.list_objects_iter(10, '2:', None, None, ':') ['3:0045:', '3:0046', '3:0046:', '3:0047', '3:0047:', '3:0048', '3:0048:', '3:0049', '3:0049:', '3:0050']) self.assertEquals( [row[0] for row in listing], '3:0049:0049', '3:0050', '3:0050:0049', '3:0051', '3:0051:0049', '3:0052', '3:0052:0049']) self.assertEquals( [row[0] for row in listing], '3:0050:', '3:0051', '3:0051:', '3:0052', '3:0052:', '3:0053']) self.assertEquals( [row[0] for row in listing], broker.put_object( '/pets/dogs/1', normalize_timestamp(0), 0, broker.put_object( '/pets/dogs/2', normalize_timestamp(0), 0, broker.put_object( '/pets/fish/a', normalize_timestamp(0), 0, broker.put_object( '/pets/fish/b', normalize_timestamp(0), 0, broker.put_object( '/pets/fish_info.txt', normalize_timestamp(0), 0, broker.put_object( '/snakes', normalize_timestamp(0), 0, self.assertEquals( [row[0] for row in listing], ['0', '0/', '0/0', '0/00', '0/1', '0/1/', '0/1/0', '00', '1', '1/', '1/0', 'a', 'a/', 'a/0', 'a/a', 'a/a/a', 'a/a/b', 'a/b', 'b', 'b/a', 'b/b', 'c']) self.assertEquals( [row[0] for row in listing], ['0', '0/', '00', '1', '1/', 'a', 'a/', 'b', 'b/', 'c']) self.assertEquals( [row[0] for row in listing], ['a/', 'a/0', 'a/a', 'a/a/', 'a/b']) self.assertEquals( [row[0] for row in listing], ['0/', '0/0', '0/00', '0/1', '0/1/']) self.assertEquals( [row[0] for row in listing], ['0/1/', '0/1/0']) self.assertEquals( [row[0] for row in listing], ['0', '00', '0:', '0:0', '0:00', '0:1', '0:1:', '0:1:0', '1', '1:', '1:0', 'a', 'a:', 'a:0', 'a:a', 'a:a:a', 'a:a:b', 'a:b', 'b', 'b:a', 'b:b', 'c']) self.assertEquals( [row[0] for row in listing], ['0', '00', '0:', '1', '1:', 'a', 'a:', 'b', 'b:', 'c']) self.assertEquals( [row[0] for row in listing], ['a:', 'a:0', 'a:a', 'a:a:', 'a:b']) self.assertEquals( [row[0] for row in listing], ['0:', '0:0', '0:00', '0:1', '0:1:']) self.assertEquals( [row[0] for row in listing], ['0:1:', '0:1:0']) hashc = ''.join( ('%2x' % (ord(a) ^ ord(b)) for a, b in zip(hasha, hashb))) hashc = ''.join( ('%02x' % (ord(a) ^ ord(b)) for a, b in zip(hasha, hashb))) 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') conn.executescript(''' ''') ['3-0045-', '3-0046', '3-0046-', '3-0047', '3-0047-', '3-0048', '3-0048-', '3-0049', '3-0049-', '3-0050']) ['3-0048-0049', '3-0049', '3-0049-', '3-0049-0049', '3-0050', '3-0050-0049', '3-0051', '3-0051-0049', '3-0052', '3-0052-0049']) ['3-0048-', '3-0049', '3-0049-', '3-0050', '3-0050-', '3-0051', '3-0051-', '3-0052', '3-0052-', '3-0053']) ['a', 'a-', 'a-a', 'a-a-a', 'a-a-b', 'a-b', 'b', 'b-a', 'b-b', 'c']) hasha = hashlib.md5( '%s-%s' % ('a', '0000000001.00000-0000000000.00000-0-0') hashb = hashlib.md5( '%s-%s' % ('b', '0000000002.00000-0000000000.00000-0-0') hashb = hashlib.md5( '%s-%s' % ('b', '0000000003.00000-0000000000.00000-0-0') conn.executescript(''' ''') put_timestamp))",""""""" Tests for swift.common.db """""" 'No valid database connection', timeout=1357) self.assertEquals(chexor('d41d8cd98f00b204e9800998ecf8427e', 'new name', normalize_timestamp(1)), 'd41d8cd98f00b204e9800998ecf8427e', None, normalize_timestamp(1)) self.assertEquals(test_size[0], 1024*1024) broker.initialize, normalize_timestamp('1')) for v in m2.itervalues())) self.assertEquals(str(exc), self.assertEquals(str(exc), points = [(r[0], r[1]) for r in conn.execute('SELECT sync_point, ' points = [(r[0], r[1]) for r in conn.execute('SELECT sync_point, ' points = [(r[0], r[1]) for r in conn.execute('SELECT sync_point, ' {'Test': ('Value', normalize_timestamp(1))}) or '' self.assertEquals(info, {'count': 0, self.assertEquals(info, {'count': 1, self.assertEquals(info, {'count': 0, 'd41d8cd98f00b204e9800998ecf8427e') 'd41d8cd98f00b204e9800998ecf8427e') 'd41d8cd98f00b204e9800998ecf8427e') 'd41d8cd98f00b204e9800998ecf8427e') listing = broker.list_objects_iter(10, '2/', None, None, '/') ['3/0045/', '3/0046', '3/0046/', '3/0047', '3/0047/', '3/0048', '3/0048/', '3/0049', '3/0049/', '3/0050']) self.assertEquals([row[0] for row in listing], '3/0049/0049', '3/0050', '3/0050/0049', '3/0051', '3/0051/0049', '3/0052', '3/0052/0049']) self.assertEquals([row[0] for row in listing], '3/0050/', '3/0051', '3/0051/', '3/0052', '3/0052/', '3/0053']) self.assertEquals([row[0] for row in listing], listing = broker.list_objects_iter(10, '2:', None, None, ':') ['3:0045:', '3:0046', '3:0046:', '3:0047', '3:0047:', '3:0048', '3:0048:', '3:0049', '3:0049:', '3:0050']) self.assertEquals([row[0] for row in listing], '3:0049:0049', '3:0050', '3:0050:0049', '3:0051', '3:0051:0049', '3:0052', '3:0052:0049']) self.assertEquals([row[0] for row in listing], '3:0050:', '3:0051', '3:0051:', '3:0052', '3:0052:', '3:0053']) self.assertEquals([row[0] for row in listing], broker.put_object('/pets/dogs/1', normalize_timestamp(0), 0, broker.put_object('/pets/dogs/2', normalize_timestamp(0), 0, broker.put_object('/pets/fish/a', normalize_timestamp(0), 0, broker.put_object('/pets/fish/b', normalize_timestamp(0), 0, broker.put_object('/pets/fish_info.txt', normalize_timestamp(0), 0, broker.put_object('/snakes', normalize_timestamp(0), 0, self.assertEquals([row[0] for row in listing], ['0', '0/', '0/0', '0/00', '0/1', '0/1/', '0/1/0', '00', '1', '1/', '1/0', 'a', 'a/', 'a/0', 'a/a', 'a/a/a', 'a/a/b', 'a/b', 'b', 'b/a', 'b/b', 'c']) self.assertEquals([row[0] for row in listing], ['0', '0/', '00', '1', '1/', 'a', 'a/', 'b', 'b/', 'c']) self.assertEquals([row[0] for row in listing], ['a/', 'a/0', 'a/a', 'a/a/', 'a/b']) self.assertEquals([row[0] for row in listing], ['0/', '0/0', '0/00', '0/1', '0/1/']) self.assertEquals([row[0] for row in listing], ['0/1/', '0/1/0']) self.assertEquals([row[0] for row in listing], ['0', '00', '0:', '0:0', '0:00', '0:1', '0:1:', '0:1:0', '1', '1:', '1:0', 'a', 'a:', 'a:0', 'a:a', 'a:a:a', 'a:a:b', 'a:b', 'b', 'b:a', 'b:b', 'c']) self.assertEquals([row[0] for row in listing], ['0', '00', '0:', '1', '1:', 'a', 'a:', 'b', 'b:', 'c']) self.assertEquals([row[0] for row in listing], ['a:', 'a:0', 'a:a', 'a:a:', 'a:b']) self.assertEquals([row[0] for row in listing], ['0:', '0:0', '0:00', '0:1', '0:1:']) self.assertEquals([row[0] for row in listing], ['0:1:', '0:1:0']) hashc = ''.join(('%2x' % (ord(a) ^ ord(b)) for a, b in zip(hasha, hashb))) hashc = ''.join(('%02x' % (ord(a) ^ ord(b)) for a, b in zip(hasha, hashb))) 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') 'text/plain', 'd41d8cd98f00b204e9800998ecf8427e') conn.executescript("""""" """""") ['3-0045-', '3-0046', '3-0046-', '3-0047', '3-0047-', '3-0048', '3-0048-', '3-0049', '3-0049-', '3-0050']) ['3-0048-0049', '3-0049', '3-0049-', '3-0049-0049', '3-0050', '3-0050-0049', '3-0051', '3-0051-0049', '3-0052', '3-0052-0049']) ['3-0048-', '3-0049', '3-0049-', '3-0050', '3-0050-', '3-0051', '3-0051-', '3-0052', '3-0052-', '3-0053']) ['a', 'a-', 'a-a', 'a-a-a', 'a-a-b', 'a-b', 'b', 'b-a', 'b-b', 'c']) hasha = hashlib.md5('%s-%s' % ('a', '0000000001.00000-0000000000.00000-0-0') hashb = hashlib.md5('%s-%s' % ('b', '0000000002.00000-0000000000.00000-0-0') hashb = hashlib.md5('%s-%s' % ('b', '0000000003.00000-0000000000.00000-0-0') conn.executescript("""""" """""") put_timestamp))",292,224
openstack%2Ftaskflow~master~Ia4773b28418a6fab42c8dbd1ebfbe88c1879a4be,openstack/taskflow,master,Ia4773b28418a6fab42c8dbd1ebfbe88c1879a4be,"Engine, task, flow, patterns unification",ABANDONED,2013-09-04 05:48:54.000000000,2013-09-04 23:22:43.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2013-09-04 05:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f865c77a80e6adcdff6b663af12f9539b80c7de0', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: Ia4773b28418a6fab42c8dbd1ebfbe88c1879a4be\n'}, {'number': 2, 'created': '2013-09-04 05:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6964267c73310cbe239200aba78fd8b748ffdba7', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: Ia4773b28418a6fab42c8dbd1ebfbe88c1879a4be\n'}, {'number': 3, 'created': '2013-09-04 05:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/400d035f76d42e28d2977d8c388f426373b6bd4e', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: Ia4773b28418a6fab42c8dbd1ebfbe88c1879a4be\n'}, {'number': 4, 'created': '2013-09-04 06:04:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4ae5b3f5d81c51bb548acd4c73a76c8238a998be', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: Ia4773b28418a6fab42c8dbd1ebfbe88c1879a4be\n'}, {'number': 5, 'created': '2013-09-04 06:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/34ae67ce2c2e06118567e88cf67b3fb21f7850db', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: Ia4773b28418a6fab42c8dbd1ebfbe88c1879a4be\n'}, {'number': 6, 'created': '2013-09-04 06:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e8571a8472a51167e3632aaa4c83385b659d9b49', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: Ia4773b28418a6fab42c8dbd1ebfbe88c1879a4be\n'}, {'number': 7, 'created': '2013-09-04 07:05:24.000000000', 'files': ['taskflow/engines/action_engine/seq_action.py', 'taskflow/blocks/patterns.py', 'taskflow/engines/action_engine/__init__.py', 'taskflow/blocks/__init__.py', 'taskflow/flow.py', 'taskflow/patterns/linear_flow.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/task.py', 'taskflow/engines/action_engine/base_action.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/blocks/base.py', 'taskflow/blocks/task.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/386f920e89f18b5e2d3b281c0a3d847cba8fa7c2', 'message': 'Engine, task, flow, patterns unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: Ia4773b28418a6fab42c8dbd1ebfbe88c1879a4be\n'}]",0,45009,386f920e89f18b5e2d3b281c0a3d847cba8fa7c2,10,2,7,1297,,,0,"Engine, task, flow, patterns unification

Instead of keeping the existing flows with there functionality
move the existing flows to just be the thing that defines the
runtime structure. Have the action_engine translate these
structures into something useful, which in the case of action_engine
is translating the structures into things that are pretty much
like the existing flows (but not exactly).

Change-Id: Ia4773b28418a6fab42c8dbd1ebfbe88c1879a4be
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/09/45009/3 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/seq_action.py', 'taskflow/flow.py', 'taskflow/patterns/linear_flow.py', 'taskflow/blocks/patterns.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/task.py', 'taskflow/engines/action_engine/base_action.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/blocks/__init__.py', 'taskflow/blocks/base.py', 'taskflow/blocks/task.py']",11,f865c77a80e6adcdff6b663af12f9539b80c7de0,master,," # -*- coding: utf-8 -*- # vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (C) 2012-2013 Yahoo! Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Terminal blocks that actually run code """""" from taskflow.blocks import base from taskflow.openstack.common import uuidutils class Task(base.Block): """"""A block that wraps a single task The task should be executed, and produced results should be saved. """""" def __init__(self, task, uuid=None): super(Task, self).__init__() self._task = task if uuid is None: self._id = uuidutils.generate_uuid() else: self._id = str(uuid) @property def task(self): return self._task @property def uuid(self): return self._id ",210,646
openstack%2Ftaskflow~master~Iab5c37bf83398bd40ff8c4a58d30133cb321a019,openstack/taskflow,master,Iab5c37bf83398bd40ff8c4a58d30133cb321a019,The functionality of tasks is the same as runners,ABANDONED,2013-09-03 22:36:58.000000000,2013-09-04 23:21:59.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-09-03 22:36:58.000000000', 'files': ['taskflow/blocks/task.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/62951b03ddf2d439e58adaf92d38819b63dadc00', 'message': 'The functionality of tasks is the same as runners\n\nReuse the same runner class instead of recreating a\nminiature version for blocks.\n\nChange-Id: Iab5c37bf83398bd40ff8c4a58d30133cb321a019\n'}]",0,44971,62951b03ddf2d439e58adaf92d38819b63dadc00,2,1,1,1297,,,0,"The functionality of tasks is the same as runners

Reuse the same runner class instead of recreating a
miniature version for blocks.

Change-Id: Iab5c37bf83398bd40ff8c4a58d30133cb321a019
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/71/44971/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/blocks/task.py'],1,62951b03ddf2d439e58adaf92d38819b63dadc00,,from taskflow.utils import flow_utils class Task(flow_utils.Runner):,"from taskflow.blocks import base from taskflow.openstack.common import uuidutils class Task(base.Block): def __init__(self, task, uuid=None): super(Task, self).__init__() self._task = task if uuid is None: self._id = uuidutils.generate_uuid() else: self._id = str(uuid) @property def task(self): return self._task @property def uuid(self): return self._id",2,19
openstack%2Fheat~master~I9f36d98e91d5175b354e423d7159e690b1e5b696,openstack/heat,master,I9f36d98e91d5175b354e423d7159e690b1e5b696,Fix AttributeError exception in autoscaling,MERGED,2013-09-04 14:17:42.000000000,2013-09-04 23:19:53.000000000,2013-09-04 22:54:42.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 6456}, {'_account_id': 6794}]","[{'number': 1, 'created': '2013-09-04 14:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2d1ed7a4eb888147966d187ffa39fd1aa5ed6771', 'message': ""Fix AttributeError exception in autoscaling\n\nUse the nested() method instead of directly accessing the _nested\nattribute which isn't always initialized.\n\nBug: fixes #1220737\nChange-Id: I9f36d98e91d5175b354e423d7159e690b1e5b696\n""}, {'number': 2, 'created': '2013-09-04 15:59:31.000000000', 'files': ['heat/engine/resources/autoscaling.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/fceff8b9651e3e43c72be679448802111a17d17c', 'message': ""Fix AttributeError exception in autoscaling\n\nUse the nested() method instead of directly accessing the _nested\nattribute which isn't always initialized.\n\nFixes bug #1220737\nChange-Id: I9f36d98e91d5175b354e423d7159e690b1e5b696\n""}]",2,45066,fceff8b9651e3e43c72be679448802111a17d17c,13,5,2,6794,,,0,"Fix AttributeError exception in autoscaling

Use the nested() method instead of directly accessing the _nested
attribute which isn't always initialized.

Fixes bug #1220737
Change-Id: I9f36d98e91d5175b354e423d7159e690b1e5b696
",git fetch https://review.opendev.org/openstack/heat refs/changes/66/45066/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/autoscaling.py'],1,2d1ed7a4eb888147966d187ffa39fd1aa5ed6771,bug/1220737, for inst in self.nested().resources.values()], for inst in self._nested.resources.values()],1,1
openstack%2Fironic~master~Ic82181c7aa85515a5a2bba49c8dc8d35b495742c,openstack/ironic,master,Ic82181c7aa85515a5a2bba49c8dc8d35b495742c,Add missing foreign key,MERGED,2013-08-27 14:02:25.000000000,2013-09-04 23:00:20.000000000,2013-09-04 23:00:20.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 4919}, {'_account_id': 5805}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-08-27 14:02:25.000000000', 'files': ['ironic/db/sqlalchemy/migrate_repo/versions/010_add_chassis_id_fk.py', 'ironic/tests/db/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c3737e4a9b5845834a159e694c2a5ea5c7e463cf', 'message': 'Add missing foreign key\n\nChassis table is created after nodes table, there\nis missing foreign key nodes.chassis_id -> chassis.id.\nThis patch adds missing FK in separate migration.\n\nChange-Id: Ic82181c7aa85515a5a2bba49c8dc8d35b495742c\n'}]",0,43888,c3737e4a9b5845834a159e694c2a5ea5c7e463cf,8,5,1,7711,,,0,"Add missing foreign key

Chassis table is created after nodes table, there
is missing foreign key nodes.chassis_id -> chassis.id.
This patch adds missing FK in separate migration.

Change-Id: Ic82181c7aa85515a5a2bba49c8dc8d35b495742c
",git fetch https://review.opendev.org/openstack/ironic refs/changes/88/43888/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/db/sqlalchemy/migrate_repo/versions/010_add_chassis_id_fk.py', 'ironic/tests/db/sqlalchemy/test_migrations.py']",2,c3737e4a9b5845834a159e694c2a5ea5c7e463cf,missing-fk," def _check_010(self, engine, data): insp = sqlalchemy.engine.reflection.Inspector.from_engine(engine) f_keys = insp.get_foreign_keys('nodes') self.assertEqual(len(f_keys), 1) f_key = f_keys[0] self.assertEqual(f_key['referred_table'], 'chassis') self.assertEqual(f_key['referred_columns'], ['id']) self.assertEqual(f_key['constrained_columns'], ['chassis_id'])",,40,0
openstack%2Fironic~master~Ic2c44519d51699b2223d8252baa6a3da1f412795,openstack/ironic,master,Ic2c44519d51699b2223d8252baa6a3da1f412795,Sync models with migrations,MERGED,2013-08-23 17:19:04.000000000,2013-09-04 23:00:20.000000000,2013-09-04 23:00:20.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 4919}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-08-23 17:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f4ee41ff358667ba2783453208125ed391490a4d', 'message': 'Sync models with migrations\n\nThis patch corrects errors in the models definitions.\n\nChange-Id: Ic2c44519d51699b2223d8252baa6a3da1f412795\n'}, {'number': 2, 'created': '2013-08-27 12:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ea05c4ba0aab16eab6af001243fb8ae6c2a4b11b', 'message': 'Sync models with migrations\n\nIronic project use migrations for create DB.\nThere is difference between DB after all migrations\nand models. This patch fix models and sync them\nwith real DB state after all migrations.\n\nChange-Id: Ic2c44519d51699b2223d8252baa6a3da1f412795\n'}, {'number': 3, 'created': '2013-08-30 08:04:26.000000000', 'files': ['ironic/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a80e808ba02732b903585ed760b1d674128e575d', 'message': 'Sync models with migrations\n\nIronic project use migrations for create DB.\nThere is difference between DB after all migrations\nand models. This patch fix models and sync them\nwith real DB state after all migrations.\n\nChange-Id: Ic2c44519d51699b2223d8252baa6a3da1f412795\n'}]",12,43509,a80e808ba02732b903585ed760b1d674128e575d,20,6,3,7711,,,0,"Sync models with migrations

Ironic project use migrations for create DB.
There is difference between DB after all migrations
and models. This patch fix models and sync them
with real DB state after all migrations.

Change-Id: Ic2c44519d51699b2223d8252baa6a3da1f412795
",git fetch https://review.opendev.org/openstack/ironic refs/changes/09/43509/3 && git format-patch -1 --stdout FETCH_HEAD,['ironic/db/sqlalchemy/models.py'],1,f4ee41ff358667ba2783453208125ed391490a4d,db-models,"from sqlalchemy import Column, Index, ForeignKey, schema uuid = Column(String(36)) __table_args__ = ( schema.UniqueConstraint('uuid', name='node_uuid_ux'), Index('node_instance_uuid', 'instance_uuid') ) uuid = Column(String(36)) instance_uuid = Column(String(36), nullable=True) __table_args__ = ( schema.UniqueConstraint('address', name='iface_address_ux'), schema.UniqueConstraint('uuid', name='port_uuid_ux') ) uuid = Column(String(36)) address = Column(String(18))","from sqlalchemy import Column, ForeignKey uuid = Column(String(36), unique=True) uuid = Column(String(36), unique=True) instance_uuid = Column(String(36), nullable=True, unique=True) uuid = Column(String(36), unique=True) address = Column(String(18), unique=True)",14,6
openstack%2Fironic~master~I59cf6e10ff00b3787e2bd60082ca872348157ec8,openstack/ironic,master,I59cf6e10ff00b3787e2bd60082ca872348157ec8,Porting nova pxe driver to ironic,MERGED,2013-06-19 09:09:17.000000000,2013-09-04 23:00:19.000000000,2013-09-04 23:00:19.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 7711}]","[{'number': 1, 'created': '2013-06-19 09:09:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1aadb51f1ec7ae2ffbecc3a9988a97a8456964f2', 'message': 'Pxe driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}, {'number': 2, 'created': '2013-06-19 18:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/095db1e2b1feea82b435a08210e0e1c65f209c98', 'message': 'Pxe driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}, {'number': 3, 'created': '2013-06-24 10:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2722d396493384a589a76d4f6fb3153e27fc8165', 'message': 'Pxe driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}, {'number': 4, 'created': '2013-06-25 10:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c234fa9f4a1a92e0db5fee1bdf119e50baed1817', 'message': 'Pxe driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}, {'number': 5, 'created': '2013-07-02 11:30:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9fdb3cdc83fd86620d3f3e82cb4cfc83964394d8', 'message': 'Porting nova pxe driver to ironic.\n\nImplements: blueprint equivalent-pxe-driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}, {'number': 6, 'created': '2013-07-08 15:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5741e75529b71b5bbf4394c74b4264003d153425', 'message': 'Porting nova pxe driver to ironic.\n\nImplements: blueprint equivalent-pxe-driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}, {'number': 7, 'created': '2013-07-12 11:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/aa78a657483ae262ceb412b51e5628acaa2ebc21', 'message': 'Porting nova pxe driver to ironic.\n\nImplements: blueprint equivalent-pxe-driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}, {'number': 8, 'created': '2013-07-19 07:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/91f4ea418450eb3df9d70387b2c36025cb499875', 'message': 'Porting nova pxe driver to ironic.\n\nImplements: blueprint equivalent-pxe-driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}, {'number': 9, 'created': '2013-08-13 22:14:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c1ecccf269f2544422968fb4852652b7a408a155', 'message': 'Porting nova pxe driver to ironic\n\nImplements: blueprint equivalent-pxe-driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}, {'number': 10, 'created': '2013-08-15 10:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2430b3482a86344cc9aac279b6419c235d8b8914', 'message': 'Porting nova pxe driver to ironic\n\nImplements: blueprint equivalent-pxe-driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}, {'number': 11, 'created': '2013-08-15 18:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2c29d2ce3680acc0efb41fa8a3471ee183e452b4', 'message': 'Porting nova pxe driver to ironic\n\nImplements: blueprint equivalent-pxe-driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}, {'number': 12, 'created': '2013-08-26 07:46:20.000000000', 'files': ['ironic/tests/nova/test_pxe.py', 'ironic/tests/db/utils.py', 'ironic/tests/drivers/test_pxe.py', 'ironic/tests/drivers/pxe_config.template', 'ironic/drivers/modules/pxe_config.template', 'ironic/common/exception.py', 'requirements.txt', 'ironic/drivers/modules/pxe.py', 'ironic/tests/test_images.py', 'ironic/common/images.py', 'etc/ironic/rootwrap.d/ironic-images.filters', 'ironic/nova/pxe.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/17b828796e10d513d18d4befec65fe3f778039b6', 'message': 'Porting nova pxe driver to ironic\n\nImplements: blueprint equivalent-pxe-driver\n\nChange-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8\n'}]",67,33616,17b828796e10d513d18d4befec65fe3f778039b6,53,7,12,1726,,,0,"Porting nova pxe driver to ironic

Implements: blueprint equivalent-pxe-driver

Change-Id: I59cf6e10ff00b3787e2bd60082ca872348157ec8
",git fetch https://review.opendev.org/openstack/ironic refs/changes/16/33616/12 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/exception.py', 'ironic/drivers/modules/pxe.py', 'ironic/common/images.py', 'openstack-common.conf', 'ironic/openstack/common/fileutils.py', 'ironic/openstack/common/strutils.py']",6,1aadb51f1ec7ae2ffbecc3a9988a97a8456964f2,bp/equivalent-pxe-driver,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" System-level utilities and helper functions. """""" import re import sys import unicodedata from ironic.openstack.common.gettextutils import _ # Used for looking up extensions of text # to their 'multiplied' byte amount BYTE_MULTIPLIERS = { '': 1, 't': 1024 ** 4, 'g': 1024 ** 3, 'm': 1024 ** 2, 'k': 1024, } BYTE_REGEX = re.compile(r'(^-?\d+)(\D*)') TRUE_STRINGS = ('1', 't', 'true', 'on', 'y', 'yes') FALSE_STRINGS = ('0', 'f', 'false', 'off', 'n', 'no') SLUGIFY_STRIP_RE = re.compile(r""[^\w\s-]"") SLUGIFY_HYPHENATE_RE = re.compile(r""[-\s]+"") def int_from_bool_as_string(subject): """"""Interpret a string as a boolean and return either 1 or 0. Any string value in: ('True', 'true', 'On', 'on', '1') is interpreted as a boolean True. Useful for JSON-decoded stuff and config file parsing """""" return bool_from_string(subject) and 1 or 0 def bool_from_string(subject, strict=False): """"""Interpret a string as a boolean. A case-insensitive match is performed such that strings matching 't', 'true', 'on', 'y', 'yes', or '1' are considered True and, when `strict=False`, anything else is considered False. Useful for JSON-decoded stuff and config file parsing. If `strict=True`, unrecognized values, including None, will raise a ValueError which is useful when parsing values passed in from an API call. Strings yielding False are 'f', 'false', 'off', 'n', 'no', or '0'. """""" if not isinstance(subject, basestring): subject = str(subject) lowered = subject.strip().lower() if lowered in TRUE_STRINGS: return True elif lowered in FALSE_STRINGS: return False elif strict: acceptable = ', '.join( ""'%s'"" % s for s in sorted(TRUE_STRINGS + FALSE_STRINGS)) msg = _(""Unrecognized value '%(val)s', acceptable values are:"" "" %(acceptable)s"") % {'val': subject, 'acceptable': acceptable} raise ValueError(msg) else: return False def safe_decode(text, incoming=None, errors='strict'): """"""Decodes incoming str using `incoming` if they're not already unicode. :param incoming: Text's current encoding :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: text or a unicode `incoming` encoded representation of it. :raises TypeError: If text is not an isntance of basestring """""" if not isinstance(text, basestring): raise TypeError(""%s can't be decoded"" % type(text)) if isinstance(text, unicode): return text if not incoming: incoming = (sys.stdin.encoding or sys.getdefaultencoding()) try: return text.decode(incoming, errors) except UnicodeDecodeError: # Note(flaper87) If we get here, it means that # sys.stdin.encoding / sys.getdefaultencoding # didn't return a suitable encoding to decode # text. This happens mostly when global LANG # var is not set correctly and there's no # default encoding. In this case, most likely # python will use ASCII or ANSI encoders as # default encodings but they won't be capable # of decoding non-ASCII characters. # # Also, UTF-8 is being used since it's an ASCII # extension. return text.decode('utf-8', errors) def safe_encode(text, incoming=None, encoding='utf-8', errors='strict'): """"""Encodes incoming str/unicode using `encoding`. If incoming is not specified, text is expected to be encoded with current python's default encoding. (`sys.getdefaultencoding`) :param incoming: Text's current encoding :param encoding: Expected encoding for text (Default UTF-8) :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: text or a bytestring `encoding` encoded representation of it. :raises TypeError: If text is not an isntance of basestring """""" if not isinstance(text, basestring): raise TypeError(""%s can't be encoded"" % type(text)) if not incoming: incoming = (sys.stdin.encoding or sys.getdefaultencoding()) if isinstance(text, unicode): return text.encode(encoding, errors) elif text and encoding != incoming: # Decode text before encoding it with `encoding` text = safe_decode(text, incoming, errors) return text.encode(encoding, errors) return text def to_bytes(text, default=0): """"""Converts a string into an integer of bytes. Looks at the last characters of the text to determine what conversion is needed to turn the input text into a byte number. Supports ""B, K(B), M(B), G(B), and T(B)"". (case insensitive) :param text: String input for bytes size conversion. :param default: Default return value when text is blank. """""" match = BYTE_REGEX.search(text) if match: magnitude = int(match.group(1)) mult_key_org = match.group(2) if not mult_key_org: return magnitude elif text: msg = _('Invalid string format: %s') % text raise TypeError(msg) else: return default mult_key = mult_key_org.lower().replace('b', '', 1) multiplier = BYTE_MULTIPLIERS.get(mult_key) if multiplier is None: msg = _('Unknown byte multiplier: %s') % mult_key_org raise TypeError(msg) return magnitude * multiplier def to_slug(value, incoming=None, errors=""strict""): """"""Normalize string. Convert to lowercase, remove non-word characters, and convert spaces to hyphens. Inspired by Django's `slugify` filter. :param value: Text to slugify :param incoming: Text's current encoding :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: slugified unicode representation of `value` :raises TypeError: If text is not an instance of basestring """""" value = safe_decode(value, incoming, errors) # NOTE(aababilov): no need to use safe_(encode|decode) here: # encodings are always ""ascii"", error handling is always ""ignore"" # and types are always known (first: unicode; second: str) value = unicodedata.normalize(""NFKD"", value).encode( ""ascii"", ""ignore"").decode(""ascii"") value = SLUGIFY_STRIP_RE.sub("""", value).strip().lower() return SLUGIFY_HYPHENATE_RE.sub(""-"", value) ",,841,9
openstack%2Fglance~master~Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed,openstack/glance,master,Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed,Introduced DB pooling for non blocking DB calls,MERGED,2013-08-09 13:57:49.000000000,2013-09-04 22:57:39.000000000,2013-09-04 22:57:39.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 616}, {'_account_id': 1030}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 7531}, {'_account_id': 8367}]","[{'number': 1, 'created': '2013-08-09 13:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/199d20aa9d0964ee7ed0d23ac1f649aef40e88f6', 'message': 'Introduced Mysql thread pool\n\nIntroduced pooling for non blocking DB calls\nGetting the api from oslo-incubator and having a common\nDBAPI object that delegates to the corresponding db api\n(sqlalchemy/simple db).\nBy default use_tpool is False\n\nRelated to bp mysql-thread-pool\n\nChange-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed\n'}, {'number': 2, 'created': '2013-08-10 14:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/601bc473b0a4eac56a1ed857863a43ee340da109', 'message': 'Introduce Mysql thread pool\n\nIntroduced pooling for non blocking DB calls\nGetting the api from oslo-incubator and having a common\nDBAPI object that delegates to the corresponding db api\n(sqlalchemy/simple db).\nBy default use_tpool is False\n\nRelated to bp mysql-thread-pool\n\nChange-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed\n'}, {'number': 3, 'created': '2013-08-13 14:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/34107c7445952cb7471a719f3ccbc1542ab09615', 'message': 'Introduced DB pooling for non blocking DB calls\n\nUsing common db api from oslo-incubator. The enclosing\nDBAPI object delegates to the corresponding db api\n(sqlalchemy/simple db).\nBy default use_tpool is False\n\nChange-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed\n'}, {'number': 4, 'created': '2013-08-13 15:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/093bd525734a48c39be923ba84383c13e2eb9b13', 'message': 'Introduced DB pooling for non blocking DB calls\n\nUsing common db api from oslo-incubator. The enclosing\nDBAPI object delegates to the corresponding db api\n(sqlalchemy/simple db).\nBy default use_tpool is False\n\nChange-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed\n'}, {'number': 5, 'created': '2013-08-20 15:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/76aee57603ff030256b4e2035e09826542ad0001', 'message': ""Introduced DB pooling for non blocking DB calls\n\nThe Sqlalchemy methods are wrapped with a decorator that checks for\nuse_tpool config and executes in a separate thread if it's enabled.\nuse_tpool is disabled (False) by default\n\nChange-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed\n""}, {'number': 6, 'created': '2013-08-21 07:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a9a2ec5a9e32f3f9e6906feee6c94fb87fceb208', 'message': "" Introduced DB pooling for non blocking DB calls\n\nThe Sqlalchemy methods are wrapped with a decorator that checks for\nuse_tpool config and executes in a separate thread if it's enabled.\nuse_tpool is disabled (False) by default\n\nChange-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed\n""}, {'number': 7, 'created': '2013-08-21 07:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/95aff111fc3ef88a3ab8863197c9e0343c7efc2e', 'message': "" Introduced DB pooling for non blocking DB calls\n\nThe Sqlalchemy methods are wrapped with a decorator that checks for\nuse_tpool config and executes in a separate thread if it's enabled.\nuse_tpool is disabled (False) by default\n\nRelated to bp mysql-thread-pool\n\nChange-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed\n""}, {'number': 8, 'created': '2013-08-26 14:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/742b1c49e48674c1a4576055aa2a96def64d8e52', 'message': 'Introduced DB pooling for non blocking DB calls\n\nThe DbApi module is wrapped with the tpool wrapper if the configuration is\nenabled. use_tpool is disabled (False) by default\n\nRelated to bp mysql-thread-pool\n\nChange-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed\n'}, {'number': 9, 'created': '2013-08-27 04:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4ada3c9cbd04bfef765dacc6434967f92199ea0d', 'message': 'Introduced DB pooling for non blocking DB calls\n\nThe DbApi module is wrapped with the tpool wrapper if the configuration is\nenabled. use_tpool is disabled (False) by default\n\nRelated to bp mysql-thread-pool\n\nChange-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed\n'}, {'number': 10, 'created': '2013-08-27 04:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ca7fcc1b7e9345b542f092d8873f3059545b2b47', 'message': 'Introduced DB pooling for non blocking DB calls\n\nThe DbApi module is wrapped with the tpool wrapper if the configuration is\nenabled. use_tpool is disabled (False) by default\n\nRelated to bp mysql-thread-pool\n\nChange-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed\n'}, {'number': 11, 'created': '2013-08-27 05:28:09.000000000', 'files': ['test-requirements.txt', 'glance/db/__init__.py', 'glance/tests/functional/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/247ada2d94e519411bc0c07dc5e54c8190f04f07', 'message': 'Introduced DB pooling for non blocking DB calls\n\nThe DbApi module is wrapped with the tpool wrapper if the configuration is\nenabled. use_tpool is disabled (False) by default\n\nRelated to bp mysql-thread-pool\n\nChange-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed\n'}]",10,41092,247ada2d94e519411bc0c07dc5e54c8190f04f07,50,8,11,7531,,,0,"Introduced DB pooling for non blocking DB calls

The DbApi module is wrapped with the tpool wrapper if the configuration is
enabled. use_tpool is disabled (False) by default

Related to bp mysql-thread-pool

Change-Id: Ie7274ac855549b96c581c3eb0bcf79f3c74be0ed
",git fetch https://review.opendev.org/openstack/glance refs/changes/92/41092/4 && git format-patch -1 --stdout FETCH_HEAD,"['glance/registry/api/v1/images.py', 'glance/tests/unit/db/test_api.py', 'glance/db/simple/api.py', 'glance/db/__init__.py', 'glance/tests/functional/db/test_registry.py', 'glance/db/api.py', 'glance/db/sqlalchemy/api.py', 'glance/openstack/common/importutils.py', 'glance/openstack/common/gettextutils.py', 'glance/openstack/common/timeutils.py', 'glance/tests/functional/db/test_simple.py', 'glance/openstack/common/local.py', 'glance/openstack/common/excutils.py', 'glance/openstack/common/lockutils.py', 'glance/openstack/common/jsonutils.py', 'glance/tests/unit/db/__init__.py', 'openstack-common.conf', 'glance/openstack/common/log.py', 'glance/tests/functional/db/test_sqlalchemy.py', 'glance/db/registry/api.py', 'glance/openstack/common/fileutils.py']",21,199d20aa9d0964ee7ed0d23ac1f649aef40e88f6,bp/mysql-thread-pool,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import contextlib import errno import os from glance.openstack.common import excutils from glance.openstack.common.gettextutils import _ # noqa from glance.openstack.common import log as logging LOG = logging.getLogger(__name__) _FILE_CACHE = {} def ensure_tree(path): """"""Create a directory (and any ancestor directories required) :param path: Directory to create """""" try: os.makedirs(path) except OSError as exc: if exc.errno == errno.EEXIST: if not os.path.isdir(path): raise else: raise def read_cached_file(filename, force_reload=False): """"""Read from a file if it has been modified. :param force_reload: Whether to reload the file. :returns: A tuple with a boolean specifying if the data is fresh or not. """""" global _FILE_CACHE if force_reload and filename in _FILE_CACHE: del _FILE_CACHE[filename] reloaded = False mtime = os.path.getmtime(filename) cache_info = _FILE_CACHE.setdefault(filename, {}) if not cache_info or mtime > cache_info.get('mtime', 0): LOG.debug(_(""Reloading cached file %s"") % filename) with open(filename) as fap: cache_info['data'] = fap.read() cache_info['mtime'] = mtime reloaded = True return (reloaded, cache_info['data']) def delete_if_exists(path): """"""Delete a file, but ignore file not found error. :param path: File to delete """""" try: os.unlink(path) except OSError as e: if e.errno == errno.ENOENT: return else: raise @contextlib.contextmanager def remove_path_on_error(path): """"""Protect code that wants to operate on PATH atomically. Any exception will cause PATH to be removed. :param path: File to work with """""" try: yield except Exception: with excutils.save_and_reraise_exception(): delete_if_exists(path) def file_open(*args, **kwargs): """"""Open file see built-in file() documentation for more details Note: The reason this is kept in a separate module is to easily be able to provide a stub module that doesn't alter system state at all (for unit tests) """""" return file(*args, **kwargs) ",,832,99
openstack%2Fnova~master~Ia15f00ee96d3c1d55d7c290f20ccc988e4c52e1a,openstack/nova,master,Ia15f00ee96d3c1d55d7c290f20ccc988e4c52e1a,Port Cheetah templates to Jinja2,MERGED,2013-08-05 11:49:33.000000000,2013-09-04 22:57:11.000000000,2013-09-04 22:57:09.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 4375}]","[{'number': 1, 'created': '2013-08-05 11:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/243efb571a274e651383ed463d90f79764d7c94d', 'message': ""Port Cheetah templates to Jinja2\n\nCheetah is unmaintained since 2010 and it's unlikely to get Python3\nsupport soon. Also, the rest of OpenStack (mostly) standardized on\nJinja2.\n\nChange-Id: Ia15f00ee96d3c1d55d7c290f20ccc988e4c52e1a\n""}, {'number': 2, 'created': '2013-08-09 15:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/23c618c0a454b0833806de55debb683329178261', 'message': ""Port Cheetah templates to Jinja2\n\nCheetah is unmaintained since 2010 and it's unlikely to get Python3\nsupport soon. Also, the rest of OpenStack (mostly) standardized on\nJinja2.\n\nChange-Id: Ia15f00ee96d3c1d55d7c290f20ccc988e4c52e1a\n""}, {'number': 3, 'created': '2013-08-12 06:51:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c70e778111ba5b0197d6088cff23ee0109492f0', 'message': ""Port Cheetah templates to Jinja2\n\nCheetah is unmaintained since 2010 and it's unlikely to get Python3\nsupport soon. Also, the rest of OpenStack (mostly) standardized on\nJinja2.\n\nImplements: blueprint jinja-templating-conversion\nChange-Id: Ia15f00ee96d3c1d55d7c290f20ccc988e4c52e1a\n""}, {'number': 4, 'created': '2013-09-02 14:00:22.000000000', 'files': ['nova/console/xvp.py', 'nova/virt/baremetal/net-dhcp.ubuntu.template', 'nova/virt/baremetal/net-static.ubuntu.template', 'nova/virt/xenapi/vm_utils.py', 'requirements.txt', 'nova/virt/baremetal/pxe_config.template', 'nova/virt/baremetal/pxe.py', 'nova/virt/baremetal/tilera.py', 'nova/console/xvp.conf.template', 'nova/cloudpipe/client.ovpn.template', 'nova/virt/interfaces.template', 'nova/virt/netutils.py', '.coveragerc'], 'web_link': 'https://opendev.org/openstack/nova/commit/fa0d61084e50c264f3231f997e4243b8037919f8', 'message': ""Port Cheetah templates to Jinja2\n\nCheetah is unmaintained since 2010 and it's unlikely to get Python3\nsupport soon. Also, the rest of OpenStack (mostly) standardized on\nJinja2.\n\nImplements: blueprint jinja-templating-conversion\nChange-Id: Ia15f00ee96d3c1d55d7c290f20ccc988e4c52e1a\n""}]",1,40205,fa0d61084e50c264f3231f997e4243b8037919f8,28,7,4,4375,,,0,"Port Cheetah templates to Jinja2

Cheetah is unmaintained since 2010 and it's unlikely to get Python3
support soon. Also, the rest of OpenStack (mostly) standardized on
Jinja2.

Implements: blueprint jinja-templating-conversion
Change-Id: Ia15f00ee96d3c1d55d7c290f20ccc988e4c52e1a
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/40205/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/console/xvp.py', 'nova/virt/baremetal/net-dhcp.ubuntu.template', 'nova/virt/baremetal/net-static.ubuntu.template', 'nova/virt/xenapi/vm_utils.py', 'requirements.txt', 'nova/virt/baremetal/pxe_config.template', 'nova/virt/baremetal/pxe.py', 'nova/virt/baremetal/tilera.py', 'nova/console/xvp.conf.template', 'nova/cloudpipe/client.ovpn.template', 'nova/virt/interfaces.template', 'nova/virt/netutils.py', '.coveragerc']",13,243efb571a274e651383ed463d90f79764d7c94d,bp/jinja-templating-conversion,"omit = nova/tests/*,nova/openstack/*","omit = nova/tests/*,nova/openstack/*,DynamicallyCompiledCheetahTemplate.py",99,136
openstack%2Fnova~master~I2b88eb28593043843a9ac0afd5bff7c268db0f60,openstack/nova,master,I2b88eb28593043843a9ac0afd5bff7c268db0f60,Remove versioning from IOVisor APIs PATH,MERGED,2013-09-03 22:41:23.000000000,2013-09-04 22:56:39.000000000,2013-09-04 22:56:37.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 8279}]","[{'number': 1, 'created': '2013-09-03 22:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f58001e0e4952fdf005d41b5ab27138f798dc841', 'message': 'Remove versioning from IOVisor APIs PATH\n\nFix bug #1220454\n\nChange-Id: I2b88eb28593043843a9ac0afd5bff7c268db0f60\n'}, {'number': 2, 'created': '2013-09-04 00:10:21.000000000', 'files': ['etc/nova/rootwrap.d/network.filters'], 'web_link': 'https://opendev.org/openstack/nova/commit/8fbd10ff3698fe9e805e84614ca9cad328ef2502', 'message': 'Remove versioning from IOVisor APIs PATH\n\nFix bug #1220454\n\nIn the first version of the IOVisor driver, versioning was included in the\nthe PATH of the native IOVisor commands which was /opt/pg/bin/0/\nIn the current version, versioning has been deleted from the PATH and\nnow it should only include /opt/pg/bin/\n\nChange-Id: I2b88eb28593043843a9ac0afd5bff7c268db0f60\n'}]",0,44972,8fbd10ff3698fe9e805e84614ca9cad328ef2502,13,6,2,704,,,0,"Remove versioning from IOVisor APIs PATH

Fix bug #1220454

In the first version of the IOVisor driver, versioning was included in the
the PATH of the native IOVisor commands which was /opt/pg/bin/0/
In the current version, versioning has been deleted from the PATH and
now it should only include /opt/pg/bin/

Change-Id: I2b88eb28593043843a9ac0afd5bff7c268db0f60
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/44972/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/nova/rootwrap.d/network.filters'],1,f58001e0e4952fdf005d41b5ab27138f798dc841,bug/1220454,"ifc_ctl: CommandFilter, /opt/pg/bin/ifc_ctl, root","ifc_ctl: CommandFilter, /opt/pg/bin/0/ifc_ctl, root",1,1
openstack%2Fswift~master~I9dfae1a473a8212ef25dcc01e338d8bdade7ef4e,openstack/swift,master,I9dfae1a473a8212ef25dcc01e338d8bdade7ef4e,Pep8 unit tests in middleware > 20 violations (7 of 12),MERGED,2013-09-01 19:15:53.000000000,2013-09-04 22:25:50.000000000,2013-09-04 22:25:50.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-09-01 19:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f6666c497a844b04f0c431a0fe6d88c40feb038a', 'message': 'Pep8 unit tests in middleware > 20 violations (7 of 12)\n\nChange-Id: I9dfae1a473a8212ef25dcc01e338d8bdade7ef4e\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-09-01 20:13:01.000000000', 'files': ['test/unit/common/middleware/test_recon.py', 'test/unit/common/middleware/test_tempurl.py', 'test/unit/common/middleware/test_staticweb.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/0ebddd87d159072daa0ff36d0ed8af8e4b60fd66', 'message': 'Pep8 unit tests in middleware > 20 violations (7 of 12)\n\nChange-Id: I9dfae1a473a8212ef25dcc01e338d8bdade7ef4e\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",0,44621,0ebddd87d159072daa0ff36d0ed8af8e4b60fd66,13,6,2,6198,,,0,"Pep8 unit tests in middleware > 20 violations (7 of 12)

Change-Id: I9dfae1a473a8212ef25dcc01e338d8bdade7ef4e
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/21/44621/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/test_recon.py', 'test/unit/common/middleware/test_tempurl.py', 'test/unit/common/middleware/test_staticweb.py']",3,f6666c497a844b04f0c431a0fe6d88c40feb038a,pep8-test," return Response( status='200 Ok', return Response(status='200 Ok', headers={ 'Content-Type': 'application/directory'})( env, start_response) return Response(status='200 Ok', headers={'Content-Type': return Response(status='200 Ok', headers={'Content-Type': return Response(status='200 Ok', headers={'Content-Type': return Response(status='200 Ok', headers={'Content-Type': headers = {'x-container-read': '.r:*'} if ((env['PATH_INFO'] in ( '/v1/a/c3', '/v1/a/c4', '/v1/a/c8', '/v1/a/c9')) and (env['QUERY_STRING'] == 'delimiter=/&format=json&prefix=subdir/')): elif env['PATH_INFO'] == '/v1/a/c10' and ( env['QUERY_STRING'] == env['QUERY_STRING'] == headers={'x-web-mode': 'false'}).get_response( self.test_staticweb) headers={'x-web-mode': 'true'}).get_response( self.test_staticweb) resp = Request.blank( '/v1/a/c2', resp = Request.blank( '/v1/a/c2', '/v1/a/c2/one.txt').get_response(self.test_staticweb) '/v1/a/c2?format=json').get_response(self.test_staticweb) resp = Request.blank( '/v1/a/c2?format=json', resp = Request.blank( '/v1/a/c2?format=json', '/v1/a/c3/subdir3/subsubdir').get_response(self.test_staticweb) '/v1/a/c3/subdir3/subsubdir/').get_response(self.test_staticweb) '/v1/a/c3/subdir/').get_response(self.test_staticweb) '/v1/a/c3/subdirx/').get_response(self.test_staticweb) '/v1/a/c3/subdiry/').get_response(self.test_staticweb) '/v1/a/c3/subdirz').get_response(self.test_staticweb) '/v1/a/c3/unknown').get_response(self.test_staticweb) resp = Request.blank( '/v1/a/c4', environ={'REMOTE_USER': 'authed'}).get_response( self.test_staticweb) resp = Request.blank( '/v1/a/c4', headers={'x-web-mode': 't'}, environ={'REMOTE_USER': 'authed'}).get_response( self.test_staticweb) '/v1/a/c4/unknown').get_response(self.test_staticweb) '/v1/a/c4/subdir/').get_response(self.test_staticweb) '/v1/a/c4/one.txt').get_response(self.test_staticweb) '/v1/a/c4/two.txt').get_response(self.test_staticweb) '/v1/a/c5/unknown').get_response(self.test_staticweb) '/v1/a/c6/subdir').get_response(self.test_staticweb) '/v1/a/c8/').get_response(self.test_staticweb) 'href=""http://localhost/stylesheets/listing.css""' in resp.body) '/v1/a/c8/subdir/').get_response(self.test_staticweb) 'href=""http://localhost/stylesheets/listing.css""' in resp.body) '/v1/a/c9/').get_response(self.test_staticweb) '/v1/a/c9/subdir/').get_response(self.test_staticweb) '/v1/a/c10/').get_response(self.test_staticweb) '/v1/a/c10/\xe2\x98\x83/').get_response(self.test_staticweb) '/v1/a/c10/\xe2\x98\x83/\xe2\x98\x83/' 'Listing of /v1/a/c10/\xe2\x98\x83/\xe2\x98\x83/' in resp.body) self.test_staticweb) self.test_staticweb) self.test_staticweb) self.test_staticweb) self.test_staticweb) with mock.patch('swift.common.middleware.staticweb.json', new=stdlib_json): '/v1/a/c4/one.txt').get_response(self.test_staticweb)"," return Response(status='200 Ok', return Response(status='200 Ok', headers={'Content-Type':\ 'application/directory'})(env, start_response) return Response(status='200 Ok', headers={'Content-Type':\ return Response(status='200 Ok', headers={'Content-Type':\ return Response(status='200 Ok', headers={'Content-Type':\ return Response(status='200 Ok', headers={'Content-Type':\ headers = {'x-container-read': '.r:*'} if env['PATH_INFO'] in ('/v1/a/c3', '/v1/a/c4', '/v1/a/c8', \ '/v1/a/c9') and \ env['QUERY_STRING'] == 'delimiter=/&format=json&prefix=subdir/': elif env['PATH_INFO'] == '/v1/a/c10' and (env['QUERY_STRING'] == \ env['QUERY_STRING'] == \ headers={'x-web-mode': 'false'}).get_response(self.test_staticweb) headers={'x-web-mode': 'true'}).get_response(self.test_staticweb) resp = Request.blank('/v1/a/c2', resp = Request.blank('/v1/a/c2', '/v1/a/c2/one.txt').get_response(self.test_staticweb) '/v1/a/c2?format=json').get_response(self.test_staticweb) resp = Request.blank('/v1/a/c2?format=json', resp = Request.blank('/v1/a/c2?format=json', '/v1/a/c3/subdir3/subsubdir').get_response(self.test_staticweb) '/v1/a/c3/subdir3/subsubdir/').get_response(self.test_staticweb) '/v1/a/c3/subdir/').get_response(self.test_staticweb) '/v1/a/c3/subdirx/').get_response(self.test_staticweb) '/v1/a/c3/subdiry/').get_response(self.test_staticweb) '/v1/a/c3/subdirz').get_response(self.test_staticweb) '/v1/a/c3/unknown').get_response(self.test_staticweb) resp = Request.blank('/v1/a/c4', environ={'REMOTE_USER': 'authed'}).get_response(self.test_staticweb) resp = Request.blank('/v1/a/c4', headers={'x-web-mode': 't'}, environ={'REMOTE_USER': 'authed'}).get_response(self.test_staticweb) '/v1/a/c4/unknown').get_response(self.test_staticweb) '/v1/a/c4/subdir/').get_response(self.test_staticweb) '/v1/a/c4/one.txt').get_response(self.test_staticweb) '/v1/a/c4/two.txt').get_response(self.test_staticweb) '/v1/a/c5/unknown').get_response(self.test_staticweb) '/v1/a/c6/subdir').get_response(self.test_staticweb) '/v1/a/c8/').get_response(self.test_staticweb) 'href=""http://localhost/stylesheets/listing.css""' in resp.body) '/v1/a/c8/subdir/').get_response(self.test_staticweb) 'href=""http://localhost/stylesheets/listing.css""' in resp.body) '/v1/a/c9/').get_response(self.test_staticweb) '/v1/a/c9/subdir/').get_response(self.test_staticweb) '/v1/a/c10/').get_response(self.test_staticweb) '/v1/a/c10/\xe2\x98\x83/').get_response(self.test_staticweb) '/v1/a/c10/\xe2\x98\x83/\xe2\x98\x83/' 'Listing of /v1/a/c10/\xe2\x98\x83/\xe2\x98\x83/' in resp.body) self.test_staticweb) self.test_staticweb) self.test_staticweb) self.test_staticweb) self.test_staticweb) with mock.patch('swift.common.middleware.staticweb.json', new=stdlib_json): '/v1/a/c4/one.txt').get_response(self.test_staticweb)",390,305
openstack%2Fceilometer~master~Ibce1978cfdf70ab068af43a548241546a85bd464,openstack/ceilometer,master,Ibce1978cfdf70ab068af43a548241546a85bd464,Add group by statistics in API v2,MERGED,2013-08-28 19:09:26.000000000,2013-09-04 22:25:17.000000000,2013-09-04 22:25:17.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 4715}, {'_account_id': 6537}, {'_account_id': 7399}]","[{'number': 1, 'created': '2013-08-28 19:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8ebab24d8191dff0cf9df811bf87058f560a23de', 'message': 'Add group by statistics tests in API v2 tests\n\nImplements blueprint api-group-by\n\nAdds group by statistics tests in API v2 tests in a new class\nTestGroupByInstance\n\nThe tests use the same data and test cases as the groupby storage\ntests in class StatisticsGroupByTest\n\nThe tests implemented are group by\n\n 1) single field, ""user-id""\n 2) single field, ""resource-id""\n 3) single field, ""project-id""\n 4) single field, ""source""\n 5) single field with invalid/unknown field value\n 6) multiple fields\n 7) single field groupby with query filter\n 8) multiple field group by with multiple query filters\n\nGroup by metadata fields is not implemented at this time.\n\nChange-Id: Ibce1978cfdf70ab068af43a548241546a85bd464\n'}, {'number': 2, 'created': '2013-08-29 15:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e9f99f6d10a89a1172dc449283f1292dc8fbcdff', 'message': 'Add group by statistics tests in API v2 tests\n\nImplements blueprint api-group-by\n\nAdds group by statistics tests in API v2 tests in a new class\nTestGroupByInstance\n\nThe tests use the same data and test cases as the groupby storage\ntests in class StatisticsGroupByTest\n\nThe tests implemented are group by\n\n 1) single field, ""user-id""\n 2) single field, ""resource-id""\n 3) single field, ""project-id""\n 4) single field, ""source""\n 5) single field with invalid/unknown field value\n 6) multiple fields\n 7) single field groupby with query filter\n 8) multiple field group by with multiple query filters\n 9) single field with start timestamp after all samples\n10) single field with end timestamp before all samples\n11) single field with start timestamp\n12) single field with end timestamp\n13) single field with start and end timestamps\n14) single field with start and end timestamps and query filter\n15) single field with start and end timestamps and period\n16) single field with start and end timestamps, query filter, and period\n\nGroup by metadata fields is not implemented at this time.\n\nChange-Id: Ibce1978cfdf70ab068af43a548241546a85bd464\n'}, {'number': 3, 'created': '2013-09-04 07:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b2950db91afa6afd685233f560e31967138bbc42', 'message': 'Add group by statistics in API v2\n\nImplements blueprint api-group-by\n\nAdd group by statistics in API v2 and group by statistics tests in\nAPI v2 tests as a new class TestGroupByInstance\n\nThe tests use the same data and test cases as the groupby storage\ntests in class StatisticsGroupByTest\n\nThe tests implemented are group by\n\n 1) single field, ""user-id""\n 2) single field, ""resource-id""\n 3) single field, ""project-id""\n 4) single field, ""source""\n 5) single field with invalid/unknown field value\n 6) multiple fields\n 7) single field groupby with query filter\n 8) multiple field group by with multiple query filters\n 9) single field with start timestamp after all samples\n10) single field with end timestamp before all samples\n11) single field with start timestamp\n12) single field with end timestamp\n13) single field with start and end timestamps\n14) single field with start and end timestamps and query filter\n15) single field with start and end timestamps and period\n16) single field with start and end timestamps, query filter, and period\n\nGroup by metadata fields is not implemented at this time.\n\nChange-Id: Ibce1978cfdf70ab068af43a548241546a85bd464\n'}, {'number': 4, 'created': '2013-09-04 18:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7b5f4cd184a1dc135402652d4b0df3064bd7c4e1', 'message': 'Add group by statistics in API v2\n\nImplements blueprint api-group-by\n\nAdd group by statistics in API v2 and group by statistics tests in\nAPI v2 tests as a new class TestGroupByInstance\n\nThe tests use the same data and test cases as the groupby storage\ntests in class StatisticsGroupByTest\n\nThe tests implemented are group by\n\n 1) single field, ""user-id""\n 2) single field, ""resource-id""\n 3) single field, ""project-id""\n 4) single field, ""source"" (*)\n 5) single field with invalid/unknown field value\n 6) multiple fields\n 7) single field groupby with query filter\n 8) multiple field group by with multiple query filters\n 9) single field with start timestamp after all samples\n10) single field with end timestamp before all samples\n11) single field with start timestamp\n12) single field with end timestamp\n13) single field with start and end timestamps\n14) single field with start and end timestamps and query filter\n15) single field with start and end timestamps and period\n16) single field with start and end timestamps, query filter, and period\n\n(*) Group by source isn\'t supported in SQLAlchemy at this time, so\n    we have to put this test in its own class TestGroupBySource\n\nGroup by metadata fields is not implemented at this time.\n\nChange-Id: Ibce1978cfdf70ab068af43a548241546a85bd464\n'}, {'number': 5, 'created': '2013-09-04 21:06:51.000000000', 'files': ['ceilometer/tests/api.py', 'ceilometer/api/controllers/v2.py', 'tests/api/v2/test_query.py', 'tests/api/v2/test_statistics_scenarios.py', 'tests/api/v2/test_compute_duration_by_resource_scenarios.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2ca3edcdc680eba2803f1b9ef554428fe5a158f7', 'message': 'Add group by statistics in API v2\n\nImplements blueprint api-group-by\n\nAdd group by statistics in API v2 and group by statistics tests in\nAPI v2 tests as a new class TestGroupByInstance\n\nThe tests use the same data and test cases as the groupby storage\ntests in class StatisticsGroupByTest\n\nThe tests implemented are group by\n\n 1) single field, ""user-id""\n 2) single field, ""resource-id""\n 3) single field, ""project-id""\n 4) single field, ""source"" (*)\n 5) single field with invalid/unknown field value\n 6) multiple fields\n 7) single field groupby with query filter\n 8) multiple field group by with multiple query filters\n 9) single field with start timestamp after all samples\n10) single field with end timestamp before all samples\n11) single field with start timestamp\n12) single field with end timestamp\n13) single field with start and end timestamps\n14) single field with start and end timestamps and query filter\n15) single field with start and end timestamps and period\n16) single field with start and end timestamps, query filter, and period\n\n(*) Group by source isn\'t supported in SQLAlchemy at this time, so\n    we have to put this test in its own class TestGroupBySource\n\nGroup by metadata fields is not implemented at this time.\n\nAlso adds a method _validate_groupby_fields() to process the groupby\npart of the request, and tests for _validate_groupby_fields().\n\nChange-Id: Ibce1978cfdf70ab068af43a548241546a85bd464\n'}]",28,44130,2ca3edcdc680eba2803f1b9ef554428fe5a158f7,28,6,5,7399,,,0,"Add group by statistics in API v2

Implements blueprint api-group-by

Add group by statistics in API v2 and group by statistics tests in
API v2 tests as a new class TestGroupByInstance

The tests use the same data and test cases as the groupby storage
tests in class StatisticsGroupByTest

The tests implemented are group by

 1) single field, ""user-id""
 2) single field, ""resource-id""
 3) single field, ""project-id""
 4) single field, ""source"" (*)
 5) single field with invalid/unknown field value
 6) multiple fields
 7) single field groupby with query filter
 8) multiple field group by with multiple query filters
 9) single field with start timestamp after all samples
10) single field with end timestamp before all samples
11) single field with start timestamp
12) single field with end timestamp
13) single field with start and end timestamps
14) single field with start and end timestamps and query filter
15) single field with start and end timestamps and period
16) single field with start and end timestamps, query filter, and period

(*) Group by source isn't supported in SQLAlchemy at this time, so
    we have to put this test in its own class TestGroupBySource

Group by metadata fields is not implemented at this time.

Also adds a method _validate_groupby_fields() to process the groupby
part of the request, and tests for _validate_groupby_fields().

Change-Id: Ibce1978cfdf70ab068af43a548241546a85bd464
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/30/44130/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/api.py', 'tests/api/v2/test_statistics_scenarios.py']",2,8ebab24d8191dff0cf9df811bf87058f560a23de,bp/api-group-by," class TestGroupByInstance(base.FunctionalTest, tests_db.MixinTestsWithBackendScenarios): PATH = '/meters/instance/statistics' def setUp(self): super(TestGroupByInstance, self).setUp() test_sample_data = ( {'volume': 2, 'user': 'user-1', 'project': 'project-1', 'resource': 'resource-1', 'timestamp': (2013, 8, 1, 16, 10), 'metadata_flavor': 'm1.tiny', 'metadata_event': 'event-1', 'source': 'source-2'}, {'volume': 2, 'user': 'user-1', 'project': 'project-2', 'resource': 'resource-1', 'timestamp': (2013, 8, 1, 15, 37), 'metadata_flavor': 'm1.large', 'metadata_event': 'event-1', 'source': 'source-2'}, {'volume': 1, 'user': 'user-2', 'project': 'project-1', 'resource': 'resource-2', 'timestamp': (2013, 8, 1, 10, 11), 'metadata_flavor': 'm1.tiny', 'metadata_event': 'event-2', 'source': 'source-1'}, {'volume': 1, 'user': 'user-2', 'project': 'project-1', 'resource': 'resource-2', 'timestamp': (2013, 8, 1, 10, 40), 'metadata_flavor': 'm1.large', 'metadata_event': 'event-2', 'source': 'source-1'}, {'volume': 2, 'user': 'user-2', 'project': 'project-1', 'resource': 'resource-1', 'timestamp': (2013, 8, 1, 14, 59), 'metadata_flavor': 'm1.large', 'metadata_event': 'event-2', 'source': 'source-1'}, {'volume': 4, 'user': 'user-2', 'project': 'project-2', 'resource': 'resource-2', 'timestamp': (2013, 8, 1, 17, 28), 'metadata_flavor': 'm1.large', 'metadata_event': 'event-2', 'source': 'source-1'}, {'volume': 4, 'user': 'user-3', 'project': 'project-1', 'resource': 'resource-3', 'timestamp': (2013, 8, 1, 11, 22), 'metadata_flavor': 'm1.tiny', 'metadata_event': 'event-2', 'source': 'source-3'}, ) for test_sample in test_sample_data: c = sample.Sample( 'instance', sample.TYPE_CUMULATIVE, unit='s', volume=test_sample['volume'], user_id=test_sample['user'], project_id=test_sample['project'], resource_id=test_sample['resource'], timestamp=datetime.datetime(*test_sample['timestamp']), resource_metadata={'flavor': test_sample['metadata_flavor'], 'event': test_sample['metadata_event'], }, source=test_sample['source'], ) msg = rpc.meter_message_from_counter( c, cfg.CONF.publisher_rpc.metering_secret, ) self.conn.record_metering_data(msg) def test_group_by_user(self): data = self.get_json(self.PATH, g=[{'field': 'user_id'}]) groupby_keys_set = set(x for sub_dict in data for x in sub_dict.keys()) self.assertEqual(groupby_keys_set, set(['user-1', 'user-2', 'user-3'])) # Check that each element of JSON list has one key (representing group) self.assertEqual([len(r) for r in data], [1, 1, 1]) # Check that the value corresponding to each group key is length one self.assertEqual([len(r.values()) for r in data], [1, 1, 1]) for r in data: grp = r.keys()[0] stats = r.values()[0] if grp == 'user-1': self.assertEqual(stats['count'], 2) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 2) self.assertEqual(stats['max'], 2) self.assertEqual(stats['sum'], 4) self.assertEqual(stats['avg'], 2) elif grp == 'user-2': self.assertEqual(stats['count'], 4) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 1) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 8) self.assertEqual(stats['avg'], 2) elif grp == 'user-3': self.assertEqual(stats['count'], 1) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 4) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 4) self.assertEqual(stats['avg'], 4) def test_group_by_resource(self): data = self.get_json(self.PATH, g=[{'field': 'resource_id'}]) groupby_keys_set = set(x for sub_dict in data for x in sub_dict.keys()) self.assertEqual(groupby_keys_set, set(['resource-1', 'resource-2', 'resource-3'])) # Check that each element of JSON list has one key (representing group) self.assertEqual([len(r) for r in data], [1, 1, 1]) # Check that the value corresponding to each group key is length one self.assertEqual([len(r.values()) for r in data], [1, 1, 1]) for r in data: grp = r.keys()[0] stats = r.values()[0] if grp == 'resource-1': self.assertEqual(stats['count'], 3) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 2) self.assertEqual(stats['max'], 2) self.assertEqual(stats['sum'], 6) self.assertEqual(stats['avg'], 2) elif grp == 'resource-2': self.assertEqual(stats['count'], 3) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 1) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 6) self.assertEqual(stats['avg'], 2) elif grp == 'resource-3': self.assertEqual(stats['count'], 1) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 4) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 4) self.assertEqual(stats['avg'], 4) def test_group_by_project(self): data = self.get_json(self.PATH, g=[{'field': 'project_id'}]) groupby_keys_set = set(x for sub_dict in data for x in sub_dict.keys()) self.assertEqual(groupby_keys_set, set(['project-1', 'project-2'])) # Check that each element of JSON list has one key (representing group) self.assertEqual([len(r) for r in data], [1, 1]) # Check that the value corresponding to each group key is length one self.assertEqual([len(r.values()) for r in data], [1, 1]) for r in data: grp = r.keys()[0] stats = r.values()[0] if grp == 'project-1': self.assertEqual(stats['count'], 5) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 1) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 10) self.assertEqual(stats['avg'], 2) elif grp == 'project-2': self.assertEqual(stats['count'], 2) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 2) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 6) self.assertEqual(stats['avg'], 3) def test_group_by_source(self): data = self.get_json(self.PATH, g=[{'field': 'source'}]) groupby_keys_set = set(x for sub_dict in data for x in sub_dict.keys()) self.assertEqual(groupby_keys_set, set(['source-1', 'source-2', 'source-3'])) # Check that each element of JSON list has one key (representing group) self.assertEqual([len(r) for r in data], [1, 1, 1]) # Check that the value corresponding to each group key is length one self.assertEqual([len(r.values()) for r in data], [1, 1, 1]) for r in data: grp = r.keys()[0] stats = r.values()[0] if grp == 'source-1': self.assertEqual(stats['count'], 4) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 1) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 8) self.assertEqual(stats['avg'], 2) elif grp == 'source-2': self.assertEqual(stats['count'], 2) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 2) self.assertEqual(stats['max'], 2) self.assertEqual(stats['sum'], 4) self.assertEqual(stats['avg'], 2) elif grp == 'source-3': self.assertEqual(stats['count'], 1) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 4) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 4) self.assertEqual(stats['avg'], 4) def test_group_by_unknown_field(self): self.assertRaises( NotImplementedError, self.get_json, self.PATH, g=[{'field': 'wtf'}]) def test_group_by_multiple_regular(self): data = self.get_json(self.PATH, g=[{'field': 'user_id'}, {'field': 'resource_id'}]) groupby_keys_set = set(x for sub_dict in data for x in sub_dict.keys()) self.assertEqual(groupby_keys_set, set([('user-1', 'resource-1'), ('user-2', 'resource-1'), ('user-2', 'resource-2'), ('user-3', 'resource-3')])) # Check that each element of JSON list has one key (representing group) self.assertEqual([len(r) for r in data], [1, 1, 1, 1]) # Check that the value corresponding to each group key is length one self.assertEqual([len(r.values()) for r in data], [1, 1, 1, 1]) for r in data: grp = r.keys()[0] stats = r.values()[0] if grp == ('user-1', 'resource-1'): self.assertEqual(stats['count'], 2) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 2) self.assertEqual(stats['max'], 2) self.assertEqual(stats['sum'], 4) self.assertEqual(stats['avg'], 2) elif grp == ('user-2', 'resource-1'): self.assertEqual(stats['count'], 1) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 2) self.assertEqual(stats['max'], 2) self.assertEqual(stats['sum'], 2) self.assertEqual(stats['avg'], 2) elif grp == ('user-2', 'resource-2'): self.assertEqual(stats['count'], 3) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 1) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 6) self.assertEqual(stats['avg'], 2) elif grp == ('user-3', 'resource-3'): self.assertEqual(stats['count'], 1) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 4) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 4) self.assertEqual(stats['avg'], 4) def test_group_by_with_query_filter(self): data = self.get_json(self.PATH, q=[{'field': 'project_id', 'value': 'project-1'}], g=[{'field': 'resource_id'}]) groupby_keys_set = set(x for sub_dict in data for x in sub_dict.keys()) self.assertEqual(groupby_keys_set, set(['resource-1', 'resource-2', 'resource-3'])) # Check that each element of JSON list has one key (representing group) self.assertEqual([len(r) for r in data], [1, 1, 1]) # Check that the value corresponding to each group key is length one self.assertEqual([len(r.values()) for r in data], [1, 1, 1]) for r in data: grp = r.keys()[0] stats = r.values()[0] if grp == 'resource-1': self.assertEqual(stats['count'], 2) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 2) self.assertEqual(stats['max'], 2) self.assertEqual(stats['sum'], 4) self.assertEqual(stats['avg'], 2) elif grp == 'resource-2': self.assertEqual(stats['count'], 2) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 1) self.assertEqual(stats['max'], 1) self.assertEqual(stats['sum'], 2) self.assertEqual(stats['avg'], 1) elif grp == 'resource-3': self.assertEqual(stats['count'], 1) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 4) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 4) self.assertEqual(stats['avg'], 4) def test_group_by_with_query_filter_multiple(self): data = self.get_json(self.PATH, q=[{'field': 'user_id', 'value': 'user-2'}, {'field': 'source', 'value': 'source-1'}], g=[{'field': 'project_id'}, {'field': 'resource_id'}]) groupby_keys_set = set(x for sub_dict in data for x in sub_dict.keys()) self.assertEqual(groupby_keys_set, set([('project-1', 'resource-1'), ('project-1', 'resource-2'), ('project-2', 'resource-2')])) # Check that each element of JSON list has one key (representing group) self.assertEqual([len(r) for r in data], [1, 1, 1]) # Check that the value corresponding to each group key is length one self.assertEqual([len(r.values()) for r in data], [1, 1, 1]) for r in data: grp = r.keys()[0] stats = r.values()[0] if grp == ('project-1', 'resource-1'): self.assertEqual(stats['count'], 1) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 2) self.assertEqual(stats['max'], 2) self.assertEqual(stats['sum'], 2) self.assertEqual(stats['avg'], 2) elif grp == ('project-1', 'resource-2'): self.assertEqual(stats['count'], 2) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 1) self.assertEqual(stats['max'], 1) self.assertEqual(stats['sum'], 2) self.assertEqual(stats['avg'], 1) elif grp == ('project-2', 'resource-2'): self.assertEqual(stats['count'], 1) self.assertEqual(stats['unit'], 's') self.assertEqual(stats['min'], 4) self.assertEqual(stats['max'], 4) self.assertEqual(stats['sum'], 4) self.assertEqual(stats['avg'], 4)",,338,1
openstack%2Fswift~master~I7317beb97e1530cb18c62da55ccf4c64206ff362,openstack/swift,master,I7317beb97e1530cb18c62da55ccf4c64206ff362,Pep8 unit test modules w/ <= 20 violations (6 of 12),MERGED,2013-09-01 19:15:53.000000000,2013-09-04 22:23:26.000000000,2013-09-04 22:23:26.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-09-01 19:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ce28c11e60853ddf9fcaa0f8926d2af0f87c88d2', 'message': 'Pep8 unit test modules w/ <= 20 violoations (6 of 12)\n\nChange-Id: I7317beb97e1530cb18c62da55ccf4c64206ff362\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}, {'number': 2, 'created': '2013-09-01 20:13:01.000000000', 'files': ['test/unit/obj/test_expirer.py', 'test/unit/common/middleware/test_quotas.py', 'test/unit/common/middleware/test_keystoneauth.py', 'test/unit/common/test_db_replicator.py', 'test/unit/common/test_direct_client.py', 'test/unit/common/middleware/test_proxy_logging.py', 'test/unit/obj/test_replicator.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/56593a1323455ced7047f05fa638b9641fec72f1', 'message': 'Pep8 unit test modules w/ <= 20 violations (6 of 12)\n\nChange-Id: I7317beb97e1530cb18c62da55ccf4c64206ff362\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",1,44620,56593a1323455ced7047f05fa638b9641fec72f1,13,6,2,6198,,,0,"Pep8 unit test modules w/ <= 20 violations (6 of 12)

Change-Id: I7317beb97e1530cb18c62da55ccf4c64206ff362
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/20/44620/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_expirer.py', 'test/unit/common/middleware/test_keystoneauth.py', 'test/unit/common/middleware/test_quotas.py', 'test/unit/common/test_db_replicator.py', 'test/unit/common/test_direct_client.py', 'test/unit/common/middleware/test_proxy_logging.py', 'test/unit/obj/test_replicator.py']",7,ce28c11e60853ddf9fcaa0f8926d2af0f87c88d2,pep8-test," pickle.dump( ring.RingData(intended_replica2part2dev_id, intended_devs, intended_part_shift), return ring.Ring(path, ring_name='object', reload_time=intended_reload_time) mount_check='false', timeout='300', stats_interval='1')) if node['ip'] not in _ips()] mount_check='false', timeout='300', stats_interval='1')) df = diskfile.DiskFile( self.devices, 'sda', cur_part, 'a', 'c', 'o', FakeLogger()) if node['ip'] not in _ips()] os.path.join(self.objects, i, diskfile.HASH_FILE), os.F_OK), result) mount_check='false', timeout='300', stats_interval='1')) df = diskfile.DiskFile( self.devices, 'sda', cur_part, 'a', 'c', 'o', FakeLogger()) if node['ip'] not in _ips()] reqs.append(mock.call(node['ip'], node['port'], node['device'], job['partition'], 'REPLICATE', '', headers=self.headers)) reqs.append(mock.call(node['replication_ip'], node['replication_port'], node['device'], repl_job['partition'], 'REPLICATE', '', headers=self.headers)) reqs.append(mock.call(node['replication_ip'], node['replication_port'], node['device'], repl_job['partition'], 'REPLICATE', '/a83', headers=self.headers))"," pickle.dump(ring.RingData(intended_replica2part2dev_id, intended_devs, intended_part_shift), return ring.Ring(path, ring_name='object', reload_time=intended_reload_time) mount_check='false', timeout='300', stats_interval='1')) if node['ip'] not in _ips()] mount_check='false', timeout='300', stats_interval='1')) df = diskfile.DiskFile(self.devices, 'sda', cur_part, 'a', 'c', 'o', FakeLogger()) if node['ip'] not in _ips()] os.path.join(self.objects, i, diskfile.HASH_FILE), os.F_OK), result) mount_check='false', timeout='300', stats_interval='1')) df = diskfile.DiskFile(self.devices, 'sda', cur_part, 'a', 'c', 'o', FakeLogger()) if node['ip'] not in _ips()] reqs.append(mock.call(node['ip'], node['port'], node['device'], job['partition'], 'REPLICATE', '', headers=self.headers)) reqs.append(mock.call(node['replication_ip'], node['replication_port'], node['device'], repl_job['partition'], 'REPLICATE', '', headers=self.headers)) reqs.append(mock.call(node['replication_ip'], node['replication_port'], node['device'], repl_job['partition'], 'REPLICATE', '/a83', headers=self.headers))",231,134
openstack%2Fopenstack-manuals~master~I60275ee4eb680e479231d94282d2c0731b672946,openstack/openstack-manuals,master,I60275ee4eb680e479231d94282d2c0731b672946,Update the location of the LH driver,MERGED,2013-09-03 18:53:28.000000000,2013-09-04 21:58:07.000000000,2013-09-04 21:58:06.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6043}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-09-03 18:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e82b704655a6d5d2622ee2138dcdae7bb18996eb', 'message': 'Update the location of the LH driver\n\nWhen the lefthand driver was pulled from nova into cinder, the\nvolume_driver location was incorrect. The migration mapped the old\nlocation to the new location;\ncinder.volume.drivers.san.HpSanISCSIDriver\nThis patch is just updating the docs to the correct location.\n\nChange-Id: I60275ee4eb680e479231d94282d2c0731b672946\n'}, {'number': 2, 'created': '2013-09-04 16:47:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/291a2ec44f99f2dfc1614e3a3b1d8e2162e89a09', 'message': 'Update the location of the LH driver\n\nWhen the lefthand driver was pulled from nova into cinder, the\nvolume_driver location was incorrect. The migration mapped the old\nlocation to the new location;\ncinder.volume.drivers.san.HpSanISCSIDriver\nThis patch is just updating the docs to the correct location.\n\nChange-Id: I60275ee4eb680e479231d94282d2c0731b672946\n'}, {'number': 3, 'created': '2013-09-04 17:12:36.000000000', 'files': ['doc/src/docbkx/openstack-config/block-storage/drivers/hp-lefthand-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2b9593ccc152c2dfdf9dd7934555a0923a3c074b', 'message': 'Update the location of the LH driver\n\nWhen the lefthand driver was pulled from nova into cinder, the\nvolume_driver location was incorrect. The migration mapped the old\nlocation to the new location;\ncinder.volume.drivers.san.HpSanISCSIDriver\nThis patch is just updating the docs to the correct location.\n\nChange-Id: I60275ee4eb680e479231d94282d2c0731b672946\n'}]",0,44937,2b9593ccc152c2dfdf9dd7934555a0923a3c074b,16,5,3,6043,,,0,"Update the location of the LH driver

When the lefthand driver was pulled from nova into cinder, the
volume_driver location was incorrect. The migration mapped the old
location to the new location;
cinder.volume.drivers.san.HpSanISCSIDriver
This patch is just updating the docs to the correct location.

Change-Id: I60275ee4eb680e479231d94282d2c0731b672946
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/37/44937/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-config/block-storage/drivers/hp-lefthand-driver.xml'],1,e82b704655a6d5d2622ee2138dcdae7bb18996eb,lh_doc_update, <listitem><para>set <literal>volume_driver=cinder.volume.drivers.san.HpSanISCSIDriver</literal>.</para></listitem>, <listitem><para>set <literal>volume_driver=cinder.volume.san.HpSanISCSIDriver</literal>.</para></listitem>,1,1
openstack%2Fpycadf~master~I121ef939fd3b768e15adf6abf95cf0a1899c71b5,openstack/pycadf,master,I121ef939fd3b768e15adf6abf95cf0a1899c71b5,bump oslo.config req to 1.2.0a3,MERGED,2013-09-04 21:31:48.000000000,2013-09-04 21:52:23.000000000,2013-09-04 21:52:23.000000000,"[{'_account_id': 3}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-09-04 21:31:48.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/2604405eb5d7f1acc3a4a130262fba1d14f5ac4e', 'message': ""bump oslo.config req to 1.2.0a3\n\nbump up oslo.config requirement to 1.2.0.a3 so it doesn't pull in\nolder oslo.config on pip install --upgrade\n\nChange-Id: I121ef939fd3b768e15adf6abf95cf0a1899c71b5\n""}]",0,45128,2604405eb5d7f1acc3a4a130262fba1d14f5ac4e,5,2,1,6537,,,0,"bump oslo.config req to 1.2.0a3

bump up oslo.config requirement to 1.2.0.a3 so it doesn't pull in
older oslo.config on pip install --upgrade

Change-Id: I121ef939fd3b768e15adf6abf95cf0a1899c71b5
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/28/45128/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2604405eb5d7f1acc3a4a130262fba1d14f5ac4e,master,-f http://tarballs.openstack.org/oslo.config/oslo.config-1.2.0a3.tar.gz#egg=oslo.config-1.2.0a3 oslo.config>=1.2.0a3 ,oslo.config>=1.1.0,3,1
openstack%2Fpython-openstackclient~master~Ie8bf41c491d97b0292a2b86bdc9b7580989a7f97,openstack/python-openstackclient,master,Ie8bf41c491d97b0292a2b86bdc9b7580989a7f97,Add Identity v2 role and service tests,MERGED,2013-08-28 22:31:36.000000000,2013-09-04 21:40:16.000000000,2013-09-04 21:40:16.000000000,"[{'_account_id': 3}, {'_account_id': 970}]","[{'number': 1, 'created': '2013-08-28 22:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6644e4455291b2ad5e9364ef4b4afc92dfa740cf', 'message': 'Add Identity v2 role and service tests\n\n* Fix identity.v2_0.role.AddRole call to roles.add_user_role()\n\nChange-Id: Ie8bf41c491d97b0292a2b86bdc9b7580989a7f97\n'}, {'number': 2, 'created': '2013-08-29 22:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8928a440690c0dae0e732270660a36b15dbcb846', 'message': 'Add Identity v2 role and service tests\n\n* Add current auth info (auth_ref) to ClientManager\n* Fix identity.v2_0.role.ListUserRole to get default user/project\n  from ClientManager.auth_ref\n* Fix identity.v2_0.role.AddRole call to roles.add_user_role()\n\nChange-Id: Ie8bf41c491d97b0292a2b86bdc9b7580989a7f97\n'}, {'number': 4, 'created': '2013-08-30 21:13:58.000000000', 'files': ['openstackclient/identity/v2_0/role.py', 'openstackclient/tests/identity/fakes.py', 'openstackclient/tests/identity/v2_0/test_service.py', 'openstackclient/common/clientmanager.py', 'openstackclient/tests/identity/v2_0/test_role.py', 'openstackclient/identity/client.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/44c97cc099a35af2d3d999f9799238fc72be071d', 'message': 'Add Identity v2 role and service tests\n\n* Add current auth info (auth_ref) to ClientManager\n* Fix identity.v2_0.role.ListUserRole to get default user/project\n  from ClientManager.auth_ref\n* Fix identity.v2_0.role.AddRole call to roles.add_user_role()\n\nChange-Id: Ie8bf41c491d97b0292a2b86bdc9b7580989a7f97\n'}, {'number': 3, 'created': '2013-08-30 21:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e92c72731afecca105ecb1e223fa0f5f37d9279b', 'message': 'Add Identity v2 role and service tests\n\n* Add current auth info (auth_ref) to ClientManager\n* Fix identity.v2_0.role.ListUserRole to get default user/project\n  from ClientManager.auth_ref\n* Fix identity.v2_0.role.AddRole call to roles.add_user_role()\n\nChange-Id: Ie8bf41c491d97b0292a2b86bdc9b7580989a7f97\n'}]",0,44169,44c97cc099a35af2d3d999f9799238fc72be071d,11,2,4,970,,,0,"Add Identity v2 role and service tests

* Add current auth info (auth_ref) to ClientManager
* Fix identity.v2_0.role.ListUserRole to get default user/project
  from ClientManager.auth_ref
* Fix identity.v2_0.role.AddRole call to roles.add_user_role()

Change-Id: Ie8bf41c491d97b0292a2b86bdc9b7580989a7f97
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/69/44169/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/identity/v2_0/role.py', 'openstackclient/tests/identity/fakes.py', 'openstackclient/tests/identity/v2_0/test_service.py', 'openstackclient/tests/identity/v2_0/test_role.py']",4,6644e4455291b2ad5e9364ef4b4afc92dfa740cf,test-service-v2,"# Copyright 2013 Nebula Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # import copy from openstackclient.identity.v2_0 import role from openstackclient.tests import fakes from openstackclient.tests.identity import fakes as identity_fakes from openstackclient.tests import utils IDENTITY_API_VERSION = ""2.0"" class TestRole(utils.TestCommand): def setUp(self): super(TestRole, self).setUp() self.app.client_manager.identity = \ identity_fakes.FakeIdentityv2Client() # Get a shortcut to the TenantManager Mock self.projects_mock = self.app.client_manager.identity.tenants # Get a shortcut to the UserManager Mock self.users_mock = self.app.client_manager.identity.users # Get a shortcut to the RoleManager Mock self.roles_mock = self.app.client_manager.identity.roles class TestRoleAdd(TestRole): def setUp(self): super(TestRoleAdd, self).setUp() self.projects_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.PROJECT), loaded=True, ) self.users_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.USER), loaded=True, ) self.roles_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.ROLE), loaded=True, ) self.roles_mock.add_user_role.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.ROLE), loaded=True, ) # Get the command object to test self.cmd = role.AddRole(self.app, None) def test_role_add(self): arglist = [ '--project', identity_fakes.project_name, '--user', identity_fakes.user_name, identity_fakes.role_name, ] verifylist = [ ('role', identity_fakes.role_name), ('project', identity_fakes.project_name), ('user', identity_fakes.user_name), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) # DisplayCommandBase.take_action() returns two tuples columns, data = self.cmd.take_action(parsed_args) # RoleManager.add_user_role(user, role, tenant=None) self.roles_mock.add_user_role.assert_called_with( identity_fakes.user_id, identity_fakes.role_id, identity_fakes.project_id, ) collist = ('id', 'name') self.assertEqual(columns, collist) datalist = ( identity_fakes.role_id, identity_fakes.role_name, ) self.assertEqual(data, datalist) class TestRoleCreate(TestRole): def setUp(self): super(TestRoleCreate, self).setUp() self.roles_mock.create.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.ROLE), loaded=True, ) # Get the command object to test self.cmd = role.CreateRole(self.app, None) def test_role_create_no_options(self): arglist = [ identity_fakes.role_name, ] verifylist = [ ('role_name', identity_fakes.role_name), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) # DisplayCommandBase.take_action() returns two tuples columns, data = self.cmd.take_action(parsed_args) # RoleManager.create(name) self.roles_mock.create.assert_called_with( identity_fakes.role_name, ) collist = ('id', 'name') self.assertEqual(columns, collist) datalist = ( identity_fakes.role_id, identity_fakes.role_name, ) self.assertEqual(data, datalist) class TestRoleDelete(TestRole): def setUp(self): super(TestRoleDelete, self).setUp() self.roles_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.ROLE), loaded=True, ) self.roles_mock.delete.return_value = None # Get the command object to test self.cmd = role.DeleteRole(self.app, None) def test_role_delete_no_options(self): arglist = [ identity_fakes.role_name, ] verifylist = [ ('role', identity_fakes.role_name), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) # DisplayCommandBase.take_action() returns two tuples self.cmd.take_action(parsed_args) self.roles_mock.delete.assert_called_with( identity_fakes.role_id, ) class TestRoleList(TestRole): def setUp(self): super(TestRoleList, self).setUp() self.roles_mock.list.return_value = [ fakes.FakeResource( None, copy.deepcopy(identity_fakes.ROLE), loaded=True, ), ] # Get the command object to test self.cmd = role.ListRole(self.app, None) def test_role_list_no_options(self): arglist = [] verifylist = [] parsed_args = self.check_parser(self.cmd, arglist, verifylist) # DisplayCommandBase.take_action() returns two tuples columns, data = self.cmd.take_action(parsed_args) self.roles_mock.list.assert_called_with() collist = ('ID', 'Name') self.assertEqual(columns, collist) datalist = (( identity_fakes.role_id, identity_fakes.role_name, ), ) self.assertEqual(tuple(data), datalist) class TestUserRoleList(TestRole): def setUp(self): super(TestUserRoleList, self).setUp() self.projects_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.PROJECT), loaded=True, ) self.users_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.USER), loaded=True, ) self.roles_mock.roles_for_user.return_value = [ fakes.FakeResource( None, copy.deepcopy(identity_fakes.ROLE), loaded=True, ), ] # Get the command object to test self.cmd = role.ListUserRole(self.app, None) def test_user_role_list_no_options(self): arglist = [] verifylist = [] parsed_args = self.check_parser(self.cmd, arglist, verifylist) # DisplayCommandBase.take_action() returns two tuples columns, data = self.cmd.take_action(parsed_args) self.roles_mock.roles_for_user.assert_called_with( identity_fakes.user_id, identity_fakes.project_id, ) collist = ('ID', 'Name', 'Project', 'User') self.assertEqual(columns, collist) datalist = (( identity_fakes.role_id, identity_fakes.role_name, identity_fakes.project_name, identity_fakes.user_name, ), ) self.assertEqual(tuple(data), datalist) def test_user_role_list_project(self): self.projects_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.PROJECT_2), loaded=True, ) arglist = [ '--project', identity_fakes.PROJECT_2['name'], ] verifylist = [ ('project', identity_fakes.PROJECT_2['name']), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) # DisplayCommandBase.take_action() returns two tuples columns, data = self.cmd.take_action(parsed_args) self.roles_mock.roles_for_user.assert_called_with( identity_fakes.user_id, identity_fakes.PROJECT_2['id'], ) collist = ('ID', 'Name', 'Project', 'User') self.assertEqual(columns, collist) datalist = (( identity_fakes.role_id, identity_fakes.role_name, identity_fakes.PROJECT_2['name'], identity_fakes.user_name, ), ) self.assertEqual(tuple(data), datalist) class TestRoleRemove(TestRole): def setUp(self): super(TestRoleRemove, self).setUp() self.projects_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.PROJECT), loaded=True, ) self.users_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.USER), loaded=True, ) self.roles_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.ROLE), loaded=True, ) self.roles_mock.remove_user_role.return_value = None # Get the command object to test self.cmd = role.RemoveRole(self.app, None) def test_role_remove(self): arglist = [ '--project', identity_fakes.project_name, '--user', identity_fakes.user_name, identity_fakes.role_name, ] verifylist = [ ('role', identity_fakes.role_name), ('project', identity_fakes.project_name), ('user', identity_fakes.user_name), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) # DisplayCommandBase.take_action() returns two tuples self.cmd.take_action(parsed_args) # RoleManager.remove_user_role(user, role, tenant=None) self.roles_mock.remove_user_role.assert_called_with( identity_fakes.user_id, identity_fakes.role_id, identity_fakes.project_id, ) class TestRoleShow(TestRole): def setUp(self): super(TestRoleShow, self).setUp() self.roles_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.ROLE), loaded=True, ) # Get the command object to test self.cmd = role.ShowRole(self.app, None) def test_service_show(self): arglist = [ identity_fakes.role_name, ] verifylist = [ ('role', identity_fakes.role_name), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) # DisplayCommandBase.take_action() returns two tuples columns, data = self.cmd.take_action(parsed_args) # RoleManager.get(role) self.roles_mock.get.assert_called_with( identity_fakes.role_name, ) collist = ('id', 'name') self.assertEqual(columns, collist) datalist = ( identity_fakes.role_id, identity_fakes.role_name, ) self.assertEqual(data, datalist) ",,666,17
openstack%2Fpbr~master~I590af708465e8a8a3d5d5f64cc4ad1a9d640abc7,openstack/pbr,master,I590af708465e8a8a3d5d5f64cc4ad1a9d640abc7,Add pypy to tox.ini,MERGED,2013-08-28 13:36:04.000000000,2013-09-04 21:35:44.000000000,2013-09-04 21:35:44.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4146}, {'_account_id': 4190}]","[{'number': 1, 'created': '2013-08-28 13:36:04.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/pbr/commit/3fbf36ef476e2ee6a368297a6300389ddfc590b0', 'message': 'Add pypy to tox.ini\n\nChange-Id: I590af708465e8a8a3d5d5f64cc4ad1a9d640abc7\n'}]",0,44051,3fbf36ef476e2ee6a368297a6300389ddfc590b0,8,5,1,1669,,,0,"Add pypy to tox.ini

Change-Id: I590af708465e8a8a3d5d5f64cc4ad1a9d640abc7
",git fetch https://review.opendev.org/openstack/pbr refs/changes/51/44051/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,3fbf36ef476e2ee6a368297a6300389ddfc590b0,jd/pypy,"envlist = py26,py27,py33,pypy,pep8","envlist = py26,py27,py33,pep8",1,1
openstack%2Fpython-openstackclient~master~Icacbb2ca740b63937bd2c4442af61b620638b53e,openstack/python-openstackclient,master,Icacbb2ca740b63937bd2c4442af61b620638b53e,Refactor fake data for projects and users,MERGED,2013-08-28 22:27:57.000000000,2013-09-04 21:32:54.000000000,2013-09-04 21:32:54.000000000,"[{'_account_id': 3}, {'_account_id': 970}]","[{'number': 1, 'created': '2013-08-28 22:27:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1fd377cfc7c3249555c100601993929d4ff4646d', 'message': 'Refactor fake data for projects and users\n\nMove fake data structures into tests/identity/fakes.py\n\nChange-Id: Icacbb2ca740b63937bd2c4442af61b620638b53e\n'}, {'number': 2, 'created': '2013-08-29 17:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/aac1cb9b7cc0f5ee06b308feeeec0c6722947c69', 'message': 'Refactor fake data for projects and users\n\n* Move fake data structures into tests/identity/fakes.py\n* Use fake clients correctly and support multiple client versions\n\nChange-Id: Icacbb2ca740b63937bd2c4442af61b620638b53e\n'}, {'number': 3, 'created': '2013-08-30 21:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/05d5b3258821788bf12cbb0694cf6c6412096c66', 'message': 'Refactor fake data for projects and users\n\n* Move fake data structures into tests/identity/fakes.py\n* Use fake clients correctly and support multiple client versions\n\nChange-Id: Icacbb2ca740b63937bd2c4442af61b620638b53e\n'}, {'number': 4, 'created': '2013-09-04 19:48:32.000000000', 'files': ['openstackclient/tests/identity/fakes.py', 'openstackclient/tests/identity/test_identity.py', 'openstackclient/tests/identity/v2_0/test_project.py', 'openstackclient/tests/identity/v2_0/test_projects.py', 'openstackclient/tests/fakes.py', 'openstackclient/tests/object/v1/lib/test_object.py', 'openstackclient/tests/identity/v2_0/test_user.py', 'openstackclient/tests/object/v1/lib/test_container.py', 'openstackclient/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/eb405a88c47e91633ecb110122410aa24c24f9cd', 'message': 'Refactor fake data for projects and users\n\n* Move fake data structures into tests/identity/fakes.py\n* Use fake clients correctly and support multiple client versions\n\nChange-Id: Icacbb2ca740b63937bd2c4442af61b620638b53e\n'}]",0,44167,eb405a88c47e91633ecb110122410aa24c24f9cd,16,2,4,970,,,0,"Refactor fake data for projects and users

* Move fake data structures into tests/identity/fakes.py
* Use fake clients correctly and support multiple client versions

Change-Id: Icacbb2ca740b63937bd2c4442af61b620638b53e
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/67/44167/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/identity/fakes.py', 'openstackclient/tests/identity/v2_0/test_project.py', 'openstackclient/tests/identity/v2_0/test_projects.py', 'openstackclient/tests/identity/v2_0/test_user.py']",4,1fd377cfc7c3249555c100601993929d4ff4646d,refactor-fakes," copy.deepcopy(identity_fakes.PROJECT), copy.deepcopy(identity_fakes.USER), arglist = [ identity_fakes.user_name, ] ('name', identity_fakes.user_name), identity_fakes.user_name, datalist = ( identity_fakes.user_email, True, identity_fakes.user_id, identity_fakes.user_name, identity_fakes.project_id, ) arglist = [ '--password', 'secret', identity_fakes.user_name, ] verifylist = [ ('name', identity_fakes.user_name), ('password', 'secret') ] identity_fakes.user_name, datalist = ( identity_fakes.user_email, True, identity_fakes.user_id, identity_fakes.user_name, identity_fakes.project_id, ) arglist = [ '--email', 'barney@example.com', identity_fakes.user_name, ] verifylist = [ ('name', identity_fakes.user_name), ('email', 'barney@example.com'), ] identity_fakes.user_name, datalist = ( identity_fakes.user_email, True, identity_fakes.user_id, identity_fakes.user_name, identity_fakes.project_id, ) copy.deepcopy(identity_fakes.PROJECT_2), USER_2 = copy.deepcopy(identity_fakes.USER) USER_2['tenantId'] = identity_fakes.PROJECT_2['id'] arglist = [ '--project', identity_fakes.PROJECT_2['name'], identity_fakes.user_name, ] verifylist = [ ('name', identity_fakes.user_name), ('project', identity_fakes.PROJECT_2['name']), ] 'tenant_id': identity_fakes.PROJECT_2['id'], identity_fakes.user_name, datalist = ( identity_fakes.user_email, True, identity_fakes.user_id, identity_fakes.user_name, identity_fakes.PROJECT_2['id'], ) arglist = [ '--enable', identity_fakes.user_name, ] verifylist = [ ('name', identity_fakes.user_name), ('enable', True), ('disable', False), ] identity_fakes.user_name, datalist = ( identity_fakes.user_email, True, identity_fakes.user_id, identity_fakes.user_name, identity_fakes.project_id, ) arglist = [ '--disable', identity_fakes.user_name, ] verifylist = [ ('name', identity_fakes.user_name), ('enable', False), ('disable', True), ] identity_fakes.user_name, datalist = ( identity_fakes.user_email, True, identity_fakes.user_id, identity_fakes.user_name, identity_fakes.project_id, ) copy.deepcopy(identity_fakes.USER), arglist = [ identity_fakes.user_id, ] ('user', identity_fakes.user_id), self.users_mock.delete.assert_called_with( identity_fakes.user_id, ) copy.deepcopy(identity_fakes.USER), datalist = (( identity_fakes.user_id, identity_fakes.user_name, ), ) arglist = [ '--project', identity_fakes.project_id, ] verifylist = [ ('project', identity_fakes.project_id), ] datalist = (( identity_fakes.user_id, identity_fakes.user_name, ), ) arglist = [ '--long', ] verifylist = [ ('long', True), ] datalist = (( identity_fakes.user_id, identity_fakes.user_name, identity_fakes.project_id, identity_fakes.user_email, True, ), ) copy.deepcopy(identity_fakes.PROJECT), copy.deepcopy(identity_fakes.USER), arglist = [ identity_fakes.user_name, ] ('user', identity_fakes.user_name), # SetUser doesn't call anything if no args are passed arglist = [ '--name', 'qwerty', identity_fakes.user_name, ] verifylist = [ ('name', 'qwerty'), ] self.users_mock.update.assert_called_with( identity_fakes.user_id, **kwargs ) arglist = [ '--password', 'secret', identity_fakes.user_name, ] verifylist = [ ('password', 'secret'), ] self.users_mock.update_password.assert_called_with( identity_fakes.user_id, 'secret', ) arglist = [ '--email', 'barney@example.com', identity_fakes.user_name, ] verifylist = [ ('email', 'barney@example.com'), ] self.users_mock.update.assert_called_with( identity_fakes.user_id, **kwargs ) arglist = [ '--project', identity_fakes.project_id, identity_fakes.user_name, ] verifylist = [ ('project', identity_fakes.project_id), ] identity_fakes.user_id, identity_fakes.project_id, arglist = [ '--enable', identity_fakes.user_name, ] verifylist = [ ('enable', True), ('disable', False), ] self.users_mock.update.assert_called_with( identity_fakes.user_id, **kwargs ) arglist = [ '--disable', identity_fakes.user_name, ] verifylist = [ ('enable', False), ('disable', True), ] self.users_mock.update.assert_called_with( identity_fakes.user_id, **kwargs ) copy.deepcopy(identity_fakes.USER), arglist = [ identity_fakes.user_id, ] verifylist = [ ('user', identity_fakes.user_id), ] self.users_mock.get.assert_called_with(identity_fakes.user_id) datalist = ( identity_fakes.user_email, True, identity_fakes.user_id, identity_fakes.user_name, identity_fakes.project_id, )","user_id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' user_name = 'paul' user_description = 'Sir Paul' user_email = 'paul@applecorps.com' project_id = '8-9-64' project_name = 'beatles' project_description = 'Fab Four' USER = { 'id': user_id, 'name': user_name, 'tenantId': project_id, 'email': user_email, 'enabled': True, } PROJECT = { 'id': project_id, 'name': project_name, 'description': project_description, 'enabled': True, } PROJECT_2 = { 'id': project_id + '-2222', 'name': project_name + ' reprise', 'description': project_description + 'plus four more', 'enabled': True, } copy.deepcopy(PROJECT), copy.deepcopy(USER), arglist = [user_name] ('name', user_name), user_name, datalist = (user_email, True, user_id, user_name, project_id) arglist = ['--password', 'secret', user_name] verifylist = [('password', 'secret')] user_name, datalist = (user_email, True, user_id, user_name, project_id) arglist = ['--email', 'barney@example.com', user_name] verifylist = [('email', 'barney@example.com')] user_name, datalist = (user_email, True, user_id, user_name, project_id) copy.deepcopy(PROJECT_2), USER_2 = copy.deepcopy(USER) USER_2['tenantId'] = PROJECT_2['id'] arglist = ['--project', PROJECT_2['name'], user_name] verifylist = [('project', PROJECT_2['name'])] 'tenant_id': PROJECT_2['id'], user_name, datalist = (user_email, True, user_id, user_name, PROJECT_2['id']) arglist = ['--enable', project_name] verifylist = [('enable', True), ('disable', False)] project_name, datalist = (user_email, True, user_id, user_name, project_id) arglist = ['--disable', project_name] verifylist = [('enable', False), ('disable', True)] project_name, datalist = (user_email, True, user_id, user_name, project_id) copy.deepcopy(USER), arglist = [user_id] ('user', user_id), self.users_mock.delete.assert_called_with(user_id) copy.deepcopy(USER), datalist = ((user_id, user_name), ) arglist = ['--project', project_id] verifylist = [('project', project_id)] datalist = ((user_id, user_name), ) arglist = ['--long'] verifylist = [('long', True)] datalist = ((user_id, user_name, project_id, user_email, True), ) copy.deepcopy(PROJECT), copy.deepcopy(USER), arglist = [user_name] ('user', user_name), arglist = ['--name', 'qwerty', user_name] verifylist = [('name', 'qwerty')] self.users_mock.update.assert_called_with(user_id, **kwargs) arglist = ['--password', 'secret', user_name] verifylist = [('password', 'secret')] self.users_mock.update_password.assert_called_with(user_id, 'secret') arglist = ['--email', 'barney@example.com', user_name] verifylist = [('email', 'barney@example.com')] self.users_mock.update.assert_called_with(user_id, **kwargs) arglist = ['--project', project_id, user_name] verifylist = [('project', project_id)] user_id, project_id, arglist = ['--enable', user_name] verifylist = [('enable', True), ('disable', False)] self.users_mock.update.assert_called_with(user_id, **kwargs) arglist = ['--disable', user_name] verifylist = [('enable', False), ('disable', True)] self.users_mock.update.assert_called_with(user_id, **kwargs) copy.deepcopy(USER), arglist = [user_id] verifylist = [('user', user_id)] self.users_mock.get.assert_called_with(user_id) datalist = (user_email, True, user_id, user_name, project_id)",712,456
openstack%2Foslo-incubator~stable%2Fgrizzly~I2f0e88435748bab631d969573d3a598d9e1f7fef,openstack/oslo-incubator,stable/grizzly,I2f0e88435748bab631d969573d3a598d9e1f7fef,Fix problem when sending long messages in Qpid,MERGED,2013-09-02 12:43:38.000000000,2013-09-04 21:23:30.000000000,2013-09-04 21:23:30.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1561}, {'_account_id': 1955}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-09-02 12:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/28551da262607aebfbd1592bf5e625be07e670b2', 'message': 'Fix problem when sending long messages in Qpid\n\nQpid has a limitation where it cannot serialize a dict containing a\nstring greater than 65535 characters. This change alters the Qpid\nimplementation to JSON encode the dict before sending it, but only if\nQpid would fail to serialize it. This maintains as much backward\ncompatibility as possible, though long messages will still fail if they\nare sent to an older receiver.\n\nThe first part of this fix was ported to Grizzly in Ib52e9458a to allow\nreceiving messages from Havana using the new format. Even though this\nchange will modify the message format, it will only do it when messages\nare longer than 65K which would be broken anyway and could cause serious\nbugs like the one linked below.\n\nFixes bug #1215091 (CVE-2013-4261)\n\nChange-Id: I2f0e88435748bab631d969573d3a598d9e1f7fef\n'}, {'number': 2, 'created': '2013-09-02 13:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/557595374297533209375ab737e0d50082ac0a8b', 'message': 'Fix problem when sending long messages in Qpid\n\nQpid has a limitation where it cannot serialize a dict containing a\nstring greater than 65535 characters. This change alters the Qpid\nimplementation to JSON encode the dict before sending it, but only if\nQpid would fail to serialize it. This maintains as much backward\ncompatibility as possible, though long messages will still fail if they\nare sent to an older receiver.\n\nThe first part of this fix was ported to Grizzly in I8b6c5734b to allow\nreceiving messages from Havana using the new format. Even though this\nchange will modify the message format, it will only do it when messages\nare longer than 65K which would be broken anyway and could cause serious\nbugs like the one linked below.\n\nFixes bug #1215091\n\nChange-Id: I2f0e88435748bab631d969573d3a598d9e1f7fef\n'}, {'number': 3, 'created': '2013-09-02 13:02:44.000000000', 'files': ['openstack/common/rpc/impl_qpid.py', 'tests/unit/rpc/test_qpid.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/4f97479ad078771f6f25461c95203a5d293ec08b', 'message': 'Fix problem when sending long messages in Qpid\n\nQpid has a limitation where it cannot serialize a dict containing a\nstring greater than 65535 characters. This change alters the Qpid\nimplementation to JSON encode the dict before sending it, but only if\nQpid would fail to serialize it. This maintains as much backward\ncompatibility as possible, though long messages will still fail if they\nare sent to an older receiver.\n\nThe first part of this fix was ported to Grizzly in I8b6c5734b to allow\nreceiving messages from Havana using the new format. Even though this\nchange will modify the message format, it will only do it when messages\nare longer than 65K which would be broken anyway and could cause serious\nbugs like the one linked below.\n\nFixes bug 1215091\n\nChange-Id: I2f0e88435748bab631d969573d3a598d9e1f7fef\n'}]",0,44695,4f97479ad078771f6f25461c95203a5d293ec08b,12,5,3,7808,,,0,"Fix problem when sending long messages in Qpid

Qpid has a limitation where it cannot serialize a dict containing a
string greater than 65535 characters. This change alters the Qpid
implementation to JSON encode the dict before sending it, but only if
Qpid would fail to serialize it. This maintains as much backward
compatibility as possible, though long messages will still fail if they
are sent to an older receiver.

The first part of this fix was ported to Grizzly in I8b6c5734b to allow
receiving messages from Havana using the new format. Even though this
change will modify the message format, it will only do it when messages
are longer than 65K which would be broken anyway and could cause serious
bugs like the one linked below.

Fixes bug 1215091

Change-Id: I2f0e88435748bab631d969573d3a598d9e1f7fef
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/95/44695/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/rpc/impl_qpid.py', 'tests/unit/rpc/test_qpid.py']",2,28551da262607aebfbd1592bf5e625be07e670b2,bug/1215091," def _test_publisher(self, message=True): """"""Test that messages containing long strings are correctly serialized in a way that Qpid can handle. :param message: The publisher may be passed either a Qpid Message object or a bare dict. This parameter controls which of those the test will send. """""" self.sent_msg = None def send_stub(msg): self.sent_msg = msg # Qpid cannot serialize a dict containing a string > 65535 chars. raw_msg = {'test': 'a' * 65536} if message: base_msg = qpid.messaging.Message(raw_msg) else: base_msg = raw_msg expected_msg = qpid.messaging.Message(jsonutils.dumps(raw_msg)) expected_msg.content_type = impl_qpid.JSON_CONTENT_TYPE mock_session = self.mox.CreateMock(self.orig_session) mock_sender = self.mox.CreateMock(self.orig_sender) mock_session.sender(mox.IgnoreArg()).AndReturn(mock_sender) self.stubs.Set(mock_sender, 'send', send_stub) self.mox.ReplayAll() publisher = impl_qpid.Publisher(mock_session, 'test_node') publisher.send(base_msg) self.assertEqual(self.sent_msg.content, expected_msg.content) self.assertEqual(self.sent_msg.content_type, expected_msg.content_type) def test_publisher_long_message(self): self._test_publisher(message=True) def test_publisher_long_dict(self): self._test_publisher(message=False) ",,67,0
openstack%2Ftempest~master~Ic21a0d060b8ebd028bc91924e0e8ccc3a9f79176,openstack/tempest,master,Ic21a0d060b8ebd028bc91924e0e8ccc3a9f79176,Force an empty patch to use 'check experimental',ABANDONED,2013-08-27 17:26:55.000000000,2013-09-04 21:18:35.000000000,,"[{'_account_id': 3}, {'_account_id': 1192}]","[{'number': 1, 'created': '2013-08-27 17:26:55.000000000', 'files': ['WIP'], 'web_link': 'https://opendev.org/openstack/tempest/commit/16771bc44e2f5b8f41a9429d3ca971b68a2b68b2', 'message': ""Force an empty patch to use 'check experimental'\n\nChange-Id: Ic21a0d060b8ebd028bc91924e0e8ccc3a9f79176\n""}]",0,43927,16771bc44e2f5b8f41a9429d3ca971b68a2b68b2,10,2,1,1192,,,0,"Force an empty patch to use 'check experimental'

Change-Id: Ic21a0d060b8ebd028bc91924e0e8ccc3a9f79176
",git fetch https://review.opendev.org/openstack/tempest refs/changes/27/43927/1 && git format-patch -1 --stdout FETCH_HEAD,['WIP'],1,16771bc44e2f5b8f41a9429d3ca971b68a2b68b2,heat-slow,,,0,0
openstack%2Fswift~master~I8e82c14ada52d44df5a31e08982ac79cd7e5c969,openstack/swift,master,I8e82c14ada52d44df5a31e08982ac79cd7e5c969,Pep8 unit test modules w/ <= 10 violations (5 of 12),MERGED,2013-09-01 19:15:52.000000000,2013-09-04 21:15:04.000000000,2013-09-04 21:15:03.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 2166}, {'_account_id': 2622}, {'_account_id': 6198}]","[{'number': 1, 'created': '2013-09-01 19:15:52.000000000', 'files': ['test/unit/common/ring/test_utils.py', 'test/unit/common/ring/test_builder.py', 'test/unit/common/middleware/test_formpost.py', 'test/unit/proxy/controllers/test_obj.py', 'test/unit/common/middleware/test_acl.py', 'test/unit/container/test_updater.py', 'test/unit/proxy/controllers/test_base.py', 'test/unit/common/test_manager.py', 'test/unit/common/middleware/test_cname_lookup.py', 'test/unit/common/middleware/test_except.py', 'test/unit/obj/test_updater.py', 'test/unit/common/test_wsgi.py', 'test/unit/common/middleware/test_account_quotas.py', 'test/unit/common/middleware/test_memcache.py', 'test/unit/common/middleware/test_name_check.py', 'test/unit/common/test_bufferedhttp.py', 'test/unit/common/test_swob.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/be1cff4f1f14bff7d310749d1424104f05883b36', 'message': 'Pep8 unit test modules w/ <= 10 violations (5 of 12)\n\nChange-Id: I8e82c14ada52d44df5a31e08982ac79cd7e5c969\nSigned-off-by: Peter Portante <peter.portante@redhat.com>\n'}]",2,44619,be1cff4f1f14bff7d310749d1424104f05883b36,10,6,1,6198,,,0,"Pep8 unit test modules w/ <= 10 violations (5 of 12)

Change-Id: I8e82c14ada52d44df5a31e08982ac79cd7e5c969
Signed-off-by: Peter Portante <peter.portante@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/19/44619/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/ring/test_utils.py', 'test/unit/common/ring/test_builder.py', 'test/unit/common/middleware/test_formpost.py', 'test/unit/proxy/controllers/test_obj.py', 'test/unit/common/middleware/test_acl.py', 'test/unit/container/test_updater.py', 'test/unit/proxy/controllers/test_base.py', 'test/unit/common/test_manager.py', 'test/unit/common/middleware/test_cname_lookup.py', 'test/unit/common/middleware/test_except.py', 'test/unit/obj/test_updater.py', 'test/unit/common/test_wsgi.py', 'test/unit/common/middleware/test_account_quotas.py', 'test/unit/common/middleware/test_memcache.py', 'test/unit/common/middleware/test_name_check.py', 'test/unit/common/test_bufferedhttp.py', 'test/unit/common/test_swob.py', 'test/unit/common/test_utils.py']",18,be1cff4f1f14bff7d310749d1424104f05883b36,pep8-test," expected_args.append( ((), {'facility': orig_sysloghandler.LOG_LOCAL3})) self.assertRaises( Exception, self.assertRaises( BaseException, with utils.lock_file( nt.name, timeout=1, unlink=False) as f: self.assertTrue( False, ""Expected LockTimeout exception"") self.assertRaises( IOError, fcntl.flock, fd, fcntl.LOCK_EX | fcntl.LOCK_NB) payload) payload)"," expected_args.append(((), {'facility': orig_sysloghandler.LOG_LOCAL3})) self.assertRaises(Exception, self.assertRaises(BaseException, with utils.lock_file(nt.name, timeout=1, unlink=False) as f: self.assertTrue(False, ""Expected LockTimeout exception"") self.assertRaises(IOError, fcntl.flock, fd, fcntl.LOCK_EX | fcntl.LOCK_NB) payload) payload)",152,106
openstack%2Fpython-novaclient~master~I1aadeafed82b3bd1febcf0d1c3e64b258d6abeda,openstack/python-novaclient,master,I1aadeafed82b3bd1febcf0d1c3e64b258d6abeda,New syntax to boot from a block device mapping,MERGED,2013-07-26 14:40:13.000000000,2013-09-04 21:13:20.000000000,2013-09-04 21:13:20.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 5511}, {'_account_id': 5652}, {'_account_id': 7534}, {'_account_id': 7808}, {'_account_id': 8291}]","[{'number': 1, 'created': '2013-07-26 14:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/72d5a036b29dae74e6e0fabb9e112017d9b019a7', 'message': 'New syntax to boot from a block device mapping\n\nAdd new arguments and syntax for booting from a block device mapping\nthat use the new os-block-device-mapping-v2-boot extension. These\nallow to:\n\n * boot or attach a volume, image or snapshot.\n * attach an swap disk on boot.\n * attach an ephemeral disk on boot.\n\nblueprint: improve-block-device-handling\n\nChange-Id: I1aadeafed82b3bd1febcf0d1c3e64b258d6abeda\n'}, {'number': 2, 'created': '2013-07-26 15:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/b43b09065269282362b0c6000c216a425227575b', 'message': 'New syntax to boot from a block device mapping\n\nAdd new arguments and syntax for booting from a block device mapping\nthat use the new os-block-device-mapping-v2-boot extension. These\nallow to:\n\n * boot or attach a volume, image or snapshot.\n * attach an swap disk on boot.\n * attach an ephemeral disk on boot.\n\nblueprint: improve-block-device-handling\n\nChange-Id: I1aadeafed82b3bd1febcf0d1c3e64b258d6abeda\n'}, {'number': 3, 'created': '2013-07-26 15:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/214f098ee9163b78ed81308b6a7602a85d7a35c3', 'message': 'New syntax to boot from a block device mapping\n\nAdd new arguments and syntax for booting from a block device mapping\nthat use the new os-block-device-mapping-v2-boot extension. These\nallow to:\n\n * boot or attach a volume, image or snapshot.\n * attach an swap disk on boot.\n * attach an ephemeral disk on boot.\n\nblueprint: improve-block-device-handling\n\nChange-Id: I1aadeafed82b3bd1febcf0d1c3e64b258d6abeda\n'}, {'number': 4, 'created': '2013-07-26 16:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/1c79a3e1c1655bbfbe7e2b3bbde21449fc659450', 'message': 'New syntax to boot from a block device mapping\n\nAdd new arguments and syntax for booting from a block device mapping\nthat use the new os-block-device-mapping-v2-boot extension. These\nallow to:\n\n * boot or attach a volume, image or snapshot.\n * attach an swap disk on boot.\n * attach an ephemeral disk on boot.\n\nblueprint: improve-block-device-handling\n\nChange-Id: I1aadeafed82b3bd1febcf0d1c3e64b258d6abeda\n'}, {'number': 5, 'created': '2013-08-02 11:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/4fc7daf7d86adcfdad961a88e6dd3916a3b17c54', 'message': 'New syntax to boot from a block device mapping\n\nAdd new arguments and syntax for booting from a block device mapping\nthat use the new os-block-device-mapping-v2-boot extension. These\nallow to:\n\n * boot from an image, volume  or snapshot (--image, --volume, --snapshot)\n * attach any type of block device (--block-device).\n * attach an swap disk on boot (--swap).\n * attach an ephemeral disk on boot (--ephemeral).\n\nblueprint: improve-block-device-handling\n\nChange-Id: I1aadeafed82b3bd1febcf0d1c3e64b258d6abeda\n'}, {'number': 6, 'created': '2013-08-06 16:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/5f271e7a58a496792a9ebd7fd1c5e78e5f4470cc', 'message': 'New syntax to boot from a block device mapping\n\nAdd new arguments and syntax for booting from a block device mapping\nthat use the new os-block-device-mapping-v2-boot extension. These\nallow to:\n\n * boot from an image, volume or snapshot (--image, --boot-volume, --snapshot)\n * attach any type of block device (--block-device).\n * attach an swap disk on boot (--swap).\n * attach an ephemeral disk on boot (--ephemeral).\n\nblueprint: improve-block-device-handling\n\nDocImpact\n\nChange-Id: I1aadeafed82b3bd1febcf0d1c3e64b258d6abeda\n'}, {'number': 7, 'created': '2013-08-20 14:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/0c3449b870c754aae24fc3a25eaa29c794ba5d77', 'message': 'New syntax to boot from a block device mapping\n\nAdd new arguments and syntax for booting from a block device mapping\nthat use the new os-block-device-mapping-v2-boot extension. These\nallow to:\n\n * boot from an image, volume or snapshot (--image, --boot-volume, --snapshot)\n * attach any type of block device (--block-device).\n * attach an swap disk on boot (--swap).\n * attach an ephemeral disk on boot (--ephemeral).\n\nblueprint: improve-block-device-handling\n\nDocImpact\n\nChange-Id: I1aadeafed82b3bd1febcf0d1c3e64b258d6abeda\n'}, {'number': 8, 'created': '2013-09-04 15:12:32.000000000', 'files': ['novaclient/tests/v1_1/fakes.py', 'novaclient/base.py', 'novaclient/v1_1/servers.py', 'novaclient/tests/v1_1/test_shell.py', 'novaclient/v1_1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/6a85c954c53f868251413db51cc1d9616acd4d02', 'message': 'New syntax to boot from a block device mapping\n\nAdd new arguments and syntax for booting from a block device mapping\nthat use the new os-block-device-mapping-v2-boot extension. These\nallow to:\n\n * boot from an image, volume or snapshot (--image, --boot-volume, --snapshot)\n * attach any type of block device (--block-device).\n * attach an swap disk on boot (--swap).\n * attach an ephemeral disk on boot (--ephemeral).\n\nblueprint: improve-block-device-handling\n\nDocImpact\n\nChange-Id: I1aadeafed82b3bd1febcf0d1c3e64b258d6abeda\n'}]",30,38815,6a85c954c53f868251413db51cc1d9616acd4d02,42,7,8,7808,,,0,"New syntax to boot from a block device mapping

Add new arguments and syntax for booting from a block device mapping
that use the new os-block-device-mapping-v2-boot extension. These
allow to:

 * boot from an image, volume or snapshot (--image, --boot-volume, --snapshot)
 * attach any type of block device (--block-device).
 * attach an swap disk on boot (--swap).
 * attach an ephemeral disk on boot (--ephemeral).

blueprint: improve-block-device-handling

DocImpact

Change-Id: I1aadeafed82b3bd1febcf0d1c3e64b258d6abeda
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/15/38815/2 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/v1_1/fakes.py', 'novaclient/base.py', 'novaclient/v1_1/servers.py', 'novaclient/tests/v1_1/test_shell.py', 'novaclient/v1_1/shell.py']",5,72d5a036b29dae74e6e0fabb9e112017d9b019a7,bp/improve-block-device-handling,"def _parse_block_device_mapping(args): bdm = [] for device_spec in args.block_device_mapping: device_name, mapping = device_spec.split('=', 1) # # The mapping is in the format: # <id>:[<type>]:[<size(GB)>]:[<delete_on_terminate>] # bdm_dict = {'device_name': device_name} mapping_parts = mapping.split(':') source_id = mapping_parts[0] if len(mapping_parts) == 1: bdm_dict['volume_id'] = source_id if len(mapping_parts) > 1: source_type = mapping_parts[1] if source_type.startswith('snap'): bdm_dict['snapshot_id'] = source_id else: bdm_dict['volume_id'] = source_id if len(mapping_parts) > 2 and mapping_parts[2]: bdm_dict['volume_size'] = str(int(mapping_parts[2])) if len(mapping_parts) > 3: bdm_dict['delete_on_termination'] = mapping_parts[3] bdm.append(bdm_dict) return bdm def _parse_block_device_mapping_v2(args): bdm = [] _translate_bdm_keys = { 'id': 'uuid', 'source': 'source_type', 'dest': 'destination_type', 'bus': 'disk_bus', 'name': 'device_name', 'size': 'volume_size', 'format': 'guest_format', 'bootindex': 'boot_index', 'device': 'device_type', 'shutdown': 'delete_on_termination', } for device_spec in args.attach_block_device: spec_dict = dict(v.split('=') for v in device_spec.split(',')) bdm_dict = {} for key, value in spec_dict.iteritems(): bdm_dict[_translate_bdm_keys[key]] = value # Convert the delete_on_termination to a boolean or set it to true by # default for local block devices when not specified. if 'delete_on_termination' in bdm_dict: action = bdm_dict['delete_on_termination'] bdm_dict['delete_on_termination'] = action == 'remove' elif bdm_dict.get('destination_type') == 'local': bdm_dict['delete_on_termination'] = True bdm.append(bdm_dict) for volume_id in args.attach_volume: bdm_dict = {'uuid': volume_id, 'delete_on_termination': False, 'source_type': 'volume', 'destination_type': 'volume'} bdm.append(bdm_dict) for snapshot_id in args.attach_snapshot: bdm_dict = {'uuid': snapshot_id, 'delete_on_termination': False, 'source_type': 'snapshot', 'destination_type': 'volume'} bdm.append(bdm_dict) for image_id in args.attach_image: bdm_dict = {'uuid': image_id, 'delete_on_termination': False, 'source_type': 'image', 'destination_type': 'volume'} bdm.append(bdm_dict) for swap_size in args.attach_swap: bdm_dict = {'source_type': 'blank', 'destination_type': 'local', 'boot_index': -1, 'delete_on_termination': True, 'guest_format': 'swap', 'volume_size': swap_size} bdm.append(bdm_dict) for ephemeral_spec in args.attach_ephemeral: bdm_dict = {'source_type': 'blank', 'destination_type': 'local', 'boot_index': -1, 'delete_on_termination': True} eph_dict = dict(v.split('=') for v in ephemeral_spec.split(',')) if 'size' in eph_dict: bdm_dict['volume_size'] = eph_dict['size'] if 'format' in eph_dict: bdm_dict['guest_format'] = eph_dict['format'] bdm.append(bdm_dict) return bdm block_device_mapping = _parse_block_device_mapping(args) block_device_mapping_v2 = _parse_block_device_mapping_v2(args) if not image and not (block_device_mapping or block_device_mapping_v2): raise exceptions.CommandError(""you need to specify an Image ID "" ""or a block device mapping "" ""or provide a set of properties to match"" "" against an image"") if block_device_mapping and block_device_mapping_v2: raise exceptions.CommandError( ""you must use only type of arguments when defining block devices: "" ""either the --block-device-mapping or any of the --attach-*"" ) block_device_mapping_v2=block_device_mapping_v2,@utils.arg('--attach-block-device', metavar=""<block device specification>"", action='append', default=[], help=""Block device mapping with the syntax:\n"" ""id=<image_id|snapshot_id|volume_id>,\n"" ""source=<image|snapshot|volume|blank>,\n"" ""dest=<volume|local>,bus=<disk bus>,\n"" ""name=<device name>,size=<device size>,\n"" ""format=<swap|ext3|iso|ntfs|...>,bootindex=<0|1|...>,\n"" ""device=<device type: disk|cdrom|...>,\n"" ""shutdown=<preserve|remove>"") @utils.arg('--attach-volume', metavar=""<volume_id>"", action='append', default=[], help=""Attach a volume block device."") @utils.arg('--attach-snapshot', metavar=""<snapshot_id>"", action='append', default=[], help=""Attach a volume block device from an snapshot."") @utils.arg('--attach-image', metavar=""<image_id>"", action='append', default=[], help=""Attach a volume block device from an image."") @utils.arg('--attach-swap', metavar=""<swap_size>"", action='append', default=[], help=""Create and attach a local swap block device of <swap_size> GB."") @utils.arg('--attach-ephemeral', metavar=""size=<size>[,format=<format>]"", action='append', default=[], help=""Create and attach a local ephemeral block device of <size> GB "" ""and format it to <format>."")"," if not image and not args.block_device_mapping: raise exceptions.CommandError(""you need to specify an Image ID "" ""or a block device mapping "" ""or provide a set of properties to match"" "" against an image"") block_device_mapping = {} for bdm in args.block_device_mapping: device_name, mapping = bdm.split('=', 1) block_device_mapping[device_name] = mapping",282,38
openstack%2Fnova~master~I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4,openstack/nova,master,I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4,Nova support for vmware cinder driver,MERGED,2013-08-05 16:11:33.000000000,2013-09-04 21:12:52.000000000,2013-09-04 21:12:49.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5638}, {'_account_id': 7400}, {'_account_id': 7575}, {'_account_id': 7629}]","[{'number': 1, 'created': '2013-08-05 16:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df5742fff64a6d8e17bde109b6bcc1f05ee2bac7', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}, {'number': 2, 'created': '2013-08-06 11:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d094e67582e6b2f6018c44df1d272404b7489d8', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}, {'number': 3, 'created': '2013-08-06 18:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01a18f0c5d7f95d59181ba96299d6f342f0a0c70', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}, {'number': 4, 'created': '2013-08-07 14:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/88cc76b57034e07f6338b5d28d13d894d80c659c', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}, {'number': 5, 'created': '2013-08-07 16:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f36fe83305a6a6ea994229943437689a9f19f2e5', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}, {'number': 6, 'created': '2013-08-08 13:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59709a5c1e45e6cae81da0dacdbcb8cf4fb028ae', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}, {'number': 7, 'created': '2013-08-12 08:28:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff8f1aacd1956bd8dbda2fa58bf003b954cdce08', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}, {'number': 8, 'created': '2013-08-20 10:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db94d123eb3beab0b019c9b22dfe2203386ab677', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}, {'number': 9, 'created': '2013-09-01 13:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10d5ae1eb4d3fa9f726aee5d52ffa3294cb8ebec', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}, {'number': 10, 'created': '2013-09-03 18:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d4aae15fd2e02c74ab790c8a065941fb5cb876b', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}, {'number': 11, 'created': '2013-09-03 18:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b7d8d86aa922f2b2dcd3eaa35170ee4d42cf94eb', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}, {'number': 12, 'created': '2013-09-04 16:20:49.000000000', 'files': ['nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/virt/vmwareapi/volumeops.py', 'nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/vim.py', 'nova/virt/vmwareapi/vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2c7a994ab3685c2532386356bc2e276a0f9e681c', 'message': 'Nova support for vmware cinder driver\n\nPart of blueprint vmware-nova-cinder-support\n\nThis is the first part of the blueprint that deals with attachment\nand detachment of volumes.\n\nChange-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4\n'}]",10,40245,2c7a994ab3685c2532386356bc2e276a0f9e681c,65,11,12,1653,,,0,"Nova support for vmware cinder driver

Part of blueprint vmware-nova-cinder-support

This is the first part of the blueprint that deals with attachment
and detachment of volumes.

Change-Id: I3ad8ae127eef7bfe600be91629c9352a7a5fa4b4
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/40245/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/virt/vmwareapi/volumeops.py', 'nova/virt/vmwareapi/vm_util.py']",3,df5742fff64a6d8e17bde109b6bcc1f05ee2bac7,bp/multiple-clusters-managed-by-one-service," device_name=None, extra_options=None): if extra_options: # add the key value pairs extra_config = [] for key, value in extra_options.iteritems(): opt = client_factory.create('ns0:OptionValue') opt.key = key opt.value = value extra_config.append(opt) config_spec.extraConfig = extra_config def get_file_backed_disk(hardware_devices, file_path): """"""Get the virtual disk backed by input file."""""" if hardware_devices.__class__.__name__ == ""ArrayOfVirtualDevice"": hardware_devices = hardware_devices.VirtualDevice for device in hardware_devices: if (device.__class__.__name__ == ""VirtualDisk"" and device.backing.__class__.__name__ == ""VirtualDiskFlatVer2BackingInfo"" and device.backing.fileName == file_path): return device", device_name=None):,143,24
openstack%2Foperations-guide~master~Ia3136d21c0ab542ffd9201ed077498def1532232,openstack/operations-guide,master,Ia3136d21c0ab542ffd9201ed077498def1532232,Add Japanese translation file.,MERGED,2013-08-31 12:56:19.000000000,2013-09-04 21:00:11.000000000,2013-09-04 21:00:11.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 3108}]","[{'number': 1, 'created': '2013-08-31 12:56:19.000000000', 'files': ['doc/src/docbkx/openstack-ops/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/758430f7a0c900607cf31da48b0194ae6ba8907f', 'message': 'Add Japanese translation file.\n\nChange-Id: Ia3136d21c0ab542ffd9201ed077498def1532232\n'}]",0,44591,758430f7a0c900607cf31da48b0194ae6ba8907f,7,3,1,7029,,,0,"Add Japanese translation file.

Change-Id: Ia3136d21c0ab542ffd9201ed077498def1532232
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/91/44591/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-ops/locale/ja.po'],1,758430f7a0c900607cf31da48b0194ae6ba8907f,ops-guide-ja,"# # Translators: # Akihiro MOTOKI <amotoki@gmail.com>, 2013 # Akira Yoshiyama <akirayoshiyama@gmail.com>, 2013 # daisy.ycguo <daisy.ycguo@gmail.com>, 2013 # doki701 <tokidokidokidoki@gmail.com>, 2013 # thatsdone <masanori.itoh@gmail.com>, 2013 # thatsdone <masanori.itoh@gmail.com>, 2013 # masayukig <masayuki.igawa@gmail.com>, 2013 # masayukig <masayuki.igawa@gmail.com>, 2013 # *はたらくpokotan* <>, 2013 # *はたらくpokotan* <>, 2013 # Shirayuki/しらゆき Shira <shirayuking@gmail.com>, 2013 # Tsutomu Takekawa <takekawa@gmail.com>, 2013 # thatsdone <masanori.itoh@gmail.com>, 2013 # tmak <t.makabe@gmail.com>, 2013 # doki701 <tokidokidokidoki@gmail.com>, 2013 # Tomoyuki KATO <tomo@dream.daynight.jp>, 2012-2013 # tmak <t.makabe@gmail.com>, 2013 # Tsutomu Takekawa <takekawa@gmail.com>, 2013 # daisy.ycguo <daisy.ycguo@gmail.com>, 2013 # Shirayuki/しらゆき Shira <shirayuking@gmail.com>, 2013 msgid """" msgstr """" ""Project-Id-Version: OpenStack Manuals\n"" ""POT-Creation-Date: 2013-05-08 15:45+0800\n"" ""PO-Revision-Date: 2013-08-30 08:40+0000\n"" ""Last-Translator: Akihiro MOTOKI <amotoki@gmail.com>\n"" ""Language-Team: Japanese (http://www.transifex.com/projects/p/openstack/language/ja/)\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Language: ja\n"" ""Plural-Forms: nplurals=1; plural=0;\n"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml16(title) msgid ""Network Design"" msgstr ""ネットワーク設計"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml17(para) msgid """" ""OpenStack provides a rich networking environment, and this chapter details "" ""the requirements and options to deliberate when designing your cloud."" msgstr ""OpenStack は高度なネットワーク環境を提供します。本章では、クラウドを設計するときに考慮すべき要件と選択肢について詳細に説明します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml20(para) msgid """" ""If this is the first time you are deploying a cloud infrastructure in your "" ""organisation, after reading this section, your first conversations should be"" "" with your networking team. Network usage in a running cloud is vastly "" ""different from traditional network deployments, and has the potential to be "" ""disruptive at both a connectivity and a policy level."" msgstr ""これがあなたの組織で初めてのクラウド基盤構築であれば、この章を読んだ後、最初にあなたの（組織の）ネットワーク管理チームと相談すべきです。クラウド運用におけるネットワークの使用は伝統的なネットワーク構築とはかなり異なり、接続性とポリシーレベルの両面で破壊的な結果をもたらす可能性があるからです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml27(para) msgid """" ""For example, you must plan the number of IP addresses that you need for both"" "" your guest instances as well as management infrastructure. Additionally, "" ""you must research and discuss cloud network connectivity through proxy "" ""servers and firewalls."" msgstr ""例えば、管理インフラだけでなくゲストインスタンス用のIPアドレスの数も計画しなければなりません。加えて、プロキシサーバーやファイアウォールを経由してのクラウドネットワークの接続性を調査・議論する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml33(title) msgid ""Management Network"" msgstr ""管理ネットワーク"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml34(para) msgid """" ""A management network, typically consisting of a separate switch and separate"" "" NICs, is a recommended option. This segregation prevents system "" ""administration and monitoring system access from being disrupted by traffic "" ""generated by the guests themselves."" msgstr ""管理ネットワークを用意するのはお薦めの選択肢です。通常、管理ネットワークは専用のスイッチと NIC で構成します。ネットワークを分離することで、システム管理と監視システムアクセスが、ゲスト自身が生成するトラフィックによって邪魔されることがなくなります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml39(para) msgid """" ""Consider creating other private networks for communication between internal "" ""components of OpenStack, such as the Message Queue and OpenStack Compute. "" ""VLANs are great for these scenarios."" msgstr ""メッセージキューや OpenStack Compute といった OpenStack 内部のコンポーネント間の通信用に別のプライベートネットワークを作成することを検討して下さい。 VLAN はこれらのシナリオに非常に適しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml45(title) msgid ""Public Addressing Options"" msgstr ""パブリックアドレスの選択肢"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml46(para) msgid """" ""There are two main types of IP addresses for guest virtual machines: Fixed "" ""IPs and Floating IPs. Fixed IPs are assigned to instances on boot, whereas "" ""Floating IP addresses can change their association between instances by "" ""action of the user. Both types of IP addresses can either be public or "" ""private, depending on your use case."" msgstr ""ゲストの仮想マシン用の IP アドレスは、固定 IP とフローティング IP の2種類に大別できます。固定 IP はインスタンス起動時にインスタンスに割り当てられ、フローティング IP はユーザ操作によりインスタンスへの割り当てを変更できます。どちらのタイプの IP アドレスについても、パブリックアドレス、プライベートアドレスのいずれかをあなたの用途に合わせて選択することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml53(para) msgid """" ""Fixed IP addresses are required, whereas it is possible to run OpenStack "" ""without Floating IPs. One of the most common use cases for Floating IPs is "" ""to provide public IP addresses to a private cloud, where there are a limited"" "" number of IP addresses available. Another is for a public cloud user to "" ""have a \""static\"" IP address that can be reassigned when an instance is "" ""upgraded or moved."" msgstr ""固定 IP アドレスは必須ですが、フローティング IP はなくても OpenStack を実行することができます。フローティング IP の最も一般的な用途の１つは、利用可能なIPアドレス数が限られているプライベートクラウドでパブリックIPアドレスを利用できるようにすることです。他の用途としては、パブリッククラウドのユーザが、インスタンスがアップグレードや移動した際でも割り当て直すことができる「静的」 IP アドレスを利用できるようにすることです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml60(para) msgid """" ""Fixed IP addresses can be private for private clouds, or public for public "" ""clouds. When an instance terminates, its Fixed IP is lost. It is worth "" ""noting that newer users of cloud computing may find their ephemeral nature "" ""frustrating."" msgstr ""固定IPアドレスは、プライベートクラウドではプライベートアドレスに、パブリッククラウドではパブリックアドレスにすることが出来ます。インスタンスが削除される際、そのインスタンスの固定IPは割当を解除されます。IPアドレスが使い終わったらすぐに解放されてしまうという動作に、クラウドコンピューティングの初心者がストレスを感じる可能性があることに注意しましょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml67(title) msgid ""IP Address Planning"" msgstr ""IP アドレス計画"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml68(para) msgid """" ""An OpenStack installation can potentially have many subnets, and different "" ""types of services in each. An IP address plan can assist with a shared "" ""understanding of network partition purposes and scalability. Control "" ""services can have public and private IP addresses, and as noted above there "" ""are a couple of options for instance's public addresses."" msgstr ""OpenStack のインストールでは、潜在的に、多数のサブネットと、サブネット毎に異なる種類のサービスが存在する可能性があります。IPアドレス計画は、ネットワーク分割の目的とスケーラビリティに関する理解を共有するのに役立ちます。コントロールサービスはパブリックIPアドレスとプライベートIPアドレスを持つ場合があり、上記の通り、インスタンスのパブリックIPアドレスには2種類のオプションが存在します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml75(para) msgid ""An IP address plan might be broken down into the following sections:"" msgstr ""IPアドレス計画は以下のセクションに分類できるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml80(para) msgid ""subnet router"" msgstr ""サブネットルータ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml81(para) msgid """" ""Packets leaving the subnet go via this address, which could be a dedicated "" ""router or a nova-network service."" msgstr ""このサブネットから出て行くパケットはこのアドレスを経由して出て行きます。このアドレスは、専用ルータにすることも、nova-network サービスにすることもできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml86(para) msgid ""control services public interfaces"" msgstr ""コントロールサービスのパブリックインターフェース"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml88(para) msgid """" ""Public access to <code>swift-proxy</code>, <code>nova-api</code>, <code"" "">glance-api</code> and horizon come to these addresses, which could be on "" ""one side of a load balancer, or pointing at individual machines."" msgstr ""<code>swift-proxy</code>, <code>nova-api</code>, <code>glance-api</code>, horizon へのパブリックアクセスはこれらのアドレス宛に行われます。これらのアドレスはロードバランサの一方か、個々のマシンに割り当てられます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml97(para) msgid ""Object Storage cluster internal communications"" msgstr ""Object Storage クラスタ内の通信"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml99(para) msgid """" ""Traffic amongst object/account/container servers and between these and the "" ""proxy server's internal interface uses this private network."" msgstr ""object/account/container サーバー間、またはこれらのサーバーとプロキシサーバーの内側のインターフェースとの間の通信は、このプライベートネットワークを使用します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml105(para) msgid ""compute and storage communications"" msgstr ""コンピュートとストレージ間の通信"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml107(para) msgid """" ""If ephemeral or block storage is external to the compute node, this network "" ""is used."" msgstr ""一時ディスクまたはブロックストレージがコンピュートノード以外にある場合、このネットワークが使用されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml112(para) msgid ""out-of-band remote management"" msgstr ""アウトバンドのリモート管理"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml114(para) msgid """" ""If a dedicated remote access controller chip is included in servers, often "" ""these are on a separate network."" msgstr ""専用のリモートアクセスコントローラーチップがサーバーに搭載されている場合、多くの場合、これらは独立したネットワーク上に置かれます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml119(para) msgid ""in-band remote management"" msgstr ""インバンドのリモート管理"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml120(para) msgid """" ""Often, an extra (such as, 1 GB) interface on compute or storage nodes is "" ""used for system administrators or monitoring tools to access the host "" ""instead of going through the public interface."" msgstr ""多くの場合、システム管理者や監視ツールからホストへのアクセスは、パブリックインタフェース経由ではなく、コンピュートノード、ストレージノードの (1Gbps などの) 追加のインタフェース経由で行われます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml128(para) msgid ""spare space for future growth"" msgstr ""将来の拡張用の予備のアドレス空間"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml130(para) msgid """" ""Adding more public-facing control services, or guest instance IPs should "" ""always be part of your plan."" msgstr ""パブリック側に置かれる制御サービスやゲストインスタンスのIPの追加は、必ずアドレス計画の一部として入れておくべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml136(para) msgid """" ""For example, take a deployment which has both OpenStack Compute and Object "" ""Storage, with private ranges 172.22.42.0/24 and 172.22.87.0/26 available. "" ""One way to segregate the space might be:"" msgstr ""例えば、OpenStack Compute と Object Storage の両方を使用し、プライベートアドレス範囲として 172.22.42.0/24 と 172.22.87.0/26 が利用できる場面を考えます。一例として、アドレス空間を以下のように分割することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml153(para) msgid """" ""A similar approach can be taken with public IP addresses, taking note that "" ""large, flat ranges are preferred for use with guest instance IPs. Take into "" ""account that for some OpenStack networking options, a public IP address in "" ""the range of a guest instance public IP address is assigned to the nova-"" ""compute host."" msgstr ""パブリックIPアドレスの場合でも同様のアプローチが取れます。但し、ゲストインスタンス用のIPとして使用する場合には、大きなフラットなアドレスレンジの方が好まれることに注意した方がよいでしょう。また、OpenStack のネットワーク方式によっては、ゲストインスタンス用のパブリックIPアドレスレンジのうち一つが nova-compute ホストに割り当てられることも考慮する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml162(title) msgid ""Network Topology"" msgstr ""ネットワークトポロジー"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml163(para) msgid """" ""OpenStack Compute provides several network managers, each with their own "" ""strengths and weaknesses. The selection of a network manager changes your "" ""network topology, so the choice should be made carefully."" msgstr ""OpenStack Compute では、数種類のネットワークマネージャーが用意されており、それぞれ長所と短所があります。どのネットワークマネージャーを選択するかは利用するネットワークトポロジーにより変わります。そのため、慎重に選択する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml170(th) msgid ""Type"" msgstr ""種別"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml171(th) msgid ""Strengths"" msgstr ""長所"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml172(th) msgid ""Weaknesses"" msgstr ""短所"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml178(para) msgid ""Flat"" msgstr ""Flat"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml179(para) msgid ""Extremely simple."" msgstr ""極めてシンプル。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml179(para) msgid ""No DHCP broadcasts."" msgstr ""DHCP ブロードキャストなし。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml181(para) msgid ""Requires file injection into the instance."" msgstr ""インスタンスに対するファイルインジェクションが必須。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml182(para) msgid ""Limited to certain distributions of Linux."" msgstr ""特定の Linux ディストリビューションしか利用できない。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml183(para) msgid ""Difficult to configure and is not recommended."" msgstr ""設定の難易度は高く、非推奨。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml188(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml65(para) msgid ""FlatDHCP"" msgstr ""FlatDHCP"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml189(para) msgid ""Relatively simple to setup."" msgstr ""比較的シンプルな構成。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml189(para) msgid ""Standard networking."" msgstr ""標準的なネットワーク。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml190(para) msgid ""Works with all operating systems."" msgstr ""すべてのオペレーティングシステムが利用できる。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml192(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml199(para) msgid ""Requires its own DHCP broadcast domain."" msgstr ""専用の DHCP ブロードキャストドメインが必要。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml196(para) msgid ""VlanManager"" msgstr ""VlanManager"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml197(para) msgid ""Each tenant is isolated to their own VLANs."" msgstr ""各テナントが専用の VLAN で分離される。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml199(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml216(para) msgid ""More complex to set up."" msgstr ""少し複雑な構成。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml201(para) msgid ""Requires many VLANs to be trunked onto a single port."" msgstr ""一つのポートに多数の VLAN をトランクが必要。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml203(para) msgid ""Standard VLAN number limitation."" msgstr ""標準的な VLAN 数の上限。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml204(para) msgid ""Switches must support 802.1q VLAN tagging."" msgstr ""802.1q VLAN タギングに対応したスイッチが必要。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml208(para) msgid ""FlatDHCP Multi-host HA"" msgstr ""FlatDHCP Multi-host HA"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml209(para) msgid """" ""Networking failure is isolated to the VMs running on the hypervisor "" ""affected."" msgstr ""ネットワーク障害が影響を受けるハイパーバイザー上の VM に限定される。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml211(para) msgid ""DHCP traffic can be isolated within an individual host."" msgstr ""DHCP トラフィックは個々のホスト内に閉じ込めることができる。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml213(para) msgid ""Network traffic is distributed to the compute nodes."" msgstr ""ネットワークトラフィックをコンピュートノード全体に分散できる。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml216(para) msgid ""By default, compute nodes need public IP addresses."" msgstr ""デフォルトでは、各コンピュートノードにパブリック IP アドレスが必要となる。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml218(para) msgid """" ""Options must be carefully configured for live migration to work with "" ""networking."" msgstr ""ライブマイグレーションでネットワークが動作するようにするためは、オプションを慎重に設定する必要がある。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml226(title) msgid ""VLANs"" msgstr ""VLAN"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml227(para) msgid """" ""VLAN configuration can be as simple or as complicated as desired. The use of"" "" VLANs has the benefit of allowing each project its own subnet and broadcast"" "" segregation from other projects. to allow OpenStack to efficiently use "" ""VLANs, you must allocate a VLAN range (one for each project) and turn each "" ""compute node switch port into a trunk port."" msgstr ""VLAN 設定は要求に応じて単純にも複雑にもなり得ます。 VLAN を使用すると、各プロジェクトのサブネットとブロードキャストを他のプロジェクトから分離できるというメリットがあります。 OpenStack が VLAN を効率的に利用できるようにするには、ある範囲の VLAN (1プロジェクト 1VLAN) を割り当て、各コンピュートノードのスイッチポートをトランクポートに設定する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml234(para) msgid """" ""For example, if you estimate that your cloud must support a max of 100 "" ""projects, pick a free VLAN range that your network infrastructure is "" ""currently not using (such as, VLAN 200 - 299). You must configure OpenStack "" ""with this range as well as configure your switch ports to allow VLAN traffic"" "" from that range."" msgstr ""例えば、あなたのクラウドでサポートする必要があるプロジェクト数が最大で100と見込まれる場合、ネットワークインフラで現在使用されていない VLAN の範囲を選んで下さい (例えば VLAN 200 - 299)。この VLAN の範囲を OpenStack に設定するとともに、この範囲の VLAN トラフィックを許可するようにスイッチポートを設定しなければいけません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml244(title) msgid ""Multi-NIC"" msgstr ""マルチNIC"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml245(para) msgid """" ""OpenStack Compute has the ability to assign multiple NICs to instances on a "" ""per-project basis. This is generally an advanced feature and not an everyday"" "" request. This can easily be done on a per-request basis, though. However, "" ""be aware that a second NIC uses up an entire subnet or VLAN. This decrements"" "" your total number of supported projects by one."" msgstr ""OpenStack Compute には、一つのインスタンス複数の NIC を割り当てる機能があり、プロジェクト単位に制御できます。一般的には、これは高度な機能で、普段から必要になるものではありません。また、この機能をリクエスト単位で使うことも簡単にできます。しかしながら、2つ目のNICを使うと、サブネット、つまり VLAN が一つまるごと必要になる点に注意して下さい。これにより、全体で収容できるプロジェクト数が一つ減ることになるからです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml254(title) msgid ""Multi-host and Single-host Networking"" msgstr ""マルチホストネットワークとシングルホストネットワーク"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml255(para) msgid """" ""The nova-network service has the ability to operate in a multi-host or "" ""single-host mode. Multi-host is when each compute node runs a copy of nova-"" ""network and the instances on that compute node use the compute node as a "" ""gateway to the Internet. The compute nodes also host the Floating IPs and "" ""Security Groups for instances on that node. Single-host is when a central "" ""server, for example, the cloud controller, runs the <code>nova-"" ""network</code> service. All compute nodes forward traffic from the instances"" "" to the cloud controller. The cloud controller then forwards traffic to the "" ""Internet. The cloud controller hosts the Floating IPs and Security Groups "" ""for all instances on all compute nodes in the cloud."" msgstr ""nova-network は、マルチホストモードでもシングルホストモードでも動作させることができます。マルチホストモードでは、各コンピュートノードで nova-network サービスを動作させ、コンピュートノード上のインスタンスはそのコンピュートノードをインターネットへのゲートウェイとして使用します。コンピュートノードはそのノード上のインスタンスに対してフローティングIPとセキュリティグループ機能も提供します。シングルホストモードでは、1台の中央のサーバー（例えば、クラウドコントローラー）で <code>nova-network</code> を動かします。全コンピュートノードがインスタンスからのトラフィックをクラウドコントローラーに転送し、クラウドコントローラーはトラフィックをインターネットに転送します。クラウドコントローラーは、クラウド上の全インスタンスに対してフローティングIPとセキュリティグループ機能を提供します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml269(para) msgid """" ""There are benefits to both modes. Single-node has the downside of a single "" ""point of failure. If the cloud controller is not available, instances cannot"" "" communicate on the network. This is not true with multi-host, but multi-"" ""host requires that each compute node has a public IP address to communicate "" ""on the Internet. If you are not able to obtain a significant block of public"" "" IP addresses, multi-host might not be an option."" msgstr ""どちらのモードにもメリットがあります。シングルホストモードには、単一障害点というマイナス面があります。クラウドコントローラーが利用できなくなると、インスタンスはネットワークと通信できなくなります。マルチホストモードでは、この状況にはなりませんが、各コンピュートノードはインターネットと通信するためのパブリックIPアドレスが必要となります。十分な大きさのパブリックIPアドレスブロックを取得できない場合には、マルチホストモードは選択肢にならないかもしれません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml281(title) msgid ""Services for Networking"" msgstr ""ネットワーク関係のサービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml282(para) msgid """" ""OpenStack, like any network application, has a number of the standard "" ""considerations to apply, such as DNS and NTP."" msgstr ""OpenStack も、他のネットワークアプリケーション同様、 DNS や NTP など標準的に考慮すべき点が多くあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml287(title) msgid ""NTP"" msgstr ""NTP"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml288(para) msgid """" ""Time synchronisation is a critical element to ensure continued operation of "" ""OpenStack components. Correct time is necessary to avoid errors in instance "" ""scheduling, replication of objects in the object store, and even matching "" ""log timestamps for debugging."" msgstr ""時刻同期は OpenStack のコンポーネントの継続的な動作を保証するためには不可欠な項目です。正しい時刻は、インスタンスのスケジューリング、オブジェクトストアでのオブジェクト複製や、デバッグ時のログのタイムスタンプの突き合わせなどでのエラーを避けるために必要です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml294(para) msgid """" ""All servers running OpenStack components should be able to access an "" ""appropriate NTP server. You may decide to set one up locally, or use the "" ""public pools available from http://www.pool.ntp.org/"" msgstr ""OpenStack のコンポーネントが動作している全てのサーバーから適切な NTP サーバにアクセスできるようにすべきです。 NTP サーバーは自分で用意するか、 http://www.pool.ntp.org/ に載っている公開 NTPサーバーを使うこともできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml299(title) msgid ""DNS"" msgstr ""DNS"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_network_design.xml300(para) msgid """" ""OpenStack does not currently provide DNS services, aside from the dnsmasq "" ""daemon which resides on <code>nova-network</code> hosts. You could consider "" ""providing a dynamic DNS service to allow instances to update a DNS entry "" ""with new IP addresses. You can also consider making a generic forward and "" ""reverse DNS mapping for instance's IP addresses, such as "" ""vm-203-0-113-123.example.com."" msgstr ""<code>nova-network</code> ホスト上で動作する dnsmasq デーモンを除くと、現時点では、OpenStack は DNS サービスを提供していません。ダイナミック DNS サービスを提供して、インスタンスが新しいIPアドレスで DNS エントリを更新できるようにすることを検討する価値があります。また、インスタンスの IP アドレスに対して、vm-203-0-113-123.example.com のような、汎用的な順引き、逆引き DNS マッピング、を行うことを検討してもよいでしょうか。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_whats_next.xml16(title) msgid ""What's Next?"" msgstr ""次はどうする？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_whats_next.xml17(para) msgid """" ""Congratulations! By now, you should have a solid design for your cloud. We "" ""now recommend that you turn to the <link xlink:title=\""OpenStack Install and "" ""Deploy Manual - Ubuntu\"" xlink:href=\""http://docs.openstack.org/folsom/openstack-"" ""compute/install/apt/content/\"">OpenStack Install and Deploy Manual - "" ""Ubuntu</link> (http://docs.openstack.org/folsom/openstack-"" ""compute/install/apt/content/), which contains a step-by-step guide on how to"" "" manually install the OpenStack packages and dependencies on your cloud."" msgstr ""おめでとうございます！ ここまでで、あなたのクラウドのしっかりとした基本設計ができたことでしょう。ここまで来たら、<link xlink:title=\""OpenStack Install and Deploy Manual - Ubuntu\"" xlink:href=\""http://docs.openstack.org/folsom/openstack-compute/install/apt/content/\"">OpenStack Install and Deploy Manual - Ubuntu</link> (http://docs.openstack.org/folsom/openstack-compute/install/apt/content/) を見ることをお薦めします。このマニュアルには、OpenStack パッケージと依存モジュールをあなたのクラウドに手動でインストールする方法がステップバイステップで説明されています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_whats_next.xml25(para) msgid """" ""While it is important for an operator to be familiar with the steps involved"" "" in deploying OpenStack, we also strongly encourage you to evaluate "" ""configuration management tools such as <glossterm>Puppet</glossterm> or "" ""<glossterm>Chef</glossterm> that can help automate this deployment process."" msgstr ""運用者が OpenStack を構築する一つ一つの手順を詳しく知ることも大事ですが、 <glossterm>Puppet</glossterm> や <glossterm>Chef</glossterm> といった設定管理ツールを評価することを強くお薦めします。これらのツールは構築手順を自動化する上で助けとなることでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_whats_next.xml31(para) msgid """" ""In the remainder of the guide, we assume that you have successfully deployed"" "" an OpenStack cloud and are able to perform basic operations such as adding "" ""images, booting instances, and attaching volumes."" msgstr ""このガイドの残りでは、OpenStack クラウドはうまく構築でき、イメージの追加、インスタンスの起動、ボリュームの接続といった基本的な操作は実行できるものとして話を進めます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_whats_next.xml35(para) msgid """" ""As your focus turns to stable operations, we recommend you do an initial "" ""skim of the remainder of the book to get a sense of the content. Some of "" ""this content is useful to read in advance, so that you can put best "" ""practices into effect to simplify your life in the long run. Other content "" ""is more useful as a reference that you might refer when an unexpected event "" ""occurs, such a power failure or troubleshooting a particular problem."" msgstr ""あなたの興味は安定した運用をどのように行うかに移っていると思いますので、この本の残りの部分にどんなことが書かれているかざっと眺めることをお薦めします。いくつかの内容は前もって読んでおくと役に立ちます。ベストプラクティスを実行することで、長い目で見ると運用が楽になることでしょう。他の内容は、電源故障や特定の問題のトラブルシューティングといった予期しない現象が起こったときに参考になります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_dochistory.xml15(title) msgid ""Document Change History"" msgstr ""ドキュメント変更履歴"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_dochistory.xml17(para) msgid """" ""This version of the document replaces and obsoletes all previous versions. "" ""The following table describes the most recent changes:"" msgstr ""このバージョンのドキュメントでは、それ以前のバージョンをすべて置き換えています。以下の変更履歴には、それ以降の最近の変更を記載しています。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml401(None) msgid """" ""@@image: 'figures/releasecyclegrizzlydiagram.png'; "" ""md5=f4cf95f80608d5069f55cb6c27c215a3"" msgstr ""@@image: 'figures/releasecyclegrizzlydiagram.png'; md5=f4cf95f80608d5069f55cb6c27c215a3"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml16(title) msgid ""Upstream OpenStack"" msgstr ""OpenStack コミュニティ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml17(para) msgid """" ""OpenStack is founded on a thriving community which is a source of help, and "" ""welcomes your contributions. This section details some of the ways you can "" ""interact with the others involved."" msgstr ""OpenStack は非常に活発なコミュニティの上に成り立っており、あなたの参加をいつでも待っています。この節では、コミュニティの他の人と交流する方法について詳しく説明します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml23(title) msgid ""Getting Help"" msgstr ""助けを得る"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml24(para) msgid """" ""There are several avenues available for seeking assistance. The quickest way"" "" to is to help the community help you. Search the Q&amp;A sites, mailing "" ""list archives, and bug lists for issues similar to yours. If you can't find "" ""anything, follow the directions for Reporting Bugs in the section below or "" ""use one of the channels for support below."" msgstr ""助けてもらうにはいくつかの方法があります。コミュニティの助けを得るのが一番早い方法です。 Q&amp;A サイト、メーリングリストのアーカイブを検索したり、バグリストにあなたが抱えている問題に似た問題がないか探します。必要な情報が見つからなかった場合、この後の節で説明する手順にしたがってバグ報告を行ったり、以下のサポートチャネルのどれかを使うことになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml31(para) msgid """" ""Your first port of call should be the official OpenStack documentation, "" ""found on http://docs.openstack.org."" msgstr ""最初に確認すべき場所は OpenStack の公式ドキュメントです。 http://docs.openstack.org にあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml33(para) msgid ""You can get questions answered on the ask.openstack.org site."" msgstr ""ask.openstack.org では、すでに回答されている質問を見ることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml34(para) msgid """" ""<link xlink:href=\""https://wiki.openstack.org/wiki/Mailing_Lists\"">Mailing "" ""Lists</link> (https://wiki.openstack.org/wiki/Mailing_Lists) are also a "" ""great place to get help. The wiki page has more information about the "" ""various lists. As an operator, the main lists you should be aware of are:"" msgstr ""<link xlink:href=\""https://wiki.openstack.org/wiki/Mailing_Lists\"">メーリングリスト</link> (https://wiki.openstack.org/wiki/Mailing_Lists) もアドバイスをもらうのに素晴らしい場所です。 Wiki ページにメーリングリストの詳しい情報が載っています。運用者としては、確認しておくべき主要なメーリングリストは以下です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml44(para) msgid """" ""<link xlink:href=\""https://launchpad.net/~openstack\"">General list</link>: "" ""<code>openstack@lists.launchpad.net</code>. The scope of this list is the "" ""current state of OpenStack. This is a very high traffic mailing list, with "" ""many, many emails per day."" msgstr ""<link xlink:href=\""https://launchpad.net/~openstack\"">一般向けメーリングリスト</link>: <code>openstack@lists.launchpad.net</code>. このリストでは、OpenStackの現行リリースに関する話題を扱います。流量は非常に多く、1日にとてもたくさんのメールが流れます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml54(para) msgid """" ""<link xlink:href=\""http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-"" ""operators\"">Operators list</link>: <code>openstack-"" ""operators@lists.openstack.org.</code> This list is intended for discussion "" ""among existing OpenStack cloud operators, such as yourself. Currently, this "" ""list is relatively low traffic, on the order of one email a day."" msgstr ""<link xlink:href=\""http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-operators\"">運用者向けリスト</link>: <code>openstack-operators@lists.openstack.org.</code> このリストは、あなたのように、実際にOpenStackクラウドの運用者間での議論を目的としています。現在のところ、メールの流量はかなり少なく、１日に１通といったレベルです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml65(para) msgid """" ""<link xlink:href=\""http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-"" ""dev\"">Development list</link>: <code>openstack-"" ""dev@lists.openstack.org</code>. The scope of this list is the future state "" ""of OpenStack. This is a high traffic mailing list, with multiple emails per "" ""day."" msgstr ""<link xlink:href=\""http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-dev\"">開発者向けリスト</link>: <code>openstack-dev@lists.openstack.org</code>. このリストでは、OpenStackの今後についての話題を扱います。流量は多く、1日に何通もメールが流れます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml75(para) msgid """" ""We recommend you subscribe to the general list and the operator list, "" ""although you must set up filters to manage the volume for the general list. "" ""You'll also find links to the mailing list archives on the mailing list wiki"" "" page where you can search through the discussions."" msgstr ""一般向けリストと運用者向けリストを購読するのがお薦めです。一般向けリストの流量に対応するにはフィルタを設定する必要があるでしょうが。 Wiki のメーリングリストのページにはメーリングリストのアーカイブへのリンクがあり、そこで議論の過程を検索することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml81(para) msgid """" ""<link xlink:href=\""https://wiki.openstack.org/wiki/IRC\"">Multiple IRC "" ""channels</link> (https://wiki.openstack.org/wiki/IRC) are available for "" ""general questions and developer discussions. The general discussion channel "" ""is <code>#openstack</code> on <code>irc.freenode.net</code>."" msgstr ""一般的な質問用や開発者の議論用など、<link xlink:href=\""https://wiki.openstack.org/wiki/IRC\"">複数の IRC チャネル</link> (https://wiki.openstack.org/wiki/IRC) があります。一般的な議論用のチャネルは <code>irc.freenode.net</code> の <code>#openstack</code>です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml91(title) msgid ""Reporting Bugs"" msgstr ""バグ報告"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml92(para) msgid """" ""As an operator, you are in a very good position to report unexpected "" ""behavior with your cloud. As OpenStack is flexible, you may be the only "" ""individual to report a particular issue. Every issue is important to fix so "" ""it is essential to learn how to easily submit a bug report."" msgstr ""運用者として、あなたは、あなたのクラウドでの予期しない動作を報告できる非常によい立場にいます。 OpenStack は柔軟性が高いので、ある特定の問題を報告するのはあなた一人かもしれません。すべての問題は重要で修正すべきものです。そのためには、簡単にバグ報告を登録する方法を知っておくことは欠かせません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml98(para) msgid """" ""All OpenStack projects use <link "" ""xlink:href=\""http://launchpad.net/\"">Launchpad</link> for bug tracking. You'll "" ""need to create an account on Launchpad before you can submit a bug report."" msgstr ""全ての OpenStack プロジェクトでは、バグ管理に <link xlink:href=\""http://launchpad.net/\"">Launchpad</link> を使っています。バグ報告を行う前に、Launchpad のアカウントを作る必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml104(para) msgid """" ""Once you have a Launchpad account, reporting a bug is as simple as "" ""identifying the project, or projects that are causing the issue. Sometimes "" ""this is more difficult than expected, but those working on the bug triage "" ""are happy to help relocate issues if their not in the right place initially."" msgstr ""Launchpad のアカウントを作った後は、バグを報告するのは、問題の原因となったプロジェクトを特定するのと同じくらい簡単です。場合によっては、思っていたよりも難しいこともありますが、最初のバグ報告が適切な場所でなかったとしても、バグの分類を行う人がバグ報告を適切なプロジェクトに割り当て直してくれます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml112(para) msgid """" ""Report a bug in <link "" ""xlink:href=\""https://bugs.launchpad.net/nova/+filebug\"">Nova</link> "" ""(https://bugs.launchpad.net/nova/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/nova/+filebug\"">Nova</link> のバグ報告 (https://bugs.launchpad.net/nova/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml118(para) msgid """" ""Report a bug in <link xlink:href=\""https://bugs.launchpad.net/python-"" ""novaclient/+filebug\"">python-novaclient</link> (https://bugs.launchpad.net"" ""/python-novaclient/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/python-novaclient/+filebug\"">python-novaclient</link> のバグ報告 (https://bugs.launchpad.net/python-novaclient/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml124(para) msgid """" ""Report a bug in <link "" ""xlink:href=\""https://bugs.launchpad.net/swift/+filebug\"">Swift</link> "" ""(https://bugs.launchpad.net/swift/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/swift/+filebug\"">Swift</link> のバグ報告 (https://bugs.launchpad.net/swift/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml130(para) msgid """" ""Report a bug in <link xlink:href=\""https://bugs.launchpad.net/python-"" ""swiftclient/+filebug\"">python-swiftclient</link> (https://bugs.launchpad.net"" ""/python-swiftclient/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/python-swiftclient/+filebug\"">python-swiftclient</link> のバグ報告(https://bugs.launchpad.net/python-swiftclient/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml137(para) msgid """" ""Report a bug in <link "" ""xlink:href=\""https://bugs.launchpad.net/glance/+filebug\"">Glance</link> "" ""(https://bugs.launchpad.net/glance/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/glance/+filebug\"">Glance</link> のバグ報告 (https://bugs.launchpad.net/glance/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml143(para) msgid """" ""Report a bug in <link xlink:href=\""https://bugs.launchpad.net/python-"" ""glanceclient/+filebug\"">python-glanceclient</link> "" ""(https://bugs.launchpad.net/python-glanceclient/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/python-glanceclient/+filebug\"">python-glanceclient</link> のバグ報告(https://bugs.launchpad.net/python-glanceclient/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml150(para) msgid """" ""Report a bug in <link "" ""xlink:href=\""https://bugs.launchpad.net/keystone/+filebug\"">Keystone</link> "" ""(https://bugs.launchpad.net/keystone/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/keystone/+filebug\"">Keystone</link> のバグ報告 (https://bugs.launchpad.net/keystone/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml156(para) msgid """" ""Report a bug in <link xlink:href=\""https://bugs.launchpad.net/python-"" ""keystoneclient/+filebug\"">python-keystoneclient</link> "" ""(https://bugs.launchpad.net/python-keystoneclient/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/python-keystoneclient/+filebug\"">python-keystoneclient</link> のバグ報告(https://bugs.launchpad.net/python-keystoneclient/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml163(para) msgid """" ""Report a bug in <link "" ""xlink:href=\""https://bugs.launchpad.net/quantum/+filebug\"">Quantum</link> "" ""(https://bugs.launchpad.net/quantum/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/quantum/+filebug\"">Quantum</link> のバグ報告 (https://bugs.launchpad.net/quantum/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml169(para) msgid """" ""Report a bug in <link xlink:href=\""https://bugs.launchpad.net/python-"" ""quantumclient/+filebug\"">python-quantumclient</link> "" ""(https://bugs.launchpad.net/python-quantumclient/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/python-quantumclient/+filebug\"">python-quantumclient</link> のバグ報告(https://bugs.launchpad.net/python-quantumclient/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml176(para) msgid """" ""Report a bug in <link "" ""xlink:href=\""https://bugs.launchpad.net/cinder/+filebug\"">Cinder</link> "" ""(https://bugs.launchpad.net/cinder/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/cinder/+filebug\"">Cinder</link> のバグ報告 (https://bugs.launchpad.net/cinder/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml182(para) msgid """" ""Report a bug in <link xlink:href=\""https://bugs.launchpad.net/python-"" ""cinderclient/+filebug\"">python-cinderclient</link> "" ""(https://bugs.launchpad.net/python-cinderclient/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/python-cinderclient/+filebug\"">python-cinderclient</link> のバグ報告(https://bugs.launchpad.net/python-cinderclient/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml189(para) msgid """" ""Report a bug in <link "" ""xlink:href=\""https://bugs.launchpad.net/horizon/+filebug\"">Horizon</link> "" ""(https://bugs.launchpad.net/horizon/+filebug)"" msgstr ""<link xlink:href=\""https://bugs.launchpad.net/horizon/+filebug\"">Horizon</link> のバグ報告 (https://bugs.launchpad.net/horizon/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml195(para) msgid """" ""Report a bug with the <link xlink:href=\""http://bugs.launchpad.net/openstack-"" ""manuals/+filebug\"">documentation</link> (http://bugs.launchpad.net"" ""/openstack-manuals/+filebug)"" msgstr ""<link xlink:href=\""http://bugs.launchpad.net/openstack-manuals/+filebug\"">ドキュメントdocumentation</link> に関するバグ報告 (http://bugs.launchpad.net/openstack-manuals/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml201(para) msgid """" ""Report a bug with the <link xlink:href=\""http://bugs.launchpad.net/openstack-api-"" ""site/+filebug\"">API documentation</link> (http://bugs.launchpad.net"" ""/openstack-api-site/+filebug)"" msgstr ""<link xlink:href=\""http://bugs.launchpad.net/openstack-api-site/+filebug\"">API ドキュメント</link> に関するバグ報告 (http://bugs.launchpad.net/openstack-api-site/+filebug)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml208(para) msgid """" ""To write a good bug report, the following process is essential. First, "" ""search for the bug to make sure there is no bug already filed for the same "" ""issue. If you find one, be sure to click on \""This bug affects X people. "" ""Does this bug affect you?\"" If you can't find the issue then enter the "" ""details of your report. It should at least include:"" msgstr ""よいバグ報告を書くには、次に述べる手順を踏むことが不可欠です。まず、バグを検索し、同じ問題に関してすでに登録されているバグがないことを確認します。見つかった場合は、\""This bug affects X people. Does this bug affect you?\"" (このバグは X 人に影響があります。あなたもこのバグの影響を受けますか?) をクリックするようにして下さい。同じ問題が見つからなかった場合は、バグ報告で詳細を入力して下さい。少なくとも以下の情報を含めるべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml217(para) msgid """" ""The release, or milestone, or commit ID corresponding to the software that "" ""you are running."" msgstr ""実行しているソフトウェアのリリースやマイルストーン、コミット ID。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml222(para) msgid ""The operating system and version where you've identified the bug."" msgstr ""あなたがバグを確認したオペレーティングシステムとそのバージョン。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml226(para) msgid ""Steps to reproduce the bug, including what went wrong."" msgstr ""バグの再現手順。何がおかしいかも含めて下さい。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml230(para) msgid ""Description of the expected results instead of what you saw."" msgstr ""期待される結果の説明 (出くわした現象ではなく)。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml234(para) msgid """" ""Read and understood your log files so you only include relevant excerpts."" msgstr ""ログファイルから関連部分のみを抜粋したもの。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml238(para) msgid ""When you do this, the bug is created with:"" msgstr ""バグ報告をすると、バグは次のステータスで作成されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml241(para) msgid ""Status: <emphasis>New</emphasis>"" msgstr ""Status: <emphasis>New</emphasis>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml245(para) msgid """" ""In the bug comments, you can contribute instructions on how to fix a given "" ""bug, and set it to <emphasis>Triaged</emphasis>. Or you can directly fix it:"" "" assign the bug to yourself, set it to <emphasis>In progress</emphasis>, "" ""branch the code, implement the fix, and propose your change for merging into"" "" trunk. But let's not get ahead of ourselves, there are bug triaging tasks "" ""as well."" msgstr ""バグのコメントでは、既知のバグの修正方法に関して案を出したり、バグの状態を <emphasis>Triaged</emphasis> (有効な報告か、対応が必要かなどを分類した状態) にセットすることができます。バグを直接修正することもできます。その場合は、バグを自分に割り当てて、状態を <emphasis>In progress</emphasis> (進行中) にセットし、コードのブランチを作り、トランクにマージしてもらうように変更を提案するという流れになります。でも、先走りし過ぎないようにしましょう。バグを分類するという仕事もありますから。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml254(title) msgid ""Confirming &amp; Prioritizing"" msgstr ""バグの確認と優先付け"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml255(para) msgid """" ""This stage is about checking that a bug is real and assessing its impact. "" ""Some of these steps require bug supervisor rights (usually limited to core "" ""teams). If the bug lacks information to properly reproduce or assess the "" ""importance of the bug, the bug is set to:"" msgstr ""このステップでは、バグが実際に起こるかのチェックやその重要度の判定が行われます。これらのステップを行うには、バグ管理者権限が必要なものがあります (通常、バグ管理者権限はコア開発者チームだけが持っています)。バグ報告に、バグを再現したり、バグの重要度を判定したりするのに必要な情報が不足している場合、バグは"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml263(para) msgid ""Status: <emphasis>Incomplete</emphasis>"" msgstr ""Status: <emphasis>Incomplete</emphasis>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml267(para) msgid """" ""Once you have reproduced the issue (or are 100% confident that this is "" ""indeed a valid bug) and have permissions to do so, set:"" msgstr ""にセットされます。問題を再現できた場合 (もしくはこの報告がバグであると 100％ 確信を持てる場合) で、セットする権限を持っている場合には、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml272(para) msgid ""Status: <emphasis>Confirmed</emphasis>"" msgstr ""Status: <emphasis>Confirmed</emphasis>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml276(para) msgid ""Core developers also prioritize the bug, based on its impact:"" msgstr ""にセットして下さい。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml280(para) msgid ""Importance: &lt;Bug impact&gt;"" msgstr ""Importance: &lt;バグ影響度&gt;"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml283(para) msgid ""The bug impacts are categorized as follows:"" msgstr ""バグ影響度は以下のカテゴリに分かれています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml286(para) msgid """" ""<emphasis>Critical</emphasis> if the bug prevents a key feature from working"" "" properly (regression) for all users (or without a simple workaround) or "" ""result in data loss"" msgstr ""<emphasis>Critical</emphasis> このバグにより、目玉となる機能が全てのユーザで正常に動作しない場合 (または簡単なワークアラウンドでは動作しない場合)、もしくはデータロスにつながるような場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml294(para) msgid """" ""<emphasis>High</emphasis> if the bug prevents a key feature from working "" ""properly for some users (or with a workaround)"" msgstr ""<emphasis>High</emphasis> このバグにより、目玉となる機能が何人かユーザで正常に動作しない場合 (または簡単なワークアラウンドで動作する場合)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml300(para) msgid """" ""<emphasis>Medium</emphasis> if the bug prevents a secondary feature from "" ""working properly"" msgstr ""<emphasis>Medium</emphasis> このバグにより、ある程度重要な機能が正常に動作しない場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml306(para) msgid ""<emphasis>Low</emphasis> if the bug is mostly cosmetic"" msgstr ""<emphasis>Low</emphasis> このバグが多くの場合で軽微な場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml311(para) msgid """" ""<emphasis>Wishlist</emphasis> if the bug is not really a bug, but rather a "" ""welcome change in behavior"" msgstr ""<emphasis>Wishlist</emphasis> 実際にはバグではないが、そのように動作を変更した方よいものの場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml317(para) msgid """" ""If the bug contains the solution, or a patch, set the bug status to "" ""<emphasis>Triaged</emphasis>"" msgstr ""バグ報告に解決方法やパッチが書かれている場合、そのバグの状態は <emphasis>Triaged</emphasis> にセットされる。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml322(title) msgid ""Bug Fixing"" msgstr ""バグ修正"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml323(para) msgid """" ""At this stage, a developer works on a fix. During that time, to avoid "" ""duplicating the work, they should set:"" msgstr ""この段階では、開発者が修正を行います。修正を行っている間、作業の重複を避けるため、バグの状態を以下のようにセットすべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml328(para) msgid ""Status: <emphasis>In progress</emphasis>"" msgstr ""Status: <emphasis>In progress</emphasis>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml332(para) msgid ""Assignee: &lt;yourself&gt;"" msgstr ""Assignee: &lt;あなた自身&gt;"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml335(para) msgid ""When the fix is ready, they propose and get the change reviewed."" msgstr ""修正が用意できたら、開発者は変更を提案し、レビューを受けます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml338(title) msgid ""After the Change is Accepted"" msgstr ""変更が受理された後"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml339(para) msgid """" ""After the change is reviewed, accepted, and lands in master, it "" ""automatically moves to:"" msgstr ""変更がレビューされ、受理されて、マスターブランチにマージされると、バグの状態は自動的に以下のようになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml343(para) msgid ""Status: <emphasis>Fix committed</emphasis>"" msgstr ""Status: <emphasis>Fix committed</emphasis>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml347(para) msgid """" ""When the fix makes it into a milestone or release branch, it automatically "" ""moves to:"" msgstr ""修正がマイルストーンやリリースブランチに取り込まれると、バグの状態は自動的に以下のようになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml351(para) msgid ""Milestone: Milestone the bug was fixed in"" msgstr ""Milestone: このバグの修正が入ったマイルストーン"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml355(para) msgid ""Status: <emphasis>Fix released</emphasis>"" msgstr ""Status: <emphasis>Fix released</emphasis>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml363(title) msgid ""Join the OpenStack Community"" msgstr ""OpenStack コミュニティに参加する"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml364(para) msgid """" ""Since you've made it this far in the book, you should consider becoming an "" ""official individual member of the community and <link "" ""xlink:href=\""https://www.openstack.org/join/\"">Join The OpenStack "" ""Foundation</link> (https://www.openstack.org/join/). The OpenStack "" ""Foundation is an independent body providing shared resources to help achieve"" "" the OpenStack mission by protecting, empowering, and promoting OpenStack "" ""software and the community around it, including users, developers and the "" ""entire ecosystem. We all share the responsibility to make this community the"" "" best it can possibly be and signing up to be a member is the first step to "" ""participating. Like the software, individual membership within the OpenStack"" "" Foundation is free and accessible to anyone."" msgstr ""この本をここまで読んで来たので、あなたはコミュニティの正式な個人メンバーになって、<link xlink:href=\""https://www.openstack.org/join/\"">Join The OpenStack Foundation</link> (https://www.openstack.org/join/) に加入することを考えていることでしょう。 OpenStack Foundation は、共有リソースを提供し OpenStack の目的の達成を支援する独立組織で、OpenStack ソフトウェア、およびユーザ、開発者、エコシステム全体といった OpenStack を取り巻くコニュニティを守り、活力を与え、普及の促進を行います。我々全員がこのコミュニティをできる限りよいものにしていく責任を共有します。メンバーになることはコミュニティに参加する最初のステップです。ソフトウェア同様、 OpenStack Foundation の個人会員は無料で誰でもなることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml382(title) msgid ""Features and the Development Roadmap"" msgstr ""機能と開発ロードマップ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml383(para) msgid """" ""OpenStack follows a six month release cycle, typically releasing in April "" ""and October each year. At the start of each cycle, the community gathers in "" ""a single location for a Design Summit. At the summit, the features for the "" ""coming releases are discussed, prioritized and planned. Here's an example "" ""release cycle with dates showing milestone releases, code freeze, and string"" "" freeze dates along with an example of when the Summit occurs. Milestones "" ""are interim releases within the cycle that are available as packages for "" ""download and testing. Code freeze is putting a stop to adding new features "" ""to the release. String freeze is putting a stop to changing any strings "" ""within the source code."" msgstr ""OpenStack は6ヶ月のリリースサイクルを取っており、通常は4月と10月にリリースが行われます。各リリースサイクルの最初に、OpenStack コミュニティは一ヶ所に集まりデザインサミットを行います。サミットでは、次のリリースでの機能が議論され、優先度付けと計画が行われます。以下はリリースサイクルの一例で、サミットが行われて以降のマイルストーンリリース、Code Freeze、String Freeze などが記載されています。マイルストーンはリリースサイクル内での中間リリースで、テスト用にパッケージが作成され、ダウンロードできるようになります。 Code Freeze では、そのリリースに向けての新機能の追加が凍結されます。String Freeze は、ソースコード内の文字列の変更が凍結されることを意味します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml405(para) msgid """" ""Feature requests typically start their life in Etherpad, a collaborative "" ""editing tool, which is used to take coordinating notes at a design summit "" ""session specific to the feature. This then leads to the creation of a "" ""blueprint on the Launchpad site for the particular project, which is used to"" "" describe the feature more formally. Blueprints are then approved by project"" "" team members, and development can begin."" msgstr ""機能追加リクエストは、通常 Etherpad で始まります。Etherpad は共同編集ツールで、デザインサミットのその機能に関するセッションで議論を整理するのに使われます。続けて、プロジェクトの Launchpad サイトに blueprint が作成され、blueprint を使ってよりきちんとした形で機能が規定されていきます。 この後、blueprint はプロジェクトメンバーによって承認され、開発が始まります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml413(para) msgid """" ""Therefore, the fastest way to get your feature request up for consideration "" ""is to create an Etherpad with your ideas and propose a session to the design"" "" summit. If the design summit has already passed, you may also create a "" ""blueprint directly. Read this <link xlink:href=\""http://vmartinezdelacruz.com/how-"" ""to-work-with-blueprints-without-losing-your-mind/\"">blog post about how to "" ""work with blueprints</link> (http://vmartinezdelacruz.com/how-to-work-with-"" ""blueprints-without-losing-your-mind/) for a developer intern's perspective, "" ""Victoria Martínez."" msgstr ""あなたの機能追加リクエストを新機能として検討してもらうのに一番早い方法は、アイデアを書いた Etherpad を作成し、デザインサミットのセッションを提案することです。デザインサミットが終わっている場合には、blueprint を直接作成することもできます。 Victoria Martínez の <link xlink:href=\""http://vmartinezdelacruz.com/how-to-work-with-blueprints-without-losing-your-mind/\"">blueprint での開発の進め方についてのブログ</link> (http://vmartinezdelacruz.com/how-to-work-with-blueprints-without-losing-your-mind/) を是非読んで下さい。 OpenStack 開発者のインターンの視点で書かれた記事です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml424(para) msgid """" ""The roadmap for the next release as it is developed can be seen at <link "" ""xlink:href=\""http://status.openstack.org/release/\"">Releases</link> "" ""(http://status.openstack.org/release/)."" msgstr ""次のリリースに向けたロードマップと開発状況は <link xlink:href=\""http://status.openstack.org/release/\"">Releases</link> (http://status.openstack.org/release/) で見ることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml429(para) msgid """" ""To determine the potential features going in to future releases, or to look "" ""at features implemented previously, take a look at the existing blueprints "" ""such as <link xlink:href=\""https://blueprints.launchpad.net/nova\"">OpenStack "" ""Compute (nova) Blueprints</link> (https://blueprints.launchpad.net/nova), "" ""<link xlink:href=\""https://blueprints.launchpad.net/keystone\"">OpenStack Identity "" ""(keystone) Blueprints</link> (https://blueprints.launchpad.net/keystone) and"" "" release notes."" msgstr ""将来のリリースで検討されている機能を確認したり、過去に実装された機能を見るには、<link xlink:href=\""https://blueprints.launchpad.net/nova\"">OpenStack Compute (nova) Blueprints</link> (https://blueprints.launchpad.net/nova), <link xlink:href=\""https://blueprints.launchpad.net/keystone\"">OpenStack Identity (keystone) Blueprints</link> (https://blueprints.launchpad.net/keystone) などの既存の Blueprint やリリースノートを見て下さい。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml443(para) msgid ""Release notes are maintained on the OpenStack wiki:"" msgstr ""リリースノートは OpenStack Wiki で管理されています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml448(th) msgid ""Series"" msgstr ""シリーズ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml449(th) msgid ""Status"" msgstr ""状態"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml450(th) msgid ""Releases"" msgstr ""リリース番号"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml451(th) msgid ""Date"" msgstr ""リリース日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml456(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1370(glossterm) msgid ""Grizzly"" msgstr ""Grizzly"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml460(link) msgid ""Under development, Release schedule"" msgstr ""開発中、リリーススケジュール"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml463(para) msgid ""Due"" msgstr ""リリース予定"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml464(para) msgid ""Apr 4, 2013"" msgstr ""2013年4月4日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml467(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml33(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1317(glossterm) msgid ""Folsom"" msgstr ""Folsom"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml468(para) msgid ""Current stable release, security-supported"" msgstr ""現在の安定版リリース、セキュリティアップデート対象"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml473(link) msgid ""2012.2"" msgstr ""2012.2"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml475(para) msgid ""Sep 27, 2012"" msgstr ""2012年9月27日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml483(link) msgid ""2012.2.1"" msgstr ""2012.2.1"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml485(para) msgid ""Nov 29, 2012"" msgstr ""2012年11月29日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml492(link) msgid ""2012.2.2"" msgstr ""2012.2.2"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml494(para) msgid ""Dec 13, 2012"" msgstr ""2012年12月13日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml501(link) msgid ""2012.2.3"" msgstr ""2012.2.3"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml503(para) msgid ""Jan 31, 2012"" msgstr ""2012年1月31日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml506(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1138(glossterm) msgid ""Essex"" msgstr ""Essex"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml507(para) msgid ""Community-supported, security-supported"" msgstr ""コミュニティによるサポートが行われている、セキュリティアップデート対象"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml512(link) msgid ""2012.1"" msgstr ""2012.1"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml514(para) msgid ""Apr 5, 2012"" msgstr ""2012年4月5日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml521(link) msgid ""2012.1.1"" msgstr ""2012.1.1"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml523(para) msgid ""Jun 22, 2012"" msgstr ""2012年6月22日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml530(link) msgid ""2012.1.2"" msgstr ""2012.1.2"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml532(para) msgid ""Aug 10, 2012"" msgstr ""2012年8月10日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml539(link) msgid ""2012.1.3"" msgstr ""2012.1.3"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml541(para) msgid ""Oct 12, 2012"" msgstr ""2012年10月12日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml544(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml983(glossterm) msgid ""Diablo"" msgstr ""Diablo"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml546(para) msgid ""Community-supported"" msgstr ""コミュニティによるサポートが行われている"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml550(link) msgid ""2011.3"" msgstr ""2011.3"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml552(para) msgid ""Sep 22, 2011"" msgstr ""2011年9月22日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml559(link) msgid ""2011.3.1"" msgstr ""2011.3.1"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml561(para) msgid ""Jan 19, 2012"" msgstr ""2012年1月19日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml564(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml501(glossterm) msgid ""Cactus"" msgstr ""Cactus"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml565(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml575(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml585(para) msgid ""Deprecated"" msgstr ""非推奨"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml569(link) msgid ""2011.2"" msgstr ""2011.2"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml571(para) msgid ""Apr 15, 2011"" msgstr ""2011年4月15日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml574(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml439(glossterm) msgid ""Bexar"" msgstr ""Bexar"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml579(link) msgid ""2011.1"" msgstr ""2011.1"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml581(para) msgid ""Feb 3, 2011"" msgstr ""2011年2月3日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml584(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml365(glossterm) msgid ""Austin"" msgstr ""Austin"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml589(link) msgid ""2010.1"" msgstr ""2010.1"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml591(para) msgid ""Oct 21, 2010"" msgstr ""2010年10月21日"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml597(title) msgid ""How to Contribute to the Documentation"" msgstr ""ドキュメント作成への貢献の仕方"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml598(para) msgid """" ""OpenStack documentation efforts encompass operator and administrator docs, "" ""API docs, and user docs."" msgstr ""OpenStack のドキュメント作成活動は、運用管理ドキュメント、API ドキュメント、ユーザドキュメントなどに渡ります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml600(para) #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml184(para) msgid """" ""The genesis of this book was an in-person event, but now that the book is in"" "" your hands we want you to contribute to it. OpenStack documentation follows"" "" the coding principles of iterative work, with bug logging, investigating, "" ""and fixing."" msgstr ""この本の元は人が集まったイベントで作成されましたが、今やこの本はみなさんも貢献できる状態になっています。 OpenStack のドキュメント作成は、バグ登録、調査、修正を繰り返し行うというコーディングの基本原則に基いて行われています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml605(para) msgid """" ""Just like the code, the <link "" ""xlink:href=\""http://docs.openstack.org\"">docs.openstack.org</link> site is updated"" "" constantly using the Gerrit review system, with source stored in GitHub in "" ""the <link xlink:href=\""http://github.com/openstack/openstack-manuals/\"">openstack-"" ""manuals</link> (http://github.com/openstack/openstack-manuals/) repository "" ""and the <link xlink:href=\""http://github.com/openstack/api-site/\"">api-site</link>"" "" (http://github.com/openstack/api-site/) repository, in DocBook format."" msgstr ""コードと全く同じく、<link xlink:href=\""http://docs.openstack.org\"">docs.openstack.org</link> サイトは Gerrit レビューシステムを使って常に更新されています。ソースは、GitHub の <link xlink:href=\""http://github.com/openstack/openstack-manuals/\"">openstack-manuals</link> (http://github.com/openstack/openstack-manuals/) レポジトリと <link xlink:href=\""http://github.com/openstack/api-site/\"">api-site</link> (http://github.com/openstack/api-site/) レポジトリに、それぞれ DocBook 形式で保存されています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml617(para) msgid """" ""To review the documentation before it's published, go to the OpenStack "" ""Gerrit server at <link "" ""xlink:href=\""http://review.openstack.org\"">review.openstack.org</link> and search "" ""for <link "" ""xlink:href=\""https://review.openstack.org/#/q/status:open+project:openstack"" ""/openstack-manuals,n,z\"">project:openstack/openstack-manuals</link> or <link"" "" xlink:href=\""https://review.openstack.org/#/q/status:open+project:openstack/api-"" ""site,n,z\"">project:openstack/api-site</link>."" msgstr ""公開される前にドキュメントのレビューを行うには、OpenStack Gerrit サーバー <link xlink:href=\""http://review.openstack.org\"">review.openstack.org</link> に行って、<link xlink:href=\""https://review.openstack.org/#/q/status:open+project:openstack/openstack-manuals,n,z\"">project:openstack/openstack-manuals</link> や <link xlink:href=\""https://review.openstack.org/#/q/status:open+project:openstack/api-site,n,z\"">project:openstack/api-site</link> を検索して下さい。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml628(para) msgid """" ""See the <link xlink:href=\""https://wiki.openstack.org/wiki/How_To_Contribute\"">How"" "" To Contribute</link> (https://wiki.openstack.org/wiki/How_To_Contribute) "" ""page on the wiki for more information on the steps you need to take to "" ""submit your first documentation review or change."" msgstr ""ドキュメントのレビューや変更を最初に行うのに必要な手続きについての詳しい情報は、Wiki の <link xlink:href=\""https://wiki.openstack.org/wiki/How_To_Contribute\"">How To Contribute</link> (https://wiki.openstack.org/wiki/How_To_Contribute) ページを参照して下さい。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml637(title) msgid ""Security Information"" msgstr ""セキュリティ情報"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml638(para) msgid """" ""As a community, we take security very seriously and follow a specific "" ""process for reporting potential issues. We vigilantly pursue fixes and "" ""regularly eliminate exposures. You can report security issues you discover "" ""through this specific process. The OpenStack Vulnerability Management Team "" ""is a very small group of experts in vulnerability management drawn from the "" ""OpenStack community. Their job is facilitating the reporting of "" ""vulnerabilities, coordinating security fixes and handling progressive "" ""disclosure of the vulnerability information. Specifically, the Team is "" ""responsible for the following functions:"" msgstr ""我々は、コミュニティとして、セキュリティを非常に重要だと考えており、潜在的な問題の報告は決められたプロセスに基いて処理されます。修正を用心深く追跡し、定期的にセキュリティ上の問題点を取り除きます。あなたは発見したセキュリティ上の問題をこの決められたプロセスを通して報告できます。OpenStack 脆弱性管理チームは、OpenStackコミュニティから選ばれた脆弱性管理の専門家で構成されるごく少人数のグループです。このチームの仕事は、脆弱性の報告を手助けし、セキュリティ上の修正を調整し、脆弱性情報の公開を続けていくことです。特に、このチームは以下の役割を担っています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml652(para) msgid """" ""Vulnerability Management: All vulnerabilities discovered by community "" ""members (or users) can be reported to the Team."" msgstr ""脆弱性管理: コミュニティメンバー (やユーザ) が発見した全ての脆弱性をこのチームに報告できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml657(para) msgid """" ""Vulnerability Tracking: The Team will curate a set of vulnerability related "" ""issues in the issue tracker. Some of these issues are private to the Team "" ""and the affected product leads, but once remediation is in place, all "" ""vulnerabilities are public."" msgstr ""脆弱性追跡: このチームはバグ追跡システムに登録された脆弱性に関連する問題の管理を行います。問題の中には、このチームと影響を受けるプロジェクトの責任者のみが参照できる場合もありますが、問題の修正が用意されると、全ての脆弱性は公開されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml665(para) msgid """" ""Responsible Disclosure: As part of our commitment to work with the security "" ""community, the team ensures that proper credit is given to security "" ""researchers who responsibly report issues in OpenStack."" msgstr ""Responsible Disclosure（責任ある情報公開）: セキュリティコミュニティと仕事をする義務の一つとして、セキュリティ情報の公開が、確実に、OpenStack のセキュリティ問題を責任をもって扱うセキュリティ研究者の適切なお墨付きを得て行われるようにします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml672(para) msgid """" ""We provide two ways to report issues to the OpenStack Vulnerability "" ""Management Team depending on how sensitive the issue is:"" msgstr ""OpenStack 脆弱性管理チームに問題を報告する方法は2種類用意されており、問題の重要度に応じて使い分けて下さい。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml677(para) msgid """" ""Open a bug in Launchpad and mark it as a 'security bug'. This makes the bug "" ""private and accessible to only the Vulnerability Management Team."" msgstr ""Launchpad でバグ報告を行い、'security bug' のマークを付ける。マークを付けると、そのバグは一般には公開されなくなり、脆弱性管理チームだけが参照できるようになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml683(para) msgid """" ""If the issue is extremely sensitive, send an encrypted email to one of the "" ""Team's members. Find their GPG keys at <link "" ""xlink:href=\""http://www.openstack.org/projects/openstack-security/\"">OpenStack "" ""Security</link> (http://www.openstack.org/projects/openstack-security/)."" msgstr ""問題が極めて慎重に扱うべき情報の場合は、脆弱性管理チームのメンバーの誰かに暗号化したメールを送って下さい。メンバーの GPG 鍵は <link xlink:href=\""http://www.openstack.org/projects/openstack-security/\"">OpenStack Security</link> (http://www.openstack.org/projects/openstack-security/) で入手できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml692(para) msgid """" ""You can find the full list of security-oriented teams you can join at <link "" ""xlink:href=\""https://wiki.openstack.org/wiki/SecurityTeams\"">Security Teams</link>"" "" (http://wiki.openstack.org/SecurityTeams). The Vulnerability Management "" ""process is fully documented at <link "" ""xlink:href=\""https://wiki.openstack.org/wiki/VulnerabilityManagement\"">Vulnerability"" "" Management</link> "" ""(https://wiki.openstack.org/wiki/VulnerabilityManagement)."" msgstr ""あなたが参加できるセキュリティ関連のチームのリストは <link xlink:href=\""https://wiki.openstack.org/wiki/SecurityTeams\"">セキュリティチーム</link> (http://wiki.openstack.org/SecurityTeams) にあります。脆弱性管理プロセスはすべてドキュメントにまとめられており、<link xlink:href=\""https://wiki.openstack.org/wiki/VulnerabilityManagement\"">脆弱性管理</link> (https://wiki.openstack.org/wiki/VulnerabilityManagement) で参照できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml704(title) msgid ""Finding Additional Information"" msgstr ""さらに情報を見つける"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_upstream.xml705(para) msgid """" ""In addition to this book, there are many other sources of information about "" ""OpenStack. The <link xlink:href=\""http://www.openstack.org\"">OpenStack "" ""website</link> (http://www.openstack.org) is a good starting point, with "" ""<link xlink:href=\""http://docs.openstack.org\"">OpenStack Docs</link> "" ""(http://docs.openstack.org) and <link "" ""xlink:href=\""http://api.openstack.org\"">OpenStack API Docs</link> "" ""(http://api.openstack.org) providing technical documentation about "" ""OpenStack. The <link xlink:href=\""https://wiki.openstack.org\"">OpenStack "" ""wiki</link> contains a lot of general information that cuts across the "" ""OpenStack projects including a list of <link "" ""xlink:href=\""https://wiki.openstack.org/wiki/OperationsTools\"">recommended "" ""tools</link> (https://wiki.openstack.org/wiki/OperationsTools ). Finally, "" ""there are a number of blogs aggregated at <link "" ""xlink:href=\""http://planet.openstack.org\"">Planet OpenStack</link> "" ""(http://planet.openstack.org)."" msgstr ""この本以外にも、OpenStack に関する情報源はたくさんあります。 <link xlink:href=\""http://www.openstack.org\"">OpenStack ウェブサイト</link> (http://www.openstack.org) は最初に見るといいでしょう。ここには、<link xlink:href=\""http://docs.openstack.org\"">OpenStack ドキュメント</link> (http://docs.openstack.org) と <link xlink:href=\""http://api.openstack.org\"">OpenStack API ドキュメント</link> (http://api.openstack.org) があり、OpenStack に関する技術情報が提供されています。 <link xlink:href=\""https://wiki.openstack.org\"">OpenStack wiki</link> には、OpenStack の各プロジェクトの範囲にとどらまらない汎用的な情報が多数あり、例えば <link xlink:href=\""https://wiki.openstack.org/wiki/OperationsTools\"">お薦めツールのリスト</link> (https://wiki.openstack.org/wiki/OperationsTools ) といった情報も載っています。最後に、<link xlink:href=\""http://planet.openstack.org\"">Planet OpenStack</link> (http://planet.openstack.org) には多くのブログが集められています。"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml19(title) msgid ""Acknowledgments"" msgstr ""謝辞"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml20(para) msgid """" ""The OpenStack Foundation supported the creation of this book with plane "" ""tickets to Austin, lodging (including one adventurous evening without power "" ""after a windstorm), and delicious food. For about USD $10,000, we could "" ""collaborate intensively for a week in the same room at the Rackspace Austin "" ""office. The authors are all members of the OpenStack Foundation, which you "" ""can join. Go to the <link xlink:href=\""https://www.openstack.org/join\"">Foundation"" "" web site</link> at http://openstack.org/join."" msgstr ""OpenStack Foundationは、オースチンへの航空券、(暴風後の停電によるドキドキの夜を含む)宿、そして美味しい食事で、この本の作成をサポートしました。約10,000USドルで、Rackspaceのオースチンオフィスの同じ部屋の中で、私たちは1週間で集中的に共同作業をすることができました。著者たちはすべてOpenStack Foundationのメンバーであり、それにはあなたも参加することができます。<link xlink:href=\""https://www.openstack.org/join\"">FoundationのWebサイト</link> (http://openstack.org/join) に行ってみてください。"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml33(para) msgid """" ""Emma Richards of Rackspace Guest Relations took excellent care of our lunch "" ""orders and even set aside a pile of sticky notes that had fallen off the "" ""walls."" msgstr ""Rackspace ゲストリレーションズの Emma Richards は、私たちのランチの注文を素晴らしく面倒を見てくれて、更に壁から剥がれ落ちた付箋紙の山を脇においてくれました。"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml39(para) msgid """" ""Betsy Hagemeier, a Fanatical Executive Assistant, took care of a room "" ""reshuffle and helped us settle in for the week."" msgstr ""熱狂的なエグゼクティブアシスタントの Betsy Hagemeier は、部屋の改造の面倒を見てくれて、1週間で解決する手助けをしてくれました。"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml44(para) msgid """" ""The Real Estate team at Rackspace in Austin, also known as \""The Victors,\"" "" ""were super responsive."" msgstr ""\""The Victors\"" としても知られている、オースチンの Rackspace の不動産チームは、素晴らしい応答をしてくれました。"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml49(para) msgid """" ""Adam Powell in Racker IT supplied us with bandwidth each day and second "" ""monitors for those of us needing more screens."" msgstr ""Rackspace IT部門 の Adam Powell は、私たちに毎日のネットワーク帯域を提供してくれました。また、より多くのスクリーンが必要となったため、セカンドモニタを提供してくれました。"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml54(para) msgid """" ""On Wednesday night we had a fun happy hour with the Austin OpenStack Meetup "" ""group and Racker Katie Schmidt took great care of our group."" msgstr ""水曜日の夜、オースチン OpenStack ミートアップグループと楽しく幸せな時間を過ごし、Racker Katie Schmidt は私たちのグループを素晴らしい世話をしてくれました。"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml60(para) msgid """" ""We also had some excellent input from outside of the room. Tim Bell from "" ""CERN gave us feedback on the outline before we started and reviewed it mid-"" ""week."" msgstr ""私たちは部屋の外から、いくつかの素晴らしいインプットを得ました。CERNの Tim Bell は、私たちが作業を開始する前に、その概要についてフィードバックを与えてくれて、週の半ばにはレビューをしてくれました。"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml64(para) msgid """" ""Sébastien Han has written excellent blogs and generously gave his permission"" "" for re-use."" msgstr ""Sébastien Han は素晴らしいブログを書いてくれて、寛大にも再利用の許可を与えてくれました。"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml66(para) msgid """" ""Oisin Feeley read it, made some edits, and provided emailed feedback right "" ""when we asked."" msgstr ""Oisin Feeley は、このマニュアルを読んで、いくつかの編集をし、私たちが問い合わせをした際には、E-mailでのフィードバックをくれました。"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml30(para) msgid """" ""We want to acknowledge our excellent host Rackers at Rackspace in Austin: "" ""<placeholder-1/>"" msgstr ""私たちは、オースチンの Rackspace での素晴らしいホスト Rackersに感謝したい: <placeholder-1/>"" #: ./doc/src/docbkx/openstack-ops/src/acknowledgements.xml70(para) msgid """" ""We couldn't have pulled it off without so much supportive help and "" ""encouragement."" msgstr ""私たちは、これらの多大な協力的な援助と励まし無しには、これを成し遂げることはできなかったでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml16(title) msgid ""Logging and Monitoring"" msgstr ""ロギングと監視"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml17(para) msgid """" ""As an OpenStack cloud is composed of so many different services, there are a"" "" large number of log files. This section aims to assist you in locating and "" ""working with them, and other ways to track the status of your deployment."" msgstr ""OpenStackクラウドは、様々なサービスから構成されるため、多くのログファイルが存在します。このセクションでは、それぞれのログの場所と取り扱い、そしてシステムのさらなる監視方法について説明します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml23(title) msgid ""Where Are the Logs?"" msgstr ""ログはどこにあるのか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml24(para) msgid """" ""On Ubuntu, most services use the convention of writing their log files to "" ""subdirectories of the <code>/var/log directory</code>."" msgstr ""Ubuntu では、ほとんどのサービスが <code>/var/log</code> ディレクトリ以下のディレクトリにログファイルを出力するという慣習に従っています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml28(title) msgid ""Cloud Controller"" msgstr ""クラウドコントローラー"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml32(th) msgid ""Service"" msgstr ""サービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml33(th) msgid ""Log Location"" msgstr ""ログの場所"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml39(code) msgid ""nova-*"" msgstr ""nova-*"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml42(code) msgid ""/var/log/nova"" msgstr ""/var/log/nova"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml47(code) msgid ""glance-*"" msgstr ""glance-*"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml50(code) msgid ""/var/log/glance"" msgstr ""/var/log/glance"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml55(code) msgid ""cinder-*"" msgstr ""cinder-*"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml58(code) msgid ""/var/log/cinder"" msgstr ""/var/log/cinder"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml63(code) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1709(glossterm) msgid ""keystone"" msgstr ""keystone"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml66(code) msgid ""/var/log/keystone"" msgstr ""/var/log/keystone"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml71(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1412(glossterm) msgid ""horizon"" msgstr ""horizon"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml73(code) msgid ""/var/log/apache2/"" msgstr ""/var/log/apache2/"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml78(para) msgid ""misc (Swift, dnsmasq)"" msgstr ""その他 (Swift, dnsmasq)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml81(code) msgid ""/var/log/syslog"" msgstr ""/var/log/syslog"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml88(title) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml16(title) msgid ""Compute Nodes"" msgstr ""コンピュートノード"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml89(para) msgid ""libvirt: <code>/var/log/libvirt/libvirtd.log</code>"" msgstr ""libvirt: <code>/var/log/libvirt/libvirtd.log</code>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml91(para) msgid """" ""Console (boot up messages) for VM instances: "" ""<code>/var/lib/nova/instances/instance-&lt;instance "" ""id&gt;/console.log</code>"" msgstr ""VMインスタンスのコンソール (ブートメッセージ): <code>/var/lib/nova/instances/instance-&lt;instance id&gt;/console.log</code>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml97(title) msgid ""Block Storage Nodes"" msgstr ""ブロックストレージ ノード"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml98(para) msgid ""cinder: <code>/var/log/cinder/cinder-volume.log</code>"" msgstr ""cinder: <code>/var/log/cinder/cinder-volume.log</code>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml104(title) msgid ""How to Read the Logs"" msgstr ""ログの読み方"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml105(para) msgid """" ""OpenStack services use the standard logging levels, at increasing severity: "" ""DEBUG, INFO, AUDIT, WARNING, ERROR, CRITICAL, TRACE. That is, messages only "" ""appear in the logs if they are more \""severe\"" than the particular log level"" "" with DEBUG allowing all log statements through. For example, TRACE is "" ""logged only if the software has a stack trace, while INFO is logged for "" ""every message including those that are only for information."" msgstr ""OpenStack サービスは標準のロギングレベルを利用しています。重要度のレベルは次の通りです(重要度の低い順): DEBUG、INFO、AUDIT、WARNING、ERROR、CRTICAL、TRACE。特定のログレベルより\""重要\""な場合のみメッセージはログに出力されます。ログレベルDEBUGの場合、すべてのログが出力されます。TRACEの場合、ソフトウェアがスタックトレースを持つ場合にのみログに出力されます。INFOの場合、情報のみのメッセージも含めて出力されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml113(para) msgid ""To disable DEBUG-level logging, edit <code>/etc/nova/nova.conf</code>:"" msgstr ""DEBUG レベルのロギングを無効にするには、以下のように <code>/etc/nova/nova.conf</code> を編集します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml116(para) msgid """" ""Keystone is handled a little differently. To modify the logging level, edit "" ""the <code>/etc/keystone/logging.conf</code> file and look at the "" ""<code>logger_root and handler_file</code> sections."" msgstr ""Keystoneは少し異なる動作をします。ロギングレベルを変更するためには、<code>/etc/keystone/logging.conf</code>を編集し、 <code>logger_root </code>と<code> handler_file</code> を修正する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml121(para) msgid """" ""Logging for Horizon is configured in "" ""<code>/etc/openstack_dashboard/local_settings.py</code>. As Horizon is a "" ""Django web application, it follows the <link xlink:title=\""Django Logging\"" "" ""xlink:href=\""https://docs.djangoproject.com/en/dev/topics/logging/\"">Django "" ""Logging</link> (https://docs.djangoproject.com/en/dev/topics/logging/) "" ""framework conventions."" msgstr ""Horizon のロギング設定は <code>/etc/openstack_dashboard/local_settings.py</code> で行います。Horizon は Django web アプリケーションですので、<link xlink:title=\""Django Logging\"" xlink:href=\""https://docs.djangoproject.com/en/dev/topics/logging/\"">Django Logging</link> (https://docs.djangoproject.com/en/dev/topics/logging/) フレームワークの規約に従います。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml129(para) msgid """" ""The first step in finding the source of an error is typically to search for "" ""a CRITICAL, TRACE, or ERROR message in the log starting at the bottom of the"" "" log file."" msgstr ""エラーの原因を見つけるための典型的な最初のステップは、 CRTICAL、TRACE、ERRORなどのメッセージがログファイルの終わりで出力されていないかを確認することです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml132(para) msgid """" ""An example of a CRITICAL log message, with the corresponding TRACE (Python "" ""traceback) immediately following:"" msgstr ""トレース(Pythonのコールスタック)付きのCRITICALなログメッセージの例は次の通りです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml165(para) msgid """" ""In this example, cinder-volumes failed to start and has provided a stack "" ""trace, since its volume back-end has been unable to setup the storage volume"" "" - probably because the LVM volume that is expected from the configuration "" ""does not exist."" msgstr ""この例では、ボリュームのバックエンドがストレージボリュームをセットアップができなかったため、cinder-volumesが起動に失敗し、スタックトレースを出力しています。おそらく、設定ファイルで指定された LVM ボリュームが存在しないためと考えられます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml170(para) msgid ""An example error log:"" msgstr ""エラーログの例:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml173(para) msgid """" ""In this error, a nova service has failed to connect to the RabbitMQ server, "" ""because it got a connection refused error."" msgstr ""このエラーでは、novaサービスがRabbitMQへの接続に失敗していました。接続が拒否されたというエラーが出力されています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml178(title) msgid ""Tracing Instance Requests"" msgstr ""インスタンスリクエストの追跡"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml179(para) msgid """" ""When an instance fails to behave properly, you will often have to trace "" ""activity associated with that instance across the log files of various "" ""<code>nova-*</code> services, and across both the cloud controller and "" ""compute nodes."" msgstr ""インスタンスが正しく動作していない場合、インスタンスに関連したログを調べる必要があります。これらのログは複数の<code>nova-*</code>サービスが出力しており、クラウドコントローラーとコンピュートノードの両方に存在します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml184(para) msgid """" ""The typical way is to trace the UUID associated with an instance across the "" ""service logs."" msgstr ""一般的な方法はインスタンスのUUIDをキーにして、各サービスのログを追跡することです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml186(para) msgid ""Consider the following example:"" msgstr ""次のような例を考えてみましょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml193(para) msgid """" ""Here the ID associated with the instance is "" ""<code>faf7ded8-4a46-413b-b113-f19590746ffe</code>. If you search for this "" ""string on the cloud controller in the <code>/var/log/nova-*.log</code> "" ""files, it appears in <code>nova-api.log</code>, <code>nova-"" ""scheduler.log</code>. If you search for this on the compute nodes in "" ""<code>/var/log/nova-*.log</code>, it appears <code>nova-network.log</code> "" ""and <code>nova-compute.log</code>. If no ERROR or CRITICAL messages appear, "" ""the most recent log entry that reports this may provide a hint about what "" ""has gone wrong."" msgstr ""ここで、インスタンスのUUIDは <code>faf7ded8-4a46-413b-b113-f19590746ffe</code>です。クラウドコントローラー上の <code>/var/log/nova-*.log</code>ファイルをこの文字列で検索すると、<code>nova-api.log</code>と <code>nova-scheduler.log</code>で見つかります。同様にコンピュートノードで検索した場合、<code>nova-network.log</code> と <code>nova-compute.log</code>で見つかります。もし、ERRORやCRITICALのメッセージが存在しない場合、最後のログエントリが、何が悪いかのヒントを示しているかもしれません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml207(title) msgid ""Adding Custom Logging Statements"" msgstr ""カスタムログの追加"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml208(para) msgid """" ""If there is not enough information in the existing logs, you may need to add"" "" your own custom logging statements to the <code>nova-*</code> services."" msgstr ""もし、ログに十分な情報がない場合、あなた自身でカスタマイズしたログを <code>nova-*</code>サービスに追加することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml211(para) msgid """" ""The source files are located in <code>/usr/lib/python2.7/dist-"" ""packages/nova</code>"" msgstr ""ソースファイルは <code>/usr/lib/python2.7/dist-packages/nova</code>に存在します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml214(para) msgid """" ""To add logging statements, the following line should be near the top of the "" ""file. For most files, these should already be there:"" msgstr ""ログステートメントを追加するには、次の行をファイルの先頭に置きます。ほとんどのファイルでは、これらは既に存在します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml219(para) msgid ""To add a DEBUG logging statement, you would do:"" msgstr ""DEBUGログステートメントを追加するには次のようにします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml221(para) msgid """" ""You may notice that all of the existing logging messages are preceded by an "" ""underscore and surrounded by parentheses, for example:"" msgstr ""以下に例を示しますが、全てのログメッセージはアンダースコアで始まり、括弧で括られていることに気づいたでしょうか?"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml225(para) msgid """" ""This is used to support translation of logging messages into different "" ""languages using the <link "" ""xlink:href=\""http://docs.python.org/2/library/gettext.html\"">gettext</link> "" ""(http://docs.python.org/2/library/gettext.html) internationalization "" ""library. You don't need to do this for your own custom log messages. "" ""However, if you want to contribute the code back to the OpenStack project "" ""that includes logging statements, you must surround your log messages with "" ""underscore and parentheses."" msgstr ""これは、ログメッセージを異なる言語に翻訳するために<link xlink:href=\""http://docs.python.org/2/library/gettext.html\"">gettext</link> (http://docs.python.org/2/library/gettext.html) 国際化ライブラリ を利用しているためです。カスタムログには必要ありませんが、もし、OpenStackプロジェクトにログステートメントを含むコードを提供する場合は、アンダースコアと括弧でログメッセージを囲わなければなりません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml237(title) msgid ""RabbitMQ Web Management Interface or rabbitmqctl"" msgstr ""RabbitMQ Web管理インターフェイス および rabbitmqctl"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml239(para) msgid """" ""Aside from connection failures, RabbitMQ log files are generally not useful "" ""for debugging OpenStack related issues. Instead, we recommend you use the "" ""RabbitMQ web management interface. Enable it on your cloud controller:"" msgstr ""接続失敗の問題は別とすると、RabbitMQログファイルはOpenStackに関連した問題のデバッグにあまり有用ではありません。その代わりにRabbitMQ Web管理インターフェイスを推奨します。 クラウドコントローラーにおいて、以下のコマンドで有効になります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml246(para) msgid """" ""The RabbitMQ web management interface is accessible on your cloud controller"" "" at http://localhost:55672."" msgstr ""RabbitMQ Web管理インターフェイスは、クラウドコントローラーから <code> http://localhost:55672 </code>でアクセスできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml249(para) msgid """" ""Ubuntu 12.04 installs RabbitMQ version 2.7.1, which uses port 55672. "" ""RabbitMQ versions 3.0 and above use port 15672 instead. You can check which "" ""version of RabbitMQ you have running on your local Ubuntu machine by doing:"" msgstr ""Ubuntu 12.04はRabiitMQのバージョン2.7.1を55672番ポートを使うようにインストールします。RabbitMQバージョン3.0以降では15672が利用されます。Ubuntuマシン上でどのバージョンのRabbitMQが実行されているかは次のように確認できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml257(para) msgid """" ""An alternative to enabling the RabbitMQ Web Management Interface is to use "" ""the <placeholder-1/> commands. For example, <placeholder-2/> displays any "" ""messages left in the queue. If there are, it's a possible sign that cinder "" ""services didn't connect properly to rabbitmq and might have to be restarted."" msgstr ""RabbitMQ Web 管理インターフェイスを有効にするもう一つの方法としては、 <placeholder-1/> コマンドを利用します。例えば <placeholder-2/> は、キューに残っているメッセージを表示します。メッセージが存在する場合、CinderサービスがRabbitMQに正しく接続できてない可能性があり、再起動が必要かもしれません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml264(para) msgid """" ""Items to monitor for RabbitMQ include the number of items in each of the "" ""queues and the processing time statistics for the server."" msgstr ""RabbitMQで監視すべき項目としては、各キューでのアイテムの数と、サーバーでの処理時間の統計情報があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml269(title) msgid ""Centrally Managing Logs"" msgstr ""ログの集中管理"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml270(para) msgid """" ""Because your cloud is most likely composed of many servers, you must check "" ""logs on each of those servers to properly piece an event together. A better "" ""solution is to send the logs of all servers to a central location so they "" ""can all be accessed from the same area."" msgstr ""クラウドは多くのサーバーから構成されるため、各サーバー上にあるイベントログを繋ぎあわせて、ログをチェックしなければなりません。よい方法は全てのサーバーのログを一ヶ所にまとめ、同じ場所で確認できるようにすることです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml275(para) msgid """" ""Ubuntu uses rsyslog as the default logging service. Since it is natively "" ""able to send logs to a remote location, you don't have to install anything "" ""extra to enable this feature, just modify the configuration file. In doing "" ""this, consider running your logging over a management network, or using an "" ""encrypted VPN to avoid interception."" msgstr ""Ubuntuはrsyslog をデフォルトのロギングサービスとして利用します。rsyslog はリモートにログを送信する機能を持っているので、何かを追加でインストールする必要はなく、設定ファイルを変更するだけです。リモート転送を実施する際は、盗聴を防ぐためにログが自身の管理ネットワーク上を通る、もしくは暗号化VPNを利用することを考慮する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml283(title) msgid ""rsyslog Client Configuration"" msgstr ""rsyslog クライアント設定"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml284(para) msgid """" ""To begin, configure all OpenStack components to log to syslog in addition to"" "" their standard log file location. Also configure each component to log to a"" "" different syslog facility. This makes it easier to split the logs into "" ""individual components on the central server."" msgstr ""まず始めに、全てのOpenStackコンポーネントのログを標準ログに加えてsyslogに出力するように設定します。また、各コンポーネントが異なるsyslogファシリティになるように設定します。これによりログサーバー上で、個々のコンポーネントのログを分離しやすくなります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml290(para) msgid ""<code>nova.conf</code>:"" msgstr ""<code>nova.conf</code>:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml294(para) msgid ""<code>glance-api.conf</code> and <code>glance-registry.conf</code>:"" msgstr ""<code>glance-api.conf</code> および <code>glance-registry.conf</code>:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml299(para) msgid ""<code>cinder.conf</code>:"" msgstr ""<code>cinder.conf</code>:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml303(para) msgid ""<code>keystone.conf</code>:"" msgstr ""<code>keystone.conf</code>:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml307(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml226(para) msgid ""Swift"" msgstr ""Swift"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml308(para) msgid ""By default, Swift logs to syslog."" msgstr ""デフォルトでSwiftはsyslogにログを出力します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml309(para) msgid ""Next, create /etc/rsyslog.d/client.conf with the following line:"" msgstr ""次に、<code> /etc/rsyslog.d/client.conf</code>に次の行を作成します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml312(para) msgid """" ""This instructs rsyslog to send all logs to the IP listed. In this example, "" ""the IP points to the Cloud Controller."" msgstr ""これは、rsyslogに全てのログを指定したIPアドレスに送るように命令しています。この例では、IPアドレスはクラウドコントローラーを指しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml317(title) msgid ""rsyslog Server Configuration"" msgstr ""rsyslog サーバー設定"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml318(para) msgid """" ""Designate a server as the central logging server. The best practice is to "" ""choose a server that is solely dedicated to this purpose. Create a file "" ""called /etc/rsyslog.d/server.conf with the following contents:"" msgstr ""集中ログサーバーとして使用するサーバーを決めます。ログ専用のサーバーを利用するのが最も良いです。<code> /etc/rsyslog.d/server.conf </code>を次のように作成します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml346(para) msgid """" ""The above example configuration handles the nova service only. It first "" ""configures rsyslog to act as a server that runs on port 512. Next, it "" ""creates a series of logging templates. Logging templates control where "" ""received logs are stored. Using the example above, a nova log from "" ""c01.example.com goes to the following locations:"" msgstr ""この設定例はnovaサービスのみを扱っています。はじめに rsyslog を UDP 514番ポートで動作するサーバーとして設定します。次に一連のログテンプレートを作成します。ログテンプレートは受け取ったログをどこに保管するかを指定します。上記の例を用いると、c01.example.comから送られるnovaのログは次の場所に保管されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml356(code) msgid ""/var/log/rsyslog/c01.example.com/nova.log"" msgstr ""/var/log/rsyslog/c01.example.com/nova.log"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml361(code) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml375(code) msgid ""/var/log/rsyslog/nova.log"" msgstr ""/var/log/rsyslog/nova.log"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml365(para) msgid ""This is useful as logs from c02.example.com go to:"" msgstr ""c02.example.comから送られたログはこちらに保管されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml370(code) msgid ""/var/log/rsyslog/c02.example.com/nova.log"" msgstr ""/var/log/rsyslog/c02.example.com/nova.log"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml379(para) msgid """" ""So you have an individual log file for each compute node as well as an "" ""aggregated log that contains nova logs from all nodes."" msgstr ""全てのノードからのnovaのログを含む集約されたログだけでなく、個々のコンピュートノードのログも持つことになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml385(title) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2616(glossterm) msgid ""StackTach"" msgstr ""StackTach"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml386(para) msgid """" ""StackTach is a tool created by Rackspace to collect and report the "" ""notifications sent by <code>nova</code>. Notifications are essentially the "" ""same as logs, but can be much more detailed. A good overview of "" ""notifications can be found at <link xlink:title=\""StackTach GitHub repo\"" "" ""xlink:href=\""https://wiki.openstack.org/wiki/SystemUsageData\"">System Usage "" ""Data</link> (https://wiki.openstack.org/wiki/SystemUsageData)."" msgstr ""StackTachはRackspaceによって作られたツールで、<code>nova</code>から送られた通知を収集してレポートします。通知は本質的にはログと同じですが、より詳細な情報を持ちます。通知の概要のよい資料は、<link xlink:title=\""StackTach GitHub repo\"" xlink:href=\""https://wiki.openstack.org/wiki/SystemUsageData\"">System Usage Data</link>(https://wiki.openstack.org/wiki/SystemUsageData)にあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml394(para) msgid """" ""To enable nova to send notifications, add the following to "" ""<code>nova.conf</code>:"" msgstr ""novaで通知の送信を有効化するには次の行を <code>nova.conf</code>に追加します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml398(para) msgid """" ""Once <code>nova</code> is sending notifications, install and configure "" ""StackTach. Since StackTach is relatively new and constantly changing, "" ""installation instructions would quickly become outdated. Please refer to the"" "" <link xlink:href=\""https://github.com/rackerlabs/stacktach\"">StackTach GitHub "" ""repo</link> (https://github.com/rackerlabs/stacktach) for instructions as "" ""well as a demo video."" msgstr ""<code>nova</code>が通知を送信するように設定後、StackTachをインストールします。StackTachは新しく、頻繁に更新されるので、インストール手順はすぐに古くなります。<link xlink:href=\""https://github.com/rackerlabs/stacktach\"">StackTach GitHub repo</link> (https://github.com/rackerlabs/stacktach) とデモビデオを参照して下さい。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml408(title) msgid ""Monitoring"" msgstr ""監視"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml409(para) msgid """" ""There are two types of monitoring: watching for problems and watching usage "" ""trends. The former ensures that all services are up and running, creating a "" ""functional cloud. The latter involves monitoring resource usage over time in"" "" order to make informed decisions about potential bottlenecks and upgrades."" msgstr ""二つの監視のタイプがあります。問題の監視と、利用傾向の監視です。前者は全てのサービスが動作していることを保証するものであり、後者は時間に沿ったリソース利用状況を監視することで、潜在的なボトルネックの発見とアップグレードのための情報を得るものです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml416(title) msgid ""Process Monitoring"" msgstr ""プロセス監視"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml417(para) msgid """" ""A basic type of alert monitoring is to simply check and see if a required "" ""process is running. For example, ensure that the <code>nova-api</code> "" ""service is running on the Cloud Controller:"" msgstr ""基本的なアラート監視は、単純に必要なプロセスが実行されているかどうかをチェックすることです。例えば、 <code>nova-api</code>サービスがクラウドコントローラーで動作していることを確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml428(para) msgid """" ""You can create automated alerts for critical processes by using Nagios and "" ""NRPE. For example, to ensure that the <code>nova-compute</code> process is "" ""running on compute nodes, create an alert on your Nagios server that looks "" ""like this:"" msgstr ""NagiosとNRPEを使って、クリティカルなプロセスの自動化されたアラートを作成することが可能です。<code>nova-compute</code> プロセスがコンピュートノードで動作していることを保証するために、Nagiosサーバー上で次のようなアラートを作成します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml441(para) msgid """" ""Then on the actual compute node, create the following NRPE configuration:"" msgstr ""そして、対象のコンピュートノードにおいて、次のようなNRPE設定を作成します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml444(para) msgid """" ""Nagios checks that at least one nova-compute service is running at all "" ""times."" msgstr ""Nagiosは常に一つ以上の <code>nova-compute</code>サービスが動作しているかをチェックします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml448(title) msgid ""Resource Alerting"" msgstr ""リソースのアラート"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml449(para) msgid """" ""Resource alerting provides notifications when one or more resources are "" ""critically low. While the monitoring thresholds should be tuned to your "" ""specific OpenStack environment, monitoring resource usage is not specific to"" "" OpenStack at all – any generic type of alert will work fine."" msgstr ""リソースのアラートは、一つ以上のリソースが極めて少なくなった場合に通知するものです。監視の閾値はインストールされたOpenStackの環境に合わせて設定すべきですが、リソース監視の利用方法は、OpenStackに固有の話ではありません。一般的なアラートのタイプが利用できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml455(para) msgid ""Some of the resources that you want to monitor include:"" msgstr ""監視項目に含む幾つかのリソースをあげます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml459(para) msgid ""Disk Usage"" msgstr ""ディスク使用量"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml462(para) msgid ""Server Load"" msgstr ""サーバー負荷"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml465(para) msgid ""Memory Usage"" msgstr ""メモリ使用量"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml468(para) msgid ""Network IO"" msgstr ""ネットワーク I/O"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml471(para) msgid ""Available vCPUs"" msgstr ""利用可能な vCPU 数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml474(para) msgid """" ""For example, to monitor disk capacity on a compute node with Nagios, add the"" "" following to your Nagios configuration:"" msgstr ""例として、コンピュートノード上のディスク容量をNagiosを使って監視する場合、次のようなNagios設定を追加します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml484(para) msgid ""On the compute node, add the following to your NRPE configuration:"" msgstr ""コンピュートノード上では、次のようなNRPE設定を追加します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml487(para) msgid """" ""Nagios alerts you with a WARNING when any disk on the compute node is 80% "" ""full and CRITICAL when 90% is full."" msgstr ""Naigosは、80%のディスク使用率でWARNING、90%でCRITICALを警告します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml492(title) msgid ""OpenStack-specific Resources"" msgstr ""OpenStack固有のリソース"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml493(para) msgid """" ""Resources such as memory, disk, and CPU are generic resources that all "" ""servers (even non-OpenStack servers) have and are important to the overall "" ""health of the server. When dealing with OpenStack specifically, these "" ""resources are important for a second reason: ensuring enough are available "" ""in order to launch instances. There are a few ways you can see OpenStack "" ""resource usage."" msgstr ""メモリ、ディスク、CPUのような一般的なリソースは、全てのサーバー(OpenStackに関連しないサーバーにも)に存在するため、サーバーの状態監視において重要です。OpenStackの場合、インスタンスを起動するために必要なリソースが確実に存在するかの確認という点でも重要です。OpenStackのリソースを見るためには幾つかの方法が存在します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml501(para) msgid ""The first is through the <code>nova</code> command:"" msgstr ""最初は <code>nova</code> コマンドを利用した例です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml504(para) msgid """" ""This command displays a list of how many instances a tenant has running and "" ""some light usage statistics about the combined instances. This command is "" ""useful for a quick overview of your cloud, but doesn't really get into a lot"" "" of details."" msgstr ""このコマンドはテナント上で実行されるインスタンスのリストと、インスタンス全体の簡単な利用統計を表示します。クラウドの簡単な概要を得るのに便利なコマンドですが、より詳細な情報については表示しません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml509(para) msgid """" ""Next, the <code>nova</code> database contains three tables that store usage "" ""information."" msgstr ""次に <code>nova</code> データベースは 利用情報に関して3つのテーブルを持っています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml511(para) msgid """" ""The <code>nova.quotas</code> and <code>nova.quota_usages</code> tables store"" "" quota information. If a tenant's quota is different than the default quota "" ""settings, their quota is stored in <code>nova.quotas</code> table. For "" ""example:"" msgstr ""<code>nova.quotas</code>と <code>nova.quota_usages</code> テーブルはクォータの情報が保管されています。もし、テナントのクォータがデフォルト設定と異なる場合、<code>nova.quotas</code>に保管されます。以下に例を示します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml531(para) msgid """" ""The <code>nova.quota_usages</code> table keeps track of how many resources "" ""the tenant currently has in use:"" msgstr ""<code>nova.quota_usages</code>テーブルはどのくらいリソースをテナントが利用しているかを記録しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml546(para) msgid """" ""By combining the resources used with the tenant's quota, you can figure out "" ""a usage percentage. For example, if this tenant is using 1 Floating IP out "" ""of 10, then they are using 10% of their Floating IP quota. You can take this"" "" procedure and turn it into a formatted report:"" msgstr ""リソース利用をテナントのクォータと結合することで、利用率を求めることが出来ます。例えば、テナントが、10個のうち1つのFloating IPを利用しているとすると、10%のFloating IP クォータを利用することになります。これを行なうことで、レポートを作ることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml573(para) msgid """" ""The above was generated using a custom script which can be found on GitHub "" ""(https://github.com/cybera/novac/blob/dev/libexec/novac-quota-report)."" msgstr ""上記の出力はこのGithub (https://github.com/cybera/novac/blob/dev/libexec/novac-quota-report) にあるカスタムスクリプトを用いて作成しました。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml577(para) msgid """" ""This script is specific to a certain OpenStack installation and must be "" ""modified to fit your environment. However, the logic should easily be "" ""transferable."" msgstr ""このスクリプトは特定のOpenStackインストール環境向けなので、自身の環境に適用する際には変更しなくてはいけませんが、ロジックは簡単に変更できるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml584(title) msgid ""Intelligent Alerting"" msgstr ""インテリジェントなアラート"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml585(para) msgid """" ""Intelligent alerting can be thought of as a form of continuous integration "" ""for operations. For example, you can easily check to see if Glance is up and"" "" running by ensuring that the <code>glance-api</code> and <code>glance-"" ""registry</code> processes are running or by seeing if <code>glace-api</code>"" "" is responding on port 9292."" msgstr ""インテリジェントなアラートは運用における継続的インテグレーションの要素の一つです。例えば、以下のような方法で簡単にGlanceが起動しているかを簡単に確認できます。<code>glance-api</code>と<code>glance-registry</code>プロセスが起動していることを確認する、もしくは<code>glace-api</code>が9292ポートに応答するといった方法です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml592(para) msgid """" ""But how can you tell if images are being successfully uploaded to the Image "" ""Service? Maybe the disk that Image Service is storing the images on is full "" ""or the S3 back-end is down. You could naturally check this by doing a quick "" ""image upload:"" msgstr ""しかし、イメージサービスにイメージが正しくアップロードされたことをどのように知ればいいのでしょうか? もしかしたら、イメージサービスが保管しているイメージのディスクが満杯、もしくはS3のバックエンドがダウンしているかもしれません。簡易的なイメージアップロードを行なうことでこれをチェックすることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml607(para) msgid """" ""By taking this script and rolling it into an alert for your monitoring "" ""system (such as Nagios), you now have an automated way of ensuring image "" ""uploads to the Image Catalog are working."" msgstr ""このスクリプトを(Nagiosのような)監視システムに組込むことで、イメージカタログのアップロードが動作していることを自動的に確認することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml612(para) msgid """" ""You must remove the image after each test. Even better, test whether you can"" "" successfully delete an image from the Image Service."" msgstr ""毎回テスト後にイメージを削除する必要があります。イメージサービスからイメージが削除できるかのテストにしてしまえば、さらによいです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml616(para) msgid """" ""Intelligent alerting takes a considerable more amount of time to plan and "" ""implement than the other alerts described in this chapter. A good outline to"" "" implement intelligent alerting is:"" msgstr ""インテリジェントなアラートは、この章で述べられているの他のアラートよりも計画、実装にかなり時間を要します。インテリジェントなアラートを実装する流れは次のようになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml622(para) msgid ""Review common actions in your cloud"" msgstr ""構築したクラウドにおいて一般的なアクションをレビューする"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml625(para) msgid ""Create ways to automatically test these actions"" msgstr ""それらのアクションに対して自動テストを作成する"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml629(para) msgid ""Roll these tests into an alerting system"" msgstr ""それらのテストをアラートシステムに組み込む"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml633(para) msgid ""Some other examples for Intelligent Alerting include:"" msgstr ""インテリジェントなアラートのその他の例としては以下があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml637(para) msgid ""Can instances launch and destroyed?"" msgstr ""インスタンスの起動と削除が可能か?"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml640(para) msgid ""Can users be created?"" msgstr ""ユーザの作成は可能か?"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml643(para) msgid ""Can objects be stored and deleted?"" msgstr ""オブジェクトの保存と削除は可能か?"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml646(para) msgid ""Can volumes be created and destroyed?"" msgstr ""ボリュームの作成と削除は可能か?"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml651(title) msgid ""Trending"" msgstr ""トレンド"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml652(para) msgid """" ""Trending can give you great insight into how your cloud is performing day to"" "" day. For example, if a busy day was simply a rare occurrence or if you "" ""should start adding new compute nodes."" msgstr ""トレンドはどのようにクラウドが実行されているかの素晴しい見通しを与えてくれます。例えば、負荷の高い日がたまたま発生したのか、新しいコンピュートノードを追加すべきか、などです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml656(para) msgid """" ""Trending takes a slightly different approach than alerting. While alerting "" ""is interested in a binary result (whether a check succeeds or fails), "" ""trending records the current state of something at a certain point in time. "" ""Once enough points in time have been recorded, you can see how the value has"" "" changed over time."" msgstr ""トレンドはアラートとは全く異なったアプローチです。アラートは0か1かの結果(チェックが成功するか失敗するか)に注目しているのに対して、トレンドはある時点での状態を定期的に記録します。十分な量が記録されれば、時系列でどのように値が変化するかを確認できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml663(para) msgid """" ""All of the alert types mentioned earlier can also be used for trend "" ""reporting. Some other trend examples include:"" msgstr ""これまでに示した全てのアラートタイプは、トレンドレポートに利用可能です。その他のトレンドの例は以下の通りです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml668(para) msgid ""The number of instances on each compute node"" msgstr ""各コンピュートノード上のインスタンス数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml672(para) msgid ""The types of flavors in use"" msgstr ""使用中のフレーバー"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml675(para) msgid ""The number of volumes in use"" msgstr ""使用中のボリューム数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml678(para) msgid ""The number of Object Storage requests each hour"" msgstr ""1時間あたりの Object Storage リクエスト数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml682(para) msgid ""The number of nova-api requests each hour"" msgstr ""1時間あたりの nova-api リクエスト数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml686(para) msgid ""The I/O statistics of your storage services"" msgstr ""ストレージサービスの I/O の統計"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml690(para) msgid """" ""As an example, recording <code>nova-api</code> usage can allow you to track "" ""the need to scale your cloud controller. By keeping an eye on <code>nova-"" ""api</code> requests, you can determine if you need to spawn more nova-api "" ""processes or go as far as introducing an entirely new server to run <code"" "">nova-api</code>. To get an approximate count of the requests, look for "" ""standard INFO messages in <code>/var/log/nova/nova-api.log</code>:"" msgstr ""例として、<code>nova-api</code>の使用を記録することでクラウドコントローラーをスケールする必要があるかを追跡できます。<code>nova-api</code>のリクエスト数に注目することにより、<code>nova-api</code>プロセスを追加するか、もしくは、<code>nova-api</code>を実行するための新しいサーバーを導入することまで行なうかを決定することができます。リクエストの概数を取得するには<code>/var/log/nova/nova-api.log</code>のINFOメッセージを検索します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml699(para) msgid ""# grep INFO /var/log/nova/nova-api.log | wc"" msgstr ""# grep INFO /var/log/nova/nova-api.log | wc"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml700(para) msgid """" ""You can obtain further statistics by looking for the number of successful "" ""requests:"" msgstr ""成功したリクエストを検索することで、更なる情報を取得できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml702(para) msgid ""# grep \"" 200 \"" /var/log/nova/nova-api.log | wc"" msgstr ""# grep \"" 200 \"" /var/log/nova/nova-api.log | wc"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml704(para) msgid """" ""By running this command periodically and keeping a record of the result, you"" "" can create a trending report over time that shows whether your <code>nova-"" ""api</code> usage is increasing, decreasing, or keeping steady."" msgstr ""このコマンドを定期的に実行し結果を記録することで、トレンドレポートを作ることができます。これにより<code>/var/log/nova/nova-api.log</code>の使用量が増えているのか、減っているのか、安定しているのか、を知ることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_log_monitor.xml709(para) msgid """" ""A tool such as collectd can be used to store this information. While "" ""collectd is out of the scope of this book, a good starting point would be to"" "" use collectd to store the result as a COUNTER data type. More information "" ""can be found in collectd's documentation "" ""(https://collectd.org/wiki/index.php/Data_source)"" msgstr ""collectdのようなツールはこのような情報を保管することに利用できます。collectdはこの本のスコープから外れますが、collectdでCOUNTERデータ形として結果を保存するのがよい出発点になります。より詳しい情報はcollectdのドキュメント (https://collectd.org/wiki/index.php/Data_source)を参照してください。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml433(None) msgid """" ""@@image: 'figures/horizon-user-project.png'; "" ""md5=73cb16964f410444bb8e27b694d2afd1"" msgstr ""@@image: 'figures/horizon-user-project.png'; md5=73cb16964f410444bb8e27b694d2afd1"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml15(title) msgid ""Managing Projects and Users"" msgstr ""プロジェクトとユーザーの管理"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml16(para) msgid """" ""An OpenStack cloud does not have much value without users. This chapter "" ""covers topics that relate to managing users, projects, and quotas."" msgstr ""OpenStack クラウドはユーザーがいないと、あまり価値がありません。本章はユーザー、プロジェクトおよびクォータの管理に関する話題を説明します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml20(title) msgid ""Projects or Tenants?"" msgstr ""プロジェクトかテナントか?"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml21(para) msgid """" ""In OpenStack user interfaces and documentation, a group of users is referred"" "" to as a <glossterm>project</glossterm> or <glossterm>tenant</glossterm>. "" ""These terms are interchangeable."" msgstr ""OpenStack のユーザーインターフェースおよびドキュメントにおいて、ユーザーのグループは<glossterm>プロジェクト</glossterm>または<glossterm>テナント</glossterm>と呼ばれます。これらの語は同じ意味で用いられます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml26(para) msgid """" ""The initial implementation of the OpenStack Compute Service (nova) had its "" ""own authentication system and used the term <literal>project</literal>. When"" "" authentication moved into the OpenStack Identity Service (keystone) "" ""project, it used the term <literal>tenant</literal> to refer to a group of "" ""users. Because of this legacy, some of the OpenStack tools refer to projects"" "" and some refer to tenants."" msgstr ""OpenStack Compute サービス (Nova) の初期実装は独自の認証システムを持ち、<literal>プロジェクト</literal>という用語を使用していました。認証が OpenStack Identity サービス (Keystone) プロジェクトに移行したとき、ユーザーのグループを参照するために<literal>テナント</literal>という用語が使用されました。このような経緯のため、いくつかの OpenStack ツールはプロジェクトを使用し、いくつかはテナントを使用します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml34(para) msgid """" ""This guide uses the term <literal>project</literal>, unless an example shows"" "" interaction with a tool that uses the term <literal>tenant</literal>."" msgstr ""このガイドは<literal>プロジェクト</literal>という用語を使用します。<literal>テナント</literal>という用語を使用するツールとやりとりする例もあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml39(title) msgid ""Managing Projects"" msgstr ""プロジェクトの管理"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml40(para) msgid """" ""Users must be associated with at least one project, though they may belong "" ""to many. Therefore, you should add at least one project before adding users."" msgstr ""ユーザーは少なくとも一つのプロジェクトに割り当てられる必要があります。複数に所属することもできます。そのため、ユーザーを追加する前に、少なくとも一つのプロジェクトを追加する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml44(title) msgid ""Adding Projects"" msgstr ""プロジェクトの追加"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml45(para) msgid ""To create a project through the dashboard:"" msgstr ""ダッシュボードからプロジェクトを追加する方法:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml48(para) msgid ""Log in as an administrative user."" msgstr ""管理ユーザーとしてログインします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml51(para) msgid ""Select the \""Projects\"" link in the left hand navigation bar."" msgstr ""左側のナビゲーションバーにある \""プロジェクト\"" リンクを選択します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml55(para) msgid ""Click on the \""Create Project\"" button at the top right."" msgstr ""右上にある \""プロジェクトの作成\"" ボタンをクリックします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml59(para) msgid """" ""You are prompted for a project name and an optional, but recommended, "" ""description. Select the check box at the bottom of the form to enable this "" ""project. By default, this is enabled."" msgstr ""プロジェクト名と説明の入力が求められます（説明の入力は任意ですが、入力をお薦めします）。このプロジェクトを有効にするには、フォームの下にあるチェックボックスを選択します。これは標準で有効になっています。"" #. <informalfigure> #. <mediaobject> #. <imageobject> #. <imagedata width=""5in"" #. fileref=""figures/horizon-add-project.png"" #. /> #. </imageobject> #. </mediaobject> #. </informalfigure> #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml72(para) msgid """" ""It is also possible to add project members and adjust the project quotas. "" ""We'll discuss those later, but in practice it can be quite convenient to "" ""deal with all these operations at one time."" msgstr ""プロジェクトメンバーを追加し、プロジェクトのクォータを調整することもできます。後述しますが、これらの操作を一度にすべて処理するほうが、実践的には非常に便利です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml77(para) msgid ""To create a project through the command-line interface (CLI):"" msgstr ""コマンドラインインターフェース (CLI) からプロジェクトを作成する方法:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml79(para) msgid """" ""To add a project through the command line, you must use the keystone "" ""utility, which uses \""tenant\"" in place of \""project\"": "" msgstr ""コマンドラインからのプロジェクト追加には、keystone ユーティリティを使用する必要があります。ここで \""プロジェクト\"" の代わりに \""テナント\"" を使用します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml83(para) msgid """" ""This command creates a project named \""demo\"". Optionally, you can add a "" ""description string by appending <code>--description &lt;tenant-"" ""description&gt;,</code> which can be very useful. You can also create a "" ""group in a disabled state by appending <code>--enabled false</code> to the "" ""command. By default, projects are created in an enabled state."" msgstr ""このコマンドは \""demo\"" という名前のプロジェクトを作成します。<code>--description &lt;tenant-description&gt;,</code> を追加で指定することで、説明の文字列を付与できます。これは非常に便利です。また、コマンドに <code>--enabled false</code> を追加することにより、無効状態のグループを作成することもできます。標準で、プロジェクトは有効状態で作成されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml95(title) msgid ""Quotas"" msgstr ""クォータ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml96(para) msgid """" ""OpenStack provides a number of quotas which are all enforced at the project "" ""(rather than user) level. As an administrative user in the Dashboard you can"" "" see (but not edit) the default quotas using the \""Quotas\"" link in the "" ""navigation sidebar. These default project quotas are specified in the "" ""<code>nova.conf</code> file on your cloud controller."" msgstr ""OpenStack には数多くのクォータがあります。クォータは (ユーザー単位ではなく) プロジェクト単位で適用されます。ダッシュボード上で管理者ユーザーであれば、ナビゲーションサイドバーにある \""クォータ\"" リンクを使用して、既定のクォータを参照できます (編集できません)。これらの規定のプロジェクトクォータはクラウドコントローラーにある <code>nova.conf</code> で指定されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml103(para) msgid """" ""If you do not make quota-related changes, the system uses the following "" ""defaults."" msgstr ""クォータ関連の変更を行っていない場合、システムは以下の既定値を使用します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml106(caption) msgid ""Description of nova.conf file configuration options for quotas"" msgstr ""nova.conf ファイルのクォータ関連の設定オプションに関する説明"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml119(th) msgid ""Configuration option=Default value"" msgstr ""設定オプション=規定値"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml120(th) msgid ""(Type) Description"" msgstr ""(型) 説明"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml126(para) msgid ""quota_cores=20"" msgstr ""quota_cores=20"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml129(para) msgid ""(IntOpt) number of instance cores allowed per project (tenant)"" msgstr ""(整数型) プロジェクト (テナント) ごとに許可されるインスタンスのコア数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml135(para) msgid ""quota_floating_ips=10"" msgstr ""quota_floating_ips=10"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml138(para) msgid ""(IntOpt) number of floating ips allowed per project (tenant)"" msgstr ""(整数型) プロジェクト (テナント) ごとに許可される Floating IP 数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml144(para) msgid ""quota_fixed_ips=-1"" msgstr ""quota_fixed_ips=-1"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml147(para) msgid """" ""(IntOpt) number of floating ips allowed per project (this should be at least"" "" the number of instances allowed). -1 is unlimited"" msgstr ""(整数型) プロジェクトごとに許可される Fixed IP 数 (少なくとも許可されたインスタンスの数にすべきです)。-1 は無制限です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml155(para) msgid ""quota_gigabytes=1000"" msgstr ""quota_gigabytes=1000"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml158(para) msgid ""(IntOpt) number of volume gigabytes allowed per project (tenant)"" msgstr ""(整数型) プロジェクト (テナント) ごとに許可されるボリューム容量（単位はギガバイト）"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml164(para) msgid ""quota_injected_file_content_bytes=10240"" msgstr ""quota_injected_file_content_bytes=10240"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml167(para) msgid ""(IntOpt) number of bytes allowed per injected file"" msgstr ""(整数型) injected file あたりの最大バイト数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml173(para) msgid ""quota_injected_file_path_bytes=255"" msgstr ""quota_injected_file_path_bytes=255"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml176(para) msgid ""(IntOpt) number of bytes allowed per injected file path"" msgstr ""(整数型) injected file のパス長の最大バイト数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml182(para) msgid ""quota_injected_files=5"" msgstr ""quota_injected_files=5"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml185(para) msgid ""(IntOpt) number of injected files allowed"" msgstr ""(整数型) 許可される injected file 数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml191(para) msgid ""quota_instances=10"" msgstr ""quota_instances=10"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml194(para) msgid ""(IntOpt) number of instances allowed per project (tenant)"" msgstr ""(整数型) プロジェクト (テナント) ごとに許可されるインスタンス数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml200(para) msgid ""quota_key_pairs=100"" msgstr ""quota_key_pairs=100"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml203(para) msgid ""(IntOpt) number of key pairs allowed per user"" msgstr ""(整数型) ユーザーごとに許可されるキーペア数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml209(para) msgid ""quota_metadata_items=128"" msgstr ""quota_metadata_items=128"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml212(para) msgid ""(IntOpt) number of metadata items allowed per instance"" msgstr ""(整数型) インスタンスごとに許可されるメタデータ項目数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml218(para) msgid ""quota_ram=51200"" msgstr ""quota_ram=51200"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml221(para) msgid ""(IntOpt) megabytes of instance ram allowed per project (tenant)"" msgstr ""(整数型) プロジェクト (テナント) ごとに許可されるインスタンスの RAM のメガバイト容量"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml227(para) msgid ""quota_security_group_rules=20"" msgstr ""quota_security_group_rules=20"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml230(para) msgid ""(IntOpt) number of security rules per security group"" msgstr ""(整数型) セキュリティグループごとのセキュリティルール数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml236(para) msgid ""quota_security_groups=10"" msgstr ""quota_security_groups=10"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml239(para) msgid ""(IntOpt) number of security groups per project (tenant)"" msgstr ""(整数型) プロジェクト (テナント) ごとに許可されるセキュリティグループ数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml245(para) msgid ""quota_volumes=10"" msgstr ""quota_volumes=10"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml248(para) msgid ""(IntOpt) number of volumes allowed per project (tenant)"" msgstr ""(整数型) プロジェクト (テナント) ごとに許可されるボリューム数"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml254(para) msgid """" ""Configuration table excerpted from http://docs.openstack.org/folsom"" ""/openstack-compute/admin/content/list-of-compute-config-options.html."" msgstr ""設定の表は from http://docs.openstack.org/folsom/openstack-compute/admin/content/list-of-compute-config-options.html から抜粋されています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml255(para) msgid """" ""The simplest way to change the default project quotas is to edit the "" ""<code>nova.conf</code> file on your cloud controller. Quotas are enforced by"" "" the <code>nova-scheduler</code> service, so you must restart that service "" ""once you change these options."" msgstr ""プロジェクトの規定のクォータを変更する最も簡単な方法は、クラウドコントローラーにおいて <code>nova.conf</code> ファイルを編集することです。クォータは <code>nova-scheduler</code> サービスにより適用されます。そのため、これらのオプションを変更すると、そのサービスを再起動する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml260(para) msgid """" ""If your site implementation varies from our example architecture, ensure any"" "" changes you make to quota default options in "" ""<code>/etc/nova/nova.conf</code> are applied to the host(s) running the "" ""<code>nova-scheduler</code> service. It is critical for consistent quota "" ""enforcement that all schedulers have identical quotas. Assuming you are "" ""following the best practices recommended in this guide, your configuration "" ""management system will automatically ensure all your schedulers have "" ""consistent configurations."" msgstr ""あなたのサイトの実装がこの例のアーキテクチャーと異なるならば、<code>/etc/nova/nova.conf</code> にあるクォータのデフォルト値に関するオプションに対するすべての変更が <code>nova-scheduler</code> サービスを実行しているホストに適用されていることを確認します。一貫性のあるクォータ設定のために、すべてのスケジューラーが同じクォータを持つことが非常に重要です。このガイドにおいて推奨されているベストプラクティスに従った場合、設定管理システムにより、自動的に、すべてのスケジューラーが一貫した設定を持った状態に保たれます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml270(para) msgid """" ""To view and edit quotas for an individual project through the Dashboard:"" msgstr ""各プロジェクトのクォータをダッシュボードから表示および編集する方法:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml274(para) msgid """" ""Use the \""Projects\"" navigation link to get a list of your existing "" ""projects."" msgstr ""既存のプロジェクトの一覧を取得するには \""プロジェクト\"" ナビゲーションリンクを使用します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml278(para) msgid """" ""Locate the project you want to modify and select \""Modify Quotas\"" from the "" ""\""Actions\"" drop down menu a the end of the line. "" msgstr ""変更したいプロジェクトに移動し、\""アクション\"" ドロップダウンメニューの最終行にある \""クォータの変更\"" を選択します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml283(para) msgid """" ""To view and edit quotas for an individual project through the CLI, follow "" ""these steps:"" msgstr ""各プロジェクトのクォータを CLI から表示および編集する方法は、以下のとおりです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml285(para) msgid """" ""You can access and modify quotas from the command line but it is a bit "" ""complicated. This is done using Keystone to get the ID and then <code>nova-"" ""manage.</code>"" msgstr ""コマンドラインからクォータの確認および変更をできますが、少しだけ複雑です。Keystone を使って ID を取得し、それから <code>nova-manage</code> を実行します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml290(para) msgid """" ""To list a project's quota, you must first find its ID using the Keystone CLI"" "" tool."" msgstr ""プロジェクトのクォータを一覧表示するには、まず Keystone CLI ツールを使用して ID を確認する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml296(para) msgid """" ""Recall that the Keystone CLI tool uses \""tenant\"" where the Nova CLI tool "" ""uses \""project\"" for the same concept."" msgstr ""Nova CLI ツールが \""プロジェクト\"" を使用するところで、Keystone CLI ツールは同じ意味で \""テナント\"" を使用することを思い出してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml299(para) msgid """" ""To show the quota for the project, for the example above, we must use the ID"" "" <code>98333a1a28e746fa8c629c83a818ad57</code>:"" msgstr ""上の例に対して、プロジェクトのクォータを表示するには、ID <code>98333a1a28e746fa8c629c83a818ad57</code> を使用する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml315(para) msgid """" ""Confusingly, <code>nova-manage project quota</code> silently accepts any "" ""string at the end of the command and reports the default quotas. In "" ""particular, if you enter the project name rather than the ID, <code>nova-"" ""manage</code> does not complain, it just lies."" msgstr ""ややこしいことに、 <code>nova-manage project quota</code> はコマンドの最後の引き数にどんな文字列でも受け付け、その場合クォータの規定値が表示されます。とくに、ID の代わりにプロジェクトの名前を入力しても、<code>nova-manage</code> は何も警告せず、単に嘘をつきます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml323(para) msgid """" ""To change these values you append <code>--key</code> and "" ""<code>--value</code> flags to the above command. To increase the tenant "" ""quota of Floating IPs from 10 to 20:"" msgstr ""これらの値を変更するには、上のコマンドに <code>--key</code> および <code>--value</code> フラグを追加します。プロジェクトの Floating IP のクォータを 10 から 20 に増やす方法:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml343(title) msgid ""User Management"" msgstr ""ユーザー管理"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml344(para) msgid """" ""The command line tools for managing users are inconvenient to use directly. "" ""They require issuing multiple commands to complete a single task, and they "" ""use UUIDs rather than symbolic names for many items. In practice, humans "" ""typically do not use these tools directly. Fortunately, the OpenStack "" ""Dashboard provides a reasonable interface to this. In addition, many sites "" ""write custom tools for local needs to enforce local policies and provide "" ""levels of self service to users that aren't currently available with "" ""packaged tools."" msgstr ""直接コマンドラインツールを使ってユーザーを管理することは面倒です。一つの作業を完了するために、複数のコマンドを実行する必要があります。多くの項目に対して、シンボル名の代わりに UUID を使用します。現実的に、人間はこれらのツールをそのまま使用しません。幸運なことに、OpenStack ダッシュボードが便利なインターフェースを提供しています。さらに、多くのサイトは個別の要求を満たすために独自ツールを作成し、サイト固有のポリシーを適用し、パッケージツールでは実現できないレベルのセルフサービスをユーザーに提供しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml356(title) msgid ""Creating New Users"" msgstr ""新規ユーザーの作成"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml357(para) msgid ""To create a user, you need the following information:"" msgstr ""ユーザーを作成するには、以下の情報が必要です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml361(para) msgid ""Username"" msgstr ""ユーザー名"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml364(para) msgid ""Email address"" msgstr ""電子メールアドレス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml367(para) msgid ""Password"" msgstr ""パスワード"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml370(para) msgid ""Primary project"" msgstr ""主プロジェクト"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml373(para) msgid ""Role"" msgstr ""役割"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml376(para) msgid """" ""Username and email address are self-explanatory, though your site may have "" ""local conventions you should observe. Setting and changing passwords in the "" ""Identity Service requires administrative privileges. As of the Folsom "" ""release, users cannot change their own passwords. This is a large driver for"" "" creating local custom tools, and must be kept in mind when assigning and "" ""distributing passwords. The primary project is simply the first project the "" ""user is associated with and must exist prior to creating the user. Role is "" ""almost always going to be \""member\"". Out of the box, OpenStack comes with "" ""two roles defined:"" msgstr ""ユーザー名と電子メールアドレスは見たとおりです。あなたのサイトは従うべき独自ルールがあるかもしれません。Identity サービスにおいてパスワードを設定および変更するには、管理者権限が必要です。Folsom リリースまでは、ユーザーが自分のパスワードを変更できません。これは独自のツールを作成する大きな理由になります。また、パスワードを割り当ておよび配布するときに気をつける必要があります。主プロジェクトは単にユーザーが割り当てられる最初のプロジェクトです。ユーザーを作成する前に存在している必要があります。役割は多くの場合ずっと \""メンバー\"" のままになります。標準の状態で、OpenStack は次の 2 つの役割が定義されています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml389(para) msgid ""\""member\"": a typical user."" msgstr ""\""member\"": 一般的なユーザー。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml392(para) msgid """" ""\""admin\"": an administrative super user which has full permissions across "" ""all projects and should be used with great care."" msgstr ""\""admin\"": すべてのプロジェクトにわたり全権限を持つ管理ユーザー。非常に注意して使用する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml397(para) msgid ""It is possible to define other roles, but doing so is uncommon."" msgstr ""他の役割を定義できますが、一般的にはそうしません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml399(para) msgid """" ""Once you've gathered this information, creating the user in the Dashboard is"" "" just another web form similar to what we've seen before and can be found on"" "" the \""Users\"" link in the \""Admin\"" navigation bar and then clicking the "" ""\""Create User\"" button at the top right."" msgstr ""一度この情報を収集すると、ダッシュボードでのユーザーの作成は、これまでに見てきた他の Web フォームと同じです。\""管理\"" ナビゲーションバーの \""ユーザー\"" リンクにあります。そして、右上にある \""ユーザーの作成\"" ボタンをクリックします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml404(para) msgid """" ""Modifying users is also done from this \""Users\"" page. If you have a large "" ""number of users, this page can get quite crowded. The \""Filter\"" search box "" ""at the top of the page can be used to limit the users listing. A form very "" ""similar to the user creation dialog can be pulled up by selecting \""Edit\"" "" ""from the actions drop down menu at the end of the line for the user you are "" ""modifying."" msgstr ""ユーザー情報の変更は、この \""ユーザー” ページから実行することもできます。かなり多くのユーザーがいるならば、このページにはたくさんのユーザーが表示されることでしょう。ページの上部にある \""フィルター\"" 検索ボックスを使うと、表示されるユーザーの一覧を絞り込むことができます。変更しようとしているユーザーの行末にあるアクションドロップダウンメニューの ”編集” を選択することにより、ユーザー作成ダイアログと非常に似ているフォームを表示できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml413(title) msgid ""Associating Users with Projects"" msgstr ""プロジェクトへのユーザーの割り当て"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml414(para) msgid """" ""Many sites run with users being associated with only one project. This is a "" ""more conservative and simpler choice both for administration and for users. "" ""Administratively if a user reports a problem with an instance or quota it is"" "" obvious which project this relates to as well. Users needn't worry about "" ""what project they are acting in if they are only in one project. However, "" ""note that, by default, any user can affect the resources of any other user "" ""within their project. It is also possible to associate users with multiple "" ""projects if that makes sense for your organization."" msgstr ""多くのサイトは一つのプロジェクトのみに割り当てられているユーザーで実行しています。これは、管理者にとってもユーザーにとっても、より保守的で分かりやすい選択です。管理の面では、ユーザーからインスタンスやクォータに関する問題の報告があった場合、どのプロジェクトに関するものかが明確です。ユーザーが一つのプロジェクトのみに所属している場合、ユーザーがどのプロジェクトで操作しているのかを気にする必要がありません。ただし、既定の設定では、どのユーザーも同じプロジェクトにいる他のユーザーのリソースに影響を与えることができることに注意してください。あなたの組織にとって意味があるならば、ユーザーを複数のプロジェクトに割り当てることも可能です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml425(para) msgid """" ""Associating existing users with an additional project or removing them from "" ""an older project is done from the \""Projects\"" page of the Dashboard by "" ""selecting the \""Modify Users\"" from the \""Actions\"" column:"" msgstr ""既存のユーザーを追加のプロジェクトに割り当てる、または古いプロジェクトから削除することは、ダッシュボードの ”プロジェクト” ページから、\""アクション\"" 列の \""ユーザーの変更\"" を選択することにより実行できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml437(para) msgid """" ""From this view you can do a number of useful and a few dangerous things."" msgstr ""このビューから、多くの有用な操作、いくつかの危険な操作を実行できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml439(para) msgid """" ""The first column of this form, titled \""All Users\"", will include a list of "" ""all the users in your cloud who are not already associated with this project"" "" and the second all the users who are. These can be quite long, but can be "" ""limited by typing a substring of the user name you are looking for in the "" ""filter field at the top of the column."" msgstr ""\""すべてのユーザー (All Users)\"" という見出しが付けられた、このフォームの最初の列に、このプロジェクトにまだ割り当てられていない、クラウドのすべてのユーザーが一覧表示されます。2 列目には、すべての割り当て済みユーザーが一覧表示されます。これらは非常に長い可能性があります。しかし、それぞれの列の上部にあるフィルターフィールドに、探しているユーザー名の部分文字列を入力することにより、表示を絞り込むことができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml446(para) msgid """" ""From here, click the <guiicon>+</guiicon> icon to add users to the project. "" ""Click the <guiicon>-</guiicon> to remove them."" msgstr ""ここから、プロジェクトにユーザーを追加するには <guiicon>+</guiicon> アイコンをクリックします。削除するには <guiicon>-</guiicon> をクリックします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml449(para) msgid """" ""The dangerous possibility comes in the ability to change member roles. This "" ""is the drop down list after the user name in the \""Project Members\"" list. "" ""In virtually all cases this value should be set to \""Member\"". This example "" ""purposefully show and administrative user where this value is \""admin\""."" msgstr ""危険な点としては、メンバーの役割を変更する機能があることです。これは \""プロジェクトメンバー\"" 一覧のユーザー名の後ろにあるドロップダウンリストです。事実上すべての場合で、この値は \""メンバー\"" に設定されています。この例では意図的に、この値が \""管理者\"" になっている管理ユーザーを示しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml454(para) msgid """" ""The \""admin\"" is global not per project so granting a user the admin role in"" "" any project gives the administrative rights across the whole cloud."" msgstr ""\""管理者\"" はプロジェクトごとではなく、グローバルです。そのため、ユーザーに管理者の役割を与えることにより、クラウド全体にわたる管理者権限を与えることになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml457(para) msgid """" ""Typical use is to only create administrative users in a single project, by "" ""convention the \""admin\"" project which is created by default during cloud "" ""setup. If your administrative users also use the cloud to launch and manage "" ""instances it is strongly recommended that you use separate user accounts for"" "" administrative access and normal operations and that they be in distinct "" ""projects."" msgstr ""一般的な使用法は、一つのプロジェクトだけに管理ユーザーを所属させることです。慣例により、\""admin\"" プロジェクトがクラウド環境のセットアップ中に標準で作成されます。管理ユーザーもクラウドを使用してインスタンスの起動、管理を行う場合には、管理アクセスと一般アクセス用に別々のユーザーアカウントを使用し、それらのユーザーを別々のプロジェクトにすることを強く推奨します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml466(title) msgid ""Customizing Authorization"" msgstr ""権限のカスタマイズ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml467(para) msgid """" ""The default <glossterm>authorization</glossterm> settings only allow "" ""administrative users to create resources on behalf of a different project. "" ""OpenStack handles two kind of authorization policies:"" msgstr ""デフォルトの<glossterm>認可</glossterm>設定では、管理ユーザーのみが他のプロジェクトのリソースを作成できます。OpenStack では以下の 2 種類の認可ポリシーを使うことができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml473(para) msgid """" ""<emphasis role=\""bold\"">Operation-based</emphasis>: policies specify access "" ""criteria for specific operations, possibly with fine-grained control over "" ""specific attributes."" msgstr ""<emphasis role=\""bold\"">操作ベース</emphasis>: 特定の操作に対するアクセス基準を指定するポリシー。特定の属性に対する詳細な制御も可能です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml481(para) msgid """" ""<emphasis role=\""bold\"">Resource-based</emphasis>: whether access to a "" ""specific resource might be granted or not according to the permissions "" ""configured for the resource (currently available only for the network "" ""resource). The actual authorization policies enforced in an OpenStack "" ""service vary from deployment to deployment."" msgstr ""<emphasis role=\""bold\"">リソースベース</emphasis>: リソースに対して設定されたパーミッションに基づいて、特性のリソースに対するアクセスを許可するかを決定する (今のところネットワークリソースでのみ利用可能)。OpenStack により強制される実際の認可ポリシーは、導入の仕方により異なります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml492(para) msgid """" ""The policy engine reads entries from the <code>policy.json</code> file. The "" ""actual location of this file might vary from distribution to distribution, "" ""for nova it is typically in <code>/etc/nova/policy.json</code>. You can "" ""update entries while the system is running, and you do not have to restart "" ""services. Currently the only way to update such policies is to edit the "" ""policy file."" msgstr ""ポリシーエンジンは <code>policy.json</code> ファイルから項目を読み込みます。このファイルの実際の位置はディストリビューションにより異なります。一般的に Nova 用の設定ファイルは <code>/etc/nova/policy.json</code> にあります。システムの実行中に項目を更新でき、サービスを再起動する必要がありません。今のところ、ポリシーファイルの編集がこのようなポリシーを更新する唯一の方法です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml501(para) msgid """" ""The OpenStack service's policy engine matches a policy directly. A rule "" ""indicates evaluation of the elements of such policies. For instance, in a "" ""<code>compute:create: [[\""rule:admin_or_owner\""]]</code> statement, the "" ""policy is <code>compute:create</code>, and the rule is "" ""<code>admin_or_owner</code>."" msgstr ""OpenStack サービスのポリシーエンジンがポリシーと直接照合を行います。ルールはそのようなポリシーの要素の評価を意味します。たとえば、<code>compute:create: [[\""rule:admin_or_owner\""]]</code> 文において、ポリシーは <code>compute:create</code> で、ルールは <code>admin_or_owner</code> です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml508(para) msgid """" ""Policies are triggered by an OpenStack policy engine whenever one of them "" ""matches an OpenStack API operation or a specific attribute being used in a "" ""given operation. For instance, the engine tests the "" ""<code>create:compute</code> policy every time a user sends a <code>POST "" ""/v2/{tenant_id}servers</code> request to the OpenStack Compute API server. "" ""Policies can be also related to specific <glossterm>API "" ""extension</glossterm>s. For instance, if a user needs an extension like "" ""<code>compute_extension:rescue</code> the attributes defined by the provider"" "" extensions trigger the rule test for that operation."" msgstr ""ポリシーのいずれかが OpenStack API 操作、もしくは指定された操作で使用されている特定の属性に一致する場合、ポリシーが OpenStack ポリシーエンジンにより呼び出されます。たとえば、ユーザーが <code>POST /v2/{tenant_id}/servers</code> リクエストを OpenStack Compute API サーバーに送信したときに必ず、エンジンが <code>create:compute</code> ポリシーを確認します。ポリシーは特定の <glossterm>API 拡張</glossterm>に関連づけることもできます。たとえば、ユーザーが <code>compute_extension:rescue</code> のような拡張に対して要求を行った場合、プロバイダー拡張により定義された属性は、その操作に対するルールテストを呼び出します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml521(para) msgid """" ""An authorization policy can be composed by one or more rules. If more rules "" ""are specified, evaluation policy is successful if any of the rules evaluates"" "" successfully; if an API operation matches multiple policies, then all the "" ""policies must evaluate successfully. Also, authorization rules are "" ""recursive. Once a rule is matched, the rule(s) can be resolved to another "" ""rule, until a terminal rule is reached. These are the rules defined:"" msgstr ""認可ポリシーは、一つまたは複数のルールにより構成できます。複数のルールを指定すると、いずれかのルールが成功と評価されれば、評価エンジンが成功になります。API 操作が複数のポリシーに一致すると、すべてのポリシーが成功と評価される必要があります。認可ルールは再帰的にもできます。あるルールにマッチした場合、これ以上展開できないルールに達するまで、そのルールは別のルールに展開されます。以下のルールが定義できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml533(para) msgid """" ""<emphasis role=\""bold\"">Role-based rules</emphasis>: evaluate successfully "" ""if the user submitting the request has the specified role. For instance "" ""<code>\""role:admin\""</code>is successful if the user submitting the request "" ""is an administrator."" msgstr ""<emphasis role=\""bold\"">役割に基づいたルール</emphasis>: リクエストを出したユーザーが指定された役割を持っていれば、成功と評価されます。たとえば、リクエストを出しているユーザーが管理者ならば、<code>\""role:admin\""</code> が成功します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml545(para) msgid """" ""<emphasis role=\""bold\"">Field-based rules: </emphasis>evaluate successfully "" ""if a field of the resource specified in the current request matches a "" ""specific value. For instance <code>\""field:networks:shared=True\""</code> is "" ""successful if the attribute shared of the network resource is set to true."" msgstr ""<emphasis role=\""bold\"">項目に基づいたルール</emphasis>: 現在のリクエストに指定されたリソースの項目が指定された値と一致すれば、成功と評価されます。たとえば、ネットワークリソースの shared 属性が True に設定されている場合、<code>\""field:networks:shared=True\""</code> が成功します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml557(para) msgid """" ""<emphasis role=\""bold\"">Generic rules:</emphasis> compare an attribute in "" ""the resource with an attribute extracted from the user's security "" ""credentials and evaluates successfully if the comparison is successful. For "" ""instance <code>\""tenant_id:%(tenant_id)s\""</code> is successful if the "" ""tenant identifier in the resource is equal to the tenant identifier of the "" ""user submitting the request."" msgstr ""<emphasis role=\""bold\"">一般的なルール</emphasis>: リソースの属性をユーザーのセキュリティクレデンシャルから抽出した属性と比較し、一致した場合に成功と評価されます。たとえば、リソースのテナント識別子がリクエストを出したユーザーのテナント識別子と一致すれば、<code>\""tenant_id:%(tenant_id)s\""</code> が成功します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml571(para) msgid """" ""Here are snippets of the default nova <filename>policy.json</filename> file:"" msgstr ""これは標準の nova <filename>policy.json</filename> ファイルの抜粋です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml575(emphasis) msgid ""[1]"" msgstr ""[1]"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml576(emphasis) msgid ""[2]"" msgstr ""[2]"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml592(emphasis) msgid ""[3]"" msgstr ""[3]"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml595(para) msgid """" ""[1] Shows a rule which evaluates successfully if the current user is an "" ""administrator or the owner of the resource specified in the request (tenant "" ""identifier is equal)."" msgstr ""[1] 現在のユーザーが、管理者、またはリクエストで指定されたリソースの所有者 (テナント識別子が同じ) であれば、成功であると評価されるルールを表します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml599(para) msgid """" ""[2] Shows the default policy which is always evaluated if an API operation "" ""does not match any of the policies in <code>policy.json</code>."" msgstr ""[2] API 操作が <code>policy.json</code> のどのポリシーとも一致しなかった場合に、必ず評価される規定のポリシーを表します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml602(para) msgid """" ""[3] Shows a policy restricting the ability of manipulating flavors to "" ""administrators using the Admin API only."" msgstr ""[3] インスタンスタイプを操作する権限を、管理 API を使用する管理者だけに限定するポリシーを表します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml605(para) msgid """" ""In some cases, some operations should be restricted to administrators only. "" ""Therefore, as a further example, let us consider how this sample policy file"" "" could be modified in a scenario where we enable users to create their own "" ""flavors:"" msgstr ""いくつかの場合では、ある操作が管理者のみに制限されるべきです。そこで、次の例では、ユーザーが自分のフレーバーを作成できるようにするシナリオの場合に、このサンプルのポリシーファイルをどのように変更すればよいかを示します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml613(title) msgid ""Users that Disrupt Other Users"" msgstr ""他のユーザーに悪影響を与えるユーザー"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml614(para) msgid """" ""Users on your cloud can disrupt other users, sometimes intentionally and "" ""maliciously and other times by accident. Understanding the situation allows "" ""you to make a better decision on how to handle the disruption."" msgstr ""クラウドのユーザーは他のユーザーに悪影響を与える場合があります。意図的に悪意を持って行わる場合もあれば、偶然起こる場合もあります。状況を理解することにより、このような混乱に対処する方法について、よりよい判断をできるようになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml619(para) msgid """" ""For example: A group of users have instances that are utilizing a large "" ""amount of compute resources for very compute-intensive tasks. This is "" ""driving the load up on compute nodes and affecting other users. In this "" ""situation, review your user use cases. You may find that high compute "" ""scenarios are common and should then plan for proper segregation in your "" ""cloud such as host aggregation or regions."" msgstr ""例えば: あるユーザーのグループが、非常に計算負荷の高い作業用に大量のコンピュートリソースを使うインスタンスを持っているとします。これにより、Compute ノードの負荷が高くなり、他のユーザーに影響を与えます。この状況では、ユーザーのユースケースを精査する必要があります。計算負荷が高いシナリオがよくあるケースだと判明し、ホスト集約やリージョンなど、クラウドを適切に分割することを計画すべき場合もあるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml627(para) msgid """" ""Another example is a user consuming a very large amount of bandwidth. Again,"" "" the key is to understand what the user is doing. If they naturally need a "" ""high amount of bandwidth, you might have to limit their transmission rate as"" "" to not affect other users or move them to an area with more bandwidth "" ""available. On the other hand, maybe the user's instance has been hacked and "" ""is part of a botnet launching DDOS attacks. Resolution to this issue is the "" ""same as if any other server on your network has been hacked. Contact the "" ""user and give them time to respond. If they don't respond, shut the instance"" "" down."" msgstr ""別の例は、あるユーザーが非常に多くの帯域を消費することです。繰り返しですが、ユーザーが実行していることを理解することが重要です。必ず多くの帯域を使用する必要があれば、他のユーザーに影響を与えないように通信帯域を制限する、または、より多くの帯域を利用可能な別の場所に移動させる必要があるかもしれません。一方、ユーザーのインスタンスが侵入され、DDOS 攻撃を行っているボットネットの一部になっているかもしれません。この問題の解決法は、ネットワークにある他のサーバーが侵入された場合と同じです。ユーザーに連絡し、対応する時間を与えます。もし対応しなければ、そのインスタンスを停止します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml639(para) msgid """" ""A final example is if a user is hammering cloud resources repeatedly. "" ""Contact the user and learn what they are trying to do. Maybe they don't "" ""understand that what they're doing is inappropriate or maybe there is an "" ""issue with the resource they are trying to access that is causing their "" ""requests to queue or lag."" msgstr ""最後の例は、ユーザーがクラウドのリソースに繰り返し悪影響を与える場合です。ユーザーと連絡をとり、何をしようとしているのか理解します。ユーザー自身が実行しようとしていることを正しく理解していない可能性があります。または、アクセスしようとしているリソースに問題があり、リクエストがキューに入ったり遅れが発生している場合もあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_projects_users.xml646(para) msgid """" ""One key element of systems administration that is often overlooked is that "" ""end users are the reason why systems administrators exist. Don't go the BOFH"" "" route and terminate every user who causes an alert to go off. Work with "" ""them to understand what they're trying to accomplish and see how your "" ""environment can better assist them in achieving their goals."" msgstr ""システム管理の見過ごされがちな大事な要素の一つに、エンドユーザのためにシステム管理者が存在するという点があります。BOFH (Bastard Operator From Hell; 「地獄から来た最悪の管理者」) の道に入って、問題の原因となっているユーザーを全員停止させるようなことはしないでください。ユーザーがやりたいことを一緒になって理解し、どうするとあなたの環境がユーザーが目的を達成するのにもっと支援できるかを見つけてください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml16(title) msgid ""Customize"" msgstr ""カスタマイズ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml17(para) msgid """" ""OpenStack might not do everything you need it to do out of the box. In these"" "" cases, you can follow one of two major paths. First, you can learn <link "" ""xlink:href=\""https://wiki.openstack.org/wiki/How_To_Contribute\"">How To "" ""Contribute</link> (https://wiki.openstack.org/wiki/How_To_Contribute), "" ""follow the <link "" ""xlink:href=\""https://wiki.openstack.org/wiki/GerritWorkflow\"">Code Review "" ""Workflow</link> (https://wiki.openstack.org/wiki/GerritWorkflow), make your "" ""changes and contribute them back to the upstream OpenStack project. This "" ""path is recommended if the feature you need requires deep integration with "" ""an existing project. The community is always open to contributions and "" ""welcomes new functionality that follows the feature development guidelines."" msgstr ""OpenStack はあなたが必要とするすべてのことをしてくれるわけではないかもしれません。この場合、主に2つのやり方のうちのいずれかに従ってください。まず最初に、<link xlink:href=\""https://wiki.openstack.org/wiki/How_To_Contribute\"">貢献するには</link> (https://wiki.openstack.org/wiki/How_To_Contribute) を学び、<link xlink:href=\""https://wiki.openstack.org/wiki/GerritWorkflow\"">Code Review Workflow</link> (https://wiki.openstack.org/wiki/GerritWorkflow) に従って、あなたの修正を上流の OpenStack プロジェクトへコントリビュートしてください。もし、あなたが必要な機能が既存のプロジェクトと密にインテグレーションする必要がある場合、これが推奨される選択肢です。コミュニティは、いつでも貢献に対して開かれていますし、機能開発ガイドラインに従う新機能を歓迎します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml33(para) msgid """" ""Alternately, if the feature you need does not require deep integration, "" ""there are other ways to customize OpenStack. If the project where your "" ""feature would need to reside uses the Python Paste framework, you can create"" "" middleware for it and plug it in through configuration. There may also be "" ""specific ways of customizing an project such as creating a new scheduler for"" "" OpenStack Compute or a customized Dashboard. This chapter focuses on the "" ""second method of customizing OpenStack."" msgstr ""代替え案としては、もしあなたが必要とする機能が密なインテグレーションを必要としないのであれば、OpenStack をカスタマイズする他の方法があります。もし、あなたの機能が必要とされるプロジェクトが Python Paste フレームワークを使っているのであれば、そのための ミドルウェアを作成し、環境設定を通じて組み込めばよいのです。例えば OpenStack Compute の新しいスケジューラーや、カスタマイズされたダッシュボードを作成するといった、プロジェクトをカスタマイズする特定の方法もあるかもしれません。この章では、OpenStack をカスタマイズする後者の方法にフォーカスします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml42(para) msgid """" ""To customize OpenStack this way you'll need a development environment. The "" ""best way to get an environment up and running quickly is to run DevStack "" ""within your cloud."" msgstr ""OpenStack をこの方法でカスタマイズするためには、開発環境が必要です。開発環境を手軽に動作させる最良の方法は、クラウドの中で DevStack を動かすことです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml47(title) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml975(glossterm) msgid ""DevStack"" msgstr ""DevStack"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml48(para) msgid """" ""You can find all of the documentation at the <link "" ""xlink:href=\""http://devstack.org/\"">DevStack</link> (http://devstack.org/) "" ""website. Depending on which project you would like to customize, either "" ""Object Storage (swift) or another project, you must configure DevStack "" ""differently. For the middleware example below, you must install with the "" ""Object Store enabled."" msgstr ""ドキュメンテーションはすべて <link xlink:href=\""http://devstack.org/\"">DevStack</link> (http://devstack.org/) のウェブサイトにあります。 どのプロジェクトをカスタマイズしたいかによって、つまり Object Storage (swift) なのか他のプロジェクトなのかによって、DevStack の環境設定が異なります。以下のミドルウェアの例では、Object Storage を有効にしてインストールしなければなりません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml57(title) msgid ""To run DevStack for the stable Folsom branch on an instance:"" msgstr ""インスタンス上で、Folsom の安定版用の DevStack を動作させるためには："" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml61(para) msgid """" ""Boot an instance from the Dashboard or the nova command-line interface (CLI)"" "" with the following parameters."" msgstr ""ダッシュボード、または nova のコマンドラインインタフェース(CLI)から、以下のパラメータでインスタンスを起動してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml66(para) msgid ""Name: devstack"" msgstr ""名前: devstack"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml69(para) msgid ""Image: Ubuntu 12.04 LTS"" msgstr ""イメージ: Ubuntu 12.04 LTS"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml72(para) msgid ""Memory Size: 4 GB RAM (you could probably get away with 2 GB)"" msgstr ""メモリサイズ: 4 GB RAM (おそらく 2 GB でもなんとかなるでしょう)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml76(para) msgid ""Disk Size: minimum 5 GB"" msgstr ""ディスクサイズ: 最低 5 GB"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml79(para) msgid """" ""If you are using the <code>nova</code> client, specify <code>--flavor "" ""6</code> on the <code>nova boot</code> command to get adequate memory and "" ""disk sizes."" msgstr ""<code>nova</code> コマンドを使っているのであれば、適切なメモリ量とディスクサイズを得るために <code>nova boot</code> コマンドに <code>--flavor 6</code> を指定してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml85(para) msgid """" ""If your images have only a root user, you must create a \""stack\"" user. "" ""Otherwise you run into permission issues with screen if you let "" ""<code>stack.sh</code> create the \""stack\"" user for you. If your images "" ""already have a user other than root, you can skip this step."" msgstr ""利用するイメージで root ユーザしか使えない場合、stack ユーザを作成しなければなりません。でなければ、<code>stack.sh</code> スクリプトに stack ユーザを作成させる時に、screen に関するパーミッションの問題にぶつかります。利用するイメージに、既に root 以外のユーザがあるのであれば、このステップは省略できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml104(para) msgid ""Enter a new password at the prompt."" msgstr ""プロンプトに対して新しいパスワードを入力します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml137(para) msgid ""Now login as the stack user and set up DevStack."" msgstr ""stack ユーザとしてログインし、DevStack の設定を行います。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml146(para) msgid """" ""At the prompt, enter the password that you created for the stack user. "" msgstr ""プロンプトに対して、stack ユーザに作ったパスワードを入力します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml176(para) msgid """" ""For Swift only, used in the <emphasis role=\""bold\"">Middleware "" ""Example</emphasis>, see the example <emphasis role=\""bold\"">[1] Swift only "" ""localrc</emphasis> below"" msgstr ""Swift のみ、<emphasis role=\""bold\"">ミドルウェア例</emphasis> で使用された, 以下の <emphasis role=\""bold\"">[1] Swift only localrc</emphasis> の例を参照してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml184(para) msgid """" ""For all other projects, used in the <emphasis role=\""bold\"">Nova Scheduler "" ""Example</emphasis>, see the example <emphasis role=\""bold\"">[2] All other "" ""projects localrc</emphasis> below"" msgstr ""他のすべてのプロジェクトについて、 <emphasis role=\""bold\"">Nova Scheduler Example</emphasis> で使用された, 以下の <emphasis role=\""bold\"">[2] All other projects localrc</emphasis> の例を参照してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml199(para) msgid ""<placeholder-1/> "" msgstr ""<placeholder-1/> "" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml206(para) msgid """" ""The <code>stack.sh</code> script takes a while to run. Perhaps take this "" ""opportunity to <link xlink:href=\""http://www.openstack.org/join/\"">join the "" ""OpenStack foundation</link> (http://www.openstack.org/join/)."" msgstr ""<code>stack.sh</code> の実行には、しばらく時間がかかります。できれば、この時間を使って <link xlink:href=\""http://www.openstack.org/join/\"">OpenStack ファウンデーションに参加</link>してください (http://www.openstack.org/join/)。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml215(para) msgid """" ""When you run <code>stack.sh</code>, you might see an error message that "" ""reads “ERROR: at least one RPC back-end must be enabled”. Don’t worry about "" ""it; swift and keystone do not need an RPC (AMQP) back-end. You can also "" ""ignore any <code>ImportErrors</code>."" msgstr ""<code>stack.sh</code> を実行する際、“ERROR: at least one RPC back-end must be enabled” というエラーメッセージが出るかもしれません。これは心配しないでください。swift と keystone はRPC (AMQP) バックエンドを必要としないのです。同様に、<code>ImportErrors</code> はすべて無視できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml226(para) msgid """" ""Screen is a useful program for viewing many related services at once. For "" ""more information, see <link "" ""xlink:href=\""http://aperiodic.net/screen/quick_reference\"">GNU screen quick "" ""reference</link>. (http://aperiodic.net/screen/quick_reference)"" msgstr ""Screen は、多くの関連するサービスを同時に見るための便利なプログラムです。<link xlink:href=\""http://aperiodic.net/screen/quick_reference\"">GNU screen quick reference</link>. (http://aperiodic.net/screen/quick_reference) を参照してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml239(para) msgid """" ""Now that you have an OpenStack development environment, you're free to hack "" ""around without worrying about damaging your production deployment. Proceed "" ""to either the <emphasis role=\""bold\"">Middleware Example</emphasis> for a "" ""Swift-only environment, or the <emphasis role=\""bold\"">Nova Scheduler "" ""Example</emphasis> for all other projects."" msgstr ""以上で OpenStack の開発環境を準備できましたので、運用環境にダメージを与えることを心配せずに自由にハックできます。Swift のみの環境では <emphasis role=\""bold\"">ミドルウェア例</emphasis> に、‘他のすべてのプロジェクトでは <emphasis role=\""bold\"">Nova Scheduler Example</emphasis> に進んでください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml248(emphasis) msgid ""[1] Swift only localrc"" msgstr ""[1] Swift only localrc"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml262(glossterm) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml161(glossterm) msgid ""account"" msgstr ""アカウント"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml262(glossterm) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2775(glossterm) msgid ""token"" msgstr ""トークン"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml270(emphasis) msgid ""[2] All other projects localrc"" msgstr ""[2] All other projects localrc"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml302(title) msgid ""Middleware Example"" msgstr ""ミドルウェア例"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml303(para) msgid """" ""Most OpenStack projects are based on the Python <link "" ""xlink:href=\""http://pythonpaste.org/\"">Paste</link>(http://pythonpaste.org/) "" ""framework. The best introduction to its architecture is <link "" ""xlink:href=\""http://pythonpaste.org/do-it-yourself-framework.html\"">A Do-It-"" ""Yourself Framework</link> (http://pythonpaste.org/do-it-yourself-"" ""framework.html). Due to the use of this framework, you are able to add "" ""features to a project by placing some custom code in a project's pipeline "" ""without having to change any of the core code."" msgstr ""ほとんどの OpenStack プロジェクトは Python <link xlink:href=\""http://pythonpaste.org/\"">Paste</link>(http://pythonpaste.org/) フレームワークに基づいています。<link xlink:href=\""http://pythonpaste.org/do-it-yourself-framework.html\"">A Do-It-Yourself Framework</link> (http://pythonpaste.org/do-it-yourself-framework.html) は、このアーキテクチャの最良の紹介です。このフレームワークを使っているため、コードに一切手をいれずに、プロジェクトの処理パイプラインになんらかのカスタム・コードを入れて機能追加を行うことができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml314(para) msgid """" ""To demonstrate customizing OpenStack like this, we'll create a piece of "" ""middleware for swift that allows access to a container from only a set of IP"" "" addresses, as determined by the container's metadata items. Such an example"" "" could be useful in many contexts. For example, you might have public access"" "" to one of your containers, but what you really want to restrict it to is a "" ""set of IPs based on a whitelist."" msgstr ""このように OpenStack をカスタマイズすることを説明するため、Swift 用に、あるコンテナに対して、そのコンテナのメタデータで指定される一群のIPアドレスのみからアクセスできるようにするミドルウェアを作成してみます。このような例は多くの状況で有用です。例えば、一般アクセス可能なコンテナを持っていますが、実際に行いたいことはホワイトリストに基づいた一群のIPアドレスにのみ制限したい場合です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml323(para) msgid """" ""This example is for illustrative purposes only. It should not be used as a "" ""container IP whitelist solution without further development and extensive "" ""security testing."" msgstr ""この例は実証目的のみのためにあります。さらなる作りこみと広範なセキュリティテストなしにコンテナのIPホワイトリスト・ソリューションとして使用するべきではありません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml328(para) msgid """" ""When you join the screen session that <code>stack.sh</code> starts with "" ""<code>screen -r stack</code>, you're greeted with three screens if you used "" ""the localrc file with just Swift installed."" msgstr ""<code>stack.sh</code> が <code>screen -r stack</code> で作成したセッションに join すると、Swift インストール用の localrc を使ったのであれば、3つの screen セッションが見えます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml333(para) msgid ""The asterisk * indicates which screen you are on."" msgstr ""* (アスタリスク)は、どの screen にいるのかを示します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml336(para) msgid """" ""<emphasis role=\""bold\""><code>0$ shell</code></emphasis>. A shell where you "" ""can get some work done."" msgstr ""<emphasis role=\""bold\""><code>0$ shell</code></emphasis>. 何か作業することができる shell セッションです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml343(para) msgid """" ""<emphasis role=\""bold\""><code>1$ key</code></emphasis>. The keystone "" ""service."" msgstr ""<emphasis role=\""bold\""><code>1$ key</code></emphasis>. keystone サービス。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml349(para) msgid """" ""<emphasis role=\""bold\""><code>2$ swift</code></emphasis>. The swift proxy "" ""service."" msgstr ""<emphasis role=\""bold\""><code>2$ swift</code></emphasis>. swift プロキシサービス。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml356(title) msgid ""To create the middleware and plug it in through Paste configuration:"" msgstr ""ミドルウェアを作成して Paste の環境設定を通して組み込むためには："" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml360(para) msgid """" ""All of the code for OpenStack lives in <code>/opt/stack</code>. Go to the "" ""swift directory in the shell screen and edit your middleware module."" msgstr ""すべての OpenStack のコードは <code>/opt/stack</code> にあります。shell セッションの screen の中で swift ディレクトリに移動し、あなたのミドルウェアモジュールを編集してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml367(code) msgid ""cd /opt/stack/swift"" msgstr ""cd /opt/stack/swift"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml372(code) msgid ""vim swift/common/middleware/ip_whitelist.py"" msgstr ""vim swift/common/middleware/ip_whitelist.py"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml379(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml777(para) msgid ""Copy in the following code. When you're done, save and close the file."" msgstr ""以下のコードをコピーしてください。作業が終わったら、ファイルを保存して閉じてください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml472(para) msgid """" ""There is a lot of useful information in <code>env</code> and "" ""<code>conf</code> that you can use to decide what to do with the request. To"" "" find out more about what properties are available, you can insert the "" ""following log statement into the <code>__init__</code> method"" msgstr ""<code>env</code> と <code>conf</code> には、リクエストについて何をするのか判断するのに使える有用な情報が多数含まれています。どんなプロパティが利用可能なのかを知るには、以下のログ出力文を <code>__init__</code> メソッドに挿入してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml480(para) msgid ""and the following log statement into the <code>__call__</code> method"" msgstr ""そして以下のログ出力分を <code>__call__</code> メソッドに挿入してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml485(para) msgid """" ""To plug this middleware into the Swift pipeline you'll need to edit one "" ""configuration file."" msgstr ""このミドルウェアを Swift のパイプラインに組み込むには、設定ファイルを1つ編集する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml490(para) msgid """" ""Find the <code>[filter:ratelimit]</code> section and copy in the following "" ""configuration section."" msgstr ""<code>[filter:ratelimit]</code> セクションを探し、以下の環境定義セクションを貼り付けてください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml504(para) msgid """" ""Find the <code>[pipeline:main]</code> section and add "" ""<code>ip_whitelist</code> to the list like so. When you're done, save and "" ""close the file."" msgstr ""<code>[pipeline:main]</code> セクションを探し、このように <code>ip_whitelist</code> リストを追加してください。完了したら、ファイルを保存して閉じてください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml512(para) msgid """" ""Restart the Swift Proxy service to make Swift use your middleware. Start by "" ""switching to the swift screen."" msgstr ""Swift にこのミドルウェアを使わせるために、Swift プロキシサービスを再起動します。swift の screen セッションに切り替えてはじめてください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml517(para) msgid """" ""Press Ctrl-A followed by pressing 2, where 2 is the label of the screen. You"" "" can also press Ctrl-A followed by pressing n to go to the next screen."" msgstr ""Ctrl-A の後で 2 を押します。ここで、2 は screen セッションのラベルです。Ctrl-A の後で n を押し、次の screen セッションに切り替えることもできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml523(para) msgid ""Press Ctrl-C to kill the service."" msgstr ""Ctrl-C を押し、サービスを終了させます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml526(para) msgid ""Press Up Arrow to bring up the last command."" msgstr ""上矢印キーを押し、最後のコマンドを表示させます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml530(para) msgid ""Press Enter to run it."" msgstr ""Enter キーを押し、実行します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml535(para) msgid """" ""Test your middleware with the Swift CLI. Start by switching to the shell "" ""screen and finish by switching back to the swift screen to check the log "" ""output."" msgstr ""Swift の CLI でミドルウェアのテストをしてください。shell の screen セッションに切り替えてテストを開始し、swift の screen セッションにもどってログ出力をチェックして終了します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml541(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml937(para) msgid ""Press Ctrl-A followed by pressing 0"" msgstr ""Ctrl-A の後で 0 を押します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml546(code) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml942(code) msgid ""cd ~/devstack"" msgstr ""cd ~/devstack"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml551(code) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml947(code) msgid ""source openrc"" msgstr ""source openrc"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml556(code) msgid ""swift post middleware-test"" msgstr ""swift post middleware-test"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml560(para) msgid ""Press Ctrl-A followed by pressing 2"" msgstr ""Ctrl-A の後で 2 を押します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml566(para) msgid ""Among the log statements you'll see the lines."" msgstr ""ログの中に以下の行があるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml571(para) msgid """" ""The first three statements basically have to do with the fact that "" ""middleware doesn't need to re-authenticate when it interacts with other "" ""Swift services. The last 2 statements are produced by our middleware and "" ""show that the request was sent from our DevStack instance and was allowed."" msgstr ""基本的に、最初の３行はこのミドルウェアが Swift の他のサービスとやりとりする際に、再度認証を行う必要がないことを示しています。最後の２行は、このミドルウェアによって出力されており、リクエストが DevStack インスタンスから送られており、許可されていることを示しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml579(para) msgid """" ""Test the middleware from outside of DevStack on a remote machine that has "" ""access to your DevStack instance."" msgstr "" DevStack 環境の外の、DevStack 用インスタンスにアクセス可能なリモートマシンからミドルウェアをテストします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml585(code) msgid """" ""swift --os-auth-url=http://203.0.113.68:5000/v2.0/ --os-region-"" ""name=RegionOne --os-username=demo:demo --os-password=devstack list "" ""middleware-test"" msgstr ""swift --os-auth-url=http://203.0.113.68:5000/v2.0/ --os-region-name=RegionOne --os-username=demo:demo --os-password=devstack list middleware-test"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml594(para) msgid """" ""Container GET failed: http://203.0.113.68:8080/v1/AUTH_.../middleware-"" ""test?format=json 403 Forbidden You shall not pass!"" msgstr ""Container GET failed: http://203.0.113.68:8080/v1/AUTH_.../middleware-test?format=json 403 Forbidden You shall not pass!"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml601(para) msgid """" ""Check the Swift log statements again and among the log statements you'll see"" "" the lines."" msgstr ""再び Swift のログをチェックすると、以下の行が見つかるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml609(para) msgid """" ""Here we can see that the request was denied because the remote IP address "" ""wasn't in the set of allowed IPs."" msgstr ""ここで、リモートIPアドレスが、許可されたIPアドレスの中になかったため、リクエストが拒否されていることがわかります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml614(para) msgid """" ""Back on your DevStack instance add some metadata to your container to allow "" ""the request from the remote machine."" msgstr ""DevStack用インスタンスに戻り、リモートマシンからのリクエストを許可するようなコンテナのメタデータを追加します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml619(para) msgid ""Press Ctrl-A followed by pressing 0"" msgstr ""Ctrl-A の後で 0 を押します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml623(code) msgid ""swift post --meta allow-dev:198.51.100.12 middleware-test"" msgstr ""swift post --meta allow-dev:198.51.100.12 middleware-test"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml631(para) msgid """" ""Now try the command from <xref linkend=\""test_middleware_step\""/> again and "" ""it succeeds."" msgstr ""<xref linkend=\""test_middleware_step\""/> に記載したコマンドをもう一度試すと、今度は成功します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml636(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml979(para) msgid """" ""Functional testing like this is not a replacement for proper unit and "" ""integration testing but it serves to get you started."" msgstr ""このような機能試験は、正しいユニットテストと結合テストの代わりになるものではありませんが、作業を開始することはできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml639(para) msgid """" ""A similar pattern can be followed in all other projects that use the Python "" ""Paste framework. Simply create a middleware module and plug it in through "" ""configuration. The middleware runs in sequence as part of that project's "" ""pipeline and can call out to other services as necessary. No project core "" ""code is touched. Look for a <code>pipeline</code> value in the project's "" ""<code>conf</code> or <code>ini</code> configuration files in "" ""<code>/etc/&lt;project&gt;</code> to identify projects that use Paste."" msgstr ""Python Paste フレームワークを使う他のすべてのプロジェクトで、類似のパターンに従うことができます。単純にミドルウェアモジュールを作成し、環境定義によって組み込んでください。そのミドルウェアはプロジェクトのパイプラインの一部として順番に実行され、必要に応じて他のサービスを呼び出します。プロジェクトのコア・コードは一切修正しません。Paste を使っているプロジェクトを確認するには、<code>/etc/&lt;project&gt;</code> に格納されている、プロジェクトの <code>conf</code> または <code>ini</code> 環境定義ファイルの中で <code>pipeline</code> 変数を探してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml649(para) msgid """" ""When your middleware is done, we encourage you to open source it and let the"" "" community know on the OpenStack mailing list. Perhaps others need the same "" ""functionality. They can use your code, provide feedback, and possibly "" ""contribute. If enough support exists for it, perhaps you can propose that it"" "" be added to the official Swift <link "" ""xlink:href=\""https://github.com/openstack/swift/tree/master/swift/common/middleware\"">middleware</link>"" "" (https://github.com/openstack/swift/tree/master/swift/common/middleware)."" msgstr ""あなたのミドルウェアが完成したら、オープンソースにし、OpenStack メーリングリストでコミュニティに知らせることを薦めます。コミュニティの人々はあなたのコードを使い、フィードバックし、おそらくコントリビュートするでしょう。もし十分な支持があれば、公式なSwift <link xlink:href=\""https://github.com/openstack/swift/tree/master/swift/common/middleware\"">ミドルウェア</link> (https://github.com/openstack/swift/tree/master/swift/common/middleware) に追加するように提案することもできるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml660(title) msgid ""Nova Scheduler Example"" msgstr ""Nova スケジューラーの例"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml661(para) msgid """" ""Many OpenStack projects allow for customization of specific features using a"" "" driver architecture. You can write a driver that conforms to a particular "" ""interface and plug it in through configuration. For example, you can easily "" ""plug in a new scheduler for nova. The existing schedulers for nova are "" ""feature full and well documented at <link "" ""xlink:href=\""http://docs.openstack.org/folsom/openstack-"" ""compute/admin/content/ch_scheduling.html\"">Scheduling</link> "" ""(http://docs.openstack.org/folsom/openstack-"" ""compute/admin/content/ch_scheduling.html). However, depending on your user's"" "" use cases, the existing schedulers might not meet your requirements. You "" ""might need to create a new scheduler."" msgstr ""多くの OpenStack のプロジェクトでは、ドライバ・アーキテクチャを使うことによって、特定の機能をカスタマイズすることができます。特定のインターフェースに適合するドライバを書き、環境定義によって組み込むことができます。例えば、簡単に nova に新しいスケジューラーを組み込むことができます。nova の既存のスケジューラーは、フル機能であり、<link xlink:href=\""http://docs.openstack.org/folsom/openstack-compute/admin/content/ch_scheduling.html\"">スケジューリング</link> (http://docs.openstack.org/folsom/openstack-compute/admin/content/ch_scheduling.html) によくドキュメントされています。しかし、あなたのユーザのユース・ケースに依存して、既存のスケジューラで要件が満たせないかもしれません。この場合は、新しいスケジューラーを作成する必要があるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml674(para) msgid """" ""To create a scheduler you must inherit from the class "" ""<code>nova.scheduler.driver.Scheduler</code>. Of the five methods that you "" ""can override, you <emphasis>must</emphasis> override the two methods "" ""indicated with a \""*\"" below."" msgstr ""スケジューラーを作成するには、<code>nova.scheduler.driver.Scheduler</code> クラスを継承しなければなりません。オーバーライド可能な５つのメソッドのうち、以下の \""*\"" で示される２つのメソッドをオーバーライド<emphasis>しなければなりません</emphasis>。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml682(code) msgid ""update_service_capabilities"" msgstr ""update_service_capabilities"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml687(code) msgid ""hosts_up"" msgstr ""hosts_up"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml692(code) msgid ""schedule_live_migration"" msgstr ""schedule_live_migration"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml696(para) msgid ""* <code>schedule_prep_resize</code>"" msgstr ""* <code>schedule_prep_resize</code>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml700(para) msgid ""* <code>schedule_run_instance</code>"" msgstr ""* <code>schedule_run_instance</code>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml704(para) msgid """" ""To demonstrate customizing OpenStack, we'll create an example of a nova "" ""scheduler that randomly places an instance on a subset of hosts depending on"" "" the originating IP address of the request and the prefix of the hostname. "" ""Such an example could be useful when you have a group of users on a subnet "" ""and you want all of their instances to start within some subset of your "" ""hosts."" msgstr ""OpenStack のカスタマイズをデモするために、リクエストの送信元IPアドレスとホスト名のプレフィックスに基づいてインスタンスを一部のホストにランダムに配置するようなNova のスケジューラーの例を作成します。この例は、１つのユーザのグループが１つのサブネットにおり、インスタンスをホスト群の中の一部のサブネットで起動したい場合に有用です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml712(para) msgid """" ""This example is for illustrative purposes only. It should not be used as a "" ""scheduler for Nova without further development and testing."" msgstr ""この例は実証目的のみのためにあります。さらなる作りこみと広範なテストなしにNovaのスケジューラーとして使用するべきではありません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml716(para) msgid """" ""When you join the screen session that <code>stack.sh</code> starts with "" ""<code>screen -r stack</code>, you are greeted with many screens."" msgstr ""<code>stack.sh</code> が <code>screen -r stack</code> で作成したセッションに join すると、多数の screen セッションが見えます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml723(para) msgid """" ""<emphasis role=\""bold\""><code>shell</code></emphasis>. A shell where you can"" "" get some work done."" msgstr ""<emphasis role=\""bold\""><code>0$ shell</code></emphasis>. 何か作業することができる shell セッションです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml730(para) msgid ""<emphasis role=\""bold\""><code>key</code></emphasis>. The keystone service."" msgstr ""<emphasis role=\""bold\""><code>1$ key</code></emphasis>. keystone サービス。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml736(para) msgid ""<emphasis role=\""bold\""><code>g-*</code></emphasis>. The glance services."" msgstr ""<emphasis role=\""bold\""><code>g-*</code></emphasis>. glance サービス。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml742(para) msgid ""<emphasis role=\""bold\""><code>n-*</code></emphasis>. The nova services."" msgstr ""<emphasis role=\""bold\""><code>n-*</code></emphasis>. nova サービス。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml748(para) msgid """" ""<emphasis role=\""bold\""><code>n-sch</code></emphasis>. The nova scheduler "" ""service."" msgstr ""<emphasis role=\""bold\""><code>n-sch</code></emphasis>。nova スケジューラーサービス。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml756(title) msgid ""To create the scheduler and plug it in through configuration:"" msgstr ""スケジューラーを作成して、設定を通して組み込むためには："" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml760(para) msgid """" ""The code for OpenStack lives in <code>/opt/stack</code> so go to the nova "" ""directory and edit your scheduler module."" msgstr ""OpenStack のコードは <code>/opt/stack</code> にあるので、nova ディレクトリに移動してあなたのスケジューラーモジュールを編集します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml766(code) msgid ""cd /opt/stack/nova"" msgstr ""cd /opt/stack/nova"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml771(code) msgid ""vim nova/scheduler/ip_scheduler.py"" msgstr ""vim nova/scheduler/ip_scheduler.py"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml888(para) msgid """" ""There is a lot of useful information in <code>context</code>, "" ""<code>request_spec</code>, and <code>filter_properties</code> that you can "" ""use to decide where to schedule the instance. To find out more about what "" ""properties are available you can insert the following log statements into "" ""the <code>schedule_run_instance</code> method of the scheduler above."" msgstr "" <code>context</code> と <code>request_spec</code> と <code>filter_properties</code>には、どこにインスタンスをスケジュールするのか決定するのに使える有用な情報が多数含まれています。どんなプロパティが利用可能なのかを知るには、以下のログ出力文を上記の <code>schedule_run_instance</code> メソッドに挿入してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml900(para) msgid """" ""To plug this scheduler into Nova you'll need to edit one configuration file."" msgstr ""このスケジューラーを Nova に組み込むには、設定ファイルを1つ編集する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml905(para) msgid """" ""Find the <code>compute_scheduler_driver</code> config and change it like so."" msgstr ""<code>compute_scheduler_driver</code> 設定を見つけ、このように変更してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml910(para) msgid """" ""Restart the Nova scheduler service to make Nova use your scheduler. Start by"" "" switching to the <code>n-sch</code> screen."" msgstr ""Nova にこのスケジューラーを使わせるために、Nova スケジューラーサービスを再起動します。 <code>n-sch</code> screen セッションに切り替えてはじめてください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml915(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml964(para) msgid ""Press Ctrl-A followed by pressing 8"" msgstr ""Ctrl-A の後で 8 を押します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml919(para) msgid ""Press Ctrl-C to kill the service"" msgstr ""Ctrl-C を押し、サービスを終了させます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml922(para) msgid ""Press Up Arrow to bring up the last command"" msgstr ""上矢印キーを押し、最後のコマンドを表示させます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml926(para) msgid ""Press Enter to run it"" msgstr ""Enter キーを押し、実行します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml931(para) msgid """" ""Test your scheduler with the Nova CLI. Start by switching to the shell "" ""screen and finish by switching back to the <code>n-sch</code> screen to "" ""check the log output."" msgstr ""Nova の CLI でスケジューラーのテストをしてください。shell の screen セッションに切り替えてテストを開始し、<code>n-sch</code> screen セッションにもどってログ出力をチェックして終了します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml952(code) msgid """" ""IMAGE_ID=`nova image-list | egrep cirros | egrep -v \""kernel|ramdisk\"" | awk"" "" '{print $2}'`"" msgstr ""IMAGE_ID=`nova image-list | egrep cirros | egrep -v \""kernel|ramdisk\"" | awk '{print $2}'`"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml959(code) msgid ""nova boot --flavor 1 --image $IMAGE_ID scheduler-test"" msgstr ""nova boot --flavor 1 --image $IMAGE_ID scheduler-test"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml970(para) msgid ""Among the log statements you'll see the line."" msgstr ""ログの中に以下の行があるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml982(para) msgid """" ""A similar pattern can be followed in all other projects that use the driver "" ""architecture. Simply create a module and class that conform to the driver "" ""interface and plug it in through configuration. Your code runs when that "" ""feature is used and can call out to other services as necessary. No project "" ""core code is touched. Look for a \""driver\"" value in the project's conf "" ""configuration files in <code>/etc/&lt;project&gt;</code> to identify "" ""projects that use a driver architecture."" msgstr ""ドライバ・アーキテクチャを使う他のすべてのプロジェクトで、類似のパターンに従うことができます。単純に、そのドライバ・インタフェースに従うモジュールとクラスを作成し、環境定義によって組み込んでください。あなたのコードはその機能が使われた時に実行され、必要に応じて他のサービスを呼び出します。プロジェクトのコア・コードは一切修正しません。ドライバ・アーキテクチャを使っているプロジェクトを確認するには、<code>/etc/&lt;project&gt;</code> に格納されている、プロジェクトの環境定義ファイルの中で <code>driver</code> 変数を探してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml991(para) msgid """" ""When your scheduler is done, we encourage you to open source it and let the "" ""community know on the OpenStack mailing list. Perhaps others need the same "" ""functionality. They can use your code, provide feedback, and possibly "" ""contribute. If enough support exists for it, perhaps you can propose that it"" "" be added to the official Nova <link "" ""xlink:href=\""https://github.com/openstack/nova/tree/master/nova/scheduler\"">schedulers</link>"" "" (https://github.com/openstack/nova/tree/master/nova/scheduler)."" msgstr ""あなたのスケジューラーが完成したら、オープンソースにし、OpenStack メーリングリストでコミュニティに知らせることをお薦めします。もしかしたら他の人も同じ機能を必要としているかもしれません。彼らはあなたのコードを使い、フィードバックし、おそらくコントリビュートするでしょう。もし十分な支持があれば、もしかしたら公式なNova <link xlink:href=\""https://github.com/openstack/nova/tree/master/nova/scheduler\"">スケジューラー</link> (https://github.com/openstack/nova/tree/master/nova/scheduler) への追加を提案してもよいでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml1001(title) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml381(title) msgid ""Dashboard"" msgstr ""ダッシュボード"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_customize.xml1002(para) msgid """" ""The Dashboard is based on the Python <link "" ""xlink:href=\""https://www.djangoproject.com/\"">Django</link> "" ""(https://www.djangoproject.com/) web application framework. The best guide "" ""to customizing it has already been written and can be found at <link "" ""xlink:href=\""http://docs.openstack.org/developer/horizon/topics/tutorial.html\"">Build"" "" on Horizon</link> "" ""(http://docs.openstack.org/developer/horizon/topics/tutorial.html)."" msgstr ""ダッシュボードは、Python <link xlink:href=\""https://www.djangoproject.com/\"">Django</link> (https://www.djangoproject.com/) Webアプリケーションフレームワークに基づいています。カスタマイズのための最良のガイドは既に執筆されており、 <link xlink:href=\""http://docs.openstack.org/developer/horizon/topics/tutorial.html\"">Build on Horizon</link> (http://docs.openstack.org/developer/horizon/topics/tutorial.html) にあります。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml274(None) msgid """" ""@@image: 'figures/os-ref-arch.png'; md5=d14dd97ceaea1a78af7f292c5d6bd605"" msgstr ""@@image: 'figures/os-ref-arch.png'; md5=d14dd97ceaea1a78af7f292c5d6bd605"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml313(None) msgid """" ""@@image: 'figures/os_physical_network_1.png'; "" ""md5=9f2bb38fdeb722bb06baca74fc91d03e"" msgstr ""@@image: 'figures/os_physical_network_1.png'; md5=9f2bb38fdeb722bb06baca74fc91d03e"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml15(title) msgid ""Example Architecture"" msgstr ""参考アーキテクチャ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml16(para) msgid """" ""Because OpenStack is highly configurable, with many different <glossterm"" "">back-ends</glossterm> and network configuration options, it is difficult to"" "" write documentation that covers all possible OpenStack deployments. "" ""Therefore, this guide defines an <emphasis>example architecture</emphasis> "" ""to simplify the task of documenting, as well as to scope this guide so that "" ""it is focused on a configuration where the authors have direct deployment "" ""experience."" msgstr ""OpenStack は設定の自由度が高く、多くの異なる<glossterm>バックエンド</glossterm>とネットワーク設定オプションがあり、考えられる OpenStack の構成をすべて網羅するドキュメントを作成するのは困難です。そのため、このガイドでは<emphasis>参考アーキテクチャ</emphasis>を定義することで、このガイドの説明範囲を明確にするとともに、ドキュメント作成を単純化しています。こうすることで、、著者らが実際に経験したことのある構成での設定に焦点を当てることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml26(title) msgid ""Overview"" msgstr ""概要"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml32(para) msgid ""OpenStack release"" msgstr ""OpenStack リリース"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml36(para) msgid ""Host operating system"" msgstr ""ホストのオペレーティングシステム"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml37(para) msgid ""Ubuntu 12.04 LTS"" msgstr ""Ubuntu 12.04 LTS"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml40(para) msgid ""OpenStack package repository"" msgstr ""OpenStack パッケージリポジトリ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml41(para) msgid """" ""<link xlink:href=\""https://wiki.ubuntu.com/ServerTeam/CloudArchive\"">Ubuntu Cloud "" ""Archive</link> (https://wiki.ubuntu.com/ServerTeam/CloudArchive) *"" msgstr ""<link xlink:href=\""https://wiki.ubuntu.com/ServerTeam/CloudArchive\"">Ubuntu Cloud Archive</link> (https://wiki.ubuntu.com/ServerTeam/CloudArchive) *"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml48(para) msgid ""Hypervisor"" msgstr ""ハイパーバイザー"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml49(para) msgid ""KVM"" msgstr ""KVM"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml52(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml247(title) msgid ""Database"" msgstr ""データベース"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml53(para) msgid ""MySQL*"" msgstr ""MySQL*"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml56(para) msgid ""Message queue"" msgstr ""メッセージキュー"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml57(para) msgid ""RabbitMQ"" msgstr ""RabbitMQ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml60(para) msgid ""Networking service"" msgstr ""ネットワークサービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml61(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1961(glossterm) msgid ""nova-network"" msgstr ""nova-network"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml64(para) msgid ""Network manager"" msgstr ""ネットワークマネージャー"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml68(para) msgid ""Single nova-network or multi-host?"" msgstr ""nova-network がシングルホストかマルチホストか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml70(para) msgid ""multi-host*"" msgstr ""マルチホスト*"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml73(para) msgid ""Image Service (glance) back-end"" msgstr ""Image Service (glance) のバックエンド"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml75(para) msgid ""file"" msgstr ""file"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml78(para) msgid ""Identity Service (keystone) driver"" msgstr ""Identity Service (keystone) のドライバー"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml80(para) msgid ""SQL"" msgstr ""SQL"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml83(para) msgid ""Block Storage Service (cinder) back-end"" msgstr ""Block Storage Service (cinder) のバックエンド"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml85(para) msgid ""LVM/iSCSI"" msgstr ""LVM/iSCSI"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml88(para) msgid ""Live Migration back-end"" msgstr ""ライブマイグレーションのバックエンド"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml89(para) msgid ""shared storage using NFS *"" msgstr ""NFS を使った共有ストレージ *"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml92(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml36(th) msgid ""Object storage"" msgstr ""オブジェクトストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml93(para) msgid ""OpenStack Object Storage (swift)"" msgstr ""OpenStack Object Storage (swift)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml98(para) msgid """" ""An asterisk (*) indicates when the example architecture deviates from the "" ""settings of a default installation."" msgstr ""アスタリスク (*) は、参考アーキテクチャでの設定がデフォルトのインストールの設定とは違うことを示します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml107(glossterm) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml897(glossterm) msgid ""dashboard"" msgstr ""ダッシュボード"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml110(glossterm) msgid ""block storage"" msgstr ""ブロックストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml114(para) msgid ""<glossterm>floating IP address</glossterm>es"" msgstr ""<glossterm>フローティング IP アドレス</glossterm>"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml118(glossterm) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1777(glossterm) msgid ""live migration"" msgstr ""ライブマイグレーション"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml122(glossterm) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2038(glossterm) msgid ""object storage"" msgstr ""オブジェクトストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml103(para) msgid """" ""The following features of OpenStack are supported by the example "" ""architecture documented in this guide, but are optional: <placeholder-1/>"" msgstr ""以下の OpenStack の機能がこのガイドの参考アーキテクチャではサポートされていますが、これらは必須項目ではありません。 <placeholder-1/>"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml130(title) msgid ""Rationale"" msgstr ""設定指針"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml131(para) msgid """" ""This example architecture has been selected based on the current default "" ""feature set of OpenStack <glossterm>Folsom</glossterm>, with an emphasis on "" ""stability. In particular, if none of the guide authors had experience "" ""deploying the Folsom release of OpenStack with a specific back-end or "" ""configuration, we did not consider it for the example architecture. We "" ""believe that many clouds that currently run OpenStack in production have "" ""made similar choices."" msgstr ""この参考アーキテクチャは、OpenStack <glossterm>Folsom</glossterm> の現在のデフォルト機能をベースとして、安定性を重視して選択されました。特に、 OpenStack Folsom リリースの構成で、この文書の著者の誰も使ったことがないバックエンドや設定については、この参考アーキテクチャでは取り上げないことにしました。きっと、現在本番環境で OpenStack を使っている多くのクラウドでは同様の選択がなされていることでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml140(para) msgid """" ""You must first choose the operating system that runs on all of the physical "" ""nodes. While OpenStack is supported on several distributions of Linux, we "" ""used <emphasis role=\""bold\"">Ubuntu 12.04 LTS (Long Term "" ""Support)</emphasis>, which is used by the majority of the development "" ""community, has feature completeness compared with other distributions, and "" ""has clear future support plans."" msgstr ""まず最初に、すべての物理ノードで動作させるオペレーティングシステムを選ばなければなりません。いくつかの Linux ディストリビューションが OpenStack をサポートしていますが、我々は <emphasis role=\""bold\"">Ubuntu 12.04 LTS (Long Term Support)</emphasis> を使うことにしました。 Ubuntu 12.04 LTS は開発コミュニティの大半の人が使っており、他のディストリビューションと比較して機能の完成度が高く、今後のサポート計画もはっきりしています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml148(para) msgid """" ""We recommend that you do not use the default Ubuntu OpenStack install "" ""packages and instead use the <link "" ""xlink:href=\""https://wiki.ubuntu.com/ServerTeam/CloudArchive\"">Ubuntu Cloud "" ""Archive</link> (https://wiki.ubuntu.com/ServerTeam/CloudArchive). The Cloud "" ""Archive is a package repository supported by Canonical that allows you to "" ""upgrade to future OpenStack releases while remaining on Ubuntu 12.04."" msgstr ""Ubuntu のデフォルトの OpenStack インストールパッケージではなく、<link xlink:href=\""https://wiki.ubuntu.com/ServerTeam/CloudArchive\"">Ubuntu Cloud Archive</link> (https://wiki.ubuntu.com/ServerTeam/CloudArchive) を使うことをお薦めします。Cloud Archive は Canonical がサポートしているパッケージレポジトリで、このレポジトリを使うことで Ubuntu 12.04 を使い続けながら新しい OpenStack リリースにアップグレードすることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml156(para) msgid """" ""<emphasis role=\""bold\"">KVM</emphasis> as a "" ""<glossterm>hypervisor</glossterm> complements the choice of Ubuntu - being a"" "" matched pair in terms of support, and also because of the significant "" ""degree of attention it garners from the OpenStack development community "" ""(including the authors, who mostly use KVM). It is also feature complete, "" ""free from licensing charges and restrictions."" msgstr ""Ubuntu を選択した場合、 <glossterm>ハイパーバイザー</glossterm> として <emphasis role=\""bold\"">KVM</emphasis> が最も適切です。サポートの観点ではぴったりの組み合わせであり、また (著者も含め) OpenStack の開発コミュニティからの関心も非常に高いからです。著者のほとんどが KVM を使っています。また、 KVM は機能が揃っていて、ライセンスの課金も制限もありません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml164(para) msgid """" ""<emphasis role=\""bold\"">MySQL</emphasis> follows a similar trend. Despite "" ""its recent change of ownership, this database is the most tested for use "" ""with OpenStack and is heavily documented for running on Ubuntu. We deviate "" ""from the default database, <emphasis>SQLite</emphasis>, because SQLite is "" ""not an appropriate database for production usage."" msgstr ""<emphasis role=\""bold\"">MySQL</emphasis> も同様の理由から選ばれました。最近開発元が変わりましたが、このデータベースは OpenStack との組み合わせで最もテストされており、 Ubuntu での動かし方についても非常によくドキュメントにまとまっています。デフォルトのデータベースである <emphasis>SQLite</emphasis> を使っていませんが、それは SQLite が本番環境での利用には適したデータベースではないからです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml171(para) msgid """" ""The choice of <emphasis role=\""bold\""> RabbitMQ</emphasis> over other AMQP "" ""compatible options that are gaining support in OpenStack, such as ZeroMQ and"" "" Qpid is due to its ease of use with Ubuntu and significant testing in "" ""production. It also is the only option which supports features such as "" ""Compute Cells. We recommend clustering with RabbitMQ, as it is an integral "" ""component of the system, and fairly simple to implement due to its inbuilt "" ""nature."" msgstr ""OpenStack では AMQP 互換の選択肢としては ZeroMQ や Qpid などのサポートが進んでいますが、 <emphasis role=\""bold\""> RabbitMQ</emphasis> を選んだのは、Ubuntu での使いやすさと、本番環境で十分にテストされているのが理由です。また、RabbitMQ は Compute Cell といった機能でサポートされている唯一の選択肢です。 RabbitMQ はクラスタ構成にすることを推奨します。それは、メッセージキューは OpenStack システムで不可欠のコンポーネントで、RabbitMQ 自体で元々サポートされているためかなり簡単に実現することができるからです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml180(para) msgid """" ""As discussed in previous chapters, there are several options for networking "" ""in OpenStack Compute. We recommend <emphasis "" ""role=\""bold\"">FlatDHCP</emphasis> and to use <emphasis role=\""bold\"">Multi-"" ""Host</emphasis> networking mode for high availability, running one <code"" "">nova-network</code> daemon per OpenStack Compute host. This provides a "" ""robust mechanism for ensuring network interruptions are isolated to "" ""individual compute hosts, and allows for the direct use of hardware network "" ""gateways."" msgstr ""前の章に議論したように、OpenStack Compute のネットワークにはいくつかの選択肢があります。我々は <emphasis role=\""bold\"">FlatDHCP</emphasis> を選択し、高可用性のために <emphasis role=\""bold\"">マルチホスト</emphasis> モードを使うことをお薦めします。マルチホストモードでは、<code>nova-network</code> デーモンを OpenStack Compute ホスト毎に一つ動作させます。この堅牢性のメカニズムでは、ネットワーク障害が各コンピュートホスト内に閉じることが保証され、各ホストがハードウェアのネットワークゲートウェイと直接通信できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml190(para) msgid """" ""<emphasis role=\""bold\"">Live Migration</emphasis> is supported by way of "" ""shared storage, with <emphasis role=\""bold\"">NFS</emphasis> as the "" ""distributed file system."" msgstr ""<emphasis role=\""bold\"">ライブマイグレーション</emphasis> は共有ストレージを使うことでサポートされます。分散ファイルシステムとして <emphasis role=\""bold\"">NFS</emphasis> を使います。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml194(para) msgid """" ""Acknowledging that many small-scale deployments see running an Object "" ""Storage service just for the storage of virtual machine images as too "" ""costly, we opted for the file back-end in the OpenStack Image Catalog and "" ""Delivery Service (Glance). If the cloud you are designing also intends to "" ""run Object Storage, it is trivial to enable this as the back-end instead, "" ""and a recommended approach."" msgstr ""多くの小規模の構成では Object Storage サービスを仮想マシンイメージのストレージのためだけに使うのはコストがかかることなので、OpenStack Image Service (Glance) のバックエンドとしてファイルバックエンドを選択しました。あなたが設計しているクラウドで Object Storage も動かすつもりであれば、代わりに Object Storage をバックエンドとして使うのは簡単なので、使用することを是非お薦めします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml203(para) msgid """" ""We chose the <emphasis role=\""bold\"">SQL back-end for Identity Service "" ""(keystone)</emphasis> over others, such as LDAP. This back-end is simple to "" ""install and is robust. The authors acknowledge that many installations want "" ""to bind with existing directory services, and caution careful understanding "" ""of the <link xlink:title=\""LDAP config options\"" "" ""xlink:href=\""http://docs.openstack.org/folsom/openstack-compute/admin/content"" ""/reference-for-ldap-config-options.html\"">array of options available</link> "" ""(http://docs.openstack.org/folsom/openstack-compute/admin/content/reference-"" ""for-ldap-config-options.html)"" msgstr ""<emphasis role=\""bold\"">Identity サービス (keystone)</emphasis> のバックエンドとして、LDAP などの他の選択肢ではなく <emphasis role=\""bold\"">SQL バックエンド</emphasis>を選択しました。 SQL バックエンドはインストールが簡単で、堅牢性があります。多くのシステムで既存のディレクトリサービスと接続したいという要望があることは理解しています。その場合は、<link xlink:title=\""LDAP config options\"" xlink:href=\""http://docs.openstack.org/folsom/openstack-compute/admin/content/reference-for-ldap-config-options.html\"">設定オプションリスト</link> (http://docs.openstack.org/folsom/openstack-compute/admin/content/reference-for-ldap-config-options.html) を注意深く理解してから使って下さい。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml213(para) msgid """" ""The Block Storage service (cinder) is installed natively on external storage"" "" nodes and uses the <emphasis role=\""bold\"">LVM/iSCSI plugin</emphasis>. "" ""Most Block Storage Service plugins are tied to particular vendor products "" ""and implementations limiting their use to consumers of those hardware "" ""platforms, but LVM/iSCSI is robust and stable on commodity hardware."" msgstr ""Block Storage サービス (cinder) は外部のストレージノードに直接インストールされ、<emphasis role=\""bold\"">LVM/iSCSI プラグイン</emphasis> を使用します。ほとんどの Block Storage サービスのプラグインは個々のベンダー製品や実装に依存しており、そのハードウェアプラットフォームを持っているユーザしか利用できませんが、 LVM/iSCSI は堅牢性と安定性があり、一般的なハードウェアで利用できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml220(para) msgid """" ""While the cloud can be run without the <emphasis role=\""bold\"">OpenStack "" ""Dashboard</emphasis>, we consider it to be indispensable, not just for user "" ""interaction with the cloud, but also as a tool for operators. Additionally, "" ""the dashboard's use of Django makes it a flexible framework for extension."" msgstr ""このクラウドは <emphasis role=\""bold\"">OpenStack ダッシュボード</emphasis> なしで動かすことはできますが、我々はダッシュボードを、クラウドのユーザ操作のためだけでなく、オペレータ向けのツールとしてもなくてはならないものと考えています。まだ、ダッシュボードは Django を使っているため拡張しやすい柔軟なフレームワークとなっています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml228(title) msgid ""Why Not Use the OpenStack Network Service (quantum)?"" msgstr ""なぜ OpenStack Networking Service (quantum) を使わないか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml230(para) msgid """" ""We do not discuss the OpenStack Network Service (quantum) in this guide, "" ""because the authors of this guide only have production deployment experience"" "" using <code>nova-network</code>. Additionally, it does not yet support "" ""multi-host networking."" msgstr ""我々はこのガイドで OpenStack Networking Service (quantum) について触れていません。それは、このガイドの著者達が <code>nova-network</code> を使った本番環境の経験しかないからです。それに加えて、quantum はまだマルチホストネットワークをサポートしていないことも理由の一つです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml237(title) msgid ""Why Use Multi-host Networking?"" msgstr ""なぜマルチホストネットワークを使うか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml238(para) msgid """" ""In a default OpenStack deployment, there is a single <code>nova-"" ""network</code> service that runs within the cloud (usually on the cloud "" ""controller) that provides services such as network address translation "" ""(NAT), DHCP, and DNS to the guest instances. If the single node that runs "" ""the <code>nova-network</code> service goes down, you cannot access your "" ""instances and the instances cannot access the Internet. The single node that"" "" runs the nova-network service can become a bottleneck if excessive network "" ""traffic comes in and goes out of the cloud."" msgstr ""デフォルトの OpenStack の構成では、<code>nova-network</code> サービスはクラウド内 (通常はクラウドコントローラー) で一つだけ動作し、ゲストインスタンスにネットワークアドレス変換 (NAT)、DHCP、DNS などのサービスを提供します。 <code>nova-network</code> サービスが動作している1台のノードがダウンすると、ユーザーはインスタンスにアクセスできなくなり、インスタンスはインターネットにアクセスできなくなります。クラウドで送受信されるネットワークトラフィックが多くなり過ぎると、nova-network サービスが動作する1台のノードがボトルネックになる可能性があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml249(para) msgid """" ""<link xlink:title=\""Multi-host\"" xlink:href=\""http://docs.openstack.org/folsom"" ""/openstack-compute/admin/content/existing-ha-networking-options.html#d6e8906"" ""\"">Multi-host</link> (http://docs.openstack.org/folsom/openstack-"" ""compute/admin/content/existing-ha-networking-options.html#d6e8906) is a "" ""high-availability option for the network configuration where the nova-"" ""network service is run on every compute node instead of running on only a "" ""single node."" msgstr ""<link xlink:title=\""Multi-host\"" xlink:href=\""http://docs.openstack.org/folsom/openstack-compute/admin/content/existing-ha-networking-options.html#d6e8906\"">マルチホスト</link> (http://docs.openstack.org/folsom/openstack-compute/admin/content/existing-ha-networking-options.html#d6e8906) は、ネットワーク設定の高可用性オプションで、 nova-network サービスを1台のノードだけで動かすのではなく、各コンピュートノードで動作させるものです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml262(title) msgid ""Detailed Description"" msgstr ""詳細な説明"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml263(para) msgid """" ""The reference architecture consists of multiple compute nodes, a cloud "" ""controller, an external NFS storage server for instance storage and an "" ""OpenStack Block Storage server for <glossterm>volume</glossterm> storage. A "" ""network time service (Network Time Protocol, NTP) synchronizes time for all "" ""the nodes. FlatDHCPManager in multi-host mode is used for the networking."" msgstr ""参考アーキテクチャは複数のコンピュートノード、クラウドコントローラー、インスタンスストレージ用の外部の NFS ストレージサーバー、<glossterm>ボリューム</glossterm> ストレージ用の OpenStack Block Storage サーバーで構成されています。ネットワーク時刻サービス (Network Time Protocol, NTP) により全ノードの時刻が同期されます。ネットワークでは、マルチホストモードの FlatDHCPManager を使用しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml278(para) msgid """" ""The cloud controller runs: the dashboard, the API services, the database "" ""(MySQL), a message queue server (RabbitMQ), the scheduler for choosing "" ""compute resources (nova-scheduler), Identity services (keystone, <code>nova-"" ""consoleauth</code>), Image services (<code>glance-api</code>, <code>glance-"" ""registry</code>), services for console access of guests, and block storage "" ""services including the scheduler for storage resources (<code>cinder-"" ""api</code> and <code>cinder-scheduler</code>)."" msgstr ""クラウドコントローラーでは、ダッシュボード、API サービス、データベース (MySQL)、メッセージキューサーバー (RabbitMQ)、コンピューティングリソースの選択を行うスケジューラー (nova-scheduler)、 Identity サービス (keystone, <code>nova-consoleauth</code>), Image Service (<code>glance-api</code>, <code>glance-registry</code>), ゲストへのコンソールアクセス用サービス、ストレージリソースのスケジューラーを含む Block Storage サービス(<code>cinder-api</code> と <code>cinder-scheduler</code>) が動作します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml289(para) msgid """" ""Compute nodes are where the computing resources are held, and in our example"" "" architecture they run the hypervisor (KVM), libvirt (the driver for the "" ""hypervisor, which enables live migration node to node), <code>nova-"" ""compute</code>, <code>nova-api-metadata</code> (generally only used when "" ""running in multi-host mode, it retrieves instance-specific metadata), nova-"" ""vncproxy, and <code>nova-network.</code>"" msgstr ""コンピュートノードはコンピューティングリソースを提供する場所です。この参考アーキテクチャでは、コンピュートノードで、ハイパーバイザー (KVM)、 libvirt (ハイパーバイザー用のドライバーで、ノード間でのライブマイグレーションを可能にします)、 <code>nova-compute</code>、 <code>nova-api-metadata</code> (通常はマルチホストモードの場合のみ使用されます。インスタンス固有のメタデータの取得に使われます)、 nova-vncproxy、 <code>nova-network</code> が動作します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml299(para) msgid """" ""The network consists of two switches, one for the management or private "" ""traffic, and one which covers public access including Floating IPs. To "" ""support this, the cloud controller and the compute nodes have two network "" ""cards. The OpenStack Block Storage and NFS storage servers only need to "" ""access the private network and therefore only need one network card, but "" ""multiple cards run in a bonded configuration are recommended if possible. "" ""Floating IP access is direct to the internet, whereas Flat IP access goes "" ""through a NAT."" msgstr ""ネットワークは2つのスイッチで構成され、一つは管理やプライベートトラフィック用で、もう一つはフローティングIPなどのパブリックアクセスに使用されます。この構成をとるため、クラウドコントローラーと各コンピュートノードにはNICを2つ用意しています。OpenStack Block Storage と NFS ストレージサーバーはプライベートネットワークだけにアクセスできればよく、そのため必要なNICは1つです。ただし、可能であれば複数のNICを bonding 設定で動作させることを推奨します。フローティング IP アクセスはインターネットと直結になりますが、フラット IP アクセスは NAT 経由となります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml320(title) msgid ""Optional Extensions"" msgstr ""さらなる拡張"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml321(para) msgid ""You can extend this reference architecture as follows:"" msgstr ""この参考アーキテクチャを以下のように拡張することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml325(para) msgid ""Add additional cloud controllers (see <xref linkend=\""maintenance\""/>)."" msgstr ""追加でクラウドコントローラーを増やす (<xref linkend=\""maintenance\""/> を参照)。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml329(para) msgid """" ""Add an OpenStack Storage service (http://docs.openstack.org/folsom"" ""/openstack-object-storage/admin/)"" msgstr ""OpenStack Storage サービスを追加する (http://docs.openstack.org/folsom/openstack-object-storage/admin/)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_example.xml333(para) msgid """" ""Add additional OpenStack Block Storage hosts (see <xref "" ""linkend=\""maintenance\""/>)."" msgstr ""追加で OpenStack Block Storage ホストを増やす (see <xref linkend=\""maintenance\""/> 参照)。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml53(None) msgid """" ""@@image: 'figures/network_packet_ping.png'; "" ""md5=3b1f2132f9133d2ce1960743a2d6c6a4"" msgstr ""@@image: 'figures/network_packet_ping.png'; md5=3b1f2132f9133d2ce1960743a2d6c6a4"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml16(title) msgid ""Network Troubleshooting"" msgstr ""ネットワークのトラブルシューティング"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml17(para) msgid """" ""Network troubleshooting can unfortunately be a very difficult and confusing "" ""procedure. A network issue can cause a problem at several points in the "" ""cloud. Using a logical troubleshooting procedure can help mitigate the "" ""confusion and more quickly isolate where exactly the network issue is. This "" ""chapter aims to give you the information you need to make yours."" msgstr ""ネットワークのトラブルシューティングは、残念ながら、非常に難しくややこしい作業です。ネットワークの問題は、クラウドのいくつかの場所で問題となりえます。論理的な問題解決手順を用いることは、混乱の緩和や迅速な切り分けに役立つでしょう。この章は、あなたがものにしたい情報を提供することを目標とします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml25(title) msgid ""Using \""ip a\"" to Check Interface States"" msgstr ""\""ip a\"" を使ってインタフェース状態をチェックする"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml26(para) msgid """" ""On compute nodes and nodes running nova-network, use the following command "" ""to see information about interfaces, including information about IPs, VLANs,"" "" and whether your interfaces are up."" msgstr ""コンピュートノード上でnova-networkが動いている場合、次のコマンドでIPやVLAN、また、インターフェイスがUPしているか、などインターフェイス関連の情報を見られます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml31(para) msgid """" ""If you're encountering any sort of networking difficulty, one good initial "" ""sanity check is to make sure that your interfaces are up. For example:"" msgstr ""もしあなたがネットワークの問題に直面した場合、まず最初にするとよいのは、インターフェイスがUPになっているかを確認することです。例えば、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml40(para) msgid """" ""You can safely ignore the state of virbr0, which is a default bridge created"" "" by QEMU and not used by OpenStack."" msgstr ""virbr0の状態は無視することができます。なぜならそれはlibvirtが作成するデフォルトのブリッジで、OpenStackからは使われないからです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml45(title) msgid ""Network Traffic in the Cloud"" msgstr ""クラウド上のネットワークトラフィック"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml46(para) msgid """" ""If you are logged in to an instance and ping an external host, for example "" ""google.com, the ping packet takes the following route:"" msgstr ""もしあなたがインスタンスにログインしており、外部ホスト、例えば google.comにpingした場合、そのpingパケットは下記経路を通ります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml59(para) msgid """" ""The instance generates a packet and places it on the virtual NIC inside the "" ""instance, such as, eth0."" msgstr ""インスタンスはパケットを生成し、インスタンス内の仮想NIC、例えば eth0にそれを渡します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml64(para) msgid """" ""The packet transfers to the virtual NIC of the compute host, such as, vnet1."" "" You can find out what vent NIC is being used by looking at the "" ""/etc/libvirt/qemu/instance-xxxxxxxx.xml file."" msgstr ""そのパケットはコンピュートホストの仮想NIC、例えば vnet1に転送されます。vnet NICの構成は、/etc/libvirt/qemu/instance-xxxxxxxx.xml を見ることで把握できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml71(para) msgid """" ""From the vnet NIC, the packet transfers to a bridge on the compute node, "" ""such as, <code>br100.</code>"" msgstr ""パケットはvnet NICからコンピュートノードのブリッジ、例えば<code>br100</code>に転送されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml75(para) msgid """" ""If you run FlatDHCPManager, one bridge is on the compute node. If you run "" ""VlanManager, one bridge exists for each VLAN."" msgstr ""もしFlatDHCPManagerを使っているのであれば、ブリッジはコンピュートノード上に一つです。VlanManagerであれば、VLANごとにブリッジが存在します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml78(para) msgid """" ""To see which bridge the packet will use, run the command: <placeholder-1/>"" msgstr ""下記コマンドを実行することで、パケットがどのブリッジを使うか確認できます。<placeholder-1/>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml82(para) msgid """" ""Look for the vnet NIC. You can also reference nova.conf and look for the "" ""flat_interface_bridge option."" msgstr ""vnet NICを探してください。また、nova.confのflat_network_bridgeオプションも参考になります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml88(para) msgid """" ""The packet transfers to the main NIC of the compute node. You can also see "" ""this NIC in the brctl output, or you can find it by referencing the "" ""flat_interface option in nova.conf."" msgstr ""パケットはコンピュートノードの物理NICに送られます。このNICはbrctlコマンドの出力から、もしくはnova.confのflat_interfaceオプションから確認できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml96(para) msgid """" ""After the packet is on this NIC, it transfers to the compute node's default "" ""gateway. The packet is now most likely out of your control at this point. "" ""The diagram depicts an external gateway. However, in the default "" ""configuration with multi-host, the compute host is the gateway."" msgstr ""パケットはこのNICに送られた後、コンピュートノードのデフォルトゲートウェイに転送されます。パケットはこの時点で、おそらくあなたの管理範囲外でしょう。図には外部ゲートウェイを描いていますが、マルチホストのデフォルト構成では、コンピュートホストがゲートウェイです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml105(para) msgid ""Reverse the direction to see the path of a ping reply."" msgstr ""pingの応答経路は、これと逆方向です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml107(para) msgid """" ""From this path, you can see that a single packet travels across four "" ""different NICs. If a problem occurs with any of these NICs, a network issue "" ""occurs."" msgstr ""この経路説明によって、あなたはパケットが4つの異なるNICの間を行き来していることがわかったでしょう。これらのどのNICに問題が発生しても、ネットワークの問題となるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml112(title) msgid ""Finding a Failure in the Path"" msgstr ""経路上の障害を見つける"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml113(para) msgid """" ""Use ping to quickly find where a failure exists in the network path. In an "" ""instance, first see if you can ping an external host, such as google.com. If"" "" you can, then there shouldn't be a network problem at all."" msgstr ""ネットワーク経路のどこに障害があるかを素早く見つけるには、pingを使います。まずあなたがインスタンス上で、google.comのような外部ホストにpingできるのであれば、ネットワークの問題はないでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml117(para) msgid """" ""If you can't, try pinging the IP address of the compute node where the "" ""instance is hosted. If you can ping this IP, then the problem is somewhere "" ""between the compute node and that compute node's gateway."" msgstr ""もしそれができないのであれば、インスタンスがホストされているコンピュートノードのIPアドレスへpingを試行してください。もしそのIPにpingできるのであれば、そのコンピュートノードと、ゲートウェイ間のどこかに問題があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml121(para) msgid """" ""If you can't ping the IP address of the compute node, the problem is between"" "" the instance and the compute node. This includes the bridge connecting the "" ""compute node's main NIC with the vnet NIC of the instance."" msgstr ""もしコンピュートノードのIPアドレスにpingできないのであれば、問題はインスタンスとコンピュートノード間にあります。これはコンピュートノードの物理NICとインスタンス vnet NIC間のブリッジ接続を含みます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml125(para) msgid """" ""One last test is to launch a second instance and see if the two instances "" ""can ping each other. If they can, the issue might be related to the firewall"" "" on the compute node."" msgstr ""最後のテストでは、2つ目のインスタンスを起動し、2つのインスタンス間でお互いにpingを実行します。実行できるのであれば、この問題にはコンピュートノード上のファイアウォールが関係しているかもしれません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml131(title) msgid ""tcpdump"" msgstr ""tcpdump"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml132(para) msgid """" ""One great, although very in-depth, way of troubleshooting network issues is "" ""to use tcpdump. It's recommended to use tcpdump at several points along the "" ""network path to correlate where a problem might be. If you prefer working "" ""with a GUI, either live or by using a tcpdump capture do also check out "" ""<link xlink:title=\""Wireshark\"" "" ""xlink:href=\""http://www.wireshark.org/\"">Wireshark</link> "" ""(http://www.wireshark.org/)."" msgstr ""ネットワーク問題の解決を徹底的に行う方法のひとつは、tcpdumpです。tcpdumpを使い、ネットワーク経路上の数点、問題のありそうなところから情報を収集することをおすすめします。もしGUIが好みであれば、<link xlink:title=\""Wireshark\"" xlink:href=\""http://www.wireshark.org/\"">Wireshark</link> (http://www.wireshark.org/)を試してみてはいかがでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml141(para) msgid ""For example, run the following command:"" msgstr ""例えば、以下のコマンドを実行します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml143(code) msgid """" ""tcpdump -i any -n -v 'icmp[icmptype] = icmp-echoreply or icmp[icmptype] = "" ""icmp-echo'"" msgstr ""tcpdump -i any -n -v 'icmp[icmptype] = icmp-echoreply or icmp[icmptype] = icmp-echo'"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml146(para) msgid ""Run this on the command line of the following areas:"" msgstr ""このコマンドは以下の場所で実行します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml150(para) msgid ""An external server outside of the cloud."" msgstr ""クラウド外部のサーバー上"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml153(para) msgid ""A compute node."" msgstr ""コンピュートノード上"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml156(para) msgid ""An instance running on that compute node."" msgstr ""コンピュートノード内のインスタンス上"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml159(para) msgid ""In this example, these locations have the following IP addresses:"" msgstr ""例では、この環境には以下のIPアドレスが存在します"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml161(remark) msgid ""DWC: Check formatting of the following:"" msgstr ""(翻訳不要)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml172(para) msgid """" ""Next, open a new shell to the instance and then ping the external host where"" "" tcpdump is running. If the network path to the external server and back is "" ""fully functional, you see something like the following:"" msgstr ""次に、新しいシェルを開いてtcpdumpの動いている外部ホストへpingを行います。もし外部サーバーとのネットワーク経路に問題がなければ、以下のように表示されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml176(para) msgid ""On the external server:"" msgstr ""外部サーバー上"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml181(para) msgid ""On the Compute Node:"" msgstr ""コンピュートノード上"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml194(para) msgid ""On the Instance:"" msgstr ""インスタンス上"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml197(para) msgid """" ""Here, the external server received the ping request and sent a ping reply. "" ""On the compute node, you can see that both the ping and ping reply "" ""successfully passed through. You might also see duplicate packets on the "" ""compute node, as seen above, because tcpdump captured the packet on both the"" "" bridge and outgoing interface."" msgstr ""外部サーバーはpingリクエストを受信し、pingリプライを送信しています。コンピュートノード上では、pingとpingリプライがそれぞれ成功していることがわかります。また、見ての通り、コンピュートノード上ではパケットが重複していることもわかるでしょう。なぜならtcpdumpはブリッジと外向けインターフェイスの両方でパケットをキャプチャするからです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml205(title) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1663(glossterm) msgid ""iptables"" msgstr ""iptables"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml206(para) msgid """" ""Nova automatically manages iptables, including forwarding packets to and "" ""from instances on a compute node, forwarding floating IP traffic, and "" ""managing security group rules."" msgstr ""Novaはiptablesを自動的に管理します。コンピュートノード上のインスタンス間でのパケット送受信、フローティングIPトラフィック、security groupのルール管理もそれに含まれます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml210(para) msgid ""Run the following command to view the current iptables configuration:"" msgstr ""iptablesの現在の構成を見るには、以下のコマンドを実行します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml213(para) msgid """" ""If you modify the configuration, it reverts the next time you restart nova-"" ""network. You must use OpenStack to manage iptables."" msgstr ""もしiptablesの構成を変更した場合、次のnova-network再起動時に前の状態に戻ります。iptablesの管理にはOpenStackを使ってください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml219(title) msgid ""Network Configuration in the Database"" msgstr ""データベースにあるネットワーク設定"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml220(para) msgid """" ""The nova database table contains a few tables with networking information:"" msgstr ""novaデータベースのテーブルには、いくつかのネットワーク情報が含まれています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml224(para) msgid """" ""fixed_ips: contains each possible IP address for the subnet(s) added to "" ""Nova. This table is related to the instances table by way of the "" ""fixed_ips.instance_uuid column."" msgstr ""fixed_ips: Novaに登録されたサブネットで利用可能なIPアドレス。このテーブルはfixed_ips.instance_uuid列で instances テーブルと関連付けられます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml230(para) msgid """" ""floating_ips: contains each floating IP address that was added to nova. This"" "" table is related to the fixed_ips table by way of the "" ""floating_ips.fixed_ip_id column."" msgstr ""floating_ips: Novaに登録されたフローティングIPアドレス。このテーブルはfloating_ips.fixed_ip_id列でfixed_ipsテーブルと関連付けられます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml236(para) msgid """" ""instances: not entirely network specific, but it contains information about "" ""the instance that is utilizing the fixed_ip and optional floating_ip."" msgstr ""instances: ネットワーク特有のテーブルではありませんが、fixed_ipとfloating_ipを使っているインスタンスの情報を管理します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml242(para) msgid """" ""From these tables, you can see that a Floating IP is technically never "" ""directly related to an instance, it must always go through a Fixed IP."" msgstr ""これらのテーブルから、フローティングIPが技術的には直接インスタンスにひも付けられておらず、固定IP経由であることがわかります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml246(title) msgid ""Manually De-Associating a Floating IP"" msgstr ""手動でフローティングIPの関連付けを解除する"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml247(para) msgid """" ""Sometimes an instance is terminated but the Floating IP was not correctly "" ""de-associated from that instance. Because the database is in an inconsistent"" "" state, the usual tools to de-associate the IP no longer work. To fix this, "" ""you must manually update the database."" msgstr ""しばしば、フローティングIPを正しく開放しないままインスタンスが終了されることがあります。するとデータベースは不整合状態となるため、通常のツールではうまく開放できません。解決するには、手動でデータベースを更新する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml253(para) msgid ""First, find the UUID of the instance in question:"" msgstr ""まず、インスタンスのUUIDを確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml256(para) msgid ""Next, find the Fixed IP entry for that UUID:"" msgstr ""次に、そのUUIDから固定IPのエントリーを探します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml258(para) msgid ""You can now get the related Floating IP entry:"" msgstr ""関連するフローティングIPのエントリーが見つかります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml261(para) msgid ""And finally, you can de-associate the Floating IP:"" msgstr ""最後に、フローティングIPを開放します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml264(para) msgid ""You can optionally also de-allocate the IP from the user's pool:"" msgstr ""また、ユーザプールからIPを開放することもできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml270(title) msgid ""Debugging DHCP Issues"" msgstr ""DHCP の問題をデバッグする"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml271(para) msgid """" ""One common networking problem is that an instance boots successfully but is "" ""not reachable because it failed to obtain an IP address from dnsmasq, which "" ""is the DHCP server that is launched by the nova-network service."" msgstr ""よくあるネットワークの問題に、インスタンスが起動しているにも関わらず、dnsmasqからのIPアドレス取得に失敗し、到達できないという現象があります。dnsmasqはnova-nwtworkサービスから起動されるDHCPサーバです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml276(para) msgid """" ""The simplest way to identify that this the problem with your instance is to "" ""look at the console output of your instance. If DHCP failed, you can "" ""retrieve the console log by doing:"" msgstr ""もっともシンプルにこの問題を特定する方法は、インスタンス上のコンソール出力を確認することです。もしDHCPが正しく動いていなければ、下記のようにコンソールログを参照してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml281(para) msgid """" ""If your instance failed to obtain an IP through DHCP, some messages should "" ""appear in the console. For example, for the Cirros image, you see output "" ""that looks like:"" msgstr ""もしインスタンスがDHCPからのIP取得に失敗していれば、いくつかのメッセージがコンソールで確認できるはずです。例えば、Cirrosイメージでは、このような出力になります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml293(para) msgid """" ""After you establish that the instance booted properly, the task is to figure"" "" out where the failure is."" msgstr ""インスタンスが正しく起動した後、この手順でどこが問題かを切り分けることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml295(para) msgid """" ""A DHCP problem might be caused by a misbehaving dnsmasq process. First, "" ""debug by checking logs and then restart the dnsmasq processes only for that "" ""project (tenant). In VLAN mode there is a dnsmasq process for each tenant. "" ""Once you have restarted targeted dnsmasq processes, the simplest way to rule"" "" out dnsmasq causes is to kill all of the dnsmasq processes on the machine, "" ""and restart nova-network. As a last resort, do this as root:"" msgstr ""DHCPの問題はdnsmasqの不具合が原因となりがちです。まず、ログを確認し、その後該当するプロジェクト(テナント)のdnsmasqプロセスを再起動してください。VLANモードにおいては、dnsmasqプロセスはテナントごとに存在します。すでに該当のdnsmasqプロセスを再起動しているのであれば、もっともシンプルな解決法は、マシン上の全てのdnsmasqプロセスをkillし、nova-networkを再起動することです。最終手段として、rootで以下を実行してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml306(para) msgid """" ""Several minutes after nova-network is restarted, you should see new dnsmasq "" ""processes running:"" msgstr ""nova-networkの再起動から数分後、新たなdnsmasqプロセスが動いていることが確認できるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml317(para) msgid """" ""If your instances are still not able to obtain IP addresses, the next thing "" ""to check is if dnsmasq is seeing the DHCP requests from the instance. On the"" "" machine that is running the dnsmasq process, which is the compute host if "" ""running in multi-host mode, look at /var/log/syslog to see the dnsmasq "" ""output. If dnsmasq is seeing the request properly and handing out an IP, the"" "" output looks like:"" msgstr ""もしまだインスタンスがIPアドレスを取得できない場合、次はdnsmasqがインスタンスからのDHCPリクエストを見えているか確認します。dnsmasqプロセスが動いているマシンで、/var/log/syslogを参照し、dnsmasqの出力を確認します。なお、マルチホストモードで動作している場合は、dnsmasqプロセスはコンピュートノードで動作します。もしdnsmasqがリクエストを正しく受け取り、処理していれば、以下のような出力になります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml329(para) msgid """" ""If you do not see the DHCPDISCOVER, a problem exists with the packet getting"" "" from the instance to the machine running dnsmasq. If you see all of above "" ""output and your instances are still not able to obtain IP addresses then the"" "" packet is able to get from the instance to the host running dnsmasq, but it"" "" is not able to make the return trip."" msgstr ""もしDHCPDISCOVERが見つからなければ、dnsmasqが動いているマシンがインスタンスからパケットを受け取れない何らかの問題があります。もし上記の出力が全て確認でき、かついまだにIPアドレスを取得できないのであれば、パケットはインスタンスからdnsmasq稼働マシンに到達していますが、その復路に問題があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml336(para) msgid ""If you see any other message, such as:"" msgstr ""もし他にこのようなメッセージを確認できたのであれば、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml338(para) msgid """" ""Then this may be a dnsmasq and/or nova-network related issue. (For the "" ""example above, the problem happened to be that dnsmasq did not have any more"" "" IP addresses to give away because there were no more Fixed IPs available in"" "" the OpenStack Compute database)."" msgstr ""これはdnsmasqの、もしくはdnsmasqとnova-network両方の問題です。(例えば上記では、OpenStack Compute データベース上に利用可能な固定IPがなく、dnsmasqがIPアドレスを払い出せない問題が発生しています)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml343(para) msgid """" ""If there's a suspicious-looking dnsmasq log message, take a look at the "" ""command-line arguments to the dnsmasq processes to see if they look correct."" msgstr ""もしdnsmasqのログメッセージで疑わしいものがあれば、コマンドラインにてdnsmasqが正しく動いているか確認してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml347(para) msgid ""The output looks something like:"" msgstr ""出力は以下のようになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml360(para) msgid """" ""If the problem does not seem to be related to dnsmasq itself, at this point,"" "" use tcpdump on the interfaces to determine where the packets are getting "" ""lost."" msgstr ""もし問題がdnsmasqと関係しないようであれば、tcpdumpを使ってパケットロスがないか確認してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml363(para) msgid """" ""DHCP traffic uses UDP. The client sends from port 68 to port 67 on the "" ""server. Try to boot a new instance and then systematically listen on the "" ""NICs until you identify the one that isn't seeing the traffic. To use "" ""tcpdump to listen to ports 67 and 68 on br100, you would do:"" msgstr ""DHCPトラフィックはUDPを使います。そして、クライアントは68番ポートからサーバーの67番ポートへパケットを送信します。新しいインスタンスを起動し、機械的にNICをリッスンしてください。トラフィックに現れない通信を特定できるまで行います。tcpdumpでbr100上のポート67、68をリッスンするには、こうします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml369(para) msgid """" ""You should be doing sanity checks on the interfaces using command such as "" ""\""<code>ip a</code>\"" and \""<code>brctl show</code>\"" to ensure that the "" ""interfaces are actually up and configured the way that you think that they "" ""are."" msgstr ""また、\""<code>ip a</code>\"" や \""<code>brctl show</code>\""などのコマンドを使って、インターフェイスが実際にUPしているか、あなたが考えたとおりに設定されているか、正当性を検査をすべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml376(title) msgid ""Debugging DNS Issues"" msgstr ""DNS の問題をデバッグする"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml377(para) msgid """" ""If you are able to ssh into an instance, but it takes a very long time (on "" ""the order of a minute) to get a prompt, then you might have a DNS issue. The"" "" reason a DNS issue can cause this problem is that the ssh server does a "" ""reverse DNS lookup on the IP address that you are connecting from. If DNS "" ""lookup isn't working on your instances, then you must wait for the DNS "" ""reverse lookup timeout to occur for the ssh login process to complete."" msgstr ""あなたがインスタンスにsshできるけれども、プロンプトが表示されるまで長い時間(約1分)を要する場合、DNSに問題があるかもしれません。sshサーバーが接続元IPアドレスのDNS逆引きをおこなうこと、それがこの問題の原因です。もしあなたのインスタンスでDNSが正しく引けない場合、sshのログインプロセスが完了するには、DNSの逆引きがタイムアウトするまで待たなければいけません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml386(para) msgid """" ""When debugging DNS issues, start by making sure the host where the dnsmasq "" ""process for that instance runs is able to correctly resolve. If the host "" ""cannot resolve, then the instances won't be able either."" msgstr ""DNS問題のデバッグをするとき、そのインスタンスのdnsmasqが動いているホストが、名前解決できるかを確認することから始めます。もしホストができないのであれば、インスタンスも同様でしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml390(para) msgid """" ""A quick way to check if DNS is working is to resolve a hostname inside your "" ""instance using the <code>host</code> command. If DNS is working, you should "" ""see:"" msgstr ""DNSが正しくホスト名をインスタンス内から解決できているか確認する簡単な方法は、<code>host</code>コマンドです。もしDNSが正しく動いていれば、以下メッセージが確認できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml398(para) msgid """" ""If you're running the Cirros image, it doesn't have the \""host\"" program "" ""installed, in which case you can use ping to try to access a machine by "" ""hostname to see if it resolves. If DNS is working, the first line of ping "" ""would be:"" msgstr ""もしあなたがCirrosイメージを使っているのであれば、\""host\""プログラムはインストールされていません。その場合はpingを使い、ホスト名が解決できているか判断できます。もしDNSが動いていれば、ping結果の先頭行はこうなるはずです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml405(para) msgid """" ""If the instance fails to resolve the hostname, you have a DNS problem. For "" ""example:"" msgstr ""もしインスタンスがホスト名の解決に失敗するのであれば、DNSに問題があります。例えば、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml409(para) msgid """" ""In an OpenStack cloud, the dnsmasq process acts as the DNS server for the "" ""instances in addition to acting as the DHCP server. A misbehaving dnsmasq "" ""process may be the source of DNS-related issues inside the instance. As "" ""mentioned in the previous section, the simplest way to rule out a "" ""misbehaving dnsmasq process is to kill all of the dnsmasq processes on the "" ""machine, and restart nova-network. However, be aware that this command "" ""affects everyone running instances on this node, including tenants that have"" "" not seen the issue. As a last resort, as root:"" msgstr ""OpenStackクラウドにおいて、dnsmasqプロセスはDHCPサーバに加えてDNSサーバーの役割を担っています。dnsmasqの不具合は、インスタンスにおけるDNS関連問題の原因となりえます。前節で述べたように、dnsmasqの不具合を解決するもっともシンプルな方法は、マシン上のすべてのdnsmasqプロセスをkillし、nova-networkを再起動することです。しかしながら、このコマンドは該当ノード上で動いているすべてのインスタンス、特に問題がないテナントにも影響します。最終手段として、rootで以下を実行します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml422(para) msgid ""After the dnsmasq processes start again, check if DNS is working."" msgstr ""dnsmasq再起動後に、DNSが動いているか確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml424(para) msgid """" ""If restarting the dnsmasq process doesn't fix the issue, you might need to "" ""use tcpdump to look at the packets to trace where the failure is. The DNS "" ""server listens on UDP port 53. You should see the DNS request on the bridge "" ""(such as, br100) of your compute node. If you start listening with tcpdump "" ""on the compute node:"" msgstr ""dnsmasqの再起動でも問題が解決しないときは、tcpdumpで問題がある場所のパケットトレースを行う必要があるでしょう。DNSサーバーはUDPポート53番でリッスンします。あなたのコンピュートノードのブリッジ(br100など)上でDNSリクエストをチェックしてください。コンピュートノード上にて、tcpdumpでリッスンを開始すると、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_network_troubleshooting.xml432(para) msgid """" ""Then, if you ssh into your instance and try to <code>ping "" ""openstack.org</code>, you should see something like:"" msgstr ""インスタンスへのssh、<code>ping openstack.org</code>の試行にて、以下のようなメッセージが確認できるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml16(title) msgid ""Cloud Controller Design"" msgstr ""クラウドコントローラーの設計"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml17(para) msgid """" ""OpenStack is designed to be massively horizontally scalable, which allows "" ""all services to be distributed widely. However, to simplify this guide we "" ""have decided to discuss services of a more central nature using the concept "" ""of a single <emphasis>cloud controller</emphasis>."" msgstr ""OpenStack は非常に水平的にスケーラブルに設計されています。これにより、すべてのサービスを広く分散させることができます。しかし、この話を単純にするために、このガイドでは単一の<emphasis>クラウドコントローラー</emphasis>の概念を使い、より集中的な性質のサービスとして議論することにしました。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml22(para) msgid """" ""For more details about the overall architecture, see the <xref "" ""linkend=\""example_architecture\""/>."" msgstr ""全体的なアーキテクチャの詳細については、<xref linkend=\""example_architecture\""/>の章を参照してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml24(para) msgid """" ""As described in this guide, the cloud controller is a single node that hosts"" "" the databases, message queue service, authentication and authorization "" ""service, image management service, user dashboard, and <glossterm>API "" ""endpoint</glossterm>s."" msgstr ""このガイドに記述されているように、クラウドコントローラーは、データベース、メッセージキューサービス、認証・認可サービス、イメージ管理サービス、ユーザーダッシュボード、<glossterm>API エンドポイント</glossterm>を収容する１台のノードです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml29(para) msgid """" ""The cloud controller provides the central management system for multi-node "" ""OpenStack deployments. Typically the cloud controller manages authentication"" "" and sends messaging to all the systems through a message queue."" msgstr ""クラウドコントローラーは、複数ノードで構成される OpenStack デプロイメントに対する集中管理機能を提供します。典型的には、クラウドコントローラーは認証および、メッセージキューを通じたメッセージのやりとりを管理します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml33(para) msgid """" ""For our example, the cloud controller has a collection of "" ""<code>nova-*</code> components that represent the global state of the cloud,"" "" talks to services such as authentication, maintains information about the "" ""cloud in a database, communicates to all compute nodes and storage "" ""<glossterm>worker</glossterm>s through a queue, and provides API access. "" ""Each service running on a designated cloud controller may be broken out into"" "" separate nodes for scalability or availability."" msgstr ""私たちの例では、クラウドコントローラーが <code>nova-*</code> コンポーネント群を持ちます。これは、クラウドのグローバルな状態を表し、認証のようなサービスとやりとりし、クラウドの情報をデータベースで維持し、メッセージキューを通してすべてのコンピュートノードとストレージ<glossterm>ワーカー</glossterm>と通信し、 API アクセスを提供します。可用性やスケーラビリティのために、あるクラウドコントローラーで動作するそれぞれのサービスを別々のノードに分離することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml44(title) msgid ""Hardware Considerations"" msgstr ""ハードウェアの考慮事項"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml45(para) msgid """" ""A cloud controller's hardware can be the same as a compute node, though you "" ""may want to further specify based on the size and type of cloud that you "" ""run."" msgstr ""クラウドコントローラー用のハードウェアはコンピュートノードのものと同じでかまいませんが、運用するクラウドのサイズとタイプに基づいて、もっと指定したいかもしれません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml48(para) msgid """" ""It's also possible to use virtual machines for all or some of the services "" ""that the cloud controller manages, such as the message queuing. In this "" ""guide, we assume that all services are running directly on the cloud "" ""controller."" msgstr ""クラウドコントローラーが管理するすべての、または一部のサービス、たとえばメッセージキューに対して仮想マシンを使うことも可能です。このガイドでは、すべてのサービスが直接クラウドコントローラー上で実行されるものと仮定します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml53(para) msgid """" ""To size the server correctly, and determine whether to virtualize any part "" ""of it, you should estimate:"" msgstr ""クラウドコントローラーのサーバーを正しくサイジングするため、および一部を仮想化するかどうか決定するため、以下を見積もるべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml57(para) msgid ""The number of instances that you expect to run"" msgstr ""予期されるインスタンス実行数"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml61(para) msgid ""The number of compute nodes that you have"" msgstr ""コンピュートノードの数"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml64(para) msgid ""The number of users who will access the compute or storage services"" msgstr ""コンピュートサービスまたはストレージサービスにアクセスするユーザー数"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml68(para) msgid """" ""Whether users interact with your cloud through the REST API or the dashboard"" msgstr ""ユーザがクラウドへ REST API でアクセスするのかダッシュボードを使うのか"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml72(para) msgid """" ""Whether users authenticate against an external system (such as, LDAP or "" ""<glossterm>Active Directory</glossterm>)"" msgstr ""ユーザーは外部のシステムに対して認証を行うのか (例えば、LDAP や <glossterm>Active Directory</glossterm>)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml77(para) msgid ""How long you expect single instances to run"" msgstr ""1 つのインスタンスがどのくらい実行され続けるのか"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml86(th) msgid ""Consideration"" msgstr ""考慮事項"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml87(th) msgid ""Ramification"" msgstr ""派生問題"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml93(para) msgid ""How many instances will run at once?"" msgstr ""同時に何インスタンス実行されますか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml96(para) msgid """" ""Size your database server accordingly, and scale out beyond one cloud "" ""controller if many instances will report status at the same time and "" ""scheduling where a new instance starts up needs computing power."" msgstr ""データベースサーバーを負荷に応じてサイジングしてください。もし、多数のインスタンスが同時に状態を報告したり、CPU能力が必要な新規インスタンス起動のスケジューリングを行う場合は、１台のクラウドコントローラーを超えてスケールアウトしてください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml105(para) msgid ""How many compute nodes will run at once?"" msgstr ""同時にコンピュートノードが何ノード実行されますか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml108(para) msgid """" ""Ensure that your messaging queue handles requests successfully and size "" ""accordingly."" msgstr ""メッセージキューが正しくリクエストを処理することを保証し、適切にサイジングしてください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml114(para) msgid ""How many users will access the API?"" msgstr ""どのくらいの数のユーザがAPIにアクセスしますか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml117(para) msgid """" ""If many users will make multiple requests, make sure that the CPU load for "" ""the cloud controller can handle. it."" msgstr ""もし多数のユーザが複数のリクエストを発行するのであれば、クラウドコントローラーがそれらを扱えるよう、CPU負荷を確認してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml124(para) msgid ""How many users will access the <glossterm>dashboard</glossterm>?"" msgstr ""どのくらいの数のユーザが <glossterm>ダッシュボード</glossterm>にアクセスしますか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml127(para) msgid """" ""The dashboard makes many requests, even more than the API access, so add "" ""even more CPU if your dashboard is the main interface for your users."" msgstr ""ダッシュボードは、APIアクセスよりもさらに多くのリクエストを発行します。そのため、もしユーザに対するインタフェースがダッシュボードなのであれば、より多くのCPUを追加してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml134(para) msgid """" ""How many <code>nova-api</code> services do you run at once for your cloud?"" msgstr ""あなたのクラウドで、何個の<code>nova-api</code>サービスを同時に実行しますか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml138(para) msgid ""You need to size the controller with a core per service."" msgstr ""サービスごとに１コア割り当ててコントローラーをサイジングする必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml143(para) msgid ""How long does a single instance run?"" msgstr ""１つのインスタンスがどのくらい実行され続けますか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml146(para) msgid """" ""Starting instances and deleting instances is demanding on the compute node "" ""but also demanding on the controller node because of all the API queries and"" "" scheduling needs."" msgstr ""インスタンスの起動と停止は コンピュートノードに負荷をかけますが、それだけでなく、すべてのAPI処理とスケジューリングの必要性のために、コントローラーノードにも負荷をかけます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml154(para) msgid ""Does your authentication system also verify externally?"" msgstr ""認証システムは外部に確認を行いますか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml157(para) msgid """" ""Ensure network connectivity between the cloud controller and external "" ""authentication system are good and that the cloud controller has the CPU "" ""power to keep up with requests."" msgstr ""クラウドコントローラーと外部の認証システムの間のネットワーク接続性が良好であることと、クラウドコントローラーがリクエストを処理するのに十分なCPU能力があることを確認してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml168(title) msgid ""Separation of Services"" msgstr ""サービスの分離"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml169(para) msgid """" ""While our example contains all central services in a single location, it is "" ""possible and indeed often a good idea to separate services onto different "" ""physical servers. The following is a list of deployment scenarios we've "" ""seen, and their justifications."" msgstr ""私たちの例には、一か所にすべての集中的なサービスが含まれていますが、サービスを異なる物理サーバーに分離するのは可能ですし、多くの場合、本当に良いアイデアです。以下は、私たちが見たデプロイメントのシナリオと、その妥当性です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml180(para) msgid """" ""Run <code>glance-*</code> servers on the <code>swift-proxy</code> server"" msgstr ""<code>glance-*</code> サーバーを、 <code>swift-proxy</code> サーバーの上で実行する"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml184(para) msgid """" ""This deployment felt the spare I/O on the Object Storage proxy server was "" ""sufficient, and the Image Delivery portion of Glance benefited from being on"" "" physical hardware and having good connectivity to the Object Storage back-"" ""end it was using."" msgstr ""このデプロイメントでは、オブジェクトストレージのプロキシサーバーの I/O の空きは十分でした。そして、Glance のイメージ配信部分は、それが利用しているオブジェクトストレージと同じ物理マシンの上にあり、バックエンドに対して良好な接続性をもつことにより、恩恵を得られました。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml196(para) msgid ""Run a central dedicated database server"" msgstr ""専用の中央データベースサーバーを運用する"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml199(para) msgid """" ""This deployment made a central dedicated server to provide the databases for"" "" all services. This simplified operations by isolating database server "" ""updates, and allowed for the simple creation of slave database servers for "" ""failover."" msgstr ""このデプロイメントでは、すべてのサービスに対するデータベースサービスを提供する専用サーバを設置しました。これにより、データベースサーバーのアップデートを分離でき、運用がシンプルになりました。また、フェイルオーバーのためのスレーブデータベースサーバーの設置が単純になりました。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml209(para) msgid ""Run one VM per service"" msgstr ""サービスごとに 1 台の VM を動作させる"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml211(para) msgid """" ""This deployment ran central services on a set of servers running KVM. A "" ""dedicated VM was created for each service (nova-scheduler, rabbitmq, "" ""database etc). This assisted the deployment with scaling as they could tune "" ""the resources given to each virtual machine based on the load they received "" ""(something that was not well understood during installation)."" msgstr ""このデプロイメントでは、KVM を実行しているサーバー群において集中的なサービス群を動作させています。 各サービス (nova-scheduler、rabbitmq、データベース等) に対して専用 VM が作成されています。これにより、各仮想マシンにかかった負荷 (構築中にはよく分からなかったこと) に応じてリソースをチューニングすることができました。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml224(para) msgid ""Use an external load balancer"" msgstr ""外部ロードバランサーを使う"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml227(para) msgid """" ""This deployment had an expensive hardware load balancer in their "" ""organisation. They ran multiple <code>nova-api</code> and <code>swift-"" ""proxy</code> servers on different physical servers and used the load "" ""balancer to switch between them."" msgstr ""このデプロイメントでは、組織内に高価なハードウェアロードバランサーを持っていました。彼らは複数の <code>nova-api</code> と<code>swift-proxy</code> サーバーを異なる物理サーバーで動作させ、それらの間の振り分けにロードバランサーを使いました。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml239(para) msgid """" ""One choice that always comes up is whether to virtualize or not. Some "" ""services, such as nova-compute, swift-proxy and swift-object servers, should"" "" not be virtualized. However, control servers can often be happily "" ""virtualized - the performance penalty can usually be offset by simply "" ""running more of the service."" msgstr ""いつも問題になる一つの選択は、仮想化するかどうかです。nova-compute、swift-proxy そして swift-object といったサーバーは仮想化するべきではありません。しかし、コントローラーサーバーは問題なく仮想化することができます。通常、性能ペナルティは、単により多くのサービスを動作させることにより相殺することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml248(para) msgid """" ""Most OpenStack Compute central services, and currently also the nova-compute"" "" nodes, use the database for stateful information. Loss of this ability "" ""leads to errors. As a result, we recommend that you cluster your databases "" ""in some way to make them failure tolerant."" msgstr ""OpenStack Compute のほとんどの中央サービスは、現在は nova-compute も含めて、状態の情報を保存するのにデータベースを利用します。この機能を喪失することはエラーにつながります。ですので、耐故障性のために、なんらかの方法でデータベースをクラスタ化することを推奨します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml255(title) msgid ""Message Queue"" msgstr ""メッセージキュー"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml256(para) msgid """" ""Most OpenStack Compute services communicate with each other using the "" ""Message Queue. In general, if the message queue fails or becomes "" ""inaccessible, the cluster grinds to a halt and ends up in a \""read only\"" "" ""state, with information stuck at the point where the last message was sent. "" ""Accordingly, we recommend that you cluster the message queue - and RabbitMQ "" ""has in-build abilities to do this."" msgstr ""OpenStack Compute のほとんどのサーバーは、メッセージキューを利用してお互いに通信しあっています。一般論として、このメッセージキューが故障するかアクセスできなくなると、Nova のクラスタは、最後のメッセージが送信されたところの情報でとどまったまま、ゆっくり停止し、「リードオンリー」状態になります。したがって、メッセージキューもクラスタ化することを推奨します。RabbitMQ には、これを行う機能が組み込まれています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml267(title) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml319(glossterm) msgid ""Application Programming Interface (API)"" msgstr ""Application Programming Interface (API)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml268(para) msgid """" ""All public access, whether direct, through a command line client, or through"" "" the web-based dashboard, uses the API service. Find the API reference at "" ""<link xlink:href=\""http://api.openstack.org/\"">http://api.openstack.org/</link>."" msgstr ""直接であっても、コマンドラインクライアントであっても、Web ベースのダッシュボードであっても、一般ユーザーからのアクセスはAPIサービスを利用します。 API リファレンスは <link xlink:href=\""http://api.openstack.org/\"">http://api.openstack.org/</link> にあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml273(para) msgid """" ""You must choose whether you want to support the Amazon EC2 compatibility "" ""APIs, or just the OpenStack APIs. One issue you might encounter when running"" "" both APIs is an inconsistent experience when referring to images and "" ""instances."" msgstr ""Amazon EC2 互換 API をサポートしたいか、OpenStack API だけなのか、選択しなければなりません。両方の API を運用する場合、イメージとインスタンスを参照する際の見え方が違うことが一つの論点になります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml278(para) msgid """" ""For example, the EC2 API refers to instances using IDs that contain "" ""hexadecimal whereas the OpenStack API uses names and digits. Similarly, the "" ""EC2 API tends to rely on DNS aliases for contacting virtual machines, as "" ""opposed to OpenStack which typically lists IP addresses."" msgstr ""例えば、EC2 API では、16 進数を含む ID を使ってインスタンスを参照するのに対して、OpenStack API では名前と数値を使います。類似の話題として、EC2 API は仮想マシンに接続するのに DNS エイリアスに頼る傾向がありますが、OpenStack では典型的には IP アドレスを使います。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml283(para) msgid """" ""If OpenStack is not set up in the right way, it is simple to have scenarios "" ""where users are unable to contact their instances due to only having an "" ""incorrect DNS alias. Despite this, EC2 compatibility can assist users "" ""migrating to your cloud."" msgstr ""もし OpenStack が正しく設定されていなければ、不正な DNS エイリアスしか得られないことによりユーザがインスタンスに接続できないという事態が容易に発生します。こうした事情にもかかわらず、EC2 互換性はユーザーをお使いのクラウドに移行させるのに役立ちます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml288(para) msgid """" ""Like databases and message queues, having more than one <glossterm>API "" ""server</glossterm> is a good thing. Traditional HTTP load balancing "" ""techniques can be used to achieve a highly available <code>nova-api</code> "" ""service."" msgstr ""データベースやメッセージキューのように、１台より多くの <glossterm>API サーバー</glossterm> を置くのは良いことです。<code>nova-api</code> サービスを高可用にするために、伝統的な HTTP 負荷分散技術を利用することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml295(title) msgid ""Extensions"" msgstr ""API 拡張"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml296(para) msgid """" ""The <link xlink:title=\""API Specifications\"" xlink:href=\""http://docs.openstack.org/api"" ""/api-specs.html\"">API Specifications</link> (http://docs.openstack.org/api"" ""/api-specs.html) define the core actions, capabilities, and media-types of "" ""the OpenStack API. A client can always depend on the availability of this "" ""core API and implementers are always required to support it in its entirety."" "" Requiring strict adherence to the core API allows clients to rely upon a "" ""minimal level of functionality when interacting with multiple "" ""implementations of the same API."" msgstr ""<link xlink:title=\""API Specifications\"" xlink:href=\""http://docs.openstack.org/api/api-specs.html\"">API Specifications</link> (http://docs.openstack.org/api/api-specs.html) に OpenStack API コアのアクション、ケーパビリティ、メディアタイプが定義されています。クライアントはいつでもこのコアAPIが使えることに依存することができますし、実装者はいつでも完全にサポートすることが求められます。コアAPIの厳守を要求することにより、クライアントは同じAPIの複数の実装とやりとりする際に、最小限のレベルの機能に依存することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml307(para) msgid """" ""The OpenStack Compute API is extensible. An extension adds capabilities to "" ""an API beyond those defined in the core. The introduction of new features, "" ""MIME types, actions, states, headers, parameters, and resources can all be "" ""accomplished by means of extensions to the core API. This allows the "" ""introduction of new features in the API without requiring a version change "" ""and allows the introduction of vendor-specific niche functionality."" msgstr ""OpenStack Compute API は拡張可能です。ある拡張は、ある API にコア定義を超えたケイパビリティを追加します。新機能、新しい MIME タイプ、アクション、状態、ヘッダ、パラメータ、そしてリソースの導入は、コア API の拡張によって達成することができます。これにより、API に対してバージョンを変更することなく新機能を導入することができ、ベンダー固有の特定の機能を導入することもできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml319(title) msgid ""Scheduler"" msgstr ""スケジューラー"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml320(para) msgid """" ""Fitting various sized virtual machines (different "" ""<emphasis>flavors</emphasis>) into different sized physical nova-compute "" ""nodes is a challenging problem - researched generically in Computer Science "" ""as a packing problem."" msgstr ""さまざまなサイズ(異なる <emphasis>フレーバー</emphasis>)の仮想マシンを、異なる能力の物理 nova-compute ノードに配置するのは、一般的にコンピュータ科学で パッキング問題として研究されている難しい問題です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml325(para) msgid """" ""You can use various techniques to handle this problem, one of which is to "" ""have flavor sizes scale linearly, be a proportional fraction of your "" ""physical node capacity, though solving this problem is out of the scope of "" ""this book. To support your scheduling choices, OpenStack Compute provides "" ""several different types of scheduling drivers, a full discussion of which is"" "" found in the <link xlink:title=\""API Specifications\"" "" ""xlink:href=\""http://docs.openstack.org/folsom/openstack-"" ""compute/admin/content/ch_scheduling.html\"">reference manual</link> "" ""(http://docs.openstack.org/folsom/openstack-"" ""compute/admin/content/ch_scheduling.html)."" msgstr ""この問題に対しては様々なテクニックを使うことができます。ひとつの方法は、フレーバーのサイズを線形にすること、つまり、物理ノードの容量に比例した割合にすることですが、この問題を解くことは本書のスコープ外です。スケジューリングの選択肢の助けとなるために、OpenStack Compute はいくつかの異なるタイプのスケジューリングドライバーを提供しており、この議論の全体は <link xlink:title=\""API Specifications\"" xlink:href=\""http://docs.openstack.org/folsom/openstack-compute/admin/content/ch_scheduling.html\"">リファレンスマニュアル</link> (http://docs.openstack.org/folsom/openstack-compute/admin/content/ch_scheduling.html) にあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml336(para) msgid """" ""For availability purposes, or for very large or high-schedule frequency "" ""installations, you should consider running multiple nova-scheduler services."" "" No special load balancing is required, as the nova-scheduler communicates "" ""entirely using the message queue."" msgstr ""可用性の目的のため、もしくは非常に大規模な環境や非常に頻繁にスケジューラーが呼び出される環境の場合には、複数の nova-scheduler サービスを動作させることを検討するべきです。nova-scheduler は完全にメッセージキューを使って通信を行うため、特別な負荷分散は必要ありません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml343(title) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml27(title) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml829(para) msgid ""Images"" msgstr ""イメージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml344(para) msgid """" ""The OpenStack Image Catalog and Delivery service consists of two parts - "" ""<code>glance-api</code> and <code>glance-registry</code>. The former is "" ""responsible for the delivery of images and the compute node uses it to "" ""download images from the back-end. The latter maintains the metadata "" ""information associated with virtual machine images and requires a database."" msgstr ""OpenStack Image Catalog and Delivery サービスは、 <code>glance-api</code> と <code>glance-registry</code> の２つの部分から構成されています。前者は コンピュートノードへのイメージの配送に責任を持ち、コンピュートノードはバックエンドからイメージをダウンロードするために使います。後者は、仮想マシンのイメージに関連するメタデータ情報を管理し、データベースを必要とします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml351(para) msgid """" ""The <code>glance-api</code> part is an abstraction layer that allows a "" ""choice of back-end. Currently, it supports:"" msgstr ""<code>glance-api</code> は、バックエンドの選択を可能にする抽象化レイヤであり、現在は以下をサポートしています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml356(para) msgid ""OpenStack Object Storage. Allows you to store images as objects."" msgstr ""OpenStack Object Storage。イメージをオブジェクトとして保存することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml360(para) msgid """" ""File system. Uses any traditional file system to store the images as files."" msgstr ""ファイルシステム。イメージをファイルとして保存するのに、任意の伝統的なファイルシステムを使用します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml364(para) msgid """" ""S3. Allows you to fetch images from Amazon S3. You cannot write images by "" ""using this mode."" msgstr ""S3。Amazon S3 からイメージを取得することができます。このモードでは、イメージの書き込みはできません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml368(para) msgid """" ""HTTP. Allows you to fetch images from a web server. You cannot write images "" ""by using this mode."" msgstr ""HTTP。Webサーバーからイメージを取得することができます。このモードでは、イメージの書き込みはできません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml373(para) msgid """" ""If you have an OpenStack Object Storage service, we recommend using this as "" ""a scalable place to store your images. Failing that, a file system with "" ""sufficient performance is the only real option - unless you do not need the "" ""ability to upload new images through OpenStack."" msgstr ""OpenStack Object Storage サービスがあるのであれば、イメージを保存するスケーラブルな場所として利用することを推奨します。そうでない場合は、OpenStack を通じて新しいイメージをアップロードする必要がない場合を除いて、充分な性能のあるファイルシステムが唯一の選択肢です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml382(para) msgid """" ""The OpenStack Dashboard is implemented as a Python web application that runs"" "" in <glossterm>Apache</glossterm><code>httpd</code>. Therefore, you may "" ""treat it the same as any other web application, provided it can reach the "" ""API servers (including their admin endpoints) over the network."" msgstr ""OpenStack ダッシュボードは、<glossterm>Apache</glossterm> <code>httpd</code>の中で実行される Python の Web アプリケーションとして実装されています。したがって、そこから ネットワーク経由で (admin エンドポイントを含む) API サーバーにアクセスできるという条件の下、他の任意の Web アプリケーションと同じように取り扱うことができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml391(title) msgid ""Authentication and Authorization"" msgstr ""認証と認可"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml392(para) msgid """" ""The concepts supporting OpenStack's authentication and authorization are "" ""derived from well understood and widely used systems of a similar nature. "" ""Users have credentials they can use to authenticate, and they can be a "" ""member of one or more groups (known as projects or tenants interchangeably)."" msgstr ""OpenStack の認証・認可を支える概念は、よく理解され、類似の性質のシステムで広く使用されているものから得られています。ユーザは、認証に使えるクレデンシャルを持ち、１つ以上のグループ(プロジェクトまたはテナントして知られています)のメンバとなることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml398(para) msgid """" ""For example, a cloud administrator might be able to list all instances in "" ""the cloud, whereas a user can only see those in their current group. "" ""Resources quotas, such as the number of cores that can be used, disk space, "" ""and so on, are associated with a project."" msgstr ""例えば、クラウドのユーザは自分の現在のグループに属するインスタンスのみが見えるのに対して、クラウドの管理者はそのクラウドのすべてのインスタンスの一覧をとることができるでしょう。利用可能なコア数、ディスク容量等のリソースのクォータはプロジェクトに対して関連づけられています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml403(para) msgid """" ""The OpenStack Identity Service (Keystone) is the point that provides the "" ""authentication decisions and user attribute information, which is then used "" ""by the other OpenStack services to perform authorization. Policy is set in "" ""the policy.json file. For information on how to configure these, see <xref "" ""linkend=\""projects_users\""/>."" msgstr ""OpenStack Identity Service (Keystone) は、認証の判定とユーザの属性情報を提供する場となり、他の OpenStack サービスから認可のために使用されます。ポリシーは policy.json で記述されます。これらを設定するための情報については、<xref linkend=\""projects_users\""/> を参照してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml410(para) msgid """" ""The Identity Service supports different plugins for back-end authentication "" ""decisions, and storing information. These range from pure storage choices to"" "" external systems and currently include:"" msgstr ""Identity サービスは、バックエンド認証と情報保持のために種々のプラグインをサポートしています。これらの選択肢は、純粋なストレージの選択から、外部認証システムにわたり、現在は以下が含まれています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml416(para) msgid ""In-memory Key-Value Store"" msgstr ""インメモリキーバリューストア"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml419(para) msgid ""SQL database"" msgstr ""SQL データベース"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml422(para) msgid ""PAM"" msgstr ""PAM"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml425(para) msgid ""LDAP"" msgstr ""LDAP"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml428(para) msgid """" ""Many deployments use the SQL database, however LDAP is also a popular choice"" "" for those with existing authentication infrastructure that needs to be "" ""integrated."" msgstr ""多くのデプロイメントで SQL データベースが使われていますが、既存の認証インフラとインテグレーションする必要のある環境では、LDAP もポピュラーな選択肢です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml435(title) msgid ""Network Considerations"" msgstr ""ネットワークの考慮事項"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml436(para) msgid """" ""Because the cloud controller handles so many different services, it must be "" ""able to handle the amount of traffic that hits it. For example, if you "" ""choose to host the OpenStack Imaging Service on the cloud controller, the "" ""cloud controller should be able to support the transferring of the images at"" "" an acceptable speed."" msgstr ""クラウドコントローラーは非常に多くのサービスを取り扱うため、到来するトラフィックを処理できなければなりません。例えば、クラウドコントローラー上に OpenStack Image サービスを乗せることにした場合、そのクラウドコントローラーは許容可能な速度でイメージを転送できなければなりません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml442(para) msgid """" ""As another example, if you choose to use single-host networking where the "" ""cloud controller is the network gateway for all instances, then the Cloud "" ""Controller must support the total amount of traffic that travels between "" ""your cloud and the public Internet."" msgstr ""別の例としては、クラウドコントローラーがすべてのインスタンスのゲートウェイとなるような単一ホストネットワークモデルを使うことにした場合、クラウドコントローラーは外部インターネットとあなたのクラウドの間でやりとりされるすべてのトラフィックを支えられなければなりません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_cloud_controller.xml447(para) msgid """" ""We recommend that you use a fast NIC, such as 10 GB. You can also choose to "" ""use two 10 GB NICs and bond them together. While you might not be able to "" ""get a full bonded 20 GB speed, different transmission streams use different "" ""NICs. For example, if the Cloud Controller transfers two images, each image "" ""uses a different NIC and gets a full 10 GB of bandwidth."" msgstr ""10GbE のような高速な NIC を使うことを推奨します。また、10GbE NIC を2枚使って ボンディングすることもできます。束ねられた 20Gbps の速度をフルに使うことはできないかもしれませんが、異なる送信ストリームは異なる NIC を使います。例えば、クラウドコントローラーが2つのイメージを送信する場合、それぞれのイメージが別の NIC を使い、10Gbps の帯域をフルに使うことができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml17(para) msgid """" ""Compute nodes form the resource core of the OpenStack Compute cloud, "" ""providing the processing, memory, network and storage resources to run "" ""instances."" msgstr ""コンピュートノードは OpenStack Compute クラウドのリソースの中核を構成し、インスタンスを動作させるためのプロセッシング、メモリ、ネットワーク、ストレージの各リソースを提供します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml21(title) msgid ""CPU Choice"" msgstr ""CPU の選択"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml22(para) msgid """" ""The type of CPU in your compute node is a very important choice. First, "" ""ensure the CPU supports virtualization by way of <emphasis>VT-x</emphasis> "" ""for Intel chips and <emphasis>AMD-v</emphasis> for AMD chips."" msgstr ""コンピュートノードの CPU 種別は非常に重要な選択です。まず、CPU は Intel チップでは <emphasis>VT-x</emphasis>、 AMD チップでは <emphasis>AMD-v</emphasis> の仮想化に対応している必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml26(para) msgid """" ""The number of cores that the CPU has also affects the decision. It's common "" ""for current CPUs to have up to 12 cores. Additionally, if the CPU supports "" ""Hyper-threading, those 12 cores are doubled to 24 cores. If you purchase a "" ""server that supports multiple CPUs, the number of cores is further "" ""multiplied."" msgstr ""CPU のコア数も選択に影響します。最近のCPUでは最大12コアあるのが一般的です。さらに、CPU がハイパースレッディングをサポートしていれば、12コアは2倍の24コアになります。複数のCPUを持つサーバーを購入すれば、コア数はさらに掛け算で増えます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml32(para) msgid """" ""Whether you should enable hyper-threading on your CPUs depends upon your use"" "" case. We recommend you do performance testing with your local workload with"" "" both hyper-threading on and off to determine what is more appropriate in "" ""your case."" msgstr ""CPUでハイパースレッディングを有効にするかどうかはユースケースに依存します。ハイパースレッディングがオン、オフの両方の状態であなたの用途に応じた負荷で性能試験を行い、どちらがユースケースに適しているかを判断することをお薦めします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml40(title) msgid ""Hypervisor Choice"" msgstr ""ハイパーバイザーの選択"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml41(para) msgid """" ""OpenStack Compute supports many hypervisors to various degrees, including "" ""<link xlink:title=\""reference manual\"" xlink:href=\""http://www.linux-"" ""kvm.org/page/Main_Page\"">KVM</link>, <link xlink:title=\""reference manual\"" "" ""xlink:href=\""http://lxc.sourceforge.net/\"">LXC</link>, <link xlink:title=\""reference "" ""manual\"" xlink:href=\""http://wiki.qemu.org/Manual\"">QEMU</link>, <link "" ""xlink:title=\""reference manual\"" xlink:href=\""http://user-mode-"" ""linux.sourceforge.net/\"">UML</link>, <link xlink:title=\""reference manual\"" "" ""xlink:href=\""http://www.vmware.com/products/vsphere-"" ""hypervisor/support.html\"">VMWare ESX/ESXi</link>, <link xlink:title=\""reference "" ""manual\"" xlink:href=\""http://www.xen.org\"">Xen</link>, <link xlink:title=\""reference "" ""manual\"" "" ""xlink:href=\""http://www-03.ibm.com/systems/power/software/virtualization/features.html\"">PowerVM</link>,"" "" <link xlink:title=\""reference manual\"" xlink:href=\""http://www.microsoft.com/en-us"" ""/server-cloud/windows-server/server-virtualization-"" ""features.aspx\"">Hyper-V</link>."" msgstr ""OpenStack Compute は多数のハイパーバイザーをサポートしており、その程度も様々です。 サポートされているハイパーバイザーは、<link xlink:title=\""reference manual\"" xlink:href=\""http://www.linux-kvm.org/page/Main_Page\"">KVM</link>, <link xlink:title=\""reference manual\"" xlink:href=\""http://lxc.sourceforge.net/\"">LXC</link>, <link xlink:title=\""reference manual\"" xlink:href=\""http://wiki.qemu.org/Manual\"">QEMU</link>, <link xlink:title=\""reference manual\"" xlink:href=\""http://user-mode-linux.sourceforge.net/\"">UML</link>, <link xlink:title=\""reference manual\"" xlink:href=\""http://www.vmware.com/products/vsphere-hypervisor/support.html\"">VMWare ESX/ESXi</link>, <link xlink:title=\""reference manual\"" xlink:href=\""http://www.xen.org\"">Xen</link>, <link xlink:title=\""reference manual\"" xlink:href=\""http://www-03.ibm.com/systems/power/software/virtualization/features.html\"">PowerVM</link>, <link xlink:title=\""reference manual\"" xlink:href=\""http://www.microsoft.com/en-us/server-cloud/windows-server/server-virtualization-features.aspx\"">Hyper-V</link> です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml60(para) msgid """" ""Probably the most important factor in your choice of hypervisor is your "" ""current usage or experience. Aside from that, there are practical concerns "" ""to do with feature parity, documentation, and the level of community "" ""experience."" msgstr ""おそらく、ハイパーバイザーの選択で最も重要な要素は、現在の使用法やこれまでの経験でしょう。それ以外では、同等の機能の実用上の懸念、ドキュメント、コミュニティでの経験量などあると思います。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml65(para) msgid """" ""For example, KVM is the most widely adopted hypervisor in the OpenStack "" ""community. Besides KVM, more deployments exist running Xen, LXC, VMWare and "" ""Hyper-V than the others listed — however, each of these are lacking some "" ""feature support or the documentation on how to use them with OpenStack is "" ""out of date."" msgstr ""例えば、 KVM は OpenStack コミュニティでは最も多く採用されているハイパーバイザーです。 KVM 以外では、Xen、LXC、VMWare、Hyper-V を使っているシステムが、（サポート）リストにある他のハイパーバイザーよりは多いです。しかしながら、これらのハイパーバイザーはどれもある機能のサポートがなかったり、OpenStack と組み合わせての使い方に関するドキュメントが最新版に追従していなかったりします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml71(para) msgid """" ""The best information available to support your choice is found on the <link "" ""xlink:title=\""reference manual\"" "" ""xlink:href=\""https://wiki.openstack.org/wiki/HypervisorSupportMatrix\"">Hypervisor "" ""Support Matrix</link> "" ""(https://wiki.openstack.org/wiki/HypervisorSupportMatrix), and in the <link "" ""xlink:title=\""reference manual\"" xlink:href=\""http://docs.openstack.org/folsom"" ""/openstack-compute/admin/content/ch_hypervisors.html\"">reference "" ""manual</link> (http://docs.openstack.org/folsom/openstack-"" ""compute/admin/content/ch_hypervisors.html)."" msgstr ""ハイパーバイザー選択の参考になる情報は、<link xlink:title=\""reference manual\"" xlink:href=\""https://wiki.openstack.org/wiki/HypervisorSupportMatrix\"">Hypervisor Support Matrix</link> (https://wiki.openstack.org/wiki/HypervisorSupportMatrix) と <link xlink:title=\""reference manual\"" xlink:href=\""http://docs.openstack.org/folsom/openstack-compute/admin/content/ch_hypervisors.html\"">レファレンスマニュアル</link> (http://docs.openstack.org/folsom/openstack-compute/admin/content/ch_hypervisors.html) です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml81(para) msgid """" ""It is also possible to run multiple hypervisors in a single deployment using"" "" Host Aggregates or Cells. However, an individual compute node can only run "" ""a single hypervisor at a time."" msgstr ""ホストアグリゲートやセルを使うと一つの OpenStack システムで複数のハイパーバイザーを動かすこともできますが、一つのコンピュートノードで同時に実行できるのは1種類のハイパーバイザーだけです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml89(title) msgid ""Instance Storage Solutions"" msgstr ""インスタンスストレージのソリューション"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml90(para) msgid """" ""As part of the procurement for a compute cluster, you must specify some "" ""storage for the disk on which the instantiated instance runs. There are "" ""three main approaches to providing this temporary-style storage, and it is "" ""important to understand the implications of the choice."" msgstr ""コンピュートクラスタを調達する際に、作成したインスタンスの（仮想）ディスク用のストレージを決めなければいけません。この一時ストレージの提供方法には主に3つのアプローチがあり、その意味を理解することが重要です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml96(para) msgid ""They are:"" msgstr ""次の3つの方法があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml99(para) msgid ""Off compute node storage – shared file system"" msgstr ""コンピュートノード外のストレージ （共有ファイルシステム）"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml103(para) msgid ""On compute node storage – shared file system"" msgstr ""コンピュートノード上のストレージ （共有ファイルシステム）"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml107(para) msgid ""On compute node storage – non-shared file system"" msgstr ""コンピュートノード上のストレージ （非共有ファイルシステム）"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml111(para) msgid """" ""In general, the questions you should be asking when selecting the storage "" ""are as follows:"" msgstr ""一般的には、ストレージを選択する際には次のような質問をされます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml115(para) msgid ""What is the platter count you can achieve?"" msgstr ""実現したいプラッター数（ディスク容量）はどれくらいか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml119(para) msgid ""Do more spindles result in better I/O despite network access?"" msgstr ""ネットワークアクセスがあったとしても、ディスク数が多い方が良い I/O 性能が得られるか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml123(para) msgid """" ""Which one results in the best cost-performance scenario you're aiming for?"" msgstr ""何があなたが目指すコストパフォーマンスのシナリオはどれか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml127(para) msgid ""How do you manage the storage operationally?"" msgstr ""運用上ストレージをどのように管理したいのか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml132(title) msgid ""Off Compute Node Storage – Shared File System"" msgstr ""コンピュートノード外のストレージ （共有ファイルシステム）"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml134(para) msgid """" ""Many operators use separate compute and storage hosts. Compute services and "" ""storage services have different requirements, compute hosts typically "" ""require more CPU and RAM than storage hosts. Therefore, for a fixed budget, "" ""it makes sense to have different configurations for your compute nodes and "" ""your storage nodes with compute nodes invested in CPU and RAM, and storage "" ""nodes invested in block storage."" msgstr ""多くの運用者はコンピュートホストとストレージホストを分離して使用しています。コンピュートサービスとストレージサービスには異なる要件があり、コンピュートホストでは通常はストレージホストよりも多くのCPUとRAMが必要です。そのため、一定の予算の中では、コンピュートホストとストレージホストで異なる構成として、コンピュートホストに多くのCPUとRAMを持たせ、ストレージホストに多くのブロックストレージを持たせるのは、理にかなっています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml143(para) msgid """" ""Also, if you use separate compute and storage hosts then you can treat your "" ""compute hosts as \""stateless\"". This simplifies maintenance for the compute "" ""hosts. As long as you don't have any instances currently running on a "" ""compute host, you can take it offline or wipe it completely without having "" ""any effect on the rest of your cloud."" msgstr ""また、コンピュートホストとストレージホストを分離しておけば、コンピュートホストを「ステートレス」（状態を保持しないもの）として扱うことができます。これにより、コンピュートホストの管理を単純にすることができます。コンピュートホスト上で動作しているインスタンスがない限り、クラウドの他の部分に影響を与えずにそのノードをオフラインにしたり取り除いたりすることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml150(para) msgid """" ""However, if you are more restricted in the number of physical hosts you have"" "" available for creating your cloud and you want to be able to dedicate as "" ""many of your hosts as possible to running instances, it makes sense to run "" ""compute and storage on the same machines."" msgstr ""一方、クラウドの構築に使用できる物理ホスト数に制限があり、できるだけ多くのホストをインスタンスの実行に使えるようにしたい場合は、同じマシンでコンピュートホストとストレージホストを動作させるのは理にかなっています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml156(para) msgid """" ""In this option, the disks storing the running instances are hosted in "" ""servers outside of the compute nodes. There are also several advantages to "" ""this approach:"" msgstr ""この方法では、実行中のインスタンスの状態を格納するディスクはコンピュートホスト外のサーバーに置かれます。この方法には以下のようなメリットもあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml162(para) msgid ""If a compute node fails, instances are usually easily recoverable."" msgstr ""コンピュートホストが故障した場合、通常インスタンスは簡単に復旧できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml166(para) msgid ""Running a dedicated storage system can be operationally simpler."" msgstr ""専用のストレージシステムを動作させることで、運用がシンプルになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml170(para) msgid ""Being able to scale to any number of spindles."" msgstr ""ディスク数がスケーラブルになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml174(para) msgid ""It may be possible to share the external storage for other purposes."" msgstr ""外部ストレージを他の用途と共有できる可能性があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml179(para) msgid ""The main downsides to this approach are:"" msgstr ""この方法の主なマイナス面は以下の点です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml182(para) msgid """" ""Depending on design, heavy I/O usage from some instances can affect "" ""unrelated instances."" msgstr ""設計次第では、一部のインスタンスの I/O が非常に多い場合に、無関係のインスタンスに影響が出る場合があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml187(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml218(para) msgid ""Use of the network can decrease performance."" msgstr ""ネットワークを使用するため、性能低下が起こる可能性があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml193(title) msgid ""On Compute Node Storage – Shared File System"" msgstr ""コンピュートノード上のストレージ （共有ファイルシステム）"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml195(para) msgid """" ""In this option, each <code>nova-compute</code> node is specified with a "" ""significant amount of disks, but a distributed file system ties the disks "" ""from each compute node into a single mount. The main advantage of this "" ""option is that it scales to external storage when you require additional "" ""storage."" msgstr ""この方法では、各 <code>nova-compute</code> ノードには多数のディスクが接続されますが、分散ファイルシステムにより各コンピュートノードのディスクは1つのマウントポイントにまとめられます。この方法の主なメリットは、追加のストレージが必要になった際に外部ストレージを利用してスケールできる点です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml201(para) msgid ""However, this option has several downsides:"" msgstr ""しかし、この方法にはいくつかマイナス点があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml204(para) msgid """" ""Running a distributed file system can make you lose your data locality "" ""compared with non-shared storage."" msgstr ""分散ファイルシステムを動作させるため、非共有ストレージと比較してデータの局所性が失われます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml209(para) msgid ""Recovery of instances is complicated by depending on multiple hosts."" msgstr ""複数の物理ホストが関係するため、インスタンスの復旧が複雑になります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml213(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml250(para) msgid """" ""The chassis size of the compute node can limit the number of spindles able "" ""to be used in a compute node."" msgstr ""コンピュートノードの筐体サイズによって、コンピュートノードに搭載できるディスク数が制限されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml225(title) msgid ""On Compute Node Storage – Non-shared File System"" msgstr ""コンピュートノード上のストレージ （非共有ファイルシステム）"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml227(para) msgid """" ""In this option, each <code>nova-compute</code> node is specified with enough"" "" disks to store the instances it hosts. There are two main reasons why this "" ""is a good idea:"" msgstr ""この方法では、各 <code>nova-compute</code> ノードには、そのホストで動作するインスタンスを収容するのに十分な量のディスクが接続されます。この方法には次の2つのメリットがあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml233(para) msgid """" ""Heavy I/O usage on one compute node does not affect instances on other "" ""compute nodes."" msgstr ""あるコンピュートノード上での I/O が非常に多い場合でも、他のコンピュートノードのインスタンスに影響がありません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml238(para) msgid ""Direct I/O access can increase performance."" msgstr ""I/O アクセスが直接行われるので、性能向上が図れます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml243(para) msgid ""This has several downsides:"" msgstr ""この方法には次のようなマイナス点があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml246(para) msgid ""If a compute node fails, the instances running on that node are lost."" msgstr ""コンピュートノードが故障すると、そのノードで実行中のインスタンスが失われてしまいます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml255(para) msgid """" ""Migrations of instances from one node to another are more complicated, and "" ""rely on features which may not continue to be developed."" msgstr ""あるノードから別のノードへのインスタンスのマイグレーションが複雑になります。また、マイグレーション方法も開発が継続されるか分からない方法に依存することになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml261(para) msgid ""If additional storage is required, this option does not to scale."" msgstr ""追加のストレージが必要になった際に、この方法はスケールしません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml267(title) msgid ""Issues with Live Migration"" msgstr ""ライブマイグレーションに関する問題"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml268(para) msgid """" ""We consider live migration an integral part of the operations of the cloud. "" ""This feature provides the ability to seamlessly move instances from one "" ""physical host to another, a necessity for performing upgrades that require "" ""reboots of the compute hosts, but only works well with shared storage."" msgstr ""我々はライブマイグレーションはクラウドの運用に不可欠なものだと考えています。この機能により、インスタンスをある物理ホストから別の物理ホストに停止せずに移動し、コンピュートホストの再起動を必要とするアップグレードを実行することができるようになります。しかし、ライブマイグレーションを行うには共有ストレージがなければなりません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml274(para) msgid """" ""Live migration can be also done with non-shared storage, using a feature "" ""known as <emphasis>KVM live block migration</emphasis>. While an earlier "" ""implementation of block-based migration in KVM and QEMU was considered "" ""unreliable, there is a newer, more reliable implementation of block-based "" ""live migration as of QEMU 1.4 and libvirt 1.0.2 that is also compatible with"" "" OpenStack. However, none of the authors of this guide have first-hand "" ""experience using live block migration."" msgstr ""ライブマイグレーションは、<emphasis>KVM ライブブロックマイグレーション</emphasis>として知られる機能を用いて、非共有ストレージでも実行できます。以前のバージョンでの KVM と QEMU におけるブロックマイグレーションの実装は信頼性がないと思われていましたが、OpenStack とも互換性のある QEMU 1.4 と libvirt 1.0.2 には、信頼性が向上した新しいライブブロックマイグレーションの実装があります。しかしながら、このガイドの執筆陣は誰もライブブロックマイグレーションを使用したことがありません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml282(title) msgid ""Choice of File System"" msgstr ""ファイルシステムの選択"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml283(para) msgid """" ""If you want to support shared storage live migration, you'll need to "" ""configure a distributed file system."" msgstr ""共有ストレージを使ったライブマイグレーションをサポートしたい場合には、分散ファイルシステムを構成する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml286(para) msgid ""Possible options include:"" msgstr ""次のような選択肢があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml289(para) msgid ""NFS (default for Linux)"" msgstr ""NFS (Linux でのデフォルト)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml292(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1363(glossterm) msgid ""GlusterFS"" msgstr ""GlusterFS"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml295(para) msgid ""MooseFS"" msgstr ""MooseFS"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml298(para) msgid ""Lustre"" msgstr ""Lustre"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml301(para) msgid """" ""We've seen deployments with all, and recommend you choose the one you are "" ""most familiar with operating."" msgstr ""我々はこれら全ての実例を見たことがありますが、一番運用方法を知っているものを選択することをお薦めします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml308(title) msgid ""Overcommitting"" msgstr ""オーバーコミット"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml309(para) msgid """" ""OpenStack allows you to overcommit CPU and RAM on compute nodes. This allows"" "" you to increase the number of instances you can have running on your cloud,"" "" at the cost of reducing the performance of the instances. OpenStack Compute"" "" uses the following ratios by default:"" msgstr ""OpenStack では、コンピュートノードの CPU と RAM をオーバーコミットすることができます。これにより、インスタンスの性能が下がるものの、クラウド上で動作可能なインスタンス数を増やすことができます。 OpenStack Compute でのデフォルト値は次のようになっています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml316(para) msgid ""CPU allocation ratio: 16"" msgstr ""CPU 割当比: 16"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml319(para) msgid ""RAM allocation ratio: 1.5"" msgstr ""RAM 割当比: 1.5"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml322(para) msgid """" ""The default CPU allocation ratio of 16 means that the scheduler allocates up"" "" to 16 virtual cores on a node per physical cores. For example, if a "" ""physical node has 12 cores, and each virtual machine instance uses 4 virtual"" "" cores, the scheduler allocates up to 192 virtual cores to instances (such "" ""as, 48 instances, in the case where each instance has 4 virtual cores)."" msgstr ""CPU 割当比のデフォルト値 16 は、スケジューラーが1つのノードで物理コア1つあたり最大16個の仮想コアを割り当てることを意味します。例えば、ある物理ノードのコア数が12の場合、スケジューラが最大で192個の仮想コアをインスタンスに割り当てることになります (例えば、各インスタンスの仮想コアが4個の場合には、48インスタンス割り当てられます)。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml329(para) msgid """" ""Similarly, the default RAM allocation ratio of 1.5 means that the scheduler "" ""allocates instances to a physical node as long as the total amount of RAM "" ""associated with the instances is less than 1.5 times the amount of RAM "" ""available on the physical node."" msgstr ""同様に、RAM 割当比のデフォルト値 1.5 は、インスタンスに割り当てられた RAM の総量がその物理ノードで利用できるメモリ量の1.5倍未満であれば、スケジューラーがその物理ノードにインスタンスを割り当てることを意味します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml334(para) msgid """" ""For example, if a physical node has 48 GB of RAM, the scheduler allocates "" ""instances to that node until the sum of the RAM associated with the "" ""instances reaches 72 GB (such as nine instances, in the case where each "" ""instance has 8 GB of RAM)."" msgstr ""例えば、物理ノードに 48GB の RAM がある場合、そのノード上のインスタンスに割り当てられた RAM の合計が 72GB に達するまでは、スケジューラーはそのノードにインスタンスを割り振ることになります (例えば、各インスタンスのメモリが 8GB であれば、9 インスタンス割り当てられます)。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml339(para) msgid """" ""You must select the appropriate CPU and RAM allocation ratio for your "" ""particular use case."" msgstr ""あなた自身のユースケースに合わせて、適切な CPU と RAM の割当比を選択しなければなりません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml343(title) msgid ""Logging"" msgstr ""ロギング"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml344(para) msgid """" ""Logging is detailed more fully in <xref linkend=\""logging\""/>. However it is"" "" an important design consideration to take into account before commencing "" ""operations of your cloud."" msgstr ""ロギングについては <xref linkend=\""logging\""/> で詳しく説明しています。しかし、ロギングはクラウドの運用を開始前に考慮しておくべき重要な検討事項です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml348(para) msgid """" ""OpenStack produces a great deal of useful logging information, however, in "" ""order for it to be useful for operations purposes you should consider having"" "" a central logging server to send logs to, and a log parsing/analysis system"" "" (such as logstash)."" msgstr ""OpenStack は非常に多くの有用なログ情報を出力しますが、運用時にログ情報を有効活用するためには、ログを集積するログサーバーや、(logstash といった) ログ解析/分析システムを用意することを検討すべきでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml355(title) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml49(emphasis) msgid ""Networking"" msgstr ""ネットワーク"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_compute_nodes.xml356(para) msgid """" ""Networking in OpenStack is a complex, multi-faceted challenge. See <xref "" ""linkend=\""network_design\""/>."" msgstr ""OpenStack のネットワークは複雑で、検討すべき点がたくさんあります。 <xref linkend=\""network_design\""/> を参照して下さい。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml16(title) msgid ""Scaling"" msgstr ""スケーリング"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml17(para) msgid """" ""If your cloud is successful, eventually you must add resources to meet the "" ""increasing demand. OpenStack is designed to be horizontally scalable. Rather"" "" than switching to larger servers, you procure more servers. Ideally, you "" ""scale out and load balance among functionally-identical services."" msgstr ""あなたのクラウドが成功していれば、いずれ増加する需要に対応するためにリソースを追加しなければなりません。OpenStack は水平的にスケールできるよう設計されています。より大きなサーバーに取り換えるのではなく、もっと多くのサーバーを購入すればよいのです。理想的には、機能的に同一のサービス間でスケールアウトして負荷分散します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml23(title) msgid ""The Starting Point"" msgstr ""出発点"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml24(para) msgid """" ""Determining the scalability of your cloud and how to improve it is an "" ""exercise with many variables to balance. No one solution meets everyone's "" ""scalability aims. However, it is helpful to track a number of metrics."" msgstr ""クラウドのスケーラビリティを決定することと、それをどう改善するのかは、多くの変数のバランスをとる問題です。万人のスケーラビリティ目標に適した解決策は存在しませんが、いくつかの指標を観察しておくと役に立つでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml29(para) msgid """" ""The starting point for most is the core count of your cloud. By applying "" ""some ratios, you can gather information about the number of virtual machines"" "" (VMs) you expect to run <code>((overcommit fraction × cores) / virtual "" ""cores per instance)</code>, how much storage is required <code>(flavor disk "" ""size × number of instances)</code>. You can use these ratios to determine "" ""how much additional infrastructure you need to support your cloud."" msgstr ""ほとんどの場合の出発点は、クラウドのコア数です。なんらかの比率を掛けることにより、実行される仮想マシン(VM)の数の期待値についての情報を得られます。 <code>((オーバーコミット率 × cores) / インスタンスごとの仮想コア数)</code>, 必要なストレージ容量は <code>(フレーバーごとのディスクサイズ × インスタンス数)</code>. あなたのクラウドにどの程度の追加機材が必要なのか、これらの比率で判断することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml37(para) msgid ""The default OpenStack flavors are:"" msgstr ""OpenStack のデフォルトフレーバー:"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml41(th) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml171(para) msgid ""Name"" msgstr ""名前"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml42(th) msgid ""Virtual cores"" msgstr ""仮想コア数"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml43(th) msgid ""Memory"" msgstr ""メモリ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml44(th) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml188(para) msgid ""Disk"" msgstr ""ディスク"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml45(th) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml199(para) msgid ""Ephemeral"" msgstr ""エフェメラル"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml50(para) msgid ""m1.tiny"" msgstr ""m1.tiny"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml51(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml58(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml522(para) msgid ""1"" msgstr ""1"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml52(para) msgid ""512 MB"" msgstr ""512 MB"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml53(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml54(para) msgid ""0 GB"" msgstr ""0 GB"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml57(para) msgid ""m1.small"" msgstr ""m1.small"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml59(para) msgid ""2 GB"" msgstr ""2 GB"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml60(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml67(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml74(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml81(para) msgid ""10 GB"" msgstr ""10 GB"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml61(para) msgid ""20 GB"" msgstr ""20 GB"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml64(para) msgid ""m1.medium"" msgstr ""m1.medium"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml65(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml529(para) msgid ""2"" msgstr ""2"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml66(para) msgid ""4 GB"" msgstr ""4 GB"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml68(para) msgid ""40 GB"" msgstr ""40 GB"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml71(para) msgid ""m1.large"" msgstr ""m1.large"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml72(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml543(para) msgid ""4"" msgstr ""4"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml73(para) msgid ""8 GB"" msgstr ""8 GB"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml75(para) msgid ""80 GB"" msgstr ""80 GB"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml78(para) msgid ""m1.xlarge"" msgstr ""m1.xlarge"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml79(para) msgid ""8"" msgstr ""8"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml80(para) msgid ""16 GB"" msgstr ""16 GB"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml82(para) msgid ""160 GB"" msgstr ""160 GB"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml87(para) msgid """" ""Assume that the following set-up supports (200 / 2) × 16 = 1600 VM instances"" "" and requires 80 TB of storage for <code>/var/lib/nova/instances</code>:"" msgstr ""以下の構築例では、 (200 / 2) × 16 = 1600 VM インスタンスをサポートし、 <code>/var/lib/nova/instances</code> 以下に80TBのストレージ領域が必要なものとします:"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml92(para) msgid ""200 physical cores"" msgstr ""200物理コア"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml95(para) msgid ""Most instances are size m1.medium (2 virtual cores, 50 GB of storage)"" msgstr ""ほとんどのインスタンスのサイズは m1.medium (仮想コア数2、ストレージ50GB)とします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml99(para) msgid """" ""Default CPU over-commit ratio (<code>cpu_allocation_ratio</code> in "" ""nova.conf) of 16:1"" msgstr ""デフォルトの CPU オーバーコミット率 (<code>cpu_allocation_ratio</code> in nova.conf) は 16:1 とします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml104(para) msgid """" ""However, you need more than the core count alone to estimate the load that "" ""the API services, database servers, and queue servers are likely to "" ""encounter. You must also consider the usage patterns of your cloud."" msgstr ""しかし、APIサービスやデータベースサーバー、MQサーバーがおそらく遭遇する負荷を見積もるためには、コア数以外の検討も行う必要があります。クラウドの利用パターンも考慮しなければなりません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml108(para) msgid """" ""As a specific example, compare a cloud that supports a managed web hosting "" ""platform with one running integration tests for a development project that "" ""creates one VM per code commit. In the former, the heavy work of creating a "" ""VM happens only every few months, whereas the latter puts constant heavy "" ""load on the cloud controller. You must consider your average VM lifetime, as"" "" a larger number generally means less load on the cloud controller."" msgstr ""特定の例としては、マネージドWebホスティングプラットフォームをサポートするクラウドと、コードコミットごとに仮想マシンを１つ作成するような開発プロジェクト用の結合テストを動かしているクラウドを比較してみましょう。前者では、VMを作成する重い処理は数か月に一度しか発生しないのに対して、後者はクラウドコントローラーに定常的に重い処理を発生させます。一般論として、VMの平均寿命が長いということは、クラウドコントローラーの負荷が軽いことを意味するため、平均的なVMの寿命を検討しなければなりません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml117(para) msgid """" ""Aside from the creation and termination of VMs, you must consider the impact"" "" of users accessing the service — particularly on nova-api and its "" ""associated database. Listing instances garners a great deal of information "" ""and, given the frequency with which users run this operation, a cloud with a"" "" large number of users can increase the load significantly. This can even "" ""occur without their knowledge — leaving the OpenStack Dashboard instances "" ""tab open in the browser refreshes the list of VMs every 30 seconds."" msgstr ""仮想マシンの起動、停止以外では、ユーザーアクセス、特に nova-api と関連データベースへのアクセスの影響を検討しなければなりません。インスタンス一覧を取得する処理は膨大な量の情報を収集しますし、ユーザーがこの処理を頻繁に行うと、ユーザー数が多いクラウドではこの負荷が著しく上昇します。この負荷は、ユーザーが知らずに発生します。つまり、ブラウザのOpenStack ダッシュボードのインスタンスタブを開いたままにすると、30秒ごとに仮想マシンの一覧が更新されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml127(para) msgid """" ""After you consider these factors, you can determine how many cloud "" ""controller cores you require. A typical 8 core, 8 GB of RAM server is "" ""sufficient for up to a rack of compute nodes — given the above caveats."" msgstr ""これらの要素を検討した後、クラウドコントローラーにどのくらいのコア数が必要なのか決定することができます。上記の注意事項において、典型的には、ラック1本分のコンピュートノードに対して8コア、メモリ8GBのサーバーで充分です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml131(para) msgid """" ""You must also consider key hardware specifications for the performance of "" ""user VMs. You must consider both budget and performance needs. Examples "" ""include: Storage performance (spindles/core), memory availability "" ""(RAM/core), network bandwidth (Gbps/core), and overall CPU performance "" ""(CPU/core)."" msgstr ""ユーザーの仮想マシンの性能のために、ハードウェアのキーになるスペックも考慮に入れなければなりません。予算と性能への需要を検討するのです。例としては、ストレージ性能(スピンドル / コア)、メモリ(メモリ量 / コア)、ネットワーク帯域(Gbps / コア)、そして全般的なCPU性能 (CPU / コア)です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml137(para) msgid """" ""For which metrics to track to determine how to scale your cloud, see <xref "" ""linkend=\""logging_monitoring\""/>."" msgstr ""クラウドをどうスケールさせるのか決定するために観察すべき指標については、<xref linkend=\""logging_monitoring\""/> を参照してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml143(title) msgid ""Adding Controller Nodes"" msgstr ""コントローラーノードの追加"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml144(para) msgid """" ""You can facilitate the horizontal expansion of your cloud by adding nodes. "" ""Adding compute nodes is straightforward — they are easily picked up by the "" ""existing installation. However, you must consider some important points when"" "" you design your cluster to be highly available."" msgstr ""クラウドの水平的な拡張は、ノード追加によって容易に実行することができます。コンピュートノードの追加は簡単です。新規のコンピュートノードは既存のシステムから簡単に認識されます。しかし、クラスタを高可用なものにするためには、設計の際にいくつかの重要なポイントを検討しなければなりません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml150(para) msgid """" ""Recall that a cloud controller node runs several different services. You can"" "" install services that communicate only using the message queue internally —"" "" <code>nova-scheduler</code> and <code>nova-console</code> — on a new server"" "" for expansion. However, other integral parts require more care."" msgstr ""クラウドコントローラーは、いくつかの異なるサービスを実行することを思い出してください。拡張のための新しいサーバーには、 <code>nova-scheduler</code> や <code>nova-console</code> のようなメッセージキューを用いて内部でのみ通信するサービスをインストールすることができます。しかし、他の不可欠な部分についてはもっと注意が必要です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml157(para) msgid """" ""You should load balance user-facing services such as Dashboard, <code>nova-"" ""api</code> or the Object Storage proxy. Use any standard HTTP load balancing"" "" method (DNS round robin, hardware load balancer, software like Pound or "" ""HAProxy). One caveat with Dashboard is the VNC proxy, which uses the "" ""WebSocket protocol — something that a L7 load balancer might struggle with. "" ""See also <link xlink:title=\""Horizon session storage\"" "" ""xlink:href=\""http://docs.openstack.org/developer/horizon/topics/deployment.html"" ""#session-storage\"">Horizon session storage</link> "" ""(http://docs.openstack.org/developer/horizon/topics/deployment.html#session-"" ""storage)."" msgstr ""ダッシュボードや<code>nova-api</code> 、Object Storage proxy のようなユーザー向けのサービスは負荷分散するべきです。任意の標準的なHTTP負荷分散方法 (DNSラウンドロビン、ハードウェアロードバランサ、Pound や HAProxy のようなソフトウェア) を使ってください。ダッシュボードに関する注意事項の一つは、VNC proxy が使う WebSocket プロトコルです。これは、L7ロードバランサで苦労することになるかもしれません。以下のリンクも参照してください。 <link xlink:title=\""Horizon session storage\"" xlink:href=\""http://docs.openstack.org/developer/horizon/topics/deployment.html#session-storage\"">Horizon session storage</link> (http://docs.openstack.org/developer/horizon/topics/deployment.html#session-storage)."" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml168(para) msgid """" ""You can configure some services, such as <code>nova-api</code> and <code"" "">glance-api</code>, to use multiple processes by changing a flag in their "" ""configuration file — allowing them to share work between multiple cores on "" ""the one machine."" msgstr ""<code>nova-api</code> や <code>glance-api</code> のようなサービスは、設定ファイルのフラグを変更することによって複数プロセスで処理させるように設定できます。これによって一台のサーバの複数のコアの間で処理を共有できるようになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml173(para) msgid """" ""Several options are available for MySQL load balancing, and RabbitMQ has in-"" ""built clustering support. Information on how to configure these and many of "" ""the other services can be found in the<emphasis role=\""bold\""> Operations "" ""Section.</emphasis>"" msgstr ""MySQLの負荷分散にはいくつかのオプションがありますし、RabbitMQ はクラスタリング機能を持っています。これらや他の多くのサービスの設定方法に関する情報は<emphasis role=\""bold\"">運用の章</emphasis>で見つけることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml182(title) msgid ""Segregating Your Cloud"" msgstr ""クラウドの分離"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml183(para) msgid """" ""Use one of the following OpenStack methods to segregate your cloud: "" ""<emphasis>cells</emphasis>, <emphasis>regions</emphasis>, "" ""<emphasis>zones</emphasis> and <emphasis>host aggregates</emphasis>. Each "" ""method provides different functionality, as described in the following "" ""table:"" msgstr ""クラウドを分離するためには、次に挙げる OpenStack の方法を使います。 <emphasis>セル</emphasis>, <emphasis>リージョン</emphasis>, <emphasis>ゾーン</emphasis> そして<emphasis>ホストアグリゲート</emphasis> です。これらは以下の表で述べるように、それぞれ異なる機能を提供します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml193(th) msgid ""Cells"" msgstr ""セル"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml194(th) msgid ""Regions"" msgstr ""リージョン"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml195(th) msgid ""Availability Zones"" msgstr ""アベイラビリティゾーン"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml196(th) msgid ""Host Aggregates"" msgstr ""ホストアグリゲート"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml201(emphasis) msgid ""Use when you need"" msgstr ""用途"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml204(para) msgid """" ""A single <glossterm>API endpoint</glossterm> for compute, or you require a "" ""second level of scheduling."" msgstr ""コンピュート資源に対する単一の <glossterm>API エンドポイント</glossterm>、もしくは２段階スケジューリングが必要な場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml208(para) msgid """" ""Discrete regions with separate API endpoints and no coordination between "" ""regions."" msgstr ""リージョンごとに別々のAPIエンドポイントが必要で、リージョン間で協調する必要がない場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml211(para) msgid """" ""Logical separation within your nova deployment for physical isolation or "" ""redundancy."" msgstr ""物理的な隔離や冗長性のために、Nova デプロイメントの中で論理的な分離が必要な場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml214(para) msgid ""To schedule a group of hosts with common features."" msgstr ""共通の機能を持ったホストのグループに対してスケジューリングしたい場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml218(emphasis) msgid ""Example"" msgstr ""例"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml220(para) msgid """" ""A cloud with multiple sites where you can schedule VMs \""anywhere\"" or on a "" ""particular site."" msgstr ""複数サイトで構成されるクラウドで、仮想マシンを「任意のサイト」または特定のサイトにスケジューリングしたい場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml223(para) msgid """" ""A cloud with multiple sites, where you schedule VMs to a particular site and"" "" you want a shared infrastructure."" msgstr ""複数サイトで構成されるクラウドで、仮想マシンを特定のサイトに対してスケジューリングでき、かつ共有インフラを利用したい場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml226(para) msgid ""A single site cloud with equipment fed by separate power supplies."" msgstr ""単一サイトのクラウドで、分離された電源供給ラインを持つ設備で構成される場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml228(para) msgid ""Scheduling to hosts with trusted hardware support."" msgstr ""トラステッドコンピューティング機能に対応したホスト群に対してスケジューリングしたい場合"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml233(emphasis) msgid ""Overhead"" msgstr ""オーバーヘッド"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml238(para) msgid ""A new service, <code>nova-cells</code>"" msgstr ""<code>nova-cells</code> という新しいサービスが必要"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml242(para) msgid ""Each cell has a full nova installation except <code>nova-api</code>"" msgstr ""各セルには <code>nova-api</code> 以外の全 nova サービスが必要"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml251(para) msgid ""A different API endpoint for every region."" msgstr ""リージョン毎に別々のAPIエンドポイントが必要"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml255(para) msgid ""Each region has a full nova installation."" msgstr ""各リージョンにフルセットのNovaサービスが必要"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml263(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml271(para) msgid ""Configuration changes to nova.conf"" msgstr ""nova.conf の設定変更が必要"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml278(emphasis) msgid ""Shared services"" msgstr ""共有サービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml281(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml283(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml284(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml286(para) msgid ""Keystone"" msgstr ""Keystone"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml281(code) msgid ""nova-api"" msgstr ""nova-api"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml284(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml286(para) msgid ""All nova services"" msgstr ""すべての Nova サービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml291(para) msgid """" ""This array of options can be best divided into two — those which result in "" ""running separate nova deployments (cells and regions), and those which "" ""merely divide a single deployment (<glossterm>availability zone</glossterm>s"" "" and host aggregates)."" msgstr ""この選択肢の表は２つに分けると一番良く理解することができます。１つは、別々の Nova デプロイメントが動作します (セルとリージョン)。もう一つは、単一の Nova デプロイメントを分割するだけです。(<glossterm>アベイラビリテイゾーン</glossterm>とホストアグリゲート)."" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml298(title) msgid ""Cells and Regions"" msgstr ""セルとリージョン"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml299(para) msgid """" ""OpenStack Compute cells are designed to allow running the cloud in a "" ""distributed fashion without having to use more complicated technologies, or "" ""being invasive to existing nova installations. Hosts in a cloud are "" ""partitioned into groups called <emphasis>cells</emphasis>. Cells are "" ""configured in a tree. The top-level cell (\""API cell\"") has a host that runs"" "" the <code>nova-api</code> service, but no <code>nova-compute</code> "" ""services. Each child cell runs all of the other typical <code>nova-*</code> "" ""services found in a regular installation, except for the <code>nova-"" ""api</code> service. Each cell has its own message queue and database "" ""service, and also runs <code>nova-cells</code> — which manages the "" ""communication between the API cell and child cells."" msgstr ""OpenStack Compute のセルは、より複雑な技術を持ち込むことなしに、また既存のNovaシステムに悪影響を与えることなしに、クラウドを分散された環境で運用することができるように設計されています。１つのクラウドの中のホストは、<emphasis>セル</emphasis>と呼ばれるグループに分割されます。セルは、木構造に構成されてます。最上位のセル (「API セル」) は<code>nova-api</code>サービスを実行するホストを持ちますが、<code>nova-compute</code> サービスを実行するホストは持ちません。それぞれの子セルは、<code>nova-api</code>サービス以外の、普通のNovaシステムに見られる他のすべての典型的な <code>nova-*</code> サービスを実行します。それぞれのセルは自分のメッセージキューとデータベースサービスを持ち、またAPIセルと子セルの間の通信を制御する<code>nova-cells</code>サービスを実行します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml315(para) msgid """" ""This allows for a single API server being used to control access to multiple"" "" cloud installations. Introducing a second level of scheduling (the cell "" ""selection), in addition to the regular <code>nova-scheduler</code> selection"" "" of hosts, provides greater flexibility to control where virtual machines "" ""are run."" msgstr ""これによって、複数のクラウドシステムに対するアクセスを、１つのAPIサーバで制御することができます。通常の<code>nova-scheduler</code>によるホストの選択に加えて、第二段階のスケジューリング(セルの選択)を導入することにより、仮想マシンを実行する場所の制御の柔軟性が大きく向上します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml322(para) msgid """" ""Contrast this with regions. Regions have a separate API endpoint per "" ""installation, allowing for a more discrete separation. Users wishing to run "" ""instances across sites have to explicitly select a region. However, the "" ""additional complexity of a running a new service is not required."" msgstr ""セルをリージョンと比較してみましょう。リージョンは、クラウドごとに別々のAPIエンドポイントを持ち、より関連性の低い分離を実現できます。サイトをまたがってインスタンスを実行したいユーザーは、明示的にリージョンを指定しなければなりません。しかし、新しいサービスを実行するという、さらなる複雑さは必要ありません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml328(para) msgid """" ""The OpenStack Dashboard (Horizon) currently only uses a single region, so "" ""one dashboard service should be run per region. Regions are a robust way to "" ""share some infrastructure between OpenStack Compute installations, while "" ""allowing for a high degree of failure tolerance."" msgstr ""現在のところ、OpenStack ダッシュボード (Horizon) は１つのリージョンだけを操作対象とします。したがって、リージョンごとにダッシュボードサービスを実行するべきです。リージョンは、高度な故障耐性を実現しつつ、複数の OpenStack Compute のシステム間でインフラのいくらかの部分を共有するための堅牢な方法です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml336(title) msgid ""Availability Zones and Host Aggregates"" msgstr ""アベイラビリティゾーンとホストアグリゲート"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml337(para) msgid """" ""Both availability zones and host aggregates partition a single nova "" ""deployment. While seeming similar to configure, host aggregates and "" ""availability zones differ in their intended use. The former allows the "" ""partition of OpenStack Compute deployments into logical groups for load "" ""balancing and instance distribution, the latter are used to provide some "" ""form of physical isolation and redundancy from other availability zones "" ""(such as by using separate power supply or network equipment). Host "" ""aggregates can be regarded as a mechanism to further partitioning an "" ""availability zone, i.e. into multiple groups of hosts that share common "" ""resources like storage and network, or have a special property such as "" ""trusted computing hardware."" msgstr ""アベイラビリティゾーンとホストアグリゲートは、いずれも単一の Nova デプロイメントを分割します。設定方法は同じように見えますが、ホストアグリゲートはその使用目的の点でアベイラビリティゾーンとは異なります。ホストアグリゲートは、負荷分散とインスタンスの分散配置のために、OpenStack Compute のデプロイメントを論理グループに分割します。アベイラビリティゾーンは、(独立した電源系統やネットワーク装置などを使って)他のアベイラビリティゾーンとの物理的な分離や冗長性を実現するために使用します。ホストアグリゲートは、アベリラビリティゾーンをさらに分割するしくみだと考えることができます。すなわち、ストレージやネットワークのようなリソースを共有するホストや、トラステッドコンピューティングハードウェアのような特別な性質を備えたホストを複数のグループに分割するしくみです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml352(para) msgid """" ""A common use of host aggregates is to provide information for use with the "" ""<code>nova-scheduler</code>. For example, limiting specific flavours or "" ""images to a subset of hosts."" msgstr ""ホストアグリゲートのよくある使い方は<code>nova-scheduler</code>サービスに情報を提供することです。例えば、特定のフレーバーやイメージの実行を一部のホストに制限することなどです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml357(para) msgid """" ""Availability zones allow you to arrange sets of either OpenStack Compute or "" ""OpenStack Block Storage hosts into logical groups. You define the "" ""availability zone that a given Compute or block Storage host is in locally "" ""on each server. Availability zones are commonly used to identify a sets of "" ""servers that have some common attribute. For instance, if some of the racks "" ""in your data center are on a separate power source, you may put servers in "" ""those racks in their own availability zone. Availability zones can also be "" ""helpful for separating out different classes of hardware. This is especially"" "" helpful with OpenStack Block Storage where you may have storage servers "" ""with different types of hard drives. When provisioning resources, users can "" ""specify what availability zone they would like their instance or volume to "" ""come from. This allows cloud consumers to ensure that their application "" ""resources are spread across multiple disparate machines to achieve high "" ""availability in the event of hardware failure."" msgstr ""アベイラビリティゾーンによって、OpenStack Compute ホストや OpenStack Block Storage ホストの集合をそれぞれ論理的なグループに分割して配置することができます。ある Compute や Block Storage のホストが各サーバーで局所的になるようにアベリラビリティゾーンを定義します。一般に、アベイラビリティゾーンは共通の性質をもつサーバの集合を識別するために使われます。例えば、データセンタの一部のラック群が別々の電源系統の上にあるとしたら、それらのラック群に設置されたサーバを独立したアベイラビリティゾーンに配置してもよいでしょう。また、アベイラビリティゾーンは異なるクラスのハードウェアを分離するのに使うことができます。これは特に、異なるタイプのハードディスクを持つストレージサーバーで構成される OpenStack Block Storage の場合に有用です。ユーザーは、リソースを割り当てる際、どのアベイラビリティゾーンのインスタンスやボリュームを使いたいのか、指定することができます。これによって、アプリケーションのリソースを異なるマシンに分散することを保証でき、ハードウェア故障が発生しても高可用性を達成することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml380(title) msgid ""Scalable Hardware"" msgstr ""スケーラブルハードウェア"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml381(para) msgid """" ""While several resources already exist to help with deploying and installing "" ""OpenStack, it's very important to make sure you have your deployment planned"" "" out ahead of time. This guide expects at least a rack has been set aside "" ""for the OpenStack cloud but also offers suggestions for when and what to "" ""scale."" msgstr ""OpenStack をインストールしてデプロイするのに有用な情報源が既にいくらか存在していますが、自分のデプロイメントで事前に計画を立てておくことは非常に重要です。このガイドでは、OpenStack用にラックを少なくとも１本用意しておくことを想定してしますが、いつ、何をスケールさせるのかについてのアドバイスも行っています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml388(title) msgid ""Hardware Procurement"" msgstr ""ハードウェア調達"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml389(para) msgid """" ""“The Cloud” has been described as a volatile environment where servers can "" ""be created and terminated at will. While this may be true, it does not mean "" ""that your servers must be volatile. Ensuring your cloud’s hardware is stable"" "" and configured correctly means your cloud environment remains up and "" ""running. Basically, put effort into creating a stable hardware environment "" ""so you can host a cloud that users may treat as unstable and volatile."" msgstr ""「クラウド」とは、サーバーが作成されたり終了されたりするという揮発性の環境であると説明されてきました。これは正しいかもしれませんが、あなたのサーバーが揮発性でなければならないという意味ではありません。クラウドを構成するハードウェアを安定させ、正しく設定されていることを保障するということは、あなたのクラウド環境が稼働中であり動作していることを意味します。基本的に、ユーザーが必要な時に確保でき揮発性なものとして扱えるようなクラウドを運営できるよう、安定したハードウェア環境を作ることに注力してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml398(para) msgid """" ""OpenStack can be deployed on any hardware supported by an OpenStack-"" ""compatible Linux distribution, such as Ubuntu 12.04 as used in this books' "" ""reference architecture."" msgstr ""OpenStack は、この本の参考アーキテクチャで使われている Ubuntu 12.04 のように、OpenStack と互換性のある Linux ディストリビューションでサポートされたハードウェアにデプロイできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml402(para) msgid """" ""Hardware does not have to be consistent, but should at least have the same "" ""type of CPU to support instance migration."" msgstr ""ハードウェアはまったく同じでなければいけないことはありませんが、少なくともインスタンスマイグレーションが可能であるような同じタイプのCPUを装備しているべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml405(para) msgid """" ""The typical hardware recommended for use with OpenStack is \""commodity\"". "" ""That is, very standard \""value-for-money\"" offerings that most hardware "" ""vendors stock. It should be straightforward to divide your procurement into "" ""building blocks such as \""compute,\"" \""object storage,\"" and \""cloud "" ""controller,\"" and request as many of these as desired. Alternately should "" ""you be unable to spend more, if you have existing servers, provided they "" ""meet your performance requirements and virtualization technology, these are "" ""quite likely to be able to support OpenStack."" msgstr ""OpenStack に使うのに推奨される典型的なハードウェアは「コモディティ」です。つまり、とても標準的な「金額に見合う価値」をもった、ほとんどのハードウェアベンダが提供するようなものです。調達を「コンピュート」や｢オブジェクトストレージ」そして「クラウドコントローラー」のような構成要素に分割し、それぞれ必要な数だけ要求するのは分かりやすい方法でしょう。これ以上費用をかけることができない場合でも、代わりに、もし既存のサーバーがあって、これらが性能や仮想化技術の要件を満たしていれば、高い確率で OpenStack を動作させられます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml418(title) msgid ""Capacity Planning"" msgstr ""キャパシティプランニング"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml419(para) msgid """" ""OpenStack is designed to increase in size in a straightforward manner. "" ""Taking into account the considerations in the <emphasis "" ""role=\""bold\"">Scalability</emphasis> chapter — particularly on the sizing of"" "" the cloud controller, it should be possible to procure additional compute "" ""or object storage nodes as needed. New nodes do not need to be the same "" ""specification, or even vendor, as existing nodes."" msgstr ""OpenStackは、単純な方法でサイズを拡大できるように設計されています。 <emphasis role=\""bold\"">スケーラビリティ</emphasis> の章の、特にクラウドコントローラーのサイジングに関する検討を考慮に入れ、必要に応じて追加のコンピュートノードやオブジェクトストレージノードを調達できるようにすべきです。新しいノードは、既存ノードと同じスペックである必要はありませんし、同じベンダーである必要すらありません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml428(para) msgid """" ""For compute nodes, <code>nova-scheduler</code> will take care of differences"" "" in sizing to do with core count and RAM amounts, however you should "" ""consider the user experience changes with differing CPU speeds. When adding "" ""object storage nodes, a <glossterm>weight</glossterm> should be specified "" ""that reflects the <glossterm>capability</glossterm> of the node."" msgstr ""コンピュートノードについては、<code>nova-scheduler</code> がコア数やメモリ量のサイジングに関する違いを吸収しますが、CPUの速度が違うことによって、ユーザーの使用感が変わることを考慮するべきです。オブジェクトストレージノードを追加する際には、 そのノードの<glossterm>capability</glossterm> を反映する<glossterm>weight</glossterm> を指定するべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml436(para) msgid """" ""Monitoring the resource usage and user growth will enable you to know when "" ""to procure. The <emphasis role=\""bold\"">Monitoring</emphasis> chapter "" ""details some useful metrics."" msgstr ""リソース利用状況の監視とユーザー増加の監視によって、（追加機材の）調達時期を知ることができます。<emphasis role=\""bold\"">監視</emphasis>の章でいくつかの有用な監視項目を詳しく解説します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml442(title) msgid ""Burn-in Testing"" msgstr ""エージング試験"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_scaling.xml443(para) msgid """" ""Server hardware's chance of failure is high at the start and the end of its "" ""life. As a result, much effort in dealing with hardware failures while in "" ""production can be avoided by appropriate burn-in testing to attempt to "" ""trigger the early-stage failures. The general principle is to stress the "" ""hardware to its limits. Examples of burn-in tests include running a CPU or "" ""disk benchmark for several days."" msgstr ""サーバーは、そのライフタイムの最初と最後にハードウェア故障の確率が高くなります。結論として、初期故障を誘発する適切なエージングテストを行うことによって、運用中の故障に対応するための多くの労力を避けることができます。一般的な原則は、限界まで負荷をかけることです。エージング試験の例としては、数日間にわたってCPUやディスクベンチマークを走行させることが含まれます。"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml86(None) msgid """" ""@@image: 'figures/1-IMG_4895.JPG'; md5=fa6e602f909a462f29afd9596a8aa998"" msgstr ""@@image: 'figures/1-IMG_4895.JPG'; md5=fa6e602f909a462f29afd9596a8aa998"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml16(title) msgid ""Preface"" msgstr ""はじめに"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml17(para) msgid """" ""OpenStack is an open source platform that lets you build an Infrastructure "" ""as a Service (IaaS) cloud that runs on commodity hardware. OpenStack is "" ""designed for scalability, so you can easily add new compute and storage "" ""resources to grow your cloud over time. Organizations such as HP and "" ""Rackspace have built massive public clouds on top of OpenStack."" msgstr ""OpenStack はオープンソースプラットフォームで、OpenStack を使うと、コモディティハードウェア上で動作する Infrastructure as a Service (IaaS) クラウドを自分で構築できます。OpenStack はスケーラビリティを意識して設計されており、運用するクラウドが大きくなるのに合わせて新しいコンピュートノードやストレージノードを簡単に追加することができます。 HP や Rackspace などの組織では、OpenStack を使って巨大なパブリッククラウドを構築しています。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml23(para) msgid """" ""OpenStack is more than a software package that you run as-is. It lets you "" ""integrate a number of different technologies to construct a cloud. This "" ""approach provides great flexibility, but the number of options might be "" ""bewildering at first."" msgstr ""OpenStack は、そのまま実行する単なるソフトウェアパッケージではなく、数多くの様々な技術を組み合わせてクラウドを構築することができます。このアプローチは非常に柔軟性がありますが、このため多くの選択肢があり最初は面食らうかもしれません。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml28(para) msgid """" ""This guide assumes that you are familiar with the Ubuntu distribution of "" ""Linux, SQL databases, and virtualization. You must be comfortable "" ""administering and configuring multiple Linux machines for networking. You "" ""must install and maintain a MySQL database, and occasionally run SQL queries"" "" against it. One of the most complex aspects of an OpenStack cloud is the "" ""networking configuration. You should be familiar with concepts such as DHCP,"" "" Linux bridges, VLANs, and iptables. You must also have access to a network "" ""hardware expert who can configure the switches and routers required in your "" ""OpenStack cloud."" msgstr ""このガイドは、Linux ディストリビューションの Ubuntu、SQL データベースや仮想化に関してよく知っていることを前提にしています。複数台の Linux マシンのネットワーク設定・管理にも慣れている必要があります。MySQL データベースのインストールと管理を行い、場合によってはデータベースに対して SQL クエリーを実行することもあります。OpenStack クラウドの最も複雑な点の一つにネットワーク設定があります。DHCP、Linux ブリッジ、VLAN、iptables といった考え方をよく理解していなければなりません。OpenStack クラウドで必要となるスイッチやルータを設定できるネットワークハードウェアの専門家と話をする必要もあります。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml44(title) msgid ""Why and How We Wrote This Book"" msgstr ""この本をなぜ書いたか？どうやって書いたか？"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml45(para) msgid """" ""We wrote this book because we have deployed and maintained OpenStack clouds "" ""for at least a year, and wanted to be able to distribute this knowledge to "" ""others. After months of being the point people for an OpenStack cloud, we "" ""also wanted to have a document to hand to our system administrators so "" ""they'd know how to operate the cloud on a daily basis — both reactively and "" ""proactively. We wanted to provide more detailed technical information about "" ""the decisions that deployers make along the way."" msgstr ""私たちは少なくとも1年以上 OpenStack クラウドを構築し運用してきました。そこで得られた知識を多くの人と共有するために、この本を書きました。 OpenStack クラウドの責任者として数ヶ月がたつと、そのドキュメントを渡しておけば、システム管理者に日々のクラウドの運用をどのように行なえばよいかが分かるようなドキュメントが欲しくなりました。また、クラウドを構築する際に選択したやり方のより詳細な技術情報を共有したいと思いました。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml59(para) msgid """" ""Design and create an architecture for your first non-trivial OpenStack "" ""cloud. After you read this guide, you'll know which questions to ask and how"" "" to organize your compute, networking, storage resources, and the associated"" "" software packages."" msgstr ""初めての本格的な OpenStack クラウドのアーキテクチャの設計と構築。この本を読み終えると、コンピュート、ネットワーク、ストレージリソースを選ぶにはどんな質問を自分にすればよいのか、どのように組み上げればよいのかや、どんなソフトウェアパッケージが必要かが分かることでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml67(para) msgid ""Perform the day-to-day tasks required to administer a cloud."" msgstr ""クラウドを管理する上で必要となる日々のタスクの実行。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml56(para) msgid ""We wrote this book to help you:<placeholder-1/>"" msgstr ""次のような場面であなたの助けとなるように、この本を書きました。<placeholder-1/>"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml72(para) msgid """" ""We wrote this book in a Book Sprint, which is a facilitated rapid "" ""development production method for books. For more information see the <link "" ""xlink:title=\""Foundation web site\"" xlink:href=\""http://www.booksprints.net\"">Book "" ""Sprint site</link>. Your authors cobbled this book together in five days "" ""during February 2013, fueled by caffeine and the best take-out food that "" ""Austin, Texas could offer."" msgstr ""私たちはこの本を Book Sprint で執筆しました。 Book Sprint は短い期間で本を建設的に作成できるメソッドです。詳しい情報は、 <link xlink:title=\""Foundation web site\"" xlink:href=\""http://www.booksprints.net\"">Book Sprint のサイト</link> を参照して下さい。著者らは2013年2月の5日間でこの本をまとめあげました。カフェインと、テキサス州オースティンの素晴らしいテイクアウトの食事は力になりました。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml80(para) msgid """" ""On the first day we filled white boards with colorful sticky notes to start "" ""to shape this nebulous book about how to architect and operate clouds. "" ""<placeholder-1/>"" msgstr ""最初の日に、アイデアを色とりどりのポストイットでホワイトボードいっぱいに書き出し、クラウドを設計し運用するという漠然とした話題を扱った本の作成を開始しました。 <placeholder-1/>"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml90(para) msgid """" ""We wrote furiously from our own experiences and bounced ideas between each "" ""other. At regular intervals we reviewed the shape and organization of the "" ""book and further molded it, leading to what you see today."" msgstr ""私たちは一心不乱に自分たちの経験に基づき執筆を行い、互いに意見をぶつけ合いました。一定の間隔で、本の現在の状況や構成をレビューし、本を作り上げていき、今皆さんが見ているものができあがりました。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml95(para) msgid ""The team includes:"" msgstr ""以下が執筆チームのメンバーです。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml98(para) msgid """" ""<emphasis role=\""bold\"">Tom Fifield</emphasis>. After learning about "" ""scalability in computing from particle physics experiments like ATLAS at the"" "" LHC, Tom works on OpenStack clouds in production to support the Australian "" ""public research sector. He lives in Melbourne, Australia and works on "" ""OpenStack documentation in his spare time."" msgstr ""<emphasis role=\""bold\"">Tom Fifield</emphasis>. LHC で ATLAS のような素粒子物理学実験でコンピューティングのスケーラビリティの経験を積んだ後、現在はオーストラリアの公的な研究部門を支援するプロダクションの OpenStack クラウドに携わっています。オーストラリアのメルボルンに住んでいて、空いた時間で OpenStack ドキュメントプロジェクトに参加しています。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml107(para) msgid """" ""<emphasis role=\""bold\"">Diane Fleming</emphasis>. Diane works on the "" ""OpenStack API documentation tirelessly. She helped out wherever she could on"" "" this project."" msgstr ""<emphasis role=\""bold\"">Diane Fleming</emphasis>. 彼女は OpenStack API ドキュメントプロジェクトで非常に熱心に活動しています。このプロジェクトでは自分ができるところであれば、どこでも取り組んでくれました。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml113(para) msgid """" ""<emphasis role=\""bold\"">Anne Gentle</emphasis>. Anne is the documentation "" ""coordinator for OpenStack and also served as an individual contributor to "" ""the Google Doc Summit in 2011, working with the Open Street Maps team. Anne "" ""has worked on doc sprints in the past with FLOSS Manuals’ Adam Hyde "" ""facilitating. Anne lives in Austin, Texas."" msgstr ""<emphasis role=\""bold\"">Anne Gentle</emphasis>. 彼女は OpenStack のドキュメントコーディネーターで、2011年の Google Doc Summit では individual contributor （個人コントリビュータ） を努め Open Street Maps チームとともに活動しました。Adam Hyde が進めていた FLOSS Manuals の以前の doc sprint にも参加しています。テキサス州オースティンに住んでいます。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml123(para) msgid """" ""<emphasis role=\""bold\"">Lorin Hochstein</emphasis>. An academic turned "" ""software developer-slash-operator, Lorin currently works as the Lead "" ""Architect for Cloud Services at Nimbis Services where he deploys OpenStack "" ""for technical computing applications. He has been working with OpenStack "" ""since the Cactus release. Previously, he worked on high-performance "" ""computing extensions for OpenStack at University of Southern California's "" ""Information Sciences Institute (USC-ISI)."" msgstr ""<emphasis role=\""bold\"">Lorin Hochstein</emphasis>. アカデミック出身のソフトウェア開発者・運用者である彼は、Nimbis Services でクラウドサービスの Lead Architect として働いています。Nimbis Service では彼は技術計算アプリケーション用の OpenStack を運用しています。 Cactus リリース以来 OpenStack に携わっています。以前は、University of Southern California's Information Sciences Institute (USC-ISI) で OpenStack の high-performance computing 向けの拡張を行いました。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml136(para) msgid """" ""<emphasis role=\""bold\"">Adam Hyde</emphasis>. Adam facilitated this Book "" ""Sprint. He also founded the Book Sprint methodology and is the most "" ""experienced Book Sprint facilitator around. See http://www.booksprints.net/ "" ""for more information. Adam founded FLOSS Manuals—a community of some 3,000 "" ""individuals developing Free Manuals about Free Software. He is also the "" ""founder and project manager for Booktype, an open source project for "" ""writing, editing, and publishing books online and in print."" msgstr ""<emphasis role=\""bold\"">Adam Hyde</emphasis>. 彼は今回の Book Sprint をリードしました。 Book Sprint メソッドを創設者でもあり、一番経験豊富な Book Sprint のファシリテーターです。詳しい情報は http://www.booksprints.net/ を見て下さい。 3000人もの参加者がいるフリーソフトウェアのフリーなマニュアルを作成するコミュニティである FLOSS Manuals の創設者です。また、Booktype の創設者でプロジェクトマネージャーです。 Booktype はオンラインで本の執筆、編集、出版を行うオープンソースプロジェクトです。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml149(para) msgid """" ""<emphasis role=\""bold\"">Jonathan Proulx</emphasis>. Jon has been piloting an"" "" OpenStack cloud as a senior system administrator at the MIT Computer "" ""Science and Artificial Intelligence Lab for his researchers to have as much "" ""computing power as they need. He started contributing to OpenStack "" ""documentation and reviewing the documentation so that he could accelerate "" ""his learning."" msgstr ""<emphasis role=\""bold\"">Jonathan Proulx</emphasis>. 彼は MIT Computer Science and Artificial Intelligence Lab で上級システム管理者として OpenStack クラウドを運用し、研究者が必要なだけの計算能力を使えるようにしています。 OpenStack の勉強を加速しようと思い、OpenStack ドキュメントへの貢献とドキュメントのレビューを始めました。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml160(para) msgid """" ""<emphasis role=\""bold\"">Everett Toews</emphasis>. Everett is a Developer "" ""Advocate at Rackspace making OpenStack and the Rackspace Cloud easy to use. "" ""Sometimes developer, sometimes advocate, and sometimes operator. He's built "" ""web applications, taught workshops, given presentations around the world, "" ""and deployed OpenStack for production use by academia and business."" msgstr ""<emphasis role=\""bold\"">Everett Toews</emphasis>. 彼は Rackspace の Developer Advocate で、OpenStack や Rackspace Cloud を使いやすくする仕事をしています。ある時は開発者、ある時は advocate、またある時は運用者です。彼は、ウェブアプリケーションを作成し、ワークショップを行い、世界中で公演を行い、教育界やビジネスでプロダクションユースとして使われる OpenStack を構築しています。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml170(para) msgid """" ""<emphasis role=\""bold\"">Joe Topjian</emphasis>. Joe has designed and "" ""deployed several clouds at Cybera, where, as a non-profit, they are building"" "" e-infrastructure to support entrepreneurs and local researchers in Alberta,"" "" Canada. He also actively maintains and operates these clouds which has "" ""generated a wealth of troubleshooting skills for cloud environments."" msgstr ""<emphasis role=\""bold\"">Joe Topjian</emphasis>. 彼は Cybera で複数のクラウドの設計と構築を行って来ました。 Cybera は、非営利でカナダのアルバータ州の起業家や研究者を支援する電子情報インフラを構築しています。また、これらのクラウドの維持・運用を活発に行なっており、その経験からクラウド環境でのトラブルシューティングの豊富な知識を持っています。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml183(title) msgid ""How to Contribute to This Book"" msgstr ""この本の作成に参加するには"" #. <para>A member of the OpenStack doc-core team publishes this #. book periodically. We plan to have events at OpenStack #. summits to work in-person on this book.</para> #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml203(para) msgid """" ""Learn more about how to contribute to the OpenStack docs at <link "" ""xlink:href=\""http://wiki.openstack.org/Documentation/HowTo\"">Documentation How "" ""To</link> (http://wiki.openstack.org/Documentation/HowTo)."" msgstr ""OpenStack ドキュメント作成プロジェクトに参加する方法については、<link xlink:href=\""http://wiki.openstack.org/Documentation/HowTo\"">Documentation How To</link> (http://wiki.openstack.org/Documentation/HowTo) を見て下さい。"" #: ./doc/src/docbkx/openstack-ops/src/preface_ops.xml208(para) msgid """" ""If you find a bug and can't fix it or aren't sure it's really a doc bug, log"" "" a bug at <link xlink:href=\""http://bugs.launchpad.net/openstack-"" ""manuals\"">OpenStack Manuals</link> (http://bugs.launchpad.net/openstack-"" ""manuals). Tag the bug under <guilabel>Extra</guilabel> options with <literal"" "">ops-guide</literal> tag to indicate that the bug is in this guide. You can "" ""assign the bug to yourself if you know how to fix it. Also, a member of the "" ""OpenStack doc-core team can triage the doc bug."" msgstr ""バグを見つけたが、どのように直せばよいか分からない場合や本当にドキュメントのバグか自信が持てない場合は、 <link xlink:href=\""http://bugs.launchpad.net/openstack-manuals\"">OpenStack Manuals</link> (http://bugs.launchpad.net/openstack-manuals) にバグを登録して、バグの <guilabel>Extra</guilabel> オプションで <literal>ops-guide</literal> タグを付けて下さい。 <literal>ops-guide</literal> タグは、そのバグがこのガイドに関するものであることを示します。どのように直せばよいか分かる場合には、そのバグの担当者を自分に割り当てることもできます。また、OpenStack doc-core チームのメンバーがドキュメントバグを分類することもできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml16(title) msgid ""User-facing Operations"" msgstr ""ユーザーによる運用"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml17(para) msgid """" ""This guide is for OpenStack operators and does not seek to be an exhaustive "" ""reference for users, but as an operator it is important that you have a "" ""basic understanding of how to use the cloud facilities. This chapter looks "" ""at OpenStack from a basic user perspective, which helps you understand your "" ""users' needs and determine when you get a trouble ticket whether it is a "" ""user issue or a service issue. The main concepts covered are images, "" ""flavors, security groups, blocks storage and instances."" msgstr ""このガイドは OpenStack の運用者向けです。ユーザー向けの膨大なリファレンスを目指すものではありません。しかし運用者として、クラウド設備を使用する方法について基本的な理解を持つことが重要です。本章は、基本的なユーザーの観点から OpenStack を見ていきます。ユーザーが必要とすることを理解する手助けになります。また、トラブルのチケットを受け取ったときに、ユーザーの問題またはサービスの問題のどちらかを判断する手助けになります。取り扱っている主な概念はイメージ、インスタンスタイプ、セキュリティグループ、ブロックストレージおよびインスタンスです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml29(para) msgid """" ""OpenStack images can often be thought of as \""virtual machine templates\"". "" ""Images can also be standard installation mediums like ISO images. "" ""Essentially, they contain bootable file systems which are used to launch "" ""instances."" msgstr ""OpenStack のイメージはしばしば \""仮想マシンテンプレート\"" と考えることができます。イメージは ISO イメージのような標準的なインストールメディアの場合もあります。基本的に、インスタンスを起動するために使用されるブート可能なファイルシステムを含みます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml35(title) msgid ""Adding Images"" msgstr ""イメージの追加"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml36(para) msgid """" ""Several pre-made images exist and can easily be imported into the Image "" ""Service. A common image to add is the CirrOS image which is very small and "" ""used for testing purposes. To add this image, simply do:"" msgstr ""いくつかの構築済みイメージが存在します。簡単に Image Service の中にインポートできます。追加する一般的なイメージは、非常に小さく、テスト目的に使用される CirrOS イメージです。このイメージを追加するには、単に次のようにします:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml41(para) msgid """" ""The <code>glance image-create</code> command provides a large set of options"" "" to give your image. For example, the <code>min-disk</code> option is useful"" "" for images that require root disks of a certain size (for example, large "" ""Windows images). To view these options, do:"" msgstr ""<code>glance image-create</code> コマンドでは、イメージに指定できる多数のオプションが用意されています。たとえば、<code>min-disk</code> オプションは、特定の容量のルートディスクを必要とするイメージ (例: 大きな Windows イメージ) のために有用です。これらのオプションを表示するには、次のようにします:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml48(para) msgid """" ""The <code>location</code> option is important to note. It does not copy the "" ""entire image into Glance, but reference an original location to where the "" ""image can be found. Upon launching an instance of that image, Glance "" ""accesses the image from the location specified."" msgstr ""<code>location</code> オプションは注意する意味があります。Glance にイメージ全体のコピーを行わず、そのイメージがある元の位置への参照を保持します。イメージのインスタンスを起動するとき、Glance が指定された場所からイメージにアクセスします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml54(para) msgid """" ""The <code>copy-from</code> option copies the image from the location "" ""specified into the <code>/var/lib/glance/images</code> directory. The same "" ""thing is done when using the STDIN redirection such as shown in the example."" msgstr ""<code>copy-from</code> オプションは、指定された位置から <code>/var/lib/glance/images</code> ディレクトリの中にコピーします。例に示されたように STDIN リダイレクションを使用するときに、同じことが実行されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml59(para) msgid ""Run the following command to view the properties of existing images:"" msgstr ""既存のイメージのプロパティを表示するために、以下のコマンドを実行します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml64(title) msgid ""Deleting Images"" msgstr ""イメージの削除"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml65(para) msgid ""To delete an image, just execute:"" msgstr ""イメージを削除するには、ただ次のとおり実行します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml68(para) msgid """" ""Deleting an image does not affect instances or snapshots that were based off"" "" the image."" msgstr ""イメージを削除しても、そのイメージがベースになっているインスタンスやスナップショットには影響がありません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml73(title) msgid ""Other CLI Options"" msgstr ""他の CLI オプション"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml74(para) msgid ""A full set of options can be found using:"" msgstr ""オプションの完全な一覧は、以下を使用して見つけられます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml76(para) msgid """" ""or the <link xlink:href=\""http://docs.openstack.org/cli/quick-start/content"" ""/glance-cli-reference.html\"">OpenStack Image Service</link> CLI Guide. "" ""(http://docs.openstack.org/cli/quick-start/content/glance-cli-"" ""reference.html)"" msgstr ""または <link xlink:href=\""http://docs.openstack.org/cli/quick-start/content/glance-cli-reference.html\"">OpenStack Image Service</link> CLI Guide. (http://docs.openstack.org/cli/quick-start/content/glance-cli-reference.html)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml82(title) msgid ""The Image Service and the Database"" msgstr ""イメージサービスおよびデータベース"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml83(para) msgid """" ""The only thing that Glance does not store in a database is the image itself."" "" The Glance database has two main tables:"" msgstr ""Glance がデータベースに保存しない唯一のものがイメージそのものです。Glance データベースは主な 2 つのテーブルを持ちます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml88(para) msgid ""images"" msgstr ""images"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml91(para) msgid ""image_properties"" msgstr ""image_properties"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml94(para) msgid """" ""Working directly with the database and SQL queries can provide you with "" ""custom lists and reports of Glance images. Technically, you can update "" ""properties about images through the database, although this is not generally"" "" recommended."" msgstr ""データベースと SQL クエリーを直接使うことで、Glance イメージの独自のリストやレポートを得ることができます。一般には、推奨されませんが、技術的にはデータベース経由でイメージのプロパティを更新できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml101(title) msgid ""Example Image Service Database Queries"" msgstr ""イメージサービスのデータベースクエリーの例"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml102(para) msgid """" ""One interesting example is modifying the table of images and the owner of "" ""that image. This can be easily done if you simply display the unique ID of "" ""the owner, this example goes one step further and displays the readable name"" "" of the owner:"" msgstr ""興味深い例の一つは、イメージとそのイメージの所有者の表の表示内容を変更することです。これは、所有者のユニーク ID を表示するようにするだけで実現できます。この例はさらに一歩進め、所有者の読みやすい形式の名前を表示します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml108(para) msgid ""Another example is displaying all properties for a certain image:"" msgstr ""もう一つの例は、特定のイメージに関するすべてのプロパティを表示することです:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml116(title) msgid ""Flavors"" msgstr ""フレーバー"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml118(para) msgid """" ""Virtual hardware templates are called \""flavors\"" in OpenStack, defining "" ""sizes for RAM, disk, number of cores and so on. The default install provides"" "" a range of five flavors. These are configurable by admin users (this too is"" "" configurable and may be delegated by redefining the access controls for "" ""<code>compute_extension:flavormanage</code> in "" ""<code>/etc/nova/policy.json</code> on the <code>nova-api</code> server). To "" ""get a list of available flavors on your system run:"" msgstr ""仮想ハードウェアのテンプレートは、OpenStack において \""フレーバー\"" と呼ばれます。これは、RAM、ディスク、コア数などを定義します。標準のインストールでは、5 種類のフレーバーが提供されます。これらは管理ユーザーにより編集可能です (これは設定可能であり、<code>nova-api</code> サーバーにおいて <code>/etc/nova/policy.json</code> にある <code>compute_extension:flavormanage</code> に対するアクセス制御を再定義することにより権限委譲できます)。お使いのシステムにおいて利用可能なフレーバーの一覧を取得するには、次のとおり実行します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml139(para) msgid """" ""The <code>nova flavor-create</code> command allows authorized users to "" ""create new flavors. Additional flavor manipulation commands can be shown "" ""with the command: <placeholder-1/>"" msgstr ""<code>nova flavor-create</code> コマンドにより、権限のあるユーザーが新しいフレーバーを作成できます。さらなるフレーバーの操作コマンドは次のコマンドを用いて表示できます: <placeholder-1/>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml144(para) msgid ""Flavors define a number of elements:"" msgstr ""フレーバーは数多くの要素を定義します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml152(emphasis) msgid ""Column"" msgstr ""項目"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml157(emphasis) msgid ""Description"" msgstr ""説明"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml163(para) msgid ""ID"" msgstr ""ID"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml166(para) msgid ""A unique numeric id."" msgstr ""一意な数値 ID。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml174(para) msgid """" ""a descriptive name. xx.size_name is conventional not required, though some "" ""third party tools may rely on it."" msgstr ""補足的な名前。xx.size_name が慣習的ですが、必須ではありません。いくつかのサードパーティツールはその名称に依存しているかもしれません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml180(para) msgid ""Memory_MB"" msgstr ""MB メモリー"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml183(para) msgid ""Memory_MB: virtual machine memory in megabytes."" msgstr ""Memory_MB: メガバイト単位の仮想マシンメモリー。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml191(para) msgid """" ""Virtual root disk size in gigabytes. This is an ephemeral disk the base "" ""image is copied into. When booting from a persistent volume it is not used. "" ""The \""0\"" size is a special case which uses the native base image size as "" ""the size of the ephemeral root volume."" msgstr ""ギガバイト単位の仮想ルートディスク容量。これはベースイメージがコピーされる一時ディスクです。永続的なボリュームからブートするとき、これは使用されません。\""0\"" という容量は特別な値で、一時ルートボリュームの容量としてベースイメージのネイティブ容量をそのまま使用することを意味します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml202(para) msgid """" ""Specifies the size of a secondary ephemeral data disk. This is an empty, "" ""unformatted disk and exists only for the life of the instance."" msgstr ""二次的な一時データディスクの容量を指定します。これは空の、フォーマットされていないディスクです。インスタンスの生存期間だけ存在します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml209(para) msgid ""Swap"" msgstr ""スワップ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml212(para) msgid ""Optional swap space allocation for the instance."" msgstr ""インスタンスに割り当てられるスワップ空間。これはオプションです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml217(para) msgid ""VCPUs"" msgstr ""仮想 CPU"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml220(para) msgid ""Number of virtual CPUs presented to the instance."" msgstr ""インスタンスに存在する仮想 CPU 数。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml225(para) msgid ""RXTX_Factor"" msgstr ""RXTX_Factor"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml228(para) msgid """" ""Optional property allows created servers to have a different bandwidth cap "" ""than that defined in the network they are attached to. This factor is "" ""multiplied by the rxtx_base property of the network. Default value is 1.0 "" ""(that is, the same as attached network)."" msgstr ""作成したサーバーが接続されたネットワークにおける定義と異なる帯域制限を持てるようにするプロパティ。これはオプションです。この要素はネットワークの rxtx_base プロパティの倍数です。既定の値は 1.0 です (つまり、接続されたネットワークと同じです)。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml236(para) msgid ""Is_Public"" msgstr ""Is_Public"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml239(para) msgid """" ""Boolean value, whether flavor is available to all users or private to the "" ""tenant it was created in. Defaults to True."" msgstr ""論理値。フレーバーがすべてのユーザーに利用可能か、または作成されたプロジェクト内のみであるか。標準で真 (True) です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml245(para) msgid ""extra_specs"" msgstr ""extra_specs"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml248(para) msgid """" ""Additional optional restrictions on which compute nodes the flavor can run "" ""on. This is implemented as key/value pairs that must match against the "" ""corresponding key/value pairs on compute nodes. Can be used to implement "" ""things like special resources (such as flavors that can only run on compute "" ""nodes with GPU hardware)."" msgstr ""フレーバーを実行できるコンピュートノードに関する追加の制限。これはオプションです。これは、コンピュートノードにおいて対応するキー/バリューペアとして実装され、コンピュートノードでの対応するキー/バリューペアと一致するものでなければいけません。(GPU ハードウェアを持つコンピュートノードのみにおいて実行するフレーバーのように) 特別なリソースのようなものを実装するために使用できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml258(title) msgid ""How do I modify an existing flavor?"" msgstr ""どのように既存のフレーバーを変更しますか?"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml259(para) msgid """" ""Unfortunately, OpenStack does not provide an interface for modifying "" ""flavors, only for creating and deleting them. The OpenStack Dashboard "" ""simulates the ability to modify a flavor by deleting an existing flavor and "" ""creating a new one with the same name."" msgstr ""残念ながら、OpenStack ではフレーバーを変更するインターフェースは提供されておらず、作成および削除のインターフェースだけがあります。OpenStack ダッシュボードは、既存のフレーバーを削除し、同じ名前の新しいものを作成することにより、フレーバーを変更する機能を模倣しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml269(title) msgid ""Security groups"" msgstr ""セキュリティグループ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml270(para) msgid """" ""One of the most common new user issues with OpenStack is failing to set "" ""appropriate security group when launching an instance and are then unable to"" "" contact the instance on the network."" msgstr ""OpenStack の新しいユーザーが非常によく経験する問題の一つが、インスタンスを起動するときに適切なセキュリティグループを設定できず、ネットワーク経由でインスタンスにアクセスできないことです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml274(para) msgid """" ""Security groups are sets of IP filter rules that are applied to an "" ""instance's networking. They are project specific and project members can "" ""edit the default rules for their group and add new rules sets. All projects "" ""have a \""default\"" security group which is applied to instances which have "" ""no other security group defined, unless changed this security group denies "" ""all incoming traffic."" msgstr ""セキュリティグループは、インスタンスのネットワークに適用される、IP フィルタールールの組です。それらはプロジェクト固有です。プロジェクトメンバーがそれらのグループの標準ルールを編集でき、新しいルールを追加できます。すべてのプロジェクトが \""default\"" セキュリティグループを持ちます。他のセキュリティグループが定義されていないインスタンスには \""default\"" セキュリティグループが適用されます。\""default\"" セキュリティグループは、ルールを変更しない限り、すべての受信トラフィックを拒否します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml281(para) msgid """" ""The <code>nova.conf</code> option <code>allow_same_net_traffic</code> (which"" "" defaults to true) globally controls whether the rules applies to hosts "" ""which share a network. When set to true, hosts on the same subnet are not "" ""filtered and are allowed to pass all types of traffic between them. On a "" ""flat network, this allows all instances from all projects unfiltered "" ""communication. With VLAN networking, this allows access between instances "" ""within the same project. If <code>allow_same_net_traffic</code> is set to "" ""false, security groups are enforced for all connections, in this case it is "" ""possible for projects to simulate the <code>allow_same_net_traffic</code> by"" "" configuring their default security group to allow all traffic from their "" ""subnet."" msgstr ""<code>nova.conf</code> のオプション <code>allow_same_net_traffic</code> (標準で true) は、同じネットワークを共有するホストにルールを適用するかを制御します。このオプションはシステム全体に影響するグローバルオプションです。true に設定したとき、同じサブネットにあるホストはフィルターされず、それらの間ですべての種類の通信が通過できるようになります。フラットなネットワークでは、これにより、全プロジェクトの全インスタンスが通信をフィルターされなくなります。VLAN ネットワークでは、これにより、同じプロジェクト内のインスタンス間でアクセスが許可されます。<code>allow_same_net_traffic</code> が false に設定されていると、セキュリティグループがすべての通信に対して強制されます。この場合、既定のセキュリティグループをそれらのサブネットからのすべての通信を許可するよう設定することにより、プロジェクトが <code>allow_same_net_traffic</code> をシミュレートできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml296(para) msgid """" ""Security groups for the current project can be found on the Horizon "" ""dashboard under \""Access &amp; Security\"" to see details of an existing "" ""group select the \""edit\"" action for that security group. Obviously "" ""modifying existing groups can be done from this \""edit\"" interface. There is"" "" a \""Create Security Group\"" button on the main Access &amp; Security page "" ""for creating new groups. We discuss the terms used in these fields when we "" ""explain the command line equivalents."" msgstr ""現在のプロジェクトのセキュリティグループが、Horizon ダッシュボードの \""アクセス &amp; セキュリティ\"" にあります。既存のグループの詳細を表示するには、セキュリティグループの \""編集\"" を選択します。自明ですが、この \""編集\"" インターフェースから既存のグループを変更できます。新しいグループを作成するための \""セキュリティグループの作成\"" ボタンが、メインの \""アクセス &amp; セキュリティ\"" ページにあります。同等のコマンドラインを説明するとき、これらの項目において使用される用語について説明します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml305(para) msgid """" ""From the command line you can get a list of security groups for the project "" ""you're acting in using the nova command:"" msgstr ""コマンドラインからは、以下の nova コマンドを使って、現在のプロジェクトのセキュリティグループのリストを取得できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml317(para) msgid ""To view the details of the \""open\"" security group:"" msgstr ""\""open\"" セキュリティグループの詳細を表示するには:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml328(para) msgid """" ""These rules are all \""allow\"" type rules as the default is deny. The first "" ""column is the IP protocol (one of icmp, tcp, or udp) the second and third "" ""columns specify the affected port range. The third column specifies the IP "" ""range in CIDR format. This example shows the full port range for all "" ""protocols allowed from all IPs."" msgstr ""標準で拒否されるので、これらのルールはすべて \""許可\"" 形式のルールです。1 番目の項目は IP プロトコル (icmp, tcp, udp のどれか) です。2 番目と 3 番目の項目は対象となるポート番号の範囲を指定します。4 番目の項目は CIDR 形式の IP アドレスの範囲を指定します。この例では、すべてのプロトコルの全ポート番号について、すべての IP からのトラフィックを許可しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml334(para) msgid """" ""As noted in the previous chapter the number of rules per security group is "" ""controlled by the quota_security_group_rules and the number of allowed "" ""security groups per project is controlled by the quota_security_groups "" ""quota. "" msgstr ""前の章で述べたとおり、セキュリティグループごとのルール数は quota_security_group_rules により制御されます。また、プロジェクトごとに許可されるセキュリティグループ数は quota_security_groups クォータにより制御されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml339(para) msgid """" ""When adding a new security group you should pick a descriptive but brief "" ""name. This name shows up in brief descriptions of the instances that use it "" ""where the longer description field often does not. Seeing that an instance "" ""is using security group \""http\"" is much easier to understand than "" ""\""bobs_group\"" or \""secgrp1\""."" msgstr ""新しいセキュリティグループを追加するとき、内容を表す簡潔な名前をつけるべきです。この名前はインスタンスの簡単な説明など、より長い説明フィールドが使用されないところで使用されます。インスタンスがセキュリティグループ \""http\"" を使っているのを見れば、\""bobs_group\"" や \""secgrp1\"" よりはずっと理解しやすいことでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml345(para) msgid """" ""As an example, let's create a security group that allows web traffic "" ""anywhere on the internet. We'll call this \""global_http\"" which is clear and"" "" reasonably concise, encapsulating what is allowed and from where. From the "" ""command line:"" msgstr ""例のとおり、インターネットのどこからでも Web 通信を許可するセキュリティグループを作成しましょう。このグループを \""global_http\"" と呼ぶことにします。許可されるものと許可されるところを要約した、明白で簡潔な名前になっています。コマンドラインから:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml355(para) msgid """" ""This creates the empty security group to make it do what we want we need to "" ""add some rules."" msgstr ""やりたいことを行うための空のセキュリティグループが作成されます。いくつかのルールを追加する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml365(para) msgid """" ""Note that the arguments are positional and the \""from-port\"" and \""to-port\"""" "" arguments specify the local port range connections are allowed to not "" ""source and destination ports of the connection. More complex rule sets can "" ""be built up through multiple invocations of nova secgroup-add-rule. For "" ""example if you want to pass both http and https traffic:"" msgstr ""引数の順番が決まっていることに注意してください。そして、\""from-port\"" と \""to-port\"" の引数は許可されるローカルのポート範囲を指定し、接続の送信元ポートと宛先ポートではないことに注意してください。nova secgroup-add-rule を複数回呼び出すことで、より複雑なルールセットを構成できます。たとえば、http と https の通信を通過させたければ:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml380(para) msgid """" ""Despite only outputting the newly added rule this operation is additive:"" msgstr ""新しく追加されたルールのみが出力されますが、この操作は追加操作です:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml389(para) msgid """" ""The inverse operation is called secgroup-delete-rule, using the same format."" "" Whole security groups can be removed with secgroup-delete."" msgstr ""逆の操作が secgroup-delete-rule です。secgroup-delete-rule のコマンドラインは同じ形式です。セキュリティグループ全体を secgroup-delete を用いて削除できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml392(para) msgid ""To create security group rules for a cluster of instances:"" msgstr ""インスタンスのクラスター向けにセキュリティグループのルールを作成するには:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml394(para) msgid """" ""SourceGroups are a special dynamic way of defining the CIDR of allowed "" ""sources. The user specifies a SourceGroup (Security Group name), all the "" ""users' other Instances using the specified SourceGroup are selected "" ""dynamically. This alleviates the need for a individual rules to allow each "" ""new member of the cluster.usage:"" msgstr ""ソースグループは許可するソースの CIDR を動的に定義する特別な方法です。ユーザーがソースグループ (セキュリティグループ名) を指定します。これにより、指定されたソースグループを使用する、ユーザーの他のインスタンスが動的にすべて選択されます。これにより、クラスターのそれぞれの新しいメンバーを許可する、個別のルールが必要なくなります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml400(para) msgid """" ""usage: nova secgroup-add-group-rule &lt;secgroup&gt; &lt;source-group&gt; "" ""&lt;ip-proto&gt; &lt;from-port&gt; &lt;to-port&gt;"" msgstr ""使用法: nova secgroup-add-group-rule &lt;secgroup&gt; &lt;source-group&gt; &lt;ip-proto&gt; &lt;from-port&gt; &lt;to-port&gt;"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml404(para) msgid """" ""The \""cluster\"" rule allows ssh access from any other instance that uses the"" "" \""global-http\"" group."" msgstr ""\""cluster\""ルールにより、\""global-http\"" グループを使用する他のすべてのインスタンスから SSH アクセスが許可されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml410(title) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml141(title) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml123(title) msgid ""Block Storage"" msgstr ""ブロックストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml411(para) msgid """" ""OpenStack volumes are persistent block storage devices which may be attached"" "" and detached from instances, but can only be attached to one instance at a "" ""time, similar to an external hard drive they do not proved shared storage in"" "" the way a network file system or object store does. It is left to the "" ""operating system in the instance to put a file system on the block device "" ""and mount it, or not."" msgstr ""OpenStack のボリュームは、インスタンスから接続および切断できる、永続的なブロックストレージデバイスです。ただし、一度に接続できるのは 1 インスタンスだけです。外部ハードディスクと似ています。ネットワークファイルシステムやオブジェクトストアがしているような共有ストレージは提供されません。ブロックデバイス上にファイルシステムを構築し、それをマウントするかどうかは、インスタンス内のオペレーティングシステムに任されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml418(para) msgid """" ""Similar to other removable disk technology it is important the operating "" ""system is not trying to make use of the disk before removing it. On Linux "" ""instances this typically involves unmounting any file systems mounted from "" ""the volume. The OpenStack volume service cannot tell if it is safe to remove"" "" volumes from an instance so it does what it is told. If a user tells the "" ""volume service to detach a volume from an instance while it is being written"" "" to you can expect some level of file system corruption as well as faults "" ""from whatever process within the instance was using the device."" msgstr ""他のリムーバブルディスク技術と同じように、ディスクを取り外す前に、オペレーティングシステムがそのディスクを使用しないようにすることが重要です。Linux インスタンスにおいて、一般的にボリュームからマウントされているすべてのファイルシステムをアンマウントする必要があります。OpenStack Volume Service は、インスタンスから安全にボリュームを取り外すことができるかはわかりません。そのため、指示されたことを実行します。ボリュームに書き込み中にインスタンスからボリュームの切断を、ユーザーが Volume Service に指示すると、何らかのレベルのファイルシステム破損が起きる可能性があります。それだけでなく、デバイスを使用していたインスタンスの中のプロセスがエラーを起こす可能性もあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml429(para) msgid """" ""There is nothing OpenStack specific in being aware of the steps needed from "" ""with in the instance operating system to access block devices, potentially "" ""formatting them for first use and being cautious when removing devices. What"" "" is specific is how to create new volumes and attach and detach them from "" ""instances. These operations can all be done from the \""Volumes\"" page of the"" "" Dashboard or using the cinder command line client."" msgstr ""ブロックデバイスにアクセスするために、インスタンスのオペレーティングシステムにおいて必要となる手順に、OpenStack 固有の事項はありません。初めて使用するときにフォーマットが必要になる、デバイスを取り外すときに注意する、などが考えられます。固有の事項は、新しいボリュームを作成し、それらをインスタンスに接続および切断する方法です。これらの操作は、ダッシュボードの \""ボリューム\"" ページからすべて実行できます。または、cinder コマンドラインクライアントを使用します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml437(para) msgid """" ""To add new volumes you only need a name and a volume size in gigabytes, "" ""ether put these into the \""create volume\"" web form or using the command "" ""line:"" msgstr ""新しいボリュームを追加する際に必要なのは、名前とギガバイト単位のボリューム容量だけです。これらを \""ボリュームの作成\"" Web フォームに記入します。または、コマンドラインを使用します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml441(para) msgid """" ""This creates a 10 GB volume named \""test-volume.\"" To list existing volumes "" ""and the instances they are connected to if any:"" msgstr ""これは \""test-volume\"" という名前の 10GB のボリュームを作成します。既存のボリュームの一覧を表示するには以下のようにします。それらが接続されているインスタンスがあれば、インスタンス情報も表示されます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml450(para) msgid """" ""The Block Storage service also allows for creating snapshots of volumes. "" ""Remember this is a block level snapshot which is crash consistent so it is "" ""best if the volume is not connected to an instance when the snapshot is "" ""taken and second best if the volume is not in use on the instance it is "" ""attached to. If the volume is under heavy use, the snapshot may have an "" ""inconsistent file system. In fact, by default, the volume service does not "" ""take a snapshot of a volume that is attached to an image, though it can be "" ""forced. To take a volume snapshot either select \""Create Snapshot\"" from the"" "" actions column next to the volume name in the dashboard volume page, or "" ""from the command line:"" msgstr ""Block Storage Service では、ボリュームのスナップショットを作成することもできます。これはブロックレベルのスナップショットであることを覚えておいてください。これはクラッシュに対する一貫性があります。そのため、スナップショットが取得されるとき、ボリュームがインスタンスに接続されていないことが最良です。ボリュームが接続されたインスタンスにおいて使用されていなければ、次に良いです。ボリュームが高負荷にある場合、スナップショットによりファイルシステムの不整合が起こる可能性があります。実際、デフォルト設定では、Volume Service はイメージに接続されたボリュームのスナップショットを取得しません。ただし、強制的に実行することができます。ボリュームのスナップショットを取得するには、ダッシュボードの \""ボリューム” ページにおいて、ボリューム名の隣にあるアクション項目から \""スナップショットの作成\"" を選択します。または、コマンドラインから次のようにします:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml473(title) msgid ""Block Storage Creation Failures"" msgstr ""ブロックストレージの作成エラー"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml474(para) msgid """" ""If a user tries to create a volume and it immediately goes into an error "" ""state, the best way to troubleshoot is to grep the Cinder log files for the "" ""volume's UUID. First try the log files on the cloud controller and then try "" ""the storage node where they volume was attempted to be created:"" msgstr ""ユーザーがボリュームを作成しようとし、すぐにエラー状態になれば、トラブル解決のために最適な方法は Cinder ログファイルをボリュームの UUID で grep することです。まずクラウドコントローラーにあるログファイルを調べます。次に、ボリュームを作成しようとしたストレージノードのログファイルを調べます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml485(title) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml174(title) msgid ""Instances"" msgstr ""インスタンス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml486(para) msgid """" ""Instances are the running virtual machines within an OpenStack cloud. This "" ""section deals with how to work with them and their underlying images, their "" ""network properties and how they are represented in the database."" msgstr ""インスタンスは OpenStack クラウドの中で実行中の仮想マシンです。このセクションは、インスタンス、インスタンスが使用するイメージ、インスタンスのネットワークプロパティを扱うための方法について取り扱います。また、それらがデータベースでどのように表現されているかについて取り扱います。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml491(title) msgid ""Starting Instances"" msgstr ""インスタンスの起動"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml492(para) msgid """" ""To launch an instance you need to select an image, a flavor, and a name. The"" "" name needn't be unique but your life is simpler if it is because many tools"" "" will use the name in place of UUID so long as the name is unique. This can "" ""be done from the dashboard either from the \""Launch Instance\"" button on the"" "" \""Instances\"" page or by selecting the \""Launch\"" action next to an image "" ""or snapshot on the \""Images &amp; Snapshots\"" page."" msgstr ""インスタンスを起動するには、イメージ、フレーバーおよび名前を選択する必要があります。名前は一意である必要がありませんが、名前が一意である限りは、多くのツールが UUID の代わりに名前を使用できるので、シンプルにできます。インスタンスの起動はダッシュボードにおいて、\""インスタンス\"" ページにある \""インスタンスの起動\"" ボタン、または \""イメージ &amp; スナップショット\"" ページにあるイメージまたはスナップショットの隣にある \""起動\"" アクションから実行できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml501(para) msgid ""On the command line:"" msgstr ""コマンドラインでは次のようにします:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml503(para) msgid """" ""There are a number of optional items that can be specified. You should read "" ""the rest of this instances section before trying to start one, but this is "" ""the base command that later details are layered upon."" msgstr ""指定できる多くのオプション項目があります。インスタンスを起動しようとする前に、このインスタンスのセクションを最後まで読んでください。しかし、これが今から説明する詳細の基本となるコマンドです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml508(para) msgid """" ""To delete instances from the dashboard select the \""Terminate instance\"" "" ""action next to the instance on the \""Instances\"" page, from the command "" ""line:"" msgstr ""ダッシュボードからインスタンスを削除するには、\""インスタンス\"" ページにおいてインスタンスの隣にある \""インスタンスの終了\"" アクションを選択します。または、コマンドラインから次のとおり実行します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml512(para) msgid """" ""It is important to note that powering off an instance does not terminate it "" ""in the OpenStack sense."" msgstr ""注意すべき大事な点は、インスタンスの電源オフは、OpenStack 的な意味でのインスタンスの終了ではないということです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml517(title) msgid ""Instance Boot Failures"" msgstr ""インスタンスの起動失敗"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml518(para) msgid """" ""If an instance fails to start and immediately moves to \""Error\"" state there"" "" are a few different ways to track down what has gone wrong. Some of these "" ""can be done with normal user access while others require access to your log "" ""server or compute nodes."" msgstr ""インスタンスの開始に失敗し、すぐに \""エラー\"" 状態になるならば、何が問題なのかを追跡するために、いくつかの異なる方法があります。いくつかの方法は通常のユーザーアクセスで実行でき、他の方法ではログサーバーやコンピュートノードへのアクセスが必要です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml523(para) msgid """" ""The simplest reasons for nodes to fail to launch are quota violations or the"" "" scheduler being unable to find a suitable compute node on which to run the "" ""instance. In these cases the error is apparent doing a <code>nova "" ""show</code> on the faulted instance."" msgstr ""ノードが起動に失敗する最も簡単な理由は、クォータ違反、またはスケジューラーがインスタンスを実行するのに適したコンピュートノードを見つけられなかった場合です。これらの場合、失敗したインスタンスに対して <code>nova show</code> を実行するとエラーが表示されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml557(para) msgid """" ""In this case looking at the \""fault\"" message shows NoValidHost indicating "" ""the scheduler was unable to match the instance requirements."" msgstr ""この場合、\""fault\"" メッセージに NoValidHost が表示されています。NoValidHost はスケジューラーがインスタンスの要件を満たせなかったことを意味します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml560(para) msgid """" ""If <code>nova show</code> does not sufficiently explain the failure "" ""searching for the instance UUID in the <code>nova-compute.log</code> on the "" ""compute node it was scheduled on or the <code>nova-scheduler.log</code> on "" ""your scheduler hosts is a good place to start looking for lower level "" ""problems."" msgstr ""<code>nova show</code> が十分な失敗の理由が表示されていない場合、そのインスタンスがスケジューリングされたコンピュートノードの <code>nova-compute.log</code> やスケジューラーホストの <code>nova-scheduler.log</code> を、インスタンスの UUID で検索するのが、より低レベルの問題を調査する良い出発点となります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml567(para) msgid """" ""Using <code>nova show</code> as an admin user will show the compute node the"" "" instance was scheduled on as <code>hostId</code>, if the instance failed "" ""during scheduling this field is blank."" msgstr ""管理ユーザーとして <code>nova show</code> を使用すると、インスタンスがスケジュールされたコンピュートノードが <code>hostId</code> として表示されます。インスタンスがスケジュール中に失敗していれば、この項目が空白です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml573(title) msgid ""Instance-specific Data"" msgstr ""インスタンス固有のデータ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml574(para) msgid """" ""There are a variety of ways to inject custom data including authorized_keys "" ""key injection, user-data, metadata service, and file injection."" msgstr ""カスタムデータを注入する方法は、認証済みキー注入、ユーザーデータ、メタデータサービス、ファイル注入 (file injection) などいろいろな方法があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml577(para) msgid """" ""To clarify user-data versus metadata, understand that \""user-data\"" is a "" ""chunk of data, set when an instance is not running. This user-data is "" ""accessible from within the instance when it is running. People use this "" ""user-data to store configuration, a script, or anything the tenant wants."" msgstr ""ユーザーデータとメタデータの違いを明確にするには、\""ユーザーデータ\"" がデータの塊で、インスタンスが実行されていないときに設定することを理解する必要があります。このユーザーデータは、インスタンスが実行中に、インスタンスの中からアクセスできます。設定、スクリプト、またはテナントが必要とする任意のものを保存するために、このユーザーデータを使用します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml583(para) msgid """" ""For Compute, instance metadata is a collection of key/value pairs associated"" "" with an instance. Compute reads and writes to these key/value pairs any "" ""time during the instance lifetime, from inside and outside the instance, "" ""when the end-user uses the Compute API to do so. However, you cannot query "" ""the instance associated key/value pairs via the metadata service that is "" ""compatible with the Amazon EC2 metadata service."" msgstr ""Compute では、インスタンスのメタデータはインスタンスと関連付けられたキーバリューペアの集まりです。エンドユーザーがこれらのキーバリューペアを読み書きするために Compute API を使用するとき、Compute がインスタンスの生存期間中にインスタンスの内外からこれらを読み書きします。しかしながら、Amazon EC2 メタデータサービスと互換性のあるメタデータサービス経由で、インスタンスに関連付けられたキーバリューペアをクエリーできません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml592(para) msgid ""Users can generate and register ssh keys using the nova command"" msgstr ""ユーザーが nova コマンドを使用して SSH 鍵を生成および登録できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml595(para) msgid """" ""This creates a key named mykey which you can associate with instances. The "" ""file mykey.pem is the private key which should be saved to a secure location"" "" as it allows root access to instances the mykey key is associated with."" msgstr ""これにより、インスタンスと関連付けられる mykey という名前の鍵が生成されます。mykey.pem というファイルが秘密鍵です。これは、mykey 鍵が関連付けられたインスタンスに root アクセスできるので、安全な場所に保存すべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml600(para) msgid """" ""You can register an existing public key with OpenStack using this command"" msgstr ""このコマンドを使用して、既存の公開鍵を OpenStack に登録できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml603(para) msgid """" ""You must have the matching private key to access instances associated with "" ""this key."" msgstr ""この鍵と関連付けられたインスタンスにアクセスするために、対応する秘密鍵を持つ必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml605(para) msgid """" ""To associate a key with an instance on boot add --key_name mykey to your "" ""command line for example:"" msgstr ""起動時にインスタンスに鍵を関連付けるには、たとえば、コマンドラインに --key_name mykey を追加します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml609(para) msgid """" ""When booting a server, you can also add metadata, so that you can more "" ""easily identify it amongst other running instances. Use the --meta option "" ""with a key=value pair, where you can make up the string for both the key and"" "" the value. For example, you could add a description and also the creator of"" "" the server."" msgstr ""サーバーを起動するとき、他の実行中のインスタンスと区別しやすくするために、メタデータを追加することもできます。--meta オプションを key=value ペアとともに使用します。ここで、キーとバリューの両方の文字列を指定することができます。たとえば、説明とサーバーの作成者を追加できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml617(para) msgid """" ""When viewing the server information, you can see the metadata included on "" ""the metadata line:"" msgstr ""サーバーの情報を表示するとき、メタデータ行に含まれるメタデータを参照できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml648(para) msgid """" ""User Data is a special key in the metadata service which holds a file that "" ""cloud aware applications within the guest instance can access. For example "" ""<link xlink:title=\""OpenStack Image Service\"" "" ""xlink:href=\""https://help.ubuntu.com/community/CloudInit\"">cloudinit</link> "" ""(https://help.ubuntu.com/community/CloudInit) is an open source package from"" "" Ubuntu that handles early initialization of a cloud instance that makes use"" "" of this user data."" msgstr ""ユーザーデータはメタデータサービスにおける特別なキーで、ゲストインスタンス内のクラウド対応アプリケーションがアクセスできるファイルを保持します。たとえば、 <link xlink:title=\""OpenStack Image Service\"" xlink:href=\""https://help.ubuntu.com/community/CloudInit\"">cloudinit</link> (https://help.ubuntu.com/community/CloudInit) は、このユーザーデータを使用するクラウドインスタンスの初期設定を処理する、Ubuntu のオープンソースパッケージです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml658(para) msgid """" ""This user-data can be put in a file on your local system and then passed in "" ""at instance creation with the flag --user-data &lt;user-data-file&gt; for "" ""example:"" msgstr ""このユーザーデータは、ローカルマシンのファイルに保存され、--user-data &lt;user-data-file&gt; フラグを用いてインスタンスの生成時に渡されます。たとえば:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml663(para) msgid """" ""Arbitrary local files can also be placed into the instance file system at "" ""creation time using the --file &lt;dst-path=src-path&gt; option. You may "" ""store up to 5 files. For example if you have a special authorized_keys file "" ""named special_authorized_keysfile that you want to put on the instance "" ""rather than using the regular ssh key injection for some reason you can use "" ""the following command:"" msgstr ""--file &lt;dst-path=src-path&gt; オプションを用いて、任意のローカルファイルを生成時にインスタンスのファイルシステムの中に置けます。5 ファイルまで保存できます。たとえば、何らかの理由で通常の SSH 鍵の注入ではなく、special_authorized_keysfile という名前の特別な authorized_keys をインスタンスに置きたい場合、以下のコマンドを使用できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml676(title) msgid ""Associating Security Groups"" msgstr ""セキュリティグループの割り当て"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml677(para) msgid """" ""Security groups as discussed earlier are typically required to allow network"" "" traffic to an instance, unless the default security group for a project has"" "" been modified to be more permissive."" msgstr ""プロジェクトの規定のセキュリティグループを新たな通信を許可するように変更していない限り、インスタンス向けのネットワーク通信を許可するには、これまでに議論してきたセキュリティグループが必要です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml681(para) msgid """" ""Adding security groups is typically done on instance boot. When launching "" ""from the dashboard this is on the \""Access &amp; Security\"" tab of the "" ""\""Launch Instance\"" dialog. When launching from the command line append "" ""--security-groups with a comma separated list of security groups."" msgstr ""セキュリティグループの追加は、一般的にインスタンスの起動時に実行されます。ダッシュボードから起動するとき、これは \""インスタンスの起動\"" ダイアログの \""アクセス &amp; セキュリティ\"" タブにあります。コマンドラインから起動する場合には、--security-groups にセキュリティグループのコンマ区切り一覧を指定します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml687(para) msgid """" ""It is also possible to add and remove security groups when an instance is "" ""running. Currently this is only available through the command line tools."" msgstr ""インスタンスを実行中にセキュリティグループを追加および削除することもできます。現在、コマンドラインツールからのみ利用可能です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml694(title) msgid ""Floating IPs"" msgstr ""Floating IP"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml695(para) msgid """" ""Projects have a quota controlled number of Floating IPs, however these need "" ""to be allocated by a user before they are available for use. To allocate a "" ""Floating IP to a project there is an \""Allocate IP to Project\"" button on "" ""the \""Access &amp; Security\"" page of the dashboard or on the command line "" ""by using:"" msgstr ""プロジェクトはクォータで管理された数の Floating IP を持ちます。しかしながら、これらは、使用可能になる前にユーザーにより確保する必要があります。Floating IP をプロジェクトに確保するために、ダッシュボードの \""アクセス &amp; セキュリティ\"" ページにある \""プロジェクトへの IP の確保\"" ボタンがあります。または、コマンドラインにおいて次を使用します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml703(para) msgid """" ""Once allocated, Floating IP can be assigned to running instances from the "" ""Dashboard either by selecting the \""Associate Floating IP\"" from the actions"" "" drop down next to the IP on the \""Access &amp; Security\"" page or the same "" ""action next to the instance you wish to associate it with on the "" ""\""Instances\"" page. The inverse action, \""Dissociate Floating IP\"", is only "" ""available from the \""Access &amp; Security\"" page and not from the Instances"" "" page."" msgstr ""一度確保すると、Floating IP を実行中のインスタンスに割り当てることができます。ダッシュボードでは、\""アクセス &amp; セキュリティ\"" ページにある IP の隣にある、アクションドロップダウンから \""Floating IP の割り当て\"" を選択することにより実行できます。または、\""インスタンス\"" ページにおいて割り当てたいインスタンスの隣にある、同じアクションから実行できます。逆の動作 \""Floating IP の解放\"" は \""アクセス &amp; セキュリティ\"" ページからのみ利用可能です。インスタンスのページから利用できません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml711(para) msgid """" ""From the command line, enter the following command to complete these tasks:"" msgstr ""これらの作業を完了するために、コマンドラインの場合、以下のコマンドにより同じことができます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml718(title) msgid ""Attaching Block Storage"" msgstr ""ブロックストレージの接続"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml719(para) msgid """" ""You can attach block storage to instances from the dashboard on the "" ""<guilabel>Volumes</guilabel> page. Click the <guibutton>Edit "" ""Attachments</guibutton> action next to the volume you wish to attach."" msgstr ""ダッシュボードから <guilabel>ボリューム</guilabel> ページにおいて、ブロックストレージをインスタンスに接続できます。接続したいボリュームの隣にある <guibutton>接続の編集</guibutton> アクションをクリックします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml723(para) msgid ""To perform this action from command line, run the following command:"" msgstr ""このアクションをコマンドラインから実行するには、以下のコマンドを実行します"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml726(para) msgid """" ""You can also specify block device mapping at instance boot time through the "" ""nova command-line client, as follows:"" msgstr ""nova コマンドラインクライアントから以下のように、インスタンスの起動時にブロックストレージのマッピングを指定することもできます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml730(para) msgid """" ""The block device mapping format is <code>&lt;dev-"" ""name=&lt;id&gt;:&lt;type&gt;:&lt;size(GB)&gt;:&lt;delete-on-"" ""terminate&gt;</code>, where:"" msgstr ""ブロックデバイスのマッピング形式は <code>&lt;dev-name=&lt;id&gt;:&lt;type&gt;:&lt;size(GB)&gt;:&lt;delete-on-terminate&gt;</code> です。ここで:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml735(term) msgid ""dev-name"" msgstr ""dev-name"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml737(para) msgid """" ""A device name where the volume is attached in the system at "" ""<code>/dev/<replaceable>dev_name</replaceable></code>."" msgstr ""そのボリュームはシステムで <code>/dev/<replaceable>dev_name</replaceable></code> に接続されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml744(literal) msgid ""id"" msgstr ""id"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml746(para) msgid """" ""The ID of the volume to boot from, as shown in the output of nova volume-"" ""list."" msgstr ""起動するボリュームの ID です。nova volume-list の出力に表示されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml751(term) msgid ""type"" msgstr ""type"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml753(para) msgid """" ""Either <literal>snap</literal>, which means that the volume was created from"" "" a snapshot, or anything other than <literal>snap</literal> (a blank string "" ""is valid). In the example above, the volume was not created from a snapshot,"" "" so we leave this field blank in our example below."" msgstr ""ボリュームがスナップショットから作成されたことを意味する <literal>snap</literal>、または <literal>snap</literal> 以外の何か (空文字列も有効) です。上の例では、ボリュームがスナップショットから作成されていません。そのため、この項目を以下の例において空白にしてあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml767(term) msgid ""size (GB)"" msgstr ""size (GB)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml769(para) msgid """" ""The size of the volume, in GB. It is safe to leave this blank and have the "" ""Compute service infer the size."" msgstr ""ボリュームのギガバイト単位の容量。このフィールドを空欄にして、Compute サービスに容量を推定させるのが安全です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml775(term) msgid ""delete-on-terminate"" msgstr ""delete-on-terminate"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml777(para) msgid """" ""A boolean to indicate whether the volume should be deleted when the instance"" "" is terminated. True can be specified as <literal>True</literal> or "" ""<literal>1</literal>. False can be specified as <literal>False</literal> or "" ""<literal>0</literal>."" msgstr ""インスタンスが終了したときに、ボリュームが削除されるかどうかを指示する論理値です。真は <literal>True</literal> または <literal>1</literal> として指定できます。偽は <literal>False</literal> または <literal>0</literal> として指定できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml795(para) msgid """" ""If you have previously prepared the block storage with a bootable file "" ""system image it is even possible to boot from persistent block storage. The "" ""following example will attempt boot from volume with "" ""ID=<literal>13</literal>, it does not delete on terminate. Replace the "" ""<literal>--key-name</literal> with a valid keypair name:"" msgstr ""ブート可能なファイルシステムイメージでブロックストレージを事前に準備していると、永続ブロックストレージからブートすることもできます。以下の例は ID=<literal>13</literal> のボリュームからブートしようとしています。終了時に削除されません。<literal>--key-name</literal> を有効なキーペア名で置き換えてください:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml805(para) msgid """" ""Because of bug <link xlink:title=\""OpenStack Image Service\"" "" ""xlink:href=\""https://bugs.launchpad.net/nova/+bug/1163566\"">1163566</link> "" ""(https://bugs.launchpad.net/nova/+bug/1163566) you must specify an image "" ""when booting from a volume in Horizon, even though this image is not used."" msgstr ""バグ <link xlink:title=\""OpenStack Image Service\"" xlink:href=\""https://bugs.launchpad.net/nova/+bug/1163566\"">1163566</link> (https://bugs.launchpad.net/nova/+bug/1163566) のため、Horizon においてボリュームからブートするとき、このイメージを使用しないにも関わらず、イメージを指定しなければいけません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml812(para) msgid """" ""To boot normally from an image and attach block storage, map to a device "" ""other than vda."" msgstr ""普通にイメージからブートし、ブロックストレージを接続するには、vda 以外のデバイスをマッピングします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml817(title) msgid ""Taking Snapshots"" msgstr ""スナップショットの取得"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml818(para) msgid """" ""OpenStack's snapshot mechanism allows you to create new images from running "" ""instances. This is a very convenient for upgrading base images or taking a "" ""published image and customizing for local use. To snapshot a running "" ""instance to an image using the CLI:"" msgstr ""OpenStack のスナップショット機能により、実行中のインスタンスから新しいイメージを作成できます。これは、基本イメージをアップグレードしたり、公開イメージを取得してローカル向けにカスタマイズしたりする場合に非常に便利です。CLI を利用して、実行中のインスタンスのスナップショットを取得し、イメージを作成するには:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml824(para) msgid """" ""The Dashboard interface for snapshots can be confusing because the Images "" ""&amp; Snapshots page splits content up into:"" msgstr ""\""イメージ &amp; スナップショット\"" のページでは、内容が以下のように分類されているので、ダッシュボードのスナップショットのインターフェースは紛らわしいです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml832(para) msgid ""Instance snapshots"" msgstr ""インスタンスのスナップショット"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml835(para) msgid ""Volume snapshots"" msgstr ""ボリュームのスナップショット"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml838(para) msgid """" ""However, an instance snapshot <emphasis>is</emphasis> an image. The only "" ""difference between an image that you upload directly to glance and an image "" ""you create by snapshot is that an image created by snapshot has additional "" ""properties in the glance database. These properties are found in the "" ""image_properties table, and include:"" msgstr ""しかしながら、インスタンスのスナップショットはイメージ<emphasis>です</emphasis>。Glance に直接アップロードしたイメージと、スナップショットにより作成したイメージとの唯一の違いは、スナップショットにより作成されたイメージが glance データベースにおいて追加のプロパティを持つことです。これらのプロパティは image_properties テーブルで確認でき、次の項目を含みます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml848(th) msgid ""name"" msgstr ""名前"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml849(th) msgid ""value"" msgstr ""値"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml855(para) msgid ""image_type"" msgstr ""image_type"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml857(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml878(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2583(glossterm) msgid ""snapshot"" msgstr ""スナップショット"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml861(para) msgid ""instance_uuid"" msgstr ""instance_uuid"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml863(para) msgid ""&lt;uuid of instance that was snapshotted&gt;"" msgstr ""&lt;スナップショットされたインスタンスの UUID&gt;"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml868(para) msgid ""base_image_ref"" msgstr ""base_image_ref"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml870(para) msgid ""&lt;uuid of original image of instance that was snapshotted&gt;"" msgstr ""&lt;スナップショットされたインスタンスの元イメージの UUID&gt;"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml876(para) msgid ""image_location"" msgstr ""image_location"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml883(title) msgid ""Ensuring snapshots are consistent"" msgstr ""スナップショットの一貫性の保証"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml884(para) msgid """" ""Content from Sébastien Han's <link xlink:title=\""OpenStack Image Service\"" "" ""xlink:href=\""http://www.sebastien-han.fr/blog/2012/12/10/openstack-perform-"" ""consistent-snapshots/\"">OpenStack: Perform Consistent Snapshots blog "" ""entry</link> (http://www.sebastien-han.fr/blog/2012/12/10/openstack-perform-"" ""consistent-snapshots/)"" msgstr ""Sébastien Han さんの <link xlink:title=\""OpenStack Image Service\"" xlink:href=\""http://www.sebastien-han.fr/blog/2012/12/10/openstack-perform-consistent-snapshots/\"">OpenStack: Perform Consistent Snapshots ブログエントリー</link> (http://www.sebastien-han.fr/blog/2012/12/10/openstack-perform-consistent-snapshots/) からのコンテンツです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml890(para) msgid """" ""A snapshot captures the state of the file system, but not the state of the "" ""memory. Therefore, to ensure your snapshot contains the data that you want, "" ""before your snapshot you need to ensure that:"" msgstr ""スナップショットは、ファイルシステムの状態をキャプチャーしますが、メモリーの状態をキャプチャーしません。そのため、スナップショットに期待するデータが含まれることを確実にするために、次のことを確実にする必要があります:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml896(para) msgid ""Running programs have written their contents to disk"" msgstr ""実行中のプログラムがコンテンツをディスクに書き込んだこと"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml900(para) msgid """" ""The file system does not have any \""dirty\"" buffers: where programs have "" ""issued the command to write to disk, but the operating system has not yet "" ""done the write"" msgstr ""ファイルシステムが \""ダーティー\"" バッファーを持たないこと: \""ダーティー\"" バッファーがあるとは、プログラムがディスクに書き込むためにコマンドを発行しましたが、オペレーティングシステムがまだ書き込みを完了していないことです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml906(para) msgid """" ""To ensure that important services have written their contents to disk (such "" ""as, databases), we recommend you read the documentation for those "" ""applications to determine what commands to issue to have them sync their "" ""contents to disk. If you are unsure how to do this, the safest approach is "" ""to simply stop these running services normally."" msgstr ""(データベースのような) 重要なサービスがコンテンツをディスクに書き込んだことを保証するために、それらのアプリケーションのドキュメントを読んで、コンテンツをディスクに同期させるためにどのコマンドを発行する必要があるかを調べることを推奨します。ディスクに同期させるための方法がはっきり分からない場合、最も安全な方法は単にこれらの実行中のサービスを通常通り停止することです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml913(para) msgid """" ""To deal with the \""dirty\"" buffer issue, we recommend using the sync command"" "" before snapshotting:"" msgstr ""\""ダーティー\"" バッファーの問題を解決するために、スナップショットの前に sync コマンドを使用することを推奨します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml916(para) msgid """" ""Running <code>sync</code> writes dirty buffer (buffered block that have been"" "" modified but not written yet to the disk block) to disk."" msgstr ""<code>sync</code> を実行することにより、ダーティーバッファー (変更されたが、ディスクに書き込まれていないバッファー済みブロック) をディスクに書き込みます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml919(para) msgid """" ""Just running <code>sync</code> is not enough to ensure the file system is "" ""consistent. We recommend you use the <code>fsfreeze</code> tool, which halts"" "" new access to the file system and create a stable image on disk that is "" ""suitable for snapshotting. fsfreeze supports several file systems, including"" "" ext3, ext4, and XFS. If your virtual machine instance is running on Ubuntu,"" "" install the util-linux package to get fsfreeze:"" msgstr ""ファイルシステムが一貫性を持つことを保証するためには、単に <code>sync</code> を実行するだけでは不十分です。<code>fsfreeze</code> ツールを使用することを推奨します。これは、ファイルシステムに対する新規アクセスを停止し、スナップショットに適した安定したイメージをディスクに作成します。fsfreeze は ext3, ext4 および XFS を含むいくつかのファイルシステムをサポートします。仮想マシンのインスタンスが Ubuntu において実行されていれば、fsfreeze を取得するために util-linux パッケージをインストールします:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml929(para) msgid """" ""If your operating system doesn't have a version of fsfreeze available, you "" ""can use xfs_freeze instead, which is available on Ubuntu in the xfsprogs "" ""package. Despite the \""xfs\"" in the name, xfs_freeze also works on ext3 and "" ""ext4 if you are using a Linux kernel version 2.6.29 or greater, since it "" ""works at the virtual file system (VFS) level starting at 2.6.29. xfs_freeze "" ""supports the same command-line arguments as fsfreeze."" msgstr ""お使いのオペレーティングシステムに利用可能なバージョンの fsfreeze がなければ、代わりに xfs_freeze を使用できます。これは Ubuntu の xfsprogs パッケージにおいて利用可能です。\""xfs\"" という名前にもかかわらず、xfs_freeze は Linux カーネル 2.6.29 またはそれ以降を使用していれば ext3 や ext4 においても動作します。それは 2.6.29 において開始された仮想ファイルシステム (VFS) レベルで動作するためです。xfs_freeze は fsfreeze と同じ名前のコマンドライン引数をサポートします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml938(para) msgid """" ""Consider the example where you want to take a snapshot of a persistent block"" "" storage volume, detected by the guest operating system as /dev/vdb and "" ""mounted on /mnt. The fsfreeze command accepts 2 arguments:"" msgstr ""永続ブロックストレージのスナップショットを取得したい例を検討します。ゲストオペレーティングシステムにより /dev/vdb として認識され、/mnt にマウントされているとします。fsfreeze コマンドが 2 つの引数を受け取ります:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml945(para) msgid ""-f: freeze the system"" msgstr ""-f: システムをフリーズします"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml948(para) msgid ""-u: thaw (un-freeze) the system"" msgstr ""-u: システムを解凍 (フリーズ解除) します"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml951(para) msgid """" ""To freeze the volume in preparation for snapshotting, you would do, as root,"" "" inside of the instance:"" msgstr ""スナップショットの準備においてボリュームをフリーズするには、インスタンスの中で root として次のとおり実行します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml955(para) msgid """" ""You <emphasis role=\""bold\"">must mount the file system</emphasis> before you"" "" run the <placeholder-1/> command."" msgstr ""<placeholder-1/> コマンドを実行する前に、<emphasis role=\""bold\"">ファイルシステムをマウントする必要があります</emphasis>。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml958(para) msgid """" ""When the \""fsfreeze -f\"" command is issued, all ongoing transactions in the "" ""file system are allowed to complete, new write system calls are halted, and "" ""other calls which modify the file system are halted. Most importantly, all "" ""dirty data, metadata, and log information are written to disk."" msgstr ""\""fsfreeze -f\"" コマンドが発行された場合、ファイルシステム内で進行中のすべてのトランザクションが完了することが認められます。新規書き込みのシステムコールは停止されます。そして、ファイルシステムを変更する他のコールは停止されます。最も重要なこととしては、すべてのダーティーデータ、メタデータ、およびログ情報がディスクに書き込まれることです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml964(para) msgid """" ""Once the volume has been frozen, do not attempt to read from or write to the"" "" volume, as these operations hang. The operating system stops every I/O "" ""operation and any I/O attempts is delayed until the file system has been "" ""unfrozen."" msgstr ""ボリュームがフリーズ状態になったら、ボリュームの読み書き命令が止まってしまうので、ボリュームの読み書きを行わないようにしてください。オペレーティングシステムがすべての I/O 操作を停止し、すべての I/O 試行がファイルシステムがフリーズ解除されるまで遅延させられます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml969(para) msgid """" ""Once you have issued the fsfreeze command, it is safe to perform the "" ""snapshot. For example, if your instance was named mon-instance, and you "" ""wanted to snapshot it to an image, named mon-snapshot, you could now run the"" "" following:"" msgstr ""fsfreeze コマンドを発行すると、スナップショットを実行しても安全です。たとえば、インスタンスが mon-instance という名前で、mon-snapshot という名前のイメージにスナップショットを取得したければ、以下のとおり実行します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml975(para) msgid """" ""When the snapshot is done, you can thaw the file system with the following "" ""command, as root, inside of the instance:"" msgstr ""スナップショットの作成が終わったら、インスタンスの中で root として以下のコマンドを用いて、ファイルシステムをフリーズ解除できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml979(para) msgid """" ""If you want to backup the root files ystem, you can't simply do the command "" ""above because it will freeze the prompt. Instead, run the following one-"" ""liner, as root, inside of the instance:"" msgstr ""ルートファイルシステムをバックアップしたければ、プロンプトがフリーズしてしますので、上のコマンドを単純に実行できません。代わりに、インスタンスの中で root として以下の 1 行を実行します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml988(title) msgid ""Instances in the Database"" msgstr ""データベースにあるインスタンス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml989(para) msgid """" ""While instance information is stored in a number of database tables, the "" ""table operators are most likely to need to look at in relation to user "" ""instances is the \""instances\"" table."" msgstr ""インスタンス情報は多くのデータベースのテーブルに保存されますが、ユーザーのインスタンスに関連して運用者が参照する必要が最もありそうなテーブルは \""instances\"" テーブルです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml993(para) msgid """" ""The instances table carries all most of the information related to both "" ""running and deleted instances. It has a bewildering array of fields, for an "" ""exhaustive list look at the database. These are the most useful fields for "" ""operators looking to form queries."" msgstr ""インスタンスのテーブルは、実行中および削除済みの両方のインスタンスに関連する情報のほとんどを保持しています。データベースで完全なリストを見ると、このテーブルには目が回るほどたくさんのフィールドがあることがわかります。以下に、クエリーを行おうとしている運用者にとって非常に有用なフィールドを挙げます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml998(para) msgid """" ""The \""deleted\"" field is set to \""1\"" if the instance has been deleted and "" ""NULL if it has not been deleted this important for excluding deleted "" ""instances from your queries."" msgstr ""\""deleted\"" フィールドは、インスタンスが削除されていると \""1\"" がセットされます。削除されていなければ NULL です。これはクエリーから削除済みインスタンスを除外するために重要です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml1002(para) msgid """" ""The \""uuid\"" field is the UUID of the instance and is used through out other"" "" tables in the database as a foreign key. This id is also reported in logs, "" ""the dashboard and command line tools to uniquely identify an instance."" msgstr ""\""uuid\"" フィールドはインスタンスの UUID です。データベースにある他の表において外部キーとして使用されます。この ID は、インスタンスを一意に識別するために、ログ、ダッシュボードおよびコマンドラインツールにおいて表示されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml1007(para) msgid """" ""A collection of foreign keys are available to find relations to the "" ""instance. The most useful of these are \""user_id\"" and \""project_id\"" are "" ""the UUIDs of the user who launched the instance and the project it was "" ""launched in."" msgstr ""外部キーはインスタンスの関連を見つけるために利用可能です。これらの中で最も有用なものは、 \""user_id\"" および \""project_id\"" です。これらは、インスタンスを起動したユーザー、およびそれが起動されたプロジェクトの UUID です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml1012(para) msgid ""The \""host\"" field tells which compute node is hosting the instance."" msgstr ""\""host\"" フィールドは、どのコンピュートノードがインスタンスをホストしているかを示します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml1014(para) msgid """" ""The \""hostname\"" field holds the name of the instance when it is launched. "" ""The \""display-name\"" is initially the same as hostname but can be reset "" ""using the nova rename command."" msgstr ""\""hostname\"" フィールドは、インスタンスが起動したときのインスタンス名を保持します。\""display-name\"" は、最初は hostname と同じですが、nova rename コマンドを使って再設定することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml1018(para) msgid """" ""A number of time related fields are useful for tracking when state changes "" ""happened on an instance:"" msgstr ""多くの時刻関連のフィールドは、いつ状態の変化がインスタンスに起こったかを追跡する際に役に立ちます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml1022(para) msgid ""created_at"" msgstr ""created_at"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml1025(para) msgid ""updated_at"" msgstr ""updated_at"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml1028(para) msgid ""deleted_at"" msgstr ""deleted_at"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml1031(para) msgid ""scheduled_at"" msgstr ""scheduled_at"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml1034(para) msgid ""launched_at"" msgstr ""launched_at"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_user_facing.xml1037(para) msgid ""terminated_at"" msgstr ""terminated_at"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml16(title) msgid ""OpenStack Operations Guide"" msgstr ""OpenStack 運用ガイド"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml18(titleabbrev) msgid ""OpenStack Ops Guide"" msgstr ""OpenStack 運用ガイド"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml26(orgname) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml32(holder) msgid ""OpenStack Foundation"" msgstr ""OpenStack Foundation"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml31(year) msgid ""2013"" msgstr ""2013"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml34(productname) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml16(emphasis) msgid ""OpenStack"" msgstr ""OpenStack"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml39(remark) msgid ""Copyright details are filled in by the template."" msgstr ""Copyright details are filled in by the template."" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml44(para) msgid """" ""This book provides information about designing and operating OpenStack "" ""clouds."" msgstr ""本書は OpenStack クラウドの設計および運用に関する情報を提供します。"" #. ... continue addding more revisions here as you change this document using #. the markup shown below... #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml50(date) msgid ""2013-04-02"" msgstr ""2013-04-02"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml54(para) msgid ""Fixes to ensure samples fit in page size and notes are formatted."" msgstr ""画面例がページや注記に収まるように修正しました。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml61(date) msgid ""2013-03-22"" msgstr ""2013-03-22"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml65(para) msgid ""Stopped chunking in HTML output."" msgstr ""HTML 出力において分割することを止めました。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml74(date) msgid ""2013-03-20"" msgstr ""2013-03-20"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml78(para) msgid ""Editorial changes."" msgstr ""編集における変更をしました。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml81(para) msgid ""Added <literal>glossterm</literal> tags to glossary terms."" msgstr ""<literal>glossterm</literal> タグを用語集の用語に追加しました。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml85(para) msgid ""Cleaned up formatting in code examples."" msgstr ""コード例におけるフォーマットを整理しました。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml89(para) msgid ""Removed future tense."" msgstr ""未来時制を削除しました。"" #. ... continue addding more revisions here as you change this document using #. the markup shown below... #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml97(date) msgid ""2013-03-11"" msgstr ""2013-03-11"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml101(para) msgid ""Moved files to OpenStack github repository."" msgstr ""ファイルを OpenStack github リポジトリに移動しました。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml150(title) msgid ""Glossary"" msgstr ""用語集"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml151(para) msgid """" ""Use this glossary to get definitions of OpenStack-related words and phrases."" msgstr ""OpenStack 関連の用語や言い回しの定義を確認するために、この用語集を使用してください。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml153(para) msgid """" ""To add to this glossary, fork the <literal>openstack/openstack-"" ""manuals</literal> repository on github.com and update the source files "" ""through the OpenStack contribution process."" msgstr ""この用語集に追加するには、OpenStack の貢献プロセスを通して、 github.com にある <literal>openstack/openstack-manuals</literal> リポジトリをフォークして、ソースファイルを更新します。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml159(title) msgid ""A"" msgstr ""A"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml163(para) msgid """" ""The swift context of an account, or a user account from an identity service "" ""such as Active Directory, /etc/passwd, OpenLDAP, keystone, and so on."" msgstr ""Swift のアカウントコンテキスト、または Active Directory、/etc/passwd、OpenLDAP、Keystone などの Identity サービスのアカウント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml170(glossterm) msgid ""account auditor"" msgstr ""account auditor"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml172(para) msgid """" ""Checks for missing replicas, incorrect, and corrupted objects in a specified"" "" swift account by running queries against the back-end SQLite database."" msgstr ""バックエンドの SQLite データベースに対して問合せを実行した特定の Swift アカウント中の消失したレプリカ、不正、破壊されたオブジェクトのチェック。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml179(glossterm) msgid ""account database"" msgstr ""アカウントデータベース"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml181(para) msgid """" ""An SQLite database that contains swift accounts and related metadata and is "" ""accessed by the accounts server. Alternately, the keystone back-end which "" ""contains accounts."" msgstr ""アカウントサーバーからアクセスされる、Swift アカウントと関連メタデータを含むSQLite データベース、又は、アカウントを含む Keystone バックエンド。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml189(glossterm) msgid ""account reaper"" msgstr ""account reaper"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml191(para) msgid """" ""A swift worker that scans for and deletes account databases that are marked "" ""for deletion on an account server."" msgstr ""アカウントサーバー上で削除済みとマークされたアカウントデータベースをスキャン／削除する Swift のワーカープロセス。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml197(glossterm) msgid ""account server"" msgstr ""account server"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml199(para) msgid """" ""Lists containers in swift and stores container information in the account "" ""database."" msgstr ""Swift 中のコンテナの一覧を表示し、アカウントデータベース中のコンテナ情報を保存する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml205(glossterm) msgid ""account service"" msgstr ""account service"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml207(para) msgid """" ""Component of swift that provides account services such as list, create, "" ""modify, and audit. Do not confuse with keystone, OpenLDAP, or similar user "" ""account services."" msgstr ""一覧、作成、修正、監査等のアカウントサービスを提供するSwift のコンポーネント。Keystone、OpenLDAP、又は同様のユーザアカウントサービスと混同しないこと。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml214(glossterm) msgid ""Active Directory"" msgstr ""Active Directory"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml216(para) msgid """" ""Authentication and Identity Service by Microsoft, based on LDAP. Supported "" ""in OpenStack."" msgstr ""OpenStack においてサポートされる、LDAP に基づいた、Microsoft による認証および識別サービス。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml222(glossterm) msgid ""address pool"" msgstr ""アドレスプール"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml224(para) msgid """" ""A group of fixed and/or floating IP addresses that are assigned to a nova "" ""project and can be used by or assigned to the VM instances in a project."" msgstr ""Nova の１プロジェクトに紐付けられ、プロジェクト内の VM インスタンスに割り当てる事で使用可能な固定 IP アドレスと Floating IP アドレスの組。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml231(glossterm) msgid ""admin API"" msgstr ""管理 API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml233(para) msgid """" ""A subset of API calls that are accessible to authorized administrators and "" ""are generally not accessible to end users or the public internet, can exist "" ""as a separate service (keystone) or can be a subset of another API (nova)."" msgstr ""認証済み管理者がアクセス可能で一般に公共のインターネットからのエンドユーザアクセスが出来ない API コールのサブセット。独立したサービス（Keystone）として存在したり、別の API（Nova）のサブセットになり得る。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml242(glossterm) msgid ""Amazon Kernel Image (AKI)"" msgstr ""Amazon Kernel Image (AKI)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml244(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml251(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml258(para) msgid ""Both a VM container format and a VM disk format. Supported by glance."" msgstr ""仮想マシンコンテナー形式および仮想マシンディスク形式。glance がサポートしている。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml249(glossterm) msgid ""Amazon Machine Image (AMI)"" msgstr ""Amazon Machine Image (AMI)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml256(glossterm) msgid ""Amazon Ramdisk Image (ARI)"" msgstr ""Amazon Ramdisk Image (ARI)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml263(glossterm) msgid ""Apache"" msgstr ""Apache"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml265(para) msgid """" ""The most common web server software currently used on the Internet, known as"" "" HTTPd."" msgstr ""現在インターネットにおいて使用されている最も一般的な Web サーバーのソフトウェア。HTTPd としても知られている。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml271(glossterm) msgid ""Apache License 2.0"" msgstr ""Apache License 2.0"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml273(para) msgid """" ""All OpenStack core projects are provided under the terms of the Apache "" ""License 2.0 license."" msgstr ""すべての OpenStack コアプロジェクトは Apache License 2.0 ライセンスの条件で提供されている。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml279(glossterm) msgid ""API endpoint"" msgstr ""API エンドポイント"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml281(para) msgid """" ""The daemon, worker, or service that a client communicates with to access an "" ""API. In OpenStack, API endpoints can provide services such as "" ""authentication, adding images, booting virtual machines, and attaching "" ""volumes."" msgstr ""クライアントが API にアクセスするために通信するデーモン、ワーカーまたはサービス。OpenStack では、認証、イメージの追加、仮想マシンの起動、ボリュームの追加といったサービスは API エンドポイントで提供される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml290(glossterm) msgid ""API extension"" msgstr ""API 拡張"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml292(para) msgid """" ""A feature of nova and quantum that allows custom modules to extend the core "" ""APIs."" msgstr ""独自モジュールがコア API を拡張できるようにする Nova と Quantum の機能。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml297(glossterm) msgid ""API extension plug-in"" msgstr ""API 拡張プラグイン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml299(para) msgid ""Alternative term for a quantum plug-in or quantum API extension."" msgstr ""quantum プラグインまたは quantum API 拡張の別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml304(glossterm) msgid ""API server"" msgstr ""API サーバー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml306(para) msgid ""Any node running a daemon or worker that provides an API endpoint."" msgstr ""API エンドポイントを提供するデーモンまたはワーカーを実行するあらゆるノード。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml311(glossterm) msgid ""API version"" msgstr ""API バージョン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml313(para) msgid """" ""In OpenStack, a the API version for a project is part of the URL. For "" ""example, <code>example.com/nova/v1/foobar</code>."" msgstr ""OpenStack において、プロジェクト向けの API バージョンは URL の一部である。たとえば、 <code>example.com/nova/v1/foobar</code>。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml322(para) msgid """" ""A collection of specifications used to access a service, application, or "" ""program. Includes service calls, required parameters for each call, and the "" ""expected return values."" msgstr ""サービス、アプリケーション、プログラムへのアクセスに使用される仕様の集合。サービス呼出、各呼出に必要なパラメーター、想定される戻り値を含む。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml330(glossterm) msgid ""arptables"" msgstr ""arptables"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml332(para) msgid """" ""Used along with iptables, ebtables, and ip6tables in nova to provide "" ""firewall services."" msgstr ""ファイアウォールサービスを提供する為に Nova 中で iptables, ebtables, ip6tables と一緒に使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml338(glossterm) msgid ""Asynchronous JavaScript and XML (AJAX)"" msgstr ""Asynchronous JavaScript and XML (AJAX)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml341(para) msgid """" ""A group of interrelated web development techniques used on the client-side "" ""to create asynchronous web applications. Used extensively in horizon."" msgstr ""非同期 Web アプリケーションを作成する為にクライアント側で使用される相互関係のある Web 開発技術の集合。Horizon で広く使用されている。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml348(glossterm) msgid ""attachment (network)"" msgstr ""アタッチ（ネットワーク）"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml350(para) msgid """" ""Association of an interface ID to a logical port. Plugs an interface into a "" ""port."" msgstr ""論理ポートへのインターフェースIDの紐付け。インターフェースをポートに差し込む。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml355(glossterm) msgid ""auditor"" msgstr ""auditor"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml357(para) msgid """" ""A worker process that verifies the integrity of swift objects, containers, "" ""and accounts. Auditors is the collective term for the swift account auditor,"" "" container auditor, and object auditor."" msgstr ""Swift オブジェクト、コンテナ、アカウントの完全な状態を検証するワーカープロセス。Auditor は Swift account auditor, container auditor, object auditor の総称。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml367(para) msgid ""Project name for the initial release of OpenStack."" msgstr ""OpenStack の最初のリリースのプロジェクト名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml372(glossterm) msgid ""authentication"" msgstr ""認証"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml374(para) msgid """" ""The process that confirms that the user, process, or client is really who "" ""they say they are through private key, secret token, password, fingerprint, "" ""or similar method. Abbreviated as AuthN."" msgstr ""ユーザー、プロセスまたはクライアントが、秘密鍵、秘密トークン、パスワード、フィンガープリントまたは同様の方式により示されている主体と本当に同じであることを確認するプロセス。AuthN と略される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml382(glossterm) msgid ""authentication token"" msgstr ""認証トークン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml384(para) msgid """" ""A string of text provided to the client after authentication. Must be "" ""provided by the user or process in subsequent requests to the API endpoint."" msgstr ""認証後にクライアントに提供されるテキスト文字列。API エンドポイントに続くリクエストにおいて、ユーザーまたはプロセスにより提供される必要がある。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml391(glossterm) msgid ""authorization"" msgstr ""認可"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml393(para) msgid """" ""The act of verifying that a user, process, or client is authorized to "" ""perform an action, such as delete a swift object, list a swift container, "" ""start a nova VM, reset a password, and so on. Abbreviate as AuthZ."" msgstr ""ユーザー、プロセス、またはクライアントが、ある操作を実行する権限があることを検証する動作。Swift オブジェクトの削除、Swift コンテナーの一覧表示、Nova 仮想マシンの起動、パスワードのリセットなどの操作です。AuthZ と略される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml401(glossterm) msgid ""availability zone"" msgstr ""アベイラビリティゾーン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml403(para) msgid ""A segregated area of a cloud deployment."" msgstr ""クラウドデプロイの独立したエリア。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml409(title) msgid ""B"" msgstr ""B"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml411(glossterm) msgid ""back-end catalog"" msgstr ""バックエンドカタログ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml413(para) msgid """" ""The storage method used by the keystone catalog service to store and "" ""retrieve information about API endpoints that are available to the client. "" ""Examples include a SQL database, LDAP database, or KVS back-end."" msgstr ""クライアントが利用可能なAPI エンドポイントに関する情報の保存、取得の為に Keystone カタログサービスで使用されるストレージ方式。例：SQL データベース、LDAP データベース、KVS バックエンドを含む。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml422(glossterm) msgid ""back-end store"" msgstr ""バックエンドストア"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml424(para) msgid """" ""The persistent data store used that glance uses to retrieve and store VM "" ""images. Options include swift, local file system, S3, and HTTP."" msgstr ""glance が仮想マシンイメージを取得および保管するために使用する永続的なデータストア。オプションに swift、ローカルファイルシステム、S3 および HTTP がある。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml431(glossterm) msgid ""bare"" msgstr ""bare"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml433(para) msgid """" ""A glance container format that indicates that no container exists for the VM"" "" image."" msgstr ""VM イメージ用にコンテナ（保存先）がない事を示す Glance のコンテナフォーマット。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml441(para) msgid """" ""A grouped release of projects related to OpenStack that came out in February"" "" of 2011. It included Compute (nova) and Object Storage (swift) only."" msgstr ""2011年２月に登場した OpenStack 関連プロジェクトのまとまったリリース。Compute (Nova) と Object Storage (Swift) のみが含まれていた。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml448(glossterm) msgid ""block device"" msgstr ""ブロックデバイス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml450(para) msgid """" ""A device that moves data in the form of blocks. These device nodes interface"" "" the devices, such as hard disks, CD-ROM drives, flash drives, and other "" ""addressable regions of memory."" msgstr ""ブロック状態のデータを移動するデバイス。これらのデバイスノードにはハードディスク、CD-ROM ドライブ、フラッシュドライブ、その他のアドレス可能なメモリの範囲等がある。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml458(glossterm) msgid ""block migration"" msgstr ""ブロックマイグレーション"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml460(para) msgid """" ""A method of VM live migration used by KVM to evacuate instances from one "" ""host to another with very little downtime during a user-initiated switch-"" ""over. Does not require shared storage. Supported by nova."" msgstr ""ユーザが移動を指示してから非常に短いダウンタイムであるあるホストから別のホストにインスタンスを移動させる為に KVM で使用される VM ライブマイグレーション方式。共有ストレージを必要としない。Nova でサポート。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml468(glossterm) msgid ""bootable disk image"" msgstr ""ブータブルディスクイメージ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml470(para) msgid ""A type of VM image that exists as a single, bootable file."" msgstr ""単独の、ブート可能なファイルとして存在する仮想マシンイメージの形式。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml475(glossterm) msgid ""builder file"" msgstr ""ビルダーファイル"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml477(para) msgid """" ""Contains configuration information for a swift ring, and is used to re-"" ""configure the ring or to recreate it from scratch after a serious failure."" msgstr ""Swift リング用の設定情報を含み、リングの再設定や深刻な障害後に１からリング情報を作成するのに使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml486(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml890(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1457(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1672(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1696(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1788(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1889(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2799(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml217(th) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml228(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml229(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml233(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml235(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml246(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml257(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml259(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml263(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml265(para) msgid "" "" msgstr "" "" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml491(title) msgid ""C"" msgstr ""C"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml493(glossterm) msgid ""cache pruner"" msgstr ""cache pruner"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml495(para) msgid """" ""An executable program that is used to keep a glance VM image cache at or "" ""below its configured maximum size."" msgstr ""Glance VM イメージキャッシュを設定された最大サイズ以下に保持する為に使用される実行可能プログラム。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml503(para) msgid """" ""An OpenStack grouped release of projects that came out in the spring of "" ""2011. It included Compute (nova), Object Storage (swift), and the Image "" ""service (glance)."" msgstr ""2011年春に登場した OpenStack 関連のプロジェクトリリース。Compute (Nova), Object Storage (Swift), Image Service (Glance) が含まれていた。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml511(glossterm) msgid ""capability"" msgstr ""キャパシティ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml513(para) msgid """" ""Defines resources for a cell, including CPU, storage, and networking. Can "" ""apply to the specific services within a cell or a whole cell."" msgstr ""CPU、ストレージ、ネットワークを含むセルのリソースを定義する。１セルやセル全体に含まれる特定のサービスに適用可能。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml520(glossterm) msgid ""capacity cache"" msgstr ""capacity cache"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml522(para) msgid """" ""A table within the nova back-end database that contains the current "" ""workload, amount of free RAM, number of VMs running on each host. Used to "" ""determine on which VM a host starts."" msgstr ""各ホストの現在の負荷、空き RAM 量、実行中の VM 数を含む、Nova バックエンドデータベース中のテーブル。どのホストで VM を起動するかを決定するのに使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml530(glossterm) msgid ""capacity updater"" msgstr ""capacity updater"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml532(para) msgid """" ""A notification driver that monitors VM instances and updates the capacity "" ""cache as needed."" msgstr ""VM インスタンスを監視し、必要に応じて容量キャッシュを更新する通知ドライバ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml538(glossterm) msgid ""catalog"" msgstr ""カタログ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml540(para) msgid """" ""Contains a list of available API endpoints to a user after they authenticate"" "" to keystone."" msgstr ""Keystone での認証後に、ユーザに返される利用可能な API エンドポイントの一覧。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml546(glossterm) msgid ""catalog service"" msgstr ""カタログサービス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml548(para) msgid """" ""A keystone service that provides a list of available API endpoints to a user"" "" after they authenticate to keystone."" msgstr ""Keystone での認証後にユーザに返される利用可能な API エンドポイントの一覧を提供する Keystone サービス。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml554(glossterm) msgid ""ceilometer"" msgstr ""ceilometer"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml556(para) msgid """" ""An incubated project that provides metering and billing facilities for "" ""OpenStack."" msgstr ""OpenStack 用のメータリング・課金基盤を提供する育成プロジェクト。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml561(glossterm) msgid ""cell"" msgstr ""セル"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml563(para) msgid """" ""Provides logical partitioning of nova resources in a child and parent "" ""relationship. Requests are passed from parent cells to child cells if the "" ""parent cannot provide the requested resource."" msgstr ""親子関係で Nova リソースの論理パーティションを提供する。親セルが要求されたリソースを提供できない場合、親セルからのリクエストは子セルに渡される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml571(glossterm) msgid ""cell forwarding"" msgstr ""セルフォワーディング"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml573(para) msgid """" ""A nova option that allows parent cells to pass resource requests to child "" ""cells if the parent cannot provide the requested resource."" msgstr ""親が要求されたリソースを提供できない場合、親セルがリソース要求を子セルに渡す事を可能にするNovaオプション。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml580(glossterm) msgid ""cell manager"" msgstr ""セルマネージャー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml582(para) msgid """" ""The nova component that contains a list of the current capabilities of each "" ""host within the cell and routes requests as appropriate."" msgstr ""セル中の各ホストの現在のキャパシティの一覧を含み、リクエストを適切な方法でルーティングする Nova コンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml589(glossterm) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml238(para) msgid ""Ceph"" msgstr ""Ceph"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml591(para) msgid """" ""Massively scalable distributed storage system that consists of an object "" ""store, block store, and POSIX-compatible distributed file system. Compatible"" "" with OpenStack."" msgstr ""オブジェクトストア、ブロックストア、および POSIX 互換分散ファイルシステムから構成される大規模スケール可能分散ストレージシステム。OpenStack 互換。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml598(glossterm) msgid ""CephFS"" msgstr ""CephFS"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml600(para) msgid ""The POSIX-compliant file system provided by Ceph."" msgstr ""Ceph により提供される POSIX 互換ファイルシステム。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml605(glossterm) msgid ""certificate authority"" msgstr ""認証局"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml607(para) msgid """" ""A simple certificate authority provided by nova for cloudpipe VPNs and VM "" ""image decryption."" msgstr ""cloudpipe VPN と VM イメージ復号用に Nova が提供するシンプルな認証局。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml613(glossterm) msgid ""chance scheduler"" msgstr ""チャンススケジューラー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml615(para) msgid """" ""A scheduling method used by nova that randomly chooses an available host "" ""from the pool."" msgstr ""プールから利用可能なホストをランダムに選択する為に Nova が使用するスケジュール方式。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml621(glossterm) msgid ""changes-since"" msgstr ""changes-since"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml623(para) msgid """" ""A nova API parameter that allows you to download changes to the requested "" ""item since your last request, instead of downloading a new, fresh set of "" ""data and comparing it against the old data."" msgstr ""新しいデータセットからのダウンロードや古いデータに対する比較の代わりに、あなたの最後のリクエストから要求されたアイテム変更をダウンロードする事を可能にするNova API パラメーター。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml631(glossterm) msgid ""Chef"" msgstr ""Chef"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml633(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2231(para) msgid ""A configuration management tool that supports OpenStack."" msgstr ""OpenStack をサポートする構成管理ツール。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml638(glossterm) msgid ""child cell"" msgstr ""子セル"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml640(para) msgid """" ""If a requested resource such as CPU time, disk storage, or memory is not "" ""available in the parent cell, the request is forwarded to its associated "" ""child cells. If the child cell can fulfill the request, it does. Otherwise, "" ""it attempts to pass the request to any of its children."" msgstr ""CPU 時間、ディスクストレージ、メモリ等の要求されたリソースが親セルで利用不可の場合、リクエストは親セルに紐付けられた子セルに転送される。子セルがリクエストに対応可能な場合、子セルはそのリクエストを処理する。対応不可の場合、そのリクエストを自分の子セルに渡そうとする。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml650(glossterm) msgid ""cinder"" msgstr ""cinder"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml652(para) msgid """" ""The OpenStack Block Storage service that maintains the block devices that "" ""can be attached to virtual machine instances."" msgstr ""仮想マシンのインスタンスに接続できるブロックデバイスを管理する OpenStack ブロックストレージサービス。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml658(glossterm) msgid ""cloud architect"" msgstr ""クラウドアーキテクト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml660(para) msgid ""A person who plans, designs, and oversees the creation of clouds."" msgstr ""クラウドの作成を計画、設計および監督する人。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml665(glossterm) msgid ""cloud controller node"" msgstr ""クラウドコントローラーノード"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml667(para) msgid """" ""A node that runs network, volume, API, scheduler and image services. Each "" ""service may be broken out into separate nodes for scalability or "" ""availability."" msgstr ""network, volume, API, scheduler, Image service を実行するノード。スケーラビリティや可用性の為、各サービスは独立したノード群に分割され得る。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml674(glossterm) msgid ""cloud-init"" msgstr ""cloud-init"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml676(para) msgid """" ""A package commonly installed in VM images that performs initialization of an"" "" instance after boot using information that it retrieves from the metadata "" ""service such as the SSH public key and user data."" msgstr ""メタデータサービスから取得したSSH 公開鍵やユーザデータ等の情報を使用して、起動後にインスタンスの初期化を実行する為にVMイメージに一般にインストールされるパッケージ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml684(glossterm) msgid ""cloudpipe"" msgstr ""cloudpipe"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml686(para) msgid ""A service in nova used to create VPNs on a per-project basis."" msgstr ""プロジェクト単位の VPN 作成用に Nova が使用するサービス。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml691(glossterm) msgid ""cloudpipe image"" msgstr ""cloudpipe イメージ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml693(para) msgid """" ""A pre-made VM image that serves as a cloudpipe server. Essentially, OpenVPN "" ""running on Linux."" msgstr ""cloudpipe サーバとしてサービスを行う為の、予め用意された VM イメージ。本質的には Linux 上で実行される OpenVPN。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml699(glossterm) msgid ""command filter"" msgstr ""コマンドフィルタ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml701(para) msgid ""Lists allowed commands within the nova rootwrap facility."" msgstr ""Nova rootwrap 機構中で許可されたコマンドの一覧。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml706(glossterm) msgid ""community project"" msgstr ""コミュニティプロジェクト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml708(para) msgid """" ""A project that is not officially endorsed by the OpenStack Foundation. If "" ""the project is successful enough, it might be elevated to an incubated "" ""project and then to a core project, or it might be merged with the main code"" "" trunk."" msgstr ""OpenStack Foundation で公認されていないプロジェクト。プロジェクトが充分成功した場合、育成プロジェクトに昇格し、その後コアプロジェクトに昇格する事がある。あるいはメインの code trunk にマージされる事もある。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml717(glossterm) msgid ""Compute API"" msgstr ""Compute API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml719(para) msgid """" ""The nova-api daemon that provides access to the nova services. Can also "" ""communicate with some outside APIs such as the Amazons EC2 API."" msgstr ""Nova サービスへのアクセスを提供する nova-api デーモン。Amazon EC2 API のようないくつかの外部 API でも通信可能。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml726(glossterm) msgid ""Compute API extension"" msgstr ""Compute API extension"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml728(para) msgid ""Alternative term for a nova API extension."" msgstr ""Nova API extension の別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml733(glossterm) msgid ""compute controller"" msgstr ""コンピュートコントローラー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml735(para) msgid """" ""The nova component that chooses suitable hosts on which to start VM "" ""instances."" msgstr ""VM インスタンスを起動する適切なホストを選択する Nova のコンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml740(glossterm) msgid ""compute node"" msgstr ""コンピュートノード"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml742(para) msgid """" ""A node that runs the nova-compute daemon and the virtual machine instances."" msgstr ""nova-compute デーモンと仮想マシンインスタンスを実行するノード。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml747(glossterm) msgid ""compute service"" msgstr ""コンピュートサービス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml749(para) msgid ""Alternative term for the nova component that manages VMs."" msgstr ""VM を管理する Nova コンポーネントの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml754(glossterm) msgid ""concatenated object"" msgstr ""連結オブジェクト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml756(para) msgid """" ""A segmented large object within swift that is put back together again and "" ""then sent to the client."" msgstr ""Swift 中で分割された大きなオブジェクト。再度結合されてから、クライアントに送信される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml762(glossterm) msgid ""consistency window"" msgstr ""一貫性ウインドウ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml764(para) msgid """" ""The amount of time it takes for a new swift object to become accessible to "" ""all clients."" msgstr ""全クライアントがアクセス可能になる為に、新しい Swift オブジェクトに必要な時間。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml770(glossterm) msgid ""console log"" msgstr ""コンソールログ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml772(para) msgid ""Contains the output from a Linux VM console in nova."" msgstr ""Nova 中の Linux VM コンソールからの出力を含む。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml777(glossterm) msgid ""container"" msgstr ""コンテナ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml779(para) msgid """" ""Used to organize and store objects within swift, similar to the concept as a"" "" Linux directory but cannot be nested. Alternative term for a glance "" ""container format."" msgstr ""Swift 中でオブジェクトの構造化、格納に使用される。Linux のディレクトリと同様のコンセプトだが、階層構造にできない。Glance コンテナフォーマットの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml786(glossterm) msgid ""container auditor"" msgstr ""コンテナオーディタ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml788(para) msgid """" ""Checks for missing replicas or incorrect objects in the specified swift "" ""containers through queries to the SQLite back-end database."" msgstr ""SQLite バックエンドデータベースへのクエリを通して、指定された Swift コンテナ中の失われたレプリカや不完全なオブジェクトをチェックする。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml795(glossterm) msgid ""container database"" msgstr ""コンテナデータベース"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml797(para) msgid """" ""A SQLite database that contains swift containers and related metadata and is"" "" accessed by the container server"" msgstr ""Swift コンテナと関連メタデータを含む SQLite データベース。container サーバからアクセスされる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml803(glossterm) msgid ""container format"" msgstr ""コンテナフォーマット"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml805(para) msgid """" ""The \""envelope\"" used by glance to store a VM image and its associated "" ""metadata, such as machine state, OS disk size, and so on."" msgstr ""VM イメージの保存用に Glance が使用する「封筒」。マシン状態、OS ディスクサイズ等のメタデータに紐付けられる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml811(glossterm) msgid ""container server"" msgstr ""コンテナサーバー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml813(para) msgid ""Component of swift that manages containers."" msgstr ""コンテナを管理する Swift のコンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml818(glossterm) msgid ""container service"" msgstr ""コンテナサービス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml820(para) msgid """" ""The swift component that provides container services, such as create, "" ""delete, list, and so on."" msgstr ""作成、削除、覧等のコンテナサービスを提供する Swift コンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml826(glossterm) msgid ""controller node"" msgstr ""コントローラーノード"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml828(para) msgid ""Alternative term for a cloud controller node."" msgstr ""クラウドコントローラーノードの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml833(glossterm) msgid ""core API"" msgstr ""コアAPI"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml835(para) msgid """" ""Depending on context, the core API is either the OpenStack API or the main "" ""API of a specific core project, such as nova, quantum, glance, and so on."" msgstr ""文脈に依存する。コアAPI は OpenStack API またはNova, Quantum, Glance 等の特定のコアプロジェクトのメイン API のいずれかである。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml842(glossterm) msgid ""core project"" msgstr ""コアプロジェクト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml844(para) msgid """" ""An official OpenStack project. Currently consists of Compute (nova), Object "" ""Storage (swift), Image Service (glance), Identity (keystone), Dashboard "" ""(horizon), Networking (quantum), and Volume (cinder)."" msgstr ""OpenStack の公式プロジェクト。現在、Compute (nova), Object Storage (swift), Image Service (glance), Identity (keystone), Dashboard (horizon), Networking (quantum), Volume (cinder) が含まれる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml852(glossterm) msgid ""credentials"" msgstr ""クレデンシャル"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml854(para) msgid """" ""Data that is only known to or accessible by a user that is used to verify "" ""the user is who they say they are and presented to the server during "" ""authentication. Examples include a password, secret key, digital "" ""certificate, fingerprint, and so on."" msgstr ""ユーザーだけが知っているデータもしくはユーザーだけがアクセスできるデータで、認証時にサーバーに示され、ユーザーが誰であるかの確認に使用される。例：パスワード、シークレットキー、デジタル認証、フィンガープリントなど。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml863(glossterm) msgid ""Crowbar"" msgstr ""Crowbar"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml865(para) msgid """" ""An open source community project by Dell that aims to provide all necessary "" ""services to quickly deploy clouds."" msgstr ""クラウドの迅速なデプロイ用に全ての必要なサービスを提供する用途の、Dell によるオープンソースコミュニティプロジェクト。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml871(glossterm) msgid ""current workload"" msgstr ""カレントワークロード"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml873(para) msgid """" ""An element of the nova capacity cache that is calculated based on the number"" "" of build, snapshot, migrate, and resize operations currently in progress on"" "" a given host."" msgstr ""指定されたホスト上で現在進行中の build, snapshot, migrate, resize の操作数を元に計算される、Nova のキャパシティキャッシュの１要素。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml880(glossterm) msgid ""customization module"" msgstr ""カスタムモジュール"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml882(para) msgid """" ""A user-created Python module that is loaded by horizon to change the look "" ""and feel of the dashboard."" msgstr ""ダッシュボードのルックアンドフィールを変更する為に Horizon がロードする、ユーザが作成した Python モジュール。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml895(title) msgid ""D"" msgstr ""D"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml899(para) msgid """" ""The web-based management interface for OpenStack. An alternative name for "" ""horizon."" msgstr ""OpenStack 用 Web ベース管理インターフェース。Horizon の別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml905(glossterm) msgid ""database replicator"" msgstr ""データベースレプリケータ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml907(para) msgid """" ""The component of swift that copies changes in the account, container, and "" ""object databases to other nodes."" msgstr ""他ノードにアカウント、コンテナ、オブジェクトデータベースの変更をコピーする Swift のコンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml913(glossterm) msgid ""default panel"" msgstr ""デフォルトパネル"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml915(para) msgid """" ""The panel that is displayed when a user accesses the horizon dashboard."" msgstr ""ユーザが Horizon ダッシュボードにアクセスした際に表示されるパネル。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml920(glossterm) msgid ""default tenant"" msgstr ""デフォルトテナント"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml922(para) msgid """" ""New users are assigned to this keystone tenant if no tenant is specified "" ""when a user is created."" msgstr ""ユーザ作成時にテナントが指定されなかった場合、新しいユーザはこの Keystone テナントに割り当てられる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml928(glossterm) msgid ""default token"" msgstr ""デフォルトトークン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml930(para) msgid """" ""A keystone token that is not associated with a specific tenant and is "" ""exchanged for a scoped token."" msgstr ""特定のテナントに紐付けられず、スコープ付きトークン用と交換される Keystone トークン。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml936(glossterm) msgid ""delayed delete"" msgstr ""遅延削除"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml938(para) msgid """" ""An option within glance so that rather than immediately delete an image, it "" ""is deleted after a pre-defined number of seconds."" msgstr ""イメージを即時削除する代わりに、あらかじめ定義された秒数後に削除する Glance のオプション。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml944(glossterm) msgid ""delivery mode"" msgstr ""デリバリモード"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml946(para) msgid """" ""Setting for the nova RabbitMQ message delivery mode, can be set to either "" ""transient or persistent."" msgstr ""Nova RabbitMQ メッセージ配信モード用設定。transient（一時）又は persistent（永続）のいずれかを設定できる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml952(glossterm) msgid ""device"" msgstr ""デバイス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml954(para) msgid ""In the context of swift this refers to the underlying storage device."" msgstr ""Swift の文中では、下位のストレージ装置を指す。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml959(glossterm) msgid ""device ID"" msgstr ""デバイス ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml961(para) msgid ""Maps swift partitions to physical storage devices."" msgstr ""Swift パーティション⇒物理ストレージ装置への対応表。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml966(glossterm) msgid ""device weight"" msgstr ""デバイスウェイト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml968(para) msgid """" ""Used to distribute the partitions among swift devices. The distribution is "" ""usually proportional to the storage capacity of the device."" msgstr ""Swift デバイス間のパーティション分散に使用される。通常、分散はデバイスのストレージ容量に比例する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml977(para) msgid """" ""Community project that uses shell scripts to quickly deploy complete "" ""OpenStack development environments."" msgstr ""完全な OpenStack 開発環境を迅速にデプロイする為のシェルスクリプトを使用するコミュニティプロジェクト。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml985(para) msgid """" ""A grouped release of projects related to OpenStack that came out in the fall"" "" of 2011, the fourth release of OpenStack. It included Compute (nova "" ""2011.3), Object Storage (swift 1.4.3), and the Image service (glance)."" msgstr ""2011年秋に登場した OpenStack 関連プロジェクトのリリース。Compute (nova 2011.3), Object Storage (swift 1.4.3), Image service (glance) が含まれる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml993(glossterm) msgid ""disk format"" msgstr ""ディスクフォーマット"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml995(para) msgid """" ""The underlying format that a disk image for a VM is stored as within the "" ""glance back-end store. For example, AMI, ISO, QCOW2, VMDK, and so on."" msgstr ""Glance バックエンドストアで格納される VM 用ディスクイメージのフォーマット。 AMI, ISO, QCOW2, VMDK など。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1002(glossterm) msgid ""dispersion"" msgstr ""dispersion"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1004(para) msgid """" ""In swift, tools to test and ensure dispersion of objects and containers to "" ""ensure fault tolerance."" msgstr ""Swift で、フォールトトレラントの確認の為に、オブジェクトとコンテナの分散をテスト、確認するツール。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1010(glossterm) msgid ""Django"" msgstr ""Django"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1012(para) msgid ""A web framework used extensively in horizon."" msgstr ""Horizon 中で広く使用される Web フレームワーク。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1017(glossterm) msgid ""dnsmasq"" msgstr ""dnsmasq"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1019(para) msgid """" ""Daemon that provides DNS, DHCP, BOOTP, and TFTP services, used by the nova "" ""VLAN manager and FlatDHCP manager."" msgstr ""DNS, DHCP, BOOTP, TFTP サービスを提供するデーモン。Nova の VLAN マネージャーと FlatDHCP マネージャーが使用する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1025(glossterm) msgid ""DNS record"" msgstr ""DNS レコード"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1027(para) msgid """" ""A record that specifies information about a particular domain and belongs to"" "" the domain."" msgstr ""特定のドメインに関する情報を指定し、ドメインに所属するレコード。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1033(glossterm) msgid ""Dynamic Host Configuration Protocol (DHCP)"" msgstr ""動的ホスト設定プロトコル（DHCP）"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1036(para) msgid """" ""A method to automatically configure networking for a host at boot time. "" ""Provided by both quantum and nova."" msgstr ""ホスト起動時に自動的にネットワークを設定する方式。Quantum と Nova の両方が提供する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1043(title) msgid ""E"" msgstr ""E"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1045(glossterm) msgid ""ebtables"" msgstr ""ebtables"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1047(para) msgid """" ""Used in nova along with arptables, iptables, and ip6tables to create "" ""firewalls and to ensure isolation of network communications."" msgstr ""ファイアウォールを作成し、ネットワーク通信の分離を確立する為に arptables, iptables, ip6tables と一緒に Nova で使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1054(glossterm) msgid ""EC2"" msgstr ""EC2"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1056(para) msgid """" ""The Amazon Elastic Compute Cloud, a public cloud run by Amazon that provides"" "" similar functionality to nova."" msgstr ""Amazon Elastic Compute Cloud。Nova と同様の機能を提供するアマゾンによるパブリッククラウド。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1062(glossterm) msgid ""EC2 access key"" msgstr ""EC2 アクセスキー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1064(para) msgid ""Used along with an EC2 secret key to access the nova EC2 API."" msgstr ""Nova の EC2 API へのアクセスの為に、EC2 シークレットキーと一緒に使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1069(glossterm) msgid ""EC2 API"" msgstr ""EC2 API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1071(para) msgid ""OpenStack supports accessing the Amazon EC2 API through nova."" msgstr ""OpenStack は Nova で Amazon EC2 API によるアクセスをサポートする。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1076(glossterm) msgid ""EC2 Compatibility API"" msgstr ""EC2 互換API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1078(para) msgid ""A nova component that allows OpenStack to communicate with Amazon EC2"" msgstr ""OpenStack による Amazon EC2 による通信を可能にする Nova コンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1083(glossterm) msgid ""EC2 secret key"" msgstr ""EC2 シークレットキー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1085(para) msgid """" ""Used along with an EC2 access key when communicating with the nova EC2 API, "" ""is used to digitally sign each request."" msgstr ""Nova の EC2 API による通信時に EC2 アクセスキーと一緒に使用される。各リクエストのデジタル署名に使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1091(glossterm) msgid ""Elastic Block Storage (EBS)"" msgstr ""Elastic Block Storage (EBS)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1093(para) msgid ""The Amazon commercial block storage product, similar to cinder."" msgstr ""Amazon の商用ブロックストレージ製品。 Cinder と似た機能を持つ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1098(glossterm) msgid ""endpoint"" msgstr ""エンドポイント"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1100(para) msgid ""See API endpoint."" msgstr ""API エンドポイントを参照。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1104(glossterm) msgid ""endpoint registry"" msgstr ""エンドポイントレジストリ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1106(para) msgid ""Alternative term for a keystone catalog."" msgstr ""keystone カタログの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1111(glossterm) msgid ""endpoint template"" msgstr ""エンドポイントテンプレート"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1113(para) msgid """" ""A list of URL and port number endpoints that indicate where a service, such "" ""as object storage, compute, identity, and so on, can be accessed."" msgstr ""Object Storage、Compute、Identity などサービスがアクセスできる場所を示す、URL とポート番号のエンドポイントの一覧。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1120(glossterm) msgid ""entity"" msgstr ""エンティティ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1122(para) msgid """" ""Any piece of hardware or software that wants to connect to the network "" ""services provided by quantum, the Network Connectivity service. An entity "" ""can make use of quantum by implementing a VIF."" msgstr ""Quantum（ネットワーク接続サービス）により提供されるネットワークサービスへの通信必要なハードウェア又はソフトウェア部品。エンティティは VIF を実装する為に Quantum に使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1130(glossterm) msgid ""ephemeral storage"" msgstr ""エフェメラルストレージ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1132(para) msgid """" ""A storage volume attached to a virtual machine instance that does not "" ""persist after the instance is terminated."" msgstr ""仮想マシンインスタンスにアタッチされたストレージボリューム。インスタンスが削除された後に永続しない。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1140(para) msgid """" ""A grouped release of projects related to OpenStack that came out in April "" ""2012, the fifth release of OpenStack. It included Compute (nova 2012.1), "" ""Object Storage (swift 1.4.8), Image (glance), Identity (keystone), and "" ""Dashboard (horizon)."" msgstr ""2012年４月に登場した OpenStack 関連プロジェクトのリリース。Compute (nova 2012.1), Object Storage (swift 1.4.8), Image (glance), Identity (keystone), Dashboard (horizon) が含まれる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1149(glossterm) msgid ""ESX"" msgstr ""ESX"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1151(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1158(para) msgid ""An OpenStack-supported hypervisor, owned by VMware."" msgstr ""OpenStack がサポートしている、VMware のハイパーバイザーの１つ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1156(glossterm) msgid ""ESXi"" msgstr ""ESXi"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1163(glossterm) msgid ""ETag"" msgstr ""ETag"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1165(para) msgid ""MD5 hash of an object within swift, used to ensure data integrity."" msgstr ""Swift 中でのオブジェクトの MD5 ハッシュ。データの完全性の保証に使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1170(glossterm) msgid ""euca2ools"" msgstr ""euca2ools"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1172(para) msgid """" ""A collection of command line tools for administering VMs, most are "" ""compatible with OpenStack."" msgstr ""仮想マシンを管理するためのコマンドラインツール集。ほとんどは OpenStack と互換性がある。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1178(glossterm) msgid ""evacuate"" msgstr ""evacuate"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1180(para) msgid """" ""The process of migrating one or all virtual machine (VM) instances from one "" ""host to another, compatible with both shared storage live migration and "" ""block migration."" msgstr ""１つまたは全ての仮想マシン（VM）インスタンスをあるホストから別のホストにマイグレーションする処理。共有ストレージのライブマイグレーションとブロックマイグレーション両方と互換がある。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1187(glossterm) msgid ""extension"" msgstr ""エクステンション"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1189(para) msgid """" ""Alternative term for a nova API extension or plug-in. In the context of "" ""keystone this is a call that is specific to the implementation, such as "" ""adding support for OpenID."" msgstr ""Nova API エクステンション又はプラグインの別名。Keystone の文脈では、OpenID 用追加サポートのような実装を示す呼び方。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1196(glossterm) msgid ""extra specs"" msgstr ""拡張仕様"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1198(para) msgid """" ""Additional requirements that a user can specify when requesting a new "" ""instance, examples include a minimum amount of network bandwidth or a GPU."" msgstr ""ユーザが新しいインスタンスをリクエストする際に指定可能な、追加の要求事項。例：最小ネットワーク帯域、GPU。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1206(title) msgid ""F"" msgstr ""F"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1208(glossterm) msgid ""FakeLDAP"" msgstr ""FakeLDAP"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1210(para) msgid """" ""An easy method to create a local LDAP directory for testing keystone and "" ""nova. Requires Redis."" msgstr ""keystone と nova をテストするためにローカル LDAP ディレクトリを作成する簡単な方法。Redis が必要。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1216(glossterm) msgid ""fill-first scheduler"" msgstr ""充填優先スケジューラー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1218(para) msgid """" ""The nova scheduling method that attempts to fill a host with VMs rather than"" "" starting new VMs on a variety of hosts."" msgstr ""様々なホスト上で新しい VM を起動するよりも、なるべく一つのホストを埋めようとする Nova スケジューリング手法。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1224(glossterm) msgid ""filter"" msgstr ""フィルター"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1226(para) msgid """" ""The step of the nova scheduling process where hosts that cannot run the VMs "" ""are eliminated and are not chosen."" msgstr ""VM を実行できないホストを排除し、選択されないようにする Nova のスケジューリング処理の段階。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1232(glossterm) msgid ""firewall"" msgstr ""ファイアウォール"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1234(para) msgid """" ""Used to restrict communications between hosts and/or nodes, implemented in "" ""nova using iptables, arptables, ip6tables and etables."" msgstr ""ホストノード間の通信を制限する為に使用される。iptables, arptables, ip6tables, ebtables を使用して Nova により実装される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1241(glossterm) msgid ""Fixed IP address"" msgstr ""固定 IP アドレス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1243(para) msgid """" ""An IP address that is associated with the same instance each time that "" ""instance boots, generally not accessible to end users or the public "" ""internet, used for management of the instance."" msgstr ""インスタンス起動時に毎回同じインスタンスに割当られるIPアドレス（一般に、エンドユーザやパブリックインターネットからはアクセス出来ない）。インスタンスの管理に使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1251(glossterm) msgid ""FlatDHCP Manager"" msgstr ""FlatDHCP マネージャー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1253(para) msgid """" ""A nova networking manager that provides a single Layer 2 domain for all "" ""subnets in the OpenStack cloud. Provides a single DHCP server for each "" ""instance of nova-network to assign and manage IP addresses for all "" ""instances."" msgstr ""OpenStack クラウド中の全サブネット用に単一のレイヤ２ドメインを提供する Nova のネットワークマネージャー。nova-network インスタンス毎に１つの DHCP サーバーを提供し、全インスタンスの IP アドレスを管理する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1262(glossterm) msgid ""Flat Manager"" msgstr ""Flat マネージャー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1264(para) msgid """" ""The nova component that gives IP addresses to authorized nodes and assumes "" ""DHCP, DNS, and routing configuration and services are provided by something "" ""else."" msgstr ""許可されたノードにIP アドレスを提供する Nova コンポーネント。DHCP、DNS、ルーティング設定、他の何かによって提供されるサービスを前提とする。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1271(glossterm) msgid ""flat mode injection"" msgstr ""フラットモードインジェクション"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1273(para) msgid """" ""A nova networking method where the OS network configuration information is "" ""injected into the VM (VM) image before the instance starts."" msgstr ""インスタンスが起動する前に VM イメージにOS ネットワーク設定を挿入する Nova ネットワーク方式。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1280(glossterm) msgid ""flat network"" msgstr ""フラットネットワーク"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1282(para) msgid """" ""A nova network configuration where all of the instances have IP addresses on"" "" the same subnet. Flat networks do not use VLANs."" msgstr ""全インスタンスが同じサブネットに IP アドレスを持つ Nova のネットワーク構成。フラットネットワークは VLAN を使用しない。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1288(glossterm) msgid ""flavor"" msgstr ""フレーバー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1290(para) msgid """" ""Describes the parameters of the various virtual machine images that are "" ""available to users, includes parameters such as CPU, storage, and memory. "" ""Also known as instance type."" msgstr ""ユーザが利用可能な様々な仮想マシンイメージのパラメーター（CPU、ストレージ、メモリ等を含む）を示す。インスタンスタイプとしても知られている。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1298(glossterm) msgid ""flavor ID"" msgstr ""フレーバー ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1300(para) msgid ""UUID for each nova or glance VM flavor or instance type."" msgstr ""Nova 又は Glance VM 用の、フレーバーまたはインスタンスタイプのUUID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1305(glossterm) msgid ""Floating IP address"" msgstr ""Floating IP アドレス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1307(para) msgid """" ""An IP address that a nova project can associate with a VM so the instance "" ""has the same public IP address each time that it boots. You create a pool of"" "" floating IP addresses and assign them to instances as they are launched to "" ""maintain a consistent IP address for maintaining DNS assignment."" msgstr ""Nova プロジェクトが１ VM に紐付け可能な IP アドレス。これにより、インスタンス起動時に毎回同じパブリック IP アドレスがインスタンスに割り当てできる。DNS 割当管理用の一貫した IP アドレスを管理する為に、Floating IP アドレスのプールを作成し、VM 起動時にインスタンスに Floating IP アドレスを割り当てできる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1319(para) msgid """" ""A grouped release of projects related to OpenStack that came out in the fall"" "" of 2012, the sixth release of OpenStack. It includes Compute (nova), Object"" "" Storage (swift), Identity (keystone), Networking (quantum), Image service "" ""(glance) and Volumes or Block Storage (cinder)."" msgstr ""2012年秋に登場した OpenStack 関連プロジェクトのリリース。Compute (nova), Object Storage (swift), Identity (keystone), Networking (quantum), Image service (glance)、Volumes 又は Block Storage (cinder) が含まれる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1329(glossterm) msgid ""FormPost"" msgstr ""FormPost"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1331(para) msgid """" ""swift middleware that allows users to upload (post) an image through a form "" ""on a web page."" msgstr ""ユーザが Web ページの Form を介してイメージをアップロード（ポスト）できるようにする為の Swift ミドルウェア。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1338(title) msgid ""G"" msgstr ""G"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1340(glossterm) msgid ""glance"" msgstr ""glance"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1342(para) msgid ""A core project that provides the OpenStack Image Service."" msgstr ""OpenStack イメージサービスを提供するコアプロジェクト。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1347(glossterm) msgid ""glance API server"" msgstr ""glance API サーバー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1349(para) msgid """" ""Processes client requests for VMs, updates glance metadata on the registry "" ""server, and communicates with the store adapter to upload VM images from the"" "" back-end store."" msgstr ""VM 用クライアントリクエストの処理、registry サーバー上での Glance メタデータの更新、バックエンドストアから VM イメージをアップロードする為のストアアダプタによる通信。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1356(glossterm) msgid ""global endpoint template"" msgstr ""グローバルエンドポイントテンプレート"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1358(para) msgid """" ""The keystone endpoint template that contains services available to all "" ""tenants."" msgstr ""全テナントが利用可能なサービスを含む Keystone のエンドポイントテンプレート。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1365(para) msgid ""An open-source, distributed, shared file system,"" msgstr ""オープンソース、分散、共有ファイルシステム。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1372(para) msgid ""Project name for the seventh release of OpenStack."" msgstr ""OpenStack の 7 回目リリースのプロジェクト名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1377(glossterm) msgid ""guest OS"" msgstr ""ゲスト OS"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1379(para) msgid """" ""An operating system instance running under the control of a hypervisor."" msgstr ""ハイパーバイザーの管理下で実行しているオペレーティングシステムのインスタンス。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1385(title) msgid ""H"" msgstr ""H"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1387(glossterm) msgid ""handover"" msgstr ""handover"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1389(para) msgid """" ""An object state in swift where a new replica of the object is automatically "" ""created due to a drive failure."" msgstr ""ドライブ障害の為、新しいオブジェクトのレプリカが自動的に作成される、Swift のオブジェクト状態。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1395(glossterm) msgid ""hard reboot"" msgstr ""ハードリブート"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1397(para) msgid """" ""A type of reboot where a physical or virtual power button is pressed as "" ""opposed to a graceful, proper shutdown of the operating system."" msgstr ""きちんとした正常なOSのシャットダウンを行わず、物理又は仮想電源ボタンを押すタイプの再起動。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1404(glossterm) msgid ""Heat"" msgstr ""Heat"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1406(para) msgid """" ""An integrated project that aims to orchestrate multiple cloud applications "" ""for OpenStack."" msgstr ""OpenStack に複数のクラウドアプリケーションをオーケストレーションする為に開発されたプロジェクト。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1414(para) msgid ""The project that provides the OpenStack Dashboard."" msgstr ""OpenStack ダッシュボードを提供するプロジェクトの名前。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1419(glossterm) msgid ""host"" msgstr ""ホスト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1421(para) msgid ""A physical computer, also known as a node. Contrast with: instance."" msgstr ""物理的なコンピュータ（ノードとしても知られる）。対比：インスタンス。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1426(glossterm) msgid ""host aggregate"" msgstr ""ホストアグリゲート"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1428(para) msgid """" ""A method to further subdivide availability zones into a collection of hosts."" msgstr ""アベイラビリティゾーンをホスト群の集合に分割する為の手法。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1433(glossterm) msgid ""Hyper-V"" msgstr ""Hyper-V"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1435(para) msgid ""One of the hypervisors supported by OpenStack, developed by Microsoft."" msgstr ""OpenStack によりサポートされるハイパーバイザーの一つ。Microsoft により開発された。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1440(glossterm) msgid ""hypervisor"" msgstr ""ハイパーバイザー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1442(para) msgid """" ""Software that arbitrates and controls VM access to the actual underlying "" ""hardware."" msgstr ""VM のアクセスを実際の下位ハードウェアに仲介して制御するソフトウェア。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1448(glossterm) msgid ""hypervisor pool"" msgstr ""ハイパーバイザープール"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1450(para) msgid ""A collection of hypervisors grouped together through host aggregates."" msgstr ""ホストアグリゲートにより一緒にグループ化されたハイパーバイザーの集合。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1462(title) msgid ""I"" msgstr ""I"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1464(glossterm) msgid ""ID number"" msgstr ""ID 番号"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1466(para) msgid """" ""Unique numeric ID associated with each user in keystone, conceptually "" ""similar to a Linux or LDAP UID."" msgstr ""Keystone 中で各ユーザに割り当てられた一意な数値 ID。Linux や LDAP の UID と同様の概念。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1472(glossterm) msgid ""Identity API"" msgstr ""Identity API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1474(para) msgid ""Alternative term for the Identity Service API."" msgstr ""Identity サービス API の別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1479(glossterm) msgid ""Identity back-end"" msgstr ""Identity バックエンド"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1481(para) msgid """" ""The source used by keystone to retrieve user information an OpenLDAP server "" ""for example."" msgstr ""Keystone がユーザー情報を取得する情報源。例えば OpenLDAP サーバー。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1487(glossterm) msgid ""Identity Service"" msgstr ""Identity サービス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1489(para) msgid ""Provides authentication services, also known as keystone."" msgstr ""認証サービスを提供する（Keystone としても知られる）。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1494(glossterm) msgid ""Identity Service API"" msgstr ""Identity サービス API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1496(para) msgid """" ""The API used to access the OpenStack Identity Service provided through "" ""keystone."" msgstr ""Keystone が提供する OpenStack Identity サービスアクセスに使用される API。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1502(glossterm) msgid ""image"" msgstr ""イメージ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1504(para) msgid """" ""A collection of files for a specific operating system (OS) that you use to "" ""create or rebuild a server. You can also create custom images, or snapshots,"" "" from servers that you have launched."" msgstr ""サーバーの作成、再構築に使用する特定のオペレーティングシステム（OS）用のファイルの集合。起動したサーバーからカスタムイメージ（又はスナップショット）を作成する事ができる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1512(glossterm) msgid ""Image API"" msgstr ""Image API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1514(para) msgid ""The glance API endpoint for management of VM images."" msgstr ""仮想マシンイメージの管理向け glance API エンドポイント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1519(glossterm) msgid ""image cache"" msgstr ""イメージキャッシュ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1521(para) msgid """" ""Used by glance to allow images on the local host to be used rather than re-"" ""downloading them from the image server each time one is requested."" msgstr ""ユーザが要求したイメージを毎回他のイメージサーバーからイメージを再ダウンロードする代わりに、ローカルホスト上のイメージを利用できるようにする為にGlance により使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1528(glossterm) msgid ""image ID"" msgstr ""イメージ ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1530(para) msgid """" ""Combination of URI and UUID used to access glance VM images through the "" ""image API."" msgstr ""イメージ API を介してGlance イメージアクセスに使用される URI と UUID の組み合わせ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1535(glossterm) msgid ""image membership"" msgstr ""イメージメンバーシップ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1537(para) msgid ""A list of tenants that can access a given VM image within glance."" msgstr ""Glance 中で与えられた VM イメージへのアクセスが可能なテナントの一覧。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1542(glossterm) msgid ""image owner"" msgstr ""イメージ所有者"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1544(para) msgid ""The keystone tenant who owns a glance virtual machine image."" msgstr ""Glance 仮想マシンイメージを所有する Keystone テナント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1549(glossterm) msgid ""image registry"" msgstr ""イメージレジストリ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1551(para) msgid ""A list of VM images that are available through glance."" msgstr ""Glance 経由で利用可能な VM イメージの一覧。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1556(glossterm) msgid ""Image Service API"" msgstr ""Image サービス API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1558(para) msgid ""Alternative name for the glance image API."" msgstr ""Glance イメージ API の別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1563(glossterm) msgid ""image status"" msgstr ""イメージ状態"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1565(para) msgid """" ""The current status of a VM image in glance, not to be confused with the "" ""status of a running instance."" msgstr ""Glance 中の VM イメージの現在の状態。稼働中のインスタンスの状態と混同しない事。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1571(glossterm) msgid ""image store"" msgstr ""イメージストア"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1573(para) msgid """" ""The back-end store used by glance to store VM images, options include swift,"" "" local file system, S3, or HTTP."" msgstr ""VM イメージの保存用に Glance が使用するバックエンドストア。選択肢には Swift、ローカルファイルシステム、S3、HTTP がある。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1579(glossterm) msgid ""image UUID"" msgstr ""イメージ UUID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1581(para) msgid ""The UUID used by glance to uniquely identify each VM image."" msgstr ""Glance が各 VM イメージを一意に識別するために使用する UUID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1586(glossterm) msgid ""incubated project"" msgstr ""インキュベートプロジェクト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1588(para) msgid """" ""A community project may be elevated to this status and is then promoted to a"" "" core project."" msgstr ""育成プロジェクト。コミュニティプロジェクトがこの状態に昇格する事があり、その後コアプロジェクトに昇格する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1594(glossterm) msgid ""ingress filtering"" msgstr ""イングレスフィルタリング"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1596(para) msgid ""The process of filtering incoming network traffic. Supported by nova."" msgstr ""外部から内部へのネットワーク通信のフィルタリング処理。Nova がサポートする。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1601(glossterm) msgid ""injection"" msgstr ""インジェクション"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1603(para) msgid """" ""The process of putting a file into a virtual machine image before the "" ""instance is started."" msgstr ""インスタンスが起動する前に、仮想マシンイメージ中にファイルを配置する処理。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1609(glossterm) msgid ""instance"" msgstr ""インスタンス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1611(para) msgid """" ""A running VM, or a VM in a known state such as suspended that can be used "" ""like a hardware server."" msgstr ""ハードウェアサーバーのように使用できる、実行中の仮想マシン、またはサスペンド中のような既知の状態にある仮想マシン。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1617(glossterm) msgid ""instance ID"" msgstr ""インスタンス ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1619(para) msgid ""Unique ID that is specific to each running nova VM instance."" msgstr ""実行中の各 nova 仮想マシンインスタンスを特定する一意な ID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1624(glossterm) msgid ""instance state"" msgstr ""インスタンス状態"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1626(para) msgid ""The current state of a nova VM image."" msgstr ""Nova の VM イメージの現在の状態。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1630(glossterm) msgid ""instance type"" msgstr ""インスタンスタイプ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1632(para) msgid ""Alternative term for flavor."" msgstr ""フレーバーの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1636(glossterm) msgid ""instance type ID"" msgstr ""インスタンスタイプ ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1638(para) msgid ""Alternative term for a flavor ID."" msgstr ""フレーバー ID の別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1642(glossterm) msgid ""instance UUID"" msgstr ""インスタンス UUID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1644(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2501(para) msgid ""Unique ID assigned to each nova VM instance."" msgstr ""各 nova 仮想マシンインスタンスに割り当てられた一意な ID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1649(glossterm) msgid ""interface ID"" msgstr ""インターフェース ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1651(para) msgid ""Unique ID for a quantum VIF or vNIC in the form of a UUID."" msgstr ""UUID 形式の、Quantum VIF 又は仮想 NIC 用の一意な ID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1656(glossterm) msgid ""ip6tables"" msgstr ""ip6tables"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1658(para) msgid """" ""Used along with arptables, ebtables, and iptables to create firewalls in "" ""nova."" msgstr ""Nova の中でファイアウォールを作成するのに、arptables, ebtables, iptables と一緒に使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1665(para) msgid """" ""Used along with arptables, ebtables, and ip6tables to create firewalls in "" ""nova."" msgstr ""Nova 中でファイアウォールを作成する為に arptables, ebtables, ip6tables と一緒に使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1677(title) msgid ""J"" msgstr ""J"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1679(glossterm) msgid ""JavaScript Object Notation (JSON)"" msgstr ""JavaScript Object Notation (JSON)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1682(para) msgid ""One of the supported response formats for the OpenStack API."" msgstr ""OpenStack API 用にサポートされたレスポンスフォーマットの１つ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1687(glossterm) msgid ""Jenkins"" msgstr ""Jenkins"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1689(para) msgid ""Tool used for OpenStack development to run jobs automatically."" msgstr ""OpenStack 開発で自動的にジョブを実行するために使用されるツール。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1701(title) msgid ""K"" msgstr ""K"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1703(glossterm) msgid ""kernel-based VM (KVM)"" msgstr ""kernel-based VM (KVM)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1705(para) msgid ""An OpenStack-supported hypervisor"" msgstr ""OpenStack がサポートするハイパーバイザの１つ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1711(para) msgid ""The project that provides OpenStack Identity services."" msgstr ""OpenStack Identity サービスを提供するプロジェクト。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1716(glossterm) msgid ""Kickstart"" msgstr ""Kickstart"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1718(para) msgid """" ""A tool to automate system configuration and installation on Red Hat, Fedora,"" "" and CentOS based Linux distributions."" msgstr ""Red Hat、Fedora、CentOS ベースの Linux ディストリビューションのインストールとシステム設定を自動化するツール。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1725(title) msgid ""L"" msgstr ""L"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1727(glossterm) msgid ""large object"" msgstr ""ラージオブジェクト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1729(para) msgid ""An object within swift that is larger than 5 GBs."" msgstr ""5GB より大きな Swift 中のオブジェクト。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1734(glossterm) msgid ""Launchpad"" msgstr ""Launchpad"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1736(para) msgid ""The collaboration site for OpenStack."" msgstr ""OpenStack 用コラボレーションサイト。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1740(glossterm) msgid ""Layer-2 network"" msgstr ""レイヤ2 ネットワーク"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1742(para) msgid ""Term used for OSI network architecture for the data link layer."" msgstr ""データリンクレイヤ用の OSI ネットワークアーキテクチャで使用される用語。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1747(glossterm) msgid ""libvirt"" msgstr ""libvirt"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1749(para) msgid """" ""Virtualization API library used by OpenStack to interact with many of its "" ""supported hypervisors, including KVM, QEMU and LXC."" msgstr ""KVM、QEMU、LXC を含む多数の対応ハイパーバイザと通信する為の、OpenStack で使用される仮想化 API ライブラリ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1756(glossterm) msgid ""Linux bridge"" msgstr ""Linux ブリッジ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1758(para) msgid """" ""Software used to allow multiple VMs to share a single physical NIC within "" ""nova."" msgstr ""Nova 中で、複数の VM が単一の物理 NIC を共用する事を可能にする為に使用されるソフトウェア。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1763(glossterm) msgid ""Linux bridge quantum plug-in"" msgstr ""Linux ブリッジ Quantum プラグイン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1765(para) msgid """" ""Plugin that allows a Linux bridge to understand a quantum port, interface "" ""attachment, and other abstractions."" msgstr ""Quantum のポート、インターフェース接続、その他抽象概念を認識する、Linux ブリッジ用のプラグイン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1771(glossterm) msgid ""Linux containers (LXC)"" msgstr ""Linux コンテナー （LXC）"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1773(para) msgid ""An OpenStack-supported hypervisor."" msgstr ""OpenStack がサポートするハイパーバイザーの１つ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1779(para) msgid """" ""The ability within nova to move running virtual machine instances from one "" ""host to another with only a small service interruption during switch-over."" msgstr ""実行中の仮想マシンインスタンスを、切替時の短時間のサービス中断だけであるホストから別ホストに移動させる為の、Nova 中の機能。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1793(title) msgid ""M"" msgstr ""M"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1795(glossterm) msgid ""management API"" msgstr ""マネジメント API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1797(para) msgid ""Alternative term for an admin API."" msgstr ""管理 API（admin API）の別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1801(glossterm) msgid ""management network"" msgstr ""管理ネットワーク"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1803(para) msgid """" ""A network segment used for administration, not accessible to the public "" ""internet."" msgstr ""管理者が使用するネットワークセグメント（パブリックインターネットからはアクセス不可）。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1808(glossterm) msgid ""manifest"" msgstr ""マニフェスト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1810(para) msgid ""Used to track segments of a large object within swift."" msgstr ""Swift 中でラージオブジェクトのセグメントを追跡する為に使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1815(glossterm) msgid ""manifest object"" msgstr ""マニフェストオブジェクト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1817(para) msgid ""A special swift object that contains the manifest for a large object."" msgstr ""ラージオブジェクトのマニフェストを含む特別な Swift オブジェクト。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1822(glossterm) msgid ""membership"" msgstr ""メンバーシップ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1824(para) msgid """" ""The association between a glance VM image and a tenant, allows images to be "" ""shared with specified tenant(s)."" msgstr ""Glance VM イメージとテナント間の関連付け。指定されたテナント間でイメージを共有できるようにする。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1830(glossterm) msgid ""membership list"" msgstr ""メンバーシップリスト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1832(para) msgid """" ""Contains a list of tenants that can access a given VM image within glance."" msgstr ""Glance 中で指定された VM イメージにアクセスできるテナントの一覧を含む。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1837(glossterm) msgid ""memory overcommit"" msgstr ""メモリーオーバーコミット"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1839(para) msgid """" ""The ability to start new VM instances based on the actual memory usage of a "" ""host, as opposed to basing the decision on the amount of RAM each running "" ""instance thinks it has available. Also known as RAM overcommit."" msgstr ""実行中の各インスタンスが利用可能と考えている RAM 量に基づく判断をベースにする代わりに、ホスト上の実際のメモリ使用量をベースにした、新しい VM インスタンスを起動する機能。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1848(glossterm) msgid ""message broker"" msgstr ""メッセージブローカー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1850(para) msgid """" ""The software package used to provide AMQP messaging capabilities within "" ""nova, default is RabbitMQ."" msgstr ""Nova 中で AMQP メッセージ機能を提供する為に使用されるソフトウェアパッケージ。デフォルトは RabbitMQ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1856(glossterm) msgid ""message bus"" msgstr ""メッセージバス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1858(para) msgid """" ""The main virtual communication line used by all AMQP messages for inter-"" ""cloud communications within nova."" msgstr ""Nova 中でクラウド間通信用の全 AMQP メッセージに使用される主要な仮想通信線。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1864(glossterm) msgid ""message queue"" msgstr ""メッセージキュー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1866(para) msgid """" ""Passes requests from clients to the appropriate workers and returns the "" ""output to the client once the job is complete."" msgstr ""クライアントからのリクエストを適切なワーカーに渡し、ジョブが完了した際にクライアントに出力を返す。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1872(glossterm) msgid ""migration"" msgstr ""マイグレーション"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1874(para) msgid ""The process of moving a VM instance from one host to another."" msgstr ""VM インスタンスをあるホストから別のホストに移動させる処理。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1879(glossterm) msgid ""multinic"" msgstr ""マルチ NIC"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1881(para) msgid """" ""Facility in nova that allows each virtual machine instance to have more than"" "" one VIF connected to it."" msgstr ""各仮想マシンインスタンスが複数の VIF を持つことを可能にする Nova の機能。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1894(title) msgid ""N"" msgstr ""N"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1896(glossterm) msgid ""network ID"" msgstr ""ネットワーク ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1898(para) msgid ""Unique ID assigned to each network segment within quantum."" msgstr ""Quantum 中で各ネットワークセグメントに割り当てられた一意な ID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1903(glossterm) msgid ""network manager"" msgstr ""ネットワークマネージャー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1905(para) msgid """" ""The nova component that manages various network components, such as firewall"" "" rules, IP address allocation, and so on."" msgstr ""ファイアウォールルール、IP アドレス割り当て等の様々なネットワークコンポーネントを管理する Nova のコンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1911(glossterm) msgid ""network node"" msgstr ""ネットワークノード"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1913(para) msgid ""Any nova node that runs the network worker daemon."" msgstr ""network ワーカーデーモンを実行する任意の Nova ノード。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1918(glossterm) msgid ""network segment"" msgstr ""ネットワークセグメント"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1920(para) msgid ""Represents a virtual, isolated OSI layer 2 subnet in quantum."" msgstr ""Quantum 中の仮想の独立した OSI レイヤ２サブネットを表現する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1925(glossterm) msgid ""network UUID"" msgstr ""ネットワーク UUID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1927(para) msgid ""Unique ID for a quantum network segment."" msgstr ""Quantum ネットワークセグメントの一意な ID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1932(glossterm) msgid ""network worker"" msgstr ""ネットワークワーカー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1934(para) msgid """" ""The nova-network worker daemon, provides services such as giving an IP "" ""address to a booting nova instance."" msgstr ""nova-network ワーカーデーモン。起動中の Nova インスタンスに IP アドレスを付与する等のサービスを提供する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1940(glossterm) msgid ""non-persistent volume"" msgstr ""非永続ボリューム"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1942(para) msgid ""Alternative term for an ephemeral volume."" msgstr ""エフェメラルボリュームの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1947(glossterm) msgid ""nova"" msgstr ""nova"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1949(para) msgid ""The OpenStack project that provides compute services."" msgstr ""Compute サービスを提供する OpenStack プロジェクト。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1954(glossterm) msgid ""nova API"" msgstr ""nova API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1956(para) msgid ""Alternative term for the nova Compute API."" msgstr ""nova Compute API の別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1963(para) msgid """" ""A nova component that manages IP address allocation, firewalls, and other "" ""network-related tasks."" msgstr ""IP アドレス割り当て、ファイアウォール、その他ネットワーク関連タスクを管理する Nova コンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1970(title) msgid ""O"" msgstr ""O"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1972(glossterm) msgid ""object"" msgstr ""オブジェクト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1974(para) msgid ""A BLOB of data held by swift, can be in any format."" msgstr ""Swift が保持する BLOB データ。フォーマットは任意。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1979(glossterm) msgid ""Object API"" msgstr ""オブジェクト API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1981(para) #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2033(para) msgid ""Alternative term for the swift object API."" msgstr ""swift オブジェクト API の別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1986(glossterm) msgid ""object auditor"" msgstr ""オブジェクトオーディター"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1988(para) msgid """" ""Opens all objects for an object server and verifies the MD5 hash, size, and "" ""metadata for each object."" msgstr ""あるオブジェクトサーバー用の全オブジェクトを開き、各オブジェクトの MD5 ハッシュ、サイズ、メタデータを検証する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1994(glossterm) msgid ""object expiration"" msgstr ""オブジェクト有効期限"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml1996(para) msgid """" ""A configurable option within swift to automatically delete objects after a "" ""specified amount of time has passed or a certain date is reached."" msgstr ""指定された時間経過後、又は指定日になった際に自動的にオブジェクトを削除するための Swift 中の設定オプション。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2003(glossterm) msgid ""object hash"" msgstr ""オブジェクトハッシュ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2005(para) msgid ""Uniquely ID for a swift object."" msgstr ""Swift オブジェクトの一意な ID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2009(glossterm) msgid ""object path hash"" msgstr ""オブジェクトパスハッシュ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2011(para) msgid """" ""Used by swift to determine the location of an object in the ring. Maps "" ""objects to partitions."" msgstr ""リング中でオブジェクトの配置を決定する為に Swift が使用する。オブジェクトとパーティションの対応表。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2017(glossterm) msgid ""object replicator"" msgstr ""オブジェクトレプリケーター"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2019(para) msgid """" ""Component of swift that copies and object to remote partitions for fault "" ""tolerance."" msgstr ""フォールトトレラント用にオブジェクトをリモートパーティションにコピーする Swift のコンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2024(glossterm) msgid ""object server"" msgstr ""オブジェクトサーバー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2026(para) msgid ""Component of swift that is responsible for managing objects."" msgstr ""オブジェクト管理に責任を持つ Swift コンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2031(glossterm) msgid ""Object Service API"" msgstr ""Object サービス API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2040(para) msgid """" ""Provides eventually consistent and redundant storage and retrieval of fixed "" ""digital content."" msgstr ""結果整合性（eventually consistent）、ストレージ冗長化、静的デジタルコンテンツ取得、といった機能を提供する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2046(glossterm) msgid ""object versioning"" msgstr ""オブジェクトバージョニング"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2048(para) msgid """" ""Allows a user to set a flag on a swift container so all objects within the "" ""container are versioned."" msgstr ""コンテナ中の全オブジェクトがバージョニングしている事を Swift コンテナ上でユーザが示す為のフラグ設定を可能にする。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2054(glossterm) msgid ""operator"" msgstr ""運用者"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2056(para) msgid """" ""The person responsible for planning and maintaining an OpenStack "" ""installation."" msgstr ""OpenStack インストールを計画し、管理する責任者。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2062(title) msgid ""P"" msgstr ""P"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2064(glossterm) msgid ""parent cell"" msgstr ""親セル"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2066(para) msgid """" ""If a requested resource, such as CPU time, disk storage, or memory, is not "" ""available in the parent cell, the request is forwarded to associated child "" ""cells."" msgstr ""要求されたリソース（CPU時間、ディスクストレージ、メモリ）が親セルで利用不可の場合、そのリクエストは紐付けられた子セルに転送される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2073(glossterm) msgid ""partition"" msgstr ""パーティション"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2075(para) msgid """" ""A unit of storage within swift used to store objects, exists on top of "" ""devices, replicated for fault tolerance."" msgstr ""オブジェクトを保存し、デバイスの上位に位置し、フォールトトレラント用にレプリケーションされる、Swift 中のストレージ単位。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2081(glossterm) msgid ""partition index"" msgstr ""パーティションインデックス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2083(para) msgid ""Contains the locations of all swift partitions within the ring."" msgstr ""リング中で全 Swift パーティションの位置を含む。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2088(glossterm) msgid ""partition shift value"" msgstr ""パーティションシフト値"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2090(para) msgid ""Used by swift to determine which partition data should reside on."" msgstr ""どのパーティションデータが配置されるべきかを決定する為に Swift に使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2095(glossterm) msgid ""pause"" msgstr ""ポーズ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2097(para) msgid """" ""A VM state where no changes occur (no changes in memory, network "" ""communications stop, etc), the VM is frozen but not shut down."" msgstr ""VM の変更が発生しない VM 状態（メモリ変更なし、ネットワーク通信停止、他）。VM は停止しているがシャットダウンしていない。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2104(glossterm) msgid ""persistent volume"" msgstr ""永続ボリューム"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2106(para) msgid """" ""Disk volumes that persist beyond the lifetime of individual virtual machine "" ""instances. Contrast with: ephemeral storage"" msgstr ""単独の仮想マシンインスタンスのライフタイムの後に永続するディスクボリューム。対比：一時ストレージ（ephemeral storage）"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2113(glossterm) msgid ""plugin"" msgstr ""プラグイン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2115(para) msgid """" ""Software component providing the actual implementation for quantum APIs, or "" ""for Compute APIs, depending on the context."" msgstr ""Quantum API 用、又は Compute API 用の実際の実装を提供するソフトウェアコンポーネント。文脈に依存する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2121(glossterm) msgid ""policy service"" msgstr ""ポリシーサービス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2123(para) msgid """" ""Component of keystone that provides a rule management interface and a rule "" ""based authorization engine."" msgstr ""ルール管理インターフェースとルールベースの認可エンジンを提供する Keystone コンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2129(glossterm) msgid ""port"" msgstr ""ポート"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2131(para) msgid """" ""A virtual network port within quantum, VIFs / vNICs are connected to a port."" msgstr ""quantum で定義される仮想ネットワークポート。仮想インターフェース / 仮想 NIC がポートに接続される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2136(glossterm) msgid ""port UUID"" msgstr ""ポート UUID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2138(para) msgid ""Unique ID for a quantum port."" msgstr ""quantum ポートの一意な ID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2142(glossterm) msgid ""preseed"" msgstr ""preseed"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2144(para) msgid """" ""A tool to automate system configuration and installation on Debian based "" ""Linux distributions."" msgstr ""Debian ベースの Linux ディストリビューションでシステム設定とインストールの自動化ツール。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2150(glossterm) msgid ""private image"" msgstr ""プライベートイメージ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2152(para) msgid ""A glance VM image that is only available to specified tenants."" msgstr ""特定のテナントだけが利用できる glance の VM イメージ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2157(glossterm) msgid ""project"" msgstr ""プロジェクト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2159(para) msgid """" ""A logical grouping of users within nova, used to define quotas and access to"" "" VM images."" msgstr ""Nova におけるユーザーの論理的なグループ。仮想マシンイメージに対するクォータやアクセス権を定義するために使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2165(glossterm) msgid ""project ID"" msgstr ""プロジェクト ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2167(para) msgid ""User defined alpha-numeric string in nova, the name of a project."" msgstr ""nova におけるユーザー定義の英数字文字列。プロジェクトの名前。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2172(glossterm) msgid ""project VPN"" msgstr ""プロジェクト VPN"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2174(para) msgid ""Alternative term for a cloudpipe."" msgstr ""cloudpipe の別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2178(glossterm) msgid ""proxy node"" msgstr ""プロキシノード"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2180(para) msgid ""A node that provides the swift proxy service."" msgstr ""Swift プロキシサービスを提供するノード。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2185(glossterm) msgid ""proxy server"" msgstr ""プロキシサーバー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2187(para) msgid """" ""Users of swift interact with the service through the proxy server which in-"" ""turn looks up the location of the requested data within the ring and returns"" "" the results to the user."" msgstr ""Swift のユーザーは、リング中にあるリクエストされたデータの場所を参照してユーザに結果を返すプロキシサーバーを介して Swift サービスに通信を行う。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2195(glossterm) msgid ""public API"" msgstr ""パブリック API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2197(para) msgid """" ""An API endpoint used for both service to service communication and end user "" ""interactions."" msgstr ""サービス間の通信とユーザとのやり取りの両方に使用される API エンドポイント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2203(glossterm) msgid ""public image"" msgstr ""パブリックイメージ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2205(para) msgid ""A glance VM image that is available to all tenants."" msgstr ""全テナントが利用可能な Glance VM イメージ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2210(glossterm) msgid ""public IP address"" msgstr ""パブリック IP アドレス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2212(para) msgid ""An IP address that is accessible to end-users."" msgstr ""エンドユーザがアクセス可能な IP アドレス。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2217(glossterm) msgid ""public network"" msgstr ""パブリックネットワーク"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2219(para) msgid """" ""The Network Controller provides virtual networks to enable compute servers "" ""to interact with each other and with the public network. All machines must "" ""have a public and private network interface. The public network interface is"" "" controlled by the public_interface option."" msgstr ""compute サーバーがパブリックネットワークと相互通信できるよう、ネットワークコントローラーが仮想ネットワークを提供する。全マシンにはパブリックとプライベートのネットワークインターフェースがなければならない。パブリックネットワークインターフェースは public_interface オプションにより制御される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2229(glossterm) msgid ""Puppet"" msgstr ""Puppet"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2236(glossterm) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml43(emphasis) msgid ""Python"" msgstr ""Python"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2238(para) msgid ""Programming language used extensively in OpenStack."" msgstr ""OpenStack において幅広く使用されるプログラミング言語。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2244(title) msgid ""Q"" msgstr ""Q"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2246(glossterm) msgid ""quantum"" msgstr ""quantum"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2248(para) msgid """" ""A core OpenStack project that provides a network connectivity abstraction "" ""layer to OpenStack Compute."" msgstr ""OpenStack のコアプロジェクトで、OpenStack Compute に対してネットワーク接続の抽象化レイヤーを提供する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2254(glossterm) msgid ""quantum API"" msgstr ""quantum API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2256(para) msgid """" ""API used to access quantum, provides and extensible architecture to allow "" ""custom plugin creation."" msgstr ""quantum へのアクセスに使用する API で、独自のプラグインが作成できる拡張性を持ったアーキテクチャになっている。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2262(glossterm) msgid ""quantum manager"" msgstr ""quantum マネージャー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2264(para) msgid """" ""Allows nova and quantum integration thus allowing quantum to perform network"" "" management for nova VMs."" msgstr ""nova と quantum を統合し、quantum が nova VM のネットワークを管理できるようにする。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2270(glossterm) msgid ""quantum plugin"" msgstr ""quantum プラグイン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2272(para) msgid """" ""Interface within quantum that allows organizations to create custom plugins "" ""for advanced features such as QoS, ACLs, or IDS."" msgstr ""quantum 内部のインタフェースで、QoS、ACL、IDS といった先進的な機能を持った独自のプラグインを作成できるようになっている。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2279(glossterm) msgid ""quarantine"" msgstr ""隔離"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2281(para) msgid """" ""If swift finds objects, containers, or accounts that are corrupt they are "" ""placed in this state, are not replicated, cannot be read by clients, and a "" ""correct copy is re-replicated."" msgstr ""swift が壊れたオブジェクト、コンテナー、アカウントを見つけた際に、そのデータはこの状態にセットされる。この状態にセットされたデータは、複製されず、クライアントが読み出すこともできなくなり、正しいコピーが再複製される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2289(glossterm) msgid ""Quick EMUlator (QEMU)"" msgstr ""Quick EMUlator (QEMU)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2291(para) msgid """" ""One of the hypervisors supported by OpenStack, generally used for "" ""development purposes."" msgstr ""OpenStack がサポートするハイパーバイザーの一つ。一般に、開発目的で使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2297(glossterm) msgid ""quota"" msgstr ""クォータ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2299(para) msgid ""In nova, the ability to set resource limits on a per-project basis."" msgstr ""プロジェクト単位に使用できるリソース上限を設定できる nova の機能。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2305(title) msgid ""R"" msgstr ""R"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2307(glossterm) msgid ""RAM filter"" msgstr ""RAM フィルター"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2309(para) msgid ""The nova setting that allows or disallows RAM overcommitment."" msgstr ""RAM オーバーコミットの有効／無効を制御する nova の設定。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2314(glossterm) msgid ""RAM overcommit"" msgstr ""RAM オーバーコミット"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2316(para) msgid """" ""The ability to start new VM instances based on the actual memory usage of a "" ""host, as opposed to basing the decision on the amount of RAM each running "" ""instance thinks it has available. Also known as memory overcommit."" msgstr ""実行中の各インスタンスが利用可能と考えている RAM 量に基づく判断をベースにする代わりに、ホスト上の実際のメモリ使用量をベースにした、新しい VM インスタンスを起動する機能。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2325(glossterm) msgid ""rate limit"" msgstr ""レートリミット"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2327(para) msgid """" ""Configurable option within swift to limit database writes on a per-account "" ""and/or per-container basis."" msgstr ""アカウント単位、コンテナー単位のデータベースの書き込みレートの上限を指定する、swift の設定オプション。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2333(glossterm) msgid ""rebalance"" msgstr ""リバランス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2335(para) msgid """" ""The process of distributing swift partitions across all drives in the ring, "" ""used during initial ring creation and after ring reconfiguration."" msgstr ""リングに登録されたすべてのドライブに swift のパーティションを分散させる処理。最初にリングを作成する際やリングの設定を変更した後に実行される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2342(glossterm) msgid ""Recon"" msgstr ""recon"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2344(para) msgid ""A component of swift used to collect metrics."" msgstr ""メトリックス（品質）の収集に使われる swift のコンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2349(glossterm) msgid ""record ID"" msgstr ""レコード ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2351(para) msgid """" ""A number within a database that is incremented each time a change is made. "" ""Used by swift when replicating."" msgstr ""変更が行われる度に増加するデータベース内の数値。 swift が複製を行う際に使用する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2357(glossterm) msgid ""registry server"" msgstr ""レジストリサーバー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2359(para) msgid """" ""A glance service that provides VM image metadata information to clients."" msgstr ""VM イメージのメタデータ情報をクライアントに提供する glance サービス。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2364(glossterm) msgid ""replica"" msgstr ""レプリカ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2366(para) msgid """" ""Provides data redundancy and fault tolerance by creating copies of swift "" ""objects, accounts, and containers so they are not lost when the underlying "" ""storage fails."" msgstr ""swift のオブジェクト、アカウント、コンテナーのコピーを作成することで、データ冗長性や耐障害性を実現する。これにより、バックエンドのストレージが故障した場合でもデータは失わない。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2373(glossterm) msgid ""replica count"" msgstr ""レプリカ数"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2375(para) msgid ""The number of replicas of the data in a swift ring."" msgstr ""swift リングでのデータのレプリカ数。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2380(glossterm) msgid ""replication"" msgstr ""レプリケーション"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2382(para) msgid """" ""The process of copying data to a separate physical device for fault "" ""tolerance and performance."" msgstr ""別の物理デバイスにデータをコピーする処理。耐障害性や性能のために行われる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2388(glossterm) msgid ""replicator"" msgstr ""レプリケーター"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2390(para) msgid ""The swift back-end process that creates and manages object replicas."" msgstr ""オブジェクトレプリカの作成、管理を行う swift のバックエンドプロセス。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2395(glossterm) msgid ""request ID"" msgstr ""リクエスト ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2397(para) msgid ""Unique ID assigned to each request sent to nova."" msgstr ""nova に送られた各リクエストに割り当てられる一意な ID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2402(glossterm) msgid ""ring"" msgstr ""リング"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2404(para) msgid """" ""An entity that maps swift data to partitions. A separate ring exists for "" ""each service, such as account, object, and container."" msgstr ""swift データのパーティションへのマッピングを行う。アカウント、オブジェクト、コンテナーというサービス単位に別々のリングが存在する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2411(glossterm) msgid ""ring builder"" msgstr ""リングビルダー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2413(para) msgid """" ""Builds and manages rings within swift, assigns partitions to devices, and "" ""pushes the configuration to other storage nodes."" msgstr ""swift のリングの作成、管理を行い、パーティションのデバイスへの割り当てを行い、他のストレージノードに設定を転送する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2419(glossterm) msgid ""role ID"" msgstr ""ロール ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2421(para) msgid ""Alpha-numeric ID assigned to each keystone role."" msgstr ""keystone のロール毎に割り当てられる英数字の ID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2426(glossterm) msgid ""rootwrap"" msgstr ""rootwrap"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2428(para) msgid """" ""A feature of nova that allows the unprivileged \""nova\"" user to run a "" ""specified list of commands as the Linux root user."" msgstr ""特権を持たない \""nova\"" ユーザーが指定されたリストにあるコマンドを Linux root ユーザーで実行できるようにする nova の機能。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2435(glossterm) msgid ""RPC driver"" msgstr ""RPC ドライバー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2437(para) msgid """" ""Modular system that allows the nova underlying message queue software to be "" ""changed. For example, from RabbitMQ to ZeroMQ or Qpid."" msgstr ""nova が利用するメッセージキューソフトウェアを変更できるようにする仕組み。例えば、 RabbitMQ を ZeroMQ や Qpid に変更できる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2445(title) msgid ""S"" msgstr ""S"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2447(glossterm) msgid ""S3"" msgstr ""S3"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2449(para) msgid """" ""Object storage service by Amazon, similar in function to swift, can act as a"" "" back-end store for glance VM images."" msgstr ""Amazon のオブジェクトストレージサービス。 swift に似た機能を持つ。 glance の VM イメージのバックエンドストレージとして利用できる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2455(glossterm) msgid ""scheduler manager"" msgstr ""スケジューラーマネージャー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2457(para) msgid """" ""A nova component that determines where VM instances should start. Uses "" ""modular design to support a variety of scheduler types."" msgstr ""どこで VM インスタンスを起動するかを決定する nova のコンポーネント。様々なスケジューラーが利用できるようにモジュラー型の設計になっている。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2463(glossterm) msgid ""scoped token"" msgstr ""スコープ付きトークン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2465(para) msgid ""A keystone API access token that is associated with a specific tenant."" msgstr ""特定のテナントと関連付けされた keystone API アクセストークン。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2470(glossterm) msgid ""secret key"" msgstr ""シークレットキー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2472(para) msgid """" ""String of text only known by the user, used along with an access key to make"" "" requests to the nova API."" msgstr ""ユーザーだけが知っている文字列。 nova API へのリクエスト時にアクセスキーとともに使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2478(glossterm) msgid ""security group"" msgstr ""セキュリティグループ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2480(para) msgid """" ""A set of network traffic filtering rules that are applied to a nova "" ""instance."" msgstr ""nova インスタンスに適用される、ネットワークトラフィックのフィルタルールの集合。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2485(glossterm) msgid ""segmented object"" msgstr ""分割オブジェクト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2487(para) msgid """" ""A swift large object that has been broken up into pieces, the re-assembled "" ""object is called a concatenated object."" msgstr ""複数に分割された swift のラージオブジェクト。再構成されたオブジェクトは \""concatenated object\"" （連結オブジェクト） と呼ばれる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2493(glossterm) msgid ""server image"" msgstr ""サーバーイメージ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2495(para) msgid ""Alternative term for a VM image."" msgstr ""VM イメージの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2499(glossterm) msgid ""server UUID"" msgstr ""サーバー UUID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2506(glossterm) msgid ""service catalog"" msgstr ""サービスカタログ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2508(para) msgid ""Alternative term for the keystone catalog."" msgstr ""keystone カタログの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2513(glossterm) msgid ""service ID"" msgstr ""サービス ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2515(para) msgid """" ""Unique ID assigned to each service that is available in the keystone "" ""catalog."" msgstr ""各サービスに割り当てられる一意な ID。 keystone カタログで使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2520(glossterm) msgid ""service registration"" msgstr ""サービス登録"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2522(para) msgid """" ""A keystone feature that allows services such as nova to automatically "" ""register with the catalog."" msgstr ""nova などのサービスをカタログに自動的に登録する keystone の機能。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2528(glossterm) msgid ""service tenant"" msgstr ""サービステナント"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2530(para) msgid """" ""Special keystone tenant that contains all services that are listed in the "" ""catalog."" msgstr ""カタログリストにあるすべてのサービスが所属する特別な keystone テナント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2536(glossterm) msgid ""service token"" msgstr ""サービストークン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2538(para) msgid """" ""An administrator defined token used by nova to communicate securely with "" ""keystone."" msgstr ""管理者が定義するトークンで、 nova が keystone と安全に通信するのに使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2543(glossterm) msgid ""session back-end"" msgstr ""セッションバックエンド"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2545(para) msgid """" ""The method of storage used by horizon to track client sessions such as local"" "" memory, cookies, a database, or memcached."" msgstr ""Horizon でクライアントセッションの追跡に使用される、ローカルメモリ、クッキー、データベース、memcached などのストレージ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2551(glossterm) msgid ""session persistence"" msgstr ""セッション持続性"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2553(para) msgid """" ""A feature of the load balancing service. It attempts to force subsequent "" ""connections to a service to be redirected to the same node as long as it is "" ""online."" msgstr ""負荷分散サービスの機能。そのノードがオンラインである限り、あるサービスへのそれ以降の接続を同じノードにリダイレクトする。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2560(glossterm) msgid ""session storage"" msgstr ""セッションストレージ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2562(para) msgid """" ""A horizon component that stores and tracks client session information. "" ""Implemented through the Django sessions framework."" msgstr ""クライアントセッションの保持と追跡を行う Horizon のコンポーネント。 Django のセッションフレームワークを用いて実装されている。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2568(glossterm) msgid ""shared storage"" msgstr ""共有ストレージ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2570(para) msgid """" ""Block storage that is simultaneously accessible by multiple clients. For "" ""example, NFS."" msgstr ""同時に複数のクライアントからアクセス可能なブロックストレージ。 NFS など。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2576(glossterm) msgid ""SmokeStack"" msgstr ""SmokeStack"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2578(para) msgid ""Runs automated tests against the core OpenStack API, written in Rails."" msgstr ""OpenStack のコア API に対して自動テストを実行する。 Rails で書かれている。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2585(para) msgid """" ""A point-in-time copy of an OpenStack storage volume or image. Use storage "" ""volume snapshots to back up volumes. Use image snapshots to back up data, or"" "" as \""gold\"" images for additional servers."" msgstr ""OpenStack ストレージボリュームやイメージの、ある時点でのコピー。ストレージのボリュームスナップショットは、ボリュームをバックアップするために使用する。イメージスナップショットは、データのバックアップを行ったり、新しいサーバー用の「ゴールド」イメージ（設定済みイメージ）としてバックアップしたりするのに使用する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2593(glossterm) msgid ""spread-first scheduler"" msgstr ""分散優先スケジューラー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2595(para) msgid """" ""The nova VM scheduling algorithm that attempts to start new VM on the host "" ""with the least amount of load."" msgstr ""新しい VM を最も負荷が低いホストで起動しようとする、nova の VM スケジューリングアルゴリズム。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2601(glossterm) msgid ""SQLAlchemy"" msgstr ""SQLAlchemy"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2603(para) msgid ""An open source SQL toolkit for Python, used in OpenStack."" msgstr ""OpenStack で使われている、オープンソースの Python 用 SQL ツールキット。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2608(glossterm) msgid ""SQLite"" msgstr ""SQLite"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2610(para) msgid """" ""A lightweight SQL database, used as the default persistent storage method in"" "" many OpenStack services."" msgstr ""軽量 SQL データベース。多くの OpenStack サービスでデフォルトの永続ストレージとして使用されている。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2618(para) msgid """" ""Community project that captures nova AMQP communications, useful for "" ""debugging."" msgstr ""nova の AMQP 通信のキャプチャーを行うコミュニティプロジェクト。デバッグに役立つ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2623(glossterm) msgid ""static IP address"" msgstr ""静的 IP アドレス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2625(para) msgid ""Alternative term for a fixed IP address."" msgstr ""固定 IP アドレスの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2630(glossterm) msgid ""StaticWeb"" msgstr ""StaticWeb"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2632(para) msgid """" ""WSGI middleware component of swift that serves container data as a static "" ""web page."" msgstr ""コンテナーのデータを静的なウェブページとして扱う swift の WSGI ミドルウェア。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2638(glossterm) msgid ""storage back-end"" msgstr ""ストレージバックエンド"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2640(para) msgid """" ""The method that a service uses for persistent storage such as iSCSI, NFS, or"" "" local disk."" msgstr ""サービスが永続ストレージで使用する方式。 iSCSI、NFS、ローカルディスクなどがある。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2646(glossterm) msgid ""storage node"" msgstr ""ストレージノード"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2648(para) msgid """" ""A swift node that provides container services, account services, and object "" ""services, controls the account databases, container databases, and object "" ""storage."" msgstr ""アカウントサービス、コンテナーサービス、オブジェクトサービスを提供する swift ノード。アカウントデータベース、コンテナーデータベース、オブジェクトストレージの制御を行う。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2656(glossterm) msgid ""storage manager"" msgstr ""ストレージマネージャー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2658(para) msgid """" ""Component of XenAPI that provides a pluggable interface to support a wide "" ""variety of persistent storage back-ends."" msgstr ""XenAPI の一つのコンポーネントで、様々な種類の永続ストレージバックエンドをサポートするための取り外し可能な（pluggable）インタフェースを提供する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2664(glossterm) msgid ""storage manager back-end"" msgstr ""ストレージマネージャーバックエンド"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2666(para) msgid ""A persistent storage method supported by XenAPI such as iSCSI or NFS."" msgstr ""iSCSI や NFS といった、XenAPI がサポートする永続ストレージ手段。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2671(glossterm) msgid ""storage services"" msgstr ""ストレージサービス"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2673(para) msgid """" ""Collective name for the swift object services, container services, and "" ""account services."" msgstr ""swift のオブジェクトサービス、コンテナーサービス、アカウントサービスの総称。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2679(glossterm) msgid ""swift"" msgstr ""swift"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2681(para) msgid ""An OpenStack core project that provides object storage services."" msgstr ""オブジェクトストレージサービスを提供する OpenStack コアプロジェクト。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2686(glossterm) msgid ""swift All in One (SAIO)"" msgstr ""swift All in One (SAIO)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2688(para) msgid ""Creates a full swift development environment within a single VM."" msgstr ""完全な swift の開発環境を1台のVM内に作成できる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2693(glossterm) msgid ""swift middleware"" msgstr ""swift ミドルウェア"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2695(para) msgid """" ""Collective term for components within swift that allows for additional "" ""functionality."" msgstr ""追加機能を実現するための swift のコンポーネントの総称。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2701(glossterm) msgid ""swift proxy server"" msgstr ""swift プロキシサーバー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2703(para) msgid """" ""Acts as the gatekeeper to swift and is responsible for authenticating the "" ""user."" msgstr ""swift への出入口として動作する。ユーザを認証する役割も持つ。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2709(glossterm) msgid ""swift storage node"" msgstr ""swift ストレージノード"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2711(para) msgid ""A node that runs swift account, container, and object services."" msgstr ""swift のアカウントサービス、コンテナーサービス、オブジェクトサービスが動作するノード。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2716(glossterm) msgid ""sync point"" msgstr ""同期ポイント"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2718(para) msgid """" ""Point in time since the last container and accounts database sync among "" ""nodes within swift."" msgstr ""swift ノード間で最後にコンテナーデータベースとアカウントデータベースの同期が行われた時点。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2725(title) msgid ""T"" msgstr ""T"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2727(glossterm) msgid ""TempAuth"" msgstr ""TempAuth"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2729(para) msgid """" ""An authentication facility within swift that allows swift itself to perform "" ""authentication and authorization, frequently used in testing and "" ""development."" msgstr ""swift 自身が認証と認可を行えるようにする swift の認証機構。もっぱらテストや開発で使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2736(glossterm) msgid ""Tempest"" msgstr ""Tempest"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2738(para) msgid """" ""Automated software test suite designed to run against the trunk of the "" ""OpenStack core project."" msgstr ""OpenStack コアプロジェクトの trunk ブランチに対してテストを実行するために設計された自動ソフトウェアテストスイート。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2744(glossterm) msgid ""TempURL"" msgstr ""TempURL"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2746(para) msgid """" ""A swift middleware component that allows a user to create URLs for temporary"" "" object access."" msgstr ""ユーザが一時的なオブジェクトアクセス用の URL を作成できるようにする swift のミドルウェア。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2752(glossterm) msgid ""tenant"" msgstr ""テナント"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2754(para) msgid """" ""A group of users, used to isolate access to nova resources. An alternative "" ""term for a nova project."" msgstr ""Nova リソースへのアクセスを分離するために使用されるユーザーのグループ。Nova のプロジェクトの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2760(glossterm) msgid ""tenant endpoint"" msgstr ""テナントエンドポイント"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2762(para) msgid ""A keystone API endpoint that is associated with one or more tenants."" msgstr ""一つ以上のテナントと関連付けされる keystone API エンドポイント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2767(glossterm) msgid ""tenant ID"" msgstr ""テナント ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2769(para) msgid """" ""Unique ID assigned to each tenant within keystone, the nova project IDs map "" ""to the keystone tenant IDs."" msgstr ""keystone 内で各テナントに割り当てられる一意な ID。 nova のプロジェクト ID は keystone のテナント ID にマッピングされる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2777(para) msgid """" ""An alpha-numeric string of text used to access OpenStack APIs and resources."" msgstr ""OpenStack API やリソースへのアクセスに使用される英数字文字列。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2782(glossterm) msgid ""tombstone"" msgstr ""tombstone"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2784(para) msgid """" ""Used to mark swift objects that have been deleted, ensures the object is not"" "" updated on another node after it has been deleted."" msgstr ""削除済みの swift オブジェクトを示す印として使われる。これにより、そのオブジェクトが削除後に別のノードで更新されないことを保証する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2790(glossterm) msgid ""transaction ID"" msgstr ""トランザクション ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2792(para) msgid """" ""Unique ID assigned to each swift request, used for debugging and tracing."" msgstr ""各 swift リクエストに割り当てられる一意な ID。デバッグや追跡に使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2804(title) msgid ""U"" msgstr ""U"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2806(glossterm) msgid ""unscoped token"" msgstr ""スコープなしトークン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2808(para) msgid ""Alternative term for a keystone default token."" msgstr ""keystone のデフォルトトークンの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2813(glossterm) msgid ""updater"" msgstr ""アップデーター"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2815(para) msgid """" ""Collective term for a group of swift components that process queued and "" ""failed updates for containers and objects."" msgstr ""キューイングされたり失敗したりした、コンテナやオブジェクトの更新要求の処理を行う swift コンポーネントの総称。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2821(glossterm) msgid ""user"" msgstr ""ユーザー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2823(para) msgid """" ""In keystone each user is associated with one or more tenants, and in nova "" ""they can be associated with roles, projects, or both."" msgstr ""keystone では、各ユーザは一つ以上のテナントに所属する。 nova では、テナントはロール、プロジェクトおよびその両方と関連付けられる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2830(glossterm) msgid ""user data"" msgstr ""ユーザーデータ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2832(para) msgid """" ""A blob of data that can be specified by the user when launching an instance."" "" This data can be accessed by the instance through the metadata service or "" ""config drive. Commonly used for passing a shell script that is executed by "" ""the instance on boot."" msgstr ""インスタンス起動時にユーザが指定できる blob データ。インスタンスはこのデータに metadata サービスや config driver 経由でアクセスできる。通常、インスタンスがブート時に実行するシェルスクリプトを渡すのに使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2842(title) msgid ""V"" msgstr ""V"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2844(glossterm) msgid ""VIF UUID"" msgstr ""VIF UUID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2846(para) msgid ""Unique ID assigned to each quantum VIF."" msgstr ""quantum VIF に割り当てられる一意な ID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2851(glossterm) msgid ""Virtual Central Processing Unit (vCPU)"" msgstr ""仮想CPU (vCPU)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2854(para) msgid """" ""Allows physical CPUs to be sub-divided and those divisions are then used by "" ""instances. Also known as virtual cores."" msgstr ""物理 CPU をいくつかに分割し、分割された部分をインスタンスが使用する。仮想コアとも呼ばれる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2860(glossterm) msgid ""Virtual Machine (VM)"" msgstr ""仮想マシン (VM)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2862(para) msgid """" ""An operating system instance that runs on top of a hypervisor. Multiple VMs "" ""can run at the same time on the same physical host."" msgstr ""ハイパーバイザー上で動作するオペレーティングシステムインスタンス。一台の物理ホストで同時に複数の VM を実行できる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2869(glossterm) msgid ""virtual network"" msgstr ""仮想ネットワーク"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2871(para) msgid ""An L2 network segment within quantum."" msgstr ""quantum の レイヤ2 ネットワークセグメント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2875(glossterm) msgid ""Virtual Network InterFace (VIF)"" msgstr ""仮想ネットワークインタフェース (VIF)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2877(para) msgid """" ""An interface that is plugged into a port in a quantum network. Typically a "" ""virtual network interface belonging to a VM."" msgstr ""quantum ネットワークのポートに接続されるインタフェース。通常は仮想ネットワークインタフェースは VM に所属する。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2883(glossterm) msgid ""virtual port"" msgstr ""仮想ポート"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2885(para) msgid """" ""Attachment point where a virtual interface connects to a virtual network."" msgstr ""仮想ネットワークへの仮想インタフェースの接続ポイント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2890(glossterm) msgid ""virtual private network (VPN)"" msgstr ""仮想プライベートネットワーク (VPN)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2892(para) msgid """" ""Provided by nova in the form of cloudpipes, specialized instances that are "" ""used to create VPNs on a per-project basis."" msgstr ""nova では cloudpipe の形で提供される。 cloudpipe では、特別なインスタンスを使って、プロジェクト毎に VPN が作成される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2898(glossterm) msgid ""virtual server"" msgstr ""仮想サーバー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2900(para) msgid ""Alternative term for a VM or guest."" msgstr ""VM やゲストの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2904(glossterm) msgid ""virtual switch (vSwitch)"" msgstr ""仮想スイッチ (vSwitch)"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2906(para) msgid """" ""Software that runs on a host or node and provides the features and functions"" "" of a hardware based network switch."" msgstr ""ホスト上で動作し、ハードウェアのネットワークスイッチと同じ機能や動作を行うソフトウェア。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2912(glossterm) msgid ""virtual VLAN"" msgstr ""仮想 VLAN"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2914(para) msgid ""Alternative term for a virtual network."" msgstr ""仮想ネットワークの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2919(glossterm) msgid ""VLAN manager"" msgstr ""VLAN マネージャー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2921(para) msgid """" ""A nova networking manager that divides subnet and tenants into different "" ""VLANs allowing for Layer 2 segregation. Provides a DHCP server for each VLAN"" "" to assign IP addresses for instances."" msgstr ""nova ネットワークマネージャーの一つで、サブネットを分割し、テナント毎に異なる VLAN を割り当て分離された Layer 2 セグメントを実現する。VLAN 毎に、インスタンスに IP アドレスの払い出しを行う DHCP サーバーが用意される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2929(glossterm) msgid ""VLAN network"" msgstr ""VLAN ネットワーク"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2931(para) msgid """" ""The Network Controller provides virtual networks to enable compute servers "" ""to interact with each other and with the public network. All machines must "" ""have a public and private network interface. A VLAN network is a private "" ""network interface, which is controlled by the vlan_interface option with "" ""VLAN managers."" msgstr ""ネットワークコントローラーは、コンピュートサーバー間、およびコンピュートサーバーとパブリックネットワークとの通信を行う仮想ネットワークを用意する。すべての物理マシンにはパブリック側とプライベート側のネットワークインタフェースが必要。VLAN ネットワークはプライベート側のネットワークインタフェースで、VLAN マネージャーの vlan_interface オプションで指定される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2942(glossterm) msgid ""VM image"" msgstr ""VM イメージ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2944(para) msgid ""Alternative term for an image."" msgstr ""イメージの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2948(glossterm) msgid ""VNC proxy"" msgstr ""VNC プロキシ"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2950(para) msgid """" ""A nova component that provides users access to the consoles of their VM "" ""instances through VNC or VMRC."" msgstr ""VNC や VMRC を使って VM インスタンスのコンソールにユーザがアクセスできるようにする nova のコンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2956(glossterm) msgid ""volume"" msgstr ""ボリューム"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2958(para) msgid """" ""Disk-based data storage generally represented as an iSCSI target with a file"" "" system that supports extended attributes, can be persistent or ephemeral. "" ""Commonly used as a synonym for block device."" msgstr ""ディスクベースのデータストレージで、ほとんどの場合 iSCSI ターゲットとして表現され、拡張属性をサポートするファイルシステムを用いて構成される。永続的ストレージと一時的ストレージの両方がある。通常は、ブロックデバイスの同義語として使用される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2966(glossterm) msgid ""Volume API"" msgstr ""Volume API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2968(para) msgid """" ""An API on a separate endpoint for attaching, detaching, and creating block "" ""storage for compute VMs."" msgstr ""コンピュート VM 用のブロックストレージの作成、接続、接続解除を行うための API で、独立したエンドポイントとして提供される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2974(glossterm) msgid ""volume controller"" msgstr ""ボリュームコントローラー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2976(para) msgid ""A nova component that oversees and coordinates storage volume actions."" msgstr ""ストレージのボリューム操作の監視と調停を行う nova のコンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2981(glossterm) msgid ""volume driver"" msgstr ""ボリュームドライバー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2983(para) msgid ""Alternative term for a volume plugin."" msgstr ""ボリュームプラグインの別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2987(glossterm) msgid ""volume ID"" msgstr ""ボリューム ID"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2989(para) msgid ""Unique ID applied to each storage volume under the nova control."" msgstr ""nova 配下の各ストレージボリュームに割り当てられる一意な ID。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2994(glossterm) msgid ""volume manager"" msgstr ""ボリュームマネージャー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml2996(para) msgid """" ""A nova component that creates, attaches, and detaches persistent storage "" ""volumes."" msgstr ""永続ストレージボリュームの作成、接続、接続解除を行う nova のコンポーネント。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3001(glossterm) msgid ""volume node"" msgstr ""ボリュームノード"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3003(para) msgid ""A nova node that runs the cinder-volume daemon."" msgstr ""cinder-volume デーモンが動作する nova ノード。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3008(glossterm) msgid ""volume plugin"" msgstr ""ボリュームプラグイン"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3010(para) msgid """" ""A plugin for the nova volume manager. Provides support for a new and "" ""specialized types of back-end storage."" msgstr ""nova ボリュームマネージャーのプラグイン。プラグインにより新しい種類や特別な種類のバックエンドストレージのサポートが提供される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3016(glossterm) msgid ""Volume Service API"" msgstr ""Volume サービス API"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3018(para) msgid ""Alternative term for the Block Storage API."" msgstr ""Block Storage API の別名。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3023(glossterm) msgid ""volume worker"" msgstr ""ボリュームワーカー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3025(para) msgid """" ""The nova component that interacts with back-end storage to manage the "" ""creation and deletion of volumes and the creation of compute volumes, "" ""provided by the nova-volume daemon."" msgstr ""バックエンドストレージとやり取りを行い、ボリュームの作成、削除、コンピュートボリュームの作成を行う nova のコンポーネント。 nova-volume デーモンにより提供される。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3034(title) msgid ""W"" msgstr ""W"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3036(glossterm) msgid ""weight"" msgstr ""ウェイト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3038(para) msgid """" ""Used by swift storage devices to determine which storage devices are "" ""suitable for the job. Devices are weighted by size."" msgstr ""swift ストレージデバイスが、そのジョブに適したストレージデバイスを判定するのに使用する。デバイスはサイズで重み付けされる。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3044(glossterm) msgid ""weighted cost"" msgstr ""重み付けコスト"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3046(para) msgid """" ""The sum of each cost used when deciding where to start a new VM instance in "" ""nova."" msgstr ""nova で新しい VM インスタンスをどこで起動するかを決定するときに使用される、個々のコストの合計値。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3052(glossterm) msgid ""weighing"" msgstr ""計量（weighing）"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3054(para) msgid """" ""A nova process that determines the suitability of the VM instances for a job"" "" for a particular host. For example, not enough RAM on the host, too many "" ""CPUs on the host, and so on."" msgstr ""ジョブ用の VM インスタンスとしてあるホストが適しているかを判定する nova プロセス。例えば、そのホストには十分なメモリがない、CPU が割り当てられすぎている、など。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3062(glossterm) msgid ""worker"" msgstr ""ワーカー"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3064(para) msgid """" ""A daemon that carries out tasks. For example, the nova-volume worker "" ""attaches storage to an VM instance. Workers listen to a queue and take "" ""action when new messages arrive."" msgstr ""タスクを実行するデーモン。例えば、 nova-volume ワーカーはストレージを VM インスタンスに接続する。ワーカーは、キューを待ち受け、新しいメッセージが到着すると操作を行う。"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3073(title) msgid ""Z"" msgstr ""Z"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3075(glossterm) msgid ""Zuul"" msgstr ""Zuul"" #: ./doc/src/docbkx/openstack-ops/src/bk_ops_guide.xml3077(para) msgid """" ""Tool used in OpenStack development to ensure correctly ordered testing of "" ""changes in parallel."" msgstr ""OpenStack 開発で使用されているツールで、変更のテストを正しい順番を保証しながら並列に実行する。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml16(title) msgid ""Backup and Recovery"" msgstr ""バックアップとリカバリー"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml17(para) msgid """" ""Standard backup best practices apply when creating your OpenStack backup "" ""policy. For example, how often to backup your data is closely related to how"" "" quickly you need to recover from data loss."" msgstr ""OpenStackバックアップポリシーを作成する際、標準的なバックアップのベストプラクティスが適用できます。例えば、どの程度の頻度でバックアップを行なうかは、どのくらい早くデータロスから復旧させる必要があるかに密接に関連しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml21(para) msgid """" ""If you cannot have any data loss at all, you should focus on High "" ""Availability as well as backups."" msgstr ""もし、いかなるデータロスも許されない場合、バックアップに加えて高可用性（High Avaialability）についても検討すべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml24(para) msgid ""Other backup considerations include:"" msgstr ""さらにバックアップの考慮点として以下があげられます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml27(para) msgid ""How many backups to keep?"" msgstr ""いくつのバックアップを持つべきか?"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml30(para) msgid ""Should backups be kept off-site?"" msgstr ""オフサイトにバックアップを置くべきか?"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml33(para) msgid ""How often should backups be tested?"" msgstr ""どの程度の頻度でバックアップをテストすべきか?"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml36(para) msgid """" ""Just as important as a backup policy is a recovery policy (or at least "" ""recovery testing)."" msgstr ""バックアップポリシーと同じくらい大事なことは、リカバリーポリシーです (少なくともリカバリーのテストは必要です)。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml41(title) msgid ""What to Backup"" msgstr ""バックアップ対象"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml42(para) msgid """" ""While OpenStack is composed of many components and moving parts, backing up "" ""the critical data is quite simple."" msgstr ""OpenStackは多くのコンポーネントから構成され、注意を払うべき箇所もたくさんありますが、大事なデータのバックアップは非常に単純です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml45(para) msgid """" ""This chapter describes only how to back up configuration files and databases"" "" that the various OpenStack components need to run. This chapter does not "" ""describe how to back up objects inside Object Storage or data contained "" ""inside Block Storage. Generally these areas are left for the user to back up"" "" on their own."" msgstr ""この章では、OpenStackコンポーネントを動作させるのに必要な設定ファイルとデータベースについてのバックアップ方法のみを説明します。オブジェクトストレージ内のオブジェクトや、ブロックストレージ内のデータのバックアップについては説明していません。一般的にこれらの領域はユーザー自身でバックアップを行います。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml53(title) msgid ""Database Backups"" msgstr ""データベースのバックアップ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml54(para) msgid """" ""The example OpenStack architecture designates the Cloud Controller as the "" ""MySQL server. This MySQL server hosts the databases for Nova, Glance, "" ""Cinder, and Keystone. With all of these databases in one place, it's very "" ""easy to create a database backup:"" msgstr ""参考アーキテクチャーでは、クラウドコントローラーを MySQL サーバにしています。このMySQL サーバーは Nova, Glance, Cinder, そして Keystone のデータベースを保持しています。全てのデータベースが一ヶ所にある場合、データベースバックアップは非常に容易となります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml63(para) msgid ""If you only want to backup a single database, you can instead run:"" msgstr ""もし、単一のデータベースのみバックアップする場合は次のように実行します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml66(para) msgid ""where <code>nova</code> is the database you want to back up."" msgstr ""ここで <code>nova</code> はバックアップ対象のデータベースです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml68(para) msgid """" ""You can easily automate this process by creating a cron job that runs the "" ""following script once per day:"" msgstr ""以下のようなcronジョブを一日に一度実行することで、簡単に自動化することも出来ます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml77(para) msgid """" ""This script dumps the entire MySQL database and delete any backups older "" ""than 7 days."" msgstr ""このスクリプトは MySQL データベース全体をダンプし、7日間より古いバックアップを削除します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml81(title) msgid ""File System Backups"" msgstr ""ファイルシステムバックアップ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml82(para) msgid """" ""This section discusses which files and directories should be backed up "" ""regularly, organized by service."" msgstr ""このセクションは、サービスにより構成される、定期的にバックアップすべきファイルとディレクトリについて議論します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml84(title) msgid ""Compute"" msgstr ""コンピュート"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml85(para) msgid """" ""The <code>/etc/nova</code> directory on both the cloud controller and "" ""compute nodes should be regularly backed up."" msgstr ""クラウドコントローラー、および、コンピュートノードの <code>/etc/nova</code>ディレクトリは定期的にバックアップされるべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml88(para) msgid """" ""<code>/var/log/nova</code> does not need backed up if you have all logs "" ""going to a central area. It is highly recommended to use a central logging "" ""server or backup the log directory."" msgstr ""<code>/var/log/nova</code> については、全てのログをリモートで集中管理しているのであれば、バックアップの必要はありません。ログ集約システムの導入か、ログディレクトリのバックアップを強く推奨します"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml93(para) msgid """" ""<code>/var/lib/nova</code> is another important directory to backup. The "" ""exception to this is the <code>/var/lib/nova/instances</code> subdirectory "" ""on compute nodes. This subdirectory contains the KVM images of running "" ""instances. You would only want to back up this directory if you need to "" ""maintain backup copies of all instances. Under most circumstances, you do "" ""not need to do this, but this can vary from cloud to cloud and your service "" ""levels. Also be aware that making a backup of a live KVM instance can cause "" ""that instance to not boot properly if it is ever restored from a backup."" msgstr ""<code>/var/lib/nova</code> がバックアップする他の重要なディレクトリです。これの例外がコンピュートノードにある <code>/var/lib/nova/instances</code> サブディレクトリです。このサブディレクトリには実行中のインスタンスの KVM イメージが置かれます。このディレクトリをバックアップしたいと思うのは、すべてのインスタンスのバックアップコピーを保持する必要がある場合だけでしょう。多くの場合において、これを実行する必要がありません。ただし、クラウドごとに異なり、サービスレベルによっても異なる可能性があります。稼働中の KVM インスタンスのバックアップは、バックアップから復元したときでも、正しく起動しない可能性があることに気をつけてください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml108(title) msgid ""Image Catalog and Delivery"" msgstr ""イメージカタログと配布"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml109(para) msgid """" ""<code>/etc/glance</code> and <code>/var/log/glance</code> follow the same "" ""rules at the nova counterparts."" msgstr ""<code>/etc/glance</code>と<code>/var/log/glance</code>はnovaの場合と同じルールに従います。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml113(para) msgid """" ""<code>/var/lib/glance</code> should also be backed up. Take special notice "" ""of <code>/var/lib/glance/images</code>. If you are using a file-based back-"" ""end of Glance, <code>/var/lib/glance/images</code> is where the images are "" ""stored and care should be taken."" msgstr ""<code>/var/lib/glance</code>もバックアップすべきです。 <code>/var/lib/glance/images</code>には特段の注意が必要です。もし、ファイルベースのバックエンドを利用しており、このディレクトリがイメージの保管ディレクトリならば特にです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml120(para) msgid """" ""There are two ways to ensure stability with this directory. The first is to "" ""make sure this directory is run on a RAID array. If a disk fails, the "" ""directory is available. The second way is to use a tool such as rsync to "" ""replicate the images to another server:"" msgstr ""このディレクトリの永続性を保証するために二つの方法があります。一つ目はRAIDアレイ上にこのディレクトリを置くことで、ディスク障害時にもこのディレクトリが利用できます。二つ目の方法はrsyncのようなツールを用いてイメージを他のサーバーに複製することです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml126(para) msgid """" ""# rsync -az --progress /var/lib/glance/images backup-"" ""server:/var/lib/glance/images/"" msgstr ""# rsync -az --progress /var/lib/glance/images backup-server:/var/lib/glance/images/"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml130(title) msgid ""Identity"" msgstr ""認証"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml131(para) msgid """" ""<code>/etc/keystone</code> and <code>/var/log/keystone</code> follow the "" ""same rules as other components."" msgstr ""<code>/etc/keystone</code>と<code>/var/log/keystone</code>は他のコンポーネントと同じルールになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml135(para) msgid """" ""<code>/var/lib/keystone</code>, while should not contain any data being "" ""used, can also be backed up just in case."" msgstr ""<code>/var/lib/keystone</code>は、使用されるデータは含まれていないはずですが、念のためバックアップします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml142(para) msgid """" ""<code>/etc/cinder</code> and <code>/var/log/cinder</code> follow the same "" ""rules as other components."" msgstr ""<code>/etc/cinder</code>と<code>/var/log/cinder</code>は他のコンポーネントと同じルールです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml146(para) msgid ""<code>/var/lib/cinder</code> should also be backed up."" msgstr ""<code>/var/lib/cinder</code>もまたバックアップされるべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml151(title) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml110(title) msgid ""Object Storage"" msgstr ""オブジェクトストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml152(para) msgid """" ""<code>/etc/swift</code> is very important to have backed up. This directory "" ""contains the Swift configuration files as well as the ring files and ring "" ""<glossterm>builder file</glossterm>s, which if lost render the data on your "" ""cluster inaccessible. A best practice is to copy the builder files to all "" ""storage nodes along with the ring files. Multiple backups copies are spread "" ""throughout your storage cluster."" msgstr ""<code>/etc/swift</code>は非常に重要ですのでバックアップが必要です。このディレクトリには、Swiftの設定ファイル以外に、RingファイルやRing<glossterm>ビルダーファイル</glossterm>が置かれています。これらのファイルを消失した場合はクラスター上のデータにアクセスできなくなります。ベストプラクティスとしては、ビルダーファイルを全てのストレージノードにringファイルと共に置くことです。この方法でストレージクラスター上にバックアップコピーが分散されて保存されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml165(title) msgid ""Recovering Backups"" msgstr ""バックアップのリカバリー"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml166(para) msgid """" ""Recovering backups is a fairly simple process. To begin, first ensure that "" ""the service you are recovering is not running. For example, to do a full "" ""recovery of nova on the cloud controller, first stop all <code>nova</code> "" ""services:"" msgstr ""バックアップのリカバリーは単純です。始めにリカバリー対象のサービスが停止していることを確認します。例を挙げると、クラウドコントローラー上のnovaの完全リカバリーを行なう場合、最初に全ての <code>nova</code> サービスを停止します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml177(para) msgid ""Once that's done, stop MySQL:"" msgstr ""その後、MySQLを停止します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml179(para) msgid ""Now you can import a previously backed up database:"" msgstr ""以前にバックアップしたデータベースをインポートします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml182(para) msgid ""As well as restore backed up nova directories:"" msgstr ""同様に、バックアップした nova のディレクトリをリストアします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml185(para) msgid ""Once the files are restored, start everything back up:"" msgstr ""ファイルをリストア後、サービスを起動します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_backup_recovery.xml193(para) msgid """" ""Other services follow the same process, with their respective directories "" ""and databases."" msgstr ""他のサービスもそれぞれのディレクトリとデータベース名で同じ処理となります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml14(title) #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml55(title) #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml152(title) #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml188(title) msgid ""Resources"" msgstr ""リソース"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml18(para) msgid """" ""<link xlink:href=\""http://docs.openstack.org/folsom/openstack-"" ""compute/admin/content/\"">OpenStack Compute Administration Manual</link> "" ""(http://docs.openstack.org/folsom/openstack-compute/admin/content/)"" msgstr ""<link xlink:href=\""http://docs.openstack.org/folsom/openstack-compute/admin/content/\"">OpenStack Compute Administration Manual</link> (http://docs.openstack.org/folsom/openstack-compute/admin/content/)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml23(para) msgid """" ""<link xlink:href=\""http://docs.openstack.org/folsom/openstack-"" ""compute/install/apt/content/\"">OpenStack Compute Install and Deploy Manual -"" "" Ubuntu</link> (http://docs.openstack.org/folsom/openstack-"" ""compute/install/apt/content/)"" msgstr ""<link xlink:href=\""http://docs.openstack.org/folsom/openstack-compute/install/apt/content/\"">OpenStack Compute Install and Deploy Manual - Ubuntu</link> (http://docs.openstack.org/folsom/openstack-compute/install/apt/content/)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml29(para) msgid """" ""<link xlink:href=\""http://www.packtpub.com/openstack-cloud-computing-"" ""cookbook/book\"">OpenStack Cloud Computing Cookbook</link> "" ""(http://www.packtpub.com/openstack-cloud-computing-cookbook/book)"" msgstr ""<link xlink:href=\""http://www.packtpub.com/openstack-cloud-computing-cookbook/book\"">OpenStack Cloud Computing Cookbook</link> (http://www.packtpub.com/openstack-cloud-computing-cookbook/book)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml35(emphasis) msgid ""Cloud (general)"" msgstr ""クラウド (全般)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml37(para) msgid """" ""<link "" ""xlink:href=\""http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf\"">NIST"" "" Cloud Computing Definition</link> "" ""(http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf)"" msgstr ""<link xlink:href=\""http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf\"">NIST Cloud Computing Definition</link> (http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml45(para) msgid """" ""<link xlink:href=\""http://www.diveintopython.net\"">Dive Into Python</link> "" ""(http://www.diveintopython.net)"" msgstr ""<link xlink:href=\""http://www.diveintopython.net\"">Dive Into Python</link> (http://www.diveintopython.net)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml51(para) msgid """" ""<link xlink:href=\""http://www.pearsonhighered.com/educator/product/TCPIP-"" ""Illustrated-Volume-1-The-Protocols/9780321336316.page\"">TCP/IP "" ""Illustrated</link> (http://www.pearsonhighered.com/educator/product/TCPIP-"" ""Illustrated-Volume-1-The-Protocols/9780321336316.page)"" msgstr ""<link xlink:href=\""http://www.pearsonhighered.com/educator/product/TCPIP-Illustrated-Volume-1-The-Protocols/9780321336316.page\"">TCP/IP Illustrated</link> (http://www.pearsonhighered.com/educator/product/TCPIP-Illustrated-Volume-1-The-Protocols/9780321336316.page)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml56(para) msgid """" ""<link xlink:href=\""http://nostarch.com/tcpip.htm\"">The TCP/IP Guide</link> "" ""(http://nostarch.com/tcpip.htm)"" msgstr ""<link xlink:href=\""http://nostarch.com/tcpip.htm\"">The TCP/IP Guide</link> (http://nostarch.com/tcpip.htm)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml59(para) msgid """" ""<link xlink:href=\""http://danielmiessler.com/study/tcpdump/\"">A tcpdump Tutorial "" ""and Primer</link> (http://danielmiessler.com/study/tcpdump/)"" msgstr ""<link xlink:href=\""http://danielmiessler.com/study/tcpdump/\"">A tcpdump Tutorial and Primer</link> (http://danielmiessler.com/study/tcpdump/)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml64(emphasis) msgid ""Systems administration"" msgstr ""システム管理"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml66(para) msgid """" ""<link xlink:href=\""http://www.admin.com/\"">UNIX and Linux Systems Administration "" ""Handbook</link> (http://www.admin.com/)"" msgstr ""<link xlink:href=\""http://www.admin.com/\"">UNIX and Linux Systems Administration Handbook</link> (http://www.admin.com/)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml71(emphasis) msgid ""Virtualization"" msgstr ""仮想化"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml73(para) msgid """" ""<link xlink:href=\""http://nostarch.com/xen.htm\"">The Book of Xen</link> "" ""(http://nostarch.com/xen.htm)"" msgstr ""<link xlink:href=\""http://nostarch.com/xen.htm\"">The Book of Xen</link> (http://nostarch.com/xen.htm)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml77(emphasis) msgid ""Configuration management"" msgstr ""設定管理"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml79(para) msgid """" ""<link xlink:href=\""http://docs.puppetlabs.com/\"">Puppet Labs Documentation</link> "" ""(http://docs.puppetlabs.com/)"" msgstr ""<link xlink:href=\""http://docs.puppetlabs.com/\"">Puppet Labs Documentation</link> (http://docs.puppetlabs.com/)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_resources.xml82(para) msgid """" ""<link xlink:href=\""http://www.apress.com/9781430230571\"">Pro Puppet</link> "" ""(http://www.apress.com/9781430230571)"" msgstr ""<link xlink:href=\""http://www.apress.com/9781430230571\"">Pro Puppet</link> (http://www.apress.com/9781430230571)"" #. When image changes, this message will be marked fuzzy or untranslated for #. you. #. It doesn't matter what you translate it to: it's not used at all. #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml95(None) msgid """" ""@@image: 'figures/os_disk_partition.png'; "" ""md5=2cd7b90349b84b8ef2c97727b9601045"" msgstr ""@@image: 'figures/os_disk_partition.png'; md5=2cd7b90349b84b8ef2c97727b9601045"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml16(title) msgid ""Provisioning and Deployment"" msgstr ""プロビジョニングとデプロイメント"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml17(para) msgid """" ""A critical part of a cloud's scalability is the amount of effort that it "" ""takes to run your cloud. To minimize the operational cost of running your "" ""cloud, set up and use an automated deployment and configuration "" ""infrastructure."" msgstr ""クラウドのスケーラビリティにおける重要な部分の一つは、クラウドを運用するのに必要な労力にあります。クラウドの運用コストを最小化するために、デプロイメントと環境設定を自動化する基盤を構築して利用しましょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml21(para) msgid """" ""This infrastructure includes systems to automatically install the operating "" ""system's initial configuration and later coordinate the configuration of all"" "" services automatically and centrally, which reduces both manual effort and "" ""chance for error."" msgstr ""この基盤には、初期構成のオペレーティングシステム自動的にインストールすること、その後すべてのサービスの環境設定を自動的かつ集中的に調整することが含まれます。これにより、手操作の労力と誤りが介在する余地を減らすことができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml27(title) msgid ""Automated Deployment"" msgstr ""自動デプロイメント"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml28(para) msgid """" ""An automated deployment system installs and configures operating systems on "" ""new servers, without intervention, after the absolute minimum amount of "" ""manual work, including physical racking, MAC to IP assignment, power "" ""configuration, and so on. Typically solutions rely on wrappers around PXE "" ""boot and TFTP servers for the basic operating system install, then hand off "" ""to an automated configuration management system."" msgstr ""自動デプロイメントシステムは、新しいサーバーに対して、物理的なラッキング、MAC アドレスへの IP アドレスの割り当て、電源設定といった必要最小限の手操作の後、人手の介在なしに、オペレーティングシステムのインストールと環境設定を行います。典型的な方法では、PXE ブートと TFTP サーバーを使った仕組みを元にしてオペレーティングシステムの基本的なインストールを行い、その後、自動環境設定管理システムに制御を渡します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml36(para) msgid """" ""Ubuntu and Red Hat Linux both include mechanisms for configuring the "" ""operating system, including preseed and kickstart, that you can use after a "" ""network boot. Typically these are used to bootstrap an automated "" ""configuration system. Alternatively, you can use an image-based approach for"" "" deploying the operating system, such as systemimager. You can use both "" ""approaches with a virtualized infrastructure, such as when you run VMs to "" ""separate your control services and physical infrastructure."" msgstr ""Ubuntu と Red Hat Linux はどちらも、preseed や kickstart といった、ネットワークブートの後に利用できる、オペレーティングシステムを設定するための仕組みを持っています。これらは、典型的には自動環境設定システムを自力で立ち上げるために使われます。他の方法としては、systemimager のようなイメージベースのオペレーティングシステムのデプロイメント手法を使うこともできます。これらの手法は、例えば物理インフラと制御サービスを分離するために仮想マシンを使う時のように、いずれも仮想化基盤といっしょに使うことができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml46(para) msgid """" ""When you create a deployment plan, focus on a few vital areas because they "" ""are very hard to modify post-deployment."" msgstr ""デプロイメントの計画を立てる際には、後から修正するのはとても困難な、いくつかの重要な領域に集中してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml51(title) msgid ""Disk Partitioning and RAID"" msgstr ""ディスクのパーティショニングと RAID"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml52(para) msgid """" ""At the very base of any operating system are the hard drives on which the OS"" "" is installed."" msgstr ""どんなオペレーティングシステムでも、もっとも根本的な部分として、それがインストールされるハードディスクがあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml54(para) msgid """" ""You must complete the following configurations on the server's hard drives:"" msgstr ""サーバーのハードディスクに対して、以下の環境設定を完了させなければなりません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml58(para) msgid ""Partitioning"" msgstr ""パーティショニング"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml61(para) msgid ""Adding to a RAID array"" msgstr ""RAID アレイへの追加"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml64(para) msgid ""The simplest option is to use one hard drive with two partitions:"" msgstr ""もっとも簡単な選択肢は、1 台のハードディスクを 2 つのパーティションに分割することです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml68(para) msgid ""File system"" msgstr ""ファイルシステム"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml71(para) msgid ""Swap space"" msgstr ""スワップ領域"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml74(para) msgid ""RAID is not used in this setup."" msgstr ""この場合は RAID は使用しません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml76(para) msgid """" ""This option is not recommended for production because if the hard drive "" ""fails, that entire server is down. Instead, we recommend that you use more "" ""than one disk. The number of disks determine what types of RAID arrays to "" ""build."" msgstr ""この選択肢は、ハードディスクが故障するとサーバー全体がダウンしてしまうため、商用環境には推奨されません。代わりに、2 台以上のディスクを使用することを推奨します。使用するディスクの台数によって、構成する RAID アレイの種類が決まります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml83(para) msgid """" ""We recommend that you choose one of the following multiple disk options:"" msgstr ""以下に挙げる複数のディスクの選択肢から選ぶことを推奨します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml87(para) msgid """" ""<emphasis role=\""bold\"">Option 1:</emphasis> Partition all drives in the "" ""same way in a horizontal fashion, as shown in the following diagram: "" ""<placeholder-1/>"" msgstr ""<emphasis role=\""bold\"">オプション 1:</emphasis> 次の図に示すように、すべてのハードディスクをまったく同じようにパーティショニングします。 <placeholder-1/>"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml99(para) msgid """" ""With this option, you can assign different partitions to different RAID "" ""arrays. You can allocate partition 1 of disk one and two to the "" ""<code>/boot</code> partition mirror. You can make partition 2 of all disks "" ""the root partition mirror. You can use partition 3 of all disks for a <code"" "">cinder-volumes</code> LVM partition running on a RAID 10 array."" msgstr ""このオプションでは、パーティションごとに異なる RAID アレイにおくことができます。例えば、ディスク 1 とディスク 2 のパーティション 1 を <code>/boot</code> パーティションのミラーとして、すべてのディスクのパーティション 2 をルートパーティションのミラーとして、すべてのディスクのパーティション 3 を RAID10 アレイの上の <code>cinder-volumes</code> の LVM パーティションとして割り当てることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml108(para) msgid """" ""While you might end up with unused partitions, such as partition 1 in disk "" ""three and four of this example, it allows for maximum utilization off disk "" ""space. I/O performance might be an issue due to all disks being used for all"" "" tasks."" msgstr ""この例にあるディスク 3 と 4 のパーティション 1 のように使用しないパーティションが残ることになるかもしれないとしても、ディスク領域の利用率を最大化することができます。すべてのディスクがすべてのタスクで利用されることにより、I/O 性能が問題になるかもしれません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml116(para) msgid """" ""<emphasis role=\""bold\"">Option 2:</emphasis> Add all raw disks to one large "" ""RAID array, either hardware or software based. You can partition this large "" ""array with the boot, root, swap, and LVM areas. This option is simple to "" ""implement and uses all partitions. However, disk I/O might suffer."" msgstr ""<emphasis role=\""bold\"">オプション 2:</emphasis> すべてのディスクを 1 つの大きな RAID アレイに追加します。ここでは、ソフトウェア RAID でもハードウェア RAID でもかまいません。この大きな RAID アレイを boot、root、swap、そして LVM 領域に分割します。この選択肢はシンプルですべてのパーティションを利用することができますが、I/O 性能に悪影響があるかもしれません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml126(para) msgid """" ""<emphasis role=\""bold\"">Option 3:</emphasis> Dedicate entire disks to "" ""certain partitions. For example, you could allocate disk one and two "" ""entirely to the boot, root, and swap partitions under a RAID 1 mirror. Then,"" "" allocate disk 3 and 4 entirely to the LVM partition, also under a RAID 1 "" ""mirror. Disk I/O should be better because I/O is focused on dedicated tasks."" "" However, the LVM partition is much smaller."" msgstr ""<emphasis role=\""bold\"">オプション 3:</emphasis> 全ディスク領域を特定のパーティションで占有させます。例えば、ディスク 1 と 2 を RAID1 ミラーで boot、root、swap パーティションに割り当て、そしてディスク 3 と 4 は、すべてをやはり RAID1 ミラーの LVM パーティションに割り当てます。この場合は、I/O を特定の目的に集中させるため、より良いディスク I/O 性能を得ることができるでしょう。ただし、LVM パーティションはだいぶ小さくなります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml138(para) msgid """" ""As with most architecture choices, the right answer depends on your "" ""environment."" msgstr ""ほとんどのアーキテクチャ上の選択のように、正しい答えは環境に依存します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml142(title) msgid ""Network Configuration"" msgstr ""ネットワーク設定"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml143(para) msgid """" ""Network configuration is a very large topic that spans multiple areas of "" ""this book. For now, make sure that your servers can PXE boot and "" ""successfully communicate with the deployment server."" msgstr ""ネットワーク設定は、この本の複数の部分にまたがるとても大きな話題です。ここでは、用意したサーバーが PXE ブートできることと、デプロイメントサーバーと正常に通信できることを確認しておいてください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml147(para) msgid """" ""For example, you usually cannot configure NICs for VLANs when PXE booting. "" ""Additionally, you usually cannot PXE boot with bonded NICs. If you run into "" ""this scenario, consider using a simple 1 GB switch in a private network on "" ""which only your cloud communicates."" msgstr ""例えば、PXE ブートの際には、通常は VLAN の設定は行えません。さらに、通常は bonding された NIC から PXE ブートを行うこともできません。このような状況の場合、クラウド内でのみ通信できるネットワークで、シンプルな 1Gbps のスイッチを使うことを検討してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml156(title) msgid ""Automated Configuration"" msgstr ""自動環境設定"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml157(para) msgid """" ""The purpose of automatic configuration management is to establish and "" ""maintain the consistency of a system with no human intervention. You want to"" "" maintain consistency in your deployments so you can have the same cloud "" ""every time, repeatably. Proper use of automatic configuration management "" ""tools ensures that components of the cloud systems are in particular states,"" "" in addition to simplifying deployment, and configuration change "" ""propagation."" msgstr ""自動環境設定管理の目的は、人間の介在なしにシステムの一貫性を確立し、維持することにあります。同じクラウド環境を毎回繰り返し作るために、デプロイメントにおける一貫性を維持したいでしょう。自動環境設定管理ツールを正しく利用することによって、デプロイメントと環境設定の変更を全体に展開する作業を単純にすることに加えて、クラウドのシステムを構成するコンポーネントが特定の状態にあるように保証することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml166(para) msgid """" ""These tools also make it possible to test and roll back changes, as they are"" "" fully repeatable. Conveniently, a large body of work has been done by the "" ""OpenStack community in this space. Puppet – a configuration management tool "" ""– even provides official modules for OpenStack."" msgstr ""これらのツールは、完全に繰り返して動作可能であるため、変更点のテストやロールバックを行うことができます。OpenStack コミュニティでは、この手法で多くの作業が便利に実行されています。設定管理ツールの 1 つである Puppet の場合、OpenStack 用のモジュールも提供されています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml172(para) msgid """" ""An integral part of a configuration management system is the items that it "" ""controls. You should carefully consider all of the items that you want, or "" ""do not want, to be automatically managed."" msgstr ""設定管理システムと、それによって管理する項目は、切っても切れない関係にあります。自動的に管理したい項目と管理したくない項目のすべてを注意深く検討するべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml179(title) msgid ""Remote Management"" msgstr ""リモート管理"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml180(para) msgid """" ""In our experience, most operators don't sit right next to the servers "" ""running the cloud, and many don't necessarily enjoy visiting the data "" ""center. OpenStack should be entirely remotely configurable, but sometimes "" ""not everything goes according to plan."" msgstr ""経験上、ほとんどの事業者はクラウドを動かすサーバーのすぐ横に席があるわけではありません。また、多くの人が必ずしもデータセンターに行くことを楽しんでいるわけではありません。OpenStack は完全にリモートから環境設定できますが、時にこの通りにならないこともあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml185(para) msgid """" ""In this instance, having an out-of-band access into nodes running OpenStack "" ""components, is a boon. The IPMI protocol is the de-facto standard here, and "" ""acquiring hardware that supports it is highly recommended to achieve that "" ""lights-out data center aim."" msgstr ""この場合、OpenStack が動くノードに対して外側からアクセスできるようにすることが重要です。ここでは、IPMI プロトコルがデファクトスタンダードです。完全自動のデータセンタを実現するために、IPMI をサポートしたハードウェアを購入することを強く推奨します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_provision.xml190(para) msgid """" ""In addition, consider remote power control as well. While IPMI usually "" ""controls the server's power state, having remote access to the PDU that the "" ""server is plugged into can really be useful for situations when everything "" ""seems wedged."" msgstr ""さらに、リモート電源管理装置も検討してください。通常、IPMI はサーバーの電源状態を制御しますが、サーバーが接続されている PDU にリモートアクセスできれば、すべてが手詰まりに見えるような状況で非常に役に立ちます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml17(title) msgid ""Maintenance, Failures, and Debugging"" msgstr ""メンテナンス、故障およびデバッグ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml18(para) msgid """" ""Downtime, whether planned or unscheduled, is a certainty when running a "" ""cloud. This chapter aims to provide useful information for dealing "" ""proactively, or reactively with these occurrences."" msgstr ""停止時間（計画的なものと予定外のものの両方）はクラウドを運用するときに確実に発生します。本章は、プロアクティブまたはリアクティブに、これらの出来事に対処するために有用な情報を提供することを目的としています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml24(title) msgid ""Cloud Controller and Storage Proxy Failures and Maintenance"" msgstr ""クラウドコントローラーとストレージプロキシの故障とメンテナンス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml26(para) msgid """" ""The cloud controller and storage proxy are very similar to each other when "" ""it comes to expected and unexpected downtime. One of each server type "" ""typically runs in the cloud, which makes them very noticeable when they are "" ""not running."" msgstr ""想定内の場合も想定外の場合も停止時間が発生した場合の挙動が、クラウドコントローラーとストレージプロキシは互いに似ています。クラウドコントローラーとストレージプロキシはそれぞれクラウドで一つ実行されるので、動作していない場合、非常に目立ちます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml31(para) msgid """" ""For the cloud controller, the good news is if your cloud is using the "" ""FlatDHCP multi-host HA network mode, existing instances and volumes continue"" "" to operate while the cloud controller is offline. However for the storage "" ""proxy, no storage traffic is possible until it is back up and running."" msgstr ""クラウドコントローラーの場合、良いニュースとしては、クラウドが FlatDHCP マルチホスト HA ネットワークモードを使用していれば、既存のインスタンスとボリュームはクラウドコントローラーがオフラインの間も動作を継続するという点があります。しかしながら、ストレージプロキシの場合には、サーバーが元に戻され動作状態になるまで、ストレージとの通信ができません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml39(title) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml115(title) msgid ""Planned Maintenance"" msgstr ""計画メンテナンス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml40(para) msgid """" ""One way to plan for cloud controller or storage proxy maintenance is to "" ""simply do it off-hours, such as at 1 or 2 A.M.. This strategy impacts fewer "" ""users. If your cloud controller or storage proxy is too important to have "" ""unavailable at any point in time, you must look into High Availability "" ""options."" msgstr ""クラウドコントローラーやストレージプロキシのメンテナンスを計画する一つの方法は、単に午前 1 時や 2 時のような利用の少ない時間帯に実行することです。この戦略はあまり多くのユーザーに影響を与えません。クラウドコントローラーやストレージプロキシが、いかなる時間帯においても、サービスが利用できないことによる影響が大きければ、高可用性オプションについて検討する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml49(title) msgid ""Rebooting a cloud controller or Storage Proxy"" msgstr ""クラウドコントローラーとストレージプロキシの再起動"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml51(para) msgid """" ""All in all, just issue the \""reboot\"" command. The operating system cleanly "" ""shuts services down and then automatically reboots. If you want to be very "" ""thorough, run your backup jobs just before you reboot."" msgstr ""多くの場合、\""reboot\"" コマンドを発行するだけです。オペレーティングシステムが正常にサービスをシャットダウンし、自動的に再起動します。万全を期したい場合、再起動する前にバックアップジョブを実行してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml59(title) msgid ""After a Cloud Controller or Storage Proxy Reboots"" msgstr ""クラウドコントローラーまたはストレージプロキシの再起動後"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml61(para) msgid """" ""After a cloud controller reboots, ensure that all required services were "" ""successfully started:"" msgstr ""クラウドコントローラーを再起動した後、すべての必要なサービスが正常に起動したことを確認します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml68(para) msgid ""Also check that all services are functioning:"" msgstr ""また、すべてのサービスが正しく機能していることを確認します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml73(para) msgid """" ""For the storage proxy, ensure that the Object Storage service has resumed:"" msgstr ""ストレージプロキシの場合、Object Storage サービスが再開していることを確認します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml76(para) msgid ""Also check that it is functioning:"" msgstr ""また、正しく機能していることを確認します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml81(title) msgid ""Total Cloud Controller Failure"" msgstr ""全体的なクラウドコントローラーの故障"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml82(para) msgid """" ""Unfortunately, this is a rough situation. The cloud controller is a integral"" "" part of your cloud. If you have only one controller, many services are "" ""missing."" msgstr ""残念ながら、これはひどい状況です。クラウドコントローラーはクラウドの不可欠な部分です。コントローラーが一つだけならば、多くのサービスが失われます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml86(para) msgid """" ""To avoid this situation, create a highly available cloud controller cluster."" "" This is outside the scope of this document, but you can read more in the "" ""draft <link xlink:title=\""OpenStack High Availability Guide\"" "" ""xlink:href=\""http://docs.openstack.org/trunk/openstack-ha/content/ch-"" ""intro.html\"">OpenStack High Availability Guide</link> "" ""(http://docs.openstack.org/trunk/openstack-ha/content/ch-intro.html)."" msgstr ""この状況を避けるために、高可用なクラウドコントローラークラスターを作成します。このことは、このドキュメントの範囲外ですが、ドラフト版の <link xlink:title=\""OpenStack High Availability Guide\"" xlink:href=\""http://docs.openstack.org/trunk/openstack-ha/content/ch-intro.html\"">OpenStack High Availability Guide</link> が http://docs.openstack.org/trunk/openstack-ha/content/ch-intro.html にあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml94(para) msgid """" ""The next best way is to use a configuration management tool such as Puppet "" ""to automatically build a cloud controller. This should not take more than 15"" "" minutes if you have a spare server available. After the controller "" ""rebuilds, restore any backups taken (see the <emphasis role=\""bold\"">Backup "" ""and Recovery</emphasis> chapter)."" msgstr ""次に最も優れている方法は、クラウドコントローラーを自動的に構築するために Puppet のような構成管理ツールを使用することです。利用可能な予備サーバーがあれば、15 分もかかりません。コントローラーを再構築後、取得したすべてのバックアップを復元します (<emphasis role=\""bold\"">バックアップとリカバリー</emphasis> の章を参照してください)。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml101(para) msgid """" ""Also, in practice, sometimes the nova-compute services on the compute nodes "" ""do not reconnect cleanly to rabbitmq hosted on the controller when it comes "" ""back up after a long reboot and a restart on the nova services on the "" ""compute nodes is required."" msgstr ""実際には、コンピュートノードの nova-compute サービスがときどき、コントローラー上で動作している rabbitmq に正しく再接続されない場合があります。時間のかかるリブートから戻ってきた場合や、コンピュートノードのnova サービスを再起動する必要がある場合です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml110(title) msgid ""Compute Node Failures and Maintenance"" msgstr ""コンピュートノードの故障とメンテナンス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml111(para) msgid """" ""Sometimes a compute node either crashes unexpectedly or requires a reboot "" ""for maintenance reasons."" msgstr ""コンピュートノードは、予期せずクラッシュしたり、メンテナンスのために再起動が必要になったりすることがときどきあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml116(para) msgid """" ""If you need to reboot a compute node due to planned maintenance (such as a "" ""software or hardware upgrade), first ensure that all hosted instances have "" ""been moved off of the node. If your cloud is utilizing shared storage, use "" ""the <code>nova live-migration</code> command. First, get a list of instances"" "" that need to be moved:"" msgstr ""(ソフトウェアやハードウェアのアップグレードのように) 計画されたメンテナンスのために、コンピュートノードを再起動する必要があれば、まずホストしている全インスタンスがノード外に移動していることを確認します。クラウドが共有ストレージを利用していれば、<code>nova live-migration</code> コマンドを使用します。初めに、移動させる必要があるインスタンスの一覧を取得します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml124(para) msgid ""Next, migrate them one by one:"" msgstr ""次に、それらを一つずつマイグレーションします"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml126(para) msgid """" ""If you are not using shared storage, you can use the <code>--block-"" ""migrate</code> option:"" msgstr ""共有ストレージを使用していない場合、<code>--block-migrate</code> オプションを使用できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml129(para) msgid """" ""After you have migrated all instances, ensure the <code>nova-compute</code> "" ""service has stopped:"" msgstr ""すべてのインスタンスをマイグレーションした後、<code>nova-compute</code> サービスが停止していることを確認します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml133(para) msgid """" ""If you use a configuration management system, such as Puppet, that ensures "" ""the <code>nova-compute</code> service is always running, you can temporarily"" "" move the init files:"" msgstr ""Puppet などの構成管理システムを使って、<code>nova-compute</code> サービスが確実に実行されているようにしている場合、init ファイルを一時的に移動します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml140(para) msgid """" ""Next, shut your compute node down, perform your maintenance, and turn the "" ""node back on. You can re-enable the <code>nova-compute</code> service by "" ""undoing the previous commands:"" msgstr ""続けて、コンピュートノードを停止し、メンテナンスを実行し、ノードを元に戻します。先のコマンドを逆に実行することにより、<code>nova-compute</code> サービスを再び有効化できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml146(para) msgid ""Then start the <code>nova-compute</code> service:"" msgstr ""そして <code>nova-compute</code> サービスを起動します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml149(para) msgid """" ""You can now optionally migrate the instances back to their original compute "" ""node."" msgstr ""インスタンスを元のコンピュートノードにマイグレーションすることもできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml154(title) msgid ""After a Compute Node Reboots"" msgstr ""コンピュートノードの再起動後"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml155(para) msgid """" ""When you reboot a compute node, first verify that it booted successfully. "" ""This includes ensuring the <code>nova-compute</code> service is running:"" msgstr ""コンピュートノードを再起動した場合、まず正常に起動したことを確認します。これには <code>nova-compute</code> サービスが実行していることを確認することが含まれます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml161(para) msgid ""Also ensure that it has successfully connected to the AMQP server:"" msgstr ""AMQP サーバーに正常に接続できることも確認します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml165(para) msgid """" ""After the compute node is successfully running, you must deal with the "" ""instances that are hosted on that compute node as none of them is running. "" ""Depending on your SLA with your users or customers, you might have to start "" ""each instance and ensure they start correctly."" msgstr ""コンピュートノードが正常に実行された後、そのコンピュートノードでホストされているインスタンスはどれも動作していないので、そのコンピュートノードにおいてホストされているインスタンスを処理する必要があります。ユーザーや顧客に対する SLA によっては、各インスタンスを開始し、正常に起動していることを確認する必要がある場合もあるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml175(para) msgid """" ""You can create a list of instances that are hosted on the compute node by "" ""performing the following command:"" msgstr ""以下のコマンドを実行することにより、コンピュートノードにおいてホストされているインスタンスの一覧を作成できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml179(para) msgid """" ""After you have the list, you can use the nova command to start each "" ""instance:"" msgstr ""一覧を取得した後、各インスタンスを起動するために nova コマンドを使用できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml183(para) msgid """" ""Any time an instance shuts down unexpectedly, it might have problems on "" ""boot. For example, the instance might require an <code>fsck</code> on the "" ""root partition. If this happens, the user can use the Dashboard VNC console "" ""to fix this."" msgstr ""予期せずシャットダウンしたときは、ブートに問題があるかもしれません。たとえば、インスタンスがルートパーティションにおいて <code>fsck</code> を実行する必要があるかもしれません。もしこうなっても、これを修復するためにダッシュボード VNC コンソールを使用できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml189(para) msgid """" ""If an instance does not boot, meaning <code>virsh list</code> never shows "" ""the instance as even attempting to boot, do the following on the compute "" ""node:"" msgstr ""インスタンスがブートしなければ、つまりブートしようとしても <code>virsh list</code> がインスタンスを表示しなければ、コンピュートノードにおいて以下のとおり実行します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml194(para) msgid """" ""Try executing the <code>nova reboot</code> command again. You should see an "" ""error message about why the instance was not able to boot"" msgstr ""再び <code>nova reboot</code> コマンドを実行してみてください。インスタンスがなぜブートできないかについて、エラーメッセージを確認すべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml197(para) msgid """" ""In most cases, the error is due to something in libvirt's XML file "" ""(<code>/etc/libvirt/qemu/instance-xxxxxxxx.xml</code>) that no longer "" ""exists. You can enforce recreation of the XML file as well as rebooting the "" ""instance by running:"" msgstr ""多くの場合、libvirt の XML ファイル (<code>/etc/libvirt/qemu/instance-xxxxxxxx.xml</code>) の何かがすでに存在しないことで、エラーが発生する。次のとおり実行することにより、インスタンスを再起動するのと同時に、強制的に XML ファイルを再作成できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml207(title) msgid ""Inspecting and Recovering Data from Failed Instances"" msgstr ""故障したインスタンスからの検査とデータ復旧"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml209(para) msgid """" ""In some scenarios, instances are running but are inaccessible through SSH "" ""and do not respond to any command. VNC console could be displaying a boot "" ""failure or kernel panic error messages. This could be an indication of a "" ""file system corruption on the VM itself. If you need to recover files or "" ""inspect the content of the instance, qemu-nbd can be used to mount the disk."" msgstr ""いくつかのシナリオでは、インスタンスが実行中であるにも関わらず、SSH 経由でアクセスできず、あらゆるコマンドに反応がありません。VNC コンソールがブート失敗やカーネルパニックのエラーメッセージを表示している可能性があります。これは仮想マシン自身においてファイルシステム破損の意味する可能性があります。ファイルを復旧したりインスタンスの中身を調査したりする必要があれば、qemu-nbd を使ってディスクをマウントできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml218(para) msgid """" ""If you access or view the user's content and data, get their approval first!"" msgstr ""ユーザーのコンテンツやデータにアクセスしたり表示したりする場合は、まず承認をもらってください!"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml221(para) msgid """" ""To access the instance's disk (/var/lib/nova/instances/instance-"" ""xxxxxx/disk), the following steps must be followed:"" msgstr ""インスタンスのディスク (/var/lib/nova/instances/instance-xxxxxx/disk) にアクセスするには、以下の手順に従う必要があります:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml226(para) msgid ""Suspend the instance using the virsh command"" msgstr ""virsh コマンドを使用してインスタンスをサスペンドします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml230(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml271(para) msgid ""Connect the qemu-nbd device to the disk"" msgstr ""qemu-nbd デバイスをディスクに接続します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml234(para) msgid ""Mount the qemu-nbd device"" msgstr ""qemu-nbd デバイスをマウントします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml237(para) msgid ""Unmount the device after inspecting"" msgstr ""デバイスを調査後、アンマウントします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml240(para) msgid ""Disconnect the qemu-nbd device"" msgstr ""qemu-nbd デバイスを切断します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml243(para) msgid ""Resume the instance"" msgstr ""インスタンスを再開します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml246(para) msgid """" ""If you do not follow the steps from 4-6, OpenStack Compute cannot manage the"" "" instance any longer. It fails to respond to any command issued by OpenStack"" "" Compute and it is marked as shutdown."" msgstr ""手順 4-6 を省略すると、OpenStack Compute がインスタンスを管理できなくなります。OpenStack Compute により発行されるすべてのコマンドに対する応答が失敗し、シャットダウンしているように見えます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml250(para) msgid """" ""Once you mount the disk file, you should be able access it and treat it as "" ""normal directories with files and a directory structure. However, we do not "" ""recommend that you edit or touch any files because this could change the "" ""acls and make the instance unbootable if it is not already."" msgstr ""ディスクファイルをマウントすると、それにアクセスでき、ファイルとディレクトリ構造を持つ通常のディレクトリのように取り扱えます。しかしながら、どのファイルの編集も操作もしないことをお薦めします。なぜなら、それにより ACL が変更されたり、起動できるインスタンスが起動できなくなってします場合があるからです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml258(para) msgid """" ""Suspend the instance using the virsh command - taking note of the internal "" ""ID."" msgstr ""virsh コマンドを使用してインスタンスを一時停止します - 内部 ID を記録します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml282(para) msgid ""Mount the qemu-nbd device."" msgstr ""qemu-nbd デバイスをマウントします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml283(para) msgid """" ""The qemu-nbd device tries to export the instance disk's different partitions"" "" as separate devices. For example if vda as the disk and vda1 as the root "" ""partition, qemu-nbd exports the device as /dev/nbd0 and /dev/nbd0p1 "" ""respectively."" msgstr ""qemu-nbd デバイスはインスタンスのディスクの個々のパーティションを別々のデバイスとしてエクスポートしようとします。たとえば、ディスクが vda で、ルートパーティションが vda1 の場合、qemu-nbd はそれぞれ /dev/nbd0 と /dev/nbd0p1 としてデバイスをエクスポートします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml293(para) msgid """" ""To examine the secondary or ephemeral disk, use an alternate mount point if "" ""you want both primary and secondary drives mounted at the same time."" msgstr ""セカンダリディスクや一時ディスクを調査する際に、プライマリディスクとセカンダリディスクを同時にマウントしたければ、別のマウントポイントを使用してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml324(para) msgid """" ""Once you have completed the inspection, umount the mount point and release "" ""the qemu-nbd device"" msgstr ""調査を完了すると、マウントポイントをアンマウントし、qemu-nbd デバイスを解放します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml332(para) msgid ""Resume the instance using virsh"" msgstr ""virsh を使用してインスタンスを再開します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml347(title) msgid ""Volumes"" msgstr ""ボリューム"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml348(para) msgid """" ""If the affected instances also had attached volumes, first generate a list "" ""of instance and volume UUIDs:"" msgstr ""影響のあったインスタンスがボリュームを接続していれば、まずインスタンスとボリュームの UUID 一覧を生成します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml355(para) msgid ""You should see a result like the following:"" msgstr ""以下のような結果を確認できます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml362(para) msgid ""Next, manually detach and reattach the volumes:"" msgstr ""次に、ボリュームを手動で切断し、再接続します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml366(para) msgid """" ""Where X is the proper mount point. Make sure that the instance has "" ""successfully booted and is at a login screen before doing the above."" msgstr ""ここで、X には適切なマウントポイントを指定します。上記を実行する前に、インスタンスが正常に起動し、ログイン画面になっていることを確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml372(title) msgid ""Total Compute Node Failure"" msgstr ""コンピュートノード全体の故障"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml373(para) msgid """" ""If a compute node fails and won't be fixed for a few hours or ever, you can "" ""relaunch all instances that are hosted on the failed node if you use shared "" ""storage for <code>/var/lib/nova/instances</code>."" msgstr ""コンピュートノードが故障し、2〜3時間もしくはそれ以上たっても復旧できないと見込まれる場合、<code>/var/lib/nova/instances</code> に共有ストレージを使用していれば、故障したノードで動作していたインスタンスをすべて再スタートすることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml377(para) msgid """" ""To do this, generate a list of instance UUIDs that are hosted on the failed "" ""node by running the following query on the nova database:"" msgstr ""これを実行するために、nova データベースにおいて以下のクエリーを実行することにより、故障したノードにおいてホストされているインスタンスの UUID の一覧を生成します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml381(para) msgid """" ""Next, tell Nova that all instances that used to be hosted on c01.example.com"" "" are now hosted on c02.example.com:"" msgstr ""次に、c01.example.com においてホストされていたすべてのインスタンスが、今度は c02.example.com でホストされることを Nova に教えます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml385(para) msgid """" ""After that, use the nova command to reboot all instances that were on "" ""c01.example.com while regenerating their XML files at the same time:"" msgstr ""その後、nova コマンドを使って、c01.example.com にあったすべてのインスタンスを再起動します。起動する際にインスタンスの XML ファイルを再生成します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml389(para) msgid """" ""Finally, re-attach volumes using the same method described in <emphasis "" ""role=\""bold\"">After a compute node Reboots</emphasis>."" msgstr ""最後に、<emphasis role=\""bold\"">コンピュートノードの再起動後</emphasis> に説明されているのと同じ方法を用いて、ボリュームを再接続します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml395(title) msgid ""/var/lib/nova/instances"" msgstr ""/var/lib/nova/instances"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml396(para) msgid """" ""It's worth mentioning this directory in the context of failed compute nodes."" "" This directory contains the libvirt KVM file-based disk images for the "" ""instances that are hosted on that compute node. If you are not running your "" ""cloud in a shared storage environment, this directory is unique across all "" ""compute nodes."" msgstr ""コンピュートノードの故障の話題に関連して、このディレクトリについては説明しておく価値があるでしょう。このディレクトリには、コンピュートノードにホストされているインスタンス用の libvirt KVM のファイル形式のディスクイメージが置かれます。共有ストレージ環境でクラウドを実行していなければ、このディレクトリはコンピュートノード全体で一つしかありません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml403(para) msgid """" ""<code>/var/lib/nova/instances</code> contains two types of directories."" msgstr ""<code>/var/lib/nova/instances</code> には 2 種類のディレクトリがあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml406(para) msgid """" ""The first is the <code>_base</code> directory. This contains all of the "" ""cached base images from glance for each unique image that has been launched "" ""on that compute node. Files ending in <code>_20</code> (or a different "" ""number) are the ephemeral base images."" msgstr ""一つ目は <code>_base</code> ディレクトリです。ここには、そのコンピュートノードで起動されたそれぞれのイメージに関して、glance から取得したすべてのベースイメージのキャッシュが置かれます。<code>_20</code> (または他の番号) で終わるファイルは一時ディスクのベースイメージです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml412(para) msgid """" ""The other directories are titled <code>instance-xxxxxxxx</code>. These "" ""directories correspond to instances running on that compute node. The files "" ""inside are related to one of the files in the <code>_base</code> directory. "" ""They're essentially differential-based files containing only the changes "" ""made from the original <code>_base</code> directory."" msgstr ""もう一つのディレクトリは <code>instance-xxxxxxxx</code> という名前です。これらのディレクトリはコンピュートノードにおいて実行中のインスタンスと対応します。中にあるファイルは <code>_base</code> ディレクトリにあるファイルのどれかと関連があります。これらは基本的に、元々の <code>_base</code> ディレクトリからの変更点のみ含む、差分ベースのファイルです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml420(para) msgid """" ""All files and directories in <code>/var/lib/nova/instances</code> are "" ""uniquely named. The files in _base are uniquely titled for the glance image "" ""that they are based on and the directory names <code>instance-"" ""xxxxxxxx</code> are uniquely titled for that particular instance. For "" ""example, if you copy all data from <code>/var/lib/nova/instances</code> on "" ""one compute node to another, you do not overwrite any files or cause any "" ""damage to images that have the same unique name, because they are "" ""essentially the same file."" msgstr ""<code>/var/lib/nova/instances</code> にあるすべてのファイルとディレクトリは一意に名前が付けられています。_base にあるファイルは元となった glance イメージに対応する一意に名前が付けられています。また、<code>instance-xxxxxxxx</code> という名前が付けられたディレクトリは特定のインスタンスに対して一意にタイトルが付けられています。たとえば、あるコンピュートノードにある <code>/var/lib/nova/instances</code> のすべてのデータを他のノードにコピーしたとしても、ファイルを上書きすることはありませんし、また同じ一意な名前を持つイメージにダメージを与えることもありません。同じ一意な名前を持つものは本質的に同じファイルだからです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml432(para) msgid """" ""Although this method is not documented or supported, you can use it when "" ""your compute node is permanently offline but you have instances locally "" ""stored on it."" msgstr ""この方法はドキュメントに書かれておらず、サポートされていない方法ですが、コンピュートノードが完全にオフラインになってしまったが、インスタンスがローカルに保存されているときに、この方法を使用できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml440(title) msgid ""Storage Node Failures and Maintenance"" msgstr ""ストレージノードの故障とメンテナンス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml441(para) msgid """" ""Due to the Object Storage's high redundancy, dealing with object storage "" ""node issues is a lot easier than dealing with compute node issues."" msgstr ""オブジェクトストレージの高い冗長性のため、オブジェクトストレージのノードに関する問題を処理することは、コンピュートノードに関する問題を処理するよりも簡単です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml446(title) msgid ""Rebooting a Storage Node"" msgstr ""ストレージノードの再起動"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml447(para) msgid """" ""If a storage node requires a reboot, simply reboot it. Requests for data "" ""hosted on that node are redirected to other copies while the server is "" ""rebooting."" msgstr ""ストレージノードの再起動が必要ならば、単に再起動します。そのノードにホストされているデータに対する要求は、サーバーが再起動している間、他のコピーに転送されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml454(title) msgid ""Shutting Down a Storage Node"" msgstr ""ストレージノードのシャットダウン"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml455(para) msgid """" ""If you need to shut down a storage node for an extended period of time (1+ "" ""days), consider removing the node from the storage ring. For example:"" msgstr ""ストレージノードを少し長い間 (1 日以上) シャットダウンする必要があれば、ノードをストレージリングから削除することを検討します。例:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml464(para) msgid ""Next, redistribute the ring files to the other nodes:"" msgstr ""次に、ring ファイルを他のノードに再配布します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml470(para) msgid """" ""These actions effectively take the storage node out of the storage cluster."" msgstr ""これらの操作はストレージノードをストレージクラスターから効率的に外せます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml472(para) msgid """" ""When the node is able to rejoin the cluster, just add it back to the ring. "" ""The exact syntax to add a node to your Swift cluster using <code>swift-ring-"" ""builder</code> heavily depends on the original options used when you "" ""originally created your cluster. Please refer back to those commands."" msgstr ""ノードがクラスターに参加できるようになったら、ただリングに再度追加するだけです。<code>swift-ring-builder</code> を使用して Swift クラスターにノードを追加するための構文は、元々クラスターを作成したときに使用した元々のオプションに強く依存します。作成時に使用したコマンドをもう一度見てください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml482(title) msgid ""Replacing a Swift Disk"" msgstr ""Swift ディスクの交換"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml483(para) msgid """" ""If a hard drive fails in a Object Storage node, replacing it is relatively "" ""easy. This assumes that your Object Storage environment is configured "" ""correctly where the data that is stored on the failed drive is also "" ""replicated to other drives in the Object Storage environment."" msgstr ""Object Storage ノードのハードディスクが故障した場合、その交換は比較的簡単です。Object Storage 環境が正しく設定され、故障したディスクに保存されているデータが Object Storage 環境内の他のディスクにも複製されていることを前提にしています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml489(para) msgid ""This example assumes that <code>/dev/sdb</code> has failed."" msgstr ""この例では、<code>/dev/sdb</code> が故障したと仮定します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml491(para) msgid ""First, unmount the disk:"" msgstr ""まず、ディスクをアンマウントします:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml493(para) msgid """" ""Next, physically remove the disk from the server and replace it with a "" ""working disk."" msgstr ""次に、ディスクを物理的にサーバーから取り外し、正常なディスクと入れ替えます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml495(para) msgid ""Ensure that the operating system has recognized the new disk:"" msgstr ""オペレーティングシステムが新しいディスクを認識していることを確認します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml498(para) msgid ""You should see a message about /dev/sdb."" msgstr ""/dev/sdb に関するメッセージを確認したほうがいいです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml499(para) msgid """" ""Because it is recommended to not use partitions on a swift disk, simply "" ""format the disk as a whole:"" msgstr ""Swift ディスクではパーティションを使用しないことが推奨されるので、単にディスク全体をフォーマットします:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml502(para) msgid ""Finally, mount the disk:"" msgstr ""最後に、ディスクをマウントします:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml504(para) msgid """" ""Swift should notice the new disk and that no data exists. It then begins "" ""replicating the data to the disk from the other existing replicas."" msgstr ""Swift は新しいディスクを認識します。また、データが存在しないことを認識します。そうすると、他の既存の複製からディスクにデータを複製しはじめます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml511(title) msgid ""Handling a Complete Failure"" msgstr ""完全な故障の対処"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml512(para) msgid """" ""A common way of dealing with the recovery from a full system failure, such "" ""as a power outage of a data center is to assign each service a priority, and"" "" restore in order."" msgstr ""データセンターの電力消失のような、完全なシステム故障から復旧する一般的な方法は、各サービスに優先度を付け、順番に復旧することです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml517(caption) msgid ""Example Service Restoration Priority List"" msgstr ""サービス復旧優先度一覧の例"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml524(para) msgid ""Internal network connectivity"" msgstr ""内部ネットワーク接続性"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml531(para) msgid ""Backing storage services"" msgstr ""バックエンドのストレージサービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml536(para) msgid ""3"" msgstr ""3"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml538(para) msgid ""Public network connectivity for user Virtual Machines"" msgstr ""ユーザーの仮想マシンに対するパブリックネットワーク接続性"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml545(para) msgid ""Nova-compute, nova-network, cinder hosts"" msgstr ""nova-compute, nova-network, cinder ホスト"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml550(para) msgid ""5"" msgstr ""5"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml552(para) msgid ""User virtual machines"" msgstr ""ユーザーの仮想マシン"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml556(para) msgid ""10"" msgstr ""10"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml558(para) msgid ""Message Queue and Database services"" msgstr ""メッセージキューとデータベースのサービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml563(para) msgid ""15"" msgstr ""15"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml565(para) msgid ""Keystone services"" msgstr ""Keystone サービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml569(para) msgid ""20"" msgstr ""20"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml571(para) msgid ""cinder-scheduler"" msgstr ""cinder-scheduler"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml575(para) msgid ""21"" msgstr ""21"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml577(para) msgid ""Image Catalogue and Delivery services"" msgstr ""イメージカタログとイメージ配信のサービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml582(para) msgid ""22"" msgstr ""22"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml584(para) msgid ""nova-scheduler services"" msgstr ""nova-scheduler サービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml588(para) msgid ""98"" msgstr ""98"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml590(para) msgid ""Cinder-api"" msgstr ""cinder-api"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml594(para) msgid ""99"" msgstr ""99"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml596(para) msgid ""Nova-api services"" msgstr ""nova-api サービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml600(para) msgid ""100"" msgstr ""100"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml602(para) msgid ""Dashboard node"" msgstr ""ダッシュボードサービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml606(para) msgid """" ""Use this example priority list to ensure that user affected services are "" ""restored as soon as possible, but not before a stable environment is in "" ""place. Of course, despite being listed as a single line item, each step "" ""requires significant work. For example, just after starting the database, "" ""you should check its integrity or, after starting the Nova services, you "" ""should verify that the hypervisor matches the database and fix any "" ""mismatches."" msgstr ""この例にある優先度一覧を使用すると、きちんと安定した状態になる前であっても、できる限り早くユーザーに影響するサービスを復旧させることができます。もちろん、1 行の項目として一覧化されていますが、各ステップは多大な作業が必要です。たとえば、データベースを開始した後、その完全性を確認すべきです。また、Nova サービスを開始した後、ハイパーバイザーがデータベースに一致しているかを確認し、不一致があれば修正すべきです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml618(title) msgid ""Configuration Management"" msgstr ""構成管理"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml619(para) msgid """" ""Maintaining an OpenStack cloud requires that you manage multiple physical "" ""servers, and this number might grow over time. Because managing nodes "" ""manually is error-prone, we strongly recommend that you use a configuration "" ""management tool. These tools automate the process of ensuring that all of "" ""your nodes are configured properly and encourage you to maintain your "" ""configuration information (such as packages and configuration options) in a "" ""version controlled repository."" msgstr ""OpenStack クラウドをメンテナンスするには、複数の物理サーバーを管理することが必要です。そして、この数は日々増えていきます。ノードを手動で管理することはエラーを起こしやすいので、構成管理ツールを使用することを強く推奨します。これらのツールはすべてのノードが適切に設定されていることを保証するプロセスを自動化します。また、これらを使うことで、(パッケージや設定オプションといった) 構成情報のバージョン管理されたリポジトリでの管理が行いやすくなります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml628(para) msgid """" ""Several configuration management tools are available, and this guide does "" ""not recommend a specific one. The two most popular ones in the OpenStack "" ""community are <link xlink:href=\""https://puppetlabs.com/\"">Puppet</link> "" ""(https://puppetlabs.com/) with available <link xlink:title=\""Optimization "" ""Overview\"" xlink:href=\""http://github.com/puppetlabs/puppetlabs-"" ""openstack\"">OpenStack Puppet modules</link> (http://github.com/puppetlabs"" ""/puppetlabs-openstack) and <link "" ""xlink:href=\""http://www.opscode.com/chef/\"">Chef</link> (http://opscode.com/chef) "" ""with available <link xlink:href=\""https://github.com/opscode/openstack-chef-"" ""repo\"">OpenStack Chef recipes</link> (https://github.com/opscode/openstack-"" ""chef-repo). Other newer configuration tools include <link "" ""xlink:href=\""https://juju.ubuntu.com/\"">Juju</link> (https://juju.ubuntu.com/) "" ""<link xlink:href=\""http://ansible.cc\"">Ansible</link> (http://ansible.cc) and "" ""<link xlink:href=\""http://saltstack.com/\"">Salt</link> (http://saltstack.com), and"" "" more mature configuration management tools include <link "" ""xlink:href=\""http://cfengine.com/\"">CFEngine</link> (http://cfengine.com) and "" ""<link xlink:href=\""http://bcfg2.org/\"">Bcfg2</link> (http://bcfg2.org)."" msgstr ""いくつかの構成管理ツールがあります。このガイドでは特定のものを推奨しません。OpenStack コミュニティで人気があるものは <link xlink:href=\""https://puppetlabs.com/\"">Puppet</link> (https://puppetlabs.com/) と <link xlink:href=\""http://www.opscode.com/chef/\"">Chef</link> (http://opscode.com/chef) の 2 つで、OpenStack 用の設定集がそれぞれ <link xlink:title=\""Optimization Overview\"" xlink:href=\""http://github.com/puppetlabs/puppetlabs-openstack\"">OpenStack Puppet modules</link> (http://github.com/puppetlabs/puppetlabs-openstack) と <link xlink:href=\""https://github.com/opscode/openstack-chef-repo\"">OpenStack Chef recipes</link> (https://github.com/opscode/openstack-chef-repo) にあります。比較的新しい他のツールとしては、<link xlink:href=\""https://juju.ubuntu.com/\"">Juju</link> (https://juju.ubuntu.com/)、<link xlink:href=\""http://ansible.cc\"">Ansible</link> (http://ansible.cc) や <link xlink:href=\""http://saltstack.com/\"">Salt</link> (http://saltstack.com) があります。もう少し成熟したツールとしては <link xlink:href=\""http://cfengine.com/\"">CFEngine</link> (http://cfengine.com) や <link xlink:href=\""http://bcfg2.org/\"">Bcfg2</link> (http://bcfg2.org) があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml658(title) msgid ""Working with Hardware"" msgstr ""ハードウェアの取り扱い"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml659(para) msgid """" ""Similar to your initial deployment, you should ensure all hardware is "" ""appropriately burned in before adding it to production. Run software that "" ""uses the hardware to its limits - maxing out RAM, CPU, disk and network. "" ""Many options are available, and normally double as benchmark software so you"" "" also get a good idea of the performance of your system."" msgstr ""初期導入時と同じように、本番環境に追加する前に、すべてのハードウェアについて適切な通電テストを行うべきでしょう。ハードウェアを限界まで使用するソフトウェアを実行します。RAM、CPU、ディスク、ネットワークを限界まで使用します。多くのオプションが利用可能であり、通常はベンチマークソフトウェアとの役割も果たします。そのため、システムのパフォーマンスに関する良いアイディアを得ることもできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml668(title) msgid ""Adding a Compute Node"" msgstr ""コンピュートノードの追加"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml669(para) msgid """" ""If you find that you have reached or are reaching the capacity limit of your"" "" computing resources, you should plan to add additional compute nodes. "" ""Adding more nodes is quite easy. The process for adding nodes is the same as"" "" when the initial compute nodes were deployed to your cloud: use an "" ""automated deployment system to bootstrap the bare-metal server with the "" ""operating system and then have a configuration management system install and"" "" configure the OpenStack Compute service. Once the Compute service has been "" ""installed and configured in the same way as the other compute nodes, it "" ""automatically attaches itself to the cloud. The cloud controller notices the"" "" new node(s) and begin scheduling instances to launch there."" msgstr ""コンピューティングリソースのキャパシティ限界に達した、または達しそうとわかれば、さらなるコンピュートノードの追加を計画すべきです。さらなるノードを追加することは簡単です。ノードを追加する手順は、最初にコンピュートノードをクラウドに導入したときと同じです。自動配備システムを使ってベアメタルサーバーにオペレーティングシステムのインストールと起動を行い、次に構成管理システムによりOpenStack Compute サービスのインストールと設定を行います。他のコンピュートノードと同じ方法で Compute サービスのインストールと設定が終わると、自動的にクラウドに接続されます。クラウドコントローラーが新しいノードを検知し、そこにインスタンスを起動するようスケジュールし始めます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml683(para) msgid """" ""If your OpenStack Block Storage nodes are separate from your compute nodes, "" ""the same procedure still applies as the same queuing and polling system is "" ""used in both services."" msgstr ""OpenStack ブロックストレージノードがコンピュートノードから分離いる場合、同じキュー管理とポーリングのシステムが両方のサービスで使用されるので、同じ手順が適用できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml687(para) msgid """" ""We recommend that you use the same hardware for new compute and block "" ""storage nodes. At the very least, ensure that the CPUs are similar in the "" ""compute nodes to not break live migration."" msgstr ""新しいコンピュートノードとブロックストレージノードには、同じハードウェアを使用することを推奨します。最低限、ライブマイグレーションが失敗しないように、コンピュートノードでは CPU は同様のものにしてください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml694(title) msgid ""Adding an Object Storage Node"" msgstr ""オブジェクトストレージノードの追加"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml695(para) msgid """" ""Adding a new object storage node is different than adding compute or block "" ""storage nodes. You still want to initially configure the server by using "" ""your automated deployment and configuration management systems. After that "" ""is done, you need to add the local disks of the object storage node into the"" "" object storage ring. The exact command to do this is the same command that "" ""was used to add the initial disks to the ring. Simply re-run this command on"" "" the object storage proxy server for all disks on the new object storage "" ""node. Once this has been done, rebalance the ring and copy the resulting "" ""ring files to the other storage nodes."" msgstr ""新しいオブジェクトストレージノードの追加は、コンピュートノードやブロックストレージノードの追加とは異なります。サーバーの設定は、これまで通り自動配備システムと構成管理システムを使って行えます。完了した後、オブジェクトストレージノードのローカルディスクをオブジェクトストレージリングに追加する必要があります。これを実行するコマンドは、最初にディスクをリングに追加するのに使用したコマンドと全く同じです。オブジェクトストレージプロキシサーバーにおいて、このコマンドを、新しいオブジェクトストレージノードにあるすべてのディスクに対して、再実行するだけです。これが終わったら、リングの再バランスを行い、更新されたリングファイルを他のストレージノードにコピーします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml709(para) msgid """" ""If your new object storage node has a different number of disks than the "" ""original nodes have, the command to add the new node is different than the "" ""original commands. These parameters vary from environment to environment."" msgstr ""新しいオブジェクトストレージノードのディスク数が元々のノードのディスク数と異なる場合には、新しいノードを追加するコマンドが元々のコマンドと異なります。これらのパラメーターは環境により異なります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml718(title) msgid ""Replacing Components"" msgstr ""コンポーネントの交換"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml719(para) msgid """" ""Failures of hardware are common in large scale deployments such as an "" ""infrastructure cloud. Consider your processes and balance time saving "" ""against availability. For example, an Object Storage cluster can easily live"" "" with dead disks in it for some period of time if it has sufficient "" ""capacity. Or, if your compute installation is not full you could consider "" ""live migrating instances off a host with a RAM failure until you have time "" ""to deal with the problem."" msgstr ""クラウドインフラなどの大規模環境では、ハードウェアの故障はよくあることです。作業内容を考慮し、可用性と時間の節約のバランスを取ります。たとえば、オブジェクトストレージクラスターは、十分な容量がある場合には、ある程度の期間は死んだディスクがあっても問題なく動作します。また、(クラウド内の) コンピュートノードに空きがある場合には、問題に対処する時間が取れるまで、ライブマイグレーションで RAM が故障したホストから他のホストへインスタンスを移動させることも考慮するとよいでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml732(title) msgid ""Databases"" msgstr ""データベース"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml733(para) msgid """" ""Almost all OpenStack components have an underlying database to store "" ""persistent information. Usually this database is MySQL. Normal MySQL "" ""administration is applicable to these databases. OpenStack does not "" ""configure the databases out of the ordinary. Basic administration includes "" ""performance tweaking, high availability, backup, recovery, and repairing. "" ""For more information, see a standard MySQL administration guide."" msgstr ""ほとんどすべての OpenStack コンポーネントは、永続的な情報を保存するために内部でデータベースを使用しています。このデータベースは通常 MySQL です。通常の MySQL の管理方法がこれらのデータベースに適用できます。OpenStack は特別な方法でデータベースを設定しているわけではありません。基本的な管理として、パフォーマンス調整、高可用性、バックアップ、リカバリーおよび修理などがあります。さらなる情報は標準の MySQL 管理ガイドを参照してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml742(para) msgid """" ""You can perform a couple tricks with the database to either more quickly "" ""retrieve information or fix a data inconsistency error. For example, an "" ""instance was terminated but the status was not updated in the database. "" ""These tricks are discussed throughout this book."" msgstr ""より迅速に情報を取得したり、データ不整合のエラーを修正したりするために、データベースでいくつかの小技を実行できます。たとえば、インスタンスが終了していたが、データベースの状態が更新されていなかった、という状況です。こうした小技がこのドキュメント全体を通して議論されています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml749(title) msgid ""Database Connectivity"" msgstr ""データベース接続性"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml750(para) msgid """" ""Review the components configuration file to see how each OpenStack component"" "" accesses its corresponding database. Look for either "" ""<code>sql_connection</code> or simply <code>connection</code>:"" msgstr ""コンポーネントの設定ファイルを確認して、それぞれの OpenStack コンポーネントが対応するデータベースにどのようにアクセスするかを把握ください。<code>sql_connection</code> またはただの <code>connection</code> を探します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml761(para) msgid ""The connection strings take this format:"" msgstr ""connection 文字列は以下の形式をとります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml766(title) msgid ""Performance and Optimizing"" msgstr ""パフォーマンスと最適化"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml767(para) msgid """" ""As your cloud grows, MySQL is utilized more and more. If you suspect that "" ""MySQL might be becoming a bottleneck, you should start researching MySQL "" ""optimization. The MySQL manual has an entire section dedicated to this topic"" "" <link xlink:href=\""http://dev.mysql.com/doc/refman/5.5/en/optimize-"" ""overview.html\"">Optimization Overview</link> "" ""(http://dev.mysql.com/doc/refman/5.5/en/optimize-overview.html)."" msgstr ""クラウドが大きくなるにつれて、MySQL がさらに使用されてきます。MySQL がボトルネックになってきたことが疑われる場合、MySQL 最適化の調査から始めるとよいでしょう。MySQL のマニュアルでは、<link xlink:href=\""http://dev.mysql.com/doc/refman/5.5/en/optimize-overview.html\"">Optimization Overview</link> (http://dev.mysql.com/doc/refman/5.5/en/optimize-overview.html) というセクションがあり、一つのセクション全部をあててこの話題を扱っています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml779(title) msgid ""HDWMY"" msgstr ""HDWMY"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml780(para) msgid """" ""Here's a quick list of various to-do items each hour, day, week, month, and "" ""year. Please note these tasks are neither required nor definitive, but "" ""helpful ideas:"" msgstr ""これらは、毎時間、日、週、月および年に実行する To Do 項目の簡単な一覧です。これらのタスクは必要なものでも、絶対的なものでもありませんが、役に立つものばかりです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml785(title) msgid ""Hourly"" msgstr ""毎時"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml788(para) msgid ""Check your monitoring system for alerts and act on them."" msgstr ""監視システムのアラートを確認し、それらに対処します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml792(para) msgid ""Check your ticket queue for new tickets."" msgstr ""チケットキューの新しいチケットを確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml799(title) msgid ""Daily"" msgstr ""日次"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml802(para) msgid ""Check for instances in a failed or weird state and investigate why."" msgstr ""故障または異常になっているインスタンスを確認し、理由を調査します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml806(para) msgid ""Check for security patches and apply them as needed."" msgstr ""セキュリティパッチを確認し、必要に応じて適用します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml813(title) msgid ""Weekly"" msgstr ""週次"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml818(para) msgid ""User quotas"" msgstr ""ユーザークォータ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml821(para) msgid ""Disk space"" msgstr ""ディスク領域"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml824(para) msgid ""Image usage"" msgstr ""イメージ使用量"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml827(para) msgid ""Large instances"" msgstr ""大きなインスタンス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml830(para) msgid ""Network usage (bandwidth and IP usage)"" msgstr ""ネットワーク使用量 (帯域および IP 使用量)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml816(para) msgid ""Check cloud usage: <placeholder-1/>"" msgstr ""クラウドの使用量を確認します: <placeholder-1/>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml836(para) msgid ""Verify your alert mechanisms are still working."" msgstr ""アラート機能が動作していることを確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml843(title) msgid ""Monthly"" msgstr ""月次"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml846(para) msgid ""Check usage and trends over the past month."" msgstr ""この 1 か月における使用量および傾向を確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml850(para) msgid ""Check for user accounts that should be removed."" msgstr ""削除すべきユーザーアカウントを確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml854(para) msgid ""Check for operator accounts that should be removed."" msgstr ""削除すべきオペレーターアカウントを確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml861(title) msgid ""Quarterly"" msgstr ""四半期ごと"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml864(para) msgid ""Review usage and trends over the past quarter."" msgstr ""この四半期における使用量および傾向を確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml868(para) msgid ""Prepare any quarterly reports on usage and statistics."" msgstr ""使用量と統計に関する四半期レポートを準備します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml872(para) msgid ""Review and plan any necessary cloud additions."" msgstr ""クラウドの追加の必要性を検討し、計画を立てます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml876(para) msgid ""Review and plan any major OpenStack upgrades."" msgstr ""OpenStack のメジャーアップグレードの内容を確認し、その計画を立てます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml883(title) msgid ""Semi-Annually"" msgstr ""半年ごと"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml886(para) msgid ""Upgrade OpenStack."" msgstr ""OpenStack をアップグレードします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml889(para) msgid """" ""Clean up after OpenStack upgrade (any unused or new services to be aware "" ""of?)"" msgstr ""OpenStack のアップグレード後に後始末を行います (未使用または新しいサービスを把握していますか?)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml897(title) msgid ""Determining which Component Is Broken"" msgstr ""故障しているコンポーネントの特定"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml898(para) msgid """" ""OpenStack's collection of different components interact with each other "" ""strongly. For example, uploading an image requires interaction from <code"" "">nova-api</code>, <code>glance-api</code>, <code>glance-registry</code>, "" ""Keystone, and potentially <code>swift-proxy</code>. As a result, it is "" ""sometimes difficult to determine exactly where problems lie. Assisting in "" ""this is the purpose of this section."" msgstr ""OpenStack は、異なるコンポーネント同士が互いに強く連携して動作しています。たとえば、イメージのアップロードでは、<code>nova-api</code>, <code>glance-api</code>, <code>glance-registry</code>, Keystone が連携する必要があります。 <code>swift-proxy</code> も関係する場合があります。その結果、時として問題が発生している箇所を正確に特定することが難しくなります。これを支援することがこのセクションの目的です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml908(title) msgid ""Tailing Logs"" msgstr ""最新ログの確認"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml909(para) msgid """" ""The first place to look is the log file related to the command you are "" ""trying to run. For example, if <code>nova list</code> is failing, try "" ""tailing a Nova log file and running the command again:"" msgstr ""最初に確認する場所は、実行しようとしているコマンドに関連するログファイルです。たとえば、<code>nova list</code> が失敗していれば、Nova ログファイルを tail 表示しながら、次のコマンドを再実行してください:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml913(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml925(para) msgid ""Terminal 1:"" msgstr ""端末 1:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml915(para) #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml927(para) msgid ""Terminal 2:"" msgstr ""端末 2:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml917(para) msgid """" ""Look for any errors or traces in the log file. For more information, see the"" "" chapter on <emphasis role=\""bold\"">Logging and Monitoring</emphasis>."" msgstr ""何らかのエラーまたはトレースをログファイルで探します。詳細は <emphasis role=\""bold\"">ロギングとモニタリング</emphasis> の章を参照してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml921(para) msgid """" ""If the error indicates that the problem is with another component, switch to"" "" tailing that component's log file. For example, if nova cannot access "" ""glance, look at the glance-api log:"" msgstr ""エラーから問題が他のコンポーネントにあることが分かる場合には、そのコンポーネントのログファイルに表示を切り替えます。nova が glance にアクセスできなければ、glance-api ログを確認します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml929(para) msgid ""Wash, rinse, repeat until you find the core cause of the problem."" msgstr ""問題の根本となる原因を見つけるまで、洗い出し、精査し、繰り返します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml935(title) msgid ""Running Daemons on the CLI"" msgstr ""コマンドラインでのデーモンの実行"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml936(para) msgid """" ""Unfortunately, sometimes the error is not apparent from the log files. In "" ""this case, switch tactics and use a different command, maybe run the service"" "" directly on the command line. For example, if the <code>glance-api</code> "" ""service refuses to start and stay running, try launching the daemon from the"" "" command line:"" msgstr ""残念ながら、ときどきエラーがログファイルに表れない場合があります。このような場合、作戦を変更し、違うコマンドを使用します。おそらくコマンドラインにおいて直接サービスを実行することです。たとえば、<code>glance-api</code> サービスが起動しなかったり、実行状態にとどまらない場合は、コマンドラインからデーモンを起動してみます:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml945(para) msgid """" ""The <literal>-H</literal> flag is required when running the daemons with "" ""sudo because some daemons will write files relative to the user's home "" ""directory, and this write may fail if <literal>-H</literal> is left off."" msgstr ""sudo を用いてデーモンを実行するとき、<literal>-H</literal> フラグが必要です。いくつかのデーモンは、ユーザーのホームディレクトリーからの相対パスのファイルに書き込みを行うため、<literal>-H</literal> がないと、この書き込みが失敗してしまいます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml944(para) msgid ""This might print the error and cause of the problem.<placeholder-1/>"" msgstr ""これにより、エラーと問題の原因が表示されるかもしれません。 <placeholder-1/>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml954(title) msgid ""Example of Complexity"" msgstr ""複雑な例"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml955(para) msgid """" ""One morning, a compute node failed to run any instances. The log files were "" ""a bit vague, claiming that a certain instance was unable to be started. This"" "" ended up being a red herring because the instance was simply the first "" ""instance in alphabetical order, so it was the first instance that nova-"" ""compute would touch."" msgstr ""ある朝、あるノードでインスタンスの実行がすべて失敗するようになりました。ログファイルがすこしあいまいでした。特定のインスタンスが起動できなかったことを示していました。これは最終的に偽の手掛かりであることがわかりました。単にそのインスタンスがアルファベット順で最初のインスタンスだったので、nova-compute が最初に操作したのがそのインスタンスだったというだけでした。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml961(para) msgid """" ""Further troubleshooting showed that libvirt was not running at all. This "" ""made more sense. If libvirt wasn't running, then no instance could be "" ""virtualized through KVM. Upon trying to start libvirt, it would silently die"" "" immediately. The libvirt logs did not explain why."" msgstr ""さらなるトラブルシューティングにより、libvirt がまったく動作していないことがわかりました。これは大きな手がかりです。libvirt が動作していないと、KVM によるインスタンスの仮想化ができません。libvirt を開始させようとしても、libvirt は何も表示せずすぐに停止しました。libvirt のログでは理由がわかりませんでした。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml967(para) msgid """" ""Next, the <code>libvirtd</code> daemon was run on the command line. Finally "" ""a helpful error message: it could not connect to d-bus. As ridiculous as it "" ""sounds, libvirt, and thus <code>nova-compute</code>, relies on d-bus and "" ""somehow d-bus crashed. Simply starting d-bus set the entire chain back on "" ""track and soon everything was back up and running."" msgstr ""次に、<code>libvirtd</code> デーモンをコマンドラインにおいて実行しました。最終的に次のような役に立つエラーメッセージが得られました。d-bus に接続できませんでした。このため、滑稽に聞こえるかもしれませんが、libvirt 、その結果として <code>nova-compute</code> も D-Bus に依存していて、どういう訳か D-Bus がクラッシュしました。単に D-Bus を開始するだけで、一連のプログラムがうまく動くようになり、すぐに全部が元に戻り動作状態になりました。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml977(title) msgid ""Upgrades"" msgstr ""アップグレード"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml978(para) msgid """" ""With the exception of Object Storage, an upgrade from one version of "" ""OpenStack to another is a great deal of work."" msgstr ""Object Storage 以外では、OpenStack をあるバージョンから別のバージョンへアップグレードするには、非常に労力を伴います。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml981(para) msgid ""The upgrade process generally follows these steps:"" msgstr ""一般的に、アップグレード作業は以下の手順で行います:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml985(para) msgid ""Read the release notes and documentation."" msgstr ""リリースノートとドキュメントを読みます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml989(para) msgid ""Find incompatibilities between different versions."" msgstr ""異なるバージョン間の非互換性を確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml993(para) msgid ""Plan an upgrade schedule and complete it in order on a test cluster."" msgstr ""アップグレードスケジュールの計画を立て、テストクラスターで手順どおりにアップグレードができることを確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml997(para) msgid ""Run the upgrade."" msgstr ""アップグレードを実行します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1000(para) msgid """" ""You can perform an upgrade while user instances run. However, this strategy "" ""can be dangerous. Don't forget appropriate notice to your users, and "" ""backups."" msgstr ""ユーザーのインスタンスが実行中のまま、アップグレードを実行することができます。しかしながら、この方法は危険です。ユーザーに対する適切な通知を忘れないようにしてください。そして、バックアップも忘れないでください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1003(para) msgid ""The general order that seems to be most successful is:"" msgstr ""最も成功すると考えられる一般的な順番は次のとおりです:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1007(para) msgid ""Upgrade the OpenStack Identity service (keystone)."" msgstr ""OpenStack Identity サービス (keystone) をアップグレードします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1011(para) msgid ""Upgrade the OpenStack Image service (glance)."" msgstr ""OpenStack Image サービス (glance) をアップグレードします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1015(para) msgid ""Upgrade all OpenStack Compute (nova) services."" msgstr ""すべての OpenStack Compute (nova) サービスをアップグレードします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1019(para) msgid ""Upgrade all OpenStack Block Storage (cinder) services."" msgstr ""すべての OpenStack Block Storage (cinder) サービスをアップグレードします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1023(para) msgid ""For each of these steps, complete the following sub-steps:"" msgstr ""これらのステップそれぞれに対して、以下のサブステップを完了します:"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1027(para) msgid ""Stop services."" msgstr ""サービスを停止します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1030(para) msgid ""Create a backup of configuration files and databases."" msgstr ""設定ファイルとデータベースのバックアップを作成します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1034(para) msgid ""Upgrade the packages using your distribution's package manager."" msgstr ""ディストリビューションのパッケージマネージャーを用いてパッケージをアップグレードします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1038(para) msgid ""Update the configuration files according to the release notes."" msgstr ""リリースノートに従って設定ファイルを更新します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1042(para) msgid ""Apply the database upgrades."" msgstr ""データベースのアップグレードを適用します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1045(para) msgid ""Restart the services."" msgstr ""サービスを再起動します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1048(para) msgid ""Verify that everything is running."" msgstr ""すべてが正しく動作することを確認します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1051(para) msgid """" ""Probably the most important step of all is the pre-upgrade testing. "" ""Especially if you are upgrading immediately after release of a new version, "" ""undiscovered bugs might hinder your progress. Some deployers prefer to wait "" ""until the first point release is announced. However, if you have a "" ""significant deployment, you might follow the development and testing of the "" ""release, thereby ensuring that bugs for your use cases are fixed."" msgstr ""おそらく、すべて中で最も大切なステップは事前のアップグレードテストです。とくに新しいバージョンのリリース後すぐにアップグレードする場合、未発見のバグによってアップグレードがうまくいかないこともあるでしょう。管理者によっては、最初のアップデート版が出るまで待つことを選ぶ場合もあります。しかしながら、重要な環境の場合には、リリース版の開発やテストに参加することで、あなたのユースケースでのバグを確実に修正することもできるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_maintenance.xml1060(para) msgid """" ""To complete an upgrade of OpenStack Compute while keeping instances running,"" "" you should be able to use live migration to move machines around while "" ""performing updates, and then move them back afterward as this is a property "" ""of the hypervisor. However, it is critical to ensure that database changes "" ""are successful otherwise an inconsistent cluster state could arise."" msgstr ""インスタンスを実行したまま、OpenStack Compute のアップグレードを行うには、ハイパーバイザーの機能のライブマイグレーションを使って、アップグレードを実行している間はインスタンスを他のマシンに移動し、終わったら元のマシンに戻す方法を取ることができます。しかしながら、データベースの更新を確実に行うことが非常に重要です。さもないと、クラスターが一貫性のない状態になってしまいます。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml14(title) msgid ""Use Cases"" msgstr ""事例"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml15(para) msgid """" ""This section contains a small selection of use cases from the community with"" "" more technical detail than usual. Further examples can be found on the "" ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""https://www.openstack.org/user-"" ""stories/\"">OpenStack Website</link> (https://www.openstack.org/user-"" ""stories/)"" msgstr ""この節ではコミュニティからを事例をいくつか紹介します。これらでは通常より多くの技術的詳細情報が提供されています。他の事例は <link xlink:title=\""OpenStack Website\"" xlink:href=\""https://www.openstack.org/user-stories/\"">OpenStack ウェブサイト</link> (https://www.openstack.org/user-stories/) で探して下さい。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml23(title) msgid ""NeCTAR"" msgstr ""NeCTAR"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml24(para) msgid """" ""Who uses it: Researchers from the Australian publicly funded research "" ""sector. Use is across a wide variety of disciplines, with the purpose of "" ""instances being from running simple web servers to using hundreds of cores "" ""for high throughput computing."" msgstr ""利用者：オーストラリアの公的資金による研究部門からの研究者。用途は、シンプルな Web サーバー用のインスタンスから高スループットコンピューティング用の数百のコア使用まで、多種多様な専門分野に渡ります。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml30(title) #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml86(title) #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml126(title) #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml170(title) msgid ""Deployment"" msgstr ""デプロイ"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml31(para) msgid """" ""Using OpenStack Compute Cells, the NeCTAR Cloud spans eight sites with "" ""approximately 4,000 cores per site."" msgstr ""OpenStack Compute Cells を使用して、NeCTAR クラウドは８サイトに及び、１サイトあたり約4,000コアがあります。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml34(para) msgid """" ""Each site runs a different configuration, as resource "" ""<glossterm>cell</glossterm>s in an OpenStack Compute cells setup. Some sites"" "" span multiple data centers, some use off compute node storage with a shared"" "" file system and some use on compute node storage with a non-shared file "" ""system. Each site deploys the Image Service with an Object Storage back-end."" "" A central Identity Service, Dashboard and Compute API Service is used. "" ""Login to the Dashboard triggers a SAML login with Shibboleth, that creates "" ""an <glossterm>account</glossterm> in the Identity Service with an SQL back-"" ""end."" msgstr ""各サイトは（OpenStack Compute のセル設定におけるリソース<glossterm>セル</glossterm>として）異なる設定で実行されています。数サイトは複数データセンターに渡り、コンピュートノード外のストレージを共有ストレージで使用しているサイトもあれば、コンピュートノード上のストレージを非共有型ファイルシステムで使用しているサイトもあります。各サイトは Object Storage バックエンドを持つ Image Service をデプロイしています。中央の Identity Service、Dashboard、Compute API サービスが使用されています。Dashboard へのログインが Shibboleth の SAML ログインのトリガーになり、SQL バックエンドの Identity サービスの<glossterm>アカウント</glossterm>を作成します。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml46(para) msgid """" ""Compute nodes have 24 to 48 cores, with at least 4 GB of RAM per core and "" ""approximately 40 GB of ephemeral storage per core."" msgstr ""コンピュートノードは 24～48コアがあり、１コアあたり 4GB 以上の RAM があり、１コアあたり約 40GB 以上の一時ストレージがあります。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml49(para) msgid """" ""All sites are based on Ubuntu 12.04 with KVM as the hypervisor. The "" ""OpenStack version in use is typically the current stable version, with 5 to "" ""10% back ported code from trunk and modifications."" msgstr ""全サイトは Ubuntu 12.04 をベースにしており、ハイパーバイザとして KVM を使用しています。使用している OpenStack のバージョンは基本的に安定バージョンであり、5～10%のコードが開発コードからバックポートされたか、修正されています。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml58(para) msgid """" ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""https://www.openstack.org/user-"" ""stories/nectar/\"">OpenStack.org Case Study</link> (https://www.openstack.org"" ""/user-stories/nectar/)"" msgstr ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""https://www.openstack.org/user-stories/nectar/\"">OpenStack.org Case Study</link> (https://www.openstack.org/user-stories/nectar/)"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml65(para) msgid """" ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""https://github.com/NeCTAR-RC"" ""/\"">NeCTAR-RC GitHub</link> (https://github.com/NeCTAR-RC/)"" msgstr ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""https://github.com/NeCTAR-RC/\"">NeCTAR-RC GitHub</link> (https://github.com/NeCTAR-RC/)"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml72(para) msgid """" ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""https://www.nectar.org.au/\"">NeCTAR"" "" Website</link> (https://www.nectar.org.au/)"" msgstr ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""https://www.nectar.org.au/\"">NeCTAR Web サイト</link> (https://www.nectar.org.au/)"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml82(title) msgid ""MIT CSAIL"" msgstr ""MIT CSAIL"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml83(para) msgid """" ""Who uses it: Researchers from the MIT Computer Science and Artificial "" ""Intelligence Lab."" msgstr ""利用者：マサチューセッツ工科大学コンピュータ科学・人工知能研究所の研究者。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml87(para) msgid """" ""The CSAIL cloud is currently 64 physical nodes with a total of 768 physical "" ""cores and 3,456 GB of RAM. Persistent data storage is largely outside of the"" "" cloud on NFS with cloud resources focused on compute resources. There are "" ""65 users in 23 projects with typical capacity utilization nearing 90% we are"" "" looking to expand."" msgstr ""CSAIL クラウドは現在 64 物理ノード、768 物理コア、3,456 GB のメモリがあります。クラウドリソースがコンピュータリソースに焦点をあてているため、永続データストレージの大部分は、クラウド外の NFS 上にあります。現在 65 ユーザと 23 プロジェクトがあり、拡張が期待される約 90% 近くの利用率があります。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml94(para) msgid """" ""The software stack is Ubuntu 12.04 LTS with OpenStack Folsom from the Ubuntu"" "" Cloud Archive. KVM is the hypervisor, deployed using FAI (http://fai-"" ""project.org/) and Puppet for configuration management. The FAI and Puppet "" ""combination is used lab wide, not only for OpenStack. There is a single "" ""cloud controller node, with the remainder of the server hardware dedicated "" ""to compute nodes. Due to the compute intensive nature of the use case, the "" ""ratio of physical CPU and RAM to virtual is 1:1 in nova.conf. Although "" ""hyper-threading is enabled so, given the way Linux counts CPUs, this is "" ""actually 2:1 in practice."" msgstr ""ソフトウェアスタックは Ubuntu 12.04 LTS と Ubuntu Cloud Archive からの OpenStack Folsom です。KVM がハイパーバイザで、FAI(http://fai-project.org/)と Puppet を設定管理に使用してデプロイされています。FAI と Puppet の組み合わせはOpenStack のみならず研究所全体で使用されています。単一のクラウドコントローラーノードがあり、他のコンピュータ・ハードウェアはコンピュートノードに使用されています。用途が計算集約型の為、nova.conf 中の物理 CPU・RAM と仮想 CPU・RAM の比は 1:1 です。しかしながら、ハイパースレッディングが有効であり（Linux がその方式を複数 CPU でカウントする為）実際には通常 2:1 になっています。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml107(para) msgid """" ""On the network side, physical systems have two network interfaces and a "" ""separate management card for IPMI management. The OpenStack network service "" ""uses multi-host networking and the FlatDHCP."" msgstr ""ネットワーク面では、物理システムは２つのネットワーク・インターフェースと、独立したIPMI管理用のマネージメントカードがあります。OpenStack ネットワークサービスはマルチホストネットワーク、FlatDHCP を使用しています。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml115(title) msgid ""DAIR"" msgstr ""DAIR"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml116(para) msgid """" ""Who uses it: DAIR is an integrated virtual environment that leverages the "" ""CANARIE network to develop and test new information communication technology"" "" (ICT) and other digital technologies. It combines such digital "" ""infrastructure as advanced networking, and cloud computing and storage to "" ""create an environment for develop and test of innovative ICT applications, "" ""protocols and services, perform at-scale experimentation for deployment, and"" "" facilitate a faster time to market."" msgstr ""利用者：DAIR は新しい情報通信技術（ICT）と他のデジタル技術を開発・評価するための CANARIE ネットワークを活用した統合仮想環境です。このシステムは、先進的なネットワーク、クラウドコンピューティング、ストレージといったデジタルインフラから構成されており、革新的な ICT アプリケーション、プロトコル、サービス、の開発・評価環境の作成、デプロイのスケールに関する実験の実施、市場へのより早期の投入促進を目的としています。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml127(para) msgid """" ""DAIR is hosted at two different data centres across Canada: one in Alberta "" ""and the other in Quebec. It consists of a cloud controller at each location,"" "" however, one is designated as the \""master\"" controller that is in charge "" ""of central authentication and quotas. This is done through custom scripts "" ""and light modifications to OpenStack. DAIR is currently running Folsom."" msgstr ""DAIR はカナダの2つの異なるデータセンタ（１つはアルバータ州、もう1つはケベック州）でホスティングされています。各拠点にはそれぞれクラウドコントローラがありますが、その１つが「マスター」コントローラーとして、認証とクォータ管理を集中して行うよう設計されています。これは、特製スクリプトと OpenStack の軽微な改造により実現されています。DAIR は現在、Folsom で運営されています。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml135(para) msgid ""For Object Storage, each region has a Swift environment."" msgstr ""オブジェクトストレージ用に、各リージョンには Swift 環境があります。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml137(para) msgid """" ""A NetApp appliance is used in each region for both block storage and "" ""instance storage. There are future plans to move the instances off of the "" ""NetApp appliance and onto a distributed file system such as "" ""<glossterm>Ceph</glossterm> or GlusterFS."" msgstr ""各リージョンでは、ブロックストレージとインスタンスストレージの両方でNetApp アプライアンスが使用されています。これらのインスタンスを NetApp アプライアンスから <glossterm>Ceph</glossterm> または GlusterFS といった分散ファイルシステム上に移動する計画があります。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml142(para) msgid """" ""VlanManager is used extensively for network management. All servers have two"" "" bonded 10gb NICs that are connected to two redundant switches. DAIR is set "" ""up to use single-node networking where the cloud controller is the gateway "" ""for all instances on all compute nodes. Internal OpenStack traffic (for "" ""example, storage traffic) does not go through the cloud controller."" msgstr ""ネットワーク管理は VlanManager が広範囲に使用されています。全てのサーバーは２つの冗長化（bonding）された 10GB NIC があり、２つの独立したスイッチに接続されています。DAIR はクラウドコントローラーが全コンピュートノード上の全インスタンス用のゲートウェイとなる、単一ノードのネットワーキングを使用する設定がされています。内部の OpenStack 通信（例：ストレージ通信）はクラウドコントローラーを経由していません。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml155(para) msgid """" ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""http://www.canarie.ca/en/dair-"" ""program/about\"">DAIR Homepage</link> (http://www.canarie.ca/en/dair-"" ""program/about)"" msgstr ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""http://www.canarie.ca/en/dair-program/about\"">DAIR ホームページ</link> (http://www.canarie.ca/en/dair-program/about)"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml165(title) msgid ""CERN"" msgstr ""CERN"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml166(para) msgid """" ""Who uses it: Researchers at CERN (European Organization for Nuclear "" ""Research) conducting high-energy physics research."" msgstr ""利用者：高エネルギー物理学研究を管理する CERN（欧州原子核共同研究機関）の研究者。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml171(para) msgid """" ""The environment is largely based on Scientific Linux 6, which is Red Hat "" ""compatible. We use KVM as our primary hypervisor although tests are ongoing "" ""with Hyper-V on Windows Server 2008."" msgstr ""この環境は、大部分は Red Hat 互換の Scientific Linux 6 ベースです。主なハイパーバイザとして KVM を使用していますが、一方 Windows Server 2008 上の Hyper-V を使用したテストも進行中です。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml175(para) msgid """" ""We use the Puppet Labs OpenStack modules to configure Compute, Image "" ""Service, Identity Service and Dashboard. Puppet is used widely for instance "" ""configuration and Foreman as a GUI for reporting and instance provisioning."" msgstr ""我々は Compute、Image Service、Identity Service、Dashboard の設定に Puppet Labs のOpenStack モジュールを使用しています。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml180(para) msgid """" ""Users and Groups are managed through Active Directory and imported into the "" ""Identity Service using LDAP. CLIs are available for Nova and Euca2ools to do"" "" this."" msgstr ""ユーザとグループは Active Directory で管理され、LDAP を使用して Identity Service にインポートされます。CLI は nova と euca2ools が使用可能です。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml184(para) msgid """" ""CERN is currently running around 250 Nova Compute nodes with approximately "" ""1,000 instances."" msgstr ""CERN は現在、約 250 台の Nova コンピュートノード上で 約 1,000 インスタンスが 稼働中です。"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml191(para) msgid """" ""<link xlink:title=\""OpenStack Website\"" "" ""xlink:href=\""http://www.slideshare.net/noggin143/20121017-openstack-accelerating-"" ""science\"">San Diego 2012 Summit</link> "" ""(http://www.slideshare.net/noggin143/20121017-openstack-accelerating-"" ""science)"" msgstr ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""http://www.slideshare.net/noggin143/20121017-openstack-accelerating-science\"">San Diego 2012 Summit</link> (http://www.slideshare.net/noggin143/20121017-openstack-accelerating-science)"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml198(para) msgid """" ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""http://cern.ch/go/N8wp\"">Review of "" ""CERN Data Centre Infrastructure</link> (http://cern.ch/go/N8wp)"" msgstr ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""http://cern.ch/go/N8wp\"">Review of CERN Data Centre Infrastructure</link> (http://cern.ch/go/N8wp)"" #: ./doc/src/docbkx/openstack-ops/src/app_usecases.xml205(para) msgid """" ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""http://information-"" ""technology.web.cern.ch/book/cern-private-cloud-user-guide\"">CERN Cloud "" ""Infrastructure User Guide</link> (http://information-"" ""technology.web.cern.ch/book/cern-private-cloud-user-guide)"" msgstr ""<link xlink:title=\""OpenStack Website\"" xlink:href=\""http://information-technology.web.cern.ch/book/cern-private-cloud-user-guide\"">CERN Cloud Infrastructure User Guide</link> (http://information-technology.web.cern.ch/book/cern-private-cloud-user-guide)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml21(title) msgid ""Storage Decisions"" msgstr ""ストレージ選定"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml22(para) msgid """" ""Storage is found in many parts of the OpenStack stack, and the differing "" ""types can cause confusion to even experienced cloud engineers. This section "" ""focuses on persistent storage options you can configure with your cloud."" msgstr ""ストレージは OpenStack スタックの多くの部分に存在し、これらのタイプの違いにより経験豊富なクラウド技術者でさえ混乱する事があります。本章では、あなたのクラウドで設定可能な永続的ストレージに焦点を当てます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml27(title) msgid ""OpenStack Storage Concepts"" msgstr ""ストレージのコンセプト"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml29(caption) msgid ""OpenStack Storage"" msgstr ""OpenStackのストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml34(th) msgid ""Ephemeral storage"" msgstr ""エフェメラルストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml35(th) msgid ""Block storage"" msgstr ""ブロックストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml41(para) msgid ""Used to…"" msgstr ""使用目的"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml42(para) msgid ""Run operating system and scratch space"" msgstr ""OS を起動し、空き領域に記録する"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml44(para) msgid ""Add additional persistent storage to a virtual machine (VM)"" msgstr ""永続的なストレージを仮想マシン（VM）へ追加する"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml46(para) msgid ""Store data, including VM images"" msgstr ""データを保存する（VMイメージも含む）"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml50(para) msgid ""Accessed through…"" msgstr ""アクセス方法"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml51(para) msgid ""A file system"" msgstr ""ファイルシステム"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml52(para) msgid """" ""A <glossterm>block device</glossterm> that can be partitioned, formatted and"" "" mounted (such as, /dev/vdc)"" msgstr ""パーティション作成、フォーマット、マウントされた<glossterm>block device</glossterm>（/dev/vdc など）"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml55(para) msgid ""REST API"" msgstr ""REST API"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml58(para) msgid ""Accessible from…"" msgstr ""アクセス可能な場所"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml59(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml60(para) msgid ""Within a VM"" msgstr ""VM内"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml61(para) msgid ""Anywhere"" msgstr ""どこからでも"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml64(para) msgid ""Managed by…"" msgstr ""管理元"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml65(para) msgid ""OpenStack Compute (Nova)"" msgstr ""OpenStack Compute (Nova)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml66(para) msgid ""OpenStack Block Storage (Cinder)"" msgstr ""OpenStack Block Storage (Cinder)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml68(para) msgid ""OpenStack Object Storage (Swift)"" msgstr ""OpenStack Object Storage (Swift)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml72(para) msgid ""Persists until…"" msgstr ""データの残存期間"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml73(para) msgid ""VM is terminated"" msgstr ""VM終了まで"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml74(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml75(para) msgid ""Deleted by user"" msgstr ""ユーザーが削除するまで"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml78(para) msgid ""Sizing determined by…"" msgstr ""容量の指定"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml79(para) msgid """" ""Administrator configures size settings, known as "" ""<emphasis>flavors</emphasis>"" msgstr ""管理者がサイズを設定（<emphasis>flavors</emphasis>）として知られる"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml82(para) msgid ""Specified by user in initial request"" msgstr ""ユーザが指定する"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml84(para) msgid ""Amount of available physical storage"" msgstr ""利用可能な物理ディスクの総量で決まる"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml88(para) msgid ""Example of typical usage…"" msgstr ""典型的な利用例"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml90(para) msgid ""10 GB first disk, 30GB second disk"" msgstr ""10GBの1台目ディスク、30GBの2台目ディスク"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml92(para) msgid ""1 TB disk"" msgstr ""1TBディスク"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml94(para) msgid ""10s of TBs of dataset storage"" msgstr ""数十TBのデータセットストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml99(para) msgid """" ""If you only deploy the OpenStack Compute Service (nova), your users do not "" ""have access to any form of persistent storage by default. The disks "" ""associated with VMs are \""ephemeral\"", meaning that (from the user's point "" ""of view) they effectively disappear when a virtual machine is terminated. "" ""You must identify what type of persistent storage you want to support for "" ""your users."" msgstr ""Novaのみを構成した場合、デフォルトではユーザにはあらゆる種類の永続ストレージへのアクセス方法がありません。この状態でVMに割り当てられるディスクは「エフェメラル」であり、これは仮想マシンが削除された時にディスクが削除される事を意味します。そのためユーザに対してどんなタイプの永続的ストレージがサポートされているか明示しておく必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml106(para) msgid """" ""Today, OpenStack clouds explicitly support two types of persistent storage: "" ""<emphasis>object storage</emphasis> and <emphasis>block storage</emphasis>."" msgstr ""現在、OpenStackでは二つの永続的ストレージ（<emphasis>object storage</emphasis> と <emphasis>block storage</emphasis>）がサポートされています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml111(para) msgid """" ""With object storage, users access binary objects through a REST API. You may"" "" be familiar with Amazon S3, which is a well-known example of an object "" ""storage system. If your intended users need to archive or manage large "" ""datasets, you want to provide them with object storage. In addition, "" ""OpenStack can store your virtual machine (VM) images inside of an object "" ""storage system, as an alternative to storing the images on a file system."" msgstr ""オブジェクトストレージでは、ユーザはREST APIを経由してバイナリオブジェクトへアクセスします。有名なオブジェクトストレージにAmazon S3があります。ユーザがアーカイブ領域や大容量のデータセットを必要としたときにオブジェクトストレージは有効です。またOpenStackはファイルシステムの代わりにオブジェクトストレージに仮想マシンイメージを保存する事が可能です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml124(para) msgid """" ""Block storage (sometimes referred to as volume storage) exposes a block "" ""device to the user. Users interact with block storage by attaching volumes "" ""to their running VM instances."" msgstr ""ブロックストレージ(ボリュームストレージとも呼ばれる)はユーザにブロックデバイスを提供します。ユーザは実行中のVMにボリュームをアタッチして、ブロックストレージを利用します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml128(para) msgid """" ""These volumes are persistent: they can be detached from one instance and re-"" ""attached to another, and the data remains intact. Block storage is "" ""implemented in OpenStack by the OpenStack Block Storage (Cinder) project, "" ""which supports multiple back-ends in the form of drivers. Your choice of a "" ""storage back-end must be supported by a Block Storage driver."" msgstr ""このボリュームは永続的です。データを残したまま仮想マシンからデタッチし、別の仮想マシンへ再アタッチすることができます。OpenStack では、ブロックストレージは OpenStack Block Storage （Cinder）で実装されており、複数のバックエンドストレージをドライバという形式でサポートします。あなたが選択するストレージバックエンドは、Block Storage のドライバによりサポートされている必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml135(para) msgid """" ""Most block storage drivers allow the instance to have direct access to the "" ""underlying storage hardware's block device. This helps increase the overall "" ""read/write IO."" msgstr ""多くのストレージドライバはインスタンスが直接ストレージハードウェアのブロックデバイスへアクセスできるようにします。これは リード/ライト I/O 性能の向上に役立ちます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml139(para) msgid """" ""Experimental support for utilizing files as volumes began in the Folsom "" ""release. This initially started as a reference driver for using NFS with "" ""Cinder. By Grizzly's release, this has expanded into a full NFS driver as "" ""well as a GlusterFS driver."" msgstr ""Folsomリリースではファイルをボリュームとして利用するための実験的サポートを開始しました。これは、最初は Cinder で NFS を使用するためのリファレンスドライバとしてスタートしたものです。Grizzly リリースまでに、このドライバはGlusterFS ドライバと同様、完全な NFS ドライバに拡張されました。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml144(para) msgid """" ""These drivers work a little differently than a traditional \""block\"" storage"" "" driver. On an NFS or GlusterFS file system, a single file is created and "" ""then mapped as a \""virtual\"" volume into the instance. This "" ""mapping/translation is similar to how OpenStack utilizes QEMU's file-based "" ""virtual machines stored in <code>/var/lib/nova/instances</code>."" msgstr ""これらのドライバーは従来のブロックストレージドライバとは少々異なる動作をします。NFSやGlusterFSでは1つのファイルが作成され、インスタンスに対して「仮想」ボリュームとしてマッピングされます。このマッピング/変換は<code>/var/lib/nova/instances</code> 下に保存される、QEMUのファイルベースの仮想マシンの、OpenStackによる扱い方と同様です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml153(title) msgid ""File-level Storage"" msgstr ""ファイルレベルストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml154(para) msgid """" ""With file-level storage, users access stored data using the operating "" ""system's file system interface. Most users, if they have used a network "" ""storage solution before, have encountered this form of networked storage. In"" "" the Unix world, the most common form of this is NFS. In the Windows world, "" ""the most common form is called CIFS (previously, SMB)."" msgstr ""ファイルレベルストレージでは、ユーザはOSのファイルシステムインターフェースを使ってデータへアクセスします。ほとんどのユーザは（以前ネットワークソリューションを使用した経験があった場合）この種類のネットワークストレージに遭遇したことがあります。UnixではNFSが一般的で、WindowsではCIFS(旧 SMB)が一般的です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml161(para) msgid """" ""OpenStack clouds do not present file-level storage to end users. However, it"" "" is important to consider file-level storage for storing instances under "" ""<code>/var/lib/nova/instances</code> when designing your cloud, since you "" ""must have a shared file system if you wish to support live migration."" msgstr ""OpenStackではエンドユーザがファイルレベルストレージを目にすることはありません。しかし、クラウド設計時、<code>/var/lib/nova/instances</code> 下のインスタンス保存用にファイルレベルストレージを検討する事は重要です。なぜなら、ライブマイグレーションをサポートしたい場合、共有ファイルシステムが必須だからです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml172(title) msgid ""Choosing Storage Back-ends"" msgstr ""ストレージバックエンドの選択"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml173(para) msgid """" ""In general, when you select <glossterm>storage back-end</glossterm>s, ask "" ""the following questions:"" msgstr ""<glossterm>storage back-end</glossterm> 選択における一般的な考慮事項："" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml178(para) msgid ""Do my users need block storage?"" msgstr ""ユーザがブロックストレージを必要とするか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml181(para) msgid ""Do my users need object storage?"" msgstr ""ユーザがオブジェクトストレージを必要とするか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml184(para) msgid ""Do I need to support live migration?"" msgstr ""管理者がライブマイグレーションを必要とするか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml187(para) msgid """" ""Should my persistent storage drives be contained in my compute nodes, or "" ""should I use external storage?"" msgstr ""永続的ストレージをコンピュートノード内に持つべきか？それとも外部ストレージに持つべきか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml192(para) msgid """" ""What is the platter count I can achieve? Do more spindles result in better "" ""I/O despite network access?"" msgstr ""実現可能な容量は？ネットワークアクセスでも、より多くのディスクがより良い I/O 性能に繋がるか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml197(para) msgid """" ""Which one results in the best cost-performance scenario I'm aiming for?"" msgstr ""どちらが自分の意図した最高のコストパフォーマンスシナリオを実現するか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml201(para) msgid ""How do I manage the storage operationally?"" msgstr ""ストレージの運用管理をどうするか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml205(para) msgid """" ""How redundant and distributed is the storage? What happens if a storage node"" "" fails? To what extent can it mitigate my data-loss disaster scenarios?"" msgstr ""ストレージの冗長性と分散をどうするか？ストレージノード障害でどうなるか？災害時、自分のデータ消失をどの程度軽減できるのか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml211(para) msgid """" ""To deploy your storage by using entirely commodity hardware, you can use a "" ""number of open-source packages, as shown in the following table:"" msgstr ""コモディティハードウェアを利用したストレージ環境の構築に、下記に表に示したいくつかのオープンソースパッケージを利用可能です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml218(th) msgid ""Object"" msgstr ""オブジェクトストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml219(th) msgid ""Block"" msgstr ""ブロックストレージ"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml220(th) msgid ""File-level* (live migration support)"" msgstr ""ファイルレベルストレージ* (ライブマイグレーションサポート)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml232(para) msgid ""LVM"" msgstr ""LVM"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml241(para) #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml264(para) msgid ""experimental"" msgstr ""実験的"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml244(para) msgid ""Gluster"" msgstr ""Gluster"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml250(para) msgid ""NFS"" msgstr ""NFS"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml256(para) msgid ""ZFS"" msgstr ""ZFS"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml262(para) msgid ""Sheepdog"" msgstr ""Sheepdog"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml269(para) msgid """" ""* This list of open-source file-level shared storage solutions is not "" ""exhaustive, other open source solutions exist (MooseFS). Your organization "" ""may already have deployed a file-level shared storage solution which you can"" "" use."" msgstr ""* このOSS ファイルレベル共有ストレージのリストは完全ではなく、他にもOSSが存在します(MooseFS)。あなたの組織では既に利用可能なファイルレベル共有ストレージがあるかもしれません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml274(para) msgid """" ""In addition to the open-source technologies, there are a number of "" ""proprietary solutions that are officially supported by OpenStack Block "" ""Storage. They are offered by the following vendors:"" msgstr ""OSSに加えて、OpenStack Block Storageではいくつかのプロプライエタリなストレージを公式にサポートしています。それらは以下のベンダーによって提供されています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml280(para) msgid ""IBM (Storwize family/SVC, XIV)"" msgstr ""IBM (Storwize family/SVC, XIV)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml283(para) msgid ""NetApp"" msgstr ""NetApp"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml286(para) msgid ""Nexenta"" msgstr ""Nexenta"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml289(para) msgid ""SolidFire"" msgstr ""SolidFire"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml292(para) msgid """" ""You can find a matrix of the functionality provided by all of the supported "" ""Block Storage drivers on the <link xlink:title=\""OpenStack wiki\"" "" ""xlink:href=\""https://wiki.openstack.org/wiki/CinderSupportMatrix\"">OpenStack "" ""wiki</link> (https://wiki.openstack.org/wiki/CinderSupportMatrix)."" msgstr ""こちらのリンクからドライバごとにサポートされている機能マトリックスを参照できます。 <link xlink:title=\""OpenStack wiki\"" xlink:href=\""https://wiki.openstack.org/wiki/CinderSupportMatrix\"">OpenStack wiki</link> (https://wiki.openstack.org/wiki/CinderSupportMatrix)"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml298(para) msgid """" ""Also, you need to decide whether you want to support object storage in your "" ""cloud. The two common use cases for providing object storage in a compute "" ""cloud are:"" msgstr ""クラウド内でオブジェクトストレージの利用を検討する必要があります。コンピュートクラウドで提供されるオブジェクトストレージの一般的な利用方法は以下の二つです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml303(para) msgid ""To provide users with a persistent storage mechanism"" msgstr ""ユーザに永続的ストレージの仕組みを提供する"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml307(para) msgid ""As a scalable, reliable data store for virtual machine images"" msgstr ""スケーラブルで信頼性のある仮想マシンイメージデータストアとして利用する"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml312(title) msgid ""Commodity Storage Back-end Technologies"" msgstr ""コモディティハードウェア上の ストレージ技術"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml313(para) msgid """" ""This section provides a high-level overview of the differences among the "" ""different commodity storage back-end technologies."" msgstr ""このセクションでは様々な コモディティハードウェアを利用するストレージ技術の差異について、上位レベルの概要を提供します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml319(para) msgid """" ""<emphasis role=\""bold\"">OpenStack Object Storage (Swift)</emphasis>. The "" ""official OpenStack Object Store implementation. It is a mature technology "" ""that has been used for several years in production by Rackspace as the "" ""technology behind Rackspace Cloud Files. As it is highly scalable, it is "" ""well-suited to managing petabytes of storage. OpenStack Object Storage's "" ""advantages are better integration with OpenStack (integrates with OpenStack "" ""Identity, works with OpenStack Dashboard interface), and better support for "" ""multiple data center deployment through support of asynchronous eventual "" ""consistency replication."" msgstr ""<emphasis role=\""bold\"">OpenStack Object Storage (Swift)</emphasis>。OpenStack公式のオブジェクトストア実装です。これはRackspace Cloud Files で採用されており、既に数年間の商用実績を持つ成熟した技術です。高度なスケーラビリティを備え、ペタバイトストレージの管理に適しています。OpenStack Object Storageの利点はOpenStackとの統合(OpenStack Identityとの統合、OpenStack Dashboardインターフェースでの操作)と、非同期の結果整合性レプリケーションによる複数データセンターのサポートです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml334(para) msgid """" ""Therefore, if you eventually plan on distributing your storage cluster "" ""across multiple data centers, if you need unified accounts for your users "" ""for both compute and object storage, or if you want to control your object "" ""storage with the OpenStack dashboard, you should consider OpenStack Object "" ""Storage. More detail can be found about OpenStack Object Storage in the "" ""section below."" msgstr ""従って、将来的に複数データセンターにまたがった分散ストレージクラスタを計画する場合や、コンピュートとオブジェクトストレージ間で統一されたアカウントを必要とする場合、または OpenStack Dashboard を使ってオブジェクトストレージを操作したい場合などに OpenStack Object Storage を検討します。OpenStack Object Storage のより詳細な情報は以後のセクションで記載します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml345(para) msgid """" ""<emphasis role=\""bold\"">Ceph</emphasis>. A scalable storage solution that "" ""replicates data across commodity storage nodes. Ceph was originally "" ""developed by one of the founders of DreamHost and is currently used in "" ""production there."" msgstr ""<emphasis role=\""bold\"">Ceph</emphasis>。コモディティなストレージノード間でデータレプリケーションを行う、スケーラブルなストレージソリューションです。Ceph は元々DreamHost の創設者の一人が開発し、現在はDreamHost の商用サービスで利用されています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml351(para) msgid """" ""Ceph was designed to expose different types of storage interfaces to the "" ""end-user: it supports object storage, block storage, and file system "" ""interfaces, although the file system interface is not yet considered "" ""production-ready. Ceph supports the same API as Swift for object storage, "" ""can be used as a back-end for Cinder block storage, as well as back-end "" ""storage for Glance images. Ceph supports \""thin provisioning\"", implemented "" ""using copy-on-write."" msgstr ""Ceph はエンドユーザに対して異なるストレージインターフェースが利用できるよう設計されています： オブジェクトストレージ、ブロックストレージ、ファイルシステムをサポートしていますが、ファイルシステムはまだ商用利用可能な状態ではありません。CephはオブジェクトストレージでSwiftと同じAPIをサポートし、Cinder ブロックストレージのバックエンドとしても利用でき、Glance用イメージのバックエンドストレージとしても利用できます。Cephはcopy-on-wirteを使って実装されたシンプロビジョニングをサポートしています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml362(para) msgid """" ""This can be useful when booting from volume because a new volume can be "" ""provisioned very quickly. Ceph also supports keystone-based authentication "" ""(as of version 0.56), so it can be a seamless swap in for the default "" ""OpenStack Swift implementation."" msgstr ""ボリューム作成が非常に高速なため、boot-from-volume に有効です。またCephはKeystoneベースの認証(version 0.56等)をサポートするため、デフォルトのOpenStack Swift との置き換えをシームレスに行えます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml368(para) msgid """" ""Ceph's advantages are that it gives the administrator more fine-grained "" ""control over data distribution and replication strategies, enables you to "" ""consolidate your object and block storage, enables very fast provisioning of"" "" boot-from-volume instances using thin provisioning, and supports a "" ""distributed file system interface, though this interface is <link "" ""xlink:title=\""OpenStack wiki\"" xlink:href=\""http://ceph.com/docs/master/faq/\"">not yet "" ""recommended</link> (http://ceph.com/docs/master/faq/) for use in production "" ""deployment by the Ceph project."" msgstr ""Cephのメリットは、管理者がデータの分散とレプリケーションを細かく計画する事ができること、ブロックストレージとオブジェクトストレージを統合できること、シンプロビジョニングを使ってインスタンスのboot-from-volumeを高速で行えること、 <link xlink:title=\""OpenStack wiki\"" xlink:href=\""http://ceph.com/docs/master/faq/\"">商用利用にはまだ推奨されていませんが</link> (http://ceph.com/docs/master/faq/) 分散ファイルシステムのインターフェースを利用できることです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml381(para) msgid """" ""If you wish to manage your object and block storage within a single system, "" ""or if you wish to support fast boot-from-volume, you should consider Ceph."" msgstr ""単一システムでブロックストレージとオブジェクトストレージを管理したい場合や、高速なboot-from-volumeをサポートしたい場合はCephの利用を検討してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml387(para) msgid """" ""<emphasis role=\""bold\"">Gluster</emphasis>. A distributed, shared file "" ""system. As of Gluster version 3.3, you can use Gluster to consolidate your "" ""object storage and file storage into one unified file and object storage "" ""solution, which is called Gluster UFO. Gluster UFO uses a customizes version"" "" of Swift that uses Gluster as the back-end."" msgstr ""<emphasis role=\""bold\"">Gluster</emphasis> 分散共有ファイルシステムです。Gluster 3.3の時点で、オブジェクトストレージとファイルストレージを統合して利用でき、これはGluster UFOと呼ばれています。Gluster UFOは、Glusterをバックエンドとして使うようにカスタマイズされたSwiftを利用しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml395(para) msgid """" ""The main advantage of using Gluster UFO over regular Swift is if you also "" ""want to support a distributed file system, either to support shared storage "" ""live migration or to provide it as a separate service to your end-users. If "" ""you wish to manage your object and file storage within a single system, you "" ""should consider Gluster UFO."" msgstr ""正規のSwift経由でGluster UFOを使う利点は、分散ファイルシステムをサポートしたい時や、共有ストレージによるライブマイグレーションのサポートや、個別サービスとしてエンドユーザにGluster UFOを提供できる事です。単一ストレージシステムでオブジェクトストレージとファイルストレージを管理したい場合はGluster UFOを検討します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml403(para) msgid """" ""<emphasis role=\""bold\"">LVM</emphasis>. The Logical Volume Manager, a Linux-"" ""based system that provides an abstraction layer on top of physical disks to "" ""expose logical volumes to the operating system. The LVM (Logical Volume "" ""Manager) back-end implements block storage as LVM logical partitions."" msgstr ""<emphasis role=\""bold\"">LVM</emphasis> 論理ボリュームマネージャ。オペレーティングシステムへ論理ディスクを公開するために、物理ディスク上の抽象化レイヤーを提供するLinuxベースの仕組みです。LVM(論理ボリュームマネージャ)のバックエンドは、LVM論理パーティションとしてブロックストレージを提供します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml410(para) msgid """" ""On each host that will house block storage, an administrator must initially "" ""create a volume group dedicated to Block Storage volumes. Blocks are created"" "" from LVM logical volumes."" msgstr ""ブロックストレージを収容する各ホストでは、管理者は事前にブロックストレージ専用のボリュームグループを作成しておく必要があります。ブロックストレージはLVM論理ボリュームから作られます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml416(para) msgid """" ""LVM does <emphasis>not</emphasis> provide any replication. Typically, "" ""administrators configure RAID on nodes that use LVM as block storage to "" ""protect against failures of individual hard drives. However, RAID does not "" ""protect against a failure of the entire host."" msgstr ""LVMはレプリケーションを<emphasis>提供しません</emphasis>。通常、管理者はブロックストレージとしてLVMを利用するホスト上にRAIDを構成し、ここのハードディスク障害からブロックストレージを保護します。しかしRAIDではホストそのものの障害には対応できません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml425(para) msgid """" ""The Solaris iSCSI driver for OpenStack Block Storage implements blocks as "" ""<emphasis role=\""bold\"">ZFS</emphasis> entities. ZFS is a file system that "" ""also has functionality of a volume manager. This is unlike on a Linux "" ""system, where there is a separation of volume manager (LVM) and file system "" ""(such as, ext3, ext4, xfs, btrfs). ZFS has a number of advantages over ext4,"" "" including improved data integrity checking."" msgstr ""Solarisの OpenStack Block Storage用のiSCSIドライバーは<emphasis role=\""bold\"">ZFS</emphasis>を実態としたブロックストレージを実装しています。ZFSはボリュームマネージャ機能を持ったファイルシステムです。これはボリュームマネージャ(LVM)とファイルシステム(ext3, ext4, xfs, btrfsのような)が分離しているLinuxとは異なっています。ZFSはデータ整合性チェックを含み、ext4より多くの利点を持っています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml435(para) msgid """" ""The ZFS back-end for OpenStack Block Storage only supports Solaris-based "" ""systems such as Illumos. While there is a Linux port of ZFS, it is not "" ""included in any of the standard Linux distributions, and it has not been "" ""tested with OpenStack Block Storage. As with LVM, ZFS does not provide "" ""replication across hosts on its own, you need to add a replication solution "" ""on top of ZFS if your cloud needs to be able to handle storage node "" ""failures."" msgstr ""OpenStack Block Storage用のZFSバックエンドは Illumos 等のSolaris ベースのシステムのみをサポートします。LinuxにポーティングされたZFSもありますが、標準的なLinuxディストリビューションには含まれておらず、OpenStack Block Storage でもテストされていません。LVMと同様にZFSはホスト間のレプリケーション機能を提供していませんので、ストレージノードの障害に対応するためには、ZFS上にレプリケーション機能を追加する必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml446(para) msgid """" ""We don't recommend ZFS unless you have previous experience with deploying "" ""it, since the ZFS back-end for Block Storage requires a Solaris-based "" ""operating system and we assume that your experience is primarily with Linux-"" ""based systems."" msgstr ""ここではLinuxベースのシステムを前提としているので、これまでにZFSの構築実績が無ければ、Solarisの知識を前提とするZFSはあえてお薦めしません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml454(para) msgid """" ""<emphasis role=\""bold\"">Sheepdog</emphasis>. A recent project that aims to "" ""provide block storage for KVM-based instances, with support for replication "" ""across hosts. We don't recommend Sheepdog for a production cloud, because "" ""its authors at NTT Labs consider Sheepdog as an experimental technology."" msgstr ""<emphasis role=\""bold\"">Sheepdog</emphasis> KVMのインスタンスにブロックストレージを提供する事に特化した新しいプロジェクトで、ホスト間のレプリケーションもサポートします。ただし、作者であるNTT研究所では、Sheepdogは実験的な技術と考えており、商用クラウドサービスでの利用はお薦めしません。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml467(title) msgid ""Notes on OpenStack Object Storage"" msgstr ""OpenStack Object Storage の注意事項"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml468(para) msgid """" ""OpenStack Object Storage provides a highly scalable, highly available "" ""storage solution by relaxing some of the constraints of traditional file "" ""systems. In designing and procuring for such a cluster, it is important to "" ""understand some key concepts about its operation. Essentially, this type of "" ""storage is built on the idea that all storage hardware fails, at every "" ""level, at some point. Infrequently encountered failures that would hamstring"" "" other storage systems, such as issues taking down RAID cards, or entire "" ""servers are handled gracefully with OpenStack Object Storage."" msgstr ""OpenStack Object Storage は従来のファイルシステムの制約を一部緩和することで、高いスケーラビリティと可用性を実現しています。その設計のためには、動作のキーコンセプトを理解することが重要です。このタイプのストレージはあらゆる場所・レベルにおいてハードウェア障害が発生する、という考えに基づいて構築されています。他のストレージシステムでは動作不能になってしまうような、まれに発生するRAIDカードやホスト全体の障害に対しても OpenStack Object Storage は正常に動作します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml479(para) msgid """" ""A good document describing the Object Storage architecture is found within "" ""<link xlink:title=\""OpenStack wiki\"" "" ""xlink:href=\""http://docs.openstack.org/developer/swift/overview_architecture.html\"">the"" "" developer documentation</link> "" ""(http://docs.openstack.org/developer/swift/overview_architecture.html) - "" ""read this first. Once you have understood the architecture, you should know "" ""what a proxy server does and how zones work. However, some there important "" ""points that are often missed at first glance."" msgstr ""オブジェクトストレージのアーキテクチャについて <link xlink:title=\""OpenStack wiki\"" xlink:href=\""http://docs.openstack.org/developer/swift/overview_architecture.html\"">the developer documentation</link> (http://docs.openstack.org/developer/swift/overview_architecture.html) に記述されています。まずアーキテクチャを理解し、プロキシサーバーとZoneがどのように働くか知る必要があります。重要なポイント見逃さないように注意してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml489(para) msgid """" ""When designing your cluster, you must consider durability and availability. "" ""Understand that the predominant source of these is the spread and placement "" ""of your data, rather than the reliability of the hardware. Consider the "" ""default value of the number of replicas, which is 3. This means that when "" ""before an object is marked as having being written at least two copies "" ""exists - in case a single server fails to write, the third copy may or may "" ""not yet exist when the write operation initially returns. Altering this "" ""number increases the robustness of your data, but reduces the amount of "" ""storage you have available. Next look at the placement of your servers. "" ""Consider spreading them widely throughout your data centre's network and "" ""power failure zones. Is a zone a rack, a server or a disk?"" msgstr ""クラスタの設計には耐久性と可用性を検討する必要があります。耐久性と可用性はハードウェアの信頼性ではなく、データの分布と配置が重要です。デフォルトのレプリカ数3について考えます。これはオブジェクトが書き込まれた時に少なくとも2つのコピーが存在する事を意味します。1台のサーバーへの書き込みが失敗した場合、3つ目のコピーは書き込み操作が返った直後には存在するかもしれないし、存在しないかもしれません。レプリカ数を増やすとデータの堅牢性は増しますが、利用できるストレージの総量は減ってしまいます。次にサーバーの配置を見てみます。データセンター全体でネットワークや電源の障害箇所とサーバーの分布を考えてください。その障害ではラック、サーバー、ディスクのどこが影響を受けますか？"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml507(para) msgid """" ""Among <glossterm>object</glossterm>, <glossterm>container</glossterm>, and "" ""<glossterm>account server</glossterm>s"" msgstr ""<glossterm>object server</glossterm> 、 <glossterm>container server</glossterm> 、 <glossterm>account server</glossterm> 間"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml513(para) msgid ""Between those servers and the proxies"" msgstr ""object/container/account server と proxy server の間"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml516(para) msgid ""Between the proxies and your users"" msgstr ""proxy server と 利用者の間"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml504(para) msgid """" ""Object Storage's network patterns might seem unfamiliar at first. Consider "" ""these main traffic flows: <placeholder-1/>"" msgstr ""オブジェクトストレージのネットワークのトラフィックは通常とは異なっているかもしれません。以下のトラフィックを考慮してください。 <placeholder-1/>"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml520(para) msgid """" ""Object Storage is very 'chatty' among servers hosting data - even a small "" ""cluster does megabytes/second of traffic, which is predominantly \""Do you "" ""have the object?\""/\""Yes I have the object!.\"" Of course, if the answer to "" ""the aforementioned question is negative or times out, replication of the "" ""object begins."" msgstr ""オブジェクトストレージはデータを保持するノード間で頻繁に通信を行います。 小さなクラスタでさえ、これは数MB/sのトラフィックで主に他ホストにオブジェクトの存在確認を行いっています。相手ノードにオブジェクトが無い場合はレプリケーションが開始されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml526(para) msgid """" ""Consider the scenario where an entire server fails, and 24 TB of data needs "" ""to be transferred \""immediately\"" to remain at three copies - this can put "" ""significant load on the network."" msgstr ""サーバー障害で3つのコピーを保つために、24TBのデータ転送が必要になる場合を考えてみてください。これはネットワークに大きな負荷を発生させます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml530(para) msgid """" ""Another oft forgotten fact is that when a new file is being uploaded, the "" ""proxy server must write out as many streams as there are replicas - giving a"" "" multiple of network traffic. For a 3-replica cluster, 10Gbps in means "" ""30Gbps out. Combining this with the previous high bandwidth demands of "" ""replication is what results in the recommendation that your private network "" ""is of significantly higher bandwidth than your public need be. Oh, and "" ""OpenStack Object Storage communicates internally with unencrypted, "" ""unauthenticated rsync for performance - you do want the private network to "" ""be private."" msgstr ""忘れてはいけない事として、レプリカがあるためファイルがアップロードされたときに、proxy server は多くのストリームを書き出す必要があることです。これは3レプリカの場合、10Gbpsのアップロードに対して、30Gbpsのダウンロードになります。これはパブリック側のネットワークよりも、プライベート側のネットワークがより多くの帯域を必要とすることを意味しています。OpenStack Object Storage はパフォーマンスのために非暗号化、未認証のrsync通信を行います。そのためプライベートネットワークは非公開である必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml541(para) msgid """" ""The remaining point on bandwidth is the public facing portion. swift-proxy "" ""is stateless, which means that you can easily add more and use http load-"" ""balancing methods to share bandwidth and availability between them."" msgstr ""残りのポイントはパブリック側のネットワーク帯域になります。swift-proxyはステートレスなため、ノードを追加し、HTTPロードバランスを使うことで帯域の増加と可用性の向上を容易に行うことができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_arch_storage.xml545(para) msgid ""More proxies means more bandwidth, if your storage can keep up."" msgstr ""ストレージ側の性能が十分であれば、proxy server の増加は帯域の増加になります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml16(title) msgid ""Lay of the Land"" msgstr ""環境の把握"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml17(para) msgid """" ""From this point forward in the guide, we assume that you have an OpenStack "" ""cloud up and running. This section helps you set up your working environment"" "" and use it to take a look around your cloud."" msgstr ""ここからは、あなたがOpenStackが稼働している環境を持っていると想定して進めます。この節は環境の構築と情報収集に役立つでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml22(title) msgid ""Client Command Line Tools"" msgstr ""クライアントコマンドラインツール"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml23(para) msgid """" ""We recommend using a combination of the OpenStack command line interface "" ""(CLI) client tools and the OpenStack Dashboard. Some users with a background"" "" in other cloud technologies may be using the EC2 Compatibility API, which "" ""uses somewhat different naming conventions from the native API. We highlight"" "" those differences."" msgstr ""OpenStack command line interface (CLI) クライアントツールとOpenStackダッシュボードを組み合わせて使うことをおすすめします。他のクラウド技術の経験を持つユーザーは、EC2互換APIを使っているかも知れませんが、それとは命名規則が少々異なります。それらの違いは必要に応じて補足します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml29(para) msgid """" ""We strongly suggest that you install the command-line clients from the <link"" "" xlink:href=\""https://pypi.python.org/\"">Python Package Index</link>(PyPI) "" ""(https://pypi.python.org/) instead of from the Ubuntu or Fedora packages. "" ""The clients are under heavy development and it is very likely at any given "" ""time the version of the packages distributed by your operating system vendor"" "" are out of date."" msgstr ""コマンドラインツールは、UbuntuやFedoraのパッケージからではなく、<link xlink:href=\""https://pypi.python.org/\"">Python Package Index</link>(PyPI) (https://pypi.python.org/) から導入することを強くおすすめします。クライアントツールは開発が活発であり、OSベンダーが配布しているパッケージのバージョンが古くなりがちなためです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml37(para) msgid """" ""The \""pip\"" utility is used to manage package installation from the PyPI "" ""archive and is available in the \""python-pip\"" package in most Linux "" ""distributions. Each OpenStack project has its own client, so depending on "" ""which services your site runs, install some or all of the following "" ""packages:"" msgstr ""\""pip\""ユーティリティはPyPIアーカイブからパッケージを導入するために使われます。そして、多くのLinuxディストリビューションでは\""pip\""ユーティリティは\""python-pip\""パッケージに含まれています。各OpenStackプロジェクトはそれぞれクライアントを持ちますので、あなたの環境で動かすサービスに合わせて、以下のパッケージを導入してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml45(para) msgid ""python-novaclient (<glossterm>nova</glossterm> CLI)"" msgstr ""python-novaclient (<glossterm>nova</glossterm> CLI)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml49(para) msgid ""python-glanceclient (<glossterm>glance</glossterm> CLI)"" msgstr ""python-glanceclient (<glossterm>glance</glossterm> CLI)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml53(para) msgid ""python-keystoneclient (<glossterm>keystone</glossterm> CLI)"" msgstr ""python-keystoneclient (<glossterm>keystone</glossterm> CLI)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml57(para) msgid ""python-cinderclient (<glossterm>cinder</glossterm> CLI)"" msgstr ""python-cinderclient (<glossterm>cinder</glossterm> CLI)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml61(para) msgid ""python-swiftclient (<glossterm>swift</glossterm> CLI)"" msgstr ""python-swiftclient (<glossterm>swift</glossterm> CLI)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml65(para) msgid ""python-quantumclient (<glossterm>quantum</glossterm> CLI)"" msgstr ""python-quantumclient (<glossterm>quantum</glossterm> CLI)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml70(title) msgid ""Installing the Tools"" msgstr ""ツールの導入"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml71(para) msgid """" ""To install (or upgrade) a package from the PyPI archive with pip, as root:"" msgstr ""PyPIアーカイブからpipを使ってパッケージをインストール (もしくはアップグレード)するには、rootとして、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml74(para) msgid ""To remove the package:"" msgstr ""パッケージを削除するには、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml76(para) msgid """" ""If you need even newer versions of the clients, pip can install directly "" ""from the upstream git repository using the <code>-e</code> flag. You must "" ""specify a name for the Python egg that is installed. For example:"" msgstr ""もし新しいバージョンのクライアントが必要な場合、<code>-e</code>フラグを指定することで、アップストリームのgitリポジトリから直接導入できます。その際は、Python egg名を指定しなければいけません。例えば、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml82(para) msgid """" ""If you support the EC2 API on your cloud you should also install the "" ""\""euca2ools\"" package or some other EC2 API tool so you can get the same "" ""view your users have. Using EC2 API based tools is mostly out of the scope "" ""of this guide, though we discuss getting credentials for use with it."" msgstr ""もしEC2 APIを使いたい場合、\""euca2ools\""パッケージなどのEC2 API対応ツールで実現できます。EC2 APIベースのツールはこのガイドの範囲外ですが、それを使うための認証情報の取得手段については触れることにします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml90(title) msgid ""Administrative Command Line Tools"" msgstr ""管理系コマンドラインツール"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml91(para) msgid """" ""There are also several <emphasis>*-</emphasis>manage command line tools:"" msgstr ""<emphasis>*-</emphasis>manageという名のコマンドラインツールがいくつかあります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml95(para) msgid ""nova-manage"" msgstr ""nova-manage"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml98(para) msgid ""glance-manage"" msgstr ""glance-manage"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml101(para) msgid ""keystone-manage"" msgstr ""keystone-manage"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml104(para) msgid ""cinder-manage"" msgstr ""cinder-manage"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml107(para) msgid """" ""Unlike the tools mentioned above, the <code>*-manage</code> tools must be "" ""run from the cloud controller, as root, because they need read access to the"" "" config files such as <code>/etc/nova/nova.conf</code> and make queries "" ""directly against the database rather than against the OpenStack "" ""<glossterm>API endpoint</glossterm>s."" msgstr ""前述のツールと違って、<code>*-manage</code>ツールはクラウドコントローラーからroot権限で実行されなければいけません。なぜなら、それらのツールは<code>/etc/nova/nova.conf</code>などの設定ファイルを読み取り、また、OpenStack <glossterm>API エンドポイント</glossterm>ではなく、データベースに対し直接クエリーを発行するからです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml114(para) msgid """" ""The existence of the <code>*-manage</code> tools is a legacy issue. It is a "" ""goal of the OpenStack project to eventually migrate all of the remaining "" ""functionality in the <code>*-manage</code> tools into the regular client "" ""tools. Until that day, you need to SSH into the <glossterm>cloud controller "" ""node</glossterm> to perform some maintenance operations that require one of "" ""the <code>*-manage</code> tools."" msgstr ""<code>*-manage</code>ツールが存在しているのは、歴史的な経緯からです。OpenStackプロジェクトは最終的に、<code>*-manage</code>の全機能を通常のクライアントツールへ移行する予定です。それまでは、<glossterm>cloud controller node</glossterm>へSSHし、必要な<code>*-manage</code>を使ってメンテナンス作業を行う必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml126(title) msgid ""Getting Credentials"" msgstr ""認証情報の取得方法"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml127(para) msgid """" ""You must have the appropriate credentials if you wish to use the command "" ""line tools to make queries against your OpenStack cloud. By far the easiest "" ""way to obtain <glossterm>authentication</glossterm> credentials to use with "" ""command line clients is to use the horizon dashboard. From the top right "" ""navigation row, select the <guilabel>Settings</guilabel> link to access the "" ""user settings page where you can set your language and timezone preferences "" ""for the dashboard view. More importantly, this action changes the left hand "" ""navigation column to include <guilabel>OpenStack API</guilabel> and "" ""<guilabel>EC2 Credentials</guilabel> links, which let you to generate files "" ""you can source in your shell to populate the environment variables the "" ""command line tools need to know where your service endpoints are as well as "" ""your authentication information."" msgstr ""OpenStackクラウドに対してクエリを発行するためにコマンドラインツールを使いたいのであれば、適切な<glossterm>認証</glossterm>情報を持っている必要があります。コマンドラインツールで使う<glossterm>認証</glossterm>情報を得るための最も簡単な方法は、Horizonダッシュボードです。ユーザー設定ページを表示するには、ページ右上のナビゲーションバーから、<guilabel>設定</guilabel>のリンクを選択し、ユーザー設定を開きます。ユーザー設定では、言語やタイムゾーンも設定できます。ここで重要なのは、このページ左側のナビゲーションにある<guilabel>OpenStack API</guilabel> と <guilabel>EC2 認証情報</guilabel> リンクです。このリンクから、あなたのサービスエンドポイントや認証情報といった環境変数を設定するファイルを生成できます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml144(para) msgid """" ""For using the OpenStack native tools follow the <guilabel>OpenStack "" ""API</guilabel> link. The top section lists the URLs of your service "" ""endpoints and below that is a section titled <guilabel>Download OpenStack RC"" "" File</guilabel>. For looking at the cloud as an administrator, you can "" ""choose admin from the drop-down menu. In this section select the project you"" "" wish to get credentials for and click <guibutton>Download RC</guibutton>. "" ""This generates a file called <code>openrc.sh</code>, which looks something "" ""like this:"" msgstr ""OpenStackネイティブのツールを使うには、 <guilabel>OpenStack API</guilabel> リンクを選択します。ページ上部にはサービスエンドポイントのURLリストが、その下にタイトル<guilabel>OpenStack RCファイルのダウンロード</guilabel>があります。管理者としてクラウドにアクセスする場合、ドロップダウンメニューから選択できます。ここから認証情報を取得したいプロジェクトを選択し、<guibutton>RCファイルのダウンロード</guibutton>をクリックします。以下のような、<code>openrc.sh</code>ファイルが生成されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml180(para) msgid """" ""This does not save your password in plain text, which is a good thing. But "" ""when you source or run the script, it prompts for your password and then "" ""stores your response in the environment variable <code>OS_PASSWORD</code>. "" ""It is important to note that this does require interactivity. It is possible"" "" to store a value directly in the script if you require a non interactive "" ""operation, but you then need to be extremely cautious with the security and "" ""permissions of this file."" msgstr ""あなたのパスワードはプレーンテキストに保存されません。これはいいことです。このスクリプトを読み込み、実行する際、パスワードの入力が要求され、環境変数<code>OS_PASSWORD</code>に設定されます。対話式に要求することが重要です。もしあなたが非対話式に操作したいのであれば、値を直接スクリプトに書くことは可能です。しかし、このファイルのセキュリティとパーミッションに細心の注意を払う必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml191(para) msgid """" ""EC2 compatibility credentials can be downloaded from the \""EC2 Credentials\"""" "" link in the left hand navigation bar, then selecting the project you want "" ""credentials for and clicking \""Download EC2 Credentials\"". This generates a "" ""zip file with server x509 certificates and a shell script fragment. Create a"" "" new directory in a secure location as, unlike the default "" ""<code>openrc</code>, these are live credentials containing all the "" ""authentication information required to access your cloud identity. Extract "" ""the zip file here. You should have cacert.pem, cert.pem, ec2rc.sh and "" ""pk.pem. The <code>ec2rc.sh</code> is similar to this:"" msgstr ""EC2互換クレデンシャルは左側ナビゲーションバー内の \""EC2 認証情報\""リンクからダウンロードできます。対象認証情報のプロジェクトを選択し、\""EC2 認証情報のダウンロード\""をクリックすると、x509証明書とシェルスクリプトを含むzipファイルが生成されます。クラウドにアクセスするために必要な認証情報を含んでいるため、<code>openrc</code>とは異なり、安全な場所へ新しいディレクトリを作り、そこへzipファイルを展開してください。cacert.pem、 cert.pem、 ec2rc.sh そして pk.pemがあるはずです。 <code>ec2rc.sh</code>は以下のようになるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml220(para) msgid """" ""To put the EC2 credentials into your environment source the "" ""<code>ec2rc.sh</code> file."" msgstr ""EC2認証情報を環境変数として有効にするには、<code>ec2rc.sh</code>ファイルを(source コマンドで) 読み込みます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml224(title) msgid ""Command Line Tricks and Traps"" msgstr ""コマンドラインのこつとはまりどころ"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml225(para) msgid """" ""The command line tools can be made to show the OpenStack API calls it's "" ""making by passing it the <code>--debug</code> flag for example:"" msgstr ""コマンドラインツールは、<code>--debug</code>フラグを渡すことでOpenStack APIコールを表示することができます。例えば、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml229(para) msgid """" ""This example shows the HTTP requests from the client and the responses from "" ""the endpoints, which can be helpful in creating custom tools written to the "" ""OpenStack API."" msgstr ""この例は、クライアントからのHTTPリクエストとエンドポイントからのレスポンスを表示しています。これはOpenStack APIを使ったカスタムツールを作る際に役立ちます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml233(para) msgid """" ""<link xlink:href=\""https://wiki.openstack.org/wiki/KeyringSupport\"">Keyring "" ""Support</link> (https://wiki.openstack.org/wiki/KeyringSupport) can be a "" ""source of confusion to the point that, as of the time of this writing, there"" "" is a <link xlink:href=\""https://bugs.launchpad.net/python-"" ""novaclient/+bug/1020238\"">bug report</link> (https://bugs.launchpad.net"" ""/python-novaclient/+bug/1020238) which has been open, closed as invalid, and"" "" reopened through a few cycles."" msgstr ""<link xlink:href=\""https://wiki.openstack.org/wiki/KeyringSupport\"">Keyring Support</link> (https://wiki.openstack.org/wiki/KeyringSupport)は、このガイドの執筆時点では混乱の元になるかもしれません。この<link xlink:href=\""https://bugs.launchpad.net/python-novaclient/+bug/1020238\"">バグレポート</link> (https://bugs.launchpad.net/python-novaclient/+bug/1020238)はオープンされた後、無効(invalid)としてクローズされ、何度かやり取りがあって再度オープンされています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml244(para) msgid """" ""The issue is that under some conditions the command line tools try to use a "" ""Python keyring as a credential cache and, under a subset of those "" ""conditions, another condition can arise where the tools prompt for a keyring"" "" password on each use. If you find yourself in this unfortunate subset, "" ""adding the <code>--no-cache</code> flag or setting the environment variable "" ""<code>OS_NO_CACHE=1</code> avoids the credentials cache."" msgstr ""その問題とは、ある条件下でコマンドラインツールがPythonのkeyringを認証情報キャッシュとして使おうとし、さらにある条件が重なった時、使用するたびにツールがkeyringパスワードを要求することです。もしあなたが運悪くその現象に遭遇した場合、認証情報キャッシュを回避するため、<code>--no-cache</code>フラグを追加するか、<code>OS_NO_CACHE=1</code>を環境変数に設定してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml254(para) msgid """" ""This causes the command line tool to authenticate on each and every "" ""interaction with the cloud."" msgstr ""no-cache を設定すると、コマンドラインツールがクラウドとやり取りを行う度に認証が行われます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml259(title) msgid ""cURL"" msgstr ""cURL"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml261(para) msgid """" ""Underlying the use of the command line tools is the OpenStack API, which is "" ""a RESTful API that runs over HTTP. There may be cases where you want to "" ""interact with the API directly or need to use it because of a suspected bug "" ""in one of the CLI tools. The best way to do this is use a combination of "" ""<link xlink:href=\""http://curl.haxx.se/\"">cURL</link> (http://curl.haxx.se/) and "" ""another tool to parse the JSON, such as <link "" ""xlink:href=\""http://stedolan.github.com/jq/\"">jq</link> "" ""(http://stedolan.github.com/jq/), from the responses."" msgstr ""コマンドラインツールの内部ではOpenStack APIが使用されます。OpenStack APIはHTTP上で動作するRESTful APIです。時に、APIと直接やりとりしたい、CLIツールのバグを疑っている、ということがあるでしょう。その際に最適な方法は、<link xlink:href=\""http://curl.haxx.se/\"">cURL</link> (http://curl.haxx.se/)と、JSONレスポンスを解析する<link xlink:href=\""http://stedolan.github.com/jq/\"">jq</link> (http://stedolan.github.com/jq/)などのツールを組み合わせることです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml275(para) msgid """" ""The first thing you must do is authenticate with the cloud using your "" ""credentials to get an <glossterm>authentication token</glossterm>."" msgstr ""まずはじめに、クラウドの認証が必要です。あなたの認証情報を用いて<glossterm>認証トークン</glossterm>を入手してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml278(para) msgid """" ""Your credentials are a combination of username, password, and tenant "" ""(project). You can extract these values from the <code>openrc.sh</code> "" ""discussed above. The token allows you to interact with your other service "" ""endpoints without needing to re-authenticate for every request. Tokens are "" ""typically good for 24 hours, and when the token expires, you are alerted "" ""with a 401 (Unauthorized) response and you can request another token."" msgstr ""あなたの認証情報はユーザー名、パスワード、テナント(プロジェクト)の組み合わせです。前述した<code>openrc.sh</code>で、それらの値を得ることができます。そのトークンのおかげで、リクエストのたびに再認証することなく、サービスエンドポイントとやりとりすることができます。トークンは通常24時間有効です。失効の際は401 (Unauthorized)レスポンスにて警告されますが、別トークンを要求することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml291(para) msgid ""Look at your OpenStack service <glossterm>catalog</glossterm>:"" msgstr ""それではOpenStack サービス<glossterm>カタログ</glossterm>を見てみましょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml298(para) msgid """" ""Read through the JSON response to get a feel for how the catalog is laid "" ""out."" msgstr ""JSONレスポンスを読むことで、カタログを把握することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml301(para) msgid """" ""To make working with subsequent requests easier, store the token in an "" ""environment variable."" msgstr ""これ以降のリクエストを楽にするため、トークンを環境変数へ設定します。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml307(para) msgid ""Now you can refer to your token on the command line as $TOKEN."" msgstr ""コマンドラインから、トークンを$TOKENとして参照できるようになりました。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml311(para) msgid """" ""Pick a service endpoint from your service catalog, such as compute, and try "" ""out a request like listing instances (servers)."" msgstr ""あなたのサービスカタログからコンピュートなどのエンドポイントを選び、試してみましょう。例えば、(サーバー)インスタンスのリスト出力など。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml322(para) msgid """" ""To discover how API requests should be structured, read the <link "" ""xlink:href=\""http://api.openstack.org/api-ref.html\"">OpenStack API "" ""Reference</link> (http://api.openstack.org/api-ref.html). To chew through "" ""the responses using jq, see the <link "" ""xlink:href=\""http://stedolan.github.com/jq/manual/\"">jq Manual</link> "" ""(http://stedolan.github.com/jq/manual/)."" msgstr ""APIリクエストがどのような構造かを知るには、<link xlink:href=\""http://api.openstack.org/api-ref.html\"">OpenStack API Reference</link> (http://api.openstack.org/api-ref.html)を参照してください。また、jqを使ってレスポンスを理解するには、<link xlink:href=\""http://stedolan.github.com/jq/manual/\"">jq Manual</link> (http://stedolan.github.com/jq/manual/)も参考になるでしょう。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml331(para) msgid """" ""The <code>-s flag</code> used in the cURL commands above are used to prevent"" "" the progress meter from being shown. If you are having trouble running cURL"" "" commands, you'll want to remove it. Likewise, to help you troubleshoot cURL"" "" commands you can include the <code>-v</code> flag to show you the verbose "" ""output. There are many more extremely useful features in cURL, refer to the "" ""man page for all of the options."" msgstr ""cURLの<code>-s</code>フラグを使うことで、プログレスメーター非表示にできます。もしcURLコマンドの実行に問題がある場合、それらを消したくなるでしょう。いっぽう、<code>-v</code>フラグは詳細を出力するため、cURLコマンドのトラブル解決に役立ちます。非常に便利な機能がcURLには多くあるので、manページでそれらのオプションを参照してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml343(title) msgid ""Servers and Services"" msgstr ""サーバーとサービス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml344(para) msgid """" ""As an administrator, there are a few ways to discover what your OpenStack "" ""cloud looks like simply by using the OpenStack tools available. This section"" "" gives you an idea of how to get an overview of your cloud, its shape, size,"" "" and current state."" msgstr ""管理者として、あなたのOpenStackクラウドがどのような状態か、ツールを使って把握する方法が、いくつかあります。この節では、あなたのクラウドの概要、形、大きさ、状態を得るアイデアをお伝えします。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml349(para) msgid """" ""First, you can discover what servers belong to your OpenStack cloud by "" ""running:"" msgstr ""まず、あなたのOpenStackクラウドに属し、稼働しているサーバーを把握することができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml352(para) msgid ""The output looks like the following:"" msgstr ""出力は以下のようになります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml363(para) msgid """" ""The output shows that there are five compute nodes and one cloud controller."" "" You see a smiley face like <code>:-)</code> which indicates that the "" ""services are up and running and functional. If a service is no longer "" ""available, the <code>:-)</code> changes to an <code>XXX</code>. This is an "" ""indication that you should troubleshoot why the service is down."" msgstr ""この出力は、5つのコンピュートノードと1つのクラウドコントローラーがあることを示しています。<code>:-)</code> のような笑顔は、サービスが起動し、稼働中であることを表しています。もしサービスが動作していない場合、<code>:-)</code>は<code>XXX</code>へと変化します。なぜサービスがダウンしているのか、問題解決すべき印です。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml370(para) msgid """" ""If you are still using <code>nova-volume</code> (this service is deprecated "" ""after the Folsom release), you might also see entries for the nova-volume "" ""service."" msgstr ""あなたがまだ<code>nova-volume</code>を使っているのであれば、nova-volumeサービスのエントリも見えるでしょう。 (nova-volumeはFolsomより後のリリースでは廃止予定です)"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml374(para) msgid """" ""If you are using Cinder, run the following command to see a similar listing:"" msgstr ""Cinderを使っているのであれば、以下のコマンドを実行すると同様のリストが見られます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml386(para) msgid """" ""With these two tables, you now have a good overview of what servers and "" ""services make up your cloud."" msgstr ""これら2つの表で、どのサーバーとサービスがあなたのクラウドを構成しているのか、概要を知ることができました。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml389(para) msgid """" ""You can also use the Identity Service (Keystone), to see what services are "" ""available in your cloud as well as what endpoints have been configured for "" ""the services."" msgstr ""また、認証サービス (Keystone)を使い、あなたのクラウドでどのサービスが使えるのか、また、どのエンドポイントがサービス向けに構成されているか、知ることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml393(para) msgid """" ""The following commands require you to have your shell environment configured"" "" with the proper administrative variables."" msgstr ""下記コマンドを実行するには、あなたのシェル環境で正しく管理系の変数が設定されている必要があります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml408(para) msgid ""The output above shows that there are five services configured."" msgstr ""上記の出力は、5つのサービスが構成されていることを示しています。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml410(para) msgid ""To see the endpoint of each service, run:"" msgstr ""各サービスのエンドポイントを見るには、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml421(para) msgid """" ""There should be a one-to-one mapping between a <emphasis>service</emphasis> "" ""and <emphasis>endpoint</emphasis>. Note the different URLs and ports between"" "" the public URL and the admin URL for some services."" msgstr ""<emphasis>service</emphasis> と <emphasis>endpoint</emphasis>は1対1でマッピングされます。いくつかのサービスではパブリックURLと管理URLが異なるので注意してください。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml429(title) msgid ""Network"" msgstr ""ネットワーク"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml430(para) msgid """" ""Next, take a look at what Fixed IP networks are configured in your cloud. "" ""You can use the <placeholder-1/> command-line client to get the IP "" ""ranges.<placeholder-2/>"" msgstr ""次に、あなたのクラウドでどのような固定IPネットワークが設定されているかを見てみましょう。<placeholder-1/> novaコマンドラインクライアントを使って、構成されているIPアドレス空間を得ることができます。<placeholder-2/>"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml439(para) msgid ""The <placeholder-1/> tool can provide some additional details."" msgstr ""<placeholder-1/> ツールを使うと、もう少し詳しい情報が表示されます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml445(para) msgid """" ""This output shows that two networks are configured, each network containing "" ""255 IPs (a /24 subnet). The first network has been assigned to a certain "" ""project while the second network is still open for assignment. You can "" ""assign this network manually or it is automatically assigned when a project "" ""launches their first instance."" msgstr ""この出力は、2つのネットワークが構成され、それぞれが255のIPアドレス (/24 サブネット)を持つことを表しています。1つ目のネットワークはあるプロジェクトに割り当てられており、2つ目はまだ割り当てられていません。手動でプロジェクトに割り当てることもできますし、プロジェクトの1つ目のインスタンスを起動する際、自動的に割り当てることもできます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml452(para) msgid ""To find out if any floating IPs are available in your cloud, run:"" msgstr ""利用可能なフローティングIPを確認するには、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml459(para) msgid """" ""Here, two floating IPs are available. The first has been allocated to a "" ""project while the other is unallocated."" msgstr ""2つのフローティングIPが利用可能であることがわかります。1つめはプロジェクトに割り当て済み、もうひとつは未割り当てです。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml464(title) msgid ""Users and Projects"" msgstr ""ユーザーとプロジェクト"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml465(para) msgid ""To see a list of projects that have been added to the cloud, run:"" msgstr ""クラウドに追加されたプロジェクトのリストを見るためには、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml486(para) msgid ""To see a list of users, run:"" msgstr ""ユーザーのリストを見るためには、"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml508(para) msgid """" ""Sometimes a user and a group have a one-to-one mapping. This happens for "" ""standard system accounts, such as cinder, glance, nova, and swift, or when "" ""only one user is ever part of a group."" msgstr ""ユーザーとグループが1対1でマッピングされることもあります。これはcinder、glance、novaやswiftなど標準のシステムアカウントや、グループに属すのが1ユーザーのみの場合がこれにあたります。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml515(title) msgid ""Running Instances"" msgstr ""稼働中のインスタンス"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml516(para) msgid ""To see a list of running instances, run:"" msgstr ""以下のコマンドで、稼働中のインスタンスのリストが得られます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml531(para) msgid """" ""Unfortunately this command does not tell you various details about the "" ""running instances, such as what compute node the instance is running on, "" ""what flavor the instance is, and so on. You can use the following command to"" "" view details about individual instances:"" msgstr ""残念ながら、このコマンドは稼働中のインスタンスの詳細を出力しません。例えば、どのコンピュートノードでインスタンスが動いているのか、フレーバーは何か、などなど。あなたは以下のコマンドでインスタンス個別の詳細情報を得ることができます。"" #: ./doc/src/docbkx/openstack-ops/src/ch_ops_lay_of_land.xml539(para) msgid ""For example: <placeholder-1/><placeholder-2/>"" msgstr ""例えば、<placeholder-1/><placeholder-2/>"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml14(title) msgid ""Tales From the Cryp^H^H^H^H Cloud"" msgstr ""ハリウッド^H^H^H^H^Hクラウドナイトメア"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml16(para) msgid """" ""Herein lies a selection of takes from OpenStack cloud operators. Read, and "" ""learn from their wisdom."" msgstr ""ここにあるのは、OpenStack クラウドオペレータ達の苦闘の抜粋である。これを読み、彼らの叡智を学ぶが良い。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml20(title) msgid ""Double VLAN"" msgstr ""ダブル VLAN"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml21(para) msgid """" ""I was on-site in Kelowna, British Columbia, Canada setting up a new "" ""OpenStack cloud. The deployment was fully automated: Cobbler deployed the OS"" "" on the bare metal, bootstrapped it, and Puppet took over from there. I had "" ""run the deployment scenario so many times in practice and took for granted "" ""that everything was working."" msgstr ""私は、新しい OpenStack クラウドのセットアップをするため、カナダのブリティッシュコロンビア州ケロウナの現地にいた。デプロイ作業は完全に自動化されていた。Cobbler が物理マシンに OS をデプロイし、それを起動し、その後は Puppet が引き継いだ。私は練習で幾度もデプロイシナリオを実行してきたし、もちろん全て正常であった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml27(para) msgid """" ""On my last day in Kelowna, I was in a conference call from my hotel. In the "" ""background, I was fooling around on the new cloud. I launched an instance "" ""and logged in. Everything looked fine. Out of boredom, I ran ps aux and all "" ""of the sudden the instance locked up."" msgstr ""ケロウナの最終日、私はホテルから電話会議に参加していた。その裏で、私は新しいクラウドをいじっていた。私はインスタンスを１つ起動し、ログインした。全ては正常に思えた。退屈しのぎに、私は ps axu を実行したところ、突然そのインスタンスがロックアップしてしまった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml32(para) msgid """" ""Thinking it was just a one-off issue, I terminated the instance and launched"" "" a new one. By then, the conference call ended and I was off to the data "" ""center."" msgstr ""これは単なる１回限りの問題と思ったので、私はインスタンスを削除して、新しいインスタンスを起動した。その後電話会議は終了し、私はデータセンターを離れた。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml35(para) msgid """" ""At the data center, I was finishing up some tasks and remembered the lock-"" ""up. I logged into the new instance and ran ps aux again. It worked. Phew. I "" ""decided to run it one more time. It locked up. WTF."" msgstr ""データセンターで、私はいくつかの仕事を済ませると、ロックアップのことを思い出した。私は新しいインスタンスにログインし、再度 ps aux を実行した。コマンドは機能した。ふぅ。私はもう一度試してみることにした。今度はロックアップした。何だこれは？"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml39(para) msgid """" ""After reproducing the problem several times, I came to the unfortunate "" ""conclusion that this cloud did indeed have a problem. Even worse, my time "" ""was up in Kelowna and I had to return back to Calgary."" msgstr ""何度か問題が再現した後、私はこのクラウドが実は問題を抱えているという不幸な結論に至った。更に悪いことに、私がケロウナから出発する時間になっており、カルガリーに戻らなければならなかった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml43(para) msgid """" ""Where do you even begin troubleshooting something like this? An instance "" ""just randomly locks when a command is issued. Is it the image? Nope — it "" ""happens on all images. Is it the compute node? Nope — all nodes. Is the "" ""instance locked up? No! New SSH connections work just fine!"" msgstr ""どこかであなたはこのような障害調査を行ったことがあるだろうか？インスタンスはコマンドを打つ度に全くランダムにロックアップしてしまう。元になったイメージの問題か？No－全てのイメージで同じ問題が発生する。コンピュートノードの問題か？No－全てのノードで発生する。インスタンスはロックアップしたのか？No！新しいSSH接続は問題なく機能する！"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml48(para) msgid """" ""We reached out for help. A networking engineer suggested it was an MTU "" ""issue. Great! MTU! Something to go on! What's MTU and why would it cause a "" ""problem?"" msgstr ""我々は助けを求めた。ネットワークエンジニアは、これは MTU の問題ではないかというのだ。素晴らしい！MTU! 事態は動き始めた! MTU とは何で、何故それが問題になるのだろうか？"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml56(para) #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml64(para) msgid """" ""Not all packets have a size of 1500. Running the ls command over SSH might "" ""only create a single packets less than 1500 bytes. However, running a "" ""command with heavy output, such as <placeholder-1/> requires several packets"" "" of 1500 bytes."" msgstr ""すべてのパケットサイズが 1500 に収まるわけではない。SSH 経由の ls コマンド実行は 1500 バイト未満のサイズのパケット１つで収まるかもしれない。しかし、 <placeholder-1/> のように多大な出力を行うコマンドを実行する場合、1500 バイトのパケットが複数必要とある。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml51(para) msgid """" ""MTU is maximum transmission unit. It specifies the maximum number of bytes "" ""that the interface accepts for each packet. If two interfaces have two "" ""different MTUs, bytes might get chopped off and weird things happen -- such "" ""as random session lockups.<placeholder-1/>"" msgstr ""MTU とは最大転送単位（Maximum Transmission Unit）である。これは、各パケットに対してそのインターフェースが受け取る最大バイト数を指定する。もし２つのインターフェースが異なる MTU であった場合、バイトは尻切れトンボとなって変なことが起こり始める…例えばセッションのランダムなロックアップとか。<placeholder-1/>"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml70(para) msgid """" ""OK, so where is the MTU issue coming from? Why haven't we seen this in any "" ""other deployment? What's new in this situation? Well, new data center, new "" ""uplink, new switches, new model of switches, new servers, first time using "" ""this model of servers… so, basically everything was new. Wonderful. We toyed"" "" around with raising the MTU at various areas: the switches, the NICs on the"" "" compute nodes, the virtual NICs in the instances, we even had the data "" ""center raise the MTU for our uplink interface. Some changes worked, some "" ""didn't. This line of troubleshooting didn't feel right, though. We shouldn't"" "" have to be changing the MTU in these areas."" msgstr ""OK。では MTU の問題はどこから来るのか？なぜ我々は他のデプロイでこの問題に遭遇しなかったのか？この状況は何が新しいのか？えっと、新しいデータセンター、新しい上位リンク、新しいスイッチ、スイッチの新機種、新しいサーバー、サーバーの新機種…つまり、基本的に全てが新しいものだった。素晴らしい。我々は様々な領域で MTU の増加を試してみた。スイッチ、コンピュータのNIC、インスタンスの仮想NIC、データセンターの上位リンク用のインターフェースのMTUまでいじってみた。いくつかの変更ではうまくいったが、他はダメだった。やはり、この線の障害対策はうまくいってないようだった。我々はこれらの領域のMTUは変更すべきではないようだ。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml82(para) msgid """" ""As a last resort, our network admin (Alvaro) and myself sat down with four "" ""terminal windows, a pencil, and a piece of paper. In one window, we ran "" ""ping. In the second window, we ran tcpdump on the cloud controller. In the "" ""third, tcpdump on the compute node. And the forth had tcpdump on the "" ""instance. For background, this cloud was a multi-node, non-multi-host setup."" msgstr ""結局、我々のネットワーク管理者（Alvao）と私自身は４つのターミナルウィンドウ、１本の鉛筆と紙切れを持って座った。１つのウインドウで我々は ping を実行した。２つ目のウインドウではクラウドコントローラー上の tcpdump、３つ目ではコンピュートノード上の tcpdump、４つ目ではインスタンス上の tcpdump を実行した。前提として、このクラウドはマルチノード、非マルチホスト構成である。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml89(para) msgid """" ""One cloud controller acted as a gateway to all compute nodes. VlanManager "" ""was used for the network config. This means that the cloud controller and "" ""all compute nodes had a different VLAN for each OpenStack project. We used "" ""the -s option of ping to change the packet size. We watched as sometimes "" ""packets would fully return, sometimes they'd only make it out and never back"" "" in, and sometimes the packets would stop at a random point. We changed "" ""tcpdump to start displaying the hex dump of the packet. We pinged between "" ""every combination of outside, controller, compute, and instance."" msgstr ""１つのクラウドコントローラーが全コンピュートノードのゲートウェイの役割を果たしていた。ネットワーク設定には VlanManager が使われていた。これは、クラウドコントローラーと全コンピュートノードで、各 OpenStack プロジェクトが異なる VLAN を持つことを意味する。パケットサイズ変更のため、ping の -s オプションを使用していた。パケットが全て戻ってくる時もあれば、パケットが出ていったきり全く戻って来ない時もあれば、パケットはランダムな場所で止まってしまう時もある、という状況だった。tcpdump を変更し、パケットの16進ダンプを表示するようにした。外部、コントローラー、コンピュート、インスタンスのあらゆる組み合わせの間で ping を実行した。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml100(para) msgid """" ""Finally, Alvaro noticed something. When a packet from the outside hits the "" ""cloud controller, it should not be configured with a VLAN. We verified this "" ""as true. When the packet went from the cloud controller to the compute node,"" "" it should only have a VLAN if it was destined for an instance. This was "" ""still true. When the ping reply was sent from the instance, it should be in "" ""a VLAN. True. When it came back to the cloud controller and on its way out "" ""to the public internet, it should no longer have a VLAN. False. Uh oh. It "" ""looked as though the VLAN part of the packet was not being removed."" msgstr ""遂に、Alvaro が何かを掴んだ。外部からのパケットがクラウドコントローラーを叩いた際、パケットは VLAN で設定されるべきではない。我々はこれが正しいことを検証した。パケットがクラウドコントローラーからコンピュートノードに行く際、パケットはインスタンス宛の場合にのみ VLAN を持つべきである。これもまた正しかった。ping のレスポンスがインスタンスから送られる際、パケットは VLAN 中にいるべきである。ＯＫ。クラウドコントローラーからパブリックインターネットにパケットが戻る際、パケットには VLAN を持つべきではない。ＮＧ。うぉっ。まるで パケットの VLAN 部分が削除されていないように見える。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml111(para) msgid ""That made no sense."" msgstr ""これでは意味が無かった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml112(para) msgid """" ""While bouncing this idea around in our heads, I was randomly typing commands"" "" on the compute node:"" msgstr ""このアイデアが我々の頭を駆け巡る間、私はコンピュートノード上でコマンドをランダムに叩いていた。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml118(para) msgid ""\""Hey Alvaro, can you run a VLAN on top of a VLAN?\"""" msgstr ""「Alvaro、VLAN 上に VLAN って作れるのかい？」"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml120(para) msgid ""\""If you did, you'd add an extra 4 bytes to the packet…\"""" msgstr ""「もしやったら、パケットに余計に４バイト追加になるよ…」"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml122(para) msgid ""Then it all made sense…"" msgstr ""やっと事の全容が判明した…"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml125(para) msgid """" ""In <code>nova.conf</code>, <code>vlan_interface</code> specifies what "" ""interface OpenStack should attach all VLANs to. The correct setting should "" ""have been: <code>vlan_interface=bond0</code>."" msgstr ""<code>nova.conf</code> 中で、<code>vlan_interface</code> は OpenStack が全ての VLAN をアタッチすべきインターフェースがどれかを指定する。正しい設定はこうだった: <code>vlan_interface=bond0</code>"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml129(para) msgid ""As this would be the server's bonded NIC."" msgstr ""これはサーバーの冗長化された（bonded）NIC であるべきだからだ。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml130(para) msgid """" ""vlan20 is the VLAN that the data center gave us for outgoing public internet"" "" access. It's a correct VLAN and is also attached to bond0."" msgstr ""vlan20 はデータセンターが外向けのパブリックなインターネットアクセス用に我々に付与した VLAN である。これは正しい VLAN で bond0 にアタッチされている。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml133(para) msgid """" ""By mistake, I configured OpenStack to attach all tenant VLANs to vlan20 "" ""instead of bond0 thereby stacking one VLAN on top of another which then "" ""added an extra 4 bytes to each packet which cause a packet of 1504 bytes to "" ""be sent out which would cause problems when it arrived at an interface that "" ""only accepted 1500!"" msgstr ""ミスにより、私は全てのテナント VLAN を bond0 の代わりに vlan20 にアタッチするよう OpenStack を設定した。それによって１つの VLAN が別の VLAN の上に積み重なり、各パケットに余分に４バイトが追加され、送信されるパケットサイズが 1504 バイトになる原因となった。これがパケットサイズ 1500 のみ許容するインターフェースに到達した際、問題の原因となったのだった！"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml139(para) msgid ""As soon as this setting was fixed, everything worked."" msgstr ""全力でこの問題を修正した結果、全てが正常に動作するようになった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml143(title) msgid ""\""The Issue\"""" msgstr ""「あの問題」"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml144(para) msgid """" ""At the end of August 2012, a post-secondary school in Alberta, Canada "" ""migrated its infrastructure to an OpenStack cloud. As luck would have it, "" ""within the first day or two of it running, one of their servers just "" ""disappeared from the network. Blip. Gone."" msgstr ""2012年8月の終わり、カナダ アルバータ州のある大学はそのインフラを OpenStack クラウドに移行した。幸か不幸か、サービスインから1～2日間に、彼らのサーバーの1台がネットワークから消失した。ビッ。いなくなった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml149(para) msgid """" ""After restarting the instance, everything was back up and running. We "" ""reviewed the logs and saw that at some point, network communication stopped "" ""and then everything went idle. We chalked this up to a random occurrence."" msgstr ""インスタンスの再起動後、全ては元通りに動くようになった。我々はログを見直し、問題の箇所（ネットワーク通信が止まり、全ては待機状態になった）を見た。我々はランダムな事象の原因はこのインスタンスだと判断した。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml154(para) msgid ""A few nights later, it happened again."" msgstr ""数日後、それは再び起こった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml155(para) msgid """" ""We reviewed both sets of logs. The one thing that stood out the most was "" ""DHCP. OpenStack, by default, sets DHCP leases for one minute. This means "" ""that every instance contacts the cloud controller (DHCP server) to renew its"" "" fixed IP. For some reason, this instance could not renew its IP. We "" ""correlated the instance's logs with the logs on the cloud controller and put"" "" together a conversation:"" msgstr ""我々はログのセットを両方見直した。頻発したログの１つは DHCP だった。OpenStack は（デフォルトで）DHCP リース期間を１分に設定する。これは、各インスタンスが固定 IP アドレスを更新するためにクラウドコントローラー（DHCP サーバー）に接続することを意味する。幾つかの理由で、このインスタンスはその IP アドレスを更新できなかった。インスタンスのログとクラウドコントローラー上のログを突き合わせ、並べてやりとりにしてみた。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml165(para) msgid ""Instance tries to renew IP."" msgstr ""インスタンスはIPアドレスを更新しようとする。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml168(para) msgid ""Cloud controller receives the renewal request and sends a response."" msgstr ""クラウドコントローラーは更新リクエストを受信し、レスポンスを返す。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml172(para) msgid ""Instance \""ignores\"" the response and re-sends the renewal request."" msgstr ""インスタンスはそのレスポンスを「無視」して、更新リクエストを再送する。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml176(para) msgid ""Cloud controller receives the second request and sends a new response."" msgstr ""クラウドコントローラーは２度めのリクエストを受信し、新しいレスポンスを返す。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml180(para) msgid """" ""Instance begins sending a renewal request to <code>255.255.255.255</code> "" ""since it hasn't heard back from the cloud controller."" msgstr ""インスタンスはクラウドコントローラーからのレスポンスを受信しなかったため、更新リクエストを<code>255.255.255.255</code>に送信し始める。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml185(para) msgid """" ""The cloud controller receives the <code>255.255.255.255</code> request and "" ""sends a third response."" msgstr ""クラウドコントローラーは <code>255.255.255.255</code> 宛のリクエストを受信し、３番めのレスポンスを返す。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml190(para) msgid ""The instance finally gives up."" msgstr ""最終的に、インスタンスはIPアドレス取得を諦める。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml193(para) msgid """" ""With this information in hand, we were sure that the problem had to do with "" ""DHCP. We thought that for some reason, the instance wasn't getting a new IP "" ""address and with no IP, it shut itself off from the network."" msgstr ""この情報により、我々は問題が DHCP 実行に起因するものと確信した。何らかの理由でインスタンスが新しいIPアドレスを取得できず、その結果IPアドレスがなくなり、インスタンスは自分自身をネットワークから切り離した、と考えた。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml197(para) msgid """" ""A quick Google search turned up this: <link xlink:title=\""DAIR project\"" "" ""xlink:href=\""https://lists.launchpad.net/openstack/msg11696.html\"">DHCP lease "" ""errors in VLAN mode</link> "" ""(https://lists.launchpad.net/openstack/msg11696.html) which further "" ""supported our DHCP theory."" msgstr ""ちょっと Google 検索した結果、これを見つけた。<link xlink:title=\""DAIR project\"" xlink:href=\""https://lists.launchpad.net/openstack/msg11696.html\"">VLAN モードでの DHCPリースエラー</link> (https://lists.launchpad.net/openstack/msg11696.html) 。この情報はその後の我々の DHCP 方針の支えになった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml203(para) msgid """" ""An initial idea was to just increase the lease time. If the instance only "" ""renewed once every week, the chances of this problem happening would be "" ""tremendously smaller than every minute. This didn't solve the problem, "" ""though. It was just covering the problem up."" msgstr ""最初のアイデアは、単にリース時間を増やすことだった。もしインスタンスが毎週１回だけIPアドレスを更新するのであれば、毎分更新する場合よりこの問題が起こる可能性は極端に低くなるだろう。これはこの問題を解決しないが、問題を単に取り繕うことはできる。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml208(para) msgid """" ""We decided to have <code>tcpdump</code> run on this instance and see if we "" ""could catch it in action again. Sure enough, we did."" msgstr ""我々は、このインスタンス上で <code>tcpdump</code> を実行して、操作で再びこの現象に遭遇するか見てみることにした。実際、我々はやってみた。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml211(para) msgid """" ""The <code>tcpdump</code> looked very, very weird. In short, it looked as "" ""though network communication stopped before the instance tried to renew its "" ""IP. Since there is so much DHCP chatter from a one minute lease, it's very "" ""hard to confirm it, but even with only milliseconds difference between "" ""packets, if one packet arrives first, it arrived first, and if that packet "" ""reported network issues, then it had to have happened before DHCP."" msgstr ""<code>tcpdump</code> の結果は非常に奇妙だった。一言で言えば、インスタンスが IP アドレスを更新しようとする前に、まるでネットワーク通信が停止しているように見えた。１分間のリース期間で大量の DHCP ネゴシエーションがあるため、確認作業は困難を極めた。しかし、パケット間のたった数ミリ秒の違いであれ、あるパケットが最初に到着する際、そのパケットが最初に到着し、そのパケットがネットワーク障害を報告した場合、DHCP より前にネットワーク障害が発生していることになる。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml219(para) msgid """" ""Additionally, this instance in question was responsible for a very, very "" ""large backup job each night. While \""The Issue\"" (as we were now calling it)"" "" didn't happen exactly when the backup happened, it was close enough (a few "" ""hours) that we couldn't ignore it."" msgstr ""加えて、問題のインスタンスは毎晩非常に長いバックアップジョブを担っていた。「あの問題」（今では我々はこの障害をこう呼んでいる）はバックアップが行われている最中には起こらなかったが、（数時間たっていて）「あの問題」が起こるまであと少しのところだった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml224(para) msgid """" ""Further days go by and we catch The Issue in action more and more. We find "" ""that dhclient is not running after The Issue happens. Now we're back to "" ""thinking it's a DHCP issue. Running <code>/etc/init.d/networking</code> "" ""restart brings everything back up and running."" msgstr ""それから何日か過ぎ、我々は「あの問題」に度々遭遇した。我々は「あの問題」の発生後、dhclient が実行されていないことを発見した。今、我々は、それが DHCP の問題であるという考えに立ち戻った。<code>/etc/init.d/networking</code> restart を実行すると、全ては元通りに実行されるようになった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml229(para) msgid """" ""Ever have one of those days where all of the sudden you get the Google "" ""results you were looking for? Well, that's what happened here. I was looking"" "" for information on dhclient and why it dies when it can't renew its lease "" ""and all of the sudden I found a bunch of OpenStack and dnsmasq discussions "" ""that were identical to the problem we were seeing!"" msgstr ""探し続けてきた Google の検索結果が突然得られたという事態をお分かりだろうか？えっと、それがここで起こったことだ。私は dhclient の情報と、何故 dhclient がそのリースを更新できない場合に死ぬのかを探していて、我々が遭遇したのと同じ問題についての OpenStack と dnsmasq の議論の束を突然発見した。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml236(para) msgid """" ""<link xlink:title=\""DAIR project\"" xlink:href=\""http://www.gossamer-"" ""threads.com/lists/openstack/operators/18197\"">Problem with Heavy Network IO "" ""and Dnsmasq</link> (http://www.gossamer-"" ""threads.com/lists/openstack/operators/18197)"" msgstr ""<link xlink:title=\""DAIR project\"" xlink:href=\""http://www.gossamer-threads.com/lists/openstack/operators/18197\"">高負荷ネットワークと Dnsmasq における問題</link> (http://www.gossamer-threads.com/lists/openstack/operators/18197)"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml241(para) msgid """" ""<link xlink:title=\""DAIR project\"" xlink:href=\""http://www.gossamer-"" ""threads.com/lists/openstack/dev/14696\"">instances loosing IP address while "" ""running, due to No DHCPOFFER</link> (http://www.gossamer-"" ""threads.com/lists/openstack/dev/14696)"" msgstr ""<link xlink:title=\""DAIR project\"" xlink:href=\""http://www.gossamer-threads.com/lists/openstack/dev/14696\"">DHCPOFFER が無いために起動中のインスタンスが IP アドレスを失う問題</link> (http://www.gossamer-threads.com/lists/openstack/dev/14696)"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml247(para) msgid ""Seriously, Google."" msgstr ""マジ？Google。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml248(para) msgid ""This bug report was the key to everything:"" msgstr ""このバグ報告は全ての鍵だった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml249(para) msgid """" ""<link xlink:title=\""DAIR project\"" "" ""xlink:href=\""https://bugs.launchpad.net/ubuntu/+source/qemu-kvm/+bug/997978\""> KVM"" "" images lose connectivity with bridged network</link> "" ""(https://bugs.launchpad.net/ubuntu/+source/qemu-kvm/+bug/997978)"" msgstr ""<link xlink:title=\""DAIR project\"" xlink:href=\""https://bugs.launchpad.net/ubuntu/+source/qemu-kvm/+bug/997978\""> KVMイメージがブリッジネットワークで接続を失う</link> (https://bugs.launchpad.net/ubuntu/+source/qemu-kvm/+bug/997978)"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml255(para) msgid """" ""It was funny to read the report. It was full of people who had some strange "" ""network problem but didn't quite explain it in the same way."" msgstr ""レポートを読むのは楽しかった。同じ奇妙なネットワーク問題にあった人々であふれていたが、全く同じ説明はなかった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml258(para) msgid ""So it was a qemu/kvm bug."" msgstr ""つまり、これは qemu/kvm のバグである。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml259(para) msgid """" ""At the same time of finding the bug report, a co-worker was able to "" ""successfully reproduce The Issue! How? He used iperf to spew a ton of "" ""bandwidth at an instance. Within 30 minutes, the instance just disappeared "" ""from the network."" msgstr ""バグ報告を発見すると同時に、同僚が「あの問題」を再現することに成功した！どうやって？彼は iperf を使用して、インスタンス上で膨大なネットワーク負荷をかけた。30分後、インスタンスはネットワークから姿を消した。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml264(para) msgid """" ""Armed with a patched qemu and a way to reproduce, we set out to see if we've"" "" finally solved The Issue. After 48 hours straight of hammering the instance"" "" with bandwidth, we were confident. The rest is history. You can search the "" ""bug report for \""joe\"" to find my comments and actual tests."" msgstr ""パッチを当てた qemu と再現方法を携えて、我々は「あの問題」を最終的に解決したかを確認する作業に着手した。インスタンスにネットワーク負荷をかけてから丸48時間後、我々は確信していた。その後のことは知っての通りだ。あなたは、joe へのバグ報告を検索し、私のコメントと実際のテストを見つけることができる。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml272(title) msgid ""Disappearing Images"" msgstr ""イメージの消失"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml273(para) msgid """" ""At the end of 2012, Cybera (a nonprofit with a mandate to oversee the "" ""development of cyberinfrastructure in Alberta, Canada) deployed an updated "" ""OpenStack cloud for their <link xlink:title=\""DAIR project\"" "" ""xlink:href=\""http://www.canarie.ca/en/dair-program/about\"">DAIR project</link> "" ""(http://www.canarie.ca/en/dair-program/about). A few days into production, a"" "" compute node locks up. Upon rebooting the node, I checked to see what "" ""instances were hosted on that node so I could boot them on behalf of the "" ""customer. Luckily, only one instance."" msgstr ""2012年の終わり、Cybera （カナダ アルバータ州にある、サイバーインフラのデプロイを監督する権限を持つ非営利団体）が、彼らの <link xlink:title=\""DAIR project\"" xlink:href=\""http://www.canarie.ca/en/dair-program/about\"">DAIR プロジェクト</link> (http://www.canarie.ca/en/dair-program/about) 用に新しい OpenStack クラウドをデプロイした。サービスインから数日後、あるコンピュートノードがロックアップした。問題のノードの再起動にあたり、私は顧客の権限でインスタンスを起動するため、そのノード上で何のインスタンスがホスティングされていたかを確認した。幸運にも、インスタンスは１つだけだった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml284(para) msgid """" ""The <code>nova reboot</code> command wasn't working, so I used "" ""<code>virsh</code>, but it immediately came back with an error saying it was"" "" unable to find the backing disk. In this case, the backing disk is the "" ""Glance image that is copied to <code>/var/lib/nova/instances/_base</code> "" ""when the image is used for the first time. Why couldn't it find it? I "" ""checked the directory and sure enough it was gone."" msgstr ""<code>nova reboot</code> コマンドは機能しなかったので、<code>virsh</code> を使用したが、すぐに仮想ディスクが見つからないとのエラーが返ってきた。この場合、仮想ディスクは Glance イメージで、イメージが最初に使用する際に <code>/var/lib/nova/instances/_base</code> にコピーされていた。何故イメージが見つからないのか？私はそのディレクトリをチェックし、イメージがないことを知った。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml293(para) msgid """" ""I reviewed the <code>nova</code> database and saw the instance's entry in "" ""the <code>nova.instances</code> table. The image that the instance was using"" "" matched what virsh was reporting, so no inconsistency there."" msgstr ""私は <code>nova</code> データベースを見直し、<code>nova.instances</code> テーブル中の当該インスタンスのレコードを見た。インスタンスが使用しているイメージは virsh が報告したものと一致した。よって、ここでは矛盾は発見されなかった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml297(para) msgid """" ""I checked Glance and noticed that this image was a snapshot that the user "" ""created. At least that was good news — this user would have been the only "" ""user affected."" msgstr ""私は Glance をチェックし、問題のイメージがそのユーザの作成したスナップショットであることに注目した。最終的に、それはグッドニュースだった。このユーザが影響を受けた唯一のユーザだった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml301(para) msgid """" ""Finally, I checked StackTach and reviewed the user's events. They had "" ""created and deleted several snapshots — most likely experimenting. Although "" ""the timestamps didn't match up, my conclusion was that they launched their "" ""instance and then deleted the snapshot and it was somehow removed from "" ""<code>/var/lib/nova/instances/_base</code>. None of that made sense, but it "" ""was the best I could come up with."" msgstr ""最後に、私は StackTack をチェックし、ユーザのイベントを見直した。彼らはいくつかのスナップショットを作ったり消したりしていた－ありそうな操作ではあるが。タイムスタンプが一致しないとはいえ、彼らがインスタンスを起動して、その後スナップショットを削除し、それが何故か <code>/var/lib/nova/instances/_base</code> から削除されたというのが私の結論だった。大した意味は無かったが、それがその時私が得た全てだった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml310(para) msgid """" ""It turns out the reason that this compute node locked up was a hardware "" ""issue. We removed it from the DAIR cloud and called Dell to have it "" ""serviced. Dell arrived and began working. Somehow or another (or a fat "" ""finger), a different compute node was bumped and rebooted. Great."" msgstr ""コンピュートノードがロックアップした原因はハードウェアの問題だったことが判明した。我々はそのハードウェアを DAIR クラウドから取り外し、修理するよう Dell に依頼した。Dell が到着して作業を開始した。何とかかんとか（あるいはタイプミス）で、異なるコンピュートノードを落としてしまい、再起動した。素晴らしい。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml316(para) msgid """" ""When this node fully booted, I ran through the same scenario of seeing what "" ""instances were running so I could turn them back on. There were a total of "" ""four. Three booted and one gave an error. It was the same error as before: "" ""unable to find the backing disk. Seriously, what?"" msgstr ""そのノードが完全に起動した際、インスタンスが起動した時に何が起こるのかを見るため、私は同じシナリオを実行して、インスタンスを復旧した。インスタンスは全部で４つあった。３つは起動し、１つはエラーになった。このエラーは以前のエラーと同じだった。「unable to find the backing disk.」マジ、何で？"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml322(para) msgid """" ""Again, it turns out that the image was a snapshot. The three other instances"" "" that successfully started were standard cloud images. Was it a problem with"" "" snapshots? That didn't make sense."" msgstr ""再度、イメージがスナップショットであることが判明した。無事に起動した他の３インスタンスは標準のクラウドイメージであった。これはスナップショットの問題か？それは意味が無かった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml326(para) msgid """" ""A note about DAIR's architecture: <code>/var/lib/nova/instances</code> is a "" ""shared NFS mount. This means that all compute nodes have access to it, which"" "" includes the <code>_base</code> directory. Another centralized area is "" ""<code>/var/log/rsyslog</code> on the cloud controller. This directory "" ""collects all OpenStack logs from all compute nodes. I wondered if there were"" "" any entries for the file that <code>virsh</code> is reporting:"" msgstr ""DAIR のアーキテクチャは <code>/var/lib/nova/instances</code> が共有 NFS マウントであることに注意したい。これは、全てのコンピュートノードがそのディレクトリにアクセスし、その中に <code>_base</code> ディレクトリが含まれることを意味していた。その他の集約化エリアはクラウドコントローラーの <code>/var/log/rsyslog</code> だ。このディレクトリは全コンピュートノードの全ての OpenStack ログが収集されていた。私は、<code>virsh</code> が報告したファイルに関するエントリがあるのだろうかと思った。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml336(code) msgid """" ""dair-ua-c03/nova.log:Dec 19 12:10:59 dair-ua-c03 2012-12-19 12:10:59 INFO "" ""nova.virt.libvirt.imagecache [-] Removing base file: "" ""/var/lib/nova/instances/_base/7b4783508212f5d242cbf9ff56fb8d33b4ce6166_10"" msgstr ""dair-ua-c03/nova.log:Dec 19 12:10:59 dair-ua-c03 2012-12-19 12:10:59 INFO nova.virt.libvirt.imagecache [-] Removing base file: /var/lib/nova/instances/_base/7b4783508212f5d242cbf9ff56fb8d33b4ce6166_10"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml341(para) msgid ""Ah-hah! So OpenStack was deleting it. But why?"" msgstr ""あっはっは！じゃぁ、OpenStack が削除したのか。でも何故？"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml342(para) msgid """" ""A feature was introduced in Essex to periodically check and see if there "" ""were any _base files not in use. If there were, Nova would delete them. This"" "" idea sounds innocent enough and has some good qualities to it. But how did "" ""this feature end up turned on? It was disabled by default in Essex. As it "" ""should be. It was <link "" ""xlink:href=\""https://bugs.launchpad.net/nova/+bug/1029674\"">decided to be turned "" ""on in Folsom</link> (https://bugs.launchpad.net/nova/+bug/1029674). I cannot"" "" emphasize enough that:"" msgstr ""Essex で、_base 下の任意のファイルが使用されていないかどうか定期的にチェックして確認する機能が導入された。もしあれば、Nova はそのファイルを削除する。このアイデアは問題がないように見え、品質的にも良いようだった。しかし、この機能を有効にすると最終的にどうなるのか？Essex ではこの機能がデフォルトで無効化されていた。そうあるべきであったからだ。これは、<link xlink:href=\""https://bugs.launchpad.net/nova/+bug/1029674 \"">Folsom で有効になることが決定された</link> (https://bugs.launchpad.net/nova/+bug/1029674)。私はそうあるべきとは思わない。何故なら"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml353(emphasis) msgid ""Actions which delete things should not be enabled by default."" msgstr ""何かを削除する操作はデフォルトで有効化されるべきではない。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml356(para) msgid ""Disk space is cheap these days. Data recovery is not."" msgstr ""今日、ディスクスペースは安価である。データの復元はそうではない。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml358(para) msgid """" ""Secondly, DAIR's shared <code>/var/lib/nova/instances</code> directory "" ""contributed to the problem. Since all compute nodes have access to this "" ""directory, all compute nodes periodically review the _base directory. If "" ""there is only one instance using an image, and the node that the instance is"" "" on is down for a few minutes, it won't be able to mark the image as still "" ""in use. Therefore, the image seems like it's not in use and is deleted. When"" "" the compute node comes back online, the instance hosted on that node is "" ""unable to start."" msgstr ""次に、DAIR の共有された <code>/var/lib/nova/instances</code> が問題を助長した。全コンピュートノードがこのディレクトリにアクセスするため、全てのコンピュートノードは定期的に _base ディレクトリを見直していた。あるイメージを使用しているインスタンスが１つだけあり、そのインスタンスが存在するノードが数分間ダウンした場合、そのイメージが使用中であるという印を付けられなくなる。それゆえ、イメージは使用中に見えず、削除されてしまったのだ。そのコンピュートノードが復帰した際、そのノード上でホスティングされていたインスタンスは起動できない。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml371(title) msgid ""The Valentine's Day Compute Node Massacre"" msgstr ""バレンタインデーのコンピュートノード大虐殺"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml372(para) msgid """" ""Although the title of this story is much more dramatic than the actual "" ""event, I don't think, or hope, that I'll have the opportunity to use "" ""\""Valentine's Day Massacre\"" again in a title."" msgstr ""この物語のタイトルは実際の事件よりかなりドラマティックだが、私はタイトル中に「バレンタインデーの大虐殺」を使用する機会が再びあるとは思わない（し望まない）。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml376(para) msgid """" ""This past Valentine's Day, I received an alert that a compute node was no "" ""longer available in the cloud — meaning,"" msgstr ""この前のバレンタインデーに、クラウド中にあるコンピュートノードが最早動いていないとの警告を受け取った。つまり"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml380(para) msgid ""showed this particular node with a status of <code>XXX</code>."" msgstr ""の出力で、この特定のノードの状態が <code>XXX</code> になっていた。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml382(para) msgid """" ""I logged into the cloud controller and was able to both ping and SSH into "" ""the problematic compute node which seemed very odd. Usually if I receive "" ""this type of alert, the compute node has totally locked up and would be "" ""inaccessible."" msgstr ""実に奇妙なことだが、私はクラウドコントローラーにログインし、問題のコンピュートノードに ping と SSH の両方を実行できた。通常、この種の警告を受け取ると、コンピュートノードは完全にロックしていてアクセス不可になる。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml387(para) msgid ""After a few minutes of troubleshooting, I saw the following details:"" msgstr ""数分間のトラブル調査の後、以下の詳細が判明した。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml391(para) msgid ""A user recently tried launching a CentOS instance on that node"" msgstr ""最近、あるユーザがそのノード上で CentOS のインスタンスを起動しようとした。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml395(para) msgid ""This user was the only user on the node (new node)"" msgstr ""このユーザはそのノード（新しいノード）上の唯一のユーザだった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml399(para) msgid ""The load shot up to 8 right before I received the alert"" msgstr ""私が警告を受け取る直前、負荷率は８に急増した。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml403(para) msgid ""The bonded 10gb network device (bond0) was in a DOWN state"" msgstr ""冗長化された 10Gb ネットワークデバイス(bond0）は DOWN 状態だった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml407(para) msgid ""The 1gb NIC was still alive and active"" msgstr ""1Gb NICはまだ生きていて、有効だった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml410(para) msgid """" ""I looked at the status of both NICs in the bonded pair and saw that neither "" ""was able to communicate with the switch port. Seeing as how each NIC in the "" ""bond is connected to a separate switch, I thought that the chance of a "" ""switch port dying on each switch at the same time was quite improbable. I "" ""concluded that the 10gb dual port NIC had died and needed replaced. I "" ""created a ticket for the hardware support department at the data center "" ""where the node was hosted. I felt lucky that this was a new node and no one "" ""else was hosted on it yet."" msgstr ""私は bonding ペアの両方の NIC の状態を確認し、両方ともスイッチポートへの通信ができないことを知った。bond 中の各 NIC が異なるスイッチに接続されていることを知り、私は、各スイッチのスイッチポートが同時に死ぬ可能性はまずないと思った。私は 10Gb デュアルポート NIC が死んで、交換が必要だと結論づけた。私は、そのノードがホスティングされているデータセンターのハードウェアサポート部門に宛てたチケットを作成した。私は、それが新しいノードで、他のインスタンスがまだそのノード上でホスティングされていないことを幸運に思った。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml420(para) msgid """" ""An hour later I received the same alert, but for another compute node. Crap."" "" OK, now there's definitely a problem going on. Just like the original node,"" "" I was able to log in by SSH. The bond0 NIC was DOWN but the 1gb NIC was "" ""active."" msgstr ""１時間後、私は同じ警告を受信したが、別のコンピュートノードだった。拍手。OK、問題は間違いなく現在進行中だ。元のノードと全く同様に、私は SSH でログインすることが出来た。bond0 NIC は DOWN だったが、1Gb NIC は有効だった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml425(para) msgid """" ""And the best part: the same user had just tried creating a CentOS instance. "" ""Wat?"" msgstr ""そして、最も重要なこと。同じユーザが CentOS インスタンスを作成しようとしたばかりだった。何だと？"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml427(para) msgid """" ""I was totally confused at this point, so I texted our network admin to see "" ""if he was available to help. He logged in to both switches and immediately "" ""saw the problem: the switches detected spanning tree packets coming from the"" "" two compute nodes and immediately shut the ports down to prevent spanning "" ""tree loops:"" msgstr ""私はこの時点で完全に混乱した。よって、私はネットワーク管理者に対して、私を助けられるか聞いてみるためメールした。彼は両方のスイッチにログインし、すぐに問題を発見した。そのスイッチは２つのコンピュートノードから来たスパニングツリーパケットを検出し、スパニングツリーループを回避するため、即時にそれらのポートをダウンさせたのだ。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml439(para) msgid """" ""He re-enabled the switch ports and the two compute nodes immediately came "" ""back to life."" msgstr ""彼はスイッチポートを再度有効にしたところ、２つのコンピュートノードは即時に復活した。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml441(para) msgid """" ""Unfortunately, this story has an open ending... we're still looking into why"" "" the CentOS image was sending out spanning tree packets. Further, we're "" ""researching a proper way on how to mitigate this from happening. It's a "" ""bigger issue than one might think. While it's extremely important for "" ""switches to prevent spanning tree loops, it's very problematic to have an "" ""entire compute node be cut from the network when this happens. If a compute "" ""node is hosting 100 instances and one of them sends a spanning tree packet, "" ""that instance has effectively DDOS'd the other 99 instances."" msgstr ""不幸にも、この話にはエンディングがない…我々は、なぜ CentOS イメージがスパニングツリーパケットを送信し始める原因をいまだ探している。更に、我々は障害時にスパニングツリーを軽減する正しい方法を調査している。これは誰かが思うより大きな問題だ。スパニングツリーループを防ぐことはスイッチにとって非常に重要であるが、スパニングツリーが起こった際に、コンピュートノード全体がネットワークから切り離されることも大きな問題である。コンピュートノードが 100 インスタンスをホスティングしていて、そのうち１つがスパニングツリーパケットを送信した場合、そのインスタンスは事実上他の 99 インスタンスを DDoS（サービス不能攻撃）したことになる。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml452(para) msgid """" ""This is an ongoing and hot topic in networking circles — especially with the"" "" raise of virtualization and virtual switches."" msgstr ""これはネットワーク業界で進行中で話題のトピックである（特に仮想マシンと仮想スイッチで発生する）。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml457(title) msgid ""Down the Rabbit Hole"" msgstr ""ウサギの穴に落ちて"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml458(para) msgid """" ""Users being able to retrieve console logs from running instances is a boon "" ""for support — many times they can figure out what's going on inside their "" ""instance and fix what's going on without bothering you. Unfortunately, "" ""sometimes overzealous logging of failures can cause problems of its own."" msgstr ""稼働中のインスタンスからコンソールログを取得可能なユーザはサポートの恩恵となる（インスタンスの中で何が起こっているのか何度も確認できるし、あなたが悩まずに問題を修正することができる）。不幸なことに、過剰な失敗の記録は時々、自らの問題となり得る。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml464(para) msgid """" ""A report came in: VMs were launching slowly, or not at all. Cue the standard"" "" checks — nothing on the nagios, but there was a spike in network towards "" ""the current master of our RabbitMQ cluster. Investigation started, but soon "" ""the other parts of the queue cluster were leaking memory like a sieve. Then "" ""the alert came in — the master rabbit server went down. Connections failed "" ""over to the slave."" msgstr ""報告が入った。VM の起動が遅いか、全く起動しない。標準のチェック項目は？Nagios 上は問題なかったが、RabbitMQ クラスタの現用系に向かうネットワークのみ高負荷を示していた。捜査を開始したが、すぐに RabbitMQ クラスタの別の部分がざるのようにメモリリークを起こしていることを発見した。また警報か？RabbitMQ サーバーの現用系はダウンしようとしていた。接続は待機系にフェイルオーバーした。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml471(para) msgid """" ""At that time, our control services were hosted by another team and we didn't"" "" have much debugging information to determine what was going on with the "" ""master, and couldn't reboot it. That team noted that it failed without "" ""alert, but managed to reboot it. After an hour, the cluster had returned to "" ""its normal state and we went home for the day."" msgstr ""この時、我々のコントロールサービスは別のチームによりホスティングされており、我々には現用系サーバー上で何が起こっているのかを調査するための大したデバッグ情報がなく、再起動もできなかった。このチームは警報なしで障害が起こったと連絡してきたが、そのサーバーの再起動を管理していた。１時間後、クラスタは通常状態に復帰し、我々はその日は帰宅した。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml478(para) msgid """" ""Continuing the diagnosis the next morning was kick started by another "" ""identical failure. We quickly got the message queue running again, and tried"" "" to work out why Rabbit was suffering from so much network traffic. Enabling"" "" debug logging on nova-api quickly brought understanding. A <code>tail -f "" ""/var/log/nova/nova-api.log</code> was scrolling by faster than we'd ever "" ""seen before. CTRL+C on that and we could plainly see the contents of a "" ""system log spewing failures over and over again - a system log from one of "" ""our users' instances."" msgstr ""翌朝の継続調査は別の同様の障害でいきなり始まった。我々は急いで RabbitMQ サーバーを再起動し、何故 RabbitMQ がそのような過剰なネットワーク負荷に直面しているのかを調べようとした。nova-api のデバッグログを出力することにより、理由はすぐに判明した。<code>tail -f /var/log/nova/nova-api.log</code> は我々が見たこともない速さでスクロールしていた。CTRL+C でコマンドを止め、障害を吐き出していたシステムログの内容をはっきり目にすることが出来た。－我々のユーザの１人のインスタンスからのシステムログだった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml489(para) msgid """" ""After finding the instance ID we headed over to "" ""<code>/var/lib/nova/instances</code> to find the <code>console.log</code>:"" msgstr ""インスタンスIDの発見後、<code>console.log</code> を探すため <code>/var/lib/nova/instances</code> にアクセスした。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml496(para) msgid """" ""Sure enough, the user had been periodically refreshing the console log page "" ""on the dashboard and the 5G file was traversing the rabbit cluster to get to"" "" the dashboard."" msgstr ""思った通り、ユーザはダッシュボード上のコンソールログページを定期的に更新しており、ダッシュボードに向けて5GB のファイルが RabbitMQ クラスタを通過していた。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml500(para) msgid """" ""We called them and asked them to stop for a while, and they were happy to "" ""abandon the horribly broken VM. After that, we started monitoring the size "" ""of console logs."" msgstr ""我々はユーザを呼び、しばらくダッシュボードの更新を止めるよう申し入れた。すると、恐ろしい VM の破壊は止み、彼らは大いに喜んだ。その後、我々はコンソールログのサイズを監視するようになった。"" #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml504(para) msgid """" ""To this day, <link xlink:href=\""https://bugs.launchpad.net/nova/+bug/832507\"">the "" ""issue</link> (https://bugs.launchpad.net/nova/+bug/832507) doesn't have a "" ""permanent resolution, but we look forward to the discussion at the next "" ""summit."" msgstr ""今日に至るまで、<link xlink:href=\""https://bugs.launchpad.net/nova/+bug/832507\"">この問題</link> (https://bugs.launchpad.net/nova/+bug/832507) には完全な解決策がないが、我々は次回のサミットの議論に期待している。"" #. Put one translator per line, in the form of NAME <EMAIL>, YEAR1, YEAR2 #: ./doc/src/docbkx/openstack-ops/src/app_crypt.xml0(None) msgid ""translator-credits"" msgstr ""Akihiro MOTOKI <amotoki@gmail.com>, 2013\nAkira Yoshiyama <akirayoshiyama@gmail.com>, 2013\nMasanori Itoh <masanori.itoh@gmail.com>, 2013\nmasayukig <masayuki.igawa@gmail.com>, 2013\n*はたらくpokotan* <>, 2013\nTsutomu TAKEKAWA <takekawa@gmail.com>, 2013\ndoki701 <tokidokidokidoki@gmail.com>, 2013\nTomoyuki KATO <tomo@dream.daynight.jp>, 2012-2013\ntmak <t.makabe@gmail.com>, 2013"" ",,14461,0
openstack%2Fnova~master~Id86874416453a8c5a597cbf17a639902c0311c6f,openstack/nova,master,Id86874416453a8c5a597cbf17a639902c0311c6f,vmwareapi: remove a useless loop,ABANDONED,2013-09-04 19:12:35.000000000,2013-09-04 20:40:33.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 5371}]","[{'number': 1, 'created': '2013-09-04 19:12:35.000000000', 'files': ['nova/virt/vmwareapi/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/640b2265f9dbd03e5d5a1edf1c7e47aa783d8c6c', 'message': 'vmwareapi: remove a useless loop\n\nThis code included a while True loop that did nothing.  The code paths\ninside of the loop could only return or raise an exception.  This patch\nremoves the loop.  There should be no functional changes here.\n\nChange-Id: Id86874416453a8c5a597cbf17a639902c0311c6f\n'}]",1,45100,640b2265f9dbd03e5d5a1edf1c7e47aa783d8c6c,6,5,1,1561,,,0,"vmwareapi: remove a useless loop

This code included a while True loop that did nothing.  The code paths
inside of the loop could only return or raise an exception.  This patch
removes the loop.  There should be no functional changes here.

Change-Id: Id86874416453a8c5a597cbf17a639902c0311c6f
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/45100/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/driver.py'],1,640b2265f9dbd03e5d5a1edf1c7e47aa783d8c6c,remove-useless-loop," try: # Login and setup the session with the ESX host for making # API calls self.vim = self._get_vim_object() session = self.vim.Login( self.vim.get_service_content().sessionManager, userName=self._host_username, password=self._host_password) # Terminate the earlier session, if possible ( For the sake of # preserving sessions as there is a limit to the number of # sessions we can have ) if self._session_id: try: self.vim.TerminateSession( self.vim.get_service_content().sessionManager, sessionId=[self._session_id]) except Exception as excep: # This exception is something we can live with. It is # just an extra caution on our side. The session may # have been cleared. We could have made a call to # SessionIsActive, but that is an overhead because we # anyway would have to call TerminateSession. LOG.debug(excep) self._session_id = session.key return except Exception as excep: LOG.critical(_(""In vmwareapi:_create_session, "" ""got this exception: %s"") % excep) raise exception.NovaException(excep)"," while True: try: # Login and setup the session with the ESX host for making # API calls self.vim = self._get_vim_object() session = self.vim.Login( self.vim.get_service_content().sessionManager, userName=self._host_username, password=self._host_password) # Terminate the earlier session, if possible ( For the sake of # preserving sessions as there is a limit to the number of # sessions we can have ) if self._session_id: try: self.vim.TerminateSession( self.vim.get_service_content().sessionManager, sessionId=[self._session_id]) except Exception as excep: # This exception is something we can live with. It is # just an extra caution on our side. The session may # have been cleared. We could have made a call to # SessionIsActive, but that is an overhead because we # anyway would have to call TerminateSession. LOG.debug(excep) self._session_id = session.key return except Exception as excep: LOG.critical(_(""In vmwareapi:_create_session, "" ""got this exception: %s"") % excep) raise exception.NovaException(excep)",29,30
openstack%2Fceilometer~master~Iba303b422a2893ed63375c79d9dc4b93711cf215,openstack/ceilometer,master,Iba303b422a2893ed63375c79d9dc4b93711cf215,Add query support to alarm history API,MERGED,2013-09-03 15:42:59.000000000,2013-09-04 20:18:59.000000000,2013-09-04 20:18:59.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-09-03 15:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/061b5e3467acf8e8e9d727382f27af6a4425e9fb', 'message': 'Add query support to alarm history API\n\nAllow alarm history retrieval to be constrained by\nuser, project, change type or timestamp.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: Iba303b422a2893ed63375c79d9dc4b93711cf215\n'}, {'number': 2, 'created': '2013-09-04 17:46:28.000000000', 'files': ['tests/api/v2/test_alarm_scenarios.py', 'ceilometer/storage/base.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/impl_log.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/storage/impl_db2.py', 'ceilometer/storage/impl_sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c0c2b844a7ac0edb0c7c937fbe9c8646d8a24efb', 'message': 'Add query support to alarm history API\n\nAllow alarm history retrieval to be constrained by\nuser, project, change type or timestamp.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: Iba303b422a2893ed63375c79d9dc4b93711cf215\n'}]",13,44908,c0c2b844a7ac0edb0c7c937fbe9c8646d8a24efb,18,6,2,2284,,,0,"Add query support to alarm history API

Allow alarm history retrieval to be constrained by
user, project, change type or timestamp.

Partially implements bp alarm-audit-api

Change-Id: Iba303b422a2893ed63375c79d9dc4b93711cf215
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/08/44908/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/api/v2/test_alarm_scenarios.py', 'ceilometer/storage/base.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/impl_log.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/storage/impl_db2.py', 'ceilometer/storage/impl_sqlalchemy.py']",8,061b5e3467acf8e8e9d727382f27af6a4425e9fb,," def get_alarm_changes(self, alarm_id, on_behalf_of, user=None, project=None, type=None, start_timestamp=None, start_timestamp_op=None, end_timestamp=None, end_timestamp_op=None): :param user: Optional ID of user to return changes for :param project: Optional ID of project to return changes for :project type: Optional change type :param start_timestamp: Optional modified timestamp start range :param start_timestamp_op: Optional timestamp start range operation :param end_timestamp: Optional modified timestamp end range :param end_timestamp_op: Optional timestamp end range operation"," def get_alarm_changes(self, alarm_id, on_behalf_of):",125,13
openstack%2Fdjango_openstack_auth~master~Ic40ac559447ce68b64f738a8838c817c6497d185,openstack/django_openstack_auth,master,Ic40ac559447ce68b64f738a8838c817c6497d185,Bump version for H3 release.,MERGED,2013-09-04 19:51:53.000000000,2013-09-04 20:03:59.000000000,2013-09-04 20:03:59.000000000,"[{'_account_id': 3}, {'_account_id': 1816}]","[{'number': 1, 'created': '2013-09-04 19:51:53.000000000', 'files': ['openstack_auth/__init__.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/7c92eee987f576f0082781b868058bad7d98e9df', 'message': 'Bump version for H3 release.\n\nChange-Id: Ic40ac559447ce68b64f738a8838c817c6497d185\n'}]",0,45110,7c92eee987f576f0082781b868058bad7d98e9df,4,2,1,1816,,,0,"Bump version for H3 release.

Change-Id: Ic40ac559447ce68b64f738a8838c817c6497d185
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/10/45110/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/__init__.py'],1,7c92eee987f576f0082781b868058bad7d98e9df,1.1.2-bump,"__version__ = ""1.1.2""","__version__ = ""1.1.1""",1,1
openstack%2Ftaskflow~master~I8f882e0d58caa189d6bff2e33b0bc30c4cee553d,openstack/taskflow,master,I8f882e0d58caa189d6bff2e33b0bc30c4cee553d,Combine multiple exceptions into a linked one,MERGED,2013-08-29 05:56:00.000000000,2013-09-04 19:41:41.000000000,2013-09-04 19:41:41.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 8367}]","[{'number': 1, 'created': '2013-08-29 05:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b6bb16dc7236ee314b973d5c51f1e26c0e659a4e', 'message': 'Combine multiple exceptions into a linked one\n\nWhen multiple tasks running at the same time\nthrow exceptions previously we would not be\nable to rethrow all the combined ones which\nwas suboptimal. Instead of doing that create\na combined linked exception that can retain\nall of the exceptions that were thrown and\nrethrow that in the situation where more than\none task fails.\n\nChange-Id: I8f882e0d58caa189d6bff2e33b0bc30c4cee553d\n'}, {'number': 2, 'created': '2013-09-03 19:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d89ead359848f6febd4b1e8655b43cb1047d239f', 'message': 'Combine multiple exceptions into a linked one\n\nWhen multiple tasks running at the same time\nthrow exceptions previously we would not be\nable to rethrow all the combined ones which\nwas suboptimal. Instead of doing that create\na combined linked exception that can retain\nall of the exceptions that were thrown and\nrethrow that in the situation where more than\none task fails.\n\nChange-Id: I8f882e0d58caa189d6bff2e33b0bc30c4cee553d\n'}, {'number': 3, 'created': '2013-09-04 18:39:51.000000000', 'files': ['taskflow/exceptions.py', 'taskflow/patterns/threaded_flow.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b0fa3b2c9aeafa965d09fb43bbe0eeac8e828c0e', 'message': 'Combine multiple exceptions into a linked one\n\nWhen multiple tasks running at the same time\nthrow exceptions previously we would not be\nable to rethrow all the combined ones which\nwas suboptimal. Instead of doing that create\na combined linked exception that can retain\nall of the exceptions that were thrown and\nrethrow that in the situation where more than\none task fails.\n\nChange-Id: I8f882e0d58caa189d6bff2e33b0bc30c4cee553d\n'}]",2,44215,b0fa3b2c9aeafa965d09fb43bbe0eeac8e828c0e,16,4,3,1297,,,0,"Combine multiple exceptions into a linked one

When multiple tasks running at the same time
throw exceptions previously we would not be
able to rethrow all the combined ones which
was suboptimal. Instead of doing that create
a combined linked exception that can retain
all of the exceptions that were thrown and
rethrow that in the situation where more than
one task fails.

Change-Id: I8f882e0d58caa189d6bff2e33b0bc30c4cee553d
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/15/44215/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/exceptions.py', 'taskflow/patterns/threaded_flow.py']",2,b6bb16dc7236ee314b973d5c51f1e26c0e659a4e,linked-excp," if len(failures) > 1: exceptions = [f.exc_info[1] for f in failures] exception_messages = [str(f.exc_info[1]) for f in failures] raise exc.LinkedException.link(exception_messages, exceptions) else: f = failures[0] raise f.exc_info[0], f.exc_info[1], f.exc_info[2]"," # TODO(harlowja): re-raise a combined exception when # there are more than one failures?? for f in failures: if all(f.exc_info): raise f.exc_info[0], f.exc_info[1], f.exc_info[2]",31,5
openstack%2Fpython-openstackclient~master~I9c60d1d9097d35aa7c3d44168e370a9f30fd6621,openstack/python-openstackclient,master,I9c60d1d9097d35aa7c3d44168e370a9f30fd6621,Update requirements.txt and test-requirements.txt,MERGED,2013-08-30 01:45:05.000000000,2013-09-04 19:20:20.000000000,2013-09-04 19:20:20.000000000,"[{'_account_id': 3}, {'_account_id': 970}]","[{'number': 1, 'created': '2013-08-30 01:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/dd731dd96957a7fe8aaccfa7f69734d8fbcabf89', 'message': 'Update requirements.txt and test-requirements.txt\n\nChange-Id: I9c60d1d9097d35aa7c3d44168e370a9f30fd6621\n'}, {'number': 2, 'created': '2013-09-03 22:56:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a03cb230650a76fa08dbd4e9febc277d6da33944', 'message': 'Update requirements.txt and test-requirements.txt\n\nChange-Id: I9c60d1d9097d35aa7c3d44168e370a9f30fd6621\n'}, {'number': 3, 'created': '2013-09-04 16:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e7480b9e80091f511049fc3bceee5f1438578df3', 'message': 'Update requirements.txt and test-requirements.txt\n\nChange-Id: I9c60d1d9097d35aa7c3d44168e370a9f30fd6621\n'}, {'number': 4, 'created': '2013-09-04 18:27:37.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/5e29928294f80cb437a9bcf5c459dd2aad1b0d27', 'message': 'Update requirements.txt and test-requirements.txt\n\nChange-Id: I9c60d1d9097d35aa7c3d44168e370a9f30fd6621\n'}]",0,44385,5e29928294f80cb437a9bcf5c459dd2aad1b0d27,12,2,4,970,,,0,"Update requirements.txt and test-requirements.txt

Change-Id: I9c60d1d9097d35aa7c3d44168e370a9f30fd6621
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/85/44385/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,dd731dd96957a7fe8aaccfa7f69734d8fbcabf89,update-reqs,"pyflakes>=0.7.2,<0.7.4hacking>=0.5.6,<0.8fixtures>=0.3.14 mock>=1.0","pyflakes==0.7.2hacking>=0.5.6,<0.7fixtures>=0.3.12 mock>=0.8.0",5,5
openstack%2Fneutron~master~Idd49f304d6b1e4fd79431ab88c9ca8e605a21e9f,openstack/neutron,master,Idd49f304d6b1e4fd79431ab88c9ca8e605a21e9f,Add clean_db cleanup to end of Arista tests.,ABANDONED,2013-09-04 19:13:19.000000000,2013-09-04 19:18:30.000000000,,[{'_account_id': 105}],"[{'number': 1, 'created': '2013-09-04 19:13:19.000000000', 'files': ['neutron/tests/unit/ml2/drivers/test_arista_mechanism_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9634db0e1822a744278f82c6cf193c9f0a8d497f', 'message': 'Add clean_db cleanup to end of Arista tests.\n\n*Thinking this might help with the periodic test failures in these tests.*\n\nChange-Id: Idd49f304d6b1e4fd79431ab88c9ca8e605a21e9f\n'}]",0,45101,9634db0e1822a744278f82c6cf193c9f0a8d497f,2,1,1,4395,,,0,"Add clean_db cleanup to end of Arista tests.

*Thinking this might help with the periodic test failures in these tests.*

Change-Id: Idd49f304d6b1e4fd79431ab88c9ca8e605a21e9f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/45101/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/ml2/drivers/test_arista_mechanism_driver.py'],1,9634db0e1822a744278f82c6cf193c9f0a8d497f,master, self.addCleanup(ndb.clear_db),,1,0
openstack%2Fnova~master~I9b65968781afbecd0db72073299c019f8cc10241,openstack/nova,master,I9b65968781afbecd0db72073299c019f8cc10241,Fix a gross duplication of context code in objects tests,MERGED,2013-08-26 18:26:35.000000000,2013-09-04 18:45:42.000000000,2013-09-04 18:45:40.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 7629}]","[{'number': 1, 'created': '2013-08-26 18:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7a065c868f8b1bcb53190c5261af9b4695ffb84', 'message': 'Fix a gross duplication of context code in objects tests\n\nBecause of the way we dual-inherit classes to get the local\nand remote testing of objects, laziness caused us to duplicate\nthe code to get a context object all over the place. This\npatch cleans that up.\n\nChange-Id: I9b65968781afbecd0db72073299c019f8cc10241\n'}, {'number': 2, 'created': '2013-08-29 16:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7ea5faf92e24ae8df1ac2af2cef794b7f0cc536', 'message': 'Fix a gross duplication of context code in objects tests\n\nBecause of the way we dual-inherit classes to get the local\nand remote testing of objects, laziness caused us to duplicate\nthe code to get a context object all over the place. This\npatch cleans that up.\n\nChange-Id: I9b65968781afbecd0db72073299c019f8cc10241\n'}, {'number': 3, 'created': '2013-08-29 20:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c955c09f0714a802c4edc8b81a283450fe516908', 'message': 'Fix a gross duplication of context code in objects tests\n\nBecause of the way we dual-inherit classes to get the local\nand remote testing of objects, laziness caused us to duplicate\nthe code to get a context object all over the place. This\npatch cleans that up.\n\nChange-Id: I9b65968781afbecd0db72073299c019f8cc10241\n'}, {'number': 4, 'created': '2013-09-03 20:09:38.000000000', 'files': ['nova/tests/objects/test_instance.py', 'nova/tests/objects/test_instance_action.py', 'nova/tests/objects/test_compute_node.py', 'nova/tests/objects/test_keypair.py', 'nova/tests/objects/test_objects.py', 'nova/tests/objects/test_instance_info_cache.py', 'nova/tests/objects/test_security_group.py', 'nova/tests/objects/test_service.py', 'nova/tests/objects/test_instance_fault.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a10fdea3f580bc1c9ef6ae29f4c2ff404d84464e', 'message': 'Fix a gross duplication of context code in objects tests\n\nBecause of the way we dual-inherit classes to get the local\nand remote testing of objects, laziness caused us to duplicate\nthe code to get a context object all over the place. This\npatch cleans that up.\n\nChange-Id: I9b65968781afbecd0db72073299c019f8cc10241\n'}]",0,43749,a10fdea3f580bc1c9ef6ae29f4c2ff404d84464e,25,8,4,4393,,,0,"Fix a gross duplication of context code in objects tests

Because of the way we dual-inherit classes to get the local
and remote testing of objects, laziness caused us to duplicate
the code to get a context object all over the place. This
patch cleans that up.

Change-Id: I9b65968781afbecd0db72073299c019f8cc10241
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/43749/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/objects/test_instance.py', 'nova/tests/objects/test_instance_action.py', 'nova/tests/objects/test_compute_node.py', 'nova/tests/objects/test_keypair.py', 'nova/tests/objects/test_objects.py', 'nova/tests/objects/test_instance_info_cache.py', 'nova/tests/objects/test_security_group.py', 'nova/tests/objects/test_service.py', 'nova/tests/objects/test_instance_fault.py']",9,d7a065c868f8b1bcb53190c5261af9b4695ffb84,keypairs," db.instance_fault_get_by_instance_uuids(self.context, ['fake-uuid'] ).AndReturn(fake_faults) self.context, 'fake-uuid') db.instance_fault_get_by_instance_uuids(self.context, ['fake-uuid'] ).AndReturn({}) self.context, 'fake-uuid') db.instance_fault_get_by_instance_uuids(self.context, ['fake-uuid'] ).AndReturn(fake_faults) self.context, ['fake-uuid']) db.instance_fault_get_by_instance_uuids(self.context, ['fake-uuid'] ).AndReturn({}) self.context, ['fake-uuid'])","from nova import context ctxt = context.get_admin_context() db.instance_fault_get_by_instance_uuids(ctxt, ['fake-uuid']).AndReturn( fake_faults) ctxt, 'fake-uuid') ctxt = context.get_admin_context() db.instance_fault_get_by_instance_uuids(ctxt, ['fake-uuid']).AndReturn( {}) ctxt, 'fake-uuid') ctxt = context.get_admin_context() db.instance_fault_get_by_instance_uuids(ctxt, ['fake-uuid']).AndReturn( fake_faults) ctxt, ['fake-uuid']) ctxt = context.get_admin_context() db.instance_fault_get_by_instance_uuids(ctxt, ['fake-uuid']).AndReturn( {}) ctxt, ['fake-uuid'])",265,339
openstack%2Fnova~master~I97419bfe6c605306bd64f9aa4fce9657509df260,openstack/nova,master,I97419bfe6c605306bd64f9aa4fce9657509df260,Make compute_api use Aggregate objects,MERGED,2013-08-21 16:11:50.000000000,2013-09-04 18:45:02.000000000,2013-09-04 18:45:00.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 7494}]","[{'number': 1, 'created': '2013-08-21 16:11:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/071126e1899a87e708baf69abc7b7291ba1da08c', 'message': ""Make compute_api use Aggregate objects\n\nThis makes the compute_api's AggregateAPI use the new Aggregate\nobject for its work.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I97419bfe6c605306bd64f9aa4fce9657509df260\n""}, {'number': 2, 'created': '2013-08-21 16:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/946f90d6d64609bcd0cbdb1c937fda9a79806fe4', 'message': ""Make compute_api use Aggregate objects\n\nThis makes the compute_api's AggregateAPI use the new Aggregate\nobject for its work.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I97419bfe6c605306bd64f9aa4fce9657509df260\n""}, {'number': 3, 'created': '2013-08-22 17:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/88be93b49de8392a12d277e28b38ff2ca439c0bc', 'message': ""Make compute_api use Aggregate objects\n\nThis makes the compute_api's AggregateAPI use the new Aggregate\nobject for its work.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I97419bfe6c605306bd64f9aa4fce9657509df260\n""}, {'number': 4, 'created': '2013-08-22 23:30:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef838810826c0563cb75c521822946579036d58b', 'message': ""Make compute_api use Aggregate objects\n\nThis makes the compute_api's AggregateAPI use the new Aggregate\nobject for its work.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I97419bfe6c605306bd64f9aa4fce9657509df260\n""}, {'number': 5, 'created': '2013-08-23 14:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5fdec8b49723fdaff95c812a19327c868dde60a', 'message': ""Make compute_api use Aggregate objects\n\nThis makes the compute_api's AggregateAPI use the new Aggregate\nobject for its work.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I97419bfe6c605306bd64f9aa4fce9657509df260\n""}, {'number': 6, 'created': '2013-08-29 16:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7272b1ff6fbee041cc49eb5b06c08b353a7c995', 'message': ""Make compute_api use Aggregate objects\n\nThis makes the compute_api's AggregateAPI use the new Aggregate\nobject for its work.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I97419bfe6c605306bd64f9aa4fce9657509df260\n""}, {'number': 7, 'created': '2013-08-29 20:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f3f584662009efe834389439c76086809de19e4', 'message': ""Make compute_api use Aggregate objects\n\nThis makes the compute_api's AggregateAPI use the new Aggregate\nobject for its work.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I97419bfe6c605306bd64f9aa4fce9657509df260\n""}, {'number': 8, 'created': '2013-09-03 20:09:39.000000000', 'files': ['nova/api/openstack/compute/contrib/aggregates.py', 'nova/api/openstack/compute/plugins/v3/aggregates.py', 'nova/tests/api/openstack/compute/contrib/test_aggregates.py', 'nova/compute/api.py', 'nova/tests/api/openstack/compute/plugins/v3/test_aggregates.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d4c95bf099d9c2a0d76d2f3345eb97f304bd386b', 'message': ""Make compute_api use Aggregate objects\n\nThis makes the compute_api's AggregateAPI use the new Aggregate\nobject for its work.\n\nRelated to blueprint compute-api-objects\n\nChange-Id: I97419bfe6c605306bd64f9aa4fce9657509df260\n""}]",1,43158,d4c95bf099d9c2a0d76d2f3345eb97f304bd386b,42,11,8,4393,,,0,"Make compute_api use Aggregate objects

This makes the compute_api's AggregateAPI use the new Aggregate
object for its work.

Related to blueprint compute-api-objects

Change-Id: I97419bfe6c605306bd64f9aa4fce9657509df260
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/43158/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/aggregates.py', 'nova/tests/api/openstack/compute/contrib/test_aggregates.py', 'nova/compute/api.py']",3,071126e1899a87e708baf69abc7b7291ba1da08c,keypairs,"from nova.objects import aggregate as aggregate_obj aggregate = aggregate_obj.Aggregate() aggregate.name = aggregate_name if availability_zone: aggregate.metadata = {'availability_zone': availability_zone} aggregate.create(context) aggregate = aggregate_obj.Aggregate.get_by_id(context, aggregate_id) aggregates = aggregate_obj.AggregateList.get_all(context) aggregate = aggregate_obj.Aggregate.get_by_id(context, aggregate_id) if 'name' in values: aggregate.name = values.pop('name') aggregate.metadata = values aggregate.save() aggregate = aggregate_obj.Aggregate.get_by_id(context, aggregate_id) aggregate.update_metadata(metadata) return aggregate aggregate = aggregate_obj.Aggregate.get_by_id(context, aggregate_id) if len(aggregate.hosts) > 0: aggregate.destroy() aggregate = aggregate_obj.Aggregate.get_by_id(context, aggregate_id) aggregate.add_host(context, host_name) aggregate=obj_base.obj_to_primitive(aggregate), host_param=host_name, host=host_name) return self._reformat_aggregate_info(aggregate) aggregate = aggregate_obj.Aggregate.get_by_id(context, aggregate_id) aggregate.delete_host(host_name) aggregate=obj_base.obj_to_primitive(aggregate), host_param=host_name, host=host_name) return self._reformat_aggregate_info(aggregate) return dict(aggregate.iteritems())"," aggregate_payload = {} values = {""name"": aggregate_name} aggregate_payload.update(values) metadata = None if availability_zone: metadata = {'availability_zone': availability_zone} aggregate_payload.update({'meta_data': metadata}) compute_utils.notify_about_aggregate_update(context, ""create.start"", aggregate_payload) aggregate = self.db.aggregate_create(context, values, metadata=metadata) aggregate_payload.update({'aggregate_id': aggregate['id']}) compute_utils.notify_about_aggregate_update(context, ""create.end"", aggregate_payload) aggregate = self.db.aggregate_get(context, aggregate_id) aggregates = self.db.aggregate_get_all(context) aggregate_payload = {'aggregate_id': aggregate_id} aggregate_payload.update({'meta_data': values}) compute_utils.notify_about_aggregate_update(context, ""updateprop.start"", aggregate_payload) aggregate = self.db.aggregate_update(context, aggregate_id, values) compute_utils.notify_about_aggregate_update(context, ""updateprop.end"", aggregate_payload) aggregate_payload = {'aggregate_id': aggregate_id} aggregate_payload.update({'meta_data': metadata}) compute_utils.notify_about_aggregate_update(context, ""updatemetadata.start"", aggregate_payload) # If a key is set to None, it gets removed from the aggregate metadata. for key in metadata.keys(): if not metadata[key]: try: self.db.aggregate_metadata_delete(context, aggregate_id, key) metadata.pop(key) except exception.AggregateMetadataNotFound as e: LOG.warn(e.format_message()) self.db.aggregate_metadata_add(context, aggregate_id, metadata) compute_utils.notify_about_aggregate_update(context, ""updatemetadata.end"", aggregate_payload) return self.get_aggregate(context, aggregate_id) hosts = self.db.aggregate_host_get_all(context, aggregate_id) if len(hosts) > 0: self.db.aggregate_delete(context, aggregate_id) aggregate = self.db.aggregate_get(context, aggregate_id) self.db.aggregate_host_add(context, aggregate_id, host_name) aggregate = self.db.aggregate_get(context, aggregate_id) aggregate=aggregate, host_param=host_name, host=host_name) return self.get_aggregate(context, aggregate_id) self.db.aggregate_host_delete(context, aggregate_id, host_name) aggregate = self.db.aggregate_get(context, aggregate_id) aggregate=aggregate, host_param=host_name, host=host_name) return self.get_aggregate(context, aggregate_id) result = dict(aggregate.iteritems()) # metadetails was not originally included here. We need to rename it # to maintain API stability. result[""metadata""] = result.pop('metadetails') return result",43,64
openstack%2Fsahara~stable%2F0.2~I5bd5bf1b55412fbebbc5d9eb84cccc57e4b1824c,openstack/sahara,stable/0.2,I5bd5bf1b55412fbebbc5d9eb84cccc57e4b1824c,Enable the scaling up of nodes in a cluster,MERGED,2013-09-03 16:53:24.000000000,2013-09-04 18:36:35.000000000,2013-09-04 18:36:35.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7478}, {'_account_id': 7555}, {'_account_id': 7700}, {'_account_id': 7710}, {'_account_id': 8304}]","[{'number': 1, 'created': '2013-09-03 16:53:24.000000000', 'files': ['savanna/plugins/hdp/validator.py', 'savanna/plugins/hdp/ambariplugin.py', 'savanna/plugins/hdp/hadoopserver.py', 'savanna/tests/unit/plugins/hdp/validator_test.py', 'savanna/plugins/hdp/savannautils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/310d8c0c71a415e54e540105cc45cb21a83135ea', 'message': 'Enable the scaling up of nodes in a cluster\n\nEnabled the ability to add nodes to a cluster.  The ability to delete\nnodes will be added in a future commit once Ambari supports the\ndeletion of hosts from a cluster.\n\nFixes: bug #1216088\n\nConflicts:\n\tsavanna/plugins/hdp/ambariplugin.py\n\tsavanna/plugins/hdp/hadoopserver.py\n\nChange-Id: I5bd5bf1b55412fbebbc5d9eb84cccc57e4b1824c\n(cherry picked from commit f2ef149aac5568c2b41f8206cfd467984ba32198)\n'}]",7,44917,310d8c0c71a415e54e540105cc45cb21a83135ea,11,9,1,7737,,,0,"Enable the scaling up of nodes in a cluster

Enabled the ability to add nodes to a cluster.  The ability to delete
nodes will be added in a future commit once Ambari supports the
deletion of hosts from a cluster.

Fixes: bug #1216088

Conflicts:
	savanna/plugins/hdp/ambariplugin.py
	savanna/plugins/hdp/hadoopserver.py

Change-Id: I5bd5bf1b55412fbebbc5d9eb84cccc57e4b1824c
(cherry picked from commit f2ef149aac5568c2b41f8206cfd467984ba32198)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/17/44917/1 && git format-patch -1 --stdout FETCH_HEAD,"['savanna/plugins/hdp/validator.py', 'savanna/plugins/hdp/ambariplugin.py', 'savanna/plugins/hdp/hadoopserver.py', 'savanna/tests/unit/plugins/hdp/validator_test.py', 'savanna/plugins/hdp/savannautils.py']",5,310d8c0c71a415e54e540105cc45cb21a83135ea,bug/1216088," def get_host_role(host): if hasattr(host, 'role'): return host.role else: return host.node_group.name def get_node_processes(host): if hasattr(host, 'node_processes'): return host.node_processes else: return host.node_group.node_processes",,403,57
openstack%2Fbarbican~master~I17a7adf7e3f386f3b0474e79731e7faab8911481,openstack/barbican,master,I17a7adf7e3f386f3b0474e79731e7faab8911481,Fix KEK generation in the P11 Plugin + fix unit tests,MERGED,2013-09-04 16:28:29.000000000,2013-09-04 18:30:03.000000000,2013-09-04 18:30:03.000000000,"[{'_account_id': 3}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}]","[{'number': 1, 'created': '2013-09-04 16:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/01fbdbadc05979ea89c77ede954a2c09235cf0a2', 'message': ""Fix KEK generation in the P11 Plugin + fix unit tests\n\nBuckle up, this is going to be a long commit msg.\n\nBackground:\n* Henry Yamauchi noted that the bind_kek_metadata method was returning\n  an object early. This return prevented the entirety of the code that\n  created the KEK on the HSM from executing\n* This was not caught because the mock tests that checked for invocation\n  of the method were wrong. Specifically they called methods like\n  assert_called_once() and assert_called_twice(). Unfortunately, while\n  assert_called_once_with(), et al are real methods on the mock objects\n  that really do assert things, assert_called_once() is not. And when\n  you call a method that doesn't exist on a mock object it returns\n  another mock object. So many of these tests were testing nothing.\nFixes:\n* bind_kek_metadata has been refactored to separate out the kek\n  generation into a new method (_generate_kek) to make the expected flow\n  clearer. And, of course, the bug has been fixed\n* The tests have had all the incorrect assert calls removed. In some\n  cases the call was actually unnecessary (typically because the test\n  already used a return value from the mock so testing that it was\n  called was not needed). In other cases an assert was added that\n  checks that the called method on the mock object is true\n\nChange-Id: I17a7adf7e3f386f3b0474e79731e7faab8911481\n""}, {'number': 2, 'created': '2013-09-04 18:13:37.000000000', 'files': ['barbican/crypto/p11_crypto.py', 'barbican/tests/crypto/test_p11_crypto.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/44fcce118d1d7115c8dfbdc1629b29cfb63c4027', 'message': ""Fix KEK generation in the P11 Plugin + fix unit tests\n\nBuckle up, this is going to be a long commit msg.\n\nBackground:\n* Henry Yamauchi noted that the bind_kek_metadata method was returning\n  an object early. This return prevented the entirety of the code that\n  created the KEK on the HSM from executing\n* This was not caught because the mock tests that checked for invocation\n  of the method were wrong. Specifically they called methods like\n  assert_called_once() and assert_called_twice(). Unfortunately, while\n  assert_called_once_with(), et al are real methods on the mock objects\n  that really do assert things, assert_called_once() is not. And when\n  you call a method that doesn't exist on a mock object it returns\n  another mock object. So many of these tests were testing nothing.\nFixes:\n* bind_kek_metadata has been refactored to separate out the kek\n  generation into a new method (_generate_kek) to make the expected flow\n  clearer. And, of course, the bug has been fixed\n* The tests have had all the incorrect assert calls removed. In some\n  cases the call was actually unnecessary (typically because the test\n  already used a return value from the mock so testing that it was\n  called was not needed). In other cases an assert was added that\n  checks that the called method on the mock object is true\n\nChange-Id: I17a7adf7e3f386f3b0474e79731e7faab8911481\n""}]",4,45079,44fcce118d1d7115c8dfbdc1629b29cfb63c4027,13,5,2,8004,,,0,"Fix KEK generation in the P11 Plugin + fix unit tests

Buckle up, this is going to be a long commit msg.

Background:
* Henry Yamauchi noted that the bind_kek_metadata method was returning
  an object early. This return prevented the entirety of the code that
  created the KEK on the HSM from executing
* This was not caught because the mock tests that checked for invocation
  of the method were wrong. Specifically they called methods like
  assert_called_once() and assert_called_twice(). Unfortunately, while
  assert_called_once_with(), et al are real methods on the mock objects
  that really do assert things, assert_called_once() is not. And when
  you call a method that doesn't exist on a mock object it returns
  another mock object. So many of these tests were testing nothing.
Fixes:
* bind_kek_metadata has been refactored to separate out the kek
  generation into a new method (_generate_kek) to make the expected flow
  clearer. And, of course, the bug has been fixed
* The tests have had all the incorrect assert calls removed. In some
  cases the call was actually unnecessary (typically because the test
  already used a return value from the mock so testing that it was
  called was not needed). In other cases an assert was added that
  checks that the called method on the mock object is true

Change-Id: I17a7adf7e3f386f3b0474e79731e7faab8911481
",git fetch https://review.opendev.org/openstack/barbican refs/changes/79/45079/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/crypto/p11_crypto.py', 'barbican/tests/crypto/test_p11_crypto.py']",2,01fbdbadc05979ea89c77ede954a2c09235cf0a2,fix-p11-kek-generation-and-tests, self.assertTrue(self.session.login.called) self.assertTrue(self.p11_mock.Mechanism.called) self.assertTrue(self.session._template2ckattrlist.called) self.assertTrue(self.p11_mock.LowLevel.CK_MECHANISM.called) gk = self.pkcs11.lib.C_Generate_Key, self.pkcs11.openSession.login.assert_called_twice() self.session.login.assert_called_twice() self.session.findObjects.assert_called_once() self.session.findObjects.assert_called_once() self.session.findObjects.assert_called_once() self.p11_mock.Mechanism.assert_called_once() self.p11_mock.Mechanism.assert_called_once() self.p11_mock.lib.C_Generate_Key.assert_called_once() self.session._template2ckattrlist.assert_called_once() self.p11_mock.LowLevel.CK_MECHANISM.assert_called_once() gk = self.p11_mock.lib.C_Generate_Key,43,48
openstack%2Fceilometer~master~If530cdf8609655ef55aabbad95a2ec8b44ed8679,openstack/ceilometer,master,If530cdf8609655ef55aabbad95a2ec8b44ed8679,Fixes service startup issue on Windows,MERGED,2013-09-03 22:17:14.000000000,2013-09-04 18:24:24.000000000,2013-09-04 18:24:24.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 3185}, {'_account_id': 8367}]","[{'number': 1, 'created': '2013-09-03 22:17:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/55053b82ad01d9da69991e79aa0be79e1b4b6ba8', 'message': 'Updates oslo-incubator files\n\nUpdates the openstack/common modules to the latest available version.\nThis is required to fix an issue in starting services on Windows.\n\nFixes bug: #1217043\n\nChange-Id: If530cdf8609655ef55aabbad95a2ec8b44ed8679\n'}, {'number': 2, 'created': '2013-09-04 10:43:27.000000000', 'files': ['ceilometer/openstack/common/service.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/11d2e2bb6228501e1b5874d2b7063bfc63c2e335', 'message': 'Fixes service startup issue on Windows\n\nA recent addition in Oslo to support SIGHUP created a blocking issue\non Windows due to missing signal.SIGHUP support.\n\nFixes bug: #1217043\n\nChange-Id: If530cdf8609655ef55aabbad95a2ec8b44ed8679\n'}]",0,44961,11d2e2bb6228501e1b5874d2b7063bfc63c2e335,14,5,2,3185,,,0,"Fixes service startup issue on Windows

A recent addition in Oslo to support SIGHUP created a blocking issue
on Windows due to missing signal.SIGHUP support.

Fixes bug: #1217043

Change-Id: If530cdf8609655ef55aabbad95a2ec8b44ed8679
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/61/44961/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/openstack/common/crypto/__init__.py', 'ceilometer/openstack/common/db/sqlalchemy/models.py', 'tools/config/generate_sample.sh', 'ceilometer/openstack/common/gettextutils.py', 'ceilometer/openstack/common/timeutils.py', 'ceilometer/openstack/common/db/exception.py', 'ceilometer/openstack/common/notifier/log_notifier.py', 'ceilometer/openstack/common/policy.py', 'ceilometer/openstack/common/deprecated/__init__.py', 'ceilometer/openstack/common/db/sqlalchemy/utils.py', 'ceilometer/openstack/common/fileutils.py', 'ceilometer/openstack/common/rpc/securemessage.py', 'ceilometer/openstack/common/crypto/utils.py', 'ceilometer/openstack/common/service.py', 'ceilometer/openstack/common/lockutils.py', 'ceilometer/openstack/common/local.py', 'ceilometer/openstack/common/test.py', 'ceilometer/openstack/common/notifier/rpc_notifier.py', 'ceilometer/openstack/common/db/sqlalchemy/test_migrations.py', 'ceilometer/openstack/common/jsonutils.py', 'ceilometer/openstack/common/notifier/rpc_notifier2.py', 'ceilometer/openstack/common/deprecated/wsgi.py', 'ceilometer/openstack/common/excutils.py', 'ceilometer/openstack/common/db/sqlalchemy/migration.py', 'ceilometer/openstack/common/xmlutils.py', 'ceilometer/openstack/common/rpc/__init__.py', 'ceilometer/openstack/common/rpc/matchmaker_ring.py', 'ceilometer/openstack/common/rpc/common.py', 'ceilometer/openstack/common/db/sqlalchemy/session.py', 'ceilometer/openstack/common/rpc/zmq_receiver.py']",30,55053b82ad01d9da69991e79aa0be79e1b4b6ba8,bug/1217043," CONF(sys.argv[1:], project='ceilometer') logging.setup(""ceilometer"")"," CONF(sys.argv[1:], project='oslo') logging.setup(""oslo"")",1662,111
openstack%2Ftaskflow~master~If7154019f1cb5e723069ff35f6301fce048323b5,openstack/taskflow,master,If7154019f1cb5e723069ff35f6301fce048323b5,Converted some examples to use patterns/engines,MERGED,2013-08-28 15:07:10.000000000,2013-09-04 18:18:44.000000000,2013-09-04 18:18:44.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 7359}, {'_account_id': 7366}, {'_account_id': 8367}]","[{'number': 1, 'created': '2013-08-28 15:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c4d9122f175928a28cb3f6e067942bb5554a20b2', 'message': 'Converted some examples to use patterns/engines\n\nChange-Id: If7154019f1cb5e723069ff35f6301fce048323b5\n'}, {'number': 2, 'created': '2013-09-04 13:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e45be794c399688578f812befa76372505886284', 'message': 'Converted some examples to use patterns/engines\n\nChange-Id: If7154019f1cb5e723069ff35f6301fce048323b5\n'}, {'number': 3, 'created': '2013-09-04 15:30:58.000000000', 'files': ['taskflow/examples/simple_linear.py', 'taskflow/examples/reverting_linear.out.txt', 'taskflow/examples/reverting_linear.py', 'taskflow/examples/calculate_in_parallel.py', 'taskflow/examples/simple_linear.out.txt', 'taskflow/examples/calculate_linear.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a638c9864f8d5f050fc59be1a84e728e30f981aa', 'message': 'Converted some examples to use patterns/engines\n\nChange-Id: If7154019f1cb5e723069ff35f6301fce048323b5\n'}]",4,44074,a638c9864f8d5f050fc59be1a84e728e30f981aa,16,6,3,7366,,,0,"Converted some examples to use patterns/engines

Change-Id: If7154019f1cb5e723069ff35f6301fce048323b5
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/74/44074/3 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/examples/simple_linear.py', 'taskflow/examples/reverting_linear.out.txt', 'taskflow/examples/reverting_linear.py', 'taskflow/examples/calculate_in_parallel.py', 'taskflow/examples/simple_linear.out.txt', 'taskflow/examples/calculate_linear.py']",6,c4d9122f175928a28cb3f6e067942bb5554a20b2,bp/patterns-and-engines,"from taskflow import blocks from taskflow.engines import action_engine as eng# In this example LinearFlow is used to group four tasks to # calculate value. Added task is used twice. In the first case # it uses default parameters ('x' and 'y') and in the second one # arguments are binding with 'z' and 'd' keys from engine storage. # Multiplier task uses binding too, but explicitly shows that 'z' # parameter is binded with 'a' key from engine storage. class Provider(task.Task): def __init__(self, name, *args): super(Provider, self).__init__(name) self._provide = args def __call__(self): def __init__(self, name): super(Adder, self).__init__(name) def __call__(self, x, y): return x + y def __init__(self, name, multiplier): self._multiplier = multiplier def __call__(self, z): return z * self._multiplier flow = blocks.LinearFlow().add( # x = 2, y = 3, d = 5 blocks.Task(Provider(""provide-adder"", 2, 3, 5), save_as=('x', 'y', 'd')), # z = x+y = 5 blocks.Task(Adder(""add""), save_as='z'), # a = z+d = 10 blocks.Task(Adder(""add""), save_as='a', rebind_args=['z', 'd']), # r = a*3 = 30 blocks.Task(Multiplier(""multi"", 3), save_as='r', rebind_args={'z': 'a'})) engine = eng.SingleThreadedActionEngine(flow) engine.run() print engine.storage.fetch_all()","from taskflow.patterns import linear_flow as lfdef flow_notify(state, details): print(""'%s' entered state: %s"" % (details['flow'], state)) def task_notify(state, details): print(""'%s' entered state: %s"" % (details['runner'], state)) # This class is used to populate requirements that further tasks need to run # by populating those tasks from a dictionary and returning said dictionary # when the flow runs (so that further tasks can use those values). You can # think of this a needed bootstrapping of a flow in a way. class Provider(task.Task): def __init__(self, name, **kwargs): super(Provider, self).__init__(name) self.provides.update(kwargs.keys()) self._provide = kwargs def __call__(self, context): def __init__(self, name, x_name, y_name, provides_name): super(Adder, self).__init__(name) self.requires.update([x_name, y_name]) self.provides.update([provides_name]) self._provides_name = provides_name def __call__(self, context, **kwargs): return { self._provides_name: sum(kwargs.values()), } def __init__(self, name, z_name, by_how_much): self.requires.update([z_name]) self._by_how_much = by_how_much self._z_name = z_name def __call__(self, context, **kwargs): return kwargs.pop(self._z_name) * self._by_how_much flow = lf.Flow(""calc-them"") flow.add(Provider(""provide-adder"", x=2, y=3, d=5)) # Add x + y to produce z (5) flow.add(Adder('add', 'x', 'y', 'z')) # Add z + d to produce a (5 + 5) flow.add(Adder('add', 'z', 'd', 'a')) # Multiple a by 3 (30) multi_uuid = flow.add(Multiplier('multi', 'a', 3)) # Get notified of the state changes the flow is going through. flow.notifier.register('*', flow_notify) # Get notified of the state changes the flows tasks/runners are going through. flow.task_notifier.register('*', task_notify) # Context is typically passed in openstack, it is not needed here. print '-' * 7 print 'Running' print '-' * 7 context = {} flow.run(context) # This will have the last results and the task that produced that result, # but we don't care about the task that produced it and just want the result # itself. print '-' * 11 print 'All results' print '-' * 11 for (uuid, v) in flow.results.items(): print '%s => %s' % (uuid, v) multi_results = flow.results[multi_uuid] print '-' * 15 print ""Multiply result"" print '-' * 15 print(multi_results) assert multi_results == 30, ""Example is broken""",142,119
openstack%2Ftaskflow~master~I4a1f78c95ae5d38660bd32ce21d2b3fb1b2af8ad,openstack/taskflow,master,I4a1f78c95ae5d38660bd32ce21d2b3fb1b2af8ad,MultiThreaded engine and parallel action,MERGED,2013-09-04 13:44:01.000000000,2013-09-04 18:18:26.000000000,2013-09-04 18:18:26.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 7359}, {'_account_id': 7366}, {'_account_id': 8367}]","[{'number': 1, 'created': '2013-09-04 13:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a24495c6b1d05c9f5d665b194587e7b1bf58e461', 'message': 'MultiThreaded engine and parallel action\n\nMultiThreaded engine was implemented to execute tasks in parallel:\n- added parallel action that executes and reverts tasks in parallel;\n- added thread-safe storage.\n\nChange-Id: I4a1f78c95ae5d38660bd32ce21d2b3fb1b2af8ad\n'}, {'number': 2, 'created': '2013-09-04 14:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/293f099cbfbdd97c1544efe44cd9d88b3e7b2486', 'message': 'MultiThreaded engine and parallel action\n\nMultiThreaded engine was implemented to execute tasks in parallel:\n- added parallel action that executes and reverts tasks in parallel;\n- added thread-safe storage.\n\nChange-Id: I4a1f78c95ae5d38660bd32ce21d2b3fb1b2af8ad\n'}, {'number': 3, 'created': '2013-09-04 15:11:27.000000000', 'files': ['taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/parallel_action.py', 'taskflow/utils/threading_utils.py', 'taskflow/tests/unit/test_action_engine.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6ee4d32fc25a7343ef4802f8390e76ef608106b9', 'message': 'MultiThreaded engine and parallel action\n\nMultiThreaded engine was implemented to execute tasks in parallel:\n- added parallel action that executes and reverts tasks in parallel;\n- added thread-safe storage.\n\nChange-Id: I4a1f78c95ae5d38660bd32ce21d2b3fb1b2af8ad\n'}]",1,45059,6ee4d32fc25a7343ef4802f8390e76ef608106b9,13,6,3,7366,,,0,"MultiThreaded engine and parallel action

MultiThreaded engine was implemented to execute tasks in parallel:
- added parallel action that executes and reverts tasks in parallel;
- added thread-safe storage.

Change-Id: I4a1f78c95ae5d38660bd32ce21d2b3fb1b2af8ad
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/59/45059/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/parallel_action.py', 'taskflow/utils/threading_utils.py', 'taskflow/tests/unit/test_action_engine.py']",5,a24495c6b1d05c9f5d665b194587e7b1bf58e461,bp/patterns-and-engines,"import multiprocessing import time def __init__(self, values=None, name=None, sleep=None): self._sleep = sleep if self._sleep: time.sleep(self._sleep) if self._sleep: time.sleep(self._sleep) if self._sleep: try: time.sleep(self._sleep) except TypeError: print 'sleep: %r' % self._sleep class EngineParallelFlowTest(EngineTestBase): def test_parallel_flow_one_task(self): flow = blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task1', sleep=0.01)) ) self._make_engine(flow).run() self.assertEquals(self.values, ['task1']) def test_parallel_flow_two_tasks(self): flow = blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task1', sleep=0.01)), blocks.Task(TestTask(self.values, name='task2', sleep=0.01)) ) self._make_engine(flow).run() result = set(self.values) self.assertEquals(result, set(['task1', 'task2'])) def test_parallel_revert_common(self): flow = blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task1')), blocks.Task(FailingTask(self.values, sleep=0.01)), blocks.Task(TestTask(self.values, name='task2')) ) engine = self._make_engine(flow) with self.assertRaisesRegexp(RuntimeError, '^Woot'): engine.run() def test_parallel_revert_exception_is_reraised(self): flow = blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task1')), blocks.Task(NastyTask()), blocks.Task(FailingTask(self.values, sleep=0.1)) ) engine = self._make_engine(flow) with self.assertRaisesRegexp(RuntimeError, '^Gotcha'): engine.run() EngineParallelFlowTest, class MultiThreadedEngineTest(EngineTaskTest, EngineLinearFlowTest, EngineParallelFlowTest, test.TestCase): def _make_engine(self, flow, flow_detail=None): return eng.MultiThreadedActionEngine(flow, flow_detail=flow_detail) def test_using_common_pool(self): flow = blocks.Task(TestTask(self.values, name='task1')) pool = multiprocessing.pool.ThreadPool() e1 = eng.MultiThreadedActionEngine(flow, thread_pool=pool) e2 = eng.MultiThreadedActionEngine(flow, thread_pool=pool) self.assertIs(e1.thread_pool, e2.thread_pool) def test_parallel_revert_specific(self): flow = blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task1', sleep=0.01)), blocks.Task(FailingTask(sleep=0.01)), blocks.Task(TestTask(self.values, name='task2', sleep=0.01)) ) engine = self._make_engine(flow) with self.assertRaisesRegexp(RuntimeError, '^Woot'): engine.run() result = set(self.values) self.assertEquals(result, set(['task1', 'task2', 'task2 reverted(5)', 'task1 reverted(5)'])) def test_parallel_revert_exception_is_reraised_(self): flow = blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task1', sleep=0.01)), blocks.Task(NastyTask()), blocks.Task(FailingTask(sleep=0.01)), blocks.Task(TestTask) # this should not get reverted ) engine = self._make_engine(flow) with self.assertRaisesRegexp(RuntimeError, '^Gotcha'): engine.run() result = set(self.values) self.assertEquals(result, set(['task1', 'task1 reverted(5)'])) def test_nested_parallel_revert_exception_is_reraised(self): flow = blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task1')), blocks.Task(TestTask(self.values, name='task2')), blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task3', sleep=0.1)), blocks.Task(NastyTask()), blocks.Task(FailingTask(sleep=0.01)) ) ) engine = self._make_engine(flow) with self.assertRaisesRegexp(RuntimeError, '^Gotcha'): engine.run() result = set(self.values) self.assertEquals(result, set(['task1', 'task1 reverted(5)', 'task2', 'task2 reverted(5)', 'task3', 'task3 reverted(5)'])) def test_parallel_revert_exception_do_not_revert_linear_tasks(self): flow = blocks.LinearFlow().add( blocks.Task(TestTask(self.values, name='task1')), blocks.Task(TestTask(self.values, name='task2')), blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task3', sleep=0.1)), blocks.Task(NastyTask()), blocks.Task(FailingTask(sleep=0.01)) ) ) engine = self._make_engine(flow) with self.assertRaisesRegexp(RuntimeError, '^Gotcha'): engine.run() result = set(self.values) self.assertEquals(result, set(['task1', 'task2', 'task3', 'task3 reverted(5)'])) def test_parallel_nested_to_linear_revert(self): flow = blocks.LinearFlow().add( blocks.Task(TestTask(self.values, name='task1')), blocks.Task(TestTask(self.values, name='task2')), blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task3', sleep=0.1)), blocks.Task(FailingTask(sleep=0.01)) ) ) engine = self._make_engine(flow) with self.assertRaisesRegexp(RuntimeError, '^Woot'): engine.run() result = set(self.values) self.assertEquals(result, set(['task1', 'task1 reverted(5)', 'task2', 'task2 reverted(5)', 'task3', 'task3 reverted(5)'])) def test_linear_nested_to_parallel_revert(self): flow = blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task1')), blocks.Task(TestTask(self.values, name='task2')), blocks.LinearFlow().add( blocks.Task(TestTask(self.values, name='task3', sleep=0.1)), blocks.Task(FailingTask(self.values, name='fail', sleep=0.01)) ) ) engine = self._make_engine(flow) with self.assertRaisesRegexp(RuntimeError, '^Woot'): engine.run() result = set(self.values) self.assertEquals(result, set(['task1', 'task1 reverted(5)', 'task2', 'task2 reverted(5)', 'task3', 'task3 reverted(5)', 'fail reverted(Failure: RuntimeError: Woot!)'])) def test_linear_nested_to_parallel_revert_exception(self): flow = blocks.ParallelFlow().add( blocks.Task(TestTask(self.values, name='task1', sleep=0.01)), blocks.Task(TestTask(self.values, name='task2', sleep=0.01)), blocks.LinearFlow().add( blocks.Task(TestTask(self.values, name='task3')), blocks.Task(NastyTask()), blocks.Task(FailingTask(sleep=0.01)) ) ) engine = self._make_engine(flow) with self.assertRaisesRegexp(RuntimeError, '^Gotcha'): engine.run() result = set(self.values) self.assertEquals(result, set(['task1', 'task1 reverted(5)', 'task2', 'task2 reverted(5)', 'task3']))"," def __init__(self, values=None, name=None):",281,1
openstack%2Fhorizon~master~I216394028876045ba29b5b7cc75ca2495c4a855c,openstack/horizon,master,I216394028876045ba29b5b7cc75ca2495c4a855c,Remove spaces from translatable strings,MERGED,2013-09-04 12:57:52.000000000,2013-09-04 18:15:17.000000000,2013-09-04 18:15:17.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 7553}, {'_account_id': 8642}]","[{'number': 1, 'created': '2013-09-04 12:57:52.000000000', 'files': ['openstack_dashboard/dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html', 'openstack_dashboard/dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html', 'openstack_dashboard/dashboards/project/loadbalancers/templates/loadbalancers/_member_details.html', 'openstack_dashboard/dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9bde3814d413a1157f5e14175d99f2788c87cc3b', 'message': 'Remove spaces from translatable strings\n\nThis patchset removes some unnesessary spaces form strings\nin load balancers details pages that will be localized.\n\nFixes bug 1220686\n\nChange-Id: I216394028876045ba29b5b7cc75ca2495c4a855c\n'}]",0,45055,9bde3814d413a1157f5e14175d99f2788c87cc3b,8,5,1,6914,,,0,"Remove spaces from translatable strings

This patchset removes some unnesessary spaces form strings
in load balancers details pages that will be localized.

Fixes bug 1220686

Change-Id: I216394028876045ba29b5b7cc75ca2495c4a855c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/55/45055/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html', 'openstack_dashboard/dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html', 'openstack_dashboard/dashboards/project/loadbalancers/templates/loadbalancers/_member_details.html', 'openstack_dashboard/dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html']",4,9bde3814d413a1157f5e14175d99f2788c87cc3b,bug/1220686," <dt>{% trans ""ID:"" %}</dt> <dt>{% trans ""Tenant ID:"" %}</dt> <dt>{% trans ""Type:"" %}</dt> <dt>{% trans ""Delay:"" %}</dt> <dt>{% trans ""Timeout:"" %}</dt> <dt>{% trans ""Max Retries:"" %}</dt> <dt>{% trans ""HTTP Method:"" %}</dt> <dt>{% trans ""URL Path:"" %}</dt> <dt>{% trans ""Expected Codes:"" %}</dt> <dt>{% trans ""Admin State Up:"" %}</dt>"," <dt>{% trans ""ID: "" %}</dt> <dt>{% trans ""Tenant ID: "" %}</dt> <dt>{% trans ""Type: "" %}</dt> <dt>{% trans ""Delay: "" %}</dt> <dt>{% trans ""Timeout: "" %}</dt> <dt>{% trans ""Max Retries: "" %}</dt> <dt>{% trans ""HTTP Method: "" %}</dt> <dt>{% trans ""URL Path: "" %}</dt> <dt>{% trans ""Expected Codes: "" %}</dt> <dt>{% trans ""Admin State Up: "" %}</dt>",45,45
openstack%2Freviewstats~master~I916349d33a356666816bc2b9e05493d004ea04d0,openstack/reviewstats,master,I916349d33a356666816bc2b9e05493d004ea04d0,added Peter Portante as a core dev,MERGED,2013-09-04 18:14:21.000000000,2013-09-04 18:15:09.000000000,2013-09-04 18:15:09.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 8367}]","[{'number': 1, 'created': '2013-09-04 18:14:21.000000000', 'files': ['projects/swift.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/cab04cb42a4daa41bce480044c43952fc45af487', 'message': 'added Peter Portante as a core dev\n\nChange-Id: I916349d33a356666816bc2b9e05493d004ea04d0\n'}]",0,45088,cab04cb42a4daa41bce480044c43952fc45af487,6,3,1,330,,,0,"added Peter Portante as a core dev

Change-Id: I916349d33a356666816bc2b9e05493d004ea04d0
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/88/45088/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/swift.json'],1,cab04cb42a4daa41bce480044c43952fc45af487,,"{""name"": ""swift"", ""subprojects"": [""openstack/swift"", ""openstack/python-swiftclient""], ""core-team"": [""darrellb"", ""torgomatic"", ""notmyname"", ""gholt"", ""chmouel"", ""cthier"", ""clay-gerrard"", ""david-goetz"", ""redbo"", ""greglange"", ""pandemicsyn"", ""peter-a-portante""]}","{""name"": ""swift"", ""subprojects"": [""openstack/swift"", ""openstack/python-swiftclient""], ""core-team"": [""darrellb"", ""torgomatic"", ""notmyname"", ""gholt"", ""chmouel"", ""cthier"", ""clay-gerrard"", ""david-goetz"", ""redbo"", ""greglange"", ""pandemicsyn""]}",1,1
openstack%2Fpython-designateclient~master~Id276fdaee9e8753568227e638408e5bccff28e67,openstack/python-designateclient,master,Id276fdaee9e8753568227e638408e5bccff28e67,Use Python 3.x compatible except construct.,MERGED,2013-09-04 12:41:32.000000000,2013-09-04 18:13:07.000000000,2013-09-04 18:13:07.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8367}]","[{'number': 1, 'created': '2013-09-04 12:41:32.000000000', 'files': ['designateclient/warlock.py', 'designateclient/cli/base.py'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/f7bc95a871abd6af6bfec062feefe851c1ad2a4e', 'message': 'Use Python 3.x compatible except construct.\n\nPython 3.x deprecated the form ""except x,y:"". Switch usage to\n""except x as y:"", which works with any Python version >= 2.6\n\nChange-Id: Id276fdaee9e8753568227e638408e5bccff28e67\n'}]",0,45049,f7bc95a871abd6af6bfec062feefe851c1ad2a4e,6,3,1,6593,,,0,"Use Python 3.x compatible except construct.

Python 3.x deprecated the form ""except x,y:"". Switch usage to
""except x as y:"", which works with any Python version >= 2.6

Change-Id: Id276fdaee9e8753568227e638408e5bccff28e67
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/49/45049/1 && git format-patch -1 --stdout FETCH_HEAD,"['designateclient/warlock.py', 'designateclient/cli/base.py']",2,f7bc95a871abd6af6bfec062feefe851c1ad2a4e,python3, except exceptions.RemoteError as e:," except exceptions.RemoteError, e:",5,5
openstack%2Fglance~master~If97fad2d6b85730ea1cebc477f5f092c1c17976d,openstack/glance,master,If97fad2d6b85730ea1cebc477f5f092c1c17976d,Remove unused local vars,MERGED,2013-08-21 14:29:19.000000000,2013-09-04 18:12:37.000000000,2013-09-04 18:12:37.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 4463}, {'_account_id': 6282}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-08-21 14:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2bf8cae0bccd2fc26584abd8a32ff2da45965aba', 'message': 'Remove unused local vars\n\nRemove unused local vars in\nglance/tests/functional/test_cache_middleware.py to make code more\ncleaner.\n\nChange-Id: If97fad2d6b85730ea1cebc477f5f092c1c17976d\n'}, {'number': 2, 'created': '2013-08-21 14:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/60f7fee89ed27e7bd41bbca205dfaa84b18478e5', 'message': 'Remove unused local vars\n\nRemove unused local vars in test files to make code more\ncleaner.\n\nChange-Id: If97fad2d6b85730ea1cebc477f5f092c1c17976d\n'}, {'number': 3, 'created': '2013-08-21 14:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/320fd49cded68fd572ddd9dfab69dbb1b26b6bad', 'message': 'Remove unused local vars\n\nRemove unused local vars in test files to make code more\ncleaner.\n\nChange-Id: If97fad2d6b85730ea1cebc477f5f092c1c17976d\n'}, {'number': 4, 'created': '2013-08-30 12:07:42.000000000', 'files': ['glance/tests/functional/v1/test_copy_to_file.py', 'glance/tests/functional/db/base.py', 'glance/tests/functional/test_api.py', 'glance/tests/functional/test_bin_glance_cache_manage.py', 'glance/tests/functional/v1/test_ssl.py', 'glance/tests/functional/test_cache_middleware.py', 'glance/tests/functional/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/844a228c3c42dac802a82510eb17fcfaccb0e1f8', 'message': 'Remove unused local vars\n\nRemove unused local vars in test files to make code cleaner.\n\nChange-Id: If97fad2d6b85730ea1cebc477f5f092c1c17976d\n'}]",1,43138,844a228c3c42dac802a82510eb17fcfaccb0e1f8,23,5,4,6282,,,0,"Remove unused local vars

Remove unused local vars in test files to make code cleaner.

Change-Id: If97fad2d6b85730ea1cebc477f5f092c1c17976d
",git fetch https://review.opendev.org/openstack/glance refs/changes/38/43138/4 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/functional/test_cache_middleware.py'],1,2bf8cae0bccd2fc26584abd8a32ff2da45965aba,UnusedLocalVar, float(time_val) except ValueError:, api_port = self.api_port registry_port = self.registry_port api_port = self.api_port registry_port = self.registry_port api_port = self.api_port registry_port = self.registry_port time_val_f = float(time_val) except ValueError as e: api_port = self.api_port api_port = self.api_port registry_port = self.registry_port api_port = self.api_port registry_port = self.registry_port ,2,19
openstack%2Fdevstack~master~I775b70407379d9c97696f536f5f89cecb33657be,openstack/devstack,master,I775b70407379d9c97696f536f5f89cecb33657be,Add my_ip option in cinder.conf,MERGED,2013-08-30 18:00:46.000000000,2013-09-04 18:10:51.000000000,2013-09-04 18:10:50.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 6948}, {'_account_id': 7708}]","[{'number': 1, 'created': '2013-08-30 18:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e2784d30ee42ceb5bd7b45af1caefe84373c1736', 'message': ""Add my_ip option in cinder.conf.\n\nThen cinder installed in multinode environment with more than one interface,\nit's better to use HOST_IP option for cinder ip address.\n\nChange-Id: I775b70407379d9c97696f536f5f89cecb33657be\n""}, {'number': 2, 'created': '2013-08-30 18:04:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a430817989cc5afb971213f0ab40051c37ef07f7', 'message': ""Add my_ip option in cinder.conf\n\nThen cinder installed in multinode environment with more than one interface,\nit's better to use HOST_IP option for cinder ip address.\n\nChange-Id: I775b70407379d9c97696f536f5f89cecb33657be\n""}, {'number': 3, 'created': '2013-08-30 18:04:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a01f6cb9e03d152d98991d831c51ca39863557fa', 'message': ""Add my_ip option in cinder.conf\n\nThen cinder installed in multinode environment with more than one interface,\nit's better to use HOST_IP option for cinder ip address.\n\nChange-Id: I775b70407379d9c97696f536f5f89cecb33657be\n""}, {'number': 4, 'created': '2013-09-03 22:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ccf62599cfa0410b3d9dfc22b237b45548b52889', 'message': ""Add my_ip option in cinder.conf\n\nThen cinder installed in multinode environment with more than one interface,\nit's better to use HOST_IP option for cinder ip address.\n\nChange-Id: I775b70407379d9c97696f536f5f89cecb33657be\n""}, {'number': 5, 'created': '2013-09-03 22:48:50.000000000', 'files': ['lib/cinder'], 'web_link': 'https://opendev.org/openstack/devstack/commit/08df29bff4e5c9e717358e7593e8c5a9c51a26bf', 'message': ""Add my_ip option in cinder.conf\n\nThen cinder installed in multinode environment with more than one interface,\nit's better to use CINDER_SERVICE_HOST option for cinder ip address.\n\nChange-Id: I775b70407379d9c97696f536f5f89cecb33657be\n""}]",2,44508,08df29bff4e5c9e717358e7593e8c5a9c51a26bf,20,7,5,6948,,,0,"Add my_ip option in cinder.conf

Then cinder installed in multinode environment with more than one interface,
it's better to use CINDER_SERVICE_HOST option for cinder ip address.

Change-Id: I775b70407379d9c97696f536f5f89cecb33657be
",git fetch https://review.opendev.org/openstack/devstack refs/changes/08/44508/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder'],1,e2784d30ee42ceb5bd7b45af1caefe84373c1736,(detached," iniset $CINDER_CONF DEFAULT my_ip ""$HOST_IP""",,1,0
openstack%2Ftaskflow~master~Ia4e5707687096c948bd8db4f3d8936bdac40dd6c,openstack/taskflow,master,Ia4e5707687096c948bd8db4f3d8936bdac40dd6c,State management for engines,MERGED,2013-09-04 12:55:37.000000000,2013-09-04 18:09:25.000000000,2013-09-04 18:09:25.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7359}, {'_account_id': 7366}, {'_account_id': 8367}]","[{'number': 1, 'created': '2013-09-04 12:55:37.000000000', 'files': ['taskflow/engines/action_engine/seq_action.py', 'taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/task.py', 'taskflow/persistence/flowdetail.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/blocks/task.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a91dd6b0e4e31132d1fcf0f9f6c2f64b599bfda0', 'message': 'State management for engines\n\nAll state management moved to storage, including flow (engine) state,\ntask states, task results and failures.\n\nNotifications for state changes were added.\n\nStorage is now implemented using taskflow.persistence and enhanced with\nmeans for result mapping and fetching task result by name.\n\nPartially implements blueprint patterns-and-engines.\n\nCo-authored-by: Anastasia Karpinska <akarpinska at griddynamics.com>\nChange-Id: Ia4e5707687096c948bd8db4f3d8936bdac40dd6c\n'}]",2,45053,a91dd6b0e4e31132d1fcf0f9f6c2f64b599bfda0,10,5,1,7366,,,0,"State management for engines

All state management moved to storage, including flow (engine) state,
task states, task results and failures.

Notifications for state changes were added.

Storage is now implemented using taskflow.persistence and enhanced with
means for result mapping and fetching task result by name.

Partially implements blueprint patterns-and-engines.

Co-authored-by: Anastasia Karpinska <akarpinska at griddynamics.com>
Change-Id: Ia4e5707687096c948bd8db4f3d8936bdac40dd6c
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/53/45053/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/seq_action.py', 'taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/task.py', 'taskflow/persistence/flowdetail.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/blocks/task.py']",9,a91dd6b0e4e31132d1fcf0f9f6c2f64b599bfda0,bp/patterns-and-engines,"from taskflow.utils import reflection def _save_as_to_mapping(save_as): """"""Convert save_as to mapping name => index Result should follow taskflow.storage.Storage convention for mappings. """""" if save_as is None: return None if isinstance(save_as, basestring): return {save_as: None} elif isinstance(save_as, tuple): return dict((key, num) for num, key in enumerate(save_as)) raise TypeError('Task block save_as parameter ' 'should be str or tuple, not %r' % save_as) def _build_arg_mapping(rebind_args, task): if rebind_args is None: rebind_args = {} task_args = reflection.get_required_callable_args(task.execute) nargs = len(task_args) if isinstance(rebind_args, (list, tuple)): if len(rebind_args) < nargs: raise ValueError('Task %(name)s takes %(nargs)d positional ' 'arguments (%(real)d given)' % dict(name=task.name, nargs=nargs, real=len(rebind_args))) result = dict(zip(task_args, rebind_args[:nargs])) # extra rebind_args go to kwargs result.update((a, a) for a in rebind_args[nargs:]) return result elif isinstance(rebind_args, dict): result = dict((a, a) for a in task_args) result.update(rebind_args) return result else: raise TypeError('rebind_args should be list, tuple or dict') def __init__(self, task, save_as=None, rebind_args=None): if isinstance(self._task, type): self._task = self._task() self._result_mapping = _save_as_to_mapping(save_as) self._args_mapping = _build_arg_mapping(rebind_args, self._task) def result_mapping(self): return self._result_mapping @property def args_mapping(self): return self._args_mapping","from taskflow.openstack.common import uuidutils def __init__(self, task, uuid=None): if uuid is None: self._id = uuidutils.generate_uuid() else: self._id = str(uuid) def uuid(self): return self._id",647,84
openstack%2Fdevstack~master~I13bb8e59ff5367ff7623fe9aa273886a957f81a7,openstack/devstack,master,I13bb8e59ff5367ff7623fe9aa273886a957f81a7,xenapi: README.md and embedded localrc updates,MERGED,2013-08-31 11:35:13.000000000,2013-09-04 18:08:00.000000000,2013-09-04 18:07:59.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5044}, {'_account_id': 6735}]","[{'number': 1, 'created': '2013-08-31 11:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/99e554e2abcc2d0d2bb5dd0efc230948caac1963', 'message': 'xenapi: README.md and embedded localrc updates\n\nThis change updates the readme, so that it is easier to get started, and\nreflects the actual behavior of DevStack.\n\nChanges in README.md:\n - Link to xenserver download page\n - Remove neutron interface - it is no longer installed by devstack\n - Add appendix with\n   - How to use a different ubuntu mirror\n   - How to use a proxy for ubuntu\n   - How to re-use the created VM\n - Remove run from snapshot section and ""do cloudy stuff""\n\nChanges in the Readme-embedded sample localrc:\n - Upload a vhd image and a uec image by default - easier to get started\n\nChange-Id: I13bb8e59ff5367ff7623fe9aa273886a957f81a7\n'}, {'number': 2, 'created': '2013-08-31 12:41:38.000000000', 'files': ['tools/xen/README.md'], 'web_link': 'https://opendev.org/openstack/devstack/commit/bbf56237747cace1f4c8f393893239488b9a344f', 'message': 'xenapi: README.md and embedded localrc updates\n\nThis change updates the readme, so that it is easier to get started, and\nreflects the actual behavior of DevStack.\n\nChanges in README.md:\n - Link to xenserver download page\n - Remove neutron interface - it is no longer installed by devstack\n - Add appendix with\n   - How to use a different ubuntu mirror\n   - How to use a proxy for ubuntu\n   - How to re-use the created VM\n - Remove run from snapshot section and ""do cloudy stuff""\n\nChanges in the Readme-embedded sample localrc:\n - Upload a vhd image and a uec image by default - easier to get started\n\nChange-Id: I13bb8e59ff5367ff7623fe9aa273886a957f81a7\n'}]",12,44588,bbf56237747cace1f4c8f393893239488b9a344f,10,5,2,5044,,,0,"xenapi: README.md and embedded localrc updates

This change updates the readme, so that it is easier to get started, and
reflects the actual behavior of DevStack.

Changes in README.md:
 - Link to xenserver download page
 - Remove neutron interface - it is no longer installed by devstack
 - Add appendix with
   - How to use a different ubuntu mirror
   - How to use a proxy for ubuntu
   - How to re-use the created VM
 - Remove run from snapshot section and ""do cloudy stuff""

Changes in the Readme-embedded sample localrc:
 - Upload a vhd image and a uec image by default - easier to get started

Change-Id: I13bb8e59ff5367ff7623fe9aa273886a957f81a7
",git fetch https://review.opendev.org/openstack/devstack refs/changes/88/44588/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/xen/README.md'],1,99e554e2abcc2d0d2bb5dd0efc230948caac1963,readme_fixes,"# Getting Started With XenServer and Devstack The purpose of the code in this directory it to help developers bootstrap a XenServer 5.6 (6.2 is recommended) + Openstack development environment. This file gives some pointers on how to get started. Xenserver is a Type 1 hypervisor, so it is best installed on bare metal. The Openstack services are configured to run within a virtual machine (called OS domU) on the XenServer host. The VM uses the XAPI toolstack to communicate with the host. ## Introduction ### Requirements ### Steps to follow ### Brief explanation - `eth0` - Connected to `UBUNTU_INST_BRIDGE_OR_NET_NAME`, defaults to `MGT_BRIDGE_OR_NET_NAME` (NOTE: you can save and later re-use the created minimal ubuntu installation by using `xe template-export` and `xe vm-import` - see [Reuse the Ubuntu VM](#reuse-the-ubuntu-vm) - `eth0` - Management interface, connected to `MGT_BRIDGE_OR_NET_NAME` - `eth1` - VM interface, connected to `VM_BRIDGE_OR_NET_NAME` - `eth2` - Public interface, connected to `PUB_BRIDGE_OR_NET_NAME`Install XenServer on a clean box. You can download the latest XenServer for free from: http://www.xenserver.org/ # Download a vhd and a uec image IMAGE_URLS=""\ https://github.com/downloads/citrix-openstack/warehouse/cirros-0.3.0-x86_64-disk.vhd.tgz,\ http://download.cirros-cloud.net/0.3.1/cirros-0.3.1-x86_64-uec.tar.gz"" # Explicitly set virt driver# Appendix This section contains useful information for running devstack in CI environments / using ubuntu network mirrors. ## Use a specific Ubuntu mirror for installation To speed up the Ubuntu installation, you can use a specific mirror. To specify a mirror explicitly, include the following settings in your `localrc` file: UBUNTU_INST_HTTP_HOSTNAME=""archive.ubuntu.com"" UBUNTU_INST_HTTP_DIRECTORY=""/ubuntu"" These variables set the `mirror/http/hostname` and `mirror/http/directory` settings in the ubuntu preseed file. The minimal ubuntu VM will use the specified parameters. ## Use an http proxy to speed up Ubuntu installation To further speed up the Ubuntu VM and package installation, an internal http proxy could be used. `squid-deb-proxy` has prooven to be stable. To use an http proxy, specify: UBUNTU_INST_HTTP_PROXY=""http://ubuntu-proxy.somedomain.com:8000"" in your `localrc` file. ## Reuse the Ubuntu VM Performing a minimal ubuntu installation could take a lot of time, depending on your mirror/network speed. If you run `install_os_domU.sh` script on a clean hypervisor, you can speed up the installation, by re-using the ubuntu vm from a previous installation. ### Export the Ubuntu VM to an XVA Given you have an nfs export `TEMPLATE_NFS_DIR`: TEMPLATE_FILENAME=devstack-jeos.xva TEMPLATE_NAME=jeos_template_for_devstack mountdir=$(mktemp -d) mount -t nfs ""$TEMPLATE_NFS_DIR"" ""$mountdir"" VM=""$(xe template-list name-label=""$TEMPLATE_NAME"" --minimal)"" xe template-export template-uuid=$VM filename=""$mountdir/$TEMPLATE_FILENAME"" umount ""$mountdir"" rm -rf ""$mountdir"" ### Import the Ubuntu VM Given you have an nfs export `TEMPLATE_NFS_DIR` where you exported the Ubuntu VM as `TEMPLATE_FILENAME`: mountdir=$(mktemp -d) mount -t nfs ""$TEMPLATE_NFS_DIR"" ""$mountdir"" xe vm-import filename=""$mountdir/$TEMPLATE_FILENAME"" umount ""$mountdir"" rm -rf ""$mountdir""","# Getting Started With XenServer 5.6 and Devstack The purpose of the code in this directory it to help developers bootstrap a XenServer 5.6 (or greater) + Openstack development environment. This file gives some pointers on how to get started. Xenserver is a Type 1 hypervisor, so it needs to be installed on bare metal. The Openstack services are configured to run within a ""privileged"" virtual machine on the Xenserver host (called OS domU). The VM uses the XAPI toolstack to communicate with the host.The requirements are:Steps to follow: - eth0 - Connected to `UBUNTU_INST_BRIDGE_OR_NET_NAME`, defaults to `MGT_BRIDGE_OR_NET_NAME` - eth0 - Management interface, connected to `MGT_BRIDGE_OR_NET_NAME` - eth1 - VM interface, connected to `VM_BRIDGE_OR_NET_NAME` - eth2 - Public interface, connected to `PUB_BRIDGE_OR_NET_NAME` - (eth3) - Optional network interface if neutron is used, to enforce xapi to create the underlying bridge.Install XenServer 5.6+ on a clean box. You can get XenServer by signing up for an account on citrix.com, and then visiting: https://www.citrix.com/English/ss/downloads/details.asp?downloadId=2311504&productId=683148 For details on installation, see: http://wiki.openstack.org/XenServer/Install # Do not download the usual images IMAGE_URLS="""" # Explicitly set virt driver here## Step 5: Do cloudy stuff! * Play with horizon * Play with the CLI * Log bugs to devstack and core projects, and submit fixes! ## Step 6: Run from snapshot If you want to quicky re-run devstack from a clean state, using the same settings you used in your previous run, you can revert the DomU to the snapshot called `before_first_boot`",91,33
openstack%2Fdevstack~master~Iad85f573b90c23140012c20c552a17277d9c97a0,openstack/devstack,master,Iad85f573b90c23140012c20c552a17277d9c97a0,xenapi: Set VM memory before starting it,MERGED,2013-08-30 12:34:50.000000000,2013-09-04 18:06:41.000000000,2013-09-04 18:06:41.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5044}]","[{'number': 1, 'created': '2013-08-30 12:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4a1c25738d79a03be119b81cd3adee1d2f3ead0a', 'message': ""xenapi: Set VM memory before starting it\n\nIf someone was re-using an existing template, for a memory change, he\nneeded to re-install the vm. This change sets the osdomu mem before\nstarting it, so it doesn't matter how much memory did the VM had\naccording to the template.\n\nChange-Id: Iad85f573b90c23140012c20c552a17277d9c97a0\n""}, {'number': 2, 'created': '2013-08-30 13:33:09.000000000', 'files': ['tools/xen/install_os_domU.sh', 'tools/xen/functions', 'tools/xen/scripts/install-os-vpx.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/16ed068db52516238b618408656fa0bc612b9218', 'message': ""xenapi: Set VM memory before starting it\n\nIf someone was re-using an existing template, for a memory change, he\nneeded to re-install the vm. This change sets the osdomu mem before\nstarting it, so it doesn't matter how much memory did the VM had\naccording to the template. It also removes the memory manipulation bits\nfrom install-os-vpx.sh.\n\nChange-Id: Iad85f573b90c23140012c20c552a17277d9c97a0\n""}]",0,44447,16ed068db52516238b618408656fa0bc612b9218,8,4,2,5044,,,0,"xenapi: Set VM memory before starting it

If someone was re-using an existing template, for a memory change, he
needed to re-install the vm. This change sets the osdomu mem before
starting it, so it doesn't matter how much memory did the VM had
according to the template. It also removes the memory manipulation bits
from install-os-vpx.sh.

Change-Id: Iad85f573b90c23140012c20c552a17277d9c97a0
",git fetch https://review.opendev.org/openstack/devstack refs/changes/47/44447/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/xen/install_os_domU.sh', 'tools/xen/functions']",2,4a1c25738d79a03be119b81cd3adee1d2f3ead0a,setmem," function set_vm_memory() { local vm_name_label local memory vm_name_label=""$1"" memory=""$2"" local vm vm=$(_vm_uuid ""$vm_name_label"") xe vm-memory-limits-set \ static-min=${memory}MiB \ static-max=${memory}MiB \ dynamic-min=${memory}MiB \ dynamic-max=${memory}MiB \ uuid=$vm }",,22,0
openstack%2Fdevstack~master~I8e1c6e2e5d4bfade50aba9259b6da3957d6d622d,openstack/devstack,master,I8e1c6e2e5d4bfade50aba9259b6da3957d6d622d,Cinder needs iscsiadm available,MERGED,2013-08-30 19:41:27.000000000,2013-09-04 18:06:34.000000000,2013-09-04 18:06:34.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5997}, {'_account_id': 6948}]","[{'number': 1, 'created': '2013-08-30 19:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e0dd899960946dd4bb19feeaba1fe843a30767ab', 'message': 'Cinder needs iscsiadm available\n\nThis patch adds the binary packages that contains\nthe iscsiadm utility for cinder.   Cinder\nuses the iscsiadm utility for various actions\nand it should be there for devstack users.\n\nFixes bug #1219032\n\nChange-Id: I8e1c6e2e5d4bfade50aba9259b6da3957d6d622d\n'}, {'number': 2, 'created': '2013-09-03 20:27:40.000000000', 'files': ['files/rpms-suse/cinder', 'files/rpms/cinder', 'files/apts/cinder'], 'web_link': 'https://opendev.org/openstack/devstack/commit/4d0d5ce778d4fa79cdbe2e5532608060a95870e3', 'message': 'Cinder needs iscsiadm available\n\nThis patch adds the binary packages that contains\nthe iscsiadm utility for cinder.   Cinder\nuses the iscsiadm utility for various actions\nand it should be there for devstack users.\n\nFixes bug #1219032\n\nChange-Id: I8e1c6e2e5d4bfade50aba9259b6da3957d6d622d\n'}]",0,44533,4d0d5ce778d4fa79cdbe2e5532608060a95870e3,12,5,2,5997,,,0,"Cinder needs iscsiadm available

This patch adds the binary packages that contains
the iscsiadm utility for cinder.   Cinder
uses the iscsiadm utility for various actions
and it should be there for devstack users.

Fixes bug #1219032

Change-Id: I8e1c6e2e5d4bfade50aba9259b6da3957d6d622d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/33/44533/2 && git format-patch -1 --stdout FETCH_HEAD,"['files/rpms-suse/cinder', 'files/rpms/cinder', 'files/apts/cinder']",3,e0dd899960946dd4bb19feeaba1fe843a30767ab,bug/1219032,open-iscsi-utils,,3,0
openstack%2Fdevstack~master~I5dd49169c45e26e8d2bb3d5920a1b7fa584be50f,openstack/devstack,master,I5dd49169c45e26e8d2bb3d5920a1b7fa584be50f,xenapi: add username to vncviewer command,MERGED,2013-08-30 12:18:37.000000000,2013-09-04 18:06:27.000000000,2013-09-04 18:06:27.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-08-30 12:18:37.000000000', 'files': ['tools/xen/install_os_domU.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/97621a1d1f39a944a24371fc9f2bf9b86faec248', 'message': ""xenapi: add username to vncviewer command\n\nDevstack prints out an instruction, how to look at the virtual machine's\nconsole. The command did not include the username, so if the user had a\nconfig file to use a different username for that network, the command\nfailed.\n\nChange-Id: I5dd49169c45e26e8d2bb3d5920a1b7fa584be50f\n""}]",0,44444,97621a1d1f39a944a24371fc9f2bf9b86faec248,6,3,1,5044,,,0,"xenapi: add username to vncviewer command

Devstack prints out an instruction, how to look at the virtual machine's
console. The command did not include the username, so if the user had a
config file to use a different username for that network, the command
failed.

Change-Id: I5dd49169c45e26e8d2bb3d5920a1b7fa584be50f
",git fetch https://review.opendev.org/openstack/devstack refs/changes/44/44444/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/xen/install_os_domU.sh'],1,97621a1d1f39a944a24371fc9f2bf9b86faec248,vncfix," echo ""vncviewer -via root@$mgmt_ip localhost:${port:2}"""," echo ""vncviewer -via $mgmt_ip localhost:${port:2}""",1,1
openstack%2Fnova~master~I446fdf4b9843155e0c818c271114b1e2e4f43b64,openstack/nova,master,I446fdf4b9843155e0c818c271114b1e2e4f43b64,Add support for API message localization,MERGED,2013-05-24 18:40:08.000000000,2013-09-04 18:05:13.000000000,2013-09-04 18:05:10.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 5046}, {'_account_id': 5371}, {'_account_id': 5652}, {'_account_id': 6829}, {'_account_id': 6928}, {'_account_id': 6983}, {'_account_id': 7138}, {'_account_id': 7179}, {'_account_id': 7996}]","[{'number': 1, 'created': '2013-05-24 18:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59f455d1a180ae0335857e806d2624b33ce5b1fc', 'message': 'support API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nand exception message to the user requested locale and return\nthat translation from the API.\n\nThis is a rough implementation of such a design.\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 2, 'created': '2013-06-14 22:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9894062de10d2291e72998a2a233ddc031594949', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nand exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 3, 'created': '2013-06-17 19:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/540afa8e9dbb3f0e2a4ba2c9735f9e2dc0f8360f', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nand exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 4, 'created': '2013-06-18 19:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3b1b98caabd58899d6f6453b3a534ed002b648a', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nand exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 5, 'created': '2013-06-18 21:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f29cdaf0491d70e604ecafb58f7c8a4b97621dc6', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nand exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 6, 'created': '2013-06-19 16:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0536b86e17e4be96775b7b00c6b2a106494e69ab', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nand exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 7, 'created': '2013-06-19 19:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e7cd1b65843697c1be355f42d92cb30757482a9', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nan exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 8, 'created': '2013-06-24 20:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86fdec095752c83be7c63687f690a5f9b3e79f19', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nan exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 9, 'created': '2013-07-08 20:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e3edc043e8423360675337327284512ec5a5170', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nan exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 10, 'created': '2013-07-11 18:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9208d880f2bdf08eaf05f15dcb493127b15049cd', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nan exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 11, 'created': '2013-07-15 17:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b923f358edd6bff94b7a313147dbb4d7b7909a75', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nan exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 12, 'created': '2013-07-19 18:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2ad70a1a0eab63599120fe6d601d06dcf8f4723', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nan exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 13, 'created': '2013-07-19 19:06:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf0eed2472d7083072a882844b1bb5b43c843e29', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nan exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nCo-authored-by: Ben Nemec <bnemec@us.ibm.com>\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 15, 'created': '2013-08-15 18:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b4cbf5c26a37fed419c642fa2c32535f2d7e8d5', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nan exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 14, 'created': '2013-08-15 18:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c34833104fe52915f9937069c50271ce2ae869bf', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nan exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}, {'number': 16, 'created': '2013-09-03 16:13:14.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_floating_ips.py', 'nova/tests/api/openstack/test_faults.py', 'nova/tests/api/test_auth.py', 'nova/virt/driver.py', 'nova/tests/api/openstack/test_wsgi.py', 'nova/api/openstack/wsgi.py', 'nova/tests/api/openstack/fakes.py', 'nova/virt/libvirt/driver.py', 'nova/cmd/__init__.py', 'nova/test.py', 'nova/utils.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ee53124ccb707f4e5aba0b9afec67e898da42911', 'message': 'Add support for API message localization\n\nUsing the lazy gettext functionality from oslo gettextutils,\nit is possible to use the Accept-Language header to translate\nan exception message to the user requested locale and return\nthat translation from the API.\n\nImplements bp user-locale-api\n\nChange-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64\n'}]",49,30479,ee53124ccb707f4e5aba0b9afec67e898da42911,103,15,16,5371,,,0,"Add support for API message localization

Using the lazy gettext functionality from oslo gettextutils,
it is possible to use the Accept-Language header to translate
an exception message to the user requested locale and return
that translation from the API.

Implements bp user-locale-api

Change-Id: I446fdf4b9843155e0c818c271114b1e2e4f43b64
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/30479/16 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi.py', 'nova/cmd/__init__.py', 'nova/tests/api/openstack/test_faults.py', 'nova/utils.py', 'nova/tests/api/openstack/test_wsgi.py']",5,59f455d1a180ae0335857e806d2624b33ce5b1fc,bp/user-locale-api," class AcceptLanguageTest(test.TestCase): def test_accept_language(self): request = wsgi.Request.blank('/') request.headers = {'Accept-Language': 'fu-br;q=1.1, en-gb;q=0.7,en-us,en;q=.5,*;q=.7'} self.assertEqual(wsgi.get_user_locale_from_request(request), 'en_US')",,121,1
openstack%2Fnova~master~I2c74dc001032e3cc4d7d55a3fa407b96fd0d0e78,openstack/nova,master,I2c74dc001032e3cc4d7d55a3fa407b96fd0d0e78,Libvirt: call capabilites before getVersion(),MERGED,2013-08-22 19:29:04.000000000,2013-09-04 18:02:06.000000000,2013-09-04 18:02:03.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1779}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2750}]","[{'number': 1, 'created': '2013-08-22 19:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b9a47ce943a19bea6d9aaeb1d742211d1e8ccf4', 'message': 'Libvirt: call capabilites before getVersion()\n\nUpdates the Nova libvirt driver so we make a call to get\nthe driver capabilities. This is clearly a work around\nbut it does allow nova-compute to startup cleanly when\nperforming a clean install of Fedora 19.\n\nSee notes in: https://bugzilla.redhat.com/show_bug.cgi?id=1000116\n\nFixes LP Bug #1215593.\n\nChange-Id: I2c74dc001032e3cc4d7d55a3fa407b96fd0d0e78\n'}, {'number': 2, 'created': '2013-08-29 14:48:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7c46f47ae84234cd4d608a491ec9d473afd2a45', 'message': 'Libvirt: call capabilites before getVersion()\n\nUpdates the Nova libvirt driver so we make a call to get\nthe driver capabilities. This is clearly a work around\nbut it does allow nova-compute to startup cleanly when\nperforming a clean install of Fedora 19.\n\nSee notes in: https://bugzilla.redhat.com/show_bug.cgi?id=1000116\n\nFixes LP Bug #1215593.\n\nChange-Id: I2c74dc001032e3cc4d7d55a3fa407b96fd0d0e78\n'}, {'number': 3, 'created': '2013-09-02 13:42:23.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/baadaa9842ad4ff8b637466affd3c9f2213b55ac', 'message': 'Libvirt: call capabilites before getVersion()\n\nUpdates the Nova libvirt driver so we make a call to get\nthe driver capabilities. This is clearly a work around\nbut it does allow nova-compute to startup cleanly when\nperforming a clean install of Fedora 19.\n\nSee notes in: https://bugzilla.redhat.com/show_bug.cgi?id=1000116\n\nFixes LP Bug #1215593.\n\nChange-Id: I2c74dc001032e3cc4d7d55a3fa407b96fd0d0e78\n'}]",0,43338,baadaa9842ad4ff8b637466affd3c9f2213b55ac,24,6,3,360,,,0,"Libvirt: call capabilites before getVersion()

Updates the Nova libvirt driver so we make a call to get
the driver capabilities. This is clearly a work around
but it does allow nova-compute to startup cleanly when
performing a clean install of Fedora 19.

See notes in: https://bugzilla.redhat.com/show_bug.cgi?id=1000116

Fixes LP Bug #1215593.

Change-Id: I2c74dc001032e3cc4d7d55a3fa407b96fd0d0e78
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/43338/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,2b9a47ce943a19bea6d9aaeb1d742211d1e8ccf4,bug/1215593," #NOTE(dprince): calling capabilities first works around a startup # initialization issue with some versions of Libvirt: # See: https://bugzilla.redhat.com/show_bug.cgi?id=1000116 # See: https://bugs.launchpad.net/nova/+bug/1215593 data[""supported_instances""] = \ self.driver.get_instance_capabilities() "," data[""supported_instances""] = \ self.driver.get_instance_capabilities() ",8,3
openstack%2Fnova~master~I04a275cf8d2cc7665720329000fbe087aa636b21,openstack/nova,master,I04a275cf8d2cc7665720329000fbe087aa636b21,Fix virtual power driver fails silently,MERGED,2013-07-16 23:26:04.000000000,2013-09-04 17:34:24.000000000,2013-09-04 17:34:22.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 1726}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2889}, {'_account_id': 4190}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5652}, {'_account_id': 5805}, {'_account_id': 7069}]","[{'number': 1, 'created': '2013-07-16 23:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03a5e77eee62a79825b159abc432f78ccf41f682', 'message': 'Fix virtual power driver fails silently when MAC not found.\n\nThis patch changes the behavior of Virtual Power driver. VPD will\nnow raise an exception should the mac address for the node not\nbe found. It will also log the node name and mac address.\n\nfixes bug 1201964\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\nChange-Id: I04a275cf8d2cc7665720329000fbe087aa636b21\n'}, {'number': 2, 'created': '2013-07-16 23:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e26647b9d2ff367761df183ff9820ed6bbfa0b69', 'message': 'Fix virtual power driver fails silently when MAC not found.\n\nThis patch changes the behavior of Virtual Power driver. VPD will\nnow raise an exception should the mac address for the node not\nbe found. It will also log the node name and mac address.\n\nfixes bug 1201964\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\nChange-Id: I04a275cf8d2cc7665720329000fbe087aa636b21\n'}, {'number': 3, 'created': '2013-07-17 00:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14db3d9b1e3a1204fe0b62a7a627cb11a8877a68', 'message': 'Fix virtual power driver fails silently when MAC not found.\n\nThis patch changes the behavior of Virtual Power driver. VPD will\nnow raise an exception should the mac address for the node not\nbe found. It will also log the node name and mac address.\n\nfixes bug 1201964\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\nChange-Id: I04a275cf8d2cc7665720329000fbe087aa636b21\n'}, {'number': 4, 'created': '2013-08-05 17:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/421e61863b79f78d839b9aea25c0bff30075353c', 'message': 'Fix virtual power driver fails silently when MAC not found.\n\nThis patch changes the behavior of Virtual Power driver. VPD will\nnow raise an exception should the mac address for the node not\nbe found. It will also log the node name and mac address.\n\nfixes bug 1201964\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\nChange-Id: I04a275cf8d2cc7665720329000fbe087aa636b21\n'}, {'number': 5, 'created': '2013-08-05 19:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a952f6685ddd29b9b5571408d5caf1751fdebee6', 'message': 'Fix virtual power driver fails silently when MAC not found\n\nThis patch changes the behavior of Virtual Power driver. VPD will\nnow raise an exception should the mac address for the node not\nbe found. It will also log the node name and mac address.\n\nfixes bug 1201964\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\nChange-Id: I04a275cf8d2cc7665720329000fbe087aa636b21\n'}, {'number': 6, 'created': '2013-08-05 22:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d30f4e324847131c76bb45d82918986353d47abf', 'message': 'Fix virtual power driver fails silently when MAC not found\n\nThis patch changes the behavior of Virtual Power driver. VPD will\nnow raise an exception should the mac address for the node not\nbe found. It will also log the node name and mac address.\n\nfixes bug 1201964\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\nChange-Id: I04a275cf8d2cc7665720329000fbe087aa636b21\n'}, {'number': 7, 'created': '2013-08-29 00:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/67f03cbe6fdb1295ed87142ea35e645d8ad9e728', 'message': 'Fix virtual power driver fails silently when MAC not found\n\nThis patch changes the behavior of Virtual Power driver. VPD will\nnow raise an exception should the mac address for the node not\nbe found. It will also log the node name and mac address.\n\nfixes bug 1201964\nAuthored-by: Chris Krelle <nobodycam@gmail.com>\nChange-Id: I04a275cf8d2cc7665720329000fbe087aa636b21\n'}, {'number': 8, 'created': '2013-08-30 17:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c99895aea5b355091965736b2d9636e4e4928f4', 'message': 'Fix virtual power driver fails silently\n\nThis patch changes the behavior of Virtual Power driver. VPD will\nnow raise an exception should the mac address for the node not\nbe found. It will also log the node name and mac address.\n\nfixes bug 1201964\nChange-Id: I04a275cf8d2cc7665720329000fbe087aa636b21\n'}, {'number': 9, 'created': '2013-08-30 17:58:15.000000000', 'files': ['nova/tests/virt/baremetal/test_virtual_power_driver.py', 'nova/virt/baremetal/virtual_power_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b64eca85b2276021bfe1031845cad34e2c291006', 'message': 'Fix virtual power driver fails silently\n\nThis patch changes the behavior of Virtual Power driver. VPD will\nnow raise an exception should the mac address for the node not\nbe found. It will also log the node name and mac address.\n\nfixes bug 1201964\nChange-Id: I04a275cf8d2cc7665720329000fbe087aa636b21\n'}]",6,37350,b64eca85b2276021bfe1031845cad34e2c291006,41,13,9,5805,,,0,"Fix virtual power driver fails silently

This patch changes the behavior of Virtual Power driver. VPD will
now raise an exception should the mac address for the node not
be found. It will also log the node name and mac address.

fixes bug 1201964
Change-Id: I04a275cf8d2cc7665720329000fbe087aa636b21
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/37350/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/baremetal/test_virtual_power_driver.py', 'nova/virt/baremetal/virtual_power_driver.py']",2,03a5e77eee62a79825b159abc432f78ccf41f682,bug/1201964," CONF.baremetal.virtual_power_type) CONF.baremetal.virtual_power_type err_msg = _('Node ""%s"" with MAC address: %s not found.' % (self._node_name, self._mac_addresses)) LOG.error(err_msg) raise exception.NovaException(err_msg)", CONF.baremetal.virtual_power_type) CONF.baremetal.virtual_power_type return False,7,5
openstack%2Fneutron~master~Ic1818e10bd64170b6f0a2f52af8dc0814d7e04e0,openstack/neutron,master,Ic1818e10bd64170b6f0a2f52af8dc0814d7e04e0,Add jump to float-snat chain after clearing snat chain,MERGED,2013-08-28 19:23:27.000000000,2013-09-04 17:34:12.000000000,2013-09-04 17:34:12.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1131}, {'_account_id': 1970}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6522}, {'_account_id': 7448}]","[{'number': 1, 'created': '2013-08-28 19:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5d90ca13f42f95e1c5766b556bd1ac1e5a7bae92', 'message': 'Add jump to float-snat chain after clearing snat chain\n\nClearing the chain in this code eliminates the rule to jump to the\nfloating-snat chain.  This is the simplest way to get it working\nagain.\n\nChange-Id: Ic1818e10bd64170b6f0a2f52af8dc0814d7e04e0\nFixes: Bug #1218040\n'}, {'number': 2, 'created': '2013-08-28 19:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd9d6cd245bb7351ec938d7f32a9c6ebb2a48beb', 'message': 'Add jump to float-snat chain after clearing snat chain\n\nClearing the chain in this code eliminates the rule to jump to the\nfloating-snat chain.  This is the simplest way to get it working\nagain.\n\nChange-Id: Ic1818e10bd64170b6f0a2f52af8dc0814d7e04e0\nFixes: Bug #1218040\n'}, {'number': 3, 'created': '2013-08-29 16:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/65e985e182f416b5297f13cf1c25e08827ae5718', 'message': 'Add jump to float-snat chain after clearing snat chain\n\nClearing the chain in this code eliminates the rule to jump to the\nfloating-snat chain.  This is the simplest way to get it working\nagain.\n\nChange-Id: Ic1818e10bd64170b6f0a2f52af8dc0814d7e04e0\nFixes: Bug #1218040\n'}, {'number': 4, 'created': '2013-08-29 16:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2551b48929ae1629bde8c17f89349108a715e1bc', 'message': 'Add jump to float-snat chain after clearing snat chain\n\nClearing the chain in this code eliminates the rule to jump to the\nfloating-snat chain.  This is the simplest way to get it working\nagain.\n\nChange-Id: Ic1818e10bd64170b6f0a2f52af8dc0814d7e04e0\nFixes: Bug #1218040\n'}, {'number': 5, 'created': '2013-08-30 21:43:05.000000000', 'files': ['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/169729cd114603b355faf5effd08ea660b81551f', 'message': 'Add jump to float-snat chain after clearing snat chain\n\nClearing the chain in this code eliminates the rule to jump to the\nfloating-snat chain.  This is the simplest way to get it working\nagain.\n\nChange-Id: Ic1818e10bd64170b6f0a2f52af8dc0814d7e04e0\nFixes: Bug #1218040\n'}]",6,44133,169729cd114603b355faf5effd08ea660b81551f,33,9,5,7448,,,0,"Add jump to float-snat chain after clearing snat chain

Clearing the chain in this code eliminates the rule to jump to the
floating-snat chain.  This is the simplest way to get it working
again.

Change-Id: Ic1818e10bd64170b6f0a2f52af8dc0814d7e04e0
Fixes: Bug #1218040
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/44133/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3_agent.py'],1,5d90ca13f42f95e1c5766b556bd1ac1e5a7bae92,bug/1218040," # Add back the jump to float-snat ri.iptables_manager.ipv4['nat'].add_rule('snat', '-j $float-snat') ",,4,0
openstack%2Fneutron~master~I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0,openstack/neutron,master,I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0,Reference driver implementation (IPsec) for VPNaaS,MERGED,2013-07-06 16:06:39.000000000,2013-09-04 17:33:32.000000000,2013-09-04 17:33:31.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 2031}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6659}, {'_account_id': 6820}, {'_account_id': 6914}, {'_account_id': 7317}, {'_account_id': 7617}]","[{'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13a38cd03ff2b81a05bc03650a122c6f566c89fd', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nNote: Currently WIP code\n\nTODOS:\n  Unit Tests\n\nFuture work:\n  VPN connection status update by actual status\n  Support multiple driver\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/92ddfb62823f5d1f40ab861e49def78ecda45a68', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nNote: Currently WIP code\n\nTODOS:\n  Unit Tests\n\nFuture work:\n  VPN connection status update by actual status\n  Support multiple driver\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1956d88e0543535d2385e6b52c6c2e06337f7f32', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nNote: Currently WIP code\n\nTODOS:\n  Unit Tests\n\nFuture work:\n  VPN connection status update by actual status\n  Support multiple driver\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 7, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/480175302e9b53a1f6597a3eb0b497e50e5bdf1e', 'message': ""Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nNote: Currently WIP code\n\nTODOS:\n  Merge Fran's nswrapper\n  Unit Tests\n     VpnRpcPlugin and plugin side rpc api\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n""}, {'number': 6, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e91da96207833da814841800c768f59171b638f5', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nNote: Currently WIP code\n\nTODOS:\n  Unit Tests\n\nFuture work:\n  VPN connection status update by actual status\n  Support multiple driver\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 5, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8b6351a034dbe4f6407b21a2a5b1e3dc7ce952af', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nNote: Currently WIP code\n\nTODOS:\n  Unit Tests\n\nFuture work:\n  VPN connection status update by actual status\n  Support multiple driver\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/58769b3f27abe0fe86fabf81cf586bc9a784e9e0', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nNote: Currently WIP code\n\nTODOS:\n  Unit Tests\n\nFuture work:\n  VPN connection status update by actual status\n  Support multiple driver\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 11, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8aeaba652fde28c3c73e3887e8c97be2e52d9367', 'message': ""Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nNote: Currently WIP code\n\nTODOS:\n  Merge Fran's nswrapper\n  Unit Tests\n     VpnRpcPlugin and plugin side rpc api\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n""}, {'number': 10, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c7d5aac50c58de2c0c17752253fdca1412770fd3', 'message': ""Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nNote: Currently WIP code\n\nTODOS:\n  Merge Fran's nswrapper\n  Unit Tests\n     VpnRpcPlugin and plugin side rpc api\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n""}, {'number': 9, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9be0dd971aa7e5b8e0400d4c909f08369276cfae', 'message': ""Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nNote: Currently WIP code\n\nTODOS:\n  Merge Fran's nswrapper\n  Unit Tests\n     VpnRpcPlugin and plugin side rpc api\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n""}, {'number': 8, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a2bef52dd0fa6278c05ec0a42d0cd173612b1545', 'message': ""Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nNote: Currently WIP code\n\nTODOS:\n  Merge Fran's nswrapper\n  Unit Tests\n     VpnRpcPlugin and plugin side rpc api\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n""}, {'number': 15, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6fbe92e6ce68147a350f94d42fb94a112f1bee8c', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n\nThis patch introduces quantum-vpn-nswrap command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/quantum-rootwrap /etc/quantum/rootwrap.conf \\\nip netns exec test_ns quantum-netns-wrapper -d \\\n--cmd ""ipsec, start"" \\\n--mount_paths /etc,/var/run \\\n--mount_prefix /opt/stack/data/quantum/ipsec/ \\\n--rootwrap_config /etc/quantum/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 14, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/09595596fabe695b4862d967bf03af55357152c6', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n\nThis patch introduces quantum-vpn-nswrap command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/quantum-rootwrap /etc/quantum/rootwrap.conf \\\nip netns exec test_ns quantum-netns-wrapper -d \\\n--cmd ""ipsec, start"" \\\n--mount_paths /etc,/var/run \\\n--mount_prefix /opt/stack/data/quantum/ipsec/ \\\n--rootwrap_config /etc/quantum/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 13, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cc5ef3d6712985d0d75121bda3256e300fa75350', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n\nThis patch introduces quantum-vpn-nswrap command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/quantum-rootwrap /etc/quantum/rootwrap.conf \\\nip netns exec test_ns quantum-netns-wrapper -d \\\n--cmd ""ipsec, start"" \\\n--mount_paths /etc,/var/run \\\n--mount_prefix /opt/stack/data/quantum/ipsec/ \\\n--rootwrap_config /etc/quantum/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 12, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4fdd34f3e15c7b54c35048253a61bc7c8daea126', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n\nThis patch introduces quantum-vpn-nswrap command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/quantum-rootwrap /etc/quantum/rootwrap.conf \\\nip netns exec test_ns quantum-netns-wrapper -d \\\n--cmd ""ipsec, start"" \\\n--mount_paths /etc,/var/run \\\n--mount_prefix /opt/stack/data/quantum/ipsec/ \\\n--rootwrap_config /etc/quantum/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 16, 'created': '2013-07-09 06:44:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/611a1e60fcc596284d6a66d787096beca9799015', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\nThis patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc,/var/run \\\n--mount_prefix /opt/stack/data/neutron/ipsec/ \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 17, 'created': '2013-07-09 07:17:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a0b5ae1fcf48e8f7d48b14bdacc87d74498fb4dc', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\nThis patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc,/var/run \\\n--mount_prefix /opt/stack/data/neutron/ipsec/ \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 18, 'created': '2013-07-09 07:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9af41d264695f1666579d8706df8719d4dd247bc', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\nThis patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc,/var/run \\\n--mount_prefix /opt/stack/data/neutron/ipsec/ \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 19, 'created': '2013-07-09 21:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3eb2e1d2ed59ec4e8d75e76a8701a0a209959982', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\n- This patch will add Cheetah for dependencies.\nCheetah is template library used for generating config file.\nThis is same way as Nova doing.\n\n- This patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 20, 'created': '2013-07-12 21:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d0a00b7942ad050a84000fd6b9417ca604fe95c', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\n- This patch will add Cheetah for dependencies.\nCheetah is template library used for generating config file.\nThis is same way as Nova doing.\n\n- This patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 21, 'created': '2013-07-16 01:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3fbbfee4ea540212388b01321bd71b89702dce4', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\n- This patch will add Cheetah for dependencies.\nCheetah is template library used for generating config file.\nThis is same way as Nova doing.\n\n- This patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 22, 'created': '2013-07-16 01:36:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c0e12cdeff99f769899baf6e61a174e9d90f75c8', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\n- This patch will add Cheetah for dependencies.\nCheetah is template library used for generating config file.\nThis is same way as Nova doing.\n\n- This patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 23, 'created': '2013-07-16 03:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ef3b1900aa43b7be1b5633715b6e79e6dc017294', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\n- This patch will add Cheetah for dependencies.\nCheetah is template library used for generating config file.\nThis is same way as Nova doing.\n\n- This patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 24, 'created': '2013-07-16 18:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/443fb8fd2fe836e6cb0d8cc945f4360af64f68ad', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\n- This patch will add Mako for dependencies.\nMako is template library used for generating config file.\n\n- This patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 25, 'created': '2013-07-16 21:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/02d15c7689ac7da7cba91d6d15e02e48bece50da', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\n- This patch will add Jinja2 for dependencies.\nJinja2 is template library used for generating config file.\n\n- This patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 26, 'created': '2013-07-16 23:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39d98d9757694b1d9c1f29fcc98a7f8ccd456fa3', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\n- This patch will add Jinja2 for dependencies.\nJinja2 is template library used for generating config file.\n\n- This patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 27, 'created': '2013-07-17 14:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/76abb287f7e16febf102bc18ab3b135c7754409f', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation\nfor VPNaaS.\nThe driver uses strongswan to manage vpn connections\n\nFuture work:\n  VPN connection status update by actual status\n  Support ikepolicy and ipsec update\n  Support multiple driver\n  Support service type framework\n\n- This patch will add Jinja2 for dependencies.\nJinja2 is template library used for generating config file.\n\n- This patch introduces neutron-netns-wrapper command.\nStrongswan that will be used for this first implementation can\'t\nbe launched several times in the same host ""as is"", because its\nconfiguration, pid and control socket files location are hard coded.\n\nAs Strongswan will be launched in a network namespace using ""ip netns""\ncommand, it will also run in a mount namespace created by this command.\n\nThe solution consists in using a wrapper that bind-mount the required\ndirectories in a speratate folder, this mount will only affect the subprocess\nlaunched by the wrapper.\n\nThis wrapper also enforces rootwrap filter validation to make sure it can\'t\nbe used to run unauthorized commands as root\n\nThe wrapper can be launched as follow:\nsudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf \\\nip netns exec test_ns neutron-netns-wrapper -d \\\n--cmd ""ipsec,start"" \\\n--mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n--rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 28, 'created': '2013-07-17 17:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e221f119bd14a2073058fb0c8e9d912905ecce9', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nReference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nVPN connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 29, 'created': '2013-07-19 08:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/70ab2106734fffba2f6e003cf58c148dc4381d4f', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nVPN connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 30, 'created': '2013-07-19 19:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/038da5c7ede715dbe9a21e053f694423e7dc4ed3', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nVPN connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 31, 'created': '2013-07-22 20:17:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/280cc8420a8e151740efd860f711113dcfb90f1f', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nVPN connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 32, 'created': '2013-07-23 18:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2da393571efe10341da9d1ee575707326349ab88', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 33, 'created': '2013-07-23 18:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c1b8cdd510aae488b4aa3821161c7adbc5c08edb', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 34, 'created': '2013-07-23 22:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b2c2ddc21040cff145be26affbe0fea4060d1d3', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 35, 'created': '2013-07-23 22:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/06498ae7fb759eeb982615730e9dfbdc25479e5e', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 36, 'created': '2013-07-25 00:30:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/27981e746c62da45c5dbf3218def2f818af583b4', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 37, 'created': '2013-07-25 18:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a1d2b0688ade60151773ebda005c3f2d117c5cb', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 38, 'created': '2013-07-25 21:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ac068122fd6a268a3c35a79d2f7663d290b147a6', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 39, 'created': '2013-07-25 22:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/04010be279ea72e7e6c8574bf0b2f31ab37246bc', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 40, 'created': '2013-07-29 22:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f98dab433b601918e5be2ec9baa70741e82334a2', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 41, 'created': '2013-07-30 20:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b15de5818c5662c2274cd08c80b4819be73b6cdd', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 42, 'created': '2013-07-30 23:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/142386d7346256719d7afd1cf1df578404fb6910', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 43, 'created': '2013-08-02 01:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d1bf2fcc9fd63dd0c835fcfaa6de0d093fde1584', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 44, 'created': '2013-08-02 05:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb3e94c0d18b843c07de769ab2dbc944ce9d5dc1', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 45, 'created': '2013-08-02 15:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/00ba420baf1076c3af6dfa27308d08bc4e36887c', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 46, 'created': '2013-08-05 18:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/745d12d215c8689a0dba0c67162b1f50f488b128', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 47, 'created': '2013-08-06 18:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a03be66c2dc4f86c7147d55e721f739f7cb2c3c', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 48, 'created': '2013-08-08 17:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d917b664812d490175cbcd52992a2a23c4d3384', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 49, 'created': '2013-08-08 20:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/648cf66cc3738183ec0d3aff784150970def55ee', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 50, 'created': '2013-08-09 17:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eebf8d236744da7287b9949e5787a204742878a4', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 51, 'created': '2013-08-09 17:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5235b56531f7717189ddc5653e4dfe6fc1ebe8e9', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 52, 'created': '2013-08-14 21:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f436a97c75e883f7a5b42a6bc7dba506fc6e6324', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 53, 'created': '2013-08-15 22:40:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/40be11a82b410067079c1ccc4cdac9add9e5c2c8', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 54, 'created': '2013-08-15 23:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fcca4c8bc8d84957f33d4c56e26ce4a16c98ea71', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 55, 'created': '2013-08-15 23:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ba99bfa40708abf1d65c437a0cdd3e3f13258e6', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 56, 'created': '2013-08-16 15:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/df89319623d66da8378496e134e18cee713ce102', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 57, 'created': '2013-08-17 00:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cb830f246c418ab59a98da2f12a46776ed3c4385', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 58, 'created': '2013-08-20 06:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/868b4d3373151bbab06cf5c08bd7339f64cc2e38', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 59, 'created': '2013-08-20 18:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d91210502fe2ffcb731e381e7141efd74c7e6275', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 60, 'created': '2013-08-20 18:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/65003ad776d864e88a17d4f41ee8a9c19da7c6f0', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 61, 'created': '2013-08-21 00:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e8b15987e586f3e0f09838395c2b5bbd8cf40e3a', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 62, 'created': '2013-08-21 17:38:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/085d664b739456b6c3a1b7f8c61438b80003debd', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 63, 'created': '2013-08-22 19:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b8d7d4731e6f0b04705268ae2e431d91dbe0104', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 64, 'created': '2013-08-22 19:47:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/02a1d4cda05171c0139027034526bb7e18920d99', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 65, 'created': '2013-08-22 19:48:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e1b20be4d25a2dc8a771deabc36d25036a192e5a', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 66, 'created': '2013-08-22 20:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4913364a711815ecb1d5a69976da6ec7c73d16a8', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 67, 'created': '2013-08-26 15:18:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cfa109b884b925b1cb5881b1e7f4a85561d5558c', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses strongswan to manage vpn connections.\n\nFuture work:\nIPSec Site connection status update by actual status\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nThis patch introduces neutron-netns-wrapper command.\n- Multiple instances of Strongswan cannot be launched in the same host ""as is"",\n  because the locations of its configuration,  pid and control socket file\n  are hard coded.\n  In addition,  since Strongswan will be launched in a network namespace\n  using ""ip netns"" command,  it needs to run in a mount namespace created\n  by this command.\n- The solution is to use a wrapper that bind-mount the required directories\n  in a separate folder. This mount will only affect the subprocess launched\n  by the wrapper.\n- This wrapper also enforces rootwrap filter validation to make sure it can\'t\n  be used to run unauthorized commands as root.\n- The wrapper can be launched as follow:\n\nip netns exec test_ns neutron-netns-wrapper -d \\\n  --cmd ""ipsec,start"" \\\n  --mount_paths /etc:/some_dir/etc,/var/run:/some_dir/var/run \\\n  --rootwrap_config /etc/neutron/rootwrap.conf\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 68, 'created': '2013-08-26 22:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e619e5c2b515f5066b09ec75f8cd64f11ab1e1d7', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work:\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 69, 'created': '2013-08-27 01:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f89a483942094df37399f6149f770575f1d468d', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work:\nSupport ikepolicy and ipsec update\nSupport multiple driver\nSupport service type framework\nIntelligent updating of resources\n\nThis patch will add Jinja2 for dependencies. Jinja2 is a template library\nused to generate strongswan config files.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 70, 'created': '2013-08-27 19:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/05b14214c66179f0bccb6abd9753336652d2cedf', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 71, 'created': '2013-08-28 15:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e99d7228a5d3ee8062da47313d92359124f29d2', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 72, 'created': '2013-08-29 17:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4820e146f539189115173e02afaf7090e5abe085', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 73, 'created': '2013-08-29 19:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dae261102db186896e07283076ab7f231c09decc', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 74, 'created': '2013-09-03 19:41:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e73f8069ea6bf863dca95b41cd27c35efa035d4e', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 75, 'created': '2013-09-03 20:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/90ba8234550df9412fbee13a63ec4ff1578989f2', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 76, 'created': '2013-09-03 22:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c97033e2c607bb8856320a67781176ac9b332d7b', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 77, 'created': '2013-09-04 01:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/24cd646c4d7c7384cf786eda218a1840b3e686d6', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 78, 'created': '2013-09-04 01:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6ebcd6b73ab8842fd0f41f672d8860edeb56cdb5', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 79, 'created': '2013-09-04 02:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1cf52a26fc0ad208ee6f046acab041bd27bdfb75', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 80, 'created': '2013-09-04 05:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6c7ebe201065b945ff0a22dbfe4d3eb76cbbd586', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 81, 'created': '2013-09-04 07:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bb170960c862c9b936cfb3e5a762983b2b780b06', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}, {'number': 82, 'created': '2013-09-04 07:52:00.000000000', 'files': ['neutron/services/vpn/device_drivers/template/openswan/ipsec.conf.template', 'neutron/db/vpn/vpn_db.py', 'neutron/agent/l3_agent.py', 'neutron/services/vpn/agent.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron/services/vpn/device_drivers/ipsec.py', 'requirements.txt', 'neutron/plugins/common/utils.py', 'neutron/plugins/common/constants.py', 'neutron/tests/unit/nicira/test_nicira_plugin.py', 'neutron/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/services/vpn/device_drivers/template/openswan/ipsec.secret.template', 'neutron/services/vpn/common/topics.py', 'etc/vpn_agent.ini', 'neutron/extensions/vpnaas.py', 'neutron/tests/unit/services/vpn/device_drivers/__init__.py', 'neutron/tests/unit/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron/services/vpn/plugin.py', 'neutron/tests/unit/metaplugin/test_basic.py', 'neutron/services/vpn/device_drivers/__init__.py', 'neutron/services/vpn/service_drivers/ipsec.py', 'setup.cfg', 'etc/neutron/rootwrap.d/vpnaas.filters', 'neutron/services/vpn/common/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bba99f29ad8500770bd838366c96ae371787d98f', 'message': 'Reference driver implementation (IPsec) for VPNaaS\n\nImplements blueprint ipsec-vpn-reference\n\nThis patch implements reference driver implementation for VPNaaS.\nThe driver uses openswan to manage vpn connections.\n\nFuture work: Support ikepolicy and ipsec update\nSupport service type framework\nIntelligent updating of resources\n\nThis commit adds jinja2 for requirements.txt for\ngenerating cofig file.\n\nChange-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0\n'}]",523,33148,bba99f29ad8500770bd838366c96ae371787d98f,343,14,82,2031,,,0,"Reference driver implementation (IPsec) for VPNaaS

Implements blueprint ipsec-vpn-reference

This patch implements reference driver implementation for VPNaaS.
The driver uses openswan to manage vpn connections.

Future work: Support ikepolicy and ipsec update
Support service type framework
Intelligent updating of resources

This commit adds jinja2 for requirements.txt for
generating cofig file.

Change-Id: I8c5ed800a71ca014dc7bdbb6a57c4f8d18fa82e0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/48/33148/51 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/plugins/services/agent_vpn/device_drivers/strongswan_driver.py', 'quantum/db/vpn/vpn_db.py', 'quantum/plugins/services/agent_vpn/plugin.py', 'quantum/plugins/services/agent_vpn/vpn_drivers/__init__.py', 'quantum/plugins/services/agent_vpn/device_drivers/template/ipsec.conf.template', 'bin/quantum-vpn-nswrap', 'quantum/agent/l3_agent.py', 'requirements.txt', 'etc/quantum/rootwrap.d/vpnaas.filters', 'quantum/plugins/services/agent_vpn/vpn_drivers/ipsec_driver.py', 'quantum/plugins/services/agent_vpn/device_drivers/template/ipsec.secret.template', 'quantum/plugins/services/agent_vpn/device_drivers/template/strongswan.conf.template', 'bin/quantum-vpn-agent', 'quantum/plugins/services/agent_vpn/common/topics.py', 'quantum/common/config.py', 'setup.cfg', 'quantum/plugins/services/agent_vpn/vpn_agent.py', 'quantum/common/utils.py']",18,13a38cd03ff2b81a05bc03650a122c6f566c89fd,bp/ipsec-vpn-reference, def sqlalchemy_to_dict(obj): obj_dict = obj.__dict__.copy() del obj_dict['_sa_instance_state'] return obj_dict,,891,81
openstack%2Fneutron~master~I90aff8ec4324bd3a7c59c411374db6a118d1a72b,openstack/neutron,master,I90aff8ec4324bd3a7c59c411374db6a118d1a72b,Embrane Neutron Plugin,MERGED,2013-07-22 23:19:29.000000000,2013-09-04 17:33:23.000000000,2013-09-04 17:33:22.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 447}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 1689}, {'_account_id': 2031}, {'_account_id': 2035}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 6072}, {'_account_id': 7987}]","[{'number': 1, 'created': '2013-07-22 23:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad399debaa411efe673d0cfa5e76f5c562219472', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 2, 'created': '2013-08-05 21:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a030594ad466ce51a6d0188c9e8e9abfac80e5f4', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 3, 'created': '2013-08-06 00:03:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/76bbf7d5bf9c80e8162064eff69222a0c3bf76bb', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 4, 'created': '2013-08-06 22:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/62d6879bb3ba4fdf6da4bd966cd80d1a5f7ed227', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 5, 'created': '2013-08-07 01:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8451d5cc781b906dc00df11762313ddb218e83e9', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 6, 'created': '2013-08-07 20:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/752f3d55dc3d4625274b55c7307ebce825061481', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 7, 'created': '2013-08-11 15:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5d0c7f2008d9001451fc21f1de291343c2b583cd', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 8, 'created': '2013-08-14 05:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13b5ff883c5b35bba697e70603ee7f9ad6c57448', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 9, 'created': '2013-08-14 07:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39fbcbc2f18cc5731998aa0c8dd8f02688868490', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 10, 'created': '2013-08-23 01:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b6090e16c9623f9809c48f482b79e31aa944d75b', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 11, 'created': '2013-08-23 01:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/65ff17f8b595a6ad2950c5d0cc5b0b2e78e4e376', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 12, 'created': '2013-08-23 01:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4501355a0693b06f8a7817f5004945db7915211', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 13, 'created': '2013-08-26 20:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c81089cdec7f5aaeba40e90e57bb31107bd6fab1', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 14, 'created': '2013-08-30 20:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d9c046e4e39d8d7d0d3532196ec8cde84103d9a', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 15, 'created': '2013-09-01 23:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c69b28254a6b9dde2e2ed75133482c4644c251e', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 16, 'created': '2013-09-02 08:30:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d19be9cc9c6816054b041f1693200eb5301cd5f', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 17, 'created': '2013-09-02 13:30:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6ec07f860a9683cfe9085923d31412ce43d8880c', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 18, 'created': '2013-09-02 16:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/123d83caa7b15c5e4215d5b051bdff3986c2f540', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 19, 'created': '2013-09-04 00:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3c9d76d0890001bb80f2980d5096b0370605b6f0', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}, {'number': 20, 'created': '2013-09-04 09:55:24.000000000', 'files': ['neutron/plugins/embrane/agent/dispatcher.py', 'neutron/plugins/embrane/l2base/fake/__init__.py', 'neutron/plugins/embrane/agent/operations/__init__.py', 'neutron/plugins/embrane/common/config.py', 'neutron/plugins/embrane/common/exceptions.py', 'neutron/plugins/embrane/__init__.py', 'neutron/plugins/embrane/common/utils.py', 'neutron/plugins/embrane/common/operation.py', 'neutron/plugins/embrane/agent/operations/router_operations.py', 'neutron/tests/unit/embrane/test_embrane_neutron_plugin.py', 'neutron/plugins/embrane/l2base/support_base.py', 'neutron/plugins/embrane/plugins/__init__.py', 'neutron/plugins/embrane/plugins/embrane_fake_plugin.py', 'neutron/plugins/embrane/l2base/openvswitch/openvswitch_support.py', 'neutron/plugins/embrane/README', 'neutron/plugins/embrane/common/contexts.py', 'neutron/plugins/embrane/l2base/__init__.py', 'neutron/plugins/embrane/l2base/fake/fakeplugin_support.py', 'neutron/tests/unit/embrane/test_embrane_l3_plugin.py', 'neutron/plugins/embrane/plugins/embrane_ovs_plugin.py', 'neutron/tests/unit/embrane/__init__.py', 'neutron/plugins/embrane/agent/__init__.py', 'neutron/plugins/embrane/l2base/openvswitch/__init__.py', 'etc/neutron/plugins/embrane/heleos_conf.ini', 'neutron/plugins/embrane/base_plugin.py', 'neutron/plugins/embrane/l2base/fake/fake_l2_plugin.py', 'neutron/tests/unit/embrane/test_embrane_defaults.py', 'neutron/plugins/embrane/l2base/support_exceptions.py', 'neutron/plugins/embrane/common/__init__.py', 'neutron/plugins/embrane/common/constants.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4c3047ba4d46b3b6fe56940832e6e1142c2e441', 'message': 'Embrane Neutron Plugin\n\nImplements blueprint embrane-neutron-plugin\n\nThis commit implements the main Embrane plugin, which covers\nroute and extratoute extensions.\n\nThe plugin will rely on existing plugins for leveraging L2 networks,\nfor now it only supports OpenVSwitch and vlan networks, but more\nsupports are to come if the model is approved (or a different one\nis suggested).\n\nChange-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b\n'}]",230,38222,d4c3047ba4d46b3b6fe56940832e6e1142c2e441,90,17,20,7987,,,0,"Embrane Neutron Plugin

Implements blueprint embrane-neutron-plugin

This commit implements the main Embrane plugin, which covers
route and extratoute extensions.

The plugin will rely on existing plugins for leveraging L2 networks,
for now it only supports OpenVSwitch and vlan networks, but more
supports are to come if the model is approved (or a different one
is suggested).

Change-Id: I90aff8ec4324bd3a7c59c411374db6a118d1a72b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/22/38222/20 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/embrane/agent/dispatcher.py', 'neutron/plugins/embrane/api/backend_operations.py', 'neutron/plugins/embrane/agent/operations/__init__.py', 'neutron/plugins/embrane/api/__init__.py', 'neutron/plugins/embrane/common/config.py', 'neutron/plugins/embrane/common/exceptions.py', 'neutron/plugins/embrane/__init__.py', 'neutron/plugins/embrane/common/utils.py', 'neutron/plugins/embrane/EmbraneInit.py', 'neutron/plugins/embrane/embranerest/Exceptions.py', 'neutron/plugins/embrane/common/operation.py', 'neutron/plugins/embrane/embranerest/__init__.py', 'neutron/plugins/embrane/common/info.py', 'neutron/plugins/embrane/embranerest/rest.py', 'neutron/plugins/embrane/plugin.py', 'neutron/plugins/embrane/l2base/support_base.py', 'neutron/plugins/embrane/embranerest/Token.py', 'neutron/plugins/embrane/embranerest/objects.py', 'neutron/plugins/embrane/l2base/openvswitch/openvswitch_support.py', 'neutron/plugins/embrane/embranerest/dvalib.py', 'neutron/plugins/embrane/common/contexts.py', 'neutron/plugins/embrane/api/api_utils.py', 'neutron/plugins/embrane/l2base/__init__.py', 'neutron/plugins/embrane/embranerest/utils.py', 'neutron/plugins/embrane/agent/__init__.py', 'neutron/plugins/embrane/l2base/openvswitch/__init__.py', 'neutron/plugins/embrane/agent/operations/routerOperations.py', 'etc/neutron/plugins/embrane/heleos_conf.ini', 'neutron/plugins/embrane/embranerest/logger.py', 'neutron/plugins/embrane/embranerest/esmlib.py', 'neutron/plugins/embrane/embranerest/embrane.py', 'neutron/plugins/embrane/l2base/support_exceptions.py', 'neutron/plugins/embrane/common/__init__.py', 'neutron/plugins/embrane/common/constants.py']",34,ad399debaa411efe673d0cfa5e76f5c562219472,bp/embrane-neutron-plugin,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2013 Embrane, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http: //www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Ivar Lazzaro, Embrane, Inc. import inspect import sys DEFAULT_DP_COUNT = 1 DVA_CREATE_TASK_TIMEOUT = 900 DVA_DELETE_TASK_TIMEOUT = 80 class IterableConstants: pass class SupportedPlugins(IterableConstants): OVS = ""neutron.plugins.openvswitch.ovs_neutron_plugin.OVSNeutronPluginV2"" LNBRG = ""neutron.plugins.linuxbridge.lb_neutron_plugin.LinuxBridgePluginV2"" # Router specific constants class Router: UTIF_LIMIT = 7 class Status(IterableConstants): # Transient CREATING = ""CREATING"" PROVISIONING = ""PROVISIONING"" UPDATING = ""UPDATING"" DELETING = ""DELETING"" # Final ACTIVE = ""ACTIVE"" ERROR = ""ERROR"" READY = ""READY"" PENDING = ""PENDING"" DELETED = ""DELETED"" class Events: CREATE_ROUTER = ""create_router"" UPDATE_ROUTER = ""update_router"" CHANGE_ROUTER_STATE = ""change_router_state"" DELETE_ROUTER = ""delete_router"" GROW_ROUTER_IF = ""grow_router_if"" SHRINK_ROUTER_IF = ""shrink_router_if"" SET_NAT_RULE = ""set_nat_rule"" RESET_NAT_RULE = ""reset_nat_rule"" operationFilter = { Status.ACTIVE: [Events.DELETE_ROUTER, Events.GROW_ROUTER_IF, Events.SHRINK_ROUTER_IF, Events.UPDATE_ROUTER, Events.SET_NAT_RULE, Events.RESET_NAT_RULE], Status.PENDING: [Events.DELETE_ROUTER, Events.GROW_ROUTER_IF, Events.SHRINK_ROUTER_IF, Events.UPDATE_ROUTER], Status.READY: [Events.DELETE_ROUTER, Events.GROW_ROUTER_IF, Events.SHRINK_ROUTER_IF, Events.UPDATE_ROUTER], Status.ERROR: [Events.DELETE_ROUTER, Events.SHRINK_ROUTER_IF], Status.PROVISIONING: [Events.DELETE_ROUTER], Status.UPDATING: [Events.DELETE_ROUTER, Events.SHRINK_ROUTER_IF, Events.RESET_NAT_RULE], Status.CREATING: [Events.DELETE_ROUTER, Events.CREATE_ROUTER], Status.DELETING: [Events.DELETE_ROUTER]} # Embrane task status class TaskStatus(IterableConstants): IDLE = ""idle"" QUEUED = ""queued"" RUNNING = ""running"" PENDING = ""pending"" SUCCEEDED = ""succeeded"" PARTIALLY_SUCCEEDED = ""partiallySucceeded"" FAILED = ""failed"" CANCELLED = ""cancelled"" # DVA STATE class DvaState(IterableConstants): POWER_ON = ""powerOn"" POWER_OFF = ""powerOff"" READY = ""ready"" class DvaOperState(IterableConstants): POWERED_ON = ""poweredOn"" POWERED_OFF = ""poweredOff"" PREPROVISIONED = ""preprovisioned"" PROVISIONING = ""provisioning"" POWERING_ON = ""poweringOn"" POWERING_OFF = ""poweringOff"" PARKING = ""parking"" # OPERATION TYPE class OperationType(IterableConstants): ARCHITECTURAL_CHANGE = ""architectural_change"" DVA_CONFIG = ""dva_configuration"" # FLAVOR class Flavor(IterableConstants): MEDIUM = ""medium"" SMALL = ""small"" class SzType(IterableConstants): IB = ""inband"" OOB = ""oob"" MGMT = ""mgmt"" DUMMY = ""dummy_utif"" # ESM uri class EsmUri(IterableConstants): BASE = ""/api/esm"" PROJECTS = ""/projects"" IMAGES = ""/dva-images"" DVAS = ""/dvas"" SZ = ""/security-zones"" CP = ""/compute-pools"" INTERFACES = ""/interfaces"" NETWORKS = ""/networks"" RESOURCES = ""/resources"" TAGS = ""/tags"" # DVA uri class DvaUri(IterableConstants): BASE = ""/api"" INTERFACES = ""/dva/network/interfaces"" NAT = ""/dva/security/nat"" NETWORK_OBJECTS = ""/dva/security/objects/network"" ROUTES = ""/dva/network/routes"" SAVE_CONFIG = ""/dva/config/startup-config/save"" TAGS = ""/dva/tags"" # Attributes class Attribute(IterableConstants): NAME = ""name"" IF_COUNT = ""ifCount"" UUID = ""uuid"" OBJECT_ID = ""objectId"" TAGS = ""tags"" USER_TRAFFIC = ""userTrafficSecurityZone"" DP_COUNT = ""dpCount"" ADMINISTRATIVE_STATE = ""administrativeState"" OPERATIONAL_STATUS = ""operationalStatus"" ADMIN_STATE = ""adminState"" STATE = ""state"" MAC_ADDRESS = ""macAddress"" SUBNET = ""subnet"" ADDRESS = ""address"" PREFIX = ""prefix"" STATUS_MESSAGE = ""statusMessage"" TYPE = ""type"" PRIORITY = ""priority"" SOURCE = ""source"" NETWORK = ""network"" DESTINATION = ""destination"" DESCRIPTION = ""description"" ENABLED = ""enabled"" # tag_keys class Tag: class Key: ESM_DVA_CREATING = ""esm.dva.creating"" ESM_PROJECT_CREATING = ""esm.project.creating"" HUI_NETWORK_TYPE = ""__HUI_NETWORK_TYPE__"" HUI_NETWORK_TYPE_DEFAULT = ""__HUI_NETWORK_TYPE_DEFAULT__"" HUI_PROJECTS_DEFAULT = ""__HUI_PROJECTS_DEFAULT__"" OPENSTACK_FLOATING_ID = ""openstack.floating.id"" OPENSTACK_ID = ""openstack.id"" OPENSTACK_NETWORK_ID = ""openstack.network.id"" OPENSTACK_NETWORK_TYPE = ""openstack.network.type"" OPENSTACK_PORT_ID = ""openstack.port.id"" OPENSTACK_PORT_TYPE = ""openstack.port.type"" OPENSTACK_ROUTER_ID = ""openstack.router.id"" OPENSTACK_TENANT = ""openstack.tenant"" OPENSTACK_VALID = ""openstack.valid"" OPENSTACK_VSERVICE_ID = ""openstack.vservice.id"" class Value: DUMMY_ID = ""dummy_id"" GW_TYPE = ""gw_type"" TRUE = ""true"" FALSE = ""false"" DUMMY_INTERFACES_TAGS_DICT = {Key.OPENSTACK_PORT_ID: Value.DUMMY_ID, Key.OPENSTACK_PORT_TYPE: SzType.DUMMY} DUMMY_INTERFACES_TAGS_LIST = [ {""key"": Key.OPENSTACK_PORT_TYPE, ""value"": SzType.DUMMY}, {""key"": Key.OPENSTACK_PORT_ID, ""value"": Value.DUMMY_ID}] class UI: SZ_MAPPING = {SzType.MGMT: ""MANAGEMENT"", SzType.IB: ""IN_BAND"", SzType.OOB: ""OUT_OF_BAND"", SzType.DUMMY: None} module = sys.modules[__name__] members = inspect.getmembers(module, inspect.isclass) for name, obj in members: if issubclass(obj, IterableConstants): member_list = [getattr(obj, attr) for attr in dir(obj) if not callable(attr) and not attr.startswith(""_"")] obj._MEMBER_LIST = member_list ",,6045,0
openstack%2Fneutron~master~I538201742950a61b92fb05c49a9256bc96ae9014,openstack/neutron,master,I538201742950a61b92fb05c49a9256bc96ae9014,OpenFlow distributed router support in NEC plugin,MERGED,2013-08-24 07:01:44.000000000,2013-09-04 17:33:11.000000000,2013-09-04 17:33:11.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6659}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-08-24 07:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b75a8c3c1432717de204d3bddff45b360fc15f21', 'message': 'OpenFlow distributed router support in NEC plugin\n\nImplements bp/nec-distribute-router\n\nThis commit makes L3 agent notifiers configurable.\nl3-agent router and OpenFlow distributed router can coexist.\nNotication to l3-agent should be done only when routers are\nhosted by l3-agent, so we need custom L3 agent notifiers\nto filter non l3-agent routers.\n\nChange-Id: I538201742950a61b92fb05c49a9256bc96ae9014\n'}, {'number': 2, 'created': '2013-08-24 07:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e250f178dae1a5853a630b43cd85eb2a45a249f2', 'message': 'OpenFlow distributed router support in NEC plugin\n\nImplements bp/nec-distribute-router\n\nThis commit makes L3 agent notifiers configurable.\nl3-agent router and OpenFlow distributed router can coexist.\nNotication to l3-agent should be done only when routers are\nhosted by l3-agent, so we need custom L3 agent notifiers\nto filter non l3-agent routers.\n\nChange-Id: I538201742950a61b92fb05c49a9256bc96ae9014\n'}, {'number': 3, 'created': '2013-08-30 18:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3305430da5c180dc590ecaf379c8803afe094d2a', 'message': 'OpenFlow distributed router support in NEC plugin\n\nImplements blueprint nec-distribute-router\n\nTwo types of neutron router will be supported: l3-agent and distributed.\nA type can be specified through ""provider"" attribute of a router.\nThe naming of the attribute ""provider"" is intentional since I plan to\nsupport the service provider framework for router in the future and\nwould like to make it easy to migrate.\n\ndistributed router in NEC OpenFLow controller now does not support NAT,\nso l3-agent and distributed router coexists. To achieve it, l3-agent\nscheudler logic is modified in NEC plugin to exclude distributed routers\nfrom candidates of floating IP hosting routers.\n\nTo support the above feature, the following related changes are done:\n- Adds a new driver to PFC driver which supports OpenFlow based router\n  support in NEC OpenFlow products in PFlow v5.\n- Update ofc_client to extract detail error message\n  from OpenFlow controller\n\nThis commit also changes the following outside of NEC plugin:\n- Makes L3 agent notifiers configurable.\n  l3-agent router and OpenFlow distributed router can coexist.\n  Notication to l3-agent should be done only when routers are\n  hosted by l3-agent, so we need custom L3 agent notifiers\n  to filter non l3-agent routers.\n- Split test_agent_scheduler base class (in OVS plugin) into\n  the base setup and testcases. By doing so we can implement\n  custom testcases related to agent scheduler.\n\nChange-Id: I538201742950a61b92fb05c49a9256bc96ae9014\n'}, {'number': 4, 'created': '2013-08-31 08:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b2e5bc5c5e8fc1671b265fd53a5ddebcddf1fe0', 'message': 'OpenFlow distributed router support in NEC plugin\n\nImplements blueprint nec-distribute-router\n\nTwo types of neutron router will be supported: l3-agent and distributed.\nA type can be specified through ""provider"" attribute of a router.\nThe naming of the attribute ""provider"" is intentional since I plan to\nsupport the service provider framework for router in the future and\nwould like to make it easy to migrate.\n\ndistributed router in NEC OpenFLow controller now does not support NAT,\nso l3-agent and distributed router coexists. To achieve it, l3-agent\nscheudler logic is modified in NEC plugin to exclude distributed routers\nfrom candidates of floating IP hosting routers.\n\nTo support the above feature, the following related changes are done:\n- Adds a new driver to PFC driver which supports OpenFlow based router\n  support in NEC OpenFlow products in PFlow v5.\n- Update ofc_client to extract detail error message\n  from OpenFlow controller\n\nThis commit also changes the following outside of NEC plugin:\n- Makes L3 agent notifiers configurable.\n  l3-agent router and OpenFlow distributed router can coexist.\n  Notication to l3-agent should be done only when routers are\n  hosted by l3-agent, so we need custom L3 agent notifiers\n  to filter non l3-agent routers.\n- Split test_agent_scheduler base class (in OVS plugin) into\n  the base setup and testcases. By doing so we can implement\n  custom testcases related to agent scheduler.\n\nChange-Id: I538201742950a61b92fb05c49a9256bc96ae9014\n'}, {'number': 5, 'created': '2013-09-02 16:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e2c0c70c75a0e464a93a1ca4ad9811fa1fbef6bd', 'message': 'OpenFlow distributed router support in NEC plugin\n\nImplements blueprint nec-distribute-router\n\nTwo types of neutron router will be supported: l3-agent and distributed.\nA type can be specified through ""provider"" attribute of a router.\nThe naming of the attribute ""provider"" is intentional since I plan to\nsupport the service provider framework for router in the future and\nwould like to make it easy to migrate.\n\ndistributed router in NEC OpenFLow controller now does not support NAT,\nso l3-agent and distributed router coexists. To achieve it, l3-agent\nscheudler logic is modified in NEC plugin to exclude distributed routers\nfrom candidates of floating IP hosting routers.\n\nTo support the above feature, the following related changes are done:\n- Adds a new driver to PFC driver which supports OpenFlow based router\n  support in NEC OpenFlow products in PFlow v5.\n- Update ofc_client to extract detail error message\n  from OpenFlow controller\n\nThis commit also changes the following outside of NEC plugin:\n- Makes L3 agent notifiers configurable.\n  l3-agent router and OpenFlow distributed router can coexist.\n  Notication to l3-agent should be done only when routers are\n  hosted by l3-agent, so we need custom L3 agent notifiers\n  to filter non l3-agent routers.\n- Split test_agent_scheduler base class (in OVS plugin) into\n  the base setup and testcases. By doing so we can implement\n  custom testcases related to agent scheduler.\n\nChange-Id: I538201742950a61b92fb05c49a9256bc96ae9014\n'}, {'number': 6, 'created': '2013-09-03 13:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab7797536af0dca9863e17a1ad328955afec536c', 'message': 'OpenFlow distributed router support in NEC plugin\n\nImplements blueprint nec-distribute-router\n\nTwo types of neutron router will be supported: l3-agent and distributed.\nA type can be specified through ""provider"" attribute of a router.\nThe naming of the attribute ""provider"" is intentional since I plan to\nsupport the service provider framework for router in the future and\nwould like to make it easy to migrate.\n\ndistributed router in NEC OpenFLow controller now does not support NAT,\nso l3-agent and distributed router coexists. To achieve it, l3-agent\nscheudler logic is modified in NEC plugin to exclude distributed routers\nfrom candidates of floating IP hosting routers.\n\nTo support the above feature, the following related changes are done:\n- Adds a new driver to PFC driver which supports OpenFlow based router\n  support in NEC OpenFlow products in PFlow v5.\n- Update ofc_client to extract detail error message\n  from OpenFlow controller\n\nThis commit also changes the following outside of NEC plugin:\n- Makes L3 agent notifiers configurable.\n  l3-agent router and OpenFlow distributed router can coexist.\n  Notication to l3-agent should be done only when routers are\n  hosted by l3-agent, so we need custom L3 agent notifiers\n  to filter non l3-agent routers.\n- Split test_agent_scheduler base class (in OVS plugin) into\n  the base setup and testcases. By doing so we can implement\n  custom testcases related to agent scheduler.\n\nChange-Id: I538201742950a61b92fb05c49a9256bc96ae9014\n'}, {'number': 7, 'created': '2013-09-03 17:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a9b3c80f93bd43e2f2f5413a330bc2d9af389a39', 'message': 'OpenFlow distributed router support in NEC plugin\n\nImplements blueprint nec-distribute-router\n\nTwo types of neutron router will be supported: l3-agent and distributed.\nA type can be specified through ""provider"" attribute of a router.\nThe naming of the attribute ""provider"" is intentional since I plan to\nsupport the service provider framework for router in the future and\nwould like to make it easy to migrate.\n\ndistributed router in NEC OpenFLow controller now does not support NAT,\nso l3-agent and distributed router coexists. To achieve it, l3-agent\nscheudler logic is modified in NEC plugin to exclude distributed routers\nfrom candidates of floating IP hosting routers.\n\nTo support the above feature, the following related changes are done:\n- Adds a new driver to PFC driver which supports OpenFlow based router\n  support in NEC OpenFlow products in PFlow v5.\n- Update ofc_client to extract detail error message\n  from OpenFlow controller\n\nThis commit also changes the following outside of NEC plugin:\n- Makes L3 agent notifiers configurable.\n  l3-agent router and OpenFlow distributed router can coexist.\n  Notication to l3-agent should be done only when routers are\n  hosted by l3-agent, so we need custom L3 agent notifiers\n  to filter non l3-agent routers.\n- Split test_agent_scheduler base class (in OVS plugin) into\n  the base setup and testcases. By doing so we can implement\n  custom testcases related to agent scheduler.\n\nChange-Id: I538201742950a61b92fb05c49a9256bc96ae9014\n'}, {'number': 8, 'created': '2013-09-03 21:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3d68bcfc898e9a57f2bbbad9e06b97d9df54918', 'message': 'OpenFlow distributed router support in NEC plugin\n\nImplements blueprint nec-distribute-router\n\nTwo types of neutron router will be supported: l3-agent and distributed.\nA type can be specified through ""provider"" attribute of a router.\nThe naming of the attribute ""provider"" is intentional since I plan to\nsupport the service provider framework for router in the future and\nwould like to make it easy to migrate.\n\ndistributed router in NEC OpenFLow controller now does not support NAT,\nso l3-agent and distributed router coexists. To achieve it, l3-agent\nscheudler logic is modified in NEC plugin to exclude distributed routers\nfrom candidates of floating IP hosting routers.\n\nTo support the above feature, the following related changes are done:\n- Adds a new driver to PFC driver which supports OpenFlow based router\n  support in NEC OpenFlow products in PFlow v5.\n- Update ofc_client to extract detail error message\n  from OpenFlow controller\n\nThis commit also changes the following outside of NEC plugin:\n- Makes L3 agent notifiers configurable.\n  l3-agent router and OpenFlow distributed router can coexist.\n  Notication to l3-agent should be done only when routers are\n  hosted by l3-agent, so we need custom L3 agent notifiers\n  to filter non l3-agent routers.\n- Split test_agent_scheduler base class (in OVS plugin) into\n  the base setup and testcases. By doing so we can implement\n  custom testcases related to agent scheduler.\n\nChange-Id: I538201742950a61b92fb05c49a9256bc96ae9014\n'}, {'number': 9, 'created': '2013-09-04 02:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c316aaaa1af10da35913aeae45f29ba0a5c15b0f', 'message': 'OpenFlow distributed router support in NEC plugin\n\nImplements blueprint nec-distribute-router\n\nTwo types of neutron router will be supported: l3-agent and distributed.\nA type can be specified through ""provider"" attribute of a router.\nThe naming of the attribute ""provider"" is intentional since I plan to\nsupport the service provider framework for router in the future and\nwould like to make it easy to migrate.\n\ndistributed router in NEC OpenFLow controller now does not support NAT,\nso l3-agent and distributed router coexists. To achieve it, l3-agent\nscheudler logic is modified in NEC plugin to exclude distributed routers\nfrom candidates of floating IP hosting routers.\n\nTo support the above feature, the following related changes are done:\n- Adds a new driver to PFC driver which supports OpenFlow based router\n  support in NEC OpenFlow products in PFlow v5.\n- Update ofc_client to extract detail error message\n  from OpenFlow controller\n\nThis commit also changes the following outside of NEC plugin:\n- Makes L3 agent notifiers configurable.\n  l3-agent router and OpenFlow distributed router can coexist.\n  Notication to l3-agent should be done only when routers are\n  hosted by l3-agent, so we need custom L3 agent notifiers\n  to filter non l3-agent routers.\n- Split test_agent_scheduler base class (in OVS plugin) into\n  the base setup and testcases. By doing so we can implement\n  custom testcases related to agent scheduler.\n\nChange-Id: I538201742950a61b92fb05c49a9256bc96ae9014\n'}, {'number': 10, 'created': '2013-09-04 03:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f345ebf0425991b11aa5365d388bce8b182f04ce', 'message': 'OpenFlow distributed router support in NEC plugin\n\nImplements blueprint nec-distribute-router\n\nTwo types of neutron router will be supported: l3-agent and distributed.\nA type can be specified through ""provider"" attribute of a router.\nThe naming of the attribute ""provider"" is intentional since I plan to\nsupport the service provider framework for router in the future and\nwould like to make it easy to migrate.\n\ndistributed router in NEC OpenFLow controller now does not support NAT,\nso l3-agent and distributed router coexists. To achieve it, l3-agent\nscheudler logic is modified in NEC plugin to exclude distributed routers\nfrom candidates of floating IP hosting routers.\n\nTo support the above feature, the following related changes are done:\n- Adds a new driver to PFC driver which supports OpenFlow based router\n  support in NEC OpenFlow products in PFlow v5.\n- Update ofc_client to extract detail error message\n  from OpenFlow controller\n\nThis commit also changes the following outside of NEC plugin:\n- Makes L3 agent notifiers configurable.\n  l3-agent router and OpenFlow distributed router can coexist.\n  Notication to l3-agent should be done only when routers are\n  hosted by l3-agent, so we need custom L3 agent notifiers\n  to filter non l3-agent routers.\n- Split test_agent_scheduler base class (in OVS plugin) into\n  the base setup and testcases. By doing so we can implement\n  custom testcases related to agent scheduler.\n\nChange-Id: I538201742950a61b92fb05c49a9256bc96ae9014\n'}, {'number': 11, 'created': '2013-09-04 08:17:33.000000000', 'files': ['etc/neutron/plugins/nec/nec.ini', 'neutron/plugins/nec/common/ofc_client.py', 'neutron/tests/unit/nec/test_nec_plugin.py', 'neutron/plugins/nec/router_drivers.py', 'neutron/tests/unit/test_extension_extraroute.py', 'neutron/plugins/nec/db/router.py', 'neutron/tests/unit/nec/test_agent_scheduler.py', 'neutron/tests/unit/nec/test_ofc_manager.py', 'neutron/db/migration/alembic_migrations/versions/66a59a7f516_nec_openflow_router.py', 'neutron/plugins/nec/common/exceptions.py', 'neutron/plugins/nec/drivers/pfc.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'neutron/plugins/nec/drivers/__init__.py', 'neutron/plugins/nec/drivers/trema.py', 'neutron/plugins/nec/ofc_manager.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/plugins/nec/common/config.py', 'neutron/tests/unit/nec/test_pfc_driver.py', 'neutron/plugins/nec/nec_plugin.py', 'neutron/db/l3_db.py', 'neutron/plugins/nec/extensions/router_provider.py', 'neutron/plugins/nec/db/api.py', 'neutron/plugins/nec/db/models.py', 'neutron/plugins/nec/nec_router.py', 'neutron/tests/unit/nec/test_ofc_client.py', 'neutron/plugins/nec/common/constants.py', 'neutron/tests/unit/nec/test_router.py', 'neutron/tests/unit/nec/stub_ofc_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d2a5c0f982e8e4f9fbdce17b90925b8d8df56c75', 'message': 'OpenFlow distributed router support in NEC plugin\n\nImplements blueprint nec-distribute-router\n\nTwo types of neutron router will be supported: l3-agent and distributed.\nA type can be specified through ""provider"" attribute of a router.\nThe naming of the attribute ""provider"" is intentional since I plan to\nsupport the service provider framework for router in the future and\nwould like to make it easy to migrate.\n\ndistributed router in NEC OpenFLow controller now does not support NAT,\nso l3-agent and distributed router coexists. To achieve it, l3-agent\nscheudler logic is modified in NEC plugin to exclude distributed routers\nfrom candidates of floating IP hosting routers.\n\nTo support the above feature, the following related changes are done:\n- Adds a new driver to PFC driver which supports OpenFlow based router\n  support in NEC OpenFlow products in PFlow v5.\n- Update ofc_client to extract detail error message\n  from OpenFlow controller\n\nThis commit also changes the following outside of NEC plugin:\n- Makes L3 agent notifiers configurable.\n  l3-agent router and OpenFlow distributed router can coexist.\n  Notication to l3-agent should be done only when routers are\n  hosted by l3-agent, so we need custom L3 agent notifiers\n  to filter non l3-agent routers.\n- Split test_agent_scheduler base class (in OVS plugin) into\n  the base setup and testcases. By doing so we can implement\n  custom testcases related to agent scheduler.\n\nChange-Id: I538201742950a61b92fb05c49a9256bc96ae9014\n'}]",72,43573,d2a5c0f982e8e4f9fbdce17b90925b8d8df56c75,67,8,11,841,,,0,"OpenFlow distributed router support in NEC plugin

Implements blueprint nec-distribute-router

Two types of neutron router will be supported: l3-agent and distributed.
A type can be specified through ""provider"" attribute of a router.
The naming of the attribute ""provider"" is intentional since I plan to
support the service provider framework for router in the future and
would like to make it easy to migrate.

distributed router in NEC OpenFLow controller now does not support NAT,
so l3-agent and distributed router coexists. To achieve it, l3-agent
scheudler logic is modified in NEC plugin to exclude distributed routers
from candidates of floating IP hosting routers.

To support the above feature, the following related changes are done:
- Adds a new driver to PFC driver which supports OpenFlow based router
  support in NEC OpenFlow products in PFlow v5.
- Update ofc_client to extract detail error message
  from OpenFlow controller

This commit also changes the following outside of NEC plugin:
- Makes L3 agent notifiers configurable.
  l3-agent router and OpenFlow distributed router can coexist.
  Notication to l3-agent should be done only when routers are
  hosted by l3-agent, so we need custom L3 agent notifiers
  to filter non l3-agent routers.
- Split test_agent_scheduler base class (in OVS plugin) into
  the base setup and testcases. By doing so we can implement
  custom testcases related to agent scheduler.

Change-Id: I538201742950a61b92fb05c49a9256bc96ae9014
",git fetch https://review.opendev.org/openstack/neutron refs/changes/73/43573/6 && git format-patch -1 --stdout FETCH_HEAD,"['etc/neutron/plugins/nec/nec.ini', 'neutron/plugins/nec/common/ofc_client.py', 'neutron/tests/unit/nec/test_nec_plugin.py', 'neutron/tests/unit/test_extension_extraroute.py', 'neutron/plugins/nec/db/router.py', 'neutron/tests/unit/nec/test_ofc_manager.py', 'neutron/plugins/nec/common/exceptions.py', 'neutron/plugins/nec/drivers/pfc.py', 'neutron/plugins/nec/drivers/__init__.py', 'neutron/plugins/nec/drivers/trema.py', 'neutron/plugins/nec/ofc_manager.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/plugins/nec/common/config.py', 'neutron/tests/unit/nec/test_pfc_driver.py', 'neutron/plugins/nec/nec_plugin.py', 'neutron/db/l3_db.py', 'neutron/plugins/nec/db/api.py', 'neutron/plugins/nec/db/models.py', 'neutron/plugins/nec/nec_router.py', 'neutron/tests/unit/nec/_test_agent_scheduler.py', 'neutron/tests/unit/nec/test_ofc_client.py', 'neutron/plugins/nec/common/constants.py', 'neutron/tests/unit/nec/test_router.py', 'neutron/tests/unit/nec/stub_ofc_driver.py']",24,b75a8c3c1432717de204d3bddff45b360fc15f21,bp/nec-distribute-router,"import netaddr from neutron.openstack.common import log as logging from neutron.openstack.common import uuidutils from neutron.plugins.nec.common import exceptions as nexcLOG = logging.getLogger(__name__) MAX_NUM_OPENFLOW_ROUTER = 2 self.autocheck = False self.reset_all() def reset_all(self): self.ofc_tenant_dict = {} self.ofc_network_dict = {} self.ofc_port_dict = {} self.ofc_filter_dict = {} self.ofc_router_dict = {} self.ofc_router_inf_dict = {} self.ofc_router_route_dict = {} def enable_autocheck(self): self.autocheck = True def disable_autocheck(self): self.autocheck = False LOG.debug('create_tenant (tenant_id=%s, desc=%s)' % (tenant_id, description)) ofc_id = ""ofc-"" + tenant_id[:-4] if self.autocheck: if ofc_id in self.ofc_tenant_dict: raise Exception('(create_tenant) OFC tenant %s already exists' % ofc_id) self.ofc_tenant_dict[ofc_id] = {'tenant_id': tenant_id, 'description': description} return ofc_id LOG.debug('delete_tenant (ofc_tenant_id=%s)' % ofc_tenant_id) if ofc_tenant_id in self.ofc_tenant_dict: del self.ofc_tenant_dict[ofc_tenant_id] else: if self.autocheck: raise Exception('(delete_tenant) OFC tenant %s not found' % ofc_tenant_id) LOG.debug('delete_tenant: SUCCEED') LOG.debug('create_network (network_id=%s, ofc_tenant_id=%s, desc=%s)' % (network_id, ofc_tenant_id, description)) ofc_id = ""ofc-"" + network_id[:-4] if self.autocheck: if ofc_tenant_id not in self.ofc_tenant_dict: raise Exception('(create_network) OFC tenant %s not found' % ofc_tenant_id) if ofc_id in self.ofc_network_dict: raise Exception('(create_network) ' 'OFC network %s already exists' % ofc_id) self.ofc_network_dict[ofc_id] = {'tenant_id': ofc_tenant_id, 'network_id': network_id, 'description': description} return ofc_id LOG.debug('update_network (ofc_network_id=%s, desc=%s)' % (ofc_network_id, description)) if self.autocheck: if ofc_network_id not in self.ofc_network_dict: raise Exception('(update_network) OFC network %s not found' % ofc_network_id) data = {'description': description} self.ofc_network_dict[ofc_network_id].update(data) LOG.debug('update_network: SUCCEED') LOG.debug('delete_network (ofc_network_id=%s)' % ofc_network_id) if ofc_network_id in self.ofc_network_dict: del self.ofc_network_dict[ofc_network_id] else: if self.autocheck: raise Exception('(delete_network) OFC network %s not found' % ofc_network_id) LOG.debug('delete_network: SUCCEED') LOG.debug('create_port (port_id=%s, ofc_network_id=%s, info=%s)' % (port_id, ofc_network_id, info)) ofc_id = ""ofc-"" + port_id[:-4] if self.autocheck: if ofc_network_id not in self.ofc_network_dict: raise Exception('(create_port) OFC network %s not found' % ofc_network_id) if ofc_id in self.ofc_port_dict: raise Exception('(create_port) OFC port %s already exists' % ofc_id) self.ofc_port_dict[ofc_id] = {'network_id': ofc_network_id, 'port_id': port_id} return ofc_id LOG.debug('delete_port (ofc_port_id=%s)' % ofc_port_id) if ofc_port_id in self.ofc_port_dict: del self.ofc_port_dict[ofc_port_id] else: if self.autocheck: raise Exception('(delete_port) OFC port %s not found' % ofc_port_id) LOG.debug('delete_port: SUCCEED') @classmethod def router_supported(cls): return True def create_router(self, ofc_tenant_id, router_id, description): LOG.debug('create_router (router_id=%s, ofc_tenant_id=%s, desc=%s)' % (router_id, ofc_tenant_id, description)) ofc_id = ""ofc-"" + router_id[:-4] if self.autocheck: if ofc_tenant_id not in self.ofc_tenant_dict: raise Exception('(create_router) OFC tenant %s not found' % ofc_tenant_id) if ofc_id in self.ofc_router_dict: raise Exception('(create_router) OFC router %s already exists' % ofc_id) if len(self.ofc_router_dict) >= MAX_NUM_OPENFLOW_ROUTER: params = {'reason': _(""Operation on OFC is failed""), 'status': 409} raise nexc.OFCException(**params) self.ofc_router_dict[ofc_id] = {'tenant_id': ofc_tenant_id, 'router_id': router_id, 'description': description} return ofc_id def delete_router(self, ofc_router_id): LOG.debug('delete_router (ofc_router_id=%s)' % ofc_router_id) if ofc_router_id in self.ofc_router_dict: del self.ofc_router_dict[ofc_router_id] else: if self.autocheck: raise Exception('(delete_router) OFC router %s not found' % ofc_router_id) LOG.debug('delete_router: SUCCEED') def add_router_interface(self, ofc_router_id, ofc_net_id, ip_address=None, mac_address=None): LOG.debug('add_router_interface (ofc_router_id=%s, ofc_net_id=%s, ' 'ip_address=%s, mac_address=%s)' % (ofc_router_id, ofc_net_id, ip_address, mac_address)) if_id = ""ofc-"" + uuidutils.generate_uuid()[:-4] # IP address should have a format of a.b.c.d/N if ip_address != str(netaddr.IPNetwork(ip_address)): raise Exception('(add_router_interface) ' 'ip_address %s is not a valid format (a.b.c.d/N).' % ip_address) if self.autocheck: if ofc_router_id not in self.ofc_router_dict: raise Exception('(add_router_interface) ' 'OFC router %s not found' % ofc_router_id) if ofc_net_id not in self.ofc_network_dict: raise Exception('(add_router_interface) ' 'OFC network %s not found' % ofc_net_id) # Check duplicate destination self.ofc_router_inf_dict[if_id] = {'router_id': ofc_router_id, 'network_id': ofc_net_id, 'ip_address': ip_address, 'mac_address': mac_address} LOG.debug('add_router_interface: SUCCEED (if_id=%s)' % if_id) return if_id def update_router_interface(self, ofc_router_inf_id, ip_address=None, mac_address=None): if ofc_router_inf_id not in self.ofc_router_inf_dict: if self.autocheck: raise Exception('(delete_router_interface) ' 'OFC router interface %s not found' % ofc_router_inf_id) self.ofc_router_inf_dict[ofc_router_inf_id] = {} inf = self.ofc_router_inf_dict[ofc_router_inf_id] if ip_address: inf.update({'ip_address': ip_address}) if mac_address: inf.update({'mac_address': mac_address}) LOG.debug('update_router_route: SUCCEED') def delete_router_interface(self, ofc_router_inf_id): LOG.debug('add_router_interface (ofc_router_inf_id=%s)' % ofc_router_inf_id) if ofc_router_inf_id in self.ofc_router_inf_dict: del self.ofc_router_inf_dict[ofc_router_inf_id] else: if self.autocheck: raise Exception('(delete_router_interface) ' 'OFC router interface %s not found' % ofc_router_inf_id) LOG.debug('delete_router_interface: SUCCEED') def add_router_route(self, ofc_router_id, destination, nexthop): LOG.debug('add_router_route (ofc_router_id=%s, destination=%s, ' 'nexthop=%s)' % (ofc_router_id, destination, nexthop)) route_id = ""ofc-"" + uuidutils.generate_uuid()[:-4] # IP address format check netaddr.IPNetwork(destination) netaddr.IPAddress(nexthop) if self.autocheck: if ofc_router_id not in self.ofc_router_dict: raise Exception('(add_router_route) OFC router %s not found' % ofc_router_id) # Check duplicate destination if destination in [route['destination'] for route in self.ofc_router_route_dict.values()]: raise Exception('(add_router_route) ' 'route to ""%s"" already exists' % destination) self.ofc_router_route_dict[route_id] = {'router_id': ofc_router_id, 'destination': destination, 'nexthop': nexthop} LOG.debug('add_router_route: SUCCEED (route_id=%s)' % route_id) return route_id def delete_router_route(self, ofc_router_route_id): LOG.debug('delete_router_route (ofc_router_route_id=%s)' % ofc_router_route_id) if ofc_router_route_id in self.ofc_router_route_dict: del self.ofc_router_route_dict[ofc_router_route_id] else: if self.autocheck: raise Exception('(delete_router_route) OFC router route %s ' 'not found' % ofc_router_route_id) LOG.debug('delete_router_route: SUCCEED') def list_router_routes(self, ofc_router_id): LOG.debug('list_router_routes (ofc_router_id=%s)' % ofc_router_id) if self.autocheck: if ofc_router_id not in self.ofc_router_dict: raise Exception('(delete_router) OFC router %s not found' % ofc_router_id) routes = [{'id': k, 'destination': v['destination'], 'nexthop': v['nexthop']} for k, v in self.ofc_router_route_dict.items() if v['router_id'] == ofc_router_id] LOG.debug('list_router_routes: routes=%s' % routes) return routes"," pass return ""ofc-"" + tenant_id[:-4] pass return ""ofc-"" + network_id[:-4] pass pass return ""ofc-"" + port_id[:-4] pass",1654,83
openstack%2Fopenstack-manuals~master~I03f58f04f246a72f810492a7bf2e774e5b827921,openstack/openstack-manuals,master,I03f58f04f246a72f810492a7bf2e774e5b827921,Use localhost connection for cinder,MERGED,2013-09-02 17:25:35.000000000,2013-09-04 17:29:52.000000000,2013-09-04 17:29:51.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 1177}, {'_account_id': 6657}]","[{'number': 1, 'created': '2013-09-02 17:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ba9572b812223b32b0809850152c62cc84717790', 'message': 'Regarding to:\nhttp://docs.openstack.org/trunk/openstack-compute/install/yum/content/cinder-install.html\n\nAs mentioned in “Set up the cinder database.”, the “PRIVILEGES” giving to cinder are local. Therefore I think it’s important to emphasize that:\n“Edit /etc/cinder/cinder.conf to reflect your settings.” will give permission to local host. Thus, instead of:\nsql_connection = mysql://cinder:openstack@192.168.127.130/cinder\nshould be written:\nsql_connection = mysql://cinder:openstack@localhost/cinder\n\ntry to fix Bug #1214764\n\nChange-Id: I03f58f04f246a72f810492a7bf2e774e5b827921\n'}, {'number': 2, 'created': '2013-09-04 08:05:10.000000000', 'files': ['doc/src/docbkx/openstack-install/cinder-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/77685842fd2c62d11d03d26239c18871a4124998', 'message': 'Use localhost connection for cinder\n\nAs mentioned in “Set up the cinder database.”, the “PRIVILEGES” giving to cinder are local. Therefore I think it’s important to emphasize that:\n“Edit /etc/cinder/cinder.conf to reflect your settings.” will give permission to local host.\n\ntry to fix Bug #1214764\n\nChange-Id: I03f58f04f246a72f810492a7bf2e774e5b827921\n'}]",0,44750,77685842fd2c62d11d03d26239c18871a4124998,9,4,2,6657,,,0,"Use localhost connection for cinder

As mentioned in “Set up the cinder database.”, the “PRIVILEGES” giving to cinder are local. Therefore I think it’s important to emphasize that:
“Edit /etc/cinder/cinder.conf to reflect your settings.” will give permission to local host.

try to fix Bug #1214764

Change-Id: I03f58f04f246a72f810492a7bf2e774e5b827921
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/50/44750/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-install/cinder-install.xml'],1,ba9572b812223b32b0809850152c62cc84717790,bug/1214764,sql_connection = mysql://cinder:openstack@localhost/cinder,sql_connection = mysql://cinder:openstack@192.168.127.130/cinder,1,1
openstack%2Ftempest~master~Ic0fc8d39a87942e175256453c6c4347f6a5cfbba,openstack/tempest,master,Ic0fc8d39a87942e175256453c6c4347f6a5cfbba,emit warning while running flake8 without virtual env,MERGED,2013-08-22 22:42:44.000000000,2013-09-04 17:21:35.000000000,2013-09-04 17:21:34.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7774}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-08-22 22:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/80ed71f8c0077cbbd01d486445b72ff08fac504e', 'message': 'emit warning while running flake8 without virtual env\n\nrun_tests.sh -N -p\nit will call the flake8 installed on your host to detect PEP8, and\nthe flake8 plugin ""OpenStack hacking"" may not installed on your\nhost, so this command may not detect the OpenStack Style Commandment\nsupplied by hacking(e.g H202).\n\nrun_tests.sh -p\nit will call the flake8 from virtual env, flake8 plugin ""OpenStack\nhacking"" installed in virtual env will be triggered.\n\nThe result from ""run_tests.sh -p"" should be trusted, and jenkins uses\nvirtual env to run flake8 too.\n\nWhen ""-N"" is enabled, emit warning to remind user.\n\nBug #1215405\n\nChange-Id: Ic0fc8d39a87942e175256453c6c4347f6a5cfbba\n'}, {'number': 2, 'created': '2013-08-27 22:35:14.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b1b7c7185923be412eea90db97078befc15151fa', 'message': 'emit warning while running flake8 without virtual env\n\nrun_tests.sh -N -p\nit will call the flake8 installed on your host to detect PEP8, and\nthe flake8 plugin ""OpenStack hacking"" may not installed on your\nhost, so this command may not detect the OpenStack Style Commandment\nsupplied by hacking(e.g H202).\n\nrun_tests.sh -p\nit will call the flake8 from virtual env, flake8 plugin ""OpenStack\nhacking"" installed in virtual env will be triggered.\n\nThe result from ""run_tests.sh -p"" should be trusted, and jenkins uses\nvirtual env to run flake8 too.\n\nWhen ""-N"" is enabled, emit warning to stderr to remind user.\n\nBug #1215405\n\nChange-Id: Ic0fc8d39a87942e175256453c6c4347f6a5cfbba\n'}]",2,43367,b1b7c7185923be412eea90db97078befc15151fa,16,7,2,7774,,,0,"emit warning while running flake8 without virtual env

run_tests.sh -N -p
it will call the flake8 installed on your host to detect PEP8, and
the flake8 plugin ""OpenStack hacking"" may not installed on your
host, so this command may not detect the OpenStack Style Commandment
supplied by hacking(e.g H202).

run_tests.sh -p
it will call the flake8 from virtual env, flake8 plugin ""OpenStack
hacking"" installed in virtual env will be triggered.

The result from ""run_tests.sh -p"" should be trusted, and jenkins uses
virtual env to run flake8 too.

When ""-N"" is enabled, emit warning to stderr to remind user.

Bug #1215405

Change-Id: Ic0fc8d39a87942e175256453c6c4347f6a5cfbba
",git fetch https://review.opendev.org/openstack/tempest refs/changes/67/43367/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,80ed71f8c0077cbbd01d486445b72ff08fac504e,bug/1215405," echo ""Running flake8 ..."" if [ $never_venv -eq 1 ]; then echo ""**WARNING**:"" echo ""Running flake8 without virtual env may miss OpenStack HACKING detection"" fi"," echo ""Running pep8 ...""",5,1
openstack%2Fpython-swiftclient~master~Ie837e4dcab8633d1e056160acfb6c5666ea1db8a,openstack/python-swiftclient,master,Ie837e4dcab8633d1e056160acfb6c5666ea1db8a,Draft for swift-client change,NEW,2013-09-03 18:42:23.000000000,2013-09-04 17:18:42.000000000,,"[{'_account_id': 455}, {'_account_id': 860}, {'_account_id': 5499}]","[{'number': 1, 'created': '2013-09-03 18:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/2c35825016d465f3881283fe0ddfb71f59d1d83d', 'message': 'Draft for swift-client change\n\nChange-Id: Ie837e4dcab8633d1e056160acfb6c5666ea1db8a\n'}, {'number': 2, 'created': '2013-09-04 17:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/035de0a3861776e27a170f18f5be64d070faefd4', 'message': 'Draft for swift-client change\n\nChange-Id: Ie837e4dcab8633d1e056160acfb6c5666ea1db8a\n'}, {'number': 3, 'created': '2013-09-04 17:18:42.000000000', 'files': ['bin/swift', 'swiftclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/e6e2cddfbe7100404d5fcb13ddf13f6f80b3b770', 'message': 'Draft for swift-client change\n\nChange-Id: Ie837e4dcab8633d1e056160acfb6c5666ea1db8a\n'}]",0,44934,e6e2cddfbe7100404d5fcb13ddf13f6f80b3b770,2,3,3,5499,,,0,"Draft for swift-client change

Change-Id: Ie837e4dcab8633d1e056160acfb6c5666ea1db8a
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/34/44934/2 && git format-patch -1 --stdout FETCH_HEAD,"['bin/swift', 'swiftclient/client.py']",2,2c35825016d465f3881283fe0ddfb71f59d1d83d,swift-client-test-draft,"from time import sleep, time self.timer = {} start_time = time() self.timer['start_time'] = start_time auth_time = time() self.timer['auth_time'] = auth_time - start_time func_time = time() self.timer['func_time'] = func_time - start_time",from time import sleep,15,6
openstack%2Fopenstack-manuals~master~I2c56e1e60121fe6d29d8fe9cfaf2eb84716c006f,openstack/openstack-manuals,master,I2c56e1e60121fe6d29d8fe9cfaf2eb84716c006f,Fixed various language and markup problems in install guide,MERGED,2013-08-29 16:49:10.000000000,2013-09-04 17:08:51.000000000,2013-09-04 17:08:50.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 1177}, {'_account_id': 8369}]","[{'number': 1, 'created': '2013-08-29 16:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9c6383472bf7614d169d03af10da14cf6c945d74', 'message': 'Fixed various language and markup problems in install guide\n\nChange-Id: I2c56e1e60121fe6d29d8fe9cfaf2eb84716c006f\n'}, {'number': 2, 'created': '2013-09-04 15:06:07.000000000', 'files': ['doc/src/docbkx/openstack-install/install-config-glance.xml', 'doc/src/docbkx/common/section_dashboard-install.xml', 'doc/src/docbkx/openstack-install/example-installation-arch.xml', 'doc/src/docbkx/openstack-install/object-storage-verifying-install.xml', 'doc/src/docbkx/openstack-install/compute-db-sync.xml', 'doc/src/docbkx/common/section_xapi-resize-setup.xml', 'doc/src/docbkx/common/section_qemu.xml', 'doc/src/docbkx/openstack-install/installing-ntp.xml', 'doc/src/docbkx/openstack-install/section_colocating-services.xml', 'doc/src/docbkx/openstack-install/install-config-proxy-node.xml', 'doc/src/docbkx/openstack-install/object-storage-sys-requirements.xml', 'doc/src/docbkx/openstack-install/compute-cloud-controller.xml', 'doc/src/docbkx/openstack-install/configure-creds.xml', 'doc/src/docbkx/openstack-install/compute-minimum-configuration.xml', 'doc/src/docbkx/openstack-install/installing-additional-compute-nodes.xml', 'doc/src/docbkx/openstack-install/compute-hypervisor-selection.xml', 'doc/src/docbkx/openstack-install/compute-config-guest-network.xml', 'doc/src/docbkx/openstack-install/identity-verify-install.xml', 'doc/src/docbkx/common/section_dashboard-system-reqs.xml', 'doc/src/docbkx/openstack-install/installing-rabbitmq.xml', 'doc/src/docbkx/openstack-install/ch_installing-openstack-overview.xml', 'doc/src/docbkx/openstack-install/installing-mysql.xml', 'doc/src/docbkx/openstack-install/ch_assumptions.xml', 'doc/src/docbkx/common/section_introduction-to-xen.xml', 'doc/src/docbkx/common/section_kvm.xml', 'doc/src/docbkx/openstack-install/cinder-install.xml', 'doc/src/docbkx/openstack-install/identity-install-keystone.xml', 'doc/src/docbkx/common/section_keystone-concepts.xml', 'doc/src/docbkx/common/section_xapi-ami-setup.xml', 'doc/src/docbkx/openstack-install/install-config-storage-nodes.xml', 'doc/src/docbkx/openstack-install/start-storage-node-services.xml', 'doc/src/docbkx/openstack-install/compute-sys-requirements.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3297eccf0937d30b85327dc3d154937d8556c327', 'message': 'Fixed various language and markup problems in install guide\n\nChange-Id: I2c56e1e60121fe6d29d8fe9cfaf2eb84716c006f\n'}]",3,44322,3297eccf0937d30b85327dc3d154937d8556c327,10,5,2,8369,,,0,"Fixed various language and markup problems in install guide

Change-Id: I2c56e1e60121fe6d29d8fe9cfaf2eb84716c006f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/22/44322/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-install/install-config-glance.xml', 'doc/src/docbkx/common/section_dashboard-install.xml', 'doc/src/docbkx/openstack-install/example-installation-arch.xml', 'doc/src/docbkx/openstack-install/object-storage-verifying-install.xml', 'doc/src/docbkx/openstack-install/compute-db-sync.xml', 'doc/src/docbkx/common/section_xapi-resize-setup.xml', 'doc/src/docbkx/common/section_qemu.xml', 'doc/src/docbkx/openstack-install/installing-ntp.xml', 'doc/src/docbkx/openstack-install/section_colocating-services.xml', 'doc/src/docbkx/openstack-install/install-config-proxy-node.xml', 'doc/src/docbkx/openstack-install/object-storage-sys-requirements.xml', 'doc/src/docbkx/openstack-install/compute-cloud-controller.xml', 'doc/src/docbkx/openstack-install/configure-creds.xml', 'doc/src/docbkx/openstack-install/compute-minimum-configuration.xml', 'doc/src/docbkx/openstack-install/installing-additional-compute-nodes.xml', 'doc/src/docbkx/openstack-install/compute-hypervisor-selection.xml', 'doc/src/docbkx/openstack-install/compute-config-guest-network.xml', 'doc/src/docbkx/openstack-install/identity-verify-install.xml', 'doc/src/docbkx/common/section_dashboard-system-reqs.xml', 'doc/src/docbkx/openstack-install/installing-rabbitmq.xml', 'doc/src/docbkx/openstack-install/ch_installing-openstack-overview.xml', 'doc/src/docbkx/openstack-install/installing-mysql.xml', 'doc/src/docbkx/openstack-install/ch_assumptions.xml', 'doc/src/docbkx/common/section_introduction-to-xen.xml', 'doc/src/docbkx/common/section_kvm.xml', 'doc/src/docbkx/openstack-install/cinder-install.xml', 'doc/src/docbkx/openstack-install/identity-install-keystone.xml', 'doc/src/docbkx/common/section_keystone-concepts.xml', 'doc/src/docbkx/common/section_xapi-ami-setup.xml', 'doc/src/docbkx/openstack-install/install-config-storage-nodes.xml', 'doc/src/docbkx/openstack-install/start-storage-node-services.xml', 'doc/src/docbkx/openstack-install/compute-sys-requirements.xml']",32,9c6383472bf7614d169d03af10da14cf6c945d74,44322," nodes. For Object Storage, time synchronization ensures the"," nodes. For Object Storage, time synchronization ensure the",135,203
openstack-attic%2Fobject-api~master~I0d173ac419bdabe64639130979ec8a9ab6c8679a,openstack-attic/object-api,master,I0d173ac419bdabe64639130979ec8a9ab6c8679a,Use unique disqus shortname,MERGED,2013-09-03 19:17:26.000000000,2013-09-04 17:06:01.000000000,2013-09-04 17:04:38.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 964}, {'_account_id': 2622}]","[{'number': 1, 'created': '2013-09-03 19:17:26.000000000', 'files': ['openstack-object-storage-dev/pom.xml'], 'web_link': 'https://opendev.org/openstack-attic/object-api/commit/dd9cbfbb05b2837dfe7cb6b4355ee01135c7e1fd', 'message': 'Use unique disqus shortname\n\nDo not use the OpenStack documentation disqus shortname but a project\nunique one. A disqus project has been setup.\n\nChange-Id: I0d173ac419bdabe64639130979ec8a9ab6c8679a\nPartial-Bug: #1067208\n'}]",0,44940,dd9cbfbb05b2837dfe7cb6b4355ee01135c7e1fd,8,4,1,6547,,,0,"Use unique disqus shortname

Do not use the OpenStack documentation disqus shortname but a project
unique one. A disqus project has been setup.

Change-Id: I0d173ac419bdabe64639130979ec8a9ab6c8679a
Partial-Bug: #1067208
",git fetch https://review.opendev.org/openstack-attic/object-api refs/changes/40/44940/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-object-storage-dev/pom.xml'],1,dd9cbfbb05b2837dfe7cb6b4355ee01135c7e1fd,disqus, <disqusShortname>os-object-api</disqusShortname> , <disqusShortname>openstackdocs</disqusShortname> ,1,1
openstack%2Ftempest~master~I02612b3591057c4f59d6571e90acda74de802444,openstack/tempest,master,I02612b3591057c4f59d6571e90acda74de802444,Move the network api tests to smoke,MERGED,2013-08-18 05:00:29.000000000,2013-09-04 16:55:56.000000000,2013-09-04 16:55:55.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5586}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 8085}]","[{'number': 1, 'created': '2013-08-18 05:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/aaf25f3b3060581bc7d03873a03f4dbe4e0e13c0', 'message': 'Move the network api tests to smoke\n\nMake the existing neutron tests voting.\nHowever what should be smoke test, does not\nhave clear definition yet, but this change let these tests to vote.\n\nChange-Id: I02612b3591057c4f59d6571e90acda74de802444\n'}, {'number': 2, 'created': '2013-08-19 11:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8ec50a9be42ccaca87a0f4171a44d60ad9e96d3b', 'message': 'Move the network api tests to smoke\n\nMake the existing neutron tests voting.\nHowever what should be smoke test, does not\nhave clear definition yet, but this change let these tests to vote.\n\nChange-Id: I02612b3591057c4f59d6571e90acda74de802444\n'}, {'number': 3, 'created': '2013-08-27 14:29:35.000000000', 'files': ['tempest/api/network/test_networks.py', 'tempest/api/network/test_routers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/71834a287fa1eae2a8002819bd14ed418b4c90ec', 'message': 'Move the network api tests to smoke\n\nMake the existing neutron tests voting.\nHowever what should be smoke test, does not\nhave clear definition yet, but this change let these tests to vote.\n\nChange-Id: I02612b3591057c4f59d6571e90acda74de802444\n'}]",0,42517,71834a287fa1eae2a8002819bd14ed418b4c90ec,18,8,3,5803,,,0,"Move the network api tests to smoke

Make the existing neutron tests voting.
However what should be smoke test, does not
have clear definition yet, but this change let these tests to vote.

Change-Id: I02612b3591057c4f59d6571e90acda74de802444
",git fetch https://review.opendev.org/openstack/tempest refs/changes/17/42517/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_networks.py'],1,aaf25f3b3060581bc7d03873a03f4dbe4e0e13c0,net-smoke," @attr(type='smoke') @attr(type='smoke') @attr(type='smoke') @attr(type='smoke') @attr(type='smoke') @attr(type='smoke') @attr(type='smoke') @attr(type='smoke') @attr(type=['negative', 'smoke']) @attr(type=['negative', 'smoke'])"," @attr(type='gate') @attr(type='gate') @attr(type='gate') @attr(type='gate') @attr(type='gate') @attr(type='gate') @attr(type='gate') @attr(type='gate') @attr(type=['negative', 'gate']) @attr(type=['negative', 'gate'])",10,10
openstack%2Fneutron~master~Ic71b24c724222ade5e695addf291c6488d665da9,openstack/neutron,master,Ic71b24c724222ade5e695addf291c6488d665da9,Fixes formatting exception from logging in BigSwitch plugin,MERGED,2013-09-04 05:36:20.000000000,2013-09-04 16:54:36.000000000,2013-09-04 16:54:35.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-09-04 05:36:20.000000000', 'files': ['neutron/plugins/bigswitch/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d6f50e8476feb3c76db485fa033d0b1c22ee024d', 'message': 'Fixes formatting exception from logging in BigSwitch plugin\n\nCorrects the data type expected for the HTTP code that comes\nback from the back-end controller in a debug log call.\n\nCloses-Bug: #1220521\nChange-Id: Ic71b24c724222ade5e695addf291c6488d665da9\n'}]",0,45006,d6f50e8476feb3c76db485fa033d0b1c22ee024d,11,5,1,7787,,,0,"Fixes formatting exception from logging in BigSwitch plugin

Corrects the data type expected for the HTTP code that comes
back from the back-end controller in a debug log call.

Closes-Bug: #1220521
Change-Id: Ic71b24c724222ade5e695addf291c6488d665da9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/06/45006/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/bigswitch/plugin.py'],1,d6f50e8476feb3c76db485fa033d0b1c22ee024d,bug/1220521," ""code %(code)s on %(action)s action to resource """," ""code %(code)d on %(action)s action to resource """,1,1
openstack%2Ftempest~master~I8ef1ac22a8b137f397847d217467df5572afde43,openstack/tempest,master,I8ef1ac22a8b137f397847d217467df5572afde43,uniforms skip messages,MERGED,2013-08-23 15:19:28.000000000,2013-09-04 16:54:33.000000000,2013-09-04 16:54:33.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5292}, {'_account_id': 5586}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6796}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-08-23 15:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7323312e03df3fc56feee80bbbc8d63070b2e5ad', 'message': 'uniforms skip messages\n\nthis is an attempt to uniform skip messages and ensure multi-line\nskips are correctly accounted by https://review.openstack.org/#/c/42424/\nI think a future update to hacking/checks.py is also needed\n\nChange-Id: I8ef1ac22a8b137f397847d217467df5572afde43\n'}, {'number': 2, 'created': '2013-08-26 08:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/306fa9d659318507d75b1df2475730b1bc15ff8e', 'message': 'uniforms skip messages\n\nthis is an attempt to uniform skip messages and ensure multi-line\nskips are correctly accounted by https://review.openstack.org/#/c/42424/\nI think a future update to hacking/checks.py is also needed\n\nChange-Id: I8ef1ac22a8b137f397847d217467df5572afde43\n'}, {'number': 3, 'created': '2013-08-26 12:47:30.000000000', 'files': ['tempest/api/compute/servers/test_server_actions.py', 'tempest/api/compute/servers/test_virtual_interfaces.py', 'tempest/thirdparty/boto/test_ec2_instance_run.py', 'tempest/api/object_storage/test_object_expiry.py', 'tempest/api/compute/servers/test_list_server_filters.py', 'tempest/api/compute/images/test_images_oneserver.py', 'tempest/api/object_storage/test_container_sync.py', 'tempest/scenario/test_stamp_pattern.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6cc3ade73cfa21cd9e5598f9786e611c17167845', 'message': 'uniforms skip messages\n\nthis is an attempt to uniform skip messages and ensure multi-line\nskips are correctly accounted by https://review.openstack.org/#/c/42424/\nI think a future update to hacking/checks.py is also needed\n\nChange-Id: I8ef1ac22a8b137f397847d217467df5572afde43\n'}]",1,43490,6cc3ade73cfa21cd9e5598f9786e611c17167845,16,9,3,6796,,,0,"uniforms skip messages

this is an attempt to uniform skip messages and ensure multi-line
skips are correctly accounted by https://review.openstack.org/#/c/42424/
I think a future update to hacking/checks.py is also needed

Change-Id: I8ef1ac22a8b137f397847d217467df5572afde43
",git fetch https://review.opendev.org/openstack/tempest refs/changes/90/43490/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/servers/test_server_actions.py', 'tempest/api/compute/servers/test_virtual_interfaces.py', 'tempest/thirdparty/boto/test_ec2_instance_run.py', 'tempest/api/object_storage/test_object_expiry.py', 'tempest/api/compute/servers/test_list_server_filters.py', 'tempest/api/compute/images/test_images_oneserver.py', 'tempest/api/object_storage/test_container_sync.py', 'tempest/scenario/test_stamp_pattern.py']",8,7323312e03df3fc56feee80bbbc8d63070b2e5ad,fix_skip_messages," @testtools.skip(""Skipped until the Bug #1205344 is resolved."")"," @testtools.skip(""Until Bug #1205344 is fixed"")",9,9
openstack%2Ftripleo-ci~master~I0a57bcce507bf3d2fdf1abfe4a8b9725b2df022e,openstack/tripleo-ci,master,I0a57bcce507bf3d2fdf1abfe4a8b9725b2df022e,Get under/over cloud logs,MERGED,2013-09-02 10:53:26.000000000,2013-09-04 16:52:34.000000000,2013-09-04 16:52:34.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-09-02 10:53:26.000000000', 'files': ['toci_test.sh', 'toci_functions.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2749047e9e9cf0ff4a40fed5f0f51470daed09c0', 'message': 'Get under/over cloud logs\n\nIn addition to the seed VM.\n\nChange-Id: I0a57bcce507bf3d2fdf1abfe4a8b9725b2df022e\n'}]",0,44675,2749047e9e9cf0ff4a40fed5f0f51470daed09c0,7,3,1,1926,,,0,"Get under/over cloud logs

In addition to the seed VM.

Change-Id: I0a57bcce507bf3d2fdf1abfe4a8b9725b2df022e
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/75/44675/1 && git format-patch -1 --stdout FETCH_HEAD,"['toci_test.sh', 'toci_functions.sh']",2,2749047e9e9cf0ff4a40fed5f0f51470daed09c0,more-logs," ssh_noprompt $1@$2 ""( set -x ; ps -ef ; df -h ; uptime ; sudo netstat -lpn ; sudo iptables-save ; brctl show ; ip addr ; dpkg -l || rpm -qa) > /var/log/host_info.txt 2>&1 ; sudo tar -czf - --exclude=udev/hwdb.bin --exclude=selinux/targeted /var/log /etc || true"" > $TOCI_LOG_DIR/$2.tgz"," ssh_noprompt root@$SEED_IP ""( set -x ; ps -ef ; df -h ; uptime ; netstat -lpn ; iptables-save ; brctl show ; ip addr ; dpkg -l || rpm -qa) > /var/log/host_info.txt 2>&1 ; tar -czf - --exclude=udev/hwdb.bin --exclude=selinux/targeted /var/log /etc || true"" > $TOCI_LOG_DIR/bootstraplogs.tgz",9,3
openstack%2Fneutron~master~Icc7ca4a48c43a8462860cdbc42626079bffadc26,openstack/neutron,master,Icc7ca4a48c43a8462860cdbc42626079bffadc26,LBaaS: add status of pool-monitor association to the pool return dict,MERGED,2013-09-02 11:17:18.000000000,2013-09-04 16:52:04.000000000,2013-09-04 16:52:03.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 841}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6072}]","[{'number': 1, 'created': '2013-09-02 11:17:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eda7313c17852e711b24af57de541593a0f1a217', 'message': 'LBaaS: add status of pool-monitor association to the pool return dict\n\nChange-Id: Icc7ca4a48c43a8462860cdbc42626079bffadc26\nCloses-Bug: #1219692\n'}, {'number': 2, 'created': '2013-09-02 11:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0402e7fc678f919c5377620656d347404c02015d', 'message': 'LBaaS: add status of pool-monitor association to the pool return dict\n\nChange-Id: Icc7ca4a48c43a8462860cdbc42626079bffadc26\nCloses-Bug: #1219692\n'}, {'number': 3, 'created': '2013-09-04 08:17:07.000000000', 'files': ['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/extensions/loadbalancer.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/70902ad4358fee050a4a8ebbc3ff2aa50278058e', 'message': 'LBaaS: add status of pool-monitor association to the pool return dict\n\nCloses-Bug: #1219692\nChange-Id: Icc7ca4a48c43a8462860cdbc42626079bffadc26\n'}]",7,44680,70902ad4358fee050a4a8ebbc3ff2aa50278058e,23,7,3,5948,,,0,"LBaaS: add status of pool-monitor association to the pool return dict

Closes-Bug: #1219692
Change-Id: Icc7ca4a48c43a8462860cdbc42626079bffadc26
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/44680/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py']",2,eda7313c17852e711b24af57de541593a0f1a217,bug/1219692," print res['pool']['health_monitors'] expected = [ {'monitor_id': monitor1['health_monitor']['id'], 'status': 'PENDING_CREATE', 'status_description': None}, {'monitor_id': monitor2['health_monitor']['id'], 'status': 'PENDING_CREATE', 'status_description': None}] self.assertEqual(sorted(expected), sorted(res['pool']['health_monitors'])) expected = [ {'monitor_id': monitor2['health_monitor']['id'], 'status': 'PENDING_CREATE', 'status_description': None} ] self.assertEqual(expected, res['pool']['health_monitors']) expected = [ {'monitor_id': health_monitor['health_monitor']['id'], 'status': 'PENDING_CREATE', 'status_description': None} ] self.assertEqual(expected, pool_updated['pool']['health_monitors'])"," self.assertIn(monitor1['health_monitor']['id'], res['pool']['health_monitors']) self.assertIn(monitor2['health_monitor']['id'], res['pool']['health_monitors']) self.assertNotIn(monitor1['health_monitor']['id'], res['pool']['health_monitors']) self.assertIn(monitor2['health_monitor']['id'], res['pool']['health_monitors']) self.assertIn(health_monitor['health_monitor']['id'], pool_updated['pool']['health_monitors'])",27,11
openstack%2Fnova~master~Iaf6b4a2d7f4e4993a6540e8a3afc774b7b158608,openstack/nova,master,Iaf6b4a2d7f4e4993a6540e8a3afc774b7b158608,Port flavormanage extension to v3 API Part 2,MERGED,2013-08-15 11:50:47.000000000,2013-09-04 16:51:10.000000000,2013-09-04 16:51:07.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 5511}, {'_account_id': 5586}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 7069}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-08-15 11:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4d80419ca9319bd932c58db6d33382e74de89de', 'message': 'Port flavormanage extension to v3 API Part 2\n\nPorts the flavormanage extension and the corresponding\nunittests to the v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Iaf6b4a2d7f4e4993a6540e8a3afc774b7b158608\n'}, {'number': 2, 'created': '2013-08-22 10:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62e0b71fcea931762aa7b57e273ab82951c973c9', 'message': 'Port flavormanage extension to v3 API Part 2\n\nPorts the flavormanage extension and the corresponding\nunittests to the v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Iaf6b4a2d7f4e4993a6540e8a3afc774b7b158608\n'}, {'number': 3, 'created': '2013-09-02 14:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0658c0c002f0bb53294af62942377350224b7212', 'message': 'Port flavormanage extension to v3 API Part 2\n\nPorts the flavormanage extension and the corresponding\nunittests to the v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Iaf6b4a2d7f4e4993a6540e8a3afc774b7b158608\n'}, {'number': 4, 'created': '2013-09-03 13:32:00.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_flavor_manage.py', 'nova/api/openstack/compute/plugins/v3/flavor_manage.py', 'etc/nova/policy.json', 'nova/tests/fake_policy.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/nova/commit/75e00f8358fe58b55c6d219c7184e66b89e55a1b', 'message': 'Port flavormanage extension to v3 API Part 2\n\nPorts the flavormanage extension and the corresponding\nunittests to the v3 framework.\n\nPartially implements blueprint nova-v3-api\n\nChange-Id: Iaf6b4a2d7f4e4993a6540e8a3afc774b7b158608\n'}]",16,42112,75e00f8358fe58b55c6d219c7184e66b89e55a1b,36,10,4,7763,,,0,"Port flavormanage extension to v3 API Part 2

Ports the flavormanage extension and the corresponding
unittests to the v3 framework.

Partially implements blueprint nova-v3-api

Change-Id: Iaf6b4a2d7f4e4993a6540e8a3afc774b7b158608
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/42112/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_flavor_manage.py', 'nova/api/openstack/compute/plugins/v3/flavormanage.py', 'etc/nova/policy.json', 'nova/tests/fake_policy.py', 'setup.cfg']",5,a4d80419ca9319bd932c58db6d33382e74de89de,bp/nova-v3-api, flavormanage = nova.api.openstack.compute.plugins.v3.flavormanage:FlavorManage,,45,63
openstack%2Ftempest~master~I1ae6460158a18517d430298602ad803fe1f8bb9f,openstack/tempest,master,I1ae6460158a18517d430298602ad803fe1f8bb9f,Switch heat template to use native nova resource,MERGED,2013-08-30 02:00:03.000000000,2013-09-04 16:50:44.000000000,2013-09-04 16:50:44.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 4571}]","[{'number': 1, 'created': '2013-08-30 02:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c0ff9d2cc5c10272ef77add62c2d414eccf02ae8', 'message': 'Switch heat template to use native nova resource\n\nThis change switches InstanceCfnInitTestJSON to use\nthe new resource type OS::Nova::Server instead of\nAWS::EC2::Instance.\n\nThe next patch in this series will rename the file to refer to\n""server"" instead of ""instance"" as per nova\'s semantics\n\nChange-Id: I1ae6460158a18517d430298602ad803fe1f8bb9f\nPartial-Bug: #1187942\n'}, {'number': 2, 'created': '2013-09-03 22:34:42.000000000', 'files': ['tempest/api/orchestration/stacks/test_server_cfn_init.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/62b7d5f7f55e3b82301db57d2c450b38c4ba8b16', 'message': 'Switch heat template to use native nova resource\n\nThis change switches InstanceCfnInitTestJSON to use\nthe new resource type OS::Nova::Server instead of\nAWS::EC2::Instance.\n\nThe next patch in this series will rename the file to refer to\n""server"" instead of ""instance"" as per nova\'s semantics\n\nChange-Id: I1ae6460158a18517d430298602ad803fe1f8bb9f\nPartial-Bug: #1187942\n'}]",0,44386,62b7d5f7f55e3b82301db57d2c450b38c4ba8b16,10,4,2,4571,,,0,"Switch heat template to use native nova resource

This change switches InstanceCfnInitTestJSON to use
the new resource type OS::Nova::Server instead of
AWS::EC2::Instance.

The next patch in this series will rename the file to refer to
""server"" instead of ""instance"" as per nova's semantics

Change-Id: I1ae6460158a18517d430298602ad803fe1f8bb9f
Partial-Bug: #1187942
",git fetch https://review.opendev.org/openstack/tempest refs/changes/86/44386/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/orchestration/stacks/test_instance_cfn_init.py'],1,c0ff9d2cc5c10272ef77add62c2d414eccf02ae8,bug/1187942,"class ServerCfnInitTestJSON(base.BaseOrchestrationTest): key_name: flavor: image: Type: OS::Nova::Server image: {Ref: image} flavor: {Ref: flavor} key_name: {Ref: key_name} security_groups: user_data: Fn::GetAtt: [SmokeServer, first_private_address] super(ServerCfnInitTestJSON, cls).setUpClass() 'key_name': keypair_name, 'flavor': cls.orchestration_cfg.instance_type, 'image': cls.orchestration_cfg.image_ref # - a user was created and credentials written to the server","class InstanceCfnInitTestJSON(base.BaseOrchestrationTest): KeyName: InstanceType: ImageId: Type: AWS::EC2::Instance ImageId: {Ref: ImageId} InstanceType: {Ref: InstanceType} KeyName: {Ref: KeyName} SecurityGroups: UserData: Fn::GetAtt: [SmokeServer, PublicIp] super(InstanceCfnInitTestJSON, cls).setUpClass() 'KeyName': keypair_name, 'InstanceType': cls.orchestration_cfg.instance_type, 'ImageId': cls.orchestration_cfg.image_ref # - a user was created and credentials written to the instance",16,16
openstack%2Ftempest~master~I3ecb39fd2347af265f72e072e4827946c10fb2f6,openstack/tempest,master,I3ecb39fd2347af265f72e072e4827946c10fb2f6,Add more detailed message about the volumes missing,MERGED,2013-08-20 18:12:24.000000000,2013-09-04 16:50:27.000000000,2013-09-04 16:50:27.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1297}, {'_account_id': 2750}, {'_account_id': 6796}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-08-20 18:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8cedef05ff8990e8a94b80b7e35ed751afdbfec4', 'message': 'Add a more detailed message about the volumes missing.\n\nInstead of just showing the ones that were missing,\nshow the ones that were expected, the list that was\nretrieved and the difference in one message. This\nmakes it much easier to see what the failure was.\n\nChange-Id: I3ecb39fd2347af265f72e072e4827946c10fb2f6\n'}, {'number': 2, 'created': '2013-08-20 18:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7a2f7e30725ed082c9d8b40a8494c16b7411bcbe', 'message': 'Add a more detailed message about the volumes missing.\n\nInstead of just showing the ones that were missing,\nshow the ones that were expected, the list that was\nretrieved and the difference in one message. This\nmakes it much easier to see what the failure was.\n\nChange-Id: I3ecb39fd2347af265f72e072e4827946c10fb2f6\n'}, {'number': 3, 'created': '2013-08-24 22:52:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8c513568cf9bc19397e286fd03c5618f765eebe0', 'message': 'Add more detailed message about the volumes missing\n\nInstead of just showing the ones that were missing,\nshow the ones that were expected, the list that was\nretrieved and the difference in one message. This\nmakes it much easier to see what the failure was.\n\nChange-Id: I3ecb39fd2347af265f72e072e4827946c10fb2f6\n'}, {'number': 4, 'created': '2013-08-24 23:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0c040242ab57e05b85853c2444edd408bf6bc8ab', 'message': 'Add more detailed message about the volumes missing\n\nInstead of just showing the ones that were missing,\nshow the ones that were expected, the list that was\nretrieved and the difference in one message. This\nmakes it much easier to see what the failure was.\n\nChange-Id: I3ecb39fd2347af265f72e072e4827946c10fb2f6\n'}, {'number': 5, 'created': '2013-08-27 00:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0aeecca66422b2786579f664f3afd80f2a54665c', 'message': 'Add more detailed message about the volumes missing\n\nInstead of just showing the ones that were missing,\nshow the ones that were expected, the list that was\nretrieved and the difference in one message. This\nmakes it much easier to see what the failure was.\n\nChange-Id: I3ecb39fd2347af265f72e072e4827946c10fb2f6\n'}, {'number': 6, 'created': '2013-08-31 20:07:40.000000000', 'files': ['tempest/api/volume/test_volumes_list.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f1574b980309c8c7ee7bc40fd0f33fd1f53568ff', 'message': 'Add more detailed message about the volumes missing\n\nInstead of just showing the ones that were missing,\nshow the ones that were expected, the list that was\nretrieved and the difference in one message. This\nmakes it much easier to see what the failure was.\n\nChange-Id: I3ecb39fd2347af265f72e072e4827946c10fb2f6\n'}]",1,42964,f1574b980309c8c7ee7bc40fd0f33fd1f53568ff,22,6,6,1297,,,0,"Add more detailed message about the volumes missing

Instead of just showing the ones that were missing,
show the ones that were expected, the list that was
retrieved and the difference in one message. This
makes it much easier to see what the failure was.

Change-Id: I3ecb39fd2347af265f72e072e4827946c10fb2f6
",git fetch https://review.opendev.org/openstack/tempest refs/changes/64/42964/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/volume/test_volumes_list.py'],1,8cedef05ff8990e8a94b80b7e35ed751afdbfec4,master,"def _prettify_volume(vol): return ""%s:%s"" + (vol['id'], vol['display_name']) failure_message = (""Failed to find volume/s %s in fetched list %s, "" ""expected %s"") failure_message = failure_message % (', '.join(_prettify_volume(v) for v in missing_vols), ', '.join(_prettify_volume(v) for v in fetched_list), ', '.join(_prettify_volume(v) for v in self.volume_list)) self.assertFalse(missing_vols, failure_message) failure_message = (""Failed to find volume/s %s in fetched list %s, "" ""expected %s"") failure_message = failure_message % (', '.join(_prettify_volume(v) for v in missing_vols), ', '.join(_prettify_volume(v) for v in fetched_list), ', '.join(_prettify_volume(v) for v in self.volume_list)) self.assertFalse(missing_vols, failure_message)"," self.assertFalse(missing_vols, ""Failed to find volume %s in fetched list"" % ', '.join(m_vol['display_name'] for m_vol in missing_vols)) self.assertFalse(missing_vols, ""Failed to find volume %s in fetched list"" % ', '.join(m_vol['display_name'] for m_vol in missing_vols))",24,8
openstack%2Ftempest~master~I4260844ed15917106436d836c939157e32a59554,openstack/tempest,master,I4260844ed15917106436d836c939157e32a59554,Add handling for inherited stress attributes,MERGED,2013-09-02 07:50:29.000000000,2013-09-04 16:50:25.000000000,2013-09-04 16:50:25.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 7872}, {'_account_id': 8625}]","[{'number': 1, 'created': '2013-09-02 07:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7822bb488fdb84a67a444c741bb572af46a1cfe2', 'message': 'Add handling for inherited stress attributes\n\nIn some cases inheritance is used for test cases (like XML/JSON tests).\nFor many of those cases inherited stress attribute are misleading\nsince they will execute nearly the same load on the system.\n\nTo avoid this issue we skip all inherited stress attributes by default\nand add parameters to deactivate this on a global level and function\nlevel.\n\nChange-Id: I4260844ed15917106436d836c939157e32a59554\n'}, {'number': 2, 'created': '2013-09-02 07:53:08.000000000', 'files': ['tempest/stress/run_stress.py', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b060441db2373faf931b1152e981330d27201acc', 'message': 'Add handling for inherited stress attributes\n\nIn some cases inheritance is used for test cases (like XML/JSON tests).\nFor many of those cases inherited stress attribute are misleading\nsince they will execute nearly the same load on the system.\n\nTo avoid this issue we skip all inherited stress attributes by default\nand add parameters to deactivate this on a global level and function\nlevel.\n\nChange-Id: I4260844ed15917106436d836c939157e32a59554\nFixes: bug #1219402\n'}]",0,44643,b060441db2373faf931b1152e981330d27201acc,11,5,2,7872,,,0,"Add handling for inherited stress attributes

In some cases inheritance is used for test cases (like XML/JSON tests).
For many of those cases inherited stress attribute are misleading
since they will execute nearly the same load on the system.

To avoid this issue we skip all inherited stress attributes by default
and add parameters to deactivate this on a global level and function
level.

Change-Id: I4260844ed15917106436d836c939157e32a59554
Fixes: bug #1219402
",git fetch https://review.opendev.org/openstack/tempest refs/changes/43/44643/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/stress/run_stress.py', 'tempest/test.py']",2,7822bb488fdb84a67a444c741bb572af46a1cfe2,bug/1219402," @param allow_inheritance: allows inheritance of this attribute if 'allow_inheritance' in kwargs: setattr(f, ""st_allow_inheritance"", kwargs['allow_inheritance']) else: setattr(f, ""st_allow_inheritance"", False)",,23,9
openstack%2Ftempest~master~I184ce2df1ee58043cf9b26c46637c1d8160910e8,openstack/tempest,master,I184ce2df1ee58043cf9b26c46637c1d8160910e8,Stress ssh_floating test,MERGED,2013-08-07 17:22:04.000000000,2013-09-04 16:50:23.000000000,2013-09-04 16:50:23.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2035}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 7872}]","[{'number': 1, 'created': '2013-08-07 17:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a0d1e16e16aa06ad8d95432e10f5d44fc366f1c9', 'message': 'stress ssh_floating\n\nWIP\n\nChange-Id: I184ce2df1ee58043cf9b26c46637c1d8160910e8\n'}, {'number': 2, 'created': '2013-08-08 11:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/563c8dd5430500bbaac9da0501d7d00e795c423c', 'message': 'Stress ssh_floating test\n\nAdd stress test for floating IP association\n with multiple configuration options.\n\nChange-Id: I184ce2df1ee58043cf9b26c46637c1d8160910e8\n'}, {'number': 3, 'created': '2013-08-08 13:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e196c9d6546c6ef7b600e2de14f9aeba4621491', 'message': 'Stress ssh_floating test\n\nAdd stress test for floating IP association\n with multiple configuration options.\n\nChange-Id: I184ce2df1ee58043cf9b26c46637c1d8160910e8\n'}, {'number': 4, 'created': '2013-08-08 14:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/60feaa05e25755dfe2a217a7a156df8d2758a1a7', 'message': 'Stress ssh_floating test\n\nAdd stress test for floating IP association\n with multiple configuration options.\n\nChange-Id: I184ce2df1ee58043cf9b26c46637c1d8160910e8\n'}, {'number': 5, 'created': '2013-08-26 20:14:19.000000000', 'files': ['tempest/stress/etc/ssh_floating.json', 'tempest/stress/actions/ssh_floating.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7cf2a22f8b161864c2e5d795bd99b651b1dbf71d', 'message': 'Stress ssh_floating test\n\nAdd stress test for floating IP association\n with multiple configuration options.\n\nChange-Id: I184ce2df1ee58043cf9b26c46637c1d8160910e8\n'}]",1,40680,7cf2a22f8b161864c2e5d795bd99b651b1dbf71d,17,6,5,5803,,,0,"Stress ssh_floating test

Add stress test for floating IP association
 with multiple configuration options.

Change-Id: I184ce2df1ee58043cf9b26c46637c1d8160910e8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/80/40680/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/stress/etc/ssh_floating.json', 'tempest/stress/actions/ssh_floating.py']",2,a0d1e16e16aa06ad8d95432e10f5d44fc366f1c9,ssh_ip_stress,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import time from tempest.common.utils.data_utils import rand_name import tempest.stress.stressaction as stressaction import tempest.test # from the scenario manager def ping_ip_address(ip_address): cmd = ['ping', '-c1', '-w1', ip_address] proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) proc.wait() return proc.returncode == 0 class FloatingStress(stressaction.StressAction): def tcp_connect_scan(self, addr, port): # like tcp s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) try: s.connect((addr, port)) except socke.error as exc: self.logger.info(str(exc)) return False s.close() return True def check_port_ssh(self): def func(): return self.tcp_connect_scan(self.floating['ip'], 22) if not tempest.test.call_until_true(func, self.check_timeout, 1): raise RuntimeError(""Cannot connect to the ssh port."") def check_icmp_echo(self): def func(): return ping_ip_address(self.floating['ip']) if not tempest.test.call_until_true(func, self.check_timeout, 1): raise RuntimeError(""Cannot ping the machine."") def _create_vm(self): self.name = name = rand_name(""instance"") server_client = self.manager.servers_client self.logger.info(""creating %s"" % name) vm_args = self.vm_extrea_args.copy() vm_args['security_groups'] = [self.sec_grp] resp, server = servers_client.create_server(name, self.image, self.flavor, **vm_args) self.server_id = server['id'] assert(resp.status == 202) if self.wait_after_vm_create: self.manager.servers_client.wait_for_server_status(self.server_id, 'ACTIVE') def _destroy_vm(self): self.logger.info(""deleting %s"" % name) resp, _ = self.manager.servers_client.delete_server(self.server_id) assert(resp.status == 204) # It cannot be 204 if I had to wait.. self.manager.servers_client.wait_for_server_termination(self.server_id) self.logger.info(""deleted %s"" % server_id) def _create_sec_group(self): sec_grp_cli = self.manage.security_groups_client s_name = rand_name('sec_grp-') s_description = rand_name('desc-') _, _sec_grp = sec_grp_cli.create_security_group(s_name, s_description) self.sec_grp = _sec_grp['id'] self.sec_group = sec_grp_cli.create_security_group_rule( self.sec_group, 'tcp', 22, 22) self.sec_group = sec_grp_cli.create_security_group_rule( self.sec_group, 'icmp', -1, -1) def _destroy_sec_grp(self): sec_grp_cli = self.manage.security_groups_client sec_grp_cli.delete_security_group(self.sec_group) def _create_flaoting_ip(self): floating_cli = self.manage.floating_ips_client self.floating = floating_cli.create_floating_ip(slef.floating_pool) del _destroy_floating_ip(self): self.manage.floating_ips_client.delete_floating_ip(self.floating) def setUp(self, **kwargs): self.image = self.manager.config.compute.image_ref self.flavor = self.manager.config.compute.flavor_ref self.vm_args = kwargs.get('vm_extra_args', {}) self.wait_after_vm_create() = kwargs.get('wait_after_vm_create', True) self.new_vm = kwargs.get('new_vm', False) self.new_sec_grp = kwargs.get('new_sec_group', False) self.new_floating = kwargs.get('new_floating', False) self.reboot = kwargs.get('reboot', False) self.floating_pool = kwargs.get('floating_pool', None) self.verify = kwargs.get('verify', ('check_port_ssh', 'check_icmp_echo')) self.check_timeout = kwargs.get('check_timeout', 120) self.check_interval = kwargs.get('check_interval', 1) # allocate floating if not new_floating: self._create_floating_ip() # add security group if not new_sec_grp: self._create_sec_group() # create vm if not new_vm: self._create_vm() def run_core(self): for method in self.verify: m = getattr(self, method) m() def run(self): if new_sec_grp: self._create_sec_group() if new_floating: self._create_floating_ip() if new_vm: self._create_vm() if slef.reboot(self): self.manager.self.reboot() self.run_core() if new_vm: self._destroy_vm() if new_floating: self._destroy_floating_ip() if new_sec_grp: self._destroy_sec_grp() def tearDown(self): if not self.new_vm: self._create_vm() if not new_floating: self._destroy_floating_ip() if not new_sec_grp: self._destroy_sec_grp() ",,174,0
openstack%2Fnova~master~I358fb6d8dcafd67c289fe5083bb82140f3759fee,openstack/nova,master,I358fb6d8dcafd67c289fe5083bb82140f3759fee,Inherit base image properties on instance creation,MERGED,2013-08-26 21:23:42.000000000,2013-09-04 16:49:55.000000000,2013-09-04 16:49:52.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4468}, {'_account_id': 5511}, {'_account_id': 7808}]","[{'number': 1, 'created': '2013-08-26 21:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7333c2f6a84fcae46f90477e3bd8de8f4410631', 'message': ""Inherit base image properties on instance creation\n\nWhen creating an instance, a few properties from the image will be saved\nin the instance's system_metadata under the prefix 'image_' for latter\nusage.\n\nThe keys that the instance will inherit from the image are: 'min_ram',\n'min_disk', 'disk_format' and 'container_format' together with the\ninheritable image properties.\n\nRelated to bug #1039662\n\nChange-Id: I358fb6d8dcafd67c289fe5083bb82140f3759fee\n""}, {'number': 2, 'created': '2013-09-02 16:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5da9fba9ce827b7e8ab3cc2a1077e492d670890e', 'message': ""Inherit base image properties on instance creation\n\nWhen creating an instance, a few properties from the image will be saved\nin the instance's system_metadata under the prefix 'image_' for latter\nusage.\n\nThe keys that the instance will inherit from the image are: 'min_ram',\n'min_disk', 'disk_format' and 'container_format' together with the\ninheritable image properties.\n\nRelated to bug #1039662\n\nChange-Id: I358fb6d8dcafd67c289fe5083bb82140f3759fee\n""}, {'number': 3, 'created': '2013-09-04 09:25:52.000000000', 'files': ['nova/virt/xenapi/agent.py', 'nova/utils.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py', 'nova/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e34cac4be6f536298e05acf1f44210e51f9b29a9', 'message': ""Inherit base image properties on instance creation\n\nWhen creating an instance, a few properties from the image will be saved\nin the instance's system_metadata under the prefix 'image_' for latter\nusage.\n\nThe keys that the instance will inherit from the image are: 'min_ram',\n'min_disk', 'disk_format' and 'container_format' together with the\ninheritable image properties.\n\nRelated to bug #1039662\n\nChange-Id: I358fb6d8dcafd67c289fe5083bb82140f3759fee\n""}]",0,43782,e34cac4be6f536298e05acf1f44210e51f9b29a9,22,7,3,7808,,,0,"Inherit base image properties on instance creation

When creating an instance, a few properties from the image will be saved
in the instance's system_metadata under the prefix 'image_' for latter
usage.

The keys that the instance will inherit from the image are: 'min_ram',
'min_disk', 'disk_format' and 'container_format' together with the
inheritable image properties.

Related to bug #1039662

Change-Id: I358fb6d8dcafd67c289fe5083bb82140f3759fee
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/43782/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/xenapi/agent.py', 'nova/utils.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py', 'nova/tests/test_utils.py']",5,d7333c2f6a84fcae46f90477e3bd8de8f4410631,bug/1039662," class GetSystemMetadataFromImageTestCase(test.TestCase): def get_image(self): image_meta = { ""id"": ""fake-image"", ""name"": ""fake-name"", ""min_ram"": 1, ""min_disk"": 1, ""disk_format"": ""raw"", ""container_format"": ""bare"", } return image_meta def get_instance_type(self): instance_type = { ""id"": ""fake.flavor"", ""root_gb"": 10, } return instance_type def test_base_image_properties(self): image = self.get_image() # Verify that we inherit all the needed keys sys_meta = utils.get_system_metadata_from_image(image) for key in utils.SM_INHERITABLE_KEYS: sys_key = ""%s%s"" % (utils.SM_IMAGE_PROP_PREFIX, key) self.assertEqual(image[key], sys_meta.get(sys_key)) # Verify that everything else is ignored self.assertEqual(len(sys_meta), len(utils.SM_INHERITABLE_KEYS)) def test_inherit_image_properties(self): image = self.get_image() image[""properties""] = {""foo1"": ""bar"", ""foo2"": ""baz""} sys_meta = utils.get_system_metadata_from_image(image) # Verify that we inherit all the image properties for key, expected in image[""properties""].iteritems(): sys_key = ""%s%s"" % (utils.SM_IMAGE_PROP_PREFIX, key) self.assertEqual(sys_meta[sys_key], expected) def test_vhd_min_disk_image(self): image = self.get_image() instance_type = self.get_instance_type() image[""disk_format""] = ""vhd"" sys_meta = utils.get_system_metadata_from_image(image, instance_type) # Verify that the min_disk property is taken from # instance_type's root_gb when using vhd disk format sys_key = ""%s%s"" % (utils.SM_IMAGE_PROP_PREFIX, ""min_disk"") self.assertEqual(sys_meta[sys_key], instance_type[""root_gb""]) def test_dont_inherit_empty_values(self): image = self.get_image() for key in utils.SM_INHERITABLE_KEYS: image[key] = None sys_meta = utils.get_system_metadata_from_image(image) # Verify that the empty properties have not been inherited for key in utils.SM_INHERITABLE_KEYS: sys_key = ""%s%s"" % (utils.SM_IMAGE_PROP_PREFIX, key) self.assertTrue(sys_key not in sys_meta)",,127,26
openstack%2Fdevstack~master~Ifd852e9d1ffe39fa23f6312d1ddf2874b5f2b9f0,openstack/devstack,master,Ifd852e9d1ffe39fa23f6312d1ddf2874b5f2b9f0,Copy policy_add() from Grenade functions,MERGED,2013-08-30 20:34:52.000000000,2013-09-04 16:47:04.000000000,2013-09-04 16:47:04.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 2976}]","[{'number': 1, 'created': '2013-08-30 20:34:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/40aad346b0cd59577d0ec0f35a4a097a96270aaf', 'message': 'Copy policy_add() from Grenade functions\n\nChange-Id: Ifd852e9d1ffe39fa23f6312d1ddf2874b5f2b9f0\n'}, {'number': 2, 'created': '2013-09-03 19:20:33.000000000', 'files': ['functions'], 'web_link': 'https://opendev.org/openstack/devstack/commit/533e14d6a5fc1ba3dbd24fb0075ef1eafd00a705', 'message': ""Copy policy_add() from Grenade functions\n\npolicy_all() was added to Grenade's functions file, which is notmally synced\nfrom DevStack so we need to bring it over here before the next sync.\n\nChange-Id: Ifd852e9d1ffe39fa23f6312d1ddf2874b5f2b9f0\n""}]",0,44546,533e14d6a5fc1ba3dbd24fb0075ef1eafd00a705,13,4,2,970,,,0,"Copy policy_add() from Grenade functions

policy_all() was added to Grenade's functions file, which is notmally synced
from DevStack so we need to bring it over here before the next sync.

Change-Id: Ifd852e9d1ffe39fa23f6312d1ddf2874b5f2b9f0
",git fetch https://review.opendev.org/openstack/devstack refs/changes/46/44546/2 && git format-patch -1 --stdout FETCH_HEAD,['functions'],1,40aad346b0cd59577d0ec0f35a4a097a96270aaf,policy-function,"# ``policy_add policy_file policy_name policy_permissions`` # # Add a policy to a policy.json file # Do nothing if the policy already exists function policy_add() { local policy_file=$1 local policy_name=$2 local policy_perm=$3 if grep -q ${policy_name} ${policy_file}; then echo ""Policy ${policy_name} already exists in ${policy_file}"" return fi # Add a terminating comma to policy lines without one # Remove the closing '}' and all lines following to the end-of-file local tmpfile=$(mktemp) uniq ${policy_file} | sed -e ' s/]$/],/ /^[}]/,$d ' > ${tmpfile} # Append policy and closing brace echo "" \""${policy_name}\"": ${policy_perm}"" >>${tmpfile} echo ""}"" >>${tmpfile} mv ${tmpfile} ${policy_file} } ",,31,0
openstack%2Fdevstack~master~I9dfd61cbb9415bd5e8fd1e40f4e41512be2ae0d2,openstack/devstack,master,I9dfd61cbb9415bd5e8fd1e40f4e41512be2ae0d2,remove multi-host timeout,MERGED,2013-08-30 13:16:36.000000000,2013-09-04 16:44:20.000000000,2013-09-04 16:44:20.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 2750}, {'_account_id': 5044}]","[{'number': 1, 'created': '2013-08-30 13:16:36.000000000', 'files': ['functions'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1533a349da34a002ab6a09cee86d47daf6d777fb', 'message': 'remove multi-host timeout\n\nIf you ran exercises with MULTI_HOST enabled, an additional sleep was\nperformed. This change removes that sleep to speed up tests.\n\nChange-Id: I9dfd61cbb9415bd5e8fd1e40f4e41512be2ae0d2\n'}]",0,44452,1533a349da34a002ab6a09cee86d47daf6d777fb,10,5,1,5044,,,0,"remove multi-host timeout

If you ran exercises with MULTI_HOST enabled, an additional sleep was
performed. This change removes that sleep to speed up tests.

Change-Id: I9dfd61cbb9415bd5e8fd1e40f4e41512be2ae0d2
",git fetch https://review.opendev.org/openstack/devstack refs/changes/52/44452/1 && git format-patch -1 --stdout FETCH_HEAD,['functions'],1,1533a349da34a002ab6a09cee86d47daf6d777fb,remove-multihost-timeout,, sleep $boot_timeout,0,1
openstack%2Fceilometer~master~Idbcc5843e1840ff2659a58d991f4256f56c93a4d,openstack/ceilometer,master,Idbcc5843e1840ff2659a58d991f4256f56c93a4d,Network: process metering reports from Neutron,MERGED,2013-08-27 14:23:03.000000000,2013-09-04 16:43:47.000000000,2013-09-04 16:43:46.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2813}, {'_account_id': 2860}, {'_account_id': 6537}, {'_account_id': 7141}, {'_account_id': 8106}, {'_account_id': 8122}]","[{'number': 1, 'created': '2013-08-27 14:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1cf9a06365493c75db1f182972500f6005fac98c', 'message': 'Network: process metering reports from Neutron\n\nThis implements part of\nhttps://blueprints.launchpad.net/ceilometer/+spec/ceilometer-quantum-bw-metering.\n\nChange-Id: Idbcc5843e1840ff2659a58d991f4256f56c93a4d\n'}, {'number': 2, 'created': '2013-09-02 10:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1fc86d8609a914c0c45c0124c51fff9fbc648cac', 'message': 'Network: process metering reports from Neutron\n\nblueprint https://blueprints.launchpad.net/ceilometer/+spec/ceilometer-quantum-bw-metering\n\nChange-Id: Idbcc5843e1840ff2659a58d991f4256f56c93a4d\n'}, {'number': 3, 'created': '2013-09-03 13:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e91f27ff21c9bb8142205cdb0f488fd637186446', 'message': 'Network: process metering reports from Neutron\n\nblueprint https://blueprints.launchpad.net/ceilometer/+spec/ceilometer-quantum-bw-metering\n\nChange-Id: Idbcc5843e1840ff2659a58d991f4256f56c93a4d\n'}, {'number': 4, 'created': '2013-09-03 14:39:46.000000000', 'files': ['ceilometer/network/notifications.py', 'tests/network/test_notifications.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3636a044a6ec04eea4ace7cbb3b377d2f412598e', 'message': 'Network: process metering reports from Neutron\n\nblueprint https://blueprints.launchpad.net/ceilometer/+spec/ceilometer-quantum-bw-metering\n\nChange-Id: Idbcc5843e1840ff2659a58d991f4256f56c93a4d\n'}]",18,43892,3636a044a6ec04eea4ace7cbb3b377d2f412598e,28,10,4,8122,,,0,"Network: process metering reports from Neutron

blueprint https://blueprints.launchpad.net/ceilometer/+spec/ceilometer-quantum-bw-metering

Change-Id: Idbcc5843e1840ff2659a58d991f4256f56c93a4d
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/92/43892/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/network/notifications.py', 'tests/network/test_notifications.py', 'setup.cfg']",3,1cf9a06365493c75db1f182972500f6005fac98c,bp/https, bandwidth = ceilometer.network.notifications:Bandwidth,,53,0
openstack%2Fopenstack-manuals~master~Ib50c5cee239c370a17d5462c2a6837357242425d,openstack/openstack-manuals,master,Ib50c5cee239c370a17d5462c2a6837357242425d,Improve Debian support in Basic Install Guide,MERGED,2013-09-02 19:03:31.000000000,2013-09-04 16:42:24.000000000,2013-09-04 16:42:23.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 1177}, {'_account_id': 3153}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-09-02 19:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/592cd7a48262acf35fb2632c23bc3708340b5165', 'message': 'Improve Debian support in Basic Install Guide\n\nThe Guide is built for both Debian and Ubuntu and there are a few\nplaces that are only relevant for either of these. These sections\nhave been updated to clarify for which OS they are.\n\nSome places used ""deb"" instead of ""debian"" or missed to add os=""debian"",\nthese were fixed as well.\n\nNote: The basic install guide is build with os=""ubuntu;debian"", so some\nof these changes do not change the generated code.\n\nChange-Id: Ib50c5cee239c370a17d5462c2a6837357242425d\nCloses-Bug: #1206328\n'}, {'number': 2, 'created': '2013-09-04 06:48:19.000000000', 'files': ['doc/src/docbkx/basic-install/src/basic-install_compute-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-dashboard.xml', 'doc/src/docbkx/basic-install/src/basic-install_intro.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-common.xml', 'doc/src/docbkx/basic-install/src/bk-basic-install.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-common.xml', 'doc/src/docbkx/basic-install/src/basic-install_common.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-services.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5d67b95cf89d612fe167110672c5d07149df84a3', 'message': 'Improve Debian support in Basic Install Guide\n\nThe Guide is built for both Debian and Ubuntu and there are a few\nplaces that are only relevant for either of these. These sections\nhave been updated to clarify for which OS they are.\n\nSome places used ""deb"" instead of ""debian"" or missed to add os=""debian"",\nthese were fixed as well.\n\nNote: The basic install guide is build with os=""ubuntu;debian"", so some\nof these changes do not change the generated code.\n\nChange-Id: Ib50c5cee239c370a17d5462c2a6837357242425d\nCloses-Bug: #1206328\n'}]",0,44758,5d67b95cf89d612fe167110672c5d07149df84a3,17,5,2,6547,,,0,"Improve Debian support in Basic Install Guide

The Guide is built for both Debian and Ubuntu and there are a few
places that are only relevant for either of these. These sections
have been updated to clarify for which OS they are.

Some places used ""deb"" instead of ""debian"" or missed to add os=""debian"",
these were fixed as well.

Note: The basic install guide is build with os=""ubuntu;debian"", so some
of these changes do not change the generated code.

Change-Id: Ib50c5cee239c370a17d5462c2a6837357242425d
Closes-Bug: #1206328
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/58/44758/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/basic-install/src/basic-install_compute-nova.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-dashboard.xml', 'doc/src/docbkx/basic-install/src/basic-install_intro.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-common.xml', 'doc/src/docbkx/basic-install/src/bk-basic-install.xml', 'doc/src/docbkx/basic-install/src/basic-install_controller-common.xml', 'doc/src/docbkx/basic-install/src/basic-install_common.xml', 'doc/src/docbkx/basic-install/src/basic-install_network-services.xml']",8,592cd7a48262acf35fb2632c23bc3708340b5165,debian," <programlisting os=""ubuntu;debian"" language=""ini"">[DEFAULT]"," <programlisting os=""ubuntu"" language=""ini"">[DEFAULT]",26,18
openstack%2Fpython-troveclient~master~I578b4f932d193c64634259f41447218006085a43,openstack/python-troveclient,master,I578b4f932d193c64634259f41447218006085a43,Adds support for admin to create flavors through mgmt API,NEW,2013-08-26 17:26:39.000000000,2013-09-04 16:36:00.000000000,,"[{'_account_id': 5293}, {'_account_id': 7799}, {'_account_id': 7806}, {'_account_id': 7831}, {'_account_id': 8310}, {'_account_id': 8312}]","[{'number': 1, 'created': '2013-08-26 17:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/249796350bdbd247e67f418078e5978d208c9160', 'message': 'Adds support for admin to create flavors through mgmt API\nExtending the management API to allow for an admin to create flavors categorized on service type in trove.\nImplements: blueprint service-type-filter-on-flavors\n\nChange-Id: I578b4f932d193c64634259f41447218006085a43\n'}, {'number': 2, 'created': '2013-08-27 12:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/f7482f79c36aebd2eb71a62c88d4b33d793e1e1b', 'message': 'Adds support for admin to create flavors through mgmt API\n\nExtending the management API to allow for an admin to\ncreate flavors categorized on service type in trove.\n\nImplements: blueprint service-type-filter-on-flavors\n\nChange-Id: I578b4f932d193c64634259f41447218006085a43\n'}, {'number': 3, 'created': '2013-08-27 15:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/2c6c3bee76bb13317a4fcdd36c3350f226869c88', 'message': 'Adds support for admin to create flavors through mgmt API\n\nExtending the management API to allow for an admin to\ncreate flavors categorized on service type in trove.\n\nImplements: blueprint service-type-filter-on-flavors\n\nChange-Id: I578b4f932d193c64634259f41447218006085a43\n'}, {'number': 4, 'created': '2013-08-28 13:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/5ecad4bc5d9a44106f7ab72f374e0a60c386aefd', 'message': 'Adds support for admin to create flavors through mgmt API\n\nExtending the management API to allow for an admin to\ncreate flavors categorized on service type in trove.\n\nImplements: blueprint service-type-filter-on-flavors\n\nChange-Id: I578b4f932d193c64634259f41447218006085a43\n'}, {'number': 5, 'created': '2013-08-31 18:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/eb38f45090a01637bd33e72077055a2f7c57492c', 'message': 'Adds support for admin to create flavors through mgmt API\n\nExtending the management API to allow for an admin to\ncreate flavors categorized on service type in trove.\n\nImplements: blueprint service-type-filter-on-flavors\n\nChange-Id: I578b4f932d193c64634259f41447218006085a43\n'}, {'number': 6, 'created': '2013-09-04 16:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/65abb6323991f81c04b5ecbf50c1a11986bf3b9d', 'message': 'Adds support for admin to create flavors through mgmt API\n\nExtending the management API to allow for an admin to\ncreate flavors categorized on service type in trove.\n\nImplements: blueprint service-type-filter-on-flavors\n\nChange-Id: I578b4f932d193c64634259f41447218006085a43\n'}, {'number': 7, 'created': '2013-09-04 16:36:00.000000000', 'files': ['troveclient/tests/test_management.py', 'troveclient/mcli.py', 'troveclient/management.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/5ddf1aa6367d7089f1f8ca3a4c60b7f9a14be5da', 'message': 'Adds support for admin to create flavors through mgmt API\n\nExtending the management API to allow for an admin to\ncreate flavors categorized on service type in trove.\n\nImplements: blueprint service-type-filter-on-flavors\n\nChange-Id: I578b4f932d193c64634259f41447218006085a43\n'}]",2,43742,5ddf1aa6367d7089f1f8ca3a4c60b7f9a14be5da,8,6,7,7806,,,0,"Adds support for admin to create flavors through mgmt API

Extending the management API to allow for an admin to
create flavors categorized on service type in trove.

Implements: blueprint service-type-filter-on-flavors

Change-Id: I578b4f932d193c64634259f41447218006085a43
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/42/43742/1 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/mcli.py', 'troveclient/flavors.py']",2,249796350bdbd247e67f418078e5978d208c9160,bp/service-type-filter-on-flavors," def create(self, name, ram, disk, vcpus, flavorid=""auto"", service_type=None): """""" Create a new flavor. """""" body = {""flavor"": { ""id"": flavorid, ""name"": name, ""ram"": ram, ""disk"": disk, ""vcpu"": vcpus, ""service_type"": service_type }} return self._create(""/flavors"", body, ""flavor"")",,36,0
openstack%2Fceilometer~master~I3814a4222298d2fbc56a25e6e4540d01066ee42f,openstack/ceilometer,master,I3814a4222298d2fbc56a25e6e4540d01066ee42f,Reject duplicate events,MERGED,2013-08-29 00:17:05.000000000,2013-09-04 16:26:34.000000000,2013-09-04 16:26:33.000000000,"[{'_account_id': 3}, {'_account_id': 236}, {'_account_id': 688}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5678}]","[{'number': 1, 'created': '2013-08-29 00:17:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7a8fc6a63e1767b2f04606366cee3cac7791d302', 'message': 'Reject duplicate events\n\nWhen ack_on_error=False, there is a possibility that we\ncould receieve the same message more than once. Reject those events.\n\nChange-Id: I3814a4222298d2fbc56a25e6e4540d01066ee42f\n'}, {'number': 2, 'created': '2013-08-29 21:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2b4ac0f15420f187b359065b4160c2110de5c5e7', 'message': 'Reject duplicate events\n\nWhen ack_on_error=False, there is a possibility that we\ncould receieve the same message more than once. Reject those events.\n\nChange-Id: I3814a4222298d2fbc56a25e6e4540d01066ee42f\n'}, {'number': 3, 'created': '2013-08-30 19:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c41d50e16ce596b75d6f9eabef053c3780d375dd', 'message': 'Reject duplicate events\n\nWhen ack_on_error=False, there is a possibility that we\ncould receieve the same message more than once. Reject those events.\n\nChange-Id: I3814a4222298d2fbc56a25e6e4540d01066ee42f\n'}, {'number': 4, 'created': '2013-09-04 04:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/316e9ab9bb48e93f2c1fc8637a07003c284e90ce', 'message': 'Reject duplicate events\n\nWhen ack_on_error=False, there is a possibility that we\ncould receieve the same message more than once. Reject those events.\n\nChange-Id: I3814a4222298d2fbc56a25e6e4540d01066ee42f\n'}, {'number': 5, 'created': '2013-09-04 13:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a4bca3760bb93ac5757240a5aaa515a9681999a9', 'message': 'Reject duplicate events\n\nWhen ack_on_error=False, there is a possibility that we\ncould receieve the same message more than once. Reject those events.\n\nChange-Id: I3814a4222298d2fbc56a25e6e4540d01066ee42f\n'}, {'number': 6, 'created': '2013-09-04 15:47:43.000000000', 'files': ['ceilometer/storage/models.py', 'tests/collector/dispatcher/test_db.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/014_add_event_message_id.py', 'tests/storage/test_storage_scenarios.py', 'tests/storage/test_models.py', 'tests/storage/test_impl_sqlalchemy.py', 'ceilometer/collector/service.py', 'ceilometer/collector/dispatcher/database.py', 'ceilometer/collector/dispatcher/file.py', 'ceilometer/storage/sqlalchemy/models.py', 'tests/collector/test_service.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5f35319dfaa463d8d08b8ac1733b80a474cb86ab', 'message': 'Reject duplicate events\n\nWhen ack_on_error=False, there is a possibility that we\ncould receieve the same message more than once. Reject those events.\n\nChange-Id: I3814a4222298d2fbc56a25e6e4540d01066ee42f\n'}]",33,44191,5f35319dfaa463d8d08b8ac1733b80a474cb86ab,39,6,6,688,,,0,"Reject duplicate events

When ack_on_error=False, there is a possibility that we
could receieve the same message more than once. Reject those events.

Change-Id: I3814a4222298d2fbc56a25e6e4540d01066ee42f
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/91/44191/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/storage/test_storage_scenarios.py', 'ceilometer/storage/models.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/collector/service.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/013_add_event_message_id.py', 'ceilometer/storage/sqlalchemy/models.py', 'tests/collector/test_service.py']",7,7a8fc6a63e1767b2f04606366cee3cac7791d302,reject_duplicates,"from ceilometer.compute import notifications from ceilometer.openstack.common.db import exception as dbexc from ceilometer.openstack.common import timeutils from ceilometer import sampleclass FakeDispatcher(object): def __init__(self, should_raise): self.should_raise = should_raise self.obj = self def record_events(self, events): if self.should_raise: raise dbexc.DBDuplicateEntry() def test_message_to_event_duplicate(self): message = {'event_type': ""foo"", 'message_id': ""abc""} self.srv.dispatcher_manager = [FakeDispatcher(True), ] with patch.object(service, 'LOG') as mylog: self.srv._message_to_event(message) self.assertEquals(2, mylog.debug.call_count) def test_message_to_event_unique(self): message = {'event_type': ""foo"", 'message_id': ""abc""} self.srv.dispatcher_manager = [FakeDispatcher(False), ] with patch.object(service, 'LOG') as mylog: self.srv._message_to_event(message) self.assertEquals(1, mylog.debug.call_count) ",from ceilometer import sample from ceilometer.openstack.common import timeutilsfrom ceilometer.compute import notifications,119,23
openstack%2Fdevstack~master~I322f4e4703e506620fa7e7456c4264ee0d050edc,openstack/devstack,master,I322f4e4703e506620fa7e7456c4264ee0d050edc,xenapi: Increase default OS domU memory to 2G,MERGED,2013-08-31 11:21:05.000000000,2013-09-04 16:17:01.000000000,2013-09-04 16:17:01.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6735}]","[{'number': 1, 'created': '2013-08-31 11:21:05.000000000', 'files': ['tools/xen/xenrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/4728001d014a38409aabf639fc9a06024342321a', 'message': 'xenapi: Increase default OS domU memory to 2G\n\nIn XenServer scenarios, an additional domU is created to run OpenStack\nservices. This change is increasing the memory for that VM to speed up\ntest runs.\n\nChange-Id: I322f4e4703e506620fa7e7456c4264ee0d050edc\n'}]",0,44587,4728001d014a38409aabf639fc9a06024342321a,9,4,1,5044,,,0,"xenapi: Increase default OS domU memory to 2G

In XenServer scenarios, an additional domU is created to run OpenStack
services. This change is increasing the memory for that VM to speed up
test runs.

Change-Id: I322f4e4703e506620fa7e7456c4264ee0d050edc
",git fetch https://review.opendev.org/openstack/devstack refs/changes/87/44587/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/xen/xenrc'],1,4728001d014a38409aabf639fc9a06024342321a,increasemem,OSDOMU_MEM_MB=2048,OSDOMU_MEM_MB=1024,1,1
openstack%2Fnova~master~I3523888c6bdd22f488c273c9e3eea1083a479700,openstack/nova,master,I3523888c6bdd22f488c273c9e3eea1083a479700,Adds metrics collection support in Hyper-V,MERGED,2013-08-21 22:19:58.000000000,2013-09-04 16:13:56.000000000,2013-09-04 16:13:53.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 3185}, {'_account_id': 5511}, {'_account_id': 6873}]","[{'number': 1, 'created': '2013-08-21 22:19:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1003f71119b60a27d3fd263d90d27276582036aa', 'message': 'Adds metrics collection support in Hyper-V\n\nBlueprint: hyper-v-metrics\n\nHyper-V Server 2012 supports a new set of metrics API that can be used to\nprovide instance metrics data to external applications, e.g. Ceilometer.\n\nMetrics collection is disabled by default and can be enabled with a config\noption.\n\nChange-Id: I3523888c6bdd22f488c273c9e3eea1083a479700\n'}, {'number': 2, 'created': '2013-08-23 19:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65ab8da0510dbd5e36338c62c9c981aa51b19e2e', 'message': 'Adds metrics collection support in Hyper-V\n\nBlueprint: hyper-v-metrics\n\nHyper-V Server 2012 supports a new set of metrics API that can be used to\nprovide instance metrics data to external applications, e.g. Ceilometer.\n\nMetrics collection is disabled by default and can be enabled with a config\noption.\n\nChange-Id: I3523888c6bdd22f488c273c9e3eea1083a479700\n'}, {'number': 3, 'created': '2013-08-24 15:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb7ba4ddf13219b2263912d71e17ae03ece97388', 'message': 'Adds metrics collection support in Hyper-V\n\nBlueprint: hyper-v-metrics\n\nHyper-V Server 2012 supports a new set of metrics API that can be used to\nprovide instance metrics data to external applications, e.g. Ceilometer.\n\nMetrics collection is disabled by default and can be enabled with a config\noption.\n\nChange-Id: I3523888c6bdd22f488c273c9e3eea1083a479700\n'}, {'number': 4, 'created': '2013-08-25 00:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/330a4f4588ccbf0e4af723edfc5e09f0dc784525', 'message': 'Adds metrics collection support in Hyper-V\n\nBlueprint: hyper-v-metrics\n\nHyper-V Server 2012 supports a new set of metrics API that can be used to\nprovide instance metrics data to external applications, e.g. Ceilometer.\n\nMetrics collection is disabled by default and can be enabled with a config\noption.\n\nChange-Id: I3523888c6bdd22f488c273c9e3eea1083a479700\n'}, {'number': 5, 'created': '2013-08-25 00:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ca9d9c9ea7f4fa0b40895b8880568d642335255', 'message': 'Adds metrics collection support in Hyper-V\n\nBlueprint: hyper-v-metrics\n\nHyper-V Server 2012 supports a new set of metrics API that can be used\nto provide instance metrics data to external applications, e.g.\nCeilometer.\n\nMetrics collection is disabled by default and can be enabled with a\nconfig option.\n\nChange-Id: I3523888c6bdd22f488c273c9e3eea1083a479700\n'}, {'number': 6, 'created': '2013-08-25 00:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d52c0f51e43a077a0ef4cfd7c673f6025980bfdf', 'message': 'Adds metrics collection support in Hyper-V\n\nBlueprint: hyper-v-metrics\n\nHyper-V Server 2012 supports a new set of metrics API that can be used\nto provide instance metrics data to external applications, e.g.\nCeilometer.\n\nMetrics collection is disabled by default and can be enabled with a\nconfig option.\n\nChange-Id: I3523888c6bdd22f488c273c9e3eea1083a479700\n'}, {'number': 7, 'created': '2013-08-25 00:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6fd6eaaa46e626f0a4a1aeb745267568cf2aba1a', 'message': 'Adds metrics collection support in Hyper-V\n\nBlueprint: hyper-v-metrics\n\nHyper-V Server 2012 supports a new set of metrics API that can be used\nto provide instance metrics data to external applications, e.g.\nCeilometer.\n\nMetrics collection is disabled by default and can be enabled with a\nconfig option.\n\nChange-Id: I3523888c6bdd22f488c273c9e3eea1083a479700\n'}, {'number': 8, 'created': '2013-09-03 19:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f9d90014c2d0ccaff04193d5d9c7efb69021965', 'message': 'Adds metrics collection support in Hyper-V\n\nBlueprint: hyper-v-metrics\n\nHyper-V Server 2012 supports a new set of metrics API that can be used\nto provide instance metrics data to external applications, e.g.\nCeilometer.\n\nMetrics collection is disabled by default and can be enabled with a\nconfig option.\n\nChange-Id: I3523888c6bdd22f488c273c9e3eea1083a479700\n'}, {'number': 9, 'created': '2013-09-03 20:31:41.000000000', 'files': ['nova/virt/hyperv/vmops.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'etc/nova/nova.conf.sample', 'nova/tests/virt/hyperv/test_vmutilsv2.py', 'nova/virt/hyperv/vmutilsv2.py', 'nova/virt/hyperv/vmutils.py', 'nova/tests/virt/hyperv/test_vmutils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d27895aab8878fbf0d1b51173aa932608f3d3d29', 'message': 'Adds metrics collection support in Hyper-V\n\nBlueprint: hyper-v-metrics\n\nHyper-V Server 2012 supports a new set of metrics API that can be used\nto provide instance metrics data to external applications, e.g.\nCeilometer.\n\nMetrics collection is disabled by default and can be enabled with a\nconfig option.\n\nChange-Id: I3523888c6bdd22f488c273c9e3eea1083a479700\n'}]",8,43197,d27895aab8878fbf0d1b51173aa932608f3d3d29,44,6,9,3185,,,0,"Adds metrics collection support in Hyper-V

Blueprint: hyper-v-metrics

Hyper-V Server 2012 supports a new set of metrics API that can be used
to provide instance metrics data to external applications, e.g.
Ceilometer.

Metrics collection is disabled by default and can be enabled with a
config option.

Change-Id: I3523888c6bdd22f488c273c9e3eea1083a479700
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/43197/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/vmops.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'etc/nova/nova.conf.sample', 'nova/tests/virt/hyperv/test_vmutilsv2.py', 'nova/virt/hyperv/vmutilsv2.py', 'nova/virt/hyperv/vmutils.py']",6,1003f71119b60a27d3fd263d90d27276582036aa,bp/hyper-v-metrics," def enable_vm_metrics_collection(self, vm_name): raise NotImplementedError(_(""Metrics collection is not supported on "" ""this version of Hyper-V""))",,65,1
openstack%2Fneutron~master~Ib34721209c282b2669ff5488a33293d9f86467ef,openstack/neutron,master,Ib34721209c282b2669ff5488a33293d9f86467ef,Add Neutron l3 metering agent,MERGED,2013-07-06 16:06:39.000000000,2013-09-04 15:47:56.000000000,2013-09-04 15:47:55.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1206}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 7141}]","[{'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d0c050baf56abc574abb26736029cde8844f43bf', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nUnit tests are being worked on.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5185bd9536fc5451eb01f550a1775c8f7e43c716', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nUnit tests are being worked on.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f4dfc95ca8b9301711c2affbf4f3fb286a8a40d3', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nUnit tests are being worked on.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/98da9cb3b0fb72b60d59484f68c7daeaeddf74e6', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nUnit tests are being worked on.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 5, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/38811931b03ac9c6d0a13b8863c9bfe9e02be1e7', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nUnit tests are being worked on.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 6, 'created': '2013-07-09 15:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/16eee07cab1c72d06b001a83e2ea0ab6cc31a7af', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nUnit tests are being worked on.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 7, 'created': '2013-07-10 16:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5fccd2b2dad0c1b215f4fa683764e290295275ea', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 8, 'created': '2013-07-11 12:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/18bf4e9f73b8161af54d0e4ccd430d28651f0fec', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 9, 'created': '2013-07-15 12:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/71ec765ed6a6b625c9cf01e4134e66e6744a792f', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 10, 'created': '2013-07-15 12:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4e2a9363e5020506ca99af8cdab87157e183252d', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 11, 'created': '2013-07-15 12:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e3319936552a857e8b31d658c4ad7446e544513', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 12, 'created': '2013-07-16 15:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab4a71f519e8bbe8a764419189146e568e6e313c', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 13, 'created': '2013-07-16 16:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c0d09b5477a940a235e6fc3bf4564aaa685d7b27', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 14, 'created': '2013-07-17 12:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e24bf243e04873b3962f897c311cd42659160d0a', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 15, 'created': '2013-07-17 13:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d7bdac0a9eb651cea2be9d55b65e618be12ef7e', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 16, 'created': '2013-07-19 08:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f8ab0ab8ee15d925221447392cb12d825c07871', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 17, 'created': '2013-07-19 08:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e754df97a7a1efce40831a54a77e42fd8365271d', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 18, 'created': '2013-07-23 10:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f26cfe374615379fae303caa69512e61cbc426b6', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 19, 'created': '2013-07-23 11:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4feadb58c80f65f4020722130400aca2f00bb1b', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 20, 'created': '2013-07-23 11:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e8b564895a025c808dd279a5e86ae9ed3d5e00e2', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 21, 'created': '2013-07-26 08:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e307227f14144fbbc3b4668d97fcb8ab731754c4', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 22, 'created': '2013-08-12 09:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6aac7d3442e1e20b75c36c095b4c1f2f1b8bc487', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 23, 'created': '2013-08-12 11:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f199e05577562be1e7047f337f31737248154b4', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 24, 'created': '2013-08-12 16:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4122443e7d3d2038b7f5f61fda9d38f0f1f23b4d', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 25, 'created': '2013-08-26 17:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b2ada76e96efe65320a3414cb5fdcc271086a3c', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 26, 'created': '2013-08-26 17:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c08ad404c506775bd1dbfdcea6fb8faa9e6aee8', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 27, 'created': '2013-08-27 09:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4e905d88cdaf8c48ce89284c277723a5f8942d70', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 28, 'created': '2013-08-30 17:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5e52a849c83a178bc02895e28df25fd5cc8d8125', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 29, 'created': '2013-08-30 22:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6123b15c0211e5ce424223fd921e72fb788ac440', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 30, 'created': '2013-09-02 08:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/67231a562fe5b0a593012f31e2f88f5685f7bb47', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 31, 'created': '2013-09-02 08:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a5795b0cab5dae6f5b93817f41048a3e7e858d3', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}, {'number': 32, 'created': '2013-09-02 09:56:53.000000000', 'files': ['etc/metering_agent.ini', 'neutron/common/constants.py', 'neutron/services/metering/drivers/abstract_driver.py', 'neutron/services/metering/agents/metering_agent.py', 'neutron/services/metering/drivers/noop/__init__.py', 'neutron/common/topics.py', 'neutron/services/metering/drivers/__init__.py', 'neutron/services/metering/drivers/noop/noop_driver.py', 'neutron/services/metering/agents/__init__.py', 'setup.cfg', 'neutron/tests/unit/services/metering/test_metering_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5ec6a60602eda70d6e65173085036b1b593afd44', 'message': 'Add Neutron l3 metering agent\n\nThis is the agent side of :\nblueprint bandwidth-router-measurement\nblueprint bandwidth-router-label\n\nThis patch initiates agent side by adding a new\nl3 metering agent and a Noop Driver.\n\nDocImpact\n\nChange-Id: Ib34721209c282b2669ff5488a33293d9f86467ef\n'}]",62,35655,5ec6a60602eda70d6e65173085036b1b593afd44,102,11,32,7141,,,0,"Add Neutron l3 metering agent

This is the agent side of :
blueprint bandwidth-router-measurement
blueprint bandwidth-router-label

This patch initiates agent side by adding a new
l3 metering agent and a Noop Driver.

DocImpact

Change-Id: Ib34721209c282b2669ff5488a33293d9f86467ef
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/35655/32 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/services/metering/drivers/noop/noop_driver.py', 'quantum/common/topics.py', 'bin/quantum-metering-agent', 'quantum/common/constants.py', 'quantum/services/metering/drivers/abstract_driver.py', 'quantum/services/metering/agents/__init__.py', 'quantum/services/metering/drivers/__init__.py', 'quantum/services/metering/agents/metering_l3_agent.py', 'quantum/services/metering/drivers/noop/__init__.py', 'quantum/services/metering/__init__.py']",10,d0c050baf56abc574abb26736029cde8844f43bf,bp/bandwidth-router-measurement-l3,"# Copyright (C) 2013 eNovance SAS <licensing@enovance.com> # # Author: Sylvain Afchain <sylvain.afchain@enovance.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License.",,479,0
openstack%2Fmurano-dashboard~master~Id4977b40cebba7e1fada055443c6c26ab64d9584,openstack/murano-dashboard,master,Id4977b40cebba7e1fada055443c6c26ab64d9584,Move muranodashboard logs to a separate file.,MERGED,2013-09-04 12:41:12.000000000,2013-09-04 15:41:37.000000000,2013-09-04 15:41:37.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7821}, {'_account_id': 8040}]","[{'number': 1, 'created': '2013-09-04 12:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/810a0db1ae629659ebb89a65f6c5d2d5beff9597', 'message': 'Draft fix for MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}, {'number': 2, 'created': '2013-09-04 12:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/c3abbecfbbd6fb84a3c9641e750fdfc34875d0ed', 'message': 'Draft fix for MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}, {'number': 3, 'created': '2013-09-04 13:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/1cf1c1c98749a97e5102ce8a14f2bdc7706eb401', 'message': 'Draft fix for MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}, {'number': 4, 'created': '2013-09-04 13:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/8c35590e4479c386ebcd32ef89c0af4844b8ddb7', 'message': 'Draft fix for MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}, {'number': 5, 'created': '2013-09-04 13:19:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/3f832bd1a87b63bfb70b784df03e9c5f6383ff21', 'message': 'Draft fix for MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}, {'number': 6, 'created': '2013-09-04 13:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/d74b3373a6cb699f15a38d729e1ecd9e9b1d2293', 'message': 'Draft fix for MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}, {'number': 7, 'created': '2013-09-04 13:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/154cfd9f8557b1c5780b1e9b54b61b16dee53955', 'message': 'Draft fix for MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}, {'number': 8, 'created': '2013-09-04 13:36:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/39aa86f5c939745bce466d25ca3a82f3d642d1c3', 'message': 'Draft fix for MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}, {'number': 9, 'created': '2013-09-04 13:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/287c5aa1d4f738383c6fb43b79f6ac53e1f76579', 'message': 'Draft fix for MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}, {'number': 10, 'created': '2013-09-04 14:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/6dd75c849139ae22ebf07ff62b127b27a45bbaf7', 'message': 'Move muranodashboard logs to a separate file\n/var/log/murano-dashboard.log.\n\nFixes: bug MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}, {'number': 11, 'created': '2013-09-04 15:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/09f96a212fc79cd7ca876c3a6983b6573c33a303', 'message': 'Move muranodashboard logs to a separate file\n/var/log/murano-dashboard.log.\n\nFixes: bug MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}, {'number': 12, 'created': '2013-09-04 15:22:31.000000000', 'files': ['setup-centos.sh', 'setup.sh', 'muranodashboard/panel/services/fields.py', 'muranodashboard/settings.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/8efc260e9bcc9a6dcd1647f517b91d2c957fdce6', 'message': 'Move muranodashboard logs to a separate file.\n\nDefault file location is /var/log/murano-dashboard.log\n(hard-coded into horizon config, still have to make it\nmore flexible). In this separate file we have the same\nlog levels which were specified in code (contrary to\nubiquitous [error] in apache logs).\n\nFixes: bug MRN-745.\n\nChange-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584\n'}]",0,45048,8efc260e9bcc9a6dcd1647f517b91d2c957fdce6,39,4,12,8040,,,0,"Move muranodashboard logs to a separate file.

Default file location is /var/log/murano-dashboard.log
(hard-coded into horizon config, still have to make it
more flexible). In this separate file we have the same
log levels which were specified in code (contrary to
ubiquitous [error] in apache logs).

Fixes: bug MRN-745.

Change-Id: Id4977b40cebba7e1fada055443c6c26ab64d9584
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/48/45048/11 && git format-patch -1 --stdout FETCH_HEAD,"['setup.sh', 'muranodashboard/panel/services/fields.py']",2,810a0db1ae629659ebb89a65f6c5d2d5beff9597,bug/MRN-745,, log.debug('Inside PasswordField compare method'),7,1
openstack%2Fceilometer~master~I3e3219d2eae0b72ad4a898630cacfd334e9390cc,openstack/ceilometer,master,I3e3219d2eae0b72ad4a898630cacfd334e9390cc,alarm api: rename counter_name to meter_name,MERGED,2013-08-29 14:20:07.000000000,2013-09-04 15:41:00.000000000,2013-09-04 15:41:00.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5678}]","[{'number': 1, 'created': '2013-08-29 14:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0324eeab5f91ce5cf9e5cc5bd55ee0e5a3c63ab1', 'message': ""alarm api: rename counter_name to meter_name\n\nWe already have a really poor naming convention the metering API, and we\ndecided to remove the counter term from everywhere. We can't fix the\nmetering API since we relesed it, so let's fix the alarming one before\nit gets released and we have to handle a lot of complicated\ncompatibility. :-(\n\nChange-Id: I3e3219d2eae0b72ad4a898630cacfd334e9390cc\n""}, {'number': 2, 'created': '2013-09-02 14:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7a9ddb0e6162809d62e69c9efd434ddec5043c5a', 'message': ""alarm api: rename counter_name to meter_name\n\nWe already have a really poor naming convention the metering API, and we\ndecided to remove the counter term from everywhere. We can't fix the\nmetering API since we relesed it, so let's fix the alarming one before\nit gets released and we have to handle a lot of complicated\ncompatibility. :-(\n\nChange-Id: I3e3219d2eae0b72ad4a898630cacfd334e9390cc\n""}, {'number': 3, 'created': '2013-09-04 11:48:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1f4ce948ac5f34bd5cc7493c44087756fd1f48f6', 'message': ""alarm api: rename counter_name to meter_name\n\nWe already have a really poor naming convention the metering API, and we\ndecided to remove the counter term from everywhere. We can't fix the\nmetering API since we relesed it, so let's fix the alarming one before\nit gets released and we have to handle a lot of complicated\ncompatibility. :-(\n\nChange-Id: I3e3219d2eae0b72ad4a898630cacfd334e9390cc\n""}, {'number': 4, 'created': '2013-09-04 12:06:46.000000000', 'files': ['ceilometer/alarm/threshold_evaluation.py', 'ceilometer/storage/models.py', 'ceilometer/storage/impl_sqlalchemy.py', 'tests/storage/test_impl_mongodb.py', 'tests/alarm/test_singleton_alarm_svc.py', 'tests/alarm/test_threshold_evaluation.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/013_rename_counter_to_meter_alarm.py', 'tests/storage/test_storage_scenarios.py', 'tests/api/v2/test_alarm_scenarios.py', 'tests/alarm/test_rpc.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/storage/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/785196931961521060e456066226284cafc553be', 'message': ""alarm api: rename counter_name to meter_name\n\nWe already have a really poor naming convention the metering API, and we\ndecided to remove the counter term from everywhere. We can't fix the\nmetering API since we relesed it, so let's fix the alarming one before\nit gets released and we have to handle a lot of complicated\ncompatibility. :-(\n\nChange-Id: I3e3219d2eae0b72ad4a898630cacfd334e9390cc\n""}]",3,44292,785196931961521060e456066226284cafc553be,21,6,4,1669,,,0,"alarm api: rename counter_name to meter_name

We already have a really poor naming convention the metering API, and we
decided to remove the counter term from everywhere. We can't fix the
metering API since we relesed it, so let's fix the alarming one before
it gets released and we have to handle a lot of complicated
compatibility. :-(

Change-Id: I3e3219d2eae0b72ad4a898630cacfd334e9390cc
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/92/44292/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/alarm/threshold_evaluation.py', 'ceilometer/storage/models.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/007_add_alarm_table.py', 'ceilometer/storage/impl_sqlalchemy.py', 'tests/storage/test_impl_mongodb.py', 'tests/alarm/test_singleton_alarm_svc.py', 'tests/alarm/test_threshold_evaluation.py', 'tests/storage/test_storage_scenarios.py', 'tests/api/v2/test_alarm_scenarios.py', 'tests/alarm/test_rpc.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/storage/sqlalchemy/models.py']",12,0324eeab5f91ce5cf9e5cc5bd55ee0e5a3c63ab1,jd/alarm-generate-id-in-api," Index('ix_alarm_meter_name', 'meter_name'), meter_name = Column(String(255))"," Index('ix_alarm_counter_name', 'counter_name'), counter_name = Column(String(255))",30,30
openstack%2Fheat~master~I86e1d5289487b34712c248bc5e68e62cc4651ec6,openstack/heat,master,I86e1d5289487b34712c248bc5e68e62cc4651ec6,Update nested stacks in parallel,MERGED,2013-09-02 17:41:02.000000000,2013-09-04 15:34:36.000000000,2013-09-04 15:34:36.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 7135}]","[{'number': 1, 'created': '2013-09-02 17:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c330281dea76a84c5dae9658a14f1c7e06832473', 'message': 'Update nested stacks in parallel\n\nThis parallelises updates for AWS::CloudFormation::Stack resources, but not\nfor autoscaling groups. Other types of nested stacks (the old LoadBalancer\nand DBInstance resources, and provider templates) have not yet implemented\nstack updates.\n\nChange-Id: I86e1d5289487b34712c248bc5e68e62cc4651ec6\n'}, {'number': 2, 'created': '2013-09-04 08:46:34.000000000', 'files': ['heat/engine/resources/autoscaling.py', 'heat/tests/test_nested_stack.py', 'heat/engine/stack_resource.py', 'heat/engine/resources/stack.py', 'heat/tests/test_stack_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a9e7278d00d95a5376a895069624517429c7671b', 'message': 'Update nested stacks in parallel\n\nThis parallelises updates for AWS::CloudFormation::Stack resources, but not\nfor autoscaling groups. Other types of nested stacks (the old LoadBalancer\nand DBInstance resources, and provider templates) have not yet implemented\nstack updates.\n\nChange-Id: I86e1d5289487b34712c248bc5e68e62cc4651ec6\n'}]",0,44754,a9e7278d00d95a5376a895069624517429c7671b,10,4,2,4257,,,0,"Update nested stacks in parallel

This parallelises updates for AWS::CloudFormation::Stack resources, but not
for autoscaling groups. Other types of nested stacks (the old LoadBalancer
and DBInstance resources, and provider templates) have not yet implemented
stack updates.

Change-Id: I86e1d5289487b34712c248bc5e68e62cc4651ec6
",git fetch https://review.opendev.org/openstack/heat refs/changes/54/44754/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/autoscaling.py', 'heat/tests/test_nested_stack.py', 'heat/engine/stack_resource.py', 'heat/engine/resources/stack.py', 'heat/tests/test_stack_resource.py']",5,c330281dea76a84c5dae9658a14f1c7e06832473,parallel-launch," updater = self.parent_resource.update_with_template( updater.run_to_completion() self.assertEqual(True, self.parent_resource.check_update_complete(updater)) def update_task(): yield self.m.StubOutWithMock(self.stack, 'update_task') self.stack.update_task(mox.IgnoreArg()).AndReturn(update_task()) updater = self.parent_resource.update_with_template(new_templ, {}) updater.run_to_completion() self.assertEqual((self.stack.UPDATE, self.stack.FAILED), self.stack.state) ex = self.assertRaises(exception.Error, self.parent_resource.check_update_complete, updater) self.assertEqual('Nested stack update failed: ', str(ex))"," update_result = self.parent_resource.update_with_template( def change_state(stack): self.m.StubOutWithMock(self.stack, 'update') self.stack.update(mox.IgnoreArg()).WithSideEffects(change_state) try: self.parent_resource.update_with_template(new_templ, {}) except exception.Error as ex: self.assertEqual('Nested stack update failed: ', ex.message)",37,14
openstack%2Fheat~master~I3757a77daf59cbb3c0a8b60329d490a89e7ec1d3,openstack/heat,master,I3757a77daf59cbb3c0a8b60329d490a89e7ec1d3,Fix problem with mocking tasks,MERGED,2013-09-02 17:41:02.000000000,2013-09-04 15:33:06.000000000,2013-09-04 15:33:05.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-09-02 17:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9e7c9df566186a04d2f743883953c24fc89b360d', 'message': 'Fix problem with mocking tasks\n\nIt was previously impossible to stub out a task with mox, because when the\nTaskRunner attempted to get the __name__ attribute it prompted an assertion\nin the mock. Using hasattr() instead of getattr() eliminates this issue.\n\nChange-Id: I3757a77daf59cbb3c0a8b60329d490a89e7ec1d3\n'}, {'number': 2, 'created': '2013-09-04 08:46:34.000000000', 'files': ['heat/engine/scheduler.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f28446e970258fac0979ddd0f6d436cc779cb488', 'message': 'Fix problem with mocking tasks\n\nIt was previously impossible to stub out a task with mox, because when the\nTaskRunner attempted to get the __name__ attribute it prompted an assertion\nin the mock. Using hasattr() instead of getattr() eliminates this issue.\n\nChange-Id: I3757a77daf59cbb3c0a8b60329d490a89e7ec1d3\n'}]",0,44753,f28446e970258fac0979ddd0f6d436cc779cb488,18,5,2,4257,,,0,"Fix problem with mocking tasks

It was previously impossible to stub out a task with mox, because when the
TaskRunner attempted to get the __name__ attribute it prompted an assertion
in the mock. Using hasattr() instead of getattr() eliminates this issue.

Change-Id: I3757a77daf59cbb3c0a8b60329d490a89e7ec1d3
",git fetch https://review.opendev.org/openstack/heat refs/changes/53/44753/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/scheduler.py'],1,9e7c9df566186a04d2f743883953c24fc89b360d,parallel-launch," name = task.__name__ if hasattr(task, '__name__') else None if isinstance(task, types.MethodType): if name is not None and hasattr(task, '__self__'): return '%s from %s' % (name, task.__self__)"," name = getattr(task, '__name__', None) if isinstance(task, types.MethodType): obj = getattr(task, '__self__', None) if name is not None and obj is not None: return '%s from %s' % (name, obj)",3,4
openstack%2Fheat~master~I184666182f5b9648d2d297d4290eb8608a09c0f0,openstack/heat,master,I184666182f5b9648d2d297d4290eb8608a09c0f0,Create a Stack.update_task() method,MERGED,2013-09-02 17:41:02.000000000,2013-09-04 15:33:04.000000000,2013-09-04 15:33:03.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}]","[{'number': 1, 'created': '2013-09-02 17:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1532b042d701a36d0fbf63c7fe52360766650495', 'message': 'Create a Stack.update_task() method\n\nThis will allow nested stack resources to run updates in parallel with\nother resources.\n\nChange-Id: I184666182f5b9648d2d297d4290eb8608a09c0f0\n'}, {'number': 2, 'created': '2013-09-04 08:46:34.000000000', 'files': ['heat/engine/parser.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/8f57e2e8b2019b72de5ee5496746944f306784f8', 'message': 'Create a Stack.update_task() method\n\nThis will allow nested stack resources to run updates in parallel with\nother resources.\n\nChange-Id: I184666182f5b9648d2d297d4290eb8608a09c0f0\n'}]",0,44752,8f57e2e8b2019b72de5ee5496746944f306784f8,25,4,2,4257,,,0,"Create a Stack.update_task() method

This will allow nested stack resources to run updates in parallel with
other resources.

Change-Id: I184666182f5b9648d2d297d4290eb8608a09c0f0
",git fetch https://review.opendev.org/openstack/heat refs/changes/52/44752/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/parser.py'],1,1532b042d701a36d0fbf63c7fe52360766650495,parallel-launch," def update(self, newstack): updater = scheduler.TaskRunner(self.update_task, newstack) updater() @scheduler.wrappertask def update_task(self, newstack, action=UPDATE): updater.start(timeout=self.timeout_secs()) yield while not updater.step(): yield yield self.update_task(oldstack, action=self.ROLLBACK)"," def update(self, newstack, action=UPDATE): updater(timeout=self.timeout_secs()) self.update(oldstack, action=self.ROLLBACK)",11,3
openstack%2Fhorizon~master~Ib684424e4cfd4a2437fc53186d07bf977c18086c,openstack/horizon,master,Ib684424e4cfd4a2437fc53186d07bf977c18086c,Fixing typos for Resource Usage page,MERGED,2013-09-04 08:55:24.000000000,2013-09-04 15:33:02.000000000,2013-09-04 15:33:01.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 4978}]","[{'number': 1, 'created': '2013-09-04 08:55:24.000000000', 'files': ['openstack_dashboard/dashboards/admin/metering/tables.py', 'openstack_dashboard/dashboards/admin/metering/templates/metering/index.html', 'openstack_dashboard/dashboards/admin/metering/tabs.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e8484934bebb041ed4036f8e98693e0caf79037f', 'message': 'Fixing typos for Resource Usage page\n\n- fixing few typos for resource usage page\n\nNOTE: it needs to go in H3, not RC1 because I am\nchanging the translated strings.\n\nChange-Id: Ib684424e4cfd4a2437fc53186d07bf977c18086c\n'}]",0,45021,e8484934bebb041ed4036f8e98693e0caf79037f,8,3,1,7585,,,0,"Fixing typos for Resource Usage page

- fixing few typos for resource usage page

NOTE: it needs to go in H3, not RC1 because I am
changing the translated strings.

Change-Id: Ib684424e4cfd4a2437fc53186d07bf977c18086c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/21/45021/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/metering/tables.py', 'openstack_dashboard/dashboards/admin/metering/templates/metering/index.html', 'openstack_dashboard/dashboards/admin/metering/tabs.py']",3,e8484934bebb041ed4036f8e98693e0caf79037f,ceilometer-resource-usage-fix-typos," ""disk.read.bytes"": _(""Volume of reads in B""), ""disk.write.bytes"": _(""Volume of writes in B""), ""network.incoming.bytes"": _(""Number of incoming bytes "" ""network.outgoing.bytes"": _(""Number of outgoing bytes "" ""network.incoming.packets"": _(""Number of incoming "" ""network.outgoing.packets"": _(""Number of outgoing """," ""disk.read.bytes"": _(""Volume of read in B""), ""disk.write.bytes"": _(""Volume of write in B""), ""network.incoming.bytes"": _(""number of incoming bytes "" ""network.outgoing.bytes"": _(""number of outgoing bytes "" ""network.incoming.packets"": _(""number of incoming "" ""network.outgoing.packets"": _(""number of outgoing """,9,9
openstack%2Fpython-keystoneclient~master~I79ad58dd8cdabf44808cc20984bc75331491bdd5,openstack/python-keystoneclient,master,I79ad58dd8cdabf44808cc20984bc75331491bdd5,upgrade to hacking 0.7,ABANDONED,2013-09-03 12:45:42.000000000,2013-09-04 15:32:44.000000000,,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6676}, {'_account_id': 7725}]","[{'number': 1, 'created': '2013-09-03 12:45:42.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/737efd253968803823ab97afeaa7dd71b48cd625', 'message': 'upgrade to hacking 0.7\n\nChange-Id: I79ad58dd8cdabf44808cc20984bc75331491bdd5\n'}]",0,44865,737efd253968803823ab97afeaa7dd71b48cd625,5,4,1,4,,,0,"upgrade to hacking 0.7

Change-Id: I79ad58dd8cdabf44808cc20984bc75331491bdd5
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/65/44865/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,737efd253968803823ab97afeaa7dd71b48cd625,(detached,"# H202 assertRaises Exception too broadignore = F821,H202,H304","ignore = F821,H304",3,2
openstack%2Fhorizon~master~Ifc72915d34767ce83f9d85b92ddeae0c2c00b8c6,openstack/horizon,master,Ifc72915d34767ce83f9d85b92ddeae0c2c00b8c6,Make Image Service image formats configurable,MERGED,2013-09-03 18:56:52.000000000,2013-09-04 15:30:26.000000000,2013-09-04 15:30:26.000000000,"[{'_account_id': 3}, {'_account_id': 1816}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6966}, {'_account_id': 8642}]","[{'number': 1, 'created': '2013-09-03 18:56:52.000000000', 'files': ['run_tests.sh', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/forms.py', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/dashboards/admin/projects/tests.py', 'openstack_dashboard/test/settings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/47757ada085b7f4d1569d15af6f0eb64597ea60d', 'message': ""Make Image Service image formats configurable\n\nAllow configuration of the available image formats\nfor image creation (corresponds to a feature added\nGlance).\n\nIncidentally fixes a test issue where the domain_get\ncall wasn't being properly stubbed out.\n\nFixes bug 1216157\n\nChange-Id: Ifc72915d34767ce83f9d85b92ddeae0c2c00b8c6\n""}]",0,44938,47757ada085b7f4d1569d15af6f0eb64597ea60d,11,6,1,1816,,,0,"Make Image Service image formats configurable

Allow configuration of the available image formats
for image creation (corresponds to a feature added
Glance).

Incidentally fixes a test issue where the domain_get
call wasn't being properly stubbed out.

Fixes bug 1216157

Change-Id: Ifc72915d34767ce83f9d85b92ddeae0c2c00b8c6
",git fetch https://review.opendev.org/openstack/horizon refs/changes/38/44938/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'openstack_dashboard/dashboards/project/images_and_snapshots/images/forms.py', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/dashboards/admin/projects/tests.py', 'openstack_dashboard/test/settings.py']",5,47757ada085b7f4d1569d15af6f0eb64597ea60d,bug/1216157,"OPENSTACK_IMAGE_BACKEND = { 'image_formats': [ ('', ''), ('aki', _('AKI - Amazon Kernel Image')), ('ami', _('AMI - Amazon Machine Image')), ('ari', _('ARI - Amazon Ramdisk Image')), ('iso', _('ISO - Optical Disk Image')), ('qcow2', _('QCOW2 - QEMU Emulator')), ('raw', _('Raw')), ('vdi', _('VDI')), ('vhd', _('VHD')), ('vmdk', _('VMDK')) ] } ",,44,21
openstack%2Fglance~master~I2d1cb7f5748dba203f72f2996c2228f7bfed7987,openstack/glance,master,I2d1cb7f5748dba203f72f2996c2228f7bfed7987,Show traceback info if a functional test fails,MERGED,2013-08-29 10:14:09.000000000,2013-09-04 15:30:25.000000000,2013-09-04 15:30:24.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6493}]","[{'number': 1, 'created': '2013-08-29 10:14:09.000000000', 'files': ['glance/tests/functional/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/f4cab3e5ccd02ed33eba36bf97fafbe413412993', 'message': 'Show traceback info if a functional test fails\n\nFixes bug 1218277\n\nChange-Id: I2d1cb7f5748dba203f72f2996c2228f7bfed7987\n'}]",0,44260,f4cab3e5ccd02ed33eba36bf97fafbe413412993,10,5,1,1390,,,0,"Show traceback info if a functional test fails

Fixes bug 1218277

Change-Id: I2d1cb7f5748dba203f72f2996c2228f7bfed7987
",git fetch https://review.opendev.org/openstack/glance refs/changes/60/44260/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/functional/__init__.py'],1,f4cab3e5ccd02ed33eba36bf97fafbe413412993,bug/1218277,default_log_levels = eventlet.wsgi.server=DEBUG,,1,0
openstack%2Fopenstack-manuals~master~Iff409277bc64e3a3b514607ce4038de0c35f0dea,openstack/openstack-manuals,master,Iff409277bc64e3a3b514607ce4038de0c35f0dea,Add preface Image Guide,MERGED,2013-09-03 18:09:31.000000000,2013-09-04 15:30:18.000000000,2013-09-04 15:30:17.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-09-03 18:09:31.000000000', 'files': ['doc/src/docbkx/openstack-image/bk-imageguide.xml', 'doc/src/docbkx/openstack-image/ch_preface.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b6178659c1d6fe76b7a4533c98bed797b55b738a', 'message': 'Add preface Image Guide\n\nThe Image Guide did not show the revision history, a simple\npreface that shows a history has been added.\n\nChange-Id: Iff409277bc64e3a3b514607ce4038de0c35f0dea\n'}]",0,44927,b6178659c1d6fe76b7a4533c98bed797b55b738a,5,2,1,6547,,,0,"Add preface Image Guide

The Image Guide did not show the revision history, a simple
preface that shows a history has been added.

Change-Id: Iff409277bc64e3a3b514607ce4038de0c35f0dea
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/27/44927/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-image/bk-imageguide.xml', 'doc/src/docbkx/openstack-image/ch_preface.xml']",2,b6178659c1d6fe76b7a4533c98bed797b55b738a,image-preface,"<?xml version=""1.0"" encoding=""UTF-8""?> <preface xmlns=""http://docbook.org/ns/docbook"" xmlns:xlink=""http://www.w3.org/1999/xlink"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:svg=""http://www.w3.org/2000/svg"" xmlns:m=""http://www.w3.org/1998/Math/MathML"" xmlns:html=""http://www.w3.org/1999/xhtml"" xmlns:db=""http://docbook.org/ns/docbook"" version=""5.0"" xml:id=""ch_preface""> <title>Preface</title> <?dbhtml stop-chunking?> <xi:include href=""../common/section_dochistory.xml""/> </preface> ",,15,0
openstack%2Fopenstack-manuals~stable%2Fgrizzly~Ia74ffbb4ed327af41f938f900fc105492606b50b,openstack/openstack-manuals,stable/grizzly,Ia74ffbb4ed327af41f938f900fc105492606b50b,Warn operators not to install openvswitch-brcompat,MERGED,2013-09-04 15:14:55.000000000,2013-09-04 15:30:11.000000000,2013-09-04 15:30:10.000000000,"[{'_account_id': 3}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-09-04 15:14:55.000000000', 'files': ['doc/src/docbkx/openstack-network-connectivity-admin/ch_install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4556714e2dfb42c7587a054fbfd52af8c701fb9d', 'message': ""Warn operators not to install openvswitch-brcompat\n\nThe LibvirtHybridOVSBridgeDriver VIF driver for the Open vSwitch\nNeutron plugin needs to create a Linux bridge using brctl for the\niptables firewall rules that implement security groups. But if the\npackage openvswitch-brcompat is installed, brctl actually creates an\nOVS bridge and the security groups won't work.\n\nbug: #1220358\n\nCherry-picked from https://review.openstack.org/45061\n\nChange-Id: Ia74ffbb4ed327af41f938f900fc105492606b50b\n""}]",0,45073,4556714e2dfb42c7587a054fbfd52af8c701fb9d,5,2,1,321,,,0,"Warn operators not to install openvswitch-brcompat

The LibvirtHybridOVSBridgeDriver VIF driver for the Open vSwitch
Neutron plugin needs to create a Linux bridge using brctl for the
iptables firewall rules that implement security groups. But if the
package openvswitch-brcompat is installed, brctl actually creates an
OVS bridge and the security groups won't work.

bug: #1220358

Cherry-picked from https://review.openstack.org/45061

Change-Id: Ia74ffbb4ed327af41f938f900fc105492606b50b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/73/45073/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-network-connectivity-admin/ch_install.xml'],1,4556714e2dfb42c7587a054fbfd52af8c701fb9d,grizzly/warn-ovsbrcompat, <warning> <para>Do not install the openvswitch-brcompat package as it breaks the security groups functionality.</para> </warning>,,4,0
openstack%2Fopenstack-manuals~master~Ife42fe26d42058aabc2864303475cd04c0c69929,openstack/openstack-manuals,master,Ife42fe26d42058aabc2864303475cd04c0c69929,Add openSUSE Basic Install Guide to docs.o.o/trunk,MERGED,2013-09-01 19:54:30.000000000,2013-09-04 15:30:04.000000000,2013-09-04 15:30:03.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-09-01 19:54:30.000000000', 'files': ['www/trunk/index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f9562944bd8c07307e7994a47ac13e25487beafc', 'message': 'Add openSUSE Basic Install Guide to docs.o.o/trunk\n\nChange-Id: Ife42fe26d42058aabc2864303475cd04c0c69929\n'}]",1,44628,f9562944bd8c07307e7994a47ac13e25487beafc,8,4,1,6547,,,0,"Add openSUSE Basic Install Guide to docs.o.o/trunk

Change-Id: Ife42fe26d42058aabc2864303475cd04c0c69929
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/28/44628/1 && git format-patch -1 --stdout FETCH_HEAD,['www/trunk/index.html'],1,f9562944bd8c07307e7994a47ac13e25487beafc,openSUSE-index," <a href=""http://docs.openstack.org/trunk/basic-install/zypper/content"" >Basic Installation Guide for openSUSE 12.3</a></dd> <dd>",,5,0
openstack%2Fnova~master~Iee86c36bcc474a604993618b8a2255af8c3d2f48,openstack/nova,master,Iee86c36bcc474a604993618b8a2255af8c3d2f48,Port all rpcapi modules to oslo.messaging interface,MERGED,2013-08-05 15:01:37.000000000,2013-09-04 15:29:35.000000000,2013-09-04 15:29:33.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5511}]","[{'number': 1, 'created': '2013-08-05 15:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4b3baecd81f19484d4ea6c6ccfa8d7ef969e6ea', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo.messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 2, 'created': '2013-08-06 06:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1a4820817a1ed0f8927fdf6d2fd3b9726f00fff', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo.messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 3, 'created': '2013-08-06 07:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/137a9135d1bac9ec5e0d16685e776c4e1af0ab2c', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo.messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 4, 'created': '2013-08-11 21:08:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e5576ab3112e939b88364d8f915be6cfd7189c79', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo.messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 5, 'created': '2013-08-11 21:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/170e56a87600a36c68d3757eef3cf1559b574705', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo.messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 6, 'created': '2013-08-16 22:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e01f8ac1c9f136a0a0c2e9391b3b4bbf60d7b421', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 7, 'created': '2013-08-17 07:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd18254c9f79b02ca8e039f758194f30fcfe9814', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 8, 'created': '2013-08-19 10:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13d80c3b319fec217dcfb04495f8607b820faee7', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 9, 'created': '2013-08-19 22:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0010769df58d52b9c66a9d671a07d90aafd13703', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 10, 'created': '2013-08-21 10:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1b51ef9752b943a3548d7aab06f1ea8a10849ee8', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 11, 'created': '2013-08-21 14:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc0c6e597d72d94b790f0cbff0947a513b5f9e12', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 12, 'created': '2013-08-21 14:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1ae41cd3b72962864cc560245fbea9cc0f5a7a0', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 13, 'created': '2013-08-23 18:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd0623027f85dc31954733a02e24b0675cbbf948', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 14, 'created': '2013-08-27 21:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e60045a67ae7fe813f132bdc21fffc99c9b5b473', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 15, 'created': '2013-08-27 23:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13291ac33b63c17457643bfb2033a680caa8fca7', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 16, 'created': '2013-08-29 08:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07bd9cfb26b91cba4a6b667ed454029868b8bb8b', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 17, 'created': '2013-08-29 09:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55d4b9c2bb45c089df414d2ae6fcfff362f17da5', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 18, 'created': '2013-08-29 23:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f0e68596f36394c7a3febc3913e43d4e95151596', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 19, 'created': '2013-08-30 06:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad7754e3dbc3241187f64c9393f9a6692a60fa5d', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 20, 'created': '2013-09-02 16:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd9916e8dffb38a583486f0b07dceaebe4f0fdcf', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 21, 'created': '2013-09-03 18:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a2733b60a91679169f9fc08e24459a0b403bb5a', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}, {'number': 22, 'created': '2013-09-03 20:27:59.000000000', 'files': ['nova/objects/base.py', 'nova/rpcclient.py', 'nova/scheduler/rpcapi.py', 'nova/consoleauth/rpcapi.py', 'nova/tests/cells/test_cells_rpc_driver.py', 'nova/cells/rpc_driver.py', 'nova/tests/network/test_rpcapi.py', 'nova/baserpc.py', 'nova/conductor/rpcapi.py', 'nova/network/rpcapi.py', 'nova/compute/cells_api.py', 'nova/console/rpcapi.py', 'nova/cert/rpcapi.py', 'nova/compute/rpcapi.py', 'nova/cells/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/33b9e6f47ce498b403c1661fdd91407ca5029f70', 'message': 'Port all rpcapi modules to oslo.messaging interface\n\nAdd a temporary nova.rpcclient.RPCClient helper class which translates\noslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy\nobject.\n\nUse this new class to port all of the rpcapi modules over to the new\nRPCClient so that the final port of Nova over to oslo.messaging will be\nsmaller and easier to review.\n\nThis patch contains no functional changes at all, except that all client\nside RPCs go through this temporary helper class.\n\nblueprint: oslo-messaging\nChange-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48\n'}]",20,40237,33b9e6f47ce498b403c1661fdd91407ca5029f70,101,7,22,1247,,,0,"Port all rpcapi modules to oslo.messaging interface

Add a temporary nova.rpcclient.RPCClient helper class which translates
oslo.messaging.rpc.RPCClient compatible calls into calls on a RpcProxy
object.

Use this new class to port all of the rpcapi modules over to the new
RPCClient so that the final port of Nova over to oslo.messaging will be
smaller and easier to review.

This patch contains no functional changes at all, except that all client
side RPCs go through this temporary helper class.

blueprint: oslo-messaging
Change-Id: Iee86c36bcc474a604993618b8a2255af8c3d2f48
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/40237/22 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/rpcclient.py', 'nova/scheduler/rpcapi.py', 'nova/consoleauth/rpcapi.py', 'nova/tests/cells/test_cells_rpc_driver.py', 'nova/cells/rpc_driver.py', 'nova/baserpc.py', 'nova/conductor/rpcapi.py', 'nova/network/rpcapi.py', 'nova/console/rpcapi.py', 'nova/cert/rpcapi.py', 'nova/compute/rpcapi.py', 'nova/cells/rpcapi.py']",13,c4b3baecd81f19484d4ea6c6ccfa8d7ef969e6ea,bp/oslo-messaging,"from nova import rpcclientclass CellsAPI(rpcclient.RpcProxy): self.client = self.get_client() self.client.cast(ctxt, 'run_compute_api_method', cell_name=cell_name, method_info=method_info, call=False) return self.client.call(ctxt, 'run_compute_api_method', cell_name=cell_name, method_info=method_info, call=True) self.client.cast(ctxt, 'schedule_run_instance', host_sched_kwargs=kwargs) cctxt = self.client.prepare(version='1.8') cctxt.cast(ctxt, 'build_instances', build_inst_kwargs=build_inst_kwargs) self.client.cast(ctxt, 'instance_update_at_top', instance=instance_p) self.client.cast(ctxt, 'instance_destroy_at_top', instance=instance_p) self.client.cast(ctxt, 'instance_delete_everywhere', instance=instance_p, delete_type=delete_type) self.client.cast(ctxt, 'instance_fault_create_at_top', instance_fault=instance_fault_p) self.client.cast(ctxt, 'bw_usage_update_at_top', bw_update_info=bw_update_info) self.client.cast(ctxt, 'instance_update_at_top', instance=instance) cctxt = self.client.prepare(version='1.1') return cctxt.call(ctxt, 'get_cell_info_for_neighbors') cctxt = self.client.prepare(version='1.1') return cctxt.cast(ctxt, 'sync_instances', project_id=project_id, updated_since=updated_since, deleted=deleted) cctxt = self.client.prepare(version='1.2') return cctxt.call(ctxt, 'service_get_all', filters=filters) cctxt = self.client.prepare(version='1.2') return cctxt.call(ctxt, 'service_get_by_compute_host', host_name=host_name) cctxt = self.client.prepare(version='1.17') return cctxt.call(context, 'get_host_uptime', host_name=host_name) cctxt = self.client.prepare(version='1.7') return cctxt.call(ctxt, 'service_update', host_name=host_name, binary=binary, params_to_update=params_to_update) cctxt = self.client.prepare(version='1.2', timeout=timeout) return cctxt.call(ctxt, 'proxy_rpc_to_manager', topic=topic, rpc_message=rpc_message, call=call, timeout=timeout) cctxt = self.client.prepare(version='1.3') return cctxt.call(ctxt, 'task_log_get_all', task_name=task_name, period_beginning=period_beginning, period_ending=period_ending, host=host, state=state) cctxt = self.client.prepare(version='1.4') return cctxt.call(ctxt, 'compute_node_get', compute_id=compute_id) cctxt = self.client.prepare(version='1.4') return cctxt.call(ctxt, 'compute_node_get_all', hypervisor_match=hypervisor_match) cctxt = self.client.prepare(version='1.4') return cctxt.call(ctxt, 'compute_node_stats') cctxt = self.client.prepare(version='1.5') return cctxt.call(ctxt, 'actions_get', cell_name=instance['cell_name'], instance_uuid=instance['uuid']) cctxt = self.client.prepare(version='1.5') return cctxt.call(ctxt, 'action_get_by_request_id', cell_name=instance['cell_name'], instance_uuid=instance['uuid'], request_id=request_id) cctxt = self.client.prepare(version='1.5') return cctxt.call(ctxt, 'action_events_get', cell_name=instance['cell_name'], action_id=action_id) cctxt = self.client.prepare(version='1.6') cctxt.cast(ctxt, 'consoleauth_delete_tokens', instance_uuid=instance_uuid) cctxt = self.client.prepare(version='1.6') return cctxt.call(ctxt, 'validate_console_port', instance_uuid=instance_uuid, console_port=console_port, console_type=console_type) cctxt = self.client.prepare(version='1.9') return cctxt.call(ctxt, 'get_capacities', cell_name=cell_name) cctxt = self.client.prepare(version='1.10') try: cctxt.cast(ctxt, 'bdm_update_or_create_at_top', bdm=bdm, create=create) cctxt = self.client.prepare(version='1.10') try: cctxt.cast(ctxt, 'bdm_destroy_at_top', instance_uuid=instance_uuid, device_name=device_name, volume_id=volume_id) cctxt = self.client.prepare(version='1.11') return cctxt.call(ctxt, 'get_migrations', filters=filters) cctxt = self.client.prepare(version='1.16') cctxt.cast(ctxt, 'instance_update_from_api', instance=instance, expected_vm_state=expected_vm_state, expected_task_state=expected_task_state, admin_state_reset=admin_state_reset) cctxt = self.client.prepare(version='1.12') cctxt.cast(ctxt, 'start_instance', instance=instance) cctxt = self.client.prepare(version='1.12') method = do_cast and cctxt.cast or cctxt.call return method(ctxt, 'stop_instance', instance=instance, do_cast=do_cast) cctxt = self.client.prepare(version='1.13') return cctxt.call(ctxt, 'cell_create', values=values) cctxt = self.client.prepare(version='1.13') return cctxt.call(ctxt, 'cell_update', cell_name=cell_name, values=values) cctxt = self.client.prepare(version='1.13') return cctxt.call(ctxt, 'cell_delete', cell_name=cell_name) cctxt = self.client.prepare(version='1.13') return cctxt.call(ctxt, 'cell_get', cell_name=cell_name) cctxt = self.client.prepare(version='1.14') cctxt.cast(ctxt, 'reboot_instance', instance=instance, reboot_type=reboot_type) cctxt = self.client.prepare(version='1.15') cctxt.cast(ctxt, 'suspend_instance', instance=instance) cctxt = self.client.prepare(version='1.15') cctxt.cast(ctxt, 'resume_instance', instance=instance) cctxt = self.client.prepare(version='1.18') cctxt.cast(ctxt, 'terminate_instance', instance=instance) cctxt = self.client.prepare(version='1.18') cctxt.cast(ctxt, 'soft_delete_instance', instance=instance)","from nova.openstack.common.rpc import proxy as rpc_proxyclass CellsAPI(rpc_proxy.RpcProxy): self.cast(ctxt, self.make_msg('run_compute_api_method', cell_name=cell_name, method_info=method_info, call=False)) return self.call(ctxt, self.make_msg('run_compute_api_method', cell_name=cell_name, method_info=method_info, call=True)) self.cast(ctxt, self.make_msg('schedule_run_instance', host_sched_kwargs=kwargs)) self.cast(ctxt, self.make_msg('build_instances', build_inst_kwargs=build_inst_kwargs), version='1.8') self.cast(ctxt, self.make_msg('instance_update_at_top', instance=instance_p)) self.cast(ctxt, self.make_msg('instance_destroy_at_top', instance=instance_p)) self.cast(ctxt, self.make_msg('instance_delete_everywhere', instance=instance_p, delete_type=delete_type)) self.cast(ctxt, self.make_msg('instance_fault_create_at_top', instance_fault=instance_fault_p)) self.cast(ctxt, self.make_msg('bw_usage_update_at_top', bw_update_info=bw_update_info)) self.cast(ctxt, self.make_msg('instance_update_at_top', instance=instance)) return self.call(ctxt, self.make_msg('get_cell_info_for_neighbors'), version='1.1') return self.cast(ctxt, self.make_msg('sync_instances', project_id=project_id, updated_since=updated_since, deleted=deleted), version='1.1') return self.call(ctxt, self.make_msg('service_get_all', filters=filters), version='1.2') return self.call(ctxt, self.make_msg('service_get_by_compute_host', host_name=host_name), version='1.2') return self.call(context, self.make_msg('get_host_uptime', host_name=host_name), version='1.17') return self.call(ctxt, self.make_msg( 'service_update', host_name=host_name, binary=binary, params_to_update=params_to_update), version='1.7') return self.call(ctxt, self.make_msg('proxy_rpc_to_manager', topic=topic, rpc_message=rpc_message, call=call, timeout=timeout), timeout=timeout, version='1.2') return self.call(ctxt, self.make_msg('task_log_get_all', task_name=task_name, period_beginning=period_beginning, period_ending=period_ending, host=host, state=state), version='1.3') return self.call(ctxt, self.make_msg('compute_node_get', compute_id=compute_id), version='1.4') return self.call(ctxt, self.make_msg('compute_node_get_all', hypervisor_match=hypervisor_match), version='1.4') return self.call(ctxt, self.make_msg('compute_node_stats'), version='1.4') return self.call(ctxt, self.make_msg('actions_get', cell_name=instance['cell_name'], instance_uuid=instance['uuid']), version='1.5') return self.call(ctxt, self.make_msg('action_get_by_request_id', cell_name=instance['cell_name'], instance_uuid=instance['uuid'], request_id=request_id), version='1.5') return self.call(ctxt, self.make_msg('action_events_get', cell_name=instance['cell_name'], action_id=action_id), version='1.5') self.cast(ctxt, self.make_msg('consoleauth_delete_tokens', instance_uuid=instance_uuid), version='1.6') return self.call(ctxt, self.make_msg('validate_console_port', instance_uuid=instance_uuid, console_port=console_port, console_type=console_type), version='1.6') return self.call(ctxt, self.make_msg('get_capacities', cell_name=cell_name), version='1.9') try: self.cast(ctxt, self.make_msg('bdm_update_or_create_at_top', bdm=bdm, create=create), version='1.10') try: self.cast(ctxt, self.make_msg('bdm_destroy_at_top', instance_uuid=instance_uuid, device_name=device_name, volume_id=volume_id), version='1.10') return self.call(ctxt, self.make_msg('get_migrations', filters=filters), version='1.11') self.cast(ctxt, self.make_msg('instance_update_from_api', instance=instance, expected_vm_state=expected_vm_state, expected_task_state=expected_task_state, admin_state_reset=admin_state_reset), version='1.16') self.cast(ctxt, self.make_msg('start_instance', instance=instance), version='1.12') method = do_cast and self.cast or self.call return method(ctxt, self.make_msg('stop_instance', instance=instance, do_cast=do_cast), version='1.12') return self.call(ctxt, self.make_msg('cell_create', values=values), version='1.13') return self.call(ctxt, self.make_msg('cell_update', cell_name=cell_name, values=values), version='1.13') return self.call(ctxt, self.make_msg('cell_delete', cell_name=cell_name), version='1.13') return self.call(ctxt, self.make_msg('cell_get', cell_name=cell_name), version='1.13') self.cast(ctxt, self.make_msg('reboot_instance', instance=instance, reboot_type=reboot_type), version='1.14') self.cast(ctxt, self.make_msg('suspend_instance', instance=instance), version='1.15') self.cast(ctxt, self.make_msg('resume_instance', instance=instance), version='1.15') self.cast(ctxt, self.make_msg('terminate_instance', instance=instance), version='1.18') self.cast(ctxt, self.make_msg('soft_delete_instance', instance=instance), version='1.18')",933,872
openstack%2Fnova~master~I6c7a918d301fe4091e92dda3fc8c509863be91e6,openstack/nova,master,I6c7a918d301fe4091e92dda3fc8c509863be91e6,Remove useless code,ABANDONED,2013-08-23 15:00:54.000000000,2013-09-04 15:28:25.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 7494}]","[{'number': 1, 'created': '2013-08-23 15:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/67a9c7e344e748a2cf15dc62cb79b8a8cfe8615a', 'message': 'Remove useless code\n\nRemove useless code in two files:\n1) nova/compute/api.py\n2) nova/objects/base.py\n\nChange-Id: I6c7a918d301fe4091e92dda3fc8c509863be91e6\n'}, {'number': 2, 'created': '2013-08-23 15:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f59af4cd0b0b0b4ee228dcd6028054c1106847e6', 'message': 'Remove useless code from nova/objects/base.py\n\nRemove useless code from nova/objects/base.py\n\nChange-Id: I6c7a918d301fe4091e92dda3fc8c509863be91e6\n'}, {'number': 3, 'created': '2013-08-24 02:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1bfb077d378851ff9bd8532b60442183be8af21', 'message': 'Remove useless code\n\nRemove useless code from two files\n1) nova/objects/base.py\n2) nova/compute/api.py\n\nChange-Id: I6c7a918d301fe4091e92dda3fc8c509863be91e6\n'}, {'number': 4, 'created': '2013-08-26 09:57:23.000000000', 'files': ['nova/objects/base.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f1aad6f0f57bbf764546d20f9b777e0560e4e643', 'message': 'Remove useless code\n\nRemove useless code from two files\n1) nova/objects/base.py\n2) nova/compute/api.py\n\nChange-Id: I6c7a918d301fe4091e92dda3fc8c509863be91e6\n'}]",6,43485,f1aad6f0f57bbf764546d20f9b777e0560e4e643,20,5,4,7494,,,0,"Remove useless code

Remove useless code from two files
1) nova/objects/base.py
2) nova/compute/api.py

Change-Id: I6c7a918d301fe4091e92dda3fc8c509863be91e6
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/43485/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/compute/api.py']",2,67a9c7e344e748a2cf15dc62cb79b8a8cfe8615a,master,," elevated = context.elevated() aggregate = self.db.aggregate_get(context, aggregate_id)",0,4
openstack%2Fcookbook-openstack-compute~master~I23200532854402778eaaad2f6e87d64b67755d33,openstack/cookbook-openstack-compute,master,I23200532854402778eaaad2f6e87d64b67755d33,Added quota attributes to nova.conf.erb,MERGED,2013-09-03 19:41:48.000000000,2013-09-04 15:27:20.000000000,2013-09-04 15:27:20.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 26}, {'_account_id': 7220}]","[{'number': 1, 'created': '2013-09-03 19:41:48.000000000', 'files': ['attributes/default.rb', 'templates/default/nova.conf.erb', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/009f8e87ef17e28ca93bbecac075134db7e374f0', 'message': 'Added quota attributes to nova.conf.erb\n\nAdded a bunch of quota attributes to the nova.conf\nbased on table 5.30 in the nova docs here:\nhttp://docs.openstack.org/trunk/openstack-compute/admin/content/list-of-compute-config-options.html\n\nChange-Id: I23200532854402778eaaad2f6e87d64b67755d33\n'}]",0,44945,009f8e87ef17e28ca93bbecac075134db7e374f0,7,4,1,161,,,0,"Added quota attributes to nova.conf.erb

Added a bunch of quota attributes to the nova.conf
based on table 5.30 in the nova docs here:
http://docs.openstack.org/trunk/openstack-compute/admin/content/list-of-compute-config-options.html

Change-Id: I23200532854402778eaaad2f6e87d64b67755d33
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/45/44945/1 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'templates/default/nova.conf.erb', 'README.md']",3,009f8e87ef17e28ca93bbecac075134db7e374f0,add_compute_quota_attributes,| **Author** | Kevin Bringard (<kbringard@att.com>) |,,48,0
openstack%2Fcinder~master~Ibd071c9c3ae9a02f26c85a09e8bc6619d8c73a37,openstack/cinder,master,Ibd071c9c3ae9a02f26c85a09e8bc6619d8c73a37,Use tempfile and cleanup in windows unit test,MERGED,2013-09-03 22:43:07.000000000,2013-09-04 15:27:18.000000000,2013-09-04 15:27:18.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2759}, {'_account_id': 4355}]","[{'number': 1, 'created': '2013-09-03 22:43:07.000000000', 'files': ['cinder/tests/test_windows.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f0ab7be7c304dad9d925dbc6a82c67ec5bbfc1da', 'message': ""Use tempfile and cleanup in windows unit test\n\nThe unit test test_windows was setting and creating\na directory c://iSCSIVirtualDisks in the root path\nand even worse wasn't deleting it on cleanup.\n\nThis patch converts that to use tempfile and also\nadds an shutil.rmtree to the teardown method to clean\nup all the junk it creates.\n\nFixes bug: 1219950\n\nChange-Id: Ibd071c9c3ae9a02f26c85a09e8bc6619d8c73a37\n""}]",0,44973,f0ab7be7c304dad9d925dbc6a82c67ec5bbfc1da,11,4,1,2243,,,0,"Use tempfile and cleanup in windows unit test

The unit test test_windows was setting and creating
a directory c://iSCSIVirtualDisks in the root path
and even worse wasn't deleting it on cleanup.

This patch converts that to use tempfile and also
adds an shutil.rmtree to the teardown method to clean
up all the junk it creates.

Fixes bug: 1219950

Change-Id: Ibd071c9c3ae9a02f26c85a09e8bc6619d8c73a37
",git fetch https://review.opendev.org/openstack/cinder refs/changes/73/44973/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_windows.py'],1,f0ab7be7c304dad9d925dbc6a82c67ec5bbfc1da,bug/1219950,"import shutil import tempfile self.lun_path_tempdir = tempfile.mkdtemp() windows_iscsi_lun_path=self.lun_path_tempdir, shutil.rmtree(self.lun_path_tempdir)"," windows_iscsi_lun_path='C:\iSCSIVirtualDisks',",5,1
openstack%2Fcinder~master~I107888e6b4dac8eb5f1b45a87721a7b5efc45632,openstack/cinder,master,I107888e6b4dac8eb5f1b45a87721a7b5efc45632,Add view builder to QoS specs API extension,MERGED,2013-08-30 18:57:13.000000000,2013-09-04 15:27:16.000000000,2013-09-04 15:27:16.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}]","[{'number': 1, 'created': '2013-08-30 18:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e8b6d2e81bc8ed6a37788b4811c7c023c52aa22b', 'message': 'Add view builder to QoS specs API extension\n\nAdd view builder for qos_specs.create(), index(), show() and associations()\nto in order to make the response more easier to be consumed by client.\n\nAlso fixed some typo in debug message and removed unused imports.\n\nfix bug: # 1219016\n\nChange-Id: I107888e6b4dac8eb5f1b45a87721a7b5efc45632\n'}, {'number': 2, 'created': '2013-08-30 19:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5e6ddb1edf6228b3a262dfe94e63fca266687f19', 'message': 'Add view builder to QoS specs API extension\n\nAdd view builder for qos_specs.create(), index(), show() and associations()\nto in order to make the response more easier to be consumed by client.\n\nAlso fixed some typo in debug message and removed unused imports.\n\nfix bug: # 1219016\n\nChange-Id: I107888e6b4dac8eb5f1b45a87721a7b5efc45632\n'}, {'number': 3, 'created': '2013-09-04 03:08:25.000000000', 'files': ['cinder/api/views/qos_specs.py', 'cinder/tests/test_qos_specs.py', 'cinder/volume/qos_specs.py', 'cinder/tests/db/test_qos_specs.py', 'cinder/api/contrib/qos_specs_manage.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/api/contrib/test_qos_specs_manage.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4a028e3f3307ef4cfdc4fe0cd6be50f408a84fef', 'message': 'Add view builder to QoS specs API extension\n\nAdd view builder for qos_specs.create(), index(), show() and associations()\nto in order to make the response more easier to be consumed by client.\n\nThis patch also:\n  fixed circular reference error when raising HTTP exception.\n  fixed some typo in debug message and removed unused imports.\n\nfix bug: # 1219016\n\nChange-Id: I107888e6b4dac8eb5f1b45a87721a7b5efc45632\n'}]",0,44524,4a028e3f3307ef4cfdc4fe0cd6be50f408a84fef,20,5,3,2759,,,0,"Add view builder to QoS specs API extension

Add view builder for qos_specs.create(), index(), show() and associations()
to in order to make the response more easier to be consumed by client.

This patch also:
  fixed circular reference error when raising HTTP exception.
  fixed some typo in debug message and removed unused imports.

fix bug: # 1219016

Change-Id: I107888e6b4dac8eb5f1b45a87721a7b5efc45632
",git fetch https://review.opendev.org/openstack/cinder refs/changes/24/44524/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/views/qos_specs.py', 'cinder/tests/test_qos_specs.py', 'cinder/volume/qos_specs.py', 'cinder/tests/db/test_qos_specs.py', 'cinder/api/contrib/qos_specs_manage.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/api/contrib/test_qos_specs_manage.py']",7,e8b6d2e81bc8ed6a37788b4811c7c023c52aa22b,qosviewbuilder," res = dict(name='qos_specs_' + str(id)) res.update(dict(consumer='back-end')) res.update(dict(id=str(id))) res.update(dict(specs=specs)) return res return [{ 'association_type': 'volume_type', 'name': 'FakeVolTypeName', 'id': 'FakeVolTypeID'}] return [ stub_qos_specs(1), stub_qos_specs(2), stub_qos_specs(3), ] return stub_qos_specs(int(id)) res = self.controller.index(req) self.assertEqual(3, len(res['qos_specs'])) names = set() for item in res['qos_specs']: self.assertEqual('value1', item['specs']['key1']) names.add(item['name']) self.assertEqual(names, set(expected_names)) self.assertEqual('1', res_dict['qos_specs']['id']) self.assertEqual('qos_specs_1', res_dict['qos_specs']['name']) self.assertEqual('FakeVolTypeName', res['qos_associations'][0]['name']) res['qos_associations'][0]['id'])"," specs.update(dict(id=str(id))) return specs return {str(id): {'FakeVolTypeName': 'FakeVolTypeID'}} return dict( qos_specs_1=stub_qos_specs(1), qos_specs_2=stub_qos_specs(2), qos_specs_3=stub_qos_specs(3) ) name = 'qos_specs_%s' % id return {name: stub_qos_specs(int(id))} res_dict = self.controller.index(req) self.assertEqual(3, len(res_dict.keys())) self.assertEqual(set(res_dict.keys()), set(expected_names)) for key in res_dict.keys(): self.assertEqual('value1', res_dict[key]['key1']) self.assertEqual(1, len(res_dict)) self.assertEqual(1, len(res_dict)) self.assertEqual('1', res_dict['qos_specs_1']['id']) self.assertEqual('1', res.keys()[0]) self.assertEqual('FakeVolTypeName', res['1'].keys()[0]) res['1']['FakeVolTypeName'])",222,106
openstack%2Fcinder~master~I74f662e736e3a5fe58a383d172780a691a2b36c7,openstack/cinder,master,I74f662e736e3a5fe58a383d172780a691a2b36c7,Fixes cinder-volume service startup on Windows,MERGED,2013-09-02 16:32:22.000000000,2013-09-04 15:27:14.000000000,2013-09-04 15:27:13.000000000,"[{'_account_id': 3}, {'_account_id': 752}, {'_account_id': 1207}, {'_account_id': 2166}, {'_account_id': 3185}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 8543}]","[{'number': 1, 'created': '2013-09-02 16:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/87b93b4efd9eac85757bf42bf1d5200ac135a224', 'message': 'Fixes cinder-volume service startup on Windows\n\nThe Windows service fails due to missing non-blocking IO features\nin eventlet. This fix adds a conditional path on Windows to execute\nthe service accordingly.\n\nFixes bug: #1219896\n\nChange-Id: I74f662e736e3a5fe58a383d172780a691a2b36c7\n'}, {'number': 2, 'created': '2013-09-03 10:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3e016f65563bc7463296730661e0ad1c49655696', 'message': 'Fixes cinder-volume service startup on Windows\n\nThe Windows service fails due to missing non-blocking IO features\nin eventlet. This fix adds a conditional path on Windows to execute\nthe service accordingly.\n\nFixes bug: #1219896\n\nChange-Id: I74f662e736e3a5fe58a383d172780a691a2b36c7\n'}, {'number': 3, 'created': '2013-09-03 15:43:34.000000000', 'files': ['bin/cinder-volume'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2f4e9b22b74f696fdac5aed8b57a70e34b113bc8', 'message': 'Fixes cinder-volume service startup on Windows\n\nThe Windows service fails due to missing non-blocking IO features\nin eventlet. This fix adds a conditional path on Windows to execute\nthe service accordingly.\n\nFixes bug: #1219896\n\nChange-Id: I74f662e736e3a5fe58a383d172780a691a2b36c7\n'}]",2,44744,2f4e9b22b74f696fdac5aed8b57a70e34b113bc8,29,9,3,8543,,,0,"Fixes cinder-volume service startup on Windows

The Windows service fails due to missing non-blocking IO features
in eventlet. This fix adds a conditional path on Windows to execute
the service accordingly.

Fixes bug: #1219896

Change-Id: I74f662e736e3a5fe58a383d172780a691a2b36c7
",git fetch https://review.opendev.org/openstack/cinder refs/changes/44/44744/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/cinder-volume'],1,87b93b4efd9eac85757bf42bf1d5200ac135a224,bug/1219896, if os.name == 'nt': eventlet.monkey_patch(os=False) else: eventlet.monkey_patch() if os.name == 'nt': launcher = service launcher.launch_server = service.serve else: launcher = service.ProcessLauncher(), eventlet.monkey_patch() launcher = service.ProcessLauncher(),11,4
openstack%2Fnova~master~Ie18300bdfaaec8d9c813352fe42a2aebec730c45,openstack/nova,master,Ie18300bdfaaec8d9c813352fe42a2aebec730c45,VMware: clean up get_network_with_the_name,MERGED,2013-08-26 15:07:50.000000000,2013-09-04 15:26:46.000000000,2013-09-04 15:26:44.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 7629}]","[{'number': 1, 'created': '2013-08-26 15:07:50.000000000', 'files': ['nova/virt/vmwareapi/network_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8a86025a48570c6bfae9b221f1688f996019a67f', 'message': 'VMware: clean up get_network_with_the_name\n\nBy default the method returns None. No need to do this explicitly.\n\nChange-Id: Ie18300bdfaaec8d9c813352fe42a2aebec730c45\n'}]",0,43720,8a86025a48570c6bfae9b221f1688f996019a67f,13,6,1,1653,,,0,"VMware: clean up get_network_with_the_name

By default the method returns None. No need to do this explicitly.

Change-Id: Ie18300bdfaaec8d9c813352fe42a2aebec730c45
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/43720/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/network_util.py'],1,8a86025a48570c6bfae9b221f1688f996019a67f,remove-redundant,, else: return None,0,2
openstack%2Fzaqar~master~Ieed92fc0a07d2e873b729242fb2fb14536462780,openstack/zaqar,master,Ieed92fc0a07d2e873b729242fb2fb14536462780,fix: claimed message require claim_id to delete,MERGED,2013-08-22 19:41:57.000000000,2013-09-04 15:26:24.000000000,2013-09-04 15:26:24.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6943}, {'_account_id': 6944}]","[{'number': 1, 'created': '2013-08-22 19:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ca9a2f0950780b69d464ed46a7455fb5fc9685ed', 'message': 'fix: claimed message require claim_id to delete\n\nBut bulk deletion can still delete both unclaimed and claimed\nmessages.  However, the major purpose to support bulk deletion\nis to make it easy for a user to issue a DELETE on the Location\nheader returned from a POST; if a user intend to use claim, then\nthis URI does not help.\n\nChange-Id: Ieed92fc0a07d2e873b729242fb2fb14536462780\nCloses-Bug: #1215484\n'}, {'number': 2, 'created': '2013-08-29 14:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7c9f133752a1836868e24381ce513b304e660102', 'message': 'fix: claimed message require claim_id to delete\n\nBut bulk deletion can still delete both unclaimed and claimed\nmessages.  However, the major purpose to support bulk deletion\nis to make it easy for a user to issue a DELETE on the Location\nheader returned from a POST; if a user intend to use claim, then\nthis URI does not help.\n\nChange-Id: Ieed92fc0a07d2e873b729242fb2fb14536462780\nCloses-Bug: #1215484\n'}, {'number': 3, 'created': '2013-08-29 14:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/4cf3ce07f2216d169bccb8527f6ee6528d57f919', 'message': 'fix: claimed message require claim_id to delete\n\nBut bulk deletion can still delete both unclaimed and claimed\nmessages.  However, the major purpose to support bulk deletion\nis to make it easy for a user to issue a DELETE on the Location\nheader returned from a POST; if a user intend to use claim, then\nthis URI does not help.\n\nChange-Id: Ieed92fc0a07d2e873b729242fb2fb14536462780\nCloses-Bug: #1215484\n'}, {'number': 4, 'created': '2013-08-29 20:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c707497b8537586dc02373c11616cca172a0a2d1', 'message': 'fix: claimed message require claim_id to delete\n\nBut bulk deletion can still delete both unclaimed and claimed\nmessages.  However, the major purpose to support bulk deletion\nis to make it easy for a user to issue a DELETE on the Location\nheader returned from a POST; if a user intend to use claim, then\nthis URI does not help.\n\nChange-Id: Ieed92fc0a07d2e873b729242fb2fb14536462780\nCloses-Bug: #1215484\n'}, {'number': 5, 'created': '2013-08-29 20:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7e74c1750d8e5538a03704343aa4f2db81dfce8f', 'message': 'fix: claimed message require claim_id to delete\n\nBut bulk deletion can still delete both unclaimed and claimed\nmessages.  However, the major purpose to support bulk deletion\nis to make it easy for a user to issue a DELETE on the Location\nheader returned from a POST; if a user intend to use claim, then\nthis URI does not help.\n\nChange-Id: Ieed92fc0a07d2e873b729242fb2fb14536462780\nCloses-Bug: #1215484\n'}, {'number': 6, 'created': '2013-08-29 20:36:09.000000000', 'files': ['marconi/storage/sqlite/messages.py', 'marconi/storage/exceptions.py', 'marconi/tests/transport/wsgi/test_claims.py', 'marconi/storage/mongodb/messages.py', 'marconi/transport/wsgi/messages.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/3376b920ed1abdc0822cbd7d97cef4b2e6a3b410', 'message': 'fix: claimed message require claim_id to delete\n\nBut bulk deletion can still delete both unclaimed and claimed\nmessages.  However, the major purpose to support bulk deletion\nis to make it easy for a user to issue a DELETE on the Location\nheader returned from a POST; if a user intend to use claim, then\nthis URI does not help.\n\nChange-Id: Ieed92fc0a07d2e873b729242fb2fb14536462780\nCloses-Bug: #1215484\n'}]",3,43339,3376b920ed1abdc0822cbd7d97cef4b2e6a3b410,21,5,6,6943,,,0,"fix: claimed message require claim_id to delete

But bulk deletion can still delete both unclaimed and claimed
messages.  However, the major purpose to support bulk deletion
is to make it easy for a user to issue a DELETE on the Location
header returned from a POST; if a user intend to use claim, then
this URI does not help.

Change-Id: Ieed92fc0a07d2e873b729242fb2fb14536462780
Closes-Bug: #1215484
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/39/43339/6 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/storage/sqlite/messages.py', 'marconi/storage/exceptions.py', 'marconi/tests/transport/wsgi/test_claims.py', 'marconi/storage/mongodb/messages.py', 'marconi/transport/wsgi/messages.py']",5,ca9a2f0950780b69d464ed46a7455fb5fc9685ed,no-delete-claimed, title = _(u'Unable to delete') description = _(u'This message is claimed; can not be ' u'deleted without an working claim_id.'), title = _(u'Invalid claim') description = _(u'The specified claim either does not ' u'exist or has expired.'),52,31
openstack%2Fheat~master~I2723b18ef3eba81ee8c8a22d866ceb79c00aad75,openstack/heat,master,I2723b18ef3eba81ee8c8a22d866ceb79c00aad75,Change _testnoexisthost_ references in tests,MERGED,2013-09-03 23:09:51.000000000,2013-09-04 15:25:19.000000000,2013-09-04 15:25:18.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7385}]","[{'number': 1, 'created': '2013-09-03 23:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b568ee86ab5422d8557cf0ddc19a39423f57bf11', 'message': ""Change _testnoexisthost_ references in tests\n\nThese dummy urls are obviously invalid, but could potentially trigger\nunexpected failures due to the underscores.\n\nInstead use RFC2606's recommended test TLD of '.test' ensures\nthat these will never resolve.\n\nChange-Id: I2723b18ef3eba81ee8c8a22d866ceb79c00aad75\n""}, {'number': 2, 'created': '2013-09-03 23:13:22.000000000', 'files': ['heat/tests/test_s3.py', 'heat/tests/test_signal.py', 'heat/tests/test_swift.py', 'heat/tests/test_waitcondition.py', 'heat/tests/test_loadbalancer.py', 'heat/tests/test_metadata_refresh.py', 'heat/tests/utils.py', 'heat/tests/test_autoscaling.py', 'heat/tests/test_heatclient.py', 'heat/tests/test_sqlalchemy_api.py', 'heat/tests/test_ceilometer_alarm.py', 'heat/tests/test_nova_utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7f3c7c690ee1968304b239486419d17dcd0bdbc8', 'message': ""Change _testnoexisthost_ references in tests\n\nThese dummy urls are obviously invalid, but could potentially trigger\nunexpected failures due to the underscores.\n\nInstead use RFC2606's recommended test TLD of '.test' ensures\nthat these will never resolve.\n\nChange-Id: I2723b18ef3eba81ee8c8a22d866ceb79c00aad75\n""}]",0,44976,7f3c7c690ee1968304b239486419d17dcd0bdbc8,9,4,2,4328,,,0,"Change _testnoexisthost_ references in tests

These dummy urls are obviously invalid, but could potentially trigger
unexpected failures due to the underscores.

Instead use RFC2606's recommended test TLD of '.test' ensures
that these will never resolve.

Change-Id: I2723b18ef3eba81ee8c8a22d866ceb79c00aad75
",git fetch https://review.opendev.org/openstack/heat refs/changes/76/44976/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_s3.py', 'heat/tests/test_signal.py', 'heat/tests/test_swift.py', 'heat/tests/test_waitcondition.py', 'heat/tests/test_loadbalancer.py', 'heat/tests/test_metadata_refresh.py', 'heat/tests/utils.py', 'heat/tests/test_autoscaling.py', 'heat/tests/test_heatclient.py', 'heat/tests/test_sqlalchemy_api.py', 'heat/tests/test_ceilometer_alarm.py', 'heat/tests/test_nova_utils.py']",12,b568ee86ab5422d8557cf0ddc19a39423f57bf11,bp/heat-trusts3," cnf.heat_metadata_server_url = 'http://server.test:123' cnf.heat_watch_server_url = 'http://server.test:345' self.assertTrue(""http://server.test:345"" in data) self.assertTrue(""http://server.test:123"" in data)"," cnf.heat_metadata_server_url = 'http://_testnoexisthost_:123' cnf.heat_watch_server_url = 'http://_testnoexisthost_:345' self.assertTrue(""http://_testnoexisthost_:345"" in data) self.assertTrue(""http://_testnoexisthost_:123"" in data)",34,34
openstack%2Fheat~master~I288114d827481bc0a24eba4556400d98b1a44c09,openstack/heat,master,I288114d827481bc0a24eba4556400d98b1a44c09,Migrate stored credentials to keystone trusts,MERGED,2013-08-22 23:36:18.000000000,2013-09-04 15:25:17.000000000,2013-09-04 15:25:16.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 7135}, {'_account_id': 7385}, {'_account_id': 7714}]","[{'number': 1, 'created': '2013-08-22 23:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6ee3cf1dfc4db4642d6feb9af9a12cd40985239b', 'message': ""Migrate stored credentials to keystone trusts\n\nMigrate the stored user_creds, which currently only supports\nstoring username/password credentials to use the keystone v3\nAPI OS-TRUST extension, which allows explicit impersonation of\nusers calling heat (trustors) by the heat service user (the\ntrustee)\n\nNote this feature is made optional via a new config option,\ndefaulted to on, and it requires the following patches to\nkeystoneclient (not yet released) and keystone to work:\n\nhttps://review.openstack.org/#/c/39899/\nhttps://review.openstack.org/#/c/42456/\n\nCurrently this is just a work-in-progress, needs tests and\nmost probably doesn't work properly - feedback welcome on\nthe general approach tho :)\n\nblueprint heat-trusts\n\nChange-Id: I288114d827481bc0a24eba4556400d98b1a44c09\n""}, {'number': 2, 'created': '2013-08-28 17:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/edbe6fbbd5c2959ac28501956555e6abea0432b7', 'message': 'Migrate stored credentials to keystone trusts\n\nMigrate the stored user_creds, which currently only supports\nstoring username/password credentials to use the keystone v3\nAPI OS-TRUST extension, which allows explicit impersonation of\nusers calling heat (trustors) by the heat service user (the\ntrustee)\n\nNote this feature is made optional via a new config option,\ndefaulted to on, and it requires the following patches to\nkeystoneclient (in 0.3.2 release) and keystone to work:\n\nhttps://review.openstack.org/#/c/39899/\nhttps://review.openstack.org/#/c/42456/\n\nblueprint heat-trusts\n\nChange-Id: I288114d827481bc0a24eba4556400d98b1a44c09\n'}, {'number': 3, 'created': '2013-08-29 16:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ff38ab4331f1b4c806242d652ce76a0f8008b276', 'message': 'Migrate stored credentials to keystone trusts\n\nMigrate the stored user_creds, which currently only supports\nstoring username/password credentials to use the keystone v3\nAPI OS-TRUST extension, which allows explicit impersonation of\nusers calling heat (trustors) by the heat service user (the\ntrustee)\n\nNote this feature is made optional via a new config option,\ndefaulted to off, and it requires the following patches to\nkeystoneclient (in 0.3.2 release) and keystone to work:\n\nhttps://review.openstack.org/#/c/39899/\nhttps://review.openstack.org/#/c/42456/\n\nblueprint heat-trusts\n\nChange-Id: I288114d827481bc0a24eba4556400d98b1a44c09\n'}, {'number': 4, 'created': '2013-08-30 17:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/404f4ce925805f8ec2efb2a53c8bf58f18bcb398', 'message': 'Migrate stored credentials to keystone trusts\n\nMigrate the stored user_creds, which currently only supports\nstoring username/password credentials to use the keystone v3\nAPI OS-TRUST extension, which allows explicit impersonation of\nusers calling heat (trustors) by the heat service user (the\ntrustee)\n\nNote this feature is made optional via a new config option,\ndefaulted to off, and it requires the following patches to\nkeystoneclient (in 0.3.2 release) and keystone to work:\n\nhttps://review.openstack.org/#/c/39899/\nhttps://review.openstack.org/#/c/42456/\n\nblueprint heat-trusts\n\nChange-Id: I288114d827481bc0a24eba4556400d98b1a44c09\n'}, {'number': 5, 'created': '2013-09-02 21:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6ebfd523b38a75dab205019459b72b77fbd6a712', 'message': 'Migrate stored credentials to keystone trusts\n\nMigrate the stored user_creds, which currently only supports\nstoring username/password credentials to use the keystone v3\nAPI OS-TRUST extension, which allows explicit impersonation of\nusers calling heat (trustors) by the heat service user (the\ntrustee)\n\nNote this feature is made optional via a new config option,\ndefaulted to off, and it requires the following patches to\nkeystoneclient (in 0.3.2 release) and keystone to work:\n\nhttps://review.openstack.org/#/c/39899/\nhttps://review.openstack.org/#/c/42456/\n\nblueprint heat-trusts\n\nChange-Id: I288114d827481bc0a24eba4556400d98b1a44c09\n'}, {'number': 6, 'created': '2013-09-02 22:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8cdf373dde1aba33ac8fc54160d86486df301515', 'message': 'Migrate stored credentials to keystone trusts\n\nMigrate the stored user_creds, which currently only supports\nstoring username/password credentials to use the keystone v3\nAPI OS-TRUST extension, which allows explicit impersonation of\nusers calling heat (trustors) by the heat service user (the\ntrustee)\n\nNote this feature is made optional via a new config option,\ndefaulted to off, and it requires the following patches to\nkeystoneclient (in 0.3.2 release) and keystone to work:\n\nhttps://review.openstack.org/#/c/39899/\nhttps://review.openstack.org/#/c/42456/\n\nblueprint heat-trusts\n\nChange-Id: I288114d827481bc0a24eba4556400d98b1a44c09\n'}, {'number': 7, 'created': '2013-09-02 22:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aafb04eed39b00125020a930073a4b21342e89a5', 'message': 'Migrate stored credentials to keystone trusts\n\nMigrate the stored user_creds, which currently only supports\nstoring username/password credentials to use the keystone v3\nAPI OS-TRUST extension, which allows explicit impersonation of\nusers calling heat (trustors) by the heat service user (the\ntrustee)\n\nNote this feature is made optional via a new config option,\ndefaulted to off, and it requires the following patches to\nkeystoneclient (in 0.3.2 release) and keystone to work:\n\nhttps://review.openstack.org/#/c/39899/\nhttps://review.openstack.org/#/c/42456/\n\nblueprint heat-trusts\n\nChange-Id: I288114d827481bc0a24eba4556400d98b1a44c09\n'}, {'number': 8, 'created': '2013-09-03 19:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7010e57e5ae642184e923a3ad1a2d25d7165faa0', 'message': 'Migrate stored credentials to keystone trusts\n\nMigrate the stored user_creds, which currently only supports\nstoring username/password credentials to use the keystone v3\nAPI OS-TRUST extension, which allows explicit impersonation of\nusers calling heat (trustors) by the heat service user (the\ntrustee)\n\nNote this feature is made optional via a new config option,\ndefaulted to off, and it requires the following patches to\nkeystoneclient (in 0.3.2 release) and keystone to work:\n\nhttps://review.openstack.org/#/c/39899/\nhttps://review.openstack.org/#/c/42456/\n\nAlso note that if the feature is enabled, by setting\ndeferred_auth_method=trusts in heat.conf, you must add\na keystone_authtoken section, which is also used by the\nkeystoneclient auth_token middleware.\n\nblueprint heat-trusts\n\nChange-Id: I288114d827481bc0a24eba4556400d98b1a44c09\n'}, {'number': 9, 'created': '2013-09-03 22:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ea611d9abbea5c6f018eac4c5bab09e6850a5670', 'message': 'Migrate stored credentials to keystone trusts\n\nMigrate the stored user_creds, which currently only supports\nstoring username/password credentials to use the keystone v3\nAPI OS-TRUST extension, which allows explicit impersonation of\nusers calling heat (trustors) by the heat service user (the\ntrustee)\n\nNote this feature is made optional via a new config option,\ndefaulted to off, and it requires the following patches to\nkeystoneclient (in 0.3.2 release) and keystone to work:\n\nhttps://review.openstack.org/#/c/39899/\nhttps://review.openstack.org/#/c/42456/\n\nAlso note that if the feature is enabled, by setting\ndeferred_auth_method=trusts in heat.conf, you must add\na keystone_authtoken section, which is also used by the\nkeystoneclient auth_token middleware.\n\nblueprint heat-trusts\n\nChange-Id: I288114d827481bc0a24eba4556400d98b1a44c09\n'}, {'number': 10, 'created': '2013-09-03 23:13:22.000000000', 'files': ['heat/tests/test_signal.py', 'heat/tests/fakes.py', 'heat/engine/service.py', 'heat/tests/test_metadata_refresh.py', 'etc/heat/heat.conf.sample', 'heat/tests/test_engine_service.py', 'heat/tests/utils.py', 'requirements.txt', 'heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py', 'heat/common/config.py', 'heat/tests/test_ceilometer_alarm.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e686699b00ee2ca190946261677d89641707e6c6', 'message': 'Migrate stored credentials to keystone trusts\n\nMigrate the stored user_creds, which currently only supports\nstoring username/password credentials to use the keystone v3\nAPI OS-TRUST extension, which allows explicit impersonation of\nusers calling heat (trustors) by the heat service user (the\ntrustee)\n\nNote this feature is made optional via a new config option,\ndefaulted to off, and it requires the following patches to\nkeystoneclient (in 0.3.2 release) and keystone to work:\n\nhttps://review.openstack.org/#/c/39899/\nhttps://review.openstack.org/#/c/42456/\n\nAlso note that if the feature is enabled, by setting\ndeferred_auth_method=trusts in heat.conf, you must add\na keystone_authtoken section, which is also used by the\nkeystoneclient auth_token middleware.\n\nblueprint heat-trusts\n\nChange-Id: I288114d827481bc0a24eba4556400d98b1a44c09\n'}]",38,43380,e686699b00ee2ca190946261677d89641707e6c6,51,9,10,4328,,,0,"Migrate stored credentials to keystone trusts

Migrate the stored user_creds, which currently only supports
storing username/password credentials to use the keystone v3
API OS-TRUST extension, which allows explicit impersonation of
users calling heat (trustors) by the heat service user (the
trustee)

Note this feature is made optional via a new config option,
defaulted to off, and it requires the following patches to
keystoneclient (in 0.3.2 release) and keystone to work:

https://review.openstack.org/#/c/39899/
https://review.openstack.org/#/c/42456/

Also note that if the feature is enabled, by setting
deferred_auth_method=trusts in heat.conf, you must add
a keystone_authtoken section, which is also used by the
keystoneclient auth_token middleware.

blueprint heat-trusts

Change-Id: I288114d827481bc0a24eba4556400d98b1a44c09
",git fetch https://review.opendev.org/openstack/heat refs/changes/80/43380/4 && git format-patch -1 --stdout FETCH_HEAD,"['etc/heat/heat.conf.sample', 'heat/engine/parser.py', 'heat/common/context.py', 'heat/db/sqlalchemy/migrate_repo/versions/024_user_creds_trusts.py', 'heat/common/heat_keystoneclient.py', 'heat/db/sqlalchemy/api.py', 'heat/db/sqlalchemy/models.py', 'heat/common/config.py', 'heat/engine/service.py']",9,6ee3cf1dfc4db4642d6feb9af9a12cd40985239b,bp/heat-trusts3,"from heat.common import heat_keystoneclient as hkc stack_context = self._load_user_creds(s.user_creds_id) def _load_user_creds(self, creds_id): user_creds = db_api.user_creds_get(creds_id) stored_context = context.RequestContext.from_dict(user_creds) kc = hkc.KeystoneClient(stored_context) return kc.trust_context() stack_context = self._load_user_creds(s.user_creds_id) stack_context = self._load_user_creds(stack.user_creds_id)", user_creds = db_api.user_creds_get(s.user_creds_id) stack_context = context.RequestContext.from_dict(user_creds) user_creds = db_api.user_creds_get(s.user_creds_id) stack_context = context.RequestContext.from_dict(user_creds) user_creds = db_api.user_creds_get(stack.user_creds_id) stack_context = context.RequestContext.from_dict(user_creds),270,35
openstack%2Fglance~master~Ice1de4d1c61a62fff778acbbeb9bc27d03ed7ab4,openstack/glance,master,Ice1de4d1c61a62fff778acbbeb9bc27d03ed7ab4,Clean up data when store receiving image occurs error,MERGED,2013-08-20 13:47:41.000000000,2013-09-04 15:25:14.000000000,2013-09-04 15:25:14.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 6159}, {'_account_id': 6493}, {'_account_id': 6549}]","[{'number': 1, 'created': '2013-08-20 13:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/92e7bea341a045150727008f95343daa5541716f', 'message': 'Clean up data when store receiving image occurs error\n\nClean up already received data from backend store to prevent potential\nleaking when driver receiving image occurs error such as\nImageSizeLimitExceeded exception.\n\nFixes bug: 1214276\n\nChange-Id: Ice1de4d1c61a62fff778acbbeb9bc27d03ed7ab4\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2013-08-21 09:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/335804874f1371084e1cd281110893f0b210cba5', 'message': 'Clean up data when store receiving image occurs error\n\nClean up already received data from backend store to prevent potential\nleaking when driver receiving image occurs error such as\nImageSizeLimitExceeded exception.\n\nFixes bug: 1214276\n\nChange-Id: Ice1de4d1c61a62fff778acbbeb9bc27d03ed7ab4\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 3, 'created': '2013-08-21 10:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d09ca562150d74ed0a9efb84059928bee75bf9cd', 'message': 'Clean up data when store receiving image occurs error\n\nClean up already received data from backend store to prevent potential\nleaking when driver receiving image occurs error such as\nImageSizeLimitExceeded exception.\n\nFixes bug: 1214276\n\nChange-Id: Ice1de4d1c61a62fff778acbbeb9bc27d03ed7ab4\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 4, 'created': '2013-08-21 16:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e0a43bbc377ab6ae8dad2ac133e6545dca06d77f', 'message': 'Clean up data when store receiving image occurs error\n\nClean up already received data from backend store to prevent potential\nleaking when driver receiving image occurs error such as\nImageSizeLimitExceeded exception.\n\nFixes bug: 1214276\n\nChange-Id: Ice1de4d1c61a62fff778acbbeb9bc27d03ed7ab4\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 6, 'created': '2013-08-28 05:01:57.000000000', 'files': ['glance/store/gridfs.py', 'glance/tests/unit/test_gridfs_store.py', 'glance/store/sheepdog.py', 'glance/tests/unit/test_rbd_store.py', 'glance/tests/unit/test_sheepdog_store.py', 'glance/store/rbd.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/436c2569551b4c8cab04e1cb32591cd32ea67d16', 'message': 'Clean up data when store receiving image occurs error\n\nClean up already received data from backend store to prevent potential\nleaking when driver receiving image occurs error such as\nImageSizeLimitExceeded exception.\n\nFixes bug: 1214276\n\nChange-Id: Ice1de4d1c61a62fff778acbbeb9bc27d03ed7ab4\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 5, 'created': '2013-08-28 05:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5f8449b1928dedc60067f4866e06a1f30f05a51a', 'message': 'Clean up data when store receiving image occurs error\n\nClean up already received data from backend store to prevent potential\nleaking when driver receiving image occurs error such as\nImageSizeLimitExceeded exception.\n\nFixes bug: 1214276\n\nChange-Id: Ice1de4d1c61a62fff778acbbeb9bc27d03ed7ab4\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}]",0,42896,436c2569551b4c8cab04e1cb32591cd32ea67d16,39,6,6,6549,,,0,"Clean up data when store receiving image occurs error

Clean up already received data from backend store to prevent potential
leaking when driver receiving image occurs error such as
ImageSizeLimitExceeded exception.

Fixes bug: 1214276

Change-Id: Ice1de4d1c61a62fff778acbbeb9bc27d03ed7ab4
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/96/42896/6 && git format-patch -1 --stdout FETCH_HEAD,"['glance/store/gridfs.py', 'glance/store/sheepdog.py', 'glance/store/rbd.py']",3,92e7bea341a045150727008f95343daa5541716f,," def _create_image(self, fsid, ioctx, image_name, size, order): :param image_name Image's name librbd.create(ioctx, image_name, size, order, old_format=False, 'image': image_name, librbd.create(ioctx, image_name, size, order, old_format=True) return StoreLocation({'image': image_name}) def _delete_image(self, image_name, snapshot_name): """""" Find the image file to delete. :param image_name Image's name :param snapshot_name Image snapshot's name :raises NotFound if image does not exist; InUseByStore if image is in use or snapshot unprotect failed """""" with rados.Rados(conffile=self.conf_file, rados_id=self.user) as conn: with conn.open_ioctx(self.pool) as ioctx: if snapshot_name: with rbd.Image(ioctx, image_name) as image: try: image.unprotect_snap(snapshot_name) except rbd.ImageBusy: log_msg = _(""snapshot %s@%s could not be "" ""unprotected because it is in use"") LOG.debug(log_msg % (image_name, snapshot_name)) raise exception.InUseByStore() image.remove_snap(snapshot_name) try: rbd.RBD().remove(ioctx, image_name) except rbd.ImageNotFound: raise exception.NotFound( _(""RBD image %s does not exist"") % image_name) except rbd.ImageBusy: log_msg = _(""image %s could not be removed "" ""because it is in use"") LOG.debug(log_msg % image_name) raise exception.InUseByStore() LOG.debug('creating image %s with order %d', image_name, order) try: loc = self._create_image(fsid, ioctx, image_name, image_size, order) try: with rbd.Image(ioctx, image_name) as image: offset = 0 chunks = utils.chunkreadable(image_file, self.chunk_size) for chunk in chunks: offset += image.write(chunk, offset) checksum.update(chunk) if loc.snapshot: image.create_snap(loc.snapshot) image.protect_snap(loc.snapshot) except: # Note(zhiyan): clean up already received data when # error occurs such as ImageSizeLimitExceeded exception. try: self._delete_image(loc.image, loc.snapshot) except: pass raise return (loc.get_uri(), image_size, checksum.hexdigest(), {}) where to find the image file to delete. :raises NotFound if image does not exist; InUseByStore if image is in use or snapshot unprotect failed self._delete_image(loc.image, loc.snapshot)"," def _create_image(self, fsid, ioctx, name, size, order): librbd.create(ioctx, name, size, order, old_format=False, 'image': name, librbd.create(ioctx, name, size, order, old_format=True) return StoreLocation({'image': name}) LOG.debug('creating image %s with order %d', image_name, order) try: location = self._create_image(fsid, ioctx, image_name, image_size, order) with rbd.Image(ioctx, image_name) as image: offset = 0 chunks = utils.chunkreadable(image_file, self.chunk_size) for chunk in chunks: offset += image.write(chunk, offset) checksum.update(chunk) if location.snapshot: image.create_snap(location.snapshot) image.protect_snap(location.snapshot) return (location.get_uri(), image_size, checksum.hexdigest(), {}) where to find the image file to delete :raises NotFound if image does not exist with rados.Rados(conffile=self.conf_file, rados_id=self.user) as conn: with conn.open_ioctx(self.pool) as ioctx: if loc.snapshot: with rbd.Image(ioctx, loc.image) as image: try: image.unprotect_snap(loc.snapshot) except rbd.ImageBusy: log_msg = _(""snapshot %s@%s could not be "" ""unprotected because it is in use"") LOG.debug(log_msg % (loc.image, loc.snapshot)) raise exception.InUseByStore() image.remove_snap(loc.snapshot) try: rbd.RBD().remove(ioctx, loc.image) except rbd.ImageNotFound: raise exception.NotFound( _('RBD image %s does not exist') % loc.image) except rbd.ImageBusy: log_msg = _(""image %s could not be removed"" ""because it is in use"") LOG.debug(log_msg % loc.image) raise exception.InUseByStore()",94,53
openstack%2Fglance~master~I050ff212d73ace8e84dcd800245b608210d6b29a,openstack/glance,master,I050ff212d73ace8e84dcd800245b608210d6b29a,Scrubber refactoring,MERGED,2013-07-30 15:08:37.000000000,2013-09-04 15:25:12.000000000,2013-09-04 15:25:12.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2166}, {'_account_id': 6484}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 7491}]","[{'number': 1, 'created': '2013-07-30 15:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b90dcdb116a1f3652c0320aef94e1869317fb455', 'message': 'Scrubber refactoring\n\n* Adding lock protection to prevent race condition between glance-api\nand glance-scrubber service.\n* Adding multiple locations image support.\n\nImplement bp: glance-scrubber-refactoring\n\nChange-Id: I050ff212d73ace8e84dcd800245b608210d6b29a\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2013-08-16 08:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/78c8fb987a7c7c0fac585e660a61022fbfac7f18', 'message': 'Scrubber refactoring\n\n* Adding multiple locations image support.\n* Adding lock protection to prevent race condition between glance-api\nand glance-scrubber service.\n\nImplement bp: glance-scrubber-refactoring\n\nChange-Id: I050ff212d73ace8e84dcd800245b608210d6b29a\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 3, 'created': '2013-08-19 07:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c0f249e00fcfa86e50ce520cc814215fdb2b15ac', 'message': 'Scrubber refactoring\n\n* Adding multiple locations image support.\n* Adding lock protection to prevent race condition between glance-api\nand glance-scrubber service.\n\nImplement bp: glance-scrubber-refactoring\n\nChange-Id: I050ff212d73ace8e84dcd800245b608210d6b29a\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 4, 'created': '2013-08-19 07:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4f30d050b77b85dd8affa6421af5edb4da6f1cf0', 'message': 'Scrubber refactoring\n\n* Adding multiple locations image support.\n* Adding lock protection to prevent race condition between glance-api\nand glance-scrubber service.\n\nImplement bp: glance-scrubber-refactoring\n\nChange-Id: I050ff212d73ace8e84dcd800245b608210d6b29a\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 6, 'created': '2013-08-22 04:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/dd616a7d123bbfff53595c03ac8c0189050c6722', 'message': 'Scrubber refactoring\n\n* Adding multiple locations image support.\n* Adding lock protection to prevent race condition between glance-api\nand glance-scrubber service.\n\nImplement bp: glance-scrubber-refactoring\n\nChange-Id: I050ff212d73ace8e84dcd800245b608210d6b29a\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 5, 'created': '2013-08-22 04:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/80c0cd62b42b87da4122d220fda0eb4fd3518c8a', 'message': 'Scrubber refactoring\n\n* Adding multiple locations image support.\n* Adding lock protection to prevent race condition between glance-api\nand glance-scrubber service.\n\nImplement bp: glance-scrubber-refactoring\n\nChange-Id: I050ff212d73ace8e84dcd800245b608210d6b29a\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 7, 'created': '2013-08-29 11:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b7cd9469fe78a9893444bf79f3566a3190992d44', 'message': 'Scrubber refactoring\n\n* Adding multiple locations image support.\n* Adding lock protection to prevent race condition between glance-api\nand glance-scrubber service.\n* Refactoring scrub queue code.\n\nImplement bp: glance-scrubber-refactoring\n\nChange-Id: I050ff212d73ace8e84dcd800245b608210d6b29a\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 8, 'created': '2013-08-29 11:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5a996a07b3b0f4d1c1b7da0fcf9dd2ac633e0692', 'message': 'Scrubber refactoring\n\n* Adding multiple locations image support.\n* Adding lock protection to prevent race condition between glance-api\nand glance-scrubber service.\n* Refactoring scrub queue code.\n\nImplement bp: glance-scrubber-refactoring\n\nChange-Id: I050ff212d73ace8e84dcd800245b608210d6b29a\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 9, 'created': '2013-08-30 09:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a20b4b5b7400110153a400a27336f222133dce58', 'message': 'Scrubber refactoring\n\n* Adding multiple locations image support.\n* Adding lock protection to prevent race condition between glance-api\nand glance-scrubber service.\n* Refactoring scrub queue code.\n\nImplement bp: glance-scrubber-refactoring\n\nChange-Id: I050ff212d73ace8e84dcd800245b608210d6b29a\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 10, 'created': '2013-09-04 03:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c05cc6b7c83fa42b012949260b26e90c8013b99f', 'message': 'Scrubber refactoring\n\n* Adding multiple locations image support.\n* Adding lock protection to prevent race condition between glance-api\nand glance-scrubber service.\n* Refactoring scrub queue code.\n\nImplement bp: glance-scrubber-refactoring\n\nChange-Id: I050ff212d73ace8e84dcd800245b608210d6b29a\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 11, 'created': '2013-09-04 04:37:18.000000000', 'files': ['glance/store/__init__.py', 'glance/store/scrubber.py', 'glance/tests/unit/v1/test_upload_utils.py', 'glance/api/v1/upload_utils.py', 'glance/tests/unit/test_http_store.py', 'glance/tests/unit/utils.py', 'etc/glance-api.conf', 'glance/cmd/scrubber.py', 'glance/api/v1/images.py', 'glance/openstack/common/lockutils.py', 'glance/tests/functional/__init__.py', 'glance/tests/unit/base.py', 'etc/glance-scrubber.conf', 'openstack-common.conf', 'glance/tests/unit/test_scrubber.py', 'glance/openstack/common/fileutils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/85075f4b116e485fa0bc9a9d28a6c1901bf7c703', 'message': 'Scrubber refactoring\n\n* Adding multiple locations image support.\n* Adding lock protection to prevent race condition between glance-api\nand glance-scrubber service.\n* Refactoring scrub queue code.\n\nImplement bp: glance-scrubber-refactoring\ndocImpact\n\nChange-Id: I050ff212d73ace8e84dcd800245b608210d6b29a\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}]",48,39309,85075f4b116e485fa0bc9a9d28a6c1901bf7c703,71,7,11,6549,,,0,"Scrubber refactoring

* Adding multiple locations image support.
* Adding lock protection to prevent race condition between glance-api
and glance-scrubber service.
* Refactoring scrub queue code.

Implement bp: glance-scrubber-refactoring
docImpact

Change-Id: I050ff212d73ace8e84dcd800245b608210d6b29a
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/09/39309/6 && git format-patch -1 --stdout FETCH_HEAD,"['glance/store/__init__.py', 'glance/store/scrubber.py', 'glance/tests/unit/v1/test_upload_utils.py', 'glance/api/v1/upload_utils.py', 'glance/tests/unit/utils.py', 'etc/glance-api.conf', 'glance/api/v1/images.py', 'glance/openstack/common/lockutils.py', 'glance/tests/functional/__init__.py', 'glance/tests/unit/base.py', 'etc/glance-scrubber.conf', 'openstack-common.conf', 'glance/openstack/common/fileutils.py']",13,b90dcdb116a1f3652c0320aef94e1869317fb455,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import contextlib import errno import os from glance.openstack.common import excutils from glance.openstack.common.gettextutils import _ # noqa from glance.openstack.common import log as logging LOG = logging.getLogger(__name__) _FILE_CACHE = {} def ensure_tree(path): """"""Create a directory (and any ancestor directories required) :param path: Directory to create """""" try: os.makedirs(path) except OSError as exc: if exc.errno == errno.EEXIST: if not os.path.isdir(path): raise else: raise def read_cached_file(filename, force_reload=False): """"""Read from a file if it has been modified. :param force_reload: Whether to reload the file. :returns: A tuple with a boolean specifying if the data is fresh or not. """""" global _FILE_CACHE if force_reload and filename in _FILE_CACHE: del _FILE_CACHE[filename] reloaded = False mtime = os.path.getmtime(filename) cache_info = _FILE_CACHE.setdefault(filename, {}) if not cache_info or mtime > cache_info.get('mtime', 0): LOG.debug(_(""Reloading cached file %s"") % filename) with open(filename) as fap: cache_info['data'] = fap.read() cache_info['mtime'] = mtime reloaded = True return (reloaded, cache_info['data']) def delete_if_exists(path): """"""Delete a file, but ignore file not found error. :param path: File to delete """""" try: os.unlink(path) except OSError as e: if e.errno == errno.ENOENT: return else: raise @contextlib.contextmanager def remove_path_on_error(path): """"""Protect code that wants to operate on PATH atomically. Any exception will cause PATH to be removed. :param path: File to work with """""" try: yield except Exception: with excutils.save_and_reraise_exception(): delete_if_exists(path) def file_open(*args, **kwargs): """"""Open file see built-in file() documentation for more details Note: The reason this is kept in a separate module is to easily be able to provide a stub module that doesn't alter system state at all (for unit tests) """""" return file(*args, **kwargs) ",,536,70
openstack%2Fnova~master~I903067476049ead01c6c34392342d915917790b3,openstack/nova,master,I903067476049ead01c6c34392342d915917790b3,Powervm driver now logs ssh stderr to warning,MERGED,2013-08-26 04:57:29.000000000,2013-09-04 15:24:44.000000000,2013-09-04 15:24:41.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 7069}, {'_account_id': 8570}]","[{'number': 1, 'created': '2013-08-26 04:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd0aa2564b0670866177e044bdfffc138c968717', 'message': 'bug 1215019\nchanged run remote ssh commands stderr logging from debug level to warning\nlevel\n\nChange-Id: I903067476049ead01c6c34392342d915917790b3\n'}, {'number': 2, 'created': '2013-08-27 01:22:21.000000000', 'files': ['nova/virt/powervm/blockdev.py', 'nova/virt/powervm/operator.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/43e102cc215aabc72a0ef84cf48965c4db2d58d4', 'message': 'Powervm driver now logs ssh stderr to warning\n\nThe run_vios_command, run_vios_command_as_root methods in\nblockdevice.py and operator.py of powervm driver currently log\nstderr at debug level, this commit changed it to log to warning\nlevel rather than debug.\n\nCloses-Bug: #1215019\nChange-Id: I903067476049ead01c6c34392342d915917790b3\n'}]",2,43651,43e102cc215aabc72a0ef84cf48965c4db2d58d4,19,8,2,8570,,,0,"Powervm driver now logs ssh stderr to warning

The run_vios_command, run_vios_command_as_root methods in
blockdevice.py and operator.py of powervm driver currently log
stderr at debug level, this commit changed it to log to warning
level rather than debug.

Closes-Bug: #1215019
Change-Id: I903067476049ead01c6c34392342d915917790b3
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/43651/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/powervm/blockdev.py', 'nova/virt/powervm/operator.py']",2,dd0aa2564b0670866177e044bdfffc138c968717,bug/1215019," LOG.warn(_(""Found error stream for command \""%(cmd)s\"": "" LOG.warn(_(""Found error stream for command \""%(command)s\"":"""," LOG.debug(_(""Found error stream for command \""%(cmd)s\"": "" LOG.debug(_(""Found error stream for command \""%(command)s\"":""",4,4
openstack%2Fkeystone~master~If5b4f9f28cb9d05f914848cbdb54b10c2c5f3b2d,openstack/keystone,master,If5b4f9f28cb9d05f914848cbdb54b10c2c5f3b2d,Update keystone wsgi httpd script for oslo logging,MERGED,2013-09-03 00:11:32.000000000,2013-09-04 15:24:12.000000000,2013-09-04 15:24:12.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-09-03 00:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5f840534004e6b4a172332017723e1d6a8e04365', 'message': 'Update keystone wsgi httpd script for oslo logging\n\nWhen updating to the oslo logging module, it appears that this script\nwas missed, and erroneously still references .DEBUG, which is not\navailable in the oslo logging module.  This commit corrects the issue\nand updates the reference to oslo log module to not be aliased to\n""logging"".\n\nThe extra logic to set the debug on the instantiated logger is still\nneeded to ensure all logging is seen (startup config logging, etc).\n\nfixes-bug: 1220012\nChange-Id: If5b4f9f28cb9d05f914848cbdb54b10c2c5f3b2d\n'}, {'number': 2, 'created': '2013-09-03 03:49:14.000000000', 'files': ['httpd/keystone.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d98dca9f983e8fbee21d874c22170952f7d781c2', 'message': 'Update keystone wsgi httpd script for oslo logging\n\nWhen updating to the oslo logging module, it appears that this script\nwas missed, and erroneously still references .DEBUG, which is not\navailable in the oslo logging module.  This commit corrects the issue\nand updates the reference to oslo log module to not be aliased to\n""logging"".\n\nThe extra logic to set the debug on the instantiated logger is still\nneeded to ensure all logging is seen (startup config logging, etc).\n\nfixes-bug: 1220012\nChange-Id: If5b4f9f28cb9d05f914848cbdb54b10c2c5f3b2d\n'}]",7,44776,d98dca9f983e8fbee21d874c22170952f7d781c2,21,7,2,2903,,,0,"Update keystone wsgi httpd script for oslo logging

When updating to the oslo logging module, it appears that this script
was missed, and erroneously still references .DEBUG, which is not
available in the oslo logging module.  This commit corrects the issue
and updates the reference to oslo log module to not be aliased to
""logging"".

The extra logic to set the debug on the instantiated logger is still
needed to ensure all logging is seen (startup config logging, etc).

fixes-bug: 1220012
Change-Id: If5b4f9f28cb9d05f914848cbdb54b10c2c5f3b2d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/76/44776/1 && git format-patch -1 --stdout FETCH_HEAD,['httpd/keystone.py'],1,5f840534004e6b4a172332017723e1d6a8e04365,bug/1220012,"import loggingfrom keystone.openstack.common import log LOG = log.getLogger(__name__) CONF.log_opt_values(log.getLogger(CONF.prog), logging.DEBUG)","from keystone.openstack.common import log as logging LOG = logging.getLogger(__name__) CONF.log_opt_values(logging.getLogger(CONF.prog), logging.DEBUG)",4,3
openstack%2Fcinder~master~I4a7f0c1bc08d88b0f75d119168dd2077487a62a0,openstack/cinder,master,I4a7f0c1bc08d88b0f75d119168dd2077487a62a0,QEMU-assisted-snapshots for GlusterFS volumes,MERGED,2013-08-19 02:32:38.000000000,2013-09-04 15:22:38.000000000,2013-09-04 15:22:37.000000000,"[{'_account_id': 3}, {'_account_id': 1330}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 6604}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-08-19 02:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7aba9a646b138092f4a592ef2611bfb7228d5956', 'message': ""Guest-assisted-snapshots for GlusterFS volumes\n\nNote: this still requires integration with Novaclient to\nbe complete\n\nCoordinate with Nova to create and delete snaphots online for\nGlusterFS volumes.\n\nCinder is responsible for creating a qcow2 file which Nova\nwill activate in the VM's snapshot chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 2, 'created': '2013-08-19 04:53:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/06568d16b3645cbc3e17b4530967febae5345227', 'message': ""Guest-assisted-snapshots for GlusterFS volumes\n\nNote: this still requires integration with Novaclient to\nbe complete\n\nCoordinate with Nova to create and delete snaphots online for\nGlusterFS volumes.\n\nCinder is responsible for creating a qcow2 file which Nova\nwill activate in the VM's snapshot chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 3, 'created': '2013-08-19 05:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8dde40fab9965fe879abdf8d1feecabb2cfc692a', 'message': ""Guest-assisted-snapshots for GlusterFS volumes\n\nNote: this still requires integration with Novaclient to\nbe complete\n\nCoordinate with Nova to create and delete snaphots online for\nGlusterFS volumes.\n\nCinder is responsible for creating a qcow2 file which Nova\nwill activate in the VM's snapshot chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 4, 'created': '2013-08-20 18:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/315d9d9558cb3824802170ba5da01f8164f06c20', 'message': ""Guest-assisted-snapshots for GlusterFS volumes\n\nNote: this still requires integration with Novaclient to\nbe complete\n\nCoordinate with Nova to create and delete snaphots online for\nGlusterFS volumes.\n\nCinder is responsible for creating a qcow2 file which Nova\nwill activate in the VM's snapshot chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 5, 'created': '2013-08-20 21:40:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c6e30c5ec48e41d1bb8a4fe72d127a9690c8a19', 'message': ""Guest-assisted-snapshots for GlusterFS volumes\n\nNote: this still requires integration with Novaclient to\nbe complete\n\nCoordinate with Nova to create and delete snaphots online for\nGlusterFS volumes.\n\nCinder is responsible for creating a qcow2 file which Nova\nwill activate in the VM's snapshot chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 6, 'created': '2013-08-21 19:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/45356d7d9039ced15886a9657620db14727d2bf5', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 7, 'created': '2013-08-26 00:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c5f253ee245cde539a2984b5be7bfe7dd173f2bf', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 8, 'created': '2013-08-26 16:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/47327a70036f352487a3edb0fa39463818b16d09', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 9, 'created': '2013-08-27 18:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cbcd3e0e99dde9a22072b81eff93e0014ab05407', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 10, 'created': '2013-08-27 19:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2d3ddfd77cffa3334d85fd9ff459b3358acc579a', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 11, 'created': '2013-08-27 19:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b2c196187aabda4799c489f81535c45da8effdef', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 13, 'created': '2013-08-31 19:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/72ebe0d300193ee5ef1ed6606d1caace1d514b80', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 12, 'created': '2013-08-31 19:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/731a91ac2559b781ab708ba2ffae572337c31418', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 14, 'created': '2013-09-02 16:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d05760c29e55cd0a57795eead1d5e5c0b4585786', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 15, 'created': '2013-09-02 18:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f713effb1c8785e1ac05edd4378b96939ca5ff01', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 16, 'created': '2013-09-03 12:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c6cd0a4a664896d1944cc9fe6427a8e8b5749c71', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}, {'number': 17, 'created': '2013-09-04 03:52:50.000000000', 'files': ['cinder/volume/manager.py', 'cinder/volume/drivers/glusterfs.py', 'etc/cinder/cinder.conf.sample', 'cinder/compute/nova.py', 'cinder/tests/compute/test_nova.py', 'cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/03a41f863b160384593ef8df130f369a0c22d393', 'message': ""QEMU-assisted-snapshots for GlusterFS volumes\n\nCoordinate with Nova to create and delete snaphots for\nGlusterFS volumes that are attached to VMs.\n\nCinder is responsible for creating a QCOW2 file which Nova\nwill activate in the VM's snapshot chain when a snapshot is\ncreated.\n\nWhen a snapshot is deleted, Cinder will request for Nova to\nperform a block commit/rebase operation to logically delete\nthe snapshot from the QCOW2 chain.\n\nImplements blueprint qemu-assisted-snapshots\n\nChange-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0\n""}]",41,42552,03a41f863b160384593ef8df130f369a0c22d393,80,10,17,4523,,,0,"QEMU-assisted-snapshots for GlusterFS volumes

Coordinate with Nova to create and delete snaphots for
GlusterFS volumes that are attached to VMs.

Cinder is responsible for creating a QCOW2 file which Nova
will activate in the VM's snapshot chain when a snapshot is
created.

When a snapshot is deleted, Cinder will request for Nova to
perform a block commit/rebase operation to logically delete
the snapshot from the QCOW2 chain.

Implements blueprint qemu-assisted-snapshots

Change-Id: I4a7f0c1bc08d88b0f75d119168dd2077487a62a0
",git fetch https://review.opendev.org/openstack/cinder refs/changes/52/42552/5 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/glusterfs.py', 'cinder/volume/manager.py']",2,7aba9a646b138092f4a592ef2611bfb7228d5956,bp/qemu-assisted-snapshots," caller_context = context # Pass context so that drivers that want to use it, can, # but it is not a requirement for all drivers. snapshot_ref['context'] = caller_context caller_context = context # Pass context so that drivers that want to use it, can, # but it is not a requirement for all drivers. snapshot_ref['context'] = caller_context",,118,30
openstack%2Fpython-keystoneclient~master~I7355cdf533800086027824fb729eb52cdd8bbc33,openstack/python-keystoneclient,master,I7355cdf533800086027824fb729eb52cdd8bbc33,Deprecation warning for the CLI,MERGED,2013-09-03 15:53:01.000000000,2013-09-04 15:22:36.000000000,2013-09-04 15:22:36.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2013-09-03 15:53:01.000000000', 'files': ['keystoneclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/661d6cf783d1586e435196f38ffb1b2361b8fe25', 'message': ""Deprecation warning for the CLI\n\nkeystoneclient/shell.py's docstr is rendered by argparse as the\ndescription for:\n\n    $ keystone --help\n\nChange-Id: I7355cdf533800086027824fb729eb52cdd8bbc33\n""}]",0,44910,661d6cf783d1586e435196f38ffb1b2361b8fe25,9,5,1,4,,,0,"Deprecation warning for the CLI

keystoneclient/shell.py's docstr is rendered by argparse as the
description for:

    $ keystone --help

Change-Id: I7355cdf533800086027824fb729eb52cdd8bbc33
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/10/44910/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/shell.py'],1,661d6cf783d1586e435196f38ffb1b2361b8fe25,(detached,"DEPRECATED: Command-line interface to the OpenStack Identity API. For a CLI, use python-openstackclient instead. For a Python library, continue using python-keystoneclient. ",Command-line interface to the OpenStack Identity API.,5,1
openstack%2Fopenstack-manuals~master~I2ed6f80beb109c60bd7f0ca2417426f776383973,openstack/openstack-manuals,master,I2ed6f80beb109c60bd7f0ca2417426f776383973,added parameters to control the behaviour,MERGED,2013-08-15 15:30:34.000000000,2013-09-04 15:18:48.000000000,2013-09-04 15:18:48.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 321}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-08-15 15:30:34.000000000', 'files': ['tools/test.py'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/03e400ba70d4bbc01c5e6b3c78becbfaebbac548', 'message': ""added parameters to control the behaviour\n\ntest.py is a modified copy of validate.py. I introduced a new\nname to not cause race conditions with the existing Jenkins\njob which actually uses validate.py.\n\nThis patch introduces the following new parameters and changes\nthe default behaviour of the script. By default the script will\ndo nothing.\n\n--check-build: With this parameter the script tries to build\n               all books affected by modified files.\n\n--check-syntax: With this parameter the script checks if modified\n                files are still using valid XML syntax.\n\n--with-niceness: Using this parameter together with --check-syntax\n                 will also check the syntax for niceness issues (for\n                 example trailing whitespaces).\n\n--non-voting: With this parameter set the script always returns 0\n              as exit code.\n\nPossible Jenkins jobs:\n\n./tools/test.py --check-build\n./tools/test.py --check-syntax\n./tools/test.py --check-syntax --with-niceness --non-voting\n\nThe force parameter is also available (as in validate.py). But\nI think it's not meaningful to force the build of all books\nor the syntax check of all files because this will result again\nin very long runtimes.\n\nWe should not use the --non-voting parameter on Jenkins. It should\nbe possible to simply define non-voting jobs. Then the job is\nfailed in the review request, but Jenkins still gives +1.\n\nChange-Id: I2ed6f80beb109c60bd7f0ca2417426f776383973\n""}]",0,42157,03e400ba70d4bbc01c5e6b3c78becbfaebbac548,9,4,1,167,,,0,"added parameters to control the behaviour

test.py is a modified copy of validate.py. I introduced a new
name to not cause race conditions with the existing Jenkins
job which actually uses validate.py.

This patch introduces the following new parameters and changes
the default behaviour of the script. By default the script will
do nothing.

--check-build: With this parameter the script tries to build
               all books affected by modified files.

--check-syntax: With this parameter the script checks if modified
                files are still using valid XML syntax.

--with-niceness: Using this parameter together with --check-syntax
                 will also check the syntax for niceness issues (for
                 example trailing whitespaces).

--non-voting: With this parameter set the script always returns 0
              as exit code.

Possible Jenkins jobs:

./tools/test.py --check-build
./tools/test.py --check-syntax
./tools/test.py --check-syntax --with-niceness --non-voting

The force parameter is also available (as in validate.py). But
I think it's not meaningful to force the build of all books
or the syntax check of all files because this will result again
in very long runtimes.

We should not use the --non-voting parameter on Jenkins. It should
be possible to simply define non-voting jobs. Then the job is
failed in the review request, but Jenkins still gives +1.

Change-Id: I2ed6f80beb109c60bd7f0ca2417426f776383973
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/57/42157/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/test.py'],1,03e400ba70d4bbc01c5e6b3c78becbfaebbac548,test,"#!/usr/bin/env python ''' Usage: test.py [path] Validates all xml files against the DocBook 5 RELAX NG schema, and attempts to build all books. Options: path Root directory, defaults to <repo root>/doc/src/doc/docbkx Ignores pom.xml files and subdirectories named ""target"". Requires: - Python 2.7 or greater (for argparse) - lxml Python library - Maven ''' from lxml import etree import argparse import multiprocessing import os import re import subprocess import sys import urllib2 # These are files that are known to not be in DocBook format FILE_EXCEPTIONS = ['ha-guide-docinfo.xml','bk001-ch003-associate-general.xml'] # These are books that we aren't checking yet BOOK_EXCEPTIONS = [] RESULTS_OF_BUILDS = [] # NOTE(berendt): check_output as provided in Python 2.7.5 to make script # usable with Python < 2.7 def check_output(*popenargs, **kwargs): """"""Run command with arguments and return its output as a byte string. If the exit code was non-zero it raises a CalledProcessError. The CalledProcessError object will have the return code in the returncode attribute and output in the output attribute. """""" if 'stdout' in kwargs: raise ValueError('stdout argument not allowed, it will be overridden.') process = subprocess.Popen(stdout=subprocess.PIPE, *popenargs, **kwargs) output, unused_err = process.communicate() retcode = process.poll() if retcode: cmd = kwargs.get(""args"") if cmd is None: cmd = popenargs[0] raise subprocess.CalledProcessError(retcode, cmd, output=output) return output def get_schema(): """"""Return the DocBook RELAX NG schema"""""" url = ""http://www.oasis-open.org/docbook/xml/5.0b5/rng/docbookxi.rng"" relaxng_doc = etree.parse(urllib2.urlopen(url)) return etree.RelaxNG(relaxng_doc) def validation_failed(schema, doc): """"""Return True if the parsed doc fails against the schema This will ignore validation failures of the type: IDREF attribute linkend references an unknown ID. This is because we are validating individual files that are being imported, and sometimes the reference isn't present in the current file."""""" return not schema.validate(doc) and \ any(log.type_name != ""DTD_UNKNOWN_ID"" for log in schema.error_log) def verify_section_tags_have_xmid(doc): """"""Check that all section tags have an xml:id attribute Will throw an exception if there's at least one missing"""""" ns = {""docbook"": ""http://docbook.org/ns/docbook""} for node in doc.xpath('//docbook:section', namespaces=ns): if ""{http://www.w3.org/XML/1998/namespace}id"" not in node.attrib: raise ValueError(""section missing xml:id attribute, line %d"" % node.sourceline) def verify_nice_usage_of_whitespaces(docfile): """"""Check that no unnecessary whitespaces are used"""""" checks = [ re.compile("".*\s+\n$""), ] elements = [ 'listitem', 'para', 'td', 'th', 'command', 'literal', 'title', 'caption', 'filename', 'userinput', 'programlisting' ] for element in elements: checks.append(re.compile("".*<%s>\s+[\w\-().:!?{}\[\]]+.*\n"" % element)), checks.append(re.compile("".*[\w\-().:!?{}\[\]]+\s+<\/%s>.*\n"" % element)) lc = 0 affected_lines = [] for line in open(docfile, 'r'): lc = lc + 1 for check in checks: if check.match(line) and lc not in affected_lines: affected_lines.append(str(lc)) if len(affected_lines) > 0: raise ValueError(""trailing or unnecessary whitespaces "" ""in following lines: %s"" % "", "".join(affected_lines)) def error_message(error_log): """"""Return a string that contains the error message. We use this to filter out false positives related to IDREF attributes """""" errs = [str(x) for x in error_log if x.type_name != 'DTD_UNKNOWN_ID'] # Reverse output so that earliest failures are reported first errs.reverse() return ""\n"".join(errs) def get_modified_files(): try: args = [""git"", ""diff"", ""--name-only"", ""--relative"", ""HEAD"", ""HEAD~1""] modified_files = check_output(args).strip().split() except (subprocess.CalledProcessError, OSError) as e: print(""git failed: %s"" % e) sys.exit(1) return modified_files def validate_individual_files(rootdir, exceptions, force=False, niceness=False, voting=True): schema = get_schema() any_failures = False modified_files = get_modified_files() print(""\nFollowing files will be validated:"") for f in modified_files: print("">>> %s"" % f) print("""") modified_files = map(lambda x: os.path.abspath(x), modified_files) for root, dirs, files in os.walk(rootdir): # Don't descend into 'target' subdirectories try: ind = dirs.index('target') del dirs[ind] except ValueError: pass for f in files: # Ignore maven files, which are called pom.xml if (f.endswith('.xml') and f != 'pom.xml' and f not in exceptions): try: path = os.path.abspath(os.path.join(root, f)) if not force and path not in modified_files: continue doc = etree.parse(path) if validation_failed(schema, doc): any_failures = True print(error_message(schema.error_log)) verify_section_tags_have_xmid(doc) if niceness: verify_nice_usage_of_whitespaces(os.path.join(root, f)) except etree.XMLSyntaxError as e: any_failures = True print(""%s: %s"" % (path, e)) except ValueError as e: any_failures = True print(""%s: %s"" % (path, e)) if voting and any_failures: sys.exit(1) def logging_build_book(result): RESULTS_OF_BUILDS.append(result) def build_book(rootdir, book): os.chdir(book) result = True returncode = 0 try: output = subprocess.check_output( [""mvn"", ""clean"", ""generate-sources""], stderr=subprocess.STDOUT ) except subprocess.CalledProcessError as e: output = e.output returncode = e.returncode result = False return (os.path.basename(book), result, output, returncode) def build_affected_books(rootdir, book_exceptions, file_exceptions, force=False, voting=True): """"""Build all the books which are affected by modified files. Looks for all directories with ""pom.xml"" and checks if a XML file in the directory includes a modified file. If at least one XML file includes a modified file the method calls ""mvn clean generate-sources"" in that directory. This will throw an exception if a book fails to build """""" modified_files = get_modified_files() modified_files = map(lambda x: os.path.abspath(x), modified_files) affected_books = [] books = [] book_root = rootdir for root, dirs, files in os.walk(rootdir): if os.path.basename(root) in book_exceptions: break elif ""pom.xml"" in files: books.append(root) book_root = root os.chdir(root) for f in files: if (f.endswith('.xml') and f != 'pom.xml' and f not in file_exceptions): path = os.path.abspath(os.path.join(root, f)) doc = etree.parse(path) ns = {""xi"": ""http://www.w3.org/2001/XInclude""} for node in doc.xpath('//xi:include', namespaces=ns): href = node.get('href') if (href.endswith('.xml') and f not in file_exceptions and os.path.abspath(href) in modified_files): affected_books.append(book_root) break if book_root in affected_books: break if not force and affected_books: books = affected_books else: print(""No books are affected by modified files. Building all books."") pool = multiprocessing.Pool(processes=multiprocessing.cpu_count()) for book in books: pool.apply_async(build_book, (rootdir, book), callback = logging_build_book) pool.close() pool.join() any_failures = False for book, result, output, returncode in RESULTS_OF_BUILDS: if result: print("">>> Build of book %s succeeded."" % book) else: any_failures = True print("">>> Build of book %s failed (returncode = %d)."" % (book, returncode)) print(""\n%s"" % output) if voting and any_failures: sys.exit(1) def main(args): if args.check_syntax: validate_individual_files(args.path, FILE_EXCEPTIONS, args.force, args.with_niceness, args.non_voting) if args.check_build: build_affected_books(args.path, BOOK_EXCEPTIONS, FILE_EXCEPTIONS, args.force, args.non_voting) def default_root(): """"""Return the location of openstack-manuals/doc/src/docbkx The current working directory must be inside of the openstack-manuals repository for this method to succeed"""""" try: args = [""git"", ""rev-parse"", ""--show-toplevel""] gitroot = check_output(args).rstrip() except (CalledProcessError, OSError) as e: print(""git failed: %s"" % e) sys.exit(1) return os.path.join(gitroot, ""doc/src/docbkx"") if __name__ == '__main__': parser = argparse.ArgumentParser(description=""Validate XML files against "" ""the DocBook 5 RELAX NG schema"") parser.add_argument('path', nargs='?', default=default_root(), help=""Root directory that contains DocBook files, "" ""defaults to `git rev-parse --show-toplevel`/doc/src/"" ""docbkx"") parser.add_argument(""--force"", help=""force the validation of all files "" ""and build all books"", action=""store_true"") parser.add_argument(""--check-build"", help=""try to build books using "" ""modified files"", action=""store_true"") parser.add_argument(""--check-syntax"", help=""check the syntax of modified "" ""files"", action=""store_true"") parser.add_argument(""--with-niceness"", help=""when checking the syntax "" ""also check the niceness of the syntax"", action=""store_true"") parser.add_argument(""--non-voting"", help=""do not exit on failures"", action=""store_false"") args = parser.parse_args() main(args) ",,322,0
openstack%2Fdevstack~master~I102033ccdcbd9da566082e740effc1c5fb49af45,openstack/devstack,master,I102033ccdcbd9da566082e740effc1c5fb49af45,Skip DHCP variables for Nova Network FlatManager,ABANDONED,2013-08-23 13:31:11.000000000,2013-09-04 15:05:14.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 3, 'created': '2013-08-23 13:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/695ffcd859163061f434a79b9baf38cc982de503', 'message': ""Skip DHCP variables for Nova Network FlatManager\n\nSet the force_dhcp_release flag to False and do not set the\ndhcpbridge_flagfile as well when the NETWORK_MANAGER is set\nto the Nova Network's FlatManager as that does not support DHCP\n\nChange-Id: I102033ccdcbd9da566082e740effc1c5fb49af45\n""}, {'number': 2, 'created': '2013-08-23 13:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/61d1641b9c82f08057467faaa3f922232b7e3eca', 'message': ""Skip DHCP variables for Nova Network FlatManager\n\nSet the force_dhcp_release flag to False and do not set the\ndhcpbridge_flagfile as well when the NETWORK_MANAGER is set\nto the Nova Network's FlatManager as that does not support DHCP\n\nChange-Id: I102033ccdcbd9da566082e740effc1c5fb49af45\n""}, {'number': 1, 'created': '2013-08-23 13:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/88a257fdd53d9563fd4ebdc6f944b839c53f5f92', 'message': ""Skip DHCP variables for Nova Network FlatManager\n\nSet the force_dhcp_release flag to False and do not set the\ndhcpbridge_flagfile as well when the NETWORK_MANAGER is set\nto the Nova Network's FlatManager as that does not support DHCP\n\nChange-Id: I102033ccdcbd9da566082e740effc1c5fb49af45\n""}, {'number': 6, 'created': '2013-08-23 13:31:11.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a12fd8b6eaa58d4913059b75f5d750550a77aa0d', 'message': ""Skip DHCP variables for Nova Network FlatManager\n\nSet the force_dhcp_release flag to False and do not set the\ndhcpbridge_flagfile as well when the NETWORK_MANAGER is set\nto the Nova Network's FlatManager as that does not support DHCP\n\nChange-Id: I102033ccdcbd9da566082e740effc1c5fb49af45\n""}, {'number': 5, 'created': '2013-08-23 13:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/cfeb8cdd912ef0c312c9508f0c2246a8e199ab74', 'message': ""Skip DHCP variables for Nova Network FlatManager\n\nSet the force_dhcp_release flag to False and do not set the\ndhcpbridge_flagfile as well when the NETWORK_MANAGER is set\nto the Nova Network's FlatManager as that does not support DHCP\n\nChange-Id: I102033ccdcbd9da566082e740effc1c5fb49af45\n""}, {'number': 4, 'created': '2013-08-23 13:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/de5b708f0e01d7fff761b7d81ae48e6ca0ac5c52', 'message': ""Skip DHCP variables for Nova Network FlatManager\n\nSet the force_dhcp_release flag to False and do not set the\ndhcpbridge_flagfile as well when the NETWORK_MANAGER is set\nto the Nova Network's FlatManager as that does not support DHCP\n\nChange-Id: I102033ccdcbd9da566082e740effc1c5fb49af45\n""}]",0,43468,a12fd8b6eaa58d4913059b75f5d750550a77aa0d,14,2,6,5638,,,0,"Skip DHCP variables for Nova Network FlatManager

Set the force_dhcp_release flag to False and do not set the
dhcpbridge_flagfile as well when the NETWORK_MANAGER is set
to the Nova Network's FlatManager as that does not support DHCP

Change-Id: I102033ccdcbd9da566082e740effc1c5fb49af45
",git fetch https://review.opendev.org/openstack/devstack refs/changes/68/43468/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,695ffcd859163061f434a79b9baf38cc982de503,master," # FlatManager does not support DHCP if [ ""$NETWORK_MANAGER"" = 'FlatManager' ]; then iniset $NOVA_CONF DEFAULT force_dhcp_release ""False"" else iniset $NOVA_CONF DEFAULT dhcpbridge_flagfile ""$NOVA_CONF"" iniset $NOVA_CONF DEFAULT force_dhcp_release ""True"" fi"," iniset $NOVA_CONF DEFAULT dhcpbridge_flagfile ""$NOVA_CONF"" iniset $NOVA_CONF DEFAULT force_dhcp_release ""True""",7,2
openstack%2Fopenstack-manuals~master~Ia74ffbb4ed327af41f938f900fc105492606b50b,openstack/openstack-manuals,master,Ia74ffbb4ed327af41f938f900fc105492606b50b,Warn operators not to install openvswitch-brcompat,MERGED,2013-09-04 13:51:51.000000000,2013-09-04 14:59:34.000000000,2013-09-04 14:59:33.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 964}]","[{'number': 1, 'created': '2013-09-04 13:51:51.000000000', 'files': ['doc/src/docbkx/openstack-network-connectivity-admin/ch_install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f1d51128ddb431bd675f073856db3219c11efdd2', 'message': ""Warn operators not to install openvswitch-brcompat\n\nThe LibvirtHybridOVSBridgeDriver VIF driver for the Open vSwitch Neutron\nplugin needs to create a Linux bridge using brctl for the iptables firewall\nrules that implement security groups. But if the package\nopenvswitch-brcompat is installed, brctl actually creates an OVS bridge and\nthe security groups won't work.\n\nbug: #1220358\nChange-Id: Ia74ffbb4ed327af41f938f900fc105492606b50b\n""}]",0,45061,f1d51128ddb431bd675f073856db3219c11efdd2,6,3,1,2733,,,0,"Warn operators not to install openvswitch-brcompat

The LibvirtHybridOVSBridgeDriver VIF driver for the Open vSwitch Neutron
plugin needs to create a Linux bridge using brctl for the iptables firewall
rules that implement security groups. But if the package
openvswitch-brcompat is installed, brctl actually creates an OVS bridge and
the security groups won't work.

bug: #1220358
Change-Id: Ia74ffbb4ed327af41f938f900fc105492606b50b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/61/45061/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-network-connectivity-admin/ch_install.xml'],1,f1d51128ddb431bd675f073856db3219c11efdd2,warn-ovsbrcompat, <warning> <para>Do not install the openvswitch-brcompat package as it breaks the security groups functionality.</para> </warning>,,4,0
openstack%2Fopenstack-manuals~master~I252577b15fd4ac30ed943cc6ffa015e7e3203909,openstack/openstack-manuals,master,I252577b15fd4ac30ed943cc6ffa015e7e3203909,Adds a Cell scheduling section to the Compute Cells configuration.,MERGED,2013-08-28 18:46:45.000000000,2013-09-04 14:59:27.000000000,2013-09-04 14:59:26.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 1030}, {'_account_id': 1177}, {'_account_id': 2448}, {'_account_id': 6547}]","[{'number': 1, 'created': '2013-08-28 18:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/db86586e9b90d638a7b693cbb6af921d6ed6ab29', 'message': 'Adds a Cell scheduling section to the Compute Cells configuration.\n\nWant to add admin user info on how to add a scheduler hint\nto launch a new VM where you want to.\n\nAlso not sure if --woffset and --wscale are now in use.\n\nPartial fix bug 1187290\n\nChange-Id: I252577b15fd4ac30ed943cc6ffa015e7e3203909\n'}, {'number': 2, 'created': '2013-08-28 18:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/50d28fb510d1a85b5327c8973bfcab5a6ed3b27f', 'message': 'Adds a Cell scheduling section to the Compute Cells configuration.\n\nWant to add admin user info on how to add a scheduler hint\nto launch a new VM where you want to.\n\nAlso not sure if --woffset and --wscale are now in use.\n\nPartial fix bug 1187290\n\nChange-Id: I252577b15fd4ac30ed943cc6ffa015e7e3203909\n'}, {'number': 3, 'created': '2013-08-28 18:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/186ca08bbb2dbf51f35af89ebaaa79f6d24062bf', 'message': 'Adds a Cell scheduling section to the Compute Cells configuration.\n\nWant to add admin user info on how to add a scheduler hint\nto launch a new VM where you want to.\n\nAlso not sure if --woffset and --wscale are now in use.\n\nPartial fix bug 1187290\n\nChange-Id: I252577b15fd4ac30ed943cc6ffa015e7e3203909\n'}, {'number': 4, 'created': '2013-08-28 19:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/02b017793c5e16b014b3fc63a4912e4b56177c6d', 'message': 'Adds a Cell scheduling section to the Compute Cells configuration.\n\nWant to add admin user info on how to add a scheduler hint\nto launch a new VM where you want to.\n\nAlso not sure if --woffset and --wscale are now in use.\n\nPartial fix bug 1187290\n\nChange-Id: I252577b15fd4ac30ed943cc6ffa015e7e3203909\n'}, {'number': 5, 'created': '2013-09-04 14:50:25.000000000', 'files': ['doc/src/docbkx/openstack-config/compute/section_compute-cells.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5152570952e328d7fd3ca36e346d003afcfe081e', 'message': 'Adds a Cell scheduling section to the Compute Cells configuration.\n\nWant to add admin user info on how to add a scheduler hint\nto launch a new VM where you want to.\n\nAlso not sure if --woffset and --wscale are now in use.\n\nPartial fix bug 1187290\n\nChange-Id: I252577b15fd4ac30ed943cc6ffa015e7e3203909\n'}]",3,44127,5152570952e328d7fd3ca36e346d003afcfe081e,19,6,5,964,,,0,"Adds a Cell scheduling section to the Compute Cells configuration.

Want to add admin user info on how to add a scheduler hint
to launch a new VM where you want to.

Also not sure if --woffset and --wscale are now in use.

Partial fix bug 1187290

Change-Id: I252577b15fd4ac30ed943cc6ffa015e7e3203909
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/27/44127/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/src/docbkx/openstack-config/ch_computecells.xml'],1,db86586e9b90d638a7b693cbb6af921d6ed6ab29,bug/1187290," pairs defining capabilities of the current cell. Values include hypervisor=xenserver;kvm,os=linux;windows.</para> <para>How long in seconds to wait for replies from calls between cells.</para> </listitem> </varlistentry> <varlistentry> <term>scheduler_filter_classes</term> <listitem> <para>Filter classes that the cells scheduler should use. Use ""nova.cells.filters.all_filters"" to map to all cells filters included with nova.</para> </listitem> </varlistentry> <varlistentry> <term>scheduler_weight_classes</term> <listitem><para>Weight classes the cells scheduler should use. Use ""nova.cells.weights.all_weighers"" to map to all cells weight filters (weighers) included with nova.</para></listitem> </varlistentry> <varlistentry> <term>ram_weight_multiplier</term> <listitem> <para>Multiplier used for weighing ram. Negative numbers mean you want nova to stack instead of spread out new VMs. Default value is 10.0.</para> <section xml:id=""cell-weights-filters""> <title>Cell Scheduling</title> <para>New for the Havana release, you can configure some cells with higher weights so that those cells are given priority for new builds.</para> <para>As an admin user, you can also add a filter that directs builds to a particular cell. The <filename>policy.json</filename> file must have a line with <literal>""cells_scheduler_filter:TargetCellFilter"" : ""is_admin:True""</literal> to let an admin user specify a scheduler hint to direct a build to a particular cell.</para> <para>There are two modules available by default in the <filename>nova.conf</filename> file so that cell selection is no longer random. These are selected with the default <filename>nova.conf</filename> file which has <literal>scheduler_weight_classes=nova.cells.weights.all_weighers</literal> as the default.</para> <itemizedlist><listitem><para>ram_by_instance_type: Select cells with the most RAM capacity for the instance type being requested. Since higher weights win, Compute returns the number of available units for the instance type requested. In nova.conf there's a ram_weight_multiplier defaulted to 10.0 that adds to the weight by a factor of 10.</para></listitem> <listitem><para>weight_offset: Allows modifying the database to weight a particular cell. You can use this when you want to disable a cell. Originally designed so you can set a default cell by making its weight_offset very high, like 999999999999999. The highest weight will be first cell scheduled for launching VMs.</para></listitem></itemizedlist> </section> <para>Cells currently keeps all intercell communication data, including usernames and passwords, in the database. This is undesirable and unnecessary since cells data isn't updated very frequently. Instead, create a JSON file to input cells data specified via a <code>[cells]cells_config</code> option. When specified, the database is no longer consulted when reloading cells data. The file will need the columns present in the Cell model (excluding common database fields and the <code>id</code> column). The queue connection information must be specified through a <code>transport_url</code> field, instead of <code>username</code>, <code>password</code>, and so on. The <code>transport_url</code> has the following form:</para>"," pairs defining capabilities of the current cell. These are sent to parent cells, but aren't used in scheduling until later filter/weight support is added.</para> <para>How long to wait for replies from calls between cells.</para> <para>Cells currently keeps all intercell communication data, including usernames and passwords, in the database. This is undesirable and unnecessary since cells data isn't updated very frequently. The change described in this section allows cells data to be drawn from a JSON file specified via a new <code>[cells]cells_config</code> option. When specified, the database is no longer consulted when reloading cells data.</para> <para>Cells may now optionally be configured through a JSON-formatted file. The file will need the columns present in the Cell model (excluding common database fields and the <code>id</code> column). The queue connection information must be specified through a <code>transport_url</code> field, instead of <code>username</code>, <code>password</code>, and so on. The <code>transport_url</code> has the following form:</para>",68,14
openstack%2Fopenstack-manuals~master~I1653ffe4908918efbb3beeac036abd8581432dcb,openstack/openstack-manuals,master,I1653ffe4908918efbb3beeac036abd8581432dcb,Document Ceilometer Agent Central in HA,MERGED,2013-08-31 09:13:44.000000000,2013-09-04 14:59:20.000000000,2013-09-04 14:59:19.000000000,"[{'_account_id': 3}, {'_account_id': 595}, {'_account_id': 964}, {'_account_id': 1669}, {'_account_id': 1918}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 3153}, {'_account_id': 4277}, {'_account_id': 4491}, {'_account_id': 4573}, {'_account_id': 4715}, {'_account_id': 6537}]","[{'number': 1, 'created': '2013-08-31 09:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1f58d78dda740864a71da19935efc3ca9d01cd9d', 'message': 'Document Ceilometer Agent Central in HA\n\nExplain how to bring highly available Ceilometer Agent Central service\nin the active / passive section.\n\nIn this manual, the service is installed on API nodes and is managed by\nPacemaker cluster manager.\n\nChange-Id: I1653ffe4908918efbb3beeac036abd8581432dcb\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 2, 'created': '2013-08-31 09:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/85907e78fc206b591c80ee10c321a9306f0e097e', 'message': 'Document Ceilometer Agent Central in HA\n\nExplain how to bring highly available Ceilometer Agent Central service\nin the active / passive section.\n\nIn this manual, the service is installed on API nodes and is managed by\nPacemaker cluster manager.\n\nChange-Id: I1653ffe4908918efbb3beeac036abd8581432dcb\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 3, 'created': '2013-09-03 11:16:14.000000000', 'files': ['doc/src/docbkx/openstack-ha/ap-ceilometer-agent-central.txt', 'doc/src/docbkx/openstack-ha/includes/pacemaker-api.crm', 'doc/src/docbkx/openstack-ha/ap-api-node.txt', 'doc/src/docbkx/openstack-ha/includes/pacemaker-ceilometer_agent_central.crm'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ef4460bad820aedcea2fd8ef1bf33091573114ec', 'message': 'Document Ceilometer Agent Central in HA\n\nExplain how to bring highly available Ceilometer Agent Central service\nin the active / passive section.\n\nIn this manual, the service is installed on API nodes and is managed by\nPacemaker cluster manager.\n\nChange-Id: I1653ffe4908918efbb3beeac036abd8581432dcb\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}]",24,44584,ef4460bad820aedcea2fd8ef1bf33091573114ec,16,14,3,3153,,,0,"Document Ceilometer Agent Central in HA

Explain how to bring highly available Ceilometer Agent Central service
in the active / passive section.

In this manual, the service is installed on API nodes and is managed by
Pacemaker cluster manager.

Change-Id: I1653ffe4908918efbb3beeac036abd8581432dcb
Signed-off-by: Emilien Macchi <emilien.macchi@enovance.com>
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/84/44584/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-ha/ap-ceilometer-agent-central.txt', 'doc/src/docbkx/openstack-ha/includes/pacemaker-api.crm', 'doc/src/docbkx/openstack-ha/ap-api-node.txt', 'doc/src/docbkx/openstack-ha/includes/pacemaker-ceilometer_agent_central.crm']",4,1f58d78dda740864a71da19935efc3ca9d01cd9d,ceilo-ha,"primitive p_ceilometer-agent-central ocf:openstack:ceilometer-agent-central \ params config=""/etc/ceilometer/ceilometer.conf"" \ op monitor interval=""30s"" timeout=""30s"" ",,66,1
openstack%2Fcinder~master~I8ffb4267834c79d056716a2c412ecb2c97217635,openstack/cinder,master,I8ffb4267834c79d056716a2c412ecb2c97217635,extract 'limits.' to constant for ratelimiting logic,MERGED,2013-09-03 14:48:38.000000000,2013-09-04 14:41:24.000000000,2013-09-04 14:41:24.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2166}, {'_account_id': 2759}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-09-03 14:48:38.000000000', 'files': ['cinder/api/v2/limits.py', 'cinder/api/v1/limits.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c494c7de697403b112857313c023bd9e83f5322e', 'message': ""extract 'limits.' to constant for ratelimiting logic\n\nbased on the equal nova code at\nhttps://review.openstack.org/#/c/41267/ the ratelimiting logic\nuses a constant to parse the limits.\n\nChange-Id: I8ffb4267834c79d056716a2c412ecb2c97217635\n""}]",0,44890,c494c7de697403b112857313c023bd9e83f5322e,10,5,1,6743,,,0,"extract 'limits.' to constant for ratelimiting logic

based on the equal nova code at
https://review.openstack.org/#/c/41267/ the ratelimiting logic
uses a constant to parse the limits.

Change-Id: I8ffb4267834c79d056716a2c412ecb2c97217635
",git fetch https://review.opendev.org/openstack/cinder refs/changes/90/44890/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/v2/limits.py', 'cinder/api/v1/limits.py']",2,c494c7de697403b112857313c023bd9e83f5322e,seif/set_constant_for_limit_string,"LIMITS_PREFIX = ""limits."" if key.startswith(LIMITS_PREFIX): username = key[len(LIMITS_PREFIX):]", if key.startswith('limits.'): username = key[7:],6,4
openstack%2Fneutron~master~Ia745b80d2826de32ba8d6883c0d6e0893047e123,openstack/neutron,master,Ia745b80d2826de32ba8d6883c0d6e0893047e123,Introduce periodic state synchronization with backend,MERGED,2013-07-06 16:06:39.000000000,2013-09-04 14:41:16.000000000,2013-09-04 14:41:16.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 4395}]","[{'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e5242bd5ed279402a92e053c1dd3d5e3c9db0cf6', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving a resource's status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of conf variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (show only in this patch)\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd1e3357e42eeef30cea3ca34912d5f739e4bc5c', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving a resource's status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of conf variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (show only in this patch)\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9aa7562f2bb7bde879dbb86b774d17a8a25c5262', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving a resource's status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of conf variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (show only in this patch)\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a6ad70b18b3fa5a1a0efe8ec3289740e9961dd43', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving a resource's status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of conf variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (show only in this patch)\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 5, 'created': '2013-07-18 20:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fa9f9d70d0d90a71da103a714a05b649409626af', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving a resource's status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of conf variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (show only in this patch)\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 6, 'created': '2013-08-13 20:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8223b76f6afb8b770d01914c8e2430ea2ee46935', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving a resource's status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of conf variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (show only in this patch)\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 7, 'created': '2013-08-20 14:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d41eea2f25d3d9594aa1a0b23155c54a3792cbc', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving resource status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of configuration variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (only 'show' support has been\nimplemented in this patch)\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 8, 'created': '2013-09-02 15:44:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/475a721cb4720421ea7f99c0c9de028ff47b0ffb', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving resource status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of configuration variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (only 'show' support has been\nimplemented in this patch)\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 9, 'created': '2013-09-03 12:08:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1ff9f5cb4441477e5581347e8048d66101a15752', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving resource status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of configuration variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (only 'show' support has been\nimplemented in this patch)\n\nThis patchs also makes some changes to the fake nvp api client in\norder to ensure each instance has a private set of dictionaries for\nfake nvp entities.\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 10, 'created': '2013-09-03 20:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e1dd999dfab74ed6f5cbdfe96d41c5b4194b7512', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving resource status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of configuration variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (only 'show' support has been\nimplemented in this patch)\n\nThis patchs also makes some changes to the fake nvp api client in\norder to ensure each instance has a private set of dictionaries for\nfake nvp entities.\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 11, 'created': '2013-09-04 01:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bebd03e086c719f55307edb5d353480333a5f9ca', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving resource status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of configuration variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (only 'show' support has been\nimplemented in this patch)\n\nThis patchs also makes some changes to the fake nvp api client in\norder to ensure each instance has a private set of dictionaries for\nfake nvp entities.\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 12, 'created': '2013-09-04 01:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1eaf37f36cca15d3198bd38c2e96052b95c7f1e4', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving resource status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of configuration variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (only 'show' support has been\nimplemented in this patch)\n\nThis patchs also makes some changes to the fake nvp api client in\norder to ensure each instance has a private set of dictionaries for\nfake nvp entities.\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}, {'number': 13, 'created': '2013-09-04 02:37:17.000000000', 'files': ['neutron/tests/unit/test_db_plugin.py', 'neutron/plugins/nicira/nvplib.py', 'neutron/tests/unit/nicira/etc/fake_get_lrouter.json', 'neutron/tests/unit/nicira/test_nvp_sync.py', 'neutron/tests/unit/nicira/fake_nvpapiclient.py', 'neutron/tests/unit/nicira/etc/fake_get_lswitch_lport.json', 'neutron/plugins/nicira/common/config.py', 'neutron/tests/unit/nicira/test_maclearning.py', 'neutron/plugins/nicira/NeutronPlugin.py', 'neutron/tests/unit/nicira/test_nicira_plugin.py', 'neutron/tests/unit/nicira/test_agent_scheduler.py', 'neutron/plugins/nicira/common/sync.py', 'neutron/tests/unit/nicira/test_nvpopts.py', 'etc/neutron/plugins/nicira/nvp.ini', 'neutron/tests/unit/nicira/etc/fake_get_lswitch.json'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c7cf2edcefe49a636092ad43a621569c3cefd4a8', 'message': ""Introduce periodic state synchronization with backend\n\nBlueprint nicira-plugin-get-improvements\n\nWith this patch GET operations on the Nicira plugin will not\nbe forwarded anymore to the NVP backend.\nResource operational status will be periodically retrieved from\nthe NVP backend using a DynamicLoopingCall.\nThe process has been designed with the aim of avoiding:\n1) frequent queries to NVP for retrieving resource status\n2) execution of large queries to NVP for retrieving the status\n   of a consistent number of resources.\nThe process can be tuned using a set of configuration variables.\nGET operations will now return a status which might differ\nfrom the actual status of the resource. For retrieving status\nin a punctual way, the field 'status' should be explicitly\nspecified in the GET request (only 'show' support has been\nimplemented in this patch)\n\nThis patchs also makes some changes to the fake nvp api client in\norder to ensure each instance has a private set of dictionaries for\nfake nvp entities.\n\nChange-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123\n""}]",119,34245,c7cf2edcefe49a636092ad43a621569c3cefd4a8,80,6,13,261,,,0,"Introduce periodic state synchronization with backend

Blueprint nicira-plugin-get-improvements

With this patch GET operations on the Nicira plugin will not
be forwarded anymore to the NVP backend.
Resource operational status will be periodically retrieved from
the NVP backend using a DynamicLoopingCall.
The process has been designed with the aim of avoiding:
1) frequent queries to NVP for retrieving resource status
2) execution of large queries to NVP for retrieving the status
   of a consistent number of resources.
The process can be tuned using a set of configuration variables.
GET operations will now return a status which might differ
from the actual status of the resource. For retrieving status
in a punctual way, the field 'status' should be explicitly
specified in the GET request (only 'show' support has been
implemented in this patch)

This patchs also makes some changes to the fake nvp api client in
order to ensure each instance has a private set of dictionaries for
fake nvp entities.

Change-Id: Ia745b80d2826de32ba8d6883c0d6e0893047e123
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/34245/5 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/plugins/nicira/common/config.py', 'quantum/tests/unit/nicira/fake_nvpapiclient.py', 'quantum/tests/unit/nicira/etc/fake_get_lrouter.json', 'quantum/tests/unit/nicira/etc/fake_get_lswitch_lport.json', 'quantum/tests/unit/nicira/test_nvp_sync.py', 'quantum/tests/unit/nicira/etc/fake_get_lswitch.json', 'quantum/tests/unit/nicira/test_nicira_plugin.py', 'quantum/tests/unit/test_db_plugin.py', 'quantum/tests/unit/nicira/test_maclearning.py', 'quantum/plugins/nicira/common/sync.py', 'quantum/plugins/nicira/nvplib.py', 'etc/quantum/plugins/nicira/nvp.ini', 'quantum/plugins/nicira/QuantumPlugin.py']",13,e5242bd5ed279402a92e053c1dd3d5e3c9db0cf6,bp/nicira-plugin-get-improvements,"from quantum.plugins.nicira.common import sync # Create a synchronizer instance for backend sync self._synchronizer = sync.NvpSynchronizer( self, self.cluster, self.nvp_opts.state_sync_interval, self.nvp_opts.min_sync_req_delay, self.nvp_opts.min_chunk_size) if fields and 'status' in fields: # Perform explicit state synchronization self._synchronizer.synchronize_network( context, network) networks = super(NvpPluginV2, self).get_networks(context, filters) for net in networks: return [self._fields(network, fields) for network in networks] ports = super(NvpPluginV2, self).get_ports(context, filters) for port in ports: self._extend_port_port_security_dict(context, port) self._extend_port_mac_learning_state(context, port) return [self._fields(port, fields) for port in ports] if fields and 'status' in fields: # Perform explicit state synchronization db_port = self._get_port(context, id) self._synchronizer.synchronize_port( context, db_port) port = super(NvpPluginV2, self).get_port(context, id, fields) self._extend_port_port_security_dict(context, port) self._extend_port_qos_queue(context, port) self._extend_port_mac_learning_state(context, port) return port def get_router(self, context, id, fields=None): if fields and 'status' in fields: router = self._get_router(context, id) # Perform explicit state synchronization self._synchronizer.synchronize_router( context, router) return super(NvpPluginV2, self).get_router(context, id, fields)","import hashlib # if the network is external, do not go to NVP if not self._network_is_external(context, id): # verify the fabric status of the corresponding # logical switch(es) in nvp try: lswitches = nvplib.get_lswitches(self.cluster, id) nvp_net_status = constants.NET_STATUS_ACTIVE quantum_status = network.status for lswitch in lswitches: relations = lswitch.get('_relations') if relations: lswitch_status = relations.get( 'LogicalSwitchStatus') # FIXME(salvatore-orlando): Being unable to fetch # logical switch status should be an exception. if (lswitch_status and not lswitch_status.get('fabric_status', None)): nvp_net_status = constants.NET_STATUS_DOWN break LOG.debug(_(""Current network status:%(nvp_net_status)s; "" ""Status in Quantum DB:%(quantum_status)s""), {'nvp_net_status': nvp_net_status, 'quantum_status': quantum_status}) if nvp_net_status != network.status: # update the network status network.status = nvp_net_status except q_exc.NotFound: network.status = constants.NET_STATUS_ERROR except Exception: err_msg = _(""Unable to get logical switches"") LOG.exception(err_msg) raise nvp_exc.NvpPluginException(err_msg=err_msg) nvp_lswitches = {} quantum_lswitches = ( super(NvpPluginV2, self).get_networks(context, filters)) for net in quantum_lswitches: tenant_ids = filters and filters.get('tenant_id') or None filter_fmt = ""&tag=%s&tag_scope=os_tid"" if context.is_admin and not tenant_ids: tenant_filter = """" else: tenant_ids = tenant_ids or [context.tenant_id] tenant_filter = ''.join(filter_fmt % tid for tid in tenant_ids) lswitch_filters = ""uuid,display_name,fabric_status,tags"" lswitch_url_path_1 = ( ""/ws.v1/lswitch?fields=%s&relations=LogicalSwitchStatus%s"" % (lswitch_filters, tenant_filter)) lswitch_url_path_2 = nvplib._build_uri_path( nvplib.LSWITCH_RESOURCE, fields=lswitch_filters, relations='LogicalSwitchStatus', filters={'tag': 'true', 'tag_scope': 'shared'}) try: res = nvplib.get_all_query_pages(lswitch_url_path_1, self.cluster) nvp_lswitches.update(dict((ls['uuid'], ls) for ls in res)) # Issue a second query for fetching shared networks. # We cannot unfortunately use just a single query because tags # cannot be or-ed res_shared = nvplib.get_all_query_pages(lswitch_url_path_2, self.cluster) nvp_lswitches.update(dict((ls['uuid'], ls) for ls in res_shared)) except Exception: err_msg = _(""Unable to get logical switches"") LOG.exception(err_msg) raise nvp_exc.NvpPluginException(err_msg=err_msg) if filters.get('id'): nvp_lswitches = dict( (uuid, ls) for (uuid, ls) in nvp_lswitches.iteritems() if uuid in set(filters['id'])) for quantum_lswitch in quantum_lswitches: # Skip external networks as they do not exist in NVP if quantum_lswitch[l3.EXTERNAL]: continue elif quantum_lswitch['id'] not in nvp_lswitches: LOG.warning(_(""Logical Switch %s found in quantum database "" ""but not in NVP.""), quantum_lswitch[""id""]) quantum_lswitch[""status""] = constants.NET_STATUS_ERROR else: # TODO(salvatore-orlando): be careful about ""extended"" # logical switches ls = nvp_lswitches.pop(quantum_lswitch['id']) if (ls[""_relations""][""LogicalSwitchStatus""][""fabric_status""]): quantum_lswitch[""status""] = constants.NET_STATUS_ACTIVE else: quantum_lswitch[""status""] = constants.NET_STATUS_DOWN # do not make the case in which switches are found in NVP # but not in Quantum catastrophic. if nvp_lswitches: LOG.warning(_(""Found %s logical switches not bound "" ""to Quantum networks. Quantum and NVP are "" ""potentially out of sync""), len(nvp_lswitches)) LOG.debug(_(""get_networks() completed for tenant %s""), context.tenant_id) if fields: ret_fields = [] for quantum_lswitch in quantum_lswitches: row = {} for field in fields: row[field] = quantum_lswitch[field] ret_fields.append(row) return ret_fields return quantum_lswitches quantum_lports = super(NvpPluginV2, self).get_ports( context, filters) for quantum_lport in quantum_lports: self._extend_port_port_security_dict(context, quantum_lport) self._extend_port_mac_learning_state(context, quantum_lport) if (filters.get('network_id') and len(filters.get('network_id')) and self._network_is_external(context, filters['network_id'][0])): # Do not perform check on NVP platform return quantum_lports vm_filter = """" tenant_filter = """" # This is used when calling delete_network. Quantum checks to see if # the network has any ports. if filters.get(""network_id""): # FIXME (Aaron) If we get more than one network_id this won't work lswitch = filters[""network_id""][0] else: lswitch = ""*"" if filters.get(""device_id""): for vm_id in filters.get(""device_id""): vm_filter = (""%stag_scope=vm_id&tag=%s&"" % (vm_filter, hashlib.sha1(vm_id).hexdigest())) else: vm_id = """" if filters.get(""tenant_id""): for tenant in filters.get(""tenant_id""): tenant_filter = (""%stag_scope=os_tid&tag=%s&"" % (tenant_filter, tenant)) nvp_lports = {} lport_fields_str = (""tags,admin_status_enabled,display_name,"" ""fabric_status_up"") try: lport_query_path = ( ""/ws.v1/lswitch/%s/lport?fields=%s&%s%stag_scope=q_port_id"" ""&relations=LogicalPortStatus"" % (lswitch, lport_fields_str, vm_filter, tenant_filter)) try: ports = nvplib.get_all_query_pages(lport_query_path, self.cluster) except q_exc.NotFound: LOG.warn(_(""Lswitch %s not found in NVP""), lswitch) ports = None if ports: for port in ports: for tag in port[""tags""]: if tag[""scope""] == ""q_port_id"": nvp_lports[tag[""tag""]] = port except Exception: err_msg = _(""Unable to get ports"") LOG.exception(err_msg) raise nvp_exc.NvpPluginException(err_msg=err_msg) lports = [] for quantum_lport in quantum_lports: # if a quantum port is not found in NVP, this migth be because # such port is not mapped to a logical switch - ie: floating ip if quantum_lport['device_owner'] in (l3_db.DEVICE_OWNER_FLOATINGIP, l3_db.DEVICE_OWNER_ROUTER_GW): lports.append(quantum_lport) continue try: quantum_lport[""admin_state_up""] = ( nvp_lports[quantum_lport[""id""]][""admin_status_enabled""]) if (nvp_lports[quantum_lport[""id""]] [""_relations""] [""LogicalPortStatus""] [""fabric_status_up""]): quantum_lport[""status""] = constants.PORT_STATUS_ACTIVE else: quantum_lport[""status""] = constants.PORT_STATUS_DOWN del nvp_lports[quantum_lport[""id""]] except KeyError: quantum_lport[""status""] = constants.PORT_STATUS_ERROR LOG.debug(_(""Quantum logical port %s was not found on NVP""), quantum_lport['id']) lports.append(quantum_lport) # do not make the case in which ports are found in NVP # but not in Quantum catastrophic. if nvp_lports: LOG.warning(_(""Found %s logical ports not bound "" ""to Quantum ports. Quantum and NVP are "" ""potentially out of sync""), len(nvp_lports)) if fields: ret_fields = [] for lport in lports: row = {} for field in fields: row[field] = lport[field] ret_fields.append(row) return ret_fields return lports quantum_db_port = super(NvpPluginV2, self).get_port(context, id, fields) self._extend_port_port_security_dict(context, quantum_db_port) self._extend_port_qos_queue(context, quantum_db_port) self._extend_port_mac_learning_state(context, quantum_db_port) if self._network_is_external(context, quantum_db_port['network_id']): return quantum_db_port nvp_id = self._nvp_get_port_id(context, self.cluster, quantum_db_port) # If there's no nvp IP do not bother going to NVP and put # the port in error state if nvp_id: # Find the NVP port corresponding to quantum port_id # Do not query by nvp id as the port might be on # an extended switch and we do not store the extended # switch uuid results = nvplib.query_lswitch_lports( self.cluster, '*', relations='LogicalPortStatus', filters={'tag': id, 'tag_scope': 'q_port_id'}) if results: port = results[0] port_status = port[""_relations""][""LogicalPortStatus""] quantum_db_port[""admin_state_up""] = ( port[""admin_status_enabled""]) if port_status[""fabric_status_up""]: quantum_db_port[""status""] = ( constants.PORT_STATUS_ACTIVE) else: quantum_db_port[""status""] = ( constants.PORT_STATUS_DOWN) else: quantum_db_port[""status""] = ( constants.PORT_STATUS_ERROR) else: quantum_db_port[""status""] = constants.PORT_STATUS_ERROR return quantum_db_port def get_router(self, context, id, fields=None): router = self._get_router(context, id) try: lrouter = nvplib.get_lrouter(self.cluster, id) relations = lrouter.get('_relations') if relations: lrouter_status = relations.get('LogicalRouterStatus') # FIXME(salvatore-orlando): Being unable to fetch the # logical router status should be an exception. if lrouter_status: router_op_status = (lrouter_status.get('fabric_status') and constants.NET_STATUS_ACTIVE or constants.NET_STATUS_DOWN) except q_exc.NotFound: lrouter = {} router_op_status = constants.NET_STATUS_ERROR if router_op_status != router.status: LOG.debug(_(""Current router status:%(router_status)s;"" ""Status in Quantum DB:%(db_router_status)s""), {'router_status': router_op_status, 'db_router_status': router.status}) # update the router status with context.session.begin(subtransactions=True): router.status = router_op_status return self._make_router_dict(router, fields) def get_routers(self, context, filters=None, fields=None): router_query = self._apply_filters_to_query( self._model_query(context, l3_db.Router), l3_db.Router, filters) routers = router_query.all() # Query routers on NVP for updating operational status if context.is_admin and not filters.get(""tenant_id""): tenant_id = None elif 'tenant_id' in filters: tenant_id = filters.get('tenant_id')[0] del filters['tenant_id'] else: tenant_id = context.tenant_id try: nvp_lrouters = nvplib.get_lrouters(self.cluster, tenant_id, fields) except NvpApiClient.NvpApiException: err_msg = _(""Unable to get logical routers from NVP controller"") LOG.exception(err_msg) raise nvp_exc.NvpPluginException(err_msg=err_msg) nvp_lrouters_dict = {} for nvp_lrouter in nvp_lrouters: nvp_lrouters_dict[nvp_lrouter['uuid']] = nvp_lrouter for router in routers: nvp_lrouter = nvp_lrouters_dict.get(router['id']) if nvp_lrouter: if (nvp_lrouter[""_relations""][""LogicalRouterStatus""] [""fabric_status""]): router.status = constants.NET_STATUS_ACTIVE else: router.status = constants.NET_STATUS_DOWN nvp_lrouters.remove(nvp_lrouter) else: router.status = constants.NET_STATUS_ERROR # do not make the case in which routers are found in NVP # but not in Quantum catastrophic. if nvp_lrouters: LOG.warning(_(""Found %s logical routers not bound "" ""to Quantum routers. Quantum and NVP are "" ""potentially out of sync""), len(nvp_lrouters)) return [self._make_router_dict(router, fields) for router in routers] ",1215,375
openstack%2Fneutron~master~Ic3de53ed9fa47f6518cbb25dac4ee7782c97bfbb,openstack/neutron,master,Ic3de53ed9fa47f6518cbb25dac4ee7782c97bfbb,Adding more unit tests for the FWaaS agent,MERGED,2013-08-23 07:46:30.000000000,2013-09-04 14:35:03.000000000,2013-09-04 14:35:02.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6072}, {'_account_id': 6995}]","[{'number': 1, 'created': '2013-08-23 07:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9d4e4169063144b41bc61d6c66406604ef168ddf', 'message': 'Adding more unit tests for the FWaaS agent.\n\nChange-Id: Ic3de53ed9fa47f6518cbb25dac4ee7782c97bfbb\nFixes: bug #1215771\n'}, {'number': 2, 'created': '2013-09-03 03:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/489c41c46b47e46065729ebeeec5c3e3c828b86a', 'message': 'Adding more unit tests for the FWaaS agent\n\nChange-Id: Ic3de53ed9fa47f6518cbb25dac4ee7782c97bfbb\nFixes: bug #1215771\n'}, {'number': 3, 'created': '2013-09-03 18:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/81e7912ba074476f3b31abbe34d318f08fa78df4', 'message': 'Adding more unit tests for the FWaaS agent\n\nChange-Id: Ic3de53ed9fa47f6518cbb25dac4ee7782c97bfbb\nFixes: bug #1215771\n'}, {'number': 4, 'created': '2013-09-03 21:36:59.000000000', 'files': ['neutron/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d518c8f39ef7b39cf4508c41e163d1cc89a5571d', 'message': 'Adding more unit tests for the FWaaS agent\n\nChange-Id: Ic3de53ed9fa47f6518cbb25dac4ee7782c97bfbb\nFixes: bug #1215771\n'}]",10,43412,d518c8f39ef7b39cf4508c41e163d1cc89a5571d,26,7,4,6995,,,0,"Adding more unit tests for the FWaaS agent

Change-Id: Ic3de53ed9fa47f6518cbb25dac4ee7782c97bfbb
Fixes: bug #1215771
",git fetch https://review.opendev.org/openstack/neutron refs/changes/12/43412/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py'],1,9d4e4169063144b41bc61d6c66406604ef168ddf,bug/1215771," def test_invoke_driver_for_plugin_api_delete(self): fake_firewall = {'id': 0, 'tenant_id': 1} self.api.plugin_rpc = mock.Mock() with contextlib.nested( mock.patch.object(self.api.plugin_rpc, 'get_routers'), mock.patch.object(self.api, '_get_router_info_list_for_tenant'), mock.patch.object(self.api.fwaas_driver, 'delete_firewall'), mock.patch.object(self.api.fwplugin_rpc, 'firewall_deleted') ) as ( mock_get_routers, mock_get_router_info_list_for_tenant, mock_driver_delete_firewall, mock_firewall_deleted): mock_driver_delete_firewall.return_value = True self.api.delete_firewall( context=mock.sentinel.context, firewall=fake_firewall, host='host') mock_get_routers.assert_called_once_with( mock.sentinel.context) mock_get_router_info_list_for_tenant.assert_called_once_with( mock_get_routers.return_value, fake_firewall['tenant_id']) mock_firewall_deleted.assert_called_once_with( mock.sentinel.context, fake_firewall['id'])",,29,0
openstack%2Fnova~master~I45e12791f36f64d681f868ea1fe69249e0534e6e,openstack/nova,master,I45e12791f36f64d681f868ea1fe69249e0534e6e,Log network changes as INFO rather than DEBUG,ABANDONED,2013-08-19 17:10:58.000000000,2013-09-04 14:08:20.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5511}, {'_account_id': 5652}, {'_account_id': 8125}]","[{'number': 1, 'created': '2013-08-19 17:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0f6c52336bb5041551fd6be7a68370b259c62778', 'message': 'Log network changes as INFO rather than DEBUG.\n\nSignificant changes such as creating or deleting bridges, IP addresses,\nroutes, and network devices can seriously affect the functionality of\nthe node.  We should log them as INFO so they show up by default, to\ngive administrators a better chance to see the source of possible\nnetwork problems.\n\nFixes bug #1214036\n\nChange-Id: I45e12791f36f64d681f868ea1fe69249e0534e6e\n'}, {'number': 2, 'created': '2013-08-20 18:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/af629267542932beb0cc03d9f0f709a237f641ff', 'message': 'Log network changes as INFO rather than DEBUG\n\nSignificant changes such as creating or deleting bridges, IP addresses,\nroutes, and network devices can seriously affect the functionality of\nthe node.  We should log them as INFO so they show up by default, to\ngive administrators a better chance to see the source of possible\nnetwork problems.\n\nFixes bug #1214036\n\nChange-Id: I45e12791f36f64d681f868ea1fe69249e0534e6e\n'}, {'number': 3, 'created': '2013-08-28 14:23:11.000000000', 'files': ['nova/virt/libvirt/vif.py', 'nova/network/linux_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bf27a0cb5707a1022bd9dd576c3ec6fd73537e10', 'message': 'Log network changes as INFO rather than DEBUG\n\nSignificant changes such as creating or deleting bridges, IP addresses,\nroutes, and network devices can seriously affect the functionality of\nthe node.  We should log them as INFO so they show up by default, to\ngive administrators a better chance to see the source of possible\nnetwork problems.\n\nFixes bug #1214036\n\nChange-Id: I45e12791f36f64d681f868ea1fe69249e0534e6e\n'}]",4,42689,bf27a0cb5707a1022bd9dd576c3ec6fd73537e10,18,8,3,5652,,,0,"Log network changes as INFO rather than DEBUG

Significant changes such as creating or deleting bridges, IP addresses,
routes, and network devices can seriously affect the functionality of
the node.  We should log them as INFO so they show up by default, to
give administrators a better chance to see the source of possible
network problems.

Fixes bug #1214036

Change-Id: I45e12791f36f64d681f868ea1fe69249e0534e6e
",git fetch https://review.opendev.org/openstack/nova refs/changes/89/42689/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/vif.py', 'nova/network/linux_net.py']",2,0f6c52336bb5041551fd6be7a68370b259c62778,bug/1214036,"import logging as stdlib_logging run_as_root=True, check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) run_as_root=True, check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) run_as_root=True, check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) 'dev', dev, run_as_root=True, loglevel=stdlib_logging.INFO) run_as_root=True, check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) run_as_root=True, check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) run_as_root=True, loglevel=stdlib_logging.INFO) 'dev', dev, run_as_root=True, loglevel=stdlib_logging.INFO) run_as_root=True, check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) run_as_root=True, check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) _execute('brctl', 'addbr', bridge, run_as_root=True, loglevel=stdlib_logging.INFO) _execute('brctl', 'setfd', bridge, 0, run_as_root=True, loglevel=stdlib_logging.INFO) _execute('brctl', 'stp', bridge, 'off', run_as_root=True, loglevel=stdlib_logging.INFO) _execute('ip', 'link', 'set', bridge, 'up', run_as_root=True, loglevel=stdlib_logging.INFO) check_exit_code=False, run_as_root=True, loglevel=stdlib_logging.INFO) run_as_root=True, check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) run_as_root=True, check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) run_as_root=True, loglevel=stdlib_logging.INFO) utils.execute('brctl', 'addbr', bridge, run_as_root=True, loglevel=stdlib_logging.INFO) utils.execute('brctl', 'setfd', bridge, str(0), run_as_root=True, loglevel=stdlib_logging.INFO) utils.execute('brctl', 'stp', bridge, 'off', run_as_root=True, loglevel=stdlib_logging.INFO) run_as_root=True, check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO) run_as_root=True, check_exit_code=[0, 2, 254], loglevel=stdlib_logging.INFO)"," run_as_root=True, check_exit_code=[0, 2, 254]) run_as_root=True, check_exit_code=[0, 2, 254]) run_as_root=True, check_exit_code=[0, 2, 254]) 'dev', dev, run_as_root=True) run_as_root=True, check_exit_code=[0, 2, 254]) run_as_root=True, check_exit_code=[0, 2, 254]) run_as_root=True) 'dev', dev, run_as_root=True) run_as_root=True, check_exit_code=[0, 2, 254]) run_as_root=True, check_exit_code=[0, 2, 254]) check_exit_code=[0, 2, 254]) check_exit_code=[0, 2, 254]) _execute('brctl', 'addbr', bridge, run_as_root=True) _execute('brctl', 'setfd', bridge, 0, run_as_root=True) _execute('brctl', 'stp', bridge, 'off', run_as_root=True) _execute('ip', 'link', 'set', bridge, 'up', run_as_root=True) check_exit_code=False, run_as_root=True) run_as_root=True, check_exit_code=[0, 2, 254]) run_as_root=True, check_exit_code=[0, 2, 254]) run_as_root=True) utils.execute('brctl', 'addbr', bridge, run_as_root=True) utils.execute('brctl', 'setfd', bridge, str(0), run_as_root=True) utils.execute('brctl', 'stp', bridge, 'off', run_as_root=True) run_as_root=True, check_exit_code=[0, 2, 254]) check_exit_code=[0, 2, 254]) run_as_root=True, check_exit_code=[0, 2, 254])",82,42
openstack%2Fceilometer~master~I0a6af67659b035c0aab80cfd423f6642214298d8,openstack/ceilometer,master,I0a6af67659b035c0aab80cfd423f6642214298d8,Alarm history storage implementation for mongodb,MERGED,2013-08-27 09:20:21.000000000,2013-09-04 14:00:39.000000000,2013-09-04 14:00:39.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 4715}, {'_account_id': 6682}, {'_account_id': 7763}]","[{'number': 1, 'created': '2013-08-27 09:20:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3fad6ff46e2d31aad55eabf16ff61fc023581bda', 'message': 'Alarm history storage implementation for mongodb\n\nTest coverage is provided by the alarm scenario tests\nincluded in a prior patch.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: I0a6af67659b035c0aab80cfd423f6642214298d8\n'}, {'number': 2, 'created': '2013-08-27 09:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/19e52a996bbfe6e2cda26ceac22d818f502b30d3', 'message': 'Alarm history storage implementation for mongodb\n\nTest coverage is provided by the alarm scenario tests\nincluded in a prior patch.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: I0a6af67659b035c0aab80cfd423f6642214298d8\n'}, {'number': 3, 'created': '2013-08-27 15:39:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/56067940b06ce1d16ec1e4be725dc88d386f888f', 'message': 'Alarm history storage implementation for mongodb\n\nTest coverage is provided by the alarm scenario tests\nincluded in a prior patch.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: I0a6af67659b035c0aab80cfd423f6642214298d8\n'}, {'number': 4, 'created': '2013-08-27 16:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/65ed0c72b211049df414af1ff5f73af6c9bd44c4', 'message': 'Alarm history storage implementation for mongodb\n\nTest coverage is provided by the alarm scenario tests\nincluded in a prior patch.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: I0a6af67659b035c0aab80cfd423f6642214298d8\n'}, {'number': 5, 'created': '2013-08-27 18:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/37e1ad889cef95a3b141c6aebbb3f75ff5d35b58', 'message': 'Alarm history storage implementation for mongodb\n\nTest coverage is provided by the alarm scenario tests\nincluded in a prior patch.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: I0a6af67659b035c0aab80cfd423f6642214298d8\n'}, {'number': 6, 'created': '2013-08-28 13:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/98b106c088441d2f2e981e75c21ee89f057dc1ad', 'message': 'Alarm history storage implementation for mongodb\n\nTest coverage is provided by the alarm scenario tests\nincluded in a prior patch.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: I0a6af67659b035c0aab80cfd423f6642214298d8\n'}, {'number': 7, 'created': '2013-08-28 14:32:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3dcda09867e1cbd3eaa305a4f5077e284509602b', 'message': 'Alarm history storage implementation for mongodb\n\nTest coverage is provided by the alarm scenario tests\nincluded in a prior patch.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: I0a6af67659b035c0aab80cfd423f6642214298d8\n'}, {'number': 8, 'created': '2013-08-29 20:15:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b1ee1f64daecd5ead004f92ae92ffe1aeea02425', 'message': 'Alarm history storage implementation for mongodb\n\nTest coverage is provided by the alarm scenario tests\nincluded in a prior patch.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: I0a6af67659b035c0aab80cfd423f6642214298d8\n'}, {'number': 9, 'created': '2013-09-02 11:09:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1787b3de3e0eb2cad07e23140739a9c66fbed74e', 'message': 'Alarm history storage implementation for mongodb\n\nTest coverage is provided by the alarm scenario tests\nincluded in a prior patch.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: I0a6af67659b035c0aab80cfd423f6642214298d8\n'}, {'number': 10, 'created': '2013-09-03 11:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9b076d8e44618a1d874ec2fafab35c97052975c8', 'message': 'Alarm history storage implementation for mongodb\n\nTest coverage is provided by the alarm scenario tests\nincluded in a prior patch.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: I0a6af67659b035c0aab80cfd423f6642214298d8\n'}, {'number': 11, 'created': '2013-09-03 13:22:04.000000000', 'files': ['tests/api/v2/test_alarm_scenarios.py', 'ceilometer/storage/impl_mongodb.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7460c98f03cd38da88b1d2aaef8077802904d8df', 'message': 'Alarm history storage implementation for mongodb\n\nTest coverage is provided by the alarm scenario tests\nincluded in a prior patch.\n\nPartially implements bp alarm-audit-api\n\nChange-Id: I0a6af67659b035c0aab80cfd423f6642214298d8\n'}]",10,43850,7460c98f03cd38da88b1d2aaef8077802904d8df,49,9,11,2284,,,0,"Alarm history storage implementation for mongodb

Test coverage is provided by the alarm scenario tests
included in a prior patch.

Partially implements bp alarm-audit-api

Change-Id: I0a6af67659b035c0aab80cfd423f6642214298d8
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/50/43850/5 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/impl_mongodb.py', 'README.rst']",2,3fad6ff46e2d31aad55eabf16ff61fc023581bda,,, ,11,4
openstack%2Fceilometer~master~I68d5e6dcf3b71c52f3259bbe24269695349bc267,openstack/ceilometer,master,I68d5e6dcf3b71c52f3259bbe24269695349bc267,Change resource.resource_metadata column type to Text,ABANDONED,2013-09-04 12:57:20.000000000,2013-09-04 13:58:23.000000000,,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 6537}, {'_account_id': 8106}]","[{'number': 1, 'created': '2013-09-04 12:57:20.000000000', 'files': ['ceilometer/storage/sqlalchemy/alembic/versions/5462a731d0bc_fix_resource_resourc.py', 'ceilometer/storage/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/838a3b0ae9aac793487aade77602a4331f4e9353', 'message': 'Change resource.resource_metadata column type to Text\n\nThe existing resource.resource_metadata column size is 5k chars, which is not enough for some large JSON metadata payload, so change to as Text column to make sure store all JSON string without truncating.\n\nFixed bug #1220683\n\nChange-Id: I68d5e6dcf3b71c52f3259bbe24269695349bc267\n'}]",0,45054,838a3b0ae9aac793487aade77602a4331f4e9353,3,4,1,8106,,,0,"Change resource.resource_metadata column type to Text

The existing resource.resource_metadata column size is 5k chars, which is not enough for some large JSON metadata payload, so change to as Text column to make sure store all JSON string without truncating.

Fixed bug #1220683

Change-Id: I68d5e6dcf3b71c52f3259bbe24269695349bc267
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/54/45054/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/sqlalchemy/alembic/versions/5462a731d0bc_fix_resource_resourc.py', 'ceilometer/storage/sqlalchemy/models.py']",2,838a3b0ae9aac793487aade77602a4331f4e9353,bug/1220683, resource_metadata = Column(JSONEncodedDict()), resource_metadata = Column(JSONEncodedDict(5000)),52,1
openstack%2Ftaskflow~master~I1f0a9c5e8a08d3ad0441b86ca5a847af86826b48,openstack/taskflow,master,I1f0a9c5e8a08d3ad0441b86ca5a847af86826b48,Thread safe storage,ABANDONED,2013-09-02 15:58:37.000000000,2013-09-04 13:54:59.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 7366}]","[{'number': 1, 'created': '2013-09-02 15:58:37.000000000', 'files': ['taskflow/engines/action_engine/seq_action.py', 'taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/parallel_action.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/utils.py', 'taskflow/engines/action_engine/task_action.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/acc6ff4d0e04ae3de57f31938124dbb222e378a1', 'message': 'Thread safe storage\n\nFor engines that run task concurrently it is important to serialize\nstorage access. This commit adds such storage class and uses it\nin MultiThreadedEngine.\n\nChange-Id: I1f0a9c5e8a08d3ad0441b86ca5a847af86826b48\n'}]",6,44736,acc6ff4d0e04ae3de57f31938124dbb222e378a1,8,4,1,7366,,,0,"Thread safe storage

For engines that run task concurrently it is important to serialize
storage access. This commit adds such storage class and uses it
in MultiThreadedEngine.

Change-Id: I1f0a9c5e8a08d3ad0441b86ca5a847af86826b48
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/36/44736/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/seq_action.py', 'taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/parallel_action.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/utils.py', 'taskflow/engines/action_engine/task_action.py']",7,acc6ff4d0e04ae3de57f31938124dbb222e378a1,enp," def __init__(self, block, engine): engine.storage.set_result_mapping(self._id, self._result_mapping) kwargs = engine.storage.fetch_mapped_args(self._args_mapping) kwargs = engine.storage.fetch_mapped_args(self._args_mapping)"," def __init__(self, block, _to_action): def _build_arguments(self, storage): return dict((key, storage.fetch(name)) for key, name in self._args_mapping.iteritems()) engine.storage.set_result_mapping(self._id, self._result_mapping) kwargs = self._build_arguments(engine.storage) kwargs = self._build_arguments(engine.storage)",55,20
openstack%2Ftaskflow~master~I9a18d9c27825e8e29cf6470224a23fa42d460547,openstack/taskflow,master,I9a18d9c27825e8e29cf6470224a23fa42d460547,MultiThreaded engine and parallel action,ABANDONED,2013-09-02 15:58:37.000000000,2013-09-04 13:54:36.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 7366}]","[{'number': 1, 'created': '2013-09-02 15:58:37.000000000', 'files': ['taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/parallel_action.py', 'taskflow/engines/action_engine/__init__.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/examples/calculate_in_parallel.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6381152efe9d2fed04d7426a8abc73a13b811104', 'message': 'MultiThreaded engine and parallel action\n\n1. MultiThreaded engine was implemented to execute tasks in parallel.\n2. Added parallel action that executes and reverts tasks in parallel.\n3. Examples and tests were updated.\n\nChange-Id: I9a18d9c27825e8e29cf6470224a23fa42d460547\n'}]",13,44735,6381152efe9d2fed04d7426a8abc73a13b811104,13,4,1,7366,,,0,"MultiThreaded engine and parallel action

1. MultiThreaded engine was implemented to execute tasks in parallel.
2. Added parallel action that executes and reverts tasks in parallel.
3. Examples and tests were updated.

Change-Id: I9a18d9c27825e8e29cf6470224a23fa42d460547
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/35/44735/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/parallel_action.py', 'taskflow/engines/action_engine/__init__.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/examples/calculate_in_parallel.py']",5,6381152efe9d2fed04d7426a8abc73a13b811104,enp,engine = eng.MultiThreadedActionEngine(flow),engine = eng.SingleThreadedActionEngine(flow),254,2
openstack%2Ftaskflow~master~I594528c3745ea0da97f5bc5ff8715ba2d0ee2a7b,openstack/taskflow,master,I594528c3745ea0da97f5bc5ff8715ba2d0ee2a7b,ActionEngine: Save and re-raise exception on flow failure,ABANDONED,2013-08-28 15:07:10.000000000,2013-09-04 13:53:31.000000000,,"[{'_account_id': 3}, {'_account_id': 7366}]","[{'number': 1, 'created': '2013-08-28 15:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1d0bc9a2108ed7b6551a761a3dd994023cf22bbd', 'message': 'ActionEngine: Save and re-raise exception on flow failure\n\nWhen a task fails (raises an exception) this exception is saved in the\nengine and re-raised after flow is reverted.\n\nChange-Id: I594528c3745ea0da97f5bc5ff8715ba2d0ee2a7b\n'}, {'number': 2, 'created': '2013-09-03 13:21:12.000000000', 'files': ['taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_action_engine.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dfb78f70f79ed928300dbc7208dacd0de3d0259a', 'message': 'ActionEngine: Save and re-raise exception on flow failure\n\nWhen a task fails (raises an exception) this exception is saved in the\nengine and re-raised after flow is reverted.\n\nChange-Id: I594528c3745ea0da97f5bc5ff8715ba2d0ee2a7b\n'}]",0,44072,dfb78f70f79ed928300dbc7208dacd0de3d0259a,4,2,2,7366,,,0,"ActionEngine: Save and re-raise exception on flow failure

When a task fails (raises an exception) this exception is saved in the
engine and re-raised after flow is reverted.

Change-Id: I594528c3745ea0da97f5bc5ff8715ba2d0ee2a7b
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/72/44072/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_action_engine.py']",2,1d0bc9a2108ed7b6551a761a3dd994023cf22bbd,enp," with self.assertRaisesRegexp(RuntimeError, '^Woot'): engine.run() with self.assertRaisesRegexp(RuntimeError, '^Woot'): engine.run() with self.assertRaisesRegexp(RuntimeError, '^Woot'): engine.run()", engine.run() engine.run() engine.run(),14,3
openstack%2Ftaskflow~master~Ib327408c589f2f90815c5402ff75cf0dfa4d021d,openstack/taskflow,master,Ib327408c589f2f90815c5402ff75cf0dfa4d021d,Pass only required arguments to task,ABANDONED,2013-08-28 15:07:10.000000000,2013-09-04 13:53:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7366}]","[{'number': 1, 'created': '2013-08-28 15:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e319a44ee851407fc7e97915f2b0904d35bfe7eb', 'message': ""Pass only required arguments to task\n\nWhen task is executed, we don't dump all our storage onto it, but\nfetch only things that are required.\n\nChange-Id: Ib327408c589f2f90815c5402ff75cf0dfa4d021d\n""}, {'number': 2, 'created': '2013-09-03 12:50:22.000000000', 'files': ['taskflow/storage.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/engines/action_engine/task_action.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4c36e86153198dbe0196d3a5dfff6bc1c306c34b', 'message': ""Pass only required arguments to task\n\nWhen task is executed, we don't dump all our storage onto it, but\nfetch only things that are required.\n\nChange-Id: Ib327408c589f2f90815c5402ff75cf0dfa4d021d\n""}]",3,44070,4c36e86153198dbe0196d3a5dfff6bc1c306c34b,7,3,2,7366,,,0,"Pass only required arguments to task

When task is executed, we don't dump all our storage onto it, but
fetch only things that are required.

Change-Id: Ib327408c589f2f90815c5402ff75cf0dfa4d021d
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/70/44070/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/storage.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/tests/unit/test_action_engine.py']",4,e319a44ee851407fc7e97915f2b0904d35bfe7eb,enp,"from taskflow import exceptionsclass MultiargsTask(task.Task): def __call__(self, a, b, c): return a + b + c def test_arguments_passing(self): flow = blocks.Task(MultiargsTask, save_as='result') engine = self._make_engine(flow) engine.storage.inject({'a': 1, 'b': 4, 'c': 9, 'x': 17}) engine.run() self.assertEquals(engine.storage.fetch_all(), { 'a': 1, 'b': 4, 'c': 9, 'x': 17, 'result': 14, }) def test_arguments_missing(self): flow = blocks.Task(MultiargsTask, save_as='result') engine = self._make_engine(flow) engine.storage.inject({'a': 1, 'b': 4, 'x': 17}) with self.assertRaisesRegexp(exceptions.NotFound, ""^Name 'c' is not mapped""): engine.run() ",,57,5
openstack%2Ftaskflow~master~I4be3789a5ee94550980fa1f61cc283249e6c4618,openstack/taskflow,master,I4be3789a5ee94550980fa1f61cc283249e6c4618,Implement notifications for action-based engine,ABANDONED,2013-08-28 15:07:10.000000000,2013-09-04 13:52:49.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7366}]","[{'number': 1, 'created': '2013-08-28 15:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/29ba1f0464d955871756701848a6336c4263e710', 'message': 'Implement notifications for action-based engine\n\nEngine should expose transition notifier which allows to register\ncallbacks to listen to task state changes.\n\nPartially implements blueprint patterns-and-engines\n\nChange-Id: I4be3789a5ee94550980fa1f61cc283249e6c4618\n'}, {'number': 2, 'created': '2013-09-03 13:14:15.000000000', 'files': ['taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/engines/action_engine/task_action.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/53967eb9c2efbd471838eda8b4ae951e09a93451', 'message': 'Implement notifications for action-based engine\n\nEngine should expose transition notifier which allows to register\ncallbacks to listen to task state changes.\n\nPartially implements blueprint patterns-and-engines\n\nChange-Id: I4be3789a5ee94550980fa1f61cc283249e6c4618\n'}]",0,44071,53967eb9c2efbd471838eda8b4ae951e09a93451,5,3,2,7366,,,0,"Implement notifications for action-based engine

Engine should expose transition notifier which allows to register
callbacks to listen to task state changes.

Partially implements blueprint patterns-and-engines

Change-Id: I4be3789a5ee94550980fa1f61cc283249e6c4618
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/71/44071/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/engine.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/tests/unit/test_action_engine.py']",3,29ba1f0464d955871756701848a6336c4263e710,enp,"class NastyTask(task.Task): def __call__(self, **kwargs): pass def revert(self, **kwargs): raise RuntimeError('Gotcha!') @staticmethod def _callback(state, values, details): name = details.get('task_name', '<unknown>') values.append('%s %s' % (name, state)) def test_run_task_with_notifications(self): flow = blocks.Task(TestTask(self.values, name='task1')) engine = self._make_engine(flow) engine.task_notifier.register('*', self._callback, kwargs={'values': self.values}) engine.run() self.assertEquals(self.values, ['task1 RUNNING', 'task1', 'task1 SUCCESS']) def test_failing_task_with_notifications(self): flow = blocks.Task(FailingTask('task1')) engine = self._make_engine(flow) engine.task_notifier.register('*', self._callback, kwargs={'values': self.values}) engine.run() self.assertEquals(self.values, ['task1 RUNNING', 'task1 FAILURE']) def test_revert_exception_is_reraised(self): flow = blocks.LinearFlow().add( blocks.Task(NastyTask), blocks.Task(FailingTask) ) engine = self._make_engine(flow) with self.assertRaisesRegexp(RuntimeError, '^Gotcha'): engine.run() ",,62,9
openstack%2Ftaskflow~master~I29a40cc8c04679b8b17af92f1f5e8eccb663cccf,openstack/taskflow,master,I29a40cc8c04679b8b17af92f1f5e8eccb663cccf,Action engines: arguments rebinding,ABANDONED,2013-08-28 15:07:10.000000000,2013-09-04 13:52:16.000000000,,"[{'_account_id': 3}, {'_account_id': 7366}]","[{'number': 1, 'created': '2013-08-28 15:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b9ada642c5fd5f3f2c7c00a6990b60e0a0a8bf27', 'message': ""Action engines: arguments rebinding\n\nThere are cases when value flow author wants to pass to task is stored\nwith name other then corresponding task argument. For that, This commit\nadds 'rebind_args' parameter to task block.\n\nThere are two possible way of using the parameter: first is to pass\ndictionary that maps task argument name to name of saved value; second,\nis to can pass a tuple or list of argument names, and values with that\nnames are passed to task.\n\nChange-Id: I29a40cc8c04679b8b17af92f1f5e8eccb663cccf\n""}, {'number': 2, 'created': '2013-09-03 13:25:30.000000000', 'files': ['taskflow/tests/unit/test_action_engine.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/blocks/task.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a430f20fa14596f3588b37c1694045134b721e51', 'message': ""Action engines: arguments rebinding\n\nThere are cases when value flow author wants to pass to task is stored\nwith name other then corresponding task argument. For that, This commit\nadds 'rebind_args' parameter to task block.\n\nThere are two possible way of using the parameter: first is to pass\ndictionary that maps task argument name to name of saved value; second,\nis to can pass a tuple or list of argument names, and values with that\nnames are passed to task.\n\nChange-Id: I29a40cc8c04679b8b17af92f1f5e8eccb663cccf\n""}]",0,44073,a430f20fa14596f3588b37c1694045134b721e51,4,2,2,7366,,,0,"Action engines: arguments rebinding

There are cases when value flow author wants to pass to task is stored
with name other then corresponding task argument. For that, This commit
adds 'rebind_args' parameter to task block.

There are two possible way of using the parameter: first is to pass
dictionary that maps task argument name to name of saved value; second,
is to can pass a tuple or list of argument names, and values with that
names are passed to task.

Change-Id: I29a40cc8c04679b8b17af92f1f5e8eccb663cccf
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/73/44073/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/task_action.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/blocks/task.py']",3,b9ada642c5fd5f3f2c7c00a6990b60e0a0a8bf27,enp,"from taskflow import utilsdef _build_arg_mapping(rebind_args, task): if rebind_args is None: rebind_args = {} task_args = utils.get_required_callable_args(task) nargs = len(task_args) if isinstance(rebind_args, (list, tuple)): if len(rebind_args) < nargs: raise ValueError('Task %(name)s takes %(nargs)d positional ' 'arguments (%(real)d given)' % dict(name=task.name, nargs=nargs, real=len(rebind_args))) result = dict(zip(task_args, rebind_args[:nargs])) # extra rebind_args go to kwargs result.update((a, a) for a in rebind_args[nargs:]) return result elif isinstance(rebind_args, dict): result = dict((a, a) for a in task_args) result.update(rebind_args) return result else: raise TypeError('rebind_args should be list, tuple or dict') def __init__(self, task, uuid=None, save_as=None, rebind_args=None): if isinstance(self._task, type): self._task = self._task() self._args_mapping = _build_arg_mapping(rebind_args, self._task) @property def args_mapping(self): return self._args_mapping"," def __init__(self, task, uuid=None, save_as=None):",99,11
openstack%2Ftaskflow~master~Idcae8acfc142c4773839f67f07590d72bab8c9f3,openstack/taskflow,master,Idcae8acfc142c4773839f67f07590d72bab8c9f3,blocks: Implement syntax for saving task results,ABANDONED,2013-08-28 15:07:10.000000000,2013-09-04 13:51:32.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7366}]","[{'number': 1, 'created': '2013-08-28 15:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/bffbcfb5a721f790cd28d630a2f7db23807d36d6', 'message': ""blocks: Implement syntax for saving task results\n\nTo indicate how task result should be saved, flow developer adds\n'save_as' parameter to task block constructor. This parameter\nshould be a string indicating a name of storage slot or a tuple\nof names, in which case task should return a tuple of values of\nthe same size.\n\nOnly results saved this way are visible to tasks that are executed\nlater on.\n\nPartially implements blueprint patterns-and-engines\n\nChange-Id: Idcae8acfc142c4773839f67f07590d72bab8c9f3\n""}, {'number': 2, 'created': '2013-09-03 12:35:52.000000000', 'files': ['taskflow/storage.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/blocks/task.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/29b06e260b7604ba83d7faaf96c5469dc77d7935', 'message': ""blocks: Implement syntax for saving task results\n\nTo indicate how task result should be saved, flow developer adds\n'save_as' parameter to task block constructor. This parameter\nshould be a string indicating a name of storage slot or a tuple\nof names, in which case task should return a tuple of values of\nthe same size.\n\nOnly results saved this way are visible to tasks that are executed\nlater on.\n\nPartially implements blueprint patterns-and-engines\n\nCo-authored-by: Anastasia Karpinska <akarpinska at griddynamics.com>\nChange-Id: Idcae8acfc142c4773839f67f07590d72bab8c9f3\n""}]",0,44069,29b06e260b7604ba83d7faaf96c5469dc77d7935,5,3,2,7366,,,0,"blocks: Implement syntax for saving task results

To indicate how task result should be saved, flow developer adds
'save_as' parameter to task block constructor. This parameter
should be a string indicating a name of storage slot or a tuple
of names, in which case task should return a tuple of values of
the same size.

Only results saved this way are visible to tasks that are executed
later on.

Partially implements blueprint patterns-and-engines

Co-authored-by: Anastasia Karpinska <akarpinska at griddynamics.com>
Change-Id: Idcae8acfc142c4773839f67f07590d72bab8c9f3
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/69/44069/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/storage.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/blocks/task.py']",5,bffbcfb5a721f790cd28d630a2f7db23807d36d6,enp,"def _save_as_to_mapping(save_as): """"""Convert save_as to mapping name => index Result should follow taskflow.storage.Storage convention for mappings. """""" if save_as is None: return None if isinstance(save_as, basestring): return {save_as: None} elif isinstance(save_as, tuple): return dict((key, num) for num, key in enumerate(save_as)) raise TypeError('Task block save_as parameter ' 'should be str or tuple, not %r' % save_as) def __init__(self, task, uuid=None, save_as=None): self._result_mapping = _save_as_to_mapping(save_as) @property def result_mapping(self): return self._result_mapping"," def __init__(self, task, uuid=None):",159,5
openstack%2Ftaskflow~master~Ifb1f25f5c1db6d588f56b5f1a11e9927b8c3d125,openstack/taskflow,master,Ifb1f25f5c1db6d588f56b5f1a11e9927b8c3d125,Save task states to storage,ABANDONED,2013-09-02 15:58:37.000000000,2013-09-04 13:48:08.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-09-02 15:58:37.000000000', 'files': ['taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/blocks/task.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/77e1ce56412d6f818ed0b69e908a21f24a020ef3', 'message': ""Save task states to storage\n\nWe should persist states, so that's storage what should manage them.\n\nChange-Id: Ifb1f25f5c1db6d588f56b5f1a11e9927b8c3d125\n""}]",0,44737,77e1ce56412d6f818ed0b69e908a21f24a020ef3,2,1,1,7366,,,0,"Save task states to storage

We should persist states, so that's storage what should manage them.

Change-Id: Ifb1f25f5c1db6d588f56b5f1a11e9927b8c3d125
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/37/44737/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/blocks/task.py']",6,77e1ce56412d6f818ed0b69e908a21f24a020ef3,enp," def __init__(self, task, save_as=None, rebind_args=None):","from taskflow.openstack.common import uuidutils def __init__(self, task, uuid=None, save_as=None, rebind_args=None): if uuid is None: self._id = uuidutils.generate_uuid() else: self._id = str(uuid) def uuid(self): return self._id @property",52,22
openstack%2Ftaskflow~master~Ieeb3ebbf858f8ec99f5ce0822d18c77e1bc6ad68,openstack/taskflow,master,Ieeb3ebbf858f8ec99f5ce0822d18c77e1bc6ad68,Resume flow from storage,ABANDONED,2013-09-02 15:58:37.000000000,2013-09-04 13:47:51.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2013-09-02 15:58:37.000000000', 'files': ['taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/tests/unit/test_action_engine.py', 'taskflow/engines/action_engine/task_action.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0c0796c23b60964876205452c81b22367a93d42b', 'message': ""Resume flow from storage\n\nThis commit adds quick and somewhat dirty implementation of flow\nresumption from storage. The idea is that we run flow as normal,\nbut if task is already in SUCCESS state we don't run it.\n\nChange-Id: Ieeb3ebbf858f8ec99f5ce0822d18c77e1bc6ad68\n""}]",1,44738,0c0796c23b60964876205452c81b22367a93d42b,3,2,1,7366,,,0,"Resume flow from storage

This commit adds quick and somewhat dirty implementation of flow
resumption from storage. The idea is that we run flow as normal,
but if task is already in SUCCESS state we don't run it.

Change-Id: Ieeb3ebbf858f8ec99f5ce0822d18c77e1bc6ad68
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/38/44738/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/storage.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/tests/unit/test_action_engine.py']",5,0c0796c23b60964876205452c81b22367a93d42b,enp,"from taskflow import storage def _make_engine(self, flow, storage=None): return eng.SingleThreadedActionEngine(flow, storage) def test_sequential_flow_two_tasks_with_resumption(self): flow = blocks.LinearFlow().add( blocks.Task(TestTask(self.values, name='task1'), save_as='x1'), blocks.Task(TestTask(self.values, name='task2'), save_as='x2') ) # NOTE(imelnikov): we don't have means to forcibly abort flow yet, # so we just pretend that a task was already run st = storage.Storage() st.add_task(task_name='task1', uuid='42') st.save('42', 17) self._make_engine(flow, st).run() self.assertEquals(self.values, ['task2']) self.assertEquals(st.fetch_all(), {'x1': 17, 'x2': 5})"," def _make_engine(self, flow): return eng.SingleThreadedActionEngine(flow)",63,10
openstack%2Ftaskflow~master~I4924bc3028d7a2cd59ecb44cbfaf1b054ec450dc,openstack/taskflow,master,I4924bc3028d7a2cd59ecb44cbfaf1b054ec450dc,Rewrite storage using persistence layer,ABANDONED,2013-09-02 15:58:37.000000000,2013-09-04 13:47:39.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7366}]","[{'number': 1, 'created': '2013-09-02 15:58:37.000000000', 'files': ['taskflow/storage.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/persistence/flowdetail.py', 'taskflow/engines/action_engine/task_action.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/85833a072abdf31da26e2da47faa0873b764e2b2', 'message': 'Rewrite storage using persistence layer\n\nNow we save task results and states into logbooks.\n\nChange-Id: I4924bc3028d7a2cd59ecb44cbfaf1b054ec450dc\n'}]",3,44739,85833a072abdf31da26e2da47faa0873b764e2b2,5,3,1,7366,,,0,"Rewrite storage using persistence layer

Now we save task results and states into logbooks.

Change-Id: I4924bc3028d7a2cd59ecb44cbfaf1b054ec450dc
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/39/44739/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/storage.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/persistence/flowdetail.py', 'taskflow/engines/action_engine/task_action.py']",4,85833a072abdf31da26e2da47faa0873b764e2b2,enp," engine.storage.add_task(task_name=self.name, uuid=self.uuid) engine.storage.set_result_mapping(self.uuid, self._result_mapping)"," engine.change_state(self, states.PENDING) engine.storage.set_result_mapping(self._id, self._result_mapping)",93,34
openstack%2Ftaskflow~master~Iedf73efcb3adcacffaeb85d21b458dc6eeb804a6,openstack/taskflow,master,Iedf73efcb3adcacffaeb85d21b458dc6eeb804a6,Make FlowDetail an engine constructor parameter,ABANDONED,2013-09-02 15:58:37.000000000,2013-09-04 13:47:22.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-09-02 15:58:37.000000000', 'files': ['taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_action_engine.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8d8a57cae104a80d89ba8de3a42483b88c25cda8', 'message': 'Make FlowDetail an engine constructor parameter\n\nEngine should run a flow using given flow detail object to track\ntask states and results. Engine should resume flow if it was\nalready run using state from given flow detail object.\n\nChange-Id: Iedf73efcb3adcacffaeb85d21b458dc6eeb804a6\n'}]",0,44740,8d8a57cae104a80d89ba8de3a42483b88c25cda8,2,1,1,7366,,,0,"Make FlowDetail an engine constructor parameter

Engine should run a flow using given flow detail object to track
task states and results. Engine should resume flow if it was
already run using state from given flow detail object.

Change-Id: Iedf73efcb3adcacffaeb85d21b458dc6eeb804a6
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/40/44740/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/engine.py', 'taskflow/tests/unit/test_action_engine.py']",2,8d8a57cae104a80d89ba8de3a42483b88c25cda8,enp,"from taskflow.persistence import taskdetail from taskflow import states def _make_engine(self, _flow, _flow_detail=None): # Create FlowDetail as if we already run task1 fd = storage.temporary_flow_detail() td = taskdetail.TaskDetail(name='task1', uuid='42') td.state = states.SUCCESS td.results = 17 fd.add(td) fd.save() td.save() engine = self._make_engine(flow, fd) engine.run() self.assertEquals(engine.storage.fetch_all(),class SingleThreadedEngineTest(EngineTaskTest, EngineLinearFlowTest, EngineParallelFlowTest, test.TestCase): def _make_engine(self, flow, flow_detail=None): return eng.SingleThreadedActionEngine(flow, flow_detail=flow_detail) def _make_engine(self, flow, flow_detail=None): return eng.MultiThreadedActionEngine(flow, flow_detail=flow_detail)"," def _make_engine(self, _flow): class SingleThreadedEngineTest(EngineTaskTest, EngineLinearFlowTest, EngineParallelFlowTest, test.TestCase): def _make_engine(self, flow, storage=None): return eng.SingleThreadedActionEngine(flow, storage) # NOTE(imelnikov): we don't have means to forcibly abort flow yet, # so we just pretend that a task was already run st = storage.Storage() st.add_task(task_name='task1', uuid='42') st.save('42', 17) self._make_engine(flow, st).run() self.assertEquals(st.fetch_all(), def _make_engine(self, flow): return eng.MultiThreadedActionEngine(flow)",29,24
openstack%2Fheat~master~Ie1dda28f8c643dc8ad66f3bb51f9ef8c59df6f52,openstack/heat,master,Ie1dda28f8c643dc8ad66f3bb51f9ef8c59df6f52,Add tools/conf/README,ABANDONED,2013-09-02 15:04:36.000000000,2013-09-04 13:43:51.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}]","[{'number': 1, 'created': '2013-09-02 15:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/328ec255a76e55af9be1a21a8fc2bb94c736d7a5', 'message': 'Add tools/conf/README\n\nAdd a simple readme describing how to use the scripts.\n\nChange-Id: Ie1dda28f8c643dc8ad66f3bb51f9ef8c59df6f52\n'}, {'number': 2, 'created': '2013-09-02 22:00:10.000000000', 'files': ['tools/conf/README'], 'web_link': 'https://opendev.org/openstack/heat/commit/504d79596833de5e7808f4d0ff716139c93e3dce', 'message': 'Add tools/conf/README\n\nAdd a simple readme describing how to use the scripts.\n\nChange-Id: Ie1dda28f8c643dc8ad66f3bb51f9ef8c59df6f52\n'}]",0,44722,504d79596833de5e7808f4d0ff716139c93e3dce,5,3,2,4328,,,0,"Add tools/conf/README

Add a simple readme describing how to use the scripts.

Change-Id: Ie1dda28f8c643dc8ad66f3bb51f9ef8c59df6f52
",git fetch https://review.opendev.org/openstack/heat refs/changes/22/44722/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/conf/README'],1,328ec255a76e55af9be1a21a8fc2bb94c736d7a5,conf_fix,"Use the scripts here to keep heat.conf.sample aligned with the code: Both need to be run from the top-level of the heat repo, to check for required updates, or to regenerate a new sample file as follows. cd ../../ ./tools/conf/check_uptodate.sh ./tools/conf/generate_sample.sh ",,8,0
openstack%2Fheat~master~I7e14567527063c9807d9db1956b59e523827c72e,openstack/heat,master,I7e14567527063c9807d9db1956b59e523827c72e,Remove broken generate_sample.sh,ABANDONED,2013-09-02 14:58:21.000000000,2013-09-04 13:43:19.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}]","[{'number': 1, 'created': '2013-09-02 14:58:21.000000000', 'files': ['tools/config/generate_sample.sh'], 'web_link': 'https://opendev.org/openstack/heat/commit/0e35812c44c134e4e77d712dcea4608526374a3b', 'message': 'Remove broken generate_sample.sh\n\nWe seem to have two copies of generate_sample.sh, only one of which\nworks properly, so remove the broken one\n\nChange-Id: I7e14567527063c9807d9db1956b59e523827c72e\n'}]",0,44720,0e35812c44c134e4e77d712dcea4608526374a3b,4,3,1,4328,,,0,"Remove broken generate_sample.sh

We seem to have two copies of generate_sample.sh, only one of which
works properly, so remove the broken one

Change-Id: I7e14567527063c9807d9db1956b59e523827c72e
",git fetch https://review.opendev.org/openstack/heat refs/changes/20/44720/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/config/generate_sample.sh'],1,0e35812c44c134e4e77d712dcea4608526374a3b,conf_fix,,"#!/usr/bin/env bash print_hint() { echo ""Try \`${0##*/} --help' for more information."" >&2 } PARSED_OPTIONS=$(getopt -n ""${0##*/}"" -o hb:p:o: \ --long help,base-dir:,package-name:,output-dir: -- ""$@"") if [ $? != 0 ] ; then print_hint ; exit 1 ; fi eval set -- ""$PARSED_OPTIONS"" while true; do case ""$1"" in -h|--help) echo ""${0##*/} [options]"" echo """" echo ""options:"" echo ""-h, --help show brief help"" echo ""-b, --base-dir=DIR Project base directory (required)"" echo ""-p, --package-name=NAME Project package name"" echo ""-o, --output-dir=DIR File output directory"" exit 0 ;; -b|--base-dir) shift BASEDIR=`echo $1 | sed -e 's/\/*$//g'` shift ;; -p|--package-name) shift PACKAGENAME=`echo $1` shift ;; -o|--output-dir) shift OUTPUTDIR=`echo $1 | sed -e 's/\/*$//g'` shift ;; --) break ;; esac done if [ -z $BASEDIR ] || ! [ -d $BASEDIR ] then echo ""${0##*/}: missing project base directory"" >&2 ; print_hint ; exit 1 fi PACKAGENAME=${PACKAGENAME:-${BASEDIR##*/}} OUTPUTDIR=${OUTPUTDIR:-$BASEDIR/etc} if ! [ -d $OUTPUTDIR ] then echo ""${0##*/}: cannot access \`$OUTPUTDIR': No such file or directory"" >&2 exit 1 fi BASEDIRESC=`echo $BASEDIR | sed -e 's/\//\\\\\//g'` FILES=$(find $BASEDIR/$PACKAGENAME -type f -name ""*.py"" ! -path ""*/tests/*"" \ -exec grep -l ""Opt("" {} + | sed -e ""s/^$BASEDIRESC\///g"" | sort -u) export EVENTLET_NO_GREENDNS=yes MODULEPATH=heat.openstack.common.config.generator OUTPUTFILE=$OUTPUTDIR/$PACKAGENAME.conf.sample python -m $MODULEPATH $FILES > $OUTPUTFILE ",0,69
openstack%2Fmurano-deployment~release-0.2~I55332c02533c42ce0ece8d89867180daca48b781,openstack/murano-deployment,release-0.2,I55332c02533c42ce0ece8d89867180daca48b781,Renamed murano-manual developers-guide,MERGED,2013-09-04 12:53:10.000000000,2013-09-04 13:05:49.000000000,2013-09-04 13:05:49.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-09-04 12:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/2c7a28457272c06f7d3293815b7ed8c1465e5014', 'message': 'Renamed murano-manual developers-guide\n\nChange-Id: I55332c02533c42ce0ece8d89867180daca48b781\n'}, {'number': 2, 'created': '2013-09-04 12:57:40.000000000', 'files': ['docs-builder/builder.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/ee4575e725901a3d90d3400dde935ba2a2788496', 'message': 'Renamed murano-manual developers-guide\n\nChange-Id: I55332c02533c42ce0ece8d89867180daca48b781\n'}]",0,45052,ee4575e725901a3d90d3400dde935ba2a2788496,7,2,2,7225,,,0,"Renamed murano-manual developers-guide

Change-Id: I55332c02533c42ce0ece8d89867180daca48b781
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/52/45052/1 && git format-patch -1 --stdout FETCH_HEAD,['docs-builder/builder.sh'],1,2c7a28457272c06f7d3293815b7ed8c1465e5014,," for manual in ""developers-guide"" ""murano-deployment-guide"""," for manual in ""murano-manual"" ""murano-deployment-guide""",1,1
openstack%2Fmurano-deployment~release-0.2~Ib02ddf2a4c5eefb851a1ce12ce515ef4b813bbc1,openstack/murano-deployment,release-0.2,Ib02ddf2a4c5eefb851a1ce12ce515ef4b813bbc1,Added feature to build master,MERGED,2013-09-04 12:46:44.000000000,2013-09-04 12:47:44.000000000,2013-09-04 12:47:44.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-09-04 12:46:44.000000000', 'files': ['docs-builder/builder.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/04568b1eafa23bb3a618dd5eab04186e5320fe6f', 'message': 'Added feature to build master\n\nChange-Id: Ib02ddf2a4c5eefb851a1ce12ce515ef4b813bbc1\n'}]",0,45051,04568b1eafa23bb3a618dd5eab04186e5320fe6f,5,2,1,7225,,,0,"Added feature to build master

Change-Id: Ib02ddf2a4c5eefb851a1ce12ce515ef4b813bbc1
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/51/45051/1 && git format-patch -1 --stdout FETCH_HEAD,['docs-builder/builder.sh'],1,04568b1eafa23bb3a618dd5eab04186e5320fe6f,,"for version in ""0.1"" ""0.2"" ""latest"" if [ ${version} = ""latest"" ]; then branch=""master"" else branch=""release-${version}"" fi git clone -b ${branch} git@github.com:stackforge/murano-docs.git docs-${version} built_manual=${TEMP}/murano-docs/${version}/${manual} cp ""target/docbkx/pdf/${manual}.pdf"" ""${built_manual}"" #clean-up rm -rf ""${TEMP}""","for version in ""0.1"" ""0.2"" git clone -b release-${version} git@github.com:stackforge/murano-docs.git docs-${version} built_manual=${TEMP}/murano-docs/docs/v${version}/${manual} cp ""target/docbkx/pdf/${manual}.pdf ${built_manual}""",14,4
openstack%2Fsahara~master~I96c6944b2081263967af0cc69617ca622a1c5a61,openstack/sahara,master,I96c6944b2081263967af0cc69617ca622a1c5a61,Remove an unncecessary loop from validation code,MERGED,2013-09-03 22:29:14.000000000,2013-09-04 12:39:47.000000000,2013-09-04 12:39:47.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6823}, {'_account_id': 7213}, {'_account_id': 7700}, {'_account_id': 7737}, {'_account_id': 8304}]","[{'number': 1, 'created': '2013-09-03 22:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/cd63f1d0549c017b29458f6be4c3fe6d5a244fe3', 'message': 'Remove an unncecessary loop from validation code\n\nIt looks like an additional loop was included, probably due to some\ncut and paste issue.\n\nChange-Id: I96c6944b2081263967af0cc69617ca622a1c5a61\nFixes:  bug #1220461\n'}, {'number': 2, 'created': '2013-09-03 22:30:33.000000000', 'files': ['savanna/plugins/hdp/validator.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/92926e0c183930b994343c87ce2a042f3c137168', 'message': 'Remove an unncecessary loop from validation code\n\nIt looks like an additional loop was included, probably due to some\ncut and paste issue.\n\nFixes:  bug #1220461\n\nChange-Id: I96c6944b2081263967af0cc69617ca622a1c5a61\n'}]",0,44965,92926e0c183930b994343c87ce2a042f3c137168,11,7,2,7737,,,0,"Remove an unncecessary loop from validation code

It looks like an additional loop was included, probably due to some
cut and paste issue.

Fixes:  bug #1220461

Change-Id: I96c6944b2081263967af0cc69617ca622a1c5a61
",git fetch https://review.opendev.org/openstack/sahara refs/changes/65/44965/2 && git format-patch -1 --stdout FETCH_HEAD,['savanna/plugins/hdp/validator.py'],1,cd63f1d0549c017b29458f6be4c3fe6d5a244fe3,bug/1220461," node_group = self._get_by_id(cluster.node_groups, ng_id) conductor.node_group_update(ctx, node_group, {'count': 0})"," for ng_id in additional: node_group = self._get_by_id(cluster.node_groups, ng_id) conductor.node_group_update(ctx, node_group, {'count': 0})",3,4
openstack%2Fsahara-dashboard~stable%2F0.2~I190a948b8780ea709516b51373f704c0c0a9fd2e,openstack/sahara-dashboard,stable/0.2,I190a948b8780ea709516b51373f704c0c0a9fd2e,Add highlight https urls to cluster info,MERGED,2013-09-03 11:19:20.000000000,2013-09-04 12:34:57.000000000,2013-09-04 12:34:57.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2013-09-03 11:19:20.000000000', 'files': ['AUTHORS', 'savannadashboard/clusters/tabs.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/0e192e541d268a3b4c0b7ca2e40acbb35c71e266', 'message': 'Add highlight https urls to cluster info\n\nChange-Id: I190a948b8780ea709516b51373f704c0c0a9fd2e\n(cherry picked from commit fe26593a14d296992b732fd6372ee1167162fc23)\n'}]",0,44854,0e192e541d268a3b4c0b7ca2e40acbb35c71e266,7,3,1,7710,,,0,"Add highlight https urls to cluster info

Change-Id: I190a948b8780ea709516b51373f704c0c0a9fd2e
(cherry picked from commit fe26593a14d296992b732fd6372ee1167162fc23)
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/54/44854/1 && git format-patch -1 --stdout FETCH_HEAD,"['AUTHORS', 'savannadashboard/clusters/tabs.py']",2,0e192e541d268a3b4c0b7ca2e40acbb35c71e266,," if str(val).startswith(('http://', 'https://')):"," if str(val).startswith(""http://""):",2,1
openstack%2Fmurano-deployment~release-0.2~I077d59f2a864ee8ccace72c35019be17680b8267,openstack/murano-deployment,release-0.2,I077d59f2a864ee8ccace72c35019be17680b8267,Fixed compatibility with Sh,MERGED,2013-09-04 12:07:35.000000000,2013-09-04 12:08:18.000000000,2013-09-04 12:08:18.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-09-04 12:07:35.000000000', 'files': ['docs-builder/builder.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/4775844b8c7066969ffcdc1d680a15b210846be0', 'message': 'Fixed compatibility with Sh\n\nChange-Id: I077d59f2a864ee8ccace72c35019be17680b8267\n'}]",0,45039,4775844b8c7066969ffcdc1d680a15b210846be0,5,2,1,7225,,,0,"Fixed compatibility with Sh

Change-Id: I077d59f2a864ee8ccace72c35019be17680b8267
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/39/45039/1 && git format-patch -1 --stdout FETCH_HEAD,['docs-builder/builder.sh'],1,4775844b8c7066969ffcdc1d680a15b210846be0,,"for version in ""0.1"" ""0.2""","VERSIONS[0]=""0.1"" VERSIONS[1]=""0.2"" for version in ${VERSIONS[@]}",1,4
openstack%2Fmurano-deployment~release-0.2~Ifbb6d989632ad2277bc1194bd9b440597c916851,openstack/murano-deployment,release-0.2,Ifbb6d989632ad2277bc1194bd9b440597c916851,Update script for building documentation,MERGED,2013-09-04 10:52:20.000000000,2013-09-04 11:47:55.000000000,2013-09-04 11:47:55.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7562}, {'_account_id': 8127}]","[{'number': 1, 'created': '2013-09-04 10:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/217f4d971990ef23b0ca045aeaf5dca73a072a1e', 'message': 'Update script for building documentation\n\nNow documentation built not from source checkouted by Jenkins, but\nchecked out explicitly from script. Also we checking out, building\nand publishing several versions at once. No landing page now\nexists.\n\nChange-Id: Ifbb6d989632ad2277bc1194bd9b440597c916851\n'}, {'number': 2, 'created': '2013-09-04 11:03:21.000000000', 'files': ['docs-builder/builder.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/0d1a1baba63ffd1b84c6ebb74d9542c2c12a7536', 'message': 'Update script for building documentation\n\nNow documentation built not from source checkouted by Jenkins, but\nchecked out explicitly from script. Also we checking out, building\nand publishing several versions at once. No landing page now\nexists.\n\nChange-Id: Ifbb6d989632ad2277bc1194bd9b440597c916851\n'}]",0,45032,0d1a1baba63ffd1b84c6ebb74d9542c2c12a7536,7,4,2,7225,,,0,"Update script for building documentation

Now documentation built not from source checkouted by Jenkins, but
checked out explicitly from script. Also we checking out, building
and publishing several versions at once. No landing page now
exists.

Change-Id: Ifbb6d989632ad2277bc1194bd9b440597c916851
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/32/45032/2 && git format-patch -1 --stdout FETCH_HEAD,['docs-builder/builder.sh'],1,217f4d971990ef23b0ca045aeaf5dca73a072a1e,feature/MRN-942," VERSIONS[0]=""0.1"" VERSIONS[1]=""0.2"" #create temp directory where we going to work TEMP=$PWD/temp-$(date +%s) mkdir ${TEMP}cd ${TEMP} git clone git@github.com:murano-docs/murano-docs.github.io.git murano-docs cd murano-docs ls -A1 | grep -v -e '\.git' | xargs git rm -rf for version in ${VERSIONS[@]} do cd ${TEMP} git clone -b release-${version} git@github.com:stackforge/murano-docs.git docs-${version} for manual in ""murano-manual"" ""murano-deployment-guide"" do cd ${TEMP}/docs-${version}/src/${manual} mvn clean generate-sources built_manual=${TEMP}/murano-docs/docs/v${version}/${manual} mkdir -p ${built_manual} cp -r target/docbkx/webhelp/${manual}/* ${built_manual} cp target/docbkx/pdf/${manual}.pdf ${built_manual} done donecd ${TEMP}/murano-docs git config user.email ""murano-eng@mirantis.com"" git config user.name ""murano-docs""git push origin master","# cd ~/testsrm -rf gh-pages git clone -b gh-pages git@github.com:Mirantis/murano-docs.git gh-pages cd gh-pages ls -A1 | grep -v -e 'CNAME' -e '\.git' -e '\.nojekyll' | xargs git rm -rf cd ~/tests #clone Murano Docs rm -rf murano-docs git clone https://github.com/stackforge/murano-docs #copy site cp murano-docs/site/index.html ~/tests/gh-pages/ #generate murano-manual cd murano-docs/src/murano-manual mvn clean generate-sources #copy murano-manual mkdir -p ~/tests/gh-pages/docs/murano-manual cp -r target/docbkx/webhelp/murano-manual/* ~/tests/gh-pages/docs/murano-manual cp target/docbkx/pdf/murano-manual.pdf ~/tests/gh-pages/docs/murano-manual cd ~/tests #generate murano-deployment-guide cd murano-docs/src/murano-deployment-guide mvn clean generate-sources #copy murano-deployment-guide mkdir -p ~/tests/gh-pages/docs/murano-deployment-guide cp -r target/docbkx/webhelp/murano-deployment-guide/* ~/tests/gh-pages/docs/murano-deployment-guide cp -r target/docbkx/pdf/murano-deployment-guide.pdf ~/tests/gh-pages/docs/murano-deployment-guide cd ~/testscd ~/tests/gh-pages git config user.email ""tnurlygayanov@mirantis.com"" git config user.name ""Timur Nurlygayanov""git push origin gh-pages",28,35
openstack%2Fmurano-agent~release-0.2~I5db00788c1384730df4ffd96827cdc5c1d14789b,openstack/murano-agent,release-0.2,I5db00788c1384730df4ffd96827cdc5c1d14789b,Added .gitreview,MERGED,2013-09-04 11:38:41.000000000,2013-09-04 11:38:59.000000000,2013-09-04 11:38:59.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2013-09-04 11:38:41.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/f006508eaf8787ca6926e2c9998d7f8c93a2c7db', 'message': 'Added .gitreview\n\nChange-Id: I5db00788c1384730df4ffd96827cdc5c1d14789b\n'}]",0,45036,f006508eaf8787ca6926e2c9998d7f8c93a2c7db,5,2,1,7225,,,0,"Added .gitreview

Change-Id: I5db00788c1384730df4ffd96827cdc5c1d14789b
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/36/45036/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,f006508eaf8787ca6926e2c9998d7f8c93a2c7db,,[gerrit] host=review.openstack.org port=29418 project=stackforge/murano-agent.git ,,4,0
openstack%2Fdiskimage-builder~master~I2feb615b2094d9d6522bfe9b422362223bb8e652,openstack/diskimage-builder,master,I2feb615b2094d9d6522bfe9b422362223bb8e652,Add --list support to dib-run-parts.,MERGED,2013-09-04 08:44:53.000000000,2013-09-04 10:59:47.000000000,2013-09-04 10:59:46.000000000,"[{'_account_id': 3}, {'_account_id': 1926}]","[{'number': 1, 'created': '2013-09-04 08:44:53.000000000', 'files': ['elements/dib-run-parts/bin/dib-run-parts'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/6311388892f2edc8c49600e371e175cf226dac78', 'message': 'Add --list support to dib-run-parts.\n\nOur custom dib-run-parts now supports --list for better compatibility\nwith some OS-provided run-parts tools.\n\nChange-Id: I2feb615b2094d9d6522bfe9b422362223bb8e652\nCloses-Bug: #1190521\n'}]",0,45019,6311388892f2edc8c49600e371e175cf226dac78,7,2,1,6449,,,0,"Add --list support to dib-run-parts.

Our custom dib-run-parts now supports --list for better compatibility
with some OS-provided run-parts tools.

Change-Id: I2feb615b2094d9d6522bfe9b422362223bb8e652
Closes-Bug: #1190521
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/19/45019/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/dib-run-parts/bin/dib-run-parts'],1,6311388892f2edc8c49600e371e175cf226dac78,dib-run-parts-list-lp1190521,"show_list= echo ""usage: $name [OPTION] scripts_directory"" >&2 echo "" --list print names of all valid files"" >&2if [ ""$1"" == ""--list"" ] ; then show_list=""1"" shift fi if [ ""$show_list"" == ""1"" ] ; then for target in $targets ; do echo ""${target_dir}/${target}"" done exit 0 fi "," echo ""usage: $name scripts_directory"" >&2",15,1
openstack%2Fmurano~release-0.2~I40df94d13ed4d1af0867c119a3954387a74162f0,openstack/murano,release-0.2,I40df94d13ed4d1af0867c119a3954387a74162f0,Fix leaking password in murano-api logs.,MERGED,2013-09-03 15:14:06.000000000,2013-09-04 10:31:12.000000000,2013-09-04 10:31:12.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7821}, {'_account_id': 8040}]","[{'number': 1, 'created': '2013-09-03 15:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/88ef0297589ad22bccbb9ea97f8b2a05d4462e6a', 'message': 'Fix leaking password in murano-api logs.\n\nChange-Id: I40df94d13ed4d1af0867c119a3954387a74162f0\nFixes: bug MRN-861.\n'}, {'number': 2, 'created': '2013-09-04 08:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/07c047bcf509ba02512cd0ab5025b74edd7aac13', 'message': 'Fix leaking password in murano-api logs.\n\nChange-Id: I40df94d13ed4d1af0867c119a3954387a74162f0\nFixes: bug MRN-861.\n'}, {'number': 3, 'created': '2013-09-04 10:24:30.000000000', 'files': ['muranoapi/db/services/sessions.py', 'muranoapi/common/service.py', 'muranoapi/api/v1/services.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/7b1656ecadb1cc41e28c1dfe7a9ca5058374ae77', 'message': 'Fix leaking password in murano-api logs.\n\nChange-Id: I40df94d13ed4d1af0867c119a3954387a74162f0\nFixes: bug MRN-861.\n'}]",1,44896,7b1656ecadb1cc41e28c1dfe7a9ca5058374ae77,14,4,3,8040,,,0,"Fix leaking password in murano-api logs.

Change-Id: I40df94d13ed4d1af0867c119a3954387a74162f0
Fixes: bug MRN-861.
",git fetch https://review.opendev.org/openstack/murano refs/changes/96/44896/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranoapi/common/service.py', 'muranoapi/db/services/sessions.py', 'muranoapi/common/utils.py', 'muranoapi/api/v1/services.py']",4,88ef0297589ad22bccbb9ea97f8b2a05d4462e6a,bug/MRN-861,"from muranoapi.common.utils import secure_data log.debug( _('Services:Post <EnvId: {0}, Path: {2}, ' 'Body: {1}>'.format(environment_id, secure_data(body), path)))"," log.debug(_('Services:Post <EnvId: {0}, Path: {2}, ' 'Body: {1}>'.format(environment_id, body, path)))",15,11
openstack%2Fnova~master~I737f474ab8c3a8a03f4b94cbf544e9cc4f18c702,openstack/nova,master,I737f474ab8c3a8a03f4b94cbf544e9cc4f18c702,"Revert ""Remove instance exists check from rebuild_instance""",ABANDONED,2013-09-04 09:03:42.000000000,2013-09-04 10:15:19.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-09-04 09:03:42.000000000', 'files': ['nova/tests/integrated/test_api_samples.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/737f474ab8c3a8a03f4b94cbf544e9cc4f18c702', 'message': 'Revert ""Remove instance exists check from rebuild_instance""\n\nThis reverts commit 856db7efad3dceda33423bb3708390475c37034c\n\nWhen evacuate to another host, similar to instance create, nova\ncompute must make sure the instance not yet exist on the host.\n\nFix bug 1216501'}]",0,45022,737f474ab8c3a8a03f4b94cbf544e9cc4f18c702,3,2,1,7494,,,0,"Revert ""Remove instance exists check from rebuild_instance""

This reverts commit 856db7efad3dceda33423bb3708390475c37034c

When evacuate to another host, similar to instance create, nova
compute must make sure the instance not yet exist on the host.

Fix bug 1216501",git fetch https://review.opendev.org/openstack/nova refs/changes/22/45022/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/integrated/test_api_samples.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",3,737f474ab8c3a8a03f4b94cbf544e9cc4f18c702,," def test_rebuild_on_host_instance_exists(self): """"""Rebuild if instance exists raises an exception."""""" db.instance_update(self.context, self.inst_ref['uuid'], {""task_state"": task_states.SCHEDULING}) self.compute.run_instance(self.context, instance=self.inst_ref) self.stubs.Set(self.compute.driver, 'instance_on_disk', lambda x: True) self.assertRaises(exception.InstanceExists, lambda: self._rebuild(on_shared_storage=True)) ",,13,1
openstack%2Fnova~master~I7c3f652d1a7b4783940c850dacc798bc4a14c539,openstack/nova,master,I7c3f652d1a7b4783940c850dacc798bc4a14c539,Remove redundant spaces in doc string,ABANDONED,2013-09-01 14:16:12.000000000,2013-09-04 10:12:57.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-09-01 14:16:12.000000000', 'files': ['nova/quota.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d6ccf6671605a24f0c9d69a3dc973f70f0589c16', 'message': 'Remove redundant spaces in doc string\n\nChange-Id: I7c3f652d1a7b4783940c850dacc798bc4a14c539\n'}]",1,44604,d6ccf6671605a24f0c9d69a3dc973f70f0589c16,4,3,1,6763,,,0,"Remove redundant spaces in doc string

Change-Id: I7c3f652d1a7b4783940c850dacc798bc4a14c539
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/44604/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/quota.py'],1,d6ccf6671605a24f0c9d69a3dc973f70f0589c16,removeRedundantSpace, quota class cannot be determined. This parameter allows it to be specified. It, quota class cannot be determined. This parameter allows it to be specified. It,2,2
openstack%2Ftripleo-ci~master~I959580684ae163dcd7972bae4a23a74b69d4ea92,openstack/tripleo-ci,master,I959580684ae163dcd7972bae4a23a74b69d4ea92,Don't restrict the source-repositories type,MERGED,2013-09-04 08:40:01.000000000,2013-09-04 10:11:21.000000000,2013-09-04 10:11:21.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-09-04 08:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/40501f3203deb27a34919ecb5dbe3fdb62584c8c', 'message': ""Don't restrict the source-repositories type\n\nfile type has been added (there may be more), each one causes toci to\nerror, so removing the retriction its not needed here.\n\nChange-Id: I959580684ae163dcd7972bae4a23a74b69d4ea92\n""}, {'number': 2, 'created': '2013-09-04 10:05:46.000000000', 'files': ['toci_git.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8f7e162e6e019e7f37a3de81fe0b77cbc2a835cd', 'message': ""Don't restrict the source-repositories type\n\nfile type has been added (there may be more), each one causes toci to\nerror, so removing the restriction its not needed here.\n\nChange-Id: I959580684ae163dcd7972bae4a23a74b69d4ea92\n""}]",0,45018,8f7e162e6e019e7f37a3de81fe0b77cbc2a835cd,11,3,2,1926,,,0,"Don't restrict the source-repositories type

file type has been added (there may be more), each one causes toci to
error, so removing the restriction its not needed here.

Change-Id: I959580684ae163dcd7972bae4a23a74b69d4ea92
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/18/45018/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_git.sh'],1,40501f3203deb27a34919ecb5dbe3fdb62584c8c,new-type,"REGEX=""^([^ ]+) ([^ ]+) ([/~][^ ]+) ([^ ]+) ?([^ ]*)$""","REGEX=""^([^ ]+) (git|tar) ([/~][^ ]+) ([^ ]+) ?([^ ]*)$"" return 1",1,2
openstack%2Ftripleo-ci~master~If77ab0cf9e8c68918f34fa6bbb891445cb4722de,openstack/tripleo-ci,master,If77ab0cf9e8c68918f34fa6bbb891445cb4722de,Specify alternate unit name for compute logs,MERGED,2013-09-02 11:10:18.000000000,2013-09-04 09:43:37.000000000,2013-09-04 09:43:36.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6773}]","[{'number': 1, 'created': '2013-09-02 11:10:18.000000000', 'files': ['toci_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6a4f99dcb4e2b72e1684c574f9ce7dce5932b32f', 'message': 'Specify alternate unit name for compute logs\n\nIf installed from package the systemd unit for nova services is\nopenstack-nova-*, on Fedora this journalctl command will find logs in\nboth packaged and non packaged cases.\n\nChange-Id: If77ab0cf9e8c68918f34fa6bbb891445cb4722de\n'}]",0,44678,6a4f99dcb4e2b72e1684c574f9ce7dce5932b32f,8,3,1,1926,,,0,"Specify alternate unit name for compute logs

If installed from package the systemd unit for nova services is
openstack-nova-*, on Fedora this journalctl command will find logs in
both packaged and non packaged cases.

Change-Id: If77ab0cf9e8c68918f34fa6bbb891445cb4722de
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/78/44678/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_test.sh'],1,6a4f99dcb4e2b72e1684c574f9ce7dce5932b32f,systemd-units, wait_for 40 10 ssh_noprompt root@$SEED_IP journalctl -u nova-compute -u openstack-nova-compute \| grep \'record updated for\' -A 100 \| grep \'Updating host status\' wait_for 40 10 ssh_noprompt heat-admin@$UNDERCLOUD_IP sudo journalctl -u nova-compute -u openstack-nova-compute \| grep \'record updated for\' -A 100 \| grep \'Updating host status\', wait_for 40 10 ssh_noprompt root@$SEED_IP journalctl _SYSTEMD_UNIT=nova-compute.service \| grep \'record updated for\' -A 100 \| grep \'Updating host status\' wait_for 40 10 ssh_noprompt heat-admin@$UNDERCLOUD_IP sudo journalctl _SYSTEMD_UNIT=nova-compute.service \| grep \'record updated for\' -A 100 \| grep \'Updating host status\',2,2
openstack%2Fceilometer~master~I94f0c82594f2573749d124e2cc59f7f9ff4b689d,openstack/ceilometer,master,I94f0c82594f2573749d124e2cc59f7f9ff4b689d,Handle volume.resize.* notifications,MERGED,2013-09-03 18:43:23.000000000,2013-09-04 09:11:21.000000000,2013-09-04 09:11:21.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-09-03 18:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0755dcd2fbd597514fe896a8455fba1e427e5072', 'message': 'Handle volume.resize.* notifications\n\nCinder sends a notification at the beginning and the end\nof the resize process. Those notifications are volume.resize.start\nand volume.resize.end. Handle them for proper usage logging.\n\nFixes: bug #1220377\nChange-Id: I94f0c82594f2573749d124e2cc59f7f9ff4b689d\n'}, {'number': 2, 'created': '2013-09-03 19:03:10.000000000', 'files': ['ceilometer/volume/notifications.py', 'tests/volume/test_notifications.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b501aaaaa4aad22046103938eaaca194e38156be', 'message': 'Handle volume.resize.* notifications\n\nCinder sends a notification at the beginning and the end\nof the resize process. Those notifications are volume.resize.start\nand volume.resize.end. Handle them for proper usage logging.\n\nFixes: bug #1220377\nChange-Id: I94f0c82594f2573749d124e2cc59f7f9ff4b689d\n'}]",0,44935,b501aaaaa4aad22046103938eaaca194e38156be,11,4,2,7156,,,0,"Handle volume.resize.* notifications

Cinder sends a notification at the beginning and the end
of the resize process. Those notifications are volume.resize.start
and volume.resize.end. Handle them for proper usage logging.

Fixes: bug #1220377
Change-Id: I94f0c82594f2573749d124e2cc59f7f9ff4b689d
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/35/44935/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/volume/notifications.py', 'tests/volume/test_notifications.py']",2,0755dcd2fbd597514fe896a8455fba1e427e5072,bug/1220377,"NOTIFICATION_VOLUME_RESIZE = { u'_context_roles': [u'Member', u'admin'], u'_context_request_id': u'req-6ba8ccb4-1093-4a39-b029-adfaa3fc7ceb', u'_context_quota_class': None, u'event_type': u'volume.resize.end', u'timestamp': u'2012-09-21 10:24:13.168630', u'message_id': u'b5814258-3425-4eb7-b6b7-bf4811203e58', u'_context_auth_token': u'277c6899de8a4b3d999f3e2e4c0915ff', u'_context_is_admin': True, u'_context_project_id': u'6c97f1ecf17047eab696786d56a0bff5', u'_context_timestamp': u'2012-09-21T10:02:27.134211', u'_context_read_deleted': u'no', u'_context_user_id': u'4d2fa4b76a4a4ecab8c468c8dea42f89', u'_context_remote_address': u'192.168.22.101', u'publisher_id': u'volume.ubuntu-VirtualBox', u'payload': {u'status': u'extending', u'volume_type_id': None, u'display_name': u'abc', u'tenant_id': u'6c97f1ecf17047eab696786d56a0bff5', u'created_at': u'2012-09-21 10:10:47', u'snapshot_id': None, u'volume_id': u'3b761164-84b4-4eb3-8fcb-1974c641d6ef', u'user_id': u'4d2fa4b76a4a4ecab8c468c8dea42f89', u'launched_at': u'2012-09-21 10:10:50', u'size': 3}, u'priority': u'INFO'} class TestNotifications(unittest.TestCase): def test_volume_resize(self): v = notifications.Volume() samples = list(v.process_notification(NOTIFICATION_VOLUME_RESIZE)) self.assertEqual(len(samples), 1) s = samples[0] self._verify_common_sample(s, 'volume', NOTIFICATION_VOLUME_RESIZE) self.assertEqual(s.volume, 1) def test_volume_size_resize(self): v = notifications.VolumeSize() samples = list(v.process_notification(NOTIFICATION_VOLUME_RESIZE)) self.assertEqual(len(samples), 1) s = samples[0] self._verify_common_sample(s, 'volume.size', NOTIFICATION_VOLUME_RESIZE) self.assertEqual(s.volume, NOTIFICATION_VOLUME_RESIZE['payload']['size'])",class TestNotifications(base.TestCase):,48,1
openstack%2Fnova~master~Ifda27fde2c062c93e6356707cc22ce33fc8f10d7,openstack/nova,master,Ifda27fde2c062c93e6356707cc22ce33fc8f10d7,Check instance existance on evacuate,ABANDONED,2013-09-03 22:28:49.000000000,2013-09-04 09:05:36.000000000,,"[{'_account_id': 3}, {'_account_id': 1782}, {'_account_id': 2166}, {'_account_id': 4393}]","[{'number': 1, 'created': '2013-09-03 22:28:49.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4f5ffe46b3b15e0ff37aa835332fc850890e598b', 'message': 'Check instance existance on evacuate\n\nIn patch 42746, the check for instance existence was removed from\ninstance work flow.\n\nBut when evacuate to another host, similar to instance create, nova\ncompute must make sure the instance not yet exist on the host.\n\nFix bug 1216501\n\nChange-Id: Ifda27fde2c062c93e6356707cc22ce33fc8f10d7\n'}]",0,44964,4f5ffe46b3b15e0ff37aa835332fc850890e598b,5,4,1,7494,,,0,"Check instance existance on evacuate

In patch 42746, the check for instance existence was removed from
instance work flow.

But when evacuate to another host, similar to instance create, nova
compute must make sure the instance not yet exist on the host.

Fix bug 1216501

Change-Id: Ifda27fde2c062c93e6356707cc22ce33fc8f10d7
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/44964/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,4f5ffe46b3b15e0ff37aa835332fc850890e598b,bug/1216501," def test_rebuild_on_host_instance_exists(self): """"""Rebuild if instance exists raises an exception."""""" db.instance_update(self.context, self.inst_ref['uuid'], {""task_state"": task_states.SCHEDULING}) self.compute.run_instance(self.context, instance=self.inst_ref) self.stubs.Set(self.compute.driver, 'instance_on_disk', lambda x: True) self.assertRaises(exception.InstanceExists, lambda: self._rebuild(on_shared_storage=True)) ",,13,0
openstack%2Fnova~master~Iffebf782ab3fbf3f25cceb068ef24813808f5045,openstack/nova,master,Iffebf782ab3fbf3f25cceb068ef24813808f5045,Remove instance exists check from rebuild_instance,MERGED,2013-08-19 22:23:41.000000000,2013-09-04 09:03:43.000000000,2013-08-22 10:56:16.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-08-19 22:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a310d4fd921d808fee7c0a689cf236161428258', 'message': ""Remove instance exists check from rebuild_instance\n\nThis existence check seems completely bogus - surely the instance must\nexist in order to rebuild it?\n\nThis issue wasn't papered over because we weren't running evacuate with\na valid compute node hostname so the rebuild_instance() gets sent to a\nbogus queue.\n\nThat call on a bogus queue will fail if we start timing out call()s in\nthe fake RPC driver when there are no consumers for a topic.\n\nblueprint: oslo-messaging\nChange-Id: Iffebf782ab3fbf3f25cceb068ef24813808f5045\n""}, {'number': 2, 'created': '2013-08-20 06:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ecc2dc21cef923f1e0c3cf6fbd7dcd41d79cf419', 'message': ""Remove instance exists check from rebuild_instance\n\nThis existence check seems completely bogus - surely the instance must\nexist in order to rebuild it?\n\nThis issue wasn't papered over because we weren't running evacuate with\na valid compute node hostname so the rebuild_instance() gets sent to a\nbogus queue.\n\nThat call on a bogus queue will fail if we start timing out call()s in\nthe fake RPC driver when there are no consumers for a topic.\n\nblueprint: oslo-messaging\nChange-Id: Iffebf782ab3fbf3f25cceb068ef24813808f5045\n""}, {'number': 3, 'created': '2013-08-20 08:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89789e6f9cce72a0f1725246cdcd4a9ca750f6aa', 'message': ""Remove instance exists check from rebuild_instance\n\nThis existence check seems completely bogus - surely the instance must\nexist in order to rebuild it?\n\nThis issue wasn't papered over because we weren't running evacuate with\na valid compute node hostname so the rebuild_instance() gets sent to a\nbogus queue.\n\nThat call on a bogus queue will fail if we start timing out call()s in\nthe fake RPC driver when there are no consumers for a topic.\n\nblueprint: oslo-messaging\nChange-Id: Iffebf782ab3fbf3f25cceb068ef24813808f5045\n""}, {'number': 4, 'created': '2013-08-21 10:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99e47dec68eb6b981c1012be6e943789d9eb735c', 'message': ""Remove instance exists check from rebuild_instance\n\nThis existence check seems completely bogus - surely the instance must\nexist in order to rebuild it?\n\nThis issue wasn't papered over because we weren't running evacuate with\na valid compute node hostname so the rebuild_instance() gets sent to a\nbogus queue.\n\nThat call on a bogus queue will fail if we start timing out call()s in\nthe fake RPC driver when there are no consumers for a topic.\n\nblueprint: oslo-messaging\nChange-Id: Iffebf782ab3fbf3f25cceb068ef24813808f5045\n""}, {'number': 5, 'created': '2013-08-22 07:30:54.000000000', 'files': ['nova/tests/integrated/test_api_samples.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/856db7efad3dceda33423bb3708390475c37034c', 'message': ""Remove instance exists check from rebuild_instance\n\nThis existence check seems completely bogus - surely the instance must\nexist in order to rebuild it?\n\nThis issue wasn't papered over because we weren't running evacuate with\na valid compute node hostname so the rebuild_instance() gets sent to a\nbogus queue.\n\nThat call on a bogus queue will fail if we start timing out call()s in\nthe fake RPC driver when there are no consumers for a topic.\n\nblueprint: oslo-messaging\nChange-Id: Iffebf782ab3fbf3f25cceb068ef24813808f5045\n""}]",0,42746,856db7efad3dceda33423bb3708390475c37034c,32,5,5,1247,,,0,"Remove instance exists check from rebuild_instance

This existence check seems completely bogus - surely the instance must
exist in order to rebuild it?

This issue wasn't papered over because we weren't running evacuate with
a valid compute node hostname so the rebuild_instance() gets sent to a
bogus queue.

That call on a bogus queue will fail if we start timing out call()s in
the fake RPC driver when there are no consumers for a topic.

blueprint: oslo-messaging
Change-Id: Iffebf782ab3fbf3f25cceb068ef24813808f5045
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/42746/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/integrated/test_api_samples.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",3,6a310d4fd921d808fee7c0a689cf236161428258,bp/oslo-messaging,," def test_rebuild_on_host_instance_exists(self): """"""Rebuild if instance exists raises an exception."""""" db.instance_update(self.context, self.inst_ref['uuid'], {""task_state"": task_states.SCHEDULING}) self.compute.run_instance(self.context, instance=self.inst_ref) self.stubs.Set(self.compute.driver, 'instance_on_disk', lambda x: True) self.assertRaises(exception.InstanceExists, lambda: self._rebuild(on_shared_storage=True)) ",1,13
openstack%2Fdiskimage-builder~master~I4c979d4eb5e34a753d9143d9dcfe4e5d08f74a0d,openstack/diskimage-builder,master,I4c979d4eb5e34a753d9143d9dcfe4e5d08f74a0d,"On Fedora, use Linux Foundation bzr lsb_release",MERGED,2013-08-29 03:10:27.000000000,2013-09-04 08:59:16.000000000,2013-09-04 08:59:15.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 4190}, {'_account_id': 4571}, {'_account_id': 6449}]","[{'number': 1, 'created': '2013-08-29 03:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/8ea6b4e9685ec670b0a030209a4f2c4db72a4d91', 'message': 'On Fedora, use Linux Foundation bzr lsb_release\n\nInstalling redhat-lsb-core adds 87M to the install due\nto bugzilla #1002342\n\nlsb_release is a platform agnostic script, so this change caches\nit from linuxfoundation bzr http and installs it to /usr/local/bin\n\nChange-Id: I4c979d4eb5e34a753d9143d9dcfe4e5d08f74a0d\n'}, {'number': 2, 'created': '2013-09-01 21:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/a4879e3c29cbe6c054ec74cdd37528775e11e4b8', 'message': 'On Fedora, use Linux Foundation bzr lsb_release\n\nInstalling redhat-lsb-core adds 87M to the install due\nto bugzilla #1002342\n\nlsb_release is a platform agnostic script, so this change fetches\na single file via source-repositories from linuxfoundation bzr http\nand installs it to /usr/local/bin\n\nChange-Id: I4c979d4eb5e34a753d9143d9dcfe4e5d08f74a0d\n'}, {'number': 3, 'created': '2013-09-03 22:18:12.000000000', 'files': ['elements/fedora/element-deps', 'elements/fedora/pre-install.d/02-lsb', 'elements/fedora/source-repository-fedora'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c182fef45c7769c242c979d1326a5d0a041cd470', 'message': 'On Fedora, use Linux Foundation bzr lsb_release\n\nInstalling redhat-lsb-core adds 87M to the install due\nto bugzilla #1002342\n\nlsb_release is a platform agnostic script, so this change fetches\na single file via source-repositories from linuxfoundation bzr http\nand installs it to /usr/local/bin\n\nChange-Id: I4c979d4eb5e34a753d9143d9dcfe4e5d08f74a0d\n'}]",3,44206,c182fef45c7769c242c979d1326a5d0a041cd470,19,6,3,4571,,,0,"On Fedora, use Linux Foundation bzr lsb_release

Installing redhat-lsb-core adds 87M to the install due
to bugzilla #1002342

lsb_release is a platform agnostic script, so this change fetches
a single file via source-repositories from linuxfoundation bzr http
and installs it to /usr/local/bin

Change-Id: I4c979d4eb5e34a753d9143d9dcfe4e5d08f74a0d
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/06/44206/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/fedora/extra-data.d/10-linuxfoundation-lsb', 'elements/fedora/pre-install.d/02-lsb']",2,8ea6b4e9685ec670b0a030209a4f2c4db72a4d91,lsb_release,set -eu #exec install-packages redhat-lsb-core install -m 0755 -o root -g root /tmp/lsb/lsb_release /usr/local/bin,exec install-packages redhat-lsb-core ,22,1
openstack%2Fdiskimage-builder~master~Ib79e41969c982a02f0235318d9f254b39c3c6d93,openstack/diskimage-builder,master,Ib79e41969c982a02f0235318d9f254b39c3c6d93,Add support for file to source-repositories,MERGED,2013-09-01 21:56:41.000000000,2013-09-04 08:26:20.000000000,2013-09-04 08:26:20.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4190}, {'_account_id': 4571}]","[{'number': 1, 'created': '2013-09-01 21:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/0a2fc8df58cf8c3178101bb0a3adf82608727fc2', 'message': 'Add support for file to source-repositories\n\nAdds a file type to source-repositories to allow individual files\nto make use of source-repositories caching.\n\nREPO_DIRECTORY has been rename to REPO_DEST since it is now sometimes\na file.\n\nThis change also fixes the incorrect path to the cache-url in the\ntar type.\n\nChange-Id: Ib79e41969c982a02f0235318d9f254b39c3c6d93\n'}, {'number': 2, 'created': '2013-09-03 22:18:11.000000000', 'files': ['elements/source-repositories/extra-data.d/98-source-repositories'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9e5bc3726500c25717d4a9cbad1edabf63d74649', 'message': 'Add support for file to source-repositories\n\nAdds a file type to source-repositories to allow individual files\nto make use of source-repositories caching.\n\nREPO_DIRECTORY has been rename to REPO_DEST since it is now sometimes\na file.\n\nThis change also fixes the incorrect path to the cache-url in the\ntar type.\n\nChange-Id: Ib79e41969c982a02f0235318d9f254b39c3c6d93\n'}]",8,44630,9e5bc3726500c25717d4a9cbad1edabf63d74649,15,4,2,4571,,,0,"Add support for file to source-repositories

Adds a file type to source-repositories to allow individual files
to make use of source-repositories caching.

REPO_DIRECTORY has been rename to REPO_DEST since it is now sometimes
a file.

This change also fixes the incorrect path to the cache-url in the
tar type.

Change-Id: Ib79e41969c982a02f0235318d9f254b39c3c6d93
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/30/44630/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/source-repositories/extra-data.d/98-source-repositories'],1,0a2fc8df58cf8c3178101bb0a3adf82608727fc2,lsb_release," local REGEX=""^([^ ]+) (git|tar|file) (/[^ ]+) ([^ ]+) ?([^ ]*)$"" local REPO_DEST=$TMP_MOUNT_PATH$REPOPATH local REPO_SUB_DIRECTORY=$(dirname $REPO_DEST) sudo git clone $CACHE_PATH $REPO_DEST sudo git clone $REPOLOCATION $REPO_DEST pushd $REPO_DEST $TMP_HOOKS_PATH/bin/cache-url $REPOLOCATION $CACHE_PATH sudo mkdir -p $REPO_DEST sudo mv $tmpdir/*/* $REPO_DEST file) sudo mkdir -p $REPO_SUB_DIRECTORY if [ -n ""$CACHE_PATH"" ] ; then if [ ! -f ""$CACHE_PATH"" -o -z ""$DIB_OFFLINE"" ] ; then ls -l $TMP_MOUNT_PATH/usr/local/bin $TMP_HOOKS_PATH/bin/cache-url $REPOLOCATION $CACHE_PATH fi sudo cp $CACHE_PATH $REPO_DEST else sudo curl $REPOLOCATION -o $REPO_DEST fi ;;"," local REGEX=""^([^ ]+) (git|tar) (/[^ ]+) ([^ ]+) ?([^ ]*)$"" local REPO_DIRECTORY=$TMP_MOUNT_PATH$REPOPATH local REPO_SUB_DIRECTORY=$(dirname $REPO_DIRECTORY) sudo git clone $CACHE_PATH $REPO_DIRECTORY sudo git clone $REPOLOCATION $REPO_DIRECTORY pushd $REPO_DIRECTORY $TMP_MOUNT_PATH/usr/local/bin/cache-url $REPOLOCATION $CACHE_PATH sudo mkdir -p $REPO_DIRECTORY sudo mv $tmpdir/*/* $REPO_DIRECTORY",21,9
openstack%2Fmurano-dashboard~release-0.2~I762dfad99cecb8eed63c4b2b8c89bcbe8ee1c2d0,openstack/murano-dashboard,release-0.2,I762dfad99cecb8eed63c4b2b8c89bcbe8ee1c2d0,Fix MRN-937,MERGED,2013-09-03 15:55:58.000000000,2013-09-04 07:33:03.000000000,2013-09-04 07:33:03.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7821}]","[{'number': 1, 'created': '2013-09-03 15:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f59272d25870c93a619fe027f608173fe32c9296', 'message': 'Fix MRN-937\n\nFix regression issue\n\nChange-Id: I762dfad99cecb8eed63c4b2b8c89bcbe8ee1c2d0\n'}, {'number': 2, 'created': '2013-09-03 15:55:58.000000000', 'files': ['muranodashboard/panel/tables.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f2fbded17ef6280427dd16684e71bcb852b0a643', 'message': 'Fix MRN-937\n\nFix regression issue\n\nChange-Id: I762dfad99cecb8eed63c4b2b8c89bcbe8ee1c2d0\n'}]",0,44911,f2fbded17ef6280427dd16684e71bcb852b0a643,9,3,2,7549,,,0,"Fix MRN-937

Fix regression issue

Change-Id: I762dfad99cecb8eed63c4b2b8c89bcbe8ee1c2d0
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/11/44911/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/panel/tables.py'],1,f59272d25870c93a619fe027f608173fe32c9296,," status, = api.get_environment_data(request, environment_id, 'status')"," status = api.get_environment_data(request, environment_id, 'status')",1,1
openstack%2Fmurano-dashboard~release-0.2~Ibaff1fd6b1e60ff7431f1eb763e449070b94247e,openstack/murano-dashboard,release-0.2,Ibaff1fd6b1e60ff7431f1eb763e449070b94247e,Placeholder emulation added in IE,MERGED,2013-09-03 14:50:15.000000000,2013-09-04 07:33:03.000000000,2013-09-04 07:33:03.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8040}]","[{'number': 1, 'created': '2013-09-03 14:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/855f065ea889429ea6be9d5e1726b275ac46fbe6', 'message': 'Placeholder imulation added in IE\n\nSo optional fieleds are marked in IE now\n\nChange-Id: Ibaff1fd6b1e60ff7431f1eb763e449070b94247e\n'}, {'number': 2, 'created': '2013-09-03 15:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/23f9822c81e3d777a6175b7029214484eba26959', 'message': 'Placeholder imulation added in IE\n\nSo optional fieleds are marked in IE now\n\nChange-Id: Ibaff1fd6b1e60ff7431f1eb763e449070b94247e\n'}, {'number': 3, 'created': '2013-09-04 07:20:46.000000000', 'files': ['muranodashboard/services/WebServer.yaml', 'muranodashboard/services/WebServerFarm.yaml', 'muranodashboard/static/muranodashboard/js/support_placeholder.js', 'muranodashboard/services/MsSqlClusterServer.yaml', 'muranodashboard/services/MsSqlServer.yaml', 'muranodashboard/services/AspNetAppFarm.yaml', 'muranodashboard/services/AspNetApp.yaml', 'muranodashboard/services/ActiveDirectory.yaml', 'muranodashboard/static/muranodashboard/css/support_placeholder.css'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/48f145a04838c7cd6af761a8e63d7e2181c5dcec', 'message': 'Placeholder emulation added in IE\n\nSo optional fieleds are marked in IE now\n\nChange-Id: Ibaff1fd6b1e60ff7431f1eb763e449070b94247e\n'}]",0,44891,48f145a04838c7cd6af761a8e63d7e2181c5dcec,14,5,3,7549,,,0,"Placeholder emulation added in IE

So optional fieleds are marked in IE now

Change-Id: Ibaff1fd6b1e60ff7431f1eb763e449070b94247e
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/91/44891/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/services/WebServer.yaml', 'muranodashboard/services/WebServerFarm.yaml', 'muranodashboard/static/muranodashboard/js/support_placeholder.js', 'muranodashboard/services/MsSqlClusterServer.yaml', 'muranodashboard/services/MsSqlServer.yaml', 'muranodashboard/services/AspNetAppFarm.yaml', 'muranodashboard/services/AspNetApp.yaml', 'muranodashboard/services/ActiveDirectory.yaml']",8,855f065ea889429ea6be9d5e1726b275ac46fbe6,, # temporaryHack widgetMedia: js: [muranodashboard/js/support_placeholder.js],,58,0
openstack%2Fneutron~master~I8ad2f1e161259bac8b0f488cdc57f66af2e1a666,openstack/neutron,master,I8ad2f1e161259bac8b0f488cdc57f66af2e1a666,Clear *.pyc before run test via tox,ABANDONED,2013-09-03 13:12:56.000000000,2013-09-04 07:00:57.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-09-03 13:12:56.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/071092b2594e6cd514b34479fb58efec3977aac0', 'message': ""Clear *.pyc before run test via tox\n\nrun_tests.sh will remove *.pyc before run test, but tox doesn't,\nit will cause problem when developers delete a python file and forget\nto remove the relative pyc file.\n\nCloses-Bug; #1220234\nChange-Id: I8ad2f1e161259bac8b0f488cdc57f66af2e1a666\n""}]",1,44872,071092b2594e6cd514b34479fb58efec3977aac0,7,5,1,6676,,,0,"Clear *.pyc before run test via tox

run_tests.sh will remove *.pyc before run test, but tox doesn't,
it will cause problem when developers delete a python file and forget
to remove the relative pyc file.

Closes-Bug; #1220234
Change-Id: I8ad2f1e161259bac8b0f488cdc57f66af2e1a666
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/44872/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,071092b2594e6cd514b34479fb58efec3977aac0,bug/1220234," /usr/bin/find . -type f -name ""*.pyc"" -delete",,1,0
openstack%2Fneutron~master~Id7ac1acf0e8ae8121828620d4b53511957d86808,openstack/neutron,master,Id7ac1acf0e8ae8121828620d4b53511957d86808,Add network isolated extension and base class,ABANDONED,2013-07-06 16:06:39.000000000,2013-09-04 06:03:12.000000000,,"[{'_account_id': 3}, {'_account_id': 55}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 6072}]","[{'number': 14, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f00f0970bb2834a86eb510efc44f9621582e9cb8', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and to specify the MAC addresses of gateway and\nDHCP server.\n\nThe DHCP MAC address is used to authorise the bootp broadcasting traffic\nand the gateway MAC address is used to unicastify the ARP braodcast\ntraffic.\n\nIf the DHCP server and/or the gateway are handled by Neutron, the MAC\naddresses are setted automaticaly.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 12, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8be44b74e5280d17e0a7b807a79ae752ba1d06f4', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and to specify the MAC addresses of gateway and\nDHCP server.\n\nThe DHCP MAC address is used to authorise the bootp broadcasting traffic\nand the gateway MAC address is used to unicastify the ARP braodcast\ntraffic.\n\nIf the DHCP server and/or the gateway are handled by Neutron, the MAC\naddresses are setted automaticaly.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 13, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab2027611da7f6d9961bef96485f3f78c4411003', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and to specify the MAC addresses of gateway and\nDHCP server.\n\nThe DHCP MAC address is used to authorise the bootp broadcasting traffic\nand the gateway MAC address is used to unicastify the ARP braodcast\ntraffic.\n\nIf the DHCP server and/or the gateway are handled by Neutron, the MAC\naddresses are setted automaticaly.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 10, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/056d829baf4ea28c104114d752512ba2c777b714', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and the subnet object to specify the MAC\naddresses of a local proxy ARP.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 11, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b57f978e15c4ae304cd9b3567e2d5c11b30fef18', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and the subnet object to specify the MAC\naddresses of a local proxy ARP.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 8, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e01e987b98e169e7c00492ec8f0c46d39d4eb547', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and the subnet object to specify the MAC\naddresses of a local proxy ARP.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 9, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e63aee9f6297b24894a7649bf74cd37d31b3483', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and the subnet object to specify the MAC\naddresses of a local proxy ARP.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 6, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa5bdf2c4c7a7f10cac99d37ff63074995f4e17f', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and the subnet object to specify the MAC\naddresses of a local proxy ARP.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 7, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1578b1f56e6833609d0bd4ed3125fc80e5ee2c96', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and the subnet object to specify the MAC\naddresses of a local proxy ARP.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 4, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3bfd3344797dae30e68151a278c1e0d7bb0ecafc', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and the subnet object to specify the MAC\naddresses of a local proxy ARP.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 5, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3005044cb94c8420a07aa7663c907f965f1f68f0', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and the subnet object to specify the MAC\naddresses of a local proxy ARP.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 2, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/34a812f8e53d2c09cbaa34965125b784afd0e1f9', 'message': ""Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with an attribute to enable or\ndisable port isolation on that network. And it adds an attribute to the\nsubnet object to precise the MAC address of a local proxy ARP that can\nbe use to authorize traffic between network's port.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n""}, {'number': 3, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8daa5907b331eaef8a4c348b8e6aca002a5aa5dc', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and to specifie the MAC addresses of gateway\nand/or DHCP server.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 1, 'created': '2013-07-06 16:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/08adfa3631ea8d88083a3c272f594e70cec1121e', 'message': ""Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with an attribute to enable or\ndisable port isolation on that network. And it adds an attribute to the\nsubnet object to precise the MAC address of a local proxy ARP that can\nbe use to authorize traffic between network's port.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n""}, {'number': 15, 'created': '2013-07-08 20:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/49b8e2e9a9c03f488539f36713953e449f7f5496', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and to specify the MAC addresses of gateway and\nDHCP server.\n\nThe DHCP MAC address is used to authorise the bootp broadcasting traffic\nand the gateway MAC address is used to unicastify the ARP braodcast\ntraffic.\n\nIf the DHCP server and/or the gateway are handled by Neutron, the MAC\naddresses are setted automaticaly.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 16, 'created': '2013-08-23 09:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/821d0819af37ca620383698dcee63743a8401eaf', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and to specify the MAC addresses of gateway and\nDHCP server.\n\nThe DHCP MAC address is used to authorise the bootp broadcasting traffic\nand the gateway MAC address is used to unicastify the ARP braodcast\ntraffic.\n\nIf the DHCP server and/or the gateway are handled by Neutron, the MAC\naddresses are setted automaticaly.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 17, 'created': '2013-08-23 12:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c2e51d6d0c14a83683cd83bde589708fd0fbceef', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and to specify the MAC addresses of gateway and\nDHCP server.\n\nThe DHCP MAC address is used to authorise the bootp broadcasting traffic\nand the gateway MAC address is used to unicastify the ARP braodcast\ntraffic.\n\nIf the DHCP server and/or the gateway are handled by Neutron, the MAC\naddresses are setted automaticaly.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 18, 'created': '2013-08-23 12:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1fa29a0bb9eee4e0515c83b69a5a6dd5dbb7110', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and to specify the MAC addresses of gateway and\nDHCP server.\n\nThe DHCP MAC address is used to authorise the bootp broadcasting traffic\nand the gateway MAC address is used to unicastify the ARP braodcast\ntraffic.\n\nIf the DHCP server and/or the gateway are handled by Neutron, the MAC\naddresses are setted automaticaly.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 19, 'created': '2013-08-24 11:01:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/282e6968f681ac27d8bf8522dd3d9b3dabe25171', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and to specify the MAC addresses of gateway and\nDHCP server.\n\nThe DHCP MAC address is used to authorise the bootp broadcasting traffic\nand the gateway MAC address is used to unicastify the ARP braodcast\ntraffic.\n\nIf the DHCP server and/or the gateway are handled by Neutron, the MAC\naddresses are setted automaticaly.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 20, 'created': '2013-08-24 11:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cba7040dfbbb91a40874a609d8f2654824e4106f', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and to specify the MAC addresses of gateway and\nDHCP server.\n\nThe DHCP MAC address is used to authorise the bootp broadcasting traffic\nand the gateway MAC address is used to unicastify the ARP braodcast\ntraffic.\n\nIf the DHCP server and/or the gateway are handled by Neutron, the MAC\naddresses are setted automaticaly.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}, {'number': 21, 'created': '2013-08-24 13:41:49.000000000', 'files': ['neutron/db/isolatednetwork_db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/api/v2/attributes.py', 'neutron/tests/unit/test_extension_isolatednetwork.py', 'etc/policy.json', 'neutron/extensions/isolatednetwork.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/aeb9026d3100182622a6b77125b2931fd41c1811', 'message': 'Add network isolated extension and base class\n\nThis a part of the blueprint isolated-network\n\nThis patch extends the network object with attributes to enable or\ndisable port isolation and to specify the MAC addresses of gateway and\nDHCP server.\n\nThe DHCP MAC address is used to authorise the bootp broadcasting traffic\nand the gateway MAC address is used to unicastify the ARP braodcast\ntraffic.\n\nIf the DHCP server and/or the gateway are handled by Neutron, the MAC\naddresses are setted automaticaly.\n\nChange-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808\n'}]",66,30252,aeb9026d3100182622a6b77125b2931fd41c1811,80,10,21,55,,,0,"Add network isolated extension and base class

This a part of the blueprint isolated-network

This patch extends the network object with attributes to enable or
disable port isolation and to specify the MAC addresses of gateway and
DHCP server.

The DHCP MAC address is used to authorise the bootp broadcasting traffic
and the gateway MAC address is used to unicastify the ARP braodcast
traffic.

If the DHCP server and/or the gateway are handled by Neutron, the MAC
addresses are setted automaticaly.

Change-Id: Id7ac1acf0e8ae8121828620d4b53511957d86808
",git fetch https://review.opendev.org/openstack/neutron refs/changes/52/30252/14 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/db/db_base_plugin_v2.py', 'quantum/extensions/isolatednetwork.py', 'quantum/db/isolatednetwork_db.py', 'quantum/api/v2/attributes.py', 'etc/policy.json']",5,f00f0970bb2834a86eb510efc44f9621582e9cb8,bp/isolated-network," ""create_network:isolated:enabled"": ""rule:admin_or_owner"", ""create_network:isolated:gateway_mac_address"": ""rule:admin_or_owner"", ""create_network:isolated:dhcp_mac_address"": ""rule:admin_or_owner"", ""update_network:isolated:enabled"": ""rule:admin_or_owner"", ""update_network:isolated:gateway_mac_address"": ""rule:admin_or_owner"", ""update_network:isolated:dhcp_mac_address"": ""rule:admin_or_owner"",",,285,4
openstack%2Fneutron~master~Ic17eef0e0006e6944c912d4d5f67e04ca890cb50,openstack/neutron,master,Ic17eef0e0006e6944c912d4d5f67e04ca890cb50,"Fixes: bug #1208847 Adding description length validation in HasStatusDescription. Adding new class called LBaaSHasStatusDescription extending HasStatusDescription that validates the status is in valid LBaaS statuses set Adding test that tests both, description length validation and status validation",ABANDONED,2013-08-19 09:09:49.000000000,2013-09-04 06:03:11.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6447}, {'_account_id': 8446}]","[{'number': 1, 'created': '2013-08-19 09:09:49.000000000', 'files': ['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/db/models_v2.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6f8400b1fbf05bd26e86e7542764e3c6e3d3c0d7', 'message': 'Fixes: bug #1208847\nAdding description length validation in HasStatusDescription.\nAdding new class called LBaaSHasStatusDescription extending HasStatusDescription\nthat validates the status is in valid LBaaS statuses set\nAdding test that tests both, description length validation and status validation\n\nChange-Id: Ic17eef0e0006e6944c912d4d5f67e04ca890cb50\n'}]",5,42589,6f8400b1fbf05bd26e86e7542764e3c6e3d3c0d7,8,6,1,8446,,,0,"Fixes: bug #1208847
Adding description length validation in HasStatusDescription.
Adding new class called LBaaSHasStatusDescription extending HasStatusDescription
that validates the status is in valid LBaaS statuses set
Adding test that tests both, description length validation and status validation

Change-Id: Ic17eef0e0006e6944c912d4d5f67e04ca890cb50
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/42589/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/db/models_v2.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py']",3,6f8400b1fbf05bd26e86e7542764e3c6e3d3c0d7,bug/1208847," def test_status_validations(self): with self.pool() as pool: self.assertEqual(pool['pool']['status'], 'PENDING_CREATE') self.assertFalse(pool['pool']['status_description']) self.assertRaises(ValueError, self.plugin.update_status, context.get_admin_context(), ldb.Pool, pool['pool']['id'], 'INVALID_STATUS', 'unknown') self.plugin.update_status(context.get_admin_context(), ldb.Pool, pool['pool']['id'], 'PENDING_CREATE', '*' * 260) updated_pool = self.plugin.get_pool(context.get_admin_context(), pool['pool']['id']) self.assertEqual(updated_pool['status'], 'PENDING_CREATE') self.assertEqual(updated_pool['status_description'], '*' * 255) ",,49,4
openstack%2Fnova~master~I1815e74bc70cff988342fce95e19be9da1c91e5b,openstack/nova,master,I1815e74bc70cff988342fce95e19be9da1c91e5b,Fixes: bug #1211784,ABANDONED,2013-08-26 09:32:43.000000000,2013-09-04 06:03:10.000000000,,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 5511}]","[{'number': 1, 'created': '2013-08-26 09:32:43.000000000', 'files': ['nova/network/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ea34276e3ea77618b0fb2a5fea72baf7288b24b2', 'message': 'Fixes: bug #1211784\n\nChange-Id: I1815e74bc70cff988342fce95e19be9da1c91e5b\n'}]",0,43668,ea34276e3ea77618b0fb2a5fea72baf7288b24b2,5,3,1,8485,,,0,"Fixes: bug #1211784

Change-Id: I1815e74bc70cff988342fce95e19be9da1c91e5b
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/43668/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/manager.py'],1,ea34276e3ea77618b0fb2a5fea72baf7288b24b2,bug/1211784," networks = self.db.network_get_all_by_host(context, self.host)", networks = self.db.network_get_all(context),1,1
openstack%2Fnova~master~I7b486d6a564f93bf19d66acc04dd9b73701fa942,openstack/nova,master,I7b486d6a564f93bf19d66acc04dd9b73701fa942,Add Kazoo-powered servicegroup driver for Zookeeper,ABANDONED,2013-05-13 14:22:57.000000000,2013-09-04 06:03:10.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1561}, {'_account_id': 1711}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 2998}, {'_account_id': 5652}, {'_account_id': 6718}]","[{'number': 1, 'created': '2013-05-13 14:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ea570b2eb64192eb940cbe0e48765965df8a598', 'message': 'Replaces evzookeeper with kazoo\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 2, 'created': '2013-05-14 07:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be2d8cdae5ba95fce09391a4501ed00f829f79df', 'message': 'Replaces evzookeeper with kazoo\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 3, 'created': '2013-05-15 07:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c7f8161a96e34828e8e3f95d626d7f45abb4d6b', 'message': 'Replaces evzookeeper with kazoo\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 4, 'created': '2013-05-15 13:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90451cbc69e5757ac8b27fcc239b5ef79d6b0513', 'message': 'Replaces evzookeeper with kazoo\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 5, 'created': '2013-05-17 07:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2023670c2070252b7df8ebeb25f7ef9cabe1f6b1', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 6, 'created': '2013-05-17 07:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/efd6f6f20ee80ab8f2bbe253952234c7fc74cd34', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 7, 'created': '2013-05-28 09:28:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/511bbf1d04b22e70cee7ee064ac42acf4cfeaf7a', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 8, 'created': '2013-05-28 12:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa95c06a0c8f8a8d000cc69b7f20b77142f27635', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 9, 'created': '2013-06-03 13:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf2d8d251eeeb5c17b392f3db6c7cdf3bfed4baf', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 10, 'created': '2013-06-04 15:32:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea55089f3d00701a8c9bb182adfc87d92fd0a5c8', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 11, 'created': '2013-06-05 13:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a40d14cf10fff9b05ed93a1a3d61ac44b8d6e934', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 12, 'created': '2013-06-05 15:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d8d3ffa897fc72527262631d5c2dbd2925db53ae', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 14, 'created': '2013-06-07 12:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff66fd86bd38a12d3e55d52eab436fea4b484edf', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 13, 'created': '2013-06-07 12:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15b99533b14ee3149b8a3987eefedadc79b8bce6', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is deloped more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 15, 'created': '2013-07-02 16:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74e4b435e7051660beaee69b18a14ec0b792e0e8', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is developed more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 16, 'created': '2013-07-03 07:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c7f0291e099f708ad6da1e3e392ff41ecdad4df', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is developed more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 17, 'created': '2013-07-03 08:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de9a9e5cd947337bf74ce9e1c0e072c4d27b51f6', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is developed more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}, {'number': 18, 'created': '2013-08-27 08:34:14.000000000', 'files': ['requirements.txt', 'nova/servicegroup/drivers/kazoo.py', 'nova/servicegroup/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/43ac94df5c1e4e96de3ab339d7556a16533d60a7', 'message': 'Add Kazoo-powered servicegroup driver for Zookeeper\n\nKazoo is a pure Python implementation of Zookeeper client.\nIt is developed more actively and does not require C bindings.\nMembership function is provided directly by Zookeeper, implemented\nusing ephemeral nodes.\n\nChange-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942\nImplements: blueprint evzookeeper-kazoo\n'}]",12,28951,43ac94df5c1e4e96de3ab339d7556a16533d60a7,83,10,18,2998,,,0,"Add Kazoo-powered servicegroup driver for Zookeeper

Kazoo is a pure Python implementation of Zookeeper client.
It is developed more actively and does not require C bindings.
Membership function is provided directly by Zookeeper, implemented
using ephemeral nodes.

Change-Id: I7b486d6a564f93bf19d66acc04dd9b73701fa942
Implements: blueprint evzookeeper-kazoo
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/28951/18 && git format-patch -1 --stdout FETCH_HEAD,['nova/servicegroup/drivers/zk.py'],1,4ea570b2eb64192eb940cbe0e48765965df8a598,bp/evzookeeper-kazoo,"kazoo = importutils.try_import('kazoo') client = importutils.try_import('kazoo.client') exceptions = importutils.try_import('kazoo.exceptions') security = importutils.try_import('kazoo.security') if not all([kazoo, client, exceptions, security]): raise ImportError('kazoo module not found') self._client = client.KazooClient(hosts=CONF.zookeeper.address, timeout=CONF.zookeeper.recv_timeout) def _create(self, group, member_id): path = self._path(group, member_id) acl = security.OPEN_ACL_UNSAFE self._client.create(path, acl=acl, ephemeral=True, makepath=True) def _path(self, group, member_id=None): prefix = CONF.zookeeper.sg_prefix if member_id is None: return '%s/%s' % (prefix, group) else: return '%s/%s/%s' % (prefix, group, member_id) try: self._create(group, member_id) except exceptions.NodeExistsError: LOG.exception(_(""Unable to join. It is possible that either "" ""another node exists with the same name, or "" ""this node just restarted. We will try "" ""again in a short while to make sure."")) eventlet.sleep(CONF.zookeeper.sg_retry_interval) self._create(group, member_id) self._client.delete(self._path(group, member_id)) except exceptions.NoNodeError: path = self._path(group_id, member_id) return self._client.exists(path) is not None try: return self._client.get_children(self._path(group_id)) except exceptions.NoNodeError:","evzookeeper = importutils.try_import('evzookeeper') membership = importutils.try_import('evzookeeper.membership') zookeeper = importutils.try_import('zookeeper') if not all([evzookeeper, membership, zookeeper]): raise ImportError('zookeeper module not found') null = open(os.devnull, ""w"") self._session = evzookeeper.ZKSession(CONF.zookeeper.address, recv_timeout= CONF.zookeeper.recv_timeout, zklog_fd=null) self._memberships = {} self._monitors = {} # Make sure the prefix exists try: self._session.create(CONF.zookeeper.sg_prefix, """", acl=[evzookeeper.ZOO_OPEN_ACL_UNSAFE]) except zookeeper.NodeExistsException: pass member = self._memberships.get((group, member_id), None) if member is None: # the first time to join. Generate a new object path = ""%s/%s"" % (CONF.zookeeper.sg_prefix, group) try: member = membership.Membership(self._session, path, member_id) except RuntimeError: LOG.exception(_(""Unable to join. It is possible that either "" ""another node exists with the same name, or "" ""this node just restarted. We will try "" ""again in a short while to make sure."")) eventlet.sleep(CONF.zookeeper.sg_retry_interval) member = membership.Membership(self._session, path, member_id) self._memberships[(group, member_id)] = member key = (group, member_id) member = self._memberships[key] member.leave() del self._memberships[key] except KeyError: all_members = self.get_all(group_id) return member_id in all_members monitor = self._monitors.get(group_id, None) if monitor is None: path = ""%s/%s"" % (CONF.zookeeper.sg_prefix, group_id) monitor = membership.MembershipMonitor(self._session, path) self._monitors[group_id] = monitor # Note(maoy): When initialized for the first time, it takes a # while to retrieve all members from zookeeper. To prevent # None to be returned, we sleep 5 sec max to wait for data to # be ready. for _retry in range(50): eventlet.sleep(0.1) all_members = monitor.get_all() if all_members is not None: return all_members all_members = monitor.get_all() if all_members is None: return all_members",37,56
openstack%2Fnova~stable%2Fgrizzly~I04b59b39f66b5844bf6399051e7e328bea79e513,openstack/nova,stable/grizzly,I04b59b39f66b5844bf6399051e7e328bea79e513,VMware: enable VNC access without user having to enter password,ABANDONED,2013-08-27 13:04:55.000000000,2013-09-04 06:03:09.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}]","[{'number': 1, 'created': '2013-08-27 13:04:55.000000000', 'files': ['nova/tests/test_vmwareapi.py', 'nova/virt/vmwareapi/vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/213cc46d62736043d46b4a5424f82ce40fbbdfb2', 'message': ""VMware: enable VNC access without user having to enter password\n\nWhen the vnc_password was not configured in the 'vmware' section\nthe user was unable to access the VNC console. The user would be\nrequested to enter a password but all attempts would fail.\n\nThe 'nvc_password' was added as a workaround to the problem above.\n\nThe fix ensures that the VMware driver behaves like all of the other\nvirt drivers when it comes to the VNC access, that is, the user will\nnot have to enter a password.\n\nThe password support will be deprecated and removed in the next\nversion.\n\nFixes bug: 1215352\n\n(cherry picked from commit 7659058fad03201e41461418568797d1591067e7)\n\nChange-Id: I04b59b39f66b5844bf6399051e7e328bea79e513\n""}]",0,43876,213cc46d62736043d46b4a5424f82ce40fbbdfb2,4,2,1,8151,,,0,"VMware: enable VNC access without user having to enter password

When the vnc_password was not configured in the 'vmware' section
the user was unable to access the VNC console. The user would be
requested to enter a password but all attempts would fail.

The 'nvc_password' was added as a workaround to the problem above.

The fix ensures that the VMware driver behaves like all of the other
virt drivers when it comes to the VNC access, that is, the user will
not have to enter a password.

The password support will be deprecated and removed in the next
version.

Fixes bug: 1215352

(cherry picked from commit 7659058fad03201e41461418568797d1591067e7)

Change-Id: I04b59b39f66b5844bf6399051e7e328bea79e513
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/43876/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_vmwareapi.py', 'nova/virt/vmwareapi/vm_util.py']",2,213cc46d62736043d46b4a5424f82ce40fbbdfb2,bug/1215352," extras = [opt_enabled, opt_port] if password: opt_pass = client_factory.create('ns0:OptionValue') opt_pass.key = ""RemoteDisplay.vnc.password"" opt_pass.value = password extras.append(opt_pass) virtual_machine_config_spec.extraConfig = extras"," opt_pass = client_factory.create('ns0:OptionValue') opt_pass.key = ""RemoteDisplay.vnc.password"" opt_pass.value = password virtual_machine_config_spec.extraConfig = [opt_enabled, opt_port, opt_pass]",15,4
openstack%2Fnova~master~Iffd0b5c819ec1b28dcef038cf83ac1e1b3d4f5fd,openstack/nova,master,Iffd0b5c819ec1b28dcef038cf83ac1e1b3d4f5fd,Retry a chunk upload during Glance upload vhd,ABANDONED,2013-08-27 06:15:58.000000000,2013-09-04 06:03:09.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-08-27 06:15:58.000000000', 'files': ['plugins/xenserver/xenapi/etc/xapi.d/plugins/glance'], 'web_link': 'https://opendev.org/openstack/nova/commit/42d48733eaa67dcbc9806951525061e8b3c10231', 'message': 'Retry a chunk upload during Glance upload vhd\n\nOn a timeout exception, the chunk upload is retried using the\nsame connection.\n\nRelated to bp retry-a-chunk-upload-for-timeout-errors\n\nChange-Id: Iffd0b5c819ec1b28dcef038cf83ac1e1b3d4f5fd\n'}]",0,43834,42d48733eaa67dcbc9806951525061e8b3c10231,5,3,1,7531,,,0,"Retry a chunk upload during Glance upload vhd

On a timeout exception, the chunk upload is retried using the
same connection.

Related to bp retry-a-chunk-upload-for-timeout-errors

Change-Id: Iffd0b5c819ec1b28dcef038cf83ac1e1b3d4f5fd
",git fetch https://review.opendev.org/openstack/nova refs/changes/34/43834/1 && git format-patch -1 --stdout FETCH_HEAD,['plugins/xenserver/xenapi/etc/xapi.d/plugins/glance'],1,42d48733eaa67dcbc9806951525061e8b3c10231,bp/retry-a-chunk-upload-for-timeout-errors,"from socket import timeout except socket.timeout try conn.send(""%x\r\n%s\r\n"" % (chunk_len, chunk)) except Exception, error: raise RetryableError(error)",,6,0
openstack%2Fglance~master~I390565165c7ec856c0b7e7051e26938b3fc2f6a6,openstack/glance,master,I390565165c7ec856c0b7e7051e26938b3fc2f6a6,Add Glance NFS Storage support,ABANDONED,2013-07-29 13:57:46.000000000,2013-09-04 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 1247}, {'_account_id': 2166}, {'_account_id': 2417}, {'_account_id': 6159}, {'_account_id': 6172}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 6623}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 7534}, {'_account_id': 7711}, {'_account_id': 8291}, {'_account_id': 8391}]","[{'number': 1, 'created': '2013-07-29 13:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e46a5b54c338d6d33335c56b2575623d7a48c526', 'message': ""Added Glance NFS Storage support.\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\nImplements: blueprint glance-nfs-storage-support\n""}, {'number': 2, 'created': '2013-07-29 16:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2751266534e176ca642cc2be32ee9aa621dcbcff', 'message': ""Added Glance NFS Storage support.\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\nImplements: blueprint glance-nfs-storage-support\n""}, {'number': 3, 'created': '2013-07-29 16:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5eb55b7d362d4ca891cf9db9fac8aa0c2ae255f5', 'message': ""Added Glance NFS Storage support.\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\nImplements: blueprint glance-nfs-storage-support\n""}, {'number': 4, 'created': '2013-07-30 07:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/36798dcd2581bd88846a367af64497307cb2a446', 'message': ""Added Glance NFS Storage support.\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\nImplements: blueprint glance-nfs-storage-support\n""}, {'number': 5, 'created': '2013-07-31 15:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/38bf1cf69623d9cb8516c92fb77744bc86f4a70a', 'message': ""Added Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\nImplements: blueprint glance-nfs-storage-support\n""}, {'number': 6, 'created': '2013-08-01 14:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/897d37ed6020d3afe710b729e365d29189df6e6c', 'message': ""Added Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n""}, {'number': 7, 'created': '2013-08-01 18:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/84996e1b413f561cdbc53feac76be1348e98da50', 'message': ""Added Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n""}, {'number': 8, 'created': '2013-08-02 07:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e0b4dcc191f3d88f0dae62e7749533798742d5c6', 'message': ""Added Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n""}, {'number': 9, 'created': '2013-08-05 12:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/dcfe6b5b3f18bf25e5fd7f6fea110583c68c8cb3', 'message': ""Added Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n""}, {'number': 10, 'created': '2013-08-05 13:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/459c2f02478e433d0cf09f1d3a830e6397ceb72c', 'message': ""Added Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n""}, {'number': 11, 'created': '2013-08-05 17:02:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cf1fd9e4315d8d42458728cd792244b92f9395e7', 'message': ""Added Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n""}, {'number': 12, 'created': '2013-08-05 17:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2b32a20890d02b5af3c59ae00c9bf52daec9e51f', 'message': ""Added Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n""}, {'number': 13, 'created': '2013-08-06 12:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4c9db44b5c4c78884790b7832d2df72675ee1c56', 'message': ""Added Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n""}, {'number': 14, 'created': '2013-08-06 16:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/70315f823b2595e9ea865cbee3e240b4fbfdfb50', 'message': ""Add Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n""}, {'number': 15, 'created': '2013-08-07 07:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2613d6cc4e692d701bee7136017c839eb7d62686', 'message': ""Add Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n""}, {'number': 16, 'created': '2013-08-07 08:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/77feaeadd9201373ab0646e3a304588842299701', 'message': ""Add Glance NFS Storage support\n\nNFS Storage for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for the Glance NFS backend in test_nfs_store.py\n- Rootwrap extension\n\nThe NFS backend uses 'mount.nfs' for mounting remote NFS share.\nAll needed parameters were included to Glance configuration.\nShare mounting are performed by Glance on any request to image.\nIPv6 addresses are supported.\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n""}, {'number': 17, 'created': '2013-08-09 16:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8f705c00910880b2b0b1e3693199b81e0c7dd849', 'message': 'Added Glance NFS Storage support\n\nNFS Storage backend for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for Glance NFS backend in test_nfs_store.py\n\nThe main idea of this patch is to improve process of working between Glance and Cinder if they are both using the same NFS backend. Glance will report the direct URL for images stored on NFS storage, so that clients (such as Cinder) will be able to read the image data directly from the storage backend without downloading image from Glance.\n\nWithout NFS Store backend Glance cannot report the NFS direct URL to client (eg. Nova, Cinder). So we can not have a full support of NFS in the OpenStak and therefore full-power using devices that support NFS in production clusters (eg. FAS/NAS devices).\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n'}, {'number': 18, 'created': '2013-08-12 11:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/51af01a7e7445e60249538afe106e1e49c5b87ef', 'message': 'Add Glance NFS Storage support\n\nNFS Storage backend for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for Glance NFS backend in test_nfs_store.py\n\nThe main idea of this patch is to improve process of working between Glance\nand Cinder if they are both using the same NFS backend. Glance will report the\ndirect URL for images stored on NFS storage, so that clients (such as Cinder)\nwill be able to read the image data directly from the storage backend without\ndownloading image from Glance.\n\nWithout NFS Store backend Glance cannot report the NFS direct URL to client\n(eg. Nova, Cinder). So we can not have a full support of NFS in the OpenStak\nand therefore full-power using devices that support NFS in production clusters\n(eg. FAS/NAS devices).\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n'}, {'number': 19, 'created': '2013-08-12 12:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ae9fb37c300a6c8a441f3d30791449d5a49f90a3', 'message': 'Add Glance NFS Storage support\n\nNFS Storage backend for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for Glance NFS backend in test_nfs_store.py\n\nThe main idea of this patch is to improve process of working between Glance\nand Cinder if they are both using the same NFS backend. Glance will report the\ndirect URL for images stored on NFS storage, so that clients (such as Cinder)\nwill be able to read the image data directly from the storage backend without\ndownloading image from Glance.\n\nWithout NFS Store backend Glance cannot report the NFS direct URL to client\n(eg. Nova, Cinder). So we can not have a full support of NFS in the OpenStak\nand therefore full-power using devices that support NFS in production clusters\n(eg. FAS/NAS devices).\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n'}, {'number': 20, 'created': '2013-08-16 16:03:32.000000000', 'files': ['glance/tests/unit/test_nfs_store.py', 'requirements.txt', 'test-requirements.txt', 'etc/glance-api.conf', 'doc/source/configuring.rst', 'glance/store/nfs.py', 'etc/glance-cache.conf'], 'web_link': 'https://opendev.org/openstack/glance/commit/7458f7decbc5ac0fa70c3063e04eeb4bfdc468f5', 'message': 'Add Glance NFS Storage support\n\nNFS Storage backend for Glance was created.\nImplementation includes:\n- Store and StoreLocation classes in nfs.py\n- Unit tests for Glance NFS backend in test_nfs_store.py\n\nThe main idea of this patch is to improve process of working between Glance\nand Cinder if they are both using the same NFS backend. Glance will report the\ndirect URL for images stored on NFS storage, so that clients (such as Cinder)\nwill be able to read the image data directly from the storage backend without\ndownloading image from Glance.\n\nWithout NFS Store backend Glance cannot report the NFS direct URL to client\n(eg. Nova, Cinder). So we can not have a full support of NFS in the OpenStak\nand therefore full-power using devices that support NFS in production clusters\n(eg. FAS/NAS devices).\n\nImplements: blueprint glance-nfs-storage-support\n\nChange-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6\n'}]",207,39080,7458f7decbc5ac0fa70c3063e04eeb4bfdc468f5,134,16,20,8291,,,0,"Add Glance NFS Storage support

NFS Storage backend for Glance was created.
Implementation includes:
- Store and StoreLocation classes in nfs.py
- Unit tests for Glance NFS backend in test_nfs_store.py

The main idea of this patch is to improve process of working between Glance
and Cinder if they are both using the same NFS backend. Glance will report the
direct URL for images stored on NFS storage, so that clients (such as Cinder)
will be able to read the image data directly from the storage backend without
downloading image from Glance.

Without NFS Store backend Glance cannot report the NFS direct URL to client
(eg. Nova, Cinder). So we can not have a full support of NFS in the OpenStak
and therefore full-power using devices that support NFS in production clusters
(eg. FAS/NAS devices).

Implements: blueprint glance-nfs-storage-support

Change-Id: I390565165c7ec856c0b7e7051e26938b3fc2f6a6
",git fetch https://review.opendev.org/openstack/glance refs/changes/80/39080/3 && git format-patch -1 --stdout FETCH_HEAD,"['glance/store/__init__.py', 'glance/tests/unit/test_nfs_store.py', 'glance/common/exception.py', 'glance/common/config.py', 'etc/glance-api.conf', 'etc/rootwrap.d/nfs.filters', 'glance/store/nfs.py', 'etc/rootwrap.conf']",8,e46a5b54c338d6d33335c56b2575623d7a48c526,bp/glance-nfs-storage-support,"# Configuration for glance-rootwrap # This file should be owned by (and only-writeable by) the root user [DEFAULT] # List of directories to load filter definitions from (separated by ','). # These directories MUST all be only writeable by root ! filters_path=/etc/glance/rootwrap.d,/usr/share/glance/rootwrap # List of directories to search executables in, in case filters do not # explicitely specify a full path (separated by ',') # If not specified, defaults to system PATH environment variable. # These directories MUST all be only writeable by root ! exec_dirs=/sbin,/usr/sbin,/bin,/usr/bin # Enable logging to syslog # Default value is False use_syslog=False # Which syslog facility to use. # Valid values include auth, authpriv, syslog, user0, user1... # Default value is 'syslog' syslog_log_facility=syslog # Which messages to log. # INFO means log all usage # ERROR means only log unsuccessful attempts syslog_log_level=ERROR ",,854,0
openstack%2Fcinder~master~If3e56ab047a8eeff8bcb0f643df179524adf19b4,openstack/cinder,master,If3e56ab047a8eeff8bcb0f643df179524adf19b4,Switch from cinder.quota to common.quota,ABANDONED,2013-07-03 12:23:45.000000000,2013-09-04 06:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 2271}, {'_account_id': 4428}, {'_account_id': 7369}]","[{'number': 1, 'created': '2013-07-03 12:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6f85e3e97c9d34e2f5d121cd36be7d54f6aaf0ee', 'message': 'Switch from cinder.quota to common.quota\n\nBlueprint: common-quota\n\nwork-in-progress\n\nChange-Id: If3e56ab047a8eeff8bcb0f643df179524adf19b4\n'}, {'number': 2, 'created': '2013-07-04 12:26:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5cde2c6647b959ee29590167f25ca4c98479dc26', 'message': 'Switch from cinder.quota to common.quota\n\nBlueprint: common-quota\n\nwork-in-progress\n\nChange-Id: If3e56ab047a8eeff8bcb0f643df179524adf19b4\n'}, {'number': 3, 'created': '2013-07-04 14:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8f41db4f035de71dda632ec965d72b4bd80e798e', 'message': 'Switch from cinder.quota to common.quota\n\nBlueprint: common-quota\n\nwork-in-progress\n\nChange-Id: If3e56ab047a8eeff8bcb0f643df179524adf19b4\n'}, {'number': 4, 'created': '2013-07-10 09:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2258b2fd4b9dc7aab5ed8251b1d141a854ab9728', 'message': 'Switch from cinder.quota to common.quota\n\nBlueprint: common-quota\n\nwork-in-progress\n\nChange-Id: If3e56ab047a8eeff8bcb0f643df179524adf19b4\n'}, {'number': 5, 'created': '2013-07-10 15:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ad7270913aff8e6de399af461c9bfcaa60431c83', 'message': 'Switch from cinder.quota to common.quota\n\nBlueprint: common-quota\n\nChange-Id: If3e56ab047a8eeff8bcb0f643df179524adf19b4\n'}, {'number': 6, 'created': '2013-07-12 07:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c387207808ddc0de68443a80fd508e429185c113', 'message': 'Switch from cinder.quota to common.quota\n\nBlueprint: common-quota\n\nChange-Id: If3e56ab047a8eeff8bcb0f643df179524adf19b4\n'}, {'number': 7, 'created': '2013-07-23 08:40:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d3d47209b167e79712068093621e6eea0c67e805', 'message': 'Switch from cinder.quota to common.quota\n\nBlueprint: common-quota\n\nChange-Id: If3e56ab047a8eeff8bcb0f643df179524adf19b4\n'}, {'number': 8, 'created': '2013-08-15 12:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2db45635f46a6941ca1a2b609949736b10800a3b', 'message': 'Switch from cinder.quota to common.quota\n\nBlueprint: common-quota\n\nChange-Id: If3e56ab047a8eeff8bcb0f643df179524adf19b4\n'}, {'number': 9, 'created': '2013-08-27 09:41:41.000000000', 'files': ['cinder/tests/test_exception.py', 'cinder/volume/manager.py', 'cinder/api/contrib/quotas.py', 'cinder/api/v1/snapshot_metadata.py', 'etc/cinder/cinder.conf.sample', 'cinder/openstack/common/crypto/__init__.py', 'cinder/api/v1/volume_metadata.py', 'cinder/api/contrib/volume_type_encryption.py', 'cinder/volume/flows/create_volume.py', 'cinder/openstack/common/quota.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/test_volume.py', 'cinder/openstack/common/db/sqlalchemy/utils.py', 'cinder/api/contrib/types_extra_specs.py', 'cinder/tests/test_db_api.py', 'cinder/openstack/common/exception.py', 'cinder/exception.py', 'openstack-common.conf', 'cinder/quota.py', 'cinder/api/contrib/volume_actions.py', 'cinder/openstack/common/crypto/utils.py', 'cinder/transfer/api.py', 'cinder/db/api.py', 'cinder/api/v2/snapshot_metadata.py', 'cinder/api/contrib/backups.py', 'cinder/api/contrib/volume_transfer.py', 'cinder/tests/test_quota.py', 'cinder/db/sqlalchemy/migrate_repo/versions/019_make_user_quotas_key_and_value.py', 'cinder/api/openstack/wsgi.py', 'cinder/db/sqlalchemy/models.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e0773bbe3710dc317699ca1fa8ad7cdcf2351de5', 'message': 'Switch from cinder.quota to common.quota\n\nBlueprint: common-quota\n\nChange-Id: If3e56ab047a8eeff8bcb0f643df179524adf19b4\n'}]",6,35479,e0773bbe3710dc317699ca1fa8ad7cdcf2351de5,56,7,9,7369,,,0,"Switch from cinder.quota to common.quota

Blueprint: common-quota

Change-Id: If3e56ab047a8eeff8bcb0f643df179524adf19b4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/79/35479/9 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/openstack/common/exception.py', 'cinder/exception.py', 'cinder/openstack/common/quota.py', 'cinder/db/sqlalchemy/api.py', 'cinder/quota.py', 'cinder/tests/test_quota.py', 'cinder/tests/test_db_api.py']",7,6f85e3e97c9d34e2f5d121cd36be7d54f6aaf0ee,bp/common-quota,"from cinder.openstack.common import exception as common_exc self.assertRaises(common_exc.ReservationNotFound, self.assertRaises(common_exc.ReservationNotFound, self.assertRaises(common_exc.ReservationNotFound, self.assertRaises(common_exc.ProjectQuotaNotFound, self.assertRaises(common_exc.ProjectQuotaNotFound, self.assertRaises(common_exc.ReservationNotFound, self.assertRaises(common_exc.QuotaUsageNotFound,"," self.assertRaises(exception.ReservationNotFound, self.assertRaises(exception.ReservationNotFound, self.assertRaises(exception.ReservationNotFound, self.assertRaises(exception.ProjectQuotaNotFound, self.assertRaises(exception.ProjectQuotaNotFound, self.assertRaises(exception.ReservationNotFound, self.assertRaises(exception.QuotaUsageNotFound,",1175,829
openstack%2Fnova~master~I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f,openstack/nova,master,I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f,Support multiple active scheduler policies/configurations,ABANDONED,2013-07-17 06:59:53.000000000,2013-09-04 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1636}, {'_account_id': 1653}, {'_account_id': 1782}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2667}, {'_account_id': 2889}, {'_account_id': 3094}, {'_account_id': 7238}, {'_account_id': 7494}]","[{'number': 1, 'created': '2013-07-17 06:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df6848832ac1e41d68587e2431dd410156ecdf10', 'message': 'blueprint multiple-scheduler-drivers\nAdd initial support for multiple scheduler policies in a single scheduler environment\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 2, 'created': '2013-07-17 08:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ae069b06edbeddf3ae790df492357ba4570c5f5', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nimplements blueprint multiple-scheduler-drivers\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 3, 'created': '2013-07-18 07:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ee2429018d57329a5b1345148de7be2f6927afb', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nimplements blueprint multiple-scheduler-drivers\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 4, 'created': '2013-07-18 10:24:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59d8dab4abe24873b4b097862a56821295d5320f', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nimplements blueprint multiple-scheduler-drivers\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 5, 'created': '2013-07-21 06:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4b75b4c532b1c1063adf2f14bd2cd075f16a98a', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nimplements blueprint multiple-scheduler-drivers\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 6, 'created': '2013-07-21 15:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be3eb659ff5f8af8f081dcf26ec4cc41da504134', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nCurrently supports Filterscheduler\nimplements blueprint multiple-scheduler-drivers\n\nTODO: add tests\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 7, 'created': '2013-07-22 21:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae977b4a445f0ef644ac562d93d539636f0cfe8e', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nCurrently supports Filterscheduler\nimplements blueprint multiple-scheduler-drivers\n\nadded initial tests\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 8, 'created': '2013-07-24 19:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb6ece8a0b4d9fa85c6f593af14cfcc30b7e2474', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nCurrently supports Filterscheduler\nimplements blueprint multiple-scheduler-drivers\n\nwork in progress: according to on going discussion in the ML,\n                  remove the policy based host filtering and\n                  remove the policy selection\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 9, 'created': '2013-07-25 08:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d632e04a2b3177194a62ab129729876df20d9c9d', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nCurrently supports Filterscheduler\nimplements blueprint multiple-scheduler-drivers\n\nTODO tests\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 10, 'created': '2013-07-25 10:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1fd02f7b222435778d52ff544fa30b4b385464c3', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nCurrently supports Filterscheduler\nimplements blueprint multiple-scheduler-drivers\n\nTODO tests\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 11, 'created': '2013-07-25 13:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1d182567b7375be987a17b7edada1ada415d372', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nCurrently supports Filterscheduler\nimplements blueprint multiple-scheduler-drivers\n\nTODO tests\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 12, 'created': '2013-07-27 09:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e378be10db6b085f1baa9c12a41909cf827c50fe', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nCurrently supports FilterScheduler\nimplements blueprint multiple-scheduler-drivers\n\nTODO tests\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 13, 'created': '2013-07-27 10:27:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2ce451a48bbbebf2fb2b9fc9b0582549ca32f1fc', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nCurrently supports FilterScheduler\nimplements blueprint multiple-scheduler-drivers\n\nTODO tests\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 14, 'created': '2013-07-27 13:37:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95270a56795b2bbd3e0f7e4abb607373fdd221b4', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nCurrently supports FilterScheduler\nimplements blueprint multiple-scheduler-drivers\n\nTODO tests\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 15, 'created': '2013-07-29 13:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc834cb4425028414837bd60a4c2bac18857d395', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single scheduler environment\nCurrently supports FilterScheduler\nimplements blueprint multiple-scheduler-drivers\n\nTODO tests\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 16, 'created': '2013-07-29 22:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb1118009e42de3a271f1ace9e09c37c4816cc95', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single\nscheduler environment\nCurrently supports FilterScheduler\nimplements blueprint multiple-scheduler-drivers\n\nTODO tests\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 17, 'created': '2013-07-29 22:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc56d55613eed4d917acc1d13ea86f6863c1d141', 'message': 'WIP: multiple scheduler policies (drivers)\n\nAdd initial support for multiple scheduler policies in a single\nscheduler environment\nCurrently supports FilterScheduler\nimplements blueprint multiple-scheduler-drivers\n\nTODO tests\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 18, 'created': '2013-07-31 22:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cdd89242a82fa8450db659b60f689a79965e63b4', 'message': 'WIP: multiple scheduler policies (drivers)\n\nSupport multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nEach valid policy/configuration is specified in nova.conf, allowing to\noverride scheduler-related options such as driver, filters, etc. (note:\nin the future, this is likely to be replaced with more dynamic,\nAPI-driven, life cycle).\n\nOn instance provisioning, desired policy is chosen using corresponding\nkey-value in the flavor extra spec (note: in the future, additional\nmechanisms for policy selection will be considered).\nAlso, optionally, a new filter can be used with FilterScheduler to\nrestrict applicable host aggregates to those specifying a matching\npolicy.\n\nimplements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 19, 'created': '2013-08-01 11:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48f2c227214ed4ba680379718d50f482007665f1', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nEach valid policy/configuration is specified in nova.conf, allowing to\noverride scheduler-related options such as driver, filters, etc. (note:\nin the future, this is likely to be replaced with more dynamic,\nAPI-driven, life cycle).\n\nOn instance provisioning, desired policy is chosen using corresponding\nkey-value in the flavor extra spec (note: in the future, additional\nmechanisms for policy selection will be considered).\nAlso, optionally, a new filter can be used with FilterScheduler to\nrestrict applicable host aggregates to those specifying a matching\npolicy.\n\nimplements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 20, 'created': '2013-08-06 14:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f619335ef78e3edbfc1657f7bd73865fbb7e93b', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nScheduler parameters (drivers, filters, options, etc) can be overridden\nby specifying them in flavor extra spec, with ""sched:"" key namespace.\n\nPartially implements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 21, 'created': '2013-08-06 14:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/29a83143f545361b3305a2fca93dbe3ff26db4a0', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nScheduler parameters (drivers, filters, options, etc) can be overridden\nby specifying them in flavor extra spec, with ""sched:"" key namespace.\n\nPartially implements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 22, 'created': '2013-08-06 16:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6eef8e5c67c7ad1be77c4b8e7d0a24369b02067a', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nScheduler parameters (drivers, filters, options, etc) can be overridden\nby specifying them in flavor extra spec, with ""sched:"" key namespace.\n\nPartially implements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 23, 'created': '2013-08-12 12:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f729363ba40ff72c970999b1c784e3dc8891689', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nScheduler parameters (drivers, filters, options, etc) can be overridden\nby specifying them in flavor extra spec, with ""sched:"" key namespace.\n\nPartially implements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 24, 'created': '2013-08-12 12:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b22defbca7f2f11aa8534fac57420afe7688960', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nScheduler parameters (drivers, filters, options, etc) can be overridden\nby specifying them in flavor extra spec, with ""sched:"" key namespace.\n\nPartially implements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 25, 'created': '2013-08-14 10:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b1c8c6c3116bd1bb8adab7d46d0116c6b829dac6', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nScheduler parameters (drivers, filters, options, etc) can be overridden\nby specifying them in flavor extra spec, with ""sched:"" key namespace.\n\nPartially implements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 26, 'created': '2013-08-15 11:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8954cf067359bb64481ff220ac726af8763caa4f', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nScheduler parameters (drivers, filters, options, etc) can be overridden\nby specifying them in flavor extra spec, with ""sched:"" key namespace.\n\nPartially implements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 27, 'created': '2013-08-20 12:44:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12eceb29c0bb3d618748936fa46e7e5eb3567fa4', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nScheduler parameters (drivers, filters, options, etc) can be overridden\nby specifying them in flavor extra spec, with ""sched:"" key namespace.\n\nPartially implements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 28, 'created': '2013-08-21 12:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fd2908c7cf8c71e3c10e9f68727b2febf7536cb', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nScheduler parameters (drivers, filters, options, etc) can be overridden\nby specifying them in flavor extra spec, with ""sched:"" key namespace.\n\nPartially implements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 29, 'created': '2013-08-25 12:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd76e50af4f859b88aacb22f03c14b655055f482', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nScheduler parameters (drivers, filters, options, etc) can be overridden\nby specifying them in flavor extra spec, with ""sched:"" key namespace.\n\nPartially implements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}, {'number': 30, 'created': '2013-08-25 14:26:45.000000000', 'files': ['nova/scheduler/filters/io_ops_filter.py', 'nova/scheduler/manager.py', 'nova/scheduler/filters/availability_zone_filter.py', 'nova/scheduler/filters/disk_filter.py', 'nova/scheduler/utils.py', 'nova/scheduler/policies_scheduler.py', 'nova/scheduler/filters/ram_filter.py', 'nova/tests/scheduler/test_host_manager.py', 'nova/scheduler/filters/core_filter.py', 'nova/tests/scheduler/test_policies_scheduler.py', 'nova/scheduler/filters/num_instances_filter.py', 'nova/scheduler/filters/isolated_hosts_filter.py', 'nova/scheduler/host_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/71e3978138eee4e1484f0fb324cc85e0c7b87bce', 'message': 'Support multiple active scheduler policies/configurations\n\nAllows maintaining multiple active scheduler policies/configurations\nwithin a single Nova deployment.\nScheduler parameters (drivers, filters, options, etc) can be overridden\nby specifying them in flavor extra spec, with ""sched:"" key namespace.\n\nPartially implements blueprint multiple-scheduler-drivers\n\nDocImpact\n\nChange-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f\n'}]",102,37407,71e3978138eee4e1484f0fb324cc85e0c7b87bce,116,13,30,7238,,,0,"Support multiple active scheduler policies/configurations

Allows maintaining multiple active scheduler policies/configurations
within a single Nova deployment.
Scheduler parameters (drivers, filters, options, etc) can be overridden
by specifying them in flavor extra spec, with ""sched:"" key namespace.

Partially implements blueprint multiple-scheduler-drivers

DocImpact

Change-Id: I8bcd3e48d8047b0ff19c435c7c8ae49cdb24352f
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/37407/30 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/manager.py'],1,df6848832ac1e41d68587e2431dd410156ecdf10,bp/multiple-scheduler-drivers,"scheduler_driver_opts = [ cfg.StrOpt('scheduler_driver', default='nova.scheduler.filter_scheduler.FilterScheduler', help='Default driver to use for the scheduler'), cfg.StrOpt('scheduler_policies_manager', default='nova.scheduler.scheduler_policies.policies_scheduler.PoliciesScheduler', help='Default policies manager to use for the scheduler'), cfg.ListOpt('enabled_scheduler_policies', default=None, help='The list of scheduler policies'),]CONF.register_opt(scheduler_driver_opts) if CONF.enabled_scheduler_policies: self.driver = importutils.import_object(CONF.scheduler_policies_manager, scheduler_driver) else: self.driver = importutils.import_object(scheduler_driver)","scheduler_driver_opt = cfg.StrOpt('scheduler_driver', default='nova.scheduler.filter_scheduler.FilterScheduler', help='Default driver to use for the scheduler')CONF.register_opt(scheduler_driver_opt) self.driver = importutils.import_object(scheduler_driver)",16,5
openstack%2Fnova~master~I8cb6b2c6892743417e93235d506af1b2fda6b18c,openstack/nova,master,I8cb6b2c6892743417e93235d506af1b2fda6b18c,VMware: Add support for resource pool in VMware Drivers,ABANDONED,2013-08-27 15:45:36.000000000,2013-09-04 06:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 7575}, {'_account_id': 7629}]","[{'number': 1, 'created': '2013-08-27 15:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26d9c78b9c43f7e6cc7655ed1db449825348477e', 'message': 'Add support for resource pool in VMware Drivers\n\nCurrently, VMware drivers boot instances in the root resource\npool of a compute resource (host or cluster). This patch allows\nadmins to specify a resource pool inside the compute resource.\n\nChange-Id: I8cb6b2c6892743417e93235d506af1b2fda6b18c\nFixes: bug #1105032\n'}, {'number': 2, 'created': '2013-08-27 16:30:31.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'etc/nova/nova.conf.sample', 'nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/virt/vmwareapi/vim_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7f16513bb7bda776017ddc14dc4abb29270d9307', 'message': 'VMware: Add support for resource pool in VMware Drivers\n\nCurrently, VMware drivers boot instances in the root resource\npool of a compute resource (host or cluster). This patch allows\nadmins to specify a resource pool inside the compute resource.\n\nChange-Id: I8cb6b2c6892743417e93235d506af1b2fda6b18c\nFixes: bug #1105032\n'}]",0,43908,7f16513bb7bda776017ddc14dc4abb29270d9307,8,6,2,1653,,,0,"VMware: Add support for resource pool in VMware Drivers

Currently, VMware drivers boot instances in the root resource
pool of a compute resource (host or cluster). This patch allows
admins to specify a resource pool inside the compute resource.

Change-Id: I8cb6b2c6892743417e93235d506af1b2fda6b18c
Fixes: bug #1105032
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/43908/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/virt/vmwareapi/vim_util.py']",4,26d9c78b9c43f7e6cc7655ed1db449825348477e,bug/1105032,"def build_object_spec(client_factory, root_folder, traversal_specs, skip=False): object_spec.skip = skipdef get_contained_objects(vim, mobj, nested_type, recursive=True): """"""Gets the descendant Managed Objects of a Managed Entity."""""" client_factory = vim.client.factory collector = vim.get_service_content().propertyCollector view_mgr = vim.get_service_content().viewManager # A container view managed object provides a means of monitoring the # contents of a single container # Eg. of a container :- HostSystem, ClusterComputeResource # This view object can be further narrowed by specifying a descendant type. # Eg. ResourcePool for HostSystem or ClusterComputeResource # If recursive is set to true, the view extends to include nested objects # of the descendant type # Eg. Resource Pools contained inside the parent Resource Pools container_view = vim.CreateContainerView(view_mgr, container=mobj, type=[nested_type], recursive=recursive) # Create a filter spec for the requested properties property_spec = build_property_spec(client_factory, type=nested_type, properties_to_collect=[""name""], all_properties=False) # Traversal spec determines the object traversal path to search for the # specified property. The following is the default for a container view traversal_spec = build_traversal_spec(client_factory, ""view"", ""ContainerView"", ""view"", False, None) # Create an object spec with the traversal spec object_spec = build_object_spec(client_factory, container_view, [traversal_spec], True) # Create a property filter spec with the property spec & object spec property_filter_spec = client_factory.create('ns0:PropertyFilterSpec') property_filter_spec.propSet = [property_spec] property_filter_spec.objectSet = [object_spec] options = client_factory.create('ns0:RetrieveOptions') options.maxObjects = CONF.vmware.maximum_objects return vim.RetrievePropertiesEx(collector, specSet=[property_filter_spec], options=options) ","def build_object_spec(client_factory, root_folder, traversal_specs): object_spec.skip = False",93,18
openstack%2Fdevstack~stable%2Fgrizzly~I25fbb23f4823b3766db647dd50a5b538aad3e55a,openstack/devstack,stable/grizzly,I25fbb23f4823b3766db647dd50a5b538aad3e55a,renamed deprecated glanceclient parameter,ABANDONED,2013-08-22 19:24:18.000000000,2013-09-04 06:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 970}, {'_account_id': 6593}]","[{'number': 1, 'created': '2013-08-22 19:24:18.000000000', 'files': ['functions', 'lib/baremetal'], 'web_link': 'https://opendev.org/openstack/devstack/commit/c046fdc8b8ecde4240b58e81d8f8df58c58c861f', 'message': 'renamed deprecated glanceclient parameter\n\nAccording to the sources the parameter --public in python-glanceclient\nshould be removed after only using the new parameter --is-public in\nDevstack.\n\nFixes: bug 1214094\nChange-Id: I25fbb23f4823b3766db647dd50a5b538aad3e55a\n(cherry picked from commit a7a219ab76d4a346f794daafd499ece5c32c5e3c)\n'}]",0,43334,c046fdc8b8ecde4240b58e81d8f8df58c58c861f,5,4,1,6593,,,0,"renamed deprecated glanceclient parameter

According to the sources the parameter --public in python-glanceclient
should be removed after only using the new parameter --is-public in
Devstack.

Fixes: bug 1214094
Change-Id: I25fbb23f4823b3766db647dd50a5b538aad3e55a
(cherry picked from commit a7a219ab76d4a346f794daafd499ece5c32c5e3c)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/34/43334/1 && git format-patch -1 --stdout FETCH_HEAD,"['functions', 'lib/baremetal']",2,c046fdc8b8ecde4240b58e81d8f8df58c58c861f,bug/1214094," --is-public True --disk-format=aki \ --is-public True --disk-format=ari \ --is-public True --disk-format=aki \ --is-public True --disk-format=ari \ --name ""$IMAGE_NAME-kernel"" --is-public True \ --name ""$IMAGE_NAME-ramdisk"" --is-public True \ --name ""${IMAGE_NAME%.img}"" --is-public True \"," --public --disk-format=aki \ --public --disk-format=ari \ --public --disk-format=aki \ --public --disk-format=ari \ --name ""$IMAGE_NAME-kernel"" --public \ --name ""$IMAGE_NAME-ramdisk"" --public \ --name ""${IMAGE_NAME%.img}"" --public \",12,12
openstack%2Fpython-glanceclient~master~I828d98ab6fd8bcf813c52276b79337f782482c94,openstack/python-glanceclient,master,I828d98ab6fd8bcf813c52276b79337f782482c94,Adding glanceclient version,ABANDONED,2013-08-06 05:07:06.000000000,2013-09-04 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 4463}, {'_account_id': 5347}, {'_account_id': 6159}]","[{'number': 1, 'created': '2013-08-06 05:07:06.000000000', 'files': ['glanceclient/common/service.py', 'glanceclient/common/base_image_service.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/ccbe921c1d17a7aed15c8e02cd7900e3795c3a47', 'message': 'Adding glanceclient version\n\nNova should be configured to use glanceclient V1 or V2. Adds an extra\nparameter in the conf to specify this value. Currently it is hardcoded\nto 1 in all the glanceclient calls\n\nChange-Id: I828d98ab6fd8bcf813c52276b79337f782482c94\nImplements: blueprint glanceclient-version\n'}]",0,40346,ccbe921c1d17a7aed15c8e02cd7900e3795c3a47,5,4,1,7701,,,0,"Adding glanceclient version

Nova should be configured to use glanceclient V1 or V2. Adds an extra
parameter in the conf to specify this value. Currently it is hardcoded
to 1 in all the glanceclient calls

Change-Id: I828d98ab6fd8bcf813c52276b79337f782482c94
Implements: blueprint glanceclient-version
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/46/40346/1 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/common/service.py', 'glanceclient/common/base_image_service.py']",2,ccbe921c1d17a7aed15c8e02cd7900e3795c3a47,bp/glanceclient-version," version = kwargs.get('version', CONF.glance.glanceclient_version) self.client = client.Client(version,"," self.client = client.Client(str(self.version),",5,1
openstack%2Fpuppet-keystone~master~If11e3eccf145b5f87e6c8979f42665577e35b50b,openstack/puppet-keystone,master,If11e3eccf145b5f87e6c8979f42665577e35b50b,WIP: Adds Support to Manage SSL,ABANDONED,2013-07-30 04:12:07.000000000,2013-09-04 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1247}, {'_account_id': 1926}, {'_account_id': 2166}, {'_account_id': 2265}, {'_account_id': 6836}, {'_account_id': 6924}, {'_account_id': 6967}, {'_account_id': 7360}, {'_account_id': 7662}]","[{'number': 1, 'created': '2013-07-30 04:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/7ee98083ba9d92c65a31688eac5134d31292c037', 'message': 'Adds Support to Manage SSL\n\nThe keystone class provides UUID and PKI token formats, but does\nnot provide the ability to manage SSL.  This patch introduces the\nenable_ssl parameter that allows users to enable and disable SSL.\n\nDefaults to true for backwards compatibility and to enable SSL.\n\nChange-Id: If11e3eccf145b5f87e6c8979f42665577e35b50b\n'}, {'number': 2, 'created': '2013-08-02 18:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/ce0792a068709f514db24bba0d97d79e01ceae42', 'message': 'Adds Support to Manage SSL\n\nThe keystone class provides UUID and PKI token formats, but does\nnot provide the ability to manage SSL.  This patch introduces the\nenable_ssl parameter that allows users to enable and disable SSL.\n\nDefaults to true for backwards compatibility and to enable SSL.\n\nChange-Id: If11e3eccf145b5f87e6c8979f42665577e35b50b\n'}, {'number': 3, 'created': '2013-08-09 16:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/4cc083924b11c3533ab81e4dd2cdcb423c0cb6d6', 'message': 'Adds Support to Manage SSL\n\nThe keystone class provides UUID and PKI token formats, but does\nnot provide the ability to manage SSL.  This patch introduces the\nenable_ssl parameter that allows users to enable and disable SSL.\n\nDefaults to true for backwards compatibility and to enable SSL.\n\nChange-Id: If11e3eccf145b5f87e6c8979f42665577e35b50b\n'}, {'number': 4, 'created': '2013-08-20 18:28:35.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/4b21de832618430d3397163b83d6b5cd3648ea80', 'message': 'WIP: Adds Support to Manage SSL\n\nThe keystone class provides UUID and PKI token formats, but does\nnot provide the ability to manage SSL.  This patch introduces the\nenable_ssl parameter that allows users to enable and disable SSL.\n\nDefaults to false for backwards compatibility and to disable SSL.\n\nChange-Id: If11e3eccf145b5f87e6c8979f42665577e35b50b\n'}]",0,39205,4b21de832618430d3397163b83d6b5cd3648ea80,28,11,4,6836,,,0,"WIP: Adds Support to Manage SSL

The keystone class provides UUID and PKI token formats, but does
not provide the ability to manage SSL.  This patch introduces the
enable_ssl parameter that allows users to enable and disable SSL.

Defaults to false for backwards compatibility and to disable SSL.

Change-Id: If11e3eccf145b5f87e6c8979f42665577e35b50b
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/05/39205/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_spec.rb', 'manifests/init.pp']",2,7ee98083ba9d92c65a31688eac5134d31292c037,ssl,"# [enable_ssl] Enable/Disable SSL support for Keystone authentication. Optional. Defaults to true. $enable_ssl = true, # ssl config keystone_config { 'ssl/enable': value => $enable_ssl; } ",,18,0
openstack%2Fnova~master~I08da7cba3319242c5ad2fe0f48f563be64c7c223,openstack/nova,master,I08da7cba3319242c5ad2fe0f48f563be64c7c223,Switch from nova.quota to common.quota,ABANDONED,2013-07-04 15:17:57.000000000,2013-09-04 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 4428}, {'_account_id': 5754}, {'_account_id': 7369}]","[{'number': 1, 'created': '2013-07-04 15:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3b08ecd975c8117e0de932722eb2ff436f48321', 'message': 'Switch from nova.quota to common.quota\n\nblueprint bp/common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}, {'number': 2, 'created': '2013-07-23 10:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c8a48d57002ca60ca798daadbb6434e257a6178b', 'message': 'Switch from nova.quota to common.quota\n\nblueprint bp/common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}, {'number': 3, 'created': '2013-07-23 10:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b0e854df025a651a2d6ff7233877d3b004c4f402', 'message': 'Switch from nova.quota to common.quota\n\nblueprint common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}, {'number': 4, 'created': '2013-07-30 09:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9cd66ecf5c89a883a74e0b4239867b17766007e', 'message': 'Switch from nova.quota to common.quota\n\nblueprint common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}, {'number': 5, 'created': '2013-07-30 09:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/165f30bd4dffb962640ffffc287587d03ef2da0b', 'message': 'Switch from nova.quota to common.quota\n\nblueprint common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}, {'number': 6, 'created': '2013-07-30 13:08:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5417b75039e3fb50ed321a3df9eff91c8702257d', 'message': 'Switch from nova.quota to common.quota\n\nblueprint common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}, {'number': 7, 'created': '2013-08-02 08:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f953ee3a5a859602c21c6ab9dfa59a9906fe8e4', 'message': 'Switch from nova.quota to common.quota\n\nblueprint common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}, {'number': 8, 'created': '2013-08-02 12:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/537f5278e9d01c6a0d986be47fb19730ef82a91b', 'message': 'Switch from nova.quota to common.quota\n\nblueprint common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}, {'number': 9, 'created': '2013-08-06 09:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45f6397d4f5caeae1b263ac209a4a947709d01b4', 'message': 'Switch from nova.quota to common.quota\n\nblueprint common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}, {'number': 10, 'created': '2013-08-08 08:08:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/76bac4a5c47691f591495247f2ab50855dd0a2c5', 'message': 'Switch from nova.quota to common.quota\n\nblueprint common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}, {'number': 11, 'created': '2013-08-15 12:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1b91d9c685f400eadddc7f85aca70c4c0867ec24', 'message': 'Switch from nova.quota to common.quota\n\nblueprint common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}, {'number': 12, 'created': '2013-08-27 09:42:05.000000000', 'files': ['nova/api/ec2/__init__.py', 'nova/api/openstack/compute/contrib/quota_classes.py', 'nova/network/manager.py', 'nova/api/openstack/compute/plugins/v3/quota_sets.py', 'nova/api/openstack/common.py', 'nova/db/sqlalchemy/api.py', 'nova/tests/api/openstack/compute/test_api.py', 'nova/api/openstack/compute/contrib/deferred_delete.py', 'nova/api/openstack/compute/plugins/v3/server_metadata.py', 'nova/tests/test_quota.py', 'openstack-common.conf', 'nova/tests/db/test_db_api.py', 'nova/compute/api.py', 'nova/api/openstack/compute/server_metadata.py', 'nova/tests/compute/test_compute_cells.py', 'nova/api/openstack/compute/contrib/quotas.py', 'nova/api/openstack/compute/servers.py', 'nova/network/floating_ips.py', 'nova/tests/api/openstack/fakes.py', 'nova/tests/compute/test_compute_api.py', 'nova/exception.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'etc/nova/nova.conf.sample', 'nova/api/openstack/compute/contrib/os_tenant_networks.py', 'nova/api/openstack/compute/plugins/v3/quota_classes.py', 'nova/api/openstack/compute/plugins/v3/deferred_delete.py', 'nova/quota.py', 'nova/openstack/common/quota.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ffa2083b3d915cc3b05f608d899bee2019c2b22d', 'message': 'Switch from nova.quota to common.quota\n\nblueprint common-quota\n\nChange-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223\n'}]",8,35668,ffa2083b3d915cc3b05f608d899bee2019c2b22d,59,9,12,7369,,,0,"Switch from nova.quota to common.quota

blueprint common-quota

Change-Id: I08da7cba3319242c5ad2fe0f48f563be64c7c223
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/35668/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_cells.py', 'nova/api/openstack/compute/contrib/quota_classes.py', 'nova/network/manager.py', 'nova/api/openstack/compute/plugins/v3/quota_sets.py', 'nova/api/openstack/common.py', 'nova/cmd/manage.py', 'nova/api/openstack/compute/contrib/quotas.py', 'nova/db/sqlalchemy/api.py', 'nova/network/floating_ips.py', 'nova/tests/test_exception.py', 'nova/tests/api/openstack/fakes.py', 'nova/tests/api/openstack/compute/test_api.py', 'nova/exception.py', 'nova/openstack/common/exception.py', 'nova/api/openstack/compute/contrib/os_tenant_networks.py', 'nova/tests/test_quota.py', 'openstack-common.conf', 'nova/quota.py', 'nova/tests/db/test_db_api.py', 'nova/openstack/common/quota.py', 'nova/compute/api.py']",21,d3b08ecd975c8117e0de932722eb2ff436f48321,bp/common-quota,from nova.openstack.common import exception as common_exc except common_exc.OverQuota: except common_exc.OverQuota as exc: except common_exc.OverQuota as exc: except common_exc.OverQuota as exc: except common_exc.OverQuota as exc: except common_exc.OverQuota: except common_exc.OverQuota: except common_exc.OverQuota:, except exception.OverQuota: except exception.OverQuota as exc: except exception.OverQuota as exc: except exception.OverQuota as exc: except exception.OverQuota as exc: except exception.OverQuota: except exception.OverQuota: except exception.OverQuota:,1376,1177
openstack%2Fpython-keystoneclient~master~I4a313fe98144e881422c12c3dc9d04d4c359898d,openstack/python-keystoneclient,master,I4a313fe98144e881422c12c3dc9d04d4c359898d,Shrink the parameter list.,ABANDONED,2013-08-28 01:08:53.000000000,2013-09-04 06:03:03.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-08-28 01:08:53.000000000', 'files': ['keystoneclient/auth/identity/base.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/312beddd0f4ce5fb1bbc8605d85b2099e258fc00', 'message': 'Shrink the parameter list.\n\nChange-Id: I4a313fe98144e881422c12c3dc9d04d4c359898d\n'}]",0,43979,312beddd0f4ce5fb1bbc8605d85b2099e258fc00,4,1,1,2218,,,0,"Shrink the parameter list.

Change-Id: I4a313fe98144e881422c12c3dc9d04d4c359898d
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/79/43979/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/auth/identity/base.py'],1,312beddd0f4ce5fb1bbc8605d85b2099e258fc00,bp/auth-plugins,"PARAM_NAMES = ['username', 'tenant_id', 'tenant_name', 'password', 'auth_url', 'region_name', 'timeout', 'endpoint', 'token', 'auth_ref', 'use_keyring', 'force_new_token', 'stale_duration', 'user_id', 'user_domain_id', 'user_domain_name', 'domain_id', 'domain_name', 'project_id', 'project_name', 'project_domain_id', 'project_domain_name', 'trust_id'] def __init__(self, *args, **kwargs): p = {} for name in PARAM_NAMES: if len(args): p[name](args.pop) if kwargs.get(name): p[name] = kwargs[name] setattr(self, ""_"" + name, p.get(name)) self._password = None if p.get('auth_ref'): auth_ref = p['auth_ref'] p.pop('auth_ref') if p.get('tenant_id'): self._project_id = p.get('tenant_id') if p.get('tenant_name'): self._project_name = p.get('tenant_name') for name in PARAM_NAMES: if p.get(name): setattr(self, ""_"" + name, p.get(name)) if p.get('user_domain_id'): self._user_domain_id = p.get('user_domain_id') elif not (self._user_id or p.get('user_domain_name')): if p.get('project_domain_id'): self._project_domain_id = p.get('project_domain_id') elif not (p.get('project_id') or p.get('project_domain_name')): if p.get('auth_url'): self._auth_url = p.get('auth_url').rstrip('/') if p.get('token'): self._auth_token_from_user = p.get('token') if p.get('endpoint'): self._management_url = p.get('endpoint').rstrip('/') if p.get('use_keyring') and keyring is None: self._use_keyring = p.get('use_keyring') and keyring is not None self._force_new_token = p.get('force_new_token') self._stale_duration = (p.get('stale_duration') or access.STALE_TOKEN_DURATION)"," def __init__(self, username=None, tenant_id=None, tenant_name=None, password=None, auth_url=None, region_name=None, timeout=None, endpoint=None, token=None, auth_ref=None, use_keyring=False, force_new_token=False, stale_duration=None, user_id=None, user_domain_id=None, user_domain_name=None, domain_id=None, domain_name=None, project_id=None, project_name=None, project_domain_id=None, project_domain_name=None, trust_id=None): if auth_ref: if tenant_id: self._project_id = tenant_id if tenant_name: self._project_name = tenant_name self._password = password if user_id: self._user_id = user_id if username: self._username = username if user_domain_id: self._user_domain_id = user_domain_id elif not (user_id or user_domain_name): if user_domain_name: self._user_domain_name = user_domain_name if domain_id: self._domain_id = domain_id if domain_name: self._domain_name = domain_name if project_id: self._project_id = project_id if project_name: self._project_name = project_name if project_domain_id: self._project_domain_id = project_domain_id elif not (project_id or project_domain_name): if project_domain_name: self._project_domain_name = project_domain_name if trust_id: self._trust_id = trust_id if auth_url: self._auth_url = auth_url.rstrip('/') if token: self._auth_token_from_user = token if endpoint: self._management_url = endpoint.rstrip('/') self._region_name = region_name if use_keyring and keyring is None: self._use_keyring = use_keyring and keyring is not None self._force_new_token = force_new_token self._stale_duration = stale_duration or access.STALE_TOKEN_DURATION",46,50
openstack%2Fnova~master~I7c4a763dc4f0c0e554d5b2c47faa233bed0d4c60,openstack/nova,master,I7c4a763dc4f0c0e554d5b2c47faa233bed0d4c60,nova failures when vCenter has multiple datacenters,ABANDONED,2013-08-26 20:15:28.000000000,2013-09-04 06:03:03.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}]","[{'number': 1, 'created': '2013-08-26 20:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a76c9cd915a5223628f23328a856dffd9b50a28c', 'message': 'nova failures when vCenter has multiple datacenters\n\nCalculates the datacenter that should be used when there\nis more than one in a vCenter. Does not negatively\naffect ESXi driver.\n\naddresses bug/1180044\n\nChange-Id: I7c4a763dc4f0c0e554d5b2c47faa233bed0d4c60\n'}, {'number': 2, 'created': '2013-08-27 22:55:56.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/virt/vmwareapi/vim_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8ada30f3469166d0d57d7935abfa530c2b2f6c36', 'message': 'nova failures when vCenter has multiple datacenters\n\nCalculates the datacenter that should be used when there\nis more than one in a vCenter. Does not negatively\naffect ESXi driver.\n\naddresses bug/1180044\n\nChange-Id: I7c4a763dc4f0c0e554d5b2c47faa233bed0d4c60\n'}]",0,43774,8ada30f3469166d0d57d7935abfa530c2b2f6c36,9,2,2,7629,,,0,"nova failures when vCenter has multiple datacenters

Calculates the datacenter that should be used when there
is more than one in a vCenter. Does not negatively
affect ESXi driver.

addresses bug/1180044

Change-Id: I7c4a763dc4f0c0e554d5b2c47faa233bed0d4c60
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/43774/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/virt/vmwareapi/vim_util.py']",2,a76c9cd915a5223628f23328a856dffd9b50a28c,bug/1214850," def get_datacenter_for_a_vm(vim, vm_ref, property_list = None): """"""retrieves the datacenter for a datastore. Object data will have the following structure: (ObjectContent){ obj = (obj){ value = ""datacenter-2"" _type = ""Datacenter"" } propSet[] = (DynamicProperty){ name = ""name"" val = ""dc000"" }, (DynamicProperty){ name = ""vmFolder"" val = (val){ value = ""group-v3"" _type = ""Folder"" } }, } :param vim: soap stub :param datastore_ref: datastore to use :param property_list: additional properties to gather :return: ObjectContent object representing datacenter """""" #TODO(hartsocks): Traversal spec here. ds_ref_ret = get_dynamic_property(vim,vm_ref,""VirtualMachine"",""datastore"") if ds_ref_ret is None: raise exception.DatastoreNotFound() ds_ref = ds_ref_ret.ManagedObjectReference[0] if property_list is None: property_list = ['name'] # no need to cancel since only one object can come back here. return get_datacenter_for_a_datastore(vim, ds_ref, property_list)",,74,15
openstack%2Ftaskflow~master~I44adc69dc9dea25bc611210bd0e6060f4dd100d5,openstack/taskflow,master,I44adc69dc9dea25bc611210bd0e6060f4dd100d5,Add a prototype of reverting strategies,ABANDONED,2013-08-27 23:32:04.000000000,2013-09-04 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2013-08-27 23:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/832f9698038173bf366b86d99ef5dd27521265ea', 'message': 'Add a prototype of reverting strategies\n\nHave the linear flow call a strategy which can\nattempt to alter how a individual task is reverted\nbefore the full set of tasks is reverted. The current\nexample allows for retrying a task a number of times\nbefore failing out all the tasks the flow has ran.\n\nbp/reversion-strategies\n\nChange-Id: I44adc69dc9dea25bc611210bd0e6060f4dd100d5\n'}, {'number': 2, 'created': '2013-08-27 23:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d399a5f6866b84334b46ae9101b06ef4cfc66b14', 'message': 'Add a prototype of reverting strategies\n\nHave the linear flow call a strategy which can\nattempt to alter how a individual task is reverted\nbefore the full set of tasks is reverted. The current\nexample allows for retrying a task a number of times\nbefore failing out all the tasks the flow has ran.\n\nPart of blueprint bp/reversion-strategies\n\nChange-Id: I44adc69dc9dea25bc611210bd0e6060f4dd100d5\n'}, {'number': 3, 'created': '2013-08-27 23:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c8a9f00e227b0bd41264ce1b800a3136894f699e', 'message': 'Add a prototype of reverting strategies\n\nHave the linear flow call a strategy which can\nattempt to alter how a individual task is reverted\nbefore the full set of tasks is reverted. The current\nexample allows for retrying a task a number of times\nbefore failing out all the tasks the flow has ran.\n\nPart of: blueprint reversion-strategies\n\nChange-Id: I44adc69dc9dea25bc611210bd0e6060f4dd100d5\n'}, {'number': 4, 'created': '2013-08-27 23:34:45.000000000', 'files': ['taskflow/patterns/linear_flow.py', 'taskflow/patterns/reverting/retry.py', 'taskflow/patterns/reverting/__init__.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4d4be0c9fe7c323a56a7cf1d589049f6a1350881', 'message': 'Add a prototype of reverting strategies\n\nHave the linear flow call a strategy which can\nattempt to alter how a individual task is reverted\nbefore the full set of tasks is reverted. The current\nexample allows for retrying a task a number of times\nbefore failing out all the tasks the flow has ran.\n\nPart of: blueprint reversion-strategies\n\nChange-Id: I44adc69dc9dea25bc611210bd0e6060f4dd100d5\n'}]",0,43972,4d4be0c9fe7c323a56a7cf1d589049f6a1350881,9,2,4,1297,,,0,"Add a prototype of reverting strategies

Have the linear flow call a strategy which can
attempt to alter how a individual task is reverted
before the full set of tasks is reverted. The current
example allows for retrying a task a number of times
before failing out all the tasks the flow has ran.

Part of: blueprint reversion-strategies

Change-Id: I44adc69dc9dea25bc611210bd0e6060f4dd100d5
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/72/43972/4 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/patterns/linear_flow.py', 'taskflow/patterns/reverting/retry.py', 'taskflow/patterns/reverting/__init__.py']",3,832f9698038173bf366b86d99ef5dd27521265ea,bp/reversion-strategies,"# -*- coding: utf-8 -*- # vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (C) 2012 Yahoo! Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",,90,1
openstack%2Ftripleo-incubator~master~Ic13c2fd954deb3a5bc5faa1528fe81e5f993a0fe,openstack/tripleo-incubator,master,Ic13c2fd954deb3a5bc5faa1528fe81e5f993a0fe,Adds architecture param to create-nodes script,ABANDONED,2013-08-26 11:29:57.000000000,2013-09-04 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4190}, {'_account_id': 7166}, {'_account_id': 7582}]","[{'number': 1, 'created': '2013-08-26 11:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/143c0fc4856f3b10038d65e894387bad3b4b203f', 'message': 'Added architecture param to create-nodes script\n\nChange-Id: Ic13c2fd954deb3a5bc5faa1528fe81e5f993a0fe\nFixes: bug #1216864\n'}, {'number': 2, 'created': '2013-08-26 12:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/dfcd31bc66610f1fbf6ad3fdf1be582e6d676925', 'message': 'Added architecture param to create-nodes script\n\nChange-Id: Ic13c2fd954deb3a5bc5faa1528fe81e5f993a0fe\nFixes: bug #1216864\n'}, {'number': 3, 'created': '2013-08-26 12:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/897679281fe377b9c2b719cad14392ad24a1ad86', 'message': 'Adds architecture param to create-nodes script\n\nIf someone builds 64bit seed/undercloud/overcloud images with\ndiskimagebuilder, then there would be an arch mismatch because\ncreate-nodes sets i686 architecture when creating VMs in libvirt.\n\nChange-Id: Ic13c2fd954deb3a5bc5faa1528fe81e5f993a0fe\nFixes: bug #1216864\n'}, {'number': 4, 'created': '2013-08-26 14:34:07.000000000', 'files': ['scripts/create-nodes', 'devtest.md'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/37200c42925c9e8117787eea5c95244d4eb6d90c', 'message': 'Adds architecture param to create-nodes script\n\nIf someone builds 64bit seed/undercloud/overcloud images with\ndiskimagebuilder, then there would be an arch mismatch because\ncreate-nodes sets i686 architecture when creating VMs in libvirt.\n\nChange-Id: Ic13c2fd954deb3a5bc5faa1528fe81e5f993a0fe\nFixes: bug #1216864\n'}]",3,43682,37200c42925c9e8117787eea5c95244d4eb6d90c,20,5,4,7582,,,0,"Adds architecture param to create-nodes script

If someone builds 64bit seed/undercloud/overcloud images with
diskimagebuilder, then there would be an arch mismatch because
create-nodes sets i686 architecture when creating VMs in libvirt.

Change-Id: Ic13c2fd954deb3a5bc5faa1528fe81e5f993a0fe
Fixes: bug #1216864
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/82/43682/4 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/create-nodes', 'devtest.md']",2,143c0fc4856f3b10038d65e894387bad3b4b203f,bug/1216864, create-nodes 1 1024 10 i386 3, create-nodes 1 1024 10 3,8,3
openstack%2Ftrove-integration~master~I75d976ebaac868e0ef27f4891d19c13502bd23d0,openstack/trove-integration,master,I75d976ebaac868e0ef27f4891d19c13502bd23d0,Include oslo.config=1.2.0a3 for trove guest VM,ABANDONED,2013-08-21 17:23:25.000000000,2013-09-04 05:58:42.000000000,,"[{'_account_id': 3}, {'_account_id': 739}, {'_account_id': 1375}, {'_account_id': 1925}, {'_account_id': 4240}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8034}, {'_account_id': 8309}]","[{'number': 1, 'created': '2013-08-21 17:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/f465d1ea84fda4fa5184106badf3abf0a14f2179', 'message': 'upgrade of oslo.config to 1.2.0a3\n\nChange-Id: I75d976ebaac868e0ef27f4891d19c13502bd23d0\n'}, {'number': 2, 'created': '2013-08-22 07:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/a85ec0a806de5377ae623c34f706366cd6c0b497', 'message': 'Added oslo.config installation from source, fixes bug https://bugs.launchpad.net/trove/+bug/1215001\n\nChange-Id: I75d976ebaac868e0ef27f4891d19c13502bd23d0\n'}, {'number': 3, 'created': '2013-08-22 10:51:35.000000000', 'files': ['scripts/files/elements/fedora-guest/install.d/15-reddwarf-dep', 'scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/1fdaa3db508a9c10421167dbdb5edba2a0ddb765', 'message': 'Include oslo.config=1.2.0a3 for trove guest VM\n\npython dependencies were being installed\n(including oslo.config) before we install\ntrove inside guest VM,therefore the\noslo.config>=1.2.0a3 was not picked\n up from trove requirements.txt.\nThe same has been addressed here.\n\nFixes: bug #1215001\n\nChange-Id: I75d976ebaac868e0ef27f4891d19c13502bd23d0\n'}]",2,43167,1fdaa3db508a9c10421167dbdb5edba2a0ddb765,28,9,3,8309,,,0,"Include oslo.config=1.2.0a3 for trove guest VM

python dependencies were being installed
(including oslo.config) before we install
trove inside guest VM,therefore the
oslo.config>=1.2.0a3 was not picked
 up from trove requirements.txt.
The same has been addressed here.

Fixes: bug #1215001

Change-Id: I75d976ebaac868e0ef27f4891d19c13502bd23d0
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/67/43167/3 && git format-patch -1 --stdout FETCH_HEAD,['scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep'],1,f465d1ea84fda4fa5184106badf3abf0a14f2179,bug/1215001,# install oslo.config from source than pypi (which is older) pip install http://tarballs.openstack.org/oslo.config/oslo.config-1.2.0a3.tar.gz#egg=oslo.config-1.2.0a3 pip install extras python-novaclient python-swiftclient python-cinderclient kombu>2.4.7 six,pip install extras python-novaclient python-swiftclient python-cinderclient oslo.config kombu>2.4.7 six,4,1
openstack%2Ftaskflow~master~I19b2992644ab2233731cbfd458e34d40cc84850e,openstack/taskflow,master,I19b2992644ab2233731cbfd458e34d40cc84850e,Show example of unification,ABANDONED,2013-09-03 23:37:12.000000000,2013-09-04 05:49:11.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2013-09-03 23:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f48b26141cd98f6afb80c2d7dc11a5dc32272d36', 'message': 'Show example of unification\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 2, 'created': '2013-09-04 00:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f5b35396b130d9ed70fe20d3f519ac1ccd83372d', 'message': 'Show example of unification\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 3, 'created': '2013-09-04 00:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d6ad9c84e5b7cd436af431e4270c85dadd5b13f8', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 4, 'created': '2013-09-04 00:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/abb0828aef3d173f006aa58c1ae98eed3ac6d3d9', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 5, 'created': '2013-09-04 00:47:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c46a9271149af2f28477b558720bf1d3c95fc173', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 6, 'created': '2013-09-04 00:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e596ff2d6c3ec7360ddf891506372e4556c23dfc', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 7, 'created': '2013-09-04 00:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a22143b5af7750d9936747e333cb9d1c020b0da0', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 8, 'created': '2013-09-04 00:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3599e2370e2633341596f5d154ebf510cbd950c8', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 9, 'created': '2013-09-04 01:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ea11ff953a9c78cce2808ff3c95680719c25ccbd', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 10, 'created': '2013-09-04 01:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/daaffceb0f44c205474a93e334f5e481704d1acd', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 11, 'created': '2013-09-04 01:07:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5a2afb822cc6c988f173ab3a87b9b405d1b2dc13', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 12, 'created': '2013-09-04 01:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/48ce00d25ab03d063070d8dcc6c93c3bfe0bb1d5', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 13, 'created': '2013-09-04 01:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a1ec19c4cb0c02e0f1c501a240ba9dc5aa85b235', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 14, 'created': '2013-09-04 01:18:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/687572743cb6c8dd95e96b6b84734b5e66b0ad9e', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 15, 'created': '2013-09-04 04:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2e5a385e23787a15b6cd2b9982e660cd9622fd77', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 16, 'created': '2013-09-04 04:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6973bd36342f1538219be890b3700adf87f9855e', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 17, 'created': '2013-09-04 04:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/137eaff5562c569f701f74e4d5569dfdc7a9b2cb', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}, {'number': 18, 'created': '2013-09-04 05:29:20.000000000', 'files': ['taskflow/engines/action_engine/seq_action.py', 'taskflow/flow.py', 'taskflow/patterns/linear_flow.py', 'taskflow/blocks/patterns.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/task.py', 'taskflow/engines/action_engine/base_action.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/blocks/__init__.py', 'taskflow/blocks/base.py', 'taskflow/blocks/task.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/eec905a486caed74bfa7c9c276a52ace027e9222', 'message': 'Show example of unification\n\nInstead of keeping the existing flows with there functionality\nmove the existing flows to just be the thing that defines the\nruntime structure. Have the action_engine translate these\nstructures into something useful, which in the case of action_engine\nis translating the structures into things that are pretty much\nlike the existing flows (but not exactly).\n\nChange-Id: I19b2992644ab2233731cbfd458e34d40cc84850e\n'}]",0,44982,eec905a486caed74bfa7c9c276a52ace027e9222,34,2,18,1297,,,0,"Show example of unification

Instead of keeping the existing flows with there functionality
move the existing flows to just be the thing that defines the
runtime structure. Have the action_engine translate these
structures into something useful, which in the case of action_engine
is translating the structures into things that are pretty much
like the existing flows (but not exactly).

Change-Id: I19b2992644ab2233731cbfd458e34d40cc84850e
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/82/44982/6 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/seq_action.py', 'taskflow/flow.py', 'taskflow/patterns/linear_flow.py', 'taskflow/engines/action_engine/engine.py']",4,f48b26141cd98f6afb80c2d7dc11a5dc32272d36,,"from taskflow.openstack.common import excutils from taskflow import taskfrom taskflow.patterns import linear_flow as lf def __init__(self, flow, translator): self._root = None self._translator = translator self._flow = flow def run(self): if self._root is None: self._root = self._translator.translate(self._flow) try: self._root.execute(self.storage) except Exception: with excutils.save_and_reraise_exception(): self._root.revert(self.storage) def SingleThreadedTranslator(object): def translate(self, pattern): if isinstance(pattern, task.Task): # Ok make a linear flow of 1 item. flow = lf.Flow() flow.add(pattern) return flow elif isinstance(pattern, lf.Flow): # Decompose the flow into something more useful. flow = lf.Flow() for p in pattern: flow.add(self.translate(p)) return flow else: raise ValueError('Pattern of unknown type: %s (type %s)' % (pattern, type(pattern))) ActionEngine.__init__(self, flow, SingleThreadedTranslator())"," def __init__(self, flow, action_map): self._root = self._to_action(flow) def _to_action(self, pattern): try: factory = self._action_map[type(pattern)] except KeyError: raise ValueError('Action of unknown type: %s (type %s)' % (pattern, type(pattern))) return factory(pattern, self._to_action) def run(self): status = self._root.execute(self) if status == states.FAILURE: self._root.revert(self) ActionEngine.__init__(self, flow, { blocks.Task: task_action.TaskAction, blocks.LinearFlow: seq_action.SequentialAction, blocks.ParallelFlow: seq_action.SequentialAction })",90,177
openstack%2Fneutron~master~I3e62ef786d3a02c761903a15d546ee8758c0bf7f,openstack/neutron,master,I3e62ef786d3a02c761903a15d546ee8758c0bf7f,Verify MTU is valid for ipsec_site_connection,MERGED,2013-09-03 18:40:28.000000000,2013-09-04 05:18:40.000000000,2013-09-04 05:18:39.000000000,"[{'_account_id': 3}, {'_account_id': 2031}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 6659}]","[{'number': 1, 'created': '2013-09-03 18:40:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6f218dbcdf5c49c26a4a6b52ddb55334d04c1844', 'message': 'Verify MTU is valid for ipsec_site_connection\n\nSince the check relies on the vpnservice subnet to determine whether this\nis IPv4 ro IPv6, we must check in the plugin. Test is done at create/update\ntime and ensures that the MTU is equal to or greater than the minimum allowed\nvalues, which are set to 68 for IPv4 minimum and 1280 for IPv6, respectively.\n\nRefactored code to allow reuse of create and update test functions, by\nallowing tests to override some settings, and to provide a dict of changed\nitems (for update).\n\nbug 1219489\n\nChange-Id: I3e62ef786d3a02c761903a15d546ee8758c0bf7f\n'}, {'number': 2, 'created': '2013-09-03 19:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/526de16a852a71282bdbe3085452fe4b033285d8', 'message': 'Verify MTU is valid for ipsec_site_connection\n\nSince the check relies on the vpnservice subnet to determine whether\nthis is IPv4 ro IPv6, we must check in the plugin. Test is done at\ncreate/update time and ensures that the MTU is equal to or greater\nthan the minimum allowed values, which are set to 68 for IPv4\nminimum and 1280 for IPv6, respectively.\n\nRefactored code to allow reuse of create and update test functions,\nby allowing tests to override some settings, and to provide a dict\nof changed items (for update).\n\nbug 1219489\n\nChange-Id: I3e62ef786d3a02c761903a15d546ee8758c0bf7f\n'}, {'number': 3, 'created': '2013-09-03 20:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b8d3749d1153ee2d629af942a7bcc5b10c10bca', 'message': 'Verify MTU is valid for ipsec_site_connection\n\nSince the check relies on the vpnservice subnet to determine whether\nthis is IPv4 ro IPv6, we must check in the plugin. Test is done at\ncreate/update time and ensures that the MTU is equal to or greater\nthan the minimum allowed values, which are set to 68 for IPv4\nminimum and 1280 for IPv6, respectively.\n\nRefactored code to allow reuse of create and update test functions,\nby allowing tests to override some settings, and to provide a dict\nof changed items (for update).\n\nbug 1219489\n\nChange-Id: I3e62ef786d3a02c761903a15d546ee8758c0bf7f\n'}, {'number': 4, 'created': '2013-09-04 02:37:10.000000000', 'files': ['neutron/db/vpn/vpn_db.py', 'neutron/extensions/vpnaas.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f9411948221b1df70d4a3f3d1271f821bea74aa', 'message': 'Verify MTU is valid for ipsec_site_connection\n\nSince the check relies on the vpnservice subnet to determine whether\nthis is IPv4 ro IPv6, we must check in the plugin. Test is done at\ncreate/update time and ensures that the MTU is equal to or greater\nthan the minimum allowed values, which are set to 68 for IPv4\nminimum and 1280 for IPv6, respectively.\n\nRefactored code to allow reuse of create and update test functions,\nby allowing tests to override some settings, and to provide a dict\nof changed items (for update).\n\nbug 1219489\n\nChange-Id: I3e62ef786d3a02c761903a15d546ee8758c0bf7f\n'}]",4,44933,0f9411948221b1df70d4a3f3d1271f821bea74aa,25,5,4,6659,,,0,"Verify MTU is valid for ipsec_site_connection

Since the check relies on the vpnservice subnet to determine whether
this is IPv4 ro IPv6, we must check in the plugin. Test is done at
create/update time and ensures that the MTU is equal to or greater
than the minimum allowed values, which are set to 68 for IPv4
minimum and 1280 for IPv6, respectively.

Refactored code to allow reuse of create and update test functions,
by allowing tests to override some settings, and to provide a dict
of changed items (for update).

bug 1219489

Change-Id: I3e62ef786d3a02c761903a15d546ee8758c0bf7f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/44933/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/vpn/vpn_db.py', 'neutron/extensions/vpnaas.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py']",3,6f218dbcdf5c49c26a4a6b52ddb55334d04c1844,bug/1219489," def _test_create_ipsec_site_connection(self, key_overrides=None, setup_overrides=None, expected_status_int=200): """"""Create ipsec_site_connection and check results."""""" params = {'ikename': 'ikepolicy1', 'ipsecname': 'ipsecpolicy1', 'vpnsname': 'vpnservice1', 'subnet_cidr': '10.2.0.0/24', 'subnet_version': 4} if setup_overrides is not None: params.update(setup_overrides) keys = {'name': 'connection1', 'description': 'my-ipsec-connection', if key_overrides is not None: keys.update(key_overrides) self.ikepolicy(name=params['ikename']), self.ipsecpolicy(name=params['ipsecname']), self.subnet(cidr=params['subnet_cidr'], ip_version=params['subnet_version']), with self.vpnservice(name=params['vpnsname'], subnet=subnet, try: with self.ipsec_site_connection( self.fmt, keys['name'], keys['peer_address'], keys['peer_id'], keys['peer_cidrs'], keys['mtu'], keys['psk'], keys['initiator'], dpd['action'], dpd['interval'], dpd['timeout'], vpnservice1, ikepolicy, ipsecpolicy, keys['admin_state_up'], description=keys['description'] ) as ipsec_site_connection: if expected_status_int != 200: self.fail(""Expected failure on create"") self._check_ipsec_site_connection( ipsec_site_connection['ipsec_site_connection'], keys, dpd) except webob.exc.HTTPClientError as ce: self.assertEqual(ce.code, expected_status_int) def test_create_ipsec_site_connection(self, **extras): """"""Test case to create an ipsec_site_connection."""""" self._test_create_ipsec_site_connection(key_overrides=extras) def test_create_ipsec_site_connection_invalid_mtu(self): """"""Test creating an ipsec_site_connection with invalid MTU."""""" self._test_create_ipsec_site_connection(key_overrides={'mtu': 67}, expected_status_int=400) ipv6_overrides = { 'peer_address': 'fe80::c0a8:10a', 'peer_id': 'fe80::c0a8:10a', 'peer_cidrs': ['fe80::c0a8:200/120', 'fe80::c0a8:300/120'], 'mtu': 1279} ipv6_setup_params = {'subnet_cidr': 'fe80::a01:0/120', 'subnet_version': 6} self._test_create_ipsec_site_connection( key_overrides=ipv6_overrides, setup_overrides=ipv6_setup_params, expected_status_int=400) keys, if k in keys)) dpd, if k in dpd)) """"""Test case for valid updates to IPSec site connection."""""" self._test_update_ipsec_site_connection(update={'dpd': dpd}) self._test_update_ipsec_site_connection(update={'mtu': 2000}) ipv6_settings = { 'peer_address': 'fe80::c0a8:10a', 'peer_id': 'fe80::c0a8:10a', 'peer_cidrs': ['fe80::c0a8:200/120', 'fe80::c0a8:300/120'], 'subnet_cidr': 'fe80::a02:0/120', 'subnet_version': 6} self._test_update_ipsec_site_connection(update={'mtu': 2000}, overrides=ipv6_settings) """"""Test updates to ipsec_site_connection with invalid DPD settings."""""" def test_update_ipsec_site_connection_with_invalid_mtu(self): """"""Test updates to ipsec_site_connection with invalid MTU settings."""""" self._test_update_ipsec_site_connection( update={'mtu': 67}, expected_status_int=400) ipv6_settings = { 'peer_address': 'fe80::c0a8:10a', 'peer_id': 'fe80::c0a8:10a', 'peer_cidrs': ['fe80::c0a8:200/120', 'fe80::c0a8:300/120'], 'subnet_cidr': 'fe80::a02:0/120', 'subnet_version': 6} self._test_update_ipsec_site_connection( update={'mtu': 1279}, overrides=ipv6_settings, expected_status_int=400) """"""Test updating an ipsec_site_connection in invalid state."""""" self._test_update_ipsec_site_connection( overrides={'make_active': False}, expected_status_int=400) """"""Test updating an ipsec_site_connection for peer_cidrs."""""" new_peers = {'peer_cidrs': ['192.168.4.0/24', '192.168.5.0/24']} self._test_update_ipsec_site_connection( update=new_peers) def _test_update_ipsec_site_connection(self, update={'name': 'new name'}, overrides=None, expected_status_int=200): """"""Creates and then updates ipsec_site_connection."""""" keys = {'name': 'new_ipsec_site_connection', 'ikename': 'ikepolicy1', 'ipsecname': 'ipsecpolicy1', 'vpnsname': 'vpnservice1', 'description': 'my-ipsec-connection', 'admin_state_up': True, 'action': 'hold', 'interval': 40, 'timeout': 120, 'subnet_cidr': '10.2.0.0/24', 'subnet_version': 4, 'make_active': True} if overrides is not None: keys.update(overrides) self.ikepolicy(name=keys['ikename']), self.ipsecpolicy(name=keys['ipsecname']), self.subnet(cidr=keys['subnet_cidr'], ip_version=keys['subnet_version']), self.router()) as ( ikepolicy, ipsecpolicy, subnet, router): with self.vpnservice(name=keys['vpnsname'], subnet=subnet, keys['name'], keys['action'], keys['interval'], keys['timeout'], description=keys['description'] ) as ipsec_site_connection: data = {'ipsec_site_connection': update} if keys.get('make_active', None): self._set_active( vpn_db.IPsecSiteConnection, (ipsec_site_connection['ipsec_site_connection'] ['id'])) ipsec_site_connection['ipsec_site_connection']['id']) res = req.get_response(self.ext_api) self.assertEqual(expected_status_int, res.status_int) if expected_status_int == 200: res_dict = self.deserialize(self.fmt, res) for k, v in update.items(): self.assertEqual( res_dict['ipsec_site_connection'][k], v)"," def test_create_ipsec_site_connection(self, **extras): """"""Test case to create an ipsec_site_connection."""""" ikename = ""ikepolicy1"" ipsecname = ""ipsecpolicy1"" vpnsname = ""vpnservice1"" name = ""connection1"" description = ""my-ipsec-connection"" keys = {'name': name, 'description': ""my-ipsec-connection"", keys.update(extras) self.ikepolicy(name=ikename), self.ipsecpolicy(name=ipsecname), self.subnet(), with self.vpnservice(name=vpnsname, subnet=subnet, with self.ipsec_site_connection( self.fmt, name, keys['peer_address'], keys['peer_id'], keys['peer_cidrs'], keys['mtu'], keys['psk'], keys['initiator'], dpd['action'], dpd['interval'], dpd['timeout'], vpnservice1, ikepolicy, ipsecpolicy, keys['admin_state_up'], description=description, **extras ) as ipsec_site_connection: self._check_ipsec_site_connection( ipsec_site_connection['ipsec_site_connection'], keys, dpd) if k in keys), keys) if k in dpd), dpd) self._test_update_ipsec_site_connection( update={'dpd': dpd} ) def _test_update_ipsec_site_connection( self, update=None, expected_status_int=200): """"""Test case to update a ipsec_site_connection."""""" name = 'new_ipsec_site_connection' ikename = 'ikepolicy1' ipsecname = 'ipsecpolicy1' vpnsname = 'vpnservice1' description = 'my-ipsec-connection' keys = {'name': 'new_ipsec_site_connection', 'description': ""my-ipsec-connection"", 'peer_address': '192.168.1.10', 'peer_id': '192.168.1.10', 'peer_cidrs': ['192.168.2.0/24', '192.168.3.0/24'], 'initiator': 'bi-directional', 'mtu': 1500, 'tenant_id': self._tenant_id, 'psk': 'abcd', 'status': 'ACTIVE', 'admin_state_up': True} dpd = {'action': 'hold', 'interval': 40, 'timeout': 120} with contextlib.nested( self.ikepolicy(name=ikename), self.ipsecpolicy(name=ipsecname), self.subnet(cidr='10.2.0.0/24'), self.router()) as ( ikepolicy, ipsecpolicy, subnet, router): with self.vpnservice(name=vpnsname, subnet=subnet, router=router) as vpnservice1: keys['vpnservice_id'] = ( vpnservice1['vpnservice']['id'] ) keys['ikepolicy_id'] = ( ikepolicy['ikepolicy']['id'] ) keys['ipsecpolicy_id'] = ( ipsecpolicy['ipsecpolicy']['id'] ) with self.ipsec_site_connection( self.fmt, name, keys['peer_address'], keys['peer_id'], keys['peer_cidrs'], keys['mtu'], keys['psk'], keys['initiator'], dpd['action'], dpd['interval'], dpd['timeout'], vpnservice1, ikepolicy, ipsecpolicy, keys['admin_state_up'], description=description ) as ipsec_site_connection: if not update: update = {'name': name} data = {'ipsec_site_connection': update} self._set_active( vpn_db.IPsecSiteConnection, ipsec_site_connection['ipsec_site_connection']['id']) req = self.new_update_request( 'ipsec-site-connections', data, ipsec_site_connection['ipsec_site_connection']['id'] ) res = req.get_response(self.ext_api) self.assertEqual(expected_status_int, res.status_int) if expected_status_int == 200: res_dict = self.deserialize( self.fmt, res ) for k, v in update.items(): self.assertEqual( res_dict['ipsec_site_connection'][k], v) """"""Test case to update an ipsec_site_connection in invalid state."""""" name = 'new_ipsec_site_connection' ikename = 'ikepolicy1' ipsecname = 'ipsecpolicy1' vpnsname = 'vpnservice1' description = 'my-ipsec-connection' keys = {'name': 'new_ipsec_site_connection', 'description': ""my-ipsec-connection"", 'peer_address': '192.168.1.10', 'peer_id': '192.168.1.10', 'peer_cidrs': ['192.168.2.0/24', '192.168.3.0/24'], 'initiator': 'bi-directional', 'mtu': 1500, 'tenant_id': self._tenant_id, 'psk': 'abcd', 'status': 'ACTIVE', 'admin_state_up': True} dpd = {'action': 'hold', 'interval': 40, 'timeout': 120} with contextlib.nested( self.ikepolicy(name=ikename), self.ipsecpolicy(name=ipsecname), self.subnet(cidr='10.2.0.0/24'), self.router()) as ( ikepolicy, ipsecpolicy, subnet, router): with self.vpnservice(name=vpnsname, subnet=subnet, router=router) as vpnservice1: keys['vpnservice_id'] = ( vpnservice1['vpnservice']['id'] ) keys['ikepolicy_id'] = ( ikepolicy['ikepolicy']['id'] ) keys['ipsecpolicy_id'] = ( ipsecpolicy['ipsecpolicy']['id'] ) with self.ipsec_site_connection( self.fmt, name, keys['peer_address'], keys['peer_id'], keys['peer_cidrs'], keys['mtu'], keys['psk'], keys['initiator'], dpd['action'], dpd['interval'], dpd['timeout'], vpnservice1, ikepolicy, ipsecpolicy, keys['admin_state_up'], description=description ) as ipsec_site_connection: data = {'ipsec_site_connection': {'name': name}} req = self.new_update_request( 'ipsec-site-connections', data, ipsec_site_connection['ipsec_site_connection']['id'] ) res = req.get_response(self.ext_api) self.assertEqual(400, res.status_int) """"""Test case to update a ipsec_site_connection for peer_cidrs."""""" name = 'ipsec_site_connection' ikename = 'ikepolicy1' ipsecname = 'ipsecpolicy1' vpnsname = 'vpnservice1' description = 'my-ipsec-connection' keys = {'name': 'ipsec_site_connection', 'description': ""my-ipsec-connection"", 'admin_state_up': True} dpd = {'action': 'hold', 'interval': 40, 'timeout': 120} self.ikepolicy(name=ikename), self.ipsecpolicy(name=ipsecname), self.subnet(cidr='10.2.0.0/24'), self.router()) as ( ikepolicy, ipsecpolicy, subnet, router): with self.vpnservice(name=vpnsname, subnet=subnet, name, dpd['action'], dpd['interval'], dpd['timeout'], description=description ) as ipsec_site_connection: data = {'ipsec_site_connection': { 'peer_cidrs': ['192.168.2.0/24', '192.168.3.0/24'] }} self._set_active( vpn_db.IPsecSiteConnection, ipsec_site_connection['ipsec_site_connection']['id']) ipsec_site_connection[ 'ipsec_site_connection']['id'] ) res = self.deserialize( self.fmt, req.get_response(self.ext_api) ) self._check_ipsec_site_connection( res['ipsec_site_connection'], keys, dpd)",178,224
openstack%2Fkeystone~master~I0c832d89698fc43a19408e8e7c159f09e0ec5e15,openstack/keystone,master,I0c832d89698fc43a19408e8e7c159f09e0ec5e15,Add a oauth1-configuration.rst and extension section to docs,MERGED,2013-08-30 14:57:05.000000000,2013-09-04 05:13:26.000000000,2013-09-04 05:13:26.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2013-08-30 14:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/00c80d7989d68b6961162cf82f01156546611c60', 'message': 'Add a configuration.rst file for oauth1\n\nThere are two reasons I want to add this file to the oauth1\nextension. 1) Endpoint filtering already has it, and this should\nhelp keep things consistent. 2) I find it really helpful, and it\nprovides some helpful docs in setting up extensions.\n\nfixes bug: #1218722\n\nChange-Id: I0c832d89698fc43a19408e8e7c159f09e0ec5e15\n'}, {'number': 2, 'created': '2013-08-30 20:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c9ba93ed720703aab889df9bc1cd731c0a5edd51', 'message': 'Add a configuration.rst file for oauth1\n\nThere are two reasons I want to add this file to the oauth1\nextension. 1) Endpoint filtering already has it, and this should\nhelp keep things consistent. 2) I find it really helpful, and it\nprovides some helpful docs in setting up extensions.\n\nfixes bug: #1218722\n\nChange-Id: I0c832d89698fc43a19408e8e7c159f09e0ec5e15\n'}, {'number': 3, 'created': '2013-08-31 05:08:01.000000000', 'files': ['doc/source/extensions/oauth1-configuration.rst', 'doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a3a40563791d876f9b3568b3821ba019e305aba3', 'message': 'Add a oauth1-configuration.rst and extension section to docs\n\nThe patch addresses the following:\n1) Add an extensions section to the configuration.rst\n2) Add the oauth-configuration.rst to the previously mentioned\nsection.\n\nfixes bug: #1218722\n\nChange-Id: I0c832d89698fc43a19408e8e7c159f09e0ec5e15\n'}]",13,44463,a3a40563791d876f9b3568b3821ba019e305aba3,20,8,3,6482,,,0,"Add a oauth1-configuration.rst and extension section to docs

The patch addresses the following:
1) Add an extensions section to the configuration.rst
2) Add the oauth-configuration.rst to the previously mentioned
section.

fixes bug: #1218722

Change-Id: I0c832d89698fc43a19408e8e7c159f09e0ec5e15
",git fetch https://review.opendev.org/openstack/keystone refs/changes/63/44463/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/contrib/oauth1/configuration.rst'],1,00c80d7989d68b6961162cf82f01156546611c60,bug1218722,".. Copyright 2011-2013 OpenStack, Foundation All Rights Reserved. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. ========================= Enabling OAuth1 Extension ========================= To enable the oauth1 extension: 1. add the oauth1 extension driver to the ``[oauth1]`` section in ``keystone.conf``. example:: [oauth1] driver = keystone.contrib.oauth1.backends.sql.OAuth1 2. add the ``oauth1_extension`` filter to the ``api_v3`` pipeline in ``keystone-paste.ini``. example:: [pipeline:api_v3] pipeline = access_log sizelimit url_normalize token_auth admin_token_auth xml_body json_body ec2_extension s3_extension oauth1_extension service_v3 3. create the oauth1 extension tables if using the provided sql backend. example:: ./bin/keystone-manage db_sync --extension oauth1 ",,35,0
openstack%2Fneutron~master~Icb9c70d8b0d7fcb34b57adc760bb713b740e5dad,openstack/neutron,master,Icb9c70d8b0d7fcb34b57adc760bb713b740e5dad,Implement ML2 port binding,MERGED,2013-08-21 14:04:29.000000000,2013-09-04 04:47:05.000000000,2013-09-04 04:47:04.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 1689}, {'_account_id': 2031}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6558}, {'_account_id': 6820}, {'_account_id': 7141}]","[{'number': 1, 'created': '2013-08-21 14:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0bebb66c061e974f730a44183f3a394a02d525ab', 'message': 'Implement ML2 port binding\n\nThe ml2 plugin uses mechanism drivers to determine which network\nsegment and what VIF driver to use for a port.\n\nThis is currently a work-in-progress. The binding needs to be used to\nselect the segment, and mechanism drivers for the existing agents are\nneeded.\n\nimplements blueprint: ml2-portbinding\n\nChange-Id: Icb9c70d8b0d7fcb34b57adc760bb713b740e5dad\n'}, {'number': 2, 'created': '2013-08-23 13:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7706e68389b69eeb1078d3f592878d8258a96cdd', 'message': 'Implement ML2 port binding\n\nThe ml2 plugin uses mechanism drivers to determine which network\nsegment and what VIF driver to use for a port.\n\nThis is currently a work-in-progress. The binding needs to be used to\nselect the segment in the get_device_details RPC, and mechanism\ndrivers for the existing agents are needed.\n\nimplements blueprint: ml2-portbinding\n\nChange-Id: Icb9c70d8b0d7fcb34b57adc760bb713b740e5dad\n'}, {'number': 3, 'created': '2013-08-24 05:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44ec8b744603207c5d296658fb5480522a7a07e9', 'message': 'Implement ML2 port binding\n\nThe ml2 plugin uses mechanism drivers to determine which network\nsegment and what VIF driver to use for a port.\n\nTo use with devstack until it is updated, set\n""Q_ML2_PLUGIN_MECHANISM_DRIVERS=openvswitch,linuxbridge"" in localrc.\n\nimplements blueprint: ml2-portbinding\n\nChange-Id: Icb9c70d8b0d7fcb34b57adc760bb713b740e5dad\n'}, {'number': 4, 'created': '2013-08-28 16:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/03d6bae356b080244b82b404e347e30e16544d67', 'message': 'Implement ML2 port binding\n\nThe ml2 plugin uses mechanism drivers to determine which network\nsegment and what VIF driver to use for a port.\n\nTo use with devstack until it is updated, set\n""Q_ML2_PLUGIN_MECHANISM_DRIVERS=openvswitch,linuxbridge"" in localrc.\n\nimplements blueprint: ml2-portbinding\n\nChange-Id: Icb9c70d8b0d7fcb34b57adc760bb713b740e5dad\n'}, {'number': 5, 'created': '2013-09-03 04:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8c4310c99a4c0b23b33f1823e875a1ec9fa7fe0', 'message': 'Implement ML2 port binding\n\nThe ml2 plugin uses mechanism drivers to determine which network\nsegment and what VIF driver to use for a port. Mechanism drivers\nsupporting the openvswitch, linuxbridge, and hyperv agents are\nadded. The binding:host attribute is set on ports belonging to the\ndhcp and l3 agents so that they can be bound.\n\nTo use with devstack until it is updated, set\n""Q_ML2_PLUGIN_MECHANISM_DRIVERS=openvswitch,linuxbridge"" in localrc.\n\nThe hyperv L2 agent does not currently implement the agents_db RPC,\nand will therefore not work with its mechanism driver. That will be\nfixed in a separate merge.\n\nimplements blueprint: ml2-portbinding\n\nChange-Id: Icb9c70d8b0d7fcb34b57adc760bb713b740e5dad\n'}, {'number': 6, 'created': '2013-09-03 13:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66dff455a87b8b6b218ac0794cdc96155e06c3b5', 'message': 'Implement ML2 port binding\n\nThe ml2 plugin uses mechanism drivers to determine which network\nsegment and what VIF driver to use for a port. Mechanism drivers\nsupporting the openvswitch, linuxbridge, and hyperv agents are\nadded. The binding:host attribute is set on ports belonging to the\ndhcp and l3 agents so that they can be bound.\n\nTo use with devstack until it is updated, set\n""Q_ML2_PLUGIN_MECHANISM_DRIVERS=openvswitch,linuxbridge"" in localrc.\n\nThe hyperv L2 agent does not currently implement the agents_db RPC,\nand will therefore not work with its ml2 mechanism driver. This issue\nwill be tracked as a bug to be fixed in a separate merge.\n\nimplements blueprint: ml2-portbinding\n\nChange-Id: Icb9c70d8b0d7fcb34b57adc760bb713b740e5dad\n'}, {'number': 7, 'created': '2013-09-03 23:22:33.000000000', 'files': ['neutron/plugins/ml2/drivers/mech_linuxbridge.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/ml2/test_port_binding.py', 'neutron/plugins/ml2/plugin.py', 'neutron/plugins/ml2/drivers/mech_hyperv.py', 'neutron/plugins/ml2/managers.py', 'neutron/plugins/ml2/db.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/plugins/ml2/drivers/mech_agent.py', 'neutron/plugins/ml2/drivers/mech_openvswitch.py', 'neutron/tests/unit/ml2/test_mech_openvswitch.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/tests/unit/ml2/_test_mech_agent.py', 'neutron/plugins/ml2/rpc.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/plugins/ml2/driver_context.py', 'neutron/tests/unit/ml2/drivers/mechanism_logger.py', 'neutron/tests/unit/ml2/drivers/mechanism_test.py', 'neutron/db/migration/alembic_migrations/versions/32a65f71af51_ml2_portbinding.py', 'neutron/common/constants.py', 'neutron/tests/unit/ml2/test_mech_hyperv.py', 'neutron/plugins/ml2/models.py', 'neutron/db/l3_rpc_base.py', 'neutron/tests/unit/ml2/test_mech_linuxbridge.py', 'neutron/db/dhcp_rpc_base.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8bc02a7fbeaf2e0c8bccbaad52f41d026c1bbf40', 'message': 'Implement ML2 port binding\n\nThe ml2 plugin uses mechanism drivers to determine which network\nsegment and what VIF driver to use for a port. Mechanism drivers\nsupporting the openvswitch, linuxbridge, and hyperv agents are\nadded. The binding:host attribute is set on ports belonging to the\ndhcp and l3 agents so that they can be bound.\n\nTo use with devstack until it is updated, set\n""Q_ML2_PLUGIN_MECHANISM_DRIVERS=openvswitch,linuxbridge"" in localrc.\n\nThe hyperv L2 agent does not currently implement the agents_db RPC,\nand will therefore not work with its ml2 mechanism driver. This issue\nwill be tracked as a bug to be fixed in a separate merge.\n\nimplements blueprint: ml2-portbinding\n\nChange-Id: Icb9c70d8b0d7fcb34b57adc760bb713b740e5dad\n'}]",31,43129,8bc02a7fbeaf2e0c8bccbaad52f41d026c1bbf40,49,14,7,1689,,,0,"Implement ML2 port binding

The ml2 plugin uses mechanism drivers to determine which network
segment and what VIF driver to use for a port. Mechanism drivers
supporting the openvswitch, linuxbridge, and hyperv agents are
added. The binding:host attribute is set on ports belonging to the
dhcp and l3 agents so that they can be bound.

To use with devstack until it is updated, set
""Q_ML2_PLUGIN_MECHANISM_DRIVERS=openvswitch,linuxbridge"" in localrc.

The hyperv L2 agent does not currently implement the agents_db RPC,
and will therefore not work with its ml2 mechanism driver. This issue
will be tracked as a bug to be fixed in a separate merge.

implements blueprint: ml2-portbinding

Change-Id: Icb9c70d8b0d7fcb34b57adc760bb713b740e5dad
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/43129/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/managers.py', 'neutron/plugins/ml2/models.py', 'neutron/plugins/ml2/db.py', 'neutron/plugins/ml2/driver_context.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/plugins/ml2/plugin.py']",6,0bebb66c061e974f730a44183f3a394a02d525ab,bp/ml2-portbinding,"from neutron.db import models_v2from neutron.plugins.ml2 import models agentschedulers_db.DhcpAgentSchedulerDbMixin): segments = db.get_network_segments(context.session, id) def _process_port_binding(self, mech_context, attrs): binding = mech_context._binding port = mech_context.current() self._update_port_dict_binding(port, binding) host = attrs and attrs.get(portbindings.HOST_ID) host_set = attributes.is_attr_set(host) if (not host_set and binding.segment and self.mechanism_manager.validate_port_binding(mech_context)): return self.mechanism_manager.unbind_port(mech_context) self._update_port_dict_binding(port, binding) if host_set: binding.host = host port[portbindings.HOST_ID] = host self.mechanism_manager.bind_port(mech_context) self._update_port_dict_binding(port, binding) def _update_port_dict_binding(self, port, binding): port[portbindings.HOST_ID] = binding.host port[portbindings.VIF_TYPE] = binding.vif_type def _delete_port_binding(self, mech_context): binding = mech_context._binding port = mech_context.current() self._update_port_dict_binding(port, binding) self.mechanism_manager.unbind_port(mech_context) self._update_port_dict_binding(port, binding) def _extend_port_dict_binding(self, port_res, port_db): # None when called during unit tests for other plugins. if port_db.port_binding: self._update_port_dict_binding(port_res, port_db.port_binding) db_base_plugin_v2.NeutronDbPluginV2.register_dict_extend_funcs( attributes.PORTS, [_extend_port_dict_binding]) # Note - The following hook methods have ""ml2"" in their names so # that they are not called twice during unit tests due to global # registration of hooks in portbindings_db.py used by other # plugins. def _ml2_port_model_hook(self, context, original_model, query): query = query.outerjoin(models.PortBinding, (original_model.id == models.PortBinding.port_id)) return query def _ml2_port_result_filter_hook(self, query, filters): values = filters and filters.get(portbindings.HOST_ID, []) if not values: return query if len(values) == 1: query = query.filter(models.PortBinding.host == values[0]) else: query = query.filter(models.PortBinding.host.in_(values)) return query db_base_plugin_v2.NeutronDbPluginV2.register_model_query_hook( models_v2.Port, ""ml2_port_bindings"", '_ml2_port_model_hook', None, '_ml2_port_result_filter_hook') def _notify_port_updated(self, mech_context): # TODO(rkukura): Use bound segment. port = mech_context._port network = mech_context.network() segments = network.network_segments() if not segments: LOG.warning(_(""In _notify_port_updated() for port %(port_id), "" ""network %(network_id) has no segments""), {'port_id': port['id'], 'network_id': network['id']}) return segment = segments[0] self.notifier.port_update(mech_context._plugin_context, port, mech_context = driver_context.NetworkContext(context, result) context, updated_network, mech_context = driver_context.NetworkContext(context, network) for segment in mech_context.network_segments(): network = self.get_network(context, result['network_id']) mech_context = driver_context.PortContext(context, result, network) self._process_port_binding(mech_context, attrs) network = self.get_network(context, original_port['network_id']) context, updated_port, network, self._process_port_binding(mech_context, attrs) self._notify_port_updated(mech_context) network = self.get_network(context, port['network_id']) mech_context = driver_context.PortContext(context, port, network) self._delete_port_binding(mech_context)","from neutron.db import portbindings_db agentschedulers_db.DhcpAgentSchedulerDbMixin, portbindings_db.PortBindingMixin): segments = self.get_network_segments(context, id) def _extend_port_dict_binding(self, context, port): # TODO(rkukura): Implement based on host_id, agents, and # MechanismDrivers. Also set CAPABILITIES. Use # base_binding_dict if applicable, or maybe a new hook so # base handles field processing and get_port and get_ports # don't need to be overridden. port[portbindings.VIF_TYPE] = portbindings.VIF_TYPE_UNBOUND def _notify_port_updated(self, context, port): session = context.session with session.begin(subtransactions=True): network_id = port['network_id'] segments = self.get_network_segments(context, network_id) if not segments: LOG.warning(_(""In _notify_port_updated() for port %(port_id), "" ""network %(network_id) has no segments""), {'port_id': port['id'], 'network_id': network_id}) return # TODO(rkukura): Use port binding to select segment. segment = segments[0] self.notifier.port_update(context, port, mech_context = driver_context.NetworkContext(self, context, result, segments=[segment]) self, context, updated_network, def get_network_segments(self, context, id): session = context.session with session.begin(subtransactions=True): segments = db.get_network_segments(session, id) return segments segments = self.get_network_segments(context, id) mech_context = driver_context.NetworkContext(self, context, network, segments=segments) for segment in segments: self._process_portbindings_create_and_update(context, attrs, result) self._extend_port_dict_binding(context, result) mech_context = driver_context.PortContext(self, context, result) self._process_portbindings_create_and_update(context, attrs, updated_port) self._extend_port_dict_binding(context, updated_port) self, context, updated_port, self._notify_port_updated(context, updated_port) def get_port(self, context, id, fields=None): session = context.session with session.begin(subtransactions=True): port = super(Ml2Plugin, self).get_port(context, id, fields) self._extend_port_dict_binding(context, port) return self._fields(port, fields) def get_ports(self, context, filters=None, fields=None, sorts=None, limit=None, marker=None, page_reverse=False): session = context.session with session.begin(subtransactions=True): ports = super(Ml2Plugin, self).get_ports(context, filters, fields, sorts, limit, marker, page_reverse) # TODO(nati): filter by security group for port in ports: self._extend_port_dict_binding(context, port) return [self._fields(port, fields) for port in ports] mech_context = driver_context.PortContext(self, context, port)",292,97
openstack%2Fkeystone~master~I12e7fa08a1cdb1994843d9f0966b0e08d688a071,openstack/keystone,master,I12e7fa08a1cdb1994843d9f0966b0e08d688a071,Update keystone-all man page,MERGED,2013-08-30 20:14:24.000000000,2013-09-04 04:46:57.000000000,2013-09-04 04:46:56.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 8574}]","[{'number': 1, 'created': '2013-08-30 20:14:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e963e5c6a1d0094ef685c059297f5fba20db253f', 'message': 'Update keystone-all man page\n\nRegenerate the keystone-all man page by running keystone-all -h\nand pasting the output.\n\nChange-Id: I12e7fa08a1cdb1994843d9f0966b0e08d688a071\n'}, {'number': 2, 'created': '2013-08-30 20:15:50.000000000', 'files': ['doc/source/man/keystone-all.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f34fcbe7aaf563cc5f83009e00c7669714e302ea', 'message': 'Update keystone-all man page\n\nRegenerate the keystone-all man page by running keystone-all -h\nand pasting the output.\n\nChange-Id: I12e7fa08a1cdb1994843d9f0966b0e08d688a071\n'}]",1,44543,f34fcbe7aaf563cc5f83009e00c7669714e302ea,13,8,2,6486,,,0,"Update keystone-all man page

Regenerate the keystone-all man page by running keystone-all -h
and pasting the output.

Change-Id: I12e7fa08a1cdb1994843d9f0966b0e08d688a071
",git fetch https://review.opendev.org/openstack/keystone refs/changes/43/44543/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/man/keystone-all.rst'],1,e963e5c6a1d0094ef685c059297f5fba20db253f,man," keystone-all [-h] [--version] [--debug] [--nodebug] [--verbose] [--noverbose] [--use-syslog] [--nouse-syslog] [--pydev-debug-port PYDEV_DEBUG_PORT] [--config-file PATH] [--log-config PATH] [--log-format FORMAT] [--log-date-format DATE_FORMAT] [--config-dir DIR] [--log-file PATH] [--log-dir LOG_DIR] [--syslog-log-facility SYSLOG_LOG_FACILITY] [--pydev-debug-host PYDEV_DEBUG_HOST] --log-format FORMAT DEPRECATED. A logging.Formatter log message format string which may use any of the available logging.LogRecord attributes. This option is deprecated. Please use logging_context_format_string and logging_default_format_string instead. Format string for %(asctime)s in log records. Default: None --log-file PATH, --logfile PATH (Optional) Name of log file to output to. If no default is set, logging will go to stdout. --log-dir LOG_DIR, --logdir LOG_DIR (Optional) The base directory used for relative --log- file paths --syslog-log-facility SYSLOG_LOG_FACILITY syslog facility to receive log lines --pydev-debug-host PYDEV_DEBUG_HOST Host to connect to for remote debugger."," keystone-all [-h] [--version] [--pydev-debug-port PYDEV_DEBUG_PORT] [--verbose] [--noverbose] [--config-dir DIR] [--log-config PATH] [--log-date-format DATE_FORMAT] [--use-syslog] [--nouse-syslog] [--log-dir LOG_DIR] [--syslog-log-facility SYSLOG_LOG_FACILITY] [--config-file PATH] [--pydev-debug-host PYDEV_DEBUG_HOST] [--debug] [--nodebug] [--log-format FORMAT] [--log-file PATH] --log-format FORMAT A logging.Formatter log message format string which may use any of the available logging.LogRecord attributes. Format string for %(asctime)s in log records. --log-file PATH Name of log file to output. If not set, logging will go to stdout. --log-dir LOG_DIR The directory in which to store log files. (will be prepended to --log-file) --syslog-log-facility SYSLOG_LOG_FACILITY syslog facility to receive log lines. --pydev-debug-host PYDEV_DEBUG_HOST Host to connect to for remote debugger.",25,20
openstack%2Fnova~master~Ida5e440d1bdb9f8e9031277ea53a02d2ef171438,openstack/nova,master,Ida5e440d1bdb9f8e9031277ea53a02d2ef171438,Have tox install via setup.py develop,MERGED,2013-08-15 17:39:07.000000000,2013-09-04 04:46:29.000000000,2013-09-04 04:46:27.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 5652}]","[{'number': 1, 'created': '2013-08-15 17:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7eb5ec04972ff278a1385bb49fefbc4041952e1', 'message': 'Have tox install via setup.py develop\n\ntox 1.6 was released, which means that we can now take advantage of the\nfeature we added to it - which is using setup.py develop to install the\ncode into the virtualenv. The logic was taken from run_tests.sh - so the\nperformance issues around using tox vs. using install_venv should now be\ngone.\n\nrun_tests.sh is still needed to handle the ui switching between\nparallel, single and debug modes to testr.\n\nChange-Id: Ida5e440d1bdb9f8e9031277ea53a02d2ef171438\n'}, {'number': 2, 'created': '2013-08-16 18:18:14.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/32d63a9fbe6f353ca1af8922d6bcbb012a2cc32c', 'message': 'Have tox install via setup.py develop\n\ntox 1.6 was released, which means that we can now take advantage of the\nfeature we added to it - which is using setup.py develop to install the\ncode into the virtualenv. The logic was taken from run_tests.sh - so the\nperformance issues around using tox vs. using install_venv should now be\ngone.\n\nrun_tests.sh is still needed to handle the ui switching between\nparallel, single and debug modes to testr.\n\nChange-Id: Ida5e440d1bdb9f8e9031277ea53a02d2ef171438\n'}]",0,42178,32d63a9fbe6f353ca1af8922d6bcbb012a2cc32c,10,6,2,2,,,0,"Have tox install via setup.py develop

tox 1.6 was released, which means that we can now take advantage of the
feature we added to it - which is using setup.py develop to install the
code into the virtualenv. The logic was taken from run_tests.sh - so the
performance issues around using tox vs. using install_venv should now be
gone.

run_tests.sh is still needed to handle the ui switching between
parallel, single and debug modes to testr.

Change-Id: Ida5e440d1bdb9f8e9031277ea53a02d2ef171438
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/42178/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d7eb5ec04972ff278a1385bb49fefbc4041952e1,openstack/requirements,minversion = 1.6skipsdist = Trueusedevelop = True python setup.py test --slowest --testr-args='{posargs}', python setup.py testr --slowest --testr-args='{posargs}',4,1
openstack%2Fkeystone~master~I34b811513ebfd48d91600051724949c0a96c0734,openstack/keystone,master,I34b811513ebfd48d91600051724949c0a96c0734,"Utilities to create directores, set ownership & permissions",MERGED,2013-08-26 19:50:27.000000000,2013-09-04 04:46:18.000000000,2013-09-04 04:46:17.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6738}, {'_account_id': 7191}, {'_account_id': 8116}]","[{'number': 1, 'created': '2013-08-26 19:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/47a749a1110f55affc5a5c6bc429124b52f61724', 'message': 'Utilities to create directores, set ownership & permissions\n\nAdd the get_unix_user(), get_unix_group(), set_permissions(),\nmake_dirs() utilities to keystone/common/utils.py. These functions are\nmuch more robust and flexible. Ownership can be specifed either with\nsymbolic names or explicit id\'s. Any value you do not want to override\ncan be passed as None and it will be skipped.\n\nThe BaseCertificateConfigure class in openssl.py had it\'s own code to\ncreate directories, set ownership, set permissions, etc. which was\nused for setting up certificates, key files, etc. Properly handling\nfile system objects should not be a property of openssl, rather these\nshould be general utilities which can be used in a variety of\nlocations. Plus the openssl versions were not fully general and had\nsome pecular limitations. The new utilies will be used in a subsequent\npatch which also needs this functionality but isn\'t in openssl code.\n\nPreviously the openssl code was inconsistent as to whether it set the\nownership and permissions, sometimes ownership and permission was set\nonly if the file/dir did not exist, other times the ownership and\npermission were set irregardless of prior existence. The modified code\nnow always sets ownerhip and permissions (if provided).\n\nThe prior code assumed an id (uid/gid) was being passed for ownership,\nbut this was not documented. The code appears to take a symbolic\nname. The cli code converted symbolic names passed on the command line\nto id\'s before instantiating a class which accepts ownership\ninformation. If you instantiated one of the class without first\nconverting a name to an id it would throw an exception. The new\nutilities accept either symbolic names or id\'s and since these\nutilities are now used internally you can pass either a name or id and\none is no longer dependent upon special handling inside cli argument\nparsing code to get correct behavior with these classes.\n\nThere were several places with code like this:\n\n    os.chown(file_name, self.use_keystone_user or -1,\n             self.use_keystone_group or -1)\n\nThe intent would appear to be to avoid setting the uid or gid if the\nattribute had a value of None. Except this fails completely if the\nuid or gid belongs to root because those id\'s are zero, thus the code\nwould never work with root id\'s. The new utilities explicitly test for\na value of None and do not rely on the weak ""truth test"".\n\nNote: these new utilities are intended to be moved into oslo-incubator\nin the near future.\n\nFixes: bug #1206254\n\nChange-Id: I34b811513ebfd48d91600051724949c0a96c0734\n'}, {'number': 2, 'created': '2013-08-30 21:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c7e893609ad15e608c54e65b2ffc9e7f3d8f44a7', 'message': 'Utilities to create directores, set ownership & permissions\n\nAdd the get_unix_user(), get_unix_group(), set_permissions(),\nmake_dirs() utilities to keystone/common/utils.py. These functions are\nmuch more robust and flexible. Ownership can be specifed either with\nsymbolic names or explicit id\'s. Any value you do not want to override\ncan be passed as None and it will be skipped.\n\nThe BaseCertificateConfigure class in openssl.py had it\'s own code to\ncreate directories, set ownership, set permissions, etc. which was\nused for setting up certificates, key files, etc. Properly handling\nfile system objects should not be a property of openssl, rather these\nshould be general utilities which can be used in a variety of\nlocations. Plus the openssl versions were not fully general and had\nsome pecular limitations. The new utilies will be used in a subsequent\npatch which also needs this functionality but isn\'t in openssl code.\n\nPreviously the openssl code was inconsistent as to whether it set the\nownership and permissions, sometimes ownership and permission was set\nonly if the file/dir did not exist, other times the ownership and\npermission were set irregardless of prior existence. The modified code\nnow always sets ownerhip and permissions (if provided).\n\nThe prior code assumed an id (uid/gid) was being passed for ownership,\nbut this was not documented. The code appears to take a symbolic\nname. The cli code converted symbolic names passed on the command line\nto id\'s before instantiating a class which accepts ownership\ninformation. If you instantiated one of the class without first\nconverting a name to an id it would throw an exception. The new\nutilities accept either symbolic names or id\'s and since these\nutilities are now used internally you can pass either a name or id and\none is no longer dependent upon special handling inside cli argument\nparsing code to get correct behavior with these classes.\n\nThere were several places with code like this:\n\n    os.chown(file_name, self.use_keystone_user or -1,\n             self.use_keystone_group or -1)\n\nThe intent would appear to be to avoid setting the uid or gid if the\nattribute had a value of None. Except this fails completely if the\nuid or gid belongs to root because those id\'s are zero, thus the code\nwould never work with root id\'s. The new utilities explicitly test for\na value of None and do not rely on the weak ""truth test"".\n\nNote: these new utilities are intended to be moved into oslo-incubator\nin the near future.\n\nFixes: bug #1206254\n\nChange-Id: I34b811513ebfd48d91600051724949c0a96c0734\n'}, {'number': 3, 'created': '2013-08-31 18:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7fe2f2ed0494a762926e0cb5320d8436b2a2e2fd', 'message': 'Utilities to create directores, set ownership & permissions\n\nAdd the get_unix_user(), get_unix_group(), set_permissions(),\nmake_dirs() utilities to keystone/common/utils.py. These functions are\nmuch more robust and flexible. Ownership can be specifed either with\nsymbolic names or explicit id\'s. Any value you do not want to override\ncan be passed as None and it will be skipped.\n\nThe BaseCertificateConfigure class in openssl.py had it\'s own code to\ncreate directories, set ownership, set permissions, etc. which was\nused for setting up certificates, key files, etc. Properly handling\nfile system objects should not be a property of openssl, rather these\nshould be general utilities which can be used in a variety of\nlocations. Plus the openssl versions were not fully general and had\nsome pecular limitations. The new utilies will be used in a subsequent\npatch which also needs this functionality but isn\'t in openssl code.\n\nPreviously the openssl code was inconsistent as to whether it set the\nownership and permissions, sometimes ownership and permission was set\nonly if the file/dir did not exist, other times the ownership and\npermission were set irregardless of prior existence. The modified code\nnow always sets ownerhip and permissions (if provided).\n\nThe prior code assumed an id (uid/gid) was being passed for ownership,\nbut this was not documented. The code appears to take a symbolic\nname. The cli code converted symbolic names passed on the command line\nto id\'s before instantiating a class which accepts ownership\ninformation. If you instantiated one of the class without first\nconverting a name to an id it would throw an exception. The new\nutilities accept either symbolic names or id\'s and since these\nutilities are now used internally you can pass either a name or id and\none is no longer dependent upon special handling inside cli argument\nparsing code to get correct behavior with these classes.\n\nThere were several places with code like this:\n\n    os.chown(file_name, self.use_keystone_user or -1,\n             self.use_keystone_group or -1)\n\nThe intent would appear to be to avoid setting the uid or gid if the\nattribute had a value of None. Except this fails completely if the\nuid or gid belongs to root because those id\'s are zero, thus the code\nwould never work with root id\'s. The new utilities explicitly test for\na value of None and do not rely on the weak ""truth test"".\n\nNote: these new utilities are intended to be moved into oslo-incubator\nin the near future.\n\nFixes: bug #1206254\n\nChange-Id: I34b811513ebfd48d91600051724949c0a96c0734\n'}, {'number': 4, 'created': '2013-08-31 21:29:38.000000000', 'files': ['keystone/common/openssl.py', 'keystone/cli.py', 'keystone/common/utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/4e6cf36697eeb02a420101e5e0be67072a5c9583', 'message': 'Utilities to create directores, set ownership & permissions\n\nAdd the get_unix_user(), get_unix_group(), set_permissions(),\nmake_dirs() utilities to keystone/common/utils.py. These functions are\nmuch more robust and flexible. Ownership can be specifed either with\nsymbolic names or explicit id\'s. Any value you do not want to override\ncan be passed as None and it will be skipped.\n\nThe BaseCertificateConfigure class in openssl.py had it\'s own code to\ncreate directories, set ownership, set permissions, etc. which was\nused for setting up certificates, key files, etc. Properly handling\nfile system objects should not be a property of openssl, rather these\nshould be general utilities which can be used in a variety of\nlocations. Plus the openssl versions were not fully general and had\nsome pecular limitations. The new utilies will be used in a subsequent\npatch which also needs this functionality but isn\'t in openssl code.\n\nPreviously the openssl code was inconsistent as to whether it set the\nownership and permissions, sometimes ownership and permission was set\nonly if the file/dir did not exist, other times the ownership and\npermission were set irregardless of prior existence. The modified code\nnow always sets ownerhip and permissions (if provided).\n\nThe prior code assumed an id (uid/gid) was being passed for ownership,\nbut this was not documented. The code appears to take a symbolic\nname. The cli code converted symbolic names passed on the command line\nto id\'s before instantiating a class which accepts ownership\ninformation. If you instantiated one of the class without first\nconverting a name to an id it would throw an exception. The new\nutilities accept either symbolic names or id\'s and since these\nutilities are now used internally you can pass either a name or id and\none is no longer dependent upon special handling inside cli argument\nparsing code to get correct behavior with these classes.\n\nThere were several places with code like this:\n\n    os.chown(file_name, self.use_keystone_user or -1,\n             self.use_keystone_group or -1)\n\nThe intent would appear to be to avoid setting the uid or gid if the\nattribute had a value of None. Except this fails completely if the\nuid or gid belongs to root because those id\'s are zero, thus the code\nwould never work with root id\'s. The new utilities explicitly test for\na value of None and do not rely on the weak ""truth test"".\n\nNote: these new utilities are intended to be moved into oslo-incubator\nin the near future.\n\nFixes: bug #1206254\n\nChange-Id: I34b811513ebfd48d91600051724949c0a96c0734\n'}]",0,43768,4e6cf36697eeb02a420101e5e0be67072a5c9583,16,8,4,8116,,,0,"Utilities to create directores, set ownership & permissions

Add the get_unix_user(), get_unix_group(), set_permissions(),
make_dirs() utilities to keystone/common/utils.py. These functions are
much more robust and flexible. Ownership can be specifed either with
symbolic names or explicit id's. Any value you do not want to override
can be passed as None and it will be skipped.

The BaseCertificateConfigure class in openssl.py had it's own code to
create directories, set ownership, set permissions, etc. which was
used for setting up certificates, key files, etc. Properly handling
file system objects should not be a property of openssl, rather these
should be general utilities which can be used in a variety of
locations. Plus the openssl versions were not fully general and had
some pecular limitations. The new utilies will be used in a subsequent
patch which also needs this functionality but isn't in openssl code.

Previously the openssl code was inconsistent as to whether it set the
ownership and permissions, sometimes ownership and permission was set
only if the file/dir did not exist, other times the ownership and
permission were set irregardless of prior existence. The modified code
now always sets ownerhip and permissions (if provided).

The prior code assumed an id (uid/gid) was being passed for ownership,
but this was not documented. The code appears to take a symbolic
name. The cli code converted symbolic names passed on the command line
to id's before instantiating a class which accepts ownership
information. If you instantiated one of the class without first
converting a name to an id it would throw an exception. The new
utilities accept either symbolic names or id's and since these
utilities are now used internally you can pass either a name or id and
one is no longer dependent upon special handling inside cli argument
parsing code to get correct behavior with these classes.

There were several places with code like this:

    os.chown(file_name, self.use_keystone_user or -1,
             self.use_keystone_group or -1)

The intent would appear to be to avoid setting the uid or gid if the
attribute had a value of None. Except this fails completely if the
uid or gid belongs to root because those id's are zero, thus the code
would never work with root id's. The new utilities explicitly test for
a value of None and do not rely on the weak ""truth test"".

Note: these new utilities are intended to be moved into oslo-incubator
in the near future.

Fixes: bug #1206254

Change-Id: I34b811513ebfd48d91600051724949c0a96c0734
",git fetch https://review.opendev.org/openstack/keystone refs/changes/68/43768/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/openssl.py', 'keystone/cli.py', 'keystone/common/utils.py']",3,47a749a1110f55affc5a5c6bc429124b52f61724,cms-nss,"import grpimport pwd def get_unix_user(user=None): '''Get the uid and user name. This is a convenience utility which accepts a variety of input which might represent a unix user. If successful it returns the uid and name. Valid input is: string A string is first considered to be a user name and a lookup is attempted under that name. If no name is found then an attempt is made to convert the string to an integer and perform a lookup as a uid. int An integer is interpretted as a uid. None None is interpreted to mean use the current process's effective user. If the input is a valid type but no user is found a KeyError is raised. If the input is not a valid type a TypeError is raised. :param object user: string, int or None specifying the user to lookup. :return: tuple of (uid, name) ''' if isinstance(user, basestring): try: user_info = pwd.getpwnam(user) except KeyError: try: i = int(user) except ValueError: raise KeyError(""user name '%s' not found"" % user) try: user_info = pwd.getpwuid(i) except KeyError: raise KeyError(""user id %d not found"" % i) elif isinstance(user, int): try: user_info = pwd.getpwuid(user) except KeyError: raise KeyError(""user id %d not found"" % user) elif user is None: user_info = pwd.getpwuid(os.geteuid()) else: raise TypeError('user must be string, int or None; not %s (%r)' % (user.__class__.__name__, user)) return user_info.pw_uid, user_info.pw_name def get_unix_group(group=None): '''Get the gid and group name. This is a convenience utility which accepts a variety of input which might represent a unix group. If successful it returns the gid and name. Valid input is: string A string is first considered to be a group name and a lookup is attempted under that name. If no name is found then an attempt is made to convert the string to an integer and perform a lookup as a gid. int An integer is interpretted as a gid. None None is interpreted to mean use the current process's effective group. If the input is a valid type but no group is found a KeyError is raised. If the input is not a valid type a TypeError is raised. :param object group: string, int or None specifying the group to lookup. :return: tuple of (gid, name) ''' if isinstance(group, basestring): try: group_info = grp.getgrnam(group) except KeyError: # Was an int passed as a string? # Try converting to int and lookup by id instead. try: i = int(group) except ValueError: raise KeyError(""group name '%s' not found"" % group) try: group_info = grp.getgrgid(i) except KeyError: raise KeyError(""group id %d not found"" % i) elif isinstance(group, int): try: group_info = grp.getgrgid(group) except KeyError: raise KeyError(""group id %d not found"" % group) elif group is None: group_info = grp.getgrgid(os.getegid()) else: raise TypeError('group must be string, int or None; not %s (%r)' % (group.__class__.__name__, group)) return group_info.gr_gid, group_info.gr_name def set_permissions(path, mode=None, user=None, group=None, log=None): '''Set the ownership and permissions on the pathname. Each of the mode, user and group are optional, if None then that aspect is not modified. Owner and group may be specified either with a symbolic name or numeric id. :param string path: Pathname of directory whose existence is assured. :param object mode: ownership permissions flags (int) i.e. chmod, if None do not set. :param object user: set user, name (string) or uid (integer), if None do not set. :param object group: set group, name (string) or gid (integer) if None do not set. :param logger log: logging.logger object, used to emit log messages, if None no logging is performed. ''' if user is None: user_uid, user_name = None, None else: user_uid, user_name = get_unix_user(user) if group is None: group_gid, group_name = None, None else: group_gid, group_name = get_unix_group(group) if log: if mode is None: mode_string = str(mode) else: mode_string = oct(mode) log.debug(""set_permissions: "" ""path='%s' mode=%s user=%s(%s) group=%s(%s)"", path, mode_string, user_name, user_uid, group_name, group_gid) # Change user and group if specified if user_uid is not None or group_gid is not None: if user_uid is None: user_uid = -1 if group_gid is None: group_gid = -1 try: os.chown(path, user_uid, group_gid) except OSError as exc: raise EnvironmentError(""chown('%s', %s, %s): %s"" % (path, user_name, group_name, exc.strerror)) # Change permission flags if mode is not None: try: os.chmod(path, mode) except OSError as exc: raise EnvironmentError(""chmod('%s', %#o): %s"" % (path, mode, exc.strerror)) def make_dirs(path, mode=None, user=None, group=None, log=None): '''Assure directory exists, set ownership and permissions. Assure the directory exists and optionally set it's ownership and permissions. Each of the mode, user and group are optional, if None then that aspect is not modified. Owner and group may be specified either with a symbolic name or numeric id. :param string path: Pathname of directory whose existence is assured. :param object mode: ownership permissions flags (int) i.e. chmod, if None do not set. :param object user: set user, name (string) or uid (integer), if None do not set. :param object group: set group, name (string) or gid (integer) if None do not set. :param logger log: logging.logger object, used to emit log messages, if None no logging is performed. ''' if log: if mode is None: mode_string = str(mode) else: mode_string = oct(mode) log.debug(""make_dirs path='%s' mode=%s user=%s group=%s"", path, mode_string, user, group) if not os.path.exists(path): try: os.makedirs(path) except OSError as exc: raise EnvironmentError(""makedirs('%s'): %s"" % (path, exc.strerror)) set_permissions(path, mode, user, group, log)",,268,37
openstack%2Ftrove~master~I1043e15c71607cabe2fd6f72f64705e80cd2cde1,openstack/trove,master,I1043e15c71607cabe2fd6f72f64705e80cd2cde1,Support Security Group Name Prefix Customization,MERGED,2013-08-29 20:01:43.000000000,2013-09-04 04:31:18.000000000,2013-09-04 04:31:18.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1925}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8214}]","[{'number': 1, 'created': '2013-08-29 20:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/38f1c768f4bd55f635265f8cafe5d786d12c0ca0', 'message': 'Support Security Group Name Prefix Customization\n\nAs of now, if CONF.trove_security_groups_support == True, then a\nSecurity Group is created for every new Instance, following the\nnaming scheme of: ""SecGroup_<Instance\'s UUID>"".\nNicira NVP for Quantum enforces a Security Group naming limitation of\n40 chars maximum. Given the UUID\'s length, this only leaves 2\ncharacters for the prefix, e.g. \'SG\' vs. \'SecGroup\'.\nEven in lieu of restrictions, it\'s not inconceivable that a\nvendor/user might want to customize the naming scheme of their\nSecurity Groups to align with other cloud providers, etc.\n\nChange-Id: I1043e15c71607cabe2fd6f72f64705e80cd2cde1\nCloses-Bug: #1218589\n'}, {'number': 2, 'created': '2013-08-29 20:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4c5e70751800a5432ebce0046d9757cbbb8f089d', 'message': 'Support Security Group Name Prefix Customization\n\nAs of now, if CONF.trove_security_groups_support == True, then a\nSecurity Group is created for every new Instance, following the\nnaming scheme of: ""SecGroup_<Instance\'s UUID>"".\n\nNicira NVP for Quantum enforces a Security Group naming limitation of\n40 chars maximum. Given the UUID\'s length, this only leaves 2\ncharacters for the prefix, e.g. \'SG\' vs. \'SecGroup\'.\n\nEven in lieu of restrictions, it\'s not inconceivable that a\nvendor/user might want to customize the naming scheme of their\nSecurity Groups to align with other cloud providers, etc.\n\nChange-Id: I1043e15c71607cabe2fd6f72f64705e80cd2cde1\nCloses-Bug: #1218589\n'}, {'number': 3, 'created': '2013-08-29 20:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9388fa24b3eec3330bda36dd73548aac0e0a19ea', 'message': 'Support Security Group Name Prefix Customization\n\nAs of now, if CONF.trove_security_groups_support == True, then a\nSecurity Group is created for every new Instance, following the\nnaming scheme of: ""SecGroup_<Instance\'s UUID>"".\n\nNicira NVP for Quantum enforces a Security Group naming limitation of\n40 chars maximum. Given the UUID\'s length, this only leaves 2\ncharacters for the prefix, e.g. \'SG\' vs. \'SecGroup\'.\n\nEven in lieu of restrictions, it\'s not inconceivable that a\nvendor/user might want to customize the naming scheme of their\nSecurity Groups to align with other cloud providers, etc.\n\nChange-Id: I1043e15c71607cabe2fd6f72f64705e80cd2cde1\nCloses-Bug: #1218589\n'}, {'number': 4, 'created': '2013-09-03 17:55:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1f3b4364be7ea65b7774ee444e6d5fb6a221e214', 'message': 'Support Security Group Name Prefix Customization\n\nAs of now, if CONF.trove_security_groups_support == True, then a\nSecurity Group is created for every new Instance, following the\nnaming scheme of: ""SecGroup_<Instance\'s UUID>"".\n\nNicira NVP for Quantum enforces a Security Group naming limitation of\n40 chars maximum. Given the UUID\'s length, this only leaves 2\ncharacters for the prefix, e.g. \'SG\' vs. \'SecGroup\'.\n\nEven in lieu of restrictions, it\'s not inconceivable that a\nvendor/user might want to customize the naming scheme of their\nSecurity Groups to align with other cloud providers, etc.\n\nChange-Id: I1043e15c71607cabe2fd6f72f64705e80cd2cde1\nCloses-Bug: #1218589\n'}, {'number': 5, 'created': '2013-09-03 17:56:18.000000000', 'files': ['trove/common/cfg.py', 'trove/extensions/security_group/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/157e1807b42f6ccd5e282bc938638ffbc0da6611', 'message': 'Support Security Group Name Prefix Customization\n\nAs of now, if CONF.trove_security_groups_support == True, then a\nSecurity Group is created for every new Instance, following the\nnaming scheme of: ""SecGroup_<Instance\'s UUID>"".\n\nNicira NVP for Quantum enforces a Security Group naming limitation of\n40 chars maximum. Given the UUID\'s length, this only leaves 2\ncharacters for the prefix, e.g. \'SG\' vs. \'SecGroup\'.\n\nEven in lieu of restrictions, it\'s not inconceivable that a\nvendor/user might want to customize the naming scheme of their\nSecurity Groups to align with other cloud providers, etc.\n\nChange-Id: I1043e15c71607cabe2fd6f72f64705e80cd2cde1\nCloses-Bug: #1218589\n'}]",0,44351,157e1807b42f6ccd5e282bc938638ffbc0da6611,25,6,5,8214,,,0,"Support Security Group Name Prefix Customization

As of now, if CONF.trove_security_groups_support == True, then a
Security Group is created for every new Instance, following the
naming scheme of: ""SecGroup_<Instance's UUID>"".

Nicira NVP for Quantum enforces a Security Group naming limitation of
40 chars maximum. Given the UUID's length, this only leaves 2
characters for the prefix, e.g. 'SG' vs. 'SecGroup'.

Even in lieu of restrictions, it's not inconceivable that a
vendor/user might want to customize the naming scheme of their
Security Groups to align with other cloud providers, etc.

Change-Id: I1043e15c71607cabe2fd6f72f64705e80cd2cde1
Closes-Bug: #1218589
",git fetch https://review.opendev.org/openstack/trove refs/changes/51/44351/5 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/cfg.py', 'trove/extensions/security_group/models.py']",2,38f1c768f4bd55f635265f8cafe5d786d12c0ca0,bug/1218589," name = _(""%s_%s"") % (CONF.trove_security_group_name_prefix, instance_id)"," name = _(""SecGroup_%s"") % instance_id",2,1
openstack-attic%2Fidentity-api~master~I696306b0679c9982267a1d8da1bfb1266c8e6a6d,openstack-attic/identity-api,master,I696306b0679c9982267a1d8da1bfb1266c8e6a6d,Authorizing user should propose roles to delegate for OAuth,MERGED,2013-08-25 05:19:18.000000000,2013-09-04 04:22:11.000000000,2013-09-04 04:22:11.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 1916}, {'_account_id': 2903}, {'_account_id': 6482}]","[{'number': 1, 'created': '2013-08-25 05:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/2c528c296b7a3266029c18c7777cb140d69d4a7d', 'message': 'Authorizing user should propose roles to delegate for OAuth\n\nCurrently in the oauth1 extension the consumer specifies roles\ninstead of delegator. This is a design fault that should be fixed\nby having the authorizing user provide a set of roles (ids)\nduring the authorize request token phase\n\nfixes bug: #1216408\n\nChange-Id: I696306b0679c9982267a1d8da1bfb1266c8e6a6d\n'}, {'number': 2, 'created': '2013-08-28 20:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/ecd53076bb82357fcb896f4edb56d926a48dd811', 'message': 'Authorizing user should propose roles to delegate for OAuth\n\nCurrently in the oauth1 extension the consumer specifies roles\ninstead of delegator. This is a design fault that should be fixed\nby having the authorizing user provide a set of roles (ids)\nduring the authorize request token phase\n\nfixes bug: #1216408\n\nChange-Id: I696306b0679c9982267a1d8da1bfb1266c8e6a6d\n'}, {'number': 3, 'created': '2013-09-04 04:16:19.000000000', 'files': ['openstack-identity-api/v3/src/markdown/identity-api-v3-os-oauth1-ext.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/06da3835aecfb966b1413abdab06a41d8db040a1', 'message': 'Authorizing user should propose roles to delegate for OAuth\n\nCurrently in the oauth1 extension the consumer specifies roles\ninstead of delegator. This is a design fault that should be fixed\nby having the authorizing user provide a set of roles (ids)\nduring the authorize request token phase\n\nfixes bug: #1216408\n\nChange-Id: I696306b0679c9982267a1d8da1bfb1266c8e6a6d\n'}]",16,43611,06da3835aecfb966b1413abdab06a41d8db040a1,21,6,3,6482,,,0,"Authorizing user should propose roles to delegate for OAuth

Currently in the oauth1 extension the consumer specifies roles
instead of delegator. This is a design fault that should be fixed
by having the authorizing user provide a set of roles (ids)
during the authorize request token phase

fixes bug: #1216408

Change-Id: I696306b0679c9982267a1d8da1bfb1266c8e6a6d
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/11/43611/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-identity-api/v3/src/markdown/identity-api-v3-os-oauth1-ext.md'],1,2c528c296b7a3266029c18c7777cb140d69d4a7d,bug1216408,"Token. Note that there is one extra parameter, `requested_project_id`. `requested_project_id` contains the ID of the project upon which the Consumer would like delegated. The Identity service may include an `oauth_expires_at` attribute in the response. If no such attribute is included, or is null, then the token may last indefinitely.To authorize the Request Token, the authorizing user must belong to the requested project. Upon successful authorization, an OAuth Verifier code is returned. The Consumer receives the OAuth Verifier from the User out-of-band. Request: { ""roles"": [ { ""id"": ""a3b29b"" }, { ""id"": ""49993e"" } ] }The returned token is scoped to the requested project and with the delegatedExample OpenStack token response: [Various OpenStack token responses](https://github.com/openstack/identity-api/blob/master/openstack-identity-api/v3/src/markdown/identity-api-v3.md#authentication-responses)","Token. Note that there are two extra parameters, `requested_role_ids` and `requested_project_id`. `requested_role_ids` contains the IDs of the roles the Consumer would like delegated. `requested_project_id` contains the ID of the project upon which the requested roles must be assigned. The Identity service may include an `oauth_expires_at` attribute in the response. If no such attribute is included, or is null, then the token may last indefinitely.- `requested_role_ids`: IDs of requested roles, comma separated - Example: `requested_role_ids=a3b29b,49993e` To authorize the Request Token, the authorizing user must have the requested role assignments on the requested project. Upon successful authorization, an OAuth Verifier code is returned. The Consumer receives the OAuth Verifier from the User out-of-band.The returned token is scoped to the requested project and with the requestedExample OpenStack token response: [Various Openstack token responses](https://github.com/openstack/identity-api/blob/master/openstack-identity-api/v3/src/markdown/identity-api-v3.md#authentication-responses)",23,16
openstack%2Fkeystone~master~I92563a125e6ac93762db5fda65412f9a68ef35e3,openstack/keystone,master,I92563a125e6ac93762db5fda65412f9a68ef35e3,Modify default file/directory permissions,MERGED,2013-08-26 19:50:27.000000000,2013-09-04 04:01:54.000000000,2013-09-04 04:01:54.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 6738}, {'_account_id': 7191}, {'_account_id': 8116}]","[{'number': 1, 'created': '2013-08-26 19:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/68a66fa4b1813dbf6c8b883e76e2aa4a868d7107', 'message': 'Modify default file/directory permissions.\n\n* Remove execute permission on regular files (PRIV_PERMS).\n* Create file mode constants for public/private directory/file.\n* Grant read access to group members for files/directores marked private.\n\nChange-Id: I92563a125e6ac93762db5fda65412f9a68ef35e3\nFixes: bug #1206254\n'}, {'number': 2, 'created': '2013-08-30 21:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d0f8d67ade65a7ec8498ab44583cf1ddc93eb5a0', 'message': 'Modify default file/directory permissions.\n\n* Remove execute permission on regular files (PRIV_PERMS).\n* Create file mode constants for public/private directory/file.\n* Grant read access to group members for files/directores marked private.\n\nChange-Id: I92563a125e6ac93762db5fda65412f9a68ef35e3\nFixes: bug #1206254\n'}, {'number': 3, 'created': '2013-08-31 18:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e625a1d1744d899610e3869e805b525667c97ea4', 'message': 'Modify default file/directory permissions.\n\n* Remove execute permission on regular files (PRIV_PERMS).\n* Create file mode constants for public/private directory/file.\n* Grant read access to group members for files/directores marked private.\n\nChange-Id: I92563a125e6ac93762db5fda65412f9a68ef35e3\nFixes: bug #1206254\n'}, {'number': 4, 'created': '2013-08-31 21:29:37.000000000', 'files': ['keystone/common/openssl.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3cfe102475e11402f61ccc54d87f542bc5d48b9b', 'message': 'Modify default file/directory permissions\n\n* Remove execute permission on regular files (PRIV_PERMS).\n* Create file mode constants for public/private directory/file.\n* Grant read access to group members for files/directores marked private.\n\nChange-Id: I92563a125e6ac93762db5fda65412f9a68ef35e3\nFixes: bug #1206254\n'}]",1,43767,3cfe102475e11402f61ccc54d87f542bc5d48b9b,18,8,4,8116,,,0,"Modify default file/directory permissions

* Remove execute permission on regular files (PRIV_PERMS).
* Create file mode constants for public/private directory/file.
* Grant read access to group members for files/directores marked private.

Change-Id: I92563a125e6ac93762db5fda65412f9a68ef35e3
Fixes: bug #1206254
",git fetch https://review.opendev.org/openstack/keystone refs/changes/67/43767/4 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/openssl.py'],1,68a66fa4b1813dbf6c8b883e76e2aa4a868d7107,cms-nss," PUBLIC_DIR_PERMS = 0755 # -rwxr-xr-x PRIVATE_DIR_PERMS = 0750 # -rwxr-x--- PUBLIC_FILE_PERMS = 0644 # -rw-r--r-- PRIVATE_FILE_PERMS = 0640 # -rw-r----- os.makedirs(dir_name, PUBLIC_DIR_PERMS) self._set_permissions(self.ssl_config_file_name, PRIVATE_FILE_PERMS) self._set_permissions(index_file_name, PRIVATE_FILE_PERMS) self._set_permissions(serial_file_name, PRIVATE_FILE_PERMS) PRIVATE_FILE_PERMS) self._set_permissions(ca_cert, PUBLIC_FILE_PERMS) self._set_permissions(os.path.dirname(signing_keyfile), PRIVATE_DIR_PERMS) self._set_permissions(signing_keyfile, PRIVATE_FILE_PERMS)","DIR_PERMS = (stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH) CERT_PERMS = stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH PRIV_PERMS = stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR os.makedirs(dir_name, DIR_PERMS) self._set_permissions(self.ssl_config_file_name, CERT_PERMS) self._set_permissions(index_file_name, PRIV_PERMS) self._set_permissions(serial_file_name, PRIV_PERMS) stat.S_IRUSR) self._set_permissions(ca_cert, CERT_PERMS) self._set_permissions(os.path.dirname(signing_keyfile), PRIV_PERMS) self._set_permissions(signing_keyfile, stat.S_IRUSR)",14,13
openstack%2Ftrove-integration~master~Ic819aaa08f8a78483e1c0ae0aa8af370c6705562,openstack/trove-integration,master,Ic819aaa08f8a78483e1c0ae0aa8af370c6705562,Custom Guest Log Directory Causes Init Failure,MERGED,2013-08-31 02:57:15.000000000,2013-09-04 04:01:37.000000000,2013-09-04 04:01:37.000000000,"[{'_account_id': 3}, {'_account_id': 739}, {'_account_id': 1375}, {'_account_id': 1925}, {'_account_id': 7092}, {'_account_id': 8214}]","[{'number': 1, 'created': '2013-08-31 02:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/ac32c77e3c5d20a84f9e20de9c7b6acd45c16c06', 'message': ""Custom Guest Log Directory Causes Init Failure\n\nThe log_dir in trove-guestagent.conf.sample currently defaults to\n'/tmp', and the log_file to 'logfile.txt'.\n\nIf the log_dir value is changed to, say, '/var/log/trove', guest\ninitialization will fail because the directory does not exist. Even\nif log_dir is set to '/var/log', initialization will fail due to\ninsufficient write permissions in said directory.\n\nSolution: The log_dir specified in trove-guestagent.conf.sample\nshould be created on-demand if necessary.\n\nChange-Id: Ic819aaa08f8a78483e1c0ae0aa8af370c6705562\nCloses-Bug: #1219137\n""}, {'number': 2, 'created': '2013-09-04 00:53:32.000000000', 'files': ['scripts/files/trove-guest.upstart.conf', 'scripts/functions_qemu', 'scripts/files/trove-guest.systemd.conf', 'scripts/files/elements/ubuntu-guest/extra-data.d/20-guest-upstart', 'scripts/functions', 'scripts/files/elements/fedora-guest/extra-data.d/20-guest-upstart'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/34ea41c273d16728c9d40dfb16009ea44a681652', 'message': ""Custom Guest Log Directory Causes Init Failure\n\nThe log_dir in trove-guestagent.conf.sample currently defaults to\n'/tmp', and the log_file to 'logfile.txt'.\n\nIf the log_dir value is changed to, say, '/var/log/trove', guest\ninitialization will fail because the directory does not exist. Even\nif log_dir is set to '/var/log', initialization will fail due to\ninsufficient write permissions in said directory.\n\nSolution: The log_dir specified in trove-guestagent.conf.sample\nshould be created on-demand if necessary.\n\nChange-Id: Ic819aaa08f8a78483e1c0ae0aa8af370c6705562\nCloses-Bug: #1219137\n""}]",0,44577,34ea41c273d16728c9d40dfb16009ea44a681652,17,6,2,8214,,,0,"Custom Guest Log Directory Causes Init Failure

The log_dir in trove-guestagent.conf.sample currently defaults to
'/tmp', and the log_file to 'logfile.txt'.

If the log_dir value is changed to, say, '/var/log/trove', guest
initialization will fail because the directory does not exist. Even
if log_dir is set to '/var/log', initialization will fail due to
insufficient write permissions in said directory.

Solution: The log_dir specified in trove-guestagent.conf.sample
should be created on-demand if necessary.

Change-Id: Ic819aaa08f8a78483e1c0ae0aa8af370c6705562
Closes-Bug: #1219137
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/77/44577/2 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/files/trove-guest.upstart.conf', 'scripts/files/trove-guest.systemd.conf', 'scripts/functions_qemu', 'scripts/files/elements/ubuntu-guest/extra-data.d/20-guest-upstart', 'scripts/functions', 'scripts/files/elements/fedora-guest/extra-data.d/20-guest-upstart']",6,ac32c77e3c5d20a84f9e20de9c7b6acd45c16c06,bug/1219137,"[ -n ""${GUEST_LOGDIR}"" ] || die ""GUEST_LOGDIR must be set to the desired guest log dir"" [ -n ""${ESCAPED_GUEST_LOGDIR}"" ] || die ""ESCAPED_GUEST_LOGDIR must be set to the escaped guest log dir""sed ""s/GUEST_USERNAME/${GUEST_USERNAME}/g;s/GUEST_LOGDIR/${ESCAPED_GUEST_LOGDIR}/g"" ${REDSTACK_SCRIPTS}/files/trove-guest.systemd.conf > ${TMP_HOOKS_PATH}/trove-guest.service","sed ""s/GUEST_USERNAME/${GUEST_USERNAME}/g"" ${REDSTACK_SCRIPTS}/files/trove-guest.systemd.conf > ${TMP_HOOKS_PATH}/trove-guest.service",35,2
openstack%2Fnova~master~I27f9397d006f1b66b53a91b04ec6763a4d8ac740,openstack/nova,master,I27f9397d006f1b66b53a91b04ec6763a4d8ac740,Improve EC2 API error responses,MERGED,2013-08-13 17:48:06.000000000,2013-09-04 04:01:08.000000000,2013-09-04 04:01:05.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2271}, {'_account_id': 5511}, {'_account_id': 6717}]","[{'number': 1, 'created': '2013-08-13 17:48:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1965e0577d487c1a523ae4c0c64c5091a54fa98c', 'message': 'Improve EC2 API error responses\n\nThis is a final patch from series of patches improving EC2 error\nresponses bringing finishing touches.\n\nUseless EC2APIError exception is finally annihilated. Nova exceptions\nthat were raised outside of EC2 API are now translated to appropriate\nEC2 error codes.\n\nExceptions caught in Executor were reordered for better readability.\n\nWith EC2 exceptions fixed, HTTP status code corresponding to raised\nexception is now returned instead of previously hardcoded 400.\n\nImplements: blueprint ec2-error-codes\n\nChange-Id: I27f9397d006f1b66b53a91b04ec6763a4d8ac740\n'}, {'number': 2, 'created': '2013-08-26 19:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90a501be9d7ffaa36b16b928690909778caf12ba', 'message': ""Improve EC2 API error responses\n\nThis is a final patch from series of patches improving EC2 error\nresponses that makes finishing touches.\n\nUseless EC2APIError exception is finally annihilated. Nova exceptions\nthat were raised outside of EC2 API are now translated to appropriate\nEC2 error codes using ec2_code attribute.\n\nWith EC2 exceptions fixed, HTTP status code corresponding to raised\nexception is now returned instead of previously hardcoded 400.\n\nFollowing valid EC2 error codes were added to existing exceptions\neliminating the need to translate them explicitly:\n\n * InvalidKeypair.ec2_code = 'InvalidKeyPair.Format'\n * KeyPairExists.ec2_code = 'InvalidKeyPair.Duplicate'\n * QuotaError.ec2_code = 'ResourceLimitExceeded'\n   (*LimitExceeded exceptions inherit from QuotaError)\n\nExceptions caught in Executor were reordered for better readability.\n\nImplements: blueprint ec2-error-codes\n\nChange-Id: I27f9397d006f1b66b53a91b04ec6763a4d8ac740\n""}, {'number': 3, 'created': '2013-08-26 19:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de394f5a824c6362d812fceb81133572cd516f73', 'message': ""Improve EC2 API error responses\n\nThis is a final patch from series of patches improving EC2 error\nresponses that makes finishing touches.\n\nUseless EC2APIError exception is finally annihilated. Nova exceptions\nthat were raised outside of EC2 API are now translated to appropriate\nEC2 error codes using ec2_code attribute.\n\nWith EC2 exceptions fixed, HTTP status code corresponding to raised\nexception is now returned instead of previously hardcoded 400.\n\nFollowing valid EC2 error codes were added to existing exceptions\neliminating the need to translate them explicitly:\n\n * InvalidKeypair.ec2_code = 'InvalidKeyPair.Format'\n * KeyPairExists.ec2_code = 'InvalidKeyPair.Duplicate'\n * QuotaError.ec2_code = 'ResourceLimitExceeded'\n   (*LimitExceeded exceptions inherit from QuotaError)\n\nExceptions caught in Executor were reordered for better readability.\n\nImplements: blueprint ec2-error-codes\n\nChange-Id: I27f9397d006f1b66b53a91b04ec6763a4d8ac740\n""}, {'number': 4, 'created': '2013-08-26 19:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c95680f489e648d2a8aaa9133a4b21f74ea660ef', 'message': ""Improve EC2 API error responses\n\nThis is a final patch from series of patches improving EC2 error\nresponses that makes finishing touches.\n\nUseless EC2APIError exception is finally annihilated. Nova exceptions\nthat were raised outside of EC2 API are now translated to appropriate\nEC2 error codes using ec2_code attribute.\n\nWith EC2 exceptions fixed, HTTP status code corresponding to raised\nexception is now returned instead of previously hardcoded 400.\n\nFollowing valid EC2 error codes were added to existing exceptions\neliminating the need to translate them explicitly:\n\n * InvalidKeypair.ec2_code = 'InvalidKeyPair.Format'\n * KeyPairExists.ec2_code = 'InvalidKeyPair.Duplicate'\n * QuotaError.ec2_code = 'ResourceLimitExceeded'\n   (*LimitExceeded exceptions inherit from QuotaError)\n\nExceptions caught in Executor were reordered for better readability.\n\nImplements: blueprint ec2-error-codes\n\nChange-Id: I27f9397d006f1b66b53a91b04ec6763a4d8ac740\n""}, {'number': 5, 'created': '2013-08-26 20:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f11cb9af7d2fd0e4206187ae095e1472eed1b7d', 'message': ""Improve EC2 API error responses\n\nThis is a final patch from series of patches improving EC2 error\nresponses that makes finishing touches.\n\nUseless EC2APIError exception is finally annihilated. Nova exceptions\nthat were raised outside of EC2 API are now translated to appropriate\nEC2 error codes using ec2_code attribute.\n\nWith EC2 exceptions fixed, HTTP status code corresponding to raised\nexception is now returned instead of previously hardcoded 400.\n\nFollowing valid EC2 error codes were added to existing exceptions\neliminating the need to translate them explicitly:\n\n * InvalidKeypair.ec2_code = 'InvalidKeyPair.Format'\n * KeyPairExists.ec2_code = 'InvalidKeyPair.Duplicate'\n * QuotaError.ec2_code = 'ResourceLimitExceeded'\n   (*LimitExceeded exceptions inherit from QuotaError)\n\nExceptions caught in Executor were reordered for better readability.\n\nImplements: blueprint ec2-error-codes\n\nChange-Id: I27f9397d006f1b66b53a91b04ec6763a4d8ac740\n""}, {'number': 6, 'created': '2013-08-27 14:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58647bd416fb8830cb8b2702e59df429e48db765', 'message': ""Improve EC2 API error responses\n\nThis is a final patch from series of patches improving EC2 error\nresponses that makes finishing touches.\n\nUseless EC2APIError exception is finally annihilated. Nova exceptions\nthat were raised outside of EC2 API are now translated to appropriate\nEC2 error codes using ec2_code attribute.\n\nWith EC2 exceptions fixed, HTTP status code corresponding to raised\nexception is now returned instead of previously hardcoded 400.\n\nFollowing valid EC2 error codes were added to existing exceptions\neliminating the need to translate them explicitly:\n\n * InvalidKeypair.ec2_code = 'InvalidKeyPair.Format'\n * KeyPairExists.ec2_code = 'InvalidKeyPair.Duplicate'\n * QuotaError.ec2_code = 'ResourceLimitExceeded'\n   (*LimitExceeded exceptions inherit from QuotaError)\n\nExceptions caught in Executor were reordered for better readability.\n\nImplements: blueprint ec2-error-codes\n\nChange-Id: I27f9397d006f1b66b53a91b04ec6763a4d8ac740\n""}, {'number': 7, 'created': '2013-08-28 15:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f95adecf7c467ffc372bbf83b6cfc6c28666143', 'message': ""Improve EC2 API error responses\n\nThis is a final patch from series of patches improving EC2 error\nresponses that makes finishing touches.\n\nUseless EC2APIError exception is finally annihilated. Nova exceptions\nthat were raised outside of EC2 API are now translated to appropriate\nEC2 error codes using ec2_code attribute.\n\nWith EC2 exceptions fixed, HTTP status code corresponding to raised\nexception is now returned instead of previously hardcoded 400. All\nexpected exceptions are treated as client errors and returned with 4xx\nHTTP status code for compatibility with EC2 API.\n\nUnexpected exceptions are now always logged on ERROR log level, CRITICAL\nwasn't really appropriate.\n\nFollowing valid EC2 error codes were added to existing exceptions\neliminating the need to translate them explicitly:\n\n * InvalidKeypair.ec2_code = 'InvalidKeyPair.Format'\n * KeyPairExists.ec2_code = 'InvalidKeyPair.Duplicate'\n * QuotaError.ec2_code = 'ResourceLimitExceeded'\n   (*LimitExceeded exceptions inherit from QuotaError)\n\nExceptions caught in Executor were reordered for better readability.\n\nImplements: blueprint ec2-error-codes\n\nChange-Id: I27f9397d006f1b66b53a91b04ec6763a4d8ac740\n""}, {'number': 8, 'created': '2013-08-29 16:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cee8cde411575857da296a40dd54a07055fbde2a', 'message': ""Improve EC2 API error responses\n\nThis is a final patch from series of patches improving EC2 error\nresponses that makes finishing touches.\n\nUseless EC2APIError exception is finally annihilated. Nova exceptions\nthat were raised outside of EC2 API are now translated to appropriate\nEC2 error codes using ec2_code attribute.\n\nWith EC2 exceptions fixed, HTTP status code corresponding to raised\nexception is now returned instead of previously hardcoded 400. All\nexpected exceptions are treated as client errors and returned with 4xx\nHTTP status code for compatibility with EC2 API.\n\nUnexpected exceptions are now always logged on ERROR log level, CRITICAL\nwasn't really appropriate.\n\nFollowing valid EC2 error codes were added to existing exceptions\neliminating the need to translate them explicitly:\n\n * InvalidKeypair.ec2_code = 'InvalidKeyPair.Format'\n * KeyPairExists.ec2_code = 'InvalidKeyPair.Duplicate'\n * QuotaError.ec2_code = 'ResourceLimitExceeded'\n   (*LimitExceeded exceptions inherit from QuotaError)\n\nExceptions caught in Executor were reordered for better readability.\n\nImplements: blueprint ec2-error-codes\n\nChange-Id: I27f9397d006f1b66b53a91b04ec6763a4d8ac740\n""}, {'number': 9, 'created': '2013-09-02 16:04:07.000000000', 'files': ['nova/api/ec2/__init__.py', 'nova/tests/api/ec2/test_error_response.py', 'nova/exception.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py', 'nova/tests/test_exception.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e11834f9a2b61578c236b958f39cdff8019465e3', 'message': ""Improve EC2 API error responses\n\nThis is a final patch from series of patches improving EC2 error\nresponses that makes finishing touches.\n\nUseless EC2APIError exception is finally annihilated. Nova exceptions\nthat were raised outside of EC2 API are now translated to appropriate\nEC2 error codes using ec2_code attribute.\n\nWith EC2 exceptions fixed, HTTP status code corresponding to raised\nexception is now returned instead of previously hardcoded 400. All\nexpected exceptions are treated as client errors and returned with 4xx\nHTTP status code for compatibility with EC2 API.\n\nUnexpected exceptions are now always logged on ERROR log level, CRITICAL\nwasn't really appropriate.\n\nFollowing valid EC2 error codes were added to existing exceptions\neliminating the need to translate them explicitly:\n\n * InvalidKeypair.ec2_code = 'InvalidKeyPair.Format'\n * KeyPairExists.ec2_code = 'InvalidKeyPair.Duplicate'\n * QuotaError.ec2_code = 'ResourceLimitExceeded'\n   (*LimitExceeded exceptions inherit from QuotaError)\n\nExceptions caught in Executor were reordered for better readability.\n\nImplements: blueprint ec2-error-codes\n\nChange-Id: I27f9397d006f1b66b53a91b04ec6763a4d8ac740\n""}]",1,41754,e11834f9a2b61578c236b958f39cdff8019465e3,41,6,9,6717,,,0,"Improve EC2 API error responses

This is a final patch from series of patches improving EC2 error
responses that makes finishing touches.

Useless EC2APIError exception is finally annihilated. Nova exceptions
that were raised outside of EC2 API are now translated to appropriate
EC2 error codes using ec2_code attribute.

With EC2 exceptions fixed, HTTP status code corresponding to raised
exception is now returned instead of previously hardcoded 400. All
expected exceptions are treated as client errors and returned with 4xx
HTTP status code for compatibility with EC2 API.

Unexpected exceptions are now always logged on ERROR log level, CRITICAL
wasn't really appropriate.

Following valid EC2 error codes were added to existing exceptions
eliminating the need to translate them explicitly:

 * InvalidKeypair.ec2_code = 'InvalidKeyPair.Format'
 * KeyPairExists.ec2_code = 'InvalidKeyPair.Duplicate'
 * QuotaError.ec2_code = 'ResourceLimitExceeded'
   (*LimitExceeded exceptions inherit from QuotaError)

Exceptions caught in Executor were reordered for better readability.

Implements: blueprint ec2-error-codes

Change-Id: I27f9397d006f1b66b53a91b04ec6763a4d8ac740
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/41754/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/ec2/__init__.py', 'nova/tests/api/ec2/test_error_response.py', 'nova/exception.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py', 'nova/tests/test_exception.py']",6,1965e0577d487c1a523ae4c0c64c5091a54fa98c,bp/ec2-error-codes,,"class EC2APIErrorTestCase(test.TestCase): def test_return_valid_error(self): # without 'code' arg err = exception.EC2APIError('fake error') self.assertEqual(err.__str__(), 'fake error') self.assertEqual(err.code, None) self.assertEqual(err.msg, 'fake error') # with 'code' arg err = exception.EC2APIError('fake error', 'blah code') self.assertEqual(err.code, 'blah code') self.assertEqual(err.msg, 'fake error') ",65,62
openstack%2Ftrove-integration~master~I5047594827bcc3f9f2e0d909d6e9c24f57d4fd19,openstack/trove-integration,master,I5047594827bcc3f9f2e0d909d6e9c24f57d4fd19,Include oslo.config=1.2.0a3 for trove guest VM,MERGED,2013-09-02 14:35:57.000000000,2013-09-04 04:01:00.000000000,2013-09-04 04:01:00.000000000,"[{'_account_id': 3}, {'_account_id': 739}, {'_account_id': 1925}, {'_account_id': 7092}, {'_account_id': 8309}]","[{'number': 1, 'created': '2013-09-02 14:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/3e7f06634effa95ae95201bd4fa0357d7aa12d53', 'message': 'Include oslo.config=1.2.0a3 for trove guest VM\n\npython dependencies were being installed\n(including oslo.config) before we install\ntrove inside guest VM,therefore the\noslo.config>=1.2.0a3 was not picked\n up from trove requirements.txt.\nThe same has been addressed here.\n\nChange-Id: I5047594827bcc3f9f2e0d909d6e9c24f57d4fd19\nFixes: bug #1215001\n'}, {'number': 2, 'created': '2013-09-04 00:34:37.000000000', 'files': ['scripts/files/elements/fedora-guest/install.d/15-reddwarf-dep', 'scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/8dc4161a457b84552182bee33566b41259b9704d', 'message': 'Include oslo.config=1.2.0a3 for trove guest VM\n\npython dependencies were being installed\n(including oslo.config) before we install\ntrove inside guest VM,therefore the\noslo.config>=1.2.0a3 was not picked\n up from trove requirements.txt.\nThe same has been addressed here.\n\nChange-Id: I5047594827bcc3f9f2e0d909d6e9c24f57d4fd19\nFixes: bug #1215001\n'}]",0,44718,8dc4161a457b84552182bee33566b41259b9704d,15,5,2,8309,,,0,"Include oslo.config=1.2.0a3 for trove guest VM

python dependencies were being installed
(including oslo.config) before we install
trove inside guest VM,therefore the
oslo.config>=1.2.0a3 was not picked
 up from trove requirements.txt.
The same has been addressed here.

Change-Id: I5047594827bcc3f9f2e0d909d6e9c24f57d4fd19
Fixes: bug #1215001
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/18/44718/2 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/files/elements/fedora-guest/install.d/15-reddwarf-dep', 'scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep']",2,3e7f06634effa95ae95201bd4fa0357d7aa12d53,bug/1215001,# install oslo.config from source than pypi (which is older) pip install http://tarballs.openstack.org/oslo.config/oslo.config-1.2.0a3.tar.gz#egg=oslo.config-1.2.0a3 pip install extras python-novaclient python-swiftclient python-cinderclient kombu>2.4.7 six babel,pip install extras python-novaclient python-swiftclient python-cinderclient oslo.config kombu>2.4.7 six babel,8,2
openstack%2Fheat~master~Id98eb4157df16674b8c8a9a190b82ee350c5386f,openstack/heat,master,Id98eb4157df16674b8c8a9a190b82ee350c5386f,Make error message for InvalidTemplateReference sane,MERGED,2013-09-03 15:33:25.000000000,2013-09-04 03:35:35.000000000,2013-09-04 03:35:35.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}]","[{'number': 1, 'created': '2013-09-03 15:33:25.000000000', 'files': ['heat/tests/test_vpc.py', 'heat/common/exception.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b4130affa26ce17b311fea8a23dbe5c22f972ed6', 'message': 'Make error message for InvalidTemplateReference sane\n\nPreviously it was more or less incomprehensible. Now it will report the\nnon-existent resource the uesr tried to reference and the path (starting\nwith Resources) in the JSON document where the error occurred.\n\nChange-Id: Id98eb4157df16674b8c8a9a190b82ee350c5386f\n'}]",1,44904,b4130affa26ce17b311fea8a23dbe5c22f972ed6,9,5,1,4257,,,0,"Make error message for InvalidTemplateReference sane

Previously it was more or less incomprehensible. Now it will report the
non-existent resource the uesr tried to reference and the path (starting
with Resources) in the JSON document where the error occurred.

Change-Id: Id98eb4157df16674b8c8a9a190b82ee350c5386f
",git fetch https://review.opendev.org/openstack/heat refs/changes/04/44904/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_vpc.py', 'heat/common/exception.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py']",4,b4130affa26ce17b311fea8a23dbe5c22f972ed6,master," def test_ref_fail(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Ref': 'baz'}, } } } }) ex = self.assertRaises(exception.InvalidTemplateReference, parser.Stack, None, 'test', tmpl) self.assertIn('""baz"" (in bar.Properties.Foo)', str(ex)) def test_getatt_fail(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Fn::GetAtt': ['baz', 'bar']}, } } } }) ex = self.assertRaises(exception.InvalidTemplateReference, parser.Stack, None, 'test', tmpl) self.assertIn('""baz"" (in bar.Properties.Foo)', str(ex)) def test_getatt_fail_nested_deep(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Fn::Join': ["","", [""blarg"", {'Fn::GetAtt': ['foo', 'bar']}, ""wibble"", {'Fn::GetAtt': ['baz', 'bar']}]]}, } } } }) ex = self.assertRaises(exception.InvalidTemplateReference, parser.Stack, None, 'test', tmpl) self.assertIn('""baz"" (in bar.Properties.Foo.Fn::Join[1][3])', str(ex)) def test_dependson_fail(self): tmpl = template.Template({ 'Resources': { 'foo': { 'Type': 'GenericResourceType', 'DependsOn': 'wibble', } } }) ex = self.assertRaises(exception.InvalidTemplateReference, parser.Stack, None, 'test', tmpl) self.assertIn('""wibble"" (in foo)', str(ex)) ",,79,9
openstack%2Fpython-heatclient~master~I3e86f482a1b814a27b15be3c102727c44153221f,openstack/python-heatclient,master,I3e86f482a1b814a27b15be3c102727c44153221f,Be backward compatible after a renaming in API,MERGED,2013-08-29 14:40:18.000000000,2013-09-04 03:35:34.000000000,2013-09-04 03:35:34.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7075}]","[{'number': 1, 'created': '2013-08-29 14:40:18.000000000', 'files': ['heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/b95657fd15e8e1880978a130c4faa45b290397a8', 'message': 'Be backward compatible after a renaming in API\n\nThe need was introduced with the renaming of field logical_resource_id\nto resource_name, so let heatclient display the good one for the two\nHeat versions.\n\nFixes bug #1216903\n\nChange-Id: I3e86f482a1b814a27b15be3c102727c44153221f\n'}]",0,44295,b95657fd15e8e1880978a130c4faa45b290397a8,10,5,1,7075,,,0,"Be backward compatible after a renaming in API

The need was introduced with the renaming of field logical_resource_id
to resource_name, so let heatclient display the good one for the two
Heat versions.

Fixes bug #1216903

Change-Id: I3e86f482a1b814a27b15be3c102727c44153221f
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/95/44295/1 && git format-patch -1 --stdout FETCH_HEAD,['heatclient/v1/shell.py'],1,b95657fd15e8e1880978a130c4faa45b290397a8,bug/1216903," fields = ['resource_type', 'resource_status', 'updated_time'] if len(resources) >= 1: if hasattr(resources[0], 'resource_name'): fields.insert(0, 'resource_name') else: fields.insert(0, 'logical_resource_id') fields = ['id', 'resource_status_reason', if len(events) >= 1: if hasattr(events[0], 'resource_name'): fields.insert(0, 'resource_name') else: fields.insert(0, 'logical_resource_id')"," fields = ['resource_name', 'resource_type', 'resource_status', 'updated_time'] fields = ['resource_name', 'id', 'resource_status_reason',",13,3
openstack%2Fpython-heatclient~master~Ib309b989df6556d7436e718e1497ce4dcacc83d6,openstack/python-heatclient,master,Ib309b989df6556d7436e718e1497ce4dcacc83d6,Fix and enable Hacking H501 warning,MERGED,2013-09-02 19:39:51.000000000,2013-09-04 03:12:33.000000000,2013-09-04 03:12:33.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7680}]","[{'number': 1, 'created': '2013-09-02 19:39:51.000000000', 'files': ['heatclient/common/http.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/d48d3587bd9593eb03ecec556eea3772b9c89d04', 'message': 'Fix and enable Hacking H501 warning\n\nEnable Gating on H501. Fix the only two cases\nthat trigger.\n\nChange-Id: Ib309b989df6556d7436e718e1497ce4dcacc83d6\n'}]",0,44761,d48d3587bd9593eb03ecec556eea3772b9c89d04,7,4,1,6593,,,0,"Fix and enable Hacking H501 warning

Enable Gating on H501. Fix the only two cases
that trigger.

Change-Id: Ib309b989df6556d7436e718e1497ce4dcacc83d6
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/61/44761/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/common/http.py', 'tox.ini']",2,d48d3587bd9593eb03ecec556eea3772b9c89d04,,"ignore = H233,H302","ignore = H233,H302,H501",5,3
openstack%2Fpython-heatclient~master~Ie86726a0221e5e9aa68f7303d8ca8c7acd878f65,openstack/python-heatclient,master,Ie86726a0221e5e9aa68f7303d8ca8c7acd878f65,Added support for running the tests under PyPy with tox,MERGED,2013-09-04 00:32:10.000000000,2013-09-04 03:11:50.000000000,2013-09-04 03:11:50.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6800}, {'_account_id': 7385}, {'_account_id': 8257}]","[{'number': 1, 'created': '2013-09-04 00:32:10.000000000', 'files': ['heatclient/tests/test_shell.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/9d19772089bedeefd33d8a8cfef8aac00998f2c7', 'message': 'Added support for running the tests under PyPy with tox\n\nThis is a precursor to having them run under check and gate.\n\nThis also fixes a single test which fails on PyPy, the test failes at\nbecause it assumes a ``dict`` has a particular order for its keys when\nit is printed out, on PyPy dicts have a different order sometimes, the\nexact ordering is not a guarnteed property of Python.\n\nChange-Id: Ie86726a0221e5e9aa68f7303d8ca8c7acd878f65\n'}]",0,44987,9d19772089bedeefd33d8a8cfef8aac00998f2c7,8,7,1,7680,,,0,"Added support for running the tests under PyPy with tox

This is a precursor to having them run under check and gate.

This also fixes a single test which fails on PyPy, the test failes at
because it assumes a ``dict`` has a particular order for its keys when
it is printed out, on PyPy dicts have a different order sometimes, the
exact ordering is not a guarnteed property of Python.

Change-Id: Ie86726a0221e5e9aa68f7303d8ca8c7acd878f65
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/87/44987/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/test_shell.py', 'tox.ini']",2,9d19772089bedeefd33d8a8cfef8aac00998f2c7,tests-on-pypy,"envlist = py26,py27,pypy,pep8","envlist = py26,py27,pep8",4,4
openstack%2Fnova~master~I02412f586465d8f628af0a16af969035d779ff1e,openstack/nova,master,I02412f586465d8f628af0a16af969035d779ff1e,Remove a couple of unused stubs,MERGED,2013-08-28 10:04:03.000000000,2013-09-04 02:12:55.000000000,2013-09-04 02:12:53.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 2166}, {'_account_id': 2270}, {'_account_id': 4393}, {'_account_id': 7069}]","[{'number': 1, 'created': '2013-08-28 10:04:03.000000000', 'files': ['nova/tests/api/openstack/fakes.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f813eb634064d1561d5fbfac1ec57a7b052307bd', 'message': 'Remove a couple of unused stubs\n\nFound a couple of unused stub functions in API fakes when grepping for\nsomething else related to volumes.  Remove these.\n\nChange-Id: I02412f586465d8f628af0a16af969035d779ff1e\n'}]",0,44019,f813eb634064d1561d5fbfac1ec57a7b052307bd,15,7,1,1030,,,0,"Remove a couple of unused stubs

Found a couple of unused stub functions in API fakes when grepping for
something else related to volumes.  Remove these.

Change-Id: I02412f586465d8f628af0a16af969035d779ff1e
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/44019/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/fakes.py'],1,f813eb634064d1561d5fbfac1ec57a7b052307bd,api_fakes_cleanup,,"def stub_volume_create_from_image(self, context, size, name, description, snapshot, volume_type, metadata, availability_zone): vol = stub_volume('1') vol['status'] = 'creating' vol['size'] = size vol['display_name'] = name vol['display_description'] = description vol['availability_zone'] = 'nova' return vol def stub_volume_get_all_by_project(self, context, search_opts=None): return [stub_volume_get(self, context, '1')] ",0,16
openstack%2Fheat~master~Idd05c880913081dccfbcbb1f26a528705e5ec924,openstack/heat,master,Idd05c880913081dccfbcbb1f26a528705e5ec924,Add unit tests for Resource dependency inference,MERGED,2013-09-03 10:04:53.000000000,2013-09-04 02:12:14.000000000,2013-09-04 02:12:14.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6800}, {'_account_id': 7385}, {'_account_id': 7761}]","[{'number': 1, 'created': '2013-09-03 10:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/34eef3dd4594e6e831c5b6c24ee3af3a46dda3d5', 'message': 'Add unit tests for Resource dependency inference\n\nChange-Id: Idd05c880913081dccfbcbb1f26a528705e5ec924\n'}, {'number': 2, 'created': '2013-09-03 15:33:25.000000000', 'files': ['heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f2acd0e6147b71f4fa989a0ce44c6cb59ce5eb78', 'message': 'Add unit tests for Resource dependency inference\n\nChange-Id: Idd05c880913081dccfbcbb1f26a528705e5ec924\n'}]",7,44837,f2acd0e6147b71f4fa989a0ce44c6cb59ce5eb78,13,7,2,4257,,,0,"Add unit tests for Resource dependency inference

Change-Id: Idd05c880913081dccfbcbb1f26a528705e5ec924
",git fetch https://review.opendev.org/openstack/heat refs/changes/37/44837/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_resource.py'],1,34eef3dd4594e6e831c5b6c24ee3af3a46dda3d5,master,"from heat.engine import dependenciesfrom heat.engine import templateclass ResourceDependenciesTest(HeatTestCase): def setUp(self): super(ResourceDependenciesTest, self).setUp() utils.setup_dummy_db() resource._register_class('GenericResourceType', generic_rsrc.GenericResource) resource._register_class('ResourceWithPropsType', generic_rsrc.ResourceWithProps) self.deps = dependencies.Dependencies() def test_no_deps(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, } }) stack = parser.Stack(None, 'test', tmpl) res = stack['foo'] res.add_dependencies(self.deps) graph = self.deps.graph() self.assertTrue(res in graph) def test_ref(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Ref': 'foo'}, } } } }) stack = parser.Stack(None, 'test', tmpl) res = stack['bar'] res.add_dependencies(self.deps) graph = self.deps.graph() self.assertTrue(res in graph) self.assertTrue(stack['foo'] in graph[res]) def test_ref_nested_dict(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Fn::Base64': {'Ref': 'foo'}}, } } } }) stack = parser.Stack(None, 'test', tmpl) res = stack['bar'] res.add_dependencies(self.deps) graph = self.deps.graph() self.assertTrue(res in graph) self.assertTrue(stack['foo'] in graph[res]) def test_ref_nested_deep(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Fn::Join': ["","", [""blarg"", {'Ref': 'foo'}, ""wibble""]]}, } } } }) stack = parser.Stack(None, 'test', tmpl) res = stack['bar'] res.add_dependencies(self.deps) graph = self.deps.graph() self.assertTrue(res in graph) self.assertTrue(stack['foo'] in graph[res]) def test_ref_fail(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Ref': 'baz'}, } } } }) self.assertRaises(exception.InvalidTemplateReference, parser.Stack, None, 'test', tmpl) def test_getatt(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Fn::GetAtt': ['foo', 'bar']}, } } } }) stack = parser.Stack(None, 'test', tmpl) res = stack['bar'] res.add_dependencies(self.deps) graph = self.deps.graph() self.assertTrue(res in graph) self.assertTrue(stack['foo'] in graph[res]) def test_getatt_nested_dict(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Fn::Base64': {'Fn::GetAtt': ['foo', 'bar']}}, } } } }) stack = parser.Stack(None, 'test', tmpl) res = stack['bar'] res.add_dependencies(self.deps) graph = self.deps.graph() self.assertTrue(res in graph) self.assertTrue(stack['foo'] in graph[res]) def test_getatt_nested_deep(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Fn::Join': ["","", [""blarg"", {'Fn::GetAtt': ['foo', 'bar']}, ""wibble""]]}, } } } }) stack = parser.Stack(None, 'test', tmpl) res = stack['bar'] res.add_dependencies(self.deps) graph = self.deps.graph() self.assertTrue(res in graph) self.assertTrue(stack['foo'] in graph[res]) def test_getatt_fail(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Fn::GetAtt': ['baz', 'bar']}, } } } }) self.assertRaises(exception.InvalidTemplateReference, parser.Stack, None, 'test', tmpl) def test_dependson(self): tmpl = template.Template({ 'Resources': { 'foo': {'Type': 'GenericResourceType'}, 'bar': { 'Type': 'GenericResourceType', 'DependsOn': 'foo', } } }) stack = parser.Stack(None, 'test', tmpl) res = stack['bar'] res.add_dependencies(self.deps) graph = self.deps.graph() self.assertTrue(res in graph) self.assertTrue(stack['foo'] in graph[res]) def test_dependson_fail(self): tmpl = template.Template({ 'Resources': { 'foo': { 'Type': 'GenericResourceType', 'DependsOn': 'wibble', } } }) self.assertRaises(exception.InvalidTemplateReference, parser.Stack, None, 'test', tmpl) ",,224,0
openstack%2Fglance~master~I43b66b414ccf1817dd8d8a9651456b49de15e09f,openstack/glance,master,I43b66b414ccf1817dd8d8a9651456b49de15e09f,Adding unit test for rest api layer of task operation,ABANDONED,2013-09-02 15:33:47.000000000,2013-09-04 02:04:17.000000000,,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 6484}, {'_account_id': 6981}]","[{'number': 1, 'created': '2013-09-02 15:33:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3601d402a468f97b2e9e19c6cc24dbf7d1927aa2', 'message': 'Adding unit test for rest api layer of task operation\n\nAdding unit test code for rest api layer to enable support for\ntask operation.\n\nChange-Id: I43b66b414ccf1817dd8d8a9651456b49de15e09f\n'}, {'number': 2, 'created': '2013-09-02 15:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b3f39b9672d96e8e3757c0c75d3adf03fbde8809', 'message': 'Adding unit test for rest api layer of task operation\n\nAdding unit test code for rest api layer to enable support for\ntask operation.\n\nChange-Id: I43b66b414ccf1817dd8d8a9651456b49de15e09f\n'}, {'number': 3, 'created': '2013-09-03 08:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5e304598a8549a3c5a48c72d278011cb93c9376f', 'message': 'Adding unit test for rest api layer of task operation\n\nAdding unit test code for rest api layer to enable support for\ntask operation.\nPartially implement blueprint async-glance-workers\n\nChange-Id: I43b66b414ccf1817dd8d8a9651456b49de15e09f\n'}, {'number': 4, 'created': '2013-09-03 10:35:36.000000000', 'files': ['glance/tests/unit/v2/test_tasks_resource.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/06c68622458a6798415887078c96a9bea000de74', 'message': 'Adding unit test for rest api layer of task operation\n\nAdding unit test code for rest api layer to enable support for\ntask operation.\nPartially implement blueprint async-glance-workers\n\nChange-Id: I43b66b414ccf1817dd8d8a9651456b49de15e09f\n'}]",3,44731,06c68622458a6798415887078c96a9bea000de74,10,4,4,6981,,,0,"Adding unit test for rest api layer of task operation

Adding unit test code for rest api layer to enable support for
task operation.
Partially implement blueprint async-glance-workers

Change-Id: I43b66b414ccf1817dd8d8a9651456b49de15e09f
",git fetch https://review.opendev.org/openstack/glance refs/changes/31/44731/4 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/v2/test_tasks_resource.py'],1,3601d402a468f97b2e9e19c6cc24dbf7d1927aa2,bp/async-glance-workers," self.assertRaises(webob.exc.HTTPBadRequest, self.deserializer.create, request) def fake_get_request_body(request): return {'tenant': TENANT1, 'direct_url': 'http://test.com'} request = unit_test_utils.get_fake_request() self.stubs.Set(self.deserializer, '_get_request_body', fake_get_request_body) self.assertRaises(webob.exc.HTTPForbidden, self.deserializer.create, request) def test_create_full(self): task = {'type': 'export', 'input': {'import_from': 'swift://cloud.foo/myaccount/mycontainer/path', 'image_from_format': 'qcow2'}, 'owner': 'admin'} def fake_get_request_body(request): return task = {'type': 'export', 'input': {'import_from': 'swift://cloud.foo/myaccount/mycontainer/path', 'image_from_format': 'qcow2'}, 'owner': 'admin'} self.stubs.Set(self.deserializer, '_get_request_body', fake_get_request_body) return_task = self.deserializer.create(unit_test_utils.get_fake_request()) self.assertEqual(return_task, task) query_params = {'sort_key': 'created_at', 'sort_dir': 'desc', 'filters': {}} request = unit_test_utils.get_fake_request() return_query_params = self.deserializer.index(request) self.assertEqual(return_query_params, query_params) type = 'export' path = '/tasks?type=%s' % type request = unit_test_utils.get_fake_request(path) output = self.deserializer.index(request) self.assertEqual(output['filters']['type'], type) status = 'success' type = 'export' path = '/tasks?status=%(status)s&type=%(type)s' % locals() request = unit_test_utils.get_fake_request(path) output = self.deserializer.index(request) self.assertEqual(output['filters']['status'], status) self.assertEqual(output['filters']['type'], type) status = 'success' path = '/tasks?status=%s&limit=1' % status request = unit_test_utils.get_fake_request(path) output = self.deserializer.index(request) self.assertEqual(output['filters']['status'], status) self.assertEqual(output['limit'], 1) path = '/tasks?limit=test' request = unit_test_utils.get_fake_request(path) self.assertRaises(webob.exc.HTTPBadRequest, self.deserializer.index, request) path = '/tasks?limit=0' request = unit_test_utils.get_fake_request(path) output = self.deserializer.index(request) self.assertEqual(output['limit'], 0) path = '/tasks?limit=-1' request = unit_test_utils.get_fake_request(path) self.assertRaises(webob.exc.HTTPBadRequest, self.deserializer.index, request) request = unit_test_utils.get_fake_request('/tasks?limit=1.1') self.assertRaises(webob.exc.HTTPBadRequest, self.deserializer.index, request) status = 'invalid' path = '/tasks?status=%s' % status request = unit_test_utils.get_fake_request(path) self.assertRaises(webob.exc.HTTPBadRequest, self.deserializer.index, request) marker = uuidutils.generate_uuid() path = '/tasks?marker=%s' % marker request = unit_test_utils.get_fake_request(path) output = self.deserializer.index(request) self.assertEqual(output.get('marker'), marker) request = unit_test_utils.get_fake_request('/tasks') output = self.deserializer.index(request) self.assertFalse('marker' in output) request = unit_test_utils.get_fake_request('/tasks') output = self.deserializer.index(request) self.assertFalse('limit' in output) query_params = {'sort_key': 'id', 'sort_dir': 'desc', 'filters': {}} request = unit_test_utils.get_fake_request('/tasks?sort_key=id') return_query_params = self.deserializer.index(request) self.assertEqual(return_query_params, query_params) query_params = {'sort_key': 'created_at', 'sort_dir': 'asc', 'filters': {}} request = unit_test_utils.get_fake_request('/tasks?sort_dir=asc') request = unit_test_utils.get_fake_request('/tasks?sort_dir=invalid') self.assertRaises(webob.exc.HTTPBadRequest, self.deserializer.index, request)"," self.assertRaises(webob.exc.HTTPBadRequest, self.deserializer.create, request) def test_create_full(self): pass pass pass def test_index_with_filter(self): pass pass pass pass pass pass pass pass pass pass pass pass pass pass pass ",88,26
openstack%2Fpuppet-cinder~master~I6e974fddfb77901827ca06bab18250529f970bae,openstack/puppet-cinder,master,I6e974fddfb77901827ca06bab18250529f970bae,Add syslog support to cinder module,MERGED,2013-08-27 14:42:22.000000000,2013-09-04 01:48:34.000000000,2013-09-04 01:48:34.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1918}, {'_account_id': 2166}, {'_account_id': 3153}, {'_account_id': 4128}, {'_account_id': 7156}]","[{'number': 1, 'created': '2013-08-27 14:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/0cdd6043c3a3273cf72a2d96b8c8b5d0a0e3e67a', 'message': 'Add syslog support to cinder module\n\nChange-Id: I6e974fddfb77901827ca06bab18250529f970bae\n'}, {'number': 2, 'created': '2013-08-28 07:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/e67493bb1ea9079415b7f3ebed04bcebc18fc682', 'message': 'Add syslog support to cinder module\n\nChange-Id: I6e974fddfb77901827ca06bab18250529f970bae\n'}, {'number': 3, 'created': '2013-08-28 12:11:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/5257a09e34ab5d060e7c39d04f22c4f32ccffe51', 'message': 'Add syslog support to cinder module\n\nChange-Id: I6e974fddfb77901827ca06bab18250529f970bae\n'}, {'number': 4, 'created': '2013-08-30 06:43:57.000000000', 'files': ['manifests/init.pp', 'spec/classes/cinder_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/9bd451830d124703ab4b50dcab10e0a697c85ad6', 'message': 'Add syslog support to cinder module\n\nChange-Id: I6e974fddfb77901827ca06bab18250529f970bae\n'}]",7,43894,9bd451830d124703ab4b50dcab10e0a697c85ad6,23,7,4,4128,,,0,"Add syslog support to cinder module

Change-Id: I6e974fddfb77901827ca06bab18250529f970bae
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/94/43894/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/cinder_spec.rb']",2,0cdd6043c3a3273cf72a2d96b8c8b5d0a0e3e67a,cinder," describe 'with syslog enabled' do let :params do req_params.merge({ :use_syslog => 'true', }) end it { should contain_cinder_config('DEFAULT/use_syslog').with_value('True') } it { should contain_cinder_config('DEFAULT/syslog_log_facility').with_value('LOG_LOCAL0') } end describe 'with syslog enabled and custom settings' do let :params do req_params.merge({ :use_syslog => 'true', :log_facility => 'LOG_LOCAL1' }) end it { should contain_cinder_config('DEFAULT/use_syslog').with_value('True') } it { should contain_cinder_config('DEFAULT/syslog_log_facility').with_value('LOG_LOCAL1') } end ",,40,0
openstack%2Fcinder~master~Iad5908a50980c59df2d8d4702743a0b99f82f9b7,openstack/cinder,master,Iad5908a50980c59df2d8d4702743a0b99f82f9b7,Add features to Zadara Storage Cinder driver,MERGED,2013-08-16 04:38:31.000000000,2013-09-04 01:43:34.000000000,2013-09-04 01:43:34.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 736}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6604}]","[{'number': 1, 'created': '2013-08-16 04:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c381afef70cdd2b5e04f1b0d35296fbe863f88ad', 'message': 'blueprint zadara-cinder-driver-update\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}, {'number': 2, 'created': '2013-08-16 21:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7ef6cf8aee030e07581f32c1ca9f89b3177c20a5', 'message': 'blueprint zadara-cinder-driver-update\n\nUpdate for Zadara Storage Cinder driver:\n- move to Zadara APIs 13.07\n- added support for extend volume\n- added support for create/delete snapshot\n- added support for create clones from volumes and snaps\n- added volume stats\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}, {'number': 3, 'created': '2013-08-17 23:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8a7dd941edfedc2157f112edc2a86ce3ba84a1c7', 'message': 'Add features to Zadara Storage Cinder driver:\n- move to Zadara APIs 13.07\n- added support for extend volume\n- added support for create/delete snapshot\n- added support for create clones from volumes and snaps\n- added volume stats\n- added tests\n\nImplements: blueprint zadara-cinder-driver-update\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}, {'number': 4, 'created': '2013-08-17 23:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7d6af88e5f6cc7589a649f3b5ab064db74abb207', 'message': 'Add features to Zadara Storage Cinder driver\n\n- move to Zadara APIs 13.07\n- added support for extend volume\n- added support for create/delete snapshot\n- added support for create clones from volumes and snaps\n- added volume stats\n- added tests\n\nImplements: blueprint zadara-cinder-driver-update\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}, {'number': 5, 'created': '2013-08-18 18:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/893fa658e0e87d2037a59d3a4910466657fad8b7', 'message': 'Add features to Zadara Storage Cinder driver\n\n- move to Zadara APIs 13.07\n- added support for extend volume\n- added support for create/delete snapshot\n- added support for create clones from volumes and snaps\n- added volume stats\n- added tests\n\nImplements: blueprint zadara-cinder-driver-update\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}, {'number': 6, 'created': '2013-08-29 20:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9b7b5a5af7cfdbc06eb68bc9b8944f303f4b156a', 'message': 'Add features to Zadara Storage Cinder driver\n\n- move to Zadara APIs 13.07\n- added support for extend volume\n- added support for create/delete snapshot\n- added support for create clones from volumes and snaps\n- added volume stats\n- added tests\n\nImplements: blueprint zadara-cinder-driver-update\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}, {'number': 7, 'created': '2013-08-29 21:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2929e05137769e37259475b16ef5b298620fedde', 'message': 'Add features to Zadara Storage Cinder driver\n\n- move to Zadara APIs 13.07\n- added support for extend volume\n- added support for create/delete snapshot\n- added support for create clones from volumes and snaps\n- added volume stats\n- added tests\n\nImplements: blueprint zadara-cinder-driver-update\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}, {'number': 8, 'created': '2013-08-29 21:44:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0d182588199b71788d6a4a221927d4461044edf7', 'message': 'Add features to Zadara Storage Cinder driver\n\n- move to Zadara APIs 13.07\n- added support for extend volume\n- added support for create/delete snapshot\n- added support for create clones from volumes and snaps\n- added volume stats\n- added tests\n\nImplements: blueprint zadara-cinder-driver-update\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}, {'number': 9, 'created': '2013-08-30 23:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a07ce74ee2e6b43fffa5049aed0bd32a6be43d4f', 'message': 'Add features to Zadara Storage Cinder driver\n\n- move to Zadara APIs 13.07\n- added support for extend volume\n- added support for create/delete snapshot\n- added support for create clones from volumes and snaps\n- added volume stats\n- added tests\n\nImplements: blueprint zadara-cinder-driver-update\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}, {'number': 10, 'created': '2013-09-03 15:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/544e7202f388636c06d7767af232334c96b29f09', 'message': 'Add features to Zadara Storage Cinder driver\n\n- move to Zadara APIs 13.07\n- added support for extend volume\n- added support for create/delete snapshot\n- added support for create clones from volumes and snaps\n- added volume stats\n- added tests\n\nImplements: blueprint zadara-cinder-driver-update\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}, {'number': 11, 'created': '2013-09-03 22:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/230df0d3bf2fb770b928869e4167acfa729ef784', 'message': 'Add features to Zadara Storage Cinder driver\n\n- move to Zadara APIs 13.07\n- added support for extend volume\n- added support for create/delete snapshot\n- added support for create clones from volumes and snaps\n- added support for multi-backend\n- added volume stats\n- added tests\n\nImplements: blueprint zadara-cinder-driver-update\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}, {'number': 12, 'created': '2013-09-03 23:16:51.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/tests/test_zadara.py', 'cinder/volume/drivers/zadara.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2f907133aeaee09f58be30e75089c23b13573500', 'message': 'Add features to Zadara Storage Cinder driver\n\n- move to Zadara APIs 13.07\n- added support for extend volume\n- added support for create/delete snapshot\n- added support for create clones from volumes and snaps\n- added support for multi-backend\n- added volume stats\n- added tests\n\nImplements: blueprint zadara-cinder-driver-update\n\nChange-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7\n'}]",33,42281,2f907133aeaee09f58be30e75089c23b13573500,63,9,12,736,,,0,"Add features to Zadara Storage Cinder driver

- move to Zadara APIs 13.07
- added support for extend volume
- added support for create/delete snapshot
- added support for create clones from volumes and snaps
- added support for multi-backend
- added volume stats
- added tests

Implements: blueprint zadara-cinder-driver-update

Change-Id: Iad5908a50980c59df2d8d4702743a0b99f82f9b7
",git fetch https://review.opendev.org/openstack/cinder refs/changes/81/42281/12 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/exception.py', 'cinder/tests/test_zadara.py', 'cinder/volume/drivers/zadara.py']",3,c381afef70cdd2b5e04f1b0d35296fbe863f88ad,bp/zadara-cinder-driver-update,"This driver requires VPSA with API ver.13.07 or higher.VERSION = '13.07' LOG = logging.getLogger(__name__) cfg.StrOpt('zadara_default_thin_policy', default='YES', help='Default thin provisioning policy for volumes'), {'name': kwargs.get('name'), 'capacity': kwargs.get('size'), 'pool': CONF.zadara_vpsa_poolname, 'thin': CONF.zadara_default_thin_policy, 'crypt': CONF.zadara_default_encryption}), 'expand_volume': ('POST', '/api/volumes/%s/expand.xml' % kwargs.get('vpsa_vol'), {'capacity': kwargs.get('size')}), # Snapshot operations 'create_snapshot': ('POST', '/api/consistency_groups/%s/snapshots.xml' % kwargs.get('cg_name'), {'display_name': kwargs.get('snap_name')}), 'delete_snapshot': ('DELETE', '/api/snapshots/%s.xml' % kwargs.get('snap_id'), {}), 'create_clone_from_snap': ('POST', '/api/consistency_groups/%s/clone.xml' % kwargs.get('cg_name'), {'name': kwargs.get('name'), 'snapshot': kwargs.get('snap_id')}), 'create_clone': ('POST', '/api/consistency_groups/%s/clone.xml' % kwargs.get('cg_name'), {'name': kwargs.get('name')}), 'list_pools': ('GET', '/api/pools.xml', {}), {}), 'list_vol_snapshots': ('GET', '/api/consistency_groups/%s/snapshots.xml' % kwargs.get('cg_name'), {})} def _get_vpsa_volume(self, name): """"""Return VPSA's name & size for the volume."""""" return (volume.findtext('name'), int(volume.findtext('virtual-capacity'))) return (None, None) def _get_vpsa_volume_name(self, name): """"""Return VPSA's name for the volume."""""" (vol_name, size) = self._get_vpsa_volume(name) return vol_name def _get_volume_cg_name(self, name): """"""Return name of the consistency group for the volume."""""" xml_tree = self.vpsa.send_cmd('list_volumes') volume = self._xml_parse_helper(xml_tree, 'volumes', ('display-name', name)) if volume is not None: return volume.findtext('cg-name') def _get_snap_id(self, cg_name, snap_name): """"""Return snapshot ID for particular volume."""""" xml_tree = self.vpsa.send_cmd('list_vol_snapshots', cg_name=cg_name) snap = self._xml_parse_helper(xml_tree, 'snapshots', ('display-name', snap_name)) if snap is not None: return snap.findtext('name') return None def _get_pool_capacity(self, pool_name): """"""Return pool's total and available capacities"""""" xml_tree = self.vpsa.send_cmd('list_pools') pool = self._xml_parse_helper(xml_tree, 'pools', ('name', pool_name)) if pool is not None: total = int(pool.findtext('capacity')) free = int(float(pool.findtext('available-capacity'))) LOG.debug(_('Pool %(name)s: %(total)sGB total, %(free)sGB free'), {'name': pool_name, 'total': total, 'free': free}) return (total, free) return ('infinite', 'infinite') def create_snapshot(self, snapshot): """"""Creates a snapshot."""""" LOG.debug(_('Create snapshot: %s'), snapshot['name']) # Retrieve the CG name for the base volume volume_name = CONF.zadara_vol_name_template % snapshot['volume_name'] cg_name = self._get_volume_cg_name(volume_name) if not cg_name: msg = _('Volume %(name)s not found') % {'name': volume_name} LOG.warning(msg) raise exception.VolumeNotFound(volume_id=volume_name) self.vpsa.send_cmd('create_snapshot', cg_name=cg_name, snap_name=snapshot['name']) def delete_snapshot(self, snapshot): """"""Deletes a snapshot."""""" LOG.debug(_('Delete snapshot: %s'), snapshot['name']) # Retrieve the CG name for the base volume volume_name = CONF.zadara_vol_name_template % snapshot['volume_name'] cg_name = self._get_volume_cg_name(volume_name) if not cg_name: # If the volume isn't present, then don't attempt to delete LOG.warning(_(""snapshot: original volume %s not found, "" ""skipping delete operations"") % snapshot['volume_name']) return True snap_id = self._get_snap_id(cg_name, snapshot['name']) if not cg_name: # If the snapshot isn't present, then don't attempt to delete LOG.warning(_(""snapshot: snapshot %s not found, "" ""skipping delete operations"") % snapshot['name']) return True self.vpsa.send_cmd('delete_snapshot', snap_id=snap_id) def create_volume_from_snapshot(self, volume, snapshot): """"""Creates a volume from a snapshot."""""" LOG.info(_('Creating volume from snapshot: %s') % snapshot['name']) # Retrieve the CG name for the base volume volume_name = CONF.zadara_vol_name_template % snapshot['volume_name'] cg_name = self._get_volume_cg_name(volume_name) if not cg_name: msg = _('Volume %(name)s not found') % {'name': volume_name} LOG.warning(msg) raise exception.VolumeNotFound(volume_id=volume_name) snap_id = self._get_snap_id(cg_name, snapshot['name']) if not cg_name: msg = _('Snapshot %(name)s not found') % {'name': snapshot['name']} LOG.warning(msg) raise exception.VolumeNotFound(volume_id=snapshot['name']) self.vpsa.send_cmd('create_clone_from_snap', cg_name=cg_name, name=CONF.zadara_vol_name_template % volume['name'], snap_id=snap_id) def create_cloned_volume(self, volume, src_vref): """"""Creates a clone of the specified volume."""""" LOG.info(_('Creating clone of volume: %s') % src_vref['name']) # Retrieve the CG name for the base volume volume_name = CONF.zadara_vol_name_template % src_vref['name'] cg_name = self._get_volume_cg_name(volume_name) if not cg_name: msg = _('Volume %(name)s not found') % {'name': volume_name} LOG.warning(msg) raise exception.VolumeNotFound(volume_id=volume_name) self.vpsa.send_cmd('create_clone', cg_name=cg_name, name=CONF.zadara_vol_name_template % volume['name']) def extend_volume(self, volume, new_size): """"""Extend an existing volume."""""" # Get volume name name = CONF.zadara_vol_name_template % volume['name'] (vpsa_vol, size) = self._get_vpsa_volume(name) if not vpsa_vol: msg = _('Volume %(name)s could not be found. ' 'It might be already deleted') % {'name': name} LOG.warning(msg) raise exception.VolumeNotFound(volume_id=name) if new_size < size: raise exception.ZadaraInvalidSize( size=new_size, reason='existing size is %s' % (size)) expand_size = new_size - size self.vpsa.send_cmd('expand_volume', vpsa_vol=vpsa_vol, size=expand_size) def get_volume_stats(self, refresh=False): """"""Get volume stats. If 'refresh' is True, run update the stats first. """""" if refresh: self._update_volume_stats() return self._stats def _update_volume_stats(self): """"""Retrieve stats info from volume group."""""" LOG.debug(_(""Updating volume stats"")) data = {} backend_name = self.configuration.safe_get('volume_backend_name') data[""volume_backend_name""] = backend_name or self.__class__.__name__ data[""vendor_name""] = 'Zadara Storage' data[""driver_version""] = VERSION data[""storage_protocol""] = 'iSCSI' data['reserved_percentage'] = self.configuration.reserved_percentage data['QoS_support'] = False (total, free) = self._get_pool_capacity(CONF.zadara_vpsa_poolname) data['total_capacity_gb'] = total data['free_capacity_gb'] = free self._stats = data","This driver requires VPSA with API ver.12.06 or higher. LOG = logging.getLogger(""cinder.volume.driver"") cfg.StrOpt('zadara_default_cache_policy', default='write-through', help='Default cache policy for volumes'), {'display_name': kwargs.get('name'), 'virtual_capacity': kwargs.get('size'), 'raid_group_name[]': CONF.zadara_vpsa_poolname, 'quantity': 1, 'cache': CONF.zadara_default_cache_policy, 'crypt': CONF.zadara_default_encryption, 'mode': CONF.zadara_default_striping_mode, 'stripesize': CONF.zadara_default_stripesize, 'force': 'NO'}), {}), } def _get_vpsa_volume_name(self, name): """"""Return VPSA's name for the volume."""""" return volume.findtext('name')",393,37
openstack%2Fcinder~master~Ibf5cd746fc050eab5ce6aff13dd70c1e8066b228,openstack/cinder,master,Ibf5cd746fc050eab5ce6aff13dd70c1e8066b228,Set vg_thin_pool to pool name instead of pool_path,MERGED,2013-09-03 16:33:47.000000000,2013-09-04 01:43:32.000000000,2013-09-04 01:43:32.000000000,"[{'_account_id': 3}, {'_account_id': 2166}, {'_account_id': 2243}, {'_account_id': 7173}]","[{'number': 1, 'created': '2013-09-03 16:33:47.000000000', 'files': ['cinder/brick/local_dev/lvm.py', 'cinder/tests/brick/test_brick_lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/29e889bde9364f30c3f1cbeb7ee835b036451cba', 'message': 'Set vg_thin_pool to pool name instead of pool_path\n\ncreate_thin_pool is setting vg_thin_pool to the pool path instead of the\npool_name. This makes volumes creation fail when the create_thin_pool\nmethod is called. This happens because create_volume builds the pool\npath itself as create_thin_pool does.\n\nKeeping the pool name in vg_thin_pool instead of the path makes more\nsense and allows it to be used in other places in the brick. Also, most\ncommands return both vg_name and pool_name separated.\n\nChange-Id: Ibf5cd746fc050eab5ce6aff13dd70c1e8066b228\nCloses-Bug: #1220286\n'}]",0,44915,29e889bde9364f30c3f1cbeb7ee835b036451cba,7,4,1,6159,,,0,"Set vg_thin_pool to pool name instead of pool_path

create_thin_pool is setting vg_thin_pool to the pool path instead of the
pool_name. This makes volumes creation fail when the create_thin_pool
method is called. This happens because create_volume builds the pool
path itself as create_thin_pool does.

Keeping the pool name in vg_thin_pool instead of the path makes more
sense and allows it to be used in other places in the brick. Also, most
commands return both vg_name and pool_name separated.

Change-Id: Ibf5cd746fc050eab5ce6aff13dd70c1e8066b228
Closes-Bug: #1220286
",git fetch https://review.opendev.org/openstack/cinder refs/changes/15/44915/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/brick/local_dev/lvm.py', 'cinder/tests/brick/test_brick_lvm.py']",2,29e889bde9364f30c3f1cbeb7ee835b036451cba,issue/1220286," def test_volume_create_after_thin_creation(self): """"""Test self.vg.vg_thin_pool is set to pool_name See bug #1220286 for more info. """""" vg_name = ""vg-name"" pool_name = vg_name + ""-pool"" pool_path = ""%s/%s"" % (vg_name, pool_name) def executor(obj, *cmd, **kwargs): self.assertEqual(pool_path, cmd[-1]) self.vg._executor = executor self.vg.create_thin_pool(pool_name, ""1G"") self.vg.create_volume(""test"", ""1G"", lv_type='thin') self.assertEqual(self.vg.vg_thin_pool, pool_name) ",,20,1
openstack%2Fneutron~master~I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e,openstack/neutron,master,I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e,Refactoring for nicira plugin to support NVP DHCP/Metadata services,MERGED,2013-08-17 01:08:38.000000000,2013-09-04 01:43:24.000000000,2013-09-04 01:43:24.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 5127}, {'_account_id': 6676}]","[{'number': 1, 'created': '2013-08-17 01:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c57d5bd2a4ae09afe970833fce072c63376df82', 'message': 'Refactoring for nicira plugin to support NVP DHCP/Metadata services\n\nThis initial patch is aimed at decoupling core plugin services from\nDHCP and metadata services. The abstraction being introduced is\nneeded so that the code can support both models where dhcp and\nmetadata services are provided by external RPC agents or solely by\nthe server-side plugin.\n\nSupports blueprint nvp-dhcp-metadata-services\n\nChange-Id: I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e\n'}, {'number': 2, 'created': '2013-08-17 16:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e69af9644c7d97577bc7f385ce954fad7591065c', 'message': 'Refactoring for nicira plugin to support NVP DHCP/Metadata services\n\nThis initial patch is aimed at decoupling core plugin services from\nDHCP and metadata services. The abstraction being introduced is\nneeded so that the code can support both models where dhcp and\nmetadata services are provided by external RPC agents or solely by\nthe server-side plugin.\n\nSupports blueprint nvp-dhcp-metadata-services\n\nChange-Id: I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e\n'}, {'number': 3, 'created': '2013-08-23 21:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ec8d8a7f6c609c4b294c422bd7d155563ca39c4a', 'message': 'Refactoring for nicira plugin to support NVP DHCP/Metadata services\n\nThis initial patch is aimed at decoupling core plugin services from\nDHCP and metadata services. The abstraction being introduced is\nneeded so that the code can support both models where dhcp and\nmetadata services are provided by external RPC agents or solely by\nthe server-side plugin.\n\nSupports blueprint nvp-dhcp-metadata-services\n\nChange-Id: I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e\n'}, {'number': 4, 'created': '2013-08-30 15:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f747adb101d57943a6dd6bf2a99313f94515f94e', 'message': 'Refactoring for nicira plugin to support NVP DHCP/Metadata services\n\nThis initial patch is aimed at decoupling core plugin services from\nDHCP and metadata services. The abstraction being introduced is\nneeded so that the code can support both models where dhcp and\nmetadata services are provided by external RPC agents or solely by\nthe server-side plugin.\n\nSupports blueprint nvp-dhcp-metadata-services\n\nChange-Id: I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e\n'}, {'number': 5, 'created': '2013-08-30 21:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa423871f6d5a8d9d73fc7307cbbcbc104c97779', 'message': 'Refactoring for nicira plugin to support NVP DHCP/Metadata services\n\nThis initial patch is aimed at decoupling core plugin services from\nDHCP and metadata services. The abstraction being introduced is\nneeded so that the code can support both models where dhcp and\nmetadata services are provided by external RPC agents or solely by\nthe server-side plugin.\n\nSupports blueprint nvp-dhcp-metadata-services\n\nChange-Id: I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e\n'}, {'number': 6, 'created': '2013-09-01 21:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44b97bd458b487474f6d0d603470574ccec6108c', 'message': 'Refactoring for nicira plugin to support NVP DHCP/Metadata services\n\nThis initial patch is aimed at decoupling core plugin services from\nDHCP and metadata services. The abstraction being introduced is\nneeded so that the code can support both models where dhcp and\nmetadata services are provided by external RPC agents or solely by\nthe server-side plugin.\n\nSupports blueprint nvp-dhcp-metadata-services\n\nChange-Id: I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e\n'}, {'number': 7, 'created': '2013-09-03 19:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5a49112fe0fcc48d3a9f866acd5b70b886c1b4c', 'message': 'Refactoring for nicira plugin to support NVP DHCP/Metadata services\n\nThis initial patch is aimed at decoupling core plugin services from\nDHCP and metadata services. The abstraction being introduced is\nneeded so that the code can support both models where dhcp and\nmetadata services are provided by external RPC agents or solely by\nthe server-side plugin.\n\nSupports blueprint nvp-dhcp-metadata-services\n\nChange-Id: I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e\n'}, {'number': 8, 'created': '2013-09-03 20:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab1030a2a8c69732a93796b4176381df3b4dabfb', 'message': 'Refactoring for nicira plugin to support NVP DHCP/Metadata services\n\nThis initial patch is aimed at decoupling core plugin services from\nDHCP and metadata services. The abstraction being introduced is\nneeded so that the code can support both models where dhcp and\nmetadata services are provided by external RPC agents or solely by\nthe server-side plugin.\n\nSupports blueprint nvp-dhcp-metadata-services\n\nChange-Id: I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e\n'}, {'number': 9, 'created': '2013-09-03 22:04:42.000000000', 'files': ['neutron/plugins/nicira/dhcp_meta/__init__.py', 'neutron/plugins/nicira/dhcpmeta_modes.py', 'neutron/plugins/nicira/common/config.py', 'neutron/plugins/nicira/NeutronPlugin.py', 'neutron/plugins/nicira/dhcp_meta/rpc.py', 'neutron/tests/unit/nicira/test_nvpopts.py', 'neutron/plugins/nicira/common/metadata_access.py', 'etc/neutron/plugins/nicira/nvp.ini', 'neutron/tests/unit/nicira/etc/nvp.ini.agentless.test'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ba4ed39616c3c6fabf24ca390c7037877c672fba', 'message': 'Refactoring for nicira plugin to support NVP DHCP/Metadata services\n\nThis initial patch is aimed at decoupling core plugin services from\nDHCP and metadata services. The abstraction being introduced is\nneeded so that the code can support both models where dhcp and\nmetadata services are provided by external RPC agents or solely by\nthe server-side plugin.\n\nSupports blueprint nvp-dhcp-metadata-services\n\nChange-Id: I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e\n'}]",29,42449,ba4ed39616c3c6fabf24ca390c7037877c672fba,52,7,9,748,,,0,"Refactoring for nicira plugin to support NVP DHCP/Metadata services

This initial patch is aimed at decoupling core plugin services from
DHCP and metadata services. The abstraction being introduced is
needed so that the code can support both models where dhcp and
metadata services are provided by external RPC agents or solely by
the server-side plugin.

Supports blueprint nvp-dhcp-metadata-services

Change-Id: I396ee7bbcbd866e4e9d4a79887e844b4f5ec3c9e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/42449/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/nicira/dhcp_meta/__init__.py', 'neutron/plugins/nicira/common/config.py', 'neutron/plugins/nicira/agent_mode.py', 'neutron/plugins/nicira/NeutronPlugin.py', 'neutron/plugins/nicira/dhcp_meta/rpc.py', 'neutron/plugins/nicira/common/metadata_access.py', 'etc/neutron/plugins/nicira/nvp.ini']",7,9c57d5bd2a4ae09afe970833fce072c63376df82,bp/nvp-dhcp-metadata-services," # Specifies in which mode the plugin needs to operate in order to provide DHCP and # metadata proxy services to tenant instances. If 'agent' is chosen (default) # the NVP plugin relies on external RPC agents (i.e. dhcp and metadata agents) to # provide such services. In this mode, the plugin supports API extensions 'agent' # and 'dhcp_agent_scheduler'. If 'agentless' is chosen (experimental in Havana), # the plugin will use NVP logical services for DHCP and metadata proxy. This # simplifies the deployment model for Neutron, in that the plugin no longer requires # the RPC agents to operate. When 'agentless' is chosen, the config option metadata_mode # becomes ineffective. The mode 'agentless' can work only with NVP 3.3 or above. # agent_mode = agent",,376,292
openstack%2Fnova~master~I76eb2e4da027a13525314bd58264f482374d270d,openstack/nova,master,I76eb2e4da027a13525314bd58264f482374d270d,Guest-assisted-snaps libvirt implementation,MERGED,2013-08-20 05:45:43.000000000,2013-09-04 01:42:25.000000000,2013-09-04 01:42:22.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2166}, {'_account_id': 4523}, {'_account_id': 5511}]","[{'number': 1, 'created': '2013-08-20 05:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a5231cb0014b0654109b39316495cdf515525a3', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 3, 'created': '2013-08-20 05:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7651fe9c2cdff72e3e0bc0e1ab830adacd687f05', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 2, 'created': '2013-08-20 05:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fcebf98fc684587414125b79369a0f9649e28681', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 5, 'created': '2013-08-26 00:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f2edee79f6714275e83a346fd859b41509b5264', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nThe update_snapshot_metadata API from cinderclient is used to\ninform Cinder of the result of these operations.\n\nThis feature requires a minimum libvirt version of 1.1.1 due\nto a bug in libvirt BlockJobInfo handling in earlier versions.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 4, 'created': '2013-08-26 00:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62c96ef4c5ca15b7d7800c281b98bb66d7a0d3e8', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nThe update_snapshot_metadata API from cinderclient is used to\ninform Cinder of the result of these operations.\n\nThis feature requires a minimum libvirt version of 1.1.1 due\nto a bug in libvirt BlockJobInfo handling in earlier versions.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 6, 'created': '2013-08-27 19:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f883caf154dd337c1189538736aa00eeb98d170', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nThe update_snapshot_status API from cinderclient is used to\ninform Cinder of the result of these operations.\n\nThis feature requires a minimum libvirt version of 1.1.1 due\nto a bug in libvirt BlockJobInfo handling in earlier versions.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 7, 'created': '2013-08-30 04:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22812cb42fc9354a6489884b531197268ac6006a', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nThe update_snapshot_status API from cinderclient is used to\ninform Cinder of the result of these operations.\n\nThis feature requires a minimum libvirt version of 1.1.1 due\nto a bug in libvirt BlockJobInfo handling in earlier versions.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 8, 'created': '2013-08-30 05:17:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55043aa2bc33433928094ffab1eca3d3d25a61cd', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nThe update_snapshot_status API from cinderclient is used to\ninform Cinder of the result of these operations.\n\nThis feature requires a minimum libvirt version of 1.1.1 due\nto a bug in libvirt BlockJobInfo handling in earlier versions.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 9, 'created': '2013-08-31 02:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4c9c63b735085c9d00e7eeba9db3b950f7dbf3a', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nThe update_snapshot_status API from cinderclient is used to\ninform Cinder of the result of these operations.\n\nThis feature requires a minimum libvirt version of 1.1.1 due\nto a bug in libvirt BlockJobInfo handling in earlier versions.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 10, 'created': '2013-08-31 02:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a9bd81625b394ca60972d0e8e2b975c3d7f461c', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nThe update_snapshot_status API from cinderclient is used to\ninform Cinder of the result of these operations.\n\nThis feature requires a minimum libvirt version of 1.1.1 due\nto a bug in libvirt BlockJobInfo handling in earlier versions.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 11, 'created': '2013-08-31 05:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c37c46d48295240c55ec985ab331da96d58bd48f', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nThe update_snapshot_status API from cinderclient is used to\ninform Cinder of the result of these operations.\n\nThis feature requires a minimum libvirt version of 1.1.1 due\nto a bug in libvirt BlockJobInfo handling in earlier versions.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 12, 'created': '2013-09-01 14:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56f151a4e84d29f2ba69c7c67e70e40c67c138b0', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nThe update_snapshot_status API from cinderclient is used to\ninform Cinder of the result of these operations.\n\nThis feature requires a minimum libvirt version of 1.1.1 due\nto a bug in libvirt BlockJobInfo handling in earlier versions.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}, {'number': 13, 'created': '2013-09-02 21:03:47.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/fakelibvirt.py', 'nova/volume/cinder.py', 'nova/tests/virt/libvirt/test_libvirt_config.py', 'nova/virt/libvirt/config.py', 'nova/tests/volume/test_cinder.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b626c2a63703ff1c9794bbe8816c098a2bd80f83', 'message': 'Guest-assisted-snaps libvirt implementation\n\nThis implements volume_snapshot_create and volume_snapshot_delete\nmethods which create snapshots of QCOW2-based Cinder volumes.\n\nThe update_snapshot_status API from cinderclient is used to\ninform Cinder of the result of these operations.\n\nThis feature requires a minimum libvirt version of 1.1.1 due\nto a bug in libvirt BlockJobInfo handling in earlier versions.\n\nLibvirt implementation for blueprint qemu-assisted-snapshots\n\nChange-Id: I76eb2e4da027a13525314bd58264f482374d270d\n'}]",92,42812,b626c2a63703ff1c9794bbe8816c098a2bd80f83,67,7,13,4523,,,0,"Guest-assisted-snaps libvirt implementation

This implements volume_snapshot_create and volume_snapshot_delete
methods which create snapshots of QCOW2-based Cinder volumes.

The update_snapshot_status API from cinderclient is used to
inform Cinder of the result of these operations.

This feature requires a minimum libvirt version of 1.1.1 due
to a bug in libvirt BlockJobInfo handling in earlier versions.

Libvirt implementation for blueprint qemu-assisted-snapshots

Change-Id: I76eb2e4da027a13525314bd58264f482374d270d
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/42812/9 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,8a5231cb0014b0654109b39316495cdf515525a3,bp/qemu-assisted-snapshots,"from nova import conductorfrom nova import volume self._conductor_api = conductor.API() self._volume_api = volume.API() def _volume_snapshot_create(self, context, instance, domain, volume_id, new_file): """"""Perform volume snapshot params: domain: VM that volume is attached to volume_id: volume UUID to snapshot new_file: relative path to new qcow2 file present on share - We don't need to know the full path since libvirt can operate fully with relative paths. """""" failure = False xml = domain.XMLDesc(0) xml_doc = etree.fromstring(xml) disks = xml_doc.findall('./devices/disk') LOG.debug(""disks: %s"" % disks) disks_to_snap = [] # to be snapshotted by libvirt disks_to_skip = [] # local disks not snapshotted bdms = self._conductor_api.block_device_mapping_get_all_by_instance( context, instance) # Only interested in searching bdms that are connected volumes bdms = [bdm for bdm in bdms if bdm['volume_id'] and bdm['connection_info']] LOG.debug(""bdms: %s"" % bdms) for node in xml_doc.findall('./devices/disk'): t = node.find('target') if t is None: continue if node.find('serial') is None: disks_to_skip.append(t.get('dev')) continue if node.findtext('serial') != volume_id: disks_to_skip.append(t.get('dev')) continue # node is a Cinder volume disk_info = { 'dev': t.get('dev'), 'serial': node.findtext('serial'), 'current_file': node.find('source').get('file') } this_bdm = [elem for elem in bdms if elem['volume_id'] == node.findtext('serial')].pop() info = {'bdm': this_bdm, 'disk': disk_info} LOG.debug(""info: %s"" % info) volume_id = disk_info['serial'] # Determine path for new_file based on current path current_file = disk_info['current_file'] new_file_path = '%s/%s' % (os.path.dirname(current_file), new_file) disks_to_snap.append((current_file, new_file_path)) xml_snapshot = etree.Element('domainsnapshot') xml_disks = etree.Element('disks') for current_name, new_filename in disks_to_snap: LOG.debug(""creating xml for disk %s"" % disk) d = etree.Element('disk', name=current_name, snapshot='external') source = etree.Element('source', file=new_filename) d.append(source) xml_disks.append(d) for dev in disks_to_skip: LOG.debug(""skipping disk %s"" % dev) d = etree.Element('disk', name=dev, snapshot='no') xml_disks.append(d) xml_snapshot.append(xml_disks) LOG.debug(""snap xml: %s"" % etree.tostring(xml_snapshot)) snap_flags = (libvirt.VIR_DOMAIN_SNAPSHOT_CREATE_DISK_ONLY | libvirt.VIR_DOMAIN_SNAPSHOT_CREATE_NO_METADATA | libvirt.VIR_DOMAIN_SNAPSHOT_CREATE_REUSE_EXT) try: QUIESCE = libvirt.VIR_DOMAIN_SNAPSHOT_CREATE_QUIESCE domain.snapshotCreateXML(etree.tostring(xml_snapshot), snap_flags | QUIESCE) except libvirt.libvirtError: msg = _('Unable to create quiesced VM snapshot, ' 'attempting again quiescing disabled.') LOG.exception(msg) msg = _('Attempting snapshot again with quiescing disabled.') LOG.warning(msg) try: domain.snapshotCreateXML(etree.tostring(xml_snapshot), snap_flags) except libvirt.libvirtError: msg = _('Unable to create VM snapshot, ' ' failing volume_snapshot operation.') LOG.exception(msg) def volume_snapshot_create(self, context, instance, volume_id, connection_info): """"""Create snapshots of a Cinder volume via libvirt. :param instance: VM instance reference :param volume_id: id of volume being snapshotted :param connection_info: dict of information used to create snapshots - type : qcow2 / <other> - new_file : qcow2 file created by Cinder which becomes the VM's active image after the snapshot is complete """""" LOG.debug(""in libvirt/driver volume_snapshot..."") LOG.debug(""instance is %s"" % instance) LOG.debug(""connection_info is %s"" % connection_info) try: virt_dom = self._lookup_by_name(instance['name']) except exception.InstanceNotFound: raise exception.InstanceNotRunning(instance_id=instance['uuid']) if connection_info['type'] != 'qcow2': raise exception.InvalidArguments('Unknown type: %s' % connection_info['type']) self._volume_snapshot_create(context, instance, virt_dom, volume_id, connection_info['new_file']) def volume_snapshot_delete(self, context, instance, volume_id, snapshot_id, delete_info=None): """""" Note: if file being merged into == active image: do a blockRebase (pull) operation else: do a blockCommit operation Files must be adjacent in snap chain. :param instance: instance reference :param volume_id: volume UUID :param snapshot_id: snapshot UUID (unused currently) :param delete_info: { 'type': 'qcow2', 'file_to_merge': 'a.img', 'merge_target_file': 'b.img' or None (if merging file_to_merge into active image) } """""" LOG.debug('in libvirt/driver volume_snapshot_delete') LOG.debug(""got delete_info: %s"" % delete_info) if delete_info['type'] != 'qcow2': msg = _('Unknown delete_info type %s') % delete_info['type'] raise exception.InvalidArguments(msg) try: virt_dom = self._lookup_by_name(instance['name']) except exception.InstanceNotFound: raise exception.InstanceNotRunning(instance_id=instance['uuid']) ##### Find dev name xml = virt_dom.XMLDesc(0) xml_doc = etree.fromstring(xml) my_dev = None active_disk = None for node in xml_doc.findall('./devices/disk'): if node.find('serial') is None: continue t = node.find('target') if t is None: continue if node.findtext('serial') == volume_id: my_dev = node.find('target').get('dev') active_disk = node.find('source').get('file') break LOG.debug(""found dev, it's %s, with active disk: %s"" % (my_dev, active_disk)) ##### bdms = self._conductor_api.block_device_mapping_get_all_by_instance( context, instance) # Eliminate bdms w/o volume_id bdms = [bdm for bdm in bdms if bdm['volume_id']] this_bdm = [elem for elem in bdms if elem['volume_id'] == volume_id].pop() conn_info = jsonutils.loads(this_bdm['connection_info']) path_to_delete = 'volume-%s.%s' % (volume_id, snapshot_id) if delete_info['merge_target_file'] is None: # pull via blockRebase() # Merge the most recent snapshot into the active image rebase_disk = my_dev rebase_base = delete_info['file_to_merge'] rebase_bw = 0 rebase_flags = 0 LOG.debug('disk: %s, base: %s, bw: %s, flags: %s' % (rebase_disk, rebase_base, rebase_bw, rebase_flags)) result = virt_dom.blockRebase(rebase_disk, rebase_base, rebase_bw, rebase_flags) if result == 0: LOG.debug('blockRebase started successfully') info = virt_dom.blockJobInfo(rebase_disk) while info == 1: info = virt_dom.blockJobInfo(rebase_disk) if info == -1: msg = _('BlockJobInfo returned -1, libvirt error.') raise exception.NovaException(msg) LOG.debug('blockRebase job running... %s' % info) time.sleep(0.5) else: # commit with blockCommit() commit_disk = my_dev commit_base = delete_info['merge_target_file'] commit_top = delete_info['file_to_merge'] bandwidth = 0 flags = 0 result = virt_dom.blockCommit(commit_disk, commit_base, commit_top, bandwidth, flags) LOG.debug('result is %s' % result) if result == 0: LOG.debug('blockCommit started successfully') info = virt_dom.blockJobInfo(commit_disk) while info == 1: info = virt_dom.blockJobInfo(commit_disk) if info == -1: msg = _('BlockJobInfo returned -1, libvirt error.') raise exception.NovaException(msg) LOG.debug('blockCommit job running... %s' % info) time.sleep(0.5) # If no exceptions by this point, operation succeeded. ",,281,0
openstack%2Fneutron~master~I9d0fb648541280cacfebb47f67f608378ae66ef3,openstack/neutron,master,I9d0fb648541280cacfebb47f67f608378ae66ef3,Default to not capturing log output in tests,MERGED,2013-09-03 16:47:14.000000000,2013-09-04 01:42:13.000000000,2013-09-04 01:42:12.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1689}, {'_account_id': 2031}, {'_account_id': 2035}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 4146}]","[{'number': 1, 'created': '2013-09-03 16:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e7af8a95b6a67517410700f1e4e8d59875669c5', 'message': 'Default to not capturing log output in tests.\n\nViewing log output while tests are still running can be useful for\ndebugging, but log output was previously always captured.  This\nchange ensures that log capture is off by default, but can still\nbe enabled by setting OS_LOG_CAPTURE=1 in the shell environment.\n\ntestr invocation is unchanged and will continue to capture logs by\ndefault.\n\nChange-Id: I9d0fb648541280cacfebb47f67f608378ae66ef3\n'}, {'number': 2, 'created': '2013-09-03 17:32:41.000000000', 'files': ['.testr.conf', 'neutron/tests/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/96adb2a6c255f96e9d82c86ec37072c30aec021c', 'message': 'Default to not capturing log output in tests\n\nViewing log output while tests are still running can be useful for\ndebugging, but log output was previously always captured.  This\nchange ensures that log capture is off by default, but can still\nbe enabled by setting OS_LOG_CAPTURE=1 in the shell environment.\n\ntestr invocation is unchanged and will continue to capture logs by\ndefault.\n\nChange-Id: I9d0fb648541280cacfebb47f67f608378ae66ef3\n'}]",0,44916,96adb2a6c255f96e9d82c86ec37072c30aec021c,15,8,2,2035,,,0,"Default to not capturing log output in tests

Viewing log output while tests are still running can be useful for
debugging, but log output was previously always captured.  This
change ensures that log capture is off by default, but can still
be enabled by setting OS_LOG_CAPTURE=1 in the shell environment.

testr invocation is unchanged and will continue to capture logs by
default.

Change-Id: I9d0fb648541280cacfebb47f67f608378ae66ef3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/16/44916/1 && git format-patch -1 --stdout FETCH_HEAD,"['.testr.conf', 'neutron/tests/base.py']",2,6e7af8a95b6a67517410700f1e4e8d59875669c5,fix-log-capture," capture_logs = os.environ.get('OS_LOG_CAPTURE') in TRUE_STRING if not capture_logs: logging.basicConfig(format=LOG_FORMAT, level=_level) self.log_fixture = self.useFixture( fixtures.FakeLogger( format=LOG_FORMAT, level=_level, nuke_handlers=capture_logs, ))"," self.useFixture(fixtures.FakeLogger(format=LOG_FORMAT, level=_level))",10,2
openstack%2Fneutron~master~I4295c9bcceb38e60f813d5596af48bd8194c1c9b,openstack/neutron,master,I4295c9bcceb38e60f813d5596af48bd8194c1c9b,LBaaS integration with service type framework,MERGED,2013-07-22 08:54:06.000000000,2013-09-04 01:35:52.000000000,2013-09-04 01:35:51.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 841}, {'_account_id': 2031}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 4149}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6522}, {'_account_id': 6659}, {'_account_id': 7317}]","[{'number': 1, 'created': '2013-07-22 08:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/028d4c87ceb6f5ac35e3c5f68ae64e5c5f932f48', 'message': 'LBaaS integration with service type framework\n\nimplements blueprint lbaas-integration-with-service-types\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 2, 'created': '2013-07-22 09:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b84f3b0838dc879af60a137a4d085666bf6d3372', 'message': 'LBaaS integration with service type framework\n\nimplements blueprint lbaas-integration-with-service-types\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 3, 'created': '2013-07-22 15:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6b62a59e98638bf43b70e41d4e7979d02f813c6d', 'message': 'LBaaS integration with service type framework\n\nimplements blueprint lbaas-integration-with-service-types\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 4, 'created': '2013-07-24 13:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55d5f7bede40fcbfb34e79ca3d706d19cd3007e1', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n\nimplements blueprint lbaas-integration-with-service-types\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 5, 'created': '2013-07-29 20:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ef23d7113a1ade02d910678795f9f9c487ac2200', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n\nimplements blueprint lbaas-integration-with-service-types\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 6, 'created': '2013-07-30 08:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f7da8ac09231d00f12525310da86477075aaa64c', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n\nimplements blueprint lbaas-integration-with-service-types\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 7, 'created': '2013-07-30 10:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/90270f0df4c1c03ddda7ce23c683e6a6bea0fe1d', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n\nimplements blueprint lbaas-integration-with-service-types\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 8, 'created': '2013-08-01 10:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb2fa46a7ea665234ba15aae67d873fddea75dbe', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n\nimplements blueprint lbaas-integration-with-service-types\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 9, 'created': '2013-08-01 12:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bcc4fbabf2a66820df014aebc5421e5afe9c40fb', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds associate_provider member action for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 10, 'created': '2013-08-01 15:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca041190ac591ad8490c2d3ed6f5e2228602bb02', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds associate_provider member action for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 11, 'created': '2013-08-01 20:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff6cfe03902278d6dc0e9ea96d74e9f7d49322a7', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds associate_provider member action for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 12, 'created': '2013-08-02 10:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ef4bd196d22a542ad7980793c67e4232dc85471e', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds associate_provider member action for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 13, 'created': '2013-08-02 10:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b78fbd94f6ce467a54034d62ee2e85ed4c8571d5', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds associate_provider member action for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 14, 'created': '2013-08-05 08:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/088ce3dc547fcdfffe350f8e9e72a3b0cfdbff5f', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds associate_provider member action for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 15, 'created': '2013-08-05 11:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55cac12f37dcad8954ba64b1051ee33a3c1846c7', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds associate_provider member action for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 16, 'created': '2013-08-07 19:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/da89d7a3a709508f5f7ed7ae8dc54ff1c20713d5', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds associate_provider member action for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 17, 'created': '2013-08-14 18:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/31bf67b0c8fc1f599a102348b16df639e2aed5e1', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds associate_provider member action for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 18, 'created': '2013-08-21 13:53:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/87ac171addaa5a0c11cc299d45f34690e32a4479', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 19, 'created': '2013-08-21 13:53:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9ba93317781372168229717040ba94b81d276d0f', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 20, 'created': '2013-08-26 19:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3c2e5717cb13b1d50097af2afffa22f7a35fe83', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 22, 'created': '2013-08-28 09:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/38031b9be83bb54b16ec21369242dd0dacb3f174', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 21, 'created': '2013-08-28 09:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c4d31d4e458c34f9bf690f88d40dbf62a2de8b64', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 24, 'created': '2013-08-28 11:52:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e8640823b5ed6164848a6ed53bd394f7e92b69c', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 23, 'created': '2013-08-28 11:52:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/60a15416767473cb8635feef5cef7601fe27a6b0', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 25, 'created': '2013-08-30 05:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9b11ba7c81b43885910c0277ce0dce5b1fbd182a', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 26, 'created': '2013-08-30 06:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e6e5a1684c49a3708d702dd1c311424d7e66f804', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 27, 'created': '2013-08-30 15:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ebcbc32bfb4f3ee05035a50b3c5f206cbd2f71c9', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 28, 'created': '2013-08-31 04:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7419be77e7adf18ace2780a0fe93feaa4e9ff8ef', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 29, 'created': '2013-08-31 10:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8407d3d358fe3f63434121cc3b2ff1790731dc93', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 30, 'created': '2013-08-31 10:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5eec29312c7ca1b81dab536b4ee69cb08965e39e', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 31, 'created': '2013-09-02 22:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d0be7c9478044ebe6ce491db91b3c9e2818e99a5', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 32, 'created': '2013-09-02 22:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0cfc2c70a577b0f62856e0936730cb6df444cc08', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 33, 'created': '2013-09-03 05:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a484f68bf9922b839c11186c700ac81e6d0f4aae', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 34, 'created': '2013-09-03 09:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/37451d00622e067785bbd848e340eb7c59491076', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 35, 'created': '2013-09-03 13:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/45a7aa60a1f4fe1ea4845103a11d3985e4361984', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 36, 'created': '2013-09-03 19:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/664108c8493831a881495cc8a491e85b08437aec', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}, {'number': 37, 'created': '2013-09-03 19:29:36.000000000', 'files': ['neutron/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron/services/loadbalancer/drivers/noop/noop_driver.py', 'etc/neutron.conf', 'neutron/services/provider_configuration.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_plugin_driver.py', 'neutron/extensions/loadbalancer.py', 'neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'neutron/db/servicetype_db.py', 'neutron/services/loadbalancer/drivers/abstract_driver.py', 'neutron/services/service_base.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/88dd89b2ff68db9ce58078f0adf0bb4b5a789918', 'message': 'LBaaS integration with service type framework\n\nThe patch makes the following changes:\n\n* adds new attribute of the pool: provider, which is provider name\nas it is written in configuration\n* adds support for multiple plugin drivers for loadbalancer\n* cleans up healthmonitor-related plugin driver API\nDrivers should work with healthmonitor associations only\n* adds ability to update provider attribute for the pool used\nto reassociate pools with new providers in case their providers\nwere removed from configuration\n\nimplements blueprint lbaas-integration-with-service-types\n\nDocImpact\n\nChange-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b\n'}]",243,38120,88dd89b2ff68db9ce58078f0adf0bb4b5a789918,216,12,37,6072,,,0,"LBaaS integration with service type framework

The patch makes the following changes:

* adds new attribute of the pool: provider, which is provider name
as it is written in configuration
* adds support for multiple plugin drivers for loadbalancer
* cleans up healthmonitor-related plugin driver API
Drivers should work with healthmonitor associations only
* adds ability to update provider attribute for the pool used
to reassociate pools with new providers in case their providers
were removed from configuration

implements blueprint lbaas-integration-with-service-types

DocImpact

Change-Id: I4295c9bcceb38e60f813d5596af48bd8194c1c9b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/38120/26 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/tests/unit/test_routerserviceinsertion.py', 'neutron/db/routerservicetype_db.py', 'neutron/db/servicetype_db.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/extensions/routerservicetype.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py']",7,028d4c87ceb6f5ac35e3c5f68ae64e5c5f932f48,bp/lbaas-integration-with-service-types,"<<<<<<< HEAD======= from oslo.config import cfg >>>>>>> 05e385a... Service Type Framework refactoring def setUp(self, core_plugin=None, lb_plugin=None): service_plugins = {'lb_plugin_name': DB_LB_PLUGIN_KLASS} cfg.CONF.set_override('service_provider', [constants.LOADBALANCER + ':lbaas:' 'neutron.services.loadbalancer.' 'drivers.haproxy.plugin_driver.' 'HaproxyOnHostPluginDriver:default'], 'service_providers') super(LoadBalancerPluginDbTestCase, self).setUp( service_plugins=service_plugins ) self._subnet_id = ""0c798ed8-33ba-11e2-8b28-000c291c4d14"" config.cfg self.plugin = loadbalancer_plugin.LoadBalancerPlugin() ext_mgr = PluginAwareExtensionManager( extensions_path, {constants.LOADBALANCER: self.plugin} ) app = config.load_paste_app('extensions_test_app') self.ext_api = ExtensionMiddleware(app, ext_mgr=ext_mgr) ",,233,98
openstack%2Fcinder~master~I6ce8afae02e61321b1842ea597913e05296ec0f0,openstack/cinder,master,I6ce8afae02e61321b1842ea597913e05296ec0f0,get quota set for an invalid tenant ID return default quota set,ABANDONED,2013-08-23 11:28:36.000000000,2013-09-04 01:34:06.000000000,,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 2166}, {'_account_id': 4120}, {'_account_id': 4355}, {'_account_id': 7198}]","[{'number': 1, 'created': '2013-08-23 11:28:36.000000000', 'files': ['cinder/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f8ebd85b549aad2f24545e73fae4f143d9c8bd3e', 'message': 'get quota set for an invalid tenant ID return default quota set\n\nwhen use an invalid tenant ID to show  quota, you should get a error message, rather than default quota set.\n\nFixs Bug #1215320\n\nChange-Id: I6ce8afae02e61321b1842ea597913e05296ec0f0\n'}]",7,43438,f8ebd85b549aad2f24545e73fae4f143d9c8bd3e,10,6,1,7653,,,0,"get quota set for an invalid tenant ID return default quota set

when use an invalid tenant ID to show  quota, you should get a error message, rather than default quota set.

Fixs Bug #1215320

Change-Id: I6ce8afae02e61321b1842ea597913e05296ec0f0
",git fetch https://review.opendev.org/openstack/cinder refs/changes/38/43438/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/db/sqlalchemy/api.py'],1,f8ebd85b549aad2f24545e73fae4f143d9c8bd3e,bug/1215320, elif context.is_admin: if context.project_id != project_id: raise exception.NotAuthorized(),,3,0
openstack%2Fpython-novaclient~master~I7d9f43837860f08b9f5e841ceffa7f823807e9a4,openstack/python-novaclient,master,I7d9f43837860f08b9f5e841ceffa7f823807e9a4,Check whether the security group id is integer or UUID,ABANDONED,2013-08-30 06:58:48.000000000,2013-09-04 01:10:54.000000000,,"[{'_account_id': 3}, {'_account_id': 7653}]","[{'number': 1, 'created': '2013-08-30 06:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/e44a848cfcccc951d0b15a5fd967d665e0074128', 'message': ""Check whether the security group id is integer or UUID.\n\nNova and Neutron provide the security group, respectively.\nnova's security group id is integer, and neutron's is UUID.\n\nFixes Bug 1217242\n\nChange-Id: I7d9f43837860f08b9f5e841ceffa7f823807e9a4\n""}, {'number': 2, 'created': '2013-08-31 07:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/e918534f7e60c931937a32606a3dffb1d59c430a', 'message': ""Check whether the security group id is integer or UUID.\n\nNova and Neutron provide the security group, respectively.\nnova's security group id is integer, and neutron's is UUID.\n\nFixes Bug 1217242\n\nChange-Id: I7d9f43837860f08b9f5e841ceffa7f823807e9a4\n""}, {'number': 3, 'created': '2013-08-31 08:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/2ea06d8c85b0a11a400036cd3f101dc94abbddc4', 'message': ""Check whether the security group id is integer or UUID\n\nNova and Neutron provide the security group, respectively.\nnova's security group id is integer, and neutron's is UUID.\n\nFixes Bug 1217242\n\nChange-Id: I7d9f43837860f08b9f5e841ceffa7f823807e9a4\n""}, {'number': 4, 'created': '2013-09-01 06:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/3ee19669312e4314b37fd9ebe3abf06b48c4fffd', 'message': ""Check whether the security group id is integer or UUID\n\nNova and Neutron provide the security group, respectively.\nnova's security group id is integer, and neutron's is UUID.\n\nFixes Bug 1217242\n\nChange-Id: I7d9f43837860f08b9f5e841ceffa7f823807e9a4\n""}, {'number': 5, 'created': '2013-09-01 07:07:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/fb90cd6cf326e5ad1f9c4500c7cadc0c0f10decf', 'message': ""Check whether the security group id is integer or UUID\n\nNova and Neutron provide the security group, respectively.\nnova's security group id is integer, and neutron's is UUID.\n\nFixes Bug 1217242\n\nChange-Id: I7d9f43837860f08b9f5e841ceffa7f823807e9a4\n""}, {'number': 6, 'created': '2013-09-01 07:10:23.000000000', 'files': ['novaclient/v1_1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/3be92ba17d365ae6f7d94728e8ef329f4ab537f0', 'message': ""Check whether the security group id is integer or UUID\n\nNova and Neutron provide the security group, respectively.\nnova's security group id is integer, and neutron's is UUID.\n\nFixes Bug 1217242\n\nChange-Id: I7d9f43837860f08b9f5e841ceffa7f823807e9a4\n""}]",0,44413,3be92ba17d365ae6f7d94728e8ef329f4ab537f0,12,2,6,7653,,,0,"Check whether the security group id is integer or UUID

Nova and Neutron provide the security group, respectively.
nova's security group id is integer, and neutron's is UUID.

Fixes Bug 1217242

Change-Id: I7d9f43837860f08b9f5e841ceffa7f823807e9a4
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/13/44413/5 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v1_1/shell.py'],1,e44a848cfcccc951d0b15a5fd967d665e0074128,bug/1217242,from novaclient.openstack.common import uuidutils try: if utils.is_integer_like(strutils.safe_encode(secgroup)): elif uuidutils.is_uuid_like(strutils.safe_encode(secgroup)): return cs.security_groups.get(secgroup) except exceptions.NotFound: pass, if utils.is_integer_like(strutils.safe_encode(secgroup)): try: except exceptions.NotFound: pass,7,4
openstack%2Ftrove~master~Ied0b740e2de563f6337dbbcc3c026aad2777cc53,openstack/trove,master,Ied0b740e2de563f6337dbbcc3c026aad2777cc53,Trove - service_statuses status set to delete when instance deleted,MERGED,2013-08-16 17:26:28.000000000,2013-09-04 01:00:14.000000000,2013-09-04 01:00:14.000000000,"[{'_account_id': 3}, {'_account_id': 739}, {'_account_id': 1375}, {'_account_id': 1925}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 7796}]","[{'number': 1, 'created': '2013-08-16 17:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/bd02d4c8f147764e097320b84b743e38eeff4120', 'message': 'Trove - service_statuses status set to delete when instance deleted\n\nA Trove Instance that is created and booted successfully has a service_statuses status as running.When the instance is deleted however, the service_statuses record remains unchanged. This fix updates the status to deleted.\n\nChange-Id: Ied0b740e2de563f6337dbbcc3c026aad2777cc53\nFixes: bug #1200373\n'}, {'number': 2, 'created': '2013-08-20 21:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3abbc0a36e91dbdcb4a4f1129d3b32980b9f75b0', 'message': 'Trove - service_statuses status set to delete when instance deleted\n\nA Trove Instance that is created and booted successfully has a\nservice_statuses status as running.When the instance is deleted\nhowever, the service_statuses record remains unchanged.\nThis fix updates the status to deleted.\n\nChange-Id: Ied0b740e2de563f6337dbbcc3c026aad2777cc53\nFixes: bug #1200373\n'}, {'number': 3, 'created': '2013-08-29 21:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6025844d273c2a836c550ff3e48fbb5d47271f26', 'message': 'Trove - service_statuses status set to delete when instance deleted\n\nA Trove Instance that is created and booted successfully has a\nservice_statuses status as running.When the instance is deleted\nhowever, the service_statuses record remains unchanged.\nThis fix updates the status to deleted.\n\nChange-Id: Ied0b740e2de563f6337dbbcc3c026aad2777cc53\nFixes: bug #1200373\n'}, {'number': 4, 'created': '2013-08-29 21:11:07.000000000', 'files': ['trove/instance/models.py', 'trove/tests/api/instances.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/fc3d2f5ed7400e7839485b7e4a3066e3a150cf33', 'message': 'Trove - service_statuses status set to delete when instance deleted\n\nA Trove Instance that is created and booted successfully has a\nservice_statuses status as running.When the instance is deleted\nhowever, the service_statuses record remains unchanged.\nThis fix updates the status to deleted.\n\nChange-Id: Ied0b740e2de563f6337dbbcc3c026aad2777cc53\nFixes: bug #1200373\n'}]",0,42388,fc3d2f5ed7400e7839485b7e4a3066e3a150cf33,34,7,4,7796,,,0,"Trove - service_statuses status set to delete when instance deleted

A Trove Instance that is created and booted successfully has a
service_statuses status as running.When the instance is deleted
however, the service_statuses record remains unchanged.
This fix updates the status to deleted.

Change-Id: Ied0b740e2de563f6337dbbcc3c026aad2777cc53
Fixes: bug #1200373
",git fetch https://review.opendev.org/openstack/trove refs/changes/88/42388/3 && git format-patch -1 --stdout FETCH_HEAD,['trove/instance/models.py'],1,bd02d4c8f147764e097320b84b743e38eeff4120,bug/1200373," self.set_servicestatus_deleted() def set_servicestatus_deleted(self): del_instance = InstanceServiceStatus.find_by(instance_id=self.id) del_instance.set_status(ServiceStatuses.DELETED) del_instance.save() DELETED = ServiceStatus(0x05, 'deleted', 'DELETED')",,7,0
openstack%2Fcookbook-openstack-block-storage~master~Ic4f03d1059b75789d465bbb7db71aa89ea61b94d,openstack/cookbook-openstack-block-storage,master,Ic4f03d1059b75789d465bbb7db71aa89ea61b94d,Turning nfs default options into attributes,MERGED,2013-08-30 16:43:10.000000000,2013-09-04 00:58:45.000000000,2013-09-04 00:58:45.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 216}, {'_account_id': 7769}]","[{'number': 1, 'created': '2013-08-30 16:43:10.000000000', 'files': ['attributes/default.rb', 'templates/default/cinder.conf.erb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/828ddd1868771c71784c6afea8dd3428fd2ce2fc', 'message': 'Turning nfs default options into attributes\n\nforgot to include these two defaults as attributes in the initial\nnfs support submission.\n\nThis change allows the user to tweak nfs_disk_util and nfs_sparsed_volumes\n\nChange-Id: Ic4f03d1059b75789d465bbb7db71aa89ea61b94d\n'}]",0,44495,828ddd1868771c71784c6afea8dd3428fd2ce2fc,7,4,1,7220,,,0,"Turning nfs default options into attributes

forgot to include these two defaults as attributes in the initial
nfs support submission.

This change allows the user to tweak nfs_disk_util and nfs_sparsed_volumes

Change-Id: Ic4f03d1059b75789d465bbb7db71aa89ea61b94d
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/95/44495/1 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'templates/default/cinder.conf.erb']",2,828ddd1868771c71784c6afea8dd3428fd2ce2fc,nfs-options,"nfs_disk_util=<%= node[""openstack""][""block-storage""][""nfs""][""nfs_disk_util""] %> nfs_sparsed_volumes=<%= node[""openstack""][""block-storage""][""nfs""][""nfs_sparsed_volumes""] %>",,4,0
openstack%2Fpython-heatclient~master~Ibda19d518dd88729108102a8a9638588fb1a5ddd,openstack/python-heatclient,master,Ibda19d518dd88729108102a8a9638588fb1a5ddd,Update from global requirements,ABANDONED,2013-09-03 23:41:50.000000000,2013-09-04 00:45:08.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2013-09-03 23:41:50.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/dbf7cfa385a5f077b72d2a863f2d5c68a5539c0a', 'message': 'Update from global requirements\n\nChange-Id: Ibda19d518dd88729108102a8a9638588fb1a5ddd\n'}]",0,44983,dbf7cfa385a5f077b72d2a863f2d5c68a5539c0a,2,1,1,4571,,,0,"Update from global requirements

Change-Id: Ibda19d518dd88729108102a8a9638588fb1a5ddd
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/83/44983/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,dbf7cfa385a5f077b72d2a863f2d5c68a5539c0a,stack_update,"pyflakes>=0.7.2,<0.7.4hacking>=0.5.6,<0.8fixtures>=0.3.14 mock>=1.0testscenarios>=0.4","pyflakes==0.7.2hacking>=0.5.6,<0.7fixtures>=0.3.12 mock>=0.8.0testscenarios>=0.4,<0.5",6,6
openstack%2Fnova~master~I79e22ab6ef66fa16dc534a4336e766065702b2f5,openstack/nova,master,I79e22ab6ef66fa16dc534a4336e766065702b2f5,Add os-assisted-volume-snapshots extension,MERGED,2013-08-19 22:31:21.000000000,2013-09-04 00:35:24.000000000,2013-09-04 00:35:21.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 4523}, {'_account_id': 4912}, {'_account_id': 5292}, {'_account_id': 5511}, {'_account_id': 5754}]","[{'number': 1, 'created': '2013-08-19 22:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53f05816c33fb58129a923f26edaeaa28a2c7dbd', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is only enabled in the admin API by\ndefault.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 2, 'created': '2013-08-20 18:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6710982f30d09e7125e15d502a61cd75c8fadc1a', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is only enabled in the admin API by\ndefault.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 3, 'created': '2013-08-21 13:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0f5923b81117a495d78aaf9b9c9f2b6fda9c6ac6', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is only enabled in the admin API by\ndefault.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 4, 'created': '2013-08-21 22:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2d1a485bc54ccff48a74961b8c4d17d4e9a79bc', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is only enabled in the admin API by\ndefault.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 5, 'created': '2013-08-22 15:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f58a795ce62675ca36154fb58d682cd90bdc1c0d', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is only enabled in the admin API by\ndefault.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 6, 'created': '2013-08-22 20:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad5d6dbc977cceb766cb83f4c335b19336fa8919', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is only enabled in the admin API by\ndefault.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 7, 'created': '2013-08-23 13:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e84ddd1604aa2ab7a32e77fc719dcbf093cfdd5', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is only enabled in the admin API by\ndefault.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 8, 'created': '2013-08-26 22:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e5ae4c8063fe519452cc0a7f009a7ef0373643f', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is only enabled in the admin API by\ndefault.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 9, 'created': '2013-08-26 22:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/827772abc6feb8291840516874c471211bee9f80', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is only enabled in the admin API by\ndefault.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 10, 'created': '2013-08-28 20:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb45d0501082a380985f837ced27ce52e1d6ebac', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is only enabled in the admin API by\ndefault.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 11, 'created': '2013-08-29 16:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6103d2c97baae239388c6653cf9845fd6b1a4f39', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is only enabled in the admin API by\ndefault.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 12, 'created': '2013-08-29 23:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/18dcb70d8778caa9fd847121b7044ab32acf3e80', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is admin only by default.  We expect it to\nonly be called by Cinder.  If you have your deployment set up in such a\nway that your adminURL is different from the public, this extension can\nonly be loaded in the admin API instance.  Cinder will pull that URL out\nof the service catalog to use.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 13, 'created': '2013-09-03 06:26:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e66d35cfcae08d033525f7f71304391a35d9d24b', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is admin only by default.  We expect it to\nonly be called by Cinder.  If you have your deployment set up in such a\nway that your adminURL is different from the public, this extension can\nonly be loaded in the admin API instance.  Cinder will pull that URL out\nof the service catalog to use.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}, {'number': 14, 'created': '2013-09-03 17:18:45.000000000', 'files': ['doc/api_samples/all_extensions/extensions-get-resp.json', 'doc/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-req.json', 'doc/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-resp.json', 'etc/nova/policy.json', 'nova/tests/integrated/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-req.xml.tpl', 'nova/tests/api/openstack/compute/contrib/test_volumes.py', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.xml.tpl', 'doc/api_samples/all_extensions/extensions-get-resp.xml', 'nova/tests/api/openstack/compute/test_extensions.py', 'nova/tests/api/openstack/fakes.py', 'doc/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-req.xml', 'doc/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-resp.xml', 'nova/tests/integrated/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-req.json.tpl', 'nova/tests/integrated/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-resp.json.tpl', 'nova/tests/fake_policy.py', 'nova/tests/integrated/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-resp.xml.tpl', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.json.tpl', 'nova/tests/integrated/test_api_samples.py', 'nova/api/openstack/compute/contrib/assisted_volume_snapshots.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fa13644b058e47fda6bdd28a853cc46597c80a97', 'message': 'Add os-assisted-volume-snapshots extension\n\nAdd a new API extension that exposes assisted volume snapshot\ncapabilities.  This extension is admin only by default.  We expect it to\nonly be called by Cinder.  If you have your deployment set up in such a\nway that your adminURL is different from the public, this extension can\nonly be loaded in the admin API instance.  Cinder will pull that URL out\nof the service catalog to use.\n\nPart of blueprint qemu-assisted-snapshots\n\nChange-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5\n'}]",22,42772,fa13644b058e47fda6bdd28a853cc46597c80a97,58,11,14,1561,,,0,"Add os-assisted-volume-snapshots extension

Add a new API extension that exposes assisted volume snapshot
capabilities.  This extension is admin only by default.  We expect it to
only be called by Cinder.  If you have your deployment set up in such a
way that your adminURL is different from the public, this extension can
only be loaded in the admin API instance.  Cinder will pull that URL out
of the service catalog to use.

Part of blueprint qemu-assisted-snapshots

Change-Id: I79e22ab6ef66fa16dc534a4336e766065702b2f5
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/42772/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/test_extensions.py', 'nova/api/openstack/compute/contrib_admin/assisted_volume_snapshots.py', 'nova/api/openstack/compute/contrib/volumes.py', 'nova/tests/api/openstack/compute/contrib/test_volumes.py']",4,53f05816c33fb58129a923f26edaeaa28a2c7dbd,bp/qemu-assisted-snapshots,"def fake_compute_volume_snapshot_delete(self, context, volume_id, snapshot_id, delete_info): pass def fake_compute_volume_snapshot_create(self, context, volume_id, connection_info): pass class FakeExtMgr(object): def is_loaded(self, *args, **kwargs): return True self.controller = volumes.SnapshotController(FakeExtMgr()) self.stubs.Set(compute_api.API, 'volume_snapshot_create', fake_compute_volume_snapshot_create) def test_create_assisted(self): self.body['snapshot']['assisted'] = True self.body['snapshot']['connection_info'] = {} self.controller.create(self.req, body=self.body) class FakeExtMgr(object): def is_loaded(self, *args, **kwargs): return True self.controller = volumes.SnapshotController(FakeExtMgr()) self.stubs.Set(compute_api.API, 'volume_snapshot_delete', fake_compute_volume_snapshot_delete) def test_assisted_delete(self): self.req.method = 'POST' self.body = {'snapshot': {'volume_id': 1}} result = self.controller.create(self.req, body=self.body) params = { 'assisted': True, 'volume_id': 1, 'delete_info': {}, } self.req = fakes.HTTPRequest.blank('/v2/fake/os-snapshots?%s' % '&'.join(['%s=%s' % (k, v) for k, v in params.iteritems()])) self.req.method = 'DELETE' result = self.controller.delete(self.req, result['snapshot']['id']) self.assertEqual(result.status_int, 202)", self.controller = volumes.SnapshotController() self.controller = volumes.SnapshotController(),169,28
openstack%2Fheat~master~Ib80af7c6c9dea0e008b03f789e024bc9264e3ab4,openstack/heat,master,Ib80af7c6c9dea0e008b03f789e024bc9264e3ab4,Add support for configuring region_name.,ABANDONED,2013-06-17 21:38:10.000000000,2013-09-03 23:20:56.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 7135}]","[{'number': 1, 'created': '2013-06-17 21:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bb61f7b3b94e1877a62492c4c6f54335ba815f99', 'message': 'Add support for configuring region_name.\n\nChange-Id: Ib80af7c6c9dea0e008b03f789e024bc9264e3ab4\n'}, {'number': 2, 'created': '2013-06-18 18:21:58.000000000', 'files': ['heat/engine/clients.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/237e01439ce68acc0f22470eecb6e80556c9a6b1', 'message': 'Add support for configuring region_name.\n\nChange-Id: Ib80af7c6c9dea0e008b03f789e024bc9264e3ab4\n'}]",1,33355,237e01439ce68acc0f22470eecb6e80556c9a6b1,9,5,2,2,,,0,"Add support for configuring region_name.

Change-Id: Ib80af7c6c9dea0e008b03f789e024bc9264e3ab4
",git fetch https://review.opendev.org/openstack/heat refs/changes/55/33355/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/clients.py'],1,bb61f7b3b94e1877a62492c4c6f54335ba815f99,," cfg.StrOpt( 'cloud_backend', default=None, help=""Cloud module to use as a backend. Defaults to OpenStack.""), cfg.StrOpt( 'region', default=None, help=""Use only this region if specified."") if cfg.CONF.region is not None: args['region_name'] = cfg.CONF.region "," cfg.StrOpt('cloud_backend', default=None, help=""Cloud module to use as a backend. Defaults to OpenStack."")",11,3
openstack%2Fnova~master~If2f63e3f997733146a9f93f43a6eaa76f77db530,openstack/nova,master,If2f63e3f997733146a9f93f43a6eaa76f77db530,VMware: remove conditional suds validation,MERGED,2013-09-03 18:07:28.000000000,2013-09-03 23:18:31.000000000,2013-09-03 23:18:29.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2166}, {'_account_id': 4393}, {'_account_id': 7629}]","[{'number': 1, 'created': '2013-09-03 18:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e505e8496a491cd69c2d08f9a52ac34a0586e3f', 'message': 'VMware: remove conditional suds validation.\n\nsuds is now part of the requirements.txt file so we no longer\nneed the conditional check.\n\nFixes bug 1220344\n\nChange-Id: If2f63e3f997733146a9f93f43a6eaa76f77db530\n'}, {'number': 2, 'created': '2013-09-03 18:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59b2686d3de279c1623f56f3a19f3f5441463aaf', 'message': 'VMware: remove conditional suds validation\n\nsuds is now part of the requirements.txt file so we no longer\nneed the conditional check.\n\nFixes bug 1220344\n\nChange-Id: If2f63e3f997733146a9f93f43a6eaa76f77db530\n'}, {'number': 3, 'created': '2013-09-03 18:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98261e111ae9f077326c64464b3bc922655d4f3e', 'message': 'VMware: remove conditional suds validation.\n\nsuds is now part of the requirements.txt file so we no longer\nneed the conditional check.\n\nFixes bug 1220344\n\nChange-Id: If2f63e3f997733146a9f93f43a6eaa76f77db530\n'}, {'number': 4, 'created': '2013-09-03 19:20:31.000000000', 'files': ['nova/virt/vmwareapi/vim.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b15354bb557500653c8a3dc63bcb5e324955ec5f', 'message': 'VMware: remove conditional suds validation\n\nsuds is now part of the requirements.txt file so we no longer\nneed the conditional check.\n\nFixes bug 1220344\n\nChange-Id: If2f63e3f997733146a9f93f43a6eaa76f77db530\n'}]",0,44926,b15354bb557500653c8a3dc63bcb5e324955ec5f,19,6,4,1653,,,0,"VMware: remove conditional suds validation

suds is now part of the requirements.txt file so we no longer
need the conditional check.

Fixes bug 1220344

Change-Id: If2f63e3f997733146a9f93f43a6eaa76f77db530
",git fetch https://review.opendev.org/openstack/nova refs/changes/26/44926/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/vim.py'],1,2e505e8496a491cd69c2d08f9a52ac34a0586e3f,bug/1220344,"import sudsclass VIMMessagePlugin(suds.plugin.MessagePlugin): def addAttributeForValue(self, node): # suds does not handle AnyType properly. # VI SDK requires type attribute to be set when AnyType is used if node.name == 'value': node.set('xsi:type', 'xsd:string') def marshalled(self, context): """"""suds will send the specified soap envelope. Provides the plugin with the opportunity to prune empty nodes and fixup nodes before sending it to the server. """""" # suds builds the entire request object based on the wsdl schema. # VI SDK throws server errors if optional SOAP nodes are sent # without values, e.g. <test/> as opposed to <test>test</test> context.envelope.prune() context.envelope.walk(self.addAttributeForValue)","try: import suds except ImportError: suds = None if suds: class VIMMessagePlugin(suds.plugin.MessagePlugin): def addAttributeForValue(self, node): # suds does not handle AnyType properly. # VI SDK requires type attribute to be set when AnyType is used if node.name == 'value': node.set('xsi:type', 'xsd:string') def marshalled(self, context): """"""suds will send the specified soap envelope. Provides the plugin with the opportunity to prune empty nodes and fixup nodes before sending it to the server. """""" # suds builds the entire request object based on the wsdl schema. # VI SDK throws server errors if optional SOAP nodes are sent # without values, e.g. <test/> as opposed to <test>test</test> context.envelope.prune() context.envelope.walk(self.addAttributeForValue)",17,23
openstack%2Fheat~master~Ifd746e0ba099e4c2b9a24ab04cf635c1f557b1a5,openstack/heat,master,Ifd746e0ba099e4c2b9a24ab04cf635c1f557b1a5,fixup,ABANDONED,2013-09-03 23:09:50.000000000,2013-09-03 23:13:39.000000000,,[],"[{'number': 1, 'created': '2013-09-03 23:09:50.000000000', 'files': ['heat/tests/utils.py', 'heat/tests/test_heatclient.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/30bd335a63b16a735b9d3c95ee0937f2fae009cd', 'message': 'fixup\n\nChange-Id: Ifd746e0ba099e4c2b9a24ab04cf635c1f557b1a5\n'}]",0,44975,30bd335a63b16a735b9d3c95ee0937f2fae009cd,1,0,1,4328,,,0,"fixup

Change-Id: Ifd746e0ba099e4c2b9a24ab04cf635c1f557b1a5
",git fetch https://review.opendev.org/openstack/heat refs/changes/75/44975/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/utils.py', 'heat/tests/test_heatclient.py']",2,30bd335a63b16a735b9d3c95ee0937f2fae009cd,bp/heat-trusts3," dummy_url = 'http://_testnoexisthost_:5000/v2.0' auth_url='http://_testnoexisthost_:5000/v3', endpoint='http://_testnoexisthost_:5000/v3') auth_url='http://_testnoexisthost_:5000/v3', endpoint='http://_testnoexisthost_:5000/v3') auth_url='http://_testnoexisthost_:5000/v3',"," dummy_url = 'http://server.test:5000/v2.0' auth_url='http://server.test:5000/v3', endpoint='http://server.test:5000/v3') auth_url='http://server.test:5000/v3', endpoint='http://server.test:5000/v3') auth_url='http://server.test:5000/v3',",7,7
openstack%2Ftempest~master~I4bcdc5dfe75198f5375ae3c0efb4837dd4d2fd17,openstack/tempest,master,I4bcdc5dfe75198f5375ae3c0efb4837dd4d2fd17,Rename to test_server_cfn_init.py,ABANDONED,2013-08-30 02:12:59.000000000,2013-09-03 22:35:28.000000000,,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 5586}]","[{'number': 1, 'created': '2013-08-30 02:12:59.000000000', 'files': ['tempest/api/orchestration/stacks/test_server_cfn_init.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e245edbbbac8d5e515b0500f97466586d34dd6d', 'message': 'Rename to test_server_cfn_init.py\n\nRenamed from test_instance_cfn_init.py to better match the\nsemantics of Nova.\n\nChange-Id: I4bcdc5dfe75198f5375ae3c0efb4837dd4d2fd17\n'}]",0,44388,5e245edbbbac8d5e515b0500f97466586d34dd6d,5,3,1,4571,,,0,"Rename to test_server_cfn_init.py

Renamed from test_instance_cfn_init.py to better match the
semantics of Nova.

Change-Id: I4bcdc5dfe75198f5375ae3c0efb4837dd4d2fd17
",git fetch https://review.opendev.org/openstack/tempest refs/changes/88/44388/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/orchestration/stacks/test_server_cfn_init.py'],1,5e245edbbbac8d5e515b0500f97466586d34dd6d,bug/1187942,,,0,0
openstack%2Fopenstack-manuals~master~I7a8e5668c93f813e8b26784e6c4f005ef234bc1b,openstack/openstack-manuals,master,I7a8e5668c93f813e8b26784e6c4f005ef234bc1b,Editorial changes in Image Guide,MERGED,2013-09-03 18:35:19.000000000,2013-09-03 22:31:57.000000000,2013-09-03 22:31:56.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2013-09-03 18:35:19.000000000', 'files': ['doc/src/docbkx/openstack-image/ch_openstack_images.xml', 'doc/src/docbkx/openstack-image/ch_obtaining_images.xml', 'doc/src/docbkx/openstack-image/ch_creating_images_automatically.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/10e850f14cffb8b01c678f54e630e8f9cc9d0aa4', 'message': 'Editorial changes in Image Guide\n\nThis fixes a couple of typos and similar minor issues.\n\nChange-Id: I7a8e5668c93f813e8b26784e6c4f005ef234bc1b\n'}]",0,44931,10e850f14cffb8b01c678f54e630e8f9cc9d0aa4,5,2,1,6547,,,0,"Editorial changes in Image Guide

This fixes a couple of typos and similar minor issues.

Change-Id: I7a8e5668c93f813e8b26784e6c4f005ef234bc1b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/31/44931/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-image/ch_openstack_images.xml', 'doc/src/docbkx/openstack-image/ch_obtaining_images.xml', 'doc/src/docbkx/openstack-image/ch_creating_images_automatically.xml']",3,10e850f14cffb8b01c678f54e630e8f9cc9d0aa4,image-cleanup," It uses a predefined set of kickstart (Red Hat-based systems) and preseed files <para>A full treatment of Oz is beyond the scope of this document, but we will provide an"," It uses a predefined set of kickstart (RedHat-based systems) and preseed files <para>A full treatment of Oz is beyond the scope of this doucment, but we will provide an",8,8
