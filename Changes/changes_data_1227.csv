id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fironic-inspector~master~I8db1d5528650e24336ad87976459c57c753486a7,openstack/ironic-inspector,master,I8db1d5528650e24336ad87976459c57c753486a7,Make firewall management optional,MERGED,2014-12-19 13:15:54.000000000,2014-12-19 15:13:48.000000000,2014-12-19 15:13:46.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-19 13:15:54.000000000', 'files': ['README.rst', 'ironic_discoverd/main.py', 'ironic_discoverd/conf.py', 'ironic_discoverd/firewall.py', 'example.conf', 'functest/run.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/cb09de95001754aae40674f0d853f0d8528ec03f', 'message': 'Make firewall management optional\n\nAdds configuration option ""manage_firewall"" that allows disabling\nfirewall management completely. Handy for testing and for future\nIPA integration work.\n\nChange-Id: I8db1d5528650e24336ad87976459c57c753486a7\nCloses-Bug: #1400475\n'}]",0,143078,cb09de95001754aae40674f0d853f0d8528ec03f,7,3,1,10239,,,0,"Make firewall management optional

Adds configuration option ""manage_firewall"" that allows disabling
firewall management completely. Handy for testing and for future
IPA integration work.

Change-Id: I8db1d5528650e24336ad87976459c57c753486a7
Closes-Bug: #1400475
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/78/143078/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'ironic_discoverd/main.py', 'ironic_discoverd/conf.py', 'ironic_discoverd/firewall.py', 'example.conf', 'functest/run.py']",6,cb09de95001754aae40674f0d853f0d8528ec03f,bug/1400475,"from ironic_discoverd import confmanage_firewall = false conf.CONF.set('discoverd', 'manage_firewall', 'false') conf_file = os.path.join(d, 'test.conf') with open(conf_file, 'wb') as fp: sys.argv[1:] = [conf_file]","from ironic_discoverd import firewall# FIXME(dtantsur): remove once firewall management is optional @mock.patch.object(firewall, '_iptables', lambda *_, **__: None) conf = os.path.join(d, 'test.conf') with open(conf, 'wb') as fp: sys.argv[1:] = [conf]",24,9
openstack%2Fyaql~master~Ia0fdfbaccb479614212dbe481f1b728ba4af5cd6,openstack/yaql,master,Ia0fdfbaccb479614212dbe481f1b728ba4af5cd6,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:59:05.000000000,2014-12-19 14:59:28.000000000,2014-12-19 14:59:26.000000000,"[{'_account_id': 3}, {'_account_id': 7225}]","[{'number': 1, 'created': '2014-12-05 03:59:05.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/yaql/commit/ded7fb45ba9e4019c2a64cb10ed214f1c9ae9dff', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: Ia0fdfbaccb479614212dbe481f1b728ba4af5cd6\n'}]",0,139510,ded7fb45ba9e4019c2a64cb10ed214f1c9ae9dff,6,2,1,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: Ia0fdfbaccb479614212dbe481f1b728ba4af5cd6
",git fetch https://review.opendev.org/openstack/yaql refs/changes/10/139510/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,ded7fb45ba9e4019c2a64cb10ed214f1c9ae9dff,infra-manual,you must follow the steps in this page: http://docs.openstack.org/infra/manual/developers.html http://docs.openstack.org/infra/manual/developers.html#development-workflow,"you must follow the steps in the ""If you're a developer, start here"" section of this page: http://wiki.openstack.org/HowToContribute http://wiki.openstack.org/GerritWorkflow",3,4
openstack%2Fpython-ironicclient~master~Ibd3bb833774b1362e628725603b9b274b09375bd,openstack/python-ironicclient,master,Ibd3bb833774b1362e628725603b9b274b09375bd,Removed http proxy environment variable so that httpretty can work,MERGED,2014-12-16 14:14:40.000000000,2014-12-19 14:57:43.000000000,2014-12-19 14:57:41.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 13719}]","[{'number': 1, 'created': '2014-12-16 14:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/9b0cc95ef315a1c0f57e62ddcd5935c444969c4b', 'message': 'Removed http proxy environment variable so that httpretty can work.\n\nIf test environment is located behind a http proxy, tox and pip\nrequire to set http proxy environment variable.\nHowever httpretty mock library does NOT work as expected if http proxy\nis set.\nTherefor code to remove the http proxy environment variable is added\ninto the fixture.\n\nChange-Id: Ibd3bb833774b1362e628725603b9b274b09375bd\nCloses-Bug: #1403046\n'}, {'number': 2, 'created': '2014-12-17 01:30:43.000000000', 'files': ['ironicclient/tests/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f746e172f4a0ba1dfa381f1abafbde2cca61cc3b', 'message': 'Removed http proxy environment variable so that httpretty can work\n\nIf test environment is located behind a http proxy, tox and pip\nrequire to set http proxy environment variable.\nHowever httpretty mock library does NOT work as expected if http proxy\nis set.\nTherefor code to remove the http proxy environment variable is added\ninto the fixture.\n\nChange-Id: Ibd3bb833774b1362e628725603b9b274b09375bd\nCloses-Bug: #1403046\n'}]",2,142112,f746e172f4a0ba1dfa381f1abafbde2cca61cc3b,18,5,2,13719,,,0,"Removed http proxy environment variable so that httpretty can work

If test environment is located behind a http proxy, tox and pip
require to set http proxy environment variable.
However httpretty mock library does NOT work as expected if http proxy
is set.
Therefor code to remove the http proxy environment variable is added
into the fixture.

Change-Id: Ibd3bb833774b1362e628725603b9b274b09375bd
Closes-Bug: #1403046
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/12/142112/2 && git format-patch -1 --stdout FETCH_HEAD,['ironicclient/tests/test_shell.py'],1,9b0cc95ef315a1c0f57e62ddcd5935c444969c4b,bug/1403046,import os # httpretty doesn't work as expected if http proxy environment # variable is set. for key in os.environ.keys(): if key.lower() == 'http_proxy' or key.lower() == 'https_proxy': del os.environ[key],,6,0
openstack%2Fdevstack-gate~master~I40492ddde453ac74c56b77682d4e2a38dfd26712,openstack/devstack-gate,master,I40492ddde453ac74c56b77682d4e2a38dfd26712,Add manila and python-manilaclient to the projects list,MERGED,2014-11-13 08:56:12.000000000,2014-12-19 14:57:28.000000000,2014-12-19 14:57:26.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-11-13 08:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/6204cc83f3b78d34318c246ea077bfe3f7bb6b9c', 'message': 'Add manila and python-manilaclient to the projects list\n\nAdd manila and python-manilaclient to the projects list in\ndevstack-vm-gate-wrap.sh\n\nChange-Id: I40492ddde453ac74c56b77682d4e2a38dfd26712\n'}, {'number': 2, 'created': '2014-12-04 18:31:02.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/2e4f106a28c65a5c0216cdbf1aab96177e2912d6', 'message': 'Add manila and python-manilaclient to the projects list\n\nAdd manila and python-manilaclient to the projects list in\ndevstack-vm-gate-wrap.sh\n\nChange-Id: I40492ddde453ac74c56b77682d4e2a38dfd26712\n'}]",0,134135,2e4f106a28c65a5c0216cdbf1aab96177e2912d6,13,5,2,8851,,,0,"Add manila and python-manilaclient to the projects list

Add manila and python-manilaclient to the projects list in
devstack-vm-gate-wrap.sh

Change-Id: I40492ddde453ac74c56b77682d4e2a38dfd26712
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/35/134135/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,6204cc83f3b78d34318c246ea077bfe3f7bb6b9c,manila,"PROJECTS=""openstack/manila $PROJECTS""PROJECTS=""openstack/python-manilaclient $PROJECTS""",,2,0
openstack%2Fnova~master~I47ba78abfe60e82226acc6a17752db503d9f21d8,openstack/nova,master,I47ba78abfe60e82226acc6a17752db503d9f21d8,Fix ironic delete fails when flavor deleted,MERGED,2014-12-16 14:52:30.000000000,2014-12-19 14:47:24.000000000,2014-12-19 14:47:21.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 4573}, {'_account_id': 5170}, {'_account_id': 5805}, {'_account_id': 7166}, {'_account_id': 7461}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10343}, {'_account_id': 10385}, {'_account_id': 13362}]","[{'number': 1, 'created': '2014-12-16 14:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be6615f0666ce30c1f581568bd4cadc40a33e9f0', 'message': 'Fix ironic delete fails when flavor deleted\n\nThe ironic virt driver looks up the flavor of an instance\nwhen it is going to delete it. This is to obtain extra\nspecs details that are not available in the instance details.\nIf the flavor has been deleted this lookup fails and causes\nthe delete to fail.\n\nThe fix makes the lookup include deleted flavors. Note that\nextra specs handling is changing in nova, so this code is\nlikely to become obsolete when they are available by\nother means.\n\nChange-Id: I47ba78abfe60e82226acc6a17752db503d9f21d8\nCo-Authored-By: Nicholas Randon <nicholas.randon@hp.com>\nCo-Authored-By: Phil Day <phil.day@hp.com>\nCloses-Bug: #1400269\n'}, {'number': 2, 'created': '2014-12-17 12:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e158b9c67e34a03d61b92925e7ac704863910288', 'message': 'Fix ironic delete fails when flavor deleted\n\nThe ironic virt driver looks up the flavor of an instance\nwhen it is going to delete it. This is to obtain extra\nspecs details that are not available in the instance details.\nIf the flavor has been deleted this lookup fails and causes\nthe delete to fail.\n\nThe fix makes the lookup include deleted flavors. Note that\nextra specs handling is changing in nova, so this code is\nlikely to become obsolete when they are available by\nother means.\n\nChange-Id: I47ba78abfe60e82226acc6a17752db503d9f21d8\nCo-Authored-By: Nicholas Randon <nicholas.randon@hp.com>\nCo-Authored-By: Phil Day <phil.day@hp.com>\nCloses-Bug: #1400269\n'}, {'number': 3, 'created': '2014-12-17 16:15:38.000000000', 'files': ['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c4eab7062301b8f3b2de2358c589aee4c53074ef', 'message': 'Fix ironic delete fails when flavor deleted\n\nThe ironic virt driver looks up the flavor of an instance\nwhen it is going to delete it. This is to obtain extra\nspecs details that are not available in the instance details.\nIf the flavor has been deleted this lookup fails and causes\nthe delete to fail.\n\nThe fix makes the lookup include deleted flavors. Note that\nextra specs handling is changing in nova, so this code is\nlikely to become obsolete when they are available by\nother means.\n\nChange-Id: I47ba78abfe60e82226acc6a17752db503d9f21d8\nCo-Authored-By: Nicholas Randon <nicholas.randon@hp.com>\nCo-Authored-By: Phil Day <phil.day@hp.com>\nCloses-Bug: #1400269\n'}]",1,142123,c4eab7062301b8f3b2de2358c589aee4c53074ef,38,16,3,7461,,,0,"Fix ironic delete fails when flavor deleted

The ironic virt driver looks up the flavor of an instance
when it is going to delete it. This is to obtain extra
specs details that are not available in the instance details.
If the flavor has been deleted this lookup fails and causes
the delete to fail.

The fix makes the lookup include deleted flavors. Note that
extra specs handling is changing in nova, so this code is
likely to become obsolete when they are available by
other means.

Change-Id: I47ba78abfe60e82226acc6a17752db503d9f21d8
Co-Authored-By: Nicholas Randon <nicholas.randon@hp.com>
Co-Authored-By: Phil Day <phil.day@hp.com>
Closes-Bug: #1400269
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/142123/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/ironic/driver.py'],1,be6615f0666ce30c1f581568bd4cadc40a33e9f0,bug/1400269," # NOTE(pmurray): Flavor may have been deleted ctxt = context.elevated(read_deleted=""yes"") flavor = objects.Flavor.get_by_id(ctxt,"," flavor = objects.Flavor.get_by_id(context,",3,1
openstack%2Ffuel-plugins~master~I755b3cd318fa1caa4076ee5131888edbe997dd39,openstack/fuel-plugins,master,I755b3cd318fa1caa4076ee5131888edbe997dd39,Set 1.0.3.dev version for fpb after release,MERGED,2014-12-19 13:51:50.000000000,2014-12-19 14:30:18.000000000,2014-12-19 14:27:41.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-19 13:51:50.000000000', 'files': ['fuel_plugin_builder/CHANGELOG.md', 'fuel_plugin_builder/setup.py'], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/6d2d7cba7d5489f935fa565b1e59685156b17530', 'message': 'Set 1.0.3.dev version for fpb after release\n\nChange-Id: I755b3cd318fa1caa4076ee5131888edbe997dd39\n'}]",0,143093,6d2d7cba7d5489f935fa565b1e59685156b17530,12,6,1,8749,,,0,"Set 1.0.3.dev version for fpb after release

Change-Id: I755b3cd318fa1caa4076ee5131888edbe997dd39
",git fetch https://review.opendev.org/openstack/fuel-plugins refs/changes/93/143093/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_plugin_builder/CHANGELOG.md', 'fuel_plugin_builder/setup.py']",2,6d2d7cba7d5489f935fa565b1e59685156b17530,release," version='1.0.3.dev',"," version='1.0.2',",3,1
openstack%2Ffuel-plugins~master~I8dd0eff7c65d9131ce0786c3b04bad989e1b7c96,openstack/fuel-plugins,master,I8dd0eff7c65d9131ce0786c3b04bad989e1b7c96,Release fpb 1.0.2,MERGED,2014-12-19 13:48:58.000000000,2014-12-19 14:28:58.000000000,2014-12-19 14:27:32.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-19 13:48:58.000000000', 'files': ['fuel_plugin_builder/CHANGELOG.md', 'fuel_plugin_builder/setup.py'], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/8736b7881025d5634a46f9de96795b0126c901f0', 'message': 'Release fpb 1.0.2\n\nChange-Id: I8dd0eff7c65d9131ce0786c3b04bad989e1b7c96\n'}]",0,143091,8736b7881025d5634a46f9de96795b0126c901f0,12,6,1,8749,,,0,"Release fpb 1.0.2

Change-Id: I8dd0eff7c65d9131ce0786c3b04bad989e1b7c96
",git fetch https://review.opendev.org/openstack/fuel-plugins refs/changes/91/143091/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_plugin_builder/CHANGELOG.md', 'fuel_plugin_builder/setup.py']",2,8736b7881025d5634a46f9de96795b0126c901f0,release," version='1.0.2',"," version='1.0.2.dev',",2,2
openstack%2Frally~master~I9e63256d409978763ee3bb9bf0d896313ba6dec9,openstack/rally,master,I9e63256d409978763ee3bb9bf0d896313ba6dec9,Use Network Context in security groups scenario,MERGED,2014-12-18 10:54:17.000000000,2014-12-19 14:22:40.000000000,2014-12-19 14:22:39.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8367}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-18 10:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1a856acdddc3ecf3e62fc3d13105feae116d2ce4', 'message': 'Use Network Context in security groups scenario\n\nThis patch replaces code that creates networking resources in\nNovaSecGroup.boot_and_delete_server_with_secgroups\nwith usage of our new Network Context.\n\nChange-Id: I9e63256d409978763ee3bb9bf0d896313ba6dec9\n'}, {'number': 2, 'created': '2014-12-18 15:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b78177aae2b0f95498db56831c71f63f42591371', 'message': 'Use Network Context in security groups scenario\n\nThis patch replaces code that creates networking resources in\nNovaSecGroup.boot_and_delete_server_with_secgroups\nwith usage of our new Network Context.\n\nChange-Id: I9e63256d409978763ee3bb9bf0d896313ba6dec9\n'}, {'number': 3, 'created': '2014-12-18 15:29:24.000000000', 'files': ['rally/benchmark/scenarios/nova/security_group.py', 'tests/unit/benchmark/scenarios/nova/test_security_group.py', 'doc/samples/tasks/scenarios/nova/boot-and-delete-server-with-secgroups.json', 'doc/samples/tasks/scenarios/nova/boot-and-delete-server-with-secgroups.yaml', 'rally-jobs/rally-neutron.yaml', 'rally-jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/15b058c3cfb30f2da15a611dd3864cba6e7ae5ba', 'message': 'Use Network Context in security groups scenario\n\nThis patch replaces code that creates networking resources in\nNovaSecGroup.boot_and_delete_server_with_secgroups\nwith usage of our new Network Context.\n\nChange-Id: I9e63256d409978763ee3bb9bf0d896313ba6dec9\n'}]",0,142729,15b058c3cfb30f2da15a611dd3864cba6e7ae5ba,16,6,3,10475,,,0,"Use Network Context in security groups scenario

This patch replaces code that creates networking resources in
NovaSecGroup.boot_and_delete_server_with_secgroups
with usage of our new Network Context.

Change-Id: I9e63256d409978763ee3bb9bf0d896313ba6dec9
",git fetch https://review.opendev.org/openstack/rally refs/changes/29/142729/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/nova/security_group.py', 'tests/unit/benchmark/scenarios/nova/test_security_group.py', 'doc/samples/tasks/scenarios/nova/boot-and-delete-server-with-secgroups.json', 'doc/samples/tasks/scenarios/nova/boot-and-delete-server-with-secgroups.yaml', 'rally-jobs/rally-neutron.yaml', 'rally-jobs/rally.yaml']",6,1a856acdddc3ecf3e62fc3d13105feae116d2ce4,use-network-context-for-sec-groups," network: start_cidr: ""100.1.0.0/26""",,25,84
openstack%2Fneutron-vpnaas~master~Ia504df51510d964c5f5baccb0b921af1de406f21,openstack/neutron-vpnaas,master,Ia504df51510d964c5f5baccb0b921af1de406f21,VPNaaS: Unit tests using policy.conf,MERGED,2014-12-15 23:11:42.000000000,2014-12-19 14:21:00.000000000,2014-12-19 13:00:21.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2035}, {'_account_id': 6659}, {'_account_id': 6951}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-15 23:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/159aa0c8bd1b2c2f4ccd2b02a1b47b8ec0ce2d4a', 'message': ""VPNaaS: Unit tests using policy.conf\n\nInstead of adding override_nvalue() in setUp() for tests that need\nthe policy.json setting for config, trying to add a decorator to\nthe BaseTestCase setUp() method.\n\nThe hope here is that it'll be less brittle, in case tests are\nadded later that need the same config changes for tests.\n\nChange-Id: Ia504df51510d964c5f5baccb0b921af1de406f21\nPartially-Implements: blueprint service-split\n""}, {'number': 2, 'created': '2014-12-17 21:32:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/07d550f87da2ce1a8cdc8a90f4c0dfa27375603b', 'message': 'VPNaaS: Unit tests using policy.conf\n\nInstead of adding override_nvalue() in setUp() for tests that need\nthe policy.json setting for config, created a new base class for\nVPN tests, which derives from the neutron BaseTestCase and overrides\nthe config for policy_file.\n\nChange-Id: Ia504df51510d964c5f5baccb0b921af1de406f21\nPartially-Implements: blueprint service-split\n'}, {'number': 3, 'created': '2014-12-18 14:34:08.000000000', 'files': ['neutron_vpnaas/tests/unit/services/vpn/test_vpnaas_extension.py', 'neutron_vpnaas/tests/__init__.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_cisco_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_cisco_csr_rest.py', 'neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron_vpnaas/tests/base.py', 'neutron_vpnaas/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/test_vpn_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/c69c9904c902fe243929b8d9170ae55b0248c75f', 'message': 'VPNaaS: Unit tests using policy.conf\n\nInstead of adding override_nvalue() in setUp() for tests that need\nthe policy.json setting for config, created a new base class for\nVPN tests, which derives from the neutron BaseTestCase and overrides\nthe config for policy_file.\n\nChange-Id: Ia504df51510d964c5f5baccb0b921af1de406f21\nPartially-Implements: blueprint service-split\n'}]",3,141932,c69c9904c902fe243929b8d9170ae55b0248c75f,23,6,3,6659,,,0,"VPNaaS: Unit tests using policy.conf

Instead of adding override_nvalue() in setUp() for tests that need
the policy.json setting for config, created a new base class for
VPN tests, which derives from the neutron BaseTestCase and overrides
the config for policy_file.

Change-Id: Ia504df51510d964c5f5baccb0b921af1de406f21
Partially-Implements: blueprint service-split
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/32/141932/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/tests/unit/services/vpn/test_vpnaas_extension.py', 'neutron_vpnaas/tests/__init__.py', 'neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron_vpnaas/tests/unit/db/vpn/test_db_vpnaas.py']",4,159aa0c8bd1b2c2f4ccd2b02a1b47b8ec0ce2d4a,bp/service-split,,from neutron_vpnaas import tests tests.override_nvalues(),14,13
openstack%2Fheat~master~Ia40310007113b1111883a20db99cb7f754ae43bf,openstack/heat,master,Ia40310007113b1111883a20db99cb7f754ae43bf,Separate StackWatch out into it's own module,MERGED,2014-12-10 08:02:20.000000000,2014-12-19 14:20:54.000000000,2014-12-19 14:20:52.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}]","[{'number': 1, 'created': '2014-12-10 08:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8f8c36e77a95473dfb55b673e6d7b0c209feafc9', 'message': ""Separate StackWatch out into it's own module\n\nIn the interest in small modules that have a matching unit test file.\n\nPart of blueprint decouple-nested\nChange-Id: Ia40310007113b1111883a20db99cb7f754ae43bf\n""}, {'number': 2, 'created': '2014-12-10 10:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8a98a236c59c9486025bdaedd71e7333e364a5c9', 'message': ""Separate StackWatch out into it's own module\n\nIn the interest in small modules that have a matching unit test file.\n\nPart of blueprint decouple-nested\nChange-Id: Ia40310007113b1111883a20db99cb7f754ae43bf\n""}, {'number': 3, 'created': '2014-12-11 10:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4b1d2c12966f3209a3527d4f3a7490917feb52a3', 'message': ""Separate StackWatch out into it's own module\n\nIn the interest in small modules that have a matching unit test file.\n\nPart of blueprint decouple-nested\nChange-Id: Ia40310007113b1111883a20db99cb7f754ae43bf\n""}, {'number': 4, 'created': '2014-12-15 01:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/98d83a1beea0b6ace11ed40f7580b532b101557e', 'message': ""Separate StackWatch out into it's own module\n\nIn the interest in small modules that have a matching unit test file.\n\nPart of blueprint decouple-nested\nChange-Id: Ia40310007113b1111883a20db99cb7f754ae43bf\n""}, {'number': 5, 'created': '2014-12-17 00:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8afa14f205aae9a4d04d9caed73052c8ec88e69f', 'message': ""Separate StackWatch out into it's own module\n\nIn the interest in small modules that have a matching unit test file.\n\nPart of blueprint decouple-nested\nChange-Id: Ia40310007113b1111883a20db99cb7f754ae43bf\n""}, {'number': 6, 'created': '2014-12-19 04:59:29.000000000', 'files': ['heat/tests/test_engine_service_stack_watch.py', 'heat/tests/test_engine_service.py', 'heat/engine/service.py', 'heat/engine/service_stack_watch.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0191ce10c208c5f6453d9671eb6a3ae08b88a171', 'message': ""Separate StackWatch out into it's own module\n\nIn the interest in small modules that have a matching unit test file.\n\nPart of blueprint decouple-nested\nChange-Id: Ia40310007113b1111883a20db99cb7f754ae43bf\n""}]",6,140604,0191ce10c208c5f6453d9671eb6a3ae08b88a171,29,5,6,4715,,,0,"Separate StackWatch out into it's own module

In the interest in small modules that have a matching unit test file.

Part of blueprint decouple-nested
Change-Id: Ia40310007113b1111883a20db99cb7f754ae43bf
",git fetch https://review.opendev.org/openstack/heat refs/changes/04/140604/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service_stack_watch.py', 'heat/tests/test_engine_service.py', 'heat/engine/service.py', 'heat/engine/service_stack_watch.py']",4,8f8c36e77a95473dfb55b673e6d7b0c209feafc9,clean-commit,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo.utils import timeutils from heat.common import context from heat.common.i18n import _LE from heat.common.i18n import _LW from heat.db import api as db_api from heat.engine import stack as parser from heat.engine import watchrule from heat.openstack.common import log as logging from heat.rpc import api as rpc_api LOG = logging.getLogger(__name__) class StackWatch(object): def __init__(self, thread_group_mgr): self.thread_group_mgr = thread_group_mgr def start_watch_task(self, stack_id, cnxt): def stack_has_a_watchrule(sid): wrs = db_api.watch_rule_get_all_by_stack(cnxt, sid) now = timeutils.utcnow() start_watch_thread = False for wr in wrs: # reset the last_evaluated so we don't fire off alarms when # the engine has not been running. db_api.watch_rule_update(cnxt, wr.id, {'last_evaluated': now}) if wr.state != rpc_api.WATCH_STATE_CEILOMETER_CONTROLLED: start_watch_thread = True children = db_api.stack_get_all_by_owner_id(cnxt, sid) for child in children: if stack_has_a_watchrule(child.id): start_watch_thread = True return start_watch_thread if stack_has_a_watchrule(stack_id): self.thread_group_mgr.add_timer( stack_id, self.periodic_watcher_task, sid=stack_id) def check_stack_watches(self, sid): # Retrieve the stored credentials & create context # Require tenant_safe=False to the stack_get to defeat tenant # scoping otherwise we fail to retrieve the stack LOG.debug(""Periodic watcher task for stack %s"" % sid) admin_context = context.get_admin_context() db_stack = db_api.stack_get(admin_context, sid, tenant_safe=False, eager_load=True) if not db_stack: LOG.error(_LE(""Unable to retrieve stack %s for periodic task""), sid) return stack = parser.Stack.load(admin_context, stack=db_stack, use_stored_context=True) # recurse into any nested stacks. children = db_api.stack_get_all_by_owner_id(admin_context, sid) for child in children: self.check_stack_watches(child.id) # Get all watchrules for this stack and evaluate them try: wrs = db_api.watch_rule_get_all_by_stack(admin_context, sid) except Exception as ex: LOG.warn(_LW('periodic_task db error watch rule removed? %(ex)s'), ex) return def run_alarm_action(stack, actions, details): for action in actions: action(details=details) for res in stack.itervalues(): res.metadata_update() for wr in wrs: rule = watchrule.WatchRule.load(stack.context, watch=wr) actions = rule.evaluate() if actions: self.thread_group_mgr.start(sid, run_alarm_action, stack, actions, rule.get_details()) def periodic_watcher_task(self, sid): """""" Periodic task, created for each stack, triggers watch-rule evaluation for all rules defined for the stack sid = stack ID """""" self.check_stack_watches(sid) ",,224,156
openstack%2Fneutron-lbaas~master~Ia504df51510d964c5f5baccb0b921af1de406f21,openstack/neutron-lbaas,master,Ia504df51510d964c5f5baccb0b921af1de406f21,LBaaS: Unit tests using policy.conf,MERGED,2014-12-18 00:23:56.000000000,2014-12-19 14:20:17.000000000,2014-12-19 07:50:35.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 6951}, {'_account_id': 10980}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-12-18 00:23:56.000000000', 'files': ['neutron_lbaas/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'neutron_lbaas/tests/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_agent_manager.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/embrane/test_embrane_defaults.py', 'neutron_lbaas/tests/unit/db/loadbalancer/test_db_loadbalancer.py', 'neutron_lbaas/tests/base.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_agent.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_api.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_cfg.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/864cde91bba13ea29a4a154681423684a3dbbd31', 'message': ""LBaaS: Unit tests using policy.conf\n\nInstead of adding override_nvalue() in setUp() for tests that need\nthe policy.json setting for config, created a new base class for\nVPN tests, which derives from the neutron BaseTestCase and overrides\nthe config for policy_file. Applying same changes as done with\n141932 for VPNaaS.\n\nThe big question here, is whether or not this is better than\nsprinkling override_nvalues() calls in the four places, where this\nis a problem currently.  The issue is that with LBaaS, there are\nsome tests that inherit from Neutron classes, other than the\nBaseTestCase, so a simple override in BaseTestCase.setUp() won't\nsuffice.\n\nChange-Id: Ia504df51510d964c5f5baccb0b921af1de406f21\nPartially-Implements: blueprint service-split\n""}]",0,142619,864cde91bba13ea29a4a154681423684a3dbbd31,9,5,1,6659,,,0,"LBaaS: Unit tests using policy.conf

Instead of adding override_nvalue() in setUp() for tests that need
the policy.json setting for config, created a new base class for
VPN tests, which derives from the neutron BaseTestCase and overrides
the config for policy_file. Applying same changes as done with
141932 for VPNaaS.

The big question here, is whether or not this is better than
sprinkling override_nvalues() calls in the four places, where this
is a problem currently.  The issue is that with LBaaS, there are
some tests that inherit from Neutron classes, other than the
BaseTestCase, so a simple override in BaseTestCase.setUp() won't
suffice.

Change-Id: Ia504df51510d964c5f5baccb0b921af1de406f21
Partially-Implements: blueprint service-split
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/19/142619/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'neutron_lbaas/tests/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_agent_manager.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/embrane/test_embrane_defaults.py', 'neutron_lbaas/tests/unit/db/loadbalancer/test_db_loadbalancer.py', 'neutron_lbaas/tests/base.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_agent.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_api.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_cfg.py']",13,864cde91bba13ea29a4a154681423684a3dbbd31,bp/service-split,from neutron_lbaas.tests import base,from neutron.tests import base,75,49
openstack%2Fcinder~master~Ie4b4785b7c93246147c8d9e6a172621f454301ae,openstack/cinder,master,Ie4b4785b7c93246147c8d9e6a172621f454301ae,Symantec NFS cinder driver,MERGED,2014-08-10 20:03:08.000000000,2014-12-19 14:14:02.000000000,2014-12-16 22:40:24.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9067}, {'_account_id': 9171}, {'_account_id': 10068}, {'_account_id': 10621}, {'_account_id': 11079}, {'_account_id': 11811}, {'_account_id': 11892}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12499}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 12832}, {'_account_id': 13049}, {'_account_id': 14103}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-08-10 20:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/37d3fe066b7c5b9a3c2a65f853d052d6753c3fb5', 'message': 'Symantec NFS cinder driver\nChanges to support Symantec Storage Foundation Clustered File System High Availability via NFS Cinder driver.\n\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 2, 'created': '2014-08-11 09:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0ae878a0409a3e14d9db0fca82e5e5dfe64f31e8', 'message': 'Symantec NFS cinder driver\nChanges to support Symantec Storage Foundation Clustered File System High Availability via NFS Cinder driver.\n\nblueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 3, 'created': '2014-08-12 00:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/be3e64603bc62cd11610a16304d0f24669185eaa', 'message': 'Symantec NFS cinder driver\n\nChanges to support Symantec Storage Foundation Clustered File System High Availability via NFS Cinder driver.\n\nimplements: blueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 4, 'created': '2014-08-26 07:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/08069cb4fa11732eca269aca4bda7436e1603cf1', 'message': 'Symantec NFS cinder driver\n\nChanges to support Symantec Storage Foundation Clustered File System High Availability via NFS Cinder driver.\n\nimplements: blueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 5, 'created': '2014-08-26 23:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ea7a123c066ce7ffa4925cc90a77d4100bd2f10', 'message': 'Symantec NFS cinder driver\n\nChanges to support Symantec Storage Foundation Clustered File System High Availability via NFS Cinder driver.\n\nimplements: blueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 6, 'created': '2014-09-12 07:30:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f50346851906799fce09360eee69b486ed4e72d1', 'message': 'Symantec NFS cinder driver\n\nChanges to support Symantec Storage Foundation Clustered File System High Availability via NFS Cinder driver.\n\nimplements: blueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 7, 'created': '2014-09-12 23:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/03cf08316a3b3256a822adcf95da7c5567b63a73', 'message': 'Symantec NFS cinder driver\n\nChanges to support Symantec Storage Foundation Clustered File System High Availability via NFS Cinder driver.\n\nimplements: blueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 8, 'created': '2014-09-13 06:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/86ed4c7c7670436043c7fc4342a54860300c8b27', 'message': 'Symantec NFS cinder driver\n\nChanges to support Symantec Storage Foundation Clustered File System High Availability via NFS Cinder driver.\n\nimplements: blueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 9, 'created': '2014-12-02 00:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e68bc785367d5ce1fbfe0cfb534151b122d208a9', 'message': 'Symantec NFS cinder driver\n\nChanges to support Symantec Storage Foundation Clustered File System High Availability via NFS Cinder driver.\n\nimplements: blueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 10, 'created': '2014-12-02 07:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e90e97c838d71afde9325af663b6e5c66f44a27a', 'message': 'Symantec NFS cinder driver\n\nChanges to support Symantec Storage Foundation Clustered File System High Availability via NFS Cinder driver.\n\nimplements: blueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 11, 'created': '2014-12-03 02:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/486f057c0978c6082eb7af9b4ec19d22c63a51ff', 'message': 'Symantec NFS cinder driver\n\nChanges to support Symantec Storage Foundation Clustered File System High Availability via NFS Cinder driver.\n\nimplements: blueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 12, 'created': '2014-12-15 12:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7674adbe08d2ddc7ec95b1a772942f349727e76b', 'message': 'Symantec NFS cinder driver\n\nChanges to support Symantec Storage Foundation Clustered File\nSystem High Availability via NFS Cinder driver.\n\ncert results at:\nhttps://bugs.launchpad.net/cinder/+bug/1402147\n\nimplements: blueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}, {'number': 13, 'created': '2014-12-15 21:37:31.000000000', 'files': ['cinder/tests/test_symantec_cnfs.py', 'cinder/volume/drivers/symantec_cnfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5301e029bfd428e2734c5cc679b3c160e88124f9', 'message': 'Symantec NFS cinder driver\n\nChanges to support Symantec Storage Foundation Clustered File\nSystem High Availability via NFS Cinder driver.\n\ncert results at:\nhttps://bugs.launchpad.net/cinder/+bug/1402147\n\nimplements: blueprint symantec-nfs-cinder-driver\nChange-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae\n'}]",55,113146,5301e029bfd428e2734c5cc679b3c160e88124f9,134,32,13,11892,,,0,"Symantec NFS cinder driver

Changes to support Symantec Storage Foundation Clustered File
System High Availability via NFS Cinder driver.

cert results at:
https://bugs.launchpad.net/cinder/+bug/1402147

implements: blueprint symantec-nfs-cinder-driver
Change-Id: Ie4b4785b7c93246147c8d9e6a172621f454301ae
",git fetch https://review.opendev.org/openstack/cinder refs/changes/46/113146/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_symantec_cnfs.py', 'cinder/volume/drivers/symantec_cnfs.py']",2,37d3fe066b7c5b9a3c2a65f853d052d6753c3fb5,bp/symantec-nfs-cinder-driver,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (c) 2014 Symantec Corporation # Copyright (c) 2014 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import time from cinder import exception from cinder.openstack.common import log as logging from cinder.volume.drivers import nfs LOG = logging.getLogger(__name__) class SymantecCNFSDriver(nfs.NfsDriver): """"""Symantec Clustered NFS based cinder driver. """""" VERSION = ""1.0.0"" driver_volume_type = 'nfs' """"""Executes commands relating to Volumes."""""" def __init__(self, *args, **kwargs): LOG.debug(""SymantecNFSDriver init called"") self._execute = None self._context = None super(SymantecCNFSDriver, self).__init__(*args, **kwargs) def set_execute(self, execute): LOG.debug(""SymantecNFSDriver set_execute called"") super(SymantecCNFSDriver, self).set_execute(execute) def do_setup(self, context): LOG.debug(""SymantecNFSDriver do_setup called"") self._context = context super(SymantecCNFSDriver, self).do_setup(context) opts = self.configuration.nfs_mount_options if not opts or opts.find('vers=3') == -1 or opts.find('nfsvers=3') == -1: msg = _(""NFS is not configured to use NFSv3"") LOG.error(msg) raise exception.NfsException(msg) def check_for_setup_error(self): """"""Validate if nfs_mount_options is nfsvers=3"""""" pass def create_volume_from_snapshot(self, volume, snapshot): """"""Creates a volume from snapshot."""""" vol_name = volume['name'] snap_name = snapshot['name'] LOG.debug(""SymantecNFSDriver create_volume_from_snapshot called vol_name %r snap_name %r"", vol_name, snap_name) self._do_clone_volume(snapshot, snap_name, volume) return {'provider_location':volume['provider_location']} def _volid_to_vol(self, volid): vol = self.db.volume_get(self._context, volid) return vol def create_snapshot(self, snapshot): """"""Create a snapshot of the volume."""""" src_vol_id = snapshot['volume_id'] src_vol_name = snapshot['volume_name'] snap_name = snapshot['name'] src_vol = self._volid_to_vol(src_vol_id) self._do_clone_volume(src_vol, src_vol_name, snapshot) LOG.debug(""SymantecNFSDriver create_snapshot-1 %r"", snapshot['provider_location']) return {'provider_location': snapshot['provider_location']} def delete_snapshot(self, snapshot): """"""Delete a snapshot."""""" if not snapshot['provider_location']: LOG.warn(_('Snapshot %s does not have provider_location specified, skipping'), snapshot['name']) return self._ensure_share_mounted(snapshot['provider_location']) snap_path = self.local_path(snapshot) self._execute('rm', '-f', snap_path, run_as_root=True) def create_cloned_volume(self, volume, src_vref): """"""Create a clone of the volume."""""" self.create_volume_from_snapshot(volume, src_vref) def extend_volume(self, volume, size): """"""Extend the volume to new size"""""" path = self.local_path(volume) volname = volume['name'] self._execute('truncate', '-s', '%sG' % size, path, run_as_root=True) LOG.debug(""SymantecNFSDrivers: extend_volume vol_name %r"", volname) def _get_local_volume_path(self, provider_loc, vol_name): mnt_path = self._get_mount_point_for_share(provider_loc) vol_path = os.path.join(mnt_path, vol_name) return vol_path def _do_clone_volume(self, src_vol, src_vol_name, tgt_vol): cnfs_share = src_vol['provider_location'] tgt_vol_name = tgt_vol['name'] tgt_vol_path = self._get_local_volume_path(cnfs_share, tgt_vol_name) src_vol_path = self._get_local_volume_path(cnfs_share, src_vol_name) tgt_vol_path_spl = tgt_vol_path + ""::snap:vxfs:"" self._execute('ln', src_vol_path, tgt_vol_path_spl, run_as_root=True) LOG.debug(""SymantecNFSDrivers: do_clone_volume -1- src_vol_path %r tgt_vol_path %r tgt_vol_path_spl %r"", src_vol_path, tgt_vol_path, tgt_vol_path_spl) if not os.path.exists(tgt_vol_path): self._execute('rm', '-f', tgt_vol_path_spl, run_as_root=True) msg = _(""Filesnap over NFS is not supported, removing the ::snap:vxfs: file"") LOG.error(msg) raise exception.NfsException(msg) tgt_vol['provider_location'] = src_vol['provider_location'] def _update_volume_stats(self): LOG.debug('SymantecNFSDrivers: update_volume_status') super(SymantecCNFSDriver, self)._update_volume_stats() backend_name = self.configuration.safe_get('volume_backend_name') self._stats[""volume_backend_name""] = backend_name or 'SymantecCNFS' self._stats[""vendor_name""] = 'Symantec' self._stats[""driver_version""] = self.VERSION self._stats[""storage_protocol""] = self.driver_volume_type ",,334,0
openstack%2Fyaql~master~I6dd90114a291bbb91f87732abab1513d6132d400,openstack/yaql,master,I6dd90114a291bbb91f87732abab1513d6132d400,Enable Python 3 support,MERGED,2014-11-14 22:51:32.000000000,2014-12-19 14:12:21.000000000,2014-12-19 14:12:18.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7600}, {'_account_id': 8127}]","[{'number': 1, 'created': '2014-11-14 22:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/b36ac99494726c60380875c395fe5b0a8151c9ed', 'message': '[WIP] Enable Python 3 support\n\nPython 3 support was tested by running UT\non Python 3.4.2 on OS X.\n\nTODO:\n* fix undefined behavior in test_arithmetic\n* unskip failing (on py34) test in test_objects\n\nChange-Id: I6dd90114a291bbb91f87732abab1513d6132d400\n'}, {'number': 2, 'created': '2014-12-16 22:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/70a522218186a38677f087e9831ef687f6d81e86', 'message': 'Enable Python 3 support\n\nPython 3 support was tested by running UT\non Python 3.4.2 on OS X.\n\nChange-Id: I6dd90114a291bbb91f87732abab1513d6132d400\n'}, {'number': 3, 'created': '2014-12-19 13:21:56.000000000', 'files': ['yaql/cli/cli_functions.py', 'yaql/__init__.py', 'yaql/language/engine.py', 'yaql/tests/__init__.py', 'yaql/functions/system.py', 'yaql/language/parser.py', 'yaql/tests/test_boolean.py', 'yaql/tests/test_objects.py', 'yaql/tests/test_containers.py', 'yaql/tests/test_system.py', 'requirements.txt', 'yaql/language/utils.py', 'yaql/tests/test_arithmetic.py', 'yaql/tests/test_execution_chains.py', 'yaql/functions/containers.py', 'yaql/functions/strings.py', 'yaql/language/context.py', 'yaql/functions/boolean.py', 'yaql/functions/arithmetic.py'], 'web_link': 'https://opendev.org/openstack/yaql/commit/89cc63f7371204c4b407879d838cc413d3184343', 'message': 'Enable Python 3 support\n\nChange-Id: I6dd90114a291bbb91f87732abab1513d6132d400\n'}]",0,134665,89cc63f7371204c4b407879d838cc413d3184343,17,5,3,7600,,,0,"Enable Python 3 support

Change-Id: I6dd90114a291bbb91f87732abab1513d6132d400
",git fetch https://review.opendev.org/openstack/yaql refs/changes/65/134665/1 && git format-patch -1 --stdout FETCH_HEAD,"['yaql/cli/cli_functions.py', 'yaql/__init__.py', 'yaql/language/engine.py', 'yaql/tests/__init__.py', 'yaql/functions/system.py', 'yaql/language/parser.py', 'yaql/tests/test_boolean.py', 'yaql/tests/test_objects.py', 'yaql/tests/test_containers.py', 'yaql/tests/test_system.py', 'yaql/language/utils.py', 'yaql/tests/test_arithmetic.py', 'yaql/tests/test_execution_chains.py', 'yaql/functions/containers.py', 'yaql/functions/strings.py', 'yaql/language/context.py', 'yaql/functions/boolean.py', 'yaql/functions/arithmetic.py']",18,b36ac99494726c60380875c395fe5b0a8151c9ed,py34,"import six return isinstance(value, six.integer_types + (float, complex))"," return isinstance(value, (int, long, float, complex))",66,60
openstack%2Fironic-specs~master~I96f029183c7f5648f251003059ae7a07278a7b29,openstack/ironic-specs,master,I96f029183c7f5648f251003059ae7a07278a7b29,Root device hints,MERGED,2014-12-03 14:01:37.000000000,2014-12-19 14:10:35.000000000,2014-12-19 14:10:33.000000000,"[{'_account_id': 3}, {'_account_id': 114}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 7623}, {'_account_id': 9315}, {'_account_id': 10202}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 13362}]","[{'number': 1, 'created': '2014-12-03 14:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/dcbb78fbed576175b2ac917292e2568c7fa15d85', 'message': 'Root device hints\n\nAllow passing hints to Ironic to decide which device should be selected\nfor the deployment.\n\nChange-Id: I96f029183c7f5648f251003059ae7a07278a7b29\n'}, {'number': 2, 'created': '2014-12-03 14:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/90b0a8ed7240d4ad7d39f183a128aaaadf00d9f3', 'message': 'Root device hints\n\nAllow passing hints to Ironic to decide which device should be selected\nfor the deployment.\n\nChange-Id: I96f029183c7f5648f251003059ae7a07278a7b29\n'}, {'number': 3, 'created': '2014-12-03 15:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/5a6e0ddd060b4c1380a50d8432657294c844aed3', 'message': 'Root device hints\n\nAllow passing hints to Ironic to decide which device should be selected\nfor the deployment.\n\nChange-Id: I96f029183c7f5648f251003059ae7a07278a7b29\n'}, {'number': 4, 'created': '2014-12-04 11:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/7b18f7b9656a6357545a8d28273a874da5ade8bd', 'message': 'Root device hints\n\nAllow passing hints to Ironic to decide which device should be selected\nfor the deployment.\n\nChange-Id: I96f029183c7f5648f251003059ae7a07278a7b29\n'}, {'number': 5, 'created': '2014-12-04 12:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/9addb8197d284a5ca2e80fc10b2663f62688517e', 'message': 'Root device hints\n\nAllow passing hints to Ironic to decide which device should be selected\nfor the deployment.\n\nChange-Id: I96f029183c7f5648f251003059ae7a07278a7b29\n'}, {'number': 6, 'created': '2014-12-05 15:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/a5f06615a67b8f3eed7b82722d3e8a623ec83cef', 'message': 'Root device hints\n\nAllow passing hints to Ironic to decide which device should be selected\nfor the deployment.\n\nChange-Id: I96f029183c7f5648f251003059ae7a07278a7b29\n'}, {'number': 7, 'created': '2014-12-17 11:14:25.000000000', 'files': ['specs/kilo/root-device-hints.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/1b5c482fd83b81038430d92ac7d740c773533c5d', 'message': 'Root device hints\n\nAllow passing hints to Ironic to decide which device should be selected\nfor the deployment.\n\nChange-Id: I96f029183c7f5648f251003059ae7a07278a7b29\n'}]",49,138729,1b5c482fd83b81038430d92ac7d740c773533c5d,44,10,7,6773,,,0,"Root device hints

Allow passing hints to Ironic to decide which device should be selected
for the deployment.

Change-Id: I96f029183c7f5648f251003059ae7a07278a7b29
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/29/138729/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/root-device-hints.rst'],1,dcbb78fbed576175b2ac917292e2568c7fa15d85,bp/root-device-hints,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================= Root device hints ================= https://blueprints.launchpad.net/ironic/+spec/root-device-hints Allow passing hints to Ironic to decide which device should be selected for the deployment. Problem description =================== When the deploy ramdisk boots Ironic picks the first disk it finds to be the root device (the device where the image will be put on). If the server has more than one SATA, SCSI or IDE disk controller, the order in which their corresponding device nodes are added is arbitrary[1]_[2]_. This may result in devices like /dev/sda and /dev/sdb switching around on each boot and Ironic picking different disk every time the machine is being deployed. .. _[1]: https://wiki.archlinux.org/index.php/persistent_block_device_naming .. _[2]: https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/5/html/Online_Storage_Reconfiguration_Guide/persistent_naming.html Proposed change =============== The change proposed by this blueprint is to give operators a mean via the Ironic API to pass some hints about what disk should be pick in deploy time. That way Ironic can always pick the right disk to write the image on. Also, with the addition of Ironic being able to create RAID arrays, it would be nice to be able to tell Ironic to use the device that was just created to be the root device for the deployment. This spec is proposing having a limited number of hints that could be passed as part of the initial work, but could be extended later on. The initial proposed hint list is: * uuid (STRING): device UUID * model (STRING): device identifier * serial (STRING): disk serial number * wwn (STRING): unique storage identifier * hctl (STRING): Host:Channel:Target:Lun for SCSI The hints should live in the `properties` attribute of the Node resource, the key would be `root_device` and the value a dictionary so operators could combine one or more hints. For example:: node.properties['root_device'] = {'wwn': '0x4000cca77fc4dba1'} Or:: node.properties['root_device'] = {'phy_sec': 4096, 'rota': True} If the hints are not specified Ironic will continue to pick the first disk it finds. If specified Ironic will try to find the right disk to deploy the image onto, if the disk is not found the deployment will be aborted. The default deploy ramdisk and IPA needs to be changed to support filtering the disks based on the hints, if specified. Alternatives ------------ We could recommend operators to avoid having multiple storage devices on the machines being managed by Ironic. Data model impact ----------------- None REST API impact --------------- As we want to use a dictionary as a value on the `properties` attribute the `bug 1398350`_ needs to be fixed. RPC API impact -------------- None Driver API impact ----------------- None Nova driver impact ------------------ None Security impact --------------- None Other end user impact --------------------- None Scalability impact ------------------ None Performance Impact ------------------ None Other deployer impact --------------------- Deployers will have a finer granularity in selecting the disk device to be used for the deployment. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: lucasagomes Other contributors: <launchpad-id or None> Work Items ---------- * Make Ironic check for hints in the node.properties * Pass the hint information to the deploy ramdisk and IPA * Add tests and documentation * Modify the default deploy ramdisk in `diskimage-builder`_ to consider the hints when picking the disk device * Modify IPA_ to consider the hints when picking the disk device Dependencies ============ * `bug 1398350`_ needs to be fixed. Testing ======= * Unit tests will be added Upgrades and Backwards Compatibility ==================================== The change is backwards compatible since if hints are not specified Ironic will continue to do what it does today (pick the first disk it found for the deployment). Documentation Impact ==================== A document explaining how hints works and what are the options and values supported is going to be added. References ========== None .. _`bug 1398350`: https://bugs.launchpad.net/ironic/+bug/1398350 .. _`diskimage-builder`: https://github.com/openstack/diskimage-builder/tree/master/elements/deploy-ironic .. _IPA: https://github.com/openstack/ironic-python-agent ",,190,0
openstack%2Fheat~master~If5a9d6b1c9dd98b31966312af16587cd148b9c6b,openstack/heat,master,If5a9d6b1c9dd98b31966312af16587cd148b9c6b,Remove duplicate test (it's already in our functional tests),MERGED,2014-12-10 08:02:20.000000000,2014-12-19 14:10:24.000000000,2014-12-19 14:10:23.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-10 08:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f6d6bcc6dc962d259d080d081281d21d32a2406e', 'message': ""Remove duplicate test (it's already in our functional tests)\n\nThis test duplicates what is here:\nhttps://github.com/openstack/heat/blob/master/heat_integrationtests/functional/test_update.py#L89-L133\n\nBut does not require a full nested stack in unit tests.\n\nPart of blueprint decouple-nested\n\nChange-Id: If5a9d6b1c9dd98b31966312af16587cd148b9c6b\n""}, {'number': 2, 'created': '2014-12-10 10:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/69b17d0baf4cd232e98af68e7a2f021286671298', 'message': ""Remove duplicate test (it's already in our functional tests)\n\nThis test duplicates what is here:\nhttps://github.com/openstack/heat/blob/master/heat_integrationtests/functional/test_update.py#L89-L133\n\nBut does not require a full nested stack in unit tests.\n\nPart of blueprint decouple-nested\n\nChange-Id: If5a9d6b1c9dd98b31966312af16587cd148b9c6b\n""}, {'number': 3, 'created': '2014-12-11 10:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dacaab51391a10abad49c0c32e6b82119aee7e8d', 'message': ""Remove duplicate test (it's already in our functional tests)\n\nThis test duplicates what is here:\nhttps://github.com/openstack/heat/blob/master/heat_integrationtests/functional/test_update.py#L89-L133\n\nBut does not require a full nested stack in unit tests.\n\nPart of blueprint decouple-nested\n\nChange-Id: If5a9d6b1c9dd98b31966312af16587cd148b9c6b\n""}, {'number': 4, 'created': '2014-12-15 01:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d5f72a28040a2df19b02c6aa26eef1ec85e1e2d9', 'message': ""Remove duplicate test (it's already in our functional tests)\n\nThis test duplicates what is here:\nhttps://github.com/openstack/heat/blob/master/heat_integrationtests/functional/test_update.py#L89-L133\n\nBut does not require a full nested stack in unit tests.\n\nPart of blueprint decouple-nested\n\nChange-Id: If5a9d6b1c9dd98b31966312af16587cd148b9c6b\n""}, {'number': 5, 'created': '2014-12-17 00:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b7b351938e2bb749fc1381fa13206aaf18d681f9', 'message': ""Remove duplicate test (it's already in our functional tests)\n\nThis test duplicates what is here:\nhttps://github.com/openstack/heat/blob/master/heat_integrationtests/functional/test_update.py#L89-L133\n\nBut does not require a full nested stack in unit tests.\n\nPart of blueprint decouple-nested\n\nChange-Id: If5a9d6b1c9dd98b31966312af16587cd148b9c6b\n""}, {'number': 6, 'created': '2014-12-19 04:59:29.000000000', 'files': ['heat/tests/test_engine_service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9f736de7576ca10e6c00c92de2a77312b9e306f3', 'message': ""Remove duplicate test (it's already in our functional tests)\n\nThis test duplicates what is here:\nhttps://github.com/openstack/heat/blob/master/heat_integrationtests/functional/test_update.py#L89-L133\n\nBut does not require a full nested stack in unit tests.\n\nPart of blueprint decouple-nested\n\nChange-Id: If5a9d6b1c9dd98b31966312af16587cd148b9c6b\n""}]",0,140603,9f736de7576ca10e6c00c92de2a77312b9e306f3,25,5,6,4715,,,0,"Remove duplicate test (it's already in our functional tests)

This test duplicates what is here:
https://github.com/openstack/heat/blob/master/heat_integrationtests/functional/test_update.py#L89-L133

But does not require a full nested stack in unit tests.

Part of blueprint decouple-nested

Change-Id: If5a9d6b1c9dd98b31966312af16587cd148b9c6b
",git fetch https://review.opendev.org/openstack/heat refs/changes/03/140603/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_engine_service.py'],1,f6d6bcc6dc962d259d080d081281d21d32a2406e,clean-commit,," def test_nested_stack_update_stack_id_equal(self): stack_name = 'test_stack_update_stack_id_equal' res._register_class('ResourceWithPropsType', generic_rsrc.ResourceWithProps) tpl = { 'HeatTemplateFormatVersion': '2012-12-12', 'Parameters': { 'some_param': {'Type': 'String'} }, 'Resources': { 'nested': { 'Type': 'AWS::CloudFormation::Stack', 'Properties': { 'TemplateURL': 'https://server.test/nested_tpl', 'Parameters': {'some_param': {'Ref': 'some_param'}} } } } } nested_tpl = { 'HeatTemplateFormatVersion': '2012-12-12', 'Parameters': { 'some_param': {'Type': 'String'} }, 'Resources': { 'A': { 'Type': 'ResourceWithPropsType', 'Properties': { 'Foo': {'Ref': 'AWS::StackId'} } } } } self.m.StubOutWithMock(urlfetch, 'get') urlfetch.get('https://server.test/nested_tpl').MultipleTimes().\ AndReturn(json.dumps(nested_tpl)) mox.Replay(urlfetch.get) template = templatem.Template(tpl) create_env = environment.Environment({'some_param': 'foo'}) create_stack = parser.Stack(self.ctx, stack_name, template, create_env) sid = create_stack.store() create_stack.create() self.assertEqual((create_stack.CREATE, create_stack.COMPLETE), create_stack.state) s = db_api.stack_get(self.ctx, sid) old_stack = parser.Stack.load(self.ctx, stack=s) self.assertEqual((old_stack.CREATE, old_stack.COMPLETE), old_stack.state) old_nested = old_stack['nested'].nested() self.m.StubOutWithMock(parser.Stack, 'load') parser.Stack.load(self.ctx, stack=s).AndReturn(old_stack) self.m.ReplayAll() result = self.man.update_stack(self.ctx, create_stack.identifier(), tpl, {'some_param': 'bar'}, None, {}) self.man.thread_group_mgr.groups[sid].wait() create_nested = create_stack['nested'].nested() self.assertEqual((old_nested.UPDATE, old_nested.COMPLETE), old_nested.state) self.assertEqual(create_stack.identifier(), result) self.assertIsNotNone(create_stack.identifier().stack_id) self.assertEqual(create_nested.identifier().arn(), old_nested['A'].properties['Foo']) self.assertEqual(create_nested['A'].id, old_nested['A'].id) self.m.VerifyAll() ",0,80
openstack%2Fheat~master~I764fedd4371a7a641df98a923b7616df6498c944,openstack/heat,master,I764fedd4371a7a641df98a923b7616df6498c944,Add some autoscaling crud unit tests,MERGED,2014-12-10 08:02:20.000000000,2014-12-19 14:10:14.000000000,2014-12-19 14:10:13.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6577}]","[{'number': 1, 'created': '2014-12-10 08:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/90107e03164063e18300c5d27f456847ccd0a9a3', 'message': 'Add some autoscaling crud unit tests\n\nThese are basic to get some coverage.\n\nPart of blueprint decouple-nested\nChange-Id: I764fedd4371a7a641df98a923b7616df6498c944\n'}, {'number': 2, 'created': '2014-12-10 10:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3d9c7223fbcf4c687ab551fbca0ddda37cfdb1e7', 'message': 'Add some autoscaling crud unit tests\n\nThese are basic to get some coverage.\n\nPart of blueprint decouple-nested\nChange-Id: I764fedd4371a7a641df98a923b7616df6498c944\n'}, {'number': 3, 'created': '2014-12-11 10:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b62cd9ad4daa2269cabd13928a9e3e9c012cb6f0', 'message': 'Add some autoscaling crud unit tests\n\nThese are basic to get some coverage.\n\nPart of blueprint decouple-nested\nChange-Id: I764fedd4371a7a641df98a923b7616df6498c944\n'}, {'number': 4, 'created': '2014-12-15 01:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8f3600f54914f355dc74edde628d015a880eb8f7', 'message': 'Add some autoscaling crud unit tests\n\nThese are basic to get some coverage.\n\nPart of blueprint decouple-nested\nChange-Id: I764fedd4371a7a641df98a923b7616df6498c944\n'}, {'number': 5, 'created': '2014-12-17 00:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/90dfc1e937b794d2bd87d21b6d9816647bedb6c9', 'message': 'Add some autoscaling crud unit tests\n\nThese are basic to get some coverage.\n\nPart of blueprint decouple-nested\nChange-Id: I764fedd4371a7a641df98a923b7616df6498c944\n'}, {'number': 6, 'created': '2014-12-19 04:59:29.000000000', 'files': ['heat/tests/autoscaling/test_scaling_group.py', 'heat/tests/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d967475eae3fc5c81d454ad95d7369510c065375', 'message': 'Add some autoscaling crud unit tests\n\nThese are basic to get some coverage.\n\nPart of blueprint decouple-nested\nChange-Id: I764fedd4371a7a641df98a923b7616df6498c944\n'}]",1,140602,d967475eae3fc5c81d454ad95d7369510c065375,23,3,6,4715,,,0,"Add some autoscaling crud unit tests

These are basic to get some coverage.

Part of blueprint decouple-nested
Change-Id: I764fedd4371a7a641df98a923b7616df6498c944
",git fetch https://review.opendev.org/openstack/heat refs/changes/02/140602/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/autoscaling/test_scaling_group.py', 'heat/tests/test_instance_group.py']",2,90107e03164063e18300c5d27f456847ccd0a9a3,clean-commit," def test_handle_create(self): self.instance_group.create_with_template = mock.Mock(return_value=None) self.instance_group.validate_launchconfig = mock.Mock( return_value=None) self.instance_group._create_template = mock.Mock(return_value='{}') self.instance_group.handle_create() expect_env = {'parameters': {}, 'resource_registry': { 'OS::Heat::ScaledResource': 'AWS::EC2::Instance'}} self.instance_group.validate_launchconfig.assert_called_once_with() self.instance_group._create_template.assert_called_once_with(2) self.instance_group.create_with_template.assert_called_once_with( '{}', expect_env) def test_handle_update_size(self): self.instance_group._try_rolling_update = mock.Mock(return_value=None) self.instance_group.resize = mock.Mock(return_value=None) get_size = self.patchobject(grouputils, 'get_size') get_size.return_value = 2 props = {'Size': 5} defn = rsrc_defn.ResourceDefinition( 'nopayload', 'AWS::AutoScaling::AutoScalingGroup', props) self.instance_group.handle_update(defn, None, props) self.instance_group.resize.assert_called_once_with(5) ",,95,0
openstack%2Fheat~master~I33a9772642c6e58b4b9419330d2aa4e3f8e5cab4,openstack/heat,master,I33a9772642c6e58b4b9419330d2aa4e3f8e5cab4,Move instance_error_causes_group_error() to functional tests,MERGED,2014-12-09 06:16:28.000000000,2014-12-19 14:09:15.000000000,2014-12-19 14:09:13.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-09 06:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4f4f07a8244ac0dc247c084635961173eb52d736', 'message': 'Delete test instance error causes group error test\n\nWhy?\nThis purely tests that rollback is disabled and that\nis the case for all nested stacks.\n\nChange-Id: I33a9772642c6e58b4b9419330d2aa4e3f8e5cab4\n'}, {'number': 2, 'created': '2014-12-10 08:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/24c4c7b55fdf70878148bcf8368e494261d9a61c', 'message': 'Delete test instance error causes group error test\n\nWhy?\nThis purely tests that rollback is disabled and that\nis the case for all nested stacks.\n\nPart of blueprint decouple-nested\nChange-Id: I33a9772642c6e58b4b9419330d2aa4e3f8e5cab4\n'}, {'number': 3, 'created': '2014-12-10 10:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/883e8c1272a403ae00ea476ceeeed9b18fb291cc', 'message': 'Delete test instance error causes group error test\n\nWhy?\nThis purely tests that rollback is disabled and that\nis the case for all nested stacks.\n\nPart of blueprint decouple-nested\nChange-Id: I33a9772642c6e58b4b9419330d2aa4e3f8e5cab4\n'}, {'number': 4, 'created': '2014-12-11 10:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/60f1053b7bfe4dbe73d3b9e55fd7c89d70083391', 'message': 'Move instance_error_causes_group_error() to functional tests\n\nPart of blueprint decouple-nested\nChange-Id: I33a9772642c6e58b4b9419330d2aa4e3f8e5cab4\n'}, {'number': 5, 'created': '2014-12-15 01:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/49b4e32da044d67bb3c40c58a029d2b9031c0b39', 'message': 'Move instance_error_causes_group_error() to functional tests\n\nPart of blueprint decouple-nested\nChange-Id: I33a9772642c6e58b4b9419330d2aa4e3f8e5cab4\n'}, {'number': 6, 'created': '2014-12-17 00:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/36c253271adcb923e3d4b72c05cfb0186542ed41', 'message': 'Move instance_error_causes_group_error() to functional tests\n\nPart of blueprint decouple-nested\nChange-Id: I33a9772642c6e58b4b9419330d2aa4e3f8e5cab4\n'}, {'number': 7, 'created': '2014-12-19 04:59:29.000000000', 'files': ['heat_integrationtests/functional/test_instance_group.py', 'heat/tests/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9d64e80586ec8ffefe2efd9c32d7c81064d09645', 'message': 'Move instance_error_causes_group_error() to functional tests\n\nPart of blueprint decouple-nested\nChange-Id: I33a9772642c6e58b4b9419330d2aa4e3f8e5cab4\n'}]",10,140245,9d64e80586ec8ffefe2efd9c32d7c81064d09645,41,7,7,4715,,,0,"Move instance_error_causes_group_error() to functional tests

Part of blueprint decouple-nested
Change-Id: I33a9772642c6e58b4b9419330d2aa4e3f8e5cab4
",git fetch https://review.opendev.org/openstack/heat refs/changes/45/140245/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_instance_group.py'],1,4f4f07a8244ac0dc247c084635961173eb52d736,clean-commit,," def test_create_instance_error_causes_group_error(self): """""" If a resource in an instance group fails to be created, the instance group itself will fail and the broken inner resource will remain. """""" t = template_format.parse(ig_template) stack = utils.parse_stack(t) self.m.StubOutWithMock(parser.Stack, 'validate') parser.Stack.validate() self.stub_ImageConstraint_validate() self.stub_KeypairConstraint_validate() self.stub_FlavorConstraint_validate() self.stub_SnapshotConstraint_validate() self.m.StubOutWithMock(instance.Instance, 'handle_create') instance.Instance.handle_create().AndRaise(Exception) self.m.ReplayAll() self.create_resource(t, stack, 'JobServerConfig') self.assertRaises( exception.ResourceFailure, self.create_resource, t, stack, 'JobServerGroup') rsrc = stack['JobServerGroup'] self.assertEqual((rsrc.CREATE, rsrc.FAILED), rsrc.state) # The failed inner resource remains self.assertEqual(1, len(rsrc.nested().resources)) child_resource = rsrc.nested().resources.values()[0] self.assertEqual((child_resource.CREATE, child_resource.FAILED), child_resource.state) self.m.VerifyAll() def test_update_instance_error_causes_group_error(self): """""" If a resource in an instance group fails to be created during an update, the instance group itself will fail and the broken inner resource will remain. """""" t = template_format.parse(ig_template) stack = utils.parse_stack(t) self._stub_create(1) self.m.ReplayAll() self.create_resource(t, stack, 'JobServerConfig') rsrc = self.create_resource(t, stack, 'JobServerGroup') self.assertEqual(1, len(rsrc.nested().resources)) succeeded_instance = rsrc.nested().resources.values()[0] self.m.VerifyAll() self.m.UnsetStubs() self.m.StubOutWithMock(parser.Stack, 'validate') parser.Stack.validate() self.stub_ImageConstraint_validate() self.stub_KeypairConstraint_validate() self.stub_FlavorConstraint_validate() self.stub_SnapshotConstraint_validate() self.m.StubOutWithMock(instance.Instance, 'handle_create') instance.Instance.handle_create().AndRaise(Exception) self.m.ReplayAll() props = copy.copy(rsrc.properties.data) props['Size'] = '2' update_snippet = rsrc_defn.ResourceDefinition(rsrc.name, rsrc.type(), props) updater = scheduler.TaskRunner(rsrc.update, update_snippet) self.assertRaises(exception.ResourceFailure, updater) self.assertEqual((rsrc.UPDATE, rsrc.FAILED), rsrc.state) # The failed inner resource remains self.assertEqual(2, len(rsrc.nested().resources)) child_resource = [r for r in rsrc.nested().resources.values() if r.name != succeeded_instance.name][0] self.assertEqual((child_resource.CREATE, child_resource.FAILED), child_resource.state) self.m.VerifyAll() ",0,85
openstack%2Fneutron-specs~master~Ibfb7f44b458a91244dea6d52e2564a3660debdf5,openstack/neutron-specs,master,Ibfb7f44b458a91244dea6d52e2564a3660debdf5,Add IPv6 prefix delegation support in Neutron,MERGED,2014-05-09 15:03:19.000000000,2014-12-19 14:08:51.000000000,2014-12-19 14:08:49.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2592}, {'_account_id': 3217}, {'_account_id': 4656}, {'_account_id': 6524}, {'_account_id': 6620}, {'_account_id': 6635}, {'_account_id': 6685}, {'_account_id': 6695}, {'_account_id': 7183}, {'_account_id': 7448}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 10257}, {'_account_id': 13409}]","[{'number': 1, 'created': '2014-05-09 15:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/eb19b4035464e185b41f6be2ae9f61c9ca02d88e', 'message': 'Add IPv6 prefix delegation support in Neutron\n\nblueprint ipv6-prefix-delegation\n\nChange-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5\n'}, {'number': 2, 'created': '2014-05-09 15:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/49e7a1a47b349ce724bf21e156f077aa4ae96efc', 'message': 'Add IPv6 prefix delegation support in Neutron\n\nblueprint ipv6-prefix-delegation\n\nChange-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5\n'}, {'number': 3, 'created': '2014-12-07 04:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c0724af4a22679aa7e89ee315aaf5e635b85cf34', 'message': 'Add IPv6 prefix delegation support in Neutron\n\nblueprint ipv6-prefix-delegation\n\nChange-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5\n'}, {'number': 4, 'created': '2014-12-07 05:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e12cecefb4f4321e8d9ee4aac83652478f5874e6', 'message': 'Add IPv6 prefix delegation support in Neutron\n\nblueprint ipv6-prefix-delegation\n\nChange-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5\n'}, {'number': 5, 'created': '2014-12-07 12:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9c0b69edf76c2ee991c7f25e383aa2ce647e5d25', 'message': 'Add IPv6 prefix delegation support in Neutron\n\nblueprint ipv6-prefix-delegation\n\nChange-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5\n'}, {'number': 6, 'created': '2014-12-08 21:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/167f299936cc1c015d48f7e217374a6d5dde57b2', 'message': 'Add IPv6 prefix delegation support in Neutron\n\nblueprint ipv6-prefix-delegation\n\nChange-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5\n'}, {'number': 7, 'created': '2014-12-08 22:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/fafab49780dc04c16889360127cee57c37e5eb86', 'message': 'Add IPv6 prefix delegation support in Neutron\n\nblueprint ipv6-prefix-delegation\n\nCo-Authored-By: John Davidge <jodavidg@cisco.com>\nCo-Authored-By: Dane LeBlanc <leblancd@cisco.com>\n\nChange-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5\n'}, {'number': 8, 'created': '2014-12-11 20:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/84232bed9ff3211cdd60715a8abf9072336baaaa', 'message': 'Add IPv6 prefix delegation support in Neutron\n\nblueprint ipv6-prefix-delegation\n\nCo-Authored-By: John Davidge <jodavidg@cisco.com>\nCo-Authored-By: Dane LeBlanc <leblancd@cisco.com>\n\nChange-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5\n'}, {'number': 9, 'created': '2014-12-19 00:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f42d34ded1d1499fd94f709dca1ccdfa9e96a57a', 'message': 'Add IPv6 prefix delegation support in Neutron\n\nblueprint ipv6-prefix-delegation\n\nCo-Authored-By: John Davidge <jodavidg@cisco.com>\nCo-Authored-By: Dane LeBlanc <leblancd@cisco.com>\n\nChange-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5\n'}, {'number': 10, 'created': '2014-12-19 00:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3ca131a71308f635742bcfac4e8a8c84f950ffa2', 'message': 'Add IPv6 prefix delegation support in Neutron\n\nblueprint ipv6-prefix-delegation\n\nCo-Authored-By: John Davidge <jodavidg@cisco.com>\nCo-Authored-By: Dane LeBlanc <leblancd@cisco.com>\n\nChange-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5\n'}, {'number': 11, 'created': '2014-12-19 03:25:52.000000000', 'files': ['specs/kilo/ipv6-prefix-delegation.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2ae062b5b78c495cfc2a5d5662b09fbf0bdf18b8', 'message': 'Add IPv6 prefix delegation support in Neutron\n\nblueprint ipv6-prefix-delegation\n\nCo-Authored-By: John Davidge <jodavidg@cisco.com>\nCo-Authored-By: Dane LeBlanc <leblancd@cisco.com>\n\nChange-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5\n'}]",77,93054,2ae062b5b78c495cfc2a5d5662b09fbf0bdf18b8,56,16,11,6685,,,0,"Add IPv6 prefix delegation support in Neutron

blueprint ipv6-prefix-delegation

Co-Authored-By: John Davidge <jodavidg@cisco.com>
Co-Authored-By: Dane LeBlanc <leblancd@cisco.com>

Change-Id: Ibfb7f44b458a91244dea6d52e2564a3660debdf5
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/54/93054/9 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/ipv6-prefix-delegation.rst'],1,eb19b4035464e185b41f6be2ae9f61c9ca02d88e,bp/ipv6-prefix-delegation,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================== Support IPv6 Prefix Delegation ============================== https://blueprints.launchpad.net/neutron/+spec/ipv6-prefix-delegation Today, prefixes need to be known before configuring IPv6 subnets with neutron. This blueprints adds support of IPv6 prefix delegation (PD) into neutron. As a result, IPv6 prefixes and addresses can be automatically configured for neutron subnets and ports. Problem description =================== `RFC 3769: Requirements for IPv6 Prefix Delegation <http://tools.ietf.org/html/rfc3769>`_ specifies the requirement for IPv6 prefix delegation. `RFC 3633: IPv6 Prefix Options for Dynamic Host Configuration Protocol (DHCP) version 6 <http://tools.ietf.org/html/rfc3633>`_ defines a mechanism to support IPv6 prefix delegation with DHCPv6. With IPv6 supported in neutron, prefix delegation can be used to automatically configure neutron routers with prefixes that can then be used for the tenant networks connected with the routers. Some benefits associated with the use of prefix delegation are: * IPv6 prefixes are obtained automatically. * Renumbering can be done automatically. A possible setup (Adapted from RFC 3633) is depicted in below: :: +-------+-------+ | Aggregation | | device | | (delegating | | router) | +-------+-------+ | | | Gateway Port +------+-------+ \ |Neutron Router| \ | (requesting | \ | router) | | +----+---+-----+ | RP1 | | RP2 | Tenant ---+-------------+-----+ +-----+-------------+--- | networks | | | | | +----+-----+ +-----+----+ +----+-----+ +-----+----+ | | Tenant | | Tenant | | Tenant | | Tenant | / | VM | | VM | | VM | | VM | / +----------+ +----------+ +----------+ +----------+ / RP1: Router Port 1 RP2: Router Port 2 In the above example, the delegating router is configured with a set of prefixes. The prefix delegation process begins when the delegating router (A nuetron router) requests configuration information through DHCP. The DHCP messages from the neutron router are received by the delegating router in the aggregation device. When the delegating router receives the request, it selects an available prefix or prefixes for delegation to the neutron router. The delegating router then returns the prefix or prefixes to the neutron router. We'll refer to the delegating router as a PD server, and the requesting router as a PD client in this specification. There are a couple of ways to assign prefixes to the router ports. The neutron router can request one or more prefixes for each of the router ports from the PD server. It can also request a short prefix (For example, /48 prefix), and further subnet the delegated prefix into longer prefixes. It then assigns the longer prefixes to the router ports as they come up. Depending on the cloud, the PD server may be an ISP, or a service provided outside of openstack. It's even possible to provide the PD server as a neutron service that can be shared by all the tenants. This specification will only focus on the support of PD client in neutron and its integration with other neutron components. The support of PD server in neutron is left for future blueprints and specifications. Proposed change =============== The detailed change hasn't been hashed out yet. Some thoughts: * Enable PD client in a neutron router * Enhance subnet APIs with which CIDR doesn't have to be specified and can be assigned automatically when such a subnet is added into a PD enabled neutron router. Similarly, the assigned prefix should be released when the subnet is removed. * Prefixes are associated with a preferred lifetime and a valid lifetime. When a prefix becomes invalid, it should be removed from the associated subnet. For example, this will happen during renumbering. * After a subnet's CIDR is assgined, interact with DHCP and RA services to advertise its prefix and/or assign IPv6 addresses from the subnet. Make sure that the prefix's lifetimes are set properly. Similarly, when a prefix is removed from a subnet, interact with DHCP and RA services to act accordingly. Alternatives ------------ None Data model impact ----------------- TBD REST API impact --------------- TBD Security impact --------------- TBD Notifications impact -------------------- TBD Other end user impact --------------------- TBD Performance Impact ------------------ TBD Other deployer impact --------------------- TBD Developer impact ---------------- TBD Implementation ============== Assignee(s) ----------- TBD Work Items ---------- TBD Dependencies ============ TBD Testing ======= TBD Documentation Impact ==================== TBd References ========== TBD ",,181,0
openstack%2Fneutron-specs~master~I37f8e5b026a81a79fb68747afc96f299cfe8e7ad,openstack/neutron-specs,master,I37f8e5b026a81a79fb68747afc96f299cfe8e7ad,ML2: portsecurity extension support,MERGED,2014-06-13 09:11:44.000000000,2014-12-19 14:06:33.000000000,2014-12-19 14:06:33.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1269}, {'_account_id': 1689}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 3217}, {'_account_id': 4395}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 6697}, {'_account_id': 6772}, {'_account_id': 6854}, {'_account_id': 7170}, {'_account_id': 7278}, {'_account_id': 7448}, {'_account_id': 7576}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 10182}, {'_account_id': 10370}, {'_account_id': 10583}, {'_account_id': 10965}, {'_account_id': 11097}, {'_account_id': 11114}, {'_account_id': 11547}, {'_account_id': 11604}, {'_account_id': 13380}]","[{'number': 1, 'created': '2014-06-13 09:11:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a3a2f8de12c1b534073264246ba65371491f6482', 'message': 'ML2 OVS: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 ovs driver\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\n'}, {'number': 2, 'created': '2014-06-17 12:30:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5d3174812929b632d7bcf05d57e68bffb66f7f8f', 'message': 'ML2 OVS: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 ovs driver\nThis is prerequisite for network service in VM.\n\nNFVImpact\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\n'}, {'number': 3, 'created': '2014-06-17 15:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8df8cd9f9ced4ade09b397af469c3bf16a61dbc9', 'message': 'ML2 OVS: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 ovs driver\nThis is prerequisite for network service in VM.\n\nNFVImpact\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\n'}, {'number': 4, 'created': '2014-07-08 04:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d41930a0a4e6dec48d4e04b409fcb389aea72441', 'message': 'ML2 OVS: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 ovs driver\nThis is prerequisite for network service in VM.\n\nNFVImpact\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\n'}, {'number': 5, 'created': '2014-07-10 00:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d2589b5eb45f600ee5468f629fe8562f7815bc8c', 'message': 'ML2 OVS: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 ovs driver\nThis is prerequisite for network service in VM.\n\nNFVImpact\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\n'}, {'number': 6, 'created': '2014-07-12 05:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6c5f76e69339dd6147e4f674de497ccc926c73a7', 'message': 'ML2 OVS: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 ovs driver\nThis is prerequisite for network service in VM.\n\nNFVImpact\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\n'}, {'number': 7, 'created': '2014-07-16 15:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/99de404e4fc9874f88ca993557dfd38f26815368', 'message': 'ML2 OVS: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 ovs driver\nThis is prerequisite for network service in VM.\n\nNFVImpact\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\n'}, {'number': 8, 'created': '2014-10-30 07:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d39d0489b701cda411c5e192b4d00b671afa092a', 'message': 'ML2 OVS: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 ovs driver\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 9, 'created': '2014-11-13 07:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3250db083b1a073147cc9fb0fe67cf9e19ffe028', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 10, 'created': '2014-11-26 04:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e5bd2d2b85a8112fba9d56f66d62b55dc4306426', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 11, 'created': '2014-11-26 06:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2566ed569d438149416ffa986779a60ebfd4a0f3', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 12, 'created': '2014-12-03 20:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/771fe721dcc44d87293f7d9112e6a13ff060d7a5', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 13, 'created': '2014-12-03 20:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/46ebd53f51ea7565fbb960b2b2c607642bd77357', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 14, 'created': '2014-12-04 07:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a363cc523f594cfb94984b88ed988cf449f8ee68', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 15, 'created': '2014-12-12 01:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/37ccee0fc95f9d9fb4ffc602cf0bb6124a07004a', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 16, 'created': '2014-12-12 01:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3e78594dd4686aeb27b4514bb21a2ac8a928923f', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 17, 'created': '2014-12-14 13:22:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/47c6b2382a21672e728093025d3f0885528289fd', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 18, 'created': '2014-12-15 04:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8a53eaff96d63673ade656a4add31bd6924ee538', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 19, 'created': '2014-12-15 14:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/de6bea2bb05276d22024e253a441c5f81fe13e3d', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 20, 'created': '2014-12-18 02:33:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/da18607eae3ba02ae7328a21908fdf6455903ee6', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 21, 'created': '2014-12-18 02:44:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ab8991f04827214e9d2da65af9ff2c2dea957bb7', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}, {'number': 22, 'created': '2014-12-19 02:44:13.000000000', 'files': ['specs/kilo/ml2-ovs-portsecurity.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f558a5464eb3b43c89b7b4b59873d1c4e50515e7', 'message': 'ML2: portsecurity extension support\n\nAdd support of portsecurity extension to ML2 and mechanism driver/agent.\nThis is prerequisite for network service in VM.\n\nChange-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad\nBlueprint: ml2-ovs-portsecurity\n'}]",295,99873,f558a5464eb3b43c89b7b4b59873d1c4e50515e7,215,33,22,333,,,0,"ML2: portsecurity extension support

Add support of portsecurity extension to ML2 and mechanism driver/agent.
This is prerequisite for network service in VM.

Change-Id: I37f8e5b026a81a79fb68747afc96f299cfe8e7ad
Blueprint: ml2-ovs-portsecurity
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/73/99873/10 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/port-security-ml2-ovs.rst'],1,a3a2f8de12c1b534073264246ba65371491f6482,bp/ml2-ovs-portsecurity,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Port security extension support for ML2 OVS mechanism driver ============================================================ https://blueprints.launchpad.net/neutron/+spec/ml2-ovs-portsecurity Problem description =================== Currently the portsecurity extension isn't supported by any open source plugins/mechanism driver. Add portsecurity extension support to ML2 OVS mechanism driver. The ability to disable any kind of firewall on port, security group, antispoofing is necessary for running network service in VM instance because network service needs to receive all packet without filtering packets. This is prerequisite for network service in VM, NFV and service VM. Proposed change =============== Add support of portsecurity extension to ML2 OVS mechanism driver. Modify OVS mechanism driver and ovs agent(OVS driver in modular agent case). Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- ML2 plugin will support portsecurity extension. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ OVS agent could be heavier because its port management task will be enhanced. Other deployer impact --------------------- configuration option to enable portsecurity extension of ML2 OVS mechanism driver will be introduced for backward compatibility. Its default is 'disabled'. Developer impact ---------------- None. The change will be contained within ovs mechanism driver and ovs agent. (ML2 extension support is assumed) Implementation ============== Assignee(s) ----------- Isaku Yamahata <yamahata> Work Items ---------- mechanism driver modification including enhancing RPC OVS agent modification test Dependencies ============ * Neutron: Support for extensions in ML2 Mechanism Drivers This is necessary for extension support of mechanism driver. * Neutron: Modular L2 agent Exactly this isn't dependent, but conflicting one. If extensions support/Modular L2 agent takes long time, it can be implemented without them. The patch can be forward ported without major logic change. Testing ======= tempest will be enhanced to check if security group isn't applied. Documentation Impact ==================== API and Admin guide will be updated so that it includes configuration to enable portsecurity extension for ML2 OVS driver. References ========== * Support for extensions in ML2 Mechanism Drivers spec review: https://review.openstack.org/#/c/89208/ etherpad: https://etherpad.openstack.org/p/ML2_MD_extensions * Modular L2 agent spec review: https://review.openstack.org/#/c/99187/ ",,144,0
openstack%2Fnova~master~Id57090397a347dc8ec789f06d842d5621d0c42c0,openstack/nova,master,Id57090397a347dc8ec789f06d842d5621d0c42c0,Remove unnessary save to avoid one db call,ABANDONED,2014-12-16 13:38:54.000000000,2014-12-19 14:06:25.000000000,,"[{'_account_id': 3}, {'_account_id': 1981}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-16 13:38:54.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a723ab2e34bcd56914bda951b4165a057970adb3', 'message': 'Remove unnessary save to avoid one db call\n\nIn Rebuild_instance, we can avoid save function to\ndecrease one db call because nova will call the\nsave function later. And there is no state change\nbetween the 2 save calls.\n\nChange-Id: Id57090397a347dc8ec789f06d842d5621d0c42c0\n'}]",0,142106,a723ab2e34bcd56914bda951b4165a057970adb3,11,7,1,6062,,,0,"Remove unnessary save to avoid one db call

In Rebuild_instance, we can avoid save function to
decrease one db call because nova will call the
save function later. And there is no state change
between the 2 save calls.

Change-Id: Id57090397a347dc8ec789f06d842d5621d0c42c0
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/142106/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,a723ab2e34bcd56914bda951b4165a057970adb3,remove_unnecessary_save_for_rebuild,, instance.save(),0,1
openstack%2Fneutron-specs~master~I89471a706e5258edca622875617354625e056aaf,openstack/neutron-specs,master,I89471a706e5258edca622875617354625e056aaf,Replace WSGI layer,MERGED,2014-12-09 19:37:45.000000000,2014-12-19 14:06:15.000000000,2014-12-19 14:06:13.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6951}, {'_account_id': 8792}, {'_account_id': 8873}, {'_account_id': 8976}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-09 19:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/91e45bda0ae6f745e1a83f97498b02e7edc432cc', 'message': 'Replace WSGI layer\n\nWith the present specification we propose to move away\nfrom the home-grown WSGI framework and switch instead\nto Pecan.\n\nApiImpact\n\nChange-Id: I89471a706e5258edca622875617354625e056aaf\n'}, {'number': 2, 'created': '2014-12-10 01:02:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5fe052fa0ffddd58788ff6356d23532de5410bb7', 'message': 'Replace WSGI layer\n\nWith the present specification we propose to move away\nfrom the home-grown WSGI framework and switch instead\nto Pecan.\n\nBlueprint: wsgi-pecan-switch\n\nApiImpact\n\nChange-Id: I89471a706e5258edca622875617354625e056aaf\n'}, {'number': 3, 'created': '2014-12-10 17:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/51ed59f9c81799405e064b5801f65c87632d6de0', 'message': 'Replace WSGI layer\n\nWith the present specification we propose to move away\nfrom the home-grown WSGI framework and switch instead\nto Pecan.\n\nBlueprint: wsgi-pecan-switch\n\nApiImpact\n\nChange-Id: I89471a706e5258edca622875617354625e056aaf\n'}, {'number': 4, 'created': '2014-12-10 17:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2caefbf8d810b5f81cbbb76b05da7f75ca23509d', 'message': 'Replace WSGI layer\n\nWith the present specification we propose to move away\nfrom the home-grown WSGI framework and switch instead\nto Pecan.\n\nBlueprint: wsgi-pecan-switch\n\nApiImpact\n\nChange-Id: I89471a706e5258edca622875617354625e056aaf\n'}, {'number': 5, 'created': '2014-12-10 17:11:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/14e85798dd5c3e89f7e2ebe4936393dae0a71330', 'message': 'Replace WSGI layer\n\nWith the present specification we propose to move away\nfrom the home-grown WSGI framework and switch instead\nto Pecan.\n\nBlueprint: wsgi-pecan-switch\n\nApiImpact\n\nChange-Id: I89471a706e5258edca622875617354625e056aaf\n'}, {'number': 6, 'created': '2014-12-10 21:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3515d1951139af74cfbc23902e7f9e54d9816ce5', 'message': 'Replace WSGI layer\n\nWith the present specification we propose to move away\nfrom the home-grown WSGI framework and switch instead\nto Pecan.\n\nBlueprint: wsgi-pecan-switch\n\nApiImpact\n\nChange-Id: I89471a706e5258edca622875617354625e056aaf\n'}, {'number': 7, 'created': '2014-12-15 11:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4476a9fbe795a26fb5446dd7fb93aa26287bba35', 'message': 'Replace WSGI layer\n\nWith the present specification we propose to move away\nfrom the home-grown WSGI framework and switch instead\nto Pecan.\n\nBlueprint: wsgi-pecan-switch\n\nApiImpact\n\nChange-Id: I89471a706e5258edca622875617354625e056aaf\n'}, {'number': 8, 'created': '2014-12-19 06:01:15.000000000', 'files': ['specs/kilo/pecan-switch.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3af2eb49fd5db7876fcb0e159f8b034b120b78df', 'message': 'Replace WSGI layer\n\nWith the present specification we propose to move away\nfrom the home-grown WSGI framework and switch instead\nto Pecan.\n\nBlueprint: wsgi-pecan-switch\n\nApiImpact\n\nChange-Id: I89471a706e5258edca622875617354625e056aaf\n'}]",121,140454,3af2eb49fd5db7876fcb0e159f8b034b120b78df,38,15,8,261,,,0,"Replace WSGI layer

With the present specification we propose to move away
from the home-grown WSGI framework and switch instead
to Pecan.

Blueprint: wsgi-pecan-switch

ApiImpact

Change-Id: I89471a706e5258edca622875617354625e056aaf
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/54/140454/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/pecan-switch.rst'],1,91e45bda0ae6f745e1a83f97498b02e7edc432cc,bp/wsgi-pecan-switch,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Replace home grown WSGI layer with Pecan ========================================== https://blueprints.launchpad.net/neutron/+spec/pecan-switch This document describes a plan to replace the current home-grown WSGI framework, including REST controllers, with a solution entirely based on the Pecan framework [#]_ .. [#] Pecan documentation: http://pecan.readthedocs.org The specification discussed in this document assumumes that the REST controllers will dispatch calls to the plugin in a different way, leveraging a new interface which is thoroughly discussed in [2]_ .. [2] New plugin interface spec [TBD] Problem Description =================== This specification addresses a number of issues arising from the fact that Neutron so far has been relying on and evolving its own framework for managing web service lifecycle and dispatch API operations to plugins. Namely: * API resource definition is performed using dictionaries, whic contain information about object attribute types, default values and attribute validation. This has a number of limits, especially when it comes to performing validation and serialization of API resources, and ti also encourages a behaviour where everything is passed around as dictionaries * The current API extension management framework implies that extensions can pretty much do everything they want with the API, and even redefine parts of it. * There is home grown code based on fork() for managing multiple API workers. While this is generally not a problem, it still is a significant amount of code that needs to be maintained. Many REST frameworks like Pecan provide builtin support for spawning multiple API workers * The REST controllers have become heavyweight components since they also need to take care of tasks such as enforcing quotas and authorizing API requests * The actual response returned by the REST layer is currently built within the plugin, because there is no object-oriented interface with the plugin: the REST controller sends a resource, and expects a resource in output * Most importantly, the current WSGI/REST framework is a relatively large size component in Neutron's codebase. Switching to a well-established framework will make the whole codebase a lot more mainteinable. Proposed Change =============== In a nutshell: replace the existing framework with Pecan, remove the current code, and make it in a way operators are not affected in any way. This means that we expect the following for the Kilo release: 1) All API requests will be served by Pecan REST controllers This will have impact on in-tree attribute extensions. Such extensions indeed will be refactored as they currently define the resources they handle using the same dict-based style as attributes.py [#]_ There will therefore be a new process for adding extensions to the Neutron API. This process will be documented as a part of this blueprint. .. [#] https://github.com/openstack/neutron/blob/master/neutron/api/v2/attributes.py 2) Service startup will not happen anymore through Python PasteDeploy, and will be managed by Pecan. Similary multiple API workers will be handled through Pecan as well. 3) The Pecan REST controller will simply take care of serializing responses and deserializing responses into appropriate transfer objects describing API resources. However, the REST layer will not anymore deal with authorization and quota enforcement. These operation will be handled by the new plugin layer discussed in the spec [2]_. For the sake of this document it is enough to say that these operations won't be performed in any case in the plugin implementation. 4) On the other hand, authentication for a request must happen before the call is dispatched to the plugin layer. Pecan hooks [#]_ will be used to perform authentication at the appropriate time. .. [#] Pecan hooks: http://pecan.readthedocs.org/en/latest/hooks.html 5) The Pecan framework however only takes care of managing the REST API server. For this reason as a part of this blueprint the REST and RPC over AMQP servers will be split. Potential impacts of this change on deployers are discussed in the relevant section. This split is not expected to have any other relevant impact on operators, developers, or users. Data Model Impact ----------------- No data model change expected. REST API Impact --------------- Even if this patch has a deep impact on the Neutron management layer, the REST API itself will not change at all, and will preserve its capabilities in terms of resources, avaialble operations, filtering, pagination and sorting. Security Impact --------------- Switching the framework handling REST API requests always have a security impact. In this case, since we are moving away from a home growm framework to another which is already widely adopted across OpenStack projects, the overall security level should increase. Also, splitting the HTTP server from the AMQP one, also increases security due to the lack of authentication and authorization checks on the RPC over AMQP channel Notifications Impact -------------------- No impact at all. Other End User Impact --------------------- End users will not even notice the difference between a server running the home grown framework and one which switched to Pecan. Performance Impact ------------------ No significant impact expected. We have however no measurement avaiable to justify this claim. For this reason performance measurements should be done as part of this bluprint implementation to ensure that switching to Pecan does not impact negatively application performance. IPv6 Impact ----------- IPv6-related APIs and IPAM capabilities will be unchanged. Other Deployer Impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * If this change is a new binary, how would it be deployed? * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? * Does this require downtime or manual intervention to apply when upgrading? Developer Impact ---------------- No developer impact expected. Community Impact ---------------- Moving away from the home-grown framework will allow the community to focus exclusively on Neutron's business logic. Moreover, members of the Neutron community will also be encouraged to contribute back to Pecan. Alternatives ------------ Other solutions such as Falcon [#]_ and WSME + Pecan [#]_ have been considered. However the adoption of Pecan appears the one that better suits Neutron. .. [#] Falcon WSGI framework: http://falconframework.org/ .. [#] WSME: http://wsme.readthedocs.org/ Implementation ============== Assignee(s) ----------- Primary assignee: Mark McClain (markmcclain) Work Items ---------- 1) Introduce API objects. 2) Define framework for Pecan controllers for core and extended resources. 3) Plug authorization and quota enforcement in the ""plugin management"" layer. 4) Split out RPC over AMQP server 5) Redefine unit tests to work with new framework 6) Validate new solution with integration testing, perform performance and scalability analysis. Dependencies ============ * New plugin interface specification [link TBD] Testing ======= Once the changes are in place and integrated with the new plugin interface discussed in [2]_, gate tests should run as usual. We do not expect this change to have any impact that might trigger race conditions leading to intermittent gate failures. Tempest Tests ------------- No new tests are anticipated. Functional Tests ---------------- Even if API functional testing will eventually be a relevant part of Neutron's functionl testing suite, this is outside the scope of this spec. API Tests --------- Please see previous section. Documentation Impact ==================== As the specification discussed in this document changes the way in which the Neutron server is deployed because of the split between the HTTP and RPC over AMQP server, this will need to be appropriately documented in the admin guide. User Documentation ------------------ No change. Developer Documentation ----------------------- The new process for developing Neutron extensions should be thoroughly documented. References ========== ",,267,0
openstack%2Fsahara~master~I4285b9c3a334cda7387776bc06147ef53c0a57e0,openstack/sahara,master,I4285b9c3a334cda7387776bc06147ef53c0a57e0,Add one more sample for pig job examples,MERGED,2014-12-15 12:30:24.000000000,2014-12-19 14:01:40.000000000,2014-12-19 14:01:38.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7745}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 8932}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-12-15 12:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/75d254893a22260e738eb3d0ba671c8a3c29bb2b', 'message': 'Add one more sample for pig job examples\n\nThis patch adds new pig example ""Top TODOers"" shown in previous\nATL OpenStack Summit.\n\nImplements blueprint: edp-examples\n\nChange-Id: I4285b9c3a334cda7387776bc06147ef53c0a57e0\n'}, {'number': 2, 'created': '2014-12-15 20:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f54ac2e72226d4b8320992c51cc29a26a0d807e6', 'message': 'Add one more sample for pig job examples\n\nThis patch adds new pig example ""Top TODOers"" shown in previous\nATL OpenStack Summit:\n\n* Updated corresponding documentation and paths in integration tests\n\nImplements blueprint: edp-examples\n\nChange-Id: I4285b9c3a334cda7387776bc06147ef53c0a57e0\n'}, {'number': 3, 'created': '2014-12-16 14:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f6a09d1a6e4bbb35bd2b95af2e3463e92a821980', 'message': 'Add one more sample for pig job examples\n\nThis patch adds new pig example ""Top TODOers"" shown in previous\nATL OpenStack Summit:\n\n* Updated corresponding documentation and paths in integration tests\n\nImplements blueprint: edp-examples\n\nChange-Id: I4285b9c3a334cda7387776bc06147ef53c0a57e0\n'}, {'number': 4, 'created': '2014-12-17 13:12:59.000000000', 'files': ['etc/edp-examples/edp-pig/top-todoers/data/expected_output', 'etc/edp-examples/edp-pig/trim-spaces/README.rst', 'etc/edp-examples/edp-pig/trim-spaces/data/expected_output', 'sahara/tests/integration/tests/edp.py', 'doc/source/horizon/dashboard.user.guide.rst', 'etc/edp-examples/edp-pig/trim-spaces/data/input', 'etc/edp-examples/edp-pig/top-todoers/example.pig', 'etc/edp-examples/edp-pig/trim-spaces/example.pig', 'etc/edp-examples/edp-pig/top-todoers/README.rst', 'etc/edp-examples/edp-pig/top-todoers/data/input', 'etc/edp-examples/edp-pig/trim-spaces/udf.jar'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4e86bda8eb7d0db7fbc0568e5e5e4bc636aba393', 'message': 'Add one more sample for pig job examples\n\nThis patch adds new pig example ""Top TODOers"" shown in previous\nATL OpenStack Summit:\n\n* Updated corresponding documentation and paths in integration tests\n\nImplements blueprint: edp-examples\n\nChange-Id: I4285b9c3a334cda7387776bc06147ef53c0a57e0\n'}]",2,141782,4e86bda8eb7d0db7fbc0568e5e5e4bc636aba393,30,10,4,7125,,,0,"Add one more sample for pig job examples

This patch adds new pig example ""Top TODOers"" shown in previous
ATL OpenStack Summit:

* Updated corresponding documentation and paths in integration tests

Implements blueprint: edp-examples

Change-Id: I4285b9c3a334cda7387776bc06147ef53c0a57e0
",git fetch https://review.opendev.org/openstack/sahara refs/changes/82/141782/4 && git format-patch -1 --stdout FETCH_HEAD,"['etc/edp-examples/edp-pig/top-todoers/data/expected_output', 'etc/edp-examples/edp-pig/trim-spaces/README.rst', 'etc/edp-examples/edp-pig/trim-spaces/data/expected_output', 'sahara/tests/integration/tests/edp.py', 'etc/edp-examples/edp-pig/trim-spaces/data/input', 'etc/edp-examples/edp-pig/top-todoers/example.pig', 'etc/edp-examples/edp-pig/trim-spaces/example.pig', 'etc/edp-examples/edp-pig/top-todoers/README.rst', 'etc/edp-examples/edp-pig/top-todoers/data/input', 'etc/edp-examples/edp-pig/trim-spaces/udf.jar']",10,75d254893a22260e738eb3d0ba671c8a3c29bb2b,bp/edp-examples,,,45,1
openstack%2Ftripleo-heat-templates~master~I3ea92a502bc4b8789f74913f232ac8bc6b843008,openstack/tripleo-heat-templates,master,I3ea92a502bc4b8789f74913f232ac8bc6b843008,Set default network interfaces to nic1,MERGED,2014-11-25 20:27:55.000000000,2014-12-19 14:01:22.000000000,2014-12-19 14:01:22.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 8399}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-11-25 20:27:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bc3519a46ffc3b18c35789900a3b10ca69d640cb', 'message': ""Set default network interfaces to nic1\n\nNow that we are using os-net-config we can make use of\nthe nic naming abstraction layer where the actual physical\nnic name is mapped automatically.\n\nThis change removes all the eth0 references and replaces\nthem with nic1 which should make it more likely\nthat these default values would actually work on\nsome distributions.\n\nIt also removes the single instance of eth2 in the\nundercloud-bm-nova-deploy.yaml template and replaces\nit with nic1 as well. Underclouds aren't a special case\nin this regard (I run my bare metal undercloud on em1)\nso there is no good reason to default to the second nic.\n\nChange-Id: I3ea92a502bc4b8789f74913f232ac8bc6b843008\n""}, {'number': 2, 'created': '2014-12-05 20:16:19.000000000', 'files': ['overcloud-without-mergepy.yaml', 'undercloud-vm-ironic-deploy.yaml', 'undercloud-bm-nova-deploy.yaml', 'controller.yaml', 'compute.yaml', 'undercloud-vm-nova-deploy.yaml', 'overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8dd57aa961b9aaf93d19bd71ab14746ed7a7a514', 'message': ""Set default network interfaces to nic1\n\nNow that we are using os-net-config we can make use of\nthe nic naming abstraction layer where the actual physical\nnic name is mapped automatically.\n\nThis change removes all the eth0 references and replaces\nthem with nic1 which should make it more likely\nthat these default values would actually work on\nsome distributions.\n\nIt also removes the single instance of eth2 in the\nundercloud-bm-nova-deploy.yaml template and replaces\nit with nic1 as well. Underclouds aren't a special case\nin this regard (I run my bare metal undercloud on em1)\nso there is no good reason to default to the second nic.\n\nChange-Id: I3ea92a502bc4b8789f74913f232ac8bc6b843008\n""}]",0,137196,8dd57aa961b9aaf93d19bd71ab14746ed7a7a514,15,6,2,360,,,0,"Set default network interfaces to nic1

Now that we are using os-net-config we can make use of
the nic naming abstraction layer where the actual physical
nic name is mapped automatically.

This change removes all the eth0 references and replaces
them with nic1 which should make it more likely
that these default values would actually work on
some distributions.

It also removes the single instance of eth2 in the
undercloud-bm-nova-deploy.yaml template and replaces
it with nic1 as well. Underclouds aren't a special case
in this regard (I run my bare metal undercloud on em1)
so there is no good reason to default to the second nic.

Change-Id: I3ea92a502bc4b8789f74913f232ac8bc6b843008
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/96/137196/2 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-without-mergepy.yaml', 'cinder-storage.yaml', 'undercloud-vm-ironic-deploy.yaml', 'undercloud-bm-nova-deploy.yaml', 'controller.yaml', 'compute.yaml', 'undercloud-vm-nova-deploy.yaml', 'overcloud-source.yaml']",8,bc3519a46ffc3b18c35789900a3b10ca69d640cb,default_nics, default: 'nic1' default: nic1, default: 'eth0' default: eth0,10,10
openstack%2Ftripleo-incubator~master~I96ba83b65ada8ce811ecefa65d36ffba91eb938f,openstack/tripleo-incubator,master,I96ba83b65ada8ce811ecefa65d36ffba91eb938f,Increase size of volume used for user image,MERGED,2014-12-17 12:32:02.000000000,2014-12-19 14:00:57.000000000,2014-12-19 14:00:57.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8399}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-12-17 12:32:02.000000000', 'files': ['scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/60665ad2a28ad02d1c1ddff66ca6af6ca1636fea', 'message': 'Increase size of volume used for user image\n\nThe uncompressed size of the fedora image is now over 2G.\nCloses-Bug: #1403470\n\nChange-Id: I96ba83b65ada8ce811ecefa65d36ffba91eb938f\n'}]",1,142434,60665ad2a28ad02d1c1ddff66ca6af6ca1636fea,10,4,1,1926,,,0,"Increase size of volume used for user image

The uncompressed size of the fedora image is now over 2G.
Closes-Bug: #1403470

Change-Id: I96ba83b65ada8ce811ecefa65d36ffba91eb938f
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/34/142434/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_overcloud.sh'],1,60665ad2a28ad02d1c1ddff66ca6af6ca1636fea,user-volume-size," nova boot --key-name default --flavor m1.tiny --block-device source=image,id=$IMAGE_ID,dest=volume,size=3,shutdown=preserve,bootindex=0 demo"," nova boot --key-name default --flavor m1.tiny --block-device source=image,id=$IMAGE_ID,dest=volume,size=2,shutdown=preserve,bootindex=0 demo",1,1
openstack%2Fironic-inspector~master~I820a77aaf5fd73094aa6ab9de770eb62db44d6d5,openstack/ironic-inspector,master,I820a77aaf5fd73094aa6ab9de770eb62db44d6d5,Reorder configuration options for clarity,MERGED,2014-12-19 12:56:58.000000000,2014-12-19 13:58:15.000000000,2014-12-19 13:58:15.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-19 12:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/570a5acfa02d21f5eafad6d28b45cb5a18772216', 'message': 'Reorder configuration options for clarify\n\n* Group options on conf.py and example.conf\n* Fix one wrong option in example.conf\n\nChange-Id: I820a77aaf5fd73094aa6ab9de770eb62db44d6d5\n'}, {'number': 2, 'created': '2014-12-19 12:57:52.000000000', 'files': ['ironic_discoverd/conf.py', 'example.conf'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/a183da302e0a2c93291ce8dec34d7a2a676129da', 'message': 'Reorder configuration options for clarity\n\n* Group options on conf.py and example.conf\n* Fix one wrong option in example.conf\n\nChange-Id: I820a77aaf5fd73094aa6ab9de770eb62db44d6d5\n'}]",0,143074,a183da302e0a2c93291ce8dec34d7a2a676129da,8,3,2,10239,,,0,"Reorder configuration options for clarity

* Group options on conf.py and example.conf
* Fix one wrong option in example.conf

Change-Id: I820a77aaf5fd73094aa6ab9de770eb62db44d6d5
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/74/143074/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/conf.py', 'example.conf']",2,570a5acfa02d21f5eafad6d28b45cb5a18772216,,;; Ironic and Keystone connection settings ; Authentication options are mandatory and don't have reasonable defaults.;; Firewall management settings ;; Discovery process settings ;clean_up_period = 60 ;; HTTP settings ;; General service settings ,;; Authentication options are mandatory and don't have reasonable defaults.;firewall_update_period = 60,28,13
openstack%2Fsahara~master~I287a92f8e72453e0a982b5671bb4b077886accb6,openstack/sahara,master,I287a92f8e72453e0a982b5671bb4b077886accb6,Adding Hadoop 2.6.0 support to Vanilla plugin,MERGED,2014-12-09 16:04:18.000000000,2014-12-19 13:57:24.000000000,2014-12-19 13:57:23.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7745}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-12-09 16:04:18.000000000', 'files': ['sahara/plugins/vanilla/v2_6_0/resources/core-default.xml', 'sahara/plugins/vanilla/hadoop2/run_scripts.py', 'sahara/plugins/vanilla/v2_6_0/__init__.py', 'sahara/plugins/vanilla/v2_6_0/resources/README.rst', 'sahara/plugins/vanilla/v2_6_0/resources/mapred-default.xml', 'sahara/plugins/vanilla/v2_6_0/config_helper.py', 'sahara/plugins/vanilla/v2_6_0/resources/yarn-default.xml', 'sahara/plugins/vanilla/v2_6_0/versionhandler.py', 'sahara/plugins/vanilla/v2_6_0/resources/hdfs-default.xml', 'MANIFEST.in', 'sahara/plugins/vanilla/v2_6_0/resources/oozie-default.xml'], 'web_link': 'https://opendev.org/openstack/sahara/commit/caad5172aeaf5188339f867c94b6a9d8e877f6f8', 'message': 'Adding Hadoop 2.6.0 support to Vanilla plugin\n\npartially implements bp: add-vanilla-2-hadoop-2-6-0\n\nChange-Id: I287a92f8e72453e0a982b5671bb4b077886accb6\n'}]",0,140390,caad5172aeaf5188339f867c94b6a9d8e877f6f8,21,7,1,12039,,,0,"Adding Hadoop 2.6.0 support to Vanilla plugin

partially implements bp: add-vanilla-2-hadoop-2-6-0

Change-Id: I287a92f8e72453e0a982b5671bb4b077886accb6
",git fetch https://review.opendev.org/openstack/sahara refs/changes/90/140390/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/vanilla/v2_6_0/resources/core-default.xml', 'sahara/plugins/vanilla/hadoop2/run_scripts.py', 'sahara/plugins/vanilla/v2_6_0/__init__.py', 'sahara/plugins/vanilla/v2_6_0/config_helper.py', 'sahara/plugins/vanilla/v2_6_0/resources/README.rst', 'sahara/plugins/vanilla/v2_6_0/resources/mapred-default.xml', 'sahara/plugins/vanilla/v2_6_0/resources/yarn-default.xml', 'sahara/plugins/vanilla/v2_6_0/versionhandler.py', 'sahara/plugins/vanilla/v2_6_0/resources/hdfs-default.xml', 'MANIFEST.in', 'sahara/plugins/vanilla/v2_6_0/resources/oozie-default.xml']",11,caad5172aeaf5188339f867c94b6a9d8e877f6f8,bp/add-vanilla-2-hadoop-2-6-0,"<?xml version=""1.0""?> <?xml-stylesheet type=""text/xsl"" href=""configuration.xsl""?> <!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. --> <configuration> <!-- ************************** VERY IMPORTANT ************************** --> <!-- This file is in the Oozie configuration directory only for reference. --> <!-- It is not loaded by Oozie, Oozie uses its own privatecopy. --> <!-- ************************** VERY IMPORTANT ************************** --> <property> <name>oozie.action.ship.launcher.jar</name> <value>true</value> <description> If true, Oozie will create and ship a ""launcher jar"" that contains classes necessary for the launcher job. If false, Oozie will not do this, and it is assumed that the necessary classes are in their respective sharelib jars or the ""oozie"" sharelib instead. When false, the sharelib is required for ALL actions; when true, the sharelib is only required for actions that need additional jars (e.g. Pig). The main advantage of setting this to false is that launching jobs should be slightly faster. </description> </property> <property> <name>oozie.action.mapreduce.uber.jar.enable</name> <value>false</value> <description> If true, enables the oozie.mapreduce.uber.jar mapreduce workflow configuration property, which is used to specify an uber jar in HDFS. Submitting a workflow with an uber jar requires at least Hadoop 2.2.0 or 1.2.0. If false, workflows which specify the oozie.mapreduce.uber.jar configuration property will fail. </description> </property> <property> <name>oozie.processing.timezone</name> <value>UTC</value> <description> Oozie server timezone. Valid values are UTC and GMT(+/-)####, for example 'GMT+0530' would be India timezone. All dates parsed and genered dates by Oozie Coordinator/Bundle will be done in the specified timezone. The default value of 'UTC' should not be changed under normal circumtances. If for any reason is changed, note that GMT(+/-)#### timezones do not observe DST changes. </description> </property> <!-- Base Oozie URL: <SCHEME>://<HOST>:<PORT>/<CONTEXT> --> <property> <name>oozie.base.url</name> <value>http://localhost:8080/oozie</value> <description> Base Oozie URL. </description> </property> <!-- Services --> <property> <name>oozie.system.id</name> <value>oozie-${user.name}</value> <description> The Oozie system ID. </description> </property> <property> <name>oozie.systemmode</name> <value>NORMAL</value> <description> System mode for Oozie at startup. </description> </property> <property> <name>oozie.delete.runtime.dir.on.shutdown</name> <value>true</value> <description> If the runtime directory should be kept after Oozie shutdowns down. </description> </property> <property> <name>oozie.services</name> <value> org.apache.oozie.service.SchedulerService, org.apache.oozie.service.InstrumentationService, org.apache.oozie.service.CallableQueueService, org.apache.oozie.service.UUIDService, org.apache.oozie.service.ELService, org.apache.oozie.service.AuthorizationService, org.apache.oozie.service.UserGroupInformationService, org.apache.oozie.service.HadoopAccessorService, org.apache.oozie.service.URIHandlerService, org.apache.oozie.service.MemoryLocksService, org.apache.oozie.service.DagXLogInfoService, org.apache.oozie.service.SchemaService, org.apache.oozie.service.LiteWorkflowAppService, org.apache.oozie.service.JPAService, org.apache.oozie.service.StoreService, org.apache.oozie.service.CoordinatorStoreService, org.apache.oozie.service.SLAStoreService, org.apache.oozie.service.DBLiteWorkflowStoreService, org.apache.oozie.service.CallbackService, org.apache.oozie.service.ActionService, org.apache.oozie.service.ActionCheckerService, org.apache.oozie.service.RecoveryService, org.apache.oozie.service.PurgeService, org.apache.oozie.service.CoordinatorEngineService, org.apache.oozie.service.BundleEngineService, org.apache.oozie.service.DagEngineService, org.apache.oozie.service.CoordMaterializeTriggerService, org.apache.oozie.service.StatusTransitService, org.apache.oozie.service.PauseTransitService, org.apache.oozie.service.GroupsService, org.apache.oozie.service.ProxyUserService </value> <description> All services to be created and managed by Oozie Services singleton. Class names must be separated by commas. </description> </property> <property> <name>oozie.services.ext</name> <value> </value> <description> To add/replace services defined in 'oozie.services' with custom implementations. Class names must be separated by commas. </description> </property> <!-- HCatAccessorService --> <property> <name>oozie.service.HCatAccessorService.jmsconnections</name> <value> default=java.naming.factory.initial#org.apache.activemq.jndi.ActiveMQInitialContextFactory;java.naming.provider.url#tcp://localhost:61616;connectionFactoryNames#ConnectionFactory </value> <description> Specify the map of endpoints to JMS configuration properties. In general, endpoint identifies the HCatalog server URL. ""default"" is used if no endpoint is mentioned in the query. If some JMS property is not defined, the system will use the property defined jndi.properties. jndi.properties files is retrieved from the application classpath. Mapping rules can also be provided for mapping Hcatalog servers to corresponding JMS providers. hcat://${1}.${2}.server.com:8020=java.naming.factory.initial#Dummy.Factory;java.naming.provider.url#tcp://broker.${2}:61616 </description> </property> <!-- TopicService --> <property> <name>oozie.service.JMSTopicService.topic.name</name> <value> default=${username} </value> <description> Topic options are ${username} or ${jobId} or a fixed string which can be specified as default or for a particular job type. For e.g To have a fixed string topic for workflows, coordinators and bundles, specify in the following comma-separated format: {jobtype1}={some_string1}, {jobtype2}={some_string2} where job type can be WORKFLOW, COORDINATOR or BUNDLE. e.g. Following defines topic for workflow job, workflow action, coordinator job, coordinator action, bundle job and bundle action WORKFLOW=workflow, COORDINATOR=coordinator, BUNDLE=bundle For jobs with no defined topic, default topic will be ${username} </description> </property> <!-- JMS Producer connection --> <property> <name>oozie.jms.producer.connection.properties</name> <value>java.naming.factory.initial#org.apache.activemq.jndi.ActiveMQInitialContextFactory;java.naming.provider.url#tcp://localhost:61616;connectionFactoryNames#ConnectionFactory</value> </property> <!-- JMSAccessorService --> <property> <name>oozie.service.JMSAccessorService.connectioncontext.impl</name> <value> org.apache.oozie.jms.DefaultConnectionContext </value> <description> Specifies the Connection Context implementation </description> </property> <!-- ConfigurationService --> <property> <name>oozie.service.ConfigurationService.ignore.system.properties</name> <value> oozie.service.AuthorizationService.security.enabled </value> <description> Specifies ""oozie.*"" properties to cannot be overriden via Java system properties. Property names must be separted by commas. </description> </property> <!-- SchedulerService --> <property> <name>oozie.service.SchedulerService.threads</name> <value>10</value> <description> The number of threads to be used by the SchedulerService to run deamon tasks. If maxed out, scheduled daemon tasks will be queued up and delayed until threads become available. </description> </property> <!-- AuthorizationService --> <property> <name>oozie.service.AuthorizationService.authorization.enabled</name> <value>false</value> <description> Specifies whether security (user name/admin role) is enabled or not. If disabled any user can manage Oozie system and manage any job. </description> </property> <property> <name>oozie.service.AuthorizationService.default.group.as.acl</name> <value>false</value> <description> Enables old behavior where the User's default group is the job's ACL. </description> </property> <!-- InstrumentationService --> <property> <name>oozie.service.InstrumentationService.logging.interval</name> <value>60</value> <description> Interval, in seconds, at which instrumentation should be logged by the InstrumentationService. If set to 0 it will not log instrumentation data. </description> </property> <!-- PurgeService --> <property> <name>oozie.service.PurgeService.older.than</name> <value>30</value> <description> Completed workflow jobs older than this value, in days, will be purged by the PurgeService. </description> </property> <property> <name>oozie.service.PurgeService.coord.older.than</name> <value>7</value> <description> Completed coordinator jobs older than this value, in days, will be purged by the PurgeService. </description> </property> <property> <name>oozie.service.PurgeService.bundle.older.than</name> <value>7</value> <description> Completed bundle jobs older than this value, in days, will be purged by the PurgeService. </description> </property> <property> <name>oozie.service.PurgeService.purge.limit</name> <value>100</value> <description> Completed Actions purge - limit each purge to this value </description> </property> <property> <name>oozie.service.PurgeService.purge.interval</name> <value>3600</value> <description> Interval at which the purge service will run, in seconds. </description> </property> <!-- RecoveryService --> <property> <name>oozie.service.RecoveryService.wf.actions.older.than</name> <value>120</value> <description> Age of the actions which are eligible to be queued for recovery, in seconds. </description> </property> <property> <name>oozie.service.RecoveryService.callable.batch.size</name> <value>10</value> <description> This value determines the number of callable which will be batched together to be executed by a single thread. </description> </property> <property> <name>oozie.service.RecoveryService.push.dependency.interval</name> <value>200</value> <description> This value determines the delay for push missing dependency command queueing in Recovery Service </description> </property> <property> <name>oozie.service.RecoveryService.interval</name> <value>60</value> <description> Interval at which the RecoverService will run, in seconds. </description> </property> <property> <name>oozie.service.RecoveryService.coord.older.than</name> <value>600</value> <description> Age of the Coordinator jobs or actions which are eligible to be queued for recovery, in seconds. </description> </property> <property> <name>oozie.service.RecoveryService.bundle.older.than</name> <value>600</value> <description> Age of the Bundle jobs which are eligible to be queued for recovery, in seconds. </description> </property> <!-- CallableQueueService --> <property> <name>oozie.service.CallableQueueService.queue.size</name> <value>10000</value> <description>Max callable queue size</description> </property> <property> <name>oozie.service.CallableQueueService.threads</name> <value>10</value> <description>Number of threads used for executing callables</description> </property> <property> <name>oozie.service.CallableQueueService.callable.concurrency</name> <value>3</value> <description> Maximum concurrency for a given callable type. Each command is a callable type (submit, start, run, signal, job, jobs, suspend,resume, etc). Each action type is a callable type (Map-Reduce, Pig, SSH, FS, sub-workflow, etc). All commands that use action executors (action-start, action-end, action-kill and action-check) use the action type as the callable type. </description> </property> <property> <name>oozie.service.CallableQueueService.callable.next.eligible</name> <value>true</value> <description> If true, when a callable in the queue has already reached max concurrency, Oozie continuously find next one which has not yet reach max concurrency. </description> </property> <property> <name>oozie.service.CallableQueueService.InterruptMapMaxSize</name> <value>500</value> <description> Maximum Size of the Interrupt Map, the interrupt element will not be inserted in the map if exceeded the size. </description> </property> <property> <name>oozie.service.CallableQueueService.InterruptTypes</name> <value>kill,resume,suspend,bundle_kill,bundle_resume,bundle_suspend,coord_kill,coord_change,coord_resume,coord_suspend</value> <description> Getting the types of XCommands that are considered to be of Interrupt type </description> </property> <!-- CoordMaterializeTriggerService --> <property> <name>oozie.service.CoordMaterializeTriggerService.lookup.interval </name> <value>300</value> <description> Coordinator Job Lookup trigger command is scheduled at this ""interval"" (in seconds).</description> </property> <property> <name>oozie.service.CoordMaterializeTriggerService.materialization.window </name> <value>3600</value> <description> Coordinator Job Lookup command materialized each job for this next ""window"" duration</description> </property> <property> <name>oozie.service.CoordMaterializeTriggerService.callable.batch.size</name> <value>10</value> <description> This value determines the number of callable which will be batched together to be executed by a single thread. </description> </property> <property> <name>oozie.service.CoordMaterializeTriggerService.materialization.system.limit</name> <value>50</value> <description> This value determines the number of coordinator jobs to be materialized at a given time. </description> </property> <property> <name>oozie.service.coord.normal.default.timeout </name> <value>10080</value> <description>Default timeout for a coordinator action input check (in minutes) for normal job. </description> </property> <property> <name>oozie.service.coord.default.max.timeout </name> <value>86400</value> <description>Default maximum timeout for a coordinator action input check (in minutes). 86400= 60days </description> </property> <property> <name>oozie.service.coord.input.check.requeue.interval </name> <value>60000</value> <description>Command re-queue interval for coordinator data input check (in millisecond). </description> </property> <property> <name>oozie.service.coord.push.check.requeue.interval </name> <value>600000</value> <description>Command re-queue interval for push dependencies (in millisecond). </description> </property> <property> <name>oozie.service.coord.default.concurrency </name> <value>1</value> <description>Default concurrency for a coordinator job to determine how many maximum action should be executed at the same time. -1 means infinite concurrency.</description> </property> <property> <name>oozie.service.coord.default.throttle </name> <value>12</value> <description>Default throttle for a coordinator job to determine how many maximum action should be in WAITING state at the same time.</description> </property> <property> <name>oozie.service.coord.materialization.throttling.factor </name> <value>0.05</value> <description>Determine how many maximum actions should be in WAITING state for a single job at any time. The value is calculated by this factor X the total queue size.</description> </property> <!-- ELService --> <!-- List of supported groups for ELService --> <property> <name>oozie.service.ELService.groups</name> <value>job-submit,workflow,wf-sla-submit,coord-job-submit-freq,coord-job-submit-nofuncs,coord-job-submit-data,coord-job-submit-instances,coord-sla-submit,coord-action-create,coord-action-create-inst,coord-sla-create,coord-action-start</value> <description>List of groups for different ELServices</description> </property> <property> <name>oozie.service.ELService.constants.job-submit</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.functions.job-submit</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <!-- Workflow specifics --> <property> <name>oozie.service.ELService.constants.workflow</name> <value> KB=org.apache.oozie.util.ELConstantsFunctions#KB, MB=org.apache.oozie.util.ELConstantsFunctions#MB, GB=org.apache.oozie.util.ELConstantsFunctions#GB, TB=org.apache.oozie.util.ELConstantsFunctions#TB, PB=org.apache.oozie.util.ELConstantsFunctions#PB, RECORDS=org.apache.oozie.action.hadoop.HadoopELFunctions#RECORDS, MAP_IN=org.apache.oozie.action.hadoop.HadoopELFunctions#MAP_IN, MAP_OUT=org.apache.oozie.action.hadoop.HadoopELFunctions#MAP_OUT, REDUCE_IN=org.apache.oozie.action.hadoop.HadoopELFunctions#REDUCE_IN, REDUCE_OUT=org.apache.oozie.action.hadoop.HadoopELFunctions#REDUCE_OUT, GROUPS=org.apache.oozie.action.hadoop.HadoopELFunctions#GROUPS </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.ext.constants.workflow</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.functions.workflow</name> <value> firstNotNull=org.apache.oozie.util.ELConstantsFunctions#firstNotNull, concat=org.apache.oozie.util.ELConstantsFunctions#concat, replaceAll=org.apache.oozie.util.ELConstantsFunctions#replaceAll, appendAll=org.apache.oozie.util.ELConstantsFunctions#appendAll, trim=org.apache.oozie.util.ELConstantsFunctions#trim, timestamp=org.apache.oozie.util.ELConstantsFunctions#timestamp, urlEncode=org.apache.oozie.util.ELConstantsFunctions#urlEncode, toJsonStr=org.apache.oozie.util.ELConstantsFunctions#toJsonStr, toPropertiesStr=org.apache.oozie.util.ELConstantsFunctions#toPropertiesStr, toConfigurationStr=org.apache.oozie.util.ELConstantsFunctions#toConfigurationStr, wf:id=org.apache.oozie.DagELFunctions#wf_id, wf:name=org.apache.oozie.DagELFunctions#wf_name, wf:appPath=org.apache.oozie.DagELFunctions#wf_appPath, wf:conf=org.apache.oozie.DagELFunctions#wf_conf, wf:user=org.apache.oozie.DagELFunctions#wf_user, wf:group=org.apache.oozie.DagELFunctions#wf_group, wf:callback=org.apache.oozie.DagELFunctions#wf_callback, wf:transition=org.apache.oozie.DagELFunctions#wf_transition, wf:lastErrorNode=org.apache.oozie.DagELFunctions#wf_lastErrorNode, wf:errorCode=org.apache.oozie.DagELFunctions#wf_errorCode, wf:errorMessage=org.apache.oozie.DagELFunctions#wf_errorMessage, wf:run=org.apache.oozie.DagELFunctions#wf_run, wf:actionData=org.apache.oozie.DagELFunctions#wf_actionData, wf:actionExternalId=org.apache.oozie.DagELFunctions#wf_actionExternalId, wf:actionTrackerUri=org.apache.oozie.DagELFunctions#wf_actionTrackerUri, wf:actionExternalStatus=org.apache.oozie.DagELFunctions#wf_actionExternalStatus, hadoop:counters=org.apache.oozie.action.hadoop.HadoopELFunctions#hadoop_counters, fs:exists=org.apache.oozie.action.hadoop.FsELFunctions#fs_exists, fs:isDir=org.apache.oozie.action.hadoop.FsELFunctions#fs_isDir, fs:dirSize=org.apache.oozie.action.hadoop.FsELFunctions#fs_dirSize, fs:fileSize=org.apache.oozie.action.hadoop.FsELFunctions#fs_fileSize, fs:blockSize=org.apache.oozie.action.hadoop.FsELFunctions#fs_blockSize, hcat:exists=org.apache.oozie.coord.HCatELFunctions#hcat_exists </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <property> <name>oozie.service.WorkflowAppService.WorkflowDefinitionMaxLength</name> <value>100000</value> <description> The maximum length of the workflow definition in bytes An error will be reported if the length exceeds the given maximum </description> </property> <property> <name>oozie.service.ELService.ext.functions.workflow</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <!-- Resolve SLA information during Workflow job submission --> <property> <name>oozie.service.ELService.constants.wf-sla-submit</name> <value> MINUTES=org.apache.oozie.util.ELConstantsFunctions#SUBMIT_MINUTES, HOURS=org.apache.oozie.util.ELConstantsFunctions#SUBMIT_HOURS, DAYS=org.apache.oozie.util.ELConstantsFunctions#SUBMIT_DAYS </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.ext.constants.wf-sla-submit</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.functions.wf-sla-submit</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <property> <name>oozie.service.ELService.ext.functions.wf-sla-submit</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <!-- Coordinator specifics -->l <!-- Phase 1 resolution during job submission --> <!-- EL Evalautor setup to resolve mainly frequency tags --> <property> <name>oozie.service.ELService.constants.coord-job-submit-freq</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.ext.constants.coord-job-submit-freq</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.functions.coord-job-submit-freq</name> <value> coord:days=org.apache.oozie.coord.CoordELFunctions#ph1_coord_days, coord:months=org.apache.oozie.coord.CoordELFunctions#ph1_coord_months, coord:hours=org.apache.oozie.coord.CoordELFunctions#ph1_coord_hours, coord:minutes=org.apache.oozie.coord.CoordELFunctions#ph1_coord_minutes, coord:endOfDays=org.apache.oozie.coord.CoordELFunctions#ph1_coord_endOfDays, coord:endOfMonths=org.apache.oozie.coord.CoordELFunctions#ph1_coord_endOfMonths, coord:conf=org.apache.oozie.coord.CoordELFunctions#coord_conf, coord:user=org.apache.oozie.coord.CoordELFunctions#coord_user </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <property> <name>oozie.service.ELService.ext.functions.coord-job-submit-freq</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <!-- EL Evalautor setup to resolve mainly all constants/variables - no EL functions is resolved --> <property> <name>oozie.service.ELService.constants.coord-job-submit-nofuncs</name> <value> MINUTE=org.apache.oozie.coord.CoordELConstants#SUBMIT_MINUTE, HOUR=org.apache.oozie.coord.CoordELConstants#SUBMIT_HOUR, DAY=org.apache.oozie.coord.CoordELConstants#SUBMIT_DAY, MONTH=org.apache.oozie.coord.CoordELConstants#SUBMIT_MONTH, YEAR=org.apache.oozie.coord.CoordELConstants#SUBMIT_YEAR </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.ext.constants.coord-job-submit-nofuncs</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.functions.coord-job-submit-nofuncs</name> <value> coord:conf=org.apache.oozie.coord.CoordELFunctions#coord_conf, coord:user=org.apache.oozie.coord.CoordELFunctions#coord_user </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <property> <name>oozie.service.ELService.ext.functions.coord-job-submit-nofuncs</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <!-- EL Evalautor setup to **check** whether instances/start-instance/end-instances are valid no EL functions will be resolved --> <property> <name>oozie.service.ELService.constants.coord-job-submit-instances</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.ext.constants.coord-job-submit-instances</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.functions.coord-job-submit-instances</name> <value> coord:hoursInDay=org.apache.oozie.coord.CoordELFunctions#ph1_coord_hoursInDay_echo, coord:daysInMonth=org.apache.oozie.coord.CoordELFunctions#ph1_coord_daysInMonth_echo, coord:tzOffset=org.apache.oozie.coord.CoordELFunctions#ph1_coord_tzOffset_echo, coord:current=org.apache.oozie.coord.CoordELFunctions#ph1_coord_current_echo, coord:currentRange=org.apache.oozie.coord.CoordELFunctions#ph1_coord_currentRange_echo, coord:offset=org.apache.oozie.coord.CoordELFunctions#ph1_coord_offset_echo, coord:latest=org.apache.oozie.coord.CoordELFunctions#ph1_coord_latest_echo, coord:latestRange=org.apache.oozie.coord.CoordELFunctions#ph1_coord_latestRange_echo, coord:future=org.apache.oozie.coord.CoordELFunctions#ph1_coord_future_echo, coord:futureRange=org.apache.oozie.coord.CoordELFunctions#ph1_coord_futureRange_echo, coord:formatTime=org.apache.oozie.coord.CoordELFunctions#ph1_coord_formatTime_echo, coord:conf=org.apache.oozie.coord.CoordELFunctions#coord_conf, coord:user=org.apache.oozie.coord.CoordELFunctions#coord_user </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <property> <name>oozie.service.ELService.ext.functions.coord-job-submit-instances</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <!-- EL Evalautor setup to **check** whether dataIn and dataOut are valid no EL functions will be resolved --> <property> <name>oozie.service.ELService.constants.coord-job-submit-data</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.ext.constants.coord-job-submit-data</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.functions.coord-job-submit-data</name> <value> coord:dataIn=org.apache.oozie.coord.CoordELFunctions#ph1_coord_dataIn_echo, coord:dataOut=org.apache.oozie.coord.CoordELFunctions#ph1_coord_dataOut_echo, coord:nominalTime=org.apache.oozie.coord.CoordELFunctions#ph1_coord_nominalTime_echo_wrap, coord:actualTime=org.apache.oozie.coord.CoordELFunctions#ph1_coord_actualTime_echo_wrap, coord:dateOffset=org.apache.oozie.coord.CoordELFunctions#ph1_coord_dateOffset_echo, coord:formatTime=org.apache.oozie.coord.CoordELFunctions#ph1_coord_formatTime_echo, coord:actionId=org.apache.oozie.coord.CoordELFunctions#ph1_coord_actionId_echo, coord:name=org.apache.oozie.coord.CoordELFunctions#ph1_coord_name_echo, coord:conf=org.apache.oozie.coord.CoordELFunctions#coord_conf, coord:user=org.apache.oozie.coord.CoordELFunctions#coord_user, coord:databaseIn=org.apache.oozie.coord.HCatELFunctions#ph1_coord_databaseIn_echo, coord:databaseOut=org.apache.oozie.coord.HCatELFunctions#ph1_coord_databaseOut_echo, coord:tableIn=org.apache.oozie.coord.HCatELFunctions#ph1_coord_tableIn_echo, coord:tableOut=org.apache.oozie.coord.HCatELFunctions#ph1_coord_tableOut_echo, coord:dataInPartitionFilter=org.apache.oozie.coord.HCatELFunctions#ph1_coord_dataInPartitionFilter_echo, coord:dataInPartitionMin=org.apache.oozie.coord.HCatELFunctions#ph1_coord_dataInPartitionMin_echo, coord:dataInPartitionMax=org.apache.oozie.coord.HCatELFunctions#ph1_coord_dataInPartitionMax_echo, coord:dataOutPartitions=org.apache.oozie.coord.HCatELFunctions#ph1_coord_dataOutPartitions_echo, coord:dataOutPartitionValue=org.apache.oozie.coord.HCatELFunctions#ph1_coord_dataOutPartitionValue_echo </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <property> <name>oozie.service.ELService.ext.functions.coord-job-submit-data</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <!-- Resolve SLA information during Coordinator job submission --> <property> <name>oozie.service.ELService.constants.coord-sla-submit</name> <value> MINUTES=org.apache.oozie.coord.CoordELConstants#SUBMIT_MINUTES, HOURS=org.apache.oozie.coord.CoordELConstants#SUBMIT_HOURS, DAYS=org.apache.oozie.coord.CoordELConstants#SUBMIT_DAYS </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.ext.constants.coord-sla-submit</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.functions.coord-sla-submit</name> <value> coord:nominalTime=org.apache.oozie.coord.CoordELFunctions#ph1_coord_nominalTime_echo_fixed, coord:conf=org.apache.oozie.coord.CoordELFunctions#coord_conf, coord:user=org.apache.oozie.coord.CoordELFunctions#coord_user </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <property> <name>oozie.service.ELService.ext.functions.coord-sla-submit</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <!-- Action creation for coordinator --> <property> <name>oozie.service.ELService.constants.coord-action-create</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.ext.constants.coord-action-create</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.functions.coord-action-create</name> <value> coord:hoursInDay=org.apache.oozie.coord.CoordELFunctions#ph2_coord_hoursInDay, coord:daysInMonth=org.apache.oozie.coord.CoordELFunctions#ph2_coord_daysInMonth, coord:tzOffset=org.apache.oozie.coord.CoordELFunctions#ph2_coord_tzOffset, coord:current=org.apache.oozie.coord.CoordELFunctions#ph2_coord_current, coord:currentRange=org.apache.oozie.coord.CoordELFunctions#ph2_coord_currentRange, coord:offset=org.apache.oozie.coord.CoordELFunctions#ph2_coord_offset, coord:latest=org.apache.oozie.coord.CoordELFunctions#ph2_coord_latest_echo, coord:latestRange=org.apache.oozie.coord.CoordELFunctions#ph2_coord_latestRange_echo, coord:future=org.apache.oozie.coord.CoordELFunctions#ph2_coord_future_echo, coord:futureRange=org.apache.oozie.coord.CoordELFunctions#ph2_coord_futureRange_echo, coord:actionId=org.apache.oozie.coord.CoordELFunctions#ph2_coord_actionId, coord:name=org.apache.oozie.coord.CoordELFunctions#ph2_coord_name, coord:formatTime=org.apache.oozie.coord.CoordELFunctions#ph2_coord_formatTime, coord:conf=org.apache.oozie.coord.CoordELFunctions#coord_conf, coord:user=org.apache.oozie.coord.CoordELFunctions#coord_user </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <property> <name>oozie.service.ELService.ext.functions.coord-action-create</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <!-- Action creation for coordinator used to only evaluate instance number like ${current (daysInMonth())}. current will be echo-ed --> <property> <name>oozie.service.ELService.constants.coord-action-create-inst</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.ext.constants.coord-action-create-inst</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.functions.coord-action-create-inst</name> <value> coord:hoursInDay=org.apache.oozie.coord.CoordELFunctions#ph2_coord_hoursInDay, coord:daysInMonth=org.apache.oozie.coord.CoordELFunctions#ph2_coord_daysInMonth, coord:tzOffset=org.apache.oozie.coord.CoordELFunctions#ph2_coord_tzOffset, coord:current=org.apache.oozie.coord.CoordELFunctions#ph2_coord_current_echo, coord:currentRange=org.apache.oozie.coord.CoordELFunctions#ph2_coord_currentRange_echo, coord:offset=org.apache.oozie.coord.CoordELFunctions#ph2_coord_offset_echo, coord:latest=org.apache.oozie.coord.CoordELFunctions#ph2_coord_latest_echo, coord:latestRange=org.apache.oozie.coord.CoordELFunctions#ph2_coord_latestRange_echo, coord:future=org.apache.oozie.coord.CoordELFunctions#ph2_coord_future_echo, coord:futureRange=org.apache.oozie.coord.CoordELFunctions#ph2_coord_futureRange_echo, coord:formatTime=org.apache.oozie.coord.CoordELFunctions#ph2_coord_formatTime, coord:conf=org.apache.oozie.coord.CoordELFunctions#coord_conf, coord:user=org.apache.oozie.coord.CoordELFunctions#coord_user </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <property> <name>oozie.service.ELService.ext.functions.coord-action-create-inst</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <!-- Resolve SLA information during Action creation/materialization --> <property> <name>oozie.service.ELService.constants.coord-sla-create</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.ext.constants.coord-sla-create</name> <value> MINUTES=org.apache.oozie.coord.CoordELConstants#SUBMIT_MINUTES, HOURS=org.apache.oozie.coord.CoordELConstants#SUBMIT_HOURS, DAYS=org.apache.oozie.coord.CoordELConstants#SUBMIT_DAYS</value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.functions.coord-sla-create</name> <value> coord:nominalTime=org.apache.oozie.coord.CoordELFunctions#ph2_coord_nominalTime, coord:conf=org.apache.oozie.coord.CoordELFunctions#coord_conf, coord:user=org.apache.oozie.coord.CoordELFunctions#coord_user </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <property> <name>oozie.service.ELService.ext.functions.coord-sla-create</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <!-- Action start for coordinator --> <property> <name>oozie.service.ELService.constants.coord-action-start</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. </description> </property> <property> <name>oozie.service.ELService.ext.constants.coord-action-start</name> <value> </value> <description> EL constant declarations, separated by commas, format is [PREFIX:]NAME=CLASS#CONSTANT. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.functions.coord-action-start</name> <value> coord:hoursInDay=org.apache.oozie.coord.CoordELFunctions#ph3_coord_hoursInDay, coord:daysInMonth=org.apache.oozie.coord.CoordELFunctions#ph3_coord_daysInMonth, coord:tzOffset=org.apache.oozie.coord.CoordELFunctions#ph3_coord_tzOffset, coord:latest=org.apache.oozie.coord.CoordELFunctions#ph3_coord_latest, coord:latestRange=org.apache.oozie.coord.CoordELFunctions#ph3_coord_latestRange, coord:future=org.apache.oozie.coord.CoordELFunctions#ph3_coord_future, coord:futureRange=org.apache.oozie.coord.CoordELFunctions#ph3_coord_futureRange, coord:dataIn=org.apache.oozie.coord.CoordELFunctions#ph3_coord_dataIn, coord:dataOut=org.apache.oozie.coord.CoordELFunctions#ph3_coord_dataOut, coord:nominalTime=org.apache.oozie.coord.CoordELFunctions#ph3_coord_nominalTime, coord:actualTime=org.apache.oozie.coord.CoordELFunctions#ph3_coord_actualTime, coord:dateOffset=org.apache.oozie.coord.CoordELFunctions#ph3_coord_dateOffset, coord:formatTime=org.apache.oozie.coord.CoordELFunctions#ph3_coord_formatTime, coord:actionId=org.apache.oozie.coord.CoordELFunctions#ph3_coord_actionId, coord:name=org.apache.oozie.coord.CoordELFunctions#ph3_coord_name, coord:conf=org.apache.oozie.coord.CoordELFunctions#coord_conf, coord:user=org.apache.oozie.coord.CoordELFunctions#coord_user, coord:databaseIn=org.apache.oozie.coord.HCatELFunctions#ph3_coord_databaseIn, coord:databaseOut=org.apache.oozie.coord.HCatELFunctions#ph3_coord_databaseOut, coord:tableIn=org.apache.oozie.coord.HCatELFunctions#ph3_coord_tableIn, coord:tableOut=org.apache.oozie.coord.HCatELFunctions#ph3_coord_tableOut, coord:dataInPartitionFilter=org.apache.oozie.coord.HCatELFunctions#ph3_coord_dataInPartitionFilter, coord:dataInPartitionMin=org.apache.oozie.coord.HCatELFunctions#ph3_coord_dataInPartitionMin, coord:dataInPartitionMax=org.apache.oozie.coord.HCatELFunctions#ph3_coord_dataInPartitionMax, coord:dataOutPartitions=org.apache.oozie.coord.HCatELFunctions#ph3_coord_dataOutPartitions, coord:dataOutPartitionValue=org.apache.oozie.coord.HCatELFunctions#ph3_coord_dataOutPartitionValue </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. </description> </property> <property> <name>oozie.service.ELService.ext.functions.coord-action-start</name> <value> </value> <description> EL functions declarations, separated by commas, format is [PREFIX:]NAME=CLASS#METHOD. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <property> <name>oozie.service.ELService.latest-el.use-current-time</name> <value>false</value> <description> Determine whether to use the current time to determine the latest dependency or the action creation time. This is for backward compatibility with older oozie behaviour. </description> </property> <!-- UUIDService --> <property> <name>oozie.service.UUIDService.generator</name> <value>counter</value> <description> random : generated UUIDs will be random strings. counter: generated UUIDs generated will be a counter postfixed with the system startup time. </description> </property> <!-- DBLiteWorkflowStoreService --> <property> <name>oozie.service.DBLiteWorkflowStoreService.status.metrics.collection.interval</name> <value>5</value> <description> Workflow Status metrics collection interval in minutes.</description> </property> <property> <name>oozie.service.DBLiteWorkflowStoreService.status.metrics.window</name> <value>3600</value> <description> Workflow Status metrics collection window in seconds. Workflow status will be instrumented for the window. </description> </property> <!-- DB Schema Info, used by DBLiteWorkflowStoreService --> <property> <name>oozie.db.schema.name</name> <value>oozie</value> <description> Oozie DataBase Name </description> </property> <!-- StoreService --> <property> <name>oozie.service.JPAService.create.db.schema</name> <value>true</value> <description> Creates Oozie DB. If set to true, it creates the DB schema if it does not exist. If the DB schema exists is a NOP. If set to false, it does not create the DB schema. If the DB schema does not exist it fails start up. </description> </property> <property> <name>oozie.service.JPAService.validate.db.connection</name> <value>false</value> <description> Validates DB connections from the DB connection pool. If the 'oozie.service.JPAService.create.db.schema' property is set to true, this property is ignored. </description> </property> <property> <name>oozie.service.JPAService.validate.db.connection.eviction.interval</name> <value>300000</value> <description> Validates DB connections from the DB connection pool. When validate db connection 'TestWhileIdle' is true, the number of milliseconds to sleep between runs of the idle object evictor thread. </description> </property> <property> <name>oozie.service.JPAService.validate.db.connection.eviction.num</name> <value>10</value> <description> Validates DB connections from the DB connection pool. When validate db connection 'TestWhileIdle' is true, the number of objects to examine during each run of the idle object evictor thread. </description> </property> <property> <name>oozie.service.JPAService.connection.data.source</name> <value>org.apache.commons.dbcp.BasicDataSource</value> <description> DataSource to be used for connection pooling. </description> </property> <property> <name>oozie.service.JPAService.jdbc.driver</name> <value>org.apache.derby.jdbc.EmbeddedDriver</value> <description> JDBC driver class. </description> </property> <property> <name>oozie.service.JPAService.jdbc.url</name> <value>jdbc:derby:${oozie.data.dir}/${oozie.db.schema.name}-db;create=true</value> <description> JDBC URL. </description> </property> <property> <name>oozie.service.JPAService.jdbc.username</name> <value>sa</value> <description> DB user name. </description> </property> <property> <name>oozie.service.JPAService.jdbc.password</name> <value> </value> <description> DB user password. IMPORTANT: if password is emtpy leave a 1 space string, the service trims the value, if empty Configuration assumes it is NULL. IMPORTANT: if the StoreServicePasswordService is active, it will reset this value with the value given in the console. </description> </property> <property> <name>oozie.service.JPAService.pool.max.active.conn</name> <value>10</value> <description> Max number of connections. </description> </property> <!-- SchemaService --> <property> <name>oozie.service.SchemaService.wf.ext.schemas</name> <value>oozie-sla-0.1.xsd,oozie-sla-0.2.xsd</value> <description> Schemas for additional actions types. IMPORTANT: if there are no schemas leave a 1 space string, the service trims the value, if empty Configuration assumes it is NULL. </description> </property> <property> <name>oozie.service.SchemaService.coord.ext.schemas</name> <value>oozie-sla-0.1.xsd,oozie-sla-0.2.xsd</value> <description> Schemas for additional actions types. IMPORTANT: if there are no schemas leave a 1 space string, the service trims the value, if empty Configuration assumes it is NULL. </description> </property> <property> <name>oozie.service.SchemaService.sla.ext.schemas</name> <value> </value> <description> Schemas for semantic validation for GMS SLA. IMPORTANT: if there are no schemas leave a 1 space string, the service trims the value, if empty Configuration assumes it is NULL. </description> </property> <!-- CallbackService --> <property> <name>oozie.service.CallbackService.base.url</name> <value>${oozie.base.url}/callback</value> <description> Base callback URL used by ActionExecutors. </description> </property> <!-- CallbackServlet --> <property> <name>oozie.servlet.CallbackServlet.max.data.len</name> <value>2048</value> <description> Max size in characters for the action completion data output. </description> </property> <!-- External stats--> <property> <name>oozie.external.stats.max.size</name> <value>-1</value> <description> Max size in bytes for action stats. -1 means infinite value. </description> </property> <!-- JobCommand --> <property> <name>oozie.JobCommand.job.console.url</name> <value>${oozie.base.url}?job=</value> <description> Base console URL for a workflow job. </description> </property> <!-- ActionService --> <property> <name>oozie.service.ActionService.executor.classes</name> <value> org.apache.oozie.action.decision.DecisionActionExecutor, org.apache.oozie.action.hadoop.JavaActionExecutor, org.apache.oozie.action.hadoop.FsActionExecutor, org.apache.oozie.action.hadoop.MapReduceActionExecutor, org.apache.oozie.action.hadoop.PigActionExecutor, org.apache.oozie.action.ssh.SshActionExecutor, org.apache.oozie.action.oozie.SubWorkflowActionExecutor </value> <description> List of ActionExecutors classes (separated by commas). Only action types with associated executors can be used in workflows. </description> </property> <property> <name>oozie.service.ActionService.executor.ext.classes</name> <value> </value> <description> List of ActionExecutors extension classes (separated by commas). Only action types with associated executors can be used in workflows. This property is a convenience property to add extensions to the built in executors without having to include all the built in ones. </description> </property> <!-- ActionCheckerService --> <property> <name>oozie.service.ActionCheckerService.action.check.interval</name> <value>60</value> <description> The frequency at which the ActionCheckService will run. </description> </property> <property> <name>oozie.service.ActionCheckerService.action.check.delay</name> <value>600</value> <description> The time, in seconds, between an ActionCheck for the same action. </description> </property> <property> <name>oozie.service.ActionCheckerService.callable.batch.size</name> <value>10</value> <description> This value determines the number of actions which will be batched together to be executed by a single thread. </description> </property> <!-- StatusTransitService --> <property> <name>oozie.service.StatusTransitService.statusTransit.interval</name> <value>60</value> <description> The frequency in seconds at which the StatusTransitService will run. </description> </property> <property> <name>oozie.service.StatusTransitService.backward.support.for.coord.status</name> <value>false</value> <description> true, if coordinator job submits using 'uri:oozie:coordinator:0.1' and wants to keep Oozie 2.x status transit. if set true, 1. SUCCEEDED state in coordinator job means materialization done. 2. No DONEWITHERROR state in coordinator job 3. No PAUSED or PREPPAUSED state in coordinator job 4. PREPSUSPENDED becomes SUSPENDED in coordinator job </description> </property> <property> <name>oozie.service.StatusTransitService.backward.support.for.states.without.error</name> <value>true</value> <description> true, if you want to keep Oozie 3.2 status transit. Change it to false for Oozie 4.x releases. if set true, No states like RUNNINGWITHERROR, SUSPENDEDWITHERROR and PAUSEDWITHERROR for coordinator and bundle </description> </property> <!-- PauseTransitService --> <property> <name>oozie.service.PauseTransitService.PauseTransit.interval</name> <value>60</value> <description> The frequency in seconds at which the PauseTransitService will run. </description> </property> <!-- JavaActionExecutor --> <!-- This is common to the subclasses of action executors for Java (e.g. map-reduce, pig, hive, java, etc) --> <property> <name>oozie.action.launcher.mapreduce.job.ubertask.enable</name> <value>false</value> <description> Enables Uber Mode for the launcher job in YARN/Hadoop 2 (no effect in Hadoop 1). Setting oozie.launcher.mapreduce.job.ubertask.enable in a an action's configuration section overrides this for that action. </description> </property> <!-- HadoopActionExecutor --> <!-- This is common to the subclasses action executors for map-reduce and pig --> <property> <name>oozie.action.retries.max</name> <value>3</value> <description> The number of retries for executing an action in case of failure </description> </property> <property> <name>oozie.action.hadoop.delete.hdfs.tmp.dir</name> <value>false</value> <description> If set to true, it will delete temporary directory at the end of execution of map reduce action. </description> </property> <!-- PigActionExecutor --> <property> <name>oozie.action.pig.delete.hdfs.tmp.dir</name> <value>false</value> <description> If set to true, it will delete temporary directory at the end of execution of pig action. </description> </property> <!-- SshActionExecutor --> <property> <name>oozie.action.ssh.delete.remote.tmp.dir</name> <value>false</value> <description> If set to true, it will delete temporary directory at the end of execution of ssh action. </description> </property> <property> <name>oozie.action.ssh.http.command</name> <value>curl</value> <description> Command to use for callback to oozie, normally is 'curl' or 'wget'. The command must available in PATH environment variable of the USER@HOST box shell. </description> </property> <property> <name>oozie.action.ssh.http.command.post.options</name> <value>--data-binary @#stdout --request POST --header ""content-type:text/plain""</value> <description> The callback command POST options. Used when the ouptut of the ssh action is captured. </description> </property> <property> <name>oozie.action.ssh.allow.user.at.host</name> <value>true</value> <description> Specifies whether the user specified by the ssh action is allowed or is to be replaced by the Job user </description> </property> <!-- HadoopAccessorService --> <property> <name>oozie.service.HadoopAccessorService.kerberos.enabled</name> <value>false</value> <description> Indicates if Oozie is configured to use Kerberos. </description> </property> <property> <name>local.realm</name> <value>LOCALHOST</value> <description> Kerberos Realm used by Oozie and Hadoop. Using 'local.realm' to be aligned with Hadoop configuration </description> </property> <property> <name>oozie.service.HadoopAccessorService.keytab.file</name> <value>${user.home}/oozie.keytab</value> <description> Location of the Oozie user keytab file. </description> </property> <property> <name>oozie.service.HadoopAccessorService.kerberos.principal</name> <value>${user.name}/localhost@${local.realm}</value> <description> Kerberos principal for Oozie service. </description> </property> <property> <name>oozie.service.HadoopAccessorService.jobTracker.whitelist</name> <value> </value> <description> Whitelisted job tracker for Oozie service. </description> </property> <property> <name>oozie.service.HadoopAccessorService.nameNode.whitelist</name> <value> </value> <description> Whitelisted job tracker for Oozie service. </description> </property> <property> <name>oozie.service.HadoopAccessorService.hadoop.configurations</name> <value>*=hadoop-conf</value> <description> Comma separated AUTHORITY=HADOOP_CONF_DIR, where AUTHORITY is the HOST:PORT of the Hadoop service (JobTracker, YARN, HDFS). The wildcard '*' configuration is used when there is no exact match for an authority. The HADOOP_CONF_DIR contains the relevant Hadoop *-site.xml files. If the path is relative is looked within the Oozie configuration directory; though the path can be absolute (i.e. to point to Hadoop client conf/ directories in the local filesystem. </description> </property> <property> <name>oozie.service.HadoopAccessorService.action.configurations</name> <value>*=action-conf</value> <description> Comma separated AUTHORITY=ACTION_CONF_DIR, where AUTHORITY is the HOST:PORT of the Hadoop MapReduce service (JobTracker, YARN). The wildcard '*' configuration is used when there is no exact match for an authority. The ACTION_CONF_DIR may contain ACTION.xml files where ACTION is the action type ('java', 'map-reduce', 'pig', 'hive', 'sqoop', etc.). If the ACTION.xml file exists, its properties will be used as defaults properties for the action. If the path is relative is looked within the Oozie configuration directory; though the path can be absolute (i.e. to point to Hadoop client conf/ directories in the local filesystem. </description> </property> <!-- Credentials --> <property> <name>oozie.credentials.credentialclasses</name> <value> </value> <description> A list of credential class mapping for CredentialsProvider </description> </property> <property> <name>oozie.actions.main.classnames</name> <value>distcp=org.apache.hadoop.tools.DistCp</value> <description> A list of class name mapping for Action classes </description> </property> <property> <name>oozie.service.WorkflowAppService.system.libpath</name> <value>/user/${user.name}/share/lib</value> <description> System library path to use for workflow applications. This path is added to workflow application if their job properties sets the property 'oozie.use.system.libpath' to true. </description> </property> <property> <name>use.system.libpath.for.mapreduce.and.pig.jobs</name> <value>false</value> <description> If set to true, submissions of MapReduce and Pig jobs will include automatically the system library path, thus not requiring users to specify where the Pig JAR files are. Instead, the ones from the system library path are used. </description> </property> <property> <name>oozie.command.default.lock.timeout</name> <value>5000</value> <description> Default timeout (in milliseconds) for commands for acquiring an exclusive lock on an entity. </description> </property> <!-- LiteWorkflowStoreService, Workflow Action Automatic Retry --> <property> <name>oozie.service.LiteWorkflowStoreService.user.retry.max</name> <value>3</value> <description> Automatic retry max count for workflow action is 3 in default. </description> </property> <property> <name>oozie.service.LiteWorkflowStoreService.user.retry.inteval</name> <value>10</value> <description> Automatic retry interval for workflow action is in minutes and the default value is 10 minutes. </description> </property> <property> <name>oozie.service.LiteWorkflowStoreService.user.retry.error.code</name> <value>JA008,JA009,JA017,JA018,JA019,FS009,FS008</value> <description> Automatic retry interval for workflow action is handled for these specified error code: FS009, FS008 is file exists error when using chmod in fs action. JA018 is output directory exists error in workflow map-reduce action. JA019 is error while executing distcp action. JA017 is job not exists error in action executor. JA008 is FileNotFoundException in action executor. JA009 is IOException in action executor. </description> </property> <property> <name>oozie.service.LiteWorkflowStoreService.user.retry.error.code.ext</name> <value> </value> <description> Automatic retry interval for workflow action is handled for these specified extra error code. </description> </property> <property> <name>oozie.service.LiteWorkflowStoreService.node.def.version</name> <value>_oozie_inst_v_1</value> <description> NodeDef default version, _oozie_inst_v_0 or _oozie_inst_v_1 </description> </property> <!-- Oozie Authentication --> <property> <name>oozie.authentication.type</name> <value>simple</value> <description> Defines authentication used for Oozie HTTP endpoint. Supported values are: simple | kerberos | #AUTHENTICATION_HANDLER_CLASSNAME# </description> </property> <property> <name>oozie.authentication.token.validity</name> <value>36000</value> <description> Indicates how long (in seconds) an authentication token is valid before it has to be renewed. </description> </property> <property> <name>oozie.authentication.signature.secret</name> <value>oozie</value> <description> The signature secret for signing the authentication tokens. If not set a random secret is generated at startup time. In order to authentiation to work correctly across multiple hosts the secret must be the same across al the hosts. </description> </property> <property> <name>oozie.authentication.cookie.domain</name> <value></value> <description> The domain to use for the HTTP cookie that stores the authentication token. In order to authentiation to work correctly across multiple hosts the domain must be correctly set. </description> </property> <property> <name>oozie.authentication.simple.anonymous.allowed</name> <value>true</value> <description> Indicates if anonymous requests are allowed when using 'simple' authentication. </description> </property> <property> <name>oozie.authentication.kerberos.principal</name> <value>HTTP/localhost@${local.realm}</value> <description> Indicates the Kerberos principal to be used for HTTP endpoint. The principal MUST start with 'HTTP/' as per Kerberos HTTP SPNEGO specification. </description> </property> <property> <name>oozie.authentication.kerberos.keytab</name> <value>${oozie.service.HadoopAccessorService.keytab.file}</value> <description> Location of the keytab file with the credentials for the principal. Referring to the same keytab file Oozie uses for its Kerberos credentials for Hadoop. </description> </property> <property> <name>oozie.authentication.kerberos.name.rules</name> <value>DEFAULT</value> <description> The kerberos names rules is to resolve kerberos principal names, refer to Hadoop's KerberosName for more details. </description> </property> <!-- Coordinator Actions default length --> <property> <name>oozie.coord.actions.default.length</name> <value>1000</value> <description> Default number of coordinator actions to be retrieved by the info command </description> </property> <!-- ForkJoin validation --> <property> <name>oozie.validate.ForkJoin</name> <value>true</value> <description> If true, fork and join should be validated at wf submission time. </description> </property> <property> <name>oozie.coord.action.get.all.attributes</name> <value>false</value> <description> Setting to true is not recommended as coord job/action info will bring all columns of the action in memory. Set it true only if backward compatibility for action/job info is required. </description> </property> <property> <name>oozie.service.HadoopAccessorService.supported.filesystems</name> <value>hdfs,hftp,webhdfs</value> <description> Enlist the different filesystems supported for federation. If wildcard ""*"" is specified, then ALL file schemes will be allowed. </description> </property> <property> <name>oozie.service.URIHandlerService.uri.handlers</name> <value>org.apache.oozie.dependency.FSURIHandler</value> <description> Enlist the different uri handlers supported for data availability checks. </description> </property> <!-- Oozie HTTP Notifications --> <property> <name>oozie.notification.url.connection.timeout</name> <value>10000</value> <description> Defines the timeout, in milliseconds, for Oozie HTTP notification callbacks. Oozie does HTTP notifications for workflow jobs which set the 'oozie.wf.action.notification.url', 'oozie.wf.worklfow.notification.url' and/or 'oozie.coord.action.notification.url' properties in their job.properties. Refer to section '5 Oozie Notifications' in the Workflow specification for details. </description> </property> <!-- Enable Distributed Cache workaround for Hadoop 2.0.2-alpha (MAPREDUCE-4820) --> <property> <name>oozie.hadoop-2.0.2-alpha.workaround.for.distributed.cache</name> <value>false</value> <description> Due to a bug in Hadoop 2.0.2-alpha, MAPREDUCE-4820, launcher jobs fail to set the distributed cache for the action job because the local JARs are implicitly included triggering a duplicate check. This flag removes the distributed cache files for the action as they'll be included from the local JARs of the JobClient (MRApps) submitting the action job from the launcher. </description> </property> <property> <name>oozie.service.EventHandlerService.filter.app.types</name> <value>workflow_job, coordinator_action</value> <description> The app-types among workflow/coordinator/bundle job/action for which for which events system is enabled. </description> </property> <property> <name>oozie.service.EventHandlerService.event.queue</name> <value>org.apache.oozie.event.MemoryEventQueue</value> <description> The implementation for EventQueue in use by the EventHandlerService. </description> </property> <property> <name>oozie.service.EventHandlerService.event.listeners</name> <value>org.apache.oozie.jms.JMSJobEventListener</value> </property> <property> <name>oozie.service.EventHandlerService.queue.size</name> <value>10000</value> <description> Maximum number of events to be contained in the event queue. </description> </property> <property> <name>oozie.service.EventHandlerService.worker.interval</name> <value>30</value> <description> The default interval (seconds) at which the worker threads will be scheduled to run and process events. </description> </property> <property> <name>oozie.service.EventHandlerService.batch.size</name> <value>10</value> <description> The batch size for batched draining per thread from the event queue. </description> </property> <property> <name>oozie.service.EventHandlerService.worker.threads</name> <value>3</value> <description> Number of worker threads to be scheduled to run and process events. </description> </property> <property> <name>oozie.sla.service.SLAService.capacity</name> <value>5000</value> <description> Maximum number of sla records to be contained in the memory structure. </description> </property> <property> <name>oozie.sla.service.SLAService.alert.events</name> <value>END_MISS</value> <description> Default types of SLA events for being alerted of. </description> </property> <property> <name>oozie.sla.service.SLAService.calculator.impl</name> <value>org.apache.oozie.sla.SLACalculatorMemory</value> <description> The implementation for SLACalculator in use by the SLAService. </description> </property> <property> <name>oozie.sla.service.SLAService.job.event.latency</name> <value>90000</value> <description> Time in milliseconds to account of latency of getting the job status event to compare against and decide sla miss/met </description> </property> </configuration> ",,9553,3
openstack%2Fironic-inspector~master~I4c50048f6ceac609315a08282a50c3ca61568d8f,openstack/ironic-inspector,master,I4c50048f6ceac609315a08282a50c3ca61568d8f,Try to set boot device to PXE before rebooting,MERGED,2014-12-19 13:47:48.000000000,2014-12-19 13:56:05.000000000,2014-12-19 13:56:03.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-19 13:47:48.000000000', 'files': ['ironic_discoverd/test/test_discover.py', 'ironic_discoverd/discover.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/98f8c0c0059a6a13295fd88e0a8c0306cdd858a1', 'message': 'Try to set boot device to PXE before rebooting\n\nChange-Id: I4c50048f6ceac609315a08282a50c3ca61568d8f\nCloses-Bug: #1401801\n'}]",0,143090,98f8c0c0059a6a13295fd88e0a8c0306cdd858a1,7,3,1,10239,,,0,"Try to set boot device to PXE before rebooting

Change-Id: I4c50048f6ceac609315a08282a50c3ca61568d8f
Closes-Bug: #1401801
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/90/143090/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/test/test_discover.py', 'ironic_discoverd/discover.py']",2,98f8c0c0059a6a13295fd88e0a8c0306cdd858a1,bug/1401801," utils.retry_on_conflict(ironic.node.set_boot_device, node.uuid, 'pxe', persistent=False) except Exception as exc: LOG.warning('Failed to set boot device to PXE for node %s: %s', node.uuid, exc) try:",,14,0
openstack%2Fsahara~master~I4c7aab009efd76b503e11b369dec51cb73438d03,openstack/sahara,master,I4c7aab009efd76b503e11b369dec51cb73438d03,Fixed pep8 after keystoneclient upgrade,MERGED,2014-12-19 00:21:24.000000000,2014-12-19 13:34:49.000000000,2014-12-19 13:34:48.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8932}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-12-19 00:21:24.000000000', 'files': ['etc/sahara/sahara.conf.sample'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4b04a8c3ab271f118cdba0aeffa41c451517063b', 'message': 'Fixed pep8 after keystoneclient upgrade\n\nChange-Id: I4c7aab009efd76b503e11b369dec51cb73438d03\nCloses-Bug: #1404062\n'}]",0,142942,4b04a8c3ab271f118cdba0aeffa41c451517063b,13,7,1,8411,,,0,"Fixed pep8 after keystoneclient upgrade

Change-Id: I4c7aab009efd76b503e11b369dec51cb73438d03
Closes-Bug: #1404062
",git fetch https://review.opendev.org/openstack/sahara refs/changes/42/142942/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/sahara/sahara.conf.sample'],1,4b04a8c3ab271f118cdba0aeffa41c451517063b,bug/1404062,"# Service user password. (string value)# Service tenant name. (string value)# Service username. (string value)# Complete public Identity API endpoint. (string value)# API version of the admin Identity API endpoint. (string value)# Env key for the swift cache. (string value)# Required if identity server requires client certificate (string# requires that PKI tokens are configured on the identity server.# delegate the authorization decision to downstream WSGI components.# (integer value)# (Optional) Indicate whether to set the X-Service-Catalog header. If# Required if identity server requires client certificate (string# (Optional) Number of seconds that an operation will wait to get a# (Optional) Number of seconds memcached server is considered dead# (Optional) Maximum total number of open connections to every # memcached server. (integer value)# (Optional) Socket timeout in seconds for communicating with a# (Optional) Number of seconds a connection to memcached is held# (Optional, mandatory if memcache_security_strategy is defined) This# (Optional) If defined, indicate whether token data should be# (Optional) Use the advanced (eventlet safe) memcache client pool.# Directory used to cache files related to PKI tokens. (string value)","# Keystone account password (string value)# Keystone service account tenant name to validate user tokens (string # value)# Keystone account username (string value)# Complete public Identity API endpoint (string value)# API version of the admin Identity API endpoint (string value)# Env key for the swift cache (string value)# Required if Keystone server requires client certificate (string# requires that PKI tokens are configured on the Keystone server.# delegate the authorization decision to downstream WSGI components# (boolean value)# (optional) indicate whether to set the X-Service-Catalog header. If# Required if Keystone server requires client certificate (string# (optional) number of seconds that an operation will wait to get a# (optional) number of seconds memcached server is considered dead# (optional) max total number of open connections to every memcached # server. (integer value)# (optional) socket timeout in seconds for communicating with a# (optional) number of seconds a connection to memcached is held# (optional, mandatory if memcache_security_strategy is defined) this# (optional) if defined, indicate whether token data should be# (optional) use the advanced (eventlet safe) memcache client pool.# Directory used to cache files related to PKI tokens (string value)",22,23
openstack%2Frally~master~I8307c7cd784fefa5b7d711c28793f264bfddf861,openstack/rally,master,I8307c7cd784fefa5b7d711c28793f264bfddf861,Fix atomic actions in NeutronNetwork wrapper,ABANDONED,2014-12-09 16:00:27.000000000,2014-12-19 13:32:59.000000000,,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 10475}]","[{'number': 1, 'created': '2014-12-09 16:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/93a92c630bd80607742274a4d634efd491ce9023', 'message': 'Fix atomic actions in NeutronNetwork wrapper\n\nAtomic actions for create and delete network were not attached to original\nscenario, so duration of these actions were missed.\n\nChange-Id: I8307c7cd784fefa5b7d711c28793f264bfddf861\n'}, {'number': 2, 'created': '2014-12-09 17:13:05.000000000', 'files': ['rally/benchmark/scenarios/nova/security_group.py', 'tests/unit/benchmark/scenarios/nova/test_security_group.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/76123083f7a2dc8751e2986a79766ca092f67d7f', 'message': 'Fix atomic actions in NeutronNetwork wrapper\n\nAtomic actions for create and delete network were not attached to original\nscenario, so duration of these actions were missed.\n\nChange-Id: I8307c7cd784fefa5b7d711c28793f264bfddf861\n'}]",0,140386,76123083f7a2dc8751e2986a79766ca092f67d7f,7,3,2,9545,,,0,"Fix atomic actions in NeutronNetwork wrapper

Atomic actions for create and delete network were not attached to original
scenario, so duration of these actions were missed.

Change-Id: I8307c7cd784fefa5b7d711c28793f264bfddf861
",git fetch https://review.opendev.org/openstack/rally refs/changes/86/140386/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/nova/security_group.py', 'tests/unit/benchmark/scenarios/nova/test_security_group.py']",2,93a92c630bd80607742274a4d634efd491ce9023,fix_atomic_actions_in_secgroups, with security_group.NeutronNetwork(mock.MagicMock()) as boot_kwargs: with security_group.NeutronNetwork(mock.MagicMock()) as boot_kwargs:," with security_group.NeutronNetwork(None, None) as boot_kwargs: with security_group.NeutronNetwork(None, None) as boot_kwargs:",16,10
openstack%2Ffuel-web~master~I44f8a6cc03c1e9e62b10daa1f91ed68ad1982349,openstack/fuel-web,master,I44f8a6cc03c1e9e62b10daa1f91ed68ad1982349,Bump JSCS to latest version,MERGED,2014-12-19 11:19:11.000000000,2014-12-19 13:30:53.000000000,2014-12-19 13:30:53.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}]","[{'number': 1, 'created': '2014-12-19 11:19:11.000000000', 'files': ['nailgun/Gruntfile.js', 'nailgun/package.json', 'nailgun/npm-shrinkwrap.json'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f0fbdfc387166ce67daadfb01abbfa3bd4b94dcc', 'message': 'Bump JSCS to latest version\n\nChange-Id: I44f8a6cc03c1e9e62b10daa1f91ed68ad1982349\n'}]",0,143042,f0fbdfc387166ce67daadfb01abbfa3bd4b94dcc,11,5,1,8735,,,0,"Bump JSCS to latest version

Change-Id: I44f8a6cc03c1e9e62b10daa1f91ed68ad1982349
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/42/143042/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/Gruntfile.js', 'nailgun/package.json', 'nailgun/npm-shrinkwrap.json']",3,f0fbdfc387166ce67daadfb01abbfa3bd4b94dcc,jscs-update," ""version"": ""1.0.8"", ""version"": ""1.4.2"", ""from"": ""ansi-regex@^0.2.1"" ""from"": ""ansi-regex@^0.2.1"" ""from"": ""inherits@2"" ""version"": ""1.0.2"", ""version"": ""2.0.1"", ""from"": ""minimatch@^2.0.1"", ""dependencies"": { ""brace-expansion"": { ""version"": ""1.1.0"", ""from"": ""brace-expansion@^1.0.0"", ""dependencies"": { ""balanced-match"": { ""version"": ""0.2.0"", ""from"": ""balanced-match@^0.2.0"" }, ""concat-map"": { ""version"": ""0.0.1"", ""from"": ""concat-map@0.0.1"" } } ""from"": ""glob@~4.0.0"", ""version"": ""0.1.41"", ""from"": ""mute-stream@0.0.4"" ""version"": ""2.3.22"", ""version"": ""2.3.22"", ""from"": ""lru-cache@~2.5.0"" ""version"": ""1.4.2"", ""from"": ""configstore@^0.3.0"", ""version"": ""1.0.8"", ""version"": ""2.5.11"", ""from"": ""async@~0.2.8"" ""version"": ""1.0.0"", ""from"": ""grunt-jscs@~1.0.0"", ""version"": ""1.8.1"", ""from"": ""jscs@~1.8.0"", ""version"": ""1.0.3"", ""from"": ""colors@~1.0.3"" ""version"": ""2.5.1"", ""from"": ""commander@~2.5.0"" ""esprima-harmony-jscs"": { ""version"": ""1.1.0-dev-harmony"", ""from"": ""esprima-harmony-jscs@1.1.0-dev-harmony"" }, ""version"": ""1.2.0"", ""from"": ""supports-color@~1.2.0"" ""version"": ""0.12.2"", ""version"": ""0.9.11"", ""version"": ""0.1.41"", ""version"": ""0.6.7"", ""version"": ""2.5.1"", ""from"": ""inherits@~2.0.1"" ""version"": ""0.1.41"", ""version"": ""2.51.0"", ""version"": ""0.2.0"", ""from"": ""form-data@~0.2.0"", }, ""mime-types"": { ""version"": ""2.0.4"", ""from"": ""mime-types@~2.0.3"", ""dependencies"": { ""mime-db"": { ""version"": ""1.3.1"", ""from"": ""mime-db@~1.3.0"" } } ""version"": ""1.4.2"", ""version"": ""0.1.41"", ""from"": ""source-map@0.1.x"", ""version"": ""0.1.41"","," ""version"": ""1.0.7"", ""version"": ""1.4.1"", ""from"": ""ansi-regex@^0.2.0"" ""from"": ""ansi-regex@^0.2.0"" ""from"": ""inherits@~2.0.1"" ""version"": ""1.0.1"", ""version"": ""1.0.0"", ""from"": ""minimatch@^1.0.0"", ""dependencies"": { ""sigmund"": { ""version"": ""1.0.0"", ""from"": ""sigmund@~1.0.0"" ""from"": ""glob@~4.0.2"", ""version"": ""0.1.40"", ""from"": ""mute-stream@~0.0.4"" ""version"": ""2.3.18"", ""version"": ""2.3.18"", ""from"": ""lru-cache@2"" ""version"": ""1.4.1"", ""from"": ""configstore@^0.3.1"", ""version"": ""1.0.7"", ""version"": ""2.5.10"", ""from"": ""async@~0.2.6"" ""version"": ""0.7.1"", ""from"": ""grunt-jscs@~0.7.1"", ""version"": ""1.6.2"", ""from"": ""jscs@~1.6.0"", ""version"": ""0.6.2"", ""from"": ""colors@~0.6.2"" ""version"": ""2.3.0"", ""from"": ""commander@~2.3.0"" ""version"": ""1.1.0"", ""from"": ""supports-color@~1.1.0"" ""version"": ""0.12.1"", ""version"": ""0.9.8"", ""version"": ""0.1.40"", ""version"": ""0.6.6"", ""version"": ""2.5.0"", ""from"": ""inherits@2"" ""version"": ""0.1.40"", ""version"": ""2.49.0"", ""version"": ""0.1.4"", ""from"": ""form-data@~0.1.0"", ""version"": ""1.4.1"", ""version"": ""0.1.40"", ""from"": ""source-map@~0.1.7"", ""version"": ""0.1.40"",",73,47
openstack%2Ftempest~master~Ib09342d7d831e8ac496efa0d799cd17af3c4a95f,openstack/tempest,master,Ib09342d7d831e8ac496efa0d799cd17af3c4a95f,Add IdentityV3Client for cleanup,MERGED,2014-12-17 09:12:39.000000000,2014-12-19 12:59:40.000000000,2014-12-19 12:59:39.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 09:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a9466aaa1ee9f35d4a435312bbb8cf38fd6dcffc', 'message': 'Add IdentityV3Client for cleanup\n\nIn identity v3 clients, there is a lot of duplicated code for\nsetting CONF. This patch adds IdentityV3Client for removing them.\n\nChange-Id: Ib09342d7d831e8ac496efa0d799cd17af3c4a95f\n'}, {'number': 2, 'created': '2014-12-17 12:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f3575f2b406740ced635723ff67a09a54ef812b8', 'message': 'Add IdentityV3Client for cleanup\n\nIn identity v3 clients, there is a lot of duplicated code for\nsetting CONF. This patch adds IdentityV3Client for removing them.\n\nChange-Id: Ib09342d7d831e8ac496efa0d799cd17af3c4a95f\n'}, {'number': 3, 'created': '2014-12-18 04:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c8a2cd96696b24916c34837d21fb16fa0eff24db', 'message': 'Add IdentityV3Client for cleanup\n\nIn identity v3 clients, there is a lot of duplicated code for\nsetting CONF. This patch adds IdentityV3Client for removing them.\n\nChange-Id: Ib09342d7d831e8ac496efa0d799cd17af3c4a95f\n'}, {'number': 4, 'created': '2014-12-19 11:14:33.000000000', 'files': ['tempest/services/identity/v3/json/policy_client.py', 'tempest/services/identity/v3/json/service_client.py', 'tempest/services/identity/v3/json/endpoints_client.py', 'tempest/services/identity/v3/json/credentials_client.py', 'tempest/services/identity/v3/json/identity_client.py', 'tempest/services/identity/v3/json/base.py', 'tempest/services/identity/v3/json/region_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e39799cde906f89fd5155a394358cea92aec007', 'message': 'Add IdentityV3Client for cleanup\n\nIn identity v3 clients, there is a lot of duplicated code for\nsetting CONF. This patch adds IdentityV3Client for removing them.\n\nChange-Id: Ib09342d7d831e8ac496efa0d799cd17af3c4a95f\n'}]",0,142387,5e39799cde906f89fd5155a394358cea92aec007,18,5,4,6167,,,0,"Add IdentityV3Client for cleanup

In identity v3 clients, there is a lot of duplicated code for
setting CONF. This patch adds IdentityV3Client for removing them.

Change-Id: Ib09342d7d831e8ac496efa0d799cd17af3c4a95f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/87/142387/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/identity/v3/json/policy_client.py', 'tempest/services/identity/v3/json/service_client.py', 'tempest/services/identity/v3/json/credentials_client.py', 'tempest/services/identity/v3/json/endpoints_client.py', 'tempest/services/identity/v3/json/identity_client.py', 'tempest/services/identity/v3/json/base.py', 'tempest/services/identity/v3/json/region_client.py']",7,a9466aaa1ee9f35d4a435312bbb8cf38fd6dcffc,rest-client,from tempest.services.identity.v3.json import base class RegionClientJSON(base.IdentityV3Client):,"from tempest.common import rest_client from tempest import config CONF = config.CONF class RegionClientJSON(rest_client.RestClient): def __init__(self, auth_provider): super(RegionClientJSON, self).__init__(auth_provider) self.service = CONF.identity.catalog_type self.endpoint_url = 'adminURL' self.api_version = ""v3""",42,61
openstack%2Foslo.log~master~I0ed8fd97672544a517c01a7a829595ca0e3fe81c,openstack/oslo.log,master,I0ed8fd97672544a517c01a7a829595ca0e3fe81c,Enhance the README a bit,MERGED,2014-12-18 03:19:16.000000000,2014-12-19 12:57:55.000000000,2014-12-19 12:57:54.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-12-18 03:19:16.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/cfcb016e53888ef9502fd13f171036680ca47e20', 'message': 'Enhance the README a bit\n\nChange-Id: I0ed8fd97672544a517c01a7a829595ca0e3fe81c\n'}]",0,142654,cfcb016e53888ef9502fd13f171036680ca47e20,11,4,1,5638,,,0,"Enhance the README a bit

Change-Id: I0ed8fd97672544a517c01a7a829595ca0e3fe81c
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/54/142654/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,cfcb016e53888ef9502fd13f171036680ca47e20,,"================================ oslo.log -- Oslo Logging Library ================================ OpenStack logging configuration library provides standardized configuration for all openstack projects. It also provides custom formatters, handlers and support for context specific logging (like resource id's etc).",========== oslo.log ========== OpenStack logging configuration library,6,4
openstack%2Fneutron~master~I200fdea75198319d02b47d0a570764f4bb53c702,openstack/neutron,master,I200fdea75198319d02b47d0a570764f4bb53c702,TEST,ABANDONED,2014-12-18 11:26:36.000000000,2014-12-19 12:52:16.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-18 11:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f709be30c5bbd34744105f7f33926ab4d289f3fa', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nFunctional test IPAM DB operation\n\nAdd a functional test to check that the IPAM logic is correct and\nthat the data stored in the DB are sane.\n\nChange-Id: I200fdea75198319d02b47d0a570764f4bb53c702\n'}, {'number': 2, 'created': '2014-12-18 11:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ae7b5a95d2b4c400f6c6aeebcf78613478dc83b', 'message': 'TEST\n\nSquash of the commits:\n\nMove DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nFunctional test IPAM DB operation\n\nAdd a functional test to check that the IPAM logic is correct and\nthat the data stored in the DB are sane.\n\nChange-Id: I200fdea75198319d02b47d0a570764f4bb53c702\n'}, {'number': 3, 'created': '2014-12-18 15:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c9e883bfaa791d53339778c287da1181e04c8a9', 'message': 'TEST\n\nSquash of the commits:\n\nMove DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nFunctional test IPAM DB operation\n\nAdd a functional test to check that the IPAM logic is correct and\nthat the data stored in the DB are sane.\n\nChange-Id: I200fdea75198319d02b47d0a570764f4bb53c702\n'}, {'number': 4, 'created': '2014-12-18 16:49:11.000000000', 'files': ['neutron/tests/functional/db/test_ipam.py', 'neutron/tests/functional/contrib/gate_hook.sh', 'doc/source/devref/db_layer.rst', 'test-requirements.txt', 'neutron/tests/functional/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc6ed9be446d5ebae037889f903f4c8cd7aeab1f', 'message': 'TEST\n\nSquash of the commits:\n\nMove DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nFunctional test IPAM DB operation\n\nAdd a functional test to check that the IPAM logic is correct and\nthat the data stored in the DB are sane.\n\nChange-Id: I200fdea75198319d02b47d0a570764f4bb53c702\n'}]",0,142734,bc6ed9be446d5ebae037889f903f4c8cd7aeab1f,52,16,4,6788,,,0,"TEST

Squash of the commits:

Move DB TestModelsMigrations from unit to functional

The tests to check that DB migrations and models are in sync depends
on the mysql and postgresql backends being available with a specific
DB user and database created. This violates the principles for unit
tests and therefore these tests should be moved to functional tests.

For these tests to work in the functional job in the gate, the
backends must be installed and the DB user and database created.
We do this via the functional gate hook.

Functional test IPAM DB operation

Add a functional test to check that the IPAM logic is correct and
that the data stored in the DB are sane.

Change-Id: I200fdea75198319d02b47d0a570764f4bb53c702
",git fetch https://review.opendev.org/openstack/neutron refs/changes/34/142734/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/db/test_ipam.py', 'neutron/tests/functional/contrib/gate_hook.sh', 'doc/source/devref/db_layer.rst', 'test-requirements.txt', 'neutron/tests/functional/db/test_migrations.py']",5,f709be30c5bbd34744105f7f33926ab4d289f3fa,ipam-func,,,358,5
openstack%2Foslo.log~master~I192238c4de8ccc3e740132219a67e22bb45cb8d0,openstack/oslo.log,master,I192238c4de8ccc3e740132219a67e22bb45cb8d0,Switch to oslo.context,MERGED,2014-12-08 21:18:04.000000000,2014-12-19 12:50:41.000000000,2014-12-19 12:50:41.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-12-08 21:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/318107de81c6100d0bd1c5c7b22930676a385691', 'message': 'Switch to oslo.context\n\nNuke our copy of context.py and switch over to the\noslo.context library.\n\nChange-Id: I192238c4de8ccc3e740132219a67e22bb45cb8d0\n'}, {'number': 2, 'created': '2014-12-09 18:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/8ae6293830dea2f7b06ea477e49604abe303802b', 'message': 'Switch to oslo.context\n\nNuke our copy of context.py and switch over to the\noslo.context library.\n\nChange-Id: I192238c4de8ccc3e740132219a67e22bb45cb8d0\n'}, {'number': 3, 'created': '2014-12-18 02:44:18.000000000', 'files': ['oslo_log/tests/unit/test_log.py', 'oslo_log/formatters.py', 'requirements.txt', 'oslo_log/log.py', 'oslo_log/tests/unit/test_context.py', 'oslo_log/context.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/4ca2b0293b82af72ccb0f7f7d53992c876cc44d4', 'message': 'Switch to oslo.context\n\nNuke our copy of context.py and switch over to the\noslo.context library.\n\nChange-Id: I192238c4de8ccc3e740132219a67e22bb45cb8d0\n'}]",0,140147,4ca2b0293b82af72ccb0f7f7d53992c876cc44d4,17,4,3,5638,,,0,"Switch to oslo.context

Nuke our copy of context.py and switch over to the
oslo.context library.

Change-Id: I192238c4de8ccc3e740132219a67e22bb45cb8d0
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/47/140147/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'oslo/log/context.py', 'oslo/log/formatters.py', 'tests/unit/test_log.py', 'oslo/log/log.py', 'tests/unit/test_context.py']",6,318107de81c6100d0bd1c5c7b22930676a385691,bp/drop-namespace-packages,"from oslo_context import context ""resource_uuid"": ""instance1"", self.assertEqual(""instance1"", ctx.resource_uuid)","from oslo.log import context ""instance_uuid"": ""instance1"", self.assertEqual(""instance1"", ctx.instance_uuid)",7,136
openstack%2Foslo.log~master~Id8e2312a72af171918fa4d40117ec652018a37bf,openstack/oslo.log,master,Id8e2312a72af171918fa4d40117ec652018a37bf,Move files out of the namespace package,MERGED,2014-11-14 18:41:29.000000000,2014-12-19 12:50:39.000000000,2014-12-19 12:50:38.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-11-14 18:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/237c609c1a722e222732dd9144887e1676f1e26a', 'message': 'Move files out of the namespace package\n\nMove oslo.log to oslo_log. Since this library has not been released, we\ndo not need to retain the old interface for compatibility.\n\nbp/drop-namespace-packages\n\nChange-Id: Id8e2312a72af171918fa4d40117ec652018a37bf\n'}, {'number': 2, 'created': '2014-11-19 14:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/042afc9f38d8573487ffe74091ae72fd9452e53c', 'message': 'Move files out of the namespace package\n\nMove oslo.log to oslo_log. Since this library has not been released, we\ndo not need to retain the old interface for compatibility.\n\nbp/drop-namespace-packages\n\nChange-Id: Id8e2312a72af171918fa4d40117ec652018a37bf\n'}, {'number': 3, 'created': '2014-11-20 21:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/dea1d18b786deadf0c1389ef4e19f7077552a5a8', 'message': 'Move files out of the namespace package\n\nMove oslo.log to oslo_log. Since this library has not been released, we\ndo not need to retain the old interface for compatibility.\n\nbp/drop-namespace-packages\n\nChange-Id: Id8e2312a72af171918fa4d40117ec652018a37bf\n'}, {'number': 4, 'created': '2014-12-05 20:13:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/99ae74b7aae2ecbb51b4338ab3bab53ca6f3479f', 'message': 'Move files out of the namespace package\n\nMove oslo.log to oslo_log. Since this library has not been released, we\ndo not need to retain the old interface for compatibility.\n\nbp/drop-namespace-packages\n\nChange-Id: Id8e2312a72af171918fa4d40117ec652018a37bf\n'}, {'number': 5, 'created': '2014-12-09 18:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/5a0d5931438333b3c627184f3c33a75b75535f18', 'message': 'Move files out of the namespace package\n\nMove oslo.log to oslo_log. Since this library has not been released, we\ndo not need to retain the old interface for compatibility.\n\nbp/drop-namespace-packages\n\nChange-Id: Id8e2312a72af171918fa4d40117ec652018a37bf\n'}, {'number': 6, 'created': '2014-12-18 02:43:51.000000000', 'files': ['oslo_log/tests/unit/fixture/test_logging.py', 'oslo_log/tests/unit/test_log.py', 'doc/source/usage.rst', 'oslo_log/context.py', 'oslo_log/fixture/logging.py', 'oslo_log/fixture/__init__.py', 'oslo_log/formatters.py', 'oslo_log/tests/unit/fixture/__init__.py', 'oslo_log/__init__.py', 'openstack-common.conf', 'oslo_log/tests/unit/test_local.py', 'oslo_log/tests/__init__.py', 'oslo_log/handlers.py', 'oslo_log/helpers.py', 'oslo_log/_local.py', 'oslo_log/_options.py', 'oslo_log/tests/unit/__init__.py', 'oslo_log/tests/unit/test_helpers.py', '.testr.conf', 'oslo/__init__.py', 'oslo_log/_i18n.py', 'oslo_log/loggers.py', 'oslo_log/log.py', 'oslo_log/tests/unit/test_context.py', 'setup.cfg', 'tox.ini', 'tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/a5b9c2eccfa90d1c35a5c82e43a34cb766e1d651', 'message': 'Move files out of the namespace package\n\nMove oslo.log to oslo_log. Since this library has not been released, we\ndo not need to retain the old interface for compatibility.\n\nbp/drop-namespace-packages\n\nChange-Id: Id8e2312a72af171918fa4d40117ec652018a37bf\n'}]",7,134622,a5b9c2eccfa90d1c35a5c82e43a34cb766e1d651,25,4,6,2472,,,0,"Move files out of the namespace package

Move oslo.log to oslo_log. Since this library has not been released, we
do not need to retain the old interface for compatibility.

bp/drop-namespace-packages

Change-Id: Id8e2312a72af171918fa4d40117ec652018a37bf
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/22/134622/4 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_log/tests/unit/fixture/test_logging.py', 'oslo_log/tests/unit/test_log.py', 'oslo_log/locale/oslo.log.pot', 'doc/source/usage.rst', 'oslo_log/context.py', 'oslo_log/fixture/logging.py', 'oslo_log/fixture/__init__.py', 'oslo_log/formatters.py', 'oslo_log/locale/oslo.log-log-error.pot', 'oslo_log/tests/unit/fixture/__init__.py', 'oslo_log/__init__.py', 'openstack-common.conf', 'oslo_log/tests/unit/test_local.py', 'oslo_log/tests/__init__.py', 'oslo_log/handlers.py', 'oslo_log/locale/oslo.log-log-critical.pot', 'oslo_log/_local.py', 'oslo_log/_options.py', 'oslo_log/locale/oslo.log-log-warning.pot', 'oslo_log/tests/unit/__init__.py', 'oslo_log/locale/oslo.log-log-info.pot', '.testr.conf', 'oslo_log/_i18n.py', 'oslo_log/loggers.py', 'oslo_log/log.py', 'oslo_log/tests/unit/test_context.py', 'setup.cfg', 'tox.ini', 'tests/__init__.py']",29,237c609c1a722e222732dd9144887e1676f1e26a,bp/drop-namespace-packages,,"# -*- coding: utf-8 -*- # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",28,43
openstack%2Ffuel-plugins~master~Idf66bf1e5c3a39ef55ba61295b55c2bbf0e40748,openstack/fuel-plugins,master,Idf66bf1e5c3a39ef55ba61295b55c2bbf0e40748,"fpb, generate checksums of each file in the plugin",MERGED,2014-12-18 16:58:38.000000000,2014-12-19 12:49:06.000000000,2014-12-19 12:47:31.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-18 16:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/96b1a0b111cd2d0a9dfc2c38bd12743d02aa1700', 'message': ""fpb, generate checksums of each file in the plugin\n\nWithout checksums file it's impossible to find out if\nplugin was changed after installation.\n\nChange-Id: Idf66bf1e5c3a39ef55ba61295b55c2bbf0e40748\nCloses-bug: #1403960\n""}, {'number': 2, 'created': '2014-12-19 10:41:02.000000000', 'files': ['fuel_plugin_builder/CHANGELOG.md', 'fuel_plugin_builder/fuel_plugin_builder/actions/build.py', 'fuel_plugin_builder/fuel_plugin_builder/tests/base.py', 'fuel_plugin_builder/fuel_plugin_builder/tests/test_utils.py', 'fuel_plugin_builder/fuel_plugin_builder/tests/test_build.py', 'fuel_plugin_builder/fuel_plugin_builder/utils.py'], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/857cc39d6358e02fed78bfd0d1a5a785469e1881', 'message': ""fpb, generate checksums of each file in the plugin\n\nWithout checksums file it's impossible to find out if\nplugin was changed after installation.\n\nChange-Id: Idf66bf1e5c3a39ef55ba61295b55c2bbf0e40748\nCloses-bug: #1403960\n""}]",9,142845,857cc39d6358e02fed78bfd0d1a5a785469e1881,23,6,2,8749,,,0,"fpb, generate checksums of each file in the plugin

Without checksums file it's impossible to find out if
plugin was changed after installation.

Change-Id: Idf66bf1e5c3a39ef55ba61295b55c2bbf0e40748
Closes-bug: #1403960
",git fetch https://review.opendev.org/openstack/fuel-plugins refs/changes/45/142845/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_plugin_builder/CHANGELOG.md', 'fuel_plugin_builder/fuel_plugin_builder/actions/build.py', 'fuel_plugin_builder/fuel_plugin_builder/tests/base.py', 'fuel_plugin_builder/fuel_plugin_builder/tests/test_utils.py', 'fuel_plugin_builder/fuel_plugin_builder/tests/test_build.py', 'fuel_plugin_builder/fuel_plugin_builder/utils.py']",6,96b1a0b111cd2d0a9dfc2c38bd12743d02aa1700,bug/1403960,"import hashlib def calculate_md5sum(file_path, chunk_size=2 ** 20): """"""Calculate file's checksum :param str file_path: file path :param int chunk_size: optional parameter, size of chunk :returns: md5sum string """""" md5 = hashlib.md5() with open(file_path, 'rb') as f: for chunk in iter(lambda: f.read(chunk_size), b''): md5.update(chunk) return md5.hexdigest() def calculate_checksums(dir_path): """"""Calculates checksums of files in the directory :param str dir_path: path to the directory :returns: list of dicts, where 'checksum' is md5sum, 'file_path' is a relative path to the file """""" checksums = [] for root, _, files in os.walk(dir_path): for file_path in files: full_path = os.path.join(root, file_path) rel_path = os.path.relpath(full_path, dir_path) checksums.append({ 'checksum': calculate_md5sum(full_path), 'file_path': rel_path}) return checksums def create_checksums_file(dir_path, checksums_file): """"""Creates file with checksums :param str dir_path: path to the directory for checksums calculation :param str checksums_file: path to the file where checksums are saved """""" checksums = calculate_checksums(dir_path) checksums_sorted = sorted(checksums, key=lambda c: c['file_path']) checksum_lines = [ '{checksum} {file_path}\n'.format(**checksum) for checksum in checksums_sorted] with open(checksums_file, 'w') as f: f.writelines(checksum_lines)",,121,0
openstack%2Ffuel-web~master~Ibf16f9705f1e3b468dade809bff098b1ae19c530,openstack/fuel-web,master,Ibf16f9705f1e3b468dade809bff098b1ae19c530,Fix Sahara logs for UI,MERGED,2014-12-18 13:29:37.000000000,2014-12-19 12:46:41.000000000,2014-12-19 12:46:40.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-18 13:29:37.000000000', 'files': ['nailgun/nailgun/settings.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/780b4d871a74d0333cf5adea66bf068921e65443', 'message': 'Fix Sahara logs for UI\n\nLog file for Sahara in 6.0 release was renamed\nfrom sahara-api to sahara-all.\nAlso we should support compatibility with previous\nenvironments.\n\nChange-Id: Ibf16f9705f1e3b468dade809bff098b1ae19c530\nCloses-bug: #1403877\n'}]",0,142778,780b4d871a74d0333cf5adea66bf068921e65443,11,6,1,8749,,,0,"Fix Sahara logs for UI

Log file for Sahara in 6.0 release was renamed
from sahara-api to sahara-all.
Also we should support compatibility with previous
environments.

Change-Id: Ibf16f9705f1e3b468dade809bff098b1ae19c530
Closes-bug: #1403877
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/78/142778/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/settings.yaml'],1,780b4d871a74d0333cf5adea66bf068921e65443,bug/1403877," - id: 'os/sahara-all' name: ""sahara-all"" <<: *remote_openstack_log_type <<: *remote_openstack_log_format <<: *os_log_group path: ""sahara-all.log""",,6,0
openstack%2Fopenstack-manuals~master~I3141f174f70cb9fe7c5daa63bf9f95676b5ad4b0,openstack/openstack-manuals,master,I3141f174f70cb9fe7c5daa63bf9f95676b5ad4b0,Fix docs about sample duplication,MERGED,2014-12-16 16:03:48.000000000,2014-12-19 12:45:45.000000000,2014-12-19 12:45:42.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 3012}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 8290}, {'_account_id': 9382}, {'_account_id': 9562}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-16 16:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e3798bb83ce3a66f328347bbfe06a0fd9dc276d1', 'message': 'Fix docs about sample duplication\n\nCurrently if some metrics  processed in pollsters and in pipeline\ntransformers this leads to sample duplication. This patch adds\nnote about it to docs.\n\nChange-Id: I3141f174f70cb9fe7c5daa63bf9f95676b5ad4b0\n'}, {'number': 2, 'created': '2014-12-17 09:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4dc9d70b2ecc844d26deb5c68b92f8b441a59bb6', 'message': 'Fix docs about sample duplication\n\nCurrently if some metrics  processed in pollsters and in pipeline\ntransformers this leads to sample duplication. This patch adds\nnote about it to docs.\n\nChange-Id: I3141f174f70cb9fe7c5daa63bf9f95676b5ad4b0\n'}, {'number': 3, 'created': '2014-12-17 10:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e830f9072a0afd19eb4a1ebe8e7bc4b7f1c6257c', 'message': 'Fix docs about sample duplication\n\nCurrently if some metrics  processed in pollsters and in pipeline\ntransformers this leads to sample duplication. This patch adds\nnote about it to docs.\n\nChange-Id: I3141f174f70cb9fe7c5daa63bf9f95676b5ad4b0\n'}, {'number': 4, 'created': '2014-12-17 11:44:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2d3e4657cfea4ae3590fe76e6124b8735e783374', 'message': 'Fix docs about sample duplication\n\nCurrently if some metrics  processed in pollsters and in pipeline\ntransformers this leads to sample duplication. This patch adds\nnote about it to docs.\n\nChange-Id: I3141f174f70cb9fe7c5daa63bf9f95676b5ad4b0\n'}, {'number': 5, 'created': '2014-12-17 12:04:33.000000000', 'files': ['doc/admin-guide-cloud/telemetry/section_telemetry-data-collection.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f1f464551b87269ab54c5ebe0f30a394b9568363', 'message': 'Fix docs about sample duplication\n\nCurrently if some metrics  processed in pollsters and in pipeline\ntransformers this leads to sample duplication. This patch adds\nnote about it to docs.\n\nChange-Id: I3141f174f70cb9fe7c5daa63bf9f95676b5ad4b0\n'}]",9,142139,f1f464551b87269ab54c5ebe0f30a394b9568363,27,9,5,13273,,,0,"Fix docs about sample duplication

Currently if some metrics  processed in pollsters and in pipeline
transformers this leads to sample duplication. This patch adds
note about it to docs.

Change-Id: I3141f174f70cb9fe7c5daa63bf9f95676b5ad4b0
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/39/142139/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/telemetry/section_telemetry-data-collection.xml'],1,e3798bb83ce3a66f328347bbfe06a0fd9dc276d1,fix_docs," <note> <para>It should be noted that all the metrics that are obtained from the pollsters already saved, so there is no need to write them also here.</para> </note>",,5,0
openstack%2Fproject-config~master~I27e67a6ea35c12c73f4d5e6142298b5ab99e1b9c,openstack/project-config,master,I27e67a6ea35c12c73f4d5e6142298b5ab99e1b9c,Enable py34 jobs for stackforge/yaql,MERGED,2014-12-19 10:52:48.000000000,2014-12-19 12:40:36.000000000,2014-12-19 12:40:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-12-19 10:52:48.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5bd7207fe13c2c0d9251bb5e2381be4e51492448', 'message': 'Enable py34 jobs for stackforge/yaql\n\nThere is a patch on review which enables Python 3 support:\nhttps://review.openstack.org/#/c/134665/\n\nWe want to make sure it passes py34 in gates.\n\nChange-Id: I27e67a6ea35c12c73f4d5e6142298b5ab99e1b9c\n'}]",0,143036,5bd7207fe13c2c0d9251bb5e2381be4e51492448,8,3,1,7600,,,0,"Enable py34 jobs for stackforge/yaql

There is a patch on review which enables Python 3 support:
https://review.openstack.org/#/c/134665/

We want to make sure it passes py34 in gates.

Change-Id: I27e67a6ea35c12c73f4d5e6142298b5ab99e1b9c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/36/143036/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,5bd7207fe13c2c0d9251bb5e2381be4e51492448,, - name: gate-yaql-python34 voting: false - name: python-jobs check: - gate-yaql-python34, check: - gate-yaql-docs - gate-yaql-pep8 - gate-yaql-python27 gate: - gate-yaql-docs - gate-yaql-pep8 - gate-yaql-python27,4,7
openstack%2Fmagnetodb~master~I522d1ad5a60f2500aecd082af63cf492c5d45ad8,openstack/magnetodb,master,I522d1ad5a60f2500aecd082af63cf492c5d45ad8,Add cassandra driver implementation with custom lsi support,ABANDONED,2014-12-19 11:16:35.000000000,2014-12-19 12:37:46.000000000,,"[{'_account_id': 8601}, {'_account_id': 10676}]","[{'number': 1, 'created': '2014-12-19 11:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/8f643e200a303a3c26a1927c35d317abc7c2b5a5', 'message': 'Add cassandra driver implementation with custom lsi support\n\nChange-Id: I522d1ad5a60f2500aecd082af63cf492c5d45ad8\n'}, {'number': 2, 'created': '2014-12-19 11:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/7b55917b31ee9bc8fb1849e40500c2fbdee29d3d', 'message': 'Add cassandra driver implementation with custom lsi support\n\nChange-Id: I522d1ad5a60f2500aecd082af63cf492c5d45ad8\n'}, {'number': 3, 'created': '2014-12-19 11:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/4e0322a504482a7e7e4c3ce5cc51ca1a6eeada7f', 'message': 'Add cassandra driver implementation with custom lsi support\n\nChange-Id: I522d1ad5a60f2500aecd082af63cf492c5d45ad8\n'}, {'number': 4, 'created': '2014-12-19 11:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/f5b0ddfef1466b74aee0c051e7d8270b7f9214db', 'message': 'Add cassandra driver implementation with custom lsi support\n\nChange-Id: I522d1ad5a60f2500aecd082af63cf492c5d45ad8\n'}, {'number': 5, 'created': '2014-12-19 12:15:52.000000000', 'files': ['contrib/cassandra/magnetodb-cassandra-custom-indices/src/main/java/com/mirantis/magnetodb/cassandra/db/index/MagnetoDBLocalSecondaryIndex.java', 'magnetodb/api/openstack/v1/data/query.py', 'magnetodb/tests/storage/test_cassandra_impl.py', 'contrib/cassandra/magnetodb-cassandra-custom-indices/build.gradle', 'etc/magnetodb-async-task-executor.conf', 'contrib/cassandra/magnetodb-cassandra-custom-indices/src/main/java/com/mirantis/magnetodb/cassandra/db/index/MagnetoDBIndexSearcher.java', 'etc/magnetodb-api.conf', 'magnetodb/tests/storage/test_cassandra_with_custom_lsi_impl.py', 'contrib/devstack/lib/magnetodb', 'magnetodb/common/cassandra/cluster_handler.py', 'magnetodb/storage/driver/cassandra/cassandra_with_custom_lsi_impl.py', 'tools/install_cassandra_ccm.sh', 'etc/magnetodb-streaming-api.conf'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/e7f4350a4d1628afa314c630a9fe26c9f9911c35', 'message': 'Add cassandra driver implementation with custom lsi support\n\nChange-Id: I522d1ad5a60f2500aecd082af63cf492c5d45ad8\n'}]",0,143041,e7f4350a4d1628afa314c630a9fe26c9f9911c35,8,2,5,10676,,,0,"Add cassandra driver implementation with custom lsi support

Change-Id: I522d1ad5a60f2500aecd082af63cf492c5d45ad8
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/41/143041/5 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/cassandra/magnetodb-cassandra-custom-indices/src/main/java/com/mirantis/magnetodb/cassandra/db/index/MagnetoDBLocalSecondaryIndex.java', 'magnetodb/api/openstack/v1/data/query.py', 'magnetodb/tests/storage/test_cassandra_impl.py', 'contrib/cassandra/magnetodb-cassandra-custom-indices/build.gradle', 'etc/magnetodb-async-task-executor.conf', 'contrib/cassandra/magnetodb-cassandra-custom-indices/src/main/java/com/mirantis/magnetodb/cassandra/db/index/MagnetoDBIndexSearcher.java', 'etc/magnetodb-api.conf', 'magnetodb/tests/storage/test_cassandra_with_custom_lsi_impl.py', 'contrib/devstack/lib/magnetodb', 'magnetodb/common/cassandra/cluster_handler.py', 'magnetodb/storage/driver/cassandra/cassandra_with_custom_lsi_impl.py', 'tools/install_cassandra_ccm.sh', 'etc/magnetodb-streaming-api.conf']",13,8f643e200a303a3c26a1927c35d317abc7c2b5a5,master," ""type"": ""magnetodb.storage.driver.cassandra.cassandra_with_custom_lsi_impl.CassandraStorageDriverWithCustomLSI"","," ""type"": ""magnetodb.storage.driver.cassandra.cassandra_impl.CassandraStorageDriver"",",6116,14
openstack%2Ftripleo-ci~master~Ic2ba912ae0c5b1cd18b52db138131ab4f38548ad,openstack/tripleo-ci,master,Ic2ba912ae0c5b1cd18b52db138131ab4f38548ad,temprevert : Move contrib directory to base test directory,MERGED,2014-12-19 04:22:48.000000000,2014-12-19 12:18:54.000000000,2014-12-19 12:18:54.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 8449}, {'_account_id': 10206}]","[{'number': 1, 'created': '2014-12-19 04:22:48.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ee763def522dd28715a4b10383e1a020994a6015', 'message': 'temprevert : Move contrib directory to base test directory\n\nTemporarily reverting a neutron commit while we figure out a permanent\nsolution.\n\nChange-Id: Ic2ba912ae0c5b1cd18b52db138131ab4f38548ad\n'}]",0,142979,ee763def522dd28715a4b10383e1a020994a6015,14,4,1,1926,,,0,"temprevert : Move contrib directory to base test directory

Temporarily reverting a neutron commit while we figure out a permanent
solution.

Change-Id: Ic2ba912ae0c5b1cd18b52db138131ab4f38548ad
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/79/142979/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,ee763def522dd28715a4b10383e1a020994a6015,temprevert,# https://review.openstack.org/#/c/142558/ temprevert neutron 7bc56f030c8bf15336a61ac0d3a513059a00a902 1404115,,2,0
openstack%2Fheat~master~Ib107eff4fe8030fdbb40aa267b9e2b394ff7a186,openstack/heat,master,Ib107eff4fe8030fdbb40aa267b9e2b394ff7a186,Add PropertyUnspecifiedError exception,MERGED,2014-12-05 14:03:16.000000000,2014-12-19 12:17:26.000000000,2014-12-19 12:17:24.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-05 14:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/673eacb19f443e2cfe5853b096009d9c985f1237', 'message': ""Add PropertySpecifyingError excception\n\nIf we have situation, when we must specify at\nleast one of two conflicted resources, and there\nis no specified resource, we get StackValidationFailed\nwith error msg looks like 'Either resource_1 or\nresource_2 must be specified'. There are a few places,\nwhere this situation appears. So it will be reasonable\nto add special exception for these situations.\n\nChange-Id: Ib107eff4fe8030fdbb40aa267b9e2b394ff7a186\n""}, {'number': 2, 'created': '2014-12-05 14:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/71571b6cf311f0ce7db619e755867b3549088111', 'message': ""Add PropertySpecifyingError exception\n\nIf we have situation, when we must specify at\nleast one of two conflicted resources, and there\nis no specified resource, we get StackValidationFailed\nwith error msg looks like 'Either resource_1 or\nresource_2 must be specified'. There are a few places,\nwhere this situation appears. So it will be reasonable\nto add special exception for these situations.\n\nChange-Id: Ib107eff4fe8030fdbb40aa267b9e2b394ff7a186""}, {'number': 3, 'created': '2014-12-10 13:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/22a30e8ec8373913a4fa701d635b3c82db945580', 'message': ""Add PropertySpecifyingError exception\n\nIf we have situation, when we must specify at\nleast one of two conflicted resources, and there\nis no specified resource, we get StackValidationFailed\nwith error msg looks like 'Either resource_1 or\nresource_2 must be specified'. There are a few places,\nwhere this situation appears. So it will be reasonable\nto add special exception for these situations.\n\nChange-Id: Ib107eff4fe8030fdbb40aa267b9e2b394ff7a186""}, {'number': 4, 'created': '2014-12-12 08:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/075f2c563f10c712b9043c58896c6585c728db0e', 'message': ""Add ExclusiveOrPropertyError exception\n\nIf we have situation, when we must specify at\nleast one of two conflicted resources, and there\nis no specified resource, we get StackValidationFailed\nwith error msg looks like 'Either resource_1 or\nresource_2 must be specified'. There are a few places,\nwhere this situation appears. So it will be reasonable\nto add special exception for these situations.\n\nChange-Id: Ib107eff4fe8030fdbb40aa267b9e2b394ff7a186\n""}, {'number': 5, 'created': '2014-12-12 11:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/401090e2d2c5be7c6ce0ced2368669c037f8e136', 'message': ""Add ExclusiveOrPropertyError exception\n\nIf we have situation, when we must specify at\nleast one of two conflicted resources, and there\nis no specified resource, we get StackValidationFailed\nwith error msg looks like 'Either resource_1 or\nresource_2 must be specified'. There are a few places,\nwhere this situation appears. So it will be reasonable\nto add special exception for these situations.\n\nChange-Id: Ib107eff4fe8030fdbb40aa267b9e2b394ff7a186\n""}, {'number': 6, 'created': '2014-12-12 11:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/05694b31a771598857ff2545e5fca66ef0568ec1', 'message': ""Add ExclusiveOrPropertyError exception\n\nIf we have situation, when we must specify at\nleast one of two conflicted resources, and there\nis no specified resource, we get StackValidationFailed\nwith error msg looks like 'Either resource_1 or\nresource_2 must be specified'. There are a few places,\nwhere this situation appears. So it will be reasonable\nto add special exception for these situations.\n\nChange-Id: Ib107eff4fe8030fdbb40aa267b9e2b394ff7a186\n""}, {'number': 7, 'created': '2014-12-15 16:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d8d902232ff7d9446e9951899b6a00d65a429d7f', 'message': ""Add PropertyUnspecifiedError exception\n\nIf we have situation, when we must specify at\nleast one of two conflicted resources, and there\nis no specified resource, we get StackValidationFailed\nwith error msg looks like 'Either resource_1 or\nresource_2 must be specified'. There are a few places,\nwhere this situation appears. So it will be reasonable\nto add special exception for these situations.\n\nChange-Id: Ib107eff4fe8030fdbb40aa267b9e2b394ff7a186\n""}, {'number': 8, 'created': '2014-12-17 15:50:57.000000000', 'files': ['heat/api/middleware/fault.py', 'heat/api/aws/exception.py', 'heat/tests/test_eip.py', 'heat/common/exception.py', 'heat/engine/resources/neutron/neutron.py', 'heat/engine/resources/eip.py', 'heat/engine/resources/neutron/router.py', 'heat/tests/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d50aca8d21ae5511db7c64ca4464365e30d98b6b', 'message': ""Add PropertyUnspecifiedError exception\n\nIf we have situation, when we must specify at\nleast one of two conflicted resources, and there\nis no specified resource, we get StackValidationFailed\nwith error msg looks like 'Either resource_1 or\nresource_2 must be specified'. There are a few places,\nwhere this situation appears. So it will be reasonable\nto add special exception for these situations.\n\nChange-Id: Ib107eff4fe8030fdbb40aa267b9e2b394ff7a186\n""}]",8,139633,d50aca8d21ae5511db7c64ca4464365e30d98b6b,40,7,8,13009,,,0,"Add PropertyUnspecifiedError exception

If we have situation, when we must specify at
least one of two conflicted resources, and there
is no specified resource, we get StackValidationFailed
with error msg looks like 'Either resource_1 or
resource_2 must be specified'. There are a few places,
where this situation appears. So it will be reasonable
to add special exception for these situations.

Change-Id: Ib107eff4fe8030fdbb40aa267b9e2b394ff7a186
",git fetch https://review.opendev.org/openstack/heat refs/changes/33/139633/8 && git format-patch -1 --stdout FETCH_HEAD,"['heat/api/middleware/fault.py', 'heat/common/exception.py', 'heat/tests/test_eip.py', 'heat/engine/resources/neutron/neutron.py', 'heat/engine/resources/eip.py', 'heat/engine/resources/neutron/router.py', 'heat/tests/test_neutron.py']",7,673eacb19f443e2cfe5853b096009d9c985f1237,add-spcf-exc," self.assertRaises(exception.PropertySpecifyingError, ex = self.assertRaises(exception.PropertySpecifyingError, res.validate)"," self.assertRaises(exception.StackValidationFailed, ex = self.assertRaises(exception.StackValidationFailed, res.validate)",28,18
openstack%2Fpuppet-ceph~master~If1ab650e1464a7fe837a2aebb0c2f769e38e6f14,openstack/puppet-ceph,master,If1ab650e1464a7fe837a2aebb0c2f769e38e6f14,"define ceph::rgw, ceph::rgw::apache.",ABANDONED,2014-12-19 12:08:09.000000000,2014-12-19 12:09:46.000000000,,[],"[{'number': 1, 'created': '2014-12-19 12:08:09.000000000', 'files': ['manifests/rgw/apache.pp', 'spec/defines/ceph_rgw_spec.rb', 'Puppetfile', 'spec/spec_helper_system.rb', 'Modulefile', 'manifests/rgw.pp', '.fixtures.yml', 'spec/system/ceph_rgw_apache_spec.rb', 'spec/defines/ceph_rgw_apache_spec.rb', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/22eb68332fb52b9de9d55e2b9a0b1f407776f06a', 'message': 'define ceph::rgw, ceph::rgw::apache.\n\nProvides setup and configuration for the ceph rados gateway.\nAlso includes setup of an apache based frontend, with an\nappropriate virtual host.\nIncludes rspec puppet and rspec system puppet for validation.\n\nChange-Id: If1ab650e1464a7fe837a2aebb0c2f769e38e6f14\n'}]",0,143061,22eb68332fb52b9de9d55e2b9a0b1f407776f06a,2,0,1,11479,,,0,"define ceph::rgw, ceph::rgw::apache.

Provides setup and configuration for the ceph rados gateway.
Also includes setup of an apache based frontend, with an
appropriate virtual host.
Includes rspec puppet and rspec system puppet for validation.

Change-Id: If1ab650e1464a7fe837a2aebb0c2f769e38e6f14
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/61/143061/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/rgw/apache.pp', 'spec/defines/ceph_rgw_spec.rb', 'Puppetfile', 'spec/spec_helper_system.rb', 'Modulefile', 'manifests/rgw.pp', '.fixtures.yml', 'spec/system/ceph_rgw_apache_spec.rb', 'manifests/params.pp', 'spec/defines/ceph_rgw_apache_spec.rb']",10,22eb68332fb52b9de9d55e2b9a0b1f407776f06a,fix/rgw_tests,"# # Copyright (C) 2014 Catalyst IT Limited. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Author: Ricardo Rocha <ricardo@catalyst.net.nz> # require 'spec_helper' describe 'ceph::rgw::apache' do let :pre_condition do 'include ceph::params' end shared_examples_for 'ceph rgw apache' do describe ""activated with default params"" do let :title do 'radosgw.gateway' end it { should contain_apache__vhost('myhost.domain-radosgw').with( { 'servername' => 'myhost.domain', 'serveradmin' => 'root@localhost', 'port' => 80, 'docroot' => '/var/www', 'rewrite_rule' => '^/([a-zA-Z0-9-_.]*)([/]?.*) /s3gw.fcgi?page=$1&params=$2&%{QUERY_STRING} [E=HTTP_AUTHORIZATION:%{HTTP:Authorization},L]', 'access_log_syslog' => true, 'error_log_syslog' => true, 'custom_fragment' => "" FastCgiExternalServer /var/www/s3gw.fcgi -socket /tmp/radosgw.sock AllowEncodedSlashes On ServerSignature Off"", })} it { should contain_class('apache') } it { should contain_class('apache::mod::alias') } it { should contain_class('apache::mod::auth_basic') } it { should contain_apache__mod('fastcgi').with ( { 'package' => 'libapache2-mod-fastcgi' } ) } it { should contain_class('apache::mod::mime') } it { should contain_class('apache::mod::rewrite') } it { should contain_file('/var/www/s3gw.fcgi').with({ 'ensure' => 'file', 'owner' => 'root', 'group' => 'root', 'mode' => '0750', 'content' => ""#!/bin/sh exec /usr/bin/radosgw -c /etc/ceph/ceph.conf -n radosgw.gateway"", })} end describe ""activated with custom params"" do let :title do 'myid' end let :params do { :rgw_dns_name => 'mydns.hostname', :rgw_socket_path => '/some/location/radosgw.sock', :rgw_port => 1111, :admin_email => 'admin@hostname', :fcgi_file => '/some/fcgi/filepath', :syslog => false, } end it { should contain_apache__vhost('mydns.hostname-radosgw').with( { 'servername' => 'mydns.hostname', 'serveradmin' => 'admin@hostname', 'port' => 1111, 'docroot' => '/var/www', 'rewrite_rule' => '^/([a-zA-Z0-9-_.]*)([/]?.*) /s3gw.fcgi?page=$1&params=$2&%{QUERY_STRING} [E=HTTP_AUTHORIZATION:%{HTTP:Authorization},L]', 'access_log_syslog' => false, 'error_log_syslog' => false, 'custom_fragment' => "" FastCgiExternalServer /some/fcgi/filepath -socket /some/location/radosgw.sock AllowEncodedSlashes On ServerSignature Off"", } ) } it { should contain_class('apache') } it { should contain_class('apache::mod::alias') } it { should contain_class('apache::mod::auth_basic') } it { should contain_apache__mod('fastcgi').with ( { 'package' => 'libapache2-mod-fastcgi' } ) } it { should contain_class('apache::mod::mime') } it { should contain_class('apache::mod::rewrite') } it { should contain_file('/some/fcgi/filepath') } end end describe 'Debian Family' do let :facts do { :concat_basedir => '/var/lib/puppet/concat', :fqdn => 'myhost.domain', :hostname => 'myhost', :osfamily => 'Debian', :operatingsystem => 'Ubuntu', :operatingsystemrelease => '12.04', } end end describe 'RedHat Family' do let :facts do { :concat_basedir => '/var/lib/puppet/concat', :fqdn => 'myhost.domain', :hostname => 'myhost', :osfamily => 'RedHat', :operatingsystem => 'RedHat', :operatingsystemrelease => '6', } end end end ",,810,3
openstack%2Fpython-blazarclient~master~I30fa1e65c82db6a1505d5d1e8075b2158bf0b2d3,openstack/python-blazarclient,master,I30fa1e65c82db6a1505d5d1e8075b2158bf0b2d3,Remove unused variable identified by pep8,ABANDONED,2014-12-19 11:35:17.000000000,2014-12-19 12:01:18.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-19 11:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/2345bf50edded6d94edab1091427a88616707d23', 'message': 'Remove unused variable identified by pep8\n\nChange-Id: I30fa1e65c82db6a1505d5d1e8075b2158bf0b2d3\nRelated-Bug: #1404190\n'}, {'number': 2, 'created': '2014-12-19 11:59:28.000000000', 'files': ['climateclient/v1/shell_commands/leases.py'], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/4dc7e5e44f9ee9362fa8f304e6880493c0f8b628', 'message': 'Remove unused variable identified by pep8\n\nChange-Id: Icef260826d84578875af1345c387395bc80cada6\nRelated-Bug: #1404190\n'}]",0,143048,4dc7e5e44f9ee9362fa8f304e6880493c0f8b628,4,1,2,11517,,,0,"Remove unused variable identified by pep8

Change-Id: Icef260826d84578875af1345c387395bc80cada6
Related-Bug: #1404190
",git fetch https://review.opendev.org/openstack/python-blazarclient refs/changes/48/143048/1 && git format-patch -1 --stdout FETCH_HEAD,['climateclient/v1/shell_commands/leases.py'],1,2345bf50edded6d94edab1091427a88616707d23,fix_1404190, except Exception:, except Exception as e:,1,1
openstack%2Fpython-troveclient~master~If08430b07b7e8b6a1737f3e71dba6a471de63794,openstack/python-troveclient,master,If08430b07b7e8b6a1737f3e71dba6a471de63794,Fallback to flavor's str_id when id is None,MERGED,2014-09-23 00:42:05.000000000,2014-12-19 11:54:24.000000000,2014-12-19 11:54:22.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 10215}, {'_account_id': 13355}]","[{'number': 1, 'created': '2014-09-23 00:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/5f43f3119083dde43284505b86aab81b25c925f9', 'message': ""Fallback to flavor's str_id when id is None\n\nWhen a nova flavor's id is a string and not an int, Trove will\nreturn None for the flavor's id and instead expect clients\nto use the str_id field.  This updates the shell to display the\nthe proper id in both cases.\n\nRelies on changes to Trove @ https://review.openstack.org/#/c/115811\n\nChange-Id: If08430b07b7e8b6a1737f3e71dba6a471de63794\n""}, {'number': 2, 'created': '2014-12-13 00:05:55.000000000', 'files': ['troveclient/utils.py', 'troveclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/a90a669c9c03d6bdbecaef8fad162b73d8d0fa9f', 'message': ""Fallback to flavor's str_id when id is None\n\nWhen a nova flavor's id is a string and not an int, Trove will\nreturn None for the flavor's id and instead expect clients\nto use the str_id field.  This updates the shell mask this\nfrom the user and always present the relevant value as id, and\nallow specifying either str_id or id for flavor-show.\n\nfind_resource() was updated to deal with ints and strings, not just\nUUIDs and ints.\n\nRelies on changes to Trove @ https://review.openstack.org/#/c/115811\n\nRelated-bug: #1333852\n\nChange-Id: If08430b07b7e8b6a1737f3e71dba6a471de63794\n""}]",0,123301,a90a669c9c03d6bdbecaef8fad162b73d8d0fa9f,41,8,2,1420,,,0,"Fallback to flavor's str_id when id is None

When a nova flavor's id is a string and not an int, Trove will
return None for the flavor's id and instead expect clients
to use the str_id field.  This updates the shell mask this
from the user and always present the relevant value as id, and
allow specifying either str_id or id for flavor-show.

find_resource() was updated to deal with ints and strings, not just
UUIDs and ints.

Relies on changes to Trove @ https://review.openstack.org/#/c/115811

Related-bug: #1333852

Change-Id: If08430b07b7e8b6a1737f3e71dba6a471de63794
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/01/123301/2 && git format-patch -1 --stdout FETCH_HEAD,['troveclient/v1/shell.py'],1,5f43f3119083dde43284505b86aab81b25c925f9,123301," flavors = [] for f in cs.flavors.list(): if not f.id and hasattr(f, 'str_id'): f.id = f.str_id flavors.append(f) ", flavors = cs.flavors.list(),6,1
openstack%2Fec2-api~master~Ief0c3507fd1c7d7e3262a34cbd1d8bfa1d4a9ace,openstack/ec2-api,master,Ief0c3507fd1c7d7e3262a34cbd1d8bfa1d4a9ace,Extract describe images,MERGED,2014-12-18 22:49:37.000000000,2014-12-19 11:53:37.000000000,2014-12-19 11:53:37.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-18 22:49:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/53bb0b0ed20a5ee9105cc41f95affa94447c722c', 'message': 'Extract describe images\n\nIt was necessary to:\n- extend DB-layer API\n- add ec2util functions to auto insert db items\n- fix and improve Describer class\n- use Describer class for volumes and snapshots\n\nChange-Id: Ief0c3507fd1c7d7e3262a34cbd1d8bfa1d4a9ace\n'}, {'number': 2, 'created': '2014-12-19 05:54:44.000000000', 'files': ['ec2api/api/snapshot.py', 'ec2api/api/cloud.py', 'ec2api/db/sqlalchemy/models.py', 'ec2api/api/ec2utils.py', 'ec2api/exception.py', 'ec2api/db/sqlalchemy/migrate_repo/versions/001_juno.py', 'ec2api/api/image.py', 'ec2api/api/instance.py', 'ec2api/api/volume.py', 'ec2api/db/api.py', 'ec2api/db/sqlalchemy/api.py', 'ec2api/api/common.py', 'ec2api/context.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/daf47b16ef0c42a794cbdcb5c4d71190b07eaf5e', 'message': 'Extract describe images\n\nIt was necessary to:\n- extend DB-layer API\n- add ec2util functions to auto insert db items\n- fix and improve Describer class\n- use Describer class for volumes and snapshots\n\nChange-Id: Ief0c3507fd1c7d7e3262a34cbd1d8bfa1d4a9ace\n'}]",2,142923,daf47b16ef0c42a794cbdcb5c4d71190b07eaf5e,9,3,2,10224,,,0,"Extract describe images

It was necessary to:
- extend DB-layer API
- add ec2util functions to auto insert db items
- fix and improve Describer class
- use Describer class for volumes and snapshots

Change-Id: Ief0c3507fd1c7d7e3262a34cbd1d8bfa1d4a9ace
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/23/142923/2 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/snapshot.py', 'ec2api/api/cloud.py', 'ec2api/db/sqlalchemy/models.py', 'ec2api/api/ec2utils.py', 'ec2api/exception.py', 'ec2api/db/sqlalchemy/migrate_repo/versions/001_juno.py', 'ec2api/api/image.py', 'ec2api/api/instance.py', 'ec2api/api/volume.py', 'ec2api/db/api.py', 'ec2api/db/sqlalchemy/api.py', 'ec2api/api/common.py', 'ec2api/context.py']",13,53bb0b0ed20a5ee9105cc41f95affa94447c722c,master,"def get_admin_context(project_id=None, read_deleted=""no""): project_id=project_id,","def get_admin_context(read_deleted=""no""): project_id=None,",558,111
openstack%2Fpython-troveclient~master~I5554a7d423990ff9cb24437a893d90d212b022b1,openstack/python-troveclient,master,I5554a7d423990ff9cb24437a893d90d212b022b1,Add instance name as parameter to CLI,MERGED,2014-12-04 17:38:22.000000000,2014-12-19 11:50:34.000000000,2014-12-19 11:50:33.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9746}, {'_account_id': 9770}, {'_account_id': 10215}]","[{'number': 1, 'created': '2014-12-04 17:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/7c43fecb7d60ee76ebb111e0db7964769e0fd752', 'message': ""Add instance name as parameter to CLI\n\nAllow CLI to take instance name as well as instance id for\nsub-commands where instance can be specified. This commit\ndoes not include the metadata-* commands as the backend for\nthat feature isn't merged. The spec will be adjusted to\nreflect that they commands will be out of scope.\n\nAffected sub-commands are:\nbackup-create\nbackup-list-instance\nconfiguration-attach\nconfiguration-default\nconfiguration-detach\ncreate (just for --replica_of)\ndatabase-create\ndatabase-delete\ndatabase-list\ndetach-replica\ndelete\nresize-flavor\nresize-instance\nresize-volume\nrestart\nroot-enable\nroot-show\nupdate\nuser-create\nuser-delete\nuser-grant-access\nuser-list\nuser-revoke-access\nuser-show\nuser-show-access\nuser-update-attributes\n\nUnit tests were added to test passing in an instance object\nfor the affected sub-commands. A new set of unit tests were\nadded for databases.py (doesn't look like any existed before).\n\nChange-Id: I5554a7d423990ff9cb24437a893d90d212b022b1\nblueprint: add-instance-name-to-cli\n""}, {'number': 2, 'created': '2014-12-08 19:29:15.000000000', 'files': ['troveclient/v1/root.py', 'troveclient/v1/databases.py', 'troveclient/v1/shell.py', 'troveclient/tests/test_databases.py', 'troveclient/v1/instances.py', 'troveclient/tests/test_users.py', 'troveclient/tests/test_instances.py', 'troveclient/tests/test_backups.py', 'troveclient/v1/backups.py', 'troveclient/v1/users.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/df3afb2abc0d3e7efb1057884e84d8f9a8813881', 'message': ""Add instance name as parameter to CLI\n\nAllow CLI to take instance name as well as instance id for\nsub-commands where instance can be specified. This commit\ndoes not include the metadata-* commands as the backend for\nthat feature isn't merged. The spec will be adjusted to\nreflect that they commands will be out of scope.\n\nAffected sub-commands are:\nbackup-create\nbackup-list-instance\nconfiguration-attach\nconfiguration-default\nconfiguration-detach\ncreate (just for --replica_of)\ndatabase-create\ndatabase-delete\ndatabase-list\ndetach-replica\ndelete\nresize-flavor\nresize-instance\nresize-volume\nrestart\nroot-enable\nroot-show\nupdate\nuser-create\nuser-delete\nuser-grant-access\nuser-list\nuser-revoke-access\nuser-show\nuser-show-access\nuser-update-attributes\n\nUnit tests were added to test passing in an instance object\nfor the affected sub-commands. A new set of unit tests were\nadded for databases.py (doesn't look like any existed before).\n\nChange-Id: I5554a7d423990ff9cb24437a893d90d212b022b1\nblueprint: add-instance-name-to-cli\n""}]",10,139126,df3afb2abc0d3e7efb1057884e84d8f9a8813881,14,7,2,9746,,,0,"Add instance name as parameter to CLI

Allow CLI to take instance name as well as instance id for
sub-commands where instance can be specified. This commit
does not include the metadata-* commands as the backend for
that feature isn't merged. The spec will be adjusted to
reflect that they commands will be out of scope.

Affected sub-commands are:
backup-create
backup-list-instance
configuration-attach
configuration-default
configuration-detach
create (just for --replica_of)
database-create
database-delete
database-list
detach-replica
delete
resize-flavor
resize-instance
resize-volume
restart
root-enable
root-show
update
user-create
user-delete
user-grant-access
user-list
user-revoke-access
user-show
user-show-access
user-update-attributes

Unit tests were added to test passing in an instance object
for the affected sub-commands. A new set of unit tests were
added for databases.py (doesn't look like any existed before).

Change-Id: I5554a7d423990ff9cb24437a893d90d212b022b1
blueprint: add-instance-name-to-cli
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/26/139126/2 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/v1/root.py', 'troveclient/v1/databases.py', 'troveclient/v1/shell.py', 'troveclient/tests/test_databases.py', 'troveclient/v1/instances.py', 'troveclient/tests/test_users.py', 'troveclient/tests/test_instances.py', 'troveclient/tests/test_backups.py', 'troveclient/v1/backups.py', 'troveclient/v1/users.py']",10,7c43fecb7d60ee76ebb111e0db7964769e0fd752,bp/add-instance-name-to-cli," def create(self, instance, users): url = ""/instances/%s/users"" % base.getid(instance) def delete(self, instance, username, hostname=None): url = ""/instances/%s/users/%s"" % (base.getid(instance), user) def get(self, instance, username, hostname=None): url = ""/instances/%s/users/%s"" % (base.getid(instance), user)"," def create(self, instance_id, users): url = ""/instances/%s/users"" % instance_id def delete(self, instance_id, username, hostname=None): url = ""/instances/%s/users/%s"" % (instance_id, user) def get(self, instance_id, username, hostname=None): url = ""/instances/%s/users/%s"" % (instance_id, user)",300,104
openstack%2Fsahara~master~Ib54d471285e38eb2ed08912d3ec1d5427de3be98,openstack/sahara,master,Ib54d471285e38eb2ed08912d3ec1d5427de3be98,Add provision steps for direct engine,ABANDONED,2014-11-14 10:16:26.000000000,2014-12-19 11:34:33.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-11-14 10:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2476c0ebebc606bf5ee283a1795f43f3b22acd27', 'message': 'Add provision step in creating cluster with direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 2, 'created': '2014-11-14 11:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/68cdf19b5acb1e89612ba74728a4b3c00496d350', 'message': 'Add provision step in creating cluster with direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 3, 'created': '2014-11-17 09:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5828d8440fa7e2871aaf6cb30056b309f062de9e', 'message': 'Add provision step in creating cluster with direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 4, 'created': '2014-11-17 12:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/52d58f65b1f8c473a725fff598f75c46119f94fa', 'message': 'Add provision step in creating cluster with direct engine\n\n* Add pereodic task to update provision progress of cluster\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 5, 'created': '2014-11-18 14:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ad971e8e59e40a67399366c32cfa781d827d8ca2', 'message': 'Add provision step in creating cluster with direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 6, 'created': '2014-11-20 10:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c6f1bfd6ba991af5b6baa0ecde08de8bfb211cfb', 'message': 'Add provision step in creating cluster with direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 7, 'created': '2014-11-20 10:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0d9d33812960c1906dd6783bb0c3a0e82fe66db6', 'message': 'Add provision step in creating cluster with direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 8, 'created': '2014-11-20 14:33:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d039d7c254bbef3b86221255337c8b304a4974af', 'message': 'Add provision step in creating cluster with direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 9, 'created': '2014-11-21 11:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/79d22b0f3e885f43babad6b6817d9006b187b390', 'message': 'Add provision step for direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 10, 'created': '2014-11-24 11:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d3ce94be5d7678f6fad0a284ba37e31bd8ee3db8', 'message': 'Add provision steps for direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 11, 'created': '2014-11-24 11:51:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/57d35c90ece94248ecb540a41dd53d582364ad5a', 'message': 'Add provision steps for direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 12, 'created': '2014-11-25 09:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e84a7558a69b98c753bce763f115a02e9a7cd695', 'message': 'Add provision steps for direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 13, 'created': '2014-11-25 14:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/985ecd1491f2560cc596f21d27774e26db66e93b', 'message': 'Add provision steps for direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 14, 'created': '2014-11-26 11:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/75f997ebc7d9479eb956db98cd435b3852778905', 'message': 'Add provision steps for direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}, {'number': 15, 'created': '2014-11-28 10:29:59.000000000', 'files': ['sahara/service/volumes.py', 'sahara/service/engine.py', 'sahara/service/direct_engine.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/18884bc0d72ff634c4f5a47da7db483e5bb884f9', 'message': 'Add provision steps for direct engine\n\nChange-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98\nImplements: blueprint event-log\n'}]",13,134490,18884bc0d72ff634c4f5a47da7db483e5bb884f9,81,9,15,12038,,,0,"Add provision steps for direct engine

Change-Id: Ib54d471285e38eb2ed08912d3ec1d5427de3be98
Implements: blueprint event-log
",git fetch https://review.opendev.org/openstack/sahara refs/changes/90/134490/14 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/volumes.py', 'sahara/service/engine.py', 'sahara/service/direct_engine.py']",3,2476c0ebebc606bf5ee283a1795f43f3b22acd27,bp/event-log,"from oslo.utils import timeutils total_instances = 0 for node_group in cluster.node_groups: total_instances += node_group.count step_id = conductor.cluster_provision_step_add(ctx, cluster.id, { 'step_name': ""Creating new instances"", 'step_type': ""creating"", 'completed': 0, 'total': total_instances, 'successful': None, 'started_at': timeutils.utcnow(), 'completed_at': None, }) self._await_active(cluster, instances, step_id) step_id = conductor.cluster_provision_step_add(ctx, cluster.id, { 'step_name': ""Assign floating ips"", 'step_type': ""creating"", 'completed': 0, 'total': total_instances, 'successful': None, 'started_at': timeutils.utcnow(), 'completed_at': None, }) self._await_networks(cluster, instances, step_id) step_id = conductor.cluster_provision_step_add(ctx, cluster.id, { 'step_name': ""Attach volumes to instances"", 'step_type': ""creating"", 'completed': 0, 'total': total_instances, 'successful': None, 'started_at': timeutils.utcnow(), 'completed_at': None, }) volumes.attach_to_instances(g.get_instances(cluster), step_id) def _await_active(self, cluster, instances, step_id=None): if self._check_if_active(instance, step_id): if step_id: conductor.cluster_event_add( context.ctx(), step_id, { 'node_group_id': instance.node_group_id, 'instance_id': instance.id, 'instance_name': instance.instance_name, 'event_info': None, 'successful': True }) if step_id: conductor.cluster_provision_step_update( context.ctx(), step_id, { 'completed': len(active_ids) }) if step_id: conductor.cluster_provision_step_remove_events( context.ctx(), step_id) conductor.cluster_provision_step_update( context.ctx(), step_id, { 'successful': True, 'completed_at': timeutils.utcnow(), }) def _check_if_active(self, instance, step_id): # NOTE (vgridnev): Event info should updated after # starting using approach with exceptions ids conductor.cluster_event_add(context.ctx(), step_id, { 'node_group_id': instance.node_group_id, 'instance_id': instance.id, 'instance_name': instance.name, 'event_info': ""Node has error status"", 'successful': True }) conductor.cluster_provision_step_update(context.ctx(), step_id, { 'successful': False, }) "," self._await_active(cluster, instances) self._await_networks(cluster, instances) volumes.attach_to_instances(g.get_instances(cluster)) def _await_active(self, cluster, instances): if self._check_if_active(instance): def _check_if_active(self, instance):",148,11
openstack%2Fneutron~master~I1c8a871becb19341c55d515cb9ed604e2d7ea723,openstack/neutron,master,I1c8a871becb19341c55d515cb9ed604e2d7ea723,Imported Translations from Transifex,MERGED,2014-12-19 06:09:47.000000000,2014-12-19 11:11:29.000000000,2014-12-19 10:09:55.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-19 06:09:47.000000000', 'files': ['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-warning.pot', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/neutron.pot', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d6c2e94778eedc6af838ebc66788b76e5b0e5dbe', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1c8a871becb19341c55d515cb9ed604e2d7ea723\n'}]",0,142989,d6c2e94778eedc6af838ebc66788b76e5b0e5dbe,19,15,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I1c8a871becb19341c55d515cb9ed604e2d7ea723
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/142989/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-warning.pot', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/neutron.pot', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po']",13,d6c2e94778eedc6af838ebc66788b76e5b0e5dbe,transifex/translations,"""POT-Creation-Date: 2014-12-19 06:09+0000\n"" ""PO-Revision-Date: 2014-12-19 03:26+0000\n""#: neutron/manager.py:115#: neutron/manager.py:155#: neutron/manager.py:173#: neutron/agent/dhcp_agent.py:602 neutron/agent/l3/agent.py:1762#: neutron/agent/l3/agent.py:1664#: neutron/db/migration/alembic_migrations/heal_script.py:221#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1401#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1584#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1123#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1178 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1195#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1207#: neutron/plugins/ml2/plugin.py:961 neutron/plugins/ml2/plugin.py:1097#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:484#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:578#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1117#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1147#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1429#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:673#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:746#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:887#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:997#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1166","""POT-Creation-Date: 2014-12-17 06:05+0000\n"" ""PO-Revision-Date: 2014-12-16 21:20+0000\n""#: neutron/manager.py:113#: neutron/manager.py:153#: neutron/manager.py:171#: neutron/agent/dhcp_agent.py:602 neutron/agent/l3/agent.py:1732#: neutron/agent/l3/agent.py:1634#: neutron/db/migration/alembic_migrations/heal_script.py:230 #, python-format msgid ""Detected removed foreign key %(fk)r on table %(table)r"" msgstr """" #: neutron/db/migration/alembic_migrations/heal_script.py:235 #, python-format msgid ""Detected added foreign key for column %(fk)r on table %(table)r"" msgstr """" #: neutron/db/migration/alembic_migrations/heal_script.py:257#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1369#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1564#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1119#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1174 #: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1191#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1203#: neutron/plugins/ml2/plugin.py:954 neutron/plugins/ml2/plugin.py:1090#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:480#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:574#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1113#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1143#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1391#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:669#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:742#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:883#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:993#: neutron/plugins/openvswitch/agent/ovs_neutron_agent.py:1162",438,527
openstack%2Fneutron~master~I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde,openstack/neutron,master,I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde,IpsetManager refactoring,MERGED,2014-09-11 15:07:18.000000000,2014-12-19 11:04:39.000000000,2014-12-19 11:04:37.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 8788}, {'_account_id': 8976}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-09-11 15:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1948ea0b56f86b97ab3ed5427c10caf7bcd93521', 'message': 'Ipset / Iptables refactor, for rebasing or followup (WIP)\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n'}, {'number': 2, 'created': '2014-09-11 16:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/88a6c5ed01a1ce5515bde978c8103d70eba43357', 'message': 'Ipset / Iptables refactor, for squashing or followup (WIP)\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n'}, {'number': 3, 'created': '2014-09-11 21:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c72fb8cd2b60d33a78aa2aa43584968020610d3c', 'message': 'Ipset / Iptables refactor, for squashing or followup (WIP)\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n'}, {'number': 4, 'created': '2014-09-11 22:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/302fab989ed0a125ece0138015c60c242da387fc', 'message': ""Ipset / Iptables refactor, for squashing or followup (WIP)\n\nMoves the ipset_chains tracking into the IpsetManager,\nexposing only two public methods. Now the ipset chains\ndiferences are calculated from previous data, deciding\nwhen it's faster to do an atomic bulk chain set, or\nadding/removing modified IPs one by one.\n\nmissing (WIP):\n   - unit test for IpsetManager, now that it has more\n     responsibilities than a thin layer to the system.\n\n   - unit test for the firewall driver, to make sure it\n     calls destroy_ipset_chain_by_name when neccesary.\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 5, 'created': '2014-09-11 22:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e8d6d5ec0859390748d46ec98e5e0af6e24fe215', 'message': ""Ipset / Iptables refactor, for squashing or followup (WIP)\n\nMoves the ipset_chains tracking into the IpsetManager,\nexposing only two public methods. Now the ipset chains\ndiferences are calculated from previous data, deciding\nwhen it's faster to do an atomic bulk chain set, or\nadding/removing modified IPs one by one.\n\nmissing (WIP):\n   - unit test for IpsetManager, now that it has more\n     responsibilities than a thin layer to the system.\n\n   - unit test for the firewall driver, to make sure it\n     calls destroy_ipset_chain_by_name when neccesary.\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 6, 'created': '2014-09-12 09:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aaf007978bb3addabbdc7a17b3c95410a17806a8', 'message': ""Ipset / Iptables refactor, for squashing or followup (WIP)\n\nMoves the ipset_chains tracking into the IpsetManager,\nexposing only two public methods. Now the ipset chains\ndiferences are calculated from previous data, deciding\nwhen it's faster to do an atomic bulk chain set, or\nadding/removing modified IPs one by one.\n\nmissing (WIP):\n   - unit test for IpsetManager, now that it has more\n     responsibilities than a thin layer to the system.\n\n   - unit test for the firewall driver, to make sure it\n     calls destroy_ipset_chain_by_name when neccesary.\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 7, 'created': '2014-09-12 10:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/51201bd6282346222b7d93cbd2a19ac314df65da', 'message': ""Ipset / Iptables refactor, for squashing or followup\n\nMoves the ipset_chains tracking into the IpsetManager,\nexposing only two public methods. Now the ipset chains\ndiferences are calculated from previous data, deciding\nwhen it's faster to do an atomic bulk chain set, or\nadding/removing modified IPs one by one.\n\nNo logical changes to behaviour, just responsibilities\nmoved from one class to another.\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 8, 'created': '2014-09-12 10:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f0200e8b18dedbf7c9bbb8406cfd66c37c8b5b9c', 'message': ""Ipset Manager, for squashing or followup\n\nMoves the ipset_chains tracking into the IpsetManager,\nexposing only two public methods. Now the ipset chains\ndiferences are calculated from previous data, deciding\nwhen it's faster to do an atomic bulk chain set, or\nadding/removing modified IPs one by one.\n\nNo logical changes to behaviour, just responsibilities\nmoved from one class to another.\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 9, 'created': '2014-09-12 12:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a0bad92ea791614b4371d5128eb47b9533f1c8c3', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only two public methods. (set and destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_ipset_chain, _del_ipset_chain_member,\n  _refresh_ipset_chain, and destroy_ipset_chain_by_name.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 10, 'created': '2014-09-16 05:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/331124576db56b51000d80f799045da98c4afc3f', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only two public methods. (set and destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_ipset_chain, _del_ipset_chain_member,\n  _refresh_ipset_chain, and destroy_ipset_chain_by_name.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 11, 'created': '2014-09-16 08:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b471181f731dac7b202a455785f4363d2a679ec8', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only two public methods. (set and destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_ipset_chain, _del_ipset_chain_member,\n  _refresh_ipset_chain, and destroy_ipset_chain_by_name.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 12, 'created': '2014-09-16 11:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4bf37c3ed905b358bcf6651bf7ae20a9bac7d802', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only two public methods. (set and destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_ipset_chain, _del_ipset_chain_member,\n  _refresh_ipset_chain, and destroy_ipset_chain_by_name.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 13, 'created': '2014-09-16 11:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/067369e31e765df46fc4d74d6675a6f25b32a58f', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only two public methods. (set and destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_ipset_chain, _del_ipset_chain_member,\n  _refresh_ipset_chain, and destroy_ipset_chain_by_name.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 14, 'created': '2014-09-16 13:49:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/37b79973b5e725db6d8fde3e78a422d02fae09c8', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 15, 'created': '2014-09-17 09:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1aac8f1c178aec5a61f3b41141f5e7e22958715f', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 16, 'created': '2014-09-17 10:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a3cdebea3bb798383306eed61bb8f63fb3e43ebb', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 17, 'created': '2014-10-31 12:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4f7a8fa83a74e5313633662f77d26852e49244d', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 18, 'created': '2014-11-03 10:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/554b54a7eef970445714ffc8bc896bd1d1c1e999', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 19, 'created': '2014-11-04 10:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0e56834a4179ce81ee11afadc9950e5e2d5abc85', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 20, 'created': '2014-11-26 11:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e1b5c0d1990a1a59400bef7459bc807dbbdf53bd', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 21, 'created': '2014-11-28 12:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9fdc9df0a863555fb6735a713ab499358a1e720e', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 22, 'created': '2014-11-28 16:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c387593cfa5208ec681fd3bfcff6d9f41714f994', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 23, 'created': '2014-11-28 16:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6dca10250298b9c9a50128b4cf5f819b4c56e670', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 24, 'created': '2014-12-03 15:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff4463f2aa123ea7648bb92a6d1eced07212af19', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 25, 'created': '2014-12-04 11:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/878af626cebf9b66b5fb8ad1ed278bc03cc0d114', 'message': ""IpsetManager refactoring\n\nThe motivation for this refactoring is moving all\nthe low level knowledge about the ipset behaviour\nand performance considerations from the firewall driver\nto the manager.\n\n- Reduced redundancy in function names, ie.\n  ipset.set_ipset_chain_members -> ipset.set_members\n\n- Ipsets are sets, not chains all the chain_name\n  are changed to set_name, but for the references in\n  iptables_firewall when it's referencing an iptables\n  chain.\n\n- Moves the ipset_chains tracking into the IpsetManager,\n  exposing only three public methods. (exists, set and\n  destroy)\n\n- Now the ipset chains diferences are calculated from\n  previous data, deciding when it's faster to do an\n  atomic bulk chain set, or adding/removing modified\n  IPs one by one. That was done in the iptables firewall\n  driver before.\n\n- No logical changes to behaviour, just responsibilities\n  moved from one class to another.\n\n- Functional testing is unchanged, just function name changes\n  (public->private) testing the system facing functions:\n  _add_member_to_set, _del_member_from_set, _refresh_set,\n  and destroy.\n\n- Unit testing is added to test the new responsibilities\n  of the class.\n\nImplements: blueprint add-ipset-to-security\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n""}, {'number': 26, 'created': '2014-12-05 12:51:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eff2ca4f1c94ab94e95f462e5ef34019b5b5ca01', 'message': 'IpsetManager refactoring\n\nRefactor the IpsetManager to move all the low level\nknowledge about the ipset behaviour and performance\nconsiderations from the firewall driver to the manager,\nreduce redundant function names, and change missleading\nvariables talking about ipset chains, where they\nshould say ipset sets.\n\nNo logical changes to behaviour, just responsibilities\nmoved from one class to another.\n\nUnit testing is move from iptables_firewall to ipset_manager\nto test the new responsibilities of the class.\n\nImplements: blueprint ipset-manager-refactor\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n'}, {'number': 27, 'created': '2014-12-06 17:22:23.000000000', 'files': ['neutron/agent/linux/iptables_firewall.py', 'neutron/tests/functional/agent/linux/test_ipset.py', 'neutron/tests/unit/agent/linux/test_ipset_manager.py', 'neutron/tests/unit/test_iptables_firewall.py', 'neutron/agent/linux/ipset_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dcd4a11258d2cebbb2f08bd6386e2c8dac0039b2', 'message': 'IpsetManager refactoring\n\nRefactor the IpsetManager to move all the low level\nknowledge about the ipset behaviour and performance\nconsiderations from the firewall driver to the manager,\nreduce redundant function names, and change missleading\nvariables talking about ipset chains, where they\nshould say ipset sets.\n\nNo logical changes to behaviour, just responsibilities\nmoved from one class to another.\n\nUnit testing is move from iptables_firewall to ipset_manager\nto test the new responsibilities of the class.\n\nImplements: blueprint ipset-manager-refactor\n\nChange-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde\n'}]",97,120806,dcd4a11258d2cebbb2f08bd6386e2c8dac0039b2,579,38,27,8788,,,0,"IpsetManager refactoring

Refactor the IpsetManager to move all the low level
knowledge about the ipset behaviour and performance
considerations from the firewall driver to the manager,
reduce redundant function names, and change missleading
variables talking about ipset chains, where they
should say ipset sets.

No logical changes to behaviour, just responsibilities
moved from one class to another.

Unit testing is move from iptables_firewall to ipset_manager
to test the new responsibilities of the class.

Implements: blueprint ipset-manager-refactor

Change-Id: I93000a37a71cd22753b32edbd0a5f3c9cb8b0bde
",git fetch https://review.opendev.org/openstack/neutron refs/changes/06/120806/12 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/iptables_firewall.py', 'neutron/agent/linux/ipset_manager.py']",2,1948ea0b56f86b97ab3ed5427c10caf7bcd93521,bp/ipset-manager-refactor,"IPSET_ADD_BULK_THRESHOLD = 5 self.ipset_chains = {} def _create_ipset_chain(self, chain_name, ethertype): self.ipset_chains[chain_name] = [] def _add_member_to_ipset_chain(self, chain_name, member_ip): self.ipset_chains[chain_name].append(member_ip) def _refresh_ipset_chain_by_name(self, chain_name, ethertype, member_ips): self.ipset_chains[chain_name] = member_ips def _get_new_chain_ips(self, chain_name, expected_ips): new_member_ips = (set(expected_ips) - set(self.ipset_chains.get(chain_name, []))) return list(new_member_ips) def _get_deleted_chain_ips(self, chain_name, expected_ips): deleted_member_ips = (set(self.ipset_chains.get(chain_name, [])) - set(expected_ips)) return list(deleted_member_ips) def _add_ips_to_ipset_chain(self, chain_name, add_ips): for ip in add_ips: if ip not in self.ipset_chains[chain_name]: self._add_member_to_ipset_chain(chain_name, ip) def _del_ips_from_ipset_chain(self, chain_name, del_ips): for ip in del_ips: if ip in self.ipset_chains[chain_name]: self._del_ipset_chain_member(chain_name, ip) def set_ipset_chain_members(self, chain_name, ethertype, member_ips): if chain_name not in self.ipset_chains: self._create_ipset_chain(chain_name, ethertype) self._refresh_ipset_chain(chain_name, ethertype, member_ips) else: add_ips = self._get_new_chain_ips(chain_name, member_ips) del_ips = self._get_deleted_chain_ips(chain_name, member_ips) if (len(add_ips) + len(del_ips) < IPSET_ADD_BULK_THRESHOLD): self._add_ips_to_ipset_chain(chain_name, add_ips) self._del_ips_from_ipset_chain(chain_name, del_ips) else: self._refresh_ipset_chain(chain_name, ethertype, member_ips) def _del_ipset_chain_member(self, chain_name, member_ip): self.ipset_chain[chain_name].remove(member_ip)"," def create_ipset_chain(self, chain_name, ethertype): def add_member_to_ipset_chain(self, chain_name, member_ip): def refresh_ipset_chain_by_name(self, chain_name, member_ips, ethertype): def del_ipset_chain_member(self, chain_name, member_ip):",46,51
openstack%2Fnova~master~Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990,openstack/nova,master,Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990,libvirt: enhance driver to configure guests based on hugepages,MERGED,2014-10-15 16:49:08.000000000,2014-12-19 11:01:50.000000000,2014-12-19 11:01:46.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11642}]","[{'number': 1, 'created': '2014-10-15 16:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5509a62d8898daecb15beb9a50d22e27d275ccbb', 'message': 'libvirt: add method to return memory backing\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 2, 'created': '2014-10-16 11:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9f5d5ea9a173d346e7bcc7e379676242c5ee1b9', 'message': 'libvirt: add method to return memory backing\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 3, 'created': '2014-10-16 16:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/41bcfebba659dbb885b5352482bb7093c3f7baca', 'message': '(WIP) libvirt: add method to return memory backing\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 4, 'created': '2014-10-20 12:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/79ead6ab196d45655394ea83170eeaee6f1288f5', 'message': '(WIP) libvirt: add method to return memory backing\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 5, 'created': '2014-10-20 12:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce3803c57f97252720174a9b8d0aeda4c8fc0e77', 'message': '(WIP) libvirt: add method to return memory backing\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 6, 'created': '2014-10-21 10:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/645291545af91ed1904a92c78b0e7f0bb19ae07e', 'message': 'libvirt: add method to return memory backing\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 7, 'created': '2014-10-21 16:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ee9660bf81708469fb0697d33b86457267b41bd', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 8, 'created': '2014-10-22 09:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ae9bf952b9153bc237929c66c76b6da85d7a9a9', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 9, 'created': '2014-10-24 10:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/79385167d51c812cf409795482eff39198974863', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 10, 'created': '2014-10-24 11:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef3657e9fb3d4c46a95ee45cf719d6e0ae4c4be2', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 11, 'created': '2014-10-24 11:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b1940b786d862705a7924663826d8711cc9f5f8', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 12, 'created': '2014-10-24 12:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19c8fb8616b947ae2c49af5a7a647396ce01fda8', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 13, 'created': '2014-10-27 17:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2af7a2beae9dd6ab87217b10f4e455a7a6bb9728', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 14, 'created': '2014-10-28 08:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/450c4cfb1c7debc6930ada5732648965544a0ebf', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 15, 'created': '2014-10-28 13:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e5a214e7f2f5eb1f717c17240453e0e4a4d59ca', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 16, 'created': '2014-10-28 15:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70ba6c07e0ba4bc56ce1f05d94ea8a2bb59ec98d', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 17, 'created': '2014-10-29 14:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5cdd4a056334511e4527a754758ecdb3e65c4a9a', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 18, 'created': '2014-10-29 15:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12ecb43e7182861b5089168fdd50bf41dfe8f259', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 19, 'created': '2014-10-29 16:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2069354ba143c0426628846087c1452f9846c8a', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 20, 'created': '2014-10-29 22:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e18ae32d19e39eff3b687dda732938f4acd061c9', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 21, 'created': '2014-10-30 08:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1243b5b8c832bfa6098584ef1bd0e7408eb7ecb3', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 22, 'created': '2014-10-30 12:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb6db0633d5f3d1560126cfcedbc5eebae3c3aee', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 23, 'created': '2014-11-05 08:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07b31a6c37aa3b03d76e3dc757e4acba0933ed94', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 24, 'created': '2014-11-06 14:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7bf755a3c5cc43f079d1b742e5e62a63bccecb91', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 25, 'created': '2014-11-06 18:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f4f50989558a945c90c461492046100fd2a1cde', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 26, 'created': '2014-11-12 14:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47c2fcf9fb759ccc725f78091d73431ae281f717', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 27, 'created': '2014-11-13 17:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/491062ecf2d1838f1ac4b35e57bf8760bad47555', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 28, 'created': '2014-11-14 08:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/118495115c6089dc756818e3a23972db8b56d992', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 29, 'created': '2014-11-14 08:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a19137423136d4857a9db2cc199a15b69c92df9b', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 30, 'created': '2014-11-14 16:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f6f6ba8aeacceda24674fe460f741a8e9cf44a5d', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 31, 'created': '2014-12-04 14:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24e2783730cee44b3bdb315ed6dc2daa286c76ca', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 32, 'created': '2014-12-05 08:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c69d56fe45c16052b1d0dc330be8b137f851e37', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 33, 'created': '2014-12-08 17:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f61d2e4ba728f58078c5402bce4c751bec6f1e82', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 34, 'created': '2014-12-08 17:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ded1a9936f59fa2998409e36771c19e55a979a48', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 35, 'created': '2014-12-09 08:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/440b80bd615a421ce99f86fa245b384afed7a5a8', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 36, 'created': '2014-12-09 12:50:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/351124dded1000806b7d1b4a3fbb1d4eb378bef7', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 37, 'created': '2014-12-10 13:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a275aa965442f199a41a26e2d35b737525fd0d22', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 38, 'created': '2014-12-10 14:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5620457ca4c233868cf16f2f47ffaf5523b1c5f0', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 39, 'created': '2014-12-10 15:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49d9b836fb6d30ac44745a66e73d02c7c173e827', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 40, 'created': '2014-12-10 16:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0c5d6a497c0e275e6f2037c1f7d45983a077cbc', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 41, 'created': '2014-12-13 09:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95ea553aaa139c88d2e0807bfd4f663b600bb7da', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 42, 'created': '2014-12-13 10:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98a4a62d3bf5691b57cc81a00c2597282ac90724', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 43, 'created': '2014-12-14 13:18:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/625832d1b30c30f153af34fc5fe3bfdd4b5ac0ea', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 44, 'created': '2014-12-15 11:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb16f771f9ae8def79b44828411dff4dafaf40f0', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 45, 'created': '2014-12-16 11:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0053a59e5197bb40321760a77b5fc0b19bda227b', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 46, 'created': '2014-12-17 14:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e409679c09dc6a557cd6c026de28ca1871982b74', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}, {'number': 47, 'created': '2014-12-17 17:04:00.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f7e69165bb6e0f2cc9f3baf419713707a85cf8a9', 'message': 'libvirt: enhance driver to configure guests based on hugepages\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990\n'}]",15,128703,f7e69165bb6e0f2cc9f3baf419713707a85cf8a9,272,12,47,7730,,,0,"libvirt: enhance driver to configure guests based on hugepages

Work-Item: Enhance libvirt driver to configure guests based on
           the flavour parameter for page sizes

Partial-Implement: blueprint virt-driver-large-pages
Change-Id: Id9d826e83f3ee5720486efb8cb0ff38c0dfcc990
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/128703/44 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,5509a62d8898daecb15beb9a50d22e27d275ccbb,bp/virt-driver-large-pages," def _get_guest_numa_memory_backing_config( self, context, instance, flavor, image_meta): host_topology = self._get_host_numa_topology() inst_topology = self._get_instance_numa_topology(context, instance) request = hardware.get_requested_memory_pagesize(flavor, image_meta) if instance_topology: guest_mem_backing = vconfig.LibvirtConfigGuestMemoryBacking() for instance_cell in instance_topology.cells: page = vconfig.LibvirtConfigGuestMemoryBackingPage() guest_mem_backing.hugepages.append(page) ",,13,0
openstack%2Fhorizon~master~Ia51bb7bb644dc213b3ec3fd3866633700a73c7f9,openstack/horizon,master,Ia51bb7bb644dc213b3ec3fd3866633700a73c7f9,Add collectstatic commands to install doc,MERGED,2014-12-15 19:26:30.000000000,2014-12-19 11:00:09.000000000,2014-12-19 11:00:07.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6162}, {'_account_id': 6610}, {'_account_id': 8040}, {'_account_id': 9317}, {'_account_id': 10063}, {'_account_id': 14124}]","[{'number': 1, 'created': '2014-12-15 19:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d061eb46d61e85e52300f3b4b0d05610a2f87d89', 'message': 'Add collectstatic commands to install doc\n\nAdded directions on how to run collectstatic as part of the install\nprocess.  Fixing obvious typos as well.\n\nChange-Id: Ia51bb7bb644dc213b3ec3fd3866633700a73c7f9\nCloses-Bug: 1392804\n'}, {'number': 2, 'created': '2014-12-16 16:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5fca7190760dc07cf1d077b1dbee0710c1aebbd8', 'message': 'Add collectstatic commands to install doc\n\nAdded directions on how to run collectstatic as part of the install\nprocess.  Fixing obvious typos as well.\n\nChange-Id: Ia51bb7bb644dc213b3ec3fd3866633700a73c7f9\nCloses-Bug: 1392804\n'}, {'number': 3, 'created': '2014-12-16 16:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/26a9b2255933a82a48b0777cdbb65c1d7391fcf8', 'message': 'Add collectstatic commands to install doc\n\nAdded directions on how to run collectstatic as part of the install\nprocess.  Fixing obvious typos as well.\n\nChange-Id: Ia51bb7bb644dc213b3ec3fd3866633700a73c7f9\nCloses-Bug: 1392804\n'}, {'number': 4, 'created': '2014-12-16 16:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/81487d6cf0dc606df4609295c2092272602ec4bc', 'message': 'Add collectstatic commands to install doc\n\nAdded directions on how to run collectstatic as part of the install\nprocess.  Fixing obvious typos as well.\n\nChange-Id: Ia51bb7bb644dc213b3ec3fd3866633700a73c7f9\nCloses-Bug: 1392804\n'}, {'number': 5, 'created': '2014-12-18 14:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ab4872606c30551cf2f4930adcdfabab397ac2ec', 'message': 'Add collectstatic commands to install doc\n\nAdded directions on how to run collectstatic and compress as part of the\ninstall process.  Fixing obvious typos as well.\n\nChange-Id: Ia51bb7bb644dc213b3ec3fd3866633700a73c7f9\nCloses-Bug: 1392804\n'}, {'number': 6, 'created': '2014-12-18 18:40:15.000000000', 'files': ['doc/source/topics/install.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/dee9385a66bc81df35509f3bcf8d15e190357dc6', 'message': 'Add collectstatic commands to install doc\n\nAdded directions on how to run collectstatic and compress as part of the\ninstall process.  Fixing obvious typos as well.\n\nChange-Id: Ia51bb7bb644dc213b3ec3fd3866633700a73c7f9\nCloses-Bug: 1392804\n'}]",8,141885,dee9385a66bc81df35509f3bcf8d15e190357dc6,39,10,6,14124,,,0,"Add collectstatic commands to install doc

Added directions on how to run collectstatic and compress as part of the
install process.  Fixing obvious typos as well.

Change-Id: Ia51bb7bb644dc213b3ec3fd3866633700a73c7f9
Closes-Bug: 1392804
",git fetch https://review.opendev.org/openstack/horizon refs/changes/85/141885/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/topics/install.rst'],1,d061eb46d61e85e52300f3b4b0d05610a2f87d89,bug/1392804," in the top directory::4. Collect static files into the appropriate directory. Run the following commands:: $ ./manage.py collectstatic Optional: If you want the static files to be compressed or minified, you'll need to configure your local_settings.py to specify ``COMPRESS_OFFLINE = True``, then run the following command:: $ ./manage.py compress 5. Set up a web server with WSGI support. ``/etc/apache2/sites-available/horizon.conf``.6. Finally, enable the above configuration and restart the web server.::"," in the top directory.::4. Set up a web server with WSGI support. ``/etc/apache2/site-available/horizon.conf``.5. Finally, enable the above configuration and restart the web server.::",15,4
openstack%2Ftrove~master~I9eae06f564c4f99255fc627dbd26006d9048be46,openstack/trove,master,I9eae06f564c4f99255fc627dbd26006d9048be46,remove keystonemiddleware settings from api-paste.ini,MERGED,2014-11-10 13:27:20.000000000,2014-12-19 10:59:44.000000000,2014-12-19 10:59:44.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 6413}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-11-10 13:27:20.000000000', 'files': ['etc/trove/api-paste.ini'], 'web_link': 'https://opendev.org/openstack/trove/commit/45b7614bedecc7dfa3b074af88b08a470fd124a3', 'message': 'remove keystonemiddleware settings from api-paste.ini\n\nThey can/should be set in the trove.conf instead, to\ncentralize all user-preserved/editable changes in the main\nconfiguration file, and allow the ability to track api-paste.ini\nunmodified from master.\n\nChange-Id: I9eae06f564c4f99255fc627dbd26006d9048be46\n'}]",0,133470,45b7614bedecc7dfa3b074af88b08a470fd124a3,21,4,1,6593,,,0,"remove keystonemiddleware settings from api-paste.ini

They can/should be set in the trove.conf instead, to
centralize all user-preserved/editable changes in the main
configuration file, and allow the ability to track api-paste.ini
unmodified from master.

Change-Id: I9eae06f564c4f99255fc627dbd26006d9048be46
",git fetch https://review.opendev.org/openstack/trove refs/changes/70/133470/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/trove/api-paste.ini'],1,45b7614bedecc7dfa3b074af88b08a470fd124a3,,,"auth_host = 127.0.0.1 auth_port = 35357 auth_protocol = http admin_tenant_name = %SERVICE_TENANT_NAME% admin_user = %SERVICE_USER% admin_password = %SERVICE_PASSWORD% # signing_dir is configurable, but the default behavior of the authtoken # middleware should be sufficient. It will create a temporary directory # in the home directory for the user the trove process is running as. #signing_dir = /var/lib/trove/keystone-signing",0,10
openstack%2Fcookbook-openstack-identity~master~Ieb0d88b28d3255d71b46599b87ab9f0c1d313cf8,openstack/cookbook-openstack-identity,master,Ieb0d88b28d3255d71b46599b87ab9f0c1d313cf8,Fix incorrect default for token expiration,MERGED,2014-11-21 20:08:22.000000000,2014-12-19 10:52:54.000000000,2014-12-19 10:52:53.000000000,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 7634}, {'_account_id': 11915}, {'_account_id': 12588}, {'_account_id': 13252}]","[{'number': 1, 'created': '2014-11-21 20:08:22.000000000', 'files': ['attributes/default.rb', 'spec/server_spec.rb', 'CHANGELOG.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/d072e121eae12583da55ea77a9ac71a1e626e59e', 'message': 'Fix incorrect default for token expiration\n\nChange-Id: Ieb0d88b28d3255d71b46599b87ab9f0c1d313cf8\nCloses-Bug: #1395178\n'}]",0,136478,d072e121eae12583da55ea77a9ac71a1e626e59e,11,6,1,7128,,,0,"Fix incorrect default for token expiration

Change-Id: Ieb0d88b28d3255d71b46599b87ab9f0c1d313cf8
Closes-Bug: #1395178
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/78/136478/1 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'spec/server_spec.rb', 'CHANGELOG.md']",3,d072e121eae12583da55ea77a9ac71a1e626e59e,bug/1395178,* Fix token expiration default value,,4,2
openstack%2Fnova~master~I9246faed2c33d6a90d9568c177cdebdd5296d223,openstack/nova,master,I9246faed2c33d6a90d9568c177cdebdd5296d223,Fix mock assertions in libvirt unit tests,ABANDONED,2014-11-26 21:30:31.000000000,2014-12-19 10:42:30.000000000,,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 7219}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-26 21:30:31.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/19ecc564d2c2d73eae83b3ac468c19a02d017286', 'message': ""Fix mock assertions in libvirt unit tests\n\nassert_not_called and assert_called are not valid methods for making\nassertions about the state of a mock. Calling them creates child mocks.\n\nThis patch replaces these false assertions with ones that check the\nvalue of the relevant mock's called attribute.\n\nChange-Id: I9246faed2c33d6a90d9568c177cdebdd5296d223\n""}]",2,137477,19ecc564d2c2d73eae83b3ac468c19a02d017286,13,9,1,7219,,,0,"Fix mock assertions in libvirt unit tests

assert_not_called and assert_called are not valid methods for making
assertions about the state of a mock. Calling them creates child mocks.

This patch replaces these false assertions with ones that check the
value of the relevant mock's called attribute.

Change-Id: I9246faed2c33d6a90d9568c177cdebdd5296d223
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/137477/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/libvirt/test_driver.py'],1,19ecc564d2c2d73eae83b3ac468c19a02d017286,mock_asserts, self.assertTrue(mock_info.called) self.assertFalse(mock_instance.save.called) self.assertFalse(mock_instance.save.called) self.assertFalse(mock_instance.save.called), mock_info.assert_called() mock_instance.save.assert_not_called() mock_instance.save.assert_not_called() mock_instance.save.assert_not_called(),4,4
openstack%2Fcookbook-openstack-ops-database~master~I64a10ed7938353098eb2e0e9d42ed51c008a47e6,openstack/cookbook-openstack-ops-database,master,I64a10ed7938353098eb2e0e9d42ed51c008a47e6,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:55:56.000000000,2014-12-19 10:40:10.000000000,2014-12-19 10:40:09.000000000,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 11915}]","[{'number': 1, 'created': '2014-12-05 03:55:56.000000000', 'files': ['CONTRIBUTING.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/392fabb2c61e25b59cde90b5b05de8bdce1b98b5', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I64a10ed7938353098eb2e0e9d42ed51c008a47e6\n'}]",0,139454,392fabb2c61e25b59cde90b5b05de8bdce1b98b5,9,3,1,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: I64a10ed7938353098eb2e0e9d42ed51c008a47e6
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-database refs/changes/54/139454/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.md'],1,392fabb2c61e25b59cde90b5b05de8bdce1b98b5,infra-manual,you must follow the steps in this page: http://docs.openstack.org/infra/manual/developers.html http://docs.openstack.org/infra/manual/developers.html#development-workflow,"you must follow the steps in the ""If you're a developer"" section of this page: http://wiki.openstack.org/HowToContribute http://wiki.openstack.org/GerritWorkflow",3,4
openstack%2Ftooz~master~I81cae059763540bced5cbae428baa3aa7799aa66,openstack/tooz,master,I81cae059763540bced5cbae428baa3aa7799aa66,README.rst tweaks,MERGED,2014-12-19 07:45:06.000000000,2014-12-19 10:38:16.000000000,2014-12-19 10:38:16.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-12-19 07:45:06.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/tooz/commit/74a85505c4688b5bf055c0d8f07955d632e3c3d9', 'message': 'README.rst tweaks\n\nAdd the links that other oslo projects\nREADME.rst have so that new people to oslo\nand tooz can find where to go.\n\nChange-Id: I81cae059763540bced5cbae428baa3aa7799aa66\n'}]",0,143005,74a85505c4688b5bf055c0d8f07955d632e3c3d9,6,2,1,1297,,,0,"README.rst tweaks

Add the links that other oslo projects
README.rst have so that new people to oslo
and tooz can find where to go.

Change-Id: I81cae059763540bced5cbae428baa3aa7799aa66
",git fetch https://review.opendev.org/openstack/tooz refs/changes/05/143005/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,74a85505c4688b5bf055c0d8f07955d632e3c3d9,,Tooz * Free software: Apache license * Documentation: http://docs.openstack.org/developer/tooz * Source: http://git.openstack.org/cgit/openstack/tooz * Bugs: http://bugs.launchpad.net/python-tooz/ Join us ------- - http://launchpad.net/python-tooz,tooz,11,1
openstack%2Fceilometer~master~I3485a27ae66e255fbc460d0548be9dbb5700fa42,openstack/ceilometer,master,I3485a27ae66e255fbc460d0548be9dbb5700fa42,Clean up bin directory,MERGED,2014-12-18 05:58:01.000000000,2014-12-19 10:24:56.000000000,2014-12-19 10:24:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 7052}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-18 05:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6bc72f58ffe24da6c8643159e5856a2392b890d8', 'message': ""Clean up bin directory\n\nMove ceilometer-test-event.py from directory bin to directory tools,\nsince it's for test purpose.\n\nChange-Id: I3485a27ae66e255fbc460d0548be9dbb5700fa42\n""}, {'number': 2, 'created': '2014-12-18 07:04:35.000000000', 'files': ['tools/ceilometer-test-event.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b1b6c17516def8d583a523b3ece9b98d388bddb6', 'message': ""Clean up bin directory\n\nMove ceilometer-test-event.py from directory bin to directory tools,\nsince it's for test purpose.\n\nChange-Id: I3485a27ae66e255fbc460d0548be9dbb5700fa42\n""}]",0,142673,b1b6c17516def8d583a523b3ece9b98d388bddb6,15,8,2,4491,,,0,"Clean up bin directory

Move ceilometer-test-event.py from directory bin to directory tools,
since it's for test purpose.

Change-Id: I3485a27ae66e255fbc460d0548be9dbb5700fa42
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/73/142673/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/ceilometer-test-event.py'],1,6bc72f58ffe24da6c8643159e5856a2392b890d8,cleanup,,,0,0
openstack%2Fopenstack-ansible~stable%2Fjuno~I916b7013c7f241435836fb75ef40665164b01867,openstack/openstack-ansible,stable/juno,I916b7013c7f241435836fb75ef40665164b01867,changed swift to use the proper tag,MERGED,2014-12-19 02:21:33.000000000,2014-12-19 10:18:39.000000000,2014-12-19 10:18:39.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9515}, {'_account_id': 9884}, {'_account_id': 12892}]","[{'number': 1, 'created': '2014-12-19 02:21:33.000000000', 'files': ['rpc_deployment/vars/repo_packages/swift.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e4064781beb70fbfaeb59f6018b4ea75f9264ac9', 'message': 'changed swift to use the proper tag\n\nSwift.yml was pinned to the wrong tag. This made it impossible to install /\nbuild for swift. To fix this issue the tag was set to the stable/juno\nrelease tag at ""2.2.0"".\n\nCloses-Bug: 1403588\nChange-Id: I916b7013c7f241435836fb75ef40665164b01867\n'}]",0,142957,e4064781beb70fbfaeb59f6018b4ea75f9264ac9,11,7,1,7353,,,0,"changed swift to use the proper tag

Swift.yml was pinned to the wrong tag. This made it impossible to install /
build for swift. To fix this issue the tag was set to the stable/juno
release tag at ""2.2.0"".

Closes-Bug: 1403588
Change-Id: I916b7013c7f241435836fb75ef40665164b01867
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/57/142957/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/vars/repo_packages/swift.yml'],1,e4064781beb70fbfaeb59f6018b4ea75f9264ac9,bug/1403588,git_install_branch: 2.2.0,git_install_branch: 2014.2,1,1
openstack%2Ftricircle~master~If2224b8760229020020bcda6e43d029b8af7a813,openstack/tricircle,master,If2224b8760229020020bcda6e43d029b8af7a813,add script module for tricircle options,MERGED,2014-12-19 10:16:39.000000000,2014-12-19 10:17:09.000000000,2014-12-19 10:17:09.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-12-19 10:16:39.000000000', 'files': ['script/tricircle.cfg', 'script/config.py', 'script/exec.sh', 'script/__init__.py', 'script/README.md'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/9ed9344fc27d2912772e5da3784d04452a963d5e', 'message': 'add script module for tricircle options\n\nadd script module for tricircle options\n\nChange-Id: If2224b8760229020020bcda6e43d029b8af7a813\n'}]",0,143028,9ed9344fc27d2912772e5da3784d04452a963d5e,6,2,1,9684,,,0,"add script module for tricircle options

add script module for tricircle options

Change-Id: If2224b8760229020020bcda6e43d029b8af7a813
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/28/143028/1 && git format-patch -1 --stdout FETCH_HEAD,"['script/config.py', 'script/tricircle.cfg', 'script/exec.sh', 'script/__init__.py', 'script/README.md']",5,9ed9344fc27d2912772e5da3784d04452a963d5e,,"Tricircle Configuration Options Updating Module =============================================== In Tricircle Project, we added many options in the *.conf files for cascading, these options among nova, glance, neutron, cinder. When deploy the cascading environment, these options should be modified based on the deployment context(IP, tenant, user, password etc.), so we have to modify each install scripts(/installation) every time for deployment because the options is configured by these scripts. It is inconvenient. This script module is created in order to managing the options in *.conf with a centralized way. It is independent of the installation scripts, but the scripts can invoke the function in it to finish the options' configuration. Composition ------ * **config.py**: the implementation to execute options updating, using python build-in lib:ConfigParser. * **tricircle.cfg**: the options you want to update are stored here. * **exec.sh**: a very simple shell commend to invoke the python code. Usage ------- - Format of the tricircle.cfg The tricircle.cfg is standard python config file(like nova.conf in /etc/nova), it contains sections and options in each section like what the *.conf is in it. The only difference is the **Naming Conventions** of the section: + Every section name start with the openstack service config-file name (nova/neutron/glance-api/cinder); + If the option to be updated needs in a special section in *.conf, the special section (keystone_authtoken e.g) should be added to the end of the section name with '_' ahead of it. For example, if the 'auth_host' option in nova.conf need be updated, it should in 'nova_keystone_authtoken' section in the tricircle.cfg. - Execution After you configured the options in tricircle.cfg, run the commend: ```python config.py [openstack-service-name]``` If you want update all services' options in tricircle.cfg, run ```python config.py all```. + **Note**: you can execute multiple times for an option with different value and do not worry about it appears multiple times in *.conf, only the latest value in the conf file. ",,233,0
openstack%2Fnova-specs~master~I49ba47c99b9deb6b1ef5707329075713be33890d,openstack/nova-specs,master,I49ba47c99b9deb6b1ef5707329075713be33890d,Libvirt hardware policy from libosinfo,MERGED,2014-11-12 12:52:08.000000000,2014-12-19 10:16:34.000000000,2014-12-19 10:16:33.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 6772}, {'_account_id': 6962}, {'_account_id': 7730}, {'_account_id': 8574}, {'_account_id': 8802}]","[{'number': 1, 'created': '2014-11-12 12:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f23135a519d53e2dc1a082111b0815a8571c98da', 'message': 'Libvirt hardware policy from libosinfo\n\nWhen launching an instance Nova needs to make decisions about how to\nconfigure the virtual hardware. Currently these decisions are often\nhardcoded, or driven by nova.conf settings, and sometimes by glance\nimage properties. The goal of this feature is to allow the user to\nspecify the guest OS type and then drive decisions from this fact,\nusing the libosinfo database.\n\nChange-Id: I49ba47c99b9deb6b1ef5707329075713be33890d\nBlueprint: libvirt-hardware-policy-from-libosinfo\n'}, {'number': 2, 'created': '2014-12-03 11:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/27a8483f0a9a363ac6d55949674e15c846e7ab9f', 'message': 'Libvirt hardware policy from libosinfo\n\nWhen launching an instance Nova needs to make decisions about how to\nconfigure the virtual hardware. Currently these decisions are often\nhardcoded, or driven by nova.conf settings, and sometimes by glance\nimage properties. The goal of this feature is to allow the user to\nspecify the guest OS type and then drive decisions from this fact,\nusing the libosinfo database.\n\nChange-Id: I49ba47c99b9deb6b1ef5707329075713be33890d\nBlueprint: libvirt-hardware-policy-from-libosinfo\n'}, {'number': 3, 'created': '2014-12-05 15:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/77b1e25f90c3a3900896414029324101e378a1e0', 'message': 'Libvirt hardware policy from libosinfo\n\nWhen launching an instance Nova needs to make decisions about how to\nconfigure the virtual hardware. Currently these decisions are often\nhardcoded, or driven by nova.conf settings, and sometimes by glance\nimage properties. The goal of this feature is to allow the user to\nspecify the guest OS type and then drive decisions from this fact,\nusing the libosinfo database.\n\nChange-Id: I49ba47c99b9deb6b1ef5707329075713be33890d\nBlueprint: libvirt-hardware-policy-from-libosinfo\n'}, {'number': 4, 'created': '2014-12-19 10:08:09.000000000', 'files': ['specs/kilo/approved/libvirt-hardware-policy-from-libosinfo.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a22ba2dedaa977af3718dfe54e3cbad6fe1aad3f', 'message': 'Libvirt hardware policy from libosinfo\n\nWhen launching an instance Nova needs to make decisions about how to\nconfigure the virtual hardware. Currently these decisions are often\nhardcoded, or driven by nova.conf settings, and sometimes by glance\nimage properties. The goal of this feature is to allow the user to\nspecify the guest OS type and then drive decisions from this fact,\nusing the libosinfo database.\n\nChange-Id: I49ba47c99b9deb6b1ef5707329075713be33890d\nBlueprint: libvirt-hardware-policy-from-libosinfo\n'}]",21,133945,a22ba2dedaa977af3718dfe54e3cbad6fe1aad3f,29,10,4,1779,,,0,"Libvirt hardware policy from libosinfo

When launching an instance Nova needs to make decisions about how to
configure the virtual hardware. Currently these decisions are often
hardcoded, or driven by nova.conf settings, and sometimes by glance
image properties. The goal of this feature is to allow the user to
specify the guest OS type and then drive decisions from this fact,
using the libosinfo database.

Change-Id: I49ba47c99b9deb6b1ef5707329075713be33890d
Blueprint: libvirt-hardware-policy-from-libosinfo
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/45/133945/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/libvirt-hardware-policy-from-libosinfo.rst'],1,f23135a519d53e2dc1a082111b0815a8571c98da,bp/libvirt-hardware-policy-from-libosinfo,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================== Libvirt hardware policy from libosinfo ====================================== https://blueprints.launchpad.net/nova/+spec/libvirt-hardware-policy-from-libosinfo When launching an instance Nova needs to make decisions about how to configure the virtual hardware. Currently these decisions are often hardcoded, or driven by nova.conf settings, and sometimes by glance image properties. The goal of this feature is to allow the user to specify the guest OS type and then drive decisions from this fact, using the libosinfo database. Problem description =================== When launching an instance Nova needs to make decisions about how to configure the virtual hardware in order to optimize operation of the guest OS. The right decision inevitably varies depending on the type of operating system being run. The right decision for a Linux guest, might be the wrong decision for a Windows guest or vica-verca. The most important example is the choice of the disk and network device models. All Linux guests want to use virtio, since it offers by far the best performance, but this is not available out of the box in Windows images so is a poor default for them. A second example is whether the BIOS clock is initialized with UTC (preferred by UNIX) or localtime (preferred by Windows). Related to the clock are various timer policy settings which control behaviour when the hypervisor cannot keep up with the required interrupt injection rate. The Nova defaults work for Linux and Windows, but are not suitable for some other proprietary operating systems. While it is possible to continue to allow overrides of config via glance image properties this is not an particularly appealing approach. A number of the settings a pretty low level and so not the kind of thing that a cloud application should directly expose to users. The more hypervisor specific settings are placed on a glance image, the harder it is for one image to be used to boot VMs across multiple different hypervisors. It also creates a burden on the user to remember a long list of settings they must place on the images to obtain optimal operation. Historically most virtualization applications have gone down the route of creating a database of hardware defaults for each operating system. Typically though, each project has tried to reinvent the wheel each time duplicating each others work leading to a plethora of incomplete & inconsistent databases. The libosinfo project started as an attempt to provide a common solution for virtualization applications to use when configuring virtual machines. It provides a, user extendable, database of information about operating systems, including facts such as the supported device types, minimum resource level requirements, installation media and more. Around this database is a C API for querying information, made accessible to non-C languages (including python) via the magic of GObject Introspection. This is in use by the virt-manager and GNOME boxes applications for configuring KVM and Xen guests and is easily consumable from Nova's libvirt driver. Use Cases ---------- The core goal is to make it simpler for an end user to boot a disk image with the optimal virtual hardware configuration for the guest operating system. Project Priority ----------------- None. Proposed change =============== There is an existing 'os_type' glance property that can be used to indicate the overall operating system family (windows vs linux vs freebsd). This is too coarse to be able to correctly configure all the different versions of these operating systems. ie the right settings for Windows XP are not the same as the right settings for Windows 2008. The intention is to a declare support for a new standard property 'os_name'. The acceptable values for this property will be taken from the libosinfo database, either of these attributes: * 'short-id' - the short name of the OS eg fedora21, winxp, freebsd9.3 * 'id' - the unique URI identifier of the OS eg http://fedoraproject.org/fedora/21, http://microsoft.com/win/xp, http://freebsd.org/freebsd/9.3 For example the user can set one of: ''' # glance image-update \ --property os_name=fedora21 \ name-of-my-fedora-image # glance image-update \ --property os_name=http://fedoraproject.org/fedora/21 \ name-of-my-fedora-image When building the guest configuration, the Nova libvirt driver will look for this 'os_name' property and query the libosinfo database to locate the operating system records. It will then use this to choose the default disk bus and network model. If available it will also lookup clock and timer settings, but this requires further development in libosinfo before it can be used. In the case that libosinfo is not installed on the compute host, the current Nova libvirt driver functionality will be unchanged. It may be desirable to add a new nova.conf setting in the '[libvirt]' section to turn on/off the use of libosinfo for hardware configuration. This would make it easier for the cloud admin to control behaviour without having to change which RPMs/packages are installed. eg ''' [libvirt] hardware_config=default|fixed|libosinfo Where * default - try to use libosinfo, otherwise fallback to fixed defautls * fixed - always use fixed defaults even if libosinfo is installed * libosinfo - always use libosinfo and abort if not installed In the future it might be possible to automatically detect what operating system is present inside a disk image using libguestfs. This would remove the need to even set the 'os_name' image property, and thus allow people to obtain optimal guest performance out of the box with no special config tasks required. Such auto-detection is out of scope for this blueprint though. Alternatives ------------ A 1st alternative would be for Nova to maintain its own database of preferred hardware settings for each operating system. This is the trap most previous virtualization applications have fallen into. This has a significant burden because of the huge variety of operating systems in existance. It is undesirable to attempt to try to reinvent the libosinfo wheel which is already mostly round in shape. An 2nd alternative would be for Nova to expose glance image properties for every single virtual hardware configuration aspect that needs to vary per guest operating system type. This would mean the user is required to have a lot of knowledge about low level hardware configuration which goes against the general cloud paradigm. It is also a significant burden to remember to set so many values. Data model impact ----------------- There will be no database schema changes. There will be a new standard glance image property defined which will be stored in the existing database tables, and should be considered a long term supported setting. REST API impact --------------- There are no API changes required. The existing glance image property support is sufficient to achieve the goals of this blueprint. Security impact --------------- Since this is simply about tuning the choice of virtual hardware settings there should not be any impact on security of the host / cloud system. Notifications impact -------------------- No change. Other end user impact --------------------- The end user will need to know about the 'os_name' glance property and the list of permissible values, as defined by the libosinfo project. This is primarily a documentation task. Performance Impact ------------------ Broadly speaking there should be no performance impact on the operation of the OpenStack services themselves. Some choices of guest hardware, however, might impose extra CPU overhead on the hypervisors. Since users already have the ability to choose different disk/net models directly, this potential performance impact is not a new (or significant) concern. It falls under the general problem space of achieving strong separation between guest virtual machines via resource utilization limits. Other deployer impact --------------------- There is likely to be a new configuration option in the nova.conf file under the libvirt group. Most deployers can ignore this and leave it on its default value which should just ""do the right thing"" in normal operation. It is there as a override to force a specific usage policy. Deployers may wish to install the libosinfo library on their compute nodes, in order to allow Nova libvirt driver to use this new feature. If they do not install the libosinfo library, operation of Nova will be unchanged vs previous releases. Installation can be done with the normal distribution package management tools. It is expected that OpenStack specific provisioning tools will eventually choose to automate this during cloud deployment. In the case of private cloud deployments, the cloud administrator may wish to provide additional libosinfo database configuration files, to optimize any custom operating systems their organization uses. Developer impact ---------------- Maintainers of other virtualization drivers may wish to engage with the libosinfo project to collaborate on extending its database to be suitable for use with more virtualization technologies beyond KVM and Xen. This would potentially enable its use with other virt drivers within Nova. It is none the less expected that the non-libvirt virt drivers will simply ignore this new feature in the short-to-medium term at least. The new 'os_name' property might be useful for VMWare which has a mechanism for telling the VMWare hypervisor what guest operating system is installed in a VM. This would entail defining some mapping between libosinfo values and the VMWare required values, which is a fairly straightforward task. Implementation ============== Assignee(s) ----------- Primary assignee: berrange Other contributors: None at this time. Work Items ---------- * Integrate with libosinfo for setup of default disk/network device models in the Nova libvirt driver * Extend devstack to install the libosinfo & object introspection packages * Work with libosinfo community to define metadata for clock and timer perferences per OS type * Extend Nova libvirt driver to configure clock/timer base on libosinfo database Dependencies ============ The Nova libvirt driver will gain an optional dependancy on the libosinfo project/library. This will be accessed by the GObject introspection Python bindings. On Fedora / RHEL systems this will entail installation of the 'libosinfo' packages and either the 'pyobject2' or 'python3-gobject' packages (yes, both Python 2 and 3 are supported). Note that although the GObject Introspection framework was developed under the umbrella of the GNOME project, it does not have any direct requirements for the graphical desktop infrastructure. It is part of their low level gobject library which is a reusable component leveraged by many non-desktop related projects now. Testing ======= The unit tests will of course cover the new code. To test in Tempest would need a gate job which has the suitable packages installed. This can be achieved by updating devstack to install the neccessary bits. Some new tests would need to be created to set the new glance image property and then verify that the guest virtual machine has received the expected configuration changes. Documentation Impact ==================== The new glance image property will need to be documented. It is also likely that we will want to document the list of valid values for this property. Alternatively document how the user can go about learning the valid values defined by libosinfo. References ========== * http://libosinfo.org * https://wiki.gnome.org/action/show/Projects/GObjectIntrospection * https://live.gnome.org/PyGObject ",,291,0
openstack%2Fmagnetodb~master~Ic846c4633c105935aebd1de155bb865c6b9f4a8c,openstack/magnetodb,master,Ic846c4633c105935aebd1de155bb865c6b9f4a8c,Documentation update and structuring,MERGED,2014-12-17 17:55:57.000000000,2014-12-19 10:13:32.000000000,2014-12-19 10:13:30.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8491}, {'_account_id': 8863}, {'_account_id': 11006}]","[{'number': 1, 'created': '2014-12-17 17:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/39463e9bba9a18fce814ceec42e49c6ed39966d7', 'message': 'Documentation update and structuring\n\n* Extended put_item documentation\n* Structured pages by operations\n\nChange-Id: Ic846c4633c105935aebd1de155bb865c6b9f4a8c\n'}, {'number': 2, 'created': '2014-12-17 17:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/f8189303f41e5c62d38331e9a21da2437db93019', 'message': 'Documentation update and structuring\n\n* Extended put_item documentation\n* Structured pages by operations\n\nCloses-Bug: #1403555\nChange-Id: Ic846c4633c105935aebd1de155bb865c6b9f4a8c\n'}, {'number': 3, 'created': '2014-12-18 13:13:10.000000000', 'files': ['doc/source/delete_item.rst', 'doc/source/describe_table.rst', 'doc/source/list_tables.rst', 'doc/source/query.rst', 'doc/api/openstack/samples/condition_exist_equal_sample.json', 'doc/source/put_item.rst', 'doc/source/scan.rst', 'doc/api/openstack/samples/list_tables_sample_response.json', 'doc/source/create_table.rst', 'doc/source/delete_table.rst', 'doc/source/batch_get_item.rst', 'doc/source/batch_write_item.rst', 'doc/source/update_item.rst', 'doc/source/get_item.rst'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/056f1e93cc4dd72dd36b326038aab166db055c47', 'message': 'Documentation update and structuring\n\n* Extended put_item documentation\n* Structured pages by operations\n\nCloses-Bug: #1403555\nChange-Id: Ic846c4633c105935aebd1de155bb865c6b9f4a8c\n'}]",4,142523,056f1e93cc4dd72dd36b326038aab166db055c47,13,5,3,8188,,,0,"Documentation update and structuring

* Extended put_item documentation
* Structured pages by operations

Closes-Bug: #1403555
Change-Id: Ic846c4633c105935aebd1de155bb865c6b9f4a8c
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/23/142523/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/delete_item.rst', 'doc/source/describe_table.rst', 'doc/source/list_tables.rst', 'doc/source/query.rst', 'doc/api/openstack/samples/condition_exist_equal_sample.json', 'doc/source/put_item.rst', 'doc/source/scan.rst', 'doc/api/openstack/samples/list_tables_sample_response.json', 'doc/source/create_table.rst', 'doc/source/delete_table.rst', 'doc/source/batch_get_item.rst', 'doc/source/batch_write_item.rst', 'doc/source/update_item.rst', 'doc/source/get_item.rst']",14,39463e9bba9a18fce814ceec42e49c6ed39966d7,bug/1403555,-------------- Request Syntax --------------Request Parameters ``````````````````--------------- Response Syntax ---------------Response Elements `````````````````------ Errors ------ | BackendInteractionException | ClusterIsNotConnectedException | ValidationError -------------- Sample Request ----------------------------- Sample Response ---------------,**Request Syntax****Request Parameters**:**Response Syntax****Response Elements****Errors** BackendInteractionException ClusterIsNotConnectedException ValidationError **Sample Request****Sample Response** ,319,129
openstack%2Ftricircle~master~Idac1a2a97f1071c613763733e0b00e2c7d7b2f74,openstack/tricircle,master,Idac1a2a97f1071c613763733e0b00e2c7d7b2f74,modify cinder client,MERGED,2014-12-19 09:57:28.000000000,2014-12-19 09:58:44.000000000,2014-12-19 09:58:44.000000000,"[{'_account_id': 3}, {'_account_id': 13924}]","[{'number': 1, 'created': '2014-12-19 09:57:28.000000000', 'files': ['cinderproxy/cinder/volume/cinder_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/72fb1af94014949083f005235f09a74467f9f680', 'message': 'modify cinder client\n\nChange-Id: Idac1a2a97f1071c613763733e0b00e2c7d7b2f74\n'}]",0,143024,72fb1af94014949083f005235f09a74467f9f680,6,2,1,13924,,,0,"modify cinder client

Change-Id: Idac1a2a97f1071c613763733e0b00e2c7d7b2f74
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/24/143024/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderproxy/cinder/volume/cinder_proxy.py'],1,72fb1af94014949083f005235f09a74467f9f680,," project_id=cfg.CONF.cinder_tenant_id, LOG.debug(_('Cascade info: change since time is none,' 'volumes: %s'), volumes) return self._query_vol_cascaded_pagination() LOG.debug(_('Cascade info: last volume update time:%s'), self._last_info_volume_state_heal) LOG.debug(_('Cascade info: heal interval:%s'), heal_interval) LOG.debug(_('Cascade info: curr_time:%s'), curr_time) LOG.debug(_(""Cascade info: update volume:%s""), volume._info) LOG.debug(_('Cascade info: Updated the volume %s status from' 'cinder-proxy'), volume_id)"," # sCatalog = getattr(client_v2, 'auth_ref').get('serviceCatalog') # compat_catalog = { # 'access': {'serviceCatalog': sCatalog} # } # sc = service_catalog.ServiceCatalog(compat_catalog) # url = sc.url_for(attr='region', # filter_value=cfg.CONF.cascaded_region_name, # service_type='volume', # service_name='cinder', # endpoint_type='publicURL') tenant_name=cfg.CONF.cinder_tenant_name, LOG.info(_('Cascade info: change since time is none,' 'volumes: %s'), volumes) raise cinder_exception.Unauthorized LOG.info(_('Cascade info: last volume update time:%s'), self._last_info_volume_state_heal) LOG.info(_('Cascade info: heal interval:%s'), heal_interval) LOG.info(_('Cascade info: curr_time:%s'), curr_time) LOG.info(_('Cascade info: Updated the volume %s status from' 'cinder-proxy'), volume_id) return return return return",11,26
openstack%2Foslo.messaging~master~Idfe94dd37cdba9f498f79cf87d4fff81e7c4249b,openstack/oslo.messaging,master,Idfe94dd37cdba9f498f79cf87d4fff81e7c4249b,Fix incorrect attribute name in matchmaker_redis,MERGED,2014-10-17 02:55:49.000000000,2014-12-19 09:53:44.000000000,2014-12-19 09:53:43.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 7805}, {'_account_id': 8415}, {'_account_id': 13290}]","[{'number': 1, 'created': '2014-10-17 02:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a8e8c98b590de55385877664ecd80a20817b0690', 'message': 'Fix incorrect attribute name in matchmaker_redis\n\nPass the correct base class attribute name for host topic to\nself.register and fix the AttributeError.\n\nChange-Id: Idfe94dd37cdba9f498f79cf87d4fff81e7c4249b\nCloses-Bugs: #1246308\n'}, {'number': 2, 'created': '2014-10-25 14:08:40.000000000', 'files': ['oslo/messaging/_drivers/matchmaker_redis.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6987b8ac288c16c141b6872b711754d204223400', 'message': 'Fix incorrect attribute name in matchmaker_redis\n\nPass the correct base class attribute name for host topic to\nself.register and fix the AttributeError.\n\nChange-Id: Idfe94dd37cdba9f498f79cf87d4fff81e7c4249b\nCloses-Bug: #1246308\n'}]",0,129114,6987b8ac288c16c141b6872b711754d204223400,19,8,2,7805,,,0,"Fix incorrect attribute name in matchmaker_redis

Pass the correct base class attribute name for host topic to
self.register and fix the AttributeError.

Change-Id: Idfe94dd37cdba9f498f79cf87d4fff81e7c4249b
Closes-Bug: #1246308
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/14/129114/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/matchmaker_redis.py'],1,a8e8c98b590de55385877664ecd80a20817b0690,bug/1246308," self.register(self.host_topic[host], host)"," self.register(self.topic_host[host], host)",1,1
openstack%2Fceilometer~master~Ib054c3e10d617686928bf03f94c5ff868905afde,openstack/ceilometer,master,Ib054c3e10d617686928bf03f94c5ff868905afde,Improve tools/make_test_data.sh correctness,MERGED,2014-12-11 14:29:21.000000000,2014-12-19 09:53:20.000000000,2014-12-19 09:53:18.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 7336}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 13273}, {'_account_id': 13367}]","[{'number': 1, 'created': '2014-12-11 14:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0b66a044fc232bd93038318ad43a2a68b1ed34be', 'message': 'Correctly work script tools/make_test_data.sh\n\nWhen we run tools/make_test_data.sh it raises TypeError:\nTypeError: unsupported type for timedelta days component: str.\nThis change allows the script tools/make_test_data.sh to work\ncorrectly and to work correctly tools/make_test_data.py.\n\nChange-Id: Ib054c3e10d617686928bf03f94c5ff868905afde\nCloses-bug: 1389684\n'}, {'number': 2, 'created': '2014-12-12 09:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/82bf2e07827e5f0fc0a45a05cccb1b611b0f8da5', 'message': 'Correctly work script tools/make_test_data.sh\n\nWhen we run tools/make_test_data.sh it raises TypeError:\nTypeError: unsupported type for timedelta days component: str.\nThis patch allows both the script ""tools/make_test_data.sh"" and ""tools/make_test_data.py"" to work correctly.\n\nChange-Id: Ib054c3e10d617686928bf03f94c5ff868905afde\nCloses-bug: 1389684'}, {'number': 3, 'created': '2014-12-12 09:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/294cb5abf539c48960d22452f72c9597be782399', 'message': 'Correctly work script tools/make_test_data.sh\n\nWhen we run tools/make_test_data.sh it raises TypeError:\nTypeError: unsupported type for timedelta days component: str.\nThis patch allows both the script ""tools/make_test_data.sh""\nand ""tools/make_test_data.py"" to work correctly.\n\nChange-Id: Ib054c3e10d617686928bf03f94c5ff868905afde\nCloses-bug: 1389684'}, {'number': 4, 'created': '2014-12-15 09:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ab6ab1838490e520c255827c507fd2eb4135893f', 'message': 'Correctly work script tools/make_test_data.sh\n\nWhen we run tools/make_test_data.sh it raises TypeError:\nTypeError: unsupported type for timedelta days component: str.\nThis change allows the script tools/make_test_data.sh to work\ncorrectly and to work correctly tools/make_test_data.py.\n\nChange-Id: Ib054c3e10d617686928bf03f94c5ff868905afde\nCloses-bug: 1389684\n'}, {'number': 5, 'created': '2014-12-16 11:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2eff036668189d24d55c75389830ed7c32019802', 'message': 'Improve tools/make_test_data.sh correctness\n\nThis change allows the script tools/make_test_data.sh to work\ncorrectly and to work correctly tools/make_test_data.py.\n\nChange-Id: Ib054c3e10d617686928bf03f94c5ff868905afde\nCloses-bug: 1389684\n'}, {'number': 6, 'created': '2014-12-17 10:15:11.000000000', 'files': ['tools/make_test_data.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f1c84280069fd8761d29ab7a05f8a4d3211d0299', 'message': 'Improve tools/make_test_data.sh correctness\n\nThis change allows the script tools/make_test_data.sh and\ntools/make_test_data.py to work correctly by handing\nexceptions appropriately.\n\n\nChange-Id: Ib054c3e10d617686928bf03f94c5ff868905afde\nCloses-bug: 1389684'}]",19,141061,f1c84280069fd8761d29ab7a05f8a4d3211d0299,55,14,6,13273,,,0,"Improve tools/make_test_data.sh correctness

This change allows the script tools/make_test_data.sh and
tools/make_test_data.py to work correctly by handing
exceptions appropriately.


Change-Id: Ib054c3e10d617686928bf03f94c5ff868905afde
Closes-bug: 1389684",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/61/141061/5 && git format-patch -1 --stdout FETCH_HEAD,['tools/make_test_data.py'],1,0b66a044fc232bd93038318ad43a2a68b1ed34be,bug/1389684," format = '%Y-%m-%dT%H:%M:%S' try: start = datetime.datetime.utcnow() - datetime.timedelta( days=int(args.start)) except ValueError: start = datetime.datetime.strptime(args.start, format) try: end = datetime.datetime.utcnow() - datetime.timedelta( days=int(args.end)) except ValueError: end = datetime.datetime.strptime(args.end, format)", start = datetime.datetime.utcnow() - datetime.timedelta(days=args.start) end = datetime.datetime.utcnow() + datetime.timedelta(days=args.end),11,2
openstack%2Fmagnetodb-specs~master~I765ae524e81d3c425d6ac3c522b4363defc3f701,openstack/magnetodb-specs,master,I765ae524e81d3c425d6ac3c522b4363defc3f701,Specification for data-encryption-support,MERGED,2014-11-17 13:44:40.000000000,2014-12-19 09:35:48.000000000,2014-12-19 09:35:47.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8321}, {'_account_id': 8491}, {'_account_id': 8601}, {'_account_id': 11006}]","[{'number': 1, 'created': '2014-11-17 13:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/b94c04b04571604befe245ca15e7f4bd1d048ed6', 'message': 'Specification for data-encryption-support\n\nChange-Id: I765ae524e81d3c425d6ac3c522b4363defc3f701\n'}, {'number': 2, 'created': '2014-11-26 15:39:54.000000000', 'files': ['specs/kilo/approved/data-encryption-support.rst'], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/1344581b1f9034cbd8f55526f0a038a26c05662e', 'message': 'Specification for data-encryption-support\n\nChange-Id: I765ae524e81d3c425d6ac3c522b4363defc3f701\n'}]",2,134936,1344581b1f9034cbd8f55526f0a038a26c05662e,12,6,2,8601,,,0,"Specification for data-encryption-support

Change-Id: I765ae524e81d3c425d6ac3c522b4363defc3f701
",git fetch https://review.opendev.org/openstack/magnetodb-specs refs/changes/36/134936/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/data-encryption-support.rst'],1,b94c04b04571604befe245ca15e7f4bd1d048ed6,data-encryption-support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================== Data encryption support ======================== Launchpad: data-encryption-support_ .. _data-encryption-support: https://blueprints.launchpad.net/magnetodb/+spec/data-encryption-support Supporting of data encryption Problem description =================== The aim of this blueprint is having secure stored data on drive. This means that if malefactor get access to our hard disk for example, he will have no ability to read tenant's data. This is pretty big task and it touches few components let us go throw them --------- Use Cases --------- User wants to encrypt tenant's data using secret key Proposed change =============== This change requires management api implemented first for providing per tenant options (encryption key) To have securely stored data we need to have: - Data encrypted - Key for encryption not stored on the same drive (at least without encryption) Also one more important point. MagnetoDB allows us to perform range queries. This means that MagnetoDB requires keys which could be compared one to another to store this keys ordered. If we are using third-party storage (Cassandra for example) we need to implement encryption between Cassandra and our drive. It seems that the most suitable for this task is file based encryption file system (like eCryptFS for Linux). For this case we need: - implement magnetodb-cassandra-agent. And run it on each Cassandra node for mounting and umounting eCryptFS partitions - improve async-task-executor for performing management-api requests (in scope of management-api implementation) - integrate with Barbican for storing secrets for encryption ------------ Alternatives ------------ Use storage internal mechanism for data encryption ----------------- Data model impact ----------------- It looks like we need to move our tenant/table info repository out from data storage (Cassandra) to some dedicated storage (MySQL for example) --------------- REST API impact --------------- Doesn't require changing of existing API --------------- Security impact --------------- Secrets shouldn't be stored in persistent storages like hard drive, only in memory. If we need to get secret we suold ask external keymanagement API (Barbican) -------------------- Notifications impact -------------------- None --------------------- Other end user impact --------------------- None ------------------ Performance Impact ------------------ eCryptFS is fast but will consume some CPU with depends on alhorithm and its paramenters (like key length) chosen --------------------- Other deployer impact --------------------- Deploing of magnetodb-cassandra-agent is required for each Cassandra node ----------- Assignee(s) ----------- Primary assignee: <None> ---------- Work Items ---------- 1. Improve management-api implementation for handling encryption property corectly 2. move out tenant/table info repository to dedicated storage 3. Implement magnetodb-cassandra-agent 4. Integrate with Barbican Dependencies ============ management-api implementation Testing ======= set of tempest tests will cover this functionality Documentation Impact ==================== Deployment procedure should be updated. New storage options for encryption should be described ",,161,0
openstack%2Ffuel-library~master~Id53d8d6f36fdcdf7766e143bbb9b788af299882b,openstack/fuel-library,master,Id53d8d6f36fdcdf7766e143bbb9b788af299882b,Unit tests script for fuel-library,MERGED,2014-11-26 11:09:22.000000000,2014-12-19 09:35:00.000000000,2014-12-19 09:35:00.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9977}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-11-26 11:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9188148ddfb6d50c2586540a775e0f8285920122', 'message': ""Unit tests script for fuel-library\n\nScript that will run unit tests (rake spec) for needed modules as\na part of our CI for fuel-library project. Currently it has a list\nof modules with disabled unit tests, due to large amount of broken\nor missing rspec tests. We'll fix those eventualy and reduce the\nlist of modules without unit tests.\n\nImplements blueprint: fuel-library-rspec-testing\n\nChange-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b\n""}, {'number': 2, 'created': '2014-11-27 09:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ceb2998a9c6cacf5b9d28a140d1e38e5d38cee78', 'message': ""Unit tests script for fuel-library\n\nScript that will run unit tests (rake spec) for needed modules as\na part of our CI for fuel-library project. Currently it has a list\nof modules with disabled unit tests, due to large amount of broken\nor missing rspec tests. We'll fix those eventualy and reduce the\nlist of modules without unit tests.\n\nImplements blueprint: fuel-library-rspec-testing\n\nChange-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 3, 'created': '2014-12-04 11:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/34cfcfa8eb30b308e0f61591a0517e71dd3661cf', 'message': ""Unit tests script for fuel-library\n\nScript that will run unit tests (rake spec) for needed modules as\na part of our CI for fuel-library project. Currently it has a list\nof modules with disabled unit tests, due to large amount of broken\nor missing rspec tests. We'll fix those eventualy and reduce the\nlist of modules without unit tests.\n\nImplements blueprint: fuel-library-rspec-testing\nPartial-bug: #1396510\n\nChange-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 4, 'created': '2014-12-04 12:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/762507840f0b3979f5143705fe89b714528ae9bc', 'message': ""Unit tests script for fuel-library\n\nScript that will run unit tests (rake spec) for needed modules as\na part of our CI for fuel-library project. Currently it has a list\nof modules with disabled unit tests, due to large amount of broken\nor missing rspec tests. We'll fix those eventualy and reduce the\nlist of modules without unit tests.\n\nImplements blueprint: fuel-library-rspec-testing\nPartial-bug: #1396510\n\nChange-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 5, 'created': '2014-12-08 15:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fb9f1726ffd8f57e053b91642565435ae8f2a68d', 'message': ""Unit tests script for fuel-library\n\nScript that will run unit tests (rake spec) for needed modules as\na part of our CI for fuel-library project. Currently it has a list\nof modules with disabled unit tests, due to large amount of broken\nor missing rspec tests. We'll fix those eventualy and reduce the\nlist of modules without unit tests.\n\nImplements blueprint: fuel-library-rspec-testing\nPartial-bug: #1396510\n\nChange-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 6, 'created': '2014-12-09 09:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/819e6d45662bdbb13b6d6ae36aac185d8359dc8c', 'message': ""Unit tests script for fuel-library\n\nScript that will run unit tests (rake spec) for needed modules as\na part of our CI for fuel-library project. Currently it has a list\nof modules with disabled unit tests, due to large amount of broken\nor missing rspec tests. We'll fix those eventualy and reduce the\nlist of modules without unit tests.\n\nImplements blueprint: fuel-library-rspec-testing\nPartial-bug: #1396510\n\nChange-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 7, 'created': '2014-12-12 14:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3ab6126d26c1e5291b6569d95c8b20bfb7911532', 'message': ""Unit tests script for fuel-library\n\nScript that will run unit tests (rake spec) for needed modules as\na part of our CI for fuel-library project. Currently it has a list\nof modules with disabled unit tests, due to large amount of broken\nor missing rspec tests. We'll fix those eventualy and reduce the\nlist of modules without unit tests.\n\nImplements blueprint: fuel-library-rspec-testing\nPartial-bug: #1396510\n\nChange-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 8, 'created': '2014-12-15 08:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/18a312f6bc220c1f4f16ae026da7b1746c3bb3f7', 'message': ""Unit tests script for fuel-library\n\nScript that will run unit tests (rake spec) for needed modules as\na part of our CI for fuel-library project. Currently it has a list\nof modules with disabled unit tests, due to large amount of broken\nor missing rspec tests. We'll fix those eventualy and reduce the\nlist of modules without unit tests.\n\nImplements blueprint: fuel-library-rspec-testing\nPartial-bug: #1396510\n\nChange-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 9, 'created': '2014-12-17 16:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0a23c77f6db6128db9f90216d4efa96cc47aef45', 'message': ""Unit tests script for fuel-library\n\nScript that will run unit tests (rake spec) for needed modules as\na part of our CI for fuel-library project. Currently it has a list\nof modules with disabled unit tests, due to large amount of broken\nor missing rspec tests. We'll fix those eventualy and reduce the\nlist of modules without unit tests.\n\nAlso includes:\n  - fixes for swift unit tests broken by our modifications\n\nImplements blueprint: fuel-library-rspec-testing\nPartial-bug: #1396510\n\nChange-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 10, 'created': '2014-12-17 17:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e70f8af41254bd1a8bf228c62ff8c4a0174f6913', 'message': ""Unit tests script for fuel-library\n\nScript that will run unit tests (rake spec) for needed modules as\na part of our CI for fuel-library project. Currently it has a list\nof modules with disabled unit tests, due to large amount of broken\nor missing rspec tests. We'll fix those eventualy and reduce the\nlist of modules without unit tests.\n\nAlso includes:\n  - fixes for swift unit tests broken by our modifications\n  - fixes for murano syntax errors\n\nImplements blueprint: fuel-library-rspec-testing\nPartial-bug: #1396510\n\nChange-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 11, 'created': '2014-12-17 17:30:02.000000000', 'files': ['deployment/puppet/swift/spec/spec_helper.rb', 'deployment/puppet/swift/manifests/ringbuilder/rebalance.pp', 'utils/jenkins/modules.disable_rspec', 'deployment/puppet/murano/manifests/db/mysql.pp', 'utils/jenkins/fuel_unit_tests.sh', 'deployment/puppet/murano/manifests/dashboard.pp', 'deployment/puppet/murano/Gemfile', 'deployment/puppet/murano/Rakefile'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ba4b1c92372dd42a0f68fa5d567694948ea13a22', 'message': ""Unit tests script for fuel-library\n\nScript that will run unit tests (rake spec) for needed modules as\na part of our CI for fuel-library project. Currently it has a list\nof modules with disabled unit tests, due to large amount of broken\nor missing rspec tests. We'll fix those eventualy and reduce the\nlist of modules without unit tests.\n\nAlso includes:\n  - fixes for swift unit tests broken by our modifications\n  - fixes for murano syntax errors\n\nImplements blueprint: fuel-library-rspec-testing\nPartial-bug: #1396510\n\nChange-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}]",2,137334,ba4b1c92372dd42a0f68fa5d567694948ea13a22,76,8,11,9387,,,0,"Unit tests script for fuel-library

Script that will run unit tests (rake spec) for needed modules as
a part of our CI for fuel-library project. Currently it has a list
of modules with disabled unit tests, due to large amount of broken
or missing rspec tests. We'll fix those eventualy and reduce the
list of modules without unit tests.

Also includes:
  - fixes for swift unit tests broken by our modifications
  - fixes for murano syntax errors

Implements blueprint: fuel-library-rspec-testing
Partial-bug: #1396510

Change-Id: Id53d8d6f36fdcdf7766e143bbb9b788af299882b
Signed-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/34/137334/6 && git format-patch -1 --stdout FETCH_HEAD,"['utils/jenkins/modules.disable_rspec', 'utils/jenkins/fuel_unit_tests.sh']",2,9188148ddfb6d50c2586540a775e0f8285920122,bp/fuel-library-rspec-testing,"#!/bin/bash # Some basic checks if ! [ -d ""$WORKSPACE"" ] ; then echo ""ERROR: WORKSPACE not found"" exit 1 fi if [ -z ""$GERRIT_BRANCH"" ] ; then echo ""ERROR: GERRIT_BRANCH variable is empty"" exit 1 fi # Function that runs rake spec using bundle function rake_spec { MODULE=`basename $(pwd)` echo ""Checking module $MODULE"" if ! [ -f ./Gemfile ] ; then echo ""Gemfile not found. Skipping unit tests."" return 0 fi if ! [ -f Rakefile ] ; then echo ""Rakefile not found. Skipping unit tests."" return 0 fi if grep -qx $MODULE $WORKSPACE/utils/jenkins/modules.disable_rspec ; then echo ""Unit tests are disabled for $MODULE module"" return 0 fi bundle --version || return 1 PUPPET_GEM_VERSION='~> 3.4.0' GEM_HOME=$WORKSPACE/.bundled_gems bundle install bundle exec rake spec SPEC_OPTS='--format documentation' return $? } # Iterate over the changed modules and run unit tests for them fail=0 modules=$(git diff --name-only $GERRIT_BRANCH | grep -o 'deployment/puppet/[^/]*/' | sort -u) for mod in $modules; do pushd $mod &> /dev/null rake_spec || let fail+=1 popd &>/dev/null done if test $fail -ne 0 ; then echo ""RSpec Test FAILED: $fail modules failed RSpec tests."" exit 1 else echo ""RSpec Test SUCCEEDED: All modules successfully passed RSpec tests."" exit 0 fi ",,108,0
openstack%2Fproject-config~master~I5fbff3f040b40afc5bf8505189e99a5185f7440f,openstack/project-config,master,I5fbff3f040b40afc5bf8505189e99a5185f7440f,Add rally-py34 job,MERGED,2014-12-18 13:41:49.000000000,2014-12-19 09:13:44.000000000,2014-12-19 09:13:42.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 8507}, {'_account_id': 9180}, {'_account_id': 9545}, {'_account_id': 9601}, {'_account_id': 10475}, {'_account_id': 12395}]","[{'number': 1, 'created': '2014-12-18 13:41:49.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/6a8b3aaade8b5569cd8a9d40196240342a9b97ab', 'message': 'Add rally-py34 job\n\nRally team started work on adding py34 support.\nThis job will help us to make progress faster and avoid regressions\n\nChange-Id: I5fbff3f040b40afc5bf8505189e99a5185f7440f\n'}]",0,142785,6a8b3aaade8b5569cd8a9d40196240342a9b97ab,14,9,1,6172,,,0,"Add rally-py34 job

Rally team started work on adding py34 support.
This job will help us to make progress faster and avoid regressions

Change-Id: I5fbff3f040b40afc5bf8505189e99a5185f7440f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/85/142785/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,6a8b3aaade8b5569cd8a9d40196240342a9b97ab,rally-py34-job, - name: gate-rally-python34 voting: false - gate-rally-python34,,3,0
openstack%2Fneutron~master~I39e2a7521a7b545a124b1cd42dc79da8986eff93,openstack/neutron,master,I39e2a7521a7b545a124b1cd42dc79da8986eff93,Move contrib directory to base test directory,MERGED,2014-12-17 19:35:06.000000000,2014-12-19 08:48:44.000000000,2014-12-19 03:27:56.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-17 19:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1dc0dcfd1155bc6f59a92f3bc453d1298c31cb9f', 'message': 'Move contrib directory to base test directory\n\nThis is needed to have post hook apply to both functional and api jobs.\n\nThis is aimed at fixing the output for the dsvm-api job in preparation\nof the retargatable testing blueprint.\n\nChange-Id: I39e2a7521a7b545a124b1cd42dc79da8986eff93\n'}, {'number': 2, 'created': '2014-12-17 22:07:27.000000000', 'files': ['neutron/tests/contrib/README', 'neutron/tests/contrib/gate_hook.sh', 'neutron/tests/functional/contrib', 'neutron/tests/contrib/filters.template', 'neutron/tests/contrib/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7bc56f030c8bf15336a61ac0d3a513059a00a902', 'message': 'Move contrib directory to base test directory\n\nThis is needed to have post hook apply to both functional and api jobs.\n\nThis is aimed at fixing the output for the dsvm-api job in preparation\nof the retargatable testing blueprint.\n\nChange-Id: I39e2a7521a7b545a124b1cd42dc79da8986eff93\n'}]",0,142558,7bc56f030c8bf15336a61ac0d3a513059a00a902,37,17,2,748,,,0,"Move contrib directory to base test directory

This is needed to have post hook apply to both functional and api jobs.

This is aimed at fixing the output for the dsvm-api job in preparation
of the retargatable testing blueprint.

Change-Id: I39e2a7521a7b545a124b1cd42dc79da8986eff93
",git fetch https://review.opendev.org/openstack/neutron refs/changes/58/142558/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/contrib/README', 'neutron/tests/contrib/gate_hook.sh', 'neutron/tests/contrib/filters.template', 'neutron/tests/functional/contrib', 'neutron/tests/contrib/post_test_hook.sh']",5,1dc0dcfd1155bc6f59a92f3bc453d1298c31cb9f,move-contrib,,,1,0
openstack%2Fnova-specs~master~Id03a998f82c13d9f168d1b7cd20e0dd460d5ef0c,openstack/nova-specs,master,Id03a998f82c13d9f168d1b7cd20e0dd460d5ef0c,Adds specification for SQL profiler,ABANDONED,2014-12-16 11:44:55.000000000,2014-12-19 08:38:54.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1849}, {'_account_id': 6849}, {'_account_id': 9569}]","[{'number': 1, 'created': '2014-12-16 11:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ccac2d7b21890d01c6b37836bee3c3d4bbe91d1b', 'message': 'Adds specification for SQL profiler\n\nDevelop and implement a profiler for SQL requests.\n\nDesign for blueprint sql-profiler\n\nChange-Id: Id03a998f82c13d9f168d1b7cd20e0dd460d5ef0c\n'}, {'number': 2, 'created': '2014-12-16 12:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a08b619dea8868256011d07bd102e64182e90468', 'message': 'Adds specification for SQL profiler\n\nDevelop and implement a profiler for SQL requests.\n\nDesign for blueprint sql-profiler\n\nChange-Id: Id03a998f82c13d9f168d1b7cd20e0dd460d5ef0c\n'}, {'number': 3, 'created': '2014-12-16 19:02:18.000000000', 'files': ['specs/kilo/approved/sql-profiler.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/40504a4ab6c2e15ec06a6474ef1b0e8b8441d125', 'message': 'Adds specification for SQL profiler\n\nDevelop and implement a profiler for SQL requests.\n\nDesign for blueprint sql-profiler\n\nChange-Id: Id03a998f82c13d9f168d1b7cd20e0dd460d5ef0c\n'}]",4,142078,40504a4ab6c2e15ec06a6474ef1b0e8b8441d125,15,5,3,9569,,,0,"Adds specification for SQL profiler

Develop and implement a profiler for SQL requests.

Design for blueprint sql-profiler

Change-Id: Id03a998f82c13d9f168d1b7cd20e0dd460d5ef0c
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/78/142078/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/sql-profiler.rst'],1,ccac2d7b21890d01c6b37836bee3c3d4bbe91d1b,bp/sql-profiler,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================= Develop and implement a profiler for SQL requests ================================================= https://blueprints.launchpad.net/nova/+spec/sql-profiler Blueprint aims to develop a SQL profiler for logging and performance estimation of SQL requests, done in the context of execution of a given REST API request. It will be implemented as an optional WSGI middleware, which can be enabled in the PasteDeploy config. Problem description =================== Performance is an important aspect of every project, including Openstack. By the means of the developed profiler developers will be able to see how fast and effectively SQL requests are processed, how many of them are issued for every REST API request. Optional launching of the profiler in PasteDeploy in tempest jobs will make it possible to estimate the performance of all REST API requests. Use Cases ---------- The developer will be able to see either the performance of the code is better or worse after the changes the developer has made. Project Priority ----------------- The kilo priorities list is currently undefined. Proposed change =============== Develop an optional WSGI middleware SQL profiler. Enable the middleware in gate jobs. Alternatives ------------ Rally/osprofiler can be used for performance tracking of SQL requests. But that would require Ceilometer to be installed. Besides Rally/osprofiler bundle is a cross-service profiler, while the proposed profiler will track the performance of SQL requests and group them by REST API requests. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- The profiler will generate an HTML report. This report will contain the following information: which REST API requests were called, for each REST API request: which SQL requests were performed while the given REST API request was processed, the time of execution of each SQL request, the place where the SQL request was called from and the SQL request itself. This report will be given to user as output file for tempest jobs in which the profiler is enabled. Performance Impact ------------------ The proposed middleware will be completely optional and disabled by default. When it’s enabled (e.g. in tempest gate jobs) the performance overhead will be negligible. Other deployer impact --------------------- Operators can optionally enable the WSGI middleware in api-paste.ini, if they want to profile SQL requests. Developer impact ---------------- The profiler will help the developers improve the performance of SQL requests. Implementation ============== Assignee(s) ----------- Primary assignee: snikitin Other contributors: None Work Items ---------- 1. Develop SQL Profiler WSGI middleware. 2. Enabled the middleware in PasteDeploy config for tempest gate jobs. Dependencies ============ The profiler will be developed on the base of SQLTap profiler. https://github.com/inconshreveable/sqltap http://sqltap.inconshreveable.com/ SQLTap profiler has Apache License, Version 2.0. This profiler was chosen because it has user friendly interface and it will be easy to modify SQLTap for our needs. Testing ======= Would need new unit tests. Documentation Impact ==================== Docs needed to explain how to enable profiler in api-paste.ini References ========== None ",,150,0
openstack%2Fcinder~master~I86d2fd477f3ae5590c5f079a4c806d1f50eb96d0,openstack/cinder,master,I86d2fd477f3ae5590c5f079a4c806d1f50eb96d0,Add unit test for commit 22abe9081,MERGED,2014-12-15 19:28:44.000000000,2014-12-19 08:26:59.000000000,2014-12-16 16:54:06.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 6873}, {'_account_id': 7198}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12779}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-15 19:28:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1d23a4a912c82a93ae8d278fd36e088257619d2d', 'message': 'Add unit test for commit 22abe9081\n\nCommit 22abe9081 fixed a bug in commit d7bd65e8e which we could have\nfound the first time with a simple unit test.\n\nThis change adds the unit test to cover that new error handling block.\n\nRelated-Bug: #1398078\n\nChange-Id: I86d2fd477f3ae5590c5f079a4c806d1f50eb96d0\n'}, {'number': 2, 'created': '2014-12-15 19:30:11.000000000', 'files': ['cinder/tests/test_iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/eb20e9e5009541ea0037588a43443c74e8968c9c', 'message': 'Add unit test for commit 22abe9081\n\nCommit 22abe9081 fixed a bug in commit d7bd65e8e which we could have\nfound the first time with a simple unit test.\n\nThis change adds the unit test to cover that new error handling block.\n\nRelated-Bug: #1398078\n\nChange-Id: I86d2fd477f3ae5590c5f079a4c806d1f50eb96d0\n'}]",0,141886,eb20e9e5009541ea0037588a43443c74e8968c9c,20,15,2,6873,,,0,"Add unit test for commit 22abe9081

Commit 22abe9081 fixed a bug in commit d7bd65e8e which we could have
found the first time with a simple unit test.

This change adds the unit test to cover that new error handling block.

Related-Bug: #1398078

Change-Id: I86d2fd477f3ae5590c5f079a4c806d1f50eb96d0
",git fetch https://review.opendev.org/openstack/cinder refs/changes/86/141886/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_iscsi.py'],1,1d23a4a912c82a93ae8d278fd36e088257619d2d,bug/1398078,"from oslo.concurrency import processutils def fake_execute(self, *cmd, **kwargs): self.cmds.append(string.join(cmd)) # Tests that if tgtadm --op show fails with 'target already exists', # we handle it gracefully and move continue. if 'tgtadm' in cmd and '--op' in cmd and 'show' in cmd: raise processutils.ProcessExecutionError( stderr='tgtadm: this target already exists') else: return """", None ",,11,0
openstack%2Fpython-openstackclient~master~I011bb95c2c824e2dbc4b822ca922ae77b8d9b955,openstack/python-openstackclient,master,I011bb95c2c824e2dbc4b822ca922ae77b8d9b955,Don't import form keystoneclient.openstack.common,MERGED,2014-12-17 08:21:22.000000000,2014-12-19 08:19:49.000000000,2014-12-19 08:19:47.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7191}, {'_account_id': 8736}, {'_account_id': 9101}]","[{'number': 1, 'created': '2014-12-17 08:21:22.000000000', 'files': ['openstackclient/identity/v2_0/role.py', 'openstackclient/identity/v2_0/user.py', 'openstackclient/tests/identity/v2_0/test_project.py', 'openstackclient/identity/v3/project.py', 'openstackclient/identity/v2_0/project.py', 'openstackclient/tests/identity/v2_0/test_role.py', 'openstackclient/identity/v3/role.py', 'openstackclient/identity/v3/group.py', 'openstackclient/tests/identity/v2_0/test_user.py', 'openstackclient/api/api.py', 'openstackclient/identity/v3/user.py', 'openstackclient/compute/v2/security_group.py', 'openstackclient/identity/v3/domain.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/25a7c1f27f1ec83edfe1e33e83116ca3eda3ba94', 'message': ""Don't import form keystoneclient.openstack.common\n\nThe keystoneclient.openstack.common directory is where we sync files\nfrom oslo incubator. It is not a public directory and should not be\nbeing consumed by openstackclient.\n\nChange-Id: I011bb95c2c824e2dbc4b822ca922ae77b8d9b955\n""}]",0,142379,25a7c1f27f1ec83edfe1e33e83116ca3eda3ba94,15,5,1,7191,,,0,"Don't import form keystoneclient.openstack.common

The keystoneclient.openstack.common directory is where we sync files
from oslo incubator. It is not a public directory and should not be
being consumed by openstackclient.

Change-Id: I011bb95c2c824e2dbc4b822ca922ae77b8d9b955
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/79/142379/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/identity/v2_0/role.py', 'openstackclient/identity/v2_0/user.py', 'openstackclient/tests/identity/v2_0/test_project.py', 'openstackclient/identity/v3/project.py', 'openstackclient/identity/v2_0/project.py', 'openstackclient/tests/identity/v2_0/test_role.py', 'openstackclient/identity/v3/role.py', 'openstackclient/identity/v3/group.py', 'openstackclient/tests/identity/v2_0/test_user.py', 'openstackclient/api/api.py', 'openstackclient/identity/v3/user.py', 'openstackclient/compute/v2/security_group.py', 'openstackclient/identity/v3/domain.py']",13,25a7c1f27f1ec83edfe1e33e83116ca3eda3ba94,apiclient,from keystoneclient import exceptions as ksc_exc,from keystoneclient.openstack.common.apiclient import exceptions as ksc_exc,13,14
openstack%2Foslo-incubator~master~I347378862ad78719cb95c0a6bf089f2a6b38aadf,openstack/oslo-incubator,master,I347378862ad78719cb95c0a6bf089f2a6b38aadf,Remove whitespace after project description + before range,ABANDONED,2014-12-08 22:33:48.000000000,2014-12-19 08:15:33.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-08 22:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/299293cc2561c1f70f75ba79aee67798bd4422c9', 'message': 'Remove whitespace after project description\n\nChange-Id: I347378862ad78719cb95c0a6bf089f2a6b38aadf\n'}, {'number': 2, 'created': '2014-12-08 22:35:30.000000000', 'files': ['tools/release_notes.sh'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/cca918c397fd667444586b55ca1a6c5a77e68885', 'message': 'Remove whitespace after project description + before range\n\nChange-Id: I347378862ad78719cb95c0a6bf089f2a6b38aadf\n'}]",0,140170,cca918c397fd667444586b55ca1a6c5a77e68885,4,1,2,1297,,,0,"Remove whitespace after project description + before range

Change-Id: I347378862ad78719cb95c0a6bf089f2a6b38aadf
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/70/140170/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/release_notes.sh'],1,299293cc2561c1f70f75ba79aee67798bd4422c9,,, ,0,2
openstack%2Foslo-incubator~master~I9e00f3287b424a429a1d855c994526cd1718da3e,openstack/oslo-incubator,master,I9e00f3287b424a429a1d855c994526cd1718da3e,Exit the script early if something fails,ABANDONED,2014-12-08 22:38:28.000000000,2014-12-19 08:15:18.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-08 22:38:28.000000000', 'files': ['tools/release_notes.sh'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/24ab397cc6807be602de87d423fe43be2295b214', 'message': ""Exit the script early if something fails\n\nIf some command fails, it's nice to have the script stop\nrunning versus continuing to run with potentially corrupt\nor invalid data.\n\nChange-Id: I9e00f3287b424a429a1d855c994526cd1718da3e\n""}]",0,140171,24ab397cc6807be602de87d423fe43be2295b214,3,1,1,1297,,,0,"Exit the script early if something fails

If some command fails, it's nice to have the script stop
running versus continuing to run with potentially corrupt
or invalid data.

Change-Id: I9e00f3287b424a429a1d855c994526cd1718da3e
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/71/140171/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/release_notes.sh'],1,24ab397cc6807be602de87d423fe43be2295b214,,set -e ,,2,0
openstack%2Fos-collect-config~master~I12eb9dbbb8bee24e50ae342ffbc7356d4583a973,openstack/os-collect-config,master,I12eb9dbbb8bee24e50ae342ffbc7356d4583a973,Add ca_certificate option for SSL'd api,MERGED,2014-12-04 13:44:25.000000000,2014-12-19 08:03:03.000000000,2014-12-19 08:03:03.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 1726}, {'_account_id': 6969}, {'_account_id': 8688}, {'_account_id': 10063}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-12-04 13:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/21a28389b011419b706c8d0304a0aff4b68df273', 'message': ""Add ca_certificate option for SSL'd api\n\nChange-Id: I12eb9dbbb8bee24e50ae342ffbc7356d4583a973\n""}, {'number': 2, 'created': '2014-12-05 13:00:22.000000000', 'files': ['os_collect_config/tests/test_cfn.py', 'os_collect_config/cfn.py'], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/c917665af918af69dfda4b956c56662b392e1fa1', 'message': ""Add ca_certificate option for SSL'd api\n\nChange-Id: I12eb9dbbb8bee24e50ae342ffbc7356d4583a973\n""}]",1,139052,c917665af918af69dfda4b956c56662b392e1fa1,18,7,2,395,,,0,"Add ca_certificate option for SSL'd api

Change-Id: I12eb9dbbb8bee24e50ae342ffbc7356d4583a973
",git fetch https://review.opendev.org/openstack/os-collect-config refs/changes/52/139052/2 && git format-patch -1 --stdout FETCH_HEAD,"['os_collect_config/tests/test_cfn.py', 'os_collect_config/cfn.py']",2,21a28389b011419b706c8d0304a0aff4b68df273,139052," cfg.StrOpt('ca_certificate', help='CA Certificate path'), url, params=params, headers=headers, verify=CONF.cfn.ca_certificate)"," url, params=params, headers=headers)",5,3
openstack%2Fneutron~master~I8bd739457e2ecccb57868a17a2c4f43013d78046,openstack/neutron,master,I8bd739457e2ecccb57868a17a2c4f43013d78046,Just a test,ABANDONED,2014-10-07 05:58:25.000000000,2014-12-19 07:48:43.000000000,,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-10-07 05:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/65a02e0d917e9adb1c95e910efac2a2fe12fd3b5', 'message': 'Just a test\n\nChange-Id: I8bd739457e2ecccb57868a17a2c4f43013d78046\n'}, {'number': 2, 'created': '2014-10-07 06:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0846551659d6f9fc75556bda0314a278cde03473', 'message': 'Just a test\n\nChange-Id: I8bd739457e2ecccb57868a17a2c4f43013d78046\n'}, {'number': 3, 'created': '2014-10-07 07:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2dcbd84d5c9f93bed1a34b6807fd56f00f817772', 'message': 'Just a test\n\nChange-Id: I8bd739457e2ecccb57868a17a2c4f43013d78046\n'}, {'number': 4, 'created': '2014-10-07 08:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e287ff46a4700e78d3625b3ac5432f1465c8ec31', 'message': 'Just a test\n\nChange-Id: I8bd739457e2ecccb57868a17a2c4f43013d78046\n'}, {'number': 5, 'created': '2014-12-16 16:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dbe48745c2e66b5b0219c6c30637abfde0d545d1', 'message': 'Just a test\n\nChange-Id: I8bd739457e2ecccb57868a17a2c4f43013d78046\n'}, {'number': 6, 'created': '2014-12-19 03:12:22.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/2026156eab2f_l2_dvr_models.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b56d2cb236523eb66bc607d37e0fff2c30eb29ed', 'message': 'Just a test\n\nChange-Id: I8bd739457e2ecccb57868a17a2c4f43013d78046\n'}]",0,126470,b56d2cb236523eb66bc607d37e0fff2c30eb29ed,116,28,6,7249,,,0,"Just a test

Change-Id: I8bd739457e2ecccb57868a17a2c4f43013d78046
",git fetch https://review.opendev.org/openstack/neutron refs/changes/70/126470/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/models_v2.py'],1,65a02e0d917e9adb1c95e910efac2a2fe12fd3b5,test,," device_owner = sa.Column(sa.String(255), nullable=False)",0,1
openstack%2Ftooz~master~I140a76c44f1b3f25cb0d89b4a1926617dd3c07aa,openstack/tooz,master,I140a76c44f1b3f25cb0d89b4a1926617dd3c07aa,Updated from global requirements,ABANDONED,2014-12-17 04:11:53.000000000,2014-12-19 07:46:55.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-17 04:11:53.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/tooz/commit/6b7acef56c13d30082cd7bd6d3a273c64ba723da', 'message': 'Updated from global requirements\n\nChange-Id: I140a76c44f1b3f25cb0d89b4a1926617dd3c07aa\n'}]",0,142337,6b7acef56c13d30082cd7bd6d3a273c64ba723da,8,2,1,11131,,,0,"Updated from global requirements

Change-Id: I140a76c44f1b3f25cb0d89b4a1926617dd3c07aa
",git fetch https://review.opendev.org/openstack/tooz refs/changes/37/142337/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py', 'requirements-py3.txt']",4,6b7acef56c13d30082cd7bd6d3a273c64ba723da,openstack/requirements,"# The order of packages is significant, because pip processes them in the order # of appearance. Changing the order has an impact on the overall integration # process, which may cause wedges in the gate later.stevedore>=1.1.0 # Apache-2.0iso8601>=0.1.9pymemcache>=1.2 # Apache 2.0 License zake>=0.1 # Apache-2.0 msgpack-python>=0.4.0 retrying>=1.2.3,!=1.3.0 # Apache-2.0 oslo.utils>=1.1.0 # Apache-2.0 redis>=2.10.0",stevedore>=0.14iso8601pymemcache>=1.2 zake>=0.1.6 msgpack-python retrying!=1.3.0 oslo.utils>=1.0.0 redis,41,26
openstack%2Fhorizon~master~I11e2dc4721629e212fba0dab94ddcc1e17568d0b,openstack/horizon,master,I11e2dc4721629e212fba0dab94ddcc1e17568d0b,Imported Translations from Transifex,MERGED,2014-12-19 06:03:41.000000000,2014-12-19 07:35:16.000000000,2014-12-19 07:35:15.000000000,"[{'_account_id': 3}, {'_account_id': 6914}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-12-19 06:03:41.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1e1f491fa74beb73b816901496c9b4bbe739be91', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I11e2dc4721629e212fba0dab94ddcc1e17568d0b\n'}]",0,142987,1e1f491fa74beb73b816901496c9b4bbe739be91,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I11e2dc4721629e212fba0dab94ddcc1e17568d0b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/87/142987/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",17,1e1f491fa74beb73b816901496c9b4bbe739be91,transifex/translations,"""POT-Creation-Date: 2014-12-18 06:58-0600\n"" ""PO-Revision-Date: 2014-12-18 12:57+0000\n""#: dashboards/admin/metadata_defs/tables.py:128#: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:79#: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:18#: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:36 #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:80#: dashboards/admin/metadata_defs/forms.py:61 #: dashboards/admin/metadata_defs/tables.py:142 #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:18#: dashboards/project/instances/views.py:79#: dashboards/project/instances/views.py:120#: dashboards/project/instances/views.py:210 #: dashboards/project/instances/views.py:352#: dashboards/admin/metadata_defs/forms.py:38 msgid ""Namespace Definition Source"" msgstr """" #: dashboards/admin/metadata_defs/forms.py:40 #: dashboards/admin/metadata_defs/forms.py:46 #: dashboards/admin/metadata_defs/forms.py:50 msgid ""Metadata Definition File"" msgstr """" #: dashboards/admin/metadata_defs/forms.py:41 #: dashboards/project/instances/workflows/create_instance.py:620 #: dashboards/project/stacks/forms.py:58 msgid ""Direct Input"" msgstr ""Direct Input"" #: dashboards/admin/metadata_defs/forms.py:47 msgid ""A local metadata definition file to upload."" msgstr """" #: dashboards/admin/metadata_defs/forms.py:54 #: dashboards/admin/metadata_defs/forms.py:58 msgid ""Namespace JSON"" msgstr """" #: dashboards/admin/metadata_defs/forms.py:55 msgid ""The JSON formatted contents of a namespace."" msgstr """" #: dashboards/admin/metadata_defs/forms.py:62 #: dashboards/admin/metadata_defs/tables.py:149 #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:20 #: dashboards/project/images/images/forms.py:96 #: dashboards/project/images/images/forms.py:229 #: dashboards/project/images/images/tables.py:241 #: dashboards/project/images/templates/images/images/_detail_overview.html:23 msgid ""Protected"" msgstr ""Protected"" #: dashboards/admin/metadata_defs/forms.py:77 msgid ""Cannot specify both file and direct input."" msgstr """" #: dashboards/admin/metadata_defs/forms.py:80 msgid ""No input was provided for the namespace content."" msgstr """" #: dashboards/admin/metadata_defs/forms.py:100 #, python-format msgid ""There was a problem loading the namespace: %s."" msgstr """" #: dashboards/admin/metadata_defs/forms.py:110 #, python-format msgid ""Namespace %s has been created."" msgstr """" #: dashboards/admin/metadata_defs/forms.py:114 #, python-format msgid ""Unable to create new namespace. %s"" msgstr """" #: dashboards/admin/metadata_defs/forms.py:140 #, python-format msgid ""Resource types updated for namespace %s."" msgstr """" #: dashboards/admin/metadata_defs/forms.py:144 #, python-format msgid ""Error updating resource types for namespace %s."" msgstr """" #: dashboards/admin/metadata_defs/panel.py:25 #: dashboards/admin/metadata_defs/templates/metadata_defs/index.html:3 #: dashboards/admin/metadata_defs/templates/metadata_defs/index.html:6 msgid ""Metadata Definitions"" msgstr """" #: dashboards/admin/metadata_defs/tables.py:30 #: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:9 #: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:35 msgid ""Import Namespace"" msgstr """" #: dashboards/admin/metadata_defs/tables.py:41 msgid ""Delete Namespace"" msgid_plural ""Delete Namespaces"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/metadata_defs/tables.py:49 msgid ""Deleted Namespace"" msgid_plural ""Deleted Namespaces"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/metadata_defs/tables.py:69 msgid ""Update Associations"" msgstr """" #: dashboards/admin/metadata_defs/tables.py:132 #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:15 #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:57#: dashboards/admin/metadata_defs/tables.py:137 msgid ""Resource Types"" msgstr """" #: dashboards/admin/metadata_defs/tables.py:165 msgid ""Namespaces"" msgstr """" #: dashboards/admin/metadata_defs/tabs.py:26 #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:3 msgid ""Namespace Overview"" msgstr """" #: dashboards/admin/metadata_defs/tabs.py:38 #: dashboards/admin/metadata_defs/views.py:106 msgid ""Unable to retrieve namespace details."" msgstr """" #: dashboards/admin/metadata_defs/tabs.py:45 msgid ""Contents"" msgstr """" #: dashboards/admin/metadata_defs/tabs.py:57 msgid ""Unable to retrieve namespace contents."" msgstr """" #: dashboards/admin/metadata_defs/views.py:75 msgid ""Error getting metadata definitions."" msgstr """" #: dashboards/admin/metadata_defs/views.py:127 #: dashboards/admin/metadata_defs/views.py:145 #: dashboards/admin/metadata_defs/views.py:159 msgid ""Error getting resource type associations."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:20 msgid ""Specify a metadata definition namespace to import."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:23 msgid ""Only definitions in raw JSON format are supported."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:26 msgid """" ""Administrator Note: Use the following CLI command to import the default "" ""definitions into Glance: "" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_contents.html:4 msgid ""Undefined"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:7 #: dashboards/admin/volumes/templates/volumes/volume_types/_volume_encryption_type_detail.html:8 msgid ""Info"" msgstr ""Info"" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:10 msgid ""Display Name"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:11 #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:13 #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:35 #: dashboards/admin/metadata_defs/templates/metadata_defs/detail.html:7 #: dashboards/admin/routers/templates/routers/_detail_overview.html:8 #: dashboards/admin/volumes/volume_types/forms.py:87 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:11 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:11 #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_details.html:14 #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:12 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:11 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:16 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:22 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:11 #: dashboards/project/images/templates/images/images/_detail_overview.html:10 #: dashboards/project/images/templates/images/images/_detail_overview.html:16 #: dashboards/project/images/templates/images/images/_detail_overview.html:49 #: dashboards/project/images/templates/images/images/_detail_overview.html:51 #: dashboards/project/instances/templates/instances/_detail_overview.html:108 #: dashboards/project/instances/templates/instances/_detail_overview.html:117 #: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:45 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:51 #: dashboards/project/networks/templates/networks/_detail_overview.html:8 #: dashboards/project/networks/templates/networks/_detail_overview.html:10 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:11 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:13 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:16 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:27 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:31 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:33 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:35 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:42 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:10 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:12 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:15 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:19 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:47 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:55 #: dashboards/project/routers/templates/routers/_detail_overview.html:4 #: dashboards/project/routers/templates/routers/_detail_overview.html:10 #: dashboards/project/routers/templates/routers/_detail_overview.html:12 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:77 #: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:7 #: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:10 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:7 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:10 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:8 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:11 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:8 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:11 msgid ""None"" msgstr ""None"" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:12 msgid ""Namespace"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:22 #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:35 #: dashboards/project/data_processing/cluster_templates/workflows/create.py:82 #: dashboards/project/data_processing/jobs/workflows/launch.py:407 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:320 #: dashboards/project/database_backups/tables.py:150 #: dashboards/project/database_backups/templates/database_backups/details.html:36 #: dashboards/project/databases/tables.py:315 #: dashboards/project/databases/templates/databases/_detail_overview.html:34 #: dashboards/project/images/templates/images/images/_detail_overview.html:27 #: dashboards/project/instances/templates/instances/_detail_overview.html:18 #: dashboards/project/instances/templates/instances/_detail_overview.html:38 #: dashboards/project/stacks/tables.py:108 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:22 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:39 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:39 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:29 msgid ""Created"" msgstr ""Created"" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:23 #: dashboards/admin/networks/views.py:57 #: dashboards/admin/routers/templates/routers/_detail_overview.html:16 #: dashboards/project/images/templates/images/images/_detail_overview.html:20 #: dashboards/project/images/templates/images/images/_detail_overview.html:31 #: dashboards/project/instances/tables.py:619 #: dashboards/project/networks/templates/networks/_detail_overview.html:14 #: dashboards/project/networks/templates/networks/_detail_overview.html:16 #: dashboards/project/networks/templates/networks/_detail_overview.html:23 #: dashboards/project/routers/templates/routers/_detail_overview.html:14 #: dashboards/project/routers/templates/routers/_detail_overview.html:16 #: dashboards/project/volumes/backups/tables.py:36 #: dashboards/project/volumes/snapshots/tables.py:126 msgid ""Unknown"" msgstr ""Unknown"" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:24 #: dashboards/project/database_backups/templates/database_backups/details.html:38 #: dashboards/project/databases/templates/databases/_detail_overview.html:36 #: dashboards/project/images/templates/images/images/_detail_overview.html:33 #: dashboards/project/stacks/tables.py:112 msgid ""Updated"" msgstr ""Updated"" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:25 #: dashboards/project/images/templates/images/images/_detail_overview.html:37 msgid ""Never updated"" msgstr ""Never updated"" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:32 msgid ""Associated Resource Types"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:39 msgid ""Prefix: "" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:42 msgid ""Properties Target: "" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:47 msgid ""No associations defined."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_resource_types.html:5 #: dashboards/admin/metadata_defs/templates/metadata_defs/_resource_types.html:8 #: dashboards/admin/metadata_defs/templates/metadata_defs/_resource_types.html:14 msgid ""Namespace Resource Type Associations"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/create.html:3 #: dashboards/admin/metadata_defs/templates/metadata_defs/create.html:6 msgid ""Create a Metadata Namespace"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/detail.html:4 msgid ""Namespace Details"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/detail.html:7 msgid ""Namespace Details: "" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:15 msgid ""Available Types"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:19 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_fields_help.html:3 msgid ""Filter"" msgstr ""Filter"" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:59 msgid """" ""Namespaces can be associated to different resource types. This makes the "" ""properties in the namespace visible in the 'Update Metadata' action for that"" "" type of resource."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:61 msgid """" ""Additionally, some resource types may require a prefix to be used when "" ""applying the metadata. In certain cases, the prefix may differ between the "" ""resource type (for example, flavor vs image)."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:63 msgid """" ""Example: The prefix 'hw:' is added to OS::Nova::Flavor for the Virtual CPU "" ""Topology namespace so that the properties will be prefixed with 'hw:' when "" ""applied to flavors."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:65 msgid """" ""Do not use a colon ':' with OS::Glance::Images. This resource type does not "" ""support the use of colons."" msgstr """" #: dashboards/admin/metering/forms.py:24 #: dashboards/admin/metering/templates/metering/stats.html:106 msgid ""Last day"" msgstr ""Last day"" #: dashboards/admin/metering/forms.py:25 #: dashboards/admin/metering/templates/metering/stats.html:107 msgid ""Last week"" msgstr ""Last week"" #: dashboards/admin/metering/forms.py:26 #: dashboards/admin/metering/templates/metering/stats.html:108 msgid ""Month to date"" msgstr ""Month to date"" #: dashboards/admin/metering/forms.py:27 #: dashboards/admin/metering/templates/metering/stats.html:109 msgid ""Last 15 days"" msgstr ""Last 15 days"" #: dashboards/admin/metering/forms.py:28 #: dashboards/admin/metering/templates/metering/stats.html:110 msgid ""Last 30 days"" msgstr ""Last 30 days"" #: dashboards/admin/metering/forms.py:29 #: dashboards/admin/metering/templates/metering/stats.html:111 msgid ""Last year"" msgstr ""Last year"" #: dashboards/admin/metering/forms.py:30 #: dashboards/admin/metering/templates/metering/stats.html:112 #: dashboards/router/nexus1000v/forms.py:59 msgid ""Other"" msgstr ""Other"" #: dashboards/admin/metering/forms.py:32 msgid ""Period"" msgstr ""Period"" #: dashboards/admin/metering/forms.py:35 msgid ""From"" msgstr ""From"" #: dashboards/admin/metering/forms.py:39 msgid ""To"" msgstr ""To"" #: dashboards/admin/metering/forms.py:48 msgid ""Must specify start of period"" msgstr ""Must specify start of period"" #: dashboards/admin/metering/forms.py:58 msgid ""Start must be earlier than end of period."" msgstr ""Start must be earlier than end of period."" #: dashboards/admin/metering/panel.py:20 msgid ""Resource Usage"" msgstr ""Resource Usage"" #: dashboards/admin/metering/tables.py:26 #: dashboards/admin/metering/templates/metering/_daily.html:9 #: dashboards/admin/metering/templates/metering/daily.html:3 #: dashboards/admin/metering/templates/metering/daily.html:6 msgid ""Modify Usage Report Parameters"" msgstr ""Modify Usage Report Parameters"" #: dashboards/admin/metering/tables.py:34 usage/tables.py:25 msgid ""Download CSV Summary"" msgstr ""Download CSV Summary"" #: dashboards/admin/metering/tables.py:43 #: dashboards/admin/metering/tables.py:62 #: dashboards/admin/metering/views.py:160 msgid ""Meter"" msgstr ""Meter"" msgid ""Edit the user's details, including the Primary Project."" msgstr """"#: dashboards/project/instances/views.py:366#: dashboards/project/instances/views.py:263#: dashboards/project/instances/views.py:363#: dashboards/project/instances/views.py:146#: dashboards/project/instances/views.py:71#: dashboards/project/instances/views.py:149 msgid ""Log length must be a nonnegative integer."" msgstr """" #: dashboards/project/instances/views.py:168#: dashboards/project/instances/views.py:179#: dashboards/project/instances/views.py:190#: dashboards/project/instances/views.py:277#: dashboards/project/instances/views.py:298#: dashboards/project/instances/views.py:307#: dashboards/project/instances/views.py:316#: dashboards/project/instances/views.py:324#: dashboards/project/instances/views.py:377","""POT-Creation-Date: 2014-12-16 22:15-0600\n"" ""PO-Revision-Date: 2014-12-17 04:14+0000\n""#: dashboards/project/instances/views.py:78#: dashboards/project/instances/views.py:119#: dashboards/project/instances/views.py:209 #: dashboards/project/instances/views.py:351#: dashboards/admin/metering/forms.py:24 #: dashboards/admin/metering/templates/metering/stats.html:106 msgid ""Last day"" msgstr ""Last day"" #: dashboards/admin/metering/forms.py:25 #: dashboards/admin/metering/templates/metering/stats.html:107 msgid ""Last week"" msgstr ""Last week"" #: dashboards/admin/metering/forms.py:26 #: dashboards/admin/metering/templates/metering/stats.html:108 msgid ""Month to date"" msgstr ""Month to date"" #: dashboards/admin/metering/forms.py:27 #: dashboards/admin/metering/templates/metering/stats.html:109 msgid ""Last 15 days"" msgstr ""Last 15 days"" #: dashboards/admin/metering/forms.py:28 #: dashboards/admin/metering/templates/metering/stats.html:110 msgid ""Last 30 days"" msgstr ""Last 30 days"" #: dashboards/admin/metering/forms.py:29 #: dashboards/admin/metering/templates/metering/stats.html:111 msgid ""Last year"" msgstr ""Last year"" #: dashboards/admin/metering/forms.py:30 #: dashboards/admin/metering/templates/metering/stats.html:112 #: dashboards/router/nexus1000v/forms.py:59 msgid ""Other"" msgstr ""Other"" #: dashboards/admin/metering/forms.py:32 msgid ""Period"" msgstr ""Period"" #: dashboards/admin/metering/forms.py:35 msgid ""From"" msgstr ""From"" #: dashboards/admin/metering/forms.py:39 msgid ""To"" msgstr ""To"" #: dashboards/admin/metering/forms.py:48 msgid ""Must specify start of period"" msgstr ""Must specify start of period"" #: dashboards/admin/metering/forms.py:58 msgid ""Start must be earlier than end of period."" msgstr ""Start must be earlier than end of period."" #: dashboards/admin/metering/panel.py:20 msgid ""Resource Usage"" msgstr ""Resource Usage"" #: dashboards/admin/metering/tables.py:26 #: dashboards/admin/metering/templates/metering/_daily.html:9 #: dashboards/admin/metering/templates/metering/daily.html:3 #: dashboards/admin/metering/templates/metering/daily.html:6 msgid ""Modify Usage Report Parameters"" msgstr ""Modify Usage Report Parameters"" #: dashboards/admin/metering/tables.py:34 usage/tables.py:25 msgid ""Download CSV Summary"" msgstr ""Download CSV Summary"" #: dashboards/admin/metering/tables.py:43 #: dashboards/admin/metering/tables.py:62 #: dashboards/admin/metering/views.py:160 msgid ""Meter"" msgstr ""Meter"" #: dashboards/admin/networks/views.py:57 #: dashboards/admin/routers/templates/routers/_detail_overview.html:16 #: dashboards/project/images/templates/images/images/_detail_overview.html:20 #: dashboards/project/images/templates/images/images/_detail_overview.html:31 #: dashboards/project/instances/tables.py:619 #: dashboards/project/networks/templates/networks/_detail_overview.html:14 #: dashboards/project/networks/templates/networks/_detail_overview.html:16 #: dashboards/project/networks/templates/networks/_detail_overview.html:23 #: dashboards/project/routers/templates/routers/_detail_overview.html:14 #: dashboards/project/routers/templates/routers/_detail_overview.html:16 #: dashboards/project/volumes/backups/tables.py:36 #: dashboards/project/volumes/snapshots/tables.py:126 msgid ""Unknown"" msgstr ""Unknown"" #: dashboards/admin/routers/templates/routers/_detail_overview.html:8 #: dashboards/admin/volumes/volume_types/forms.py:87 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:11 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:11 #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_details.html:14 #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:12 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:11 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:16 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:22 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:11 #: dashboards/project/images/templates/images/images/_detail_overview.html:10 #: dashboards/project/images/templates/images/images/_detail_overview.html:16 #: dashboards/project/images/templates/images/images/_detail_overview.html:49 #: dashboards/project/images/templates/images/images/_detail_overview.html:51 #: dashboards/project/instances/templates/instances/_detail_overview.html:108 #: dashboards/project/instances/templates/instances/_detail_overview.html:117 #: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:45 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:51 #: dashboards/project/networks/templates/networks/_detail_overview.html:8 #: dashboards/project/networks/templates/networks/_detail_overview.html:10 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:11 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:13 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:16 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:27 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:31 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:33 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:35 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:42 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:10 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:12 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:15 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:19 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:47 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:55 #: dashboards/project/routers/templates/routers/_detail_overview.html:4 #: dashboards/project/routers/templates/routers/_detail_overview.html:10 #: dashboards/project/routers/templates/routers/_detail_overview.html:12 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:77 #: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:7 #: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:10 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:7 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:10 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:8 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:11 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:8 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:11 msgid ""None"" msgstr ""None"" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:35 #: dashboards/project/data_processing/cluster_templates/workflows/create.py:82 #: dashboards/project/data_processing/jobs/workflows/launch.py:407 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:320 #: dashboards/project/database_backups/tables.py:150 #: dashboards/project/database_backups/templates/database_backups/details.html:36 #: dashboards/project/databases/tables.py:315 #: dashboards/project/databases/templates/databases/_detail_overview.html:34 #: dashboards/project/images/templates/images/images/_detail_overview.html:27 #: dashboards/project/instances/templates/instances/_detail_overview.html:18 #: dashboards/project/instances/templates/instances/_detail_overview.html:38 #: dashboards/project/stacks/tables.py:108 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:22 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:39 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:39 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:29 msgid ""Created"" msgstr ""Created"" #: dashboards/admin/volumes/templates/volumes/volume_types/_volume_encryption_type_detail.html:8 msgid ""Info"" msgstr ""Info"" msgid ""Edit the user's details, including the Primary Project and Role."" msgstr ""Edit the user's details, including the Primary Project and Role.""#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_fields_help.html:3 msgid ""Filter"" msgstr ""Filter"" #: dashboards/project/instances/views.py:365#: dashboards/project/database_backups/templates/database_backups/details.html:38 #: dashboards/project/databases/templates/databases/_detail_overview.html:36 #: dashboards/project/images/templates/images/images/_detail_overview.html:33 #: dashboards/project/stacks/tables.py:112 msgid ""Updated"" msgstr ""Updated"" #: dashboards/project/instances/views.py:262#: dashboards/project/images/images/forms.py:96 #: dashboards/project/images/images/forms.py:229 #: dashboards/project/images/images/tables.py:241 #: dashboards/project/images/templates/images/images/_detail_overview.html:23 msgid ""Protected"" msgstr ""Protected"" #: dashboards/project/images/templates/images/images/_detail_overview.html:37 msgid ""Never updated"" msgstr ""Never updated"" #: dashboards/project/instances/views.py:362#: dashboards/project/instances/views.py:152#: dashboards/project/instances/views.py:70#: dashboards/project/instances/views.py:167#: dashboards/project/instances/views.py:178#: dashboards/project/instances/views.py:189#: dashboards/project/instances/views.py:276#: dashboards/project/instances/views.py:297#: dashboards/project/instances/views.py:306#: dashboards/project/instances/views.py:315#: dashboards/project/instances/views.py:323#: dashboards/project/instances/views.py:376#: dashboards/project/instances/workflows/create_instance.py:620 #: dashboards/project/stacks/forms.py:58 msgid ""Direct Input"" msgstr ""Direct Input"" ",7498,3401
openstack%2Fceilometer~master~I2156466e8ca5c5ec8bc808e3fbe275b591721f8a,openstack/ceilometer,master,I2156466e8ca5c5ec8bc808e3fbe275b591721f8a,Added missing measurements and corrected errors in doc,MERGED,2014-12-15 03:27:52.000000000,2014-12-19 07:20:02.000000000,2014-12-19 07:20:00.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 7336}, {'_account_id': 7634}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 9562}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-12-15 03:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bf8a6843debd880f6157ef219df69642f3d7bf5d', 'message': 'Added missing measurements and corrected errors in doc\n\n1. Added the missing hardware snmp metrics.\n2. Fixed some errors in the compute metrics which are not available on\nlibvirt.\n\nChange-Id: I2156466e8ca5c5ec8bc808e3fbe275b591721f8a\nCloses-Bug: #1393328\n'}, {'number': 2, 'created': '2014-12-16 01:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/515b0442e5fc2cdd15e916a93f238773b7390437', 'message': 'Added missing measurements and corrected errors in doc\n\n1. Added the missing hardware snmp metrics.\n2. Fixed some errors in the compute metrics which are not available on\nlibvirt.\n\nChange-Id: I2156466e8ca5c5ec8bc808e3fbe275b591721f8a\nCloses-Bug: #1393328\n'}, {'number': 3, 'created': '2014-12-18 05:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5136e20efa7941564292e1a483039784c9672e43', 'message': 'Added missing measurements and corrected errors in doc\n\n1. Added the missing hardware snmp metrics.\n2. Added a note to guide the users to avoid meter duplications of some\ncompute metrics on HyperV/Vsphere/XenAPI.\n\nChange-Id: I2156466e8ca5c5ec8bc808e3fbe275b591721f8a\nCloses-Bug: #1393328\n'}, {'number': 4, 'created': '2014-12-18 07:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a27dfb54f0b4969e6c1a3eb6b4657f1d42f9f1c8', 'message': 'Added missing measurements and corrected errors in doc\n\n1. Added the missing hardware snmp metrics.\n2. Added a note about some compute metrics which are generated by\nrate_of_change transformer on certain hypervisor.\n\nChange-Id: I2156466e8ca5c5ec8bc808e3fbe275b591721f8a\nCloses-Bug: #1393328\n'}, {'number': 5, 'created': '2014-12-18 10:39:13.000000000', 'files': ['doc/source/measurements.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/748cd238deadc3127f247b609e6958a24de0c94f', 'message': 'Added missing measurements and corrected errors in doc\n\n1. Added the missing hardware snmp metrics.\n2. Added a note about some compute metrics which are generated by\nrate_of_change transformer on certain hypervisor.\n\nChange-Id: I2156466e8ca5c5ec8bc808e3fbe275b591721f8a\nCloses-Bug: #1393328\n'}]",16,141698,748cd238deadc3127f247b609e6958a24de0c94f,51,14,5,4491,,,0,"Added missing measurements and corrected errors in doc

1. Added the missing hardware snmp metrics.
2. Added a note about some compute metrics which are generated by
rate_of_change transformer on certain hypervisor.

Change-Id: I2156466e8ca5c5ec8bc808e3fbe275b591721f8a
Closes-Bug: #1393328
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/98/141698/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/measurements.rst'],1,bf8a6843debd880f6157ef219df69642f3d7bf5d,bug/1393328,"disk.read.requests.rate g request/s inst ID p 2, 3 Average rate of read requests per seconddisk.write.requests.rate g request/s inst ID p 2, 3 Average rate of write requests per seconddisk.read.bytes.rate g B/s inst ID p 2, 3, 4 Average rate of reads in B per seconddisk.write.bytes.rate g B/s inst ID p 2, 3, 4 Average volume of writes in B per seconddisk.device.read.requests.rate g request/s disk ID p 2, 3 Average rate of read requests per second per devicedisk.device.write.requests.rate g request/s disk ID p 2, 3 Average rate of write requests per second per devicedisk.device.read.bytes.rate g B/s disk ID p 2, 3 Average rate of reads in B per second per devicedisk.device.write.bytes.rate g B/s disk ID p 2, 3 Average volume of writes in B per second per devicenetwork.incoming.bytes.rate g B/s iface ID p 2, 3, 4 Average rate per sec of incoming bytes on a VM network interfacenetwork.outgoing.bytes.rate g B/s iface ID p 2, 3, 4 Average rate per sec of outgoing bytes on a VM network interfacenetwork.incoming.packets.rate g packet/s iface ID p 2, 3, 4 Average rate per sec of incoming packets on a VM network interfacenetwork.outgoing.packets.rate g packet/s iface ID p 2, 3, 4 Average rate per sec of outgoing packets on a VM network interface Generic Host ================================ These meters are generic host metrics getting from snmp. To enable these, snmpd agent should be running on the endpoint machines which the meters are getting from. ========================================= ========== ========= ========================== ======== ==================================================== Meter Type Unit Resource Origin Note ========================================= ========== ========= ========================== ======== ==================================================== hardware.cpu.load.1min Gauge process <host ID> pollster CPU load in the past 1 minute hardware.cpu.load.5min Gauge process <host ID> pollster CPU load in the past 5 minutes hardware.cpu.load.15min Gauge process <host ID> pollster CPU load in the past 15 minutes hardware.disk.size.total Gauge B <host ID>.<device path> pollster Total disk size hardware.disk.size.used Gauge B <host ID>.<device path> pollster Used disk size hardware.memory.total Gauge B <host ID> pollster Total physical memory size hardware.memory.used Gauge B <host ID> pollster Used physical memory size hardware.memory.swap.total Gauge B <host ID> pollster Total swap space size hardware.memory.avail Gauge B <host ID> pollster Available swap space size hardware.network.incoming.bytes Cumulative B <host ID>.<interface name> pollster Bytes received by network interface hardware.network.outgoing.bytes Cumulative B <host ID>.<interface name> pollster Bytes sent by network interface hardware.network.outgoing.errors Cumulative packet <host ID>.<interface name> pollster Sending error of the network interface hardware.network.ip.incoming.datagrams Cumulative datagrams <host ID> pollster Total number of received datagrams hardware.network.ip.outgoing.datagrams Cumulative datagrams <host ID> pollster Total number of sent datagrams hardware.system_stats.io.incoming.blocks Cumulative blocks <host ID> pollster Aggregated number of blocks received to block device hardware.system_stats.io.outgoing.blocks Cumulative blocks <host ID> pollster Aggregated number of blocks sent to block device hardware.system_stats.cpu.idle Gauge % <host ID> pollster CPU idle percentage ========================================= ========== ========= ========================== ======== ==================================================== ","disk.read.requests.rate g request/s inst ID p 1, 2, 3 Average rate of read requests per seconddisk.write.requests.rate g request/s inst ID p 1, 2, 3 Average rate of write requests per seconddisk.read.bytes.rate g B/s inst ID p 1, 2, 3, 4 Average rate of reads in B per seconddisk.write.bytes.rate g B/s inst ID p 1, 2, 3, 4 Average volume of writes in B per seconddisk.device.read.requests.rate g request/s disk ID p 1, 2, 3 Average rate of read requests per second per devicedisk.device.write.requests.rate g request/s disk ID p 1, 2, 3 Average rate of write requests per second per devicedisk.device.read.bytes.rate g B/s disk ID p 1, 2, 3 Average rate of reads in B per second per devicedisk.device.write.bytes.rate g B/s disk ID p 1, 2, 3 Average volume of writes in B per second per devicenetwork.incoming.bytes.rate g B/s iface ID p 1, 2, 3, 4 Average rate per sec of incoming bytes on a VM network interfacenetwork.outgoing.bytes.rate g B/s iface ID p 1, 2, 3, 4 Average rate per sec of outgoing bytes on a VM network interfacenetwork.incoming.packets.rate g packet/s iface ID p 1, 2, 3, 4 Average rate per sec of incoming packets on a VM network interfacenetwork.outgoing.packets.rate g packet/s iface ID p 1, 2, 3, 4 Average rate per sec of outgoing packets on a VM network interface",42,12
openstack%2Fopenstack-manuals~stable%2Fjuno~I1b9568c4765fb5820e24045dbfcd5e834f1894e0,openstack/openstack-manuals,stable/juno,I1b9568c4765fb5820e24045dbfcd5e834f1894e0,Clarify Installation Guide sections for compute node installation,MERGED,2014-12-18 19:18:49.000000000,2014-12-19 06:55:22.000000000,2014-12-19 06:55:20.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 12402}, {'_account_id': 13384}]","[{'number': 1, 'created': '2014-12-18 19:18:49.000000000', 'files': ['doc/install-guide/section_nova-compute-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b4682abd9c4e9096892f494b5f80af6f1bdf4d57', 'message': 'Clarify Installation Guide sections for compute node installation\n\nAdd note to compute guide installation section to clarify what\nsections are needed to only install additional compute nodes.\nInclude links to performing basic config steps as well as using\neither OpenStack Networking or nova-network.\n\nChange-Id: I1b9568c4765fb5820e24045dbfcd5e834f1894e0\nbackport: juno\nCloses-Bug: 1372492\n(cherry picked from commit e821eda3cf36dc5b20eedc11df437d50bdba04ad)\n'}]",0,142881,b4682abd9c4e9096892f494b5f80af6f1bdf4d57,8,5,1,9515,,,0,"Clarify Installation Guide sections for compute node installation

Add note to compute guide installation section to clarify what
sections are needed to only install additional compute nodes.
Include links to performing basic config steps as well as using
either OpenStack Networking or nova-network.

Change-Id: I1b9568c4765fb5820e24045dbfcd5e834f1894e0
backport: juno
Closes-Bug: 1372492
(cherry picked from commit e821eda3cf36dc5b20eedc11df437d50bdba04ad)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/81/142881/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_nova-compute-install.xml'],1,b4682abd9c4e9096892f494b5f80af6f1bdf4d57,bug/1372492," <note> <para>This section assumes that you are following the instructions in this guide step-by-step to configure the first compute node. If you want to configure additional compute nodes, prepare them in a similar fashion to the first compute node in the <link linkend=""architecture_example-architectures"">example architectures </link> section using the same networking service as your existing environment. For either networking service, follow the <link linkend=""basics-ntp-other-nodes"">NTP configuration</link> and <link linkend=""basics-packages"">OpenStack packages</link> instructions. For OpenStack Networking (neutron), also follow the <link linkend=""basics-networking-neutron"">OpenStack Networking compute node</link> instructions. For legacy networking (nova-network), also follow the <link linkend=""basics-networking-nova"">legacy networking compute node</link> instructions. Each additional compute node requires unique IP addresses.</para> </note>",,18,0
openstack%2Fsecurity-doc~master~Iffc425d63b9b1ce86f4d0ad7dd68542d7b7b8bf3,openstack/security-doc,master,Iffc425d63b9b1ce86f4d0ad7dd68542d7b7b8bf3,Updated from openstack-manuals,MERGED,2014-12-19 06:37:13.000000000,2014-12-19 06:54:49.000000000,2014-12-19 06:54:48.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-19 06:37:13.000000000', 'files': ['glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/4d1ededdbb7752d0672da32a5594ff6cf5569020', 'message': 'Updated from openstack-manuals\n\nChange-Id: Iffc425d63b9b1ce86f4d0ad7dd68542d7b7b8bf3\n'}]",0,142998,4d1ededdbb7752d0672da32a5594ff6cf5569020,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Iffc425d63b9b1ce86f4d0ad7dd68542d7b7b8bf3
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/98/142998/1 && git format-patch -1 --stdout FETCH_HEAD,['glossary/locale/ja.po'],1,4d1ededdbb7752d0672da32a5594ff6cf5569020,openstack/openstack-manuals,"""POT-Creation-Date: 2014-12-18 22:19+0000\n"" ""PO-Revision-Date: 2014-12-19 02:21+0000\n""msgstr ""IP アドレスの割り当て、割り当て解除、管理を自動化するプロセス。現在、Compute、melange、Networking により提供される。""msgstr ""Networking により、受信リクエストを指定されたインスタンス間で均等に分散できるようになる。""msgstr ""伝統的なパーティションスキーマよりも柔軟に、大規模ストレージデバイスに領域を割り当てる方式を提供する。""","""POT-Creation-Date: 2014-12-15 18:58+0000\n"" ""PO-Revision-Date: 2014-12-15 19:11+0000\n""msgstr """"msgstr """"msgstr """"",5,5
openstack%2Foperations-guide~master~I2d9c60087964135cfadf2f0fa12ae3cd0836ac44,openstack/operations-guide,master,I2d9c60087964135cfadf2f0fa12ae3cd0836ac44,Updated from openstack-manuals,MERGED,2014-12-19 06:37:10.000000000,2014-12-19 06:54:22.000000000,2014-12-19 06:54:21.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-19 06:37:10.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/89d446bdf9dd5d561771bcb5065abe759774a113', 'message': 'Updated from openstack-manuals\n\nChange-Id: I2d9c60087964135cfadf2f0fa12ae3cd0836ac44\n'}]",0,142997,89d446bdf9dd5d561771bcb5065abe759774a113,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I2d9c60087964135cfadf2f0fa12ae3cd0836ac44
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/97/142997/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,89d446bdf9dd5d561771bcb5065abe759774a113,openstack/openstack-manuals,"""POT-Creation-Date: 2014-12-18 22:19+0000\n"" ""PO-Revision-Date: 2014-12-19 02:21+0000\n""msgstr ""IP アドレスの割り当て、割り当て解除、管理を自動化するプロセス。現在、Compute、melange、Networking により提供される。""msgstr ""Networking により、受信リクエストを指定されたインスタンス間で均等に分散できるようになる。""msgstr ""伝統的なパーティションスキーマよりも柔軟に、大規模ストレージデバイスに領域を割り当てる方式を提供する。""","""POT-Creation-Date: 2014-12-15 18:58+0000\n"" ""PO-Revision-Date: 2014-12-15 19:11+0000\n""msgstr """"msgstr """"msgstr """"",5,5
openstack%2Fha-guide~master~Ia51503753d32610af652bf40aa45970e281afaf6,openstack/ha-guide,master,Ia51503753d32610af652bf40aa45970e281afaf6,Updated from openstack-manuals,MERGED,2014-12-19 06:37:05.000000000,2014-12-19 06:53:50.000000000,2014-12-19 06:53:50.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-19 06:37:05.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/3822199fd86946d0b663575842c90d2d98e3203c', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ia51503753d32610af652bf40aa45970e281afaf6\n'}]",0,142996,3822199fd86946d0b663575842c90d2d98e3203c,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Ia51503753d32610af652bf40aa45970e281afaf6
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/96/142996/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,3822199fd86946d0b663575842c90d2d98e3203c,openstack/openstack-manuals,"""POT-Creation-Date: 2014-12-18 22:19+0000\n"" ""PO-Revision-Date: 2014-12-19 02:21+0000\n""msgstr ""IP アドレスの割り当て、割り当て解除、管理を自動化するプロセス。現在、Compute、melange、Networking により提供される。""msgstr ""Networking により、受信リクエストを指定されたインスタンス間で均等に分散できるようになる。""msgstr ""伝統的なパーティションスキーマよりも柔軟に、大規模ストレージデバイスに領域を割り当てる方式を提供する。""","""POT-Creation-Date: 2014-12-15 18:58+0000\n"" ""PO-Revision-Date: 2014-12-15 19:11+0000\n""msgstr """"msgstr """"msgstr """"",5,5
openstack%2Fopenstack-manuals~master~I3eed70c64b8e55291a22947d9805d5afe799db2f,openstack/openstack-manuals,master,I3eed70c64b8e55291a22947d9805d5afe799db2f,Imported Translations from Transifex,MERGED,2014-12-19 06:14:50.000000000,2014-12-19 06:34:51.000000000,2014-12-19 06:34:50.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-19 06:14:50.000000000', 'files': ['doc/user-guide/locale/ja.po', 'doc/install-guide/locale/pt_BR.po', 'doc/user-guide/locale/fr.po', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/install-guide/locale/ja.po', 'doc/user-guide/locale/user-guide.pot', 'doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fff7afd0ea9e253e33fb0113afb2f67ebfc2c666', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I3eed70c64b8e55291a22947d9805d5afe799db2f\n'}]",0,142990,fff7afd0ea9e253e33fb0113afb2f67ebfc2c666,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I3eed70c64b8e55291a22947d9805d5afe799db2f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/90/142990/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/pt_BR.po', 'doc/user-guide/locale/ja.po', 'doc/user-guide/locale/fr.po', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/install-guide/locale/ja.po', 'doc/glossary/locale/ja.po', 'doc/user-guide/locale/user-guide.pot']",7,fff7afd0ea9e253e33fb0113afb2f67ebfc2c666,transifex/translations,"""POT-Creation-Date: 2014-12-19 06:14+0000\n""#: ./doc/user-guide/section_cli_nova_boot.xml:189(replaceable) ./doc/user-guide/app_cheat_sheet.xml:167(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:15(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:19(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:39(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:44(replaceable) ./doc/user-guide/section_cli_nova_get_console.xml:30(replaceable)msgid ""Administrative users might want to suspend an instance if it is infrequently used or to perform system maintenance. When you suspend an instance, its VM state is stored on disk, all memory is written to disk, and the virtual machine is stopped. Suspending an instance is similar to placing a device in hibernation.""#: ./doc/user-guide/section_cli_nova_startstop.xml:33(para) msgid ""Suspending an instance will not free allocated memory or virtual CPU resources. To release them, delete the instance."" msgstr """" #: ./doc/user-guide/section_cli_nova_startstop.xml:37(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:42(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:49(title)#: ./doc/user-guide/section_cli_nova_startstop.xml:50(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:55(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:57(term)#: ./doc/user-guide/section_cli_nova_startstop.xml:58(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:61(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:66(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:73(replaceable)#: ./doc/user-guide/section_cli_nova_startstop.xml:64(term)#: ./doc/user-guide/section_cli_nova_startstop.xml:65(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:69(term)#: ./doc/user-guide/section_cli_nova_startstop.xml:70(para)","""POT-Creation-Date: 2014-12-15 06:10+0000\n""#: ./doc/user-guide/section_cli_nova_boot.xml:189(replaceable) ./doc/user-guide/app_cheat_sheet.xml:167(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:15(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:19(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:36(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:41(replaceable) ./doc/user-guide/section_cli_nova_get_console.xml:30(replaceable)msgid ""Administrative users might want to suspend an instance if it is infrequently used or to perform system maintenance. When you suspend an instance, its VM state is stored on disk, all memory is written to disk, and the virtual machine is stopped. Suspending an instance is similar to placing a device in hibernation; memory and vCPUs become available to create other instances.""#: ./doc/user-guide/section_cli_nova_startstop.xml:34(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:39(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:46(title)#: ./doc/user-guide/section_cli_nova_startstop.xml:47(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:52(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:54(term)#: ./doc/user-guide/section_cli_nova_startstop.xml:55(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:58(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:63(replaceable) ./doc/user-guide/section_cli_nova_startstop.xml:70(replaceable)#: ./doc/user-guide/section_cli_nova_startstop.xml:61(term)#: ./doc/user-guide/section_cli_nova_startstop.xml:62(para)#: ./doc/user-guide/section_cli_nova_startstop.xml:66(term)#: ./doc/user-guide/section_cli_nova_startstop.xml:67(para)",189,145
openstack%2Fswift~master~I1daf0b247358d260bc4495ead275b8a3f650885d,openstack/swift,master,I1daf0b247358d260bc4495ead275b8a3f650885d,"Added Nicolas, who was erantly left out of AUTHORS",ABANDONED,2014-12-19 05:03:32.000000000,2014-12-19 06:25:51.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-19 05:03:32.000000000', 'files': ['AUTHORS'], 'web_link': 'https://opendev.org/openstack/swift/commit/1281ec9b7d7302f03277ca611eec2a1c4977c224', 'message': 'Added Nicolas, who was erantly left out of AUTHORS\n\nChange-Id: I1daf0b247358d260bc4495ead275b8a3f650885d\n'}]",0,142983,1281ec9b7d7302f03277ca611eec2a1c4977c224,7,3,1,330,,,0,"Added Nicolas, who was erantly left out of AUTHORS

Change-Id: I1daf0b247358d260bc4495ead275b8a3f650885d
",git fetch https://review.opendev.org/openstack/swift refs/changes/83/142983/1 && git format-patch -1 --stdout FETCH_HEAD,['AUTHORS'],1,1281ec9b7d7302f03277ca611eec2a1c4977c224,oops,Nicolas Trangez (ikke@nicolast.be),,1,0
openstack%2Fneutron~master~I7b89feef3f19ca07dbfb05acfaa30529a5bf683d,openstack/neutron,master,I7b89feef3f19ca07dbfb05acfaa30529a5bf683d,Move DB TestModelsMigrations from unit to functional,MERGED,2014-10-05 05:27:38.000000000,2014-12-19 06:18:06.000000000,2014-12-19 05:31:56.000000000,"[{'_account_id': 3}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5892}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-10-05 05:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39600062b12d57c751e260e8f14f4c51e9e976e0', 'message': 'Test\n\nDB migrations check in functional job.\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 2, 'created': '2014-10-05 14:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cb70e14ca5e74e60b5e70cebf7b9b605bbff8c07', 'message': 'Test\n\nDB migrations check in functional job.\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 3, 'created': '2014-10-05 17:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/615699808052f216e013ba32be028e3079025a17', 'message': 'Test\n\nDB migrations check in functional job.\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 4, 'created': '2014-10-05 18:02:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78f9dc9f3afb2f8569d6bf4e2ac65712fbc11b57', 'message': 'Test\n\nDB migrations check in functional job.\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 5, 'created': '2014-10-05 19:36:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c264884dd144601481b31d08b478344e7c6d7e6', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends on the\nmysql and postgresql backends being available with a specific DB user and\ndatabase created. This violates the principles for unit tests and therefore\nthese tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the backends must be\ninstalled and the DB user and database created. We do this via the functional\ngate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 6, 'created': '2014-10-05 19:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/898a915c0b6f9796865a3633b881f1b0bd197d83', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 7, 'created': '2014-10-06 15:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/badc42a63fea932d7c0756318763aff60e1c3aee', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 8, 'created': '2014-12-10 00:22:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4847193b8c3e100651dd67ceffdd533cfb53a39b', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 9, 'created': '2014-12-10 00:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a7e83c3dd63f860183f96897409a6d2f1b0e5508', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 10, 'created': '2014-12-10 16:16:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b12fc64b0d4f503859983c2231edc4d9285faf20', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 11, 'created': '2014-12-10 17:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f212c7bf1e1de2c71f807527ac4af628cc0d6609', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 12, 'created': '2014-12-15 11:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5fea98da88fd52918d02e0c5cd440c00149c8138', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 13, 'created': '2014-12-15 12:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/40258707b9554f0f32b657199d4d7243a0082d29', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 14, 'created': '2014-12-18 16:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5e4214242ba302f466dfa716174a7f0763209a65', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 15, 'created': '2014-12-18 19:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a013f177bc6c9eae88d855933f82c3b2411a8e85', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}, {'number': 16, 'created': '2014-12-19 03:44:02.000000000', 'files': ['doc/source/devref/db_layer.rst', 'test-requirements.txt', 'neutron/tests/contrib/gate_hook.sh', 'neutron/tests/functional/db/test_migrations.py', 'tox.ini', 'neutron/tests/functional/requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3e0745827f414ecc39a0b0a40349e3646a8e2db9', 'message': 'Move DB TestModelsMigrations from unit to functional\n\nThe tests to check that DB migrations and models are in sync depends\non the mysql and postgresql backends being available with a specific\nDB user and database created. This violates the principles for unit\ntests and therefore these tests should be moved to functional tests.\n\nFor these tests to work in the functional job in the gate, the\nbackends must be installed and the DB user and database created.\nWe do this via the functional gate hook.\n\nCloses-bug: #1372981\n\nChange-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d\n'}]",4,126175,3e0745827f414ecc39a0b0a40349e3646a8e2db9,299,33,16,6524,,,0,"Move DB TestModelsMigrations from unit to functional

The tests to check that DB migrations and models are in sync depends
on the mysql and postgresql backends being available with a specific
DB user and database created. This violates the principles for unit
tests and therefore these tests should be moved to functional tests.

For these tests to work in the functional job in the gate, the
backends must be installed and the DB user and database created.
We do this via the functional gate hook.

Closes-bug: #1372981

Change-Id: I7b89feef3f19ca07dbfb05acfaa30529a5bf683d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/75/126175/16 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/contrib/gate_hook.sh', 'neutron/tests/functional/db/test_migration.py']",2,39600062b12d57c751e260e8f14f4c51e9e976e0,bug/1393691,,,36,0
openstack%2Fneutron~stable%2Fjuno~I965232930502c21b605fe360bb138bb6ea73d2b0,openstack/neutron,stable/juno,I965232930502c21b605fe360bb138bb6ea73d2b0,Auto allocate gateway_ip even for SLAAC subnets,MERGED,2014-12-16 06:56:44.000000000,2014-12-19 06:05:23.000000000,2014-12-19 04:01:03.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10257}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-16 06:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4eb7d589f44cb1ff171ce1e27f3aa79ac13c997', 'message': 'Auto allocate gateway_ip even for SLAAC subnets\n\nFor a SLAAC subnet that is created without specifying the gateway_ip,\nNeutron currently allocates (If0c48a7287a828eef4a0f0b0859d4f898d2937bd)\nthe gateway_ip at a later stage (i.e., neutron router_interface_add).\nIn order to keep the API consistent between IPv4 and IPv6, it is\nrecommended to allocate the gateway_ip during subnet_create stage itself.\n\nCloses-Bug: #1394112\nChange-Id: I965232930502c21b605fe360bb138bb6ea73d2b0\n(cherry picked from commit 66dcb8b935a00e7f7566802d662ebb1f265eab1f)\n'}, {'number': 2, 'created': '2014-12-16 18:28:58.000000000', 'files': ['neutron/tests/unit/test_l3_plugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/tests/unit/oneconvergence/test_nvsd_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f97180833958da7b99b51232561df7201bb3caf', 'message': 'Auto allocate gateway_ip even for SLAAC subnets\n\nFor a SLAAC subnet that is created without specifying the gateway_ip,\nNeutron currently allocates (If0c48a7287a828eef4a0f0b0859d4f898d2937bd)\nthe gateway_ip at a later stage (i.e., neutron router_interface_add).\nIn order to keep the API consistent between IPv4 and IPv6, it is\nrecommended to allocate the gateway_ip during subnet_create stage itself.\n\nCloses-Bug: #1402407\nCloses-Bug: #1394112\nPartial-Bug: #1377985\nChange-Id: I965232930502c21b605fe360bb138bb6ea73d2b0\n(cherry picked from commit 66dcb8b935a00e7f7566802d662ebb1f265eab1f)\n'}]",0,142002,2f97180833958da7b99b51232561df7201bb3caf,35,16,2,10257,,,0,"Auto allocate gateway_ip even for SLAAC subnets

For a SLAAC subnet that is created without specifying the gateway_ip,
Neutron currently allocates (If0c48a7287a828eef4a0f0b0859d4f898d2937bd)
the gateway_ip at a later stage (i.e., neutron router_interface_add).
In order to keep the API consistent between IPv4 and IPv6, it is
recommended to allocate the gateway_ip during subnet_create stage itself.

Closes-Bug: #1402407
Closes-Bug: #1394112
Partial-Bug: #1377985
Change-Id: I965232930502c21b605fe360bb138bb6ea73d2b0
(cherry picked from commit 66dcb8b935a00e7f7566802d662ebb1f265eab1f)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/02/142002/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_l3_plugin.py', 'neutron/tests/unit/oneconvergence/test_nvsd_plugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/l3_db.py']",5,d4eb7d589f44cb1ff171ce1e27f3aa79ac13c997,," if not subnet['gateway_ip']: fixed_ip = {'ip_address': subnet['gateway_ip'], 'subnet_id': subnet['id']}","from neutron.common import ipv6_utils if (not subnet['gateway_ip'] and not ipv6_utils.is_slaac_subnet(subnet)): if subnet['gateway_ip']: fixed_ip = {'ip_address': subnet['gateway_ip'], 'subnet_id': subnet['id']} else: fixed_ip = {'subnet_id': subnet['id']}",20,14
openstack%2Fcinder-specs~master~I9f06fc86bcdd24d9cf73d4ac2aefb6065ed4360e,openstack/cinder-specs,master,I9f06fc86bcdd24d9cf73d4ac2aefb6065ed4360e,Add test for trailing spaces in specs,MERGED,2014-12-18 13:06:08.000000000,2014-12-19 05:36:28.000000000,2014-12-19 05:36:27.000000000,"[{'_account_id': 3}, {'_account_id': 170}]","[{'number': 1, 'created': '2014-12-18 13:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/e0dfd8e4455c6db798410da2226c0ad7b606fc30', 'message': 'Add test for trailing spaces in specs\n\nI tired to do it manually each time in review. Let Jenkins do it.\nAll existing specs in for Juno and Kilo fixed.\n\nChange-Id: I9f06fc86bcdd24d9cf73d4ac2aefb6065ed4360e\n'}, {'number': 2, 'created': '2014-12-18 13:22:13.000000000', 'files': ['tests/test_titles.py', 'specs/juno/cinder-storwize-driver-qos.rst', 'specs/juno/pool-aware-cinder-scheduler.rst', 'specs/juno/restblock-driver.rst', 'specs/juno/hyper-v-smbfs-volume-driver.rst', 'specs/juno/smbfs-volume-driver.rst', 'specs/kilo/incremental-backup.rst', 'specs/kilo/xio-volume-driver-1-1.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/ab63d6b01ddef2a9f762f79d37df0770adae7a4a', 'message': 'Add test for trailing spaces in specs\n\nI tired to do it manually each time in review. Let Jenkins do it.\nAll existing specs in for Juno and Kilo fixed.\n\nChange-Id: I9f06fc86bcdd24d9cf73d4ac2aefb6065ed4360e\n'}]",0,142765,ab63d6b01ddef2a9f762f79d37df0770adae7a4a,8,2,2,1736,,,0,"Add test for trailing spaces in specs

I tired to do it manually each time in review. Let Jenkins do it.
All existing specs in for Juno and Kilo fixed.

Change-Id: I9f06fc86bcdd24d9cf73d4ac2aefb6065ed4360e
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/65/142765/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_titles.py', 'specs/juno/cinder-storwize-driver-qos.rst', 'specs/juno/pool-aware-cinder-scheduler.rst', 'specs/juno/restblock-driver.rst', 'specs/juno/hyper-v-smbfs-volume-driver.rst', 'specs/juno/smbfs-volume-driver.rst', 'specs/kilo/incremental-backup.rst', 'specs/kilo/xio-volume-driver-1-1.rst']",8,e0dfd8e4455c6db798410da2226c0ad7b606fc30,bug/1403869,"- QoS specs - add ability to pass down IOPSmin, IOPSmax and IOPSburst to","- QoS specs - add ability to pass down IOPSmin, IOPSmax and IOPSburst to ",14,7
openstack%2Fcinder-specs~master~I6a31e86bbbb05d72e5d6169efa45fe85418fe036,openstack/cinder-specs,master,I6a31e86bbbb05d72e5d6169efa45fe85418fe036,Fix search path for specs in tests,MERGED,2014-12-18 13:06:08.000000000,2014-12-19 05:32:35.000000000,2014-12-19 05:32:35.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 7198}]","[{'number': 1, 'created': '2014-12-18 13:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/cfa1188bd597d6e74b9f9dc6b596b7f2e5aa6bb6', 'message': ""Fix search path for specs in tests\n\nAlso more verbose error message added for '_check_titles' test\n\nChange-Id: I6a31e86bbbb05d72e5d6169efa45fe85418fe036\nCloses-Bug: #1403869\n""}, {'number': 2, 'created': '2014-12-18 13:20:28.000000000', 'files': ['tests/test_titles.py', 'specs/kilo/over-subscription-in-thin-provisioning.rst', 'specs/kilo/support-iscsi-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/ec868741aa8f4a7b3ac8608a38b0261694abcbc1', 'message': ""Fix search path for specs in tests\n\nAlso more verbose error message added for '_check_titles' test\n\nChange-Id: I6a31e86bbbb05d72e5d6169efa45fe85418fe036\nCloses-Bug: #1403869\n""}]",3,142764,ec868741aa8f4a7b3ac8608a38b0261694abcbc1,12,4,2,1736,,,0,"Fix search path for specs in tests

Also more verbose error message added for '_check_titles' test

Change-Id: I6a31e86bbbb05d72e5d6169efa45fe85418fe036
Closes-Bug: #1403869
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/64/142764/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_titles.py', 'specs/kilo/over-subscription-in-thin-provisioning.rst']",2,cfa1188bd597d6e74b9f9dc6b596b7f2e5aa6bb6,bug/1403869,-------------,===============,18,6
openstack%2Fceilometer~master~I0287058e8eebff6413268526504011914651cc94,openstack/ceilometer,master,I0287058e8eebff6413268526504011914651cc94,Avoid NoneType error when inspect mem usage failed,ABANDONED,2014-12-17 04:02:00.000000000,2014-12-19 05:05:01.000000000,,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-12-17 04:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fa75a933b0cade55bf9031bb65be4cbeeaad0cc7', 'message': 'Avoid NoneType error when inspect mem usage failed\n\nWhen MemoryUsagePollster get samples failed for inspector cannot get\nmemory usage of instance, a NoneType error will be record in log file.\n\nChange-Id: I0287058e8eebff6413268526504011914651cc94\n'}, {'number': 2, 'created': '2014-12-18 09:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/157fbb2a7a54efe1653eab36648146e5d30ed330', 'message': 'Avoid NoneType error when inspect mem usage failed\n\nWhen MemoryUsagePollster get samples failed for inspector cannot get\nmemory usage of instance, a NoneType error will be record in log file.\n\nChange-Id: I0287058e8eebff6413268526504011914651cc94\nCloses-bug: #1403787\n'}, {'number': 3, 'created': '2014-12-19 01:06:53.000000000', 'files': ['ceilometer/compute/pollsters/memory.py', 'ceilometer/tests/compute/pollsters/test_memory.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/46c03c40f9688f30d36af2ed5713033f44a91edb', 'message': 'Avoid NoneType error when inspect mem usage failed\n\nWhen MemoryUsagePollster get samples failed for inspector cannot get\nmemory usage of instance, a NoneType error will be record in log file.\n\nChange-Id: I0287058e8eebff6413268526504011914651cc94\nCloses-bug: #1403787\n'}]",4,142329,46c03c40f9688f30d36af2ed5713033f44a91edb,22,9,3,8290,,,0,"Avoid NoneType error when inspect mem usage failed

When MemoryUsagePollster get samples failed for inspector cannot get
memory usage of instance, a NoneType error will be record in log file.

Change-Id: I0287058e8eebff6413268526504011914651cc94
Closes-bug: #1403787
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/29/142329/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/compute/pollsters/memory.py', 'ceilometer/tests/compute/pollsters/test_memory.py']",2,fa75a933b0cade55bf9031bb65be4cbeeaad0cc7,mem_usage," def test_get_samples_with_inspect_mem_failed(self): self.inspector.inspect_memory_usage = mock.Mock(return_value=None) mgr = manager.AgentManager() pollster = memory.MemoryUsagePollster() cache = {} LOG = mock.MagicMock() with mock.patch('ceilometer.compute.pollsters.memory.LOG', LOG): samples = list(pollster.get_samples(mgr, cache, [self.instance])) self.assertIsEmpty(samples) LOG.debug.assert_called_with('Could not get Memory Usage for ' 'instance %s', self.instance.id)",,16,0
openstack%2Fneutron~master~I792697b94fef39971693cf8aff715c270601cecb,openstack/neutron,master,I792697b94fef39971693cf8aff715c270601cecb,Fix AttributeError during startup of ovs agent in DVR mode,MERGED,2014-11-21 23:34:45.000000000,2014-12-19 04:46:42.000000000,2014-12-19 02:49:58.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8645}, {'_account_id': 9305}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14103}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-11-21 23:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b3658bb18cbcef6b8227d2501d09744bd98ec79', 'message': 'Fix AttributeError during startup of ovs agent in DVR mode\n\nMake sure the agent starts processing incoming requests only\nafter the entire initialization is complete. This is done by\ndeferring the rpc loop all the way to the end of the agent\ninit code.\n\nThis fix was necessary because the agent starts processing\nrpc messages even though it has not completed the entire\ninitialization of bridges, etc.\n\nThis is usually okay, but especially in distributed mode,\nthis leads to a chicken-and-egg problem when the agent\nrequires the DVR MAC address for the host, the first time\nit starts.\n\nChange-Id: I792697b94fef39971693cf8aff715c270601cecb\nCloses-bug: #1395196\n'}, {'number': 2, 'created': '2014-12-05 04:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3581ff7e951fa17b669e7323fd799c80ef9fe5e7', 'message': 'Fix AttributeError during startup of ovs agent in DVR mode\n\nMake sure the agent starts processing incoming requests only after the entire\ninitialization is complete. This is done by making explicit when the rpc loop\nis supposed to start, i.e. right at the end of the init process.\n\nThis fix was necessary because the agent starts processing rpc messages even\nthough it has not completed the entire initialization of bridges and data\nstructures; this is usually okay, but in case of DVR, this leads to a\nsituation where during the the first run, the agent asks the server to be\nassigned a MAC address; this in turn leads the server to fanout the generated\nMAC to the running agents, the requesting one included; because of the\nincomplete setup, the above mentioned error occurs. During subsequent\nrestarts, the problem no longer appears.\n\nCloses-bug: #1395196\n\nChange-Id: I792697b94fef39971693cf8aff715c270601cecb\n'}, {'number': 3, 'created': '2014-12-08 19:58:13.000000000', 'files': ['neutron/tests/unit/test_agent_rpc.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/agent/rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa728c00bab3bb6b3e00866e44ca054b1e848bb6', 'message': 'Fix AttributeError during startup of ovs agent in DVR mode\n\nMake sure the agent starts processing incoming requests only after the entire\ninitialization is complete. This is done by making explicit when the rpc loop\nis supposed to start, i.e. right at the end of the init process.\n\nThis fix was necessary because the agent starts processing rpc messages even\nthough it has not completed the entire initialization of bridges and data\nstructures; this is usually okay, but in case of DVR, this leads to a\nsituation where during the the first run, the agent asks the server to be\nassigned a MAC address; this in turn leads the server to fanout the generated\nMAC to the running agents, the requesting one included; because of the\nincomplete setup, the above mentioned error occurs. During subsequent\nrestarts, the problem no longer appears.\n\nCloses-bug: #1395196\n\nChange-Id: I792697b94fef39971693cf8aff715c270601cecb\n'}]",13,136529,aa728c00bab3bb6b3e00866e44ca054b1e848bb6,104,35,3,748,,,0,"Fix AttributeError during startup of ovs agent in DVR mode

Make sure the agent starts processing incoming requests only after the entire
initialization is complete. This is done by making explicit when the rpc loop
is supposed to start, i.e. right at the end of the init process.

This fix was necessary because the agent starts processing rpc messages even
though it has not completed the entire initialization of bridges and data
structures; this is usually okay, but in case of DVR, this leads to a
situation where during the the first run, the agent asks the server to be
assigned a MAC address; this in turn leads the server to fanout the generated
MAC to the running agents, the requesting one included; because of the
incomplete setup, the above mentioned error occurs. During subsequent
restarts, the problem no longer appears.

Closes-bug: #1395196

Change-Id: I792697b94fef39971693cf8aff715c270601cecb
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/136529/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_agent_rpc.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/agent/rpc.py']",3,2b3658bb18cbcef6b8227d2501d09744bd98ec79,bug/1395196,"def create_consumers(endpoints, prefix, topic_details, start_listening=True): :param start_listening: if True, it starts the processing loop if start_listening: connection.consume_in_threads()","def create_consumers(endpoints, prefix, topic_details): connection.consume_in_threads()",34,8
openstack%2Fcinder~master~I26cc5ea4ee8cc63be7c7f61240b91b8b7f92c1a6,openstack/cinder,master,I26cc5ea4ee8cc63be7c7f61240b91b8b7f92c1a6,Move 3 Fujitsu ETERNUS DX related file,ABANDONED,2014-12-19 04:07:46.000000000,2014-12-19 04:09:38.000000000,,[],"[{'number': 1, 'created': '2014-12-19 04:07:46.000000000', 'files': ['cinder/volume/drivers/fujitsu/__init__.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/62148d76208d3123ef44caaf1fcab4240cc01ec2', 'message': ""Move 3 Fujitsu ETERNUS DX related file\n\nSince there are three volume driver files relating to Fujitsu ETERNUS DX in cinder.volume.drivers,\nI make 'fujitsu' directory at cinder.volume.drivers and I move these files to the directory.\n\nCloses-Bug #1402349\nhttps://bugs.launchpad.net/cinder/+bug/1402349\n\nChange-Id: I26cc5ea4ee8cc63be7c7f61240b91b8b7f92c1a6\n""}]",0,142977,62148d76208d3123ef44caaf1fcab4240cc01ec2,2,0,1,10674,,,0,"Move 3 Fujitsu ETERNUS DX related file

Since there are three volume driver files relating to Fujitsu ETERNUS DX in cinder.volume.drivers,
I make 'fujitsu' directory at cinder.volume.drivers and I move these files to the directory.

Closes-Bug #1402349
https://bugs.launchpad.net/cinder/+bug/1402349

Change-Id: I26cc5ea4ee8cc63be7c7f61240b91b8b7f92c1a6
",git fetch https://review.opendev.org/openstack/cinder refs/changes/77/142977/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/fujitsu/__init__.py'],1,62148d76208d3123ef44caaf1fcab4240cc01ec2,bug/1402349,,,0,0
openstack%2Fcinder~master~I2bce27a3c05a0382fd94ded2454a211e03c0d941,openstack/cinder,master,I2bce27a3c05a0382fd94ded2454a211e03c0d941,Move 3 Fujitsu ETERNUS DX related file,ABANDONED,2014-12-19 04:00:41.000000000,2014-12-19 04:09:15.000000000,,[],"[{'number': 1, 'created': '2014-12-19 04:00:41.000000000', 'files': ['cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_fc.py', 'cinder/tests/test_fujitsu.py', 'cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_iscsi.py', 'cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/986c7125b69b61a7e660315d369fd5b7bfb6f804', 'message': ""Move 3 Fujitsu ETERNUS DX related file\n\nSince there are three volume driver files relating to Fujitsu ETERNUS DX in cinder.volume.drivers,\nI make 'fujitsu' directory at cinder.volume.drivers and I move these files to the directory.\n\nCloses-Bug #1402349\nhttps://bugs.launchpad.net/cinder/+bug/1402349\n\nChange-Id: I2bce27a3c05a0382fd94ded2454a211e03c0d941\n""}]",0,142976,986c7125b69b61a7e660315d369fd5b7bfb6f804,2,0,1,10674,,,0,"Move 3 Fujitsu ETERNUS DX related file

Since there are three volume driver files relating to Fujitsu ETERNUS DX in cinder.volume.drivers,
I make 'fujitsu' directory at cinder.volume.drivers and I move these files to the directory.

Closes-Bug #1402349
https://bugs.launchpad.net/cinder/+bug/1402349

Change-Id: I2bce27a3c05a0382fd94ded2454a211e03c0d941
",git fetch https://review.opendev.org/openstack/cinder refs/changes/76/142976/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_fc.py', 'cinder/tests/test_fujitsu.py', 'cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_iscsi.py', 'cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_common.py']",4,986c7125b69b61a7e660315d369fd5b7bfb6f804,bug/1402349,,,5,5
openstack%2Fcongress~master~Ib0b8fa9185553301a95b093a939b306e3b94d25a,openstack/congress,master,Ib0b8fa9185553301a95b093a939b306e3b94d25a,Fix passing incorrect args to LOG,ABANDONED,2014-11-20 22:35:10.000000000,2014-12-19 04:01:34.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-11-20 22:35:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/532a75a5675efc769913031a8925664a5439c4d8', 'message': 'Fix passing incorrect args to LOG\n\nChange-Id: Ib0b8fa9185553301a95b093a939b306e3b94d25a\ncloses-bug: 1394781\n'}, {'number': 2, 'created': '2014-12-19 04:01:25.000000000', 'files': ['congress/policy/runtime.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/8a03ad663f6dc19ef0f9078ec5a1c00a1772334c', 'message': 'Fix passing incorrect args to LOG\n\nChange-Id: Ib0b8fa9185553301a95b093a939b306e3b94d25a\ncloses-bug: 1394781\n'}]",1,136157,8a03ad663f6dc19ef0f9078ec5a1c00a1772334c,10,4,2,4395,,,0,"Fix passing incorrect args to LOG

Change-Id: Ib0b8fa9185553301a95b093a939b306e3b94d25a
closes-bug: 1394781
",git fetch https://review.opendev.org/openstack/congress refs/changes/57/136157/2 && git format-patch -1 --stdout FETCH_HEAD,['congress/policy/runtime.py'],1,532a75a5675efc769913031a8925664a5439c4d8,bug/1394781," func(""%s %s %s"" % ((""| "" * depth), msg, args))"," func((""| "" * depth) + msg, *args)",1,1
openstack%2Fneutron~master~I32049399b16338996d6bef342c004d5de2446cf1,openstack/neutron,master,I32049399b16338996d6bef342c004d5de2446cf1,tests: drop unit tests that only check default configuration values,MERGED,2014-12-16 19:30:34.000000000,2014-12-19 03:49:35.000000000,2014-12-19 03:49:33.000000000,"[{'_account_id': 3}, {'_account_id': 2035}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 7743}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 11822}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-16 19:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/14f4c0f906a95bf1a10a0493c4800fb982e98f67', 'message': 'tests: drop unit tests that only check default configuration values\n\nThose tests do not add much value and only introduce burden when a\ndefault value should be changed.\n\nChange-Id: I32049399b16338996d6bef342c004d5de2446cf1\n'}, {'number': 2, 'created': '2014-12-17 11:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/071873995015776f36d15e6abeb02dab4c8c6985', 'message': 'tests: drop unit tests that only check default configuration values\n\nThose tests do not add much value and only introduce burden when a\ndefault value should be changed.\n\nChange-Id: I32049399b16338996d6bef342c004d5de2446cf1\n'}, {'number': 3, 'created': '2014-12-18 20:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5eb7b19576cf7d00dd1eb6052aa7e739bec164ef', 'message': 'tests: drop unit tests that only check default configuration values\n\nThose tests do not add much value and only introduce burden when a\ndefault value should be changed.\n\nChange-Id: I32049399b16338996d6bef342c004d5de2446cf1\n'}, {'number': 4, 'created': '2014-12-18 20:29:07.000000000', 'files': ['neutron/tests/unit/linuxbridge/test_defaults.py', 'neutron/tests/unit/openvswitch/test_ovs_defaults.py', 'neutron/tests/unit/test_config.py', 'neutron/tests/unit/mlnx/test_defaults.py', 'neutron/tests/unit/ofagent/test_ofa_defaults.py', 'neutron/tests/unit/embrane/test_embrane_defaults.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/534e69fa146ae2476e5cd695e92acd409c2ec6dd', 'message': 'tests: drop unit tests that only check default configuration values\n\nThose tests do not add much value and only introduce burden when a\ndefault value should be changed.\n\nChange-Id: I32049399b16338996d6bef342c004d5de2446cf1\n'}]",0,142201,534e69fa146ae2476e5cd695e92acd409c2ec6dd,72,23,4,9656,,,0,"tests: drop unit tests that only check default configuration values

Those tests do not add much value and only introduce burden when a
default value should be changed.

Change-Id: I32049399b16338996d6bef342c004d5de2446cf1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/142201/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/linuxbridge/test_defaults.py', 'neutron/tests/unit/openvswitch/test_ovs_defaults.py', 'neutron/tests/unit/mlnx/test_defaults.py', 'neutron/tests/unit/ofagent/test_ofa_defaults.py', 'neutron/tests/unit/embrane/test_embrane_defaults.py']",5,14f4c0f906a95bf1a10a0493c4800fb982e98f67,drop-unneeded-test,,"# Copyright 2013 Embrane, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo.config import cfg from neutron.plugins.embrane.common import config # noqa from neutron.tests import base class ConfigurationTest(base.BaseTestCase): def test_defaults(self): self.assertEqual('admin', cfg.CONF.heleos.admin_username) self.assertEqual('default', cfg.CONF.heleos.resource_pool_id) self.assertTrue(cfg.CONF.heleos.async_requests) ",0,166
openstack%2Fnova~master~Ic1bb69c8675f2ffb71cdf8a4b38ba7b02e697458,openstack/nova,master,Ic1bb69c8675f2ffb71cdf8a4b38ba7b02e697458,Use osapi_compute worker for api v2 service,MERGED,2014-12-11 01:44:27.000000000,2014-12-19 03:43:23.000000000,2014-12-18 21:35:07.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6589}, {'_account_id': 7858}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-11 01:44:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a11a8023881f8024c1887922d172af5347ae924', 'message': 'Set a config limit for api_v2 workers\n\nUnlike other API services, the openstack_compute_api_v2 service did not\nhave a throttle for workers, and would always fire off NumCPU. This\nintroduces the config entry in order to limit it like the rest.\n\nChange-Id: Ic1bb69c8675f2ffb71cdf8a4b38ba7b02e697458\n'}, {'number': 2, 'created': '2014-12-13 01:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/446c75612705fcdd64821980149c7ead1ab16be6', 'message': ""Use osapi_compute worker for api v2 service\n\nosapi_compute is intended to be a superset of the compute APIs (v1\nthrough v3 and beyond). So use the worker settings for osapi_compute\nwhen launching any service that starts with 'openstack_compute_api' that\nmight be defined in paste.ini and in enabled_apis.\n\nChange-Id: Ic1bb69c8675f2ffb71cdf8a4b38ba7b02e697458\n""}, {'number': 3, 'created': '2014-12-16 17:17:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5579070543f7d7f9ef2988d17e6da84d4e2aa198', 'message': ""Use osapi_compute worker for api v2 service\n\nosapi_compute is intended to be a superset of the compute APIs (v1\nthrough v3 and beyond). So use the worker settings for osapi_compute\nwhen launching any service that starts with 'openstack_compute_api' that\nmight be defined in paste.ini and in enabled_apis.\n\nChange-Id: Ic1bb69c8675f2ffb71cdf8a4b38ba7b02e697458\n""}, {'number': 4, 'created': '2014-12-16 20:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fc5a08fb4f62c953ab1d7a5ed1e6706e39eab1b', 'message': ""Use osapi_compute worker for api v2 service\n\nosapi_compute is intended to be a superset of the compute APIs (v1\nthrough v3 and beyond). So use the worker settings for osapi_compute\nwhen launching any service that starts with 'openstack_compute_api' that\nmight be defined in paste.ini and in enabled_apis.\n\nChange-Id: Ic1bb69c8675f2ffb71cdf8a4b38ba7b02e697458\n""}, {'number': 5, 'created': '2014-12-17 00:36:51.000000000', 'files': ['nova/service.py', 'nova/tests/unit/test_service.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/39ca2976c00023bc3666d1d209f8a53280129b38', 'message': ""Use osapi_compute worker for api v2 service\n\nosapi_compute is intended to be a superset of the compute APIs (v1\nthrough v3 and beyond). So use the worker settings for osapi_compute\nwhen launching any service that starts with 'openstack_compute_api' that\nmight be defined in paste.ini and in enabled_apis. While this could\nresult in the single setting causing nX workers, where n is each\nopenstack_compute_api_* thing defined, it is expected that only one is\nenabled, or the full superset is enabled.\n\nChange-Id: Ic1bb69c8675f2ffb71cdf8a4b38ba7b02e697458\n""}]",8,140893,39ca2976c00023bc3666d1d209f8a53280129b38,53,13,5,6589,,,0,"Use osapi_compute worker for api v2 service

osapi_compute is intended to be a superset of the compute APIs (v1
through v3 and beyond). So use the worker settings for osapi_compute
when launching any service that starts with 'openstack_compute_api' that
might be defined in paste.ini and in enabled_apis. While this could
result in the single setting causing nX workers, where n is each
openstack_compute_api_* thing defined, it is expected that only one is
enabled, or the full superset is enabled.

Change-Id: Ic1bb69c8675f2ffb71cdf8a4b38ba7b02e697458
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/140893/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/service.py'],1,0a11a8023881f8024c1887922d172af5347ae924,limit-v2-api-servers," cfg.IntOpt('openstack_compute_api_v2_workers', help='Number of workers for v2 API service. The default will ' 'be equal to the number of CPUs available.'),",,3,0
openstack%2Fcinder~master~I7a68c6b17d1676a04c55abd8ffb93d71d9c206f5,openstack/cinder,master,I7a68c6b17d1676a04c55abd8ffb93d71d9c206f5,Move 3 Fujitsu ETERNUS DX related file,ABANDONED,2014-12-19 03:35:52.000000000,2014-12-19 03:43:17.000000000,,[],"[{'number': 1, 'created': '2014-12-19 03:35:52.000000000', 'files': ['cinder/volume/drivers/fujitsu/__init__.py', 'cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_fc.py', 'cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_iscsi.py', 'cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3cd25f996ed19695aa4e2883c2fa78810aad978e', 'message': ""Move 3 Fujitsu ETERNUS DX related file\n\nSince there are three volume driver files relating to Fujitsu ETERNUS DX in cinder.voluhme.drivers,\nI make 'fujitsu' directory at cinder.volume.drivers and I move these files to the directory.\n\nCloses-Bug #1402349\nhttps://bugs.launchpad.net/cinder/+bug/1402349\n\nChange-Id: I7a68c6b17d1676a04c55abd8ffb93d71d9c206f5\n""}]",0,142972,3cd25f996ed19695aa4e2883c2fa78810aad978e,2,0,1,10674,,,0,"Move 3 Fujitsu ETERNUS DX related file

Since there are three volume driver files relating to Fujitsu ETERNUS DX in cinder.voluhme.drivers,
I make 'fujitsu' directory at cinder.volume.drivers and I move these files to the directory.

Closes-Bug #1402349
https://bugs.launchpad.net/cinder/+bug/1402349

Change-Id: I7a68c6b17d1676a04c55abd8ffb93d71d9c206f5
",git fetch https://review.opendev.org/openstack/cinder refs/changes/72/142972/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/fujitsu/__init__.py', 'cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_fc.py', 'cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_iscsi.py', 'cinder/volume/drivers/fujitsu/fujitsu_eternus_dx_common.py']",4,3cd25f996ed19695aa4e2883c2fa78810aad978e,bug/1402349,"# Copyright (c) 2014 FUJITSU LIMITED # Copyright (c) 2012 - 2014 EMC Corporation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Common class for SMI-S based FUJITSU ETERNUS DX volume drivers. This common class is for FUJITSU ETERNUS DX volume drivers based on SMI-S. """""" import base64 import hashlib import time from xml.dom.minidom import parseString from oslo.config import cfg from oslo.utils import units import six from cinder import exception from cinder.i18n import _, _LE, _LI, _LW from cinder.openstack.common import log as logging from cinder.openstack.common import loopingcall from cinder.volume import volume_types LOG = logging.getLogger(__name__) CONF = cfg.CONF try: import pywbem except ImportError: pass CINDER_CONFIG_FILE = '/etc/cinder/cinder_fujitsu_eternus_dx.xml' SMIS_ROOT = 'root/eternus' PROVISIONING = 'storagetype:provisioning' POOL = 'storagetype:pool' STOR_CONF_SVC = 'FUJITSU_StorageConfigurationService' SCSI_PROT_CTR = 'FUJITSU_AffinityGroupController' STOR_HWID = 'FUJITSU_StorageHardwareID' CTRL_CONF_SVC = 'FUJITSU_ControllerConfigurationService' STOR_HWID_MNG_SVC = 'FUJITSU_StorageHardwareIDManagementService' STOR_VOL = 'FUJITSU_StorageVolume' REPL_SVC = 'FUJITSU_ReplicationService' STOR_POOLS = ['FUJITSU_ThinProvisioningPool', 'FUJITSU_RAIDStoragePool'] AUTH_PRIV = 'FUJITSU_AuthorizedPrivilege' STOR_SYNC = 'FUJITSU_StorageSynchronized' VOL_PREFIX = 'FJosv_' drv_opts = [ cfg.StrOpt('cinder_smis_config_file', default=CINDER_CONFIG_FILE, help='The configuration file for the Cinder ' 'SMI-S driver'), ] CONF.register_opts(drv_opts) BROKEN = 5 SNAPOPC = 4 OPC = 5 RETURN_TO_RESOURCEPOOL = 19 DETACH = 8 JOB_RETRIES = 60 INTERVAL_10_SEC = 10 OPERATION_dic = {SNAPOPC: RETURN_TO_RESOURCEPOOL, OPC: DETACH } RETCODE_dic = {'0': 'Success', '1': 'Method Not Supported', '4': 'Failed', '5': 'Invalid Parameter', '4097': 'Size Not Supported', '32769': 'Maximum number of Logical Volume in' ' a RAID group has been reached', '32770': 'Maximum number of Logical Volume in' ' the storage device has been reached', '32771': 'Maximum number of registered Host WWN' ' has been reached', '32772': 'Maximum number of affinity group has been reached', '32773': 'Maximum number of host affinity has been reached', '32785': 'The RAID group is in busy state', '32786': 'The Logical Volume is in busy state', '32787': 'The device is in busy state', '32788': 'Element Name is in use', '32792': 'No Copy License', '32796': 'Quick Format Error', '32801': 'The CA port is in invalid setting', '32802': 'The Logical Volume is Mainframe volume', '32803': 'The RAID group is not operative', '32804': 'The Logical Volume is not operative', '32808': 'No Thin Provisioning License', '32809': 'The Logical Element is ODX volume', '32811': 'This operation cannot be performed' ' to the NAS resources', '32812': 'This operation cannot be performed' ' to the Storage' ' Cluster resources', '32816': 'Fatal error generic', '35302': 'Invalid LogicalElement', '35304': 'LogicalElement state error', '35316': 'Multi-hop error', '35318': 'Maximum number of multi-hop has been reached', '35324': 'RAID is broken', '35331': 'Maximum number of session has been reached' '(per device)', '35333': 'Maximum number of session has been reached' '(per SourceElement)', '35334': 'Maximum number of session has been reached' '(per TargetElement)', '35335': 'Maximum number of Snapshot generation has been' ' reached (per SourceElement)', '35346': 'Copy table size is not setup', '35347': 'Copy table size is not enough' } class FJDXCommon(object): """"""Common code that can be used by ISCSI and FC drivers."""""" stats = {'driver_version': '1.2', 'free_capacity_gb': 0, 'reserved_percentage': 0, 'storage_protocol': None, 'total_capacity_gb': 0, 'vendor_name': 'FUJITSU', 'volume_backend_name': None} def __init__(self, prtcl, configuration=None): self.protocol = prtcl self.configuration = configuration self.configuration.append_config_values(drv_opts) ip, port = self._get_ecom_server() self.user, self.passwd = self._get_ecom_cred() self.url = 'http://' + ip + ':' + port self.conn = self._get_ecom_connection() def create_volume(self, volume): """"""Creates a volume."""""" LOG.debug('Entering create_volume.') volumesize = int(volume['size']) * units.Gi volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Create Volume: %(volume)s Size: %(size)lu') % {'volume': volumename, 'size': volumesize}) self.conn = self._get_ecom_connection() storage_type = self._get_storage_type(volume) LOG.debug('Create Volume: %(volume)s ' 'Storage type: %(storage_type)s' % {'volume': volumename, 'storage_type': storage_type}) pool, storage_system = self._find_pool(storage_type[POOL]) LOG.debug('Create Volume: %(volume)s Pool: %(pool)s ' 'Storage System: %(storage_system)s' % {'volume': volumename, 'pool': pool, 'storage_system': storage_system}) configservice = self._find_storage_configuration_service( storage_system) if configservice is None: exception_message = (_(""Error Create Volume: %(volumename)s. "" ""Storage Configuration Service not found "" ""for pool %(storage_type)s."") % {'volumename': volumename, 'storage_type': storage_type}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) provisioning = self._get_provisioning(storage_type) LOG.debug('Create Volume: %(name)s Method: ' 'CreateOrModifyElementFromStoragePool ConfigServicie: ' '%(service)s ElementName: %(name)s InPool: %(pool)s ' 'ElementType: %(provisioning)s Size: %(size)lu' % {'service': configservice, 'name': volumename, 'pool': pool, 'provisioning': provisioning, 'size': volumesize}) rc, job = self.conn.InvokeMethod( 'CreateOrModifyElementFromStoragePool', configservice, ElementName=volumename, InPool=pool, ElementType=self._getnum(provisioning, '16'), Size=self._getnum(volumesize, '64')) LOG.debug('Create Volume: %(volumename)s Return code: %(rc)lu' % {'volumename': volumename, 'rc': rc}) if rc == 5L: # for DX S2 # retry with 16 digit of volume name volumename = volumename[:16] LOG.debug('Retry with 16 digit of volume name.' 'Create Volume: %(name)s Method: ' 'CreateOrModifyElementFromStoragePool' ' ConfigServicie: %(service)s' ' ElementName: %(name)s InPool: %(pool)s ' 'ElementType: %(provisioning)s Size: %(size)lu' % {'service': configservice, 'name': volumename, 'pool': pool, 'provisioning': provisioning, 'size': volumesize}) rc, job = self.conn.InvokeMethod( 'CreateOrModifyElementFromStoragePool', configservice, ElementName=volumename, InPool=pool, ElementType=self._getnum(provisioning, '16'), Size=self._getnum(volumesize, '64')) LOG.debug('Create Volume: %(volumename)s Return code: %(rc)lu' % {'volumename': volumename, 'rc': rc}) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: LOG.error(_LE('Error Create Volume: %(volumename)s. ' 'Return code: %(rc)lu. Error: %(error)s') % {'volumename': volumename, 'rc': rc, 'error': errordesc}) raise exception.VolumeBackendAPIException(data=errordesc) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TheElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_volume: %(volumename)s ' 'Return code: %(rc)lu ' 'volume instance: %(name)s' % {'volumename': volumename, 'rc': rc, 'name': name}) return name def create_volume_from_snapshot(self, volume, snapshot): """"""Creates a volume from a snapshot."""""" LOG.debug('Entering create_volume_from_snapshot.') snapshotname = snapshot['name'] volumename = self._create_volume_name(volume['id']) vol_instance = None LOG.info(_LI('Create Volume from Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s') % {'volumename': volumename, 'snapshotname': snapshotname}) self.conn = self._get_ecom_connection() snapshot_instance = self._find_lun(snapshot) storage_system = snapshot_instance['SystemName'] LOG.debug('Create Volume from Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Snapshot Instance: ' '%(snapshotinstance)s Storage System: %(storage_system)s.' % {'volumename': volumename, 'snapshotname': snapshotname, 'snapshotinstance': snapshot_instance.path, 'storage_system': storage_system}) repservice = self._find_replication_service(storage_system) if repservice is None: exception_message = (_('Error Create Volume from Snapshot: ' 'Volume: %(volumename)s Snapshot: ' '%(snapshotname)s. Cannot find Replication ' 'Service to create volume from snapshot.') % {'volumename': volumename, 'snapshotname': snapshotname}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug('Create Volume from Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Method: CreateElementReplica ' 'ReplicationService: %(service)s ElementName: ' '%(elementname)s SyncType: 8 SourceElement: ' '%(sourceelement)s' % {'volumename': volumename, 'snapshotname': snapshotname, 'service': repservice, 'elementname': volumename, 'sourceelement': snapshot_instance.path}) # Create a Clone from snapshot name = self.create_volume(volume) instancename = self._getinstancename(name['classname'], name['keybindings']) vol_instance = self.conn.GetInstance(instancename) rc, job = self.conn.InvokeMethod( 'CreateElementReplica', repservice, ElementName=volumename, SyncType=self._getnum(8, '16'), SourceElement=snapshot_instance.path, TargetElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: exception_message = (_('Error Create Volume from Snapshot: ' 'Volume: %(volumename)s Snapshot:' '%(snapshotname)s. ' 'Return code: %(rc)lu.' 'Error: %(error)s') % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) volume['provider_location'] = six.text_type(name) self.delete_volume(volume) raise exception.VolumeBackendAPIException( data=exception_message) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TargetElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_volume_from_snapshot: Volume: ' '%(volumename)s Snapshot: %(snapshotname)s ' 'Return code: %(rc)lu.' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) return name def create_cloned_volume(self, volume, src_vref): """"""Creates a clone of the specified volume."""""" LOG.debug('Entering create_cloned_volume.') srcname = self._create_volume_name(src_vref['id']) volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Create a Clone from Volume: Volume: %(volumename)s ' 'Source Volume: %(srcname)s') % {'volumename': volumename, 'srcname': srcname}) self.conn = self._get_ecom_connection() src_instance = self._find_lun(src_vref) storage_system = src_instance['SystemName'] LOG.debug('Create Cloned Volume: Volume: %(volumename)s ' 'Source Volume: %(srcname)s Source Instance: ' '%(src_instance)s Storage System: %(storage_system)s.' % {'volumename': volumename, 'srcname': srcname, 'src_instance': src_instance.path, 'storage_system': storage_system}) repservice = self._find_replication_service(storage_system) if repservice is None: exception_message = (_('Error Create Cloned Volume: ' 'Volume: %(volumename)s Source Volume: ' '%(srcname)s. Cannot find Replication ' 'Service to create cloned volume.') % {'volumename': volumename, 'srcname': srcname}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug('Create Cloned Volume: Volume: %(volumename)s ' 'Source Volume: %(srcname)s Method: CreateElementReplica ' 'ReplicationService: %(service)s ElementName: ' '%(elementname)s SyncType: 8 SourceElement: ' '%(sourceelement)s' % {'volumename': volumename, 'srcname': srcname, 'service': repservice, 'elementname': volumename, 'sourceelement': src_instance.path}) # Create a Clone from source volume name = self.create_volume(volume) instancename = self._getinstancename(name['classname'], name['keybindings']) vol_instance = self.conn.GetInstance(instancename) rc, job = self.conn.InvokeMethod( 'CreateElementReplica', repservice, ElementName=volumename, SyncType=self._getnum(8, '16'), SourceElement=src_instance.path, TargetElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: exception_message = (_('Error Create Cloned Volume: ' 'Volume: %(volumename)s Source Volume:' '%(srcname)s. Return code: %(rc)lu.' 'Error: %(error)s') % {'volumename': volumename, 'srcname': srcname, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) volume['provider_location'] = six.text_type(name) self.delete_volume(volume) raise exception.VolumeBackendAPIException( data=exception_message) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TargetElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_cloned_volume: Volume: ' '%(volumename)s Source Volume: %(srcname)s ' 'Return code: %(rc)lu.' % {'volumename': volumename, 'srcname': srcname, 'rc': rc}) return name def delete_volume(self, volume): """"""Deletes an volume."""""" LOG.debug('Entering delete_volume.') volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Delete Volume: %(volume)s') % {'volume': volumename}) self.conn = self._get_ecom_connection() cpsession, storage_system = self._find_copysession(volume) if cpsession is not None: LOG.debug('delete_volume,volumename:%(volumename)s,' 'volume is using by copysession[%(cpsession)s].' 'delete copysession.' % {'volumename': volumename, 'cpsession': cpsession}) self._delete_copysession(storage_system, cpsession) vol_instance = self._find_lun(volume) if vol_instance is None: LOG.error(_LE('Volume %(name)s not found on the array. ' 'No volume to delete.') % {'name': volumename}) return configservice =\ self._find_storage_configuration_service(storage_system) if configservice is None: exception_message = (_(""Error Delete Volume: %(volumename)s. "" ""Storage Configuration Service not found."") % {'volumename': volumename}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) device_id = vol_instance['DeviceID'] LOG.debug('Delete Volume: %(name)s DeviceID: %(deviceid)s' % {'name': volumename, 'deviceid': device_id}) LOG.debug('Delete Volume: %(name)s Method: ReturnToStoragePool ' 'ConfigServic: %(service)s TheElement: %(vol_instance)s' % {'service': configservice, 'name': volumename, 'vol_instance': vol_instance.path}) rc, job =\ self.conn.InvokeMethod('ReturnToStoragePool', configservice, TheElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: exception_message = (_('Error Delete Volume: %(volumename)s. ' 'Return code: %(rc)lu. ' 'Error: %(error)s') % {'volumename': volumename, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) LOG.debug('Leaving delete_volume: %(volumename)s Return code: ' '%(rc)lu' % {'volumename': volumename, 'rc': rc}) def create_snapshot(self, snapshot, volume): """"""Creates a snapshot."""""" LOG.debug('Entering create_snapshot.') snapshotname = self._create_volume_name(snapshot['id']) volumename = snapshot['volume_name'] LOG.info(_LI('Create snapshot: %(snapshot)s: volume: %(volume)s') % {'snapshot': snapshotname, 'volume': volumename}) self.conn = self._get_ecom_connection() vol_instance = self._find_lun(volume) device_id = vol_instance['DeviceID'] snappool = self._get_snappool_conffile() pool, storage_system = self._find_pool(snappool) LOG.debug('Device ID: %(deviceid)s: Storage System: ' '%(storagesystem)s' % {'deviceid': device_id, 'storagesystem': storage_system}) repservice = self._find_replication_service(storage_system) if repservice is None: LOG.error(_LE(""Cannot find Replication Service to create snapshot "" ""for volume %s."") % volumename) exception_message = (_(""Cannot find Replication Service to "" ""create snapshot for volume %s."") % volumename) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug(""Create Snapshot: Method: CreateElementReplica: "" ""Target: %(snapshot)s Source: %(volume)s Replication "" ""Service: %(service)s ElementName: %(elementname)s Sync "" ""Type: 7 SourceElement: %(sourceelement)s."" % {'snapshot': snapshotname, 'volume': volumename, 'service': repservice, 'elementname': snapshotname, 'sourceelement': vol_instance.path}) rc, job =\ self.conn.InvokeMethod('CreateElementReplica', repservice, ElementName=snapshotname, SyncType=self._getnum(7, '16'), TargetPool=pool, SourceElement=vol_instance.path) LOG.debug('Create Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Return code: %(rc)lu' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) if rc == 5L: # for DX S2 # retry by CreateReplica snapshotname = snapshotname[:16] LOG.debug('retry Create Snapshot: ' 'snapshotname:%(snapshotname)s,' 'source volume name:%(volumename)s,' 'vol_instance.path:%(vol_instance)s,' 'Invoke CreateReplica' % {'snapshotname': snapshotname, 'volumename': volumename, 'vol_instance': six.text_type(vol_instance.path)}) configservice = self._find_storage_configuration_service( storage_system) if configservice is None: exception_message = (_(""Create Snapshot: %(snapshotname)s. "" ""Storage Configuration Service "" ""not found"") % {'snapshotname': snapshotname}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) # Invoke method for create snapshot rc, job = self.conn.InvokeMethod( 'CreateReplica', configservice, ElementName=snapshotname, TargetPool=pool, CopyType=self._getnum(4, '16'), SourceElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: exception_message = (_('Error Create Snapshot: %(snapshot)s ' 'Volume: %(volume)s ' 'Error: %(errordesc)s') % {'snapshot': snapshotname, 'volume': volumename, 'errordesc': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TargetElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_snapshot: Snapshot: %(snapshot)s ' 'Volume: %(volume)s Return code: %(rc)lu.' % {'snapshot': snapshotname, 'volume': volumename, 'rc': rc}) return name def delete_snapshot(self, snapshot, volume): """"""Deletes a snapshot."""""" LOG.debug('Entering delete_snapshot.') snapshotname = snapshot['name'] volumename = snapshot['volume_name'] LOG.info(_LI('Delete Snapshot: %(snapshot)s: volume: %(volume)s') % {'snapshot': snapshotname, 'volume': volumename}) self.conn = self._get_ecom_connection() LOG.debug('Delete Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Finding StorageSychronization_SV_SV.' % {'snapshot': snapshotname, 'volume': volumename}) sync_name, storage_system =\ self._find_storage_sync_sv_sv(snapshot, volume, False) if sync_name is None: LOG.error(_LE('Snapshot: %(snapshot)s: volume: %(volume)s ' 'not found on the array. No snapshot to delete.') % {'snapshot': snapshotname, 'volume': volumename}) return repservice = self._find_replication_service(storage_system) if repservice is None: exception_message = (_(""Cannot find Replication Service to "" ""create snapshot for volume %s."") % volumename) raise exception.VolumeBackendAPIException(data=exception_message) # Delete snapshot - deletes both the target element # and the snap session LOG.debug(""Delete Snapshot: Target: %(snapshot)s "" ""Source: %(volume)s. Method: "" ""ModifyReplicaSynchronization: "" ""Replication Service: %(service)s Operation: 19 "" ""Synchronization: %(sync_name)s."" % {'snapshot': snapshotname, 'volume': volumename, 'service': repservice, 'sync_name': sync_name}) rc, job =\ self.conn.InvokeMethod('ModifyReplicaSynchronization', repservice, Operation=self._getnum(19, '16'), Synchronization=sync_name) LOG.debug('Delete Snapshot: Volume: %(volumename)s Snapshot: ' '%(snapshotname)s Return code: %(rc)lu' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) if rc != 0L: rc, errordesc = self._wait_for_job_complete(self.conn, job) if rc != 0L: exception_message = (_('Error Delete Snapshot: Volume: ' '%(volumename)s Snapshot: ' '%(snapshotname)s. ' 'Return code: %(rc)lu.' ' Error: %(error)s') % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) # It takes a while for the relationship between the snapshot # and the source volume gets cleaned up. Needs to wait until # it is cleaned up. Otherwise, the source volume can't be # deleted immediately after the snapshot deletion because it # still has snapshot. wait_timeout = int(self._get_timeout()) wait_interval = 10 start = int(time.time()) def _wait_for_job(): try: sync_name, storage_system =\ self._find_storage_sync_sv_sv(snapshot, volume, False) if sync_name is None: LOG.info(_LI('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot is deleted.') % {'snapshot': snapshotname, 'volume': volumename}) raise loopingcall.LoopingCallDone() if int(time.time()) - start >= wait_timeout: LOG.warn(_LW('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot deleted but cleanup timed out.') % {'snapshot': snapshotname, 'volume': volumename}) raise loopingcall.LoopingCallDone() except Exception as ex: if ex.args[0] == 6: # 6 means object not found, so snapshot is deleted cleanly LOG.info(_LI('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot is deleted.') % {'snapshot': snapshotname, 'volume': volumename}) else: LOG.warn(_LW('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot deleted but error during cleanup. ' 'Error: %(error)s') % {'snapshot': snapshotname, 'volume': volumename, 'error': six.text_type(ex.args)}) raise loopingcall.LoopingCallDone() timer = loopingcall.FixedIntervalLoopingCall( _wait_for_job) timer.start(interval=wait_interval) LOG.debug('Leaving delete_snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Return code: %(rc)lu.' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) # Mapping method def _expose_paths(self, configservice, vol_instance, connector): """"""This method maps a volume to a host. It adds a volume and initiator to a Storage Group and therefore maps the volume to the host. """""" results = [] volumename = vol_instance['ElementName'] lun_name = vol_instance['Name'] initiators = self._find_initiator_names(connector) storage_system = vol_instance['SystemName'] lunmask_ctrls = self._find_lunmasking_scsi_protocol_controller( storage_system, connector) targets = self.get_target_portid(connector) if len(lunmask_ctrls) == 0: # create new lunmasking for target in targets: LOG.debug('ExposePaths: %(vol)s ConfigServicie: %(service)s ' 'LUNames: %(lun_name)s ' 'InitiatorPortIDs: %(initiator)s ' 'TargetPortIDs: %(target)s DeviceAccesses: 2' % {'vol': vol_instance.path, 'service': configservice, 'lun_name': lun_name, 'initiator': initiators, 'target': target}) rc, controller =\ self.conn.InvokeMethod('ExposePaths', configservice, LUNames=[lun_name], InitiatorPortIDs=initiators, TargetPortIDs=[target], DeviceAccesses=[self._getnum(2, '16' )]) results.append(rc) if rc != 0L: msg = (_('Error mapping volume %(volumename)s.rc:%(rc)lu') % {'volumename': volumename, 'rc': rc}) LOG.warn(msg) else: # add lun to lunmasking for lunmask_ctrl in lunmask_ctrls: LOG.debug('ExposePaths parameter ' 'LunMaskingSCSIProtocolController: ' '%(lunmasking)s' % {'lunmasking': lunmask_ctrl}) rc, controller =\ self.conn.InvokeMethod('ExposePaths', configservice, LUNames=[lun_name], DeviceAccesses=[ self._getnum(2, '16')], ProtocolControllers=[lunmask_ctrl]) results.append(rc) if rc != 0L: msg = (_('Error mapping volume %(volumename)s.rc:%(rc)lu') % {'volumename': volumename, 'rc': rc}) LOG.warn(msg) if 0L not in results: msg = (_('Error mapping volume %(volumename)s:%(results)s.') % {'volumename': volumename, 'results': results}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('ExposePaths for volume %s completed successfully.' % volumename) # Unmapping method def _hide_paths(self, configservice, vol_instance, connector): """"""This method unmaps a volume from the host. Removes a volume from the Storage Group and therefore unmaps the volume from the host. """""" volumename = vol_instance['ElementName'] lun_name = vol_instance['Name'] lunmask_ctrls =\ self._find_lunmasking_scsi_protocol_controller_for_vol( vol_instance, connector) for lunmask_ctrl in lunmask_ctrls: LOG.debug('HidePaths: %(vol)s ConfigServicie: %(service)s ' 'LUNames: %(lun_name)s' ' LunMaskingSCSIProtocolController: ' '%(lunmasking)s' % {'vol': vol_instance.path, 'service': configservice, 'lun_name': lun_name, 'lunmasking': lunmask_ctrl}) rc, controller = self.conn.InvokeMethod( 'HidePaths', configservice, LUNames=[lun_name], ProtocolControllers=[lunmask_ctrl]) if rc != 0L: msg = (_('Error unmapping volume %(volumename)s.rc:%(rc)lu') % {'volumename': volumename, 'rc': rc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('HidePaths for volume %s completed successfully.' % volumename) def _map_lun(self, volume, connector): """"""Maps a volume to the host."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Map volume: %(volume)s') % {'volume': volumename}) vol_instance = self._find_lun(volume) storage_system = vol_instance['SystemName'] configservice = self._find_controller_configuration_service( storage_system) if configservice is None: exception_message = (_(""Cannot find Controller Configuration "" ""Service for storage system %s"") % storage_system) raise exception.VolumeBackendAPIException(data=exception_message) self._expose_paths(configservice, vol_instance, connector) def _unmap_lun(self, volume, connector): """"""Unmaps a volume from the host."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Unmap volume: %(volume)s') % {'volume': volumename}) device_info = self.find_device_number(volume, connector) device_number = device_info['hostlunid'] if device_number is None: LOG.info(_LI(""Volume %s is not mapped. No volume to unmap."") % (volumename)) return vol_instance = self._find_lun(volume) storage_system = vol_instance['SystemName'] configservice = self._find_controller_configuration_service( storage_system) if configservice is None: exception_message = (_(""Cannot find Controller Configuration "" ""Service for storage system %s"") % storage_system) raise exception.VolumeBackendAPIException(data=exception_message) self._hide_paths(configservice, vol_instance, connector) def initialize_connection(self, volume, connector): """"""Initializes the connection and returns connection info."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Initialize connection: %(volume)s') % {'volume': volumename}) self.conn = self._get_ecom_connection() device_info = self.find_device_number(volume, connector) device_number = device_info['hostlunid'] if device_number is not None: LOG.info(_LI(""Volume %s is already mapped."") % (volumename)) else: self._map_lun(volume, connector) # Find host lun id again after the volume is exported to the host device_info = self.find_device_number(volume, connector) return device_info def terminate_connection(self, volume, connector): """"""Disallow connection from connector."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Terminate connection: %(volume)s') % {'volume': volumename}) self.conn = self._get_ecom_connection() self._unmap_lun(volume, connector) vol_instance = self._find_lun(volume) storage_system = vol_instance['SystemName'] ctrl = self._find_lunmasking_scsi_protocol_controller( storage_system, connector) return ctrl def extend_volume(self, volume, new_size): """"""Extends an existing volume."""""" LOG.debug('Entering extend_volume.') volumesize = int(new_size) * units.Gi volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Extend Volume: %(volume)s New size: %(size)lu') % {'volume': volumename, 'size': volumesize}) self.conn = self._get_ecom_connection() storage_type = self._get_storage_type(volume) vol_instance = self._find_lun(volume) device_id = vol_instance['DeviceID'] storage_system = vol_instance['SystemName'] LOG.debug('Device ID: %(deviceid)s: Storage System: ' '%(storagesystem)s' % {'deviceid': device_id, 'storagesystem': storage_system}) configservice = self._find_storage_configuration_service( storage_system) if configservice is None: exception_message = (_(""Error Extend Volume: %(volumename)s. "" ""Storage Configuration Service not found."") % {'volumename': volumename}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) provisioning = self._get_provisioning(storage_type) LOG.debug('Extend Volume: %(name)s Method: ' 'CreateOrModifyElementFromStoragePool ConfigServicie: ' '%(service)s ElementType: %(provisioning)s Size: %(size)lu' 'Volume path: %(volumepath)s' % {'service': configservice, 'name': volumename, 'provisioning': provisioning, 'size': volumesize, 'volumepath': vol_instance.path}) rc, job = self.conn.InvokeMethod( 'CreateOrModifyElementFromStoragePool', configservice, ElementType=self._getnum(provisioning, '16'), Size=self._getnum(volumesize, '64'), TheElement=vol_instance.path) LOG.debug('Extend Volume: %(volumename)s Return code: %(rc)lu' % {'volumename': volumename, 'rc': rc}) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: exception_message = (_('Error Extend Volume: %(volumename)s. ' 'Return code: %(rc)lu. ' 'Error: %(error)s') % {'volumename': volumename, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) LOG.debug('Leaving extend_volume: %(volumename)s ' 'Return code: %(rc)lu ' % {'volumename': volumename, 'rc': rc}) def update_volume_stats(self): """"""Retrieve stats info."""""" LOG.debug(""Updating volume stats"") self.stats['total_capacity_gb'] = 'unknown' self.stats['free_capacity_gb'] = 'unknown' return self.stats def _get_storage_type(self, volume, filename=None): """"""Get storage type. Look for user input volume type first. If not available, fall back to finding it in conf file. """""" specs = self._get_volumetype_extraspecs(volume) if not specs: specs = self._get_storage_type_conffile() LOG.debug(""Storage Type: %s"" % (specs)) return specs def _get_storage_type_conffile(self, filename=None): """"""Get the storage type from the config file."""""" if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) storageTypes = dom.getElementsByTagName('StorageType') if storageTypes is not None and len(storageTypes) > 0: storageType = storageTypes[0].toxml() storageType = storageType.replace('<StorageType>', '') storageType = storageType.replace('</StorageType>', '') LOG.debug(""Found Storage Type in config file: %s"" % (storageType)) specs = {} specs[POOL] = storageType return specs else: exception_message = (_(""Storage type not found."")) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) def _get_snappool_conffile(self, filename=None): """"""Get the snap pool from the config file."""""" snappool = None if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) snappools = dom.getElementsByTagName('SnapPool') if snappools is not None and len(snappools) > 0: snappool = snappools[0].toxml() snappool = snappool.replace('<SnapPool>', '') snappool = snappool.replace('</SnapPool>', '') LOG.debug(""Found Snap Pool in config file: [%s]"" % (snappool)) return snappool else: exception_message = (_(""Snap pool not found."")) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) def _get_timeout(self, filename=None): if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) timeouts = dom.getElementsByTagName('Timeout') if timeouts is not None and len(timeouts) > 0: timeout = timeouts[0].toxml().replace('<Timeout>', '') timeout = timeout.replace('</Timeout>', '') LOG.debug(""Found Timeout: %s"" % (timeout)) return timeout else: LOG.debug(""Timeout not specified."") return 10 def _get_ecom_cred(self, filename=None): if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) ecomUsers = dom.getElementsByTagName('EcomUserName') if ecomUsers is not None and len(ecomUsers) > 0: ecomUser = ecomUsers[0].toxml().replace('<EcomUserName>', '') ecomUser = ecomUser.replace('</EcomUserName>', '') ecomPasswds = dom.getElementsByTagName('EcomPassword') if ecomPasswds is not None and len(ecomPasswds) > 0: ecomPasswd = ecomPasswds[0].toxml().replace('<EcomPassword>', '') ecomPasswd = ecomPasswd.replace('</EcomPassword>', '') if ecomUser is not None and ecomPasswd is not None: return ecomUser, ecomPasswd else: LOG.debug(""Ecom user not found."") return None def _get_ecom_server(self, filename=None): if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) ecomIps = dom.getElementsByTagName('EcomServerIp') if ecomIps is not None and len(ecomIps) > 0: ecomIp = ecomIps[0].toxml().replace('<EcomServerIp>', '') ecomIp = ecomIp.replace('</EcomServerIp>', '') ecomPorts = dom.getElementsByTagName('EcomServerPort') if ecomPorts is not None and len(ecomPorts) > 0: ecomPort = ecomPorts[0].toxml().replace('<EcomServerPort>', '') ecomPort = ecomPort.replace('</EcomServerPort>', '') if ecomIp is not None and ecomPort is not None: LOG.debug(""Ecom IP: %(ecomIp)s Port: %(ecomPort)s"", {'ecomIp': ecomIp, 'ecomPort': ecomPort}) return ecomIp, ecomPort else: LOG.debug(""Ecom server not found."") return None def _get_ecom_connection(self, filename=None): conn = pywbem.WBEMConnection(self.url, (self.user, self.passwd), default_namespace=SMIS_ROOT) if conn is None: exception_message = (_(""Cannot connect to ECOM server"")) raise exception.VolumeBackendAPIException(data=exception_message) return conn def _find_replication_service(self, storage_system): foundRepService = None repservices = self.conn.EnumerateInstanceNames( REPL_SVC) for repservice in repservices: if storage_system == repservice['SystemName']: foundRepService = repservice LOG.debug(""Found Replication Service: %s"" % (repservice)) break return foundRepService def _find_storage_configuration_service(self, storage_system): foundConfigService = None configservices = self.conn.EnumerateInstanceNames( STOR_CONF_SVC) for configservice in configservices: if storage_system == configservice['SystemName']: foundConfigService = configservice LOG.debug(""Found Storage Configuration Service: %s"" % (configservice)) break return foundConfigService def _find_controller_configuration_service(self, storage_system): foundConfigService = None configservices = self.conn.EnumerateInstanceNames( CTRL_CONF_SVC) for configservice in configservices: if storage_system == configservice['SystemName']: foundConfigService = configservice LOG.debug(""Found Controller Configuration Service: %s"" % (configservice)) break return foundConfigService def _find_storage_hardwareid_service(self, storage_system): foundConfigService = None configservices = self.conn.EnumerateInstanceNames( STOR_HWID_MNG_SVC) for configservice in configservices: if storage_system == configservice['SystemName']: foundConfigService = configservice LOG.debug(""Found Storage Hardware ID Management Service: %s"" % (configservice)) break return foundConfigService # Find pool based on storage_type def _find_pool(self, storage_type, details=False): foundPool = None systemname = None poolinstanceid = None # Only get instance names if details flag is False; # Otherwise get the whole instances systemname, port = self._get_ecom_server() poolinstanceid = self._get_pool_instance_id(storage_type) if details is False: pools = self.conn.EnumerateInstanceNames( 'CIM_StoragePool') else: pools = self.conn.EnumerateInstances( 'CIM_StoragePool') for pool in pools: if six.text_type(pool['InstanceID']) == six.text_type( poolinstanceid): foundPool = pool break if foundPool is None: exception_message = (_(""Pool %(storage_type)s is not found."") % {'storage_type': storage_type}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) if systemname is None: exception_message = (_(""Storage system not found for pool "" ""%(storage_type)s."") % {'storage_type': storage_type}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug(""Pool: %(pool)s SystemName: %(systemname)s."" % {'pool': foundPool, 'systemname': systemname}) return foundPool, systemname def _find_lun(self, volume): foundinstance = None volumename = self._create_volume_name(volume['id']) loc = volume['provider_location'] try: name = eval(loc) instancename = self._getinstancename(name['classname'], name['keybindings']) foundinstance = self.conn.GetInstance(instancename) except Exception: foundinstance = None if foundinstance is None: LOG.debug(""Volume %(volumename)s not found on the array."" ""volume instance is None."" % {'volumename': volumename}) else: LOG.debug(""Volume name: %(volumename)s Volume instance: "" ""%(vol_instance)s."" % {'volumename': volumename, 'vol_instance': foundinstance.path}) return foundinstance def _find_storage_sync_sv_sv(self, snapshot, volume, waitforsync=True): foundsyncname = None storage_system = None snapshotname = self._create_volume_name(snapshot['id']) volumename = self._create_volume_name(volume['id']) LOG.debug(""Source: %(volumename)s Target: %(snapshotname)s."" % {'volumename': volumename, 'snapshotname': snapshotname}) snapshot_instance = self._find_lun(snapshot) volume_instance = self._find_lun(volume) if snapshot_instance is None or volume_instance is None: LOG.info(_LI('Snapshot Volume %(snapshotname)s, ' 'Source Volume %(volumename)s not ' 'found on the array.') % {'snapshotname': snapshotname, 'volumename': volumename}) return None, None storage_system = volume_instance['SystemName'] classname = STOR_SYNC bindings = {'SyncedElement': snapshot_instance.path, 'SystemElement': volume_instance.path} foundsyncname = self._getinstancename(classname, bindings) if foundsyncname is None: LOG.debug(""Source: %(volumename)s Target: %(snapshotname)s. "" ""Storage Synchronized not found. "" % {'volumename': volumename, 'snapshotname': snapshotname}) else: LOG.debug(""Storage system: %(storage_system)s "" ""Storage Synchronized instance: %(sync)s."" % {'storage_system': storage_system, 'sync': foundsyncname}) # Wait for SE_StorageSynchronized_SV_SV to be fully synced if waitforsync: self.wait_for_sync(self.conn, foundsyncname) return foundsyncname, storage_system def _find_initiator_names(self, connector): foundinitiatornames = [] iscsi = 'iscsi' fc = 'fc' name = 'initiator name' if self.protocol.lower() == iscsi and connector['initiator']: foundinitiatornames.append(connector['initiator']) elif self.protocol.lower() == fc and connector['wwpns']: for wwn in connector['wwpns']: foundinitiatornames.append(wwn) name = 'world wide port names' if foundinitiatornames is None or len(foundinitiatornames) == 0: msg = (_('Error finding %s.') % name) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug(""Found %(name)s: %(initiator)s."" % {'name': name, 'initiator': foundinitiatornames}) return foundinitiatornames def _wait_for_job_complete(self, conn, job): """"""Given the job wait for it to complete. :param conn: connection the ecom server :param job: the job dict """""" def _wait_for_job_complete(): """"""Called at an interval until the job is finished"""""" if self._is_job_finished(conn, job): raise loopingcall.LoopingCallDone() if self.retries > JOB_RETRIES: LOG.error(_LE(""_wait_for_job_complete failed after %(retries)d"" "" tries"") % {'retries': self.retries}) raise loopingcall.LoopingCallDone() try: self.retries += 1 if not self.wait_for_job_called: if self._is_job_finished(conn, job): self.wait_for_job_called = True except Exception as e: LOG.error(_LE(""Exception: %s"") % six.text_type(e)) exceptionMessage = (_(""Issue encountered waiting for job."")) LOG.error(exceptionMessage) raise exception.VolumeBackendAPIException(exceptionMessage) self.retries = 0 self.wait_for_job_called = False timer = loopingcall.FixedIntervalLoopingCall(_wait_for_job_complete) timer.start(interval=INTERVAL_10_SEC).wait() jobInstanceName = job['Job'] jobinstance = conn.GetInstance(jobInstanceName, LocalOnly=False) rc = jobinstance['ErrorCode'] errordesc = jobinstance['ErrorDescription'] return rc, errordesc def _is_job_finished(self, conn, job): """"""Check if the job is finished. :param conn: connection the ecom server :param job: the job dict :returns: True if finished; False if not finished; """""" jobInstanceName = job['Job'] jobinstance = conn.GetInstance(jobInstanceName, LocalOnly=False) jobstate = jobinstance['JobState'] # From ValueMap of JobState in CIM_ConcreteJob # 2L=New, 3L=Starting, 4L=Running, 32767L=Queue Pending # ValueMap(""2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13..32767, # 32768..65535""), # Values(""New, Starting, Running, Suspended, Shutting Down, # Completed, Terminated, Killed, Exception, Service, # Query Pending, DMTF Reserved, Vendor Reserved"")] # NOTE(deva): string matching based on # http://ipmitool.cvs.sourceforge.net/ # viewvc/ipmitool/ipmitool/lib/ipmi_chassis.c if jobstate in [2L, 3L, 4L, 32767L]: return False else: return True def wait_for_sync(self, conn, syncName): """"""Given the sync name wait for it to fully synchronize. :param conn: connection the ecom server :param syncName: the syncName """""" def _wait_for_sync(): """"""Called at an interval until the synchronization is finished"""""" if self._is_sync_complete(conn, syncName): raise loopingcall.LoopingCallDone() if self.retries > JOB_RETRIES: LOG.error(_LE(""_wait_for_sync failed after %(retries)d tries"") % {'retries': self.retries}) raise loopingcall.LoopingCallDone() try: self.retries += 1 if not self.wait_for_sync_called: if self._is_sync_complete(conn, syncName): self.wait_for_sync_called = True except Exception as e: LOG.error(_LE(""Exception: %s"") % six.text_type(e)) exceptionMessage = (_(""Issue encountered waiting for "" ""synchronization."")) LOG.error(exceptionMessage) raise exception.VolumeBackendAPIException(exceptionMessage) self.retries = 0 self.wait_for_sync_called = False timer = loopingcall.FixedIntervalLoopingCall(_wait_for_sync) timer.start(interval=INTERVAL_10_SEC).wait() def _is_sync_complete(self, conn, syncName): """"""Check if the job is finished. :param conn: connection the ecom server :param syncName: the sync name :returns: True if fully synchronized; False if not; """""" syncInstance = conn.GetInstance(syncName, LocalOnly=False) percentSynced = syncInstance['PercentSynced'] if percentSynced < 100: return False else: return True # Find LunMaskingSCSIProtocolController for the local host on the # specified storage system def _find_lunmasking_scsi_protocol_controller(self, storage_system, connector): foundCtrls = [] initiators = self._find_initiator_names(connector) controllers = self.conn.EnumerateInstanceNames( SCSI_PROT_CTR) for ctrl in controllers: if storage_system != ctrl['SystemName']: continue associators =\ self.conn.Associators(ctrl, ResultClass=AUTH_PRIV) for assoc in associators: for initiator in initiators: if initiator.lower() not in assoc['InstanceID'].lower(): continue LOG.debug('_find_lunmasking_scsi_protocol_controller,' 'AffinityGroup:%(ag)s' % {'ag': ctrl}) foundCtrls.append(ctrl) break break LOG.debug(""LunMaskingSCSIProtocolController for storage system "" ""%(storage_system)s and initiator %(initiator)s is "" ""%(ctrl)s."" % {'storage_system': storage_system, 'initiator': initiators, 'ctrl': foundCtrls}) return foundCtrls # Find LunMaskingSCSIProtocolController for the local host and the # specified storage volume def _find_lunmasking_scsi_protocol_controller_for_vol(self, vol_instance, connector): foundCtrls = [] initiators = self._find_initiator_names(connector) controllers =\ self.conn.AssociatorNames( vol_instance.path, ResultClass=SCSI_PROT_CTR) LOG.debug('_find_lunmasking_scsi_protocol_controller_for_vol:' 'controllers:%(controllers)s' % {'controllers': controllers}) for ctrl in controllers: associators =\ self.conn.Associators( ctrl, ResultClass=AUTH_PRIV) foundCtrl = None for assoc in associators: for initiator in initiators: if initiator.lower() not in assoc['InstanceID'].lower(): continue LOG.debug('_find_lunmasking_scsi_protocol_controller' '_for_vol,' 'AffinityGroup:%(ag)s' % {'ag': ctrl}) foundCtrl = ctrl foundCtrls.append(foundCtrl) break if foundCtrl is not None: break LOG.debug(""LunMaskingSCSIProtocolController for storage volume "" ""%(vol)s and initiator %(initiator)s is %(ctrl)s."" % {'vol': vol_instance.path, 'initiator': initiators, 'ctrl': foundCtrls}) return foundCtrls # Find out how many volumes are mapped to a host # assoociated to the LunMaskingSCSIProtocolController def get_num_volumes_mapped(self, volume, connector): numVolumesMapped = 0 volumename = volume['name'] vol_instance = self._find_lun(volume) if vol_instance is None: msg = (_('Volume %(name)s not found on the array. ' 'Cannot determine if there are volumes mapped.') % {'name': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) storage_system = vol_instance['SystemName'] ctrl = self._find_lunmasking_scsi_protocol_controller( storage_system, connector) LOG.debug(""LunMaskingSCSIProtocolController for storage system "" ""%(storage)s and %(connector)s is %(ctrl)s."" % {'storage': storage_system, 'connector': connector, 'ctrl': ctrl}) associators = self.conn.Associators( ctrl, resultClass=STOR_VOL) numVolumesMapped = len(associators) LOG.debug(""Found %(numVolumesMapped)d volumes on storage system "" ""%(storage)s mapped to %(connector)s."" % {'numVolumesMapped': numVolumesMapped, 'storage': storage_system, 'connector': connector}) return numVolumesMapped # Find a device number that a host can see for a volume def find_device_number(self, volume, connector): out_num_device_number = None volumename = self._create_volume_name(volume['id']) vol_instance = self._find_lun(volume) storage_system = vol_instance['SystemName'] sp = None ctrls = self._find_lunmasking_scsi_protocol_controller_for_vol( vol_instance, connector) LOG.debug(""LunMaskingSCSIProtocolController for "" ""volume %(vol)s and connector %(connector)s "" ""is %(ctrl)s."" % {'vol': vol_instance.path, 'connector': connector, 'ctrl': ctrls}) if len(ctrls) != 0: unitnames = self.conn.ReferenceNames( vol_instance.path, ResultClass='CIM_ProtocolControllerForUnit') for unitname in unitnames: controller = unitname['Antecedent'] classname = controller['CreationClassName'] index = classname.find(SCSI_PROT_CTR) if index > -1: if ctrls[0]['DeviceID'] != controller['DeviceID']: continue # Get an instance of CIM_ProtocolControllerForUnit unitinstance = self.conn.GetInstance(unitname, LocalOnly=False) numDeviceNumber = int(unitinstance['DeviceNumber'], 16) out_num_device_number = numDeviceNumber break if out_num_device_number is None: LOG.info(_LI(""Device number not found for volume "" ""%(volumename)s %(vol_instance)s."") % {'volumename': volumename, 'vol_instance': vol_instance.path}) else: LOG.debug(""Found device number %(device)d for volume "" ""%(volumename)s %(vol_instance)s."" % {'device': out_num_device_number, 'volumename': volumename, 'vol_instance': vol_instance.path}) data = {'hostlunid': out_num_device_number, 'storagesystem': storage_system, 'owningsp': sp} LOG.debug(""Device info: %(data)s."" % {'data': data}) return data def _getnum(self, num, datatype): try: result = { '8': pywbem.Uint8(num), '16': pywbem.Uint16(num), '32': pywbem.Uint32(num), '64': pywbem.Uint64(num) } result = result.get(datatype, num) except NameError: result = num return result def _getinstancename(self, classname, bindings): instancename = None try: instancename = pywbem.CIMInstanceName( classname, namespace=SMIS_ROOT, keybindings=bindings) except NameError: instancename = None return instancename # Find Storage Hardware IDs def _find_storage_hardwareids(self, connector): foundInstances = [] wwpns = self._find_initiator_names(connector) hardwareids = self.conn.EnumerateInstances( STOR_HWID) for hardwareid in hardwareids: storid = hardwareid['StorageID'] for wwpn in wwpns: if wwpn.lower() == storid.lower(): foundInstances.append(hardwareid.path) LOG.debug(""Storage Hardware IDs for %(wwpns)s is "" ""%(foundInstances)s."" % {'wwpns': wwpns, 'foundInstances': foundInstances}) return foundInstances def _get_volumetype_extraspecs(self, volume): specs = {} type_id = volume['volume_type_id'] if type_id is not None: specs = volume_types.get_volume_type_extra_specs(type_id) # If specs['storagetype:pool'] not defined, # set specs to {} so we can ready from config file later if POOL not in specs: specs = {} return specs def _get_provisioning(self, storage_type): # provisioning is thin (5) by default provisioning = 5 thick_str = 'thick' try: type_prov = storage_type[PROVISIONING] if type_prov.lower() == thick_str.lower(): provisioning = 2 except KeyError: # Default to thin if not defined pass return provisioning def _create_volume_name(self, id_code): """"""create volume_name on ETERNUS from id on OpenStack."""""" LOG.debug('_create_volume_name [%s],Enter method.' % id_code) if id_code is None: msg = (_('_create_volume_name,' 'id_code is None.')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # pylint: disable=E1101 m = hashlib.md5() m.update(id_code) # pylint: disable=E1121 volname = base64.urlsafe_b64encode((m.digest())) ret = VOL_PREFIX + six.text_type(volname) LOG.debug('_create_volume_name: ' ' id:%(id)s' ' volumename:%(ret)s' ' Exit method.' % {'id': id_code, 'ret': ret}) return ret def _get_pool_instance_id(self, poolname): """"""get pool instacne_id from pool name"""""" LOG.debug('_get_pool_instance_id,' 'Enter method,poolname:%s' % (poolname)) poolinstanceid = None pool = None pools = [] msg = None try: pools = self.conn.EnumerateInstances( 'CIM_StoragePool') except Exception: msg = (_('_get_pool_instance_id,' 'poolname:%(poolname)s,' 'EnumerateInstances,' 'cannot connect to ETERNUS.') % {'poolname': poolname}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) for pool in pools: pool_elementname = pool['ElementName'] poolclass = pool.path.classname LOG.debug('poolname from file or VolumeType:%s' ' poolname from smis:%s' ' poolclass from smis:%s' % (poolname, pool_elementname, poolclass)) if six.text_type(poolname) == six.text_type(pool_elementname): if poolclass in STOR_POOLS: poolinstanceid = pool['InstanceID'] break if poolinstanceid is None: msg = (_('_get_pool_instance_id,' 'poolname:%(poolname)s,' 'poolinstanceid is None.') % {'poolname': poolname}) LOG.info(msg) LOG.debug('_get_pool_instance_id,' 'Exit method,poolinstanceid:%s' % (poolinstanceid)) return poolinstanceid def get_target_portid(self, connector): """"""return target_portid"""""" LOG.debug('get_target_portid,Enter method') target_portidlist = [] tgtportlist = [] tgtport = None conn_type = {'fc': 2, 'iscsi': 7} try: tgtportlist = self.conn.EnumerateInstances( 'CIM_SCSIProtocolEndpoint') except Exception: msg = (_('get_target_portid,' 'connector:%(connector)s,' 'EnumerateInstances,' 'cannot connect to ETERNUS.') % {'connector': connector}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) for tgtport in tgtportlist: if tgtport['ConnectionType'] == conn_type[self.protocol.lower()]: target_portidlist.append(tgtport['Name']) LOG.debug('get_target_portid,' 'portid:%(portid)s,' 'connection type:%(cont)s,' % {'portid': tgtport['Name'], 'cont': tgtport['ConnectionType']}) LOG.debug('get_target_portid,' 'target portid: %(target_portid)s ' % {'target_portid': target_portidlist}) if len(target_portidlist) == 0: msg = (_('get_target_portid,' 'protcol:%(protocol)s,' 'connector:%(connector)s,' 'target_portid does not found.') % {'protocol': self.protocol, 'connector': connector}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('get_target_portid,Exit method') return target_portidlist def _find_copysession(self, volume): """"""find copysession from volumename on ETERNUS"""""" LOG.debug('_find_copysession, Enter method') cpsession = None vol_instance = None repservice = None rc = 0 replicarellist = None replicarel = None snapshot_vol_instance = None msg = None errordesc = None vol_instance = self._find_lun(volume) if vol_instance is None: return None, None volumename = vol_instance['ElementName'] storage_system = vol_instance['SystemName'] if vol_instance is not None: # find target_volume # get copysession list repservice = self._find_replication_service(storage_system) if repservice is None: msg = (_('_find_copysession,' 'Cannot find Replication Service to ' 'find copysession')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def _wait_for_job(repservice): cpsession_instance = None LOG.debug('_find_copysession,source_volume' ' while copysession') cpsession = None rc, replicarellist = self.conn.InvokeMethod( 'GetReplicationRelationships', repservice, Type=self._getnum(2, '16'), Mode=self._getnum(2, '16'), Locality=self._getnum(2, '16')) errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: msg = (_('_find_copysession,' 'source_volumename:%(volumename)s,' 'Return code:%(rc)lu,' 'Error:%(errordesc)s') % {'volumename': volumename, 'rc': rc, 'errordesc': errordesc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) for replicarel in replicarellist['Synchronizations']: LOG.debug('_find_copysession,' 'source_volume,' 'replicarel:%(replicarel)s' % {'replicarel': replicarel}) try: snapshot_vol_instance = self.conn.GetInstance( replicarel['SystemElement'], LocalOnly=False) except Exception: msg = (_('_find_copysession,' 'source_volumename:%(volumename)s,' 'GetInstance,' 'cannot connect to ETERNUS.') % {'volumename': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('_find_copysession,' 'snapshot ElementName:%(elementname)s,' 'source_volumename:%(volumename)s' % {'elementname': snapshot_vol_instance['ElementName'], 'volumename': volumename}) if volumename == snapshot_vol_instance['ElementName']: # find copysession cpsession = replicarel LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized instance:%(sync)s' % {'volumename': volumename, 'sync': six.text_type(cpsession)}) msg = (_('_find_copy_session,' 'source_volumename:%(volumename)s,' 'wait for end of copysession') % {'volumename': volumename}) LOG.info(msg) try: cpsession_instance = self.conn.GetInstance( replicarel) except Exception: break LOG.debug('_find_copysession,' 'status:%(status)s' % {'status': cpsession_instance['CopyState']}) if cpsession_instance['CopyState'] == BROKEN: msg = (_('_find_copysession,' 'source_volumename:%(volumename)s,' 'copysession state is BROKEN') % {'volumename': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) break else: LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized not found.' % {'volumename': volumename}) if cpsession is None: raise loopingcall.LoopingCallDone() timer = loopingcall.FixedIntervalLoopingCall( _wait_for_job, repservice) timer.start(interval=10).wait() rc, replicarellist = self.conn.InvokeMethod( 'GetReplicationRelationships', repservice, Type=self._getnum(2, '16'), Mode=self._getnum(2, '16'), Locality=self._getnum(2, '16')) errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: msg = (_('_find_copysession,' 'source_volumename:%(volumename)s,' 'Return code:%(rc)lu,' 'Error:%(errordesc)s') % {'volumename': volumename, 'rc': rc, 'errordesc': errordesc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # find copysession for target_volume for replicarel in replicarellist['Synchronizations']: LOG.debug('_find_copysession,' 'replicarel:%(replicarel)s' % {'replicarel': replicarel}) # target volume try: snapshot_vol_instance = self.conn.GetInstance( replicarel['SyncedElement'], LocalOnly=False) except Exception: msg = (_('_find_copysession,' 'target_volumename:%(volumename)s,' 'GetInstance,' 'cannot connect to ETERNUS.') % {'volumename': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('_find_copysession,' 'snapshot ElementName:%(elementname)s,' 'volumename:%(volumename)s' % {'elementname': snapshot_vol_instance['ElementName'], 'volumename': volumename}) if volumename == snapshot_vol_instance['ElementName']: # find copysession cpsession = replicarel LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized instance:%(sync)s' % {'volumename': volumename, 'sync': six.text_type(cpsession)}) break else: LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized not found.' % {'volumename': volumename}) else: # does not find target_volume of copysession msg = (_('_find_copysession,' 'volumename:%(volumename)s,' 'not found.') % {'volumename': volumename}) LOG.info(msg) LOG.debug('_find_copysession,Exit method') return cpsession, storage_system def _delete_copysession(self, storage_system, cpsession): """"""delete copysession"""""" LOG.debug('_delete_copysession,Entering') LOG.debug('_delete_copysession,[%s]' % cpsession) snapshot_instance = None msg = None errordesc = None try: snapshot_instance = self.conn.GetInstance( cpsession, LocalOnly=False) except Exception: msg = (_('_delete_copysession, ' 'copysession:%(cpsession)s,' 'GetInstance,' 'cannot connect to ETERNUS.') % {'cpsession': cpsession}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) copytype = snapshot_instance['CopyType'] # set oparation code operation = OPERATION_dic[copytype] repservice = self._find_replication_service(storage_system) if repservice is None: msg = (_('_delete_copysession,' 'Cannot find Replication Service to ' 'delete copysession')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # Invoke method for delete copysession rc, job = self.conn.InvokeMethod( 'ModifyReplicaSynchronization', repservice, Operation=self._getnum(operation, '16'), Synchronization=cpsession, Force=True, WaitForCopyState=self._getnum(15, '16')) errordesc = RETCODE_dic[six.text_type(rc)] LOG.debug('_delete_copysession,' 'copysession:%(cpsession)s,' 'operation:%(operation)s,' 'Return code:%(rc)lu,' 'Error:%(errordesc)s,' 'Exit method' % {'cpsession': cpsession, 'operation': operation, 'rc': rc, 'errordesc': errordesc}) if rc != 0L: msg = (_('_delete_copysession,' 'copysession:%(cpsession)s,' 'operation:%(operation)s,' 'Return code:%(rc)lu,' 'Error:%(errordesc)s') % {'cpsession': cpsession, 'operation': operation, 'rc': rc, 'errordesc': errordesc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return ",,2649,0
openstack%2Fcinder~master~I6ad52affcefabf45f46cb4516fde773247f6860f,openstack/cinder,master,I6ad52affcefabf45f46cb4516fde773247f6860f,Move 3 Fujitsu ETERNUS DX related file,ABANDONED,2014-12-19 03:32:25.000000000,2014-12-19 03:36:38.000000000,,[{'_account_id': 10068}],"[{'number': 1, 'created': '2014-12-19 03:32:25.000000000', 'files': ['cinder/volume/drivers/fujitsu_eternus_dx_fc.py', 'cinder/tests/test_fujitsu.py', 'cinder/volume/drivers/fujitsu_eternus_dx_iscsi.py', 'cinder/volume/drivers/fujitsu_eternus_dx_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5929ec8bfc924d41d41aadfa46e8a0b3717e33f5', 'message': ""Move 3 Fujitsu ETERNUS DX related file\n\nSince there are three volume driver files relating to Fujitsu ETERNUS DX in cinder.voluhme.driver,\nI make 'fujitsu' directory at cinder.volume.driver and I move these files to the directory.\n\nCloses-Bug #1402349\nhttps://bugs.launchpad.net/cinder/+bug/1402349\n\nChange-Id: I6ad52affcefabf45f46cb4516fde773247f6860f\n""}]",0,142970,5929ec8bfc924d41d41aadfa46e8a0b3717e33f5,3,1,1,10674,,,0,"Move 3 Fujitsu ETERNUS DX related file

Since there are three volume driver files relating to Fujitsu ETERNUS DX in cinder.voluhme.driver,
I make 'fujitsu' directory at cinder.volume.driver and I move these files to the directory.

Closes-Bug #1402349
https://bugs.launchpad.net/cinder/+bug/1402349

Change-Id: I6ad52affcefabf45f46cb4516fde773247f6860f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/70/142970/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/fujitsu_eternus_dx_fc.py', 'cinder/tests/test_fujitsu.py', 'cinder/volume/drivers/fujitsu_eternus_dx_iscsi.py', 'cinder/volume/drivers/fujitsu_eternus_dx_common.py']",4,5929ec8bfc924d41d41aadfa46e8a0b3717e33f5,bug/1402349,,"# Copyright (c) 2014 FUJITSU LIMITED # Copyright (c) 2012 - 2014 EMC Corporation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Common class for SMI-S based FUJITSU ETERNUS DX volume drivers. This common class is for FUJITSU ETERNUS DX volume drivers based on SMI-S. """""" import base64 import hashlib import time from xml.dom.minidom import parseString from oslo.config import cfg from oslo.utils import units import six from cinder import exception from cinder.i18n import _, _LE, _LI, _LW from cinder.openstack.common import log as logging from cinder.openstack.common import loopingcall from cinder.volume import volume_types LOG = logging.getLogger(__name__) CONF = cfg.CONF try: import pywbem except ImportError: pass CINDER_CONFIG_FILE = '/etc/cinder/cinder_fujitsu_eternus_dx.xml' SMIS_ROOT = 'root/eternus' PROVISIONING = 'storagetype:provisioning' POOL = 'storagetype:pool' STOR_CONF_SVC = 'FUJITSU_StorageConfigurationService' SCSI_PROT_CTR = 'FUJITSU_AffinityGroupController' STOR_HWID = 'FUJITSU_StorageHardwareID' CTRL_CONF_SVC = 'FUJITSU_ControllerConfigurationService' STOR_HWID_MNG_SVC = 'FUJITSU_StorageHardwareIDManagementService' STOR_VOL = 'FUJITSU_StorageVolume' REPL_SVC = 'FUJITSU_ReplicationService' STOR_POOLS = ['FUJITSU_ThinProvisioningPool', 'FUJITSU_RAIDStoragePool'] AUTH_PRIV = 'FUJITSU_AuthorizedPrivilege' STOR_SYNC = 'FUJITSU_StorageSynchronized' VOL_PREFIX = 'FJosv_' drv_opts = [ cfg.StrOpt('cinder_smis_config_file', default=CINDER_CONFIG_FILE, help='The configuration file for the Cinder ' 'SMI-S driver'), ] CONF.register_opts(drv_opts) BROKEN = 5 SNAPOPC = 4 OPC = 5 RETURN_TO_RESOURCEPOOL = 19 DETACH = 8 JOB_RETRIES = 60 INTERVAL_10_SEC = 10 OPERATION_dic = {SNAPOPC: RETURN_TO_RESOURCEPOOL, OPC: DETACH } RETCODE_dic = {'0': 'Success', '1': 'Method Not Supported', '4': 'Failed', '5': 'Invalid Parameter', '4097': 'Size Not Supported', '32769': 'Maximum number of Logical Volume in' ' a RAID group has been reached', '32770': 'Maximum number of Logical Volume in' ' the storage device has been reached', '32771': 'Maximum number of registered Host WWN' ' has been reached', '32772': 'Maximum number of affinity group has been reached', '32773': 'Maximum number of host affinity has been reached', '32785': 'The RAID group is in busy state', '32786': 'The Logical Volume is in busy state', '32787': 'The device is in busy state', '32788': 'Element Name is in use', '32792': 'No Copy License', '32796': 'Quick Format Error', '32801': 'The CA port is in invalid setting', '32802': 'The Logical Volume is Mainframe volume', '32803': 'The RAID group is not operative', '32804': 'The Logical Volume is not operative', '32808': 'No Thin Provisioning License', '32809': 'The Logical Element is ODX volume', '32811': 'This operation cannot be performed' ' to the NAS resources', '32812': 'This operation cannot be performed' ' to the Storage' ' Cluster resources', '32816': 'Fatal error generic', '35302': 'Invalid LogicalElement', '35304': 'LogicalElement state error', '35316': 'Multi-hop error', '35318': 'Maximum number of multi-hop has been reached', '35324': 'RAID is broken', '35331': 'Maximum number of session has been reached' '(per device)', '35333': 'Maximum number of session has been reached' '(per SourceElement)', '35334': 'Maximum number of session has been reached' '(per TargetElement)', '35335': 'Maximum number of Snapshot generation has been' ' reached (per SourceElement)', '35346': 'Copy table size is not setup', '35347': 'Copy table size is not enough' } class FJDXCommon(object): """"""Common code that can be used by ISCSI and FC drivers."""""" stats = {'driver_version': '1.2', 'free_capacity_gb': 0, 'reserved_percentage': 0, 'storage_protocol': None, 'total_capacity_gb': 0, 'vendor_name': 'FUJITSU', 'volume_backend_name': None} def __init__(self, prtcl, configuration=None): self.protocol = prtcl self.configuration = configuration self.configuration.append_config_values(drv_opts) ip, port = self._get_ecom_server() self.user, self.passwd = self._get_ecom_cred() self.url = 'http://' + ip + ':' + port self.conn = self._get_ecom_connection() def create_volume(self, volume): """"""Creates a volume."""""" LOG.debug('Entering create_volume.') volumesize = int(volume['size']) * units.Gi volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Create Volume: %(volume)s Size: %(size)lu') % {'volume': volumename, 'size': volumesize}) self.conn = self._get_ecom_connection() storage_type = self._get_storage_type(volume) LOG.debug('Create Volume: %(volume)s ' 'Storage type: %(storage_type)s' % {'volume': volumename, 'storage_type': storage_type}) pool, storage_system = self._find_pool(storage_type[POOL]) LOG.debug('Create Volume: %(volume)s Pool: %(pool)s ' 'Storage System: %(storage_system)s' % {'volume': volumename, 'pool': pool, 'storage_system': storage_system}) configservice = self._find_storage_configuration_service( storage_system) if configservice is None: exception_message = (_(""Error Create Volume: %(volumename)s. "" ""Storage Configuration Service not found "" ""for pool %(storage_type)s."") % {'volumename': volumename, 'storage_type': storage_type}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) provisioning = self._get_provisioning(storage_type) LOG.debug('Create Volume: %(name)s Method: ' 'CreateOrModifyElementFromStoragePool ConfigServicie: ' '%(service)s ElementName: %(name)s InPool: %(pool)s ' 'ElementType: %(provisioning)s Size: %(size)lu' % {'service': configservice, 'name': volumename, 'pool': pool, 'provisioning': provisioning, 'size': volumesize}) rc, job = self.conn.InvokeMethod( 'CreateOrModifyElementFromStoragePool', configservice, ElementName=volumename, InPool=pool, ElementType=self._getnum(provisioning, '16'), Size=self._getnum(volumesize, '64')) LOG.debug('Create Volume: %(volumename)s Return code: %(rc)lu' % {'volumename': volumename, 'rc': rc}) if rc == 5L: # for DX S2 # retry with 16 digit of volume name volumename = volumename[:16] LOG.debug('Retry with 16 digit of volume name.' 'Create Volume: %(name)s Method: ' 'CreateOrModifyElementFromStoragePool' ' ConfigServicie: %(service)s' ' ElementName: %(name)s InPool: %(pool)s ' 'ElementType: %(provisioning)s Size: %(size)lu' % {'service': configservice, 'name': volumename, 'pool': pool, 'provisioning': provisioning, 'size': volumesize}) rc, job = self.conn.InvokeMethod( 'CreateOrModifyElementFromStoragePool', configservice, ElementName=volumename, InPool=pool, ElementType=self._getnum(provisioning, '16'), Size=self._getnum(volumesize, '64')) LOG.debug('Create Volume: %(volumename)s Return code: %(rc)lu' % {'volumename': volumename, 'rc': rc}) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: LOG.error(_LE('Error Create Volume: %(volumename)s. ' 'Return code: %(rc)lu. Error: %(error)s') % {'volumename': volumename, 'rc': rc, 'error': errordesc}) raise exception.VolumeBackendAPIException(data=errordesc) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TheElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_volume: %(volumename)s ' 'Return code: %(rc)lu ' 'volume instance: %(name)s' % {'volumename': volumename, 'rc': rc, 'name': name}) return name def create_volume_from_snapshot(self, volume, snapshot): """"""Creates a volume from a snapshot."""""" LOG.debug('Entering create_volume_from_snapshot.') snapshotname = snapshot['name'] volumename = self._create_volume_name(volume['id']) vol_instance = None LOG.info(_LI('Create Volume from Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s') % {'volumename': volumename, 'snapshotname': snapshotname}) self.conn = self._get_ecom_connection() snapshot_instance = self._find_lun(snapshot) storage_system = snapshot_instance['SystemName'] LOG.debug('Create Volume from Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Snapshot Instance: ' '%(snapshotinstance)s Storage System: %(storage_system)s.' % {'volumename': volumename, 'snapshotname': snapshotname, 'snapshotinstance': snapshot_instance.path, 'storage_system': storage_system}) repservice = self._find_replication_service(storage_system) if repservice is None: exception_message = (_('Error Create Volume from Snapshot: ' 'Volume: %(volumename)s Snapshot: ' '%(snapshotname)s. Cannot find Replication ' 'Service to create volume from snapshot.') % {'volumename': volumename, 'snapshotname': snapshotname}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug('Create Volume from Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Method: CreateElementReplica ' 'ReplicationService: %(service)s ElementName: ' '%(elementname)s SyncType: 8 SourceElement: ' '%(sourceelement)s' % {'volumename': volumename, 'snapshotname': snapshotname, 'service': repservice, 'elementname': volumename, 'sourceelement': snapshot_instance.path}) # Create a Clone from snapshot name = self.create_volume(volume) instancename = self._getinstancename(name['classname'], name['keybindings']) vol_instance = self.conn.GetInstance(instancename) rc, job = self.conn.InvokeMethod( 'CreateElementReplica', repservice, ElementName=volumename, SyncType=self._getnum(8, '16'), SourceElement=snapshot_instance.path, TargetElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: exception_message = (_('Error Create Volume from Snapshot: ' 'Volume: %(volumename)s Snapshot:' '%(snapshotname)s. ' 'Return code: %(rc)lu.' 'Error: %(error)s') % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) volume['provider_location'] = six.text_type(name) self.delete_volume(volume) raise exception.VolumeBackendAPIException( data=exception_message) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TargetElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_volume_from_snapshot: Volume: ' '%(volumename)s Snapshot: %(snapshotname)s ' 'Return code: %(rc)lu.' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) return name def create_cloned_volume(self, volume, src_vref): """"""Creates a clone of the specified volume."""""" LOG.debug('Entering create_cloned_volume.') srcname = self._create_volume_name(src_vref['id']) volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Create a Clone from Volume: Volume: %(volumename)s ' 'Source Volume: %(srcname)s') % {'volumename': volumename, 'srcname': srcname}) self.conn = self._get_ecom_connection() src_instance = self._find_lun(src_vref) storage_system = src_instance['SystemName'] LOG.debug('Create Cloned Volume: Volume: %(volumename)s ' 'Source Volume: %(srcname)s Source Instance: ' '%(src_instance)s Storage System: %(storage_system)s.' % {'volumename': volumename, 'srcname': srcname, 'src_instance': src_instance.path, 'storage_system': storage_system}) repservice = self._find_replication_service(storage_system) if repservice is None: exception_message = (_('Error Create Cloned Volume: ' 'Volume: %(volumename)s Source Volume: ' '%(srcname)s. Cannot find Replication ' 'Service to create cloned volume.') % {'volumename': volumename, 'srcname': srcname}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug('Create Cloned Volume: Volume: %(volumename)s ' 'Source Volume: %(srcname)s Method: CreateElementReplica ' 'ReplicationService: %(service)s ElementName: ' '%(elementname)s SyncType: 8 SourceElement: ' '%(sourceelement)s' % {'volumename': volumename, 'srcname': srcname, 'service': repservice, 'elementname': volumename, 'sourceelement': src_instance.path}) # Create a Clone from source volume name = self.create_volume(volume) instancename = self._getinstancename(name['classname'], name['keybindings']) vol_instance = self.conn.GetInstance(instancename) rc, job = self.conn.InvokeMethod( 'CreateElementReplica', repservice, ElementName=volumename, SyncType=self._getnum(8, '16'), SourceElement=src_instance.path, TargetElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: exception_message = (_('Error Create Cloned Volume: ' 'Volume: %(volumename)s Source Volume:' '%(srcname)s. Return code: %(rc)lu.' 'Error: %(error)s') % {'volumename': volumename, 'srcname': srcname, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) volume['provider_location'] = six.text_type(name) self.delete_volume(volume) raise exception.VolumeBackendAPIException( data=exception_message) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TargetElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_cloned_volume: Volume: ' '%(volumename)s Source Volume: %(srcname)s ' 'Return code: %(rc)lu.' % {'volumename': volumename, 'srcname': srcname, 'rc': rc}) return name def delete_volume(self, volume): """"""Deletes an volume."""""" LOG.debug('Entering delete_volume.') volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Delete Volume: %(volume)s') % {'volume': volumename}) self.conn = self._get_ecom_connection() cpsession, storage_system = self._find_copysession(volume) if cpsession is not None: LOG.debug('delete_volume,volumename:%(volumename)s,' 'volume is using by copysession[%(cpsession)s].' 'delete copysession.' % {'volumename': volumename, 'cpsession': cpsession}) self._delete_copysession(storage_system, cpsession) vol_instance = self._find_lun(volume) if vol_instance is None: LOG.error(_LE('Volume %(name)s not found on the array. ' 'No volume to delete.') % {'name': volumename}) return configservice =\ self._find_storage_configuration_service(storage_system) if configservice is None: exception_message = (_(""Error Delete Volume: %(volumename)s. "" ""Storage Configuration Service not found."") % {'volumename': volumename}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) device_id = vol_instance['DeviceID'] LOG.debug('Delete Volume: %(name)s DeviceID: %(deviceid)s' % {'name': volumename, 'deviceid': device_id}) LOG.debug('Delete Volume: %(name)s Method: ReturnToStoragePool ' 'ConfigServic: %(service)s TheElement: %(vol_instance)s' % {'service': configservice, 'name': volumename, 'vol_instance': vol_instance.path}) rc, job =\ self.conn.InvokeMethod('ReturnToStoragePool', configservice, TheElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: exception_message = (_('Error Delete Volume: %(volumename)s. ' 'Return code: %(rc)lu. ' 'Error: %(error)s') % {'volumename': volumename, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) LOG.debug('Leaving delete_volume: %(volumename)s Return code: ' '%(rc)lu' % {'volumename': volumename, 'rc': rc}) def create_snapshot(self, snapshot, volume): """"""Creates a snapshot."""""" LOG.debug('Entering create_snapshot.') snapshotname = self._create_volume_name(snapshot['id']) volumename = snapshot['volume_name'] LOG.info(_LI('Create snapshot: %(snapshot)s: volume: %(volume)s') % {'snapshot': snapshotname, 'volume': volumename}) self.conn = self._get_ecom_connection() vol_instance = self._find_lun(volume) device_id = vol_instance['DeviceID'] snappool = self._get_snappool_conffile() pool, storage_system = self._find_pool(snappool) LOG.debug('Device ID: %(deviceid)s: Storage System: ' '%(storagesystem)s' % {'deviceid': device_id, 'storagesystem': storage_system}) repservice = self._find_replication_service(storage_system) if repservice is None: LOG.error(_LE(""Cannot find Replication Service to create snapshot "" ""for volume %s."") % volumename) exception_message = (_(""Cannot find Replication Service to "" ""create snapshot for volume %s."") % volumename) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug(""Create Snapshot: Method: CreateElementReplica: "" ""Target: %(snapshot)s Source: %(volume)s Replication "" ""Service: %(service)s ElementName: %(elementname)s Sync "" ""Type: 7 SourceElement: %(sourceelement)s."" % {'snapshot': snapshotname, 'volume': volumename, 'service': repservice, 'elementname': snapshotname, 'sourceelement': vol_instance.path}) rc, job =\ self.conn.InvokeMethod('CreateElementReplica', repservice, ElementName=snapshotname, SyncType=self._getnum(7, '16'), TargetPool=pool, SourceElement=vol_instance.path) LOG.debug('Create Snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Return code: %(rc)lu' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) if rc == 5L: # for DX S2 # retry by CreateReplica snapshotname = snapshotname[:16] LOG.debug('retry Create Snapshot: ' 'snapshotname:%(snapshotname)s,' 'source volume name:%(volumename)s,' 'vol_instance.path:%(vol_instance)s,' 'Invoke CreateReplica' % {'snapshotname': snapshotname, 'volumename': volumename, 'vol_instance': six.text_type(vol_instance.path)}) configservice = self._find_storage_configuration_service( storage_system) if configservice is None: exception_message = (_(""Create Snapshot: %(snapshotname)s. "" ""Storage Configuration Service "" ""not found"") % {'snapshotname': snapshotname}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) # Invoke method for create snapshot rc, job = self.conn.InvokeMethod( 'CreateReplica', configservice, ElementName=snapshotname, TargetPool=pool, CopyType=self._getnum(4, '16'), SourceElement=vol_instance.path) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: exception_message = (_('Error Create Snapshot: %(snapshot)s ' 'Volume: %(volume)s ' 'Error: %(errordesc)s') % {'snapshot': snapshotname, 'volume': volumename, 'errordesc': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) # Find the newly created volume if ""job"" in job: associators = self.conn.Associators( job['Job'], resultClass=STOR_VOL) volpath = associators[0].path else: # for ETERNUS DX volpath = job['TargetElement'] name = {} name['classname'] = volpath.classname keys = {} keys['CreationClassName'] = volpath['CreationClassName'] keys['SystemName'] = volpath['SystemName'] keys['DeviceID'] = volpath['DeviceID'] keys['SystemCreationClassName'] = volpath['SystemCreationClassName'] name['keybindings'] = keys LOG.debug('Leaving create_snapshot: Snapshot: %(snapshot)s ' 'Volume: %(volume)s Return code: %(rc)lu.' % {'snapshot': snapshotname, 'volume': volumename, 'rc': rc}) return name def delete_snapshot(self, snapshot, volume): """"""Deletes a snapshot."""""" LOG.debug('Entering delete_snapshot.') snapshotname = snapshot['name'] volumename = snapshot['volume_name'] LOG.info(_LI('Delete Snapshot: %(snapshot)s: volume: %(volume)s') % {'snapshot': snapshotname, 'volume': volumename}) self.conn = self._get_ecom_connection() LOG.debug('Delete Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Finding StorageSychronization_SV_SV.' % {'snapshot': snapshotname, 'volume': volumename}) sync_name, storage_system =\ self._find_storage_sync_sv_sv(snapshot, volume, False) if sync_name is None: LOG.error(_LE('Snapshot: %(snapshot)s: volume: %(volume)s ' 'not found on the array. No snapshot to delete.') % {'snapshot': snapshotname, 'volume': volumename}) return repservice = self._find_replication_service(storage_system) if repservice is None: exception_message = (_(""Cannot find Replication Service to "" ""create snapshot for volume %s."") % volumename) raise exception.VolumeBackendAPIException(data=exception_message) # Delete snapshot - deletes both the target element # and the snap session LOG.debug(""Delete Snapshot: Target: %(snapshot)s "" ""Source: %(volume)s. Method: "" ""ModifyReplicaSynchronization: "" ""Replication Service: %(service)s Operation: 19 "" ""Synchronization: %(sync_name)s."" % {'snapshot': snapshotname, 'volume': volumename, 'service': repservice, 'sync_name': sync_name}) rc, job =\ self.conn.InvokeMethod('ModifyReplicaSynchronization', repservice, Operation=self._getnum(19, '16'), Synchronization=sync_name) LOG.debug('Delete Snapshot: Volume: %(volumename)s Snapshot: ' '%(snapshotname)s Return code: %(rc)lu' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) if rc != 0L: rc, errordesc = self._wait_for_job_complete(self.conn, job) if rc != 0L: exception_message = (_('Error Delete Snapshot: Volume: ' '%(volumename)s Snapshot: ' '%(snapshotname)s. ' 'Return code: %(rc)lu.' ' Error: %(error)s') % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) # It takes a while for the relationship between the snapshot # and the source volume gets cleaned up. Needs to wait until # it is cleaned up. Otherwise, the source volume can't be # deleted immediately after the snapshot deletion because it # still has snapshot. wait_timeout = int(self._get_timeout()) wait_interval = 10 start = int(time.time()) def _wait_for_job(): try: sync_name, storage_system =\ self._find_storage_sync_sv_sv(snapshot, volume, False) if sync_name is None: LOG.info(_LI('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot is deleted.') % {'snapshot': snapshotname, 'volume': volumename}) raise loopingcall.LoopingCallDone() if int(time.time()) - start >= wait_timeout: LOG.warn(_LW('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot deleted but cleanup timed out.') % {'snapshot': snapshotname, 'volume': volumename}) raise loopingcall.LoopingCallDone() except Exception as ex: if ex.args[0] == 6: # 6 means object not found, so snapshot is deleted cleanly LOG.info(_LI('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot is deleted.') % {'snapshot': snapshotname, 'volume': volumename}) else: LOG.warn(_LW('Snapshot: %(snapshot)s: volume: %(volume)s. ' 'Snapshot deleted but error during cleanup. ' 'Error: %(error)s') % {'snapshot': snapshotname, 'volume': volumename, 'error': six.text_type(ex.args)}) raise loopingcall.LoopingCallDone() timer = loopingcall.FixedIntervalLoopingCall( _wait_for_job) timer.start(interval=wait_interval) LOG.debug('Leaving delete_snapshot: Volume: %(volumename)s ' 'Snapshot: %(snapshotname)s Return code: %(rc)lu.' % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': rc}) # Mapping method def _expose_paths(self, configservice, vol_instance, connector): """"""This method maps a volume to a host. It adds a volume and initiator to a Storage Group and therefore maps the volume to the host. """""" results = [] volumename = vol_instance['ElementName'] lun_name = vol_instance['Name'] initiators = self._find_initiator_names(connector) storage_system = vol_instance['SystemName'] lunmask_ctrls = self._find_lunmasking_scsi_protocol_controller( storage_system, connector) targets = self.get_target_portid(connector) if len(lunmask_ctrls) == 0: # create new lunmasking for target in targets: LOG.debug('ExposePaths: %(vol)s ConfigServicie: %(service)s ' 'LUNames: %(lun_name)s ' 'InitiatorPortIDs: %(initiator)s ' 'TargetPortIDs: %(target)s DeviceAccesses: 2' % {'vol': vol_instance.path, 'service': configservice, 'lun_name': lun_name, 'initiator': initiators, 'target': target}) rc, controller =\ self.conn.InvokeMethod('ExposePaths', configservice, LUNames=[lun_name], InitiatorPortIDs=initiators, TargetPortIDs=[target], DeviceAccesses=[self._getnum(2, '16' )]) results.append(rc) if rc != 0L: msg = (_('Error mapping volume %(volumename)s.rc:%(rc)lu') % {'volumename': volumename, 'rc': rc}) LOG.warn(msg) else: # add lun to lunmasking for lunmask_ctrl in lunmask_ctrls: LOG.debug('ExposePaths parameter ' 'LunMaskingSCSIProtocolController: ' '%(lunmasking)s' % {'lunmasking': lunmask_ctrl}) rc, controller =\ self.conn.InvokeMethod('ExposePaths', configservice, LUNames=[lun_name], DeviceAccesses=[ self._getnum(2, '16')], ProtocolControllers=[lunmask_ctrl]) results.append(rc) if rc != 0L: msg = (_('Error mapping volume %(volumename)s.rc:%(rc)lu') % {'volumename': volumename, 'rc': rc}) LOG.warn(msg) if 0L not in results: msg = (_('Error mapping volume %(volumename)s:%(results)s.') % {'volumename': volumename, 'results': results}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('ExposePaths for volume %s completed successfully.' % volumename) # Unmapping method def _hide_paths(self, configservice, vol_instance, connector): """"""This method unmaps a volume from the host. Removes a volume from the Storage Group and therefore unmaps the volume from the host. """""" volumename = vol_instance['ElementName'] lun_name = vol_instance['Name'] lunmask_ctrls =\ self._find_lunmasking_scsi_protocol_controller_for_vol( vol_instance, connector) for lunmask_ctrl in lunmask_ctrls: LOG.debug('HidePaths: %(vol)s ConfigServicie: %(service)s ' 'LUNames: %(lun_name)s' ' LunMaskingSCSIProtocolController: ' '%(lunmasking)s' % {'vol': vol_instance.path, 'service': configservice, 'lun_name': lun_name, 'lunmasking': lunmask_ctrl}) rc, controller = self.conn.InvokeMethod( 'HidePaths', configservice, LUNames=[lun_name], ProtocolControllers=[lunmask_ctrl]) if rc != 0L: msg = (_('Error unmapping volume %(volumename)s.rc:%(rc)lu') % {'volumename': volumename, 'rc': rc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('HidePaths for volume %s completed successfully.' % volumename) def _map_lun(self, volume, connector): """"""Maps a volume to the host."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Map volume: %(volume)s') % {'volume': volumename}) vol_instance = self._find_lun(volume) storage_system = vol_instance['SystemName'] configservice = self._find_controller_configuration_service( storage_system) if configservice is None: exception_message = (_(""Cannot find Controller Configuration "" ""Service for storage system %s"") % storage_system) raise exception.VolumeBackendAPIException(data=exception_message) self._expose_paths(configservice, vol_instance, connector) def _unmap_lun(self, volume, connector): """"""Unmaps a volume from the host."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Unmap volume: %(volume)s') % {'volume': volumename}) device_info = self.find_device_number(volume, connector) device_number = device_info['hostlunid'] if device_number is None: LOG.info(_LI(""Volume %s is not mapped. No volume to unmap."") % (volumename)) return vol_instance = self._find_lun(volume) storage_system = vol_instance['SystemName'] configservice = self._find_controller_configuration_service( storage_system) if configservice is None: exception_message = (_(""Cannot find Controller Configuration "" ""Service for storage system %s"") % storage_system) raise exception.VolumeBackendAPIException(data=exception_message) self._hide_paths(configservice, vol_instance, connector) def initialize_connection(self, volume, connector): """"""Initializes the connection and returns connection info."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Initialize connection: %(volume)s') % {'volume': volumename}) self.conn = self._get_ecom_connection() device_info = self.find_device_number(volume, connector) device_number = device_info['hostlunid'] if device_number is not None: LOG.info(_LI(""Volume %s is already mapped."") % (volumename)) else: self._map_lun(volume, connector) # Find host lun id again after the volume is exported to the host device_info = self.find_device_number(volume, connector) return device_info def terminate_connection(self, volume, connector): """"""Disallow connection from connector."""""" volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Terminate connection: %(volume)s') % {'volume': volumename}) self.conn = self._get_ecom_connection() self._unmap_lun(volume, connector) vol_instance = self._find_lun(volume) storage_system = vol_instance['SystemName'] ctrl = self._find_lunmasking_scsi_protocol_controller( storage_system, connector) return ctrl def extend_volume(self, volume, new_size): """"""Extends an existing volume."""""" LOG.debug('Entering extend_volume.') volumesize = int(new_size) * units.Gi volumename = self._create_volume_name(volume['id']) LOG.info(_LI('Extend Volume: %(volume)s New size: %(size)lu') % {'volume': volumename, 'size': volumesize}) self.conn = self._get_ecom_connection() storage_type = self._get_storage_type(volume) vol_instance = self._find_lun(volume) device_id = vol_instance['DeviceID'] storage_system = vol_instance['SystemName'] LOG.debug('Device ID: %(deviceid)s: Storage System: ' '%(storagesystem)s' % {'deviceid': device_id, 'storagesystem': storage_system}) configservice = self._find_storage_configuration_service( storage_system) if configservice is None: exception_message = (_(""Error Extend Volume: %(volumename)s. "" ""Storage Configuration Service not found."") % {'volumename': volumename}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) provisioning = self._get_provisioning(storage_type) LOG.debug('Extend Volume: %(name)s Method: ' 'CreateOrModifyElementFromStoragePool ConfigServicie: ' '%(service)s ElementType: %(provisioning)s Size: %(size)lu' 'Volume path: %(volumepath)s' % {'service': configservice, 'name': volumename, 'provisioning': provisioning, 'size': volumesize, 'volumepath': vol_instance.path}) rc, job = self.conn.InvokeMethod( 'CreateOrModifyElementFromStoragePool', configservice, ElementType=self._getnum(provisioning, '16'), Size=self._getnum(volumesize, '64'), TheElement=vol_instance.path) LOG.debug('Extend Volume: %(volumename)s Return code: %(rc)lu' % {'volumename': volumename, 'rc': rc}) if rc != 0L: if ""job"" in job: rc, errordesc = self._wait_for_job_complete(self.conn, job) else: errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: exception_message = (_('Error Extend Volume: %(volumename)s. ' 'Return code: %(rc)lu. ' 'Error: %(error)s') % {'volumename': volumename, 'rc': rc, 'error': errordesc}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( data=exception_message) LOG.debug('Leaving extend_volume: %(volumename)s ' 'Return code: %(rc)lu ' % {'volumename': volumename, 'rc': rc}) def update_volume_stats(self): """"""Retrieve stats info."""""" LOG.debug(""Updating volume stats"") self.stats['total_capacity_gb'] = 'unknown' self.stats['free_capacity_gb'] = 'unknown' return self.stats def _get_storage_type(self, volume, filename=None): """"""Get storage type. Look for user input volume type first. If not available, fall back to finding it in conf file. """""" specs = self._get_volumetype_extraspecs(volume) if not specs: specs = self._get_storage_type_conffile() LOG.debug(""Storage Type: %s"" % (specs)) return specs def _get_storage_type_conffile(self, filename=None): """"""Get the storage type from the config file."""""" if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) storageTypes = dom.getElementsByTagName('StorageType') if storageTypes is not None and len(storageTypes) > 0: storageType = storageTypes[0].toxml() storageType = storageType.replace('<StorageType>', '') storageType = storageType.replace('</StorageType>', '') LOG.debug(""Found Storage Type in config file: %s"" % (storageType)) specs = {} specs[POOL] = storageType return specs else: exception_message = (_(""Storage type not found."")) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) def _get_snappool_conffile(self, filename=None): """"""Get the snap pool from the config file."""""" snappool = None if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) snappools = dom.getElementsByTagName('SnapPool') if snappools is not None and len(snappools) > 0: snappool = snappools[0].toxml() snappool = snappool.replace('<SnapPool>', '') snappool = snappool.replace('</SnapPool>', '') LOG.debug(""Found Snap Pool in config file: [%s]"" % (snappool)) return snappool else: exception_message = (_(""Snap pool not found."")) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) def _get_timeout(self, filename=None): if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) timeouts = dom.getElementsByTagName('Timeout') if timeouts is not None and len(timeouts) > 0: timeout = timeouts[0].toxml().replace('<Timeout>', '') timeout = timeout.replace('</Timeout>', '') LOG.debug(""Found Timeout: %s"" % (timeout)) return timeout else: LOG.debug(""Timeout not specified."") return 10 def _get_ecom_cred(self, filename=None): if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) ecomUsers = dom.getElementsByTagName('EcomUserName') if ecomUsers is not None and len(ecomUsers) > 0: ecomUser = ecomUsers[0].toxml().replace('<EcomUserName>', '') ecomUser = ecomUser.replace('</EcomUserName>', '') ecomPasswds = dom.getElementsByTagName('EcomPassword') if ecomPasswds is not None and len(ecomPasswds) > 0: ecomPasswd = ecomPasswds[0].toxml().replace('<EcomPassword>', '') ecomPasswd = ecomPasswd.replace('</EcomPassword>', '') if ecomUser is not None and ecomPasswd is not None: return ecomUser, ecomPasswd else: LOG.debug(""Ecom user not found."") return None def _get_ecom_server(self, filename=None): if filename is None: filename = self.configuration.cinder_smis_config_file file = open(filename, 'r') data = file.read() file.close() dom = parseString(data) ecomIps = dom.getElementsByTagName('EcomServerIp') if ecomIps is not None and len(ecomIps) > 0: ecomIp = ecomIps[0].toxml().replace('<EcomServerIp>', '') ecomIp = ecomIp.replace('</EcomServerIp>', '') ecomPorts = dom.getElementsByTagName('EcomServerPort') if ecomPorts is not None and len(ecomPorts) > 0: ecomPort = ecomPorts[0].toxml().replace('<EcomServerPort>', '') ecomPort = ecomPort.replace('</EcomServerPort>', '') if ecomIp is not None and ecomPort is not None: LOG.debug(""Ecom IP: %(ecomIp)s Port: %(ecomPort)s"", {'ecomIp': ecomIp, 'ecomPort': ecomPort}) return ecomIp, ecomPort else: LOG.debug(""Ecom server not found."") return None def _get_ecom_connection(self, filename=None): conn = pywbem.WBEMConnection(self.url, (self.user, self.passwd), default_namespace=SMIS_ROOT) if conn is None: exception_message = (_(""Cannot connect to ECOM server"")) raise exception.VolumeBackendAPIException(data=exception_message) return conn def _find_replication_service(self, storage_system): foundRepService = None repservices = self.conn.EnumerateInstanceNames( REPL_SVC) for repservice in repservices: if storage_system == repservice['SystemName']: foundRepService = repservice LOG.debug(""Found Replication Service: %s"" % (repservice)) break return foundRepService def _find_storage_configuration_service(self, storage_system): foundConfigService = None configservices = self.conn.EnumerateInstanceNames( STOR_CONF_SVC) for configservice in configservices: if storage_system == configservice['SystemName']: foundConfigService = configservice LOG.debug(""Found Storage Configuration Service: %s"" % (configservice)) break return foundConfigService def _find_controller_configuration_service(self, storage_system): foundConfigService = None configservices = self.conn.EnumerateInstanceNames( CTRL_CONF_SVC) for configservice in configservices: if storage_system == configservice['SystemName']: foundConfigService = configservice LOG.debug(""Found Controller Configuration Service: %s"" % (configservice)) break return foundConfigService def _find_storage_hardwareid_service(self, storage_system): foundConfigService = None configservices = self.conn.EnumerateInstanceNames( STOR_HWID_MNG_SVC) for configservice in configservices: if storage_system == configservice['SystemName']: foundConfigService = configservice LOG.debug(""Found Storage Hardware ID Management Service: %s"" % (configservice)) break return foundConfigService # Find pool based on storage_type def _find_pool(self, storage_type, details=False): foundPool = None systemname = None poolinstanceid = None # Only get instance names if details flag is False; # Otherwise get the whole instances systemname, port = self._get_ecom_server() poolinstanceid = self._get_pool_instance_id(storage_type) if details is False: pools = self.conn.EnumerateInstanceNames( 'CIM_StoragePool') else: pools = self.conn.EnumerateInstances( 'CIM_StoragePool') for pool in pools: if six.text_type(pool['InstanceID']) == six.text_type( poolinstanceid): foundPool = pool break if foundPool is None: exception_message = (_(""Pool %(storage_type)s is not found."") % {'storage_type': storage_type}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) if systemname is None: exception_message = (_(""Storage system not found for pool "" ""%(storage_type)s."") % {'storage_type': storage_type}) LOG.error(exception_message) raise exception.VolumeBackendAPIException(data=exception_message) LOG.debug(""Pool: %(pool)s SystemName: %(systemname)s."" % {'pool': foundPool, 'systemname': systemname}) return foundPool, systemname def _find_lun(self, volume): foundinstance = None volumename = self._create_volume_name(volume['id']) loc = volume['provider_location'] try: name = eval(loc) instancename = self._getinstancename(name['classname'], name['keybindings']) foundinstance = self.conn.GetInstance(instancename) except Exception: foundinstance = None if foundinstance is None: LOG.debug(""Volume %(volumename)s not found on the array."" ""volume instance is None."" % {'volumename': volumename}) else: LOG.debug(""Volume name: %(volumename)s Volume instance: "" ""%(vol_instance)s."" % {'volumename': volumename, 'vol_instance': foundinstance.path}) return foundinstance def _find_storage_sync_sv_sv(self, snapshot, volume, waitforsync=True): foundsyncname = None storage_system = None snapshotname = self._create_volume_name(snapshot['id']) volumename = self._create_volume_name(volume['id']) LOG.debug(""Source: %(volumename)s Target: %(snapshotname)s."" % {'volumename': volumename, 'snapshotname': snapshotname}) snapshot_instance = self._find_lun(snapshot) volume_instance = self._find_lun(volume) if snapshot_instance is None or volume_instance is None: LOG.info(_LI('Snapshot Volume %(snapshotname)s, ' 'Source Volume %(volumename)s not ' 'found on the array.') % {'snapshotname': snapshotname, 'volumename': volumename}) return None, None storage_system = volume_instance['SystemName'] classname = STOR_SYNC bindings = {'SyncedElement': snapshot_instance.path, 'SystemElement': volume_instance.path} foundsyncname = self._getinstancename(classname, bindings) if foundsyncname is None: LOG.debug(""Source: %(volumename)s Target: %(snapshotname)s. "" ""Storage Synchronized not found. "" % {'volumename': volumename, 'snapshotname': snapshotname}) else: LOG.debug(""Storage system: %(storage_system)s "" ""Storage Synchronized instance: %(sync)s."" % {'storage_system': storage_system, 'sync': foundsyncname}) # Wait for SE_StorageSynchronized_SV_SV to be fully synced if waitforsync: self.wait_for_sync(self.conn, foundsyncname) return foundsyncname, storage_system def _find_initiator_names(self, connector): foundinitiatornames = [] iscsi = 'iscsi' fc = 'fc' name = 'initiator name' if self.protocol.lower() == iscsi and connector['initiator']: foundinitiatornames.append(connector['initiator']) elif self.protocol.lower() == fc and connector['wwpns']: for wwn in connector['wwpns']: foundinitiatornames.append(wwn) name = 'world wide port names' if foundinitiatornames is None or len(foundinitiatornames) == 0: msg = (_('Error finding %s.') % name) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug(""Found %(name)s: %(initiator)s."" % {'name': name, 'initiator': foundinitiatornames}) return foundinitiatornames def _wait_for_job_complete(self, conn, job): """"""Given the job wait for it to complete. :param conn: connection the ecom server :param job: the job dict """""" def _wait_for_job_complete(): """"""Called at an interval until the job is finished"""""" if self._is_job_finished(conn, job): raise loopingcall.LoopingCallDone() if self.retries > JOB_RETRIES: LOG.error(_LE(""_wait_for_job_complete failed after %(retries)d"" "" tries"") % {'retries': self.retries}) raise loopingcall.LoopingCallDone() try: self.retries += 1 if not self.wait_for_job_called: if self._is_job_finished(conn, job): self.wait_for_job_called = True except Exception as e: LOG.error(_LE(""Exception: %s"") % six.text_type(e)) exceptionMessage = (_(""Issue encountered waiting for job."")) LOG.error(exceptionMessage) raise exception.VolumeBackendAPIException(exceptionMessage) self.retries = 0 self.wait_for_job_called = False timer = loopingcall.FixedIntervalLoopingCall(_wait_for_job_complete) timer.start(interval=INTERVAL_10_SEC).wait() jobInstanceName = job['Job'] jobinstance = conn.GetInstance(jobInstanceName, LocalOnly=False) rc = jobinstance['ErrorCode'] errordesc = jobinstance['ErrorDescription'] return rc, errordesc def _is_job_finished(self, conn, job): """"""Check if the job is finished. :param conn: connection the ecom server :param job: the job dict :returns: True if finished; False if not finished; """""" jobInstanceName = job['Job'] jobinstance = conn.GetInstance(jobInstanceName, LocalOnly=False) jobstate = jobinstance['JobState'] # From ValueMap of JobState in CIM_ConcreteJob # 2L=New, 3L=Starting, 4L=Running, 32767L=Queue Pending # ValueMap(""2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13..32767, # 32768..65535""), # Values(""New, Starting, Running, Suspended, Shutting Down, # Completed, Terminated, Killed, Exception, Service, # Query Pending, DMTF Reserved, Vendor Reserved"")] # NOTE(deva): string matching based on # http://ipmitool.cvs.sourceforge.net/ # viewvc/ipmitool/ipmitool/lib/ipmi_chassis.c if jobstate in [2L, 3L, 4L, 32767L]: return False else: return True def wait_for_sync(self, conn, syncName): """"""Given the sync name wait for it to fully synchronize. :param conn: connection the ecom server :param syncName: the syncName """""" def _wait_for_sync(): """"""Called at an interval until the synchronization is finished"""""" if self._is_sync_complete(conn, syncName): raise loopingcall.LoopingCallDone() if self.retries > JOB_RETRIES: LOG.error(_LE(""_wait_for_sync failed after %(retries)d tries"") % {'retries': self.retries}) raise loopingcall.LoopingCallDone() try: self.retries += 1 if not self.wait_for_sync_called: if self._is_sync_complete(conn, syncName): self.wait_for_sync_called = True except Exception as e: LOG.error(_LE(""Exception: %s"") % six.text_type(e)) exceptionMessage = (_(""Issue encountered waiting for "" ""synchronization."")) LOG.error(exceptionMessage) raise exception.VolumeBackendAPIException(exceptionMessage) self.retries = 0 self.wait_for_sync_called = False timer = loopingcall.FixedIntervalLoopingCall(_wait_for_sync) timer.start(interval=INTERVAL_10_SEC).wait() def _is_sync_complete(self, conn, syncName): """"""Check if the job is finished. :param conn: connection the ecom server :param syncName: the sync name :returns: True if fully synchronized; False if not; """""" syncInstance = conn.GetInstance(syncName, LocalOnly=False) percentSynced = syncInstance['PercentSynced'] if percentSynced < 100: return False else: return True # Find LunMaskingSCSIProtocolController for the local host on the # specified storage system def _find_lunmasking_scsi_protocol_controller(self, storage_system, connector): foundCtrls = [] initiators = self._find_initiator_names(connector) controllers = self.conn.EnumerateInstanceNames( SCSI_PROT_CTR) for ctrl in controllers: if storage_system != ctrl['SystemName']: continue associators =\ self.conn.Associators(ctrl, ResultClass=AUTH_PRIV) for assoc in associators: for initiator in initiators: if initiator.lower() not in assoc['InstanceID'].lower(): continue LOG.debug('_find_lunmasking_scsi_protocol_controller,' 'AffinityGroup:%(ag)s' % {'ag': ctrl}) foundCtrls.append(ctrl) break break LOG.debug(""LunMaskingSCSIProtocolController for storage system "" ""%(storage_system)s and initiator %(initiator)s is "" ""%(ctrl)s."" % {'storage_system': storage_system, 'initiator': initiators, 'ctrl': foundCtrls}) return foundCtrls # Find LunMaskingSCSIProtocolController for the local host and the # specified storage volume def _find_lunmasking_scsi_protocol_controller_for_vol(self, vol_instance, connector): foundCtrls = [] initiators = self._find_initiator_names(connector) controllers =\ self.conn.AssociatorNames( vol_instance.path, ResultClass=SCSI_PROT_CTR) LOG.debug('_find_lunmasking_scsi_protocol_controller_for_vol:' 'controllers:%(controllers)s' % {'controllers': controllers}) for ctrl in controllers: associators =\ self.conn.Associators( ctrl, ResultClass=AUTH_PRIV) foundCtrl = None for assoc in associators: for initiator in initiators: if initiator.lower() not in assoc['InstanceID'].lower(): continue LOG.debug('_find_lunmasking_scsi_protocol_controller' '_for_vol,' 'AffinityGroup:%(ag)s' % {'ag': ctrl}) foundCtrl = ctrl foundCtrls.append(foundCtrl) break if foundCtrl is not None: break LOG.debug(""LunMaskingSCSIProtocolController for storage volume "" ""%(vol)s and initiator %(initiator)s is %(ctrl)s."" % {'vol': vol_instance.path, 'initiator': initiators, 'ctrl': foundCtrls}) return foundCtrls # Find out how many volumes are mapped to a host # assoociated to the LunMaskingSCSIProtocolController def get_num_volumes_mapped(self, volume, connector): numVolumesMapped = 0 volumename = volume['name'] vol_instance = self._find_lun(volume) if vol_instance is None: msg = (_('Volume %(name)s not found on the array. ' 'Cannot determine if there are volumes mapped.') % {'name': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) storage_system = vol_instance['SystemName'] ctrl = self._find_lunmasking_scsi_protocol_controller( storage_system, connector) LOG.debug(""LunMaskingSCSIProtocolController for storage system "" ""%(storage)s and %(connector)s is %(ctrl)s."" % {'storage': storage_system, 'connector': connector, 'ctrl': ctrl}) associators = self.conn.Associators( ctrl, resultClass=STOR_VOL) numVolumesMapped = len(associators) LOG.debug(""Found %(numVolumesMapped)d volumes on storage system "" ""%(storage)s mapped to %(connector)s."" % {'numVolumesMapped': numVolumesMapped, 'storage': storage_system, 'connector': connector}) return numVolumesMapped # Find a device number that a host can see for a volume def find_device_number(self, volume, connector): out_num_device_number = None volumename = self._create_volume_name(volume['id']) vol_instance = self._find_lun(volume) storage_system = vol_instance['SystemName'] sp = None ctrls = self._find_lunmasking_scsi_protocol_controller_for_vol( vol_instance, connector) LOG.debug(""LunMaskingSCSIProtocolController for "" ""volume %(vol)s and connector %(connector)s "" ""is %(ctrl)s."" % {'vol': vol_instance.path, 'connector': connector, 'ctrl': ctrls}) if len(ctrls) != 0: unitnames = self.conn.ReferenceNames( vol_instance.path, ResultClass='CIM_ProtocolControllerForUnit') for unitname in unitnames: controller = unitname['Antecedent'] classname = controller['CreationClassName'] index = classname.find(SCSI_PROT_CTR) if index > -1: if ctrls[0]['DeviceID'] != controller['DeviceID']: continue # Get an instance of CIM_ProtocolControllerForUnit unitinstance = self.conn.GetInstance(unitname, LocalOnly=False) numDeviceNumber = int(unitinstance['DeviceNumber'], 16) out_num_device_number = numDeviceNumber break if out_num_device_number is None: LOG.info(_LI(""Device number not found for volume "" ""%(volumename)s %(vol_instance)s."") % {'volumename': volumename, 'vol_instance': vol_instance.path}) else: LOG.debug(""Found device number %(device)d for volume "" ""%(volumename)s %(vol_instance)s."" % {'device': out_num_device_number, 'volumename': volumename, 'vol_instance': vol_instance.path}) data = {'hostlunid': out_num_device_number, 'storagesystem': storage_system, 'owningsp': sp} LOG.debug(""Device info: %(data)s."" % {'data': data}) return data def _getnum(self, num, datatype): try: result = { '8': pywbem.Uint8(num), '16': pywbem.Uint16(num), '32': pywbem.Uint32(num), '64': pywbem.Uint64(num) } result = result.get(datatype, num) except NameError: result = num return result def _getinstancename(self, classname, bindings): instancename = None try: instancename = pywbem.CIMInstanceName( classname, namespace=SMIS_ROOT, keybindings=bindings) except NameError: instancename = None return instancename # Find Storage Hardware IDs def _find_storage_hardwareids(self, connector): foundInstances = [] wwpns = self._find_initiator_names(connector) hardwareids = self.conn.EnumerateInstances( STOR_HWID) for hardwareid in hardwareids: storid = hardwareid['StorageID'] for wwpn in wwpns: if wwpn.lower() == storid.lower(): foundInstances.append(hardwareid.path) LOG.debug(""Storage Hardware IDs for %(wwpns)s is "" ""%(foundInstances)s."" % {'wwpns': wwpns, 'foundInstances': foundInstances}) return foundInstances def _get_volumetype_extraspecs(self, volume): specs = {} type_id = volume['volume_type_id'] if type_id is not None: specs = volume_types.get_volume_type_extra_specs(type_id) # If specs['storagetype:pool'] not defined, # set specs to {} so we can ready from config file later if POOL not in specs: specs = {} return specs def _get_provisioning(self, storage_type): # provisioning is thin (5) by default provisioning = 5 thick_str = 'thick' try: type_prov = storage_type[PROVISIONING] if type_prov.lower() == thick_str.lower(): provisioning = 2 except KeyError: # Default to thin if not defined pass return provisioning def _create_volume_name(self, id_code): """"""create volume_name on ETERNUS from id on OpenStack."""""" LOG.debug('_create_volume_name [%s],Enter method.' % id_code) if id_code is None: msg = (_('_create_volume_name,' 'id_code is None.')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # pylint: disable=E1101 m = hashlib.md5() m.update(id_code) # pylint: disable=E1121 volname = base64.urlsafe_b64encode((m.digest())) ret = VOL_PREFIX + six.text_type(volname) LOG.debug('_create_volume_name: ' ' id:%(id)s' ' volumename:%(ret)s' ' Exit method.' % {'id': id_code, 'ret': ret}) return ret def _get_pool_instance_id(self, poolname): """"""get pool instacne_id from pool name"""""" LOG.debug('_get_pool_instance_id,' 'Enter method,poolname:%s' % (poolname)) poolinstanceid = None pool = None pools = [] msg = None try: pools = self.conn.EnumerateInstances( 'CIM_StoragePool') except Exception: msg = (_('_get_pool_instance_id,' 'poolname:%(poolname)s,' 'EnumerateInstances,' 'cannot connect to ETERNUS.') % {'poolname': poolname}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) for pool in pools: pool_elementname = pool['ElementName'] poolclass = pool.path.classname LOG.debug('poolname from file or VolumeType:%s' ' poolname from smis:%s' ' poolclass from smis:%s' % (poolname, pool_elementname, poolclass)) if six.text_type(poolname) == six.text_type(pool_elementname): if poolclass in STOR_POOLS: poolinstanceid = pool['InstanceID'] break if poolinstanceid is None: msg = (_('_get_pool_instance_id,' 'poolname:%(poolname)s,' 'poolinstanceid is None.') % {'poolname': poolname}) LOG.info(msg) LOG.debug('_get_pool_instance_id,' 'Exit method,poolinstanceid:%s' % (poolinstanceid)) return poolinstanceid def get_target_portid(self, connector): """"""return target_portid"""""" LOG.debug('get_target_portid,Enter method') target_portidlist = [] tgtportlist = [] tgtport = None conn_type = {'fc': 2, 'iscsi': 7} try: tgtportlist = self.conn.EnumerateInstances( 'CIM_SCSIProtocolEndpoint') except Exception: msg = (_('get_target_portid,' 'connector:%(connector)s,' 'EnumerateInstances,' 'cannot connect to ETERNUS.') % {'connector': connector}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) for tgtport in tgtportlist: if tgtport['ConnectionType'] == conn_type[self.protocol.lower()]: target_portidlist.append(tgtport['Name']) LOG.debug('get_target_portid,' 'portid:%(portid)s,' 'connection type:%(cont)s,' % {'portid': tgtport['Name'], 'cont': tgtport['ConnectionType']}) LOG.debug('get_target_portid,' 'target portid: %(target_portid)s ' % {'target_portid': target_portidlist}) if len(target_portidlist) == 0: msg = (_('get_target_portid,' 'protcol:%(protocol)s,' 'connector:%(connector)s,' 'target_portid does not found.') % {'protocol': self.protocol, 'connector': connector}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('get_target_portid,Exit method') return target_portidlist def _find_copysession(self, volume): """"""find copysession from volumename on ETERNUS"""""" LOG.debug('_find_copysession, Enter method') cpsession = None vol_instance = None repservice = None rc = 0 replicarellist = None replicarel = None snapshot_vol_instance = None msg = None errordesc = None vol_instance = self._find_lun(volume) if vol_instance is None: return None, None volumename = vol_instance['ElementName'] storage_system = vol_instance['SystemName'] if vol_instance is not None: # find target_volume # get copysession list repservice = self._find_replication_service(storage_system) if repservice is None: msg = (_('_find_copysession,' 'Cannot find Replication Service to ' 'find copysession')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def _wait_for_job(repservice): cpsession_instance = None LOG.debug('_find_copysession,source_volume' ' while copysession') cpsession = None rc, replicarellist = self.conn.InvokeMethod( 'GetReplicationRelationships', repservice, Type=self._getnum(2, '16'), Mode=self._getnum(2, '16'), Locality=self._getnum(2, '16')) errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: msg = (_('_find_copysession,' 'source_volumename:%(volumename)s,' 'Return code:%(rc)lu,' 'Error:%(errordesc)s') % {'volumename': volumename, 'rc': rc, 'errordesc': errordesc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) for replicarel in replicarellist['Synchronizations']: LOG.debug('_find_copysession,' 'source_volume,' 'replicarel:%(replicarel)s' % {'replicarel': replicarel}) try: snapshot_vol_instance = self.conn.GetInstance( replicarel['SystemElement'], LocalOnly=False) except Exception: msg = (_('_find_copysession,' 'source_volumename:%(volumename)s,' 'GetInstance,' 'cannot connect to ETERNUS.') % {'volumename': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('_find_copysession,' 'snapshot ElementName:%(elementname)s,' 'source_volumename:%(volumename)s' % {'elementname': snapshot_vol_instance['ElementName'], 'volumename': volumename}) if volumename == snapshot_vol_instance['ElementName']: # find copysession cpsession = replicarel LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized instance:%(sync)s' % {'volumename': volumename, 'sync': six.text_type(cpsession)}) msg = (_('_find_copy_session,' 'source_volumename:%(volumename)s,' 'wait for end of copysession') % {'volumename': volumename}) LOG.info(msg) try: cpsession_instance = self.conn.GetInstance( replicarel) except Exception: break LOG.debug('_find_copysession,' 'status:%(status)s' % {'status': cpsession_instance['CopyState']}) if cpsession_instance['CopyState'] == BROKEN: msg = (_('_find_copysession,' 'source_volumename:%(volumename)s,' 'copysession state is BROKEN') % {'volumename': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) break else: LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized not found.' % {'volumename': volumename}) if cpsession is None: raise loopingcall.LoopingCallDone() timer = loopingcall.FixedIntervalLoopingCall( _wait_for_job, repservice) timer.start(interval=10).wait() rc, replicarellist = self.conn.InvokeMethod( 'GetReplicationRelationships', repservice, Type=self._getnum(2, '16'), Mode=self._getnum(2, '16'), Locality=self._getnum(2, '16')) errordesc = RETCODE_dic[six.text_type(rc)] if rc != 0L: msg = (_('_find_copysession,' 'source_volumename:%(volumename)s,' 'Return code:%(rc)lu,' 'Error:%(errordesc)s') % {'volumename': volumename, 'rc': rc, 'errordesc': errordesc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # find copysession for target_volume for replicarel in replicarellist['Synchronizations']: LOG.debug('_find_copysession,' 'replicarel:%(replicarel)s' % {'replicarel': replicarel}) # target volume try: snapshot_vol_instance = self.conn.GetInstance( replicarel['SyncedElement'], LocalOnly=False) except Exception: msg = (_('_find_copysession,' 'target_volumename:%(volumename)s,' 'GetInstance,' 'cannot connect to ETERNUS.') % {'volumename': volumename}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('_find_copysession,' 'snapshot ElementName:%(elementname)s,' 'volumename:%(volumename)s' % {'elementname': snapshot_vol_instance['ElementName'], 'volumename': volumename}) if volumename == snapshot_vol_instance['ElementName']: # find copysession cpsession = replicarel LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized instance:%(sync)s' % {'volumename': volumename, 'sync': six.text_type(cpsession)}) break else: LOG.debug('_find_copysession,' 'volumename:%(volumename)s,' 'Storage Synchronized not found.' % {'volumename': volumename}) else: # does not find target_volume of copysession msg = (_('_find_copysession,' 'volumename:%(volumename)s,' 'not found.') % {'volumename': volumename}) LOG.info(msg) LOG.debug('_find_copysession,Exit method') return cpsession, storage_system def _delete_copysession(self, storage_system, cpsession): """"""delete copysession"""""" LOG.debug('_delete_copysession,Entering') LOG.debug('_delete_copysession,[%s]' % cpsession) snapshot_instance = None msg = None errordesc = None try: snapshot_instance = self.conn.GetInstance( cpsession, LocalOnly=False) except Exception: msg = (_('_delete_copysession, ' 'copysession:%(cpsession)s,' 'GetInstance,' 'cannot connect to ETERNUS.') % {'cpsession': cpsession}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) copytype = snapshot_instance['CopyType'] # set oparation code operation = OPERATION_dic[copytype] repservice = self._find_replication_service(storage_system) if repservice is None: msg = (_('_delete_copysession,' 'Cannot find Replication Service to ' 'delete copysession')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # Invoke method for delete copysession rc, job = self.conn.InvokeMethod( 'ModifyReplicaSynchronization', repservice, Operation=self._getnum(operation, '16'), Synchronization=cpsession, Force=True, WaitForCopyState=self._getnum(15, '16')) errordesc = RETCODE_dic[six.text_type(rc)] LOG.debug('_delete_copysession,' 'copysession:%(cpsession)s,' 'operation:%(operation)s,' 'Return code:%(rc)lu,' 'Error:%(errordesc)s,' 'Exit method' % {'cpsession': cpsession, 'operation': operation, 'rc': rc, 'errordesc': errordesc}) if rc != 0L: msg = (_('_delete_copysession,' 'copysession:%(cpsession)s,' 'operation:%(operation)s,' 'Return code:%(rc)lu,' 'Error:%(errordesc)s') % {'cpsession': cpsession, 'operation': operation, 'rc': rc, 'errordesc': errordesc}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return ",3,2652
openstack%2Fnova~master~I7ab9f7f0615c137025aa07e4113e0d207d36a4c5,openstack/nova,master,I7ab9f7f0615c137025aa07e4113e0d207d36a4c5,extract RPC setup into a fixture,MERGED,2014-12-10 15:42:13.000000000,2014-12-19 03:26:46.000000000,2014-12-18 23:58:34.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 15:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f1b9e1c3856237b75fca2152f7ccfa2d9d545efa', 'message': 'extract RPC setup into a fixture\n\nThis extracts the common RPC setup into a fixture. Eventually we need\nto get this fixture off the base setup as < 5% of tests actually use\nthe RPC infrastructure today (probably more than half of those are\nusing it by accident due to insufficient mocking), and only 3 cells\ntests actually need the exmods setting.\n\nThis moves the ball forward slightly towards getting there.\n\npart of bp:functional-tests-for-nova\n\nChange-Id: I7ab9f7f0615c137025aa07e4113e0d207d36a4c5\n'}, {'number': 2, 'created': '2014-12-10 19:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f5e24b3af1e02bcf2521afc402416e9bd5bf456', 'message': 'extract RPC setup into a fixture\n\nThis extracts the common RPC setup into a fixture. Eventually we need\nto get this fixture off the base setup as < 5% of tests actually use\nthe RPC infrastructure today (probably more than half of those are\nusing it by accident due to insufficient mocking), and only 3 cells\ntests actually need the exmods setting.\n\nThis moves the ball forward slightly towards getting there.\n\npart of bp:functional-tests-for-nova\n\nChange-Id: I7ab9f7f0615c137025aa07e4113e0d207d36a4c5\n'}, {'number': 3, 'created': '2014-12-18 20:52:28.000000000', 'files': ['nova/tests/fixtures.py', 'nova/test.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d907e778e26aafca0d996e3827d6009d7965f736', 'message': 'extract RPC setup into a fixture\n\nThis extracts the common RPC setup into a fixture. Eventually we need\nto get this fixture off the base setup as < 5% of tests actually use\nthe RPC infrastructure today (probably more than half of those are\nusing it by accident due to insufficient mocking), and only 3 cells\ntests actually need the exmods setting.\n\nThis moves the ball forward slightly towards getting there.\n\npart of bp:functional-tests-for-nova\n\nChange-Id: I7ab9f7f0615c137025aa07e4113e0d207d36a4c5\n'}]",0,140739,d907e778e26aafca0d996e3827d6009d7965f736,41,12,3,2750,,,0,"extract RPC setup into a fixture

This extracts the common RPC setup into a fixture. Eventually we need
to get this fixture off the base setup as < 5% of tests actually use
the RPC infrastructure today (probably more than half of those are
using it by accident due to insufficient mocking), and only 3 cells
tests actually need the exmods setting.

This moves the ball forward slightly towards getting there.

part of bp:functional-tests-for-nova

Change-Id: I7ab9f7f0615c137025aa07e4113e0d207d36a4c5
",git fetch https://review.opendev.org/openstack/nova refs/changes/39/140739/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/fixtures.py', 'nova/test.py']",2,f1b9e1c3856237b75fca2152f7ccfa2d9d545efa,bp/functional-tests-for-nova, self.useFixture(nova_fixtures.RPCFixture('nova.test')),from oslo.messaging import conffixture as messaging_conffixturefrom nova import rpc rpc.add_extra_exmods('nova.test') self.addCleanup(rpc.clear_extra_exmods) self.addCleanup(rpc.cleanup) self.messaging_conf = messaging_conffixture.ConfFixture(CONF) self.messaging_conf.transport_driver = 'fake' self.useFixture(self.messaging_conf) rpc.init(CONF),20,13
openstack%2Fneutron~master~I7d0ba7f00567ae5a4dd0669ed86d6e8d554ca4ec,openstack/neutron,master,I7d0ba7f00567ae5a4dd0669ed86d6e8d554ca4ec,Update heal_script for alembic 0.7.1,MERGED,2014-12-04 09:25:24.000000000,2014-12-19 03:25:01.000000000,2014-12-19 03:24:59.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 8645}, {'_account_id': 8655}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 11816}, {'_account_id': 12040}, {'_account_id': 12683}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-04 09:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e1a03c171c3c7225151bc8105da4b7a57db4f06b', 'message': 'Update heal_script up to alembic 0.7.1\n\nAlembic 0.7.1 contains checks of foreign keys so\nmethod check_foreign_keys is not needed anymore.\nHeal script should be updated to make it possible to use alembic\nmethods.\n\nCloses-bug: #1398417\n\nChange-Id: I7d0ba7f00567ae5a4dd0669ed86d6e8d554ca4ec\n'}, {'number': 2, 'created': '2014-12-04 15:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8df94bf6747bce6abaddb989509a0e0798deb307', 'message': 'Update heal_script for alembic 0.7.1\n\nAlembic 0.7.1 contains checks of foreign keys so\nmethod check_foreign_keys is not needed anymore.\nHeal script should be updated to make it possible to use alembic\nmethods.\n\nCloses-bug: #1398417\n\nChange-Id: I7d0ba7f00567ae5a4dd0669ed86d6e8d554ca4ec\n'}, {'number': 3, 'created': '2014-12-05 13:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/56c7618ebd92a6d37c95853c79f13f96a162ea6b', 'message': 'Update heal_script for alembic 0.7.1\n\nAlembic 0.7.1 contains checks of foreign keys so\nmethod check_foreign_keys is not needed anymore.\nHeal script should be updated to make it possible to use alembic\nmethods.\n\nCloses-bug: #1398417\n\nChange-Id: I7d0ba7f00567ae5a4dd0669ed86d6e8d554ca4ec\n'}, {'number': 4, 'created': '2014-12-05 13:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1908612326d1f33f34e7e0c451399bfb0edbcb3', 'message': 'Update heal_script for alembic 0.7.1\n\nAlembic 0.7.1 contains checks of foreign keys so\nmethod check_foreign_keys is not needed anymore.\nHeal script should be updated to make it possible to use alembic\nmethods.\n\nCloses-bug: #1398417\n\nChange-Id: I7d0ba7f00567ae5a4dd0669ed86d6e8d554ca4ec\n'}, {'number': 5, 'created': '2014-12-18 14:20:28.000000000', 'files': ['neutron/db/migration/alembic_migrations/heal_script.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e5c24336bee834334e56a5ef8ccb66e380baa3b', 'message': 'Update heal_script for alembic 0.7.1\n\nAlembic 0.7.1 contains checks of foreign keys so\nmethod check_foreign_keys is not needed anymore.\nHeal script should be updated to make it possible to use alembic\nmethods.\n\nCloses-bug: #1398417\n\nChange-Id: I7d0ba7f00567ae5a4dd0669ed86d6e8d554ca4ec\n'}]",11,138998,8e5c24336bee834334e56a5ef8ccb66e380baa3b,119,35,5,7249,,,0,"Update heal_script for alembic 0.7.1

Alembic 0.7.1 contains checks of foreign keys so
method check_foreign_keys is not needed anymore.
Heal script should be updated to make it possible to use alembic
methods.

Closes-bug: #1398417

Change-Id: I7d0ba7f00567ae5a4dd0669ed86d6e8d554ca4ec
",git fetch https://review.opendev.org/openstack/neutron refs/changes/98/138998/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/alembic_migrations/heal_script.py'],1,e1a03c171c3c7225151bc8105da4b7a57db4f06b,bug/1398417,"from neutron.i18n import _LI, _LW diff = autogen.compare_metadata(mc, models_metadata) else: LOG.warning(_LW(""Alembic command %s is not processed""), command[0])def remove_fk(fk): op.drop_constraint(fk.name, fk.parent.name, type_='foreignkey')def add_fk(fk): fk_table = fk.parent.name fk_ref = fk._referred_table.name fk_local_cols = [] for column in fk.columns: if not isinstance(column, basestring): fk_local_cols.append(column.name) else: fk_local_cols.append(column) fk_remote_cols = [k.column.name for k in fk._elements.values()]","from neutron.i18n import _LI diff1 = autogen.compare_metadata(mc, models_metadata) # Alembic does not contain checks for foreign keys. Because of that it # checks separately. added_fks, dropped_fks = check_foreign_keys(models_metadata) diff = dropped_fks + diff1 + added_fks # For each difference run commanddef drop_key(fk_name, fk_table): op.drop_constraint(fk_name, fk_table, type_='foreignkey')def add_key(fk): fk_table = fk.parent.table.name fk_ref = fk.column.table.name fk_local_cols = [fk.parent.name] fk_remote_cols = [fk.column.name]def check_foreign_keys(metadata): # This methods checks foreign keys that tables contain in models with # foreign keys that are in db. added_fks = [] dropped_fks = [] bind = op.get_bind() insp = sqlalchemy.engine.reflection.Inspector.from_engine(bind) # Get all tables from db db_tables = insp.get_table_names() # Get all tables from models model_tables = metadata.tables for table in db_tables: if table not in model_tables: continue # Get all necessary information about key of current table from db fk_db = dict((_get_fk_info_db(i), i['name']) for i in insp.get_foreign_keys(table)) fk_db_set = set(fk_db.keys()) # Get all necessary information about key of current table from models fk_models = dict((_get_fk_info_from_model(fk), fk) for fk in model_tables[table].foreign_keys) fk_models_set = set(fk_models.keys()) for key in (fk_db_set - fk_models_set): dropped_fks.append(('drop_key', fk_db[key], table)) LOG.info(_LI(""Detected removed foreign key %(fk)r on "" ""table %(table)r""), {'fk': fk_db[key], 'table': table}) for key in (fk_models_set - fk_db_set): added_fks.append(('add_key', fk_models[key])) LOG.info(_LI(""Detected added foreign key for column %(fk)r on "" ""table %(table)r""), {'fk': fk_models[key].column.name, 'table': table}) return (added_fks, dropped_fks) def _get_fk_info_db(fk): return (tuple(fk['constrained_columns']), fk['referred_table'], tuple(fk['referred_columns'])) def _get_fk_info_from_model(fk): return ((fk.parent.name,), fk.column.table.name, (fk.column.name,)) ",16,59
openstack%2Fneutron~master~I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef,openstack/neutron,master,I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef,Avoid unnecessary explicit str() conversion around exceptions,MERGED,2014-12-03 12:57:58.000000000,2014-12-19 03:21:39.000000000,2014-12-19 03:21:37.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10237}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 11816}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}, {'_account_id': 14352}]","[{'number': 1, 'created': '2014-12-03 12:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/574133d97364b999bc5715f730494334eb84ac3b', 'message': 'test\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 2, 'created': '2014-12-03 14:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b8985b5027b75c0ae3daf2e13f2d68b407be9914', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 3, 'created': '2014-12-03 14:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/143d5059c659361a93f5fd70714d17624122498e', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 4, 'created': '2014-12-03 14:36:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e31abb0ebc5ca3b8d7960878af9709e35afdf2c1', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 5, 'created': '2014-12-03 15:02:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8dd3219905d6f6abee5f4d9446b0970d40c52bf', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 6, 'created': '2014-12-04 10:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3f0786e6a1024f92dd29a2afc773500a37bcee44', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 7, 'created': '2014-12-04 10:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/56c6b9ec128526379a77066620eb1d56d2c687b3', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 8, 'created': '2014-12-05 11:02:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ca1cf46dcff95ae9d592ef09dd95ba2903b6129', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion. Also LOG.error could be replaced with\nLOG.exception, so argument exc won\'t be needed at all.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 9, 'created': '2014-12-05 12:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2eb8f597b0081d62a36a474341c25d6a4edd7ae4', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion. Also LOG.error could be replaced with\nLOG.exception, so argument exc won\'t be needed at all.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 10, 'created': '2014-12-05 12:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44d5a5d807c9f85cd4c755aed3ed7ad9f4b7bcec', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion. Also LOG.error could be replaced with\nLOG.exception, so argument exc won\'t be needed at all.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 11, 'created': '2014-12-05 12:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7aabeab692994e5eaa08ac45008e74ef68383f28', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion. Also LOG.error could be replaced with\nLOG.exception, so argument exc won\'t be needed at all.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 12, 'created': '2014-12-05 14:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/885fcd41ab5e73be6832157132becf230fdf2405', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion. Also LOG.error could be replaced with\nLOG.exception, so argument exc won\'t be needed at all.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 13, 'created': '2014-12-05 14:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/df6de52898edca939b7d6e43b7f7287a041f97f4', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion. Also LOG.error could be replaced with\nLOG.exception, so argument exc won\'t be needed at all.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 14, 'created': '2014-12-08 08:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d8dd792421d17c6277b1615d0fcff043913dbd72', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion. Also LOG.error could be replaced with\nLOG.exception, so argument exc won\'t be needed at all.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 15, 'created': '2014-12-11 07:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3abaf000b615a201024e179dbf59580f3b4bd0b3', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion. Also LOG.error could be replaced with\nLOG.exception, so argument exc won\'t be needed at all.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 16, 'created': '2014-12-16 08:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae23e3486f763b8ac4a4de916d5c66a9cf3a80c5', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion. Also LOG.error could be replaced with\nLOG.exception, so argument exc won\'t be needed at all.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}, {'number': 17, 'created': '2014-12-16 08:18:03.000000000', 'files': ['neutron/db/migration/cli.py', 'neutron/agent/l3/agent.py', 'neutron/tests/unit/database_stubs.py', 'neutron/plugins/nec/packet_filter.py', 'neutron/plugins/nuage/syncmanager.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/plugins/vmware/check_nsx_config.py', 'neutron/plugins/vmware/nsxlib/switch.py', 'neutron/plugins/vmware/nsxlib/router.py', 'neutron/plugins/sriovnicagent/pci_lib.py', 'neutron/plugins/cisco/l3/hosting_device_drivers/csr1kv_hd_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3a7c3f77b0a311447c8db8d4d7c50326f40b2515', 'message': 'Avoid unnecessary explicit str() conversion around exceptions\n\nThere are number of places like\n\nexcept Exception as exc:\n            LOG.error(""Failed to get network: %s"", str(exc))\n\nwhere str() is not needed since %s substitution already does\nthe same conversion. Also LOG.error could be replaced with\nLOG.exception, so argument exc won\'t be needed at all.\n\nCloses-bug: #1398839\n\nChange-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef\n'}]",25,138709,3a7c3f77b0a311447c8db8d4d7c50326f40b2515,399,43,17,7249,,,0,"Avoid unnecessary explicit str() conversion around exceptions

There are number of places like

except Exception as exc:
            LOG.error(""Failed to get network: %s"", str(exc))

where str() is not needed since %s substitution already does
the same conversion. Also LOG.error could be replaced with
LOG.exception, so argument exc won't be needed at all.

Closes-bug: #1398839

Change-Id: I73cc6e1ce55ade08e7706b99a5ab075f7059a4ef
",git fetch https://review.opendev.org/openstack/neutron refs/changes/09/138709/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/nec/packet_filter.py', 'neutron/agent/l3_agent.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/agent/linux/async_process.py', 'neutron/tests/unit/opencontrail/test_contrail_plugin.py', 'neutron/tests/unit/database_stubs.py', 'neutron/plugins/nuage/syncmanager.py', 'neutron/plugins/cisco/l3/hosting_device_drivers/csr1kv_hd_driver.py', 'neutron/tests/unit/test_basetestcase.py', 'neutron/tests/unit/nec/test_portbindings.py', 'neutron/plugins/mlnx/mlnx_plugin.py', 'neutron/agent/linux/ovs_lib.py', 'neutron/db/migration/cli.py', 'neutron/plugins/hyperv/agent/hyperv_neutron_agent.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/plugins/ml2/drivers/brocade/nos/nosdriver.py', 'neutron/plugins/vmware/check_nsx_config.py', 'neutron/plugins/vmware/nsxlib/router.py', 'neutron/plugins/midonet/plugin.py', 'neutron/plugins/brocade/nos/nosdriver.py', 'neutron/tests/unit/test_common_utils.py', 'neutron/plugins/ml2/drivers/cisco/nexus/nexus_network_driver.py', 'neutron/plugins/midonet/midonet_lib.py', 'neutron/plugins/vmware/nsxlib/switch.py', 'neutron/agent/linux/utils.py', 'neutron/plugins/sriovnicagent/pci_lib.py', 'neutron/tests/unit/nec/test_ofc_client.py']",27,574133d97364b999bc5715f730494334eb84ac3b,bug/1398839,"import six self.assertEqual(expected_data, six.text_type(e))"," self.assertEqual(expected_data, str(e))",88,57
openstack%2Fpython-ironicclient~master~I930fd61a896f62a2984cca1e4d40e5d89644aa3f,openstack/python-ironicclient,master,I930fd61a896f62a2984cca1e4d40e5d89644aa3f,Fix to properly issue an Unauthorized exception,MERGED,2014-12-16 19:38:01.000000000,2014-12-19 02:54:01.000000000,2014-12-18 14:18:04.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 10343}, {'_account_id': 14228}]","[{'number': 1, 'created': '2014-12-16 19:38:01.000000000', 'files': ['ironicclient/tests/test_http.py', 'ironicclient/exc.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/4017ae76888c3b0a61df9ecacd15d89f039a95b6', 'message': ""Fix to properly issue an Unauthorized exception\n\nThis change adds a small workaround in exc.py to avoid a situation\nwhere an HTTP response that has a content-type of 'text/*' but\nno text attribute will trigger an AttributeError exception in\nthe openstack.common.apiclient.exceptions module.\n\nAdded a test to make sure the ironic client throws an 'Unauthorized'\nexception when it encounters a 401 Unauthorized HTTP response instead\nof the observed behavior of throwing an inappropriate AttributeError\nexception.\n\nThe workaround mentioned above corrects the tested behavior.\n\nChange-Id: I930fd61a896f62a2984cca1e4d40e5d89644aa3f\nPartial-Bug: #1402840\n""}]",4,142204,4017ae76888c3b0a61df9ecacd15d89f039a95b6,17,6,1,14228,,,0,"Fix to properly issue an Unauthorized exception

This change adds a small workaround in exc.py to avoid a situation
where an HTTP response that has a content-type of 'text/*' but
no text attribute will trigger an AttributeError exception in
the openstack.common.apiclient.exceptions module.

Added a test to make sure the ironic client throws an 'Unauthorized'
exception when it encounters a 401 Unauthorized HTTP response instead
of the observed behavior of throwing an inappropriate AttributeError
exception.

The workaround mentioned above corrects the tested behavior.

Change-Id: I930fd61a896f62a2984cca1e4d40e5d89644aa3f
Partial-Bug: #1402840
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/04/142204/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/tests/test_http.py', 'ironicclient/exc.py']",2,4017ae76888c3b0a61df9ecacd15d89f039a95b6,bug/1402840," if (response.headers['Content-Type'].startswith('text/') and not hasattr(response, 'text')): # NOTE(clif_h): There seems to be a case in the # openstack.common.apiclient.exceptions module where if the # content-type of the response is text/* then it expects # the response to have a 'text' attribute, but that # doesn't always seem to necessarily be the case. # This is to work around that problem. response.text = '' ",,23,0
openstack%2Ftricircle~master~I8d81193050d7847d288ddc7c936b2cb4616d4c50,openstack/tricircle,master,I8d81193050d7847d288ddc7c936b2cb4616d4c50,fix  tenant name for  admin client,MERGED,2014-12-19 02:47:57.000000000,2014-12-19 02:49:04.000000000,2014-12-19 02:49:04.000000000,"[{'_account_id': 3}, {'_account_id': 13924}]","[{'number': 1, 'created': '2014-12-19 02:47:57.000000000', 'files': ['tricircle', 'cinderproxy/cinder/volume/cinder_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/1b9de6b874d0afe5c23feb006560b70072f8ac18', 'message': 'fix  tenant name for  admin client\n\nChange-Id: I8d81193050d7847d288ddc7c936b2cb4616d4c50\n'}]",0,142961,1b9de6b874d0afe5c23feb006560b70072f8ac18,6,2,1,13924,,,0,"fix  tenant name for  admin client

Change-Id: I8d81193050d7847d288ddc7c936b2cb4616d4c50
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/61/142961/1 && git format-patch -1 --stdout FETCH_HEAD,"['tricircle', 'cinderproxy/cinder/volume/cinder_proxy.py']",2,1b9de6b874d0afe5c23feb006560b70072f8ac18,," tenant_name=cfg.CONF.cinder_tenant_name, except cinder_exception.Unauthorized: self.adminCinderClient = self._get_cinder_cascaded_admin_client()"," tenant_id=cfg.CONF.cinder_tenant_name, return except cinder_exception.Unauthorized:",2,3
openstack%2Fcinder~master~I308b3b2dff315ec33451fb45a30ecd53d5d4c353,openstack/cinder,master,I308b3b2dff315ec33451fb45a30ecd53d5d4c353,Ensure that lun_id is an int for NetApp Drivers,MERGED,2014-12-15 16:10:24.000000000,2014-12-19 02:39:59.000000000,2014-12-16 19:15:13.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 7198}, {'_account_id': 10058}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11865}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 12779}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-15 16:10:24.000000000', 'files': ['cinder/tests/volume/drivers/netapp/fakes.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/tests/volume/drivers/netapp/test_utils.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py', 'cinder/volume/drivers/netapp/dataontap/block_base.py', 'cinder/tests/volume/drivers/netapp/dataontap/fakes.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2d0204ff3ca3a7d42fac5722d577e18edd34ea83', 'message': 'Ensure that lun_id is an int for NetApp Drivers\n\nVarious NetApp drivers were treating the lun_id as a string\nrather than an int.  This was causing attempts to mount NetApp\nvolumes to Hyper-V nodes to fail as they were checking an integer\ntype against a unicode type which would fail.\n\nThis change casts result_lun to an integer after the value has\ngone through the ssh injection attack check.  This way Hyper-V\nis able to verify if the found LUN is the target LUN, enabling\nmounting of NetApp volumes to Hyper-V.\n\nThis change also refactors initialize_connection into some helper\nmethods so as to enable simpler unit testing of the patchset.\n\nCloses-bug: 1372808\n\nChange-Id: I308b3b2dff315ec33451fb45a30ecd53d5d4c353\n'}]",1,141834,2d0204ff3ca3a7d42fac5722d577e18edd34ea83,24,13,1,11878,,,0,"Ensure that lun_id is an int for NetApp Drivers

Various NetApp drivers were treating the lun_id as a string
rather than an int.  This was causing attempts to mount NetApp
volumes to Hyper-V nodes to fail as they were checking an integer
type against a unicode type which would fail.

This change casts result_lun to an integer after the value has
gone through the ssh injection attack check.  This way Hyper-V
is able to verify if the found LUN is the target LUN, enabling
mounting of NetApp volumes to Hyper-V.

This change also refactors initialize_connection into some helper
methods so as to enable simpler unit testing of the patchset.

Closes-bug: 1372808

Change-Id: I308b3b2dff315ec33451fb45a30ecd53d5d4c353
",git fetch https://review.opendev.org/openstack/cinder refs/changes/34/141834/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/volume/drivers/netapp/fakes.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/tests/volume/drivers/netapp/test_utils.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py', 'cinder/volume/drivers/netapp/dataontap/block_base.py', 'cinder/tests/volume/drivers/netapp/dataontap/fakes.py']",6,2d0204ff3ca3a7d42fac5722d577e18edd34ea83,bug/1372808," 'data': {'target_lun': 1,"," 'data': {'target_lun': '1',",97,40
openstack%2Fneutron-specs~master~I6c3e8bd49b080af65fefa7f5cfc753734f9f6d31,openstack/neutron-specs,master,I6c3e8bd49b080af65fefa7f5cfc753734f9f6d31,Remove the tab in the diagram.,ABANDONED,2014-12-18 15:30:43.000000000,2014-12-19 02:25:41.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-18 15:30:43.000000000', 'files': ['specs/kilo/virtual-network-performance-monitor.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/de940261690e3b74155767a0957e25982b96c361', 'message': 'Remove the tab in the diagram.\n\nChange-Id: I6c3e8bd49b080af65fefa7f5cfc753734f9f6d31\n'}]",0,142818,de940261690e3b74155767a0957e25982b96c361,3,1,1,13000,,,0,"Remove the tab in the diagram.

Change-Id: I6c3e8bd49b080af65fefa7f5cfc753734f9f6d31
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/18/142818/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/virtual-network-performance-monitor.rst'],1,de940261690e3b74155767a0957e25982b96c361,bp/virtual-network-performance-monitor,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Virtual Network Performance Monitor(VNPM) ============================================================ https://blueprints.launchpad.net/neutron/+spec/virtual-network-performance-monitor The tenants and operators need to be aware of the network performance, such as delay, delay jitter and packet loss ratio, but current Neutron APIs do not support such requirements. The blueprint introduces a virtual network performance monitor service extension API and corresponding data model for the tenants to specify their requirements on monitoring virtual network performance. Besides, this blueprint also describes the reference implementation of the extended API. Problem description =================== Currently neutron allows tenants to create virtual network services, but does not provide available API for the tenants to monitor the virtual network for alarming and performance optimization. So, VNPM API is necessary to be provided to monitor network performance indicators (KPIs), including delay, delay jitter, and packet loss. The tenants may obtain these network performance indicators (KPIs) information by running specific tools on VMs now. However, this self-implementation way is complex, special-purpose, error-prone and time consuming. Thus, it is valuable to provide a virtual network performance monitor API to provide that. Proposed change =============== This blueprint proposes 1) a North Bound Neutron API to represent the requirement of monitoring virtual network performance in the logical resources. 2) a reference architecture to implement the proposed API. Specifically, the virtual network performance parameters in this blueprint include: 1. Delay: the delay from one port to another port, the port refers to the virtual port in neutron. 2. Delay jitter: the variation of packet delay from one port to another port. 3. Packet loss: the ratio of lost packets to total transmitted packets from one port to another port. The introduced interface allows the tenants to express their requirements on virtual network performance monitoring, e.g., the source and destination of the port to monitor. The main advantage of the extensions described in this blueprint is that they provide a standard and flexible way for the tenants and operators to monitor virtual network performance, while current Neutron APIs do not support such requirements. The following diagram illustrates the overall workflows. +-------------------------+ | | | | | Neutron Server | +-------+ +-----+ | | | | | | | | | | | | | +-------------------------+ | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | ML2 Plugin | | VNPM Plugin | | | | | | | | | | | | | | | | | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | | | | +-------------------------+ | | | | | Compute Node | | | | | | +----------------------+ | +-----------+ | | | | |----| VNPM Agent | | | | | +----------------+ | | | | | | | | | vProbe | +-------+--------------+ | | | | +------------+ | | +-----------+ VNPM plugin is proposed to provide North Bound REST interface, which supports CRUD operation on VNPM resource. VNPM Agent and vProbe is proposed to implement the function of measuring network performance. Specifically, each compute node deploys VNPM agent and vProbe. The VNPM plugin transforms the Rest APIs into Neutron RPC messages. The RPC messages are sent to the proposed VNPM agents by the RabbitMQ bus. According to the received messages, the VNPM agent manages the vProbe, and the vProbe sends test packets to other vProbe to test the network performance. The vProbe then sends the test result to the VNPM agent, and the VNPM agent further populates the network performance information with the Oslo notification mechanism. The above architecture/method is only for reference implementation. The developers can also use other architecture/methods to implement the proposed interfaces. for supporting this VNPM API, vProbe and VNPM agent are proposed to use. Alternatives ------------ Since new data model and interface is being proposed here, a direct alternate does not exist. If ovs/linuxbridge has the vProbe function, VNPM plugin can directly communicate with ovs/linuxbridge. Data model impact ----------------- Add DB tables: * neutron.VNPMs New DB model introduced: 1.VNPM *vn_performance_monitors - the VNPM resource. Attributes: *id - unique identifier. *name - user readable name of the specified VNPM. *description - description of the VNPM. *tenant-id - the creator and owner of the VNPM. *source_id - the neutron port of the source of the network performance to be measured. *destination_id - the neutron port of the destination of the network performance to be measured. *test_type - once or periodic measurement. *period_time - the time duration of a measurement, only functions when the test type is set to periodic. *response_type - two options: {normal, only alarm}. If the value is set to ""normal"", every measurement results will be reported. If the value is set to ""only alarm"", only the measurement results that exceeds the specified threshold be reported. *reachability - indicates whether to test reachability or not. *delay - indicates whether to test delay or not. *delay_threhold - the threshold of the delay, only functions when delay is tested and the response_type is set to ""only alarm"". *jitter - indicates whether to test delay jitter or not. *jitter_threhold - the threshold of the delay jitter, only functions when delay jitter is tested and the response_type is set to ""only alarm"". *loss - indicates whether to test packet loss ratio or not. *loss_threhold- the threshold of the packet loss ratio, only functions when packet loss is tested and the response_type is set to ""only alarm"". REST API impact --------------- A separate extension will be created that will expose the VNPM resource. The VNPM resource property is presented as follows: RESOURCE_ATTRIBUTE_MAP = { 'vn_performance_monitors': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'description': {'allow_post': True,'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'source_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'destination_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'test_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['once','periodic']}, 'is_visible': True, 'default': 'once'}, 'period_time': {'allow_post': True, 'allow_put': True, 'validate': {'type:float': None}, 'is_visible': True}, 'response_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['normal','only_alarm']}, 'is_visible': True}, 'reachability': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'jitter': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'loss': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'jitter_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'loss_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, } } Security impact --------------- Standard Neutron tenant object ownership rules will apply. Notifications impact -------------------- New notifications will be added to report the virtual network performance. The format of the notification: +--------------+------------+--------------------------------------------------------+ |key |Value |Notes | +--------------+------------+--------------------------------------------------------+ |id |Integer |VNPM ID | +--------------+------------+--------------------------------------------------------+ |test_type |String |The value should be ""once"" or ""periodic"" | +--------------+------------+--------------------------------------------------------+ |period_time |Integer |Time duration for two tests if test_type is set to | | | |""periodic"" | +--------------+------------+--------------------------------------------------------+ |response_type |String |The value should be ""normal"" or ""only alarm"" | +------------------------------------------------------------------------------------+ |notification_ |Integer | | |time | |The time sending this notification | +--------------+------------+--------------------------------------------------------+ |reachability |Bool |True if reachable; False if not reachable | +--------------+------------+--------------------------------------------------------+ |delay(ms) |float |The packets delay from the source neutron port to the | | | |destination neutron port | +--------------+------------+--------------------------------------------------------+ |jitter(ms) |float |The delay jitter | +--------------+------------+--------------------------------------------------------+ |loss |float |packets loss ratio | +--------------+------------+--------------------------------------------------------+ Other end user impact --------------------- None. Performance Impact ------------------ The vProbes need to send test packets and therefore have impact on system performance. However, the administrator can configure how much resource the vProbe can use, including the percentage of CPU cycle, the total throughput, to minimize the impact. Other deployer impact --------------------- If vProbe is to be enabled, it is required to configure the vProbe plugin in neutron.conf. Developer impact ---------------- This API is a new resource extension, and will not affect existing API. Implementation ============== Assignee(s) ----------- Work Items ---------- 1. Implementing Rest API extension *Add a file under neutron/extensions to implement resource extension to and the base class of the plugin to process the API request. *Add a file under neutron/db to implement the data base operation. *Add a directory under neutron/services to implement the plugin. 2. Implementing vProbe *The function of vProbe includes sending test packets to specified IP, calculating the network performance parameter according to the received test packets. Besides, the vProbe should provide interfaces to communicate with VNPM agents. The implementation will be deployed on compute node as a system service. 3. Implementing VNPM agent *The function of VNPM agent includes interaction with the VNPM plugin through RPC, managing vProbes, populate the network performance information with Oslo notification mechanism. The implementation file of VNPM agent will be put under neutron/services/VNPM, and deployed on compute node. Dependencies ============ None Testing ======= Both, functional and, system tests will be added. Documentation Impact ==================== Virtual network performance monitor resource will be added in the documentation. References ========== None",".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Virtual Network Performance Monitor(VNPM) ============================================================ https://blueprints.launchpad.net/neutron/+spec/virtual-network-performance-monitor The tenants and operators need to be aware of the network performance, such as delay, delay jitter and packet loss ratio, but current Neutron APIs do not support such requirements. The blueprint introduces a virtual network performance monitor service extension API and corresponding data model for the tenants to specify their requirements on monitoring virtual network performance. Besides, this blueprint also describes the reference implementation of the extended API. Problem description =================== Currently neutron allows tenants to create virtual network services, but does not provide available API for the tenants to monitor the virtual network for alarming and performance optimization. So, VNPM API is necessary to be provided to monitor network performance indicators (KPIs), including delay, delay jitter, and packet loss. The tenants may obtain these network performance indicators (KPIs) information by running specific tools on VMs now. However, this self-implementation way is complex, special-purpose, error-prone and time consuming. Thus, it is valuable to provide a virtual network performance monitor API to provide that. Proposed change =============== This blueprint proposes 1) a North Bound Neutron API to represent the requirement of monitoring virtual network performance in the logical resources. 2) a reference architecture to implement the proposed API. Specifically, the virtual network performance parameters in this blueprint include: 1. Delay: the delay from one port to another port, the port refers to the virtual port in neutron. 2. Delay jitter: the variation of packet delay from one port to another port. 3. Packet loss: the ratio of lost packets to total transmitted packets from one port to another port. The introduced interface allows the tenants to express their requirements on virtual network performance monitoring, e.g., the source and destination of the port to monitor. The main advantage of the extensions described in this blueprint is that they provide a standard and flexible way for the tenants and operators to monitor virtual network performance, while current Neutron APIs do not support such requirements. The following diagram illustrates the overall workflows. +-------------------------+ | | | | | Neutron Server | +-------+ +-----+ | | | | | | | | | | | | | +-------------------------+ | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | ML2 Plugin | | VNPM Plugin | | | | | | | | | | | | | | | | | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | | | | +-------------------------+ | | | | | Compute Node | | | | | | +----------------------+ | +-----------+ | | | | |----| VNPM Agent | | | | | +----------------+ | | | | | | | | | vProbe | +-------+--------------+ | | | | +------------+ | | +-----------+ VNPM plugin is proposed to provide North Bound REST interface, which supports CRUD operation on VNPM resource. VNPM Agent and vProbe is proposed to implement the function of measuring network performance. Specifically, each compute node deploys VNPM agent and vProbe. The VNPM plugin transforms the Rest APIs into Neutron RPC messages. The RPC messages are sent to the proposed VNPM agents by the RabbitMQ bus. According to the received messages, the VNPM agent manages the vProbe, and the vProbe sends test packets to other vProbe to test the network performance. The vProbe then sends the test result to the VNPM agent, and the VNPM agent further populates the network performance information with the Oslo notification mechanism. The above architecture/method is only for reference implementation. The developers can also use other architecture/methods to implement the proposed interfaces. for supporting this VNPM API, vProbe and VNPM agent are proposed to use. Alternatives ------------ Since new data model and interface is being proposed here, a direct alternate does not exist. If ovs/linuxbridge has the vProbe function, VNPM plugin can directly communicate with ovs/linuxbridge. Data model impact ----------------- Add DB tables: * neutron.VNPMs New DB model introduced: 1.VNPM *vn_performance_monitors - the VNPM resource. Attributes: *id - unique identifier. *name - user readable name of the specified VNPM. *description - description of the VNPM. *tenant-id - the creator and owner of the VNPM. *source_id - the neutron port of the source of the network performance to be measured. *destination_id - the neutron port of the destination of the network performance to be measured. *test_type - once or periodic measurement. *period_time - the time duration of a measurement, only functions when the test type is set to periodic. *response_type - two options: {normal, only alarm}. If the value is set to ""normal"", every measurement results will be reported. If the value is set to ""only alarm"", only the measurement results that exceeds the specified threshold be reported. *reachability - indicates whether to test reachability or not. *delay - indicates whether to test delay or not. *delay_threhold - the threshold of the delay, only functions when delay is tested and the response_type is set to ""only alarm"". *jitter - indicates whether to test delay jitter or not. *jitter_threhold - the threshold of the delay jitter, only functions when delay jitter is tested and the response_type is set to ""only alarm"". *loss - indicates whether to test packet loss ratio or not. *loss_threhold- the threshold of the packet loss ratio, only functions when packet loss is tested and the response_type is set to ""only alarm"". REST API impact --------------- A separate extension will be created that will expose the VNPM resource. The VNPM resource property is presented as follows: RESOURCE_ATTRIBUTE_MAP = { 'vn_performance_monitors': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'description': {'allow_post': True,'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'source_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'destination_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'test_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['once','periodic']}, 'is_visible': True, 'default': 'once'}, 'period_time': {'allow_post': True, 'allow_put': True, 'validate': {'type:float': None}, 'is_visible': True}, 'response_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['normal','only_alarm']}, 'is_visible': True}, 'reachability': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'jitter': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'loss': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'jitter_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'loss_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, } } Security impact --------------- Standard Neutron tenant object ownership rules will apply. Notifications impact -------------------- New notifications will be added to report the virtual network performance. The format of the notification: +--------------+------------+--------------------------------------------------------+ |key |Value |Notes | +--------------+------------+--------------------------------------------------------+ |id |Integer |VNPM ID | +--------------+------------+--------------------------------------------------------+ |test_type |String |The value should be ""once"" or ""periodic"" | +--------------+------------+--------------------------------------------------------+ |period_time |Integer |Time duration for two tests if test_type is set to | | | |""periodic"" | +--------------+------------+--------------------------------------------------------+ |response_type |String |The value should be ""normal"" or ""only alarm"" | +------------------------------------------------------------------------------------+ |notification_ |Integer | | |time | |The time sending this notification | +--------------+------------+--------------------------------------------------------+ |reachability |Bool |True if reachable; False if not reachable | +--------------+------------+--------------------------------------------------------+ |delay(ms) |float |The packets delay from the source neutron port to the | | | |destination neutron port | +--------------+------------+--------------------------------------------------------+ |jitter(ms) |float |The delay jitter | +--------------+------------+--------------------------------------------------------+ |loss |float |packets loss ratio | +--------------+------------+--------------------------------------------------------+ Other end user impact --------------------- None. Performance Impact ------------------ The vProbes need to send test packets and therefore have impact on system performance. However, the administrator can configure how much resource the vProbe can use, including the percentage of CPU cycle, the total throughput, to minimize the impact. Other deployer impact --------------------- If vProbe is to be enabled, it is required to configure the vProbe plugin in neutron.conf. Developer impact ---------------- This API is a new resource extension, and will not affect existing API. Implementation ============== Assignee(s) ----------- Work Items ---------- 1. Implementing Rest API extension *Add a file under neutron/extensions to implement resource extension to and the base class of the plugin to process the API request. *Add a file under neutron/db to implement the data base operation. *Add a directory under neutron/services to implement the plugin. 2. Implementing vProbe *The function of vProbe includes sending test packets to specified IP, calculating the network performance parameter according to the received test packets. Besides, the vProbe should provide interfaces to communicate with VNPM agents. The implementation will be deployed on compute node as a system service. 3. Implementing VNPM agent *The function of VNPM agent includes interaction with the VNPM plugin through RPC, managing vProbes, populate the network performance information with Oslo notification mechanism. The implementation file of VNPM agent will be put under neutron/services/VNPM, and deployed on compute node. Dependencies ============ None Testing ======= Both, functional and, system tests will be added. Documentation Impact ==================== Virtual network performance monitor resource will be added in the documentation. References ========== None ",346,345
openstack%2Fneutron-specs~master~I5c4d17be0f8da6fbbc45cb0cb7f3504a77175147,openstack/neutron-specs,master,I5c4d17be0f8da6fbbc45cb0cb7f3504a77175147,Last updated is not effectual.Update again.,ABANDONED,2014-12-18 15:03:02.000000000,2014-12-19 02:25:23.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-18 15:03:02.000000000', 'files': ['specs/kilo/virtual-network-performance-monitor.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d3a8f55c1e9318e75154810d1c6f9770aafd1419', 'message': 'Last updated is not effectual.Update again.\n\nChange-Id: I5c4d17be0f8da6fbbc45cb0cb7f3504a77175147\n'}]",0,142810,d3a8f55c1e9318e75154810d1c6f9770aafd1419,3,1,1,13000,,,0,"Last updated is not effectual.Update again.

Change-Id: I5c4d17be0f8da6fbbc45cb0cb7f3504a77175147
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/10/142810/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/virtual-network-performance-monitor.rst'],1,d3a8f55c1e9318e75154810d1c6f9770aafd1419,bp/virtual-network-performance-monitor,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Virtual Network Performance Monitor(VNPM) ============================================================ https://blueprints.launchpad.net/neutron/+spec/virtual-network-performance-monitor The tenants and operators need to be aware of the network performance, such as delay, delay jitter and packet loss ratio, but current Neutron APIs do not support such requirements. The blueprint introduces a virtual network performance monitor service extension API and corresponding data model for the tenants to specify their requirements on monitoring virtual network performance. Besides, this blueprint also describes the reference implementation of the extended API. Problem description =================== Currently neutron allows tenants to create virtual network services, but does not provide available API for the tenants to monitor the virtual network for alarming and performance optimization. So, VNPM API is necessary to be provided to monitor network performance indicators (KPIs), including delay, delay jitter, and packet loss. The tenants may obtain these network performance indicators (KPIs) information by running specific tools on VMs now. However, this self-implementation way is complex, special-purpose, error-prone and time consuming. Thus, it is valuable to provide a virtual network performance monitor API to provide that. Proposed change =============== This blueprint proposes 1) a North Bound Neutron API to represent the requirement of monitoring virtual network performance in the logical resources. 2) a reference architecture to implement the proposed API. Specifically, the virtual network performance parameters in this blueprint include: 1. Delay: the delay from one port to another port, the port refers to the virtual port in neutron. 2. Delay jitter: the variation of packet delay from one port to another port. 3. Packet loss: the ratio of lost packets to total transmitted packets from one port to another port. The introduced interface allows the tenants to express their requirements on virtual network performance monitoring, e.g., the source and destination of the port to monitor. The main advantage of the extensions described in this blueprint is that they provide a standard and flexible way for the tenants and operators to monitor virtual network performance, while current Neutron APIs do not support such requirements. The following diagram illustrates the overall workflows. +-------------------------+ | | | | | Neutron Server | +-------+ +-----+ | | | | | | | | | | | | | +-------------------------+ | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | ML2 Plugin | | VNPM Plugin | | | | | | | | | | | | | | | | | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | | | | +-------------------------+ | | | | | Compute Node | | | | | | +----------------------+ | +-----------+ | | | | |----| VNPM Agent | | | | | +----------------+ | | | | | | | | | vProbe | +-------+--------------+ | | | | +------------+ | | +-----------+ VNPM plugin is proposed to provide North Bound REST interface, which supports CRUD operation on VNPM resource. VNPM Agent and vProbe is proposed to implement the function of measuring network performance. Specifically, each compute node deploys VNPM agent and vProbe. The VNPM plugin transforms the Rest APIs into Neutron RPC messages. The RPC messages are sent to the proposed VNPM agents by the RabbitMQ bus. According to the received messages, the VNPM agent manages the vProbe, and the vProbe sends test packets to other vProbe to test the network performance. The vProbe then sends the test result to the VNPM agent, and the VNPM agent further populates the network performance information with the Oslo notification mechanism. The above architecture/method is only for reference implementation. The developers can also use other architecture/methods to implement the proposed interfaces. for supporting this VNPM API, vProbe and VNPM agent are proposed to use. Alternatives ------------ Since new data model and interface is being proposed here, a direct alternate does not exist. If ovs/linuxbridge has the vProbe function, VNPM plugin can directly communicate with ovs/linuxbridge. Data model impact ----------------- Add DB tables: * neutron.VNPMs New DB model introduced: 1.VNPM *vn_performance_monitors - the VNPM resource. Attributes: *id - unique identifier. *name - user readable name of the specified VNPM. *description - description of the VNPM. *tenant-id - the creator and owner of the VNPM. *source_id - the neutron port of the source of the network performance to be measured. *destination_id - the neutron port of the destination of the network performance to be measured. *test_type - once or periodic measurement. *period_time - the time duration of a measurement, only functions when the test type is set to periodic. *response_type - two options: {normal, only alarm}. If the value is set to ""normal"", every measurement results will be reported. If the value is set to ""only alarm"", only the measurement results that exceeds the specified threshold be reported. *reachability - indicates whether to test reachability or not. *delay - indicates whether to test delay or not. *delay_threhold - the threshold of the delay, only functions when delay is tested and the response_type is set to ""only alarm"". *jitter - indicates whether to test delay jitter or not. *jitter_threhold - the threshold of the delay jitter, only functions when delay jitter is tested and the response_type is set to ""only alarm"". *loss - indicates whether to test packet loss ratio or not. *loss_threhold- the threshold of the packet loss ratio, only functions when packet loss is tested and the response_type is set to ""only alarm"". REST API impact --------------- A separate extension will be created that will expose the VNPM resource. The VNPM resource property is presented as follows: RESOURCE_ATTRIBUTE_MAP = { 'vn_performance_monitors': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'description': {'allow_post': True,'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'source_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'destination_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'test_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['once','periodic']}, 'is_visible': True, 'default': 'once'}, 'period_time': {'allow_post': True, 'allow_put': True, 'validate': {'type:float': None}, 'is_visible': True}, 'response_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['normal','only_alarm']}, 'is_visible': True}, 'reachability': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'jitter': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'loss': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'jitter_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'loss_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, } } Security impact --------------- Standard Neutron tenant object ownership rules will apply. Notifications impact -------------------- New notifications will be added to report the virtual network performance. The format of the notification: +--------------+------------+--------------------------------------------------------+ |key |Value |Notes | +--------------+------------+--------------------------------------------------------+ |id |Integer |VNPM ID | +--------------+------------+--------------------------------------------------------+ |test_type |String |The value should be ""once"" or ""periodic"" | +--------------+------------+--------------------------------------------------------+ |period_time |Integer |Time duration for two tests if test_type is set to | | | |""periodic"" | +--------------+------------+--------------------------------------------------------+ |response_type |String |The value should be ""normal"" or ""only alarm"" | +------------------------------------------------------------------------------------+ |notification_ |Integer | | |time | |The time sending this notification | +--------------+------------+--------------------------------------------------------+ |reachability |Bool |True if reachable; False if not reachable | +--------------+------------+--------------------------------------------------------+ |delay(ms) |float |The packets delay from the source neutron port to the | | | |destination neutron port | +--------------+------------+--------------------------------------------------------+ |jitter(ms) |float |The delay jitter | +--------------+------------+--------------------------------------------------------+ |loss |float |packets loss ratio | +--------------+------------+--------------------------------------------------------+ Other end user impact --------------------- None. Performance Impact ------------------ The vProbes need to send test packets and therefore have impact on system performance. However, the administrator can configure how much resource the vProbe can use, including the percentage of CPU cycle, the total throughput, to minimize the impact. Other deployer impact --------------------- If vProbe is to be enabled, it is required to configure the vProbe plugin in neutron.conf. Developer impact ---------------- This API is a new resource extension, and will not affect existing API. Implementation ============== Assignee(s) ----------- Work Items ---------- 1. Implementing Rest API extension *Add a file under neutron/extensions to implement resource extension to and the base class of the plugin to process the API request. *Add a file under neutron/db to implement the data base operation. *Add a directory under neutron/services to implement the plugin. 2. Implementing vProbe *The function of vProbe includes sending test packets to specified IP, calculating the network performance parameter according to the received test packets. Besides, the vProbe should provide interfaces to communicate with VNPM agents. The implementation will be deployed on compute node as a system service. 3. Implementing VNPM agent *The function of VNPM agent includes interaction with the VNPM plugin through RPC, managing vProbes, populate the network performance information with Oslo notification mechanism. The implementation file of VNPM agent will be put under neutron/services/VNPM, and deployed on compute node. Dependencies ============ None Testing ======= Both, functional and, system tests will be added. Documentation Impact ==================== Virtual network performance monitor resource will be added in the documentation. References ========== None",".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Virtual Network Performance Monitor(VNPM) ============================================================ https://blueprints.launchpad.net/neutron/+spec/virtual-network-performance-monitor The tenants and operators need to be aware of the network performance, such as delay, delay jitter and packet loss ratio, but current Neutron APIs do not support such requirements. The blueprint introduces a virtual network performance monitor service extension API and corresponding data model for the tenants to specify their requirements on monitoring virtual network performance. Besides, this blueprint also describes the reference implementation of the extended API. Problem description =================== Currently neutron allows tenants to create virtual network services, but does not provide available API for the tenants to monitor the virtual network for alarming and performance optimization. So, VNPM API is necessary to be provided to monitor network performance indicators (KPIs), including delay, delay jitter, and packet loss. The tenants may obtain these network performance indicators (KPIs) information by running specific tools on VMs now. However, this self-implementation way is complex, special-purpose, error-prone and time consuming. Thus, it is valuable to provide a virtual network performance monitor API to provide that. Proposed change =============== This blueprint proposes 1) a North Bound Neutron API to represent the requirement of monitoring virtual network performance in the logical resources. 2) a reference architecture to implement the proposed API. Specifically, the virtual network performance parameters in this blueprint include: 1. Delay: the delay from one port to another port, the port refers to the virtual port in neutron. 2. Delay jitter: the variation of packet delay from one port to another port. 3. Packet loss: the ratio of lost packets to total transmitted packets from one port to another port. The introduced interface allows the tenants to express their requirements on virtual network performance monitoring, e.g., the source and destination of the port to monitor. The main advantage of the extensions described in this blueprint is that they provide a standard and flexible way for the tenants and operators to monitor virtual network performance, while current Neutron APIs do not support such requirements. The following diagram illustrates the overall workflows. +-------------------------+ | | | | | Neutron Server | +-------+ +-----+ | | | | | | | | | | | | | +-------------------------+ | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | ML2 Plugin | | VNPM Plugin | | | | | | | | | | | | | | | | | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | | | | +-------------------------+ | | | | | Compute Node | | | | | | +----------------------+ | +-----------+ | | | | |----| VNPM Agent | | | | | +----------------+ | | | | | | | | | vProbe | +-------+--------------+ | | | | +------------+ | | +-----------+ VNPM plugin is proposed to provide North Bound REST interface, which supports CRUD operation on VNPM resource. VNPM Agent and vProbe is proposed to implement the function of measuring network performance. Specifically, each compute node deploys VNPM agent and vProbe. The VNPM plugin transforms the Rest APIs into Neutron RPC messages. The RPC messages are sent to the proposed VNPM agents by the RabbitMQ bus. According to the received messages, the VNPM agent manages the vProbe, and the vProbe sends test packets to other vProbe to test the network performance. The vProbe then sends the test result to the VNPM agent, and the VNPM agent further populates the network performance information with the Oslo notification mechanism. The above architecture/method is only for reference implementation. The developers can also use other architecture/methods to implement the proposed interfaces. for supporting this VNPM API, vProbe and VNPM agent are proposed to use. Alternatives ------------ Since new data model and interface is being proposed here, a direct alternate does not exist. If ovs/linuxbridge has the vProbe function, VNPM plugin can directly communicate with ovs/linuxbridge. Data model impact ----------------- Add DB tables: * neutron.VNPMs New DB model introduced: 1.VNPM *vn_performance_monitors - the VNPM resource. Attributes: *id - unique identifier. *name - user readable name of the specified VNPM. *description - description of the VNPM. *tenant-id - the creator and owner of the VNPM. *source_id - the neutron port of the source of the network performance to be measured. *destination_id - the neutron port of the destination of the network performance to be measured. *test_type - once or periodic measurement. *period_time - the time duration of a measurement, only functions when the test type is set to periodic. *response_type - two options: {normal, only alarm}. If the value is set to ""normal"", every measurement results will be reported. If the value is set to ""only alarm"", only the measurement results that exceeds the specified threshold be reported. *reachability - indicates whether to test reachability or not. *delay - indicates whether to test delay or not. *delay_threhold - the threshold of the delay, only functions when delay is tested and the response_type is set to ""only alarm"". *jitter - indicates whether to test delay jitter or not. *jitter_threhold - the threshold of the delay jitter, only functions when delay jitter is tested and the response_type is set to ""only alarm"". *loss - indicates whether to test packet loss ratio or not. *loss_threhold- the threshold of the packet loss ratio, only functions when packet loss is tested and the response_type is set to ""only alarm"". REST API impact --------------- A separate extension will be created that will expose the VNPM resource. The VNPM resource property is presented as follows: RESOURCE_ATTRIBUTE_MAP = { 'vn_performance_monitors': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'description': {'allow_post': True,'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'source_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'destination_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'test_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['once','periodic']}, 'is_visible': True, 'default': 'once'}, 'period_time': {'allow_post': True, 'allow_put': True, 'validate': {'type:float': None}, 'is_visible': True}, 'response_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['normal','only_alarm']}, 'is_visible': True}, 'reachability': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'jitter': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'loss': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'jitter_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'loss_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, } } Security impact --------------- Standard Neutron tenant object ownership rules will apply. Notifications impact -------------------- New notifications will be added to report the virtual network performance. The format of the notification: +--------------+------------+--------------------------------------------------------+ |key |Value |Notes | +--------------+------------+--------------------------------------------------------+ |id |Integer |VNPM ID | +--------------+------------+--------------------------------------------------------+ |test_type |String |The value should be ""once"" or ""periodic"" | +--------------+------------+--------------------------------------------------------+ |period_time |Integer |Time duration for two tests if test_type is set to | | | |""periodic"" | +--------------+------------+--------------------------------------------------------+ |response_type |String |The value should be ""normal"" or ""only alarm"" | +------------------------------------------------------------------------------------+ |notification_ |Integer | | |time | |The time sending this notification | +--------------+------------+--------------------------------------------------------+ |reachability |Bool |True if reachable; False if not reachable | +--------------+------------+--------------------------------------------------------+ |delay(ms) |float |The packets delay from the source neutron port to the | | | |destination neutron port | +--------------+------------+--------------------------------------------------------+ |jitter(ms) |float |The delay jitter | +--------------+------------+--------------------------------------------------------+ |loss |float |packets loss ratio | +--------------+------------+--------------------------------------------------------+ Other end user impact --------------------- None. Performance Impact ------------------ The vProbes need to send test packets and therefore have impact on system performance. However, the administrator can configure how much resource the vProbe can use, including the percentage of CPU cycle, the total throughput, to minimize the impact. Other deployer impact --------------------- If vProbe is to be enabled, it is required to configure the vProbe plugin in neutron.conf. Developer impact ---------------- This API is a new resource extension, and will not affect existing API. Implementation ============== Assignee(s) ----------- Work Items ---------- 1. Implementing Rest API extension *Add a file under neutron/extensions to implement resource extension to and the base class of the plugin to process the API request. *Add a file under neutron/db to implement the data base operation. *Add a directory under neutron/services to implement the plugin. 2. Implementing vProbe *The function of vProbe includes sending test packets to specified IP, calculating the network performance parameter according to the received test packets. Besides, the vProbe should provide interfaces to communicate with VNPM agents. The implementation will be deployed on compute node as a system service. 3. Implementing VNPM agent *The function of VNPM agent includes interaction with the VNPM plugin through RPC, managing vProbes, populate the network performance information with Oslo notification mechanism. The implementation file of VNPM agent will be put under neutron/services/VNPM, and deployed on compute node. Dependencies ============ None Testing ======= Both, functional and, system tests will be added. Documentation Impact ==================== Virtual network performance monitor resource will be added in the documentation. References ========== None ",346,345
openstack%2Fneutron-specs~master~Ibef922949629d75432c9645097087ba39a69e228,openstack/neutron-specs,master,Ibef922949629d75432c9645097087ba39a69e228,Update the bp for remove the trailing spaces and carriage return.,ABANDONED,2014-12-18 14:38:42.000000000,2014-12-19 02:25:04.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-18 14:38:42.000000000', 'files': ['specs/kilo/virtual-network-performance-monitor.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/785551ae6d7b75894a08db6004fe5ccb952ceeb4', 'message': 'Update the bp for remove the trailing spaces and carriage return.\n\nChange-Id: Ibef922949629d75432c9645097087ba39a69e228\n'}]",0,142801,785551ae6d7b75894a08db6004fe5ccb952ceeb4,3,1,1,13000,,,0,"Update the bp for remove the trailing spaces and carriage return.

Change-Id: Ibef922949629d75432c9645097087ba39a69e228
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/01/142801/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/virtual-network-performance-monitor.rst'],1,785551ae6d7b75894a08db6004fe5ccb952ceeb4,bp/virtual-network-performance-monitor,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Virtual Network Performance Monitor(VNPM) ============================================================ https://blueprints.launchpad.net/neutron/+spec/virtual-network-performance-monitor The tenants and operators need to be aware of the network performance, such as delay, delay jitter and packet loss ratio, but current Neutron APIs do not support such requirements. The blueprint introduces a virtual network performance monitor service extension API and corresponding data model for the tenants to specify their requirements on monitoring virtual network performance. Besides, this blueprint also describes the reference implementation of the extended API. Problem description =================== Currently neutron allows tenants to create virtual network services, but does not provide available API for the tenants to monitor the virtual network for alarming and performance optimization. So, VNPM API is necessary to be provided to monitor network performance indicators (KPIs), including delay, delay jitter, and packet loss. The tenants may obtain these network performance indicators (KPIs) information by running specific tools on VMs now. However, this self-implementation way is complex, special-purpose, error-prone and time consuming. Thus, it is valuable to provide a virtual network performance monitor API to provide that. Proposed change =============== This blueprint proposes 1) a North Bound Neutron API to represent the requirement of monitoring virtual network performance in the logical resources. 2) a reference architecture to implement the proposed API. Specifically, the virtual network performance parameters in this blueprint include: 1. Delay: the delay from one port to another port, the port refers to the virtual port in neutron. 2. Delay jitter: the variation of packet delay from one port to another port. 3. Packet loss: the ratio of lost packets to total transmitted packets from one port to another port. The introduced interface allows the tenants to express their requirements on virtual network performance monitoring, e.g., the source and destination of the port to monitor. The main advantage of the extensions described in this blueprint is that they provide a standard and flexible way for the tenants and operators to monitor virtual network performance, while current Neutron APIs do not support such requirements. The following diagram illustrates the overall workflows. +-------------------------+ | | | | | Neutron Server | +-------+ +-----+ | | | | | | | | | | | | | +-------------------------+ | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | ML2 Plugin | | VNPM Plugin | | | | | | | | | | | | | | | | | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | | | | +-------------------------+ | | | | | Compute Node | | | | | | +----------------------+ | +-----------+ | | | | |----| VNPM Agent | | | | | +----------------+ | | | | | | | | | vProbe | +-------+--------------+ | | | | +------------+ | | +-----------+ VNPM plugin is proposed to provide North Bound REST interface, which supports CRUD operation on VNPM resource. VNPM Agent and vProbe is proposed to implement the function of measuring network performance. Specifically, each compute node deploys VNPM agent and vProbe. The VNPM plugin transforms the Rest APIs into Neutron RPC messages. The RPC messages are sent to the proposed VNPM agents by the RabbitMQ bus. According to the received messages, the VNPM agent manages the vProbe, and the vProbe sends test packets to other vProbe to test the network performance. The vProbe then sends the test result to the VNPM agent, and the VNPM agent further populates the network performance information with the Oslo notification mechanism. The above architecture/method is only for reference implementation. The developers can also use other architecture/methods to implement the proposed interfaces. for supporting this VNPM API, vProbe and VNPM agent are proposed to use. Alternatives ------------ Since new data model and interface is being proposed here, a direct alternate does not exist. If ovs/linuxbridge has the vProbe function, VNPM plugin can directly communicate with ovs/linuxbridge. Data model impact ----------------- Add DB tables: * neutron.VNPMs New DB model introduced: 1.VNPM *vn_performance_monitors - the VNPM resource. Attributes: *id - unique identifier. *name - user readable name of the specified VNPM. *description - description of the VNPM. *tenant-id - the creator and owner of the VNPM. *source_id - the neutron port of the source of the network performance to be measured. *destination_id - the neutron port of the destination of the network performance to be measured. *test_type - once or periodic measurement. *period_time - the time duration of a measurement, only functions when the test type is set to periodic. *response_type - two options: {normal, only alarm}. If the value is set to ""normal"", every measurement results will be reported. If the value is set to ""only alarm"", only the measurement results that exceeds the specified threshold be reported. *reachability - indicates whether to test reachability or not. *delay - indicates whether to test delay or not. *delay_threhold - the threshold of the delay, only functions when delay is tested and the response_type is set to ""only alarm"". *jitter - indicates whether to test delay jitter or not. *jitter_threhold - the threshold of the delay jitter, only functions when delay jitter is tested and the response_type is set to ""only alarm"". *loss - indicates whether to test packet loss ratio or not. *loss_threhold- the threshold of the packet loss ratio, only functions when packet loss is tested and the response_type is set to ""only alarm"". REST API impact --------------- A separate extension will be created that will expose the VNPM resource. The VNPM resource property is presented as follows: RESOURCE_ATTRIBUTE_MAP = { 'vn_performance_monitors': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'description': {'allow_post': True,'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'source_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'destination_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'test_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['once','periodic']}, 'is_visible': True, 'default': 'once'}, 'period_time': {'allow_post': True, 'allow_put': True, 'validate': {'type:float': None}, 'is_visible': True}, 'response_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['normal','only_alarm']}, 'is_visible': True}, 'reachability': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'jitter': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'loss': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'jitter_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'loss_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, } } Security impact --------------- Standard Neutron tenant object ownership rules will apply. Notifications impact -------------------- New notifications will be added to report the virtual network performance. The format of the notification: +--------------+------------+--------------------------------------------------------+ |key |Value |Notes | +--------------+------------+--------------------------------------------------------+ |id |Integer |VNPM ID | +--------------+------------+--------------------------------------------------------+ |test_type |String |The value should be ""once"" or ""periodic"" | +--------------+------------+--------------------------------------------------------+ |period_time |Integer |Time duration for two tests if test_type is set to | | | |""periodic"" | +--------------+------------+--------------------------------------------------------+ |response_type |String |The value should be ""normal"" or ""only alarm"" | +------------------------------------------------------------------------------------+ |notification_ |Integer | | |time | |The time sending this notification | +--------------+------------+--------------------------------------------------------+ |reachability |Bool |True if reachable; False if not reachable | +--------------+------------+--------------------------------------------------------+ |delay(ms) |float |The packets delay from the source neutron port to the | | | |destination neutron port | +--------------+------------+--------------------------------------------------------+ |jitter(ms) |float |The delay jitter | +--------------+------------+--------------------------------------------------------+ |loss |float |packets loss ratio | +--------------+------------+--------------------------------------------------------+ Other end user impact --------------------- None. Performance Impact ------------------ The vProbes need to send test packets and therefore have impact on system performance. However, the administrator can configure how much resource the vProbe can use, including the percentage of CPU cycle, the total throughput, to minimize the impact. Other deployer impact --------------------- If vProbe is to be enabled, it is required to configure the vProbe plugin in neutron.conf. Developer impact ---------------- This API is a new resource extension, and will not affect existing API. Implementation ============== Assignee(s) ----------- Work Items ---------- 1. Implementing Rest API extension *Add a file under neutron/extensions to implement resource extension to and the base class of the plugin to process the API request. *Add a file under neutron/db to implement the data base operation. *Add a directory under neutron/services to implement the plugin. 2. Implementing vProbe *The function of vProbe includes sending test packets to specified IP, calculating the network performance parameter according to the received test packets. Besides, the vProbe should provide interfaces to communicate with VNPM agents. The implementation will be deployed on compute node as a system service. 3. Implementing VNPM agent *The function of VNPM agent includes interaction with the VNPM plugin through RPC, managing vProbes, populate the network performance information with Oslo notification mechanism. The implementation file of VNPM agent will be put under neutron/services/VNPM, and deployed on compute node. Dependencies ============ None Testing ======= Both, functional and, system tests will be added. Documentation Impact ==================== Virtual network performance monitor resource will be added in the documentation. References ========== None",".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Virtual Network Performance Monitor(VNPM) ============================================================ https://blueprints.launchpad.net/neutron/+spec/virtual-network-performance-monitor The tenants and operators need to be aware of the network performance, such as delay, delay jitter and packet loss ratio, but current Neutron APIs do not support such requirements. The blueprint introduces a virtual network performance monitor service extension API and corresponding data model for the tenants to specify their requirements on monitoring virtual network performance. Besides, this blueprint also describes the reference implementation of the extended API. Problem description =================== Currently neutron allows tenants to create virtual network services, but does not provide available API for the tenants to monitor the virtual network for alarming and performance optimization. So, VNPM API is necessary to be provided to monitor network performance indicators (KPIs), including delay, delay jitter, and packet loss. The tenants may obtain these network performance indicators (KPIs) information by running specific tools on VMs now. However, this self-implementation way is complex, special-purpose, error-prone and time consuming. Thus, it is valuable to provide a virtual network performance monitor API to provide that. Proposed change =============== This blueprint proposes 1) a North Bound Neutron API to represent the requirement of monitoring virtual network performance in the logical resources. 2) a reference architecture to implement the proposed API. Specifically, the virtual network performance parameters in this blueprint include: 1. Delay: the delay from one port to another port, the port refers to the virtual port in neutron. 2. Delay jitter: the variation of packet delay from one port to another port. 3. Packet loss: the ratio of lost packets to total transmitted packets from one port to another port. The introduced interface allows the tenants to express their requirements on virtual network performance monitoring, e.g., the source and destination of the port to monitor. The main advantage of the extensions described in this blueprint is that they provide a standard and flexible way for the tenants and operators to monitor virtual network performance, while current Neutron APIs do not support such requirements. The following diagram illustrates the overall workflows. +-------------------------+ | | | | | Neutron Server | +-------+ +-----+ | | | | | | | | | | | | | +-------------------------+ | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | ML2 Plugin | | VNPM Plugin | | | | | | | | | | | | | | | | | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | | | | +-------------------------+ | | | | | Compute Node | | | | | | +----------------------+ | +-----------+ | | | | |----| VNPM Agent | | | | | +----------------+ | | | | | | | | | vProbe | +-------+--------------+ | | | | +------------+ | | +-----------+ VNPM plugin is proposed to provide North Bound REST interface, which supports CRUD operation on VNPM resource. VNPM Agent and vProbe is proposed to implement the function of measuring network performance. Specifically, each compute node deploys VNPM agent and vProbe. The VNPM plugin transforms the Rest APIs into Neutron RPC messages. The RPC messages are sent to the proposed VNPM agents by the RabbitMQ bus. According to the received messages, the VNPM agent manages the vProbe, and the vProbe sends test packets to other vProbe to test the network performance. The vProbe then sends the test result to the VNPM agent, and the VNPM agent further populates the network performance information with the Oslo notification mechanism. The above architecture/method is only for reference implementation. The developers can also use other architecture/methods to implement the proposed interfaces. for supporting this VNPM API, vProbe and VNPM agent are proposed to use. Alternatives ------------ Since new data model and interface is being proposed here, a direct alternate does not exist. If ovs/linuxbridge has the vProbe function, VNPM plugin can directly communicate with ovs/linuxbridge. Data model impact ----------------- Add DB tables: * neutron.VNPMs New DB model introduced: 1.VNPM *vn_performance_monitors - the VNPM resource. Attributes: *id - unique identifier. *name - user readable name of the specified VNPM. *description - description of the VNPM. *tenant-id - the creator and owner of the VNPM. *source_id - the neutron port of the source of the network performance to be measured. *destination_id - the neutron port of the destination of the network performance to be measured. *test_type - once or periodic measurement. *period_time - the time duration of a measurement, only functions when the test type is set to periodic. *response_type - two options: {normal, only alarm}. If the value is set to ""normal"", every measurement results will be reported. If the value is set to ""only alarm"", only the measurement results that exceeds the specified threshold be reported. *reachability - indicates whether to test reachability or not. *delay - indicates whether to test delay or not. *delay_threhold - the threshold of the delay, only functions when delay is tested and the response_type is set to ""only alarm"". *jitter - indicates whether to test delay jitter or not. *jitter_threhold - the threshold of the delay jitter, only functions when delay jitter is tested and the response_type is set to ""only alarm"". *loss - indicates whether to test packet loss ratio or not. *loss_threhold- the threshold of the packet loss ratio, only functions when packet loss is tested and the response_type is set to ""only alarm"". REST API impact --------------- A separate extension will be created that will expose the VNPM resource. The VNPM resource property is presented as follows: RESOURCE_ATTRIBUTE_MAP = { 'vn_performance_monitors': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'description': {'allow_post': True,'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'source_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'destination_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'test_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['once','periodic']}, 'is_visible': True, 'default': 'once'}, 'period_time': {'allow_post': True, 'allow_put': True, 'validate': {'type:float': None}, 'is_visible': True}, 'response_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['normal','only_alarm']}, 'is_visible': True}, 'reachability': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'jitter': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'loss': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'jitter_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'loss_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, } } Security impact --------------- Standard Neutron tenant object ownership rules will apply. Notifications impact -------------------- New notifications will be added to report the virtual network performance. The format of the notification: +--------------+------------+--------------------------------------------------------+ |key |Value |Notes | +--------------+------------+--------------------------------------------------------+ |id |Integer |VNPM ID | +--------------+------------+--------------------------------------------------------+ |test_type |String |The value should be ""once"" or ""periodic"" | +--------------+------------+--------------------------------------------------------+ |period_time |Integer |Time duration for two tests if test_type is set to | | | |""periodic"" | +--------------+------------+--------------------------------------------------------+ |response_type |String |The value should be ""normal"" or ""only alarm"" | +------------------------------------------------------------------------------------+ |notification_ |Integer | | |time | |The time sending this notification | +--------------+------------+--------------------------------------------------------+ |reachability |Bool |True if reachable; False if not reachable | +--------------+------------+--------------------------------------------------------+ |delay(ms) |float |The packets delay from the source neutron port to the | | | |destination neutron port | +--------------+------------+--------------------------------------------------------+ |jitter(ms) |float |The delay jitter | +--------------+------------+--------------------------------------------------------+ |loss |float |packets loss ratio | +--------------+------------+--------------------------------------------------------+ Other end user impact --------------------- None. Performance Impact ------------------ The vProbes need to send test packets and therefore have impact on system performance. However, the administrator can configure how much resource the vProbe can use, including the percentage of CPU cycle, the total throughput, to minimize the impact. Other deployer impact --------------------- If vProbe is to be enabled, it is required to configure the vProbe plugin in neutron.conf. Developer impact ---------------- This API is a new resource extension, and will not affect existing API. Implementation ============== Assignee(s) ----------- Work Items ---------- 1. Implementing Rest API extension *Add a file under neutron/extensions to implement resource extension to and the base class of the plugin to process the API request. *Add a file under neutron/db to implement the data base operation. *Add a directory under neutron/services to implement the plugin. 2. Implementing vProbe *The function of vProbe includes sending test packets to specified IP, calculating the network performance parameter according to the received test packets. Besides, the vProbe should provide interfaces to communicate with VNPM agents. The implementation will be deployed on compute node as a system service. 3. Implementing VNPM agent *The function of VNPM agent includes interaction with the VNPM plugin through RPC, managing vProbes, populate the network performance information with Oslo notification mechanism. The implementation file of VNPM agent will be put under neutron/services/VNPM, and deployed on compute node. Dependencies ============ None Testing ======= Both, functional and, system tests will be added. Documentation Impact ==================== Virtual network performance monitor resource will be added in the documentation. References ========== None ",346,345
openstack%2Fceilometer~stable%2Fjuno~I47d9ed3b38f79cdb1a71f9959bc31ad7e22a2fb4,openstack/ceilometer,stable/juno,I47d9ed3b38f79cdb1a71f9959bc31ad7e22a2fb4,Updated from global requirements,MERGED,2014-12-14 00:09:53.000000000,2014-12-19 02:23:11.000000000,2014-12-19 02:23:10.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1420}, {'_account_id': 2472}, {'_account_id': 3012}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 9656}, {'_account_id': 10987}, {'_account_id': 13273}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-14 00:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/69cc8936d91ae36d5e2af43d945047aed9b7b520', 'message': 'Updated from global requirements\n\nChange-Id: I47d9ed3b38f79cdb1a71f9959bc31ad7e22a2fb4\n'}, {'number': 2, 'created': '2014-12-16 14:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/77c38fd067549fe56ff14446878bddd29c6a0daa', 'message': 'Updated from global requirements\n\nChange-Id: I47d9ed3b38f79cdb1a71f9959bc31ad7e22a2fb4\n'}, {'number': 3, 'created': '2014-12-16 23:02:09.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b275dae9729a165e8a10060940efad41057e53d9', 'message': 'Updated from global requirements\n\nChange-Id: I47d9ed3b38f79cdb1a71f9959bc31ad7e22a2fb4\n'}]",4,141593,b275dae9729a165e8a10060940efad41057e53d9,29,11,3,11131,,,0,"Updated from global requirements

Change-Id: I47d9ed3b38f79cdb1a71f9959bc31ad7e22a2fb4
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/93/141593/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,69cc8936d91ae36d5e2af43d945047aed9b7b520,openstack/requirements,"SQLAlchemy>=0.8.4,<=0.9.99,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,!=0.9.4,!=0.9.5,!=0.9.6","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",2,2
openstack%2Fneutron-specs~master~I65c026c11fbaa2a904cbc970d95fdcb6d61ff70c,openstack/neutron-specs,master,I65c026c11fbaa2a904cbc970d95fdcb6d61ff70c,ofagent-edge-overlay,ABANDONED,2014-10-27 07:34:34.000000000,2014-12-19 02:22:39.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 2888}, {'_account_id': 4149}, {'_account_id': 6854}, {'_account_id': 8645}]","[{'number': 1, 'created': '2014-10-27 07:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ada34f553dd63d052003079d0832d60069674c7b', 'message': 'ofagent-edge-overlay\n\nChange-Id: I65c026c11fbaa2a904cbc970d95fdcb6d61ff70c\n'}, {'number': 2, 'created': '2014-11-11 03:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a01917805dcbd99c82ad2b620b886aec2d381539', 'message': 'ofagent-edge-overlay\n\nChange-Id: I65c026c11fbaa2a904cbc970d95fdcb6d61ff70c\n'}, {'number': 3, 'created': '2014-11-12 02:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/89069af2f1c44d94604d6e56e1813bd01bff7afd', 'message': 'ofagent-edge-overlay\n\nChange-Id: I65c026c11fbaa2a904cbc970d95fdcb6d61ff70c\n'}, {'number': 4, 'created': '2014-11-13 18:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/60699c6cc52a8367e772ed826afb1e6677662804', 'message': 'ofagent-edge-overlay\n\nChange-Id: I65c026c11fbaa2a904cbc970d95fdcb6d61ff70c\n'}, {'number': 5, 'created': '2014-11-26 03:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/01da51f001233e36d28be67a7b1b1caab2ef1202', 'message': 'ofagent-edge-overlay\n\nChange-Id: I65c026c11fbaa2a904cbc970d95fdcb6d61ff70c\n'}, {'number': 6, 'created': '2014-11-26 03:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d484807b16b52c9b853591a53bca806abd8091dc', 'message': 'ofagent-edge-overlay\n\nChange-Id: I65c026c11fbaa2a904cbc970d95fdcb6d61ff70c\n'}, {'number': 7, 'created': '2014-11-27 02:37:22.000000000', 'files': ['specs/kilo/ofagent-edge-overlay.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/70c2d8b168971d0a68f7cb59daf532e96bca2dfc', 'message': 'ofagent-edge-overlay\n\nChange-Id: I65c026c11fbaa2a904cbc970d95fdcb6d61ff70c\n'}]",27,131038,70c2d8b168971d0a68f7cb59daf532e96bca2dfc,34,8,7,6854,,,0,"ofagent-edge-overlay

Change-Id: I65c026c11fbaa2a904cbc970d95fdcb6d61ff70c
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/38/131038/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ofagent-edge-overlay.rst'],1,ada34f553dd63d052003079d0832d60069674c7b,bp/ofagent-edge-overlay,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================= OFAgent: Edge-to-edge overlay ============================= https://blueprints.launchpad.net/neutron/+spec/ofagent-edge-overlay Problem Description =================== tbd Proposed Change =============== - make agents aware of full network topology. (probably on-demand query to neutron server + caching) - map tunnel-ids to edge ports, rather than networks. edge port in the sense where a packet leaves neutron managed network. - when receiving the first packet in a flow, the agent determines necessary translations (eg. snat) and egress port, and the node to which the port belongs. - after performing necessary translations, the agent forwards the packet to the destination node's agent via tunnel, using tunnel-id corresponding to the edge port. - the destination node's agent looks at tunnel-id and maps it back to edge port. and it sends the packet out to the port. - broadcast needs some special treatment. probably having special tunnel ids which represent networks. (as it is today) note: it's intendended to implement DVR-like functionality on this. however, the first step will not likely include that part. Alternatives ------------ none Data Model Impact ----------------- neutron server (plugin/mech driver) needs to maintain the mapping between edge ports and tunnel_id. REST API Impact --------------- none Security Impact --------------- none Notifications Impact -------------------- none Other End User Impact --------------------- none Performance Impact ------------------ none Other Deployer Impact --------------------- none Developer Impact ---------------- none Community Impact ---------------- none Implementation ============== Assignee(s) ----------- Primary assignee: yamamoto Other contributors: kakuma Work Items ---------- see ""Proposed Change"" section. Dependencies ============ https://blueprints.launchpad.net/neutron/+spec/ofagent-flow-based-tunneling Testing ======= Tempest Tests ------------- none Functional Tests ---------------- none API Tests --------- none Documentation Impact ==================== User Documentation ------------------ none Developer Documentation ----------------------- none References ========== none ",,151,0
openstack%2Fneutron-specs~master~I0b7dfef52d0605a881563e2f86c1f23d7fdfd116,openstack/neutron-specs,master,I0b7dfef52d0605a881563e2f86c1f23d7fdfd116,NSX-vSphere Neutron plugin,ABANDONED,2014-06-26 05:02:17.000000000,2014-12-19 02:17:53.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 6598}, {'_account_id': 6981}, {'_account_id': 7317}, {'_account_id': 10441}]","[{'number': 1, 'created': '2014-06-26 05:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8ae689a132496ed614dd245cca922a2ce5ae817c', 'message': 'NSX-vSphere Neutron plugin\n\nProposes the addition of a VMware VSX-vSphere Neutron plugin.\nThis is related to the blueprint vmware-nsx-v\n\nChange-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116\n'}, {'number': 2, 'created': '2014-06-26 11:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/be043ddf6287a57413527450db2c9d2c8f794406', 'message': 'NSX-vSphere Neutron plugin\n\nProposes the addition of a VMware VSX-vSphere Neutron plugin.\nThis is related to the blueprint vmware-nsx-v\n\nChange-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116\n'}, {'number': 3, 'created': '2014-06-29 11:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2b2acfa8e38c6efee267417c9c20231d44cb2e2e', 'message': 'NSX-vSphere Neutron plugin\n\nProposes the addition of a VMware VSX-vSphere Neutron plugin.\nThis is related to the blueprint vmware-nsx-v\n\nChange-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116\n'}, {'number': 4, 'created': '2014-07-08 06:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/df8c391ab7ee6701d2c3aab0a4200d47855df522', 'message': 'NSX-vSphere Neutron plugin\n\nProposes the addition of a VMware VSX-vSphere Neutron plugin.\n\nPart of umbrella blueprint esx-neutron\n\nChange-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116\n'}, {'number': 5, 'created': '2014-07-12 00:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9732d037c3123e2b42e6c4ed3df100fef209e618', 'message': 'NSX-vSphere Neutron plugin\n\nProposes the addition of a VMware VSX-vSphere Neutron plugin.\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116\n'}, {'number': 6, 'created': '2014-08-03 17:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f850985d0393432b23a95c67f31e2046aa46219f', 'message': 'NSX-vSphere Neutron plugin\n\nProposes the addition of a VMware VSX-vSphere Neutron plugin.\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116\n'}, {'number': 7, 'created': '2014-10-13 07:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6949bd84bfd1482a8fabcbace27eb716141d9157', 'message': 'NSX-vSphere Neutron plugin\n\nProposes the addition of a VMware VSX-vSphere Neutron plugin.\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116\n'}, {'number': 8, 'created': '2014-10-15 17:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/300031fa4a3af7cc1907988fb0bc657d11dcba16', 'message': 'NSX-vSphere Neutron plugin\n\nProposes the addition of a VMware VSX-vSphere Neutron plugin.\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116\n'}, {'number': 9, 'created': '2014-10-19 11:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3e5b1cb2227bf92c7af702374a6f8285993051a1', 'message': 'NSX-vSphere Neutron plugin\n\nProposes the addition of a VMware VSX-vSphere Neutron plugin.\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116\n'}, {'number': 10, 'created': '2014-11-09 13:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/556b37a88145454df300c6d76de106ac900dccf2', 'message': 'NSX-vSphere Neutron plugin\n\nProposes the addition of a VMware NSX-vSphere Neutron plugin.\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116\n'}, {'number': 11, 'created': '2014-11-19 12:05:36.000000000', 'files': ['specs/kilo/vmware-nsx-v.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/32bb2c2c44f23584efe3dd41f2a173ee5baed469', 'message': 'NSX-vSphere Neutron plugin\n\nProposes the addition of a VMware NSX-vSphere Neutron plugin.\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116\n'}]",38,102720,32bb2c2c44f23584efe3dd41f2a173ee5baed469,50,10,11,1653,,,0,"NSX-vSphere Neutron plugin

Proposes the addition of a VMware NSX-vSphere Neutron plugin.

Part of umbrella blueprint vsphere-neutron

Change-Id: I0b7dfef52d0605a881563e2f86c1f23d7fdfd116
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/20/102720/11 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/vmware-nsx-v.rst'],1,8ae689a132496ed614dd245cca922a2ce5ae817c,bp/vsphere-neutron,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================= VMware NSX-vSphere plugin ========================= https://blueprints.launchpad.net/neutron/+spec/vmware-nsx-v The NSX-vSphere plugin is aimed at enabling existing vSphere users to deploy an OpenStack cloud with Neutron networking services. The plugin will provide support for the existing Neutron features. Problem description =================== vSphere users would like to make use of the Neutron functionality with the OpenStack VMware Nova driver. A NSX-vSphere Neutron plugin would enable that. Proposed change =============== Provide a VMware NSX-vSphere Neutron plugin that enables Neutron to create DVS networks (VLAN and VXLAN). The proposal would be to have a VMware driver that interfaces with the NSX-vSphere. This driver will make use of the NSX-vSphere API's to create and manage the virtual networks, ports etc. The user will be able to select between the following plugin classes: * neutron.plugins.vmware.plugin.NsxPlugin (existing plugin with controller) * neutron.plugins.vmware.plugin.NsxvSpherePlugin Alternatives ------------ At the moment there is no other option where the Neutron core feature setup can be achieved. Data model impact ----------------- None. All of the chnages are internal to the plugin. REST API impact --------------- None. All of the changes are internal to the plugin. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- The user will need to configure the configuration file of the plugin to interface with the NSX-vSphere. This will be documented. Performance Impact ------------------ None Other deployer impact --------------------- The user will need to deploy the various NSX-vSphere components. This will be documented. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: garyk Other contributors: sorlando arosen shadab bolin gals Work Items ---------- The following work items will be done: * NSX-vSphere networking management class * NSX-vSphere core plugin support * NSX-vSphere security group support * NSX-vSphere router and floating IP support * NSX-vSphere metadata service support * Minesweeper CI Dependencies ============ None Testing ======= We will add Minesweeper CI for the new plugin. Documentation Impact ==================== We will need to document the installation process and configuring of the plugin. References ========== * NSX-vSphere API - http://wwwcontentdev.vmware.com:9998/pdf/nsx_60_api.pdf ",,139,0
openstack%2Fneutron-specs~master~I576594f1853a22cfa9cc03764ca9e3751bf0aa31,openstack/neutron-specs,master,I576594f1853a22cfa9cc03764ca9e3751bf0aa31,OFAgent: Improvement port monitor,ABANDONED,2014-12-03 03:37:11.000000000,2014-12-19 02:16:34.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6854}]","[{'number': 1, 'created': '2014-12-03 03:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/aa938ef21044cebcda3f22d55807f5b238156490', 'message': 'OFAgent: Improvement port monitor\n\nChange-Id: I576594f1853a22cfa9cc03764ca9e3751bf0aa31\n'}, {'number': 2, 'created': '2014-12-05 04:03:08.000000000', 'files': ['specs/kilo/ofagent-port-monitor2.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/63179d657d56de06c0582e6e06ae2d4ce1d8c064', 'message': 'OFAgent: Improvement port monitor\n\nChange-Id: I576594f1853a22cfa9cc03764ca9e3751bf0aa31\n'}]",0,138618,63179d657d56de06c0582e6e06ae2d4ce1d8c064,8,3,2,6854,,,0,"OFAgent: Improvement port monitor

Change-Id: I576594f1853a22cfa9cc03764ca9e3751bf0aa31
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/18/138618/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ofagent-port-monitor2.rst'],1,aa938ef21044cebcda3f22d55807f5b238156490,bp/ofagent-port-monitor2,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================= OFAgent: Improvement port monitor ================================= https://blueprints.launchpad.net/neutron/+spec/ofagent-port-monitor2 Problem Description =================== ofagent uses periodic polling to monitor port status changes. * it wastes cpu even when idle * port processing can be deferred by polling interval Proposed Change =============== monitor port changes using openflow port-status asynchronous messages [#port_status]_ as mentioned in the relevant blueprint for juno [#juno_bp]_. Alternatives ------------ none Data Model Impact ----------------- none REST API Impact --------------- none Security Impact --------------- none Notifications Impact -------------------- none Other End User Impact --------------------- none Performance Impact ------------------ the agent performance is expected to be improved a little. IPv6 Impact ----------- none Other Deployer Impact --------------------- none Developer Impact ---------------- none Community Impact ---------------- none Implementation ============== Assignee(s) ----------- Primary assignee: yamamoto Other contributors: kakuma Work Items ---------- see ""Proposed Change"" section. Dependencies ============ none Testing ======= update the existing tests if necessary. Tempest Tests ------------- none Functional Tests ---------------- none API Tests --------- none Documentation Impact ==================== User Documentation ------------------ none Developer Documentation ----------------------- none References ========== .. [#port_status] OpenFlow 1.3.3 7.4.3 Port Status Message .. [#juno_bp] https://blueprints.launchpad.net/neutron/+spec/ofagent-port-monitor ",,145,0
openstack%2Fneutron-specs~master~Ic51694544746a6226583b9e5ed0ad165a5cd025b,openstack/neutron-specs,master,Ic51694544746a6226583b9e5ed0ad165a5cd025b,ML2 Mechanism Driver for Mellanox SDN,ABANDONED,2014-12-03 20:36:09.000000000,2014-12-19 02:16:13.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6598}, {'_account_id': 8645}, {'_account_id': 12065}, {'_account_id': 12171}, {'_account_id': 12970}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-03 20:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8095fdf0a0b7422ed6ba8aa4eca242fd23e60d2d', 'message': 'ML2 Mechanism Driver for Mellanox SDN\n\nChange-Id: Ic51694544746a6226583b9e5ed0ad165a5cd025b\nImplements: blueprint mlnx-sdn-ml2-mech-driver\n'}, {'number': 2, 'created': '2014-12-03 21:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9c8e880b2996c49ea6cd5cd364d5f3bc627b7d5a', 'message': 'ML2 Mechanism Driver for Mellanox SDN\n\nChange-Id: Ic51694544746a6226583b9e5ed0ad165a5cd025b\nImplements: blueprint mlnx-sdn-ml2-mech-driver\n'}, {'number': 3, 'created': '2014-12-03 21:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5872e9a031607e9a7d6dd1b4fe12ee5df79b39b8', 'message': 'ML2 Mechanism Driver for Mellanox SDN\n\nChange-Id: Ic51694544746a6226583b9e5ed0ad165a5cd025b\nImplements: blueprint mlnx-sdn-ml2-mech-driver\n'}, {'number': 4, 'created': '2014-12-04 07:17:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/947ad9ed7820ea45dab81207ccdf858275299706', 'message': 'ML2 Mechanism Driver for Mellanox SDN\n\nChange-Id: Ic51694544746a6226583b9e5ed0ad165a5cd025b\nImplements: blueprint mlnx-sdn-ml2-mech-driver\n'}, {'number': 5, 'created': '2014-12-07 07:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d8a9995fc4189658a950aa5e2befc14d9a9035d0', 'message': 'ML2 Mechanism Driver for Mellanox SDN\n\nChange-Id: Ic51694544746a6226583b9e5ed0ad165a5cd025b\nImplements: blueprint mlnx-sdn-ml2-mech-driver\n'}, {'number': 6, 'created': '2014-12-07 20:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8781950660d154bba0c985de185b0409f7eb8be4', 'message': 'ML2 Mechanism Driver for Mellanox SDN\n\nChange-Id: Ic51694544746a6226583b9e5ed0ad165a5cd025b\nImplements: blueprint mlnx-sdn-ml2-mech-driver\n'}, {'number': 7, 'created': '2014-12-08 13:45:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9d39b8f2f166b16a47dd2cf507bb9167dee1ab0c', 'message': 'ML2 Mechanism Driver for Mellanox SDN\n\nChange-Id: Ic51694544746a6226583b9e5ed0ad165a5cd025b\nImplements: blueprint mlnx-sdn-ml2-mech-driver\n'}, {'number': 8, 'created': '2014-12-08 13:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c90a5a0ff3adb66e5c2819340758e8e09985d0c3', 'message': 'ML2 Mechanism Driver for Mellanox SDN\n\nChange-Id: Ic51694544746a6226583b9e5ed0ad165a5cd025b\nImplements: blueprint mlnx-sdn-ml2-mech-driver\n'}, {'number': 9, 'created': '2014-12-10 17:03:01.000000000', 'files': ['specs/kilo/ml2-mlnx-sdn-mechanism-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/30635ce88616dba35e82903885246c73511ac42c', 'message': 'ML2 Mechanism Driver for Mellanox SDN\n\nChange-Id: Ic51694544746a6226583b9e5ed0ad165a5cd025b\nImplements: blueprint mlnx-sdn-ml2-mech-driver\n'}]",54,138849,30635ce88616dba35e82903885246c73511ac42c,30,8,9,12065,,,0,"ML2 Mechanism Driver for Mellanox SDN

Change-Id: Ic51694544746a6226583b9e5ed0ad165a5cd025b
Implements: blueprint mlnx-sdn-ml2-mech-driver
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/49/138849/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ml2-mlnx-sdn-mechanism-driver.rst'],1,8095fdf0a0b7422ed6ba8aa4eca242fd23e60d2d,bp/mlnx-sdn-ml2-mech-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================================== ML2 mechanism driver for Mellanox SDN ===================================== https://blueprints.launchpad.net/neutron/+spec/mlnx-sdn-ml2-mech-driver The Mellanox's Virtual Protocol Interconnect (VPI) SDN product is a platform for managing scale-out computing environments. It enables data center operators to monitor, efficiently provision, and operate the modern data center fabric on both Infiniband and Ethernet. This spec proposes to add a new ML2 mechanism driver for Mellanox's SDN. Problem Description =================== dynamically manage networking. It will configure the physical layer and manage the Vlans, QOS, etc. Mellanox SDN supports both Ethernet and Infiniband, and will enable easy Infiniband's configuration, such as Pkeys and Guids which are currently not supported in Openstack. Use Cases: 1.External SDN controller who can monitor the fabric and act upon events. 2.Dynamic configuration of Vlans. In Infiniband, there will also be a conversion between Vlans to Pkeys and Mac addresses do Guids Proposed Change =============== The diagram below provides a high level overview of how the Mellanox SDN will integrate into a working environment consisting of multiple hosts with physical switches. The Mellanox SDN Mechanism Driver for ML2 communicated with the SDN via its REST API. Flows: +---------------------------+ | | | Neutron Server | | with ML2 Plugin | | | | +---------+-------------+ | +-------+ | L2 Port | MLNX SDN | | | | | binding | Mechanism | | +-----------------+ | | | Mech | Driver | +------------------+ | | +----+ | Driver | | | REST API | Mellanox | | | | +---------+-------------+ | | SDN | | | +---------------------------+ | | | | | | | | +-+---+-----------+ | | +--------------------------+ | | | +----+ +-----+ | | | | | | | | | | HOST 1 | | | | | | | | | | | | | | +--------+---|------+ | +--------------------------+ | | | | | +------+ +---------+------+--+ | | | | | +--------------------------+ | | Mellanox | +-------+ +------------+ | VPI | | | | | Switches | | HOST 2 | +--+ | | | | | | | +-------------------+ +--------------------------+ The Mellanox SDN mechanism driver updates the Mellanox SDN with ports, networks and subnets changes from Neutron. It will acts as a REST proxy and will pass all Neutron API calls into the SDN. The SDN will be able to configure the physical switches with Vlans or Pkeys and monitor them. The Mellanox SDN is responsible for the Fabric side only, and will work along any L2 port binding mechanism driver. Data Model Impact ----------------- None. REST API Impact --------------- None. Security Impact --------------- None. Notifications Impact -------------------- None. Other End User Impact --------------------- None. Performance Impact ------------------ Unless the MlnxSDNMechanismDriver is explicitly configured (in ml2_conf.ini), it has no runtime effect, including no possible performance impact on a standard OpenStack system. IPv6 Impact ----------- None. Other Deployer Impact --------------------- The deployer must provide the following in order to be able to connect to Mellanox SDN: 1. IP address of Mellanox SDN. 2. Admin, Username and password to log into Mellanox SDN. The Deployer should also configure any L2 port binding nechanism driver he wishes to work with. Developer Impact ---------------- None. Community Impact ---------------- Alternatives ------------ None. Implementation ============== Assignee(s) ----------- Primary assignee: Nuritv Other contributors: Moshele Work Items ---------- Work Items can be roughly divided into the following tasks: * Mechanism driver which implement REST to handle all (network/subnet/port) requests. * Unit test cases to test the mechanism driver and client code. * Tempest test cases to perform functional testing. Dependencies ============ None. Testing ======= This change will be tested by Tempest tests in a third-party CI system, to be set up and operated as described at https://wiki.openstack.org/wiki/NeutronThirdPartyTesting, to test the combination of this spec Tempest Tests ------------- Third party testing will be provided. The Mellanox CI will report on all changes affecting this mechanism driver. The testing will run on a setup with an OpenStack deployment connected to Mellanox's SDN. Functional Tests ---------------- None. API Tests --------- None. Documentation Impact ==================== User Documentation ------------------ Configuration details for this mechanism driver. Developer Documentation ----------------------- None. References ========== None. ",,215,0
openstack%2Fneutron-specs~master~I55e0a0bba20b49cb4451b2773259890b0299a6e0,openstack/neutron-specs,master,I55e0a0bba20b49cb4451b2773259890b0299a6e0,Design Spec For Vyatta vRouter L3 Plugin,ABANDONED,2014-11-11 19:51:18.000000000,2014-12-19 02:16:07.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 490}, {'_account_id': 5217}, {'_account_id': 6659}, {'_account_id': 7021}, {'_account_id': 8645}, {'_account_id': 10182}]","[{'number': 1, 'created': '2014-11-11 19:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/eeca3c6499b7c2956e530800f3d7922d656924dd', 'message': 'Design Spec For Vyatta vRouter L3 Plugin\n\nChange-Id: I55e0a0bba20b49cb4451b2773259890b0299a6e0\n'}, {'number': 2, 'created': '2014-12-04 23:49:49.000000000', 'files': ['specs/kilo/vyatta_l3_plugin.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5a5f5d26a03a8b83ac2226f036ba44ff5f7fad0b', 'message': 'Design Spec For Vyatta vRouter L3 Plugin\n\nChange-Id: I55e0a0bba20b49cb4451b2773259890b0299a6e0\n'}]",6,133817,5a5f5d26a03a8b83ac2226f036ba44ff5f7fad0b,19,11,2,10182,,,0,"Design Spec For Vyatta vRouter L3 Plugin

Change-Id: I55e0a0bba20b49cb4451b2773259890b0299a6e0
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/17/133817/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/vyatta_l3_plugin.rst'],1,eeca3c6499b7c2956e530800f3d7922d656924dd,bp/l3-plugin-brocade-vyatta-vrouter,".. .. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================= Brocade Neutron L3 Plugin for Vyatta vRouter ============================================= Launchpad blueprint URL: https://blueprints.launchpad.net/neutron/+spec/l3-plugin-brocade-vyatta-vrouter This blueprint is for implementing an L3 service plugin for Brocade Vyatta vRouter appliance. Problem Description =================== Cloud service providers want to use Brocade Vyatta vRouter as a tenant virtual router in their OpenStack cloud. In order to perform the vRouter VM lifecycle management and required configurations, a new Neutron L3 plugin for Brocade Vyatta vRouter is required. Brocade Neutron L3 Plugin for Vyatta vRouter supports CRUD operations on vRouter, add/remove interfaces from vRouter and floating IPs for VMs. It performs vRouter VM lifecyle management by calling Nova APIs during the Create and Delete Router calls. Once the vRouter VM is up, L3 plugin connects to the REST API end-point exposed by the vRouter VM using REST API to perform the appropriate configurations.L3 plugin supports add/remove router interfaces by attaching/detaching the neutron ports to vRouter VM using Nova API. Basic workflow is as shown below: :: +---------------------------+ | | | | | Neutron Server | | | | | | +-----------------------+ | +---------------+ | | L3 Plugin for Brocade | | | | | | Vyatta vRouter +----------> Nova API | | | | | | | +-+----------+------------+-+ +-------+-------+ | | | | |REST API | | | | | +-------V----------+ | | | | | Brocade Vyatta | | | vRouter VM <--------------------+ | | +------------------+ Proposed Change =============== Brocade Vyatta vRouter L3 plugin implements the below operations: - Create/Update/Delete Routers - Configure/Clear External Gateway - Create/Delete Router-interfaces - Create/Delete Floating-IPs During the tenant router creation, L3 plugin will invoke nova-api by using the admin tenant credentials mentioned in the plugin configuration file (More details specified in deployer impact section). Nova-api is invoked to provision Vyatta vRouter VM on-demand in admin tenant (Service VM tenant) by using the tenant-id, image-id, management network name and flavor-id specified in plugin configuration file. Vyatta vRouter VM's UUID is used while creating the Neutron router so that router's UUID is the same as VM's UUID. During vRouter VM creation, we will poll the status of the VM synchronously.Only when it becomes 'Active', we create the neutron router and the router creation process is declared as successful.Once the vRouter VM is up, L3 plugin will use REST API to configure the router name and administration state. If L3 plugin encounters error from nova-api during vRouter VM creation or while using REST API to communicate with the vRouter VM, router creation will fail and appropriate error message is returned to the user. When external gateway is configured, L3 plugin will create a neutron port in external network and attach the port to vRouter VM using nova-api. Vyatta vRouter image will recognize the hot-plugged interface. Once the port is attached, L3 plugin will use REST API to configure the interface ip-address on the ethernet interface. It will also create SNAT rules for all the private subnets configured in router interfaces using REST API. SNAT rules and the external gateway port will be deleted when external gateway configuration is removed. If L3 plugin encounters error from nova-api during port attachment or while using REST API to communicate with the vRouter VM, external gateway configuration will fail and appropriate error message is returned to the user. While adding a router interface, L3 plugin will create a neutron port in tenant network and attach the port to vRouter VM using nova-api. Vyatta vRouter image will recognize the hot-plugged interface. Once the port is attached, L3 plugin will use REST API to configure the subnet on the ethernet interface. It will also create SNAT rule for the router interface subnet using REST API if external gateway is configured in the router. If L3 plugin encounters error from nova-api during port attachment or while using REST API to communicate with the vRouter VM, router interface addition will fail and appropriate error message is returned to the user. While deleting a router interface, L3 plugin will remove the ethernet interface ip-address configuration, SNAT rule (if configured because of external gateway) using REST API, detach and delete the neutron port in the tenant network. If L3 plugin encounters error from nova-api during port detachment or while using REST API to communicate with the vRouter VM, router interface deletion will fail and appropriate error message is returned to the user. When floating IPs are configured, L3 plugin will create SNAT and DNAT rules for the translation between floating IPs and private network IPs using REST API. SNAT and DNAT rules will be deleted when the floating IPs are disassociated. If L3 plugin encounters error while using REST API to communicate with the vRouter VM, floating IP configurations will fail and appropriate error message is returned to the user. While deleting the router, l3 plugin will first validate for non-existence of router interfaces and external gateway configuration. It will delete the router VM using Nova API and then delete the Neutron router. Data Model Impact ----------------- None REST API Impact --------------- None Security Impact --------------- None Notifications Impact -------------------- None Other End User Impact --------------------- While creating the Neutron router, end user has to wait for the vRouter VM to be up (as it is spawned on-demand). This can take around 20 seconds. Performance Impact ------------------ None Other Deployer Impact --------------------- 1. Edit Neutron configuration file /etc/neutron/neutron.conf to specify Vyatta vRouter L3 plugin: service_plugins = neutron.plugins.brocade.vyatta.vrouter_neutron_plugin.VyattaVRouterPlugin 2. Import the Brocade Vyatta vRouter image using the below glance command: glance image-create --name ""Vyatta vRouter"" --is-public true --disk-format qcow2 --file ./vyatta_l3_plugin/image/vyatta_vrouter.qcow2 --container-format bare 3. Note the provider management network name. This needs to be specified in the plugin configuration. 4. Configure the L3 plugin configuration file /etc/neutron/plugins/brocade/vyatta/vrouter.ini with the below parameters: # Tenant admin name tenant_admin_name = admin # Tenant admin password tenant_admin_password = devstack # Admin or service VM Tenant-id tenant_id = <UUID of the admin or service VM tenant> # Keystone URL. Example: http://<Controller node>:5000/v2.0/ keystone_url = http://10.18.160.5:5000/v2.0 # Vyatta vRouter Image id. Image should be imported using Glance image_id = <UUID> # vRouter VM Flavor-id (Small) flavor = 2 # vRouter Management network id management_network = <UUID of the management network> Once configured, L3 plugin will be invoked for the CRUD operations on tenant router, add/remove router interfaces and floating ip support. Developer Impact ---------------- None Community Impact ---------------- None Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: natarajk Other contributors: None Work Items ---------- Brocade Vyatta vRouter L3 plugin source code files: vrouter_neutron_plugin.py - Implements L3 API and calls the vRouter driver. vrouter_driver.py - Uses Nova API for vRouter VM provisioning and vRouter REST API for configuration. Code is available for review: https://review.openstack.org/#/c/102336/ Dependencies ============ None Testing ======= Tempest Tests ------------- - 3rd party testing will be provided (Brocade Vyatta CI). - Brocade Vyatta CI will report on all changes affecting this plugin. - Testing is done using devstack and Vyatta vRouter. Functional Tests ---------------- None API Tests --------- None Documentation Impact ==================== User Documentation ------------------ Configuration details for this L3 plugin. Developer Documentation ----------------------- None References ========== None ",,285,0
openstack%2Fneutron-specs~master~Ic1c5ec89ac7e9821cfbb7042ed5a8c62701575cc,openstack/neutron-specs,master,Ic1c5ec89ac7e9821cfbb7042ed5a8c62701575cc,Spec for Brocade IronwareOS ML2 mechanism driver,ABANDONED,2014-12-09 07:58:51.000000000,2014-12-19 02:15:40.000000000,,"[{'_account_id': 3}, {'_account_id': 261}]","[{'number': 1, 'created': '2014-12-09 07:58:51.000000000', 'files': ['specs/kilo/ml2-brocade-ironwareos-mech-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b8be38143ec33d209baa693e4ab44330b2565784', 'message': 'Spec for Brocade IronwareOS ML2 mechanism driver\n\nChange-Id: Ic1c5ec89ac7e9821cfbb7042ed5a8c62701575cc\n'}]",0,140261,b8be38143ec33d209baa693e4ab44330b2565784,4,2,1,11660,,,0,"Spec for Brocade IronwareOS ML2 mechanism driver

Change-Id: Ic1c5ec89ac7e9821cfbb7042ed5a8c62701575cc
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/61/140261/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ml2-brocade-ironwareos-mech-driver.rst'],1,b8be38143ec33d209baa693e4ab44330b2565784,bp/ml2-brocade-ironwareos-mech-driver,.. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================ Brocade ML2 Mechanism driver for Ironware OS ============================================ https://blueprints.launchpad.net/neutron/+spec/ml2-brocade-ironwareos-mech-driver This Blueprint is to introduce ML2 Mechanism driver for Brocade MLX and ICX switches in OpenStack Neutron. Problem Description =================== Brocade already has the mechanism driver for the VDX switches. For OpenStack Kilo release introducing ML2 mechanism driver for MLX and ICX switch gear. The FINI mechanism driver will allow to configure FastIron gear at access layer and NetIron based switches at the core layer for L2 traffic. Proposed Change =============== ML2 Driver for Ironware OS switches ( MLX and ICX switches) gear allow customer to configure VLANs. Data Model Impact ----------------- None. REST API Impact --------------- None. Security Impact --------------- None. Notifications Impact -------------------- None. Other End User Impact --------------------- None. Performance Impact ------------------ None. IPv6 Impact ----------- None. Other Deployer Impact --------------------- None Developer Impact ---------------- None. Community Impact ---------------- This change will enable customer manage L2 networks on Brocade MLX & ICX switches. Alternatives ------------ None. Implementation ============== Assignee(s) ----------- Primary assignee: Prakash Kaligotla Other contributors: Nagendra Rao Jaladanki Work Items ---------- - Implement ML2 mechanical driver. - Unit test the driver with MLX and ICX gear. Dependencies ============ None. Testing ======= Unit tests will be performed to make sure network create/delete and VM instance attach/detach operations are successful. Tempest Tests ------------- None. Functional Tests ---------------- None. API Tests --------- Documentation Impact ==================== None. User Documentation ------------------ Configuration update details will be provided to configure the Brocade Ironware OS based switches. Developer Documentation ----------------------- None. References ========== ,,156,0
openstack%2Fneutron-specs~master~I81e39b3576067ea6c709ac19cf6cd036e050a048,openstack/neutron-specs,master,I81e39b3576067ea6c709ac19cf6cd036e050a048,Spec for Brocade SVI plugin for MLX,ABANDONED,2014-12-09 07:32:23.000000000,2014-12-19 02:15:28.000000000,,"[{'_account_id': 3}, {'_account_id': 261}]","[{'number': 1, 'created': '2014-12-09 07:32:23.000000000', 'files': ['specs/kilo/l3-brocade-mlx-svi-service-plugin.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c4f8b5932d17e09a4d2e0a5eccdaf147afc41df6', 'message': 'Spec for Brocade SVI plugin for MLX\n\nChange-Id: I81e39b3576067ea6c709ac19cf6cd036e050a048\n'}]",0,140257,c4f8b5932d17e09a4d2e0a5eccdaf147afc41df6,4,2,1,11660,,,0,"Spec for Brocade SVI plugin for MLX

Change-Id: I81e39b3576067ea6c709ac19cf6cd036e050a048
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/57/140257/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/l3-brocade-mlx-svi-service-plugin.rst'],1,c4f8b5932d17e09a4d2e0a5eccdaf147afc41df6,bp/l3-brocade-svi-mlx-plugin,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================================= Layer 3 service plugin to support hardware based routing (SVI) on Brocade MLX ============================================================================= https://blueprints.launchpad.net/neutron/+spec/l3-brocade-mlx-svi-service-plugin This blueprint exploits the L3 SVI functionality in the Brocade MLX switch via an L3 router service plugin. Problem Description =================== Brocade Hardware supports SVI (Switch Virtual Interface) which provides ASIC level routing/gateway functionality in the switch for configured VLANs. This Service plugin provides support for this feature which enables line rate routing/gateway functionality. Please see definition of SVI in the references section of this document. Proposed Change =============== This proposal will introduce a Layer 3 service plugin which will interface with the Brocade MLX switch using SSH. The SSH Connection will be used to program the SVI on the switch. This plug-in works in conjunction with Brocade MLX/ICX ML2 Driver which will continue to manage networks, subnets, and ports. The plan is to support the full API. Data Model Impact ----------------- In the Brocade specific DB a table will be added to track the SVI created on a tenant basis. Mapping of the SVI to the VLAN will also be provided. new table: brocade_db.svi (id, vlan, tenant_id) id - standard uuid vlan - svi's associated vlan tenant_id: tenant this svi belongs to REST API Impact --------------- None. Security Impact --------------- None. Notifications Impact -------------------- none Other End User Impact --------------------- None. Performance Impact ------------------ There are no changes to any existing code patterns, hence there is no significant change in performance profile. Instead of software L3 service this blueprint provides the same service using the MLX hardware. IPv6 Impact ----------- None. Other Deployer Impact --------------------- None. Developer Impact ---------------- None. Community Impact ---------------- This change will enable customer the L3 SVI functionality in the Brocade MLX switch via an L3 router service plugin. Alternatives ------------ The alternative approach is to use the open source agent based layer 3 router plugin and update the L3 agent to interact with Brocade Hardware. Implementation ============== Assignee(s) ----------- Nagendra Rao Jaladanki Work Items ---------- * L3-SVI Service Plugin for Brocade MLX * DevStack related enhancements to support this plugin Dependencies ============ None. Testing ======= Complete unit test coverage of the code will be provided with mocked hardware. Brocade will provide Third-Party tempest code coverage of this functionality. This will be implemented as a CI (continuous integration) Testing. L3 routing tests will be enabled. Tempest Tests ------------- None. Functional Tests ---------------- None. API Tests --------- None Documentation Impact ==================== Documentation to configure and deploy this service plugin will be provided in the Openstack wiki. User Documentation ------------------ None. Developer Documentation ----------------------- None. References ========== SVI General definition: Wikipedia: http://en.wikipedia.org/wiki/Switvh_virtual_interface ",,182,0
openstack%2Fneutron-specs~master~Ie12803535a2c8b2bf0607f7b4763bb45e5c9b18b,openstack/neutron-specs,master,Ie12803535a2c8b2bf0607f7b4763bb45e5c9b18b,Cisco routing service using vif hotplugging,ABANDONED,2014-12-08 20:17:25.000000000,2014-12-19 02:15:20.000000000,,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 1689}, {'_account_id': 6995}, {'_account_id': 7021}]","[{'number': 1, 'created': '2014-12-08 20:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a4dfe31d1bc36f611bcded1b78aad79f1c441b29', 'message': 'Cisco routing service using ML2 OVS as the core plugin\n\nAdds the specification for a new plugging driver for connectivity operations in\nthe Cisco routing service when ML2 with OVS is used as the core plugin.\n\nChange-Id: Ie12803535a2c8b2bf0607f7b4763bb45e5c9b18b\n'}, {'number': 2, 'created': '2014-12-08 20:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/7985b66627392e7d06be8866f22dad7f86fbecc4', 'message': 'Cisco routing service using ML2 OVS as the core plugin\n\nAdds the specification for a new plugging driver for connectivity operations in\nthe Cisco routing service when ML2 with OVS is used as the core plugin.\n\nChange-Id: Ie12803535a2c8b2bf0607f7b4763bb45e5c9b18b\n'}, {'number': 3, 'created': '2014-12-10 18:50:35.000000000', 'files': ['specs/kilo/cisco-routing-service-using-vif-hotplugging.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b9f6b00fad391ee63897fc0e11e2bbd6f201af63', 'message': 'Cisco routing service using vif hotplugging\n\nAdds the specification for a new plugging driver that allows cisco routing service\nto use vif hot plugging for inserting router interfaces in tenant networks\nand ML2 as the core plugin.\n\nChange-Id: Ie12803535a2c8b2bf0607f7b4763bb45e5c9b18b\n'}]",4,140138,b9f6b00fad391ee63897fc0e11e2bbd6f201af63,13,6,3,7021,,,0,"Cisco routing service using vif hotplugging

Adds the specification for a new plugging driver that allows cisco routing service
to use vif hot plugging for inserting router interfaces in tenant networks
and ML2 as the core plugin.

Change-Id: Ie12803535a2c8b2bf0607f7b4763bb45e5c9b18b
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/38/140138/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/cisco-routing-service-using-ml2-ovs.rst'],1,a4dfe31d1bc36f611bcded1b78aad79f1c441b29,bp/cisco-routing-ml2,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================== Cisco routing service using ML2 OVS =================================== https://blueprints.launchpad.net/neutron/+spec/cisco-routing-service-using-ml2-ovs This feature allows the cisco routing service to use ML2 as the core plugin with OVS as the mechanism driver for all its L2 operations. Problem Description =================== The current cisco routing service [1] makes use of CSR1000v service VM [2] to implement the routing functionality. When a service VM is created or deleted and when a logical resource like a neutron router implemented inside a service VM is attached or detached from a neutron network/subnet, a number of things related to connectivity need to happen. Because of the coupling to connectivity these operations have a dependency on the neutron environment, specifically the core plugin in use. These operations are abstracted under a plugging driver API that the service plugin calls. Thus for each core plugin, a corresponding plugging driver is needed and configured (via the plugging_driver field in the cisco_router_plugin.ini) Currently the cisco routing service plugin uses the cisco Nexus 1000v (n1kv) monolithic plugin as the core plugin. There is an n1kv plugging driver that implements all the n1kv plugin calls needed to setup connectivity for the VM and attach it to tenant networks as part of the router-interface-add/delete commands. When using ML2 as the core plugin with OVS as the mechanism driver, a similiar plugging driver needs to be developed for the connecivity operations. This blueprint captures that work. Proposed Change =============== This blueprint implements a new ML2 OVS plugging driver. When a new service VM is created, this plugging driver will create a management port for it and attach it to the management network, so that the cisco config agent can reach it to apply configurations. When a tenant request a router-interface-add, the plugging driver will configure the router port in the ML2 specific way and attach it to the service VM. Similiary for router-interface-delete operation, it will remove the router port and detach it from the service VM. The routing service driver in the cisco config agent will be modified to configure the interfaces of the service VM. Data Model Impact ----------------- None REST API Impact --------------- None Security Impact --------------- None Notifications Impact -------------------- No additional notifications are added. Other End User Impact --------------------- End users will not experience any changes. Performance Impact ------------------ None IPv6 Impact ----------- This change will not have any impact on IPv6 in Neutron. Other Deployer Impact --------------------- Deployers need to ensure the following. 1. ML2 is used as the L2 plugin with OVS as the mechanism driver. 2. In cisco_router_plugin.ini file, the plugging driver should be set to the new ML2 OVS plugging driver. Developer Impact ---------------- None Community Impact ---------------- This is a vendor related functionality and hence no direct community impact. Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: hareesh-puthalath (hputhala@cisco.com) Other contributors: bob-melander (bmelande@cisco.com) Work Items ---------- The following are the work items involved for execution of this blueprint: 1. A ML2 OVS based plugging driver. 2. A modified routing driver for the cisco config agent to configure the router interfaces. Dependencies ============ None Testing ======= Tempest Tests ------------- The current tempest testing on the cisco routing service (via Cisco CI) will be adequate since no new functionality is added. But the tests will be run ensuring that ML2 is configured as the core plugin. Functional Tests ---------------- No additional functional tests are needed since no new functionality is added to the routing service. API Tests --------- None Documentation Impact ==================== There are no changes to the Openstack documentation for this blueprint. The vendor deployment/install documentation will be updated, specifically on the configuration options. User Documentation ------------------ None Developer Documentation ----------------------- None References ========== [1] Cisco routing service plugin : https://blueprints.launchpad.net/neutron/+spec/cisco-routing-service-vm [2] Cisco CSR 1000v: http://www.cisco.com/c/en/us/products/routers/cloud-services-router-1000v-series/index.html",,190,0
openstack%2Fneutron-specs~master~I51e1ac2c28e8877169b2ee633251af56491fc536,openstack/neutron-specs,master,I51e1ac2c28e8877169b2ee633251af56491fc536,New ML2 mechanism driver for 'Calico'-style VM connectivity,ABANDONED,2014-10-24 10:57:34.000000000,2014-12-19 02:14:28.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 333}, {'_account_id': 2888}, {'_account_id': 6524}, {'_account_id': 7448}, {'_account_id': 13507}, {'_account_id': 13635}, {'_account_id': 13734}]","[{'number': 1, 'created': '2014-10-24 10:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4aecae56beddb4cfbe14792fe3933009a19a5d76', 'message': ""New ML2 mechanism driver for 'Calico'-style VM connectivity\n\nChange-Id: I51e1ac2c28e8877169b2ee633251af56491fc536\n""}, {'number': 2, 'created': '2014-10-31 18:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/1937b0cc6cc25d1c81a29b86e3041b1733723525', 'message': ""New ML2 mechanism driver for 'Calico'-style VM connectivity\n\nChange-Id: I51e1ac2c28e8877169b2ee633251af56491fc536\n""}, {'number': 3, 'created': '2014-11-26 14:10:24.000000000', 'files': ['specs/kilo/calico-mechanism-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5f85999646252aaa3646e0e50f64f76edbcc3cdc', 'message': ""New ML2 mechanism driver for 'Calico'-style VM connectivity\n\nChange-Id: I51e1ac2c28e8877169b2ee633251af56491fc536\n""}]",12,130737,5f85999646252aaa3646e0e50f64f76edbcc3cdc,18,10,3,13734,,,0,"New ML2 mechanism driver for 'Calico'-style VM connectivity

Change-Id: I51e1ac2c28e8877169b2ee633251af56491fc536
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/37/130737/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/calico-mechanism-driver.rst'],1,4aecae56beddb4cfbe14792fe3933009a19a5d76,calico-mechanism-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================================== New ML2 mechanism driver for 'Calico'-style VM connectivity =========================================================== https://blueprints.launchpad.net/neutron/+spec/calico-mechanism-driver The open source Project Calico (http://www.projectcalico.org/) provides VM connectivity using highly scalable L3 techniques - IP routing and BGP - instead of simulating bridged L2 networks across multiple compute hosts, for deployments where VMs only require L3 service. This spec proposes to add a new ML2 mechanism driver for Calico-style VM connectivity. Problem Description =================== We wish to support an alternative networking model in which each compute node routes the data to/from its VMs, instead of bridging it: :: VM | tapXXXX | Linux IP routing, iptables etc. | external network interface The detailed connectivity is then controlled by how routing and iptables are set up (by an agent) on each compute node. Project Calico (http://www.projectcalico.org/) implements this model by arranging, on each compute host, that: * The compute node's routing table includes a route for each local VM IP address, which directs traffic via the relevant TAP interface. * Each VM is configured (by DHCP) to have the compute node as its default gateway. * Proxy ARP is enabled on all VM TAP interfaces on the compute host, so that VMs on multiple compute hosts can belong to the same IP subnet. * Manipulation of the L-bit for IPv6 address assignment provides the same function as Proxy ARP does for IPv4 * BGP operates between all the compute nodes, so as to propagate VM routes from one compute node to all the other nodes. * Configured connectivity and security restrictions are implemented through a combination of iptables and route filters on the compute nodes. Proposed Change =============== This change adds a file neutron/plugins/ml2/drivers/mech_calico.py, providing a new ML2 mechanism driver class, CalicoMechanismDriver. The key points of the CalicoMechanismDriver class are as follows. - It supports 'local' and 'flat' networks. - It tells ML2 to use VIF_TYPE_ROUTED, for the VMs attached to networks associated with the CalicoMechanismDriver. - It uses the _port_postcommit hooks provided by neutron/plugins/ml2/driver_api.py to be aware of VM port changes and to pass those on to the Calico agent. - It hooks the ML2 plugin's notifier in order to be aware of security configuration changes, and to pass those on to the Calico ACL Manager component. - It communicates with other Calico components over 0MQ sockets. Data Model Impact ----------------- None. REST API Impact --------------- None. Security Impact --------------- None. Notifications Impact -------------------- None. Other End User Impact --------------------- None. Performance Impact ------------------ Unless the CalicoMechanismDriver is explicitly configured (in ml2_conf.ini), it has no runtime effect, including no possible performance impact on a standard OpenStack system. Other Deployer Impact --------------------- None. It does not require downtime or manual intervention to apply when upgrading. Developer Impact ---------------- None. Community Impact ---------------- This driver has not yet been discussed with the Neutron community, but will be so shortly - as appropriate - on the mailing list, at weekly Neutron meetings, and at the next design summit. The developers of this extension will also be at the next OpenStack summit and will be happy to discuss this there. We believe this extension is compatible with the direction of the Neutron community. Alternatives ------------ None. Implementation ============== Assignee(s) ----------- Primary assignee: neil-jerram Other contributors: lukasaoz cliljenstolpe Work Items ---------- The latest implementation of CalicoMechanismDriver may be seen at https://github.com/Metaswitch/calico-neutron/blob/master/neutron/plugins/ml2/drivers/mech_calico.py. It has been tested, on an Icehouse base, as part of Project Calico (http://www.projectcalico.org/), but further OpenStack environment testing is planned, as described below. Remaining work items are as follows: * Implement Tempest and 3rd party CI tests as described below. * Verify that proposed changes pass all existing tests (including code style), as well as new tests. * Submit changes formally for review. * Participate in resulting discussions, mark up and re-review processes. * Repeat until done! Dependencies ============ Successful operation of CalicoMechanismDriver depends on: - https://blueprints.launchpad.net/nova/+spec/vif-type-routed, which allows Nova to create an unbridged virtual interface to a VM. - https://blueprints.launchpad.net/neutron/+spec/dhcp-for-routed-ifs, which enhances the Neutron DHCP agent code to handle DHCP for routed TAP interfaces. Testing ======= This change will be tested by Tempest tests in a third-party CI system, to be set up and operated as described at https://wiki.openstack.org/wiki/NeutronThirdPartyTesting, to test the combination of (i) this spec, (ii) the prerequisite Nova spec [A] to allows Nova to create an unbridged virtual interface to a VM, and (iii) the prerequisite Neutron spec [B] to enable DHCP agent function for VIF_TYPE_ROUTED interfaces. [A] https://blueprints.launchpad.net/nova/+spec/vif-type-routed [B] https://blueprints.launchpad.net/neutron/+spec/dhcp-for-routed-ifs In addition, these changes are being tested by the related development at Project Calico (http://www.projectcalico.org/), and will continue to be so. Tempest Tests ------------- Create VMs on one or more compute hosts, using unbridged networking (i.e. with VIF_TYPE_ROUTED, RoutedInterfaceDriver and the Calico mechanism driver), and verify that they have the expected IP addressing, and the expected connectivity to each other (over both IPv4 and IPv6). Functional Tests ---------------- None beyond the above. API Tests --------- None. Documentation Impact ==================== No documentation changes are anticipated within OpenStack docs, as it appears that existing in-tree mechanism drivers are undocumented, and hence that there is no appropriate place to add to. However the Calico networking concept is extensively described and documented at http://www.projectcalico.org/ and https://github.com/Metaswitch/calico-docs. User Documentation ------------------ As above, this is provided by the Project Calico websites just cited. Developer Documentation ----------------------- As above, this is provided by the Project Calico websites just cited. References ========== http://www.projectcalico.org/ https://github.com/Metaswitch/calico-nova https://github.com/Metaswitch/calico-neutron https://github.com/Metaswitch/calico-dnsmasq ",,268,0
openstack%2Fneutron-specs~master~Iaeb019f1a0fbabf269f5b56e1234ec3858aea4be,openstack/neutron-specs,master,Iaeb019f1a0fbabf269f5b56e1234ec3858aea4be,Blueprint for ML2 Mech Driver for VDX non-AMPP mode,ABANDONED,2014-12-02 23:51:44.000000000,2014-12-19 02:13:54.000000000,,"[{'_account_id': 3}, {'_account_id': 105}]","[{'number': 1, 'created': '2014-12-02 23:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/561d7e33ee2902072010e590f6aec9a1abf61edc', 'message': 'Blueprint for ML2 Mech Driver for VDX non-AMPP mode\n\nThe non-AMPP mode of VDX requires significant changes\nto the way the switch configuration needs to be orchestrated,\nextending the AMPP version of MD is not an straight forward\noption.\n\nChange-Id: Iaeb019f1a0fbabf269f5b56e1234ec3858aea4be\n'}, {'number': 2, 'created': '2014-12-02 23:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d6e42f18b3b6ddb066da56c9da05df51b43bcd56', 'message': 'Blueprint for ML2 Mech Driver for VDX non-AMPP mode\n\nThe non-AMPP mode of VDX requires significant changes\nto the way the switch configuration needs to be orchestrated,\nextending the AMPP version of MD is not an straight forward\noption.\n\nChange-Id: Iaeb019f1a0fbabf269f5b56e1234ec3858aea4be\n'}, {'number': 3, 'created': '2014-12-03 00:13:36.000000000', 'files': ['specs/kilo/ml2-brocade-non-ampp-mechanism-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2277fabc8375ff46db0a2fea69177af9bc593e2f', 'message': 'Blueprint for ML2 Mech Driver for VDX non-AMPP mode\n\nThe non-AMPP mode of VDX requires significant changes\nto the way the switch configuration needs to be orchestrated,\nextending the AMPP version of MD is not an straight forward\noption.\n\nChange-Id: Iaeb019f1a0fbabf269f5b56e1234ec3858aea4be\n'}]",0,138581,2277fabc8375ff46db0a2fea69177af9bc593e2f,8,2,3,5217,,,0,"Blueprint for ML2 Mech Driver for VDX non-AMPP mode

The non-AMPP mode of VDX requires significant changes
to the way the switch configuration needs to be orchestrated,
extending the AMPP version of MD is not an straight forward
option.

Change-Id: Iaeb019f1a0fbabf269f5b56e1234ec3858aea4be
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/81/138581/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ml2-brocade-non-ampp-mechanism-driver.rst'],1,561d7e33ee2902072010e590f6aec9a1abf61edc,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================================== ML2 Mechanism Driver for Brocade VDX Switch (Non-AMPP) ====================================================== https://blueprints.launchpad.net/neutron/+spec/ml2-brocade-non-ampp-mechanism-driver The purpose of this blueprint is to add support for Brocade VDX Switch in Non-AMPP mode in OpenStack neutron as a ML2 mechanism driver. Problem Description =================== Brocade already has mechanism driver for VDX switches, however this is limited to AMPP (Automatic Migration of Port-Profile) mode. AMPP mode brings in automatic configuration of vlans to ports based on traffic from the virtual machine and automates the re-configuration as VMs migrate. However, this mode has limitation of maximum 1024 port-profiles which limits the number of networks that can be created to the same number. Proposed Change =============== Data Model Impact ----------------- In addition to the vendor specific data model defined for the AMPP version of the mechanism driver the non-AMPP version will additionally need to define a table to store the toplogy/connectivity of the switch to the hosts machines. In AMPP version this was not needed as it was automatically discovered and used transparently. REST API Impact --------------- None. Security Impact --------------- None. Notifications Impact -------------------- None. Other End User Impact --------------------- None. Performance Impact ------------------ None. IPv6 Impact ----------- None. Other Deployer Impact --------------------- Configuration of multiple switches will require providing NETCONF managment IP address/username/password for each switch. The deployer will additionally need to specify the connectivity of the switch to the host machines. These should be provided in: /opt/stack/neutron/etc/neutron/plugins/ml2/ml2_conf_vdx_non_ampp.ini Developer Impact ---------------- None. Community Impact ---------------- This change adds a new mechanism driver for ML2 plugin aligned with the community direction. Alternatives ------------ Alternative is to use the AMPP version of the plugin however this can be limiting in very large deployments. Implementation ============== Assignee(s) ----------- Primary assignee: <shivharis> Work Items ---------- Work Items can be roughly divided into the following tasks: * Mechanism driver to handle network/subnet/port CRUD requests. * NETCONF templates * Unit test cases to test the mechanism driver and client code. * Tempest test cases to peform functional testing (CI) Dependencies ============ Following third party library used: * nclient library (NETCCONF client library) Testing ======= Tempest Tests ------------- Third party testing will be provided. The Brocade-Non-AMPP CI will report on all changes affecting this mechanism driver. The testing will run on a setup with an OpenStack deployment connected to VDX switch in non-AMPP mode. This CI will be distinct from the AMPP mode that currently reports as Brocade-VDX-CI. Functional Tests ---------------- New functional tests will be added by mocking the VSM responses. API Tests --------- None. Documentation Impact ==================== User Documentation ------------------ Configuration details for this mechanism driver will be provided in order to deploy this switch/mechanism driver. Developer Documentation ----------------------- None. References ========== http://www.brocade.com/downloads/documents/product_manuals/B_VDX/NOS_NetconfOpsGuide_v300.pdf ",,162,0
openstack%2Fneutron-specs~master~Id5670d80a9e72866ff3fc818ba414984215ed2df,openstack/neutron-specs,master,Id5670d80a9e72866ff3fc818ba414984215ed2df,Specification for ml2-huawei-switch-mech-driver,ABANDONED,2014-12-01 04:02:52.000000000,2014-12-19 02:13:49.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1689}, {'_account_id': 6558}]","[{'number': 1, 'created': '2014-12-01 04:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/419a362c43b2a725a74e9f1c3504c92174a37ffd', 'message': 'Specification for ml2-huawei-switch-mech-driver\n\nChange-Id: Id5670d80a9e72866ff3fc818ba414984215ed2df\n'}, {'number': 2, 'created': '2014-12-01 04:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d986278d7754166899734b64ff80ee822244192e', 'message': 'Specification for ml2-huawei-switch-mech-driver\n\nChange-Id: Id5670d80a9e72866ff3fc818ba414984215ed2df\n'}, {'number': 3, 'created': '2014-12-01 04:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f17f20f5b9fc67d11c1ddf92ddb1be0d70bb3fbe', 'message': 'Specification for ml2-huawei-switch-mech-driver\n\nChange-Id: Id5670d80a9e72866ff3fc818ba414984215ed2df\n'}, {'number': 4, 'created': '2014-12-01 04:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/127231b1384e16a0416265c47caf2aab1eba99a6', 'message': 'Specification for ml2-huawei-switch-mech-driver\n\nChange-Id: Id5670d80a9e72866ff3fc818ba414984215ed2df\n'}, {'number': 5, 'created': '2014-12-01 04:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/bb9c6d308253f87af80c4d6d56476ec53fdc546a', 'message': 'Specification for ml2-huawei-switch-mech-driver\n\nChange-Id: Id5670d80a9e72866ff3fc818ba414984215ed2df\n'}, {'number': 6, 'created': '2014-12-01 05:27:02.000000000', 'files': ['specs/kilo/ml2-huawei-switch-mech-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/77866cf8fde726bb8726ae71e1fb3b9489453444', 'message': 'Specification for ml2-huawei-switch-mech-driver\n\nChange-Id: Id5670d80a9e72866ff3fc818ba414984215ed2df\n'}]",0,137990,77866cf8fde726bb8726ae71e1fb3b9489453444,15,4,6,1978,,,0,"Specification for ml2-huawei-switch-mech-driver

Change-Id: Id5670d80a9e72866ff3fc818ba414984215ed2df
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/90/137990/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ml2-huawei-switch-mech-driver.rst'],1,419a362c43b2a725a74e9f1c3504c92174a37ffd,bp/ml2-huawei-switch-mech-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================== Huawei Switch ML2 Mechanism driver ================================== https://blueprints.launchpad.net/neutron/+spec/ml2-huawei-switch-mech-driver This blueprint is to introduce support for Huawei switches in Neutron as a ML2 mechanism driver. Problem description =================== This blueprint proposes Huawei's modular L2 mechanism driver to automate the provisioning of physical Huawei switches (spine and leaf switches) based on the virtual network configuration in OpenStack Neutron. Proposed change =============== The diagram below provides a brief overview of how the Huawei Switch ML2 Mechanism driver interact with Neutron Server and Huawei switches. +-------------------------+ | Neutron Server | | with ML2 plugin | +------------+ | | | +----------------+ NetConf | | | +-----------------------+ | +-------+ | Huawei Switch +---------------------+ | | | | | ML2 Mechanism | | | | | | | Driver | | | | | | | | +-------------+----+ | | +--------+----------------+ | | | | | | +---------+------+--+ | | +-----------+-------------+ | | | | +-------+ L2 Agent | OVS or +---------+ | Huawei | | | | Linux Bridge| | | switches | | +-----------+-------------+ | | | | | Compute Host 1 | +-+ | | | | +---+---------------+ | +-------------------------+ | | | | +------------+-------------+ | | | L2 Agent | OVS or | | +------------+ | Linux Bridge+--------------+ +------------+-------------+ | Compute Host 2 | | | +--------------------------+ The Huawei Switch ML2 driver will implement CRUD APIs for network, subnets, and ports. It configures the physical switch through NetConf protocol. The Huawei Switch ML2 driver is deisgned to operate togehter with the OVS mechanism driver or Linux bridge for handling network operation and port binding on the compute nodes. The following Neutron events are supported: * Network create/update/delete * Subnet create/update/delete * Port create/update/delete (Note: the driver does not handle port bindingi -- the OVS driver or linux bridge driver already handle it.) Supported network types include vlan and other types will be provided in future. Alternatives ------------ None Data model impact ----------------- This mechanism driver introduces three new tables which are specific to the Huawei Switch mechanism driver. * huawei_switch_tenant: Stores tenant information. * huawei_switch_port: Stores between network and port configuration. * huawei_switch_network: Stores between network and network segmentation (VLAN) information No existing models are changed. REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- The deployer must configure the installation to use the Huawei Switch ML2 mechanism driver with the following configuration variables: * IP address of Huawei switches * Username and password to access Huawei switches' netconf agent * VLAN ranges to be used by OpenStack * Huawei switch with hosts mapping for the compute nodes Additionally, the deployer must configure the ML2 plugin to include Huawei Switch ML2 mechanism driver: :: [ml2] mechanism_drivers = openvswitch,huawei_switch Developer impact ---------------- None Implementation ============== None Assignee(s) ----------- Primary assignee: liaowenqi yapengwu Work Items ---------- Huawei Switch ML2 mechanism driver code Unit tests Huawei CI infrastructure with ML2 driver Dependencies ============ None Testing ======= Unit Test coverage Support for this driver in Huawei CI Documentation Impact ==================== Huawei Switch ML2 Mechanism driver description and configuration details will be added. References ========== https://wiki.openstack.org/wiki/Ml2-huawei-switch-mech-driver ",,196,0
openstack%2Fneutron-specs~master~I27ed6981152618b009d23a552122cdf3f0d28034,openstack/neutron-specs,master,I27ed6981152618b009d23a552122cdf3f0d28034,ML2 Mechanism Driver for Cisco UCS Manager,ABANDONED,2014-11-12 21:30:35.000000000,2014-12-19 02:13:39.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 1689}, {'_account_id': 6558}, {'_account_id': 6598}, {'_account_id': 6685}, {'_account_id': 6697}, {'_account_id': 10370}]","[{'number': 1, 'created': '2014-11-12 21:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0ab8262997ede8cd0371d6b5bf8c82f75bea803f', 'message': 'ML2 Mechanism Driver for Cisco UCS Manager\n\nChange-Id: I27ed6981152618b009d23a552122cdf3f0d28034\nImplements: blueprint ml2-ucs-manager-mechanism-driver\n'}, {'number': 2, 'created': '2014-11-12 21:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d5720c4edfc04e60ce12046150c92c28b3bc67ea', 'message': 'ML2 Mechanism Driver for Cisco UCS Manager\n\nImplements: blueprint ml2-ucs-manager-mechanism-driver\n\nChange-Id: I27ed6981152618b009d23a552122cdf3f0d28034\n'}, {'number': 3, 'created': '2014-11-13 16:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/392d26062e8be954e8aac6e9845ae79410a19914', 'message': 'ML2 Mechanism Driver for Cisco UCS Manager\n\nImplements: blueprint ml2-ucs-manager-mechanism-driver\n\nChange-Id: I27ed6981152618b009d23a552122cdf3f0d28034\n'}, {'number': 4, 'created': '2014-11-13 17:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/61751a5fb8ea55998399b6e9ff53670c1b5de1ba', 'message': 'ML2 Mechanism Driver for Cisco UCS Manager\n\nImplements: blueprint ml2-ucs-manager-mechanism-driver\n\nChange-Id: I27ed6981152618b009d23a552122cdf3f0d28034\n'}, {'number': 5, 'created': '2014-11-17 17:19:43.000000000', 'files': ['specs/kilo/ml2-ucs-manager-mechanism-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/15f1499396101801f1223c37de7476853afc44e6', 'message': 'ML2 Mechanism Driver for Cisco UCS Manager\n\nImplements: blueprint ml2-ucs-manager-mechanism-driver\n\nChange-Id: I27ed6981152618b009d23a552122cdf3f0d28034\n'}]",28,134056,15f1499396101801f1223c37de7476853afc44e6,21,9,5,6697,,,0,"ML2 Mechanism Driver for Cisco UCS Manager

Implements: blueprint ml2-ucs-manager-mechanism-driver

Change-Id: I27ed6981152618b009d23a552122cdf3f0d28034
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/56/134056/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ml2-ucs-manager-mechanism-driver.rst'],1,0ab8262997ede8cd0371d6b5bf8c82f75bea803f,bp/ml2-ucs-manager-mechanism-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== ML2 Mechanism Driver for Cisco UCS Manager ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/ml2-ucs-manager-mechanism-driver The purpose of this blueprint is to add support for Cisco UCS Manager into Openstack Neutron. This plugin for Cisco UCS Manager is implemented as a ML2 mechanism driver. Problem Description =================== This section includes a brief introduction to the SR-IOV and Cisco VM-FEX technologies in addition to a detailed description of what the mechanism driver is trying to achieve: 1. This mechanism driver needs to be able to configure Cisco VM-FEX on specific Cisco NICs on the UCS by communicating with a UCS Manager. 2. Cisco VM-FEX technology is based on SR-IOV technology which allows a single PCIe physical device (PF - physical function) to be divided into multiple logical devices (VF - virtual functions). For more details on Cisco VM-Fex technology, please refer to [1]. 3. With SR-IOV and Cisco VM-FEX a VM's port can be configured in either the ""direct"" or ""macvtap"" modes. In the ""direct"" mode, the VM's port is connected directly to the VF and to a macvtap device on the host in the ""macvtap"" mode. In both these modes, the VM's traffic completely bypasses the hypervisor, sending and receiving traffic directly to and from the vNIC and thus the upstream switch. This results in a significant increase in throughput on the VM and frees up CPU resources on the host OS to handle more VMs. Due to this direct connection with the upstream switch, the ""direct"" mode does not support live migration of the VMs that it is attached to. 4. Cisco VM-FEX technology is based on the 802.1qbh and works on top of the SR-IOV technology using the concept of port profiles. Port profiles are configuration entities that specify additional config that needs to be applied on the VF. This config includes the vlan-id, QoS (not applicable in Openstack for now) and the mode (direct/macvtap). 5. This mechanism driver needs to configure port profiles on the UCS Manager and pass this port profile to Nova so that it can stick it into the VM's domain XML file. 6. This mechanism driver is responsible for creating, updating and deleting port profiles in the UCS Manager and maintaining the same info in a local DB. 7. This mechanism driver also needs to support SR-IOV capable Intel NICs on the UCS servers. 8. Security groups cannot be applied on SR-IOV and VM-FEX ports because no TAP devices exist on the compute nodes. (Since the SR-IOV VFs appear as interfaces on the upstream switch, ACLs can be applied on the VFs at the upstream switch.) This does not seem like an issue in the NFV use case. Also, when changes proposed by the port security extension become available, security groups can be turned off for SR-IOV ports. 9. The mechanism driver should also be able to program the UCS Manager during the creation of regular non-SR-IOV based VMs. To achieve this, the mechanism driver needs to manipulate the Service Profile associated with the UCS Server where the VM is being launched. 10. Security groups can continue to be applied on non-SR-IOV ports. 11. The UCS Manager runs on the Fabric Interconnet which among other functions, provides connectivity between the UCS Server and the upstream switch. The mechanism driver needs to provide connectivity to SR-IOV and non-SR-IOV ports attached to VMs by creating/maintaining VLAN configuration on the above mentioned Fabric Interconnect. Proposed Change =============== 1. This ML2 mechanism driver communicates to the UCS manager via UCS Python SDK. 2. There is no need for a L2 agent to be running on the compute host to configure the SR-IOV and VM-FEX ports. Although, for non-SR-IOV ports, we would continue to use an L2 agent on the compute host. 3. The ML2 mechanism driver takes care of binding an SR-IOV port if the pci vendor info in the binding:profile portbinding attribute matches the pci device attributes of the SR-IOV devices it can handle. 4. The mechanism driver also expects to get the physical network information as part of port binding:profile at the time of bind port. 5. When a SR-IOV port is being bound to a VM, the mechanism driver uses the segmentation-id associated with the network to determine if a new port profile needs to be created. According to the DB maintained by the ML2 driver, if a port profile with that vlan_id already exists, then it re-uses this port profile for the neutron port being created. 6. If the mechanism driver determines that an existing port profile cannot be re-used it tries to create a new port profile on the UCS manager using the vlan_id from the network. Since port profile is a vendor specific entity, we did not want to expose this to the cloud admin or the tenant. So, port profiles are created and maintained completely behind the scenes by the ML2 driver. 7. Port profiles created by this mechanism driver will have the name ""OS-PP-<vlan-id>"". The process of creating a port profile on the UCS Manager involves: A. Connecting to the UCS manager and starting a new transaction B. Creating a Fabric Vlan managed object corresponding to the vlan-id C. Creating a vNIC Port Profile managed object that is associated with the above Fabric Vlan managed object. D. Creating a Profile Client managed object that corresponds to the vNIC Port Profile managed object. E. Ending the current transaction and disconnecting from UCS maanager 8. Once the above entities are created on the UCS manager, the ML2 driver populates the profile:vif_details portbindings attribute with the profile_id (name of the port profile). Nova then uses Neutron V2 API to grab the profile_id and populates the VM's domain XML. After the VM is successfully launched by libvirt, the configuration of VM-FEX is complete. 9. In the case of NICs that support SR-IOV and not VM-FEX (for example, the Intel NIC), the portbinding profile:vif_details attribute is populated with the vlan_id. This vlan_id is then written into the VM's domain XML file by Nova's generic vif driver. 10. In the case of non-SR-IOV or regular neutron ports, an L2 agent on the compute host takes care of configuring the neutron port on the server's hypervisor. The mechanism driver programs the Fabric Interconnect to allow traffic on the VLAN-id associated with this port by manipulating the Service Profile configuartion on the UCS Manager. Data Model Impact ----------------- One new data model is created by this driver to keep track of port profiles created by Openstack. Other port profiles can exist on the UCS Manager that this driver does not care about. PortProfile: Tracks the vlan-id of the port associated with a given port profile. __tablename__ = 'ml2_ucsm_config' vlan_id = sa.Colum(sa.Integer(), nullable=False) profile_id = sa.Column(sa.String(64), nullable=False, primary_key=True) created_on_ucsm = sa.Column(sa.Boolean(), nullable=False) The profile_id to port_id mapping is kept track of via ml2_port_bindings table where the profile_id is stored in vif_details. As the name suggests, created_on_ucsm is a flag that keeps track of whether a Port Profile was successfully created on the UCS Manager. If not, when another VM is lauched on the same VLAN, another attempt is made at creating the same Port Profile, making this a retry mechanism of sorts. REST API Impact --------------- None. Security Impact --------------- None.[Security groups cannot be applied on SR-IOV ports as explained earlier.] Notifications Impact -------------------- None. Other End User Impact --------------------- No end user impact. Performance Impact ------------------ The ML2 driver code would have to conditionally communicate with the UCS Manager to configure, update or delete Port Profiles, update Service Profiles and associated configuration. These tasks would have a performance impact on Neutron's responsiveness to a command that affects port config. Other Deployer Impact --------------------- The deployer must provide the following in order to be able to connect to a UCS Manager and add support for SR-IOV ports. 1. IP address of UCS Manager. 2. Admin Username and password to log into UCS Manager. 3. Add ""cisco_ucsm"" as a ML2 driver to handle SR-IOV port configuration. 4. Add the ""vlan"" type driver. Currently, this mechansim driver supports only the VLAN type driver. These should be provided in: /opt/stack/neutron/etc/neutron/plugins/ml2/ml2_conf_cisco.ini. Example: [ml2_cisco_ucsm] # Hostname for UCS Manager # ucsm_ip=1.1.1.1 # Username for the UCS Manager # ucsm_username=username # Password for UCS Manager # ucsm_password=password # UCS Manager Host to Service Profile mapping # ucsm_host_list = {""hostname1"":""service_profile1"", ""hostname2"":""service_profile2""} The deployer should also install the Cisco UCS Python SDK for this ML2 mechanism driver to connect and configure the UCS Manager. The SDK and install instructions can be found at: https://github.com/CiscoUcs/UcsPythonSDK. Developer Impact ---------------- None. Community Impact ---------------- SR-IOV is an important enabler for NFV and can be implemented only as a vendor specific feature. SR-IOV in general and this mechanism driver has been discussed in the ML quite a bit and has received some attention in the ML2 subteam. Alternatives ------------ SR-IOV and VM-FEX (Cisco specific extension to SR-IOV) are tightly coupled with the features supported on the HW NICs on the host m/cs. There are several vendors that provide this functionality. Implementation ============== Assignee(s) ----------- Sandhya Dasu is responsible for providing the implementation associated with this BP. Primary assignee: sadasu Other contributors: None Work Items ---------- Configuration of SR-IOV ports was attempted in Juno was very close to being merged. The configuration of non-SR-IOV ports is new for Kilo. Dependencies ============ * This mechanism driver is not dependent on any other Neutron BP, but will be affected by ML2 Hierarchical Port Binding [2] and Port Security extension [3] specs. * This mechanism driver communicates with the UCS Manager through the UCS SDK that can be found at : https://github.com/CiscoUcs/UcsPythonSDK. Version 0.8.2 of the UCS SDK is being used during the development of this mechanism driver. Testing ======= Tempest tests are going to be added to specifically test the SR-IOV features as part of Kilo.Third party tempest testing will be provided for this mechanism driver. Cisco CI will start reporting on all changes affecting this driver. The third party tempest tests will run on a setup which runs Openstack (devstack) code on a multi-node setup that is connected to a UCS Manager system. Tempest Tests ------------- New tempest tests would be added to test SR-IOV functionality but a link to those are not yet available. Functional Tests ---------------- New functional tests are still being worked on for the SR-IOV feature which will further test this mechanism driver. API Tests --------- No API changes so no new API tests are being added as a result of this mechanism driver. Documentation Impact ==================== Details regarding configuring this mechanism driver has to be documented. User Documentation ------------------ No existing user documentation needs to be changed as a result of this spec. Developer Documentation ----------------------- No API changes are being made. References ========== * [1] Information in Cisco VM-FEX: http://www.cisco.com/c/en/us/solutions/data-center-virtualization/data-center-virtual-machine-fabric-extender-vm-fex/index.html * [2] https://blueprints.launchpad.net/neutron/+spec/ml2-hierarchical-port-binding * [3] https://blueprints.launchpad.net/neutron/+spec/ml2-ovs-portsecurity * [4] Here is the link to the larger discussion around PCI passthrough ports: https://wiki.openstack.org/wiki/Meetings/Passthrough * [5] Useful links on VM-FEX - http://www.cisco.com/c/en/us/solutions/data-center-virtualization/data-center-virtual-machine-fabric-extender-vm-fex/index.html and https://www.youtube.com/watch?v=8uCU9ghxJKg ",,345,0
openstack%2Fneutron-specs~master~I1c2138f877e683285b8ac1d292a9b4edaa78cd9c,openstack/neutron-specs,master,I1c2138f877e683285b8ac1d292a9b4edaa78cd9c,Add spec for ML2 mechanism driver for SDN-VE,ABANDONED,2014-10-31 12:26:51.000000000,2014-12-19 02:13:30.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 1923}, {'_account_id': 2592}, {'_account_id': 6697}, {'_account_id': 6854}, {'_account_id': 9970}, {'_account_id': 12223}]","[{'number': 1, 'created': '2014-10-31 12:26:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4245c69cde67781d12b7358b4a04931d51f7940b', 'message': 'Add spec for ML2 mechanism driver for SDN-VE\n\nAdds the specification for a new ML2 mechanism driver for SDN-VE,\nthe IBM SDN controller.\n\nChange-Id: I1c2138f877e683285b8ac1d292a9b4edaa78cd9c\n'}, {'number': 2, 'created': '2014-11-05 08:09:35.000000000', 'files': ['specs/kilo/ml2-ibm-sdnve-mechanism-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0e4a47d17a924c0e37f1516f45089776fd153733', 'message': 'Add spec for ML2 mechanism driver for SDN-VE\n\nAdds the specification for a new ML2 mechanism driver for SDN-VE,\nthe IBM SDN controller.\n\nChange-Id: I1c2138f877e683285b8ac1d292a9b4edaa78cd9c\n'}]",8,132226,0e4a47d17a924c0e37f1516f45089776fd153733,18,9,2,12223,,,0,"Add spec for ML2 mechanism driver for SDN-VE

Adds the specification for a new ML2 mechanism driver for SDN-VE,
the IBM SDN controller.

Change-Id: I1c2138f877e683285b8ac1d292a9b4edaa78cd9c
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/26/132226/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ml2-ibm-sdnve-mechanism-driver.rst'],1,4245c69cde67781d12b7358b4a04931d51f7940b,bp/ml2-ibm-sdnve-mechanism-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================== ML2 Mechanism Driver for IBM SDN-VE Controller ============================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/ml2-ibm-sdnve-mechanism-driver This blueprint is for adding support for IBM SDN-VE controller through a new mechanism driver. Problem Description =================== SDN-VE is a controller that provides network virtualization and support for software defined networking. In order to utilize SDN-VE with OpenStack, we need to provide a plugin or mechanism driver for this controller. Proposed Change =============== We propose the addition of a new ML2 mechanism driver for supporting SDN-VE controller. The proposed mechanism driver will mainly act as a pass through driver responsible for passing incoming Neutron requests to the controller through the SDN-VE REST API (after preprocessing the requests as needed and also processing received responses from the controller). Data Model Impact ----------------- None REST API Impact --------------- None Security Impact --------------- None Notifications Impact -------------------- None Other End User Impact --------------------- None Performance Impact ------------------ None Other Deployer Impact --------------------- None Developer Impact ---------------- None Community Impact ---------------- None Alternatives ------------ None Implementation ============== Assignee(s) ----------- Mamta Prabhu <mamprabhu@in.ibm.com> Work Items ---------- * Developing a library for communication with SDN-VE * Developing the mechanism driver * Deprecate the monolithic SDN-VE plugin Dependencies ============ None Testing ======= Unit test coverage will be provided. Tempest Tests ------------- Since access to the SDN-VE controller is required for testing the proposed cahnges, the 3rd party testing is essential. We will use the current CI being used for the monolithic SDN-VE plugin while we create a new and improved zuul based CI system. Functional Tests ---------------- None API Tests --------- None Documentation Impact ==================== None User Documentation ------------------ The configuration and deployment steps will be update in the Openstack wiki. Developer Documentation ----------------------- None References ========== None ",,148,0
openstack%2Fneutron-specs~master~Ie299e5f93bfd62f55001f48ec95bf87c41279e76,openstack/neutron-specs,master,Ie299e5f93bfd62f55001f48ec95bf87c41279e76,State synchronization for Cisco N1KV plugin,ABANDONED,2014-10-10 17:41:19.000000000,2014-12-19 02:13:18.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2592}, {'_account_id': 7018}, {'_account_id': 8940}, {'_account_id': 11757}, {'_account_id': 12749}]","[{'number': 1, 'created': '2014-10-10 17:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c622f3769a6397c3cb19bebe358db82af54701f7', 'message': 'State synchronization for Cisco N1KV plugin\n\nAdd spec to support state synchronization between neutron DB and\nthe Cisco N1KV controller (VSM).\n\nChange-Id: Ie299e5f93bfd62f55001f48ec95bf87c41279e76\n'}, {'number': 2, 'created': '2014-11-01 01:35:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/85126bb276d32398194199a680bbde3f749ae56a', 'message': 'State synchronization for Cisco N1KV plugin\n\nAdd spec to support state synchronization between neutron DB and\nthe Cisco N1KV controller (VSM).\n\nChange-Id: Ie299e5f93bfd62f55001f48ec95bf87c41279e76\n'}, {'number': 3, 'created': '2014-11-01 01:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0f8d25667f2b052894e43152e215ca2bdad8967b', 'message': 'State synchronization for Cisco N1KV plugin\n\nAdd spec to support state synchronization between neutron DB and\nthe Cisco N1KV controller (VSM).\n\nChange-Id: Ie299e5f93bfd62f55001f48ec95bf87c41279e76\n'}, {'number': 4, 'created': '2014-11-01 01:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/441e24a9ced8d9a3fb1dd9b6e3be347bc0cdda15', 'message': 'State synchronization for Cisco N1KV plugin\n\nAdd spec to support state synchronization between neutron DB and\nthe Cisco N1KV controller (VSM).\n\nChange-Id: Ie299e5f93bfd62f55001f48ec95bf87c41279e76\n'}, {'number': 5, 'created': '2014-11-07 21:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/1134cafc5ea520239708f73968413fd61fbeb8fb', 'message': 'State synchronization for Cisco N1KV plugin\n\nAdd spec to support state synchronization between neutron DB and\nthe Cisco N1KV controller (VSM).\n\nChange-Id: Ie299e5f93bfd62f55001f48ec95bf87c41279e76\n'}, {'number': 6, 'created': '2014-11-07 22:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d283be51856661eec8a1bc2877b4ba089c97e463', 'message': 'State synchronization for Cisco N1KV plugin\n\nAdd spec to support state synchronization between neutron DB and\nthe Cisco N1KV controller (VSM).\n\nChange-Id: Ie299e5f93bfd62f55001f48ec95bf87c41279e76\n'}, {'number': 7, 'created': '2014-11-07 22:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ee262b865cb473c244d385142b3945c41ef50332', 'message': 'State synchronization for Cisco N1KV plugin\n\nAdd spec to support state synchronization between neutron DB and\nthe Cisco N1KV controller (VSM).\n\nChange-Id: Ie299e5f93bfd62f55001f48ec95bf87c41279e76\n'}, {'number': 8, 'created': '2014-11-19 23:38:17.000000000', 'files': ['specs/kilo/cisco-n1kv-full-sync.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5a5319c5338002c1ebfb0deed234e2a2f04a63d0', 'message': 'State synchronization for Cisco N1KV plugin\n\nAdd spec to support state synchronization between neutron DB and\nthe Cisco N1KV controller (VSM).\n\nChange-Id: Ie299e5f93bfd62f55001f48ec95bf87c41279e76\n'}]",0,127606,5a5319c5338002c1ebfb0deed234e2a2f04a63d0,22,7,8,9680,,,0,"State synchronization for Cisco N1KV plugin

Add spec to support state synchronization between neutron DB and
the Cisco N1KV controller (VSM).

Change-Id: Ie299e5f93bfd62f55001f48ec95bf87c41279e76
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/06/127606/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/cisco-n1kv-full-sync.rst'],1,c622f3769a6397c3cb19bebe358db82af54701f7,full-sync-specs,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Add the capability to sync neutron resources to the N1KV VSM ============================================================ https://blueprints.launchpad.net/neutron/+spec/cisco-n1kv-full-sync The purpose of this blueprint is to add support to synchronize the state of neutron database with Cisco N1KV controller (VSM). Problem description =================== Today if there is any inconsistency in the state of neutron and the VSM databases, there is no way to push all the neutron configuration back into the VSM. Proposed change =============== The proposed change is to introduce support for state synchronization between neutron and VSM in the N1KV plugin. Creates and updates of resources are rolled back in neutron if an error is encountered on the VSM. In case the VSM loses its config, a sync is triggered from the neutron plugin. The sync compares the resources present in neutron DB with those in the VSM. It issues creates or deletes as appropriate in order to synchronize the state of the VSM with that of the neutron DB. Deletes cannot be rolled back in neutron. If a resource delete fails on the VSM due to connection failures, neutron will attempt to synchronize that resource periodically. The full sync will be triggered based on a boolean config parameter i.e. enable_sync_on_start. If ""enable_sync_on_start"" is True, neutron will attempt to synchronize its state with that of VSM. If ""enable_sync_on_start"" is set to False, neutron will not attempt any state sync. This blueprint will introduce a bare minimum capability of synchronizing resources. It does not cover out-of-sync detection logic. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: abhraut Work Items ---------- * Add logic to the plugin module to push database state to the VSM. * Add configuration parameter in cisco_plugins.ini Dependencies ============ None Testing ======= Unit tests will be provided. Documentation Impact ==================== Update documentation to reflect the new configuration parameter. References ========== None ",,125,0
openstack%2Fneutron-specs~master~I6be36b10e2167d0ce1a202bc63f9065732527a31,openstack/neutron-specs,master,I6be36b10e2167d0ce1a202bc63f9065732527a31,Add spec for L3 service plugin for IBM SDN-VE,ABANDONED,2014-10-31 13:08:10.000000000,2014-12-19 02:12:59.000000000,,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 2592}, {'_account_id': 6854}, {'_account_id': 7021}, {'_account_id': 9970}]","[{'number': 1, 'created': '2014-10-31 13:08:10.000000000', 'files': ['specs/kilo/ibm-sdnve-l3-service-agent.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/14b4ab17850871de2cbc492f34fbdcd76787be77', 'message': 'Add spec for L3 service plugin for IBM SDN-VE\n\nAdds the specification for a new L3 Service plugin for SDN-VE,\nthe IBM SDN controller.\n\nChange-Id: I6be36b10e2167d0ce1a202bc63f9065732527a31\n'}]",1,132242,14b4ab17850871de2cbc492f34fbdcd76787be77,9,6,1,12223,,,0,"Add spec for L3 service plugin for IBM SDN-VE

Adds the specification for a new L3 Service plugin for SDN-VE,
the IBM SDN controller.

Change-Id: I6be36b10e2167d0ce1a202bc63f9065732527a31
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/42/132242/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ibm-sdnve-l3-service-agent.rst'],1,14b4ab17850871de2cbc492f34fbdcd76787be77,bp/ibm-sdnve-l3-service-agent,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================== ML2 Mechanism Driver for IBM SDN-VE Controller ============================================== https://blueprints.launchpad.net/neutron/+spec/ibm-sdnve-l3-service-agent This blueprint is for adding L3 support for IBM SDN-VE Controller. Problem Description =================== The IBM ML2 driver manages the networks, subnets and ports for the controller. However, the controller additional support L3 functionality as well. To support the L3 routing feature a new service plugin is required which will work along-side the ml2 plugin to support complete L3 functionally for the controller. Proposed Change =============== This proposed l3 service plugin will mainly act as a pass through driver responsible for passing incoming Neutron l3 requests to the controller through the SDN-VE REST API (after preprocessing the requests as needed and also processing received responses from the controller). The service plugin will enable in providing full l3 provisioning on the SDN-VE Controller. Data Model Impact ----------------- None REST API Impact --------------- None Security Impact --------------- None Notifications Impact -------------------- None Other End User Impact --------------------- None Performance Impact ------------------ None Other Deployer Impact --------------------- The SDN-VE service plugin specific configuration parameters that are to be provided by deployers will be specified in the updated documentation. These parameters include the address and credentials required for accessing the SDN-VE controller. Developer Impact ---------------- None Community Impact ---------------- None Alternatives ------------ None Implementation ============== Assignee(s) ----------- Mamta Prabhu <mamprabhu@in.ibm.com> Work Items ---------- L3 Service Plugin Dependencies ============ None Testing ======= Unit test coverage will be provided. Tempest Tests ------------- Since access to the SDN-VE controller is required for testing the proposed cahnges, the 3rd party testing is essential. We will use the current CI being used for the monolithic SDN-VE plugin while we create a new and improved zuul based CI system. Functional Tests ---------------- None API Tests --------- None Documentation Impact ==================== Documentation needs to be updated to reflect the addition of a new service plugin with new configuration parameters. User Documentation ------------------ The configuration and deployment steps will be update in the Openstack wiki. Developer Documentation ----------------------- None References ========== None ",,154,0
openstack%2Fneutron-specs~master~Ife9c41b90155e9f6693a5a29e111f3e3c5927e35,openstack/neutron-specs,master,Ife9c41b90155e9f6693a5a29e111f3e3c5927e35,Huawei SDN Mechanism Driver for ML2 Plugin,ABANDONED,2014-10-29 08:49:54.000000000,2014-12-19 02:11:57.000000000,,"[{'_account_id': 3}, {'_account_id': 2592}]","[{'number': 1, 'created': '2014-10-29 08:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/fa0d9e1928e76abc57c0713469ae743c38a08af5', 'message': 'Huawei SDN Mechanism Driver for ML2 Plugin\n\nresubmit Huawei MD after approving in juno because code review\nhave not catch up with juno\n\nChange-Id: Ife9c41b90155e9f6693a5a29e111f3e3c5927e35\n'}, {'number': 2, 'created': '2014-10-29 09:08:32.000000000', 'files': ['specs/kilo/huawei-ml2-mechanism-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/bc2374bc88213d375f1276c7bf09d3cfa726a2bd', 'message': 'Huawei SDN Mechanism Driver for ML2 Plugin\n\nresubmit Huawei MD after approving in juno because code review\nhave not catch up with juno\n\nChange-Id: Ife9c41b90155e9f6693a5a29e111f3e3c5927e35\n'}]",0,131670,bc2374bc88213d375f1276c7bf09d3cfa726a2bd,7,2,2,8646,,,0,"Huawei SDN Mechanism Driver for ML2 Plugin

resubmit Huawei MD after approving in juno because code review
have not catch up with juno

Change-Id: Ife9c41b90155e9f6693a5a29e111f3e3c5927e35
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/70/131670/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/huawei-ml2-mechanism-driver.rst'],1,fa0d9e1928e76abc57c0713469ae743c38a08af5,bp/huawei-ml2-mechanism-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Huawei ML2 mechanism driver ========================================== https://blueprints.launchpad.net/neutron/+spec/huawei-ml2-mechanism-driver * HW-SDN MD : Huawei SDN Mechanism Driver * HW-SDN CR : Huawei SDN Controller The purpose of this blueprint is to build an ML2 Mechanism Driver for Huawei software define network (SDN) controller, which proxies RESTful calls (formatted for Huawei SDN controller) from ML2 plugin of Neutron to Huawei SDN controller. Huawei SDN controller enables network automation and provision to simplify virtual machine deployments and move on a larger layer 2 network. When a cloud administrator provisions VMs, instances of network flow rules are automatically created and applied to the OpenvSwitch(OVS) which hosted on each compute node. As VMs move across the compute nodes, the network flow rules are automatically applied to each OVS. Problem description =================== Huawei SDN controller requires information of OpenStack Neutron based networks and ports to manage virtual network appliances and OVS flow rules. In order to recieve such information from neutron service, a new ML2 mechanism driver is needed to post the _postcommit data to Huawei SDN controller. The following sections describe the proposed changes in Neutron, a new ML2 mechanism driver, and make it possible to use OpenStack in Huawei SDN topology. The following diagram depicts the OpenStack deployment in Huawei SDN topology. Huawei SDN Topology:: +-----------------------+ +----------------+ | | | | | OpenStack | | | | Controller | | | | Node | | | | | | | | +---------------------+ | Huawei SDN | | |Huawei SDN mechanism | REST API | controller | | |driver |--------------| | | | | | | +-+--------+-----+------+ +--+----------+--+ | | | | | | | | | +--------------+ | | | | | | +----------+---------+ +---+---------+------+ | | | | | | | OVS | | OVS | | +--------------------+ ---- +--------------------+ | | OpenStack compute | | OpenStack compute | | | node 1 | | node n | | +----------+---------+ +--------------------+ | | | | | +-----------------------------------------+ As shown in the diagram above, each OpenStack compute node is connected to Huawei SDN controller, which is responsible for provisioning, monitoring and troubleshooting of cloud network infrastructures. The Neutron API requests will be proxied to SDN controller, then network topology information can be built. When a VM instance starts to communicate with another, the first packet will be pushed to Huawei SDN controller by OVS, then the flow rules will be calculated and applied to related compute nodes by SDN controller. Finally, OVS follows the rules to forward packets to the destination instance. Proposed change =============== The requirements for ML2 mechanism driver to support huawei SDN controller are as follow: 1. SDN controller exchanges information with OpenStack controller node by using REST API. To support this, we need a specific client. 2. OpenStack controller (Neutron configured with ML2 plugin) must be configured with SDN controller access credentials. 3. The network, subnet and port information should be sent to SDN controller when network or port is created, updated, or deleted. 4. SDN controller address should be set on OVS. SDN controller will detect port change and calculate flow tables based on network information sent from OpenStack controller. These flow tables will be applied on OVS on related compute nodes. Huawei Mechanism driver handles the following postcommit operations. Network create/update/delete Subnet create/update/delete Port create/delete Supported network types include vlan and vxlan. Huawei SDN mechanism driver handles VM port binding within the mechanism driver. 'bind_port' function verifies the supported network types (vlan, vxlan) and calls context.set_binding with binding details. Huawei SDN Controller manages the flows required on OVS, so we don't have an extra agent. Sequence flow of events for create_network is as follow: :: create_network { neutron -> ML2_plugin ML2_plugin -> HW-SDN-MD HW-SDN-MD -> HW-SDN-CR HW-SDN-MD <-- HW-SDN-CR ML2_plugin <-- HW-SDN-MD neutron <-- ML2_plugin } Port binding task is handled within the mechanism driver, So OVS mechanism driver is not required when this mechanism driver is enabled. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- Recently a feature of enabling OVS secure mode was added to the OVS agent. Huawei SDN controller doesn't rely on the OVS agent but secure mode will be enabled when deploying Huawei SDN controller and OVS. Notifications impact -------------------- None Other end user impact --------------------- This change doesn't take immediate effect. 1. Configuration parameters regarding SDN (such as ip address,...) should be added to the mechanism driver configuration file. Update /etc/neutron/plugins/ml2/ml2_conf_huawei.ini, as follow: :: [ml2_Huawei] nos_host = 128.100.1.7 nos_port = 8080 2. An SDN controller account should be created for OpenStack to access, also this account should be added to the mechanism driver configuration file. Update /etc/neutron/plugins/ml2/ml2_conf_huawei.ini, as follow: :: [ml2_Huawei] nos_username = admin nos_password = my_password Performance Impact ------------------ There are create/update/delete_<resource>_postcommit functions to proxy those requests to SDN controller in the ML2 mechanism driver. All those processes require database access in SDN controller, which may impact the Neutron API performance a little. Other deployer impact --------------------- This change doesn't take immediate effect. 1. Add new configuration options for SDN controller, which are ip address and credentials. Update /etc/neutron/plugins/ml2/ml2_conf_huawei.ini, as follow: :: [ml2_Huawei] nos_host = 128.100.1.7 nos_port = 8080 nos_username = admin nos_password = my_password 2. Configure parameters of section ml2_type_vxlan in ml2_conf.ini, setting vni_ranges for vxlan network segment ids and vxlan_group for multicast. Update /etc/neutron/plugins/ml2/ml2_conf.ini, as follow: :: [ml2_type_vxlan] vni_ranges = 1001:2000 vxlan_group = 239.1.1.1 Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: yangxurong Work Items ---------- 1. Change the setup.cfg to introduce 'huawei' as the mechanism driver. 2. An REST client for SDN controller should be developed first. 3. Mechanism driver should implement create/update/delete_resource_postcommit. 4. Test connection between two new instances under different subnets. Dependencies ============ None Testing ======= 1. The whole setup can be deployed using OVS and SDN controller can be deployed in VM. 2. For each module added to the mechanism driver, unit test is provided. 3. Functional testing with tempest will be provided. The third-party Huawei CI report will be provided to validate this ML2 mechanism driver. Documentation Impact ==================== Huawei SDN mechanism driver description and configuration details will be added. References ========== https://review.openstack.org/#/c/68148/ ",,268,0
openstack%2Fneutron-specs~master~Id7c466a889395a18027d8ef97545473375b9cb50,openstack/neutron-specs,master,Id7c466a889395a18027d8ef97545473375b9cb50,Multi VSM support for Cisco Nexus 1000V,ABANDONED,2014-10-31 00:20:28.000000000,2014-12-19 02:11:38.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 10068}, {'_account_id': 13660}]","[{'number': 1, 'created': '2014-10-31 00:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9be0fe2a1700bae9072eb140c0851a0197a6ce79', 'message': 'Multi VSM support for Cisco Nexus 1000V\n\nThe purpose of this blueprint is to add support for Multiple Cisco Nexus1000V\nVirtual Supervisor Module (VSM) to Cisco Nexus1000V ML2 Driver.\n\nChange-Id: Id7c466a889395a18027d8ef97545473375b9cb50\n'}, {'number': 2, 'created': '2014-10-31 00:42:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9e94bdd1c9f58df71fb86bfafbb2b9a6e480216d', 'message': 'Multi VSM support for Cisco Nexus 1000V\n\nThe purpose of this blueprint is to add support for Multiple Cisco Nexus1000V\nVirtual Supervisor Module (VSM) to Cisco Nexus1000V ML2 Driver.\n\nChange-Id: Id7c466a889395a18027d8ef97545473375b9cb50\n'}, {'number': 3, 'created': '2014-10-31 00:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4c0c9a9217bbf2875e8d570528609b36ab80172b', 'message': 'Multi VSM support for Cisco Nexus 1000V\n\nThe purpose of this blueprint is to add support for Multiple Cisco Nexus1000V\nVirtual Supervisor Module (VSM) to Cisco Nexus1000V ML2 Driver.\n\nChange-Id: Id7c466a889395a18027d8ef97545473375b9cb50\n'}, {'number': 4, 'created': '2014-10-31 01:09:20.000000000', 'files': ['specs/kilo/cisco-n1kv-multi-vsm-support.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a2ad60ea18dd778bd8d8743e69b35a877db83f04', 'message': 'Multi VSM support for Cisco Nexus 1000V\n\nThe purpose of this blueprint is to add support for Multiple Cisco Nexus1000V\nVirtual Supervisor Module (VSM) to Cisco Nexus1000V ML2 Driver.\n\nChange-Id: Id7c466a889395a18027d8ef97545473375b9cb50\n'}]",0,132138,a2ad60ea18dd778bd8d8743e69b35a877db83f04,12,4,4,13660,,,0,"Multi VSM support for Cisco Nexus 1000V

The purpose of this blueprint is to add support for Multiple Cisco Nexus1000V
Virtual Supervisor Module (VSM) to Cisco Nexus1000V ML2 Driver.

Change-Id: Id7c466a889395a18027d8ef97545473375b9cb50
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/38/132138/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/cisco-n1kv-multi-vsm-support.rst'],1,9be0fe2a1700bae9072eb140c0851a0197a6ce79,bp/is,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================= Multi VSM support for Cisco Nexus 1000V ======================================= https://blueprints.launchpad.net/neutron/+spec/cisco-n1kv-multi-vsm-support The purpose of this blueprint is to add support for Multiple Cisco Nexus1000V Virtual Supervisor Module (VSM) to Cisco Nexus1000V ML2 Driver. Problem Description =================== Cisco Nexus 1000V for KVM is a distributed virtual switch that works with the Linux Kernel-based virtual machine (KVM) open source hypervisor. * Virtual Supervisor Module (VSM): Controller of the Cisco Nexus1000V distributed virtual switch based on Cisco NX-OS software. * Network Profiles: Container for one or more networks. VLAN and VXLAN type of network profiles will be supported in the initial version. * Policy Profiles: Policy profiles are the primary mechanism by which network policy is defined and applied to VM ports in a Nexus 1000V system. Currently the Openstack Neutron has support to talk to one VSM through REST API and this limits the number of hosts supported to 512. This blueprint proposes the first step to add support for multiple VSM. Credential set for multiple VSMs will be accepted in the cisco_plugins.ini. Policy profiles common to the all VSMs would be displayed to the admin user. Network profiles, networks, subnets and ports created by the admin will be pushed to all VSMs. Optimizations will be done in phases. Proposed Change =============== The cisco_plugins.ini will accept multiple sections of the below VSM credential. # [N1KV:<IP address of VSM>] # username=<credential username> # password=<credential password> Cisco policy profile table will be expanded to include VSM IP from which the policy profile is derived. Only if a policy profile exists on all VSMs,the user will be allowed to use it during instance creation. The network profiles, networks, subnets and ports created will be pushed to all the VSMs. In case of failure of any REST api, the operation will be rolled back from the neutron database. Data Model Impact ----------------- This change does not introduce any new tables. cisco_policy_profiles table will have an additional column to store the VSM IPs REST API Impact --------------- None. Security Impact --------------- None. Notifications Impact -------------------- None. Other End User Impact --------------------- None. Performance Impact ------------------ None Other Deployer Impact --------------------- The Deployer has the option to provide multiple VSM credential set in the cisco_plugins.ini. Developer Impact ---------------- None. Community Impact ---------------- None Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: <shivrao> Other contributors: <rmanam>, <abhraut>, <sopatwar> Work Items ---------- Work Items can be roughly divided into the following tasks: * Add logic to retrieve multiple VSM credentials from the config * Extend the cisco policy profile table to include VSM IPs and logic to retrieve them. * Modify RESTful methods to replicate communication with all VSMs Dependencies ============ None Testing ======= Tempest Tests ------------- The Cisco CI setup will be updated with an OpenStack deployment connected to multiple VSM. Functional Tests ---------------- New functional tests will be added by mocking multiple VSM responses. API Tests --------- None. Documentation Impact ==================== User Documentation ------------------ Configuration details for multi - VSM configuration. Developer Documentation ----------------------- None. References ========== http://www.cisco.com/go/nexus1000v ",,177,0
openstack%2Fnova-specs~master~I8ba44561824eb6634239b006f0e600daa0be6f1f,openstack/nova-specs,master,I8ba44561824eb6634239b006f0e600daa0be6f1f,Propose: Allow Nova to use either Glance V1 or V2,ABANDONED,2014-04-02 22:47:48.000000000,2014-12-19 02:04:19.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 616}, {'_account_id': 782}, {'_account_id': 964}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2537}, {'_account_id': 2861}, {'_account_id': 3031}, {'_account_id': 4393}, {'_account_id': 5347}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 6873}, {'_account_id': 7400}, {'_account_id': 8021}, {'_account_id': 8027}, {'_account_id': 8158}, {'_account_id': 8574}, {'_account_id': 8759}, {'_account_id': 8909}, {'_account_id': 10585}, {'_account_id': 11642}]","[{'number': 1, 'created': '2014-04-02 22:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a6f631825c38f2ec3c682e340a86964dfbc347fb', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 2, 'created': '2014-04-02 22:49:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8a7d2174ba51af2ab61c643c23b1007ff102be07', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 3, 'created': '2014-04-02 22:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c3980e7da3edeceb35cd20e82a222581e62705f7', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 4, 'created': '2014-04-04 20:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1e44184e9cbad0089428166e9736b8a9cc880399', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 5, 'created': '2014-04-15 21:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/76995ea558f43f0f9ac24cfa3ab51be185faea7f', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 6, 'created': '2014-04-15 22:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/edf58219173449c959bbff352d01f2d673030823', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 7, 'created': '2014-05-02 22:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a8b7edec1c021c4567bdeafe9658bc2521192a7d', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 8, 'created': '2014-05-03 00:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/aaeec8fa68b4a4db567387d300d0ae744ef815ee', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 9, 'created': '2014-05-10 02:41:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e05659b667b455e5e3331ff4c3c282b1833405aa', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 10, 'created': '2014-05-27 20:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2371539c0632562ee1a4718351ee07a74f800c0b', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 11, 'created': '2014-06-04 00:48:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/15b9d98211ec9be80e64964267de00ecc791575a', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 12, 'created': '2014-06-04 00:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e3cc54b72b9e6d40066668153173fa471fd5e5c9', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 13, 'created': '2014-06-11 20:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/49d489564406f91859014d63daa62abd3829fa84', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 14, 'created': '2014-06-17 03:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/643a1c8522ca6a0fb02e0be81c3727599feb7ed0', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 15, 'created': '2014-06-26 07:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b9581fa8444ceac3fc4041521e594f6041b083b0', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 16, 'created': '2014-07-04 09:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fd9dd5ff4054ab1f031ccbf14d162644583c2ccf', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 17, 'created': '2014-07-22 17:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5eccc2b5fb259d78a6ec11f46b1d047877e4d9bc', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 18, 'created': '2014-07-22 18:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f99a07971313699bd3dc8b04f3e7c5da64afb97e', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}, {'number': 19, 'created': '2014-10-23 12:55:48.000000000', 'files': ['specs/kilo/use-glance-v2-api.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/34517803f571ac7c9388fb1a133da41ece3328bf', 'message': 'Propose: Allow Nova to use either Glance V1 or V2\n\nNova should be configurable via a configuration parameter to use either\nGlance V1 or V2 API. Due to differences in the workflow exposed by the\nAPI, the image service layer will need to be able to present a\nconsistent interface to Nova while performing necessary translations to\ninteract with the configured Glance API version.\n\nChange-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f\n'}]",97,84887,34517803f571ac7c9388fb1a133da41ece3328bf,167,26,19,8759,,,0,"Propose: Allow Nova to use either Glance V1 or V2

Nova should be configurable via a configuration parameter to use either
Glance V1 or V2 API. Due to differences in the workflow exposed by the
API, the image service layer will need to be able to present a
consistent interface to Nova while performing necessary translations to
interact with the configured Glance API version.

Change-Id: I8ba44561824eb6634239b006f0e600daa0be6f1f
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/87/84887/9 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/use-glance-v2-api.rst'],1,a6f631825c38f2ec3c682e340a86964dfbc347fb,bp/use-glance-v2-api,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================================== Allow Nova to use Glance V1 or V2 API ===================================== https://blueprints.launchpad.net/nova/+spec/use-glance-v2-api Nova should be configurable via a configuration parameter to use either Glance V1 or V2 API. Due to differences in the workflow exposed by the API, the image service layer will need to be able to present a consistent interface to Nova while performing necessary translations to interact with the configured Glance API version. Problem description =================== Due to the fact that Nova is currently using Glance V1 API, Nova cannot take advantages of features available in Glance V2 API. Proposed change =============== This approach proposed here is to have a configuration option giving the ability to select if Nova uses Glance V1 or V2 API. This ability involves some refactoring to have glance drivers for each version of the API in Nova. If V1 is selected, then the Glance driver V1 is used (similarly for V2). Alternatives ------------ - Have a discovery mechanism of the version of the endpoints available: the main problem with that is that the operator might want to keep using a previous version of the API that is trusted a slowly move to the new version of the API. Also, the behavior of features have changed between V1 and V2 (and consequently are not wholly compatible): image properties in V2 can have schema restrictions placed by the deployer but V1 ignore these restrictions. Auto-negotiating could potentially result in undesired changes. - Have some part of Glance (client, stores) becoming a transfer service that has the capability of providing to Nova what is needed to spawn a VM and being version agnostic. This would require several key architectural changes both in Glance and Nova: not ready for that at this point. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- An optional configuration variable will need to be set in the configuration: 'glance_api_version'. Its default value is 1 meaning that by default Nova will be using Glance API V1. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: Eddie Sheffield (esheffield) Other contributors: Zhi Yan Liu (zhiyan) Arnaud Legendre (arnaud) Work Items ---------- - Refactor the image layer to support Glance V2 support - Add Glance driver for V1 - Add Glance driver for V2 Dependencies ============ None. Testing ======= Tempest test should be added to make sure that V2 API features cannot be called with V1 API driver and same the other way around. Unit tests will be part of the patches for each version of the API. Documentation Impact ==================== The new configuration variable 'glance_api_version' needs to be documented. References ========== Mailing list discussion: http://www.mail-archive.com/openstack-dev%40lists.openstack.org/msg06385.html Discussed at the Glance Mini-summit in Washington DC. ",,136,0
openstack%2Foslo.log~master~I26d8542317937b775133718085c0e9ac2a9dfbd5,openstack/oslo.log,master,I26d8542317937b775133718085c0e9ac2a9dfbd5,Switch context module to oslo_context,ABANDONED,2014-12-18 03:36:04.000000000,2014-12-19 01:56:25.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-18 03:36:04.000000000', 'files': ['oslo_log/tests/unit/test_log.py', 'oslo_log/formatters.py', 'requirements.txt', 'oslo_log/log.py', 'oslo_log/tests/unit/test_context.py', 'oslo_log/context.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/ab4b8d03ac9f4c416075cbcd0c15af6fb155f681', 'message': 'Switch context module to oslo_context\n\nUse the context module from oslo_context library instead of the\nlocal copy from oslo-incubator.\n\nChange-Id: I26d8542317937b775133718085c0e9ac2a9dfbd5\n'}]",0,142656,ab4b8d03ac9f4c416075cbcd0c15af6fb155f681,7,3,1,5638,,,0,"Switch context module to oslo_context

Use the context module from oslo_context library instead of the
local copy from oslo-incubator.

Change-Id: I26d8542317937b775133718085c0e9ac2a9dfbd5
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/56/142656/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_log/formatters.py', 'oslo_log/tests/unit/test_log.py', 'requirements.txt', 'oslo_log/log.py', 'oslo_log/tests/unit/test_context.py', 'oslo_log/context.py']",6,ab4b8d03ac9f4c416075cbcd0c15af6fb155f681,,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Simple class that stores security context information in the web request. Projects should subclass this class if they wish to enhance the request context or provide additional information in their specific WSGI pipeline. """""" import itertools import uuid # NOTE(dims): We need this variable for ContextAdapter and ContextFormatter _config = None def generate_request_id(): return b'req-' + str(uuid.uuid4()).encode('ascii') class RequestContext(object): """"""Helper class to represent useful information about a request context. Stores information about the security context under which the user accesses the system, as well as additional request information. """""" user_idt_format = '{user} {tenant} {domain} {user_domain} {p_domain}' def __init__(self, auth_token=None, user=None, tenant=None, domain=None, user_domain=None, project_domain=None, is_admin=False, read_only=False, show_deleted=False, request_id=None, instance_uuid=None): self.auth_token = auth_token self.user = user self.tenant = tenant self.domain = domain self.user_domain = user_domain self.project_domain = project_domain self.is_admin = is_admin self.read_only = read_only self.show_deleted = show_deleted self.instance_uuid = instance_uuid if not request_id: request_id = generate_request_id() self.request_id = request_id def to_dict(self): user_idt = ( self.user_idt_format.format(user=self.user or '-', tenant=self.tenant or '-', domain=self.domain or '-', user_domain=self.user_domain or '-', p_domain=self.project_domain or '-')) return {'user': self.user, 'tenant': self.tenant, 'domain': self.domain, 'user_domain': self.user_domain, 'project_domain': self.project_domain, 'is_admin': self.is_admin, 'read_only': self.read_only, 'show_deleted': self.show_deleted, 'auth_token': self.auth_token, 'request_id': self.request_id, 'instance_uuid': self.instance_uuid, 'user_identity': user_idt} @classmethod def from_dict(cls, ctx): return cls( auth_token=ctx.get(""auth_token""), user=ctx.get(""user""), tenant=ctx.get(""tenant""), domain=ctx.get(""domain""), user_domain=ctx.get(""user_domain""), project_domain=ctx.get(""project_domain""), is_admin=ctx.get(""is_admin"", False), read_only=ctx.get(""read_only"", False), show_deleted=ctx.get(""show_deleted"", False), request_id=ctx.get(""request_id""), instance_uuid=ctx.get(""instance_uuid"")) def get_admin_context(show_deleted=False): context = RequestContext(None, tenant=None, is_admin=True, show_deleted=show_deleted) return context def get_context_from_function_and_args(function, args, kwargs): """"""Find an arg of type RequestContext and return it. This is useful in a couple of decorators where we don't know much about the function we're wrapping. """""" for arg in itertools.chain(kwargs.values(), args): if isinstance(arg, RequestContext): return arg return None def is_user_context(context): """"""Indicates if the request context is a normal user."""""" if not context: return False if context.is_admin: return False if not context.user_id or not context.project_id: return False return True ",4,189
openstack%2Fnova~master~I600840a96b13c1de4f2f409069f452e18e1c1c52,openstack/nova,master,I600840a96b13c1de4f2f409069f452e18e1c1c52,objects: add method to verify requested hugepages,MERGED,2014-10-16 11:03:11.000000000,2014-12-19 01:45:50.000000000,2014-12-18 18:53:29.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11303}]","[{'number': 1, 'created': '2014-10-16 11:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ace392c9a0a405e3f841aa84bc7333140297e9ef', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 2, 'created': '2014-10-16 16:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/44ae71440980b4d9596d1d48c7b625c34727b53d', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 3, 'created': '2014-10-20 12:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a5b8b149a870787e18dd87c734d4f8b26814b4f', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 4, 'created': '2014-10-20 12:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92c0b20f2bfc5e45fa9312dbdaa0611e672d6554', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 5, 'created': '2014-10-20 17:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5334c89df157e222dd67fac447bf99684236d6e3', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 6, 'created': '2014-10-21 08:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95fedc5df92f3472d7c6ee6ff3091ebaf0bf9dee', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 7, 'created': '2014-10-21 10:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea958fc62e7ef47a3697211ff51cc4453a3a6387', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 8, 'created': '2014-10-21 16:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/136b904276821f5b02d797cedbe1c105f65654a4', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 9, 'created': '2014-10-22 09:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b499d91c867640247d8c99bf3ce4b31a816c0ab3', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 10, 'created': '2014-10-24 10:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2581489b34b40daf35ebc37a6c74bd196d81ba49', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 11, 'created': '2014-10-24 12:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8dae9224505d33334bf695a900afe94e38566c19', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 12, 'created': '2014-10-27 17:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d769a33b559e45d5f8d7f62db2b634c6a1eb86c', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 13, 'created': '2014-10-28 08:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b16000b7c489f7c73f367675016c8f001e08333', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 14, 'created': '2014-10-28 13:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7277d355e57ac8e5dc6c26db7b43a360121f5b50', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 15, 'created': '2014-10-28 15:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b03ccddfe01cc80159b4b61e1b8d5de3a79a4684', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fite_hugepages to the cell\ntopology class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 16, 'created': '2014-10-29 14:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4d1591a26bd2fdbd891d6df23bd3e2b15989246', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 17, 'created': '2014-10-29 15:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/321ed7f7e6d3195fa83b51e78bf46e16cd0812d1', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 18, 'created': '2014-10-29 16:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ed073741e60bbb3320b3516b846087063b13859', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 19, 'created': '2014-10-29 22:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/878b0a82a295a720228fe77b3e501612b1dfd348', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 20, 'created': '2014-10-30 08:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42d1ef24ffffcbc7d888d51a1b79ff53142f2f37', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 21, 'created': '2014-10-30 12:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5e563503318f48a808663d8aa9d1c720d1569ba', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 22, 'created': '2014-11-05 08:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48eeb538a07e50f3de9399ac447779a181f15145', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 23, 'created': '2014-11-06 14:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d66049e57c1003a9e297fcb0829681dbbd5ff273', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 24, 'created': '2014-11-06 18:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea83af222fb1a15a7f2b416e5244014fd6d214c1', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 25, 'created': '2014-11-12 14:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8065e1c45b43d13592672491a4e181cf88be3723', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 26, 'created': '2014-11-13 17:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f0656bb7bbc31d57c813100b4635381c72e60aa', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 27, 'created': '2014-11-14 08:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/40f9f2e4a5e3b158344247e44013a5992f48c0e6', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 28, 'created': '2014-11-14 16:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb4faeeb0d7ff3b38f8f7dd295f9d94504b52d77', 'message': 'hardware: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to the cell\ntopology host class. also update VirtNUMAPagesInfo to return free\npages.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 29, 'created': '2014-12-03 12:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c7b4e32ae4b4c40df444d51a621e22290fb861e', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 30, 'created': '2014-12-04 14:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a91cbb7c21ba6fdbe684c85d3970cb736333b63', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 31, 'created': '2014-12-05 08:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/73da7c9e3e78a7b54d51eaec085238fb18095df0', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 32, 'created': '2014-12-08 17:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e51e61715d4212bf6342215b0d7f85d7f65f166', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 33, 'created': '2014-12-08 17:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56b6141eb85dcf7f2dc89abd1f47df3f4622da1c', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 34, 'created': '2014-12-09 08:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f8359fd6c1e7128aff5e2a993d89aa6b1dec72b4', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 35, 'created': '2014-12-09 12:50:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/647bb5b1f272fb2006e8d4eb93730f099eff2346', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 36, 'created': '2014-12-10 13:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/620e6ddf5c07bb207a1558677a6d7e0728c097a7', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 37, 'created': '2014-12-10 14:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f78fc7a1cef9367e10a290092125d58037cd4d39', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 38, 'created': '2014-12-10 15:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53e533a100a32c9c26d6d9eb78ac238e107878aa', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 39, 'created': '2014-12-10 16:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eda126cce41fd5061b630a1beafbf5c37292946e', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 40, 'created': '2014-12-13 09:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d940e1fe3ddaa743c2209b559309d03e67f74a3c', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 41, 'created': '2014-12-13 10:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12a8fa21c80f91b9e9f33f5369e55c33eabd41aa', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 42, 'created': '2014-12-14 13:18:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1eeff78b8e5585a78468a5e4f3d9a8d16063c893', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 43, 'created': '2014-12-15 11:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b78fa7b31fdc0f2a3e8f0bc4d2230bf5de193830', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 44, 'created': '2014-12-16 11:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0e39cdaa56ad4adec585057b68b2a9e8246971d', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}, {'number': 45, 'created': '2014-12-17 14:52:13.000000000', 'files': ['nova/exception.py', 'nova/objects/numa.py', 'nova/tests/unit/objects/test_numa.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/90bd22610a7cc1af87bc7d43bf66ae10201e41ef', 'message': 'objects: add method to verify requested hugepages\n\nIntroduces a new method can_fit_hugepages to numa cell object\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52\n'}]",21,128882,90bd22610a7cc1af87bc7d43bf66ae10201e41ef,279,14,45,7730,,,0,"objects: add method to verify requested hugepages

Introduces a new method can_fit_hugepages to numa cell object

Work-Item: Enhance libvirt driver to configure guests based on
           the flavour parameter for page sizes

Partial-Implement: blueprint virt-driver-large-pages
Change-Id: I600840a96b13c1de4f2f409069f452e18e1c1c52
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/128882/43 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/test_hardware.py', 'nova/virt/hardware.py']",2,ace392c9a0a405e3f841aa84bc7333140297e9ef,bp/virt-driver-large-pages,"from oslo.utils import unitsMEMPAGES_KBYTES = { MEMPAGES_2M: 2 * (units.Mi / units.Ki), MEMPAGES_1G: 1 * (units.Gi / units.Ki), } def can_fit_hugepages(self, size, memory): """"""Returns whether memory can fit into hugepages size :param size: a page size MEMPAGES_1G or MEMPAGES_2M :param memory: a memory asked to fit in KiB :return: a tuple (can fit or not, memory proposed) if the pages size is not supported return (None, None) """""" kbytes = MEMPAGES_KBYTES[size] for info in self.mempages: if info.size == kbytes: if memory > (info.free * info.size): return False, None if (memory % info.size) == 0: return True, memory else: return True, (memory / info.size) * info.size return None, None # size not supported by the cell. @property def free(self): return self.total - self.used ",,52,0
openstack%2Ftempest~master~I76de07e984f13e3eec4977a4d823d1ef367e8f46,openstack/tempest,master,I76de07e984f13e3eec4977a4d823d1ef367e8f46,Change neutron client methods to return one value and update tests,MERGED,2014-12-11 20:26:57.000000000,2014-12-19 01:37:54.000000000,2014-12-19 01:37:52.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2035}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 10969}]","[{'number': 1, 'created': '2014-12-11 20:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7cf3a4549a9c35d018ccdcef0b4cdb6b9d02de1a', 'message': 'Change neutron client methods to return one value and update tests\n\nAlso removed redundant ok checks in javelin.py\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46\n'}, {'number': 2, 'created': '2014-12-11 21:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/72a516d3d6ea8d44dcbc8a810cd2e11574959f5b', 'message': 'Change neutron client methods to return one value and update tests\n\nAlso removed redundant ok checks in javelin.py\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46\n'}, {'number': 3, 'created': '2014-12-11 22:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b7db7b0246666e28fbc960d4259ce8124293b7b6', 'message': 'Change neutron client methods to return one value and update tests\n\nAlso removed redundant ok checks in javelin.py\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46\n'}, {'number': 4, 'created': '2014-12-11 23:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/154e471440823f8317aacc3c19cee258a5ec8e63', 'message': 'Change neutron client methods to return one value and update tests\n\nAlso removed redundant ok checks in javelin.py\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46\n'}, {'number': 5, 'created': '2014-12-12 14:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/38a928b7b60610c2f9898327a4191281e171b770', 'message': 'Change neutron client methods to return one value and update tests\n\nAlso removed redundant ok checks in javelin.py.\nIt was necessary to change the mocked network calls in the unit tests.\nSince the mocked status is never referenced, it was just removed.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46\n'}, {'number': 6, 'created': '2014-12-12 15:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/61ce6a54a18f0b60b7ea74a306828578c1f6096a', 'message': 'Change neutron client methods to return one value and update tests\n\nAlso removed redundant ok checks in javelin.py.\nIt was necessary to change the mocked network calls in the unit tests.\nSince the mocked status is never referenced, it was just removed.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46\n'}, {'number': 7, 'created': '2014-12-15 03:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6326607a1fd67a0a41d15c3e52b3a8fa34762119', 'message': 'Change neutron client methods to return one value and update tests\n\nAlso removed redundant ok checks in javelin.py.\nIt was necessary to change the mocked network calls in the unit tests.\nSince the mocked status is never referenced, it was just removed.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46\n'}, {'number': 8, 'created': '2014-12-15 14:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c4e4592c2cdcd158b3cbcf51c7056a20c59b62b5', 'message': 'Change neutron client methods to return one value and update tests\n\nAlso removed redundant ok checks in javelin.py.\nIt was necessary to change the mocked network calls in the unit tests.\nSince the mocked status is never referenced, it was just removed.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46\n'}, {'number': 9, 'created': '2014-12-15 22:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c3eb492da590356bb1727731c46663b0ef6a7d56', 'message': 'Change neutron client methods to return one value and update tests\n\nAlso removed redundant ok checks in javelin.py.\nIt was necessary to change the mocked network calls in the unit tests.\nSince the mocked status is never referenced, it was just removed.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46\n'}, {'number': 10, 'created': '2014-12-17 15:22:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b2fd4fed03b671b97bec01f2f70184209176e6d8', 'message': ""Change neutron client methods to return one value and update tests\n\nAlso removed redundant ok checks in javelin.py and put in a work-around\nfor the existing assumption that all client 'list_' methods have the same\nsignature.\n\nIt was necessary to change the mocked network calls in the unit tests.\nSince the mocked status is never referenced, it was just removed.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46\n""}, {'number': 11, 'created': '2014-12-18 14:56:31.000000000', 'files': ['tempest/services/network/json/network_client.py', 'tempest/cmd/cleanup_service.py', 'tempest/scenario/manager.py', 'tempest/cmd/verify_tempest_config.py', 'tempest/api/network/admin/test_external_network_extension.py', 'tempest/api/orchestration/stacks/test_neutron_resources.py', 'tempest/api/network/test_dhcp_ipv6.py', 'tempest/api/network/test_extensions.py', 'tempest/scenario/test_baremetal_basic_ops.py', 'tempest/api/network/admin/test_dhcp_agent_scheduler.py', 'tempest/api/network/test_allowed_address_pair.py', 'tempest/api/network/admin/test_lbaas_agent_scheduler.py', 'tempest/cmd/javelin.py', 'tempest/api/network/test_metering_extensions.py', 'tempest/api/network/test_load_balancer.py', 'tempest/api/network/admin/test_agent_management.py', 'tempest/api/network/base_security_groups.py', 'tempest/api/network/test_fwaas_extensions.py', 'tempest/api/network/test_security_groups_negative.py', 'tempest/api/compute/servers/test_create_server.py', 'tempest/api/network/admin/test_quotas.py', 'tempest/api/network/admin/test_floating_ips_admin_actions.py', 'tempest/api/network/test_networks.py', 'tempest/api/network/test_ports.py', 'tempest/api/network/test_routers.py', 'tempest/api/network/test_service_type_management.py', 'tempest/api/network/test_extra_dhcp_options.py', 'tempest/api/network/test_floating_ips.py', 'tempest/api/network/test_security_groups.py', 'tempest/services/network/resources.py', 'tempest/api/network/admin/test_l3_agent_scheduler.py', 'tempest/common/isolated_creds.py', 'tempest/services/network/network_client_base.py', 'tempest/api/network/base_routers.py', 'tempest/tests/cmd/test_verify_tempest_config.py', 'tempest/api/network/test_vpnaas_extensions.py', 'tempest/api/orchestration/base.py', 'tempest/tests/test_tenant_isolation.py', 'tempest/api/network/admin/test_load_balancer_admin_actions.py', 'tempest/api/network/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/34e881201d0dcd790304e65405057ae4215eec1f', 'message': ""Change neutron client methods to return one value and update tests\n\nAlso removed redundant ok checks in javelin.py and put in a work-around\nfor the existing assumption that all client 'list_' methods have the same\nsignature.\n\nIt was necessary to change the mocked network calls in the unit tests.\nSince the mocked status is never referenced, it was just removed.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46\n""}]",5,141152,34e881201d0dcd790304e65405057ae4215eec1f,68,9,11,1192,,,0,"Change neutron client methods to return one value and update tests

Also removed redundant ok checks in javelin.py and put in a work-around
for the existing assumption that all client 'list_' methods have the same
signature.

It was necessary to change the mocked network calls in the unit tests.
Since the mocked status is never referenced, it was just removed.

Partially implements: blueprint clients-return-one-value

Change-Id: I76de07e984f13e3eec4977a4d823d1ef367e8f46
",git fetch https://review.opendev.org/openstack/tempest refs/changes/52/141152/7 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/network/json/network_client.py', 'tempest/cmd/cleanup_service.py', 'tempest/scenario/manager.py', 'tempest/api/network/admin/test_external_network_extension.py', 'tempest/api/orchestration/stacks/test_neutron_resources.py', 'tempest/api/network/test_extensions.py', 'tempest/api/network/admin/test_dhcp_agent_scheduler.py', 'tempest/api/network/test_allowed_address_pair.py', 'tempest/api/network/admin/test_lbaas_agent_scheduler.py', 'tempest/cmd/javelin.py', 'tempest/api/network/test_metering_extensions.py', 'tempest/api/network/test_load_balancer.py', 'tempest/api/network/admin/test_agent_management.py', 'tempest/api/network/base_security_groups.py', 'tempest/api/network/test_fwaas_extensions.py', 'tempest/api/network/test_security_groups_negative.py', 'tempest/api/network/admin/test_quotas.py', 'tempest/api/network/admin/test_floating_ips_admin_actions.py', 'tempest/api/network/test_networks.py', 'tempest/api/network/test_ports.py', 'tempest/api/network/test_routers.py', 'tempest/api/network/test_service_type_management.py', 'tempest/api/network/test_extra_dhcp_options.py', 'tempest/api/network/test_floating_ips.py', 'tempest/api/network/test_security_groups.py', 'tempest/api/network/admin/test_l3_agent_scheduler.py', 'tempest/common/isolated_creds.py', 'tempest/services/network/network_client_base.py', 'tempest/api/network/base_routers.py', 'tempest/api/network/test_vpnaas_extensions.py', 'tempest/api/orchestration/base.py', 'tempest/api/network/admin/test_load_balancer_admin_actions.py', 'tempest/api/network/base.py']",33,7cf3a4549a9c35d018ccdcef0b4cdb6b9d02de1a,bp/clients-return-one-value," body = cls.client.create_network(name=network_name) body = client.create_subnet( body = cls.client.create_port(network_id=network['id'], **kwargs) body = cls.client.update_port(port['id'], **kwargs) body = cls.client.create_router( body = cls.client.create_floatingip( body = cls.client.create_pool( body = cls.client.update_pool(name=name) body = cls.client.create_vip(name=name, body = cls.client.update_vip(name=name) body = cls.client.create_member(address=member_address, protocol_port=protocol_port, pool_id=pool['id']) body = cls.client.update_member(admin_state_up=admin_state_up) body = cls.client.create_health_monitor(delay=delay, max_retries=max_retries, type=Type, timeout=timeout) body = cls.client.update_vip(admin_state_up=admin_state_up) interface = cls.client.add_router_interface_with_subnet_id( body = cls.client.create_vpnservice( body = cls.client.create_ikepolicy(name=name) body = cls.client.create_firewall_rule( body = cls.client.create_firewall_policy( body = cls.client.list_router_interfaces(router['id']) body = cls.client.create_ipsecpolicy(name=name) body = cls.admin_client.create_metering_label( body = cls.admin_client.create_metering_label_rule("," resp, body = cls.client.create_network(name=network_name) resp, body = client.create_subnet( resp, body = cls.client.create_port(network_id=network['id'], **kwargs) resp, body = cls.client.update_port(port['id'], **kwargs) resp, body = cls.client.create_router( resp, body = cls.client.create_floatingip( resp, body = cls.client.create_pool( resp, body = cls.client.update_pool(name=name) resp, body = cls.client.create_vip(name=name, resp, body = cls.client.update_vip(name=name) resp, body = cls.client.create_member(address=member_address, protocol_port=protocol_port, pool_id=pool['id']) resp, body = cls.client.update_member(admin_state_up=admin_state_up) resp, body = cls.client.create_health_monitor(delay=delay, max_retries=max_retries, type=Type, timeout=timeout) resp, body = cls.client.update_vip(admin_state_up=admin_state_up) resp, interface = cls.client.add_router_interface_with_subnet_id( resp, body = cls.client.create_vpnservice( resp, body = cls.client.create_ikepolicy(name=name) resp, body = cls.client.create_firewall_rule( resp, body = cls.client.create_firewall_policy( resp, body = cls.client.list_router_interfaces(router['id']) _, body = cls.client.create_ipsecpolicy(name=name) resp, body = cls.admin_client.create_metering_label( resp, body = cls.admin_client.create_metering_label_rule(",449,452
openstack%2Fkeystone~master~I155e7491a9033c794ef7582bca18286b1b4a80aa,openstack/keystone,master,I155e7491a9033c794ef7582bca18286b1b4a80aa,Update federation docs to point to specs.o.org,MERGED,2014-11-14 16:26:25.000000000,2014-12-19 01:11:44.000000000,2014-12-19 01:11:43.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 11022}, {'_account_id': 13055}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-11-14 16:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7b028739c1cc7f0e6f9b6316e61c2df4e72d477c', 'message': 'Update federation docs to point to specs.o.org\n\nCurrently, some parts of the federation docs points to links on\ngithub.com. We should use the new specs.o.org/keystone/api links\ninstead.\n\nChange-Id: I155e7491a9033c794ef7582bca18286b1b4a80aa\n'}, {'number': 2, 'created': '2014-12-18 04:34:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1276c2ca7717a19aa5fe6b0c678fdc5a7ab2062e', 'message': 'Update federation docs to point to specs.o.org\n\nCurrently, some parts of the federation docs points to links on\ngithub.com. We should use the new specs.o.org/keystone/api links\ninstead.\n\nChange-Id: I155e7491a9033c794ef7582bca18286b1b4a80aa\n'}, {'number': 3, 'created': '2014-12-18 15:57:13.000000000', 'files': ['doc/source/configure_federation.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/8771aed5aeb691977b1fe36695d90b4410b3eaa6', 'message': 'Update federation docs to point to specs.o.org\n\nCurrently, some parts of the federation docs points to links on\ngithub.com. We should use the new specs.o.org/keystone/api links\ninstead.\n\nChange-Id: I155e7491a9033c794ef7582bca18286b1b4a80aa\n'}]",3,134590,8771aed5aeb691977b1fe36695d90b4410b3eaa6,19,15,3,6482,,,0,"Update federation docs to point to specs.o.org

Currently, some parts of the federation docs points to links on
github.com. We should use the new specs.o.org/keystone/api links
instead.

Change-Id: I155e7491a9033c794ef7582bca18286b1b4a80aa
",git fetch https://review.opendev.org/openstack/keystone refs/changes/90/134590/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configure_federation.rst'],1,7b028739c1cc7f0e6f9b6316e61c2df4e72d477c,github_links,"<http://specs.openstack.org/openstack/keystone-specs/api/v3/identity-api-v3.html#create-group>`_<http://specs.openstack.org/openstack/keystone-specs/api/v3/identity-api-v3.html#grant-role-to-group-on-project>`_,<http://specs.openstack.org/openstack/keystone-specs/api/v3/identity-api-v3-os-federation-ext.html>`__.<http://specs.openstack.org/openstack/keystone-specs/api/v3/identity-api-v3-os-federation-ext.html#register-an-identity-provider>`__.<http://specs.openstack.org/openstack/keystone-specs/api/v3/identity-api-v3-os-federation-ext.html#create-a-mapping>`__.<http://specs.openstack.org/openstack/keystone-specs/api/v3/identity-api-v3-os-federation-ext.html#add-a-protocol-and-attribute-mapping-to-an-identity-provider>`__ and specify the mapping id<http://specs.openstack.org/openstack/keystone-specs/api/v3/identity-api-v3-os-federation-ext.html#authenticating>`__.<http://specs.openstack.org/openstack/keystone-specs/api/v3/identity-api-v3-os-federation-ext.html#listing-projects-and-domainss>`__.<http://specs.openstack.org/openstack/keystone-specs/api/v3/identity-api-v3-os-federation-ext.html#request-a-scoped-os-federation-token>`__.","<https://github.com/openstack/identity-api/blob/master/v3/src/markdown/identity-api-v3.md#create-group-post-groups>`_<https://github.com/openstack/identity-api/blob/master/v3/src/markdown/identity-api-v3.md#grant-role-to-group-on-project-put-projectsproject_idgroupsgroup_idrolesrole_id>`_,<https://github.com/openstack/identity-api/blob/master/v3/src/markdown/identity-api-v3-os-federation-ext.md>`__.<https://github.com/openstack/identity-api/blob/master/v3/src/markdown/identity-api-v3-os-federation-ext.md#register-an-identity-provider-put-os-federationidentity_providersidp_id>`__.<https://github.com/openstack/identity-api/blob/master/v3/src/markdown/identity-api-v3-os-federation-ext.md#create-a-mapping-put-os-federationmappingsmapping_id>`__.<https://github.com/openstack/identity-api/blob/master/v3/src/markdown/identity-api-v3-os-federation-ext.md#add-a-supported-protocol-and-attribute-mapping-combination-to-an-identity-provider-put-os-federationidentity_providersidp_idprotocolsprotocol_id>`__ and specify the mapping id<https://github.com/openstack/identity-api/blob/master/v3/src/markdown/identity-api-v3-os-federation-ext.md#authenticating>`__.<https://github.com/openstack/identity-api/blob/master/v3/src/markdown/identity-api-v3-os-federation-ext.md#listing-projects-and-domains>`__.<https://github.com/openstack/identity-api/blob/master/v3/src/markdown/identity-api-v3-os-federation-ext.md#request-a-scoped-os-federation-token-post-authtokens>`__.",9,9
openstack%2Fproject-config~master~If9d85c64497beaaec526b5bcf2c78e67453179a2,openstack/project-config,master,If9d85c64497beaaec526b5bcf2c78e67453179a2,Oops! - Remove extra braces in nova-docker pre/post hook,MERGED,2014-12-19 00:30:57.000000000,2014-12-19 01:10:47.000000000,2014-12-19 01:10:46.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6316}]","[{'number': 1, 'created': '2014-12-19 00:30:57.000000000', 'files': ['jenkins/jobs/nova-docker.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/dd4ce21d6c534ecca94b9cf848c9582c81bfca15', 'message': 'Oops! - Remove extra braces in nova-docker pre/post hook\n\nChange-Id: If9d85c64497beaaec526b5bcf2c78e67453179a2\n'}]",0,142944,dd4ce21d6c534ecca94b9cf848c9582c81bfca15,7,3,1,5638,,,0,"Oops! - Remove extra braces in nova-docker pre/post hook

Change-Id: If9d85c64497beaaec526b5bcf2c78e67453179a2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/44/142944/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/nova-docker.yaml'],1,dd4ce21d6c534ecca94b9cf848c9582c81bfca15,, function pre_test_hook { } function post_test_hook { }, function pre_test_hook {{ }} function post_test_hook {{ }},4,4
openstack%2Fneutron~master~I76af175c4387326a4e5ff95c2f15d8b866dedab3,openstack/neutron,master,I76af175c4387326a4e5ff95c2f15d8b866dedab3,Backward compatibility for advanced services,MERGED,2014-12-16 16:41:34.000000000,2014-12-19 01:10:01.000000000,2014-12-18 20:18:05.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 8655}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9828}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-16 16:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c73f17ff269bd40c03797e968d507e4db2a7484b', 'message': ""Backward compatibility for advanced services\n\nPatch implements translation from class paths to neutron to class paths\nto neutron_<adv_service>. It's achieved by defining entry point in\nsetup.cfg which is translated by stevedore.\n\nThere will be needed patches in advanced services tree calling\nget_provider_driver_class() function before importing class.\n\nAlternative and better solution would be implementing new DriverType\nto oslo.config, which will have callback to\nget_provider_driver_class()-like function.\n\nChange-Id: I76af175c4387326a4e5ff95c2f15d8b866dedab3\nPartial-Bug: #1401895\n""}, {'number': 2, 'created': '2014-12-16 16:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ddb2576e28d5739b65930264d5a52c78f39b1fa7', 'message': ""Backward compatibility for advanced services\n\nPatch implements translation from class paths to neutron to class paths\nto neutron_<adv_service>. It's achieved by defining entry point in\nsetup.cfg which is translated by stevedore.\n\nThere will be needed patches in advanced services tree calling\nget_provider_driver_class() function before importing class.\n\nAlternative and better solution would be implementing new DriverType\nto oslo.config, which will have callback to\nget_provider_driver_class()-like function.\n\nChange-Id: I76af175c4387326a4e5ff95c2f15d8b866dedab3\nPartial-Bug: 1401895\n""}, {'number': 3, 'created': '2014-12-16 18:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d930c58d59e865fb79af0cd21d5216a3be864952', 'message': ""Backward compatibility for advanced services\n\nPatch implements translation from class paths to neutron to class paths\nto neutron_<adv_service>. It's achieved by defining entry point in\nsetup.cfg which is translated by stevedore.\n\nThere will be needed patches in advanced services tree calling\nget_provider_driver_class() function before importing class.\n\nAlternative and better solution would be implementing new DriverType\nto oslo.config, which will have callback to\nget_provider_driver_class()-like function.\n\nChange-Id: I76af175c4387326a4e5ff95c2f15d8b866dedab3\nPartial-Bug: 1401895\n""}, {'number': 4, 'created': '2014-12-16 19:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3ef449d8bded3f0e421b8cee6e9a6884f7009ea4', 'message': ""Backward compatibility for advanced services\n\nPatch implements translation from class paths to neutron to class paths\nto neutron_<adv_service>. It's achieved by defining entry point in\nsetup.cfg which is translated by stevedore.\n\nThere will be needed patches in advanced services tree calling\nget_provider_driver_class() function before importing class.\n\nAlternative and better solution would be implementing new DriverType\nto oslo.config, which will have callback to\nget_provider_driver_class()-like function.\n\nChange-Id: I76af175c4387326a4e5ff95c2f15d8b866dedab3\nPartial-Bug: 1401895\n""}, {'number': 5, 'created': '2014-12-16 22:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/97ff510fe7deeb8d6437e792ccb936383fedf566', 'message': ""Backward compatibility for advanced services\n\nPatch implements translation from class paths to neutron to class paths\nto neutron_<adv_service>. It's achieved by defining entry point in\nsetup.cfg which is translated by stevedore.\n\nThere will be needed patches in advanced services tree calling\nget_provider_driver_class() function before importing class.\n\nThis patch specifically fixes loading service plugins and\ndrivers for service plugin. Patches for agents are still needed in\nneutron repo and adv services repos.\n\nAlternative and better solution would be implementing new DriverType\nto oslo.config, which will have callback to\nget_provider_driver_class()-like function.\n\nChange-Id: I76af175c4387326a4e5ff95c2f15d8b866dedab3\nPartial-Bug: 1401895\n""}, {'number': 6, 'created': '2014-12-17 11:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/27bcffbfcdf001069df999080301e4e47d9645ac', 'message': ""Backward compatibility for advanced services\n\nPatch implements translation from class paths to neutron to class paths\nto neutron_<adv_service>. It's achieved by defining entry point in\nsetup.cfg which is translated by stevedore.\n\nThere will be needed patches in advanced services tree calling\nget_provider_driver_class() function before importing class.\n\nThis patch specifically fixes loading service plugins and\ndrivers for service plugin. Patches for agents are still needed in\nneutron repo and adv services repos.\n\nAlternative and better solution would be implementing new DriverType\nto oslo.config, which will have callback to\nget_provider_driver_class()-like function.\n\nCo-Authored-By: Ihar Hrachyshka <ihrachys@redhat.com>\nChange-Id: I76af175c4387326a4e5ff95c2f15d8b866dedab3\nPartial-Bug: 1401895\n""}, {'number': 7, 'created': '2014-12-17 15:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c2d099f925ce0206e335e413599ec9d7a5520e3c', 'message': ""Backward compatibility for advanced services\n\nPatch implements translation from class paths to neutron to class paths\nto neutron_<adv_service>. It's achieved by defining entry point in\nsetup.cfg which is translated by stevedore.\n\nThere will be needed patches in advanced services tree calling\nget_provider_driver_class() function before importing class.\n\nThis patch specifically fixes loading service plugins and\ndrivers for service plugin. Patches for agents are still needed in\nneutron repo and adv services repos.\n\nAlternative and better solution would be implementing new DriverType\nto oslo.config, which will have callback to\nget_provider_driver_class()-like function.\n\nCo-Authored-By: Ihar Hrachyshka <ihrachys@redhat.com>\nChange-Id: I76af175c4387326a4e5ff95c2f15d8b866dedab3\nPartial-Bug: 1401895\n""}, {'number': 8, 'created': '2014-12-17 18:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a37827d422cb2a4987cb4ef40b3b0910dc90b483', 'message': ""Backward compatibility for advanced services\n\nPatch implements translation from class paths to neutron to class paths\nto neutron_<adv_service>. It's achieved by defining entry point in\nsetup.cfg which is translated by stevedore.\n\nThere will be needed patches in advanced services tree calling\nget_provider_driver_class() function before importing class.\n\nThis patch specifically fixes loading service plugins and\ndrivers for service plugin. Patches for agents are still needed in\nneutron repo and adv services repos.\n\nAlternative and better solution would be implementing new DriverType\nto oslo.config, which will have callback to\nget_provider_driver_class()-like function.\n\nCo-Authored-By: Ihar Hrachyshka <ihrachys@redhat.com>\nChange-Id: I76af175c4387326a4e5ff95c2f15d8b866dedab3\nPartial-Bug: 1401895\n""}, {'number': 9, 'created': '2014-12-18 17:27:53.000000000', 'files': ['neutron/tests/unit/services/vpn/test_plugin_shim.py', 'neutron/services/provider_configuration.py', 'neutron/services/firewall/agents/l3reference/firewall_l3_agent.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/tests/unit/services/vpn/__init__.py', 'neutron/services/firewall/fwaas_plugin.py', 'neutron/services/vpn/plugin.py', 'neutron/manager.py', 'neutron/tests/unit/test_provider_configuration.py', 'neutron/tests/unit/services/loadbalancer/test_plugin_shim.py', 'neutron/tests/unit/services/firewall/test_plugin_shim.py', 'neutron/tests/unit/services/loadbalancer/__init__.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/21842feeae0c1a0a59242d28d74765f5cc761c8c', 'message': ""Backward compatibility for advanced services\n\nPatch implements translation from class paths to neutron to class paths\nto neutron_<adv_service>. It's achieved by defining entry point in\nsetup.cfg which is translated by stevedore.\n\nThere will be needed patches in advanced services tree calling\nget_provider_driver_class() function before importing class.\n\nThis patch specifically fixes loading service plugins and\ndrivers for service plugin. Patches for agents are still needed in\nneutron repo and adv services repos.\n\nAlternative and better solution would be implementing new DriverType\nto oslo.config, which will have callback to\nget_provider_driver_class()-like function.\n\nCo-Authored-By: Ihar Hrachyshka <ihrachys@redhat.com>\nChange-Id: I76af175c4387326a4e5ff95c2f15d8b866dedab3\nPartial-Bug: 1401895\n""}]",27,142150,21842feeae0c1a0a59242d28d74765f5cc761c8c,183,23,9,8655,,,0,"Backward compatibility for advanced services

Patch implements translation from class paths to neutron to class paths
to neutron_<adv_service>. It's achieved by defining entry point in
setup.cfg which is translated by stevedore.

There will be needed patches in advanced services tree calling
get_provider_driver_class() function before importing class.

This patch specifically fixes loading service plugins and
drivers for service plugin. Patches for agents are still needed in
neutron repo and adv services repos.

Alternative and better solution would be implementing new DriverType
to oslo.config, which will have callback to
get_provider_driver_class()-like function.

Co-Authored-By: Ihar Hrachyshka <ihrachys@redhat.com>
Change-Id: I76af175c4387326a4e5ff95c2f15d8b866dedab3
Partial-Bug: 1401895
",git fetch https://review.opendev.org/openstack/neutron refs/changes/50/142150/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/firewall/fwaas_plugin.py', 'neutron/services/vpn/plugin.py', 'neutron/services/provider_configuration.py', 'setup.cfg', 'neutron/services/loadbalancer/plugin.py']",5,c73f17ff269bd40c03797e968d507e4db2a7484b,bug/1401895,,"# Copyright 2014 A10 Networks, Inc # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from neutron.i18n import _LE from neutron.openstack.common import log as logging LOG = logging.getLogger(__name__) try: from neutron_lbaas.services.loadbalancer import plugin except Exception as e: LOG.error(_LE(""Loadbalancer service plugin requires neutron-lbaas module"")) raise e class LoadBalancerPlugin(plugin.LoadBalancerPlugin): pass ",28,90
openstack%2Fnova~master~Ib8546c2a22017f738f644b94dcf00f4afd3582fc,openstack/nova,master,Ib8546c2a22017f738f644b94dcf00f4afd3582fc,hardware: determine whether a pagesize request is acceptable,MERGED,2014-11-13 17:22:13.000000000,2014-12-19 00:31:22.000000000,2014-12-18 18:56:27.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11604}]","[{'number': 1, 'created': '2014-11-13 17:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64e04deaedc0deae040e3f2b9da22bae6152928d', 'message': 'hardware: determines whether a request is acceptable by host cell\n\nEnhance VirtPageSizeRequest to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 2, 'created': '2014-11-14 08:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/248f012fe8123ad6e97baf770a496f3e2b98f7f2', 'message': 'hardware: determines whether a request is acceptable by host cell\n\nEnhance VirtPageSizeRequest to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 3, 'created': '2014-11-14 16:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eae86f323f0dcc210b2ea9cedc31c48d9cca3546', 'message': 'hardware: determines whether a request is acceptable by host cell\n\nEnhance VirtPageSizeRequest to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 4, 'created': '2014-12-03 12:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe46ddfe4199d0467f3e7e4f2dc1b102ec996200', 'message': 'hardware: determine whether a request is acceptable by host cell\n\nEnhances VirtPageSizeRequest to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 5, 'created': '2014-12-04 14:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ad7280a0f77b5ccf6213500c0caec9eb2c69d1b', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_istance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 6, 'created': '2014-12-05 08:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1dc6aba3559cf1342ed1c43c79db08d564be8ac7', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 7, 'created': '2014-12-08 17:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/812febf088be36f70844f515aee1423fa14de686', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 8, 'created': '2014-12-08 17:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/965652ca8cf0b65eee8456496ecd15e9c4e82545', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 9, 'created': '2014-12-09 08:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/40f6cbf4463b4ff4396d090377cfd8985025299e', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 10, 'created': '2014-12-09 12:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c551b3c46e1cb4a3cf40cae8948f1c62f078d63', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 11, 'created': '2014-12-10 13:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d594d6238e6fd0ac438b645a1df71f3c3dd412a6', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 12, 'created': '2014-12-10 14:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/79dbef7fc453e1cc5a50d895006f65a42dda1dae', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 13, 'created': '2014-12-10 15:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11f6c99f6a1e67911ec927f9f8cf7090be50416a', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 14, 'created': '2014-12-10 16:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d1d59bd82a7f2747487884d5880270bfdc9734a', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 15, 'created': '2014-12-13 09:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7087483b40984bc834777ffda2eda83fda4c844f', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 16, 'created': '2014-12-13 10:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1555f511cb137e975808bc55b2c1771416f96e66', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 17, 'created': '2014-12-14 13:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a91cf92d55b36e1d1e3ca553bbd16860f6bbbf4f', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 18, 'created': '2014-12-15 11:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/153dbe102f25cc4829d8e5db45602f3fd20b418b', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 19, 'created': '2014-12-16 11:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4fb862d01290f2473a23836daee103139d18346', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}, {'number': 20, 'created': '2014-12-17 14:52:13.000000000', 'files': ['nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e1ab5855a98608cde5206bcecf3aa7ca2f04d431', 'message': 'hardware: determine whether a pagesize request is acceptable\n\nEnhances numa_fit_isintance_cell to return whether the cell host\ncan handle the page size request\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc\n'}]",14,134308,e1ab5855a98608cde5206bcecf3aa7ca2f04d431,139,12,20,7730,,,0,"hardware: determine whether a pagesize request is acceptable

Enhances numa_fit_isintance_cell to return whether the cell host
can handle the page size request

Work-Item: Enhance libvirt driver to configure guests based on
           the flavour parameter for page sizes

Partial-Implement: blueprint virt-driver-large-pages
Change-Id: Ib8546c2a22017f738f644b94dcf00f4afd3582fc
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/134308/11 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py']",2,64e04deaedc0deae040e3f2b9da22bae6152928d,bp/virt-driver-large-pages," def can_cell_accepts_request(self, host_cell, inst_cell): """"""Determines whether the cell can accept the request. :param host_cell: host cell to fit the instance cell onto :param inst_cell: instance cell we want to fit :returns: Whether the host_cell is able to handle request """""" avail_pagesize = [page for page in host_cell.mempages] avail_pagesize.sort(key=lambda x: x.size_kb) # Smallest to biggest def verify_pagesizes(host_cell, inst_cell, avail_pagesize): for pagesize in avail_pagesize: if host_cell.can_fit_hugepages( pagesize, inst_cell.memory * units.Mi / units.Ki): return True return False if self.request in (MEMPAGES_SMALL, MEMPAGES_ANY): # We do not want check here since operator can have # rules for oversubscription return True elif self.request == MEMPAGES_LARGE: # We do not want to check for the smallest page return verify_pagesizes(host_cell, inst_cell, avail_pagesize[1:]) else: return verify_pagesizes( host_cell, inst_cell, [VirtPageSize(self.request)]) ",,69,0
openstack%2Fnova~master~Ia728025345b09687da9744004f0f47ad73ce196c,openstack/nova,master,Ia728025345b09687da9744004f0f47ad73ce196c,Fix recent regression filling in flavor extra_specs,MERGED,2014-12-17 16:40:32.000000000,2014-12-19 00:19:22.000000000,2014-12-18 18:56:55.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 16:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c0b9765b4e4f8fed8d28d4196f0692383950a8e', 'message': 'Fix recent regression filling in flavor extra_specs in build_request_spec()\n\nIn commit 4c7bb8e24e8f73c70628fff5d7a7d8272a4993af, we dropped an extra\nDB query to fill in flavor extra_specs because the object should already\nhave those set. However, if we pulled the flavor from the instance,\nextra_specs are mostly not stored, which means we effectively cut off\nthe scheduler filters from access to those things.\n\nThis adds that back in for that case, but only temporarily. Soon we will\nbe merging a change to stash real flavor objects with the instance, which\nwill make this moot. However, that may take a while to merge and this is\nbroken now.\n\nChange-Id: Ia728025345b09687da9744004f0f47ad73ce196c\nCloses-Bug: #1403547\n'}, {'number': 2, 'created': '2014-12-18 15:58:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f6dd7a89c23e9ed012f57d2acbf3090e8ae6876', 'message': 'Fix recent regression filling in flavor extra_specs\n\nIn commit 4c7bb8e24e8f73c70628fff5d7a7d8272a4993af, we dropped an extra\nDB query to fill in flavor extra_specs because the object should already\nhave those set. However, if we pulled the flavor from the instance,\nextra_specs are mostly not stored, which means we effectively cut off\nthe scheduler filters from access to those things.\n\nThis adds that back in for that case, but only temporarily. Soon we will\nbe merging a change to stash real flavor objects with the instance, which\nwill make this moot. However, that may take a while to merge and this is\nbroken now.\n\nChange-Id: Ia728025345b09687da9744004f0f47ad73ce196c\nCloses-Bug: #1403547'}, {'number': 3, 'created': '2014-12-18 16:00:09.000000000', 'files': ['nova/scheduler/utils.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/tests/unit/scheduler/test_scheduler_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/41cb43d5a53cfd9bc9a2d6f8e1abe252bcb48253', 'message': 'Fix recent regression filling in flavor extra_specs\n\nIn commit cb338cb7692e12cc94515f1f09008d0e328c1505, we dropped an extra\nDB query to fill in flavor extra_specs because the object should already\nhave those set. However, if we pulled the flavor from the instance,\nextra_specs are mostly not stored, which means we effectively cut off\nthe scheduler filters from access to those things.\n\nThis adds that back in for that case, but only temporarily. Soon we will\nbe merging a change to stash real flavor objects with the instance, which\nwill make this moot. However, that may take a while to merge and this is\nbroken now.\n\nChange-Id: Ia728025345b09687da9744004f0f47ad73ce196c\nCloses-Bug: #1403547'}]",4,142493,41cb43d5a53cfd9bc9a2d6f8e1abe252bcb48253,28,11,3,4393,,,0,"Fix recent regression filling in flavor extra_specs

In commit cb338cb7692e12cc94515f1f09008d0e328c1505, we dropped an extra
DB query to fill in flavor extra_specs because the object should already
have those set. However, if we pulled the flavor from the instance,
extra_specs are mostly not stored, which means we effectively cut off
the scheduler filters from access to those things.

This adds that back in for that case, but only temporarily. Soon we will
be merging a change to stash real flavor objects with the instance, which
will make this moot. However, that may take a while to merge and this is
broken now.

Change-Id: Ia728025345b09687da9744004f0f47ad73ce196c
Closes-Bug: #1403547",git fetch https://review.opendev.org/openstack/nova refs/changes/93/142493/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/utils.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/tests/unit/scheduler/test_scheduler_utils.py']",3,8c0b9765b4e4f8fed8d28d4196f0692383950a8e,bug/1403547,"from nova.tests.unit.objects import test_flavor @mock.patch('nova.objects.Flavor.get_by_flavor_id') def test_build_request_spec_requeries_extra_specs(self, mock_get): flavor = objects.Flavor(**test_flavor.fake_flavor) flavor.extra_specs = {'hw:numa_cpus.1': '1985'} instance = objects.Instance(id=0, uuid=uuid.uuid4().hex, system_metadata={}) with mock.patch.object(instance, 'save'): instance.set_flavor(flavor.obj_clone()) flavor.extra_specs = {'second': '2015', 'third': '1885'} mock_get.return_value = flavor request_spec = scheduler_utils.build_request_spec(self.context, None, [instance]) mock_get.assert_called_once_with(self.context, flavor.flavorid) self.assertEqual({'hw:numa_cpus.1': '1985', 'second': '2015', 'third': '1885'}, request_spec['instance_type']['extra_specs']) @mock.patch('nova.objects.Flavor.get_by_flavor_id') def test_build_request_spec_without_image(self, mock_get): instance_type = objects.Flavor(**test_flavor.fake_flavor) mock_get.return_value = objects.Flavor(extra_specs={}) @mock.patch('nova.objects.Flavor.get_by_flavor_id') def test_build_request_spec_with_object(self, mock_get, extract_flavor): instance_type = objects.Flavor(**test_flavor.fake_flavor) mock_get.return_value = objects.Flavor(extra_specs={}) "," def test_build_request_spec_without_image(self): instance_type = {'flavorid': 'fake-id'} def test_build_request_spec_with_object(self, extract_flavor): instance_type = {'flavorid': 'fake-id'}",37,4
openstack%2Fdjango_openstack_auth~master~I88fbd996b5e567fc738cc6186c8da8b8f3634a25,openstack/django_openstack_auth,master,I88fbd996b5e567fc738cc6186c8da8b8f3634a25,Use keystone auth plugins,ABANDONED,2014-12-09 11:58:09.000000000,2014-12-19 00:09:27.000000000,,"[{'_account_id': 3}, {'_account_id': 7191}, {'_account_id': 14124}]","[{'number': 1, 'created': '2014-12-09 11:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/788f0704598e79f5889d24e3f27289ff0f1589cd', 'message': 'Use keystone auth plugins\n\nConvert the existing DOA to using authentication plugins keeping as\nclose to the current code structure as possible.\n\nThis will allow us to add additional authentication plugins later and\nto start changing horizon to use these plugins when talking to other\nservices rather than hacking tokens into the clients.\n\nChange-Id: I88fbd996b5e567fc738cc6186c8da8b8f3634a25\n'}, {'number': 2, 'created': '2014-12-18 20:02:54.000000000', 'files': ['openstack_auth/tests/tests.py', 'openstack_auth/user.py', 'openstack_auth/views.py', 'openstack_auth/backend.py', 'openstack_auth/utils.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/2a8101dbd876bed6edd17fb71d94987ac7fdac04', 'message': 'Use keystone auth plugins\n\nConvert the existing DOA to using authentication plugins keeping as\nclose to the current code structure as possible.\n\nThis will allow us to add additional authentication plugins later and\nto start changing horizon to use these plugins when talking to other\nservices rather than hacking tokens into the clients.\n\nChange-Id: Idd9ad5044e998a6c514f6161f5159b44391a0849'}]",5,140308,2a8101dbd876bed6edd17fb71d94987ac7fdac04,7,3,2,7191,,,0,"Use keystone auth plugins

Convert the existing DOA to using authentication plugins keeping as
close to the current code structure as possible.

This will allow us to add additional authentication plugins later and
to start changing horizon to use these plugins when talking to other
services rather than hacking tokens into the clients.

Change-Id: Idd9ad5044e998a6c514f6161f5159b44391a0849",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/08/140308/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_auth/tests/tests.py', 'openstack_auth/user.py', 'openstack_auth/views.py', 'openstack_auth/backend.py', 'openstack_auth/utils.py']",5,788f0704598e79f5889d24e3f27289ff0f1589cd,authplugin,"from keystoneclient.auth import token_endpoint from keystoneclient.auth.identity import v2 as v2_auth from keystoneclient.auth.identity import v3 as v3_auth from keystoneclient import sessiondef get_session(): insecure = getattr(settings, 'OPENSTACK_SSL_NO_VERIFY', False) verify = getattr(settings, 'OPENSTACK_SSL_CACERT', None) if insecure: verify = False return session.Session(verify=verify) def fix_auth_url_version(auth_url): """"""Fix up the auth url if an invalid version prefix was given. People still give a v2 auth_url even when they specify that they want v3 authentication. Fix the URL to say v3. This should be smarter and take the base, unversioned URL and discovery. """""" if get_keystone_version() >= 3: if has_in_url_path(auth_url, ""/v2.0""): LOG.warning(""The settings.py file points to a v2.0 keystone "" ""endpoint, but v3 is specified as the API version "" ""to use. Using v3 endpoint for authentication."") auth_url = url_path_replace(auth_url, ""/v2.0"", ""/v3"", 1) return auth_url def get_password_auth_plugin(auth_url, username, password, user_domain_name): if get_keystone_version() >= 3: return v3_auth.Password(auth_url=auth_url, username=username, password=password, user_domain_name=user_domain_name) else: return v2_auth.Password(auth_url=auth_url, username=username, password=password) def get_token_auth_plugin(auth_url, token, project_id): if get_keystone_version() >= 3: return v3_auth.Token(auth_url=auth_url, token=token, project_id=project_id, reauthenticate=False) else: return v2_auth.Token(auth_url=auth_url, token=token, tenant_id=project_id, reauthenticate=False) sess = kwargs.get('session') or get_session() auth = token_endpoint.Token(kwargs['auth_url'], kwargs['token']) client = get_keystone_client().Client(session=sess, auth=auth) if get_keystone_version() < 3:"," if get_keystone_version() < 3: auth_url = url_path_replace( kwargs.get('auth_url', ''), '/v3', '/v2.0', 1) kwargs['auth_url'] = auth_url client = get_keystone_client().Client(*args, **kwargs) auth_url = url_path_replace( kwargs.get('auth_url', ''), '/v2.0', '/v3', 1) kwargs['auth_url'] = auth_url client = get_keystone_client().Client(*args, **kwargs) client.management_url = auth_url",278,212
openstack%2Fneutron~master~If765dd8f2f8010b79eb168179a64dccf940e9cbb,openstack/neutron,master,If765dd8f2f8010b79eb168179a64dccf940e9cbb,Improve performance of get_active_networks_info,MERGED,2014-11-11 09:12:49.000000000,2014-12-19 00:05:32.000000000,2014-12-19 00:05:29.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6659}, {'_account_id': 6697}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7448}, {'_account_id': 7743}, {'_account_id': 7805}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8646}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 8976}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9911}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 11825}, {'_account_id': 12040}, {'_account_id': 12215}, {'_account_id': 12412}, {'_account_id': 12683}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-11-11 09:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e0dd75efac82139b0db09115fd94d27ed42b0f14', 'message': ""Improve performance of get_active_networks_info\n\nRPC 'get_active_networks_info' currently uses nested loop to fill\nthe network structure with subnet and port info. Speed up this\noperation by buliding dictionary of networks.\n\nChange-Id: If765dd8f2f8010b79eb168179a64dccf940e9cbb\nCloses-Bug: #1390356\n""}, {'number': 2, 'created': '2014-11-14 03:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c08544cd9b95254ba0a595cae480e20185004ce4', 'message': ""Improve performance of get_active_networks_info\n\nRPC 'get_active_networks_info' currently uses nested loop to fill\nthe network structure with subnet and port info. Speed up this\noperation by using itertools.groupby.\n\nChange-Id: If765dd8f2f8010b79eb168179a64dccf940e9cbb\nCloses-Bug: #1390356\n""}, {'number': 3, 'created': '2014-11-17 02:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c510ebcec68b510325a49d990a23143228d6df2', 'message': ""Improve performance of get_active_networks_info\n\nRPC 'get_active_networks_info' currently uses nested loop to fill\nthe network structure with subnet and port info. Speed up this\noperation by using itertools.groupby.\n\nChange-Id: If765dd8f2f8010b79eb168179a64dccf940e9cbb\nCloses-Bug: #1390356\n""}, {'number': 4, 'created': '2014-12-08 10:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39e48b497c821abee676980132d11e20fe793e8b', 'message': ""Improve performance of get_active_networks_info\n\nRPC 'get_active_networks_info' currently uses nested loop to fill\nthe network structure with subnet and port info. Speed up this\noperation by using itertools.groupby.\n\nChange-Id: If765dd8f2f8010b79eb168179a64dccf940e9cbb\nCloses-Bug: #1390356\n""}, {'number': 5, 'created': '2014-12-15 08:21:27.000000000', 'files': ['neutron/tests/unit/test_dhcp_rpc.py', 'neutron/api/rpc/handlers/dhcp_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f0894c7bf99d918c0e67ab25498d53e990c09aff', 'message': ""Improve performance of get_active_networks_info\n\nRPC 'get_active_networks_info' currently uses nested loop to fill\nthe network structure with subnet and port info. Speed up this\noperation by using itertools.groupby.\n\nChange-Id: If765dd8f2f8010b79eb168179a64dccf940e9cbb\nCloses-Bug: #1390356\n""}]",18,133636,f0894c7bf99d918c0e67ab25498d53e990c09aff,145,51,5,8646,,,0,"Improve performance of get_active_networks_info

RPC 'get_active_networks_info' currently uses nested loop to fill
the network structure with subnet and port info. Speed up this
operation by using itertools.groupby.

Change-Id: If765dd8f2f8010b79eb168179a64dccf940e9cbb
Closes-Bug: #1390356
",git fetch https://review.opendev.org/openstack/neutron refs/changes/36/133636/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/api/rpc/handlers/dhcp_rpc.py', 'neutron/tests/unit/test_dhcp_rpc.py']",2,e0dd75efac82139b0db09115fd94d27ed42b0f14,bug/1390356," def test_get_active_networks_info(self): plugin_retval = [dict(id='a'), dict(id='b')] self.plugin.get_networks.return_value = plugin_retval port = dict(network_id='a') subnet = dict(network_id='b') self.plugin.get_ports.return_value = [port] self.plugin.get_subnets.return_value = [subnet] networks = self.callbacks.get_active_networks_info(mock.Mock(), host='host') self.assertEqual(networks, [{'id': 'a', 'subnets': [], 'ports': [port]}, {'id': 'b', 'subnets': [subnet], 'ports': []}]) ",,23,4
openstack%2Foslo.config~master~I35bf14ad469fd98486cb02ce66c5bfde5e4f1b11,openstack/oslo.config,master,I35bf14ad469fd98486cb02ce66c5bfde5e4f1b11,Stop sorting options on output,MERGED,2014-11-21 20:25:58.000000000,2014-12-19 00:00:02.000000000,2014-12-19 00:00:01.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6486}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-11-21 20:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/7c426c217ad5e12837727f5ac423b25ddf0cb511', 'message': 'Stop sorting options on output\n\nThe option definitions within a group should not be sorted, since the\napplication or library developer may want to present them in a\nparticular logical order to make them easier to understand\n\nChange-Id: I35bf14ad469fd98486cb02ce66c5bfde5e4f1b11\nCloses-Bug: #1356591\n'}, {'number': 2, 'created': '2014-12-10 13:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/b3a18ea9514df65d1b43b16db4dd884b2fca4362', 'message': 'Stop sorting options on output\n\nThe option definitions within a group should not be sorted, since the\napplication or library developer may want to present them in a\nparticular logical order to make them easier to understand\n\nChange-Id: I35bf14ad469fd98486cb02ce66c5bfde5e4f1b11\nCloses-Bug: #1356591\n'}, {'number': 3, 'created': '2014-12-15 19:30:46.000000000', 'files': ['oslo_config/generator.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/6feb19b0704d753d54fae6e46680a086a149b13c', 'message': 'Stop sorting options on output\n\nThe option definitions within a group should not be sorted, since the\napplication or library developer may want to present them in a\nparticular logical order to make them easier to understand\n\nChange-Id: I35bf14ad469fd98486cb02ce66c5bfde5e4f1b11\nCloses-Bug: #1356591\n'}]",1,136482,6feb19b0704d753d54fae6e46680a086a149b13c,22,7,3,2472,,,0,"Stop sorting options on output

The option definitions within a group should not be sorted, since the
application or library developer may want to present them in a
particular logical order to make them easier to understand

Change-Id: I35bf14ad469fd98486cb02ce66c5bfde5e4f1b11
Closes-Bug: #1356591
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/82/136482/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo_config/generator.py'],1,7c426c217ad5e12837727f5ac423b25ddf0cb511,bug/1356591," namespaces.append((namespace, opts)) for (namespace, opts) in sorted(namespaces, key=operator.itemgetter(0)): for opt in opts:"," namespaces.append((namespace, dict((opt.dest, opt) for opt in opts))) for (namespace, opts_by_dest) in sorted(namespaces, key=operator.itemgetter(0)): for opt in sorted(opts_by_dest.values(), key=operator.attrgetter('dest')):",4,6
openstack%2Fglance~stable%2Ficehouse~I72dbead3cb2dcb87f52658ddb880e26880cc229b,openstack/glance,stable/icehouse,I72dbead3cb2dcb87f52658ddb880e26880cc229b,To prevent client use v2 patch api to handle file and swift location,MERGED,2014-12-18 14:01:48.000000000,2014-12-18 23:59:54.000000000,2014-12-18 23:59:53.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 9311}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-12-18 14:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/05b6d94d4a9f0439056d65a67bd873745052667f', 'message': 'To prevent client use v2 patch api to handle file and swift location\n\nThe change will be used to restrict client to download and delete any\nfile in glance-api server. The same resone and logic as what we did in\nv1:\nhttps://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429\n\nCloses-Bug: bug/1400966\nDocImpact\n\nNote: Even this change could fully resolve the problem for Glance, but\nwe still need to fix this issue from glance_store perspective\nseparatelly due to other projects can use the lib directly.\n\nConflicts:\n\tglance/api/v1/images.py\n\tglance/common/store_utils.py\n\tglance/location.py\n\tglance/tests/functional/v1/test_copy_to_file.py\n\tglance/tests/functional/v2/test_images.py\n\tglance/tests/unit/test_store_image.py\n\tglance/tests/unit/test_store_location.py\n\tglance/tests/unit/utils.py\n\tglance/tests/unit/v1/test_api.py\n\n(cherry picked from commit 4afdb017aa1ccef01482f117cb8d0736a6da38ed)\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\nChange-Id: I72dbead3cb2dcb87f52658ddb880e26880cc229b'}, {'number': 2, 'created': '2014-12-18 17:15:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6a038287e22727c018faec719ef12b45962cc03a', 'message': 'To prevent client use v2 patch api to handle file and swift location\n\nThe change will be used to restrict client to download and delete any\nfile in glance-api server. The same resone and logic as what we did in\nv1:\nhttps://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429\n\nCloses-Bug: bug/1400966\nDocImpact\n\nNote: Even this change could fully resolve the problem for Glance, but\nwe still need to fix this issue from glance_store perspective\nseparatelly due to other projects can use the lib directly.\n\nConflicts:\n\tglance/api/v1/images.py\n\tglance/common/store_utils.py\n\tglance/location.py\n\tglance/tests/functional/v1/test_copy_to_file.py\n\tglance/tests/functional/v2/test_images.py\n\tglance/tests/unit/test_store_image.py\n\tglance/tests/unit/test_store_location.py\n\tglance/tests/unit/utils.py\n\tglance/tests/unit/v1/test_api.py\n\n(cherry picked from commit 4afdb017aa1ccef01482f117cb8d0736a6da38ed)\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\nChange-Id: I72dbead3cb2dcb87f52658ddb880e26880cc229b\n'}, {'number': 3, 'created': '2014-12-18 21:33:46.000000000', 'files': ['glance/tests/functional/v1/test_copy_to_file.py', 'glance/store/__init__.py', 'glance/tests/functional/v2/test_images.py', 'glance/tests/unit/test_store_location.py', 'glance/tests/unit/utils.py', 'glance/tests/unit/v1/test_api.py', 'glance/api/v1/images.py', 'glance/tests/unit/test_store_image.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/8bdb7ed9f5beaf816e7abba726904646bf3680dd', 'message': 'To prevent client use v2 patch api to handle file and swift location\n\nThe change will be used to restrict client to download and delete any\nfile in glance-api server. The same resone and logic as what we did in\nv1:\nhttps://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429\n\nCloses-Bug: bug/1400966\nDocImpact\n\nConflicts:\n\tglance/api/v1/images.py\n\tglance/common/store_utils.py\n\tglance/location.py\n\tglance/tests/functional/v1/test_copy_to_file.py\n\tglance/tests/functional/v2/test_images.py\n\tglance/tests/unit/test_store_image.py\n\tglance/tests/unit/test_store_location.py\n\tglance/tests/unit/utils.py\n\tglance/tests/unit/v1/test_api.py\n\n(cherry picked from commit 4afdb017aa1ccef01482f117cb8d0736a6da38ed)\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\nChange-Id: I72dbead3cb2dcb87f52658ddb880e26880cc229b\n'}]",1,142788,8bdb7ed9f5beaf816e7abba726904646bf3680dd,12,4,3,6549,,,0,"To prevent client use v2 patch api to handle file and swift location

The change will be used to restrict client to download and delete any
file in glance-api server. The same resone and logic as what we did in
v1:
https://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429

Closes-Bug: bug/1400966
DocImpact

Conflicts:
	glance/api/v1/images.py
	glance/common/store_utils.py
	glance/location.py
	glance/tests/functional/v1/test_copy_to_file.py
	glance/tests/functional/v2/test_images.py
	glance/tests/unit/test_store_image.py
	glance/tests/unit/test_store_location.py
	glance/tests/unit/utils.py
	glance/tests/unit/v1/test_api.py

(cherry picked from commit 4afdb017aa1ccef01482f117cb8d0736a6da38ed)
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
Change-Id: I72dbead3cb2dcb87f52658ddb880e26880cc229b
",git fetch https://review.opendev.org/openstack/glance refs/changes/88/142788/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/functional/v1/test_copy_to_file.py', 'glance/store/__init__.py', 'glance/tests/functional/v2/test_images.py', 'glance/tests/unit/test_store_location.py', 'glance/tests/unit/utils.py', 'glance/tests/unit/v1/test_api.py', 'glance/api/v1/images.py', 'glance/tests/unit/test_store_image.py']",8,05b6d94d4a9f0439056d65a67bd873745052667f,,from glance.tests.unit import base as unit_test_baseclass TestImageFactory(unit_test_base.StoreClearingUnitTest):,class TestImageFactory(utils.BaseTestCase):,243,123
openstack%2Fkeystone~master~I4c84513a5b94c08d7733de20a2b54ca0afbf5b23,openstack/keystone,master,I4c84513a5b94c08d7733de20a2b54ca0afbf5b23,sync to oslo commit 1cf2c6,MERGED,2014-12-02 04:41:24.000000000,2014-12-18 23:59:03.000000000,2014-12-18 23:59:01.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 9142}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-12-02 04:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4a4119eb9fa6cced0dc8eb921186784479683c75', 'message': 'sync oslo\n\nChange-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23\n'}, {'number': 2, 'created': '2014-12-02 05:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c83a5fbc91c07315fbccf5db0f4bcf17bed69873', 'message': 'sync to oslo commit b19af08\n\nSyncs with oslo incubator commit:\n  b19af0806f0e2dffc83607d39a88e408928da72c\n\nFirst, remove the existing code to cleanup:\n $ rm -r keyestoneclient/openstack/*\n\nThen, sync from oslo-incubator:\n $ python update.py ../keystone\n\nNote: had to undo the deletes to config.py and\ngettextutils.py, since they are still being used\n\nChange-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23\n'}, {'number': 3, 'created': '2014-12-02 06:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f02a8e7e88f8d4915cf0c4903650f1eb16f59d7f', 'message': 'sync to oslo commit b19af08\n\nSyncs with oslo incubator commit:\n  b19af0806f0e2dffc83607d39a88e408928da72c\n\nFirst, remove the existing code to cleanup:\n $ rm -r keyestoneclient/openstack/*\n\nThen, sync from oslo-incubator:\n $ python update.py ../keystone\n\nNote: had to undo the deletes to config.py,\nimportutils.py and gettextutils.py, since they are\nstill being used\n\nChange-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23\n'}, {'number': 4, 'created': '2014-12-03 17:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9ad629dc28df0f47d95daed01a78b141e2b247a7', 'message': 'sync to oslo commit b19af08\n\nSyncs with oslo incubator commit:\n  b19af0806f0e2dffc83607d39a88e408928da72c\n\nFirst, remove the existing code to cleanup:\n $ rm -r keyestoneclient/openstack/*\n\nThen, sync from oslo-incubator:\n $ python update.py ../keystone\n\nNote: had to undo the deletes to config.py,\nimportutils.py and gettextutils.py, since they are\nstill being used\n\nChange-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23\n'}, {'number': 5, 'created': '2014-12-08 02:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9c25998f69f669d94d3b00b03d86a545e1e00d65', 'message': 'sync to oslo commit b19af08\n\nSyncs with oslo incubator commit:\n  b19af0806f0e2dffc83607d39a88e408928da72c\n\nFirst, remove the existing code to cleanup:\n $ rm -r keyestoneclient/openstack/*\n\nThen, sync from oslo-incubator:\n $ python update.py ../keystone\n\nNote: had to undo the deletes to config.py,\nimportutils.py and gettextutils.py, since they are\nstill being used\n\nChange-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23\n'}, {'number': 6, 'created': '2014-12-15 19:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/91ed17d4554b5f9277b90e6cda644b673c38b8bf', 'message': 'sync to oslo commit b19af08\n\nSyncs with oslo incubator commit:\n  b19af0806f0e2dffc83607d39a88e408928da72c\n\nFirst, remove the existing code to cleanup:\n $ rm -r keyestoneclient/openstack/*\n\nThen, sync from oslo-incubator:\n $ python update.py ../keystone\n\nNote: had to undo the deletes to config.py,\nimportutils.py and gettextutils.py, since they are\nstill being used\n\nChange-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23\n'}, {'number': 7, 'created': '2014-12-15 19:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6b27ba00e6e716a3fbad501065555079545b5cb1', 'message': 'sync to oslo commit 1cf2c6\n\nSyncs with oslo incubator commit:\n  1cf2c61673be2fc077fa3445bcd4bc21fd0c298b\n\nFirst, remove the existing code to cleanup:\n $ rm -r keyestoneclient/openstack/*\n\nThen, sync from oslo-incubator:\n $ python update.py ../keystone\n\nNote: had to undo the deletes to config.py,\nimportutils.py and gettextutils.py, since they are\nstill being used\n\nChange-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23\n'}, {'number': 8, 'created': '2014-12-15 19:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/452cbdeaba83f33e3d8d5a1b2999133733294db9', 'message': 'sync to oslo commit 1cf2c6\n\nSyncs with oslo incubator commit:\n  1cf2c61673be2fc077fa3445bcd4bc21fd0c298b\n\nFirst, remove the existing code to cleanup:\n $ rm -r keyestone/openstack/*\n\nThen, sync from oslo-incubator:\n $ python update.py ../keystone\n\nNote: had to undo the deletes to config.py,\nimportutils.py and gettextutils.py, since they are\nstill being used\n\nChange-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23\n'}, {'number': 9, 'created': '2014-12-15 19:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dff8d0fd412b52d567adbeb28f02e0a84e9a9c87', 'message': 'sync to oslo commit 1cf2c6\n\nSyncs with oslo incubator commit:\n  1cf2c61673be2fc077fa3445bcd4bc21fd0c298b\n\nFirst, remove the existing code to cleanup:\n $ rm -r keystone/openstack/*\n\nThen, sync from oslo-incubator:\n $ python update.py ../keystone\n\nNote: had to undo the deletes to config.py,\nimportutils.py and gettextutils.py, since they are\nstill being used\n\nChange-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23\n'}, {'number': 10, 'created': '2014-12-18 02:43:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/46a43d627a6ded82dbc8de403ff3e96eef3fe47a', 'message': 'sync to oslo commit 1cf2c6\n\nSyncs with oslo incubator commit:\n  1cf2c61673be2fc077fa3445bcd4bc21fd0c298b\n\nFirst, remove the existing code to cleanup:\n $ rm -r keystone/openstack/*\n\nThen, sync from oslo-incubator:\n $ python update.py ../keystone\n\nNote: had to undo the deletes to config.py,\nimportutils.py and gettextutils.py, since they are\nstill being used\n\nChange-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23\n'}, {'number': 11, 'created': '2014-12-18 20:22:50.000000000', 'files': ['keystone/openstack/common/threadgroup.py', 'keystone/openstack/common/fileutils.py', 'keystone/openstack/common/eventlet_backdoor.py', 'keystone/openstack/common/policy.py', 'keystone/openstack/common/log.py', 'keystone/openstack/common/_i18n.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7b63af6186c598c5bce2f120984b1474a25ac3ff', 'message': 'sync to oslo commit 1cf2c6\n\nSyncs with oslo incubator commit:\n  1cf2c61673be2fc077fa3445bcd4bc21fd0c298b\n\nFirst, remove the existing code to cleanup:\n $ rm -r keystone/openstack/*\n\nThen, sync from oslo-incubator:\n $ python update.py ../keystone\n\nNote: had to undo the deletes to config/*, README,\nimportutils.py and gettextutils.py, since they are\nstill being used\n\nChange-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23\n'}]",7,138253,7b63af6186c598c5bce2f120984b1474a25ac3ff,42,7,11,6482,,,0,"sync to oslo commit 1cf2c6

Syncs with oslo incubator commit:
  1cf2c61673be2fc077fa3445bcd4bc21fd0c298b

First, remove the existing code to cleanup:
 $ rm -r keystone/openstack/*

Then, sync from oslo-incubator:
 $ python update.py ../keystone

Note: had to undo the deletes to config/*, README,
importutils.py and gettextutils.py, since they are
still being used

Change-Id: I4c84513a5b94c08d7733de20a2b54ca0afbf5b23
",git fetch https://review.opendev.org/openstack/keystone refs/changes/53/138253/8 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/openstack/common/README', 'keystone/openstack/common/threadgroup.py', 'keystone/openstack/common/eventlet_backdoor.py', 'keystone/openstack/common/fileutils.py', 'keystone/openstack/common/policy.py', 'keystone/openstack/common/log.py', 'keystone/openstack/common/_i18n.py']",7,4a4119eb9fa6cced0dc8eb921186784479683c75,oslo_sync,"try: import oslo.i18n # NOTE(dhellmann): This reference to o-s-l-o will be replaced by the # application name when this module is synced into the separate # repository. It is OK to have more than one translation function # using the same domain, since there will still only be one message # catalog. _translators = oslo.i18n.TranslatorFactory(domain='keystone') # The primary translation function using the well-known name ""_"" _ = _translators.primary # Translators for log levels. # # The abbreviated names are meant to reflect the usual use of a short # name like '_'. The ""L"" is for ""log"" and the other letter comes from # the level. _LI = _translators.log_info _LW = _translators.log_warning _LE = _translators.log_error _LC = _translators.log_critical except ImportError: # NOTE(dims): Support for cases where a project wants to use # code from keystone-incubator, but is not ready to be internationalized # (like tempest) _ = _LI = _LW = _LE = _LC = lambda x: x","import oslo.i18n # NOTE(dhellmann): This reference to o-s-l-o will be replaced by the # application name when this module is synced into the separate # repository. It is OK to have more than one translation function # using the same domain, since there will still only be one message # catalog. _translators = oslo.i18n.TranslatorFactory(domain='keystone') # The primary translation function using the well-known name ""_"" _ = _translators.primary # Translators for log levels. # # The abbreviated names are meant to reflect the usual use of a short # name like '_'. The ""L"" is for ""log"" and the other letter comes from # the level. _LI = _translators.log_info _LW = _translators.log_warning _LE = _translators.log_error _LC = _translators.log_critical",87,54
openstack%2Fglance~master~I87595a29634e6ffda4e1581d42a92dfe6f84044b,openstack/glance,master,I87595a29634e6ffda4e1581d42a92dfe6f84044b,Generate glance-manage.conf,MERGED,2014-12-15 22:09:39.000000000,2014-12-18 23:58:13.000000000,2014-12-18 23:58:11.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 6159}, {'_account_id': 8127}, {'_account_id': 8158}, {'_account_id': 11356}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-12-15 22:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/570a641087858a1d9cf8af1e6aa6a29c390b936f', 'message': 'Generate glance-manage.conf\n\nChange-Id: I87595a29634e6ffda4e1581d42a92dfe6f84044b\nImplements: blueprint create-glance-manage-conf\nRelated-bug: #1391211\n'}, {'number': 2, 'created': '2014-12-15 23:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/37b95f693a17ef3c81593ad20cefb450521d453e', 'message': 'Generate glance-manage.conf\n\nAs specified in the blueprint, we are only going to set log_file in the\nconfiguration file for now, and we read it last in glance.cmd.manage.\nThis allows glance-manage to use the appropriate log-file and still\nretain the settings it needs in glance-api.conf and glance-registry.conf\n\nChange-Id: I87595a29634e6ffda4e1581d42a92dfe6f84044b\nImplements: blueprint create-glance-manage-conf\nCloses-bug: #1391211\n'}, {'number': 3, 'created': '2014-12-18 14:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cdf40e9a9f40fea59fc93ed9296a50e359c357c1', 'message': 'Generate glance-manage.conf\n\nAs specified in the blueprint, we are only going to set log_file in the\nconfiguration file for now, and we read it last in glance.cmd.manage.\nThis allows glance-manage to use the appropriate log-file and still\nretain the settings it needs in glance-api.conf and glance-registry.conf\n\nDocImpact\n\nChange-Id: I87595a29634e6ffda4e1581d42a92dfe6f84044b\nImplements: blueprint create-glance-manage-conf\nCloses-bug: #1391211\n'}, {'number': 4, 'created': '2014-12-18 14:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/34c97202f0e34a3e550185d859b52c3606803448', 'message': 'Generate glance-manage.conf\n\nAs specified in the blueprint, we are only going to set log_file in the\nconfiguration file for now, and we read it last in glance.cmd.manage.\nThis allows glance-manage to use the appropriate log-file and still\nretain the settings it needs in glance-api.conf and glance-registry.conf\n\nDocImpact\n\nChange-Id: I87595a29634e6ffda4e1581d42a92dfe6f84044b\nImplements: blueprint create-glance-manage-conf\nCloses-bug: #1391211\n'}, {'number': 5, 'created': '2014-12-18 16:23:25.000000000', 'files': ['glance/cmd/manage.py', 'doc/source/man/glancemanage.rst', 'etc/glance-manage.conf', 'doc/source/configuring.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/8a02cf035c830736f3475fd282bbb7cd33b950bf', 'message': 'Generate glance-manage.conf\n\nAs specified in the blueprint, we are only going to set log_file in the\nconfiguration file for now, and we read it last in glance.cmd.manage.\nThis allows glance-manage to use the appropriate log-file and still\nretain the settings it needs in glance-api.conf and glance-registry.conf\n\nDocImpact\n\nChange-Id: I87595a29634e6ffda4e1581d42a92dfe6f84044b\nImplements: blueprint create-glance-manage-conf\nCloses-bug: #1391211\n'}]",1,141917,8a02cf035c830736f3475fd282bbb7cd33b950bf,32,10,5,12000,,,0,"Generate glance-manage.conf

As specified in the blueprint, we are only going to set log_file in the
configuration file for now, and we read it last in glance.cmd.manage.
This allows glance-manage to use the appropriate log-file and still
retain the settings it needs in glance-api.conf and glance-registry.conf

DocImpact

Change-Id: I87595a29634e6ffda4e1581d42a92dfe6f84044b
Implements: blueprint create-glance-manage-conf
Closes-bug: #1391211
",git fetch https://review.opendev.org/openstack/glance refs/changes/17/141917/5 && git format-patch -1 --stdout FETCH_HEAD,['etc/glance-manage.conf'],1,570a641087858a1d9cf8af1e6aa6a29c390b936f,bug/1391211,"[DEFAULT] # # From glance.manage # # DEPRECATED. TO BE REMOVED IN THE JUNO RELEASE. Whether or not to # enforce that all DB tables have charset utf8. If your database # tables do not have charset utf8 you will need to convert before this # option is removed. This option is only relevant if your database # engine is MySQL. (boolean value) #db_enforce_mysql_charset = true # Print debugging output (set logging level to DEBUG instead of # default WARNING level). (boolean value) #debug = false # The name of a logging configuration file. This file is appended to # any existing logging configuration files. For details about logging # configuration files, see the Python logging module documentation. # (string value) # Deprecated group/name - [DEFAULT]/log_config #log_config_append = <None> # Format string for %%(asctime)s in log records. Default: %(default)s # . (string value) #log_date_format = %Y-%m-%d %H:%M:%S # (Optional) The base directory used for relative --log-file paths. # (string value) # Deprecated group/name - [DEFAULT]/logdir #log_dir = <None> # (Optional) Name of log file to output to. If no default is set, # logging will go to stdout. (string value) # Deprecated group/name - [DEFAULT]/logfile log_file = /var/log/glance/manage.log # DEPRECATED. A logging.Formatter log message format string which may # use any of the available logging.LogRecord attributes. This option # is deprecated. Please use logging_context_format_string and # logging_default_format_string instead. (string value) #log_format = <None> # Syslog facility to receive log lines. (string value) #syslog_log_facility = LOG_USER # Use syslog for logging. Existing syslog format is DEPRECATED during # I, and will change in J to honor RFC5424. (boolean value) #use_syslog = false # (Optional) Enables or disables syslog rfc5424 format for logging. If # enabled, prefixes the MSG part of the syslog message with APP-NAME # (RFC5424). The format without the APP-NAME is deprecated in I, and # will be removed in J. (boolean value) #use_syslog_rfc_format = false # Print more verbose output (set logging level to INFO instead of # default WARNING level). (boolean value) #verbose = false [database] # # From oslo.db # # The back end to use for the database. (string value) # Deprecated group/name - [DEFAULT]/db_backend #backend = sqlalchemy # The SQLAlchemy connection string to use to connect to the database. # (string value) # Deprecated group/name - [DEFAULT]/sql_connection # Deprecated group/name - [DATABASE]/sql_connection # Deprecated group/name - [sql]/connection #connection = <None> # Verbosity of SQL debugging information: 0=None, 100=Everything. # (integer value) # Deprecated group/name - [DEFAULT]/sql_connection_debug #connection_debug = 0 # Add Python stack traces to SQL as comment strings. (boolean value) # Deprecated group/name - [DEFAULT]/sql_connection_trace #connection_trace = false # If True, increases the interval between database connection retries # up to db_max_retry_interval. (boolean value) #db_inc_retry_interval = true # Maximum database connection retries before error is raised. Set to # -1 to specify an infinite retry count. (integer value) #db_max_retries = 20 # If db_inc_retry_interval is set, the maximum seconds between # database connection retries. (integer value) #db_max_retry_interval = 10 # Seconds between database connection retries. (integer value) #db_retry_interval = 1 # Timeout before idle SQL connections are reaped. (integer value) # Deprecated group/name - [DEFAULT]/sql_idle_timeout # Deprecated group/name - [DATABASE]/sql_idle_timeout # Deprecated group/name - [sql]/idle_timeout #idle_timeout = 3600 # If set, use this value for max_overflow with SQLAlchemy. (integer # value) # Deprecated group/name - [DEFAULT]/sql_max_overflow # Deprecated group/name - [DATABASE]/sqlalchemy_max_overflow #max_overflow = <None> # Maximum number of SQL connections to keep open in a pool. (integer # value) # Deprecated group/name - [DEFAULT]/sql_max_pool_size # Deprecated group/name - [DATABASE]/sql_max_pool_size #max_pool_size = <None> # Maximum number of database connection retries during startup. Set to # -1 to specify an infinite retry count. (integer value) # Deprecated group/name - [DEFAULT]/sql_max_retries # Deprecated group/name - [DATABASE]/sql_max_retries #max_retries = 10 # Minimum number of SQL connections to keep open in a pool. (integer # value) # Deprecated group/name - [DEFAULT]/sql_min_pool_size # Deprecated group/name - [DATABASE]/sql_min_pool_size #min_pool_size = 1 # The SQL mode to be used for MySQL sessions. This option, including # the default, overrides any server-set SQL mode. To use whatever SQL # mode is set by the server configuration, set this to no value. # Example: mysql_sql_mode= (string value) #mysql_sql_mode = TRADITIONAL # If set, use this value for pool_timeout with SQLAlchemy. (integer # value) # Deprecated group/name - [DATABASE]/sqlalchemy_pool_timeout #pool_timeout = <None> # Interval between retries of opening a SQL connection. (integer # value) # Deprecated group/name - [DEFAULT]/sql_retry_interval # Deprecated group/name - [DATABASE]/reconnect_interval #retry_interval = 10 # The SQLAlchemy connection string to use to connect to the slave # database. (string value) #slave_connection = <None> # The file name to use with SQLite. (string value) # Deprecated group/name - [DEFAULT]/sqlite_db #sqlite_db = oslo.sqlite # If True, SQLite uses synchronous mode. (boolean value) # Deprecated group/name - [DEFAULT]/sqlite_synchronous #sqlite_synchronous = true # Enable the experimental use of database reconnect on connection # lost. (boolean value) #use_db_reconnect = false # # From oslo.db.concurrency # # Enable the experimental use of thread pooling for all DB API calls # (boolean value) # Deprecated group/name - [DEFAULT]/dbapi_use_tpool #use_tpool = false ",,174,0
openstack%2Fnova~master~Ief296211d5cff8b3ccfc8231cb2336582bd47ef1,openstack/nova,master,Ief296211d5cff8b3ccfc8231cb2336582bd47ef1,Use constant for microversions header name (cleanup),MERGED,2014-11-29 11:59:09.000000000,2014-12-18 23:57:48.000000000,2014-12-18 23:57:45.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-11-29 11:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f27241f9a4882a0a474f0731c8034620de45187', 'message': 'Use constant for microversions header name (cleanup)\n\nDefine and use a constant for the microversion header\nname rather than repeat the string literal in multiple places.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1\n'}, {'number': 2, 'created': '2014-12-01 03:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b7e0368c27dfa66f834bff708e8ec5a9e528c306', 'message': 'Use constant for microversions header name (cleanup)\n\nDefine and use a constant for the microversion header\nname rather than repeat the string literal in multiple places.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1\n'}, {'number': 3, 'created': '2014-12-02 00:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a941736af78b7432a909380dfdb6f7f39be31ea', 'message': 'Use constant for microversions header name (cleanup)\n\nDefine and use a constant for the microversion header\nname rather than repeat the string literal in multiple places.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1\n'}, {'number': 4, 'created': '2014-12-02 04:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83bb61389d93a677a24ce89c60dce0c549836767', 'message': 'Use constant for microversions header name (cleanup)\n\nDefine and use a constant for the microversion header\nname rather than repeat the string literal in multiple places.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1\n'}, {'number': 5, 'created': '2014-12-02 06:11:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5be3ec10a7925c3522ef22dd33d76fa06e17c939', 'message': 'Use constant for microversions header name (cleanup)\n\nDefine and use a constant for the microversion header\nname rather than repeat the string literal in multiple places.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1\n'}, {'number': 6, 'created': '2014-12-02 13:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2eaf746ac45c5fa0041f5d0db9e22907ef5461ef', 'message': 'Use constant for microversions header name (cleanup)\n\nDefine and use a constant for the microversion header\nname rather than repeat the string literal in multiple places.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1\n'}, {'number': 7, 'created': '2014-12-05 01:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad45316c5ca5e38a36cd09ab914e22b23e800ac7', 'message': 'Use constant for microversions header name (cleanup)\n\nDefine and use a constant for the microversion header\nname rather than repeat the string literal in multiple places.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1\n'}, {'number': 8, 'created': '2014-12-05 03:56:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc322f58f2b1b1cab8d21569cabaab89ab3b3bc9', 'message': 'Use constant for microversions header name (cleanup)\n\nDefine and use a constant for the microversion header\nname rather than repeat the string literal in multiple places.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1\n'}, {'number': 9, 'created': '2014-12-10 03:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6389b485db6cef693a635f5a2750ece4a768d6e', 'message': 'Use constant for microversions header name (cleanup)\n\nDefine and use a constant for the microversion header\nname rather than repeat the string literal in multiple places.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1\n'}, {'number': 10, 'created': '2014-12-10 07:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3097b526f2b1a8051a307d8255ed5e4a25d20eb', 'message': 'Use constant for microversions header name (cleanup)\n\nDefine and use a constant for the microversion header\nname rather than repeat the string literal in multiple places.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1\n'}, {'number': 11, 'created': '2014-12-17 03:01:16.000000000', 'files': ['nova/api/openstack/wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d21e5dc94d3d82e2232d7d074d744db51b7b8561', 'message': 'Use constant for microversions header name (cleanup)\n\nDefine and use a constant for the microversion header\nname rather than repeat the string literal in multiple places.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1\n'}]",0,137910,d21e5dc94d3d82e2232d7d074d744db51b7b8561,89,15,11,5292,,,0,"Use constant for microversions header name (cleanup)

Define and use a constant for the microversion header
name rather than repeat the string literal in multiple places.

Partially implements blueprint api-microversions

Change-Id: Ief296211d5cff8b3ccfc8231cb2336582bd47ef1
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/137910/11 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/wsgi.py'],1,6f27241f9a4882a0a474f0731c8034620de45187,bp/api-microversions,# Name of header used by clients to request a specific version # of the REST API API_VERSION_REQUEST_HEADER = 'X-OpenStack-Compute-API-Version' if API_VERSION_REQUEST_HEADER in self.headers: hdr_string = self.headers[API_VERSION_REQUEST_HEADER] response.headers[API_VERSION_REQUEST_HEADER] = \ response.headers['Vary'] = API_VERSION_REQUEST_HEADER self.wrapped_exc.headers[API_VERSION_REQUEST_HEADER] = \ API_VERSION_REQUEST_HEADER, if 'X-OpenStack-Compute-API-Version' in self.headers: hdr_string = self.headers['X-OpenStack-Compute-API-Version'] response.headers['X-OpenStack-Compute-API-Version'] = \ response.headers['Vary'] = 'X-OpenStack-Compute-API-Version' self.wrapped_exc.headers['X-OpenStack-Compute-API-Version'] = \ 'X-OpenStack-Compute-API-Version',10,6
openstack%2Fdevstack~master~Idccc4b79a700ca34a80f590e942e1647cdfdefb0,openstack/devstack,master,Idccc4b79a700ca34a80f590e942e1647cdfdefb0,"Revert ""Revert ""Pin version of setuptools""""",MERGED,2014-12-18 22:14:11.000000000,2014-12-18 23:57:18.000000000,2014-12-18 23:57:17.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 5263}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-18 22:14:11.000000000', 'files': ['tools/install_pip.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/2191f838a718049b3ba3be42f3aef8a970ff4278', 'message': 'Revert ""Revert ""Pin version of setuptools""""\n\nThis reverts commit b7ebc4765a327e97837f2f6696682859eb77a93d.\n\nWe weren\'t quite ready yet... :/\n\nChange-Id: Idccc4b79a700ca34a80f590e942e1647cdfdefb0\n'}]",0,142912,2191f838a718049b3ba3be42f3aef8a970ff4278,11,4,1,5263,,,0,"Revert ""Revert ""Pin version of setuptools""""

This reverts commit b7ebc4765a327e97837f2f6696682859eb77a93d.

We weren't quite ready yet... :/

Change-Id: Idccc4b79a700ca34a80f590e942e1647cdfdefb0
",git fetch https://review.opendev.org/openstack/devstack refs/changes/12/142912/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_pip.sh'],1,2191f838a718049b3ba3be42f3aef8a970ff4278,setuptools-8-patch1,"pip_install -U ""setuptools<8.0""",pip_install -U setuptools,1,1
openstack%2Fneutron~master~Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1,openstack/neutron,master,Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1,Advanced services support in neutron-db-manage,MERGED,2014-12-10 00:27:45.000000000,2014-12-18 23:54:12.000000000,2014-12-18 20:03:26.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6951}, {'_account_id': 7249}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-10 00:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e6767eb0ad1f3993d6a47d4b9ee8297c8932cb94', 'message': 'Advanced services support in neutron-db-manage\n\nChange-Id: Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1\n'}, {'number': 2, 'created': '2014-12-10 01:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/490233674c91dccd990882b73fe41599fb07c669', 'message': 'Advanced services support in neutron-db-manage\n\nChange-Id: Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1\n'}, {'number': 3, 'created': '2014-12-10 06:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/230986f3c296b21e6ece3223a016e4c5f2d5716a', 'message': 'Advanced services support in neutron-db-manage\n\nChange-Id: Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1\n'}, {'number': 4, 'created': '2014-12-10 23:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f592630d1e3737578de9e9e1a06af5b2f80600bc', 'message': 'Advanced services support in neutron-db-manage\n\nChange-Id: Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1\n'}, {'number': 5, 'created': '2014-12-11 19:38:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f88221f45d19f9c6c395443a355ff4b492903bb', 'message': 'Advanced services support in neutron-db-manage\n\nPartially-Implements: blueprint split-services\n\nChange-Id: Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1\n'}, {'number': 6, 'created': '2014-12-11 20:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d5fb5868c64c60a62f6764657f41f72839fa7399', 'message': 'Advanced services support in neutron-db-manage\n\nPartially-Implements: blueprint split-services\n\nChange-Id: Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1\n'}, {'number': 7, 'created': '2014-12-11 20:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5b1891810dbec02cd1b487985f4bf3608169be7', 'message': 'Advanced services support in neutron-db-manage\n\nPartially-Implements: blueprint services-split\n\nChange-Id: Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1\n'}, {'number': 8, 'created': '2014-12-15 19:57:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1bdd9a86676d05311a433bdea917d5d1f273a286', 'message': 'Advanced services support in neutron-db-manage\n\nPartially-Implements: blueprint services-split\n\nChange-Id: Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1\n'}, {'number': 9, 'created': '2014-12-16 06:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d857e8a80b48a7037bc37a390a001f6d76594c7a', 'message': 'Advanced services support in neutron-db-manage\n\nPartially-Implements: blueprint services-split\n\nChange-Id: Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1\n'}, {'number': 10, 'created': '2014-12-16 17:02:19.000000000', 'files': ['neutron/db/migration/cli.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1abcead6040df1db87862c2383a145c41705906d', 'message': 'Advanced services support in neutron-db-manage\n\nPartially-Implements: blueprint services-split\n\nChange-Id: Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1\n'}]",31,140537,1abcead6040df1db87862c2383a145c41705906d,249,35,10,6951,,,0,"Advanced services support in neutron-db-manage

Partially-Implements: blueprint services-split

Change-Id: Ib8cd77e5e777be83c44b69edc0a6d2d2ba5d2ab1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/140537/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/cli.py'],1,e6767eb0ad1f3993d6a47d4b9ee8297c8932cb94,neutron-db-manage-services,"LBAAS_SERVICE = 'lbaas' FWAAS_SERVICE = 'fwaas' VPNAAS_SERVICE = 'vpnaas' SERVICES_SCRIPT_LOCATION = 'db/migration/alembic_migrations' cfg.StrOpt('service', default='', help=_(""Advanced service to run command""))def get_script_location(neutron_config): location = 'neutron.db.migration:alembic_migrations' service_name = neutron_config.service service_lib = None if service_name == LBAAS_SERVICE: import neutron_lbaas as service_lib elif service_name == FWAAS_SERVICE: import neutron_fwaas as service_lib elif service_name == VPNAAS_SERVICE: import neutron_vpnaas as service_lib if service_lib is not None: location = service_lib.__file__.rstrip('__init__.pyc') location = location.rstrip('__init__.py') location += SERVICES_SCRIPT_LOCATION return location config.set_main_option('script_location', get_script_location(CONF)) CONF(project='neutron')"," config.set_main_option('script_location', 'neutron.db.migration:alembic_migrations') # attach the Neutron conf to the Alembic conf CONF(project='neutron')",26,4
openstack%2Ftaskflow~master~I069881c80b0b2916cc0c414992b80171f7eeb79f,openstack/taskflow,master,I069881c80b0b2916cc0c414992b80171f7eeb79f,"Move over to using oslo.utils [reflection, uuidutils]",MERGED,2014-12-09 03:57:55.000000000,2014-12-18 23:42:37.000000000,2014-12-18 23:42:35.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-09 03:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4545b23fd3781e44a732058f901dd782599670df', 'message': 'Move over to using oslo.utils [reflection, uuidutils]\n\nThe reflection module is now part of oslo.utils so we should\nremove our local version and use that version instead; this\nalso goes for the uuidutils module which is now part of the\nsame module so we no longer need our local version.\n\nNote that one reflection method `find_subclasses` which was to\nspecific to taskflow is now moved to the misc utility module\ninstead of its prior home in the reflection module.\n\nChange-Id: I069881c80b0b2916cc0c414992b80171f7eeb79f\n'}, {'number': 2, 'created': '2014-12-09 03:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9f0abc6e52a744a59512948a4e38d2a0d691b6c7', 'message': 'Move over to using oslo.utils [reflection, uuidutils]\n\nThe reflection module is now part of oslo.utils so we should\nremove our local version and use that version instead; this\nalso goes for the uuidutils module which is now part of the\nsame module so we no longer need our local version.\n\nNote that one reflection method `find_subclasses` which was to\nspecific to taskflow is now moved to the misc utility module\ninstead of its prior home in the reflection module.\n\nChange-Id: I069881c80b0b2916cc0c414992b80171f7eeb79f\n'}, {'number': 3, 'created': '2014-12-09 04:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ba7e7377485accc4013834a639e440ea79fe3b11', 'message': 'Move over to using oslo.utils [reflection, uuidutils]\n\nThe reflection module is now part of oslo.utils so we should\nremove our local version and use that version instead; this\nalso goes for the uuidutils module which is now part of\noslo.utils as well so we no longer need our local version\ncopied from the incubator...\n\nNote that one reflection method `find_subclasses` which was to\nspecific to taskflow is now moved to the misc utility module\ninstead of its prior home in the reflection module.\n\nChange-Id: I069881c80b0b2916cc0c414992b80171f7eeb79f\n'}, {'number': 4, 'created': '2014-12-11 04:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a10bc3d8d2a9f36b8b63bceabd5e50aba85d60cb', 'message': 'Move over to using oslo.utils [reflection, uuidutils]\n\nThe reflection module is now part of oslo.utils so we should\nremove our local version and use that version instead; this\nalso goes for the uuidutils module which is now part of\noslo.utils as well so we no longer need our local version\ncopied from the incubator...\n\nNote that one reflection method `find_subclasses` which was to\nspecific to taskflow is now moved to the misc utility module\ninstead of its prior home in the reflection module.\n\nChange-Id: I069881c80b0b2916cc0c414992b80171f7eeb79f\n'}, {'number': 5, 'created': '2014-12-11 23:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2de595f28f767bede981325083ce77750387be33', 'message': 'Move over to using oslo.utils [reflection, uuidutils]\n\nThe reflection module is now part of oslo.utils so we should\nremove our local version and use that version instead; this\nalso goes for the uuidutils module which is now part of\noslo.utils as well so we no longer need our local version\ncopied from the incubator...\n\nNote that one reflection method `find_subclasses` which was to\nspecific to taskflow is now moved to the misc utility module\ninstead of its prior home in the reflection module.\n\nChange-Id: I069881c80b0b2916cc0c414992b80171f7eeb79f\n'}, {'number': 6, 'created': '2014-12-14 03:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e69a05cb0e9f4ddd73bface44e70e09a4a3d712a', 'message': 'Move over to using oslo.utils [reflection, uuidutils]\n\nThe reflection module is now part of oslo.utils so we should\nremove our local version and use that version instead; this\nalso goes for the uuidutils module which is now part of\noslo.utils as well so we no longer need our local version\ncopied from the incubator...\n\nNote that one reflection method `find_subclasses` which was to\nspecific to taskflow is now moved to the misc utility module\ninstead of its prior home in the reflection module.\n\nChange-Id: I069881c80b0b2916cc0c414992b80171f7eeb79f\n'}, {'number': 7, 'created': '2014-12-14 05:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ecd77e37d557983e90e0a0358c31feb508434bd8', 'message': 'Move over to using oslo.utils [reflection, uuidutils]\n\nThe reflection module is now part of oslo.utils so we should\nremove our local version and use that version instead; this\nalso goes for the uuidutils module which is now part of\noslo.utils as well so we no longer need our local version\ncopied from the incubator...\n\nNote that one reflection method `find_subclasses` which was to\nspecific to taskflow is now moved to the misc utility module\ninstead of its prior home in the reflection module.\n\nChange-Id: I069881c80b0b2916cc0c414992b80171f7eeb79f\n'}, {'number': 8, 'created': '2014-12-18 21:58:48.000000000', 'files': ['taskflow/tests/unit/persistence/base.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/utils/deprecation.py', 'taskflow/types/failure.py', 'taskflow/openstack/__init__.py', 'taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/jobs/job.py', 'taskflow/tests/unit/persistence/test_zk_persistence.py', 'taskflow/utils/reflection.py', 'taskflow/atom.py', 'taskflow/examples/create_parallel_volume.py', 'taskflow/flow.py', 'taskflow/storage.py', 'taskflow/examples/resume_vm_boot.py', 'taskflow/persistence/backends/sqlalchemy/models.py', 'openstack-common.conf', 'taskflow/engines/helpers.py', 'taskflow/tests/unit/worker_based/test_worker.py', 'taskflow/engines/worker_based/protocol.py', 'taskflow/engines/worker_based/worker.py', 'taskflow/tests/unit/worker_based/test_endpoint.py', 'taskflow/utils/persistence_utils.py', 'taskflow/openstack/common/uuidutils.py', 'taskflow/persistence/logbook.py', 'taskflow/types/cache.py', 'taskflow/examples/fake_billing.py', 'taskflow/tests/unit/worker_based/test_protocol.py', 'taskflow/tests/unit/worker_based/test_pipeline.py', 'taskflow/tests/unit/jobs/base.py', 'taskflow/tests/unit/worker_based/test_message_pump.py', 'taskflow/types/notifier.py', 'taskflow/openstack/common/__init__.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/worker_based/executor.py', 'taskflow/task.py', 'doc/source/utils.rst', 'taskflow/engines/worker_based/endpoint.py', 'taskflow/tests/unit/test_utils.py', 'taskflow/utils/kazoo_utils.py', 'taskflow/tests/unit/jobs/test_zk_job.py', 'taskflow/tests/unit/test_listeners.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4e514f41e57983e728db9025126df6f791a2594a', 'message': 'Move over to using oslo.utils [reflection, uuidutils]\n\nThe reflection module is now part of oslo.utils so we should\nremove our local version and use that version instead; this\nalso goes for the uuidutils module which is now part of\noslo.utils as well so we no longer need our local version\ncopied from the incubator...\n\nNote that one reflection method `find_subclasses` which was to\nspecific to taskflow is now moved to the misc utility module\ninstead of its prior home in the reflection module.\n\nChange-Id: I069881c80b0b2916cc0c414992b80171f7eeb79f\n'}]",0,140220,4e514f41e57983e728db9025126df6f791a2594a,31,4,8,1297,,,0,"Move over to using oslo.utils [reflection, uuidutils]

The reflection module is now part of oslo.utils so we should
remove our local version and use that version instead; this
also goes for the uuidutils module which is now part of
oslo.utils as well so we no longer need our local version
copied from the incubator...

Note that one reflection method `find_subclasses` which was to
specific to taskflow is now moved to the misc utility module
instead of its prior home in the reflection module.

Change-Id: I069881c80b0b2916cc0c414992b80171f7eeb79f
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/20/140220/8 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/tests/unit/persistence/base.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/utils/deprecation.py', 'taskflow/types/failure.py', 'taskflow/openstack/__init__.py', 'taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/jobs/job.py', 'taskflow/tests/unit/persistence/test_zk_persistence.py', 'taskflow/utils/reflection.py', 'taskflow/atom.py', 'taskflow/examples/create_parallel_volume.py', 'taskflow/flow.py', 'taskflow/storage.py', 'taskflow/examples/resume_vm_boot.py', 'taskflow/persistence/backends/sqlalchemy/models.py', 'openstack-common.conf', 'taskflow/engines/helpers.py', 'taskflow/tests/unit/worker_based/test_worker.py', 'taskflow/tests/unit/test_task.py', 'taskflow/engines/worker_based/protocol.py', 'taskflow/engines/worker_based/worker.py', 'taskflow/tests/unit/worker_based/test_endpoint.py', 'taskflow/utils/persistence_utils.py', 'taskflow/openstack/common/uuidutils.py', 'taskflow/persistence/logbook.py', 'taskflow/types/cache.py', 'taskflow/examples/fake_billing.py', 'taskflow/tests/unit/worker_based/test_protocol.py', 'taskflow/tests/unit/worker_based/test_pipeline.py', 'taskflow/tests/unit/jobs/base.py', 'taskflow/tests/unit/worker_based/test_message_pump.py', 'taskflow/types/notifier.py', 'requirements-py2.txt', 'taskflow/openstack/common/__init__.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/worker_based/executor.py', 'taskflow/task.py', 'taskflow/engines/worker_based/endpoint.py', 'taskflow/tests/unit/test_utils.py', 'taskflow/utils/kazoo_utils.py', 'taskflow/tests/unit/jobs/test_zk_job.py', 'requirements-py3.txt', 'taskflow/tests/unit/test_listeners.py', 'taskflow/utils/misc.py']",44,4545b23fd3781e44a732058f901dd782599670df,use-oslo-utils,"import typesfrom oslo.utils import importutilsfrom oslo.utils import reflectiondef find_subclasses(locations, base_cls, exclude_hidden=True): """"""Finds subclass types in the given locations. This will examines the given locations for types which are subclasses of the base class type provided and returns the found subclasses (or fails with exceptions if this introspection can not be accomplished). If a string is provided as one of the locations it will be imported and examined if it is a subclass of the base class. If a module is given, all of its members will be examined for attributes which are subclasses of the base class. If a type itself is given it will be examined for being a subclass of the base class. """""" derived = set() for item in locations: module = None if isinstance(item, six.string_types): try: pkg, cls = item.split(':') except ValueError: module = importutils.import_module(item) else: obj = importutils.import_class('%s.%s' % (pkg, cls)) if not reflection.is_subclass(obj, base_cls): raise TypeError(""Item %s is not a %s subclass"" % (item, base_cls)) derived.add(obj) elif isinstance(item, types.ModuleType): module = item elif reflection.is_subclass(item, base_cls): derived.add(item) else: raise TypeError(""Item %s unexpected type: %s"" % (item, type(item))) # If it's a module derive objects from it if we can. if module is not None: for (name, obj) in inspect.getmembers(module): if name.startswith(""_"") and exclude_hidden: continue if reflection.is_subclass(obj, base_cls): derived.add(obj) return derived ",from taskflow.utils import reflection,95,606
openstack%2Ftaskflow~master~I2684f39b3525ee2d43a03ab353d029fdc0e1b2a1,openstack/taskflow,master,I2684f39b3525ee2d43a03ab353d029fdc0e1b2a1,Add a parallel table mutation example,MERGED,2014-11-07 14:25:35.000000000,2014-12-18 23:41:18.000000000,2014-12-18 23:41:17.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6773}]","[{'number': 1, 'created': '2014-11-07 14:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7e43327f47150a0fb23ca7cff3ffdd7c4e292998', 'message': 'Add a parallel table mutation example\n\nA new simple example that is pretty easy to follow that does\na embarrassingly parallel computation on some input table to\ncreate a new output table (by performing a multiplication on\neach cell in that source table to create a new table).\n\nChange-Id: I2684f39b3525ee2d43a03ab353d029fdc0e1b2a1\n'}, {'number': 2, 'created': '2014-11-07 14:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dd8f7c0762933a01986d5c8ab73c44fd50fbb992', 'message': 'Add a parallel table mutation example\n\nA new simple example that is pretty easy to follow that does\na embarrassingly parallel computation on some input table to\ncreate a new output table (by performing a multiplication on\neach cell in that source table to create a new table).\n\nChange-Id: I2684f39b3525ee2d43a03ab353d029fdc0e1b2a1\n'}, {'number': 3, 'created': '2014-11-07 14:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8a03cd87f692f42bb1af66e22aef565fe948ca1f', 'message': 'Add a parallel table mutation example\n\nA new simple example that is pretty easy to follow that does\na embarrassingly parallel computation on some input table to\ncreate a new output table (by performing a multiplication on\neach cell in that source table to create a new table).\n\nChange-Id: I2684f39b3525ee2d43a03ab353d029fdc0e1b2a1\n'}, {'number': 4, 'created': '2014-11-07 14:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a201a1245352217a069427846297eb2cd88b5023', 'message': 'Add a parallel table mutation example\n\nA new simple example that is pretty easy to follow that does\na embarrassingly parallel computation on some input table to\ncreate a new output table (by performing a multiplication on\neach cell in that source table to create a new table).\n\nChange-Id: I2684f39b3525ee2d43a03ab353d029fdc0e1b2a1\n'}, {'number': 5, 'created': '2014-12-17 19:13:35.000000000', 'files': ['doc/source/examples.rst', 'taskflow/examples/parallel_table_multiply.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cafa3b2e256275d24d1c2a298580316448119740', 'message': 'Add a parallel table mutation example\n\nA new simple example that is pretty easy to follow that does\na embarrassingly parallel computation on some input table to\ncreate a new output table (by performing a multiplication on\neach cell in that source table to create a new table).\n\nPart of blueprint more-examples\n\nChange-Id: I2684f39b3525ee2d43a03ab353d029fdc0e1b2a1\n'}]",0,133247,cafa3b2e256275d24d1c2a298580316448119740,18,5,5,1297,,,0,"Add a parallel table mutation example

A new simple example that is pretty easy to follow that does
a embarrassingly parallel computation on some input table to
create a new output table (by performing a multiplication on
each cell in that source table to create a new table).

Part of blueprint more-examples

Change-Id: I2684f39b3525ee2d43a03ab353d029fdc0e1b2a1
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/47/133247/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/examples.rst', 'taskflow/examples/parallel_table_multiply.py']",2,7e43327f47150a0fb23ca7cff3ffdd7c4e292998,,"# -*- coding: utf-8 -*- # Copyright (C) 2014 Yahoo! Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import csv import logging import os import random import sys logging.basicConfig(level=logging.ERROR) top_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir, os.pardir)) sys.path.insert(0, top_dir) from six.moves import range as compat_range from taskflow import engines from taskflow.patterns import unordered_flow as uf from taskflow import task from taskflow.types import futures from taskflow.utils import async_utils # INTRO: This example walks through a miniature workflow which does a parallel # table modification where each row in the table gets adjusted by a thread, or # green thread (if eventlet is available) in parallel and then the result # is reformed into a new table and some verifications are performed on it # to ensure everything went as expected. MULTIPLER = 10 class RowMultiplier(task.Task): """"""Performs a modification of an input row, creating a output row."""""" def __init__(self, name, index, row, multiplier): super(RowMultiplier, self).__init__(name=name) self.index = index self.multiplier = multiplier self.row = row def execute(self): return [r * self.multiplier for r in self.row] def make_flow(table): # This creation will allow for parallel computation (since the flow here # is specifically unordered; and when things are unordered they have # no dependencies and when things have no dependencies they can just be # ran at the same time, limited in concurrency by the executor or max # workers of that executor...) f = uf.Flow(""root"") for i, row in enumerate(table): f.add(RowMultiplier(""m-%s"" % i, i, row, MULTIPLER)) return f def main(): if len(sys.argv) == 2: tbl = [] with open(sys.argv[1], 'rb') as fh: reader = csv.reader(fh) for row in reader: tbl.append([float(r) if r else 0.0 for r in row]) else: # Make some random table out of thin air.... tbl = [] cols = random.randint(1, 100) rows = random.randint(1, 100) for _i in compat_range(0, rows): row = [] for _j in compat_range(0, cols): row.append(random.random()) tbl.append(row) f = make_flow(tbl) if async_utils.EVENTLET_AVAILABLE: executor = futures.GreenThreadPoolExecutor(max_workers=5) else: executor = futures.ThreadPoolExecutor(max_workers=5) try: e = engines.load(f, engine='parallel', executor=executor) for st in e.run_iter(): print(st) finally: executor.shutdown() # Find the old rows and put them into place... # # TODO(harlowja): probably easier just to sort instead of search... computed_tbl = [] for i in compat_range(0, len(tbl)): for t in f: if t.index == i: computed_tbl.append(e.storage.get(t.name)) if len(computed_tbl) != len(tbl): return 1 else: return 0 if __name__ == ""__main__"": sys.exit(main()) ",,140,0
openstack%2Fcinder~master~I119abb67a109d60f05b64a132ea8472ffef23941,openstack/cinder,master,I119abb67a109d60f05b64a132ea8472ffef23941,Fix format errors in brick/iscsi LOG messages,ABANDONED,2014-12-18 22:23:47.000000000,2014-12-18 23:38:07.000000000,,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 11811}, {'_account_id': 12370}]","[{'number': 1, 'created': '2014-12-18 22:23:47.000000000', 'files': ['cinder/brick/iscsi/iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/999b8cdef82b307771ac20be0b9dada10ff824cf', 'message': 'Fix format errors in brick/iscsi LOG messages\n\nCurrently in cinder.brick.iscsi.iscs:LioADM.create_iscsi_target\nThe Log message for the exception is: LOG.error(""%s"" % e),\n\nthis rightfully results in:\n  *** UnicodeError: UnicodeError(u\'Message objects\n      do not support str() because they may contain\n      non-ascii characters. Please use unicode() or\n      translate() instead.\',)\n\nIn some cases this causes the Volume service to stop and\ndoesn\'t help a ton with debug.\n\nWe could use combinations of translate() or unicode()\nas suggested, or even maybe the six lib, but also we\ncould just log the stderr member of the exception only.\n\nThis is probably better here anyway, so we don\'t do things\nlike leak chap creds in to the log files.\n\nChange-Id: I119abb67a109d60f05b64a132ea8472ffef23941\nCloses-Bug: #1402078\n'}]",17,142913,999b8cdef82b307771ac20be0b9dada10ff824cf,7,5,1,2243,,,0,"Fix format errors in brick/iscsi LOG messages

Currently in cinder.brick.iscsi.iscs:LioADM.create_iscsi_target
The Log message for the exception is: LOG.error(""%s"" % e),

this rightfully results in:
  *** UnicodeError: UnicodeError(u'Message objects
      do not support str() because they may contain
      non-ascii characters. Please use unicode() or
      translate() instead.',)

In some cases this causes the Volume service to stop and
doesn't help a ton with debug.

We could use combinations of translate() or unicode()
as suggested, or even maybe the six lib, but also we
could just log the stderr member of the exception only.

This is probably better here anyway, so we don't do things
like leak chap creds in to the log files.

Change-Id: I119abb67a109d60f05b64a132ea8472ffef23941
Closes-Bug: #1402078
",git fetch https://review.opendev.org/openstack/cinder refs/changes/13/142913/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/brick/iscsi/iscsi.py'],1,999b8cdef82b307771ac20be0b9dada10ff824cf,bug/1402078," except putils.ProcessExecutionError as e: LOG.error(_LE(""Failed recovery attempt to create "" ""iscsi backing lun for Volume "" ""ID: %(vol_id)s: %(e)s"") % {'vol_id': name, 'e': e.stderr}) LOG.debug('Failed to open config for Volume ' 'ID: %(vol_id)s: %(e)s' % {'vol_id': vol_id, 'e': e.stderr}) LOG.debug('Failed to find CHAP auth from config for ' 'Volume ID: %s' % vol_id) LOG.info(_LI('Creating iscsi_target for ' 'Volume ID: %s') % vol_id) LOG.warning(_LW(""Failed to create iscsi target for Volume "" ""ID: %(vol_id)s: %(e)s"") % {'vol_id': vol_id, 'e': e.stderr}) LOG.error(_LE(""Failed to create iscsi target for Volume "" ""ID: %(vol_id)s. Please ensure your tgtd config "" ""file contains 'include %(volumes_dir)s/*'"") % { LOG.info(_LI('Removing iscsi_target for Volume ID: %s') % vol_id) LOG.error(_LE(""Failed to remove iscsi target for Volume "" ""ID: %(vol_id)s: %(e)s"") % {'vol_id': vol_id, 'e': e.stderr}) LOG.error(_LE(""Failed to remove iscsi target for Volume "" ""ID: %(vol_id)s: %(e)s"") % {'vol_id': vol_id, 'e': e.stderr}) LOG.error(_LE(""Failed to create iscsi target for Volume "" ""ID: %(vol_id)s: %(e)s"") % {'vol_id': vol_id, 'e': e.stderr}) LOG.info(_LI('Removing iscsi_target for Volume ID: %s') % vol_id) LOG.info(_LI('Creating iscsi_target for Volume ID: %s') % vol_id) LOG.error(_LE(""Failed to create iscsi target for Volume "" ""ID: %(vol_id)s, Error: %(err)s."") % {'vol_id': vol_id, 'err': e.stderr}) LOG.error(_LE(""Failed to create iscsi target for Volume "" ""ID: %s."") % vol_id) LOG.info(_LI('Removing iscsi_target for Volume ID: %s') % vol_id) LOG.error(_LE(""Failed to remove iscsi target for Volume "" ""ID: %(vol_id)s, Error: %(err)s"") % {'vol_id': vol_id, 'err': e.stderr})","import six LOG.debug('StdOut from recreate backing lun: %s' % out) LOG.debug('StdErr from recreate backing lun: %s' % err) except putils.ProcessExecutionError as e: LOG.error(_LE(""Failed to recover attempt to create "" ""iscsi backing lun for volume "" ""id:%(vol_id)s: %(e)s"") % {'vol_id': name, 'e': e}) LOG.debug('Failed to open config for %(vol_id)s: %(e)s' % {'vol_id': vol_id, 'e': six.text_type(e)}) LOG.debug('Failed to find CHAP auth from config for %s' % vol_id) LOG.info(_LI('Creating iscsi_target for: %s') % vol_id) LOG.debug(""StdOut from tgt-admin --update: %s"", out) LOG.debug(""StdErr from tgt-admin --update: %s"", err) LOG.warning(_LW(""Failed to create iscsi target for volume "" ""id:%(vol_id)s: %(e)s"") % {'vol_id': vol_id, 'e': e}) LOG.error(_LE(""Failed to create iscsi target for volume "" ""id:%(vol_id)s. Please ensure your tgtd config file "" ""contains 'include %(volumes_dir)s/*'"") % { LOG.info(_LI('Removing iscsi_target for: %s') % vol_id) LOG.error(_LE(""Failed to remove iscsi target for volume "" ""id:%(vol_id)s: %(e)s"") % {'vol_id': vol_id, 'e': e}) LOG.error(_LE(""Failed to remove iscsi target for volume "" ""id:%(vol_id)s: %(e)s"") % {'vol_id': vol_id, 'e': e}) LOG.error(_LE(""Failed to create iscsi target for volume "" ""id:%(vol_id)s: %(e)s"") % {'vol_id': vol_id, 'e': e}) LOG.info(_LI('Removing iscsi_target for volume: %s') % vol_id) LOG.info(_LI('Creating iscsi_target for volume: %s') % vol_id) LOG.error(_LE(""Failed to create iscsi target for volume "" ""id:%s."") % vol_id) LOG.error(""%s"" % e) LOG.error(_LE(""Failed to create iscsi target for volume "" ""id:%s."") % vol_id) LOG.info(_LI('Removing iscsi_target: %s') % vol_id) LOG.error(_LE(""Failed to remove iscsi target for volume "" ""id:%s."") % vol_id) LOG.error(""%s"" % e)",38,40
openstack%2Fheat-templates~master~I09a58250f965a0545c55c316a65ad7c525be17c7,openstack/heat-templates,master,I09a58250f965a0545c55c316a65ad7c525be17c7,Fix broken heat-config-notify,MERGED,2014-12-18 22:44:47.000000000,2014-12-18 23:17:16.000000000,2014-12-18 23:17:15.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 13134}]","[{'number': 1, 'created': '2014-12-18 22:44:47.000000000', 'files': ['hot/software-config/elements/heat-config/bin/heat-config-notify'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/fa1732161361e011439620d90f6ab9b93f526ee6', 'message': 'Fix broken heat-config-notify\n\ninit_logging did not return log, so the script would exit on the\nfirst attempt to log anything.\n\nChange-Id: I09a58250f965a0545c55c316a65ad7c525be17c7\n'}]",0,142921,fa1732161361e011439620d90f6ab9b93f526ee6,7,3,1,4571,,,0,"Fix broken heat-config-notify

init_logging did not return log, so the script would exit on the
first attempt to log anything.

Change-Id: I09a58250f965a0545c55c316a65ad7c525be17c7
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/21/142921/1 && git format-patch -1 --stdout FETCH_HEAD,['hot/software-config/elements/heat-config/bin/heat-config-notify'],1,fa1732161361e011439620d90f6ab9b93f526ee6,heat-config-kubelet, return log,,1,0
openstack%2Ffuel-web~master~I434960e8ae7707608e4c1b1235300fcb2db26596,openstack/fuel-web,master,I434960e8ae7707608e4c1b1235300fcb2db26596,Describes Fuel build system,MERGED,2014-10-02 13:39:14.000000000,2014-12-18 23:11:58.000000000,2014-12-18 23:11:57.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 6476}, {'_account_id': 7195}, {'_account_id': 8003}, {'_account_id': 8787}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 9977}, {'_account_id': 10014}, {'_account_id': 12200}, {'_account_id': 12867}, {'_account_id': 12972}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-10-02 13:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/90ce32143f4046c18b4596d55815508629d469c5', 'message': 'Describes Fuel build system\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 2, 'created': '2014-10-02 14:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/13db99e960be86c12ddbd142ac4087a2453e2453', 'message': 'Describes Fuel build system\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 3, 'created': '2014-11-05 09:56:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2487e5caead1d2605a710ab7f0c15265daa23e95', 'message': 'Describes Fuel build system\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 4, 'created': '2014-11-05 10:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6505d3a6be21f1b18766151b7b68559ae4dc6018', 'message': 'Describes Fuel build system\n\nco-authored by: Vladimir Kozhukalov <v.kozhukalov@mirantis.com>\nco-authored by: Irina Povolotskaya <i.povolotskaya@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 5, 'created': '2014-11-05 10:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f4b83c697e28b2f2dd2829f8df557e4037352004', 'message': 'Describes Fuel build system\n\nco-authored by: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\nco-authored by: Irina Povolotskaya <ipovolotskaya@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 6, 'created': '2014-11-06 07:30:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3406a49b98282bdd8e9e1f02e8157fb1b14b8413', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 7, 'created': '2014-11-07 09:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9a753de0f7729dfeda0d8ef702e04b2d28f6fc0b', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 8, 'created': '2014-11-10 07:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2a43ce6df670d8f586a65a2472d3273c16fe21a5', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 9, 'created': '2014-11-12 11:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8af42054ee6d371e10137f563db013275c5e02ca', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 10, 'created': '2014-11-12 11:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ae9a9789597b3b25854ee7d2ec83061b1827795c', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 11, 'created': '2014-11-12 12:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6dce465b2b0283cedd076d9e1545dd580dab4e53', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 12, 'created': '2014-11-12 12:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e1a10a93bf64c4b9059b3607f391b72fc6f3479d', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 13, 'created': '2014-11-12 13:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1873f8bc5719c81ac867c087807ccaf01823b48d', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 14, 'created': '2014-11-12 14:04:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bffd40ccbd6754d8b4a1e8595d9540244cb50589', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 15, 'created': '2014-11-13 08:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/55286bc6ac7fc1309aa4970b203f1e236ebae5b6', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 16, 'created': '2014-11-13 14:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1c0a4f8e581ced4d38b0927430137140ebd50755', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 17, 'created': '2014-11-14 09:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/896cc5473d8d05cc835334b3c5d48ec1390c44e0', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 18, 'created': '2014-11-14 12:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e98aca1fe47dc7ada65a3d02033171b42909d2bf', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 19, 'created': '2014-11-14 13:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c5067a0c8e8ffddde80dbd257a238cae58002397', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 20, 'created': '2014-11-14 13:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3955dc46be1878c76251fcf47f81e17411ac9645', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 21, 'created': '2014-11-18 08:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/464f692314482d53af5de5f15646257b7295792c', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 22, 'created': '2014-11-19 11:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/675632353c750b6e6eabf60226890155353151d4', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 23, 'created': '2014-11-25 07:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/387f1a75810de8bf8a6c3e0e28d6791cc66111f8', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 24, 'created': '2014-12-02 13:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e1b7e31559aac3eec54c445c6a81d3ff114de474', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 25, 'created': '2014-12-02 14:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/018d5e59ae077d393238ea4517af2c9bee4b3f0d', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}, {'number': 26, 'created': '2014-12-18 10:52:34.000000000', 'files': ['docs/buildsystem.rst', 'docs/index.rst'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9d94d8a61093714d0b39305da3eb1c64e70a4138', 'message': 'Describes Fuel build system\n\nCo-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>\n\nChange-Id: I434960e8ae7707608e4c1b1235300fcb2db26596\nCloses-Bug: 1365441\n'}]",89,125637,9d94d8a61093714d0b39305da3eb1c64e70a4138,178,15,26,13082,,,0,"Describes Fuel build system

Co-Authored-By: Vladimir Kozhukalov <vkozhukalov@mirantis.com>

Change-Id: I434960e8ae7707608e4c1b1235300fcb2db26596
Closes-Bug: 1365441
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/37/125637/25 && git format-patch -1 --stdout FETCH_HEAD,['buildsystem/buildsystem.rst'],1,90ce32143f4046c18b4596d55815508629d469c5,bug/1365441,"Build options ------------- All build options are mentioned in `config.mk <https://github.com/stackforge/fuel-main/blob/master/config.mk>`_. You can provide options via command line, environment variables or put them directly in config.mk - TOP_DIR - base for calculation of other directories. Not used directly - BUILD_DIR - path for build objects. - ARTS_DIR - path for build artifacts. - LOCAL_MIRROR - path for local mirror. - DEPS_DIR - path for artifacts from another releases (for upgrade tarball). - PRODUCT_VERSION - version of master node and current release. - ISO_NAME - name of iso file without extension. - UPGRADE_TARBALL_NAME - name of upgrade tarball without extension. - OPENSTACK_PATCH_TARBALL_NAME - deprecated - VBOX_SCRIPTS_NAME - name of zip file with Virtualbox scripts without extension. This variables can be changed only in config.mk (Should we allow to change them via environment variables?): ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ - ISO_PATH - full path for the iso (ignores ISO_NAME). - IMG_PATH - full path for the img (ignores ISO_NAME). - UPGRADE_TARBALL_PATH - full path for upgrade tarball (ignores UPGRADE_TARBALL_NAME). - VBOX_SCRIPTS_PATH - full path for Virtualbox scripts archive (ignores VBOX_SCRIPTS_NAME). - NO_UI_OPTIMIZE - use uncompressed UI (for development). Default network settings for master node ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ - MASTER_IP - MASTER_DNS - MASTER_NETMASK - MASTER_GW Other options ~~~~~~~~~~~~~ - BUILD_PACKAGES - deprecated - BUILD_OPENSTACK_PACKAGES - list of openstack packages to be rebuilt from source - [repo]_REPO - remote source code repo - [repo]_COMMIT - branch for checkout - [repo]_GERRIT_URL - gerrit repo - [repo]_GERRIT_COMMIT - list of extra commits from gerrit - [repo]_SPEC_REPO - repo for rpm/deb specs of openstack packages - [repo]_SPEC_COMMIT - branch for checkout - [repo]_SPEC_GERRIT_URL - gerrit repo for openstack specs - [repo]_SPEC_GERRIT_COMMIT - list of extra commits from gerrit for specs repo is on of: FUELLIB, NAILGUN, ASTUTE, OSTF TBD: get list of openstack repos - USE_MIRROR - Use pre-built mirrors from Fuel infrastructure (ext/srt/msk/hrk/none) - MIRROR_CENTOS - Download centos packages from this remote repo - MIRROR_UBUNTU - Download ubuntu packages from this remote repo - MIRROR_DOCKER - Download docker images form this remote url - MIRROR_FUEL - Download Fuel centos packages from this repo. Should be converted to external url. - MIRROR_FUEL_UBUNTU - Download Fuel ubuntu packages from this repo. Should be converted to external url. - YUM_REPOS - should be depricated - EXTRA_RPM_REPOS - extra repos with rpm packages. See config.mk for exact format - EXTRA_DEP_REPOS - extra repos with deb packages. See config.mk for exact format If you want to add more packages to the master node, update requirements-rpm.txt and requirements-deb.txt. FEATURE_GROUPS - Options for the iso. Combination of: mirantis (use mirantis logos and logic), experimental (allow experimental features on ui) DOCKER_PREBUILT - deprecated DOCKER_PREBUILT_SOURCE - deprecated PRODUCTION - deprecated Fuel build system ----------------- Fuel build process is based on make utility. - repos - mirror - puppet - packages - OpenStack packages - Docker - ISO - Upgrade - Virtualbox - Fuelweb_test",,105,0
openstack%2Fnova~master~I2a61dba5a273455d6b3c15e9cae0f3bff7f641fa,openstack/nova,master,I2a61dba5a273455d6b3c15e9cae0f3bff7f641fa,libvirt: introduce a fixture for mocking out libvirt connections,MERGED,2014-12-10 15:06:18.000000000,2014-12-18 23:11:42.000000000,2014-12-18 18:58:15.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64cf047348a3fb24f77e764a11089e01e17149ca', 'message': 'libvirt: introduce a fixture for mocking out libvirt connections\n\nThe various libvirt test suites all have different ways of mocking\nout libvirt connections. Some use fakelibvirt, others create their\nown lame re-implementation of fakelibvirt, others mock random\nmethods. To improve sanity, introduce a standard fixture to be used\nby all libvirt tests for mocking libvirt. This will ensure that the\nlibvirt.openAuth method always returns an instance of fakelibvirt\nvirConnect object. This should allow for a number of the fakelibvirt\nreimplementations to be eliminated eventually.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I2a61dba5a273455d6b3c15e9cae0f3bff7f641fa\n'}, {'number': 2, 'created': '2014-12-10 17:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6321663cec1662829230ecf032b59d732743db9b', 'message': 'libvirt: introduce a fixture for mocking out libvirt connections\n\nThe various libvirt test suites all have different ways of mocking\nout libvirt connections. Some use fakelibvirt, others create their\nown lame re-implementation of fakelibvirt, others mock random\nmethods. To improve sanity, introduce a standard fixture to be used\nby all libvirt tests for mocking libvirt. This will ensure that the\nlibvirt.openAuth method always returns an instance of fakelibvirt\nvirConnect object. This should allow for a number of the fakelibvirt\nreimplementations to be eliminated eventually.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I2a61dba5a273455d6b3c15e9cae0f3bff7f641fa\n'}, {'number': 3, 'created': '2014-12-16 12:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a0b6e2b7fa75160ce1e62eebb07f917647f5c5b4', 'message': 'libvirt: introduce a fixture for mocking out libvirt connections\n\nThe various libvirt test suites all have different ways of mocking\nout libvirt connections. Some use fakelibvirt, others create their\nown lame re-implementation of fakelibvirt, others mock random\nmethods. To improve sanity, introduce a standard fixture to be used\nby all libvirt tests for mocking libvirt. This will ensure that the\nlibvirt.openAuth method always returns an instance of fakelibvirt\nvirConnect object. This should allow for a number of the fakelibvirt\nreimplementations to be eliminated eventually.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I2a61dba5a273455d6b3c15e9cae0f3bff7f641fa\n'}, {'number': 4, 'created': '2014-12-17 11:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93f6ba60537cc884d04ed3d6db0eb94011d04d4b', 'message': 'libvirt: introduce a fixture for mocking out libvirt connections\n\nThe various libvirt test suites all have different ways of mocking\nout libvirt connections. Some use fakelibvirt, others create their\nown lame re-implementation of fakelibvirt, others mock random\nmethods. To improve sanity, introduce a standard fixture to be used\nby all libvirt tests for mocking libvirt. This will ensure that the\nlibvirt.openAuth method always returns an instance of fakelibvirt\nvirConnect object. This should allow for a number of the fakelibvirt\nreimplementations to be eliminated eventually.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I2a61dba5a273455d6b3c15e9cae0f3bff7f641fa\n'}, {'number': 5, 'created': '2014-12-18 14:18:25.000000000', 'files': ['nova/tests/unit/virt/libvirt/fakelibvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/635580fdb9595cc55fcfb23b96028399d9044874', 'message': 'libvirt: introduce a fixture for mocking out libvirt connections\n\nThe various libvirt test suites all have different ways of mocking\nout libvirt connections. Some use fakelibvirt, others create their\nown lame re-implementation of fakelibvirt, others mock random\nmethods. To improve sanity, introduce a standard fixture to be used\nby all libvirt tests for mocking libvirt. This will ensure that the\nlibvirt.openAuth method always returns an instance of fakelibvirt\nvirConnect object. This should allow for a number of the fakelibvirt\nreimplementations to be eliminated eventually.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I2a61dba5a273455d6b3c15e9cae0f3bff7f641fa\n'}]",2,140714,635580fdb9595cc55fcfb23b96028399d9044874,48,15,5,1779,,,0,"libvirt: introduce a fixture for mocking out libvirt connections

The various libvirt test suites all have different ways of mocking
out libvirt connections. Some use fakelibvirt, others create their
own lame re-implementation of fakelibvirt, others mock random
methods. To improve sanity, introduce a standard fixture to be used
by all libvirt tests for mocking libvirt. This will ensure that the
libvirt.openAuth method always returns an instance of fakelibvirt
virConnect object. This should allow for a number of the fakelibvirt
reimplementations to be eliminated eventually.

Blueprint: libvirt-driver-class-refactor
Change-Id: I2a61dba5a273455d6b3c15e9cae0f3bff7f641fa
",git fetch https://review.opendev.org/openstack/nova refs/changes/14/140714/5 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/libvirt/fakelibvirt.py'],1,64cf047348a3fb24f77e764a11089e01e17149ca,libvirt-driver-refactor-3,"import fixtures from lxml import etree import mock class FakeLibvirtFixture(fixtures.Fixture): """"""This fixture patches the libvirt.openAuth method so that it always returns an instance of fakelibvirt.virConnect. This ensures the tests don't mistakenly connect to a real libvirt daemon instance which would lead non-deterministic behaviour. """""" def setUp(self): super(FakeLibvirtFixture, self).setUp() try: import libvirt patcher = mock.patch.object( libvirt, ""openAuth"", return_value=virConnect(""qemu:///system"")) patcher.start() self.addCleanup(patcher.stop) except ImportError: # If we can't import libvirt, the tests will use # fakelibvirt regardless, so nothing todo here pass",from lxml import etree ,28,2
openstack%2Ffuel-docs~master~I8867755a3e385c0dd6d55f2a8ae3f8be5b4e4251,openstack/fuel-docs,master,I8867755a3e385c0dd6d55f2a8ae3f8be5b4e4251,Cinder text changed for Assign roles to nodes,MERGED,2014-12-12 20:17:30.000000000,2014-12-18 23:00:16.000000000,2014-12-18 23:00:15.000000000,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8735}, {'_account_id': 8787}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-12-12 20:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/986d520310bee61feb0f0f6088fdb867bbce3249', 'message': 'Cinder text changed for Assign roles to nodes\n\nAlso added pointer to Zabbix planning doc\nand explained the MAC address component of the default node name\n\nChange-Id: I8867755a3e385c0dd6d55f2a8ae3f8be5b4e4251\nPartial-Bug: 136845\n'}, {'number': 2, 'created': '2014-12-13 00:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/57fb79dc3e83d4fe16812f11b42bd09ecdfcb368', 'message': 'Cinder text changed for Assign roles to nodes\n\nAlso added pointer to Zabbix planning doc\nand explained the MAC address component of the default node name\n\nChange-Id: I8867755a3e385c0dd6d55f2a8ae3f8be5b4e4251\nPartial-Bug: 136845\n'}, {'number': 3, 'created': '2014-12-15 11:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1ce213aeb89b2e40efd778beaef5f7d2779c37d0', 'message': 'Cinder text changed for Assign roles to nodes\n\nAlso added pointer to Zabbix planning doc\nand explained the MAC address component of the default node name\n\nChange-Id: I8867755a3e385c0dd6d55f2a8ae3f8be5b4e4251\nPartial-Bug: 136845\n'}, {'number': 4, 'created': '2014-12-18 22:28:39.000000000', 'files': ['pages/user-guide/config-environment/1200-customize-partitions.rst', 'pages/user-guide/config-environment/1000-assign-roles.rst', 'pages/release-notes/v6-0/9010-vmware-tech.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/7ac22ea69bdaa4d7ddf8795a97c142fe3ef59c4c', 'message': 'Cinder text changed for Assign roles to nodes\n\nAlso added pointer to Zabbix planning doc\nand explained the MAC address component of the default node name\n\nCo-Authored-By: Dmitry Borodaenko <dborodaenko@mirantis.com>\nChange-Id: I8867755a3e385c0dd6d55f2a8ae3f8be5b4e4251\nCloses-Bug: #1398780\n'}]",4,141481,7ac22ea69bdaa4d7ddf8795a97c142fe3ef59c4c,31,8,4,10014,,,0,"Cinder text changed for Assign roles to nodes

Also added pointer to Zabbix planning doc
and explained the MAC address component of the default node name

Co-Authored-By: Dmitry Borodaenko <dborodaenko@mirantis.com>
Change-Id: I8867755a3e385c0dd6d55f2a8ae3f8be5b4e4251
Closes-Bug: #1398780
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/81/141481/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/user-guide/config-environment/1000-assign-roles.rst', '_images/user_screen_shots/assign-roles1.png']",2,986d520310bee61feb0f0f6088fdb867bbce3249,bug/136845,,,6,9
openstack%2Fneutron-specs~master~I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d,openstack/neutron-specs,master,I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d,FWaaS Insertion Model on Routers,MERGED,2014-12-03 09:37:29.000000000,2014-12-18 22:59:53.000000000,2014-12-18 22:59:51.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 6995}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9375}, {'_account_id': 10041}, {'_account_id': 10182}, {'_account_id': 12525}]","[{'number': 1, 'created': '2014-12-03 09:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9841919a9bcd36a77e2264e3c7127740e1cb4fde', 'message': 'FWaaS Insertion Model on a Single Router\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith a specified Router as opposed to the current model of association\nwith all Routers in the tenant.\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}, {'number': 2, 'created': '2014-12-03 22:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0224c530b62c6d55b409e5d79d17da0dcadddb36', 'message': 'FWaaS Insertion Model on a Single Router\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith a specified Router as opposed to the current model of association\nwith all Routers in the tenant.\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}, {'number': 3, 'created': '2014-12-09 21:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f099f86cc92530e58c0fcb6f641bc80b9ea3502a', 'message': 'FWaaS Insertion Model on a Single Router\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith a specified Router as opposed to the current model of association\nwith all Routers in the tenant.\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}, {'number': 4, 'created': '2014-12-12 06:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ecfa3cd11f09419200728ab416186f1c61e6de41', 'message': 'FWaaS Insertion Model on a Single Router\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith a specified Router as opposed to the current model of association\nwith all Routers in the tenant.\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}, {'number': 5, 'created': '2014-12-12 06:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d71562dfa1e4f186a0e967fe0e996951656e51fa', 'message': 'FWaaS Insertion Model on a Single Router\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith a specified Router as opposed to the current model of association\nwith all Routers in the tenant.\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}, {'number': 6, 'created': '2014-12-12 21:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c07e2cb79976e7964123ebb0722424ed0c8d3ef2', 'message': 'FWaaS Insertion Model on a Single Router\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith a specified Router as opposed to the current model of association\nwith all Routers in the tenant.\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}, {'number': 7, 'created': '2014-12-12 21:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/27ac2a383c7968a8a7f9c2ef917d47483e121ac1', 'message': 'FWaaS Insertion Model on a Single Router\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith a specified Router as opposed to the current model of association\nwith all Routers in the tenant.\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}, {'number': 8, 'created': '2014-12-15 16:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/58ef911b3738c66f2a4caae8f22ae298307e3c4b', 'message': 'FWaaS Insertion Model on a Single Router\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith a specified Router as opposed to the current model of association\nwith all Routers in the tenant.\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}, {'number': 9, 'created': '2014-12-17 04:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/16a2c529f4a35b5f244b98e56e35121adfdd1402', 'message': 'FWaaS Insertion Model on a Single Router\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith a specified Router as opposed to the current model of association\nwith all Routers in the tenant.\n\nAPIImpact\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}, {'number': 10, 'created': '2014-12-17 04:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8a1afafffbf8acd854182b4372739764ee4afba2', 'message': 'FWaaS Insertion Model on a Single Router\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith a specified Router as opposed to the current model of association\nwith all Routers in the tenant.\n\nAPIImpact\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}, {'number': 11, 'created': '2014-12-18 07:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/1bbefeb3c25f25b676ce86339a88b7cfcf85cb78', 'message': 'FWaaS Insertion Model on Routers\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith specified Routers as opposed to the current model of association\nwith all Routers in the tenant.\n\nAPIImpact\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}, {'number': 12, 'created': '2014-12-18 07:35:02.000000000', 'files': ['specs/kilo/fwaas-router-insertion.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e484c082023205f72402cccfe1f80ab866ad7989', 'message': 'FWaaS Insertion Model on Routers\n\nSpecification to change the FWaaS insertion model to associate a Firewall\nwith specified Routers as opposed to the current model of association\nwith all Routers in the tenant.\n\nAPIImpact\n\nChange-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d\nImplements: blueprint fwaas-router-insertion\n'}]",107,138672,e484c082023205f72402cccfe1f80ab866ad7989,75,20,12,6995,,,0,"FWaaS Insertion Model on Routers

Specification to change the FWaaS insertion model to associate a Firewall
with specified Routers as opposed to the current model of association
with all Routers in the tenant.

APIImpact

Change-Id: I14085af97f3bbad4530a3ff97c107b6dbbc8bd1d
Implements: blueprint fwaas-router-insertion
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/72/138672/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/fwaas-router-insertion.rst'],1,9841919a9bcd36a77e2264e3c7127740e1cb4fde,bp/fwaas-router-insertion,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== FWaaS Insertion Model on a Single Router ========================================== https://blueprints.launchpad.net/neutron/+spec/fwaas-router-insertion The blueprint proposes a change to the FWaaS insertion model to associate a Firewall with a specified Router as opposed to the current model of association with all Routers in the tenant. Problem Description =================== The FWaaS model defines 3 resources: Firewall rules, Firewall policies and Firewalls. The Firewall rules has attributes to specify a filter rule. The Firewall policy is a container for a collection of rules. The Firewall itself is associated with a Firewall policy and thereby indirectly to a set of rules. The insertion point of the Firewall is not specified with the intent to abstract insertion from the service itself to allow for various types of insertion points (L3, Bump in the wire etc). The FWaaS reference implementation inserts the Firewall on all 'qr-' interfaces on all routers in the tenant. The plan was to allow the insertion point to be driven by the Service Insertion proposals.[1][2] Given that the Service Insertion proposals have not been adopted for various reasons, the objective of this effort is to restrict the scope to FWaaS and insertion on a single Router. In the current model and implementation we can only support a single Firewall on a tenant as the Firewall is present on all Routers. This does not provide the ability to selectively Firewall traffic for a subnet or a set of subnets in the tenant topology. This requires all Rules for a tenant topology to be collected together in the policy associated with the Firewall. This is both inefficient and prone to errors. Routers are not tracked on the Firewall DB so it is not always straightforward to reflect the Firewall state based on the state transtions on one of potentiall many Routers associated with the Firewall. We can handle the case when a new Router is added but it is more involved to handle Router deletions. Proposed Change =============== It is being proposed to associate a Firewall with a single Router which is specified in the API. Resource validation can be performed and appropriate action can be taken by the Plugin. The insertion point as the Router will be tracked in the Firewall DB. With this change we can support multiple Firewalls within a tenant with better discrimination based on the Router insertion point rather than have all rules for the entire topology applied every where. With some trepidition the additional attribute can be proposed as an extension or this can be added as an attribute to the Firewall extension. Some suggestions and comments are solicited to drive consensus on this point especially in light of the refactor happening with extensions. A minor variation with this same fundamental intent of the Firewall being associated with a single Router is more favored based on discussions with members of the FWaaS subteam and associated individuals with interactions with Customers and Deployers. Rather than associating with a Router and implicitly on all its interfaces, an option to selectively apply to a specified set of the Router's interfaces is proposed. This enables some of the typical use cases such as a Firewall for the Engineering subnet and a different Firewall for the Sales subnet both hanging off the same Router. An option to specify to apply on all interfaces can be supported for users looking at this just as a perimeter firewall without the need to be specific on a subset of interfaces. With this variation on the theme, the list of interfaces in addition to the Router will be accomodated as an attribute to the Firewall extension or proposed as an extension. Data Model Impact ----------------- The proposal is to introduce a table that tracks the insertion points (Router + List of its interfaces) of the Firewall resource. It is felt that taking this approach as opposed to adding this to the firewall table keeps the model more flexible. Other approaches can be considered based on feedback. As these attributes are Foreign Keys, appropriate constraints can be applied as well. +-------------------+------------+-----------+------+-------------------------+ | Attribute name | Type | Required | CRUD | Description | +-------------------+------------+-----------+------+-------------------------+ | fwid | uuid | Y | R |Firewall id | +-------------------+------------+-----------+------+-------------------------+ | router_id | uuid | N | CRU |Associated Router | +-------------------+------------+-----------+------+-------------------------+ | port_id_list | list | N | CRU |List of Router ports | +-------------------+------------+-----------+------+-------------------------+ REST API Impact --------------- This would the addition to the Firewall resource. As mentioned earlier, an approach consistent with the extensions rework will be adopted. .. code-block:: python RESOURCE_ATTRIBUTE_MAP = { 'firewalls': { 'router_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True}, 'router_ports': {'allow_post': True, 'allow_put': True, 'validate': {'type:uuid_list': None}, 'convert_to': attr.convert_none_to_empty_list, 'default': None, 'is_visible': True}, } } Security Impact --------------- None. Notifications Impact -------------------- The FWaaS Agent will not need to consume all router_add events as in the current model. No changes to any messaging is planned. Other End User Impact --------------------- In the current model, FWaaS does not specify any insertion point. The API will now accomodate the Router and the list of Router interfaces. As in the current model, the state will start in PENDING_CREATE (or CREATED in DVR mode) and will go to ACTIVE with successful completion of messaging with the FWaaS Agent and the iptables backend. The CLI representation below is one possible suggestion. neutron firewall-create FW-POLICY --router-id <r1> --port-id <p1> --port-id <p2> ... And if this is needed on all ports of the router then a form similar to the below CLI representation can be used. This can also ensure that any new interfaces on the Router can have the Firewall installed on it automatically by listening on Router notifications. neutron firewall-create FW-POLICY --router-id <r1> --all-ports If these new attributes are not specified on firewall-create, the firewall logical resource will be created and be in PENDING_CREATE (or CREATED in DVR mode) state. This is similar to the current model when there are no routers present in the tenant. With this proposal, the Firewall state will change to ACTIVE on a firewall-update with the insertion point details. The CLI representation below is one possible suggestion. neutron firewall-update FIREWALL --router-id <r1> --port-id <p1> --port-id <p2> ... There are no changes on the Firewall Rules and Firewall Policy resources. Performance Impact ------------------ None. IPv6 Impact ----------- No impacts. Other Deployer Impact --------------------- Deployers will need to provide the additional attributes for the Firewall resource. Further, deployers will need to be aware that the Firewall will not be applied to all Routers in the tenant automatically. Developer Impact ---------------- Any Plugins that rely on the Firewall being installed on all Routers in the tenant and are based directly off the reference implementation will need to be changed. This model has been brought up in the FWaaS IRC and by reaching out to the FWaaS developers. No significant impact has been noted. This spec also serves to address any concerns. Community Impact ---------------- This change has been discussed in the past and attempts were made to address this through the Service Insertion blueprints. The need to address this issue has been discussed within the FWaaS subteam. And this has been brought up at the recent summit by Mark and discussed with other cores. Some of the details on the approach has been discussed amongst the FWaaS subteam at the summit and continued over at the FWaaS IRC. Alternatives ------------ * Add just the Router as the insertion point. * Look again at one of the earlier Service Insertion proposals.[1][2] Implementation ============== Assignee(s) ----------- skandasw Work Items ---------- * Refactor Plugin for new attribute(s) to be supported. * DB changes to track the insertion points for the firewall. * Agent interaction changes to the messaging dict to include the insertion points. * Refactor FW Agent, to deal with specified router and not worry about all routers. * Refactor iptables driver to support interface list. Dependencies ============ No direct dependency but with the services spinout, L3 Agent refactor this can cause some pain. But it is seen that some of this can be complementary. Testing ======= Tempest Tests ------------- Existing tempest test will be modified to add additional attributes. Functional Tests ---------------- Basic functionality is not being changed so the changes to functional tests will just involve the addition of specifying new insertion point attributes. API Tests --------- Changes to add the new attributes. Documentation Impact ==================== User Documentation ------------------ User Documentation will be updated to include the new attributes and minor change to the workflow wherein now the insertion points will need to be specified. Developer Documentation ----------------------- API changes will be documented. References ========== [1]https://blueprints.launchpad.net/neutron/+spec/neutron-services-insertion-chaining-steering [2]https://blueprints.launchpad.net/neutron/+spec/service-base-class-and-insertion ",,244,0
openstack%2Ftripleo-image-elements~master~If584b153e8ded71e63be129b62cecd7544aabb07,openstack/tripleo-image-elements,master,If584b153e8ded71e63be129b62cecd7544aabb07,Only configure Neutron DB connection if it is set,MERGED,2014-11-25 20:11:15.000000000,2014-12-18 22:59:22.000000000,2014-12-18 22:59:21.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6928}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-11-25 20:11:15.000000000', 'files': ['elements/neutron/os-apply-config/etc/neutron/plugins/ml2/ml2_conf.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d1ead0cbe20852322a2d620b0ededc26dc38434f', 'message': 'Only configure Neutron DB connection if it is set\n\nThe Neutron ml2 agent does not require access to the database.\nThis patch avoids configuring the database/connection setting\nif no metadata is present.\n\nChange-Id: If584b153e8ded71e63be129b62cecd7544aabb07\n'}]",0,137190,d1ead0cbe20852322a2d620b0ededc26dc38434f,13,4,1,360,,,0,"Only configure Neutron DB connection if it is set

The Neutron ml2 agent does not require access to the database.
This patch avoids configuring the database/connection setting
if no metadata is present.

Change-Id: If584b153e8ded71e63be129b62cecd7544aabb07
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/90/137190/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/neutron/os-apply-config/etc/neutron/plugins/ml2/ml2_conf.ini'],1,d1ead0cbe20852322a2d620b0ededc26dc38434f,neutron_db,{{#neutron.ovs_db}}{{/neutron.ovs_db}},,2,0
openstack%2Fnova~master~I1d737fc22bc26b686790c06362eb7c61b26bd39d,openstack/nova,master,I1d737fc22bc26b686790c06362eb7c61b26bd39d,libvirt: convert test_host.py to use FakeLibvirtFixture,MERGED,2014-12-10 15:06:18.000000000,2014-12-18 22:54:41.000000000,2014-12-18 18:58:42.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dcd9b8dee44eb1099d357b62d714d53d5d9855ba', 'message': 'libvirt: convert test_host.py to use FakeLibvirtFixture\n\nInstead of monkey patching the Host class to use fakelibvirt,\njust use the FakeLibvirtFixture. Also create an instance of\nthe Host class in setUp since every test case needs it.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I1d737fc22bc26b686790c06362eb7c61b26bd39d\n'}, {'number': 2, 'created': '2014-12-10 17:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4ca44a2d85f107ea523e01e38b998e1e833e779', 'message': 'libvirt: convert test_host.py to use FakeLibvirtFixture\n\nInstead of monkey patching the Host class to use fakelibvirt,\njust use the FakeLibvirtFixture. Also create an instance of\nthe Host class in setUp since every test case needs it.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I1d737fc22bc26b686790c06362eb7c61b26bd39d\n'}, {'number': 3, 'created': '2014-12-16 12:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a4532a88eefc7fb351c04a1cbc2f34f8d4d9d78', 'message': 'libvirt: convert test_host.py to use FakeLibvirtFixture\n\nInstead of monkey patching the Host class to use fakelibvirt,\njust use the FakeLibvirtFixture. Also create an instance of\nthe Host class in setUp since every test case needs it.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I1d737fc22bc26b686790c06362eb7c61b26bd39d\n'}, {'number': 4, 'created': '2014-12-17 11:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02c790117af97523dbb0628f70f28ab46a4dcb6d', 'message': 'libvirt: convert test_host.py to use FakeLibvirtFixture\n\nInstead of monkey patching the Host class to use fakelibvirt,\njust use the FakeLibvirtFixture. Also create an instance of\nthe Host class in setUp since every test case needs it.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I1d737fc22bc26b686790c06362eb7c61b26bd39d\n'}, {'number': 5, 'created': '2014-12-18 14:18:25.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_host.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4a46f16cdb52dac6cbfcbebfb1cd6d7ba7354dbe', 'message': 'libvirt: convert test_host.py to use FakeLibvirtFixture\n\nInstead of monkey patching the Host class to use fakelibvirt,\njust use the FakeLibvirtFixture. Also create an instance of\nthe Host class in setUp since every test case needs it.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I1d737fc22bc26b686790c06362eb7c61b26bd39d\n'}]",6,140715,4a46f16cdb52dac6cbfcbebfb1cd6d7ba7354dbe,49,13,5,1779,,,0,"libvirt: convert test_host.py to use FakeLibvirtFixture

Instead of monkey patching the Host class to use fakelibvirt,
just use the FakeLibvirtFixture. Also create an instance of
the Host class in setUp since every test case needs it.

Blueprint: libvirt-driver-class-refactor
Change-Id: I1d737fc22bc26b686790c06362eb7c61b26bd39d
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/140715/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/libvirt/test_host.py'],1,dcd9b8dee44eb1099d357b62d714d53d5d9855ba,libvirt-driver-refactor-3," def setUp(self): super(HostTestCase, self).setUp() self.useFixture(fakelibvirt.FakeLibvirtFixture()) self.host = host.Host(""qemu:///system"") mock.patch.object(fakelibvirt.virConnect, ""registerCloseCallback"", self.host.get_connection() mock.patch.object(fakelibvirt.virConnect, ""registerCloseCallback"", connection = self.host.get_connection() mock.patch.object(fakelibvirt.virConnect, ""registerCloseCallback"", connection = self.host.get_connection() conn = self.host._connect(""qemu:///system"", False) fakelibvirt.virConnect, ""getLibVersion"", self.assertFalse(self.host._test_connection(conn)) self.host._connect_auth_cb, creds, False) conn = hostimpl.get_connection() False) def get_conn_currency(host): host.get_connection().getLibVersion() return fakelibvirt.openAuth(""qemu:///system"", [[], lambda: 1, None], 0) self.stubs.Set(self.host, ""_connect"", self.stubs.Set(fakelibvirt.virConnect, 'domainEventRegisterAny', fake_register) get_conn_currency(self.host) get_conn_currency(self.host) def get_conn_currency(host): host.get_connection().getLibVersion() return fakelibvirt.openAuth(""qemu:///system"", [[], lambda: 1, None], 0) self.stubs.Set(self.host, ""_connect"", self.stubs.Set(fakelibvirt.virConnect, 'domainEventRegisterAny', fake_register) thr1 = eventlet.spawn(get_conn_currency, self.host) thr2 = eventlet.spawn(get_conn_currency, self.host) mock.patch.object(fakelibvirt.virConnect, 'getLibVersion'), ) as (mock_ver, ): self.assertTrue(self.host.has_min_version((1, 4, 0))) self.assertFalse(self.host.has_min_version((1, 4, 0))) self.assertTrue(self.host.has_min_version((1, 4, 0)))"," conn = fakelibvirt.Connection(""qemu:///system"") hostimpl = host.Host(""qemu:///system"") mock.patch.object(hostimpl, ""_connect"", return_value=conn), mock.patch.object(conn, ""registerCloseCallback"", hostimpl.get_connection() conn = fakelibvirt.Connection(""qemu:///system"") hostimpl = host.Host(""qemu:///system"") mock.patch.object(hostimpl, ""_connect"", return_value=conn), mock.patch.object(conn, ""registerCloseCallback"", connection = hostimpl.get_connection() conn = fakelibvirt.Connection(""qemu:///system"") hostimpl = host.Host(""qemu:///system"") mock.patch.object(hostimpl, ""_connect"", return_value=conn), mock.patch.object(conn, ""registerCloseCallback"", connection = hostimpl.get_connection() conn = fakelibvirt.Connection(""qemu:///system"") hostimpl = host.Host(""qemu:///system"") hostimpl, ""_connect"", return_value=conn), mock.patch.object( conn, ""getLibVersion"", self.assertFalse(hostimpl._test_connection(conn)) hostimpl = host.Host(""qemu:///system"") hostimpl._connect_auth_cb, creds, False) conn = fakelibvirt.Connection(""qemu:///system"") ""cef19ce0-0ca2-11df-855d-b19fbce37686"") def get_conn_currency(hostimpl): hostimpl.get_connection().getLibVersion() self.conn = fakelibvirt.Connection(""qemu:///system"") return self.conn hostimpl = host.Host(""qemu:///system"") self.stubs.Set(hostimpl, ""_connect"", self.stubs.Set(self.conn, 'domainEventRegisterAny', fake_register) get_conn_currency(hostimpl) get_conn_currency(hostimpl) def get_conn_currency(hostimpl): hostimpl.get_connection().getLibVersion() self.conn = fakelibvirt.Connection(""qemu:///system"") return self.conn hostimpl = host.Host(""qemu:///system"") self.stubs.Set(hostimpl, ""_connect"", self.stubs.Set(self.conn, 'domainEventRegisterAny', fake_register) thr1 = eventlet.spawn(get_conn_currency, hostimpl) thr2 = eventlet.spawn(get_conn_currency, hostimpl) conn = fakelibvirt.Connection(""qemu:///system"") hostimpl = host.Host(""qemu:///system"") mock.patch.object(conn, 'getLibVersion'), mock.patch.object(host.Host, ""get_connection"", return_value=conn), ) as (mock_ver, mock_conn): self.assertTrue(hostimpl.has_min_version((1, 4, 0))) self.assertFalse(hostimpl.has_min_version((1, 4, 0))) self.assertTrue(hostimpl.has_min_version((1, 4, 0)))",44,57
openstack%2Foslo.i18n~master~I800f121c271d8e69f6e776c4aef509bbb8008170,openstack/oslo.i18n,master,I800f121c271d8e69f6e776c4aef509bbb8008170,Move out of the oslo namespace package,MERGED,2014-10-09 19:36:56.000000000,2014-12-18 22:45:33.000000000,2014-12-18 22:45:32.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 4190}, {'_account_id': 5638}, {'_account_id': 6601}, {'_account_id': 6928}, {'_account_id': 11816}]","[{'number': 1, 'created': '2014-10-09 19:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/c0d3fe8840bfccf8d4cc47ab466495e380090324', 'message': 'Move out of the oslo namespace package\n\nMove the public API out of oslo.i18n to oslo_i18n. Retain the ability to\nimport from the old namespace package for backwards compatibility for\nthis release cycle.\n\nChange-Id: I800f121c271d8e69f6e776c4aef509bbb8008170\n'}, {'number': 2, 'created': '2014-11-13 19:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/cd4a4af2f4c645789bf04ecf2c5ca297976a5068', 'message': 'Move out of the oslo namespace package\n\nMove the public API out of oslo.i18n to oslo_i18n. Retain the ability to\nimport from the old namespace package for backwards compatibility for\nthis release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: I800f121c271d8e69f6e776c4aef509bbb8008170\n'}, {'number': 3, 'created': '2014-11-13 19:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/09dfa19aa188bb7a1857308357bd789df991c03d', 'message': 'Move out of the oslo namespace package\n\nMove the public API out of oslo.i18n to oslo_i18n. Retain the ability to\nimport from the old namespace package for backwards compatibility for\nthis release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: I800f121c271d8e69f6e776c4aef509bbb8008170\n'}, {'number': 4, 'created': '2014-11-13 19:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/8d7e4ca4ad2f3861ef1beba6b83325372c6520c9', 'message': 'Move out of the oslo namespace package\n\nMove the public API out of oslo.i18n to oslo_i18n. Retain the ability to\nimport from the old namespace package for backwards compatibility for\nthis release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: I800f121c271d8e69f6e776c4aef509bbb8008170\n'}, {'number': 5, 'created': '2014-12-05 20:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/6bb6f2379b64e2cdbfc51b47fd026d816fee3069', 'message': 'Move out of the oslo namespace package\n\nMove the public API out of oslo.i18n to oslo_i18n. Retain the ability to\nimport from the old namespace package for backwards compatibility for\nthis release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: I800f121c271d8e69f6e776c4aef509bbb8008170\n'}, {'number': 6, 'created': '2014-12-12 21:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/edb464843e88c04378baf26efc38da031441e3cf', 'message': 'Move out of the oslo namespace package\n\nMove the public API out of oslo.i18n to oslo_i18n. Retain the ability to\nimport from the old namespace package for backwards compatibility for\nthis release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: I800f121c271d8e69f6e776c4aef509bbb8008170\n'}, {'number': 7, 'created': '2014-12-18 21:45:22.000000000', 'files': ['oslo_i18n/fixture.py', 'tests/test_handler.py', 'oslo_i18n/_i18n.py', 'tests/test_warning.py', 'doc/source/api.rst', 'doc/source/usage.rst', 'oslo_i18n/tests/test_fixture.py', 'oslo_i18n/tests/fakes.py', 'oslo/i18n/__init__.py', 'oslo_i18n/tests/test_locale_dir_variable.py', 'oslo_i18n/tests/test_message.py', 'oslo/i18n/fixture.py', 'oslo_i18n/_message.py', 'oslo_i18n/__init__.py', 'oslo_i18n/_factory.py', 'oslo_i18n/log.py', 'oslo_i18n/tests/test_gettextutils.py', 'oslo/i18n/log.py', 'oslo_i18n/tests/test_logging.py', 'oslo_i18n/tests/test_lazy.py', 'oslo_i18n/tests/utils.py', 'oslo_i18n/_lazy.py', 'oslo_i18n/tests/__init__.py', 'oslo_i18n/tests/test_translate.py', 'tests/test_public_api.py', 'oslo_i18n/_gettextutils.py', 'tests/test_fixture.py', 'oslo_i18n/tests/test_factory.py', 'oslo_i18n/tests/test_public_api.py', 'oslo_i18n/_translate.py', 'oslo_i18n/tests/test_handler.py', 'setup.cfg', 'tox.ini', 'oslo_i18n/_locale.py', 'doc/source/guidelines.rst'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/ba05e9a9b919e844121164fd23c560056da8a7bb', 'message': 'Move out of the oslo namespace package\n\nMove the public API out of oslo.i18n to oslo_i18n. Retain the ability to\nimport from the old namespace package for backwards compatibility for\nthis release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: I800f121c271d8e69f6e776c4aef509bbb8008170\n'}]",14,127323,ba05e9a9b919e844121164fd23c560056da8a7bb,28,8,7,2472,,,0,"Move out of the oslo namespace package

Move the public API out of oslo.i18n to oslo_i18n. Retain the ability to
import from the old namespace package for backwards compatibility for
this release cycle.

bp/drop-namespace-packages

Change-Id: I800f121c271d8e69f6e776c4aef509bbb8008170
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/23/127323/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_i18n/fixture.py', 'tests/test_handler.py', 'oslo_i18n/_i18n.py', 'doc/source/api.rst', 'doc/source/usage.rst', 'oslo_i18n/tests/test_fixture.py', 'oslo_i18n/tests/fakes.py', 'oslo_i18n/tests/test_locale_dir_variable.py', 'oslo_i18n/tests/test_message.py', 'oslo_i18n/_message.py', 'oslo_i18n/__init__.py', 'oslo_i18n/_factory.py', 'oslo_i18n/log.py', 'oslo_i18n/tests/test_gettextutils.py', 'oslo/i18n.py', 'oslo_i18n/tests/test_logging.py', 'oslo_i18n/tests/test_lazy.py', 'oslo_i18n/tests/utils.py', 'oslo_i18n/_lazy.py', 'oslo_i18n/tests/__init__.py', 'oslo_i18n/tests/test_translate.py', 'tests/test_public_api.py', 'oslo_i18n/_gettextutils.py', 'tests/test_fixture.py', 'oslo_i18n/tests/test_factory.py', 'oslo_i18n/tests/test_public_api.py', 'oslo_i18n/_translate.py', 'oslo_i18n/tests/test_handler.py', 'setup.cfg', 'tox.ini', 'oslo_i18n/_locale.py', 'doc/source/guidelines.rst']",32,c0d3fe8840bfccf8d4cc47ab466495e380090324,bp/drop-namespace-packages,":py:attr:`TranslatorFactory.primary <oslo_i18n.TranslatorFactory.primary>`, which should",":py:attr:`TranslatorFactory.primary <oslo.i18n.TranslatorFactory.primary>`, which should",298,78
openstack%2Fstevedore~master~I92ba44ada0d055d1ca8cc6c950cc2d2d201bf7f3,openstack/stevedore,master,I92ba44ada0d055d1ca8cc6c950cc2d2d201bf7f3,Fix the README.rst file format for pypi,MERGED,2014-12-18 21:12:49.000000000,2014-12-18 22:43:00.000000000,2014-12-18 22:43:00.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-12-18 21:12:49.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/stevedore/commit/9324bf0b675160f6eb4099d17231e289b68097be', 'message': 'Fix the README.rst file format for pypi\n\nPyPI uses vanila docutils instead of sphinx to render the README to\nHTML, so we need to be careful about what directives and roles we use.\n\nChange-Id: I92ba44ada0d055d1ca8cc6c950cc2d2d201bf7f3\n'}]",0,142905,9324bf0b675160f6eb4099d17231e289b68097be,6,2,1,2472,,,0,"Fix the README.rst file format for pypi

PyPI uses vanila docutils instead of sphinx to render the README to
HTML, so we need to be careful about what directives and roles we use.

Change-Id: I92ba44ada0d055d1ca8cc6c950cc2d2d201bf7f3
",git fetch https://review.opendev.org/openstack/stevedore refs/changes/05/142905/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,9324bf0b675160f6eb4099d17231e289b68097be,fix-readme-for-pypi,"=========================================================== stevedore -- Manage dynamic plugins for Python applications ===========================================================library for doing this, using ``__import__`` or ``importlib``. stevedore avoids creating yet another extension","============================================================= stevedore -- Manage dynamic plugins for Python applications =============================================================library for doing this, using ``__import__`` or :mod:`importlib`. stevedore avoids creating yet another extension",5,5
openstack%2Ftooz~master~I9b4e0304483e2c7155f4d5107fd2967ed2c8d1a4,openstack/tooz,master,I9b4e0304483e2c7155f4d5107fd2967ed2c8d1a4,A few more documentation tweaks,MERGED,2014-12-18 21:20:34.000000000,2014-12-18 22:40:51.000000000,2014-12-18 22:40:51.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-12-18 21:20:34.000000000', 'files': ['doc/source/install.rst', 'doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/tooz/commit/4c2996525f96fc7ab93fe787b470d82da6561c19', 'message': 'A few more documentation tweaks\n\n- Capitalize tooz where appropriate.\n- Adjust contents to be an actual header.\n- Add a footnote that states tooz can be generally useful\n  for anyone (and not just openstack projects); this was taken\n  from taskflows similar footnote.\n\nChange-Id: I9b4e0304483e2c7155f4d5107fd2967ed2c8d1a4\n'}]",0,142906,4c2996525f96fc7ab93fe787b470d82da6561c19,6,2,1,1297,,,0,"A few more documentation tweaks

- Capitalize tooz where appropriate.
- Adjust contents to be an actual header.
- Add a footnote that states tooz can be generally useful
  for anyone (and not just openstack projects); this was taken
  from taskflows similar footnote.

Change-Id: I9b4e0304483e2c7155f4d5107fd2967ed2c8d1a4
",git fetch https://review.opendev.org/openstack/tooz refs/changes/06/142906/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install.rst', 'doc/source/index.rst']",2,4c2996525f96fc7ab93fe787b470d82da6561c19,," Tooz -- Distributed System Helper Librarya coordination API helping developers to build distributed applications. [#f1]_ Contents ======== .. [#f1] It should be noted that even though it is designed with OpenStack integration in mind, and that is where most of its *current* integration is it aims to be generally usable and useful in any project.", tooz -- Distributed System Helper Librarya coordination API helping developers to build distributed applications. Contents:,13,6
openstack%2Ffuel-docs~master~I8b00c1a2c946de17133b9abed71e193679d89159,openstack/fuel-docs,master,I8b00c1a2c946de17133b9abed71e193679d89159,Modularize new features in Release Notes,MERGED,2014-12-16 03:22:36.000000000,2014-12-18 22:40:24.000000000,2014-12-18 22:40:24.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 13082}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-12-16 03:22:36.000000000', 'files': ['pages/release-notes/v6-0/0023-other-enhancements.rst', 'pages/release-notes/v6-0/new-features/vlan-for-vcenter.rst', 'pages/release-notes/v6-0/new-features/image-provision.rst', 'pages/release-notes/v6-0/0020-new-features.rst', 'pages/release-notes/v6-0/new-features/openstack-update.rst', 'pages/release-notes/v6-0/new-features/1-1-instance-vsphere-map.rst', 'pages/release-notes/v6-0-juno-full.rst', 'pages/release-notes/v6-0/new-features/100-node.rst', 'pages/release-notes/v6-0/new-features/ha-improve.rst', 'pages/release-notes/v6-0/new-features/nsx.rst', 'pages/release-notes/v6-0/new-features/DNS-NTP-external.rst', 'pages/release-notes/v6-0/new-features/glance-vmdk.rst', 'pages/release-notes/v6-0/new-features/ceilometer-vcenter.rst', 'pages/release-notes/v6-0/new-features/fuel-upgrade.rst', 'pages/release-notes/v6-0/new-features/mongodb-external.rst', 'pages/release-notes/v6-0/new-features/statistics.rst', 'pages/release-notes/v6-0/new-features/plugin-arch.rst', 'pages/release-notes/v6-0/new-features/l2-multiple.rst', 'pages/release-notes/v6-0/new-features/ml2.rst', 'pages/release-notes/v6-0/new-features/sahara-vcenter.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/cb4eddc86410d438f94e5490751c2b53138b68bd', 'message': 'Modularize new features in Release Notes\n\nSTRUCTURE MODIFICATIONS ONLY! No text changes have been made.\n\nBreaking up the New Features and Other Enhancements sections\nof the Release Notes so we have one file per feature heading.\nThis will enable us to populate this information from the CRs\nabout the feature so the Release Notes can cross-reference the\nother docs.\n\n""Other Enhancements"" was not in the tree from the TP so added that\nand created the other-enhancements subdirectory.  Content will be\ndeveloped in the same modular fashion as the new-features.\n\nChange-Id: I8b00c1a2c946de17133b9abed71e193679d89159\n'}]",0,141967,cb4eddc86410d438f94e5490751c2b53138b68bd,13,7,1,10014,,,0,"Modularize new features in Release Notes

STRUCTURE MODIFICATIONS ONLY! No text changes have been made.

Breaking up the New Features and Other Enhancements sections
of the Release Notes so we have one file per feature heading.
This will enable us to populate this information from the CRs
about the feature so the Release Notes can cross-reference the
other docs.

""Other Enhancements"" was not in the tree from the TP so added that
and created the other-enhancements subdirectory.  Content will be
developed in the same modular fashion as the new-features.

Change-Id: I8b00c1a2c946de17133b9abed71e193679d89159
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/67/141967/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v6-0/0023-other-enhancements.rst', 'pages/release-notes/v6-0/new-features/vlan-for-vcenter.rst', 'pages/release-notes/v6-0/new-features/image-provision.rst', 'pages/release-notes/v6-0/0020-new-features.rst', 'pages/release-notes/v6-0/new-features/openstack-update.rst', 'pages/release-notes/v6-0/new-features/1-1-instance-vsphere-map.rst', 'pages/release-notes/v6-0-juno-full.rst', 'pages/release-notes/v6-0/new-features/100-node.rst', 'pages/release-notes/v6-0/new-features/ha-improve.rst', 'pages/release-notes/v6-0/new-features/nsx.rst', 'pages/release-notes/v6-0/new-features/DNS-NTP-external.rst', 'pages/release-notes/v6-0/new-features/glance-vmdk.rst', 'pages/release-notes/v6-0/new-features/ceilometer-vcenter.rst', 'pages/release-notes/v6-0/new-features/fuel-upgrade.rst', 'pages/release-notes/v6-0/new-features/mongodb-external.rst', 'pages/release-notes/v6-0/new-features/statistics.rst', 'pages/release-notes/v6-0/new-features/plugin-arch.rst', 'pages/release-notes/v6-0/new-features/l2-multiple.rst', 'pages/release-notes/v6-0/new-features/ml2.rst', 'pages/release-notes/v6-0/new-features/sahara-vcenter.rst']",20,cb4eddc86410d438f94e5490751c2b53138b68bd,rn-features-structure," Sahara can run in vCenter environment ------------------------------------- Sahara can run in a :ref:`vCenter<vcenter-term>` environment, allowing vCenter to be used for running :ref:`Hadoop<hadoop-term>`. Cluster provisioning, attaching :ref:`Cinder<cinder-term>` volumes, and :ref:`Swift<swift-object-storage-term>` Hadoop integration (including the :ref:`Ceph<ceph-term>` Swift interface that allows Ceph to be used as the storage backend for HDFS file systems) have been implemented and tested. See the `Enable Sahara support in vCenter <https://bugs.launchpad.net/fuel/+bug/1370708>`_ blueprint for implementation details. ",,315,275
openstack%2Fnova~master~I1925a433a00f5ea3b65899ecb64d904045519340,openstack/nova,master,I1925a433a00f5ea3b65899ecb64d904045519340,libvirt: remove unused get_connection parameter from VIF driver,MERGED,2014-12-10 15:06:18.000000000,2014-12-18 22:34:48.000000000,2014-12-18 19:00:27.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4904647f5a479bd4777dc726275bb1c7dcc500a5', 'message': 'libvirt: remove unused get_connection parameter from VIF driver\n\nPreviously the VIF driver would have to take different action\nfor OpenVSwitch depending on the libvirt version. Since we\nbumped the min libvirt version this is no longer required, so\nthe get_connection parameter to the VIF driver is unused.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I1925a433a00f5ea3b65899ecb64d904045519340\n'}, {'number': 2, 'created': '2014-12-10 17:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7b2d1837d8ac1f98fc3a539425080dcd561a28f', 'message': 'libvirt: remove unused get_connection parameter from VIF driver\n\nPreviously the VIF driver would have to take different action\nfor OpenVSwitch depending on the libvirt version. Since we\nbumped the min libvirt version this is no longer required, so\nthe get_connection parameter to the VIF driver is unused.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I1925a433a00f5ea3b65899ecb64d904045519340\n'}, {'number': 3, 'created': '2014-12-16 12:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b23670e3808e81509345440d1841136e4194ede9', 'message': 'libvirt: remove unused get_connection parameter from VIF driver\n\nPreviously the VIF driver would have to take different action\nfor OpenVSwitch depending on the libvirt version. Since we\nbumped the min libvirt version this is no longer required, so\nthe get_connection parameter to the VIF driver is unused.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I1925a433a00f5ea3b65899ecb64d904045519340\n'}, {'number': 4, 'created': '2014-12-17 11:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a6898d07f8433512348411aa7eda6c16af27a76e', 'message': 'libvirt: remove unused get_connection parameter from VIF driver\n\nPreviously the VIF driver would have to take different action\nfor OpenVSwitch depending on the libvirt version. Since we\nbumped the min libvirt version this is no longer required, so\nthe get_connection parameter to the VIF driver is unused.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I1925a433a00f5ea3b65899ecb64d904045519340\n'}, {'number': 5, 'created': '2014-12-18 14:18:25.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/vif.py', 'nova/tests/unit/virt/libvirt/test_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/700be0908bc4482a6c410fce38f336833f586bcd', 'message': 'libvirt: remove unused get_connection parameter from VIF driver\n\nPreviously the VIF driver would have to take different action\nfor OpenVSwitch depending on the libvirt version. Since we\nbumped the min libvirt version this is no longer required, so\nthe get_connection parameter to the VIF driver is unused.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I1925a433a00f5ea3b65899ecb64d904045519340\n'}]",0,140717,700be0908bc4482a6c410fce38f336833f586bcd,40,12,5,1779,,,0,"libvirt: remove unused get_connection parameter from VIF driver

Previously the VIF driver would have to take different action
for OpenVSwitch depending on the libvirt version. Since we
bumped the min libvirt version this is no longer required, so
the get_connection parameter to the VIF driver is unused.

Blueprint: libvirt-driver-class-refactor
Change-Id: I1925a433a00f5ea3b65899ecb64d904045519340
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/140717/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/vif.py', 'nova/tests/unit/virt/libvirt/test_vif.py']",3,4904647f5a479bd4777dc726275bb1c7dcc500a5,libvirt-driver-refactor-3, d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver() d = vif.LibvirtGenericVIFDriver(),"from nova.tests.unit.virt.libvirt import fakelibvirt def _get_conn(self, uri=""qemu:///session"", ver=None): def __inner(): if ver is None: return fakelibvirt.Connection(uri, False) else: return fakelibvirt.Connection(uri, False, ver) return __inner d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn(""xen:///system"")) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9010)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9011)) d = vif.LibvirtGenericVIFDriver(self._get_conn(ver=9011)) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn()) d = vif.LibvirtGenericVIFDriver(self._get_conn())",40,53
openstack%2Fproject-config~master~Id4d7a04b9c98e497d758c5c95bfe454b5cc92743,openstack/project-config,master,Id4d7a04b9c98e497d758c5c95bfe454b5cc92743,Prepare project-config for puppet module split #2,ABANDONED,2014-12-10 01:09:41.000000000,2014-12-18 22:24:32.000000000,,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 6547}, {'_account_id': 7979}, {'_account_id': 9624}]","[{'number': 1, 'created': '2014-12-10 01:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/62894ae9229703eaa34c1ee2522cadab898d4538', 'message': ""Prepare project-config for puppet module split #2\n\nUpdating the gerrit/project.yaml for each puppet-module is a bit tedious.\nNow that we have all the subtrees for the puppet modules running as a cron job [1],\nlet's include all of them here, but commented out.\n\nWhen we're ready to merge, simply uncomment the lines related to the desired module in this file\nand merge. Optionally, you can update the repo url, or make any other adjustments.\n\nSupport: http://specs.openstack.org/openstack-infra/infra-specs/specs/puppet-modules.html\n[1] https://review.openstack.org/#/c/137991/\n\nChange-Id: Id4d7a04b9c98e497d758c5c95bfe454b5cc92743\n""}, {'number': 2, 'created': '2014-12-15 19:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8a38b55076f76ec3fa8c80e30474ed5ae5367a7f', 'message': ""Prepare project-config for puppet module split #2\n\nUpdating the gerrit/project.yaml for each puppet-module is a bit tedious.\nNow that we have all the subtrees for the puppet modules running as a cron job [1],\nlet's include all of them here, but commented out.\n\nWhen we're ready to merge, simply uncomment the lines related to the desired\nmodule in this file and merge. Update the repo url, description, etc.\n\nAfter all desired puppet-modules are split, another patch will be proposed to\nclean-up remaining commented-out lines.\n\nSupport: http://specs.openstack.org/openstack-infra/infra-specs/specs/puppet-modules.html\n[1] https://review.openstack.org/#/c/137991/\n\nChange-Id: Id4d7a04b9c98e497d758c5c95bfe454b5cc92743\n""}, {'number': 3, 'created': '2014-12-15 19:12:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e1ce813f4ced47e9d661eb4ac3045f347a554ed0', 'message': ""Prepare project-config for puppet module split #2\n\nUpdating the gerrit/project.yaml for each puppet-module is a bit tedious.\nNow that we have all the subtrees for the puppet modules running as a cron job [1],\nlet's include all of them here, but commented out.\n\nWhen we're ready to merge, simply uncomment the lines related to the desired\nmodule in this file and merge. Update the repo url, description, etc.\n\nAfter all desired puppet-modules are split, another patch will be proposed to\nclean-up remaining commented-out lines.\n\nSupport: http://specs.openstack.org/openstack-infra/infra-specs/specs/puppet-modules.html\n[1] https://review.openstack.org/#/c/137991/\n\nRelated patch #1: I311af3f7eb724115ba6a2496d0aea4910a98f632\n\nChange-Id: Id4d7a04b9c98e497d758c5c95bfe454b5cc92743\n""}, {'number': 4, 'created': '2014-12-15 21:54:18.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/540c488b351aff0b19097086c74afeaa415dcd6e', 'message': ""Prepare project-config for puppet module split #2\n\nUpdating the gerrit/project.yaml for each puppet-module is a bit tedious.\nNow that we have all the subtrees for the puppet modules running as a cron job [1],\nlet's include all of them here, but commented out.\n\nWhen we're ready to merge, simply uncomment the lines related to the desired\nmodule in this file and merge. Update the repo url, description, etc.\n\nAfter all desired puppet-modules are split, another patch will be proposed to\nclean-up remaining commented-out lines.\n\nSupport: http://specs.openstack.org/openstack-infra/infra-specs/specs/puppet-modules.html\n[1] https://review.openstack.org/#/c/137991/\n\nRelated patch #1: I311af3f7eb724115ba6a2496d0aea4910a98f632\n\nChange-Id: Id4d7a04b9c98e497d758c5c95bfe454b5cc92743\n""}]",1,140548,540c488b351aff0b19097086c74afeaa415dcd6e,22,5,4,9624,,,0,"Prepare project-config for puppet module split #2

Updating the gerrit/project.yaml for each puppet-module is a bit tedious.
Now that we have all the subtrees for the puppet modules running as a cron job [1],
let's include all of them here, but commented out.

When we're ready to merge, simply uncomment the lines related to the desired
module in this file and merge. Update the repo url, description, etc.

After all desired puppet-modules are split, another patch will be proposed to
clean-up remaining commented-out lines.

Support: http://specs.openstack.org/openstack-infra/infra-specs/specs/puppet-modules.html
[1] https://review.openstack.org/#/c/137991/

Related patch #1: I311af3f7eb724115ba6a2496d0aea4910a98f632

Change-Id: Id4d7a04b9c98e497d758c5c95bfe454b5cc92743
",git fetch https://review.opendev.org/openstack/project-config refs/changes/48/140548/2 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,62894ae9229703eaa34c1ee2522cadab898d4538,module-split,# - project: openstack-infra/puppet-accessbot # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-accessbot.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add accessbot functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-ansible # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-ansible.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add ansible functionality # groups: # - openstack-ci# - project: openstack-infra/puppet-asterisk # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-asterisk.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add asterisk functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-bugdaystats # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-bugdaystats.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add bugdaystats functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-bup # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-bup.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add bup functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-cgit # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-cgit.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add cgit functionality # groups: # - openstack-ci# - project: openstack-infra/puppet-devstack_host # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-devstack_host.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add devstack_host functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-drupal # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-drupal.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add drupal functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-elastic_recheck # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-elastic_recheck.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add elastic_recheck functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-elasticsearch # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-elasticsearch.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add elasticsearch functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-etherpad_lite # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-etherpad_lite.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add etherpad_lite functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-exim # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-exim.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add exim functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-gerrit # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-gerrit.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add gerrit functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-gerritbot # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-gerritbot.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add gerritbot functionality # groups: # - openstack-ci# - project: openstack-infra/puppet-graphite # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-graphite.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add graphite functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-haveged # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-haveged.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add haveged functionality # groups: # - openstack-ci# - project: openstack-infra/puppet-iptables # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-iptables.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add iptables functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-jeepyb # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-jeepyb.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add jeepyb functionality # groups: # - openstack-ci# - project: openstack-infra/puppet-kerberos # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-kerberos.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add kerberos functionality # groups: # - openstack-ci# - project: openstack-infra/puppet-lodgeit # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-lodgeit.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add lodgeit functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-log_processor # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-log_processor.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add log_processor functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-logrotate # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-logrotate.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add logrotate functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-logstash # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-logstash.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add logstash functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-mailman # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-mailman.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add mailman functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-mediawiki # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-mediawiki.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add mediawiki functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-meetbot # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-meetbot.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add meetbot functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-mysql_backup # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-mysql_backup.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add mysql_backup functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-nodepool # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-nodepool.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add nodepool functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-openafs # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-openafs.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add openafs functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-openstackid # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-openstackid.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add openstackid functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-openstack_project # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-openstack_project.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add openstack_project functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-packagekit # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-packagekit.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add packagekit functionality # groups: # - openstack-ci# - project: openstack-infra/puppet-planet # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-planet.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add planet functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-project_config # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-project_config.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add project_config functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-redis # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-redis.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add redis functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-releasestatus # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-releasestatus.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add releasestatus functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-remove_nginx # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-remove_nginx.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add remove_nginx functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-reviewday # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-reviewday.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add reviewday functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-snmpd # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-snmpd.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add snmpd functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-ssh # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-ssh.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add ssh functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-ssl_cert_check # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-ssl_cert_check.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add ssl_cert_check functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-statusbot # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-statusbot.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add statusbot functionality # groups: # - openstack-ci# - project: openstack-infra/puppet-subunit2sql # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-subunit2sql.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add subunit2sql functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-subversion # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-subversion.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add subversion functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-sudoers # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-sudoers.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add sudoers functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-tmpreaper # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-tmpreaper.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add tmpreaper functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-ulimit # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-ulimit.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add ulimit functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-unattended_upgrades # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-unattended_upgrades.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add unattended_upgrades functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-unbound # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-unbound.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add unbound functionality # groups: # - openstack-ci # - project: openstack-infra/puppet-user # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-user.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add user functionality # groups: # - openstack-ci#TODO: There already exists an empty openstack-infra/puppet-zuul project # - project: openstack-infra/puppet-zuul # use-storyboard: true # upstream: git://github.com/Triniplex/puppet-zuul.git # acl-config: /home/gerrit2/acls/openstack-infra/puppet-system.config # description: Puppet module to add zuul functionality # groups: # - openstack-ci,,358,0
openstack%2Fpbr~master~I2a5072d73e19ce77fa29ba5d8aa6e9649859a551,openstack/pbr,master,I2a5072d73e19ce77fa29ba5d8aa6e9649859a551,Prefix git suffixes with + instead of .,ABANDONED,2014-12-13 20:26:21.000000000,2014-12-18 22:19:55.000000000,,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4190}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-13 20:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/0c4aba19b9bd31a00ac8dbf20f34c21b88c0dcc2', 'message': ""Prefix git suffixes with + instead of .\n\nsetuptools 8.0 enforces the accepted version of PEP440, which means\nthat 1.2.3.g123456 is now sorted before 1.0. Forget for a second that\nunder no obvious human inspection this makes sense, it is now the law of\nthe land and we must comply.\n\nI swear to god I'm going to start coding in Go.\n\nChange-Id: I2a5072d73e19ce77fa29ba5d8aa6e9649859a551\n""}, {'number': 2, 'created': '2014-12-13 20:32:27.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/fafd6c4db07789b2d378fdb5ceda89115d2abe30', 'message': ""Prefix git suffixes with + instead of .\n\nsetuptools 8.0 enforces the accepted version of PEP440, which means\nthat 1.2.3.g123456 is now sorted before 1.0. Forget for a second that\nunder no obvious human inspection this makes sense, it is now the law of\nthe land and we must comply.\n\nI swear to god I'm going to start coding in Go.\n\nChange-Id: I2a5072d73e19ce77fa29ba5d8aa6e9649859a551\n""}]",1,141580,fafd6c4db07789b2d378fdb5ceda89115d2abe30,13,5,2,2,,,0,"Prefix git suffixes with + instead of .

setuptools 8.0 enforces the accepted version of PEP440, which means
that 1.2.3.g123456 is now sorted before 1.0. Forget for a second that
under no obvious human inspection this makes sense, it is now the law of
the land and we must comply.

I swear to god I'm going to start coding in Go.

Change-Id: I2a5072d73e19ce77fa29ba5d8aa6e9649859a551
",git fetch https://review.opendev.org/openstack/pbr refs/changes/80/141580/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,0c4aba19b9bd31a00ac8dbf20f34c21b88c0dcc2,fix-the-world," return ""%s.dev%s+g%s"" % (pre_version, _get_revno(git_dir), sha) else: return = _run_git_command( ['describe', '--always'], git_dir).replace('-', '.').replace('.g', '+g')"," return ""%s.dev%s.g%s"" % (pre_version, _get_revno(git_dir), sha) else: return _run_git_command( ['describe', '--always'], git_dir).replace('-', '.')",4,3
openstack%2Fopenstack-ansible~stable%2Ficehouse~I94f46f3adb8fa26965959d5e8c6473eff1b4591c,openstack/openstack-ansible,stable/icehouse,I94f46f3adb8fa26965959d5e8c6473eff1b4591c,Use a shared session key among Horizon nodes,MERGED,2014-12-18 20:09:18.000000000,2014-12-18 22:19:16.000000000,2014-12-18 22:19:15.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-18 20:09:18.000000000', 'files': ['etc/rpc_deploy/user_variables.yml', 'rpc_deployment/roles/horizon_common/templates/local_settings.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9989b6d86ee2a9022765960e52ec195158667420', 'message': 'Use a shared session key among Horizon nodes\n\nThis change adds a configuration setting for the Horizon session key. If\npresent, this key is set into all Horizon nodes, so that they can share\nsessions.\n\nChange-Id: I94f46f3adb8fa26965959d5e8c6473eff1b4591c\nCloses-bug: 1403611\n(cherry-picked from commit b5fbb9a673abeedf00c3632f26e31e2d3b18febc)\n'}]",0,142896,9989b6d86ee2a9022765960e52ec195158667420,7,3,1,12606,,,0,"Use a shared session key among Horizon nodes

This change adds a configuration setting for the Horizon session key. If
present, this key is set into all Horizon nodes, so that they can share
sessions.

Change-Id: I94f46f3adb8fa26965959d5e8c6473eff1b4591c
Closes-bug: 1403611
(cherry-picked from commit b5fbb9a673abeedf00c3632f26e31e2d3b18febc)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/96/142896/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/rpc_deploy/user_variables.yml', 'rpc_deployment/roles/horizon_common/templates/local_settings.py']",2,9989b6d86ee2a9022765960e52ec195158667420,bug/1403611,"{% if horizon_secret_key %} SECRET_KEY = ""{{ horizon_secret_key }}"" {% else %}{% endif %}",,5,1
openstack%2Fopenstack-manuals~master~I4c11c73fe9ba42e77c86cefe4360ce2496e810e1,openstack/openstack-manuals,master,I4c11c73fe9ba42e77c86cefe4360ce2496e810e1,Suspending instance will not update resource usage,MERGED,2014-12-17 01:59:51.000000000,2014-12-18 22:18:57.000000000,2014-12-18 22:18:56.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 4428}, {'_account_id': 6772}, {'_account_id': 12402}]","[{'number': 1, 'created': '2014-12-17 01:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1ea7af6a530aab87a5c9a76fbb7c12a2c43cc754', 'message': 'Suspending instance will not update resource usage\n\nAs reported in the bug, ""memory and vCPUs NOT become available to\ncreate other instances when suspending instance"". So update the\ndescription for \' Suspend and resume an instance\'.\n\nChange-Id: I4c11c73fe9ba42e77c86cefe4360ce2496e810e1\nCloses-bug: #1402502\n'}, {'number': 2, 'created': '2014-12-18 00:43:25.000000000', 'files': ['doc/user-guide/section_cli_nova_startstop.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ea465673461d99f44491afb7f29852acd2a637e1', 'message': 'Suspending instance will not update resource usage\n\nAs reported in the bug, ""memory and vCPUs NOT become available to\ncreate other instances when suspending instance"". So update the\ndescription for \' Suspend and resume an instance\'.\n\nChange-Id: I4c11c73fe9ba42e77c86cefe4360ce2496e810e1\nCloses-bug: #1402502\n'}]",2,142302,ea465673461d99f44491afb7f29852acd2a637e1,12,5,2,4428,,,0,"Suspending instance will not update resource usage

As reported in the bug, ""memory and vCPUs NOT become available to
create other instances when suspending instance"". So update the
description for ' Suspend and resume an instance'.

Change-Id: I4c11c73fe9ba42e77c86cefe4360ce2496e810e1
Closes-bug: #1402502
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/02/142302/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide/section_cli_nova_startstop.xml'],1,1ea7af6a530aab87a5c9a76fbb7c12a2c43cc754,wrong-suspend-description, hibernation.</para> <note> <para>Suspending instance will not update resource usage.</para> </note>, hibernation; memory and vCPUs become available to create other instances.</para>,4,2
openstack%2Fopenstack-manuals~stable%2Fjuno~Iae3e5adb26201a8024fa1b7b642b963186f69872,openstack/openstack-manuals,stable/juno,Iae3e5adb26201a8024fa1b7b642b963186f69872,Fixes EPEL repository URL Error,MERGED,2014-12-18 19:20:58.000000000,2014-12-18 22:18:44.000000000,2014-12-18 22:18:43.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 4428}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-18 19:20:58.000000000', 'files': ['doc/install-guide/section_basics-packages.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dea1cdaaa1ba0d02360696e3f489b4ebe92327d9', 'message': 'Fixes EPEL repository URL Error\n\nyum install\nhttp://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-2.noarch.rpm\nshould be:\nyum install\nhttp://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm\n\nChange-Id: Iae3e5adb26201a8024fa1b7b642b963186f69872\nCloses-bug: #1402945\n(cherry picked from commit 4f34cb1276f9714bdd077b2f5e16d8df7f7472c5)\n'}]",0,142883,dea1cdaaa1ba0d02360696e3f489b4ebe92327d9,7,4,1,9515,,,0,"Fixes EPEL repository URL Error

yum install
http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-2.noarch.rpm
should be:
yum install
http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm

Change-Id: Iae3e5adb26201a8024fa1b7b642b963186f69872
Closes-bug: #1402945
(cherry picked from commit 4f34cb1276f9714bdd077b2f5e16d8df7f7472c5)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/83/142883/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_basics-packages.xml'],1,dea1cdaaa1ba0d02360696e3f489b4ebe92327d9,juno/backport/142294," <screen os=""fedora;centos;rhel""><prompt>#</prompt> <userinput>yum install http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm</userinput></screen>"," <screen os=""fedora;centos;rhel""><prompt>#</prompt> <userinput>yum install http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-2.noarch.rpm</userinput></screen>",1,1
openstack%2Ftaskflow~master~I7c04f5508b35b945c49e5798ece0e298d2e1b979,openstack/taskflow,master,I7c04f5508b35b945c49e5798ece0e298d2e1b979,Add a basic map/reduce example to show how this can be done,MERGED,2014-10-22 00:24:09.000000000,2014-12-18 22:13:00.000000000,2014-12-18 22:13:00.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-10-22 00:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5c45b06933f1ed3922e8c9ca01929872f50aca06', 'message': 'Add a basic map/reduce example to show how this can be done\n\nSince we can create tasks, run them in a parallel then direct\nthere result into a result task we can create a workflow that\ncan define how this can be accomplished and have the map ops\nrun in parallel (with the reduction op happening after all the\nmap ops have finished).\n\nChange-Id: I7c04f5508b35b945c49e5798ece0e298d2e1b979\n'}, {'number': 2, 'created': '2014-10-27 23:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cedb73c9f2363abef47985395f4479a48f5fbdb2', 'message': 'Add a basic map/reduce example to show how this can be done\n\nSince we can create tasks, run them in a parallel then direct\nthere result into a result task we can create a workflow that\ncan define how this can be accomplished and have the map ops\nrun in parallel (with the reduction op happening after all the\nmap ops have finished).\n\nChange-Id: I7c04f5508b35b945c49e5798ece0e298d2e1b979\n'}, {'number': 3, 'created': '2014-12-17 19:13:45.000000000', 'files': ['doc/source/examples.rst', 'taskflow/examples/simple_map_reduce.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6520b9c35e1fe2f5a851b0beb9e337595fb58874', 'message': 'Add a basic map/reduce example to show how this can be done\n\nSince we can create tasks, run them in a parallel then direct\nthere result into a result task we can create a workflow that\ncan define how this can be accomplished and have the map ops\nrun in parallel (with the reduction op happening after all the\nmap ops have finished).\n\nPart of blueprint more-examples\n\nChange-Id: I7c04f5508b35b945c49e5798ece0e298d2e1b979\n'}]",0,130072,6520b9c35e1fe2f5a851b0beb9e337595fb58874,13,4,3,1297,,,0,"Add a basic map/reduce example to show how this can be done

Since we can create tasks, run them in a parallel then direct
there result into a result task we can create a workflow that
can define how this can be accomplished and have the map ops
run in parallel (with the reduction op happening after all the
map ops have finished).

Part of blueprint more-examples

Change-Id: I7c04f5508b35b945c49e5798ece0e298d2e1b979
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/72/130072/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/examples.rst', 'taskflow/examples/simple_map_reduce.py']",2,5c45b06933f1ed3922e8c9ca01929872f50aca06,,"# -*- coding: utf-8 -*- # Copyright (C) 2014 Yahoo! Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging import os import sys logging.basicConfig(level=logging.ERROR) self_dir = os.path.abspath(os.path.dirname(__file__)) top_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir, os.pardir)) sys.path.insert(0, top_dir) sys.path.insert(0, self_dir) # INTRO: this examples shows a simplistic map/reduce implementation where # a set of mapper(s) will sum a series of input numbers (in parallel) and # return there individual summed result. A reducer will then use those # produced values and perform a final summation and this result will then be # printed (and verified to ensure the calculation was as expected). from taskflow import engines from taskflow.patterns import linear_flow from taskflow.patterns import unordered_flow from taskflow import task class SumMapper(task.Task): def execute(self, inputs): # Sums some set of provided inputs. return sum(inputs) class TotalReducer(task.Task): def execute(self, *args, **kwargs): # Reduces all mapped summed outputs into a single value. return sum(kwargs.values()) # Upper bound of numbers to sum for example purposes... UPPER_BOUND = 1000 SPLIT = 10 # This will be the workflow we will compose and run. w = linear_flow.Flow(""root"") # The mappers will run in parallel. store = {} provided = [] mappers = unordered_flow.Flow('map') for i in range(0, SPLIT): mapper_name = 'mapper_%s' % i # Give that mapper some information to compute. store[mapper_name] = list(range(0, UPPER_BOUND)) provided.append(""reduction_%s"" % i) mappers.add(SumMapper(mapper_name, rebind={'inputs': mapper_name}, provides=provided[-1])) w.add(mappers) # The reducer will run last (after all mappers). w.add(TotalReducer('reduce', requires=provided)) # Now go! e = engines.load(w, engine='parallel', store=store) e.run() # Now get the result the reducer created. total = e.storage.get('reduce') print(total) # Calculate it manually to verify that it worked... calc_total = SPLIT * sum(range(0, UPPER_BOUND)) if calc_total != total: sys.exit(1) ",,101,0
openstack%2Fswift~master~Ib5b29a19e1d577026deb50fc9d26064a8da81cd7,openstack/swift,master,Ib5b29a19e1d577026deb50fc9d26064a8da81cd7,fix dlo manifest file getting versioned,MERGED,2014-12-09 02:32:46.000000000,2014-12-18 22:03:33.000000000,2014-12-18 22:03:30.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 5189}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-09 02:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9174c8a8720c104754fecff15186709a25017ba4', 'message': 'fix dlo manifest file getting versioned\n\nAccording to documentation dlo manifest files should not\nbe versioned. This patch fixes this issue and adds\nsome unit and functional for this scenario.\n\nChange-Id: Ib5b29a19e1d577026deb50fc9d26064a8da81cd7\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 2, 'created': '2014-12-09 02:43:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8bcb49926c9d43e79a12d2b9be488ee1494d9721', 'message': 'fix dlo manifest file getting versioned\n\nAccording to documentation dlo manifest files should not\nbe versioned. This patch fixes this issue and adds\nsome unit and functional for this scenario.\n\nChange-Id: Ib5b29a19e1d577026deb50fc9d26064a8da81cd7\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 3, 'created': '2014-12-18 20:14:19.000000000', 'files': ['test/unit/proxy/test_server.py', 'test/functional/tests.py', 'swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/24330771af0b77bb1042e280af5db3c51e8b883b', 'message': 'fix dlo manifest file getting versioned\n\nAccording to documentation dlo manifest files should not\nbe versioned. This patch fixes this issue and adds\nsome unit and functional for this scenario.\n\nChange-Id: Ib5b29a19e1d577026deb50fc9d26064a8da81cd7\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}]",1,140206,24330771af0b77bb1042e280af5db3c51e8b883b,18,8,3,9625,,,0,"fix dlo manifest file getting versioned

According to documentation dlo manifest files should not
be versioned. This patch fixes this issue and adds
some unit and functional for this scenario.

Change-Id: Ib5b29a19e1d577026deb50fc9d26064a8da81cd7
Signed-off-by: Thiago da Silva <thiago@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/06/140206/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/proxy/test_server.py', 'test/functional/tests.py', 'swift/proxy/controllers/obj.py']",3,9174c8a8720c104754fecff15186709a25017ba4,fix_obj_version_dlo_manifest, is_manifest = 'X-Object-Manifest' in req.headers or \ 'X-Object-Manifest' in hresp.headers if hresp.status_int != HTTP_NOT_FOUND and not is_manifest:, if hresp.status_int != HTTP_NOT_FOUND:,45,13
openstack%2Fproject-config~master~I48944176d5c0c1a044e12bf771bfa5a1c997580b,openstack/project-config,master,I48944176d5c0c1a044e12bf771bfa5a1c997580b,Support pre/post test hooks for nova-docker jobs,MERGED,2014-12-18 20:35:58.000000000,2014-12-18 21:56:09.000000000,2014-12-18 21:56:07.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6316}]","[{'number': 1, 'created': '2014-12-18 20:35:58.000000000', 'files': ['jenkins/jobs/nova-docker.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f17433fa3084a41b8045e4cbba77d9a756ec1872', 'message': 'Support pre/post test hooks for nova-docker jobs\n\nChange-Id: I48944176d5c0c1a044e12bf771bfa5a1c997580b\n'}]",0,142899,f17433fa3084a41b8045e4cbba77d9a756ec1872,8,3,1,5638,,,0,"Support pre/post test hooks for nova-docker jobs

Change-Id: I48944176d5c0c1a044e12bf771bfa5a1c997580b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/99/142899/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/nova-docker.yaml'],1,f17433fa3084a41b8045e4cbba77d9a756ec1872,, function pre_test_hook {{ if [ -f $BASE/new/nova-docker/contrib/devstack/pre_test_hook.sh ] ; then $BASE/new/nova-docker/contrib/devstack/pre_test_hook.sh fi }} export -f pre_test_hook function post_test_hook {{ if [ -f $BASE/new/nova-docker/contrib/devstack/post_test_hook.sh ] ; then $BASE/new/nova-docker/contrib/devstack/post_test_hook.sh fi }} export -f post_test_hook ,,16,0
openstack%2Fcinder~stable%2Ficehouse~I4db42d2521d7e6018f4f7ad0c4ab13441871675e,openstack/cinder,stable/icehouse,I4db42d2521d7e6018f4f7ad0c4ab13441871675e,NetApp 7mode NFS driver doesn't honor netapp_vfiler option,MERGED,2014-12-09 13:04:39.000000000,2014-12-18 21:55:34.000000000,2014-12-18 21:55:32.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 9366}, {'_account_id': 10621}]","[{'number': 1, 'created': '2014-12-09 13:04:39.000000000', 'files': ['cinder/test.py', 'etc/cinder/cinder.conf.sample', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/options.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2670384c59cb572c5aba3ce5eb4f5e698c277ecb', 'message': ""NetApp 7mode NFS driver doesn't honor netapp_vfiler option\n\nThis patch fixes the NetApp 7mode NFS driver to register and use\nthe netapp_vfiler option if it is configured in cinder.conf.\n\nDocImpact\nChange-Id: I4db42d2521d7e6018f4f7ad0c4ab13441871675e\nCloses-Bug: 1381716\n(inspired by commit: 504cb9f3d9954138fcb62d2fbb20b8505ca0f0ac)\n""}]",1,140324,2670384c59cb572c5aba3ce5eb4f5e698c277ecb,13,5,1,9366,,,0,"NetApp 7mode NFS driver doesn't honor netapp_vfiler option

This patch fixes the NetApp 7mode NFS driver to register and use
the netapp_vfiler option if it is configured in cinder.conf.

DocImpact
Change-Id: I4db42d2521d7e6018f4f7ad0c4ab13441871675e
Closes-Bug: 1381716
(inspired by commit: 504cb9f3d9954138fcb62d2fbb20b8505ca0f0ac)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/24/140324/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/test.py', 'etc/cinder/cinder.conf.sample', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/options.py']",5,2670384c59cb572c5aba3ce5eb4f5e698c277ecb,bug/1381716, 'family of Data ONTAP operating in 7-Mode. Only use this ', 'family of Data ONTAP operating in 7-Mode and the ' 'storage protocol selected is iSCSI. Only use this ',145,27
openstack%2Fnova-specs~master~Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246,openstack/nova-specs,master,Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246,API: Proxy neutron configuration to guest instance,MERGED,2014-04-28 20:01:23.000000000,2014-12-18 21:43:27.000000000,2014-12-18 21:43:25.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1082}, {'_account_id': 1297}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 3217}, {'_account_id': 4190}, {'_account_id': 4393}, {'_account_id': 4573}, {'_account_id': 6062}, {'_account_id': 7156}, {'_account_id': 7602}, {'_account_id': 9061}, {'_account_id': 10342}, {'_account_id': 10380}, {'_account_id': 11547}]","[{'number': 5, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8047020845b672243a96109f205f292002a9b522', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network information.\nLike user_data and vendor_data, we should also provide network_data. Really we should\nprovide all the information we can (from neutron) in both config drive and metadata service.\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ddde5e11ee67ef2cef8827a62f848012584ebe97', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network information.\nLike user_data and vendor_data, we should also provide network_data. Really we should\nprovide all the information we can (from neutron) in both config drive and metadata service.\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 7, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/80da582bb2725f907869513a60901f9f985d9d32', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network information.\nLike user_data and vendor_data, we should also provide network_data. Really we should\nprovide all the information we can (from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 6, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b14d1fc41d34a5b81bdedebe7f03194a8b9612e0', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network information.\nLike user_data and vendor_data, we should also provide network_data. Really we should\nprovide all the information we can (from neutron) in both config drive and metadata service.\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/131ded7f810a497a7c5a6918e19ad0cca11660df', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network information.\nLike user_data and vendor_data, we should also provide network_data. Really we should\nprovide all the information we can (from neutron) in both config drive and metadata service.\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d1eda4bcf2d02fdaea5cc5b3936233897199f814', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network information.\nLike user_data and vendor_data, we should also provide network_data. Really we should\nprovide all the information we can (from neutron) in both config drive and metadata service.\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c132f336ee29c54d27dc1021fc6b5cc13ab14f72', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network information.\nLike user_data and vendor_data, we should also provide network_data. Really we should\nprovide all the information we can (from neutron) in both config drive and metadata service.\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 8, 'created': '2014-05-12 10:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5213c7cb02a1cc194654ab11ed10ee412a960958', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network information.\nLike user_data and vendor_data, we should also provide network_data. Really we should\nprovide all the information we can (from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 9, 'created': '2014-06-26 18:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/82be8da5278e4e87f66262f339f4489a1dd7ce23', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network information.\nLike user_data and vendor_data, we should also provide network_data. Really we should\nprovide all the information we can (from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 10, 'created': '2014-07-07 21:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/30b37f9f8392dd8e3121f503215202ac19150dcc', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network\ninformation. Like user_data and vendor_data, we should also provide\nnetwork_data. Really we should provide all the information we can\n(from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 11, 'created': '2014-07-07 22:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f25111388d2509a6220de77c2b8b775844f0cb44', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network\ninformation. Like user_data and vendor_data, we should also provide\nnetwork_data. Really we should provide all the information we can\n(from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 12, 'created': '2014-07-08 00:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d97efa1b028d712c437323557442e34e23afac96', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network\ninformation. Like user_data and vendor_data, we should also provide\nnetwork_data. Really we should provide all the information we can\n(from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 13, 'created': '2014-07-10 01:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/12a7f713831ebdb7d247cdd82e3d561d7ac11cec', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network\ninformation. Like user_data and vendor_data, we should also provide\nnetwork_data. Really we should provide all the information we can\n(from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 14, 'created': '2014-09-04 19:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/564a3cc90df733aa686bb87c59297d9a08ae89d2', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network\ninformation. Like user_data and vendor_data, we should also provide\nnetwork_data. Really we should provide all the information we can\n(from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\n'}, {'number': 15, 'created': '2014-09-04 19:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/68ab780a2e4fa7785aaf1ad748d5660ed58be029', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network\ninformation. Like user_data and vendor_data, we should also provide\nnetwork_data. Really we should provide all the information we can\n(from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\nCo-Authored-By: Josh Gachnang <josh@servercobra.com>\n'}, {'number': 16, 'created': '2014-10-10 22:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3e0aa7247906503c1afa4752dcfe3799bc617aa8', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network\ninformation. Like user_data and vendor_data, we should also provide\nnetwork_data. Really we should provide all the information we can\n(from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\nCo-Authored-By: Josh Gachnang <josh@servercobra.com>\n'}, {'number': 17, 'created': '2014-12-09 23:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/bbf0cbc127e3dce1bb07f718b8cc15b8610eab04', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network\ninformation. Like user_data and vendor_data, we should also provide\nnetwork_data. Really we should provide all the information we can\n(from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\nCo-Authored-By: Josh Gachnang <josh@servercobra.com>\n'}, {'number': 18, 'created': '2014-12-15 18:25:25.000000000', 'files': ['specs/kilo/approved/metadata-service-network-info.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c43781f4fe40dffeef31012397363d2a29c21028', 'message': 'API: Proxy neutron configuration to guest instance\n\nCurrently the metadata service only contains minimal network\ninformation. Like user_data and vendor_data, we should also provide\nnetwork_data. Really we should provide all the information we can\n(from neutron) in both config drive and metadata service.\n\nblueprint metadata-service-network-info\n\nChange-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246\nCo-Authored-By: Josh Gachnang <josh@servercobra.com>\n'}]",84,85673,c43781f4fe40dffeef31012397363d2a29c21028,128,21,18,7602,,,0,"API: Proxy neutron configuration to guest instance

Currently the metadata service only contains minimal network
information. Like user_data and vendor_data, we should also provide
network_data. Really we should provide all the information we can
(from neutron) in both config drive and metadata service.

blueprint metadata-service-network-info

Change-Id: Ia6967af4b4147ad4dcf6ae3ae5f4b6d9c1fda246
Co-Authored-By: Josh Gachnang <josh@servercobra.com>
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/73/85673/17 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/metadata-service-network-info.rst'],1,8047020845b672243a96109f205f292002a9b522,bp/metadata-service-network-info,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================== API: Proxy neutron configuration to guest instance ================================================== https://blueprints.launchpad.net/nova/+spec/metadata-service-network-info Improve the networking info given in both config drive and the metadata service to instances. Problem description =================== Currently the metadata service only contains minimal network information. Like user_data and vendor_data, we should also provide network_data. Really we should provide all the information we can (from neutron) in both config drive and metadata service. Main use case: * cloud has no DHCP * image has no ""nova-agent"" or similar * but image is still able to setup network info * image can have custom startup scripts to get networking config from Config Drive Other usecase: Consider a VM with the first interface configured by DHCP, and all other interfaces on private networks where the interfaces are statically configured, but you are not using config drive, just the metadata service, and not cheating by doing file injection, presenting the data in a guest agnostic format. Proposed change =============== * Only in v3 API * Information comes from current network_info for instance * API should be fairly similar to the neutron get port details API * We only really need concrete info: mac address, fixed IP address, subnet, gateway, host routes, neutron port-id, neutron network-id, neutron subnet-id * It should all be grouped by mac address, so guest can link it to the VIFs correctly Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- Sample API for getting network information from metadata service GET: http://169.254.169.254/openstack/latest/metadata/network_data JSON Response:: { ""ports"":[ { ""name"":""foo"", ""network_id"":""ebda9658-093b-41ba-80ce-0cf8cb8365d4"", ""mac_address"":""fa:16:3e:b9:ef:05"", ""fixed_ips"":[ { ""subnet-id"":""91e47a57-7508-46fe-afc9-fc454e8580e1"", ""ip_address"":""172.24.4.227"", ""cidr"":""10.0.3.0/24"", ""dns_nameservers"":[""10.0.3.2""], ""enable_dhcp"":true, ""gateway_ip"":""10.0.3.1"", ""host_routes"":[ { ""destination"":""10.0.3.0/24"", ""nexthop"":""172.24.4.228"" }], ""ip_version"":4, }], ""id"":""664ebd1a-facd-4c20-948c-07a784475ab0"", }, { ""name"":"""", ""network_id"":... ... }] } Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: claxton Work Items ---------- * Get basic networking info from neutron into Metadata Service (list of: mac, IP, subnet, gateway, neutron-port-id, host-routes) * Add above information into ConfigDrive as ""network_data"" Dependencies ============ None Testing ======= Tempest tests to be added to check if network data is returned. Documentation Impact ==================== Changes to the Metadata Service api to ask and return network data. References ========== https://etherpad.openstack.org/p/IcehouseNovaMetadataService ",,163,0
openstack%2Fdevstack~master~I6d2d63746f98f0f885816395f36022a2706fb9c5,openstack/devstack,master,I6d2d63746f98f0f885816395f36022a2706fb9c5,"Revert ""Pin version of setuptools""",MERGED,2014-12-17 03:33:11.000000000,2014-12-18 21:34:40.000000000,2014-12-18 21:34:37.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7687}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 03:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1ee08e95ef25500cac225684b5e030ccacf41886', 'message': 'Revert ""Pin version of setuptools""\n\nThis reverts commit 3b782d304ec2073a6406c37b9e1a76c8aecfc9a3.\n\nThe blockers for setuptools 8 compatibility should all be resolved\nnow.\n\nChange-Id: I6d2d63746f98f0f885816395f36022a2706fb9c5\n'}, {'number': 2, 'created': '2014-12-18 16:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f2e1ddd9a096f44cf6def3cb458404ab7e58dcab', 'message': 'Revert ""Pin version of setuptools""\n\nThis reverts commit 3b782d304ec2073a6406c37b9e1a76c8aecfc9a3.\n\nThe blockers for setuptools 8 compatibility should all be resolved\nnow. Also silence runtime warnings from pkg_resources we can\'t do\nanything about.\n\nChange-Id: I6d2d63746f98f0f885816395f36022a2706fb9c5\n'}, {'number': 3, 'created': '2014-12-18 17:09:39.000000000', 'files': ['tools/install_pip.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b7ebc4765a327e97837f2f6696682859eb77a93d', 'message': 'Revert ""Pin version of setuptools""\n\nThis reverts commit 3b782d304ec2073a6406c37b9e1a76c8aecfc9a3.\n\nThe blockers for setuptools 8 compatibility should all be resolved\nnow.\n\nChange-Id: I6d2d63746f98f0f885816395f36022a2706fb9c5\n'}]",0,142322,b7ebc4765a327e97837f2f6696682859eb77a93d,16,5,3,5263,,,0,"Revert ""Pin version of setuptools""

This reverts commit 3b782d304ec2073a6406c37b9e1a76c8aecfc9a3.

The blockers for setuptools 8 compatibility should all be resolved
now.

Change-Id: I6d2d63746f98f0f885816395f36022a2706fb9c5
",git fetch https://review.opendev.org/openstack/devstack refs/changes/22/142322/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_pip.sh'],1,1ee08e95ef25500cac225684b5e030ccacf41886,setuptools-8-patch1,pip_install -U setuptools,"pip_install -U ""setuptools<8.0""",1,1
openstack%2Fnova~master~I025d22e5028832f1b41a20bb5dd607821bb2fad0,openstack/nova,master,I025d22e5028832f1b41a20bb5dd607821bb2fad0,WIP: experimenting with testresources,ABANDONED,2014-12-01 21:59:47.000000000,2014-12-18 21:32:15.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-01 21:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95fe82d906a1ee8cea9f9cb3e2d989ee4dc25cf3', 'message': 'WIP: experimenting with testresources\n\nThis is an attempt to get testresources to work with the api_samples\ncode. It currently does not.\n\nVery clearly the wsgi stack is deleted at the end of every test, which\nis what we were trying to avoid happening.\n\nPosted in the hope that this might be addressable.\n\nChange-Id: I025d22e5028832f1b41a20bb5dd607821bb2fad0\n'}, {'number': 2, 'created': '2014-12-03 16:22:39.000000000', 'files': ['test-requirements.txt', 'nova/tests/functional/integrated_helpers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e2d3e5b69d329c748c5a67ab1ed8c41478bd06a0', 'message': 'WIP: experimenting with testresources\n\nThis is an attempt to get testresources to work with the api_samples\ncode. It currently does not.\n\nVery clearly the wsgi stack is deleted at the end of every test, which\nis what we were trying to avoid happening.\n\nPosted in the hope that this might be addressable.\n\nFoo\n\nChange-Id: I025d22e5028832f1b41a20bb5dd607821bb2fad0'}]",0,138192,e2d3e5b69d329c748c5a67ab1ed8c41478bd06a0,17,9,2,2750,,,0,"WIP: experimenting with testresources

This is an attempt to get testresources to work with the api_samples
code. It currently does not.

Very clearly the wsgi stack is deleted at the end of every test, which
is what we were trying to avoid happening.

Posted in the hope that this might be addressable.

Foo

Change-Id: I025d22e5028832f1b41a20bb5dd607821bb2fad0",git fetch https://review.opendev.org/openstack/nova refs/changes/92/138192/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'nova/tests/functional/integrated_helpers.py']",2,95fe82d906a1ee8cea9f9cb3e2d989ee4dc25cf3,test_refactor,"import testresourcesclass NovaAPIResourceManager(testresources.TestResourceManager): def clean(self, resource): self.assertTrue(False, ""tried to call clean"") resource.stop() nova.tests.unit.image.fake.FakeImageService_reset() def _reset(self, resource, dependency_resources): nova.tests.unit.image.fake.FakeImageService_reset() return resource def make(self, dependency_resource): osapi = service.WSGIService(""osapi_compute"") osapi.start() return osapi def isDirty(self): return False class NovaCellsResourceManager(testresources.TestResourceManager): def make(self, foo): fix = test.ServiceFixture('cells', None, manager=CONF.cells.manager) fix.setUp() return fix.service def _reset(self, resouce, dependency_resources): pass def isDirty(self): return False resources = [ ('cells', NovaCellsResourceManager()), ('osapi', NovaAPIResourceManager())] testresources.setUpResources( self, self.resources, testresources._get_result()) self.addCleanup( testresources.tearDownResources, self, self.resources, testresources._get_result() )"," self.cells = self.start_service('cells', manager=CONF.cells.manager) def tearDown(self): self.osapi.stop() nova.tests.unit.image.fake.FakeImageService_reset() super(_IntegratedTestBase, self).tearDown() self.osapi = service.WSGIService(""osapi_compute"") self.osapi.start()",43,8
openstack%2Fdevstack-gate~master~I60e6cda1470e02fef95068697512f125ad7a9ede,openstack/devstack-gate,master,I60e6cda1470e02fef95068697512f125ad7a9ede,disable ceilometer in grenade runs,ABANDONED,2014-12-02 20:40:44.000000000,2014-12-18 21:32:06.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 6133}, {'_account_id': 6873}]","[{'number': 1, 'created': '2014-12-02 20:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/90b68dfcc88d653588c2db81631d964050ca582b', 'message': 'disable ceilometer in grenade runs\n\nCeilometer has a lock step upgrade issue with swift driven by non\noverlapping oslo.utils and pip dependency resolution issues.\n\nChange-Id: I60e6cda1470e02fef95068697512f125ad7a9ede\n'}, {'number': 2, 'created': '2014-12-16 13:57:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8b8d245760f4fa35eacf10c3e807db76f13728f2', 'message': 'disable ceilometer in grenade runs\n\nCeilometer has a lock step upgrade issue with swift driven by non\noverlapping oslo.utils and pip dependency resolution issues.\n\nChange-Id: I60e6cda1470e02fef95068697512f125ad7a9ede\n'}, {'number': 3, 'created': '2014-12-16 13:58:47.000000000', 'files': ['features.yaml', 'test-features.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/e5607f5dd5b3fdb7e37275001a50bcaabc958e10', 'message': 'disable ceilometer in grenade runs\n\nCeilometer has a lock step upgrade issue with swift driven by non\noverlapping oslo.utils and pip dependency resolution issues.\n\nRelated-Bug: #1403024\n\nChange-Id: I60e6cda1470e02fef95068697512f125ad7a9ede'}]",0,138528,e5607f5dd5b3fdb7e37275001a50bcaabc958e10,15,6,3,2750,,,0,"disable ceilometer in grenade runs

Ceilometer has a lock step upgrade issue with swift driven by non
overlapping oslo.utils and pip dependency resolution issues.

Related-Bug: #1403024

Change-Id: I60e6cda1470e02fef95068697512f125ad7a9ede",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/28/138528/3 && git format-patch -1 --stdout FETCH_HEAD,['features.yaml'],1,90b68dfcc88d653588c2db81631d964050ca582b,no_grenade_ceilometer," rm-features: [trove, sahara, ceilometer]"," rm-features: [trove, sahara]",1,1
openstack%2Fdevstack~master~I461b02cf738ab85cc0c65e1f73663243a3f9c7ef,openstack/devstack,master,I461b02cf738ab85cc0c65e1f73663243a3f9c7ef,WIP: DON'T MERGE,ABANDONED,2014-12-04 12:22:04.000000000,2014-12-18 21:31:54.000000000,,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-04 12:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/16147d600f567f510be8d8921b4637ce68db5c04', 'message': ""WIP: DON'T MERGE\n\nTesting that v21default does the right thing, and see how it works.\n\nChange-Id: I461b02cf738ab85cc0c65e1f73663243a3f9c7ef\n""}, {'number': 2, 'created': '2014-12-04 16:09:31.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d03d87d0c24347664c88e0ae3773e1482cc5c249', 'message': ""WIP: DON'T MERGE\n\nTesting that v21default does the right thing, and see how it works.\n\nChange-Id: I461b02cf738ab85cc0c65e1f73663243a3f9c7ef\n""}]",0,139036,d03d87d0c24347664c88e0ae3773e1482cc5c249,8,3,2,2750,,,0,"WIP: DON'T MERGE

Testing that v21default does the right thing, and see how it works.

Change-Id: I461b02cf738ab85cc0c65e1f73663243a3f9c7ef
",git fetch https://review.opendev.org/openstack/devstack refs/changes/36/139036/2 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,16147d600f567f510be8d8921b4637ce68db5c04,add-nova-v21-api,NOVA_API_VERSION=v21default ,,2,0
openstack%2Ftripleo-heat-templates~master~Ieac08f595086acb8dd336e33efc705ee0b8a3a87,openstack/tripleo-heat-templates,master,Ieac08f595086acb8dd336e33efc705ee0b8a3a87,Set more aggressive keepalive timings,MERGED,2014-12-17 18:10:14.000000000,2014-12-18 21:31:00.000000000,2014-12-18 21:31:00.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7582}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-12-17 18:10:14.000000000', 'files': ['overcloud-without-mergepy.yaml', 'overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2f7f4ed50c53e25041bf29d317c5f3358e46e706', 'message': 'Set more aggressive keepalive timings\n\nWe want to customize the default kernel keepalive timings and\nmake them more aggressive to workaround lack of hearbeat support\nin the Oslo RabbitMQ client, see:\n\nhttps://bugs.launchpad.net/oslo.messaging/+bug/856764/comments/19\nand\nhttps://bugs.launchpad.net/oslo.messaging/+bug/856764/comments/70\n\nChange-Id: Ieac08f595086acb8dd336e33efc705ee0b8a3a87\nCloses-Bug: 1301431\nCloses-Bug: 1385240\nCloses-Bug: 1385234\n'}]",0,142527,2f7f4ed50c53e25041bf29d317c5f3358e46e706,12,6,1,6796,,,0,"Set more aggressive keepalive timings

We want to customize the default kernel keepalive timings and
make them more aggressive to workaround lack of hearbeat support
in the Oslo RabbitMQ client, see:

https://bugs.launchpad.net/oslo.messaging/+bug/856764/comments/19
and
https://bugs.launchpad.net/oslo.messaging/+bug/856764/comments/70

Change-Id: Ieac08f595086acb8dd336e33efc705ee0b8a3a87
Closes-Bug: 1301431
Closes-Bug: 1385240
Closes-Bug: 1385234
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/27/142527/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-without-mergepy.yaml', 'overcloud-source.yaml']",2,2f7f4ed50c53e25041bf29d317c5f3358e46e706,bug/1301431, sysctl: net.ipv4.tcp_keepalive_time: 5 net.ipv4.tcp_keepalive_probes: 5 net.ipv4.tcp_keepalive_intvl: 1,,8,0
openstack%2Fglance~master~Ic1af8753a70f1aada22efe8132e48cbc16e14f3f,openstack/glance,master,Ic1af8753a70f1aada22efe8132e48cbc16e14f3f,Using oslo.concurrency lib,MERGED,2014-11-27 14:58:13.000000000,2014-12-18 21:30:00.000000000,2014-12-18 21:29:59.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 8158}, {'_account_id': 8871}, {'_account_id': 11356}, {'_account_id': 12000}, {'_account_id': 13717}]","[{'number': 1, 'created': '2014-11-27 14:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/127b0b969616b3420143144d3e288cac6e162c58', 'message': 'Using oslo.concurrency lib\n\nReplace processutils and lockutils modules of oslo-incubator with\noslo.concurrency lib.\n\nChange-Id: Ic1af8753a70f1aada22efe8132e48cbc16e14f3f\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2014-11-28 16:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/83aafa6b4e250ed5e8c88e6a5c63857df6d43243', 'message': 'Using oslo.concurrency lib\n\nReplace processutils and lockutils modules of oslo-incubator with\noslo.concurrency lib.\n\nChange-Id: Ic1af8753a70f1aada22efe8132e48cbc16e14f3f\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 3, 'created': '2014-12-11 06:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a7a02f86932afa3a1d1c6a0567f75040acce68d4', 'message': 'Using oslo.concurrency lib\n\nReplace processutils and lockutils modules of oslo-incubator with\noslo.concurrency lib.\n\nChange-Id: Ic1af8753a70f1aada22efe8132e48cbc16e14f3f\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 4, 'created': '2014-12-11 07:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c899e912a7481bae29e1eb43bbdd913c535ca993', 'message': 'Using oslo.concurrency lib\n\nReplace processutils and lockutils modules of oslo-incubator with\noslo.concurrency lib.\n\nChange-Id: Ic1af8753a70f1aada22efe8132e48cbc16e14f3f\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 5, 'created': '2014-12-11 14:06:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/95807c0237dea7ce514cf2283b21fd483250a76f', 'message': 'Using oslo.concurrency lib\n\nReplace processutils and lockutils modules of oslo-incubator with\noslo.concurrency lib.\n\nChange-Id: Ic1af8753a70f1aada22efe8132e48cbc16e14f3f\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 6, 'created': '2014-12-13 13:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8ab8a4b595a0a73f1915f9b386fef7d253a22a4c', 'message': 'Using oslo.concurrency lib\n\nReplace processutils and lockutils modules of oslo-incubator with\noslo.concurrency lib.\n\nChange-Id: Ic1af8753a70f1aada22efe8132e48cbc16e14f3f\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 7, 'created': '2014-12-17 05:22:40.000000000', 'files': ['glance/opts.py', 'glance/tests/unit/test_opts.py', 'run_tests.sh', 'requirements.txt', 'glance/common/wsgi.py', 'glance/common/config.py', 'etc/glance-api.conf', 'glance/common/scripts/image_import/main.py', 'glance/openstack/common/lockutils.py', 'glance/openstack/common/processutils.py', 'glance/tests/unit/base.py', 'etc/glance-scrubber.conf', 'openstack-common.conf', 'etc/oslo-config-generator/glance-scrubber.conf', 'tox.ini', 'etc/oslo-config-generator/glance-api.conf', 'glance/async/eventlet_executor.py', 'glance/scrubber.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/882049a613c0cbbf417835296732e35aa28fa07c', 'message': 'Using oslo.concurrency lib\n\nReplace processutils and lockutils modules of oslo-incubator with\noslo.concurrency lib.\n\nChange-Id: Ic1af8753a70f1aada22efe8132e48cbc16e14f3f\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}]",0,137657,882049a613c0cbbf417835296732e35aa28fa07c,43,10,7,6549,,,0,"Using oslo.concurrency lib

Replace processutils and lockutils modules of oslo-incubator with
oslo.concurrency lib.

Change-Id: Ic1af8753a70f1aada22efe8132e48cbc16e14f3f
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/57/137657/6 && git format-patch -1 --stdout FETCH_HEAD,"['glance/opts.py', 'requirements.txt', 'glance/common/wsgi.py', 'glance/common/scripts/image_import/main.py', 'glance/openstack/common/lockutils.py', 'glance/openstack/common/processutils.py', 'openstack-common.conf', 'etc/oslo-config-generator/glance-scrubber.conf', 'tox.ini', 'etc/oslo-config-generator/glance-api.conf', 'glance/async/eventlet_executor.py', 'glance/scrubber.py']",12,127b0b969616b3420143144d3e288cac6e162c58,,from oslo.concurrency import lockutils,from glance.openstack.common import lockutils,10,627
openstack%2Fnova~master~Idc536e408b22cadf8b12ec2bd4ed978f1110fd83,openstack/nova,master,Idc536e408b22cadf8b12ec2bd4ed978f1110fd83,libvirt: sanitize use of mocking in test_host.py,MERGED,2014-12-10 15:06:18.000000000,2014-12-18 21:28:53.000000000,2014-12-18 18:59:57.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b62e43f49735cc24152a649f4901aa521ef0ddc8', 'message': 'libvirt: sanitize use of mocking in test_host.py\n\nTidy up the test_host.py test suite, so that it uses mock\nexclusively instead of stubs. Also annotate test methods\nin preference to using nested contexts since it leads to\nclearer test methods.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Idc536e408b22cadf8b12ec2bd4ed978f1110fd83\n'}, {'number': 2, 'created': '2014-12-10 17:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37e1edacc2662e557788e6b3faf9a959ece098aa', 'message': 'libvirt: sanitize use of mocking in test_host.py\n\nTidy up the test_host.py test suite, so that it uses mock\nexclusively instead of stubs. Also annotate test methods\nin preference to using nested contexts since it leads to\nclearer test methods.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Idc536e408b22cadf8b12ec2bd4ed978f1110fd83\n'}, {'number': 3, 'created': '2014-12-16 12:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/593b15b2390564ab4b77249c07fcfe2e1278cc96', 'message': 'libvirt: sanitize use of mocking in test_host.py\n\nTidy up the test_host.py test suite, so that it uses mock\nexclusively instead of stubs. Also annotate test methods\nin preference to using nested contexts since it leads to\nclearer test methods.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Idc536e408b22cadf8b12ec2bd4ed978f1110fd83\n'}, {'number': 4, 'created': '2014-12-17 11:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/415a24648848851378d97f231b8ad2abc36e76de', 'message': 'libvirt: sanitize use of mocking in test_host.py\n\nTidy up the test_host.py test suite, so that it uses mock\nexclusively instead of stubs. Also annotate test methods\nin preference to using nested contexts since it leads to\nclearer test methods.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Idc536e408b22cadf8b12ec2bd4ed978f1110fd83\n'}, {'number': 5, 'created': '2014-12-18 14:18:25.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_host.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/feb19b33973bc8053577e17db40300758077169d', 'message': 'libvirt: sanitize use of mocking in test_host.py\n\nTidy up the test_host.py test suite, so that it uses mock\nexclusively instead of stubs. Also annotate test methods\nin preference to using nested contexts since it leads to\nclearer test methods.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Idc536e408b22cadf8b12ec2bd4ed978f1110fd83\n'}]",0,140716,feb19b33973bc8053577e17db40300758077169d,42,13,5,1779,,,0,"libvirt: sanitize use of mocking in test_host.py

Tidy up the test_host.py test suite, so that it uses mock
exclusively instead of stubs. Also annotate test methods
in preference to using nested contexts since it leads to
clearer test methods.

Blueprint: libvirt-driver-class-refactor
Change-Id: Idc536e408b22cadf8b12ec2bd4ed978f1110fd83
",git fetch https://review.opendev.org/openstack/nova refs/changes/16/140716/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/libvirt/test_host.py'],1,b62e43f49735cc24152a649f4901aa521ef0ddc8,libvirt-driver-refactor-3," @mock.patch.object(fakelibvirt.virConnect, ""registerCloseCallback"") def test_close_callback(self, mock_close): mock_close.side_effect = set_close_callback # verify that the driver registers for the close callback self.host.get_connection() self.assertTrue(self.close_callback) @mock.patch.object(fakelibvirt.virConnect, ""registerCloseCallback"") def test_close_callback_bad_signature(self, mock_close): mock_close.side_effect = TypeError('dd') connection = self.host.get_connection() self.assertTrue(connection) @mock.patch.object(fakelibvirt.virConnect, ""registerCloseCallback"") def test_close_callback_not_defined(self, mock_close): mock_close.side_effect = AttributeError('dd') connection = self.host.get_connection() self.assertTrue(connection) @mock.patch.object(fakelibvirt.virConnect, ""getLibVersion"") def test_broken_connection(self, mock_ver): mock_ver.side_effect = fakelibvirt.make_libvirtError( libvirt.libvirtError, ""Connection broken"", error_code=error, error_domain=domain) self.assertFalse(self.host._test_connection(conn)) @mock.patch.object(fakelibvirt.virConnect, ""domainEventRegisterAny"") @mock.patch.object(host.Host, ""_connect"") def test_get_connection_serial(self, mock_conn, mock_event): mock_conn.side_effect = connect_with_block mock_event.side_effect = fake_register @mock.patch.object(fakelibvirt.virConnect, ""domainEventRegisterAny"") @mock.patch.object(host.Host, ""_connect"") def test_get_connection_concurrency(self, mock_conn, mock_event): mock_conn.side_effect = connect_with_block mock_event.side_effect = fake_register @mock.patch.object(fakelibvirt.virConnect, ""getLibVersion"") def test_min_version_cap(self, mock_ver): mock_ver.return_value = utils.convert_version_to_int((1, 5, 0)) self.flags(version_cap=""2.0.0"", group=""libvirt"") self.assertTrue(self.host.has_min_version((1, 4, 0))) self.flags(version_cap=""1.3.0"", group=""libvirt"") self.assertFalse(self.host.has_min_version((1, 4, 0))) self.flags(version_cap="""", group=""libvirt"") self.assertTrue(self.host.has_min_version((1, 4, 0)))","import contextlib def test_close_callback(self): with contextlib.nested( mock.patch.object(fakelibvirt.virConnect, ""registerCloseCallback"", side_effect=set_close_callback)): # verify that the driver registers for the close callback self.host.get_connection() self.assertTrue(self.close_callback) def test_close_callback_bad_signature(self): with contextlib.nested( mock.patch.object(fakelibvirt.virConnect, ""registerCloseCallback"", side_effect=TypeError('dd'))): connection = self.host.get_connection() self.assertTrue(connection) def test_close_callback_not_defined(self): with contextlib.nested( mock.patch.object(fakelibvirt.virConnect, ""registerCloseCallback"", side_effect=AttributeError('dd'))): connection = self.host.get_connection() self.assertTrue(connection) def test_broken_connection(self): with contextlib.nested( mock.patch.object( fakelibvirt.virConnect, ""getLibVersion"", side_effect=fakelibvirt.make_libvirtError( libvirt.libvirtError, ""Connection broken"", error_code=error, error_domain=domain))): self.assertFalse(self.host._test_connection(conn)) def test_get_connection_serial(self): self.stubs.Set(self.host, ""_connect"", connect_with_block) self.stubs.Set(fakelibvirt.virConnect, 'domainEventRegisterAny', fake_register) def test_get_connection_concurrency(self): self.stubs.Set(self.host, ""_connect"", connect_with_block) self.stubs.Set(fakelibvirt.virConnect, 'domainEventRegisterAny', fake_register) def test_min_version_cap(self): with contextlib.nested( mock.patch.object(fakelibvirt.virConnect, 'getLibVersion'), ) as (mock_ver, ): mock_ver.return_value = utils.convert_version_to_int((1, 5, 0)) self.flags(version_cap=""2.0.0"", group=""libvirt"") self.assertTrue(self.host.has_min_version((1, 4, 0))) self.flags(version_cap=""1.3.0"", group=""libvirt"") self.assertFalse(self.host.has_min_version((1, 4, 0))) self.flags(version_cap="""", group=""libvirt"") self.assertTrue(self.host.has_min_version((1, 4, 0)))",43,57
openstack%2Fcinder~stable%2Fjuno~I2f81fed18342fe384e3c61184948f1e4052765d5,openstack/cinder,stable/juno,I2f81fed18342fe384e3c61184948f1e4052765d5,Fix NetApp AutoSupport Shortcomings.,MERGED,2014-12-08 16:30:42.000000000,2014-12-18 21:26:56.000000000,2014-12-18 21:26:51.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 9186}, {'_account_id': 10621}]","[{'number': 1, 'created': '2014-12-08 16:30:42.000000000', 'files': ['cinder/volume/drivers/netapp/utils.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/tests/test_netapp_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/08bf23170e94c0ad2947bee81051b5d1e57f8da5', 'message': 'Fix NetApp AutoSupport Shortcomings.\n\nThis patch addresses several problems with the current implementation.\n\n1. Appending a record to EMS should not in itself trigger ASUP\ndelivery. These should be separately scheduled and Openstack cinder\nshould have no role in ASUP scheduling or delivery, only a role in\nlogging via EMS.\n\n2. Log frequency should be adjusted from weekly to hourly.\n\n3. The log message should be useful for support. It should include\nrelease (Havana, Icehouse, Juno, etc.) version (2014.1.1), and\ndistribution information (RHEL-OSP, etc.) rather than simply noting that\nthe message came from ""Openstack.""\n\nCloses-Bug: 1367676\nChange-Id: I2f81fed18342fe384e3c61184948f1e4052765d5\n(cherry picked from commit b3be30b14ce3f31af8a5f23542246ca8d0c4da8c)\n'}]",1,140067,08bf23170e94c0ad2947bee81051b5d1e57f8da5,10,5,1,9003,,,0,"Fix NetApp AutoSupport Shortcomings.

This patch addresses several problems with the current implementation.

1. Appending a record to EMS should not in itself trigger ASUP
delivery. These should be separately scheduled and Openstack cinder
should have no role in ASUP scheduling or delivery, only a role in
logging via EMS.

2. Log frequency should be adjusted from weekly to hourly.

3. The log message should be useful for support. It should include
release (Havana, Icehouse, Juno, etc.) version (2014.1.1), and
distribution information (RHEL-OSP, etc.) rather than simply noting that
the message came from ""Openstack.""

Closes-Bug: 1367676
Change-Id: I2f81fed18342fe384e3c61184948f1e4052765d5
(cherry picked from commit b3be30b14ce3f31af8a5f23542246ca8d0c4da8c)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/67/140067/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/netapp/utils.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/tests/test_netapp_utils.py']",5,08bf23170e94c0ad2947bee81051b5d1e57f8da5,bug/1367676,"# Copyright 2014 Tom Barron. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import platform import mock from cinder.openstack.common import processutils as putils from cinder import test from cinder import version from cinder.volume.drivers.netapp import utils as na_utils class OpenstackInfoTestCase(test.TestCase): UNKNOWN_VERSION = 'unknown version' UNKNOWN_RELEASE = 'unknown release' UNKNOWN_VENDOR = 'unknown vendor' UNKNOWN_PLATFORM = 'unknown platform' VERSION_STRING_RET_VAL = 'fake_version_1' RELEASE_STRING_RET_VAL = 'fake_release_1' PLATFORM_RET_VAL = 'fake_platform_1' VERSION_INFO_VERSION = 'fake_version_2' VERSION_INFO_RELEASE = 'fake_release_2' RPM_INFO_VERSION = 'fake_version_3' RPM_INFO_RELEASE = 'fake_release_3' RPM_INFO_VENDOR = 'fake vendor 3' PUTILS_RPM_RET_VAL = ('fake_version_3 fake_release_3 fake vendor 3', '') NO_PKG_FOUND = ('', 'whatever') PUTILS_DPKG_RET_VAL = ('epoch:upstream_version-debian_revision', '') DEB_RLS = 'upstream_version-debian_revision' DEB_VENDOR = 'debian_revision' def setUp(self): super(OpenstackInfoTestCase, self).setUp() def test_openstack_info_init(self): info = na_utils.OpenStackInfo() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(version.version_info, 'version_string', mock.Mock(return_value=VERSION_STRING_RET_VAL)) def test_update_version_from_version_string(self): info = na_utils.OpenStackInfo() info._update_version_from_version_string() self.assertEqual(self.VERSION_STRING_RET_VAL, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(version.version_info, 'version_string', mock.Mock(side_effect=Exception)) def test_xcption_in_update_version_from_version_string(self): info = na_utils.OpenStackInfo() info._update_version_from_version_string() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(version.version_info, 'release_string', mock.Mock(return_value=RELEASE_STRING_RET_VAL)) def test_update_release_from_release_string(self): info = na_utils.OpenStackInfo() info._update_release_from_release_string() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.RELEASE_STRING_RET_VAL, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(version.version_info, 'release_string', mock.Mock(side_effect=Exception)) def test_xcption_in_update_release_from_release_string(self): info = na_utils.OpenStackInfo() info._update_release_from_release_string() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(platform, 'platform', mock.Mock(return_value=PLATFORM_RET_VAL)) def test_update_platform(self): info = na_utils.OpenStackInfo() info._update_platform() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.PLATFORM_RET_VAL, info._platform) @mock.patch.object(platform, 'platform', mock.Mock(side_effect=Exception)) def test_xcption_in_update_platform(self): info = na_utils.OpenStackInfo() info._update_platform() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_version', mock.Mock(return_value=VERSION_INFO_VERSION)) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_release', mock.Mock(return_value=VERSION_INFO_RELEASE)) def test_update_info_from_version_info(self): info = na_utils.OpenStackInfo() info._update_info_from_version_info() self.assertEqual(self.VERSION_INFO_VERSION, info._version) self.assertEqual(self.VERSION_INFO_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_version', mock.Mock(return_value='')) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_release', mock.Mock(return_value=None)) def test_no_info_from_version_info(self): info = na_utils.OpenStackInfo() info._update_info_from_version_info() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_version', mock.Mock(return_value=VERSION_INFO_VERSION)) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_release', mock.Mock(side_effect=Exception)) def test_xcption_in_info_from_version_info(self): info = na_utils.OpenStackInfo() info._update_info_from_version_info() self.assertEqual(self.VERSION_INFO_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(putils, 'execute', mock.Mock(return_value=PUTILS_RPM_RET_VAL)) def test_update_info_from_rpm(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_rpm() self.assertEqual(self.RPM_INFO_VERSION, info._version) self.assertEqual(self.RPM_INFO_RELEASE, info._release) self.assertEqual(self.RPM_INFO_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertTrue(found_package) @mock.patch.object(putils, 'execute', mock.Mock(return_value=NO_PKG_FOUND)) def test_update_info_from_rpm_no_pkg_found(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_rpm() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertFalse(found_package) @mock.patch.object(putils, 'execute', mock.Mock(side_effect=Exception)) def test_xcption_in_update_info_from_rpm(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_rpm() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertFalse(found_package) @mock.patch.object(putils, 'execute', mock.Mock(return_value=PUTILS_DPKG_RET_VAL)) def test_update_info_from_dpkg(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_dpkg() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.DEB_RLS, info._release) self.assertEqual(self.DEB_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertTrue(found_package) @mock.patch.object(putils, 'execute', mock.Mock(return_value=NO_PKG_FOUND)) def test_update_info_from_dpkg_no_pkg_found(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_dpkg() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertFalse(found_package) @mock.patch.object(putils, 'execute', mock.Mock(side_effect=Exception)) def test_xcption_in_update_info_from_dpkg(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_dpkg() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertFalse(found_package) @mock.patch.object(na_utils.OpenStackInfo, '_update_version_from_version_string', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_release_from_release_string', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_platform', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_version_info', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_rpm', mock.Mock(return_value=True)) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_dpkg') def test_update_openstack_info_rpm_pkg_found(self, mock_updt_from_dpkg): info = na_utils.OpenStackInfo() info._update_openstack_info() self.assertFalse(mock_updt_from_dpkg.called) @mock.patch.object(na_utils.OpenStackInfo, '_update_version_from_version_string', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_release_from_release_string', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_platform', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_version_info', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_rpm', mock.Mock(return_value=False)) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_dpkg') def test_update_openstack_info_rpm_pkg_not_found(self, mock_updt_from_dpkg): info = na_utils.OpenStackInfo() info._update_openstack_info() self.assertTrue(mock_updt_from_dpkg.called) ",,424,18
openstack%2Ftaskflow~master~I9bbf5d9082e4e6ee9283c7e11ed0b2474a4e070a,openstack/taskflow,master,I9bbf5d9082e4e6ee9283c7e11ed0b2474a4e070a,Updated from global requirements,MERGED,2014-12-18 01:28:42.000000000,2014-12-18 21:24:59.000000000,2014-12-18 21:24:59.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-18 01:28:42.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e5ae74d6bf2afe6fc005e5a45cc8ebcb1703132e', 'message': 'Updated from global requirements\n\nChange-Id: I9bbf5d9082e4e6ee9283c7e11ed0b2474a4e070a\n'}]",0,142640,e5ae74d6bf2afe6fc005e5a45cc8ebcb1703132e,8,2,1,11131,,,0,"Updated from global requirements

Change-Id: I9bbf5d9082e4e6ee9283c7e11ed0b2474a4e070a
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/40/142640/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,e5ae74d6bf2afe6fc005e5a45cc8ebcb1703132e,openstack/requirements,alembic>=0.7.1,alembic>=0.6.4,1,1
openstack%2Ftaskflow~master~Ieeae83b984b7797320997c0c4cb4289eb1a837ee,openstack/taskflow,master,Ieeae83b984b7797320997c0c4cb4289eb1a837ee,Use explict 'attr_dict' when adding provider->consumer edge,MERGED,2014-12-06 19:37:07.000000000,2014-12-18 21:24:57.000000000,2014-12-18 21:24:54.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-06 19:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ba71c2623ba886c0060edabfe7e10ba14b5767d5', 'message': ""Use explict 'attr_dict' when adding provider->consumer edge\n\nInstead using the less explicit **kwarg support when adding\nan edge use the attr_dict keyword argument instead and use\nthe constant defined the the flow module as the correct key\ninto that dictionary (therefore this will be adjusted if that\nkey ever changes).\n\nChange-Id: Ieeae83b984b7797320997c0c4cb4289eb1a837ee\n""}, {'number': 2, 'created': '2014-12-06 19:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a68c92828191e8801f30f84d312c8ff8166c50d6', 'message': ""Use explict 'attr_dict' when adding provider->consumer edge\n\nInstead of using the less explicit **kwarg support when adding\nan edge between a explicit producer and consumer use the 'attr_dict'\nkeyword argument instead and use the constant defined the the flow\nmodule as the key into that dictionary (this also ensure that the\nkey will be adjusted automatically if that key value ever changes).\n\nChange-Id: Ieeae83b984b7797320997c0c4cb4289eb1a837ee\n""}, {'number': 3, 'created': '2014-12-06 20:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ca4efb271f1c7a1771cdcf23d0fb6dc24a30a172', 'message': ""Use explict 'attr_dict' when adding provider->consumer edge\n\nInstead of using the less explicit **kwarg support when adding\nan edge between a explicit producer and consumer use the 'attr_dict'\nkeyword argument instead and use the constant defined the the flow\nmodule as the key into that dictionary (this also ensure that the\nkey will be adjusted automatically if that key value ever changes).\n\nChange-Id: Ieeae83b984b7797320997c0c4cb4289eb1a837ee\n""}, {'number': 4, 'created': '2014-12-06 20:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/90e70e6b2b215d8d410a2bfc5d5536f61c861c54', 'message': ""Use explict 'attr_dict' when adding provider->consumer edge\n\nInstead of using the less explicit **kwarg support when adding\nan edge between a explicit producer and consumer use the 'attr_dict'\nkeyword argument instead and use the constant defined the the flow\nmodule as the key into that dictionary (this also ensure that the\nkey will be adjusted automatically if that key value ever changes).\n\nChange-Id: Ieeae83b984b7797320997c0c4cb4289eb1a837ee\n""}, {'number': 5, 'created': '2014-12-06 21:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ec0da65541941d66f6fb9d2309b7f9cb842cc072', 'message': ""Use explict 'attr_dict' when adding provider->consumer edge\n\nInstead of using the less explicit **kwarg support when adding\nan edge between a explicit producer and consumer use the 'attr_dict'\nkeyword argument instead and use the constant defined the the flow\nmodule as the key into that dictionary (this also ensure that the\nkey will be adjusted automatically if that key value ever changes).\n\nChange-Id: Ieeae83b984b7797320997c0c4cb4289eb1a837ee\n""}, {'number': 6, 'created': '2014-12-07 03:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8efc47f41b6965ee3e60b2943310aeb1dc421c36', 'message': ""Use explict 'attr_dict' when adding provider->consumer edge\n\nInstead of using the less explicit **kwarg support when adding\nan edge between a explicit producer and consumer use the 'attr_dict'\nkeyword argument instead and use the constant defined the the flow\nmodule as the key into that dictionary (this also ensure that the\nkey will be adjusted automatically if that key value ever changes).\n\nChange-Id: Ieeae83b984b7797320997c0c4cb4289eb1a837ee\n""}, {'number': 7, 'created': '2014-12-07 03:18:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/18410a61061a372754349a6f1f3241f9767b89e5', 'message': ""Use explict 'attr_dict' when adding provider->consumer edge\n\nInstead of using the less explicit **kwarg support when adding\nan edge between a explicit producer and consumer use the 'attr_dict'\nkeyword argument instead and use the constant defined the the flow\nmodule as the key into that dictionary (this also ensure that the\nkey will be adjusted automatically if that key value ever changes).\n\nChange-Id: Ieeae83b984b7797320997c0c4cb4289eb1a837ee\n""}, {'number': 8, 'created': '2014-12-11 04:10:16.000000000', 'files': ['taskflow/engines/action_engine/compiler.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fda6fde26270c58a0d893d74086122ee45bda95a', 'message': ""Use explict 'attr_dict' when adding provider->consumer edge\n\nInstead of using the less explicit **kwarg support when adding\nan edge between a explicit producer and consumer use the 'attr_dict'\nkeyword argument instead and use the constant defined the the flow\nmodule as the key into that dictionary (this also ensure that the\nkey will be adjusted automatically if that key value ever changes).\n\nChange-Id: Ieeae83b984b7797320997c0c4cb4289eb1a837ee\n""}]",0,139825,fda6fde26270c58a0d893d74086122ee45bda95a,19,3,8,1297,,,0,"Use explict 'attr_dict' when adding provider->consumer edge

Instead of using the less explicit **kwarg support when adding
an edge between a explicit producer and consumer use the 'attr_dict'
keyword argument instead and use the constant defined the the flow
module as the key into that dictionary (this also ensure that the
key will be adjusted automatically if that key value ever changes).

Change-Id: Ieeae83b984b7797320997c0c4cb4289eb1a837ee
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/25/139825/8 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/action_engine/compiler.py'],1,ba71c2623ba886c0060edabfe7e10ba14b5767d5,explict-attrs," graph.add_edge(provider, consumer, attr_dict={ flow.LINK_REASONS: reasons, })"," graph.add_edge(provider, consumer, reasons=reasons)",4,1
openstack%2Ftaskflow~master~I93f86552f5a0c26b269319e4de6d9b8fb3b3b219,openstack/taskflow,master,I93f86552f5a0c26b269319e4de6d9b8fb3b3b219,"Add a history retry object, makes retry histories easier to use",MERGED,2014-09-24 01:18:44.000000000,2014-12-18 21:24:43.000000000,2014-12-18 21:24:41.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-09-24 01:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d59d936d3dc11db850e6929f22d6df3a2dc06989', 'message': 'Add a history retry object, makes retry histories easier to us\n\nWhen a retry is asked to make a decision about the nested flow/tasks\nit controls it is currently provided a complex object that contains\nwhat has failed and why and what was provided to try to resolve this\nfailure as raw types. To make it easier to interact with that history\nprovide and use a more easier to interact with helper object that\nprovides useful functionality built ontop of the raw types.\n\nPart of blueprint intuitive-retries\n\nChange-Id: I93f86552f5a0c26b269319e4de6d9b8fb3b3b219\n'}, {'number': 2, 'created': '2014-09-24 01:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8ae534acb3a6b003712b2144bb2ede8552c374b0', 'message': 'Add a history retry object, makes retry histories easier to use\n\nWhen a retry object is asked to make a decision about the atoms\nit controls it is currently provided a complex object that contains\nwhat has failed and why and what was provided to try to resolve this\nfailure as raw types. To make it easier to interact with that history\nprovide and use a more easier to interact with helper object that\nprovides useful functionality built ontop of the raw types.\n\nPart of blueprint intuitive-retries\n\nChange-Id: I93f86552f5a0c26b269319e4de6d9b8fb3b3b219\n'}, {'number': 3, 'created': '2014-09-24 05:13:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/259d9af2748d4b5b9c26284ff7e12e896c31d8f9', 'message': 'Add a history retry object, makes retry histories easier to use\n\nWhen a retry object is asked to make a decision about the atoms\nit controls it is currently provided a complex object that contains\nwhat has failed and why and what was provided to try to resolve this\nfailure as raw types. To make it easier to interact with that history\nprovide and use a more easier to interact with helper object that\nprovides useful functionality built ontop of the raw types.\n\nPart of blueprint intuitive-retries\n\nChange-Id: I93f86552f5a0c26b269319e4de6d9b8fb3b3b219\n'}, {'number': 4, 'created': '2014-09-24 06:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1aabafc4698b6aa08bd15e38ad87f298b00c2443', 'message': 'Add a history retry object, makes retry histories easier to use\n\nWhen a retry object is asked to make a decision about the atoms\nit controls it is currently provided a complex object that contains\nwhat has failed and why and what was provided to try to resolve this\nfailure as raw types. To make it easier to interact with that history\nprovide and use a more easier to interact with helper object that\nprovides useful functionality built ontop of the raw types.\n\nPart of blueprint intuitive-retries\n\nChange-Id: I93f86552f5a0c26b269319e4de6d9b8fb3b3b219\n'}, {'number': 5, 'created': '2014-09-25 02:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/bf16dca0a14efb9c4ed4758e0b5e83385bc9ac66', 'message': 'Add a history retry object, makes retry histories easier to use\n\nWhen a retry object is asked to make a decision about the atoms\nit controls it is currently provided a complex object that contains\nwhat has failed and why and what was provided to try to resolve this\nfailure as raw types. To make it easier to interact with that history\nprovide and use a more easier to interact with helper object that\nprovides useful functionality built ontop of the raw types.\n\nPart of blueprint intuitive-retries\n\nChange-Id: I93f86552f5a0c26b269319e4de6d9b8fb3b3b219\n'}, {'number': 6, 'created': '2014-09-25 18:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/671af57f3441ab2c71db4f9dc5a1928a5f43aa9f', 'message': 'Add a history retry object, makes retry histories easier to use\n\nWhen a retry object is asked to make a decision about the atoms\nit controls it is currently provided a complex object that contains\nwhat has failed and why and what was provided to try to resolve this\nfailure as raw types. To make it easier to interact with that history\nprovide and use a more easier to interact with helper object that\nprovides useful functionality built ontop of the raw types.\n\nPart of blueprint intuitive-retries\n\nChange-Id: I93f86552f5a0c26b269319e4de6d9b8fb3b3b219\n'}, {'number': 7, 'created': '2014-10-23 23:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/37fadc0ac3a4211ee6e0335bdcede26210e15529', 'message': 'Add a history retry object, makes retry histories easier to use\n\nWhen a retry object is asked to make a decision about the atoms\nit controls it is currently provided a complex object that contains\nwhat has failed and why and what was provided to try to resolve this\nfailure as raw types. To make it easier to interact with that history\nprovide and use a more easier to interact with helper object that\nprovides useful functionality built ontop of the raw types.\n\nPart of blueprint intuitive-retries\n\nChange-Id: I93f86552f5a0c26b269319e4de6d9b8fb3b3b219\n'}, {'number': 8, 'created': '2014-10-24 23:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/de03e0ff21ea16442432495e1e524280c699636e', 'message': 'Add a history retry object, makes retry histories easier to use\n\nWhen a retry object is asked to make a decision about the atoms\nit controls it is currently provided a complex object that contains\nwhat has failed and why and what was provided to try to resolve this\nfailure as raw types. To make it easier to interact with that history\nprovide and use a more easier to interact with helper object that\nprovides useful functionality built ontop of the raw types.\n\nPart of blueprint intuitive-retries\n\nChange-Id: I93f86552f5a0c26b269319e4de6d9b8fb3b3b219\n'}, {'number': 9, 'created': '2014-11-19 21:13:07.000000000', 'files': ['taskflow/storage.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/retry.py', 'taskflow/tests/unit/test_retries.py', 'doc/source/arguments_and_results.rst'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2a7ca479676e1293fefb707788e17b37b17770f4', 'message': 'Add a history retry object, makes retry histories easier to use\n\nWhen a retry object is asked to make a decision about the atoms\nit controls it is currently provided a complex object that contains\nwhat has failed and why and what was provided to try to resolve this\nfailure as raw types. To make it easier to interact with that history\nprovide and use a more easier to interact with helper object that\nprovides useful functionality built ontop of the raw types.\n\nPart of blueprint intuitive-retries\n\nChange-Id: I93f86552f5a0c26b269319e4de6d9b8fb3b3b219\n'}]",0,123616,2a7ca479676e1293fefb707788e17b37b17770f4,26,5,9,1297,,,0,"Add a history retry object, makes retry histories easier to use

When a retry object is asked to make a decision about the atoms
it controls it is currently provided a complex object that contains
what has failed and why and what was provided to try to resolve this
failure as raw types. To make it easier to interact with that history
provide and use a more easier to interact with helper object that
provides useful functionality built ontop of the raw types.

Part of blueprint intuitive-retries

Change-Id: I93f86552f5a0c26b269319e4de6d9b8fb3b3b219
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/16/123616/8 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/storage.py', 'taskflow/tests/unit/test_storage.py', 'taskflow/retry.py', 'taskflow/tests/unit/test_retries.py']",4,d59d936d3dc11db850e6929f22d6df3a2dc06989,bp/intuitive-retries," r = FailingRetry('broken') self.assertEqual([], list(r.history.outcomes_iter())) self.assertEqual(1, len(list(r.history.failures_iter()))) self.assertEqual(r.name, r.history.owner) self.assertTrue(r.history.caused_by(ValueError, include_owner=True))"," r = FailingRetry() self.assertEqual(r.history[0][1], {}) self.assertEqual(isinstance(r.history[0][0], misc.Failure), True)",95,15
openstack%2Ftaskflow~master~If2226d3e9f921a1c5f62a6727016fe86cd50a9b5,openstack/taskflow,master,If2226d3e9f921a1c5f62a6727016fe86cd50a9b5,Remove default setting of 'mysql_traditional_mode',MERGED,2014-11-25 01:09:19.000000000,2014-12-18 21:20:20.000000000,2014-12-18 21:20:18.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-11-25 01:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c1bc69a8b4300bdeaf2764a739ccfa89bfb9b20e', 'message': ""Remove default setting of 'mysql_traditional_mode'\n\nThe sqlalchemy versions we are using/supporting (0.6+)\nhave the detection of the mysql mode built-in so only\nactivate the connect setting if we are somehow overriden\nby a user who knows what they are doing.\n\nChange-Id: If2226d3e9f921a1c5f62a6727016fe86cd50a9b5\n""}, {'number': 2, 'created': '2014-11-25 17:57:29.000000000', 'files': ['taskflow/persistence/backends/impl_sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cf85dd0f61dcf402c42b3649b9ed449142a1ac56', 'message': ""Remove default setting of 'mysql_traditional_mode'\n\nThe sqlalchemy versions we are using/supporting (0.6+)\nhave the detection of the mysql mode built-in so only\nactivate the connect setting if we are somehow overriden\nby a user who knows what they are doing.\n\nFixes bug 1396278\n\nChange-Id: If2226d3e9f921a1c5f62a6727016fe86cd50a9b5\n""}]",0,136938,cf85dd0f61dcf402c42b3649b9ed449142a1ac56,12,5,2,1297,,,0,"Remove default setting of 'mysql_traditional_mode'

The sqlalchemy versions we are using/supporting (0.6+)
have the detection of the mysql mode built-in so only
activate the connect setting if we are somehow overriden
by a user who knows what they are doing.

Fixes bug 1396278

Change-Id: If2226d3e9f921a1c5f62a6727016fe86cd50a9b5
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/38/136938/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/persistence/backends/impl_sqlalchemy.py'],1,c1bc69a8b4300bdeaf2764a739ccfa89bfb9b20e,bug/1396278,," if _as_bool(conf.pop('mysql_traditional_mode', True)): mode = 'TRADITIONAL'",0,2
openstack%2Ftaskflow~master~Ib930c54bcdf15876093cbe5b6527a195b9594f40,openstack/taskflow,master,Ib930c54bcdf15876093cbe5b6527a195b9594f40,Cleanup some doc warnings/bad/broken links,MERGED,2014-12-14 07:10:31.000000000,2014-12-18 21:18:18.000000000,2014-12-18 21:18:17.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 11356}, {'_account_id': 12892}, {'_account_id': 14320}]","[{'number': 1, 'created': '2014-12-14 07:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e351949845c8e0784fd15a66b112748ae151ead8', 'message': ""Cleanup some doc warnings/bad links\n\nThe greenthread pool executor wasn't refering to the right\nlocation anymore, and this addresses some sphinx warnings\nabout how we need to be *args and **kwargs in quotes to\nensure it doesn't believe these are bold or italic styles.\n\nChange-Id: Ib930c54bcdf15876093cbe5b6527a195b9594f40\n""}, {'number': 2, 'created': '2014-12-14 20:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e8b5d76b60458261f312089aef4b66e5b3164425', 'message': 'Cleanup some doc warnings/bad links\n\nThis fixes some of the old links to classes that\nhave been moved, fixes some of the sphinx warnings\nthat were being output and cleans up the reference\nto deprecated properties.\n\nChange-Id: Ib930c54bcdf15876093cbe5b6527a195b9594f40\n'}, {'number': 3, 'created': '2014-12-15 03:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1581c370cb02b2e9403eaaa622ee70a2d14d6fc9', 'message': 'Cleanup some doc warnings/bad links\n\nThis fixes some of the old links to classes that\nhave been moved, fixes some of the sphinx warnings\nthat were being output and cleans up the reference\nto deprecated properties.\n\nChange-Id: Ib930c54bcdf15876093cbe5b6527a195b9594f40\n'}, {'number': 4, 'created': '2014-12-15 03:38:52.000000000', 'files': ['doc/source/engines.rst', 'doc/source/notifications.rst', 'taskflow/utils/reflection.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/aa8d55d948d3e0c47898446fef88654299ad014e', 'message': 'Cleanup some doc warnings/bad/broken links\n\nThis fixes some of the old links to classes that\nhave been moved, or split, fixes some of the sphinx\nwarnings that were being output and cleans up the\nreference to deprecated properties.\n\nChange-Id: Ib930c54bcdf15876093cbe5b6527a195b9594f40\n'}]",0,141626,aa8d55d948d3e0c47898446fef88654299ad014e,16,6,4,1297,,,0,"Cleanup some doc warnings/bad/broken links

This fixes some of the old links to classes that
have been moved, or split, fixes some of the sphinx
warnings that were being output and cleans up the
reference to deprecated properties.

Change-Id: Ib930c54bcdf15876093cbe5b6527a195b9594f40
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/26/141626/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/engines.rst', 'taskflow/utils/reflection.py']",2,e351949845c8e0784fd15a66b112748ae151ead8,better-docs, Special arguments (like ``*args`` and ``**kwargs``) are not included into, Special arguments (like *args and **kwargs) are not included into,2,2
openstack%2Ftaskflow~master~Ie8a4ab02b7b2c254eb63a0b43763c9893f7fa083,openstack/taskflow,master,Ie8a4ab02b7b2c254eb63a0b43763c9893f7fa083,Have the sphinx copyright date be dynamic,MERGED,2014-12-09 00:51:43.000000000,2014-12-18 21:18:14.000000000,2014-12-18 21:18:13.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-12-09 00:51:43.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a11336877fc4f8b99f02f73e3a67841340c8b23c', 'message': ""Have the sphinx copyright date be dynamic\n\nInstead of having the copyright date be statically\nencoded to '2013-2014' have it be dynamically picked\nup from the datetime module instead.\n\nChange-Id: Ie8a4ab02b7b2c254eb63a0b43763c9893f7fa083\n""}]",0,140190,a11336877fc4f8b99f02f73e3a67841340c8b23c,10,5,1,1297,,,0,"Have the sphinx copyright date be dynamic

Instead of having the copyright date be statically
encoded to '2013-2014' have it be dynamically picked
up from the datetime module instead.

Change-Id: Ie8a4ab02b7b2c254eb63a0b43763c9893f7fa083
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/90/140190/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,a11336877fc4f8b99f02f73e3a67841340c8b23c,,"import datetimecopyright = u'%s, OpenStack Foundation' % datetime.date.today().year","copyright = u'2013-2014, OpenStack Foundation'",2,1
openstack%2Ftaskflow~master~Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca,openstack/taskflow,master,Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca,Base task executor should provide 'wait_for_any',MERGED,2014-11-04 10:56:38.000000000,2014-12-18 21:17:46.000000000,2014-12-18 21:17:45.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-11-04 10:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/83163af994e1897ce835f07143217973c557a32d', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 2, 'created': '2014-11-04 10:58:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/69bca6b0a330d826b0518d93967819a591020ec7', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 3, 'created': '2014-11-04 16:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b402e674d049ca6a3f37e491613625b2d786fee5', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 4, 'created': '2014-11-15 03:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5ead6e050c949515d6e2f1a27972bb143f6a6e2a', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 5, 'created': '2014-11-15 03:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e4630559262c012c8c8d96284c4ccf37c0d8272f', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 6, 'created': '2014-11-15 12:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6fa26774bda99db4730463bbe7d2c5044b1698ff', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 7, 'created': '2014-11-17 21:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b035748b8bdb9e457bc7dfc304635951536b2057', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 8, 'created': '2014-11-19 19:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9f15758b44c6dc01b10008f676fbfda63cc81db4', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 9, 'created': '2014-12-06 23:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c893263222289d664029a81c5a092b3b188e5d53', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 10, 'created': '2014-12-13 07:45:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8b739206dec37632aea8c300b53c965c5527c889', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 11, 'created': '2014-12-14 04:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/52f5ff2e431fb5638187c56cc935851b3f1454b5', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 12, 'created': '2014-12-14 04:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f32dce5b762626bb3d8993623c07f25acec68523', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}, {'number': 13, 'created': '2014-12-15 23:53:14.000000000', 'files': ['taskflow/engines/worker_based/executor.py', 'taskflow/tests/unit/worker_based/test_executor.py', 'taskflow/engines/action_engine/executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/97b4e18cc2b4e6c0ae7228ff70ef75dc4a5a1df7', 'message': ""Base task executor should provide 'wait_for_any'\n\nInstead of having each task executor reproduce the same\ncode for 'wait_for_any' we can just have the base task\nimplementation provide the function that everyone is\nreplicating instead; making common code common and save\nthe headache caused by the same code being in multiple\nplaces (which is bad for multiple reasons).\n\nChange-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca\n""}]",0,132651,97b4e18cc2b4e6c0ae7228ff70ef75dc4a5a1df7,43,4,13,1297,,,0,"Base task executor should provide 'wait_for_any'

Instead of having each task executor reproduce the same
code for 'wait_for_any' we can just have the base task
implementation provide the function that everyone is
replicating instead; making common code common and save
the headache caused by the same code being in multiple
places (which is bad for multiple reasons).

Change-Id: Icea4b7e3df605ab11b17c248d05acb3f9c02a1ca
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/51/132651/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/executor.py', 'taskflow/tests/unit/worker_based/test_executor.py', 'taskflow/engines/action_engine/executor.py']",3,83163af994e1897ce835f07143217973c557a32d,," return async_utils.wait_for_any(fs, timeout)"," @abc.abstractmethod def wait_for_any(self, fs, timeout=None): return async_utils.wait_for_any(fs, timeout) def wait_for_any(self, fs, timeout=None): return async_utils.wait_for_any(fs, timeout) ",2,13
openstack%2Fproject-config~master~Iba034445006a3016be496614b217ebaec98b243b,openstack/project-config,master,Iba034445006a3016be496614b217ebaec98b243b,Make gate-sqlalchemy-migrate-python33 non-voting,MERGED,2014-12-18 17:27:58.000000000,2014-12-18 20:56:47.000000000,2014-12-18 20:56:45.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6873}, {'_account_id': 11816}]","[{'number': 1, 'created': '2014-12-18 17:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/66822b70423b0994c5c2e119dab071f2e567f52a', 'message': 'Revert ""sqlalchemy-migrate: enable the py33 gate.""\n\nThis reverts commit 7ac466af2dc5ae69d62a46bd7e71b0a813761b01.\n\nApparently when this was turned on the py33 job wasn\'t running on sqlalchemy-migrate but it is now and it doesn\'t work, there are script tests that don\'t work, so revert this change to stop running broken unit tests in a voting py33 job for sqla-migrate.\n\nChange-Id: Iba034445006a3016be496614b217ebaec98b243b\nCloses-Bug: #1403965\n'}, {'number': 2, 'created': '2014-12-18 17:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/eda547ee4822ddb90ead6da31ae11c8113c17772', 'message': 'Revert ""sqlalchemy-migrate: enable the py33 gate.""\n\nThis reverts commit 7ac466af2dc5ae69d62a46bd7e71b0a813761b01.\n\nApparently when this was turned on the py33 job wasn\'t running on\nsqlalchemy-migrate but it is now and it doesn\'t work, there are script\ntests that don\'t work, so revert this change to stop running broken\nunit tests in a voting py33 job for sqla-migrate.\n\nCloses-Bug: #1403965\n\nChange-Id: Iba034445006a3016be496614b217ebaec98b243b\n'}, {'number': 3, 'created': '2014-12-18 17:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e5b3d2f9e3e6bd791375b6d45fced4fe4ce4c389', 'message': 'Revert ""sqlalchemy-migrate: enable the py33 gate.""\n\nThis reverts commit 7ac466af2dc5ae69d62a46bd7e71b0a813761b01.\n\nApparently when this was turned on the py33 job wasn\'t running on\nsqlalchemy-migrate but it is now and it doesn\'t work, there are script\ntests that don\'t work, so revert this change to stop running broken\nunit tests in a voting py33 job for sqla-migrate.\n\nCloses-Bug: #1403965\n\nChange-Id: Iba034445006a3016be496614b217ebaec98b243b\n'}, {'number': 4, 'created': '2014-12-18 18:30:44.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/6933bc5558eba14e32a64dfa000ede47f03fed95', 'message': ""Make gate-sqlalchemy-migrate-python33 non-voting\n\nApparently when the py33 job was enabled for migrate\nin commit 7ac466af2dc5ae69d62a46bd7e71b0a813761b01 the\njob wasn't running yet, but it doesn't work, there are\nscript tests that fail with python 3.3 so let's make\nit non-voting since it's blocking other changes from\ngetting in and the project doesn't claim support for\npython 3.3.\n\nCloses-Bug: #1403965\n\nChange-Id: Iba034445006a3016be496614b217ebaec98b243b\n""}]",0,142850,6933bc5558eba14e32a64dfa000ede47f03fed95,16,5,4,6873,,,0,"Make gate-sqlalchemy-migrate-python33 non-voting

Apparently when the py33 job was enabled for migrate
in commit 7ac466af2dc5ae69d62a46bd7e71b0a813761b01 the
job wasn't running yet, but it doesn't work, there are
script tests that fail with python 3.3 so let's make
it non-voting since it's blocking other changes from
getting in and the project doesn't claim support for
python 3.3.

Closes-Bug: #1403965

Change-Id: Iba034445006a3016be496614b217ebaec98b243b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/50/142850/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,66822b70423b0994c5c2e119dab071f2e567f52a,bug/1403965,, - name: python3-jobs,0,1
openstack%2Frequirements~stable%2Ficehouse~I85a7ae0d1f2dff9dc44e9608029f4a610be6f482,openstack/requirements,stable/icehouse,I85a7ae0d1f2dff9dc44e9608029f4a610be6f482,"Revert ""Exclude testtools 1.4.0""",ABANDONED,2014-11-20 03:48:02.000000000,2014-12-18 20:54:46.000000000,,"[{'_account_id': 3}, {'_account_id': 979}]","[{'number': 1, 'created': '2014-11-20 03:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/206c28e6a085f6262bf3601252a55d4794187c59', 'message': 'Revert ""Exclude testtools 1.4.0""\n\nThis reverts commit bbe375c56509bcd6a1ad279736293855f71cc718.\n\nChange-Id: I85a7ae0d1f2dff9dc44e9608029f4a610be6f482\n'}, {'number': 2, 'created': '2014-12-18 20:36:18.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/34ebb7908204442fa7ef9412a45809da15351ece', 'message': 'Revert ""Exclude testtools 1.4.0""\n\nTesttools>=1.4.0 was added because it broke tempest support for attrs\nwhich in turn broke our gate job definitions. This was fixed in tempest\nchange Ia5dda59f7989f37997276cbd19bb9fdc7b7d2624 so the exclude is no\nlonger necessary.\n\nThis reverts commit bbe375c56509bcd6a1ad279736293855f71cc718.\n\nChange-Id: I85a7ae0d1f2dff9dc44e9608029f4a610be6f482\n'}]",0,135834,34ebb7908204442fa7ef9412a45809da15351ece,4,2,2,5196,,,0,"Revert ""Exclude testtools 1.4.0""

Testtools>=1.4.0 was added because it broke tempest support for attrs
which in turn broke our gate job definitions. This was fixed in tempest
change Ia5dda59f7989f37997276cbd19bb9fdc7b7d2624 so the exclude is no
longer necessary.

This reverts commit bbe375c56509bcd6a1ad279736293855f71cc718.

Change-Id: I85a7ae0d1f2dff9dc44e9608029f4a610be6f482
",git fetch https://review.opendev.org/openstack/requirements refs/changes/34/135834/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,206c28e6a085f6262bf3601252a55d4794187c59,exclude-testtools-1.4.0-icehouse,"testtools>=0.9.34,!=1.2.0","testtools>=0.9.34,!=1.2.0,!=1.4.0",1,1
openstack%2Frequirements~stable%2Fjuno~Id886ba95ae0f62051c5e52be9deaa6e5b1eed947,openstack/requirements,stable/juno,Id886ba95ae0f62051c5e52be9deaa6e5b1eed947,"Revert ""Exclude testtools 1.4.0""",ABANDONED,2014-11-20 03:47:48.000000000,2014-12-18 20:54:35.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-11-20 03:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/9bf607f103771868bf9f69d60e74ce10469301d3', 'message': 'Revert ""Exclude testtools 1.4.0""\n\nThis reverts commit 60b2332edec4a233d5915c8f67194c3138b829c6.\n\nChange-Id: Id886ba95ae0f62051c5e52be9deaa6e5b1eed947\n'}, {'number': 2, 'created': '2014-12-18 20:36:35.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5c4a3cdf19be23df9c6fd9ebd4dac906c3a047a9', 'message': 'Revert ""Exclude testtools 1.4.0""\n\nTesttools>=1.4.0 was added because it broke tempest support for attrs\nwhich in turn broke our gate job definitions. This was fixed in tempest\nchange Ia5dda59f7989f37997276cbd19bb9fdc7b7d2624 so the exclude is no\nlonger necessary.\n\nThis reverts commit 60b2332edec4a233d5915c8f67194c3138b829c6.\n\nChange-Id: Id886ba95ae0f62051c5e52be9deaa6e5b1eed947\n'}]",0,135833,5c4a3cdf19be23df9c6fd9ebd4dac906c3a047a9,6,3,2,5196,,,0,"Revert ""Exclude testtools 1.4.0""

Testtools>=1.4.0 was added because it broke tempest support for attrs
which in turn broke our gate job definitions. This was fixed in tempest
change Ia5dda59f7989f37997276cbd19bb9fdc7b7d2624 so the exclude is no
longer necessary.

This reverts commit 60b2332edec4a233d5915c8f67194c3138b829c6.

Change-Id: Id886ba95ae0f62051c5e52be9deaa6e5b1eed947
",git fetch https://review.opendev.org/openstack/requirements refs/changes/33/135833/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,9bf607f103771868bf9f69d60e74ce10469301d3,exclude-testtools-1.4.0-juno,testtools>=0.9.34,"testtools>=0.9.34,!=1.4.0",1,1
openstack%2Fproject-config~master~Iac6e0abe8c0e88e2d5c92c8c3139b5151cb61210,openstack/project-config,master,Iac6e0abe8c0e88e2d5c92c8c3139b5151cb61210,Go back to rc for pre-releases,MERGED,2014-12-18 14:05:22.000000000,2014-12-18 20:54:06.000000000,2014-12-18 20:54:05.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-18 14:05:22.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c0b7bf442c4aa557778eecaf2d115df75ae91fcb', 'message': 'Go back to rc for pre-releases\n\nsetuptools 8.1 is released with the update to the PEP440 spec. That\nmeans that rc is now the normalization target.\n\nChange-Id: Iac6e0abe8c0e88e2d5c92c8c3139b5151cb61210\n'}]",0,142791,c0b7bf442c4aa557778eecaf2d115df75ae91fcb,8,4,1,2,,,0,"Go back to rc for pre-releases

setuptools 8.1 is released with the update to the PEP440 spec. That
means that rc is now the normalization target.

Change-Id: Iac6e0abe8c0e88e2d5c92c8c3139b5151cb61210
",git fetch https://review.opendev.org/openstack/project-config refs/changes/91/142791/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,c0b7bf442c4aa557778eecaf2d115df75ae91fcb,, ref: ^refs/tags/[0-9]+(\.[0-9]+)*(a|b|rc)[0-9]+$, ref: ^refs/tags/[0-9]+(\.[0-9]+)*(a|b|c)[0-9]+$,1,1
openstack%2Fproject-config~master~Id67603c26114abd05873ffd6f80194a691f5b3c3,openstack/project-config,master,Id67603c26114abd05873ffd6f80194a691f5b3c3,The ci-sandbox project should not require an ICLA,MERGED,2014-12-18 14:45:26.000000000,2014-12-18 20:49:32.000000000,2014-12-18 20:49:32.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-18 14:45:26.000000000', 'files': ['gerrit/acls/openstack-dev/ci-sandbox.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/12421c485506f3d86aa39fb5833b7cd2806fdfe8', 'message': 'The ci-sandbox project should not require an ICLA\n\nThe openstack-dev/ci-sandbox project is meant to be a place for\nthird-party testing systems administrators to test their\nimplementations, which sometimes involves creating changes in Gerrit\nto validate stream-events triggers. Many of these sysadmins are not\nsoftware contributors to OpenStack projects and are likely to not\nhave signed the ICLA or joined the OpenStack Foundation, and so this\ntest project should not require such things thereby reducing the\nnumber of prerequisites for them.\n\nChange-Id: Id67603c26114abd05873ffd6f80194a691f5b3c3\n'}]",0,142804,12421c485506f3d86aa39fb5833b7cd2806fdfe8,7,3,1,5263,,,0,"The ci-sandbox project should not require an ICLA

The openstack-dev/ci-sandbox project is meant to be a place for
third-party testing systems administrators to test their
implementations, which sometimes involves creating changes in Gerrit
to validate stream-events triggers. Many of these sysadmins are not
software contributors to OpenStack projects and are likely to not
have signed the ICLA or joined the OpenStack Foundation, and so this
test project should not require such things thereby reducing the
number of prerequisites for them.

Change-Id: Id67603c26114abd05873ffd6f80194a691f5b3c3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/04/142804/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack-dev/ci-sandbox.config'],1,12421c485506f3d86aa39fb5833b7cd2806fdfe8,ci-sandbox,,requireContributorAgreement = true,0,1
openstack%2Ftaskflow~master~Ic362ef3400f9c77e60ed07b0097e3427b999d1cd,openstack/taskflow,master,Ic362ef3400f9c77e60ed07b0097e3427b999d1cd,Properly handle and skip empty intermediary flows,MERGED,2014-11-18 01:40:48.000000000,2014-12-18 20:45:11.000000000,2014-12-18 20:45:09.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-11-18 01:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/063daf5c763c03e07b5dce226259f0cdf62dddd7', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 2, 'created': '2014-11-18 03:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a0cff3f9b1e4a4da66ae0080e38fa0ce057ee577', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 3, 'created': '2014-11-18 05:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1ba88ca3a5f5b31b200c636889a446538ed323ea', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 4, 'created': '2014-11-18 21:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/788fc063278cdc0637a519f76dc1c7e0c436cd61', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 5, 'created': '2014-11-19 22:41:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7cda4c20fcc315ab2f1486670bd0e66da73b2e39', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 6, 'created': '2014-12-02 19:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/aee07d4f6e7746b14d3c17825d18553a977e8c81', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 7, 'created': '2014-12-04 22:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5516985e2ca2a6c7c3ca8e261c3d1c8d5ea121c5', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 8, 'created': '2014-12-05 06:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fc6e566da991115c6b260e0da0caa6f2f494d312', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 9, 'created': '2014-12-05 06:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/392cdc2c7ecc20f5580cd0aa9368824d6d60996e', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 10, 'created': '2014-12-05 06:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/733533147e5c1fe1e290db06f77ac043ae605938', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 11, 'created': '2014-12-06 00:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/82bdc1dbda3cf0b2bbacdffd68a2322f070b972c', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 12, 'created': '2014-12-06 18:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fee8330167b2d5ebcfcbb295f1d0f1b73de0d767', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 13, 'created': '2014-12-06 18:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/08f9a6880e98dd1530e51674464d6a393b762327', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 14, 'created': '2014-12-06 19:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fbc843d488df20950b91fae3cb0c6afff6313107', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 15, 'created': '2014-12-06 19:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b742424556cee35cbadc3dea87f6bdb769c87119', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 16, 'created': '2014-12-06 20:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c0ea3fe1fb7e8ead26a0782ce4e5a3e2d8188da0', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 17, 'created': '2014-12-06 21:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b20c6eab83eb654b4860398cd98bd802db3d2d64', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 18, 'created': '2014-12-07 03:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/eca3b2537153c0396497b488a40d3444211daaa4', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 19, 'created': '2014-12-07 03:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/eb6a2604ed7ce0fce94d0b136b5cbc757535870b', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}, {'number': 20, 'created': '2014-12-11 04:06:26.000000000', 'files': ['taskflow/engines/action_engine/compiler.py', 'taskflow/exceptions.py', 'taskflow/tests/unit/action_engine/test_compile.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/eaf49950383865438dd5aaef05de7d86977403f5', 'message': 'Properly handle and skip empty intermediary flows\n\nInstead of linking nodes which have elements to\npredecessors which do not we should search backwards\nthrough the prior predecessors and link to one that\ndoes have nodes; this ensures that we do not create\nbad workflows when empty flows are injected.\n\nFixes bug 1392650\n\nChange-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd\n'}]",0,135146,eaf49950383865438dd5aaef05de7d86977403f5,55,5,20,1297,,,0,"Properly handle and skip empty intermediary flows

Instead of linking nodes which have elements to
predecessors which do not we should search backwards
through the prior predecessors and link to one that
does have nodes; this ensures that we do not create
bad workflows when empty flows are injected.

Fixes bug 1392650

Change-Id: Ic362ef3400f9c77e60ed07b0097e3427b999d1cd
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/46/135146/4 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/compiler.py', 'taskflow/tests/unit/action_engine/test_compile.py']",2,063daf5c763c03e07b5dce226259f0cdf62dddd7,bug/1392650," def test_empty_flow_in_linear_flow(self): flow = lf.Flow('lf') a = test_utils.ProvidesRequiresTask('a', provides=[], requires=[]) b = test_utils.ProvidesRequiresTask('b', provides=[], requires=[]) empty_flow = gf.Flow(""empty"") flow.add(a, empty_flow, b) compilation = compiler.PatternCompiler(flow).compile() g = compilation.execution_graph self.assertItemsEqual(g.edges(data=True), [ (a, b, {'invariant': True}), ]) def test_empty_flow_in_nested_flow(self): flow = lf.Flow('lf') a = test_utils.ProvidesRequiresTask('a', provides=[], requires=[]) b = test_utils.ProvidesRequiresTask('b', provides=[], requires=[]) flow2 = lf.Flow(""lf-2"") c = test_utils.ProvidesRequiresTask('c', provides=[], requires=[]) d = test_utils.ProvidesRequiresTask('d', provides=[], requires=[]) empty_flow = gf.Flow(""empty"") flow2.add(c, empty_flow, d) flow.add(a, flow2, b) compilation = compiler.PatternCompiler(flow).compile() g = compilation.execution_graph self.assertTrue(g.has_edge(a, c)) self.assertTrue(g.has_edge(c, d)) self.assertTrue(g.has_edge(d, b)) def test_empty_flow_in_graph_flow(self): flow = lf.Flow('lf') a = test_utils.ProvidesRequiresTask('a', provides=['a'], requires=[]) b = test_utils.ProvidesRequiresTask('b', provides=[], requires=['a']) empty_flow = lf.Flow(""empty"") flow.add(a, empty_flow, b) compilation = compiler.PatternCompiler(flow).compile() g = compilation.execution_graph self.assertTrue(g.has_edge(a, b)) def test_empty_flow_in_graph_flow_empty_linkage(self): flow = gf.Flow('lf') a = test_utils.ProvidesRequiresTask('a', provides=[], requires=[]) b = test_utils.ProvidesRequiresTask('b', provides=[], requires=[]) empty_flow = lf.Flow(""empty"") flow.add(a, empty_flow, b) flow.link(empty_flow, b) compilation = compiler.PatternCompiler(flow).compile() g = compilation.execution_graph self.assertEqual(0, len(g.edges())) def test_empty_flow_in_graph_flow_linkage(self): flow = gf.Flow('lf') a = test_utils.ProvidesRequiresTask('a', provides=[], requires=[]) b = test_utils.ProvidesRequiresTask('b', provides=[], requires=[]) empty_flow = lf.Flow(""empty"") flow.add(a, empty_flow, b) flow.link(a, b) compilation = compiler.PatternCompiler(flow).compile() g = compilation.execution_graph self.assertEqual(1, len(g.edges())) self.assertTrue(g.has_edge(a, b)) ",,127,19
openstack%2Fproject-config~master~I47fae9682e4148d2e71c0e0c82742b3f8f3bd3a4,openstack/project-config,master,I47fae9682e4148d2e71c0e0c82742b3f8f3bd3a4,Pre-release tags use rc instead of c,ABANDONED,2014-12-18 15:20:43.000000000,2014-12-18 20:37:22.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-18 15:20:43.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f63e9193cd39523b45f3de0a86c6546ef306d022', 'message': 'Pre-release tags use rc instead of c\n\nSetuptools 8.1 now normalizes ""c"" to ""rc"" in release candidate\nversions, so our pre-release tag pattern needs to strictly match\nthat.\n\nChange-Id: I47fae9682e4148d2e71c0e0c82742b3f8f3bd3a4\n'}]",0,142814,f63e9193cd39523b45f3de0a86c6546ef306d022,5,2,1,5263,,,0,"Pre-release tags use rc instead of c

Setuptools 8.1 now normalizes ""c"" to ""rc"" in release candidate
versions, so our pre-release tag pattern needs to strictly match
that.

Change-Id: I47fae9682e4148d2e71c0e0c82742b3f8f3bd3a4
",git fetch https://review.opendev.org/openstack/project-config refs/changes/14/142814/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,f63e9193cd39523b45f3de0a86c6546ef306d022,setuptools-8, ref: ^refs/tags/[0-9]+(\.[0-9]+)*(a|b|rc)[0-9]+$, ref: ^refs/tags/[0-9]+(\.[0-9]+)*(a|b|c)[0-9]+$,1,1
openstack%2Fbarbican~master~Ida180fc7c53ea5111fb3d0f5d6cd2c2cdbd0a5fe,openstack/barbican,master,Ida180fc7c53ea5111fb3d0f5d6cd2c2cdbd0a5fe,Use 'project' in test related files,ABANDONED,2014-12-17 00:09:07.000000000,2014-12-18 20:29:31.000000000,,"[{'_account_id': 3}, {'_account_id': 7789}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-12-17 00:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/de0973e87205e8ad61a8db9db43aa60e3cbb86b5', 'message': 'Use project in test related files\n\nChange tenant in favor of projects in both docs and files that are\nrelated to the functional tests.\n\nPartially implements: blueprint replace-concept-of-tenants-for-projects\n\nChange-Id: Ida180fc7c53ea5111fb3d0f5d6cd2c2cdbd0a5fe\n'}, {'number': 2, 'created': '2014-12-17 00:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/fb6ff47fc53ca8646f0b300c9adbd24b65f8ac4b', 'message': ""Use 'project' in test related files\n\nChange tenant in favor of projects in both docs and files that are\nrelated to the functional tests.\n\nPartially implements: blueprint replace-concept-of-tenants-for-projects\n\nChange-Id: Ida180fc7c53ea5111fb3d0f5d6cd2c2cdbd0a5fe\n""}, {'number': 3, 'created': '2014-12-17 01:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/a15c632d6f50de3348f89ccded7ba413be9859e6', 'message': ""Use 'project' in test related files\n\nChange tenant in favor of projects in both docs and files that are\nrelated to the functional tests.\n\nPartially implements: blueprint replace-concept-of-tenants-for-projects\n\nChange-Id: Ida180fc7c53ea5111fb3d0f5d6cd2c2cdbd0a5fe\n""}, {'number': 4, 'created': '2014-12-18 19:30:12.000000000', 'files': ['functionaltests/api/base.py', 'etc/barbican/barbican-api-paste.ini', 'etc/dev_tempest.conf'], 'web_link': 'https://opendev.org/openstack/barbican/commit/951f948abe93b5e32768bf57705f7b9b4ce1289b', 'message': ""Use 'project' in test related files\n\nChange tenant in favor of projects in files that are related\nto the functional tests. On the other hand, v3 is introduced in\nthe devstack conf.\n\nPartially implements: blueprint replace-concept-of-tenants-for-projects\n\nChange-Id: Ida180fc7c53ea5111fb3d0f5d6cd2c2cdbd0a5fe\n""}]",6,142262,951f948abe93b5e32768bf57705f7b9b4ce1289b,12,3,4,10873,,,0,"Use 'project' in test related files

Change tenant in favor of projects in files that are related
to the functional tests. On the other hand, v3 is introduced in
the devstack conf.

Partially implements: blueprint replace-concept-of-tenants-for-projects

Change-Id: Ida180fc7c53ea5111fb3d0f5d6cd2c2cdbd0a5fe
",git fetch https://review.opendev.org/openstack/barbican refs/changes/62/142262/2 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/api/base.py', 'etc/barbican/barbican-api-paste.ini', 'contrib/devstack/lib/barbican', 'doc/source/setup/keystone.rst', 'etc/dev_tempest.conf']",5,de0973e87205e8ad61a8db9db43aa60e3cbb86b5,bp/replace-concept-of-tenants-for-projects,project_name=adminadmin_project_name=admin,tenant_name=adminadmin_tenant_name=admin,6,6
openstack%2Ftaskflow~master~I842fcc5d3e06f69a9479b60b3b89a24233171cfb,openstack/taskflow,master,I842fcc5d3e06f69a9479b60b3b89a24233171cfb,Add a 'can_be_registered' method that checks before notifying,MERGED,2014-12-16 00:43:42.000000000,2014-12-18 20:23:07.000000000,2014-12-18 20:23:06.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 8092}, {'_account_id': 9608}]","[{'number': 1, 'created': '2014-12-16 00:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c269964da8789cce4fdd8b7c34800516c843f63e', 'message': ""Add a 'can_be_notified' method that checks before notifying\n\nAdd a new method that can be used to check if a event type is\nallowed to trigger a notification; and initially use it to\ndisallow the ANY meta event type from being used to trigger\nnotifications.\n\nChange-Id: I842fcc5d3e06f69a9479b60b3b89a24233171cfb\n""}, {'number': 2, 'created': '2014-12-16 00:44:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d3b558677a38fd38a3d76a3a9a972bf42b4a40c9', 'message': ""Add a 'can_be_notified' method that checks before notifying\n\nAdd a new method that can be used to check if a event type is\nallowed to trigger a notification; and initially use it to\ndisallow the ANY meta event type from being used to trigger\nnotifications.\n\nChange-Id: I842fcc5d3e06f69a9479b60b3b89a24233171cfb\n""}, {'number': 3, 'created': '2014-12-16 00:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dbbff8719a9db385a50ddfbfdd21cd86769fe03b', 'message': ""Add a 'can_be_notified' method that checks before notifying\n\nAdd a new method that can be used to check if a event type is\nallowed to trigger a notification; and initially use it to\ndisallow the ANY meta event type from being used to trigger\nnotifications.\n\nChange-Id: I842fcc5d3e06f69a9479b60b3b89a24233171cfb\n""}, {'number': 4, 'created': '2014-12-16 03:18:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9563d29e5b98bbe6802ef0f61ed5c93f701cdf14', 'message': ""Add a 'can_be_notified' method that checks before notifying\n\nAdd a new method that can be used to check if a event type is\nallowed to trigger a notification; and initially use it to\ndisallow the ANY meta event type from being used to trigger\nnotifications.\n\nChange-Id: I842fcc5d3e06f69a9479b60b3b89a24233171cfb\n""}, {'number': 5, 'created': '2014-12-16 03:19:38.000000000', 'files': ['taskflow/types/notifier.py', 'taskflow/tests/unit/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1b0618338c5eb70116cc056b31d83c18d90eac59', 'message': ""Add a 'can_be_registered' method that checks before notifying\n\nAdd a new method that can be used to check if a event type is\nallowed to trigger a notification; and initially use it to\ndisallow the 'ANY' meta event type from being used to trigger\nnotifications.\n\nChange-Id: I842fcc5d3e06f69a9479b60b3b89a24233171cfb\n""}]",0,141955,1b0618338c5eb70116cc056b31d83c18d90eac59,23,6,5,1297,,,0,"Add a 'can_be_registered' method that checks before notifying

Add a new method that can be used to check if a event type is
allowed to trigger a notification; and initially use it to
disallow the 'ANY' meta event type from being used to trigger
notifications.

Change-Id: I842fcc5d3e06f69a9479b60b3b89a24233171cfb
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/55/141955/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/types/notifier.py', 'taskflow/tests/unit/test_notifier.py']",2,c269964da8789cce4fdd8b7c34800516c843f63e,," def test_notify_not_called(self): call_collector = [] def call_me(state, details): call_collector.append((state, details)) notifier = nt.Notifier() notifier.register(nt.Notifier.ANY, call_me) notifier.notify(nt.Notifier.ANY, {}) self.assertFalse(notifier.can_be_notified(nt.Notifier.ANY)) self.assertEqual(0, len(call_collector)) self.assertEqual(1, len(notifier)) ",,28,1
openstack%2Fneutron-specs~master~I063fd81e29abb1b72c519606c2c9238811c0515d,openstack/neutron-specs,master,I063fd81e29abb1b72c519606c2c9238811c0515d,IPSec strongSwan VPNaaS Driver,MERGED,2014-06-20 09:28:00.000000000,2014-12-18 20:14:38.000000000,2014-12-18 20:14:38.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 935}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 2874}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7183}, {'_account_id': 7823}, {'_account_id': 8645}, {'_account_id': 9911}, {'_account_id': 12035}]","[{'number': 1, 'created': '2014-06-20 09:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3fec9c679e6596bc2130ae3b9fc47769df3e9bea', 'message': 'IPSec Strongswan Driver\n\nProvide one choice for ubuntu customers to run strongswan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 2, 'created': '2014-06-20 09:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/bec4d03af1258f17c166afd7c9ea8bb2ecd354f6', 'message': 'IPSec Strongswan Driver\n\nProvide one choice for ubuntu customers to run strongswan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 3, 'created': '2014-06-22 00:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d299f411133da64f69c4e118cd57da21db284459', 'message': 'IPSec Strongswan VPNaaS Driver\n\nProvide one choice for ubuntu customers to run strongswan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 4, 'created': '2014-06-28 02:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0d7326e81d89d772facd45699b24eb476e01882c', 'message': 'IPSec Strongswan VPNaaS Driver\n\nProvide one choice for ubuntu customers to run strongswan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 5, 'created': '2014-10-09 13:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/7c3d37c8320c5738ba278ce9d6f80ea604666391', 'message': 'IPSec strongSwan VPNaaS Driver\n\nProvide one choice for ubuntu customers to run strongSwan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 6, 'created': '2014-10-10 11:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/133b20fe757d8d8b6694ce1fae38cbd24ef8265e', 'message': 'IPSec strongSwan VPNaaS Driver\n\nProvide one choice for ubuntu customers to run strongSwan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 7, 'created': '2014-10-13 06:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c9a4227e647564dda2799602d27bbe7192303742', 'message': 'IPSec strongSwan VPNaaS Driver\n\nProvide one choice for ubuntu customers to run strongSwan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 8, 'created': '2014-11-01 03:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e7e5e5b48adc8b4463ec91b19b5b173cdb12b59b', 'message': 'IPSec strongSwan VPNaaS Driver\n\nProvide one choice for ubuntu customers to run strongSwan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 9, 'created': '2014-11-10 05:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/eb53446c741dbcd9fa635600762956b3da4b2b1d', 'message': 'IPSec strongSwan VPNaaS Driver\n\nProvide one choice for ubuntu customers to run strongSwan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 10, 'created': '2014-12-11 08:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ebd8f0676e02df91e5d031e18b06d6795c55f64f', 'message': 'IPSec strongSwan VPNaaS Driver\n\nProvide one choice for ubuntu customers to run strongSwan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 11, 'created': '2014-12-11 09:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e40948e97d78f45b4489864b136d666fefab5379', 'message': 'IPSec strongSwan VPNaaS Driver\n\nProvide one choice for ubuntu customers to run strongSwan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 12, 'created': '2014-12-12 08:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ebc3b69d06e30e57caca743dc05f42655935fca7', 'message': 'IPSec strongSwan VPNaaS Driver\n\nProvide one choice for ubuntu customers to run strongSwan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}, {'number': 13, 'created': '2014-12-18 08:44:53.000000000', 'files': ['specs/kilo/ipsec-strongswan-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/da95a047ae54adf3044264628661117ea978ce42', 'message': 'IPSec strongSwan VPNaaS Driver\n\nProvide one choice for ubuntu customers to run strongSwan\nipsec vpn on it just as openswan does on Redhat.\n\nChange-Id: I063fd81e29abb1b72c519606c2c9238811c0515d\nImplements: blueprint ipsec-strongswan-driver\n'}]",56,101457,da95a047ae54adf3044264628661117ea978ce42,89,17,13,2711,,,0,"IPSec strongSwan VPNaaS Driver

Provide one choice for ubuntu customers to run strongSwan
ipsec vpn on it just as openswan does on Redhat.

Change-Id: I063fd81e29abb1b72c519606c2c9238811c0515d
Implements: blueprint ipsec-strongswan-driver
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/57/101457/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/ipsec-strongswan-driver.rst'],1,3fec9c679e6596bc2130ae3b9fc47769df3e9bea,bp/ipsec-strongswan-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== IPSec Strongswan VPNaaS Driver ========================================== https://blueprints.launchpad.net/neutron/+spec/ipsec-strongswan-driver Problem description =================== This driver will provide one choice for ubuntu 14.04 customers to run strongswan ipsec vpn on it just as openswan does on Redhat. Proposed change =============== Strongswan driver is very similar with openswan driver in addition to quite difference of their configuration files. So the currently implemented methods are: * We'd have to create a strongswan_opts based off openswan_opts. * Provide different configuration file template. * Create a StrongSwanProcess class based off OpenSwanProcess in the file neutron/services/vpn/device_drivers/ipsec.py (openswan uses pluto and whack, while strongSwan uses 'charon' and 'stroke' respectively). * The IPsecDriver._update_nat looks like it sets the right iptables ipsec needed rules for strongSwan. Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: https://launchpad.net/~zhhuabj Work Items ---------- * StrongSwanProcess code in neutron/services/vpn/device_drivers/ipsec.py * Work out a configuration file for best practice * Unit tests * A netns wrapper to support running strongswan in different namespace. Dependencies ============ None Testing ======= * Unit tests Documentation Impact ==================== Documentation about this strongswan configuration will need to be written. References ========== * IPSec openswan driver bluprint: https://blueprints.launchpad.net/neutron/+spec/ipsec-vpn-reference * IPSec openswan driver code: https://review.openstack.org/#/c/33148/ * IPSec openswan driver spec: https://docs.google.com/presentation/d/1uoYMl2fAEHTpogAe27xtGpPcbhm7Y3tlHIw_G1Dy5aQ/edit ",,123,0
openstack%2Ftooz~master~Id1b244671e3aec982bdf713a38ff8fae22ac8dfe,openstack/tooz,master,Id1b244671e3aec982bdf713a38ff8fae22ac8dfe,Update links + python version supported,MERGED,2014-12-10 00:39:37.000000000,2014-12-18 20:03:09.000000000,2014-12-18 20:03:09.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-12-10 00:39:37.000000000', 'files': ['doc/source/install.rst'], 'web_link': 'https://opendev.org/openstack/tooz/commit/7b93dc7182ae63f96241d51c7a2ff05af96f9230', 'message': 'Update links + python version supported\n\nUse the right git link and the tested python versions.\n\nChange-Id: Id1b244671e3aec982bdf713a38ff8fae22ac8dfe\n'}]",0,140541,7b93dc7182ae63f96241d51c7a2ff05af96f9230,21,3,1,1297,,,0,"Update links + python version supported

Use the right git link and the tested python versions.

Change-Id: Id1b244671e3aec982bdf713a38ff8fae22ac8dfe
",git fetch https://review.opendev.org/openstack/tooz refs/changes/41/140541/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install.rst'],1,7b93dc7182ae63f96241d51c7a2ff05af96f9230,,tooz is tested under Python 2.7 and 3.4.The source is hosted on the OpenStack infrastructure: https://git.openstack.org/cgit/openstack/tooz/,tooz is tested under Python 2.7 and 3.3.The source is hosted on the OpenStack infrastructure: https://git.openstack.org/cgit/stackforge/tooz/,2,2
openstack%2Ftrove~master~I6330569680c999945badc699be90dbf128fa5448,openstack/trove,master,I6330569680c999945badc699be90dbf128fa5448,Enable volume resize tests,MERGED,2014-12-02 18:55:21.000000000,2014-12-18 19:58:13.000000000,2014-12-18 19:58:12.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 6413}, {'_account_id': 8214}, {'_account_id': 8871}, {'_account_id': 11783}, {'_account_id': 13355}]","[{'number': 1, 'created': '2014-12-02 18:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/cfb9f6b2d36a829d29f4bd55b5ba2a3920276a4d', 'message': 'Enable volume resize tests\n\nChange-Id: I6330569680c999945badc699be90dbf128fa5448\nCloses-Bug: 1100058\n'}, {'number': 2, 'created': '2014-12-10 16:58:14.000000000', 'files': ['trove/tests/api/instances_actions.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/9e6a9fde52207b0a880e2496e534d2629e60ce2e', 'message': 'Enable volume resize tests\n\nChange-Id: I6330569680c999945badc699be90dbf128fa5448\nCloses-Bug: #1100058\n'}]",0,138482,9e6a9fde52207b0a880e2496e534d2629e60ce2e,31,7,2,11783,,,0,"Enable volume resize tests

Change-Id: I6330569680c999945badc699be90dbf128fa5448
Closes-Bug: #1100058
",git fetch https://review.opendev.org/openstack/trove refs/changes/82/138482/2 && git format-patch -1 --stdout FETCH_HEAD,['trove/tests/api/instances_actions.py'],1,cfb9f6b2d36a829d29f4bd55b5ba2a3920276a4d,bug/1100058," groups=[GROUP, tests.INSTANCES, INSTANCE_GROUP, GROUP_RESIZE],"," groups=[GROUP, tests.INSTANCES],",1,1
openstack%2Fdesignate~master~I51825db13c79ec6fd67b7f42c12fac2a60e1c375,openstack/designate,master,I51825db13c79ec6fd67b7f42c12fac2a60e1c375,Imported Translations from Transifex,MERGED,2014-12-18 06:09:41.000000000,2014-12-18 19:48:07.000000000,2014-12-18 19:48:07.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-12-18 06:09:41.000000000', 'files': ['designate/locale/ko_KR/LC_MESSAGES/designate-log-critical.po'], 'web_link': 'https://opendev.org/openstack/designate/commit/73a3530ac586dbfcbd0d14263075a31e55b900c9', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I51825db13c79ec6fd67b7f42c12fac2a60e1c375\n'}]",0,142679,73a3530ac586dbfcbd0d14263075a31e55b900c9,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I51825db13c79ec6fd67b7f42c12fac2a60e1c375
",git fetch https://review.opendev.org/openstack/designate refs/changes/79/142679/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/locale/ko_KR/LC_MESSAGES/designate-log-critical.po'],1,73a3530ac586dbfcbd0d14263075a31e55b900c9,transifex/translations,"# Translations template for designate. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the designate project. # # Translators: # Sungjin Kang <potopro@gmail.com>, 2014 msgid """" msgstr """" ""Project-Id-Version: Designate\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-12-18 06:09+0000\n"" ""PO-Revision-Date: 2014-12-17 12:37+0000\n"" ""Last-Translator: Sungjin Kang <potopro@gmail.com>\n"" ""Language-Team: Korean (Korea) (http://www.transifex.com/projects/p/designate/"" ""language/ko_KR/)\n"" ""Language: ko_KR\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=1; plural=0;\n"" #: designate/api/middleware.py:144 msgid ""Starting designate testcontext middleware"" msgstr ""Designate 테스트 콘텍스트 미들웨어 시작"" #: designate/api/middleware.py:145 msgid ""**** DO NOT USE IN PRODUCTION ****"" msgstr ""**** 제품에서는 사용하지 마세요 ****"" #: designate/backend/impl_powerdns/__init__.py:140 #, python-format msgid """" ""Attempted to delete a domain which is not present in the backend. ID: %s"" msgstr ""백엔드에 존재하지 않는 도메인을 삭제하려고 했습니다. ID: %s"" #: designate/central/service.py:862 msgid ""No servers configured. Please create at least one server"" msgstr ""서버가 구성되어있지 않습니다. 적어도 하나이상의 서버를 생성하십시오."" ",,39,0
openstack%2Fdesignate~master~I9d1f71f9c27169a2478ad196e0eab64a7a2e93d0,openstack/designate,master,I9d1f71f9c27169a2478ad196e0eab64a7a2e93d0,Adds negative tests to test_records.py,MERGED,2014-12-17 08:47:45.000000000,2014-12-18 19:47:49.000000000,2014-12-18 19:47:49.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 2222}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-12-17 08:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/2dc7d5cc6393f95b873acbfe91ded2dfbd009a76', 'message': 'Adds negative tests to test_records.py\n\nThis submission adds two negative tests under\n""designate/tests/test_api/test_v1/test_records.py"" script.\nFollowing are the negative tests -\n1. test_create_record_invalid_ttl\n2. test_update_record_negative_ttl\n\nChange-Id: I9d1f71f9c27169a2478ad196e0eab64a7a2e93d0\n'}, {'number': 2, 'created': '2014-12-18 06:13:59.000000000', 'files': ['designate/tests/test_api/test_v1/test_records.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/2040bec75a0a560b605c34f3232d0a27a45ef1d5', 'message': 'Adds negative tests to test_records.py\n\nThis submission adds two negative tests under\n""designate/tests/test_api/test_v1/test_records.py"" script.\nFollowing are the negative tests -\n1. test_create_record_invalid_ttl\n2. test_update_record_negative_ttl\n\nChange-Id: I9d1f71f9c27169a2478ad196e0eab64a7a2e93d0\n'}]",2,142383,2040bec75a0a560b605c34f3232d0a27a45ef1d5,11,4,2,1037,,,0,"Adds negative tests to test_records.py

This submission adds two negative tests under
""designate/tests/test_api/test_v1/test_records.py"" script.
Following are the negative tests -
1. test_create_record_invalid_ttl
2. test_update_record_negative_ttl

Change-Id: I9d1f71f9c27169a2478ad196e0eab64a7a2e93d0
",git fetch https://review.opendev.org/openstack/designate refs/changes/83/142383/2 && git format-patch -1 --stdout FETCH_HEAD,['designate/tests/test_api/test_v1/test_records.py'],1,2dc7d5cc6393f95b873acbfe91ded2dfbd009a76,separate/designate_records_unittests," def test_create_record_invalid_ttl(self): fixture = self.get_record_fixture(self.recordset['type']) fixture.update({ 'name': self.recordset['name'], 'type': self.recordset['type'], }) # Set the TTL to a invalid value fixture['ttl'] = ""$?!."" # Create a record, Ensuring it Fails with a 400 self.post('domains/%s/records' % self.domain['id'], data=fixture, status_code=400) def test_update_record_negative_ttl(self): # Create a record record = self.create_record(self.domain, self.recordset) data = {'ttl': -1, 'junk': 'Junk Field'} self.put('domains/%s/records/%s' % (self.domain['id'], record['id']), data=data, status_code=400) ",,23,0
openstack%2Ftooz~master~I78931eca9478289e5c643ce37364e059d8009728,openstack/tooz,master,I78931eca9478289e5c643ce37364e059d8009728,tests: use scenarios attributes for timeout capability,MERGED,2014-12-02 14:32:45.000000000,2014-12-18 19:36:37.000000000,2014-12-18 19:36:36.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2813}]","[{'number': 1, 'created': '2014-12-02 14:32:45.000000000', 'files': ['tooz/tests/test_coordination.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/39c09eda6033556072f80701afa1e6d720e366ca', 'message': 'tests: use scenarios attributes for timeout capability\n\nChange-Id: I78931eca9478289e5c643ce37364e059d8009728\n'}]",0,138378,39c09eda6033556072f80701afa1e6d720e366ca,7,3,1,1669,,,0,"tests: use scenarios attributes for timeout capability

Change-Id: I78931eca9478289e5c643ce37364e059d8009728
",git fetch https://review.opendev.org/openstack/tooz refs/changes/78/138378/1 && git format-patch -1 --stdout FETCH_HEAD,['tooz/tests/test_coordination.py'],1,39c09eda6033556072f80701afa1e6d720e366ca,jd/bug1386846," 'bad_url': 'memcached://localhost:1', 'timeout_capable': True}), 'bad_url': 'redis://localhost:1', 'timeout_capable': True}), if not getattr(self, ""timeout_capable"", False): self.skipTest(""This test only works with timeout capable drivers"")"," 'bad_url': 'memcached://localhost:1'}), 'bad_url': 'redis://localhost:1'}), # Only certain drivers have the tested support for timeouts that we test # here, these are the lists of driver types that do support our test type. timeout_capable = [ 'memcached://', 'redis://', ] def skipIfNotSupported(self, supported): applicable = False for prefix in supported: if self.url.startswith(prefix): applicable = True break if not applicable: self.skipTest(""This test only works with %s types for now"" % list(supported)) self.skipIfNotSupported(self.timeout_capable)",6,20
openstack%2Ftooz~master~I4c9e1098dbcd480a2efdf3c73acb99431fe0b242,openstack/tooz,master,I4c9e1098dbcd480a2efdf3c73acb99431fe0b242,Sync requirements to global requirements,MERGED,2014-12-11 05:15:45.000000000,2014-12-18 19:36:31.000000000,2014-12-18 19:36:29.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 7450}]","[{'number': 1, 'created': '2014-12-11 05:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/fecb5f2b8dfaea748a68fbdef967c850c92f107a', 'message': ""Sync requirements to global requirements\n\nFor better tooz adoption, we'll need the requirements to be sync'ed\nto global requirements.\n\nChange-Id: I4c9e1098dbcd480a2efdf3c73acb99431fe0b242\nDepends-On: If934a117039b4101190aba98dfe33ae491027956\n""}, {'number': 2, 'created': '2014-12-11 16:15:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/69fbc06fcc836c1430f3b3db82e5d4123ec3aa1b', 'message': ""Sync requirements to global requirements\n\nFor better tooz adoption, we'll need the requirements to be sync'ed\nto global requirements.\n\nChange-Id: I4c9e1098dbcd480a2efdf3c73acb99431fe0b242\nDepends-On: If934a117039b4101190aba98dfe33ae491027956\n""}, {'number': 3, 'created': '2014-12-11 16:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/cb1ec96848a3689f565ab1449ed4ca7c1f6c03db', 'message': ""Sync requirements to global requirements\n\nFor better tooz adoption, we'll need the requirements to be sync'ed\nto global requirements. sysv_ipc is only on linux platforms and NOT\non windows platforms, so separate that out.\n\nChange-Id: I4c9e1098dbcd480a2efdf3c73acb99431fe0b242\nDepends-On: If934a117039b4101190aba98dfe33ae491027956\n""}, {'number': 4, 'created': '2014-12-11 16:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/961ac7b8f5e05e31391345c4d95bdbafd5176685', 'message': ""Sync requirements to global requirements\n\nFor better tooz adoption, we'll need the requirements to be sync'ed\nto global requirements. sysv_ipc is only on linux platforms and NOT\non windows platforms, so separate that out.\n\nChange-Id: I4c9e1098dbcd480a2efdf3c73acb99431fe0b242\nDepends-On: If934a117039b4101190aba98dfe33ae491027956\n""}, {'number': 5, 'created': '2014-12-11 16:24:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/e3bcd5dc4100bc3d9694c76ab768d15864075d41', 'message': ""Sync requirements to global requirements\n\nFor better tooz adoption, we'll need the requirements to be sync'ed\nto global requirements. sysv_ipc is only on linux platforms and NOT\non windows platforms, and as it is a optional plugin, let's specify\nthat in test-requirements\n\nChange-Id: I4c9e1098dbcd480a2efdf3c73acb99431fe0b242\nDepends-On: If934a117039b4101190aba98dfe33ae491027956\n""}, {'number': 6, 'created': '2014-12-11 20:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/aa20158baa0b971426f5d2c29dee44c4f2600c27', 'message': ""Sync requirements to global requirements\n\nFor better tooz adoption, we'll need the requirements to be sync'ed\nto global requirements. sysv_ipc is only on linux platforms and NOT\non windows platforms, and as it is a optional plugin, let's specify\nthat in test-requirements\n\nChange-Id: I4c9e1098dbcd480a2efdf3c73acb99431fe0b242\nDepends-On: If934a117039b4101190aba98dfe33ae491027956\nDepends-On: I9660a0af74e8b43942f99a6f889213b457cd85db\n""}, {'number': 7, 'created': '2014-12-17 21:25:12.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/tooz/commit/9cfe5db9cca2d65ad4749f88d915fe0b0ed74e02', 'message': ""Sync requirements to global requirements\n\nFor better tooz adoption, we'll need the requirements to be sync'ed\nto global requirements. sysv_ipc is only on linux platforms and NOT\non windows platforms, and as it is a optional plugin, let's specify\nthat in test-requirements\n\nChange-Id: I4c9e1098dbcd480a2efdf3c73acb99431fe0b242\nDepends-On: If934a117039b4101190aba98dfe33ae491027956\nDepends-On: I9660a0af74e8b43942f99a6f889213b457cd85db\n""}]",3,140921,9cfe5db9cca2d65ad4749f88d915fe0b0ed74e02,35,5,7,5638,,,0,"Sync requirements to global requirements

For better tooz adoption, we'll need the requirements to be sync'ed
to global requirements. sysv_ipc is only on linux platforms and NOT
on windows platforms, and as it is a optional plugin, let's specify
that in test-requirements

Change-Id: I4c9e1098dbcd480a2efdf3c73acb99431fe0b242
Depends-On: If934a117039b4101190aba98dfe33ae491027956
Depends-On: I9660a0af74e8b43942f99a6f889213b457cd85db
",git fetch https://review.opendev.org/openstack/tooz refs/changes/21/140921/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'requirements-py3.txt']",3,fecb5f2b8dfaea748a68fbdef967c850c92f107a,,"stevedore>=1.1.0msgpack-python>=0.4.0 retrying>=1.2.3,!=1.3.0sysv_ipc>=0.6.8",stevedore>=0.14msgpack-python retrying!=1.3.0,18,17
openstack%2Fmistral~master~Iabb96fad6a86934b8ff49c3d3511adb4e87bf651,openstack/mistral,master,Iabb96fad6a86934b8ff49c3d3511adb4e87bf651,Fixing parsing inline syntax parameters,MERGED,2014-12-17 14:12:17.000000000,2014-12-18 19:35:52.000000000,2014-12-18 06:53:21.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 10126}]","[{'number': 1, 'created': '2014-12-17 14:12:17.000000000', 'files': ['mistral/tests/unit/workbook/v2/test_dsl_specs_v2.py', 'mistral/workbook/base.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/120e6624ef98e28820183bbc716d9e630623cc2a', 'message': 'Fixing parsing inline syntax parameters\n\nCloses-bug: #1401039\n\nChange-Id: Iabb96fad6a86934b8ff49c3d3511adb4e87bf651\n'}]",1,142452,120e6624ef98e28820183bbc716d9e630623cc2a,8,6,1,7700,,,0,"Fixing parsing inline syntax parameters

Closes-bug: #1401039

Change-Id: Iabb96fad6a86934b8ff49c3d3511adb4e87bf651
",git fetch https://review.opendev.org/openstack/mistral refs/changes/52/142452/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/workbook/v2/test_dsl_specs_v2.py', 'mistral/workbook/base.py']",2,120e6624ef98e28820183bbc716d9e630623cc2a,bug/1401039,"PARAMS_PTRN = re.compile(""([\w]+)=(\""[^\""]*\""\s*|'[^']*'\s*|"" ""\{[^}]*\}\s*|\[.*\]\s*|[\.,:\w\d\.]+)"") v = v.strip()","PARAMS_PTRN = re.compile(""([\w]+)=(\""[^=]*\""|\'[^=]*'|"" ""\{[^=]*\}|\[[^=]*\]|[\.,:\w\d\.]*)"")",14,3
openstack%2Fopenstack-manuals~master~I497452689b06e3c46e4f6cf1d79514a5661b20cc,openstack/openstack-manuals,master,I497452689b06e3c46e4f6cf1d79514a5661b20cc,Configure messaging for glance in the Installation Guide,ABANDONED,2014-10-10 13:09:54.000000000,2014-12-18 19:14:28.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 9515}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-10-10 13:09:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e33646c56cf0648e536fd0fea33c532c65f7de8a', 'message': 'Configure messaging for glance in the Installation Guide\n\nBecause messaging is enabled by default in Juno and it is not possible\nto disable messaging right now it is necessary to configure it.\n\nChange-Id: I497452689b06e3c46e4f6cf1d79514a5661b20cc\n'}, {'number': 2, 'created': '2014-10-10 13:12:31.000000000', 'files': ['doc/install-guide/section_glance-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/18b45405aa584c7a1810aa19e751c20c8987b909', 'message': 'Configure messaging for glance in the Installation Guide\n\nBecause messaging is enabled by default in Juno and it is not possible\nto disable messaging right now it is necessary to configure it.\n\nChange-Id: I497452689b06e3c46e4f6cf1d79514a5661b20cc\n'}]",0,127516,18b45405aa584c7a1810aa19e751c20c8987b909,17,5,2,167,,,0,"Configure messaging for glance in the Installation Guide

Because messaging is enabled by default in Juno and it is not possible
to disable messaging right now it is necessary to configure it.

Change-Id: I497452689b06e3c46e4f6cf1d79514a5661b20cc
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/16/127516/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_glance-install.xml'],1,e33646c56cf0648e536fd0fea33c532c65f7de8a,glance_disable_messaging," </step> <para>Since Juno the <option>notification_driver</option> has no more effect and messaging is enabled by default. Set the following parameters in the <literal>[DEFAULT]</literal> section:</para> <programlisting language=""ini"">[DEFAULT] ... rabbit_host = <replaceable>controller</replaceable> rabbit_password = <replaceable>RABBIT_PASS</replaceable> </programlisting> <note> <para>At the moment it is not possible to disable messaging because of the lack of a no-operation driver in <literal>oslo.messaging</literal>.</para> </note> <step>",,15,0
openstack%2Fmanila~master~I77cab322beba7ec2258e106eebf631c081cfebe5,openstack/manila,master,I77cab322beba7ec2258e106eebf631c081cfebe5,Fix driver mode opt definition,MERGED,2014-12-18 18:00:36.000000000,2014-12-18 19:03:07.000000000,2014-12-18 19:03:04.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 9003}, {'_account_id': 11878}]","[{'number': 1, 'created': '2014-12-18 18:00:36.000000000', 'files': ['manila/tests/share/test_driver.py', 'manila/share/driver.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/397950e1e92b6a99102213b440820b01c84bdede', 'message': 'Fix driver mode opt definition\n\nShare driver mode opt should be StrOpt, but now it is ListOpt. We get driver\nmode validation error when option is redefined within external config file.\nIt can not be caught by update of config opt within code.\n\nChange-Id: I77cab322beba7ec2258e106eebf631c081cfebe5\nCloses-Bug: #1403952\n'}]",0,142861,397950e1e92b6a99102213b440820b01c84bdede,10,5,1,8851,,,0,"Fix driver mode opt definition

Share driver mode opt should be StrOpt, but now it is ListOpt. We get driver
mode validation error when option is redefined within external config file.
It can not be caught by update of config opt within code.

Change-Id: I77cab322beba7ec2258e106eebf631c081cfebe5
Closes-Bug: #1403952
",git fetch https://review.opendev.org/openstack/manila refs/changes/61/142861/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/share/test_driver.py', 'manila/share/driver.py']",2,397950e1e92b6a99102213b440820b01c84bdede,bug/1403952, cfg.StrOpt(, cfg.ListOpt(,17,1
openstack%2Fgrenade~stable%2Fjuno~Ib7560bb4f19d4593b5958b1f94a462c09a23cee7,openstack/grenade,stable/juno,Ib7560bb4f19d4593b5958b1f94a462c09a23cee7,Remove call to inexistent unfubar_testtools function,MERGED,2014-12-10 17:29:02.000000000,2014-12-18 18:57:38.000000000,2014-12-18 18:57:38.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 5174}]","[{'number': 1, 'created': '2014-12-10 17:29:02.000000000', 'files': ['upgrade-infra'], 'web_link': 'https://opendev.org/openstack/grenade/commit/0b5ab81b7f2da876528eb6e0f216a5f8d21d2961', 'message': ""Remove call to inexistent unfubar_testtools function\n\nThe function was removed here I5554514dd862a2004454daf295abbcf9cf9f2bfb\nand since icehouse is not target in grenade job the call it's no longer needed\nhere we can remove it - wasn't causing any big issue besides a 'command\nnot found' but at least closes a bug.\n\nChange-Id: Ib7560bb4f19d4593b5958b1f94a462c09a23cee7\nCloses-bug: #1356178\n(cherry picked from commit 40f30d3d51a5cd53d9c34b11adc598ba5675fe50)\n""}]",0,140778,0b5ab81b7f2da876528eb6e0f216a5f8d21d2961,13,4,1,5174,,,0,"Remove call to inexistent unfubar_testtools function

The function was removed here I5554514dd862a2004454daf295abbcf9cf9f2bfb
and since icehouse is not target in grenade job the call it's no longer needed
here we can remove it - wasn't causing any big issue besides a 'command
not found' but at least closes a bug.

Change-Id: Ib7560bb4f19d4593b5958b1f94a462c09a23cee7
Closes-bug: #1356178
(cherry picked from commit 40f30d3d51a5cd53d9c34b11adc598ba5675fe50)
",git fetch https://review.opendev.org/openstack/grenade refs/changes/78/140778/1 && git format-patch -1 --stdout FETCH_HEAD,['upgrade-infra'],1,0b5ab81b7f2da876528eb6e0f216a5f8d21d2961,bug/1356178,,unfubar_setuptools ,0,2
openstack%2Fgrenade~master~I04a29377fadc4695fc332787c04a212143173ca6,openstack/grenade,master,I04a29377fadc4695fc332787c04a212143173ca6,remove pip install workarounds,MERGED,2014-12-18 12:03:02.000000000,2014-12-18 18:57:35.000000000,2014-12-18 18:57:35.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 5196}]","[{'number': 1, 'created': '2014-12-18 12:03:02.000000000', 'files': ['prep-base'], 'web_link': 'https://opendev.org/openstack/grenade/commit/3277eb976dad1365c0504f3d23225e37099ebb2e', 'message': 'remove pip install workarounds\n\nThese are now solved with global requirements installation\n\nChange-Id: I04a29377fadc4695fc332787c04a212143173ca6\n'}]",0,142741,3277eb976dad1365c0504f3d23225e37099ebb2e,7,3,1,2750,,,0,"remove pip install workarounds

These are now solved with global requirements installation

Change-Id: I04a29377fadc4695fc332787c04a212143173ca6
",git fetch https://review.opendev.org/openstack/grenade refs/changes/41/142741/1 && git format-patch -1 --stdout FETCH_HEAD,['prep-base'],1,3277eb976dad1365c0504f3d23225e37099ebb2e,cleanups,," # NOTE(sdague): remove as soon as we can get cliff to work with older python # toolchains for setuputils pip_install 'cliff>=1.4.3,<1.4.5' # NOTE(sdague): further work arounds for Bug #1403024 # # stable/juno requirements allows oslo.db 1.3. Ceilometer installs # into Swift middleware. Ceilometer depends on oslo.db>1.0 but allows # for SQLA 0.8.4 in stable. Ceilometer ends up installing an oslo.db # which doesn't believe it can work with the SQLA that was fine. When # it loads via the pipeline load in swift the conflict causes earth # shattering kaboom (why Ceilometer doesn't self explode, I don't # know). # # The work around is to put an old oslo.db down first pip_install 'oslo.db<1.3'",0,17
openstack%2Fneutron-fwaas~master~Ic287177dd9130dfcce97400532b40712af97a307,openstack/neutron-fwaas,master,Ic287177dd9130dfcce97400532b40712af97a307,Update documentation files for FWaaS,MERGED,2014-12-18 14:46:30.000000000,2014-12-18 18:57:29.000000000,2014-12-18 18:57:28.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4395}, {'_account_id': 9656}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-18 14:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/76e30f5600b6af53b924e89c94b0485fb5e1dd4f', 'message': 'Update the FWaaS README\n\nThe README file was not updated during the services split to accurately\nreflect what project this was.\n\nChange-Id: Ic287177dd9130dfcce97400532b40712af97a307\n'}, {'number': 2, 'created': '2014-12-18 15:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/32df6a2090632dcd9d560e712822be937f036845', 'message': 'Update documentation files for FWaaS\n\nThe README file was not updated during the services split to accurately\nreflect what project this was. Also, update CONTRIBUTING.rst, HACKING.rst,\nand TESTING.rst to point to their Neutron counterparts. This makes\nmaintaining a single copy easier.\n\nChange-Id: Ic287177dd9130dfcce97400532b40712af97a307\n'}, {'number': 3, 'created': '2014-12-18 16:05:37.000000000', 'files': ['CONTRIBUTING.rst', 'README.rst', 'TESTING.rst', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/28eec97e4908aec5b8a25da0afa75ff8b819434f', 'message': 'Update documentation files for FWaaS\n\nThe README file was not updated during the services split to accurately\nreflect what project this was. Also, update CONTRIBUTING.rst, HACKING.rst,\nand TESTING.rst to point to their Neutron counterparts. This makes\nmaintaining a single copy easier.\n\nChange-Id: Ic287177dd9130dfcce97400532b40712af97a307\n'}]",0,142806,28eec97e4908aec5b8a25da0afa75ff8b819434f,12,5,3,105,,,0,"Update documentation files for FWaaS

The README file was not updated during the services split to accurately
reflect what project this was. Also, update CONTRIBUTING.rst, HACKING.rst,
and TESTING.rst to point to their Neutron counterparts. This makes
maintaining a single copy easier.

Change-Id: Ic287177dd9130dfcce97400532b40712af97a307
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/06/142806/3 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,76e30f5600b6af53b924e89c94b0485fb5e1dd4f,readme,"This package contains the code for the Neutron Firewall as a Service (FWaaS) service. This includes third-party drivers. This package requires Neutron to run.site for asking for help, and filing bugs. We use a single Launchpad page for all Neutron projects. Code is available on git.openstack.org at: <http://git.openstack.org/cgit/openstack/neutron-fwaas>. ","You have come across a cloud computing network fabric controller. It has identified itself as ""Neutron."" It aims to tame your (cloud) networking!site for asking for help, and filing bugs. Code is available on git.openstack.org at <http://git.openstack.org/cgit/openstack/neutron>. The latest and most in-depth documentation on how to use Neutron is available at: <http://docs.openstack.org>. This includes: Neutron Administrator Guide http://docs.openstack.org/admin-guide-cloud/content/ch_networking.html Neutron API Reference: http://docs.openstack.org/api/openstack-network/2.0/content/ Current Neutron developer documentation is available at: http://wiki.openstack.org/NeutronDevelopment For help on usage and hacking of Neutron, please send mail to <mailto:openstack-dev@lists.openstack.org>. For information on how to contribute to Neutron, please see the contents of the CONTRIBUTING.rst file.",7,20
openstack%2Fneutron-lbaas~master~I6392cdca2d8bb7b9a4623fc7394a4e87f446c25a,openstack/neutron-lbaas,master,I6392cdca2d8bb7b9a4623fc7394a4e87f446c25a,Update documentation files for LBaaS,MERGED,2014-12-18 14:46:46.000000000,2014-12-18 18:57:21.000000000,2014-12-18 18:57:21.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4395}, {'_account_id': 9656}, {'_account_id': 10980}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-12-18 14:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/8ee4811d267db031b7b1b73be3b502f016125943', 'message': 'Update the README file\n\nThe README file was not updated during the services split to accurately\nreflect what project this was.\n\nChange-Id: I6392cdca2d8bb7b9a4623fc7394a4e87f446c25a\n'}, {'number': 2, 'created': '2014-12-18 15:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/758ca7c7ed819f9ab7af0dcd54a27c9acc2b0079', 'message': 'Update documentation files for LBaaS\n\nThe README file was not updated during the services split to accurately\nreflect what project this was. Also, update CONTRIBUTING.rst, HACKING.rst,\nand TESTING.rst to point to their Neutron counterparts. This makes\nmaintaining a single copy easier.\n\nChange-Id: I6392cdca2d8bb7b9a4623fc7394a4e87f446c25a\n'}, {'number': 3, 'created': '2014-12-18 16:05:21.000000000', 'files': ['CONTRIBUTING.rst', 'README.rst', 'TESTING.rst', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/9bc2cd285bc5892dc08f8a1548f556b27bc59331', 'message': 'Update documentation files for LBaaS\n\nThe README file was not updated during the services split to accurately\nreflect what project this was. Also, update CONTRIBUTING.rst, HACKING.rst,\nand TESTING.rst to point to their Neutron counterparts. This makes\nmaintaining a single copy easier.\n\nChange-Id: I6392cdca2d8bb7b9a4623fc7394a4e87f446c25a\n'}]",0,142807,9bc2cd285bc5892dc08f8a1548f556b27bc59331,14,6,3,105,,,0,"Update documentation files for LBaaS

The README file was not updated during the services split to accurately
reflect what project this was. Also, update CONTRIBUTING.rst, HACKING.rst,
and TESTING.rst to point to their Neutron counterparts. This makes
maintaining a single copy easier.

Change-Id: I6392cdca2d8bb7b9a4623fc7394a4e87f446c25a
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/07/142807/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,8ee4811d267db031b7b1b73be3b502f016125943,readme,"This package contains the code for the Neutron Load Balancer as a Service (LBaaS) service. This includes third-party drivers. This package requires Neutron to run.site for asking for help, and filing bugs. We use a single Launchpad page for all Neutron projects. Code is available on git.openstack.org at: <http://git.openstack.org/cgit/openstack/neutron-fwaas>.","You have come across a cloud computing network fabric controller. It has identified itself as ""Neutron."" It aims to tame your (cloud) networking!site for asking for help, and filing bugs. Code is available on git.openstack.org at <http://git.openstack.org/cgit/openstack/neutron>. The latest and most in-depth documentation on how to use Neutron is available at: <http://docs.openstack.org>. This includes: Neutron Administrator Guide http://docs.openstack.org/admin-guide-cloud/content/ch_networking.html Neutron API Reference: http://docs.openstack.org/api/openstack-network/2.0/content/ Current Neutron developer documentation is available at: http://wiki.openstack.org/NeutronDevelopment For help on usage and hacking of Neutron, please send mail to <mailto:openstack-dev@lists.openstack.org>. For information on how to contribute to Neutron, please see the contents of the CONTRIBUTING.rst file.",7,21
openstack%2Ftempest~master~Ib345f2173c82999d94031aa0adc092c289463d5a,openstack/tempest,master,Ib345f2173c82999d94031aa0adc092c289463d5a,Enable block_migration_for_live_migration by default,ABANDONED,2014-11-18 01:00:21.000000000,2014-12-18 18:57:14.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 7350}, {'_account_id': 8623}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-18 01:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/954d57c9ccf2942b8e6399c93b0d8451a2a76115', 'message': ""Enable block_migration_for_live_migration by default\n\nNow that we are starting to try testing multi node devstack we want to\ntest live migration with block devices attached (volumes). Turning this\nflag on by default shouldn't impact single node devstack tests as the\nblock_migration_for_live_migration test won't run if there are less then\ntwo compute nodes.\n\nChange-Id: Ib345f2173c82999d94031aa0adc092c289463d5a\n""}, {'number': 2, 'created': '2014-11-25 13:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/164bfe7d624e784a846a39705dafecaad0ff463d', 'message': ""Enable block_migration_for_live_migration by default\n\nNow that we are starting to try testing multi node devstack we want to\ntest live migration with block devices attached (volumes). Turning this\nflag on by default shouldn't impact single node devstack tests as the\nblock_migration_for_live_migration test won't run if there are less then\ntwo compute nodes.\n\n(Pulling from gate, late -2).\n\nChange-Id: Ib345f2173c82999d94031aa0adc092c289463d5a""}, {'number': 3, 'created': '2014-11-25 15:12:59.000000000', 'files': ['etc/tempest.conf.sample', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/3886c5d72f63491074cf4ead7c50b414fadbaeca', 'message': ""Enable block_migration_for_live_migration by default\n\nNow that we are starting to try testing multi node devstack we want to\ntest live migration with block devices attached (volumes). Turning this\nflag on by default shouldn't impact single node devstack tests as the\nblock_migration_for_live_migration test won't run if there are less then\ntwo compute nodes.\n\nChange-Id: Ib345f2173c82999d94031aa0adc092c289463d5a""}]",0,135142,3886c5d72f63491074cf4ead7c50b414fadbaeca,22,9,3,1849,,,0,"Enable block_migration_for_live_migration by default

Now that we are starting to try testing multi node devstack we want to
test live migration with block devices attached (volumes). Turning this
flag on by default shouldn't impact single node devstack tests as the
block_migration_for_live_migration test won't run if there are less then
two compute nodes.

Change-Id: Ib345f2173c82999d94031aa0adc092c289463d5a",git fetch https://review.opendev.org/openstack/tempest refs/changes/42/135142/3 && git format-patch -1 --stdout FETCH_HEAD,"['etc/tempest.conf.sample', 'tempest/config.py']",2,954d57c9ccf2942b8e6399c93b0d8451a2a76115,live," default=True,"," default=False,",2,2
openstack%2Fneutron-vpnaas~master~I4d9cee887753fc6d7b8b1116deebd2a90faa0f3b,openstack/neutron-vpnaas,master,I4d9cee887753fc6d7b8b1116deebd2a90faa0f3b,Update documentation files for VPNaaS,MERGED,2014-12-18 14:47:06.000000000,2014-12-18 18:56:47.000000000,2014-12-18 18:56:46.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}, {'_account_id': 6659}, {'_account_id': 9656}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-18 14:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/eaab451c3f8195baf3b354b9f2dc6a93d9b5eb8e', 'message': 'Update the README file\n\nThe README file was not updated during the services split to accurately\nreflect what project this was.\n\nChange-Id: I4d9cee887753fc6d7b8b1116deebd2a90faa0f3b\n'}, {'number': 2, 'created': '2014-12-18 15:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/c517cbf3ce1ef5dfc2c61328d8288603f6060c94', 'message': 'Update documentation files for VPNaaS\n\nThe README file was not updated during the services split to accurately\nreflect what project this was. Also, update CONTRIBUTING.rst, HACKING.rst,\nand TESTING.rst to point to their Neutron counterparts. This makes\nmaintaining a single copy easier.\n\nChange-Id: I4d9cee887753fc6d7b8b1116deebd2a90faa0f3b\n'}, {'number': 3, 'created': '2014-12-18 16:04:52.000000000', 'files': ['CONTRIBUTING.rst', 'README.rst', 'TESTING.rst', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/578c4c554b9a04a2811f0b6bb51af00eff8ab1dc', 'message': 'Update documentation files for VPNaaS\n\nThe README file was not updated during the services split to accurately\nreflect what project this was. Also, update CONTRIBUTING.rst, HACKING.rst,\nand TESTING.rst to point to their Neutron counterparts. This makes\nmaintaining a single copy easier.\n\nChange-Id: I4d9cee887753fc6d7b8b1116deebd2a90faa0f3b\n'}]",2,142808,578c4c554b9a04a2811f0b6bb51af00eff8ab1dc,14,6,3,105,,,0,"Update documentation files for VPNaaS

The README file was not updated during the services split to accurately
reflect what project this was. Also, update CONTRIBUTING.rst, HACKING.rst,
and TESTING.rst to point to their Neutron counterparts. This makes
maintaining a single copy easier.

Change-Id: I4d9cee887753fc6d7b8b1116deebd2a90faa0f3b
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/08/142808/3 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,eaab451c3f8195baf3b354b9f2dc6a93d9b5eb8e,readme,"This package contains the code for the Neutron VPN as a Service (VPNaaS) service. This includes third-party drivers. This package requires Neutron to run.site for asking for help, and filing bugs. We use a single Launchpad page for all Neutron projects. Code is available on git.openstack.org at: <http://git.openstack.org/cgit/openstack/neutron-fwaas>.","You have come across a cloud computing network fabric controller. It has identified itself as ""Neutron."" It aims to tame your (cloud) networking!site for asking for help, and filing bugs. Code is available on git.openstack.org at <http://git.openstack.org/cgit/openstack/neutron>. The latest and most in-depth documentation on how to use Neutron is available at: <http://docs.openstack.org>. This includes: Neutron Administrator Guide http://docs.openstack.org/admin-guide-cloud/content/ch_networking.html Neutron API Reference: http://docs.openstack.org/api/openstack-network/2.0/content/ Current Neutron developer documentation is available at: http://wiki.openstack.org/NeutronDevelopment For help on usage and hacking of Neutron, please send mail to <mailto:openstack-dev@lists.openstack.org>. For information on how to contribute to Neutron, please see the contents of the CONTRIBUTING.rst file.",7,21
openstack%2Ffuel-docs~master~Iecc85e2cc46c3b7ae757b9f380bc7ac030bec062,openstack/fuel-docs,master,Iecc85e2cc46c3b7ae757b9f380bc7ac030bec062,Replace Name Environment and Choose distro screen,MERGED,2014-11-22 01:25:54.000000000,2014-12-18 18:50:12.000000000,2014-12-18 18:50:12.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-11-22 01:25:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/7e562607e3dad19d3661d007317fde4d5e6733f9', 'message': 'Replace Name Environment and Choose distro screen\n\nUpdated for 6.0\n\nChange-Id: Iecc85e2cc46c3b7ae757b9f380bc7ac030bec062\n'}, {'number': 2, 'created': '2014-12-18 06:25:02.000000000', 'files': ['_images/user_screen_shots/name_environ.png', 'pages/user-guide/create-environment/1500-name-distro.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/20378b0c4371c3e676a60ed767b37c0fefff76fd', 'message': 'Replace Name Environment and Choose distro screen\n\nUpdated for 6.0\n\nChange-Id: Iecc85e2cc46c3b7ae757b9f380bc7ac030bec062\n'}]",1,136543,20378b0c4371c3e676a60ed767b37c0fefff76fd,17,6,2,10014,,,0,"Replace Name Environment and Choose distro screen

Updated for 6.0

Change-Id: Iecc85e2cc46c3b7ae757b9f380bc7ac030bec062
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/43/136543/2 && git format-patch -1 --stdout FETCH_HEAD,"['_images/user_screen_shots/name_environ.png', 'pages/user-guide/create-environment/1500-name-distro.rst']",2,7e562607e3dad19d3661d007317fde4d5e6733f9,user-name," Juno on Ubuntu 12.04.4 (2014.2-6.0) Juno on CentOS 6.5 (2014.2-6.0)it is formed by concatenating the Juno Release numberIn this case, the ""2014.2"" string corresponds to the Juno release version; the ""6.0"" string is the Mirantis OpenStack release number.lists all the releases that your Fuel 6.0 can manage.Fuel 6.0 can manage environments that were previously deployed using those releases. It cannot, however, deploy a new environment using those releases."," Icehouse on Ubuntu 12.04.4 (2014.1.1-5.1) Icehouse on CentOS 6.5 (2014.1.1-5.1)it is formed by concatenating the IceHouse Release numberIn this case, the ""2014.1.1"" string corresponds to the Icehouse release version; the ""5.1"" string is the Mirantis OpenStack release number.lists all the releases that Fuel 5.1 manages.Fuel 5.1 can manage environments that were previously deployed using these releases. It cannot, however, deploy a new environment using these releases.",9,9
openstack%2Fmanila~master~I2e4201842ee2fa2825bad3e14ff1615670a18d31,openstack/manila,master,I2e4201842ee2fa2825bad3e14ff1615670a18d31,Adds Oracle ZFSSA driver for Manila,MERGED,2014-12-05 20:21:17.000000000,2014-12-18 18:48:52.000000000,2014-12-18 18:17:55.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11047}, {'_account_id': 11878}, {'_account_id': 13524}]","[{'number': 1, 'created': '2014-12-05 20:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/64ad74ee0987fd93f986114f6a0ff5909482a449', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}, {'number': 2, 'created': '2014-12-05 21:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/074d8161133c1ab914c8ee04f991f63713ed9211', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}, {'number': 3, 'created': '2014-12-09 20:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d9b5597928239f039054853f386a7bfeae90193b', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}, {'number': 4, 'created': '2014-12-09 22:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c3874f0609f52ff7b1fab38f8ec1163d25a8e5e6', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}, {'number': 5, 'created': '2014-12-12 19:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c6d9d09847643104f0c7bfd5d0e685331bb48867', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}, {'number': 6, 'created': '2014-12-15 17:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7c1494cba9665062c1a7d42d4e24cfbc46427a43', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nDocImpact\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}, {'number': 7, 'created': '2014-12-15 18:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7e13274bce1509654f59299b8c9b259deb5336eb', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nDocImpact\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}, {'number': 8, 'created': '2014-12-16 02:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f2a9eabaab4e1cfa8c16de362e0a6bfe2983de29', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create shares from snapshots.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nDocImpact\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}, {'number': 9, 'created': '2014-12-16 19:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/889caf7d53d136232096fcea66a8e63ccf988d05', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create shares from snapshots.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nDocImpact\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}, {'number': 10, 'created': '2014-12-17 22:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3d2759e90d9eef11b0e61a82c60cffb1caa9f824', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create shares from snapshots.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nDocImpact\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}, {'number': 11, 'created': '2014-12-18 00:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/bc67ed926328341e7021c73b435a57831af1827f', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create shares from snapshots.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nDocImpact\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}, {'number': 12, 'created': '2014-12-18 15:37:14.000000000', 'files': ['manila/share/drivers/zfssa/zfssarest.py', 'manila/tests/share/drivers/zfssa/test_zfssashare.py', 'manila/tests/fake_zfssa.py', 'manila/tests/share/drivers/zfssa/test_zfssarest.py', 'manila/share/drivers/zfssa/__init__.py', 'manila/share/drivers/zfssa/zfssashare.py', 'manila/opts.py', 'manila/tests/share/drivers/zfssa/__init__.py', 'manila/share/drivers/zfssa/restclient.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/6c4f6f6340ce1d9a9fe100eb02234b00e4bd1222', 'message': 'Adds Oracle ZFSSA driver for Manila\n\nThe driver allows Oracle ZFSSA to be a storage resource for Manila.\nIt uses the REST API to communicate with ZFSSA and perform the following:\n* Create/delete NFS/CIFS shares.\n* Create shares from snapshots.\n* Create/delete snapshots.\n* Allow/deny IP access to an NFS share.\n* Get share status.\n\nDocImpact\nChange-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31\nImplements: blueprint oracle-zfssa-driver\n'}]",170,139730,6c4f6f6340ce1d9a9fe100eb02234b00e4bd1222,80,7,12,13524,,,0,"Adds Oracle ZFSSA driver for Manila

The driver allows Oracle ZFSSA to be a storage resource for Manila.
It uses the REST API to communicate with ZFSSA and perform the following:
* Create/delete NFS/CIFS shares.
* Create shares from snapshots.
* Create/delete snapshots.
* Allow/deny IP access to an NFS share.
* Get share status.

DocImpact
Change-Id: I2e4201842ee2fa2825bad3e14ff1615670a18d31
Implements: blueprint oracle-zfssa-driver
",git fetch https://review.opendev.org/openstack/manila refs/changes/30/139730/2 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/zfssa/zfssarest.py', 'manila/share/drivers/zfssa/__init__.py', 'manila/share/drivers/zfssa/zfssashare.py', 'manila/tests/share/drivers/test_zfssa.py', 'manila/share/drivers/zfssa/restclient.py']",5,64ad74ee0987fd93f986114f6a0ff5909482a449,bp/oracle-zfssa-driver,"# Copyright (c) 2014, Oracle and/or its affiliates. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" ZFS Storage Appliance REST API Client Programmatic Interface """""" import httplib import json import StringIO import time import urllib2 def log(obj, message): if obj.log_function: obj.log_function(message) class Status(object): """"""Result HTTP Status."""""" def __init__(self): pass #: Request return OK OK = httplib.OK #: New resource created successfully CREATED = httplib.CREATED #: Command accepted ACCEPTED = httplib.ACCEPTED #: Command returned OK but no data will be returned NO_CONTENT = httplib.NO_CONTENT #: Bad Request BAD_REQUEST = httplib.BAD_REQUEST #: User is not authorized UNAUTHORIZED = httplib.UNAUTHORIZED #: The request is not allowed FORBIDDEN = httplib.FORBIDDEN #: The requested resource was not found NOT_FOUND = httplib.NOT_FOUND #: The request is not allowed NOT_ALLOWED = httplib.METHOD_NOT_ALLOWED #: Request timed out TIMEOUT = httplib.REQUEST_TIMEOUT #: Invalid request CONFLICT = httplib.CONFLICT #: Service Unavailable BUSY = httplib.SERVICE_UNAVAILABLE class RestResult(object): """"""Result from a REST API operation."""""" def __init__(self, logfunc=None, response=None, err=None): """"""Initialize a RestResult containing the results from a REST call :param response: HTTP response """""" self.response = response self.log_function = logfunc self.error = err self.data = """" self.status = 0 if self.response: self.status = self.response.getcode() result = self.response.read() while result: self.data += result result = self.response.read() if self.error: self.status = self.error.code self.data = httplib.responses[self.status] log(self, 'Response code: %s' % self.status) log(self, 'Response data: %s' % self.data) def get_header(self, name): """"""Get an HTTP header with the given name from the results :param name: HTTP header name :return: The header value or None if no value is found """""" if self.response is None: return None info = self.response.info() return info.getheader(name) class RestClientError(Exception): """"""Exception for ZFS REST API client errors."""""" def __init__(self, status, name=""ERR_INTERNAL"", message=None): """"""Create a REST Response exception :param status: HTTP response status :param name: The name of the REST API error type :param message: Descriptive error message returned from REST call """""" super(RestClientError, self).__init__(message) self.code = status self.name = name self.msg = message if status in httplib.responses: self.msg = httplib.responses[status] def __str__(self): return ""%d %s %s"" % (self.code, self.name, self.msg) class RestClientURL(object): """"""ZFSSA urllib2 client."""""" def __init__(self, url, logfunc=None, **kwargs): """"""Initialize a REST client. :param url: The ZFSSA REST API URL :key session: HTTP Cookie value of x-auth-session obtained from a normal BUI login. :key timeout: Time in seconds to wait for command to complete. (Default is 60 seconds) """""" self.url = url self.log_function = logfunc self.local = kwargs.get(""local"", False) self.base_path = kwargs.get(""base_path"", ""/api"") self.timeout = kwargs.get(""timeout"", 60) self.headers = None if kwargs.get('session'): self.headers['x-auth-session'] = kwargs.get('session') self.headers = {""content-type"": ""application/json""} self.do_logout = False self.auth_str = None def _path(self, path, base_path=None): """"""build rest url path."""""" if path.startswith(""http://"") or path.startswith(""https://""): return path if base_path is None: base_path = self.base_path if not path.startswith(base_path) and not ( self.local and (""/api"" + path).startswith(base_path)): path = ""%s%s"" % (base_path, path) if self.local and path.startswith(""/api""): path = path[4:] return self.url + path def _authorize(self): """"""Performs authorization setting x-auth-session."""""" self.headers['authorization'] = 'Basic %s' % self.auth_str if 'x-auth-session' in self.headers: del self.headers['x-auth-session'] try: result = self.post(""/access/v1"") del self.headers['authorization'] if result.status == httplib.CREATED: self.headers['x-auth-session'] = \ result.get_header('x-auth-session') self.do_logout = True log(self, ('ZFSSA version: %s') % result.get_header('x-zfssa-version')) elif result.status == httplib.NOT_FOUND: raise RestClientError(result.status, name=""ERR_RESTError"", message=""REST Not Available: \ Please Upgrade"") except RestClientError as err: del self.headers['authorization'] raise err def login(self, auth_str): """"""Login to an appliance using a user name and password. Start a session like what is done logging into the BUI. This is not a requirement to run REST commands, since the protocol is stateless. What is does is set up a cookie session so that some server side caching can be done. If login is used remember to call logout when finished. :param auth_str: Authorization string (base64) """""" self.auth_str = auth_str self._authorize() def logout(self): """"""Logout of an appliance."""""" result = None try: result = self.delete(""/access/v1"", base_path=""/api"") except RestClientError: pass self.headers.clear() self.do_logout = False return result def islogin(self): """"""return if client is login."""""" return self.do_logout @staticmethod def mkpath(*args, **kwargs): """"""Make a path?query string for making a REST request :cmd_params args: The path part :cmd_params kwargs: The query part """""" buf = StringIO.StringIO() query = ""?"" for arg in args: buf.write(""/"") buf.write(arg) for k in kwargs: buf.write(query) if query == ""?"": query = ""&"" buf.write(k) buf.write(""="") buf.write(kwargs[k]) return buf.getvalue() def request(self, path, request, body=None, **kwargs): """"""Make an HTTP request and return the results :param path: Path used with the initialized URL to make a request :param request: HTTP request type (GET, POST, PUT, DELETE) :param body: HTTP body of request :key accept: Set HTTP 'Accept' header with this value :key base_path: Override the base_path for this request :key content: Set HTTP 'Content-Type' header with this value """""" out_hdrs = dict.copy(self.headers) if kwargs.get(""accept""): out_hdrs['accept'] = kwargs.get(""accept"") if body: if isinstance(body, dict): body = str(json.dumps(body)) if body and len(body): out_hdrs['content-length'] = len(body) zfssaurl = self._path(path, kwargs.get(""base_path"")) req = urllib2.Request(zfssaurl, body, out_hdrs) req.get_method = lambda: request maxreqretries = kwargs.get(""maxreqretries"", 10) retry = 0 response = None log(self, 'Request: %s %s' % (request, zfssaurl)) log(self, 'Out headers: %s' % out_hdrs) if body and body != '': log(self, 'Body: %s' % body) while retry < maxreqretries: try: response = urllib2.urlopen(req, timeout=self.timeout) except urllib2.HTTPError as err: if err.code == httplib.NOT_FOUND: log(self, 'REST Not Found: %s' % err.code) else: log(self, ('REST Not Available: %s') % err.code) if err.code == httplib.SERVICE_UNAVAILABLE and \ retry < maxreqretries: retry += 1 time.sleep(1) log(self, ('Server Busy retry request: %s') % retry) continue if (err.code == httplib.UNAUTHORIZED or err.code == httplib.INTERNAL_SERVER_ERROR) and \ '/access/v1' not in zfssaurl: try: log(self, ('Authorizing request: ' '%(zfssaurl)s' 'retry: %(retry)d .') % {'zfssaurl': zfssaurl, 'retry': retry}) self._authorize() req.add_header('x-auth-session', self.headers['x-auth-session']) except RestClientError: pass retry += 1 time.sleep(1) continue return RestResult(self.log_function, err=err) except urllib2.URLError as err: log(self, ('URLError: %s') % err.reason) raise RestClientError(-1, name=""ERR_URLError"", message=err.reason) break if response and response.getcode() == httplib.SERVICE_UNAVAILABLE and \ retry >= maxreqretries: raise RestClientError(response.getcode(), name=""ERR_HTTPError"", message=""REST Not Available: Disabled"") return RestResult(self.log_function, response=response) def get(self, path, **kwargs): """"""Make an HTTP GET request :param path: Path to resource. """""" return self.request(path, ""GET"", **kwargs) def post(self, path, body="""", **kwargs): """"""Make an HTTP POST request :param path: Path to resource. :param body: Post data content """""" return self.request(path, ""POST"", body, **kwargs) def put(self, path, body="""", **kwargs): """"""Make an HTTP PUT request :param path: Path to resource. :param body: Put data content """""" return self.request(path, ""PUT"", body, **kwargs) def delete(self, path, **kwargs): """"""Make an HTTP DELETE request :param path: Path to resource that will be deleted. """""" return self.request(path, ""DELETE"", **kwargs) def head(self, path, **kwargs): """"""Make an HTTP HEAD request :param path: Path to resource. """""" return self.request(path, ""HEAD"", **kwargs) ",,1315,0
openstack%2Fopenstack-chef-specs~master~I792e4127c31718d2fda9b738f1ea0503fbf1cfcf,openstack/openstack-chef-specs,master,I792e4127c31718d2fda9b738f1ea0503fbf1cfcf,Specification for enable OpenStack Bare Metal Service,MERGED,2014-12-11 09:03:59.000000000,2014-12-18 18:44:43.000000000,2014-12-18 18:44:43.000000000,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 8106}, {'_account_id': 8112}, {'_account_id': 12323}]","[{'number': 1, 'created': '2014-12-11 09:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef-specs/commit/1b1602e5e72359f26712b820b53522f4d1fc4691', 'message': 'Specification for enable OpenStack Bare Metal Service\n\nChange-Id: I792e4127c31718d2fda9b738f1ea0503fbf1cfcf\nImplements: blueprint bare-metal-enablement\n'}, {'number': 2, 'created': '2014-12-11 09:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef-specs/commit/b032d292c90de1113ffe570b7d1b1e9f8d41ea77', 'message': 'Specification for enable OpenStack Bare Metal Service\n\nChange-Id: I792e4127c31718d2fda9b738f1ea0503fbf1cfcf\nImplements: blueprint bare-metal-enablement\n'}, {'number': 3, 'created': '2014-12-11 09:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef-specs/commit/1a8a09b00916da1563dcb904abdfba71a1f1fee9', 'message': 'Specification for enable OpenStack Bare Metal Service\n\nChange-Id: I792e4127c31718d2fda9b738f1ea0503fbf1cfcf\nImplements: blueprint bare-metal-enablement\n'}, {'number': 4, 'created': '2014-12-15 06:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef-specs/commit/f5702bb1eddb04cd475b692dcd50876407085aeb', 'message': 'Specification for enable OpenStack Bare Metal Service\n\nChange-Id: I792e4127c31718d2fda9b738f1ea0503fbf1cfcf\nImplements: blueprint bare-metal-enablement\n'}, {'number': 5, 'created': '2014-12-15 06:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef-specs/commit/a37884dd32ee69ae0709856334493e1c1683d543', 'message': 'Specification for enable OpenStack Bare Metal Service\n\nChange-Id: I792e4127c31718d2fda9b738f1ea0503fbf1cfcf\nImplements: blueprint bare-metal-enablement\n'}, {'number': 6, 'created': '2014-12-16 05:46:47.000000000', 'files': ['doc/source/index.rst', 'specs/kilo/bare-metal/bare-metal-enablement.rst'], 'web_link': 'https://opendev.org/openstack/openstack-chef-specs/commit/49206cfd7b1f315624b7c9b2e3b57195f8c226a9', 'message': 'Specification for enable OpenStack Bare Metal Service\n\nChange-Id: I792e4127c31718d2fda9b738f1ea0503fbf1cfcf\nImplements: blueprint bare-metal-enablement\n'}]",30,140983,49206cfd7b1f315624b7c9b2e3b57195f8c226a9,24,5,6,8112,,,0,"Specification for enable OpenStack Bare Metal Service

Change-Id: I792e4127c31718d2fda9b738f1ea0503fbf1cfcf
Implements: blueprint bare-metal-enablement
",git fetch https://review.opendev.org/openstack/openstack-chef-specs refs/changes/83/140983/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/bare-metal/bare-metal-enablement.rst'],1,1b1602e5e72359f26712b820b53522f4d1fc4691,bp/bare-metal-enablement,"========================================== Enable Bare Metal Service by Chef ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/openstack-chef/+spec/bare-metal-enablement OpenStack Bare Metal Service known as Ironic OpenStack project name provisions Bare Metal machines by leveraging common technologies such as PXE boot and IPMI to cover a wide range of hardware. Problem description =================== * OpenStack Bare Metal Service was available as an incubated project in the ""Icehouse"" release, with many stability and feature improvements in the ""Juno"", it is officially integrated with OpenStack beginning with the ""Kilo"" release. * Currently, there is no Chef cookbook support to install and configure OpenStack Bare Metal Service. Proposed change =============== Add a cookbook included recipes and related attributes/unit tests to install and configure OpenStack Bare Metal Service. The packages which need to be installed include: * RedHat: openstack-ironic-api, openstack-ironic-conductor, openstack-ironic-common and python-ironicclient. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- Refer to [REST_API_V1]_ for details. Security impact --------------- * Authentication method to use when connecting to OpenStack other components is keystone with PKI as well as others. * Allow ironicclient to preform ""secure"" SSL (https) requests, supported SSL version are TLSv1, SSLv23 and SSLv3, but the certificates and key exchange are not in the scope of enabling Bare Metal Service. * Hash algorithms to use for hashing PKI tokens include md5, etc. * The commands which require the use of sudo are: qemu-img iscsiadm blkid blockdev mkswap mkfs mount umount dd fuser parted * About resource exhaustion attack, there is no security impact of this Spec. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: - wenchma@cn.ibm.com Other contributors: - None Work Items ---------- * Add a basic cookbook with the default files for getting thru first gate .gitignore .gitreview .rubocop.yml Berksfile CONTRIBUTING.md Gemfile metadata.md Rakefile README.md TESTING.md /spec/spec_helper.rb * Add the default attribute file to determine Bare Metal Service configuration items. * Add the recipe files to install the packages of Bare Metal Service, configure the [BARE_METAL_TEMPLATE]_ and start Bare Metal services. * Add the template files to enable Bare Metal Service to be configurable. * Add the unit tests. Dependencies ============ * This depends on the blueprint [BARE_METAL_ENABLEMENT]_ * This requires configuring the Bare Metal Service's driver for Compute Service. * This requires the setup of supported boot mode, such as PXE and IPMI. Testing ======= * Add unit tests for the recipes. * For function and CI integration test, at least one node with OpenStack all-in-one deployment is recommended. Documentation Impact ==================== None References ========== .. [BARE_METAL_TEMPLATE] `Bare Metal Template values <http://docs.openstack.org/trunk/config-reference/content/ch_configuring-openstack-bare-metal.html>`_ .. [BARE_METAL_ENABLEMENT] `Bare Metal enablement blueprint <https://blueprints.launchpad.net/openstack-chef/+spec/bare-metal-enablement>`_ .. [REST_API_V1] `Bare Metal RESTful Web API v1 <http://docs.openstack.org/developer/ironic/webapi/v1.html>`_ ",,179,0
openstack%2Fcongress~master~Ica4d4e7d812e14d43375d766c7bebb9d4ce127a4,openstack/congress,master,Ica4d4e7d812e14d43375d766c7bebb9d4ce127a4,Enable: E129,MERGED,2014-12-06 14:10:18.000000000,2014-12-18 18:43:34.000000000,2014-12-18 17:49:40.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 12256}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-06 14:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/55ed9dd9b1a690a00ea5c6cb2286ac413940c173', 'message': 'Enable: E129 visually indented line with same indent as next logical line Edit\n\nChange-Id: Ica4d4e7d812e14d43375d766c7bebb9d4ce127a4\nCloses-Bug: #1398542\n'}, {'number': 2, 'created': '2014-12-06 15:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/dd3777ac075c3c72c3405a196bd3b48479287847', 'message': 'Enable: E129 visually indented line with same\n        indent as next logical line Edit\n\nChange-Id: Ica4d4e7d812e14d43375d766c7bebb9d4ce127a4\nCloses-Bug: #1398542\n'}, {'number': 3, 'created': '2014-12-18 07:27:54.000000000', 'files': ['congress/datasources/swift_driver.py', 'congress/datasources/neutron_driver.py', 'congress/datasources/ceilometer_driver.py', 'tox.ini', 'congress/policy/runtime.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/45fb42d3cc775ecf0ba5a377e467425f73364a2e', 'message': 'Enable: E129\n\nvisually indented line with same indent as next logical line Edit\n\nChange-Id: Ica4d4e7d812e14d43375d766c7bebb9d4ce127a4\nCloses-Bug: #1398542\n'}]",4,139800,45fb42d3cc775ecf0ba5a377e467425f73364a2e,25,5,3,12256,,,0,"Enable: E129

visually indented line with same indent as next logical line Edit

Change-Id: Ica4d4e7d812e14d43375d766c7bebb9d4ce127a4
Closes-Bug: #1398542
",git fetch https://review.opendev.org/openstack/congress refs/changes/00/139800/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/datasources/swift_driver.py', 'congress/datasources/ceilometer_driver.py', 'congress/datasources/neutron_driver.py', 'tox.ini', 'congress/policy/runtime.py']",5,55ed9dd9b1a690a00ea5c6cb2286ac413940c173,bug/1398542, theory is self.theory[self.DATABASE]): return self.theory[self.ENFORCEMENT_THEORY], theory is self.theory[self.DATABASE]): return self.theory[self.ENFORCEMENT_THEORY],29,30
openstack%2Ftripleo-incubator~master~I9a8ace4712c8a3b71f63b0bafe381e3bc6c707da,openstack/tripleo-incubator,master,I9a8ace4712c8a3b71f63b0bafe381e3bc6c707da,Add sysctl to all images,MERGED,2014-12-17 18:00:47.000000000,2014-12-18 18:39:50.000000000,2014-12-18 18:39:49.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7582}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-12-17 18:00:47.000000000', 'files': ['scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/bdfde7186ba77c66bfa4b492fe7847d54d008a29', 'message': 'Add sysctl to all images\n\nThis is needed to customize the default kernel keepalive timings, see\nhttps://bugs.launchpad.net/oslo.messaging/+bug/856764/comments/19\n\nChange-Id: I9a8ace4712c8a3b71f63b0bafe381e3bc6c707da\nPartial-Bug: 1301431\nPartial-Bug: 1385240\nPartial-Bug: 1385234\n'}]",0,142524,bdfde7186ba77c66bfa4b492fe7847d54d008a29,13,6,1,6796,,,0,"Add sysctl to all images

This is needed to customize the default kernel keepalive timings, see
https://bugs.launchpad.net/oslo.messaging/+bug/856764/comments/19

Change-Id: I9a8ace4712c8a3b71f63b0bafe381e3bc6c707da
Partial-Bug: 1301431
Partial-Bug: 1385240
Partial-Bug: 1385234
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/24/142524/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_overcloud.sh'],1,bdfde7186ba77c66bfa4b492fe7847d54d008a29,bug/1301431, swift-proxy swift-storage keepalived haproxy sysctl \ baremetal os-collect-config dhcp-all-interfaces sysctl \ $DIB_COMMON_ELEMENTS $OVERCLOUD_BLOCKSTORAGE_DIB_EXTRA_ARGS 2>&1 | \ dhcp-all-interfaces sysctl \ $DIB_COMMON_ELEMENTS $OVERCLOUD_COMPUTE_DIB_EXTRA_ARGS 2>&1 | \, swift-proxy swift-storage keepalived haproxy \ baremetal os-collect-config \ dhcp-all-interfaces $DIB_COMMON_ELEMENTS \ $OVERCLOUD_BLOCKSTORAGE_DIB_EXTRA_ARGS 2>&1 | \ dhcp-all-interfaces $DIB_COMMON_ELEMENTS $OVERCLOUD_COMPUTE_DIB_EXTRA_ARGS 2>&1 | \,5,5
openstack%2Ffuel-docs~master~Iff66af305b0a386651aa78df78929f3dffb06f9e,openstack/fuel-docs,master,Iff66af305b0a386651aa78df78929f3dffb06f9e,Brings back limitation for Ceilometer support,MERGED,2014-11-19 08:29:31.000000000,2014-12-18 18:39:23.000000000,2014-12-18 18:39:23.000000000,"[{'_account_id': 3}, {'_account_id': 7732}, {'_account_id': 8787}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11427}, {'_account_id': 12139}, {'_account_id': 13082}, {'_account_id': 14046}]","[{'number': 1, 'created': '2014-11-19 08:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6e817e957c08dc306791a7660db3b2ac0b3e082f', 'message': 'Brings back limitation for Ceilometer support\n\nFuel 6.0 does not fully support Ceilometer.\nChanges in User Guide have been restored.\n\nImplements: blueprint ceilometer-support-for-vcenter\n\nChange-Id: Iff66af305b0a386651aa78df78929f3dffb06f9e\n'}, {'number': 2, 'created': '2014-11-25 13:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a6f20ef77af6b1f82712f760c2ab577ac2b2b1b3', 'message': 'Brings back limitation for Ceilometer support\n\nFuel 6.0 does not fully support Ceilometer.\nChanges in User Guide have been restored.\n\nImplements: blueprint ceilometer-support-for-vcenter\n\nChange-Id: Iff66af305b0a386651aa78df78929f3dffb06f9e\n'}, {'number': 3, 'created': '2014-12-03 20:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1d48baf350491283551f8bf514c43376783a9f76', 'message': 'Brings back limitation for Ceilometer support\n\nFuel 6.0 does not fully support Ceilometer.\nChanges in User Guide have been restored.\n\nImplements: blueprint ceilometer-support-for-vcenter\n\nChange-Id: Iff66af305b0a386651aa78df78929f3dffb06f9e\n'}, {'number': 4, 'created': '2014-12-18 08:05:54.000000000', 'files': ['pages/user-guide/7300-vcenter.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4aecc43ee70f5ab11ab74c249518c371a769da4f', 'message': 'Brings back limitation for Ceilometer support\n\nFuel 6.0 does not fully support Ceilometer.\nChanges in User Guide have been restored.\n\nImplements: blueprint ceilometer-support-for-vcenter\n\nChange-Id: Iff66af305b0a386651aa78df78929f3dffb06f9e\n'}]",5,135531,4aecc43ee70f5ab11ab74c249518c371a769da4f,37,11,4,13082,,,0,"Brings back limitation for Ceilometer support

Fuel 6.0 does not fully support Ceilometer.
Changes in User Guide have been restored.

Implements: blueprint ceilometer-support-for-vcenter

Change-Id: Iff66af305b0a386651aa78df78929f3dffb06f9e
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/31/135531/4 && git format-patch -1 --stdout FETCH_HEAD,['pages/user-guide/7300-vcenter.rst'],1,6e817e957c08dc306791a7660db3b2ac0b3e082f,bp/ceilometer-support-for-vcenter,"Fuel has very limited support for :ref:`Ceilometer<ceilometer-term>`; not all metrics are collected. For more details about the Ceilometer plugin for vCenter, see `Support for VMware vCenter Server <https://wiki.openstack.org/wiki/Ceilometer/ blueprints/vmware-vcenter-server#Support_for_VMware_vCenter_Server>`_.",Fuel 6.0 can install a :ref:`Ceilometer<ceilometer-term>` agent on the Controller node where the Compute role is installed when deploying a vCenter environment. Operators can then configure Ceilometer to collect metrics for the vCenter environment; see :ref:`ceilometer-vcenter`. See the `Implement possibility to setup ceilometer compute agent on controller <https://blueprints.launchpad.net/fuel/+spec/ceilometer-support-for-vcenter>`_ blueprint for implementation details.,5,7
openstack%2Ftripleo-image-elements~master~I101db98c4be9d8c865b7457474a483fedebf281c,openstack/tripleo-image-elements,master,I101db98c4be9d8c865b7457474a483fedebf281c,Disable set -x for passwords,MERGED,2014-12-17 19:45:55.000000000,2014-12-18 18:37:53.000000000,2014-12-18 18:37:53.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 8399}]","[{'number': 1, 'created': '2014-12-17 19:45:55.000000000', 'files': ['elements/mysql-migration/os-refresh-config/migration.d/10-bootstrap-mysql', 'elements/tempest/bin/run-tempest'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/262e3ba3cd74b8aeb9ae2e4511bfa9cd1388b42a', 'message': 'Disable set -x for passwords\n\nWhen we are interacting with passwords we should disable logging.\n\nCloses-Bug: #1298205\n\nChange-Id: I101db98c4be9d8c865b7457474a483fedebf281c\n'}]",1,142562,262e3ba3cd74b8aeb9ae2e4511bfa9cd1388b42a,12,3,1,10035,,,0,"Disable set -x for passwords

When we are interacting with passwords we should disable logging.

Closes-Bug: #1298205

Change-Id: I101db98c4be9d8c865b7457474a483fedebf281c
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/62/142562/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/mysql-migration/os-refresh-config/migration.d/10-bootstrap-mysql', 'elements/tempest/bin/run-tempest']",2,262e3ba3cd74b8aeb9ae2e4511bfa9cd1388b42a,fix/dont-log-passwords,# We dont want to output passwords set +xset -x,,9,0
openstack%2Fcinder-specs~master~I48d0b05f0bbc3ed351da94b318299da2a30066c8,openstack/cinder-specs,master,I48d0b05f0bbc3ed351da94b318299da2a30066c8,Add new volume availability checks,ABANDONED,2014-07-15 22:32:20.000000000,2014-12-18 18:29:03.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 7219}, {'_account_id': 11538}]","[{'number': 1, 'created': '2014-07-15 22:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/0541be5675fda99da457aec31c61fe19963ae788', 'message': 'Add new volume availability checks\n\nThis proposal adds new cinderclient methods\nfor checking the availability of a volume for\nattaches and detaches.\n\nblueprint add-volume-checks\n\nChange-Id: I48d0b05f0bbc3ed351da94b318299da2a30066c8\n'}, {'number': 2, 'created': '2014-07-15 22:37:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/a3dec812c0f8b0b506f0ae1d20719c0ca0dbdd93', 'message': 'Add new volume availability checks\n\nThis proposal adds new cinderclient methods\nfor checking the availability of a volume for\nattaches and detaches.\n\nblueprint add-volume-checks\n\nChange-Id: I48d0b05f0bbc3ed351da94b318299da2a30066c8\n'}, {'number': 3, 'created': '2014-07-15 22:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/ee9dd067155493345d64158d5ff5a6d2346e23d8', 'message': 'Add new volume availability checks\n\nThis proposal adds new cinderclient methods\nfor checking the availability of a volume for\nattaches and detaches.\n\nblueprint add-volume-checks\n\nChange-Id: I48d0b05f0bbc3ed351da94b318299da2a30066c8\n'}, {'number': 4, 'created': '2014-07-16 18:14:11.000000000', 'files': ['specs/juno/cinderclient-add-volume-checks.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/79ec7b847ce1ad9dfd7eb7c881a4b4d0f8f59c08', 'message': 'Add new volume availability checks\n\nThis proposal adds new cinderclient methods\nfor checking the availability of a volume for\nattaches and detaches.\n\nblueprint add-volume-checks\n\nChange-Id: I48d0b05f0bbc3ed351da94b318299da2a30066c8\n'}]",4,107196,79ec7b847ce1ad9dfd7eb7c881a4b4d0f8f59c08,32,7,4,5997,,,0,"Add new volume availability checks

This proposal adds new cinderclient methods
for checking the availability of a volume for
attaches and detaches.

blueprint add-volume-checks

Change-Id: I48d0b05f0bbc3ed351da94b318299da2a30066c8
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/96/107196/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/cinderclient-add-volume-checks.rst'],1,0541be5675fda99da457aec31c61fe19963ae788,add-volume-checks,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== https://blueprints.launchpad.net/cinder/+spec/add-volume-checks Problem description =================== The Cinderclient is missing some calls to see if a volume is in a state that it can be attached/detached. Nova currently fetches a volume, then looks at the state of the volume object to make a decision on attaching/detaching. This has several problems: * Cinder knows the internal state of a volume better than anyone and should be asked if a volume is available to attach/detach. * If cinder changes how volume states are managed, then all other projects that use cinder will have to change their current code to match the changes in cinder. * The state of a volume can possibly change between when the volume info is fetched in nova and when nova checks the state of the volume. For example, today nova's nova/volume/cinder.py has methods for check_attach and check_detach. Those methods require fetching a volume first, then looking at the internal state of the volume object to determine if nova can attach a volume or not. This also makes a big assumption that nova knows the logic of cinder's volume state. Proposed change =============== The cinderclient should be modified to add new methods for checking the availabilty of the volume for taking actions. Other projects can then change their use of the cinderclient to make the inquiries on the volume. Alternatives ------------ The actual checks for availability to take an action on a volume can be done in 1 of 2 places: * The cinderclient can fetch the volume and then check the state, depending on the action being requested. This prevents needing to change the cinder volume manager to add the new checks. * The cinderclient can simply pass through the request into cinder itself to do more complicated checks. This saves the overhead of sending the volume object from cinder to where the cinderclient is running. This requires adding new methods in the cinder volume manager to do the checks in question. I prefer moving the checks into the volume manager itself. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- I would say this has negligable security impact. It does help keep some of the cinder volume state checks in Cinder's realm, by exposing new calls to do the checks in Cinder. There is still nothing preventing someone from looking at the state values in the volume. Notifications impact -------------------- None Other end user impact --------------------- An end user/admin won't interact with this change. It does have the added benefit of creating a cleaner contract for using Cinder and determining if a user of cinder can attach/detach a volume. * The python-cinderclient will have new methods added for doing the checks. This also enables tempest to have an api to call to do the same work. * The new methods on the python-cinderclient would look like client.volumes.check_attach(volume_id) client.volumes.check_detach(volume_id) client.volumes.check_attached(volume_id) Performance Impact ------------------ Most places in Nova that call the check_attach code first makes a call to fetch the volume. * If the checks are moved down into the cinder volume manager, then that volume fetch over the wire never has to happen. This would be a small improvement in data traffic between Nova and Cinder. * If the checks are simply moved into the cinderclient, then the cinderclient will have to first fetch the volume from cinder before doing the check. This is basically the same overall performance as it is today. Other deployer impact --------------------- These are brand new cinderclient APIs that no one is using. This shouldn't impact deployments of Cinder. Developer impact ---------------- This won't affect Cinder driver developers. When/If Cinder changes the state management of volumes, the developer making those logic changes may have to update the new methods in the cinderclient or volume manager. Implementation ============== Assignee(s) ----------- Primary assignee: walter-boring Work Items ---------- * Add the new methods to the python-cinderclient * Add the needed methods to the cinder volume manager. * Add unit tests Dependencies ============ * Include specific references to specs and/or blueprints in cinder, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Cinder (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Testing ======= New unit tests will have to be written to test the new check_* calls. The upside is that the logic for the volume state can be tested in cinder and eventually Tempest. Documentation Impact ==================== None References ========== I discovered this issue while working on the multi-attach patches for cinder, cinderclient and nova. I was required to make major logic changes in the nova/volume/cinder.py check_attach code, since multi-attach changes the availability logic for Cinder volumes. This change will help prevent future nova changes if the internal state of volume availability changes. We'll simply update cinder's code that does the check and nova will still get a valid, but updated answer. * https://review.openstack.org/#/c/85852 * https://review.openstack.org/#/c/85852/2/nova/volume/cinder.py ",,196,0
openstack%2Fpython-cinderclient~master~I4b082cdf96a24d6b5984beafcb7ddf727b94fdaf,openstack/python-cinderclient,master,I4b082cdf96a24d6b5984beafcb7ddf727b94fdaf,Add new volume availability checks,ABANDONED,2014-07-21 23:11:02.000000000,2014-12-18 18:28:52.000000000,,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 5538}, {'_account_id': 5997}]","[{'number': 1, 'created': '2014-07-21 23:11:02.000000000', 'files': ['cinderclient/tests/v2/test_volumes.py', 'cinderclient/tests/v2/fakes.py', 'cinderclient/v2/volumes.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/6d1eb7c429e4860de62617c2a95f995076a9724e', 'message': 'Add new volume availability checks\n\nThis patch adds 3 new api calls to check\nthe availability of a volume.\n\ncan_attach\nis_attached\ncan_detach\n\nThis patch is the result of the cinder-specs:\nhttps://review.openstack.org/#/c/107196/\n\nChange-Id: I4b082cdf96a24d6b5984beafcb7ddf727b94fdaf\nImplements: blueprint add-volume-checks\n'}]",0,108529,6d1eb7c429e4860de62617c2a95f995076a9724e,6,4,1,5997,,,0,"Add new volume availability checks

This patch adds 3 new api calls to check
the availability of a volume.

can_attach
is_attached
can_detach

This patch is the result of the cinder-specs:
https://review.openstack.org/#/c/107196/

Change-Id: I4b082cdf96a24d6b5984beafcb7ddf727b94fdaf
Implements: blueprint add-volume-checks
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/29/108529/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/tests/v2/test_volumes.py', 'cinderclient/tests/v2/fakes.py', 'cinderclient/v2/volumes.py']",3,6d1eb7c429e4860de62617c2a95f995076a9724e,bp/add-volume-checks," def can_attach(self, volume_id): """"""Check to see if a volume can be attached. :param volume_id: The ID of the volume to get. """""" resp, body = self._action('os-can-attach', volume_id) return body[""can_attach""] def is_attached(self, volume_id, instance_uuid=None): """"""Check to see if a volume is attached. :param volume_id: The ID of the volume to get. :param instance_uuid: uuid of an instance """""" resp, body = self._action('os-is-attached', volume_id, {'instance_uuid': instance_uuid}) return body[""is_attached""] def can_detach(self, volume_id): """"""Check to see if a volume can be detached. :param volume_id: The ID of the volume to get. """""" resp, body = self._action('os-can-detach', volume_id) return body[""can_detach""] ",,58,0
openstack%2Fproject-config~master~I2820f1403cfd34390320f5841786f4065d0e4cf0,openstack/project-config,master,I2820f1403cfd34390320f5841786f4065d0e4cf0,Add VMware-NSX to StackForge,MERGED,2014-12-09 17:13:18.000000000,2014-12-18 18:24:02.000000000,2014-12-18 18:24:01.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 1106}, {'_account_id': 1653}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 7192}, {'_account_id': 11610}, {'_account_id': 12100}]","[{'number': 1, 'created': '2014-12-09 17:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/00b419f57462866901c2429047768e5587905d3a', 'message': 'Add VMware-NSX to StackForge\n\nThis repository will hold the Neutron drivers for the\nVMware NSX. This is required by [1].\n\nThe need of setting this repo up is inline with\nspec proposal [2], where core elements of the Neutron\nproject are decoupled by the internals of the\ntechnology being supported.\n\n[1] https://review.openstack.org/#/c/102720/\n[2] https://review.openstack.org/#/c/134680/\n\nChange-Id: I2820f1403cfd34390320f5841786f4065d0e4cf0\n'}, {'number': 2, 'created': '2014-12-16 12:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/eed840d7b6c48205222d62a9a7a1bbcff9956759', 'message': 'Add VMware-NSX to StackForge\n\nThis repository will hold the Neutron drivers for the\nVMware NSX. This is required by [1].\n\nThe need of setting this repo up is inline with\nspec proposal [2], where core elements of the Neutron\nproject are decoupled by the internals of the\ntechnology being supported.\n\n[1] https://review.openstack.org/#/c/102720/\n[2] https://review.openstack.org/#/c/134680/\n\nChange-Id: I2820f1403cfd34390320f5841786f4065d0e4cf0\n'}, {'number': 3, 'created': '2014-12-16 12:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ce8adedee4c4510f9693559c1475b636f28d948b', 'message': 'Add VMware-NSX to StackForge\n\nThis repository will hold the Neutron drivers for the\nVMware NSX. This is required by [1].\n\nThe need of setting this repo up is inline with\nspec proposal [2], where core elements of the Neutron\nproject are decoupled by the internals of the\ntechnology being supported.\n\n[1] https://review.openstack.org/#/c/102720/\n[2] https://review.openstack.org/#/c/134680/\n\nChange-Id: I2820f1403cfd34390320f5841786f4065d0e4cf0\n'}, {'number': 4, 'created': '2014-12-17 11:13:52.000000000', 'files': ['jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'gerrit/acls/stackforge/vmware-nsx.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/461bde74cb1a17fc32cca6c8b36db817a48ee3a6', 'message': 'Add VMware-NSX to StackForge\n\nThis repository will hold the Neutron drivers for the\nVMware NSX. This is required by [1].\n\nThe need of setting this repo up is inline with\nspec proposal [2], where core elements of the Neutron\nproject are decoupled by the internals of the\ntechnology being supported.\n\n[1] https://review.openstack.org/#/c/102720/\n[2] https://review.openstack.org/#/c/134680/\n\nChange-Id: I2820f1403cfd34390320f5841786f4065d0e4cf0\n'}]",3,140409,461bde74cb1a17fc32cca6c8b36db817a48ee3a6,49,11,4,1653,,,0,"Add VMware-NSX to StackForge

This repository will hold the Neutron drivers for the
VMware NSX. This is required by [1].

The need of setting this repo up is inline with
spec proposal [2], where core elements of the Neutron
project are decoupled by the internals of the
technology being supported.

[1] https://review.openstack.org/#/c/102720/
[2] https://review.openstack.org/#/c/134680/

Change-Id: I2820f1403cfd34390320f5841786f4065d0e4cf0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/09/140409/4 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'gerrit/acls/stackforge/vmware-nsx.config']",4,00b419f57462866901c2429047768e5587905d3a,vmware-nsx,"[access ""refs/heads/*""] abandon = group vmware-nsx-core label-Code-Review = -2..+2 group vmware-nsx-core label-Workflow = -1..+1 group vmware-nsx-core [access ""refs/tags/*""] pushSignedTag = group vmware-nsx-release [receive] requireChangeId = true requireContributorAgreement = true [submit] mergeContent = true ",,29,0
openstack%2Fneutron-specs~master~I5074548d4d18f5086bb2114597278a456f9dc3ea,openstack/neutron-specs,master,I5074548d4d18f5086bb2114597278a456f9dc3ea,Allow more flexible connection to external network,ABANDONED,2014-04-18 16:22:42.000000000,2014-12-18 18:16:16.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 841}, {'_account_id': 1689}, {'_account_id': 2592}, {'_account_id': 2888}, {'_account_id': 6854}, {'_account_id': 7141}, {'_account_id': 7183}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8172}, {'_account_id': 8279}, {'_account_id': 9060}, {'_account_id': 9911}, {'_account_id': 11367}, {'_account_id': 11685}, {'_account_id': 11731}, {'_account_id': 12051}, {'_account_id': 13702}]","[{'number': 1, 'created': '2014-04-18 16:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/1430c6b008d178a2b4c32342aed62040cff0ab01', 'message': 'Allow more flexible connection to external network\n\nThis feature will add an interface and driver mechanism to make\nplugging in to an external network more flexible.  This will enable\nsolving problems with scalability and public IP address waste.\n\nbp pluggable-ext-net\n\nChange-Id: I5074548d4d18f5086bb2114597278a456f9dc3ea\n'}, {'number': 2, 'created': '2014-04-22 18:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4144442a1d29c36a036ff9b8a9f1ed9d4ba5c2dd', 'message': 'Allow more flexible connection to external network\n\nThis feature will add an interface and driver mechanism to make\nplugging in to an external network more flexible.  This will enable\nsolving problems with scalability and public IP address waste.\n\nbp pluggable-ext-net\n\nChange-Id: I5074548d4d18f5086bb2114597278a456f9dc3ea\n'}, {'number': 3, 'created': '2014-04-22 18:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/67131bf446691564fe1a08b28353d332022cc184', 'message': 'Allow more flexible connection to external network\n\nThis feature will add an interface and driver mechanism to make\nplugging in to an external network more flexible.  This will enable\nsolving problems with scalability and public IP address waste.\n\nbp pluggable-ext-net\n\nChange-Id: I5074548d4d18f5086bb2114597278a456f9dc3ea\n'}, {'number': 4, 'created': '2014-05-05 19:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2c01e51140ea5b4577f3ac9ea7328eec2f751732', 'message': 'Allow more flexible connection to external network\n\nThis feature will add an interface and driver mechanism to make\nplugging in to an external network more flexible.  This will enable\nsolving problems with scalability and public IP address waste.\n\nbp pluggable-ext-net\n\nChange-Id: I5074548d4d18f5086bb2114597278a456f9dc3ea\n'}, {'number': 5, 'created': '2014-05-15 03:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/fc82ab460fad805f66bc1e0af5ae029e53f45158', 'message': 'Allow more flexible connection to external network\n\nThis feature will add an interface and driver mechanism to make\nplugging in to an external network more flexible.  This will enable\nsolving problems with scalability and public IP address waste.\n\nbp pluggable-ext-net\n\nChange-Id: I5074548d4d18f5086bb2114597278a456f9dc3ea\n'}, {'number': 6, 'created': '2014-10-15 11:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e10aad838c9b4fa3f436b44aeed56ae7750e65da', 'message': 'Allow more flexible connection to external network\n\nThis feature will add an interface and driver mechanism to make\nplugging in to an external network more flexible.  This will enable\nsolving problems with scalability and public IP address waste.\n\nbp pluggable-ext-net\n\nChange-Id: I5074548d4d18f5086bb2114597278a456f9dc3ea\n'}, {'number': 7, 'created': '2014-11-18 22:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3aa537f045c7707e41777b832f8390875caf2754', 'message': 'Allow more flexible connection to external network\n\nThis feature will add an interface and driver mechanism to make\nplugging in to an external network more flexible.  This will enable\nsolving problems with scalability and public IP address waste.\n\nbp pluggable-ext-net\n\nChange-Id: I5074548d4d18f5086bb2114597278a456f9dc3ea\n'}, {'number': 8, 'created': '2014-12-03 19:52:53.000000000', 'files': ['specs/kilo/pluggable-ext-net.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0523051f62247b64c2e5508f725961ef3cee2deb', 'message': 'Allow more flexible connection to external network\n\nThis feature will add an interface and driver mechanism to make\nplugging in to an external network more flexible.  This will enable\nsolving problems with scalability and public IP address waste.\n\nbp pluggable-ext-net\n\nChange-Id: I5074548d4d18f5086bb2114597278a456f9dc3ea\n'}]",109,88619,0523051f62247b64c2e5508f725961ef3cee2deb,60,22,8,7448,,,0,"Allow more flexible connection to external network

This feature will add an interface and driver mechanism to make
plugging in to an external network more flexible.  This will enable
solving problems with scalability and public IP address waste.

bp pluggable-ext-net

Change-Id: I5074548d4d18f5086bb2114597278a456f9dc3ea
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/19/88619/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/pluggable-ext-net.rst'],1,1430c6b008d178a2b4c32342aed62040cff0ab01,bp/pluggable-ext-net,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================== Pluggable External Net ====================== https://blueprints.launchpad.net/neutron/+spec/pluggable-ext-net :Author: Carl Baldwin <carl.baldwin@hp.com> :Copyright: 2014 Hewlett-Packard Development Company, L.P. Plugging a router external gateway to an external network in the L3 agent can only be done in one way. It was designed to operate on a single L2 network with little configuration on the upstream router. But, it has some weaknesses. This blueprint will add a driver interface so that other implementations can be written to overcome its weaknesses. Problem description =================== In Neutron, an external network is hosted on a single L2 network. Routers connect directly and use arping to announce their ips. This could limit the scalability or flexibility of the external network. For example, floating ips are not free to float between L2 networks. Another weakness is that each Neutron router consumes a public IP address that is dedicated to it in addition to any floating ips it hosts. The DVR [#]_ blueprint adds an additional requirement of an extra namespace on each compute host in the datapath. This namespace consumes an extra public IP address for each compute host in the cloud. No traffic should ever be sourced using this IP and so these IP addresses are essentially wasted. .. [#] https://blueprints.launchpad.net/neutron/+spec/neutron-ovs-dvr Proposed change =============== Overview -------- This blueprint is to abstract the concept of plugging in to an external network to allow for more flexibility. #. Reduce or eliminate unnecessary public IP address consumption for infrastructure. #. Allow public IP pools to span L2 networks in some scenarios. #. Allow other forms of address advertisement. .. TODO These are likely to be done before this blueprint #. Use multiple arbitrary IP subnets on the external network [#]_. #. Allow the use of a provider network as an external network [#]_. .. [#] https://bugs.launchpad.net/neutron/+bug/1212947 .. [#] https://bugs.launchpad.net/neutron/+bug/1056437 .. TODO https://blueprints.launchpad.net/fuel/+spec/separate-public-floating What is an External Network? ____________________________ To abstract the concept of plugging in to an external network it is important to understand what it is used for in an OpenStack cloud. Plugging in to an external network is all about getting connectivity outside of the cloud at L3 and above. That an external network's subnet sits on top of a single L2 network is really just an implementation detail. An external network ... #. Provides a gateway for traffic to escape the cloud. #. Hosts one or more ""public"" IP address pools by which compute instances can be reached. #. Announces addresses externally (e.g. arping) .. This was work that I thought would need a blueprint to do. However, I played around with it and discovered that the current L3 can *almost* do it. I think I'd like to do this as a bug instead of in the blueprint Multiple Subnets ---------------- One important capability that this blueprint will add is the ability for a single external network to host more than one subnet and more than one floating ip pool on each subnet. This enables the full flexibility of the Neutron model for networks, subnets, and allocation pools for external networks. .. TODO neutron subnet-create ext-net XX.YY.ZZ.0/24 --disable-dhcp Works but I'm not sure where things break down. I was able to create a floating ip on this second subnet and even associate the floating ip with an instance. I watched the floating ip address get added to the qg interface. I did not expect this to work. The floating IP is useable from inside the router namespace. The floating IP appeared to work all the way through once I added a route to the default namespace in devstack: sudo ip addr add 10.224.24.1/24 dev br-ex I did some tcpdumps. Saw this in both router and default namespaces. 19:06:13.375330 ARP, Request who-has 10.224.24.2 tell 172.24.4.1, length 28 19:06:13.375340 ARP, Reply 10.224.24.2 is-at fa:16:3e:f9:c3:f9 (oui Unknown), length 28 The question is what happens with traffic to another FIP on the subnet where the router would send it to the upstream router because it doesn't have an on-link route. I tried this out and found that Eliminating the Need for a Dedicated Router IP ______________________________________________ Currently in Neutron, each router gets a primary address on the public network. This address is currently needed for a number of purposes. The router's dedicated primary public IP ... #. provides a Default SNAT address for instances without a floating IP. - For DVR, this is only needed on the central component. Not the IRs. - It can be turned off router-by-router. - There may be alternatives to default SNAT that have not yet been considered. #. serves as the `Router Primary Address`_ for the router gateway port on the subnet. #. allows DNS queries passed through from the dnsmasq instance running in the DHCP namespace to access an Internet accessible upstream DNS server.. - DNS passthrough could be configured to use an address on a private subnet. A DNS service needs to be configured that will listen on the `Private Subnet`_. #. allows for troubleshooting (e.g. sending pings to and from the router namespaces.) - This could be done using a `Private Subnet`_. The goal is to avoid allocating a dedicated IP to the router if it isn't absolutely necessary. This will save IP space where there is a crunch. Eliminating the public IP address entirely may require more work that is out of the scope of this blueprint. Router Primary Address ~~~~~~~~~~~~~~~~~~~~~~ This section describes a technique to eliminate the waste of public addresses as primary interface addresses. In Linux, when an interface has multiple addresses on the same subnet, one becomes the primary address and the others secondary. An interesting thing to note is that when the primary address is removed, all of the secondary addresses are removed with it [#]_. .. [#] The sysctl setting net.ipv4.conf.*.promote_secondaries overrides this behavior. A common practice is to allocate a primary address to the interface using a /NN subnet prefix (e.g. /21) and then add floating or virtual IPs as secondary IP addresses using the same prefix. The primary address is treated as permanent. Another similar practice is to add extra addresses using /32 after adding the primary. Neutron does this. In this scenario, the primary address is needed for two reasons. .. There is some code in the L3 agent that uses this fact to distinguish floating IPs by the /32 prefix. #. It generates a corresponding on-link route for the subnet. #. It is used as the source address for traffic originating from the host. An on-link route can be added without an address:: ip route add 10.1.1.0/24 dev eth0 scope link To provide a default source address, only one subnet (**primary**) on the network needs an address. If the router itself does not source traffic to the Internet, this primary subnet can be a private non-routable subnet. All other subnets (**secondary**) can be added using on-link routes. Floating IPs can be added and used as they are today. This technique brings the flexibility to operate a router without a dedicated public primary address. Private Subnet ~~~~~~~~~~~~~~ To serve some of these needs, a private non-routable subnet can be used as the primary subnet. Care should be taken to avoid creating a security problem by introducing this new subnet. #. It must not open up access to any under-cloud resources. #. It must not inadvertently allow routing or NAT to the Internet. #. It must not open up access to other routers owned by other tenants. This subnet could be used to intentionally allow compute instances access to some infrastructure resources even where it does not have an associated public IP address or default public SNAT is not enabled. For example, it could provide ... #. A DNS service accessible by compute instances. #. A HTTP proxy to the Internet as an alternative to default SNAT. #. Repository mirrors for guest operating systems. #. License Servers that should be accessible by compute instances. Default SNAT ~~~~~~~~~~~~ Default SNAT is currently dependent on the assumption that a `Router Primary Address`_ is allocated from the public IP space. It piggy-backs off of that and uses it as its source address. This blueprint changes that assumption. It particular, it will allow the flexibility to avoid allocating a public IP address for a router if not needed. The code around default SNAT will need to change to operate given the new rules. If it is enabled on a router, then a check will need to be performed to see if a (not-floating) public IP is already available for use. If not, it will take action to allocate one. Driver Interface ________________ A new driver interface needs to be added to the L3 agent and integrate with the code. This new interface will support the following operations. A reference implementation will be developed along with the interface to preserve the current behavior of the code. ======================= ========================================== Call Inputs ======================= ========================================== Host Setup network, subnets, driver_config Host Teardown network, subnets, driver_config Plug External Gateway network, subnets, gw_port, driver_config Unplug External Gateway network, subnets, gw_port, driver_config Connect Floating IP network, subnets, gw_port, driver_config Disconnect Floating IP network, subnets, gw_port, driver_config ======================= ========================================== Implementations should take care to only make changes when necessary. For example, if the agent gets restarted, the implementation should efficiently detect whether things are already in the right state and do nothing in that case. It would be unacceptable to tear down the connection and rebuild it on an agent restart or to remove a floating ip and add it back if it was already operational. These operations cause disruption in service. Host Setup/Teardown ~~~~~~~~~~~~~~~~~~~ Each driver will implement a call to setup a connection to an external network on the host when the network is associated with an agent. Also, a corresponding call to tear it down. The following are possible actions performed as part of this step. #. Create or ensure the existence of a bridge or other network plumbing. #. Create a namespace for the external network if one is required. #. Make calls to RPC to allocate addresses if needed. Plug/Unplug External Gateway ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This is called to plug or unplug a router in to an external network when the router's external gateway is set or cleared. There needs to be an API server component to this. The driver may determine how to allocate L2 and L3 addresses for the gateway on the API side. Connect/Disconnect Floating IP ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Called to associate a floating IP with a given gateway port. This does not include setting up the DNAT and SNAT rules to associate the floating IP with an internal port. That will remain outside the driver for now. Implementations _______________ =================== =========== ================= ============ ================= _ `Direct`_ `Direct Private`_ `Routed`_ `Routed Private`_ =================== =========== ================= ============ ================= Extra Address Per Router/Host None Compute Host None Announcement arp arp proxyarp proxyarp Private Subnet None Yes None Yes Extra Router Config None Private Subnet None Private Subnet ... =================== =========== ================= ============ ================= The following implementations may not all be completed as part of this blueprint. They will be implemented as needed. There are other possible implementations which are not discussed here. Direct ~~~~~~ This will be the initial reference implementation. It works exactly the same way as external networks work today in Neutron. It will be the default for the basic (non-DVR) router and will require no difference in configuration from today. Upgrading a working external network to this model will be seamlessly done with a code update. Given this implementation, an easy derivative implementation could be easily created to experiment with using a macvtap to connect to the network rather than a veth pair. Direct Private ~~~~~~~~~~~~~~ This implementation will build from the `Direct`_ implementation. It uses a private subnet on link that will not be visible to tenants through the API. The notable difference is that this implementation does not require a public IP address dedicated to the router. ================= ================================= Driver specific configuration --------------------------------------------------- Field Description ================= ================================= cidr The private subnet address space. gateway The router's gateway address. allocations_pools ================= ================================= In order to use Neutron's IPAM capabilities for the allocation of IPs on the private subnet, it will be necessary to create a subnet linked to the network that is only available to the driver. This subnet should be created in a way that it will be unavailable when allocating ports or floating ips on the network. How to do this is an open question. Requires the configuration of an extra private subnet with gateway on the upstream router. Replaces `Direct`_ and `Routed`_ for all DVR and non-DVR router components. If a Neutron router is connected directly to both the tenant's internal networks and a private non-routable external subnet then there is a potential address space conflict. The solution to this problem is to make use of the ""Shared Address Space"" allocated by IANA in 2012 for applications like carrier grade NAT [#]_. Using this space will guarantee no conflict with tenant networks. .. [#] http://tools.ietf.org/html/rfc6598 .. Shared Address Space is distinct from RFC 1918 private address space because it is intended for use on Service Provider networks. Routed ~~~~~~ The `Direct`_ implementation presented a problem for the DVR blueprint because each IR would need to have its own address. This would have meant consuming one address for every router/host combination. That would be unacceptable. To solve this, a slightly different method for connecting each IR to the external net was devised. This method adds a new namespace on each compute host to route floating IP traffic to Neutron routers. The namespace is configured with proxyarp for the IPs it hosts. It consumes a single extra IP address from the public IP pool for each compute host to use as the primary address on the public interface. This will be the default connection for each DVR IR component. Upgrading a DVR IR to this model will be seamless and not require any extra configuration. If DVR has not been released and is not in wide use by the time this blueprint is implemented then it may not be necessary to implement this at all. Routed Private ~~~~~~~~~~~~~~ This method is to `Routed`_ as `Direct Private`_ is to `Direct`_. It uses a private primary subnet to avoid the need to allocate public IP addresses for compute hosts. It adds an extra namespace per host for routing and proxyarp in the same manner. The driver specific configuration is the same as for `Direct Private`_. IPs will be allocated from the private subnet in the same way as in `Direct Private`_ Requires the configuration of an extra private subnet with gateway on the upstream router. Replaces `Routed`_ for all DVR IR components. Dynamic Routed ~~~~~~~~~~~~~~ This blueprint allows the flexibility to implement a driver that uses dynamic routing on the external network to announce public IP addresses. The implementation is out of this scope. Alternatives ------------ I haven't thought of any yet. Data model impact ----------------- The database will need to store a driver association for each network/host. This association will need to carry some configuration specific to the driver. =========== ======================== Table: **external_network_driver** ------------------------------------ Column Description =========== ======================== network_id External Network Id host_id Host ID driver The driver class to use config Driver specific config =========== ======================== There are a few reasons to include the host_id instead of just the network. A row with null for host_id can be used as the default driver configuration. #. With the initial DVR implementation, IRs are connected using the `Routed`_ model but the central component of a DVR router may be connected using a `Direct`_ connection. #. Different hosts can be connected to different L2 networks. #. This will allow for controlled migrations where a new plugin can be tested on a small subset of hosts before being rolled out to the rest. Rolling Upgrades ________________ During a rolling transition to a new implementation, there will be some Neutron Network and Compute hosts that still use the old implementation and some that have the new. Even inside of a single host it will take the L3 agent some time to iterate through the routers and rewire them. Each implementation should work out a method to transition seamlessly from at least the `Direct`_ implementation so that routers can connect to the same external network using either implementation during the transation and still maintain connectivity.A brief interruption in network connectivity through the router may be tolerable for each router. It should not be long enough that TCP connections through the router will be interrupted. If DVR is in wide use before this is implemented, implementations should do the same from `Routed`_. REST API impact --------------- The API will be extended to allow configuring the driver for ""router:external"" networks for given hosts. Needs driver specific parameters. If the extension is not used, a default driver will be used to mimic today's behavior. This section is a work-in-progress. .. TODO What extensions are there that I can look at. router:external Notifications impact -------------------- The name of the driver and a configuration dictionary will be returned with the router data when the L3 agent requests them. I'm not certain if this constitutes an RPC version change or not. This will be investigated. :: ************************************************************************ ************************************************************************ ************************************************************************ ************************************************************************ ************************************************************************ ************************************************************************ ************************************************************************ ************************************************************************ Security impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? * Does this change involve cryptography or hashing? * Does this change require the use of sudo or any elevated privileges? * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. For more detailed guidance, please see the OpenStack Security Guidelines as a reference (https://wiki.openstack.org/wiki/Security/Guidelines). These guidelines are a work in progress and are designed to help you identify security best practices. For further information, feel free to reach out to the OpenStack Security Group at openstack-security@lists.openstack.org. Other end user impact --------------------- Aside from the API, are there other ways a user will interact with this feature? * Does this change have an impact on python-neutronclient? What does the user interface there look like? Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A periodic task might look like a small addition but if it calls conductor or another service the load is multiplied by the number of nodes in the system. * A small change in a utility function or a commonly used decorator can have a large impacts on performance. * Calls which result in a database queries (whether direct or via conductor) can have a profound impact on performance when called in critical sections of the code. * Will the change include any locking, and if so what considerations are there on holding the lock? Other deployer impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * If this change is a new binary, how would it be deployed? * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? Developer impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the API, discussion of how other plugins would implement the feature is required. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in neutron, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Neutron (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Testing ======= Please discuss how the change will be tested. We especially want to know what tempest tests will be added. It is assumed that unit test coverage will be added so that doesn't need to be mentioned explicitly, but discussion of why you think unit tests are sufficient and we don't need to add more tempest tests would need to be included. Is this untestable in gate given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc). Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. link any vendor documentation) * Anything else you feel it is worthwhile to refer to ",,650,0
openstack%2Ftempest~master~I11e8fe80c35a1d3a90a4d7c8bf2b36c4114b5cc6,openstack/tempest,master,I11e8fe80c35a1d3a90a4d7c8bf2b36c4114b5cc6,Fix slowest test output after test run,MERGED,2014-12-06 00:07:54.000000000,2014-12-18 18:06:44.000000000,2014-12-18 18:06:44.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7244}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-06 00:07:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f8a9a055329e9c64f57294197d26fbe06380333a', 'message': ""Fix slowest test output after test run\n\nThis commit fixes the output from pretty_tox.sh so that the testr\nslowest output isn't gobbled up by the pipe into subunit-trace.\n\nChange-Id: I11e8fe80c35a1d3a90a4d7c8bf2b36c4114b5cc6\n""}, {'number': 2, 'created': '2014-12-06 01:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d2df08fb857ed0c38919c1f987469ffca0c25337', 'message': ""Fix slowest test output after test run\n\nThis commit fixes the output from pretty_tox.sh so that the testr\nslowest output isn't gobbled up by the pipe into subunit-trace.\n\nChange-Id: I11e8fe80c35a1d3a90a4d7c8bf2b36c4114b5cc6\n""}, {'number': 3, 'created': '2014-12-12 16:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d24c71c030bab197a5b7dd0237b55ccd8fe12480', 'message': ""Fix slowest test output after test run\n\nThis commit fixes the output from pretty_tox.sh so that the testr\nslowest output isn't gobbled up by the pipe into subunit-trace.\n\nChange-Id: I11e8fe80c35a1d3a90a4d7c8bf2b36c4114b5cc6\n""}, {'number': 4, 'created': '2014-12-18 15:14:39.000000000', 'files': ['tools/pretty_tox.sh'], 'web_link': 'https://opendev.org/openstack/tempest/commit/16b6826b9474cfa065a3ce24b22ee3a363716d21', 'message': ""Fix slowest test output after test run\n\nThis commit fixes the output from pretty_tox.sh so that the testr\nslowest output isn't gobbled up by the pipe into subunit-trace.\n\nChange-Id: I11e8fe80c35a1d3a90a4d7c8bf2b36c4114b5cc6\n""}]",0,139765,16b6826b9474cfa065a3ce24b22ee3a363716d21,23,6,4,5196,,,0,"Fix slowest test output after test run

This commit fixes the output from pretty_tox.sh so that the testr
slowest output isn't gobbled up by the pipe into subunit-trace.

Change-Id: I11e8fe80c35a1d3a90a4d7c8bf2b36c4114b5cc6
",git fetch https://review.opendev.org/openstack/tempest refs/changes/65/139765/4 && git format-patch -1 --stdout FETCH_HEAD,['tools/pretty_tox.sh'],1,f8a9a055329e9c64f57294197d26fbe06380333a,139765,"python setup.py testr --testr-args=""--subunit $TESTRARGS"" | subunit-trace --no-failure-debug -f retval=$? # NOTE(mtreinish) The pipe would eat the slowest display from pbr's testr # wrapper so just manually print the slowest tests. testr slowest exit $retval","python setup.py testr --slowest --testr-args=""--subunit $TESTRARGS"" | subunit-trace --no-failure-debug -f",6,1
openstack%2Fnova~master~Ifde89b209f2fcc2283894195b1e7e866cf28dccb,openstack/nova,master,Ifde89b209f2fcc2283894195b1e7e866cf28dccb,Add pci_stats to the compute_node object,ABANDONED,2014-07-30 17:58:21.000000000,2014-12-18 18:03:10.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 4573}, {'_account_id': 5170}, {'_account_id': 6681}, {'_account_id': 7461}, {'_account_id': 7543}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-30 17:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/194603edf2f2c2677ad4595fa549e69ac0938eda', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 2, 'created': '2014-07-30 17:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3f48e1c5be3e20fa6f3448c20ca40119c6e34f4', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 3, 'created': '2014-07-30 20:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85cb1d79b15883418b3a2377028856d46e658d27', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 4, 'created': '2014-07-30 20:20:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f59f353610aa0c9f479f5adc005cde091af513c8', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 5, 'created': '2014-08-07 18:43:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7315560214dada01f7e7bd5c2307a7bce49bcbc', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 6, 'created': '2014-08-07 20:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9338c040e02d87d70f92cfe7bb7c016a74b47b0', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 7, 'created': '2014-08-07 20:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/680b311fd068346e94b80adbeab31f01b178e8cb', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 8, 'created': '2014-08-19 17:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/425bc8d2cb45fddfcd3fc0247164c5300e6b1469', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 9, 'created': '2014-08-26 17:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/483edf3b3d956441a20edfce101eb40e3ed756e1', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 10, 'created': '2014-08-27 20:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2446b4884dd65e8af50d9008bf0d79f33a5d7e25', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 11, 'created': '2014-08-27 21:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b499154a850eb99c7cfbb441f74790160a4c204', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 12, 'created': '2014-08-28 18:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4e7a25245ef43da5c801c20d3627aaceef9ac68', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field is list\nof dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}, {'number': 13, 'created': '2014-11-06 22:29:41.000000000', 'files': ['nova/tests/pci/test_device.py', 'nova/tests/objects/test_compute_node.py', 'nova/objects/compute_node.py', 'nova/objects/service.py', 'nova/tests/objects/test_objects.py', 'nova/tests/objects/test_service.py', 'nova/tests/compute/test_compute.py', 'nova/tests/compute/test_multiple_nodes.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6a3c513eebbfa0130209889d6d127c917eda85d2', 'message': 'Add pci_stats to the compute_node object\n\nChange compute node object to include pci_stats. The pci_stats field\nis list of dicts, the value in the dict item is a string.\n\nImplements: blueprint make-resource-tracker-use-objects\n\nChange-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n'}]",0,110739,6a3c513eebbfa0130209889d6d127c917eda85d2,82,14,13,4573,,,0,"Add pci_stats to the compute_node object

Change compute node object to include pci_stats. The pci_stats field
is list of dicts, the value in the dict item is a string.

Implements: blueprint make-resource-tracker-use-objects

Change-Id: Ifde89b209f2fcc2283894195b1e7e866cf28dccb
",git fetch https://review.opendev.org/openstack/nova refs/changes/39/110739/13 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/compute_node.py', 'nova/tests/objects/test_compute_node.py', 'nova/tests/objects/test_objects.py', 'nova/tests/objects/test_service.py', 'nova/tests/compute/test_compute.py', 'nova/tests/compute/test_multiple_nodes.py']",6,194603edf2f2c2677ad4595fa549e69ac0938eda,bp/make-resource-tracker-use-objects," 'pci_stats': '',",,47,23
openstack%2Fhacking~master~I43862a0d73706ee4b28951d5c8de6938c0cf5f27,openstack/hacking,master,I43862a0d73706ee4b28951d5c8de6938c0cf5f27,Remove complex import rules,MERGED,2014-12-17 21:42:32.000000000,2014-12-18 17:57:14.000000000,2014-12-18 17:57:14.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-12-17 21:42:32.000000000', 'files': ['hacking/checks/imports.py', 'hacking/tests/checks/test_imports.py', 'setup.cfg', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/hacking/commit/8f1fcbdb9aa4fc61349e5e879153c722195b1233', 'message': 'Remove complex import rules\n\nPer the discussion in [1], we are removing the import rules that\nrequire introspection of the actual imported code due to the\ncomplex and error-prone nature of those checks, and the fact that\nsome of them are simply impossible to implement sanely.\n\nChecks that operate solely on the text of the import are left\nalone because they should be less problematic.\n\n[1]: http://lists.openstack.org/pipermail/openstack-dev/2014-December/052519.html\n\nChange-Id: I43862a0d73706ee4b28951d5c8de6938c0cf5f27\n'}]",1,142586,8f1fcbdb9aa4fc61349e5e879153c722195b1233,11,4,1,6928,,,0,"Remove complex import rules

Per the discussion in [1], we are removing the import rules that
require introspection of the actual imported code due to the
complex and error-prone nature of those checks, and the fact that
some of them are simply impossible to implement sanely.

Checks that operate solely on the text of the import are left
alone because they should be less problematic.

[1]: http://lists.openstack.org/pipermail/openstack-dev/2014-December/052519.html

Change-Id: I43862a0d73706ee4b28951d5c8de6938c0cf5f27
",git fetch https://review.opendev.org/openstack/hacking refs/changes/86/142586/1 && git format-patch -1 --stdout FETCH_HEAD,"['hacking/checks/imports.py', 'hacking/tests/checks/test_imports.py', 'setup.cfg', 'HACKING.rst']",4,8f1fcbdb9aa4fc61349e5e879153c722195b1233,remove-checks,"- Do not import objects, only modules (*)- [H306] Order your imports by the full module path - Organize your imports according to the `Import order","- [H302] Do not import objects, only modules (*)- Order your imports by the full module path - [H305 H306 H307] Organize your imports according to the `Import order",6,637
openstack%2Fhacking~master~I601bb2eca0288f85597d3070abb855078eb1f29c,openstack/hacking,master,I601bb2eca0288f85597d3070abb855078eb1f29c,Remove Git commit message checks,MERGED,2014-12-17 21:42:32.000000000,2014-12-18 17:53:53.000000000,2014-12-18 17:53:53.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 6928}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-12-17 21:42:32.000000000', 'files': ['hacking/checks/git.py', 'setup.cfg', 'hacking/tests/test_gittest.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/hacking/commit/45586b65b0b91262f8ad6ecbfac1420d73bfd52d', 'message': ""Remove Git commit message checks\n\nPer the discussion in [1], we are removing the git commit message\nhacking checks.  These cause issues with things like Gerrit reverts\nand aren't that important to rigidly enforce.\n\n[1]: http://lists.openstack.org/pipermail/openstack-dev/2014-December/052519.html\n\nChange-Id: I601bb2eca0288f85597d3070abb855078eb1f29c\n""}]",0,142585,45586b65b0b91262f8ad6ecbfac1420d73bfd52d,11,5,1,6928,,,0,"Remove Git commit message checks

Per the discussion in [1], we are removing the git commit message
hacking checks.  These cause issues with things like Gerrit reverts
and aren't that important to rigidly enforce.

[1]: http://lists.openstack.org/pipermail/openstack-dev/2014-December/052519.html

Change-Id: I601bb2eca0288f85597d3070abb855078eb1f29c
",git fetch https://review.opendev.org/openstack/hacking refs/changes/85/142585/1 && git format-patch -1 --stdout FETCH_HEAD,"['hacking/checks/git.py', 'setup.cfg', 'hacking/tests/test_gittest.py', 'HACKING.rst']",4,45586b65b0b91262f8ad6ecbfac1420d73bfd52d,remove-checks,readable.,"readable. Follow these guidelines: - [H802] First, provide a brief summary of 50 characters or less. Summaries of greater then 72 characters will be rejected by the gate. - [H801] The first line of the commit message should provide an accurate description of the change, not just a reference to a bug or blueprint.",1,144
openstack%2Fmurano-apps~master~I76c0ce82404862ceeacd0d2539c04ba206ac4483,openstack/murano-apps,master,I76c0ce82404862ceeacd0d2539c04ba206ac4483,Add PostgreSQL database,MERGED,2014-12-10 00:32:35.000000000,2014-12-18 17:49:56.000000000,2014-12-18 17:49:56.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-12-10 00:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/a3c6f7f5444b2f8217d409b9d7f7d16906384bfb', 'message': 'Add PostgreSQL database\n\nChange-Id: I76c0ce82404862ceeacd0d2539c04ba206ac4483\n'}, {'number': 2, 'created': '2014-12-18 17:39:35.000000000', 'files': ['io.murano.databases.PostgreSql/Resources/scripts/deployPostgreSql.sh', 'io.murano.databases.PostgreSql/Resources/AssignUserPostgreSql.template', 'io.murano.databases.PostgreSql/Resources/scripts/createPostgreSqlUser.sh', 'io.murano.databases.PostgreSql/Resources/DeployPostgreSql.template', 'io.murano.databases.PostgreSql/Resources/scripts/assignPostgreSqlUser.sh', 'io.murano.databases.PostgreSql/logo.png', 'io.murano.databases.PostgreSql/manifest.yaml', 'io.murano.databases.PostgreSql/Resources/CreatePostgreSqlDatabase.template', 'io.murano.databases.PostgreSql/UI/ui.yaml', 'io.murano.databases.PostgreSql/Resources/CreatePostgreSqlUser.template', 'io.murano.databases.PostgreSql/Classes/PostgreSql.yaml', 'io.murano.databases.PostgreSql/Resources/scripts/createPostgreSqlDatabase.sh'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/e03d96b2ab05ed1fce7cbb87b5811e36c9b30a6e', 'message': 'Add PostgreSQL database\n\nChange-Id: I76c0ce82404862ceeacd0d2539c04ba206ac4483\n'}]",0,140538,e03d96b2ab05ed1fce7cbb87b5811e36c9b30a6e,10,3,2,7225,,,0,"Add PostgreSQL database

Change-Id: I76c0ce82404862ceeacd0d2539c04ba206ac4483
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/38/140538/1 && git format-patch -1 --stdout FETCH_HEAD,"['io.murano.databases.PostgreSql/Resources/scripts/deployPostgreSql.sh', 'io.murano.databases.PostgreSql/Resources/AssignUserPostgreSql.template', 'io.murano.databases.PostgreSql/Resources/scripts/createPostgreSqlUser.sh', 'io.murano.databases.PostgreSql/Resources/DeployPostgreSql.template', 'io.murano.databases.PostgreSql/Resources/scripts/assignPostgreSqlUser.sh', 'io.murano.databases.PostgreSql/logo.png', 'io.murano.databases.PostgreSql/manifest.yaml', 'io.murano.databases.PostgreSql/Resources/CreatePostgreSqlDatabase.template', 'io.murano.databases.PostgreSql/UI/ui.yaml', 'io.murano.databases.PostgreSql/Resources/CreatePostgreSqlUser.template', 'io.murano.databases.PostgreSql/Classes/PostgreSql.yaml', 'io.murano.databases.PostgreSql/Resources/scripts/createPostgreSqlDatabase.sh']",12,a3c6f7f5444b2f8217d409b9d7f7d16906384bfb,app/databases.PostgreSql,"#!/bin/bash sudo -u postgres psql -c ""CREATE DATABASE $1"" ",,337,0
openstack%2Fcookbook-openstack-network~master~Idd904f80cd51711db456606298e9761452bed23d,openstack/cookbook-openstack-network,master,Idd904f80cd51711db456606298e9761452bed23d,Renamed common.rb to default.rb,MERGED,2014-12-16 18:51:51.000000000,2014-12-18 17:49:34.000000000,2014-12-18 17:49:33.000000000,"[{'_account_id': 3}, {'_account_id': 11915}, {'_account_id': 12323}, {'_account_id': 12588}, {'_account_id': 13252}]","[{'number': 1, 'created': '2014-12-16 18:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/1d241419c8cff1a873956feac285f9125121e64e', 'message': 'Renamed common.rb to default.rb\n\nRenamed the common cookbook in an early attempt to simplify the\nrefactor happening here: https://review.openstack.org/#/c/141459/\n\nChange-Id: Idd904f80cd51711db456606298e9761452bed23d\n'}, {'number': 2, 'created': '2014-12-17 13:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/788c0497dde41be30d5e69955991917e89033b95', 'message': 'Renamed common.rb to default.rb\n\nRenamed the common.rb recipe to default.rb in an early attempt\nto simplify the refactor happening here:\nhttps://review.openstack.org/#/c/141459/\n\nChange-Id: Idd904f80cd51711db456606298e9761452bed23d\n'}, {'number': 3, 'created': '2014-12-17 16:47:54.000000000', 'files': ['recipes/cisco.rb', 'recipes/plumgrid.rb', 'recipes/metadata_agent.rb', 'recipes/balancer.rb', 'recipes/dhcp_agent.rb', 'recipes/hyperv.rb', 'recipes/nec.rb', 'recipes/linuxbridge.rb', 'spec/default_spec.rb', 'recipes/openvswitch.rb', 'CHANGELOG.md', 'recipes/metaplugin.rb', 'recipes/bigswitch.rb', 'recipes/server.rb', 'recipes/ryu.rb', 'recipes/midonet.rb', 'recipes/brocade.rb', 'recipes/nicira.rb', 'spec/dhcp_agent_spec.rb', 'recipes/l3_agent.rb', 'spec/default-redhat_spec.rb', 'recipes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/dc2c87d1f96e4dbef4540a343889d493fccd9e0a', 'message': 'Renamed common.rb to default.rb\n\nRenamed the common.rb recipe to default.rb in an early attempt\nto simplify the refactor happening here:\nhttps://review.openstack.org/#/c/141459/\n\nChange-Id: Idd904f80cd51711db456606298e9761452bed23d\n'}]",4,142185,dc2c87d1f96e4dbef4540a343889d493fccd9e0a,19,5,3,12588,,,0,"Renamed common.rb to default.rb

Renamed the common.rb recipe to default.rb in an early attempt
to simplify the refactor happening here:
https://review.openstack.org/#/c/141459/

Change-Id: Idd904f80cd51711db456606298e9761452bed23d
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/85/142185/2 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/cisco.rb', 'recipes/plumgrid.rb', 'recipes/metadata_agent.rb', 'recipes/balancer.rb', 'recipes/dhcp_agent.rb', 'recipes/hyperv.rb', 'recipes/nec.rb', 'recipes/linuxbridge.rb', 'spec/default_spec.rb', 'recipes/openvswitch.rb', 'recipes/metaplugin.rb', 'recipes/bigswitch.rb', 'recipes/server.rb', 'recipes/ryu.rb', 'recipes/midonet.rb', 'recipes/brocade.rb', 'recipes/nicira.rb', 'spec/dhcp_agent_spec.rb', 'recipes/l3_agent.rb', 'spec/default-redhat_spec.rb', 'recipes/default.rb']",21,1d241419c8cff1a873956feac285f9125121e64e,move_common_to_default,# Recipe:: default,# Recipe:: common,21,21
openstack%2Fmurano-apps~master~I3fbe4d1ba9a7368f93c006081227b1a8db917ca5,openstack/murano-apps,master,I3fbe4d1ba9a7368f93c006081227b1a8db917ca5,Add MySQL database application,MERGED,2014-12-10 00:26:30.000000000,2014-12-18 17:48:35.000000000,2014-12-18 17:48:34.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-12-10 00:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/0402a2ff23cabb90b7613bfd395dede159e946ee', 'message': 'Add MySQL database application\n\nChange-Id: I3fbe4d1ba9a7368f93c006081227b1a8db917ca5\n'}, {'number': 2, 'created': '2014-12-18 17:43:05.000000000', 'files': ['io.murano.databases.MySql/manifest.yaml', 'io.murano.databases.MySql/UI/ui.yaml', 'io.murano.databases.MySql/Classes/MySql.yaml', 'io.murano.databases.MySql/Resources/CreateMySqlDatabase.template', 'io.murano.databases.MySql/Resources/scripts/deployMySql.sh', 'io.murano.databases.MySql/logo.png', 'io.murano.databases.MySql/Resources/scripts/createMySqlDatabase.sh', 'io.murano.databases.MySql/Resources/scripts/assignMySqlUser.sh', 'io.murano.databases.MySql/Resources/AssignUserMySql.template', 'io.murano.databases.MySql/Resources/DeployMySql.template', 'io.murano.databases.MySql/Resources/CreateMySqlUser.template', 'io.murano.databases.MySql/Resources/scripts/createMySqlUser.sh'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/5b1405bb650acdc7cf2b07d331de6f9f1caba8c0', 'message': 'Add MySQL database application\n\nChange-Id: I3fbe4d1ba9a7368f93c006081227b1a8db917ca5\n'}]",1,140535,5b1405bb650acdc7cf2b07d331de6f9f1caba8c0,11,3,2,7225,,,0,"Add MySQL database application

Change-Id: I3fbe4d1ba9a7368f93c006081227b1a8db917ca5
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/35/140535/1 && git format-patch -1 --stdout FETCH_HEAD,"['io.murano.databases.MySql/manifest.yaml', 'io.murano.databases.MySql/UI/ui.yaml', 'io.murano.databases.MySql/Classes/MySql.yaml', 'io.murano.databases.MySql/Resources/CreateMySqlDatabase.template', 'io.murano.databases.MySql/Resources/scripts/deployMySql.sh', 'io.murano.databases.MySql/logo.png', 'io.murano.databases.MySql/Resources/scripts/createMySqlDatabase.sh', 'io.murano.databases.MySql/Resources/scripts/assignMySqlUser.sh', 'io.murano.databases.MySql/Resources/AssignUserMySql.template', 'io.murano.databases.MySql/Resources/DeployMySql.template', 'io.murano.databases.MySql/Resources/CreateMySqlUser.template', 'io.murano.databases.MySql/Resources/scripts/createMySqlUser.sh']",12,0402a2ff23cabb90b7613bfd395dede159e946ee,app/databases.MySQL,"#!/bin/bash mysql --user=root --password=root -e ""CREATE USER '$1'@'localhost' IDENTIFIED BY '$2'"" mysql --user=root --password=root -e ""CREATE USER '$1'@'%' IDENTIFIED BY '$2'"" ",,343,0
openstack%2Fmurano-apps~master~I72072dd1056a071b48fb54ba8ff844d21ed86011,openstack/murano-apps,master,I72072dd1056a071b48fb54ba8ff844d21ed86011,Add abstract interface for SQL databases,MERGED,2014-12-10 00:21:45.000000000,2014-12-18 17:48:29.000000000,2014-12-18 17:48:28.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-12-10 00:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/91f761fa2bd6b169907466f2054ab36aba3499d6', 'message': 'Add abstract interface for SQL databases\n\nChange-Id: I72072dd1056a071b48fb54ba8ff844d21ed86011\n'}, {'number': 2, 'created': '2014-12-10 00:23:26.000000000', 'files': ['io.murano.databases.SqlDatabase/Classes/SqlDatabase.yaml', 'io.murano.databases.SqlDatabase/manifest.yaml'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/c6dc79e52d373c32e5fee7600725ed8f1c2a54f9', 'message': 'Add abstract interface for SQL databases\n\nChange-Id: I72072dd1056a071b48fb54ba8ff844d21ed86011\n'}]",0,140534,c6dc79e52d373c32e5fee7600725ed8f1c2a54f9,9,3,2,7225,,,0,"Add abstract interface for SQL databases

Change-Id: I72072dd1056a071b48fb54ba8ff844d21ed86011
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/34/140534/2 && git format-patch -1 --stdout FETCH_HEAD,"['io.murano.databases.SqlDatabase/Classes/SqlDatabase.yaml', 'io.murano.databases.SqlDatabase/manifest.yaml']",2,91f761fa2bd6b169907466f2054ab36aba3499d6,app/databases.SqlDatabase,"Format: 1.0 Type: Library FullName: io.murano.databases Name: SQL Library Description: | This is the interface defining API for different SQL - RDBMS databases Author: 'Mirantis, Inc' Tags: [sql, RDSMS] Classes: io.murano.databases.SqlDatabase: SqlDatabase.yaml ",,46,0
openstack%2Ftooz~master~I49f6bf5b397d6bc5426c074f6196c764c8938d23,openstack/tooz,master,I49f6bf5b397d6bc5426c074f6196c764c8938d23,Add driver autogenerated docs,MERGED,2014-12-09 08:07:06.000000000,2014-12-18 17:48:15.000000000,2014-12-18 17:48:14.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-12-09 08:07:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/125b62b3f44fa75a20a9f8f32c60a981c01c1ba7', 'message': 'Add driver autogenerated docs\n\nStart to add/build a developer oriented doc that\ncan be further refined to explain to developers how\nto use the different tooz drivers (and what the varying\ndrivers capabilities are).\n\nChange-Id: I49f6bf5b397d6bc5426c074f6196c764c8938d23\n'}, {'number': 2, 'created': '2014-12-10 05:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/9e1230e278ffbb2e929ae6698bb560e231ef0cad', 'message': 'Add driver autogenerated docs\n\nStart to add/build a developer oriented doc that\ncan be further refined to explain to developers how\nto use the different tooz drivers (and what the varying\ndrivers capabilities are).\n\nChange-Id: I49f6bf5b397d6bc5426c074f6196c764c8938d23\n'}, {'number': 3, 'created': '2014-12-10 05:25:34.000000000', 'files': ['tooz/drivers/mysql.py', 'doc/source/developers.rst', 'doc/source/index.rst', 'tooz/drivers/ipc.py', 'doc/source/conf.py', 'tooz/drivers/pgsql.py', 'tooz/drivers/memcached.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/836fec02da5af5d53ac1852720d3a10cbfff59d2', 'message': 'Add driver autogenerated docs\n\nStart to add/build a developer oriented doc that\ncan be further refined to explain to developers how\nto use the different tooz drivers (and what the varying\ndrivers capabilities are).\n\nChange-Id: I49f6bf5b397d6bc5426c074f6196c764c8938d23\n'}]",3,140263,836fec02da5af5d53ac1852720d3a10cbfff59d2,18,3,3,1297,,,0,"Add driver autogenerated docs

Start to add/build a developer oriented doc that
can be further refined to explain to developers how
to use the different tooz drivers (and what the varying
drivers capabilities are).

Change-Id: I49f6bf5b397d6bc5426c074f6196c764c8938d23
",git fetch https://review.opendev.org/openstack/tooz refs/changes/63/140263/1 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/drivers/mysql.py', 'doc/source/drivers.rst', 'tooz/drivers/ipc.py', 'doc/source/conf.py', 'tooz/drivers/memcached.py', 'tooz/drivers/pgsql.py']",6,125b62b3f44fa75a20a9f8f32c60a981c01c1ba7,," """"""An PostgreSQL based driver.""""""",,74,0
openstack%2Frally~master~Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b,openstack/rally,master,Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b,Add Network Context Class,MERGED,2014-06-28 09:35:22.000000000,2014-12-18 17:39:59.000000000,2014-12-18 17:39:56.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 4428}, {'_account_id': 5950}, {'_account_id': 6124}, {'_account_id': 6172}, {'_account_id': 6732}, {'_account_id': 6785}, {'_account_id': 7126}, {'_account_id': 7132}, {'_account_id': 7227}, {'_account_id': 7369}, {'_account_id': 8084}, {'_account_id': 8824}, {'_account_id': 9545}, {'_account_id': 9601}, {'_account_id': 10061}, {'_account_id': 10475}, {'_account_id': 11105}, {'_account_id': 12395}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-06-28 09:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2b85ec9ba812cee9452b77920db25f2eb5dcdecb', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 2, 'created': '2014-07-01 01:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/be92eb7744f6cb4105a5df4065287109bae2481c', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 3, 'created': '2014-07-02 13:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/76c9bf51e3b5f90bf6533f45620cb1a0a35beb9b', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 4, 'created': '2014-07-06 15:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e83cb7a2eced41b102186d86f3a135ae9b5418ad', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 5, 'created': '2014-07-06 16:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/927115a4c6761217a51b6fcea42ed50fb10147fc', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 6, 'created': '2014-07-07 16:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/812ff19a853e03953276a524f9c541da695f13e9', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 7, 'created': '2014-07-12 15:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/67bbfff471e561015b33af65a29507c2cda1f2c8', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 8, 'created': '2014-07-20 03:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4f111fc7562ab8affa3cc288e538c7914e6ae106', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 9, 'created': '2014-07-20 15:51:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d6d04e599f22ca5e8b5e934e1e265f16e4caae8b', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 10, 'created': '2014-07-21 14:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b1b791737b715e45c7dbb9f47928d81496c880d5', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 11, 'created': '2014-07-23 16:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/17171153701ccbd08872656924889f3a6fb43e8b', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 12, 'created': '2014-07-27 12:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e20566d2b3dc2a03d093d64120a6f207d730f88b', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 13, 'created': '2014-07-27 14:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4b16d253cda8f51b73fc37d5d8be94a9e99fae8e', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 14, 'created': '2014-07-30 16:03:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c9ec98fa23257d02e99134c2642d159cbc36aa63', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 15, 'created': '2014-08-02 03:13:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2152bf3d91c2672168f0a0c6cc9dc05a894bd807', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism. If the tenant has no network, the vm creation will failed.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 16, 'created': '2014-08-16 06:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d8caf62fd6a5f055776fa62ecc7edc3761aab656', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 17, 'created': '2014-08-16 14:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9074e2e19ffb1e55dcb9dd1c09a7db38c9337167', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 18, 'created': '2014-08-16 18:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/62c5ab680432a6bd597403cc401728784ff32085', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 19, 'created': '2014-08-30 07:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c9ae2194351620fbeec988ceb346db9abf9bd90a', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nAlso-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 20, 'created': '2014-08-30 09:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/eded2842a34cfd5b17502a6928b9e384c1c0d814', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nAlso-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 21, 'created': '2014-08-30 09:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c62e5547f71373a58cc4fb14a25ee923be8b80c8', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nAlso-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 22, 'created': '2014-08-30 10:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c743e7f84f0f96db7912744a8a386349f3a4d4b8', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nAlso-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 23, 'created': '2014-08-30 11:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e6dd928de1a9dca270214aea257cf37e18a8762e', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nAlso-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 24, 'created': '2014-08-30 11:30:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/98463e93ab3d8f73d514a0933423e28a9197c527', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nAlso-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 25, 'created': '2014-08-30 12:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/13e55c1adbfff85fc49d67e5bdd59a49b4acb5ec', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nAlso-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 26, 'created': '2014-08-30 12:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/753a0807f39eceaf672ec0705ab9cb62b7966946', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nAlso-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 27, 'created': '2014-08-30 14:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/30abc1dad03d442a6b57ca9fb075d2242a83c634', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 28, 'created': '2014-08-30 18:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0bd22dd972e9c3142ea4f9fe34bff07737a3c29d', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 29, 'created': '2014-08-30 19:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/63c70d59e5ec379b803589224bfd13820cdcede4', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 30, 'created': '2014-08-31 04:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c07d8274c2d7317505531b2ad07c6d12aa97d074', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 31, 'created': '2014-08-31 05:46:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2800f18f2a19c46abf08c920e529d339fad9d855', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 32, 'created': '2014-09-04 12:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/20dd526a966f2575cb3b98755b752a8db95437e3', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 33, 'created': '2014-09-05 10:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ff226c5eed7e0c578fbac8463a4f2d1c0aac4249', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 34, 'created': '2014-09-06 15:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/71f220a890d93dbb294185010b135a32b8d6054c', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 35, 'created': '2014-09-18 11:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/15deb1a5eba1ce452001988cefff980f5f608f92', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 36, 'created': '2014-09-18 11:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ec5444ca1acdbf7c08cdae34b88a4c2c0091e707', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 37, 'created': '2014-09-18 11:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d9729852dcafae60b5ca7a1c877fa16ea8a43b29', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 38, 'created': '2014-09-18 11:54:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4d964c5abb60ec9ee87145561927e3752014695d', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 39, 'created': '2014-09-18 12:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/aec71ea07cc29a7f9230ddb2ff8685175d2cf9cf', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 40, 'created': '2014-09-18 12:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/98aba4fa8c1403bec81d45717423ab9567da96e2', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 41, 'created': '2014-09-18 14:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b2465922e573ab32d0b3c82a183c83fa30a129f1', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 42, 'created': '2014-09-18 14:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/21550575f82cd299e8039d4b1d22cdaf5b90b988', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 43, 'created': '2014-09-18 16:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bdad7c51075dbc8d361434130e284cd5967d9350', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 44, 'created': '2014-09-19 07:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8b2bd06d2f5674862da531ca14c24f0943711856', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 45, 'created': '2014-09-19 10:25:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f5b633ec55cb5d3edc158e8870681c84d26949cd', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 46, 'created': '2014-09-19 11:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0b5b4f1c121ea87ab9acb40444575c960998ff17', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 47, 'created': '2014-09-22 13:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2ba079ed6f4c752444adb14f44181733be8ed87a', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 48, 'created': '2014-09-25 15:30:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6ccd399d6708b9dd0be7e8526178a360836c4b63', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 49, 'created': '2014-09-25 17:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7d7c979bd2962d25b93d51918d474597501fe075', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 50, 'created': '2014-09-25 17:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a8914adaba6d16a090aa245b4ba8747432c2afc5', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 51, 'created': '2014-10-14 18:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0e4a756c04f787ee8a9c9d897d0de7516c18202d', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 52, 'created': '2014-10-14 19:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ac16558ffad07a76d93d0d996fa4e1b667a427b6', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 53, 'created': '2014-10-14 19:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9d4fd90ef9e2671d792eadf197cf781bbb41a319', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 54, 'created': '2014-10-14 19:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c2812184ed2e11d2dd8814652c91915d58c2ee24', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 55, 'created': '2014-10-15 09:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c29e639bbf031c322b8c0686cf5d3e8e334a845a', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 56, 'created': '2014-10-15 11:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/49b6ea439a11b504b4c8226f7845138d7fbd6bb2', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 57, 'created': '2014-10-15 11:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d223f0485816136af19498db76c3885d963c1f79', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 58, 'created': '2014-10-15 13:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a702c7645903a38292318e65f0887adb8307a083', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 59, 'created': '2014-10-15 14:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/eec61a4abc3542676f818c536929f0f735152036', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 60, 'created': '2014-10-17 08:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bc6e7c1f59eacba3ff2ba438f920b07996d2d36f', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 61, 'created': '2014-10-21 14:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3220d38af77eece1a335ffbfbe3d9bf36425441b', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 62, 'created': '2014-10-24 13:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9bc8185e113d98b0b8fd94240e58c1d92ebee444', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 63, 'created': '2014-10-24 13:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6faffd79ef1583313780759f4b345a873b8bb328', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 64, 'created': '2014-10-24 16:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f29208297665d2dff7a377500706524c14dfe27e', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 65, 'created': '2014-10-28 07:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c2e125f54c127b590b8630597740f999f24c1209', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 66, 'created': '2014-10-28 11:06:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/099e05a8e8ff02b61eb4a62a6e80699115814894', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 67, 'created': '2014-10-28 13:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/718502f251b59cf3abfba248d69cb6a6388c10cc', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 68, 'created': '2014-10-28 15:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3ef8ecc382921ccdb61b3b27137f641adb122c6d', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 69, 'created': '2014-10-29 06:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2f23987afac7b92f1bab27212db3aa966a240542', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 70, 'created': '2014-10-29 07:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/762dec5ac75a0bfbb3eb04b8c9d69ade691183de', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 71, 'created': '2014-11-11 08:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/12a5b3e050fa601277b52c3a62b5247e3f36cb87', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 72, 'created': '2014-11-11 10:31:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4af16006815abe196aa74d33f3ffda16b4fcee72', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 73, 'created': '2014-11-11 12:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bc624c3ebdf3d105e90111693da714bfee114acf', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 74, 'created': '2014-11-11 14:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/149503add7ffe503ff533b411d349d6546c7ef3f', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 75, 'created': '2014-11-19 12:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5c407d624aa5f2d86cde34cb5bdee4927bb03108', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 76, 'created': '2014-11-19 12:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6c1411208b069c8548fb10716730464782d690e9', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 77, 'created': '2014-11-19 13:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/db727123e58ff2ae810210c50819c18de60318e4', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 78, 'created': '2014-11-19 14:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1eb3efc8e9b16641e472d28ca2aeb92016acc70b', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 79, 'created': '2014-11-19 16:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/68d285a8888c947347a1046f758cf0ab0d81c59f', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 80, 'created': '2014-11-24 14:25:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f5071e6328fd96f357a77794e31e34683aa5eede', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 81, 'created': '2014-11-25 10:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/974464d21b2fdc733802d8381536c727eb932b7c', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 82, 'created': '2014-11-25 10:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3fd2ac205e2f876a36d29855c309cc789cc245a9', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 83, 'created': '2014-11-25 11:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/48568f6389cf07b48770a5a0261b249a8307f464', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 84, 'created': '2014-11-25 11:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a1e4a7b0f8cd749df76b989a88d05f25fc138730', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 85, 'created': '2014-11-26 12:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/58be6059f0339d84c86f50d33456d8635a931cbb', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 86, 'created': '2014-11-28 12:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/67ab0879b052f602e3b3c1dbaf1404f0bd458ada', 'message': 'Adding Network Context Class\n\nThis context class implements network context subclass to benchmarking\nmechanism.\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 87, 'created': '2014-12-08 11:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bed2d8380028dc37d5191b4b2facef1c98ac53da', 'message': 'Add Network Context Class\n\nContext for networking resources.\n\nMain changes:\n  * the network context class\n  * rally.benchmark.utils.RAMInt class that represents integer value in RAM,\n    so we can make process safe sync of cluster-unique stuff (like CIDRs)\n  * services layer package rally.benchmark.services, that simplifies\n    and unifies OpenStack services usage from both context and scenarios\n\nNot done yet:\n  * tests\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\nCo-Authored-By: Aleksandr Maretskiy <amaretskiy@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 88, 'created': '2014-12-09 18:48:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b41aedf72293d0a093d9fd16e5a1ea5db688a14a', 'message': 'Add Network Context Class\n\nContext for networking resources.\n\nMain changes:\n  * the network context class\n  * rally.benchmark.utils.RAMInt class that represents integer value in RAM,\n    so we can make process safe sync of cluster-unique stuff (like CIDRs)\n  * services layer package rally.benchmark.services, that simplifies\n    and unifies OpenStack services usage from both context and scenarios\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\nCo-Authored-By: Aleksandr Maretskiy <amaretskiy@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 89, 'created': '2014-12-12 17:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/af8b13c7e4cb5a6b8ec53efd0c64e4cf8e8ba36d', 'message': 'Add Network Context Class\n\nContext for networking resources.\n\nMain changes:\n  * the network context class\n  * rally.benchmark.utils.RAMInt class that represents integer value in RAM,\n    so we can make process safe sync of cluster-unique stuff (like CIDRs)\n  * services layer package rally.benchmark.services, that simplifies\n    and unifies OpenStack services usage from both context and scenarios\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\nCo-Authored-By: Aleksandr Maretskiy <amaretskiy@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 90, 'created': '2014-12-15 18:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9df4b8c2c22ba0a92d42f293976186ae48162913', 'message': 'Add Network Context Class\n\nContext for networking resources.\n\nMain changes:\n  * the network context class\n  * rally.benchmark.utils.RAMInt class that represents integer value in RAM,\n    so we can make process safe sync of cluster-unique stuff (like CIDRs)\n  * rally.benchmark.wrappers.network module, that unifies network service\n    implementation, for usage both in context and scenarios\n\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\nCo-Authored-By: Aleksandr Maretskiy <amaretskiy@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 91, 'created': '2014-12-16 11:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cccf43cb104161ce5ea277067f8d0d2f744ea5e1', 'message': 'Add Network Context Class\n\nContext for networking resources.\n\nMain changes:\n  * the network context class\n  * rally.benchmark.utils.RAMInt class that represents integer value in RAM,\n    so we can make process safe sync of cluster-unique stuff (like CIDRs)\n  * rally.benchmark.wrappers.network module, that unifies network service\n    implementation, for usage both in context and scenarios\n\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\nCo-Authored-By: Aleksandr Maretskiy <amaretskiy@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 92, 'created': '2014-12-16 13:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/300e62f2853d46bf7892762d14a99f0ebd0e698e', 'message': 'Add Network Context Class\n\nContext for networking resources.\n\nMain changes:\n  * the network context class\n  * rally.benchmark.utils.RAMInt class that represents integer value in RAM,\n    so we can make process safe sync of cluster-unique stuff (like CIDRs)\n  * rally.benchmark.wrappers.network module, that unifies network service\n    implementation, for usage both in context and scenarios\n\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\nCo-Authored-By: Aleksandr Maretskiy <amaretskiy@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 93, 'created': '2014-12-17 18:11:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9bc8c970cc2b30a35bcf4630fd8382194c078fec', 'message': 'Add Network Context Class\n\nContext for networking resources.\n\nMain changes:\n  * the network context class\n  * rally.benchmark.utils.RAMInt class that represents integer value in RAM,\n    so we can make process safe sync of cluster-unique stuff (like CIDRs)\n  * rally.benchmark.wrappers.network module, that unifies network service\n    implementation, for usage both in context and scenarios\n  * optimization in NovaScenario._boot_server\n\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\nCo-Authored-By: Aleksandr Maretskiy <amaretskiy@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 94, 'created': '2014-12-18 10:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/882afebf93d1d123cbe9f7d5e01ff00d1da400dc', 'message': 'Add Network Context Class\n\nContext for networking resources.\n\nNote:\n  using this context in security_groups related scenarios\n  will be added in another patch.\n\nMain changes:\n  * the network context class\n  * rally.benchmark.utils.RAMInt class that represents integer value in RAM,\n    so we can make process safe sync of cluster-unique stuff (like CIDRs)\n  * rally.benchmark.wrappers.network module, that unifies network service\n    implementation, for usage both in context and scenarios\n  * optimization in NovaScenario._boot_server\n\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Murashov <smurashov@mirantis.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\nCo-Authored-By: Aleksandr Maretskiy <amaretskiy@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 95, 'created': '2014-12-18 14:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/14f2f50553479638acb329f1d64b489f604c6c56', 'message': 'Add Network Context Class\n\nContext for networking resources.\n\nNote:\n  using this context in security_groups related scenarios\n  will be added in another patch.\n\nMain changes:\n  * the network context class\n  * rally.benchmark.utils.RAMInt class that represents integer value in RAM,\n    so we can make process safe sync of cluster-unique stuff (like CIDRs)\n  * rally.benchmark.wrappers.network module, that unifies network service\n    implementation, for usage both in context and scenarios\n  * optimization in NovaScenario._boot_server\n\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Skripnick <sskripnick@mirantis.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\nCo-Authored-By: Aleksandr Maretskiy <amaretskiy@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}, {'number': 96, 'created': '2014-12-18 15:22:26.000000000', 'files': ['rally/benchmark/scenarios/nova/utils.py', 'tests/unit/benchmark/context/test_network.py', 'tests/unit/test_utils.py', 'rally/utils.py', 'rally/benchmark/scenarios/neutron/utils.py', 'tests/unit/fakes.py', 'tests/unit/benchmark/wrappers/test_network.py', 'rally/benchmark/context/network.py', 'tests/unit/benchmark/scenarios/neutron/test_utils.py', 'rally/benchmark/wrappers/network.py', 'rally-jobs/rally-neutron.yaml', 'tests/unit/benchmark/scenarios/nova/test_utils.py', 'rally-jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/f72bc702a01ccee7fce7f9be3b0c7e9a3f133eee', 'message': 'Add Network Context Class\n\nContext for networking resources.\n\nNote:\n  using this context in security_groups related scenarios\n  will be added in another patch.\n\nMain changes:\n  * the network context class\n  * rally.benchmark.utils.RAMInt class that represents integer value in RAM,\n    so we can make process safe sync of cluster-unique stuff (like CIDRs)\n  * rally.benchmark.wrappers.network module, that unifies network service\n    implementation, for usage both in context and scenarios\n  * optimization in NovaScenario._boot_server\n\nCo-Authored-By: Lingxian Kong <anlin.kong@gmail.com>\nCo-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>\nCo-Authored-By: Sergey Skripnick <sskripnick@mirantis.com>\nCo-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>\nCo-Authored-By: Aleksandr Maretskiy <amaretskiy@mirantis.com>\n\nImplements: blueprint benchmark-context-network\nChange-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b\n'}]",262,103306,f72bc702a01ccee7fce7f9be3b0c7e9a3f133eee,350,21,96,6732,,,0,"Add Network Context Class

Context for networking resources.

Note:
  using this context in security_groups related scenarios
  will be added in another patch.

Main changes:
  * the network context class
  * rally.benchmark.utils.RAMInt class that represents integer value in RAM,
    so we can make process safe sync of cluster-unique stuff (like CIDRs)
  * rally.benchmark.wrappers.network module, that unifies network service
    implementation, for usage both in context and scenarios
  * optimization in NovaScenario._boot_server

Co-Authored-By: Lingxian Kong <anlin.kong@gmail.com>
Co-Authored-By: Timur Nurlygayanov <tnurlygayanov@mirantis.com>
Co-Authored-By: Sergey Skripnick <sskripnick@mirantis.com>
Co-Authored-By: Vadim Rovachev <vrovachev@mirantis.com>
Co-Authored-By: Aleksandr Maretskiy <amaretskiy@mirantis.com>

Implements: blueprint benchmark-context-network
Change-Id: Ia2c461ba3421dc9650c4bb7949c115fee08c6b7b
",git fetch https://review.opendev.org/openstack/rally refs/changes/06/103306/23 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/context/networks.py', 'rally/benchmark/scenarios/nova/utils.py', 'tests/benchmark/context/test_networks.py']",3,2b85ec9ba812cee9452b77920db25f2eb5dcdecb,bp/benchmark-context-network,"# Copyright 2014: Huawei # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from rally.benchmark.context import networks from tests import fakes from tests import test CTX = ""rally.benchmark.context"" class NetworkContextTestCase(test.TestCase): class FakeNetwork(object): def __init__(self): self.id = ""uuid"" fake_network = FakeNetwork() def setUp(self): super(NetworkContextTestCase, self).setUp() self.tenants_num = 2 self.users_per_tenant = 5 task = mock.MagicMock() self.user_key = [{'id': i, 'tenant_id': j, 'endpoint': 'endpoint'} for j in range(self.tenants_num) for i in range(self.users_per_tenant)] self.ctx_with_nets = { ""users"": self.user_key, ""task"": task, ""admin"": {""endpoint"": ""endpoint""}, ""nets"": [{'network_id': 'uuid', 'network': self.fake_network, 'endpoint': 'endpoint', 'tenant_id': j} for j in range(self.tenants_num) for i in range(self.users_per_tenant)] } self.ctx_without_nets = { ""users"": self.user_key, ""task"": task, ""admin"": {""endpoint"": ""endpoint""} } @mock.patch(""%s.networks.Network._neutron_used"" % CTX) @mock.patch(""%s.networks.osclients"" % CTX) @mock.patch(""%s.networks.Network._ensure_network"" % CTX) def test_network_setup_and_cleanup_with_neutron(self, mock_ensure, mock_osclients, mock_neutron_used): fc = fakes.FakeClients() mock_osclients.Clients.return_value = fc mock_ensure.return_value = self.fake_network network_ctx = networks.Network(self.ctx_without_nets) network_ctx.setup() self.assertEqual(self.ctx_without_nets, self.ctx_with_nets) mock_neutron_used.return_value = True fc.neutron().delete_network = mock.MagicMock() network_ctx.cleanup() calls = [mock.call(""uuid"") for i in range(self.tenants_num)] fc.neutron().delete_network.assert_has_calls(calls) @mock.patch(""%s.networks.Network._neutron_used"" % CTX) @mock.patch(""%s.networks.osclients"" % CTX) @mock.patch(""%s.networks.Network._ensure_network"" % CTX) def test_network_setup_and_cleanup_with_nova(self, mock_ensure, mock_osclients, mock_neutron_used): fc = fakes.FakeClients() mock_osclients.Clients.return_value = fc mock_ensure.return_value = self.fake_network network_ctx = networks.Network(self.ctx_without_nets) network_ctx.setup() self.assertEqual(self.ctx_without_nets, self.ctx_with_nets) mock_neutron_used.return_value = False fc.nova().networks.delete = mock.MagicMock() network_ctx.cleanup() calls = [mock.call(self.fake_network) for i in range(self.tenants_num)] fc.nova().networks.delete.assert_has_calls(calls) ",,228,0
openstack%2Fmurano-apps~master~I15d28fa96c021df7c6f6e137207e2ae0880cc444,openstack/murano-apps,master,I15d28fa96c021df7c6f6e137207e2ae0880cc444,Add Apache HTTP Server application,MERGED,2014-12-10 00:39:35.000000000,2014-12-18 17:39:09.000000000,2014-12-18 17:39:09.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-12-10 00:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/36bfdbd41d9866316f83d51372f3ed7252884ae7', 'message': 'Add Apache HTTP Server application\n\nChange-Id: I15d28fa96c021df7c6f6e137207e2ae0880cc444\n'}, {'number': 2, 'created': '2014-12-18 16:02:04.000000000', 'files': ['io.murano.apps.apache.ApacheHttpServer/Resources/scripts/runApacheDeploy.sh', 'io.murano.apps.apache.ApacheHttpServer/Classes/ApacheHttpServer.yaml', 'io.murano.apps.apache.ApacheHttpServer/Resources/DeployApache.template', 'io.murano.apps.apache.ApacheHttpServer/logo.png', 'io.murano.apps.apache.ApacheHttpServer/UI/ui.yaml', 'io.murano.apps.apache.ApacheHttpServer/manifest.yaml'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/c33e769f95d48ea5facb45588ced49e58a7fcbc9', 'message': 'Add Apache HTTP Server application\n\nChange-Id: I15d28fa96c021df7c6f6e137207e2ae0880cc444\n'}]",0,140540,c33e769f95d48ea5facb45588ced49e58a7fcbc9,10,3,2,7225,,,0,"Add Apache HTTP Server application

Change-Id: I15d28fa96c021df7c6f6e137207e2ae0880cc444
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/40/140540/1 && git format-patch -1 --stdout FETCH_HEAD,"['io.murano.apps.apache.ApacheHttpServer/Resources/scripts/runApacheDeploy.sh', 'io.murano.apps.apache.ApacheHttpServer/Classes/ApacheHttpServer.yaml', 'io.murano.apps.apache.ApacheHttpServer/Resources/DeployApache.template', 'io.murano.apps.apache.ApacheHttpServer/logo.png', 'io.murano.apps.apache.ApacheHttpServer/UI/ui.yaml', 'io.murano.apps.apache.ApacheHttpServer/.DS_Store', 'io.murano.apps.apache.ApacheHttpServer/manifest.yaml']",7,36bfdbd41d9866316f83d51372f3ed7252884ae7,app/apache.ApacheHttpServer,"Format: 1.0 Type: Application FullName: io.murano.apps.apache.ApacheHttpServer Name: Apache HTTP Server Description: | The Apache HTTP Server Project is an effort to develop and maintain an open-source HTTP server for modern operating systems including UNIX and Windows NT. The goal of this project is to provide a secure, efficient and extensible server that provides HTTP services in sync with the current HTTP standards. Apache httpd has been the most popular web server on the Internet since April 1996, and celebrated its 17th birthday as a project this February. Author: 'Mirantis, Inc' Tags: [HTTP, Server, WebServer, HTML, Apache] Classes: io.murano.apps.apache.ApacheHttpServer: ApacheHttpServer.yaml ",,184,0
openstack%2Fmurano-apps~master~I18a197d540fc8a90793a9f83992b298c99044c22,openstack/murano-apps,master,I18a197d540fc8a90793a9f83992b298c99044c22,Add WordPress application,MERGED,2014-12-10 00:47:34.000000000,2014-12-18 17:38:54.000000000,2014-12-18 17:38:53.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-12-10 00:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/8005c112a8e53fbcf8717b1c002998a98954999d', 'message': 'Add WordPress application\n\nChange-Id: I18a197d540fc8a90793a9f83992b298c99044c22\n'}, {'number': 2, 'created': '2014-12-18 15:59:08.000000000', 'files': ['io.murano.apps.WordPress/logo.png', 'io.murano.apps.WordPress/Classes/WordPress.yaml', 'io.murano.apps.WordPress/manifest.yaml', 'io.murano.apps.WordPress/Resources/ConfigureAccessToMySql.template', 'io.murano.apps.WordPress/Resources/DeployWordPress.template', 'io.murano.apps.WordPress/Resources/scripts/deployWordPress.sh', 'io.murano.apps.WordPress/Resources/scripts/configureAccessToMySql.sh', 'io.murano.apps.WordPress/UI/ui.yaml'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/3c8436a2008b85a61892aed508f70e777cebfd65', 'message': 'Add WordPress application\n\nChange-Id: I18a197d540fc8a90793a9f83992b298c99044c22\n'}]",1,140544,3c8436a2008b85a61892aed508f70e777cebfd65,12,4,2,7225,,,0,"Add WordPress application

Change-Id: I18a197d540fc8a90793a9f83992b298c99044c22
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/44/140544/1 && git format-patch -1 --stdout FETCH_HEAD,"['io.murano.apps.WordPress/.DS_Store', 'io.murano.apps.WordPress/logo.png', 'io.murano.apps.WordPress/Classes/WordPress.yaml', 'io.murano.apps.WordPress/manifest.yaml', 'io.murano.apps.WordPress/Resources/ConfigureAccessToMySql.template', 'io.murano.apps.WordPress/Resources/DeployWordPress.template', 'io.murano.apps.WordPress/Resources/scripts/configureAccessToMySql.sh', 'io.murano.apps.WordPress/Resources/scripts/deployWordPress.sh', 'io.murano.apps.WordPress/UI/ui.yaml']",9,8005c112a8e53fbcf8717b1c002998a98954999d,app/WordPress,"Version: 2 Application: ?: type: io.murano.apps.WordPress name: $.appConfiguration.name database: $.appConfiguration.database server: $.appConfiguration.server dbName: $.dbConfiguration.database dbUser: $.dbConfiguration.username dbPassword: $.dbConfiguration.password monitoring: $.appConfiguration.zabbix Forms: - appConfiguration: fields: - name: name type: string label: Application Name initial: 'WordPress' description: >- Enter a desired name for the application. Just A-Z, a-z, 0-9, dash and underline are allowed - name: database type: io.murano.databases.MySql label: Database Server description: >- Select a database server to host the application's database - name: server type: io.murano.apps.apache.ApacheHttpServer label: HTTP Server description: >- Select an instance of Apache HTTP Server to run the app - name: zabbix type: io.murano.apps.ZabbixAgent label: Monitoring required: false description: >- Select an instance of monitoring system (optional) - dbConfiguration: fields: - name: title type: string required: false hidden: true descriptionTitle: Database Configuration description: Specify the properties of the database which will be created at the selected DB Server - name: database type: string label: Database name initial: wordpress description: >- Please, provide database name that is going to be created - name: username type: string initial: wp_user label: Username description: >- Please, provide username that is going to be used to connect to the database - name: password type: password label: Password descriptionTitle: Password description: >- Please, provide password that is going to be used to connect to the database ",,211,0
openstack%2Fmurano-apps~master~I0c0611a588a64b686753b470fbd3e01378c91cbf,openstack/murano-apps,master,I0c0611a588a64b686753b470fbd3e01378c91cbf,Add Zabbix monitoring application,MERGED,2014-12-10 00:46:30.000000000,2014-12-18 17:38:25.000000000,2014-12-18 17:38:25.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-12-10 00:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/119f5485418e947041bc01b7b8ce21e67425d3d6', 'message': 'Add Zabbix monitoring application\n\nChange-Id: I0c0611a588a64b686753b470fbd3e01378c91cbf\n'}, {'number': 2, 'created': '2014-12-18 15:57:29.000000000', 'files': ['io.murano.apps.ZabbixServer/Classes/ZabbixServer.yaml', 'io.murano.apps.ZabbixAgent/logo.png', 'io.murano.apps.ZabbixAgent/Resources/scripts/launchConfiguring.sh', 'io.murano.apps.ZabbixAgent/Resources/scripts/zabbixApi.py', 'io.murano.apps.ZabbixServer/Resources/scripts/deployZabbixServer.sh', 'io.murano.apps.ZabbixServer/UI/ui.yaml', 'io.murano.apps.ZabbixAgent/Resources/DeployZabbixAgent.template', 'io.murano.apps.ZabbixServer/Resources/DeployZabbixServer.template', 'io.murano.apps.ZabbixAgent/Resources/scripts/addProbe.py', 'io.murano.apps.ZabbixAgent/manifest.yaml', 'io.murano.apps.ZabbixServer/logo.png', 'io.murano.apps.ZabbixAgent/Resources/scripts/deployZabbixAgent.sh', 'io.murano.apps.ZabbixServer/manifest.yaml', 'io.murano.apps.ZabbixAgent/Classes/ZabbixAgent.yaml', 'io.murano.apps.ZabbixAgent/UI/ui.yaml', 'io.murano.apps.ZabbixAgent/Resources/ConfigureProbe.template'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/67a706e900c8c7c76c292bca9615c7dbecd9ad4a', 'message': 'Add Zabbix monitoring application\n\nChange-Id: I0c0611a588a64b686753b470fbd3e01378c91cbf\n'}]",2,140543,67a706e900c8c7c76c292bca9615c7dbecd9ad4a,11,3,2,7225,,,0,"Add Zabbix monitoring application

Change-Id: I0c0611a588a64b686753b470fbd3e01378c91cbf
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/43/140543/2 && git format-patch -1 --stdout FETCH_HEAD,"['io.murano.apps.ZabbixServer/Classes/ZabbixServer.yaml', 'io.murano.apps.ZabbixAgent/logo.png', 'io.murano.apps.ZabbixAgent/Resources/scripts/launchConfiguring.sh', 'io.murano.apps.ZabbixAgent/Resources/scripts/zabbixApi.py', 'io.murano.apps.ZabbixServer/Resources/scripts/deployZabbixServer.sh', 'io.murano.apps.ZabbixServer/UI/ui.yaml', 'io.murano.apps.ZabbixAgent/Classes/.DS_Store', 'io.murano.apps.ZabbixAgent/Resources/DeployZabbixAgent.template', 'io.murano.apps.ZabbixServer/Resources/DeployZabbixServer.template', 'io.murano.apps.ZabbixAgent/Resources/scripts/addProbe.py', 'io.murano.apps.ZabbixAgent/manifest.yaml', 'io.murano.apps.ZabbixServer/logo.png', 'io.murano.apps.ZabbixAgent/Resources/scripts/deployZabbixAgent.sh', 'io.murano.apps.ZabbixServer/manifest.yaml', 'io.murano.apps.ZabbixAgent/Classes/ZabbixAgent.yaml', 'io.murano.apps.ZabbixAgent/.DS_Store', 'io.murano.apps.ZabbixAgent/UI/ui.yaml', 'io.murano.apps.ZabbixAgent/Resources/ConfigureProbe.template']",18,119f5485418e947041bc01b7b8ce21e67425d3d6,app/Zabbix,"FormatVersion: 2.0.0 Version: 1.0.0 Name: Configure Probe Parameters: probe: $probe server: $server hostname: $hostname instanceIp: $instanceIp Body: | return deploy('{0} {1} {2} {3}'.format(args.probe, args.server, args.hostname, args.instanceIp)).stdout Scripts: deploy: Type: Application Version: 1.0.0 EntryPoint: launchConfiguring.sh Files: - <zabbixApi.py> - <addProbe.py> Options: captureStdout: true captureStderr: true ",,601,0
openstack%2Fneutron~master~I0455906c443cb15d5b919e77aabf906e0a02c5ee,openstack/neutron,master,I0455906c443cb15d5b919e77aabf906e0a02c5ee,test,ABANDONED,2014-12-18 13:17:40.000000000,2014-12-18 17:29:08.000000000,,"[{'_account_id': 5170}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10386}, {'_account_id': 12441}]","[{'number': 1, 'created': '2014-12-18 13:17:40.000000000', 'files': ['neutron/db/test1'], 'web_link': 'https://opendev.org/openstack/neutron/commit/24787683df81c7b0660ad6268c7175f14c9955ca', 'message': 'test\n\nChange-Id: I0455906c443cb15d5b919e77aabf906e0a02c5ee\n'}]",0,142775,24787683df81c7b0660ad6268c7175f14c9955ca,11,6,1,12441,,,0,"test

Change-Id: I0455906c443cb15d5b919e77aabf906e0a02c5ee
",git fetch https://review.opendev.org/openstack/neutron refs/changes/75/142775/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/test1'],1,24787683df81c7b0660ad6268c7175f14c9955ca,mellanox-master,1111,test,1,1
openstack%2Fproject-config~master~I832ff0ae3c8af91ca4eac80d05a4b8c026c521c0,openstack/project-config,master,I832ff0ae3c8af91ca4eac80d05a4b8c026c521c0,sqlalchemy-migrate: enable the py33 gate.,MERGED,2014-10-29 15:22:47.000000000,2014-12-18 17:27:58.000000000,2014-11-07 15:10:41.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-10-29 15:22:47.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7ac466af2dc5ae69d62a46bd7e71b0a813761b01', 'message': 'sqlalchemy-migrate: enable the py33 gate.\n\nThis now works with Python 3, so this gate should be enabled.\n\nChange-Id: I832ff0ae3c8af91ca4eac80d05a4b8c026c521c0\n'}]",0,131797,7ac466af2dc5ae69d62a46bd7e71b0a813761b01,8,3,1,8122,,,0,"sqlalchemy-migrate: enable the py33 gate.

This now works with Python 3, so this gate should be enabled.

Change-Id: I832ff0ae3c8af91ca4eac80d05a4b8c026c521c0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/97/131797/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,7ac466af2dc5ae69d62a46bd7e71b0a813761b01,py3-sqlalchemy-migrate, - name: python3-jobs,,1,0
openstack%2Fneutron~master~I5fc1f016cac5afa373e0334efa1b66ab3f1bf5d0,openstack/neutron,master,I5fc1f016cac5afa373e0334efa1b66ab3f1bf5d0,test2,ABANDONED,2014-12-18 13:17:40.000000000,2014-12-18 17:27:01.000000000,,"[{'_account_id': 5170}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 14212}]","[{'number': 1, 'created': '2014-12-18 13:17:40.000000000', 'files': ['neutron/db/test1'], 'web_link': 'https://opendev.org/openstack/neutron/commit/05d4bc452012fb87b5002e671ff1335b523d1873', 'message': 'test2\n\nChange-Id: I5fc1f016cac5afa373e0334efa1b66ab3f1bf5d0\nSigned-off-by: Omri Marcovitch <omrim@mellanox.com>\n'}]",0,142773,05d4bc452012fb87b5002e671ff1335b523d1873,13,11,1,12441,,,0,"test2

Change-Id: I5fc1f016cac5afa373e0334efa1b66ab3f1bf5d0
Signed-off-by: Omri Marcovitch <omrim@mellanox.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/73/142773/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/test1'],1,05d4bc452012fb87b5002e671ff1335b523d1873,mellanox-master,test ,,1,0
openstack%2Fironic~master~I77154e578f5c98e8f3fb055005454d9a852f6c98,openstack/ironic,master,I77154e578f5c98e8f3fb055005454d9a852f6c98,Update command options in the Installation Guide,MERGED,2014-12-16 13:43:42.000000000,2014-12-18 17:23:23.000000000,2014-12-18 17:23:21.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 9315}, {'_account_id': 10068}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 12356}, {'_account_id': 14355}]","[{'number': 1, 'created': '2014-12-16 13:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/65d7a5b9031771d9b34e34f26396197f68957471', 'message': 'Update command options in the Installation Guide\n\nFixed some of deprecated options.\n  - python-glanceclient: --public option is ignored. (from version 0.15.0)\n  - diskimage-builder: disk-image-get-kernel is deprecated.\n\nChange-Id: I77154e578f5c98e8f3fb055005454d9a852f6c98\n'}, {'number': 2, 'created': '2014-12-16 14:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bd05cf6bb12702812aba72ca89ef3edd4b857873', 'message': 'Update command options in the Installation Guide\n\nFixed some of deprecated options.\n  - python-glanceclient: --public option is ignored. (from version 0.15.0)\n  - diskimage-builder: disk-image-get-kernel is deprecated.\n\nChange-Id: I77154e578f5c98e8f3fb055005454d9a852f6c98\n\nUpdate command options in the Installation Guide\n\nFixed some of deprecated options.\n  - python-glanceclient: --public option is ignored. (from version 0.15.0)\n  - diskimage-builder: disk-image-get-kernel is deprecated.\n\nFixed my typos.\n\nChange-Id: I77154e578f5c98e8f3fb055005454d9a852f6c98\n'}, {'number': 3, 'created': '2014-12-16 23:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/79391edc4eed77772ac90e0431013aa4383970b0', 'message': 'Update command options in the Installation Guide\n\nFixed some of deprecated options.\n  - python-glanceclient: --public option is ignored. (from version 0.15.0)\n  - diskimage-builder: disk-image-get-kernel is deprecated.\n\nChange-Id: I77154e578f5c98e8f3fb055005454d9a852f6c98\n'}, {'number': 4, 'created': '2014-12-17 14:33:49.000000000', 'files': ['doc/source/deploy/install-guide.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b6329aa6276787b42583f61d8de07dfa5dd23523', 'message': 'Update command options in the Installation Guide\n\nFixed some of deprecated options.\n  - python-glanceclient: --public option is ignored. (from version 0.15.0)\n  - diskimage-builder: disk-image-get-kernel is deprecated.\n\nChange-Id: I77154e578f5c98e8f3fb055005454d9a852f6c98\n'}]",2,142107,b6329aa6276787b42583f61d8de07dfa5dd23523,30,8,4,14355,,,0,"Update command options in the Installation Guide

Fixed some of deprecated options.
  - python-glanceclient: --public option is ignored. (from version 0.15.0)
  - diskimage-builder: disk-image-get-kernel is deprecated.

Change-Id: I77154e578f5c98e8f3fb055005454d9a852f6c98
",git fetch https://review.opendev.org/openstack/ironic refs/changes/07/142107/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/deploy/install-guide.rst'],1,65d7a5b9031771d9b34e34f26396197f68957471,I77154e578f5c98e8f3fb055005454d9a852f6c98," bin/disk-image-create ubuntu baremetal -o my-image The above command creates *my-image.qcow2*, *my-image.vmlinuz* and *my-image.initrd* files.If you want to use Fedora image, replace *ubuntu* with *fedora* in the above command. These images are used while deploying the actual OS the users will run, my-image in our case. glance image-create --name my-kernel --is-public True \ --disk-format aki < my-image.vmlinuz glance image-create --name my-image.initrd --is-public True \ glance image-create --name my-image --is-public True \ glance image-create --name deploy-vmlinuz --is-public True \ glance image-create --name deploy-initrd --is-public True \"," bin/disk-image-create -u ubuntu -o my-image The above command creates *my-image.qcow2* file. If you want to use Fedora image, replace *ubuntu* with *fedora* in the above command. - Extract the kernel & ramdisk:: bin/disk-image-get-kernel -d ./ -o my \ -i $(pwd)/my-image.qcow2 The above command creates *my-vmlinuz* and *my-initrd* files. These images are used while deploying the actual OS the users will run, my-image in our case. glance image-create --name my-kernel --public \ --disk-format aki < my-vmlinuz glance image-create --name my-ramdisk --public \ glance image-create --name my-image --public \ glance image-create --name deploy-vmlinuz --public \ glance image-create --name deploy-initrd --public \",12,18
openstack%2Fhorizon~stable%2Fjuno~I69ce13e1e3fc9674c4f25e7d04d79a3f550014a6,openstack/horizon,stable/juno,I69ce13e1e3fc9674c4f25e7d04d79a3f550014a6,Return eye-icon to its place when validation message is shown,MERGED,2014-11-19 10:33:55.000000000,2014-12-18 17:18:58.000000000,2014-12-18 17:18:56.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 979}, {'_account_id': 1420}, {'_account_id': 1941}, {'_account_id': 1955}, {'_account_id': 2455}, {'_account_id': 2750}, {'_account_id': 4264}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6763}, {'_account_id': 6914}, {'_account_id': 8040}, {'_account_id': 9317}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 12355}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-11-19 10:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f44035873044f2a09acec3cf42459a9dfc90658e', 'message': ""Return eye-icon to its place when validation message is shown\n\nMaking eye-icon properly positioned relies on its parent having\n'has-feedback' class - which makes the parent to obey 'position:\nrelative' and thus eye-icon with its 'position: absolute' is properly\npositioned within it.\n\nChange-Id: I69ce13e1e3fc9674c4f25e7d04d79a3f550014a6\nCloses-Bug: #1386126\n(cherry picked from commit 6ffebb6d200a071774048e792752cd201a5c6d0d)\n""}, {'number': 2, 'created': '2014-11-26 15:40:50.000000000', 'files': ['horizon/static/horizon/js/horizon.forms.js', 'openstack_dashboard/static/dashboard/scss/horizon.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2cd943510a0b181fb79644390cdf8dc1ac95c571', 'message': ""Return eye-icon to its place when validation message is shown\n\nMaking eye-icon properly positioned relies on its parent having\n'has-feedback' class - which makes the parent to obey 'position:\nrelative' and thus eye-icon with its 'position: absolute' is properly\npositioned within it.\n\nChange-Id: I69ce13e1e3fc9674c4f25e7d04d79a3f550014a6\nCloses-Bug: #1386126\n(cherry picked from commit 6ffebb6d200a071774048e792752cd201a5c6d0d)\n""}]",0,135562,2cd943510a0b181fb79644390cdf8dc1ac95c571,60,20,2,12355,,,0,"Return eye-icon to its place when validation message is shown

Making eye-icon properly positioned relies on its parent having
'has-feedback' class - which makes the parent to obey 'position:
relative' and thus eye-icon with its 'position: absolute' is properly
positioned within it.

Change-Id: I69ce13e1e3fc9674c4f25e7d04d79a3f550014a6
Closes-Bug: #1386126
(cherry picked from commit 6ffebb6d200a071774048e792752cd201a5c6d0d)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/62/135562/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/horizon/js/horizon.forms.js', 'openstack_dashboard/static/dashboard/scss/horizon.scss']",2,f44035873044f2a09acec3cf42459a9dfc90658e,, .has-feedback .form-control-feedback { top: 0; },,5,1
openstack%2Fopenstack-manuals~master~Iae3e5adb26201a8024fa1b7b642b963186f69872,openstack/openstack-manuals,master,Iae3e5adb26201a8024fa1b7b642b963186f69872,Fixes EPEL repository URL Error,MERGED,2014-12-17 01:22:41.000000000,2014-12-18 17:18:07.000000000,2014-12-17 04:35:24.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 9515}, {'_account_id': 10497}]","[{'number': 1, 'created': '2014-12-17 01:22:41.000000000', 'files': ['doc/install-guide/section_basics-packages.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4f34cb1276f9714bdd077b2f5e16d8df7f7472c5', 'message': 'Fixes EPEL repository URL Error\n\nyum install\nhttp://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-2.noarch.rpm\nshould be:\nyum install\nhttp://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm\n\nChange-Id: Iae3e5adb26201a8024fa1b7b642b963186f69872\nCloses-bug: #1402945\n'}]",0,142294,4f34cb1276f9714bdd077b2f5e16d8df7f7472c5,8,4,1,4428,,,0,"Fixes EPEL repository URL Error

yum install
http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-2.noarch.rpm
should be:
yum install
http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm

Change-Id: Iae3e5adb26201a8024fa1b7b642b963186f69872
Closes-bug: #1402945
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/94/142294/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_basics-packages.xml'],1,4f34cb1276f9714bdd077b2f5e16d8df7f7472c5,epel-url-error," <screen os=""fedora;centos;rhel""><prompt>#</prompt> <userinput>yum install http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm</userinput></screen>"," <screen os=""fedora;centos;rhel""><prompt>#</prompt> <userinput>yum install http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-2.noarch.rpm</userinput></screen>",1,1
openstack-attic%2Fidentity-api~master~I7e523370405d72dcab7737135d80d4510b183560,openstack-attic/identity-api,master,I7e523370405d72dcab7737135d80d4510b183560,Registry of token formats,ABANDONED,2014-12-18 16:55:24.000000000,2014-12-18 17:15:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2903}]","[{'number': 1, 'created': '2014-12-18 16:55:24.000000000', 'files': ['v3/src/markdown/identity-api-v3-token-formats.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/b8fa48a9ff20dbebb80912fcebbcd8577d93d9bc', 'message': 'Registry of token formats\n\nChange-Id: I7e523370405d72dcab7737135d80d4510b183560\n'}]",0,142842,b8fa48a9ff20dbebb80912fcebbcd8577d93d9bc,5,2,1,2218,,,0,"Registry of token formats

Change-Id: I7e523370405d72dcab7737135d80d4510b183560
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/42/142842/1 && git format-patch -1 --stdout FETCH_HEAD,['v3/src/markdown/identity-api-v3-token-formats.md'],1,b8fa48a9ff20dbebb80912fcebbcd8577d93d9bc,token-format-registry,"OpenStack Identity API v3 token formats ======================================= The Identity API supports multiple token formats. Applications should treat the tokens as opaque references to remote objects. However, since implementations of token parsing must be language agnostic, the various token formats are documented here. # Historical Formats ## UUID Tokens A UUID token is the oldest format, and has no identifying data in it. A UUID token looks like this: e60191a29486420f96b7d660a5421aab ## ASN1 Tokens The first form of tokens to contain a format identifier are tokens that contain all of the data from the token validation response. The JSON document is converted into a Crypto Message Syntax (CMS) encoded document which is base64 encoded. The non URL safe `/` chracter in the encoded form is replaced with the URL safe `-` character. The '-----BEGIN CMS-----' and '-----END CMS-----' delimeters are removed, as are any line breaks. The CMS format uses ASN1 as an intermediate format. ASN1 encodes field lengths included the length of the overall message. For PKI tokens, the lengths, once Base64 encode, lead to the message starting with the string 'MII'. This artifact was used as a token format identifier. ## PKIZ The Data encoded in the token quickly expanded to sizes that were impractical to transmit in headers. The first attempt to minimize the token size was to compress the tokens. To distinguish these tokens from the earlier format, the format identifier `PKIZ` is prepended to these tokens. # Token Naming conventions In order to support multiple token formats without each one coming up with an ad-hoc naming scheme, tokens will contain the following naming scheme prefix. The following prefix identifies the token as an OpenStack Identity API Authorization token. `OSAUTHZ` The next 4 characters will be the Hexidecimal representation of the token format. Thus the formats will range from `OSAUTHZ0000` to `OSAUTHZFFFF` The table below contains the registered Token formats. OSAUTHZ0000 : UUID token. Replaces the UUID token format OSAUTHZ0001 : ASN1 token. Replaces the ASN1 format indicator OSAUTHZ0002 : PKIZ token. Replaces the PKIZ_ format indicator All historical formats are depricated and should be replaced with the values above. ",,62,0
openstack%2Fopenstack-manuals~master~I87cbcd24a25407e48f02da55525654b2d9ee7666,openstack/openstack-manuals,master,I87cbcd24a25407e48f02da55525654b2d9ee7666,Clarified text about [database] section,MERGED,2014-12-17 21:00:31.000000000,2014-12-18 17:15:18.000000000,2014-12-18 02:06:06.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6772}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-12-17 21:00:31.000000000', 'files': ['doc/install-guide/section_nova-controller-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ab69109bf539f5030e8d54f3d1b12bb5dbdfb655', 'message': 'Clarified text about [database] section\n\nClarified text in the install guide to indicate\nthat you need to add a [database] section\nto nova.conf.\n\nChange-Id: I87cbcd24a25407e48f02da55525654b2d9ee7666\nbackport: juno\nCloses-Bug: #1402686\n'}]",0,142579,ab69109bf539f5030e8d54f3d1b12bb5dbdfb655,8,4,1,9770,,,0,"Clarified text about [database] section

Clarified text in the install guide to indicate
that you need to add a [database] section
to nova.conf.

Change-Id: I87cbcd24a25407e48f02da55525654b2d9ee7666
backport: juno
Closes-Bug: #1402686
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/79/142579/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_nova-controller-install.xml'],1,ab69109bf539f5030e8d54f3d1b12bb5dbdfb655,fix-bug-1402686," <para>Add a <literal>[database]</literal> section, and configure"," <para>In the <literal>[database]</literal> section, configure",1,1
openstack%2Fswift~master~Ia1e1effcbd89bd2cf6d5b8c64019f1647c736a3a,openstack/swift,master,Ia1e1effcbd89bd2cf6d5b8c64019f1647c736a3a,Adds console logging to swift-drive-audit,MERGED,2014-12-11 08:19:58.000000000,2014-12-18 17:10:57.000000000,2014-12-18 17:10:55.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 860}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 7134}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 9051}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-11 08:19:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/70290a495bea20fecde9e0f1f459c6b93cb97cf1', 'message': 'Adds console logging to swift-drive-audit\n\nThis patch adds console logging ability to swift-drive-audit.\nThere are cases where logging to console is necessary when drive-audit\nis done. This can be consumed for flagging errors in monitoring tools\nsuch as icinga.\n\nChange-Id: Ia1e1effcbd89bd2cf6d5b8c64019f1647c736a3a\n'}, {'number': 2, 'created': '2014-12-12 13:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/375eca118f3a714b4e996056d835ea321ed92daa', 'message': 'Adds console logging to swift-drive-audit\n\nThis patch adds console logging ability to swift-drive-audit.\nThere are cases where logging to console is necessary when drive-audit\nis done. This can be consumed for flagging errors in monitoring tools\nsuch as icinga.\n\nChange-Id: Ia1e1effcbd89bd2cf6d5b8c64019f1647c736a3a\n'}, {'number': 3, 'created': '2014-12-18 08:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8cbe9e04dc23d9fc488f8f4a95ef87539da4cc99', 'message': 'Adds console logging to swift-drive-audit\n\nThis patch adds console logging ability to swift-drive-audit.\nThere are cases where logging to console is necessary when drive-audit\nis done. This can be consumed for flagging errors in monitoring tools\nsuch as icinga.\n\nDocImpact\nChange-Id: Ia1e1effcbd89bd2cf6d5b8c64019f1647c736a3a\n'}, {'number': 4, 'created': '2014-12-18 08:49:55.000000000', 'files': ['bin/swift-drive-audit', 'etc/drive-audit.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/1ffe6b39534655b35b84506ef21da68803bbd11a', 'message': 'Adds console logging to swift-drive-audit\n\nThis patch adds console logging ability to swift-drive-audit.\nThere are cases where logging to console is necessary when drive-audit\nis done. This can be consumed for flagging errors in monitoring tools\nsuch as icinga.\n\nDocImpact\nChange-Id: Ia1e1effcbd89bd2cf6d5b8c64019f1647c736a3a\n'}]",4,140972,1ffe6b39534655b35b84506ef21da68803bbd11a,28,11,4,9051,,,0,"Adds console logging to swift-drive-audit

This patch adds console logging ability to swift-drive-audit.
There are cases where logging to console is necessary when drive-audit
is done. This can be consumed for flagging errors in monitoring tools
such as icinga.

DocImpact
Change-Id: Ia1e1effcbd89bd2cf6d5b8c64019f1647c736a3a
",git fetch https://review.opendev.org/openstack/swift refs/changes/72/140972/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/swift-drive-audit', 'etc/drive-audit.conf-sample']",2,70290a495bea20fecde9e0f1f459c6b93cb97cf1,log_to_console,# log_to_console = True,,4,1
openstack%2Fnova~master~I05e8b3d01bffebe2f68bbd50fc775e1ef48616cc,openstack/nova,master,I05e8b3d01bffebe2f68bbd50fc775e1ef48616cc,Refactor Ironic driver tests as per review comment,MERGED,2014-10-21 02:56:48.000000000,2014-12-18 17:10:20.000000000,2014-12-18 17:10:16.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 8125}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-21 02:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/977f2f7ebe181d6192b9bd8f5a309f8f898ab20d', 'message': 'Refactor Ironic driver tests as per review comment\n\nDuring the Ironic driver merge into Nova, there were some\nsuggestions on refactoring the tests as per this review\n(https://review.openstack.org/#/c/111425/19/nova/...\n...tests/virt/ironic/test_driver.py)\n\nThis patch implements these suggestions.\n\nChange-Id: I05e8b3d01bffebe2f68bbd50fc775e1ef48616cc\n'}, {'number': 2, 'created': '2014-11-04 11:47:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28e19427d12c53b4bab63bad9a7c26eba05207e4', 'message': 'Refactor Ironic driver tests as per review comment\n\nDuring the Ironic driver merge into Nova, there were some\nsuggestions on refactoring the tests as per this review\n(https://review.openstack.org/#/c/111425/19/nova/...\n...tests/virt/ironic/test_driver.py)\n\nThis patch implements these suggestions.\n\nChange-Id: I05e8b3d01bffebe2f68bbd50fc775e1ef48616cc\n'}, {'number': 3, 'created': '2014-11-19 03:02:01.000000000', 'files': ['nova/tests/unit/virt/ironic/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/11a965a9f45e4a6a1bd57cc7bfa22e6704b75e3d', 'message': 'Refactor Ironic driver tests as per review comment\n\nDuring the Ironic driver merge into Nova, there were some\nsuggestions on refactoring the tests as per this review\n(https://review.openstack.org/#/c/111425/19/nova/...\n...tests/virt/ironic/test_driver.py)\n\nThis patch implements these suggestions.\n\nChange-Id: I05e8b3d01bffebe2f68bbd50fc775e1ef48616cc\n'}]",2,129774,11a965a9f45e4a6a1bd57cc7bfa22e6704b75e3d,34,11,3,8125,,,0,"Refactor Ironic driver tests as per review comment

During the Ironic driver merge into Nova, there were some
suggestions on refactoring the tests as per this review
(https://review.openstack.org/#/c/111425/19/nova/...
...tests/virt/ironic/test_driver.py)

This patch implements these suggestions.

Change-Id: I05e8b3d01bffebe2f68bbd50fc775e1ef48616cc
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/129774/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/ironic/test_driver.py'],1,977f2f7ebe181d6192b9bd8f5a309f8f898ab20d,129774," self.instance_uuid = uuidutils.generate_uuid() instance_uuid=self.instance_uuid) uuid=self.instance_uuid) uuid=self.instance_uuid) instance_uuid=self.instance_uuid, uuid=self.instance_uuid) self.instance_uuid) uuid=self.instance_uuid) self.instance_uuid) 'instance_uuid': self.instance_uuid, node = ironic_utils.get_test_node(instance_uuid=self.instance_uuid, uuid=self.instance_uuid) instance_uuid=self.instance_uuid) instance_uuid=self.instance_uuid) instance_uuid=self.instance_uuid) self._test_power_on_off(mock_sp, fake_validate, mock_looping, method_name='power_off') self._test_power_on_off(mock_sp, fake_validate, mock_looping, method_name='power_on') def _test_power_on_off(self, mock_sp, fake_validate, mock_looping, method_name=None): node=self.instance_uuid) # Call the method under test here if method_name == 'power_on': self.driver.power_on(self.ctx, instance, utils.get_test_network_info()) mock_sp.assert_called_once_with(node.uuid, 'on') elif method_name == 'power_off': self.driver.power_off(instance) mock_sp.assert_called_once_with(node.uuid, 'off') else: raise TypeError('Unsupported test method names') instance_uuid=self.instance_uuid, uuid=self.instance_uuid, instance_uuid=self.instance_uuid, uuid=self.instance_uuid,"," instance_uuid = uuidutils.generate_uuid() instance_uuid=instance_uuid) uuid=instance_uuid) instance_uuid = uuidutils.generate_uuid(), uuid=instance_uuid) instance_uuid = uuidutils.generate_uuid() instance_uuid=instance_uuid, instance_uuid = 'fake-uuid' uuid=instance_uuid) instance_uuid) instance_uuid = 'fake-uuid' uuid=instance_uuid) instance_uuid) 'instance_uuid': uuidutils.generate_uuid(), instance_uuid = 'aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee' node = ironic_utils.get_test_node(instance_uuid=instance_uuid, uuid=instance_uuid) instance_uuid='fake-id') instance_uuid='fake-id') instance_uuid='fake-id') node = ironic_utils.get_test_node() fake_validate.side_effect = [node, node] fake_looping_call = FakeLoopingCall() mock_looping.return_value = fake_looping_call instance_uuid = uuidutils.generate_uuid() instance = fake_instance.fake_instance_obj(self.ctx, node=instance_uuid) self.driver.power_off(instance) mock_sp.assert_called_once_with(node.uuid, 'off') instance_uuid = uuidutils.generate_uuid() node=instance_uuid) self.driver.power_on(self.ctx, instance, utils.get_test_network_info()) mock_sp.assert_called_once_with(node.uuid, 'on') instance_uuid = uuidutils.generate_uuid() instance_uuid=instance_uuid, uuid=instance_uuid, instance_uuid = uuidutils.generate_uuid() instance_uuid=instance_uuid, uuid=instance_uuid,",37,43
openstack%2Fmonasca-agent~master~I4f0fd39ac3ac32b4a4b219e064c0f12b6286ee87,openstack/monasca-agent,master,I4f0fd39ac3ac32b4a4b219e064c0f12b6286ee87,Fixed issue with agent startup if Keystone is down,MERGED,2014-12-16 20:54:14.000000000,2014-12-18 17:09:22.000000000,2014-12-18 17:09:21.000000000,"[{'_account_id': 3}, {'_account_id': 11094}, {'_account_id': 11809}, {'_account_id': 12443}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-12-16 20:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/657fefb370fd9e625a8b03a336e97e15579e8936', 'message': 'Fixed issue with agent startup if Keystone is down\n\nThe agent was not starting properly if Keystone was unavailable and\nno error message was output. Moved creation of Keystone object from\nthe AgentCheck class to the HTTPCheck class in the collector.  Also,\ncache the token in the Keystone class to keep from hitting the Keystone\nAPI multiple times.  If Keystone is unavailable, cache the messages.\n\nChange-Id: I4f0fd39ac3ac32b4a4b219e064c0f12b6286ee87\n'}, {'number': 2, 'created': '2014-12-18 16:27:15.000000000', 'files': ['monagent/forwarder/api/mon.py', 'monagent/collector/checks/check.py', 'monagent/collector/checks_d/http_check.py', 'monagent/common/emitter.py', 'monagent/common/keystone.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/6a735a5ac73a7a0e1892b5e3d3a90f79259f1dec', 'message': 'Fixed issue with agent startup if Keystone is down\n\nThe agent was not starting properly if Keystone was unavailable and\nno error message was output. Moved creation of Keystone object from\nthe AgentCheck class to the HTTPCheck class in the collector.  Also,\ncache the token in the Keystone class to keep from hitting the Keystone\nAPI multiple times.  If Keystone is unavailable, cache the messages.\n\nChange-Id: I4f0fd39ac3ac32b4a4b219e064c0f12b6286ee87\n'}]",1,142220,6a735a5ac73a7a0e1892b5e3d3a90f79259f1dec,10,5,2,12108,,,0,"Fixed issue with agent startup if Keystone is down

The agent was not starting properly if Keystone was unavailable and
no error message was output. Moved creation of Keystone object from
the AgentCheck class to the HTTPCheck class in the collector.  Also,
cache the token in the Keystone class to keep from hitting the Keystone
API multiple times.  If Keystone is unavailable, cache the messages.

Change-Id: I4f0fd39ac3ac32b4a4b219e064c0f12b6286ee87
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/20/142220/2 && git format-patch -1 --stdout FETCH_HEAD,"['monagent/forwarder/api/mon.py', 'monagent/collector/checks/check.py', 'monagent/collector/checks_d/http_check.py', 'monagent/common/emitter.py', 'monagent/common/keystone.py']",5,657fefb370fd9e625a8b03a336e97e15579e8936,monasca/keystone-down,"import logging log = logging.getLogger(__name__) self._keystone_client = None self._token = None if not self._token: if not self._keystone_client: try: self._keystone_client = self._get_ksclient() except Exception as exc: log.error(""Unable to create the Keystone Client. "" + ""Error was {}"".format(repr(exc))) return None if self._keystone_client.project_id: self._token = self._keystone_client.auth_token else: self._token = None self._keystone_client = None raise exc.CommandError(""User does not have a default project. "" ""You must provide the following parameters "" ""in the agent config file: "" ""project_id OR (project_name AND "" ""(project_domain OR project_domain_name))."") return self._token self._token = None self._keystone_client = None"," self._keystone_client = self._get_ksclient() if self._keystone_client.project_id: return self._keystone_client.auth_token raise exc.CommandError(""User does not have a default project. "" ""You must provide the following parameters "" ""in the agent config file: "" ""project_id OR (project_name AND "" ""(project_domain OR project_domain_name))."") self._get_ksclient()",55,25
openstack%2Fgnocchi~master~Ia698461d8c4b6cc5cbc41ebc8dc1012fa63adbd1,openstack/gnocchi,master,Ia698461d8c4b6cc5cbc41ebc8dc1012fa63adbd1,rest: check that the Content-Type is JSON,MERGED,2014-12-17 17:42:00.000000000,2014-12-18 17:07:12.000000000,2014-12-18 17:07:11.000000000,"[{'_account_id': 3}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-17 17:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8ea5636c1011d8f98c0105d93b5b78286e641846', 'message': 'rest: check that the Content-Type is JSON\n\nChange-Id: Ia698461d8c4b6cc5cbc41ebc8dc1012fa63adbd1\n'}, {'number': 2, 'created': '2014-12-18 10:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/fc42ad140d64d0ccdcdb0612be480ec1d22c7d3a', 'message': 'rest: check that the Content-Type is JSON\n\nChange-Id: Ia698461d8c4b6cc5cbc41ebc8dc1012fa63adbd1\n'}, {'number': 3, 'created': '2014-12-18 16:10:04.000000000', 'files': ['gnocchi/rest/__init__.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1ec2590c25c958a53cd22414ab88e608ebd60e6f', 'message': 'rest: check that the Content-Type is JSON\n\nChange-Id: Ia698461d8c4b6cc5cbc41ebc8dc1012fa63adbd1\n'}]",0,142517,1ec2590c25c958a53cd22414ab88e608ebd60e6f,12,2,3,1669,,,0,"rest: check that the Content-Type is JSON

Change-Id: Ia698461d8c4b6cc5cbc41ebc8dc1012fa63adbd1
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/17/142517/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'gnocchi/tests/test_rest.py']",2,8ea5636c1011d8f98c0105d93b5b78286e641846,jd/simplify-metric," def test_deserialize_force_json(self): self.app.post( ""/v1/archive_policy"", params=""foo"", status=415) ",,11,3
openstack%2Fgnocchi~master~I2f1faf4755765a7d64d7f6037701eed11d2165df,openstack/gnocchi,master,I2f1faf4755765a7d64d7f6037701eed11d2165df,indexer: simplify resource ↔ metric relationship,MERGED,2014-12-17 00:15:09.000000000,2014-12-18 17:07:10.000000000,2014-12-18 17:07:10.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-17 00:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/fdd56326d95a3ef36f3537d99aa685ca1628fb7f', 'message': 'indexer: simplify resource ↔ metric relationship\n\nIt used to be N ↔ N and we simplify it to 1 resource ↔ N metric to\nsimplify and optimize the schema.\n\nChange-Id: I2f1faf4755765a7d64d7f6037701eed11d2165df\n'}, {'number': 2, 'created': '2014-12-18 10:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/b931ecccb9a59283468b5b259fc8103cb8e54127', 'message': 'indexer: simplify resource ↔ metric relationship\n\nIt used to be N ↔ N and we simplify it to 1 resource ↔ N metric to\nsimplify and optimize the schema.\n\nChange-Id: I2f1faf4755765a7d64d7f6037701eed11d2165df\n'}, {'number': 3, 'created': '2014-12-18 16:10:04.000000000', 'files': ['gnocchi/tests/test_indexer.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8cac0ac2634a279d796676db977b5eb1e41532c1', 'message': 'indexer: simplify resource ↔ metric relationship\n\nIt used to be N ↔ N and we simplify it to 1 resource ↔ N metric to\nsimplify and optimize the schema.\n\nChange-Id: I2f1faf4755765a7d64d7f6037701eed11d2165df\n'}]",2,142264,8cac0ac2634a279d796676db977b5eb1e41532c1,12,3,3,1669,,,0,"indexer: simplify resource ↔ metric relationship

It used to be N ↔ N and we simplify it to 1 resource ↔ N metric to
simplify and optimize the schema.

Change-Id: I2f1faf4755765a7d64d7f6037701eed11d2165df
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/64/142264/2 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/test_indexer.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py']",3,fdd56326d95a3ef36f3537d99aa685ca1628fb7f,jd/simplify-metric,"class ArchivePolicy(Base, GnocchiBase): __tablename__ = 'archive_policy' sqlalchemy.Index('ix_archive_policy_name', 'name'), name = sqlalchemy.Column(sqlalchemy.String(255), primary_key=True) back_window = sqlalchemy.Column(sqlalchemy.Integer, nullable=False) definition = sqlalchemy.Column(sqlalchemy_utils.JSONType, nullable=False) class Metric(Base, GnocchiBase): __tablename__ = 'metric' __table_args__ = ( sqlalchemy.Index('ix_metric_id', 'id'), sqlalchemy.UniqueConstraint(""resource_id"", ""name"", name=""uniq_metric0resource_id0name""), COMMON_TABLES_ARGS, ) id = sqlalchemy.Column(sqlalchemy_utils.UUIDType(binary=False), primary_key=True) archive_policy = sqlalchemy.Column( sqlalchemy.String(255), sqlalchemy.ForeignKey('archive_policy.name', ondelete=""RESTRICT""), nullable=False) created_by_user_id = sqlalchemy.Column( sqlalchemy_utils.UUIDType(binary=False), nullable=False) created_by_project_id = sqlalchemy.Column( sqlalchemy_utils.UUIDType(binary=False), nullable=False) ondelete=""CASCADE"")) name = sqlalchemy.Column(sqlalchemy.String(255)) metrics = sqlalchemy.orm.relationship(Metric) archive_policy, name=None, resource_id=None): archive_policy=archive_policy, name=name, resource_id=resource_id) if metrics is not None: self._set_metrics_for_resource(session, id, metrics) r['metrics'] = dict((m['name'], six.text_type(m['id'])) for m in resource.metrics) session.query(Metric).filter( Metric.resource_id == uuid).update( {""resource_id"": None}) self._set_metrics_for_resource(session, uuid, metrics) def _set_metrics_for_resource(self, session, resource_id, metrics): for name, metric_id in six.iteritems(metrics): # TODO(jd) Check for permissions! try: update = session.query(Metric).filter( Metric.id == metric_id).update( {""resource_id"": resource_id, ""name"": name}) except exception.DBDuplicateEntry: raise indexer.NamedMetricAlreadyExists(name) if update == 0: raise indexer.NoSuchMetric(metric_id) ","class ResourceMetric(Base, GnocchiBase): __tablename__ = 'resource_metric' sqlalchemy.UniqueConstraint('resource_id', 'name', name=""name_unique""), ondelete=""CASCADE""), primary_key=True) metric_id = sqlalchemy.Column(sqlalchemy_utils.UUIDType(binary=False), sqlalchemy.ForeignKey('metric.id', ondelete=""CASCADE""), primary_key=True) name = sqlalchemy.Column(sqlalchemy.String(255), nullable=False) resources = sqlalchemy.orm.relationship('Resource') metrics = sqlalchemy.orm.relationship(ResourceMetric)class ArchivePolicy(Base, GnocchiBase): __tablename__ = 'archive_policy' __table_args__ = ( sqlalchemy.Index('ix_archive_policy_name', 'name'), COMMON_TABLES_ARGS, ) name = sqlalchemy.Column(sqlalchemy.String(255), primary_key=True) back_window = sqlalchemy.Column(sqlalchemy.Integer, nullable=False) definition = sqlalchemy.Column(sqlalchemy_utils.JSONType, nullable=False) class Metric(Base, GnocchiBase): __tablename__ = 'metric' __table_args__ = ( sqlalchemy.Index('ix_metric_id', 'id'), COMMON_TABLES_ARGS, ) id = sqlalchemy.Column(sqlalchemy_utils.UUIDType(binary=False), primary_key=True) archive_policy = sqlalchemy.Column( sqlalchemy.String(255), sqlalchemy.ForeignKey('archive_policy.name', ondelete=""RESTRICT""), nullable=False) created_by_user_id = sqlalchemy.Column( sqlalchemy_utils.UUIDType(binary=False), nullable=False) created_by_project_id = sqlalchemy.Column( sqlalchemy_utils.UUIDType(binary=False), nullable=False) archive_policy): archive_policy=archive_policy) if metrics is None: metrics = {} for name, e in six.iteritems(metrics): session.add(ResourceMetric(resource_id=r.id, metric_id=e, name=name)) try: session.flush() except exception.DBReferenceError as ex: if ex.table == 'resource_metric': if ex.key == 'metric_id': raise indexer.NoSuchMetric(e) if ex.key == 'resource_id': raise indexer.NoSuchResource(r.id) raise r['metrics'] = dict((k.name, str(k.metric_id)) for k in resource.metrics) session.query(ResourceMetric).filter( ResourceMetric.resource_id == uuid).delete() for name, eid in six.iteritems(metrics): with session.begin(subtransactions=True): session.add(ResourceMetric(resource_id=uuid, metric_id=eid, name=name)) try: session.flush() except exception.DBReferenceError as e: if e.key == 'metric_id': raise indexer.NoSuchMetric(eid) if e.key == 'resource_id': raise indexer.NoSuchResource(uuid) raise except exception.DBDuplicateEntry as e: raise indexer.NamedMetricAlreadyExists(name)",68,86
openstack%2Fgnocchi~master~I0fe368703b36a7a0e4774dcc82654e833f37c4c9,openstack/gnocchi,master,I0fe368703b36a7a0e4774dcc82654e833f37c4c9,rest: allow to delete archive policies,MERGED,2014-12-16 16:33:28.000000000,2014-12-18 17:07:04.000000000,2014-12-18 17:07:03.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-16 16:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/be64b1cd26b26e0e1805d23ed25fa55d89046090', 'message': 'rest: allow to delete archive policies\n\nChange-Id: I0fe368703b36a7a0e4774dcc82654e833f37c4c9\n'}, {'number': 2, 'created': '2014-12-18 10:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/587201fd3fb6fc16c69b6ccfc041a8fc566dec26', 'message': 'rest: allow to delete archive policies\n\nChange-Id: I0fe368703b36a7a0e4774dcc82654e833f37c4c9\n'}, {'number': 3, 'created': '2014-12-18 16:10:04.000000000', 'files': ['gnocchi/rest/__init__.py', 'doc/source/rest.j2', 'doc/source/rest.yaml', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c198164b9147b0956d92167d7ce451a214d2cab9', 'message': 'rest: allow to delete archive policies\n\nChange-Id: I0fe368703b36a7a0e4774dcc82654e833f37c4c9\n'}]",4,142148,c198164b9147b0956d92167d7ce451a214d2cab9,12,3,3,1669,,,0,"rest: allow to delete archive policies

Change-Id: I0fe368703b36a7a0e4774dcc82654e833f37c4c9
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/48/142148/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'doc/source/rest.j2', 'doc/source/rest.yaml', 'gnocchi/tests/test_rest.py']",4,be64b1cd26b26e0e1805d23ed25fa55d89046090,jd/simplify-metric," def test_delete_archive_policy(self): params = {""name"": str(uuid.uuid4()), ""back_window"": 1, ""definition"": [{ ""granularity"": ""10s"", ""points"": 20, }]} self.app.post_json( ""/v1/archive_policy"", params=params) self.app.delete(""/v1/archive_policy/%s"" % params['name'], status=204) def test_delete_archive_policy_non_existent(self): ap = str(uuid.uuid4()) result = self.app.delete(""/v1/archive_policy/%s"" % ap, status=400) self.assertIn( b""Archive policy "" + ap + "" does not exist"", result.body) def test_delete_archive_policy_in_use(self): ap = str(uuid.uuid4()) params = {""name"": ap, ""back_window"": 1, ""definition"": [{ ""granularity"": ""10s"", ""points"": 20, }]} self.app.post_json( ""/v1/archive_policy"", params=params) self.app.post_json(""/v1/metric"", params={""archive_policy"": ap}) result = self.app.delete(""/v1/archive_policy/%s"" % ap, status=400) self.assertIn( b""Archive policy "" + ap + "" is still in use"", result.body) ",,72,2
openstack%2Fbarbican~master~Iea0b3653151b6a794c3ad60b815e53d6b2a74359,openstack/barbican,master,Iea0b3653151b6a794c3ad60b815e53d6b2a74359,Setting the max secret bit_length size to be 32767,MERGED,2014-12-17 20:11:57.000000000,2014-12-18 17:06:57.000000000,2014-12-18 17:06:56.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7789}, {'_account_id': 9234}]","[{'number': 1, 'created': '2014-12-17 20:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/858f18889db463b45c83b53c88e139297862ac47', 'message': 'Setting the max secret bit_length size to be 32767\n\nSetting the max size to be that of a MySQL signed small int.\n\nChange-Id: Iea0b3653151b6a794c3ad60b815e53d6b2a74359\nCloses-Bug: 1376019\n'}, {'number': 2, 'created': '2014-12-17 22:07:42.000000000', 'files': ['barbican/common/validators.py', 'functionaltests/api/v1/functional/test_orders.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/adb85962383c2e1d02b79e75a781d4e7483eaabc', 'message': 'Setting the max secret bit_length size to be 32767\n\nSetting the max size to be that of a MySQL signed small int.\n\nChange-Id: Iea0b3653151b6a794c3ad60b815e53d6b2a74359\nCloses-Bug: 1376019\n'}]",2,142568,adb85962383c2e1d02b79e75a781d4e7483eaabc,12,5,2,7262,,,0,"Setting the max secret bit_length size to be 32767

Setting the max size to be that of a MySQL signed small int.

Change-Id: Iea0b3653151b6a794c3ad60b815e53d6b2a74359
Closes-Bug: 1376019
",git fetch https://review.opendev.org/openstack/barbican refs/changes/68/142568/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/common/validators.py', 'functionaltests/api/v1/functional/test_orders.py']",2,858f18889db463b45c83b53c88e139297862ac47,bug/1376019," '1024': [1024], '2048': [2048], '4096': [4096] 'space': [' '], 'over_signed_small_int': [32768]", '16M_plus_256': [16777472] 'space': [' '],10,3
openstack%2Fzaqar~master~I26b095317e4aa16c23ee14f2465c71e7e6bd0de4,openstack/zaqar,master,I26b095317e4aa16c23ee14f2465c71e7e6bd0de4,Clean up pooling meta-controllers,MERGED,2014-11-05 19:34:25.000000000,2014-12-18 17:01:40.000000000,2014-12-18 17:01:39.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 13398}]","[{'number': 1, 'created': '2014-11-05 19:34:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/a0e419b31c46e5e0af4124212c95704864df5a95', 'message': 'Clean up pooling meta-controllers\n\nThis patch removes the virtually unused RoutingController class, and has\neach meta-controller inherit from its respective base storage class\ninstead.\n\nIt also adds get_{message,claim,queue}_controller methods to Catalog,\nwhich allows the removal of some duplicated code in the meta-controller\nmethods.\n\nChange-Id: I26b095317e4aa16c23ee14f2465c71e7e6bd0de4\n'}, {'number': 2, 'created': '2014-12-14 05:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/15c5b025df31b94fe49db5467dbb5d8af722bce3', 'message': 'Clean up pooling meta-controllers\n\nThis patch removes the virtually unused RoutingController class, and has\neach meta-controller inherit from its respective base storage class\ninstead.\n\nIt also adds get_{message,claim,queue}_controller methods to Catalog,\nwhich allows the removal of some duplicated code in the meta-controller\nmethods.\n\nChange-Id: I26b095317e4aa16c23ee14f2465c71e7e6bd0de4\n'}, {'number': 3, 'created': '2014-12-14 12:47:47.000000000', 'files': ['tests/unit/queues/storage/test_impl_sqlalchemy.py', 'tests/unit/queues/storage/test_impl_mongodb.py', 'zaqar/storage/pooling.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/db5f132f6cc1f94755587bf38afcdeb06156f08d', 'message': 'Clean up pooling meta-controllers\n\nThis patch removes the virtually unused RoutingController class, and has\neach meta-controller inherit from its respective base storage class\ninstead.\n\nIt also adds get_{message,claim,queue}_controller methods to Catalog,\nwhich allows the removal of some duplicated code in the meta-controller\nmethods.\n\nChange-Id: I26b095317e4aa16c23ee14f2465c71e7e6bd0de4\n'}]",0,132907,db5f132f6cc1f94755587bf38afcdeb06156f08d,22,4,3,13398,,,0,"Clean up pooling meta-controllers

This patch removes the virtually unused RoutingController class, and has
each meta-controller inherit from its respective base storage class
instead.

It also adds get_{message,claim,queue}_controller methods to Catalog,
which allows the removal of some duplicated code in the meta-controller
methods.

Change-Id: I26b095317e4aa16c23ee14f2465c71e7e6bd0de4
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/07/132907/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/queues/storage/test_impl_sqlalchemy.py', 'tests/unit/queues/storage/test_impl_mongodb.py', 'zaqar/queues/storage/pooling.py']",3,a0e419b31c46e5e0af4124212c95704864df5a95,bug/1351462,"class QueueController(storage.Queue): """"""Routes operations to a queue controller in the appropriate pool. :param pool_catalog: a catalog of available pools :type pool_catalog: queues.pooling.base.Catalog def __init__(self, pool_catalog): super(QueueController, self).__init__(None) self._get_controller = self._pool_catalog.get_queue_controller control = self._get_controller(name, project) if not control: return control.create(name, metadata=metadata, project=project) control = self._get_controller(name, project) if control: def exists(self, name, project=None): control = self._get_controller(name, project) if control: control = self._get_controller(name, project) if control: control = self._get_controller(name, project) if control: control = self._get_controller(name, project) if control:class MessageController(storage.Message): """"""Routes operations to a message controller in the appropriate pool. :param pool_catalog: a catalog of available pools :type pool_catalog: queues.pooling.base.Catalog """""" super(MessageController, self).__init__(None) self._pool_catalog = pool_catalog self._get_controller = self._pool_catalog.get_message_controller control = self._get_controller(queue, project) if control: control = self._get_controller(queue, project) if control: def bulk_delete(self, queue, message_ids, project=None): control = self._get_controller(queue, project) if control: control = self._get_controller(queue, project) if control: control = self._get_controller(queue, project) if control: control = self._get_controller(queue, project) if control: control = self._get_controller(queue, project) if control: control = self._get_controller(queue, project) if control:class ClaimController(storage.Claim): """"""Routes operations to a claim controller in the appropriate pool. :param pool_catalog: a catalog of available pools :type pool_catalog: queues.pooling.base.Catalog """""" super(ClaimController, self).__init__(None) self._pool_catalog = pool_catalog self._get_controller = self._pool_catalog.get_claim_controller control = self._get_controller(queue, project) if control: control = self._get_controller(queue, project) if control: control = self._get_controller(queue, project) if control: control = self._get_controller(queue, project) if control: def get_queue_controller(self, queue, project=None): """"""Lookup the queue controller for the given queue and project. :param queue: Name of the queue for which to find a pool :param project: Project to which the queue belongs, or None to specify the ""global"" or ""generic"" project. :returns: The queue controller associated with the data driver for the pool containing (queue, project) or None if this doesn't exist. :rtype: Maybe QueueController """""" target = self.lookup(queue, project) return target and target.queue_controller def get_message_controller(self, queue, project=None): """"""Lookup the message controller for the given queue and project. :param queue: Name of the queue for which to find a pool :param project: Project to which the queue belongs, or None to specify the ""global"" or ""generic"" project. :returns: The message controller associated with the data driver for the pool containing (queue, project) or None if this doesn't exist. :rtype: Maybe MessageController """""" target = self.lookup(queue, project) return target and target.message_controller def get_claim_controller(self, queue, project=None): """"""Lookup the claim controller for the given queue and project. :param queue: Name of the queue for which to find a pool :param project: Project to which the queue belongs, or None to specify the ""global"" or ""generic"" project. :returns: The claim controller associated with the data driver for the pool containing (queue, project) or None if this doesn't exist. :rtype: Maybe ClaimController """""" target = self.lookup(queue, project) return target and target.claim_controller ","class RoutingController(storage.base.ControllerBase): """"""Routes operations to the appropriate pool. This controller stands in for a regular storage controller, routing operations to a driver instance that represents the pool to which the queue has been assigned. Do not instantiate this class directly; use one of the more specific child classes instead. _resource_name = None def __init__(self, pool_catalog): super(RoutingController, self).__init__(None) self._ctrl_property_name = self._resource_name + '_controller' @decorators.memoized_getattr def __getattr__(self, name): # NOTE(kgriffs): Use a closure trick to avoid # some attr lookups each time forward() is called. lookup = self._pool_catalog.lookup # NOTE(kgriffs): Assume that every controller method # that is exposed to the transport declares queue name # as its first arg. The only exception to this # is QueueController.list def forward(queue, *args, **kwargs): # NOTE(kgriffs): Using .get since 'project' is an # optional argument. storage = lookup(queue, kwargs.get('project')) target_ctrl = getattr(storage, self._ctrl_property_name) return getattr(target_ctrl, name)(queue, *args, **kwargs) return forward class QueueController(RoutingController): """"""Controller to facilitate special processing for queue operations."""""" _resource_name = 'queue' def __init__(self, pool_catalog): super(QueueController, self).__init__(pool_catalog) self._lookup = self._pool_catalog.lookup target = self._lookup(name, project) if not target: return target.queue_controller.create(name, metadata=metadata, project=project) target = self._lookup(name, project) if target: control = target.queue_controller def exists(self, name, project=None, **kwargs): target = self._lookup(name, project) if target: control = target.queue_controller target = self._lookup(name, project) if target: control = target.queue_controller target = self._lookup(name, project) if target: control = target.queue_controller target = self._lookup(name, project) if target: control = target.queue_controllerclass MessageController(RoutingController): _resource_name = 'message' super(MessageController, self).__init__(pool_catalog) self._lookup = self._pool_catalog.lookup target = self._lookup(queue, project) if target: control = target.message_controller target = self._lookup(queue, project) if target: control = target.message_controller def bulk_delete(self, queue, message_ids=None, project=None): target = self._lookup(queue, project) if target: control = target.message_controller target = self._lookup(queue, project) if target: control = target.message_controller target = self._lookup(queue, project) if target: control = target.message_controller target = self._lookup(queue, project) if target: control = target.message_controller target = self._lookup(queue, project) if target: control = target.message_controller target = self._lookup(queue, project) if target: control = target.message_controllerclass ClaimController(RoutingController): _resource_name = 'claim' super(ClaimController, self).__init__(pool_catalog) self._lookup = self._pool_catalog.lookup target = self._lookup(queue, project) if target: control = target.claim_controller target = self._lookup(queue, project) if target: control = target.claim_controller target = self._lookup(queue, project) if target: control = target.claim_controller target = self._lookup(queue, project) if target: control = target.claim_controller",112,114
openstack%2Frally~master~I1a4f0b30dcfba08f8830448c99e687014282e094,openstack/rally,master,I1a4f0b30dcfba08f8830448c99e687014282e094,Add list_servers scenario for Nova,MERGED,2014-12-18 13:33:07.000000000,2014-12-18 16:54:20.000000000,2014-12-18 16:54:19.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 14135}, {'_account_id': 14138}]","[{'number': 1, 'created': '2014-12-18 13:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a3d7b2c867f7fbb7a1da7b06af426fa1d8757c99', 'message': 'Add list_servers scenario for Nova\n\nCurrent Rally provides ""boot_and_list_server"" scenario, but doesn\'t provide\n""list_servers"" scenario. User can specify number of servers which will be\ncreated in context.\n\nChange-Id: I1a4f0b30dcfba08f8830448c99e687014282e094\n'}, {'number': 2, 'created': '2014-12-18 14:25:26.000000000', 'files': ['rally/benchmark/scenarios/nova/servers.py', 'doc/samples/tasks/scenarios/nova/list-servers.json', 'rally/benchmark/context/servers.py', 'doc/samples/tasks/scenarios/nova/list-servers.yaml', 'tests/unit/benchmark/scenarios/nova/test_servers.py', 'rally-jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/99dc73af345b7b6b921a24fe39c516170a263d48', 'message': 'Add list_servers scenario for Nova\n\nCurrent Rally provides ""boot_and_list_server"" scenario, but doesn\'t provide\n""list_servers"" scenario. User can specify number of servers which will be\ncreated in context.\n\nChange-Id: I1a4f0b30dcfba08f8830448c99e687014282e094\n'}]",0,142779,99dc73af345b7b6b921a24fe39c516170a263d48,14,5,2,14138,,,0,"Add list_servers scenario for Nova

Current Rally provides ""boot_and_list_server"" scenario, but doesn't provide
""list_servers"" scenario. User can specify number of servers which will be
created in context.

Change-Id: I1a4f0b30dcfba08f8830448c99e687014282e094
",git fetch https://review.opendev.org/openstack/rally refs/changes/79/142779/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/samples/tasks/scenarios/nova/list-servers.json', 'rally/benchmark/context/servers.py', 'rally/benchmark/scenarios/nova/servers.py', 'doc/samples/tasks/scenarios/nova/list-servers.yaml', 'tests/unit/benchmark/scenarios/nova/test_servers.py']",5,a3d7b2c867f7fbb7a1da7b06af426fa1d8757c99,add_list_servers_scenario, def test_list_servers(self): scenario = servers.NovaServers() scenario._list_servers = mock.MagicMock() scenario.list_servers(True) scenario._list_servers.assert_called_once_with(True) ,,67,1
openstack%2Fglance-specs~master~If938e327ec08a7507133f7767fec74ebee3bfc33,openstack/glance-specs,master,If938e327ec08a7507133f7767fec74ebee3bfc33,Remove explicit cycle names,MERGED,2014-12-18 16:33:11.000000000,2014-12-18 16:51:53.000000000,2014-12-18 16:51:52.000000000,"[{'_account_id': 3}, {'_account_id': 2537}]","[{'number': 1, 'created': '2014-12-18 16:33:11.000000000', 'files': ['specs/kilo/create-glance-manage-conf.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/224ade269d6b81e04c64dd6533e0186d449180ce', 'message': 'Remove explicit cycle names\n\nChange-Id: If938e327ec08a7507133f7767fec74ebee3bfc33\n'}]",0,142832,224ade269d6b81e04c64dd6533e0186d449180ce,6,2,1,12000,,,0,"Remove explicit cycle names

Change-Id: If938e327ec08a7507133f7767fec74ebee3bfc33
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/32/142832/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/create-glance-manage-conf.rst'],1,224ade269d6b81e04c64dd6533e0186d449180ce,update-cycle-reference,"configure ``glance-manage.conf`` for a later cycle. In that cycle, we will stop depending on ``glance-registry.conf`` and ``glance-api.conf``. The","configure ``glance-manage.conf`` for the L cycle. In the L cycle, we will stop depending on ``glance-registry.conf`` and ``glance-api.conf``. The",2,2
openstack%2Fzaqar~master~I6da7c8e4dedc9722858f360b074611b904c8d131,openstack/zaqar,master,I6da7c8e4dedc9722858f360b074611b904c8d131,Expose pools and flavors in homedoc,MERGED,2014-12-11 07:35:01.000000000,2014-12-18 16:48:52.000000000,2014-12-18 16:48:50.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6484}]","[{'number': 1, 'created': '2014-12-11 07:35:01.000000000', 'files': ['zaqar/transport/wsgi/v1_1/homedoc.py', 'zaqar/transport/wsgi/v1_1/__init__.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/5684c2da22bcad0dfa84e791db17856336f5f5c3', 'message': 'Expose pools and flavors in homedoc\n\nPools and flavors were missing from our v1.1 homedoc. This patches adds\nthem just when admin_mode is enabled. To do so, the falcon resource now\naccepts a conf object.\n\nFollow up patches should make all resources accept a conf object, for\nthe sake of consistency.\n\nChange-Id: I6da7c8e4dedc9722858f360b074611b904c8d131\nCloses-bug: #1361275\n'}]",0,140969,5684c2da22bcad0dfa84e791db17856336f5f5c3,11,4,1,6159,,,0,"Expose pools and flavors in homedoc

Pools and flavors were missing from our v1.1 homedoc. This patches adds
them just when admin_mode is enabled. To do so, the falcon resource now
accepts a conf object.

Follow up patches should make all resources accept a conf object, for
the sake of consistency.

Change-Id: I6da7c8e4dedc9722858f360b074611b904c8d131
Closes-bug: #1361275
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/69/140969/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/transport/wsgi/v1_1/homedoc.py', 'zaqar/transport/wsgi/v1_1/__init__.py']",2,5684c2da22bcad0dfa84e791db17856336f5f5c3,bug/1361275," homedoc.Resource(conf)),"," homedoc.Resource()),",68,2
openstack%2Fneutron~master~I284b477ebaf8ec762264d219bb50d0567cd07bda,openstack/neutron,master,I284b477ebaf8ec762264d219bb50d0567cd07bda,test7,ABANDONED,2014-12-18 13:17:40.000000000,2014-12-18 16:42:17.000000000,,"[{'_account_id': 5170}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10153}]","[{'number': 1, 'created': '2014-12-18 13:17:40.000000000', 'files': ['neutron/api/test7'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e64f973a3f89c4ef4c53f18d6c4c161eb2753b61', 'message': 'test7\n\nChange-Id: I284b477ebaf8ec762264d219bb50d0567cd07bda\n'}]",0,142774,e64f973a3f89c4ef4c53f18d6c4c161eb2753b61,8,6,1,12441,,,0,"test7

Change-Id: I284b477ebaf8ec762264d219bb50d0567cd07bda
",git fetch https://review.opendev.org/openstack/neutron refs/changes/74/142774/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/test7'],1,e64f973a3f89c4ef4c53f18d6c4c161eb2753b61,mellanox-master,test ,,1,0
openstack%2Fcinder~master~I4febd485ff53936b636947c86773a23724e24c65,openstack/cinder,master,I4febd485ff53936b636947c86773a23724e24c65,DB migration tests,MERGED,2014-10-31 10:35:58.000000000,2014-12-18 16:42:13.000000000,2014-12-16 19:55:54.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10503}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11880}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 13636}, {'_account_id': 14102}]","[{'number': 1, 'created': '2014-10-31 10:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4773cc55ec83bc2db14e4d774f120674c3ce8ee3', 'message': 'WIP. DB migration tests\n\nImplements blueprint: db-migration-tests\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}, {'number': 2, 'created': '2014-11-04 17:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/52199fd17abc77b21e885bf05da50f1a1487aca1', 'message': 'WIP. DB migration tests\n\nImplements blueprint: db-migration-tests\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}, {'number': 3, 'created': '2014-11-05 13:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/58c4f7607e73566eb4dc7bd33bd121936a9b204a', 'message': 'WIP. DB migration tests\n\nImplements blueprint: db-migration-tests\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}, {'number': 4, 'created': '2014-11-24 22:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/23713f08234a1be5e68a5694f3dedde26351c31f', 'message': 'WIP. DB migration tests\n\nImplements blueprint: db-migration-tests\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}, {'number': 5, 'created': '2014-11-25 10:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ef7da5d3b6732d0e83fa8e0ba752704ba4af5ac', 'message': 'WIP. DB migration tests\n\nImplements blueprint: db-migration-tests\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}, {'number': 6, 'created': '2014-11-25 14:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6784243c9b1ce0be74840ed9a3fef3bfcd715926', 'message': 'WIP. DB migration tests\n\nImplements blueprint: db-migration-tests\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}, {'number': 7, 'created': '2014-11-25 14:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/488d30815ecd3a748a59ba5ac6dbb782e0b2771f', 'message': 'DB migration tests\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nImplements blueprint: db-migration-tests\nRelated-bug: #1266595\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}, {'number': 8, 'created': '2014-11-25 21:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b88dfcfa1f557993749ddbd065124c00c6a2d87f', 'message': 'DB migration tests\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nImplements blueprint: db-migration-tests\nRelated-bug: #1266595\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}, {'number': 9, 'created': '2014-11-26 13:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d8c73c17cd3b47d75e88bc1528e0dd464a70da1a', 'message': 'DB migration tests\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nImplements blueprint: db-migration-tests\nRelated-bug: #1266595\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}, {'number': 10, 'created': '2014-12-03 11:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c606aec2292a47b65bd36d46c6a0fdb1c6e72c3b', 'message': 'DB migration tests\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nImplements blueprint: db-migration-tests\nRelated-bug: #1266595\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}, {'number': 11, 'created': '2014-12-03 11:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3631e21c1721b8a4d340b071c549db578dc96080', 'message': 'DB migration tests\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nImplements blueprint: db-migration-tests\nRelated-bug: #1266595\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}, {'number': 12, 'created': '2014-12-15 10:57:16.000000000', 'files': ['cinder/test.py', 'cinder/tests/test_cmd.py', 'cinder/tests/test_migrations.conf', 'cinder/db/sqlalchemy/migrate_repo/versions/011_add_bootable_column.py', 'test-requirements.txt', 'cinder/cmd/manage.py', 'cinder/db/sqlalchemy/migration.py', 'setup.cfg', 'cinder/db/migration.py', 'cinder/db/sqlalchemy/migrate_repo/versions/001_cinder_init.py', 'cinder/tests/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9b94302d7b695dc25237a02e6c50ad1496b7c579', 'message': 'DB migration tests\n\nRefactored migration tests to use OpportunisticTestCase, removed\nunused code and ``test_migrations.conf`` file.\n\nThe main feature of this approach is to create a new database with\nrandom name for each migration test.  This will avoid migration tests of\nrace conditions and reduce tests intersection. After this change, database\n``openstack_citest`` will be used only for initial connection to the database.\n\n``test_migrations.conf`` file not required anymore, because we create test\ndatabase for migration test, so we no longer need to keep database credentials.\n\nImplements blueprint: db-migration-tests\nRelated-bug: #1266595\nChange-Id: I4febd485ff53936b636947c86773a23724e24c65\n'}]",4,132201,9b94302d7b695dc25237a02e6c50ad1496b7c579,98,19,12,1736,,,0,"DB migration tests

Refactored migration tests to use OpportunisticTestCase, removed
unused code and ``test_migrations.conf`` file.

The main feature of this approach is to create a new database with
random name for each migration test.  This will avoid migration tests of
race conditions and reduce tests intersection. After this change, database
``openstack_citest`` will be used only for initial connection to the database.

``test_migrations.conf`` file not required anymore, because we create test
database for migration test, so we no longer need to keep database credentials.

Implements blueprint: db-migration-tests
Related-bug: #1266595
Change-Id: I4febd485ff53936b636947c86773a23724e24c65
",git fetch https://review.opendev.org/openstack/cinder refs/changes/01/132201/10 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/db/sqlalchemy/migrate_repo/versions/011_add_bootable_column.py', 'cinder/db/sqlalchemy/migrate_repo/versions/001_cinder_init.py', 'cinder/tests/test_migrations.py']",3,4773cc55ec83bc2db14e4d774f120674c3ce8ee3,bug/1266595,"from oslo.db.sqlalchemy import test_migrations from oslo.db.sqlalchemy import test_base from oslo.db.sqlalchemy import utils as db_utils# def get_table(engine, name): # """"""Returns an sqlalchemy table dynamically from db. # # Needed because the models don't work for us in migrations # as models will be far out of sync with the current data. # """""" # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # return sqlalchemy.Table(name, metadata, autoload=True) class MigrationsMixin(test_migrations.WalkVersionsMixin): # MIGRATE_FILE = cinder.db.sqlalchemy.migrate_repo.__file__ # REPOSITORY = repository.Repository( # os.path.abspath(os.path.dirname(MIGRATE_FILE))) super(MigrationsMixin, self).setUp() @property def INIT_VERSION(self): return migration.db_initial_version() @property def REPOSITORY(self): migrate_file = cinder.db.sqlalchemy.migrate_repo.__file__ return repository.Repository( os.path.abspath(os.path.dirname(migrate_file))) @property def migration_api(self): return migration_api @property def migrate_engine(self): return self.engine # def test_mysql_connect_fail(self): # """"""Test for mysql connection failure. # # Test that we can trigger a mysql connection failure and we fail # gracefully to ensure we don't break people without mysql # """""" # if _is_mysql_avail(user=""openstack_cifail""): # self.fail(""Shouldn't have connected"") # # @testtools.skipUnless(_have_mysql(), ""mysql not available"") # def test_mysql_innodb(self): # """"""Test that table creation on mysql only builds InnoDB tables."""""" # # add this to the global lists to make reset work with it, it's removed # # automatically in tearDown so no need to clean it up here. # connect_string = _get_connect_string('mysql') # engine = sqlalchemy.create_engine(connect_string) # self.engines[""mysqlcitest""] = engine # self.test_databases[""mysqlcitest""] = connect_string # # # build a fully populated mysql database with all the tables # self._reset_databases() # self._walk_versions(engine, False, False) # # uri = _get_connect_string('mysql', database=""information_schema"") # connection = sqlalchemy.create_engine(uri).connect() # # # sanity check # total = connection.execute(""SELECT count(*) "" # ""from information_schema.TABLES "" # ""where TABLE_SCHEMA='openstack_citest'"") # self.assertGreater(total.scalar(), 0, # msg=""No tables found. Wrong schema?"") # # noninnodb = connection.execute(""SELECT count(*) "" # ""from information_schema.TABLES "" # ""where TABLE_SCHEMA='openstack_citest' "" # ""and ENGINE!='InnoDB' "" # ""and TABLE_NAME!='migrate_version'"") # count = noninnodb.scalar() # self.assertEqual(count, 0, ""%d non InnoDB tables created"" % count) # # def test_postgresql_connect_fail(self): # """"""Test connection failure on PostgrSQL. # # Test that we can trigger a postgres connection failure and we fail # gracefully to ensure we don't break people without postgres. # """""" # if _is_backend_avail('postgres', user=""openstack_cifail""): # self.fail(""Shouldn't have connected"") # # @testtools.skipUnless(_is_backend_avail('postgres'), # ""postgresql not available"") # def test_postgresql_opportunistically(self): # # add this to the global lists to make reset work with it, it's removed # # automatically in tearDown so no need to clean it up here. # connect_string = _get_connect_string(""postgres"") # engine = sqlalchemy.create_engine(connect_string) # self.engines[""postgresqlcitest""] = engine # self.test_databases[""postgresqlcitest""] = connect_string # # # build a fully populated postgresql database with all the tables # self._reset_databases() # self._walk_versions(engine, False, False) # def _pre_upgrade_004(self, engine): """"""Change volume types to UUID """""" volume_types = db_utils.get_table(engine, 'volume_types') volume_type_es = db_utils.get_table(engine, 'volume_type_extra_specs') volumes = db_utils.get_table(engine, 'volumes') volumes = db_utils.get_table(engine, 'volumes') volume_types = db_utils.get_table(engine, 'volume_types') vtes = db_utils.get_table(engine, 'volume_type_extra_specs') def _check_005(self, engine, data): volumes = db_utils.get_table(engine, 'volumes') self.assertIsInstance(volumes.c.source_volid.type, sqlalchemy.types.VARCHAR) def _check_006(self, engine, data): snapshots = db_utils.get_table(engine, 'snapshots') self.assertIsInstance(snapshots.c.provider_location.type, sqlalchemy.types.VARCHAR) def _post_downgrade_006(self, engine): snapshots = db_utils.get_table(engine, 'snapshots') self.assertNotIn('provider_location', snapshots.c) def _check_007(self, engine, data): snapshots = db_utils.get_table(engine, 'snapshots') volumes = db_utils.get_table(engine, 'volumes') fkey, = snapshots.c.volume_id.foreign_keys self.assertIsNotNone(fkey) def _post_downgrade_007(self, engine): snapshots = db_utils.get_table(engine, 'snapshots') self.assertEqual(0, len(snapshots.c.volume_id.foreign_keys)) def _pre_upgrade_008(self, engine): self.assertFalse(engine.dialect.has_table(engine.connect(), ""backups"")) def _check_008(self, engine, data): self.assertTrue(engine.dialect.has_table(engine.connect(), ""backups"")) backups = db_utils.get_table(engine, 'backups') # self.assertIsInstance(backups.c.created_at.type, # self.time_type[engine.name]) # self.assertIsInstance(backups.c.updated_at.type, # self.time_type[engine.name]) # self.assertIsInstance(backups.c.deleted_at.type, # self.time_type[engine.name]) # self.assertIsInstance(backups.c.deleted.type, # self.bool_type[engine.name]) self.assertIsInstance(backups.c.id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.volume_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.user_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.project_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.host.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.availability_zone.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.display_name.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.display_description.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.container.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.status.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.fail_reason.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.service_metadata.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.service.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.size.type, sqlalchemy.types.INTEGER) self.assertIsInstance(backups.c.object_count.type, sqlalchemy.types.INTEGER) def _check_009(self, engine, data): self.assertTrue(engine.dialect.has_table(engine.connect(), ""snapshot_metadata"")) snapshot_metadata = db_utils.get_table(engine, 'snapshot_metadata') # self.assertIsInstance(snapshot_metadata.c.created_at.type, # self.time_type[engine.name]) # self.assertIsInstance(snapshot_metadata.c.updated_at.type, # self.time_type[engine.name]) # self.assertIsInstance(snapshot_metadata.c.deleted_at.type, # self.time_type[engine.name]) # self.assertIsInstance(snapshot_metadata.c.deleted.type, # self.bool_type[engine.name]) # self.assertIsInstance(snapshot_metadata.c.deleted.type, # self.bool_type[engine.name]) self.assertIsInstance(snapshot_metadata.c.id.type, sqlalchemy.types.INTEGER) self.assertIsInstance(snapshot_metadata.c.snapshot_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(snapshot_metadata.c.key.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(snapshot_metadata.c.value.type, sqlalchemy.types.VARCHAR) def _post_downgrade_008(self, engine): self.assertFalse(engine.dialect.has_table(engine.connect(), ""snapshot_metadata"")) def _check_010(self, engine, data): self.assertTrue(engine.dialect.has_table(engine.connect(), ""transfers"")) transfers = db_utils.get_table(engine, 'transfers') # self.assertIsInstance(transfers.c.created_at.type, # self.time_type[engine.name]) # self.assertIsInstance(transfers.c.updated_at.type, # self.time_type[engine.name]) # self.assertIsInstance(transfers.c.deleted_at.type, # self.time_type[engine.name]) # self.assertIsInstance(transfers.c.deleted.type, # self.bool_type[engine.name]) self.assertIsInstance(transfers.c.id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(transfers.c.volume_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(transfers.c.display_name.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(transfers.c.salt.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(transfers.c.crypt_hash.type, sqlalchemy.types.VARCHAR) # self.assertIsInstance(transfers.c.expires_at.type, # self.time_type[engine.name]) def _post_downgrade_010(self, engine): self.assertFalse(engine.dialect.has_table(engine.connect(), ""transfers"")) def _check_011(self, engine, data): volumes = db_utils.get_table(engine, 'volumes') self.assertIn('bootable', volumes.c) # self.assertIsInstance(volumes.c.bootable.type, # self.bool_type[engine.name]) def _post_downgrade_011(self, engine): volumes = db_utils.get_table(engine, 'volumes') self.assertNotIn('bootable', volumes.c) # def test_migration_012(self): # """"""Test that adding attached_host column works correctly."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 11) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 12) # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertIsInstance(volumes.c.attached_host.type, # sqlalchemy.types.VARCHAR) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 11) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertNotIn('attached_host', volumes.c) # # def test_migration_013(self): # """"""Test that adding provider_geometry column works correctly."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 12) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 13) # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertIsInstance(volumes.c.provider_geometry.type, # sqlalchemy.types.VARCHAR) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 12) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertNotIn('provider_geometry', volumes.c) # # def test_migration_014(self): # """"""Test that adding _name_id column works correctly."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 13) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 14) # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertIsInstance(volumes.c._name_id.type, # sqlalchemy.types.VARCHAR) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 13) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertNotIn('_name_id', volumes.c) # # def test_migration_015(self): # """"""Test removing migrations table works correctly."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 15) # # self.assertFalse(engine.dialect.has_table(engine.connect(), # ""migrations"")) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 14) # # self.assertTrue(engine.dialect.has_table(engine.connect(), # ""migrations"")) # # def test_migration_016(self): # """"""Test that dropping xen storage manager tables works correctly."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 15) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 16) # self.assertFalse(engine.dialect.has_table(engine.connect(), # 'sm_flavors')) # self.assertFalse(engine.dialect.has_table(engine.connect(), # 'sm_backend_config')) # self.assertFalse(engine.dialect.has_table(engine.connect(), # 'sm_volume')) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 15) # self.assertTrue(engine.dialect.has_table(engine.connect(), # 'sm_flavors')) # self.assertTrue(engine.dialect.has_table(engine.connect(), # 'sm_backend_config')) # self.assertTrue(engine.dialect.has_table(engine.connect(), # 'sm_volume')) # # def test_migration_017(self): # """"""Test that added encryption information works correctly."""""" # # # upgrade schema # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 16) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 17) # # # encryption key UUID # volumes = sqlalchemy.Table('volumes', metadata, autoload=True) # self.assertIn('encryption_key_id', volumes.c) # self.assertIsInstance(volumes.c.encryption_key_id.type, # sqlalchemy.types.VARCHAR) # # snapshots = sqlalchemy.Table('snapshots', metadata, autoload=True) # self.assertIn('encryption_key_id', snapshots.c) # self.assertIsInstance(snapshots.c.encryption_key_id.type, # sqlalchemy.types.VARCHAR) # self.assertIn('volume_type_id', snapshots.c) # self.assertIsInstance(snapshots.c.volume_type_id.type, # sqlalchemy.types.VARCHAR) # # # encryption types table # encryption = sqlalchemy.Table('encryption', # metadata, # autoload=True) # self.assertIsInstance(encryption.c.volume_type_id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(encryption.c.cipher.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(encryption.c.key_size.type, # sqlalchemy.types.INTEGER) # self.assertIsInstance(encryption.c.provider.type, # sqlalchemy.types.VARCHAR) # # # downgrade schema # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 16) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # volumes = sqlalchemy.Table('volumes', metadata, autoload=True) # self.assertNotIn('encryption_key_id', volumes.c) # # snapshots = sqlalchemy.Table('snapshots', metadata, autoload=True) # self.assertNotIn('encryption_key_id', snapshots.c) # # self.assertFalse(engine.dialect.has_table(engine.connect(), # 'encryption')) # # def test_migration_018(self): # """"""Test that added qos_specs table works correctly."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 17) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 18) # self.assertTrue(engine.dialect.has_table( # engine.connect(), ""quality_of_service_specs"")) # qos_specs = sqlalchemy.Table('quality_of_service_specs', # metadata, # autoload=True) # self.assertIsInstance(qos_specs.c.created_at.type, # self.time_type[engine.name]) # self.assertIsInstance(qos_specs.c.updated_at.type, # self.time_type[engine.name]) # self.assertIsInstance(qos_specs.c.deleted_at.type, # self.time_type[engine.name]) # self.assertIsInstance(qos_specs.c.deleted.type, # self.bool_type[engine.name]) # self.assertIsInstance(qos_specs.c.id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(qos_specs.c.specs_id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(qos_specs.c.key.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(qos_specs.c.value.type, # sqlalchemy.types.VARCHAR) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 17) # # self.assertFalse(engine.dialect.has_table( # engine.connect(), ""quality_of_service_specs"")) # # def test_migration_019(self): # """"""Test that adding migration_status column works correctly."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 18) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 19) # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertIsInstance(volumes.c.migration_status.type, # sqlalchemy.types.VARCHAR) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 18) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertNotIn('migration_status', volumes.c) # # def test_migration_020(self): # """"""Test adding volume_admin_metadata table works correctly."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 19) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 20) # # self.assertTrue(engine.dialect.has_table(engine.connect(), # ""volume_admin_metadata"")) # volume_admin_metadata = sqlalchemy.Table('volume_admin_metadata', # metadata, # autoload=True) # # self.assertIsInstance(volume_admin_metadata.c.created_at.type, # self.time_type[engine.name]) # self.assertIsInstance(volume_admin_metadata.c.updated_at.type, # self.time_type[engine.name]) # self.assertIsInstance(volume_admin_metadata.c.deleted_at.type, # self.time_type[engine.name]) # self.assertIsInstance(volume_admin_metadata.c.deleted.type, # self.bool_type[engine.name]) # self.assertIsInstance(volume_admin_metadata.c.id.type, # sqlalchemy.types.INTEGER) # self.assertIsInstance(volume_admin_metadata.c.volume_id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(volume_admin_metadata.c.key.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(volume_admin_metadata.c.value.type, # sqlalchemy.types.VARCHAR) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 19) # # self.assertFalse(engine.dialect.has_table(engine.connect(), # ""volume_admin_metadata"")) # # def test_migration_021(self): # """"""Test adding default data for quota classes works correctly."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 20) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 21) # # quota_class_metadata = sqlalchemy.Table('quota_classes', # metadata, # autoload=True) # # num_defaults = quota_class_metadata.count().\ # where(quota_class_metadata.c.class_name == 'default').\ # execute().scalar() # # self.assertEqual(3, num_defaults) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 20) # # # Defaults should not be deleted during downgrade # num_defaults = quota_class_metadata.count().\ # where(quota_class_metadata.c.class_name == 'default').\ # execute().scalar() # # self.assertEqual(3, num_defaults) # # def test_migration_022(self): # """"""Test that adding disabled_reason column works correctly."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 21) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 22) # services = sqlalchemy.Table('services', # metadata, # autoload=True) # self.assertIsInstance(services.c.disabled_reason.type, # sqlalchemy.types.VARCHAR) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 21) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # services = sqlalchemy.Table('services', # metadata, # autoload=True) # self.assertNotIn('disabled_reason', services.c) # # def test_migration_023(self): # """"""Test that adding reservations index works correctly."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 22) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 23) # reservations = sqlalchemy.Table('reservations', # metadata, # autoload=True) # index_columns = [] # for idx in reservations.indexes: # if idx.name == 'reservations_deleted_expire_idx': # index_columns = idx.columns.keys() # break # # self.assertEqual(sorted(['deleted', 'expire']), # sorted(index_columns)) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 22) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # reservations = sqlalchemy.Table('reservations', # metadata, # autoload=True) # index_names = [idx.name for idx in reservations.indexes] # self.assertNotIn('reservations_deleted_expire_idx', index_names) # # def test_migration_024(self): # """"""Test adding replication columns to volume table."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 23) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 24) # # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertIsInstance(volumes.c.replication_status.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(volumes.c.replication_extended_status.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(volumes.c.replication_driver_data.type, # sqlalchemy.types.VARCHAR) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 23) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertNotIn('replication_status', volumes.c) # self.assertNotIn('replication_extended_status', volumes.c) # self.assertNotIn('replication_driver_data', volumes.c) # # def test_migration_025(self): # """"""Test adding table and columns for consistencygroups."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 24) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # # Upgrade # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 25) # # # Test consistencygroup_id is in Table volumes # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertIsInstance(volumes.c.consistencygroup_id.type, # sqlalchemy.types.VARCHAR) # # # Test cgsnapshot_id is in Table snapshots # snapshots = sqlalchemy.Table('snapshots', # metadata, # autoload=True) # self.assertIsInstance(snapshots.c.cgsnapshot_id.type, # sqlalchemy.types.VARCHAR) # # # Test Table consistencygroups exists # self.assertTrue(engine.dialect.has_table(engine.connect(), # ""consistencygroups"")) # consistencygroups = sqlalchemy.Table('consistencygroups', # metadata, # autoload=True) # # self.assertIsInstance(consistencygroups.c.created_at.type, # self.time_type[engine.name]) # self.assertIsInstance(consistencygroups.c.updated_at.type, # self.time_type[engine.name]) # self.assertIsInstance(consistencygroups.c.deleted_at.type, # self.time_type[engine.name]) # self.assertIsInstance(consistencygroups.c.deleted.type, # self.bool_type[engine.name]) # self.assertIsInstance(consistencygroups.c.id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(consistencygroups.c.user_id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(consistencygroups.c.project_id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(consistencygroups.c.host.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(consistencygroups.c.availability_zone.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(consistencygroups.c.name.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(consistencygroups.c.description.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(consistencygroups.c.volume_type_id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(consistencygroups.c.status.type, # sqlalchemy.types.VARCHAR) # # # Test Table cgsnapshots exists # self.assertTrue(engine.dialect.has_table(engine.connect(), # ""cgsnapshots"")) # cgsnapshots = sqlalchemy.Table('cgsnapshots', # metadata, # autoload=True) # # self.assertIsInstance(cgsnapshots.c.created_at.type, # self.time_type[engine.name]) # self.assertIsInstance(cgsnapshots.c.updated_at.type, # self.time_type[engine.name]) # self.assertIsInstance(cgsnapshots.c.deleted_at.type, # self.time_type[engine.name]) # self.assertIsInstance(cgsnapshots.c.deleted.type, # self.bool_type[engine.name]) # self.assertIsInstance(cgsnapshots.c.id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(cgsnapshots.c.user_id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(cgsnapshots.c.project_id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(cgsnapshots.c.consistencygroup_id.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(cgsnapshots.c.name.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(cgsnapshots.c.description.type, # sqlalchemy.types.VARCHAR) # self.assertIsInstance(cgsnapshots.c.status.type, # sqlalchemy.types.VARCHAR) # # # Verify foreign keys are created # fkey, = volumes.c.consistencygroup_id.foreign_keys # self.assertEqual(consistencygroups.c.id, fkey.column) # self.assertEqual(1, len(volumes.foreign_keys)) # # fkey, = snapshots.c.cgsnapshot_id.foreign_keys # self.assertEqual(cgsnapshots.c.id, fkey.column) # fkey, = snapshots.c.volume_id.foreign_keys # self.assertEqual(volumes.c.id, fkey.column) # # 2 foreign keys in Table snapshots # self.assertEqual(2, len(snapshots.foreign_keys)) # # # Downgrade # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 24) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # # Test consistencygroup_id is not in Table volumes # volumes = sqlalchemy.Table('volumes', # metadata, # autoload=True) # self.assertNotIn('consistencygroup_id', volumes.c) # # # Test cgsnapshot_id is not in Table snapshots # snapshots = sqlalchemy.Table('snapshots', # metadata, # autoload=True) # self.assertNotIn('cgsnapshot_id', snapshots.c) # # # Verify foreign keys are removed # self.assertEqual(0, len(volumes.foreign_keys)) # self.assertEqual(1, len(snapshots.foreign_keys)) # # volume_id foreign key is still in Table snapshots # fkey, = snapshots.c.volume_id.foreign_keys # self.assertEqual(volumes.c.id, fkey.column) # # # Test Table cgsnapshots doesn't exist any more # self.assertFalse(engine.dialect.has_table(engine.connect(), # ""cgsnapshots"")) # # # Test Table consistencygroups doesn't exist any more # self.assertFalse(engine.dialect.has_table(engine.connect(), # ""consistencygroups"")) # # def test_migration_026(self): # """"""Test adding default data for consistencygroups quota class."""""" # for (key, engine) in self.engines.items(): # migration_api.version_control(engine, # TestMigrations.REPOSITORY, # migration.db_initial_version()) # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 25) # metadata = sqlalchemy.schema.MetaData() # metadata.bind = engine # # quota_class_metadata = sqlalchemy.Table('quota_classes', # metadata, # autoload=True) # # num_defaults = quota_class_metadata.count().\ # where(quota_class_metadata.c.class_name == 'default').\ # execute().scalar() # # self.assertEqual(3, num_defaults) # # migration_api.upgrade(engine, TestMigrations.REPOSITORY, 26) # # num_defaults = quota_class_metadata.count().\ # where(quota_class_metadata.c.class_name == 'default').\ # execute().scalar() # # self.assertEqual(4, num_defaults) # # migration_api.downgrade(engine, TestMigrations.REPOSITORY, 25) # # # Defaults should not be deleted during downgrade # num_defaults = quota_class_metadata.count().\ # where(quota_class_metadata.c.class_name == 'default').\ # execute().scalar() # # self.assertEqual(4, num_defaults) class TestSqliteMigrations(test_base.DbTestCase, MigrationsMixin): def test_walk_versions(self): self.walk_versions(True, True)","# Copyright 2010-2011 OpenStack Foundation # All Rights Reserved. #def get_table(engine, name): """"""Returns an sqlalchemy table dynamically from db. Needed because the models don't work for us in migrations as models will be far out of sync with the current data. """""" metadata = sqlalchemy.schema.MetaData() metadata.bind = engine return sqlalchemy.Table(name, metadata, autoload=True) class TestMigrations(test.TestCase): MIGRATE_FILE = cinder.db.sqlalchemy.migrate_repo.__file__ REPOSITORY = repository.Repository( os.path.abspath(os.path.dirname(MIGRATE_FILE))) super(TestMigrations, self).setUp() # We start each test case with a completely blank slate. self._reset_databases() # We destroy the test data store between each test case, # and recreate it, which ensures that we have no side-effects # from the tests self.addCleanup(self._reset_databases) def _reset_databases(self): def execute_cmd(cmd=None): proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True) proc.communicate()[0] self.assertEqual(0, proc.returncode) for key, engine in self.engines.items(): conn_string = self.test_databases[key] conn_pieces = urlparse.urlparse(conn_string) engine.dispose() if conn_string.startswith('sqlite'): # We can just delete the SQLite database, which is # the easiest and cleanest solution db_path = conn_pieces.path.strip('/') if os.path.exists(db_path): os.unlink(db_path) # No need to recreate the SQLite DB. SQLite will # create it for us if it's not there... elif conn_string.startswith('mysql'): # We can execute the MySQL client to destroy and re-create # the MYSQL database, which is easier and less error-prone # than using SQLAlchemy to do this via MetaData...trust me. database = conn_pieces.path.strip('/') loc_pieces = conn_pieces.netloc.split('@') host = loc_pieces[1] auth_pieces = loc_pieces[0].split(':') user = auth_pieces[0] password = """" if len(auth_pieces) > 1: if auth_pieces[1].strip(): password = ""-p\""%s\"""" % auth_pieces[1] sql = (""drop database if exists %(database)s; create database "" ""%(database)s;"") % {'database': database} cmd = (""mysql -u \""%(user)s\"" %(password)s -h %(host)s "" ""-e \""%(sql)s\"""") % {'user': user, 'password': password, 'host': host, 'sql': sql} execute_cmd(cmd) elif conn_string.startswith('postgresql'): database = conn_pieces.path.strip('/') loc_pieces = conn_pieces.netloc.split('@') host = loc_pieces[1] auth_pieces = loc_pieces[0].split(':') user = auth_pieces[0] password = """" if len(auth_pieces) > 1: password = auth_pieces[1].strip() # note(krtaylor): File creation problems with tests in # venv using .pgpass authentication, changed to # PGPASSWORD environment variable which is no longer # planned to be deprecated os.environ['PGPASSWORD'] = password os.environ['PGUSER'] = user # note(boris-42): We must create and drop database, we can't # drop database which we have connected to, so for such # operations there is a special database template1. sqlcmd = (""psql -w -U %(user)s -h %(host)s -c"" "" '%(sql)s' -d template1"") sql = (""drop database if exists %(database)s;"") % {'database': database} droptable = sqlcmd % {'user': user, 'host': host, 'sql': sql} execute_cmd(droptable) sql = (""create database %(database)s;"") % {'database': database} createtable = sqlcmd % {'user': user, 'host': host, 'sql': sql} execute_cmd(createtable) os.unsetenv('PGPASSWORD') os.unsetenv('PGUSER') def test_walk_versions(self): """"""Test walk versions. Walks all version scripts for each tested database, ensuring that there are no errors in the version scripts for each engine """""" for key, engine in self.engines.items(): self._walk_versions(engine, self.snake_walk) def test_mysql_connect_fail(self): """"""Test for mysql connection failure. Test that we can trigger a mysql connection failure and we fail gracefully to ensure we don't break people without mysql """""" if _is_mysql_avail(user=""openstack_cifail""): self.fail(""Shouldn't have connected"") @testtools.skipUnless(_have_mysql(), ""mysql not available"") def test_mysql_innodb(self): """"""Test that table creation on mysql only builds InnoDB tables."""""" # add this to the global lists to make reset work with it, it's removed # automatically in tearDown so no need to clean it up here. connect_string = _get_connect_string('mysql') engine = sqlalchemy.create_engine(connect_string) self.engines[""mysqlcitest""] = engine self.test_databases[""mysqlcitest""] = connect_string # build a fully populated mysql database with all the tables self._reset_databases() self._walk_versions(engine, False, False) uri = _get_connect_string('mysql', database=""information_schema"") connection = sqlalchemy.create_engine(uri).connect() # sanity check total = connection.execute(""SELECT count(*) "" ""from information_schema.TABLES "" ""where TABLE_SCHEMA='openstack_citest'"") self.assertGreater(total.scalar(), 0, msg=""No tables found. Wrong schema?"") noninnodb = connection.execute(""SELECT count(*) "" ""from information_schema.TABLES "" ""where TABLE_SCHEMA='openstack_citest' "" ""and ENGINE!='InnoDB' "" ""and TABLE_NAME!='migrate_version'"") count = noninnodb.scalar() self.assertEqual(count, 0, ""%d non InnoDB tables created"" % count) def test_postgresql_connect_fail(self): """"""Test connection failure on PostgrSQL. Test that we can trigger a postgres connection failure and we fail gracefully to ensure we don't break people without postgres. """""" if _is_backend_avail('postgres', user=""openstack_cifail""): self.fail(""Shouldn't have connected"") @testtools.skipUnless(_is_backend_avail('postgres'), ""postgresql not available"") def test_postgresql_opportunistically(self): # add this to the global lists to make reset work with it, it's removed # automatically in tearDown so no need to clean it up here. connect_string = _get_connect_string(""postgres"") engine = sqlalchemy.create_engine(connect_string) self.engines[""postgresqlcitest""] = engine self.test_databases[""postgresqlcitest""] = connect_string # build a fully populated postgresql database with all the tables self._reset_databases() self._walk_versions(engine, False, False) def _walk_versions(self, engine=None, snake_walk=False, downgrade=True): # Determine latest version script from the repo, then # upgrade from 1 through to the latest, with no data # in the databases. This just checks that the schema itself # upgrades successfully. # Place the database under version control migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) self.assertEqual(migration.db_initial_version(), migration_api.db_version(engine, TestMigrations.REPOSITORY)) migration_api.upgrade(engine, TestMigrations.REPOSITORY, migration.db_initial_version() + 1) for version in xrange(migration.db_initial_version() + 2, TestMigrations.REPOSITORY.latest + 1): # upgrade -> downgrade -> upgrade self._migrate_up(engine, version, with_data=True) if snake_walk: self._migrate_down(engine, version - 1) self._migrate_up(engine, version) if downgrade: # Now walk it back down to 0 from the latest, testing # the downgrade paths. for version in reversed( xrange(migration.db_initial_version() + 1, TestMigrations.REPOSITORY.latest)): # downgrade -> upgrade -> downgrade self._migrate_down(engine, version) if snake_walk: self._migrate_up(engine, version + 1) self._migrate_down(engine, version) def _migrate_down(self, engine, version): migration_api.downgrade(engine, TestMigrations.REPOSITORY, version) self.assertEqual(version, migration_api.db_version(engine, TestMigrations.REPOSITORY)) def _migrate_up(self, engine, version, with_data=False): """"""Migrate up to a new version of the db. We allow for data insertion and post checks at every migration version with special _prerun_### and _check_### functions in the main test. """""" # NOTE(sdague): try block is here because it's impossible to debug # where a failed data migration happens otherwise try: if with_data: data = None prerun = getattr(self, ""_prerun_%3.3d"" % version, None) if prerun: data = prerun(engine) migration_api.upgrade(engine, TestMigrations.REPOSITORY, version) self.assertEqual( version, migration_api.db_version(engine, TestMigrations.REPOSITORY)) if with_data: check = getattr(self, ""_check_%3.3d"" % version, None) if check: check(engine, data) except Exception: raise # migration 004 - change volume types to UUID def _prerun_004(self, engine): volume_types = get_table(engine, 'volume_types') volume_type_es = get_table(engine, 'volume_type_extra_specs') volumes = get_table(engine, 'volumes') volumes = get_table(engine, 'volumes') volume_types = get_table(engine, 'volume_types') vtes = get_table(engine, 'volume_type_extra_specs') def test_migration_005(self): for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 4) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 5) volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertIsInstance(volumes.c.source_volid.type, sqlalchemy.types.VARCHAR) def _metadatas(self, upgrade_to, downgrade_to=None): for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, upgrade_to) if downgrade_to is not None: migration_api.downgrade( engine, TestMigrations.REPOSITORY, downgrade_to) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine yield metadata def metadatas_upgraded_to(self, revision): return self._metadatas(revision) def metadatas_downgraded_from(self, revision): return self._metadatas(revision, revision - 1) def test_upgrade_006_adds_provider_location(self): for metadata in self.metadatas_upgraded_to(6): snapshots = sqlalchemy.Table('snapshots', metadata, autoload=True) self.assertIsInstance(snapshots.c.provider_location.type, sqlalchemy.types.VARCHAR) def test_downgrade_006_removes_provider_location(self): for metadata in self.metadatas_downgraded_from(6): snapshots = sqlalchemy.Table('snapshots', metadata, autoload=True) self.assertNotIn('provider_location', snapshots.c) def test_upgrade_007_adds_fk(self): for metadata in self.metadatas_upgraded_to(7): snapshots = sqlalchemy.Table('snapshots', metadata, autoload=True) volumes = sqlalchemy.Table('volumes', metadata, autoload=True) fkey, = snapshots.c.volume_id.foreign_keys self.assertEqual(volumes.c.id, fkey.column) def test_downgrade_007_removes_fk(self): for metadata in self.metadatas_downgraded_from(7): snapshots = sqlalchemy.Table('snapshots', metadata, autoload=True) self.assertEqual(0, len(snapshots.c.volume_id.foreign_keys)) def test_migration_008(self): for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 7) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 8) self.assertTrue(engine.dialect.has_table(engine.connect(), ""backups"")) backups = sqlalchemy.Table('backups', metadata, autoload=True) self.assertIsInstance(backups.c.created_at.type, self.time_type[engine.name]) self.assertIsInstance(backups.c.updated_at.type, self.time_type[engine.name]) self.assertIsInstance(backups.c.deleted_at.type, self.time_type[engine.name]) self.assertIsInstance(backups.c.deleted.type, self.bool_type[engine.name]) self.assertIsInstance(backups.c.id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.volume_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.user_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.project_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.host.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.availability_zone.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.display_name.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.display_description.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.container.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.status.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.fail_reason.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.service_metadata.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.service.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(backups.c.size.type, sqlalchemy.types.INTEGER) self.assertIsInstance(backups.c.object_count.type, sqlalchemy.types.INTEGER) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 7) self.assertFalse(engine.dialect.has_table(engine.connect(), ""backups"")) def test_migration_009(self): for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 8) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 9) self.assertTrue(engine.dialect.has_table(engine.connect(), ""snapshot_metadata"")) snapshot_metadata = sqlalchemy.Table('snapshot_metadata', metadata, autoload=True) self.assertIsInstance(snapshot_metadata.c.created_at.type, self.time_type[engine.name]) self.assertIsInstance(snapshot_metadata.c.updated_at.type, self.time_type[engine.name]) self.assertIsInstance(snapshot_metadata.c.deleted_at.type, self.time_type[engine.name]) self.assertIsInstance(snapshot_metadata.c.deleted.type, self.bool_type[engine.name]) self.assertIsInstance(snapshot_metadata.c.deleted.type, self.bool_type[engine.name]) self.assertIsInstance(snapshot_metadata.c.id.type, sqlalchemy.types.INTEGER) self.assertIsInstance(snapshot_metadata.c.snapshot_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(snapshot_metadata.c.key.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(snapshot_metadata.c.value.type, sqlalchemy.types.VARCHAR) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 8) self.assertFalse(engine.dialect.has_table(engine.connect(), ""snapshot_metadata"")) def test_migration_010(self): for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 9) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 10) self.assertTrue(engine.dialect.has_table(engine.connect(), ""transfers"")) transfers = sqlalchemy.Table('transfers', metadata, autoload=True) self.assertIsInstance(transfers.c.created_at.type, self.time_type[engine.name]) self.assertIsInstance(transfers.c.updated_at.type, self.time_type[engine.name]) self.assertIsInstance(transfers.c.deleted_at.type, self.time_type[engine.name]) self.assertIsInstance(transfers.c.deleted.type, self.bool_type[engine.name]) self.assertIsInstance(transfers.c.id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(transfers.c.volume_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(transfers.c.display_name.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(transfers.c.salt.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(transfers.c.crypt_hash.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(transfers.c.expires_at.type, self.time_type[engine.name]) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 9) self.assertFalse(engine.dialect.has_table(engine.connect(), ""transfers"")) def test_migration_011(self): for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 10) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine volumes_v10 = sqlalchemy.Table('volumes', metadata, autoload=True) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 11) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine self.assertTrue(engine.dialect.has_table(engine.connect(), ""volumes"")) volumes = sqlalchemy.Table('volumes', metadata, autoload=True) # Make sure we didn't miss any columns in the upgrade for column in volumes_v10.c: self.assertTrue(volumes.c.__contains__(column.name)) self.assertIsInstance(volumes.c.bootable.type, self.bool_type[engine.name]) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 10) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertNotIn('bootable', volumes.c) # Make sure we put all the columns back for column in volumes_v10.c: self.assertTrue(volumes.c.__contains__(column.name)) def test_migration_012(self): """"""Test that adding attached_host column works correctly."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 11) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 12) volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertIsInstance(volumes.c.attached_host.type, sqlalchemy.types.VARCHAR) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 11) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertNotIn('attached_host', volumes.c) def test_migration_013(self): """"""Test that adding provider_geometry column works correctly."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 12) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 13) volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertIsInstance(volumes.c.provider_geometry.type, sqlalchemy.types.VARCHAR) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 12) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertNotIn('provider_geometry', volumes.c) def test_migration_014(self): """"""Test that adding _name_id column works correctly."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 13) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 14) volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertIsInstance(volumes.c._name_id.type, sqlalchemy.types.VARCHAR) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 13) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertNotIn('_name_id', volumes.c) def test_migration_015(self): """"""Test removing migrations table works correctly."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 15) self.assertFalse(engine.dialect.has_table(engine.connect(), ""migrations"")) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 14) self.assertTrue(engine.dialect.has_table(engine.connect(), ""migrations"")) def test_migration_016(self): """"""Test that dropping xen storage manager tables works correctly."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 15) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 16) self.assertFalse(engine.dialect.has_table(engine.connect(), 'sm_flavors')) self.assertFalse(engine.dialect.has_table(engine.connect(), 'sm_backend_config')) self.assertFalse(engine.dialect.has_table(engine.connect(), 'sm_volume')) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 15) self.assertTrue(engine.dialect.has_table(engine.connect(), 'sm_flavors')) self.assertTrue(engine.dialect.has_table(engine.connect(), 'sm_backend_config')) self.assertTrue(engine.dialect.has_table(engine.connect(), 'sm_volume')) def test_migration_017(self): """"""Test that added encryption information works correctly."""""" # upgrade schema for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 16) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 17) # encryption key UUID volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertIn('encryption_key_id', volumes.c) self.assertIsInstance(volumes.c.encryption_key_id.type, sqlalchemy.types.VARCHAR) snapshots = sqlalchemy.Table('snapshots', metadata, autoload=True) self.assertIn('encryption_key_id', snapshots.c) self.assertIsInstance(snapshots.c.encryption_key_id.type, sqlalchemy.types.VARCHAR) self.assertIn('volume_type_id', snapshots.c) self.assertIsInstance(snapshots.c.volume_type_id.type, sqlalchemy.types.VARCHAR) # encryption types table encryption = sqlalchemy.Table('encryption', metadata, autoload=True) self.assertIsInstance(encryption.c.volume_type_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(encryption.c.cipher.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(encryption.c.key_size.type, sqlalchemy.types.INTEGER) self.assertIsInstance(encryption.c.provider.type, sqlalchemy.types.VARCHAR) # downgrade schema migration_api.downgrade(engine, TestMigrations.REPOSITORY, 16) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertNotIn('encryption_key_id', volumes.c) snapshots = sqlalchemy.Table('snapshots', metadata, autoload=True) self.assertNotIn('encryption_key_id', snapshots.c) self.assertFalse(engine.dialect.has_table(engine.connect(), 'encryption')) def test_migration_018(self): """"""Test that added qos_specs table works correctly."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 17) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 18) self.assertTrue(engine.dialect.has_table( engine.connect(), ""quality_of_service_specs"")) qos_specs = sqlalchemy.Table('quality_of_service_specs', metadata, autoload=True) self.assertIsInstance(qos_specs.c.created_at.type, self.time_type[engine.name]) self.assertIsInstance(qos_specs.c.updated_at.type, self.time_type[engine.name]) self.assertIsInstance(qos_specs.c.deleted_at.type, self.time_type[engine.name]) self.assertIsInstance(qos_specs.c.deleted.type, self.bool_type[engine.name]) self.assertIsInstance(qos_specs.c.id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(qos_specs.c.specs_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(qos_specs.c.key.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(qos_specs.c.value.type, sqlalchemy.types.VARCHAR) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 17) self.assertFalse(engine.dialect.has_table( engine.connect(), ""quality_of_service_specs"")) def test_migration_019(self): """"""Test that adding migration_status column works correctly."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 18) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 19) volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertIsInstance(volumes.c.migration_status.type, sqlalchemy.types.VARCHAR) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 18) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertNotIn('migration_status', volumes.c) def test_migration_020(self): """"""Test adding volume_admin_metadata table works correctly."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 19) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 20) self.assertTrue(engine.dialect.has_table(engine.connect(), ""volume_admin_metadata"")) volume_admin_metadata = sqlalchemy.Table('volume_admin_metadata', metadata, autoload=True) self.assertIsInstance(volume_admin_metadata.c.created_at.type, self.time_type[engine.name]) self.assertIsInstance(volume_admin_metadata.c.updated_at.type, self.time_type[engine.name]) self.assertIsInstance(volume_admin_metadata.c.deleted_at.type, self.time_type[engine.name]) self.assertIsInstance(volume_admin_metadata.c.deleted.type, self.bool_type[engine.name]) self.assertIsInstance(volume_admin_metadata.c.id.type, sqlalchemy.types.INTEGER) self.assertIsInstance(volume_admin_metadata.c.volume_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(volume_admin_metadata.c.key.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(volume_admin_metadata.c.value.type, sqlalchemy.types.VARCHAR) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 19) self.assertFalse(engine.dialect.has_table(engine.connect(), ""volume_admin_metadata"")) def test_migration_021(self): """"""Test adding default data for quota classes works correctly."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 20) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 21) quota_class_metadata = sqlalchemy.Table('quota_classes', metadata, autoload=True) num_defaults = quota_class_metadata.count().\ where(quota_class_metadata.c.class_name == 'default').\ execute().scalar() self.assertEqual(3, num_defaults) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 20) # Defaults should not be deleted during downgrade num_defaults = quota_class_metadata.count().\ where(quota_class_metadata.c.class_name == 'default').\ execute().scalar() self.assertEqual(3, num_defaults) def test_migration_022(self): """"""Test that adding disabled_reason column works correctly."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 21) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 22) services = sqlalchemy.Table('services', metadata, autoload=True) self.assertIsInstance(services.c.disabled_reason.type, sqlalchemy.types.VARCHAR) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 21) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine services = sqlalchemy.Table('services', metadata, autoload=True) self.assertNotIn('disabled_reason', services.c) def test_migration_023(self): """"""Test that adding reservations index works correctly."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 22) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 23) reservations = sqlalchemy.Table('reservations', metadata, autoload=True) index_columns = [] for idx in reservations.indexes: if idx.name == 'reservations_deleted_expire_idx': index_columns = idx.columns.keys() break self.assertEqual(sorted(['deleted', 'expire']), sorted(index_columns)) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 22) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine reservations = sqlalchemy.Table('reservations', metadata, autoload=True) index_names = [idx.name for idx in reservations.indexes] self.assertNotIn('reservations_deleted_expire_idx', index_names) def test_migration_024(self): """"""Test adding replication columns to volume table."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 23) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine migration_api.upgrade(engine, TestMigrations.REPOSITORY, 24) volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertIsInstance(volumes.c.replication_status.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(volumes.c.replication_extended_status.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(volumes.c.replication_driver_data.type, sqlalchemy.types.VARCHAR) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 23) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertNotIn('replication_status', volumes.c) self.assertNotIn('replication_extended_status', volumes.c) self.assertNotIn('replication_driver_data', volumes.c) def test_migration_025(self): """"""Test adding table and columns for consistencygroups."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 24) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine # Upgrade migration_api.upgrade(engine, TestMigrations.REPOSITORY, 25) # Test consistencygroup_id is in Table volumes volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertIsInstance(volumes.c.consistencygroup_id.type, sqlalchemy.types.VARCHAR) # Test cgsnapshot_id is in Table snapshots snapshots = sqlalchemy.Table('snapshots', metadata, autoload=True) self.assertIsInstance(snapshots.c.cgsnapshot_id.type, sqlalchemy.types.VARCHAR) # Test Table consistencygroups exists self.assertTrue(engine.dialect.has_table(engine.connect(), ""consistencygroups"")) consistencygroups = sqlalchemy.Table('consistencygroups', metadata, autoload=True) self.assertIsInstance(consistencygroups.c.created_at.type, self.time_type[engine.name]) self.assertIsInstance(consistencygroups.c.updated_at.type, self.time_type[engine.name]) self.assertIsInstance(consistencygroups.c.deleted_at.type, self.time_type[engine.name]) self.assertIsInstance(consistencygroups.c.deleted.type, self.bool_type[engine.name]) self.assertIsInstance(consistencygroups.c.id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(consistencygroups.c.user_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(consistencygroups.c.project_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(consistencygroups.c.host.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(consistencygroups.c.availability_zone.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(consistencygroups.c.name.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(consistencygroups.c.description.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(consistencygroups.c.volume_type_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(consistencygroups.c.status.type, sqlalchemy.types.VARCHAR) # Test Table cgsnapshots exists self.assertTrue(engine.dialect.has_table(engine.connect(), ""cgsnapshots"")) cgsnapshots = sqlalchemy.Table('cgsnapshots', metadata, autoload=True) self.assertIsInstance(cgsnapshots.c.created_at.type, self.time_type[engine.name]) self.assertIsInstance(cgsnapshots.c.updated_at.type, self.time_type[engine.name]) self.assertIsInstance(cgsnapshots.c.deleted_at.type, self.time_type[engine.name]) self.assertIsInstance(cgsnapshots.c.deleted.type, self.bool_type[engine.name]) self.assertIsInstance(cgsnapshots.c.id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(cgsnapshots.c.user_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(cgsnapshots.c.project_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(cgsnapshots.c.consistencygroup_id.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(cgsnapshots.c.name.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(cgsnapshots.c.description.type, sqlalchemy.types.VARCHAR) self.assertIsInstance(cgsnapshots.c.status.type, sqlalchemy.types.VARCHAR) # Verify foreign keys are created fkey, = volumes.c.consistencygroup_id.foreign_keys self.assertEqual(consistencygroups.c.id, fkey.column) self.assertEqual(1, len(volumes.foreign_keys)) fkey, = snapshots.c.cgsnapshot_id.foreign_keys self.assertEqual(cgsnapshots.c.id, fkey.column) fkey, = snapshots.c.volume_id.foreign_keys self.assertEqual(volumes.c.id, fkey.column) # 2 foreign keys in Table snapshots self.assertEqual(2, len(snapshots.foreign_keys)) # Downgrade migration_api.downgrade(engine, TestMigrations.REPOSITORY, 24) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine # Test consistencygroup_id is not in Table volumes volumes = sqlalchemy.Table('volumes', metadata, autoload=True) self.assertNotIn('consistencygroup_id', volumes.c) # Test cgsnapshot_id is not in Table snapshots snapshots = sqlalchemy.Table('snapshots', metadata, autoload=True) self.assertNotIn('cgsnapshot_id', snapshots.c) # Verify foreign keys are removed self.assertEqual(0, len(volumes.foreign_keys)) self.assertEqual(1, len(snapshots.foreign_keys)) # volume_id foreign key is still in Table snapshots fkey, = snapshots.c.volume_id.foreign_keys self.assertEqual(volumes.c.id, fkey.column) # Test Table cgsnapshots doesn't exist any more self.assertFalse(engine.dialect.has_table(engine.connect(), ""cgsnapshots"")) # Test Table consistencygroups doesn't exist any more self.assertFalse(engine.dialect.has_table(engine.connect(), ""consistencygroups"")) def test_migration_026(self): """"""Test adding default data for consistencygroups quota class."""""" for (key, engine) in self.engines.items(): migration_api.version_control(engine, TestMigrations.REPOSITORY, migration.db_initial_version()) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 25) metadata = sqlalchemy.schema.MetaData() metadata.bind = engine quota_class_metadata = sqlalchemy.Table('quota_classes', metadata, autoload=True) num_defaults = quota_class_metadata.count().\ where(quota_class_metadata.c.class_name == 'default').\ execute().scalar() self.assertEqual(3, num_defaults) migration_api.upgrade(engine, TestMigrations.REPOSITORY, 26) num_defaults = quota_class_metadata.count().\ where(quota_class_metadata.c.class_name == 'default').\ execute().scalar() self.assertEqual(4, num_defaults) migration_api.downgrade(engine, TestMigrations.REPOSITORY, 25) # Defaults should not be deleted during downgrade num_defaults = quota_class_metadata.count().\ where(quota_class_metadata.c.class_name == 'default').\ execute().scalar() self.assertEqual(4, num_defaults) ",829,1067
openstack%2Ffuel-web~master~Iae11de9bd56cfe2326f44849a9208c5681bb68ef,openstack/fuel-web,master,Iae11de9bd56cfe2326f44849a9208c5681bb68ef,"Revert ""Revert ""Bump up lodash version to 2.4.1""""",MERGED,2014-12-17 09:30:27.000000000,2014-12-18 16:40:49.000000000,2014-12-18 16:40:49.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}]","[{'number': 1, 'created': '2014-12-17 09:30:27.000000000', 'files': ['nailgun/static/js/libs/custom/backbone-lodash-monkeypatch.js', 'nailgun/bower.json', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/nodes_tab_subviews.jsx', 'nailgun/static/js/utils.js', 'nailgun/ui_tests/test_cluster_network.js', 'nailgun/static/js/config.js', 'nailgun/static/js/main.js', 'nailgun/static/js/models.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7fb4318e5ab42f3bf36c061bc95e88848e8fc1de', 'message': 'Revert ""Revert ""Bump up lodash version to 2.4.1""""\n\nThis reverts commit 2eb7ed75daa1f7ff8c89d2cc5667c1b13e983167.\n\nAnother attempt to merge lodash version bumpup. It seems to work\nfor Firefox after all.\n\nChange-Id: Iae11de9bd56cfe2326f44849a9208c5681bb68ef\nCloses-Bug: #1281076\n'}]",0,142390,7fb4318e5ab42f3bf36c061bc95e88848e8fc1de,10,5,1,13445,,,0,"Revert ""Revert ""Bump up lodash version to 2.4.1""""

This reverts commit 2eb7ed75daa1f7ff8c89d2cc5667c1b13e983167.

Another attempt to merge lodash version bumpup. It seems to work
for Firefox after all.

Change-Id: Iae11de9bd56cfe2326f44849a9208c5681bb68ef
Closes-Bug: #1281076
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/90/142390/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/libs/custom/backbone-lodash-monkeypatch.js', 'nailgun/bower.json', 'nailgun/static/js/utils.js', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/nodes_tab_subviews.jsx', 'nailgun/ui_tests/test_cluster_network.js', 'nailgun/static/js/config.js', 'nailgun/static/js/main.js', 'nailgun/static/js/models.js']",8,7fb4318e5ab42f3bf36c061bc95e88848e8fc1de,bug/1281076,"define(['underscore', 'utils', 'expression', 'deepModel'], function(_, utils, Expression) {","define(['utils', 'expression', 'deepModel'], function(utils, Expression) {",64,8
openstack%2Fopenstack-ansible~stable%2Ficehouse~I5b42c85bf87b4032334177f7411fb4527860a19f,openstack/openstack-ansible,stable/icehouse,I5b42c85bf87b4032334177f7411fb4527860a19f,Change MariaDB repo from JMU to OSU,MERGED,2014-12-18 11:00:07.000000000,2014-12-18 16:40:13.000000000,2014-12-18 16:40:13.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-18 11:00:07.000000000', 'files': ['rpc_deployment/vars/repo_packages/all_common.yml', 'rpc_deployment/inventory/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0b46b11178738afc18e337c877d21dae014f11e1', 'message': ""Change MariaDB repo from JMU to OSU\n\nThis patch changes the MariaDB repository used from JMU to OSU, which\nappears to be the primary source repository for all mirrors.\n\nThis has become necessary due to JMU's mirror being unavailable due to\nmaintenance.\n\nChange-Id: I5b42c85bf87b4032334177f7411fb4527860a19f\nCloses-Bug: #1403795\n(cherry picked from commit ae07f1a08cb56d98a8d5043db9b71569532970bc)\n""}]",0,142730,0b46b11178738afc18e337c877d21dae014f11e1,9,5,1,7307,,,0,"Change MariaDB repo from JMU to OSU

This patch changes the MariaDB repository used from JMU to OSU, which
appears to be the primary source repository for all mirrors.

This has become necessary due to JMU's mirror being unavailable due to
maintenance.

Change-Id: I5b42c85bf87b4032334177f7411fb4527860a19f
Closes-Bug: #1403795
(cherry picked from commit ae07f1a08cb56d98a8d5043db9b71569532970bc)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/30/142730/1 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/vars/repo_packages/all_common.yml', 'rpc_deployment/inventory/group_vars/all.yml']",2,0b46b11178738afc18e337c877d21dae014f11e1,bug/1403795," - { repo: ""deb http://ftp.osuosl.org/pub/mariadb/repo/5.5/ubuntu {{ ansible_distribution_release }} main"", state: ""present"" }"," - { repo: ""deb http://mirror.jmu.edu/pub/mariadb/repo/5.5/ubuntu {{ ansible_distribution_release }} main"", state: ""present"" }",2,2
openstack%2Fzaqar~master~I9f21fde548f60e9bd450e63f03857e9c743c205f,openstack/zaqar,master,I9f21fde548f60e9bd450e63f03857e9c743c205f,Temporally remove Sphinx from test-requirements-py3,MERGED,2014-12-18 15:08:02.000000000,2014-12-18 16:40:11.000000000,2014-12-18 16:40:09.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-12-18 15:08:02.000000000', 'files': ['test-requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9fdc3933879e3734dfbe570cb01a8c0cd3ed527b', 'message': 'Temporally remove Sphinx from test-requirements-py3\n\nAn untranslated version of Docutils is being run in the py33 gate.\nDisabling Sphinx from our requirements is a simple workaround for\nthis issue, until a new pbr is released.\n\nChange-Id: I9f21fde548f60e9bd450e63f03857e9c743c205f\nCloses-Bug: #1403510\n'}]",0,142812,9fdc3933879e3734dfbe570cb01a8c0cd3ed527b,6,2,1,6413,,,0,"Temporally remove Sphinx from test-requirements-py3

An untranslated version of Docutils is being run in the py33 gate.
Disabling Sphinx from our requirements is a simple workaround for
this issue, until a new pbr is released.

Change-Id: I9f21fde548f60e9bd450e63f03857e9c743c205f
Closes-Bug: #1403510
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/12/142812/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements-py3.txt'],1,9fdc3933879e3734dfbe570cb01a8c0cd3ed527b,bug/1403510,"# NOTE(vkmc) sphinx modules are commented out as a workaround for bug #1403510 # sphinx>=1.1.2,!=1.2.0,!=1.3b1,<1.3 # oslosphinx>=2.2.0 # Apache-2.0","sphinx>=1.1.2,!=1.2.0,!=1.3b1,<1.3 oslosphinx>=2.2.0 # Apache-2.0",3,2
openstack%2Fnova-specs~master~I15fe09c03263f2678733bf7570fd55d4cd4c984d,openstack/nova-specs,master,I15fe09c03263f2678733bf7570fd55d4cd4c984d,Change the handling for volume operation timeouts,ABANDONED,2014-12-18 16:20:01.000000000,2014-12-18 16:35:45.000000000,,[{'_account_id': 6873}],"[{'number': 1, 'created': '2014-12-18 16:20:01.000000000', 'files': ['specs/kilo/approved/volume-status-polling-nova.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/059d95ecce343d2e9fb4428868ab8d4861610a3f', 'message': 'Change the handling for volume operation timeouts\n\nMoved the spec from the wrong folder ../ to here.\n\nChange-Id: I15fe09c03263f2678733bf7570fd55d4cd4c984d\n'}]",0,142828,059d95ecce343d2e9fb4428868ab8d4861610a3f,3,1,1,10851,,,0,"Change the handling for volume operation timeouts

Moved the spec from the wrong folder ../ to here.

Change-Id: I15fe09c03263f2678733bf7570fd55d4cd4c984d
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/28/142828/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/volume-status-polling-nova.rst'],1,059d95ecce343d2e9fb4428868ab8d4861610a3f,,"This recall can happen as often if wanted. As a reply the callerA configuration shall determine how often a recall shall be possible. It shall be possible to configure no recall, to have the excact behaviour as without the solution proposed by this blueprint, or to configure unlimited number of recalls (as long as there are finishing requests, the backend is still alive), or to configure a certain amount, e.g. 10 recalls are allowed.http://review.openstack.org/#/c135367/",This recall can happen as often as wanted. As a reply Nova,8,1
openstack%2Fpuppet-keystone~master~Ia8dc346600e21546c40a2b52fead9fe673f00557,openstack/puppet-keystone,master,Ia8dc346600e21546c40a2b52fead9fe673f00557,Use openstackclient for keystone_service,ABANDONED,2014-12-18 15:44:46.000000000,2014-12-18 16:35:35.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-18 15:44:46.000000000', 'files': ['lib/puppet/provider/keystone_service/openstack.rb', 'lib/puppet/type/keystone_service.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/850aa4b8c962b5ba7c3871f453a7dfaa9d4561f0', 'message': 'Use openstackclient for keystone_service\n\nChange-Id: Ia8dc346600e21546c40a2b52fead9fe673f00557\n'}]",0,142821,850aa4b8c962b5ba7c3871f453a7dfaa9d4561f0,3,1,1,9983,,,0,"Use openstackclient for keystone_service

Change-Id: Ia8dc346600e21546c40a2b52fead9fe673f00557
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/21/142821/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/keystone_service/openstack.rb', 'lib/puppet/type/keystone_service.rb']",2,850aa4b8c962b5ba7c3871f453a7dfaa9d4561f0,service-openstackclient,"require 'puppet/util/openstack' auth_param_doc=<<EOT If no other credentials are present, the provider will search in /etc/keystone/keystone.conf for an admin token and auth url. EOT Puppet::Util::Openstack.add_aviator_params(self, auth_param_doc)",,18,18
openstack%2Fbarbican~master~Iab6699e300e9688f26dd39d0c947c9a45fb3384f,openstack/barbican,master,Iab6699e300e9688f26dd39d0c947c9a45fb3384f,Delete secret from plugin only if there's metadata,MERGED,2014-12-16 02:30:01.000000000,2014-12-18 16:33:55.000000000,2014-12-18 16:33:53.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-12-16 02:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/5806769bdb71ad077771af9ba7a6e0f1d5946a08', 'message': ""Delete secret from plugin only if there's metadata\n\nIf for some reason there is no metadata available for a certain\nsecret, the secret deletion will fail, as it tries to delete it from\nthe plugin first. This change makes that optional. Thus, now a secret\nwith no metadata will either way be deleted from the database.\n\nChange-Id: Iab6699e300e9688f26dd39d0c947c9a45fb3384f\nCloses-Bug: 1377330\n""}, {'number': 2, 'created': '2014-12-16 02:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/a91986aa7a524e68fb7b1899fb0fe4814562c216', 'message': ""Delete secret from plugin only if there's metadata\n\nIf for some reason there is no metadata available for a certain\nsecret, the secret deletion will fail, as it tries to delete it from\nthe plugin first. This change makes that optional. Thus, now a secret\nwith no metadata will either way be deleted from the database.\n\nChange-Id: Iab6699e300e9688f26dd39d0c947c9a45fb3384f\nCloses-Bug: 1377330\n""}, {'number': 3, 'created': '2014-12-17 23:56:48.000000000', 'files': ['barbican/plugin/resources.py', 'functionaltests/api/v1/smoke/test_secrets.py', 'barbican/tests/plugin/test_resource.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/3c87f9aab71e7737d98df22db2e000b4c3d58bcb', 'message': ""Delete secret from plugin only if there's metadata\n\nIf for some reason there is no metadata available for a certain\nsecret, the secret deletion will fail, as it tries to delete it from\nthe plugin first. This change makes that optional. Thus, now a secret\nwith no metadata will either way be deleted from the database.\n\nChange-Id: Iab6699e300e9688f26dd39d0c947c9a45fb3384f\nCloses-Bug: 1377330\n""}]",9,141963,3c87f9aab71e7737d98df22db2e000b4c3d58bcb,23,14,3,10873,,,0,"Delete secret from plugin only if there's metadata

If for some reason there is no metadata available for a certain
secret, the secret deletion will fail, as it tries to delete it from
the plugin first. This change makes that optional. Thus, now a secret
with no metadata will either way be deleted from the database.

Change-Id: Iab6699e300e9688f26dd39d0c947c9a45fb3384f
Closes-Bug: 1377330
",git fetch https://review.opendev.org/openstack/barbican refs/changes/63/141963/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/plugin/resources.py'],1,5806769bdb71ad077771af9ba7a6e0f1d5946a08,bug/1377330, # We should only try to delete a secret using the plugin interface if # there's the metadata available. This addresses bug/1377330. if secret_metadata: # Locate a suitable plugin to delete the secret from. plugin_manager = secret_store.SecretStorePluginManager() delete_plugin = plugin_manager.get_plugin_retrieve_delete( secret_metadata.get('plugin_name')) # Delete the secret from plugin storage. delete_plugin.delete_secret(secret_metadata), # Locate a suitable plugin to delete the secret from. plugin_manager = secret_store.SecretStorePluginManager() delete_plugin = plugin_manager.get_plugin_retrieve_delete( secret_metadata.get('plugin_name')) # Delete the secret from plugin storage. delete_plugin.delete_secret(secret_metadata),9,6
openstack%2Fgnocchi~master~I1679a2ca42e587888bc9b88e7cf8974a063cb96f,openstack/gnocchi,master,I1679a2ca42e587888bc9b88e7cf8974a063cb96f,Remove mox from import exceptions,MERGED,2014-12-09 15:58:36.000000000,2014-12-18 16:33:46.000000000,2014-12-18 16:33:44.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-12-09 15:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/506d033bd72b7a3fa07162f18bad66579c1dcc73', 'message': ""Remove mox from import exceptions\n\nWe don't use it.\n\nChange-Id: I1679a2ca42e587888bc9b88e7cf8974a063cb96f\n""}, {'number': 2, 'created': '2014-12-11 13:43:52.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7e341ad6326c575e21fa75d314985808ef44cea8', 'message': ""Remove mox from import exceptions\n\nWe don't use it.\n\nChange-Id: I1679a2ca42e587888bc9b88e7cf8974a063cb96f\n""}]",0,140385,7e341ad6326c575e21fa75d314985808ef44cea8,8,2,2,1669,,,0,"Remove mox from import exceptions

We don't use it.

Change-Id: I1679a2ca42e587888bc9b88e7cf8974a063cb96f
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/85/140385/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,506d033bd72b7a3fa07162f18bad66579c1dcc73,jd/remove-mox-from-tox,, six.moves.mox,0,1
openstack%2Fceilometer~master~Ib9579417cd0654b790cc0b3c111b06e4dcecf728,openstack/ceilometer,master,Ib9579417cd0654b790cc0b3c111b06e4dcecf728,"Revert ""Skip to poll and publish when no resources found""",MERGED,2014-12-17 12:59:53.000000000,2014-12-18 16:25:22.000000000,2014-12-18 15:21:46.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 7729}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-17 12:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9fcbc4e753848842018d1ba1aa823499887630dc', 'message': 'Revert ""Skip to poll and publish when no resources found""\n\nWe revert commit 934a90d4c61ff66f99e5a46480047dec355b5d61\nas it doesn\'t take into account that pollsters may have no\nexpectation of an explicit resource list, such as in the\nIPMI case.\n\nChange-Id: Ib9579417cd0654b790cc0b3c111b06e4dcecf728\nCloses-Bug: #1403280\n'}, {'number': 2, 'created': '2014-12-18 10:47:16.000000000', 'files': ['ceilometer/tests/agent/agentbase.py', 'ceilometer/agent/base.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/817314e7266ece5020de0fa989f89f2ff4c05889', 'message': 'Revert ""Skip to poll and publish when no resources found""\n\nWe revert commit 934a90d4c61ff66f99e5a46480047dec355b5d61\nas it doesn\'t take into account that pollsters may have no\nexpectation of an explicit resource list, such as in the\nIPMI case.\n\nChange-Id: Ib9579417cd0654b790cc0b3c111b06e4dcecf728\nCloses-Bug: #1403280\n'}]",0,142435,817314e7266ece5020de0fa989f89f2ff4c05889,22,9,2,2284,,,0,"Revert ""Skip to poll and publish when no resources found""

We revert commit 934a90d4c61ff66f99e5a46480047dec355b5d61
as it doesn't take into account that pollsters may have no
expectation of an explicit resource list, such as in the
IPMI case.

Change-Id: Ib9579417cd0654b790cc0b3c111b06e4dcecf728
Closes-Bug: #1403280
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/35/142435/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/agent/agentbase.py', 'ceilometer/agent/base.py']",2,9fcbc4e753848842018d1ba1aa823499887630dc,,," if not polling_resources: LOG.info(_( ""Skip polling pollster %s, no resources found""), pollster.name) continue",0,17
openstack%2Fmurano~master~Id4e0ccf5cdec8fc489c698cc8c1eb0a73cdf57fb,openstack/murano,master,Id4e0ccf5cdec8fc489c698cc8c1eb0a73cdf57fb,Drop unused dependencies,MERGED,2014-12-13 14:45:11.000000000,2014-12-18 16:17:59.000000000,2014-12-17 23:12:39.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7600}, {'_account_id': 7770}, {'_account_id': 7821}, {'_account_id': 13149}]","[{'number': 1, 'created': '2014-12-13 14:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/ee0d8c3ddf8cf248f4e447a83a5d57761a6c6d49', 'message': '[WIP] Drop unused dependencies\n\n* argparse\n* pycrypto\n* pycrypto\n\nChange-Id: Id4e0ccf5cdec8fc489c698cc8c1eb0a73cdf57fb\n'}, {'number': 2, 'created': '2014-12-13 15:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/26b2021f72f1bd7d6ac59b0f49e9e0c06fff16a8', 'message': 'Drop unused dependencies\n\nFollowing dependencies were present in requirements.txt, but\nwere not used in Murano:\n* argparse\n* pycrypto\n* pycrypto\n\nChange-Id: Id4e0ccf5cdec8fc489c698cc8c1eb0a73cdf57fb\n'}, {'number': 3, 'created': '2014-12-13 15:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/6c5b8403175f104b4c8f61f9bc3eda7345f52729', 'message': 'Drop unused dependencies\n\nFollowing dependencies were present in requirements.txt, but\nwere not used in Murano:\n* argparse\n* pycrypto\n* passlib\n\nChange-Id: Id4e0ccf5cdec8fc489c698cc8c1eb0a73cdf57fb\n'}, {'number': 4, 'created': '2014-12-17 03:10:30.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/murano/commit/421113b6ea6953ccca3ed0eaca45105f03a44fea', 'message': 'Drop unused dependencies\n\nFollowing dependencies were present in requirements.txt, but\nwere not used in Murano:\n* argparse\n* pycrypto\n* passlib\n\nChange-Id: Id4e0ccf5cdec8fc489c698cc8c1eb0a73cdf57fb\n'}]",2,141556,421113b6ea6953ccca3ed0eaca45105f03a44fea,31,7,4,7600,,,0,"Drop unused dependencies

Following dependencies were present in requirements.txt, but
were not used in Murano:
* argparse
* pycrypto
* passlib

Change-Id: Id4e0ccf5cdec8fc489c698cc8c1eb0a73cdf57fb
",git fetch https://review.opendev.org/openstack/murano refs/changes/56/141556/4 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,ee0d8c3ddf8cf248f4e447a83a5d57761a6c6d49,murano-cleanup,,argparsepycrypto>=2.6passlib,0,3
openstack%2Fironic-inspector~master~Ie0028133c088e393df3c0723d9cdf297b4316fbc,openstack/ironic-inspector,master,Ie0028133c088e393df3c0723d9cdf297b4316fbc,Enable functional testing with local ramdisk source,MERGED,2014-12-18 15:08:00.000000000,2014-12-18 16:02:07.000000000,2014-12-18 16:02:07.000000000,"[{'_account_id': 3}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-18 15:08:00.000000000', 'files': ['functest/run.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/71451867edfac6fbf953636b44b5471f43eb7136', 'message': 'Enable functional testing with local ramdisk source\n\nChange-Id: Ie0028133c088e393df3c0723d9cdf297b4316fbc\n'}]",0,142811,71451867edfac6fbf953636b44b5471f43eb7136,6,2,1,10239,,,0,"Enable functional testing with local ramdisk source

Change-Id: Ie0028133c088e393df3c0723d9cdf297b4316fbc
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/11/142811/1 && git format-patch -1 --stdout FETCH_HEAD,['functest/run.py'],1,71451867edfac6fbf953636b44b5471f43eb7136,,"import re if re.match(r'^https?://', ramdisk_url): ramdisk = requests.get(ramdisk_url).content else: with open(ramdisk_url, 'rb') as f: ramdisk = f.read()", ramdisk = requests.get(ramdisk_url).content,6,1
openstack%2Fmistral-extra~master~Ic5451c80a3dfe0df7d573248dd03f861d9a54411,openstack/mistral-extra,master,Ic5451c80a3dfe0df7d573248dd03f861d9a54411,Adding readme for multiple services example,MERGED,2014-12-18 13:39:58.000000000,2014-12-18 15:59:53.000000000,2014-12-18 15:59:53.000000000,"[{'_account_id': 3}, {'_account_id': 8592}, {'_account_id': 8731}]","[{'number': 1, 'created': '2014-12-18 13:39:58.000000000', 'files': ['examples/v2/services_registration/README.md'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/f3844e4b4f50d869c0bb39588413b2d382a5f0c7', 'message': 'Adding readme for multiple services example\n\nChange-Id: Ic5451c80a3dfe0df7d573248dd03f861d9a54411\n'}]",0,142783,f3844e4b4f50d869c0bb39588413b2d382a5f0c7,7,3,1,7700,,,0,"Adding readme for multiple services example

Change-Id: Ic5451c80a3dfe0df7d573248dd03f861d9a54411
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/83/142783/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/v2/services_registration/README.md'],1,f3844e4b4f50d869c0bb39588413b2d382a5f0c7,,"Multiple services registration example (based on v2 API/DSL) ============================================================ The example is created to demonstrate how Mistral can be used to interact with multiple third party service's API. This specific example works with Vyatta Firewall service and Zabbix monitoring service. It registers a newly created VM in Zabbix service and Vyatta Firewall. It requires two created workflows - Zabbix machine registration and Vyatta Firewall. They can be found in corresponding directories - 'zabbix' and 'vyatta'. How to run ---------- 1. Load workbook from multiple_services_registration.yaml: mistral workbook-create multiple_services_registration.yaml 2. Make sure you have created Zabbix and Vyatta workflows: mistral workbook-update vyatta_firewall.yaml mistral workbook-update zabbix_machine_registration.yaml 3. Create input.json file containing workflow input: { ""server_name"": [Name of the new instance], ""server_port"": [Port to open], ""image_id"": [image id from Glance service], ""flavor_id"": [flavor id - type of instance hardware], ""ssh_username"": [VM username], ""ssh_password"": [VM password], ""zabbix_host"": [Zabbix host], ""zabbix_username"": [Zabbix username], ""zabbix_password"": [Zabbix password], ""vyatta_host"": [Vyatta host], ""vyatta_username"": [Vyatta username], ""vyatta_password"": [Vyatta password], } 4. Run the execution: mistral execution-create register_in_multiple_services.create_and_register input.json 5. Using execution id from the previous step wait for completion (workflow SUCCESS state): mistral execution-get <execution_id> 6. Check your Zabbix host group. You will see new host group, one host in it and one simple check item. Log in your Vyatta and check Firewall service. You will see new accept rule with configured IP address, protocol and port.",,56,0
openstack%2Fhorizon~master~Id20d5b3bd4fe2ddd549b1c2753c621ffdf496df4,openstack/horizon,master,Id20d5b3bd4fe2ddd549b1c2753c621ffdf496df4,"Fixes the disappearance of ""Change Password"" Panel",ABANDONED,2014-11-04 06:40:41.000000000,2014-12-18 15:58:44.000000000,,"[{'_account_id': 3}, {'_account_id': 581}, {'_account_id': 4978}, {'_account_id': 6763}, {'_account_id': 11599}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-11-04 06:40:41.000000000', 'files': ['openstack_dashboard/dashboards/settings/password/panel.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/69be09180bb44490a5ebb50ff3a55a9fdea6a3c6', 'message': 'Fixes the disappearance of ""Change Password"" Panel\n\nWhen admin user creates a new user and uses that user to login,\nthe password change panel doens\'t show up for that user.\n\nAlso this panel is also not shown to the demo user.\n\nChange-Id: Id20d5b3bd4fe2ddd549b1c2753c621ffdf496df4\nCloses-bug: #1382316\n'}]",0,132622,69be09180bb44490a5ebb50ff3a55a9fdea6a3c6,13,6,1,11599,,,0,"Fixes the disappearance of ""Change Password"" Panel

When admin user creates a new user and uses that user to login,
the password change panel doens't show up for that user.

Also this panel is also not shown to the demo user.

Change-Id: Id20d5b3bd4fe2ddd549b1c2753c621ffdf496df4
Closes-bug: #1382316
",git fetch https://review.opendev.org/openstack/horizon refs/changes/22/132622/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/settings/password/panel.py'],1,69be09180bb44490a5ebb50ff3a55a9fdea6a3c6,bugs/#1382316_password,," policy_rules = ((""identity"", ""identity:change_password""),)",0,1
openstack%2Fmistral-extra~master~Idafcf90b6424f1177438dbd49be657765bb8c0b1,openstack/mistral-extra,master,Idafcf90b6424f1177438dbd49be657765bb8c0b1,Adding readme for vyatta firewall example,MERGED,2014-12-18 13:23:31.000000000,2014-12-18 15:56:50.000000000,2014-12-18 15:56:50.000000000,"[{'_account_id': 3}, {'_account_id': 8592}, {'_account_id': 8731}]","[{'number': 1, 'created': '2014-12-18 13:23:31.000000000', 'files': ['examples/v2/services_registration/vyatta/README.md'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/37b2ef89639d6550bda3dc4b5d91b9b9af4ac1cc', 'message': 'Adding readme for vyatta firewall example\n\nChange-Id: Idafcf90b6424f1177438dbd49be657765bb8c0b1\n'}]",0,142776,37b2ef89639d6550bda3dc4b5d91b9b9af4ac1cc,7,3,1,7700,,,0,"Adding readme for vyatta firewall example

Change-Id: Idafcf90b6424f1177438dbd49be657765bb8c0b1
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/76/142776/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/v2/services_registration/vyatta/README.md'],1,37b2ef89639d6550bda3dc4b5d91b9b9af4ac1cc,,"Vyatta Firewall example (based on v2 API/DSL) ============================================= The example is created to demonstrate how Mistral can be used to interact with third party service's API through HTTP requests. This specific example works with Vyatta Firewall service. Mistral uses auth information provided by the user to retrieve Vyatta configuration URL. Then it creates accept rule in Firewall service, sets IP address, protocol and port to this rule and commit transaction. How to run ---------- 1. Load workbook from vyatta_firewall.yaml: mistral workbook-create vyatta_firewall.yaml 2. Create input.json file containing workflow input: { ""machine_ip"": [your machine IP], ""machine_name"": [your machine name], ""port"": [Firewall port to open], ""vyatta_host"": [Zabbix host], ""vyatta_username"": [Zabbix username], ""vyatta_password"": [Zabbix password], } 3. Run the execution: mistral execution-create vyatta.register_in_vyatta_firewall input.json 4. Using execution id from the previous step wait for completion (workflow SUCCESS state): mistral execution-get <execution_id> 5. Log in your Vyatta and check Firewall service. You will see new accept rule with configured IP address, protocol and port.",,41,0
openstack%2Fopenstack-manuals~master~I96e3092a32015f14c7fd6cb591f32021ab4e804a,openstack/openstack-manuals,master,I96e3092a32015f14c7fd6cb591f32021ab4e804a,Update docco about dispatchers available for Telemetry,MERGED,2014-12-17 14:22:12.000000000,2014-12-18 15:55:09.000000000,2014-12-18 15:55:08.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-12-17 14:22:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ed125dfeca34323538e7dc9a270820c60b3721bf', 'message': 'Update docco about dispatchers available for Telemetry\n\nAdd documentation about the new HTTP dispatcher and also a few lines\nabout the file dispatcher, which is not documented at the moment.\n\nChange-Id: I96e3092a32015f14c7fd6cb591f32021ab4e804a\nCloses-Bug: #1400422\n'}, {'number': 2, 'created': '2014-12-17 14:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cde0e1865b20085ac5861079b7b3cf7cc2c31587', 'message': 'Update docco about dispatchers available for Telemetry\n\nAdd documentation about the new HTTP dispatcher and also a few lines\nabout the file dispatcher, which is not documented at the moment.\n\nChange-Id: I96e3092a32015f14c7fd6cb591f32021ab4e804a\nCloses-Bug: #1400422\n'}, {'number': 3, 'created': '2014-12-17 14:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b8d7b40e153034372f7eac4bf4db7aed3deb3a2d', 'message': 'Update docco about dispatchers available for Telemetry\n\nAdd documentation about the new HTTP dispatcher and also a few lines\nabout the file dispatcher, which is not documented at the moment.\n\nChange-Id: I96e3092a32015f14c7fd6cb591f32021ab4e804a\nCloses-Bug: #1400422\n'}, {'number': 4, 'created': '2014-12-17 21:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f7df15800fba6088dacce9858fcf64a60939af7f', 'message': 'Update docco about dispatchers available for Telemetry\n\nAdd documentation about the new HTTP dispatcher and also a few lines\nabout the file dispatcher, which is not documented at the moment.\n\nChange-Id: I96e3092a32015f14c7fd6cb591f32021ab4e804a\nCloses-Bug: #1400422\n'}, {'number': 5, 'created': '2014-12-18 06:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4956608bbba9a55db410fe3b8066ca2b18c46133', 'message': 'Update docco about dispatchers available for Telemetry\n\nAdd documentation about the new HTTP dispatcher and also a few lines\nabout the file dispatcher, which is not documented at the moment.\n\nChange-Id: I96e3092a32015f14c7fd6cb591f32021ab4e804a\nCloses-Bug: #1400422\n'}, {'number': 6, 'created': '2014-12-18 06:37:54.000000000', 'files': ['doc/admin-guide-cloud/telemetry/section_telemetry-data-collection.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f150c158df00123b9e208ec85b81de3be651c16c', 'message': 'Update docco about dispatchers available for Telemetry\n\nAdd documentation about the new HTTP dispatcher and also a few lines\nabout the file dispatcher, which is not documented at the moment.\n\nChange-Id: I96e3092a32015f14c7fd6cb591f32021ab4e804a\nCloses-Bug: #1400422\n'}]",10,142453,f150c158df00123b9e208ec85b81de3be651c16c,19,5,6,9562,,,0,"Update docco about dispatchers available for Telemetry

Add documentation about the new HTTP dispatcher and also a few lines
about the file dispatcher, which is not documented at the moment.

Change-Id: I96e3092a32015f14c7fd6cb591f32021ab4e804a
Closes-Bug: #1400422
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/53/142453/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/telemetry/section_telemetry-data-collection.xml'],1,ed125dfeca34323538e7dc9a270820c60b3721bf,ceilo-dispatcher-update," that is coming from the pollsters or received as notifications. The data can be stored in a file or a database back end, for which the list of supported databases can be found in <xref linkend=""section_telemetry-supported-dbs""/>. The data can also be sent to an external data store by using an HTTP dispatcher. these samples without any modification in the configured back end or via HTTP. The service has to run on a host machine from which it has access to the database, if you chose that option for persisting data.</para> <note> <para>Multiple dispatchers can be configured for Telemetry at one time.</para> </note> <simplesect> <title>Database dispatcher</title> <para>By default the time to live value (ttl) for samples is set to -1, which means that they are kept in the database forever. This can be changed by modifying the <parameter>time_to_live </parameter> parameter in <filename>ceilometer.conf</filename>. The value has to be specified in seconds and it means that every sample that based on its timestamp is older, than the specified value will be deleted from the database.</para> <para>When the samples are deleted, there are cases, when users and resources remain in the database without any corresponding sample. There is a command line script, that deletes these useless entries, which is called <systemitem class=""service"">ceilometer-expirer</systemitem>. This script should be run periodically, for instance in a cron job, to ensure that the database is cleaned up properly.</para> <para>The level of support differs in case of the configured back end:</para> <table rules=""all""> <caption>Time-to-live support for database back ends</caption> <col width=""24%""/> <col width=""38%""/> <col width=""38%""/> <thead> <tr> <td>Database</td> <td>ttl value support</td> <td><systemitem class=""service"">ceilometer-expirer</systemitem> capabilities</td> </tr> </thead> <tbody> <tr> <td>MongoDB</td> <td>MongoDB has a built-in mechanism for deleting samples that are older than the configured ttl value.</td> <td>In case of this database, only the lingering dead resource, user and project entries will be deleted by <systemitem class=""service"">ceilometer-expirer</systemitem>. </td> </tr> <tr> <td>SQL-based back ends</td> <td>The library (SQLAlchemy) that is used for accessing SQL-based back ends does not support using the ttl value.</td> <td><systemitem class=""service"">ceilometer-expirer</systemitem> has to be used for deleting both the samples and the remaining entires in other database tables. The script will delete samples based on the <parameter>time_to_live</parameter> value that is set in the configuration file.</td> </tr> <tr> <td>HBase</td> <td>HBase does not support this functionality currently, therefore the ttl value in the configuration file is ignored.</td> <td>The samples are not deleted by using <systemitem class=""service"">ceilometer-expirer</systemitem>, this functionality is not supported.</td> </tr> <tr> <td>DB2</td> <td>Same case as MongoDB.</td> <td>Same case as MongoDB.</td> </tr> </tbody> </table> </simplesect> <simplesect> <title>HTTP dispatcher</title> <para>The Telemetry module supports sending samples to an external HTTP target. The samples are sent without any modification. To set this option as data storage, the <option>dispatcher</option> has to be changed to <literal>http</literal> in the <filename>ceilometer.conf</filename> configuration file. For the list of options that you need to set, see the see the <link xlink:href=""http://docs.openstack.org/trunk/config-reference/content/ch_configuring-openstack-telemetry.html""> <literal>dispatcher_http</literal> section</link> in the <citetitle>OpenStack Configuration Reference</citetitle>.</para> </simplesect> <simplesect> <title>File dispatcher</title> <para>You can store samples in a file by setting the <option>dispatcher</option> option in <filename>ceilometer.conf</filename> o <literal>file</literal>. For the list of configuration options, see the <link xlink:href=""http://docs.openstack.org/trunk/config-reference/content/ch_configuring-openstack-telemetry.html""> <literal>dispatcher_file</literal> section</link> in the <citetitle>OpenStack Configuration Reference</citetitle>.</para> </simplesect>"," that is coming from the pollsters or received as notifications. The data is stored in a database back end, the list of supported databases can be found in <xref linkend=""section_telemetry-supported-dbs""/>. these samples without any modification in the configured back end. The service has to run on a host machine from which it has access to the database.</para> <para>By default the time to live value (ttl) for samples is set to -1, which means that they are kept in the database forever. This can be changed by modifying the <parameter>time_to_live </parameter> parameter in <filename>ceilometer.conf</filename>. The value has to be specified in seconds and it means that every sample that based on its timestamp is older, than the specified value will be deleted from the database.</para> <para>When the samples are deleted, there are cases, when users and resources remain in the database without any corresponding sample. There is a command line script, that deletes these useless entries, which is called <systemitem class=""service"">ceilometer-expirer</systemitem>. This script should be run periodically, for instance in a cron job, to ensure that the database is cleaned up properly.</para> <para>The level of support differs in case of the configured back end:</para> <table rules=""all""> <caption>Time-to-live support for database back ends</caption> <col width=""24%""/> <col width=""38%""/> <col width=""38%""/> <thead> <tr> <td>Database</td> <td>ttl value support</td> <td><systemitem class=""service"">ceilometer-expirer</systemitem> capabilities</td> </tr> </thead> <tbody> <tr> <td>MongoDB</td> <td>MongoDB has a built-in mechanism for deleting samples that are older than the configured ttl value.</td> <td>In case of this database, only the lingering dead resource, user and project entries will be deleted by <systemitem class=""service"">ceilometer-expirer</systemitem>. </td> </tr> <tr> <td>SQL-based back ends</td> <td>The library (SQLAlchemy) that is used for accessing SQL-based back ends does not support using the ttl value.</td> <td><systemitem class=""service"">ceilometer-expirer</systemitem> has to be used for deleting both the samples and the remaining entires in other database tables. The script will delete samples based on the <parameter>time_to_live</parameter> value that is set in the configuration file.</td> </tr> <tr> <td>HBase</td> <td>HBase does not support this functionality currently, therefore the ttl value in the configuration file is ignored.</td> <td>The samples are not deleted by using <systemitem class=""service"">ceilometer-expirer</systemitem>, this functionality is not supported.</td> </tr> <tr> <td>DB2</td> <td>Same case as MongoDB.</td> <td>Same case as MongoDB.</td> </tr> </tbody> </table>",92,64
openstack%2Fmistral~master~I98301f7292841ee574a01308a5af398574f2352a,openstack/mistral,master,I98301f7292841ee574a01308a5af398574f2352a,Refacor resume algorithm,MERGED,2014-12-18 13:07:57.000000000,2014-12-18 15:54:13.000000000,2014-12-18 15:54:12.000000000,"[{'_account_id': 3}, {'_account_id': 8592}, {'_account_id': 8731}]","[{'number': 1, 'created': '2014-12-18 13:07:57.000000000', 'files': ['mistral/workflow/base.py', 'mistral/engine1/policies.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/63e6ac1e8636f2b84f50f8e33a17396045569178', 'message': 'Refacor resume algorithm\n\nChange-Id: I98301f7292841ee574a01308a5af398574f2352a\n'}]",0,142768,63e6ac1e8636f2b84f50f8e33a17396045569178,7,3,1,7700,,,0,"Refacor resume algorithm

Change-Id: I98301f7292841ee574a01308a5af398574f2352a
",git fetch https://review.opendev.org/openstack/mistral refs/changes/68/142768/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/workflow/base.py', 'mistral/engine1/policies.py']",2,63e6ac1e8636f2b84f50f8e33a17396045569178,refactor_resume, return (PauseBeforePolicy(pause_before_policy) if pause_before_policy else None), return PauseBeforePolicy(pause_before_policy) \ if pause_before_policy else None,18,14
openstack%2Fpython-cinderclient~master~I2735d7050d90589d19f45e21096577febdcca8bb,openstack/python-cinderclient,master,I2735d7050d90589d19f45e21096577febdcca8bb,Added type description for volume type client,MERGED,2014-10-31 20:35:38.000000000,2014-12-18 15:53:59.000000000,2014-12-18 15:53:58.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 6491}, {'_account_id': 8074}, {'_account_id': 8871}, {'_account_id': 9624}, {'_account_id': 11047}, {'_account_id': 11880}, {'_account_id': 11903}, {'_account_id': 11904}, {'_account_id': 11941}]","[{'number': 1, 'created': '2014-10-31 20:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/b1ad99d47b14671e4bef8daf7756609b8a6ffabe', 'message': 'Added volume type description for volume type\n\nThis patch added client handling and unit tests for volume type description:\n\n* Added 2 client methods for volume type\n  default: to get the default volume type\n  update: to upate an existing volume type\n\n* Added 2 new command-lines\n  type-update (adminitrator only)\n  type-default\n\n* type-list should have description shows up.\n\nThe corresponding cinder APIs change volume-type-description:\nhttps://review.openstack.org/#/c/131871/\n\nImplements: blueprint volume-type-description\nChange-Id: I2735d7050d90589d19f45e21096577febdcca8bb\n'}, {'number': 2, 'created': '2014-10-31 21:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/22d762f2d4682d87c7d67eecec32625b5e2c263a', 'message': 'Added type description for volume type client\n\nThis patch added client handling and unit tests for volume type description:\n\n* Added 2 client methods for volume type\n  default: to get the default volume type\n  update: to upate an existing volume type\n\n* Added 2 new command-lines\n  type-update (adminitrator only)\n  type-default\n\n* type-list should have description shows up.\n\n* type-create should have an option for entering the description\n\nThe corresponding cinder APIs change volume-type-description:\nhttps://review.openstack.org/#/c/131871/\n\nImplements: blueprint volume-type-description\nChange-Id: I2735d7050d90589d19f45e21096577febdcca8bb\n'}, {'number': 3, 'created': '2014-11-05 22:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/382eb3ca0d2b562eec5af67061eb99213db03d31', 'message': 'Added type description for volume type client\n\nThis patch added client handling and unit tests for volume type description:\n\n* Added 2 client methods for volume type\n  default: to get the default volume type\n  update: to upate an existing volume type\n\n* Added 2 new command-lines\n  type-update (adminitrator only)\n  type-default\n\n* type-list should have description shows up.\n\n* type-create should have an option for entering the description.\n\nThe corresponding cinder APIs change volume-type-description:\nhttps://review.openstack.org/#/c/131871/\n\nImplements: blueprint volume-type-description\nChange-Id: I2735d7050d90589d19f45e21096577febdcca8bb\n'}, {'number': 4, 'created': '2014-11-21 21:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/fa6914636101c5282d9486c6724db347691d666f', 'message': 'Added type description for volume type client\n\nThis patch added client handling and unit tests for volume type description:\n\n* Added 2 client methods for volume type\n  default: to get the default volume type\n  update: to upate an existing volume type\n\n* Added 2 new command-lines\n  type-update (adminitrator only)\n  type-default\n\n* type-list should have description shows up.\n\n* type-create should have an option for entering the description.\n\nThe corresponding cinder APIs change volume-type-description:\nhttps://review.openstack.org/#/c/131871/\n\nImplements: blueprint volume-type-description\nChange-Id: I2735d7050d90589d19f45e21096577febdcca8bb\n'}, {'number': 5, 'created': '2014-11-21 23:36:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/3319e6fd6a235cc30fa221d9231d4230559d1eb2', 'message': 'Added type description for volume type client\n\nThis patch added client handling and unit tests for volume type description:\n\n* Added 2 client methods for volume type.\n  default: to get the default volume type\n  update: to upate an existing volume type\n\n* Added 2 new command-line operations.\n  type-update (adminitrator only)\n  type-default\n\n* type-list should display description.\n\n* type-create should have an option for entering the description.\n\nThe corresponding cinder APIs change volume-type-description:\nhttps://review.openstack.org/#/c/131871/\n\nImplements: blueprint volume-type-description\nChange-Id: I2735d7050d90589d19f45e21096577febdcca8bb\n'}, {'number': 6, 'created': '2014-12-02 00:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/0d921321290574b6e9c979d2f8aa0c7806becb97', 'message': 'Added type description for volume type client\n\nThis patch added client handling and unit tests for volume type description:\n\n* Added 2 client methods for volume type.\n  default: to get the default volume type\n  update: to upate an existing volume type\n\n* Added 2 new command-line operations.\n  type-update (adminitrator only)\n  type-default\n\n* type-list should display description.\n\n* type-create should have an option for entering the description.\n\nThe corresponding cinder APIs change volume-type-description:\nhttps://review.openstack.org/#/c/131871/\n\nImplements: blueprint volume-type-description\nChange-Id: I2735d7050d90589d19f45e21096577febdcca8bb\n'}, {'number': 7, 'created': '2014-12-06 02:10:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/bdd265338f025126ba8a9163c18a78357ee94297', 'message': 'Added type description for volume type client\n\nThis patch added client handling and unit tests for volume type description:\n\n* Added 2 client methods for volume type.\n  default: to get the default volume type\n  update: to upate an existing volume type\n\n* Added 2 new command-line operations.\n  type-update (adminitrator only)\n  type-default\n\n* type-list should display description.\n\n* type-create should have an option for entering the description.\n\nThe corresponding cinder APIs change volume-type-description:\nhttps://review.openstack.org/#/c/131871/\n\nImplements: blueprint volume-type-description\nChange-Id: I2735d7050d90589d19f45e21096577febdcca8bb\n'}, {'number': 8, 'created': '2014-12-11 18:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/3f10fecde761e219b01053bd90b3c2c740cd5786', 'message': 'Added type description for volume type client\n\nThis patch added client handling and unit tests for volume type description:\n\n* Added 2 client methods for volume type.\n  default: to get the default volume type\n  update: to upate an existing volume type\n\n* Added 2 new command-line operations.\n  type-update (adminitrator only)\n  type-default\n\n* type-list should display description.\n\n* type-create should have an option for entering the description.\n\nThe corresponding cinder APIs change volume-type-description:\nhttps://review.openstack.org/#/c/131871/\n\nImplements: blueprint volume-type-description\nChange-Id: I2735d7050d90589d19f45e21096577febdcca8bb\n'}, {'number': 9, 'created': '2014-12-11 18:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/483fc447d80f49de828f6c49a29b7abb23c34762', 'message': 'Added type description for volume type client\n\nThis patch added client handling and unit tests for volume type description:\n\n* Added 2 client methods for volume type.\n  default: to get the default volume type\n  update: to upate an existing volume type to update description\n\n* Added 2 new command-line operations.\n  type-update (adminitrator only)\n  type-default\n\n* type-list should display description.\n\n* type-create should have an option for entering the description.\n\nThe corresponding cinder APIs change volume-type-description:\nhttps://review.openstack.org/#/c/131871/\n\nImplements: blueprint volume-type-description\nChange-Id: I2735d7050d90589d19f45e21096577febdcca8bb\n'}, {'number': 10, 'created': '2014-12-17 15:37:21.000000000', 'files': ['cinderclient/base.py', 'cinderclient/tests/v2/fakes.py', 'cinderclient/v2/volume_types.py', 'cinderclient/v2/shell.py', 'cinderclient/tests/v2/test_types.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/bc2b8bf1be95a8f45eca57e1f75dcc5f6504873a', 'message': 'Added type description for volume type client\n\nThis patch added client handling and unit tests for volume type description:\n\n* Added 2 client methods for volume type.\n  default: to get the default volume type\n  update: to upate an existing volume type to update description\n\n* Added 2 new command-line operations.\n  type-update (adminitrator only)\n  type-default\n\n* type-list should display description.\n\n* type-create should have an option for entering the description.\n\nThe corresponding cinder APIs change volume-type-description:\nhttps://review.openstack.org/#/c/131871/\n\nImplements: blueprint volume-type-description\nChange-Id: I2735d7050d90589d19f45e21096577febdcca8bb\n'}]",7,132354,bc2b8bf1be95a8f45eca57e1f75dcc5f6504873a,66,14,10,11880,,,0,"Added type description for volume type client

This patch added client handling and unit tests for volume type description:

* Added 2 client methods for volume type.
  default: to get the default volume type
  update: to upate an existing volume type to update description

* Added 2 new command-line operations.
  type-update (adminitrator only)
  type-default

* type-list should display description.

* type-create should have an option for entering the description.

The corresponding cinder APIs change volume-type-description:
https://review.openstack.org/#/c/131871/

Implements: blueprint volume-type-description
Change-Id: I2735d7050d90589d19f45e21096577febdcca8bb
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/54/132354/9 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/base.py', 'cinderclient/tests/v2/fakes.py', 'cinderclient/v2/volume_types.py', 'cinderclient/v2/shell.py', 'cinderclient/tests/v2/test_types.py']",5,b1ad99d47b14671e4bef8daf7756609b8a6ffabe,pb/volume-type-description," def test_update(self): t = cs.volume_types.update('1', 'test_type_1', 'test_desc_1') cs.assert_called('PUT', '/types/1') self.assertIsInstance(t, volume_types.VolumeType) def test_get(self): t = cs.volume_types.get('1') cs.assert_called('GET', '/types/1') self.assertIsInstance(t, volume_types.VolumeType) def test_default(self): t = cs.volume_types.default() cs.assert_called('GET', '/types/default') self.assertIsInstance(t, volume_types.VolumeType) ",,78,4
openstack%2Fnova~master~I537686af662f559248b981a93ee932d2aed231c2,openstack/nova,master,I537686af662f559248b981a93ee932d2aed231c2,WIP Add flavor properties to Instance object,ABANDONED,2014-10-06 17:07:50.000000000,2014-12-18 15:53:22.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-06 17:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2ffcf5533bc638aab5844878f49e3ca55457db8', 'message': 'WIP Add flavor properties to Instance object\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 2, 'created': '2014-10-06 20:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02fef4ad1945b64e02b468b9d1578f31783279fd', 'message': 'WIP Add flavor properties to Instance object\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 3, 'created': '2014-10-07 14:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4818dd40c65e29f8a1775e398164ea5ffe2658b6', 'message': 'WIP Add flavor properties to Instance object\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 4, 'created': '2014-10-07 20:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d54eadb39161df79806ddec0b5a775e9c583cef', 'message': 'WIP Add flavor properties to Instance object\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 5, 'created': '2014-10-08 14:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/126181f89e94864b7a3d51463a2f678b3b220004', 'message': 'WIP Add flavor properties to Instance object\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 6, 'created': '2014-10-08 18:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ebed9331d07feacfbc26c64ab344728fec7a0d9', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 7, 'created': '2014-10-14 14:55:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e78d3e74292e63f3c232b7c70023018ef2593f8', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 8, 'created': '2014-10-14 17:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/31f5d0cef6cdcc7d6e38e4da8e3e968e6ff22371', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 9, 'created': '2014-10-14 18:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/61b822dbe83beb86975facb2b7366819ff19d32b', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 10, 'created': '2014-10-14 19:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a64191151cd34883986e97520eb664e09b77b06', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 11, 'created': '2014-10-14 22:08:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66db96d0ca2b0aaa8c4d4ab0b093897801f9ab05', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 12, 'created': '2014-10-15 15:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f2699045f736a22f878586e69475bcb2098fa60', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 13, 'created': '2014-10-15 16:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cad803962d285a324b3eadaa8069028ba8fc2752', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 14, 'created': '2014-10-15 18:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be6b2511358e566bf13538aba48dba1224d6210c', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 15, 'created': '2014-10-15 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec9b2496b3a6f4b5e6ec2e8af7bf285084809e10', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 16, 'created': '2014-10-16 16:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edc5c0d14d8916b80c117e14f18d33f5e91d9041', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 17, 'created': '2014-10-16 16:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5801aa0b3129706b2a6c7751e303a3cf2de5b476', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 18, 'created': '2014-10-16 19:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/81473f02b0225210868a8f7eb7e9df4191c3c191', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 19, 'created': '2014-10-16 20:36:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f37d395ea38a01323684f6be909056794f5e7df', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 20, 'created': '2014-10-17 14:15:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/524e9fd1ee061382d93a4693e28ebfa360b8e3e3', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 21, 'created': '2014-10-17 14:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b7b5c75ac0cff689a7df951f401d5ab30faec452', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 22, 'created': '2014-10-17 16:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/af5dae726599e0d9247a1f22271b80d7746b245d', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 23, 'created': '2014-10-20 14:33:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f12b7882a7431f8c5cb05f853986e1d6e3061767', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 24, 'created': '2014-10-22 15:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d5d752442429f6ec2306f8838c6d485c131cbea', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 25, 'created': '2014-10-24 14:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aacc18e2c8b1e6760718352de3ec1bd482a12b79', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 26, 'created': '2014-10-28 19:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/82a9309c023371ee56a9b983732d75f0dc90eba0', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 27, 'created': '2014-11-11 17:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24fed5510812ce5503c2e233e8e8a489b7e1043a', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 28, 'created': '2014-11-11 18:32:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58485e2fe501f5a248f20fd34847dbc0f1b4e1ad', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 29, 'created': '2014-11-11 20:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4978e332a3064de4b018839c9476a1d7b8ed2b33', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 30, 'created': '2014-11-13 17:14:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a947a355e3144cd0edab4789c91a0f492c61c26', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 31, 'created': '2014-11-13 21:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c94240bd0dfcdc302c51c622a55d8ee510142bd9', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 32, 'created': '2014-11-17 16:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e966a45254ad2bb7ace074c38379c638a5eeab0', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}, {'number': 33, 'created': '2014-11-17 20:27:04.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/compute/flavors.py', 'nova/tests/unit/api/openstack/compute/contrib/test_simple_tenant_usage.py', 'nova/tests/unit/compute/test_compute.py', 'nova/objects/block_device.py', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/tests/unit/virt/libvirt/test_driver.py', 'nova/objects/floating_ip.py', 'nova/tests/unit/objects/test_objects.py', 'nova/api/openstack/compute/plugins/v3/simple_tenant_usage.py', 'nova/tests/unit/fake_instance.py', 'nova/objects/instance.py', 'nova/compute/manager.py', 'nova/tests/unit/objects/test_instance.py', 'nova/objects/fixed_ip.py', 'nova/compute/api.py', 'nova/api/openstack/compute/contrib/simple_tenant_usage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f6091158c79b8e89e7835d854cf8f6a6842bb529', 'message': 'WIP Add flavor properties to Instance object\n\nRelated to blueprint flavor-from-sysmeta-to-blob\n\nChange-Id: I537686af662f559248b981a93ee932d2aed231c2\n'}]",0,126363,f6091158c79b8e89e7835d854cf8f6a6842bb529,152,8,33,4393,,,0,"WIP Add flavor properties to Instance object

Related to blueprint flavor-from-sysmeta-to-blob

Change-Id: I537686af662f559248b981a93ee932d2aed231c2
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/126363/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/objects/test_instance.py', 'nova/tests/fake_instance.py', 'nova/objects/instance.py']",3,d2ffcf5533bc638aab5844878f49e3ca55457db8,bp/flavor-from-sysmeta-to-blob,"from nova.openstack.common import jsonutils_INSTANCE_OPTIONAL_NON_COLUMN_FIELDS = ['fault', 'old_flavor', 'new_flavor']_INSTANCE_EXTRA_FIELDS = ['numa_topology', 'pci_requests', 'flavor'] if ('system_metadata' not in simple_cols and ('flavor' in expected_attrs or 'new_flavor' in expected_attrs or 'old_flavor' in expected_attrs)): # NOTE(danms): As long as we need compatibility with # instances that might have flavor data stashed in sysmeta, # we need to imply loading it if flavors are requested simple_cols.append('system_metadata') # Version 1.17: Added flavor, old_flavor, new_flavor VERSION = '1.17' 'flavor': fields.ObjectField('Flavor'), 'old_flavor': fields.ObjectField('Flavor', nullable=True), 'new_flavor': fields.ObjectField('Flavor', nullable=True), for field in ('flavor', 'old_flavor', 'new_flavor'): if (self.obj_attr_is_set(field) and self[field] and (fields is None or field in fields)): self[field].obj_reset_changes() def _flavordata_from_db_object(context, instance, db_inst): if 'system_metadata' in db_inst and db_inst['system_metadata']: sysmeta = utils.instance_sys_meta(db_inst) else: sysmeta = {} if ('system_metadata' in db_inst and 'instance_type_id' in sysmeta): # NOTE(danms): Unconverted instance record, provide compatibility # This has to stay until we can be sure that any/all instances in the # database have been converted to the storage in extra. instance.flavor = objects.Flavor(**flavors.extract_flavor(db_inst)) try: instance.old_flavor = objects.Flavor( **flavors.extract_flavor(db_inst, 'old_')) except KeyError: instance.old_flavor = None try: instance.new_flavor = objects.Flavor( **flavors.extract_flavor(db_inst, 'new_')) except KeyError: instance.new_flavor = None elif ('extra' in db_inst and 'flavor' in db_inst['extra'] and db_inst['extra']['flavor'] is not None): # New style instance with flavor in .extra flavor_info = jsonutils.loads(db_inst['extra']['flavor']) instance.flavor = objects.Flavor.obj_from_primitive(flavor_info['cur']) if 'old' in flavor_info and flavor_info['old']: instance.old_flavor = objects.Flavor.obj_from_primitive(flavor_info['old']) else: instance.old_flavor = None if 'new' in flavor_info and flavor_info['new']: instance.new_flavor = objects.Flavor.obj_from_primitive(flavor_info['new']) else: instance.new_flavor = None else: print 'no flavor loaded' print db_inst['system_metadata'] print 'extra' in db_inst print db_inst['extra'] print 'flavor' in db_inst['extra'] print db_inst['extra']['flavor'] @staticmethod instance._flavordata_from_db_object(context, instance, db_inst) print 'Joining: %s for %s' % (columns_to_join, expected_attrs) def _save_flavor(self, context): flavor_info = { 'cur': self.flavor, 'old': self.old_flavor, 'new': self.new_flavor, } if not any([x.obj_what_changed() if x else None for x in flavor_info.values()]): # No changes to any of the flavors return for key, flavor in flavor_info.items(): if flavor: flavor_info[key] = flavor.obj_to_primitive() updates = {'flavor': jsonutils.dumps(flavor_info)} print ""Saving flavors: %s"" % updates # NOTE(danms): We're migrating flavor information to the extra # blob, so don't save it back into system_metadata. This can be # removed when we're past the point of having migrated everything. print 'PRECLEAN: %s' % self.system_metadata if 'instance_type_flavorid' in self.system_metadata: for key in self.system_metadata.keys(): if 'instance_type_' in key: del self.system_metadata[key] print 'POSTCLEAN: %s' % self.system_metadata # NOTE(danms): This could be done more efficiently by combining # it with the main instance update via the relationship. However, # this happens very infrequently, so do the simple thing first. db.instance_extra_update_by_uuid(context, self.uuid, updates) def _save_old_flavor(self, context): return self._save_flavor() def _save_new_flavor(self, context): return self._save_flavor() # NOTE(danms): The flavor saving routines above may have altered # system_metadata, so check to see if we need to save that now. This # can be removed once we drop compatibility for flavors in sysmeta. if 'system_metadata' in self.obj_what_changed(): updates['system_metadata'] = self.system_metadata # FIXME(danms): This is deprecated now def get_flavor(self, namespace=None): return getattr(self, '%sflavor' % (namespace and (namespace + '_') or '')) # FIXME(danms): This is deprecated now def set_flavor(self, flavor, namespace=None): getattr(self, '%sflavor' % (namespace and (namespace + '_') or '')).update(flavor) print ""SET %s FLAVOR: %s"" % (namespace, flavor) print ""My flavorid: %s"" % self.flavor.flavorid print ""My flavorid: %s"" % self.flavor.flavorid # FIXME(danms): This is deprecated now def delete_flavor(self, namespace): setattr(self, '%sflavor' % (namespace and (namespace + '_') or ''), None)","_INSTANCE_OPTIONAL_NON_COLUMN_FIELDS = ['fault']_INSTANCE_EXTRA_FIELDS = ['numa_topology', 'pci_requests'] VERSION = '1.16' print 'Columns: %s' % columns_to_join def get_flavor(self, namespace=None): prefix = ('%s_' % namespace) if namespace is not None else '' db_flavor = flavors.extract_flavor(self, prefix) flavor = objects.Flavor(self._context) for key in flavors.system_metadata_flavor_props: flavor[key] = db_flavor[key] return flavor def set_flavor(self, flavor, namespace=None): prefix = ('%s_' % namespace) if namespace is not None else '' self.system_metadata = flavors.save_flavor_info( self.system_metadata, flavor, prefix) def delete_flavor(self, namespace): self.system_metadata = flavors.delete_flavor_info( self.system_metadata, ""%s_"" % namespace)",149,30
openstack%2Fmurano-agent~master~I325667478349c5d825650a3f299d79a6545a58e4,openstack/murano-agent,master,I325667478349c5d825650a3f299d79a6545a58e4,Fix use of the oslo-config-generator,MERGED,2014-11-25 15:53:44.000000000,2014-12-18 15:49:23.000000000,2014-12-18 15:49:22.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 13149}]","[{'number': 1, 'created': '2014-11-25 15:53:44.000000000', 'files': ['muranoagent/openstack/common/log.py', 'muranoagent/openstack/common/eventlet_backdoor.py', 'muranoagent/common/config.py', 'config-generator.conf', 'openstack-common.conf', 'muranoagent/opts.py', 'setup.cfg', 'tox.ini', 'etc/oslo-config-generator/muranoagent.conf'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/3ae8b6274eb688fe6910613e2c82d763f8fbe96e', 'message': 'Fix use of the oslo-config-generator\n\nChange-Id: I325667478349c5d825650a3f299d79a6545a58e4\n'}]",0,137109,3ae8b6274eb688fe6910613e2c82d763f8fbe96e,16,6,1,13149,,,0,"Fix use of the oslo-config-generator

Change-Id: I325667478349c5d825650a3f299d79a6545a58e4
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/09/137109/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranoagent/openstack/common/log.py', 'muranoagent/openstack/common/eventlet_backdoor.py', 'muranoagent/common/config.py', 'config-generator.conf', 'openstack-common.conf', 'muranoagent/opts.py', 'setup.cfg', 'tox.ini', 'etc/oslo-config-generator/muranoagent.conf']",9,3ae8b6274eb688fe6910613e2c82d763f8fbe96e,,[DEFAULT] output_file = etc/muranoagent/muranoagent.conf.sample namespace = muranoagent ,,71,31
openstack%2Fmurano-apps~master~If7e0a417fb9b184389f6717c7d37c3cc1b485d1f,openstack/murano-apps,master,If7e0a417fb9b184389f6717c7d37c3cc1b485d1f,Add Tomcat application server,MERGED,2014-12-10 00:36:16.000000000,2014-12-18 15:48:09.000000000,2014-12-18 15:48:09.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-12-10 00:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/0dfb2a1011cd517c571bdd98106f8c2e44426ec4', 'message': 'Add Tomcat application server\n\nChange-Id: If7e0a417fb9b184389f6717c7d37c3cc1b485d1f\n'}, {'number': 2, 'created': '2014-12-18 08:54:20.000000000', 'files': ['io.murano.apps.apache.Tomcat/Resources/scripts/deployTomcat.sh', 'io.murano.apps.apache.Tomcat/manifest.yaml', 'io.murano.apps.apache.Tomcat/UI/ui.yaml', 'io.murano.apps.apache.Tomcat/logo.png', 'io.murano.apps.apache.Tomcat/Resources/DeployTomcat.template', 'io.murano.apps.apache.Tomcat/Classes/Tomcat.yaml'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/4f7567ab627c6d4501bde2155f4fc7119e209fcb', 'message': 'Add Tomcat application server\n\nChange-Id: If7e0a417fb9b184389f6717c7d37c3cc1b485d1f\n'}]",0,140539,4f7567ab627c6d4501bde2155f4fc7119e209fcb,9,3,2,7225,,,0,"Add Tomcat application server

Change-Id: If7e0a417fb9b184389f6717c7d37c3cc1b485d1f
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/39/140539/1 && git format-patch -1 --stdout FETCH_HEAD,"['io.murano.apps.apache.Tomcat/Resources/scripts/deployTomcat.sh', 'io.murano.apps.apache.Tomcat/manifest.yaml', 'io.murano.apps.apache.Tomcat/UI/ui.yaml', 'io.murano.apps.apache.Tomcat/logo.png', 'io.murano.apps.apache.Tomcat/Resources/DeployTomcat.template', 'io.murano.apps.apache.Tomcat/Classes/Tomcat.yaml']",6,0dfb2a1011cd517c571bdd98106f8c2e44426ec4,app/apache.Tomcat,"Namespaces: =: io.murano.apps.apache std: io.murano res: io.murano.resources sys: io.murano.system Name: Tomcat Extends: std:Application Properties: name: Contract: $.string().notNull() instance: Contract: $.class(res:Instance).notNull() Methods: initialize: Body: - $._environment: $.find(std:Environment).require() deploy: Body: - If: not $.getAttr(deployed, false) Then: - $._environment.reporter.report($this, 'Creating VM for Tomcat ') - $securityGroupIngress: - ToPort: 80 FromPort: 80 IpProtocol: tcp External: true - ToPort: 8080 FromPort: 8080 IpProtocol: tcp External: true - ToPort: 443 FromPort: 443 IpProtocol: tcp External: true - $._environment.securityGroupManager.addGroupIngress($securityGroupIngress) - $.instance.deploy() - $resources: new(sys:Resources) # Deploy Apache Tomcat - $template: $resources.yaml('DeployTomcat.template') - $._environment.reporter.report($this, 'Instance is created. Deploying Tomcat') - $.instance.agent.call($template, $resources) - $._environment.reporter.report($this, 'Tomcat is installed') - $.setAttr(deployed, true) ",,157,0
openstack%2Ffuel-library~master~I87fcd87a22371f664a305ea314e2019d3a5e3d38,openstack/fuel-library,master,I87fcd87a22371f664a305ea314e2019d3a5e3d38,Fix ceilometer puppet scripts to work with vCenter,MERGED,2014-09-22 09:44:22.000000000,2014-12-18 15:37:51.000000000,2014-12-18 15:37:51.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 3012}, {'_account_id': 6926}, {'_account_id': 7126}, {'_account_id': 7195}, {'_account_id': 7227}, {'_account_id': 7604}, {'_account_id': 7729}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 11427}]","[{'number': 1, 'created': '2014-09-22 09:44:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/38d12227c6f016471dc3b007bb3bbbc62369ff39', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* Set polling and evaluator interval to 60 seconds\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 2, 'created': '2014-09-22 09:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bf699d0c50e523d6ec84b636b0ff56671c0fbaa9', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* Set polling and evaluator interval to 60 seconds\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 3, 'created': '2014-09-22 10:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/037150396947042ec5267bf4bfd3f0011b971d4a', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* Set polling and evaluator interval to 60 seconds\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 4, 'created': '2014-09-22 10:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8ad1a7d0c5972169197d5e151cb30818f2184033', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* Set polling and evaluator interval to 60 seconds\n\nCloses-bug: #1370700\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 5, 'created': '2014-09-22 11:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7dde5c0486cb4517b5d2cbe3dd34db793f4efdb0', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* Set polling and evaluator interval to 60 seconds\n\nCloses-bug: #1370700\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 6, 'created': '2014-09-22 12:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/29c5c55511c9850186c062d2de6f8ed97ea44172', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* Set polling and evaluator interval to 60 seconds\n\nCloses-bug: #1370700\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 7, 'created': '2014-09-22 12:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a065df89739600cc538d941405746f2a0be7839f', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n\nCloses-bug: #1370700\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 8, 'created': '2014-09-22 13:30:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2bde1b7703fdd39f2211c318c108113e3f85f8dc', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n\n* Setup ceilometer-agent-compute on controller node\n\nCloses-bug: #1370700\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 9, 'created': '2014-09-29 08:59:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/26542a80a7e303ae4d177cb4716f08d0facdcbba', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n\n* Setup ceilometer-agent-compute on controller node\n\nCloses-bug: #1370700\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 10, 'created': '2014-10-01 10:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d43e5eb0d7dcea651e8b3abdc95daf8f19446fb3', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 11, 'created': '2014-10-01 10:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0fd1eb3eb23e05e09e1e314a51473fa93bab2a4c', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 12, 'created': '2014-10-06 11:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/739b0002dbd051ac66afd298bd620b7b23d5a864', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 13, 'created': '2014-10-22 07:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3bd5ee014fdc32d7813956052cad369280f1d514', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 14, 'created': '2014-10-22 07:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0c850ee42d3c0a2d3453b8ab4919d862faf100df', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 15, 'created': '2014-10-22 12:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ce775e58c8ff9040b58d973887699b586556a76d', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 16, 'created': '2014-10-22 12:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/968d7a2cfc3f3c67dfb4c1f3c46f71b9afacea0d', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 17, 'created': '2014-10-24 07:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ede67aaf961e1c73c6f6dcfd65ba6f1c3fd558df', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 18, 'created': '2014-10-24 09:02:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f2f77a933490929cf47a34f969f0fe462d47cea8', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 19, 'created': '2014-10-28 09:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1aca785af7ed53061fd9f9b88affca9f0b9d1954', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 20, 'created': '2014-10-28 09:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/60c4879fdcaef44e19c105af038f60bcc929d90a', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 21, 'created': '2014-10-28 16:58:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1f21d52cb10ad1963ac627a9ba3bc8ac78a8f4ae', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 22, 'created': '2014-10-29 15:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3caaf125e2f7af438799f35ec64ef93e9f44099e', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 23, 'created': '2014-10-29 15:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6891dcf5b31d76e959a0a8cd4d8a5d2fc2b7a90c', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 24, 'created': '2014-10-30 09:38:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cd49132daf9fbbb50c44450c78308f2cfe798c38', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 25, 'created': '2014-11-06 16:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7248a94f4baddcb3f77358b0fcd9e7396c06f4d0', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 26, 'created': '2014-11-10 17:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7ab5781398d97d2bfc6f6b7f70dce22e4e0697be', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 27, 'created': '2014-11-10 17:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/70237268422a1789ddb0e6f7f089c45308c77d32', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 28, 'created': '2014-11-11 09:13:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4d869c1a18fac041ee73b61978935ef4bfef33d2', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 29, 'created': '2014-11-13 07:40:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5bb552fa32a8bf885eb7233820c6d0a87060fc97', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 30, 'created': '2014-11-13 07:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b49d92b1751dcb1610c683f6e6da4ae1e47d02d3', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 31, 'created': '2014-11-13 09:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6e03ac9a90288af8cfeadadeece729c4f178ef00', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 32, 'created': '2014-11-13 15:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0af61b3ef59787429a341ce4babc9f37144acbd6', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 33, 'created': '2014-11-13 15:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a3fa6cf570f98ec06d13a135fc54d7fa03661708', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 34, 'created': '2014-12-17 16:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0ca49e06a7f5b56de0f4431fa8cf925bb21c8860', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}, {'number': 35, 'created': '2014-12-18 09:17:07.000000000', 'files': ['deployment/puppet/vmware/manifests/ceilometer/ha.pp', 'deployment/puppet/vmware/files/ocf/ceilometer-agent-compute', 'deployment/puppet/vmware/spec/classes/ceilometer_spec.rb', 'deployment/puppet/vmware/files/ceilometer-compute-init-ubuntu', 'deployment/puppet/vmware/templates/ceilometer-compute.conf.erb', 'deployment/puppet/vmware/manifests/ceilometer/simple.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp', 'deployment/puppet/vmware/spec/defines/vmware_ceilometer_ha_spec.rb', 'deployment/puppet/vmware/.fixtures.yml', 'deployment/puppet/vmware/manifests/ceilometer.pp', 'deployment/puppet/vmware/spec/defines/vmware_ceilometer_simple_spec.rb', 'deployment/puppet/vmware/manifests/init.pp', 'deployment/puppet/vmware/files/ceilometer-compute-init-centos'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ab39fb9d1cb3fdfa3e1e65ae49a405507b5c04b3', 'message': 'Fix ceilometer puppet scripts to work with vCenter\n\n* Setup ceilometer-agent-compute on controller node\n* pass vcenter credentials to ceilometer\n\nImplements blueprint ceilometer-support-for-vcenter\n\nChange-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38\n'}]",23,123088,ab39fb9d1cb3fdfa3e1e65ae49a405507b5c04b3,263,16,35,7732,,,0,"Fix ceilometer puppet scripts to work with vCenter

* Setup ceilometer-agent-compute on controller node
* pass vcenter credentials to ceilometer

Implements blueprint ceilometer-support-for-vcenter

Change-Id: I87fcd87a22371f664a305ea314e2019d3a5e3d38
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/88/123088/19 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/controller.pp', 'deployment/puppet/openstack/manifests/controller_ha.pp', 'deployment/puppet/ceilometer/manifests/init.pp', 'deployment/puppet/openstack/manifests/ceilometer.pp', 'deployment/puppet/ceilometer/manifests/alarm/evaluator.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp']",7,38d12227c6f016471dc3b007bb3bbbc62369ff39,bp/ceilometer-support-for-vcenter," $vcenter = true $vcenter = false vcenter => $vcenter,",,28,1
openstack%2Ffuel-library~master~I675dd2b7cdeacae1e703b82001dc2c855511e320,openstack/fuel-library,master,I675dd2b7cdeacae1e703b82001dc2c855511e320,configure nova-compute use one vsphere cluster,MERGED,2014-09-17 20:45:54.000000000,2014-12-18 15:37:38.000000000,2014-12-18 15:37:38.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6926}, {'_account_id': 7732}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11427}, {'_account_id': 12139}, {'_account_id': 13343}]","[{'number': 1, 'created': '2014-09-17 20:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1e719d1858e896a5b687362bde5d83d4730617c9', 'message': ""tie one nova-compute with one vsphere cluster\n\n- create nova-compute individual configuration file per nova-compute;\n  file is named `/etc/nova/nova-compute-%CLUSTER_NAME%.conf', e.g.\n  /etc/nova/nova-compute-Cluster1.conf\n- set `log_file' setting for each nova-compute, so that deployer or\n  field engineer can easily determine which log file nova-compute\n  service instance writes its data\n- set `pid' parameter for each corosync resource, without invidiual PID\n  file pacemaker cannot start several nova-compute instances on same\n  controller, becase monitor() function in OCF file will be checking PID\n  file of first started nova-compute service\n- create appropriate corosync resource/primitive for each nova-compute\n- we use same credentials for all nova-computes\n- remove loop in template `cluster_name' generation\n- consolidate nova-compute service provisioning into separate file\n  vmware/manifests/compute.pp\n\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster\n""}, {'number': 2, 'created': '2014-09-18 14:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/dac4627ad7fb2058937c26a689741e0e6a151d04', 'message': ""tie one nova-compute with one vsphere cluster\n\n- in simple mode thing are left as they are right now, single\n  nova-compute service manages multiple vSphere clusters managed by one\n  vCenter server\n- split template `nova-compute.conf.erb' into two (for simple and HA\n  deployment modes)\n- in HA mode create directory `/etc/nova/nova-compute.d' which will hold\n  all configuration files related to vSphere clusters\n- create individual configuration file per nova-compute; file is named\n  `/etc/nova/nova-compute.d/vcenter-%CLUSTER_NAME%.conf', e.g.\n  /etc/nova/nova-compute.d/vcenter-Cluster1.conf\n- in HA configuration template set `log_file' stanza for each\n  nova-compute, so that deployer or field engineer can easily determine\n  which log file nova-compute service instance writes its diagnostics\n- in HA configuration template set `pid' parameter for each corosync\n  resource, without invidiual PID file pacemaker cannot start several\n  nova-compute instances on same controller, becase monitor() function\n  in OCF file will be checking PID file of first started nova-compute\n  service\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- we use same credentials for all nova-computes\n- consolidate nova-compute service provisioning into separate manifest\n  vmware/manifests/compute.pp\n- change owner and group of /etc/nova/nova-compute.conf to `nova'\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster\n""}, {'number': 3, 'created': '2014-09-18 14:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f3d29f45dac9fcee12a1c3d6004038bf66f019d0', 'message': ""tie one nova-compute with one vsphere cluster\n\n- in simple mode thing are left as they are right now, single\n  nova-compute service manages multiple vSphere clusters managed by one\n  vCenter server\n- split template `nova-compute.conf.erb' into two (for simple and HA\n  deployment modes)\n- in HA mode create directory `/etc/nova/nova-compute.d' which will hold\n  all configuration files related to vSphere clusters\n- create individual configuration file per nova-compute; file is named\n  `/etc/nova/nova-compute.d/vcenter-%CLUSTER_NAME%.conf', e.g.\n  /etc/nova/nova-compute.d/vcenter-Cluster1.conf\n- in HA configuration template set `log_file' stanza for each\n  nova-compute, so that deployer or field engineer can easily determine\n  which log file nova-compute service instance writes its diagnostics\n- in HA configuration template set `pid' parameter for each corosync\n  resource, without invidiual PID file pacemaker cannot start several\n  nova-compute instances on same controller, becase monitor() function\n  in OCF file will be checking PID file of first started nova-compute\n  service\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- we use same credentials for all nova-computes\n- consolidate nova-compute service provisioning into separate manifest\n  vmware/manifests/compute.pp\n- change owner and group of /etc/nova/nova-compute.conf to `nova'\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 4, 'created': '2014-09-19 15:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d94b855dc3a015bc83f5fe8f2201299f27d4f31d', 'message': ""tie one nova-compute with one vsphere cluster\n\n- in simple mode thing are left as they are right now, single\n  nova-compute service manages multiple vSphere clusters managed by one\n  vCenter server\n- split template `nova-compute.conf.erb' into two (for simple and HA\n  deployment modes)\n- in HA mode create directory `/etc/nova/nova-compute.d' which will hold\n  all configuration files related to vSphere clusters\n- create individual configuration file per nova-compute; file is named\n  `/etc/nova/nova-compute.d/vcenter-%CLUSTER_NAME%.conf', e.g.\n  /etc/nova/nova-compute.d/vcenter-Cluster1.conf\n- in HA configuration template set `log_file' stanza for each\n  nova-compute, so that deployer or field engineer can easily determine\n  which log file nova-compute service instance writes its diagnostics\n- in HA configuration template set `pid' parameter for each corosync\n  resource, without invidiual PID file pacemaker cannot start several\n  nova-compute instances on same controller, becase monitor() function\n  in OCF file will be checking PID file of first started nova-compute\n  service\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- we use same credentials for all nova-computes\n- consolidate nova-compute service provisioning into separate manifest\n  vmware/manifests/compute.pp\n- change owner and group of /etc/nova/nova-compute.conf to `nova'\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster\n""}, {'number': 5, 'created': '2014-09-24 14:50:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4a60f399e272c0ce0a38671e61dbf9392be534fb', 'message': ""tie one nova-compute with one vsphere cluster\n\n- in simple mode thing are left as they are right now, single\n  nova-compute service manages multiple vSphere clusters managed by one\n  vCenter server\n- split template `nova-compute.conf.erb' into two (for simple and HA\n  deployment modes)\n- in HA mode create directory `/etc/nova/nova-compute.d' which will hold\n  all configuration files related to vSphere clusters\n- create individual configuration file per nova-compute; file is named\n  `/etc/nova/nova-compute.d/vcenter-%CLUSTER_NAME%.conf', e.g.\n  /etc/nova/nova-compute.d/vcenter-Cluster1.conf\n- in HA configuration template set `log_file' stanza for each\n  nova-compute, so that deployer or field engineer can easily determine\n  which log file nova-compute service instance writes its diagnostics\n- in HA configuration template set `pid' parameter for each corosync\n  resource, without invidiual PID file pacemaker cannot start several\n  nova-compute instances on same controller, becase monitor() function\n  in OCF file will be checking PID file of first started nova-compute\n  service\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- we use same credentials for all nova-computes\n- consolidate nova-compute service provisioning into separate manifest\n  vmware/manifests/compute.pp\n- change owner and group of /etc/nova/nova-compute.conf to `nova'\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster\n""}, {'number': 6, 'created': '2014-09-30 14:02:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/edafe9959b9c6717d04e9dfa18ef2f9313cc71e3', 'message': ""tie one nova-compute with one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_name% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%CLUSTER_NAME%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-Cluster1.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n- change owner and group of /etc/nova/nova-compute.conf to `nova'\n\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster\n""}, {'number': 7, 'created': '2014-10-01 12:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b08dbe0ab61f1b114d178dca5336efb53aa9e271', 'message': ""tie one nova-compute with one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_name% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%CLUSTER_NAME%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-Cluster1.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n- change owner and group of /etc/nova/nova-compute.conf to `nova'\n\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 8, 'created': '2014-10-02 10:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/02fd3f318dfd55a46ea3509ac1425c02f9bbed33', 'message': ""tie one nova-compute with one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_name% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%CLUSTER_NAME%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-Cluster1.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n- change owner and group of /etc/nova/nova-compute.conf to `nova'\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 9, 'created': '2014-10-02 13:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/02b9c27a67ba78b73a4ad319cec532dcf93980db', 'message': ""tie one nova-compute with one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 10, 'created': '2014-10-02 13:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9c7badf2ccfb46891367f6331935de3918e7f9b7', 'message': ""tie one nova-compute with one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 11, 'created': '2014-10-02 13:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/094c6d115e5f56eef22839cc2341e95e996e315a', 'message': ""tie one nova-compute with one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 12, 'created': '2014-10-02 13:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/be4bb27ed00df4f27a2537e32bffd01ee0614754', 'message': ""tie one nova-compute with one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 13, 'created': '2014-10-02 13:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c324d10c60e3fb7e58a49c007181d46ba397f997', 'message': ""tie one nova-compute with one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 14, 'created': '2014-10-02 14:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e188ae119642a514dbbe4bec81bd8965f180ce32', 'message': ""tie one nova-compute with one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 15, 'created': '2014-10-06 13:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e12d9a1762355933e2d0caba3867df03efd38f8d', 'message': ""tie one nova-compute with one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 16, 'created': '2014-10-09 14:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c57a0869d82bf721a1539663b9e71642bb236766', 'message': ""configure nova-compute use one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- Ubuntu init system (Upstart) requires initd service to be restarted,\n  on CentOS we run '/bin/true'\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service in case of HA\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 17, 'created': '2014-10-21 20:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4c25a14b44c0a1b68715d5ba48b98a5f55fdc901', 'message': ""configure nova-compute use one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- Ubuntu init system (Upstart) requires initd service to be restarted,\n  on CentOS we run '/bin/true'\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service in case of HA\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n- set 'multi_host' configuration stanza to False for both deployment\n  modes (nonHA/HA)\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 18, 'created': '2014-10-24 14:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/55d3e6683307a1fc84aefdc7c5f94401a8675e36', 'message': ""configure nova-compute use one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- Ubuntu init system (Upstart) requires initd service to be restarted,\n  on CentOS we run '/bin/true'\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service in case of HA\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n- set 'multi_host' configuration stanza to False for both deployment\n  modes (nonHA/HA)\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 19, 'created': '2014-10-27 19:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/485fd6f0022c64072d7f6d4c7f95065485d1fe28', 'message': ""configure nova-compute use one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- Ubuntu init system (Upstart) requires initd service to be restarted,\n  on CentOS we run '/bin/true'\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service in case of HA\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n- set 'multi_host' configuration stanza to False for both deployment\n  modes (nonHA/HA)\n- add basic unit test coverage for provided functionality\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 20, 'created': '2014-11-06 16:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d96e6229d9fe39491344d079422895c47759943e', 'message': ""configure nova-compute use one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- Ubuntu init system (Upstart) requires initd service to be restarted,\n  on CentOS we run '/bin/true'\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service in case of HA\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n- set 'multi_host' configuration stanza to False for both deployment\n  modes (nonHA/HA)\n- add basic unit test coverage for provided functionality\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 21, 'created': '2014-12-17 15:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b83176473bb85a32d634b1cfccb5ce962d6fbc2b', 'message': ""configure nova-compute use one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- Ubuntu init system (Upstart) requires initd service to be restarted,\n  on CentOS we run '/bin/true'\n- create individual nova-compute configuration file per vsphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service in case of HA\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n- set 'multi_host' configuration stanza to False for both deployment\n  modes (nonHA/HA)\n- add basic unit test coverage for provided functionality\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 22, 'created': '2014-12-17 17:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6cc2fa126666952a3db9b9e6249681523129b6d6', 'message': ""configure nova-compute use one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- Ubuntu init system (Upstart) requires initd service to be restarted,\n  on CentOS we run '/bin/true'\n- create individual nova-compute configuration file per vSphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service in case of HA\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n- set 'multi_host' configuration stanza to False for both deployment\n  modes (nonHA/HA)\n- add basic unit test coverage for provided functionality\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}, {'number': 23, 'created': '2014-12-17 19:52:55.000000000', 'files': ['deployment/puppet/vmware/Gemfile', 'deployment/puppet/vmware/spec/functions/vmware_index_spec.rb', 'deployment/puppet/vmware/spec/spec_helper.rb', 'deployment/puppet/vmware/spec/defines/vmware_compute_simple_spec.rb', 'deployment/puppet/vmware/manifests/controller.pp', 'deployment/puppet/vmware/manifests/compute/simple.pp', 'deployment/puppet/vmware/manifests/network/nova.pp', 'deployment/puppet/vmware/spec/classes/controller_spec.rb', 'deployment/puppet/vmware/.fixtures.yml', 'deployment/puppet/vmware/spec/defines/vmware_compute_ha_spec.rb', 'deployment/puppet/vmware/manifests/compute/ha.pp', 'deployment/puppet/vmware/files/nova-compute-init-centos', 'deployment/puppet/vmware/templates/nova-compute.conf.erb', 'deployment/puppet/vmware/manifests/init.pp', 'deployment/puppet/vmware/lib/puppet/parser/functions/vmware_index.rb', 'deployment/puppet/vmware/files/nova-compute-init-ubuntu', 'deployment/puppet/vmware/spec/spec.opts', 'deployment/puppet/vmware/Rakefile'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/47c5088be0ec4486398b2db3196cfce82a661846', 'message': ""configure nova-compute use one vsphere cluster\n\n- create separate directory '/etc/nova/nova-compute.d' where all\n  configuration files that hold all configuration stanzas related to\n  vmware compute driver\n- in simple mode we upload init script in appropriate directory and\n  create symbolic links on it that are named like\n  nova-compute-vmware-%cluster_id% ; script internally splits its own\n  file name and extracts cluster name.  This allow user to selectively\n  start/stop nova-compute services.\n- Ubuntu init system (Upstart) requires initd service to be restarted,\n  on CentOS we run '/bin/true'\n- create individual nova-compute configuration file per vSphere cluster;\n  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',\n  e.g.  /etc/nova/nova-compute.d/vmware-0.conf\n- create appropriate corosync resource/primitive per nova-compute\n  service in case of HA\n- currently we use same login and password for all nova-computes\n- set more strict access permissions (0600) on nova-compute.conf and\n  generated files in `nova-compute.d' directory; these files hold\n  sensitive information (credentials to vCenter server)\n- set 'multi_host' configuration stanza to False for both deployment\n  modes (nonHA/HA)\n- add basic unit test coverage for provided functionality\n\nDocImpact\nChange-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320\nImpelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping\n""}]",2,122242,47c5088be0ec4486398b2db3196cfce82a661846,167,12,23,11427,,,0,"configure nova-compute use one vsphere cluster

- create separate directory '/etc/nova/nova-compute.d' where all
  configuration files that hold all configuration stanzas related to
  vmware compute driver
- in simple mode we upload init script in appropriate directory and
  create symbolic links on it that are named like
  nova-compute-vmware-%cluster_id% ; script internally splits its own
  file name and extracts cluster name.  This allow user to selectively
  start/stop nova-compute services.
- Ubuntu init system (Upstart) requires initd service to be restarted,
  on CentOS we run '/bin/true'
- create individual nova-compute configuration file per vSphere cluster;
  file is named `/etc/nova/nova-compute.d/vmware-%cluster_id%.conf',
  e.g.  /etc/nova/nova-compute.d/vmware-0.conf
- create appropriate corosync resource/primitive per nova-compute
  service in case of HA
- currently we use same login and password for all nova-computes
- set more strict access permissions (0600) on nova-compute.conf and
  generated files in `nova-compute.d' directory; these files hold
  sensitive information (credentials to vCenter server)
- set 'multi_host' configuration stanza to False for both deployment
  modes (nonHA/HA)
- add basic unit test coverage for provided functionality

DocImpact
Change-Id: I675dd2b7cdeacae1e703b82001dc2c855511e320
Impelements: blueprint 1-1-nova-compute-vsphere-cluster-mapping
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/42/122242/16 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/vmware/templates/nova-compute.conf.erb', 'deployment/puppet/vmware/manifests/controller.pp', 'deployment/puppet/vmware/manifests/compute.pp']",3,1e719d1858e896a5b687362bde5d83d4730617c9,bp/1-1-nova-compute-vsphere-cluster-mapping,"# This resource creates nova-compute service for provided vSphere # clusters (cluster that is formed of ESXi hosts and is managed by vCenter # server. define vmware::compute( $amqp_port = '5673', $api_retry_count = 5, $compute_driver = 'vmwareapi.VMwareVCDriver', $maximum_objects = 100, $nova_conf = '/etc/nova/nova.conf', $task_poll_interval = 5.0, $use_linked_clone = true, ) { $nova_compute_conf = ""/etc/nova/nova-compute-${name}.conf"" file { ""${nova_compute_conf}"": content => template(""vmware/nova-compute.conf.erb""), mode => 0644, owner => root, group => root, ensure => present, } cs_resource { ""p_vcenter_nova_compute_${name}"": ensure => present, primitive_class => 'ocf', provided_by => 'mirantis', primitive_type => 'nova-compute', metadata => { resource-stickiness => '1' }, parameters => { amqp_server_port => $amqp_port, config => $nova_conf, pid => ""/var/run/nova/nova-compute-${name}.pid"", additional_parameters => ""--config-file=${nova_compute_conf}"", }, operations => { monitor => { interval => '20', timeout => '10', }, start => { timeout => '30', }, stop => { timeout => '30', } } } service { ""p_vcenter_nova_compute_${name}"": ensure => running, enable => true, provider => 'pacemaker', } } ",,78,83
openstack%2Fzaqar~master~I9ab6296a6b955b6dc01cc01a94619cf784664afc,openstack/zaqar,master,I9ab6296a6b955b6dc01cc01a94619cf784664afc,Updated from global requirements,MERGED,2014-12-11 07:21:14.000000000,2014-12-18 15:30:33.000000000,2014-12-18 15:30:31.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 7488}]","[{'number': 1, 'created': '2014-12-11 07:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e93271fcacf1d98b6f41ebc837af0930b567c744', 'message': 'Updated from global requirements\n\nChange-Id: I9ab6296a6b955b6dc01cc01a94619cf784664afc\n'}, {'number': 2, 'created': '2014-12-12 22:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7608316e8bd6233890f382677c6f49f80d4c2395', 'message': 'Updated from global requirements\n\nChange-Id: I9ab6296a6b955b6dc01cc01a94619cf784664afc\n'}, {'number': 3, 'created': '2014-12-16 19:37:48.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/17d9177272f530f23840399af43d77dc06834e50', 'message': 'Updated from global requirements\n\nChange-Id: I9ab6296a6b955b6dc01cc01a94619cf784664afc\n'}]",0,140963,17d9177272f530f23840399af43d77dc06834e50,14,3,3,11131,,,0,"Updated from global requirements

Change-Id: I9ab6296a6b955b6dc01cc01a94619cf784664afc
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/63/140963/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,e93271fcacf1d98b6f41ebc837af0930b567c744,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,2,2
openstack%2Fnova~master~I9152594962a7c14f69737eab7d50b4e31f8d71bc,openstack/nova,master,I9152594962a7c14f69737eab7d50b4e31f8d71bc,Fix import group ordering errors,ABANDONED,2014-11-18 17:36:28.000000000,2014-12-18 15:27:34.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6928}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-18 17:36:28.000000000', 'files': ['nova/virt/hyperv/vhdutilsv2.py', 'nova/tests/unit/api/openstack/compute/contrib/test_attach_interfaces.py', 'nova/tests/unit/virt/libvirt/test_fakelibvirt.py', 'nova/virt/hyperv/vhdutils.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_server_attributes.py', 'nova/tests/unit/api/test_wsgi.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py', 'nova/virt/disk/vfs/api.py', 'nova/objects/instance.py', 'nova/tests/unit/virt/hyperv/test_ioutils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/82f1fec45a8b3d7d85efe24e75ed46089481826f', 'message': 'Fix import group ordering errors\n\nThis fixes all current failures of the forthcoming H308 hacking\ncheck.\n\nChange-Id: I9152594962a7c14f69737eab7d50b4e31f8d71bc\n'}]",0,135373,82f1fec45a8b3d7d85efe24e75ed46089481826f,9,8,1,6928,,,0,"Fix import group ordering errors

This fixes all current failures of the forthcoming H308 hacking
check.

Change-Id: I9152594962a7c14f69737eab7d50b4e31f8d71bc
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/135373/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/vhdutilsv2.py', 'nova/tests/unit/api/openstack/compute/contrib/test_attach_interfaces.py', 'nova/tests/unit/virt/libvirt/test_fakelibvirt.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_server_attributes.py', 'nova/tests/unit/api/test_wsgi.py', 'nova/virt/hyperv/vhdutils.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py', 'nova/virt/disk/vfs/api.py', 'nova/objects/instance.py', 'nova/tests/unit/virt/hyperv/test_ioutils.py']",10,82f1fec45a8b3d7d85efe24e75ed46089481826f,h308,import mock ,import mock ,14,21
openstack%2Fceilometer~master~I568b5ca3d84371c4fd3bbdfed7b3e801164dbc5e,openstack/ceilometer,master,I568b5ca3d84371c4fd3bbdfed7b3e801164dbc5e,[SQLalchemy] Add groupby ability resource_metadata,MERGED,2014-12-12 14:43:43.000000000,2014-12-18 15:26:35.000000000,2014-12-18 15:26:33.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-12 14:43:43.000000000', 'files': ['ceilometer/storage/impl_sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f1439a1fe467525ac24039048350f8c6105ad93c', 'message': '[SQLalchemy] Add groupby ability resource_metadata\n\nIt would be useful to have groupby functionality to derive meters\nby their resource_metadata. This commit adds groupby by\nresource_metadata.instance_type for sqlalchemy.\n\nChange-Id: I568b5ca3d84371c4fd3bbdfed7b3e801164dbc5e\nPartially-Closes-Bug: 1331508\n'}]",0,141389,f1439a1fe467525ac24039048350f8c6105ad93c,15,6,1,13273,,,0,"[SQLalchemy] Add groupby ability resource_metadata

It would be useful to have groupby functionality to derive meters
by their resource_metadata. This commit adds groupby by
resource_metadata.instance_type for sqlalchemy.

Change-Id: I568b5ca3d84371c4fd3bbdfed7b3e801164dbc5e
Partially-Closes-Bug: 1331508
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/89/141389/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/storage/impl_sqlalchemy.py'],1,f1439a1fe467525ac24039048350f8c6105ad93c,bug/1331508," group_attributes = [] for g in groupby: if g != 'resource_metadata.instance_type': group_attributes.append(getattr(models.Resource, g)) else: group_attributes.append( getattr(models.MetaText, 'value') .label('resource_metadata.instance_type')) query = ( session.query(*select) .join(models.Meter, models.Meter.id == models.Sample.meter_id) .join(models.Resource, models.Resource.internal_id == models.Sample.resource_id) .group_by(models.Meter.unit)) for g in groupby: if g == 'resource_metadata.instance_type': query = query.join( models.MetaText, models.Resource.internal_id == models.MetaText.id) query = query.filter( models.MetaText.meta_key == 'instance_type') if group not in ['user_id', 'project_id', 'resource_id', 'resource_metadata.instance_type']:"," group_attributes = [getattr(models.Resource, g) for g in groupby] query = (session.query(*select) .join(models.Meter, models.Meter.id == models.Sample.meter_id) .join( models.Resource, models.Resource.internal_id == models.Sample.resource_id) .group_by(models.Meter.unit)) if group not in ['user_id', 'project_id', 'resource_id']:",25,9
openstack%2Fkeystone~master~I48a045cd9ec5e80c7a9bccdbd8f6e11b783fb9e9,openstack/keystone,master,I48a045cd9ec5e80c7a9bccdbd8f6e11b783fb9e9,Max complexity check considered harmful,ABANDONED,2014-12-09 00:46:53.000000000,2014-12-18 15:04:15.000000000,,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 8871}, {'_account_id': 9142}]","[{'number': 1, 'created': '2014-12-09 00:46:53.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/46285c7f35c5c51147380a3fdba960b529b704cf', 'message': ""Max complexity check considered harmful\n\nThe max complexity check will lead to poor code structure. Worse\nthan if the check wasn't there. This is because the check doesn't\nconsider an embedded function separate from the function it's in.\n\nChange-Id: I48a045cd9ec5e80c7a9bccdbd8f6e11b783fb9e9\n""}]",0,140188,46285c7f35c5c51147380a3fdba960b529b704cf,12,4,1,6486,,,0,"Max complexity check considered harmful

The max complexity check will lead to poor code structure. Worse
than if the check wasn't there. This is because the check doesn't
consider an embedded function separate from the function it's in.

Change-Id: I48a045cd9ec5e80c7a9bccdbd8f6e11b783fb9e9
",git fetch https://review.opendev.org/openstack/keystone refs/changes/88/140188/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,46285c7f35c5c51147380a3fdba960b529b704cf,considered_harmful,,max-complexity=24,0,1
openstack%2Fmonasca-api~master~Ica644ada7b97f974a542a96fdf0d424b154a2e96,openstack/monasca-api,master,Ica644ada7b97f974a542a96fdf0d424b154a2e96,Factor out SubAlarmDefinition class into separate file,MERGED,2014-12-17 15:29:30.000000000,2014-12-18 15:00:48.000000000,2014-12-18 15:00:47.000000000,"[{'_account_id': 3}, {'_account_id': 10046}, {'_account_id': 11809}]","[{'number': 1, 'created': '2014-12-17 15:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/7afbfa6a2522a383dfa5e6e749010254c72025c5', 'message': 'Factor out SubAlarmDefinition class into separate file\n\nChange-Id: Ica644ada7b97f974a542a96fdf0d424b154a2e96\n'}, {'number': 2, 'created': '2014-12-17 20:44:58.000000000', 'files': ['monasca/common/repositories/model/__init__.py', 'monasca/common/repositories/mysql/alarm_definitions_repository.py', 'monasca/common/repositories/mysql/mysql_repository.py', 'monasca/common/repositories/model/sub_alarm_definition.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/59ee7581cc08dde9930e479dce7fd62ad8723ba1', 'message': 'Factor out SubAlarmDefinition class into separate file\n\nChange-Id: Ica644ada7b97f974a542a96fdf0d424b154a2e96\n'}]",0,142466,59ee7581cc08dde9930e479dce7fd62ad8723ba1,9,3,2,12512,,,0,"Factor out SubAlarmDefinition class into separate file

Change-Id: Ica644ada7b97f974a542a96fdf0d424b154a2e96
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/66/142466/2 && git format-patch -1 --stdout FETCH_HEAD,"['monasca/common/repositories/model/__init__.py', 'monasca/common/repositories/mysql/alarm_definitions_repository.py', 'monasca/common/repositories/mysql/mysql_repository.py', 'monasca/common/repositories/model/sub_alarm_definition.py']",4,7afbfa6a2522a383dfa5e6e749010254c72025c5,feature/refactor-SubAlarmDefinition,"# Copyright 2014 Hewlett-Packard # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. class SubAlarmDefinition(object): """"""Holds sub alarm definition Used for comparing sub alarm definitions for equality. """""" def __init__(self, row=None, sub_expr=None): """"""Initialize :param row: Database row :param sub_expr: Result from expression parser :return: """""" super(SubAlarmDefinition, self).__init__() if row and sub_expr: raise Exception('Only one of row or sub_expr can be specified, ' 'not both') if row: # id is not used for compare or hash. self.id = row['id'] self.alarm_definition_id = row['alarm_definition_id'] self.metric_name = row['metric_name'] self.dimensions_str = row['dimensions'] self.dimensions = self._init_dimensions(row['dimensions']) self.function = row['function'] self.operator = row['operator'] # Make sure that the following are converted to unicode self.period = str(row['period']).decode('utf8') self.periods = str(row['periods']).decode('utf8') # threshold comes from the DB as a float in 0.0 form. self.threshold = str(row['threshold']).decode('utf8') if sub_expr: # id is not used for compare or hash. self.id = '' # Must be injected. self.alarm_definition_id = '' self.metric_name = sub_expr.metric_name self.dimensions_str = sub_expr.dimensions_str self.dimensions = self._init_dimensions(sub_expr.dimensions_str) self.function = sub_expr.normalized_func.decode('utf8') self.operator = sub_expr.normalized_operator self.period = sub_expr.period self.periods = sub_expr.periods self.threshold = sub_expr.threshold def _init_dimensions(self, dimensions_str): dimensions = {} if dimensions_str: for dimension in dimensions_str.split(','): name, value = dimension.split('=') dimensions[name] = value return dimensions @property def expression(self): """"""Build the entire expressions as a string with spaces."""""" result = ""{}({}"".format(self.function.lower().encode('utf8'), self.metric_name.encode('utf8')) if self.dimensions_str: result += ""{{{}}}"".format(self.dimensions_str.encode('utf8')) if self.period: result += "", {}"".format(self.period.encode('utf8')) result += "")"" result += "" {} {}"".format(self.operator.encode('utf8'), self.threshold.encode('utf8')) if self.periods: result += "" times {}"".format(self.periods.encode('utf8')) return result.decode('utf8') def __hash__(self): dimensions_str = """".join(sorted([name + value for name, value in self.dimensions.iteritems()])) # don't use id to hash. return (hash(self.alarm_definition_id) ^ hash(dimensions_str) ^ hash(self.function) ^ hash(self.metric_name) ^ hash(self.operator) ^ hash(self.period) ^ hash(self.periods) ^ # Convert to float to handle cases like 0.0 == 0 hash(float(self.threshold))) def __eq__(self, other): if id(self) == id(other): return True if not isinstance(other, SubAlarmDefinition): return False # don't use id to compare. return (self.alarm_definition_id == other.alarm_definition_id and self.dimensions == other.dimensions and self.function == other.function and self.metric_name == other.metric_name and self.operator == other.operator and self.period == other.period and self.periods == other.periods and # Convert to float to handle cases like 0.0 == 0 float(self.threshold) == float(other.threshold)) def same_key_fields(self, other): # compare everything but operator and threshold return (self.metric_name == other.metric_name and self.dimensions == other.dimensions and self.function == other.function and self.period == other.period and self.periods == other.periods)",,146,132
openstack%2Fmanila~master~I2744cccfbe2c09c3d942822f902793493cd9befb,openstack/manila,master,I2744cccfbe2c09c3d942822f902793493cd9befb,Add driver mode interface,MERGED,2014-11-24 09:46:03.000000000,2014-12-18 14:54:12.000000000,2014-12-18 14:54:12.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 6529}, {'_account_id': 7102}, {'_account_id': 7331}, {'_account_id': 7534}, {'_account_id': 8851}, {'_account_id': 11878}]","[{'number': 1, 'created': '2014-11-24 09:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/20ec67af4e8bae99661c3767536ad4d38b77df46', 'message': ""Mode selection for Manila drivers\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'mode' which can possess values 'single_svm', 'managed_multi_svm'.\n\nAdd 'mode' attribute to generic driver (only 'managed_multi_svm' mode is available now).\n\nImplements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 2, 'created': '2014-11-25 08:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1c27a80c63e694c5a9c7d71701f7cc5681d0b357', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_mode' which can possess values\n'single_svm', 'managed_multi_svm'.\n\nAdd 'mode' attribute to share driver (for generic driver only 'managed_multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 3, 'created': '2014-11-26 08:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c9757a90980bb39f14312043a1ebcdf16b20267a', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_mode' which can possess multiple\nvalues at a time'.\n\nAdd 'mode' attribute to share driver (for generic driver only 'managed_multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 4, 'created': '2014-12-03 08:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/747de3c7fe67c0b11a6bfba02a66b7973c9d4025', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'mode' attribute to share driver (for generic driver only 'managed_multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 5, 'created': '2014-12-04 08:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f136f76c263d421dee86760e6fa31fb7a0a9e672', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'mode' attribute to share driver (for generic driver only 'managed_multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 6, 'created': '2014-12-04 09:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/25b660af5a275dbbfb27d21fa1e802284bb384bb', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'mode' attribute to share driver (for generic driver only 'managed_multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 7, 'created': '2014-12-05 07:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/560c80642b328d2b14261b1378b844b93c658e76', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'mode' attribute to share driver (for generic driver only 'managed_multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 8, 'created': '2014-12-05 08:45:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ca436031a23bd070505ca4d625728b50ae39219d', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'mode' attribute to share driver (for generic driver only 'managed_multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 9, 'created': '2014-12-08 07:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/34a260caa30771706c8c3f3d09f17b67ef155bb2', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'mode' attribute to share driver (for generic driver only 'managed_multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 10, 'created': '2014-12-09 08:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/14f03e0da2e3b9668cfd818d3ae16d92f54a28bf', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'mode' attribute to share driver (for generic driver only 'managed_multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 11, 'created': '2014-12-09 08:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/932347989ee446dc5113fd7c1715d323aa481de3', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'modes' attribute to generic share driver (for generic driver only 'multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 12, 'created': '2014-12-09 09:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/34f35a35a52624426bc2b38959ba62a1741ebe8a', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'modes' attribute to generic share driver (for generic driver only 'multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 13, 'created': '2014-12-17 10:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2a3fe165a7d50bc763ef54ff75e28b777fb334a5', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'modes' attribute to generic share driver (for generic driver only 'multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 14, 'created': '2014-12-17 14:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/000240be6f6574267a3fe798bf9a5cf2573ac76e', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'modes' attribute to generic share driver (for generic driver only 'multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 15, 'created': '2014-12-18 09:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/19471645bd1b8bca9a9edbd76f04486687368cd2', 'message': ""Add 'share_driver_mode' config option\n\nThe addition of driver modes allows the administrator to tell Manila\nhow each driver should operate.\n\nAdd new config parameter 'share_driver_modes' which can possess multiple\nvalues at a time.\n\nAdd 'modes' attribute to generic share driver (for generic driver only 'multi_svm'\nmode is available now).\n\nPartially Implements bp driver-modes\n\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 16, 'created': '2014-12-18 12:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f00ef538bbcc34d543a3acd37d6563203e1509a7', 'message': ""Add driver mode interface\n\nImplement driver mode interface for share driver, that will allow operator\nto switch share drivers to work in specific mode, like single or multi SVM.\n\nAdd usage of driver mode interface to Generic driver as an example.\n\nTo set driver mode use config option 'share_driver_mode'. Available values\nare specified within its help message.\n\nPartially Implements bp driver-modes\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 17, 'created': '2014-12-18 12:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0ff83f107a1bd78ec8c15b4d92787bd3604c206a', 'message': ""Add driver mode interface\n\nImplement driver mode interface for share driver, that will allow operator\nto switch share drivers to work in specific mode, like single or multi SVM.\n\nAdd usage of driver mode interface to Generic driver as an example.\n\nTo set driver mode use config option 'share_driver_mode'. Available values\nare specified within its help message.\n\nPartially Implements bp driver-modes\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 18, 'created': '2014-12-18 12:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/927777bfc3c66256455dffba6fa5dd70b4d393b1', 'message': ""Add driver mode interface\n\nImplement driver mode interface for share driver, that will allow operator\nto switch share drivers to work in specific mode, like single or multi SVM.\n\nAdd usage of driver mode interface to Generic driver as an example.\n\nTo set driver mode use config option 'share_driver_mode'. Available values\nare specified within its help message.\n\nPartially Implements bp driver-modes\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}, {'number': 19, 'created': '2014-12-18 13:20:49.000000000', 'files': ['manila/tests/fake_driver.py', 'manila/tests/share/drivers/test_generic.py', 'manila/tests/share/test_driver.py', 'manila/share/driver.py', 'manila/common/constants.py', 'manila/share/drivers/generic.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/28f311c9ad392a8d2bb21373e57f4792049dc793', 'message': ""Add driver mode interface\n\nImplement driver mode interface for share driver, that will allow operator\nto switch share drivers to work in specific mode, like single or multi SVM.\n\nAdd usage of driver mode interface to Generic driver as an example.\n\nTo set driver mode use config option 'share_driver_mode'. Available values\nare specified within its help message.\n\nPartially Implements bp driver-modes\nChange-Id: I2744cccfbe2c09c3d942822f902793493cd9befb\n""}]",49,136714,28f311c9ad392a8d2bb21373e57f4792049dc793,70,9,19,7331,,,0,"Add driver mode interface

Implement driver mode interface for share driver, that will allow operator
to switch share drivers to work in specific mode, like single or multi SVM.

Add usage of driver mode interface to Generic driver as an example.

To set driver mode use config option 'share_driver_mode'. Available values
are specified within its help message.

Partially Implements bp driver-modes
Change-Id: I2744cccfbe2c09c3d942822f902793493cd9befb
",git fetch https://review.opendev.org/openstack/manila refs/changes/14/136714/14 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/fake_driver.py', 'manila/share/manager.py', 'manila/share/driver.py', 'manila/share/drivers/generic.py', 'manila/tests/share/test_manager.py']",5,20ec67af4e8bae99661c3767536ad4d38b77df46,bp/driver-modes," def test_create_share_with_sn_id_single_svm_mode(self): self.share_manager.driver.mode = 'single_svm' share_net = self._create_share_network() share = self._create_share(share_network_id=share_net['id']) share_ref = db.share_get(self.context, share['id']) export_location = 'fake_location' self.stubs.Set(self.share_manager, '_provide_share_server_for_share', mock.Mock()) self.stubs.Set(self.share_manager.driver, 'create_share', mock.Mock(return_value=export_location)) self.stubs.Set(db, 'share_update', mock.Mock()) self.stubs.Set(db, 'share_get', mock.Mock(return_value=share_ref)) self.share_manager.create_share(self.context, share['id']) self.assertFalse( self.share_manager._provide_share_server_for_share.called) self.share_manager.driver.create_share.assert_called_once_with( mock.ANY, share_ref, share_server=None) db.share_update.assert_has_called(mock.ANY, share['id'], export_location) ",,40,1
openstack%2Fglance_store~master~I8e315628dbada85506d42fa4c08aedb5f82c852f,openstack/glance_store,master,I8e315628dbada85506d42fa4c08aedb5f82c852f,Swift Store to use Multiple Containers,MERGED,2014-10-02 20:13:51.000000000,2014-12-18 14:45:58.000000000,2014-12-18 14:45:57.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 2537}, {'_account_id': 2835}, {'_account_id': 5202}, {'_account_id': 8158}, {'_account_id': 8871}, {'_account_id': 11391}]","[{'number': 1, 'created': '2014-10-02 20:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/054550e18dae88ff37121b8f5c2b21f61cb24198', 'message': 'Swift Store to use Multiple Containers\n\nSwift Store will now use multiple containers in single-tenant mode\nin order to avoid swift rate limiting on a single container\n\nRelated spec: https://review.openstack.org/#/c/124522i\n\nThis is a WORK IN PROGRESS commit\n\nChange-Id: I8e315628dbada85506d42fa4c08aedb5f82c852f\n'}, {'number': 2, 'created': '2014-10-02 20:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/c850a33fd274f670d2e34df174ba287b1288a1ab', 'message': 'Swift Store to use Multiple Containers\n\nSwift Store will now use multiple containers in single-tenant mode\nin order to avoid swift rate limiting on a single container\n\nRelated spec: https://review.openstack.org/#/c/124522i\n\nThis is a WORK IN PROGRESS commit\n\nChange-Id: I8e315628dbada85506d42fa4c08aedb5f82c852f\n'}, {'number': 3, 'created': '2014-10-02 20:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/22cf03cc9277ef9f0b1a39eecb1c0f4cc8fd7ee6', 'message': 'Swift Store to use Multiple Containers\n\nSwift Store will now use multiple containers in single-tenant mode\nin order to avoid swift rate limiting on a single container\n\nRelated spec: https://review.openstack.org/#/c/124522i\n\nThis is a WORK IN PROGRESS commit\n\nChange-Id: I8e315628dbada85506d42fa4c08aedb5f82c852f\n'}, {'number': 4, 'created': '2014-10-03 14:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/0133e3827d5a1a1f45af161c746a11760ad192ba', 'message': 'Swift Store to use Multiple Containers\n\nSwift Store will now use multiple containers in single-tenant mode\nin order to avoid swift rate limiting on a single container\n\nRelated spec: https://review.openstack.org/#/c/124522\n\nThis is a WORK IN PROGRESS commit\n\nChange-Id: I8e315628dbada85506d42fa4c08aedb5f82c852f\n'}, {'number': 5, 'created': '2014-10-08 19:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/376ac59f6651d13ac0bd98861e73c4a3918faac9', 'message': 'Swift Store to use Multiple Containers\n\nSwift Store will now use multiple containers in single-tenant mode\nin order to avoid swift rate limiting on a single container\n\nRelated spec: https://review.openstack.org/#/c/124522\n\nThis is a WORK IN PROGRESS commit\n\nChange-Id: I8e315628dbada85506d42fa4c08aedb5f82c852f\n'}, {'number': 6, 'created': '2014-10-24 17:43:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/bc30722306f2a07eb4cfd43fa4ca9fc4303d419f', 'message': 'Swift Store to use Multiple Containers\n\nSwift Store will now use multiple containers in single-tenant mode\nin order to avoid swift rate limiting on a single container\n\nRelated spec: https://review.openstack.org/#/c/124522\n\nThis is a WORK IN PROGRESS commit\n\nChange-Id: I8e315628dbada85506d42fa4c08aedb5f82c852f\n'}, {'number': 7, 'created': '2014-12-12 20:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/907652c860450d1394c1048909aa8f59a649c05a', 'message': 'Swift Store to use Multiple Containers\n\nSwift Store will now use multiple containers in single-tenant mode\nin order to avoid swift rate limiting on a single container\n\nApproved spec:\n https://review.openstack.org/#/c/124522\n\nRelated blueprint:\n https://blueprints.launchpad.net/glance/+spec/swift-store-multiple-containers\n\nChange-Id: I8e315628dbada85506d42fa4c08aedb5f82c852f\n'}, {'number': 8, 'created': '2014-12-15 20:23:36.000000000', 'files': ['glance_store/_drivers/swift/store.py', 'tests/unit/test_swift_store.py', 'tests/unit/test_opts.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/3cd690b37dc9d935445aca0998e8aec34a3e3530', 'message': 'Swift Store to use Multiple Containers\n\nSwift Store will now use multiple containers in single-tenant mode\nin order to avoid swift rate limiting on a single container\n\nApproved spec:\n https://review.openstack.org/#/c/124522\n\nbp: swift-store-multiple-containers\nChange-Id: I8e315628dbada85506d42fa4c08aedb5f82c852f\n'}]",6,125760,3cd690b37dc9d935445aca0998e8aec34a3e3530,36,8,8,11864,,,0,"Swift Store to use Multiple Containers

Swift Store will now use multiple containers in single-tenant mode
in order to avoid swift rate limiting on a single container

Approved spec:
 https://review.openstack.org/#/c/124522

bp: swift-store-multiple-containers
Change-Id: I8e315628dbada85506d42fa4c08aedb5f82c852f
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/60/125760/7 && git format-patch -1 --stdout FETCH_HEAD,"['glance_store/_drivers/swift/store.py', 'tests/unit/test_swift_store.py', 'tests/unit/test_opts.py']",3,054550e18dae88ff37121b8f5c2b21f61cb24198,bp/swift-store-multiple-containers," 'swift_store_multiple_containers_seed', 'swift_store_use_multiple_containers',",,338,2
openstack%2Fkeystone-specs~master~Iff76f9dad9658c8ab015e05d3b64f5fade0f7673,openstack/keystone-specs,master,Iff76f9dad9658c8ab015e05d3b64f5fade0f7673,Add requirement for APIImpact flag,MERGED,2014-10-31 17:00:11.000000000,2014-12-18 14:42:35.000000000,2014-12-18 14:42:35.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1112}, {'_account_id': 5046}, {'_account_id': 5292}, {'_account_id': 6460}, {'_account_id': 8978}, {'_account_id': 11022}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-10-31 17:00:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/f3aec209e1402e2f8b5888a1c2192768694f9553', 'message': 'Add requirement for APIImpact flag\n\nAdds a requirement for an APIImpact flag in\nthe commit message for a proposed spec if it proposes\nchanges to the HTTP API. This will make it\nmuch easier for people such as the API WG who want to\nreview API changes across OpenStack to find and\nreview proposed API changes.\n\nChange-Id: Iff76f9dad9658c8ab015e05d3b64f5fade0f7673\n'}, {'number': 2, 'created': '2014-10-31 19:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/6ee20a38fb7b7c358e700b4f54a35973ff4ce641', 'message': 'Add requirement for APIImpact flag\n\nAdds a requirement for an APIImpact flag in\nthe commit message for a proposed spec if it proposes\nchanges to the HTTP API. This will make it\nmuch easier for people such as the API WG who want to\nreview API changes across OpenStack to find and\nreview proposed API changes.\n\nChange-Id: Iff76f9dad9658c8ab015e05d3b64f5fade0f7673\n'}, {'number': 3, 'created': '2014-10-31 19:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/7c282198130c1f6ae168171855c254e3fa9aaccb', 'message': 'Add requirement for APIImpact flag\n\nAdds a requirement for an APIImpact flag in\nthe commit message for a proposed spec if it proposes\nchanges to the HTTP API. This will make it\nmuch easier for people such as the API WG who want to\nreview API changes across OpenStack to find and\nreview proposed API changes.\n\nChange-Id: Iff76f9dad9658c8ab015e05d3b64f5fade0f7673\n'}, {'number': 4, 'created': '2014-11-19 23:20:51.000000000', 'files': ['specs/template.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/d6e636ec577a481a7672e26c2a1c043718d3ab92', 'message': 'Add requirement for APIImpact flag\n\nAdds a requirement for an APIImpact flag in\nthe commit message for a proposed spec if it proposes\nchanges to the HTTP API. This will make it\nmuch easier for people such as the API WG who want to\nreview API changes across OpenStack to find and\nreview proposed API changes.\n\nChange-Id: Iff76f9dad9658c8ab015e05d3b64f5fade0f7673\n'}]",8,132303,d6e636ec577a481a7672e26c2a1c043718d3ab92,24,9,4,1112,,,0,"Add requirement for APIImpact flag

Adds a requirement for an APIImpact flag in
the commit message for a proposed spec if it proposes
changes to the HTTP API. This will make it
much easier for people such as the API WG who want to
review API changes across OpenStack to find and
review proposed API changes.

Change-Id: Iff76f9dad9658c8ab015e05d3b64f5fade0f7673
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/03/132303/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/template.rst'],1,f3aec209e1402e2f8b5888a1c2192768694f9553,add_api_impact_flag,"* If your spec has an impact on the HTTP API, propose the corresponding changes to the ``api/`` directory for review along with your spec and add the APIImpact flag to the commit message. Specifications with the APIImpact flag can be found with the following query: https://review.openstack.org/#/q/status:open+project:openstack/keystone-specs+message:apiimpact,n,z","If your spec has an impact on the HTTP API, propose the corresponding changes to the ``api/`` directory for review along with your spec.",6,2
openstack%2Frally~master~Icd2889434179ba08b8237b6c32d9ee6939dbf00a,openstack/rally,master,Icd2889434179ba08b8237b6c32d9ee6939dbf00a,Converting scenario context to dict,MERGED,2014-12-16 19:05:17.000000000,2014-12-18 14:33:07.000000000,2014-12-18 14:33:07.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 9545}, {'_account_id': 13609}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-16 19:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bba01df5d433fac78d435f471b62f1aa5509320d', 'message': 'Converting scenario context to dict\n\nThis changes scenario context that is function to\na simple dict.\n\nChange-Id: Icd2889434179ba08b8237b6c32d9ee6939dbf00a\n'}, {'number': 2, 'created': '2014-12-17 14:44:42.000000000', 'files': ['rally/benchmark/scenarios/nova/security_group.py', 'rally/benchmark/scenarios/vm/utils.py', 'tests/unit/benchmark/scenarios/sahara/test_jobs.py', 'rally/benchmark/scenarios/nova/utils.py', 'rally/benchmark/scenarios/base.py', 'rally/benchmark/scenarios/sahara/clusters.py', 'rally/benchmark/scenarios/tempest/utils.py', 'rally/benchmark/scenarios/neutron/utils.py', 'tests/unit/benchmark/scenarios/cinder/test_utils.py', 'rally/benchmark/scenarios/sahara/jobs.py', 'rally/benchmark/scenarios/sahara/utils.py', 'tests/unit/benchmark/scenarios/vm/test_utils.py', 'tests/unit/benchmark/scenarios/test_base.py', 'tests/unit/benchmark/scenarios/neutron/test_utils.py', 'rally/benchmark/scenarios/cinder/utils.py', 'rally/benchmark/scenarios/tempest/tempest.py', 'rally/benchmark/scenarios/cinder/volumes.py', 'rally/benchmark/scenarios/quotas/quotas.py', 'tests/unit/benchmark/scenarios/sahara/test_clusters.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/c29e1b64ac0d3bddf01c8e938af750afe814ab39', 'message': 'Converting scenario context to dict\n\nThis changes scenario context that is function to\na simple dict.\n\nChange-Id: Icd2889434179ba08b8237b6c32d9ee6939dbf00a\n'}]",0,142189,c29e1b64ac0d3bddf01c8e938af750afe814ab39,34,6,2,13609,,,0,"Converting scenario context to dict

This changes scenario context that is function to
a simple dict.

Change-Id: Icd2889434179ba08b8237b6c32d9ee6939dbf00a
",git fetch https://review.opendev.org/openstack/rally refs/changes/89/142189/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/vm/utils.py', 'tests/unit/benchmark/scenarios/sahara/test_jobs.py', 'rally/benchmark/scenarios/nova/utils.py', 'rally/benchmark/scenarios/base.py', 'rally/benchmark/scenarios/sahara/clusters.py', 'rally/benchmark/scenarios/tempest/utils.py', 'rally/benchmark/scenarios/neutron/utils.py', 'tests/unit/benchmark/scenarios/cinder/test_utils.py', 'rally/benchmark/scenarios/sahara/jobs.py', 'rally/benchmark/scenarios/sahara/utils.py', 'tests/unit/benchmark/scenarios/vm/test_utils.py', 'tests/unit/benchmark/scenarios/test_base.py', 'tests/unit/benchmark/scenarios/neutron/test_utils.py', 'rally/benchmark/scenarios/cinder/utils.py', 'rally/benchmark/scenarios/tempest/tempest.py', 'rally/benchmark/scenarios/cinder/volumes.py', 'rally/benchmark/scenarios/quotas/quotas.py', 'tests/unit/benchmark/scenarios/sahara/test_clusters.py']",18,bba01df5d433fac78d435f471b62f1aa5509320d,," clusters_scenario.context = { ""tenant"": { ""sahara_image"": ""test_image"" } } clusters_scenario.context = { ""tenant"": { ""sahara_image"": ""test_image"" } }"," clusters_scenario.context = mock.MagicMock(return_value={ ""tenant"": { ""sahara_image"": ""test_image""}} ) clusters_scenario.context = mock.MagicMock(return_value={ ""tenant"": { ""sahara_image"": ""test_image""}} )",60,58
openstack%2Frally~master~Id195d7df6cb369d448f8a0019891a693a0d3d0aa,openstack/rally,master,Id195d7df6cb369d448f8a0019891a693a0d3d0aa,Updates in Context order,MERGED,2014-12-17 17:07:32.000000000,2014-12-18 14:33:00.000000000,2014-12-18 14:32:59.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-17 17:07:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1d6b1c5f470ae10a509ff23cc189974125f7a92b', 'message': 'Updates in Context order.\n\nSmall change that fixes cleanup order, and a bit of refactoring.\n\nChanges:\n  * order values in rally.benchmark.context.cleanup.context\n    set to maximum value, so this cleanup runs first after scenario\n    is finished. That avoids blocking of context resources deletion\n    by resources that created by scenarios.\n  * change some resources order so they are not immediately follows\n    after each other: 301, 302, 303 -> 310, 320, 330.\n\nChange-Id: Id195d7df6cb369d448f8a0019891a693a0d3d0aa\n'}, {'number': 2, 'created': '2014-12-17 17:10:43.000000000', 'files': ['rally/benchmark/context/roles.py', 'rally/benchmark/context/secgroup.py', 'rally/benchmark/context/keypair.py', 'rally/benchmark/context/cleanup/context.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/8908da799b3e87317e9b0c04c0f95262210c8ebd', 'message': 'Updates in Context order\n\nSmall change that fixes cleanup order, and a bit of refactoring.\n\nChanges:\n  * order values in rally.benchmark.context.cleanup.context\n    set to maximum value, so this cleanup runs first after scenario\n    is finished. That avoids blocking of context resources deletion\n    by resources that created by scenarios.\n  * change some resources order so they are not immediately follows\n    after each other: 301, 302, 303 -> 310, 320, 330.\n\nChange-Id: Id195d7df6cb369d448f8a0019891a693a0d3d0aa\n'}]",0,142510,8908da799b3e87317e9b0c04c0f95262210c8ebd,14,4,2,10475,,,0,"Updates in Context order

Small change that fixes cleanup order, and a bit of refactoring.

Changes:
  * order values in rally.benchmark.context.cleanup.context
    set to maximum value, so this cleanup runs first after scenario
    is finished. That avoids blocking of context resources deletion
    by resources that created by scenarios.
  * change some resources order so they are not immediately follows
    after each other: 301, 302, 303 -> 310, 320, 330.

Change-Id: Id195d7df6cb369d448f8a0019891a693a0d3d0aa
",git fetch https://review.opendev.org/openstack/rally refs/changes/10/142510/2 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/context/roles.py', 'rally/benchmark/context/secgroup.py', 'rally/benchmark/context/keypair.py', 'rally/benchmark/context/cleanup/context.py']",4,1d6b1c5f470ae10a509ff23cc189974125f7a92b,changes-in-context-order,"import sys # NOTE(amaretskiy): Set order to run this before UserCleanup @base.context(name=""admin_cleanup"", order=(sys.maxint - 1), hidden=True)# NOTE(amaretskiy): Set maximum order to run this last @base.context(name=""cleanup"", order=sys.maxint, hidden=True)","@base.context(name=""admin_cleanup"", order=200, hidden=True)@base.context(name=""cleanup"", order=201, hidden=True)",9,5
openstack%2Fironic~master~Ia002c4df71d5e39fbd6ef9a594c4fa67c5ae2f94,openstack/ironic,master,Ia002c4df71d5e39fbd6ef9a594c4fa67c5ae2f94,Improve Agent deploy driver validation,MERGED,2014-12-15 10:42:15.000000000,2014-12-18 14:21:47.000000000,2014-12-18 09:47:01.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 9315}, {'_account_id': 10343}, {'_account_id': 12081}, {'_account_id': 13362}]","[{'number': 1, 'created': '2014-12-15 10:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b0a58f82fb81b7cb13b88d89a6d09ddef5aad782', 'message': ""Improve Agent deploy driver validation\n\n1) Check that 'image_source' is specified.\n2) More informative message about missing PXE boot params.\n\nChange-Id: Ia002c4df71d5e39fbd6ef9a594c4fa67c5ae2f94\n""}, {'number': 2, 'created': '2014-12-15 10:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a7a1a82110d71c6c19e422a1912c738a1bb78b92', 'message': ""Improve Agent deploy driver validation\n\n1) Check that 'image_source' is specified.\n2) More informative message about missing PXE boot params.\n\nChange-Id: Ia002c4df71d5e39fbd6ef9a594c4fa67c5ae2f94\n""}, {'number': 3, 'created': '2014-12-15 14:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/75bb4486c3ddc1bf26b94573bdfadadb0ffd62c8', 'message': ""Improve Agent deploy driver validation\n\n1) Check that 'image_source' is specified.\n2) More informative message about missing PXE boot params.\n\nChange-Id: Ia002c4df71d5e39fbd6ef9a594c4fa67c5ae2f94\n""}, {'number': 4, 'created': '2014-12-16 09:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c6da58c215373e4f549008453df6803d4f45f6ee', 'message': ""Improve Agent deploy driver validation\n\n1) Check that 'image_source' is specified.\n2) More informative message about missing PXE boot params.\n\nChange-Id: Ia002c4df71d5e39fbd6ef9a594c4fa67c5ae2f94\n""}, {'number': 5, 'created': '2014-12-17 12:51:45.000000000', 'files': ['ironic/drivers/modules/agent.py', 'ironic/tests/drivers/test_agent.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9b4aab1693dc82da3d0072360aee1fcedc0a78e0', 'message': ""Improve Agent deploy driver validation\n\n1) Check that 'image_source' is specified.\n2) More informative message about missing params.\n\nChange-Id: Ia002c4df71d5e39fbd6ef9a594c4fa67c5ae2f94\n""}]",22,141766,9b4aab1693dc82da3d0072360aee1fcedc0a78e0,45,11,5,7711,,,0,"Improve Agent deploy driver validation

1) Check that 'image_source' is specified.
2) More informative message about missing params.

Change-Id: Ia002c4df71d5e39fbd6ef9a594c4fa67c5ae2f94
",git fetch https://review.opendev.org/openstack/ironic refs/changes/66/141766/5 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/agent.py', 'ironic/tests/drivers/test_agent.py']",2,b0a58f82fb81b7cb13b88d89a6d09ddef5aad782,validate-agent," e = self.assertRaises(exception.MissingParameterValue, self.driver.validate, task) self.assertIn('deploy_ramdisk', str(e)) self.assertIn('deploy_kernel', str(e)) def test_validate_instance_info(self): self.node.instance_info = {} self.node.save() with task_manager.acquire( self.context, self.node['uuid'], shared=False) as task: self.assertRaises(exception.MissingParameterValue, self.driver.validate, task)"," self.assertRaises(exception.InvalidParameterValue, self.driver.validate, task)",24,9
openstack%2Fzaqar~stable%2Fjuno~I67092a80ecd71f1210761dc8658f33f64a4078b8,openstack/zaqar,stable/juno,I67092a80ecd71f1210761dc8658f33f64a4078b8,Updated from global requirements,MERGED,2014-12-14 00:17:57.000000000,2014-12-18 14:18:13.000000000,2014-12-18 14:18:11.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 2472}, {'_account_id': 6413}, {'_account_id': 6484}, {'_account_id': 6547}, {'_account_id': 7488}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-12-14 00:17:57.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/94906d8592ed5f731ae2feca45f6c0ce9d1ca150', 'message': 'Updated from global requirements\n\nChange-Id: I67092a80ecd71f1210761dc8658f33f64a4078b8\n'}]",0,141605,94906d8592ed5f731ae2feca45f6c0ce9d1ca150,16,8,1,11131,,,0,"Updated from global requirements

Change-Id: I67092a80ecd71f1210761dc8658f33f64a4078b8
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/05/141605/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,94906d8592ed5f731ae2feca45f6c0ce9d1ca150,openstack/requirements,"SQLAlchemy>=0.8.4,<=0.9.99,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,!=0.9.4,!=0.9.5,!=0.9.6","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",2,2
openstack%2Ftrove~master~I4611c136e611214f901eb35fbbb613ab1107a4df,openstack/trove,master,I4611c136e611214f901eb35fbbb613ab1107a4df,Adds negative test to test_instance_controller.py,MERGED,2014-12-10 11:48:59.000000000,2014-12-18 14:17:57.000000000,2014-12-18 14:17:55.000000000,"[{'_account_id': 3}, {'_account_id': 1795}, {'_account_id': 2222}, {'_account_id': 5293}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 14009}]","[{'number': 1, 'created': '2014-12-10 11:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/49842ec78e50b93e216ca125e6d012bf948c8480', 'message': 'Adds negative test to test_instance_controller.py\n\nThis submission adds a new negative unittest\n""test_validate_create_invalid_name"" under\n""trove/tests/unittests/instance"" script, to validate\ninstance creation with invalid name.\n\nChange-Id: I4611c136e611214f901eb35fbbb613ab1107a4df\n'}, {'number': 2, 'created': '2014-12-11 06:45:12.000000000', 'files': ['trove/tests/unittests/instance/test_instance_controller.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/4cb12fa70ed3f51b4e5bc64ab830a5581dc96e68', 'message': 'Adds negative test to test_instance_controller.py\n\nThis submission adds a new negative unittest\n""test_validate_create_invalid_name"" under\n""trove/tests/unittests/instance"" script, to validate\ninstance creation with invalid name.\n\nChange-Id: I4611c136e611214f901eb35fbbb613ab1107a4df\n'}]",4,140650,4cb12fa70ed3f51b4e5bc64ab830a5581dc96e68,26,7,2,1845,,,0,"Adds negative test to test_instance_controller.py

This submission adds a new negative unittest
""test_validate_create_invalid_name"" under
""trove/tests/unittests/instance"" script, to validate
instance creation with invalid name.

Change-Id: I4611c136e611214f901eb35fbbb613ab1107a4df
",git fetch https://review.opendev.org/openstack/trove refs/changes/50/140650/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/tests/unittests/instance/test_instance_controller.py'],1,49842ec78e50b93e216ca125e6d012bf948c8480,separate/trove-instance-unittests," def test_validate_create_invalid_name(self): body = self.instance body['instance']['name'] = ""$#$%^^"" schema = self.controller.get_schema('create', body) validator = jsonschema.Draft4Validator(schema) self.assertFalse(validator.is_valid(body)) errors = sorted(validator.iter_errors(body), key=lambda e: e.path) self.assertThat(len(errors), Is(1)) self.assertThat(errors[0].message, Equals(""'$#$%^^' does not match '^.*[0-9a-zA-Z]+.*$'"")) ",,11,0
openstack%2Frally~master~I2188b984183578c5c3f1f42b5e1ba5593692683f,openstack/rally,master,I2188b984183578c5c3f1f42b5e1ba5593692683f,Remove SLA checks for NovaServers.boot_server_from_volume_and_delete,MERGED,2014-12-18 13:02:32.000000000,2014-12-18 14:17:13.000000000,2014-12-18 14:17:12.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-18 13:02:32.000000000', 'files': ['rally-jobs/rally-neutron.yaml', 'rally-jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/ee6a9ebd5910e01c3f632d26ea49ddca033642db', 'message': 'Remove SLA checks for NovaServers.boot_server_from_volume_and_delete\n\nThis benchmark is super unstable and almost fully block rally gate.\nThe reason is in Nova and Neutron races. So we have to remove until\nwe fix those projects.\n\nChange-Id: I2188b984183578c5c3f1f42b5e1ba5593692683f\n'}]",0,142763,ee6a9ebd5910e01c3f632d26ea49ddca033642db,7,3,1,6172,,,0,"Remove SLA checks for NovaServers.boot_server_from_volume_and_delete

This benchmark is super unstable and almost fully block rally gate.
The reason is in Nova and Neutron races. So we have to remove until
we fix those projects.

Change-Id: I2188b984183578c5c3f1f42b5e1ba5593692683f
",git fetch https://review.opendev.org/openstack/rally refs/changes/63/142763/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally-jobs/rally-neutron.yaml', 'rally-jobs/rally.yaml']",2,ee6a9ebd5910e01c3f632d26ea49ddca033642db,remove_sec_group_check,, sla: failure_rate: max: 25,0,6
openstack%2Fos-apply-config~master~Ibc8b21cd6922b8664ca71e9e6009c8573ea9d107,openstack/os-apply-config,master,Ibc8b21cd6922b8664ca71e9e6009c8573ea9d107,Output useful JSON data,MERGED,2014-12-16 14:46:02.000000000,2014-12-18 14:10:48.000000000,2014-12-18 12:55:01.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 9369}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-12-16 14:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/324adc1801d9bd5267d3e8e7871244f674c244a2', 'message': ""Output useful JSON data\n\nIf you use os-apply-config to slice out a JSON blob on the command\nline you'll get back a string formatted dump of a python\ndictionary (or list). Ideally we would print out proper JSON text\nso that other tooling (jq, etc) can post process things in a\nuseful manner.\n\nThis patch updates apply_config so that if an output key is\ndetected to be an array or a list it is printed to stdout\nin a JSON format.\n\nChange-Id: Ibc8b21cd6922b8664ca71e9e6009c8573ea9d107\n""}, {'number': 2, 'created': '2014-12-16 16:54:03.000000000', 'files': ['os_apply_config/tests/test_apply_config.py', 'os_apply_config/apply_config.py'], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/fcb3d0f96f83fe18fe04e984fd4440b3b78c64b7', 'message': ""Output useful JSON data\n\nIf you use os-apply-config to slice out a JSON blob on the command\nline you'll get back a string formatted dump of a python\ndictionary (or list). Ideally we would print out proper JSON text\nso that other tooling (jq, etc) can post process things in a\nuseful manner.\n\nThis patch updates apply_config so that if an output key is\ndetected to be a dict or a list it is printed to stdout\nin a JSON format.\n\nChange-Id: Ibc8b21cd6922b8664ca71e9e6009c8573ea9d107""}]",3,142120,fcb3d0f96f83fe18fe04e984fd4440b3b78c64b7,31,7,2,360,,,0,"Output useful JSON data

If you use os-apply-config to slice out a JSON blob on the command
line you'll get back a string formatted dump of a python
dictionary (or list). Ideally we would print out proper JSON text
so that other tooling (jq, etc) can post process things in a
useful manner.

This patch updates apply_config so that if an output key is
detected to be a dict or a list it is printed to stdout
in a JSON format.

Change-Id: Ibc8b21cd6922b8664ca71e9e6009c8573ea9d107",git fetch https://review.opendev.org/openstack/os-apply-config refs/changes/20/142120/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_apply_config/tests/test_apply_config.py', 'os_apply_config/apply_config.py']",2,324adc1801d9bd5267d3e8e7871244f674c244a2,json_output," if isinstance(config, (dict, list)): print(json.dumps(config)) else: print(str(config))", print(str(config)),22,1
openstack%2Fgovernance~master~I11ab187b9cb32d26da5378236e451d1f46721543,openstack/governance,master,I11ab187b9cb32d26da5378236e451d1f46721543,Project structure reform specification,MERGED,2014-12-02 19:50:24.000000000,2014-12-18 14:10:27.000000000,2014-12-18 13:14:16.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1112}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 2889}, {'_account_id': 4257}, {'_account_id': 6172}, {'_account_id': 6316}, {'_account_id': 7973}, {'_account_id': 8443}]","[{'number': 1, 'created': '2014-12-02 19:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/69d704834ffa3dcdd762ae7f727bc379795699f4', 'message': 'Project structure reform specification\n\nAdd a resolution to describe the rationale and proposed implementation\nfor the OpenStack project structure reform.\n\nChange-Id: I11ab187b9cb32d26da5378236e451d1f46721543\n'}, {'number': 2, 'created': '2014-12-02 20:17:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/ab3d16d6121ed7be3d0a82b346cbe1f40ef94bdb', 'message': 'Project structure reform specification\n\nAdd a resolution to describe the rationale and proposed implementation\nfor the OpenStack project structure reform.\n\nChange-Id: I11ab187b9cb32d26da5378236e451d1f46721543\n'}, {'number': 3, 'created': '2014-12-10 14:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/00e6870ddecbbd312797090742ca71580133c1ef', 'message': 'Project structure reform specification\n\nAdd a resolution to describe the rationale and proposed implementation\nfor the OpenStack project structure reform.\n\nChange-Id: I11ab187b9cb32d26da5378236e451d1f46721543\n'}, {'number': 4, 'created': '2014-12-12 08:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/e9c7f252e861c16cd43ab8d5011dd7b47050a86e', 'message': 'Project structure reform specification\n\nAdd a resolution to describe the rationale and proposed implementation\nfor the OpenStack project structure reform.\n\nChange-Id: I11ab187b9cb32d26da5378236e451d1f46721543\n'}, {'number': 5, 'created': '2014-12-16 20:19:18.000000000', 'files': ['resolutions/20141202-project-structure-reform-spec.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/185f85f7c82891f90bd270ea10225e2b7b183c23', 'message': 'Project structure reform specification\n\nAdd a resolution to describe the rationale and proposed implementation\nfor the OpenStack project structure reform.\n\nChange-Id: I11ab187b9cb32d26da5378236e451d1f46721543\n'}]",73,138504,185f85f7c82891f90bd270ea10225e2b7b183c23,65,20,5,308,,,0,"Project structure reform specification

Add a resolution to describe the rationale and proposed implementation
for the OpenStack project structure reform.

Change-Id: I11ab187b9cb32d26da5378236e451d1f46721543
",git fetch https://review.opendev.org/openstack/governance refs/changes/04/138504/1 && git format-patch -1 --stdout FETCH_HEAD,['resolutions/20141202-project-structure-reform-spec.rst'],1,69d704834ffa3dcdd762ae7f727bc379795699f4,project-structure-reform-spec,"================================== OpenStack project structure reform specification ================================== Problem description =================== Our project structure is currently organized as a ladder. Developers form teams, work on a project, then apply for incubation and ultimately graduate to be part of the OpenStack integrated release. Only integrated projects (and the few horizontal efforts necessary to build them) are recognized officially as ""OpenStack"" efforts. This creates a number of issues, which were particularly visible at the Technical Committee level over the Juno development cycle. First, the integrated release as it stands today is not a useful product for our users. The current collection of services in the integrated release spans from cloud native APIs (swift, zaqar in incubation), base-level IaaS blocks (nova, glance, cinder), high-level aaS (savana, trove), and lots of things that span domains. Some projects (swift, ironic...) can be used quite well outside of the rest of the OpenStack stack, while others (glance, nova) really don't function in a different context. Skilled operators aren't deploying ""the integrated release"": they are picking and choosing between components they feel are useful. New users, however, are presented with a complex and scary ""integrated release"" as the thing they have to deploy and manage: this inhibits adoption, and this inhibits the adoption of a slice of OpenStack that could serve their need. Second, the integrated release being the only and ultimate goal for projects, there is no lack of candidates, and the list is always-growing. Why reject Sahara if you accepted Trove? However, processes and services are applied equally to all members of the integrated release: we gate everything in the integrated release against everything else, we do a common, time-based release every 6 months, we produce documentation for all the integrated release components, etc. The resources working on those integrated horizontal tasks are very finite, and complexity grows non-linearly as we add more projects. So there is outside pressure to add more projects, and internal pressure to resist further additions. Third, the binary nature of the integrated release results in projects outside the integrated release failing to get the recognition they deserve. ""Non-official"" projects are second- or third-class citizens which can't get development resources. Alternative solutions can't emerge in the shadow of the blessed approach. Becoming part of the integrated release, which was originally designed to be a technical decision, quickly became a life-or-death question for new projects, and a political/community minefield. In summary, the ""integrated release"" is paradoxically too large to be effectively integrated, installed or upgraded in one piece, and too small to express the diversity of our rich ecosystem. Its slow-moving, binary nature is too granular to represent the complexity of what our community produces, and therefore we need to reform it. The challenge is to fix those three issues at the same time. Embrace the diversity of our ecosystem while making sure that what we produce is easily understandable and consumable by our downstream users (distributions, deployers, end users), all that without putting more stress on the already overworked horizontal teams providing services to all OpenStack projects, and without limiting the current teams access to common finite resources. Proposed change =============== Provide a precise taxonomy to help navigating the ecosystem ----------------------------------------------------------- We can't add any more ""OpenStack"" projects without dramatically revisiting the information we provide. It is the duty of the Technical Committee to help downstream consumers of OpenStack understand what each project means to them, and provide them with accurate statuses for those projects. Currently the landscape is very simple: you're in the integrated release, or you're not. But since there was only one category (or badge of honor), it ended up meaning different things to different people. From a release management perspective, it meant what we released on the same day. From a CI perspective, it meant what was co-gated. From an OpenStack distribution perspective, it meant what you should be packaging. From some operator perspective, it meant the base set of projects you should be deploying. From some other operator perspective, it meant the set of mature, stable projects. Those are all different things, and yet we used a single category to describe it. The first part of the change is to create a framework of tags to describe more accurately and more objectively what each project produced in the OpenStack community means. The Technical Committee will define tags and the objective rules to apply them. This framework will allow us to progressively replace the ""integrated release"" single badge with a richer and more nuanced description of all ""OpenStack"" projects. It will allow the Technical Committee to provide more precise answers to the Foundation Board of Directors questions about which set of projects may make sense for a given trademark license program. It will allow our downstream users to know which projects are mature, which are security-supported, which are used in more than one public cloud, or which are really massively scalable. Recognize all our community is a part of OpenStack -------------------------------------------------- The second part of the change is recognizing that there is more to ""OpenStack"" than a finite set of projects blessed by the Technical Committee. We already have plenty of projects that are developed on OpenStack infrastructure, follow the OpenStack way of doing things, have development discussions on the openstack-dev mailing-list and use #openstack-meeting channels for their team meetings. Those are part of the OpenStack community as well, and we propose that those should be hosted under the ""openstack"" GitHub organization, as long as: * They align with the OpenStack Mission: the project should help further the OpenStack mission, by providing a cloud infrastructure service, or directly building on an existing one * They follow the OpenStack way: open source (licensing), open community (leadership chosen by the contributors to the project), open development (public reviews on Gerrit, core reviewers, gate), and open design (direction discussed at Design Summit and on public MLs) * They ensure basic interoperability (API services should support at least Keystone) * They submit to the OpenStack Technical Committee oversight These criteria are objective, and therefore the Technical Committee may delegate processing applications to another team. However, it retains full authority over the approved projects, and may decide to encourage collaboration between similar projects, or to remove dead projects. This proposed structure will replace the current program-driven structure. Contributors to those projects will all be considered ATCs and participate in electing the Technical Committee. Transition ---------- As for all significant governance changes, we need to ensure a seamless transition and reduce the effect of the reform on the current development cycle. To ensure this seamless transition, the OpenStack taxonomy will initially define one tag, ""integrated-release"", which will contain the integrated projects for the Kilo cycle. To minimize disruption, this tag will be used throughout the Kilo development cycle and for the Kilo end release. This tag may be split, replaced or redefined in the future, but that will be discussed as separate changes. Implementation ============== Assignee(s) ----------- The work on this transition is assigned to the Technical Committee members, under the coordination of the Chair of the Technical Committee. Work Items ---------- * Create project taxonomy base structure * Replace incubation-integration-requirements.rst by rules definition for the ""integrated-release"" transitional tag * Create taxonomy navigation website, to make the taxonomy easily discoverable, searchable and browseable * Define new objective OpenStack project requirements (to replace old new-programs-requirements.rst) * Update Technical Committee charter to get rid of the ""Programs"" concept (and redefine ATC as contributors to any OpenStack project) Impact ====== Impact for horizontal teams --------------------------- Horizontal teams (documentation, infrastructure, QA, release management, stable maintenance, vulnerability management, translators...) have set a number of expectations toward the projects in the ""integrated release"". This is what created tension as the Technical Committee added more projects which those horizontal teams had to support. Those expectations have to be revisited as we replace the ""integrated release"" with a richer landscape. With this proposed change, the work of horizontal teams shall gradually move away from centrally handling work for all projects, to a more decentralized model where they provide processes and tools to empower projects to do the work themselves. Each horizontal team will have to redefine how they organize their work under the new project structure, and which (if any) projects they still directly handle. They will be able to define tags (like ""security-supported"") to communicate that new organization. Note that most teams already started that transition as more projects were being added to the integrated release, so this will help them to more explicitly describe the service they provide. Impact for existing integrated projects and the Kilo cycle ---------------------------------------------------------- This change in itself doesn't adversely impact existing integrated projects: they will continue to exist and be defined under the transitional ""integrated-release"" tag. However, one end goal of the reform is to deconstruct the ""integrated release"" binary concept and replace it with more precise and objective groupings, so there should come a time in the future where the ""integrated-release"" concept won't mean anything anymore, and the transitional tag will be discontinued. This change puts in place the framework that will allow us to do that, but doesn't actually do anything yet. In particular, the ""integrated release"" as a concept will still very much exist at least until the end of the Kilo development cycle. Trademark checks ---------------- The OpenStack Foundation legal staff currently performs trademark checks as a project is incubated, before its inclusion in the integrated release. It will continue to apply the same preventive analysis to any project that will be used as part of OpenStack Foundation trademark license programs. However projects under the ""openstack/"" GitHub organization(s) are considered projects from the OpenStack Community, and won't all be preventively checked for potential trademark conflicts. To communicate that, a note will be posted on the GitHub organization pages stating that the OpenStack Foundation is not responsible for the project names or content below, which are posted by independent developers. The Technical Committee however expects that if a reasonable challenge is presented to a given project under the ""openstack/"" GitHub organization, a rename of the project has to be considered. References ========== * Original mailing-list discussion: http://lists.openstack.org/pipermail/openstack-dev/2014-August/041929.html * Blogposts: * ""OpenStack as Layers"" https://dague.net/2014/08/26/openstack-as-layers/ (Sean Dague) * ""OpenStack as Layers but also a Big Tents but also a bunch of Cats"" http://inaugust.com/post/108 (Monty Taylor) * ""The problem space in the big tent"" http://ttx.re/problem-space-in-the-big-tent.html (Thierry Carrez) * ""So, What is the Core of OpenStack?"" http://www.joinfu.com/2014/09/so-what-is-the-core-of-openstack/ (Jay Pipes) * ""On Layers"" http://www.stillhq.com/openstack/kilo/000002.html (Mikal Still) * Strawman governance change proposals: * Doug's strawman v1: https://review.openstack.org/#/q/status:open+topic:big-tent,n,z * Doug's strawman v2: https://review.openstack.org/#/c/131422/ * Jay's strawman: https://review.openstack.org/#/c/126582/ * Public notes from discussions between TC members: https://etherpad.openstack.org/p/project-restructure-hangouts ",,265,0
openstack%2Fheat-templates~master~I8c30e50bd788297930fad0a8a764db6019575f1b,openstack/heat-templates,master,I8c30e50bd788297930fad0a8a764db6019575f1b,Puppet hook: add hiera_prefix option,ABANDONED,2014-12-17 03:07:47.000000000,2014-12-18 14:09:55.000000000,,"[{'_account_id': 3}, {'_account_id': 360}]","[{'number': 1, 'created': '2014-12-17 03:07:47.000000000', 'files': ['hot/software-config/elements/heat-config-puppet/install.d/hook-puppet.py', 'tests/software_config/test_hook_puppet.py'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/270a32459f41ef221def99b3221bf5fadcdfe860', 'message': ""Puppet hook: add hiera_prefix option\n\nAdd a 'hiera_prefix' option to the puppet config hook. When\nset this option will prefix all hiera variables. Useful\nif you want to automatically set variables for a shim\nwrapper class in Puppet which automatically align with\nthe Heat puppet software config inputs.\n\nChange-Id: I8c30e50bd788297930fad0a8a764db6019575f1b\n""}]",0,142315,270a32459f41ef221def99b3221bf5fadcdfe860,4,2,1,360,,,0,"Puppet hook: add hiera_prefix option

Add a 'hiera_prefix' option to the puppet config hook. When
set this option will prefix all hiera variables. Useful
if you want to automatically set variables for a shim
wrapper class in Puppet which automatically align with
the Heat puppet software config inputs.

Change-Id: I8c30e50bd788297930fad0a8a764db6019575f1b
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/15/142315/1 && git format-patch -1 --stdout FETCH_HEAD,"['hot/software-config/elements/heat-config-puppet/install.d/hook-puppet.py', 'tests/software_config/test_hook_puppet.py']",2,270a32459f41ef221def99b3221bf5fadcdfe860,hiera_prefix," def test_hook_hiera(self, prefix=''): self.data['options']['hiera_prefix'] = prefix '%sfoo' % prefix: 'bar', '%sanother' % prefix: 'input', def test_hook_hiera_with_prefix(self): self.test_hook_hiera('project::prefix::')"," def test_hook_hiera(self): 'foo': 'bar', 'another': 'input',",11,4
openstack%2Fpython-keystoneclient~master~Ifbd68c9de329c2e0c70824ba873caa579e8e86d0,openstack/python-keystoneclient,master,Ifbd68c9de329c2e0c70824ba873caa579e8e86d0,Take plugin params from ENV rather than default,MERGED,2014-10-31 13:00:56.000000000,2014-12-18 14:05:01.000000000,2014-12-18 14:05:00.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 8978}, {'_account_id': 9101}, {'_account_id': 11022}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-10-31 13:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/0555a20e936d9e348306d065ad13f46c66fa8414', 'message': 'Take plugin params from ENV rather than default\n\nThe way the argparse options were being structured, if there was a\ndefault value set on the option it would use this value as the default\nand not check the environment variables.\n\nThis is wrong, we expect the environment variables to be used and the\ndefault value to be the final fallback.\n\nChange-Id: Ifbd68c9de329c2e0c70824ba873caa579e8e86d0\nCloses-Bug: #1388076\n'}, {'number': 2, 'created': '2014-10-31 14:19:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/a1513cba9a2e51cec951f67e8f75ef118916bc27', 'message': 'Take plugin params from ENV rather than default\n\nThe way the argparse options were being structured, if there was a\ndefault value set on the option it would use this value as the default\nand not check the environment variables.\n\nThis is wrong, we expect the environment variables to be used and the\ndefault value to be the final fallback.\n\nChange-Id: Ifbd68c9de329c2e0c70824ba873caa579e8e86d0\nCloses-Bug: #1388076\n'}, {'number': 3, 'created': '2014-12-09 23:45:29.000000000', 'files': ['keystoneclient/auth/base.py', 'keystoneclient/tests/auth/test_cli.py', 'keystoneclient/tests/auth/utils.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/b78dc19d9b47f3347a99394ee839c02f5127a986', 'message': 'Take plugin params from ENV rather than default\n\nThe way the argparse options were being structured, if there was a\ndefault value set on the option it would use this value as the default\nand not check the environment variables.\n\nThis is wrong, we expect the environment variables to be used and the\ndefault value to be the final fallback.\n\nChange-Id: Ifbd68c9de329c2e0c70824ba873caa579e8e86d0\nCloses-Bug: #1388076\n'}]",2,132240,b78dc19d9b47f3347a99394ee839c02f5127a986,21,8,3,7191,,,0,"Take plugin params from ENV rather than default

The way the argparse options were being structured, if there was a
default value set on the option it would use this value as the default
and not check the environment variables.

This is wrong, we expect the environment variables to be used and the
default value to be the final fallback.

Change-Id: Ifbd68c9de329c2e0c70824ba873caa579e8e86d0
Closes-Bug: #1388076
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/40/132240/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/auth/base.py', 'keystoneclient/tests/auth/test_cli.py']",2,0555a20e936d9e348306d065ad13f46c66fa8414,cli-default,"import fixtures def env(self, name, value=None): if value: # environment variables are always strings value = str(value) return self.useFixture(fixtures.EnvironmentVariable(name, value)) @utils.mock_plugin def test_env_overrides_default_opt(self, m): name = uuid.uuid4().hex int_val = 10 self.env('OS_A_INT', int_val) klass = cli.register_argparse_arguments(self.p, [], default=name) opts = self.p.parse_args([]) a = klass.load_from_argparse_arguments(opts) self.assertEqual(int_val, a['a_int']) ",,24,6
openstack%2Fglance~stable%2Ficehouse~I6e6947513a10ba4106699cf28dcf9cada8268661,openstack/glance,stable/icehouse,I6e6947513a10ba4106699cf28dcf9cada8268661,To prevent client use v2 patch api to handle file and swift location,ABANDONED,2014-12-18 08:53:10.000000000,2014-12-18 14:02:40.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 9311}]","[{'number': 1, 'created': '2014-12-18 08:53:10.000000000', 'files': ['glance/tests/functional/v1/test_copy_to_file.py', 'glance/store/__init__.py', 'glance/tests/functional/v2/test_images.py', 'glance/tests/unit/test_store_location.py', 'glance/tests/unit/utils.py', 'glance/tests/unit/v1/test_api.py', 'glance/api/v1/images.py', 'glance/tests/unit/test_store_image.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/83eb63747223df9ac0bf4da6ebde6e72e5e6cdab', 'message': 'To prevent client use v2 patch api to handle file and swift location\n\nThe change will be used to restrict client to download and delete any\nfile in glance-api server. The same resone and logic as what we did in\nv1:\nhttps://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429\n\nCloses-Bug: bug/1400966\nDocImpact\n\nNote: Even this change could fully resolve the problem for Glance, but\nwe still need to fix this issue from glance_store perspective\nseparatelly due to other projects can use the lib directly.\n\nConflicts:\n\tglance/api/v1/images.py\n\tglance/common/store_utils.py\n\tglance/location.py\n\tglance/tests/functional/v1/test_copy_to_file.py\n\tglance/tests/functional/v2/test_images.py\n\tglance/tests/unit/test_store_image.py\n\tglance/tests/unit/test_store_location.py\n\tglance/tests/unit/utils.py\n\tglance/tests/unit/v1/test_api.py\n\n(cherry picked from commit 4afdb017aa1ccef01482f117cb8d0736a6da38ed)\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\nChange-Id: I6e6947513a10ba4106699cf28dcf9cada8268661'}]",2,142703,83eb63747223df9ac0bf4da6ebde6e72e5e6cdab,7,4,1,6549,,,0,"To prevent client use v2 patch api to handle file and swift location

The change will be used to restrict client to download and delete any
file in glance-api server. The same resone and logic as what we did in
v1:
https://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429

Closes-Bug: bug/1400966
DocImpact

Note: Even this change could fully resolve the problem for Glance, but
we still need to fix this issue from glance_store perspective
separatelly due to other projects can use the lib directly.

Conflicts:
	glance/api/v1/images.py
	glance/common/store_utils.py
	glance/location.py
	glance/tests/functional/v1/test_copy_to_file.py
	glance/tests/functional/v2/test_images.py
	glance/tests/unit/test_store_image.py
	glance/tests/unit/test_store_location.py
	glance/tests/unit/utils.py
	glance/tests/unit/v1/test_api.py

(cherry picked from commit 4afdb017aa1ccef01482f117cb8d0736a6da38ed)
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
Change-Id: I6e6947513a10ba4106699cf28dcf9cada8268661",git fetch https://review.opendev.org/openstack/glance refs/changes/03/142703/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/functional/v1/test_copy_to_file.py', 'glance/store/__init__.py', 'glance/tests/functional/v2/test_images.py', 'glance/tests/unit/test_store_location.py', 'glance/tests/unit/utils.py', 'glance/tests/unit/v1/test_api.py', 'glance/api/v1/images.py', 'glance/tests/unit/test_store_image.py']",8,83eb63747223df9ac0bf4da6ebde6e72e5e6cdab,,from glance.tests.unit import base as unit_test_baseclass TestImageFactory(unit_test_base.StoreClearingUnitTest):,class TestImageFactory(utils.BaseTestCase):,252,123
openstack%2Ffuel-main~master~Ie4231780144f79e138e4fa37408194bf6f5284a6,openstack/fuel-main,master,Ie4231780144f79e138e4fa37408194bf6f5284a6,Fix free/top error aborting on Mac and Cygwin,ABANDONED,2014-10-24 14:33:54.000000000,2014-12-18 14:02:17.000000000,,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 10667}]","[{'number': 1, 'created': '2014-10-24 14:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4c5d85ad0e77eee3f8a5a0b13a520abd0033ffa7', 'message': 'Fix free/top error aborting on Mac and Cygwin\n\nChange-Id: Ie4231780144f79e138e4fa37408194bf6f5284a6\n'}, {'number': 2, 'created': '2014-10-27 09:06:01.000000000', 'files': ['virtualbox/actions/prepare-environment.sh', 'virtualbox/launch.sh', 'virtualbox/functions/memory.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6f7522278fb12822bb9796189b03062244248e46', 'message': 'Fix free/top error aborting on Mac and Cygwin\n\nChange-Id: Ie4231780144f79e138e4fa37408194bf6f5284a6\n'}]",2,130814,6f7522278fb12822bb9796189b03062244248e46,14,7,2,12866,,,0,"Fix free/top error aborting on Mac and Cygwin

Change-Id: Ie4231780144f79e138e4fa37408194bf6f5284a6
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/14/130814/2 && git format-patch -1 --stdout FETCH_HEAD,"['virtualbox/actions/prepare-environment.sh', 'virtualbox/launch.sh', 'virtualbox/functions/memory.sh']",3,4c5d85ad0e77eee3f8a5a0b13a520abd0033ffa7,fix-free-top-error," case ""$(uname)"" in Linux) if [ ""$(which free)"" != """" ]; then # using free total_memory=$(LANG=C free | grep Mem | awk '{print $2}') elif [ ""$(which top)"" != """" ]; then # using top total_memory=$(LANG=C top -n 1 | grep ""Mem:"" | awk '{ print $4 }') else total_memory=""-1"" fi ;; Darwin) if [ ""$(which sysctl)"" != """" ]; then # using sysctl total_memory=$(sysctl -n hw.memsize) total_memory=$(( $total_memory / 1024 )) else total_memory=""-1"" fi ;; CYGWIN*) if [ ""$(which free)"" != """" ]; then # using free total_memory=$(LANG=C free | grep Mem | awk '{print $2}') elif [ ""$(which top)"" != """" ]; then # using top total_memory=$(LANG=C top -n 1 | grep ""Mem:"" | awk '{ print $4 }') else total_memory=""-1"" fi ;; esac"," if [ ""$os_type"" = ""linux"" ]; then if [ ""$(which free)"" != """" ]; then # using free total_memory=$(LANG=C free | grep Mem | awk '{print $2}') elif [ ""$(which top)"" != """" ]; then # using top total_memory=$(LANG=C top -n 1 | grep ""Mem:"" | awk '{ print $4 }') else total_memory=""-1"" fi elif [ ""$os_type"" = ""darwin"" ]; then if [ ""$(which sysctl)"" != """" ]; then # using sysctl total_memory=$(sysctl -n hw.memsize) total_memory=$(( $total_memory / 1024 )) else total_memory=""-1"" fi elif [ ""$os_type"" = ""cygwin"" ]; then if [ ""$(which free)"" != """" ]; then # using free total_memory=$(LANG=C free | grep Mem | awk '{print $2}') elif [ ""$(which top)"" != """" ]; then # using top total_memory=$(LANG=C top -n 1 | grep ""Mem:"" | awk '{ print $4 }') else total_memory=""-1"" fi fi",46,35
openstack%2Fpython-keystoneclient~master~I707e549a4fa349d0e9a0bdac61a2573aa2e5b434,openstack/python-keystoneclient,master,I707e549a4fa349d0e9a0bdac61a2573aa2e5b434,get_endpoint should return the override,MERGED,2014-10-28 12:27:00.000000000,2014-12-18 14:00:15.000000000,2014-12-18 14:00:15.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-10-28 12:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/b846d9d13667f086443d9f3b3d7bf886bd69f354', 'message': 'get_endpoint should return the override\n\nIf your adapter has an endpoint_override set then this value will be\nconsumed by session and used in preference to whatever you give to\nendpoint_filter.\n\nThis means that if you ask the adapter for the endpoint it is going to\nuse to query a URL you expect to get back the override because this is\nwhere it will be sent.\n\nChange-Id: I707e549a4fa349d0e9a0bdac61a2573aa2e5b434\n'}, {'number': 2, 'created': '2014-12-07 23:08:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/c94a1fe82c48e6b5e6413b6abe4feb90bf7dc564', 'message': 'get_endpoint should return the override\n\nIf your adapter has an endpoint_override set then this value will be\nconsumed by session and used in preference to whatever you give to\nendpoint_filter.\n\nThis means that if you ask the adapter for the endpoint it is going to\nuse to query a URL you expect to get back the override because this is\nwhere it will be sent.\n\nChange-Id: I707e549a4fa349d0e9a0bdac61a2573aa2e5b434\n'}, {'number': 3, 'created': '2014-12-07 23:08:31.000000000', 'files': ['keystoneclient/tests/test_session.py', 'keystoneclient/adapter.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/6b0fd667ce8ab213c7748e8e9e91b2f0c32b41f2', 'message': 'get_endpoint should return the override\n\nIf your adapter has an endpoint_override set then this value will be\nconsumed by session and used in preference to whatever you give to\nendpoint_filter.\n\nThis means that if you ask the adapter for the endpoint it is going to\nuse to query a URL you expect to get back the override because this is\nwhere it will be sent.\n\nCloses-Bug: #1400174\nChange-Id: I707e549a4fa349d0e9a0bdac61a2573aa2e5b434\n'}]",0,131408,6b0fd667ce8ab213c7748e8e9e91b2f0c32b41f2,15,4,3,7191,,,0,"get_endpoint should return the override

If your adapter has an endpoint_override set then this value will be
consumed by session and used in preference to whatever you give to
endpoint_filter.

This means that if you ask the adapter for the endpoint it is going to
use to query a URL you expect to get back the override because this is
where it will be sent.

Closes-Bug: #1400174
Change-Id: I707e549a4fa349d0e9a0bdac61a2573aa2e5b434
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/08/131408/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/tests/test_session.py', 'keystoneclient/adapter.py']",2,b846d9d13667f086443d9f3b3d7bf886bd69f354,override, if self.endpoint_override: return self.endpoint_override ,,5,0
openstack%2Fneutron~master~Ic5e9db2a19aa7652cbbd1ee04d7e02914e8d0093,openstack/neutron,master,Ic5e9db2a19aa7652cbbd1ee04d7e02914e8d0093,Cisco: unsupported format character in log format,MERGED,2014-12-17 04:46:38.000000000,2014-12-18 13:47:27.000000000,2014-12-18 13:47:26.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-17 04:46:38.000000000', 'files': ['neutron/plugins/cisco/cfg_agent/cfg_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a1a908e815f27f630bc7a7a5dfc06031cfc2bf3b', 'message': 'Cisco: unsupported format character in log format\n\nCiscoCfgAgent.hosting_devices_removed() contains an error in the\nformat string used to log errors:\n\n    LOG.error(_LE(""Invalid payload format for received RPC message ""\n\t\t""`hosting_devices_removed`. Error is %{error}s. ""\n\t\t""Payload is %(payload)s""),\n\t      {\'error\': e, \'payload\': payload})\n\n""%{error}s"" should be ""%(error)s""\n\nThe existing version raises ""ValueError: unsupported format character\n\'{\' (0x7b)"" when invoked.\n\n(found via pylint)\n\nChange-Id: Ic5e9db2a19aa7652cbbd1ee04d7e02914e8d0093\nCloses-Bug: #1403304\n'}]",0,142342,a1a908e815f27f630bc7a7a5dfc06031cfc2bf3b,24,17,1,11279,,,0,"Cisco: unsupported format character in log format

CiscoCfgAgent.hosting_devices_removed() contains an error in the
format string used to log errors:

    LOG.error(_LE(""Invalid payload format for received RPC message ""
		""`hosting_devices_removed`. Error is %{error}s. ""
		""Payload is %(payload)s""),
	      {'error': e, 'payload': payload})

""%{error}s"" should be ""%(error)s""

The existing version raises ""ValueError: unsupported format character
'{' (0x7b)"" when invoked.

(found via pylint)

Change-Id: Ic5e9db2a19aa7652cbbd1ee04d7e02914e8d0093
Closes-Bug: #1403304
",git fetch https://review.opendev.org/openstack/neutron refs/changes/42/142342/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/cisco/cfg_agent/cfg_agent.py'],1,a1a908e815f27f630bc7a7a5dfc06031cfc2bf3b,bug/1403304," ""`hosting_devices_removed`. Error is %(error)s. """," ""`hosting_devices_removed`. Error is %{error}s. """,1,1
openstack%2Fironic~master~I955e4e3bcf0c1f04f8f83a85447048f1ca3f2c38,openstack/ironic,master,I955e4e3bcf0c1f04f8f83a85447048f1ca3f2c38,Updated from global requirements,MERGED,2014-12-18 01:22:12.000000000,2014-12-18 13:47:19.000000000,2014-12-18 13:47:18.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-18 01:22:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/164cc8e80b207bf189fda1d320b0adcf0f7e3552', 'message': 'Updated from global requirements\n\nChange-Id: I955e4e3bcf0c1f04f8f83a85447048f1ca3f2c38\n'}, {'number': 2, 'created': '2014-12-18 10:14:59.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/772f94f07af2e411f847702cc32185fda44dc301', 'message': 'Updated from global requirements\n\nChange-Id: I955e4e3bcf0c1f04f8f83a85447048f1ca3f2c38\n'}]",0,142635,772f94f07af2e411f847702cc32185fda44dc301,15,4,2,11131,,,0,"Updated from global requirements

Change-Id: I955e4e3bcf0c1f04f8f83a85447048f1ca3f2c38
",git fetch https://review.opendev.org/openstack/ironic refs/changes/35/142635/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,164cc8e80b207bf189fda1d320b0adcf0f7e3552,openstack/requirements,alembic>=0.7.1,alembic>=0.6.4,1,1
openstack%2Frequirements~master~Ifbbcfe2ccf2caa70758f75e44d526d23d7f466cb,openstack/requirements,master,Ifbbcfe2ccf2caa70758f75e44d526d23d7f466cb,Update python-ldap version for Keystone,MERGED,2014-10-16 03:22:23.000000000,2014-12-18 13:35:09.000000000,2014-10-24 22:21:58.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 2592}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 6786}, {'_account_id': 7680}, {'_account_id': 9098}]","[{'number': 1, 'created': '2014-10-16 03:22:23.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/312029d2d0e0279d72411abb7c2ef535019ac9b8', 'message': 'Update python-ldap version for Keystone\n\nWe are currently pinned to an old version of python-ldap. Version\n2.4 of python-ldap has been out for over 3 years now, and most\nplatforms are shipping it.  We should be testing against it instead\nof using an old version.\n\nChange-Id: Ifbbcfe2ccf2caa70758f75e44d526d23d7f466cb\n'}]",0,128817,312029d2d0e0279d72411abb7c2ef535019ac9b8,13,8,1,9098,,,0,"Update python-ldap version for Keystone

We are currently pinned to an old version of python-ldap. Version
2.4 of python-ldap has been out for over 3 years now, and most
platforms are shipping it.  We should be testing against it instead
of using an old version.

Change-Id: Ifbbcfe2ccf2caa70758f75e44d526d23d7f466cb
",git fetch https://review.opendev.org/openstack/requirements refs/changes/17/128817/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,312029d2d0e0279d72411abb7c2ef535019ac9b8,python-ldap-2.4,python-ldap>=2.4,python-ldap==2.3.13,1,1
openstack%2Ffuel-main~master~I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d,openstack/fuel-main,master,I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d,system tests for VMware vCenter functionality,MERGED,2014-09-30 13:14:29.000000000,2014-12-18 13:32:45.000000000,2014-12-18 13:32:45.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11427}, {'_account_id': 11969}, {'_account_id': 12139}, {'_account_id': 12141}, {'_account_id': 12199}, {'_account_id': 12415}]","[{'number': 1, 'created': '2014-09-30 13:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d0a2a37fd53a288584ac8a7ec532975b102aab92', 'message': 'nsx_tests\nAdded smoke tests for nsx according to document:\nPartner Integration Team -> NSX_smoke\nhttps://docs.google.com/a/mirantis.com/spreadsheets/d/12pxHDADqago_6PO4y0VZ1IrwymswqNiuvhMSUoCFaYc/edit?pli=1#gid=624382510\n\nBug: https://bugs.launchpad.net/fuel/+bug/1368285\n\nAdded acceptance tests for nsx\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 2, 'created': '2014-10-06 15:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0dadf5f65d3f73c721ee44d3cbc51bde7181af48', 'message': 'nsx_vcenter_tests\n\nPartner Integration Team -> tests are related to nsx and vcenter features.\nAdded acceptance tests for nsx and vcenter features,  according to document:\nhttps://docs.google.com/a/mirantis.com/spreadsheets/d/12pxHDADqago_6PO4y0VZ1IrwymswqNiuvhMSUoCFaYc/edit?pli=1#gid=624382510\n\nCloses-bug: https://bugs.launchpad.net/fuel/+bug/1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 3, 'created': '2014-10-06 15:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0053138dd0db4f89a5fde478422705f097ee396a', 'message': 'nsx_vcenter_tests\n\nPartner Integration Team -> tests are related to nsx and vcenter features.\nAdded acceptance tests for nsx and vcenter features,  according to document:\nhttps://docs.google.com/a/mirantis.com/spreadsheets/d/12pxHDADqago_6PO4y0VZ1IrwymswqNiuvhMSUoCFaYc/edit?pli=1#gid=624382510\n\nCloses-bug: https://bugs.launchpad.net/fuel/+bug/1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 4, 'created': '2014-10-06 15:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/bd248ce305a1f4ae2c8082b6c681ca1cb1cbac9c', 'message': 'nsx_vcenter_tests\n\nPartner Integration Team -> tests are related to nsx and vcenter features.\nAdded acceptance tests for nsx and vcenter features,  according to document:\nhttps://docs.google.com/a/mirantis.com/spreadsheets/d/12pxHDADqago_6PO4y0VZ1IrwymswqNiuvhMSUoCFaYc/edit?pli=1#gid=624382510\n\nCloses-bug: https://bugs.launchpad.net/fuel/+bug/1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 5, 'created': '2014-10-08 15:30:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c075043bbe28425020f5142bc923e46d630d1b26', 'message': 'nsx_vcenter_tests\n\nAdded acceptance system tests of nsx and vcenter features\nwhich based on manual checklists here: http://goo.gl/51JTsD\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 6, 'created': '2014-10-09 09:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/006a2a04424d19267afcc706305406437afe25c8', 'message': 'Added new system tests of nsx and vcenter features\n\nAdded acceptance system tests of nsx and vcenter features\nwhich based on manual checklists here: http://goo.gl/51JTsD\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 7, 'created': '2014-11-10 09:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/905bbe50e0b597f0fed781d93bbad457078a1d93', 'message': 'Added new system tests of nsx and vcenter features\n\nAdded acceptance system tests of nsx and vcenter features\nwhich based on manual checklists here: http://goo.gl/51JTsD\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 8, 'created': '2014-11-10 14:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f0d8875ba6bbe37d2ac20bf6d246ffbe13562159', 'message': 'Added new system tests of nsx and vcenter features\n\nAdded acceptance system tests of nsx and vcenter features\nwhich based on manual checklists here: http://goo.gl/51JTsD\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 9, 'created': '2014-11-26 11:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6217ea9edd6cfc8ceb41615c045d4dc038ea9f51', 'message': 'Added new system tests of nsx and vcenter features\n\nAdded acceptance system tests of nsx and vcenter features\nwhich based on manual checklists here: http://goo.gl/51JTsD\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 10, 'created': '2014-11-26 11:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/45271f94edb0e6358e21997fd41da62a1f71cf66', 'message': 'Added new system tests of nsx and vcenter features\n\nAdded acceptance system tests of nsx and vcenter features\nwhich based on manual checklists here: http://goo.gl/51JTsD\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 11, 'created': '2014-11-26 13:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ae99f98bf07929cba7317276b92ba8296ca6db61', 'message': 'Added new system tests of nsx and vcenter features\n\nAdded acceptance system tests of nsx and vcenter features\nwhich based on manual checklists here: http://goo.gl/51JTsD\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 12, 'created': '2014-11-26 16:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/496ec3e00191987172a40b778e5f108511cf8525', 'message': 'Added new system tests of nsx and vcenter features\n\nAdded acceptance system tests of nsx and vcenter features\nwhich based on manual checklists here: http://goo.gl/51JTsD\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 13, 'created': '2014-11-26 16:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d8c7307d9bfa86b0aa51a01f7526dc09306f056d', 'message': 'Added new system tests of nsx and vcenter features\n\nAdded acceptance system tests of nsx and vcenter features\nwhich based on manual checklists here: http://goo.gl/51JTsD\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 14, 'created': '2014-12-02 12:31:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e6d4d42eb88d03b6e7e1ab88d61af6cd2183f91e', 'message': 'Added new system tests of nsx and vcenter features\n\nAdded acceptance system tests of nsx and vcenter features\nwhich based on manual checklists here: http://goo.gl/51JTsD\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 15, 'created': '2014-12-02 12:34:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/562a267a88cd40188cf42965abf277fa8356b93d', 'message': 'Added new system tests of nsx and vcenter features\n\nAdded acceptance system tests of nsx and vcenter features\nwhich based on manual checklists here: http://goo.gl/51JTsD\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 16, 'created': '2014-12-04 13:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7b7f4624134014a234008cbffe436f482ccbd6e6', 'message': 'system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- implement following scenarios:\n  basic deployment:\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   - deploy OpenStack cluster in HA mode, run OSTF\n   - deploy OpenStack cluster in HA mode with standalone cinder node,\n     run OSTF\n  destructive scenario:\n   - start cluster deployment with 4 nodes, stop deployment process,\n     wait till nodes are online, start deployment again\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 17, 'created': '2014-12-04 13:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/52440f90ea170b7a7238d4eea8f4887734ee0d17', 'message': 'system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- implement following scenarios:\n  basic deployment:\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   - deploy OpenStack cluster in HA mode, run OSTF\n   - deploy OpenStack cluster in HA mode with standalone cinder node,\n     run OSTF\n  destructive scenario:\n   - start cluster deployment with 4 nodes, stop deployment process,\n     wait till nodes are online, start deployment again\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 18, 'created': '2014-12-04 13:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e195b240d9c988989ef0d5accf7595334e15e43a', 'message': 'system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- implement following scenarios:\n  basic deployment:\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   - deploy OpenStack cluster in HA mode, run OSTF\n   - deploy OpenStack cluster in HA mode with standalone cinder node,\n     run OSTF\n  destructive scenario:\n   - start cluster deployment with 4 nodes, stop deployment process,\n     wait till nodes are online, start deployment again\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 19, 'created': '2014-12-04 19:34:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b34cdef84bc0f497fee3746cefc1d73b5ff71603', 'message': 'system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- implement following scenarios:\n  basic deployment:\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   - deploy OpenStack cluster in HA mode, run OSTF\n   - deploy OpenStack cluster in HA mode with standalone cinder node,\n     run OSTF\n  destructive scenario:\n   - start cluster deployment with 4 nodes, stop deployment process,\n     wait till nodes are online, start deployment again\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 20, 'created': '2014-12-10 11:49:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/aa50d96cdb7203b502333a8d6e49ad4404061e05', 'message': 'system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- implement following scenarios:\n  basic deployment:\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   - deploy OpenStack cluster in HA mode, run OSTF\n   - deploy OpenStack cluster in HA mode with standalone cinder node,\n     run OSTF\n  destructive scenario:\n   - start cluster deployment with 4 nodes, stop deployment process,\n     wait till nodes are online, start deployment again\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 21, 'created': '2014-12-10 11:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d180b0f78cb83e83879148c998c5c7e57e5edc40', 'message': 'system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- implement following scenarios:\n  basic deployment:\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   - deploy OpenStack cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   - deploy OpenStack cluster in HA mode, run OSTF\n   - deploy OpenStack cluster in HA mode with standalone cinder node,\n     run OSTF\n  destructive scenario:\n   - start cluster deployment with 4 nodes, stop deployment process,\n     wait till nodes are online, start deployment again\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n'}, {'number': 22, 'created': '2014-12-12 09:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e458f85102a0edde63b81fdbf0c980ff2256ea97', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True)\n- implement following scenarios:\n   vcenter_one_node_simple:\n     deploy cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   vcenter_multiple_cluster:\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha:\n     deploy cluster with 3 controllers and vCenter as\n     hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_reset_node_during_deployment:\n     start HA cluster deployment, reset one of contrller when deployment\n     progress reaches 30%\n   vcenter_ha_stop_deployment\n     start HA cluster deployment, stop deployment when progress reaches\n     40% (primary controller is in 'ready' state), start deployment again\n     when nodes are ready\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 23, 'created': '2014-12-12 10:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/beeb0da8572252f59691047492e8fd82e88a7018', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True)\n- implement following scenarios:\n   vcenter_one_node_simple:\n     deploy cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   vcenter_multiple_cluster:\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha:\n     deploy cluster with 3 controllers and vCenter as\n     hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_reset_node_during_deployment:\n     start HA cluster deployment, reset one of controller when deployment\n     progress reaches 30%\n   vcenter_ha_stop_deployment\n     start HA cluster deployment, stop deployment when progress reaches\n     40% (primary controller is in 'ready' state), start deployment again\n     when nodes are ready\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 24, 'created': '2014-12-12 10:21:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c082783a75ed894987204704a8773f6efc405c88', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True)\n- implement following scenarios:\n   vcenter_one_node_simple:\n     deploy cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   vcenter_multiple_cluster:\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha:\n     deploy cluster with 3 controllers and vCenter as\n     hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_reset_node_during_deployment:\n     start HA cluster deployment, reset one of controller when deployment\n     progress reaches 30%\n   vcenter_ha_stop_deployment\n     start HA cluster deployment, stop deployment when progress reaches\n     40% (primary controller is in 'ready' state), start deployment again\n     when nodes are ready\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 25, 'created': '2014-12-12 11:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/506ee78c8d18e6ef653f5159da73487ad8a37200', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True)\n- implement following scenarios:\n   vcenter_one_node_simple:\n     deploy cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   vcenter_multiple_cluster:\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha:\n     deploy cluster with 3 controllers and vCenter as\n     hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_reset_node_during_deployment:\n     start HA cluster deployment, reset one of controller when deployment\n     progress reaches 30%\n   vcenter_ha_stop_deployment\n     start HA cluster deployment, stop deployment when progress reaches\n     40% (primary controller is in 'ready' state), start deployment again\n     when nodes are ready\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 26, 'created': '2014-12-12 11:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/334b927922962868668ed95b23379e4547a81f66', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True)\n- implement following scenarios:\n   vcenter_one_node_simple:\n     deploy cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   vcenter_multiple_cluster:\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha:\n     deploy cluster with 3 controllers and vCenter as\n     hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_reset_node_during_deployment:\n     start HA cluster deployment, reset one of controller when deployment\n     progress reaches 30%\n   vcenter_ha_stop_deployment\n     start HA cluster deployment, stop deployment when progress reaches\n     40% (primary controller is in 'ready' state), start deployment again\n     when nodes are ready\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 27, 'created': '2014-12-12 12:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a8539f2269738c501bbc9caf393533b4a8da86cb', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True)\n- implement following scenarios:\n   vcenter_one_node_simple:\n     deploy cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   vcenter_multiple_cluster:\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha:\n     deploy cluster with 3 controllers and vCenter as\n     hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_reset_node_during_deployment:\n     start HA cluster deployment, reset one of controller when deployment\n     progress reaches 30%\n   vcenter_ha_stop_deployment\n     start HA cluster deployment, stop deployment when progress reaches\n     40% (primary controller is in 'ready' state), start deployment again\n     when nodes are ready\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 28, 'created': '2014-12-12 13:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2f4d4fba5f18d4e851ade0cd2b237891d22ca3ad', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True)\n- implement following scenarios:\n   vcenter_one_node_simple\n     deploy cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   vcenter_multiple_cluster\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha\n     deploy cluster with 3 controllers and vCenter as\n     hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_reset_node_during_deployment\n     start HA cluster deployment, reset one of controller when deployment\n     progress reaches 30%\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 29, 'created': '2014-12-12 13:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/370d88ed43288a48fef80b1087e7c342c8199020', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True)\n- implement following scenarios:\n   vcenter_one_node_simple\n     deploy cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   vcenter_multiple_cluster\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha\n     deploy cluster with 3 controllers and vCenter as\n     hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_reset_node_during_deployment\n     start HA cluster deployment, reset one of controller when deployment\n     progress reaches 30%\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 30, 'created': '2014-12-12 15:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2b25415be959686204a1b2b287cd9420519dbaa2', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True)\n- implement following scenarios:\n   vcenter_one_node_simple\n     deploy cluster with one controller that uses vCenter with\n     one vSphere cluster, validate cluster, create instance and delete\n   vcenter_multiple_cluster\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha\n     deploy cluster with 3 controllers and vCenter as\n     hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_reset_node_during_deployment\n     start HA cluster deployment, reset one of controller when deployment\n     progress reaches 30%\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 31, 'created': '2014-12-15 10:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/51d25e6c188bcdfd9a59e44deba1a14a4ede0042', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True), otherwise OSTF tests will\n  fail\n- implement following scenarios:\n   vcenter_multiple_cluster\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha\n     deploy cluster with 3 controllers and vCenter as hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_deployment_with_cinder\n     deploy HA cluster with standalone cinder node, run checks\n   vcenter_simple_stop_deployment\n     deploy cluster with one controller, stop deployment process, start\n     it againt, run checks\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 32, 'created': '2014-12-15 10:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6811caba90f7b3bcf97fdf601c0249945b96e33c', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True), otherwise OSTF tests will\n  fail\n- implement following scenarios:\n   vcenter_multiple_cluster\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha\n     deploy cluster with 3 controllers and vCenter as hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_deployment_with_cinder\n     deploy HA cluster with standalone cinder node, run checks\n   vcenter_simple_stop_deployment\n     deploy cluster with one controller, stop deployment process, start\n     it againt, run checks\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 33, 'created': '2014-12-15 11:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ca8fd4f5e69f5a2ea848a1d3ec066896cea1a306', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True), otherwise OSTF tests will\n  fail\n- implement following scenarios:\n   vcenter_multiple_cluster\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha\n     deploy cluster with 3 controllers and vCenter as hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_deployment_with_cinder\n     deploy HA cluster with standalone cinder node, run checks\n   vcenter_simple_stop_deployment\n     deploy cluster with one controller, stop deployment process, start\n     it againt, run checks\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}, {'number': 34, 'created': '2014-12-16 12:49:29.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/test_vcenter.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9079556440fac755c93faad0c30ff45b8fd3750a', 'message': ""system tests for VMware vCenter functionality\n\n- test basic OpenStack with vCenter functionality\n- when vCenter is used as hypervisor, Cinder must be configured to use\n  VMDK backend (`volumes_vmdk' must be True), otherwise OSTF tests will\n  fail\n- implement following scenarios:\n   vcenter_multiple_cluster\n     deploy cluster with one controller that uses vCenter with\n     two vSphere clusters, verify that we have two hypevisors\n   vcenter_ha\n     deploy cluster with 3 controllers and vCenter as hypervisor\n   vcenter_simple_add_cinder\n     deploy cluster with one controller, add standalone cinder node\n   vcenter_ha_deployment_with_cinder\n     deploy HA cluster with standalone cinder node, run checks\n   vcenter_simple_stop_deployment\n     deploy cluster with one controller, stop deployment process, start\n     it againt, run checks\n\nCloses-bug: #1368285\nChange-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d\n""}]",354,125048,9079556440fac755c93faad0c30ff45b8fd3750a,206,13,34,12415,,,0,"system tests for VMware vCenter functionality

- test basic OpenStack with vCenter functionality
- when vCenter is used as hypervisor, Cinder must be configured to use
  VMDK backend (`volumes_vmdk' must be True), otherwise OSTF tests will
  fail
- implement following scenarios:
   vcenter_multiple_cluster
     deploy cluster with one controller that uses vCenter with
     two vSphere clusters, verify that we have two hypevisors
   vcenter_ha
     deploy cluster with 3 controllers and vCenter as hypervisor
   vcenter_simple_add_cinder
     deploy cluster with one controller, add standalone cinder node
   vcenter_ha_deployment_with_cinder
     deploy HA cluster with standalone cinder node, run checks
   vcenter_simple_stop_deployment
     deploy cluster with one controller, stop deployment process, start
     it againt, run checks

Closes-bug: #1368285
Change-Id: I3dddd6fb80d3acd5ef1a03de2004ec1e5da4c85d
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/48/125048/30 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/tests/test_nsx.py', 'fuelweb_test/tests/test_vcenter.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/settings.py', 'fuelweb_test/tests/base_test_case.py']",7,d0a2a37fd53a288584ac8a7ec532975b102aab92,vcenter-system-tests," @test(depends_on=[prepare_release], groups=[""prepare_slaves_7""]) @log_snapshot_on_error def prepare_slaves_7(self): """"""Bootstrap 7 slave nodes Scenario: 1. Revert snapshot ""ready"" 2. Start 7 slave nodes Snapshot: ready_with_7_slaves """""" self.check_run(""ready_with_7_slaves"") self.env.revert_snapshot(""ready"") self.env.bootstrap_nodes(self.env.nodes().slaves[:7]) self.env.make_snapshot(""ready_with_7_slaves"", is_make=True)",,1095,18
openstack%2Ffuel-main~stable%2F6.0~I0291f227cf84f1cdce11c801a044d51f24448654,openstack/fuel-main,stable/6.0,I0291f227cf84f1cdce11c801a044d51f24448654,Use gateway only for 'public' net in bonding test,MERGED,2014-12-17 16:21:03.000000000,2014-12-18 13:31:46.000000000,2014-12-18 13:31:45.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}, {'_account_id': 12867}]","[{'number': 1, 'created': '2014-12-17 16:21:03.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/eaabcc0cd1af629cad81a2fe7ae4d6b580471c3a', 'message': ""Use gateway only for 'public' net in bonding test\n\nIn system tests for bonding feature we use IP subnet\nfor public network (/24) for other networks which are\nassigned to bonded interface by splitting it on /27\nsubnets. But we can't use public network router as\ngateway for them.\n\nChange-Id: I0291f227cf84f1cdce11c801a044d51f24448654\nCloses-bug: #1403007\n""}]",0,142483,eaabcc0cd1af629cad81a2fe7ae4d6b580471c3a,8,7,1,11081,,,0,"Use gateway only for 'public' net in bonding test

In system tests for bonding feature we use IP subnet
for public network (/24) for other networks which are
assigned to bonded interface by splitting it on /27
subnets. But we can't use public network router as
gateway for them.

Change-Id: I0291f227cf84f1cdce11c801a044d51f24448654
Closes-bug: #1403007
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/83/142483/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/fuel_web_client.py'],1,eaabcc0cd1af629cad81a2fe7ae4d6b580471c3a,," if 'admin' in net_name: net_config['ip_ranges'] = self.get_range(ip_network, 2) if net_config['name'] == 'public': net_config['gateway'] = self.environment.router('public') def get_floating_ranges(self, network_set=''): net_name = 'public{0}'.format(network_set)"," if 'admin' in net_name: net_config['ip_ranges'] = self.get_range(ip_network, 2) net_config['gateway'] = self.environment.router('public') def get_floating_ranges(self, network_set=None): if network_set: net_name = 'public{0}'.format(network_set)",7,6
openstack%2Ffuel-main~master~I0291f227cf84f1cdce11c801a044d51f24448654,openstack/fuel-main,master,I0291f227cf84f1cdce11c801a044d51f24448654,Use gateway only for 'public' net in bonding test,MERGED,2014-12-17 16:13:15.000000000,2014-12-18 13:31:14.000000000,2014-12-18 13:31:12.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}]","[{'number': 1, 'created': '2014-12-17 16:13:15.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4ee2d0a634018cfc3fc7d3604d7e1b46e9711fa0', 'message': ""Use gateway only for 'public' net in bonding test\n\nIn system tests for bonding feature we use IP subnet\nfor public network (/24) for other networks which are\nassigned to bonded interface by splitting it on /27\nsubnets. But we can't use public network router as\ngateway for them.\n\nChange-Id: I0291f227cf84f1cdce11c801a044d51f24448654\nCloses-bug: #1403007\n""}]",1,142478,4ee2d0a634018cfc3fc7d3604d7e1b46e9711fa0,11,9,1,11081,,,0,"Use gateway only for 'public' net in bonding test

In system tests for bonding feature we use IP subnet
for public network (/24) for other networks which are
assigned to bonded interface by splitting it on /27
subnets. But we can't use public network router as
gateway for them.

Change-Id: I0291f227cf84f1cdce11c801a044d51f24448654
Closes-bug: #1403007
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/78/142478/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/fuel_web_client.py'],1,4ee2d0a634018cfc3fc7d3604d7e1b46e9711fa0,bug/1403007," if 'admin' in net_name: net_config['ip_ranges'] = self.get_range(ip_network, 2) if net_config['name'] == 'public': net_config['gateway'] = self.environment.router('public') def get_floating_ranges(self, network_set=''): net_name = 'public{0}'.format(network_set)"," if 'admin' in net_name: net_config['ip_ranges'] = self.get_range(ip_network, 2) net_config['gateway'] = self.environment.router('public') def get_floating_ranges(self, network_set=None): if network_set: net_name = 'public{0}'.format(network_set)",7,6
openstack%2Fbarbican~master~Ieeab73c71312e35f7e1ab6ab5ac32d0f2a22ac43,openstack/barbican,master,Ieeab73c71312e35f7e1ab6ab5ac32d0f2a22ac43,Updated from global requirements,MERGED,2014-12-18 01:20:40.000000000,2014-12-18 13:28:09.000000000,2014-12-18 13:28:08.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}]","[{'number': 1, 'created': '2014-12-18 01:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/a1c3793016c00e0e28176bf3cf674ad287481247', 'message': 'Updated from global requirements\n\nChange-Id: Ieeab73c71312e35f7e1ab6ab5ac32d0f2a22ac43\n'}, {'number': 2, 'created': '2014-12-18 10:13:27.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/barbican/commit/b04659bc47e7d09b9d88a454e4f88701c0adfd0c', 'message': 'Updated from global requirements\n\nChange-Id: Ieeab73c71312e35f7e1ab6ab5ac32d0f2a22ac43\n'}]",0,142634,b04659bc47e7d09b9d88a454e4f88701c0adfd0c,18,4,2,11131,,,0,"Updated from global requirements

Change-Id: Ieeab73c71312e35f7e1ab6ab5ac32d0f2a22ac43
",git fetch https://review.opendev.org/openstack/barbican refs/changes/34/142634/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a1c3793016c00e0e28176bf3cf674ad287481247,openstack/requirements,alembic>=0.7.1,alembic>=0.6.4,1,1
openstack%2Fheat~stable%2Fjuno~I164fbd93140a0048c8173ae4187b9e8b882bdebb,openstack/heat,stable/juno,I164fbd93140a0048c8173ae4187b9e8b882bdebb,Updated from global requirements,MERGED,2014-12-14 00:10:53.000000000,2014-12-18 13:26:01.000000000,2014-12-18 12:53:33.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4328}, {'_account_id': 9542}, {'_account_id': 9656}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-14 00:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/40a32792a5f05939c9dabcdedd09e09750659c6f', 'message': 'Updated from global requirements\n\nChange-Id: I164fbd93140a0048c8173ae4187b9e8b882bdebb\n'}, {'number': 2, 'created': '2014-12-16 14:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c368c5523489f5c7dfaf25bea378a3b3dabae499', 'message': 'Updated from global requirements\n\nChange-Id: I164fbd93140a0048c8173ae4187b9e8b882bdebb\n'}, {'number': 3, 'created': '2014-12-16 23:03:04.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/fcc1b97c0ee36459061809ce30f9ca6dac221ef1', 'message': 'Updated from global requirements\n\nChange-Id: I164fbd93140a0048c8173ae4187b9e8b882bdebb\n'}]",3,141597,fcc1b97c0ee36459061809ce30f9ca6dac221ef1,21,6,3,11131,,,0,"Updated from global requirements

Change-Id: I164fbd93140a0048c8173ae4187b9e8b882bdebb
",git fetch https://review.opendev.org/openstack/heat refs/changes/97/141597/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,40a32792a5f05939c9dabcdedd09e09750659c6f,openstack/requirements,"SQLAlchemy>=0.8.4,<=0.9.99,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,!=0.9.4,!=0.9.5,!=0.9.6","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",1,1
openstack%2Frally~master~I5bcee5db2d7188633d45e6161e0c956449ad2197,openstack/rally,master,I5bcee5db2d7188633d45e6161e0c956449ad2197,Python 3 incompatible issue: iteritems,MERGED,2014-12-17 09:37:24.000000000,2014-12-18 13:24:36.000000000,2014-12-18 13:24:35.000000000,"[{'_account_id': 3}, {'_account_id': 8507}, {'_account_id': 9545}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-17 09:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ba7fa6dfc3f16ee6fe3f833afb4acd151643d746', 'message': 'Python 3 incompatible issue: iteritems\n\ndict.iteritems() was removed in Python 3. This patch\nreplace dict.iteritems() with six.iteritems() to support\nboth Python 2 and Python 3\n\nChange-Id: I5bcee5db2d7188633d45e6161e0c956449ad2197\n'}, {'number': 2, 'created': '2014-12-17 09:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e58fd264cffaef1a565b1ec416be33e5b9438d12', 'message': 'Python 3 incompatible issue: iteritems\n\ndict.iteritems() was removed in Python 3. This patch\nreplace dict.iteritems() with six.iteritems() to support\nboth Python 2 and Python 3\n\nCloses-Bug: #1403071\n\nChange-Id: I5bcee5db2d7188633d45e6161e0c956449ad2197\n'}, {'number': 3, 'created': '2014-12-17 10:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/71b7c759099add8ad9deaa08c10cfd9de9650ca5', 'message': 'Python 3 incompatible issue: iteritems\n\ndict.iteritems() was removed in Python 3. This patch\nreplace dict.iteritems() with six.iteritems() to support\nboth Python 2 and Python 3\n\nCloses-Bug: #1403071\n\nChange-Id: I5bcee5db2d7188633d45e6161e0c956449ad2197\n'}, {'number': 4, 'created': '2014-12-17 10:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7bdcb4d0dab6d28cabb2792219d4ceda9530035a', 'message': 'Python 3 incompatible issue: iteritems\n\ndict.iteritems() was removed in Python 3. This patch\nreplace dict.iteritems() with six.iteritems() to support\nboth Python 2 and Python 3\n\nCloses-Bug: #1403071\n\nChange-Id: I5bcee5db2d7188633d45e6161e0c956449ad2197\n'}, {'number': 5, 'created': '2014-12-17 13:32:51.000000000', 'files': ['rally/benchmark/scenarios/nova/utils.py', 'tests/unit/deploy/serverprovider/test_provider.py', 'rally/benchmark/context/base.py', 'rally/benchmark/context/secgroup.py', 'tests/unit/benchmark/scenarios/quotas/test_utils.py', 'rally/deploy/serverprovider/providers/lxc.py', 'tests/unit/fakes.py', 'rally/deploy/engines/lxc.py', 'rally/benchmark/engine.py', 'rally/deploy/engines/devstack.py', 'tests/unit/benchmark/context/cleanup/test_manager.py', 'rally/benchmark/runners/base.py', 'rally/deploy/engines/multihost.py', 'rally/benchmark/sla/base.py', 'rally/benchmark/processing/plot.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/1c70896ea0ef5841c702fa5d93d8f484155779db', 'message': 'Python 3 incompatible issue: iteritems\n\ndict.iteritems() was removed in Python 3. This patch\nreplace dict.iteritems() with six.iteritems() to support\nboth Python 2 and Python 3\n\nCloses-Bug: #1403071\n\nChange-Id: I5bcee5db2d7188633d45e6161e0c956449ad2197\n'}]",0,142394,1c70896ea0ef5841c702fa5d93d8f484155779db,26,4,5,8367,,,0,"Python 3 incompatible issue: iteritems

dict.iteritems() was removed in Python 3. This patch
replace dict.iteritems() with six.iteritems() to support
both Python 2 and Python 3

Closes-Bug: #1403071

Change-Id: I5bcee5db2d7188633d45e6161e0c956449ad2197
",git fetch https://review.opendev.org/openstack/rally refs/changes/94/142394/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/nova/utils.py', 'tests/unit/deploy/serverprovider/test_provider.py', 'rally/benchmark/context/base.py', 'rally/benchmark/context/secgroup.py', 'tests/unit/benchmark/scenarios/quotas/test_utils.py', 'rally/deploy/serverprovider/providers/lxc.py', 'tests/unit/fakes.py', 'rally/deploy/engines/lxc.py', 'rally/benchmark/engine.py', 'rally/deploy/engines/devstack.py', 'tests/unit/benchmark/context/cleanup/test_manager.py', 'rally/benchmark/runners/base.py', 'rally/deploy/engines/multihost.py', 'rally/benchmark/sla/base.py', 'rally/benchmark/processing/plot.py']",15,ba7fa6dfc3f16ee6fe3f833afb4acd151643d746,bug/1403071,"import six for k, v in six.iteritems(output): for k, v in six.iteritems(atomic_durations): for name, durations in six.iteritems(data[""atomic_durations""]):"," for k, v in output.iteritems(): for k, v in atomic_durations.iteritems(): for name, durations in data[""atomic_durations""].iteritems():",35,21
openstack%2Fnova-specs~master~I17002abf79157d108b649b6e0a58c4b50ea9ebae,openstack/nova-specs,master,I17002abf79157d108b649b6e0a58c4b50ea9ebae,i18n lazy translation enablement,MERGED,2014-10-07 20:23:57.000000000,2014-12-18 13:22:16.000000000,2014-12-18 13:22:14.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 6601}, {'_account_id': 6873}, {'_account_id': 12898}]","[{'number': 1, 'created': '2014-10-07 20:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/45b2e2d8a3559689f52aa3c11a83cd2419310cc8', 'message': 'i18n lazy translation enablement\n\nEnable lazy translation of messages to support the\nAccept-Language header\n\nPreviously-approved: juno\nPart of blueprint i18n-enablement\n\nChange-Id: I17002abf79157d108b649b6e0a58c4b50ea9ebae\n'}, {'number': 2, 'created': '2014-10-08 14:32:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/878523b7e43a02e0a58dc75eb2599de116c9789e', 'message': 'i18n lazy translation enablement\n\nEnable lazy translation of messages to support the\nAccept-Language header\n\nPreviously-approved: juno\nPart of blueprint i18n-enablement\n\nChange-Id: I17002abf79157d108b649b6e0a58c4b50ea9ebae\n'}, {'number': 3, 'created': '2014-10-08 19:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/76c26a0736e4e2fad8b94e197fe7c17db15955fb', 'message': 'i18n lazy translation enablement\n\nEnable lazy translation of messages to support the\nAccept-Language header\n\nPreviously-approved: juno\nPart of blueprint i18n-enablement\n\nChange-Id: I17002abf79157d108b649b6e0a58c4b50ea9ebae\n'}, {'number': 4, 'created': '2014-10-16 15:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2db05a3a73b224975e4d658c41d0108ad3095568', 'message': 'i18n lazy translation enablement\n\nEnable lazy translation of messages to support the\nAccept-Language header\n\nPreviously-approved: juno\nPart of blueprint i18n-enablement\n\nChange-Id: I17002abf79157d108b649b6e0a58c4b50ea9ebae\n'}, {'number': 5, 'created': '2014-10-16 16:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e180071d291984e5cb87795aa3fdaf980196d73a', 'message': 'i18n lazy translation enablement\n\nEnable lazy translation of messages to support the\nAccept-Language header\n\nPreviously-approved: juno\nPart of blueprint i18n-enablement\n\nChange-Id: I17002abf79157d108b649b6e0a58c4b50ea9ebae\n'}, {'number': 6, 'created': '2014-10-16 18:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/56b117946f02a41aed00be3930abb8747ce42332', 'message': 'i18n lazy translation enablement\n\nEnable lazy translation of messages to support the\nAccept-Language header\n\nPreviously-approved: juno\nPart of blueprint i18n-enablement\n\nChange-Id: I17002abf79157d108b649b6e0a58c4b50ea9ebae\n'}, {'number': 7, 'created': '2014-10-17 18:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a02bb646f15cca26bee36d1b6bf98d1c9036d4d5', 'message': 'i18n lazy translation enablement\n\nEnable lazy translation of messages to support the\nAccept-Language header\n\nPreviously-approved: juno\nPart of blueprint i18n-enablement\n\nChange-Id: I17002abf79157d108b649b6e0a58c4b50ea9ebae\n'}, {'number': 8, 'created': '2014-12-09 22:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e6c155ee322b853f4bb37e8ebe6e028e8cc34c93', 'message': 'i18n lazy translation enablement\n\nEnable lazy translation of messages to support the\nAccept-Language header\n\nPreviously-approved: juno\nPart of blueprint i18n-enablement-juno\n\nChange-Id: I17002abf79157d108b649b6e0a58c4b50ea9ebae\n'}, {'number': 9, 'created': '2014-12-16 16:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e72f4a80d2e1db46dcf8665ff0518d3214b25e85', 'message': 'i18n lazy translation enablement\n\nEnable lazy translation of messages to support the\nAccept-Language header\n\nPreviously-approved: juno\nPart of blueprint i18n-enablement-juno\n\nChange-Id: I17002abf79157d108b649b6e0a58c4b50ea9ebae\n'}, {'number': 10, 'created': '2014-12-16 19:21:26.000000000', 'files': ['specs/kilo/approved/i18n-enablement.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/712d26bfb5d4983bee08c9832873002545cd49af', 'message': 'i18n lazy translation enablement\n\nEnable lazy translation of messages to support the\nAccept-Language header\n\nPreviously-approved: juno\nPart of blueprint i18n-enablement-juno\n\nChange-Id: I17002abf79157d108b649b6e0a58c4b50ea9ebae\n'}]",39,126717,712d26bfb5d4983bee08c9832873002545cd49af,46,10,10,6601,,,0,"i18n lazy translation enablement

Enable lazy translation of messages to support the
Accept-Language header

Previously-approved: juno
Part of blueprint i18n-enablement-juno

Change-Id: I17002abf79157d108b649b6e0a58c4b50ea9ebae
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/17/126717/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/i18n-enablement.rst'],1,45b2e2d8a3559689f52aa3c11a83cd2419310cc8,bp/i18n-enablement-juno,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== i18n Enablement for Nova ========================================== https://blueprints.launchpad.net/nova/+spec/i18n-enablement This BluePrint/Spec proposes completing the enablement of i18n (internationalization) support for Nova by turning on the ""lazy"" translation support from the oslo.i18n library and updating Nova to adhere to the restrictions this adds to translatable strings. Internationalization implementation has been an on-going effort in OpenStack during recent releases. The original blueprint for the Oslo support was included in Havana: https://blueprints.launchpad.net/oslo/+spec/delayed-message-translation Blueprints for this support in Nova have been approved and worked on in previous releases (https://blueprints.launchpad.net/nova/+spec/user-locale-api). During the Icehouse release, the foundational support for internationalization was merged into Nova. Specifically the update of Oslo's gettextutils and the pre-existing work of explicitly importing '_' from gettextutils. During the Juno release, hacking checks were added to restrict how translatable messasges are used in Nova. In particular, ensuring that translatable messges are not concatenated and that str() is not used on exceptions. To finalize this work in Kilo we need to enable the ""lazy"" translation provided in the oslo.i18n library and fix a few cases where str() is used on a translatable message. Enablement of lazy translation will allow end users to not only have logs produced in multiple languages, but adds the ability for REST API messages to also be returned in the language chosen by the user. This functionality is important to support the use of OpenStack by the international community. Problem description =================== Today all users of Nova must agree on a common locale to use to translate messages. This is because messages are translated when they are created. There is a need for different Nova users to be able to use different translations simultaneously. Use Cases --------- A user calls Nova via the REST API and specifies a value for Accept-Language in the Header that does not match the locale being used by the server. Instead of the messages being returned in the locale specified by the user, the messages are returned translated to the server's locale. With this change the messages are translated prior to being returned by the server using the locale specified by the user, and if the translation is available the message is translated to that locale and returned. Project Priority ---------------- Low -- but needs to be enabled as early as possible to provide as much 'burn in' time as possible. Proposed change =============== This proposal is to use the oslo.i18n library support in order to enable ""lazy"" translation of messages. This support, instead of immediately translating the messages, creates a Message object which holds the message and replacement text until the message can be translated using the locale associated with the Accept-Language Header from the user request. The code changes will be done as a single patch that adds an enable_lazy() helper method (that calls oslo.i18n's enable_lazy()) to nova/i18n.py and adds a call to this new helper in nova/cmd/__init__.py. It will also include removal of a couple of cases where str() is being called on translatable messages. Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- There is no additional changes to the REST API other than the fact that the change enables the user to specify the language they wish REST API responses to be returned in using the Accept-Language option. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- Once merged this feature is immediately available to users. Developer impact ---------------- The developer impacts have already been in place for some time. Developers have been using _() around messages that need translation. Implementation ============== Assignee(s) ----------- Primary assignee: <jecarey@us.ibm.com> Work Items ---------- I am planning to implement this as one patch: * Add enable_lazy() helper to nova/i18n.py * Add call to helper in nova/cmd/__init__.py * Remove use of str() on translatable messages Dependencies ============ This depends on a new version of the oslo.vmware library which contains https://review.openstack.org/#/c/122193/ which fixes lazy enablement support. Testing ======= * There will be a tempest test added for Nova that will ensure that lazy translation is working properly. * Hacking checks were added in Juno for: * Concatenation of translatable messages * Use of str() on exceptions Documentation Impact ==================== None. References ========== * Accept-Language header: http://www.w3.org/International/questions/qa-accept-lang-locale ",,186,0
openstack%2Fpuppet-tempest~master~I6d5c17393630fda156bebc55fe28f97bcabecca4,openstack/puppet-tempest,master,I6d5c17393630fda156bebc55fe28f97bcabecca4,Allow to not manage Tempest code in Puppet,MERGED,2014-12-03 19:55:24.000000000,2014-12-18 13:07:48.000000000,2014-12-17 16:34:48.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7616}, {'_account_id': 8482}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-12-03 19:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/2e6b663d7daf37a23fa73bec338e42a6ebfd89f4', 'message': 'Allow to not manage Tempest code in Puppet\n\nIn the case you are using a package, you may want the flexibility to not\nuse VCS to manage Tempest code and just use the Puppet module to\nconfigure Tempest itself.\n\nAdding a new parameter, true by default to keep backward compatibility.\n\nChange-Id: I6d5c17393630fda156bebc55fe28f97bcabecca4\n'}, {'number': 2, 'created': '2014-12-09 01:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/297fbc178268332aba97bd6435e6c9d83c4098d3', 'message': 'Allow to not manage Tempest code in Puppet\n\nIn the case you are using a package, you may want the flexibility to not\nuse VCS to manage Tempest code and just use the Puppet module to\nconfigure Tempest itself.\n\nAdding a new parameter, true by default to keep backward compatibility.\n\nChange-Id: I6d5c17393630fda156bebc55fe28f97bcabecca4\n'}, {'number': 3, 'created': '2014-12-15 20:28:21.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/05fc037265964e16429639e26601d8fd6d28ec4c', 'message': 'Allow to not manage Tempest code in Puppet\n\nIn the case you are using a package, you may want the flexibility to not\nuse VCS to manage Tempest code and just use the Puppet module to\nconfigure Tempest itself.\n\nAdding a new parameter, true by default to keep backward compatibility.\n\nChange-Id: I6d5c17393630fda156bebc55fe28f97bcabecca4\n'}]",4,138838,05fc037265964e16429639e26601d8fd6d28ec4c,20,8,3,3153,,,0,"Allow to not manage Tempest code in Puppet

In the case you are using a package, you may want the flexibility to not
use VCS to manage Tempest code and just use the Puppet module to
configure Tempest itself.

Adding a new parameter, true by default to keep backward compatibility.

Change-Id: I6d5c17393630fda156bebc55fe28f97bcabecca4
",git fetch https://review.opendev.org/openstack/puppet-tempest refs/changes/38/138838/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,2e6b663d7daf37a23fa73bec338e42a6ebfd89f4,install-tempest," $manage_packages = true, if $manage_packages { ensure_packages([ 'git', 'python-setuptools', ]) ensure_packages($tempest::params::dev_packages) exec { 'install-pip': command => '/usr/bin/easy_install pip', unless => '/usr/bin/which pip', require => Package['python-setuptools'], } exec { 'install-tox': command => ""${tempest::params::pip_bin_path}/pip install -U tox"", unless => '/usr/bin/which tox', require => Exec['install-pip'], } vcsrepo { $tempest_clone_path: ensure => 'present', source => $tempest_repo_uri, revision => $tempest_repo_revision, provider => 'git', require => Package['git'], user => $tempest_clone_owner, } if $setup_venv { # virtualenv will be installed along with tox exec { 'setup-venv': command => ""/usr/bin/python ${tempest_clone_path}/tools/install_venv.py"", cwd => $tempest_clone_path, unless => ""/usr/bin/test -d ${tempest_clone_path}/.venv"", require => [ Vcsrepo[$tempest_clone_path], Exec['install-tox'], Package[$tempest::params::dev_packages], ], } } $tempest_conf = ""${tempest_clone_path}/etc/tempest.conf"" file { $tempest_conf: replace => false, source => ""${tempest_conf}.sample"", require => Vcsrepo[$tempest_clone_path], owner => $tempest_clone_owner, } Tempest_config { path => $tempest_conf, require => File[$tempest_conf], } } else { $tempest_conf = '/etc/tempest.conf' Tempest_config { path => $tempest_conf, }"," ensure_packages([ 'git', 'python-setuptools', ]) ensure_packages($tempest::params::dev_packages) exec { 'install-pip': command => '/usr/bin/easy_install pip', unless => '/usr/bin/which pip', require => Package['python-setuptools'], } exec { 'install-tox': command => ""${tempest::params::pip_bin_path}/pip install -U tox"", unless => '/usr/bin/which tox', require => Exec['install-pip'], } vcsrepo { $tempest_clone_path: ensure => 'present', source => $tempest_repo_uri, revision => $tempest_repo_revision, provider => 'git', require => Package['git'], user => $tempest_clone_owner, } if $setup_venv { # virtualenv will be installed along with tox exec { 'setup-venv': command => ""/usr/bin/python ${tempest_clone_path}/tools/install_venv.py"", cwd => $tempest_clone_path, unless => ""/usr/bin/test -d ${tempest_clone_path}/.venv"", require => [ Vcsrepo[$tempest_clone_path], Exec['install-tox'], Package[$tempest::params::dev_packages], ], } } $tempest_conf = ""${tempest_clone_path}/etc/tempest.conf"" file { $tempest_conf: replace => false, source => ""${tempest_conf}.sample"", require => Vcsrepo[$tempest_clone_path], owner => $tempest_clone_owner, } Tempest_config { path => $tempest_conf, require => File[$tempest_conf],",58,48
openstack%2Fpuppet-tempest~stable%2Fjuno~I6d5c17393630fda156bebc55fe28f97bcabecca4,openstack/puppet-tempest,stable/juno,I6d5c17393630fda156bebc55fe28f97bcabecca4,Allow to not manage Tempest code in Puppet,ABANDONED,2014-12-17 16:13:35.000000000,2014-12-18 13:07:06.000000000,,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-12-17 16:13:35.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/e026eaf2b6def3673f67c98eac3f8897845cfed0', 'message': 'Allow to not manage Tempest code in Puppet\n\nIn the case you are using a package, you may want the flexibility to not\nuse VCS to manage Tempest code and just use the Puppet module to\nconfigure Tempest itself.\n\nAdding a new parameter, true by default to keep backward compatibility.\n\nChange-Id: I6d5c17393630fda156bebc55fe28f97bcabecca4\n'}]",0,142480,e026eaf2b6def3673f67c98eac3f8897845cfed0,4,5,1,3153,,,0,"Allow to not manage Tempest code in Puppet

In the case you are using a package, you may want the flexibility to not
use VCS to manage Tempest code and just use the Puppet module to
configure Tempest itself.

Adding a new parameter, true by default to keep backward compatibility.

Change-Id: I6d5c17393630fda156bebc55fe28f97bcabecca4
",git fetch https://review.opendev.org/openstack/puppet-tempest refs/changes/80/142480/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,e026eaf2b6def3673f67c98eac3f8897845cfed0,," $install_from_source = true, $tempest_config_file = '/var/lib/tempest/etc/tempest.conf', if $install_from_source { ensure_packages([ 'git', 'python-setuptools', ]) ensure_packages($tempest::params::dev_packages) exec { 'install-pip': command => '/usr/bin/easy_install pip', unless => '/usr/bin/which pip', require => Package['python-setuptools'], } exec { 'install-tox': command => ""${tempest::params::pip_bin_path}/pip install -U tox"", unless => '/usr/bin/which tox', require => Exec['install-pip'], } vcsrepo { $tempest_clone_path: ensure => 'present', source => $tempest_repo_uri, revision => $tempest_repo_revision, provider => 'git', require => Package['git'], user => $tempest_clone_owner, } if $setup_venv { # virtualenv will be installed along with tox exec { 'setup-venv': command => ""/usr/bin/python ${tempest_clone_path}/tools/install_venv.py"", cwd => $tempest_clone_path, unless => ""/usr/bin/test -d ${tempest_clone_path}/.venv"", require => [ Vcsrepo[$tempest_clone_path], Exec['install-tox'], Package[$tempest::params::dev_packages], ], } } $tempest_conf = ""${tempest_clone_path}/etc/tempest.conf"" file { $tempest_conf: replace => false, source => ""${tempest_conf}.sample"", require => Vcsrepo[$tempest_clone_path], owner => $tempest_clone_owner, } Tempest_config { path => $tempest_conf, require => File[$tempest_conf], } } else { Tempest_config { path => $tempest_config_file, }"," ensure_packages([ 'git', 'python-setuptools', ]) ensure_packages($tempest::params::dev_packages) exec { 'install-pip': command => '/usr/bin/easy_install pip', unless => '/usr/bin/which pip', require => Package['python-setuptools'], } exec { 'install-tox': command => ""${tempest::params::pip_bin_path}/pip install -U tox"", unless => '/usr/bin/which tox', require => Exec['install-pip'], } vcsrepo { $tempest_clone_path: ensure => 'present', source => $tempest_repo_uri, revision => $tempest_repo_revision, provider => 'git', require => Package['git'], user => $tempest_clone_owner, } if $setup_venv { # virtualenv will be installed along with tox exec { 'setup-venv': command => ""/usr/bin/python ${tempest_clone_path}/tools/install_venv.py"", cwd => $tempest_clone_path, unless => ""/usr/bin/test -d ${tempest_clone_path}/.venv"", require => [ Vcsrepo[$tempest_clone_path], Exec['install-tox'], Package[$tempest::params::dev_packages], ], } } $tempest_conf = ""${tempest_clone_path}/etc/tempest.conf"" file { $tempest_conf: replace => false, source => ""${tempest_conf}.sample"", require => Vcsrepo[$tempest_clone_path], owner => $tempest_clone_owner, } Tempest_config { path => $tempest_conf, require => File[$tempest_conf],",57,48
openstack%2Fgnocchi~master~I8778b9ac50189ad9c964c2db3cc3735699ab240e,openstack/gnocchi,master,I8778b9ac50189ad9c964c2db3cc3735699ab240e,aggregates: added moving average,MERGED,2014-11-19 17:51:40.000000000,2014-12-18 12:57:24.000000000,2014-12-18 12:57:22.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 10683}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-11-19 17:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e6588346c01ff8c493e72275a563f6b2292839ec', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 2, 'created': '2014-12-02 15:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6f01f9b32d631e5c9019afa36fa6c00a74c55aa2', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 3, 'created': '2014-12-02 16:34:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/0711de041ba633262fb2ee86ddfa9da013f68b29', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 4, 'created': '2014-12-05 06:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a42d590f3b99ac645af4444af0cb08b3308fc6a3', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 5, 'created': '2014-12-10 02:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/859b6b994a2502e12cf4ce8fe90804c43cdcca39', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 6, 'created': '2014-12-10 12:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6b1b2228ad0f0c0d8b8abf7b5983f3f5d184ee81', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 7, 'created': '2014-12-10 13:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/234ff46b216ad8fccab3cc4e2cab41763fced974', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 8, 'created': '2014-12-12 00:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/ccdd4a6a68cfd4d696615bf2ed7ed0f5bec3a03b', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 9, 'created': '2014-12-12 01:08:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8369941a97ad68c31534fdcd4609476c5bc322a9', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 10, 'created': '2014-12-12 17:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/5cb3415405ea204d7aa59129decc24a8be15b948', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 11, 'created': '2014-12-12 18:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/b1e18f6dd9d5cbbf654866920f03ef6bcaf73fe4', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 12, 'created': '2014-12-16 19:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4efcf7861bdf48a8fb77f9081baf8965af27152e', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}, {'number': 13, 'created': '2014-12-16 20:22:34.000000000', 'files': ['gnocchi/tests/base.py', 'requirements.txt', 'gnocchi/tests/test_aggregates.py', 'gnocchi/aggregates/moving_stats.py', 'setup.cfg', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/2bf6925e46a6c76eec55e1185d94d3f0f82d1930', 'message': 'aggregates: added moving average\n\nChange-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e\n'}]",23,135678,2bf6925e46a6c76eec55e1185d94d3f0f82d1930,43,5,13,10683,,,0,"aggregates: added moving average

Change-Id: I8778b9ac50189ad9c964c2db3cc3735699ab240e
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/78/135678/10 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/aggregates/__init__.py', 'gnocchi/tests/test_aggregates.py', 'gnocchi/aggregates/moving_stats.py', 'setup.cfg', 'gnocchi/tests/test_rest.py']",5,e6588346c01ff8c493e72275a563f6b2292839ec,custom_agg," def _test_get_measure_aggregation_custom(self, agg_method, expected): result = self.app.post_json(""/v1/entity"", params={""archive_policy"": ""medium""}) entity = json.loads(result.text) self.app.post_json(""/v1/entity/%s/measures"" % entity['id'], params=[{""timestamp"": '2013-01-01 12:00:00', ""value"": 69}, {""timestamp"": '2013-01-01 12:00:20', ""value"": 42}, {""timestamp"": '2013-01-01 12:00:40', ""value"": 6}, {""timestamp"": '2013-01-01 12:01:00', ""value"": 44}, {""timestamp"": '2013-01-01 12:01:20', ""value"": 7}]) path = ""/v1/entity/%s/measures?aggregation=%s&window=120s"" ret = self.app.get(path % (entity['id'], agg_method), status=200) result = json.loads(ret.text) self.assertEqual(expected, result) def test_get_measure_moving_average(self): r = [[u'2014-01-01T12:00:00.000000', 120.0, 32.25]] self._test_get_measure_aggregation_custom('moving-average', r) ",,262,2
openstack%2Fneutron~master~I181fc4f2b066eca08f2f23c5d2ff996aa46795ab,openstack/neutron,master,I181fc4f2b066eca08f2f23c5d2ff996aa46795ab,Updated from global requirements,MERGED,2014-12-18 01:23:15.000000000,2014-12-18 12:56:29.000000000,2014-12-18 12:56:28.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-18 01:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/61dceeebeff6490e99a05821a4ea7ac22e29a0ee', 'message': 'Updated from global requirements\n\nChange-Id: I181fc4f2b066eca08f2f23c5d2ff996aa46795ab\n'}, {'number': 2, 'created': '2014-12-18 10:16:01.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ce9ba42c3ba5a772031a4d3f5a96dcb5e665c961', 'message': 'Updated from global requirements\n\nChange-Id: I181fc4f2b066eca08f2f23c5d2ff996aa46795ab\n'}]",0,142637,ce9ba42c3ba5a772031a4d3f5a96dcb5e665c961,40,19,2,11131,,,0,"Updated from global requirements

Change-Id: I181fc4f2b066eca08f2f23c5d2ff996aa46795ab
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/142637/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,61dceeebeff6490e99a05821a4ea7ac22e29a0ee,openstack/requirements,alembic>=0.7.1,alembic>=0.6.4,1,1
openstack%2Fopenstack-ansible~master~I4270a9d11039b62d631f82d24de7cc87d5f142c9,openstack/openstack-ansible,master,I4270a9d11039b62d631f82d24de7cc87d5f142c9,delegate container_create to physical hosts,MERGED,2014-12-04 22:50:33.000000000,2014-12-18 12:56:22.000000000,2014-12-18 11:43:25.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-04 22:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/75a50e8d511d722d5281172ca2730a6d7bef78d8', 'message': 'delegate container_create\n\nChange-Id: I4270a9d11039b62d631f82d24de7cc87d5f142c9\n'}, {'number': 2, 'created': '2014-12-08 11:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/585d8f1261afbc4fd989276838e714e0f44c8a25', 'message': 'delegate container_create\n\nChange-Id: I4270a9d11039b62d631f82d24de7cc87d5f142c9\n'}, {'number': 3, 'created': '2014-12-09 15:37:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9c2ad69cd6ea307c1bbc1e5d060213f1f04bd19e', 'message': 'delegate container_create to physical hosts\n\nThis eliminates the use of hostvars[] in container creation which allows\nus to use templated variables, necessary for the fix for #1399427 which\nhas already been merged.\n\nNotes:\n  * Might increase speed as $forks containers can be created in parallel\n  * Might introduce races as multiple tasks may be delegated to the same\n    physical host concurrently.\n\nCloses-Bug: #1399427\nChange-Id: I4270a9d11039b62d631f82d24de7cc87d5f142c9\n'}, {'number': 4, 'created': '2014-12-09 22:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/032c6a77611aba7ad5d929c25f778a3c9b3da25d', 'message': 'delegate container_create to physical hosts\n\nThis eliminates the use of hostvars[] in container creation which allows\nus to use templated variables, necessary for the fix for #1399427 which\nhas already been merged.\n\nNotes:\n  * Might increase speed as $forks containers can be created in parallel\n  * Might introduce races as multiple tasks may be delegated to the same\n    physical host concurrently.\n  * Improves container create capabilities.\n\nCloses-Bug: #1399427\nChange-Id: I4270a9d11039b62d631f82d24de7cc87d5f142c9\n'}, {'number': 5, 'created': '2014-12-10 08:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e91df302230a1dd83c1d47f426c2487bdec15df4', 'message': 'delegate container_create to physical hosts\n\nThis eliminates the use of hostvars[] in container creation which allows\nus to use templated variables, necessary for the fix for #1399427 which\nhas already been merged.\n\nNotes:\n  * Might increase speed as $forks containers can be created in parallel\n  * Might introduce races as multiple tasks may be delegated to the same\n    physical host concurrently.\n  * Improves container create capabilities.\n\nCloses-Bug: #1399427\nChange-Id: I4270a9d11039b62d631f82d24de7cc87d5f142c9\n'}, {'number': 6, 'created': '2014-12-10 08:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ddba5b1043eabce96fb1af4ea9f5bd5df53073ba', 'message': 'delegate container_create to physical hosts\n\nThis eliminates the use of hostvars[] in container creation which allows\nus to use templated variables, necessary for the fix for #1399427 which\nhas already been merged.\n\nNotes:\n  * Might increase speed as $forks containers can be created in parallel\n  * Might introduce races as multiple tasks may be delegated to the same\n    physical host concurrently.\n\nCloses-Bug: #1399427\nChange-Id: I4270a9d11039b62d631f82d24de7cc87d5f142c9\n'}, {'number': 7, 'created': '2014-12-10 10:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6b158b792aafb6a433ed9e078dd4658180a44bcb', 'message': 'delegate container_create to physical hosts\n\nThis eliminates the use of hostvars[] in container creation which allows\nus to use templated variables, necessary for the fix for #1399427 which\nhas already been merged.\n\nNotes:\n  * Might increase speed as $forks containers can be created in parallel\n  * Potential for races as multiple tasks may be delegated to the same\n    physical host concurrently, however the tasks that are delegated\n    (lvm check, lxc-create) are safe to run in parallel.\n\nCloses-Bug: #1399427\nChange-Id: I4270a9d11039b62d631f82d24de7cc87d5f142c9\n'}, {'number': 8, 'created': '2014-12-10 16:44:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1f476dc9195bb6d27ab25851b959ec31c43d536a', 'message': 'delegate container_create to physical hosts\n\nThis eliminates the use of hostvars[] in container creation which allows\nus to use templated variables, necessary for the fix for #1399427 which\nhas already been merged.\n\nNotes:\n  * Creates containers in parallel.\n  * Improves flexability in container create as a specific group or container\n    can be targeted on the CLI.\n  * Syntax clean up.\n  * Adds option to specify the container volume group name.\n  * Removes the ""ignored"" failure note when running in an environment that does\n    not use LVM and have an LXC volume group.\n\nCloses-Bug: #1399427\nChange-Id: I4270a9d11039b62d631f82d24de7cc87d5f142c9\n'}, {'number': 9, 'created': '2014-12-10 18:42:12.000000000', 'files': ['rpc_deployment/roles/container_create/tasks/container_create.yml', 'rpc_deployment/roles/host_common/tasks/main.yml', 'rpc_deployment/playbooks/setup/build-containers.yml', 'rpc_deployment/roles/host_common/tasks/check_container_bridge.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/96b9b494a46e1e81ffbb15238d84ac7dd646b18c', 'message': 'delegate container_create to physical hosts\n\nThis eliminates the use of hostvars[] in container creation which allows\nus to use templated variables, necessary for the fix for #1399427 which\nhas already been merged.\n\nNotes:\n  * Creates containers in parallel.\n  * Improves flexability in container create as a specific group or container\n    can be targeted on the CLI.\n  * Syntax clean up.\n  * Adds option to specify the container volume group name.\n  * Removes the ""ignored"" failure note when running in an environment that does\n    not use LVM and have an LXC volume group.\n\nCloses-Bug: #1399427\nChange-Id: I4270a9d11039b62d631f82d24de7cc87d5f142c9\n'}]",5,139242,96b9b494a46e1e81ffbb15238d84ac7dd646b18c,56,6,9,4,,,0,"delegate container_create to physical hosts

This eliminates the use of hostvars[] in container creation which allows
us to use templated variables, necessary for the fix for #1399427 which
has already been merged.

Notes:
  * Creates containers in parallel.
  * Improves flexability in container create as a specific group or container
    can be targeted on the CLI.
  * Syntax clean up.
  * Adds option to specify the container volume group name.
  * Removes the ""ignored"" failure note when running in an environment that does
    not use LVM and have an LXC volume group.

Closes-Bug: #1399427
Change-Id: I4270a9d11039b62d631f82d24de7cc87d5f142c9
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/42/139242/1 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/roles/container_create/tasks/container_create.yml', 'rpc_deployment/playbooks/setup/build-containers.yml', 'rpc_deployment/roles/container_create/tasks/main.yml']",3,75a50e8d511d722d5281172ca2730a6d7bef78d8,bug/1399427,, when: container_groups|length > 0,13,14
openstack%2Fnova~master~I87ef651383c9b4ab3abe4bf8a5c49501e353abc4,openstack/nova,master,I87ef651383c9b4ab3abe4bf8a5c49501e353abc4,virt: pass instance object to block_stats & get_instance_disk_info,MERGED,2014-12-10 15:06:18.000000000,2014-12-18 12:54:12.000000000,2014-12-18 12:54:08.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/57780cbf8c6c18c911ee75b23a1f3ed621c20ecb', 'message': 'virt: pass instance object to block_stats & get_instance_disk_info\n\nThe block_stats and get_instance_disk_info methods are the last\ntwo virt driver methods which do not take a full Nova Instance\nobject. They are trivially convertable.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I87ef651383c9b4ab3abe4bf8a5c49501e353abc4\n'}, {'number': 2, 'created': '2014-12-10 17:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/004bf00d1f29aa3954f5dcab32bbea7a8aa02263', 'message': 'virt: pass instance object to block_stats & get_instance_disk_info\n\nThe block_stats and get_instance_disk_info methods are the last\ntwo virt driver methods which do not take a full Nova Instance\nobject. They are trivially convertable.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I87ef651383c9b4ab3abe4bf8a5c49501e353abc4\n'}, {'number': 3, 'created': '2014-12-16 12:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4e711351c98688369ea50d57c2261aa0d85c069', 'message': 'virt: pass instance object to block_stats & get_instance_disk_info\n\nThe block_stats and get_instance_disk_info methods are the last\ntwo virt driver methods which do not take a full Nova Instance\nobject. They are trivially convertable.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I87ef651383c9b4ab3abe4bf8a5c49501e353abc4\n'}, {'number': 4, 'created': '2014-12-17 11:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/319c2f0d2d39a1866b14e2edc8befdac2019fbef', 'message': 'virt: pass instance object to block_stats & get_instance_disk_info\n\nThe block_stats and get_instance_disk_info methods are the last\ntwo virt driver methods which do not take a full Nova Instance\nobject. They are trivially convertable.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I87ef651383c9b4ab3abe4bf8a5c49501e353abc4\n'}, {'number': 5, 'created': '2014-12-17 15:47:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a87a995eef65ad8c2c15320958a896ae75026f5e', 'message': 'virt: pass instance object to block_stats & get_instance_disk_info\n\nThe block_stats and get_instance_disk_info methods are the last\ntwo virt driver methods which do not take a full Nova Instance\nobject. They are trivially convertable.\n\nNOTE(mriedem): updating commit message to pull from gate queue\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I87ef651383c9b4ab3abe4bf8a5c49501e353abc4\n'}, {'number': 6, 'created': '2014-12-17 15:48:13.000000000', 'files': ['nova/virt/hyperv/driver.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/driver.py', 'nova/virt/fake.py', 'nova/virt/vmwareapi/driver.py', 'nova/tests/unit/compute/test_compute.py', 'nova/virt/driver.py', 'nova/compute/manager.py', 'nova/tests/unit/virt/test_virt_drivers.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9b29237cbe09db54fe4dd78eb34e32b954636552', 'message': 'virt: pass instance object to block_stats & get_instance_disk_info\n\nThe block_stats and get_instance_disk_info methods are the last\ntwo virt driver methods which do not take a full Nova Instance\nobject. They are trivially convertable.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I87ef651383c9b4ab3abe4bf8a5c49501e353abc4\n'}]",0,140713,9b29237cbe09db54fe4dd78eb34e32b954636552,62,13,6,1779,,,0,"virt: pass instance object to block_stats & get_instance_disk_info

The block_stats and get_instance_disk_info methods are the last
two virt driver methods which do not take a full Nova Instance
object. They are trivially convertable.

Blueprint: libvirt-driver-class-refactor
Change-Id: I87ef651383c9b4ab3abe4bf8a5c49501e353abc4
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/140713/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/driver.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/driver.py', 'nova/virt/fake.py', 'nova/virt/vmwareapi/driver.py', 'nova/tests/unit/compute/test_compute.py', 'nova/virt/driver.py', 'nova/compute/manager.py', 'nova/tests/unit/virt/test_virt_drivers.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",10,57780cbf8c6c18c911ee75b23a1f3ed621c20ecb,bp/libvirt-driver-class-refactor," conn.get_instance_disk_info(instance, instance = objects.Instance(**self.test_instance) instance, mock_get.assert_called_once_with(instance) instance = objects.Instance(**self.test_instance) if instance_name == instance.name: info = conn.get_instance_disk_info(instance) instance = objects.Instance(**self.test_instance) if instance_name == instance.name: info = conn.get_instance_disk_info(instance, mock_get_disk_info.assert_called_once_with(instance, instance = self._create_instance() instance)"," conn.get_instance_disk_info(instance[""name""], {'name': 'instance_name'}, mock_get.assert_called_once_with('instance_name') instance_ref = objects.Instance(**self.test_instance) if instance_name == instance_ref['name']: info = conn.get_instance_disk_info(instance_ref['name']) instance_ref = objects.Instance(**self.test_instance) if instance_name == instance_ref['name']: info = conn.get_instance_disk_info(instance_ref['name'], mock_get_disk_info.assert_called_once_with(instance.name, instance_name = ""fake-instance-name"" instance_name)",41,41
openstack%2Fhorizon~master~I02454508080efe8c79fac4cfebe83585b75121ac,openstack/horizon,master,I02454508080efe8c79fac4cfebe83585b75121ac,Updated from global requirements,MERGED,2014-12-18 10:14:50.000000000,2014-12-18 12:53:57.000000000,2014-12-18 12:53:55.000000000,"[{'_account_id': 3}, {'_account_id': 6914}, {'_account_id': 9317}]","[{'number': 1, 'created': '2014-12-18 10:14:50.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f0ce19f654ad5972750225664efddf1ca8aaffba', 'message': 'Updated from global requirements\n\nChange-Id: I02454508080efe8c79fac4cfebe83585b75121ac\n'}]",0,142713,f0ce19f654ad5972750225664efddf1ca8aaffba,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I02454508080efe8c79fac4cfebe83585b75121ac
",git fetch https://review.opendev.org/openstack/horizon refs/changes/13/142713/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f0ce19f654ad5972750225664efddf1ca8aaffba,openstack/requirements,pytz>=2013.6,pytz,1,1
openstack%2Fhorizon~master~I3f57ece2656a0131982ad9d9fe16131a502741a0,openstack/horizon,master,I3f57ece2656a0131982ad9d9fe16131a502741a0,Updated description of update user form,MERGED,2014-12-17 05:43:02.000000000,2014-12-18 12:53:45.000000000,2014-12-18 12:53:43.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 7012}, {'_account_id': 9317}, {'_account_id': 11592}, {'_account_id': 12030}, {'_account_id': 14124}]","[{'number': 1, 'created': '2014-12-17 05:43:02.000000000', 'files': ['openstack_dashboard/dashboards/identity/users/templates/users/_update.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1c0a3ab328fd9feff99d85604e3464697bc5a3db', 'message': 'Updated description of update user form\n\nThe update user form does not allow to change the role\nof the user. So, removed it from the description of the\nupdate user form.\n\nChange-Id: I3f57ece2656a0131982ad9d9fe16131a502741a0\nCloses-bug: #1401822\n'}]",0,142349,1c0a3ab328fd9feff99d85604e3464697bc5a3db,13,7,1,12030,,,0,"Updated description of update user form

The update user form does not allow to change the role
of the user. So, removed it from the description of the
update user form.

Change-Id: I3f57ece2656a0131982ad9d9fe16131a502741a0
Closes-bug: #1401822
",git fetch https://review.opendev.org/openstack/horizon refs/changes/49/142349/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/identity/users/templates/users/_update.html'],1,1c0a3ab328fd9feff99d85604e3464697bc5a3db,bug/1401822," <p>{% trans ""Edit the user's details, including the Primary Project."" %}</p>"," <p>{% trans ""Edit the user's details, including the Primary Project and Role."" %}</p>",1,1
openstack%2Fheat~master~Ic2c92d4b044f725b43242ae32282d45ef770793b,openstack/heat,master,Ic2c92d4b044f725b43242ae32282d45ef770793b,Imported Translations from Transifex,MERGED,2014-12-10 06:00:55.000000000,2014-12-18 12:53:27.000000000,2014-12-18 12:53:25.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-10 06:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d07712eaa787d9a5b32461f790614c6f75e10ff2', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic2c92d4b044f725b43242ae32282d45ef770793b\n'}, {'number': 2, 'created': '2014-12-11 06:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/40b0c81292a2626f261c3f987b34808659929d49', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic2c92d4b044f725b43242ae32282d45ef770793b\n'}, {'number': 3, 'created': '2014-12-12 06:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f4e16b6890e3ac7c66fc0fbfdf464e3bff11063f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic2c92d4b044f725b43242ae32282d45ef770793b\n'}, {'number': 4, 'created': '2014-12-13 06:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1effb2956165daba1903d596fb36dff2ec90b3df', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic2c92d4b044f725b43242ae32282d45ef770793b\n'}, {'number': 5, 'created': '2014-12-14 06:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1cb9cceef4c58fc3c3fee34cc83bd1379d847583', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic2c92d4b044f725b43242ae32282d45ef770793b\n'}, {'number': 6, 'created': '2014-12-15 06:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/27bf1a1c95c63fefd0b3dbd5452ae37a3126fd67', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic2c92d4b044f725b43242ae32282d45ef770793b\n'}, {'number': 7, 'created': '2014-12-16 06:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3260f3bcbab8d8cf1012315aa43cb35c42c2840d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic2c92d4b044f725b43242ae32282d45ef770793b\n'}, {'number': 8, 'created': '2014-12-17 06:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/27a3a9dd1f6d1a72649f6b0f249c0f7331b634fe', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic2c92d4b044f725b43242ae32282d45ef770793b\n'}, {'number': 9, 'created': '2014-12-18 06:04:41.000000000', 'files': ['heat/locale/ko_KR/LC_MESSAGES/heat-log-error.po', 'heat/locale/pt_BR/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat.pot', 'heat/locale/fr/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat-log-info.pot', 'heat/locale/es/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat-log-error.pot', 'heat/locale/de/LC_MESSAGES/heat-log-error.po', 'heat/locale/fr/LC_MESSAGES/heat-log-info.po', 'heat/locale/es/LC_MESSAGES/heat-log-info.po'], 'web_link': 'https://opendev.org/openstack/heat/commit/b38c25e16a0c7fca3e28b8146d08c165bc7ef983', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic2c92d4b044f725b43242ae32282d45ef770793b\n'}]",0,140579,b38c25e16a0c7fca3e28b8146d08c165bc7ef983,41,6,9,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ic2c92d4b044f725b43242ae32282d45ef770793b
",git fetch https://review.opendev.org/openstack/heat refs/changes/79/140579/6 && git format-patch -1 --stdout FETCH_HEAD,"['heat/locale/heat.pot', 'heat/locale/heat-log-info.pot', 'heat/locale/fr/LC_MESSAGES/heat-log-info.po', 'heat/locale/es/LC_MESSAGES/heat-log-info.po']",4,d07712eaa787d9a5b32461f790614c6f75e10ff2,transifex/translations,"""POT-Creation-Date: 2014-12-10 06:00+0000\n"" ""PO-Revision-Date: 2014-12-09 11:24+0000\n""#: heat/engine/stack.py:906#: heat/engine/stack.py:914msgid ""Tried to store a stack that does not exist %s""#: heat/engine/stack.py:999 heat/engine/stack.py:1011#: heat/engine/stack.py:1027#: heat/engine/stack.py:1048#: heat/engine/stack_resource.py:269#: heat/engine/resources/eip.py:107 heat/engine/resources/eip.py:121#: heat/engine/resources/aws/scaling_policy.py:119#: heat/engine/resources/loadbalancer.py:440#: heat/engine/resources/server.py:989#: heat/engine/resources/swiftsignal.py:249 #: heat/engine/resources/wait_condition.py:368#: heat/engine/resources/swiftsignal.py:256 #: heat/engine/resources/wait_condition.py:373#: heat/engine/resources/wait_condition.py:360#: heat/engine/resources/aws/scaling_policy.py:125 #: heat/engine/resources/openstack/scaling_policy.py:134#: heat/engine/resources/aws/scaling_policy.py:139 #: heat/engine/resources/openstack/scaling_policy.py:148#: heat/engine/resources/openstack/scaling_policy.py:128","""POT-Creation-Date: 2014-12-08 06:00+0000\n"" ""PO-Revision-Date: 2014-12-05 16:21+0000\n""#: heat/engine/stack.py:965#: heat/engine/stack.py:974msgid ""Tried to store a stack that does not exist %s ""#: heat/engine/stack.py:991 heat/engine/stack.py:1003#: heat/engine/stack.py:1019#: heat/engine/stack.py:1040#: heat/engine/stack_resource.py:257#: heat/engine/resources/eip.py:106 heat/engine/resources/eip.py:120#: heat/engine/resources/aws/scaling_policy.py:118#: heat/engine/resources/loadbalancer.py:439#: heat/engine/resources/server.py:984#: heat/engine/resources/swiftsignal.py:248 #: heat/engine/resources/wait_condition.py:367#: heat/engine/resources/swiftsignal.py:255 #: heat/engine/resources/wait_condition.py:372#: heat/engine/resources/wait_condition.py:359#: heat/engine/resources/aws/scaling_policy.py:124 #: heat/engine/resources/openstack/scaling_policy.py:133#: heat/engine/resources/aws/scaling_policy.py:138 #: heat/engine/resources/openstack/scaling_policy.py:147#: heat/engine/resources/openstack/scaling_policy.py:127",213,208
openstack%2Ftempest~master~I8d42d73464a94f5229ff7065404bbf3b402c75c7,openstack/tempest,master,I8d42d73464a94f5229ff7065404bbf3b402c75c7,"Add a word ""Test"" to metering test classes",MERGED,2014-12-09 02:18:48.000000000,2014-12-18 12:48:54.000000000,2014-12-18 12:48:53.000000000,"[{'_account_id': 3}, {'_account_id': 5174}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7249}, {'_account_id': 8556}, {'_account_id': 8859}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 02:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9bc396fa855ab75c257ea3f9d1700dc979af07b4', 'message': 'Add a word ""Test"" to metering test classes\n\nAll test class except metering test classes contains ""Test"" in their\nnames. This patch adds the word to metering test classes for clarifying\nthe test classes.\n\nChange-Id: I8d42d73464a94f5229ff7065404bbf3b402c75c7\n'}, {'number': 2, 'created': '2014-12-18 04:18:33.000000000', 'files': ['tempest/api/network/test_metering_extensions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/eb6af63b79113ad212809caacafab5211d4b3b8b', 'message': 'Add a word ""Test"" to metering test classes\n\nAll test class except metering test classes contains ""Test"" in their\nnames. This patch adds the word to metering test classes for clarifying\nthe test classes.\n\nChange-Id: I8d42d73464a94f5229ff7065404bbf3b402c75c7\n'}]",0,140203,eb6af63b79113ad212809caacafab5211d4b3b8b,21,8,2,6167,,,0,"Add a word ""Test"" to metering test classes

All test class except metering test classes contains ""Test"" in their
names. This patch adds the word to metering test classes for clarifying
the test classes.

Change-Id: I8d42d73464a94f5229ff7065404bbf3b402c75c7
",git fetch https://review.opendev.org/openstack/tempest refs/changes/03/140203/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_metering_extensions.py'],1,9bc396fa855ab75c257ea3f9d1700dc979af07b4,cleanup,"class MeteringTestJSON(base.BaseAdminNetworkTest): super(MeteringTestJSON, cls).resource_setup()class MeteringIpV6TestJSON(MeteringTestJSON):","class MeteringJSON(base.BaseAdminNetworkTest): super(MeteringJSON, cls).resource_setup()class MeteringIpV6JSON(MeteringJSON):",3,3
openstack%2Ffuel-main~stable%2F6.0~I28b4b5b16cbab1efddccb3ce414edc04c8f42f11,openstack/fuel-main,stable/6.0,I28b4b5b16cbab1efddccb3ce414edc04c8f42f11,Change the way how ntp placed in master node,ABANDONED,2014-12-16 17:52:02.000000000,2014-12-18 12:41:50.000000000,,"[{'_account_id': 8971}, {'_account_id': 11827}]","[{'number': 1, 'created': '2014-12-16 17:52:02.000000000', 'files': ['iso/ks.template'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5acf237b6088db37678cb59c73f77e5fe72db691', 'message': 'Change the way how ntp placed in master node\n\nChange-Id: I28b4b5b16cbab1efddccb3ce414edc04c8f42f11\n'}]",0,142170,5acf237b6088db37678cb59c73f77e5fe72db691,5,2,1,11827,,,0,"Change the way how ntp placed in master node

Change-Id: I28b4b5b16cbab1efddccb3ce414edc04c8f42f11
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/70/142170/1 && git format-patch -1 --stdout FETCH_HEAD,['iso/ks.template'],1,5acf237b6088db37678cb59c73f77e5fe72db691,6.0,sed -i '$ a server 127.127.1.0\nfudge 127.127.1.0 stratum 10\ntos orphan 7' /etc/ntp.conf,"echo ""server 127.127.1.0"" >> /etc/ntp.conf echo ""fudge 127.127.1.0 stratum 10"" >> /etc/ntp.conf echo ""tos orphan 7"" >> /etc/ntp.conf",1,3
openstack%2Fglance~stable%2Fjuno~I72dbead3cb2dcb87f52658ddb880e26880cc229b,openstack/glance,stable/juno,I72dbead3cb2dcb87f52658ddb880e26880cc229b,To prevent client use v2 patch api to handle file and swift location,MERGED,2014-12-17 07:36:34.000000000,2014-12-18 12:40:45.000000000,2014-12-18 12:40:42.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 8158}, {'_account_id': 9311}]","[{'number': 1, 'created': '2014-12-17 07:36:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/93c01ec1581095f1159ad59436e07d7691cff013', 'message': 'To prevent client use v2 patch api to handle file and swift location\n\nThe change will be used to restrict client to download and delete any\nfile in glance-api server. The same resone and logic as what we did in\nv1:\nhttps://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429\n\nCloses-Bug: bug/1400966\nDocImpact\n\nNote: Even this change could fully resolve the problem for Glance, but\nwe still need to fix this issue from glance_store perspective\nseparatelly due to other projects can use the lib directly.\n\nConflicts:\n\tglance/api/v1/images.py\n\tglance/location.py\n\tglance/tests/functional/v2/test_images.py\n\tglance/tests/unit/test_store_location.py\n\tglance/tests/unit/v1/test_api.py\n\n(cherry-picked from 4afdb017aa1ccef01482f117cb8d0736a6da38ed)\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\nChange-Id: I72dbead3cb2dcb87f52658ddb880e26880cc229b\n'}, {'number': 2, 'created': '2014-12-17 07:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a3a3b4ddc9c0a18829cd2d31f64ead86c03e07ed', 'message': 'To prevent client use v2 patch api to handle file and swift location\n\nThe change will be used to restrict client to download and delete any\nfile in glance-api server. The same resone and logic as what we did in\nv1:\nhttps://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429\n\nCloses-Bug: bug/1400966\nDocImpact\n\nNote: Even this change could fully resolve the problem for Glance, but\nwe still need to fix this issue from glance_store perspective\nseparatelly due to other projects can use the lib directly.\n\nConflicts:\n\tglance/api/v1/images.py\n\tglance/location.py\n\tglance/tests/functional/v2/test_images.py\n\tglance/tests/unit/test_store_location.py\n\tglance/tests/unit/v1/test_api.py\n\n(cherry-picked from 4afdb017aa1ccef01482f117cb8d0736a6da38ed)\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\nChange-Id: I72dbead3cb2dcb87f52658ddb880e26880cc229b\n'}, {'number': 3, 'created': '2014-12-17 07:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/dc753a15ed1dfdc50d0ad1e99c7228e77e9493bf', 'message': 'To prevent client use v2 patch api to handle file and swift location\n\nThe change will be used to restrict client to download and delete any\nfile in glance-api server. The same resone and logic as what we did in\nv1:\nhttps://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429\n\nCloses-Bug: bug/1400966\nDocImpact\n\nNote: Even this change could fully resolve the problem for Glance, but\nwe still need to fix this issue from glance_store perspective\nseparatelly due to other projects can use the lib directly.\n\nConflicts:\n\tglance/api/v1/images.py\n\tglance/location.py\n\tglance/tests/functional/v2/test_images.py\n\tglance/tests/unit/test_store_location.py\n\tglance/tests/unit/v1/test_api.py\n\n(cherry-picked from 4afdb017aa1ccef01482f117cb8d0736a6da38ed)\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\nChange-Id: I72dbead3cb2dcb87f52658ddb880e26880cc229b\n'}, {'number': 4, 'created': '2014-12-17 07:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0554cbcbb59f08f34f4c4a11e678c0ccf585c546', 'message': 'To prevent client use v2 patch api to handle file and swift location\n\nThe change will be used to restrict client to download and delete any\nfile in glance-api server. The same resone and logic as what we did in\nv1:\nhttps://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429\n\nCloses-Bug: bug/1400966\nDocImpact\n\nNote: Even this change could fully resolve the problem for Glance, but\nwe still need to fix this issue from glance_store perspective\nseparatelly due to other projects can use the lib directly.\n\nConflicts:\n\tglance/api/v1/images.py\n\tglance/location.py\n\tglance/tests/functional/v2/test_images.py\n\tglance/tests/unit/test_store_location.py\n\tglance/tests/unit/v1/test_api.py\n\n(cherry-picked from 4afdb017aa1ccef01482f117cb8d0736a6da38ed)\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\nChange-Id: I72dbead3cb2dcb87f52658ddb880e26880cc229b\n'}, {'number': 5, 'created': '2014-12-17 09:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6b02cb17a6cf654f08e63a50228c8e619f8ce693', 'message': 'To prevent client use v2 patch api to handle file and swift location\n\nThe change will be used to restrict client to download and delete any\nfile in glance-api server. The same resone and logic as what we did in\nv1:\nhttps://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429\n\nCloses-Bug: bug/1400966\nDocImpact\n\nNote: Even this change could fully resolve the problem for Glance, but\nwe still need to fix this issue from glance_store perspective\nseparatelly due to other projects can use the lib directly.\n\nConflicts:\n\tglance/api/v1/images.py\n\tglance/location.py\n\tglance/tests/functional/v2/test_images.py\n\tglance/tests/unit/test_store_location.py\n\tglance/tests/unit/v1/test_api.py\n\n(cherry-picked from 4afdb017aa1ccef01482f117cb8d0736a6da38ed)\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\nChange-Id: I72dbead3cb2dcb87f52658ddb880e26880cc229b\n'}, {'number': 6, 'created': '2014-12-18 05:54:13.000000000', 'files': ['glance/location.py', 'glance/tests/functional/v1/test_copy_to_file.py', 'glance/tests/functional/v2/test_images.py', 'glance/tests/unit/test_store_location.py', 'glance/tests/unit/utils.py', 'glance/tests/unit/v1/test_api.py', 'glance/api/v1/images.py', 'glance/common/store_utils.py', 'glance/tests/unit/test_store_image.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/d9a928eac360add67477e29f516af868adfe0d5e', 'message': 'To prevent client use v2 patch api to handle file and swift location\n\nThe change will be used to restrict client to download and delete any\nfile in glance-api server. The same resone and logic as what we did in\nv1:\nhttps://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429\n\nCloses-Bug: bug/1400966\nDocImpact\n\nNote: Even this change could fully resolve the problem for Glance, but\nwe still need to fix this issue from glance_store perspective\nseparatelly due to other projects can use the lib directly.\n\nConflicts:\n\tglance/api/v1/images.py\n\tglance/location.py\n\tglance/tests/functional/v2/test_images.py\n\tglance/tests/unit/test_store_location.py\n\tglance/tests/unit/v1/test_api.py\n\n(cherry-picked from 4afdb017aa1ccef01482f117cb8d0736a6da38ed)\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\nChange-Id: I72dbead3cb2dcb87f52658ddb880e26880cc229b\n'}]",1,142373,d9a928eac360add67477e29f516af868adfe0d5e,21,6,6,6159,,,0,"To prevent client use v2 patch api to handle file and swift location

The change will be used to restrict client to download and delete any
file in glance-api server. The same resone and logic as what we did in
v1:
https://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429

Closes-Bug: bug/1400966
DocImpact

Note: Even this change could fully resolve the problem for Glance, but
we still need to fix this issue from glance_store perspective
separatelly due to other projects can use the lib directly.

Conflicts:
	glance/api/v1/images.py
	glance/location.py
	glance/tests/functional/v2/test_images.py
	glance/tests/unit/test_store_location.py
	glance/tests/unit/v1/test_api.py

(cherry-picked from 4afdb017aa1ccef01482f117cb8d0736a6da38ed)
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
Change-Id: I72dbead3cb2dcb87f52658ddb880e26880cc229b
",git fetch https://review.opendev.org/openstack/glance refs/changes/73/142373/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/location.py', 'glance/tests/functional/v2/test_images.py', 'glance/db/simple/.ropeproject/config.py', 'glance/tests/unit/v1/test_api.py', 'glance/common/store_utils.py', 'glance/db/simple/.ropeproject/objectdb', 'glance/db/simple/.ropeproject/globalnames', 'glance/tests/unit/test_store_image.py', 'glance/tests/functional/v1/test_copy_to_file.py', 'glance/db/simple/.ropeproject/history', 'glance/tests/unit/test_store_location.py', 'glance/tests/unit/utils.py', 'glance/api/v1/images.py', 'glance/tests/unit/v2/test_images_resource.py.orig', 'glance/tests/functional/v2/#test_images.py#']",15,93c01ec1581095f1159ad59436e07d7691cff013,,"# Copyright 2012 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import BaseHTTPServer import os import signal import tempfile import uuid from oslo.serialization import jsonutils import requests import six from glance.tests import functional TENANT1 = str(uuid.uuid4()) TENANT2 = str(uuid.uuid4()) TENANT3 = str(uuid.uuid4()) TENANT4 = str(uuid.uuid4()) def get_handler_class(fixture): class StaticHTTPRequestHandler(BaseHTTPServer.BaseHTTPRequestHandler): def do_GET(self): self.send_response(200) self.send_header('Content-Length', str(len(fixture))) self.end_headers() self.wfile.write(fixture) return def do_HEAD(self): self.send_response(200) self.send_header('Content-Length', str(len(fixture))) self.end_headers() return def log_message(*args, **kwargs): # Override this method to prevent debug output from going # to stderr during testing return return StaticHTTPRequestHandler def http_server(image_id, image_data): server_address = ('127.0.0.1', 0) handler_class = get_handler_class(image_data) httpd = BaseHTTPServer.HTTPServer(server_address, handler_class) port = httpd.socket.getsockname()[1] pid = os.fork() if pid == 0: httpd.serve_forever() else: return pid, port class TestImages(functional.FunctionalTest): def setUp(self): super(TestImages, self).setUp() self.cleanup() self.api_server.deployment_flavor = 'noauth' self.api_server.data_api = 'glance.db.sqlalchemy.api' def _url(self, path): return 'http://127.0.0.1:%d%s' % (self.api_port, path) def _headers(self, custom_headers=None): base_headers = { 'X-Identity-Status': 'Confirmed', 'X-Auth-Token': '932c5c84-02ac-4fe5-a9ba-620af0e2bb96', 'X-User-Id': 'f9a41d13-0c13-47e9-bee2-ce4e8bfe958e', 'X-Tenant-Id': TENANT1, 'X-Roles': 'member', } base_headers.update(custom_headers or {}) return base_headers def test_image_lifecycle(self): # Image list should be empty self.start_servers(**self.__dict__.copy()) path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # Create an image (with two deployer-defined properties) path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) data = jsonutils.dumps({'name': 'image-1', 'type': 'kernel', 'foo': 'bar', 'disk_format': 'aki', 'container_format': 'aki', 'abc': 'xyz'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image_location_header = response.headers['Location'] # Returned image entity should have a generated id and status image = jsonutils.loads(response.text) image_id = image['id'] checked_keys = set([ u'status', u'name', u'tags', u'created_at', u'updated_at', u'visibility', u'self', u'protected', u'id', u'file', u'min_disk', u'foo', u'abc', u'type', u'min_ram', u'schema', u'disk_format', u'container_format', u'owner', u'checksum', u'size', u'virtual_size', ]) self.assertEqual(checked_keys, set(image.keys())) expected_image = { 'status': 'queued', 'name': 'image-1', 'tags': [], 'visibility': 'private', 'self': '/v2/images/%s' % image_id, 'protected': False, 'file': '/v2/images/%s/file' % image_id, 'min_disk': 0, 'foo': 'bar', 'abc': 'xyz', 'type': 'kernel', 'min_ram': 0, 'schema': '/v2/schemas/image', } for key, value in expected_image.items(): self.assertEqual(value, image[key], key) # Image list should now have one entry path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(1, len(images)) self.assertEqual(image_id, images[0]['id']) # Create another image (with two deployer-defined properties) path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) data = jsonutils.dumps({'name': 'image-2', 'type': 'kernel', 'bar': 'foo', 'disk_format': 'aki', 'container_format': 'aki', 'xyz': 'abc'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Returned image entity should have a generated id and status image = jsonutils.loads(response.text) image2_id = image['id'] checked_keys = set([ u'status', u'name', u'tags', u'created_at', u'updated_at', u'visibility', u'self', u'protected', u'id', u'file', u'min_disk', u'bar', u'xyz', u'type', u'min_ram', u'schema', u'disk_format', u'container_format', u'owner', u'checksum', u'size', u'virtual_size', ]) self.assertEqual(checked_keys, set(image.keys())) expected_image = { 'status': 'queued', 'name': 'image-2', 'tags': [], 'visibility': 'private', 'self': '/v2/images/%s' % image2_id, 'protected': False, 'file': '/v2/images/%s/file' % image2_id, 'min_disk': 0, 'bar': 'foo', 'xyz': 'abc', 'type': 'kernel', 'min_ram': 0, 'schema': '/v2/schemas/image', } for key, value in expected_image.items(): self.assertEqual(value, image[key], key) # Image list should now have two entries path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(2, len(images)) self.assertEqual(image2_id, images[0]['id']) self.assertEqual(image_id, images[1]['id']) # Image list should list only image-2 as image-1 doesn't contain the # property 'bar' path = self._url('/v2/images?bar=foo') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(1, len(images)) self.assertEqual(image2_id, images[0]['id']) # Image list should list only image-1 as image-2 doesn't contain the # property 'foo' path = self._url('/v2/images?foo=bar') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(1, len(images)) self.assertEqual(image_id, images[0]['id']) # The ""changes-since"" filter shouldn't work on glance v2 path = self._url('/v2/images?changes-since=20001007T10:10:10') response = requests.get(path, headers=self._headers()) self.assertEqual(400, response.status_code) path = self._url('/v2/images?changes-since=aaa') response = requests.get(path, headers=self._headers()) self.assertEqual(400, response.status_code) # Image list should list only image-1 based on the filter # 'foo=bar&abc=xyz' path = self._url('/v2/images?foo=bar&abc=xyz') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(1, len(images)) self.assertEqual(image_id, images[0]['id']) # Image list should list only image-2 based on the filter # 'bar=foo&xyz=abc' path = self._url('/v2/images?bar=foo&xyz=abc') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(1, len(images)) self.assertEqual(image2_id, images[0]['id']) # Image list should not list anything as the filter 'foo=baz&abc=xyz' # is not satisfied by either images path = self._url('/v2/images?foo=baz&abc=xyz') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # Get the image using the returned Location header response = requests.get(image_location_header, headers=self._headers()) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertEqual(image_id, image['id']) self.assertIsNone(image['checksum']) self.assertIsNone(image['size']) self.assertIsNone(image['virtual_size']) self.assertEqual('bar', image['foo']) self.assertFalse(image['protected']) self.assertEqual('kernel', image['type']) self.assertTrue(image['created_at']) self.assertTrue(image['updated_at']) self.assertEqual(image['updated_at'], image['created_at']) # The image should be mutable, including adding and removing properties path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) data = jsonutils.dumps([ {'op': 'replace', 'path': '/name', 'value': 'image-2'}, {'op': 'replace', 'path': '/disk_format', 'value': 'vhd'}, {'op': 'replace', 'path': '/container_format', 'value': 'ami'}, {'op': 'replace', 'path': '/foo', 'value': 'baz'}, {'op': 'add', 'path': '/ping', 'value': 'pong'}, {'op': 'replace', 'path': '/protected', 'value': True}, {'op': 'remove', 'path': '/type'}, ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) # Returned image entity should reflect the changes image = jsonutils.loads(response.text) self.assertEqual('image-2', image['name']) self.assertEqual('vhd', image['disk_format']) self.assertEqual('baz', image['foo']) self.assertEqual('pong', image['ping']) self.assertTrue(image['protected']) self.assertFalse('type' in image, response.text) # Adding 11 image properties should fail since configured limit is 10 path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) changes = [] for i in range(11): changes.append({'op': 'add', 'path': '/ping%i' % i, 'value': 'pong'}) data = jsonutils.dumps(changes) response = requests.patch(path, headers=headers, data=data) self.assertEqual(413, response.status_code, response.text) # Adding 3 image locations should fail since configured limit is 2 for i in range(3): file_path = os.path.join(self.test_dir, 'fake_image_%i' % i) with open(file_path, 'w') as fap: fap.write('glance') path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) changes = [] for i in range(3): changes.append({'op': 'add', 'path': '/locations/-', 'value': {'url': 'file://{0}'.format( os.path.join(self.test_dir, 'fake_image_%i' % i)), 'metadata': {}}, }) data = jsonutils.dumps(changes) response = requests.patch(path, headers=headers, data=data) self.assertEqual(413, response.status_code, response.text) # Ensure the v2.0 json-patch content type is accepted path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.0-json-patch' headers = self._headers({'content-type': media_type}) data = jsonutils.dumps([{'add': '/ding', 'value': 'dong'}]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) # Returned image entity should reflect the changes image = jsonutils.loads(response.text) self.assertEqual('dong', image['ding']) # Updates should persist across requests path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertEqual(image_id, image['id']) self.assertEqual('image-2', image['name']) self.assertEqual('baz', image['foo']) self.assertEqual('pong', image['ping']) self.assertTrue(image['protected']) self.assertFalse('type' in image, response.text) # Try to download data before its uploaded path = self._url('/v2/images/%s/file' % image_id) headers = self._headers() response = requests.get(path, headers=headers) self.assertEqual(204, response.status_code) def _verify_image_checksum_and_status(checksum, status): # Checksum should be populated and status should be active path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertEqual(checksum, image['checksum']) self.assertEqual(status, image['status']) # Upload some image data path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.put(path, headers=headers, data='ZZZZZ') self.assertEqual(204, response.status_code) expected_checksum = '8f113e38d28a79a5a451b16048cc2b72' _verify_image_checksum_and_status(expected_checksum, 'active') # `disk_format` and `container_format` cannot # be replaced when the image is active. immutable_paths = ['/disk_format', '/container_format'] media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) path = self._url('/v2/images/%s' % image_id) for immutable_path in immutable_paths: data = jsonutils.dumps([ {'op': 'replace', 'path': immutable_path, 'value': 'ari'}, ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(403, response.status_code) # Try to download the data that was just uploaded path = self._url('/v2/images/%s/file' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) self.assertEqual(expected_checksum, response.headers['Content-MD5']) self.assertEqual('ZZZZZ', response.text) # Uploading duplicate data should be rejected with a 409. The # original data should remain untouched. path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.put(path, headers=headers, data='XXX') self.assertEqual(409, response.status_code) _verify_image_checksum_and_status(expected_checksum, 'active') # Ensure the size is updated to reflect the data uploaded path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) self.assertEqual(5, jsonutils.loads(response.text)['size']) # Deletion should not work on protected images path = self._url('/v2/images/%s' % image_id) response = requests.delete(path, headers=self._headers()) self.assertEqual(403, response.status_code) # Unprotect image for deletion path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) doc = [{'op': 'replace', 'path': '/protected', 'value': False}] data = jsonutils.dumps(doc) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) # Remove all locations of the image then the image size shouldn't be # able to access path = self._url('/v2/images/%s' % image2_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) doc = [{'op': 'replace', 'path': '/locations', 'value': []}] data = jsonutils.dumps(doc) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) image = jsonutils.loads(response.text) self.assertIsNone(image['size']) self.assertIsNone(image['virtual_size']) self.assertEqual('queued', image['status']) # Deletion should work. Deleting image-1 path = self._url('/v2/images/%s' % image_id) response = requests.delete(path, headers=self._headers()) self.assertEqual(204, response.status_code) # This image should be no longer be directly accessible path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(404, response.status_code) # And neither should its data path = self._url('/v2/images/%s/file' % image_id) headers = self._headers() response = requests.get(path, headers=headers) self.assertEqual(404, response.status_code) # Image list should now contain just image-2 path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(1, len(images)) self.assertEqual(image2_id, images[0]['id']) # Deleting image-2 should work path = self._url('/v2/images/%s' % image2_id) response = requests.delete(path, headers=self._headers()) self.assertEqual(204, response.status_code) # Image list should now be empty path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) self.stop_servers() def test_download_random_access(self): self.start_servers(**self.__dict__.copy()) # Create another image (with two deployer-defined properties) path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) data = jsonutils.dumps({'name': 'image-2', 'type': 'kernel', 'bar': 'foo', 'disk_format': 'aki', 'container_format': 'aki', 'xyz': 'abc'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] # Upload data to image image_data = 'Z' * 15 path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.put(path, headers=headers, data=image_data) self.assertEqual(204, response.status_code) result_body = '' for x in range(15): # NOTE(flaper87): Read just 1 byte. Content-Range is # 0-indexed and it specifies the first byte to read # and the last byte to read. content_range = 'bytes %s-%s/15' % (x, x) headers = self._headers({'Content-Range': content_range}) path = self._url('/v2/images/%s/file' % image_id) response = requests.get(path, headers=headers) result_body += response.text self.assertEqual(result_body, image_data) self.stop_servers() def test_download_policy_when_cache_is_not_enabled(self): rules = {'context_is_admin': 'role:admin', 'default': '', 'download_image': '!'} self.set_policy_rules(rules) self.start_servers(**self.__dict__.copy()) # Create an image path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'member'}) data = jsonutils.dumps({'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Returned image entity image = jsonutils.loads(response.text) image_id = image['id'] expected_image = { 'status': 'queued', 'name': 'image-1', 'tags': [], 'visibility': 'private', 'self': '/v2/images/%s' % image_id, 'protected': False, 'file': '/v2/images/%s/file' % image_id, 'min_disk': 0, 'min_ram': 0, 'schema': '/v2/schemas/image', } for key, value in six.iteritems(expected_image): self.assertEqual(value, image[key], key) # Upload data to image path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.put(path, headers=headers, data='ZZZZZ') self.assertEqual(204, response.status_code) # Get an image should fail path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.get(path, headers=headers) self.assertEqual(403, response.status_code) # Image Deletion should work path = self._url('/v2/images/%s' % image_id) response = requests.delete(path, headers=self._headers()) self.assertEqual(204, response.status_code) # This image should be no longer be directly accessible path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(404, response.status_code) self.stop_servers() def test_download_image_not_allowed_using_restricted_policy(self): rules = { ""context_is_admin"": ""role:admin"", ""default"": """", ""restricted"": ""not ('aki':%(container_format)s and role:_member_)"", ""download_image"": ""role:admin or rule:restricted"" } self.set_policy_rules(rules) self.start_servers(**self.__dict__.copy()) # Create an image path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'member'}) data = jsonutils.dumps({'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Returned image entity image = jsonutils.loads(response.text) image_id = image['id'] expected_image = { 'status': 'queued', 'name': 'image-1', 'tags': [], 'visibility': 'private', 'self': '/v2/images/%s' % image_id, 'protected': False, 'file': '/v2/images/%s/file' % image_id, 'min_disk': 0, 'min_ram': 0, 'schema': '/v2/schemas/image', } for key, value in six.iteritems(expected_image): self.assertEqual(value, image[key], key) # Upload data to image path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.put(path, headers=headers, data='ZZZZZ') self.assertEqual(204, response.status_code) # Get an image should fail path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream', 'X-Roles': '_member_'}) response = requests.get(path, headers=headers) self.assertEqual(403, response.status_code) # Image Deletion should work path = self._url('/v2/images/%s' % image_id) response = requests.delete(path, headers=self._headers()) self.assertEqual(204, response.status_code) # This image should be no longer be directly accessible path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(404, response.status_code) self.stop_servers() def test_download_image_allowed_using_restricted_policy(self): rules = { ""context_is_admin"": ""role:admin"", ""default"": """", ""restricted"": ""not ('aki':%(container_format)s and role:_member_)"", ""download_image"": ""role:admin or rule:restricted"" } self.set_policy_rules(rules) self.start_servers(**self.__dict__.copy()) # Create an image path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'member'}) data = jsonutils.dumps({'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Returned image entity image = jsonutils.loads(response.text) image_id = image['id'] expected_image = { 'status': 'queued', 'name': 'image-1', 'tags': [], 'visibility': 'private', 'self': '/v2/images/%s' % image_id, 'protected': False, 'file': '/v2/images/%s/file' % image_id, 'min_disk': 0, 'min_ram': 0, 'schema': '/v2/schemas/image', } for key, value in six.iteritems(expected_image): self.assertEqual(value, value, key) # Upload data to image path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.put(path, headers=headers, data='ZZZZZ') self.assertEqual(204, response.status_code) # Get an image should be allowed path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream', 'X-Roles': 'member'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) # Image Deletion should work path = self._url('/v2/images/%s' % image_id) response = requests.delete(path, headers=self._headers()) self.assertEqual(204, response.status_code) # This image should be no longer be directly accessible path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(404, response.status_code) self.stop_servers() def test_image_size_cap(self): self.api_server.image_size_cap = 128 self.start_servers(**self.__dict__.copy()) # create an image path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) data = jsonutils.dumps({'name': 'image-size-cap-test-image', 'type': 'kernel', 'disk_format': 'aki', 'container_format': 'aki'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] # try to populate it with oversized data path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) class StreamSim(object): # Using a one-shot iterator to force chunked transfer in the PUT # request def __init__(self, size): self.size = size def __iter__(self): yield 'Z' * self.size response = requests.put(path, headers=headers, data=StreamSim( self.api_server.image_size_cap + 1)) self.assertEqual(413, response.status_code) # hashlib.md5('Z'*129).hexdigest() # == '76522d28cb4418f12704dfa7acd6e7ee' # If the image has this checksum, it means that the whole stream was # accepted and written to the store, which should not be the case. path = self._url('/v2/images/{0}'.format(image_id)) headers = self._headers({'content-type': 'application/json'}) response = requests.get(path, headers=headers) image_checksum = jsonutils.loads(response.text).get('checksum') self.assertNotEqual(image_checksum, '76522d28cb4418f12704dfa7acd6e7ee') def test_permissions(self): self.start_servers(**self.__dict__.copy()) # Create an image that belongs to TENANT1 path = self._url('/v2/images') headers = self._headers({'Content-Type': 'application/json'}) data = jsonutils.dumps({'name': 'image-1', 'disk_format': 'raw', 'container_format': 'bare'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image_id = jsonutils.loads(response.text)['id'] # Upload some image data path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.put(path, headers=headers, data='ZZZZZ') self.assertEqual(204, response.status_code) # TENANT1 should see the image in their list path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(image_id, images[0]['id']) # TENANT1 should be able to access the image directly path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) # TENANT2 should not see the image in their list path = self._url('/v2/images') headers = self._headers({'X-Tenant-Id': TENANT2}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # TENANT2 should not be able to access the image directly path = self._url('/v2/images/%s' % image_id) headers = self._headers({'X-Tenant-Id': TENANT2}) response = requests.get(path, headers=headers) self.assertEqual(404, response.status_code) # TENANT2 should not be able to modify the image, either path = self._url('/v2/images/%s' % image_id) headers = self._headers({ 'Content-Type': 'application/openstack-images-v2.1-json-patch', 'X-Tenant-Id': TENANT2, }) doc = [{'op': 'replace', 'path': '/name', 'value': 'image-2'}] data = jsonutils.dumps(doc) response = requests.patch(path, headers=headers, data=data) self.assertEqual(404, response.status_code) # TENANT2 should not be able to delete the image, either path = self._url('/v2/images/%s' % image_id) headers = self._headers({'X-Tenant-Id': TENANT2}) response = requests.delete(path, headers=headers) self.assertEqual(404, response.status_code) # Publicize the image as an admin of TENANT1 path = self._url('/v2/images/%s' % image_id) headers = self._headers({ 'Content-Type': 'application/openstack-images-v2.1-json-patch', 'X-Roles': 'admin', }) doc = [{'op': 'replace', 'path': '/visibility', 'value': 'public'}] data = jsonutils.dumps(doc) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code) # TENANT3 should now see the image in their list path = self._url('/v2/images') headers = self._headers({'X-Tenant-Id': TENANT3}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(image_id, images[0]['id']) # TENANT3 should also be able to access the image directly path = self._url('/v2/images/%s' % image_id) headers = self._headers({'X-Tenant-Id': TENANT3}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) # TENANT3 still should not be able to modify the image path = self._url('/v2/images/%s' % image_id) headers = self._headers({ 'Content-Type': 'application/openstack-images-v2.1-json-patch', 'X-Tenant-Id': TENANT3, }) doc = [{'op': 'replace', 'path': '/name', 'value': 'image-2'}] data = jsonutils.dumps(doc) response = requests.patch(path, headers=headers, data=data) self.assertEqual(403, response.status_code) # TENANT3 should not be able to delete the image, either path = self._url('/v2/images/%s' % image_id) headers = self._headers({'X-Tenant-Id': TENANT3}) response = requests.delete(path, headers=headers) self.assertEqual(403, response.status_code) # Image data should still be present after the failed delete path = self._url('/v2/images/%s/file' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) self.assertEqual(response.text, 'ZZZZZ') self.stop_servers() def test_property_protections_with_roles(self): # Enable property protection self.api_server.property_protection_file = self.property_file_roles self.start_servers(**self.__dict__.copy()) # Image list should be empty path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # Create an image for role member with extra props # Raises 403 since user is not allowed to set 'foo' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'member'}) data = jsonutils.dumps({'name': 'image-1', 'foo': 'bar', 'disk_format': 'aki', 'container_format': 'aki', 'x_owner_foo': 'o_s_bar'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(403, response.status_code) # Create an image for role member without 'foo' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'member'}) data = jsonutils.dumps({'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_owner_foo': 'o_s_bar'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Returned image entity should have 'x_owner_foo' image = jsonutils.loads(response.text) image_id = image['id'] expected_image = { 'status': 'queued', 'name': 'image-1', 'tags': [], 'visibility': 'private', 'self': '/v2/images/%s' % image_id, 'protected': False, 'file': '/v2/images/%s/file' % image_id, 'min_disk': 0, 'x_owner_foo': 'o_s_bar', 'min_ram': 0, 'schema': '/v2/schemas/image', } for key, value in expected_image.items(): self.assertEqual(value, image[key], key) # Create an image for role spl_role with extra props path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'spl_role'}) data = jsonutils.dumps({'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'spl_create_prop': 'create_bar', 'spl_create_prop_policy': 'create_policy_bar', 'spl_read_prop': 'read_bar', 'spl_update_prop': 'update_bar', 'spl_delete_prop': 'delete_bar', 'spl_delete_empty_prop': ''}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] # Attempt to replace, add and remove properties which are forbidden path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'spl_role'}) data = jsonutils.dumps([ {'op': 'replace', 'path': '/spl_read_prop', 'value': 'r'}, {'op': 'replace', 'path': '/spl_update_prop', 'value': 'u'}, ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(403, response.status_code, response.text) # Attempt to replace, add and remove properties which are forbidden path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'spl_role'}) data = jsonutils.dumps([ {'op': 'add', 'path': '/spl_new_prop', 'value': 'new'}, {'op': 'remove', 'path': '/spl_create_prop'}, {'op': 'remove', 'path': '/spl_delete_prop'}, ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(403, response.status_code, response.text) # Attempt to replace properties path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'spl_role'}) data = jsonutils.dumps([ # Updating an empty property to verify bug #1332103. {'op': 'replace', 'path': '/spl_update_prop', 'value': ''}, {'op': 'replace', 'path': '/spl_update_prop', 'value': 'u'}, ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) # Returned image entity should reflect the changes image = jsonutils.loads(response.text) # 'spl_update_prop' has update permission for spl_role # hence the value has changed self.assertEqual('u', image['spl_update_prop']) # Attempt to remove properties path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'spl_role'}) data = jsonutils.dumps([ {'op': 'remove', 'path': '/spl_delete_prop'}, # Deleting an empty property to verify bug #1332103. {'op': 'remove', 'path': '/spl_delete_empty_prop'}, ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) # Returned image entity should reflect the changes image = jsonutils.loads(response.text) # 'spl_delete_prop' and 'spl_delete_empty_prop' have delete # permission for spl_role hence the property has been deleted self.assertNotIn('spl_delete_prop', image.keys()) self.assertNotIn('spl_delete_empty_prop', image.keys()) # Image Deletion should work path = self._url('/v2/images/%s' % image_id) response = requests.delete(path, headers=self._headers()) self.assertEqual(204, response.status_code) # This image should be no longer be directly accessible path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(404, response.status_code) self.stop_servers() def test_property_protections_with_policies(self): # Enable property protection self.api_server.property_protection_file = self.property_file_policies self.api_server.property_protection_rule_format = 'policies' self.start_servers(**self.__dict__.copy()) # Image list should be empty path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # Create an image for role member with extra props # Raises 403 since user is not allowed to set 'foo' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'member'}) data = jsonutils.dumps({'name': 'image-1', 'foo': 'bar', 'disk_format': 'aki', 'container_format': 'aki', 'x_owner_foo': 'o_s_bar'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(403, response.status_code) # Create an image for role member without 'foo' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'member'}) data = jsonutils.dumps({'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Returned image entity image = jsonutils.loads(response.text) image_id = image['id'] expected_image = { 'status': 'queued', 'name': 'image-1', 'tags': [], 'visibility': 'private', 'self': '/v2/images/%s' % image_id, 'protected': False, 'file': '/v2/images/%s/file' % image_id, 'min_disk': 0, 'min_ram': 0, 'schema': '/v2/schemas/image', } for key, value in expected_image.items(): self.assertEqual(value, image[key], key) # Create an image for role spl_role with extra props path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'spl_role, admin'}) data = jsonutils.dumps({'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'spl_creator_policy': 'creator_bar', 'spl_default_policy': 'default_bar'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] self.assertEqual('creator_bar', image['spl_creator_policy']) self.assertEqual('default_bar', image['spl_default_policy']) # Attempt to replace a property which is permitted path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'admin'}) data = jsonutils.dumps([ # Updating an empty property to verify bug #1332103. {'op': 'replace', 'path': '/spl_creator_policy', 'value': ''}, {'op': 'replace', 'path': '/spl_creator_policy', 'value': 'r'}, ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) # Returned image entity should reflect the changes image = jsonutils.loads(response.text) # 'spl_creator_policy' has update permission for admin # hence the value has changed self.assertEqual('r', image['spl_creator_policy']) # Attempt to replace a property which is forbidden path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'spl_role'}) data = jsonutils.dumps([ {'op': 'replace', 'path': '/spl_creator_policy', 'value': 'z'}, ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(403, response.status_code, response.text) # Attempt to read properties path = self._url('/v2/images/%s' % image_id) headers = self._headers({'content-type': media_type, 'X-Roles': 'random_role'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) # 'random_role' is allowed read 'spl_default_policy'. self.assertEqual(image['spl_default_policy'], 'default_bar') # 'random_role' is forbidden to read 'spl_creator_policy'. self.assertFalse('spl_creator_policy' in image) # Attempt to replace and remove properties which are permitted path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'admin'}) data = jsonutils.dumps([ # Deleting an empty property to verify bug #1332103. {'op': 'replace', 'path': '/spl_creator_policy', 'value': ''}, {'op': 'remove', 'path': '/spl_creator_policy'}, ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) # Returned image entity should reflect the changes image = jsonutils.loads(response.text) # 'spl_creator_policy' has delete permission for admin # hence the value has been deleted self.assertFalse('spl_creator_policy' in image) # Attempt to read a property that is permitted path = self._url('/v2/images/%s' % image_id) headers = self._headers({'content-type': media_type, 'X-Roles': 'random_role'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) # Returned image entity should reflect the changes image = jsonutils.loads(response.text) self.assertEqual(image['spl_default_policy'], 'default_bar') # Image Deletion should work path = self._url('/v2/images/%s' % image_id) response = requests.delete(path, headers=self._headers()) self.assertEqual(204, response.status_code) # This image should be no longer be directly accessible path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(404, response.status_code) self.stop_servers() def test_property_protections_special_chars_roles(self): # Enable property protection self.api_server.property_protection_file = self.property_file_roles self.start_servers(**self.__dict__.copy()) # Verify both admin and unknown role can create properties marked with # '@' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_all_permitted_admin': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] expected_image = { 'status': 'queued', 'name': 'image-1', 'tags': [], 'visibility': 'private', 'self': '/v2/images/%s' % image_id, 'protected': False, 'file': '/v2/images/%s/file' % image_id, 'min_disk': 0, 'x_all_permitted_admin': '1', 'min_ram': 0, 'schema': '/v2/schemas/image', } for key, value in expected_image.items(): self.assertEqual(value, image[key], key) path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'joe_soap'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_all_permitted_joe_soap': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] expected_image = { 'status': 'queued', 'name': 'image-1', 'tags': [], 'visibility': 'private', 'self': '/v2/images/%s' % image_id, 'protected': False, 'file': '/v2/images/%s/file' % image_id, 'min_disk': 0, 'x_all_permitted_joe_soap': '1', 'min_ram': 0, 'schema': '/v2/schemas/image', } for key, value in expected_image.items(): self.assertEqual(value, image[key], key) # Verify both admin and unknown role can read properties marked with # '@' headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertEqual('1', image['x_all_permitted_joe_soap']) headers = self._headers({'content-type': 'application/json', 'X-Roles': 'joe_soap'}) path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertEqual('1', image['x_all_permitted_joe_soap']) # Verify both admin and unknown role can update properties marked with # '@' path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'admin'}) data = jsonutils.dumps([ {'op': 'replace', 'path': '/x_all_permitted_joe_soap', 'value': '2'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) image = jsonutils.loads(response.text) self.assertEqual('2', image['x_all_permitted_joe_soap']) path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'joe_soap'}) data = jsonutils.dumps([ {'op': 'replace', 'path': '/x_all_permitted_joe_soap', 'value': '3'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) image = jsonutils.loads(response.text) self.assertEqual('3', image['x_all_permitted_joe_soap']) # Verify both admin and unknown role can delete properties marked with # '@' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_all_permitted_a': '1', 'x_all_permitted_b': '2' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'admin'}) data = jsonutils.dumps([ {'op': 'remove', 'path': '/x_all_permitted_a'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) image = jsonutils.loads(response.text) self.assertNotIn('x_all_permitted_a', image.keys()) path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'joe_soap'}) data = jsonutils.dumps([ {'op': 'remove', 'path': '/x_all_permitted_b'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) image = jsonutils.loads(response.text) self.assertNotIn('x_all_permitted_b', image.keys()) # Verify neither admin nor unknown role can create a property protected # with '!' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_none_permitted_admin': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(403, response.status_code) path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'joe_soap'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_none_permitted_joe_soap': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(403, response.status_code) # Verify neither admin nor unknown role can read properties marked with # '!' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_none_read': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] self.assertNotIn('x_none_read', image.keys()) headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertNotIn('x_none_read', image.keys()) headers = self._headers({'content-type': 'application/json', 'X-Roles': 'joe_soap'}) path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertNotIn('x_none_read', image.keys()) # Verify neither admin nor unknown role can update properties marked # with '!' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_none_update': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] self.assertEqual('1', image['x_none_update']) path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'admin'}) data = jsonutils.dumps([ {'op': 'replace', 'path': '/x_none_update', 'value': '2'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(403, response.status_code, response.text) path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'joe_soap'}) data = jsonutils.dumps([ {'op': 'replace', 'path': '/x_none_update', 'value': '3'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(409, response.status_code, response.text) # Verify neither admin nor unknown role can delete properties marked # with '!' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_none_delete': '1', }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'admin'}) data = jsonutils.dumps([ {'op': 'remove', 'path': '/x_none_delete'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(403, response.status_code, response.text) path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'joe_soap'}) data = jsonutils.dumps([ {'op': 'remove', 'path': '/x_none_delete'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(409, response.status_code, response.text) self.stop_servers() def test_property_protections_special_chars_policies(self): # Enable property protection self.api_server.property_protection_file = self.property_file_policies self.api_server.property_protection_rule_format = 'policies' self.start_servers(**self.__dict__.copy()) # Verify both admin and unknown role can create properties marked with # '@' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_all_permitted_admin': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] expected_image = { 'status': 'queued', 'name': 'image-1', 'tags': [], 'visibility': 'private', 'self': '/v2/images/%s' % image_id, 'protected': False, 'file': '/v2/images/%s/file' % image_id, 'min_disk': 0, 'x_all_permitted_admin': '1', 'min_ram': 0, 'schema': '/v2/schemas/image', } for key, value in expected_image.items(): self.assertEqual(value, image[key], key) path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'joe_soap'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_all_permitted_joe_soap': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] expected_image = { 'status': 'queued', 'name': 'image-1', 'tags': [], 'visibility': 'private', 'self': '/v2/images/%s' % image_id, 'protected': False, 'file': '/v2/images/%s/file' % image_id, 'min_disk': 0, 'x_all_permitted_joe_soap': '1', 'min_ram': 0, 'schema': '/v2/schemas/image', } for key, value in expected_image.items(): self.assertEqual(value, image[key], key) # Verify both admin and unknown role can read properties marked with # '@' headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertEqual('1', image['x_all_permitted_joe_soap']) headers = self._headers({'content-type': 'application/json', 'X-Roles': 'joe_soap'}) path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertEqual('1', image['x_all_permitted_joe_soap']) # Verify both admin and unknown role can update properties marked with # '@' path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'admin'}) data = jsonutils.dumps([ {'op': 'replace', 'path': '/x_all_permitted_joe_soap', 'value': '2'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) image = jsonutils.loads(response.text) self.assertEqual('2', image['x_all_permitted_joe_soap']) path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'joe_soap'}) data = jsonutils.dumps([ {'op': 'replace', 'path': '/x_all_permitted_joe_soap', 'value': '3'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) image = jsonutils.loads(response.text) self.assertEqual('3', image['x_all_permitted_joe_soap']) # Verify both admin and unknown role can delete properties marked with # '@' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_all_permitted_a': '1', 'x_all_permitted_b': '2' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'admin'}) data = jsonutils.dumps([ {'op': 'remove', 'path': '/x_all_permitted_a'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) image = jsonutils.loads(response.text) self.assertNotIn('x_all_permitted_a', image.keys()) path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'joe_soap'}) data = jsonutils.dumps([ {'op': 'remove', 'path': '/x_all_permitted_b'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) image = jsonutils.loads(response.text) self.assertNotIn('x_all_permitted_b', image.keys()) # Verify neither admin nor unknown role can create a property protected # with '!' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_none_permitted_admin': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(403, response.status_code) path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'joe_soap'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_none_permitted_joe_soap': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(403, response.status_code) # Verify neither admin nor unknown role can read properties marked with # '!' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_none_read': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] self.assertNotIn('x_none_read', image.keys()) headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertNotIn('x_none_read', image.keys()) headers = self._headers({'content-type': 'application/json', 'X-Roles': 'joe_soap'}) path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertNotIn('x_none_read', image.keys()) # Verify neither admin nor unknown role can update properties marked # with '!' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_none_update': '1' }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] self.assertEqual('1', image['x_none_update']) path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'admin'}) data = jsonutils.dumps([ {'op': 'replace', 'path': '/x_none_update', 'value': '2'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(403, response.status_code, response.text) path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'joe_soap'}) data = jsonutils.dumps([ {'op': 'replace', 'path': '/x_none_update', 'value': '3'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(409, response.status_code, response.text) # Verify neither admin nor unknown role can delete properties marked # with '!' path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json', 'X-Roles': 'admin'}) data = jsonutils.dumps({ 'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki', 'x_none_delete': '1', }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'admin'}) data = jsonutils.dumps([ {'op': 'remove', 'path': '/x_none_delete'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(403, response.status_code, response.text) path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type, 'X-Roles': 'joe_soap'}) data = jsonutils.dumps([ {'op': 'remove', 'path': '/x_none_delete'} ]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(409, response.status_code, response.text) self.stop_servers() def test_tag_lifecycle(self): self.start_servers(**self.__dict__.copy()) # Create an image with a tag - duplicate should be ignored path = self._url('/v2/images') headers = self._headers({'Content-Type': 'application/json'}) data = jsonutils.dumps({'name': 'image-1', 'tags': ['sniff', 'sniff']}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image_id = jsonutils.loads(response.text)['id'] # Image should show a list with a single tag path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) tags = jsonutils.loads(response.text)['tags'] self.assertEqual(['sniff'], tags) # Delete all tags for tag in tags: path = self._url('/v2/images/%s/tags/%s' % (image_id, tag)) response = requests.delete(path, headers=self._headers()) self.assertEqual(204, response.status_code) # Update image with too many tags via PUT # Configured limit is 10 tags for i in range(10): path = self._url('/v2/images/%s/tags/foo%i' % (image_id, i)) response = requests.put(path, headers=self._headers()) self.assertEqual(204, response.status_code) # 11th tag should fail path = self._url('/v2/images/%s/tags/fail_me' % image_id) response = requests.put(path, headers=self._headers()) self.assertEqual(413, response.status_code) # Make sure the 11th tag was not added path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) tags = jsonutils.loads(response.text)['tags'] self.assertEqual(10, len(tags)) # Update image tags via PATCH path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) doc = [ { 'op': 'replace', 'path': '/tags', 'value': ['foo'], }, ] data = jsonutils.dumps(doc) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code) # Update image with too many tags via PATCH # Configured limit is 10 tags path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) tags = ['foo%d' % i for i in range(11)] doc = [ { 'op': 'replace', 'path': '/tags', 'value': tags, }, ] data = jsonutils.dumps(doc) response = requests.patch(path, headers=headers, data=data) self.assertEqual(413, response.status_code) # Tags should not have changed since request was over limit path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) tags = jsonutils.loads(response.text)['tags'] self.assertEqual(['foo'], tags) # Update image with duplicate tag - it should be ignored path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) doc = [ { 'op': 'replace', 'path': '/tags', 'value': ['sniff', 'snozz', 'snozz'], }, ] data = jsonutils.dumps(doc) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code) tags = jsonutils.loads(response.text)['tags'] self.assertEqual(['sniff', 'snozz'], sorted(tags)) # Image should show the appropriate tags path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) tags = jsonutils.loads(response.text)['tags'] self.assertEqual(['sniff', 'snozz'], sorted(tags)) # Attempt to tag the image with a duplicate should be ignored path = self._url('/v2/images/%s/tags/snozz' % image_id) response = requests.put(path, headers=self._headers()) self.assertEqual(204, response.status_code) # Create another more complex tag path = self._url('/v2/images/%s/tags/gabe%%40example.com' % image_id) response = requests.put(path, headers=self._headers()) self.assertEqual(204, response.status_code) # Double-check that the tags container on the image is populated path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) tags = jsonutils.loads(response.text)['tags'] self.assertEqual(['gabe@example.com', 'sniff', 'snozz'], sorted(tags)) # Query images by single tag path = self._url('/v2/images?tag=sniff') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(1, len(images)) self.assertEqual('image-1', images[0]['name']) # Query images by multiple tags path = self._url('/v2/images?tag=sniff&tag=snozz') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(1, len(images)) self.assertEqual('image-1', images[0]['name']) # Query images by tag and other attributes path = self._url('/v2/images?tag=sniff&status=queued') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(1, len(images)) self.assertEqual('image-1', images[0]['name']) # Query images by tag and a nonexistent tag path = self._url('/v2/images?tag=sniff&tag=fake') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # The tag should be deletable path = self._url('/v2/images/%s/tags/gabe%%40example.com' % image_id) response = requests.delete(path, headers=self._headers()) self.assertEqual(204, response.status_code) # List of tags should reflect the deletion path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) tags = jsonutils.loads(response.text)['tags'] self.assertEqual(['sniff', 'snozz'], sorted(tags)) # Deleting the same tag should return a 404 path = self._url('/v2/images/%s/tags/gabe%%40example.com' % image_id) response = requests.delete(path, headers=self._headers()) self.assertEqual(404, response.status_code) # The tags won't be able to query the images after deleting path = self._url('/v2/images?tag=gabe%%40example.com') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) self.stop_servers() def test_images_container(self): # Image list should be empty and no next link should be present self.start_servers(**self.__dict__.copy()) path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] first = jsonutils.loads(response.text)['first'] self.assertEqual(0, len(images)) self.assertTrue('next' not in jsonutils.loads(response.text)) self.assertEqual('/v2/images', first) # Create 7 images images = [] fixtures = [ {'name': 'image-3', 'type': 'kernel', 'ping': 'pong'}, {'name': 'image-4', 'type': 'kernel', 'ping': 'pong'}, {'name': 'image-1', 'type': 'kernel', 'ping': 'pong'}, {'name': 'image-3', 'type': 'ramdisk', 'ping': 'pong'}, {'name': 'image-2', 'type': 'kernel', 'ping': 'ding'}, {'name': 'image-3', 'type': 'kernel', 'ping': 'pong'}, {'name': 'image-2', 'type': 'kernel', 'ping': 'pong'}, ] path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) for fixture in fixtures: data = jsonutils.dumps(fixture) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) images.append(jsonutils.loads(response.text)) # Image list should contain 7 images path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) body = jsonutils.loads(response.text) self.assertEqual(7, len(body['images'])) self.assertEqual('/v2/images', body['first']) self.assertFalse('next' in jsonutils.loads(response.text)) # Begin pagination after the first image template_url = ('/v2/images?limit=2&sort_dir=asc&sort_key=name' '&marker=%s&type=kernel&ping=pong') path = self._url(template_url % images[2]['id']) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) body = jsonutils.loads(response.text) self.assertEqual(2, len(body['images'])) response_ids = [image['id'] for image in body['images']] self.assertEqual([images[6]['id'], images[0]['id']], response_ids) # Continue pagination using next link from previous request path = self._url(body['next']) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) body = jsonutils.loads(response.text) self.assertEqual(2, len(body['images'])) response_ids = [image['id'] for image in body['images']] self.assertEqual([images[5]['id'], images[1]['id']], response_ids) # Continue pagination - expect no results path = self._url(body['next']) response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) body = jsonutils.loads(response.text) self.assertEqual(0, len(body['images'])) # Delete first image path = self._url('/v2/images/%s' % images[0]['id']) response = requests.delete(path, headers=self._headers()) self.assertEqual(204, response.status_code) # Ensure bad request for using a deleted image as marker path = self._url('/v2/images?marker=%s' % images[0]['id']) response = requests.get(path, headers=self._headers()) self.assertEqual(400, response.status_code) self.stop_servers() def test_image_visibility_to_different_users(self): self.cleanup() self.api_server.deployment_flavor = 'fakeauth' self.registry_server.deployment_flavor = 'fakeauth' kwargs = self.__dict__.copy() kwargs['use_user_token'] = True self.start_servers(**kwargs) owners = ['admin', 'tenant1', 'tenant2', 'none'] visibilities = ['public', 'private'] for owner in owners: for visibility in visibilities: path = self._url('/v2/images') headers = self._headers({ 'content-type': 'application/json', 'X-Auth-Token': 'createuser:%s:admin' % owner, }) data = jsonutils.dumps({ 'name': '%s-%s' % (owner, visibility), 'visibility': visibility, }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) def list_images(tenant, role='', visibility=None): auth_token = 'user:%s:%s' % (tenant, role) headers = {'X-Auth-Token': auth_token} path = self._url('/v2/images') if visibility is not None: path += '?visibility=%s' % visibility response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) return jsonutils.loads(response.text)['images'] # 1. Known user sees public and their own images images = list_images('tenant1') self.assertEqual(5, len(images)) for image in images: self.assertTrue(image['visibility'] == 'public' or 'tenant1' in image['name']) # 2. Known user, visibility=public, sees all public images images = list_images('tenant1', visibility='public') self.assertEqual(4, len(images)) for image in images: self.assertEqual('public', image['visibility']) # 3. Known user, visibility=private, sees only their private image images = list_images('tenant1', visibility='private') self.assertEqual(1, len(images)) image = images[0] self.assertEqual('private', image['visibility']) self.assertTrue('tenant1' in image['name']) # 4. Unknown user sees only public images images = list_images('none') self.assertEqual(4, len(images)) for image in images: self.assertEqual('public', image['visibility']) # 5. Unknown user, visibility=public, sees only public images images = list_images('none', visibility='public') self.assertEqual(4, len(images)) for image in images: self.assertEqual('public', image['visibility']) # 6. Unknown user, visibility=private, sees no images images = list_images('none', visibility='private') self.assertEqual(0, len(images)) # 7. Unknown admin sees all images images = list_images('none', role='admin') self.assertEqual(8, len(images)) # 8. Unknown admin, visibility=public, shows only public images images = list_images('none', role='admin', visibility='public') self.assertEqual(4, len(images)) for image in images: self.assertEqual('public', image['visibility']) # 9. Unknown admin, visibility=private, sees only private images images = list_images('none', role='admin', visibility='private') self.assertEqual(4, len(images)) for image in images: self.assertEqual('private', image['visibility']) # 10. Known admin sees all images images = list_images('admin', role='admin') self.assertEqual(8, len(images)) # 11. Known admin, visibility=public, sees all public images images = list_images('admin', role='admin', visibility='public') self.assertEqual(4, len(images)) for image in images: self.assertEqual('public', image['visibility']) # 12. Known admin, visibility=private, sees all private images images = list_images('admin', role='admin', visibility='private') self.assertEqual(4, len(images)) for image in images: self.assertEqual('private', image['visibility']) self.stop_servers() def test_update_locations(self): self.start_servers(**self.__dict__.copy()) # Create an image path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) data = jsonutils.dumps({'name': 'image-1', 'disk_format': 'aki', 'container_format': 'aki'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Returned image entity should have a generated id and status image = jsonutils.loads(response.text) image_id = image['id'] self.assertEqual('queued', image['status']) self.assertIsNone(image['size']) self.assertIsNone(image['virtual_size']) file_path = os.path.join(self.test_dir, 'fake_image') with open(file_path, 'w') as fap: fap.write('glance') # Update locations for the queued image path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) data = jsonutils.dumps([{'op': 'replace', 'path': '/locations', 'value': [{'url': 'file://' + file_path, 'metadata': {}}]}]) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code, response.text) # The image size should be updated path = self._url('/v2/images/%s' % image_id) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertEqual(6, image['size']) class TestImagesWithRegistry(TestImages): def setUp(self): super(TestImagesWithRegistry, self).setUp() self.api_server.data_api = ( 'glance.tests.functional.v2.registry_data_api') self.registry_server.deployment_flavor = 'trusted-auth' class TestImageDirectURLVisibility(functional.FunctionalTest): def setUp(self): super(TestImageDirectURLVisibility, self).setUp() self.cleanup() self.api_server.deployment_flavor = 'noauth' def _url(self, path): return 'http://127.0.0.1:%d%s' % (self.api_port, path) def _headers(self, custom_headers=None): base_headers = { 'X-Identity-Status': 'Confirmed', 'X-Auth-Token': '932c5c84-02ac-4fe5-a9ba-620af0e2bb96', 'X-User-Id': 'f9a41d13-0c13-47e9-bee2-ce4e8bfe958e', 'X-Tenant-Id': TENANT1, 'X-Roles': 'member', } base_headers.update(custom_headers or {}) return base_headers def test_v2_not_enabled(self): self.api_server.enable_v2_api = False self.start_servers(**self.__dict__.copy()) path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(300, response.status_code) self.stop_servers() def test_v2_enabled(self): self.api_server.enable_v2_api = True self.start_servers(**self.__dict__.copy()) path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) self.stop_servers() def test_image_direct_url_visible(self): self.api_server.show_image_direct_url = True self.start_servers(**self.__dict__.copy()) # Image list should be empty path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # Create an image path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) data = jsonutils.dumps({'name': 'image-1', 'type': 'kernel', 'foo': 'bar', 'disk_format': 'aki', 'container_format': 'aki', 'visibility': 'public'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Get the image id image = jsonutils.loads(response.text) image_id = image['id'] # Image direct_url should not be visible before location is set path = self._url('/v2/images/%s' % image_id) headers = self._headers({'Content-Type': 'application/json'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertFalse('direct_url' in image) # Upload some image data, setting the image location path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.put(path, headers=headers, data='ZZZZZ') self.assertEqual(204, response.status_code) # Image direct_url should be visible path = self._url('/v2/images/%s' % image_id) headers = self._headers({'Content-Type': 'application/json'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertTrue('direct_url' in image) # Image direct_url should be visible to non-owner, non-admin user path = self._url('/v2/images/%s' % image_id) headers = self._headers({'Content-Type': 'application/json', 'X-Tenant-Id': TENANT2}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertIn('direct_url', image) # Image direct_url should be visible in a list path = self._url('/v2/images') headers = self._headers({'Content-Type': 'application/json'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text)['images'][0] self.assertTrue('direct_url' in image) self.stop_servers() def test_image_multiple_location_url_visible(self): self.api_server.show_multiple_locations = True self.start_servers(**self.__dict__.copy()) # Create an image path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) data = jsonutils.dumps({'name': 'image-1', 'type': 'kernel', 'foo': 'bar', 'disk_format': 'aki', 'container_format': 'aki'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Get the image id image = jsonutils.loads(response.text) image_id = image['id'] # Image locations should not be visible before location is set path = self._url('/v2/images/%s' % image_id) headers = self._headers({'Content-Type': 'application/json'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertTrue('locations' in image) self.assertTrue(image[""locations""] == []) # Upload some image data, setting the image location path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.put(path, headers=headers, data='ZZZZZ') self.assertEqual(204, response.status_code) # Image locations should be visible path = self._url('/v2/images/%s' % image_id) headers = self._headers({'Content-Type': 'application/json'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertTrue('locations' in image) loc = image['locations'] self.assertTrue(len(loc) > 0) loc = loc[0] self.assertTrue('url' in loc) self.assertTrue('metadata' in loc) self.stop_servers() def test_image_direct_url_not_visible(self): self.api_server.show_image_direct_url = False self.start_servers(**self.__dict__.copy()) # Image list should be empty path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # Create an image path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) data = jsonutils.dumps({'name': 'image-1', 'type': 'kernel', 'foo': 'bar', 'disk_format': 'aki', 'container_format': 'aki'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Get the image id image = jsonutils.loads(response.text) image_id = image['id'] # Upload some image data, setting the image location path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.put(path, headers=headers, data='ZZZZZ') self.assertEqual(204, response.status_code) # Image direct_url should not be visible path = self._url('/v2/images/%s' % image_id) headers = self._headers({'Content-Type': 'application/json'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertFalse('direct_url' in image) # Image direct_url should not be visible in a list path = self._url('/v2/images') headers = self._headers({'Content-Type': 'application/json'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text)['images'][0] self.assertFalse('direct_url' in image) self.stop_servers() class TestImageDirectURLVisibilityWithRegistry(TestImageDirectURLVisibility): def setUp(self): super(TestImageDirectURLVisibilityWithRegistry, self).setUp() self.api_server.data_api = ( 'glance.tests.functional.v2.registry_data_api') self.registry_server.deployment_flavor = 'trusted-auth' class TestImageLocationSelectionStrategy(functional.FunctionalTest): def setUp(self): super(TestImageLocationSelectionStrategy, self).setUp() self.cleanup() self.api_server.deployment_flavor = 'noauth' self.foo_image_file = tempfile.NamedTemporaryFile() self.foo_image_file.write(""foo image file"") self.foo_image_file.flush() self.addCleanup(self.foo_image_file.close) ret = http_server(""foo_image_id"", ""foo_image"") self.http_server_pid, self.http_port = ret def tearDown(self): if self.http_server_pid is not None: os.kill(self.http_server_pid, signal.SIGKILL) super(TestImageLocationSelectionStrategy, self).tearDown() def _url(self, path): return 'http://127.0.0.1:%d%s' % (self.api_port, path) def _headers(self, custom_headers=None): base_headers = { 'X-Identity-Status': 'Confirmed', 'X-Auth-Token': '932c5c84-02ac-4fe5-a9ba-620af0e2bb96', 'X-User-Id': 'f9a41d13-0c13-47e9-bee2-ce4e8bfe958e', 'X-Tenant-Id': TENANT1, 'X-Roles': 'member', } base_headers.update(custom_headers or {}) return base_headers def test_image_locations_with_order_strategy(self): self.api_server.show_image_direct_url = True self.api_server.show_multiple_locations = True self.image_location_quota = 10 self.api_server.location_strategy = 'location_order' preference = ""http, swift, filesystem"" self.api_server.store_type_location_strategy_preference = preference self.start_servers(**self.__dict__.copy()) # Create an image path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) data = jsonutils.dumps({'name': 'image-1', 'type': 'kernel', 'foo': 'bar', 'disk_format': 'aki', 'container_format': 'aki'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Get the image id image = jsonutils.loads(response.text) image_id = image['id'] # Image locations should not be visible before location is set path = self._url('/v2/images/%s' % image_id) headers = self._headers({'Content-Type': 'application/json'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertTrue('locations' in image) self.assertTrue(image[""locations""] == []) # Update image locations via PATCH path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) values = [{'url': 'file://%s' % self.foo_image_file.name, 'metadata': {'idx': '1'}}, {'url': 'http://127.0.0.1:%s/foo_image' % self.http_port, 'metadata': {'idx': '0'}}] doc = [{'op': 'replace', 'path': '/locations', 'value': values}] data = jsonutils.dumps(doc) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code) # Image locations should be visible path = self._url('/v2/images/%s' % image_id) headers = self._headers({'Content-Type': 'application/json'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertTrue('locations' in image) self.assertEqual(values, image['locations']) self.assertTrue('direct_url' in image) self.assertEqual(values[0]['url'], image['direct_url']) self.stop_servers() def test_image_locatons_with_store_type_strategy(self): self.api_server.show_image_direct_url = True self.api_server.show_multiple_locations = True self.image_location_quota = 10 self.api_server.location_strategy = 'store_type' preference = ""http, swift, filesystem"" self.api_server.store_type_location_strategy_preference = preference self.start_servers(**self.__dict__.copy()) # Create an image path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) data = jsonutils.dumps({'name': 'image-1', 'type': 'kernel', 'foo': 'bar', 'disk_format': 'aki', 'container_format': 'aki'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) # Get the image id image = jsonutils.loads(response.text) image_id = image['id'] # Image locations should not be visible before location is set path = self._url('/v2/images/%s' % image_id) headers = self._headers({'Content-Type': 'application/json'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertTrue('locations' in image) self.assertTrue(image[""locations""] == []) # Update image locations via PATCH path = self._url('/v2/images/%s' % image_id) media_type = 'application/openstack-images-v2.1-json-patch' headers = self._headers({'content-type': media_type}) values = [{'url': 'file://%s' % self.foo_image_file.name, 'metadata': {'idx': '1'}}, {'url': 'http://127.0.0.1:%s/foo_image' % self.http_port, 'metadata': {'idx': '0'}}] doc = [{'op': 'replace', 'path': '/locations', 'value': values}] data = jsonutils.dumps(doc) response = requests.patch(path, headers=headers, data=data) self.assertEqual(200, response.status_code) values.sort(key=lambda loc: int(loc['metadata']['idx'])) # Image locations should be visible path = self._url('/v2/images/%s' % image_id) headers = self._headers({'Content-Type': 'application/json'}) response = requests.get(path, headers=headers) self.assertEqual(200, response.status_code) image = jsonutils.loads(response.text) self.assertTrue('locations' in image) self.assertEqual(values, image['locations']) self.assertTrue('direct_url' in image) self.assertEqual(values[0]['url'], image['direct_url']) self.stop_servers() class TestImageLocationSelectionStrategyWithRegistry( TestImageLocationSelectionStrategy): def setUp(self): super(TestImageLocationSelectionStrategyWithRegistry, self).setUp() self.api_server.data_api = ( 'glance.tests.functional.v2.registry_data_api') self.registry_server.deployment_flavor = 'trusted-auth' class TestImageMembers(functional.FunctionalTest): def setUp(self): super(TestImageMembers, self).setUp() self.cleanup() self.api_server.deployment_flavor = 'fakeauth' self.registry_server.deployment_flavor = 'fakeauth' self.start_servers(**self.__dict__.copy()) def _url(self, path): return 'http://127.0.0.1:%d%s' % (self.api_port, path) def _headers(self, custom_headers=None): base_headers = { 'X-Identity-Status': 'Confirmed', 'X-Auth-Token': '932c5c84-02ac-4fe5-a9ba-620af0e2bb96', 'X-User-Id': 'f9a41d13-0c13-47e9-bee2-ce4e8bfe958e', 'X-Tenant-Id': TENANT1, 'X-Roles': 'member', } base_headers.update(custom_headers or {}) return base_headers def test_image_member_lifecycle(self): def get_header(tenant, role=''): auth_token = 'user:%s:%s' % (tenant, role) headers = {'X-Auth-Token': auth_token} return headers # Image list should be empty path = self._url('/v2/images') response = requests.get(path, headers=get_header('tenant1')) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) owners = ['tenant1', 'tenant2', 'admin'] visibilities = ['public', 'private'] image_fixture = [] for owner in owners: for visibility in visibilities: path = self._url('/v2/images') headers = self._headers({ 'content-type': 'application/json', 'X-Auth-Token': 'createuser:%s:admin' % owner, }) data = jsonutils.dumps({ 'name': '%s-%s' % (owner, visibility), 'visibility': visibility, }) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image_fixture.append(jsonutils.loads(response.text)) # Image list should contain 4 images for tenant1 path = self._url('/v2/images') response = requests.get(path, headers=get_header('tenant1')) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(4, len(images)) # Image list should contain 3 images for TENANT3 path = self._url('/v2/images') response = requests.get(path, headers=get_header(TENANT3)) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(3, len(images)) # Add Image member for tenant1-private image path = self._url('/v2/images/%s/members' % image_fixture[1]['id']) body = jsonutils.dumps({'member': TENANT3}) response = requests.post(path, headers=get_header('tenant1'), data=body) self.assertEqual(200, response.status_code) image_member = jsonutils.loads(response.text) self.assertEqual(image_fixture[1]['id'], image_member['image_id']) self.assertEqual(TENANT3, image_member['member_id']) self.assertTrue('created_at' in image_member) self.assertTrue('updated_at' in image_member) self.assertEqual('pending', image_member['status']) # Image list should contain 3 images for TENANT3 path = self._url('/v2/images') response = requests.get(path, headers=get_header(TENANT3)) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(3, len(images)) # Image list should contain 0 shared images for TENANT3 # because default is accepted path = self._url('/v2/images?visibility=shared') response = requests.get(path, headers=get_header(TENANT3)) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # Image list should contain 4 images for TENANT3 with status pending path = self._url('/v2/images?member_status=pending') response = requests.get(path, headers=get_header(TENANT3)) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(4, len(images)) # Image list should contain 4 images for TENANT3 with status all path = self._url('/v2/images?member_status=all') response = requests.get(path, headers=get_header(TENANT3)) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(4, len(images)) # Image list should contain 1 image for TENANT3 with status pending # and visibility shared path = self._url('/v2/images?member_status=pending&visibility=shared') response = requests.get(path, headers=get_header(TENANT3)) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(1, len(images)) self.assertEqual(images[0]['name'], 'tenant1-private') # Image list should contain 0 image for TENANT3 with status rejected # and visibility shared path = self._url('/v2/images?member_status=rejected&visibility=shared') response = requests.get(path, headers=get_header(TENANT3)) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # Image list should contain 0 image for TENANT3 with status accepted # and visibility shared path = self._url('/v2/images?member_status=accepted&visibility=shared') response = requests.get(path, headers=get_header(TENANT3)) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # Image list should contain 0 image for TENANT3 with status accepted # and visibility private path = self._url('/v2/images?visibility=private') response = requests.get(path, headers=get_header(TENANT3)) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # Image tenant2-private's image members list should contain no members path = self._url('/v2/images/%s/members' % image_fixture[3]['id']) response = requests.get(path, headers=get_header('tenant2')) self.assertEqual(200, response.status_code) body = jsonutils.loads(response.text) self.assertEqual(0, len(body['members'])) # Tenant 1, who is the owner cannot change status of image member path = self._url('/v2/images/%s/members/%s' % (image_fixture[1]['id'], TENANT3)) body = jsonutils.dumps({'status': 'accepted'}) response = requests.put(path, headers=get_header('tenant1'), data=body) self.assertEqual(403, response.status_code) # Tenant 1, who is the owner can get status of its own image member path = self._url('/v2/images/%s/members/%s' % (image_fixture[1]['id'], TENANT3)) response = requests.get(path, headers=get_header('tenant1')) self.assertEqual(200, response.status_code) body = jsonutils.loads(response.text) self.assertEqual('pending', body['status']) self.assertEqual(image_fixture[1]['id'], body['image_id']) self.assertEqual(TENANT3, body['member_id']) # Tenant 3, who is the member can get status of its own status path = self._url('/v2/images/%s/members/%s' % (image_fixture[1]['id'], TENANT3)) response = requests.get(path, headers=get_header(TENANT3)) self.assertEqual(200, response.status_code) body = jsonutils.loads(response.text) self.assertEqual('pending', body['status']) self.assertEqual(image_fixture[1]['id'], body['image_id']) self.assertEqual(TENANT3, body['member_id']) # Tenant 2, who not the owner cannot get status of image member path = self._url('/v2/images/%s/members/%s' % (image_fixture[1]['id'], TENANT3)) response = requests.get(path, headers=get_header('tenant2')) self.assertEqual(404, response.status_code) # Tenant 3 can change status of image member path = self._url('/v2/images/%s/members/%s' % (image_fixture[1]['id'], TENANT3)) body = jsonutils.dumps({'status': 'accepted'}) response = requests.put(path, headers=get_header(TENANT3), data=body) self.assertEqual(200, response.status_code) image_member = jsonutils.loads(response.text) self.assertEqual(image_fixture[1]['id'], image_member['image_id']) self.assertEqual(TENANT3, image_member['member_id']) self.assertEqual('accepted', image_member['status']) # Image list should contain 4 images for TENANT3 because status is # accepted path = self._url('/v2/images') response = requests.get(path, headers=get_header(TENANT3)) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(4, len(images)) # Tenant 3 invalid status change path = self._url('/v2/images/%s/members/%s' % (image_fixture[1]['id'], TENANT3)) body = jsonutils.dumps({'status': 'invalid-status'}) response = requests.put(path, headers=get_header(TENANT3), data=body) self.assertEqual(400, response.status_code) # Owner cannot change status of image path = self._url('/v2/images/%s/members/%s' % (image_fixture[1]['id'], TENANT3)) body = jsonutils.dumps({'status': 'accepted'}) response = requests.put(path, headers=get_header('tenant1'), data=body) self.assertEqual(403, response.status_code) # Add Image member for tenant2-private image path = self._url('/v2/images/%s/members' % image_fixture[3]['id']) body = jsonutils.dumps({'member': TENANT4}) response = requests.post(path, headers=get_header('tenant2'), data=body) self.assertEqual(200, response.status_code) image_member = jsonutils.loads(response.text) self.assertEqual(image_fixture[3]['id'], image_member['image_id']) self.assertEqual(TENANT4, image_member['member_id']) self.assertTrue('created_at' in image_member) self.assertTrue('updated_at' in image_member) # Add Image member to public image path = self._url('/v2/images/%s/members' % image_fixture[0]['id']) body = jsonutils.dumps({'member': TENANT2}) response = requests.post(path, headers=get_header('tenant1'), data=body) self.assertEqual(403, response.status_code) # Image tenant1-private's members list should contain 1 member path = self._url('/v2/images/%s/members' % image_fixture[1]['id']) response = requests.get(path, headers=get_header('tenant1')) self.assertEqual(200, response.status_code) body = jsonutils.loads(response.text) self.assertEqual(1, len(body['members'])) # Admin can see any members path = self._url('/v2/images/%s/members' % image_fixture[1]['id']) response = requests.get(path, headers=get_header('tenant1', 'admin')) self.assertEqual(200, response.status_code) body = jsonutils.loads(response.text) self.assertEqual(1, len(body['members'])) # Image members not found for private image not owned by TENANT 1 path = self._url('/v2/images/%s/members' % image_fixture[3]['id']) response = requests.get(path, headers=get_header('tenant1')) self.assertEqual(404, response.status_code) # Image members forbidden for public image path = self._url('/v2/images/%s/members' % image_fixture[0]['id']) response = requests.get(path, headers=get_header('tenant1')) self.assertEqual(403, response.status_code) # Image Member Cannot delete Image membership path = self._url('/v2/images/%s/members/%s' % (image_fixture[1]['id'], TENANT3)) response = requests.delete(path, headers=get_header(TENANT3)) self.assertEqual(403, response.status_code) # Delete Image member path = self._url('/v2/images/%s/members/%s' % (image_fixture[1]['id'], TENANT3)) response = requests.delete(path, headers=get_header('tenant1')) self.assertEqual(204, response.status_code) # Now the image has only no members path = self._url('/v2/images/%s/members' % image_fixture[1]['id']) response = requests.get(path, headers=get_header('tenant1')) self.assertEqual(200, response.status_code) body = jsonutils.loads(response.text) self.assertEqual(0, len(body['members'])) # Adding 11 image members should fail since configured limit is 10 path = self._url('/v2/images/%s/members' % image_fixture[1]['id']) for i in range(10): body = jsonutils.dumps({'member': str(uuid.uuid4())}) response = requests.post(path, headers=get_header('tenant1'), data=body) self.assertEqual(200, response.status_code) body = jsonutils.dumps({'member': str(uuid.uuid4())}) response = requests.post(path, headers=get_header('tenant1'), data=body) self.assertEqual(413, response.status_code) # Delete Image members not found for public image path = self._url('/v2/images/%s/members/%s' % (image_fixture[0]['id'], TENANT3)) response = requests.get(path, headers=get_header('tenant1')) self.assertEqual(404, response.status_code) self.stop_servers() class TestImageMembersWithRegistry(TestImageMembers): def setUp(self): super(TestImageMembersWithRegistry, self).setUp() self.api_server.data_api = ( 'glance.tests.functional.v2.registry_data_api') self.registry_server.deployment_flavor = 'trusted-auth' class TestQuotas(functional.FunctionalTest): def setUp(self): super(TestQuotas, self).setUp() self.cleanup() self.api_server.deployment_flavor = 'noauth' self.registry_server.deployment_flavor = 'trusted-auth' self.user_storage_quota = 100 self.start_servers(**self.__dict__.copy()) def _url(self, path): return 'http://127.0.0.1:%d%s' % (self.api_port, path) def _headers(self, custom_headers=None): base_headers = { 'X-Identity-Status': 'Confirmed', 'X-Auth-Token': '932c5c84-02ac-4fe5-a9ba-620af0e2bb96', 'X-User-Id': 'f9a41d13-0c13-47e9-bee2-ce4e8bfe958e', 'X-Tenant-Id': TENANT1, 'X-Roles': 'member', } base_headers.update(custom_headers or {}) return base_headers def _upload_image_test(self, data_src, expected_status): # Image list should be empty path = self._url('/v2/images') response = requests.get(path, headers=self._headers()) self.assertEqual(200, response.status_code) images = jsonutils.loads(response.text)['images'] self.assertEqual(0, len(images)) # Create an image (with a deployer-defined property) path = self._url('/v2/images') headers = self._headers({'content-type': 'application/json'}) data = jsonutils.dumps({'name': 'testimg', 'type': 'kernel', 'foo': 'bar', 'disk_format': 'aki', 'container_format': 'aki'}) response = requests.post(path, headers=headers, data=data) self.assertEqual(201, response.status_code) image = jsonutils.loads(response.text) image_id = image['id'] # upload data path = self._url('/v2/images/%s/file' % image_id) headers = self._headers({'Content-Type': 'application/octet-stream'}) response = requests.put(path, headers=headers, data=data_src) self.assertEqual(expected_status, response.status_code) # Deletion should work path = self._url('/v2/images/%s' % image_id) response = requests.delete(path, headers=self._headers()) self.assertEqual(204, response.status_code) def test_image_upload_under_quota(self): data = 'x' * (self.user_storage_quota - 1) self._upload_image_test(data, 204) def test_image_upload_exceed_quota(self): data = 'x' * (self.user_storage_quota + 1) self._upload_image_test(data, 413) def test_chunked_image_upload_under_quota(self): def data_gen(): yield 'x' * (self.user_storage_quota - 1) self._upload_image_test(data_gen(), 204) def test_chunked_image_upload_exceed_quota(self): def data_gen(): yield 'x' * (self.user_storage_quota + 1) self._upload_image_test(data_gen(), 413) class TestQuotasWithRegistry(TestQuotas): def setUp(self): super(TestQuotasWithRegistry, self).setUp() self.api_server.data_api = ( 'glance.tests.functional.v2.registry_data_api') self.registry_server.deployment_flavor = 'trusted-auth' ",,6623,128
openstack%2Fnova~master~I23e0ca58bd8c6a16bff5d36c5d108056e4135351,openstack/nova,master,I23e0ca58bd8c6a16bff5d36c5d108056e4135351,hardware: make get_constraints to return topology for hugepages,MERGED,2014-10-20 17:47:39.000000000,2014-12-18 12:40:22.000000000,2014-12-18 12:40:19.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7166}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-20 17:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0833786c0a83678aeb7aa6be9948855e8c96ba9d', 'message': 'compute: update hugepages usage from resource_tracker\n\nMakes resource_tracker to update memory pages usages.\n\nWork-item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 2, 'created': '2014-10-21 08:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b82f401c5422a67350ea5ef542c751900febb73d', 'message': 'compute: update hugepages usage from resource_tracker\n\nMakes resource_tracker to update memory pages usages.\n\nWork-item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 3, 'created': '2014-10-22 09:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e308c48a9b78521ff1adcc97f60e7b2b92170ba1', 'message': 'compute: update hugepages usage from resource_tracker\n\nMakes resource_tracker to update memory pages usages.\n\nWork-item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 4, 'created': '2014-10-28 13:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba662ce9b9caeded8344038b2b1c25cb7fede377', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state dat\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 5, 'created': '2014-10-28 15:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c5758db7323e2ac75d4e97c83d6df46f1f2fbbe', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state dat\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 6, 'created': '2014-10-29 14:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62b1f75e852655ba01b739029f5478cbd3212fa6', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state dat\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 7, 'created': '2014-10-29 15:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e60962c88625ab8b31f8756e05290b67e144e2f2', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state dat\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 8, 'created': '2014-10-29 16:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64b03ec4a8aa96e50eb899497e9d87c242e1a293', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state dat\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 9, 'created': '2014-10-29 22:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2cea8265b7a7f877f127893f53eb7d0666d31f3', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state dat\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 10, 'created': '2014-10-30 12:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d178446fc78feec60a0d77954f1c6b8596f8a694', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state dat\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 11, 'created': '2014-11-05 08:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6283aaf515e06e380f38720e0b548d16a3dd6f0', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 12, 'created': '2014-11-12 14:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9bc80e47db09966102610b0f58b2d00b2a3f7615', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 13, 'created': '2014-11-13 17:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/afeba65600e3405e7bf626e44415b4b108695920', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 14, 'created': '2014-11-14 08:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58770e8f5b864731098efd008ab939e0b833dde5', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 15, 'created': '2014-11-14 16:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd52cd16095a87d6325eea22e62d412bd3585b2d', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 16, 'created': '2014-12-03 13:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f83b51a0ea68ce51b5ea16b2f21a6e0b81ff162', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 17, 'created': '2014-12-04 14:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b94663fad6458e441269776b98adc3e07dfe5372', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 18, 'created': '2014-12-05 08:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7e3c6e43d36d68daa084a8fa11755ab62d27c31', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 19, 'created': '2014-12-08 17:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/77fb0ea0b0b34a03b20f44faf8385912a154eccb', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 20, 'created': '2014-12-08 17:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8917fd1f0120440cad19ae43689a16cc666ec320', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 21, 'created': '2014-12-09 08:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e18e70f38f298ac0936783767f2af278c02ca506', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 22, 'created': '2014-12-09 12:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0828197023705f77c1bae82a8b4cda7a884f5f56', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 23, 'created': '2014-12-10 13:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02fab6dc2d7c3d07338fcc6889a6eb2a8aa0afe8', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 24, 'created': '2014-12-10 14:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8577f0f4d7740c782a7c31223ced8bfe73089f17', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 25, 'created': '2014-12-10 15:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5307e1225fabfef0704c1b7b7b114d30e7ebd02c', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 26, 'created': '2014-12-10 16:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6980502683bdcf514b386038ca0e0ef8226c27ca', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 27, 'created': '2014-12-13 09:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4bd8a39569e9d58eed3502a0d01fcb0b272c3b31', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 28, 'created': '2014-12-13 10:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/61eb7241c37e18a152f9b275e3f650a9b6ca5707', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 29, 'created': '2014-12-14 13:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47ea7cd3d8ac621505e35d3048f28006920f4611', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 30, 'created': '2014-12-15 11:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30e0de4e184cafed560e7259131c86a17ec8d0c3', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 31, 'created': '2014-12-16 11:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/77184455cabbba27724f350c7286074b19622437', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}, {'number': 32, 'created': '2014-12-17 14:52:13.000000000', 'files': ['nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b0c65f531254a2b8d2d4fd99032cd218d6d326e7', 'message': 'hardware: make get_constraints to return topology for hugepages\n\nWhether a numa node is defined or not, if using hugepages we\nshould create an numa instance topology.\n\nWork-Item: Enhance libvirt driver to report available\n           large pages per NUMA node in the host state data\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351\n'}]",13,129683,b0c65f531254a2b8d2d4fd99032cd218d6d326e7,208,13,32,7730,,,0,"hardware: make get_constraints to return topology for hugepages

Whether a numa node is defined or not, if using hugepages we
should create an numa instance topology.

Work-Item: Enhance libvirt driver to report available
           large pages per NUMA node in the host state data

Partial-Implement: blueprint virt-driver-large-pages
Change-Id: I23e0ca58bd8c6a16bff5d36c5d108056e4135351
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/129683/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/resource_tracker.py'],1,0833786c0a83678aeb7aa6be9948855e8c96ba9d,bp/virt-driver-large-pages," if ""hugepages_topology"" not in resources: resources[""hugepages_topology""] = None # Calculate the hugepages usage if resources['hugepages_topology']: freepages = self.driver.get_free_pages() htopology = hardware.VirtNUMAHostPagesTopology.from_json( resources['hugepages_topology']) htopology = hardware.VirtNUMAHostPagesTopology.usage_from_host( htopology.cells, freepages) resources['hugepages_topology'] = htopology.to_json() ",,11,0
openstack%2Fheat~master~Ib09a46f2ca7825e4190c3fb8c7c1510e95688a10,openstack/heat,master,Ib09a46f2ca7825e4190c3fb8c7c1510e95688a10,Integration test for remote stack,MERGED,2014-12-12 13:10:54.000000000,2014-12-18 12:40:08.000000000,2014-12-18 12:40:07.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4715}, {'_account_id': 7193}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 8871}, {'_account_id': 13009}, {'_account_id': 13323}]","[{'number': 1, 'created': '2014-12-12 13:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/01c164c9e0b8a47fd10341f10b23daa4a991d306', 'message': 'Integration test for remote stack\n\nA test case that exercise the OS::Heat::Stack resource as part of the\nintegration tests.\n\nChange-Id: Ib09a46f2ca7825e4190c3fb8c7c1510e95688a10\n'}, {'number': 2, 'created': '2014-12-12 14:53:32.000000000', 'files': ['heat_integrationtests/functional/test_remote_stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/fdf41dafef3c6b4c1dcbbb7cbac841776eabf3fe', 'message': 'Integration test for remote stack\n\nA test case that exercise the OS::Heat::Stack resource as part of the\nintegration tests.\n\nChange-Id: Ib09a46f2ca7825e4190c3fb8c7c1510e95688a10\n'}]",4,141364,fdf41dafef3c6b4c1dcbbb7cbac841776eabf3fe,18,9,2,8246,,,0,"Integration test for remote stack

A test case that exercise the OS::Heat::Stack resource as part of the
integration tests.

Change-Id: Ib09a46f2ca7825e4190c3fb8c7c1510e95688a10
",git fetch https://review.opendev.org/openstack/heat refs/changes/64/141364/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/functional/test_remote_stack.py'],1,01c164c9e0b8a47fd10341f10b23daa4a991d306,remote-stack-integration-test,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging import six from heat_integrationtests.common import exceptions from heat_integrationtests.common import test from heatclient import exc LOG = logging.getLogger(__name__) class RemoteStackTest(test.HeatIntegrationTest): template = ''' heat_template_version: 2013-05-23 resources: my_stack: type: OS::Heat::Stack properties: context: region_name: RegionOne template: get_file: remote_stack.yaml outputs: key: value: {get_attr: [my_stack, outputs]} ''' remote_template = ''' heat_template_version: 2013-05-23 resources: random1: type: OS::Heat::RandomString outputs: remote_key: value: {get_attr: [random1, value]} ''' def setUp(self): super(RemoteStackTest, self).setUp() self.client = self.orchestration_client def test_remote_stack_alone(self): stack_id = self.stack_create(template=self.remote_template) expected_resources = {'random1': 'OS::Heat::RandomString'} self.assertEqual(expected_resources, self.list_resources(stack_id)) stack = self.client.stacks.get(stack_id) output_value = self._stack_output(stack, 'remote_key') self.assertEqual(32, len(output_value)) def test_stack_create(self): files = {'remote_stack.yaml': self.remote_template} stack_id = self.stack_create(files=files) expected_resources = {'my_stack': 'OS::Heat::Stack'} self.assertEqual(expected_resources, self.list_resources(stack_id)) stack = self.client.stacks.get(stack_id) output = self._stack_output(stack, 'key') parent_output_value = output['remote_key'] self.assertEqual(32, len(parent_output_value)) rsrc = self.client.resources.get(stack_id, 'my_stack') remote_id = rsrc.physical_resource_id rstack = self.client.stacks.get(remote_id) self.assertEqual(remote_id, rstack.id) remote_output_value = self._stack_output(rstack, 'remote_key') self.assertEqual(32, len(remote_output_value)) self.assertEqual(parent_output_value, remote_output_value) remote_resources = {'random1': 'OS::Heat::RandomString'} self.assertEqual(remote_resources, self.list_resources(remote_id)) def test_stack_create_bad_region(self): stack_name = 'stack_to_fail' tmpl_bad_region = self.template.replace('RegionOne', 'DARKHOLE') files = {'remote_stack.yaml': self.remote_template} kwargs = { 'stack_name': stack_name, 'template': tmpl_bad_region, 'files': files } ex = self.assertRaises(exc.HTTPBadRequest, self.stack_create, **kwargs) error_msg = ('ERROR: Cannot establish connection to Heat endpoint ' 'at region ""DARKHOLE"" due to ""publicURL endpoint for ' 'orchestration service in DARKHOLE region not found""') self.assertEqual(error_msg, six.text_type(ex)) def test_stack_resource_validation_fail(self): stack_name = 'stack_to_fail' tmpl_bad_format = self.remote_template.replace('resources', 'resource') files = {'remote_stack.yaml': tmpl_bad_format} kwargs = {'stack_name': stack_name, 'files': files} ex = self.assertRaises(exc.HTTPBadRequest, self.stack_create, **kwargs) error_msg = ('ERROR: Failed validating stack template using Heat ' 'endpoint at region ""RegionOne"" due to ' '""ERROR: The template section is invalid: resource""') self.assertEqual(error_msg, six.text_type(ex)) def test_stack_update(self): files = {'remote_stack.yaml': self.remote_template} stack_id = self.stack_create(files=files) expected_resources = {'my_stack': 'OS::Heat::Stack'} self.assertEqual(expected_resources, self.list_resources(stack_id)) rsrc = self.client.resources.get(stack_id, 'my_stack') physical_resource_id = rsrc.physical_resource_id rstack = self.client.stacks.get(physical_resource_id) self.assertEqual(physical_resource_id, rstack.id) remote_resources = {'random1': 'OS::Heat::RandomString'} self.assertEqual(remote_resources, self.list_resources(rstack.id)) # do an update update_template = self.remote_template.replace('random1', 'random2') files = {'remote_stack.yaml': update_template} self.update_stack(stack_id, self.template, files=files) # check if the remote stack is still there with the same ID self.assertEqual(expected_resources, self.list_resources(stack_id)) rsrc = self.client.resources.get(stack_id, 'my_stack') physical_resource_id = rsrc.physical_resource_id rstack = self.client.stacks.get(physical_resource_id) self.assertEqual(physical_resource_id, rstack.id) remote_resources = {'random2': 'OS::Heat::RandomString'} self.assertEqual(remote_resources, self.list_resources(rstack.id)) def test_stack_suspend_resume(self): files = {'remote_stack.yaml': self.remote_template} stack_id = self.stack_create(files=files) rsrc = self.client.resources.get(stack_id, 'my_stack') remote_id = rsrc.physical_resource_id # suspend stack self.client.actions.suspend(stack_id) self._wait_for_stack_status(stack_id, 'SUSPEND_COMPLETE') rsrc = self.client.stacks.get(remote_id) self.assertEqual('SUSPEND_COMPLETE', rsrc.stack_status) # resume stack self.client.actions.resume(stack_id) self._wait_for_stack_status(stack_id, 'RESUME_COMPLETE') rsrc = self.client.stacks.get(remote_id) self.assertEqual('RESUME_COMPLETE', rsrc.stack_status) ",,159,0
openstack%2Fneutron~master~I4093a3c8faf3da5790ee31fdebec0b8ed70f84f3,openstack/neutron,master,I4093a3c8faf3da5790ee31fdebec0b8ed70f84f3,Removed unused iso8601 dependency,MERGED,2014-12-16 10:53:05.000000000,2014-12-18 12:39:51.000000000,2014-12-18 12:39:49.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6635}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7743}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-16 10:53:05.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/074b3963e7baa7ee3331956573d24050141af9bb', 'message': 'Removed unused iso8601 dependency\n\nIt should have been removed when migrating to oslo.utils when we dropped\ntimeutils module from our tree.\n\nChange-Id: I4093a3c8faf3da5790ee31fdebec0b8ed70f84f3\n'}]",0,142060,074b3963e7baa7ee3331956573d24050141af9bb,39,25,1,9656,,,0,"Removed unused iso8601 dependency

It should have been removed when migrating to oslo.utils when we dropped
timeutils module from our tree.

Change-Id: I4093a3c8faf3da5790ee31fdebec0b8ed70f84f3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/142060/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,074b3963e7baa7ee3331956573d24050141af9bb,iso-remove,,iso8601>=0.1.9,0,1
openstack%2Fgnocchi~master~I476cd0eb02ea818707ec800244ed5c76e4cb9c75,openstack/gnocchi,master,I476cd0eb02ea818707ec800244ed5c76e4cb9c75,Allows to get aggregated measurements of metrics,MERGED,2014-10-02 08:43:04.000000000,2014-12-18 12:38:52.000000000,2014-12-18 12:38:50.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 10683}]","[{'number': 1, 'created': '2014-10-02 08:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/06f5c1319b41c61860ef10a8ea205d7347e9c224', 'message': 'Allows to get measurements with resource attributes\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n'}, {'number': 2, 'created': '2014-10-02 08:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/098ff1039f7223a6c0b68f629e0cc4951e5d3173', 'message': ""Allows to get aggregated measurements of entities\n\nThis allows to get aggregated measurements of entities\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     entities/cpu_util&aggregation=60\n\nto aggregated the measurements of entities that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 3, 'created': '2014-10-02 10:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/50c52cf9224b2218e0be37a541e628da4461cda0', 'message': ""Allows to get aggregated measurements of entities\n\nThis allows to get aggregated measurements of entities\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     entities/cpu_util&aggregation=60\n\nto aggregated the measurements of entities that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 4, 'created': '2014-10-07 08:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/90bb1d9c44a7b68ac5e864ba71b37f6c41747532', 'message': ""Allows to get aggregated measurements of entities\n\nThis allows to get aggregated measurements of entities\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     entities/cpu_util&aggregation=60\n\nto aggregated the measurements of entities that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 5, 'created': '2014-10-14 07:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d1a1b0cf63fe966173ac3d7fcfaa744870f4e8f3', 'message': ""Allows to get aggregated measurements of entities\n\nThis allows to get aggregated measurements of entities\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     entities/cpu_util&aggregation=60\n\nto aggregated the measurements of entities that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 6, 'created': '2014-10-17 09:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c202a1527fda63eec195c9c7f64d3f3acac3c44e', 'message': ""Allows to get aggregated measurements of entities\n\nThis allows to get aggregated measurements of entities\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     entities/cpu_util&aggregation=60\n\nto aggregated the measurements of entities that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 7, 'created': '2014-10-17 14:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c71f104a90d5affade173631d1a27f4180daa808', 'message': ""Allows to get aggregated measurements of entities\n\nThis allows to get aggregated measurements of entities\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     entities/cpu_util&aggregation=60\n\nto aggregated the measurements of entities that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 8, 'created': '2014-10-22 07:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/667e40e34abcba54aeff9031056d932bb31d78ed', 'message': ""Allows to get aggregated measurements of entities\n\nThis allows to get aggregated measurements of entities\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     entities/cpu_util&aggregation=60\n\nto aggregated the measurements of entities that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 9, 'created': '2014-12-04 12:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e8031971ee6c659c87a62d7935969d222e50923d', 'message': ""Allows to get aggregated measurements of metrics\n\nThis allows to get aggregated measurements of metrics\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     metrics/cpu_util&aggregation=max\n\nto aggregated the measurements of metrics that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 10, 'created': '2014-12-04 12:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/ba50e50c8c7acb97e6d017452f8bbe89722e2114', 'message': ""Allows to get aggregated measurements of metrics\n\nThis allows to get aggregated measurements of metrics\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     metrics/cpu_util&aggregation=max\n\nto aggregated the measurements of metrics that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 11, 'created': '2014-12-04 13:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/80c01bd9221cbcdf1135ac635681d058d5ee3386', 'message': ""Allows to get aggregated measurements of metrics\n\nThis allows to get aggregated measurements of metrics\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     metrics/cpu_util&aggregation=max\n\nto aggregated the measurements of metrics that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 12, 'created': '2014-12-09 11:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d2b666fea957b7eab2bacacdb0dcdc2d5363b641', 'message': ""Allows to get aggregated measurements of metrics\n\nThis allows to get aggregated measurements of metrics\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     metrics/cpu_util&aggregation=max\n\nto aggregated the measurements of metrics that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 13, 'created': '2014-12-09 12:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7b6bba884565ffa0bc9044242146747a6696ad47', 'message': ""Allows to get aggregated measurements of metrics\n\nThis allows to get aggregated measurements of metrics\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     metrics/cpu_util&aggregation=max\n\nto aggregated the measurements of metrics that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 14, 'created': '2014-12-09 12:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/485ea24871b290cf713847ca5905d5d033d944e2', 'message': ""Allows to get aggregated measurements of metrics\n\nThis allows to get aggregated measurements of metrics\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     metrics/cpu_util?aggregation=max\n\nto aggregated the measurements of metrics that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 15, 'created': '2014-12-10 10:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/9fc7ca738de501fcca0b731d6c513e0662bd1596', 'message': ""Allows to get aggregated measurements of metrics\n\nThis allows to get aggregated measurements of metrics\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     metrics/cpu_util?aggregation=max\n\nto aggregated the measurements of metrics that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 16, 'created': '2014-12-11 07:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/825b813afa7a54577712feeb9814034275f9fc18', 'message': ""Allows to get aggregated measurements of metrics\n\nThis allows to get aggregated measurements of metrics\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     metrics/cpu_util?aggregation=max\n\nto aggregated the measurements of metrics that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}, {'number': 17, 'created': '2014-12-11 15:37:42.000000000', 'files': ['gnocchi/rest/__init__.py', 'gnocchi/tests/base.py', 'requirements.txt', 'gnocchi/tests/test_carbonara.py', 'gnocchi/storage/__init__.py', 'gnocchi/storage/_carbonara.py', 'gnocchi/tests/test_storage.py', 'gnocchi/carbonara.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/546cb38bb3289ae8d1ee73633273684ea5e4928c', 'message': ""Allows to get aggregated measurements of metrics\n\nThis allows to get aggregated measurements of metrics\nvia a new kind of endpoint:\n\n  /v1/resource/instance/server_group=foobar∧display_name=ex/ \\\n     metrics/cpu_util?aggregation=max\n\nto aggregated the measurements of metrics that are instance with\nattributes server_group set to foobar and display_name set to ex\n\nOnly '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes\nare implemented.\n\nChange-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75\n""}]",66,125572,546cb38bb3289ae8d1ee73633273684ea5e4928c,58,6,17,2813,,,0,"Allows to get aggregated measurements of metrics

This allows to get aggregated measurements of metrics
via a new kind of endpoint:

  /v1/resource/instance/server_group=foobar∧display_name=ex/ \
     metrics/cpu_util?aggregation=max

to aggregated the measurements of metrics that are instance with
attributes server_group set to foobar and display_name set to ex

Only '=' attribute operator and '∧ (LOGICAL AND)' for joining attributes
are implemented.

Change-Id: I476cd0eb02ea818707ec800244ed5c76e4cb9c75
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/72/125572/16 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'gnocchi/tests/test_carbonara.py', 'gnocchi/storage/__init__.py', 'gnocchi/storage/swift.py', 'gnocchi/tests/test_storage.py', 'gnocchi/carbonara.py', 'tox.ini', 'gnocchi/storage/file.py', 'gnocchi/tests/test_rest.py']",9,06f5c1319b41c61860ef10a8ea205d7347e9c224,sileht/aggregated-measurement," def test_get_resource_named_entity_measure_aggregation(self): result = self.app.post_json(""/v1/entity"", params={""archive_policy"": ""medium""}) entity1 = json.loads(result.body) self.app.post_json(""/v1/entity/%s/measures"" % entity1['id'], params=[{""timestamp"": '2013-01-01 12:00:01', ""value"": 8}, {""timestamp"": '2013-01-01 12:00:02', ""value"": 16}]) result = self.app.post_json(""/v1/entity"", params={""archive_policy"": ""medium""}) entity2 = json.loads(result.body) self.app.post_json(""/v1/entity/%s/measures"" % entity2['id'], params=[{""timestamp"": '2013-01-01 12:00:01', ""value"": 0}, {""timestamp"": '2013-01-01 12:00:02', ""value"": 4}]) # NOTE(sileht): because the database is never cleaned between each test # we must ensure that the query will not match resources from an other # test, to achieve this we set a different server_group on each test. server_group = str(uuid.uuid4()) if self.resource_type == 'instance': self.attributes['server_group'] = server_group self.attributes['entities'] = {'foo': entity1['id']} self.app.post_json(""/v1/resource/"" + self.resource_type, params=self.attributes) self.attributes['id'] = str(uuid.uuid4()) self.attributes['entities'] = {'foo': entity2['id']} self.app.post_json(""/v1/resource/"" + self.resource_type, params=self.attributes) result = self.app.get(""/v1/resource/"" + self.resource_type + ""/server_group="" + server_group + ""∧display_name=myinstance"" + ""/entity/foo/measures?aggregation=max"", expect_errors=True) if self.resource_type == 'instance': self.assertEqual(200, result.status_code) measures = json.loads(result.body) self.assertEqual({'2013-01-01T12:00:00.000000': 16.0, '2013-01-01T00:00:00.000000': 16.0}, measures) else: self.assertEqual(400, result.status_code) result = self.app.get(""/v1/resource/"" + self.resource_type + ""/server_group="" + server_group + ""∧display_name=myinstance"" + ""/entity/foo/measures?aggregation=min"", expect_errors=True) if self.resource_type == 'instance': self.assertEqual(200, result.status_code) measures = json.loads(result.body) self.assertEqual({'2013-01-01T12:00:00.000000': 0.0, '2013-01-01T00:00:00.000000': 0.0}, measures) else: self.assertEqual(400, result.status_code) ",,297,10
openstack%2Fpbr~feature%2F0.10~Ideb71863b2ffa43d3677984670a7d20a76f0e9fc,openstack/pbr,feature/0.10,Ideb71863b2ffa43d3677984670a7d20a76f0e9fc,Only import sphinx during hook processing,ABANDONED,2014-12-17 17:04:46.000000000,2014-12-18 12:33:36.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 6482}, {'_account_id': 7687}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-12-17 17:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/1a4abff0de108c8a8cd130dcf7aa5691a2a3d375', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncrazy knockon effect once docutils is trying to be installed on a\nsystem with pbr installed.\n\nChange-Id: Ideb71863b2ffa43d3677984670a7d20a76f0e9fc\n""}, {'number': 2, 'created': '2014-12-17 17:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/8f252e77a0a108d78193e4e14b19d0c3fb8c3f2c', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncrazy knockon effect once docutils is trying to be installed on a\nsystem with pbr installed.\n\nCloses-bug: #1403510\nChange-Id: Ideb71863b2ffa43d3677984670a7d20a76f0e9fc\n""}, {'number': 3, 'created': '2014-12-17 17:08:42.000000000', 'files': ['pbr/packaging.py', 'pbr/hooks/commands.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/fb2afcb355fb56f471d3fab9a29148578da267a4', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncrazy knockon effect once docutils is trying to be installed on a\nsystem with pbr installed.\n\nCloses-bug: #1403510\nChange-Id: Ideb71863b2ffa43d3677984670a7d20a76f0e9fc\n""}]",1,142509,fb2afcb355fb56f471d3fab9a29148578da267a4,15,7,3,2,,,0,"Only import sphinx during hook processing

When pbr is imported to handle writing the egg_info file because of
the entry point, it's causing sphinx to get imported. This has a
crazy knockon effect once docutils is trying to be installed on a
system with pbr installed.

Closes-bug: #1403510
Change-Id: Ideb71863b2ffa43d3677984670a7d20a76f0e9fc
",git fetch https://review.opendev.org/openstack/pbr refs/changes/09/142509/2 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/packaging.py', 'pbr/hooks/commands.py']",2,1a4abff0de108c8a8cd130dcf7aa5691a2a3d375,bug/1403510, if packaging.get_sphinx_hooks():, if packaging.have_sphinx():,127,122
openstack%2Fheat~master~Iddb5024971f9f7882c5e46d879439182d2a92124,openstack/heat,master,Iddb5024971f9f7882c5e46d879439182d2a92124,Check stack adopt enable before adopting,MERGED,2014-11-27 10:26:09.000000000,2014-12-18 12:32:25.000000000,2014-12-18 12:32:24.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 11956}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-11-27 10:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/339bbed3dfa3b4a59eeca59f8da4506aadd7fcb7', 'message': ""Check stack adopt enable before adopting\n\nIf the configuration is disable, don't start to adopt.\n\nChange-Id: Iddb5024971f9f7882c5e46d879439182d2a92124\nCloses-Bug: #1396917\n""}, {'number': 2, 'created': '2014-12-03 01:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1943fb89b058a2c8134ef274189935d7719155c5', 'message': ""Check stack adopt enable before adopting\n\nIf the configuration is disable, don't start to adopt.\n\nChange-Id: Iddb5024971f9f7882c5e46d879439182d2a92124\nCloses-Bug: #1396917\n""}, {'number': 3, 'created': '2014-12-04 01:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/857697dab10547161c4ff61219daf8df8f577573', 'message': ""Check stack adopt enable before adopting\n\nIf the configuration is disabled, don't start to adopt.\n\nChange-Id: Iddb5024971f9f7882c5e46d879439182d2a92124\nCloses-Bug: #1396917\n""}, {'number': 4, 'created': '2014-12-05 03:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2b54ceecbd4c8282ebc4702b205ec843ad9b89d7', 'message': ""Check stack adopt enable before adopting\n\nIf the configuration is disabled, don't start to adopt.\n\nChange-Id: Iddb5024971f9f7882c5e46d879439182d2a92124\nCloses-Bug: #1396917\n""}, {'number': 5, 'created': '2014-12-05 06:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ab84384fb2086f293aed4147380fc448f27ecdc2', 'message': ""Check stack adopt enable before adopting\n\nIf the configuration is disabled, don't start to adopt.\n\nChange-Id: Iddb5024971f9f7882c5e46d879439182d2a92124\nCloses-Bug: #1396917\n""}, {'number': 6, 'created': '2014-12-10 04:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/559ed475ea4737ddec1b6529573f18f4661e9552', 'message': ""Check stack adopt enable before adopting\n\nIf the configuration is disabled, don't start to adopt.\n\nChange-Id: Iddb5024971f9f7882c5e46d879439182d2a92124\nCloses-Bug: #1396917\n""}, {'number': 7, 'created': '2014-12-12 06:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a2509444866bd3b326c220301ef6e0cad1318b20', 'message': ""Check stack adopt enable before adopting\n\nIf the configuration is disabled, don't start to adopt.\n\nChange-Id: Iddb5024971f9f7882c5e46d879439182d2a92124\nCloses-Bug: #1396917\n""}, {'number': 8, 'created': '2014-12-18 02:12:23.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0217812261482d238150e8dea4fc8fa56eb332a4', 'message': ""Check stack adopt enable before adopting\n\nIf the configuration is disabled, don't start to adopt.\n\nCo-Authored-by: huangtianhua <huangtianhua@huawei.com>\nCo-Authored-by: asalkeld <asalkeld@mirantis.com>\n\nChange-Id: Iddb5024971f9f7882c5e46d879439182d2a92124\nCloses-Bug: #1396917\n""}]",9,137570,0217812261482d238150e8dea4fc8fa56eb332a4,47,16,8,8289,,,0,"Check stack adopt enable before adopting

If the configuration is disabled, don't start to adopt.

Co-Authored-by: huangtianhua <huangtianhua@huawei.com>
Co-Authored-by: asalkeld <asalkeld@mirantis.com>

Change-Id: Iddb5024971f9f7882c5e46d879439182d2a92124
Closes-Bug: #1396917
",git fetch https://review.opendev.org/openstack/heat refs/changes/70/137570/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/engine/service.py']",2,339bbed3dfa3b4a59eeca59f8da4506aadd7fcb7,bug/1396917, if stack.adopt_stack_data and not cfg.CONF.enable_stack_adopt: msg = _('Adopting a stack when configuration is disable') raise exception.NotSupported(feature=msg) , if not cfg.CONF.enable_stack_adopt: raise exception.NotSupported(feature='Stack Adopt') ,16,3
openstack%2Fglance~master~I98dbb9535b14608cfb96a2320907c6bdb68e7c8e,openstack/glance,master,I98dbb9535b14608cfb96a2320907c6bdb68e7c8e,Imported Translations from Transifex,MERGED,2014-11-24 06:05:35.000000000,2014-12-18 12:32:15.000000000,2014-12-18 12:32:12.000000000,"[{'_account_id': 3}, {'_account_id': 6549}]","[{'number': 1, 'created': '2014-11-24 06:05:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7247733eb9abac01abef23e02e40bfe00029a30c', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 2, 'created': '2014-11-25 06:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/df7f73db6a9f01fa46c10bb9710531f0d211c07b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 3, 'created': '2014-11-26 06:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/34cfe15971bff93790e51d8b4eed4c6dacf995cb', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 4, 'created': '2014-11-27 06:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1fae74bc22d0d059d784632a3a9aa0dade2ba689', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 5, 'created': '2014-11-28 06:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fe79d547a00bc105c52849d091cc7a5203e0df26', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 6, 'created': '2014-11-29 06:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/81e9703507c657fd3fa1aab54e8c52825dbee9aa', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 7, 'created': '2014-11-30 06:02:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3421f35a5d0eade7c5056a1e331f0ba666fe7c6b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 8, 'created': '2014-12-01 06:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9883bfa40513b98fd02531a78ad8835d884daa4b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 9, 'created': '2014-12-02 06:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3134d0a2f321972c5d5b69eaa2a1f6424870ecc5', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 10, 'created': '2014-12-03 06:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e63a2fc41ac999f5b7bbca3ed06637da78ac0723', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 11, 'created': '2014-12-04 06:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5ad828f85f6a679cbb361430732b9ba4f9950d66', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 12, 'created': '2014-12-05 06:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/789c7111e41cd17993ede27a94e0ee74debda067', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 13, 'created': '2014-12-06 06:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6ca065450f41fa3114adea9f141a36d75287389c', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 14, 'created': '2014-12-07 06:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4fbbc5346cdc5ba114171b36da794b07dc891ce8', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 15, 'created': '2014-12-08 06:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c556bc30c09bfedd1a6251cc4f5b0c21d647c335', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 16, 'created': '2014-12-09 06:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/aece3ea54bbdc10fcc5e8b47d7240a28f06f3461', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 17, 'created': '2014-12-10 06:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/27b3c97a4601c7989b3d18437a47b435f5de2756', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 18, 'created': '2014-12-11 06:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f89ca2194769820c57c2e87c2e3ed27ca4e57756', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 19, 'created': '2014-12-12 06:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9e5f46a5d38e8399d57fcd1665ed600d216dd684', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 20, 'created': '2014-12-13 06:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9a1a410388446e169a422335c81b06b513039921', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 21, 'created': '2014-12-14 06:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3a12953a0b277c307ad1f3205a476bf3024af00f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 22, 'created': '2014-12-15 06:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ea0dfa5dbd0fd948e3fd5847a03c41ffb15954b0', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 23, 'created': '2014-12-16 06:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/acd05c6aa430d87100c3b82f83a0d23fa8354130', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 24, 'created': '2014-12-17 06:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/04aa4fbed7769e75c04459c95f4a0b81c25c5d7c', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}, {'number': 25, 'created': '2014-12-18 06:06:48.000000000', 'files': ['glance/locale/en_US/LC_MESSAGES/glance.po', 'glance/locale/pt_BR/LC_MESSAGES/glance-log-info.po', 'glance/locale/fr/LC_MESSAGES/glance-log-error.po', 'glance/locale/glance-log-error.pot', 'glance/locale/ko_KR/LC_MESSAGES/glance-log-error.po', 'glance/locale/glance-log-info.pot', 'glance/locale/en_GB/LC_MESSAGES/glance-log-warning.po', 'glance/locale/glance-log-warning.pot', 'glance/locale/glance.pot', 'glance/locale/pt_BR/LC_MESSAGES/glance-log-warning.po', 'glance/locale/en_GB/LC_MESSAGES/glance-log-info.po'], 'web_link': 'https://opendev.org/openstack/glance/commit/8a12bc28737203f0133efaaf9d8f1e44cc5d323a', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e\n'}]",0,136686,8a12bc28737203f0133efaaf9d8f1e44cc5d323a,54,2,25,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I98dbb9535b14608cfb96a2320907c6bdb68e7c8e
",git fetch https://review.opendev.org/openstack/glance refs/changes/86/136686/15 && git format-patch -1 --stdout FETCH_HEAD,"['glance/locale/fr/LC_MESSAGES/glance-log-error.po', 'glance/locale/fr/LC_MESSAGES/glance-log-warning.po']",2,7247733eb9abac01abef23e02e40bfe00029a30c,transifex/translations,"# Translations template for glance. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the glance project. # # Translators: # Maxime COQUEREL <max.coquerel@gmail.com>, 2014 msgid """" msgstr """" ""Project-Id-Version: Glance\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-11-24 06:05+0000\n"" ""PO-Revision-Date: 2014-11-23 21:13+0000\n"" ""Last-Translator: Maxime COQUEREL <max.coquerel@gmail.com>\n"" ""Language-Team: French (http://www.transifex.com/projects/p/glance/language/"" ""fr/)\n"" ""Language: fr\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1);\n"" #: glance/scrubber.py:217 #, python-format msgid ""Failed to find image to delete: %s"" msgstr ""Échec pour trouver l'image à supprimer: %s"" #: glance/scrubber.py:582 #, python-format msgid ""Unable to delete URI from image %s."" msgstr ""Impossible de supprimer URI depuis image %s."" #: glance/api/v1/images.py:707 #, python-format msgid """" ""Failed to activate image %s in registry. About to delete image bits from "" ""store and update status to 'killed'."" msgstr """" #: glance/api/v2/images.py:854 #, python-format msgid """" ""Could not find schema properties file %s. Continuing without custom "" ""properties"" msgstr """" ""Fichier de propriétés du schéma %s introuvable. Poursuivre dans les "" ""propriétés personnalisées"" #: glance/common/store_utils.py:62 #, python-format msgid ""Failed to delete image %s in store from URI"" msgstr ""Échec de suppression de l'image %s dans le store depuis URI"" #: glance/common/scripts/image_import/main.py:157 #, python-format msgid ""Task %(task_id)s failed with exception %(error)s"" msgstr ""Échec de la tache %(task_id)s avec l'exception %(error)s"" #: glance/db/sqlalchemy/api.py:71 msgid ""Deadlock detected. Retrying..."" msgstr ""Blocage détecté . Nouvelle tentative ..."" #: glance/db/sqlalchemy/api.py:321 msgid ""Id not in sort_keys; is sort_keys unique?"" msgstr ""ID absent de sort_keys ; sort_keys unique ?"" #: glance/db/sqlalchemy/metadata.py:239 #, python-format msgid ""Duplicate entry for values: %s"" msgstr ""Entrée en double pour les valeurs: %s"" #: glance/db/sqlalchemy/migrate_repo/versions/017_quote_encrypted_swift_credentials.py:91 #, python-format msgid ""Failed to decrypt location value for image %(image_id)s"" msgstr """" ""Échec pour décrypter la valeur de l'emplacement de l'image %(image_id)s "" #: glance/image_cache/__init__.py:71 #, python-format msgid """" ""Image cache driver '%(driver_name)s' failed to load. Got error: "" ""'%(import_err)s."" msgstr """" ""Echec de chargement du pilote de cache d'image '%(driver_name)s'. Erreur "" ""obtenue : '%(import_err)s."" #: glance/image_cache/__init__.py:92 #, python-format msgid """" ""Image cache driver '%(driver_module)s' failed to configure. Got error: "" ""'%(config_err)s"" msgstr """" ""Echec de configuration du pilote de cache d'image '%(driver_module)s'. "" ""Erreur obtenue : '%(config_err)s."" #: glance/image_cache/prefetcher.py:47 #, python-format msgid ""Image '%s' is not active. Not caching."" msgstr ""L'image '%s' n'est pas active. Pas de mise en cache."" #: glance/image_cache/prefetcher.py:52 #, python-format msgid ""No metadata found for image '%s'"" msgstr ""Métadonnées non trouvées pour l'image '%s'"" #: glance/image_cache/prefetcher.py:80 msgid ""Failed to successfully cache all images in queue."" msgstr ""Echec de la mise en cache de toutes les images en file d'attente."" #: glance/image_cache/drivers/sqlite.py:458 #, python-format msgid ""Failed to delete file %(path)s. Got error: %(e)s"" msgstr ""Echec pour supprimer le fichier %(path)s. Erreur: %(e)s"" #: glance/image_cache/drivers/sqlite.py:495 #: glance/image_cache/drivers/xattr.py:446 #, python-format msgid ""Cached image file '%s' doesn't exist, unable to delete"" msgstr """" ""Le fichier image mis en cache '%s' n'existe pas, suppression impossible"" ",,125,5
openstack%2Fdesignate~master~I7928ec26b507c2d46f91c79be2b68b508685f693,openstack/designate,master,I7928ec26b507c2d46f91c79be2b68b508685f693,DynECT: Fix error handling when creating domain,ABANDONED,2014-12-18 12:30:51.000000000,2014-12-18 12:31:56.000000000,,[],"[{'number': 1, 'created': '2014-12-18 12:30:51.000000000', 'files': ['designate/backend/impl_dynect.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/7c44cd7cedf25f72114dffcaab0eb2f28594bb3c', 'message': 'DynECT: Fix error handling when creating domain\n\nChange-Id: I7928ec26b507c2d46f91c79be2b68b508685f693\nCloses-Bug: #1398989\n'}]",0,142757,7c44cd7cedf25f72114dffcaab0eb2f28594bb3c,2,0,1,395,,,0,"DynECT: Fix error handling when creating domain

Change-Id: I7928ec26b507c2d46f91c79be2b68b508685f693
Closes-Bug: #1398989
",git fetch https://review.opendev.org/openstack/designate refs/changes/57/142757/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/backend/impl_dynect.py'],1,7c44cd7cedf25f72114dffcaab0eb2f28594bb3c,dynect-tests," msg = _LI(""Domain already exists, updating existing domain"" "" instead %s"") LOG.info(msg % domain['name']) break else: raise e"," msg = _LI( ""Domain already exists, updating existing domain instead %s"") LOG.info(msg % domain['name'])",6,3
openstack%2Fpbr~master~Ie84c1284a5f58a00883ba070b33f5d837a6a6f08,openstack/pbr,master,Ie84c1284a5f58a00883ba070b33f5d837a6a6f08,Check for git installation before using git.,ABANDONED,2014-12-18 11:56:36.000000000,2014-12-18 12:31:15.000000000,,[{'_account_id': 10068}],"[{'number': 1, 'created': '2014-12-18 11:56:36.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/11a670a86922ee55cb1ede2e7a7fa124f537942e', 'message': 'Check for git installation before using git.\n\nMake sure _get_version_from_git() does not call git-related\nfunctions if git is not present.\n\nChange-Id: Ie84c1284a5f58a00883ba070b33f5d837a6a6f08\nCloses-Bug: 1403842\n'}]",0,142738,11a670a86922ee55cb1ede2e7a7fa124f537942e,3,1,1,14385,,,0,"Check for git installation before using git.

Make sure _get_version_from_git() does not call git-related
functions if git is not present.

Change-Id: Ie84c1284a5f58a00883ba070b33f5d837a6a6f08
Closes-Bug: 1403842
",git fetch https://review.opendev.org/openstack/pbr refs/changes/38/142738/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,11a670a86922ee55cb1ede2e7a7fa124f537942e,bug/1403842, git_dir = None if _git_is_installed(): git_dir = _get_git_directory() if git_dir:, git_dir = _get_git_directory() if git_dir and _git_is_installed():,4,2
openstack%2Fpbr~master~I59fc27e31181a847237d812fb89f17b7fe975fb9,openstack/pbr,master,I59fc27e31181a847237d812fb89f17b7fe975fb9,Revert all of the semver patches,ABANDONED,2014-12-13 20:26:21.000000000,2014-12-18 12:30:48.000000000,,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-12-13 20:26:21.000000000', 'files': ['pbr/tests/test_version.py', 'pbr/packaging.py', 'doc/source/index.rst', 'pbr/testr_command.py', 'pbr/tests/testpackage/pbr_testpackage/__init__.py', 'pbr/tests/base.py', 'pbr/tests/test_packaging.py', 'doc/source/packagers.rst', 'pbr/find_package.py', 'pbr/tests/testpackage/setup.cfg', 'pbr/version.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/7bd49841c43fa7f80192640f91210848bb6c7b28', 'message': ""Revert all of the semver patches\n\nWe need to make a change to pbr version creation and make a release\nASAP. Since semver doesn't work yet, revert it. We'll come back to it\nwhen it works.\n\nChange-Id: I59fc27e31181a847237d812fb89f17b7fe975fb9\n""}]",0,141579,7bd49841c43fa7f80192640f91210848bb6c7b28,7,3,1,2,,,0,"Revert all of the semver patches

We need to make a change to pbr version creation and make a release
ASAP. Since semver doesn't work yet, revert it. We'll come back to it
when it works.

Change-Id: I59fc27e31181a847237d812fb89f17b7fe975fb9
",git fetch https://review.opendev.org/openstack/pbr refs/changes/79/141579/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/test_version.py', 'doc/source/index.rst', 'pbr/packaging.py', 'pbr/testr_command.py', 'pbr/tests/testpackage/pbr_testpackage/__init__.py', 'pbr/tests/base.py', 'pbr/tests/test_packaging.py', 'doc/source/packagers.rst', 'pbr/find_package.py', 'pbr/tests/testpackage/setup.cfg', 'pbr/version.py']",11,7bd49841c43fa7f80192640f91210848bb6c7b28,fix-the-world," self.release = None return provider.version return packaging.get_version(self.package) if self.release is None: self.release = self._get_version_from_pkg_resources() return self.release if self.version is None: parts = [] for part in self.release_string().split('.'): if part[0].isdigit(): parts.append(part) else: break self.version = ""."".join(parts) return self.version","import itertools import operator def _is_int(string): try: int(string) return True except ValueError: return False class SemanticVersion(object): """"""A pure semantic version independent of serialisation. See the pbr doc 'semver' for details on the semantics. """""" def __init__(self, major, minor=0, patch=0, prerelease_type=None, prerelease=None, dev_count=None, githash=None): """"""Create a SemanticVersion. :param major: Major component of the version. :param minor: Minor component of the version. Defaults to 0. :param patch: Patch level component. Defaults to 0. :param prerelease_type: What sort of prerelease version this is - one of a(alpha), b(beta) or rc(release candidate). :param prerelease: For prerelease versions, what number prerelease. Defaults to 0. :param dev_count: How many commits since the last release. :param githash: What tree hash is this version for. :raises: ValueError if both a prerelease version and dev_count or githash are supplied. This is because semver (see the pbr semver documentation) does not permit both a prerelease version and a dev marker at the same time. """""" self._major = major self._minor = minor self._patch = patch self._prerelease_type = prerelease_type self._prerelease = prerelease if self._prerelease_type and not self._prerelease: self._prerelease = 0 self._dev_count = dev_count self._githash = githash if prerelease_type is not None and dev_count is not None: raise ValueError( ""invalid version: cannot have prerelease and dev strings %s %s"" % (prerelease_type, dev_count)) def __eq__(self, other): if not isinstance(other, SemanticVersion): return False return self.__dict__ == other.__dict__ def __hash__(self): return sum(map(hash, self.__dict__.values())) def __lt__(self, other): """"""Compare self and other, another Semantic Version."""""" # NB(lifeless) this could perhaps be rewritten as # lt (tuple_of_one, tuple_of_other) with a single check for # the typeerror corner cases - that would likely be faster # if this ever becomes performance sensitive. if not isinstance(other, SemanticVersion): raise TypeError(""ordering to non-SemanticVersion is undefined"") this_tuple = (self._major, self._minor, self._patch) other_tuple = (other._major, other._minor, other._patch) if this_tuple < other_tuple: return True elif this_tuple > other_tuple: return False if self._prerelease_type: if other._prerelease_type: # Use the a < b < rc cheat this_tuple = (self._prerelease_type, self._prerelease) other_tuple = (other._prerelease_type, other._prerelease) return this_tuple < other_tuple elif other._dev_count: raise TypeError( ""ordering pre-release with dev builds is undefined"") else: return True elif self._dev_count: if other._dev_count: if self._dev_count < other._dev_count: return True elif self._dev_count > other._dev_count: return False elif self._githash == other._githash: # == it not < return False raise TypeError( ""same version with different hash has no defined order"") elif other._prerelease_type: raise TypeError( ""ordering pre-release with dev builds is undefined"") else: return True else: # This is not pre-release. # If the other is pre-release or dev, we are greater, which is ! < # If the other is not pre-release, we are equal, which is ! < return False def __le__(self, other): return self == other or self < other def __ge__(self, other): return not self < other def __gt__(self, other): return not self <= other def __ne__(self, other): return not self == other def __repr__(self): return ""pbr.version.SemanticVersion(%s)"" % self.release_string() @classmethod def from_pip_string(klass, version_string): """"""Create a SemanticVersion from a pip version string. This method will parse a version like 1.3.0 into a SemanticVersion. This method is responsible for accepting any version string that any older version of pbr ever created. Therefore: versions like 1.3.0a1 versions are handled, parsed into a canonical form and then output - resulting in 1.3.0.0a1. Pre pbr-semver dev versions like 0.10.1.3.g83bef74 will be parsed but output as 0.10.1.dev3.g83bef74. :raises ValueError: Never tagged versions sdisted by old pbr result in just the git hash, e.g. '1234567' which poses a substantial problem since they collide with the semver versions when all the digits are numerals. Such versions will result in a ValueError being thrown if any non-numeric digits are present. They are an exception to the general case of accepting anything we ever output, since they were never intended and would permanently mess up versions on PyPI if ever released - we're treating that as a critical bug that we ever made them and have stopped doing that. """""" input_components = version_string.split('.') # decimals first (keep pre-release and dev/hashes to the right) components = [c for c in input_components if c.isdigit()] digit_len = len(components) if digit_len == 0: raise ValueError(""Invalid version %r"" % version_string) elif digit_len < 3: if (digit_len < len(input_components) and input_components[digit_len][0].isdigit()): # Handle X.YaZ - Y is a digit not a leadin to pre-release. mixed_component = input_components[digit_len] last_component = ''.join(itertools.takewhile( lambda x: x.isdigit(), mixed_component)) components.append(last_component) input_components[digit_len:digit_len + 1] = [ last_component, mixed_component[len(last_component):]] digit_len += 1 components.extend([0] * (3 - digit_len)) components.extend(input_components[digit_len:]) major = int(components[0]) minor = int(components[1]) dev_count = None prerelease_type = None prerelease = None githash = None def _parse_type(segment): # Discard leading digits (the 0 in 0a1) isdigit = operator.methodcaller('isdigit') segment = ''.join(itertools.dropwhile(isdigit, segment)) isalpha = operator.methodcaller('isalpha') prerelease_type = ''.join(itertools.takewhile(isalpha, segment)) prerelease = segment[len(prerelease_type)::] return prerelease_type, int(prerelease) if _is_int(components[2]): patch = int(components[2]) else: # legacy version e.g. 1.2.0a1 (canonical is 1.2.0.0a1) # or 1.2.dev4.g1234 or 1.2.b4 patch = 0 components[2:2] = [0] remainder = components[3:] remainder_starts_with_int = False try: if remainder and int(remainder[0]): remainder_starts_with_int = True except ValueError: pass if remainder_starts_with_int: # old dev format - 0.1.2.3.g1234 dev_count = int(remainder[0]) else: if remainder and (remainder[0][0] == '0' or remainder[0][0] in ('a', 'b', 'r')): # Current RC/beta layout prerelease_type, prerelease = _parse_type(remainder[0]) remainder = remainder[1:] if remainder: component = remainder[0] if component.startswith('dev'): dev_count = int(component[3:]) elif component.startswith('g'): # git hash - so use a dev_count of 1 as we have to have one dev_count = 1 githash = component[1:] else: raise ValueError( 'Unknown remainder %r in %r' % (remainder, version_string)) if len(remainder) > 1: githash = remainder[1][1:] return SemanticVersion( major, minor, patch, prerelease_type=prerelease_type, prerelease=prerelease, dev_count=dev_count, githash=githash) def brief_string(self): """"""Return the short version minus any alpha/beta tags."""""" return ""%s.%s.%s"" % (self._major, self._minor, self._patch) def debian_string(self): """"""Return the version number to use when building a debian package. This translates the PEP440/semver precedence rules into Debian version sorting operators. """""" return self._long_version(""~"", ""+g"") def decrement(self, minor=False, major=False): """"""Return a decremented SemanticVersion. Decrementing versions doesn't make a lot of sense - this method only exists to support rendering of pre-release versions strings into serialisations (such as rpm) with no sort-before operator. The 9999 magic version component is from the spec on this - pbr-semver. :return: A new SemanticVersion object. """""" if self._patch: new_patch = self._patch - 1 new_minor = self._minor new_major = self._major else: new_patch = 9999 if self._minor: new_minor = self._minor - 1 new_major = self._major else: new_minor = 9999 if self._major: new_major = self._major - 1 else: new_major = 0 return SemanticVersion( new_major, new_minor, new_patch) def increment(self, minor=False, major=False): """"""Return an incremented SemanticVersion. The default behaviour is to perform a patch level increment. When incrementing a prerelease version, the patch level is not changed - the prerelease serial is changed (e.g. beta 0 -> beta 1). Incrementing non-pre-release versions will not introduce pre-release versions - except when doing a patch incremental to a pre-release version the new version will only consist of major/minor/patch. :param minor: Increment the minor version. :param major: Increment the major version. :return: A new SemanticVersion object. """""" if self._prerelease_type: new_prerelease_type = self._prerelease_type new_prerelease = self._prerelease + 1 new_patch = self._patch else: new_prerelease_type = None new_prerelease = None new_patch = self._patch + 1 if minor: new_minor = self._minor + 1 new_patch = 0 new_prerelease_type = None new_prerelease = None else: new_minor = self._minor if major: new_major = self._major + 1 new_minor = 0 new_patch = 0 new_prerelease_type = None new_prerelease = None else: new_major = self._major return SemanticVersion( new_major, new_minor, new_patch, new_prerelease_type, new_prerelease) def _long_version(self, pre_separator, hash_separator, rc_marker=""""): """"""Construct a long string version of this semver. :param pre_separator: What separator to use between components that sort before rather than after. If None, use . and lower the version number of the component to preserve sorting. (Used for rpm support) :param hash_separator: What separator to use to append the git hash. """""" if ((self._prerelease_type or self._dev_count) and pre_separator is None): segments = [self.decrement().brief_string()] pre_separator = ""."" else: segments = [self.brief_string()] if self._prerelease_type: segments.append( ""%s%s%s%s"" % (pre_separator, rc_marker, self._prerelease_type, self._prerelease)) if self._dev_count: segments.append(pre_separator) segments.append('dev') segments.append(self._dev_count) if self._githash: segments.append(hash_separator) segments.append(self._githash) return """".join(str(s) for s in segments) def release_string(self): """"""Return the full version of the package. This including suffixes indicating VCS status. """""" return self._long_version(""."", "".g"", ""0"") def rpm_string(self): """"""Return the version number to use when building an RPM package. This translates the PEP440/semver precedence rules into RPM version sorting operators. Because RPM has no sort-before operator (such as the ~ operator in dpkg), we show all prerelease versions as being versions of the release before. """""" return self._long_version(None, ""+g"") def to_dev(self, dev_count, githash): """"""Return a development version of this semver. :param dev_count: The number of commits since the last release. :param githash: The git hash of the tree with this version. """""" return SemanticVersion( self._major, self._minor, self._patch, dev_count=dev_count, githash=githash) def to_release(self): """"""Discard any pre-release or dev metadata. :return: A new SemanticVersion with major/minor/patch the same as this one. """""" return SemanticVersion(self._major, self._minor, self._patch) def version_tuple(self): """"""Present the version as a version_info tuple. For documentation on version_info tuples see the Python documentation for sys.version_info. Since semver and PEP-440 represent overlapping but not subsets of versions, we have to have some heuristic / mapping rules: - a/b/rc take precedence. - if there is no pre-release version the dev version is used. - serial is taken from the dev/a/b/c component. - final non-dev versions never get serials. """""" segments = [self._major, self._minor, self._patch] if self._prerelease_type: type_map = {'a': 'alpha', 'b': 'beta', 'rc': 'candidate', } segments.append(type_map[self._prerelease_type]) segments.append(self._prerelease) elif self._dev_count: segments.append('dev') segments.append(self._dev_count - 1) else: segments.append('final') segments.append(0) return tuple(segments) self._semantic = None result_string = provider.version result_string = packaging.get_version(self.package) return SemanticVersion.from_pip_string(result_string) return self.semantic_version().release_string() def semantic_version(self): """"""Return the SemanticVersion object for this version."""""" if self._semantic is None: self._semantic = self._get_version_from_pkg_resources() return self._semantic return self.semantic_version().brief_string()",67,1135
openstack%2Fhorizon~master~I11e8aa0c6538df3dc9b2f1c1b002a7d2e034b45c,openstack/horizon,master,I11e8aa0c6538df3dc9b2f1c1b002a7d2e034b45c,Imported Translations from Transifex,MERGED,2014-12-18 06:04:05.000000000,2014-12-18 12:28:23.000000000,2014-12-18 12:28:22.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-12-18 06:04:05.000000000', 'files': ['openstack_dashboard/locale/de/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3b0d9e850b65e47e0a76569906537898ba910239', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I11e8aa0c6538df3dc9b2f1c1b002a7d2e034b45c\n'}]",0,142677,3b0d9e850b65e47e0a76569906537898ba910239,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I11e8aa0c6538df3dc9b2f1c1b002a7d2e034b45c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/77/142677/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/locale/de/LC_MESSAGES/django.po'],1,3b0d9e850b65e47e0a76569906537898ba910239,transifex/translations,"""PO-Revision-Date: 2014-12-17 12:40+0000\n"" ""Last-Translator: Ettore Atalan <atalanttore@googlemail.com>\n""msgstr ""Volumentyp-Verschlüsselung erstellen""msgstr ""Volumentyp-Verschlüsselungsübersicht""msgstr ""Steuerungsort""msgstr ""Volumentyp ist nicht verschlüsselt.""msgstr ""Verschlüsselten Volumentyp erstellen""msgstr ""Einen verschlüsselten Volumentyp erstellen""msgstr ""Volumentyp-Verschlüsselungsdetails""msgstr ""Verschlüsselung erfolgreich erstellt für Volumentyp: %s""msgstr ""Netzwerkdetails: %(network_name)s""msgstr ""Volumensicherungsdetails: %(backup_name)s""","""PO-Revision-Date: 2014-12-17 04:14+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",12,12
openstack%2Fpbr~master~I1758a7afa1cab572590112567e0cac2920d94506,openstack/pbr,master,I1758a7afa1cab572590112567e0cac2920d94506,Make a PEP440-ish version for non-tagged repos,ABANDONED,2014-12-13 22:39:28.000000000,2014-12-18 12:27:00.000000000,,"[{'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2014-12-13 22:39:28.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/bab6479532fd9eb76acdda3bbfaa3ccae835eab7', 'message': 'Make a PEP440-ish version for non-tagged repos\n\nIf a repo has no tags, it produces a git short-sha, which can be\nconfusing.\n\nChange-Id: I1758a7afa1cab572590112567e0cac2920d94506\n'}]",0,141586,bab6479532fd9eb76acdda3bbfaa3ccae835eab7,4,2,1,2,,,0,"Make a PEP440-ish version for non-tagged repos

If a repo has no tags, it produces a git short-sha, which can be
confusing.

Change-Id: I1758a7afa1cab572590112567e0cac2920d94506
",git fetch https://review.opendev.org/openstack/pbr refs/changes/86/141586/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,bab6479532fd9eb76acdda3bbfaa3ccae835eab7,fix-the-world," raw_version = _run_git_command( if '.' not in raw_version: raw_version = ""0.0.0.%s+g%s"" % ( _get_revno(git_dir), raw_version) return raw_version", return _run_git_command(,5,1
openstack%2Fglance~stable%2Fjuno~I24b1f2d9298c247a4d3f703180d90989f1c00eff,openstack/glance,stable/juno,I24b1f2d9298c247a4d3f703180d90989f1c00eff,To prevent client use v2 patch api to handle file and swift location,ABANDONED,2014-12-17 11:03:33.000000000,2014-12-18 12:26:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6549}, {'_account_id': 8158}, {'_account_id': 9311}]","[{'number': 1, 'created': '2014-12-17 11:03:33.000000000', 'files': ['glance/location.py', 'glance/tests/functional/v1/test_copy_to_file.py', 'glance/tests/functional/v2/test_images.py', 'glance/tests/unit/test_store_location.py', 'glance/tests/unit/utils.py', 'glance/tests/unit/v1/test_api.py', 'glance/api/v1/images.py', 'glance/common/store_utils.py', 'glance/tests/unit/test_store_image.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/178e27c271fe98037219771253fe52ba4cf4b91f', 'message': 'To prevent client use v2 patch api to handle file and swift location\n\nThe change will be used to restrict client to download and delete any\nfile in glance-api server. The same resone and logic as what we did in\nv1:\nhttps://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429\n\nCloses-Bug: #1400966\nDocImpact\n\nNote: Even this change could fully resolve the problem for Glance, but\nwe still need to fix this issue from glance_store perspective\nseparatelly due to other projects can use the lib directly.\n\n(cherry picked from commit I72dbead3cb2dcb87f52658ddb880e26880cc229b)\n\nConflicts:\n\n\tglance/api/v1/images.py\n\tglance/location.py\n\tglance/tests/functional/v2/test_images.py\n\tglance/tests/unit/test_store_location.py\n\tglance/tests/unit/v1/test_api.py\n\nChange-Id: I24b1f2d9298c247a4d3f703180d90989f1c00eff\n'}]",0,142419,178e27c271fe98037219771253fe52ba4cf4b91f,4,4,1,5202,,,0,"To prevent client use v2 patch api to handle file and swift location

The change will be used to restrict client to download and delete any
file in glance-api server. The same resone and logic as what we did in
v1:
https://github.com/openstack/glance/blob/master/glance/api/v1/images.py#L429

Closes-Bug: #1400966
DocImpact

Note: Even this change could fully resolve the problem for Glance, but
we still need to fix this issue from glance_store perspective
separatelly due to other projects can use the lib directly.

(cherry picked from commit I72dbead3cb2dcb87f52658ddb880e26880cc229b)

Conflicts:

	glance/api/v1/images.py
	glance/location.py
	glance/tests/functional/v2/test_images.py
	glance/tests/unit/test_store_location.py
	glance/tests/unit/v1/test_api.py

Change-Id: I24b1f2d9298c247a4d3f703180d90989f1c00eff
",git fetch https://review.opendev.org/openstack/glance refs/changes/19/142419/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/location.py', 'glance/tests/functional/v1/test_copy_to_file.py', 'glance/tests/functional/v2/test_images.py', 'glance/tests/unit/test_store_location.py', 'glance/tests/unit/utils.py', 'glance/tests/unit/v1/test_api.py', 'glance/api/v1/images.py', 'glance/common/store_utils.py', 'glance/tests/unit/test_store_image.py']",9,178e27c271fe98037219771253fe52ba4cf4b91f,stable/juno,from glance.tests.unit import base as unit_test_baseclass TestImageFactory(unit_test_base.StoreClearingUnitTest):,class TestImageFactory(utils.BaseTestCase):,222,134
openstack%2Fmistral-extra~master~Ifcc3da6b01fd86caa047811eb56b8dc018a1d5d2,openstack/mistral-extra,master,Ifcc3da6b01fd86caa047811eb56b8dc018a1d5d2,"Adding README file for ""tenant statistics"" example",MERGED,2014-12-17 13:32:42.000000000,2014-12-18 12:24:10.000000000,2014-12-18 12:24:07.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-12-17 13:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/330d312c28d5dd0b39e39582dc2096a22ad275f3', 'message': 'Adding README file for ""tenant statistics"" example\n\nChange-Id: Ifcc3da6b01fd86caa047811eb56b8dc018a1d5d2\n'}, {'number': 2, 'created': '2014-12-18 10:02:35.000000000', 'files': ['examples/v2/tenant_statistics/README.md'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/d3be234d26561aa77dee1ff7d33ddf109b3ccbc4', 'message': 'Adding README file for ""tenant statistics"" example\n\nChange-Id: Ifcc3da6b01fd86caa047811eb56b8dc018a1d5d2\n'}]",3,142442,d3be234d26561aa77dee1ff7d33ddf109b3ccbc4,14,5,2,8731,,,0,"Adding README file for ""tenant statistics"" example

Change-Id: Ifcc3da6b01fd86caa047811eb56b8dc018a1d5d2
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/42/142442/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/v2/tenant_statistics/README.md'],1,330d312c28d5dd0b39e39582dc2096a22ad275f3,fix_readme,"Tenant statistics example (based on v2 API/DSL) =============================================== The example shows how Mistral can be used to gather information about OpenStack tenant. The workbook ""tenant_statistics"" contains two workflows that solve the same task: they send an email report containing a number of virtual machines, number of active virtual machines and number of networks. Workflow ""tenant_statistics_plain"" runs runs all its tasks sequentially one after another. Workflow ""tenant_statistics_join"" runs two tasks in parallel to gather tenant metrics, waits their completion using ""join"" workflow control and after that sends a report. To run the example: 1. Load workbook from tenant_statistics.yaml: mistral workbook-create tenant_statistics.yaml 1. Create input.json file containing workflow input parameters as follows: { ""to_email"": ""admin@my_domain.com"", ""from_email"": ""my_address@my_domain.com"", ""smtp_server"": ""smtp.my_domain.com:587"", ""smtp_password"": ""my_password"" } 1. Start workflow: mistral execution-create tenant_statistics.tenant_statistics_join input.json 1. Using execution id from the previous step wait for completion (workflow SUCCESS state): mistral execution-get <execution_id> 1. Check email inbox for the expected report. ",,36,0
openstack%2Fmistral-extra~master~I4f0dc4e50a2a232bc863c7d05992cdd54d079b10,openstack/mistral-extra,master,I4f0dc4e50a2a232bc863c7d05992cdd54d079b10,Fixing README files,MERGED,2014-12-17 13:06:23.000000000,2014-12-18 12:23:11.000000000,2014-12-18 12:23:10.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-12-17 13:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/bfa51d20f29b874292fd9cd613857c06c1983e6e', 'message': 'Fixing README files\n\n* Fixed root README files\n* Added detailed README file for OpenStack example\n\nChange-Id: I4f0dc4e50a2a232bc863c7d05992cdd54d079b10\n'}, {'number': 2, 'created': '2014-12-18 10:02:35.000000000', 'files': ['examples/v2/openstack/README.md', 'README.md'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/b1f316e5961fd27ec5aff0102ef019cfb6bec321', 'message': 'Fixing README files\n\n* Fixed root README files\n* Added detailed README file for OpenStack example\n\nChange-Id: I4f0dc4e50a2a232bc863c7d05992cdd54d079b10\n'}]",3,142436,b1f316e5961fd27ec5aff0102ef019cfb6bec321,10,5,2,8731,,,0,"Fixing README files

* Fixed root README files
* Added detailed README file for OpenStack example

Change-Id: I4f0dc4e50a2a232bc863c7d05992cdd54d079b10
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/36/142436/2 && git format-patch -1 --stdout FETCH_HEAD,"['examples/v2/openstack/README.md', 'README.md']",2,bfa51d20f29b874292fd9cd613857c06c1983e6e,fix_readme,"Contains Mistral examples. To see more detailed information about particular examples use README files located in corresponding folders under ""examples/"".","Contains example applications and additional tools for Mistral. Currently, there are three examples: #### Create VM Connects to OpenStack Nova and creates a VM with image and flavor id provided. See `examples/create_vm/README.md` for more. #### Run VM job Spins up a VM, deploys web server, sends request, reports by email if an error occurred. See `examples/vm_job/README.md` for more. #### Webhooks scheduling Starts local webserver and then assess it periodically using HTTP action. See `examples/webhooks/README.md` for more.",95,16
openstack%2Fmistral-extra~master~Ib46f41be63b9fbd0f82d37ed0a1f522a28bbdf07,openstack/mistral-extra,master,Ib46f41be63b9fbd0f82d37ed0a1f522a28bbdf07,"Adding README file for ""join"" example",MERGED,2014-12-17 14:06:41.000000000,2014-12-18 12:23:07.000000000,2014-12-18 12:23:06.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-12-17 14:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/cb1caec5d0853e0bfd6977867b305faabfa0f8f6', 'message': 'Adding README file for ""join"" example\n\nChange-Id: Ib46f41be63b9fbd0f82d37ed0a1f522a28bbdf07\n'}, {'number': 2, 'created': '2014-12-18 10:04:50.000000000', 'files': ['examples/v2/capabilities/join/README.md'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/c6a854782cbbca37568a494611a8d76de56c9f87', 'message': 'Adding README file for ""join"" example\n\nChange-Id: Ib46f41be63b9fbd0f82d37ed0a1f522a28bbdf07\n'}]",5,142449,c6a854782cbbca37568a494611a8d76de56c9f87,11,5,2,8731,,,0,"Adding README file for ""join"" example

Change-Id: Ib46f41be63b9fbd0f82d37ed0a1f522a28bbdf07
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/49/142449/2 && git format-patch -1 --stdout FETCH_HEAD,['examples/v2/capabilities/join/README.md'],1,cb1caec5d0853e0bfd6977867b305faabfa0f8f6,add_join_example_readme,"""join"" control examples (based on v2 API/DSL) ============================================= Workflow ""create_vm_with_volume"" demonstrates usage of ""join"" workflow control to synchronize multiple workflow routes. Specifically, it creates a virtual machine and Cinder volume in parallel, waits till their completion using ""join"" and attaches the volume to the newly created virtual machine. Note: Unlike some other examples this example doesn't use workbook concept. File ""create_vm_with_volume"" contains a workflow definition in the first place so in order to load the workflow ""mistral workflow-create"" CLI command must be used (not ""mistral workbook-create""). To run the example: 1. Load workflow create_vm_with_volume.yaml: mistral workflow-create create_vm_with_volume.yaml 1. Create input.json file containing workflow input parameters as follows: { ""server_name"": ""mistral_test_vm"", ""image_id"": ""aaacd887-5afa-4cb7-a33d-1ef0b72d21c4"", ""flavor_id"": ""2"", ""ssh_username"": ""ubuntu"", ""ssh_password"": ""my_pass"", ""volume_name"": ""mistral_test_volume"" } 1. Start workflow: mistral execution-create create_vm_with_volume input.json 1. Using execution id from the previous step wait for completion (workflow SUCCESS state): mistral execution-get <execution_id> 1. Make sure that a virtual machine and a volume have been created. It can be done by opening Horizon UI or using Nova client (python-novaclient). ",,40,0
openstack%2Fgnocchi~master~I23bc59768e35096670dcb2a5020f570d667bf4de,openstack/gnocchi,master,I23bc59768e35096670dcb2a5020f570d667bf4de,indexer: add delete_archive_policy,MERGED,2014-12-16 14:16:00.000000000,2014-12-18 12:12:53.000000000,2014-12-18 12:12:52.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-12-16 14:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/209867bcbd61b1bb84d6d933813f0e4ec8546836', 'message': 'indexer: add delete_archive_policy\n\nChange-Id: I23bc59768e35096670dcb2a5020f570d667bf4de\n'}, {'number': 2, 'created': '2014-12-16 16:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/44d48bcbf7433547aaed999ebb2006ac6330e35a', 'message': 'indexer: add delete_archive_policy\n\nChange-Id: I23bc59768e35096670dcb2a5020f570d667bf4de\n'}, {'number': 3, 'created': '2014-12-18 10:54:11.000000000', 'files': ['gnocchi/tests/test_indexer.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/419208c81fc10ac645110ed3653609fbb9ff934e', 'message': 'indexer: add delete_archive_policy\n\nChange-Id: I23bc59768e35096670dcb2a5020f570d667bf4de\n'}]",0,142113,419208c81fc10ac645110ed3653609fbb9ff934e,11,3,3,1669,,,0,"indexer: add delete_archive_policy

Change-Id: I23bc59768e35096670dcb2a5020f570d667bf4de
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/13/142113/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/test_indexer.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py']",3,209867bcbd61b1bb84d6d933813f0e4ec8546836,jd/simplify-metric," def delete_archive_policy(self, name): session = self.engine_facade.get_session() try: if session.query(ArchivePolicy).filter( ArchivePolicy.name == name).delete() == 0: raise indexer.NoSuchArchivePolicy(name) except exception.DBError as e: # TODO(jd) Add an exception in oslo.db to match foreign key # violations if isinstance(e.inner_exception, sqlalchemy.exc.IntegrityError): raise indexer.ArchivePolicyInUse(name) ",,56,0
openstack%2Fheat~master~I40b33aa3a6ab027cb77b9230c4e71421ca12b778,openstack/heat,master,I40b33aa3a6ab027cb77b9230c4e71421ca12b778,Sync policy from oslo-incubator,ABANDONED,2014-11-12 06:16:13.000000000,2014-12-18 11:57:42.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-11-12 06:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3908fbac3bad50bd6f85bd105de0ba8a2de3b007', 'message': 'Sync policy from oslo-incubator\n\nSync latest policy module at 32351ed8f6ecf7df6e25b660a1dd38b1493d261e to\nhelp remove it\'s dependency for oslo.serialization. It also fixes some\nbugs and introduce new option ""policy_dirs"", allow developer to add some\npolicy files in some directories.\n\nChange-Id: I40b33aa3a6ab027cb77b9230c4e71421ca12b778\n'}, {'number': 2, 'created': '2014-11-12 06:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eb7aac5e2aa783c2e1725d069d1b958478529516', 'message': 'Sync policy from oslo-incubator\n\nSync latest policy module at 32351ed8f6ecf7df6e25b660a1dd38b1493d261e to\nhelp remove it\'s dependency for jsonutils. It also fixes some\nbugs and introduce new option ""policy_dirs"", allow developer to add some\npolicy files in some directories.\n\nChange-Id: I40b33aa3a6ab027cb77b9230c4e71421ca12b778\n'}, {'number': 3, 'created': '2014-11-12 06:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7b6784ad7a37c7a96c838042b0bf0bca0685c761', 'message': 'Sync policy from oslo-incubator\n\nSync latest policy module at 32351ed8f6ecf7df6e25b660a1dd38b1493d261e to\nhelp remove it\'s dependency for jsonutils. It also fixes some\nbugs and introduces new option ""policy_dirs"", allow developer to add some\npolicy files in multiple directories.\n\nChange-Id: I40b33aa3a6ab027cb77b9230c4e71421ca12b778\n'}, {'number': 4, 'created': '2014-11-12 12:44:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/debb624d7946cf5281794126b77056d78690a8b7', 'message': 'Sync policy from oslo-incubator\n\nSync latest policy module at ddd63a7346bb57a47b0cd031608fc9475d68e241 to\nhelp remove it\'s dependency for jsonutils. It also fixes some\nbugs and introduces new option ""policy_dirs"", allow developer to add some\npolicy files in multiple directories.\n\nChange-Id: I40b33aa3a6ab027cb77b9230c4e71421ca12b778\n'}, {'number': 5, 'created': '2014-11-12 14:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/87de8d3e136cc277b9aec72c58ff3e0dbe949749', 'message': 'Sync policy from oslo-incubator\n\nSync latest policy module at ddd63a7346bb57a47b0cd031608fc9475d68e241 to\nhelp remove it\'s dependency for jsonutils. It also fixes some\nbugs and introduces new option ""policy_dirs"", allow developer to add some\npolicy files in multiple directories.\n\nChange-Id: I40b33aa3a6ab027cb77b9230c4e71421ca12b778\n'}, {'number': 6, 'created': '2014-12-08 02:19:01.000000000', 'files': ['heat/openstack/common/policy.py', 'heat/tests/test_common_context.py', 'heat/tests/test_common_policy.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ca9d5fd975a2687054cf0ed8c603f8bf031201ee', 'message': 'Sync policy from oslo-incubator\n\nSync latest policy module at ddd63a7346bb57a47b0cd031608fc9475d68e241 to\nhelp remove it\'s dependency for jsonutils. It also fixes some\nbugs and introduces new option ""policy_dirs"", allow developer to add some\npolicy files in multiple directories.\n\nChange-Id: I40b33aa3a6ab027cb77b9230c4e71421ca12b778\n'}]",2,133894,ca9d5fd975a2687054cf0ed8c603f8bf031201ee,28,8,6,9796,,,0,"Sync policy from oslo-incubator

Sync latest policy module at ddd63a7346bb57a47b0cd031608fc9475d68e241 to
help remove it's dependency for jsonutils. It also fixes some
bugs and introduces new option ""policy_dirs"", allow developer to add some
policy files in multiple directories.

Change-Id: I40b33aa3a6ab027cb77b9230c4e71421ca12b778
",git fetch https://review.opendev.org/openstack/heat refs/changes/94/133894/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/openstack/common/policy.py', 'heat/tests/test_common_context.py', 'heat/tests/test_common_policy.py']",3,3908fbac3bad50bd6f85bd105de0ba8a2de3b007,sync_policy," cfg.CONF.set_override('policy_file', filename) (base_policy.Enforcer._get_policy_path(cfg.CONF.policy_file). MultipleTimes().AndReturn(pf))", base_policy.Enforcer._get_policy_path().MultipleTimes().AndReturn(pf),54,20
openstack%2Fglance~master~Icfa40555280ce69766381b0abe7ef399b806f6a0,openstack/glance,master,Icfa40555280ce69766381b0abe7ef399b806f6a0,Adding Metadef Tag support,MERGED,2014-11-12 02:14:52.000000000,2014-12-18 11:42:58.000000000,2014-12-18 11:42:57.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 7665}, {'_account_id': 8871}, {'_account_id': 8959}, {'_account_id': 10383}, {'_account_id': 11356}, {'_account_id': 11391}, {'_account_id': 12395}, {'_account_id': 13717}]","[{'number': 1, 'created': '2014-11-12 02:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/afea924554a230bb50a9c072f3574ca0bbf89295', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\nCloses-Bug: 1391691\n'}, {'number': 2, 'created': '2014-11-12 20:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d3bda2031c29e3a28c58496e353e0dbd240155fd', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\nCloses-Bug: 1391691\n'}, {'number': 3, 'created': '2014-11-12 21:34:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/33897370d30265cd31aaace612def90da3adc4b6', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\nCloses-Bug: 1391691\n'}, {'number': 4, 'created': '2014-11-13 00:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4549d80231ecf1f25dea5857668e5d74b557efa5', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\nCloses-Bug: 1391691\n'}, {'number': 5, 'created': '2014-11-13 00:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a2c62055d70db30e46aed0b6c2cba48de9787191', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\nCloses-Bug: 1391691\n'}, {'number': 6, 'created': '2014-11-13 21:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/750bdd1ced990efb8363e448cd89ed033a18092c', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\nCloses-Bug: 1391691\n'}, {'number': 7, 'created': '2014-11-14 19:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c9a5ee82f58cd073f474293d633cfe620d96ce7f', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nThe bug partially implements https://review.openstack.org/#/c/128143/1/specs/kilo/metadefs-tags.rst\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\nCloses-Bug: 1391691\n'}, {'number': 8, 'created': '2014-11-14 19:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1574158f7a55bb933bb85f3a9964d9ddbe09179a', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nThe bug partially implements\nhttps://review.openstack.org/#/c/128143/1/specs/kilo/metadefs-tags.rst\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\nCloses-Bug: 1391691\n'}, {'number': 9, 'created': '2014-11-18 16:36:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c91bb955ffb1a7637665deda525ca22c1fa6f9e0', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements:\nhttps://review.openstack.org/#/c/128143\n(partial implementation)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 10, 'created': '2014-11-18 16:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bb358b4ba309190d4a01fcac56db889c8469a1ef', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 11, 'created': '2014-11-20 20:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8108f83c5594faefebddf9ed67eb2cd6a557d9f4', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 12, 'created': '2014-11-21 18:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a389b68fcfe3a779193b3eab828d5fb189e679ae', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 13, 'created': '2014-12-02 14:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6c3589ad7a101b250538fdfd15d12d1b69916b84', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 14, 'created': '2014-12-02 21:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/983d12d36d1b0ec2313ede31cac7a583a055f552', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 15, 'created': '2014-12-03 01:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/19479389a6b9a4265e19a9be852f91c00b657f70', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 16, 'created': '2014-12-04 02:04:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7a9e9a812a8a8b81007da093f43ba68ae097737e', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 17, 'created': '2014-12-05 19:12:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7edc6df6aebc7c58f75e29c1012678fc78975ea4', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 18, 'created': '2014-12-10 20:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/26112dfd894e0225d759b7147726bcca3e36a6b4', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 19, 'created': '2014-12-12 02:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/df0b25e805cbd679f02d732da810bba572a14b89', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 20, 'created': '2014-12-12 16:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d0b27e588179cb9c92d26fc1c5a2751e49b44468', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 21, 'created': '2014-12-12 17:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/04b5393f1b37148a9c7f02b9315bde4da3b80549', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 22, 'created': '2014-12-12 19:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c46ccd3d1f86f70dac50aacd7555cab5df3573aa', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 23, 'created': '2014-12-17 00:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/029dc9240b79af3ad962bffaf9e1ed07183ad787', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 24, 'created': '2014-12-17 00:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/16f90615ba6f049bc73a6b30a90bf043dd7ac8df', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 25, 'created': '2014-12-17 11:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/019fa932fb246bf73f5127ae97e79f33d7dfdb20', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://review.openstack.org/#/c/128143\n(partial implementation for metadef_tags table)\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}, {'number': 26, 'created': '2014-12-17 19:45:40.000000000', 'files': ['glance/api/authorization.py', 'glance/tests/unit/test_migrations.py', 'glance/common/exception.py', 'glance/db/simple/api.py', 'glance/db/sqlalchemy/api.py', 'glance/api/v2/model/metadef_tag.py', 'glance/api/v2/model/metadef_namespace.py', 'glance/domain/__init__.py', 'glance/api/policy.py', 'glance/api/v2/router.py', 'glance/api/v2/metadef_namespaces.py', 'glance/domain/proxy.py', 'glance/tests/etc/policy.json', 'glance/tests/functional/db/base_metadef.py', 'glance/tests/unit/test_db_metadef.py', 'etc/policy.json', 'glance/db/registry/api.py', 'glance/api/v2/metadef_tags.py', 'glance/db/sqlalchemy/models_metadef.py', 'glance/db/__init__.py', 'glance/db/sqlalchemy/metadef_api/tag.py', 'glance/gateway.py', 'glance/tests/unit/v2/test_metadef_resources.py', 'glance/db/sqlalchemy/metadata.py', 'glance/db/sqlalchemy/migrate_repo/versions/038_add_metadef_tags_table.py', 'glance/tests/functional/v2/test_metadef_tags.py', 'glance/api/v2/schemas.py', 'glance/db/sqlalchemy/metadef_api/namespace.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/c7fa300cc54b4b72d7922c017e95320236526b40', 'message': 'Adding Metadef Tag support\n\nAdding rest api and db support for CRUD operations on the new\nmetadef_tags table.\n\nImplements: https://blueprints.launchpad.net/glance/+spec/metadefs-tags\nDocImpact\n\nChange-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0\n'}]",131,133874,c7fa300cc54b4b72d7922c017e95320236526b40,117,12,26,10383,,,0,"Adding Metadef Tag support

Adding rest api and db support for CRUD operations on the new
metadef_tags table.

Implements: https://blueprints.launchpad.net/glance/+spec/metadefs-tags
DocImpact

Change-Id: Icfa40555280ce69766381b0abe7ef399b806f6a0
",git fetch https://review.opendev.org/openstack/glance refs/changes/74/133874/26 && git format-patch -1 --stdout FETCH_HEAD,"['glance/api/authorization.py', 'glance/common/exception.py', 'glance/db/simple/api.py', 'glance/db/sqlalchemy/api.py', 'glance/db/sqlalchemy/migrate_repo/versions/037_add_metadef_tags_table.py', 'glance/api/v2/model/metadef_tag.py', 'glance/api/v2/model/metadef_namespace.py', 'glance/domain/__init__.py', 'glance/api/policy.py', 'glance/api/v2/router.py', 'glance/api/v2/metadef_namespaces.py', 'glance/domain/proxy.py', 'glance/tests/functional/db/base_metadef.py', 'glance/tests/unit/test_db_metadef.py', 'glance/db/registry/api.py', 'glance/api/v2/metadef_tags.py', 'glance/db/sqlalchemy/models_metadef.py', 'glance/db/__init__.py', 'glance/db/sqlalchemy/metadef_api/tag.py', 'glance/gateway.py', 'glance/tests/unit/v2/test_metadef_resources.py', 'glance/tests/functional/v2/test_metadef_tags.py', 'glance/api/v2/schemas.py', 'glance/db/sqlalchemy/metadef_api/namespace.py']",24,afea924554a230bb50a9c072f3574ca0bbf89295,bp/metadef-tags," metadef_api.tag.delete_namespace_content( context, namespace_rec.id, session)",,1857,6
openstack%2Fmistral-extra~master~Ifa488b120f1fffa67cc26f684dec712e085bc29f,openstack/mistral-extra,master,Ifa488b120f1fffa67cc26f684dec712e085bc29f,Adding README.md to zabbix_machine_registration example,MERGED,2014-12-17 14:46:42.000000000,2014-12-18 11:39:48.000000000,2014-12-18 11:39:46.000000000,"[{'_account_id': 3}, {'_account_id': 8592}, {'_account_id': 8731}]","[{'number': 1, 'created': '2014-12-17 14:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/b1d4819fd4428491d0d8e4f9dc693fb3e96ecdd0', 'message': 'Adding README.md to zabbix_machine_registration example\n\nChange-Id: Ifa488b120f1fffa67cc26f684dec712e085bc29f\n'}, {'number': 2, 'created': '2014-12-17 14:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/32bdc3517150ab38f8e20801bccac9af5eeb3fc2', 'message': 'Adding README.md to zabbix_machine_registration example\n\nChange-Id: Ifa488b120f1fffa67cc26f684dec712e085bc29f\n'}, {'number': 3, 'created': '2014-12-18 11:05:10.000000000', 'files': ['examples/v2/services_registration/zabbix/README.md'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/ac5c5caddf547d750b8c39c9cdb57cf836d954d4', 'message': 'Adding README.md to zabbix_machine_registration example\n\nChange-Id: Ifa488b120f1fffa67cc26f684dec712e085bc29f\n'}]",3,142457,ac5c5caddf547d750b8c39c9cdb57cf836d954d4,10,3,3,7700,,,0,"Adding README.md to zabbix_machine_registration example

Change-Id: Ifa488b120f1fffa67cc26f684dec712e085bc29f
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/57/142457/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/v2/services_registration/zabbix/README.md'],1,b1d4819fd4428491d0d8e4f9dc693fb3e96ecdd0,,"Zabbix registration example (based on v2 API/DSL) ================================================= The example is created to demonstrate how Mistral can be used to interact with third party service's API through HTTP requests. In this specific example it is used Zabbix monitoring service. Mistral uses auth information provided by the user to retrieve Zabbix auth token. Then it creates host group (in terms of Zabbix), host with given machine IP and set simple check item - ping machine every 5 seconds. How to run ---------- 1. Load workbook from zabbix_machine_registration.yaml: mistral workbook-create zabbix_machine_registration.yaml 2. Create input.json file containing workflow input: { ""machine_ip"": [your machine IP], ""machine_port"": [your machine port], ""zabbix_host"": [Zabbix host], ""zabbix_username"": [Zabbix username], ""zabbix_password"": [Zabbix password], } 3. Run the execution: mistral execution-create zabbix.register_in_zabbix input.json 4. Using execution id from the previous step wait for completion (workflow SUCCESS state): mistral execution-get <execution_id> 5. Check your Zabbix host group. You will see new host group, one host in it and one simple check item.",,39,0
openstack%2Fcinder~stable%2Fjuno~I4db42d2521d7e6018f4f7ad0c4ab13441871675e,openstack/cinder,stable/juno,I4db42d2521d7e6018f4f7ad0c4ab13441871675e,NetApp 7mode NFS driver doesn't honor netapp_vfiler option,MERGED,2014-12-04 15:44:49.000000000,2014-12-18 11:38:54.000000000,2014-12-18 11:38:53.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 9366}, {'_account_id': 10621}]","[{'number': 1, 'created': '2014-12-04 15:44:49.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/options.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/dc008376dcdd772710e815aaf67f1adbfd1e8840', 'message': ""NetApp 7mode NFS driver doesn't honor netapp_vfiler option\n\nThis patch fixes the NetApp 7mode NFS driver to register and use\nthe netapp_vfiler option if it is configured in cinder.conf.\n\nDocImpact\nChange-Id: I4db42d2521d7e6018f4f7ad0c4ab13441871675e\nCloses-Bug: 1381716\n(inspired by commit: 504cb9f3d9954138fcb62d2fbb20b8505ca0f0ac)\n""}]",2,139093,dc008376dcdd772710e815aaf67f1adbfd1e8840,13,6,1,9366,,,0,"NetApp 7mode NFS driver doesn't honor netapp_vfiler option

This patch fixes the NetApp 7mode NFS driver to register and use
the netapp_vfiler option if it is configured in cinder.conf.

DocImpact
Change-Id: I4db42d2521d7e6018f4f7ad0c4ab13441871675e
Closes-Bug: 1381716
(inspired by commit: 504cb9f3d9954138fcb62d2fbb20b8505ca0f0ac)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/93/139093/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/cinder.conf.sample', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/options.py']",4,dc008376dcdd772710e815aaf67f1adbfd1e8840,bug/1381716, 'family of Data ONTAP operating in 7-Mode. Only use this ', 'family of Data ONTAP operating in 7-Mode and the ' 'storage protocol selected is iSCSI. Only use this ',132,27
openstack%2Fgnocchi~master~I24ddd20f72746e8d64a4ae30f8132afb3efecaac,openstack/gnocchi,master,I24ddd20f72746e8d64a4ae30f8132afb3efecaac,"indexer, rest: simplify metric model",MERGED,2014-12-12 14:30:31.000000000,2014-12-18 11:38:47.000000000,2014-12-18 11:38:47.000000000,"[{'_account_id': 3}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-12 14:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/db9d42a5ac65834cf26d22671e375c50510266e3', 'message': ""indexer, rest: simplify metric model\n\nThis change makes the metric to not be a 'resource' anymore. The\nmotivation behind that is simplification of the metric attribute to the\nbare minimal, and the reduction of the global resource table (making\nquerying faster).\n\nIt will also lead to RABC simplification on the metric/resource\nassociation later, as we'll be able to grant access to a metric if its\nassociated to a resource with the correct user_id/project_id (that is\nnot yet implemented).\n\nChange-Id: I24ddd20f72746e8d64a4ae30f8132afb3efecaac\n""}, {'number': 2, 'created': '2014-12-12 16:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4554a48fff81e375754fcbaec728335be94d98f5', 'message': ""indexer, rest: simplify metric model\n\nThis change makes the metric to not be a 'resource' anymore. The\nmotivation behind that is simplification of the metric attribute to the\nbare minimal, and the reduction of the global resource table (making\nquerying faster).\n\nIt will also lead to RABC simplification on the metric/resource\nassociation later, as we'll be able to grant access to a metric if its\nassociated to a resource with the correct user_id/project_id (that is\nnot yet implemented).\n\nChange-Id: I24ddd20f72746e8d64a4ae30f8132afb3efecaac\n""}, {'number': 3, 'created': '2014-12-18 10:54:11.000000000', 'files': ['gnocchi/tests/test_indexer.py', 'gnocchi/rest/__init__.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c1704a3e1ac704b35c516dd51d1e75556a263bd9', 'message': ""indexer, rest: simplify metric model\n\nThis change makes the metric to not be a 'resource' anymore. The\nmotivation behind that is simplification of the metric attribute to the\nbare minimal, and the reduction of the global resource table (making\nquerying faster).\n\nIt will also lead to RABC simplification on the metric/resource\nassociation later, as we'll be able to grant access to a metric if its\nassociated to a resource with the correct user_id/project_id (that is\nnot yet implemented).\n\nChange-Id: I24ddd20f72746e8d64a4ae30f8132afb3efecaac\n""}]",0,141386,c1704a3e1ac704b35c516dd51d1e75556a263bd9,10,2,3,1669,,,0,"indexer, rest: simplify metric model

This change makes the metric to not be a 'resource' anymore. The
motivation behind that is simplification of the metric attribute to the
bare minimal, and the reduction of the global resource table (making
querying faster).

It will also lead to RABC simplification on the metric/resource
association later, as we'll be able to grant access to a metric if its
associated to a resource with the correct user_id/project_id (that is
not yet implemented).

Change-Id: I24ddd20f72746e8d64a4ae30f8132afb3efecaac
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/86/141386/3 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/test_indexer.py', 'gnocchi/rest/__init__.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py', 'gnocchi/tests/test_rest.py']",5,db9d42a5ac65834cf26d22671e375c50510266e3,jd/simplify-metric,," def test_get_metric_with_concerned_user(self): result = self.app.post_json( ""/v1/metric"", params={ ""archive_policy"": ""low"", ""user_id"": FakeMemcache.USER_ID_2, ""project_id"": FakeMemcache.PROJECT_ID_2, }) with self.app.use_another_user(): self.app.get(result.headers['Location']) def test_get_metric_as_resource(self): result = self.app.post_json( ""/v1/metric"", params={""archive_policy"": ""medium""}, status=201) self.assertEqual(""application/json"", result.content_type) metric = json.loads(result.text) result = self.app.get(""/v1/resource/metric/%s"" % metric['id']) self.assertDictContainsSubset(metric, json.loads(result.text)) def test_list_metric_as_resource(self): result = self.app.post_json( ""/v1/metric"", params={""archive_policy"": ""medium""}, status=201) metric = json.loads(result.text) result = self.app.get(""/v1/resource/metric"") self.assertIn(metric['id'], [r['id'] for r in json.loads(result.text)]) def test_post_metric_as_resource(self): self.app.post_json(""/v1/resource/metric"", params={""archive_policy"": ""medium""}, status=403) def test_get_measure_with_a_concerned_user(self): result = self.app.post_json( ""/v1/metric"", params={ ""archive_policy"": ""low"", ""user_id"": FakeMemcache.USER_ID_2, ""project_id"": FakeMemcache.PROJECT_ID_2, }) metric = json.loads(result.text) self.app.post_json(""/v1/metric/%s/measures"" % metric['id'], params=[{""timestamp"": '2013-01-01 23:23:23', ""value"": 1234.2}]) with self.app.use_another_user(): ret = self.app.get(""/v1/metric/%s/measures"" % metric['id']) result = json.loads(ret.text) self.assertEqual( [[u'2013-01-01T00:00:00.000000', 86400.0, 1234.2], [u'2013-01-01T23:00:00.000000', 3600.0, 1234.2], [u'2013-01-01T23:20:00.000000', 300.0, 1234.2]], result) ",91,155
openstack%2Fgnocchi~master~Ieff38be31b49f42fdc220a7b64fec40ec890deb9,openstack/gnocchi,master,Ieff38be31b49f42fdc220a7b64fec40ec890deb9,rest: allow to list metrics via GET /v1/metric,MERGED,2014-12-10 10:35:23.000000000,2014-12-18 11:38:35.000000000,2014-12-18 11:38:35.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-10 10:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c4f27c4568b122b402d45ce89bfa61cb07376101', 'message': 'rest: allow to list metrics via GET /v1/metric\n\nChange-Id: Ieff38be31b49f42fdc220a7b64fec40ec890deb9\n'}, {'number': 2, 'created': '2014-12-11 13:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/41009921a4133d23ba19bc5be68fe98a9eb81cc5', 'message': 'rest: allow to list metrics via GET /v1/metric\n\nChange-Id: Ieff38be31b49f42fdc220a7b64fec40ec890deb9\n'}, {'number': 3, 'created': '2014-12-12 14:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/9afcdc05c74a63ab097ccb9fe59769964fdbc962', 'message': 'rest: allow to list metrics via GET /v1/metric\n\nChange-Id: Ieff38be31b49f42fdc220a7b64fec40ec890deb9\n'}, {'number': 4, 'created': '2014-12-18 10:54:11.000000000', 'files': ['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json', 'doc/source/rest.j2', 'doc/source/rest.yaml', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a19d5b8aa22d93c6b24dc2e0c4430a18cd0f4b29', 'message': 'rest: allow to list metrics via GET /v1/metric\n\nChange-Id: Ieff38be31b49f42fdc220a7b64fec40ec890deb9\n'}]",7,140636,a19d5b8aa22d93c6b24dc2e0c4430a18cd0f4b29,16,3,4,1669,,,0,"rest: allow to list metrics via GET /v1/metric

Change-Id: Ieff38be31b49f42fdc220a7b64fec40ec890deb9
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/36/140636/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json', 'gnocchi/tests/test_rest.py']",3,c4f27c4568b122b402d45ce89bfa61cb07376101,jd/simplify-metric," def test_list_metric(self): result = self.app.post_json( ""/v1/metric"", params={""archive_policy"": ""medium""}, status=201) metric = json.loads(result.text) result = self.app.get(""/v1/metric"") self.assertIn(metric['id'], [r['id'] for r in json.loads(result.text)]) def test_list_metric_as_resource(self): result = self.app.post_json( ""/v1/metric"", params={""archive_policy"": ""medium""}, status=201) metric = json.loads(result.text) result = self.app.get(""/v1/resource/metric"") self.assertIn(metric['id'], [r['id'] for r in json.loads(result.text)]) ",,36,0
openstack%2Fnova~master~I088bb6ba1a9c0492eb17669f53405e5af4cabbd9,openstack/nova,master,I088bb6ba1a9c0492eb17669f53405e5af4cabbd9,Add comments about Glance image format for XenAPI,ABANDONED,2014-10-20 11:33:59.000000000,2014-12-18 11:34:42.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9796}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-20 11:33:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89760a41c95812131c6127fbdba0d2a487bf3ad9', 'message': ""Add comments about Glance image format for XenAPI\n\nxapi plugin glance always uncompress the images while downloading\nimage to dom0, if image's format is not compressed, this leads to\nplugin glance hang, so add comments about this when using images\nfrom Glance.\n\nChange-Id: I088bb6ba1a9c0492eb17669f53405e5af4cabbd9\n""}, {'number': 2, 'created': '2014-10-22 02:08:14.000000000', 'files': ['nova/virt/xenapi/image/glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c6f011b54e012762adb0fa5cda1834307145ef25', 'message': ""Add comments about Glance image format for XenAPI\n\nxapi plugin glance always uncompress the images while downloading\nimage to dom0, if image's format is not compressed, this leads to\nplugin glance hang, so add comments about this when using images\nfrom Glance.\n\nChange-Id: I088bb6ba1a9c0492eb17669f53405e5af4cabbd9\n""}]",2,129580,c6f011b54e012762adb0fa5cda1834307145ef25,18,9,2,9796,,,0,"Add comments about Glance image format for XenAPI

xapi plugin glance always uncompress the images while downloading
image to dom0, if image's format is not compressed, this leads to
plugin glance hang, so add comments about this when using images
from Glance.

Change-Id: I088bb6ba1a9c0492eb17669f53405e5af4cabbd9
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/129580/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/xenapi/image/glance.py'],1,89760a41c95812131c6127fbdba0d2a487bf3ad9,add_image_warn,"# NOTE(gcb): Make sure images were created in Glance with compressed # format like *.vhd.tgz , because xapi plugin glance always uncompress # with command 'tar -zc', otherwise plugin glance will hang and not # return.",,4,0
openstack%2Ffuel-main~master~I07f0ac96b281d593a335793ba7331a8ab7dcc7d1,openstack/fuel-main,master,I07f0ac96b281d593a335793ba7331a8ab7dcc7d1,Add option to build containers in installed ISO,MERGED,2014-11-20 15:44:03.000000000,2014-12-18 11:32:54.000000000,2014-12-18 11:32:54.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 9977}, {'_account_id': 11081}, {'_account_id': 13505}]","[{'number': 1, 'created': '2014-11-20 15:44:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/aa04438a429f95c87826acccc4b4d7643c622c35', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 2, 'created': '2014-11-20 15:49:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3c85e135146b6cd68b1c37557ba57c7262d75ed3', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 3, 'created': '2014-11-20 18:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8bca63e7b889618d7b4db45938de40d80e4af03c', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 4, 'created': '2014-11-21 10:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/921026b915192369f06b686f070cdfda5ff09c54', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 5, 'created': '2014-11-21 10:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/53c6813cf716fd303f468afd4670474db5b7d5bb', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 6, 'created': '2014-11-21 11:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a5a9b9fd4ce0cee3ab54a37c1fddd16970bfb901', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 7, 'created': '2014-11-25 11:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/88ca0a5e085504472e1b4c25a774f3351e537749', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 8, 'created': '2014-11-27 10:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/701a66940fcf2b80b3d6b7ab01bbe7cbd0412fe1', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 9, 'created': '2014-12-01 10:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0c4f61194b6403347b73355d243b2a24d7e891ee', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 10, 'created': '2014-12-03 15:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/50d29912c3fcae5725b8acbd9864baf174b9051e', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 11, 'created': '2014-12-03 15:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6746b4e0aec96d4bccdf0ba510015b6c054d21ab', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 12, 'created': '2014-12-05 12:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a5b4f83dc4bade38d2a6913a8cc5120c29b11beb', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}, {'number': 13, 'created': '2014-12-17 12:04:40.000000000', 'files': ['fuelweb_test/models/environment.py', 'fuelweb_test/tests/test_admin_node.py', 'iso/module.mk', 'docker/module.mk', 'iso/bootstrap_admin_node.docker.sh', 'iso/ks.template', 'utils/simple_http_daemon.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/60da3730c455da8cc7421113c113366ccbb83b25', 'message': 'Add option to build containers in installed ISO\n\nAdd kernel parameter build_images=1 to enable Docker image\nbuilding, which creates /root/.build_images.\nThis in turn replaces the option to unpack prebuild Docker\nimages and load them.\n\nblueprint fuel-master-ci-tests\n\nChange-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1\n'}]",8,136031,60da3730c455da8cc7421113c113366ccbb83b25,68,10,13,7195,,,0,"Add option to build containers in installed ISO

Add kernel parameter build_images=1 to enable Docker image
building, which creates /root/.build_images.
This in turn replaces the option to unpack prebuild Docker
images and load them.

blueprint fuel-master-ci-tests

Change-Id: I07f0ac96b281d593a335793ba7331a8ab7dcc7d1
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/31/136031/7 && git format-patch -1 --stdout FETCH_HEAD,"['docker/module.mk', 'iso/bootstrap_admin_node.docker.sh', 'iso/ks.template']",3,aa04438a429f95c87826acccc4b4d7643c622c35,bp/fuel-master-ci-tests," [ -n ""$build_images"" ] && touch /root/.build_images",,34,18
openstack%2Ffuel-main~stable%2F6.0~I22cf260ea487588806061c25ab8c615b63fcf79f,openstack/fuel-main,stable/6.0,I22cf260ea487588806061c25ab8c615b63fcf79f,Add ability to deploy ceph_multinode_cluster test with neutron,MERGED,2014-12-17 17:09:40.000000000,2014-12-18 11:32:21.000000000,2014-12-18 11:32:21.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-17 17:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4567c492f3db86a2659d2b19412bef4da4bd2b53', 'message': 'Add ability to deploy ceph_multinode_cluster test with neutron\n\nChange-Id: I22cf260ea487588806061c25ab8c615b63fcf79f\nCloses-Bug: #1403578\n'}, {'number': 2, 'created': '2014-12-18 09:00:08.000000000', 'files': ['fuelweb_test/tests/test_ceph.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/358556ceb9af12c786a288670868d82ef6dcb9cd', 'message': 'Add ability to deploy ceph_multinode_cluster test with neutron\n\nChange-Id: I22cf260ea487588806061c25ab8c615b63fcf79f\nCloses-Bug: #1403578\n'}]",1,142511,358556ceb9af12c786a288670868d82ef6dcb9cd,14,5,2,10136,,,0,"Add ability to deploy ceph_multinode_cluster test with neutron

Change-Id: I22cf260ea487588806061c25ab8c615b63fcf79f
Closes-Bug: #1403578
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/11/142511/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_ceph.py'],1,4567c492f3db86a2659d2b19412bef4da4bd2b53,(detached,"from fuelweb_test.settings import NEUTRON_ENABLE if NEUTRON_ENABLE: settings = { ""net_provider"": 'neutron', ""net_segment_type"": ""vlan"" } ", if settings.OPENSTACK_RELEASE == settings.OPENSTACK_RELEASE_REDHAT: raise SkipTest() ,7,3
openstack%2Ffuel-main~master~I763a76cf44a8ba69be4621375c782431eccaaf55,openstack/fuel-main,master,I763a76cf44a8ba69be4621375c782431eccaaf55,"Default showmenu=yes, add workaround for VirtualBox",MERGED,2014-12-17 11:57:48.000000000,2014-12-18 11:31:44.000000000,2014-12-18 11:31:43.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 7195}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 12866}]","[{'number': 1, 'created': '2014-12-17 11:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d82bcccc7f66a759a44f2747df22edbce83360eb', 'message': 'Default showmenu=yes, add workaround for VirtualBox\n\nChange-Id: I763a76cf44a8ba69be4621375c782431eccaaf55\nCloses-Bug: #1402519\n'}, {'number': 2, 'created': '2014-12-17 15:48:49.000000000', 'files': ['virtualbox/actions/master-node-create-and-install.sh', 'virtualbox/config.sh', 'virtualbox/functions/product.sh', 'iso/isolinux/isolinux.cfg'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6eef8ae834cebcd25424c9bf44736310664f336a', 'message': 'Default showmenu=yes, add workaround for VirtualBox\n\nChange-Id: I763a76cf44a8ba69be4621375c782431eccaaf55\nCloses-Bug: #1402519\n'}]",0,142427,6eef8ae834cebcd25424c9bf44736310664f336a,16,9,2,7195,,,0,"Default showmenu=yes, add workaround for VirtualBox

Change-Id: I763a76cf44a8ba69be4621375c782431eccaaf55
Closes-Bug: #1402519
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/27/142427/2 && git format-patch -1 --stdout FETCH_HEAD,"['virtualbox/config.sh', 'virtualbox/functions/product.sh', 'iso/isolinux/isolinux.cfg']",3,d82bcccc7f66a759a44f2747df22edbce83360eb,bug/1402519, append initrd=initrd.img biosdevname=0 ks=cdrom:/ks.cfg ip=10.20.0.2 gw=10.20.0.1 dns1=10.20.0.1 netmask=255.255.255.0 hostname=fuel.domain.tld showmenu=yes, append initrd=initrd.img biosdevname=0 ks=cdrom:/ks.cfg ip=10.20.0.2 gw=10.20.0.1 dns1=10.20.0.1 netmask=255.255.255.0 hostname=fuel.domain.tld showmenu=no,46,1
openstack%2Ffuel-main~master~I22cf260ea487588806061c25ab8c615b63fcf79f,openstack/fuel-main,master,I22cf260ea487588806061c25ab8c615b63fcf79f,Add ability to deploy ceph_multinode_cluster test with neutron,MERGED,2014-12-17 16:53:18.000000000,2014-12-18 11:20:43.000000000,2014-12-18 11:20:43.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12129}]","[{'number': 1, 'created': '2014-12-17 16:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9c5ceba72a21b49a43f31437330ac99567dba7b8', 'message': 'Add ability to deploy ceph_multinode_cluster test with neutron\n\nChange-Id: I22cf260ea487588806061c25ab8c615b63fcf79f\nCloses-Bug: #1403578\n'}, {'number': 2, 'created': '2014-12-17 16:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/054401db50094944d90ab87480bd34b71fc38d1d', 'message': 'Add ability to deploy ceph_multinode_cluster test with neutron\n\nChange-Id: I22cf260ea487588806061c25ab8c615b63fcf79f\nCloses-Bug: #1403578\n'}, {'number': 3, 'created': '2014-12-17 17:02:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c8cbe5221a91243d8cc18aabe8e05d8f36380f53', 'message': 'Add ability to deploy ceph_multinode_cluster test with neutron\n\nChange-Id: I22cf260ea487588806061c25ab8c615b63fcf79f\nCloses-Bug: #1403578\n'}, {'number': 4, 'created': '2014-12-17 17:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/63d2ca88691f4df5d6e29e2755209416f14b1557', 'message': 'Add ability to deploy ceph_multinode_cluster test with neutron\n\nChange-Id: I22cf260ea487588806061c25ab8c615b63fcf79f\nCloses-Bug: #1403578\n'}, {'number': 5, 'created': '2014-12-18 08:55:00.000000000', 'files': ['fuelweb_test/tests/test_ceph.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4c8043ee6db4c09d51bfedbefef41cb16a756f7f', 'message': 'Add ability to deploy ceph_multinode_cluster test with neutron\n\nChange-Id: I22cf260ea487588806061c25ab8c615b63fcf79f\nCloses-Bug: #1403578\n'}]",1,142502,4c8043ee6db4c09d51bfedbefef41cb16a756f7f,25,6,5,10136,,,0,"Add ability to deploy ceph_multinode_cluster test with neutron

Change-Id: I22cf260ea487588806061c25ab8c615b63fcf79f
Closes-Bug: #1403578
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/02/142502/4 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_ceph.py'],1,9c5ceba72a21b49a43f31437330ac99567dba7b8,addNeutronToCeph," if settings.NEUTRON_ENABLE: settings = { ""net_provider"": 'neutron', ""net_segment_type"": ""vlan"" } ",,6,0
openstack%2Fopenstack-ansible~master~Iabce466018d3895f61dc736087a14b15af08a35b,openstack/openstack-ansible,master,Iabce466018d3895f61dc736087a14b15af08a35b,Add swift to the all-in-one build check,MERGED,2014-12-12 10:52:40.000000000,2014-12-18 11:05:34.000000000,2014-12-18 09:40:25.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}, {'_account_id': 12892}]","[{'number': 1, 'created': '2014-12-12 10:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5258cfd5405966e4a13f19844d9ff512fe60cc9a', 'message': '[WIP] Add swift to the all-in-one build check (do not merge)\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity and has a sprinkle of refactoring for improved\nhealth and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 2, 'created': '2014-12-12 11:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2e7d68bd8f724c28b5353770a34454f7b834dd78', 'message': '[WIP] Add swift to the all-in-one build check (do not merge)\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity, removes br-snet as it is unused,and has a sprinkle\nof refactoring for improved health and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 3, 'created': '2014-12-12 11:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/dd73b78feb5e3e6be591b106bbd1c4369f15cdf9', 'message': '[WIP] Add swift to the all-in-one build check (do not merge)\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity, removes br-snet as it is unused,and has a sprinkle\nof refactoring for improved health and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 4, 'created': '2014-12-12 11:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ae41389baa2f0efe700ae8a8eee42875037296a3', 'message': '[WIP] Add swift to the all-in-one build check (do not merge)\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity, removes br-snet as it is unused,and has a sprinkle\nof refactoring for improved health and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 5, 'created': '2014-12-12 13:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/83ffcda5864314a3cc9080c7f79d20969b306224', 'message': '[WIP] Add swift to the all-in-one build check (do not merge)\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity, removes br-snet as it is unused,and has a sprinkle\nof refactoring for improved health and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 6, 'created': '2014-12-16 09:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e228e027713b69578f4644bab451c9bd3028d500', 'message': '[WIP] Add swift to the all-in-one build check (do not merge)\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity, removes br-snet as it is unused, configures glance\nto use swift, and has a sprinkle of refactoring for improved health and\nhappiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 7, 'created': '2014-12-16 11:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5b6a6d6a53dcd36a0e45c5f04388c2ce12daeb7c', 'message': 'Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity, removes br-snet as it is unused, configures glance\nto use swift, and has a sprinkle of refactoring for improved health and\nhappiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 8, 'created': '2014-12-16 11:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f591193cc7622cf53123a980c7b2a42cde5471c6', 'message': 'Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity, removes br-snet as it is unused, configures glance\nto use swift, and has a sprinkle of refactoring for improved health and\nhappiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 9, 'created': '2014-12-16 13:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a477c55f5111081e8e4ee78786554daee8bc31e2', 'message': 'Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity, removes br-snet as it is unused, configures glance\nto use swift, and has a sprinkle of refactoring for improved health and\nhappiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 10, 'created': '2014-12-16 16:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bcd87cd057836a04fbfacad024c814b29009e89f', 'message': 'Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity, removes br-snet as it is unused, configures glance\nto use swift, and has a sprinkle of refactoring for improved health and\nhappiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 11, 'created': '2014-12-16 17:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d7f7e9e55ae877845e24f1bd49830e9979e3036a', 'message': 'Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity, removes br-snet as it is unused, configures glance\nto use swift, and has a sprinkle of refactoring for improved health and\nhappiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 12, 'created': '2014-12-16 20:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/590ec2e29ab22b003d42c1343eb3c70fe48bc9d6', 'message': 'Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. It also adds comments to various parts of the check\nscript for clarity, removes br-snet as it is unused, configures glance\nto use swift, and has a sprinkle of refactoring for improved health and\nhappiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n'}, {'number': 13, 'created': '2014-12-16 20:17:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/64290538d359affa4c94f19a58861551db988e70', 'message': ""Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. The script will deploy swift and configure glance to\nuse swift by default, but this can be disabled by setting the\nenvironment variable DEPLOY_SWIFT to be any value other than 'yes'.\n\nThis patch also adds comments to various parts of the check script for\nclarity, removes br-snet as it is unused, and has a sprinkle of\nrefactoring for improved health and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n""}, {'number': 14, 'created': '2014-12-16 20:40:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/37ded645e9660b0425f0578377b673d742e27e47', 'message': ""Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. The script will deploy swift and configure glance to\nuse swift by default, but this can be disabled by setting the\nenvironment variable DEPLOY_SWIFT to be any value other than 'yes'.\n\nThis patch also adds comments to various parts of the check script for\nclarity, removes br-snet as it is unused, and has a sprinkle of\nrefactoring for improved health and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n""}, {'number': 15, 'created': '2014-12-17 12:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/07606849cf31d833429b5a741a8b90b97f837e0a', 'message': ""Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. The script will deploy swift and configure glance to\nuse swift by default, but this can be disabled by setting the\nenvironment variable DEPLOY_SWIFT to be any value other than 'yes'.\n\nThis patch also adds comments to various parts of the check script for\nclarity, removes br-snet as it is unused, and has a sprinkle of\nrefactoring for improved health and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n""}, {'number': 16, 'created': '2014-12-17 12:34:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/281f0bc227b2238a97104f4f28fed7a6f5f2aabb', 'message': ""Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. The script will deploy swift and configure glance to\nuse swift by default, but this can be disabled by setting the\nenvironment variable DEPLOY_SWIFT to be any value other than 'yes'.\n\nThis patch also adds comments to various parts of the check script for\nclarity, removes br-snet as it is unused, and has a sprinkle of\nrefactoring for improved health and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n""}, {'number': 17, 'created': '2014-12-17 12:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f520aa6025c43b539f7027dc181bf9cab87009e5', 'message': ""Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. The script will deploy swift and configure glance to\nuse swift by default, but this can be disabled by setting the\nenvironment variable DEPLOY_SWIFT to be any value other than 'yes'.\n\nThis patch also adds comments to various parts of the check script for\nclarity, removes br-snet as it is unused, and has a sprinkle of\nrefactoring for improved health and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n""}, {'number': 18, 'created': '2014-12-17 17:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/00dc2e826b08f54286f0cd9d8972f3e4aa766985', 'message': ""Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. The script will deploy swift and configure glance to\nuse swift by default, but this can be disabled by setting the\nenvironment variable DEPLOY_SWIFT to be any value other than 'yes'.\n\nThis patch also adds comments to various parts of the check script for\nclarity, removes br-snet as it is unused, and has a sprinkle of\nrefactoring for improved health and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n""}, {'number': 19, 'created': '2014-12-17 18:36:16.000000000', 'files': ['scripts/os-ansible-aio-check.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ffda5b7da7bd8256329f74cbca358ca38b9ba316', 'message': ""Add swift to the all-in-one build check\n\nThis patch adds swift to the all-in-one build check used for testing\nand gate checks. The script will deploy swift and configure glance to\nuse swift by default, but this can be disabled by setting the\nenvironment variable DEPLOY_SWIFT to be any value other than 'yes'.\n\nThis patch also adds comments to various parts of the check script for\nclarity, removes br-snet as it is unused, and has a sprinkle of\nrefactoring for improved health and happiness.\n\nChange-Id: Iabce466018d3895f61dc736087a14b15af08a35b\nCloses-Bug: #1401287\n""}]",4,141326,ffda5b7da7bd8256329f74cbca358ca38b9ba316,75,7,19,6816,,,0,"Add swift to the all-in-one build check

This patch adds swift to the all-in-one build check used for testing
and gate checks. The script will deploy swift and configure glance to
use swift by default, but this can be disabled by setting the
environment variable DEPLOY_SWIFT to be any value other than 'yes'.

This patch also adds comments to various parts of the check script for
clarity, removes br-snet as it is unused, and has a sprinkle of
refactoring for improved health and happiness.

Change-Id: Iabce466018d3895f61dc736087a14b15af08a35b
Closes-Bug: #1401287
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/26/141326/16 && git format-patch -1 --stdout FETCH_HEAD,['scripts/os-ansible-aio-check.sh'],1,5258cfd5405966e4a13f19844d9ff512fe60cc9a,bug/1401287,"ADMIN_PASSWORD=${ADMIN_PASSWORD:-""secrete""} # update the package cache and install required packages xfsprogs \function loopback_create() { LOOP_FILENAME=${1} LOOP_FILESIZE=${2} if ! losetup -a | grep ""(${LOOP_FILENAME})$"" > /dev/null; then LOOP_DEVICE=$(losetup -f) dd if=/dev/zero of=${LOOP_FILENAME} bs=1 count=0 seek=${LOOP_FILESIZE} losetup ${LOOP_DEVICE} ${LOOP_FILENAME} fi } # ensure that the current kernel can support vxlan# ensure that swap is configured# ensure that swap stays enabled after a reboot# build the loopback drive for cinder to use CINDER=""cinder.img"" loopback_create /opt/${CINDER} 1000G CINDER_DEVICE=$(losetup -a | awk -F: ""/${CINDER}/ {print \$1}"") if ! pvs ${CINDER_DEVICE} > /dev/null; then pvcreate ${CINDER_DEVICE}if ! vgs cinder-volumes > /dev/null; then vgcreate cinder-volumes ${CINDER_DEVICE} fi # build the looback drives for swift to use for SWIFT in swift1.img swift2.img swift3.img; do loopback_create /opt/${SWIFT} 1000G SWIFT_DEVICE=$(losetup -a | awk -F: ""/${SWIFT}/ {print \$1}"") if ! grep ""${SWIFT}"" /etc/fstab > /dev/null; then echo ""${SWIFT_DEVICE} /srv/${SWIFT} xfs noatime,nodiratime,nobarrier,logbufs=8 0 0"" >> /etc/fstab fi if ! grep ""${SWIFT}"" /proc/mounts > /dev/null; then mkfs.xfs -f ${SWIFT_DEVICE} mkdir -p /srv/${SWIFT} mount /srv/${SWIFT} fi done# change the generated passwords for the OpenStack (admin) and Kibana (kibana) accounts sed -i ""s/keystone_auth_admin_password:.*/keystone_auth_admin_password: ${ADMIN_PASSWORD}/"" /etc/rpc_deploy/user_variables.yml sed -i ""s/kibana_password:.*/kibana_password: ${ADMIN_PASSWORD}/"" /etc/rpc_deploy/user_variables.yml # build the required user configurationcidr_networks: external_lb_vip_address: 192.168.10.10for i in br-storage br-vlan br-vxlan br-mgmt; do"," CINDER=""/opt/cinder.img"" if [ ! ""$(losetup -a | grep /opt/cinder.img)"" ];then LOOP=$(losetup -f) dd if=/dev/zero of=${CINDER} bs=1 count=0 seek=1000G losetup ${LOOP} ${CINDER} pvcreate ${LOOP} vgcreate cinder-volumes ${LOOP}cat > /etc/rpc_deploy/user_variables.yml <<EOF --- rpc_repo_url: ${FROZEN_REPO_URL} required_kernel: 3.13.0-30-generic ## Rackspace Cloud Details rackspace_cloud_auth_url: https://identity.api.rackspacecloud.com/v2.0 rackspace_cloud_tenant_id: SomeTenantID rackspace_cloud_username: SomeUserName rackspace_cloud_password: SomeUsersPassword rackspace_cloud_api_key: SomeAPIKey ## Rabbit Options rabbitmq_password: secrete rabbitmq_cookie_token: secrete ## Tokens memcached_encryption_key: secrete ## Container default user container_openstack_password: secrete ## Galera Options mysql_root_password: secrete mysql_debian_sys_maint_password: secrete ## Keystone Options keystone_container_mysql_password: secrete keystone_auth_admin_token: secrete keystone_auth_admin_password: secrete keystone_service_password: secrete ## Cinder Options cinder_container_mysql_password: secrete cinder_service_password: secrete cinder_v2_service_password: secrete # Set default_store to ""swift"" if using Cloud Files or swift backend glance_default_store: file glance_container_mysql_password: secrete glance_service_password: secrete glance_swift_store_auth_address: ""{{ rackspace_cloud_auth_url }}"" glance_swift_store_user: ""{{ rackspace_cloud_tenant_id }}:{{ rackspace_cloud_username }}"" glance_swift_store_key: ""{{ rackspace_cloud_password }}"" glance_swift_store_container: SomeContainerName glance_swift_store_region: SomeRegion glance_swift_store_endpoint_type: internalURL glance_notification_driver: noop ## Heat Options heat_stack_domain_admin_password: secrete heat_container_mysql_password: secrete ### THE HEAT AUTH KEY NEEDS TO BE 32 CHARACTERS LONG ## heat_auth_encryption_key: 12345678901234567890123456789012 ### THE HEAT AUTH KEY NEEDS TO BE 32 CHARACTERS LONG ## heat_service_password: secrete heat_cfn_service_password: secrete ## Horizon Options horizon_container_mysql_password: secrete ## MaaS Options maas_auth_method: password maas_auth_url: ""{{ rackspace_cloud_auth_url }}"" maas_username: ""{{ rackspace_cloud_username }}"" maas_api_key: ""{{ rackspace_cloud_api_key }}"" maas_auth_token: some_token maas_api_url: https://monitoring.api.rackspacecloud.com/v1.0/{{ rackspace_cloud_tenant_id }} maas_notification_plan: npManaged # By default we will create an agent token for each entity, however if you'd # prefer to use the same agent token for all entities then specify it here #maas_agent_token: some_token maas_target_alias: public0_v4 maas_scheme: https # Override scheme for specific service remote monitor by specifying here: E.g. # maas_nova_scheme: http maas_keystone_user: maas maas_keystone_password: secrete # Check this number of times before registering state change maas_alarm_local_consecutive_count: 3 maas_alarm_remote_consecutive_count: 1 # Timeout must be less than period maas_check_period: 60 maas_check_timeout: 30 maas_monitoring_zones: - mzdfw - mziad - mzord - mzlon - mzhkg ## Neutron Options neutron_container_mysql_password: secrete neutron_service_password: secrete ## Nova Options nova_virt_type: qemu nova_container_mysql_password: secrete nova_metadata_proxy_secret: secrete nova_ec2_service_password: secrete nova_service_password: secrete nova_v3_service_password: secrete nova_s3_service_password: secrete ## RPC Support rpc_support_holland_password: secrete ## Kibana Options kibana_password: secrete EOF # This is the md5 of the environment file# User defined CIDR used for containers cidr_networks: # Cidr used in the Management network # Cidr used in the Service network snet: 172.29.248.0/22 # Cidr used in the VM network # Cidr used in the Storage network # Internal Management vip address # External DMZ VIP address external_lb_vip_address: 10.200.200.146 # Bridged interface to use with tunnel type networks # Bridged interface to build containers with # Define your Add on container networks. - glance_api - nova_compute - neutron_linuxbridge_agent type: ""raw"" container_bridge: ""br-snet"" container_interface: ""eth3"" ip_from_q: ""snet"" - network: group_binds: # Name of load balancer lb_name: lb_name_in_core # User defined Infrastructure Hosts, this should be a required group# User defined Compute Hosts, this should be a required group# User defined Storage Hosts, this should be a required group# User defined Logging Hosts, this should be a required group# User defined Networking Hosts, this should be a required group auto br-snet iface br-snet inet static bridge_stp off bridge_waitport 0 bridge_fd 0 bridge_ports none # Notice there is NO physical interface in this bridge! address 172.29.248.100 netmask 255.255.252.0for i in br-snet br-storage br-vlan br-vxlan br-mgmt; do",45,145
openstack%2Fcinder~master~Ic819afb4391708a0afebe4fc2855c93e3cb3f4c4,openstack/cinder,master,Ic819afb4391708a0afebe4fc2855c93e3cb3f4c4,Convert mox to mock: tests/compute/test_nova.py,MERGED,2014-12-12 10:10:12.000000000,2014-12-18 10:58:50.000000000,2014-12-15 18:18:30.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 10068}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 13527}, {'_account_id': 13636}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-12 10:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a85e4f1347d79c1efd754c348ff1b21d3954601a', 'message': 'Convertion of mox to mock\n\nReplace mox testing library by mock in the file\ncinder/tests/compute/test_nova.py\n\nImplements: blueprint mox-to-mock-conversion\nChange-Id: Ic819afb4391708a0afebe4fc2855c93e3cb3f4c4\n'}, {'number': 2, 'created': '2014-12-15 07:14:54.000000000', 'files': ['cinder/tests/compute/test_nova.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/be751cb7e354a621502ee94e72f431f826e14444', 'message': 'Convert mox to mock: tests/compute/test_nova.py\n\nReplace mox testing library by mock in the file\ncinder/tests/compute/test_nova.py\n\nImplements: blueprint mox-to-mock-conversion\nChange-Id: Ic819afb4391708a0afebe4fc2855c93e3cb3f4c4\n'}]",0,141316,be751cb7e354a621502ee94e72f431f826e14444,25,13,2,14314,,,0,"Convert mox to mock: tests/compute/test_nova.py

Replace mox testing library by mock in the file
cinder/tests/compute/test_nova.py

Implements: blueprint mox-to-mock-conversion
Change-Id: Ic819afb4391708a0afebe4fc2855c93e3cb3f4c4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/16/141316/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/compute/test_nova.py'],1,a85e4f1347d79c1efd754c348ff1b21d3954601a,mox-to-mock-conversion,"import contextlib import mock with contextlib.nested( mock.patch.object(nova, 'novaclient'), mock.patch.object(self.novaclient.volumes, 'update_server_volume') ) as (mock_novaclient, mock_update_server_volume): mock_novaclient.return_value = self.novaclient self.api.update_server_volume(self.ctx, 'server_id', 'attach_id', 'new_volume_id') mock_novaclient.assert_called_once_with(self.ctx) mock_update_server_volume.assert_called_once_with( 'server_id', 'attach_id', 'new_volume_id' )"," self.mox.StubOutWithMock(nova, 'novaclient') nova.novaclient(self.ctx).AndReturn(self.novaclient) self.mox.StubOutWithMock(self.novaclient.volumes, 'update_server_volume') self.novaclient.volumes.update_server_volume('server_id', 'attach_id', 'new_volume_id') self.mox.ReplayAll() self.api.update_server_volume(self.ctx, 'server_id', 'attach_id', 'new_volume_id')",20,9
openstack%2Fopenstack-ansible~stable%2Ficehouse~I1f41ad386460f71629205798db06fbad6ccbfe9b,openstack/openstack-ansible,stable/icehouse,I1f41ad386460f71629205798db06fbad6ccbfe9b,Change nova scheduler filters,MERGED,2014-12-11 11:10:31.000000000,2014-12-18 10:53:17.000000000,2014-12-18 10:30:08.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-11 11:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/75b419178a33db4c93b54c11c771e2710ccf6851', 'message': 'Change nova scheduler filters\n\nThis change adds DiskFilter and changes AggregateCoreFilter to\nCoreFilter.  In stable/juno we have AggregateCoreFilter and\nAggregateDiskFilter, but AggregateDiskFilter is not available in\nicehouse.  If someone actually needs the aggregate versions of\nthese filters then they can set local overrides.\n\nChange-Id: I1f41ad386460f71629205798db06fbad6ccbfe9b\nCloses-Bug: #1399364\n'}, {'number': 2, 'created': '2014-12-11 11:19:57.000000000', 'files': ['rpc_deployment/inventory/group_vars/nova_all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/909bc03d598a83d57e0d551b9bb2dbae27bc67c3', 'message': 'Change nova scheduler filters\n\nThis change adds DiskFilter and changes AggregateCoreFilter to\nCoreFilter.  In stable/juno we have AggregateCoreFilter and\nAggregateDiskFilter, but AggregateDiskFilter is not available in\nicehouse.  If someone actually needs the aggregate versions of\nthese filters then they can set local overrides.\n\nChange-Id: I1f41ad386460f71629205798db06fbad6ccbfe9b\nCloses-Bug: 1399364\n'}]",0,141013,909bc03d598a83d57e0d551b9bb2dbae27bc67c3,18,6,2,7307,,,0,"Change nova scheduler filters

This change adds DiskFilter and changes AggregateCoreFilter to
CoreFilter.  In stable/juno we have AggregateCoreFilter and
AggregateDiskFilter, but AggregateDiskFilter is not available in
icehouse.  If someone actually needs the aggregate versions of
these filters then they can set local overrides.

Change-Id: I1f41ad386460f71629205798db06fbad6ccbfe9b
Closes-Bug: 1399364
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/13/141013/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/inventory/group_vars/nova_all.yml'],1,75b419178a33db4c93b54c11c771e2710ccf6851,bug/1399364,"nova_scheduler_default_filters: RetryFilter,AvailabilityZoneFilter,RamFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter,CoreFilter,DiskFilter","nova_scheduler_default_filters: RetryFilter,AvailabilityZoneFilter,RamFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter,AggregateCoreFilter",1,1
openstack%2Fcinder~master~If6c6e7370ac253f332ed532c0ca3956624267442,openstack/cinder,master,If6c6e7370ac253f332ed532c0ca3956624267442,Convert test_image_utils tests to mock,MERGED,2014-12-11 11:51:04.000000000,2014-12-18 10:52:53.000000000,2014-12-18 10:52:51.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 13636}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-11 11:51:04.000000000', 'files': ['cinder/image/image_utils.py', 'cinder/tests/test_image_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f3809dec5a359dc293f9a0098d7c34d083a124a4', 'message': ""Convert test_image_utils tests to mock\n\nThe tests for cinder/image/image_utils.py mainly use mox. This patch\nreplaces the tests in cinder/tests/test_image_utils.py and adds\nadditional tests that use mock.\n\nThis commit removes the following trivial functions that were only used\nonce within image_utils and don't appear to provide any tangible\nbenefit:\n    - file_exist\n    - rename_file\n\nChange-Id: If6c6e7370ac253f332ed532c0ca3956624267442\n""}]",0,141025,f3809dec5a359dc293f9a0098d7c34d083a124a4,15,11,1,7219,,,0,"Convert test_image_utils tests to mock

The tests for cinder/image/image_utils.py mainly use mox. This patch
replaces the tests in cinder/tests/test_image_utils.py and adds
additional tests that use mock.

This commit removes the following trivial functions that were only used
once within image_utils and don't appear to provide any tangible
benefit:
    - file_exist
    - rename_file

Change-Id: If6c6e7370ac253f332ed532c0ca3956624267442
",git fetch https://review.opendev.org/openstack/cinder refs/changes/25/141025/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/image/image_utils.py', 'cinder/tests/test_image_utils.py']",2,f3809dec5a359dc293f9a0098d7c34d083a124a4,image_utils," class TestQemuImgInfo(test.TestCase): @mock.patch('cinder.openstack.common.imageutils.QemuImgInfo') @mock.patch('cinder.utils.execute') def test_qemu_img_info(self, mock_exec, mock_info): mock_out = mock.sentinel.out mock_err = mock.sentinel.err test_path = mock.sentinel.path mock_exec.return_value = (mock_out, mock_err) output = image_utils.qemu_img_info(test_path) mock_exec.assert_called_once_with('env', 'LC_ALL=C', 'qemu-img', 'info', test_path, run_as_root=True) self.assertEqual(mock_info.return_value, output) @mock.patch('cinder.openstack.common.imageutils.QemuImgInfo') @mock.patch('cinder.utils.execute') def test_qemu_img_info_not_root(self, mock_exec, mock_info): mock_out = mock.sentinel.out mock_err = mock.sentinel.err test_path = mock.sentinel.path mock_exec.return_value = (mock_out, mock_err) output = image_utils.qemu_img_info(test_path, run_as_root=False) mock_exec.assert_called_once_with('env', 'LC_ALL=C', 'qemu-img', 'info', test_path, run_as_root=False) self.assertEqual(mock_info.return_value, output) @mock.patch('cinder.image.image_utils.os') @mock.patch('cinder.openstack.common.imageutils.QemuImgInfo') @mock.patch('cinder.utils.execute') def test_qemu_img_info_on_nt(self, mock_exec, mock_info, mock_os): mock_out = mock.sentinel.out mock_err = mock.sentinel.err test_path = mock.sentinel.path mock_exec.return_value = (mock_out, mock_err) mock_os.name = 'nt' output = image_utils.qemu_img_info(test_path) mock_exec.assert_called_once_with('qemu-img', 'info', test_path, run_as_root=True) self.assertEqual(mock_info.return_value, output) class TestConvertImage(test.TestCase): @mock.patch('cinder.image.image_utils.os.stat') @mock.patch('cinder.utils.execute') @mock.patch('cinder.volume.utils.setup_blkio_cgroup', return_value=(mock.sentinel.cgcmd, )) @mock.patch('cinder.utils.is_blk_device', return_value=True) def test_defaults_block_dev(self, mock_isblk, mock_cgroup, mock_exec, mock_stat): source = mock.sentinel.source dest = mock.sentinel.dest out_format = mock.sentinel.out_format cgcmd = mock.sentinel.cgcmd mock_stat.return_value.st_size = 1048576 with mock.patch('cinder.volume.utils.check_for_odirect_support', return_value=True): output = image_utils.convert_image(source, dest, out_format) self.assertIsNone(output) mock_exec.assert_called_once_with(cgcmd, 'qemu-img', 'convert', '-t', 'none', '-O', out_format, source, dest, run_as_root=True) mock_exec.reset_mock() with mock.patch('cinder.volume.utils.check_for_odirect_support', return_value=False): output = image_utils.convert_image(source, dest, out_format) self.assertIsNone(output) mock_exec.assert_called_once_with(cgcmd, 'qemu-img', 'convert', '-O', out_format, source, dest, run_as_root=True) @mock.patch('cinder.volume.utils.check_for_odirect_support', return_value=True) @mock.patch('cinder.image.image_utils.os.stat') @mock.patch('cinder.utils.execute') @mock.patch('cinder.volume.utils.setup_blkio_cgroup', return_value=(mock.sentinel.cgcmd, )) @mock.patch('cinder.utils.is_blk_device', return_value=False) def test_defaults_not_block_dev(self, mock_isblk, mock_cgroup, mock_exec, mock_stat, mock_odirect): source = mock.sentinel.source dest = mock.sentinel.dest out_format = mock.sentinel.out_format cgcmd = mock.sentinel.cgcmd mock_stat.return_value.st_size = 1048576 output = image_utils.convert_image(source, dest, out_format) self.assertIsNone(output) mock_exec.assert_called_once_with(cgcmd, 'qemu-img', 'convert', '-O', out_format, source, dest, run_as_root=True) class TestResizeImage(test.TestCase): @mock.patch('cinder.utils.execute') def test_defaults(self, mock_exec): source = mock.sentinel.source size = mock.sentinel.size output = image_utils.resize_image(source, size) self.assertIsNone(output) mock_exec.assert_called_once_with('qemu-img', 'resize', source, 'sentinel.sizeG', run_as_root=False) @mock.patch('cinder.utils.execute') def test_run_as_root(self, mock_exec): source = mock.sentinel.source size = mock.sentinel.size output = image_utils.resize_image(source, size, run_as_root=True) self.assertIsNone(output) mock_exec.assert_called_once_with('qemu-img', 'resize', source, 'sentinel.sizeG', run_as_root=True) class TestFetch(test.TestCase): @mock.patch('cinder.image.image_utils.fileutils') def test_defaults(self, mock_fileutils, mock_stat): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id path = 'test_path' _user_id = mock.sentinel._user_id _project_id = mock.sentinel._project_id mock_open = mock.mock_open() mock_stat.return_value.st_size = 1048576 with mock.patch('cinder.image.image_utils.open', new=mock_open, create=True): output = image_utils.fetch(ctxt, image_service, image_id, path, _user_id, _project_id) self.assertIsNone(output) image_service.download.assert_called_once_with(ctxt, image_id, mock_open.return_value) mock_open.assert_called_once_with(path, 'wb') mock_fileutils.remove_path_on_error.assert_called_once_with(path) (mock_fileutils.remove_path_on_error.return_value.__enter__ .assert_called_once_with()) (mock_fileutils.remove_path_on_error.return_value.__exit__ .assert_called_once_with(None, None, None)) class TestVerifyImage(test.TestCase): @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.fileutils') @mock.patch('cinder.image.image_utils.fetch') def test_defaults(self, mock_fetch, mock_fileutils, mock_info): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest mock_data = mock_info.return_value mock_data.file_format = 'test_format' mock_data.backing_file = None output = image_utils.fetch_verify_image(ctxt, image_service, image_id, dest) self.assertIsNone(output) mock_fetch.assert_called_once_with(ctxt, image_service, image_id, dest, None, None) mock_info.assert_called_once_with(dest, run_as_root=True) mock_fileutils.remove_path_on_error.assert_called_once_with(dest) (mock_fileutils.remove_path_on_error.return_value.__enter__ .assert_called_once_with()) (mock_fileutils.remove_path_on_error.return_value.__exit__ .assert_called_once_with(None, None, None)) @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.fileutils') @mock.patch('cinder.image.image_utils.fetch') def test_kwargs(self, mock_fetch, mock_fileutils, mock_info): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id size = 2 run_as_root = mock.sentinel.run_as_root mock_data = mock_info.return_value mock_data.file_format = 'test_format' mock_data.backing_file = None mock_data.virtual_size = 1 output = image_utils.fetch_verify_image( ctxt, image_service, image_id, dest, user_id=user_id, project_id=project_id, size=size, run_as_root=run_as_root) self.assertIsNone(output) mock_fetch.assert_called_once_with(ctxt, image_service, image_id, dest, None, None) mock_info.assert_called_once_with(dest, run_as_root=run_as_root) mock_fileutils.remove_path_on_error.assert_called_once_with(dest) (mock_fileutils.remove_path_on_error.return_value.__enter__ .assert_called_once_with()) (mock_fileutils.remove_path_on_error.return_value.__exit__ .assert_called_once_with(None, None, None)) @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.fileutils') @mock.patch('cinder.image.image_utils.fetch') def test_format_error(self, mock_fetch, mock_fileutils, mock_info): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest mock_data = mock_info.return_value mock_data.file_format = None mock_data.backing_file = None ctxt, image_service, image_id, dest) @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.fileutils') @mock.patch('cinder.image.image_utils.fetch') def test_backing_file_error(self, mock_fetch, mock_fileutils, mock_info): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest mock_data = mock_info.return_value mock_data.file_format = 'test_format' mock_data.backing_file = 'test_backing_file' self.assertRaises(exception.ImageUnacceptable, image_utils.fetch_verify_image, ctxt, image_service, image_id, dest) @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.fileutils') @mock.patch('cinder.image.image_utils.fetch') def test_size_error(self, mock_fetch, mock_fileutils, mock_info): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest size = 1 mock_data = mock_info.return_value mock_data.file_format = 'test_format' mock_data.backing_file = None mock_data.virtual_size = 2 self.assertRaises(exception.ImageUnacceptable, image_utils.fetch_verify_image, ctxt, image_service, image_id, dest, size=size) ctxt = mock.sentinel.context output = image_utils.upload_volume(ctxt, image_service, image_meta, ctxt, image_meta['id'], {}, ctxt = mock.sentinel.context output = image_utils.upload_volume(ctxt, image_service, image_meta, ctxt, image_meta['id'], {}, ctxt = mock.sentinel.context output = image_utils.upload_volume(ctxt, image_service, image_meta, ctxt, image_meta['id'], {}, ctxt = mock.sentinel.context ctxt, image_service, image_meta, volume_path) class TestFetchToVhd(test.TestCase): @mock.patch('cinder.image.image_utils.fetch_to_volume_format') def test_defaults(self, mock_fetch_to): ctxt = mock.sentinel.context image_service = mock.sentinel.image_service image_id = mock.sentinel.image_id dest = mock.sentinel.dest blocksize = mock.sentinel.blocksize output = image_utils.fetch_to_vhd(ctxt, image_service, image_id, dest, blocksize) self.assertIsNone(output) mock_fetch_to.assert_called_once_with(ctxt, image_service, image_id, dest, 'vpc', blocksize, None, None, run_as_root=True) @mock.patch('cinder.image.image_utils.fetch_to_volume_format') def test_kwargs(self, mock_fetch_to): ctxt = mock.sentinel.context image_service = mock.sentinel.image_service image_id = mock.sentinel.image_id dest = mock.sentinel.dest blocksize = mock.sentinel.blocksize user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id run_as_root = mock.sentinel.run_as_root output = image_utils.fetch_to_vhd(ctxt, image_service, image_id, dest, blocksize, user_id=user_id, project_id=project_id, run_as_root=run_as_root) self.assertIsNone(output) mock_fetch_to.assert_called_once_with(ctxt, image_service, image_id, dest, 'vpc', blocksize, user_id, project_id, run_as_root=run_as_root) class TestFetchToRaw(test.TestCase): @mock.patch('cinder.image.image_utils.fetch_to_volume_format') def test_defaults(self, mock_fetch_to): ctxt = mock.sentinel.context image_service = mock.sentinel.image_service image_id = mock.sentinel.image_id dest = mock.sentinel.dest blocksize = mock.sentinel.blocksize output = image_utils.fetch_to_raw(ctxt, image_service, image_id, dest, blocksize) self.assertIsNone(output) mock_fetch_to.assert_called_once_with(ctxt, image_service, image_id, dest, 'raw', blocksize, None, None, None, run_as_root=True) @mock.patch('cinder.image.image_utils.fetch_to_volume_format') def test_kwargs(self, mock_fetch_to): ctxt = mock.sentinel.context image_service = mock.sentinel.image_service image_id = mock.sentinel.image_id dest = mock.sentinel.dest blocksize = mock.sentinel.blocksize user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id size = mock.sentinel.size run_as_root = mock.sentinel.run_as_root output = image_utils.fetch_to_raw(ctxt, image_service, image_id, dest, blocksize, user_id=user_id, project_id=project_id, size=size, run_as_root=run_as_root) self.assertIsNone(output) mock_fetch_to.assert_called_once_with(ctxt, image_service, image_id, dest, 'raw', blocksize, user_id, project_id, size, run_as_root=run_as_root) class TestFetchToVolumeFormat(test.TestCase): @mock.patch('cinder.image.image_utils.convert_image') @mock.patch('cinder.image.image_utils.volume_utils.copy_volume') @mock.patch( 'cinder.image.image_utils.replace_xenserver_image_with_coalesced_vhd') @mock.patch('cinder.image.image_utils.is_xenserver_image', return_value=False) @mock.patch('cinder.image.image_utils.fetch') @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.temporary_file') @mock.patch('cinder.image.image_utils.CONF') def test_defaults(self, mock_conf, mock_temp, mock_info, mock_fetch, mock_is_xen, mock_repl_xen, mock_copy, mock_convert): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest volume_format = mock.sentinel.volume_format blocksize = mock.sentinel.blocksize bps_limit = mock.sentinel.bps_limit mock_conf.volume_copy_bps_limit = bps_limit data = mock_info.return_value data.file_format = volume_format data.backing_file = None data.virtual_size = 1234 tmp = mock_temp.return_value.__enter__.return_value output = image_utils.fetch_to_volume_format(ctxt, image_service, image_id, dest, volume_format, blocksize) self.assertIsNone(output) image_service.show.assert_called_once_with(ctxt, image_id) mock_temp.assert_called_once_with() mock_info.assert_has_calls([ mock.call(tmp, run_as_root=True), mock.call(tmp, run_as_root=True), mock.call(dest, run_as_root=True)]) mock_fetch.assert_called_once_with(ctxt, image_service, image_id, tmp, None, None) self.assertFalse(mock_repl_xen.called) self.assertFalse(mock_copy.called) mock_convert.assert_called_once_with(tmp, dest, volume_format, bps_limit=bps_limit, run_as_root=True) @mock.patch('cinder.image.image_utils.convert_image') @mock.patch('cinder.image.image_utils.volume_utils.copy_volume') @mock.patch( 'cinder.image.image_utils.replace_xenserver_image_with_coalesced_vhd') @mock.patch('cinder.image.image_utils.is_xenserver_image', return_value=False) @mock.patch('cinder.image.image_utils.fetch') @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.temporary_file') @mock.patch('cinder.image.image_utils.CONF') def test_kwargs(self, mock_conf, mock_temp, mock_info, mock_fetch, mock_is_xen, mock_repl_xen, mock_copy, mock_convert): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest volume_format = mock.sentinel.volume_format blocksize = mock.sentinel.blocksize user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id size = 4321 run_as_root = mock.sentinel.run_as_root bps_limit = mock.sentinel.bps_limit mock_conf.volume_copy_bps_limit = bps_limit data = mock_info.return_value data.file_format = volume_format data.backing_file = None data.virtual_size = 1234 tmp = mock_temp.return_value.__enter__.return_value output = image_utils.fetch_to_volume_format( ctxt, image_service, image_id, dest, volume_format, blocksize, user_id=user_id, project_id=project_id, size=size, run_as_root=run_as_root) self.assertIsNone(output) image_service.show.assert_called_once_with(ctxt, image_id) mock_temp.assert_called_once_with() mock_info.assert_has_calls([ mock.call(tmp, run_as_root=run_as_root), mock.call(tmp, run_as_root=run_as_root), mock.call(dest, run_as_root=run_as_root)]) mock_fetch.assert_called_once_with(ctxt, image_service, image_id, tmp, user_id, project_id) self.assertFalse(mock_repl_xen.called) self.assertFalse(mock_copy.called) mock_convert.assert_called_once_with(tmp, dest, volume_format, bps_limit=bps_limit, run_as_root=run_as_root) @mock.patch('cinder.image.image_utils.convert_image') @mock.patch('cinder.image.image_utils.volume_utils.copy_volume') @mock.patch( 'cinder.image.image_utils.replace_xenserver_image_with_coalesced_vhd') @mock.patch('cinder.image.image_utils.is_xenserver_image', return_value=False) @mock.patch('cinder.image.image_utils.fetch') @mock.patch('cinder.image.image_utils.qemu_img_info', side_effect=processutils.ProcessExecutionError) @mock.patch('cinder.image.image_utils.temporary_file') @mock.patch('cinder.image.image_utils.CONF') def test_no_qemu_img_and_is_raw(self, mock_conf, mock_temp, mock_info, mock_fetch, mock_is_xen, mock_repl_xen, mock_copy, mock_convert): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest volume_format = mock.sentinel.volume_format blocksize = mock.sentinel.blocksize user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id size = 4321 run_as_root = mock.sentinel.run_as_root bps_limit = mock.sentinel.bps_limit mock_conf.volume_copy_bps_limit = bps_limit tmp = mock_temp.return_value.__enter__.return_value image_service.show.return_value = {'disk_format': 'raw', 'size': mock.sentinel.image_size} output = image_utils.fetch_to_volume_format( ctxt, image_service, image_id, dest, volume_format, blocksize, user_id=user_id, project_id=project_id, size=size, run_as_root=run_as_root) self.assertIsNone(output) image_service.show.assert_called_once_with(ctxt, image_id) mock_temp.assert_called_once_with() mock_info.assert_called_once_with(tmp, run_as_root=run_as_root) mock_fetch.assert_called_once_with(ctxt, image_service, image_id, tmp, user_id, project_id) self.assertFalse(mock_repl_xen.called) mock_copy.assert_called_once_with(tmp, dest, mock.sentinel.image_size, blocksize) self.assertFalse(mock_convert.called) @mock.patch('cinder.image.image_utils.convert_image') @mock.patch('cinder.image.image_utils.volume_utils.copy_volume') @mock.patch( 'cinder.image.image_utils.replace_xenserver_image_with_coalesced_vhd') @mock.patch('cinder.image.image_utils.is_xenserver_image', return_value=False) @mock.patch('cinder.image.image_utils.fetch') @mock.patch('cinder.image.image_utils.qemu_img_info', side_effect=processutils.ProcessExecutionError) @mock.patch('cinder.image.image_utils.temporary_file') @mock.patch('cinder.image.image_utils.CONF') def test_no_qemu_img_not_raw(self, mock_conf, mock_temp, mock_info, mock_fetch, mock_is_xen, mock_repl_xen, mock_copy, mock_convert): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest volume_format = mock.sentinel.volume_format blocksize = mock.sentinel.blocksize user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id size = 4321 run_as_root = mock.sentinel.run_as_root bps_limit = mock.sentinel.bps_limit mock_conf.volume_copy_bps_limit = bps_limit tmp = mock_temp.return_value.__enter__.return_value image_service.show.return_value = {'disk_format': 'not_raw'} self.assertRaises( exception.ImageUnacceptable, image_utils.fetch_to_volume_format, ctxt, image_service, image_id, dest, volume_format, blocksize, user_id=user_id, project_id=project_id, size=size, run_as_root=run_as_root) image_service.show.assert_called_once_with(ctxt, image_id) mock_temp.assert_called_once_with() mock_info.assert_called_once_with(tmp, run_as_root=run_as_root) self.assertFalse(mock_fetch.called) self.assertFalse(mock_repl_xen.called) self.assertFalse(mock_copy.called) self.assertFalse(mock_convert.called) @mock.patch('cinder.image.image_utils.convert_image') @mock.patch('cinder.image.image_utils.volume_utils.copy_volume') @mock.patch( 'cinder.image.image_utils.replace_xenserver_image_with_coalesced_vhd') @mock.patch('cinder.image.image_utils.is_xenserver_image', return_value=False) @mock.patch('cinder.image.image_utils.fetch') @mock.patch('cinder.image.image_utils.qemu_img_info', side_effect=processutils.ProcessExecutionError) @mock.patch('cinder.image.image_utils.temporary_file') @mock.patch('cinder.image.image_utils.CONF') def test_no_qemu_img_no_metadata(self, mock_conf, mock_temp, mock_info, mock_fetch, mock_is_xen, mock_repl_xen, mock_copy, mock_convert): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest volume_format = mock.sentinel.volume_format blocksize = mock.sentinel.blocksize user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id size = 4321 run_as_root = mock.sentinel.run_as_root bps_limit = mock.sentinel.bps_limit mock_conf.volume_copy_bps_limit = bps_limit tmp = mock_temp.return_value.__enter__.return_value image_service.show.return_value = None self.assertRaises( exception.ImageUnacceptable, image_utils.fetch_to_volume_format, ctxt, image_service, image_id, dest, volume_format, blocksize, user_id=user_id, project_id=project_id, size=size, run_as_root=run_as_root) image_service.show.assert_called_once_with(ctxt, image_id) mock_temp.assert_called_once_with() mock_info.assert_called_once_with(tmp, run_as_root=run_as_root) self.assertFalse(mock_fetch.called) self.assertFalse(mock_repl_xen.called) self.assertFalse(mock_copy.called) self.assertFalse(mock_convert.called) @mock.patch('cinder.image.image_utils.convert_image') @mock.patch('cinder.image.image_utils.volume_utils.copy_volume') @mock.patch( 'cinder.image.image_utils.replace_xenserver_image_with_coalesced_vhd') @mock.patch('cinder.image.image_utils.is_xenserver_image', return_value=False) @mock.patch('cinder.image.image_utils.fetch') @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.temporary_file') @mock.patch('cinder.image.image_utils.CONF') def test_size_error(self, mock_conf, mock_temp, mock_info, mock_fetch, mock_is_xen, mock_repl_xen, mock_copy, mock_convert): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest volume_format = mock.sentinel.volume_format blocksize = mock.sentinel.blocksize user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id size = 1234 run_as_root = mock.sentinel.run_as_root bps_limit = mock.sentinel.bps_limit mock_conf.volume_copy_bps_limit = bps_limit data = mock_info.return_value data.file_format = volume_format data.backing_file = None data.virtual_size = 4321 * 1024 ** 3 tmp = mock_temp.return_value.__enter__.return_value self.assertRaises( exception.ImageUnacceptable, image_utils.fetch_to_volume_format, ctxt, image_service, image_id, dest, volume_format, blocksize, user_id=user_id, project_id=project_id, size=size, run_as_root=run_as_root) image_service.show.assert_called_once_with(ctxt, image_id) mock_temp.assert_called_once_with() mock_info.assert_has_calls([ mock.call(tmp, run_as_root=run_as_root), mock.call(tmp, run_as_root=run_as_root)]) mock_fetch.assert_called_once_with(ctxt, image_service, image_id, tmp, user_id, project_id) self.assertFalse(mock_repl_xen.called) self.assertFalse(mock_copy.called) self.assertFalse(mock_convert.called) @mock.patch('cinder.image.image_utils.convert_image') @mock.patch('cinder.image.image_utils.volume_utils.copy_volume') @mock.patch( 'cinder.image.image_utils.replace_xenserver_image_with_coalesced_vhd') @mock.patch('cinder.image.image_utils.is_xenserver_image', return_value=False) @mock.patch('cinder.image.image_utils.fetch') @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.temporary_file') @mock.patch('cinder.image.image_utils.CONF') def test_qemu_img_parse_error(self, mock_conf, mock_temp, mock_info, mock_fetch, mock_is_xen, mock_repl_xen, mock_copy, mock_convert): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest volume_format = mock.sentinel.volume_format blocksize = mock.sentinel.blocksize user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id size = 4321 run_as_root = mock.sentinel.run_as_root bps_limit = mock.sentinel.bps_limit mock_conf.volume_copy_bps_limit = bps_limit data = mock_info.return_value data.file_format = None data.backing_file = None data.virtual_size = 1234 tmp = mock_temp.return_value.__enter__.return_value self.assertRaises( exception.ImageUnacceptable, image_utils.fetch_to_volume_format, ctxt, image_service, image_id, dest, volume_format, blocksize, user_id=user_id, project_id=project_id, size=size, run_as_root=run_as_root) image_service.show.assert_called_once_with(ctxt, image_id) mock_temp.assert_called_once_with() mock_info.assert_has_calls([ mock.call(tmp, run_as_root=run_as_root), mock.call(tmp, run_as_root=run_as_root)]) mock_fetch.assert_called_once_with(ctxt, image_service, image_id, tmp, user_id, project_id) self.assertFalse(mock_repl_xen.called) self.assertFalse(mock_copy.called) self.assertFalse(mock_convert.called) @mock.patch('cinder.image.image_utils.convert_image') @mock.patch('cinder.image.image_utils.volume_utils.copy_volume') @mock.patch( 'cinder.image.image_utils.replace_xenserver_image_with_coalesced_vhd') @mock.patch('cinder.image.image_utils.is_xenserver_image', return_value=False) @mock.patch('cinder.image.image_utils.fetch') @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.temporary_file') @mock.patch('cinder.image.image_utils.CONF') def test_backing_file_error(self, mock_conf, mock_temp, mock_info, mock_fetch, mock_is_xen, mock_repl_xen, mock_copy, mock_convert): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest volume_format = mock.sentinel.volume_format blocksize = mock.sentinel.blocksize user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id size = 4321 run_as_root = mock.sentinel.run_as_root bps_limit = mock.sentinel.bps_limit mock_conf.volume_copy_bps_limit = bps_limit data = mock_info.return_value data.file_format = volume_format data.backing_file = mock.sentinel.backing_file data.virtual_size = 1234 tmp = mock_temp.return_value.__enter__.return_value self.assertRaises( exception.ImageUnacceptable, image_utils.fetch_to_volume_format, ctxt, image_service, image_id, dest, volume_format, blocksize, user_id=user_id, project_id=project_id, size=size, run_as_root=run_as_root) image_service.show.assert_called_once_with(ctxt, image_id) mock_temp.assert_called_once_with() mock_info.assert_has_calls([ mock.call(tmp, run_as_root=run_as_root), mock.call(tmp, run_as_root=run_as_root)]) mock_fetch.assert_called_once_with(ctxt, image_service, image_id, tmp, user_id, project_id) self.assertFalse(mock_repl_xen.called) self.assertFalse(mock_copy.called) self.assertFalse(mock_convert.called) @mock.patch('cinder.image.image_utils.convert_image') @mock.patch('cinder.image.image_utils.volume_utils.copy_volume') @mock.patch( 'cinder.image.image_utils.replace_xenserver_image_with_coalesced_vhd') @mock.patch('cinder.image.image_utils.is_xenserver_image', return_value=False) @mock.patch('cinder.image.image_utils.fetch') @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.temporary_file') @mock.patch('cinder.image.image_utils.CONF') def test_format_mismatch(self, mock_conf, mock_temp, mock_info, mock_fetch, mock_is_xen, mock_repl_xen, mock_copy, mock_convert): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest volume_format = mock.sentinel.volume_format blocksize = mock.sentinel.blocksize user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id size = 4321 run_as_root = mock.sentinel.run_as_root bps_limit = mock.sentinel.bps_limit mock_conf.volume_copy_bps_limit = bps_limit data = mock_info.return_value data.file_format = mock.sentinel.file_format data.backing_file = None data.virtual_size = 1234 tmp = mock_temp.return_value.__enter__.return_value self.assertRaises( exception.ImageUnacceptable, image_utils.fetch_to_volume_format, ctxt, image_service, image_id, dest, volume_format, blocksize, user_id=user_id, project_id=project_id, size=size, run_as_root=run_as_root) image_service.show.assert_called_once_with(ctxt, image_id) mock_temp.assert_called_once_with() mock_info.assert_has_calls([ mock.call(tmp, run_as_root=run_as_root), mock.call(tmp, run_as_root=run_as_root), mock.call(dest, run_as_root=run_as_root)]) mock_fetch.assert_called_once_with(ctxt, image_service, image_id, tmp, user_id, project_id) self.assertFalse(mock_repl_xen.called) self.assertFalse(mock_copy.called) mock_convert.assert_called_once_with(tmp, dest, volume_format, bps_limit=bps_limit, run_as_root=run_as_root) @mock.patch('cinder.image.image_utils.convert_image') @mock.patch('cinder.image.image_utils.volume_utils.copy_volume') @mock.patch( 'cinder.image.image_utils.replace_xenserver_image_with_coalesced_vhd') @mock.patch('cinder.image.image_utils.is_xenserver_image', return_value=True) @mock.patch('cinder.image.image_utils.fetch') @mock.patch('cinder.image.image_utils.qemu_img_info') @mock.patch('cinder.image.image_utils.temporary_file') @mock.patch('cinder.image.image_utils.CONF') def test_xenserver_to_vhd(self, mock_conf, mock_temp, mock_info, mock_fetch, mock_is_xen, mock_repl_xen, mock_copy, mock_convert): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id dest = mock.sentinel.dest volume_format = mock.sentinel.volume_format blocksize = mock.sentinel.blocksize user_id = mock.sentinel.user_id project_id = mock.sentinel.project_id size = 4321 run_as_root = mock.sentinel.run_as_root bps_limit = mock.sentinel.bps_limit mock_conf.volume_copy_bps_limit = bps_limit data = mock_info.return_value data.file_format = volume_format data.backing_file = None data.virtual_size = 1234 tmp = mock_temp.return_value.__enter__.return_value output = image_utils.fetch_to_volume_format( ctxt, image_service, image_id, dest, volume_format, blocksize, user_id=user_id, project_id=project_id, size=size, run_as_root=run_as_root) self.assertIsNone(output) image_service.show.assert_called_once_with(ctxt, image_id) mock_temp.assert_called_once_with() mock_info.assert_has_calls([ mock.call(tmp, run_as_root=run_as_root), mock.call(tmp, run_as_root=run_as_root), mock.call(dest, run_as_root=run_as_root)]) mock_fetch.assert_called_once_with(ctxt, image_service, image_id, tmp, user_id, project_id) mock_repl_xen.assert_called_once_with(tmp) self.assertFalse(mock_copy.called) mock_convert.assert_called_once_with(tmp, dest, volume_format, bps_limit=bps_limit, run_as_root=run_as_root) class TestXenserverUtils(test.TestCase): @mock.patch('cinder.image.image_utils.is_xenserver_format') def test_is_xenserver_image(self, mock_format): ctxt = mock.sentinel.context image_service = mock.Mock() image_id = mock.sentinel.image_id output = image_utils.is_xenserver_image(ctxt, image_service, image_id) image_service.show.assert_called_once_with(ctxt, image_id) mock_format.assert_called_once_with(image_service.show.return_value) self.assertEqual(mock_format.return_value, output) def test_is_xenserver_format(self): image_meta1 = {'disk_format': 'vhd', 'container_format': 'ovf'} self.assertTrue(image_utils.is_xenserver_format(image_meta1)) image_meta2 = {'disk_format': 'test_disk_format', 'container_format': 'test_cont_format'} self.assertFalse(image_utils.is_xenserver_format(image_meta2)) @mock.patch('cinder.image.image_utils.utils.execute') def test_extract_targz(self, mock_exec): name = mock.sentinel.archive_name target = mock.sentinel.target output = image_utils.extract_targz(name, target) mock_exec.assert_called_once_with('tar', '-xzf', name, '-C', target) self.assertIsNone(output) class TestVhdUtils(test.TestCase): @mock.patch('cinder.image.image_utils.utils.execute') def test_set_vhd_parent(self, mock_exec): vhd_path = mock.sentinel.vhd_path parentpath = mock.sentinel.parentpath output = image_utils.set_vhd_parent(vhd_path, parentpath) mock_exec.assert_called_once_with('vhd-util', 'modify', '-n', vhd_path, '-p', parentpath) self.assertIsNone(output) @mock.patch('cinder.image.image_utils.set_vhd_parent') def test_fix_vhd_chain(self, mock_set_parent): vhd_chain = (mock.sentinel.first, mock.sentinel.second, mock.sentinel.third, mock.sentinel.fourth, mock.sentinel.fifth) output = image_utils.fix_vhd_chain(vhd_chain) self.assertIsNone(output) mock_set_parent.assert_has_calls([ mock.call(mock.sentinel.first, mock.sentinel.second), mock.call(mock.sentinel.second, mock.sentinel.third), mock.call(mock.sentinel.third, mock.sentinel.fourth), mock.call(mock.sentinel.fourth, mock.sentinel.fifth)]) @mock.patch('cinder.image.image_utils.utils.execute', return_value=(98765.43210, mock.sentinel.error)) def test_get_vhd_size(self, mock_exec): vhd_path = mock.sentinel.vhd_path output = image_utils.get_vhd_size(vhd_path) mock_exec.assert_called_once_with('vhd-util', 'query', '-n', vhd_path, '-v') self.assertEqual(98765, output) @mock.patch('cinder.image.image_utils.utils.execute') def test_resize_vhd(self, mock_exec): vhd_path = mock.sentinel.vhd_path size = 387549349 journal = mock.sentinel.journal output = image_utils.resize_vhd(vhd_path, size, journal) self.assertIsNone(output) mock_exec.assert_called_once_with('vhd-util', 'resize', '-n', vhd_path, '-s', str(size), '-j', journal) @mock.patch('cinder.image.image_utils.utils.execute') def test_coalesce_vhd(self, mock_exec): vhd_path = mock.sentinel.vhd_path output = image_utils.coalesce_vhd(vhd_path) self.assertIsNone(output) mock_exec.assert_called_once_with('vhd-util', 'coalesce', '-n', vhd_path) @mock.patch('cinder.image.image_utils.coalesce_vhd') @mock.patch('cinder.image.image_utils.resize_vhd') @mock.patch('cinder.image.image_utils.get_vhd_size') @mock.patch('cinder.image.image_utils.utils.execute') def test_coalesce_chain(self, mock_exec, mock_size, mock_resize, mock_coal): vhd_chain = (mock.sentinel.first, mock.sentinel.second, mock.sentinel.third, mock.sentinel.fourth, mock.sentinel.fifth) output = image_utils.coalesce_chain(vhd_chain) self.assertEqual(mock.sentinel.fifth, output) mock_size.assert_has_calls([ mock.call(mock.sentinel.first), mock.call(mock.sentinel.second), mock.call(mock.sentinel.third), mock.call(mock.sentinel.fourth)]) mock_resize.assert_has_calls([ mock.call(mock.sentinel.second, mock_size.return_value, mock.ANY), mock.call(mock.sentinel.third, mock_size.return_value, mock.ANY), mock.call(mock.sentinel.fourth, mock_size.return_value, mock.ANY), mock.call(mock.sentinel.fifth, mock_size.return_value, mock.ANY)]) mock_coal.assert_has_calls([ mock.call(mock.sentinel.first), mock.call(mock.sentinel.second), mock.call(mock.sentinel.third), mock.call(mock.sentinel.fourth)]) @mock.patch('cinder.image.image_utils.os.path') def test_discover_vhd_chain(self, mock_path): directory = '/some/test/directory' mock_path.join.side_effect = lambda x, y: '/'.join((x, y)) mock_path.exists.side_effect = (True, True, True, False) output = image_utils.discover_vhd_chain(directory) expected_output = ['/some/test/directory/0.vhd', '/some/test/directory/1.vhd', '/some/test/directory/2.vhd'] self.assertEqual(expected_output, output) @mock.patch('cinder.image.image_utils.temporary_dir') @mock.patch('cinder.image.image_utils.os.rename') @mock.patch('cinder.image.image_utils.fileutils.delete_if_exists') @mock.patch('cinder.image.image_utils.coalesce_chain') @mock.patch('cinder.image.image_utils.fix_vhd_chain') @mock.patch('cinder.image.image_utils.discover_vhd_chain') @mock.patch('cinder.image.image_utils.extract_targz') def test_replace_xenserver_image_with_coalesced_vhd( self, mock_targz, mock_discover, mock_fix, mock_coal, mock_delete, mock_rename, mock_temp): image_file = mock.sentinel.image_file tmp = mock_temp.return_value.__enter__.return_value output = image_utils.replace_xenserver_image_with_coalesced_vhd( image_file) self.assertIsNone(output) mock_targz.assert_called_once_with(image_file, tmp) mock_discover.assert_called_once_with(tmp) mock_fix.assert_called_once_with(mock_discover.return_value) mock_coal.assert_called_once_with(mock_discover.return_value) mock_delete.assert_called_once_with(image_file) mock_rename.assert_called_once_with(mock_coal.return_value, image_file) class TestCreateTemporaryFile(test.TestCase): @mock.patch('cinder.image.image_utils.os.close') @mock.patch('cinder.image.image_utils.CONF') @mock.patch('cinder.image.image_utils.os.path.exists') @mock.patch('cinder.image.image_utils.os.makedirs') @mock.patch('cinder.image.image_utils.tempfile.mkstemp') def test_create_temporary_file_no_dir(self, mock_mkstemp, mock_dirs, mock_path, mock_conf, mock_close): mock_conf.image_conversion_dir = None fd = mock.sentinel.file_descriptor path = mock.sentinel.absolute_pathname mock_mkstemp.return_value = (fd, path) output = image_utils.create_temporary_file() self.assertEqual(path, output) mock_mkstemp.assert_called_once_with(dir=None) mock_close.assert_called_once_with(fd) @mock.patch('cinder.image.image_utils.os.close') @mock.patch('cinder.image.image_utils.CONF') @mock.patch('cinder.image.image_utils.os.path.exists', return_value=True) @mock.patch('cinder.image.image_utils.os.makedirs') @mock.patch('cinder.image.image_utils.tempfile.mkstemp') def test_create_temporary_file_with_dir(self, mock_mkstemp, mock_dirs, mock_path, mock_conf, mock_close): conv_dir = mock.sentinel.image_conversion_dir mock_conf.image_conversion_dir = conv_dir fd = mock.sentinel.file_descriptor path = mock.sentinel.absolute_pathname mock_mkstemp.return_value = (fd, path) output = image_utils.create_temporary_file() self.assertEqual(path, output) self.assertFalse(mock_dirs.called) mock_mkstemp.assert_called_once_with(dir=conv_dir) mock_close.assert_called_once_with(fd) @mock.patch('cinder.image.image_utils.os.close') @mock.patch('cinder.image.image_utils.CONF') @mock.patch('cinder.image.image_utils.os.path.exists', return_value=False) @mock.patch('cinder.image.image_utils.os.makedirs') @mock.patch('cinder.image.image_utils.tempfile.mkstemp') def test_create_temporary_file_and_dir(self, mock_mkstemp, mock_dirs, mock_path, mock_conf, mock_close): conv_dir = mock.sentinel.image_conversion_dir mock_conf.image_conversion_dir = conv_dir fd = mock.sentinel.file_descriptor path = mock.sentinel.absolute_pathname mock_mkstemp.return_value = (fd, path) output = image_utils.create_temporary_file() self.assertEqual(path, output) mock_dirs.assert_called_once_with(conv_dir) mock_mkstemp.assert_called_once_with(dir=conv_dir) mock_close.assert_called_once_with(fd) class TestTemporaryFileContextManager(test.TestCase): @mock.patch('cinder.image.image_utils.create_temporary_file', return_value=mock.sentinel.temporary_file) @mock.patch('cinder.image.image_utils.fileutils.delete_if_exists') def test_temporary_file(self, mock_delete, mock_create): with image_utils.temporary_file() as tmp_file: self.assertEqual(mock.sentinel.temporary_file, tmp_file) self.assertFalse(mock_delete.called) mock_delete.assert_called_once_with(mock.sentinel.temporary_file)","import contextlib import moxfrom oslo.config import cfg from oslo.utils import units from cinder import contextfrom cinder.openstack.common import fileutilsfrom cinder import utils from cinder.volume import utils as volume_utils CONF = cfg.CONF class FakeImageService: def __init__(self): self._imagedata = {} def download(self, context, image_id, data): self.show(context, image_id) data.write(self._imagedata.get(image_id, '')) def show(self, context, image_id): return {'size': 2 * units.Gi, 'disk_format': 'qcow2', 'container_format': 'bare'} def update(self, context, image_id, metadata, path): pass class TestUtils(test.TestCase): TEST_IMAGE_ID = 321 TEST_DEV_PATH = ""/dev/ether/fake_dev"" def setUp(self): super(TestUtils, self).setUp() self._mox = mox.Mox() self._image_service = FakeImageService() self.addCleanup(self._mox.UnsetStubs) def test_resize_image(self): mox = self._mox mox.StubOutWithMock(utils, 'execute') TEST_IMG_SOURCE = 'boobar.img' TEST_IMG_SIZE_IN_GB = 1 utils.execute('qemu-img', 'resize', TEST_IMG_SOURCE, '%sG' % TEST_IMG_SIZE_IN_GB, run_as_root=True) mox.ReplayAll() image_utils.resize_image(TEST_IMG_SOURCE, TEST_IMG_SIZE_IN_GB, run_as_root=True) mox.VerifyAll() def test_convert_image(self, mock_stat): mox = self._mox mox.StubOutWithMock(utils, 'execute') mox.StubOutWithMock(utils, 'is_blk_device') TEST_OUT_FORMAT = 'vmdk' TEST_SOURCE = 'img/qemu.img' TEST_DEST = '/img/vmware.vmdk' utils.is_blk_device(TEST_DEST).AndReturn(True) utils.execute('dd', 'count=0', 'if=img/qemu.img', 'of=/img/vmware.vmdk', 'oflag=direct', run_as_root=True) utils.execute( 'qemu-img', 'convert', '-t', 'none', '-O', TEST_OUT_FORMAT, TEST_SOURCE, TEST_DEST, run_as_root=True) mox.ReplayAll() image_utils.convert_image(TEST_SOURCE, TEST_DEST, TEST_OUT_FORMAT, run_as_root=True) mox.VerifyAll() def test_qemu_img_info(self): TEST_PATH = ""img/qemu.qcow2"" TEST_RETURN = ""image: qemu.qcow2\n""\ ""backing_file: qemu.qcow2 (actual path: qemu.qcow2)\n""\ ""file_format: qcow2\n""\ ""virtual_size: 50M (52428800 bytes)\n""\ ""cluster_size: 65536\n""\ ""disk_size: 196K (200704 bytes)\n""\ ""Snapshot list:\n""\ ""ID TAG VM SIZE DATE VM CLOCK\n""\ ""1 snap1 1.7G 2011-10-04 19:04:00 32:06:34.974"" TEST_STR = ""image: qemu.qcow2\n""\ ""file_format: qcow2\n""\ ""virtual_size: 52428800\n""\ ""disk_size: 200704\n""\ ""cluster_size: 65536\n""\ ""backing_file: qemu.qcow2\n""\ ""snapshots: [{'date': '2011-10-04', ""\ ""'vm_clock': '19:04:00 32:06:34.974', ""\ ""'vm_size': '1.7G', 'tag': 'snap1', 'id': '1'}]"" mox = self._mox mox.StubOutWithMock(utils, 'execute') utils.execute( 'env', 'LC_ALL=C', 'qemu-img', 'info', TEST_PATH, run_as_root=True).AndReturn( (TEST_RETURN, 'ignored')) mox.ReplayAll() inf = image_utils.qemu_img_info(TEST_PATH, run_as_root=True) self.assertEqual(inf.image, 'qemu.qcow2') self.assertEqual(inf.backing_file, 'qemu.qcow2') self.assertEqual(inf.file_format, 'qcow2') self.assertEqual(inf.virtual_size, 52428800) self.assertEqual(inf.cluster_size, 65536) self.assertEqual(inf.disk_size, 200704) self.assertEqual(inf.snapshots[0]['id'], '1') self.assertEqual(inf.snapshots[0]['tag'], 'snap1') self.assertEqual(inf.snapshots[0]['vm_size'], '1.7G') self.assertEqual(inf.snapshots[0]['date'], '2011-10-04') self.assertEqual(inf.snapshots[0]['vm_clock'], '19:04:00 32:06:34.974') self.assertEqual(str(inf), TEST_STR) def test_qemu_img_info_alt(self): """"""Test a slightly different variation of qemu-img output. (Based on Fedora 19's qemu-img 1.4.2.) """""" TEST_PATH = ""img/qemu.qcow2"" TEST_RETURN = ""image: qemu.qcow2\n""\ ""backing file: qemu.qcow2 (actual path: qemu.qcow2)\n""\ ""file format: qcow2\n""\ ""virtual size: 50M (52428800 bytes)\n""\ ""cluster_size: 65536\n""\ ""disk size: 196K (200704 bytes)\n""\ ""Snapshot list:\n""\ ""ID TAG VM SIZE DATE VM CLOCK\n""\ ""1 snap1 1.7G 2011-10-04 19:04:00 32:06:34.974"" TEST_STR = ""image: qemu.qcow2\n""\ ""file_format: qcow2\n""\ ""virtual_size: 52428800\n""\ ""disk_size: 200704\n""\ ""cluster_size: 65536\n""\ ""backing_file: qemu.qcow2\n""\ ""snapshots: [{'date': '2011-10-04', ""\ ""'vm_clock': '19:04:00 32:06:34.974', ""\ ""'vm_size': '1.7G', 'tag': 'snap1', 'id': '1'}]"" mox = self._mox mox.StubOutWithMock(utils, 'execute') cmd = ['env', 'LC_ALL=C', 'qemu-img', 'info', TEST_PATH] utils.execute(*cmd, run_as_root=True).AndReturn( (TEST_RETURN, 'ignored')) mox.ReplayAll() inf = image_utils.qemu_img_info(TEST_PATH, run_as_root=True) self.assertEqual(inf.image, 'qemu.qcow2') self.assertEqual(inf.backing_file, 'qemu.qcow2') self.assertEqual(inf.file_format, 'qcow2') self.assertEqual(inf.virtual_size, 52428800) self.assertEqual(inf.cluster_size, 65536) self.assertEqual(inf.disk_size, 200704) self.assertEqual(inf.snapshots[0]['id'], '1') self.assertEqual(inf.snapshots[0]['tag'], 'snap1') self.assertEqual(inf.snapshots[0]['vm_size'], '1.7G') self.assertEqual(inf.snapshots[0]['date'], '2011-10-04') self.assertEqual(inf.snapshots[0]['vm_clock'], '19:04:00 32:06:34.974') self.assertEqual(str(inf), TEST_STR) def _test_fetch_to_raw(self, has_qemu=True, src_inf=None, dest_inf=None, bps_limit=0): mox = self._mox mox.StubOutWithMock(image_utils, 'create_temporary_file') mox.StubOutWithMock(utils, 'execute') mox.StubOutWithMock(image_utils, 'fetch') mox.StubOutWithMock(volume_utils, 'setup_blkio_cgroup') mox.StubOutWithMock(utils, 'is_blk_device') TEST_INFO = (""image: qemu.qcow2\n"" ""file format: raw\n"" ""virtual size: 0 (0 bytes)\n"" ""disk size: 0"") utils.is_blk_device(self.TEST_DEV_PATH).AndReturn(True) self.override_config('volume_copy_bps_limit', bps_limit) image_utils.create_temporary_file().AndReturn(self.TEST_DEV_PATH) test_qemu_img = utils.execute( 'env', 'LC_ALL=C', 'qemu-img', 'info', self.TEST_DEV_PATH, run_as_root=True) if has_qemu: test_qemu_img.AndReturn((TEST_INFO, 'ignored')) image_utils.fetch(context, self._image_service, self.TEST_IMAGE_ID, self.TEST_DEV_PATH, None, None) else: test_qemu_img.AndRaise(processutils.ProcessExecutionError()) if has_qemu and src_inf: utils.execute( 'env', 'LC_ALL=C', 'qemu-img', 'info', self.TEST_DEV_PATH, run_as_root=True).AndReturn( (src_inf, 'ignored')) if has_qemu and dest_inf: if bps_limit: prefix = ('cgexec', '-g', 'blkio:test') else: prefix = () utils.execute('dd', 'count=0', 'if=/dev/ether/fake_dev', 'of=/dev/ether/fake_dev', 'oflag=direct', run_as_root=True) cmd = prefix + ('qemu-img', 'convert', '-t', 'none', '-O', 'raw', self.TEST_DEV_PATH, self.TEST_DEV_PATH) volume_utils.setup_blkio_cgroup( self.TEST_DEV_PATH, self.TEST_DEV_PATH, bps_limit).AndReturn(prefix) utils.execute(*cmd, run_as_root=True) utils.execute( 'env', 'LC_ALL=C', 'qemu-img', 'info', self.TEST_DEV_PATH, run_as_root=True).AndReturn( (dest_inf, 'ignored')) self._mox.ReplayAll() @mock.patch('os.stat') def test_fetch_to_raw(self, mock_stat): SRC_INFO = (""image: qemu.qcow2\n"" ""file_format: qcow2 \n"" ""virtual_size: 50M (52428800 bytes)\n"" ""cluster_size: 65536\n"" ""disk_size: 196K (200704 bytes)"") DST_INFO = (""image: qemu.raw\n"" ""file_format: raw\n"" ""virtual_size: 50M (52428800 bytes)\n"" ""cluster_size: 65536\n"" ""disk_size: 196K (200704 bytes)\n"") self._test_fetch_to_raw(src_inf=SRC_INFO, dest_inf=DST_INFO) image_utils.fetch_to_raw(context, self._image_service, self.TEST_IMAGE_ID, self.TEST_DEV_PATH, mox.IgnoreArg(), run_as_root=True) self._mox.VerifyAll() @mock.patch('os.stat') def test_fetch_to_raw_with_bps_limit(self, mock_stat): SRC_INFO = (""image: qemu.qcow2\n"" ""file_format: qcow2 \n"" ""virtual_size: 50M (52428800 bytes)\n"" ""cluster_size: 65536\n"" ""disk_size: 196K (200704 bytes)"") DST_INFO = (""image: qemu.raw\n"" ""file_format: raw\n"" ""virtual_size: 50M (52428800 bytes)\n"" ""cluster_size: 65536\n"" ""disk_size: 196K (200704 bytes)\n"") self._test_fetch_to_raw(src_inf=SRC_INFO, dest_inf=DST_INFO, bps_limit=1048576) image_utils.fetch_to_raw(context, self._image_service, self.TEST_IMAGE_ID, self.TEST_DEV_PATH, mox.IgnoreArg()) self._mox.VerifyAll() def test_fetch_to_raw_no_qemu_img(self): self._test_fetch_to_raw(has_qemu=False) self.assertRaises(exception.ImageUnacceptable, image_utils.fetch_to_raw, context, self._image_service, self.TEST_IMAGE_ID, self.TEST_DEV_PATH, mox.IgnoreArg()) def test_fetch_to_raw_on_error_parsing_failed(self): SRC_INFO_NO_FORMAT = (""image: qemu.qcow2\n"" ""virtual_size: 50M (52428800 bytes)\n"" ""cluster_size: 65536\n"" ""disk_size: 196K (200704 bytes)"") self._test_fetch_to_raw(src_inf=SRC_INFO_NO_FORMAT) self.assertRaises(exception.ImageUnacceptable, image_utils.fetch_to_raw, context, self._image_service, self.TEST_IMAGE_ID, self.TEST_DEV_PATH, mox.IgnoreArg()) def test_fetch_to_raw_on_error_backing_file(self): SRC_INFO_BACKING_FILE = (""image: qemu.qcow2\n"" ""backing_file: qemu.qcow2\n"" ""file_format: qcow2 \n"" ""virtual_size: 50M (52428800 bytes)\n"" ""cluster_size: 65536\n"" ""disk_size: 196K (200704 bytes)"") self._test_fetch_to_raw(src_inf=SRC_INFO_BACKING_FILE) self.assertRaises(exception.ImageUnacceptable, image_utils.fetch_to_raw, context, self._image_service, self.TEST_IMAGE_ID, self.TEST_DEV_PATH, mox.IgnoreArg()) @mock.patch('os.stat') def test_fetch_to_raw_on_error_not_convert_to_raw(self, mock_stat): IMG_INFO = (""image: qemu.qcow2\n"" ""file_format: qcow2 \n"" ""virtual_size: 50M (52428800 bytes)\n"" ""cluster_size: 65536\n"" ""disk_size: 196K (200704 bytes)"") self._test_fetch_to_raw(src_inf=IMG_INFO, dest_inf=IMG_INFO) self.assertRaises(exception.ImageUnacceptable, image_utils.fetch_to_raw, context, self._image_service, self.TEST_IMAGE_ID, self.TEST_DEV_PATH, mox.IgnoreArg()) def test_fetch_to_raw_on_error_image_size(self): TEST_VOLUME_SIZE = 1 SRC_INFO = (""image: qemu.qcow2\n"" ""file_format: qcow2 \n"" ""virtual_size: 2G (2147483648 bytes)\n"" ""cluster_size: 65536\n"" ""disk_size: 196K (200704 bytes)"") self._test_fetch_to_raw(src_inf=SRC_INFO) self.assertRaises(exception.ImageUnacceptable, image_utils.fetch_to_raw, context, self._image_service, self.TEST_IMAGE_ID, self.TEST_DEV_PATH, mox.IgnoreArg(), size=TEST_VOLUME_SIZE) def _test_fetch_verify_image(self, qemu_info, volume_size=1): fake_image_service = FakeImageService() mox = self._mox mox.StubOutWithMock(image_utils, 'fetch') mox.StubOutWithMock(utils, 'execute') image_utils.fetch(context, fake_image_service, self.TEST_IMAGE_ID, self.TEST_DEV_PATH, None, None) utils.execute( 'env', 'LC_ALL=C', 'qemu-img', 'info', self.TEST_DEV_PATH, run_as_root=True).AndReturn( (qemu_info, 'ignored')) self._mox.ReplayAll() context, fake_image_service, self.TEST_IMAGE_ID, self.TEST_DEV_PATH, size=volume_size) def test_fetch_verify_image_with_backing_file(self): TEST_RETURN = ""image: qemu.qcow2\n""\ ""backing_file: qemu.qcow2 (actual path: qemu.qcow2)\n""\ ""file_format: qcow2\n""\ ""virtual_size: 50M (52428800 bytes)\n""\ ""cluster_size: 65536\n""\ ""disk_size: 196K (200704 bytes)\n""\ ""Snapshot list:\n""\ ""ID TAG VM SIZE DATE VM CLOCK\n""\ ""1 snap1 1.7G 2011-10-04 19:04:00 32:06:34.974"" self._test_fetch_verify_image(TEST_RETURN) def test_fetch_verify_image_without_file_format(self): TEST_RETURN = ""image: qemu.qcow2\n""\ ""virtual_size: 50M (52428800 bytes)\n""\ ""cluster_size: 65536\n""\ ""disk_size: 196K (200704 bytes)\n""\ ""Snapshot list:\n""\ ""ID TAG VM SIZE DATE VM CLOCK\n""\ ""1 snap1 1.7G 2011-10-04 19:04:00 32:06:34.974"" self._test_fetch_verify_image(TEST_RETURN) def test_fetch_verify_image_image_size(self): TEST_RETURN = ""image: qemu.qcow2\n""\ ""file_format: qcow2\n""\ ""virtual_size: 2G (2147483648 bytes)\n""\ ""cluster_size: 65536\n""\ ""disk_size: 196K (200704 bytes)\n""\ ""Snapshot list:\n""\ ""ID TAG VM SIZE DATE VM CLOCK\n""\ ""1 snap1 1.7G 2011-10-04 19:04:00 32:06:34.974"" self._test_fetch_verify_image(TEST_RETURN) class TestExtractTo(test.TestCase): def test_extract_to_calls_tar(self): mox = self.mox mox.StubOutWithMock(utils, 'execute') utils.execute( 'tar', '-xzf', 'archive.tgz', '-C', 'targetpath').AndReturn( ('ignored', 'ignored')) mox.ReplayAll() image_utils.extract_targz('archive.tgz', 'targetpath') mox.VerifyAll() class TestSetVhdParent(test.TestCase): def test_vhd_util_call(self): mox = self.mox mox.StubOutWithMock(utils, 'execute') utils.execute( 'vhd-util', 'modify', '-n', 'child', '-p', 'parent').AndReturn( ('ignored', 'ignored')) mox.ReplayAll() image_utils.set_vhd_parent('child', 'parent') mox.VerifyAll() class TestFixVhdChain(test.TestCase): def test_empty_chain(self): mox = self.mox mox.StubOutWithMock(image_utils, 'set_vhd_parent') mox.ReplayAll() image_utils.fix_vhd_chain([]) def test_single_vhd_file_chain(self): mox = self.mox mox.StubOutWithMock(image_utils, 'set_vhd_parent') mox.ReplayAll() image_utils.fix_vhd_chain(['0.vhd']) def test_chain_with_two_elements(self): mox = self.mox mox.StubOutWithMock(image_utils, 'set_vhd_parent') image_utils.set_vhd_parent('0.vhd', '1.vhd') mox.ReplayAll() image_utils.fix_vhd_chain(['0.vhd', '1.vhd']) class TestGetSize(test.TestCase): def test_vhd_util_call(self): mox = self.mox mox.StubOutWithMock(utils, 'execute') utils.execute( 'vhd-util', 'query', '-n', 'vhdfile', '-v').AndReturn( ('1024', 'ignored')) mox.ReplayAll() result = image_utils.get_vhd_size('vhdfile') mox.VerifyAll() self.assertEqual(1024, result) class TestResize(test.TestCase): def test_vhd_util_call(self): mox = self.mox mox.StubOutWithMock(utils, 'execute') utils.execute( 'vhd-util', 'resize', '-n', 'vhdfile', '-s', '1024', '-j', 'journal').AndReturn(('ignored', 'ignored')) mox.ReplayAll() image_utils.resize_vhd('vhdfile', 1024, 'journal') mox.VerifyAll() class TestCoalesce(test.TestCase): def test_vhd_util_call(self): mox = self.mox mox.StubOutWithMock(utils, 'execute') utils.execute( 'vhd-util', 'coalesce', '-n', 'vhdfile' ).AndReturn(('ignored', 'ignored')) mox.ReplayAll() image_utils.coalesce_vhd('vhdfile') mox.VerifyAll() @contextlib.contextmanager def fake_context(return_value): yield return_value class TestTemporaryFile(test.TestCase): def test_file_unlinked(self): mox = self.mox mox.StubOutWithMock(image_utils, 'create_temporary_file') mox.StubOutWithMock(fileutils, 'delete_if_exists') image_utils.create_temporary_file().AndReturn('somefile') fileutils.delete_if_exists('somefile') mox.ReplayAll() with image_utils.temporary_file(): pass def test_file_unlinked_on_error(self): mox = self.mox mox.StubOutWithMock(image_utils, 'create_temporary_file') mox.StubOutWithMock(fileutils, 'delete_if_exists') image_utils.create_temporary_file().AndReturn('somefile') fileutils.delete_if_exists('somefile') mox.ReplayAll() def sut(): with image_utils.temporary_file(): raise test.TestingException() self.assertRaises(test.TestingException, sut) class TestCoalesceChain(test.TestCase): def test_single_vhd(self): mox = self.mox mox.StubOutWithMock(image_utils, 'get_vhd_size') mox.StubOutWithMock(image_utils, 'resize_vhd') mox.StubOutWithMock(image_utils, 'coalesce_vhd') mox.ReplayAll() result = image_utils.coalesce_chain(['0.vhd']) mox.VerifyAll() self.assertEqual('0.vhd', result) def test_chain_of_two_vhds(self): self.mox.StubOutWithMock(image_utils, 'get_vhd_size') self.mox.StubOutWithMock(image_utils, 'temporary_dir') self.mox.StubOutWithMock(image_utils, 'resize_vhd') self.mox.StubOutWithMock(image_utils, 'coalesce_vhd') self.mox.StubOutWithMock(image_utils, 'temporary_file') image_utils.get_vhd_size('0.vhd').AndReturn(1024) image_utils.temporary_dir().AndReturn(fake_context('tdir')) image_utils.resize_vhd('1.vhd', 1024, 'tdir/vhd-util-resize-journal') image_utils.coalesce_vhd('0.vhd') self.mox.ReplayAll() result = image_utils.coalesce_chain(['0.vhd', '1.vhd']) self.mox.VerifyAll() self.assertEqual('1.vhd', result) class TestDiscoverChain(test.TestCase): def test_discovery_calls(self): mox = self.mox mox.StubOutWithMock(image_utils, 'file_exist') image_utils.file_exist('some/path/0.vhd').AndReturn(True) image_utils.file_exist('some/path/1.vhd').AndReturn(True) image_utils.file_exist('some/path/2.vhd').AndReturn(False) mox.ReplayAll() result = image_utils.discover_vhd_chain('some/path') mox.VerifyAll() self.assertEqual( ['some/path/0.vhd', 'some/path/1.vhd'], result) class TestXenServerImageToCoalescedVhd(test.TestCase): def test_calls(self): mox = self.mox mox.StubOutWithMock(image_utils, 'temporary_dir') mox.StubOutWithMock(image_utils, 'extract_targz') mox.StubOutWithMock(image_utils, 'discover_vhd_chain') mox.StubOutWithMock(image_utils, 'fix_vhd_chain') mox.StubOutWithMock(image_utils, 'coalesce_chain') mox.StubOutWithMock(image_utils.os, 'unlink') mox.StubOutWithMock(fileutils, 'delete_if_exists') mox.StubOutWithMock(image_utils, 'rename_file') image_utils.temporary_dir().AndReturn(fake_context('somedir')) image_utils.extract_targz('image', 'somedir') image_utils.discover_vhd_chain('somedir').AndReturn( ['somedir/0.vhd', 'somedir/1.vhd']) image_utils.fix_vhd_chain(['somedir/0.vhd', 'somedir/1.vhd']) image_utils.coalesce_chain( ['somedir/0.vhd', 'somedir/1.vhd']).AndReturn('somedir/1.vhd') fileutils.delete_if_exists('image') image_utils.rename_file('somedir/1.vhd', 'image') mox.ReplayAll() image_utils.replace_xenserver_image_with_coalesced_vhd('image') mox.VerifyAll() context = mock.sentinel.context output = image_utils.upload_volume(context, image_service, image_meta, context, image_meta['id'], {}, context = mock.sentinel.context output = image_utils.upload_volume(context, image_service, image_meta, context, image_meta['id'], {}, context = mock.sentinel.context output = image_utils.upload_volume(context, image_service, image_meta, context, image_meta['id'], {}, context = mock.sentinel.context context, image_service, image_meta, volume_path)",1037,620
openstack%2Fheat~master~I332b6623b6047c6576e8991541dec6e97f40d129,openstack/heat,master,I332b6623b6047c6576e8991541dec6e97f40d129,Add coalesce function to HOT,ABANDONED,2014-11-06 10:53:58.000000000,2014-12-18 10:50:37.000000000,,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6899}, {'_account_id': 7193}, {'_account_id': 8688}]","[{'number': 1, 'created': '2014-11-06 10:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f5d67b40649ad27c809d4d0307c53bc28d3f086f', 'message': 'Add coalesce function to HOT\n\nThis function returns its first non-null argument, considering empty\nstrings, lists and dicts as null.\n\nChange-Id: I332b6623b6047c6576e8991541dec6e97f40d129\n'}, {'number': 2, 'created': '2014-11-06 14:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d64cc797d7741579ed4c3bebc2ea9c9c51769ce9', 'message': 'Add coalesce function to HOT\n\nThis function returns its first non-null argument, considering empty\nstrings, lists and dicts as null. This allows EG:\n\n  some_thing:\n    config:\n      ControlVIP:\n        first_nonnull:\n         - {get_param: ControlVIP}\n         - {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]}]}\n\nChange-Id: I332b6623b6047c6576e8991541dec6e97f40d129\n'}, {'number': 3, 'created': '2014-11-06 14:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e0f9f766a87fbed54fb05e06807f8bd3803e7191', 'message': 'Add coalesce function to HOT\n\nThis function returns its first non-null, non-empty argument. False and 0\nare returned. This allows EG:\n\n  some_thing:\n    config:\n      ControlVIP:\n        first_nonnull:\n         - {get_param: ControlVIP}\n         - {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]}]}\n\nChange-Id: I332b6623b6047c6576e8991541dec6e97f40d129\n'}, {'number': 4, 'created': '2014-11-06 14:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6ef253fe481852bb5a0fae0e30f8bac21b0242a3', 'message': 'Add coalesce function to HOT\n\nThis function returns its first non-null, non-empty argument. False and 0\nare returned. This allows EG:\n\n  some_thing:\n    config:\n      ControlVIP:\n        first_nonnull:\n         - {get_param: ControlVIP}\n         - {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]}]}\n\nChange-Id: I332b6623b6047c6576e8991541dec6e97f40d129\n'}, {'number': 5, 'created': '2014-11-06 15:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0a72eb5719464072cf24986e95f2e98ea5833f0d', 'message': 'Add coalesce function to HOT\n\nThis function returns its first non-null, non-empty argument. False and 0\nare returned. This allows EG:\n\n  some_thing:\n    config:\n      ControlVIP:\n        first_nonnull:\n         - {get_param: ControlVIP}\n         - {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]}]}\n\nChange-Id: I332b6623b6047c6576e8991541dec6e97f40d129\n'}, {'number': 6, 'created': '2014-11-06 15:14:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a88460627273949f05a6112fc81f516b43213f32', 'message': 'Add coalesce function to HOT\n\nThis function returns its first non-null, non-empty argument. False and 0\nare returned. This allows EG:\n\n  some_thing:\n    config:\n      ControlVIP:\n        first_nonnull:\n         - {get_param: ControlVIP}\n         - {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]}]}\n\nChange-Id: I332b6623b6047c6576e8991541dec6e97f40d129\n'}, {'number': 7, 'created': '2014-11-07 02:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5e0fa9f865401e08bf76e935f11f9c12b0492a30', 'message': 'Add coalesce function to HOT\n\nThis function returns its first non-null, non-empty argument. False and 0\nare returned. This allows EG:\n\n  some_thing:\n    config:\n      ControlVIP:\n        first_nonnull:\n         - {get_param: ControlVIP}\n         - {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]}]}\n\nChange-Id: I332b6623b6047c6576e8991541dec6e97f40d129\n'}, {'number': 8, 'created': '2014-11-07 02:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1cad0c804d7c80534cda22e7d6e32d69b0edb09c', 'message': 'Add coalesce function to HOT\n\nThis function returns its first non-null, non-empty argument. False and 0\nare returned. This allows EG:\n\n  some_thing:\n    config:\n      ControlVIP:\n        coalesce:\n         - {get_param: ControlVIP}\n         - {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]}]}\n\nThe function has been added to HOT version 2014-10-16.\n\nChange-Id: I332b6623b6047c6576e8991541dec6e97f40d129\n'}, {'number': 9, 'created': '2014-11-07 07:21:46.000000000', 'files': ['heat/engine/hot/functions.py', 'doc/source/template_guide/hot_spec.rst', 'heat/engine/hot/template.py', 'heat/tests/test_hot.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3e31df6912ee077d7dae69be771757307dc13e05', 'message': 'Add coalesce function to HOT\n\nThis function returns its first non-null, non-empty argument. False and 0\nare returned. This allows EG:\n\n  some_thing:\n    config:\n      ControlVIP:\n        coalesce:\n         - {get_param: ControlVIP}\n         - {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]}]}\n\nThe function has been added to HOT version 2014-10-16.\n\nChange-Id: I332b6623b6047c6576e8991541dec6e97f40d129\n'}]",5,132996,3e31df6912ee077d7dae69be771757307dc13e05,27,6,9,8688,,,0,"Add coalesce function to HOT

This function returns its first non-null, non-empty argument. False and 0
are returned. This allows EG:

  some_thing:
    config:
      ControlVIP:
        coalesce:
         - {get_param: ControlVIP}
         - {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]}]}

The function has been added to HOT version 2014-10-16.

Change-Id: I332b6623b6047c6576e8991541dec6e97f40d129
",git fetch https://review.opendev.org/openstack/heat refs/changes/96/132996/9 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/hot/functions.py'],1,f5d67b40649ad27c809d4d0307c53bc28d3f086f,,"class Coalesce(function.Function): ''' A function for returning the first non-null argument. Empty strings, lists and dicts are all considered null. For example:: coalesce: - <arg1> - .. - <argN> ''' def result(self): args = function.resolve(self.args) if not args: return '' for arg in args: if arg: return arg else: return '' ",,25,0
openstack%2Fcinder~master~Idecba85e19a0fe16dfc9f840913857137bfeee1b,openstack/cinder,master,Idecba85e19a0fe16dfc9f840913857137bfeee1b,Improve use of temporary_file and temporary_dir,MERGED,2014-12-09 12:06:43.000000000,2014-12-18 10:48:17.000000000,2014-12-18 10:48:15.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 7219}, {'_account_id': 8871}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-09 12:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ff6ac1cefd6935f28632d7df4e5ec648a9bcbc1', 'message': 'Improve use of temporary_file and temporary_dir\n\ncinder/image/image_utils.py contains the functions temporary_file and\ntemporary_dir for use with handling temporary data.\n\ntemporary_file automatically creates files in CONF.image_conversion_dir\nand will create CONF.image_conversion_dir if required. This commit\nremoves duplicate code that checks for/creates the dir before calling\ntemporary_file. This commit also replaces code that duplicates the\nfunctionality of temporary_file with temporary_file.\n\ntemporary_dir requires that CONF.image_conversion_dir exists. This\ncommit adds a check to the function that creates it if it is missing.\n\nChange-Id: Idecba85e19a0fe16dfc9f840913857137bfeee1b\n'}, {'number': 2, 'created': '2014-12-09 16:58:03.000000000', 'files': ['cinder/image/image_utils.py', 'cinder/volume/drivers/windows/windows.py', 'cinder/tests/test_image_utils.py', 'cinder/tests/windows/test_windows.py', 'cinder/tests/test_sheepdog.py', 'cinder/volume/drivers/sheepdog.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/297794bfbf3dc73b5667c0b34ab3a4f0e7bf43dd', 'message': 'Improve use of temporary_file and temporary_dir\n\ncinder/image/image_utils.py contains the functions temporary_file and\ntemporary_dir for use with handling temporary data.\n\ntemporary_file automatically creates files in CONF.image_conversion_dir\nand will create CONF.image_conversion_dir if required. This commit\nremoves duplicate code that checks for/creates the dir before calling\ntemporary_file. This commit also replaces code that duplicates the\nfunctionality of temporary_file with temporary_file.\n\ntemporary_dir requires that CONF.image_conversion_dir exists. This\ncommit adds a check to the function that creates it if it is missing.\n\nChange-Id: Idecba85e19a0fe16dfc9f840913857137bfeee1b\n'}]",6,140309,297794bfbf3dc73b5667c0b34ab3a4f0e7bf43dd,24,11,2,7219,,,0,"Improve use of temporary_file and temporary_dir

cinder/image/image_utils.py contains the functions temporary_file and
temporary_dir for use with handling temporary data.

temporary_file automatically creates files in CONF.image_conversion_dir
and will create CONF.image_conversion_dir if required. This commit
removes duplicate code that checks for/creates the dir before calling
temporary_file. This commit also replaces code that duplicates the
functionality of temporary_file with temporary_file.

temporary_dir requires that CONF.image_conversion_dir exists. This
commit adds a check to the function that creates it if it is missing.

Change-Id: Idecba85e19a0fe16dfc9f840913857137bfeee1b
",git fetch https://review.opendev.org/openstack/cinder refs/changes/09/140309/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/image/image_utils.py', 'cinder/volume/drivers/windows/windows.py', 'cinder/tests/test_image_utils.py', 'cinder/volume/drivers/sheepdog.py']",4,8ff6ac1cefd6935f28632d7df4e5ec648a9bcbc1,conv_dir," with image_utils.temporary_file() as tmp: image_id, tmp) image_utils.convert_image(tmp, 'sheepdog:%s' % volume['name'],","import osimport tempfile def _ensure_dir_exists(self, tmp_dir): if tmp_dir and not os.path.exists(tmp_dir): os.makedirs(tmp_dir) # use the image_conversion_dir as a temporary place to save the image conversion_dir = CONF.image_conversion_dir self._ensure_dir_exists(conversion_dir) with tempfile.NamedTemporaryFile(dir=conversion_dir) as tmp: image_id, tmp.name) image_utils.convert_image(tmp.name, 'sheepdog:%s' % volume['name'],",51,27
openstack%2Fhorizon~master~Ie34007f73af7e0941631a52f03841068e509a72c,openstack/horizon,master,Ie34007f73af7e0941631a52f03841068e509a72c,Base Glance Metadata Definitions Admin UI,MERGED,2014-07-02 03:46:05.000000000,2014-12-18 10:48:07.000000000,2014-12-18 10:48:04.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6650}, {'_account_id': 7665}, {'_account_id': 8642}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 10247}, {'_account_id': 11600}, {'_account_id': 12231}, {'_account_id': 12299}, {'_account_id': 12814}, {'_account_id': 13161}]","[{'number': 1, 'created': '2014-07-02 03:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c687d1554cefcb666f24413bb19a812bedb0f603', 'message': 'Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nSee https://review.openstack.org/#/c/98554/\n\nThis patch brings in the admin UI for the basic coarse grained\nactions on managing the metadata in the catalog. This includes creating a\nnamespace, importing metadata definitions into it, clearing metadata\ndefinitions from the namespace, deleting the namespace, and associating\nthe namespace for use with specific resource types.\n\nCurrent TODOs for this patch:\n* Switch to real Glance API\n* Add edit namespace info\n* Add project membership\n* Add policy checks\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 2, 'created': '2014-07-18 22:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/13bac0f76c3853ec3900d95381bca54949d0022d', 'message': 'Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nGlance is adding a metadata definitions catalog targeted for Juno. This\nis a common API hosted by the Glance service for vendors, admins,\nservices, and users to users to meaningfully describe and share key /\nvalue pair and tag metadata. The intent is to enable better metadata\ncollaboration across artifacts services, and projects for OpenStack\nusers.\n\nGlance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nRelated Glance Spec: https://review.openstack.org/#/c/98554/\n\nThis patch brings in the admin UI for the basic coarse grained\nactions on managing the metadata in the catalog. This includes creating a\nnamespace, importing metadata definitions into it, clearing metadata\ndefinitions from the namespace, deleting the namespace, and associating\nthe namespace for use with specific resource types.\n\nCurrent TODOs for this patch:\n* Switch to real Glance API\n* Add edit namespace info\n* Add project membership\n* Add policy checks\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 3, 'created': '2014-07-23 01:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/da3e755580329725c26a20f12e095eded69df0e9', 'message': 'Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nGlance is adding a metadata definitions catalog targeted for Juno. This\nis a common API hosted by the Glance service for vendors, admins,\nservices, and users to users to meaningfully describe and share key /\nvalue pair and tag metadata. The intent is to enable better metadata\ncollaboration across artifacts services, and projects for OpenStack\nusers.\n\nGlance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nRelated Glance Spec: https://review.openstack.org/#/c/98554/\n\nThis patch brings in the admin UI for the basic coarse grained\nactions on managing the metadata in the catalog. This includes creating a\nnamespace, importing metadata definitions into it, clearing metadata\ndefinitions from the namespace, deleting the namespace, and associating\nthe namespace for use with specific resource types.\n\nCurrent TODOs for this patch:\n* Switch to real Glance API\n* Add edit namespace info\n* Add project membership\n* Add policy checks\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 4, 'created': '2014-07-23 22:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5d7c0ebf0c7ebbb98b0863d0a965edfb77034f99', 'message': 'Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nGlance is adding a metadata definitions catalog targeted for Juno. This\nis a common API hosted by the Glance service for vendors, admins,\nservices, and users to users to meaningfully describe and share key /\nvalue pair and tag metadata. The intent is to enable better metadata\ncollaboration across artifacts services, and projects for OpenStack\nusers.\n\nGlance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nRelated Glance Spec: https://review.openstack.org/#/c/98554/\n\nThis patch brings in the admin UI for the basic coarse grained\nactions on managing the metadata in the catalog. This includes creating a\nnamespace, importing metadata definitions into it, clearing metadata\ndefinitions from the namespace, deleting the namespace, and associating\nthe namespace for use with specific resource types.\n\nCurrent TODOs for this patch:\n* Switch to real Glance API\n* Add edit namespace info\n* Add project membership\n* Add policy checks\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 5, 'created': '2014-07-23 23:30:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/05142f11c06db18c35d87414deeac61c904d8d1a', 'message': 'Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nGlance is adding a metadata definitions catalog targeted for Juno. This\nis a common API hosted by the Glance service for vendors, admins,\nservices, and users to users to meaningfully describe and share key /\nvalue pair and tag metadata. The intent is to enable better metadata\ncollaboration across artifacts services, and projects for OpenStack\nusers.\n\nGlance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nRelated Glance Spec: https://review.openstack.org/#/c/98554/\n\nThis patch brings in the admin UI for the basic coarse grained\nactions on managing the metadata in the catalog. This includes creating a\nnamespace, importing metadata definitions into it, clearing metadata\ndefinitions from the namespace, deleting the namespace, and associating\nthe namespace for use with specific resource types.\n\nCurrent TODOs for this patch:\n* Switch to real Glance API\n* Add edit namespace info\n* Add project membership\n* Add policy checks\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 6, 'created': '2014-07-24 00:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9ee071b5be79cab5b012be1e7339575c84d6c9b1', 'message': 'Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nGlance is adding a metadata definitions catalog targeted for Juno. This\nis a common API hosted by the Glance service for vendors, admins,\nservices, and users to users to meaningfully describe and share key /\nvalue pair and tag metadata. The intent is to enable better metadata\ncollaboration across artifacts services, and projects for OpenStack\nusers.\n\nGlance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nRelated Glance Spec: https://review.openstack.org/#/c/98554/\n\nThis patch brings in the admin UI for the basic coarse grained\nactions on managing the metadata in the catalog. This includes creating a\nnamespace, importing metadata definitions into it, clearing metadata\ndefinitions from the namespace, deleting the namespace, and associating\nthe namespace for use with specific resource types.\n\nCurrent TODOs for this patch:\n* Switch to real Glance API\n* Add edit namespace info\n* Add project membership\n* Add policy checks\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 7, 'created': '2014-07-28 13:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d63d451a456724d4da5aa1e7096a820d4f87ab32', 'message': 'Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nGlance is adding a metadata definitions catalog targeted for Juno. This\nis a common API hosted by the Glance service for vendors, admins,\nservices, and users to users to meaningfully describe and share key /\nvalue pair and tag metadata. The intent is to enable better metadata\ncollaboration across artifacts services, and projects for OpenStack\nusers.\n\nGlance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nRelated Glance Spec: https://review.openstack.org/#/c/98554/\n\nThis patch brings in the admin UI for the basic coarse grained\nactions on managing the metadata in the catalog. This includes creating a\nnamespace, importing metadata definitions into it, clearing metadata\ndefinitions from the namespace, deleting the namespace, and associating\nthe namespace for use with specific resource types.\n\nCurrent TODOs for this patch:\n* Switch to real Glance API\n* Add edit namespace info\n* Add project membership\n* Add policy checks\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 8, 'created': '2014-07-31 00:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/37aa8fed388997276de46848251568a1fa839c04', 'message': 'Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nGlance is adding a metadata definitions catalog targeted for Juno. This\nis a common API hosted by the Glance service for vendors, admins,\nservices, and users to users to meaningfully describe and share key /\nvalue pair and tag metadata. The intent is to enable better metadata\ncollaboration across artifacts services, and projects for OpenStack\nusers.\n\nGlance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nRelated Glance Spec: https://review.openstack.org/#/c/98554/\n\nThis patch brings in the admin UI for the basic coarse grained\nactions on managing the metadata in the catalog. This includes creating a\nnamespace, importing metadata definitions into it, clearing metadata\ndefinitions from the namespace, deleting the namespace, and associating\nthe namespace for use with specific resource types.\n\nCurrent TODOs for this patch:\n* Switch to real Glance API\n* Finish resource type management\n* Add policy checks\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 9, 'created': '2014-07-31 23:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f14c8b6ba390c0cc9965afa4b5a5e75a3b53f181', 'message': ""Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nGlance is adding a metadata definitions catalog targeted for Juno.\nA common API hosted by the Glance service for vendors, admins,\nservices, and users to meaningfully define available key / value\npair and tag metadata. The intent is to enable better metadata\ncollaboration across artifacts,services, and projects for\nOpenStack users.\n\nThis is about the definition of the available metadata that can\nbe used on different types of resources (images, artifacts,\nvolumes, flavors, aggregates, etc). A definition includes the\nproperties type, its key, it's description, and it's constraints.\nThis catalog will not store the values for specific instance\nproperties.\n\nGlance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nRelated Glance Spec: https://review.openstack.org/#/c/98554/\n\nThis patch brings in the admin UI for the basic coarse grained\nactions on managing the metadata in the catalog. This includes creating a\nnamespace, importing metadata definitions into it, clearing metadata\ndefinitions from the namespace, deleting the namespace, and associating\nthe namespace for use with specific resource types.\n\nCurrent TODOs for this patch:\n* Switch to real Glance API\n* Finish resource type management\n* Add policy checks\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n""}, {'number': 10, 'created': '2014-08-07 17:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c96d357aa90011755f3c6f5b70ec3e8cadfa3010', 'message': ""Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nIn Juno, Glance will provide a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the metadata in the catalog. This includes creating\n(importing) a namespace, viewing and editing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\nCurrent TODOs for this patch:\n* Switch to real Glance API\n* Finish resource type management\n* Add policy checks\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nNote: The Glance catalog will provide the definition of the available\nmetadata that can be used on different types of resources (images,\nartifacts, volumes, flavors, aggregates, etc). A definition includes the\nproperties type, its key, it's description, and it's constraints. This\ncatalog will not store the values for specific instance properties.\nOther Horizon widgets will be added to make use of the definitions.\n\n - https://blueprints.launchpad.net/horizon/+spec/tagging\n - https://blueprints.launchpad.net/horizon/+spec/glance-metadata-images\n - https://blueprints.launchpad.net/horizon/+spec/glaance-metadata-flavors\n - https://blueprints.launchpad.net/horizon/+spec/host-aggregate-update-metadata\n - https://blueprints.launchpad.net/horizon/+spec/ability-to-add-metadata-to-cinder-volumes-and-snapshots\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n""}, {'number': 11, 'created': '2014-08-08 01:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/125d80e042a7d93ab53b55a58e505d0bb8bddc67', 'message': 'Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nIn Juno, Glance will provide a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the metadata in the catalog. This includes creating\n(importing) a namespace, viewing and editing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\nCurrent TODOs for this patch:\n* Switch to real Glance API\n* Finish resource type management\n* Add policy checks\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 12, 'created': '2014-08-13 03:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e8a777d9bbd898a3a8c22c70ce706b320e202605', 'message': 'Base Glance Metadata Definitions Admin UI\n\nThis is a work in progress patch that will track the development\nconcepts of the Glance metadata definitions catalog.  It is initially\nbeing developed against a mock-api and will be switched to\nthe real Glance API when it is available.\n\nIn Juno, Glance will provide a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the metadata in the catalog. This includes creating\n(importing) a namespace, viewing and editing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\nCurrent TODOs for this patch:\n* Finish resource type management\n* Add policy checks\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 13, 'created': '2014-08-13 21:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f04c6cf303b545491a42475bba13aeeeb7ff2152', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\nCurrent TODOs for this patch:\n* Add policy checks\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 14, 'created': '2014-08-14 17:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ad4afa9d2c5fb37911c80dec9f0bc23abe8284cf', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\nCurrent TODOs for this patch:\n* Add policy checks\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 15, 'created': '2014-08-14 20:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/397f74395e654bd80c585216e731955ddd0fa7a6', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\nCurrent TODOs for this patch:\n* Add policy checks\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 16, 'created': '2014-08-15 05:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/06d90bf0351400cc47b8a54f0b7c68df829109a4', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\nCurrent TODOs for this patch:\n* Add policy checks\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 17, 'created': '2014-08-19 00:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/08763a5cd478b1f2ca3d8a2a407f489d890337e2', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 18, 'created': '2014-08-19 19:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b10b6503c5fd338dd31a9cc82e1bd0ea9cc83601', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 19, 'created': '2014-08-19 21:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9151b77bd368aca4422a65d74deffa26d599f89c', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 20, 'created': '2014-08-19 21:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a06684bc6384e6b7a5332f7122e759d3ebcefa31', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 21, 'created': '2014-08-21 11:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/edee7c8548133ea10f7f0351f1031b8894d25c24', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 22, 'created': '2014-08-21 11:28:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f450477ce1c9efcff97a7cdd4d6b991b6fadecaa', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 23, 'created': '2014-08-21 13:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/16a3e33bd2006c8518fb9696df41d7f7bf0bff7d', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 24, 'created': '2014-08-21 14:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e50c6fb6e02d0e51566d32dabcca96ada7045a16', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 25, 'created': '2014-08-25 21:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f7e384c5be2f7bbe867b1b756610149f899c0a12', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 26, 'created': '2014-08-27 01:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/da7442d3b0bb0e4e24013a75951cbdafb7009aa6', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 27, 'created': '2014-08-27 14:48:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/083e2820447840fcccee437b7f787e35e2ed752a', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nAdditional blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\n\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 28, 'created': '2014-08-27 18:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e6e2fa959d76db5a50930ac8850d44f19eef2638', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 29, 'created': '2014-08-27 22:38:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d65f31da5426498fcc6705af4a7d55e56fe3c263', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 30, 'created': '2014-08-29 16:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8fb9999efd4910410cab2d83c9efc7d9cf12c277', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 31, 'created': '2014-08-29 19:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0859c6d72bf12b6bbc86c83e7af4d9961eb0533d', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 32, 'created': '2014-08-29 23:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b2d62877809c394c8024c0a66ec8003e85cc8e40', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 33, 'created': '2014-09-01 17:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/64e643129631803d1fdd32af4d0bcdc3cf141abb', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 34, 'created': '2014-09-05 20:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f42865a935240f2db5b443022e71ae19ed2cfbf7', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 35, 'created': '2014-09-06 13:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e39c8665f8fc13e24ce0c24b281646ba6215974c', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 36, 'created': '2014-09-07 00:07:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/36584b5ac48aebf247a774b55ce96008ef534e75', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 37, 'created': '2014-09-07 08:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/51f992964eb29b945cf121b4f5ddf261f0ec45c5', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 38, 'created': '2014-09-10 16:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3f5d91a0bbd84b78d0a91abc9128684867833564', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 39, 'created': '2014-09-11 16:12:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3c25ab4a3eb54bcd0f60ab7b1e3ad11e6842d3d0', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\n********************** TESTING **************************\nYou can test this code with Glance patches by following\nthe instructions at the bottom of this etherpad:\nGo toː https://etherpad.openstack.org/p/j3-glance-patches\n\nThen merging api/glance.py (preferring this one)\n*********************************************************\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 40, 'created': '2014-09-11 18:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/56be077ab01f20e145eeada355dac423b64ef01b', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 41, 'created': '2014-09-11 18:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1b5fa6cb99e44df4651ccc145b317f3bffb20262', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 42, 'created': '2014-09-12 12:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b08ef920933f214cf8a3da4654aa17c6681c7bb4', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 43, 'created': '2014-09-12 15:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f634ad89076261f4f26fc07f5ebf63fae0bd88e4', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 44, 'created': '2014-09-15 19:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3b5adbcdad1a943eb00fa1306d450d12808525c0', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 45, 'created': '2014-09-15 21:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/069ea310bdf35cf8e4b243b9e89982afb1294add', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance is providing a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This include both simple tags and key / value pairs\n(properties, specs, etc).\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 46, 'created': '2014-10-06 16:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/081b1d7883150932df7773cfc2708a384164a049', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 47, 'created': '2014-10-07 05:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/911b53af0b833523b4a5fdb6e91baab1823ab186', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 48, 'created': '2014-10-14 03:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/67f28009c120852ba7ecad1d70f157514d2126fd', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 49, 'created': '2014-10-14 03:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7798c3c187b41744e37dd434c34a7dd6a23f7dc8', 'message': 'Base Glance Metadata Definitions Admin UI\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 50, 'created': '2014-10-16 04:31:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ff98fbda31cda6fc7e4053828f39f084add841c0', 'message': 'Base Glance Metadata Definitions Admin UI\n\nProvide a base admin UI for viewing, importing, and associating the\nmetadata definitions that can be used with various resource types\nsuch as flavors, images, and host aggregates.\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact: Concept awareness\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 51, 'created': '2014-12-08 21:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/325621186b946e22b603204de8b3a46316ad86dd', 'message': 'Base Glance Metadata Definitions Admin UI\n\nProvide a base admin UI for viewing, importing, and associating the\nmetadata definitions that can be used with various resource types\nsuch as flavors, images, and host aggregates.\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact: Concept awareness\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 52, 'created': '2014-12-16 06:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3bdc2d5acea10bcfbcc15be1a09161fa4e682221', 'message': 'Base Glance Metadata Definitions Admin UI\n\nProvide a base admin UI for viewing, importing, and associating the\nmetadata definitions that can be used with various resource types\nsuch as flavors, images, and host aggregates.\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact: Concept awareness\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 53, 'created': '2014-12-16 06:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/78ba8dfce2b51ed3933a83096d73e1d6133d4cf8', 'message': 'Base Glance Metadata Definitions Admin UI\n\nProvide a base admin UI for viewing, importing, and associating the\nmetadata definitions that can be used with various resource types\nsuch as flavors, images, and host aggregates.\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact: Concept awareness\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 54, 'created': '2014-12-16 23:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4e0c0c1956d978e9b7181f6b83175c041d85290e', 'message': 'Base Glance Metadata Definitions Admin UI\n\nProvide a base admin UI for viewing, importing, and associating the\nmetadata definitions that can be used with various resource types\nsuch as flavors, images, and host aggregates.\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact: Concept awareness\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 55, 'created': '2014-12-17 00:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/339651cf72cbfa7847123310f3a8c199f2dd0f2d', 'message': 'Base Glance Metadata Definitions Admin UI\n\nProvide a base admin UI for viewing, importing, and associating the\nmetadata definitions that can be used with various resource types\nsuch as flavors, images, and host aggregates.\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact: Concept awareness\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 56, 'created': '2014-12-17 17:17:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/eef098790517416c40bee530d66ee24e703203f3', 'message': 'Base Glance Metadata Definitions Admin UI\n\nProvide a base admin UI for viewing, importing, and associating the\nmetadata definitions that can be used with various resource types\nsuch as flavors, images, and host aggregates.\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact: Concept awareness\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 57, 'created': '2014-12-17 17:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/398113fd62c5f6844f6f9255fe4e5a139b21e9e3', 'message': 'Base Glance Metadata Definitions Admin UI\n\nProvide a base admin UI for viewing, importing, and associating the\nmetadata definitions that can be used with various resource types\nsuch as flavors, images, and host aggregates.\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metaata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact: Concept awareness\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 58, 'created': '2014-12-17 17:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/dd86a19cdbdafb9b28fdcff71345024cae02ae45', 'message': 'Base Glance Metadata Definitions Admin UI\n\nProvide a base admin UI for viewing, importing, and associating the\nmetadata definitions that can be used with various resource types\nsuch as flavors, images, and host aggregates.\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metadata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact: Concept awareness\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}, {'number': 59, 'created': '2014-12-17 23:11:01.000000000', 'files': ['horizon/static/horizon/js/angular/controllers/namespace-controller.js', 'openstack_dashboard/dashboards/admin/metadata_defs/tabs.py', 'openstack_dashboard/dashboards/admin/metadata_defs/urls.py', 'openstack_dashboard/dashboards/admin/metadata_defs/templates/metadata_defs/index.html', 'openstack_dashboard/dashboards/admin/metadata_defs/views.py', 'horizon/templates/horizon/_scripts.html', 'openstack_dashboard/dashboards/admin/metadata_defs/tables.py', 'openstack_dashboard/dashboards/admin/metadata_defs/templates/metadata_defs/_resource_types.html', 'openstack_dashboard/dashboards/admin/metadata_defs/constants.py', 'openstack_dashboard/dashboards/admin/dashboard.py', 'openstack_dashboard/dashboards/admin/metadata_defs/__init__.py', 'openstack_dashboard/dashboards/admin/metadata_defs/forms.py', 'openstack_dashboard/dashboards/admin/metadata_defs/panel.py', 'openstack_dashboard/dashboards/admin/metadata_defs/tests.py', 'openstack_dashboard/dashboards/admin/metadata_defs/templates/metadata_defs/create.html', 'openstack_dashboard/static/dashboard/scss/horizon.scss', 'openstack_dashboard/conf/glance_policy.json', 'openstack_dashboard/dashboards/admin/metadata_defs/templates/metadata_defs/_detail_contents.html', 'openstack_dashboard/dashboards/admin/metadata_defs/templates/metadata_defs/_create.html', 'openstack_dashboard/dashboards/admin/metadata_defs/templates/metadata_defs/detail.html', 'openstack_dashboard/dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html', 'openstack_dashboard/api/glance.py', 'openstack_dashboard/dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7e5f4d1594905e66919f04946e93f45d10e149e9', 'message': 'Base Glance Metadata Definitions Admin UI\n\nProvide a base admin UI for viewing, importing, and associating the\nmetadata definitions that can be used with various resource types\nsuch as flavors, images, and host aggregates.\n\nIn Juno, Glance provided a metadata definitions catalog[1][2] where\nusers can register the available metadata definitions that can be used\non different types of resources (images, artifacts, volumes, flavors,\naggregates, etc). This includes key / value pairs such as\nproperties, extra specs, etc. Horizon landed several patches that\nread these properties. You can view the functionality in the\n""update metadata"" action on Flavors, Images, and Host Aggregates.\n\nThis specific patch is to bring in the Admin UI for the basic coarse\ngrained actions on the definitions in the catalog. This includes creating\n(importing) a namespace, viewing the overview details about\nit, deleting the namespace, and associating the namespace for use with\nspecific resource types.\n\nFuture blueprints will be registered for:\n - CRUD on individual metadata definitions within the namespace\nFor example, editing the default value of an individual property.\n\n[1] Approved Glance Juno Spec:\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\n[2] Glance PTL Juno Feature Overview:\nhttps://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s\n\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>\nCo-Authored-By: Bartosz Fic <bartosz.fic@intel.com>\nCo-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>\nCo-Authored-By: Michal Dulko <michal.dulko@intel.com>\nDocImpact: Concept awareness\nChange-Id: Ie34007f73af7e0941631a52f03841068e509a72c\nImplements: blueprint glance-metadata-definitions-base-admin-ui\n'}]",152,104063,7e5f4d1594905e66919f04946e93f45d10e149e9,225,16,59,7665,,,0,"Base Glance Metadata Definitions Admin UI

Provide a base admin UI for viewing, importing, and associating the
metadata definitions that can be used with various resource types
such as flavors, images, and host aggregates.

In Juno, Glance provided a metadata definitions catalog[1][2] where
users can register the available metadata definitions that can be used
on different types of resources (images, artifacts, volumes, flavors,
aggregates, etc). This includes key / value pairs such as
properties, extra specs, etc. Horizon landed several patches that
read these properties. You can view the functionality in the
""update metadata"" action on Flavors, Images, and Host Aggregates.

This specific patch is to bring in the Admin UI for the basic coarse
grained actions on the definitions in the catalog. This includes creating
(importing) a namespace, viewing the overview details about
it, deleting the namespace, and associating the namespace for use with
specific resource types.

Future blueprints will be registered for:
 - CRUD on individual metadata definitions within the namespace
For example, editing the default value of an individual property.

[1] Approved Glance Juno Spec:
https://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst

[2] Glance PTL Juno Feature Overview:
https://www.youtube.com/watch?v=3ptriiw1wK8&t=14m27s

Co-Authored-By: Travis Tripp <travis.tripp@hp.com>
Co-Authored-By: Santiago Baldassin<santiago.b.baldassin@intel.com>
Co-Authored-By: Bartosz Fic <bartosz.fic@intel.com>
Co-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>
Co-Authored-By: Michal Dulko <michal.dulko@intel.com>
DocImpact: Concept awareness
Change-Id: Ie34007f73af7e0941631a52f03841068e509a72c
Implements: blueprint glance-metadata-definitions-base-admin-ui
",git fetch https://review.opendev.org/openstack/horizon refs/changes/63/104063/21 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/metadata/constants.py', 'openstack_dashboard/dashboards/admin/metadata/workflows.py', 'openstack_dashboard/dashboards/admin/metadata/templates/metadata/resource_types.html', 'openstack_dashboard/dashboards/admin/dashboard.py', 'openstack_dashboard/dashboards/admin/metadata/forms.py', 'openstack_dashboard/dashboards/admin/metadata/templates/metadata/index.html', 'openstack_dashboard/dashboards/admin/metadata/tables.py', 'openstack_dashboard/dashboards/admin/metadata/mock_api.py', 'openstack_dashboard/dashboards/admin/metadata/tabs.py', 'openstack_dashboard/dashboards/admin/metadata/urls.py', 'openstack_dashboard/dashboards/admin/metadata/__init__.py', 'openstack_dashboard/dashboards/admin/metadata/views.py', 'openstack_dashboard/dashboards/admin/metadata/templates/metadata/_create.html', 'openstack_dashboard/dashboards/admin/metadata/templates/metadata/_detail_overview.html', 'openstack_dashboard/dashboards/admin/metadata/templates/metadata/detail.html', 'openstack_dashboard/dashboards/admin/metadata/panel.py', 'openstack_dashboard/dashboards/admin/metadata/templates/metadata/create.html']",17,c687d1554cefcb666f24413bb19a812bedb0f603,bp/s,"{% extends 'base.html' %} {% load i18n %} {% block title %}{% trans ""Create a Metadata Namespace"" %}{% endblock %} {% block page_header %} {% include ""horizon/common/_page_header.html"" with title=_(""Create a Metadata Namespace"") %} {% endblock page_header %} {% block main %} {% include 'admin/metadata/_create.html' %} {% endblock %} ",,847,1
openstack%2Fdevstack~master~I8568bddda2a5c66235ecae23af58983ee94c720a,openstack/devstack,master,I8568bddda2a5c66235ecae23af58983ee94c720a,Fix rabbit_userid for multi node devstack,MERGED,2014-12-16 21:34:31.000000000,2014-12-18 10:47:56.000000000,2014-12-18 10:47:55.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5196}, {'_account_id': 7118}, {'_account_id': 10385}, {'_account_id': 11080}]","[{'number': 1, 'created': '2014-12-16 21:34:31.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f6287c2adb4722b5688da9a4ac61dc6eda4a1372', 'message': ""Fix rabbit_userid for multi node devstack\n\nI43a231c9611b4cc2e390b603aa3bfb49c915bdc5 introduced a new setting\nRABBIT_USERID but only set it if rabbit is enabled. In multi node\ndevstack the second node uses RABBIT_USERID but the service rabbit isn't\nenabled on it.\n\nAlways set RABBIT_USERID, if a different message queue is used the\nvariable will just be ignored.\n\nChange-Id: I8568bddda2a5c66235ecae23af58983ee94c720a\n""}]",0,142229,f6287c2adb4722b5688da9a4ac61dc6eda4a1372,12,6,1,1849,,,0,"Fix rabbit_userid for multi node devstack

I43a231c9611b4cc2e390b603aa3bfb49c915bdc5 introduced a new setting
RABBIT_USERID but only set it if rabbit is enabled. In multi node
devstack the second node uses RABBIT_USERID but the service rabbit isn't
enabled on it.

Always set RABBIT_USERID, if a different message queue is used the
variable will just be ignored.

Change-Id: I8568bddda2a5c66235ecae23af58983ee94c720a
",git fetch https://review.opendev.org/openstack/devstack refs/changes/29/142229/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,f6287c2adb4722b5688da9a4ac61dc6eda4a1372,badrabbit,"# In multi node devstack, second node needs RABBIT_USERID, but rabbit # isn't enabled. RABBIT_USERID=${RABBIT_USERID:-stackrabbit}", RABBIT_USERID=${RABBIT_USERID:-stackrabbit},3,1
openstack%2Fneutron~master~Ia7bcef7a0efacc79c467b18863cb8180b6a89a28,openstack/neutron,master,Ia7bcef7a0efacc79c467b18863cb8180b6a89a28,Imported Translations from Transifex,MERGED,2014-12-17 06:05:44.000000000,2014-12-18 10:47:34.000000000,2014-12-18 10:47:33.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 7743}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-17 06:05:44.000000000', 'files': ['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-warning.pot', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/neutron.pot', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b06ce3b0582a1a53f64679d3b38aecef94648a02', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ia7bcef7a0efacc79c467b18863cb8180b6a89a28\n'}]",0,142354,b06ce3b0582a1a53f64679d3b38aecef94648a02,22,17,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ia7bcef7a0efacc79c467b18863cb8180b6a89a28
",git fetch https://review.opendev.org/openstack/neutron refs/changes/54/142354/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-warning.pot', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/neutron.pot', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po']",13,b06ce3b0582a1a53f64679d3b38aecef94648a02,transifex/translations,"""POT-Creation-Date: 2014-12-17 06:05+0000\n"" ""PO-Revision-Date: 2014-12-16 21:20+0000\n""#: neutron/agent/dhcp_agent.py:602 neutron/agent/l3/agent.py:1732#: neutron/agent/l3/agent.py:1634#: neutron/db/l3_db.py:1017#: neutron/db/l3_db.py:1023#: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:264#: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:191#: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:222#: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:236","""POT-Creation-Date: 2014-12-14 06:05+0000\n"" ""PO-Revision-Date: 2014-12-14 03:11+0000\n""#: neutron/agent/dhcp_agent.py:602 neutron/agent/l3/agent.py:1734#: neutron/agent/l3/agent.py:1636#: neutron/db/l3_db.py:1022#: neutron/db/l3_db.py:1028#: neutron/plugins/mlnx/mlnx_plugin.py:188#: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:267#: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:194#: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:225#: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:239#: neutron/plugins/mlnx/mlnx_plugin.py:178 #, python-format msgid ""Physical Network type mappings: %s"" msgstr """" ",172,367
openstack%2Fopenstack-ansible~master~I5b42c85bf87b4032334177f7411fb4527860a19f,openstack/openstack-ansible,master,I5b42c85bf87b4032334177f7411fb4527860a19f,Change MariaDB repo from JMU to OSU,MERGED,2014-12-18 09:31:41.000000000,2014-12-18 10:40:41.000000000,2014-12-18 10:12:43.000000000,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-18 09:31:41.000000000', 'files': ['rpc_deployment/vars/repo_packages/all_common.yml', 'rpc_deployment/inventory/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ae07f1a08cb56d98a8d5043db9b71569532970bc', 'message': ""Change MariaDB repo from JMU to OSU\n\nThis patch changes the MariaDB repository used from JMU to OSU, which\nappears to be the primary source repository for all mirrors.\n\nThis has become necessary due to JMU's mirror being unavailable due to\nmaintenance.\n\nChange-Id: I5b42c85bf87b4032334177f7411fb4527860a19f\nCloses-Bug: #1403795\n""}]",0,142707,ae07f1a08cb56d98a8d5043db9b71569532970bc,8,4,1,6816,,,0,"Change MariaDB repo from JMU to OSU

This patch changes the MariaDB repository used from JMU to OSU, which
appears to be the primary source repository for all mirrors.

This has become necessary due to JMU's mirror being unavailable due to
maintenance.

Change-Id: I5b42c85bf87b4032334177f7411fb4527860a19f
Closes-Bug: #1403795
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/07/142707/1 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/vars/repo_packages/all_common.yml', 'rpc_deployment/inventory/group_vars/all.yml']",2,ae07f1a08cb56d98a8d5043db9b71569532970bc,bug/1403795," - { repo: ""deb http://ftp.osuosl.org/pub/mariadb/repo/5.5/ubuntu {{ ansible_distribution_release }} main"", state: ""present"" }"," - { repo: ""deb http://mirror.jmu.edu/pub/mariadb/repo/5.5/ubuntu {{ ansible_distribution_release }} main"", state: ""present"" }",2,2
openstack%2Frally~master~I547717ddad83024da553672e1574f1053713eb78,openstack/rally,master,I547717ddad83024da553672e1574f1053713eb78,Make cli tests work on MOS,ABANDONED,2014-12-01 22:34:05.000000000,2014-12-18 10:36:09.000000000,,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 9601}, {'_account_id': 10475}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-01 22:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1d1995c2d2862ba478ef5cdb8d1cce0759a52f91', 'message': 'Make cli tests work on MOS\n\nChange-Id: I547717ddad83024da553672e1574f1053713eb78\n'}, {'number': 2, 'created': '2014-12-03 14:42:25.000000000', 'files': ['tests/functional/test_cli_show.py', 'tests/functional/test_cli_verify.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/b7296301a20d1b6527597a3005825f6026c90685', 'message': 'Make cli tests work on MOS\n\nChange-Id: I547717ddad83024da553672e1574f1053713eb78\n'}]",5,138196,b7296301a20d1b6527597a3005825f6026c90685,60,5,2,7369,,,0,"Make cli tests work on MOS

Change-Id: I547717ddad83024da553672e1574f1053713eb78
",git fetch https://review.opendev.org/openstack/rally refs/changes/96/138196/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/functional/test_cli_show.py', 'tests/functional/test_cli_verify.py']",2,1d1995c2d2862ba478ef5cdb8d1cce0759a52f91,ecli_mos," self.fail(""Number of failed tests more than 50%. %r"" % results)"," self.fail(""Number of failed tests more than 50%."")",3,3
openstack%2Fpuppet-openstacklib~master~I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e,openstack/puppet-openstacklib,master,I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e,Add db::postgresql to openstacklib,MERGED,2014-07-15 21:35:35.000000000,2014-12-18 10:24:08.000000000,2014-12-18 10:24:07.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7822}, {'_account_id': 8482}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-07-15 21:35:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/f9b32068ca3f26850223f053223dcef3ae00d84a', 'message': 'Add db::postgresql to openstacklib\n\nThe openstacklib::db::postgresql resource is a library resource that can be\nused by nova, cinder, ceilometer, etc., rather than replicating equivalent\nfunctionality across all of these modules. This resource is very simple, but\nits addition will make maintenance and adding features much more\nstraightforward and consistent than implementing individually across modules.\n\nopenstacklib::db::postgresql uses the puppetlabs postgresql::server::db\nresource to configure the database and user. openstacklib::db::postgresql\naccepts a password_hash as a parameter and passes it to the\npostgresql::server::db resource as the password parameter. While this seems to\nconflict, the postgresql::server::db resource is actually using the password\nparameter as a password hash.\n\nChange-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e\nImplements: blueprint commmon-openstack-database-resource\n'}, {'number': 2, 'created': '2014-07-22 21:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/13226d99272bd523198a5dbe43f4fdf9eb6f4c56', 'message': 'Add db::postgresql to openstacklib\n\nThe openstacklib::db::postgresql resource is a library resource that can be\nused by nova, cinder, ceilometer, etc., rather than replicating equivalent\nfunctionality across all of these modules. This resource is very simple, but\nits addition will make maintenance and adding features much more\nstraightforward and consistent than implementing individually across modules.\n\nopenstacklib::db::postgresql uses the puppetlabs postgresql::server::db\nresource to configure the database and user. openstacklib::db::postgresql\naccepts a password_hash as a parameter and passes it to the\npostgresql::server::db resource as the password parameter. While this seems to\nconflict, the postgresql::server::db resource is actually using the password\nparameter as a password hash.\n\nChange-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e\nImplements: blueprint commmon-openstack-database-resource\n'}, {'number': 3, 'created': '2014-07-22 21:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/515c2d3de6f92c6c571fd1ee2c50aec4dc2990a8', 'message': 'Add db::postgresql to openstacklib\n\nThe openstacklib::db::postgresql resource is a library resource that can be\nused by nova, cinder, ceilometer, etc., rather than replicating equivalent\nfunctionality across all of these modules. This resource is very simple, but\nits addition will make maintenance and adding features much more\nstraightforward and consistent than implementing individually across modules.\n\nopenstacklib::db::postgresql uses the puppetlabs postgresql::server::db\nresource to configure the database and user. openstacklib::db::postgresql\naccepts a password_hash as a parameter and passes it to the\npostgresql::server::db resource as the password parameter. While this seems to\nconflict, the postgresql::server::db resource is actually using the password\nparameter as a password hash.\n\nChange-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e\nImplements: blueprint commmon-openstack-database-resource\n'}, {'number': 4, 'created': '2014-07-29 22:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/1ea5fd588abf1e2fbdcd08781c3a49a56e1ee03a', 'message': 'Add db::postgresql to openstacklib\n\nThe openstacklib::db::postgresql resource is a library resource that can be\nused by nova, cinder, ceilometer, etc., rather than replicating equivalent\nfunctionality across all of these modules. This resource is very simple, but\nits addition will make maintenance and adding features much more\nstraightforward and consistent than implementing individually across modules.\n\nopenstacklib::db::postgresql uses the puppetlabs postgresql::server::db\nresource to configure the database and user. openstacklib::db::postgresql\naccepts a password_hash as a parameter and passes it to the\npostgresql::server::db resource as the password parameter. While this seems to\nconflict, the postgresql::server::db resource is actually using the password\nparameter as a password hash.\n\nChange-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e\nImplements: blueprint commmon-openstack-database-resource\n'}, {'number': 5, 'created': '2014-08-04 21:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/01b8e6097377f762d16e345e2b9aacc16bc099c1', 'message': 'Add db::postgresql to openstacklib\n\nThe openstacklib::db::postgresql resource is a library resource that can be\nused by nova, cinder, ceilometer, etc., rather than replicating equivalent\nfunctionality across all of these modules. This resource is very simple, but\nits addition will make maintenance and adding features much more\nstraightforward and consistent than implementing individually across modules.\n\nopenstacklib::db::postgresql uses the puppetlabs postgresql::server::db\nresource to configure the database and user. openstacklib::db::postgresql\naccepts a password_hash as a parameter and passes it to the\npostgresql::server::db resource as the password parameter. While this seems to\nconflict, the postgresql::server::db resource is actually using the password\nparameter as a password hash.\n\nChange-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e\nImplements: blueprint commmon-openstack-database-resource\n'}, {'number': 6, 'created': '2014-08-04 22:04:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/453cb9b1879ef93d7c00e07ac4663c9c441dd885', 'message': 'Add db::postgresql to openstacklib\n\nThe openstacklib::db::postgresql resource is a library resource that can be\nused by nova, cinder, ceilometer, etc., rather than replicating equivalent\nfunctionality across all of these modules. This resource is very simple, but\nits addition will make maintenance and adding features much more\nstraightforward and consistent than implementing individually across modules.\n\nopenstacklib::db::postgresql uses the puppetlabs postgresql::server::db\nresource to configure the database and user. openstacklib::db::postgresql\naccepts a password_hash as a parameter and passes it to the\npostgresql::server::db resource as the password parameter. While this seems to\nconflict, the postgresql::server::db resource is actually using the password\nparameter as a password hash.\n\nChange-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e\nImplements: blueprint commmon-openstack-database-resource\n'}, {'number': 7, 'created': '2014-11-13 20:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/02b9f251eb9e8c46e69dbc48f2cb426f0aa34fbc', 'message': 'Add db::postgresql to openstacklib\n\nThe openstacklib::db::postgresql resource is a library resource that can be\nused by nova, cinder, ceilometer, etc., rather than replicating equivalent\nfunctionality across all of these modules. This resource is very simple, but\nits addition will make maintenance and adding features much more\nstraightforward and consistent than implementing individually across modules.\n\nopenstacklib::db::postgresql uses the puppetlabs postgresql::server::db\nresource to configure the database and user. openstacklib::db::postgresql\naccepts a password_hash as a parameter and passes it to the\npostgresql::server::db resource as the password parameter. While this seems to\nconflict, the postgresql::server::db resource is actually using the password\nparameter as a password hash.\n\nChange-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e\nImplements: blueprint commmon-openstack-database-resource\n'}, {'number': 8, 'created': '2014-11-17 03:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/cae4ec45c5303cd194c16a3d79a66f99cd2c7b86', 'message': 'Add db::postgresql to openstacklib\n\nThe openstacklib::db::postgresql resource is a library resource that can be\nused by nova, cinder, ceilometer, etc., rather than replicating equivalent\nfunctionality across all of these modules. This resource is very simple, but\nits addition will make maintenance and adding features much more\nstraightforward and consistent than implementing individually across modules.\n\nopenstacklib::db::postgresql uses the puppetlabs postgresql::server::db\nresource to configure the database and user. openstacklib::db::postgresql\naccepts a password_hash as a parameter and passes it to the\npostgresql::server::db resource as the password parameter. While this seems to\nconflict, the postgresql::server::db resource is actually using the password\nparameter as a password hash.\n\nChange-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e\nImplements: blueprint commmon-openstack-database-resource\n'}, {'number': 9, 'created': '2014-12-14 00:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/7dc8b25f7fb58b9d5a83d100b52f5306451b08ba', 'message': 'Add db::postgresql to openstacklib\n\nThe openstacklib::db::postgresql resource is a library resource that can be\nused by nova, cinder, ceilometer, etc., rather than replicating equivalent\nfunctionality across all of these modules. This resource is very simple, but\nits addition will make maintenance and adding features much more\nstraightforward and consistent than implementing individually across modules.\n\nopenstacklib::db::postgresql uses the puppetlabs postgresql::server::db\nresource to configure the database and user. openstacklib::db::postgresql\naccepts a password_hash as a parameter and passes it to the\npostgresql::server::db resource as the password parameter. While this seems to\nconflict, the postgresql::server::db resource is actually using the password\nparameter as a password hash.\n\nChange-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e\nImplements: blueprint commmon-openstack-database-resource\n'}, {'number': 10, 'created': '2014-12-14 01:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/c90fd38c53acfa0836de8f6ab0b6cae35fcecb01', 'message': 'Add db::postgresql to openstacklib\n\nThe openstacklib::db::postgresql resource is a library resource that can be\nused by nova, cinder, ceilometer, etc., rather than replicating equivalent\nfunctionality across all of these modules. This resource is very simple, but\nits addition will make maintenance and adding features much more\nstraightforward and consistent than implementing individually across modules.\n\nopenstacklib::db::postgresql uses the puppetlabs postgresql::server::db\nresource to configure the database and user. openstacklib::db::postgresql\naccepts a password_hash as a parameter and passes it to the\npostgresql::server::db resource as the password parameter. While this seems to\nconflict, the postgresql::server::db resource is actually using the password\nparameter as a password hash.\n\nChange-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e\nImplements: blueprint commmon-openstack-database-resource\n'}, {'number': 11, 'created': '2014-12-15 03:59:04.000000000', 'files': ['metadata.json', '.fixtures.yml', 'manifests/db/postgresql.pp', 'README.md', 'spec/defines/openstacklib_db_postgresql_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/082d2882b87c97e7ef9c6ae29bf72191e0e9fae8', 'message': 'Add db::postgresql to openstacklib\n\nThe openstacklib::db::postgresql resource is a library resource that can be\nused by nova, cinder, ceilometer, etc., rather than replicating equivalent\nfunctionality across all of these modules. This resource is very simple, but\nits addition will make maintenance and adding features much more\nstraightforward and consistent than implementing individually across modules.\n\nopenstacklib::db::postgresql uses the puppetlabs postgresql::server::db\nresource to configure the database and user. openstacklib::db::postgresql\naccepts a password_hash as a parameter and passes it to the\npostgresql::server::db resource as the password parameter. While this seems to\nconflict, the postgresql::server::db resource is actually using the password\nparameter as a password hash.\n\nChange-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e\nImplements: blueprint commmon-openstack-database-resource\n'}]",2,107179,082d2882b87c97e7ef9c6ae29bf72191e0e9fae8,50,6,11,8482,,,0,"Add db::postgresql to openstacklib

The openstacklib::db::postgresql resource is a library resource that can be
used by nova, cinder, ceilometer, etc., rather than replicating equivalent
functionality across all of these modules. This resource is very simple, but
its addition will make maintenance and adding features much more
straightforward and consistent than implementing individually across modules.

openstacklib::db::postgresql uses the puppetlabs postgresql::server::db
resource to configure the database and user. openstacklib::db::postgresql
accepts a password_hash as a parameter and passes it to the
postgresql::server::db resource as the password parameter. While this seems to
conflict, the postgresql::server::db resource is actually using the password
parameter as a password hash.

Change-Id: I1446f37e7fba3305cff3eb3dd7ea4e7d5577eb4e
Implements: blueprint commmon-openstack-database-resource
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/79/107179/3 && git format-patch -1 --stdout FETCH_HEAD,"['Modulefile', '.fixtures.yml', 'manifests/db/postgresql.pp', 'README.md', 'spec/defines/openstacklib_db_postgresql_spec.rb']",5,f9b32068ca3f26850223f053223dcef3ae00d84a,bp/commmon-openstack-database-resource,"require 'spec_helper' describe 'openstacklib::db::postgresql' do password_hash = 'AA1420F182E88B9E5F874F6FBE7459291E8F4601' title = 'nova' let (:title) { title } let :required_params do { :password_hash => password_hash } end context 'on a RedHat osfamily' do let :facts do { :postgres_default_version => '8.4', :osfamily => 'RedHat' } end context 'with only required parameters' do let :params do required_params end it { should contain_postgresql__server__db(title).with( :user => title, :password => password_hash )} end context 'when overriding encoding' do let :params do { :encoding => 'latin1' }.merge(required_params) end it { should contain_postgresql__server__db(title).with_encoding(params[:encoding]) } end context 'when omitting the required parameter password_hash' do let :params do required_params.delete(:password_hash) end it { expect { should raise_error(Puppet::Error) } } end context 'when notifying other resources' do let :pre_condition do 'exec { ""nova-db-sync"": }' end let :params do { :notify => 'Exec[nova-db-sync]'}.merge(required_params) end it {should contain_exec('nova-db-sync').that_subscribes_to(""Openstacklib::Db::Postgresql[#{title}]"") } end context 'when required for other openstack services' do let :pre_condition do 'service {""keystone"":}' end let :title do 'keystone' end let :params do { :before => 'Service[keystone]'}.merge(required_params) end it { should contain_service('keystone').that_requires(""Openstacklib::Db::Postgresql[keystone]"") } end end context 'on a Debian osfamily' do let :facts do { :osfamily => 'Debian' } end context 'with only required parameters' do let :params do required_params end it { should contain_postgresql__server__db(title).with( :user => title, :password => password_hash )} end context 'when overriding encoding' do let :params do { :encoding => 'latin1' }.merge(required_params) end it { should contain_postgresql__server__db(title).with_encoding(params[:encoding]) } end context 'when omitting the required parameter password_hash' do let :params do required_params.delete(:password_hash) end it { expect { should raise_error(Puppet::Error) } } end context 'when notifying other resources' do let :pre_condition do 'exec { ""nova-db-sync"": }' end let :params do { :notify => 'Exec[nova-db-sync]'}.merge(required_params) end it {should contain_exec('nova-db-sync').that_subscribes_to(""Openstacklib::Db::Postgresql[#{title}]"") } end context 'when required for other openstack services' do let :pre_condition do 'service {""keystone"":}' end let :title do 'keystone' end let :params do { :before => 'Service[keystone]'}.merge(required_params) end it { should contain_service('keystone').that_requires(""Openstacklib::Db::Postgresql[keystone]"") } end end end ",,237,2
openstack%2Ffuel-library~master~I364e26968f066d2e970c62c2ec1585ed4186b5e2,openstack/fuel-library,master,I364e26968f066d2e970c62c2ec1585ed4186b5e2,Refactor pacemaker service provider,ABANDONED,2014-11-10 14:04:14.000000000,2014-12-18 10:22:20.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-11-10 14:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cd9d324941e66515703cb53caf570977756152d6', 'message': 'Sort new pacemaker function\n\n* Fix enable/disable\n* Give more timeout\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 2, 'created': '2014-11-10 17:11:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b00830f982d5c46c917a0e9318731cc67525923e', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 3, 'created': '2014-11-10 17:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1d478169409aea10ecf4528a70d217de085564df', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 4, 'created': '2014-11-10 18:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ff2433c5216bb43c5b48c34089af108b3d69f7ac', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 5, 'created': '2014-11-10 19:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1dbec447a2ed5295fb4f9885fcb66f209e73e9dd', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 6, 'created': '2014-11-11 12:14:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/44ea8908ad648c238ec0ca061edd1e5317d8bd39', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 7, 'created': '2014-11-11 17:07:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0e333312c323d063ad0f5d0e63b4b956497f50b0', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 8, 'created': '2014-11-11 17:08:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/48b717309da172fd9485d17f5aa22dc8ec9d7a64', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 9, 'created': '2014-11-11 17:08:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d8906a2d27448e4aaf180894af5dd31b7c45a825', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 10, 'created': '2014-11-12 11:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7931be086004847900f6110cf6cb315b95af390f', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 11, 'created': '2014-11-12 14:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d2f5b09f13bb7f544cced4da30aa1ad2f2aa010f', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 12, 'created': '2014-11-25 19:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4176902db5be7d6f494d6ef1c63f5ca5b68019c1', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 13, 'created': '2014-11-25 19:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b60c41245131ea93f4388a3611530011f5473d6e', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 14, 'created': '2014-11-25 19:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/88c18d5d1a339e18b8bb3c3f5509d448095d001d', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 15, 'created': '2014-11-28 20:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/85945857fd5f02a9a6b93cda1a1f04bf67056679', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 16, 'created': '2014-12-01 13:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9041a6dd5bad18514123dbbd225f41d816c4e32d', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 17, 'created': '2014-12-01 16:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/56cf8400a2db5c38f2e5ed83a42bf3fcd5137ebd', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}, {'number': 18, 'created': '2014-12-01 16:40:08.000000000', 'files': ['deployment/puppet/corosync/lib/puppet/provider/pacemaker_common.rb', 'deployment/puppet/corosync/lib/puppet/provider/service/pacemaker.rb', 'deployment/puppet/corosync/spec/unit/puppet/provider/service/pacemaker_spec.rb', 'deployment/puppet/corosync/spec/unit/puppet/provider/cib.xml', 'deployment/puppet/corosync/spec/unit/puppet/provider/pacemaker_common_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8fa01ad7d79625618c99e25f8fb96aef5a9ba37f', 'message': 'Refactor pacemaker service provider\n\n* Sort library functions\n* Fix enable/disable\n* Increase timeout\n* Add configuration flags for start/stop mode\n* Add configuration flags for service disable and constraints\n\nChange-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2\nRelated-Blueprint: pacemaker-improvements\n'}]",1,133482,8fa01ad7d79625618c99e25f8fb96aef5a9ba37f,114,4,18,9037,,,0,"Refactor pacemaker service provider

* Sort library functions
* Fix enable/disable
* Increase timeout
* Add configuration flags for start/stop mode
* Add configuration flags for service disable and constraints

Change-Id: I364e26968f066d2e970c62c2ec1585ed4186b5e2
Related-Blueprint: pacemaker-improvements
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/82/133482/17 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/corosync/lib/puppet/provider/pacemaker_common.rb', 'deployment/puppet/corosync/lib/puppet/provider/service/pacemaker.rb']",2,cd9d324941e66515703cb53caf570977756152d6,bp/pacemaker-improvements,, commands :cibadmin => 'cibadmin',290,264
openstack%2Ffuel-library~master~Id5fc2217558371998e91165cfb813003335bd885,openstack/fuel-library,master,Id5fc2217558371998e91165cfb813003335bd885,Refactor corosync resources to definitions,ABANDONED,2014-08-26 08:43:40.000000000,2014-12-18 10:22:06.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-26 08:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2fefec1b93ba29a7b8540a11dcaa02343e2db9d7', 'message': 'Refactor corosync resources to definitions\n\n* Move cs_resources to definitions\n* Add handler for manual operation or debugging\n  of ocf scripts\n\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885\n'}, {'number': 2, 'created': '2014-08-26 09:29:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e0b12477c71f25e9b4b0f098c2beb8d915f3d1c6', 'message': 'Refactor corosync resources to definitions\n\n* Move cs_resources to definitions\n* Add handler for manual operation or debugging\n  of ocf scripts\n\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885\n'}, {'number': 3, 'created': '2014-08-26 11:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7211d1bf75d9594c3d9243e8ab01ebda45e8fcdc', 'message': 'Refactor corosync resources to definitions\n\n* Move cs_resources to definitions\n* Add handler for manual operation or debugging\n  of ocf scripts\n\nPartial-Blueprint: farther-pacemaker-improvements\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885'}, {'number': 4, 'created': '2014-10-02 08:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cb366124b774a6b39925631a9980b1c32c5a1f03', 'message': 'Refactor corosync resources to definitions\n\n* Move cs_resources to definitions\n* Add handler for manual operation or debugging\n  of ocf scripts.\n\nPartial-Blueprint: farther-pacemaker-improvements\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885\n'}, {'number': 5, 'created': '2014-10-02 08:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e74cb300bdb8c93f4e249319abda82e9030191f1', 'message': 'Refactor corosync resources to definitions\n\n* Move cs_resources to definitions\n* Add handler for manual operation or debugging\n  of ocf scripts.\n\nPartial-Blueprint: pacemaker-improvements\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885\n'}, {'number': 6, 'created': '2014-10-02 08:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1f874bde5eea9d8742c5cf29008a8637e8ace6cb', 'message': 'Refactor corosync resources to definitions\n\n* Move cs_resources to definitions\n* Add handler for manual operation or debugging\n  of ocf scripts.\n\nPartial-Blueprint: pacemaker-improvements\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885\n'}, {'number': 7, 'created': '2014-10-03 11:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/03adf7bd10ed0f438095888efe8bea454465d65c', 'message': ""Refactor corosync resources to definitions\n\n* Move cs_resources to definition.\n* Add wrapper for manual operation or debugging of OCF scripts.\n\nOCF Wrapper is handy for Cloud Operators when it's required to debug OCF script\nmanually. It includes all necessary environment variables. In case of problems just run\nwrapper and see output.\n\nDocImpact\nPartial-Blueprint: pacemaker-improvements\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885\n""}, {'number': 8, 'created': '2014-10-06 13:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/217d57846d4bf4f301e55195631af0721e7ac324', 'message': ""Refactor corosync resources to definitions\n\n* Move cs_resources to definition.\n* Add wrapper for manual operation or debugging of OCF scripts.\n\nOCF Wrapper is handy for Cloud Operators when it's required to debug OCF script\nmanually. It includes all necessary environment variables. In case of problems just run\nwrapper and see output.\n\nDocImpact\nPartial-Blueprint: pacemaker-improvements\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885\n""}, {'number': 9, 'created': '2014-10-06 14:42:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/43d2a5e8fbdb7d1195c1c139d6623a0902971af2', 'message': ""Refactor corosync resources to definitions\n\n* Move cs_resources to definition.\n* Add wrapper for manual operation or debugging of OCF scripts.\n\nOCF Wrapper is handy for Cloud Operators when it's required to debug OCF script\nmanually. It includes all necessary environment variables. In case of problems\njust run wrapper and see output.\n\nDocImpact\nPartial-Blueprint: pacemaker-improvements\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885\n""}, {'number': 10, 'created': '2014-10-07 15:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a8861ced4ac84762961daff0bee7993be3f446d7', 'message': ""Refactor corosync resources to definitions\n\n* Move cs_resources to definition.\n* Add wrapper for manual operation or debugging of OCF scripts.\n\nOCF Wrapper is handy for Cloud Operators when it's required to debug OCF script\nmanually. It includes all necessary environment variables. In case of problems just run\nwrapper and see output.\n\nDocImpact\nPartial-Blueprint: pacemaker-improvements\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885\n""}, {'number': 11, 'created': '2014-10-10 15:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/22af4528fbde214d60c32b8a9503a4d1f1df9486', 'message': ""Refactor corosync resources to definitions\n\n* Move cs_resources to definition.\n* Add wrapper for manual operation or debugging of OCF scripts.\n\nOCF Wrapper is handy for Cloud Operators when it's required to debug OCF script\nmanually. It includes all necessary environment variables. In case of problems just run\nwrapper and see output.\n\nDocImpact\nPartial-Blueprint: pacemaker-improvements\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885\n""}, {'number': 12, 'created': '2014-10-20 09:56:01.000000000', 'files': ['deployment/puppet/mysql/manifests/server.pp', 'deployment/puppet/cluster/manifests/haproxy_ocf.pp', 'deployment/puppet/vmware/manifests/controller.pp', 'deployment/puppet/vmware/manifests/network/nova.pp', 'deployment/puppet/ceilometer/manifests/alarm/evaluator.pp', 'deployment/puppet/heat/manifests/engine.pp', 'deployment/puppet/galera/manifests/init.pp', 'deployment/puppet/corosync/manifests/resource.pp', 'deployment/puppet/nova/manifests/rabbitmq.pp', 'deployment/puppet/ceilometer/manifests/agent/central.pp', 'deployment/puppet/cluster/manifests/virtual_ip.pp', 'deployment/puppet/corosync/templates/ocf_handler.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6d30a4b46926de65abb2308e648941fca580d070', 'message': ""Refactor corosync resources to definitions\n\n* Move cs_resources to definition.\n* Add wrapper for manual operation or debugging of OCF scripts.\n\nOCF Wrapper is handy for Cloud Operators when it's required to debug OCF script\nmanually. It includes all necessary environment variables. In case of problems just run\nwrapper and see output\n\nDocImpact\nPartial-Blueprint: pacemaker-improvements\nChange-Id: Id5fc2217558371998e91165cfb813003335bd885\n""}]",5,116825,6d30a4b46926de65abb2308e648941fca580d070,88,5,12,9037,,,0,"Refactor corosync resources to definitions

* Move cs_resources to definition.
* Add wrapper for manual operation or debugging of OCF scripts.

OCF Wrapper is handy for Cloud Operators when it's required to debug OCF script
manually. It includes all necessary environment variables. In case of problems just run
wrapper and see output

DocImpact
Partial-Blueprint: pacemaker-improvements
Change-Id: Id5fc2217558371998e91165cfb813003335bd885
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/25/116825/12 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/mysql/manifests/server.pp', 'deployment/puppet/neutron/manifests/agents/ovs.pp', 'deployment/puppet/cluster/manifests/haproxy_ocf.pp', 'deployment/puppet/vmware/manifests/controller.pp', 'deployment/puppet/neutron/manifests/agents/metadata.pp', 'deployment/puppet/vmware/manifests/network/nova.pp', 'deployment/puppet/ceilometer/manifests/alarm/evaluator.pp', 'deployment/puppet/heat/manifests/engine.pp', 'deployment/puppet/neutron/manifests/agents/dhcp.pp', 'deployment/puppet/neutron/manifests/agents/l3.pp', 'deployment/puppet/galera/manifests/init.pp', 'deployment/puppet/corosync/manifests/resource.pp', 'deployment/puppet/nova/manifests/rabbitmq.pp', 'deployment/puppet/ceilometer/manifests/agent/central.pp', 'deployment/puppet/neutron/manifests/agents/ml2_agent.pp', 'deployment/puppet/cluster/manifests/virtual_ip.pp', 'deployment/puppet/corosync/templates/ocf_handler.erb']",17,2fefec1b93ba29a7b8540a11dcaa02343e2db9d7,bp/pacemaker-improvements,"#!/bin/sh export OCF_ROOT='<%= @ocf_root %>' <% if @parameters.is_a? Hash -%> <% @parameters.each do |k,v| -%> <% v = v.to_s -%> <% v = v + ""'"" unless v.end_with? ""'"" -%> <% v = ""'"" + v unless v.start_with? ""'"" -%> <%= ""export OCF_RESKEY_#{k}=#{v}"" %> <% end -%> <% end -%> help() { cat<<EOF OCF wrapper for <%= @title %> Pacemaker resource Usage: ocf_<%= @title %> [-dh] (action) Options: -d - Use set -x to debug the shell script -h - Show this help Main actions: * start * stop * monitor * meta-data * validate-all Multistate: * promote * demote * notify Migration: * migrate_to * migrate_from Optional and unused: * usage * help * status * reload * restart * recover EOF } ec2error() { case ""${1}"" in 0) echo 'Running' ;; 1) echo 'Error: Generic' ;; 2) echo 'Error: Arguments' ;; 3) echo 'Error: Unimplemented' ;; 4) echo 'Error: Permissions' ;; 5) echo 'Error: Installation' ;; 6) echo 'Error: Configuration' ;; 7) echo 'Not Running' ;; 8) echo 'Master Running' ;; 9) echo 'Master Failed' ;; *) echo ""Unknown"" ;; esac } DEBUG='0' while getopts ':dh' opt; do case $opt in d) DEBUG='1' ;; h) help exit 0 ;; \?) echo ""Invalid option: -${OPTARG}"" >&2 help exit 1 ;; esac done shift ""$((OPTIND - 1))"" ACTION=""${1}"" # set default action to monitor if [ ""${ACTION}"" = '' ]; then ACTION='monitor' fi if [ ""${DEBUG}"" = '1' ]; then bash -x <%= @ocf_file %> ""${ACTION}"" else <%= @ocf_file %> ""${ACTION}"" fi ec=""${?}"" message=""$(ec2error ${ec})"" echo ""Exit status: ${message} (${ec})"" exit ""${ec}"" ",,156,15
openstack%2Fheat~master~I33f599e91e79fccadafcab0e311464d7c54a9973,openstack/heat,master,I33f599e91e79fccadafcab0e311464d7c54a9973,Change hardcoded attr names in _resolve_attribute,MERGED,2014-12-17 16:36:19.000000000,2014-12-18 10:12:09.000000000,2014-12-18 10:12:07.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 8246}, {'_account_id': 9542}, {'_account_id': 14101}]","[{'number': 1, 'created': '2014-12-17 16:36:19.000000000', 'files': ['heat/engine/resources/volume.py', 'heat/engine/resources/nova_keypair.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/5199b3d0f64f29eaf28c140d2cea9893e9e607a1', 'message': 'Change hardcoded attr names in _resolve_attribute\n\nThis patch changes hardcoded attribute names in\n_resolve_attribute to attribute_schema values.\nBesides that, it fixes name of attribute in nova_keypair.\n\nChange-Id: I33f599e91e79fccadafcab0e311464d7c54a9973\n'}]",0,142491,5199b3d0f64f29eaf28c140d2cea9893e9e607a1,12,6,1,13009,,,0,"Change hardcoded attr names in _resolve_attribute

This patch changes hardcoded attribute names in
_resolve_attribute to attribute_schema values.
Besides that, it fixes name of attribute in nova_keypair.

Change-Id: I33f599e91e79fccadafcab0e311464d7c54a9973
",git fetch https://review.opendev.org/openstack/heat refs/changes/91/142491/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/volume.py', 'heat/engine/resources/nova_keypair.py']",2,5199b3d0f64f29eaf28c140d2cea9893e9e607a1,hrdcd-rslv-rm," PUBLIC_KEY_ATTR, PRIVATE_KEY_ATTR, PUBLIC_KEY_ATTR: attributes.Schema( PRIVATE_KEY_ATTR: attributes.Schema( attr_fn = {self.PRIVATE_KEY_ATTR: self.private_key, self.PUBLIC_KEY_ATTR: self.public_key}"," PUBLIC_KEY_ATTR, PRIVATE_KEY, PUBLIC_KEY: attributes.Schema( PRIVATE_KEY: attributes.Schema( attr_fn = {'private_key': self.private_key, 'public_key': self.public_key}",7,7
openstack%2Fheat~master~I46d4edbfffdb0e606e4f4c767610c137d03495f4,openstack/heat,master,I46d4edbfffdb0e606e4f4c767610c137d03495f4,Use configured auth for standalone middleware,MERGED,2014-12-15 21:40:08.000000000,2014-12-18 10:11:10.000000000,2014-12-18 10:11:09.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-12-15 21:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b6d628589c8daf720b3e36e9f72dc49b6e20a3d0', 'message': ""Use configured auth for standalone middleware\n\nPreviously auth_password.KeystonePasswordAuthProtocol directly created\na keystone v2 client, which means that heat-standalone wouldn't\nwork if heat-engine is using the default KeystoneClientV3 client.\n\nThis change creates a heat_keystoneclient.KeystoneClient and uses that to\nfetch the data required to build the authenticated env to pass to the\nrequest context. This means that the standalone middleware will now work\nwith the default v3 keystone backend, the contrib v2 backend, or any other\nvalid implementation of KeystoneClient. The type of KeystoneClient is\ndetermined by the heat.conf keystone_backend value, which means that this\nvalue is now read by heat-api when using the standalone middleware.\n\nFor v3 the service catalog is left empty, which means heat-engine will fetch\nit again.\n\nChange-Id: I46d4edbfffdb0e606e4f4c767610c137d03495f4\nCloses-Bug: #1402472\n""}, {'number': 2, 'created': '2014-12-16 01:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f8324f9c8dfde2afec1d2d04dc11feeba2b6562a', 'message': ""Use configured auth for standalone middleware\n\nPreviously auth_password.KeystonePasswordAuthProtocol directly created\na keystone v2 client, which means that heat-standalone wouldn't\nwork if heat-engine is using the default KeystoneClientV3 client.\n\nThis change creates a heat_keystoneclient.KeystoneClient and uses that to\nfetch the data required to build the authenticated env to pass to the\nrequest context. This means that the standalone middleware will now work\nwith the default v3 keystone backend, the contrib v2 backend, or any other\nvalid implementation of KeystoneClient. The type of KeystoneClient is\ndetermined by the heat.conf keystone_backend value, which means that this\nvalue is now read by heat-api when using the standalone middleware.\n\nFor v3 the service catalog is left empty, which means heat-engine will fetch\nit again.\n\nChange-Id: I46d4edbfffdb0e606e4f4c767610c137d03495f4\nCloses-Bug: #1402472\n""}, {'number': 3, 'created': '2014-12-17 21:42:13.000000000', 'files': ['heat/common/auth_password.py', 'heat/tests/test_auth_password.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a17e0ee4c60bdc704621394602e1f0d43707750a', 'message': ""Use configured auth for standalone middleware\n\nPreviously auth_password.KeystonePasswordAuthProtocol directly created\na keystone v2 client, which means that heat-standalone wouldn't\nwork if heat-engine is using the default KeystoneClientV3 client.\n\nThis change creates a heat_keystoneclient.KeystoneClient and uses that to\nfetch the data required to build the authenticated env to pass to the\nrequest context. This means that the standalone middleware will now work\nwith the default v3 keystone backend, the contrib v2 backend, or any other\nvalid implementation of KeystoneClient. The type of KeystoneClient is\ndetermined by the heat.conf keystone_backend value, which means that this\nvalue is now read by heat-api when using the standalone middleware.\n\nFor v3 the service catalog is left empty, which means heat-engine will fetch\nit again.\n\nChange-Id: I46d4edbfffdb0e606e4f4c767610c137d03495f4\nCloses-Bug: #1402472\n""}]",0,141908,a17e0ee4c60bdc704621394602e1f0d43707750a,20,4,3,4571,,,0,"Use configured auth for standalone middleware

Previously auth_password.KeystonePasswordAuthProtocol directly created
a keystone v2 client, which means that heat-standalone wouldn't
work if heat-engine is using the default KeystoneClientV3 client.

This change creates a heat_keystoneclient.KeystoneClient and uses that to
fetch the data required to build the authenticated env to pass to the
request context. This means that the standalone middleware will now work
with the default v3 keystone backend, the contrib v2 backend, or any other
valid implementation of KeystoneClient. The type of KeystoneClient is
determined by the heat.conf keystone_backend value, which means that this
value is now read by heat-api when using the standalone middleware.

For v3 the service catalog is left empty, which means heat-engine will fetch
it again.

Change-Id: I46d4edbfffdb0e606e4f4c767610c137d03495f4
Closes-Bug: #1402472
",git fetch https://review.opendev.org/openstack/heat refs/changes/08/141908/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/common/auth_password.py'],1,b6d628589c8daf720b3e36e9f72dc49b6e20a3d0,bug/1402472,"import logging from heat.common import context from heat.common import heat_keystoneclient LOG = logging.getLogger(__name__) ctx = context.RequestContext(username=username, password=password, tenant_id=tenant, auth_url=auth_url) hc = heat_keystoneclient.KeystoneClient(ctx) client = hc.client if token_info.get('version') == 'v3': keystone_token_info = {'token': token_info} tenant_id = token_info['project']['id'] tenant_name = token_info['project']['name'] user_id = token_info['user']['id'] user_name = token_info['user']['name'] roles = ','.join( [role['name'] for role in token_info['roles']]) service_catalog = None auth_token = token_info['auth_token'] else: keystone_token_info = token_info tenant_id = token_info['token']['tenant']['id'] tenant_name = token_info['token']['tenant']['name'] user_id = token_info['user']['id'] user_name = token_info['user']['name'] roles = ','.join( [role['name'] for role in token_info['user']['roles']]) service_catalog = token_info['serviceCatalog'] auth_token = token_info['token']['id'] 'keystone.token_info': keystone_token_info,","from keystoneclient.v2_0 import client as keystone_client client = keystone_client.Client( username=username, password=password, tenant_id=tenant, auth_url=auth_url) env['keystone.token_info'] = client.auth_ref tenant_id = token_info['token']['tenant']['id'] tenant_name = token_info['token']['tenant']['name'] user_id = token_info['user']['id'] user_name = token_info['user']['name'] roles = ','.join( [role['name'] for role in token_info['user']['roles']]) service_catalog = token_info['serviceCatalog'] auth_token = token_info['token']['id']",36,13
openstack%2Fnova~master~Ia373771eaaad4154a2aa0695bf3878713a68dd9f,openstack/nova,master,Ia373771eaaad4154a2aa0695bf3878713a68dd9f,libvirt: disk_bus setting is being lost when migration is reverted,MERGED,2014-11-05 21:00:44.000000000,2014-12-18 10:10:53.000000000,2014-12-18 10:10:49.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8802}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-05 21:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b7741bcde2ce34ee1f5b74a1a34cdde28ca9fcc9', 'message': ""libvirt: disk_bus setting is being lost when migration is reverted\n\nfinish_revert_migration() should use image_meta, if it exist, when constructing\nthe disk_info.\nRefactoring the image metadata extraction to it's own method.\n\nCloses-Bug: #1389850\nChange-Id: Ia373771eaaad4154a2aa0695bf3878713a68dd9f\n""}, {'number': 2, 'created': '2014-11-06 18:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b1637453a8768b43f40decee62ad07a0953a3fdd', 'message': 'libvirt: disk_bus setting is being lost when migration is reverted\n\nfinish_revert_migration() should use image_meta, if it exist, when constructing\nthe disk_info.\n\nCloses-Bug: #1389850\nChange-Id: Ia373771eaaad4154a2aa0695bf3878713a68dd9f\n'}, {'number': 3, 'created': '2014-11-06 20:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/137a53a7ea6af86e221116332e02526bfd2ddc62', 'message': 'libvirt: disk_bus setting is being lost when migration is reverted\n\nfinish_revert_migration() should use image_meta, if it exist, when constructing\nthe disk_info.\n\nCloses-Bug: #1389850\nChange-Id: Ia373771eaaad4154a2aa0695bf3878713a68dd9f\n'}, {'number': 4, 'created': '2014-12-04 20:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5296854d2e69219410a6c04bb8026cce94fd1d28', 'message': 'libvirt: disk_bus setting is being lost when migration is reverted\n\nfinish_revert_migration() should use image_meta, if it exist, when constructing\nthe disk_info.\n\nCloses-Bug: #1389850\nChange-Id: Ia373771eaaad4154a2aa0695bf3878713a68dd9f\n'}, {'number': 5, 'created': '2014-12-16 13:11:12.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c039eb0326690ea45e3770d00b1d397a49a49662', 'message': 'libvirt: disk_bus setting is being lost when migration is reverted\n\nfinish_revert_migration() should use image_meta, if it exist,\nwhen constructing the disk_info.\n\nCloses-Bug: #1389850\nChange-Id: Ia373771eaaad4154a2aa0695bf3878713a68dd9f\n'}]",6,132913,c039eb0326690ea45e3770d00b1d397a49a49662,49,9,5,8802,,,0,"libvirt: disk_bus setting is being lost when migration is reverted

finish_revert_migration() should use image_meta, if it exist,
when constructing the disk_info.

Closes-Bug: #1389850
Change-Id: Ia373771eaaad4154a2aa0695bf3878713a68dd9f
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/132913/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py']",2,b7741bcde2ce34ee1f5b74a1a34cdde28ca9fcc9,bug/1389850," def test_finish_revert_migration_preserves_disk_bus(self): def fake_get_guest_xml(context, instance, network_info, disk_info, block_device_info=None): self.assertEqual('ide', disk_info['disk_bus']) image_meta = {""properties"": {""hw_disk_bus"": ""ide""}} instance = self._create_instance() conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) with contextlib.nested( mock.patch.object(conn, '_create_domain_and_network'), mock.patch.object(conn, '_get_image_metadata', return_value= image_meta), mock.patch.object(conn, '_get_guest_xml', side_effect=fake_get_guest_xml)): conn.finish_revert_migration('', instance, None, power_on=False) ",,37,12
openstack%2Frequirements~master~I5af13d3ff66ad298ee82831f957c72cbe2fddf99,openstack/requirements,master,I5af13d3ff66ad298ee82831f957c72cbe2fddf99,Ensure we have a PEP 440 compatible version of pytz,MERGED,2014-12-17 05:31:15.000000000,2014-12-18 10:10:38.000000000,2014-12-18 10:10:36.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 7687}]","[{'number': 1, 'created': '2014-12-17 05:31:15.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/051dfe98839cccdcdb93cb160d7a8e916d9817b6', 'message': 'Ensure we have a PEP 440 compatible version of pytz\n\nChange-Id: I5af13d3ff66ad298ee82831f957c72cbe2fddf99\n'}]",0,142348,051dfe98839cccdcdb93cb160d7a8e916d9817b6,10,4,1,7687,,,0,"Ensure we have a PEP 440 compatible version of pytz

Change-Id: I5af13d3ff66ad298ee82831f957c72cbe2fddf99
",git fetch https://review.opendev.org/openstack/requirements refs/changes/48/142348/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,051dfe98839cccdcdb93cb160d7a8e916d9817b6,pep440-pytz,# 2013.6 is the first version of pytz that is PEP 440 compatible. pytz>=2013.6,pytz,2,1
openstack%2Ffuel-web~master~Ida4120c612ba0ad3cfec18eb27d2e4a295d7c503,openstack/fuel-web,master,Ida4120c612ba0ad3cfec18eb27d2e4a295d7c503,Test added for db.remove(),MERGED,2014-12-12 17:48:12.000000000,2014-12-18 10:04:18.000000000,2014-12-18 10:04:17.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11577}]","[{'number': 1, 'created': '2014-12-12 17:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/77e8ab8739c4f8d4013caeabfb330c4c50b9c5cf', 'message': 'Test added for db.remove()\n\nFix for https://bugs.launchpad.net/fuel/+bug/1401521 was committed w/o unit tests.\nIt is here.\n\nCloses-Bug: #1402000\n\nChange-Id: Ida4120c612ba0ad3cfec18eb27d2e4a295d7c503\n'}, {'number': 2, 'created': '2014-12-12 17:51:08.000000000', 'files': ['nailgun/nailgun/test/unit/test_statistics.py', 'nailgun/nailgun/statistics/statsenderd.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/404030f9244f0cb59032cd69b54a0a8804422a77', 'message': 'Test added for db.remove()\n\nFix for https://bugs.launchpad.net/fuel/+bug/1401521 was committed w/o unit tests.\nIt is here.\nStatSender is refactored slightly to make testing easier.\n\nCloses-Bug: #1402000\n\nChange-Id: Ida4120c612ba0ad3cfec18eb27d2e4a295d7c503\n'}]",0,141443,404030f9244f0cb59032cd69b54a0a8804422a77,18,8,2,8392,,,0,"Test added for db.remove()

Fix for https://bugs.launchpad.net/fuel/+bug/1401521 was committed w/o unit tests.
It is here.
StatSender is refactored slightly to make testing easier.

Closes-Bug: #1402000

Change-Id: Ida4120c612ba0ad3cfec18eb27d2e4a295d7c503
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/43/141443/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/unit/test_statistics.py', 'nailgun/nailgun/statistics/statsenderd.py']",2,77e8ab8739c4f8d4013caeabfb330c4c50b9c5cf,bug/1402000," def send_stats_once(self): try: if self.must_send_stats(): if self.ping_collector(): self.send_action_log() self.send_installation_info() time.sleep(dithered(settings.STATS_SEND_INTERVAL)) else: time.sleep(dithered(settings.COLLECTOR_PING_INTERVAL)) else: time.sleep(dithered(settings.STATS_ENABLE_CHECK_INTERVAL)) except Exception as e: logger.error(""Stats sender exception: %s"", six.text_type(e)) finally: db.remove() while True: StatsSender().send_stats_once()"," def run(self, *args, **kwargs): while True: try: if self.must_send_stats(): if self.ping_collector(): self.send_action_log() self.send_installation_info() time.sleep(dithered(settings.STATS_SEND_INTERVAL)) else: time.sleep(dithered(settings.COLLECTOR_PING_INTERVAL)) else: time.sleep(dithered(settings.STATS_ENABLE_CHECK_INTERVAL)) except Exception as e: logger.error(""Stats sender exception: %s"", six.text_type(e)) finally: db.remove() StatsSender().run()",45,16
openstack%2Ffuel-library~master~I62caa7cb4ee6e5a34d54dd2ce731f5b13248db12,openstack/fuel-library,master,I62caa7cb4ee6e5a34d54dd2ce731f5b13248db12,Fix cs_location idempotency,ABANDONED,2014-12-01 20:10:59.000000000,2014-12-18 10:02:55.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-01 20:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/32de73d20a7adcdebcd9a9dafe50da8f16a3bd0c', 'message': 'Fix cs_location idempotency\n\nChange-Id: I62caa7cb4ee6e5a34d54dd2ce731f5b13248db12\nRelated-Bug: 1396481\nFuel-CI: disable\n'}, {'number': 2, 'created': '2014-12-02 14:44:04.000000000', 'files': ['deployment/puppet/corosync/lib/puppet/provider/cs_location/crm.rb', 'deployment/puppet/corosync/lib/puppet/type/cs_location.rb', 'deployment/puppet/cluster/manifests/virtual_ip.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9f15ea6194ad5ebfd5a0dd12e0c8cb3f8fa12d9f', 'message': 'Fix cs_location idempotency\n\nChange-Id: I62caa7cb4ee6e5a34d54dd2ce731f5b13248db12\nRelated-Bug: 1396481\nFuel-CI: disable\n'}]",0,138167,9f15ea6194ad5ebfd5a0dd12e0c8cb3f8fa12d9f,13,4,2,9037,,,0,"Fix cs_location idempotency

Change-Id: I62caa7cb4ee6e5a34d54dd2ce731f5b13248db12
Related-Bug: 1396481
Fuel-CI: disable
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/67/138167/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/corosync/lib/puppet/provider/cs_location/1.xml', 'deployment/puppet/corosync/lib/puppet/provider/cs_location/crm.rb', 'deployment/puppet/corosync/lib/puppet/type/cs_location.rb', 'deployment/puppet/cluster/manifests/virtual_ip.pp']",4,32de73d20a7adcdebcd9a9dafe50da8f16a3bd0c,bug/1396481,," cib => ""ping_${vip_name}"",",454,113
openstack%2Ffuel-library~stable%2F5.1~Ie2523d05a6a52cdac08b0d8c70c68642f64bcb8f,openstack/fuel-library,stable/5.1,Ie2523d05a6a52cdac08b0d8c70c68642f64bcb8f,Change haproxy health check from TCP to HTTP,MERGED,2014-12-03 13:05:23.000000000,2014-12-18 09:55:30.000000000,2014-12-18 09:55:30.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 13343}]","[{'number': 1, 'created': '2014-12-03 13:05:23.000000000', 'files': ['deployment/puppet/openstack/manifests/ha/glance.pp', 'deployment/puppet/openstack/manifests/ha/heat.pp', 'deployment/puppet/openstack/manifests/ha/keystone.pp', 'deployment/puppet/openstack/manifests/ha/neutron.pp', 'deployment/puppet/openstack/manifests/ha/cinder.pp', 'deployment/puppet/openstack/manifests/ha/nova.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bc49271672643d79bb61929897d936c8e98615dd', 'message': 'Change haproxy health check from TCP to HTTP\n\nSwitch from L4 healtch checks to L7 where possible.\n\nChange-Id: Ie2523d05a6a52cdac08b0d8c70c68642f64bcb8f\nCloses-bug: #1394195\n'}]",0,138713,bc49271672643d79bb61929897d936c8e98615dd,14,8,1,11090,,,0,"Change haproxy health check from TCP to HTTP

Switch from L4 healtch checks to L7 where possible.

Change-Id: Ie2523d05a6a52cdac08b0d8c70c68642f64bcb8f
Closes-bug: #1394195
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/13/138713/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/ha/glance.pp', 'deployment/puppet/openstack/manifests/ha/heat.pp', 'deployment/puppet/openstack/manifests/ha/keystone.pp', 'deployment/puppet/openstack/manifests/ha/neutron.pp', 'deployment/puppet/openstack/manifests/ha/cinder.pp', 'deployment/puppet/openstack/manifests/ha/nova.pp']",6,bc49271672643d79bb61929897d936c8e98615dd,bug/1394195," order => '050', listen_port => 8774, public => true, require_service => 'nova-api', haproxy_config_options => { option => ['httpchk', 'httplog','httpclose'], }, balancermember_options => 'check inter 10s fastinter 2s downinter 3s rise 3 fall 3', order => '060', listen_port => 8775, require_service => 'nova-api', haproxy_config_options => { option => ['httpchk', 'httplog','httpclose'], }, balancermember_options => 'check inter 10s fastinter 2s downinter 3s rise 3 fall 3', } "," order => '050', listen_port => 8774, public => true, require_service => 'nova-api', order => '060', listen_port => 8775, require_service => 'nova-api', } ",81,40
openstack%2Fhorizon~master~Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a,openstack/horizon,master,Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a,Check input for Log length,MERGED,2014-06-26 03:59:35.000000000,2014-12-18 09:52:01.000000000,2014-12-18 09:51:59.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 4428}, {'_account_id': 4978}, {'_account_id': 6610}, {'_account_id': 6763}, {'_account_id': 7634}, {'_account_id': 8090}, {'_account_id': 8648}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9659}, {'_account_id': 9981}, {'_account_id': 10242}, {'_account_id': 10295}, {'_account_id': 11599}, {'_account_id': 12000}, {'_account_id': 12015}, {'_account_id': 13325}, {'_account_id': 13747}, {'_account_id': 14107}, {'_account_id': 14151}]","[{'number': 1, 'created': '2014-06-26 03:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/724f5020f0526e9366bcfe7ace988b9880663a83', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is digit\nand larger than 0.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 2, 'created': '2014-06-26 07:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/485947311532535257075702274309624721f22e', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is digit\nand larger than 0.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 3, 'created': '2014-06-26 08:43:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6b0d7961e762d936ef4f070eb4ab02bcc9bda68b', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is digit\nand larger than 0.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 4, 'created': '2014-06-26 14:23:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/04d8bc13f7e5b8c334a0b3fb9fa494995a2579d4', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is digit\nand larger than 0.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 5, 'created': '2014-06-27 02:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/629e44835a0e3731dfa2f7d1edbabb3d1e6108ef', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is digit\nand larger than 0.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 6, 'created': '2014-06-29 02:07:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9fa8f6392d4fe78e050d0b5b86f2c32ec33b8eaa', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is digit\nand larger than 0.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 7, 'created': '2014-07-01 02:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7b0d40ab67999b7487857c59a2cb8c917e0bbfb5', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is digit\nand larger than 0.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 8, 'created': '2014-07-17 13:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8c07038868ef6571a96d207c92fbe3a4139837c6', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is digit\nand larger than 0.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 9, 'created': '2014-07-18 13:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/efdf3f25f247f0f76c42c4969168139ba6bec058', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is digit\nand larger than 0.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 10, 'created': '2014-07-18 15:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/709780333b0a6592bca5c09eb64962bbf796dc64', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is digit\nand larger than 0.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 11, 'created': '2014-07-21 03:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/97852c9fe07fae3a5522d2d65fcfc0136a258f56', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is digit\nand larger than 0.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 12, 'created': '2014-07-21 15:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bc22c275593fffbf1b0698d8ae599d3fb605e16f', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is integer\nlarger than -1.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 13, 'created': '2014-11-21 11:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5139d537bb40f42d548c05bcff39be9a3bf4e414', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is integer\nlarger than -1.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 14, 'created': '2014-11-21 12:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/55b8fe9ab3e0d8f80840378690e284ffa28bdf58', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is integer\nlarger than -1.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 15, 'created': '2014-11-24 15:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a131506f030d163762d0845c020dc5394e4c4d58', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is a nonnegative\ninteger.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}, {'number': 16, 'created': '2014-12-15 02:24:02.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/instances/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a1a2869fe0b402150e4f31549e6df06b215efca9', 'message': 'Check input for Log length\n\nCheck input for Log length to make sure the input is a nonnegative\ninteger.\n\nChange-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a\nCloses-bug: 1331624\n'}]",54,102712,a1a2869fe0b402150e4f31549e6df06b215efca9,123,25,16,4428,,,0,"Check input for Log length

Check input for Log length to make sure the input is a nonnegative
integer.

Change-Id: Iae3dbf4236f1c7ceb8260540dd4f9086349bc13a
Closes-bug: 1331624
",git fetch https://review.opendev.org/openstack/horizon refs/changes/12/102712/9 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/views.py'],1,724f5020f0526e9366bcfe7ace988b9880663a83,bug/1331624,"from horizon import messages if not tail.isdigit(): data = _('Log Length must be digit and larger than 0') messages.warning(request, data) else: data = api.nova.server_console_output(request, instance_id, tail_length=tail)"," data = api.nova.server_console_output(request, instance_id, tail_length=tail)",8,3
openstack%2Fnova~master~I879e973180278faa51e664d526d75e5f095a64ea,openstack/nova,master,I879e973180278faa51e664d526d75e5f095a64ea,Small cleanup in db.sqlalchemy.api.action_finish(),MERGED,2014-12-10 16:50:24.000000000,2014-12-18 09:48:03.000000000,2014-12-18 09:48:00.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 9008}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 16:50:24.000000000', 'files': ['nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f99a5a8999f511c70b9fbe9213a28811d9d7233a', 'message': ""Small cleanup in db.sqlalchemy.api.action_finish()\n\nThis function was pulling back a row, updating the returned object,\nthen returning a reference to it. This potentially races, as the\nobject may be updated in another transaction after fetching. In\npractise it's probably fine, but the new code is more obviously\ncorrect, and probably slightly nicer to sqlalchemy.\n\nChange-Id: I879e973180278faa51e664d526d75e5f095a64ea\n""}]",0,140771,f99a5a8999f511c70b9fbe9213a28811d9d7233a,18,9,1,9555,,,0,"Small cleanup in db.sqlalchemy.api.action_finish()

This function was pulling back a row, updating the returned object,
then returning a reference to it. This potentially races, as the
object may be updated in another transaction after fetching. In
practise it's probably fine, but the new code is more obviously
correct, and probably slightly nicer to sqlalchemy.

Change-Id: I879e973180278faa51e664d526d75e5f095a64ea
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/140771/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api.py'],1,f99a5a8999f511c70b9fbe9213a28811d9d7233a,db/cleanup," query = model_query(context, models.InstanceAction, session=session).\ filter_by(request_id=values['request_id']) if query.update(values) != 1: return query.one()"," action_ref = model_query(context, models.InstanceAction, session=session).\ filter_by(request_id=values['request_id']).\ first() if not action_ref: action_ref.update(values) return action_ref",4,9
openstack%2Fcinder-specs~master~I94ad25be521b598c254d5dbd27218edaecf6c540,openstack/cinder-specs,master,I94ad25be521b598c254d5dbd27218edaecf6c540,RemoteFS configuration improvements,MERGED,2014-11-07 09:31:57.000000000,2014-12-18 09:48:02.000000000,2014-12-02 19:22:16.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2417}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9067}, {'_account_id': 9366}, {'_account_id': 10058}, {'_account_id': 10115}, {'_account_id': 11865}, {'_account_id': 11904}, {'_account_id': 13527}]","[{'number': 1, 'created': '2014-11-07 09:31:57.000000000', 'files': ['specs/kilo/remotefs-cfg-improvements.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/1c1ecab8710019cb05bb03f7f786e8aa03a9e57e', 'message': 'RemoteFS configuration improvements\n\nA new model to configure NFS/GlusterFS/etc. drivers.\n\nblueprint: remotefs-share-cfg-improvements\n\nChange-Id: I94ad25be521b598c254d5dbd27218edaecf6c540\n'}]",5,133173,1c1ecab8710019cb05bb03f7f786e8aa03a9e57e,21,15,1,4523,,,0,"RemoteFS configuration improvements

A new model to configure NFS/GlusterFS/etc. drivers.

blueprint: remotefs-share-cfg-improvements

Change-Id: I94ad25be521b598c254d5dbd27218edaecf6c540
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/73/133173/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/remotefs-cfg-improvements.rst'],1,1c1ecab8710019cb05bb03f7f786e8aa03a9e57e,bp/remotefs-share-cfg-improvements,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== RemoteFS Config Improvements ========================================== https://blueprints.launchpad.net/cinder/+spec/remotefs-share-cfg-improvements RemoteFS drivers (NFS, GlusterFS, etc.) are currently configured by adding a list of shares to a text config file which is referenced by cinder.conf. This means that one driver instance manages a handful of storage locations for the driver. This work will a) have these drivers configured like most other Cinder drivers are, and b) leverage the Cinder scheduler for selection between different storage backends rather than having the driver act as a pseudo-scheduler. Problem description =================== The configuration system for NFS/GlusterFS/etc drivers: * is different from other drivers * is more complex than necessary * limits functionality such as migration Proposed change =============== Replace the <x>_shares_config setting with settings that can be used to login to the storage platforms. This means that an nfs_shares_config file such as:: 192.168.1.10:/export1 -o sync 192.168.1.11:/export2 -o vers=nfs4 would become, in cinder.conf:: [nfs1] address = 192.168.1.10 export_path = /export1 options = -o sync [nfs2] address = 192.168.1.11 export_path = /export2 options = -o vers=nfs4 Each Cinder backend will then only manage one export rather than a handful of exports. This brings the RemoteFS drivers closer to how other Cinder drivers operate. Alternatives ------------ Leave things as they are today. (Not desireable.) Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- It will be possible to use Cinder volume migration to move volumes between all NFS exports when previously this was not always possible (since the different exports were managed by the same driver instance). Performance Impact ------------------ None Other deployer impact --------------------- nfs_shares_config, glusterfs_shares_config, etc., will be deprecated (but still functional for Kilo). Setting the new options will cause these settings to be ignored. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: eharney Other contributors: Other interested parties? Work Items ---------- * Create new options for address, export, mount options * Mark options and code to be removed in L as deprecated in Kilo Dependencies ============ None Testing ======= The NFS driver and GlusterFS drivers will be gaining CI during the Kilo cycle which will cover this. Manual testing should cover both the current and new configuration paths. Documentation Impact ==================== New configuration options and possibly guide changes for configuring the NFS driver. References ========== None ",,147,0
openstack%2Fdevstack~master~I4e52e0881df464dfb7b28e22581f462e14e37bdb,openstack/devstack,master,I4e52e0881df464dfb7b28e22581f462e14e37bdb,Add WSGIPassAuthorization to the admin port too,MERGED,2014-12-16 01:56:48.000000000,2014-12-18 09:47:41.000000000,2014-12-18 09:47:41.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-16 01:56:48.000000000', 'files': ['files/apache-keystone.template'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b57f636ec8fc648917c05c80469473d4f1deb14e', 'message': 'Add WSGIPassAuthorization to the admin port too\n\nAccidentally only added WSGIPassAuthorization to the public port,\nlike all the other WSGI props, it should be added for both ports.\n\nChange-Id: I4e52e0881df464dfb7b28e22581f462e14e37bdb\n'}]",0,141958,b57f636ec8fc648917c05c80469473d4f1deb14e,11,5,1,6482,,,0,"Add WSGIPassAuthorization to the admin port too

Accidentally only added WSGIPassAuthorization to the public port,
like all the other WSGI props, it should be added for both ports.

Change-Id: I4e52e0881df464dfb7b28e22581f462e14e37bdb
",git fetch https://review.opendev.org/openstack/devstack refs/changes/58/141958/1 && git format-patch -1 --stdout FETCH_HEAD,['files/apache-keystone.template'],1,b57f636ec8fc648917c05c80469473d4f1deb14e,add_wsgi_auth_pass, WSGIPassAuthorization On,,1,0
openstack%2Fdevstack~master~I84a82e56f6540724d50c6201a68c480ba7645add,openstack/devstack,master,I84a82e56f6540724d50c6201a68c480ba7645add,Don't install sphinx from distro,MERGED,2014-12-17 16:50:05.000000000,2014-12-18 09:47:38.000000000,2014-12-18 09:47:37.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 16:50:05.000000000', 'files': ['files/debs/horizon', 'files/rpms-suse/ryu', 'files/rpms/ryu', 'files/rpms/horizon', 'files/rpms-suse/horizon', 'files/debs/ryu'], 'web_link': 'https://opendev.org/openstack/devstack/commit/684e9e9ce2bfbe21571b7ba61aa9b91ea49892fa', 'message': ""Don't install sphinx from distro\n\nWe don't generate docs in devstack. But also, sphinx depends on babel\nwhich has a hard depend that breaks with setuptools 8. However, pip\ninstalled babel/sphinx should not have this problem.\n\nChange-Id: I84a82e56f6540724d50c6201a68c480ba7645add\n""}]",0,142497,684e9e9ce2bfbe21571b7ba61aa9b91ea49892fa,11,6,1,2,,,0,"Don't install sphinx from distro

We don't generate docs in devstack. But also, sphinx depends on babel
which has a hard depend that breaks with setuptools 8. However, pip
installed babel/sphinx should not have this problem.

Change-Id: I84a82e56f6540724d50c6201a68c480ba7645add
",git fetch https://review.opendev.org/openstack/devstack refs/changes/97/142497/1 && git format-patch -1 --stdout FETCH_HEAD,"['files/debs/horizon', 'files/rpms-suse/ryu', 'files/rpms/ryu', 'files/rpms-suse/horizon', 'files/rpms/horizon', 'files/debs/ryu']",6,684e9e9ce2bfbe21571b7ba61aa9b91ea49892fa,,,python-sphinx,0,6
openstack%2Fdevstack~master~I644b5b1579952959d253758b2a12b97d8a704657,openstack/devstack,master,I644b5b1579952959d253758b2a12b97d8a704657,remove $KEYSTONE_TOKEN_HASH_ALGORITHM,MERGED,2014-12-16 17:08:49.000000000,2014-12-18 09:46:54.000000000,2014-12-18 09:46:53.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2903}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-16 17:08:49.000000000', 'files': ['lib/keystone', 'lib/horizon'], 'web_link': 'https://opendev.org/openstack/devstack/commit/ef844fd08da208947c8e5d8e74e598d7cf7072af', 'message': 'remove $KEYSTONE_TOKEN_HASH_ALGORITHM\n\nNow that Keystone is back to UUID token defaults the use case for this\nin devstack is extremely dubious, and it can be set through via\nlocal.conf if anyone *really* cares.\n\nPart of bp:devstack-nounset\n\nChange-Id: I644b5b1579952959d253758b2a12b97d8a704657\n'}]",0,142159,ef844fd08da208947c8e5d8e74e598d7cf7072af,11,6,1,2750,,,0,"remove $KEYSTONE_TOKEN_HASH_ALGORITHM

Now that Keystone is back to UUID token defaults the use case for this
in devstack is extremely dubious, and it can be set through via
local.conf if anyone *really* cares.

Part of bp:devstack-nounset

Change-Id: I644b5b1579952959d253758b2a12b97d8a704657
",git fetch https://review.opendev.org/openstack/devstack refs/changes/59/142159/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/keystone', 'lib/horizon']",2,ef844fd08da208947c8e5d8e74e598d7cf7072af,unset,," if [[ -n ""$KEYSTONE_TOKEN_HASH_ALGORITHM"" ]]; then _horizon_config_set $local_settings """" OPENSTACK_TOKEN_HASH_ALGORITHM \""""$KEYSTONE_TOKEN_HASH_ALGORITHM""\"" fi",0,10
openstack%2Fdevstack~master~Idebe5af84d481d52d529575e666105e4b0e06a59,openstack/devstack,master,Idebe5af84d481d52d529575e666105e4b0e06a59,lib/swift : fix misleading typo in a code comment,MERGED,2014-12-17 11:41:14.000000000,2014-12-18 09:46:30.000000000,2014-12-18 09:46:29.000000000,"[{'_account_id': 3}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 11:41:14.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/fc0ff92777cc6be1914ff59b02d10e9fb75eb199', 'message': 'lib/swift : fix misleading typo in a code comment\n\nThe code comment was picked from lib/keystone but not changed.\n\nChange-Id: Idebe5af84d481d52d529575e666105e4b0e06a59\n'}]",0,142422,fc0ff92777cc6be1914ff59b02d10e9fb75eb199,8,3,1,7350,,,0,"lib/swift : fix misleading typo in a code comment

The code comment was picked from lib/keystone but not changed.

Change-Id: Idebe5af84d481d52d529575e666105e4b0e06a59
",git fetch https://review.opendev.org/openstack/devstack refs/changes/22/142422/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,fc0ff92777cc6be1914ff59b02d10e9fb75eb199,,# Toggle for deploying Swift under HTTPD + mod_wsgi,# Toggle for deploying Keystone under HTTPD + mod_wsgi,1,1
openstack%2Ftrove~stable%2Fjuno~Ia530441999320b766dd71815e1e0182699c429a7,openstack/trove,stable/juno,Ia530441999320b766dd71815e1e0182699c429a7,Updated from global requirements,MERGED,2014-12-14 00:17:51.000000000,2014-12-18 09:45:58.000000000,2014-12-18 09:45:58.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5293}, {'_account_id': 8214}, {'_account_id': 9656}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-14 00:17:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/trove/commit/dcd50ccc6e07ab3d88d7e223106efa67870a4581', 'message': 'Updated from global requirements\n\nChange-Id: Ia530441999320b766dd71815e1e0182699c429a7\n'}]",0,141604,dcd50ccc6e07ab3d88d7e223106efa67870a4581,16,6,1,11131,,,0,"Updated from global requirements

Change-Id: Ia530441999320b766dd71815e1e0182699c429a7
",git fetch https://review.opendev.org/openstack/trove refs/changes/04/141604/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,dcd50ccc6e07ab3d88d7e223106efa67870a4581,openstack/requirements,"SQLAlchemy>=0.8.4,<=0.9.99,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,!=0.9.4,!=0.9.5,!=0.9.6","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",1,1
openstack%2Fopenstack-ansible~master~I494bba6995a01488da0a71f5cffe9f61a9c4165e,openstack/openstack-ansible,master,I494bba6995a01488da0a71f5cffe9f61a9c4165e,Fix MOTD script name reference in chmod command,MERGED,2014-12-17 15:01:45.000000000,2014-12-18 09:38:02.000000000,2014-12-18 09:38:02.000000000,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 7634}, {'_account_id': 9820}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-17 15:01:45.000000000', 'files': ['scripts/cloudserver-aio.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/29abd6dddfeeb7f7da7329f4095f33e9cc7d95f6', 'message': 'Fix MOTD script name reference in chmod command\n\nThe chmod command incorrectly referenced the wrong script name. This\npatch fixes that.\n\nChange-Id: I494bba6995a01488da0a71f5cffe9f61a9c4165e\nCloses-Bug: #1403534\n'}]",0,142460,29abd6dddfeeb7f7da7329f4095f33e9cc7d95f6,10,6,1,6816,,,0,"Fix MOTD script name reference in chmod command

The chmod command incorrectly referenced the wrong script name. This
patch fixes that.

Change-Id: I494bba6995a01488da0a71f5cffe9f61a9c4165e
Closes-Bug: #1403534
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/60/142460/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/cloudserver-aio.sh'],1,29abd6dddfeeb7f7da7329f4095f33e9cc7d95f6,bug/1403534,chmod +x /etc/update-motd.d/20-openstack,chmod +x /etc/update-motd.d/00-rpc-notice,1,1
openstack%2Fmurano~master~Ia975d53031f91d93c5da59eeba2ae6957ea7431a,openstack/murano,master,Ia975d53031f91d93c5da59eeba2ae6957ea7431a,Removed unused file from openstack/common,MERGED,2014-12-14 02:06:48.000000000,2014-12-18 09:34:24.000000000,2014-12-18 09:34:22.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-14 02:06:48.000000000', 'files': ['murano/openstack/common/context.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/murano/commit/84b42cfa1a08ddd7b54b74b100e2528a0fa98dd4', 'message': ""Removed unused file from openstack/common\n\nopenstack/common/context.py wasn't used anywhere. And in case\nif it is needed we will need to use oslo.context.\n\nChange-Id: Ia975d53031f91d93c5da59eeba2ae6957ea7431a\n""}]",0,141611,84b42cfa1a08ddd7b54b74b100e2528a0fa98dd4,13,5,1,7600,,,0,"Removed unused file from openstack/common

openstack/common/context.py wasn't used anywhere. And in case
if it is needed we will need to use oslo.context.

Change-Id: Ia975d53031f91d93c5da59eeba2ae6957ea7431a
",git fetch https://review.opendev.org/openstack/murano refs/changes/11/141611/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/openstack/common/context.py', 'openstack-common.conf']",2,84b42cfa1a08ddd7b54b74b100e2528a0fa98dd4,murano-cleanup,,module=context,0,123
openstack%2Fnova~stable%2Fjuno~I935592d6c597db402ab3ffa452b990adc87987ff,openstack/nova,stable/juno,I935592d6c597db402ab3ffa452b990adc87987ff,Updated from global requirements,MERGED,2014-12-14 00:15:25.000000000,2014-12-18 09:27:50.000000000,2014-12-18 09:27:48.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2472}, {'_account_id': 5170}, {'_account_id': 9656}, {'_account_id': 10118}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-14 00:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0543ce26f19b88f6c7f86773cf6d3ff7bf3c0f82', 'message': 'Updated from global requirements\n\nChange-Id: I935592d6c597db402ab3ffa452b990adc87987ff\n'}, {'number': 2, 'created': '2014-12-16 14:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7c479cd5122a3287ed81924641fa6f0dfa39f81', 'message': 'Updated from global requirements\n\nChange-Id: I935592d6c597db402ab3ffa452b990adc87987ff\n'}, {'number': 3, 'created': '2014-12-16 23:06:59.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/fb2570da3687ec0ab9baefdf9eabf5ab11e7cd57', 'message': 'Updated from global requirements\n\nChange-Id: I935592d6c597db402ab3ffa452b990adc87987ff\n'}]",1,141601,fb2570da3687ec0ab9baefdf9eabf5ab11e7cd57,19,7,3,11131,,,0,"Updated from global requirements

Change-Id: I935592d6c597db402ab3ffa452b990adc87987ff
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/141601/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,0543ce26f19b88f6c7f86773cf6d3ff7bf3c0f82,openstack/requirements,"SQLAlchemy>=0.8.4,<=0.9.99,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,!=0.9.4,!=0.9.5,!=0.9.6","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",1,1
openstack%2Ftripleo-ci~master~I1a060e5eb5bcadd092b5887c81170b055c0e5367,openstack/tripleo-ci,master,I1a060e5eb5bcadd092b5887c81170b055c0e5367,Move pbr into downloaded packages,MERGED,2014-12-18 00:43:14.000000000,2014-12-18 09:22:02.000000000,2014-12-18 09:22:01.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-12-18 00:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/211212a93bdf726327cb49225d1f17660bdb6c72', 'message': 'Fix pbr build fail\n\nChange-Id: I1a060e5eb5bcadd092b5887c81170b055c0e5367\n'}, {'number': 2, 'created': '2014-12-18 01:10:52.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3d86dd4c885a68eabddb7f73a6dbe6f3e75fde64', 'message': ""Move pbr into downloaded packages\n\nWe were building pbr sdist's on every commit. Instead, lets just\ndownload pbr from upstream. This fixes a CI failure where pbr cannot be\nbuild from master.\n\nCloses-Bug: #1403684\n\nChange-Id: I1a060e5eb5bcadd092b5887c81170b055c0e5367\n""}]",0,142624,3d86dd4c885a68eabddb7f73a6dbe6f3e75fde64,13,4,2,10035,,,0,"Move pbr into downloaded packages

We were building pbr sdist's on every commit. Instead, lets just
download pbr from upstream. This fixes a CI failure where pbr cannot be
build from master.

Closes-Bug: #1403684

Change-Id: I1a060e5eb5bcadd092b5887c81170b055c0e5367
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/24/142624/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,211212a93bdf726327cb49225d1f17660bdb6c72,fix/pbr-build-fail,pip freeze,,1,0
openstack%2Fmurano~master~I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda,openstack/murano,master,I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda,Adds per-class configs,MERGED,2014-11-13 12:33:14.000000000,2014-12-18 09:19:41.000000000,2014-12-18 09:19:40.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-11-13 12:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/1d43bef0974012e8d3b6f97f6cb58f60f13e6064', 'message': 'Adds per-class configs\n\nAdds ability to have per-class configuration and special properties\nwith usage ""Config"". Such properties get their values from config\n(if it is present) rather than from object model.\n\nConfig files can also modify defaults for other property types.\n\nConfig files are stored in special folder that is configured in\n[engine] section of Murano config file under class_configs key.\n\nConfig files must me named using %FQ class name%.json or\n%FQ class name%.yaml pattern and contain dictionary of a form\npropertyName -> propertyValue\n\nChange-Id: I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda\nImplements: blueprint class-configs\n'}, {'number': 2, 'created': '2014-11-13 13:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/4875d13060fd6ba61b0b93a79dd766f76bf4b308', 'message': 'Adds per-class configs\n\nAdds ability to have per-class configuration and special properties\nwith usage ""Config"". Such properties get their values from config\n(if it is present) rather than from object model.\n\nConfig files can also modify defaults for other property types.\n\nConfig files are stored in special folder that is configured in\n[engine] section of Murano config file under class_configs key.\n\nConfig files must me named using %FQ class name%.json or\n%FQ class name%.yaml pattern and contain dictionary of a form\npropertyName -> propertyValue\n\nChange-Id: I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda\nImplements: blueprint class-configs\n'}, {'number': 3, 'created': '2014-11-13 16:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0f13458abd2137441a06a244fd754b45b08ce756', 'message': 'Adds per-class configs\n\nAdds ability to have per-class configuration and special properties\nwith usage ""Config"". Such properties get their values from config\n(if it is present) rather than from object model.\n\nConfig files can also modify defaults for other property types.\n\nConfig files are stored in special folder that is configured in\n[engine] section of Murano config file under class_configs key.\n\nConfig files must me named using %FQ class name%.json or\n%FQ class name%.yaml pattern and contain dictionary of a form\npropertyName -> propertyValue\n\nChange-Id: I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda\nImplements: blueprint class-configs\n'}, {'number': 4, 'created': '2014-11-13 19:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f3b631710d63d198b10de48b79f6b06c92c17a2b', 'message': 'Adds per-class configs\n\nAdds ability to have per-class configuration and special properties\nwith usage ""Config"". Such properties get their values from config\n(if it is present) rather than from object model.\n\nConfig files can also modify defaults for other property types.\n\nConfig files are stored in special folder that is configured in\n[engine] section of Murano config file under class_configs key.\n\nConfig files must me named using %FQ class name%.json or\n%FQ class name%.yaml pattern and contain dictionary of a form\npropertyName -> propertyValue\n\nChange-Id: I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda\nImplements: blueprint class-configs\n'}, {'number': 5, 'created': '2014-11-13 20:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/3576484fd4699571698996b3fcfab89cfb01b0de', 'message': 'Adds per-class configs\n\nAdds ability to have per-class configuration and special properties\nwith usage ""Config"". Such properties get their values from config\n(if it is present) rather than from object model.\n\nConfig files can also modify defaults for other property types.\n\nConfig files are stored in special folder that is configured in\n[engine] section of Murano config file under class_configs key.\n\nConfig files must me named using %FQ class name%.json or\n%FQ class name%.yaml pattern and contain dictionary of a form\npropertyName -> propertyValue\n\nChange-Id: I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda\nImplements: blueprint class-configs\n'}, {'number': 6, 'created': '2014-11-13 22:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/729eb4fb4b52c1cdb3abffb00fc071fda0c2c15e', 'message': 'Adds per-class configs\n\nAdds ability to have per-class configuration and special properties\nwith usage ""Config"". Such properties get their values from config\n(if it is present) rather than from object model.\n\nConfig files can also modify defaults for other property types.\n\nConfig files are stored in special folder that is configured in\n[engine] section of Murano config file under class_configs key.\n\nConfig files must me named using %FQ class name%.json or\n%FQ class name%.yaml pattern and contain dictionary of a form\npropertyName -> propertyValue\n\nChange-Id: I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda\nImplements: blueprint class-configs\n'}, {'number': 7, 'created': '2014-11-13 22:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/1812eddc6cf9f85fe89492039329f1cb90c90066', 'message': 'Adds per-class configs\n\nAdds ability to have per-class configuration and special properties\nwith usage ""Config"". Such properties get their values from config\n(if it is present) rather than from object model.\n\nConfig files can also modify defaults for other property types.\n\nConfig files are stored in special folder that is configured in\n[engine] section of Murano config file under class_configs key.\n\nConfig files must me named using %FQ class name%.json or\n%FQ class name%.yaml pattern and contain dictionary of a form\npropertyName -> propertyValue\n\nChange-Id: I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda\nImplements: blueprint class-configs\n'}, {'number': 8, 'created': '2014-12-12 13:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/a407b408112feef04c2763e3f6fe419487fe53ba', 'message': 'Adds per-class configs\n\nAdds ability to have per-class configuration and special properties\nwith usage ""Config"". Such properties get their values from config\n(if it is present) rather than from object model.\n\nConfig files can also modify defaults for other property types.\n\nConfig files are stored in special folder that is configured in\n[engine] section of Murano config file under class_configs key.\n\nConfig files must me named using %FQ class name%.json or\n%FQ class name%.yaml pattern and contain dictionary of a form\npropertyName -> propertyValue\n\nChange-Id: I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda\nImplements: blueprint class-configs\n'}, {'number': 9, 'created': '2014-12-12 18:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/137914725bef9314fddb8c749892f08b9ae82a09', 'message': 'Adds per-class configs\n\nAdds ability to have per-class configuration and special properties\nwith usage ""Config"". Such properties get their values from config\n(if it is present) rather than from object model.\n\nConfig files can also modify defaults for other property types.\n\nConfig files are stored in special folder that is configured in\n[engine] section of Murano config file under class_configs key.\n\nConfig files must me named using %FQ class name%.json or\n%FQ class name%.yaml pattern and contain dictionary of a form\npropertyName -> propertyValue\n\nChange-Id: I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda\nImplements: blueprint class-configs\n'}, {'number': 10, 'created': '2014-12-16 21:49:17.000000000', 'files': ['murano/dsl/typespec.py', 'murano/tests/unit/dsl/test_property_access.py', 'murano/common/config.py', 'murano/tests/unit/dsl/meta/DerivedFrom2Classes.yaml', 'murano/dsl/murano_class.py', 'murano/tests/unit/dsl/meta/ConfigProperties.yaml', 'murano/tests/unit/dsl/foundation/test_case.py', 'murano/tests/unit/dsl/foundation/test_class_loader.py', 'murano/dsl/murano_method.py', 'murano/tests/unit/dsl/test_config_properties.py', 'murano/engine/package_class_loader.py', 'murano/dsl/class_loader.py', 'murano/dsl/murano_object.py', 'murano/engine/simple_cloader.py', 'murano/tests/unit/test_heat_stack.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/b5f0b0f245705e606d0199e2547e7e2d82beecb9', 'message': 'Adds per-class configs\n\nAdds ability to have per-class configuration and special properties\nwith usage ""Config"". Such properties get their values from config\n(if it is present) rather than from object model.\n\nConfig files can also modify defaults for other property types.\n\nConfig files are stored in special folder that is configured in\n[engine] section of Murano config file under class_configs key.\n\nConfig files must me named using %FQ class name%.json or\n%FQ class name%.yaml pattern and contain dictionary of a form\npropertyName -> propertyValue\n\nChange-Id: I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda\nImplements: blueprint class-configs\n'}]",1,134183,b5f0b0f245705e606d0199e2547e7e2d82beecb9,55,5,10,7226,,,0,"Adds per-class configs

Adds ability to have per-class configuration and special properties
with usage ""Config"". Such properties get their values from config
(if it is present) rather than from object model.

Config files can also modify defaults for other property types.

Config files are stored in special folder that is configured in
[engine] section of Murano config file under class_configs key.

Config files must me named using %FQ class name%.json or
%FQ class name%.yaml pattern and contain dictionary of a form
propertyName -> propertyValue

Change-Id: I0f45fa7064183f5605c5ef393b5b00e8c8ae2bda
Implements: blueprint class-configs
",git fetch https://review.opendev.org/openstack/murano refs/changes/83/134183/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/dsl/typespec.py', 'murano/tests/unit/dsl/test_property_access.py', 'murano/common/config.py', 'murano/tests/unit/dsl/meta/DerivedFrom2Classes.yaml', 'murano/dsl/murano_class.py', 'murano/tests/unit/dsl/meta/ConfigProperties.yaml', 'murano/tests/unit/dsl/foundation/test_case.py', 'murano/tests/unit/dsl/foundation/test_class_loader.py', 'murano/dsl/murano_method.py', 'murano/tests/unit/dsl/test_config_properties.py', 'murano/engine/package_class_loader.py', 'murano/dsl/class_loader.py', 'murano/dsl/murano_object.py', 'murano/engine/simple_cloader.py']",14,1d43bef0974012e8d3b6f97f6cb58f60f13e6064,bp/class-configs,,"# Copyright (c) 2013 Mirantis Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import os.path import yaml import murano.dsl.class_loader as class_loader import murano.dsl.yaql_expression as yaql_expression import murano.engine.system.yaql_functions as yaql_functions def yaql_constructor(loader, node): value = loader.construct_scalar(node) return yaql_expression.YaqlExpression(value) yaml.add_constructor(u'!yaql', yaql_constructor) yaml.add_implicit_resolver(u'!yaql', yaql_expression.YaqlExpression) class SimpleClassLoader(class_loader.MuranoClassLoader): def __init__(self, base_path): self._base_path = base_path super(SimpleClassLoader, self).__init__() def load_definition(self, name): path = os.path.join(self._base_path, name, 'manifest.yaml') if not os.path.exists(path): return None with open(path) as stream: return yaml.load(stream) def create_root_context(self): context = super(SimpleClassLoader, self).create_root_context() yaql_functions.register(context) return context ",154,65
openstack%2Fkeystone~stable%2Fjuno~If98293e9277dc99c596a2a8e9c9584b58f8bc6fc,openstack/keystone,stable/juno,If98293e9277dc99c596a2a8e9c9584b58f8bc6fc,Updated from global requirements,MERGED,2014-12-14 00:11:34.000000000,2014-12-18 09:12:00.000000000,2014-12-18 09:11:59.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1420}, {'_account_id': 2472}, {'_account_id': 9656}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-14 00:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/02ad9ad19bd881e3ee380b8d616f957437f69478', 'message': 'Updated from global requirements\n\nChange-Id: If98293e9277dc99c596a2a8e9c9584b58f8bc6fc\n'}, {'number': 2, 'created': '2014-12-16 14:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/93313af07d218e18aca5d7ac9b63fa81367d16c1', 'message': 'Updated from global requirements\n\nChange-Id: If98293e9277dc99c596a2a8e9c9584b58f8bc6fc\n'}, {'number': 3, 'created': '2014-12-16 23:03:42.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/57c0244bb60900a88d6e91a9eac42599893a731a', 'message': 'Updated from global requirements\n\nChange-Id: If98293e9277dc99c596a2a8e9c9584b58f8bc6fc\n'}]",2,141599,57c0244bb60900a88d6e91a9eac42599893a731a,15,6,3,11131,,,0,"Updated from global requirements

Change-Id: If98293e9277dc99c596a2a8e9c9584b58f8bc6fc
",git fetch https://review.opendev.org/openstack/keystone refs/changes/99/141599/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,02ad9ad19bd881e3ee380b8d616f957437f69478,openstack/requirements,"SQLAlchemy>=0.8.4,<=0.9.99,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,!=0.9.4,!=0.9.5,!=0.9.6","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",2,2
openstack%2Fsahara~stable%2Fjuno~I2d39657625c5f6117714e09c340acd148088c4f9,openstack/sahara,stable/juno,I2d39657625c5f6117714e09c340acd148088c4f9,Updated from global requirements,MERGED,2014-12-16 23:08:54.000000000,2014-12-18 09:11:40.000000000,2014-12-18 09:11:38.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2472}, {'_account_id': 7213}, {'_account_id': 9656}, {'_account_id': 10670}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-16 23:08:54.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/3556ba1c89b2101cdfefeb20ab84e65f8cd1401e', 'message': 'Updated from global requirements\n\nChange-Id: I2d39657625c5f6117714e09c340acd148088c4f9\n'}]",1,142255,3556ba1c89b2101cdfefeb20ab84e65f8cd1401e,13,7,1,11131,,,0,"Updated from global requirements

Change-Id: I2d39657625c5f6117714e09c340acd148088c4f9
",git fetch https://review.opendev.org/openstack/sahara refs/changes/55/142255/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3556ba1c89b2101cdfefeb20ab84e65f8cd1401e,openstack/requirements,"oslo.db>=1.0.0,<1.1 # Apache-2.0","oslo.db>=1.0.0,<1.3 # Apache-2.0",1,1
openstack%2Fneutron~master~Id058b7ddef2ed337627dc692d0418786ad14f4b4,openstack/neutron,master,Id058b7ddef2ed337627dc692d0418786ad14f4b4,Add OVS status and fix OVS crash,MERGED,2014-12-09 14:31:59.000000000,2014-12-18 09:11:25.000000000,2014-12-18 09:11:24.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 704}, {'_account_id': 1561}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5950}, {'_account_id': 6502}, {'_account_id': 7743}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-09 14:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/53ae7d4e624b00ffe39daa2d216c606d989b77e2', 'message': ""Add OVS status and fix OVS crash\n\nOVS crash/restart is unpredictable, so neutron-ovs-agent should be\nrobust enough under that situation. But currently ovs-agent doesn't\nfigure out this error status(only check ovs restarted status) and\nstill continue to apply subsequent operations(set br/add patch\nport/...) till causing exceptions/crash. Add flag to fully represent\novs status. Base on that, we can add proper fail-over code in method\nrpc_loop, to treat ovs dead/restart gracefully to prevent agent\ncrashes while it is running.\nCloses-bug: #1296202\n\nChange-Id: Id058b7ddef2ed337627dc692d0418786ad14f4b4\n""}, {'number': 2, 'created': '2014-12-11 15:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a51292a7d37bb32858ef140b8086408491d26d38', 'message': ""Add OVS status and fix OVS crash\n\nOVS crash/restart is unpredictable, so neutron-ovs-agent should be\nrobust enough under that situation. But currently ovs-agent doesn't\nfigure out this error status(only check ovs restarted status) and\nstill continue to apply subsequent operations(set br/add patch\nport/...) till causing exceptions/crash. Add flag to fully represent\novs status. Base on that, we can add proper fail-over code in method\nrpc_loop, to treat ovs dead/restart gracefully to prevent agent\ncrashes while it is running.\nCloses-bug: #1296202\n\nChange-Id: Id058b7ddef2ed337627dc692d0418786ad14f4b4\n""}, {'number': 3, 'created': '2014-12-15 15:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c24291e748bf2204ed21a1faa55c4f8454cb20d', 'message': ""Add OVS status and fix OVS crash\n\nOVS crash/restart is unpredictable, so neutron-ovs-agent should be\nrobust enough under that situation. But currently ovs-agent doesn't\nfigure out this error status(only check ovs restart/normal status)\nand still continue to apply subsequent operations(set br/add patch\nport/...) till causing exceptions/crash. Add flag to fully represent\novs status. Base on that, we can add proper fail-over code in method\nrpc_loop, to treat ovs dead/restart gracefully to prevent agent\ncrashes while it is running.\nCloses-bug: #1296202\n\nChange-Id: Id058b7ddef2ed337627dc692d0418786ad14f4b4\n""}, {'number': 4, 'created': '2014-12-17 15:25:22.000000000', 'files': ['neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/common/constants.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/91b7fc7f162751936f7cb15d4add932a4aebd55b', 'message': ""Add OVS status and fix OVS crash\n\nOVS crash/restart is unpredictable, so neutron-ovs-agent should be\nrobust enough under that situation. But currently ovs-agent doesn't\nfigure out this error status(only check ovs restart/normal status)\nand still continue to apply subsequent operations(set br/add patch\nport/...) till causing exceptions/crash. Add flag to fully represent\novs status. Base on that, we can add proper fail-over code in method\nrpc_loop, to treat ovs dead/restart gracefully to prevent agent\ncrashes while it is running.\nCloses-bug: #1296202\n\nChange-Id: Id058b7ddef2ed337627dc692d0418786ad14f4b4\n""}]",6,140342,91b7fc7f162751936f7cb15d4add932a4aebd55b,92,27,4,7743,,,0,"Add OVS status and fix OVS crash

OVS crash/restart is unpredictable, so neutron-ovs-agent should be
robust enough under that situation. But currently ovs-agent doesn't
figure out this error status(only check ovs restart/normal status)
and still continue to apply subsequent operations(set br/add patch
port/...) till causing exceptions/crash. Add flag to fully represent
ovs status. Base on that, we can add proper fail-over code in method
rpc_loop, to treat ovs dead/restart gracefully to prevent agent
crashes while it is running.
Closes-bug: #1296202

Change-Id: Id058b7ddef2ed337627dc692d0418786ad14f4b4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/42/140342/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/openvswitch/common/constants.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py']",3,53ae7d4e624b00ffe39daa2d216c606d989b77e2,bug/1296202," def check_ovs_status(self): if canary_flow == '': LOG.warn(_LW(""OVS is restarted. Reset bridges and "" ""recover ports."")) return constants.OVS_RESTARTED elif canary_flow is None: LOG.warn(_LW(""OVS is dead. OVSNeutronAgent will keep running "" ""and checking OVS status periodically."")) return constants.OVS_DEAD else: # OVS is in normal status return constants.OVS_NORMAL def loop_count_and_wait(self, start_time, port_stats): # sleep till end of polling interval elapsed = (time.time() - start_time) LOG.debug(""Agent rpc_loop - iteration:%(iter_num)d "" ""completed. Processed ports statistics: "" ""%(port_stats)s. Elapsed:%(elapsed).3f"", {'iter_num': self.iter_num, 'port_stats': port_stats, 'elapsed': elapsed}) if (elapsed < self.polling_interval): time.sleep(self.polling_interval - elapsed) else: LOG.debug(""Loop iteration exceeded interval "" ""(%(polling_interval)s vs. %(elapsed)s)!"", {'polling_interval': self.polling_interval, 'elapsed': elapsed}) self.iter_num = self.iter_num + 1 ovs_status = constants.OVS_NORMAL while self.run_daemon_loop: start_time = time.time() ovs_status = self.check_ovs_status() if ovs_status == constants.OVS_RESTARTED: elif ovs_status == constants.OVS_DEAD: # Agent doesn't apply any operations when ovs is dead, to # prevent unexpected failure or crash. Sleep and continue # loop in which ovs status will be checked periodically. self.loop_count_and_wait(start_time, port_stats) continue ovs_restarted = (ovs_status == constants.OVS_RESTARTED) 'elapsed': time.time() - start_time}) 'elapsed': time.time() - start_time}) 'elapsed': time.time() - start_time}) 'elapsed': time.time() - start_time}) 'elapsed': time.time() - start_time}) self.loop_count_and_wait(start_time, port_stats)"," def check_ovs_restart(self): return not canary_flow ovs_restarted = False while self.run_daemon_loop: start = time.time() ovs_restarted = self.check_ovs_restart() if ovs_restarted: 'elapsed': time.time() - start}) 'elapsed': time.time() - start}) 'elapsed': time.time() - start}) 'elapsed': time.time() - start}) 'elapsed': time.time() - start}) # sleep till end of polling interval elapsed = (time.time() - start) LOG.debug(""Agent rpc_loop - iteration:%(iter_num)d "" ""completed. Processed ports statistics: "" ""%(port_stats)s. Elapsed:%(elapsed).3f"", {'iter_num': self.iter_num, 'port_stats': port_stats, 'elapsed': elapsed}) if (elapsed < self.polling_interval): time.sleep(self.polling_interval - elapsed) else: LOG.debug(""Loop iteration exceeded interval "" ""(%(polling_interval)s vs. %(elapsed)s)!"", {'polling_interval': self.polling_interval, 'elapsed': elapsed}) self.iter_num = self.iter_num + 1",62,33
openstack%2Fkeystone~master~I9e56a2d3d58c425b9655507263f7d453fab2c568,openstack/keystone,master,I9e56a2d3d58c425b9655507263f7d453fab2c568,Remove unnecessary ldap import,MERGED,2014-12-16 19:10:20.000000000,2014-12-18 09:11:08.000000000,2014-12-18 09:11:07.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 9101}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-12-16 19:10:20.000000000', 'files': ['keystone/common/ldap/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/753770652603b8e4d25b50a71aaea9980c9fcc8b', 'message': 'Remove unnecessary ldap import\n\nSince ldap.filter is imported, there is no need to also import ldap.\n\nChange-Id: I9e56a2d3d58c425b9655507263f7d453fab2c568\n'}]",0,142192,753770652603b8e4d25b50a71aaea9980c9fcc8b,12,6,1,6482,,,0,"Remove unnecessary ldap import

Since ldap.filter is imported, there is no need to also import ldap.

Change-Id: I9e56a2d3d58c425b9655507263f7d453fab2c568
",git fetch https://review.opendev.org/openstack/keystone refs/changes/92/142192/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/ldap/core.py'],1,753770652603b8e4d25b50a71aaea9980c9fcc8b,remove_extra_import,,import ldap,0,1
openstack%2Fnova~master~Ie6b2d998dea6c5b9c7d3eee9c1c01f9169679451,openstack/nova,master,Ie6b2d998dea6c5b9c7d3eee9c1c01f9169679451,Fix spelling error in compute api,MERGED,2014-12-15 15:16:49.000000000,2014-12-18 09:10:50.000000000,2014-12-18 09:10:47.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10559}]","[{'number': 1, 'created': '2014-12-15 15:16:49.000000000', 'files': ['nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5308a63766e88afb7b80de4182709b9d34f544be', 'message': 'Fix spelling error in compute api\n\nChange-Id: Ie6b2d998dea6c5b9c7d3eee9c1c01f9169679451\n'}]",0,141821,5308a63766e88afb7b80de4182709b9d34f544be,36,11,1,10559,,,0,"Fix spelling error in compute api

Change-Id: Ie6b2d998dea6c5b9c7d3eee9c1c01f9169679451
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/141821/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,5308a63766e88afb7b80de4182709b9d34f544be,compute_api_typo," secondary sort ket, etc.). For each sort key, the associated sort"," seconardy sort ket, etc.). For each sort key, the associated sort",1,1
openstack%2Fglance~master~Ia6b4cb215c4945fb0373e9af5358725209353aa8,openstack/glance,master,Ia6b4cb215c4945fb0373e9af5358725209353aa8,Update config and docs for Multiple Containers,MERGED,2014-12-12 23:08:35.000000000,2014-12-18 09:02:46.000000000,2014-12-18 09:02:45.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 2537}, {'_account_id': 8158}, {'_account_id': 11864}]","[{'number': 1, 'created': '2014-12-12 23:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2b2a36a984d50ad34b757816b72636558c6e6ea4', 'message': 'Update glance-api.conf and configuring.rst for Multiple Containers\n\nThis adds appropriate config options to reflect changes in the Multiple\nContainers spec.\n\nApproved spec:\n https://review.openstack.org/#/c/124522\n\nRelated blueprint:\n  https://blueprints.launchpad.net/glance/+spec/swift-store-multiple-containers\n\nChange-Id: Ia6b4cb215c4945fb0373e9af5358725209353aa8\n'}, {'number': 2, 'created': '2014-12-12 23:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/60f49e55bda5786842cb295fe201301c63e75cfa', 'message': 'Update config and docs for Multiple Containers\n\nThis adds appropriate config options to reflect\nchanges in the Multiple Containers spec.\n\nApproved spec:\n https://review.openstack.org/#/c/124522\n\nRelated blueprint:\n  https://blueprints.launchpad.net/glance/+spec/swift-store-multiple-containers\n\nChange-Id: Ia6b4cb215c4945fb0373e9af5358725209353aa8\n'}, {'number': 3, 'created': '2014-12-15 20:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ddacb73fc8cd69a98a6cf5793c885c35c0371804', 'message': 'Update config and docs for Multiple Containers\n\nThis adds appropriate config options to reflect\nchanges in the Multiple Containers spec.\n\nApproved spec:\n https://review.openstack.org/#/c/124522\n\nRelated blueprint:\n  https://blueprints.launchpad.net/glance/+spec/swift-store-multiple-containers\n\nDocImpact\nChange-Id: Ia6b4cb215c4945fb0373e9af5358725209353aa8\n'}, {'number': 4, 'created': '2014-12-15 20:22:37.000000000', 'files': ['etc/glance-api.conf', 'doc/source/configuring.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/2237303150ea25291c817feb9ad4e54fbc801845', 'message': 'Update config and docs for Multiple Containers\n\nThis adds appropriate config options to reflect\nchanges in the Multiple Containers spec.\n\nApproved spec:\n https://review.openstack.org/#/c/124522\n\nDocImpact\nbp: swift-store-multiple-containers\nChange-Id: Ia6b4cb215c4945fb0373e9af5358725209353aa8\n'}]",4,141516,2237303150ea25291c817feb9ad4e54fbc801845,25,5,4,11864,,,0,"Update config and docs for Multiple Containers

This adds appropriate config options to reflect
changes in the Multiple Containers spec.

Approved spec:
 https://review.openstack.org/#/c/124522

DocImpact
bp: swift-store-multiple-containers
Change-Id: Ia6b4cb215c4945fb0373e9af5358725209353aa8
",git fetch https://review.opendev.org/openstack/glance refs/changes/16/141516/4 && git format-patch -1 --stdout FETCH_HEAD,"['etc/glance-api.conf', 'doc/source/configuring.rst']",2,2b2a36a984d50ad34b757816b72636558c6e6ea4,bp/swift-store-multiple-containers,"* ``swift_store_multiple_containers_seed`` Optional. Default: ``0`` Can only be specified in configuration files. `This option is specific to the Swift storage backend.` When set to 0, a single-tenant store will only use one container to store all images. When set to an integer value between 1 and 32, a single-tenant store will use multiple containers to store images, and this value will determine how many containers are created. Used only when swift_store_multi_tenant is disabled. The total number of containers that will be used is approximately equal to 16^N. Example: if this config option is set to 3 and swift_store_container = 'glance', then an image with UUID 'fdae39a1-bac5-4238-aba4-69bcc726e848' would be placed in the container 'glance_fda'. All dashes in the UUID are included when creating the container name but do not count toward the character limit, so in this example with N=10 the container name would be 'glance_fdae39a1-ba'. When choosing the value for swift_store_multiple_containers_seed, deployers should discuss a suitable value with their swift operations team. The authors of this option recommend that large scale deployments use a value of '2', which will create a maximum of ~256 containers. Choosing a higher number than this, even in extremely large scale deployments, may not have any positive impact on performance and could lead to a large number of empty, unused containers. The largest of deployments could notice an increase in performance if swift rate limits are throttling on single container. Note: If dynamic container creation is turned off, any value for this configuration option higher than '1' may be unreasonable as the deployer would have to manually create each container. ",,44,0
openstack%2Fmistral~master~Ibf0ca7b17ce100467e4243b411f94ce481ec4962,openstack/mistral,master,Ibf0ca7b17ce100467e4243b411f94ce481ec4962,Implement pause-before,MERGED,2014-12-10 03:37:36.000000000,2014-12-18 09:00:54.000000000,2014-12-18 09:00:53.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 12936}]","[{'number': 1, 'created': '2014-12-10 03:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/8ea4c18a61c5d25368dc2cb9713da9161b078e1c', 'message': 'Implement pause-before\n\n Implements blueprint mistral-pause-before-policy\n\nChange-Id: Ibf0ca7b17ce100467e4243b411f94ce481ec4962\n'}, {'number': 2, 'created': '2014-12-12 21:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bafc962337d6765e98da940f3f376b5583ef0cf8', 'message': 'Implement pause-before\n\n Implements blueprint mistral-pause-before-policy\n\nChange-Id: Ibf0ca7b17ce100467e4243b411f94ce481ec4962\n'}, {'number': 3, 'created': '2014-12-12 21:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/48c9e853da5485a1407e7321f0856774c3306731', 'message': 'Implement pause-before\n\n Implements blueprint mistral-pause-before-policy\n\nChange-Id: Ibf0ca7b17ce100467e4243b411f94ce481ec4962\n'}, {'number': 4, 'created': '2014-12-16 17:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/010447ba06adcefc2a5ea60eb3c252e04e6099ff', 'message': 'Implement pause-before\n\n Implements blueprint mistral-pause-before-policy\n\nChange-Id: Ibf0ca7b17ce100467e4243b411f94ce481ec4962\n'}, {'number': 5, 'created': '2014-12-17 17:32:43.000000000', 'files': ['mistral/engine1/commands.py', 'mistral/workflow/states.py', 'mistral/workflow/base.py', 'doc/source/dsl/dsl_v2.rst', 'mistral/workbook/v2/task_policies.py', 'mistral/engine1/policies.py', 'mistral/tests/unit/engine1/test_policies.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/9c06dca52c2519c70fa3833d00f0e0d8c2d01b28', 'message': 'Implement pause-before\n\n Implements blueprint mistral-pause-before-policy\n\nChange-Id: Ibf0ca7b17ce100467e4243b411f94ce481ec4962\n'}]",13,140564,9c06dca52c2519c70fa3833d00f0e0d8c2d01b28,20,4,5,12936,,,0,"Implement pause-before

 Implements blueprint mistral-pause-before-policy

Change-Id: Ibf0ca7b17ce100467e4243b411f94ce481ec4962
",git fetch https://review.opendev.org/openstack/mistral refs/changes/64/140564/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/dsl/dsl_v2.rst', 'mistral/workbook/v2/task_policies.py', 'mistral/api/controllers/v2/task.py', 'mistral/engine1/policies.py', 'mistral/tests/unit/engine1/test_policies.py']",5,8ea4c18a61c5d25368dc2cb9713da9161b078e1c,," self.assertEqual(5, len(arr)) self.assertEqual(5, len(arr))"," self.assertEqual(4, len(arr)) self.assertEqual(4, len(arr))",56,7
openstack%2Fmistral~master~I467f4d493cd379c11cf7e5e872e4baa4faeac674,openstack/mistral,master,I467f4d493cd379c11cf7e5e872e4baa4faeac674,Updates logging configuration samples,MERGED,2014-12-17 01:34:17.000000000,2014-12-18 08:56:24.000000000,2014-12-18 08:56:22.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}]","[{'number': 1, 'created': '2014-12-17 01:34:17.000000000', 'files': ['etc/logging.conf.sample', 'etc/wf_trace_logging.conf.sample'], 'web_link': 'https://opendev.org/openstack/mistral/commit/df5f04c58a28d213a127ea88b0c8237a412c03d5', 'message': 'Updates logging configuration samples\n\n- Changed all formats to look more like the default formatters. This simplifies parsing\n  in tools like logstash etc.\n- Changed location of all log files to end up in /var/log instead of /tmp. /var/log is\n  a better default than /tmp for log files.\n- In wf_trace_conf_logging.conf.sample using separate formatters for different handlers.\n  This accounts for the usecase of each handler having its own specific log format to\n  reduce redundancy in log statements.\n\nChange-Id: I467f4d493cd379c11cf7e5e872e4baa4faeac674\nCloses-Bug: 1322740\n'}]",0,142295,df5f04c58a28d213a127ea88b0c8237a412c03d5,7,4,1,10126,,,0,"Updates logging configuration samples

- Changed all formats to look more like the default formatters. This simplifies parsing
  in tools like logstash etc.
- Changed location of all log files to end up in /var/log instead of /tmp. /var/log is
  a better default than /tmp for log files.
- In wf_trace_conf_logging.conf.sample using separate formatters for different handlers.
  This accounts for the usecase of each handler having its own specific log format to
  reduce redundancy in log statements.

Change-Id: I467f4d493cd379c11cf7e5e872e4baa4faeac674
Closes-Bug: 1322740
",git fetch https://review.opendev.org/openstack/mistral refs/changes/95/142295/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/logging.conf.sample', 'etc/wf_trace_logging.conf.sample']",2,df5f04c58a28d213a127ea88b0c8237a412c03d5,bug/1322740,"keys=consoleHandler, wfTraceFileHandler, fileHandlerkeys=wfFormatter, simpleFormatter, verboseFormatterhandlers=consoleHandler, wfTraceFileHandlerformatter=verboseFormatter args=(""/var/log/mistral.log"",)[handler_wfTraceFileHandler]formatter=wfFormatter args=(""/var/log/mistral_wf_trace.log"",) [formatter_verboseFormatter] format=%(asctime)s %(thread)s %(levelname)s %(module)s [-] %(message)s datefmt=format=%(asctime)s %(levelname)s [-] %(message)s datefmt= [formatter_wfFormatter] format=%(asctime)s WF [-] %(message)s datefmt= ","keys=consoleHandler, prettyFileHandler, fileHandlerkeys=simpleFormatterhandlers=consoleHandler, fileHandlerformatter=simpleFormatter args=(""/tmp/mistral.log"",)[handler_prettyFileHandler]formatter=simpleFormatter args=(""/tmp/mistral_wf_trace.log"",) format=%(asctime)s - WF - %(message)s datefmt=%y-%m-%d %H:%M:%S",20,13
openstack%2Fopenstack-manuals~stable%2Fjuno~Id8032abce573619735567f946f38886c63eae7ee,openstack/openstack-manuals,stable/juno,Id8032abce573619735567f946f38886c63eae7ee,Added mlnx plugin deprecation notice in stable/juno,MERGED,2014-12-17 09:16:36.000000000,2014-12-18 07:35:03.000000000,2014-12-18 07:35:01.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 10705}]","[{'number': 1, 'created': '2014-12-17 09:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1e8b94e83387645805ce854365d231703249bdd4', 'message': 'Added mlnx plugin deprecation notice in stable/juno\n\nAdded deprecation notice in the Cloud adminstrator guide and Configuration Reference Guide\n\nChange-Id: Id8032abce573619735567f946f38886c63eae7ee\nbackport: none\nPartial-bug: #1403206\n'}, {'number': 2, 'created': '2014-12-17 09:21:44.000000000', 'files': ['doc/admin-guide-cloud/networking/section_networking_introduction.xml', 'doc/config-reference/networking/section_networking-plugins.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/14b937424572ab13b812509c70c8188d817e60f0', 'message': 'Added mlnx plugin deprecation notice in stable/juno\n\nAdded deprecation notice in the Cloud Administrator Guide and Configuration Reference Guide\n\nChange-Id: Id8032abce573619735567f946f38886c63eae7ee\nbackport: none\nPartial-bug: #1403206\n'}]",2,142388,14b937424572ab13b812509c70c8188d817e60f0,15,4,2,10705,,,0,"Added mlnx plugin deprecation notice in stable/juno

Added deprecation notice in the Cloud Administrator Guide and Configuration Reference Guide

Change-Id: Id8032abce573619735567f946f38886c63eae7ee
backport: none
Partial-bug: #1403206
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/88/142388/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/networking/section_networking_introduction.xml', 'doc/config-reference/networking/section_networking-plugins.xml']",2,1e8b94e83387645805ce854365d231703249bdd4,mlnxdeprecate_juno/darren, <note> <title>Plug-in deprecation notice</title> <para>The Mellanox plug-in is deprecated in the Juno release and will be removed in the Kilo release.</para> </note>,,10,0
openstack%2Fkeystone~master~I4247b104d0490d264bbc36c3dad0c59f29c4345d,openstack/keystone,master,I4247b104d0490d264bbc36c3dad0c59f29c4345d,Change config option examples to v3,MERGED,2014-10-26 23:12:16.000000000,2014-12-18 07:34:13.000000000,2014-12-18 07:34:12.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5046}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-10-26 23:12:16.000000000', 'files': ['etc/keystone.conf.sample', 'keystone/common/config.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/bccac63ace69629239e64a1738549b25ec2b8566', 'message': 'Change config option examples to v3\n\nReference v3 in the config help text for the day when v2 is removed.\n\nChange-Id: I4247b104d0490d264bbc36c3dad0c59f29c4345d\n'}]",0,131004,bccac63ace69629239e64a1738549b25ec2b8566,24,7,1,6486,,,0,"Change config option examples to v3

Reference v3 in the config help text for the day when v2 is removed.

Change-Id: I4247b104d0490d264bbc36c3dad0c59f29c4345d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/04/131004/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/common/config.py']",2,bccac63ace69629239e64a1738549b25ec2b8566,cleanup, 'request to http://server:5000/v3/users will ' '(e.g. /prefix/v3) or the endpoint should be found ' 'request to http://server:35357/v3/users will ' '(e.g. /prefix/v3) or the endpoint should be found ', 'request to http://server:5000/v2.0/users will ' '(e.g. /prefix/v2.0) or the endpoint should be found ' 'request to http://server:35357/v2.0/users will ' '(e.g. /prefix/v2.0) or the endpoint should be found ',14,14
openstack%2Fnova~master~I94e63159ee5539ed7b947614ff0ec87182f184a4,openstack/nova,master,I94e63159ee5539ed7b947614ff0ec87182f184a4,hardware: add method to return requested memory page size,MERGED,2014-10-13 16:20:54.000000000,2014-12-18 07:33:47.000000000,2014-12-18 07:33:44.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6062}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11642}]","[{'number': 1, 'created': '2014-10-13 16:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2bcfd31e042bbb7c328409408fc24aed250c3838', 'message': 'hardware: add method to return desired memory page size from flavor\n\nIntroduce method to return desired memory pages size\nfrom flavor.\nThis commit also add a new exception MemoryPageSizeInvalid\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 2, 'created': '2014-10-13 17:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bae29cf59ac88360579f16e8eab5fb29c675046e', 'message': 'hardware: add method to return requested memory page size\n\nIntroduce method to return requested memory pages size.\nThis commit also add a new exception MemoryPageSizeInvalid and\nnew constants MEMPAGES_*\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 3, 'created': '2014-10-14 08:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b9129cffc68abb8873eafd26e535f0841d92425', 'message': 'hardware: add method to return requested memory page size\n\nIntroduce method to return requested memory pages size.\nThis commit also add a new exception MemoryPageSizeInvalid and\nnew constants MEMPAGES_*\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 4, 'created': '2014-10-14 15:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51ce0ab7c8a0ef68a441897f9587c4fa11db61e6', 'message': 'hardware: add method to return requested memory page size\n\nIntroduce method to return requested memory pages size.\nThis commit also add a new exception MemoryPageSizeInvalid and\nnew constants MEMPAGES_*\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 5, 'created': '2014-10-15 16:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/914d539f9b718b4638e582ca512dfbed5d2df3c8', 'message': 'hardware: add method to return requested memory page size\n\nIntroduce method to return requested memory pages size.\nThis commit also add a new exception MemoryPageSizeInvalid and\nnew constants MEMPAGES_*\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 6, 'created': '2014-10-16 11:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c4126fe24aca6d66170ff317ad23d4936236ca6', 'message': 'hardware: add method to return requested memory page size\n\nIntroduce method to return requested memory pages size.\nThis commit also add a new exception MemoryPageSizeInvalid and\nnew constants MEMPAGES_*\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 7, 'created': '2014-10-20 12:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e175112eb61bc352406ceed9a0f59aafc8ee76fe', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exception MemoryPageSizeInvalid and\nnew constants MEMPAGES_*\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 8, 'created': '2014-10-20 12:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b7579e43009a917f3a75a605c6c0276b4f227a8', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exception MemoryPageSizeInvalid and\nnew constants MEMPAGES_*\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 9, 'created': '2014-10-20 17:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/734914c4eaba0fdac63f87a5b09295fea6d255b1', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exception MemoryPageSizeInvalid and\nnew constants MEMPAGES_*\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 10, 'created': '2014-10-21 08:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c330256d9d64ef199ee9fbea68b50c723717131', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exception MemoryPageSizeInvalid and\nnew constants MEMPAGES_*\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 11, 'created': '2014-10-22 09:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/718dad871eae4e6ddd7883fe986b6d5d53ac61db', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exception MemoryPageSizeInvalid and\nnew constants MEMPAGES_*\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 12, 'created': '2014-10-24 10:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/40b2adc11979b6c5e5c7c8cea4cff2dcb59b0e92', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 13, 'created': '2014-10-24 12:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/914920e42e5c62be78ef8cc8d665daa4a903b15e', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 14, 'created': '2014-10-27 17:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1fe1223d3da1b3b49e0b452c7ca8c6c28364deda', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 15, 'created': '2014-10-28 08:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b2be29d0a8fc1aa39dcfbfdafcbca68345b31d88', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 16, 'created': '2014-10-28 13:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/35d6700a6f7e7210913d834858d54cc988fa5d43', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 17, 'created': '2014-10-28 15:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c300be1758a319d419fbfd571da1dcdce647a29', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 18, 'created': '2014-10-29 14:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e053047adc4d8ea90cadd9f7d5c54681ef04d3ad', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 19, 'created': '2014-10-29 15:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15ae2bf30cb62d04ae3a32542881be786636fd2b', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 20, 'created': '2014-10-29 16:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b4758f51025273912ccd1d4639ca265886f202b', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 21, 'created': '2014-10-29 22:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd0bc4631e3aeb4a4eb76342091cad4317bb523b', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 22, 'created': '2014-10-30 08:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83742d0691fb65abe1aedbcd469a03e7be3ee007', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 23, 'created': '2014-10-30 12:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0bdb68a125dc6898130c6fd8a9e6cf57810d50a', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 24, 'created': '2014-11-05 08:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0bfbe4a769aeec9d5c7e62e776830c03aa839b7f', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 25, 'created': '2014-11-06 14:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6000d29b40f3ebc36086e98573117639abe9546', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 26, 'created': '2014-11-06 18:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/194425186329e64e51ec6ea13bc4edd628f30235', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 27, 'created': '2014-11-12 14:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3765d53d7966b4efe12bedea29209a05066ae49', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 28, 'created': '2014-11-13 17:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4263be0cb162f554219ab227fee438bf2a512634', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 29, 'created': '2014-11-14 08:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f109baf7dde46ec41ceac16adcb10e7c09a3310c', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 30, 'created': '2014-11-14 16:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/43068649b5230f3650a56313d302dcfaa6656e72', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 31, 'created': '2014-12-03 10:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/488e4c96985d024f9d5f23df97a8a57951e2ebc7', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nVirtRequestPageSize, is use to handle a requested memory page size\nand will determine whether an instance cell can be accepted by on\nhost cell.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 32, 'created': '2014-12-03 10:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cff4386544f7f67129d3bc4b2f97b2f538accc62', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nVirtRequestPageSize, is use to handle a requested memory page size\nand will determine whether an instance cell can be accepted by on\nhost cell.\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 33, 'created': '2014-12-04 14:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0c7472884b1498b659206da0acea828c2053afc', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 34, 'created': '2014-12-05 08:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01e1d96bdb92d2d160a94515a19b3047bd9e4a3a', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 35, 'created': '2014-12-08 17:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a90a25140e68b8a1ac2d78bf5273de23ea696ff', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeInvalidForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 36, 'created': '2014-12-08 17:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1887903667d3eaf42c170c3264ae81fd2f21b53', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 37, 'created': '2014-12-09 08:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0aabc2abc411bc6803d52bdde99030e1d986d35c', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 38, 'created': '2014-12-09 12:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b0a5d2f531796dcc78522078801b6bea172c79d2', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 39, 'created': '2014-12-10 13:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2bd8a61d210cec7446f30a410bae4cb09935a94c', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 40, 'created': '2014-12-10 14:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d8ccb66b0cdbab22ceb4900b62f9e69b966e3ef', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 41, 'created': '2014-12-10 15:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f512afd416eabc515a957258a9f4a49128a98b58', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 42, 'created': '2014-12-10 16:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b1ddc34efdba271f406a6db39c8deeeeadcb8cc9', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 43, 'created': '2014-12-13 09:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d6bc40903881976627643941aa9d0cad5880cfa', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 44, 'created': '2014-12-13 10:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1a05c5c71f56168ad5e64cd483eff98e2d7adca', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 45, 'created': '2014-12-14 13:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a72af3421a774c5772139dc451e82f2b96fc6fcd', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 46, 'created': '2014-12-15 11:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d5547cd9bc3899024f78ac169bb100988361226b', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 47, 'created': '2014-12-16 11:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f0033a09db18d84fd5f0d5e7fcb607f03f8891c', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}, {'number': 48, 'created': '2014-12-17 14:52:13.000000000', 'files': ['nova/exception.py', 'nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2935436b55969b856346fde5d571271f4a0a86e8', 'message': 'hardware: add method to return requested memory page size\n\nIntroduces method to return requested memory pages size.\nThis commit also add a new exceptions MemoryPageSizeInvalid and\nMemoryPageSizeForbidden\n\nWork-Item: Enhance libvirt driver to configure guests based on\n           the flavour parameter for page sizes\n\nPartial-Implement: blueprint virt-driver-large-pages\nChange-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4\n'}]",46,128006,2935436b55969b856346fde5d571271f4a0a86e8,301,14,48,7730,,,0,"hardware: add method to return requested memory page size

Introduces method to return requested memory pages size.
This commit also add a new exceptions MemoryPageSizeInvalid and
MemoryPageSizeForbidden

Work-Item: Enhance libvirt driver to configure guests based on
           the flavour parameter for page sizes

Partial-Implement: blueprint virt-driver-large-pages
Change-Id: I94e63159ee5539ed7b947614ff0ec87182f184a4
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/128006/20 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/test_hardware.py', 'nova/exception.py', 'nova/virt/hardware.py']",3,2bcfd31e042bbb7c328409408fc24aed250c3838,bp/virt-driver-large-pages,"MEMPAGES_SMALL = ""small"" MEMPAGES_LARGE = ""large"" MEMPAGES_ANY = ""any"" MEMPAGES_2M = ""2M"" MEMPAGES_1G = ""1G"" MEMPAGES_AVAIL = ( MEMPAGES_SMALL, MEMPAGES_LARGE, MEMPAGES_ANY, MEMPAGES_2M, MEMPAGES_1G, ) MEMPAGES_DEFAULT = MEMPAGES_SMALL def get_mempages_size_from_flavor(flavor): """"""Return the pages size of a given flavor Read in the extra spec of a given flavor the value hw:mem_page_size, if nothing is found return hardware.MEMPAGES_DEFAULT. Raises an exception MemoryPagesSizeInvalid is the value found is not in hardware.MEMPAGES_AVAIL. :param flavor: a Flavor object to read extra specs from :returns: a string in (small|large|any|2MB|1GB) """""" pagesize = flavor.extra_specs.get(""hw:mem_page_size"", MEMPAGES_DEFAULT) pagesize = pagesize.strip() if pagesize not in MEMPAGES_AVAIL: raise exception.MemoryPageSizeInvalid( page=pagesize, avail=MEMPAGES_AVAIL) return pagesize ",,62,0
openstack%2Fnova~master~I207f0e737139c06c5b1ea9019cfbf4659aa5ca1a,openstack/nova,master,I207f0e737139c06c5b1ea9019cfbf4659aa5ca1a,VMware: make use of oslo.vmware pbm_wsdl_loc_set,MERGED,2014-12-11 17:15:50.000000000,2014-12-18 07:33:25.000000000,2014-12-18 07:33:22.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7575}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-11 17:15:50.000000000', 'files': ['nova/virt/vmwareapi/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/23deb99619d8b4a3ea82b32a7816f386d2e378e2', 'message': 'VMware: make use of oslo.vmware pbm_wsdl_loc_set\n\nMake use of the oslo.vmware method for setting a defined wsdl.\n\nChange-Id: I207f0e737139c06c5b1ea9019cfbf4659aa5ca1a\n'}]",0,141103,23deb99619d8b4a3ea82b32a7816f386d2e378e2,19,10,1,1653,,,0,"VMware: make use of oslo.vmware pbm_wsdl_loc_set

Make use of the oslo.vmware method for setting a defined wsdl.

Change-Id: I207f0e737139c06c5b1ea9019cfbf4659aa5ca1a
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/141103/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/driver.py'],1,23deb99619d8b4a3ea82b32a7816f386d2e378e2,wsdl-update, self._session.pbm_wsdl_loc_set(pbm_wsdl_loc), # TODO(garyk): Update this with oslo.vmware method. The session.pbm # is lazy loaded so this enables us to update this entry on the fly self._session._pbm_wsdl_loc = pbm_wsdl_loc self._session._pbm = None,1,4
openstack%2Fcongress~master~I776488661b5dc9080ec883cf30f1a9b09f6f98c9,openstack/congress,master,I776488661b5dc9080ec883cf30f1a9b09f6f98c9,Updated from global requirements,MERGED,2014-12-18 01:29:17.000000000,2014-12-18 07:29:13.000000000,2014-12-18 07:08:53.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-18 01:29:17.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/congress/commit/9857d23b9248504df7be226bf4f2ccdb51782ee9', 'message': 'Updated from global requirements\n\nChange-Id: I776488661b5dc9080ec883cf30f1a9b09f6f98c9\n'}]",0,142641,9857d23b9248504df7be226bf4f2ccdb51782ee9,9,3,1,11131,,,0,"Updated from global requirements

Change-Id: I776488661b5dc9080ec883cf30f1a9b09f6f98c9
",git fetch https://review.opendev.org/openstack/congress refs/changes/41/142641/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9857d23b9248504df7be226bf4f2ccdb51782ee9,openstack/requirements,alembic>=0.7.1,alembic>=0.6.4,1,1
openstack%2Fnova~master~I625f13061fddfb0cdb16c8e36336656b40696447,openstack/nova,master,I625f13061fddfb0cdb16c8e36336656b40696447,Add pci_device_pools to ComputeNode object,MERGED,2014-11-28 19:47:12.000000000,2014-12-18 07:27:38.000000000,2014-12-18 07:27:35.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 4393}, {'_account_id': 4573}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 7461}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-28 19:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2f1ab061c9b394ad924e70395ed76874c9473b4', 'message': ""Add pci_stats to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci pools to\ntrack the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciPool has been created for\nthe data about pci pools. The pci_stats field is added to\nthe ComputeNode object as a list of PciPool objects. The\ntype of the field is:\n\n    ListOfObjectsField('PciPool')\n\nThe format that the PciPool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere is an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 2, 'created': '2014-12-02 18:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a1724e71618a66d4cff968fa95c17453e62cf0d', 'message': ""Add pci_stats to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci pools to\ntrack the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciPool has been created for\nthe data about pci pools. The pci_stats field is added to\nthe ComputeNode object as a list of PciDevicePool objects.\nThe type of the field is:\n\n    ListOfObjectsField('PciDevicePool')\n\nThe format that the PciPool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere is an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 3, 'created': '2014-12-03 14:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11fb104333394892755b988215f17a99f68976d7', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a list of PciDevicePool objects.\nThe type of the field is:\n\n    ListOfObjectsField('PciDevicePool')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 4, 'created': '2014-12-03 18:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ce57acfc814b300972c81a21660deda5a93fb95', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a list of PciDevicePool objects.\nThe type of the field is:\n\n    ListOfObjectsField('PciDevicePool')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 5, 'created': '2014-12-04 11:58:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc393ab0ee9f0058c1401ad39b8212b3a4d49f1f', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a list of PciDevicePool objects.\nThe type of the field is:\n\n    ListOfObjectsField('PciDevicePool')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 6, 'created': '2014-12-09 21:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/50d46ee77cf259dce48b59663efbfeaeb3fa3250', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a list of PciDevicePool objects.\nThe type of the field is:\n\n    ListOfObjectsField('PciDevicePool')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 7, 'created': '2014-12-11 15:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cafb1dde459b63ccb52f092046f0ff902a797cdc', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a list of PciDevicePool objects.\nThe type of the field is:\n\n    ListOfObjectsField('PciDevicePool')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 8, 'created': '2014-12-11 15:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edbb7d882c40605d9e93a0c34204c0cac2dca329', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a PciDevicePoolList object.\nThe type of the field is:\n\n    ObjectField('PciDevicePoolList')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 9, 'created': '2014-12-11 20:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cd55379df69cbaa8165d170bc99904608718749', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a PciDevicePoolList object.\nThe type of the field is:\n\n    ObjectField('PciDevicePoolList')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 10, 'created': '2014-12-11 21:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da0f3c3fdc8f1488b082c0aa167552c22d4515ce', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a PciDevicePoolList object.\nThe type of the field is:\n\n    ObjectField('PciDevicePoolList')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 11, 'created': '2014-12-12 00:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/54ff7c3029d0ea5f2dde43188038c2becc40f889', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a PciDevicePoolList object.\nThe type of the field is:\n\n    ObjectField('PciDevicePoolList')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 12, 'created': '2014-12-12 20:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c3d36ead4a808ae7516a4e47e4603ccdee1a41d7', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a PciDevicePoolList object.\nThe type of the field is:\n\n    ObjectField('PciDevicePoolList')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 13, 'created': '2014-12-15 15:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f70bb3cc44cb5a7cda6f17606fba2548f7924fb', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a PciDevicePoolList object.\nThe type of the field is:\n\n    ObjectField('PciDevicePoolList')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 14, 'created': '2014-12-15 18:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3cde5996d67d54cf3961e64609f016e1605bb3ab', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a PciDevicePoolList object.\nThe type of the field is:\n\n    ObjectField('PciDevicePoolList')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 15, 'created': '2014-12-16 10:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c3a33ef8b07784534f7253a2a3f7283656b459d', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a PciDevicePoolList object.\nThe type of the field is:\n\n    ObjectField('PciDevicePoolList')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 16, 'created': '2014-12-16 13:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9720a287ac307d7e872ee6e1be57321329d01aa1', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a PciDevicePoolList object.\nThe type of the field is:\n\n    ObjectField('PciDevicePoolList')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}, {'number': 17, 'created': '2014-12-17 14:34:45.000000000', 'files': ['nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_pci_device_pool.py', 'nova/tests/unit/objects/test_compute_node.py', 'nova/objects/compute_node.py', 'nova/objects/service.py', 'nova/objects/pci_device_pool.py', 'nova/objects/__init__.py', 'nova/tests/unit/objects/test_service.py', 'nova/tests/unit/fake_pci_device_pools.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6fbf84b8a4f8e708d3c2e61cd68334ea0f5e5cd4', 'message': ""Add pci_device_pools to ComputeNode object\n\nThe compute_nodes table has a field called pci_stats\nthat is used to pass pci device availability to the\nscheduler. The pci device data is obtained by the virt\ndrivers and passed to the resource tracker in the available\nresource data. The resource tracker creates pci device pools\nto track the number of similar devices as a resource.\n\nThe pci_stats field contains the pci pool data.\n\nA new object versioned called PciDevicePool has been created\nfor the pci device pool data. The pci_device_pools field is added\nto the ComputeNode object as a PciDevicePoolList object.\nThe type of the field is:\n\n    ObjectField('PciDevicePoolList')\n\nThe format that the PciDevicePool object uses to store data in the\ndatabase is made backward compatible with the existing format.\n\nThere was an alternative patch by yjiang5 that does not version\nthe data in the field, this patch replaces that one. The original\ncan be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb\n\nCo-Authored-By: Paul Murray <pmurray@hp.com>\nCo-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>\nCo-Authored-By: Ed Leafe <ed@leafe.com>\n\nChange-Id: I625f13061fddfb0cdb16c8e36336656b40696447\n""}]",65,137847,6fbf84b8a4f8e708d3c2e61cd68334ea0f5e5cd4,184,15,17,7461,,,0,"Add pci_device_pools to ComputeNode object

The compute_nodes table has a field called pci_stats
that is used to pass pci device availability to the
scheduler. The pci device data is obtained by the virt
drivers and passed to the resource tracker in the available
resource data. The resource tracker creates pci device pools
to track the number of similar devices as a resource.

The pci_stats field contains the pci pool data.

A new object versioned called PciDevicePool has been created
for the pci device pool data. The pci_device_pools field is added
to the ComputeNode object as a PciDevicePoolList object.
The type of the field is:

    ObjectField('PciDevicePoolList')

The format that the PciDevicePool object uses to store data in the
database is made backward compatible with the existing format.

There was an alternative patch by yjiang5 that does not version
the data in the field, this patch replaces that one. The original
can be found here Ifde89b209f2fcc2283894195b1e7e866cf28dccb

Co-Authored-By: Paul Murray <pmurray@hp.com>
Co-Authored-By: yunhong-jiang <yunhong-jiang@intel.com>
Co-Authored-By: Ed Leafe <ed@leafe.com>

Change-Id: I625f13061fddfb0cdb16c8e36336656b40696447
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/137847/17 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_pci_pool.py', 'nova/objects/compute_node.py', 'nova/tests/unit/objects/test_compute_node.py', 'nova/objects/service.py', 'nova/objects/pci_pool.py', 'nova/objects/__init__.py', 'nova/tests/unit/objects/test_service.py']",8,c2f1ab061c9b394ad924e70395ed76874c9473b4,bp/make-resource-tracker-use-objects," def pci_stats_comparator(self, expected, obj_val): obj_val = [pool.to_dict() for pool in obj_val] self.json_comparator(expected, obj_val) 'supported_hv_specs': self.supported_hv_specs_comparator, 'pci_stats': self.pci_stats_comparator}", 'supported_hv_specs': self.supported_hv_specs_comparator},164,15
openstack%2Fnova~master~I42ceaa461ddbf33dde44355d0cb0fb752c361f2f,openstack/nova,master,I42ceaa461ddbf33dde44355d0cb0fb752c361f2f,Handle invalid sort keys/dirs gracefully,MERGED,2014-12-16 22:44:34.000000000,2014-12-18 07:27:17.000000000,2014-12-18 07:27:14.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10559}]","[{'number': 1, 'created': '2014-12-16 22:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef5c26b7421e27667d0beae84b8dbec82df1aaac', 'message': 'Handle invalid sort keys/dirs gracefully\n\nIf an invalid sort key or sort direction is supplied on a GET servers\nREST API call, the API returns an error code 500 with the ""The server\nhas either erred or is incapable of performing the requested\noperation."" message.\n\nThis is occurring because the exceptions raised in\noslo.db.sqlalchemy.utils.paginate_query are not caught and handled in\nnova.\n\npaginate_query raises oslo.db.exception.InvalidSortKey for an invalid\nsort key and raises a ValueError for an invalid sort direction.\n\nChange-Id: I42ceaa461ddbf33dde44355d0cb0fb752c361f2f\nCloses-Bug: 1403230\n'}, {'number': 2, 'created': '2014-12-17 14:27:46.000000000', 'files': ['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c6d82c0ac25ddeed4e06f1d79d1128e915dafb74', 'message': 'Handle invalid sort keys/dirs gracefully\n\nIf an invalid sort key or sort direction is supplied on a GET servers\nREST API call, the API returns an error code 500 with the ""The server\nhas either erred or is incapable of performing the requested\noperation."" message.\n\nThis is occurring because the exceptions raised in\noslo.db.sqlalchemy.utils.paginate_query are not caught and handled in\nnova.\n\npaginate_query raises oslo.db.exception.InvalidSortKey for an invalid\nsort key and raises a ValueError for an invalid sort direction.\n\nChange-Id: I42ceaa461ddbf33dde44355d0cb0fb752c361f2f\nCloses-Bug: 1403230\n'}]",4,142247,c6d82c0ac25ddeed4e06f1d79d1128e915dafb74,22,8,2,10559,,,0,"Handle invalid sort keys/dirs gracefully

If an invalid sort key or sort direction is supplied on a GET servers
REST API call, the API returns an error code 500 with the ""The server
has either erred or is incapable of performing the requested
operation."" message.

This is occurring because the exceptions raised in
oslo.db.sqlalchemy.utils.paginate_query are not caught and handled in
nova.

paginate_query raises oslo.db.exception.InvalidSortKey for an invalid
sort key and raises a ValueError for an invalid sort direction.

Change-Id: I42ceaa461ddbf33dde44355d0cb0fb752c361f2f
Closes-Bug: 1403230
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/142247/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,ef5c26b7421e27667d0beae84b8dbec82df1aaac,bug/1403230," try: query_prefix = sqlalchemyutils.paginate_query(query_prefix, models.Instance, limit, sort_keys, marker=marker, sort_dirs=sort_dirs) except db_exc.InvalidSortKey: raise exception.InvalidSortKey() # Verify sort direction if sort_dirs: for sort_dir in sort_dirs: if sort_dir not in ('asc', 'desc'): msg = _(""Unknown sort direction, must be 'desc' or 'asc'"") raise exception.InvalidInput(reason=msg) "," query_prefix = sqlalchemyutils.paginate_query(query_prefix, models.Instance, limit, sort_keys, marker=marker, sort_dirs=sort_dirs)",32,5
openstack%2Ftempest~master~Ia5e177ad1124f9ee6cd7e92fad614f3310e1a86f,openstack/tempest,master,Ia5e177ad1124f9ee6cd7e92fad614f3310e1a86f,Fix ipv6 network scenario in multi-network environment,MERGED,2014-12-12 16:20:25.000000000,2014-12-18 07:26:45.000000000,2014-12-18 07:26:43.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1420}, {'_account_id': 5196}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-12 16:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8319528ace43320e883c37e3665c607dbac905aa', 'message': 'Fix ipv6 network scenario in multi-network environment\n\nThis commit makes the server creation as part of the testing use the\nnetwork created for the test. This is required if there is more than\n1 network for the tenant used by the test. Which is normally the case\noutside of running with tenant isolation.\n\nCloses-Bug: #1401961\n\nChange-Id: Ia5e177ad1124f9ee6cd7e92fad614f3310e1a86f\n'}, {'number': 2, 'created': '2014-12-12 16:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/055ecdd3259d7d984fb93d309c81d7b7a5d1201c', 'message': 'Fix ipv6 network scenario in multi-network environment\n\nThis commit makes the server creation as part of the testing use the\nnetwork created for the test. This is required if there is more than\n1 network for the tenant used by the test. Which is normally the case\noutside of running with tenant isolation.\n\nCloses-Bug: #1401961\n\nChange-Id: Ia5e177ad1124f9ee6cd7e92fad614f3310e1a86f\n'}, {'number': 3, 'created': '2014-12-12 19:27:15.000000000', 'files': ['tempest/scenario/test_network_v6.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8e48ad63ffa091c1c823082242ccc217a30356b5', 'message': 'Fix ipv6 network scenario in multi-network environment\n\nThis commit makes the server creation as part of the testing use the\nnetwork created for the test. This is required if there is more than\n1 network for the tenant used by the test. Which is normally the case\noutside of running with tenant isolation.\n\nCloses-Bug: #1401961\n\nChange-Id: Ia5e177ad1124f9ee6cd7e92fad614f3310e1a86f\n'}]",2,141419,8e48ad63ffa091c1c823082242ccc217a30356b5,27,6,3,5196,,,0,"Fix ipv6 network scenario in multi-network environment

This commit makes the server creation as part of the testing use the
network created for the test. This is required if there is more than
1 network for the tenant used by the test. Which is normally the case
outside of running with tenant isolation.

Closes-Bug: #1401961

Change-Id: Ia5e177ad1124f9ee6cd7e92fad614f3310e1a86f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/19/141419/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_network_v6.py'],1,8319528ace43320e883c37e3665c607dbac905aa,bug/1401961," self.network = self._create_network(tenant_id=self.tenant_id) sub6 = self._create_subnet(network=self.network, create_kwargs = self.srv_kwargs create_kwargs['networks'] = {'uuid': self.network.id} srv = self.create_server(create_kwargs=create_kwargs)"," net = self._create_network(tenant_id=self.tenant_id) sub6 = self._create_subnet(network=net, srv = self.create_server(create_kwargs=self.srv_kwargs)",6,3
openstack%2Fnova~master~I33dc14085ca0c887778c7379f0498714e8d30425,openstack/nova,master,I33dc14085ca0c887778c7379f0498714e8d30425,Remove unused network_api.get_instance_uuids_by_ip_filter(),MERGED,2014-11-14 13:21:01.000000000,2014-12-18 07:26:19.000000000,2014-12-18 07:26:16.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-14 13:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f0a424f17301228b79a6718e9247aeadbea8badf', 'message': 'Remove unused network_api.get_instance_uuids_by_ip_filter()\n\nChange-Id: I33dc14085ca0c887778c7379f0498714e8d30425\n'}, {'number': 2, 'created': '2014-11-23 14:02:46.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/network/rpcapi.py', 'nova/network/api.py', 'nova/network/base_api.py', 'nova/network/manager.py', 'nova/tests/unit/network/test_rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b9c57efbc7f6f9e6d5ac24e78ac6c02d5576eb67', 'message': 'Remove unused network_api.get_instance_uuids_by_ip_filter()\n\nLast usage was removed in ae781ee97947c33d6d43e4c21df4f338c875bf1c\n\nChange-Id: I33dc14085ca0c887778c7379f0498714e8d30425\n'}]",0,134529,b9c57efbc7f6f9e6d5ac24e78ac6c02d5576eb67,21,9,2,6450,,,0,"Remove unused network_api.get_instance_uuids_by_ip_filter()

Last usage was removed in ae781ee97947c33d6d43e4c21df4f338c875bf1c

Change-Id: I33dc14085ca0c887778c7379f0498714e8d30425
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/134529/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py', 'nova/network/rpcapi.py', 'nova/network/api.py', 'nova/network/base_api.py', 'nova/tests/unit/network/test_rpcapi.py']",6,f0a424f17301228b79a6718e9247aeadbea8badf,remove-unused-network-api-calls,," def test_get_instance_uuids_by_ip_filter(self): self._test_network_api('get_instance_uuids_by_ip_filter', rpc_method='call', filters={}) ",1,44
openstack%2Fhorizon~master~I7cee747413c6484e8af5377a049b4956f6d9f5cf,openstack/horizon,master,I7cee747413c6484e8af5377a049b4956f6d9f5cf,Expose Image owner info in the image table,ABANDONED,2014-12-18 05:54:02.000000000,2014-12-18 07:14:24.000000000,,"[{'_account_id': 6610}, {'_account_id': 11599}]","[{'number': 1, 'created': '2014-12-18 05:54:02.000000000', 'files': ['openstack_dashboard/dashboards/project/images/images/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/125851fe3ea0e139f54e1004a3ffb1acd2a14b22', 'message': 'Expose Image owner info in the image table\n\nCurrently Image table does not show the owner information,\nCode has been implemented which will add a new column in the\nImage table to display the owner information.\n\nimplements bp expose-image-owner-info\n\nChange-Id: I7cee747413c6484e8af5377a049b4956f6d9f5cf\n'}]",0,142672,125851fe3ea0e139f54e1004a3ffb1acd2a14b22,4,2,1,14005,,,0,"Expose Image owner info in the image table

Currently Image table does not show the owner information,
Code has been implemented which will add a new column in the
Image table to display the owner information.

implements bp expose-image-owner-info

Change-Id: I7cee747413c6484e8af5377a049b4956f6d9f5cf
",git fetch https://review.opendev.org/openstack/horizon refs/changes/72/142672/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/images/images/tables.py'],1,125851fe3ea0e139f54e1004a3ffb1acd2a14b22,bp/expose-image-owner-info," return getattr(image, ""owner"", """")"," owner = getattr(image, ""owner"", """") return owner",1,2
openstack%2Fcongress~master~I9bf646b58595f05107f2e2e90a8505bf17c6c23d,openstack/congress,master,I9bf646b58595f05107f2e2e90a8505bf17c6c23d,Enable: F812 list comprehension redefines name from line,ABANDONED,2014-12-06 15:13:52.000000000,2014-12-18 07:12:34.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-06 15:13:52.000000000', 'files': ['tox.ini', 'congress/policy/runtime.py', 'congress/api/schema_model.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/be937d0627e8aa2f430bd68e959af8e5b7e464f1', 'message': 'Enable: F812 list comprehension redefines name from line\n\nChange-Id: I9bf646b58595f05107f2e2e90a8505bf17c6c23d\nCloses-Bug: #1398549\n'}]",0,139808,be937d0627e8aa2f430bd68e959af8e5b7e464f1,8,4,1,12256,,,0,"Enable: F812 list comprehension redefines name from line

Change-Id: I9bf646b58595f05107f2e2e90a8505bf17c6c23d
Closes-Bug: #1398549
",git fetch https://review.opendev.org/openstack/congress refs/changes/08/139808/1 && git format-patch -1 --stdout FETCH_HEAD,"['tox.ini', 'congress/api/schema_model.py', 'congress/policy/runtime.py']",3,be937d0627e8aa2f430bd68e959af8e5b7e464f1,bug/1398549," to_add = [Event(f) for f in to_add] to_rem = [Event(f, insert=False) for f in to_rem]"," to_add = [Event(formula) for formula in to_add] to_rem = [Event(formula, insert=False) for formula in to_rem]",4,5
openstack%2Fcongress~master~I7734da4720966c5065c212728fe8568bdefced91,openstack/congress,master,I7734da4720966c5065c212728fe8568bdefced91,Enable: F402 import module shadowed by loop variable,MERGED,2014-12-06 14:26:55.000000000,2014-12-18 07:04:31.000000000,2014-12-18 07:04:31.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-06 14:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/3938fe629fd6040c05fdac870152d0d2aeb08892', 'message': 'Enable: F402 import module shadowed by loop variable\n\nChange-Id: I7734da4720966c5065c212728fe8568bdefced91\nCloses-Bug: #1398547\n'}, {'number': 2, 'created': '2014-12-18 06:08:22.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/congress/commit/237034e76bfa361ee398e641289852866f216cd4', 'message': 'Enable: F402 import module shadowed by loop variable\n\nChange-Id: I7734da4720966c5065c212728fe8568bdefced91\nCloses-Bug: #1398547\n'}]",0,139802,237034e76bfa361ee398e641289852866f216cd4,12,4,2,12256,,,0,"Enable: F402 import module shadowed by loop variable

Change-Id: I7734da4720966c5065c212728fe8568bdefced91
Closes-Bug: #1398547
",git fetch https://review.opendev.org/openstack/congress refs/changes/02/139802/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,3938fe629fd6040c05fdac870152d0d2aeb08892,bug/1398547,"ignore = E128,E129,E251,F811,F812,H237,H305,H401,H404,H405,H904,H231,E122,H302","# F402 import module shadowed by loop variableignore = E128,E129,E251,F402,F811,F812,H237,H305,H401,H404,H405,H904,H231,E122,H302",1,2
openstack%2Fopenstack-manuals~master~Id1ea4ab1c1c6df0399e4da7158a2c5accbe71c0f,openstack/openstack-manuals,master,Id1ea4ab1c1c6df0399e4da7158a2c5accbe71c0f,Imported Translations from Transifex,MERGED,2014-12-18 06:13:30.000000000,2014-12-18 07:02:08.000000000,2014-12-18 07:02:06.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-18 06:13:30.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/install-guide/locale/pt_BR.po', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/install-guide/locale/ja.po', 'doc/cli-reference/locale/cli-reference.pot'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/87f62ae60262e206ea41793715c5fbb60ba0db7e', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Id1ea4ab1c1c6df0399e4da7158a2c5accbe71c0f\n'}]",0,142680,87f62ae60262e206ea41793715c5fbb60ba0db7e,10,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Id1ea4ab1c1c6df0399e4da7158a2c5accbe71c0f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/80/142680/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/install-guide/locale/pt_BR.po', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/install-guide/locale/ja.po', 'doc/cli-reference/locale/cli-reference.pot']",5,87f62ae60262e206ea41793715c5fbb60ba0db7e,transifex/translations,"""POT-Creation-Date: 2014-12-18 06:12+0000\n""#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:295(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:379(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:376(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:384(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:393(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:399(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:408(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:416(td)msgid ""lsiLogicsas"" msgstr """" #: ./doc/cli-reference/ch_cli_glance_property_keys.xml:380(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:381(literal) msgid ""paraVirtual""msgid ""vmware_ostype"" msgstr """" #: ./doc/cli-reference/ch_cli_glance_property_keys.xml:388(literal) msgid ""otherGuest"" msgstr """" #: ./doc/cli-reference/ch_cli_glance_property_keys.xml:386(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:390(link)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:389(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:427(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:394(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:395(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:396(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:400(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:401(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:405(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:413(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:409(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:410(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:417(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:422(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:418(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:429(link)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:432(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:443(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:433(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:438(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:438(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:434(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:440(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:444(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:447(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:448(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:445(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:451(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:451(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:451(td)","""POT-Creation-Date: 2014-12-17 06:11+0000\n""#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:295(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:376(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:383(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:392(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:398(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:407(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:415(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:379(td) msgid ""<placeholder-1/>, <placeholder-2/>, or <placeholder-3/>"" msgstr """" #: ./doc/cli-reference/ch_cli_glance_property_keys.xml:384(td) msgid ""vmware_ostype"" msgstr """" #: ./doc/cli-reference/ch_cli_glance_property_keys.xml:387(literal) msgid ""otherGuest""#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:389(link)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:388(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:426(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:393(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:394(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:395(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:399(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:400(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:404(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:412(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:408(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:409(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:416(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:421(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:417(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:428(link)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:431(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:442(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:432(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:437(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:437(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:433(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:439(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:443(td) ./doc/cli-reference/ch_cli_glance_property_keys.xml:446(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:447(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:444(td)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:450(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:450(literal)#: ./doc/cli-reference/ch_cli_glance_property_keys.xml:450(td)",220,166
openstack%2Fmistral~master~I5c023573f0950cb599a99d0bd48dba95f3c8dc40,openstack/mistral,master,I5c023573f0950cb599a99d0bd48dba95f3c8dc40,Fixing for-each,MERGED,2014-12-15 14:11:59.000000000,2014-12-18 06:43:29.000000000,2014-12-18 06:43:26.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-12-15 14:11:59.000000000', 'files': ['mistral/engine1/commands.py', 'mistral/tests/unit/workflow/test_for_each.py', 'mistral/workflow/for_each.py', 'mistral/workflow/base.py', 'mistral/utils/for_each_utils.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/bfe87db3d5b3a6eeee8659c8f64d05456fd8cd42', 'message': 'Fixing for-each\n\n * Fixing for-each according to comments in https://review.openstack.org/#/c/140327/\n * Normalizing for-each output\n * Better index checking\n * Move for_each module to mistral/workflows/\n * Unit tests on for_each module\n\nPartially implements mistral-dataflow-collections\n\nChange-Id: I5c023573f0950cb599a99d0bd48dba95f3c8dc40\n'}]",3,141806,bfe87db3d5b3a6eeee8659c8f64d05456fd8cd42,8,5,1,7700,,,0,"Fixing for-each

 * Fixing for-each according to comments in https://review.openstack.org/#/c/140327/
 * Normalizing for-each output
 * Better index checking
 * Move for_each module to mistral/workflows/
 * Unit tests on for_each module

Partially implements mistral-dataflow-collections

Change-Id: I5c023573f0950cb599a99d0bd48dba95f3c8dc40
",git fetch https://review.opendev.org/openstack/mistral refs/changes/06/141806/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine1/commands.py', 'mistral/tests/unit/workflow/test_for_each.py', 'mistral/workflow/for_each.py', 'mistral/workflow/base.py', 'mistral/utils/for_each_utils.py']",5,bfe87db3d5b3a6eeee8659c8f64d05456fd8cd42,,,"# Copyright 2014 - Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import copy from mistral import expressions as expr def get_for_each_output(task_db, task_spec, raw_result): t_name = task_db.name # Calc output for for-each (only list form is used). out_key = (task_spec.get_publish().keys()[0] if task_spec.get_publish() else None) # TODO(nmakhotkin): Simplify calculating task output. e_data = raw_result.error output = expr.evaluate_recursively( task_spec.get_publish(), raw_result.data or {} ) if not task_db.output: task_db.output = {} task_output = copy.copy(task_db.output) if out_key: if out_key in task_output: task_output[out_key].append( output.get(out_key) or e_data ) else: task_output[out_key] = [output.get(out_key) or e_data] # Add same result to task output under key 'task'. task_output['task'] = { t_name: task_output[out_key] } else: if 'task' not in task_output: task_output.update({'task': {t_name: [output or e_data]}}) else: task_output['task'][t_name].append(output or e_data) return task_output def calc_for_each_input(action_input): # In case of for-each iterate over action_input and send # each part of data to executor. # Calculate action input collection for separating input. action_input_collection = [] for key, value in action_input.items(): for index, item in enumerate(value): iter_context = {key: item} if index >= len(action_input_collection): action_input_collection.append(iter_context) else: action_input_collection[index].update(iter_context) return action_input_collection",229,88
openstack%2Foperations-guide~master~I75c6fed50ee91055a3f38915f8633ac06aac75da,openstack/operations-guide,master,I75c6fed50ee91055a3f38915f8633ac06aac75da,Imported Translations from Transifex,MERGED,2014-12-18 06:01:05.000000000,2014-12-18 06:32:54.000000000,2014-12-18 06:32:53.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-18 06:01:05.000000000', 'files': ['doc/openstack-ops/locale/openstack-ops.pot', 'doc/openstack-ops/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/cf9d1fbc8730c629211d9c32107ee16f1c758535', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I75c6fed50ee91055a3f38915f8633ac06aac75da\n'}]",0,142675,cf9d1fbc8730c629211d9c32107ee16f1c758535,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I75c6fed50ee91055a3f38915f8633ac06aac75da
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/75/142675/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/openstack-ops/locale/openstack-ops.pot', 'doc/openstack-ops/locale/ja.po']",2,cf9d1fbc8730c629211d9c32107ee16f1c758535,transifex/translations,"""POT-Creation-Date: 2014-12-18 01:41+0000\n"" ""PO-Revision-Date: 2014-12-17 23:31+0000\n""#: ./doc/openstack-ops/ch_ops_upgrades.xml1566(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1575(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1135(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1583(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1584(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1146(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1593(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1151(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1596(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1166(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1609(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1192(para)""should continue to operate normally. However, instances might experience ""#: ./doc/openstack-ops/ch_ops_upgrades.xml1093(para)""Review the <link """"Release Notes</link> before you upgrade to learn about new features that you"" "" might want to enable and deprecated features that you should disable.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1100(para)""Consider adopting conventions associated with newer configuration files and "" ""merging them with your existing configuration files after completing the "" ""upgrade process.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1105(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1109(para)"" all compute nodes that remain on Havana. This is done by editing the "" ""<filename>/etc/nova/nova-compute.conf</filename> file:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1118(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1129(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1138(para) msgid ""Save the configuration files on all nodes:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1154(para) msgid """" ""Although not necessary, you should consider updating your MySQL server "" ""configuration as described in the <link "" ""href=\""http://docs.openstack.org/icehouse/install-guide/install/apt/content"" ""/basics-database-controller.html\"">MySQL controller setup</link> section of "" ""the <link href=\""http://docs.openstack.org/icehouse/install-"" ""guide/install/apt/content/\""><citetitle>OpenStack Installation "" ""Guide</citetitle></link>."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1168(para) msgid ""Complete the following actions on all nodes."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1170(para) msgid ""Remove the repository for Havana packages:""msgid ""Add the repository for Icehouse packages:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1178(para)""Disable any <link href=\""https://help.ubuntu.com/12.04/serverguide"" ""/automatic-updates.html\"">automatic package updates</link>.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1185(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1662(title) msgid ""Upgrade the Controller Node"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1188(para) msgid ""Upgrade packages on the controller node to Icehouse:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1202(para) msgid """" ""When the package manager prompts you to update various configuration files, "" ""reject the changes. The package manager appends <filename>.dpkg-"" ""dist</filename> to newer versions of the configuration files. To find newer "" ""versions of configuration files, enter the following command:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1212(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1678(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1213(para)""The upgrade procedure for each service generally requires that you stop the """"database, and start the service to apply the new configuration. You will "" ""need administrator privileges to perform these procedures. Some services "" ""will require additional steps.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1220(title) msgid ""Upgrade OpenStack Identity""#: ./doc/openstack-ops/ch_ops_upgrades.xml1222(para) msgid """" ""Edit the <filename>/etc/keystone/keystone.conf</filename> file for "" ""compatibility for Icehouse:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1225(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1269(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1693(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1731(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1226(para)""Move the <option>connection</option> key from the<literal>[sql]</literal> ""#: ./doc/openstack-ops/ch_ops_upgrades.xml1231(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1289(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1313(para) msgid ""Stop the services:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1234(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1321(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1395(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1442(para) msgid ""Upgrade the database:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1238(para) msgid ""Start the services.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1243(title) msgid ""Upgrade OpenStack Image Service"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1244(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1246(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1337(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1788(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1259(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1265(para)""<filename>/etc/glance/glance-registry.conf</filename> files for "" ""compatibility with Icehouse:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1271(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1732(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1277(para)""In the <filename>/etc/glance/glance-api.conf</filename> file, add RabbitMQ "" ""message broker keys to the <literal>[DEFAULT]</literal> section.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1283(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1419(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1423(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1743(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1874(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1878(replaceable) msgid ""controller"" msgstr ""controller"" #: ./doc/openstack-ops/ch_ops_upgrades.xml1284(replaceable) msgid ""RABBIT_PASS"" msgstr ""RABBIT_PASS"" #: ./doc/openstack-ops/ch_ops_upgrades.xml1285(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1296(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1324(para) msgid ""Start the services:"" msgstr ""サービスを起動します。"" #: ./doc/openstack-ops/ch_ops_upgrades.xml1302(title) msgid ""Upgrading OpenStack Compute""#: ./doc/openstack-ops/ch_ops_upgrades.xml1303(para)""Edit the <filename>/etc/nova/nova.conf</filename> file and change the "" ""<option>rpc_backend</option> key from <literal>nova.rpc.impl_kombu</literal>"" "" to <literal>rabbit</literal>.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1307(para)""Edit the <filename>/etc/nova/api-paste.ini</filename> file and comment out "" ""or remove any keys in the <literal>[filter:authtoken]</literal> section "" ""beneath the <literal>paste.filter_factory = ""#: ./doc/openstack-ops/ch_ops_upgrades.xml1334(title) msgid ""Upgrade OpenStack Networking""#: ./doc/openstack-ops/ch_ops_upgrades.xml1335(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1786(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1374(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1825(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1380(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1481(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1513(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1929(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1960(para)"" with the equivalent configuration for your environment.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1383(para)""Do not edit the <filename>/etc/neutron/neutron.conf</filename> file until "" ""after the conversion steps.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1388(para) msgid """" ""Because the conversion script cannot roll back, you must perform a database "" ""backup prior to executing the following commands."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1392(para) msgid ""Stop the service:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1401(para) msgid ""Perform the conversion from OVS to ML2:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1404(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1844(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1408(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1858(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1421(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1876(replaceable) msgid ""SERVICE_TENANT_ID"" msgstr ""SERVICE_TENANT_ID"" #: ./doc/openstack-ops/ch_ops_upgrades.xml1422(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1877(replaceable) msgid ""NOVA_PASS"" msgstr ""NOVA_PASS"" #: ./doc/openstack-ops/ch_ops_upgrades.xml1425(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1862(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1431(para) msgid ""Start Networking services:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1436(title) msgid ""Upgrade OpenStack Block Storage""#: ./doc/openstack-ops/ch_ops_upgrades.xml1437(para) msgid ""Stop services:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1445(para) msgid ""Start services:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1452(title) msgid ""Update Dashboard"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1453(para)""file, and change the <option>OPENSTACK_KEYSTONE_DEFAULT_ROLE</option> key "" ""from <literal>\""Member\""</literal> to <literal>\""_member_\""</literal>.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1458(para) msgid ""Restart Dashboard services:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1464(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1914(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1466(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1915(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1468(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1500(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1533(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1917(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1948(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1978(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1475(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1507(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1924(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1955(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1484(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1517(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1936(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1967(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1487(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1520(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1938(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1969(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1496(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1945(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1498(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1946(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1523(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1971(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1529(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1975(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1531(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1976(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1540(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1983(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1548(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1551(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1567(para) msgid """" ""The upgrade process interrupts management of your environment, including the"" "" dashboard. If you properly prepare for this upgrade, tenant instances "" ""continue to operate normally. However, instances might experience "" ""intermittent network interruptions while the Networking service rebuilds "" ""virtual networking infrastructure."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1576(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1599(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1610(para) msgid """" ""On all nodes, remove the repository for Havana packages and add the "" ""repository for Icehouse packages:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1616(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1619(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1625(title) msgid ""Upgrade Notes"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1628(para) msgid ""Disable Compute file injection:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1629(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1633(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1636(para) msgid ""Edit the <filename>/etc/nova/nova-compute.conf</filename> file:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1644(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1645(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1656(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1663(para) msgid ""Upgrade packages on the controller node to Icehouse, as follows:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1667(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1679(para) msgid """" ""The upgrade procedure for each service typically requires that you stop the "" ""service, run the database synchronization command to update the associated "" ""database, and start the service to apply the new configuration. You need "" ""administrator privileges for these procedures. Some services require "" ""additional steps."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1687(para) msgid ""OpenStack Identity:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1688(para) msgid ""Update the configuration file for compatibility with Icehouse."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1690(para) msgid ""Edit the <filename>/etc/keystone/keystone.conf</filename> file:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1694(para) msgid """" ""Move the <option>connection</option> key from the <literal>[sql]</literal> "" ""section to the <literal>[database]</literal> section."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1697(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1768(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1885(para) msgid ""Stop services, upgrade the database, and start services."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1705(para) msgid ""OpenStack Image Service:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1706(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1708(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1721(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1725(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1754(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1897(para) msgid ""Update the configuration for compatibility with Icehouse."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1727(para) msgid """" ""Edit the <filename>/etc/glance/glance-api.conf</filename> and "" ""<filename>/etc/glance/glance-registry.conf</filename> files:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1735(para) msgid ""Edit the <filename>/etc/glance/glance-api.conf</filename> file:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1738(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1744(para) msgid ""Stop services, upgrade the database, and start services:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1753(para) msgid ""OpenStack Compute:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1756(para) msgid ""Edit the <filename>/etc/nova/nova.conf</filename> file:"" msgstr ""<filename>/etc/nova/nova.conf</filename> ファイルを編集します。"" #: ./doc/openstack-ops/ch_ops_upgrades.xml1758(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1761(para) msgid ""Edit the <filename>/etc/nova/api-paste.ini</filename> file:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1763(para) msgid """" ""Comment out or remove any keys in the <literal>[filter:authtoken]</literal> "" ""section beneath the <literal>paste.filter_factory = "" ""keystoneclient.middleware.auth_token:filter_factory</literal> statement."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1785(para) msgid ""OpenStack Networking:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1830(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1922(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1953(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1832(para) msgid """" ""Populate the <filename>/etc/neutron/plugins/ml2/ml2_conf.ini</filename> file"" "" with the equivalent configuration for your environment. Do not edit the "" ""<filename>/etc/neutron/neutron.conf</filename> file until after the "" ""conversion steps."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1838(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1933(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1964(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1842(para) msgid """" ""Stop services, upgrade the database, and perform the conversion from OVS to "" ""ML2."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1847(para) msgid """" ""We highly recommend that you perform a database backup prior to executing "" ""the following commands as the conversion script cannot roll back."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1880(para) msgid ""Start Networking services."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1884(para) msgid ""OpenStack Block Storage:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1896(para) msgid ""Dashboard:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1899(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1902(para) msgid """" ""Change the <option>OPENSTACK_KEYSTONE_DEFAULT_ROLE</option> key from "" ""<literal>\""Member\""</literal> to <literal>\""_member_\""</literal>."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1906(para) msgid ""Restart Dashboard services."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1910(para) msgid """" ""The controller node update is complete. Now you can upgrade the remaining "" ""nodes."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1988(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1990(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1996(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2000(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2004(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2013(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2018(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml2020(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2032(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2041(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2046(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2050(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2054(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2058(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2070(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2075(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml2078(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2082(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2089(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2096(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2108(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2111(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2118(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2166(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2173(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2204(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2256(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2263(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2272(para)","""POT-Creation-Date: 2014-12-01 21:48+0000\n"" ""PO-Revision-Date: 2014-12-01 21:48+0000\n""#: ./doc/openstack-ops/ch_ops_upgrades.xml1519(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1528(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1098(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1536(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1537(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1107(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1546(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1110(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1549(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1123(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1562(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1179(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1520(para)""continue to operate normally. However, instances might experience ""#: ./doc/openstack-ops/ch_ops_upgrades.xml1091(para)""Always review the <link """"Release Notes</link> before you upgrade to learn about newly available "" ""features that you might want to enable and deprecated features that you "" ""should disable.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1099(para) msgid ""Save the configuration files on all nodes:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1113(para)""Although not necessary, you should consider updating your MySQL server "" ""configuration as described in the <link "" ""href=\""http://docs.openstack.org/icehouse/install-guide/install/apt/content"" ""/basics-database-controller.html\"">MySQL controller setup</link> section of "" ""the <link href=\""http://docs.openstack.org/icehouse/install-"" ""guide/install/apt/content/\""><citetitle>OpenStack Installation "" ""Guide</citetitle></link>.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1124(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1563(para) msgid """" ""On all nodes, remove the repository for Havana packages and add the "" ""repository for Icehouse packages:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1129(para) msgid """" ""Disable any <link href=\""https://help.ubuntu.com/12.04/serverguide"" ""/automatic-updates.html\"">automatic package updates</link>."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1135(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1578(title) msgid ""Upgrade Notes"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1138(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1581(para) msgid ""Disable Compute file injection:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1139(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1143(para)"" all compute nodes that remain on Havana.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1146(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1589(para) msgid ""Edit the <filename>/etc/nova/nova-compute.conf</filename> file:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1154(para) msgid ""Convert from the OVS plug-in to the ML2 plug-in:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1156(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1167(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1173(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1615(title) msgid ""Upgrade the Controller Node""#: ./doc/openstack-ops/ch_ops_upgrades.xml1616(para) msgid ""Upgrade packages on the controller node to Icehouse, as follows:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1187(para)""The package manager prompts you to update various configuration files. "" ""Reject these changes. The package manager appends <filename>.dpkg-"" ""dist</filename> to the newer versions of existing configuration files. You "" ""should consider adopting conventions associated with the newer configuration"" "" files and merging them with your existing configuration files after "" ""completing the upgrade process. You can find newer versions of existing "" ""configuration files with the following command:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1199(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1631(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1200(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1632(para)""The upgrade procedure for each service typically requires that you stop the """"database, and start the service to apply the new configuration. You need "" ""administrator privileges for these procedures. Some services require "" ""additional steps.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1208(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1640(para) msgid ""OpenStack Identity:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1209(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1641(para) msgid ""Update the configuration file for compatibility with Icehouse.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1211(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1643(para) msgid ""Edit the <filename>/etc/keystone/keystone.conf</filename> file:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1214(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1252(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1646(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1684(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1215(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1647(para)""Move the <option>connection</option> key from the <literal>[sql]</literal> ""#: ./doc/openstack-ops/ch_ops_upgrades.xml1218(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1404(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1650(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1721(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1838(para) msgid ""Stop services, upgrade the database, and start services.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1226(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1658(para) msgid ""OpenStack Image Service:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1227(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1229(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1313(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1741(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1242(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1246(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1279(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1416(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1678(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1707(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1850(para) msgid ""Update the configuration for compatibility with Icehouse."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1248(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1680(para)""<filename>/etc/glance/glance-registry.conf</filename> files:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1253(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1685(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1256(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1688(para) msgid ""Edit the <filename>/etc/glance/glance-api.conf</filename> file:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1259(para)""Add RabbitMQ message broker keys to the <literal>[DEFAULT]</literal> "" ""section.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1261(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1267(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1393(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1397(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1696(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1827(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1831(replaceable) msgid ""controller"" msgstr ""controller"" #: ./doc/openstack-ops/ch_ops_upgrades.xml1268(replaceable) msgid ""RABBIT_PASS"" msgstr ""RABBIT_PASS"" #: ./doc/openstack-ops/ch_ops_upgrades.xml1269(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1697(para) msgid ""Stop services, upgrade the database, and start services:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1278(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1706(para) msgid ""OpenStack Compute:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1281(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1709(para) msgid ""Edit the <filename>/etc/nova/nova.conf</filename> file:"" msgstr ""<filename>/etc/nova/nova.conf</filename> ファイルを編集します。"" #: ./doc/openstack-ops/ch_ops_upgrades.xml1283(para)""Change the <option>rpc_backend</option> key from "" ""<literal>nova.rpc.impl_kombu</literal> to <literal>rabbit</literal>.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1286(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1714(para) msgid ""Edit the <filename>/etc/nova/api-paste.ini</filename> file:"" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1288(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1716(para)""Comment out or remove any keys in the <literal>[filter:authtoken]</literal> "" ""section beneath the <literal>paste.filter_factory = ""#: ./doc/openstack-ops/ch_ops_upgrades.xml1310(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1738(para) msgid ""OpenStack Networking:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1311(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1739(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1350(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1778(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1355(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1785(para)"" with the equivalent configuration for your environment. Do not edit the "" ""<filename>/etc/neutron/neutron.conf</filename> file until after the "" ""conversion steps.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1361(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1795(para)""Stop services, upgrade the database, and perform the conversion from OVS to "" ""ML2.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1363(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1797(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1366(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1800(para) msgid """" ""We highly recommend that you perform a database backup prior to executing "" ""the following commands as the conversion script cannot roll back."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1377(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1811(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1381(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1815(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1395(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1829(replaceable) msgid ""SERVICE_TENANT_ID"" msgstr ""SERVICE_TENANT_ID"" #: ./doc/openstack-ops/ch_ops_upgrades.xml1396(replaceable) #: ./doc/openstack-ops/ch_ops_upgrades.xml1830(replaceable) msgid ""NOVA_PASS"" msgstr ""NOVA_PASS"" #: ./doc/openstack-ops/ch_ops_upgrades.xml1399(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1833(para) msgid ""Start Networking services.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1403(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1837(para) msgid ""OpenStack Block Storage:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1415(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1849(para) msgid ""Dashboard:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1418(para)""file:""#: ./doc/openstack-ops/ch_ops_upgrades.xml1421(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1855(para) msgid """" ""Change the <option>OPENSTACK_KEYSTONE_DEFAULT_ROLE</option> key from "" ""<literal>\""Member\""</literal> to <literal>\""_member_\""</literal>.""#: ./doc/openstack-ops/ch_ops_upgrades.xml1425(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1859(para) msgid ""Restart Dashboard services."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1429(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1863(para) msgid """" ""The controller node update is complete. Now you can upgrade the remaining "" ""nodes."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1433(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1867(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1434(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1868(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1436(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1463(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1489(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1870(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1901(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1931(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1442(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1469(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1877(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1908(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1447(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1474(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1882(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1913(para) msgid """" ""Populate the <filename>/etc/neutron/plugins/ml2/ml2_conf.ini</filename> file"" "" with the equivalent configuration for your environment."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml1451(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1478(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1889(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1920(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1453(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1480(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1891(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1922(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1460(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1898(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1461(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1899(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1482(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1924(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1486(title) #: ./doc/openstack-ops/ch_ops_upgrades.xml1928(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1487(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1929(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1495(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1936(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1501(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1504(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1529(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1552(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1569(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1572(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1582(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1586(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1597(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1598(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1609(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1620(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1659(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1661(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1674(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1691(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1711(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1783(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1875(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1906(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1791(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1886(para) #: ./doc/openstack-ops/ch_ops_upgrades.xml1917(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1852(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1941(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1943(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1949(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1953(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1957(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1966(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1971(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml1973(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1985(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1994(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml1999(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2003(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2007(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2011(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2023(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2028(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml2031(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2035(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2042(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2049(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2061(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2064(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2071(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2119(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2126(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2157(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2209(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2216(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml2225(para)",815,591
openstack%2Fhorizon~stable%2Fjuno~I6f745f7f95272eb87b6d867d76d7726c7eb5bb24,openstack/horizon,stable/juno,I6f745f7f95272eb87b6d867d76d7726c7eb5bb24,Fix popup error when volume service disabled,MERGED,2014-12-09 09:24:47.000000000,2014-12-18 06:32:10.000000000,2014-12-18 06:32:08.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 2455}, {'_account_id': 4264}, {'_account_id': 4428}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6635}, {'_account_id': 6914}, {'_account_id': 7244}, {'_account_id': 9317}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-12-09 09:24:47.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/workflows/create_instance.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/962a0a7c9fc252f5e41595f82ee96cc9bcee3d68', 'message': ""Fix popup error when volume service disabled\n\nIn an enviroment, where cinder is disabled, I'm getting error popups\nwhen trying to 'launch instance':\nError: Unable to retrieve list of volumes.\nError: Unable to retrieve list of volume snapshots.\nSo we need to make sure whether the volume service exists when\ncalling the cinder api in the launch instance workflow.\n\nCloses-bug: #1394900\n\nConflicts:\n\topenstack_dashboard/dashboards/project/instances/workflows/create_instance.py\n\nChange-Id: I6f745f7f95272eb87b6d867d76d7726c7eb5bb24\n(cherry picked from commit 6a7b95ad8e33a01f55ae857ca5a0fad496dde4da)\n""}]",2,140280,962a0a7c9fc252f5e41595f82ee96cc9bcee3d68,24,12,1,4264,,,0,"Fix popup error when volume service disabled

In an enviroment, where cinder is disabled, I'm getting error popups
when trying to 'launch instance':
Error: Unable to retrieve list of volumes.
Error: Unable to retrieve list of volume snapshots.
So we need to make sure whether the volume service exists when
calling the cinder api in the launch instance workflow.

Closes-bug: #1394900

Conflicts:
	openstack_dashboard/dashboards/project/instances/workflows/create_instance.py

Change-Id: I6f745f7f95272eb87b6d867d76d7726c7eb5bb24
(cherry picked from commit 6a7b95ad8e33a01f55ae857ca5a0fad496dde4da)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/80/140280/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/workflows/create_instance.py'],1,962a0a7c9fc252f5e41595f82ee96cc9bcee3d68,bug/1394900," volumes = [] try: if base.is_service_enabled(request, 'volume'): volumes = [self._get_volume_display_name(v) for v in cinder.volume_list(self.request) if (v.status == api.cinder.VOLUME_STATE_AVAILABLE and v.bootable == 'true')] except Exception: snapshots = [] try: if base.is_service_enabled(request, 'volume'): snaps = cinder.volume_snapshot_list(self.request) snapshots = [self._get_volume_display_name(s) for s in snaps if s.status == api.cinder.VOLUME_STATE_AVAILABLE] except Exception:", try: volumes = [self._get_volume_display_name(v) for v in cinder.volume_list(self.request) if v.status == api.cinder.VOLUME_STATE_AVAILABLE and v.bootable == 'true'] except Exception: volumes = [] try: snapshots = cinder.volume_snapshot_list(self.request) snapshots = [self._get_volume_display_name(s) for s in snapshots if s.status == api.cinder.VOLUME_STATE_AVAILABLE] except Exception: snapshots = [],11,9
openstack%2Ftricircle~master~I3fc12173c9bb988775494a556327b9893bcdbc36,openstack/tricircle,master,I3fc12173c9bb988775494a556327b9893bcdbc36,rollback update_available_resource,MERGED,2014-12-18 06:07:21.000000000,2014-12-18 06:08:26.000000000,2014-12-18 06:08:26.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-12-18 06:07:21.000000000', 'files': ['novaproxy/nova/compute/manager_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/82e81414b32fca44484ce857627bed6b29345a5f', 'message': 'rollback update_available_resource\n\nthe update_available_resource aims to notify the compute hosts info\nto db.\n\nChange-Id: I3fc12173c9bb988775494a556327b9893bcdbc36\n'}]",0,142678,82e81414b32fca44484ce857627bed6b29345a5f,6,2,1,9684,,,0,"rollback update_available_resource

the update_available_resource aims to notify the compute hosts info
to db.

Change-Id: I3fc12173c9bb988775494a556327b9893bcdbc36
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/78/142678/1 && git format-patch -1 --stdout FETCH_HEAD,['novaproxy/nova/compute/manager_proxy.py'],1,82e81414b32fca44484ce857627bed6b29345a5f,," self.update_available_resource(nova.context.get_admin_context()) @periodic_task.periodic_task new_resource_tracker_dict = {} nodenames = set(self.driver.get_available_nodes()) for nodename in nodenames: rt = self._get_resource_tracker(nodename) rt.update_available_resource(context) new_resource_tracker_dict[nodename] = rt # Delete orphan compute node not reported by driver but still in db compute_nodes_in_db = self._get_compute_nodes_in_db(context, use_slave=True) for cn in compute_nodes_in_db: if cn.hypervisor_hostname not in nodenames: LOG.audit(_(""Deleting orphan compute node %s"") % cn.id) cn.destroy() self._resource_tracker_dict = new_resource_tracker_dict"," # self.update_available_resource(nova.context.get_admin_context()) #periodic_task.periodic_task # new_resource_tracker_dict = {} # nodenames = set(self.driver.get_available_nodes()) # for nodename in nodenames: # rt = self._get_resource_tracker(nodename) # rt.update_available_resource(context) # new_resource_tracker_dict[nodename] = rt # # Delete orphan compute node not reported by driver but still in db # compute_nodes_in_db = self._get_compute_nodes_in_db(context, # use_slave=True) # # for cn in compute_nodes_in_db: # if cn.hypervisor_hostname not in nodenames: # LOG.audit(_(""Deleting orphan compute node %s"") % cn.id) # cn.destroy() # # self._resource_tracker_dict = new_resource_tracker_dict",16,18
openstack%2Fnova~master~I0eb10dae71ac22ea7c24771dfb525cd0d9eb3698,openstack/nova,master,I0eb10dae71ac22ea7c24771dfb525cd0d9eb3698,Add missing oslo libraries to generate nova.conf.sample,ABANDONED,2014-12-06 06:30:37.000000000,2014-12-18 05:46:13.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-06 06:30:37.000000000', 'files': ['tools/config/oslo.config.generator.rc'], 'web_link': 'https://opendev.org/openstack/nova/commit/086c0ae31da09ec721b11d37dc54687a54cf921c', 'message': ""Add missing oslo libraries to generate nova.conf.sample\n\nCurrent generate_sample.sh can't generate config options for oslo.db\nand oslo.concurrency, this commit fixes it.\n\nChange-Id: I0eb10dae71ac22ea7c24771dfb525cd0d9eb3698\n""}]",0,139787,086c0ae31da09ec721b11d37dc54687a54cf921c,9,6,1,9796,,,0,"Add missing oslo libraries to generate nova.conf.sample

Current generate_sample.sh can't generate config options for oslo.db
and oslo.concurrency, this commit fixes it.

Change-Id: I0eb10dae71ac22ea7c24771dfb525cd0d9eb3698
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/139787/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/config/oslo.config.generator.rc'],1,086c0ae31da09ec721b11d37dc54687a54cf921c,add_config,"NOVA_CONFIG_GENERATOR_EXTRA_LIBRARIES=""oslo.concurrency oslo.messaging oslo.db""",NOVA_CONFIG_GENERATOR_EXTRA_LIBRARIES=oslo.messaging,1,1
openstack%2Fpython-cinderclient~master~Ibcc182800dac94b4c2fb629070a0bc158b057408,openstack/python-cinderclient,master,Ibcc182800dac94b4c2fb629070a0bc158b057408,Fixed several typos,ABANDONED,2014-04-29 19:10:42.000000000,2014-12-18 05:29:40.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 170}, {'_account_id': 7680}, {'_account_id': 8871}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-04-29 19:10:42.000000000', 'files': ['cinderclient/tests/test_utils.py', 'doc/source/index.rst', 'cinderclient/v1/shell.py', 'cinderclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/c52796d4ea1e0bf2cafb9e9dcbf20e97f8fff050', 'message': 'Fixed several typos\n\nChange-Id: Ibcc182800dac94b4c2fb629070a0bc158b057408\n'}]",0,91138,c52796d4ea1e0bf2cafb9e9dcbf20e97f8fff050,18,6,1,7680,,,0,"Fixed several typos

Change-Id: Ibcc182800dac94b4c2fb629070a0bc158b057408
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/38/91138/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/tests/test_utils.py', 'doc/source/index.rst', 'cinderclient/v1/shell.py', 'cinderclient/v2/shell.py']",4,c52796d4ea1e0bf2cafb9e9dcbf20e97f8fff050,typo-fixes," msg = (""Unable to reset the state for any of the specified """," msg = (""Unable to reset the state for any of the the specified """,5,5
openstack%2Fneutron~master~I674c72e37b56aa1f729110310e6f697297c47c09,openstack/neutron,master,I674c72e37b56aa1f729110310e6f697297c47c09,L3 Agent restructure - observer hierarchy,MERGED,2014-11-22 02:18:54.000000000,2014-12-18 04:21:55.000000000,2014-12-18 04:21:53.000000000,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 2035}, {'_account_id': 2888}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 6995}, {'_account_id': 7021}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 8976}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10182}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 13380}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-11-22 02:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0793bd87a8191fe82d99964a093630d95f542950', 'message': 'L3 Agent restructure - observer hierarchy\n\nThis attempts to do two things. First, it creates an ABC class hierarchy for\nthe advanced services. These classes will be used to provide an ""observer""\nfor event notifications from the L3 agent. This way, the L3 events are\ndecoupled from the services that will perform actions upon them.\n\nSecond, it takes a slice through most of the startup process, to give a view\ninto where this is heading. It shows how a service (VPN) can be set up, load\nits device drivers, and respond to a notification from the L3 agent for an\nevent (_add_router).\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not \'improve/change\' functionality.\n- This is one step of a series of steps to move to the \'final\' restructuring.\n- Because we\'re incrementally changing the code, there are going to be some\n  temporary changes to allow existing code to continue to work.\n\nTODO:\n- Add unit tests for new methods created\n- Create concrete service observers for FWaaS, LBaaS, metadata proxy.\n\nThe next few steps are perceived to be:\n- Define the notification handlers in the observer base class.\n- Move handlers from the existing agents into concrete observer handlers.\n- Create a factory to instantiate the enabled services.\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n'}, {'number': 2, 'created': '2014-11-23 15:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c1e1a2bf500bc0bfe2e1a3183ba73936d765521d', 'message': ""L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced services,\nas part of a multi-step refactoring effort of the L3 agent. It performs\ntwo things. First, it loads the device drivers for a service. Second, it\nregisters the service with the L3 agent, so that the service can be\nnotified for various events.\n\nIn future refactorings, the notification mechanism will be fleshed out,\nand handlers defined and implemented (adapting from logic in the current\nagents).\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not 'improve/change' functionality.\n- This is one step of a series of steps to move to the 'final' restructuring.\n- Because we're incrementally changing the code, there may be temporary\n  changes to allow existing code to continue to work.\n\nTODO:\n- Add unit tests for new methods created\n- Create concrete service observers for FWaaS, LBaaS, metadata proxy.\n\nThe next few steps are perceived to be:\n- Define the notification handlers in the observer base class.\n- Move handlers from the existing agents into concrete observer handlers.\n- Create a factory to instantiate the enabled services.\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n""}, {'number': 3, 'created': '2014-11-24 18:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa804852d488f12b5d889e41989bbb3ca2e5766c', 'message': ""L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced services,\nas part of a multi-step refactoring effort of the L3 agent. It performs\ntwo things. First, it loads the device drivers for a service. Second, it\nregisters the service with the L3 agent, so that the service can be\nnotified for various events.\n\nIn future refactorings, the notification mechanism will be fleshed out,\nand handlers defined and implemented (adapting from logic in the current\nagents).\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not 'improve/change' functionality.\n- This is one step of a series of steps to move to the 'final' restructuring.\n- Because we're incrementally changing the code, there may be temporary\n  changes to allow existing code to continue to work.\n\nTODO:\n- Loadbalancer must be added. Metadata proxy too?\n- Need class for Subject (containing add_observer). Location?\n\nNOTE: The FWaaS agent is a base class of the L3 agent, so the add_observer()\nneeds to (temporarily) reside there. Future patches should create a new\nmodule, so it is outside of the L3 agent hierachy that is being torn apart\n(and because LBaaS is not in that hierarchy).\n\nThe next few refactoring steps (after this one) are perceived to be:\n- Define the notification handlers in the observer base class.\n- Move handlers from the existing agents into concrete observer handlers.\n- Create a factory to instantiate the enabled services.\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n""}, {'number': 4, 'created': '2014-11-27 16:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d8faed86174852498debcf904734e7b47558440', 'message': ""L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced services,\nas part of a multi-step refactoring effort of the L3 agent. It performs\ntwo things. First, it loads the device drivers for a service. Second, it\nregisters the service with the L3 agent, so that the service can be\nnotified for various events.\n\nIn future refactorings, the notification mechanism will be fleshed out,\nand handlers defined and implemented (adapting from logic in the current\nagents).\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not 'improve/change' functionality.\n- This is one step of a series of steps to move to the 'final' restructuring.\n- Because we're incrementally changing the code, there may be temporary\n  changes to allow existing code to continue to work.\n\nTODO:\n- Loadbalancer must be added. Metadata proxy too?\n- Need class for Subject (containing add_observer). Location?\n\nNOTE: The FWaaS agent is a base class of the L3 agent, so the add_observer()\nneeds to (temporarily) reside there. Future patches should create a new\nmodule, so it is outside of the L3 agent hierachy that is being torn apart\n(and because LBaaS is not in that hierarchy).\n\nThe next few refactoring steps (after this one) are perceived to be:\n- Define the notification handlers in the observer base class.\n- Move handlers from the existing agents into concrete observer handlers.\n- Create a factory to instantiate the enabled services.\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n""}, {'number': 5, 'created': '2014-11-27 18:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6b2b56d1126f194073212e6240278b9c1043cca5', 'message': ""L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced services,\nas part of a multi-step refactoring effort of the L3 agent. It performs\ntwo things. First, it loads the device drivers for a service. Second, it\nregisters the service with the L3 agent, so that the service can be\nnotified for various events.\n\nIn future refactorings, the notification mechanism will be fleshed out,\nand handlers defined and implemented (adapting from logic in the current\nagents).\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not 'improve/change' functionality.\n- This is one step of a series of steps to move to the 'final' restructuring.\n- Because we're incrementally changing the code, there may be temporary\n  changes to allow existing code to continue to work.\n\nTODO:\n- Loadbalancer must be added. Metadata proxy too?\n- Need class for Subject (containing add_observer). Location?\n\nNOTE: The FWaaS agent is a base class of the L3 agent, so the add_observer()\nneeds to (temporarily) reside there. Future patches should create a new\nmodule, so it is outside of the L3 agent hierachy that is being torn apart\n(and because LBaaS is not in that hierarchy).\n\nThe next few refactoring steps (after this one) are perceived to be:\n- Define the notification handlers in the observer base class.\n- Move handlers from the existing agents into concrete observer handlers.\n- Create a factory to instantiate the enabled services.\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n""}, {'number': 6, 'created': '2014-11-28 15:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/98b6725bdd9a1491d99da0f26c45c2e633a62c36', 'message': ""L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced services,\nas part of a multi-step refactoring effort of the L3 agent. It performs\ntwo things. First, it loads the device drivers for a service. Second, it\nregisters the service with the L3 agent, so that the service can be\nnotified for various events.\n\nIn future refactorings, the notification mechanism will be fleshed out,\nand handlers defined and implemented (adapting from logic in the current\nagents).\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not 'improve/change' functionality.\n- This is one step of a series of steps to move to the 'final' restructuring.\n- Because we're incrementally changing the code, there may be temporary\n  changes to allow existing code to continue to work.\n\nTODO:\n- Loadbalancer must be added. Metadata proxy too?\n- Need class for Subject (containing add_observer). Location?\n\nNOTE: The FWaaS agent is a base class of the L3 agent, so the add_observer()\nneeds to (temporarily) reside there. Future patches should create a new\nmodule, so it is outside of the L3 agent hierachy that is being torn apart\n(and because LBaaS is not in that hierarchy).\n\nThe next few refactoring steps (after this one) are perceived to be:\n- Define the notification handlers in the observer base class.\n- Move handlers from the existing agents into concrete observer handlers.\n- Create a factory to instantiate the enabled services.\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n""}, {'number': 7, 'created': '2014-12-05 18:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/40a5522079310de7534050401c64bf6cb0c6044e', 'message': 'L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced services,\nas part of a multi-step refactoring effort of the L3 agent. It performs\ntwo things. First, it loads the device drivers for a service. Second, it\nregisters the service with an L3EventObservers object, so that the\nservice can be notified for various events.\n\nIn future refactorings, the notification mechanism will be fleshed out,\nidentifying notification points for L3 agent events, and creating/moving\nhandlers from the existing agents into the service classes. Once the\nL3 agent is split up, a factory may be used to create the service\ninstances.\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not \'improve/change\' functionality.\n- This is one step of a series of steps to move to the \'final\' restructuring.\n- Because we\'re incrementally changing the code, there may be temporary\n  changes to allow existing code to continue to work.\n\nThis WIP still needs to add loadbalancer and metadata proxy observers.\nThere are two questions in the patch set (as TODO), requesting feedback\non whether we should ""try"" to prevent instances of AdvancedService base\nclass, and whether there should be one observer list for all services.\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n'}, {'number': 8, 'created': '2014-12-08 22:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/783340335380dcc490b8f031b477725ce85ed11b', 'message': 'L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced services,\nas part of a multi-step refactoring effort of the L3 agent. It performs\ntwo things. First, it loads the device drivers for a service. Second, it\nregisters the service with an L3EventObservers object, so that the\nservice can be notified for various events.\n\nIn future refactorings, the notification mechanism will be fleshed out,\nidentifying notification points for L3 agent events, and creating/moving\nhandlers from the existing agents into the service classes. Once the\nL3 agent is split up, a factory may be used to create the service\ninstances.\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not \'improve/change\' functionality.\n- This is one step of a series of steps to move to the \'final\' restructuring.\n- Because we\'re incrementally changing the code, there may be temporary\n  changes to allow existing code to continue to work.\n\nThere are two questions in the patch set (as TODO), requesting feedback\non whether we should ""try"" to prevent instances of AdvancedService base\nclass, and whether there should be one observer list for all services.\n\nCo-Authored-By: Assaf Muller\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n'}, {'number': 9, 'created': '2014-12-09 05:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a424d1ae074c23f40e73babf0ca9e1f6fd6a4159', 'message': ""L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced\nservices, as part of a multi-step refactoring effort of the L3 agent.\nIt performs two things. First, it loads the device drivers for a\nservice. Second, it registers the service with an L3EventObservers\nobject, so that the service can be notified for various events.\n\nIn future refactorings, the notification mechanism will be fleshed\nout, identifying notification points for L3 agent events, and\ncreating/moving handlers from the existing agents into the service\nclasses. Once the L3 agent is split up, a factory may be used to\ncreate the service instances.\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not 'improve/change'\n  functionality.\n- This is one step of a series of steps to move to the 'final'\n  restructuring.\n- Because we're incrementally changing the code, there may be\n  temporary changes to allow existing code to continue to work.\n\nCo-Authored-By: Assaf Muller\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n""}, {'number': 10, 'created': '2014-12-09 14:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8e184914c2b447e3cd4641304599e2a4864f652', 'message': ""L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced\nservices, as part of a multi-step refactoring effort of the L3 agent.\nIt performs two things. First, it loads the device drivers for a\nservice. Second, it registers the service with an L3EventObservers\nobject, so that the service can be notified for various events.\n\nIn future refactorings, the notification mechanism will be fleshed\nout, identifying notification points for L3 agent events, and\ncreating/moving handlers from the existing agents into the service\nclasses. Once the L3 agent is split up, a factory may be used to\ncreate the service instances.\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not 'improve/change'\n  functionality.\n- This is one step of a series of steps to move to the 'final'\n  restructuring.\n- Because we're incrementally changing the code, there may be\n  temporary changes to allow existing code to continue to work.\n\nCo-Authored-By: Assaf Muller\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n""}, {'number': 11, 'created': '2014-12-10 23:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fee1c41cd7b2e26c9581f6b6602c6c9efaed6073', 'message': ""L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced\nservices, as part of a multi-step refactoring effort of the L3 agent.\n\nThe change set has these modifications:\n\n- Device drivers for VPN and FW services are loaded.\n- AdvancedService child instances are created for VPN and FW.\n- L3EventObservers is created by the L3 agent and the VPN and FW\n  service objects are registered for notifications of events.\n- VPN device driver event handlers moved to VPN service instance.\n- VPN device driver callbacks to VPN agent, moved to VPN service.\n  to service from the VPN device driver.\n- Test cases updated and moved related to these changes.\n- UT updated to test new methods and refactoring changes.\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not 'improve/change'\n  functionality (other than broken tests).\n- This is one step of a series of steps to move to the 'final'\n  restructuring.\n- Because we're incrementally changing the code, there may be\n  temporary changes to allow existing code to continue to work.\n\nCo-Authored-By: Assaf Muller\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n""}, {'number': 12, 'created': '2014-12-11 00:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/61d6fe6d0fae9cb66e370416730d771a67af3765', 'message': ""L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced\nservices, as part of a multi-step refactoring effort of the L3 agent.\n\nThe change set has these modifications:\n\n- Device drivers for VPN and FW services are loaded.\n- AdvancedService child instances are created for VPN and FW.\n- L3EventObservers is created by the L3 agent and the VPN and FW\n  service objects are registered for notifications of events.\n- VPN device driver event handlers moved to VPN service instance.\n- VPN device driver callbacks to VPN agent, moved to VPN service.\n  to service from the VPN device driver.\n- Test cases updated and moved related to these changes.\n- UT updated to test new methods and refactoring changes.\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not 'improve/change'\n  functionality (other than broken tests).\n- This is one step of a series of steps to move to the 'final'\n  restructuring.\n- Because we're incrementally changing the code, there may be\n  temporary changes to allow existing code to continue to work.\n\nCo-Authored-By: Assaf Muller\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n""}, {'number': 13, 'created': '2014-12-12 18:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ab09782cce237e0e4eb6d51086b0b7211481741', 'message': ""L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced\nservices, as part of a multi-step refactoring effort of the L3 agent.\n\nThe change set has these modifications:\n\n- Device drivers for VPN and FW services are loaded.\n- AdvancedService child instances are created for VPN and FW.\n- L3EventObservers is created by the L3 agent and the VPN and FW\n  service objects are registered for notifications of events.\n- VPN device driver event handlers moved to VPN service instance.\n- VPN device driver callbacks to VPN agent, moved to VPN service.\n  to service from the VPN device driver.\n- Test cases updated and moved related to these changes.\n- UT updated to test new methods and refactoring changes.\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not 'improve/change'\n  functionality (other than broken tests).\n- This is one step of a series of steps to move to the 'final'\n  restructuring.\n- Because we're incrementally changing the code, there may be\n  temporary changes to allow existing code to continue to work.\n\nCo-Authored-By: Assaf Muller\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n""}, {'number': 14, 'created': '2014-12-12 22:57:14.000000000', 'files': ['neutron/agent/l3/event_observers.py', 'neutron/agent/l3/agent.py', 'neutron/tests/unit/services/test_advanced_service.py', 'neutron/services/advanced_service.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/unit/agent/test_l3_event_observers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d264666bba0d633f2c6be423bf9f7e08db4ff289', 'message': ""L3 Agent restructure - observer hierarchy\n\nThis commit creates the basic observer hierarchy for advanced\nservices, as part of a multi-step refactoring effort of the L3 agent.\n\nThe change set has these modifications:\n\n- Device drivers for VPN and FW services are loaded.\n- AdvancedService child instances are created for VPN and FW.\n- L3EventObservers is created by the L3 agent and the VPN and FW\n  service objects are registered for notifications of events.\n- VPN device driver event handlers moved to VPN service instance.\n- VPN device driver callbacks to VPN agent, moved to VPN service.\n  to service from the VPN device driver.\n- Test cases updated and moved related to these changes.\n- UT updated to test new methods and refactoring changes.\n\nFuture commits will massage the event notification points in the\nL3 agent, and implement handlers.\n\nPlease keep these things in mind, when reviewing:\n- The goal is to refactor the code and not 'improve/change'\n  functionality (other than broken tests).\n- This is one step of a series of steps to move to the 'final'\n  restructuring.\n- Because we're incrementally changing the code, there may be\n  temporary changes to allow existing code to continue to work.\n\nCo-Authored-By: Assaf Muller\n\nChange-Id: I674c72e37b56aa1f729110310e6f697297c47c09\nPartially-implements: blueprint restructure-l3-agent\n""}]",108,136549,d264666bba0d633f2c6be423bf9f7e08db4ff289,331,44,14,6659,,,0,"L3 Agent restructure - observer hierarchy

This commit creates the basic observer hierarchy for advanced
services, as part of a multi-step refactoring effort of the L3 agent.

The change set has these modifications:

- Device drivers for VPN and FW services are loaded.
- AdvancedService child instances are created for VPN and FW.
- L3EventObservers is created by the L3 agent and the VPN and FW
  service objects are registered for notifications of events.
- VPN device driver event handlers moved to VPN service instance.
- VPN device driver callbacks to VPN agent, moved to VPN service.
  to service from the VPN device driver.
- Test cases updated and moved related to these changes.
- UT updated to test new methods and refactoring changes.

Future commits will massage the event notification points in the
L3 agent, and implement handlers.

Please keep these things in mind, when reviewing:
- The goal is to refactor the code and not 'improve/change'
  functionality (other than broken tests).
- This is one step of a series of steps to move to the 'final'
  restructuring.
- Because we're incrementally changing the code, there may be
  temporary changes to allow existing code to continue to work.

Co-Authored-By: Assaf Muller

Change-Id: I674c72e37b56aa1f729110310e6f697297c47c09
Partially-implements: blueprint restructure-l3-agent
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/136549/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3_agent.py', 'neutron/services/vpn/agent.py', 'neutron/services/advanced_service.py', 'neutron/tests/unit/services/vpn/test_vpn_service.py', 'neutron/services/vpn/vpn_service.py']",5,0793bd87a8191fe82d99964a093630d95f542950,bp/restructure-l3-agent,"# Copyright 2012 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo.config import cfg from neutron.extensions import vpnaas from neutron.openstack.common import importutils from neutron.openstack.common import log as logging from neutron.services import advanced_service LOG = logging.getLogger(__name__) class VPNService(advanced_service.AdvancedService): """"""VPN Service observer."""""" def __init__(self, l3_agent): super(VPNService, self).__init__(l3_agent) def load_device_drivers(self, agent, host): """"""Loads one or more device drivers for VPNaaS."""""" self.devices = [] for device_driver in cfg.CONF.vpnagent.vpn_device_driver: try: self.devices.append(importutils.import_object(device_driver, agent, host)) LOG.debug('Loaded VPNaaS device driver: %s', device_driver) except ImportError: raise vpnaas.DeviceDriverImportError( device_driver=device_driver) return self.devices def after_router_add(self, router_id, router): # EXAMPLE: Copied from VPN agent.py """"""Router added event. :param router_id: id of added router :param router: dict of rotuer """""" LOG.debug('VPN agent doing after_router_add actions') for device in self.devices: device.create_router(router_id) ",,182,23
openstack%2Fhorizon~master~I95fd2c25dc4e2e5ddc47cd390b472c8ee2310e97,openstack/horizon,master,I95fd2c25dc4e2e5ddc47cd390b472c8ee2310e97,Test's random name gen now uses uuid4,MERGED,2014-12-15 21:22:21.000000000,2014-12-18 04:20:10.000000000,2014-12-18 04:20:08.000000000,"[{'_account_id': 3}, {'_account_id': 581}, {'_account_id': 1941}, {'_account_id': 6635}, {'_account_id': 7012}, {'_account_id': 8040}, {'_account_id': 8577}, {'_account_id': 9317}, {'_account_id': 9981}, {'_account_id': 12355}, {'_account_id': 13325}, {'_account_id': 14124}]","[{'number': 1, 'created': '2014-12-15 21:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e2ef303cf72afb1c3b419f2221fb11315246f976', 'message': ""Test's random name gen now uses uuid4\n\nThis test used a random integer to generate the name of a file.  Although\nit doesn't pose a real problem, it's probably better just to drop a UUID\nin instead of a 3-digit number, to avoid collisions.\n\nChange-Id: I95fd2c25dc4e2e5ddc47cd390b472c8ee2310e97\nCloses-Bug: 1399219\n""}, {'number': 2, 'created': '2014-12-16 14:48:19.000000000', 'files': ['openstack_dashboard/test/integration_tests/tests/test_keypair.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3f17e9d5ed0be99edb6c95a420e616e9bee6a9ce', 'message': ""Test's random name gen now uses uuid4\n\nThis test used a random integer to generate the name of a file.  Although\nit doesn't pose a real problem, it's probably better just to drop a UUID\nin instead of a 3-digit number, to avoid collisions.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I95fd2c25dc4e2e5ddc47cd390b472c8ee2310e97\nCloses-Bug: 1399219\n""}]",4,141906,3f17e9d5ed0be99edb6c95a420e616e9bee6a9ce,25,12,2,14124,,,0,"Test's random name gen now uses uuid4

This test used a random integer to generate the name of a file.  Although
it doesn't pose a real problem, it's probably better just to drop a UUID
in instead of a 3-digit number, to avoid collisions.

Partially implements blueprint: selenium-integration-testing

Change-Id: I95fd2c25dc4e2e5ddc47cd390b472c8ee2310e97
Closes-Bug: 1399219
",git fetch https://review.opendev.org/openstack/horizon refs/changes/06/141906/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/tests/test_keypair.py'],1,e2ef303cf72afb1c3b419f2221fb11315246f976,bug/1399219,import uuid KEYPAIR_NAME = 'horizonkeypair' + str(uuid.uuid4()),"import random KEYPAIR_NAME = 'horizonkeypair' + str(random.randint(0, 1000))",2,2
openstack%2Fneutron-fwaas~master~I54c92a80e1d61bf7e2f710d3160697c22e2c94f5,openstack/neutron-fwaas,master,I54c92a80e1d61bf7e2f710d3160697c22e2c94f5,Kill oslo-incubator files,MERGED,2014-12-12 16:58:10.000000000,2014-12-18 04:19:11.000000000,2014-12-18 04:19:10.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 9656}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-12 16:58:10.000000000', 'files': ['neutron_fwaas/openstack/common/middleware/__init__.py', 'neutron_fwaas/openstack/common/fileutils.py', 'neutron_fwaas/openstack/common/cache/backends.py', 'neutron_fwaas/openstack/common/middleware/request_id.py', 'neutron_fwaas/openstack/common/fixture/logging.py', 'neutron_fwaas/openstack/common/local.py', 'neutron_fwaas/openstack/common/uuidutils.py', 'neutron_fwaas/openstack/common/eventlet_backdoor.py', 'neutron_fwaas/openstack/common/loopingcall.py', 'neutron_fwaas/openstack/common/__init__.py', 'neutron_fwaas/openstack/common/middleware/catch_errors.py', 'neutron_fwaas/openstack/common/policy.py', 'neutron_fwaas/openstack/common/log.py', 'openstack-common.conf', 'neutron_fwaas/openstack/common/systemd.py', 'neutron_fwaas/openstack/common/_i18n.py', 'neutron_fwaas/openstack/common/service.py', 'neutron_fwaas/openstack/common/cache/cache.py', 'neutron_fwaas/openstack/common/lockutils.py', 'neutron_fwaas/openstack/common/periodic_task.py', 'neutron_fwaas/openstack/__init__.py', 'neutron_fwaas/openstack/common/context.py', 'neutron_fwaas/openstack/common/cache/__init__.py', 'neutron_fwaas/openstack/common/versionutils.py', 'neutron_fwaas/openstack/common/fixture/lockutils.py', 'neutron_fwaas/openstack/common/fixture/__init__.py', 'neutron_fwaas/openstack/common/processutils.py', 'neutron_fwaas/openstack/common/threadgroup.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/48e027cad8109428e63276f08102c223361c0dbe', 'message': 'Kill oslo-incubator files\n\nThey are not used, and just use space. If any of those modules is\nneeded, just use its version from neutron repo.\n\nChange-Id: I54c92a80e1d61bf7e2f710d3160697c22e2c94f5\n'}]",0,141425,48e027cad8109428e63276f08102c223361c0dbe,15,4,1,9656,,,0,"Kill oslo-incubator files

They are not used, and just use space. If any of those modules is
needed, just use its version from neutron repo.

Change-Id: I54c92a80e1d61bf7e2f710d3160697c22e2c94f5
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/25/141425/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/openstack/common/middleware/__init__.py', 'neutron_fwaas/openstack/common/fileutils.py', 'neutron_fwaas/openstack/common/cache/backends.py', 'neutron_fwaas/openstack/common/middleware/request_id.py', 'neutron_fwaas/openstack/common/fixture/logging.py', 'neutron_fwaas/openstack/common/local.py', 'neutron_fwaas/openstack/common/uuidutils.py', 'neutron_fwaas/openstack/common/eventlet_backdoor.py', 'neutron_fwaas/openstack/common/loopingcall.py', 'neutron_fwaas/openstack/common/__init__.py', 'neutron_fwaas/openstack/common/middleware/catch_errors.py', 'neutron_fwaas/openstack/common/policy.py', 'neutron_fwaas/openstack/common/log.py', 'openstack-common.conf', 'neutron_fwaas/openstack/common/systemd.py', 'neutron_fwaas/openstack/common/_i18n.py', 'neutron_fwaas/openstack/common/service.py', 'neutron_fwaas/openstack/common/cache/cache.py', 'neutron_fwaas/openstack/common/lockutils.py', 'neutron_fwaas/openstack/common/periodic_task.py', 'neutron_fwaas/openstack/__init__.py', 'neutron_fwaas/openstack/common/context.py', 'neutron_fwaas/openstack/common/cache/__init__.py', 'neutron_fwaas/openstack/common/versionutils.py', 'neutron_fwaas/openstack/common/fixture/lockutils.py', 'neutron_fwaas/openstack/common/fixture/__init__.py', 'neutron_fwaas/openstack/common/processutils.py', 'neutron_fwaas/openstack/common/threadgroup.py']",28,48e027cad8109428e63276f08102c223361c0dbe,,,"# Copyright 2012 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import threading import eventlet from eventlet import greenpool from neutron_fwaas.openstack.common import log as logging from neutron_fwaas.openstack.common import loopingcall LOG = logging.getLogger(__name__) def _thread_done(gt, *args, **kwargs): """"""Callback function to be passed to GreenThread.link() when we spawn() Calls the :class:`ThreadGroup` to notify if. """""" kwargs['group'].thread_done(kwargs['thread']) class Thread(object): """"""Wrapper around a greenthread, that holds a reference to the :class:`ThreadGroup`. The Thread will notify the :class:`ThreadGroup` when it has done so it can be removed from the threads list. """""" def __init__(self, thread, group): self.thread = thread self.thread.link(_thread_done, group=group, thread=self) def stop(self): self.thread.kill() def wait(self): return self.thread.wait() def link(self, func, *args, **kwargs): self.thread.link(func, *args, **kwargs) class ThreadGroup(object): """"""The point of the ThreadGroup class is to: * keep track of timers and greenthreads (making it easier to stop them when need be). * provide an easy API to add timers. """""" def __init__(self, thread_pool_size=10): self.pool = greenpool.GreenPool(thread_pool_size) self.threads = [] self.timers = [] def add_dynamic_timer(self, callback, initial_delay=None, periodic_interval_max=None, *args, **kwargs): timer = loopingcall.DynamicLoopingCall(callback, *args, **kwargs) timer.start(initial_delay=initial_delay, periodic_interval_max=periodic_interval_max) self.timers.append(timer) def add_timer(self, interval, callback, initial_delay=None, *args, **kwargs): pulse = loopingcall.FixedIntervalLoopingCall(callback, *args, **kwargs) pulse.start(interval=interval, initial_delay=initial_delay) self.timers.append(pulse) def add_thread(self, callback, *args, **kwargs): gt = self.pool.spawn(callback, *args, **kwargs) th = Thread(gt, self) self.threads.append(th) return th def thread_done(self, thread): self.threads.remove(thread) def _stop_threads(self): current = threading.current_thread() # Iterate over a copy of self.threads so thread_done doesn't # modify the list while we're iterating for x in self.threads[:]: if x is current: # don't kill the current thread. continue try: x.stop() except eventlet.greenlet.GreenletExit: pass except Exception as ex: LOG.exception(ex) def stop_timers(self): for x in self.timers: try: x.stop() except Exception as ex: LOG.exception(ex) self.timers = [] def stop(self, graceful=False): """"""stop function has the option of graceful=True/False. * In case of graceful=True, wait for all threads to be finished. Never kill threads. * In case of graceful=False, kill threads immediately. """""" self.stop_timers() if graceful: # In case of graceful=True, wait for all threads to be # finished, never kill threads self.wait() else: # In case of graceful=False(Default), kill threads # immediately self._stop_threads() def wait(self): for x in self.timers: try: x.wait() except eventlet.greenlet.GreenletExit: pass except Exception as ex: LOG.exception(ex) current = threading.current_thread() # Iterate over a copy of self.threads so thread_done doesn't # modify the list while we're iterating for x in self.threads[:]: if x is current: continue try: x.wait() except eventlet.greenlet.GreenletExit: pass except Exception as ex: LOG.exception(ex) ",0,4680
openstack%2Fglance~stable%2Fjuno~I38909f327f5d168fca2f53a8e32eb39db5d98ee9,openstack/glance,stable/juno,I38909f327f5d168fca2f53a8e32eb39db5d98ee9,Updated from global requirements,MERGED,2014-12-14 00:10:37.000000000,2014-12-18 04:18:24.000000000,2014-12-18 04:18:23.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1420}, {'_account_id': 2472}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-14 00:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4a3fc0ed096bc52bce5c75aee7b04a1be0dceca3', 'message': 'Updated from global requirements\n\nChange-Id: I38909f327f5d168fca2f53a8e32eb39db5d98ee9\n'}, {'number': 2, 'created': '2014-12-16 14:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/db34f65637add28a7001a021bacade809b581afd', 'message': 'Updated from global requirements\n\nChange-Id: I38909f327f5d168fca2f53a8e32eb39db5d98ee9\n'}, {'number': 3, 'created': '2014-12-16 23:02:50.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/glance/commit/749187a75af02989f1a3bf1f6a44004776a7e303', 'message': 'Updated from global requirements\n\nChange-Id: I38909f327f5d168fca2f53a8e32eb39db5d98ee9\n'}]",1,141596,749187a75af02989f1a3bf1f6a44004776a7e303,20,7,3,11131,,,0,"Updated from global requirements

Change-Id: I38909f327f5d168fca2f53a8e32eb39db5d98ee9
",git fetch https://review.opendev.org/openstack/glance refs/changes/96/141596/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4a3fc0ed096bc52bce5c75aee7b04a1be0dceca3,openstack/requirements,"SQLAlchemy>=0.8.4,<=0.9.99,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,!=0.9.4,!=0.9.5,!=0.9.6","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",1,1
openstack%2Fnova~master~Iad9ecf99734fb4c200ba046da42128299a1162f2,openstack/nova,master,Iad9ecf99734fb4c200ba046da42128299a1162f2,Replace use of handle_schedule_error() with set_vm_state_and_notify(),MERGED,2014-12-01 10:14:33.000000000,2014-12-18 04:18:06.000000000,2014-12-18 04:18:03.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6450}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-01 10:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b23afb22c0d16f59e802e86c0fe135f3d4cb8882', 'message': 'Replace use of handle_schedule_error() with set_vm_state_and_notify()\n\nConductor task build_instances() currently uses error handling code in\nscheduler driver to set instance error state and issue notifications.\nThere is a similar method in scheduler utils that does the exact same,\nwhich a prior change converted to correctly send instance objects to\nnotifications send_update().\n\nThis in additon has the added benefit of decoupling conductor from\nscheduler driver internals.\n\nChange-Id: Iad9ecf99734fb4c200ba046da42128299a1162f2\nRelated-Bug: #1396324\n'}, {'number': 2, 'created': '2014-12-08 11:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fe5c7ebb7e8379bdbb54d3bc522a989d56d5408', 'message': 'Replace use of handle_schedule_error() with set_vm_state_and_notify()\n\nConductor task build_instances() currently uses error handling code in\nscheduler driver to set instance error state and issue notifications.\nThere is a similar method in scheduler utils that does the exact same,\nwhich a prior change converted to correctly send instance objects to\nnotifications send_update().\n\nThis in additon has the added benefit of decoupling conductor from\nscheduler driver internals.\n\nChange-Id: Iad9ecf99734fb4c200ba046da42128299a1162f2\nRelated-Bug: #1396324\n'}, {'number': 3, 'created': '2014-12-15 11:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/975ec03d9091d7c2c39af8be381ac5724e7ed2f5', 'message': 'Replace use of handle_schedule_error() with set_vm_state_and_notify()\n\nConductor task build_instances() currently uses error handling code in\nscheduler driver to set instance error state and issue notifications.\nThere is a similar method in scheduler utils that does the exact same,\nwhich a prior change converted to correctly send instance objects to\nnotifications send_update().\n\nThis in additon has the added benefit of decoupling conductor from\nscheduler driver internals.\n\nChange-Id: Iad9ecf99734fb4c200ba046da42128299a1162f2\nRelated-Bug: #1396324\n'}, {'number': 4, 'created': '2014-12-17 06:41:26.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cd16fa7b485e53f611a3f831569ddacce5393368', 'message': 'Replace use of handle_schedule_error() with set_vm_state_and_notify()\n\nConductor task build_instances() currently uses error handling code in\nscheduler driver to set instance error state and issue notifications.\nThere is a similar method in scheduler utils that does the exact same,\nwhich a prior change converted to correctly send instance objects to\nnotifications send_update().\n\nThis in additon has the added benefit of decoupling conductor from\nscheduler driver internals.\n\nChange-Id: Iad9ecf99734fb4c200ba046da42128299a1162f2\nRelated-Bug: #1396324\n'}]",5,138027,cd16fa7b485e53f611a3f831569ddacce5393368,54,12,4,6450,,,0,"Replace use of handle_schedule_error() with set_vm_state_and_notify()

Conductor task build_instances() currently uses error handling code in
scheduler driver to set instance error state and issue notifications.
There is a similar method in scheduler utils that does the exact same,
which a prior change converted to correctly send instance objects to
notifications send_update().

This in additon has the added benefit of decoupling conductor from
scheduler driver internals.

Change-Id: Iad9ecf99734fb4c200ba046da42128299a1162f2
Related-Bug: #1396324
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/138027/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py']",2,b23afb22c0d16f59e802e86c0fe135f3d4cb8882,bug/1396324," updates = {'vm_state': vm_states.ERROR, 'task_state': None} self._set_vm_state_and_notify(context, 'build_instances', updates, exc, request_spec)","from nova.scheduler import driver as scheduler_driver for instance in instances: scheduler_driver.handle_schedule_error(context, exc, instance.uuid, request_spec)",8,8
openstack%2Fnova~master~I37431dd14165883d9a4f81c3892bd6c3a94da86d,openstack/nova,master,I37431dd14165883d9a4f81c3892bd6c3a94da86d,Fix set_vm_state_and_notify passing SQLA objects to send_update(),MERGED,2014-11-26 10:17:19.000000000,2014-12-18 04:17:45.000000000,2014-12-18 04:17:41.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6450}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-26 10:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e95bbfdc3d83da6ea0b5e79f090a0388ae3c0be', 'message': 'Fix set_vm_state_and_notify passing SQLA objects to send_update()\n\nSimilar to the fix in https://review.openstack.org/137194, with the\nrecent changes to notifications this must now pass an instance object.\n\nChange-Id: I37431dd14165883d9a4f81c3892bd6c3a94da86d\nRelated-Bug: #1396324\n'}, {'number': 2, 'created': '2014-11-27 10:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49f5a47f736ec0e656a5b9b596689ca074e1516f', 'message': 'Fix set_vm_state_and_notify passing non-object Instance to send_update()\n\nSimilar to the fix in https://review.openstack.org/137194, with the\nrecent changes to notifications this must now pass an instance object.\n\nChange-Id: I37431dd14165883d9a4f81c3892bd6c3a94da86d\nRelated-Bug: #1396324\n'}, {'number': 3, 'created': '2014-11-27 10:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/04b4579d67dfbc6911cf4186a0c419c8a9810ceb', 'message': 'Fix set_vm_state_and_notify passing SQLA objects to send_update()\n\nSimilar to the fix in https://review.openstack.org/137194, with the\nrecent changes to notifications this must now pass an instance object.\n\nAlso change a call in build_instances() to use this updated method\ninstead of the old handle_schedule_error() method in scheduler.\n\nChange-Id: I37431dd14165883d9a4f81c3892bd6c3a94da86d\nRelated-Bug: #1396324\n'}, {'number': 4, 'created': '2014-12-01 10:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33a0e1a9af901037df7b3aeea17d4f7ecde8a9b8', 'message': 'Fix set_vm_state_and_notify passing SQLA objects to send_update()\n\nSimilar to the fix in https://review.openstack.org/137194, with the\nrecent changes to notifications this must now pass an instance object.\n\nChange-Id: I37431dd14165883d9a4f81c3892bd6c3a94da86d\nRelated-Bug: #1396324\n'}, {'number': 5, 'created': '2014-12-08 11:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/386644735c61822635113eff22afd68419aa2243', 'message': 'Fix set_vm_state_and_notify passing SQLA objects to send_update()\n\nSimilar to the fix in https://review.openstack.org/137194, with the\nrecent changes to notifications this must now pass an instance object.\n\nChange-Id: I37431dd14165883d9a4f81c3892bd6c3a94da86d\nRelated-Bug: #1396324\n'}, {'number': 6, 'created': '2014-12-15 11:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d3585833ae418a9bdea76301a10f3a763784bf9', 'message': 'Fix set_vm_state_and_notify passing SQLA objects to send_update()\n\nSimilar to the fix in https://review.openstack.org/137194, with the\nrecent changes to notifications this must now pass an instance object.\n\nChange-Id: I37431dd14165883d9a4f81c3892bd6c3a94da86d\nRelated-Bug: #1396324\n'}, {'number': 7, 'created': '2014-12-17 06:29:15.000000000', 'files': ['nova/scheduler/utils.py', 'nova/tests/unit/scheduler/test_scheduler_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9d6158c890cb86e4f800cbfb1eec1b9f455528cb', 'message': 'Fix set_vm_state_and_notify passing SQLA objects to send_update()\n\nSimilar to the fix in https://review.openstack.org/137194, with the\nrecent changes to notifications this must now pass an instance object.\n\nChange-Id: I37431dd14165883d9a4f81c3892bd6c3a94da86d\nRelated-Bug: #1396324\n'}]",3,137322,9d6158c890cb86e4f800cbfb1eec1b9f455528cb,95,14,7,6450,,,0,"Fix set_vm_state_and_notify passing SQLA objects to send_update()

Similar to the fix in https://review.openstack.org/137194, with the
recent changes to notifications this must now pass an instance object.

Change-Id: I37431dd14165883d9a4f81c3892bd6c3a94da86d
Related-Bug: #1396324
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/137322/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/utils.py', 'nova/tests/unit/scheduler/test_scheduler.py', 'nova/tests/unit/scheduler/test_scheduler_utils.py']",3,8e95bbfdc3d83da6ea0b5e79f090a0388ae3c0be,bug/1396324," self.mox.StubOutWithMock(objects.Instance, '_from_db_object') inst_obj = 'inst_obj' self.context, _uuid, updates, columns_to_join=['system_metadata']).AndReturn( (old_ref, new_ref)) objects.Instance._from_db_object( self.context, mox.IgnoreArg(), new_ref, expected_attrs=['system_metadata']).AndReturn(inst_obj) notifications.send_update(self.context, old_ref, inst_obj,"," self.context, _uuid, updates).AndReturn((old_ref, new_ref)) notifications.send_update(self.context, old_ref, new_ref,",51,73
openstack%2Fnova~master~I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b,openstack/nova,master,I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b,Add API schema for v2.1 block_device_mapping extension,MERGED,2014-01-22 08:21:00.000000000,2014-12-18 04:14:44.000000000,2014-12-18 04:14:41.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6167}, {'_account_id': 7882}, {'_account_id': 8412}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9533}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-01-22 08:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc5b9c9e3b7577895199ec6e7a9ddaf719f41184', 'message': 'Add API schema for v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 2, 'created': '2014-02-05 09:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19c299ceaf3db41f7681276166ec9672be9caa7a', 'message': 'Add API schema for v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 3, 'created': '2014-02-05 09:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1cdff5aad0f48b41389ccd8d0312df7d2ee06bc2', 'message': 'Add API schema for v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 4, 'created': '2014-02-12 06:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ee5e1ac39e90620d787c2aa55d1650174359fd0', 'message': 'Add API schema for v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 5, 'created': '2014-02-19 07:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c11b5f85bd909e64d461b71946a605c7d6f4e55', 'message': 'Add API schema for v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 6, 'created': '2014-06-18 06:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a7c6f93fa885d8ba0c3ea3e79ab9c1a35c588a6', 'message': 'Add API schema for v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 7, 'created': '2014-06-18 06:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/318fc94fb9af6a2cd50bfa438412c81afd63b9b2', 'message': 'Add API schema for v2.1/v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 8, 'created': '2014-06-19 07:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf2036042457367f58d81d424b617efdb60c3e16', 'message': 'Add API schema for v2.1/v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 9, 'created': '2014-08-07 03:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c2ac76bf398770ed0d83c62c5f815f76869bf7e', 'message': 'Add API schema for v2.1/v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 10, 'created': '2014-08-11 07:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b5893be9fd3c6d2a31bdd775ad8ad0d2a54b2ef', 'message': 'Add API schema for v2.1/v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 11, 'created': '2014-08-12 02:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46f274833d016ac255e514d3d0a0783650f1e663', 'message': 'Add API schema for v2.1/v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 12, 'created': '2014-08-20 07:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98ac0baa3b8e8caaae6667f5582f884f1cd25a1f', 'message': 'Add API schema for v2.1/v3 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 13, 'created': '2014-12-09 06:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b014ec6fb7af144172c218be6ce8b4a3e9a95075', 'message': 'Add API schema for v2.1 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 14, 'created': '2014-12-09 06:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1cb76db1087eee8dec9534ed00de91f93415596f', 'message': 'Add API schema for v2.1 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}, {'number': 15, 'created': '2014-12-12 06:28:43.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/block_device_mapping.py', 'nova/api/openstack/compute/schemas/v3/block_device_mapping.py', 'nova/tests/unit/api/openstack/compute/contrib/test_block_device_mapping.py', 'nova/api/validation/parameter_types.py', 'nova/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5316aeabfeae71451ede2cc8fcd3efc83c806b83', 'message': 'Add API schema for v2.1 block_device_mapping extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b\n'}]",27,68338,5316aeabfeae71451ede2cc8fcd3efc83c806b83,169,16,15,7882,,,0,"Add API schema for v2.1 block_device_mapping extension

By defining the API schema, it is possible to separate the validation
code from the API method. The API method can be more simple.
In addition, a response of API validation error can be consistent for
the whole Nova API.

Partially implements blueprint v2-on-v3-api

Change-Id: I6d53ef2e3dad5a4ac9b67a5838f6e07606a8372b
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/68338/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/block_device_mapping.py', 'nova/api/openstack/compute/schemas/v3/block_device_mapping.py', 'nova/tests/api/openstack/compute/plugins/v3/test_block_device_mapping.py']",3,cc5b9c9e3b7577895199ec6e7a9ddaf719f41184,bp/v2-on-v3-api,"class BlockDeviceMappingAPIValidationTest(test.TestCase): def setUp(self): super(BlockDeviceMappingAPIValidationTest, self).setUp() ext_info = plugins.LoadedExtensionInfo() self.controller = servers.ServersController(extension_info=ext_info) fake.stub_out_image_service(self.stubs) self.bdm = [{ 'no_device': None, 'source_type': 'volume', 'destination_type': 'volume', 'uuid': 'fake', 'device_name': 'vda', 'delete_on_termination': False, }] def _test_create(self, params): body = { 'server': { 'name': 'server_test', 'image_ref': '76fa36fc-c930-4bf3-8c8a-ea2a2420deb6', 'flavor_ref': 'http://localhost/123/flavors/3', }, } body['server'].update(params) req = fakes.HTTPRequestV3.blank('/servers') req.method = 'POST' req.headers['content-type'] = 'application/json' req.body = jsonutils.dumps(body) self.controller.create(req, body=body) def test_create_instance_with_device_name_not_string(self): self.bdm[0]['device_name'] = 123 params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exception.ValidationError, self._test_create, params) def test_create_instance_with_device_name_empty(self): self.bdm[0]['device_name'] = '' params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exception.ValidationError, self._test_create, params) def test_create_instance_with_device_name_too_long(self): self.bdm[0]['device_name'] = 'a' * 256 params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exception.ValidationError, self._test_create, params) def test_create_instance_with_space_in_device_name(self): self.bdm[0]['device_name'] = 'v da' params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exception.ValidationError, self._test_create, params) def test_create_instance_with_invalid_size(self): self.bdm[0]['volume_size'] = 'hello world' params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exception.ValidationError, self._test_create, params) def test_create_instance_with_invalid_field(self): self.bdm[0]['invalid_field'] = 'test' params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exception.ValidationError, self._test_create, params) def test_create_instance_with_invalid_source_type(self): self.bdm[0]['source_type'] = 'test' params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exception.ValidationError, self._test_create, params) "," def test_create_instance_with_device_name_not_string(self): self.bdm[0]['device_name'] = 123 old_create = compute_api.API.create def create(*args, **kwargs): self.assertEqual(kwargs['block_device_mapping'], self.bdm) return old_create(*args, **kwargs) self.stubs.Set(compute_api.API, 'create', create) params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exc.HTTPBadRequest, self._test_create, params) def test_create_instance_with_device_name_empty(self): self.bdm[0]['device_name'] = '' old_create = compute_api.API.create def create(*args, **kwargs): self.assertEqual(kwargs['block_device_mapping'], self.bdm) return old_create(*args, **kwargs) self.stubs.Set(compute_api.API, 'create', create) params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exc.HTTPBadRequest, self._test_create, params) def test_create_instance_with_device_name_too_long(self): self.bdm[0]['device_name'] = 'a' * 256 old_create = compute_api.API.create def create(*args, **kwargs): self.assertEqual(kwargs['block_device_mapping'], self.bdm) return old_create(*args, **kwargs) self.stubs.Set(compute_api.API, 'create', create) params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exc.HTTPBadRequest, self._test_create, params) def test_create_instance_with_space_in_device_name(self): self.bdm[0]['device_name'] = 'v da' old_create = compute_api.API.create def create(*args, **kwargs): self.assertTrue(kwargs['legacy_bdm']) self.assertEqual(kwargs['block_device_mapping'], self.bdm) return old_create(*args, **kwargs) self.stubs.Set(compute_api.API, 'create', create) params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exc.HTTPBadRequest, self._test_create, params) def test_create_instance_with_invalid_size(self): self.bdm[0]['volume_size'] = 'hello world' old_create = compute_api.API.create def create(*args, **kwargs): self.assertEqual(kwargs['block_device_mapping'], self.bdm) return old_create(*args, **kwargs) self.stubs.Set(compute_api.API, 'create', create) params = {block_device_mapping.ATTRIBUTE_NAME: self.bdm} self.assertRaises(exc.HTTPBadRequest, self._test_create, params) ",183,70
openstack%2Fneutron~master~I6f899f86034145ac88b5c2e0f3036f7477f9702f,openstack/neutron,master,I6f899f86034145ac88b5c2e0f3036f7477f9702f,Simplify L3 HA unit test structure,MERGED,2014-12-01 09:33:41.000000000,2014-12-18 04:12:33.000000000,2014-12-18 04:12:31.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 7141}, {'_account_id': 7249}, {'_account_id': 7448}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10237}, {'_account_id': 10971}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-12-01 09:33:41.000000000', 'files': ['neutron/tests/unit/db/test_l3_ha_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c32741a1ea347feedc08cacdc3c502ce1fdb1af1', 'message': 'Simplify L3 HA unit test structure\n\nPreviously we had two fake test plugins: With and without agents.\nI removed the one without agents and merged two test cases.\nThis allows test writers to add additional tests more easily\nwithout mocking things that should not be mocked.\n\nChange-Id: I6f899f86034145ac88b5c2e0f3036f7477f9702f\n'}]",0,138019,c32741a1ea347feedc08cacdc3c502ce1fdb1af1,40,29,1,8873,,,0,"Simplify L3 HA unit test structure

Previously we had two fake test plugins: With and without agents.
I removed the one without agents and merged two test cases.
This allows test writers to add additional tests more easily
without mocking things that should not be mocked.

Change-Id: I6f899f86034145ac88b5c2e0f3036f7477f9702f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/19/138019/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/db/test_l3_ha_db.py'],1,c32741a1ea347feedc08cacdc3c502ce1fdb1af1,l3_ha_unit_test,"from neutron.db import l3_agentschedulers_dbclass FakeL3PluginWithAgents(common_db_mixin.CommonDbMixin, l3_hamode_db.L3_HA_NAT_db_mixin, l3_agentschedulers_db.L3AgentSchedulerDbMixin, self.plugin = FakeL3PluginWithAgents() self._register_agents() def _register_agents(self): agent_status = { 'agent_type': constants.AGENT_TYPE_L3, 'binary': 'neutron-l3-agent', 'host': 'l3host', 'topic': 'N/A' } self.plugin.create_or_update_agent(self.admin_ctx, agent_status) agent_status['host'] = 'l3host_2' self.plugin.create_or_update_agent(self.admin_ctx, agent_status) self.agent1, self.agent2 = self.plugin.get_agents(self.admin_ctx) def test_l3_agent_routers_query_interface(self): router = self._create_router() self._bind_router(router['id']) routers = self.plugin.get_ha_sync_data_for_host(self.admin_ctx, self.agent1['host']) self.assertEqual(1, len(routers)) router = routers[0] self.assertIsNotNone(router.get('ha')) interface = router.get(constants.HA_INTERFACE_KEY) self.assertIsNotNone(interface) self.assertEqual(constants.DEVICE_OWNER_ROUTER_HA_INTF, interface['device_owner']) self.assertEqual(cfg.CONF.l3_ha_net_cidr, interface['subnet']['cidr']) def test_update_state(self): router = self._create_router() self._bind_router(router['id']) routers = self.plugin.get_ha_sync_data_for_host(self.admin_ctx, self.agent1['host']) state = routers[0].get(constants.HA_ROUTER_STATE_KEY) self.assertEqual('standby', state) self.plugin.update_router_state(self.admin_ctx, router['id'], 'active', self.agent1['host']) routers = self.plugin.get_ha_sync_data_for_host(self.admin_ctx, self.agent1['host']) state = routers[0].get(constants.HA_ROUTER_STATE_KEY) self.assertEqual('active', state) ","class FakeL3Plugin(common_db_mixin.CommonDbMixin, l3_hamode_db.L3_HA_NAT_db_mixin): pass class FakeL3PluginWithAgents(FakeL3Plugin, mock.patch.object(l3_hamode_db.L3_HA_NAT_db_mixin, 'get_l3_agents', create=True, return_value=[1, 2]).start() class L3HAGetSyncDataTestCase(L3HATestFramework): def setUp(self): super(L3HAGetSyncDataTestCase, self).setUp() self.plugin = FakeL3PluginWithAgents() self._register_agents() def _register_agents(self): agent_status = { 'agent_type': constants.AGENT_TYPE_L3, 'binary': 'neutron-l3-agent', 'host': 'l3host', 'topic': 'N/A' } self.plugin.create_or_update_agent(self.admin_ctx, agent_status) agent_status['host'] = 'l3host_2' self.plugin.create_or_update_agent(self.admin_ctx, agent_status) self.agent1, self.agent2 = self.plugin.get_agents(self.admin_ctx) def test_l3_agent_routers_query_interface(self): router = self._create_router() self._bind_router(router['id']) routers = self.plugin.get_ha_sync_data_for_host(self.admin_ctx, self.agent1['host']) self.assertEqual(1, len(routers)) router = routers[0] self.assertIsNotNone(router.get('ha')) interface = router.get(constants.HA_INTERFACE_KEY) self.assertIsNotNone(interface) self.assertEqual(constants.DEVICE_OWNER_ROUTER_HA_INTF, interface['device_owner']) self.assertEqual(cfg.CONF.l3_ha_net_cidr, interface['subnet']['cidr']) def test_update_state(self): router = self._create_router() self._bind_router(router['id']) routers = self.plugin.get_ha_sync_data_for_host(self.admin_ctx, self.agent1['host']) state = routers[0].get(constants.HA_ROUTER_STATE_KEY) self.assertEqual('standby', state) self.plugin.update_router_state(self.admin_ctx, router['id'], 'active', self.agent1['host']) routers = self.plugin.get_ha_sync_data_for_host(self.admin_ctx, self.agent1['host']) state = routers[0].get(constants.HA_ROUTER_STATE_KEY) self.assertEqual('active', state) def setUp(self): super(L3HATestCase, self).setUp() self.plugin = FakeL3Plugin() self.plugin = FakeL3Plugin()",54,68
openstack%2Fpython-ceilometerclient~master~Ic30032bb70efae41ed3eaf57c3713ad95200f970,openstack/python-ceilometerclient,master,Ic30032bb70efae41ed3eaf57c3713ad95200f970,Fix Bad Request responses from Ceilometer APIs,ABANDONED,2014-12-09 02:20:36.000000000,2014-12-18 03:40:32.000000000,,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 7052}, {'_account_id': 8290}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-09 02:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/11dd896b571dcebc80200563ee6fd12a27614d0c', 'message': 'Fix Bad Request responses from Ceilometer APIs\n\nThe CLI exception message display has been broken for wrong parsing of\nexception message, the related bug has been fixed in oslo-incubator,\nThis change sync from oslo-incubator change to close the bug 1388714.\n\nChange-Id: Ic30032bb70efae41ed3eaf57c3713ad95200f970\nCloses-bug: #1354470\n'}, {'number': 2, 'created': '2014-12-18 03:39:11.000000000', 'files': ['ceilometerclient/openstack/common/apiclient/exceptions.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/05f737e57fe07cf94e560475855fa75f013efa05', 'message': 'Fix Bad Request responses from Ceilometer APIs\n\nThe CLI exception message display has been broken for wrong parsing of\nexception message, the related bug has been fixed in oslo-incubator,\nThis change sync from oslo-incubator change to close the bug 1388714.\n\nChange-Id: Ic30032bb70efae41ed3eaf57c3713ad95200f970\nCloses-bug: #1354470\n'}]",0,140205,05f737e57fe07cf94e560475855fa75f013efa05,10,7,2,8290,,,0,"Fix Bad Request responses from Ceilometer APIs

The CLI exception message display has been broken for wrong parsing of
exception message, the related bug has been fixed in oslo-incubator,
This change sync from oslo-incubator change to close the bug 1388714.

Change-Id: Ic30032bb70efae41ed3eaf57c3713ad95200f970
Closes-bug: #1354470
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/05/140205/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometerclient/openstack/common/apiclient/exceptions.py'],1,11dd896b571dcebc80200563ee6fd12a27614d0c,bug/1388714," # Sync from change: https://review.openstack.org/#/c/132542/ # note this py file has been marked ""DEPRECATED"" in oslo-incubator, # more details please see: # https://etherpad.openstack.org/p/kilo-oslo-library-proposals # and https://launchpad.net/python-openstacksdk # But, the exception message display of ceilometerclient has been # broken a long time, this change fix it. if isinstance(body, dict): error = body.get(list(body)[0]) if isinstance(error, dict): kwargs[""message""] = (error.get(""message"") or error.get(""faultstring"")) kwargs[""details""] = (error.get(""details"") or six.text_type(body))"," if isinstance(body, dict) and isinstance(body.get(""error""), dict): error = body[""error""] kwargs[""message""] = error.get(""message"") kwargs[""details""] = error.get(""details"")",14,4
openstack%2Fbarbican~master~I42662cacfdfd7070ed04fe3276a7ee2ce9949982,openstack/barbican,master,I42662cacfdfd7070ed04fe3276a7ee2ce9949982,Fix diff-cover gate broken by parent CR,ABANDONED,2014-12-08 01:05:18.000000000,2014-12-18 03:34:28.000000000,,"[{'_account_id': 3}, {'_account_id': 7789}, {'_account_id': 8623}]","[{'number': 1, 'created': '2014-12-08 01:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e52a5b3eadcdc4f6a96ff6d7c778491e7ed9d5e8', 'message': ""Fix diff-cover gate broken by parent CR\n\nWherever log messages were modified by the parent CR per the revised\nolso.i18n approach, missing unit tests were exposed by the diff-cover\ngate job. Hence this CR adds those missing unit tests. This effort also\nfixed issues with our current database unit tests, and also with the\nmodel package's models and repositories modules.\n\nChange-Id: I42662cacfdfd7070ed04fe3276a7ee2ce9949982\n""}, {'number': 2, 'created': '2014-12-08 02:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/add75c932cb965b119d37fcec68a253ecfd9f720', 'message': ""Fix diff-cover gate broken by parent CR\n\nWherever log messages were modified by the parent CR per the revised\nolso.i18n approach, missing unit tests were exposed by the diff-cover\ngate job. Hence this CR adds those missing unit tests. This effort also\nfixed issues with our current database unit tests, and also with the\nmodel package's models and repositories modules. Also fixed some\nmessage wording per comments from dependent CR.\n\nChange-Id: I42662cacfdfd7070ed04fe3276a7ee2ce9949982\n""}, {'number': 3, 'created': '2014-12-09 00:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e8b04bf1d4b84d76f579b63f650c2a7d326960f4', 'message': ""Fix diff-cover gate broken by parent CR\n\nWherever log messages were modified by the parent CR per the revised\nolso.i18n approach, missing unit tests were exposed by the diff-cover\ngate job. Hence this CR adds those missing unit tests. This effort also\nfixed issues with our current database unit tests, and also with the\nmodel package's models and repositories modules. Also fixed some\nmessage wording per comments from dependent CR.\n\nChange-Id: I42662cacfdfd7070ed04fe3276a7ee2ce9949982\n""}, {'number': 4, 'created': '2014-12-09 17:42:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/fa99b2b1ff982bf1da68e04e2c7b8bfd33eb13b8', 'message': ""Fix diff-cover gate broken by parent CR\n\nWherever log messages were modified by the parent CR per the revised\nolso.i18n approach, missing unit tests were exposed by the diff-cover\ngate job. Hence this CR adds those missing unit tests. This effort also\nfixed issues with our current database unit tests, and also with the\nmodel package's models and repositories modules. Also fixed some\nmessage wording per comments from dependent CR.\n\nChange-Id: I42662cacfdfd7070ed04fe3276a7ee2ce9949982\n""}, {'number': 5, 'created': '2014-12-09 21:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/195ed8d718129243a60329e8341282c8753b4aa5', 'message': ""Fix diff-cover gate broken by parent CR\n\nWherever log messages were modified by the parent CR per the revised\nolso.i18n approach, missing unit tests were exposed by the diff-cover\ngate job. Hence this CR adds those missing unit tests. This effort also\nfixed issues with our current database unit tests, and also with the\nmodel package's models and repositories modules. Also fixed some\nmessage wording per comments from dependent CR.\n\nChange-Id: I42662cacfdfd7070ed04fe3276a7ee2ce9949982\n""}, {'number': 6, 'created': '2014-12-09 21:35:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/544e68599f58e9730b4301fa2d8166c0d0f82db1', 'message': ""Fix diff-cover gate broken by parent CR\n\nWherever log messages were modified by the parent CR per the revised\nolso.i18n approach, missing unit tests were exposed by the diff-cover\ngate job. Hence this CR adds those missing unit tests. This effort also\nfixed issues with our current database unit tests, and also with the\nmodel package's models and repositories modules. Also fixed some\nmessage wording per comments from dependent CR.\n\nChange-Id: I42662cacfdfd7070ed04fe3276a7ee2ce9949982\n""}, {'number': 7, 'created': '2014-12-10 13:18:46.000000000', 'files': ['barbican/tests/model/repositories/test_repositories_consumers.py', 'barbican/tests/model/repositories/test_repositories_projects.py', 'barbican/tests/model/repositories/test_repositories_containers.py', 'barbican/api/controllers/consumers.py', 'barbican/plugin/interface/secret_store.py', 'barbican/tests/tasks/test_keystone_consumer.py', 'barbican/tests/api/__init__.py', 'barbican/common/exception.py', 'barbican/tests/api/middleware/test_context.py', 'barbican/tests/api/middleware/test_simple.py', 'barbican/tests/model/repositories/test_repositories_secrets.py', 'barbican/tasks/resources.py', 'barbican/model/models.py', 'barbican/tests/model/repositories/test_repositories_transport_keys.py', 'barbican/tests/utils.py', '.coveragerc', 'barbican/locale/barbican.pot', 'barbican/plugin/interface/certificate_manager.py', 'barbican/tests/model/repositories/test_repositories_orders.py', 'barbican/api/controllers/containers.py', 'barbican/tests/model/test_repositories.py', 'barbican/tests/model/repositories/test_repositories.py', 'barbican/tests/plugin/test_dogtag.py', 'barbican/tests/tasks/test_resources.py', 'barbican/model/repositories.py', 'barbican/tests/api/test_init.py', 'barbican/tests/model/repositories/__init__.py', 'barbican/tests/plugin/interface/test_secret_store.py', 'barbican/api/middleware/context.py', 'barbican/tests/api/middleware/__init__.py', 'barbican/tests/api/test_resources.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/1448e65be0d4f628de42df7b72aac71a4e3a6a3f', 'message': ""Fix diff-cover gate broken by parent CR\n\nWherever log messages were modified by the parent CR per the revised\nolso.i18n approach, missing unit tests were exposed by the diff-cover\ngate job. Hence this CR adds those missing unit tests. This effort also\nfixed issues with our current database unit tests, and also with the\nmodel package's models and repositories modules. Also fixed some\nmessage wording per comments from dependent CR.\n\nChange-Id: I42662cacfdfd7070ed04fe3276a7ee2ce9949982\n""}]",2,139894,1448e65be0d4f628de42df7b72aac71a4e3a6a3f,20,3,7,7789,,,0,"Fix diff-cover gate broken by parent CR

Wherever log messages were modified by the parent CR per the revised
olso.i18n approach, missing unit tests were exposed by the diff-cover
gate job. Hence this CR adds those missing unit tests. This effort also
fixed issues with our current database unit tests, and also with the
model package's models and repositories modules. Also fixed some
message wording per comments from dependent CR.

Change-Id: I42662cacfdfd7070ed04fe3276a7ee2ce9949982
",git fetch https://review.opendev.org/openstack/barbican refs/changes/94/139894/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/tests/model/repositories/test_repositories_consumers.py', 'barbican/tests/model/repositories/test_repositories_projects.py', 'barbican/tests/model/repositories/test_repositories_containers.py', 'barbican/api/controllers/consumers.py', 'barbican/tests/tasks/test_keystone_consumer.py', 'barbican/tests/api/__init__.py', 'barbican/common/exception.py', 'barbican/tests/api/middleware/test_context.py', 'barbican/tests/api/middleware/test_simple.py', 'barbican/tests/model/repositories/test_repositories_secrets.py', 'barbican/tasks/resources.py', 'barbican/model/models.py', 'barbican/tests/model/repositories/test_repositories_transport_keys.py', 'barbican/tests/utils.py', '.coveragerc', 'barbican/tests/model/repositories/test_repositories_orders.py', 'barbican/api/controllers/containers.py', 'barbican/tests/model/test_repositories.py', 'barbican/tests/model/repositories/test_repositories.py', 'barbican/tests/plugin/test_dogtag.py', 'barbican/tests/tasks/test_resources.py', 'barbican/model/repositories.py', 'barbican/tests/api/test_init.py', 'barbican/tests/model/repositories/__init__.py', 'barbican/tests/plugin/interface/test_secret_store.py', 'barbican/tests/api/middleware/__init__.py', 'barbican/tests/api/test_resources.py']",27,e52a5b3eadcdc4f6a96ff6d7c778491e7ed9d5e8,logging-move-to-latest-gettext-approach-unit-tests," args, kwargs = self.consumer_repo.create_or_update_from.call_args calls.append(mock.call(consumer.id, self.project_keystone_id)) calls.append(mock.call(consumer.id, self.project_keystone_id))"," args, kwargs = self.consumer_repo.create_from.call_args calls.append(mock.call(consumer.id)) calls.append(mock.call(consumer.id))",1718,667
openstack%2Ftempest~master~I965090417ef0719246cfdc2db6a9d33d4e78e326,openstack/tempest,master,I965090417ef0719246cfdc2db6a9d33d4e78e326,Add Test to Create Port with no security groups,MERGED,2014-08-21 09:27:20.000000000,2014-12-18 03:04:00.000000000,2014-12-18 02:55:52.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7249}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 8767}, {'_account_id': 10385}, {'_account_id': 10969}, {'_account_id': 11670}, {'_account_id': 11671}, {'_account_id': 12393}, {'_account_id': 12626}, {'_account_id': 14103}]","[{'number': 1, 'created': '2014-08-21 09:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7a73dea9921ecabe1cfd34c67d8c1245432f3cfc', 'message': 'Add Test to Create Port with no security groups\n\n-Create a Port with no security groups\n-Validate length of security group list is zero in response\n\nAdd Test to Update Port  with no security groups\n\n-Update a Port with no security groups\n-Validate length of security group list is zero in response\n\nChange-Id: I965090417ef0719246cfdc2db6a9d33d4e78e326\n'}, {'number': 2, 'created': '2014-08-22 06:02:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e8e86fea8755f2cf8c33e64f2f9fb9865165e520', 'message': 'Add Test to Create Port with no security groups\n\n-Create a Port with no security groups\n-Validate length of security group list is zero in response\n\nAdd Test to Update Port  with no security groups\n\n-Update a Port with no security groups\n-Validate length of security group list is zero in response\n\nChange-Id: I965090417ef0719246cfdc2db6a9d33d4e78e326\n'}, {'number': 3, 'created': '2014-11-14 06:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/585fa17557a80a1e62f93cc8f40db865f997aaff', 'message': 'Add Test to Create Port with no security groups\n\n-Create a Port with no security groups\n-Validate length of security group list is zero in response\n\nAdd Test to Update Port  with no security groups\n\n-Create a Port with default security groups\n-Validate length of security group list is not zero in response\n-Update a Port with no security groups\n-Validate length of security group list is zero in response\n\nChange-Id: I965090417ef0719246cfdc2db6a9d33d4e78e326\n'}, {'number': 4, 'created': '2014-11-14 09:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/244c11ffe76610b57464dd9c3450ba6b2ce1aee4', 'message': 'Add Test to Create Port with no security groups\n\n-Create a Port with no security groups\n-Validate length of security group list is zero in response\n\nAdd Test to Update Port  with no security groups\n\n-Create a Port with default security groups\n-Validate length of security group list is not zero in response\n-Update a Port with no security groups\n-Validate length of security group list is zero in response\n\nChange-Id: I965090417ef0719246cfdc2db6a9d33d4e78e326\n'}, {'number': 5, 'created': '2014-11-20 10:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/156a524bcbdc7f6020f2964e6bba8950d3d86f14', 'message': 'Add Test to Create Port with no security groups\n\n-Create a Port with no security groups\n-Validate length of security group list is zero in response\n\nAdd Test to Update Port  with no security groups\n\n-Create a Port with default security groups\n-Validate length of security group list is not zero in response\n-Update a Port with no security groups\n-Validate length of security group list is zero in response\n\nChange-Id: I965090417ef0719246cfdc2db6a9d33d4e78e326\n'}, {'number': 6, 'created': '2014-12-05 12:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/395b87a9f2b400c5c92f3066b5dfad6c971fd5a5', 'message': 'Add Test to Create Port with no security groups\n\n-Create a Port with no security groups\n-Validate length of security group list is zero in response\n\nAdd Test to Update Port  with no security groups\n\n-Create a Port with default security groups\n-Validate length of security group list is not zero in response\n-Update a Port with no security groups\n-Validate length of security group list is zero in response\n\nChange-Id: I965090417ef0719246cfdc2db6a9d33d4e78e326\n'}, {'number': 7, 'created': '2014-12-17 05:34:30.000000000', 'files': ['tempest/api/network/test_ports.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0f562a86a8c5b7de9611c325d361b34f983c3026', 'message': 'Add Test to Create Port with no security groups\n\n-Create a Port with no security groups\n-Validate length of security group list is zero in response\n\nAdd Test to Update Port  with no security groups\n\n-Create a Port with default security groups\n-Validate length of security group list is not zero in response\n-Update a Port with no security groups\n-Validate length of security group list is zero in response\n\nChange-Id: I965090417ef0719246cfdc2db6a9d33d4e78e326\n'}]",24,115908,0f562a86a8c5b7de9611c325d361b34f983c3026,59,15,7,12626,,,0,"Add Test to Create Port with no security groups

-Create a Port with no security groups
-Validate length of security group list is zero in response

Add Test to Update Port  with no security groups

-Create a Port with default security groups
-Validate length of security group list is not zero in response
-Update a Port with no security groups
-Validate length of security group list is zero in response

Change-Id: I965090417ef0719246cfdc2db6a9d33d4e78e326
",git fetch https://review.opendev.org/openstack/tempest refs/changes/08/115908/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/network/xml/network_client.py', 'tempest/api/network/test_ports.py']",2,7a73dea9921ecabe1cfd34c67d8c1245432f3cfc,Test-Port-No-Security-Group," @test.attr(type='smoke') def test_create_port_with_no_securitygroups(self): post_body = {""network_id"": self.network['id'], ""security_groups"": []} _, body = self.client.create_port(**post_body) port = body['port'] self.addCleanup(self.client.delete_port, port['id']) self.assertIsNotNone(port['security_groups']) self.assertTrue(len(port['security_groups']) == 0) @test.attr(type='smoke') def test_update_port_with_no_securitygroups(self): post_body = {""network_id"": self.network['id']} _, body = self.client.create_port(**post_body) port = body['port'] self.addCleanup(self.client.delete_port, port['id']) update_body = {""security_groups"": []} _, body = self.client.update_port(port['id'], **update_body) updated_port = body['port'] self.assertIsNotNone(updated_port['security_groups']) self.assertTrue(len(updated_port['security_groups']) == 0) ",,24,1
openstack%2Ftempest~master~I92d5809ef8c46350684ebbed7269cd6df04f39da,openstack/tempest,master,I92d5809ef8c46350684ebbed7269cd6df04f39da,Use isolated creds for dashboard scenario,MERGED,2014-12-13 00:57:26.000000000,2014-12-18 03:03:59.000000000,2014-12-18 02:55:33.000000000,"[{'_account_id': 3}, {'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-13 00:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3885bd5d00fe489a1150934a482dfcb0d6b58fa9', 'message': 'Use isolated creds for dashboard scenario\n\nThis commit modifies the dashboard basic ops scenario to use isolated\ncreds allocated during the setupClass. Previously this test used hard\ncoded values from the config file. But, moving forward those options\nwill be deprecated in favor of the test-accounts file. In preparation\nfor that shift this test needs to be modified to use the credentials\nprovided by either tenant isolation or test accounts.\n\nChange-Id: I92d5809ef8c46350684ebbed7269cd6df04f39da\n'}, {'number': 2, 'created': '2014-12-13 04:15:40.000000000', 'files': ['tempest/scenario/test_dashboard_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/643f4c60dd67aa8e76a605c613ab40413b866b72', 'message': 'Use isolated creds for dashboard scenario\n\nThis commit modifies the dashboard basic ops scenario to use isolated\ncreds allocated during the setupClass. Previously this test used hard\ncoded values from the config file. But, moving forward those options\nwill be deprecated in favor of the test-accounts file. In preparation\nfor that shift this test needs to be modified to use the credentials\nprovided by either tenant isolation or test accounts.\n\nChange-Id: I92d5809ef8c46350684ebbed7269cd6df04f39da\n'}]",0,141531,643f4c60dd67aa8e76a605c613ab40413b866b72,12,4,2,5196,,,0,"Use isolated creds for dashboard scenario

This commit modifies the dashboard basic ops scenario to use isolated
creds allocated during the setupClass. Previously this test used hard
coded values from the config file. But, moving forward those options
will be deprecated in favor of the test-accounts file. In preparation
for that shift this test needs to be modified to use the credentials
provided by either tenant isolation or test accounts.

Change-Id: I92d5809ef8c46350684ebbed7269cd6df04f39da
",git fetch https://review.opendev.org/openstack/tempest refs/changes/31/141531/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_dashboard_basic_ops.py'],1,3885bd5d00fe489a1150934a482dfcb0d6b58fa9,," def user_login(self, username, password): params = {'username': username, 'password': password, username = self.credentials.username password = self.credential.password self.user_login(username, password)"," def user_login(self): params = {'username': CONF.identity.username, 'password': CONF.identity.password, self.user_login()",6,4
openstack%2Ftempest~master~I08919f935df1f34e8b75efa2772b08a9eb643872,openstack/tempest,master,I08919f935df1f34e8b75efa2772b08a9eb643872,Do not test the metadata_items limit when there is no limit,MERGED,2014-12-10 14:17:30.000000000,2014-12-18 03:03:59.000000000,2014-12-18 02:55:23.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 14:17:30.000000000', 'files': ['tempest/api/compute/servers/test_server_metadata_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/cf3de04a6f05aabe663e098f5ebc64213408ab23', 'message': 'Do not test the metadata_items limit when there is no limit\n\nChange-Id: I08919f935df1f34e8b75efa2772b08a9eb643872\nCloses-Bug: #1401116\n'}]",0,140691,cf3de04a6f05aabe663e098f5ebc64213408ab23,9,5,1,8122,,,0,"Do not test the metadata_items limit when there is no limit

Change-Id: I08919f935df1f34e8b75efa2772b08a9eb643872
Closes-Bug: #1401116
",git fetch https://review.opendev.org/openstack/tempest refs/changes/91/140691/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_server_metadata_negative.py'],1,cf3de04a6f05aabe663e098f5ebc64213408ab23,bug/1401116," if quota_metadata == -1: raise self.skipException(""No limit for metadata_items"") ",,3,0
openstack%2Ftempest~master~Id276b94ae757801babc5e026ee5e38179d9e09e8,openstack/tempest,master,Id276b94ae757801babc5e026ee5e38179d9e09e8,Fix rebuild server tests for wrong input,MERGED,2014-12-16 00:34:05.000000000,2014-12-18 03:03:58.000000000,2014-12-18 02:55:42.000000000,"[{'_account_id': 3}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-16 00:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ab0a86ed51286dc1a6cbeff8443a5ca7553c0010', 'message': ""Fix rebuild server tests for wrong input\n\nNova rebuild server API takes 'metadata' as one of the input in\nrequest body. But test_rebuild_non_existent_server pass\nwrong input 'meta' in rebuild server call.\n\nThis tests does not fail because Nova V2 does not have strong input validation.\nIt is failed in Nova V2.1 experimental job on-\nIb13b02cefb9617e8af3b62b81d2f7eb7cd88eab1\n\nChange-Id: Id276b94ae757801babc5e026ee5e38179d9e09e8\n""}, {'number': 2, 'created': '2014-12-17 04:17:23.000000000', 'files': ['tempest/api/compute/servers/test_servers_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/fe087de4b78232bd4bf425386cad878b4102511f', 'message': ""Fix rebuild server tests for wrong input\n\nNova rebuild server API takes 'metadata' as one of the input in\nrequest body. But test_rebuild_non_existent_server pass\nwrong input 'meta' in rebuild server call.\n\nThis patch removes optional arg of rebuild call from this test.\n\nThis tests does not fail because Nova V2 does not have strong input validation.\nIt is failed in Nova V2.1 experimental job on-\nIb13b02cefb9617e8af3b62b81d2f7eb7cd88eab1\n\nChange-Id: Id276b94ae757801babc5e026ee5e38179d9e09e8\n""}]",2,141953,fe087de4b78232bd4bf425386cad878b4102511f,26,5,2,8556,,,0,"Fix rebuild server tests for wrong input

Nova rebuild server API takes 'metadata' as one of the input in
request body. But test_rebuild_non_existent_server pass
wrong input 'meta' in rebuild server call.

This patch removes optional arg of rebuild call from this test.

This tests does not fail because Nova V2 does not have strong input validation.
It is failed in Nova V2.1 experimental job on-
Ib13b02cefb9617e8af3b62b81d2f7eb7cd88eab1

Change-Id: Id276b94ae757801babc5e026ee5e38179d9e09e8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/53/141953/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_servers_negative.py'],1,ab0a86ed51286dc1a6cbeff8443a5ca7553c0010,(detached," name=new_name, metadata=meta,"," name=new_name, meta=meta,",1,1
openstack%2Ftempest~master~Ia909018c8e6a18c1e9e00f395a5447d881820269,openstack/tempest,master,Ia909018c8e6a18c1e9e00f395a5447d881820269,Remove unnecessary setting from CredentialsTests,MERGED,2014-12-17 08:18:59.000000000,2014-12-18 03:03:57.000000000,2014-12-18 02:55:14.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 08:18:59.000000000', 'files': ['tempest/tests/test_credentials.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/933a55545b7b091ac6ad723229913e9e9de7bd55', 'message': 'Remove unnecessary setting from CredentialsTests\n\nIn CredentialsTests, ClosingHttp is not used.\nAnd TempestConfigPrivate setting is duplicated between test classes.\nThis patch removes them for cleanup.\n\nChange-Id: Ia909018c8e6a18c1e9e00f395a5447d881820269\n'}]",0,142378,933a55545b7b091ac6ad723229913e9e9de7bd55,10,4,1,6167,,,0,"Remove unnecessary setting from CredentialsTests

In CredentialsTests, ClosingHttp is not used.
And TempestConfigPrivate setting is duplicated between test classes.
This patch removes them for cleanup.

Change-Id: Ia909018c8e6a18c1e9e00f395a5447d881820269
",git fetch https://review.opendev.org/openstack/tempest refs/changes/78/142378/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/tests/test_credentials.py'],1,933a55545b7b091ac6ad723229913e9e9de7bd55,rest-client,,"from tempest.tests import fake_http self.fake_http = fake_http.fake_httplib2(return_type=200) self.stubs.Set(http.ClosingHttp, 'request', self.fake_http.request) self.stubs.Set(config, 'TempestConfigPrivate', fake_config.FakePrivate)",0,4
openstack%2Fpbr~feature%2F0.10~Ic8e0c74a779b23842369a8cf01fcbf37885202ef,openstack/pbr,feature/0.10,Ic8e0c74a779b23842369a8cf01fcbf37885202ef,Properly check for git before getting git dir,MERGED,2014-12-17 22:23:33.000000000,2014-12-18 03:03:52.000000000,2014-12-18 02:54:58.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-12-17 22:23:33.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/e7d2825d39fce2111d0d413e63e553603a0e56fb', 'message': 'Properly check for git before getting git dir\n\nWe cannot get the git dir if git is not installed. Check that git is\ninstalled before querying for the git dir. Return None if the git dir\ncannot be found or if git is not installed.\n\nChange-Id: Ic8e0c74a779b23842369a8cf01fcbf37885202ef\nFixes-bug: 1326682\n'}]",0,142593,e7d2825d39fce2111d0d413e63e553603a0e56fb,8,3,1,4146,,,0,"Properly check for git before getting git dir

We cannot get the git dir if git is not installed. Check that git is
installed before querying for the git dir. Return None if the git dir
cannot be found or if git is not installed.

Change-Id: Ic8e0c74a779b23842369a8cf01fcbf37885202ef
Fixes-bug: 1326682
",git fetch https://review.opendev.org/openstack/pbr refs/changes/93/142593/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,e7d2825d39fce2111d0d413e63e553603a0e56fb,142351, git_dir = _run_git_functions() git_dir = _run_git_functions() git_dir = _run_git_functions() git_dir = None if _git_is_installed(): git_dir = _get_git_directory() return git_dir or None, git_dir = _get_git_directory() git_dir = _get_git_directory() git_dir = _get_git_directory() git_dir = _get_git_directory() if git_dir and _git_is_installed(): return git_dir return None,7,7
openstack%2Fnova~master~I1662e2d1e2e729da873c14a0cc307e412c699320,openstack/nova,master,I1662e2d1e2e729da873c14a0cc307e412c699320,libvirt: move setting of clock out into helper method,MERGED,2014-12-08 17:21:39.000000000,2014-12-18 03:03:08.000000000,2014-12-18 03:03:05.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12898}]","[{'number': 1, 'created': '2014-12-08 17:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/76ab0f3fd7834b69f6a43d00a03c9fe804422741', 'message': 'libvirt: move setting of clock out into helper method\n\nMove clock settings will be added in the future, so it\nmakes sense to have a separate helper method for all\nof them.\n\nRelated-bug: #1400315\nChange-Id: I1662e2d1e2e729da873c14a0cc307e412c699320\n'}, {'number': 2, 'created': '2014-12-11 16:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/31176566e15570c31375f722e1bcac27450d2810', 'message': 'libvirt: move setting of clock out into helper method\n\nMove clock settings will be added in the future, so it\nmakes sense to have a separate helper method for all\nof them.\n\nRelated-bug: #1400315\nChange-Id: I1662e2d1e2e729da873c14a0cc307e412c699320\n'}, {'number': 3, 'created': '2014-12-16 11:44:51.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b6a5b25335fc93bf605de19cd8531380535de666', 'message': 'libvirt: move setting of clock out into helper method\n\nMove clock settings will be added in the future, so it\nmakes sense to have a separate helper method for all\nof them.\n\nRelated-bug: #1400315\nChange-Id: I1662e2d1e2e729da873c14a0cc307e412c699320\n'}]",1,140084,b6a5b25335fc93bf605de19cd8531380535de666,38,12,3,1779,,,0,"libvirt: move setting of clock out into helper method

Move clock settings will be added in the future, so it
makes sense to have a separate helper method for all
of them.

Related-bug: #1400315
Change-Id: I1662e2d1e2e729da873c14a0cc307e412c699320
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/140084/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,76ab0f3fd7834b69f6a43d00a03c9fe804422741,libvirt-win-timers," def _set_clock(self, guest, instance, image_meta, virt_type): # NOTE(mikal): Microsoft Windows expects the clock to be in # ""localtime"". If the clock is set to UTC, then you can use a # registry key to let windows know, but Microsoft says this is # buggy in http://support.microsoft.com/kb/2687252 clk = vconfig.LibvirtConfigGuestClock() if instance['os_type'] == 'windows': LOG.info(_LI('Configuring timezone for windows instance to ' 'localtime'), instance=instance) clk.offset = 'localtime' else: clk.offset = 'utc' guest.set_clock(clk) if virt_type == ""kvm"": self._set_kvm_timers(clk, image_meta) self._set_clock(guest, instance, image_meta, virt_type)"," # NOTE(mikal): Microsoft Windows expects the clock to be in # ""localtime"". If the clock is set to UTC, then you can use a # registry key to let windows know, but Microsoft says this is # buggy in http://support.microsoft.com/kb/2687252 clk = vconfig.LibvirtConfigGuestClock() if instance['os_type'] == 'windows': LOG.info(_LI('Configuring timezone for windows instance to ' 'localtime'), instance=instance) clk.offset = 'localtime' else: clk.offset = 'utc' guest.set_clock(clk) if virt_type == ""kvm"": self._set_kvm_timers(clk, image_meta)",18,15
openstack%2Fneutron~stable%2Fjuno~I0271e5b25934ade786852125b33f13a2b548c3f2,openstack/neutron,stable/juno,I0271e5b25934ade786852125b33f13a2b548c3f2,Updated from global requirements,MERGED,2014-12-16 23:04:27.000000000,2014-12-18 03:02:50.000000000,2014-12-18 03:02:50.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1653}, {'_account_id': 2472}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 12040}, {'_account_id': 13900}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-16 23:04:27.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/20db82675a125a31c1c152c5301ae69a230449e3', 'message': 'Updated from global requirements\n\nChange-Id: I0271e5b25934ade786852125b33f13a2b548c3f2\n'}]",1,142253,20db82675a125a31c1c152c5301ae69a230449e3,22,17,1,11131,,,0,"Updated from global requirements

Change-Id: I0271e5b25934ade786852125b33f13a2b548c3f2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/53/142253/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,20db82675a125a31c1c152c5301ae69a230449e3,openstack/requirements,"oslo.db>=1.0.0,<1.1 # Apache-2.0","oslo.db>=1.0.0,<1.3 # Apache-2.0",1,1
openstack%2Fneutron~master~Ic6572abc3121535e19d21e9a34d70bb42b9782de,openstack/neutron,master,Ic6572abc3121535e19d21e9a34d70bb42b9782de,Cleanup req_format in test_api_v2_resource,MERGED,2014-12-15 12:49:29.000000000,2014-12-18 03:02:36.000000000,2014-12-18 03:02:35.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6788}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7743}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10237}, {'_account_id': 11822}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-15 12:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1be0c317cb94511199bc474ac451c53938af127a', 'message': 'Cleanup req_format in test_api_v2_resource\n\nSince XML support has been removed test cases in test_api_v2_resource\nno longer need to specify req_format to get a deserializer.\n\nChange-Id: Ic6572abc3121535e19d21e9a34d70bb42b9782de\nRelated-Bug: #1380787\n'}, {'number': 2, 'created': '2014-12-16 09:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/29a1d4b2023902e32f7cf3cf9cef312b8a38423c', 'message': 'Cleanup req_format in test_api_v2_resource\n\nSince XML support has been removed test cases in test_api_v2_resource\nno longer need to specify req_format to get a deserializer.\n\nChange-Id: Ic6572abc3121535e19d21e9a34d70bb42b9782de\nRelated-Bug: #1380787\n'}, {'number': 3, 'created': '2014-12-17 10:04:32.000000000', 'files': ['neutron/tests/unit/test_api_v2_resource.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d481cdd3d9ea07a31c2480286d9b7f247049ba5d', 'message': 'Cleanup req_format in test_api_v2_resource\n\nSince XML support has been removed test cases in test_api_v2_resource\nno longer need to specify req_format.\n\nChange-Id: Ic6572abc3121535e19d21e9a34d70bb42b9782de\nRelated-Bug: #1380787\n'}]",6,141785,d481cdd3d9ea07a31c2480286d9b7f247049ba5d,98,29,3,7293,,,0,"Cleanup req_format in test_api_v2_resource

Since XML support has been removed test cases in test_api_v2_resource
no longer need to specify req_format.

Change-Id: Ic6572abc3121535e19d21e9a34d70bb42b9782de
Related-Bug: #1380787
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/141785/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/test_api_v2_resource.py'],1,1be0c317cb94511199bc474ac451c53938af127a,bug/1380787, def _get_deserializer(): def test_unhandled_error(self): req_format='json') self._get_deserializer().deserialize(res.body)) def test_not_implemented_error(self): req_format='json') self._get_deserializer().deserialize(res.body))," def _get_deserializer(req_format): def _test_unhandled_error(self, req_format='json'): req_format=req_format) self._get_deserializer( req_format).deserialize(res.body)) def test_unhandled_error_with_json(self): self._test_unhandled_error() def _test_not_implemented_error(self, req_format='json'): req_format=req_format) self._get_deserializer( req_format).deserialize(res.body)) def test_not_implemented_error_with_json(self): self._test_not_implemented_error()",7,15
openstack%2Fneutron-specs~master~Iae70385f4743aa824c87195a91b3fa83596ae844,openstack/neutron-specs,master,Iae70385f4743aa824c87195a91b3fa83596ae844,Update the subnet allocation quota mechanism,MERGED,2014-12-16 21:48:32.000000000,2014-12-18 02:57:52.000000000,2014-12-18 02:57:51.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1689}, {'_account_id': 2592}, {'_account_id': 4187}, {'_account_id': 4656}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8351}]","[{'number': 1, 'created': '2014-12-16 21:48:32.000000000', 'files': ['specs/kilo/subnet-allocation.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/15493771a04da92bcf200bbb8e106515b40f7ec2', 'message': 'Update the subnet allocation quota mechanism\n\nAt the recent Neutron mid-cycle, we discussed using the absolute\nnumber of addresses for expressing IP allocation quota.  After\nspeaking with SMEs in IPv6 and user experience it seemed that this\nwould be a difficult way of handling these quotas.\n\nFirst, with IPv6 the numbers are just too large for normal integer\nfields.  Python seems to handle it gracefully but there are also\nconsiderations for databases too.  Even an unsigned BIGINT in mysql is\nnot large enough.  I will argue that this proposal is simpler from an\nimplementation perspective and shares all code between IP versions.\n\nSecond, it would require some complexity around the user experience\nfor IPv6.  This new proposal provides a *more* common experience to\nthe user since the numbers will be low enough to understand in both\ncases.  The only thing that the user will need to grok is the minimum\naddress unit for each version.  This should be spelled out clearly in\ndocumentation.\n\nDocImpact\n\nChange-Id: Iae70385f4743aa824c87195a91b3fa83596ae844\n'}]",7,142231,15493771a04da92bcf200bbb8e106515b40f7ec2,20,11,1,7448,,,0,"Update the subnet allocation quota mechanism

At the recent Neutron mid-cycle, we discussed using the absolute
number of addresses for expressing IP allocation quota.  After
speaking with SMEs in IPv6 and user experience it seemed that this
would be a difficult way of handling these quotas.

First, with IPv6 the numbers are just too large for normal integer
fields.  Python seems to handle it gracefully but there are also
considerations for databases too.  Even an unsigned BIGINT in mysql is
not large enough.  I will argue that this proposal is simpler from an
implementation perspective and shares all code between IP versions.

Second, it would require some complexity around the user experience
for IPv6.  This new proposal provides a *more* common experience to
the user since the numbers will be low enough to understand in both
cases.  The only thing that the user will need to grok is the minimum
address unit for each version.  This should be spelled out clearly in
documentation.

DocImpact

Change-Id: Iae70385f4743aa824c87195a91b3fa83596ae844
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/31/142231/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/subnet-allocation.rst'],1,15493771a04da92bcf200bbb8e106515b40f7ec2,subnet-allocation,"terms of the number of minimum atomically allocatable address units. To keep the math simple, the unit size will be hard-coded at /32 for IPv4 and /64 for IPv6. Counting the total number of addresses with IPv6 will make things cumbersome since even an unsigned 64 bit integer is not sufficient to express numbers this large. It would also require extra complexity around presentation in order to present these numbers to a user in a way that makes any sense at all. The implementation will share code between IP versions. The only difference will be the prefix size constant. The resource quotas are applied to is not the SubnetPool, but rather IP addresses. As such, the current quota engine is not able to perform this operation so management and enforcement should occur in a custom fashion.","terms of absolute number of IP addresses. The resource quotas are applied to is not the SubnetPool, but rather IP addresses. As such, the current quota engine is not able to perform this operation so management and enforcement should occur in a custom fashion.",12,4
openstack%2Fnova~master~Ia71963161966af3ca0e6e30e2245f12120f8f8d1,openstack/nova,master,Ia71963161966af3ca0e6e30e2245f12120f8f8d1,Adds support for versioned schema validation for microversions api,MERGED,2014-11-27 13:23:42.000000000,2014-12-18 02:57:34.000000000,2014-12-18 02:57:31.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-11-27 13:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c07c915ad55143ee583d882b9819422042c348ed', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 2, 'created': '2014-11-28 00:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06a1a20262e23e6fec4e78a335c1a568178cc660', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 3, 'created': '2014-11-28 04:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5252f81cce8c7b979ec024baaf92537d961ed28', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 4, 'created': '2014-11-29 11:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de104a70a9e0d178e6a3d517797463ad6d784c01', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 5, 'created': '2014-11-29 11:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8cf2556539e72fb592621f6c7f3f60c5762b881', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 6, 'created': '2014-12-01 03:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f6dd5026cbcd18ad234c64e39cf750510e1e9de0', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 7, 'created': '2014-12-02 00:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/469ce07266b0e8e4f3f7f7d14752d8b746e1df38', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 8, 'created': '2014-12-02 04:56:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/967bbf132b3ec4234412ea048dbc041a80936a68', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 9, 'created': '2014-12-02 06:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d08d0410e9a1d9ec12e8a1f08760119a956300b3', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 10, 'created': '2014-12-02 13:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9331117d9005059ca92c0a91292a605fb45fdb7e', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 11, 'created': '2014-12-05 01:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83b34d4a4210969270c5df1f926756b6de67fbb8', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 12, 'created': '2014-12-05 03:55:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/269176d0b17cbe92b8d123e0b5ce5c104ae7a5a8', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur throught the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 13, 'created': '2014-12-10 03:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0be9df98cda245f59ac68bcaca7594b3e7c03f43', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur through the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 14, 'created': '2014-12-10 07:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f65871563797bd642ad0ed2c648a26e8d29d196', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur through the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}, {'number': 15, 'created': '2014-12-17 03:01:16.000000000', 'files': ['nova/tests/unit/test_api_validation.py', 'nova/api/validation/__init__.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_access.py', 'nova/tests/unit/api/openstack/compute/contrib/test_attach_interfaces.py', 'nova/tests/unit/api/openstack/compute/test_microversions.py', 'nova/tests/unit/api/openstack/compute/contrib/test_agents.py', 'nova/tests/unit/api/openstack/compute/contrib/test_volumes.py', 'nova/tests/unit/api/openstack/compute/contrib/test_hosts.py', 'nova/tests/unit/api/openstack/compute/test_plugins/dummy_schema.py', 'nova/tests/unit/api/openstack/compute/plugins/v3/test_extended_volumes.py', 'nova/tests/unit/api/openstack/compute/contrib/test_server_external_events.py', 'nova/tests/unit/api/openstack/compute/test_plugins/microversions.py', 'nova/tests/unit/api/openstack/fakes.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1c7e985000ab4712261031fe4b800b58eb328e56', 'message': 'Adds support for versioned schema validation for microversions api\n\nAdds the ability to specify minimum and maximum API microversion\nversions on jsonschema validation decorators. Validation will\nonly occur through the decorator if the incoming request version\nmatches the version range specified. If no range is specified then\nvalidation will always occur.\n\nPartially implements blueprint api-microversions\n\nChange-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1\n'}]",17,137633,1c7e985000ab4712261031fe4b800b58eb328e56,123,14,15,5292,,,0,"Adds support for versioned schema validation for microversions api

Adds the ability to specify minimum and maximum API microversion
versions on jsonschema validation decorators. Validation will
only occur through the decorator if the incoming request version
matches the version range specified. If no range is specified then
validation will always occur.

Partially implements blueprint api-microversions

Change-Id: Ia71963161966af3ca0e6e30e2245f12120f8f8d1
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/137633/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/contrib/test_flavor_access.py', 'nova/tests/unit/api/openstack/compute/contrib/test_attach_interfaces.py', 'nova/tests/unit/api/openstack/compute/test_microversions.py', 'nova/tests/unit/api/openstack/compute/contrib/test_agents.py', 'nova/tests/unit/api/openstack/compute/contrib/test_hosts.py', 'nova/tests/unit/api/openstack/compute/plugins/v3/test_extended_volumes.py', 'nova/tests/unit/api/openstack/compute/contrib/test_server_external_events.py', 'nova/tests/unit/api/openstack/compute/test_plugins/microversions.py', 'nova/tests/unit/api/openstack/fakes.py', 'nova/tests/unit/test_api_validation.py', 'nova/api/validation/__init__.py']",11,c07c915ad55143ee583d882b9819422042c348ed,bp/api-microversions,"from nova.api.openstack import api_version_request as api_version from nova.api.validation import validators def schema(request_body_schema, min_version=None, max_version=None): schema_validator = validators._SchemaValidator(request_body_schema) min_ver = api_version.APIVersionRequest(min_version) max_ver = api_version.APIVersionRequest(max_version) # The request object is always the second argument. # However numerous unittests pass in the request object # via kwargs instead so we handle that as well. # TODO(cyeoh): clenaup unittests so we don't have to # to do this if 'req' in kwargs: ver = kwargs['req'].api_version_request else: ver = args[1].api_version_request if ver.matches(min_ver, max_ver): # Only validate against the schema if it lies within # the version range specified. Note that if both min # and max are not specified the validator will always # be run. schema_validator.validate(kwargs['body']) ",from validators import _SchemaValidator def schema(request_body_schema): schema_validator = _SchemaValidator(request_body_schema) schema_validator.validate(kwargs['body']),249,127
openstack%2Fironic~stable%2Fjuno~I809780fd6ba6cbe647656b4c6d1f9a1cdac596bd,openstack/ironic,stable/juno,I809780fd6ba6cbe647656b4c6d1f9a1cdac596bd,Updated from global requirements,MERGED,2014-12-14 00:11:21.000000000,2014-12-18 02:57:06.000000000,2014-12-18 02:57:05.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 6618}, {'_account_id': 7491}, {'_account_id': 8106}, {'_account_id': 10343}, {'_account_id': 12081}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-14 00:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4ce3f8ec5fbf1a3bb392be8983dbb3962ad46f2b', 'message': 'Updated from global requirements\n\nChange-Id: I809780fd6ba6cbe647656b4c6d1f9a1cdac596bd\n'}, {'number': 2, 'created': '2014-12-16 14:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0ee9ce4ec6175721be89d008789d996dbe92cff4', 'message': 'Updated from global requirements\n\nChange-Id: I809780fd6ba6cbe647656b4c6d1f9a1cdac596bd\n'}, {'number': 3, 'created': '2014-12-16 23:03:29.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/96177e71dcb21777471a2f6bf1b08da80ecc4962', 'message': 'Updated from global requirements\n\nChange-Id: I809780fd6ba6cbe647656b4c6d1f9a1cdac596bd\n'}]",1,141598,96177e71dcb21777471a2f6bf1b08da80ecc4962,28,10,3,11131,,,0,"Updated from global requirements

Change-Id: I809780fd6ba6cbe647656b4c6d1f9a1cdac596bd
",git fetch https://review.opendev.org/openstack/ironic refs/changes/98/141598/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4ce3f8ec5fbf1a3bb392be8983dbb3962ad46f2b,openstack/requirements,"SQLAlchemy>=0.8.4,<=0.9.99,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,!=0.9.4,!=0.9.5,!=0.9.6","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",1,1
openstack%2Fnova~master~I66e68ec120cba2cee86e36aa26720199876c40a4,openstack/nova,master,I66e68ec120cba2cee86e36aa26720199876c40a4,Use oslo db concurrency to generate nova.conf.sample,MERGED,2014-11-14 21:01:28.000000000,2014-12-18 02:56:49.000000000,2014-12-18 02:56:46.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-14 21:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fc8c7183e38aad3feb511757fa6330d0717611d', 'message': 'Use oslo.db to generate nova.conf.sample\n\nMake sure we include database options in the sample config file.\n\nChange-Id: I66e68ec120cba2cee86e36aa26720199876c40a4\nCloses-Bug: #1391782\n'}, {'number': 2, 'created': '2014-12-15 20:08:48.000000000', 'files': ['tools/config/oslo.config.generator.rc'], 'web_link': 'https://opendev.org/openstack/nova/commit/6859dd61a8472e0cf8f9f4d30f1da7312dc0385d', 'message': 'Use oslo db concurrency to generate nova.conf.sample\n\nMake sure we include database and concurrency options in the\nsample config file.\n\nChange-Id: I66e68ec120cba2cee86e36aa26720199876c40a4\nCloses-Bug: #1391782\n'}]",0,134645,6859dd61a8472e0cf8f9f4d30f1da7312dc0385d,28,11,2,1849,,,0,"Use oslo db concurrency to generate nova.conf.sample

Make sure we include database and concurrency options in the
sample config file.

Change-Id: I66e68ec120cba2cee86e36aa26720199876c40a4
Closes-Bug: #1391782
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/134645/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/config/oslo.config.generator.rc'],1,4fc8c7183e38aad3feb511757fa6330d0717611d,bug/1391782,"NOVA_CONFIG_GENERATOR_EXTRA_LIBRARIES=""oslo.messaging oslo.db""",NOVA_CONFIG_GENERATOR_EXTRA_LIBRARIES=oslo.messaging,1,1
openstack%2Fkeystone~master~Ib78132093cc0ab9b964013b20734ada1039f0679,openstack/keystone,master,Ib78132093cc0ab9b964013b20734ada1039f0679,Update docs to no longer show XML support,MERGED,2014-10-02 20:01:04.000000000,2014-12-18 02:56:02.000000000,2014-12-18 02:56:01.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 9142}, {'_account_id': 9751}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-10-02 20:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/37e0b167c139646b7370ad526ebdccef25da701c', 'message': 'Update docs to no longer show XML support\n\nimplements bp removed-as-of-kilo\n\nChange-Id: Ib78132093cc0ab9b964013b20734ada1039f0679\n'}, {'number': 2, 'created': '2014-10-06 05:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b8c12259adcf6e2d1312b49264a7c9fbaa8edfb3', 'message': 'Update docs to no longer show XML support\n\nimplements bp removed-as-of-kilo\n\nChange-Id: Ib78132093cc0ab9b964013b20734ada1039f0679\n'}, {'number': 3, 'created': '2014-10-23 05:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bde102fc3bcead98f994a567342e1698f46bbf2f', 'message': 'Update docs to no longer show XML support\n\nimplements bp removed-as-of-kilo\n\nChange-Id: Ib78132093cc0ab9b964013b20734ada1039f0679\n'}, {'number': 4, 'created': '2014-10-27 23:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1a19c682dfbed9c02f52d339e949537a0a182a11', 'message': 'Update docs to no longer show XML support\n\nimplements bp removed-as-of-kilo\n\nChange-Id: Ib78132093cc0ab9b964013b20734ada1039f0679\n'}, {'number': 5, 'created': '2014-10-28 18:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dfed72b2f26b0761592af789697a2de8db8bda60', 'message': 'Update docs to no longer show XML support\n\nimplements bp removed-as-of-kilo\n\nChange-Id: Ib78132093cc0ab9b964013b20734ada1039f0679\n'}, {'number': 6, 'created': '2014-11-27 03:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/540bfb8441d90e7d060bf20958ec48140812a1a3', 'message': 'Update docs to no longer show XML support\n\nimplements bp removed-as-of-kilo\n\nChange-Id: Ib78132093cc0ab9b964013b20734ada1039f0679\n'}, {'number': 7, 'created': '2014-12-02 14:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/66a3b51a595622d8f599f7a29bfd954a8e3f48f3', 'message': 'Update docs to no longer show XML support\n\nimplements bp removed-as-of-kilo\n\nChange-Id: Ib78132093cc0ab9b964013b20734ada1039f0679\n'}, {'number': 8, 'created': '2014-12-08 02:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/51309c9fb558d7ae528c3e936c19146593f63066', 'message': 'Update docs to no longer show XML support\n\nimplements bp removed-as-of-kilo\n\nChange-Id: Ib78132093cc0ab9b964013b20734ada1039f0679\n'}, {'number': 9, 'created': '2014-12-14 00:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/94825a7361959af0cbd0efe514f0d2baa535f8b5', 'message': 'Update docs to no longer show XML support\n\nimplements bp removed-as-of-kilo\n\nChange-Id: Ib78132093cc0ab9b964013b20734ada1039f0679\n'}, {'number': 10, 'created': '2014-12-17 03:51:40.000000000', 'files': ['doc/source/extensions/endpoint_policy.rst', 'doc/source/architecture.rst', 'doc/source/configuration.rst', 'doc/source/external-auth.rst', 'doc/source/extensions/revoke.rst', 'doc/source/api_curl_examples.rst', 'doc/source/extensions/endpoint_filter.rst', 'doc/source/extensions/federation.rst', 'doc/source/extensions/oauth1.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/5d376ba9ad80af5663e263c07bc912b1f4e5931e', 'message': 'Update docs to no longer show XML support\n\nimplements bp removed-as-of-kilo\n\nChange-Id: Ib78132093cc0ab9b964013b20734ada1039f0679\n'}]",2,125753,5d376ba9ad80af5663e263c07bc912b1f4e5931e,34,10,10,6482,,,0,"Update docs to no longer show XML support

implements bp removed-as-of-kilo

Change-Id: Ib78132093cc0ab9b964013b20734ada1039f0679
",git fetch https://review.opendev.org/openstack/keystone refs/changes/53/125753/7 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/extensions/endpoint_policy.rst', 'doc/source/architecture.rst', 'doc/source/configuration.rst', 'doc/source/extensions/revoke.rst', 'doc/source/external-auth.rst', 'doc/source/api_curl_examples.rst', 'doc/source/extensions/endpoint_filter.rst', 'doc/source/extensions/federation.rst', 'doc/source/extensions/oauth1.rst', 'doc/source/setup.rst']",10,37e0b167c139646b7370ad526ebdccef25da701c,bp/removed-as-of-kilo, $ sudo apt-get install python-dev libxslt1-dev libsasl2-dev libsqlite3-dev libssl-dev libldap2-dev libffi-dev $ sudo yum install python-sqlite2 python-greenlet-devel python-ldap sqlite-devel openldap-devel python-devel libxslt-devel openssl-devel $ brew install python openssl gettext, $ sudo apt-get install python-dev libxml2-dev libxslt1-dev libsasl2-dev libsqlite3-dev libssl-dev libldap2-dev libffi-dev $ sudo yum install python-sqlite2 python-lxml python-greenlet-devel python-ldap sqlite-devel openldap-devel python-devel libxslt-devel openssl-devel $ brew install python openssl gettext libxmlsec1,12,16
openstack%2Ftempest~master~I6e7797a5dd60da8e5c69caab2224ab27add8a2f4,openstack/tempest,master,I6e7797a5dd60da8e5c69caab2224ab27add8a2f4,Do not test the maxImageMeta limit when there is no limit,MERGED,2014-12-08 16:31:18.000000000,2014-12-18 02:55:05.000000000,2014-12-18 02:55:04.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5174}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-08 16:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/234467c7c3bca5072da2284d9cd67e986c166fcd', 'message': 'Do not test the maxImageMeta limit when there is no limit\n\nChange-Id: I6e7797a5dd60da8e5c69caab2224ab27add8a2f4\nCloses-Bug: #1400383\n'}, {'number': 2, 'created': '2014-12-09 11:07:43.000000000', 'files': ['tempest/api/compute/limits/test_absolute_limits_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b87b817b92e277525afd2b9f40c00b93b6f2d8ef', 'message': 'Do not test the maxImageMeta limit when there is no limit\n\nChange-Id: I6e7797a5dd60da8e5c69caab2224ab27add8a2f4\nCloses-Bug: #1400383\n'}]",1,140068,b87b817b92e277525afd2b9f40c00b93b6f2d8ef,13,6,2,8122,,,0,"Do not test the maxImageMeta limit when there is no limit

Change-Id: I6e7797a5dd60da8e5c69caab2224ab27add8a2f4
Closes-Bug: #1400383
",git fetch https://review.opendev.org/openstack/tempest refs/changes/68/140068/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/limits/test_absolute_limits_negative.py'],1,234467c7c3bca5072da2284d9cd67e986c166fcd,bug/1400383, # No point in running this test if there is no limit. if int(max_meta) == -1: return ,,4,0
openstack%2Fpbr~feature%2F0.10~I553a0bf9f522d50bcbdb16756c994058bd27da77,openstack/pbr,feature/0.10,I553a0bf9f522d50bcbdb16756c994058bd27da77,Use post version signifiers,MERGED,2014-12-17 05:44:49.000000000,2014-12-18 02:54:52.000000000,2014-12-18 02:54:52.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7687}]","[{'number': 1, 'created': '2014-12-17 05:44:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/2e6496f51815f2afc280274b1828a2287b353a16', 'message': 'Use post version signifiers\n\nPEP440 is unhappy about revcounts after pre-release tags.\n\nChange-Id: I553a0bf9f522d50bcbdb16756c994058bd27da77\n'}, {'number': 2, 'created': '2014-12-17 17:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/9ad2af07b84b2e89e2907c200e1cf56c2dcae81a', 'message': 'Use post version signifiers\n\nPEP440 is unhappy about revcounts after pre-release tags.\n\nChange-Id: I553a0bf9f522d50bcbdb16756c994058bd27da77\n'}, {'number': 3, 'created': '2014-12-17 21:54:55.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/5dd31ac46b8b5b7d3b0e1fb123f653ac915eeac6', 'message': 'Use post version signifiers\n\nPEP440 is unhappy about revcounts after pre-release tags.\n\nChange-Id: I553a0bf9f522d50bcbdb16756c994058bd27da77\n'}]",0,142351,5dd31ac46b8b5b7d3b0e1fb123f653ac915eeac6,13,5,3,2,,,0,"Use post version signifiers

PEP440 is unhappy about revcounts after pre-release tags.

Change-Id: I553a0bf9f522d50bcbdb16756c994058bd27da77
",git fetch https://review.opendev.org/openstack/pbr refs/changes/51/142351/3 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,2e6496f51815f2afc280274b1828a2287b353a16,142351," return ""0.0.0.post%s"" % _get_revno(git_dir) # Finally, if we convert - to .post, which will turn the remaining # - which separates the version from the revcount into a PEP440 # post string return stripped_version.replace('-', '.post')"," return ""0.0.0.%s"" % _get_revno(git_dir) # Finally, if we convert - to ., we'll get the version we want return stripped_version.replace('-', '.')",5,3
openstack%2Fpbr~feature%2F0.10~I79d67bf41a09d7e5aad8ed32eaf107f139167eb8,openstack/pbr,feature/0.10,I79d67bf41a09d7e5aad8ed32eaf107f139167eb8,Only import sphinx during hook processing,MERGED,2014-12-17 19:42:17.000000000,2014-12-18 02:54:37.000000000,2014-12-18 02:54:36.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7687}]","[{'number': 1, 'created': '2014-12-17 19:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/7cbdfcfa0e4c31ee3af824b6bbda03cbf5465aa6', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a\nsystem with pbr installed. If some of the imports fail along the way,\nallow pbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those extensions\nwill work again when the commands for build_sphinx, etc. are run\nseparately.\n\nChange-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8\nCloses-bug: #1403510\n""}, {'number': 2, 'created': '2014-12-17 20:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/6c370f4a569a0026762d9c423ed0fbfc9bde1b74', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a\nsystem with pbr installed. If some of the imports fail along the way,\nallow pbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those extensions\nwill work again when the commands for build_sphinx, etc. are run\nseparately.\n\nChange-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8\nCloses-bug: #1403510\n""}, {'number': 3, 'created': '2014-12-17 21:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/2ddc0ad9a866ad445eb5ab58adcdc0b54c30b93e', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a\nsystem with pbr installed. If some of the imports fail along the way,\nallow pbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those extensions\nwill work again when the commands for build_sphinx, etc. are run\nseparately.\n\nAlso slip in a change to reorder the default list of environments run by\ntox so the testr database is created using a dbm format available to all\npython versions.\n\nChange-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8\nCloses-bug: #1403510\n""}, {'number': 4, 'created': '2014-12-17 21:29:25.000000000', 'files': ['pbr/packaging.py', 'pbr/tests/base.py', 'pbr/util.py', 'pbr/builddoc.py', 'pbr/hooks/commands.py', 'pbr/options.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/pbr/commit/65f4fafd907a16ea1952ab7072676db2e9e0c51d', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a\nsystem with pbr installed. If some of the imports fail along the way,\nallow pbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those extensions\nwill work again when the commands for build_sphinx, etc. are run\nseparately.\n\nAlso slip in a change to reorder the default list of environments run by\ntox so the testr database is created using a dbm format available to all\npython versions.\n\nChange-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8\nCloses-bug: #1403510\n""}]",2,142561,65f4fafd907a16ea1952ab7072676db2e9e0c51d,13,6,4,2472,,,0,"Only import sphinx during hook processing

When pbr is imported to handle writing the egg_info file because of
the entry point, it's causing sphinx to get imported. This has a
cascading effect once docutils is trying to be installed on a
system with pbr installed. If some of the imports fail along the way,
allow pbr to continue usefully but without the Sphinx extensions
available. Eventually, when everything is installed, those extensions
will work again when the commands for build_sphinx, etc. are run
separately.

Also slip in a change to reorder the default list of environments run by
tox so the testr database is created using a dbm format available to all
python versions.

Change-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8
Closes-bug: #1403510
",git fetch https://review.opendev.org/openstack/pbr refs/changes/61/142561/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/packaging.py', 'pbr/tests/base.py', 'pbr/util.py', 'pbr/builddoc.py', 'pbr/hooks/commands.py', 'pbr/options.py']",6,7cbdfcfa0e4c31ee3af824b6bbda03cbf5465aa6,bug/1403510,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # # Copyright (C) 2013 Association of Universities for Research in Astronomy # (AURA) # # Redistribution and use in source and binary forms, with or without # modification, are permitted provided that the following conditions are met: # # 1. Redistributions of source code must retain the above copyright # notice, this list of conditions and the following disclaimer. # # 2. Redistributions in binary form must reproduce the above # copyright notice, this list of conditions and the following # disclaimer in the documentation and/or other materials provided # with the distribution. # # 3. The name of AURA and its representatives may not be used to # endorse or promote products derived from this software without # specific prior written permission. # # THIS SOFTWARE IS PROVIDED BY AURA ``AS IS'' AND ANY EXPRESS OR IMPLIED # WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF # MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE # DISCLAIMED. IN NO EVENT SHALL AURA BE LIABLE FOR ANY DIRECT, INDIRECT, # INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, # BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS import os TRUE_VALUES = ('true', '1', 'yes') def get_boolean_option(option_dict, option_name, env_name): return ((option_name in option_dict and option_dict[option_name][1].lower() in TRUE_VALUES) or str(os.getenv(env_name)).lower() in TRUE_VALUES) ",,242,171
openstack%2Fheat-templates~master~I6ba7468b46ca8cfad1e58207cd3f814a178ff6f1,openstack/heat-templates,master,I6ba7468b46ca8cfad1e58207cd3f814a178ff6f1,Break out signalling heat-config-notify command,MERGED,2014-12-12 01:38:20.000000000,2014-12-18 02:38:16.000000000,2014-12-18 02:38:15.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7193}]","[{'number': 1, 'created': '2014-12-12 01:38:20.000000000', 'files': ['hot/software-config/elements/heat-config/os-refresh-config/configure.d/55-heat-config', 'hot/software-config/elements/heat-config/bin/heat-config-notify', 'tests/software_config/test_heat_config_notify.py', 'tests/software_config/heat_config_notify.py', 'tests/software_config/test_heat_config.py'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/25c4759fe0ef1db422df7fbcc55cebbdaecec3e7', 'message': 'Break out signalling heat-config-notify command\n\nCurrently signalling heat is done in a chunk of python at the end\nof 55-heat-config. This change moves the signalling to its own\ncommand heat-config-notify, which can be called from 55-heat-config\nor anything else which wants to signal heat.\n\nThis change also adds proper test coverage to the signalling logic.\n\nChange-Id: I6ba7468b46ca8cfad1e58207cd3f814a178ff6f1\n'}]",0,141239,25c4759fe0ef1db422df7fbcc55cebbdaecec3e7,7,3,1,4571,,,0,"Break out signalling heat-config-notify command

Currently signalling heat is done in a chunk of python at the end
of 55-heat-config. This change moves the signalling to its own
command heat-config-notify, which can be called from 55-heat-config
or anything else which wants to signal heat.

This change also adds proper test coverage to the signalling logic.

Change-Id: I6ba7468b46ca8cfad1e58207cd3f814a178ff6f1
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/39/141239/1 && git format-patch -1 --stdout FETCH_HEAD,"['hot/software-config/elements/heat-config/os-refresh-config/configure.d/55-heat-config', 'hot/software-config/elements/heat-config/bin/heat-config-notify', 'tests/software_config/test_heat_config_notify.py', 'tests/software_config/heat_config_notify.py', 'tests/software_config/test_heat_config.py']",5,25c4759fe0ef1db422df7fbcc55cebbdaecec3e7,heat-config-kubelet, def test_run_heat_config(self):,"import requests_mock @requests_mock.Mocker(kw='mock_request') def test_run_heat_config(self, mock_request): mock_request.register_uri('POST', 'mock://192.0.2.2/foo') mock_request.register_uri('POST', 'mock://192.0.2.3/foo')",332,61
openstack%2Frally~master~Ia382734af7b613608a901c21a85136c9e491589f,openstack/rally,master,Ia382734af7b613608a901c21a85136c9e491589f,Fix cli tests vs MOS clouds,MERGED,2014-12-17 15:28:28.000000000,2014-12-18 02:32:22.000000000,2014-12-18 02:32:20.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-17 15:28:28.000000000', 'files': ['tests/functional/test_cli_show.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/7caafc4cdee2309e879ed28ab629dd7224d43e4c', 'message': 'Fix cli tests vs MOS clouds\n\nMOS clouds have ""TestVM"" image and ""novanetwork"" network by default.\n\nChange-Id: Ia382734af7b613608a901c21a85136c9e491589f\n'}]",0,142465,7caafc4cdee2309e879ed28ab629dd7224d43e4c,8,4,1,7369,,,0,"Fix cli tests vs MOS clouds

MOS clouds have ""TestVM"" image and ""novanetwork"" network by default.

Change-Id: Ia382734af7b613608a901c21a85136c9e491589f
",git fetch https://review.opendev.org/openstack/rally refs/changes/65/142465/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/functional/test_cli_show.py'],1,7caafc4cdee2309e879ed28ab629dd7224d43e4c,ecli_mos," cirros = ""cirros"" in res testvm = ""TestVM"" in res self.assertTrue(cirros or testvm) private = ""private"" in res novanetwork = ""novanetwork"" in res self.assertTrue(private or novanetwork)"," self.assertIn(""cirros"", res) self.assertIn(""private"", res)",6,2
openstack%2Fnova-specs~master~I489ab606341ed406024fff0c7e302fc158d20be2,openstack/nova-specs,master,I489ab606341ed406024fff0c7e302fc158d20be2,Propose Isolate Scheduler DB for Aggregates,MERGED,2014-04-23 16:29:50.000000000,2014-12-18 02:27:30.000000000,2014-12-18 02:27:29.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 819}, {'_account_id': 1063}, {'_account_id': 1501}, {'_account_id': 1849}, {'_account_id': 1981}, {'_account_id': 2033}, {'_account_id': 2468}, {'_account_id': 4393}, {'_account_id': 4491}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 7461}, {'_account_id': 7494}, {'_account_id': 7641}, {'_account_id': 8514}, {'_account_id': 8690}, {'_account_id': 9275}, {'_account_id': 9407}, {'_account_id': 9555}, {'_account_id': 10937}]","[{'number': 1, 'created': '2014-04-23 16:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1098f19fa86ea33c43fe535bd06eb47e4fd8236e', 'message': 'Propose Isolate Scheduler DB blueprint\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 2, 'created': '2014-04-23 16:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0c41260ba56cceafaf4a2f1f09af67a38c159101', 'message': 'Propose Isolate Scheduler DB blueprint\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 3, 'created': '2014-04-23 16:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e2893c8a34b7828a4014039df093ab37c45b0f0a', 'message': 'Propose Isolate Scheduler DB\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 4, 'created': '2014-04-28 15:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/05dc7e9d2e931eed0439e21257918c30036b38bd', 'message': 'Propose Isolate Scheduler DB\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 5, 'created': '2014-05-06 10:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/17e279ca282594cb3f7999965e005258859f02cf', 'message': 'Propose Isolate Scheduler DB\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 6, 'created': '2014-05-26 14:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/144aba6a6422d411733ee06597ba8f4329c7523e', 'message': 'Propose Isolate Scheduler DB\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 7, 'created': '2014-07-04 17:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e07609ba4069d143593c6c1811ae0cf41d50c5e7', 'message': 'Propose Isolate Scheduler DB\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 8, 'created': '2014-07-04 20:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/98d84bb7a361841e1d1e2a3d7308995b86c5d9ca', 'message': 'Propose Isolate Scheduler DB\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 9, 'created': '2014-07-23 14:51:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2d17bd8f872cf871c326c3b596b7a8b166f080e4', 'message': 'Propose Isolate Scheduler DB\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 10, 'created': '2014-07-25 13:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4cc4e34ab2d8eecdd16dff6fd14cda6260d9094d', 'message': 'Propose Isolate Scheduler DB\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 11, 'created': '2014-07-25 15:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/938f817099abcb8a188d35f453fa408f506b8151', 'message': 'Propose Isolate Scheduler DB\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 12, 'created': '2014-10-16 10:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/81f8db68b1c1b900fecc2a2329d148af92f7182d', 'message': 'Propose Isolate Scheduler DB\n\nIdentifies work to do on scheduler for reducing dependencies to other\nNova objects in order to prepare scheduler forklift.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 13, 'created': '2014-11-03 15:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/67636a7432ca94bc167f73a0e3a0f7e3b55c2e61', 'message': 'Propose Isolate Scheduler DB for Aggregates\n\nDefines a clear way on how to update HostState thru a new RPCAPI endpoint.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 14, 'created': '2014-11-10 09:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2725fbff6277c2378c6385012b181ed9b41e4d37', 'message': 'Propose Isolate Scheduler DB for Aggregates\n\nDefines a clear way on how to update HostState thru a new RPCAPI endpoint.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 15, 'created': '2014-11-10 09:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/df926d9abc7d6e2dedac4ec2c4ac241aa8b14970', 'message': 'Propose Isolate Scheduler DB for Aggregates\n\nDefines a clear way on how to update HostState thru a new RPCAPI endpoint.\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 16, 'created': '2014-12-05 11:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/61f7e407de9c3a90b0b1733b8dd61e599514c3ff', 'message': 'Propose Isolate Scheduler DB for Aggregates\n\nDefines a clear way on how to get Aggregate information from the filters\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 17, 'created': '2014-12-16 14:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/65a2fa5bf8d5c17158b103dbd9893ba0173826dc', 'message': 'Propose Isolate Scheduler DB for Aggregates\n\nDefines a clear way on how to get Aggregate information from the filters\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 18, 'created': '2014-12-17 16:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/762536c4e0bcd8121b9f6310ad0c6114c4030c2f', 'message': 'Propose Isolate Scheduler DB for Aggregates\n\nDefines a clear way on how to get Aggregate information from the filters\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 19, 'created': '2014-12-17 17:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b7ac10cdf6e24dfefbd0159788d6229422c48dba', 'message': 'Propose Isolate Scheduler DB for Aggregates\n\nDefines a clear way on how to get Aggregate information from the filters\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}, {'number': 20, 'created': '2014-12-18 01:31:24.000000000', 'files': ['specs/kilo/approved/isolate-scheduler-db-aggregates.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f942d221d27eba7b96442ea76a402bca46240234', 'message': 'Propose Isolate Scheduler DB for Aggregates\n\nDefines a clear way on how to get Aggregate information from the filters\n\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I489ab606341ed406024fff0c7e302fc158d20be2\n'}]",149,89893,f942d221d27eba7b96442ea76a402bca46240234,158,23,20,7166,,,0,"Propose Isolate Scheduler DB for Aggregates

Defines a clear way on how to get Aggregate information from the filters

Implements: blueprint isolate-scheduler-db

Change-Id: I489ab606341ed406024fff0c7e302fc158d20be2
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/93/89893/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/isolate-scheduler-db.rst'],1,1098f19fa86ea33c43fe535bd06eb47e4fd8236e,bp/isolate-scheduler-db,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================== Isolate Scheduler Database ========================== https://blueprints.launchpad.net/nova/+spec/isolate-scheduler-db We want to split out nova-scheduler into gantt. To do this, we need to isolate the scheduler from the rest of nova. In this blueprint, we need to isolate all accesses to the database that Scheduler is doing and refactor code (manager, filters, weighters) so that scheduler is only internally accessing scheduler-related tables. Note : this blueprint is targeted for Juno-2. Problem description =================== Within scheduler code, some accesses are done to other DB tables like host aggregates or instances thanks to either API, conductor or SQLAlchemy directly. We need to figure out all the direct calls to these elements and refactor how resources are provided so that scheduler won't lookup at them directly. This change in approach for the gantt project was agreed at the Nova Icehouse mid-cycle meetup: https://etherpad.openstack.org/p/icehouse-external-scheduler Proposed change =============== The basic points to note about this change are: * No change in behaviour. This is just a refactor. * At the moment of writing this spec, only aggregates and instances accesses are subject to change. * We consider accesses to services table, vm_state, vm_mode modules and servicegroup API as being part of the scheduler for the moment. 1. Regarding accesses to aggregates table, the change we propose can be divided in two parts : - modify ResourceTracker update_available_resource so that it provides to scheduler the list of aggregates the host belongs to, as part of the RT stats (thanks to extensible RT blueprint) - update scheduler filters so that it looks into compute_nodes table instead of querying DB 2. Regarding accesses to instances (Affinity, Trusted, TypeAffinity filters), we will provide full list of instances as filter property when calling select_destinations. Alternatives ------------ The other alternative would be to fork the scheduler code at a point in time to a separate Git repository, do the necessary changes within the code (unittests, imports). However neither syncing changes or having a code freeze on nova-scheduler seem like the best approach. Data model impact ----------------- None, we rely on extensible RT blueprint for storing extra values. REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None. Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Ideally: * Filters should no longer place calls to other bits of code except Scheduler Implementation ============== Assignee(s) ----------- Primary assignee: sylvain-bauza Other contributors: None Work Items ---------- * Modify RT update_resource_stats to include aggregates info as extensible resource * Refactoring of filters to make use of stats for aggregates * Pass list of instances as filter property on select_destinations() * Refactoring of filters by using filter_properties for list of instances Dependencies ============ * https://review.openstack.org/#/c/86050/ (bp/extensible-resource-tracking) Testing ======= Covered by existing tempest tests and CIs. Documentation Impact ==================== None References ========== * Other effort related to RT using objects is not mandatory for this blueprint but both efforts can mutally benefit https://blueprints.launchpad.net/nova/+spec/make-resource-tracker-use-objects (pmurray) * Cast to scheduler for running instances is mandatory for the Gantt forklift but not for this blueprint https://blueprints.launchpad.net/nova/+spec/remove-cast-to-schedule-run-instance (alaski) * https://etherpad.openstack.org/p/icehouse-external-scheduler * http://eavesdrop.openstack.org/meetings/gantt/2014/gantt.2014-03-18-15.00.html ",,181,0
openstack%2Ftempest~master~I5c8dbb7954238b701eab95fecbe401f763df8381,openstack/tempest,master,I5c8dbb7954238b701eab95fecbe401f763df8381,Add ServerFault exception in test_instance_usage_audit_log_negative,ABANDONED,2014-12-03 06:11:57.000000000,2014-12-18 02:17:26.000000000,,"[{'_account_id': 3}, {'_account_id': 7930}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 13663}]","[{'number': 1, 'created': '2014-12-03 06:11:57.000000000', 'files': ['tempest/api/compute/admin/test_instance_usage_audit_log_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/04720d427b1edecb07f5ec8a6369716fef7239bc', 'message': 'Add ServerFault exception in test_instance_usage_audit_log_negative\n\nexception return code changed between V2 and V2.1 for nova api, we\nneed to update the changes into tempest.\nchanges: add ServerFault\n\nChange-Id: I5c8dbb7954238b701eab95fecbe401f763df8381\n'}]",1,138638,04720d427b1edecb07f5ec8a6369716fef7239bc,8,5,1,13663,,,0,"Add ServerFault exception in test_instance_usage_audit_log_negative

exception return code changed between V2 and V2.1 for nova api, we
need to update the changes into tempest.
changes: add ServerFault

Change-Id: I5c8dbb7954238b701eab95fecbe401f763df8381
",git fetch https://review.opendev.org/openstack/tempest refs/changes/38/138638/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_instance_usage_audit_log_negative.py'],1,04720d427b1edecb07f5ec8a6369716fef7239bc,br-instance-usage-audit-log-negtive," self.assertRaises((exceptions.Unauthorized, exceptions.ServerFault), self.assertRaises((exceptions.Unauthorized, exceptions.ServerFault),"," self.assertRaises(exceptions.Unauthorized, self.assertRaises(exceptions.Unauthorized,",4,2
openstack%2Fbarbican~master~I017bb6d85f4dea6b20926f825227f46b3c6f0942,openstack/barbican,master,I017bb6d85f4dea6b20926f825227f46b3c6f0942,Use keystone v3 credentials for functional tests,MERGED,2014-12-16 23:04:35.000000000,2014-12-18 02:08:03.000000000,2014-12-18 02:08:02.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-12-16 23:04:35.000000000', 'files': ['functionaltests/common/client.py', 'functionaltests/api/base.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/27c1b15df1d9d1a244c854f854b96e5defb90c87', 'message': 'Use keystone v3 credentials for functional tests\n\nChange-Id: I017bb6d85f4dea6b20926f825227f46b3c6f0942\nPartially implements: blueprint replace-concept-of-tenants-for-projects\n'}]",2,142254,27c1b15df1d9d1a244c854f854b96e5defb90c87,17,13,1,10873,,,0,"Use keystone v3 credentials for functional tests

Change-Id: I017bb6d85f4dea6b20926f825227f46b3c6f0942
Partially implements: blueprint replace-concept-of-tenants-for-projects
",git fetch https://review.opendev.org/openstack/barbican refs/changes/54/142254/1 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/common/client.py', 'functionaltests/api/base.py']",2,27c1b15df1d9d1a244c854f854b96e5defb90c87,bp/replace-concept-of-tenants-for-projects,class BarbicanCredentials(auth.KeystoneV3Credentials): project_name=CONF.identity.admin_tenant_name,class BarbicanCredentials(auth.KeystoneV2Credentials): tenant_name=CONF.identity.admin_tenant_name,4,4
openstack%2Fbarbican~master~I9aba97771b97d1e7ce0fba0edf974a6a1adfe3a0,openstack/barbican,master,I9aba97771b97d1e7ce0fba0edf974a6a1adfe3a0,Removing conditional logic around KMIP tests,MERGED,2014-12-16 13:14:28.000000000,2014-12-18 02:07:52.000000000,2014-12-18 02:07:51.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 6783}, {'_account_id': 7063}, {'_account_id': 7136}, {'_account_id': 7789}, {'_account_id': 8623}]","[{'number': 1, 'created': '2014-12-16 13:14:28.000000000', 'files': ['barbican/tests/plugin/test_kmip.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/6c6ef25559c156d41c9c4c5a72c84c09339ade8e', 'message': 'Removing conditional logic around KMIP tests\n\n- This is not needed anymore now that pykmip is in test requirments\n\nChange-Id: I9aba97771b97d1e7ce0fba0edf974a6a1adfe3a0\n'}]",1,142096,6c6ef25559c156d41c9c4c5a72c84c09339ade8e,11,7,1,11716,,,0,"Removing conditional logic around KMIP tests

- This is not needed anymore now that pykmip is in test requirments

Change-Id: I9aba97771b97d1e7ce0fba0edf974a6a1adfe3a0
",git fetch https://review.opendev.org/openstack/barbican refs/changes/96/142096/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/tests/plugin/test_kmip.py'],1,6c6ef25559c156d41c9c4c5a72c84c09339ade8e,kmip-tests,from kmip.core import attributes as attr from kmip.core import enums from kmip.core.factories import attributes from kmip.core.factories import secrets from kmip.core.messages import contents from kmip.core import objects from kmip.services import kmip_client as proxy from kmip.services import results from barbican.plugin import kmip_secret_store as kss ,"import testtoolstry: from kmip.core import attributes as attr from kmip.core import enums from kmip.core.factories import attributes from kmip.core.factories import secrets from kmip.core.messages import contents from kmip.core import objects from kmip.services import kmip_client as proxy from kmip.services import results from barbican.plugin import kmip_secret_store as kss kmip_available = True except ImportError: kmip_available = False @testtools.skipIf(not kmip_available, ""KMIP imports not available"")",9,15
openstack%2Fcongress~master~I0acbcdd2e5bd079faf648bf53c0dad5707a422a8,openstack/congress,master,I0acbcdd2e5bd079faf648bf53c0dad5707a422a8,Add tempest code coverage for keystone driver,MERGED,2014-12-17 07:09:41.000000000,2014-12-18 01:38:41.000000000,2014-12-18 01:38:40.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}, {'_account_id': 13664}]","[{'number': 1, 'created': '2014-12-17 07:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/1f035682e84ea7acf15b15bd098d76bf46afe7d9', 'message': 'Add tempest code coverage for keystone driver\n\nChange-Id: I0acbcdd2e5bd079faf648bf53c0dad5707a422a8\nCloses-Bug: 1376479\n'}, {'number': 2, 'created': '2014-12-17 22:34:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/cce74848b2a4ff105c0d5a5af1a8adb9f27464e7', 'message': 'Add tempest code coverage for keystone driver\n\nChange-Id: I0acbcdd2e5bd079faf648bf53c0dad5707a422a8\nCloses-Bug: 1376479\n'}, {'number': 3, 'created': '2014-12-17 22:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/dc35c10f445f52b036f9705fa43fff3e8521f600', 'message': 'Add tempest code coverage for keystone driver\n\nChange-Id: I0acbcdd2e5bd079faf648bf53c0dad5707a422a8\nCloses-Bug: 1376479\n'}, {'number': 4, 'created': '2014-12-17 22:42:39.000000000', 'files': ['contrib/tempest/tempest/scenario/congress_datasources/test_keystonev2.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/7a475b128243d85c57e73210c1a16ceafe68e623', 'message': 'Add tempest code coverage for keystone driver\n\nChange-Id: I0acbcdd2e5bd079faf648bf53c0dad5707a422a8\nCloses-Bug: 1376479\n'}]",14,142370,7a475b128243d85c57e73210c1a16ceafe68e623,23,5,4,13664,,,0,"Add tempest code coverage for keystone driver

Change-Id: I0acbcdd2e5bd079faf648bf53c0dad5707a422a8
Closes-Bug: 1376479
",git fetch https://review.opendev.org/openstack/congress refs/changes/70/142370/4 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/scenario/congress_datasources/test_keystone.py'],1,1f035682e84ea7acf15b15bd098d76bf46afe7d9,bug/1376479,"# Copyright 2014 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest import clients from tempest import config from tempest import exceptions from tempest.openstack.common import log as logging from tempest.scenario import manager_congress from tempest import test CONF = config.CONF LOG = logging.getLogger(__name__) class TestKeystoneDriver(manager_congress.ScenarioPolicyBase): @classmethod def check_preconditions(cls): super(TestKeystoneDriver, cls).check_preconditions() if not (CONF.network.tenant_networks_reachable or CONF.network.public_network_id): msg = ('Either tenant_networks_reachable must be ""true"", or' 'public_network_id must be defined.') cls.enabled = False raise cls.skipException(msg) def setUp(cls): super(TestKeystoneDriver, cls).setUp() cls.os = clients.Manager(cls.admin_credentials()) cls.keystone = cls.os.identity_client @test.attr(type='smoke') def test_keystone_user_table(self): _, users = self.keystone.get_users() user_map = {} for user in users: user_map[user['id']] = user user_schema = \ self.admin_manager.congress_client.show_datasource_table_schema( 'keystone', 'users')['columns'] def _check_data_table_keystone_users(): results = \ self.admin_manager.congress_client.list_datasource_rows( 'keystone', 'users') for row in results['results']: user_row = user_map[row['data'][4]] for index in range(len(user_schema)): if (str(row['data'][index]) != str(user_row[user_schema[index]['name']])): return False return True if not test.call_until_true(func=_check_data_table_keystone_users, duration=20, sleep_for=4): raise exceptions.TimeoutException(""Data did not converge in time "" ""or failure in server"") ",,70,0
openstack%2Ffuel-docs~master~Iab2c09cd48902844dfbe059b9ceef0f9b5054841,openstack/fuel-docs,master,Iab2c09cd48902844dfbe059b9ceef0f9b5054841,Screen shots for roles and nodes,MERGED,2014-11-12 03:04:01.000000000,2014-12-18 01:27:25.000000000,2014-12-18 01:27:25.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 13082}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-11-12 03:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/081d6789314655ff4bb7898aa85ec8ba368da4c3', 'message': 'Screen shots for roles and nodes\n\nUpdated screen shots to match 6.0 screens.\n\nadd-nodes1.png shows the release number so will have to be updated for GA\n\nChange-Id: Iab2c09cd48902844dfbe059b9ceef0f9b5054841\n'}, {'number': 2, 'created': '2014-11-14 00:04:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/99114300b1351b896c9bd8b177ad22536b6c5509', 'message': 'Screen shots for roles and nodes\n\nUpdated screen shots to match 6.0 screens.\n\nadd-nodes1.png shows the release number so will have to be updated for GA\n\nChange-Id: Iab2c09cd48902844dfbe059b9ceef0f9b5054841\n'}, {'number': 3, 'created': '2014-11-22 10:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/e5370ca40f3526e4e437e63a182d164389a1e58a', 'message': 'Screen shots for roles and nodes\n\nUpdated screen shots to match 6.0 screens.\n\nadd-nodes1.png shows the release number so will have to be updated for GA\n\nChange-Id: Iab2c09cd48902844dfbe059b9ceef0f9b5054841\n'}, {'number': 4, 'created': '2014-12-16 01:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/52a647ab2e6758f15f0dc0d8670ab5efccd2a913', 'message': 'Screen shots for roles and nodes\n\nUpdated screen shots to match 6.0 screens.\n\nadd-nodes1.png shows the release number so will have to be updated for GA\n\nChange-Id: Iab2c09cd48902844dfbe059b9ceef0f9b5054841\n'}, {'number': 5, 'created': '2014-12-18 01:18:34.000000000', 'files': ['pages/user-guide/config-environment/1000-assign-roles.rst', '_images/user_screen_shots/assign-roles2.png', '_images/user_screen_shots/assign-roles1.png', '_images/user_screen_shots/add-nodes1.png'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a8f7e49c05b568b5a93f4ef261e0f07beabae917', 'message': 'Screen shots for roles and nodes\n\nUpdated screen shots to match 6.0 screens.\n\nadd-nodes1.png shows the release number so will have to be updated for GA\n\nChange-Id: Iab2c09cd48902844dfbe059b9ceef0f9b5054841\n'}]",9,133878,a8f7e49c05b568b5a93f4ef261e0f07beabae917,36,8,5,10014,,,0,"Screen shots for roles and nodes

Updated screen shots to match 6.0 screens.

add-nodes1.png shows the release number so will have to be updated for GA

Change-Id: Iab2c09cd48902844dfbe059b9ceef0f9b5054841
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/78/133878/4 && git format-patch -1 --stdout FETCH_HEAD,"['pages/user-guide/config-environment/1000-assign-roles.rst', '_images/user_screen_shots/assign-roles1.png', '_images/user_screen_shots/add-nodes1.png']",3,081d6789314655ff4bb7898aa85ec8ba368da4c3,user-nodes-roles,,,13,8
openstack%2Fnova-specs~master~I5bcb24346062219adae49ddafb5c1cd69b8e24b3,openstack/nova-specs,master,I5bcb24346062219adae49ddafb5c1cd69b8e24b3,Implement policy should be enforced at REST API layer,MERGED,2014-10-09 07:41:24.000000000,2014-12-18 01:26:57.000000000,2014-12-18 01:26:56.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5292}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7166}, {'_account_id': 7641}, {'_account_id': 9420}, {'_account_id': 12175}, {'_account_id': 12898}]","[{'number': 1, 'created': '2014-10-09 07:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6ac3636eaf4736d273b9ccc1bb80cbec99f5d899', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 2, 'created': '2014-10-13 02:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/71d6d805934d9061be61cfe3fa59dd507adfdd32', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 3, 'created': '2014-10-13 02:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8e3e3ec07e3570b8965d65ee748e53632047b3b2', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 4, 'created': '2014-10-13 02:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/855ea619037b0fab5fb5853718853b897d96f71f', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 5, 'created': '2014-10-24 07:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d96738c5d02795325702814cfbd28c878faf2983', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 6, 'created': '2014-11-14 05:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/609e75cceda8e2e080ab90a854269dcf76523bf6', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 7, 'created': '2014-12-03 06:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/226873011f80dedd7d88db072bc370380a5b035d', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 8, 'created': '2014-12-03 07:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7204a5bf4d5540cbc76fa347147c36698ee168ad', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 9, 'created': '2014-12-10 03:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5f4ab1b73792651882eaa2f6f17c5557197d7a5a', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 10, 'created': '2014-12-10 05:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f02482cf5ab030bd86d6b66a23ebd03bf8119d71', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 11, 'created': '2014-12-10 06:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/187cf6e348ae08436e40d9e3096ade3a206cb989', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 12, 'created': '2014-12-12 02:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/410c2553da0fe8bb5e3362d4b7eb1387b7d3e1b3', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 13, 'created': '2014-12-13 00:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/127d4f7fa5a32adaf26d260c787d15be9c22de9d', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 14, 'created': '2014-12-16 08:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/526cd270251cfadb9622474b6f1c55d8c751d756', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 15, 'created': '2014-12-16 08:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8da6992f90c199dca78bfd81db9c543e9acbd676', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 16, 'created': '2014-12-16 14:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9ba95aef77fc7a5d06ef1b73581fd4a6bbcfc5ba', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 17, 'created': '2014-12-16 16:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9dfa2805ac8be61d9a80706e86ade2ca7d36edf7', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 18, 'created': '2014-12-17 02:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2ee64aa9a6a59eb9c9ed222a3a10a3adcdfbf074', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 19, 'created': '2014-12-17 13:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5578aa72532b35e473038fa44efb09ba3b2a8a99', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 20, 'created': '2014-12-17 15:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/16eb89edb14b27a8c0e6a9435efd346763ab85c2', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}, {'number': 21, 'created': '2014-12-17 22:52:02.000000000', 'files': ['specs/kilo/approved/nova-api-policy.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/995c676a3ee56af479b7f74960d468c050cc2fbc', 'message': 'Implement policy should be enforced at REST API layer\n\nThis is proposed blueprint for implementing policy should be\nenforced at REST API layer for ec2, v2.1 API.\n\nPart of blueprint v3-api-policy\n\nChange-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3\n'}]",46,127160,995c676a3ee56af479b7f74960d468c050cc2fbc,96,15,21,5754,,,0,"Implement policy should be enforced at REST API layer

This is proposed blueprint for implementing policy should be
enforced at REST API layer for ec2, v2.1 API.

Part of blueprint v3-api-policy

Change-Id: I5bcb24346062219adae49ddafb5c1cd69b8e24b3
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/60/127160/17 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/nova-api-policy.rst'],1,6ac3636eaf4736d273b9ccc1bb80cbec99f5d899,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================================== Policy should be enforced at API REST layer where possible =========================================================== https://blueprints.launchpad.net/nova/+spec/v3-api-policy This BP proposes enforcing all policy checks only at the Nova REST API layer. The extra permission checks at the lower layers of Nova will be removed. There will be consistent policy naming for the V2.1 API and backwards compatibility will be retained for existing policy checks related to the V2 API so that the policy checks remain effectively the same, even though they may in practice be implemented at different points. This BP is already discussed at Icehouse summit: https://etherpad.openstack.org/p/icehouse-summit-nova-v3-api Problem description =================== Currently policy permission checking is spread through the various levels of the Nova code. There are also duplicated checks where effectively the same sort of policy check under different names is done at different levels such as both at the Nova REST API layer and the Nova Compute API layer. In addition to this there are also some cases where there are hard coded permission checks in the db layer. This situation makes it much harder for operators to correctly configure the policy settings that they want and because of the multi layered complexity of permission the implementation itself is more vulnerable to security bugs. A detailed description of the problem: * Permission checking spread in different level of nova code Example: * REST API layer: pause server ""compute_extension:admin_actions:pause"" * Compute API layer: pause in compute API ""compute:pause"" * DB layer: require_admin_context decorator for db API service_get * Duplicated policy checking for same API. Example: * For server's pause action: * REST API layer: ""compute_extension:admin_actions:pause"": ""rule:admin_or_owner"" * Compute API layer: ""compute:pause"": """" * Hard code policy check at db layer Example: :: @require_admin_context def service_get_all(context, disabled=None): query = model_query(context, models.Service) if disabled is not None: query = query.filter_by(disabled=disabled) return query.all() This means it won't have any effect after you modify the policy at REST API layer, it always enforced as admin at db layer. Proposed change =============== Enforce policy at REST API layer. Because REST API will access different internal APIs, like compute API, DB API or other internal API, the REST API layer is the place to enforce policy consistently. * Remove policy check from compute API layer * For V2.1 API, there will only be policy checks in the nova REST API layer. There will be a parameter 'skip_policy_check' for compute API to control whether doing the policy checks. For V2.1 API, skip_policy_check will be True. https://review.openstack.org/#/c/100408/2/nova/api/openstack/compute/plugins/v3/shelve.py * For Ec2, We also want to keep backwards compatibility. we will move the compute API layer policy checking into REST API layer, the same as V2.1 API. * For V2 API, we want to keep the backwards-compatibility. So we won't move the compute API layer policy checking into REST API layer. We will set compute API's parameter skip_policy_check to False, that means still doing policy checking at compute API layer. It's because V2 API will be depreciated. Before V2 API removed, we needn't take risk of breaking existed code. https://review.openstack.org/#/c/100408/2/nova/compute/api.py * Remove hard-code permission check from db layer * Example: https://review.openstack.org/#/c/73490/ * For the v2.1 API, we remove all the hard-code permission check from DB layer. And we should ensure we have policy check at REST API layer. * For the v2 API, we remove all the hard-code permission check from DB layer. And with UpgradeImpact flags that notify deployer to update their development configuration. * Update policy configuration file to match the existing behavior. * Correct the policy rule name specification for the v2.1 api The policy naming style as below: api:[extension_alias]:[action] * We won't use 'compute' and 'compute_extension' to distingish the core and extension API. Because the core API may be changed in the future. * We also remove the API verison from the policy rule. Because after we have Micro-version, the version will be changed often. * For volume related extensions, there isn't any thing can do, there already have policy checks at REST API layer, also have policy checks by cinder. * For network related extensions, we are doing same change like compute API. For nova-network, move all the policy enforcement into REST API layer from network API, and remove the db layer hard-code permission checks. Alternatives ------------ The alternative is the status quo which is confusing for both deployers as well as developers having to maintain the current implementation Data model impact ----------------- None REST API impact --------------- None Security impact --------------- This BP will remove the policy permission checks in the compute API layer and DB layer. These patches will require very rigorous double checking and high quality reviews to ensure that security bugs are not introduced as the nova internal calls can be called from quite a few different code paths (Ec2, V2 API, V2.1 API and other internals). Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ This BP will improve the error handling performance. Because the permission checking occurs at the API level rather than at a lower level in Nova less processing will occur before a request is rejected. Also potentially for newer versions of the API redundant policy checks are removed which will also improve performance. Other deployer impact --------------------- Every effort will be made to keep all existing policy permission settings backwards compatible. Where this is not possible or too impractical the policy file changes required to keep the existing behaviour will be very clearly documented in upgrade documentation. Developer impact ---------------- When a developer adds a new REST API for nova policy permission checks will only be added at the REST API layer. Implementation ============== Assignee(s) ----------- Primary assignee: Alex Xu <xuhj@linux.vnet.ibm.com> Other contributors: Ivan Zhu <bozhu@linux.vnet.ibm.com> Ji Chen <jichenjc@cn.ibm.com> Shuangtai Tian <shuangtai.tian@intel.com> Chris Yeoh <cyeoh@au1.ibm.com> Work Items ---------- * Move compute API layer policy checking into REST API layer. * Remove the db layer permission checking. * Move nova network API layer policy checking into REST API layer. * Remove db layer policy checking for nova network related db API. * Rename all the policy rules. Working list: https://etherpad.openstack.org/p/apipolicycheck Dependencies ============ None Testing ======= No tempest changes. All the policy checks tests will be test by unittest, as this is mostly an internal nova blueprint. Documentation Impact ==================== The db layer permission checks will be deleted, this should be document at upgrade documentation. All the policy should enforce at API layer, this should be document at developer documentation. For the consistent configuration of policy rule, this should be document at Cloud Admin documentation. References ========== https://etherpad.openstack.org/p/icehouse-summit-nova-v3-api ",,236,0
openstack%2Fnova-specs~master~Ie81a9c84490393720e119ca50ca3962ef4642cfe,openstack/nova-specs,master,Ie81a9c84490393720e119ca50ca3962ef4642cfe,Pass on the capabilities in the flavor to the ironic,MERGED,2014-11-20 19:33:48.000000000,2014-12-18 01:26:50.000000000,2014-12-18 01:26:48.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2889}, {'_account_id': 5441}, {'_account_id': 10202}, {'_account_id': 11076}, {'_account_id': 11297}, {'_account_id': 12898}]","[{'number': 1, 'created': '2014-11-20 19:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7e927472527b68f5a3ff18eed12d3859427cea61', 'message': 'Pass on the capabilities in the flavor to the ironic\n\nImplements : blueprint pass-flavor-capabilities-to-ironic-virt-driver\n\nChange-Id: Ie81a9c84490393720e119ca50ca3962ef4642cfe\n'}, {'number': 2, 'created': '2014-12-07 23:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ec4182f77af210ddae08b99e9f6eb32219558baa', 'message': 'Pass on the capabilities in the flavor to the ironic\n\nImplements : blueprint pass-flavor-capabilities-to-ironic-virt-driver\n\nChange-Id: Ie81a9c84490393720e119ca50ca3962ef4642cfe\n'}, {'number': 3, 'created': '2014-12-11 20:54:46.000000000', 'files': ['specs/kilo/approved/pass-flavor-capabilities-to-ironic-virt-driver.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d8ef2dd6a429e5bb27ad411c2db771139c4e238e', 'message': 'Pass on the capabilities in the flavor to the ironic\n\nImplements : blueprint pass-flavor-capabilities-to-ironic-virt-driver\n\nChange-Id: Ie81a9c84490393720e119ca50ca3962ef4642cfe\n'}]",6,136104,d8ef2dd6a429e5bb27ad411c2db771139c4e238e,30,9,3,11297,,,0,"Pass on the capabilities in the flavor to the ironic

Implements : blueprint pass-flavor-capabilities-to-ironic-virt-driver

Change-Id: Ie81a9c84490393720e119ca50ca3962ef4642cfe
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/04/136104/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/pass-flavor-capabilities-to-ironic-virt-driver.rst'],1,7e927472527b68f5a3ff18eed12d3859427cea61,bp/pass-flavor-capabilities-to-ironic-virt-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================================================== Pass on the capabilities in the flavor to the ironic ===================================================== https://blueprints.launchpad.net/nova/+spec/pass-flavor-capabilities-to-ironic-virt-driver Today nova doesn't pass on the `capabilities` defined in `extra-spec` key of the flavor. The ironic needs to be aware of the requested capability in the flavor. Problem description =================== Today nova doesn't pass on the `capabilities` defined in `extra-spec` key of the flavor. Today Nova is able to read the capabilities defined in the ironic node's properties field and select the node using the ComputeCapabilities Filter. Now, the ironic needs to be aware of the requested capability in the flavor so that it can take specific actions as per the request in the flavor once the node has been scheduled by Nova. Use Cases ---------- The ironic can use it for following: 1. Prepare the node in the desired state before deploy. 2. The same can be used during decommisioning the node for unwinding to its original state. Example: say a capability as, `power_optimized=True` as given in flavor-key. The ironic has node.properties updated with capability as `power_optimzied=True`. The node is selected via ComputeCapabilities Filter. Now, if the node's instance_info is updated by nova as `power_optimzied=True`, the ironic driver can prepare the node in desired power state. This is applicable for all the hardware capabilities which requires some action from the driver as per the requested capability in the flavor extra-spec key. Project Priority ----------------- The kilo priorities list is currently undefined, But this partly falls under the cross project requirement. Proposed change =============== The proposal is to update the instance_info field of the node object with the capabilities defined in the flavor extra-spec. Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- This change takes immediate effect once the ironic is supported for hardware capabilities which is a work-in-progress for kilo in ironic. Developer impact ---------------- None. Implementation ============== See Work Items below. Assignee(s) ----------- Primary assignee: agarwalnisha1980 Work Items ---------- * Require changes in nova/virt/ironic/patcher.py to update the instance_info field with the flavor capabilities. Dependencies ============ None. Testing ======= Unit tests will be added. Documentation Impact ==================== This will be documented under ironic. References ========== Exposing Hardware capabilities: https://review.openstack.org/#/c/131272/ https://etherpad.openstack.org/p/kilo-ironic-exposing-different-capabilities For supporting multiple values with `capabilities`: https://review.openstack.org/133534 ",,147,0
openstack%2Ffuel-docs~master~I5327a4791fb62683aa59cfcd512ce72bec1dbf41,openstack/fuel-docs,master,I5327a4791fb62683aa59cfcd512ce72bec1dbf41,atop documentation,MERGED,2014-11-26 21:09:10.000000000,2014-12-18 01:26:42.000000000,2014-12-18 01:26:41.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11090}, {'_account_id': 12866}, {'_account_id': 13344}]","[{'number': 1, 'created': '2014-11-26 21:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1ee9fe3c11131a3c447d73b0e4eeffc11cfcc21b', 'message': 'atop documentation\n\nDocument the atop/screen logging facility added in 6.0\n\noperations/troubleshooting/1000-logs -- describe implmentation\nand advanced configuration and usage instructions.\n\nWe need information about:\n- How to disable (can it be done from UI?)\n- How to modify implementation (amount of data kept, duration, etc)\n- How to view the information\n- Is there a way to aggregate this data for the whole environment?\n\nChange-Id: I5327a4791fb62683aa59cfcd512ce72bec1dbf41\nPartial-Bug: 1385122\n'}, {'number': 2, 'created': '2014-12-06 02:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f6d1ce1178f6e0a18f3c02f20983b07b05ace32e', 'message': 'atop documentation\n\nDocument the atop/screen logging facility added in 6.0\n\noperations/troubleshooting/1000-logs -- describe implmentation\nand advanced configuration and usage instructions.\n\nterminology/overcommit -- reference this material as a way\nto monitor resource utilization.\n\nChange-Id: I5327a4791fb62683aa59cfcd512ce72bec1dbf41\nPartial-Bug: 1385122\n'}, {'number': 3, 'created': '2014-12-15 06:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/297be8a1c8eef3813f14d1b4a613cf5957d909ad', 'message': 'atop documentation\n\nDocument the atop/screen logging facility added in 6.0\n\noperations/troubleshooting/1000-logs -- describe implmentation\nand advanced configuration and usage instructions.\n\nterminology/overcommit -- reference this material as a way\nto monitor resource utilization.\n\nChange-Id: I5327a4791fb62683aa59cfcd512ce72bec1dbf41\nPartial-Bug: 1385122\n'}, {'number': 4, 'created': '2014-12-15 21:13:34.000000000', 'files': ['pages/terminology/o/overcommit.rst', 'pages/operations/troubleshoot/1000-logs.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/9d19fab5a9202c13dd7fda249436c7379e11e751', 'message': 'atop documentation\n\nDocument the atop/screen logging facility added in 6.0\n\noperations/troubleshooting/1000-logs -- describe implmentation\nand advanced configuration and usage instructions.\n\nterminology/overcommit -- reference this material as a way\nto monitor resource utilization.\n\nChange-Id: I5327a4791fb62683aa59cfcd512ce72bec1dbf41\nPartial-Bug: 1385122\n'}]",5,137474,9d19fab5a9202c13dd7fda249436c7379e11e751,32,9,4,10014,,,0,"atop documentation

Document the atop/screen logging facility added in 6.0

operations/troubleshooting/1000-logs -- describe implmentation
and advanced configuration and usage instructions.

terminology/overcommit -- reference this material as a way
to monitor resource utilization.

Change-Id: I5327a4791fb62683aa59cfcd512ce72bec1dbf41
Partial-Bug: 1385122
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/74/137474/3 && git format-patch -1 --stdout FETCH_HEAD,['pages/operations/troubleshoot/1000-logs.rst'],1,1ee9fe3c11131a3c447d73b0e4eeffc11cfcc21b,bug/1385122,".. _atop-ops: atop logs +++++++++ Fuel installs and runs `atop <http://www.atoptool.nl/>`_ and `screen <https://www.gnu.org/software/screen/manual/screen.html>`_ on all deployed nodes in the environment. This provides detailed information about resource usage on each node that can be used to troubleshoot performance and scalability issues. The data shows usage of the hardware resources that are most important from a performance standpoint: CPU, memory, disk, and network cards. The implementation is: * By default, these tools take a snapshot of system status every 20 seconds and stores this information in binary form. * The binary data is stored locally on each node in the */var/log/atop* directory. * Data is kept for seven days; a logrotate job deletes logs older than seven days. * The data consumes no more than 2GB of disk space on each node. * The Diagnostic Logs snapshot includes the *atop* data for the current day only. ",,31,0
openstack%2Foperations-guide~master~I25bbe51eb0dd5665e577d461e98b08fa917b0669,openstack/operations-guide,master,I25bbe51eb0dd5665e577d461e98b08fa917b0669,Fix typo in the figure of Logical Architecture,MERGED,2014-12-17 10:42:24.000000000,2014-12-18 01:25:11.000000000,2014-12-18 01:25:10.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 7634}, {'_account_id': 12402}]","[{'number': 1, 'created': '2014-12-17 10:42:24.000000000', 'files': ['doc/openstack-ops/figures/osog_0001.png'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/42f9b27db04afc4d47da2d4956f28edac0c365c5', 'message': 'Fix typo in the figure of Logical Architecture\n\nChange-Id: I25bbe51eb0dd5665e577d461e98b08fa917b0669\nCloses-Bug: 1402870\n'}]",0,142416,42f9b27db04afc4d47da2d4956f28edac0c365c5,9,5,1,10497,,,0,"Fix typo in the figure of Logical Architecture

Change-Id: I25bbe51eb0dd5665e577d461e98b08fa917b0669
Closes-Bug: 1402870
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/16/142416/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/figures/osog_0001.png'],1,42f9b27db04afc4d47da2d4956f28edac0c365c5,bug/1402870,,,0,0
openstack%2Fopenstack-manuals~master~I0b4e5b8a54b96c47a8e6d262ae7ecb925c959a63,openstack/openstack-manuals,master,I0b4e5b8a54b96c47a8e6d262ae7ecb925c959a63,Add missing vmware_adaptertype values,MERGED,2014-12-17 18:43:03.000000000,2014-12-18 01:24:55.000000000,2014-12-18 01:24:54.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-17 18:43:03.000000000', 'files': ['doc/cli-reference/ch_cli_glance_property_keys.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/60c85c79537159226e48d75d46014530bebacf41', 'message': 'Add missing vmware_adaptertype values\n\nAdd lsiLogic and paraVirtual adapter types.\n\nChange-Id: I0b4e5b8a54b96c47a8e6d262ae7ecb925c959a63\nCloses-Bug: #1291045\n'}]",0,142533,60c85c79537159226e48d75d46014530bebacf41,7,3,1,6547,,,0,"Add missing vmware_adaptertype values

Add lsiLogic and paraVirtual adapter types.

Change-Id: I0b4e5b8a54b96c47a8e6d262ae7ecb925c959a63
Closes-Bug: #1291045
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/33/142533/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/ch_cli_glance_property_keys.xml'],1,60c85c79537159226e48d75d46014530bebacf41,bug/1291045," <td><literal>lsiLogic</literal>, <literal>lsiLogicsas</literal>, <literal>busLogic</literal>, <literal>ide</literal>, or <literal>paraVirtual</literal></td>"," <td><literal>lsiLogic</literal>, <literal>busLogic</literal>, or <literal>ide</literal></td>",3,2
openstack%2Fneutron-specs~master~Ic4c7c53ad2f268c0364175a6365762fc24acb96d,openstack/neutron-specs,master,Ic4c7c53ad2f268c0364175a6365762fc24acb96d,Added specs for ARP spoofing patch.,MERGED,2014-10-16 23:41:04.000000000,2014-12-18 01:24:45.000000000,2014-12-18 01:24:43.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 6139}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7021}]","[{'number': 1, 'created': '2014-10-16 23:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/19fe34e2cc072644a4c1ef9e1bc62e909c713256', 'message': 'Added specs for ARP spoofing patch.\n\nChange-Id: Ic4c7c53ad2f268c0364175a6365762fc24acb96d\n'}, {'number': 2, 'created': '2014-12-17 20:13:11.000000000', 'files': ['specs/kilo/arp-spoof-filtering-ebtables.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8949f27a6bdc609e08f0fd2ce6d9b8eadd725ab4', 'message': 'Added specs for ARP spoofing patch.\n\nChange-Id: Ic4c7c53ad2f268c0364175a6365762fc24acb96d\n'}]",16,129090,8949f27a6bdc609e08f0fd2ce6d9b8eadd725ab4,35,11,2,6139,,,0,"Added specs for ARP spoofing patch.

Change-Id: Ic4c7c53ad2f268c0364175a6365762fc24acb96d
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/90/129090/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/arp-spoof-filtering-ebtables.rst'],1,19fe34e2cc072644a4c1ef9e1bc62e909c713256,master,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================== ARP spoofing filtering via ebtables =================================== Launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/arp-spoof-patch-ebtables The blueprint proposes a fix to to bug 1274034: https://bugs.launchpad.net/neutron/+bug/1274034 This issue allows ARP cache poisoning attacks to be started from a guest VM to other VMs in the same network. This is a security issue, especially on shared networks. Ths blueprint suggest that we utilize the ebtables tool to configure Ethernet-frame-level filtering, which prevents these spoofing packets to be sent by a VM. Problem Description =================== With an ARP cache poisoning attack a device in the local network can impersonate someone else. Specifically, a device can claim ownership of an IP address, which it does not actually have. The attacker sends out a gratuituous ARP response, in which their network interface (identified by MAC address) claims to be configured with a certain IP address. However, this might be someone else's IP address. Other devices in the network update their ARP cache with the spoofed entry and will put the attacking device's MAC address as the destination address of frames that are to be sent to the attacked IP address. Proposed Change =============== We propose to add an 'ebtables manager', which knows how to utilize the ebtables utility. This utility can be used to create Ethernet frame level filtering rules. Whenever a port for a VM is created or deleted, we use the ebtables manager to update ebtables rules, which prevent the sending of spoofed ARP packets through this port. Please note that the ebtables manager code is largely based on the work of Édouard Thuleau, who had submitted a patch here: https://review.openstack.org/#/c/70067/ This patch, however, did not make it into the release and was abandoned. We are now resurrecting much of this patch. An updated version of this patch was submitted for Juno, but was rejected for various reasons. The existing patch replaced some of the iptables-based filtering with new ebtables filters. Therefore, it changed quite a bit of the existing code in iptables_firewall.py. This was not appreciated, since this code was seen as brittle and in need of a re-write. Therefore, we are now proposing that the changes to iptables code are kept to a minimum. We merely need to add a few small hooks in the iptables code, so that the ebtables manager code is envoked when a port is created or deleted. If at some later time the iptables code is going to be re-written, any hooks to the ebtables code can easily be ported over. Data Model Impact ----------------- None. REST API Impact --------------- None. Security Impact --------------- The ebtables manager code is run with the same privileges as the iptables code (sudo). It improves security of VMs on shared networks. Notifications Impact -------------------- None. Other End User Impact --------------------- None. Performance Impact ------------------ The new code will be called whenever a VM port is created or deleted. The impact of calling the ebtables code is similar to the impact of the iptables code. It will be called in addition to the iptables code and does not replace it. Other Deployer Impact --------------------- The 'ebtables' utility needs to be installed. This is normally available in various standard packages. On Debian, for example, it's installed like this: # apt-get install ebtables Developer Impact ---------------- None. In fact, the proposed patch is designed to have as little impact as possible. The existing code isn't changed and both the iptables and ebtables code can be independently refactored without impacting each other. Community Impact ---------------- ? Alternatives ------------ It seems that iptables isn't capable of performing such filtering and therefore can't be used for this. Another alternative is to do nothing: This is only an issue on shared networks. That's a business decision, though, and it seems some people are quite eager to have this patch. Implementation ============== Assignee(s) ----------- Primary assignee: Juergen Brendel (jbrendel@cisco.com) Work Items ---------- * Implement the ebtables code. * Implement the code that uses the ebtables manager to create the spoofing related rules. * Integrate code with iptables: Add the small hooks into the iptables-firewall code. * All sorts of tests. Dependencies ============ * The ebtables utility needs to be installed. Testing ======= Tempest Tests ------------- Not sure yet. Functional Tests ---------------- Funtional tests to show that the iptables and ebtables code work together properly. API Tests --------- None. Documentation Impact ==================== The need for ebtables may be listed somewhere as a requirement. User Documentation ------------------ None. Developer Documentation ----------------------- None. References ========== * Original patch by Édouard Thuleau: https://review.openstack.org/#/c/70067/ * Launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/arp-spoof-patch-ebtables ",,216,0
openstack%2Fcinder-specs~master~Ie8470a05dac936b7ad241c41c2429bc8ffbc0ff2,openstack/cinder-specs,master,Ie8470a05dac936b7ad241c41c2429bc8ffbc0ff2,Add spec for 'Enhance iSCSI multipath support',MERGED,2014-11-21 22:08:04.000000000,2014-12-18 01:24:39.000000000,2014-12-18 01:24:36.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 8074}, {'_account_id': 9176}, {'_account_id': 10115}, {'_account_id': 10221}, {'_account_id': 10549}, {'_account_id': 11538}, {'_account_id': 12924}]","[{'number': 1, 'created': '2014-11-21 22:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/7a843b6644352499c7562c740fbd32135a1253cf', 'message': ""Add spec for 'Enhance iSCSI multipath support'\n\nThis spec proposes to enhance iSCSI multipath support by\ndefining the way to tell multiple iSCSI portals/iqns/luns\nto access a volume to Nova.\n\nChange-Id: Ie8470a05dac936b7ad241c41c2429bc8ffbc0ff2\nblueprint: iscsi-multipath-enhancement\n""}, {'number': 2, 'created': '2014-11-21 23:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/f7f42b799dec49d3af9c99a64dbf7e13d89491b1', 'message': ""Add spec for 'Enhance iSCSI multipath support'\n\nThis spec proposes to enhance iSCSI multipath support by\ndefining the way to tell multiple iSCSI portals/iqns/luns\nto access a volume to Nova.\n\nChange-Id: Ie8470a05dac936b7ad241c41c2429bc8ffbc0ff2\nblueprint: iscsi-multipath-enhancement\n""}, {'number': 3, 'created': '2014-11-24 20:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/70b5e6ab241376d5bc78676effa0220d6683d132', 'message': ""Add spec for 'Enhance iSCSI multipath support'\n\nThis spec proposes to enhance iSCSI multipath support by\ndefining the way to tell multiple iSCSI portals/iqns/luns\nto access a volume to Nova.\n\nChange-Id: Ie8470a05dac936b7ad241c41c2429bc8ffbc0ff2\nblueprint: iscsi-multipath-enhancement\n""}, {'number': 4, 'created': '2014-11-26 00:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/4d58beeee14ecb161128b77e495b2551d0441c7e', 'message': ""Add spec for 'Enhance iSCSI multipath support'\n\nThis spec proposes to enhance iSCSI multipath support by\ndefining the way to tell multiple iSCSI portals/iqns/luns\nto access a volume to Nova.\n\nChange-Id: Ie8470a05dac936b7ad241c41c2429bc8ffbc0ff2\nblueprint: iscsi-multipath-enhancement\n""}, {'number': 5, 'created': '2014-11-26 00:45:07.000000000', 'files': ['specs/kilo/iscsi-multipath-enhancement.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/09ae87d42b1f8158e8e310d02662b18dbda648b8', 'message': ""Add spec for 'Enhance iSCSI multipath support'\n\nThis spec proposes to enhance iSCSI multipath support by\ndefining the way to tell multiple iSCSI portals/iqns/luns\nto access a volume to Nova.\n\nChange-Id: Ie8470a05dac936b7ad241c41c2429bc8ffbc0ff2\nblueprint: iscsi-multipath-enhancement\n""}]",12,136500,09ae87d42b1f8158e8e310d02662b18dbda648b8,34,12,5,9176,,,0,"Add spec for 'Enhance iSCSI multipath support'

This spec proposes to enhance iSCSI multipath support by
defining the way to tell multiple iSCSI portals/iqns/luns
to access a volume to Nova.

Change-Id: Ie8470a05dac936b7ad241c41c2429bc8ffbc0ff2
blueprint: iscsi-multipath-enhancement
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/00/136500/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/iscsi-multipath-enhancement.rst'],1,7a843b6644352499c7562c740fbd32135a1253cf,bp/iscsi-multipath-enhancement,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Enhance iSCSI multipath support ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/cinder/+spec/enhance-iscsi-multipath This spec proposes to enhance iSCSI multipath support by defining the way to tell multiple iSCSI portals/iqns/luns to access a volume (LU) to Nova. Problem description =================== Currently, nova-compute supports multipath for iSCSI volume data path. It depends on response to targets discovery of from the main iSCSI portal, expecting multiple portal addresses are contained. However, some arrays only respond to discovery with a single portal address, even if secondary portals are available. In this case, nova-compute cannot know secondary portals and corresponding iSCSI target IQN, so nova-compute cannot establish multiple sessions for the target(s). To enable nova-compute to login to secondary portals, cinder should tell the secondary portal addresses and corresponding target iqns/luns. Proposed change =============== If nova-compute can support multipath for iSCSI (that is, if multipathd is installed and CONF.libvirt.iscsi_use_multipath is set True), nova-compute should call Cinder initialize_connection API with a new 'multipath=True' optional parameter. This parameter is passed to the backend driver so that the driver can export a volume to multiple ports. When the 'multipath=True' is specified, 'connection_info' of the API response will contain multiple portal addresses and corresponding target iqns/luns. Current 'target_portal'/'target_iqn'/'target_lun' parameters will be replaced with 'target_portals'/'target_iqns'/'target_luns' which have a list of the addresses of the iSCSI portals and the corresponding iqn/lun to each portal. When nova-compute recognizes these parameters, it will log into every portal address/target/lun. When the backend doesn't support (or not configured to support) multipath, the driver may return current 'target_portal'/ 'target_iqn'/'target_lun' set. When the 'multipath=False' is specified or the parameter is omitted, the API must return 'target_portal'/'target_iqn'/'target_lun' set. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- 'os-initialize_connection' volume action API will have new optional parameter 'multipath', which take True or False value. When the 'multipath=True' parameter is specified, 'os-initialize_connection' volume action API respond with 'target_portals'/'target_iqns'/'target_luns' in 'connection_info' which contain a list of portal IP address:port pairs, a list of secondary iqn's and lun's corresponding to each portal address. For example: {""connection_info"": {""driver_volume_type"": ""iscsi"", ... ""data"": {""target_portals"": [""10.0.1.2:3260"", ""10.0.2.2:3260""], ""target_iqns"": [ ""iqn.2014-2.org.example:vol1-1"", ""iqn.2014-2.org.example:vol1-2""], ""target_luns"": [1, 2], ...}}} In this case, ""iqn.2014-2.org.example:vol1-1"", lun=1 is for portal ""10.0.1.2:3260"", and ""iqn.2014-2.org.example:vol1-2"", lun=2 is for portal ""10.0.2.2:3260"". Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Since nova-compute can omit discovery query to find multiple portals and targets, this change may make volume-attach/detach operations faster. Other deployer impact --------------------- Backend driver may have additional settings to enable iSCSI portal multipath. For example, to utilize this feature in iSCSI LVM driver, we needs to specify a list of secondary IP addresses of the cinder-volume node where iSCSI targets run on. Developer impact ---------------- To enable multiple iSCSI portals functionality, backend drivers must change the implementation of initialize_connection method to return parameters 'target_portals', 'target_iqns' and 'target_luns' instead of 'target_portal', 'target_iqn', and 'target_lun'. Implementation ============== Assignee(s) ----------- Primary assignee: tsekiyama Work Items ---------- - Implement this feature in LVM iSCSI driver as a sample - Enable nova and brick library to handle multiple portals/iqns/luns. Dependencies ============ None Testing ======= - Unit tests should be added for drivers which support this feature, so that initialize_connection will return correct connection_info. - To test this feature in tempest, multiple addresses must be asigned to the test environment in order to establish multiple sessions to volumes. Implementation in LVM iSCSI driver would be useful for testing. Documentation Impact ==================== A section to describe this feature should be added. If the driver needs additional settings for this feature, the documentation for them should be added. References ========== * Enable multipath for libvirt iSCSI Volume Driver (merged) https://review.openstack.org/#/c/17946/ * Nova-specs: Support iSCSI portal multipath https://review.openstack.org/#/c/134299/ ",,172,0
openstack%2Fcinder-specs~master~Ie19c1c8bb66c30e3438708951607c9bb1005839d,openstack/cinder-specs,master,Ie19c1c8bb66c30e3438708951607c9bb1005839d,Add spec for 'Failover to alternative iSCSI portals on login failure',MERGED,2014-10-28 17:12:01.000000000,2014-12-18 01:24:31.000000000,2014-12-18 01:24:30.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7160}, {'_account_id': 9176}, {'_account_id': 9382}, {'_account_id': 10221}, {'_account_id': 13933}]","[{'number': 1, 'created': '2014-10-28 17:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/353fa266905ec95556e64bf46d6adaa77c0d66c6', 'message': ""Add spec for 'Support iSCSI portal multipath'\n\nCurrently, data path to iSCSI volumes supports multipath via Nova's\ncontrol. However, if the primary iSCSI portal address becomes\nunaccessible due to network failure etc., Nova-compute will fail to\nattach or detach volumes even if another address for the portal is\nonline. To avoid this issue, Cinder should pass secondary addresses\nof iSCSI portal to Nova-computes.\n\nThis spec proposes to add multipath support of iSCSI portals.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-portal-multipath\n""}, {'number': 2, 'created': '2014-11-12 20:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/dc5b1f54b08e3d93a2b44c65521672caaf3602f6', 'message': ""Add spec for 'Support iSCSI portal multipath'\n\nCurrently, data path to iSCSI volumes supports multipath via Nova's\ncontrol. However, if the primary iSCSI portal address becomes\nunaccessible due to network failure etc., Nova-compute will fail to\nattach or detach volumes even if another address for the portal is\nonline. To avoid this issue, Cinder should pass secondary addresses\nof iSCSI portal to Nova-computes.\n\nThis spec proposes to add multipath support of iSCSI portals.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-portal-multipath\n""}, {'number': 3, 'created': '2014-11-12 22:05:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/d06fb2403365f8b8c7e53a088d11363e3a46f433', 'message': ""Add spec for 'Support iSCSI portal multipath'\n\nCurrently, data path to iSCSI volumes supports multipath via Nova's\ncontrol. However, if the primary iSCSI portal address becomes\nunaccessible due to network failure etc., Nova-compute will fail to\nattach or detach volumes even if another address for the portal is\nonline. To avoid this issue, Cinder should pass secondary addresses\nof iSCSI portal to Nova-computes.\n\nThis spec proposes to add multipath support of iSCSI portals.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-portal-multipath\n""}, {'number': 4, 'created': '2014-11-13 17:07:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/9be34c2b642136cc3a16c75463b46bf55f21e6ab', 'message': ""Add spec for 'Support iSCSI portal multipath'\n\nCurrently, data path to iSCSI volumes supports multipath via Nova's\ncontrol. However, if the primary iSCSI portal address becomes\nunaccessible due to network failure etc., Nova-compute will fail to\nattach or detach volumes even if another address for the portal is\nonline. To avoid this issue, Cinder should pass secondary addresses\nof iSCSI portal to Nova-computes.\n\nThis spec proposes to add multipath support of iSCSI portals.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-portal-multipath\n""}, {'number': 5, 'created': '2014-11-13 21:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/e84ecc621b3999bca2778d2db88b84b20961bf51', 'message': ""Add spec for 'Support iSCSI portal multipath'\n\nCurrently, data path to iSCSI volumes supports multipath via Nova's\ncontrol. However, if the primary iSCSI portal address becomes\nunaccessible due to network failure etc., Nova-compute will fail to\nattach or detach volumes even if another address for the portal is\nonline. To avoid this issue, Cinder should pass secondary addresses\nof iSCSI portal to Nova-computes.\n\nThis spec proposes to add multipath support of iSCSI portals.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-portal-multipath\n""}, {'number': 6, 'created': '2014-11-18 23:26:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/babdd2514cd2c1249c6cca6f75405c34ef5341f8', 'message': ""Add spec for 'Support iSCSI portal multipath'\n\nCurrently, data path to iSCSI volumes supports multipath via Nova's\ncontrol. However, if the primary iSCSI portal address becomes\nunaccessible due to network failure etc., Nova-compute will fail to\nattach or detach volumes even if another address for the portal is\nonline. To avoid this issue, Cinder should pass secondary addresses\nof iSCSI portal to Nova-computes.\n\nThis spec proposes to add multipath support of iSCSI portals.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-portal-multipath\n""}, {'number': 7, 'created': '2014-11-19 20:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/838a50c6d0bc7c051021effa357122d3fa32c2f5', 'message': ""Add spec for 'Support iSCSI portal multipath'\n\nCurrently, data path to iSCSI volumes supports multipath via Nova's\ncontrol. However, if the primary iSCSI portal address becomes\nunaccessible due to network failure etc., Nova-compute will fail to\nattach or detach volumes even if another address for the portal is\nonline. To avoid this issue, Cinder should pass secondary addresses\nof iSCSI portal to Nova-computes.\n\nThis spec proposes to add multipath support of iSCSI portals.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-portal-multipath\n""}, {'number': 8, 'created': '2014-11-21 21:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/ec5974746a74f1469d974e120161f91f1680a1a9', 'message': ""Add spec for 'Support iSCSI portal multipath'\n\nWhen the main iSCSI portal is unreachable by network failure etc.,\nvolume attach/detach will fail even though the other portal addresses\nis reachable. To enable nova-compute to fall-back to alternative portal\naddresses, cinder should tell the alternative portal addresses to nova.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-alternative-portal\n""}, {'number': 9, 'created': '2014-11-21 22:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/c7ea7e1c22b33f81b4b1ab10a6439e7ba01bc6fa', 'message': ""Add spec for 'Failover to alternative iSCSI portals on login failure'\n\nWhen the main iSCSI portal is unreachable by network failure etc.,\nvolume attach/detach will fail even though the other portal addresses\nis reachable. To enable nova-compute to fall-back to alternative portal\naddresses, cinder should tell the alternative portal addresses to nova.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-alternative-portal\n""}, {'number': 10, 'created': '2014-11-24 20:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/6c85be154e3dba41b8a1ba0045fbf8e555abac4a', 'message': ""Add spec for 'Failover to alternative iSCSI portals on login failure'\n\nWhen the main iSCSI portal is unreachable by network failure etc.,\nvolume attach/detach will fail even though the other portal addresses\nis reachable. To enable nova-compute to fall-back to alternative portal\naddresses, cinder should tell the alternative portal addresses to nova.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-alternative-portal\n""}, {'number': 11, 'created': '2014-11-26 20:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/1f3af93da7f59f75bcca24ae0b2202a951a67c12', 'message': ""Add spec for 'Failover to alternative iSCSI portals on login failure'\n\nWhen the main iSCSI portal is unreachable by network failure etc.,\nvolume attach/detach will fail even though the other portal addresses\nis reachable. To enable nova-compute to fall-back to alternative portal\naddresses, cinder should tell the alternative portal addresses to nova.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-alternative-portal\n""}, {'number': 12, 'created': '2014-12-01 17:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/657c61a41d17d21912c746d15dba4648b44305e4', 'message': ""Add spec for 'Failover to alternative iSCSI portals on login failure'\n\nWhen the main iSCSI portal is unreachable by network failure etc.,\nvolume attach/detach will fail even though the other portal addresses\nis reachable. To enable nova-compute to fall-back to alternative portal\naddresses, cinder should tell the alternative portal addresses to nova.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-alternative-portal\n""}, {'number': 13, 'created': '2014-12-01 21:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/d40a563c185b2841bd24a5eb01cb2a00244c30e3', 'message': ""Add spec for 'Failover to alternative iSCSI portals on login failure'\n\nWhen the main iSCSI portal is unreachable by network failure etc.,\nvolume attach/detach will fail even though the other portal addresses\nis reachable. To enable nova-compute to fall-back to alternative portal\naddresses, cinder should tell the alternative portal addresses to nova.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-alternative-portal\n""}, {'number': 14, 'created': '2014-12-12 00:14:44.000000000', 'files': ['specs/kilo/iscsi-alternative-portal.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/56d0bf550b69032c26fc9aa6aaf9d80d07b02331', 'message': ""Add spec for 'Failover to alternative iSCSI portals on login failure'\n\nWhen the main iSCSI portal is unreachable by network failure etc.,\nvolume attach/detach will fail even though the other portal addresses\nis reachable. To enable nova-compute to fall-back to alternative portal\naddresses, cinder should tell the alternative portal addresses to nova.\n\nChange-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d\nblueprint: iscsi-alternative-portal\n""}]",37,131502,56d0bf550b69032c26fc9aa6aaf9d80d07b02331,65,11,14,9176,,,0,"Add spec for 'Failover to alternative iSCSI portals on login failure'

When the main iSCSI portal is unreachable by network failure etc.,
volume attach/detach will fail even though the other portal addresses
is reachable. To enable nova-compute to fall-back to alternative portal
addresses, cinder should tell the alternative portal addresses to nova.

Change-Id: Ie19c1c8bb66c30e3438708951607c9bb1005839d
blueprint: iscsi-alternative-portal
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/02/131502/13 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/iscsi-portal-multipath.rst'],1,353fa266905ec95556e64bf46d6adaa77c0d66c6,bp/iscsi-alternative-portal,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Support iSCSI portal multipath ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/cinder/+spec/iscsi-portal-multipath This spec proposes to add multipath support of iSCSI portals. Problem description =================== Currently, data path to iSCSI volumes supports multipath via Nova's control. However, if the primary iSCSI portal address becomes unaccessible due to network failure etc., Nova-compute will fail to attach or detach volumes even if another address for the portal is online. To avoid this issue, Cinder should pass secondary addresses of iSCSI portal to Nova-computes. Proposed change =============== Add an optional 'target_portal_secondary' parameter in 'connection_info' returned by os-initialize_connection volume action API that represents a list of secondary addresses of the iSCSI portal. Nova-compute which can recognize this parameter will send discovery query to every portals to get a list of targets. Old nova-compute just ignores the parameter, so it works without changes if the primary portal address is alive. Alternatives ------------ Return multiple addresses in 'target_portal' parameter, as a list of addresses or a comma separated values. This may confuse old nova-compute. Data model impact ----------------- Backend drivers can put multiple portal addresses into 'provider_location' field of volume tables: provider_location = '<portal ip>:<port>;<portal ip 2>:<port>,<portal> <iqn>' For example, provider_location = '10.0.1.2:3260;10.0.2.2:3260,0 iqn.2010-10.org.openstack: volume-12345678-abcd-1234-5678-12345678abcd' REST API impact --------------- 'os-initialize_connection' volume action API response may have additional parameter 'target_portal_secondary', which contains a list of portal IP addresses and ports. For example: {""connection_info"": {""driver_volume_type"": ""iscsi"", ... ""data"": {""target_portal"": ""10.0.1.2:3260"", ""target_portal_secondary"": [""10.0.2.2:3260"", ""10.0.3.2:3260""], ...}}} Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- Backend driver may have additional settings to enable iSCSI portal multipath. For example, to utilize this feature in iSCSI LVM driver, we needs to specify a list of secodary IP addresses of the cinder-volume node where iSCSI targets run on. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: tsekiyama Work Items ---------- - Implement this feature in LVM iSCSI driver as a sample - Modify nova and brick library to send discovery query to multiple portals Dependencies ============ None Testing ======= - Unit tests should be added for drivers which support this feature, so that initialize_connection will return correct connection_info. Documentation Impact ==================== If the driver needs additional settings for this feature, the documentation for them should be added. References ========== * Enable multipath for libvirt iSCSI Volume Driver (merged) https://review.openstack.org/#/c/17946/ ",,139,0
openstack%2Fcinder-specs~master~I27b29925343d9c634b82cce1f5e28bc1a609bc98,openstack/cinder-specs,master,I27b29925343d9c634b82cce1f5e28bc1a609bc98,Support import/export snapshots in cinder,MERGED,2014-08-25 12:38:49.000000000,2014-12-18 01:24:24.000000000,2014-12-18 01:24:23.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 5538}, {'_account_id': 6491}, {'_account_id': 8874}]","[{'number': 1, 'created': '2014-08-25 12:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/23a4c35524115343bf1384be2cfcd4ae1f64c687', 'message': 'Support import/export snapshots in cinder\n\nCurrently cinder support import/export volume function. Import/export\nsnapshots function could be an complement for the function of\nimport/export volume.\n\nFunctions:\n1.It could provide the ability to import volumes\' snapshot from one cinder\nto another cinder,\nand import ""non"" openstack snapshots already on a back-end device into\nOpenStack/cinder.\n2. Additionally, export snapshots works the same way as export volumes.\n\nBenefits:\nWhen import volumes that have snapshots, we need to import snapshots.\n1. First we could use the import snapshots as volume templates to create\nvolumes.\n2. Import snapshots function could provide an effect mean to manage the\nimport\nvolumes.\n    For example, we could not delete the import volume that has snapshots.\n    By using import snapshots function to import snapshots, we could\n    first delete the import snapshots, and then delete the import volumes.\n\nblueprint support-import-export-snapshots\n\nChange-Id: I27b29925343d9c634b82cce1f5e28bc1a609bc98\n'}, {'number': 2, 'created': '2014-08-26 03:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/ee901fca32c47ed6c27388c656886d2f6f724174', 'message': 'Support import/export snapshots in cinder\n\nCurrently cinder support import/export volume function. Import/export\nsnapshots function could be an complement for the function of\nimport/export volume.\n\nFunctions:\n1.It could provide the ability to import volumes\' snapshot from one cinder\nto another cinder,\nand import ""non"" openstack snapshots already on a back-end device into\nOpenStack/cinder.\n2. Additionally, export snapshots works the same way as export volumes.\n\nBenefits:\nWhen import volumes that have snapshots, we need to import snapshots.\n1. First we could use the import snapshots as volume templates to create\nvolumes.\n2. Import snapshots function could provide an effect mean to manage the\nimport\nvolumes.\n    For example, we could not delete the import volume that has snapshots.\n    By using import snapshots function to import snapshots, we could\n    first delete the import snapshots, and then delete the import volumes.\n\nblueprint support-import-export-snapshots\n\nChange-Id: I27b29925343d9c634b82cce1f5e28bc1a609bc98\n'}, {'number': 3, 'created': '2014-08-26 07:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/a44768678bedead16205cd5f713ace73b2357d7e', 'message': 'Support import/export snapshots in cinder\n\nCurrently cinder support import/export volume function. Import/export\nsnapshots function could be an complement for the function of\nimport/export volume.\n\nFunctions:\n1.It could provide the ability to import volumes\' snapshot from one cinder\nto another cinder,\nand import ""non"" openstack snapshots already on a back-end device into\nOpenStack/cinder.\n2. Additionally, export snapshots works the same way as export volumes.\n\nBenefits:\nWhen import volumes that have snapshots, we need to import snapshots.\n1. First we could use the import snapshots as volume templates to create\nvolumes.\n2. Import snapshots function could provide an effect mean to manage the\nimport\nvolumes.\n    For example, we could not delete the import volume that has snapshots.\n    By using import snapshots function to import snapshots, we could\n    first delete the import snapshots, and then delete the import volumes.\n\nblueprint support-import-export-snapshots\n\nChange-Id: I27b29925343d9c634b82cce1f5e28bc1a609bc98\n'}, {'number': 4, 'created': '2014-08-26 08:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/61bae72a9ae2a4d1901caa39042380e0161ea942', 'message': 'Support import/export snapshots in cinder\n\nCurrently cinder support import/export volume function. Import/export\nsnapshots function could be an complement for the function of\nimport/export volume.\n\nFunctions:\n1.It could provide the ability to import volumes\' snapshot from one cinder\nto another cinder,\nand import ""non"" openstack snapshots already on a back-end device into\nOpenStack/cinder.\n2. Additionally, export snapshots works the same way as export volumes.\n\nBenefits:\nWhen import volumes that have snapshots, we need to import snapshots.\n1. First we could use the import snapshots as volume templates to create\nvolumes.\n2. Import snapshots function could provide an effect mean to manage the\nimport\nvolumes.\n    For example, we could not delete the import volume that has snapshots.\n    By using import snapshots function to import snapshots, we could\n    first delete the import snapshots, and then delete the import volumes.\n\nblueprint support-import-export-snapshots\n\nChange-Id: I27b29925343d9c634b82cce1f5e28bc1a609bc98\n'}, {'number': 5, 'created': '2014-09-15 09:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/16ac39affb5c825da7abe49ced18640fc11200d9', 'message': 'Support import/export snapshots in cinder\n\nCurrently cinder support import/export volume function. Import/export\nsnapshots function could be an complement for the function of\nimport/export volume.\n\nFunctions:\n1.It could provide the ability to import volumes\' snapshot from one cinder\nto another cinder,\nand import ""non"" openstack snapshots already on a back-end device into\nOpenStack/cinder.\n2. Additionally, export snapshots works the same way as export volumes.\n\nBenefits:\nWhen import volumes that have snapshots, we need to import snapshots.\n1. First we could use the import snapshots as volume templates to create\nvolumes.\n2. Import snapshots function could provide an effect mean to manage the\nimport\nvolumes.\n    For example, we could not delete the import volume that has snapshots.\n    By using import snapshots function to import snapshots, we could\n    first delete the import snapshots, and then delete the import volumes.\n\nblueprint support-import-export-snapshots\n\nChange-Id: I27b29925343d9c634b82cce1f5e28bc1a609bc98\n'}, {'number': 6, 'created': '2014-09-16 12:23:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/5e54bab983a18edd097347579f614d03dcdf30b1', 'message': 'Support import/export snapshots in cinder\n\nCurrently cinder support import/export volume function. Import/export\nsnapshots function could be an complement for the function of\nimport/export volume.\n\nFunctions:\n1.It could provide the ability to import volumes\' snapshot from one cinder\nto another cinder,\nand import ""non"" openstack snapshots already on a back-end device into\nOpenStack/cinder.\n2. Additionally, export snapshots works the same way as export volumes.\n\nBenefits:\nWhen import volumes that have snapshots, we need to import snapshots.\n1. First we could use the import snapshots as volume templates to create\nvolumes.\n2. Import snapshots function could provide an effect mean to manage the\nimport\nvolumes.\n    For example, we could not delete the import volume that has snapshots.\n    By using import snapshots function to import snapshots, we could\n    first delete the import snapshots, and then delete the import volumes.\n\nblueprint support-import-export-snapshots\n\nChange-Id: I27b29925343d9c634b82cce1f5e28bc1a609bc98\n'}, {'number': 7, 'created': '2014-09-17 06:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/4454daec96ae6a98425f4fca16f9c6e7a5821062', 'message': 'Support import/export snapshots in cinder\n\nCurrently cinder support import/export volume function. Import/export\nsnapshots function could be an complement for the function of\nimport/export volume.\n\nFunctions:\n1.It could provide the ability to import volumes\' snapshot from one cinder\nto another cinder,\nand import ""non"" openstack snapshots already on a back-end device into\nOpenStack/cinder.\n2. Additionally, export snapshots works the same way as export volumes.\n\nBenefits:\nWhen import volumes that have snapshots, we need to import snapshots.\n1. First we could use the import snapshots as volume templates to create\nvolumes.\n2. Import snapshots function could provide an effect mean to manage the\nimport\nvolumes.\n    For example, we could not delete the import volume that has snapshots.\n    By using import snapshots function to import snapshots, we could\n    first delete the import snapshots, and then delete the import volumes.\n\nblueprint support-import-export-snapshots\n\nChange-Id: I27b29925343d9c634b82cce1f5e28bc1a609bc98\n'}, {'number': 8, 'created': '2014-09-18 10:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/8243f1b791a7c2a72044a5653838844d51687000', 'message': 'Support import/export snapshots in cinder\n\nCurrently cinder support import/export volume function. Import/export\nsnapshots function could be an complement for the function of\nimport/export volume.\n\nFunctions:\n1.It could provide the ability to import volumes\' snapshot from one cinder\nto another cinder,\nand import ""non"" openstack snapshots already on a back-end device into\nOpenStack/cinder.\n2. Additionally, export snapshots works the same way as export volumes.\n\nBenefits:\nWhen import volumes that have snapshots, we need to import snapshots.\n1. First we could use the import snapshots as volume templates to create\nvolumes.\n2. Import snapshots function could provide an effect mean to manage the\nimport\nvolumes.\n    For example, we could not delete the import volume that has snapshots.\n    By using import snapshots function to import snapshots, we could\n    first delete the import snapshots, and then delete the import volumes.\n\nblueprint support-import-export-snapshots\n\nChange-Id: I27b29925343d9c634b82cce1f5e28bc1a609bc98\n'}, {'number': 9, 'created': '2014-12-17 19:47:43.000000000', 'files': ['specs/kilo/support-import-export-snapshots.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/34e3558116f36fc5360da832a00f100404e13b6d', 'message': 'Support import/export snapshots in cinder\n\nCurrently cinder support import/export volume function. Import/export\nsnapshots function could be an complement for the function of\nimport/export volume.\n\nFunctions:\n1.It could provide the ability to import volumes\' snapshot from one cinder\nto another cinder,\nand import ""non"" openstack snapshots already on a back-end device into\nOpenStack/cinder.\n2. Additionally, export snapshots works the same way as export volumes.\n\nBenefits:\nWhen import volumes that have snapshots, we need to import snapshots.\n1. First we could use the import snapshots as volume templates to create\nvolumes.\n2. Import snapshots function could provide an effect mean to manage the\nimport\nvolumes.\n    For example, we could not delete the import volume that has snapshots.\n    By using import snapshots function to import snapshots, we could\n    first delete the import snapshots, and then delete the import volumes.\n\nblueprint support-import-export-snapshots\n\nChange-Id: I27b29925343d9c634b82cce1f5e28bc1a609bc98\n'}]",6,116599,34e3558116f36fc5360da832a00f100404e13b6d,33,8,9,8874,,,0,"Support import/export snapshots in cinder

Currently cinder support import/export volume function. Import/export
snapshots function could be an complement for the function of
import/export volume.

Functions:
1.It could provide the ability to import volumes' snapshot from one cinder
to another cinder,
and import ""non"" openstack snapshots already on a back-end device into
OpenStack/cinder.
2. Additionally, export snapshots works the same way as export volumes.

Benefits:
When import volumes that have snapshots, we need to import snapshots.
1. First we could use the import snapshots as volume templates to create
volumes.
2. Import snapshots function could provide an effect mean to manage the
import
volumes.
    For example, we could not delete the import volume that has snapshots.
    By using import snapshots function to import snapshots, we could
    first delete the import snapshots, and then delete the import volumes.

blueprint support-import-export-snapshots

Change-Id: I27b29925343d9c634b82cce1f5e28bc1a609bc98
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/99/116599/9 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/support-import-export-snapshots.rst'],1,23a4c35524115343bf1384be2cfcd4ae1f64c687,bp/support-import-export-snapshots,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================= Support import/export snapshots in cinder ========================================= Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/cinder/+spec/support-import-export-snapshots Provide a mean to import/export snapshots. Import/export snapshots function could be an complement for the function of import/export volume. Problem description =================== Import/export snapshots function: * It could provide the ability to import volumes' snapshot from one cinder to another cinder, and and import ""non"" OpenStack snapshots already on a back-end device into OpenStack/cinder. * Export snapshots works the same way as export volumes. Benefits: * We could use the import snapshots as volume templates to create volumes from snapshots. * Import snapshots function could provide an effect mean to manage the import volumes. :: For example, we could not delete the import volume that has snapshots. By using import snapshots function to import snapshots, we could first delete the import snapshots, and then delete the import volumes. Proposed change =============== By supporting import/export snapshots, we need to do the following changes. * Add import/export snapshots API. * Add import/export snapshots work flow. :: Export snapshots work almost the same as delete snapshot, but it doesn't delete the snapshot data. * Add manage_snapshot_existing and manage_existing_get_size interface in volume driver and implement these two interface in LVM driver. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- 1. Add one API ""manage_snapshot"" The rest API look like this in v2:: /v2/{project_id}/os-snapshot-manage { 'snapshot':{ 'host': 'cinder-volume', 'volume_id': 'volume-058660ab-6771-4f82-9627-687b179175d6' 'ref': '_snapshot-058660ab-6771-4f82-9627-687b179175d6' } } * The <string> 'host' means cinder volume host name. No default value. * The <string> 'volume_id' means the import snapshot's volume id. No default value. * The <string> 'ref' means the import snapshot name exist in storage back-end. No default value. The response body of it is like:: { ""snapshot"": { ""status"": ""creating"", ""description"": null, ""created_at"": ""2014-08-25T11:14:31.469591"", ""metadata"": {}, ""volume_id"": ""fbd83a45-cce7-4333-b991-dafd2251edd4"", ""size"": 1, ""id"": ""71543ced-a8af-45b6-a5c4-a46282108a90"", ""name"": null } } * The <string> 'status' will be creating. * The <string> 'description' means the import snapshot display name. * The <date> 'created_at' means the import time. * The <map> 'metadata' means the snapshot's metadata. * The <string> 'volume_id' means the snapshot's volume id. * The <string> 'id' means the snapshot's id. * The <string> 'name' means the alias of snapshot id. 2. Add one API ""unmanage_snapshot"". The rest API look like this in v2:: /v2/{project_id}/os-snapshot-manage/{id}/action { 'os-unmanage':{} } The status code will be HTTP 202 when the request has succeeded. Security impact --------------- None Notifications impact -------------------- None. Other end user impact --------------------- Users can import snapshots that are already exist in volume back-end storage device. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: ling-yun<zengyunling@huawei.com> Work Items ---------- * Implement code that mentioned in ""Proposed change"". * Add change API doc. Dependencies ============ None Testing ======= Both unit and Tempest tests need to be created to cover the code change that mentioned in ""Proposed change"" and ensure that Cinder snapshot feature works well while introducing import/export snapshots. Documentation Impact ==================== The cinder API documentation will need to be updated to reflect the REST API changes. References ========== None ",,201,0
openstack%2Fnova-specs~master~I14193b3be2dcad14f0cd4ffede720b44a8629877,openstack/nova-specs,master,I14193b3be2dcad14f0cd4ffede720b44a8629877,Add blueprint for make swap disk use ram,ABANDONED,2014-10-29 13:09:31.000000000,2014-12-18 01:16:24.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-10-29 13:09:31.000000000', 'files': ['specs/kilo/approved/make-swap-disk-use-ram.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/84c3bf765e9d95069273c59cf87e6aaa4cbad07e', 'message': 'Add blueprint for make swap disk use ram\n\nuse ram disk instead of hard disk as swap disk.\n\nChange-Id: I14193b3be2dcad14f0cd4ffede720b44a8629877\n'}]",1,131740,84c3bf765e9d95069273c59cf87e6aaa4cbad07e,4,3,1,6062,,,0,"Add blueprint for make swap disk use ram

use ram disk instead of hard disk as swap disk.

Change-Id: I14193b3be2dcad14f0cd4ffede720b44a8629877
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/40/131740/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/make-swap-disk-use-ram.rst'],1,84c3bf765e9d95069273c59cf87e6aaa4cbad07e,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================== Query lock status of instance ================================================== https://blueprints.launchpad.net/nova/+spec/make-swap-disk-use-ram Make hypervisor able to use ram disk as swap disk. Problem description =================== Currently the guest can only use disks as their swap devices. However, under some circumstance, the swap disk in RAM will make the performance better. Use Cases --------- Guest under high I/O workload can utilize ram as their swap disk. Project Priority ----------------- Low Proposed change =============== Alternatives ------------ Keep existing solution, only store swap disk to hard disk. Data model impact ----------------- None REST API impact --------------- Add an option to boot command like --swap-use-ram. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None Performance Impact ------------------ Guest under high I/O will benfit. Other deployer impact --------------------- None. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: jichenjc Work Items ---------- * change API layer to add supported interface listed above. * change compute layer to check whether a flavor with 'swap-use-ram' extra key is there or the boot option has 'swap-use-ram' * change low lower virt driver (libvirt planned) to create ram disk instead of create disk * considering the ram usage's side effect to host ram calculation Dependencies ============ None Testing ======= None Documentation Impact ==================== API document will be updated in order to support 'swap-use-ram' option References ========== None ",,118,0
openstack%2Fpuppet-monasca~master~I635920bb4ecb2a35caa33a8709517901e84f797e,openstack/puppet-monasca,master,I635920bb4ecb2a35caa33a8709517901e84f797e,Changed yaml files for checks to build with concat,MERGED,2014-12-17 17:01:56.000000000,2014-12-18 01:11:17.000000000,2014-12-18 01:11:17.000000000,"[{'_account_id': 3}, {'_account_id': 8126}]","[{'number': 1, 'created': '2014-12-17 17:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/f4ec277d3365f92b11ec94b991c8e7d875400d03', 'message': 'Changed yaml files for checks to build with concat\n\nChange-Id: I635920bb4ecb2a35caa33a8709517901e84f797e\n'}, {'number': 2, 'created': '2014-12-17 19:32:00.000000000', 'files': ['manifests/checks/network.pp', 'templates/checks/nagios_wrapper.yaml.erb', 'templates/checks/http_check.erb', 'manifests/checks/host_alive.pp', 'manifests/checks/instances/host_alive.pp', 'manifests/checks/instances/nagios_wrapper.pp', 'manifests/checks/rabbitmq.pp', 'manifests/checks/instances/apache.pp', 'manifests/checks/zk.pp', 'manifests/checks/instances/zk.pp', 'manifests/checks/apache.pp', 'manifests/checks/instances/network.pp', 'templates/checks/rabbitmq.erb', 'manifests/checks/instances/http_check.pp', 'manifests/checks/instances/rabbitmq.pp', 'templates/checks/apache.erb', 'templates/checks/host_alive.yaml.erb', 'manifests/checks/instances/process.pp', 'manifests/checks/mysql.pp', 'templates/checks/host_alive.erb', 'templates/checks/nagios_wrapper.erb', 'templates/checks/generic.yaml.erb', 'templates/checks/mysql.erb', 'templates/checks/zk.erb', 'templates/checks/process.erb', 'manifests/checks/instances/mysql.pp', 'templates/checks/network.erb', 'manifests/checks/http_check.pp', 'manifests/checks/process.pp', 'manifests/checks/nagios_wrapper.pp'], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/13ea7d6cd448feb85366283fd9623e6ee5730944', 'message': 'Changed yaml files for checks to build with concat\n\nChange-Id: I635920bb4ecb2a35caa33a8709517901e84f797e\n'}]",0,142506,13ea7d6cd448feb85366283fd9623e6ee5730944,7,2,2,11155,,,0,"Changed yaml files for checks to build with concat

Change-Id: I635920bb4ecb2a35caa33a8709517901e84f797e
",git fetch https://review.opendev.org/openstack/puppet-monasca refs/changes/06/142506/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/checks/network.pp', 'templates/checks/nagios_wrapper.yaml.erb', 'templates/checks/http_check.erb', 'manifests/checks/host_alive.pp', 'manifests/checks/instances/host_alive.pp', 'manifests/checks/instances/nagios_wrapper.pp', 'manifests/checks/rabbitmq.pp', 'manifests/checks/instances/apache.pp', 'manifests/checks/zk.pp', 'manifests/checks/instances/zk.pp', 'manifests/checks/apache.pp', 'manifests/checks/instances/network.pp', 'templates/checks/rabbitmq.erb', 'manifests/checks/instances/http_check.pp', 'manifests/checks/instances/rabbitmq.pp', 'templates/checks/apache.erb', 'templates/checks/host_alive.yaml.erb', 'manifests/checks/instances/process.pp', 'manifests/checks/mysql.pp', 'templates/checks/host_alive.erb', 'templates/checks/nagios_wrapper.erb', 'templates/checks/generic.yaml.erb', 'templates/checks/mysql.erb', 'templates/checks/zk.erb', 'templates/checks/process.erb', 'manifests/checks/instances/mysql.pp', 'templates/checks/network.erb', 'manifests/checks/http_check.pp', 'manifests/checks/process.pp', 'manifests/checks/nagios_wrapper.pp']",30,f4ec277d3365f92b11ec94b991c8e7d875400d03,,"# An hash of instances for the check.# service_name (the instance key): The name of the instance.# instances: # load: # check_command: 'check_load -r -w 2,1.5,1 -c 10,5,4' # disk: # check_command: 'check_disk -w 15\% -c 5\% -A -i /srv/node' # check_interval: '300' $instances = undef, if($instances){ Concat[""${conf_dir}/nagios_wrapper.yaml""] ~> Service['monasca-agent'] concat { ""${conf_dir}/nagios_wrapper.yaml"": owner => 'root', group => $::monasca::group, mode => '0640', warn => true, require => File[$conf_dir], } concat::fragment { 'nagios_wrapper_header': target => ""${conf_dir}/nagios_wrapper.yaml"", order => '0', content => template('monasca/checks/nagios_wrapper.yaml.erb'), } create_resources('monasca::checks::instances::nagios_wrapper', $instances) }","# An array of instances for the check.# name (required)# $instances = [{service_name => 'load', # check_command => 'check_load -r -w 2,1.5,1 -c 10,5,4'}, # {service_name => 'disk', # check_command => 'check_disk -w 15\% -c 5\% -A -i /srv/node', # check_interval => '300'}] $instances = [], File[""${conf_dir}/nagios_wrapper.yaml""] ~> Service['monasca-agent'] file { ""${conf_dir}/nagios_wrapper.yaml"": owner => 'root', group => $::monasca::group, mode => '0640', content => template('monasca/checks/nagios_wrapper.yaml.erb'), require => File[$conf_dir], } ",488,172
openstack%2Fnova-specs~master~I9e8e760497122d120e9c4fbf690993747281c30a,openstack/nova-specs,master,I9e8e760497122d120e9c4fbf690993747281c30a,Cells instance mapping,MERGED,2014-11-19 16:37:08.000000000,2014-12-18 01:03:45.000000000,2014-12-18 01:03:44.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 3031}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9420}, {'_account_id': 12548}, {'_account_id': 12898}, {'_account_id': 13530}]","[{'number': 1, 'created': '2014-11-19 16:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/acdd4e1b570971862741b913a35cc7266ff2662e', 'message': 'Cells instance mapping\n\nSpec for adding a new table that can map an instance to the cell that it\nlives in.\n\nbp cells-instance-mapping\n\nChange-Id: I9e8e760497122d120e9c4fbf690993747281c30a\n'}, {'number': 2, 'created': '2014-11-20 20:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4a8d84e08a1fbba9129c0579c720ce309b8b59a6', 'message': 'Cells instance mapping\n\nSpec for adding a new table that can map an instance to the cell that it\nlives in.\n\nbp cells-instance-mapping\n\nChange-Id: I9e8e760497122d120e9c4fbf690993747281c30a\n'}, {'number': 3, 'created': '2014-11-21 21:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e0806f834a764485be708a5c835df7f1aac7d8b2', 'message': 'Cells instance mapping\n\nSpec for adding a new table that can map an instance to the cell that it\nlives in.\n\nbp cells-instance-mapping\n\nChange-Id: I9e8e760497122d120e9c4fbf690993747281c30a\n'}, {'number': 4, 'created': '2014-11-24 19:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/29daf4248542b4407620f993ac7691ce8da3c8df', 'message': 'Cells instance mapping\n\nSpec for adding a new table that can map an instance to the cell that it\nlives in.\n\nbp cells-instance-mapping\n\nChange-Id: I9e8e760497122d120e9c4fbf690993747281c30a\n'}, {'number': 5, 'created': '2014-12-02 20:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9e4661bf6ad3f1345b5d834153c695c2795fe4e9', 'message': 'Cells instance mapping\n\nSpec for adding a new table that can map an instance to the cell that it\nlives in.\n\nbp cells-instance-mapping\n\nChange-Id: I9e8e760497122d120e9c4fbf690993747281c30a\n'}, {'number': 6, 'created': '2014-12-05 20:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7cf8e119c167df6ce3dcba678a14eafe04925668', 'message': 'Cells instance mapping\n\nSpec for adding a new table that can map an instance to the cell that it\nlives in.\n\nbp cells-instance-mapping\n\nChange-Id: I9e8e760497122d120e9c4fbf690993747281c30a\n'}, {'number': 7, 'created': '2014-12-08 20:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c7273f6bc7d0cd58b0369f6e031db5be0f53bdcf', 'message': 'Cells instance mapping\n\nSpec for adding a new table that can map an instance to the cell that it\nlives in.\n\nbp cells-instance-mapping\n\nChange-Id: I9e8e760497122d120e9c4fbf690993747281c30a\n'}, {'number': 8, 'created': '2014-12-12 20:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c6728ab973a31d976e1ca18825a56b402cdcb54c', 'message': 'Cells instance mapping\n\nSpec for adding a new table that can map an instance to the cell that it\nlives in.\n\nbp cells-instance-mapping\n\nChange-Id: I9e8e760497122d120e9c4fbf690993747281c30a\n'}, {'number': 9, 'created': '2014-12-15 21:42:43.000000000', 'files': ['specs/kilo/approved/cells-instance-mapping.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b4f74f1b7e315ed6c0e75a87b472849d0e1b9e64', 'message': 'Cells instance mapping\n\nSpec for adding a new table that can map an instance to the cell that it\nlives in.\n\nbp cells-instance-mapping\n\nChange-Id: I9e8e760497122d120e9c4fbf690993747281c30a\n'}]",49,135644,b4f74f1b7e315ed6c0e75a87b472849d0e1b9e64,63,13,9,5441,,,0,"Cells instance mapping

Spec for adding a new table that can map an instance to the cell that it
lives in.

bp cells-instance-mapping

Change-Id: I9e8e760497122d120e9c4fbf690993747281c30a
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/44/135644/9 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/cells-instance-mapping.rst'],1,acdd4e1b570971862741b913a35cc7266ff2662e,bp/cells-instance-mapping,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Cells instance mapping ========================================== https://blueprints.launchpad.net/nova/+spec/cells-instance-mapping In order for compute api nodes to communicate with the correct cell for an instance there will need to be a mapping of instance to cell. A new table will be created which can store this mapping. Problem description =================== When Nova is partitioned into cells, the compute api needs to know which cell to communicate with for a particular instance. There is currently no mapping of instance to cell in which it lives. Use Cases ---------- * Developers who want to make database queries or send RPC messages to the specific cell that an instance is in. Project Priority ----------------- Cells v2 has been made a project priority for Kilo. Proposed change =============== The change being proposed is a new table for storing a mapping of instance to cell. There is nothing in place to use this yet so the scope of work ends at just having the capability to do it. Alternatives ------------ We could continue to use the nova-cells model in place today. The downsides of this have been discussed in the etherpad link in the references section. Data model impact ----------------- A new 'instance_mapping' table will be added. And it should be added to the 'nova_api' database. The table will look approximately like: CREATE TABLE `instance_mapping` ( `created_at` datetime DEFAULT NULL, `updated_at` datetime DEFAULT NULL, `deleted_at` datetime DEFAULT NULL, `id` int(11) NOT NULL AUTO_INCREMENT, `instance_uuid` varchar(36) NOT NULL, `cell_uuid` varchar(36) NOT NULL, `project_id` varchar(255) NOT NULL, `deleted` int(11) DEFAULT NULL) REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ On its own this change does not introduce a performance impact. When it's used by later specs it does introduce another database lookup for many actions within Nova. For example a 'nova show <uuid>' will require Nova to look up the database that an instance is in before it can query it for instance data. Other deployer impact --------------------- This introduces a new table into the 'nova_api' database. Developer impact ---------------- Developers should be beginning to see that all instances in a deployment may not be in the same database. But no development changes should necessary at this point. Implementation ============== Assignee(s) ----------- Primary assignee: alaski Other contributors: <launchpad-id or None> Work Items ---------- * Add database migration for 'instance_mapping' table. Dependencies ============ https://blueprints.launchpad.net/nova/+spec/cells-v2-mapping Testing ======= Since this is designed to be an internal re-architecting of Nova with no user visible changes the current suite of Tempest or functional tests should suffice. At some point we will want to look at how to test multiple cells or potentially exposing the concept of a cell in the API and we will tackle testing requirements then. Documentation Impact ==================== Documentation should be added about the new table and what its usage will be. References ========== ``https://etherpad.openstack.org/p/kilo-nova-cells`` ",,155,0
openstack%2Fnova~master~I293fa45458492c1fdfe3e68eb5eca0d2b76ebd66,openstack/nova,master,I293fa45458492c1fdfe3e68eb5eca0d2b76ebd66,Enables rescheduling when rebuild instance.,ABANDONED,2014-12-17 08:46:03.000000000,2014-12-18 01:03:44.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 08:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b6b98fef905481088a19e5d250560135a3047b4', 'message': 'Enables rescheduling when rebuild instance.\n\nThis patches enables rescheduling when rebuild instance failed\nby claim test failed.\n\nChange-Id: I293fa45458492c1fdfe3e68eb5eca0d2b76ebd66\nPartial-Bug: #1400015\n'}, {'number': 2, 'created': '2014-12-17 09:11:51.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e665d990fea872cbe1d6feea1571c3f57f1d2b5e', 'message': 'Enables rescheduling when rebuild instance.\n\nThis patches enables rescheduling when rebuild instance failed\nby claim test failed.\n\nChange-Id: I293fa45458492c1fdfe3e68eb5eca0d2b76ebd66\nCo-Authored-By: Alex Xu <hejie.xu@intel.com>\nPartial-Bug: #1400015\n'}]",0,142382,e665d990fea872cbe1d6feea1571c3f57f1d2b5e,10,6,2,6062,,,0,"Enables rescheduling when rebuild instance.

This patches enables rescheduling when rebuild instance failed
by claim test failed.

Change-Id: I293fa45458492c1fdfe3e68eb5eca0d2b76ebd66
Co-Authored-By: Alex Xu <hejie.xu@intel.com>
Partial-Bug: #1400015
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/142382/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,3b6b98fef905481088a19e5d250560135a3047b4,rebuild_retry_when_no_valid_host_5," try: with rt.instance_claim(context, instance, limits): self._rebuild_handle(**kwargs) except exception.ComputeResourcesUnavailable as e: LOG.debug(e.format_message(), instance=instance) retry = filter_properties.get('retry', None) if not retry: LOG.debug(""Retry info not present, will not "" ""reschedule"", instance=instance) return retry['exc'] = traceback.format_exception(*sys.exc_info()) instance.task_state = task_states.REBUILDING instance.save() self.compute_task_api.rebuild_instance(context, instance=instance, new_pass=new_pass, injected_files=injected_files, image_ref=image_ref, orig_image_ref=orig_image_ref, orig_sys_metadata=orig_sys_metadata, bdms=bdms, preserve_ephemeral=preserve_ephemeral, host=instance.host, filter_properties=filter_properties, kwargs=kwargs) return"," with rt.instance_claim(context, instance, limits): self._rebuild_handle(**kwargs)",24,2
openstack%2Fglance-specs~master~I3ff8611f270006835bf34bc4405ca7684387f91a,openstack/glance-specs,master,I3ff8611f270006835bf34bc4405ca7684387f91a,Add glance-manage configuration file specification,MERGED,2014-11-16 16:22:53.000000000,2014-12-18 01:03:34.000000000,2014-12-18 01:03:33.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 8158}, {'_account_id': 11356}, {'_account_id': 12000}, {'_account_id': 13717}]","[{'number': 1, 'created': '2014-11-16 16:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/46ae0464a72294902aff3a3d25fa52354bad3eac', 'message': ""Add glance-manage configuration file specification\n\nPer discussion on IRC and bug #1391211, I'm creating a new specification\nto describe the changes necessary to craft a fix.\n\nRelated-bug: #1391211\nChange-Id: I3ff8611f270006835bf34bc4405ca7684387f91a\n""}, {'number': 2, 'created': '2014-11-19 03:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/36bf2f22a5ded3196a39ce7ed6cf56a57a4a5dc8', 'message': ""Add glance-manage configuration file specification\n\nPer discussion on IRC and bug #1391211, I'm creating a new specification\nto describe the changes necessary to craft a fix.\n\nRelated-bug: #1391211\nChange-Id: I3ff8611f270006835bf34bc4405ca7684387f91a\n""}, {'number': 3, 'created': '2014-11-25 16:59:20.000000000', 'files': ['specs/kilo/create-glance-manage-conf.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/38b17681daf7cb06fa14adaa970521e8cd8da5f4', 'message': ""Add glance-manage configuration file specification\n\nPer discussion on IRC and bug #1391211, I'm creating a new specification\nto describe the changes necessary to craft a fix.\n\nBlueprint create-glance-manage-conf\nRelated-bug: #1391211\nChange-Id: I3ff8611f270006835bf34bc4405ca7684387f91a\n""}]",21,134810,38b17681daf7cb06fa14adaa970521e8cd8da5f4,21,8,3,12000,,,0,"Add glance-manage configuration file specification

Per discussion on IRC and bug #1391211, I'm creating a new specification
to describe the changes necessary to craft a fix.

Blueprint create-glance-manage-conf
Related-bug: #1391211
Change-Id: I3ff8611f270006835bf34bc4405ca7684387f91a
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/10/134810/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/create-glance-manage-conf.rst'],1,46ae0464a72294902aff3a3d25fa52354bad3eac,bug/1391211,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================ Create and Use ``glance-manage`` config file ============================================ https://blueprints.launchpad.net/glance/+spec/create-glance-manage ``glance-manage`` currently uses the configuration files meant for ``glance-registry`` and ``glance-api``. This was ostensibly done to reduce the number of places that an operator may need to add, update, or remove settings. I would like to create a ``glance-manage.conf`` file to allow ``glance-manage`` to be independently configured. Problem description =================== If ``glance-api`` is started by a user (or service) but a different user tries to use ``glance-manage`` they can encounter permissions errors if ``/var/log/glance/api.log`` is not writable to by the user trying to use ``glance-manage``. While this is one symptom of the dependence on the registry and api configuration files, more may soon appear. Proposed change =============== I am proposing that we add another configuration file, ``glance-manage.conf`` to side-step this and any other issues we have with depending on the registry and api's configuration files. For Kilo, we will add the ``glance-manage.conf`` file and continue to load the ``glance-registry.conf`` and ``glance-api.conf`` files in the ``glance-manage`` command setup step. Currently the load order of configuration files (which causes ``glance-manage`` to use ``/var/log/glance/api.log``) is: - ``glance-registry.conf`` - ``glance-api.conf`` We will preserve this order and then load ``glance-manage.conf``. We will only default to setting ``log_file`` in ``glance-manage.conf`` to prevent overriding settings from the other two files. We will also issue a deprecation warning pointing to this specification so that operators and end users know to configure ``glance-manage.conf`` for the L cycle. In the L cycle, we will stop depending on ``glance-registry.conf`` and ``glance-api.conf``. The documentation should also immediately begin to instruct users to configure settings for ``glance-manage`` in ``glance-manage.conf``. Alternatives ------------ One way we could address this would be to remove the default ``log_file`` values in Glance's configuration files. If we did this, all log files would then be named ``/var/log/{{ command }}.log``, e.g., ``/var/log/glance-api.log`` would be the file used by ``glance-api``. We other settings around the current way of logging. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- This would introduce another file that would need to be edited by end users. Some settings may also be present in ``glance-registry.conf`` and ``glance-api.conf``. Any potential security problems caused by needing to copy and synchronize settings between three files are applicable here. Notifications impact -------------------- None Other end user impact --------------------- This introduces another file with configuration options. Common configuration options for will need to be copied and pasted from file-to-file and will need attention to keep synchronized. This will likely increase the complexity of maintaining an installation of Glance. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: icordasc Other contributors: None Reviewers --------- Core reviewer(s): nikhil-komawar None Other reviewer(s): kragniz None Work Items ---------- - Generate a default ``glance-manage.conf`` as described above - Begin loading it in ``glance-manage`` - Add deprecation messages regarding ``glance-registry.conf`` and ``glance-api.conf``. Dependencies ============ None Testing ======= We can test this by ensuring that a separate log file is generated for ``glance-manage``, i.e., ``/var/log/glance/manage.log`` is present after running the command. Documentation Impact ==================== This will require the documentation team to describe how to configure ``glance-manage`` to continue working as it has in the past. References ========== * https://bugs.launchpad.net/glance/+bug/1391211 ",,170,0
openstack%2Fdesignate~master~I92bca80063f2d5cf4d74f31668f8879aa3c53841,openstack/designate,master,I92bca80063f2d5cf4d74f31668f8879aa3c53841,Added smart update of Records Objects in v2,MERGED,2014-12-15 19:49:49.000000000,2014-12-18 01:03:22.000000000,2014-12-18 01:03:21.000000000,"[{'_account_id': 3}, {'_account_id': 395}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2014-12-15 19:49:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/633597f96a5a1146f3dda9e1c3068230a6f5d8e5', 'message': 'Added smart update of Records Objects during a v2 RRSet PUT operation\n\nChange-Id: I92bca80063f2d5cf4d74f31668f8879aa3c53841\nCloses-Bug: 1396720\n'}, {'number': 2, 'created': '2014-12-15 19:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/b24d5a13b4e523783e5f59164a0fce7fd71fbed6', 'message': 'Added smart update of Records Objects in v2\n\nIn the V2 API RRSet PUT operation we now only create /\ndelete records that have changed\n\nChange-Id: I92bca80063f2d5cf4d74f31668f8879aa3c53841\nCloses-Bug: 1396720\n'}, {'number': 3, 'created': '2014-12-15 21:31:29.000000000', 'files': ['designate/api/v2/controllers/recordsets.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/95e824993db148a867ce2eeb839fcb9d90173d53', 'message': 'Added smart update of Records Objects in v2\n\nIn the V2 API RRSet PUT operation we now only create /\ndelete records that have changed\nChange-Id: I92bca80063f2d5cf4d74f31668f8879aa3c53841\nCloses-Bug: 1396720\n'}]",5,141887,95e824993db148a867ce2eeb839fcb9d90173d53,17,6,3,8099,,,0,"Added smart update of Records Objects in v2

In the V2 API RRSet PUT operation we now only create /
delete records that have changed
Change-Id: I92bca80063f2d5cf4d74f31668f8879aa3c53841
Closes-Bug: 1396720
",git fetch https://review.opendev.org/openstack/designate refs/changes/87/141887/3 && git format-patch -1 --stdout FETCH_HEAD,['designate/api/v2/controllers/recordsets.py'],1,633597f96a5a1146f3dda9e1c3068230a6f5d8e5,bug/1396720,"from designate.objects import RecordSet, Record new_recordset = self._view.load(context, request, body) # Get original list of Records original_records = set() for record in recordset.records: original_records.add(record.data) # Get new list of Records new_records = set() for record in new_recordset['records']: new_records.add(record.data) # Get differences of Records records_to_add = new_records.difference(original_records) records_to_rm = original_records.difference(new_records) # Update all items except records del new_recordset['records'] recordset.update(new_recordset) # Remove deleted records for record in recordset.records: if record.data in records_to_rm: recordset.records.remove(record) # Add new records for record in records_to_add: recordset.records.append(Record(data=record)) # Persist the resource","from designate.objects import RecordSet # Update and persist the resource recordset.update(self._view.load(context, request, body))",28,3
openstack%2Fnova~master~Ib10411f8493db74593ebe367dbaddfeefb4738dd,openstack/nova,master,Ib10411f8493db74593ebe367dbaddfeefb4738dd,Add instance claim for evacuate operations,ABANDONED,2014-12-16 06:55:11.000000000,2014-12-18 01:03:17.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-16 06:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07f23f93c27283f7f8520a3c82a1596c2ff90baf', 'message': 'Add instance claim for evacuate operations\n\nThere is no instance claim when we do evacuate operation,\nthis patch adds the claim function because it will create\nanother instance on the specified host.\n\nChange-Id: Ib10411f8493db74593ebe367dbaddfeefb4738dd\nPartial-Bug: #1289064\n'}, {'number': 2, 'created': '2014-12-17 08:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6eb65ca50db858546c919fb23a6f1842222ef4f5', 'message': 'Add instance claim for evacuate operations\n\nThere is no instance claim when we do evacuate operation,\nthis patch adds the claim function because it will create\nanother instance on the specified host.\n\nChange-Id: Ib10411f8493db74593ebe367dbaddfeefb4738dd\nPartial-Bug: #1289064\n'}, {'number': 3, 'created': '2014-12-17 09:11:51.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5e1d063446e61184373a8b2a36702dcd5ea5b4ab', 'message': 'Add instance claim for evacuate operations\n\nThere is no instance claim when we do evacuate operation,\nthis patch adds the claim function because it will create\nanother instance on the specified host.\n\nChange-Id: Ib10411f8493db74593ebe367dbaddfeefb4738dd\nCo-Authored-By: Alex Xu <hejie.xu@intel.com>\nPartial-Bug: #1289064\n'}]",0,142001,5e1d063446e61184373a8b2a36702dcd5ea5b4ab,17,6,3,6062,,,0,"Add instance claim for evacuate operations

There is no instance claim when we do evacuate operation,
this patch adds the claim function because it will create
another instance on the specified host.

Change-Id: Ib10411f8493db74593ebe367dbaddfeefb4738dd
Co-Authored-By: Alex Xu <hejie.xu@intel.com>
Partial-Bug: #1289064
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/142001/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,07f23f93c27283f7f8520a3c82a1596c2ff90baf,rebuild_retry_when_no_valid_host_5," def _rebuild_handle(self, **kwargs): try: self.driver.rebuild(**kwargs) except NotImplementedError: # NOTE(rpodolyaka): driver doesn't provide specialized version # of rebuild, fall back to the default implementation self._rebuild_default_impl(**kwargs) def _rebuild_handle_claim(self, limits, **kwargs): recreate = kwargs.get('recreate') context = kwargs.get('context') instance = kwargs.get('instance') if recreate: rt = self._get_resource_tracker(instance.node) with rt.instance_claim(context, instance, limits): self._rebuild_handle(**kwargs) else: self._rebuild_handle(**kwargs) if not filter_properties: filter_properties = {} limits = filter_properties.get('limits', {}) self._rebuild_handle_claim(limits, **kwargs) "," try: self.driver.rebuild(**kwargs) except NotImplementedError: # NOTE(rpodolyaka): driver doesn't provide specialized version # of rebuild, fall back to the default implementation self._rebuild_default_impl(**kwargs)",26,6
openstack%2Fnova~master~I2b6a39201c3b28da904115b9f7dc0f3e8a43932d,openstack/nova,master,I2b6a39201c3b28da904115b9f7dc0f3e8a43932d,Add filter_properities to compute rpc call.,ABANDONED,2014-12-16 06:55:11.000000000,2014-12-18 01:03:00.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 8412}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-16 06:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/34a3461431881104764f2c99b013f30c0cd0e56f', 'message': ""Add filter_properities to compute rpc call\n\nCurrently the filter_properities is not in compute RPC call.\nThis patch add the value to RPC call so that compute node\ncan know whether it need to reschedule to another host\nif it's needed.\n\nChange-Id: I2b6a39201c3b28da904115b9f7dc0f3e8a43932d\nPartial-Bug: #1400015\n""}, {'number': 2, 'created': '2014-12-17 07:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2ebb6b54ace514d323d6cdf8895fd87765e6c307', 'message': ""Add filter_properities to compute rpc call\n\nCurrently the filter_properities is not in compute RPC call.\nThis patch add the value to RPC call so that compute node\ncan know whether it need to reschedule to another host\nif it's needed.\n\nChange-Id: I2b6a39201c3b28da904115b9f7dc0f3e8a43932d\nPartial-Bug: #1400015\n""}, {'number': 3, 'created': '2014-12-17 08:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f0c726f3900ed1f4d88d32ab8b704d35e284dd2', 'message': ""Add filter_properities to compute rpc call.\n\nCurrently the filter_properities is not in compute RPC call.\nThis patch add the value to RPC call so that compute node\ncan know whether it need to reschedule to another host\nif it's needed.\n\nChange-Id: I2b6a39201c3b28da904115b9f7dc0f3e8a43932d\nPartial-Bug: #1400015\n""}, {'number': 4, 'created': '2014-12-17 09:11:51.000000000', 'files': ['nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9f5687735adda2ec37773d9222ee30f80f814232', 'message': ""Add filter_properities to compute rpc call.\n\nCurrently the filter_properities is not in compute RPC call.\nThis patch add the value to RPC call so that compute node\ncan know whether it need to reschedule to another host\nif it's needed.\n\nChange-Id: I2b6a39201c3b28da904115b9f7dc0f3e8a43932d\nCo-Authored-By: Alex Xu <hejie.xu@intel.com>\nPartial-Bug: #1400015\n""}]",2,142000,9f5687735adda2ec37773d9222ee30f80f814232,20,8,4,6062,,,0,"Add filter_properities to compute rpc call.

Currently the filter_properities is not in compute RPC call.
This patch add the value to RPC call so that compute node
can know whether it need to reschedule to another host
if it's needed.

Change-Id: I2b6a39201c3b28da904115b9f7dc0f3e8a43932d
Co-Authored-By: Alex Xu <hejie.xu@intel.com>
Partial-Bug: #1400015
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/142000/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py']",3,34a3461431881104764f2c99b013f30c0cd0e56f,rebuild_retry_when_no_valid_host_5," * 3.38 - Add filter_properties to rebuild_instance preserve_ephemeral=False, kwargs=None, filter_properties=None): extra = {'preserve_ephemeral': preserve_ephemeral, 'filter_properties': filter_properties} version = '3.38'"," preserve_ephemeral=False, kwargs=None): extra = {'preserve_ephemeral': preserve_ephemeral} version = '3.21'",9,5
openstack%2Fnova~master~Ic6429d26bbc20b9b395c82f7cd9456f211d44485,openstack/nova,master,Ic6429d26bbc20b9b395c82f7cd9456f211d44485,Add filter_properties param to rebuild instance.,ABANDONED,2014-12-16 06:55:11.000000000,2014-12-18 01:02:45.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-16 06:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fdd63bc0a374836a845f07db7c2257b6dd42f9e', 'message': 'Add filter_properties param to rebuild instance\n\nWhen enables rescheduling, it need retry info from previous scheduling.\nThis patch adds filter_properties parameter to rebuild_instance RPC API,\nthat enables pass the previous scheduling retry info back.\n\nChange-Id: Ic6429d26bbc20b9b395c82f7cd9456f211d44485\nPartial-Bug: #1400015\n'}, {'number': 2, 'created': '2014-12-17 08:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49ec28b13fb640fcfd71e8c86eec2cd029258e99', 'message': 'Add filter_properties param to rebuild instance.\n\nWhen enables rescheduling, it need retry info from previous scheduling.\nThis patch adds filter_properties parameter to rebuild_instance RPC API,\nthat enables pass the previous scheduling retry info back.\n\nChange-Id: Ic6429d26bbc20b9b395c82f7cd9456f211d44485\nPartial-Bug: #1400015\n'}, {'number': 3, 'created': '2014-12-17 09:11:51.000000000', 'files': ['nova/conductor/rpcapi.py', 'nova/conductor/api.py', 'nova/tests/functional/test_api_samples.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/tests/functional/v3/test_evacuate.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/23909f782afb6c161bda7834c83f9f7c0abd61e6', 'message': 'Add filter_properties param to rebuild instance.\n\nWhen enables rescheduling, it need retry info from previous scheduling.\nThis patch adds filter_properties parameter to rebuild_instance RPC API,\nthat enables pass the previous scheduling retry info back.\n\nChange-Id: Ic6429d26bbc20b9b395c82f7cd9456f211d44485\nCo-Authored-By: Alex Xu <hejie.xu@intel.com>\nPartial-Bug: #1400015\n'}]",1,141999,23909f782afb6c161bda7834c83f9f7c0abd61e6,15,6,3,6062,,,0,"Add filter_properties param to rebuild instance.

When enables rescheduling, it need retry info from previous scheduling.
This patch adds filter_properties parameter to rebuild_instance RPC API,
that enables pass the previous scheduling retry info back.

Change-Id: Ic6429d26bbc20b9b395c82f7cd9456f211d44485
Co-Authored-By: Alex Xu <hejie.xu@intel.com>
Partial-Bug: #1400015
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/141999/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conductor/rpcapi.py', 'nova/conductor/api.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py']",4,4fdd63bc0a374836a845f07db7c2257b6dd42f9e,rebuild_retry_when_no_valid_host_5," target = messaging.Target(namespace='compute_task', version='1.11') preserve_ephemeral=False, host=None, filter_properties=None): if filter_properties is None: filter_properties = {'ignore_hosts': [instance.host]}"," target = messaging.Target(namespace='compute_task', version='1.10') preserve_ephemeral=False, host=None): filter_properties = {'ignore_hosts': [instance.host]}",56,10
openstack%2Fnova~master~Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6,openstack/nova,master,Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6,Imported Translations from Transifex,MERGED,2014-12-05 06:15:58.000000000,2014-12-18 01:02:39.000000000,2014-12-18 01:02:35.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-05 06:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2701e03a4dda431f7a28f64ab8fb972bb73bb954', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 2, 'created': '2014-12-06 06:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/792b903e0f0c89bb520cb0953342bcbb68a93595', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 3, 'created': '2014-12-07 06:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd930e2b4d2ca107a5dbefd6925f7afda9122442', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 4, 'created': '2014-12-08 06:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a32917b7c59b32249136a8e6c5f1325c20518b06', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 5, 'created': '2014-12-09 06:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6dc672590e2dbe461643e4477f0ba4cd653a3156', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 6, 'created': '2014-12-10 06:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/449a69f4e4e3c1ffb04c3a1abc294394db1d2441', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 7, 'created': '2014-12-11 06:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4aaa8c8dc9d1a538b2c97c896b8f56f7d8fb40ea', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 8, 'created': '2014-12-12 06:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3e7b64317365ccab61ebcf9023ab68fd938db81', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 9, 'created': '2014-12-13 06:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0458cacbc0c3b0da412d6c7954f14f59f73a92f6', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 10, 'created': '2014-12-14 06:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62031371c4e682613e22cfcdae4e519d2de19718', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 11, 'created': '2014-12-15 06:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8859895c9f3a15f62b0331da26fca9c9882c4431', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 12, 'created': '2014-12-16 06:06:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ebc869c2db3491aa6f8f52c12c4aee5df115dbf0', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}, {'number': 13, 'created': '2014-12-17 06:16:38.000000000', 'files': ['nova/locale/it/LC_MESSAGES/nova-log-error.po', 'nova/locale/es/LC_MESSAGES/nova-log-info.po', 'nova/locale/fr/LC_MESSAGES/nova-log-error.po', 'nova/locale/nova.pot', 'nova/locale/zh_TW/LC_MESSAGES/nova-log-info.po', 'nova/locale/zh_CN/LC_MESSAGES/nova-log-info.po', 'nova/locale/fr/LC_MESSAGES/nova-log-warning.po', 'nova/locale/nova-log-error.pot', 'nova/locale/es/LC_MESSAGES/nova-log-warning.po', 'nova/locale/es/LC_MESSAGES/nova.po', 'nova/locale/it/LC_MESSAGES/nova-log-info.po', 'nova/locale/en_GB/LC_MESSAGES/nova-log-info.po', 'nova/locale/fr/LC_MESSAGES/nova.po', 'nova/locale/ja/LC_MESSAGES/nova-log-info.po', 'nova/locale/nova-log-warning.pot', 'nova/locale/fr/LC_MESSAGES/nova-log-info.po', 'nova/locale/en_US/LC_MESSAGES/nova.po', 'nova/locale/ko_KR/LC_MESSAGES/nova-log-info.po', 'nova/locale/pt_BR/LC_MESSAGES/nova-log-info.po', 'nova/locale/es/LC_MESSAGES/nova-log-error.po', 'nova/locale/nova-log-info.pot'], 'web_link': 'https://opendev.org/openstack/nova/commit/1e957fa9045c97ef035b2177e36d0ed2a2a61afb', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6\n'}]",0,139530,1e957fa9045c97ef035b2177e36d0ed2a2a61afb,84,8,13,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ie30bed8cad51c384e7539dbe9fc945d5aed3ada6
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/139530/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/locale/es/LC_MESSAGES/nova-log-info.po', 'nova/locale/nova.pot', 'nova/locale/zh_TW/LC_MESSAGES/nova-log-info.po', 'nova/locale/zh_CN/LC_MESSAGES/nova-log-info.po', 'nova/locale/es/LC_MESSAGES/nova.po', 'nova/locale/it/LC_MESSAGES/nova-log-info.po', 'nova/locale/en_GB/LC_MESSAGES/nova-log-info.po', 'nova/locale/fr/LC_MESSAGES/nova.po', 'nova/locale/ja/LC_MESSAGES/nova-log-info.po', 'nova/locale/fr/LC_MESSAGES/nova-log-info.po', 'nova/locale/en_US/LC_MESSAGES/nova.po', 'nova/locale/ko_KR/LC_MESSAGES/nova-log-info.po', 'nova/locale/pt_BR/LC_MESSAGES/nova-log-info.po', 'nova/locale/nova-log-info.pot']",14,2701e03a4dda431f7a28f64ab8fb972bb73bb954,transifex/translations,"""Project-Id-Version: nova 2015.1.dev1223.g0ba66aa\n""""POT-Creation-Date: 2014-12-05 06:15+0000\n""#: nova/api/openstack/wsgi.py:703#: nova/api/openstack/wsgi.py:706#: nova/compute/api.py:1657#: nova/compute/api.py:1667#: nova/compute/api.py:1684#: nova/scheduler/filters/utils.py:65#: nova/virt/hyperv/vmops.py:331 nova/virt/vmwareapi/vmops.py:570#: nova/virt/hyperv/vmops.py:344 nova/virt/libvirt/driver.py:2790#: nova/virt/libvirt/driver.py:2078#: nova/virt/libvirt/driver.py:2121#: nova/virt/libvirt/driver.py:2137#: nova/virt/libvirt/driver.py:2166#: nova/virt/libvirt/driver.py:2333#: nova/virt/libvirt/driver.py:2349#: nova/virt/libvirt/driver.py:2384 msgid """" ""Instance is configured with a file console, but the backing file is not "" ""(yet?) present"" msgstr """" #: nova/virt/libvirt/driver.py:2395 nova/virt/libvirt/driver.py:2422#: nova/virt/libvirt/driver.py:2653#: nova/virt/libvirt/driver.py:2781#: nova/virt/libvirt/driver.py:3771#: nova/virt/libvirt/driver.py:4662#: nova/virt/libvirt/driver.py:4668#: nova/virt/libvirt/driver.py:4969#: nova/virt/libvirt/driver.py:5760#: nova/virt/libvirt/driver.py:6118#: nova/virt/libvirt/driver.py:6131#: nova/virt/libvirt/driver.py:6135#: nova/virt/libvirt/utils.py:525#: nova/virt/vmwareapi/vmops.py:1197 nova/virt/xenapi/vmops.py:1619#: nova/virt/vmwareapi/vmops.py:1201 nova/virt/xenapi/vmops.py:1623","""Project-Id-Version: nova 2015.1.dev1181.g342e5d9\n""""POT-Creation-Date: 2014-12-04 06:15+0000\n""#: nova/api/openstack/wsgi.py:681#: nova/api/openstack/wsgi.py:684#: nova/compute/api.py:1649#: nova/compute/api.py:1659#: nova/compute/api.py:1676#: nova/scheduler/filters/utils.py:50#: nova/virt/hyperv/vmops.py:331 nova/virt/vmwareapi/vmops.py:569#: nova/virt/hyperv/vmops.py:344 nova/virt/libvirt/driver.py:2772#: nova/virt/libvirt/driver.py:2076#: nova/virt/libvirt/driver.py:2119#: nova/virt/libvirt/driver.py:2135#: nova/virt/libvirt/driver.py:2164#: nova/virt/libvirt/driver.py:2322#: nova/virt/libvirt/driver.py:2338#: nova/virt/libvirt/driver.py:2377 nova/virt/libvirt/driver.py:2404#: nova/virt/libvirt/driver.py:2635#: nova/virt/libvirt/driver.py:2763#: nova/virt/libvirt/driver.py:3746#: nova/virt/libvirt/driver.py:4634#: nova/virt/libvirt/driver.py:4640#: nova/virt/libvirt/driver.py:4941#: nova/virt/libvirt/driver.py:5732#: nova/virt/libvirt/driver.py:6086#: nova/virt/libvirt/driver.py:6099#: nova/virt/libvirt/driver.py:6103#: nova/virt/libvirt/utils.py:513#: nova/virt/vmwareapi/vmops.py:1196 nova/virt/xenapi/vmops.py:1619#: nova/virt/vmwareapi/vmops.py:1200 nova/virt/xenapi/vmops.py:1623",719,675
openstack%2Fnova~master~I85024ccebdd7da6c2ed61fd385ca70259b04183d,openstack/nova,master,I85024ccebdd7da6c2ed61fd385ca70259b04183d,Populates retry info when rebuild instance.,ABANDONED,2014-12-16 06:55:11.000000000,2014-12-18 01:02:05.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-16 06:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0f67cce3dd570f79a9dea3a775dca23fc40862de', 'message': 'Populates retry info when rebuild instance\n\nThis patch populates retry info into filter_properties when\nrebuild instance. This is used to support rescheduling for\nrebuild instance actions.\n\nChange-Id: I85024ccebdd7da6c2ed61fd385ca70259b04183d\nPartial-Bug: #1400015\n'}, {'number': 2, 'created': '2014-12-17 08:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4248eb44062a8a0f9e77940dbf9397dab713ff1', 'message': 'Populates retry info when rebuild instance.\n\nThis patch populates retry info into filter_properties when\nrebuild instance. This is used to support rescheduling for\nrebuild instance actions.\n\nChange-Id: I85024ccebdd7da6c2ed61fd385ca70259b04183d\nPartial-Bug: #1400015\n'}, {'number': 3, 'created': '2014-12-17 09:11:51.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2a88404e9060905233236e758e41adc23f278814', 'message': 'Populates retry info when rebuild instance.\n\nThis patch populates retry info into filter_properties when\nrebuild instance. This is used to support rescheduling for\nrebuild instance actions.\n\nChange-Id: I85024ccebdd7da6c2ed61fd385ca70259b04183d\nCo-Authored-By: Alex Xu <hejie.xu@intel.com>\nPartial-Bug: #1400015\n'}]",0,141998,2a88404e9060905233236e758e41adc23f278814,16,6,3,6062,,,0,"Populates retry info when rebuild instance.

This patch populates retry info into filter_properties when
rebuild instance. This is used to support rescheduling for
rebuild instance actions.

Change-Id: I85024ccebdd7da6c2ed61fd385ca70259b04183d
Co-Authored-By: Alex Xu <hejie.xu@intel.com>
Partial-Bug: #1400015
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/141998/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py']",2,0f67cce3dd570f79a9dea3a775dca23fc40862de,rebuild_retry_when_no_valid_host_5," scheduler_utils.populate_retry(filter_properties, instance.uuid)",,6,2
openstack%2Ftempest~master~I0a063e543e320ea625a5411547bce7fa2ad66b7d,openstack/tempest,master,I0a063e543e320ea625a5411547bce7fa2ad66b7d,DHCPv6 network tests,MERGED,2014-08-28 09:07:57.000000000,2014-12-18 00:58:35.000000000,2014-12-18 00:58:34.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 6524}, {'_account_id': 6579}, {'_account_id': 7183}, {'_account_id': 7249}, {'_account_id': 7350}, {'_account_id': 7872}, {'_account_id': 8767}, {'_account_id': 8871}, {'_account_id': 10257}, {'_account_id': 10385}, {'_account_id': 10969}, {'_account_id': 13753}]","[{'number': 1, 'created': '2014-08-28 09:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bbcb03499d804743696a6f8702239e7ba1e2d2c6', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 2, 'created': '2014-08-28 10:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0cf008f57949057fd48be09f540712ac3ab43590', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort:\nhttps://github.com/openstack/qa-specs/blob/master/\nspecs/ipv6-api-testing-parity.rst\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 3, 'created': '2014-08-29 11:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e1784eaf15d1df4ed1fc114862aaf7f79b678350', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort:\nhttps://github.com/openstack/qa-specs/blob/master/\nspecs/ipv6-api-testing-parity.rst\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 4, 'created': '2014-08-29 14:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2bcfeecf04a779e6eac3ad0f785522260e1035c2', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort:\nhttps://github.com/openstack/qa-specs/blob/master/\nspecs/ipv6-api-testing-parity.rst\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 5, 'created': '2014-08-30 20:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1f08cbef6b47693500aad704e3a767dca2055561', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort:\nhttps://github.com/openstack/qa-specs/blob/master/\nspecs/ipv6-api-testing-parity.rst\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 6, 'created': '2014-08-30 23:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e3726eeca08d3295d3a8c81d25a2e3f9fcf7d68', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort:\nhttps://github.com/openstack/qa-specs/blob/master/\nspecs/ipv6-api-testing-parity.rst\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 7, 'created': '2014-08-31 07:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/031cf07e4cecc9bb43d75c5070a5ae6bd5f3d560', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort:\nhttps://github.com/openstack/qa-specs/blob/master/\nspecs/ipv6-api-testing-parity.rst\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 8, 'created': '2014-09-01 11:42:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3bb2d241ee0f71e1ebadf09c9efb4bdcb3711493', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort:\nhttps://github.com/openstack/qa-specs/blob/master/\nspecs/ipv6-api-testing-parity.rst\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 9, 'created': '2014-09-01 15:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ecb1e19fbf65818da491232a703a92851dae1dfa', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort:\nhttps://github.com/openstack/qa-specs/blob/master/\nspecs/ipv6-api-testing-parity.rst\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 10, 'created': '2014-09-01 22:05:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/088ab89588310a83b3f1ae3dd173a6a868dbeb6f', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort:\nhttps://github.com/openstack/qa-specs/blob/master/\nspecs/ipv6-api-testing-parity.rst\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 11, 'created': '2014-09-18 12:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/df158eeaba0801b24fbb437d3504958e759ec3f8', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 12, 'created': '2014-09-18 12:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6a2098485b25557303dc740f2431d9e089d97590', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 13, 'created': '2014-09-18 14:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2cf0010de9473fe32bcfb9306e4291b87f0f33e6', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 14, 'created': '2014-09-22 13:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2b0f7b66a9d32789687f7636ab6cbea08917d0c3', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 15, 'created': '2014-09-23 09:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ec4951c70062697f7d021e9064fe50dc07b77c2e', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 16, 'created': '2014-09-23 12:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/659226a22e5040631c79ff7d3bcbcd6116edbba0', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nBP for IPv6 test effort: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 17, 'created': '2014-09-23 12:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ce2180e6ed529fc9fc9791c6f820fd859e87fd60', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nImplements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 18, 'created': '2014-10-08 22:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9a54246b1843658b88ad189428003f485d98c22e', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nImplements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 19, 'created': '2014-10-09 00:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6e5d005007f484052a018c7699f9e6a548c2ba08', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, DAD, stateless, etc. RFC: 3315, etc.\nImplements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 20, 'created': '2014-11-11 21:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/75e40560110f692ce61920c2ab1c679de585bf23', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, stateless, etc. RFC: 3315, etc.\nPartially implements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 21, 'created': '2014-11-11 22:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/81b5310eb36e2cb9357e8fff5087a8dc3193e312', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, stateless, etc. RFC: 3315, etc.\nPartially implements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 22, 'created': '2014-11-12 06:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/912e09681789385fd3d337574c4a4153774e135c', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, stateless, etc. RFC: 3315, etc.\nPartially implements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 23, 'created': '2014-11-12 09:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d0b3ecb7a1f70b02da860a44f10435d90a38de67', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, stateless, etc. RFC: 3315, etc.\nPartially implements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 24, 'created': '2014-11-12 22:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4503836381f42d6f71c3a74c4c25749028051544', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, stateless, etc. RFC: 3315, etc.\nPartially implements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 25, 'created': '2014-11-14 15:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/09ae040ee300eb45b0617498e4d84b7489d3f83f', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, stateless, etc. RFC: 3315, etc.\nPartially implements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 26, 'created': '2014-11-20 20:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/66920c242c8efc8b898461e4d1ab3e82d84f2088', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, stateless, etc. RFC: 3315, etc.\nPartially implements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 27, 'created': '2014-11-20 22:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3313cbf43938dd20e99b84288bfb607a0db4acbd', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, stateless, etc. RFC: 3315, etc.\nPartially implements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}, {'number': 28, 'created': '2014-11-24 13:09:19.000000000', 'files': ['tempest/common/utils/data_utils.py', 'tempest/api/network/test_dhcp_ipv6.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f0ce225d7b17579d8c90050897196d9f706e68b0', 'message': ""DHCPv6 network tests\n\nWith upcoming IPv6 support we need to test specific\nDHCPv6 features that don't exist on IPv4, like\nSLAAC, stateless, etc. RFC: 3315, etc.\nPartially implements: blueprint ipv6-api-testing-parity\n\nChange-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d\n""}]",77,117458,f0ce225d7b17579d8c90050897196d9f706e68b0,162,18,28,10969,,,0,"DHCPv6 network tests

With upcoming IPv6 support we need to test specific
DHCPv6 features that don't exist on IPv4, like
SLAAC, stateless, etc. RFC: 3315, etc.
Partially implements: blueprint ipv6-api-testing-parity

Change-Id: I0a063e543e320ea625a5411547bce7fa2ad66b7d
",git fetch https://review.opendev.org/openstack/tempest refs/changes/58/117458/6 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/utils/data_utils.py', 'tempest/api/network/test_dhcp_ipv6.py']",2,bbcb03499d804743696a6f8702239e7ba1e2d2c6,bp/ipv6-api-testing-parity,"import random import netaddr from tempest.api.network import base from tempest import test from tempest.common.utils.data_utils import get_ipv6_addr_by_EUI64, \ rand_mac_address from tempest import exceptions class NetworksTestDHCPv6JSON(base.BaseNetworkTest): _interface = 'json' _ip_version = 6 @classmethod @test.safe_setup def setUpClass(cls): super(NetworksTestDHCPv6JSON, cls).setUpClass() cls.network = cls.create_network() def _clean_network(self, **kwargs): if ""ports"" in kwargs: for port in kwargs[""ports""]: self.client.delete_port(port['id']) if ""router_interfaces"" in kwargs: for interface in kwargs[""router_interfaces""]: self.client.remove_router_interface_with_subnet_id(*interface) if ""subnets"" in kwargs: for subnet in kwargs[""subnets""]: self.client.delete_subnet(subnet['id']) if ""routers"" in kwargs: for router in kwargs[""routers""]: self.client.delete_router(router['id']) @test.attr(type='smoke') def test_dhcpv6_stateless_eui64(self): """"""When subnets configured with RAs SLAAC (AOM=100) and DHCP stateless (AOM=110) both for radvd and dnsmasq, port shall receive IP address calculated from its MAC. """""" for ra_mode, add_mode in ( ('slaac', 'slaac'), ('dhcpv6-stateless', 'dhcpv6-stateless'), ): kwargs = {'ipv6_ra_mode': ra_mode, 'ipv6_address_mode': add_mode} subnet = self.create_subnet(self.network, **kwargs) self.subnets.pop() port_mac = rand_mac_address() port = self.create_port(self.network, mac_address=port_mac) self.ports.pop() real_ip = next(iter(port['fixed_ips']))['ip_address'] eui_ip = get_ipv6_addr_by_EUI64(subnet['cidr'], port_mac).format() self._clean_network(ports=[port], subnets=[subnet]) self.assertEqual(eui_ip, real_ip, ('Real port IP is %s, but shall be %s when ' 'ipv6_ra_mode=%s and ipv6_address_mode=%s') % ( real_ip, eui_ip, ra_mode, add_mode)) @test.attr(type='smoke') def test_dhcpv6_stateless_only_ra(self): """"""When subnets configured with RAs SLAAC (AOM=100) and DHCP stateless (AOM=110) for radvd and dnsmasq is not configured, port shall receive IP address calculated from its MAC and mask advertised from RAs """""" for ra_mode, add_mode in ( ('slaac', None), ('dhcpv6-stateless', None), ): kwargs = {'ipv6_ra_mode': ra_mode, 'ipv6_address_mode': add_mode} kwargs = {k: v for k, v in kwargs.iteritems() if v} subnet = self.create_subnet(self.network, **kwargs) self.subnets.pop() router = self.create_router(router_name=""router1"", admin_state_up=True) self.create_router_interface(router['id'], subnet['id']) self.routers.pop() port_mac = rand_mac_address() port = self.create_port(self.network, mac_address=port_mac) self.ports.pop() real_ip = next(iter(port['fixed_ips']))['ip_address'] eui_ip = get_ipv6_addr_by_EUI64(subnet['cidr'], port_mac).format() self._clean_network(ports=[port], subnets=[subnet], router_interfaces=[(router['id'], subnet['id'])], routers=[router]) self.assertEqual(eui_ip, real_ip, ('Real port IP is %s, but shall be %s when ' 'ipv6_ra_mode=%s and ipv6_address_mode=%s') % ( real_ip, eui_ip, ra_mode if ra_mode else ""Off"", add_mode if add_mode else ""Off"")) @test.attr(type='smoke') def test_dhcpv6_stateless_no_ra(self): """"""When subnets configured with dnsmasq SLAAC and DHCP stateless and there is no radvd, port shall receive IP address calculated from its MAC and mask of subnet. """""" for ra_mode, add_mode in ( (None, 'slaac'), (None, 'dhcpv6-stateless'), ): kwargs = {'ipv6_ra_mode': ra_mode, 'ipv6_address_mode': add_mode} kwargs = {k: v for k, v in kwargs.iteritems() if v} subnet = self.create_subnet(self.network, **kwargs) self.subnets.pop() port_mac = rand_mac_address() port = self.create_port(self.network, mac_address=port_mac) self.ports.pop() real_ip = next(iter(port['fixed_ips']))['ip_address'] eui_ip = get_ipv6_addr_by_EUI64(subnet['cidr'], port_mac).format() self._clean_network(ports=[port], subnets=[subnet]) self.assertEqual(eui_ip, real_ip, ('Real port IP %s equal to EUI-64 %s when ' 'ipv6_ra_mode=%s and ipv6_address_mode=%s') % ( real_ip, eui_ip, ra_mode if ra_mode else ""Off"", add_mode if add_mode else ""Off"")) @test.attr(type='smoke') def test_dhcpv6_invalid_options(self): """"""Different configurations for radvd and dnsmasq are not allowed"""""" for ra_mode, add_mode in ( ('dhcpv6-stateless', 'dhcpv6-stateful'), ('dhcpv6-stateless', 'slaac'), ('slaac', 'dhcpv6-stateful'), ('dhcpv6-stateful', 'dhcpv6-stateless'), ('dhcpv6-stateful', 'slaac'), ('slaac', 'dhcpv6-stateless'), ): kwargs = {'ipv6_ra_mode': ra_mode, 'ipv6_address_mode': add_mode} self.assertRaises(exceptions.BadRequest, self.create_subnet, self.network, **kwargs) @test.attr(type='smoke') def test_dhcpv6_stateless_no_ra_no_dhcp(self): """"""If no radvd option and no dnsmasq option is configured port shall receive IP from fixed IPs list of subnet. """""" subnet = self.create_subnet(self.network) self.subnets.pop() port_mac = rand_mac_address() port = self.create_port(self.network, mac_address=port_mac) self.ports.pop() real_ip = next(iter(port['fixed_ips']))['ip_address'] eui_ip = get_ipv6_addr_by_EUI64(subnet['cidr'], port_mac).format() self._clean_network(ports=[port], subnets=[subnet]) self.assertNotEqual(eui_ip, real_ip, ('Real port IP %s equal to EUI-64 %s when ' 'ipv6_ra_mode=Off and ipv6_address_mode=Off') % ( real_ip, eui_ip)) @test.attr(type='smoke') def test_dhcpv6_stateless_two_subnets(self): """"""When 2 subnets configured with dnsmasq SLAAC and DHCP stateless and there is radvd, port shall receive IP addresses calculated from its MAC and mask of subnet from both subnets. """""" for ra_mode, add_mode in ( ('slaac', 'slaac'), ('dhcpv6-stateless', 'dhcpv6-stateless'), ): kwargs = {'ipv6_ra_mode': ra_mode, 'ipv6_address_mode': add_mode} subnet1 = self.create_subnet(self.network, **kwargs) self.subnets.pop() subnet2 = self.create_subnet(self.network, **kwargs) self.subnets.pop() port_mac = rand_mac_address() port = self.create_port(self.network, mac_address=port_mac) self.ports.pop() real_ips = [i['ip_address'] for i in port['fixed_ips']] eui_ips = [ get_ipv6_addr_by_EUI64(i['cidr'], port_mac).format() for i in (subnet1, subnet2) ] self._clean_network(ports=[port], subnets=[subnet1, subnet2]) self.assertSequenceEqual(sorted(real_ips), sorted(eui_ips), ('Real port IPs %s and %s are not equal to' ' SLAAC IPs %s %s') % tuple(real_ips + eui_ips)) @test.attr(type='smoke') def test_dhcpv6_two_subnets(self): """"""When one subnet configured with dnsmasq SLAAC or DHCP stateless and other is with DHCP stateful, port shall receive EUI-64 IP addresses from first subnet and DHCP address from second one. Order of subnet creating should be unimportant. """""" for order in (""slaac_first"", ""dhcp_first""): for ra_mode, add_mode in ( ('slaac', 'slaac'), ('dhcpv6-stateless', 'dhcpv6-stateless'), ): kwargs = {'ipv6_ra_mode': ra_mode, 'ipv6_address_mode': add_mode} kwargs_dhcp = {'ipv6_address_mode': 'dhcpv6-stateful'} if order == ""slaac_first"": subnet_slaac = self.create_subnet(self.network, **kwargs) subnet_dhcp = self.create_subnet(self.network, **kwargs_dhcp) else: subnet_dhcp = self.create_subnet(self.network, **kwargs_dhcp) subnet_slaac = self.create_subnet(self.network, **kwargs) port_mac = rand_mac_address() port = self.create_port(self.network, mac_address=port_mac) real_ips = dict([(k['subnet_id'], k['ip_address']) for k in port['fixed_ips']]) real_dhcp_ip, real_eui_ip = [real_ips[sub['id']] for sub in subnet_dhcp, subnet_slaac] dhcp_ip = subnet_dhcp[""allocation_pools""][0][""start""] eui_ip = get_ipv6_addr_by_EUI64( subnet_slaac['cidr'], port_mac ).format() self.subnets.pop() self.subnets.pop() self.ports.pop() self._clean_network(ports=[port], subnets=[subnet_slaac, subnet_dhcp]) self.assertSequenceEqual((real_eui_ip, real_dhcp_ip), (eui_ip, dhcp_ip), ('Real port IPs %s and %s are not equal' ' to planned IPs %s %s') % ( real_dhcp_ip, real_eui_ip, eui_ip, dhcp_ip)) @test.attr(type='smoke') def test_slaac_duplicate(self): """"""When creating SLAAC address, neutron shall check that there are not any duplicates of this address in the network. """""" kwargs = {'ipv6_ra_mode': 'slaac', 'ipv6_address_mode': 'slaac'} subnet = self.create_subnet(self.network, **kwargs) port_mac = rand_mac_address() eui_ip = get_ipv6_addr_by_EUI64(subnet['cidr'], port_mac).format() port = self.create_port(self.network, fixed_ips=[ {'subnet_id': subnet['id'], 'ip_address': eui_ip}]) port_ip = next(iter(port['fixed_ips']))['ip_address'] self.assertEqual(port_ip, eui_ip, ""IP is not EUI-64: %s"" % port_ip) self.assertRaisesRegexp( exceptions.Conflict, ""An object with that identifier already exists"", self.create_port, self.network, mac_address=port_mac) @test.attr(type='smoke') def test_dhcp_stateful(self): """"""When all options below, DHCPv6 shall allocate first address from subnet pool to port.. """""" for ra_mode, add_mode in ( ('dhcpv6-stateful', 'dhcpv6-stateful'), ('dhcpv6-stateful', None), (None, 'dhcpv6-stateful'), ): kwargs = {'ipv6_ra_mode': ra_mode, 'ipv6_address_mode': add_mode} kwargs = {k: v for k, v in kwargs.iteritems() if v} subnet = self.create_subnet(self.network, **kwargs) self.subnets.pop() port = self.create_port(self.network,) self.ports.pop() port_ip = next(iter(port['fixed_ips']))['ip_address'] first_alloc = subnet[""allocation_pools""][0][""start""] self._clean_network(ports=[port], subnets=[subnet]) self.assertEqual(port_ip, first_alloc, (""Port IP %s is not as first IP from "" ""subnets allocation pool: %s"") % ( port_ip, first_alloc)) @test.attr(type='smoke') def test_dhcp_stateful_fixedips(self): """"""When all options below, port shall be able to get requested IP from fixed IP range not depending on DHCP settings configured.. """""" for ra_mode, add_mode in ( ('dhcpv6-stateful', 'dhcpv6-stateful'), ('dhcpv6-stateful', None), (None, 'dhcpv6-stateful'), ('slaac', 'slaac'), ('dhcpv6-stateless', 'dhcpv6-stateless'), (None, 'slaac'), (None, 'dhcpv6-stateless'), ('slaac', None), ('dhcpv6-stateless', None), ): kwargs = {'ipv6_ra_mode': ra_mode, 'ipv6_address_mode': add_mode} kwargs = {k: v for k, v in kwargs.iteritems() if v} subnet = self.create_subnet(self.network, **kwargs) self.subnets.pop() ip_range = netaddr.IPRange(subnet[""allocation_pools""][0][""start""], subnet[""allocation_pools""][0][""end""]) ip = netaddr.IPAddress(random.randrange(ip_range.first, ip_range.last)).format() port = self.create_port(self.network, fixed_ips=[ {'subnet_id': subnet['id'], 'ip_address': ip}]) self.ports.pop() port_ip = next(iter(port['fixed_ips']))['ip_address'] self._clean_network(ports=[port], subnets=[subnet]) self.assertEqual(port_ip, ip, (""Port IP %s is not as fixed IP from "" ""port create request: %s"") % ( port_ip, ip)) @test.attr(type='smoke') def test_dhcp_stateful_fixedips_outrange(self): """"""When port gets IP address from fixed IP range it shall be checked if it's from subnets range. """""" kwargs = {'ipv6_ra_mode': 'dhcpv6-stateful', 'ipv6_address_mode': 'dhcpv6-stateful'} subnet = self.create_subnet(self.network, **kwargs) ip_range = netaddr.IPRange(subnet[""allocation_pools""][0][""start""], subnet[""allocation_pools""][0][""end""]) ip = netaddr.IPAddress(random.randrange( ip_range.last+1, ip_range.last+10)).format() self.assertRaisesRegexp(exceptions.BadRequest, ""not a valid IP for the defined subnet"", self.create_port, self.network, fixed_ips=[{'subnet_id': subnet['id'], 'ip_address': ip}]) @test.attr(type='smoke') def test_dhcp_stateful_fixedips_duplicate(self): """"""When port gets IP address from fixed IP range it shall be checked if it's not duplicate. """""" kwargs = {'ipv6_ra_mode': 'dhcpv6-stateful', 'ipv6_address_mode': 'dhcpv6-stateful'} subnet = self.create_subnet(self.network, **kwargs) ip_range = netaddr.IPRange(subnet[""allocation_pools""][0][""start""], subnet[""allocation_pools""][0][""end""]) ip = netaddr.IPAddress(random.randrange( ip_range.first, ip_range.last)).format() self.create_port(self.network, fixed_ips=[ {'subnet_id': subnet['id'], 'ip_address': ip}]) self.assertRaisesRegexp(exceptions.Conflict, ""object with that identifier already exists"", self.create_port, self.network, fixed_ips=[{'subnet_id': subnet['id'], 'ip_address': ip}]) class NetworksTestDHCPv6XML(NetworksTestDHCPv6JSON): _interface = 'xml' ",,387,0
openstack%2Fswift~master~If9ff345b2c7c6d88f527cae643168bc725b26f8d,openstack/swift,master,If9ff345b2c7c6d88f527cae643168bc725b26f8d,Remove unneeded condition,MERGED,2014-12-15 15:11:58.000000000,2014-12-18 00:58:07.000000000,2014-12-18 00:58:05.000000000,"[{'_account_id': 3}, {'_account_id': 5619}, {'_account_id': 6968}, {'_account_id': 7847}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-15 15:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/15077a00e3794729c59fc1b537691a16fe1cd480', 'message': ""Remove unneeded condition\n\nThe CName loopkup middleware checked a hostname against the configured\ndomains. This check is likely a remnant from when cname lookup only\nsupported a single hostname. Now, however, the configured domain is\nactually a list of domains, so checking a single hostname will never\nmatch. The check isn't really needed anyway, as it's been broken since\nswift 1.10.\n\nChange-Id: If9ff345b2c7c6d88f527cae643168bc725b26f8d\nFixes: #1402704\n""}, {'number': 2, 'created': '2014-12-15 15:14:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b0c15f39781f92e593f5268974ce6acda208655e', 'message': ""Remove unneeded condition\n\nThe CName loopkup middleware checked a hostname against the configured\ndomains. This check is likely a remnant from when cname lookup only\nsupported a single hostname. Now, however, the configured domain is\nactually a list of domains, so checking a single hostname will never\nmatch. The check isn't really needed anyway, as it's been broken since\nswift 1.10.\n\nCloses-Bug: #1402704\nChange-Id: If9ff345b2c7c6d88f527cae643168bc725b26f8d\n""}, {'number': 3, 'created': '2014-12-16 13:26:10.000000000', 'files': ['swift/common/middleware/cname_lookup.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/bfbf0d1e78ff47937adb06bce648a0b915c838d1', 'message': ""Remove unneeded condition\n\nThe CName loopkup middleware checked a hostname against the configured\ndomains. This check is likely a remnant from when cname lookup only\nsupported a single hostname. Now, however, the configured domain is\nactually a list of domains, so checking a single hostname will never\nmatch. The check isn't really needed anyway, as it has been broken since\nswift 1.10.\n\nCloses-Bug: #1402704\nChange-Id: If9ff345b2c7c6d88f527cae643168bc725b26f8d\n""}]",0,141818,bfbf0d1e78ff47937adb06bce648a0b915c838d1,17,5,3,5619,,,0,"Remove unneeded condition

The CName loopkup middleware checked a hostname against the configured
domains. This check is likely a remnant from when cname lookup only
supported a single hostname. Now, however, the configured domain is
actually a list of domains, so checking a single hostname will never
match. The check isn't really needed anyway, as it has been broken since
swift 1.10.

Closes-Bug: #1402704
Change-Id: If9ff345b2c7c6d88f527cae643168bc725b26f8d
",git fetch https://review.opendev.org/openstack/swift refs/changes/18/141818/3 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/middleware/cname_lookup.py'],1,15077a00e3794729c59fc1b537691a16fe1cd480,bug/1402704,," if given_domain == self.storage_domain[1:]: # strip initial '.' return self.app(env, start_response)",0,2
openstack%2Frequirements~master~Ifc618a63ee0df6ac5c1b3a2b2f4176ebb9a1e080,openstack/requirements,master,Ifc618a63ee0df6ac5c1b3a2b2f4176ebb9a1e080,Set alembic>=0.7.1,MERGED,2014-12-09 09:04:05.000000000,2014-12-18 00:57:55.000000000,2014-12-18 00:57:54.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 6524}, {'_account_id': 6786}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 7680}, {'_account_id': 11816}]","[{'number': 1, 'created': '2014-12-09 09:04:05.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/099e60cdf8d5f661946989baadac812abc0ebc9e', 'message': 'Set alembic>=0.7.1\n\nAlembic 0.7.1 contains some new functions like autogeneration of\nforeign keys that are important and can reduce some code in neutron\nand oslo.db\n\nChange-Id: Ifc618a63ee0df6ac5c1b3a2b2f4176ebb9a1e080\nRelated-bug: #1398417\n'}]",0,140275,099e60cdf8d5f661946989baadac812abc0ebc9e,12,9,1,7249,,,0,"Set alembic>=0.7.1

Alembic 0.7.1 contains some new functions like autogeneration of
foreign keys that are important and can reduce some code in neutron
and oslo.db

Change-Id: Ifc618a63ee0df6ac5c1b3a2b2f4176ebb9a1e080
Related-bug: #1398417
",git fetch https://review.opendev.org/openstack/requirements refs/changes/75/140275/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,099e60cdf8d5f661946989baadac812abc0ebc9e,,alembic>=0.7.1,alembic>=0.6.4,1,1
openstack%2Fnova~master~Id75def84bd4bdc1c1fb06221b4223322a99251eb,openstack/nova,master,Id75def84bd4bdc1c1fb06221b4223322a99251eb,Reject non existent mock assert calls,MERGED,2014-12-12 13:50:41.000000000,2014-12-18 00:57:37.000000000,2014-12-18 00:57:33.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 679}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9545}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-12 13:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9bf578d9f040a7c217034a6f5b1f79c23f4f804', 'message': ""Reject non existent mock assert calls\n\nassert_called and assert_not_called are not asserting the state\nof the mock object but considered as mocked calls so mock\nwill never raise exception but always executed successfully\n\nThis change patches the Mock class during unit test\nto raise an exception if a function called on a mock object\nthat's name starts with 'assert' and does not one\nof the supported Mock assert calls.\n\nThis change also fix the unit test to call only the supported\nassert function on mock object.\n\nChange-Id: Id75def84bd4bdc1c1fb06221b4223322a99251eb\n""}, {'number': 2, 'created': '2014-12-16 10:42:07.000000000', 'files': ['nova/hacking/checks.py', 'nova/test.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/test_hacking.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e0d22ba4dea6d7b70faba14c6918fbc2151983a5', 'message': ""Reject non existent mock assert calls\n\nassert_called and assert_not_called are not asserting the state\nof the mock object but considered as mocked calls so mock\nwill never raise exception but always executed successfully\n\nThis change patches the Mock class during unit test\nto raise an exception if a function called on a mock object\nthat's name starts with 'assert' and does not one\nof the supported Mock assert calls.\n\nThis change also fix the unit test to call only the supported\nassert function on mock object.\n\nThis change also removes hacking rule N327 as the mock change\nrenders this hacking rule obsolete.\n\nChange-Id: Id75def84bd4bdc1c1fb06221b4223322a99251eb\n""}]",0,141371,e0d22ba4dea6d7b70faba14c6918fbc2151983a5,29,13,2,9708,,,0,"Reject non existent mock assert calls

assert_called and assert_not_called are not asserting the state
of the mock object but considered as mocked calls so mock
will never raise exception but always executed successfully

This change patches the Mock class during unit test
to raise an exception if a function called on a mock object
that's name starts with 'assert' and does not one
of the supported Mock assert calls.

This change also fix the unit test to call only the supported
assert function on mock object.

This change also removes hacking rule N327 as the mock change
renders this hacking rule obsolete.

Change-Id: Id75def84bd4bdc1c1fb06221b4223322a99251eb
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/141371/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/test.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",3,f9bf578d9f040a7c217034a6f5b1f79c23f4f804,mock_assert_called," self.assertTrue(mock_info.called) def test_create_domain(self, mock_safe_decode): mock_domain.createWithFlags.assert_has_calls([mock.call(0)]) self.assertFalse(mock_instance.called) self.assertFalse(mock_instance.called) self.assertFalse(mock_instance.called)"," mock_info.assert_called() @mock.patch.object(fake_libvirt_utils, 'get_instance_path') def test_create_domain(self, mock_safe_decode, mock_get_inst_path): mock_get_inst_path.return_value = '/tmp/' mock_get_inst_path.assertHasCalls([mock.call(mock_instance)]) mock_domain.createWithFlags.assertHasCalls([mock.call(0)]) mock_instance.save.assert_not_called() mock_instance.save.assert_not_called() mock_instance.save.assert_not_called()",31,10
openstack%2Fdevstack~master~I11fb3728e08adc1e0f7acca63e5a308d24dce78e,openstack/devstack,master,I11fb3728e08adc1e0f7acca63e5a308d24dce78e,Fix rabbitmq retry for error checking,MERGED,2014-12-15 23:14:09.000000000,2014-12-18 00:57:09.000000000,2014-12-18 00:57:08.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 8074}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-15 23:14:09.000000000', 'files': ['lib/rpc_backend'], 'web_link': 'https://opendev.org/openstack/devstack/commit/64b56a53d8f5136c6902ce0fa948317f171a664d', 'message': 'Fix rabbitmq retry for error checking\n\nI think this retry check has been broken since we introduced ""set -e"".\nUnfortunately it seems the issue of rabbitmq not starting first-time\npersists on centos 7 hosts occasionally, e.g. [1]:\n\n---\n + rabbit_setuser stackrabbit secretrabbit\n + local user=stackrabbit pass=secretrabbit found= out=\n ++ sudo rabbitmqctl list_users\n Error: unable to connect to node \'rabbit@devstack-centos7-rax-iad-100675\': nodedown\n\n DIAGNOSTICS\n ===========\n\n nodes in question: [\'rabbit@devstack-centos7-rax-iad-100675\']\n\n hosts, their running nodes and ports:\n - devstack-centos7-rax-iad-100675: [{rabbitmqctl29293,39511}]\n\n current node details:\n - node name: \'rabbitmqctl29293@devstack-centos7-rax-iad-100675\'\n - home dir: /var/lib/rabbitmq\n - cookie hash: KieJnx1pnllKbHVihGcDqA==\n---\n\nFix up this retry while we investigate [2]\n\n[1] http://logs.openstack.org/64/141864/1/check//check-tempest-dsvm-centos7/4308f0c/logs/devstacklog.txt.gz\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1144100\n\nChange-Id: I11fb3728e08adc1e0f7acca63e5a308d24dce78e\n'}]",0,141933,64b56a53d8f5136c6902ce0fa948317f171a664d,13,6,1,7118,,,0,"Fix rabbitmq retry for error checking

I think this retry check has been broken since we introduced ""set -e"".
Unfortunately it seems the issue of rabbitmq not starting first-time
persists on centos 7 hosts occasionally, e.g. [1]:

---
 + rabbit_setuser stackrabbit secretrabbit
 + local user=stackrabbit pass=secretrabbit found= out=
 ++ sudo rabbitmqctl list_users
 Error: unable to connect to node 'rabbit@devstack-centos7-rax-iad-100675': nodedown

 DIAGNOSTICS
 ===========

 nodes in question: ['rabbit@devstack-centos7-rax-iad-100675']

 hosts, their running nodes and ports:
 - devstack-centos7-rax-iad-100675: [{rabbitmqctl29293,39511}]

 current node details:
 - node name: 'rabbitmqctl29293@devstack-centos7-rax-iad-100675'
 - home dir: /var/lib/rabbitmq
 - cookie hash: KieJnx1pnllKbHVihGcDqA==
---

Fix up this retry while we investigate [2]

[1] http://logs.openstack.org/64/141864/1/check//check-tempest-dsvm-centos7/4308f0c/logs/devstacklog.txt.gz
[2] https://bugzilla.redhat.com/show_bug.cgi?id=1144100

Change-Id: I11fb3728e08adc1e0f7acca63e5a308d24dce78e
",git fetch https://review.opendev.org/openstack/devstack refs/changes/33/141933/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/rpc_backend'],1,64b56a53d8f5136c6902ce0fa948317f171a664d,rabbit-return-code," # Reference: https://bugzilla.redhat.com/show_bug.cgi?id=1144100 local rc=0 [[ $i -eq ""10"" ]] && die $LINENO ""Failed to set rabbitmq password"" rabbit_setuser ""$RABBIT_USERID"" ""$RABBIT_PASSWORD"" || rc=$? if [ $rc -ne 0 ]; then continue fi sudo rabbitmqctl change_password \ $RABBIT_USERID $RABBIT_PASSWORD || rc=$? if [ $rc -ne 0 ]; then continue; fi break"," # Reference: https://bugzilla.redhat.com/show_bug.cgi?id=1059028 rabbit_setuser ""$RABBIT_USERID"" ""$RABBIT_PASSWORD"" sudo rabbitmqctl change_password $RABBIT_USERID $RABBIT_PASSWORD && break [[ $i -eq ""10"" ]] && die $LINENO ""Failed to set rabbitmq password""",18,4
openstack%2Fnova~master~I3f8d49d25b99dd0a498dfaad705c6332908cb72f,openstack/nova,master,I3f8d49d25b99dd0a498dfaad705c6332908cb72f,objects: remove dict compat support from all XXXList() objects,MERGED,2014-12-12 11:05:43.000000000,2014-12-18 00:55:42.000000000,2014-12-18 00:55:39.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-12 11:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c42931d5452dfacddf95c33ae98712e1ef78aed', 'message': ""objects: remove dict compat support from all XXXList() objects\n\nThe XXXList() classes only ever have a single 'objects' attribute\nand this is never directly accessed as a dict key, instead all\ncallers use it in list context. Thus the dict compat support can\nbe removed from all these objects\n\nChange-Id: I3f8d49d25b99dd0a498dfaad705c6332908cb72f\n""}, {'number': 2, 'created': '2014-12-12 14:09:47.000000000', 'files': ['nova/objects/tag.py', 'nova/objects/dns_domain.py', 'nova/objects/service.py', 'nova/objects/bandwidth_usage.py', 'nova/objects/instance_fault.py', 'nova/objects/block_device.py', 'nova/objects/security_group_rule.py', 'nova/objects/agent.py', 'nova/objects/keypair.py', 'nova/objects/instance_action.py', 'nova/objects/pci_device.py', 'nova/objects/floating_ip.py', 'nova/objects/compute_node.py', 'nova/objects/network.py', 'nova/objects/instance_group.py', 'nova/objects/network_request.py', 'nova/objects/flavor.py', 'nova/objects/instance.py', 'nova/objects/aggregate.py', 'nova/objects/fixed_ip.py', 'nova/objects/security_group.py', 'nova/objects/migration.py', 'nova/objects/virtual_interface.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e3b63f3b71eac944fd6c19e0b7efef428abe1472', 'message': ""objects: remove dict compat support from all XXXList() objects\n\nThe XXXList() classes only ever have a single 'objects' attribute\nand this is never directly accessed as a dict key, instead all\ncallers use it in list context. Thus the dict compat support can\nbe removed from all these objects\n\nChange-Id: I3f8d49d25b99dd0a498dfaad705c6332908cb72f\n""}]",0,141329,e3b63f3b71eac944fd6c19e0b7efef428abe1472,28,12,2,1779,,,0,"objects: remove dict compat support from all XXXList() objects

The XXXList() classes only ever have a single 'objects' attribute
and this is never directly accessed as a dict key, instead all
callers use it in list context. Thus the dict compat support can
be removed from all these objects

Change-Id: I3f8d49d25b99dd0a498dfaad705c6332908cb72f
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/141329/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/tag.py', 'nova/objects/dns_domain.py', 'nova/objects/service.py', 'nova/objects/bandwidth_usage.py', 'nova/objects/instance_fault.py', 'nova/objects/block_device.py', 'nova/objects/security_group_rule.py', 'nova/objects/agent.py', 'nova/objects/keypair.py', 'nova/objects/instance_action.py', 'nova/objects/pci_device.py', 'nova/objects/floating_ip.py', 'nova/objects/compute_node.py', 'nova/objects/network.py', 'nova/objects/instance_group.py', 'nova/objects/network_request.py', 'nova/objects/flavor.py', 'nova/objects/instance.py', 'nova/objects/aggregate.py', 'nova/objects/fixed_ip.py', 'nova/objects/security_group.py', 'nova/objects/migration.py', 'nova/objects/virtual_interface.py']",23,6c42931d5452dfacddf95c33ae98712e1ef78aed,,"class VirtualInterfaceList(base.ObjectListBase, base.NovaObject):","# TODO(berrange): Remove NovaObjectDictCompat class VirtualInterfaceList(base.ObjectListBase, base.NovaObject, base.NovaObjectDictCompat):",24,72
openstack%2Fnova~master~I7431b5d8e889eebacfef9179c9dceab54ac286ca,openstack/nova,master,I7431b5d8e889eebacfef9179c9dceab54ac286ca,objects: stop conductor manager using dict field access on objects,MERGED,2014-12-12 14:09:46.000000000,2014-12-18 00:55:19.000000000,2014-12-18 00:55:16.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-12 14:09:46.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ef264b11af1400bdf913ad1ff0c0807a7caebc5d', 'message': ""objects: stop conductor manager using dict field access on objects\n\nThe conductor manager 'object_action' method was accessing object\nfields using dict syntax instead of attribute syntax. This meant\nthat every single object would always have to support dict compat\nmode.\n\nChange-Id: I7431b5d8e889eebacfef9179c9dceab54ac286ca\n""}]",0,141376,ef264b11af1400bdf913ad1ff0c0807a7caebc5d,19,11,1,1779,,,0,"objects: stop conductor manager using dict field access on objects

The conductor manager 'object_action' method was accessing object
fields using dict syntax instead of attribute syntax. This meant
that every single object would always have to support dict compat
mode.

Change-Id: I7431b5d8e889eebacfef9179c9dceab54ac286ca
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/141376/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py']",2,ef264b11af1400bdf913ad1ff0c0807a7caebc5d,," getattr(oldobj, name) != getattr(objinst, name)): getattr(objinst, name))", oldobj[name] != objinst[name]): objinst[name]),3,4
openstack%2Fnova~master~I03f93f0c40df6f5f7df9cefe28dff900c22294c9,openstack/nova,master,I03f93f0c40df6f5f7df9cefe28dff900c22294c9,objects: allow creation of objects without dict item compat,MERGED,2014-12-11 18:58:25.000000000,2014-12-18 00:52:40.000000000,2014-12-18 00:52:37.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-11 18:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0f59fee75e3dae341b39b90f242a5333bf066ca0', 'message': ""objects: allow creation of objects without dict item compat\n\nThe dict compat support in NovaObject is useful for incrementally\nconverting existing code over to use objects. Any brand new objects\nthough have no reason to support dictionary access, so there should\nbe a way to disable this compat mode.\n\nThis adds a class level property 'dict_item_access' which is set to\nFalse by default. Objects which require legacy dict based access\ncan temporarily set it to True, until all code has been converted\nto attribute access style. This sets all existing objects to allow\ndict access, since no effort has been made to audit the code yet.\n\nChange-Id: I03f93f0c40df6f5f7df9cefe28dff900c22294c9\n""}, {'number': 2, 'created': '2014-12-12 10:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5199c5aa34eb42a49d0bfd5f8712fdced9604bb', 'message': ""objects: allow creation of objects without dict item compat\n\nThe dict compat support in NovaObject is useful for incrementally\nconverting existing code over to use objects. Any brand new objects\nthough have no reason to support dictionary access, so there should\nbe a way to disable this compat mode.\n\nThis moves all the dict compat support methods out of NovaObject,\nto a new class NovaObjectDictCompat. All existing objects are\nupdated to add this new class as a mix-in parent.\n\nIn future any completely new objects (ie ones which aren't being\nused to converted existing code from dict instances) should avoid\ninheriting from NovaObjectDictCompat. Existing objects should\nalso have this parent class removed once all callers are audited\nand/or updated to ensure they do not require dict compat.\n\nChange-Id: I03f93f0c40df6f5f7df9cefe28dff900c22294c9\n""}, {'number': 3, 'created': '2014-12-12 14:09:47.000000000', 'files': ['nova/objects/base.py', 'nova/objects/tag.py', 'nova/objects/dns_domain.py', 'nova/objects/hv_spec.py', 'nova/objects/service.py', 'nova/objects/bandwidth_usage.py', 'nova/objects/instance_numa_topology.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/objects/instance_fault.py', 'nova/objects/block_device.py', 'nova/objects/security_group_rule.py', 'nova/objects/keypair.py', 'nova/objects/virt_cpu_topology.py', 'nova/objects/compute_node.py', 'nova/objects/quotas.py', 'nova/objects/flavor.py', 'nova/objects/instance_pci_requests.py', 'nova/objects/fixed_ip.py', 'nova/objects/virtual_interface.py', 'nova/objects/numa.py', 'nova/objects/ec2.py', 'nova/objects/agent.py', 'nova/objects/instance_action.py', 'nova/objects/instance_info_cache.py', 'nova/objects/pci_device.py', 'nova/objects/floating_ip.py', 'nova/tests/unit/objects/test_objects.py', 'nova/objects/network.py', 'nova/objects/instance_group.py', 'nova/objects/network_request.py', 'nova/objects/instance.py', 'nova/objects/aggregate.py', 'nova/objects/security_group.py', 'nova/objects/migration.py', 'nova/objects/external_event.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/722e789309cfe3ef743c486f3f99c235f664153d', 'message': ""objects: allow creation of objects without dict item compat\n\nThe dict compat support in NovaObject is useful for incrementally\nconverting existing code over to use objects. Any brand new objects\nthough have no reason to support dictionary access, so there should\nbe a way to disable this compat mode.\n\nThis moves all the dict compat support methods out of NovaObject,\nto a new class NovaObjectDictCompat. All existing objects are\nupdated to add this new class as a mix-in parent.\n\nIn future any completely new objects (ie ones which aren't being\nused to converted existing code from dict instances) should avoid\ninheriting from NovaObjectDictCompat. Existing objects should\nalso have this parent class removed once all callers are audited\nand/or updated to ensure they do not require dict compat.\n\nChange-Id: I03f93f0c40df6f5f7df9cefe28dff900c22294c9\n""}]",2,141131,722e789309cfe3ef743c486f3f99c235f664153d,42,13,3,1779,,,0,"objects: allow creation of objects without dict item compat

The dict compat support in NovaObject is useful for incrementally
converting existing code over to use objects. Any brand new objects
though have no reason to support dictionary access, so there should
be a way to disable this compat mode.

This moves all the dict compat support methods out of NovaObject,
to a new class NovaObjectDictCompat. All existing objects are
updated to add this new class as a mix-in parent.

In future any completely new objects (ie ones which aren't being
used to converted existing code from dict instances) should avoid
inheriting from NovaObjectDictCompat. Existing objects should
also have this parent class removed once all callers are audited
and/or updated to ensure they do not require dict compat.

Change-Id: I03f93f0c40df6f5f7df9cefe28dff900c22294c9
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/141131/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/objects/tag.py', 'nova/objects/dns_domain.py', 'nova/objects/hv_spec.py', 'nova/objects/service.py', 'nova/objects/bandwidth_usage.py', 'nova/objects/instance_numa_topology.py', 'nova/objects/instance_fault.py', 'nova/objects/block_device.py', 'nova/objects/security_group_rule.py', 'nova/objects/keypair.py', 'nova/objects/virt_cpu_topology.py', 'nova/objects/compute_node.py', 'nova/objects/quotas.py', 'nova/objects/flavor.py', 'nova/objects/instance_pci_requests.py', 'nova/objects/fixed_ip.py', 'nova/objects/virtual_interface.py', 'nova/objects/numa.py', 'nova/objects/ec2.py', 'nova/objects/agent.py', 'nova/objects/instance_action.py', 'nova/objects/instance_info_cache.py', 'nova/objects/pci_device.py', 'nova/objects/floating_ip.py', 'nova/tests/unit/objects/test_objects.py', 'nova/objects/network.py', 'nova/objects/instance_group.py', 'nova/objects/network_request.py', 'nova/objects/instance.py', 'nova/objects/aggregate.py', 'nova/objects/security_group.py', 'nova/objects/migration.py', 'nova/objects/external_event.py']",34,0f59fee75e3dae341b39b90f242a5333bf066ca0,, # TODO(berrange): identify & remove any remaining dict # style property access dict_item_compat = True ,,342,24
openstack%2Fnova~master~I0109c93a7697ea60d97501200e5f559345ee2730,openstack/nova,master,I0109c93a7697ea60d97501200e5f559345ee2730,Fix race order issue in test_build_instances_scheduler_failure,ABANDONED,2014-12-17 17:54:13.000000000,2014-12-18 00:52:30.000000000,,"[{'_account_id': 7}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6450}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 17:54:13.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/007462bad4215e5cc018c0886fd51ae1acf9b852', 'message': ""Fix race order issue in test_build_instances_scheduler_failure\n\nThe calls to the handle_schedule_error mock are not deterministic\nwithout ordering the instances list and this leads to race failures in\nthe gate.\n\nSince we don't care about the actual order of the instances passed to\nhandle_schedule_error, simply stub out the method and assert the\ninstances are in the list of instances we created for the test,\nregardless of order.\n\nCloses-Bug: #1403564\n\nChange-Id: I0109c93a7697ea60d97501200e5f559345ee2730\n""}]",0,142522,007462bad4215e5cc018c0886fd51ae1acf9b852,8,6,1,6873,,,0,"Fix race order issue in test_build_instances_scheduler_failure

The calls to the handle_schedule_error mock are not deterministic
without ordering the instances list and this leads to race failures in
the gate.

Since we don't care about the actual order of the instances passed to
handle_schedule_error, simply stub out the method and assert the
instances are in the list of instances we created for the test,
regardless of order.

Closes-Bug: #1403564

Change-Id: I0109c93a7697ea60d97501200e5f559345ee2730
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/142522/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/conductor/test_conductor.py'],1,007462bad4215e5cc018c0886fd51ae1acf9b852,bug/1403564," instance_uuids = [instance.uuid for instance in instances] def fake_handle_schedule_error(context, exc, instance_uuid, request_spec): self.assertEqual(self.context, context) self.assertEqual(exception, exc) self.assertIn(instance_uuid, instance_uuids) self.assertEqual(spec, request_spec) self.stubs.Set(scheduler_driver, 'handle_schedule_error', fake_handle_schedule_error)"," self.mox.StubOutWithMock(scheduler_driver, 'handle_schedule_error') for instance in instances: scheduler_driver.handle_schedule_error(self.context, exception, instance.uuid, spec)",11,4
openstack%2Fhorizon~master~I94260db6089e44e66bf19b0ede172eec1756cdc5,openstack/horizon,master,I94260db6089e44e66bf19b0ede172eec1756cdc5,Integration tests - 3 new form fields,MERGED,2014-11-06 17:13:42.000000000,2014-12-18 00:51:05.000000000,2014-12-18 00:51:04.000000000,"[{'_account_id': 3}, {'_account_id': 581}, {'_account_id': 1941}, {'_account_id': 4978}, {'_account_id': 6825}, {'_account_id': 7179}, {'_account_id': 8090}, {'_account_id': 8577}, {'_account_id': 9317}, {'_account_id': 9981}, {'_account_id': 10684}, {'_account_id': 11473}, {'_account_id': 12355}, {'_account_id': 12721}, {'_account_id': 12954}, {'_account_id': 13049}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-11-06 17:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d2f93146fb094cf8a39ced463fe29a20bb94bb3f', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand chek if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I seperated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}, {'number': 2, 'created': '2014-11-09 09:30:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/67b6423da9ae0ba8e1d4b52ff7983bbf80decdad', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand check if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I separated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}, {'number': 3, 'created': '2014-11-11 16:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/23911ebf71a25400259f65929afdf6b4ca06587a', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand check if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I separated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}, {'number': 4, 'created': '2014-11-21 14:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ad927b1c648bd445244fb510b492a8af2ca2e74b', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand check if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I separated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}, {'number': 5, 'created': '2014-11-25 14:08:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/12440478fb76711166d77d29cde413d43d2b6840', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand check if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I separated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}, {'number': 6, 'created': '2014-11-27 21:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0561f14e1bf2b96137c0f9cb210cda637fa9ed5d', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand check if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I separated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}, {'number': 7, 'created': '2014-12-09 20:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f70ce94e1b6d00a9ec3293e97f7d1f1aaff42b0a', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand check if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I separated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}, {'number': 8, 'created': '2014-12-13 20:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/68ae271ef7f2ce3b496e9d2b90c7e53a4c687942', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand check if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I separated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}, {'number': 9, 'created': '2014-12-15 09:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5f60f3cdfb9cfb95cc93d15f39dc7e8129e794bb', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand check if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I separated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}, {'number': 10, 'created': '2014-12-16 20:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a1daa38e06725200949f874959c5195dbac12e1e', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand check if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I separated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}, {'number': 11, 'created': '2014-12-17 09:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7a8799155608c640e71ae6a69cd6f538a1f01bf6', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand check if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I separated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}, {'number': 12, 'created': '2014-12-17 10:49:31.000000000', 'files': ['openstack_dashboard/test/integration_tests/regions/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/4da228687510593608aced5b7e4d59eaadaa435e', 'message': ""Integration tests - 3 new form fields\n\nI added 3 new form fields, that are frequently used\nin different horizon's forms:\n* CheckBoxFormField - with the options to mark, unmark\nand check if already marked.\n* ChooseFileField - with a choose file action.\n* TextAreaFormField - intended for multi-line text input box.\n\nThe reason I separated this change from the Images page patch\nis to allow others to use it in their patches without forcing\nthe images as a dependency.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5\n""}]",7,133095,4da228687510593608aced5b7e4d59eaadaa435e,48,17,12,8577,,,0,"Integration tests - 3 new form fields

I added 3 new form fields, that are frequently used
in different horizon's forms:
* CheckBoxFormField - with the options to mark, unmark
and check if already marked.
* ChooseFileField - with a choose file action.
* TextAreaFormField - intended for multi-line text input box.

The reason I separated this change from the Images page patch
is to allow others to use it in their patches without forcing
the images as a dependency.

Partially implements blueprint: selenium-integration-testing

Change-Id: I94260db6089e44e66bf19b0ede172eec1756cdc5
",git fetch https://review.opendev.org/openstack/horizon refs/changes/95/133095/12 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/regions/forms.py'],1,d2f93146fb094cf8a39ced463fe29a20bb94bb3f,bp/selenium-integration-testing,"class CheckBoxFormFieldRegion(BaseFormFieldRegion): """"""checkbox field."""""" _element_locator = (by.By.CSS_SELECTOR, 'div > label > input[type=checkbox]') def is_marked(self): return self.element.is_selected() def mark(self): if not self.is_marked(): self.element.click() def unmark(self): if self.is_marked(): self.element.click() class ChooseFileFormFieldRegion(BaseFormFieldRegion): """"""choose File field."""""" _element_locator = (by.By.CSS_SELECTOR, 'div > input[type=file]') def choose(self, path): self.element.send_keys(path) class TextAreaFormFieldRegion(BaseTextFormFieldRegion): """"""Multi-line text input box."""""" _element_locator = (by.By.CSS_SELECTOR, 'div > textarea') ",,33,0
openstack%2Fcongress~master~I27ae9d6e0f3a132f1bdaa86a172adc366f451d09,openstack/congress,master,I27ae9d6e0f3a132f1bdaa86a172adc366f451d09,Enable: E128 continuation line under-indented for visual indent,MERGED,2014-12-06 13:26:14.000000000,2014-12-18 00:50:49.000000000,2014-12-17 23:39:44.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-06 13:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/555493c1663f1412d3bcd635af754f45c1ac7ce7', 'message': 'Enable: E128 continuation line under-indented for visual indent\n\nChange-Id: I27ae9d6e0f3a132f1bdaa86a172adc366f451d09\nCloses-Bug: #1398540\n'}, {'number': 2, 'created': '2014-12-17 12:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/093060820c5ff6bf50b6ac280081488e8b51336a', 'message': 'Enable: E128 continuation line under-indented for visual indent\n\nChange-Id: I27ae9d6e0f3a132f1bdaa86a172adc366f451d09\nCloses-Bug: #1398540\n'}, {'number': 3, 'created': '2014-12-17 15:06:03.000000000', 'files': ['congress/tests/policy/brokentest_runtime.py', 'congress/tests/datasources/test_datasource_driver.py', 'congress/tests/policy/test_runtime.py', 'congress/datasources/swift_driver.py', 'congress/dse/deepsix.py', 'congress/datasources/datasource_driver.py', 'congress/policy/dsepolicy.py', 'congress/policy/runtime.py', 'congress/tests/policy/test_unify.py', 'congress/harness.py', 'congress/policy/unify.py', 'congress/tests/policy/test_compiler.py', 'congress/datasources/ceilometer_driver.py', 'congress/tests/policy/builtin/test_builtin.py', 'congress/tests/policy/test_materialized.py', 'tox.ini', 'congress/tests/datasources/test_swift_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/d4c76d451a345d2d0954b15efc48900bd73561af', 'message': 'Enable: E128 continuation line under-indented for visual indent\n\nChange-Id: I27ae9d6e0f3a132f1bdaa86a172adc366f451d09\nCloses-Bug: #1398540\n'}]",0,139799,d4c76d451a345d2d0954b15efc48900bd73561af,18,4,3,12256,,,0,"Enable: E128 continuation line under-indented for visual indent

Change-Id: I27ae9d6e0f3a132f1bdaa86a172adc366f451d09
Closes-Bug: #1398540
",git fetch https://review.opendev.org/openstack/congress refs/changes/99/139799/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/policy/brokentest_runtime.py', 'congress/tests/policy/test_runtime.py', 'congress/datasources/swift_driver.py', 'congress/dse/deepsix.py', 'congress/datasources/datasource_driver.py', 'congress/policy/dsepolicy.py', 'congress/policy/runtime.py', 'congress/policy/builtin/tests/test_builtin.py', 'congress/tests/policy/test_unify.py', 'congress/harness.py', 'congress/policy/unify.py', 'congress/tests/policy/test_compiler.py', 'congress/datasources/ceilometer_driver.py', 'congress/tests/policy/test_materialized.py', 'tox.ini', 'congress/tests/datasources/test_swift_driver.py']",16,555493c1663f1412d3bcd635af754f45c1ac7ce7,(detached," '9204776814ca62c92c7996de725ecc6b', 'file-1', 'application/octet-stream', 'container1'), object_list[0]) 'c2b86044dd50a29d60c0e92e23e3ceea', 'file-2', 'application/octet-stream', 'container2'), object_list[1]) '9204776814ca62c92c7996de725ecc6b', 'file-1', 'application/octet-stream', 'container1'), object_list[1]) 'c2b86044dd50a29d60c0e92e23e3ceea', 'file-2', 'application/octet-stream', 'container2'), object_list[0])"," '9204776814ca62c92c7996de725ecc6b', 'file-1', 'application/octet-stream', 'container1'), object_list[0]) 'c2b86044dd50a29d60c0e92e23e3ceea', 'file-2', 'application/octet-stream', 'container2'), object_list[1]) '9204776814ca62c92c7996de725ecc6b', 'file-1', 'application/octet-stream', 'container1'), object_list[1]) 'c2b86044dd50a29d60c0e92e23e3ceea', 'file-2', 'application/octet-stream', 'container2'), object_list[0])",74,78
openstack%2Ffuel-web~stable%2F6.0~I7e4ba8f3a6a0ba822c47b9c14fe4d02b3523d658,openstack/fuel-web,stable/6.0,I7e4ba8f3a6a0ba822c47b9c14fe4d02b3523d658,Serialize default_gateway/other_nets for 6.0 only,MERGED,2014-12-17 17:48:47.000000000,2014-12-17 23:39:13.000000000,2014-12-17 23:39:11.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8789}, {'_account_id': 8829}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-17 17:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9bd51c1f83e7664cf0ee31277eae72d49b659ec0', 'message': 'Serialize default_gateway/other_nets for 6.0 only\n\nBoth default_gateway and other_nets fields have been introduced in Fuel 6.0,\nbut accidently were serialized for old envs too. This led to puppet\nerrors when we tried to re-deploy node in one of the old envs.\n\nChange-Id: I7e4ba8f3a6a0ba822c47b9c14fe4d02b3523d658\nCloses-Bug: #1403560\n'}, {'number': 2, 'created': '2014-12-17 17:51:03.000000000', 'files': ['nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/test/integration/test_cluster_changes_handler.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5f91157daa6798ff522ca9f6d34e7e135f150a90', 'message': 'Serialize default_gateway/other_nets for 6.0 only\n\nBoth default_gateway and other_nets fields have been introduced in Fuel 6.0,\nbut accidently were serialized for old envs too. This led to puppet\nerrors when we tried to re-deploy node in one of the old envs.\n\nChange-Id: I7e4ba8f3a6a0ba822c47b9c14fe4d02b3523d658\nCloses-Bug: #1403560\n'}]",0,142519,5f91157daa6798ff522ca9f6d34e7e135f150a90,16,5,2,10391,,,0,"Serialize default_gateway/other_nets for 6.0 only

Both default_gateway and other_nets fields have been introduced in Fuel 6.0,
but accidently were serialized for old envs too. This led to puppet
errors when we tried to re-deploy node in one of the old envs.

Change-Id: I7e4ba8f3a6a0ba822c47b9c14fe4d02b3523d658
Closes-Bug: #1403560
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/19/142519/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/fixtures/openstack.yaml']",3,9bd51c1f83e7664cf0ee31277eae72d49b659ec0,," version: ""2014.1.3-5.1.1"""," version: ""2014.2-6.0""",490,21
openstack%2Ffuel-web~master~I7e4ba8f3a6a0ba822c47b9c14fe4d02b3523d658,openstack/fuel-web,master,I7e4ba8f3a6a0ba822c47b9c14fe4d02b3523d658,Serialize default_gateway/other_nets for 6.0 only,MERGED,2014-12-17 17:48:20.000000000,2014-12-17 23:37:21.000000000,2014-12-17 23:37:20.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8789}, {'_account_id': 8829}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-12-17 17:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6b1538a67f46abc12b2c2100f68c12e084c1b460', 'message': 'Serialize default_gateway/other_nets for 6.0 only\n\nBoth default_gateway and other_nets fields have been introduced in Fuel 6.0,\nbut accidently were serialized for old envs too. This led to puppet\nerrors when we tried to re-deploy node in one of the old envs.\n\nChange-Id: I7e4ba8f3a6a0ba822c47b9c14fe4d02b3523d658\nCloses-Bug: #1403560\n'}, {'number': 2, 'created': '2014-12-17 17:50:29.000000000', 'files': ['nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/test/integration/test_cluster_changes_handler.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4e7a99598b2ced232a90c18af79ed80f02d540ca', 'message': 'Serialize default_gateway/other_nets for 6.0 only\n\nBoth default_gateway and other_nets fields have been introduced in Fuel 6.0,\nbut accidently were serialized for old envs too. This led to puppet\nerrors when we tried to re-deploy node in one of the old envs.\n\nChange-Id: I7e4ba8f3a6a0ba822c47b9c14fe4d02b3523d658\nCloses-Bug: #1403560\n'}]",2,142518,4e7a99598b2ced232a90c18af79ed80f02d540ca,18,7,2,10391,,,0,"Serialize default_gateway/other_nets for 6.0 only

Both default_gateway and other_nets fields have been introduced in Fuel 6.0,
but accidently were serialized for old envs too. This led to puppet
errors when we tried to re-deploy node in one of the old envs.

Change-Id: I7e4ba8f3a6a0ba822c47b9c14fe4d02b3523d658
Closes-Bug: #1403560
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/18/142518/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/fixtures/openstack.yaml']",3,6b1538a67f46abc12b2c2100f68c12e084c1b460,bug/1403560," version: ""2014.1.3-5.1.1"""," version: ""2014.2-6.0""",490,21
openstack%2Ffuel-main~stable%2F5.1~I41f67b5ef01709860c5fb42e84937155470bf878,openstack/fuel-main,stable/5.1,I41f67b5ef01709860c5fb42e84937155470bf878,Bump product version to 5.1.2,MERGED,2014-12-17 16:53:11.000000000,2014-12-17 23:36:06.000000000,2014-12-17 23:36:05.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8789}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 10474}]","[{'number': 1, 'created': '2014-12-17 16:53:11.000000000', 'files': ['config.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9b1d200d46a7b0053fb40058f397e73a294f0aee', 'message': 'Bump product version to 5.1.2\n\nChange-Id: I41f67b5ef01709860c5fb42e84937155470bf878\n'}]",0,142501,9b1d200d46a7b0053fb40058f397e73a294f0aee,11,7,1,9977,,,0,"Bump product version to 5.1.2

Change-Id: I41f67b5ef01709860c5fb42e84937155470bf878
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/01/142501/1 && git format-patch -1 --stdout FETCH_HEAD,['config.mk'],1,9b1d200d46a7b0053fb40058f397e73a294f0aee,,PRODUCT_VERSION:=5.1.2,PRODUCT_VERSION:=5.1.1,1,1
openstack%2Fneutron~stable%2Fjuno~Id0a3af22fb85992bde35d8c691bee3ddf435639d,openstack/neutron,stable/juno,Id0a3af22fb85992bde35d8c691bee3ddf435639d,Fix race condition in ProcessMonitor,ABANDONED,2014-12-17 12:01:00.000000000,2014-12-17 23:34:38.000000000,,"[{'_account_id': 5170}, {'_account_id': 8788}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-12-17 12:01:00.000000000', 'files': ['neutron/agent/linux/external_process.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d3712c552e577171ed39842b6f1571b5f360ba40', 'message': 'Fix race condition in ProcessMonitor\n\nIf any new external process was enabled/disabled during\nthe process monitoring loop time, a RuntimeError: dictionary\nchanged size during iteration was thrown. This is fixed\nby pre-building the service list from the dictionary\nfor the iteration.\n\nCloses-Bug: #1401042\n\nChange-Id: Id0a3af22fb85992bde35d8c691bee3ddf435639d\n(cherry picked from commit b25915f1d94e19756c932ae18119bdf872cc6316)\n'}]",0,142430,d3712c552e577171ed39842b6f1571b5f360ba40,8,8,1,9656,,,0,"Fix race condition in ProcessMonitor

If any new external process was enabled/disabled during
the process monitoring loop time, a RuntimeError: dictionary
changed size during iteration was thrown. This is fixed
by pre-building the service list from the dictionary
for the iteration.

Closes-Bug: #1401042

Change-Id: Id0a3af22fb85992bde35d8c691bee3ddf435639d
(cherry picked from commit b25915f1d94e19756c932ae18119bdf872cc6316)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/142430/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/external_process.py'],1,d3712c552e577171ed39842b6f1571b5f360ba40,, # we build the list of keys before iterating in the loop to cover # the case where other threads add or remove items from the # dictionary which otherwise will cause a RuntimeError for service_id in list(self._process_managers):, for service_id in self._process_managers:,4,1
openstack%2Fmonasca-agent~master~I445ae8d1b76be9a797bce5c39db71f7511f332be,openstack/monasca-agent,master,I445ae8d1b76be9a797bce5c39db71f7511f332be,Adding check for required dependencies in setup,MERGED,2014-12-11 17:34:13.000000000,2014-12-17 23:12:38.000000000,2014-12-17 23:12:36.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11094}, {'_account_id': 12108}, {'_account_id': 12443}]","[{'number': 1, 'created': '2014-12-11 17:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/80d6f3579a8112aa0a6f7150bf05cf77107975f4', 'message': 'Adding check for required dependencies in setup\n\nChange-Id: I445ae8d1b76be9a797bce5c39db71f7511f332be\n'}, {'number': 2, 'created': '2014-12-11 19:01:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/6170f8c8045144296ce18fc428c31fa08e81b941', 'message': 'Adding check for required dependencies in setup\n\nThis check was added because the agent will run without these packages installed\nbut the agent would not send all of the documented system metrics with no explanation of why.\n\nChange-Id: I445ae8d1b76be9a797bce5c39db71f7511f332be\n'}, {'number': 3, 'created': '2014-12-11 19:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/59a1d7d6b7be3a3f27f1c2a2c80dc6e8b31b8c9d', 'message': 'Adding check for required dependencies in setup\n\nThis check was added because the agent will run without these packages installed\nbut the agent would not send all of the documented system metrics with no explanation of why.\n\nChange-Id: I445ae8d1b76be9a797bce5c39db71f7511f332be\n'}, {'number': 4, 'created': '2014-12-11 19:08:52.000000000', 'files': ['monsetup/main.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/5dfb2d15fe0913a5ed985894a6f6d23e6e2ff373', 'message': 'Adding check for required dependencies in setup\n\nThis check was added because the agent will run without these packages installed\nbut the agent would not send all of the documented system metrics with no explanation of why.\n\nChange-Id: I445ae8d1b76be9a797bce5c39db71f7511f332be\n'}]",2,141107,5dfb2d15fe0913a5ed985894a6f6d23e6e2ff373,15,5,4,12108,,,0,"Adding check for required dependencies in setup

This check was added because the agent will run without these packages installed
but the agent would not send all of the documented system metrics with no explanation of why.

Change-Id: I445ae8d1b76be9a797bce5c39db71f7511f332be
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/07/141107/1 && git format-patch -1 --stdout FETCH_HEAD,['monsetup/main.py'],1,80d6f3579a8112aa0a6f7150bf05cf77107975f4,monasca/check-system-dependencies," linux_flavor = platform.linux_distribution()[0] if 'Ubuntu' or 'debian' in linux_flavor: required_packages = ['coreutils', 'sysstat'] for package in required_packages: #Check for required dependencies for system checks try: output = subprocess.check_output('dpkg -s {}'.format(package), stderr=subprocess.STDOUT, shell=True) except subprocess.CalledProcessError: log.error(""*** {} package is not installed! ***"".format(package) + ""\nPlease install the {} "".format(package) + ""package and re-run the monasca-setup program."" + ""\nExiting setup program..."") sys.exit() else: pass", pass,18,1
openstack%2Fneutron-specs~master~If7822dabfacb65bddcb714f04573993c017c53cc,openstack/neutron-specs,master,If7822dabfacb65bddcb714f04573993c017c53cc,firewall: add mcafee ngfw driver support,MERGED,2014-04-30 07:25:52.000000000,2014-12-17 23:12:23.000000000,2014-12-17 23:12:21.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 490}, {'_account_id': 2592}, {'_account_id': 4149}, {'_account_id': 4992}, {'_account_id': 6854}, {'_account_id': 6995}, {'_account_id': 7021}, {'_account_id': 8645}, {'_account_id': 11114}, {'_account_id': 11347}, {'_account_id': 12525}]","[{'number': 1, 'created': '2014-04-30 07:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d1cc6bb11a47fb4ffc652964c8c92cb0978e01a1', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\n'}, {'number': 2, 'created': '2014-04-30 07:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6da0f3ad9bc77bbd522d0a4589c53e6330af5823', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\n'}, {'number': 3, 'created': '2014-05-04 01:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9eca5c5654a31b9dac29e72187f1f4bf249a995d', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\n'}, {'number': 4, 'created': '2014-06-02 09:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5123de5e7bff9b7c6b2cc2e99fe666d5b99a46bf', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\n'}, {'number': 5, 'created': '2014-06-12 05:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/aa0f684524c2ab36cb3cee8573ef78419cb84473', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\n'}, {'number': 6, 'created': '2014-07-15 09:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/50f677b4de186af3717b9059c65164548c34d293', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\n'}, {'number': 7, 'created': '2014-10-30 07:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/676501b74804c4e9fdfbcf5ca2b188c937c12d7c', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 8, 'created': '2014-11-13 13:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9909d4b64b68a4f34322b439f4ef00b33c94e151', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 9, 'created': '2014-11-13 14:09:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/21d7c78ebfedcb95a9480d2aae541079add7fe79', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 10, 'created': '2014-11-17 01:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/863f0448cf205f9e113c86bcc73ff9ae2bfb4df3', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 11, 'created': '2014-11-19 03:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9661cc93231e6ac2799a591253907c811903fc7f', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 12, 'created': '2014-11-26 07:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6a12a3da10c768e4f039258815dc2139da908c15', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 13, 'created': '2014-12-08 06:16:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/86e105723256766cc110d84312a8e4c09a81c4c7', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 14, 'created': '2014-12-12 02:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/7b904308786445f0f69936614832a4e01b333b16', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 15, 'created': '2014-12-12 03:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5cf5b22ca22ec094892b5b62ba2c94deaa8a42c2', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 16, 'created': '2014-12-12 05:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3768087812a24b51c22e438cab0d2e92d956daae', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 17, 'created': '2014-12-12 07:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0510522267bd58976b58bf75287f62a92da62304', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 18, 'created': '2014-12-12 08:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2b839027cf2c8ab5cd7755551dc9aa0ff8c980ad', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 19, 'created': '2014-12-13 01:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/7531436f89e3a2cc4689be007624c4fef447d4e7', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 20, 'created': '2014-12-17 00:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5e8382e91fac501dba32a4c7d9a872d66910faae', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}, {'number': 21, 'created': '2014-12-17 02:34:07.000000000', 'files': ['specs/kilo/mcafee-ngfw-fwaas-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/46704b040469675b364b5c6c26b97c2ee4b45283', 'message': 'firewall: add mcafee ngfw driver support\n\nChange-Id: If7822dabfacb65bddcb714f04573993c017c53cc\nblueprint: mcafee-ngfw-fwaas-driver\n'}]",87,91286,46704b040469675b364b5c6c26b97c2ee4b45283,124,16,21,333,,,0,"firewall: add mcafee ngfw driver support

Change-Id: If7822dabfacb65bddcb714f04573993c017c53cc
blueprint: mcafee-ngfw-fwaas-driver
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/86/91286/21 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/ngfw-firewall-driver.rst'],1,d1cc6bb11a47fb4ffc652964c8c92cb0978e01a1,bp/mcafee-ngfw-fwaas-driver,.. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================ Add firewall driver for McAfee NGFW firewall ============================================ https://blueprints.launchpad.net/neutron/+spec/mcafee-ngfw-fwaas-driver Implements FWaaS driver for McAfee ngfw fireall Proposed change =============== Introduce a new driver and enhancement to agent for FWaaS. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- New service provider for the driver will be introduced. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: yamahata Other contributors: None Work Items ---------- * FWaaS driver * Agent enhancement * third party testing Dependencies ============ * McAfee NGFW Testing ======= Third party testing would be added. Documentation Impact ==================== Admin guide will be updated. References ========== * http://www.mcafee.com/us/products/next-generation-firewall.aspx ,,117,0
openstack%2Fmanila~master~I3b05369f01777675c1b834af5ee076d8b7219a0f,openstack/manila,master,I3b05369f01777675c1b834af5ee076d8b7219a0f,Move networking from share manager to driver interface,MERGED,2014-12-12 20:31:37.000000000,2014-12-17 23:12:13.000000000,2014-12-17 23:12:11.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 8851}, {'_account_id': 11047}, {'_account_id': 11878}, {'_account_id': 14232}]","[{'number': 1, 'created': '2014-12-12 20:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/39ac4e46fbcdd06e4e558507825a721ebf342d2e', 'message': ""[WIP] Move networing from share manager to driver interface\n\nSeveral things are implemented:\n- Allocation/deallocation now handled by drivers instead of share manager.\nit provides flexibility for drivers.\n- Neutron network plugin was updated to support new approach for setting config\nopts.\n\nConfig opts for network plugin can be defined via three sources:\na) using separate config group\nb) using config group of back end\nc) using DEFAULT config group\nVariants (a) and (b) are mutually exclusive, there are switched by\nopt 'network_config_group' that belongs to share driver interface.\n\nTODO: update unit tests\n\nPartially implements bp network-helper\n\nChange-Id: I3b05369f01777675c1b834af5ee076d8b7219a0f\n""}, {'number': 2, 'created': '2014-12-15 20:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b3e0212707d5493b41d0e10baa201ef0209506f8', 'message': ""Move networking from share manager to driver interface\n\nSeveral things are implemented:\n- Allocation/deallocation now handled by drivers instead of share manager.\nit provides flexibility for drivers.\n- Network plugin interface was updated to support new approach for\nconfiguration options setting.\n\nConfig opts for network plugin can be defined via three sources:\na) using separate config group\nb) using config group of back end\nc) using DEFAULT config group\nVariants (a) and (b) are mutually exclusive, there are switched by\nopt 'network_config_group' that belongs to share driver interface.\n\nPartially implements bp network-helper\n\nChange-Id: I3b05369f01777675c1b834af5ee076d8b7219a0f\n""}, {'number': 3, 'created': '2014-12-15 20:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8c1502910567d6cdc7c2d29b0c3aacad3a41e78e', 'message': ""Move networking from share manager to driver interface\n\nSeveral things are implemented:\n- Allocation/deallocation now handled by drivers instead of share manager.\nit provides flexibility for drivers.\n- Network plugin interface was updated to support new approach for\nconfiguration options setting.\n\nConfig opts for network plugin can be defined via three sources:\na) using separate config group\nb) using config group of back end\nc) using DEFAULT config group\nVariants (a) and (b) are mutually exclusive, there are switched by\nopt 'network_config_group' that belongs to share driver interface.\n\nImplements bp network-helper\n\nChange-Id: I3b05369f01777675c1b834af5ee076d8b7219a0f\n""}, {'number': 4, 'created': '2014-12-16 15:32:40.000000000', 'files': ['manila/network/__init__.py', 'manila/share/drivers/glusterfs_native.py', 'manila/tests/network/neutron/test_neutron_api.py', 'manila/network/neutron/api.py', 'manila/share/driver.py', 'manila/share/drivers/emc/driver.py', 'manila/share/drivers/ibm/gpfs.py', 'manila/share/manager.py', 'manila/tests/share/test_driver.py', 'manila/network/neutron/neutron_network_plugin.py', 'manila/network/neutron/__init__.py', 'manila/share/drivers/glusterfs.py', 'manila/tests/share/test_manager.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/36db3f39178123625d9e38b29ba6118f8b870254', 'message': ""Move networking from share manager to driver interface\n\nSeveral things are implemented:\n- Allocation/deallocation now handled by drivers instead of share manager.\nIt provides flexibility for drivers.\n- Network plugin interface was updated to support new approach for\nconfiguration options setting.\n\nConfig opts for network plugin can be defined via three sources:\na) using separate config group\nb) using config group of back end\nc) using DEFAULT config group\nVariants (a) and (b) are mutually exclusive, there are switched by\nopt 'network_config_group' that belongs to share driver interface.\n\nImplements bp network-helper\n\nChange-Id: I3b05369f01777675c1b834af5ee076d8b7219a0f\n""}]",39,141483,36db3f39178123625d9e38b29ba6118f8b870254,21,7,4,8851,,,0,"Move networking from share manager to driver interface

Several things are implemented:
- Allocation/deallocation now handled by drivers instead of share manager.
It provides flexibility for drivers.
- Network plugin interface was updated to support new approach for
configuration options setting.

Config opts for network plugin can be defined via three sources:
a) using separate config group
b) using config group of back end
c) using DEFAULT config group
Variants (a) and (b) are mutually exclusive, there are switched by
opt 'network_config_group' that belongs to share driver interface.

Implements bp network-helper

Change-Id: I3b05369f01777675c1b834af5ee076d8b7219a0f
",git fetch https://review.opendev.org/openstack/manila refs/changes/83/141483/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/network/__init__.py', 'manila/share/drivers/glusterfs_native.py', 'manila/network/neutron/api.py', 'manila/share/drivers/ibm/gpfs.py', 'manila/share/manager.py', 'manila/share/driver.py', 'manila/network/neutron/neutron_network_plugin.py', 'manila/network/neutron/__init__.py', 'manila/share/drivers/glusterfs.py']",9,39ac4e46fbcdd06e4e558507825a721ebf342d2e,bp/network-helper, def get_network_allocations_number(self): return 0 ,,149,140
openstack%2Fkeystone-specs~master~I057c0fd74ce26c19431c9ad62be90ca22b5d66c7,openstack/keystone-specs,master,I057c0fd74ce26c19431c9ad62be90ca22b5d66c7,rescope tokens unscoped to scoped only,MERGED,2014-09-24 15:26:43.000000000,2014-12-17 23:12:02.000000000,2014-12-17 23:12:01.000000000,"[{'_account_id': 3}, {'_account_id': 220}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6460}, {'_account_id': 6534}, {'_account_id': 7244}, {'_account_id': 8978}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-09-24 15:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/6047792ee01a487e3969aa4dd954d30baca29707', 'message': 'rescope tokens unscoped to scoped only\n\nChange-Id: I057c0fd74ce26c19431c9ad62be90ca22b5d66c7\n'}, {'number': 2, 'created': '2014-10-19 14:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/26e7c3f5301adcbeaea6e9c7a8c1e96769d44018', 'message': 'rescope tokens unscoped to scoped only\n\nChange-Id: I057c0fd74ce26c19431c9ad62be90ca22b5d66c7\n'}, {'number': 3, 'created': '2014-10-20 01:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/98e025f7e811ad8364ef842ffcb0e81d57d38d56', 'message': 'rescope tokens unscoped to scoped only\n\nChange-Id: I057c0fd74ce26c19431c9ad62be90ca22b5d66c7\n'}, {'number': 4, 'created': '2014-11-01 01:30:03.000000000', 'files': ['specs/kilo/rescoping.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/a7e3c288c4d899f854645baaf3680347b678f5f7', 'message': 'rescope tokens unscoped to scoped only\n\nChange-Id: I057c0fd74ce26c19431c9ad62be90ca22b5d66c7\n'}]",14,123760,a7e3c288c4d899f854645baaf3680347b678f5f7,25,10,4,2218,,,0,"rescope tokens unscoped to scoped only

Change-Id: I057c0fd74ce26c19431c9ad62be90ca22b5d66c7
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/60/123760/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/rescoping.rst'],1,6047792ee01a487e3969aa4dd954d30baca29707,123760,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Rescoping Spec - The title of your blueprint ========================================== `bp rescoping <https://blueprints.launchpad.net/keystone/+spec/rescoping>`_ Limit the rescoping of tokens to prevent unauthorized reuse. Problem Description =================== Any token a user requests themselves can be used to request another token. Effectivly, any such token is unconstrained. Proposed Change =============== Constrain tokens such that any token that is not ""unscoped"" cannot be exchanged for a token that is scoped to a domain or project. Alternatives ------------ None: Security Impact --------------- * Does this change touch sensitive data such as tokens, keys, or user data? Yes: token for token echanges are to be limited. * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? No * Does this change involve cryptography or hashing? No * Does this change require the use of sudo or any elevated privileges? No * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. No * Can this change enable a resource exhaustion attack. No Notifications Impact -------------------- None Other End User Impact --------------------- This should be hidden from the end user in just about every case. The one exception is people making direct CURL calls to Keystone. The Keystone client will make this seemless elsewhere. Performance Impact ------------------ Many requests for a single, scoped, token will now require multiple tokens. First one will be unscoped, second will be scoped. Horizon will be the primary consumer that sees this. However, in LDAP deployments, Horizon already works this way. Other Deployer Impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? A Config flag to enable,disable this feature * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? Needs to be explicitly enabled * If this change is a new binary, how would it be deployed? No Developer Impact ---------------- All services that need multiple tokens will have to hold on to one unscoped token to get the other tokens. This should be managed by the keystone client. Implementation ============== Assignee(s) ----------- Primary assignee: ayoung : Adam Young <ayoung@redhat.com> Other contributors: <launchpad-id or None> Work Items ---------- Dependencies ============ * References ========== Requires the implementation for http://git.openstack.org/cgit/openstack/keystone-specs/tree/specs/kilo/explicit-unscoped.rst ",,134,0
openstack%2Fdesignate~master~Ieb5b4dc241d8cc50931ca40e5158e0d931108228,openstack/designate,master,Ieb5b4dc241d8cc50931ca40e5158e0d931108228,Fixed the syntax of obj_reset_changes in SQLA,MERGED,2014-12-15 18:59:23.000000000,2014-12-17 23:11:58.000000000,2014-12-17 23:11:56.000000000,"[{'_account_id': 3}, {'_account_id': 395}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-12-15 18:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/348fa099ab0d2d5a5deafa7a5554dd9ca7532c1f', 'message': 'Fixed the syntax of obj_reset_changes in SQLA\n\nChange-Id: Ieb5b4dc241d8cc50931ca40e5158e0d931108228\nCloses-Bug: 1402788\n'}, {'number': 2, 'created': '2014-12-15 19:03:56.000000000', 'files': ['designate/storage/impl_sqlalchemy/__init__.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/8b1dccd81765aced68faa766bb821376c36fd907', 'message': 'Fixed the syntax of obj_reset_changes in SQLA\n\nChange-Id: Ieb5b4dc241d8cc50931ca40e5158e0d931108228\nCloses-Bug: 1402788\n'}]",3,141879,8b1dccd81765aced68faa766bb821376c36fd907,11,5,2,8099,,,0,"Fixed the syntax of obj_reset_changes in SQLA

Change-Id: Ieb5b4dc241d8cc50931ca40e5158e0d931108228
Closes-Bug: 1402788
",git fetch https://review.opendev.org/openstack/designate refs/changes/79/141879/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/storage/impl_sqlalchemy/__init__.py'],1,348fa099ab0d2d5a5deafa7a5554dd9ca7532c1f,bug/1402788, recordset.obj_reset_changes(['records']) recordset.obj_reset_changes(['records']) recordset.obj_reset_changes(['records']) recordset.obj_reset_changes(['records']) pool.obj_reset_changes(['attributes']) pool.obj_reset_changes(['nameservers']) pool.obj_reset_changes(['attributes']) pool.obj_reset_changes(['nameservers']) pool.obj_reset_changes(['attributes']) pool.obj_reset_changes(['nameservers']) pool.obj_reset_changes(['attributes']) pool.obj_reset_changes(['nameservers']), recordset.obj_reset_changes('records') recordset.obj_reset_changes('records') recordset.obj_reset_changes('records') recordset.obj_reset_changes('records') pool.obj_reset_changes('attributes') pool.obj_reset_changes('nameservers') pool.obj_reset_changes('attributes') pool.obj_reset_changes('nameservers') pool.obj_reset_changes('attributes') pool.obj_reset_changes('nameservers') pool.obj_reset_changes('attributes') pool.obj_reset_changes('nameservers'),12,12
openstack%2Fcinder-specs~master~Ifb77b5e808458e5a081e69dffec81b1703ca76c1,openstack/cinder-specs,master,Ifb77b5e808458e5a081e69dffec81b1703ca76c1,Database purge deleted spec,MERGED,2014-11-04 14:54:10.000000000,2014-12-17 23:11:49.000000000,2014-12-17 23:11:48.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5538}, {'_account_id': 6172}, {'_account_id': 7244}, {'_account_id': 11904}, {'_account_id': 12092}]","[{'number': 1, 'created': '2014-11-04 14:54:10.000000000', 'files': ['specs/kilo/database-purge.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/c41fb53859b19dce43f26cfd7df15da77d130cf0', 'message': ""Database purge deleted spec\n\nThis spec details the ability to cleanly purge 'deleted' rows.\nThis provides for confirmed data destruction, beyond the current\narchive_deleted_rows functionality.\n\nChange-Id: Ifb77b5e808458e5a081e69dffec81b1703ca76c1\n""}]",6,132685,c41fb53859b19dce43f26cfd7df15da77d130cf0,18,10,1,12092,,,0,"Database purge deleted spec

This spec details the ability to cleanly purge 'deleted' rows.
This provides for confirmed data destruction, beyond the current
archive_deleted_rows functionality.

Change-Id: Ifb77b5e808458e5a081e69dffec81b1703ca76c1
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/85/132685/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/database-purge.rst'],1,c41fb53859b19dce43f26cfd7df15da77d130cf0,add-database-purge,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== cinder db purge utility ========================================== https://blueprints.launchpad.net/cinder/+spec/database-purge This spec adds the ability to sanely and safely purge deleted rows from the cinder database for all relavent tables. Presently, we keep all deleted rows, or archive them to a 'shadow' table. I believe this is unmaintainable as we move towards more upgradable releases. Today, most users depend on manual DB queries to delete this data, but this opens up to human errors. The goal is to have this be an extention to the `cinder-manage db` command. Similar specs are being submitted to all the various projects that touch a database. Problem description =================== Very long lived Openstack installations will carry around database rows for years and years. To date, there is no ""mechanism"" to programatically purge the deleted data. The archive rows feature doesn't solve this. Use Cases ---------- Operators should have the ability to purge deleted rows, possibily on a schedule (cronjob) or as needed (Before an upgrade, prior to maintenance) The intended use would be to specify a number of days prior to today for deletion, e.g. ""cinder-manage db purge 60"" would purge deleted rows that have the ""deleted_at"" column greater than 60 days ago Project Priority ----------------- Low Proposed change =============== The proposal is to add a ""purge"" method to DbCommands in cinder/cinder/cmd/manage.py This will take a number of days argument, and use that for a data_sub match Like: delete from instances where deleted != 0 and deleted_at > data_sub(NOW()...) Alternatives ------------ Today, this can be accomplished manually with SQL commands, or via script. There is also the archive_deleted_rows method. However, this won't satisfy certain data destruction policies that may exist at some companies. Data model impact ----------------- None, all tables presently include a ""deleted_at"" column. REST API impact --------------- None, this would be run from cinder-manage Security impact --------------- Low, This only touches already deleted rows. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ This has the potential to improve performance for very large databases. Very long-lived installations can suffer from inefficient operations on large tables. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- primary author and contact. Abel Lopez <al592b> Primary assignee: <al592b> Other contributors: <al592b> Work Items ---------- Add purge functionality to manage.py db/api.py db/sqlalchemy/api.py Add tests to confirm functionality Add documentation of feature Dependencies ============ None Testing ======= The test will be written as such. Three rows will be inserted into a test db. Two will be ""deleted=1"", one will be ""deleted=0"" One of the deleted rows will have ""deleted_at"" be NOW(), the other will be ""deleted_at"" a few days ago, lets say 10. The test will call the new function with the argument of ""7"", to verify that only the row that was deleted at 10 days ago will be purged. The two other rows should remain. Documentation Impact ==================== will need to add documentation of this feature References ========== This was discussed on both the openstack-operators mailing list and the openstack-developers mailing lists with positive feedback from the group. http://lists.openstack.org/pipermail/openstack-dev/2014-October/049616.html ",,150,0
openstack%2Fcinder-specs~master~Id8b627acf826bfc308d2916852ad5d2f82f8f3d0,openstack/cinder-specs,master,Id8b627acf826bfc308d2916852ad5d2f82f8f3d0,Support iSER driver within the ISCSIDriver flow,MERGED,2014-12-16 16:02:14.000000000,2014-12-17 23:11:40.000000000,2014-12-17 23:11:39.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 12065}, {'_account_id': 12088}]","[{'number': 1, 'created': '2014-12-16 16:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/af3389d514841b942806551465bc2c0c36cedb53', 'message': 'Support iSER driver within the ISCSIDriver flow\n\nThis proposes to refactor the current iSER code in order to\navoid code duplication of classes and parameters, and to prevent\ninstability in the iSER driver flow, for the TGT and LIO cases.\n\nblueprint support-iscsi-driver\nChange-Id: Id8b627acf826bfc308d2916852ad5d2f82f8f3d0\n'}, {'number': 2, 'created': '2014-12-16 16:16:55.000000000', 'files': ['specs/kilo/support-iscsi-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/0de228eda118296037c82c9aaf9c890b0cfb7d0d', 'message': 'Support iSER driver within the ISCSIDriver flow\n\nThis proposes to refactor the current iSER code in order to\navoid code duplication of classes and parameters, and to prevent\ninstability in the iSER driver flow, for the TGT and LIO cases.\n\nblueprint support-iscsi-driver\nChange-Id: Id8b627acf826bfc308d2916852ad5d2f82f8f3d0\n'}]",2,142138,0de228eda118296037c82c9aaf9c890b0cfb7d0d,9,5,2,11968,,,0,"Support iSER driver within the ISCSIDriver flow

This proposes to refactor the current iSER code in order to
avoid code duplication of classes and parameters, and to prevent
instability in the iSER driver flow, for the TGT and LIO cases.

blueprint support-iscsi-driver
Change-Id: Id8b627acf826bfc308d2916852ad5d2f82f8f3d0
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/38/142138/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/support-iscsi-driver.rst'],1,af3389d514841b942806551465bc2c0c36cedb53,bp/support-iscsi-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================================== Support iSER driver within the ISCSIDriver flow =============================================== https://blueprints.launchpad.net/cinder/+spec/support-iscsi-driver This purpose of this BP is to avoid code duplications of classes and parameters, and to prevent instability in the iSER driver flow, for the TGT and LIO cases. Problem description =================== #. Currently the iSER driver is supported over TGT only, without LIO support. #. There are a couple of iSER classes that inherit from iSCSI driver/target classes, but most of their functionality is the same as the iSCSI classes. This code duplication causes instability in the iSER driver code, when new features or changes are added to the iSCSI driver flow. Proposed change =============== These two problems can be solved by adding a small fix, which includes a new enable_iser parameter within iSCSI Tgt/LIO classes. All that is needed for RDMA support over iSER, in the Tgt and LIO cases, is to set just one extra parameter in the volume creation stage. A deprecation alert will be added to ISERTgtAdm, since This change will act as a replacement to the current iSER Tgt code. The Nova part of this spec is specified at: https://review.openstack.org/#/c/130721/ Alternatives ------------ Leaving ISERTgtAdm, LVMISERDriver, ISERDriver and iser_opts the way they are, or just deprecating a part of them (but it will miss the purpose of this code refactoring). Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- Adding a new ""enable_iser"" parameter, set to ""False"" by default. This parameter will be used in TGT or LIO volume creation for setting RDMA based portals. This single parameter will deprecate all iser_opts parameters, that are a duplication from iscsi parameters. Developer impact ---------------- This change will simplify the maintanance of the iSER driver flow, since no extra classes or duplicated parameters will be used. Implementation ============== Assignee(s) ----------- Aviram Bar-Haim <aviramb@mellanox.com> Work Items ---------- #. Fix bug https://bugs.launchpad.net/cinder/+bug/1396265 and add the correct driver parameter, with a configurable value to VOLUME_CONF and VOLUME_CONF_WITH_CHAP_AUTH. #. Add a new ""enable_iser"" parameter that is set to false by default. #. Set the driver parameter at the VOLUME_CONFs template in TgtAdm for the TGT case. #. Add _set_iser(1) on the network portal object in rtslib for the LIO case, according to ""enable_iser"" value. #. Set ISCSIDriver's ""driver_volume_type"" to ""iscsi"" or ""iser"" value, according to the ""enable_iser"" value. Dependencies ============ None Testing ======= HW that supports RDMA is required in order to test volume attachment over iSER. A new unit test will be added with the new enable_iser parameter over iSCSI volume driver. Documentation Impact ==================== After adding the new enable_iser parameter, An updated iSER configuration guidelines will be added to: * https://wiki.openstack.org/wiki/Mellanox-Cinder * http://docs.openstack.org/juno/config-reference/content/lvm-volume-driver.html * http://community.mellanox.com/docs/DOC-1462 References ========== None ",,142,0
openstack%2Fcinder-specs~master~I574550889421497743485613b773f1500cbeabb4,openstack/cinder-specs,master,I574550889421497743485613b773f1500cbeabb4,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:40:52.000000000,2014-12-17 23:11:13.000000000,2014-12-17 23:11:11.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 6491}]","[{'number': 1, 'created': '2014-12-05 03:40:52.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/e813fbd1bd437589384ff0ffdc2f44fa504b2b93', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I574550889421497743485613b773f1500cbeabb4\n'}]",0,139315,e813fbd1bd437589384ff0ffdc2f44fa504b2b93,9,5,1,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: I574550889421497743485613b773f1500cbeabb4
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/15/139315/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,e813fbd1bd437589384ff0ffdc2f44fa504b2b93,infra-manual, http://docs.openstack.org/infra/manual/developers.html#development-workflow, https://wiki.openstack.org/wiki/Gerrit_Workflow,1,1
openstack%2Fproject-config~master~Id6dad2a37ab7cb0d602384ac41223becce181d0e,openstack/project-config,master,Id6dad2a37ab7cb0d602384ac41223becce181d0e,python-surveilclient: Added gate checks,MERGED,2014-12-16 19:32:43.000000000,2014-12-17 23:10:55.000000000,2014-12-17 23:10:53.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 11312}]","[{'number': 1, 'created': '2014-12-16 19:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/14422fda6a7b46e7c74a334c524cb04b97971b61', 'message': 'python-surveilclient: Added gate checks\n\nChange-Id: Id6dad2a37ab7cb0d602384ac41223becce181d0e\n'}, {'number': 2, 'created': '2014-12-16 19:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ad18f0112c39086caf60856aeb14fc58f46fe3a6', 'message': 'python-surveilclient: Added gate checks\n\nChange-Id: Id6dad2a37ab7cb0d602384ac41223becce181d0e\n'}, {'number': 3, 'created': '2014-12-16 19:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9639f6c73ddf094ba1f8f8e5ec582b5677fcf1c8', 'message': 'python-surveilclient: Added gate checks\n\nChange-Id: Id6dad2a37ab7cb0d602384ac41223becce181d0e\n'}, {'number': 4, 'created': '2014-12-16 19:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/dae1baaca730f7dcbf708c231b89df7460a02c86', 'message': 'python-surveilclient: Added gate checks\n\nChange-Id: Id6dad2a37ab7cb0d602384ac41223becce181d0e\n'}, {'number': 5, 'created': '2014-12-16 19:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8ec5bb8dcff2d09025719bc070ba13aa209e8777', 'message': 'python-surveilclient: Added gate checks\n\nChange-Id: Id6dad2a37ab7cb0d602384ac41223becce181d0e\n'}, {'number': 6, 'created': '2014-12-16 20:00:17.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/98b22a1b91011ddfab5fdeaacb44e1b5ef9cb340', 'message': 'python-surveilclient: Added gate checks\n\nChange-Id: Id6dad2a37ab7cb0d602384ac41223becce181d0e\n'}]",4,142202,98b22a1b91011ddfab5fdeaacb44e1b5ef9cb340,20,5,6,11312,,,0,"python-surveilclient: Added gate checks

Change-Id: Id6dad2a37ab7cb0d602384ac41223becce181d0e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/02/142202/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,14422fda6a7b46e7c74a334c524cb04b97971b61,, check: - gate-surveil-docs - gate-surveil-pep8 - gate-surveil-python27 gate: - gate-surveil-docs - gate-surveil-pep8 - gate-surveil-python27 ,,9,0
openstack%2Fproject-config~master~I97362b1cc6a8c19b54903e53638aba8cb4928e19,openstack/project-config,master,I97362b1cc6a8c19b54903e53638aba8cb4928e19,Fix the log path returned from zuul,MERGED,2014-12-17 01:11:19.000000000,2014-12-17 23:10:44.000000000,2014-12-17 23:10:43.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 11610}]","[{'number': 1, 'created': '2014-12-17 01:11:19.000000000', 'files': ['zuul/openstack_functions.py'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4be76786165e3769194908815c200bfabf620d12', 'message': ""Fix the log path returned from zuul\n\nLogs are currently coming back from zuul with two slashes in them.\nThe paths already have a trailing slash so the final LOG_PATH doesn't\nneed to add it.\n\nChange-Id: I97362b1cc6a8c19b54903e53638aba8cb4928e19\n""}]",0,142291,4be76786165e3769194908815c200bfabf620d12,9,5,1,7069,,,0,"Fix the log path returned from zuul

Logs are currently coming back from zuul with two slashes in them.
The paths already have a trailing slash so the final LOG_PATH doesn't
need to add it.

Change-Id: I97362b1cc6a8c19b54903e53638aba8cb4928e19
",git fetch https://review.opendev.org/openstack/project-config refs/changes/91/142291/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/openstack_functions.py'],1,4be76786165e3769194908815c200bfabf620d12,fix_log_path," params['LOG_PATH'] = path + '%s/%s/' % (job.name, params['ZUUL_UUID'][:7])"," params['LOG_PATH'] = path + '/%s/%s/' % (job.name, params['ZUUL_UUID'][:7])",2,2
openstack%2Fproject-config~master~Iecc635824fcde2d00bf42ff6ebac0cc57735843d,openstack/project-config,master,Iecc635824fcde2d00bf42ff6ebac0cc57735843d,openstack/requirements stable branch ACL update,MERGED,2014-12-17 13:49:13.000000000,2014-12-17 23:10:17.000000000,2014-12-17 23:10:17.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1106}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-17 13:49:13.000000000', 'files': ['gerrit/acls/openstack/requirements.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/629fb08b25c87d8504242999f6d293dd58683989', 'message': 'openstack/requirements stable branch ACL update\n\nWe recently switched stable branches changes to be reviewed by specific\nteams instead of a common team. The openstack/requirements repository\nmakes use of stable branches but was left out of the previous changes\n(since it does not rely on a project-specific team).\n\nThis commit assigns requirements stable branch reviews to the new,\ncross-project, stable-maint-core team.\n\nChange-Id: Iecc635824fcde2d00bf42ff6ebac0cc57735843d\n'}]",0,142446,629fb08b25c87d8504242999f6d293dd58683989,9,5,1,308,,,0,"openstack/requirements stable branch ACL update

We recently switched stable branches changes to be reviewed by specific
teams instead of a common team. The openstack/requirements repository
makes use of stable branches but was left out of the previous changes
(since it does not rely on a project-specific team).

This commit assigns requirements stable branch reviews to the new,
cross-project, stable-maint-core team.

Change-Id: Iecc635824fcde2d00bf42ff6ebac0cc57735843d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/46/142446/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/requirements.config'],1,629fb08b25c87d8504242999f6d293dd58683989,requirements-stable-acl,"[access ""refs/heads/stable/*""] abandon = group stable-maint-core exclusiveGroupPermissions = abandon label-Code-Review label-Workflow label-Code-Review = -2..+2 group stable-maint-core label-Code-Review = -1..+1 group Registered Users label-Workflow = -1..+1 group stable-maint-core ",,7,0
openstack%2Ffuel-docs~master~If9cef6761cc58b97b438e207e2faad590c421609,openstack/fuel-docs,master,If9cef6761cc58b97b438e207e2faad590c421609,Adds Datastore regexp option to set for vCenter,MERGED,2014-11-28 11:25:37.000000000,2014-12-17 23:09:27.000000000,2014-12-17 23:09:25.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 12139}, {'_account_id': 13082}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-11-28 11:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/918d7119c50d63b8d9815bf15c2101f8ceec6055', 'message': ""Adds Datastore regexp option to set for vCenter\n\nSince the Fuel web UI now enables setting Datastore regexp for vCenter,\nlet's add a note about it in the User Guide.\n\nChange-Id: If9cef6761cc58b97b438e207e2faad590c421609\nCloses-Bug: 1396972\n""}, {'number': 2, 'created': '2014-12-01 10:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4e4ed32bcd5e34843b8f69358fcee12eeeef9bf3', 'message': ""Adds Datastore regexp option to set for vCenter\n\nSince the Fuel web UI now enables setting Datastore regexp for vCenter,\nlet's add a note about it in the User Guide.\n\nChange-Id: If9cef6761cc58b97b438e207e2faad590c421609\nCloses-Bug: 1396972\n""}, {'number': 3, 'created': '2014-12-01 11:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ab7879097c6a26b4ad200c02d035de36dfc6f771', 'message': ""Adds Datastore regexp option to set for vCenter\n\nSince the Fuel web UI now enables setting Datastore regexp for vCenter,\nlet's add a note about it in the User Guide.\n\nChange-Id: If9cef6761cc58b97b438e207e2faad590c421609\nCloses-Bug: 1396972\n""}, {'number': 4, 'created': '2014-12-01 11:44:08.000000000', 'files': ['pages/user-guide/7300-vcenter.rst', '_images/vcenter-regexp.png'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/9cd97f8d186bbc686339b7313931724d83b5bbad', 'message': ""Adds Datastore regexp option to set for vCenter\n\nSince the Fuel web UI now enables setting Datastore regexp for vCenter,\nlet's add a note about it in the User Guide.\n\nChange-Id: If9cef6761cc58b97b438e207e2faad590c421609\nCloses-Bug: 1396972\n""}]",1,137767,9cd97f8d186bbc686339b7313931724d83b5bbad,27,9,4,13082,,,0,"Adds Datastore regexp option to set for vCenter

Since the Fuel web UI now enables setting Datastore regexp for vCenter,
let's add a note about it in the User Guide.

Change-Id: If9cef6761cc58b97b438e207e2faad590c421609
Closes-Bug: 1396972
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/67/137767/4 && git format-patch -1 --stdout FETCH_HEAD,['pages/user-guide/7300-vcenter.rst'],1,918d7119c50d63b8d9815bf15c2101f8ceec6055,bug/1396972,.. note: The Fuel web UI now has a new option for vCenter: Datastore regexp setting is enabled to specify the data stores to use with Compute. ,,4,0
openstack%2Fproject-config~master~Ibfbf2ecb7f8dfea207171965eb23f86450bdaf4f,openstack/project-config,master,Ibfbf2ecb7f8dfea207171965eb23f86450bdaf4f,Fix the OSSA ACL config,ABANDONED,2014-12-16 23:22:41.000000000,2014-12-17 21:57:38.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1106}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-16 23:22:41.000000000', 'files': ['gerrit/acls/openstack/ossa.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/80c7d9f0913f3cf3205e21894aefac05309931fe', 'message': 'Fix the OSSA ACL config\n\nChange-Id: Ibfbf2ecb7f8dfea207171965eb23f86450bdaf4f\n'}]",0,142258,80c7d9f0913f3cf3205e21894aefac05309931fe,8,5,1,748,,,0,"Fix the OSSA ACL config

Change-Id: Ibfbf2ecb7f8dfea207171965eb23f86450bdaf4f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/58/142258/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/ossa.config'],1,80c7d9f0913f3cf3205e21894aefac05309931fe,extend-acl-check,abandon = group vmt-core label-Code-Review = -2..+2 group vmt-core label-Workflow = -1..+1 group vmt-core,abandon = group vmt label-Code-Review = -2..+2 group vmt label-Workflow = -1..+1 group vmt,3,3
openstack%2Fcongress~master~I3596bce0b2715fd8722850c46e03faf4d64b77c9,openstack/congress,master,I3596bce0b2715fd8722850c46e03faf4d64b77c9,Modifying identation for pep8,ABANDONED,2014-12-17 20:24:40.000000000,2014-12-17 21:43:28.000000000,,"[{'_account_id': 4395}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-17 20:24:40.000000000', 'files': ['congress/openstack/common/eventlet_backdoor.py', 'congress/tests/policy/brokentest_runtime.py', 'congress/tests/datasources/test_datasource_driver.py', 'congress/openstack/common/policy.py', 'congress/tests/policy/test_runtime.py', 'congress/datasources/swift_driver.py', 'congress/tests/datasources/test_neutron_driver.py', 'congress/dse/deepsix.py', 'congress/tests/datasources/test_plexxi_driver.py', 'congress/datasources/datasource_driver.py', 'congress/policy/dsepolicy.py', 'congress/policy/runtime.py', 'congress/tests/policy/test_unify.py', 'congress/harness.py', 'congress/datasources/plexxi_driver.py', 'congress/policy/unify.py', 'congress/tests/policy/test_compiler.py', 'congress/datasources/ceilometer_driver.py', 'congress/tests/policy/builtin/test_builtin.py', 'congress/tests/policy/test_materialized.py', 'tox.ini', 'congress/tests/test_benchmark_updates.py', 'congress/tests/datasources/test_swift_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/544e9c4c18d73e40989122e536c090b24525bec4', 'message': 'Modifying identation for pep8\n\nCleaning up indentation in various files in order to enable E128 pep8 check.\n\nChange-Id: I3596bce0b2715fd8722850c46e03faf4d64b77c9\nCloses-Bug: #1403636\n'}]",0,142571,544e9c4c18d73e40989122e536c090b24525bec4,4,2,1,13593,,,0,"Modifying identation for pep8

Cleaning up indentation in various files in order to enable E128 pep8 check.

Change-Id: I3596bce0b2715fd8722850c46e03faf4d64b77c9
Closes-Bug: #1403636
",git fetch https://review.opendev.org/openstack/congress refs/changes/71/142571/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/openstack/common/eventlet_backdoor.py', 'congress/tests/policy/brokentest_runtime.py', 'congress/tests/datasources/test_datasource_driver.py', 'congress/openstack/common/policy.py', 'congress/tests/policy/test_runtime.py', 'congress/datasources/swift_driver.py', 'congress/tests/datasources/test_neutron_driver.py', 'congress/dse/deepsix.py', 'congress/tests/datasources/test_plexxi_driver.py', 'congress/datasources/datasource_driver.py', 'congress/policy/dsepolicy.py', 'congress/policy/runtime.py', 'congress/tests/policy/test_unify.py', 'congress/harness.py', 'congress/datasources/plexxi_driver.py', 'congress/policy/unify.py', 'congress/tests/policy/test_compiler.py', 'congress/datasources/ceilometer_driver.py', 'congress/tests/policy/builtin/test_builtin.py', 'congress/tests/policy/test_materialized.py', 'tox.ini', 'congress/tests/test_benchmark_updates.py', 'congress/tests/datasources/test_swift_driver.py']",23,544e9c4c18d73e40989122e536c090b24525bec4,," '9204776814ca62c92c7996de725ecc6b', 'file-1', 'application/octet-stream', 'container1'), object_list[0]) 'c2b86044dd50a29d60c0e92e23e3ceea', 'file-2', 'application/octet-stream', 'container2'), object_list[1]) '9204776814ca62c92c7996de725ecc6b', 'file-1', 'application/octet-stream', 'container1'), object_list[1]) 'c2b86044dd50a29d60c0e92e23e3ceea', 'file-2', 'application/octet-stream', 'container2'), object_list[0])"," '9204776814ca62c92c7996de725ecc6b', 'file-1', 'application/octet-stream', 'container1'), object_list[0]) 'c2b86044dd50a29d60c0e92e23e3ceea', 'file-2', 'application/octet-stream', 'container2'), object_list[1]) '9204776814ca62c92c7996de725ecc6b', 'file-1', 'application/octet-stream', 'container1'), object_list[1]) 'c2b86044dd50a29d60c0e92e23e3ceea', 'file-2', 'application/octet-stream', 'container2'), object_list[0])",90,90
openstack%2Fopenstack-ansible~stable%2Fjuno~I5d3b62b7e1c83f5879a20f9f511c244d9011526a,openstack/openstack-ansible,stable/juno,I5d3b62b7e1c83f5879a20f9f511c244d9011526a,Clone specific tag instead of branch,ABANDONED,2014-12-17 19:57:49.000000000,2014-12-17 21:31:36.000000000,,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-17 19:57:49.000000000', 'files': ['rpc_deployment/vars/repo_packages/openstack_global_requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/73071010b96700f47ff43371dd3b6dbe341844e3', 'message': 'Clone specific tag instead of branch\n\nChange last reference to stable/juno in branch. Now a tag is referenced instead\nof a branch.\n\nChange-Id: I5d3b62b7e1c83f5879a20f9f511c244d9011526a\nRelated-Bug: 1403018\nCloses-Bug: 1403628\n'}]",0,142563,73071010b96700f47ff43371dd3b6dbe341844e3,5,3,1,14119,,,0,"Clone specific tag instead of branch

Change last reference to stable/juno in branch. Now a tag is referenced instead
of a branch.

Change-Id: I5d3b62b7e1c83f5879a20f9f511c244d9011526a
Related-Bug: 1403018
Closes-Bug: 1403628
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/63/142563/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/vars/repo_packages/openstack_global_requirements.yml'],1,73071010b96700f47ff43371dd3b6dbe341844e3,bug/1403018,git_install_branch: 2014.2,git_install_branch: stable/juno,1,1
openstack%2Fpbr~feature%2F0.10~If10cf01c10bb8e8294229f8c3078af635731240d,openstack/pbr,feature/0.10,If10cf01c10bb8e8294229f8c3078af635731240d,Set review branch,ABANDONED,2014-12-17 19:42:17.000000000,2014-12-17 21:30:58.000000000,,[],"[{'number': 1, 'created': '2014-12-17 19:42:17.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/pbr/commit/092f809523277a46f4286264c100879e5c5991e4', 'message': 'Set review branch\n\nChange-Id: If10cf01c10bb8e8294229f8c3078af635731240d\n'}]",0,142560,092f809523277a46f4286264c100879e5c5991e4,2,0,1,2472,,,0,"Set review branch

Change-Id: If10cf01c10bb8e8294229f8c3078af635731240d
",git fetch https://review.opendev.org/openstack/pbr refs/changes/60/142560/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,092f809523277a46f4286264c100879e5c5991e4,bug/1403510,defaultbranch=feature/0.10,,1,0
openstack%2Fneutron~master~Id35a5f10cd7d2dda565bffb14fc6a2fbd7eef3ea,openstack/neutron,master,Id35a5f10cd7d2dda565bffb14fc6a2fbd7eef3ea,Refactor process_router method in L3 agent,MERGED,2014-12-09 00:59:50.000000000,2014-12-17 21:14:09.000000000,2014-12-13 02:34:52.000000000,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-09 00:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f87c02a70ed2d54f22526abb38da8ced23008399', 'message': 'Refactor process_router method in L3 agent\n\nRefactors the process_router method of the L3NATAgent class to several methods\nthat coherently group functionallity. The aim is to make the code more readable\nand maintainable. There is no functional change in this patch.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: Id35a5f10cd7d2dda565bffb14fc6a2fbd7eef3ea\n'}, {'number': 2, 'created': '2014-12-09 21:34:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e33783f8390b7d982ddc285fb3ab83e9e675427f', 'message': 'Refactor process_router method in L3 agent\n\nRefactors the process_router method of the L3NATAgent class to several methods\nthat coherently group functionallity. The aim is to make the code more readable\nand maintainable. There is no functional change in this patch.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: Id35a5f10cd7d2dda565bffb14fc6a2fbd7eef3ea\n'}, {'number': 3, 'created': '2014-12-10 00:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/11e85f80ec974f422afc4f4dea05aeb60d5084f5', 'message': 'Refactor process_router method in L3 agent\n\nRefactors the process_router method of the L3NATAgent class to several methods\nthat coherently group functionallity. The aim is to make the code more readable\nand maintainable. There is no functional change in this patch.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: Id35a5f10cd7d2dda565bffb14fc6a2fbd7eef3ea\n'}, {'number': 4, 'created': '2014-12-11 00:08:07.000000000', 'files': ['neutron/agent/l3/agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/db5dda5bef7f989e34b692443f9b82689c509199', 'message': 'Refactor process_router method in L3 agent\n\nRefactors the process_router method of the L3NATAgent class to several methods\nthat coherently group functionallity. The aim is to make the code more readable\nand maintainable. There is no functional change in this patch.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: Id35a5f10cd7d2dda565bffb14fc6a2fbd7eef3ea\n'}]",21,140193,db5dda5bef7f989e34b692443f9b82689c509199,105,29,4,4694,,,0,"Refactor process_router method in L3 agent

Refactors the process_router method of the L3NATAgent class to several methods
that coherently group functionallity. The aim is to make the code more readable
and maintainable. There is no functional change in this patch.

Partially-Implements: bp restructure-l3-agent

Change-Id: Id35a5f10cd7d2dda565bffb14fc6a2fbd7eef3ea
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/140193/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3/agent.py'],1,f87c02a70ed2d54f22526abb38da8ced23008399,bp/restructure-l3-agent," def _process_internal_ports(self, ri): # Enable RA # TODO!!! existing_devices needed outside this method def _process_external_gateway(self, ri): ex_gw_port = self._get_ex_gw_port(ri) existing_devices = self._get_existing_devices(ri) def _process_snat_dnat_for_fip(self, ri): ex_gw_port = self._get_ex_gw_port(ri) if not ex_gw_port: return existing_floating_ips = ri.floating_ips self.process_router_floating_ip_nat_rules(ri) ri.iptables_manager.defer_apply_off() # Once NAT rules for floating IPs are safely in place # configure their addresses on the external gateway port fip_statuses = self.process_router_floating_ip_addresses( ri, ex_gw_port) # Identify floating IPs which were disabled ri.floating_ips = set(fip_statuses.keys()) for fip_id in existing_floating_ips - ri.floating_ips: fip_statuses[fip_id] = l3_constants.FLOATINGIP_STATUS_DOWN # Update floating IP status on the neutron server self.plugin_rpc.update_floatingip_statuses( self.context, ri.router_id, fip_statuses) def _process_ha_router(self, ri): @common_utils.exception_logger() def process_router(self, ri): # TODO(mrsmith) - we shouldn't need to check here if 'distributed' not in ri.router: ri.router['distributed'] = False ri.iptables_manager.defer_apply_on() self._process_internal_ports(ri) self._process_external_gateway(ri) # Process static routes for router self.routes_updated(ri) # Process SNAT/DNAT rules for floating IPs self._process_snat_dnat_for_fip(ri) # Enable or disable keepalived for ha routers self._process_ha_router(ri) # Update ex_gw_port and enable_snat on the router info cache ri.ex_gw_port = self._get_ex_gw_port(ri) ri.snat_ports = ri.router.get(l3_constants.SNAT_ROUTER_INTF_KEY, []) ri.enable_snat = ri.router.get('enable_snat') "," @common_utils.exception_logger() def process_router(self, ri): # TODO(mrsmith) - we shouldn't need to check here if 'distributed' not in ri.router: ri.router['distributed'] = False ri.iptables_manager.defer_apply_on() ex_gw_port = self._get_ex_gw_port(ri) snat_ports = ri.router.get(l3_constants.SNAT_ROUTER_INTF_KEY, []) # TODO(salv-orlando): RouterInfo would be a better place for # this logic too # Process static routes for router self.routes_updated(ri) # Process SNAT/DNAT rules for floating IPs if ex_gw_port: existing_floating_ips = ri.floating_ips self.process_router_floating_ip_nat_rules(ri) ri.iptables_manager.defer_apply_off() # Once NAT rules for floating IPs are safely in place # configure their addresses on the external gateway port fip_statuses = self.process_router_floating_ip_addresses( ri, ex_gw_port) if ex_gw_port: # Identify floating IPs which were disabled ri.floating_ips = set(fip_statuses.keys()) for fip_id in existing_floating_ips - ri.floating_ips: fip_statuses[fip_id] = l3_constants.FLOATINGIP_STATUS_DOWN # Update floating IP status on the neutron server self.plugin_rpc.update_floatingip_statuses( self.context, ri.router_id, fip_statuses) # Update ex_gw_port and enable_snat on the router info cache ri.ex_gw_port = ex_gw_port ri.snat_ports = snat_ports ri.enable_snat = ri.router.get('enable_snat') ",49,34
openstack%2Fsecurity-doc~master~I4078ad13b72650116d922ac9ec8ada9e40c254ef,openstack/security-doc,master,I4078ad13b72650116d922ac9ec8ada9e40c254ef,Adding OSSN-0038: Suds local cache poisoning.,MERGED,2014-10-15 12:54:22.000000000,2014-12-17 21:10:58.000000000,2014-12-17 21:10:57.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2807}, {'_account_id': 5638}, {'_account_id': 6486}, {'_account_id': 6772}, {'_account_id': 7063}, {'_account_id': 9098}, {'_account_id': 11029}, {'_account_id': 11716}, {'_account_id': 12402}]","[{'number': 1, 'created': '2014-10-15 12:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/3a24083af9c552233b27f4218352ad926b75d989', 'message': 'Adding OSSN-0038: Suds local cache poisoning.\n\nChange-Id: I4078ad13b72650116d922ac9ec8ada9e40c254ef\nCloses-bug: 1341954\n'}, {'number': 2, 'created': '2014-10-16 09:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/bf4cd15a26df276fa5ca32e26d7c9fc10c653243', 'message': 'Adding OSSN-0038: Suds local cache poisoning.\n\nCloses-bug: 1341954\nChange-Id: I4078ad13b72650116d922ac9ec8ada9e40c254ef\n'}, {'number': 3, 'created': '2014-10-16 09:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/ad9b037578962a8d3bb172365d8c692e504b181f', 'message': 'Adding OSSN-0038: Suds local cache poisoning.\n\nCloses-bug: 1341954\nChange-Id: I4078ad13b72650116d922ac9ec8ada9e40c254ef\n'}, {'number': 4, 'created': '2014-10-30 15:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/5097beaa56b313c00632c2f6ce8b9e61aace91e3', 'message': 'Adding OSSN-0038: Suds local cache poisoning.\n\nCloses-bug: 1341954\nChange-Id: I4078ad13b72650116d922ac9ec8ada9e40c254ef\n'}, {'number': 5, 'created': '2014-10-31 13:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/9d4209c9ccd46e5c56aa38dd1eaf6ba5d59631b3', 'message': 'Adding OSSN-0038: Suds local cache poisoning.\n\nCloses-bug: 1341954\nChange-Id: I4078ad13b72650116d922ac9ec8ada9e40c254ef\n'}, {'number': 6, 'created': '2014-11-13 14:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/e987ac263d395baf58e87e52680c377d5728fb36', 'message': 'Adding OSSN-0038: Suds local cache poisoning.\n\nCloses-bug: 1341954\nChange-Id: I4078ad13b72650116d922ac9ec8ada9e40c254ef\n'}, {'number': 7, 'created': '2014-11-13 14:31:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/5730fa08aca3a9351b68e8bbfabb06b4b4872b31', 'message': 'Adding OSSN-0038: Suds local cache poisoning.\n\nCloses-bug: 1341954\nChange-Id: I4078ad13b72650116d922ac9ec8ada9e40c254ef\n'}, {'number': 8, 'created': '2014-12-11 18:09:59.000000000', 'files': ['security-notes/OSSN-0038'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/762e408d5f729126a2374e412170acfad72f269a', 'message': 'Adding OSSN-0038: Suds local cache poisoning.\n\nCloses-bug: 1341954\nChange-Id: I4078ad13b72650116d922ac9ec8ada9e40c254ef\n'}]",42,128636,762e408d5f729126a2374e412170acfad72f269a,48,11,8,11716,,,0,"Adding OSSN-0038: Suds local cache poisoning.

Closes-bug: 1341954
Change-Id: I4078ad13b72650116d922ac9ec8ada9e40c254ef
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/36/128636/7 && git format-patch -1 --stdout FETCH_HEAD,['security-notes/OSSN-0038'],1,3a24083af9c552233b27f4218352ad926b75d989,bug/1341954,"Suds client subject to cache poisoning by local attacker --- ### Summary ### Suds is a Python SOAP client for consuming Web Services. Its default cache implementation stores pickled objects to a predictable path in /tmp. This can be used by a local attacker to redirect SOAP requests via symlinks or run a privilege escalation / code execution attack via a pickle exploit. ### Affected Services / Software ### Cinder, Nova, Oslo.vmware - Grizzly, Havana, Icehouse ### Discussion ### The python 'suds' package is used by oslo.vmware to interface with SOAP service APIs and both Cinder and Nova have dependencies on oslo.vmware. By default suds uses an on-disk cache that places pickle files into a known location '/tmp/suds'. An attacker could use symlinks or place crafted files into this location that would later be deserialised by suds using the python pickle mechanism. This opens the potential for arbitrary code execution via pickle based exploits, the code will run with the permissions of service using suds and can thus lead to possible privilege escalation. At the time of writing, the suds package appears largely unmaintained upstream. However, venders have released patched versions that do not suffer from the predictable cache path problem, Ubuntu is known to offer one such patched version. ### Recommended Actions ### Potential ways to fix this include explicitly setting the cache location to a directory created via tempfile.mkdtemp() or disabling cache usage in the configuration as show: 'client.set_options(cache=None)' A fix has been released to oslo.vmware that disables the use of the disk cache by default. Cinder and Nova have both bummed their requirements to include this fixed version. Deployers wishing to re-enable the cache should ascertain whether or not their vender shipped suds package is susceptible and consider the above advice. ### Contacts / References ### This OSSN : https://wiki.openstack.org/wiki/OSSN/OSSN-0030 Original LaunchPad Bug : https://bugs.launchpad.net/ossn/+bug/1341954 OpenStack Security ML : openstack-security@lists.openstack.org OpenStack Security Group : https://launchpad.net/~openstack-ossg Suds: https://pypi.python.org/pypi/suds",,48,0
openstack%2Fkeystone-specs~master~I4031c50b76e759f445dc7dfdb08789de7c2abc5f,openstack/keystone-specs,master,I4031c50b76e759f445dc7dfdb08789de7c2abc5f,Fix RST formatting issues,MERGED,2014-12-15 22:57:39.000000000,2014-12-17 21:10:03.000000000,2014-12-17 21:10:01.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 964}, {'_account_id': 2903}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 9142}, {'_account_id': 10873}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-12-15 22:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/21111606c582366ff69f459e3be65701cd68de13', 'message': 'Fix RST formatting issues\n\nAll of these issues were the results of the automated\nmarkdown-to-restructuredtext conversion. This is mostly just whitespace\nchanges, so I did them all at once, but they affect the rendering of the\nfinal document considerably.\n\nChange-Id: I4031c50b76e759f445dc7dfdb08789de7c2abc5f\nCloses-Bug: 1402824\n'}, {'number': 2, 'created': '2014-12-16 21:08:15.000000000', 'files': ['api/v3/identity-api-v3-os-endpoint-policy.rst', 'api/v3/identity-api-v3-os-ep-filter-ext.rst', 'api/v3/identity-api-v3-os-revoke-ext.rst', 'api/v3/identity-api-v3.rst', 'api/v3/identity-api-v3-os-trust-ext.rst', 'api/v3/identity-api-v3-os-inherit-ext.rst', 'api/v3/identity-api-v3-os-oauth1-ext.rst', 'api/v3/identity-api-v3-os-federation-ext.rst', 'api/v3/identity-api-v3-os-simple-certs-ext.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/0b60632f8f8d428d5f1687640db27b4d2f885265', 'message': 'Fix RST formatting issues\n\nAll of these issues were the results of the automated\nmarkdown-to-restructuredtext conversion. This is mostly just whitespace\nchanges, so I did them all at once, but they affect the rendering of the\nfinal document considerably.\n\nChange-Id: I4031c50b76e759f445dc7dfdb08789de7c2abc5f\nCloses-Bug: 1402824\n'}]",7,141930,0b60632f8f8d428d5f1687640db27b4d2f885265,19,9,2,4,,,0,"Fix RST formatting issues

All of these issues were the results of the automated
markdown-to-restructuredtext conversion. This is mostly just whitespace
changes, so I did them all at once, but they affect the rendering of the
final document considerably.

Change-Id: I4031c50b76e759f445dc7dfdb08789de7c2abc5f
Closes-Bug: 1402824
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/30/141930/1 && git format-patch -1 --stdout FETCH_HEAD,"['api/v3/identity-api-v3-os-endpoint-policy.rst', 'api/v3/identity-api-v3-os-ep-filter-ext.rst', 'api/v3/identity-api-v3-os-revoke-ext.rst', 'api/v3/identity-api-v3.rst', 'api/v3/identity-api-v3-os-trust-ext.rst', 'api/v3/identity-api-v3-os-inherit-ext.rst', 'api/v3/identity-api-v3-os-oauth1-ext.rst', 'api/v3/identity-api-v3-os-federation-ext.rst', 'api/v3/identity-api-v3-os-simple-certs-ext.rst']",9,21111606c582366ff69f459e3be65701cd68de13,bug/1402824,"When using Public Key Infrastructure (PKI) tokens with the identity service, users must have access to the signing certificate and the certificate authority's (CA) certificate for the token issuer in order to validate tokens. This extension provides a simple means of retrieving these certificates from an identity service.The identity server uses X.509 certificates to cryptographically sign issued tokens. Certificates are a public resource and can be shared. Typically when validating a certificate we would only require the issuing certificate authority's certificate however PKI tokens are distributed without including the original signing certificate in the message so this must be retrievable as well. Certificates are provided in the Private Enchanced Mail (PEM) file format. Certificates in PEM files can be represented with or without the certificate data (examples shown). The represented certificate is for informative purposes and the only required information is presented between the ``-----BEGIN CERTIFICATE-----`` and ``-----END CERTIFICATE-----`` tags.It is possible that a chain of certificates (more than one) is returned. In this case the chain should be used when validating a token.Fetches the certificates containing the public key for the private key that has been used to sign tokens. In an environment with multiple token signers this call will return all valid certificates.There are no certificates to be returned. This will typically indicate that keystone is using UUID tokens and therefore there are no certificates available.An Error was produced on the server. A typical example is that the server is configured to use PKI tokens but is misconfigured and the certificates were unable to be found.","When using Public Key Infrastructure (PKI) tokens with the identity service, users must have access to the signing certificate and the certificate authority's (CA) certificate for the token issuer in order to validate tokens. This extension provides a simple means of retrieving these certificates from an identity service.The identity server uses X.509 certificates to cryptographically sign issued tokens. Certificates are a public resource and can be shared. Typically when validating a certificate we would only require the issuing certificate authority's certificate however PKI tokens are distributed without including the original signing certificate in the message so this must be retrievable as well. Certificates are provided in the Private Enchanced Mail (PEM) file format. Certificates in PEM files can be represented with or without the certificate data (examples shown). The represented certificate is for informative purposes and the only required information is presented between the ``-----BEGIN CERTIFICATE-----`` and ``-----END CERTIFICATE-----`` tags.It is possible that a chain of certificates (more than one) is returned. In this case the chain should be used when validating a token.Fetches the certificates containing the public key for the private key that has been used to sign tokens. In an environment with multiple token signers this call will return all valid certificates.There are no certificates to be returned. This will typically indicate that keystone is using UUID tokens and therefore there are no certificates available.An Error was produced on the server. A typical example is that the server is configured to use PKI tokens but is misconfigured and the certificates were unable to be found.",1237,1270
openstack%2Fkolla~master~I67dff2b16a99bc44e928cd6a679dff8cc6a99b39,openstack/kolla,master,I67dff2b16a99bc44e928cd6a679dff8cc6a99b39,Reduce code duplication in kolla-common.sh,MERGED,2014-12-17 04:15:53.000000000,2014-12-17 21:08:04.000000000,2014-12-17 21:08:04.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6836}]","[{'number': 1, 'created': '2014-12-17 04:15:53.000000000', 'files': ['docker/fedora-rdo-base/kolla-common.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/e1b90581c0da0a9bb1b3d5d1b82ca11eb9cfad31', 'message': 'Reduce code duplication in kolla-common.sh\n\nIntroduce a generic check_for_os_service function that exits unless it\nreceives a successful response from the corresponding OpenStack service.\n\nAdditionally use the local keyword to not leak local variables, and fix\ncheck for non-existing NEUTRON_API_SERVICE_HOST variable in\ncheck_for_neutron().\n\nChange-Id: I67dff2b16a99bc44e928cd6a679dff8cc6a99b39\n'}]",0,142338,e1b90581c0da0a9bb1b3d5d1b82ca11eb9cfad31,7,3,1,13039,,,0,"Reduce code duplication in kolla-common.sh

Introduce a generic check_for_os_service function that exits unless it
receives a successful response from the corresponding OpenStack service.

Additionally use the local keyword to not leak local variables, and fix
check for non-existing NEUTRON_API_SERVICE_HOST variable in
check_for_neutron().

Change-Id: I67dff2b16a99bc44e928cd6a679dff8cc6a99b39
",git fetch https://review.opendev.org/openstack/kolla refs/changes/38/142338/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/fedora-rdo-base/kolla-common.sh'],1,e1b90581c0da0a9bb1b3d5d1b82ca11eb9cfad31,refactor_kolla-common,"# Exit unless we receive a successful response from corresponding OpenStack # service. check_for_os_service() { local name=$1 local host_var=$2 local port=$3 local api_version=$4 check_required_vars $host_var local endpoint=""http://${!host_var}:$port/$api_version"" curl -sf -o /dev/null ""$endpoint"" || { echo ""ERROR: $name is not available @ $endpoint"" >&2 exit 1 } echo ""$name is active @ $endpoint"" } check_for_glance() { check_for_os_service glance GLANCE_API_SERVICE_HOST 9292 } check_for_keystone() { check_for_os_service keystone KEYSTONE_PUBLIC_SERVICE_HOST 5000 v2.0 } check_for_nova() { check_for_os_service nova NOVA_API_SERVICE_HOST 8774 } check_for_neutron() { check_for_os_service neutron NEUTRON_SERVER_SERVICE_HOST 9696","# Exit unless we receive a successful response from the Glance API. check_for_glance() { check_required_vars GLANCE_API_SERVICE_HOST GLANCE_API_URL=""http://${GLANCE_API_SERVICE_HOST}:9292/"" curl -sf -o /dev/null ""$GLANCE_API_URL"" || { echo ""ERROR: glance is not available @ $GLANCE_API_URL"" >&2 exit 1 } echo ""glance is active @ $GLANCE_API_URL"" } # Exit unless we receive a successful response from the Keystone API. check_for_keystone() { check_required_vars KEYSTONE_PUBLIC_SERVICE_HOST KEYSTONE_URL=""http://${KEYSTONE_PUBLIC_SERVICE_HOST}:5000/v2.0"" curl -sf -o /dev/null ""$KEYSTONE_URL"" || { echo ""ERROR: keystone is not available @ $KEYSTONE_URL"" >&2 exit 1 } echo ""keystone is active @ $KEYSTONE_URL"" } # Exit unless we receive a successful response from the Nova API. check_for_nova() { check_required_vars NOVA_API_SERVICE_HOST NOVA_API_URL=""http://${NOVA_API_SERVICE_HOST}:8774"" curl -sf -o /dev/null ""$NOVA_API_URL"" || { echo ""ERROR: nova is not available @ $NOVA_API_URL"" >&2 exit 1 } echo ""nova is active @ $NOVA_API_URL"" } # Exit unless we receive a successful response from the Neutron API. check_for_neutron() { check_required_vars NEUTRON_API_SERVICE_HOST NEUTRON_API_URL=""http://${NEUTRON_SERVER_SERVICE_HOST}:9696"" curl -sf -o /dev/null ""$NEUTRON_API_URL"" || { echo ""ERROR: neutron is not available @ $NEUTRON_API_URL"" >&2 exit 1 } echo ""neutron is active @ $NEUTRON_API_URL""",24,43
openstack%2Fkolla~master~I89719e084fcea7010dd6a29beba999e04989d8c5,openstack/kolla,master,I89719e084fcea7010dd6a29beba999e04989d8c5,Remove unused libvirt-service.json file,MERGED,2014-12-17 04:03:26.000000000,2014-12-17 21:07:58.000000000,2014-12-17 21:07:58.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6836}]","[{'number': 1, 'created': '2014-12-17 04:03:26.000000000', 'files': ['k8s/service/libvirt-service.json'], 'web_link': 'https://opendev.org/openstack/kolla/commit/7317a86b08e67713ef3bdd82f4a85d271b05b7e2', 'message': 'Remove unused libvirt-service.json file\n\nThis file is a duplicate of nova-libvirt-service.yaml and is presumably\na merge accident after all service files were converted to yaml.\n\nChange-Id: I89719e084fcea7010dd6a29beba999e04989d8c5\n'}]",0,142331,7317a86b08e67713ef3bdd82f4a85d271b05b7e2,7,3,1,13039,,,0,"Remove unused libvirt-service.json file

This file is a duplicate of nova-libvirt-service.yaml and is presumably
a merge accident after all service files were converted to yaml.

Change-Id: I89719e084fcea7010dd6a29beba999e04989d8c5
",git fetch https://review.opendev.org/openstack/kolla refs/changes/31/142331/1 && git format-patch -1 --stdout FETCH_HEAD,['k8s/service/libvirt-service.json'],1,7317a86b08e67713ef3bdd82f4a85d271b05b7e2,libvirt-service_json,,"{ ""id"": ""libvirt"", ""kind"": ""Service"", ""apiVersion"": ""v1beta1"", ""port"": 16509, ""containerPort"": 16509, ""selector"": { ""name"": ""nova-compute"" } } ",0,10
openstack%2Fkolla~master~I514953471646904b541321d1d878d40a2c8f8b26,openstack/kolla,master,I514953471646904b541321d1d878d40a2c8f8b26,Add gitignore file,MERGED,2014-12-17 03:53:55.000000000,2014-12-17 21:07:51.000000000,2014-12-17 21:07:51.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6836}]","[{'number': 1, 'created': '2014-12-17 03:53:55.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/kolla/commit/363eb0939e36ff83cd8d846f2d43cb4a7d75f15b', 'message': ""Add gitignore file\n\nThe initial gitignore includes build-docker-image script's private\nconfiguration file, tox generated files and common temp files created by\nvim and emacs.\n\nChange-Id: I514953471646904b541321d1d878d40a2c8f8b26\n""}]",0,142326,363eb0939e36ff83cd8d846f2d43cb4a7d75f15b,7,3,1,13039,,,0,"Add gitignore file

The initial gitignore includes build-docker-image script's private
configuration file, tox generated files and common temp files created by
vim and emacs.

Change-Id: I514953471646904b541321d1d878d40a2c8f8b26
",git fetch https://review.opendev.org/openstack/kolla refs/changes/26/142326/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,363eb0939e36ff83cd8d846f2d43cb4a7d75f15b,gitignore,# vim and emacs temp files *~ [._]*.s[a-w][a-z] .tox/ .buildconf ,,6,0
openstack%2Fkolla~master~Ib65b0189d0a767212fbb7eff4ce81717d492c3e2,openstack/kolla,master,Ib65b0189d0a767212fbb7eff4ce81717d492c3e2,Fix use of undefined KEYSTONE_SERVICE_HOST in Ceilometer,MERGED,2014-12-17 04:24:35.000000000,2014-12-17 21:07:41.000000000,2014-12-17 21:07:41.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6836}]","[{'number': 1, 'created': '2014-12-17 04:24:35.000000000', 'files': ['docker/ceilometer/ceilometer-base/config-ceilometer.sh', 'docker/ceilometer/ceilometer-compute/start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/bfa5d0a2ec8599be983d11acc09e326f5b84263d', 'message': 'Fix use of undefined KEYSTONE_SERVICE_HOST in Ceilometer\n\nThis variable is never defined anywhere, and it is not one of the\nvariable automatically exported by k8s or docker.\nIt should be KEYSTONE_PUBLIC_SERVICE_HOST instead.\n\nChange-Id: Ib65b0189d0a767212fbb7eff4ce81717d492c3e2\n'}]",0,142340,bfa5d0a2ec8599be983d11acc09e326f5b84263d,7,3,1,13039,,,0,"Fix use of undefined KEYSTONE_SERVICE_HOST in Ceilometer

This variable is never defined anywhere, and it is not one of the
variable automatically exported by k8s or docker.
It should be KEYSTONE_PUBLIC_SERVICE_HOST instead.

Change-Id: Ib65b0189d0a767212fbb7eff4ce81717d492c3e2
",git fetch https://review.opendev.org/openstack/kolla refs/changes/40/142340/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/ceilometer/ceilometer-base/config-ceilometer.sh', 'docker/ceilometer/ceilometer-compute/start.sh']",2,bfa5d0a2ec8599be983d11acc09e326f5b84263d,fix_undefined_KEYSTONE_SERVICE_HOST,check_required_vars KEYSTONE_ADMIN_TOKEN RABBITMQ_SERVICE_HOST KEYSTONE_AUTH_PROTOCOL CEILOMETER_KEYSTONE_USER ADMIN_TENANT_NAMEcrudini --set $cfg rabbit_host ${RABBITMQ_SERVICE_HOST},check_required_vars KEYSTONE_ADMIN_TOKEN KEYSTONE_SERVICE_HOST KEYSTONE_AUTH_PROTOCOL CEILOMETER_KEYSTONE_USER ADMIN_TENANT_NAMEcrudini --set $cfg rabbit_host ${KEYSTONE_SERVICE_HOST},5,5
openstack%2Ftripleo-image-elements~master~Ia90a83da27cd4767425c4913fd150d5df5c3163e,openstack/tripleo-image-elements,master,Ia90a83da27cd4767425c4913fd150d5df5c3163e,os-net-config: log at log level info again...,MERGED,2014-12-17 13:59:53.000000000,2014-12-17 21:06:25.000000000,2014-12-17 21:06:24.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 4328}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-12-17 13:59:53.000000000', 'files': ['elements/neutron-openvswitch-agent/bin/init-neutron-ovs', 'elements/os-net-config/os-refresh-config/configure.d/20-os-net-config'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/2df6e04fe06869c06bf2eb0933b1262ae36a7116', 'message': 'os-net-config: log at log level info again...\n\nWe standardized the logging options in os-net-config in\nI31005e4e10372018685a93dc2f80619f16c513d9. Previously\nos-net-config was functionally logging at the info level\nhowever, which is what we want.\n\nThis patch switches all the os-net-config commands to use\n-v INFO level logging again.\n\nChange-Id: Ia90a83da27cd4767425c4913fd150d5df5c3163e\n'}]",0,142447,2df6e04fe06869c06bf2eb0933b1262ae36a7116,9,5,1,360,,,0,"os-net-config: log at log level info again...

We standardized the logging options in os-net-config in
I31005e4e10372018685a93dc2f80619f16c513d9. Previously
os-net-config was functionally logging at the info level
however, which is what we want.

This patch switches all the os-net-config commands to use
-v INFO level logging again.

Change-Id: Ia90a83da27cd4767425c4913fd150d5df5c3163e
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/47/142447/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/neutron-openvswitch-agent/bin/init-neutron-ovs', 'elements/os-net-config/os-refresh-config/configure.d/20-os-net-config']",2,2df6e04fe06869c06bf2eb0933b1262ae36a7116,os-net-config-log-fix, os-net-config -c /etc/os-net-config/config.json -v, os-net-config -c /etc/os-net-config/config.json -d,2,2
